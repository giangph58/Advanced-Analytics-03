{"aid":"http://arxiv.org/abs/2503.21690v1","title":"CMED: A Child Micro-Expression Dataset","summary":"Micro-expressions are short bursts of emotion that are difficult to hide.\nTheir detection in children is an important cue to assist psychotherapists in\nconducting better therapy. However, existing research on the detection of\nmicro-expressions has focused on adults, whose expressions differ in their\ncharacteristics from those of children. The lack of research is a direct\nconsequence of the lack of a child-based micro-expressions dataset as it is\nmuch more challenging to capture children's facial expressions due to the lack\nof predictability and controllability. This study compiles a dataset of\nspontaneous child micro-expression videos, the first of its kind, to the best\nof the authors knowledge. The dataset is captured in the wild using video\nconferencing software. This dataset enables us to then explore key features and\ndifferences between adult and child micro-expressions. This study also\nestablishes a baseline for the automated spotting and recognition of\nmicro-expressions in children using three approaches comprising of hand-created\nand learning-based approaches.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T16:55:32Z"}
{"aid":"http://arxiv.org/abs/2503.21692v1","title":"RapidPoseTriangulation: Multi-view Multi-person Whole-body Human Pose\n  Triangulation in a Millisecond","summary":"The integration of multi-view imaging and pose estimation represents a\nsignificant advance in computer vision applications, offering new possibilities\nfor understanding human movement and interactions. This work presents a new\nalgorithm that improves multi-view multi-person pose estimation, focusing on\nfast triangulation speeds and good generalization capabilities. The approach\nextends to whole-body pose estimation, capturing details from facial\nexpressions to finger movements across multiple individuals and viewpoints.\nAdaptability to different settings is demonstrated through strong performance\nacross unseen datasets and configurations. To support further progress in this\nfield, all of this work is publicly accessible.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T16:57:33Z"}
{"aid":"http://arxiv.org/abs/2503.21719v1","title":"The Principle of Redundant Reflection","summary":"The fact that redundant information does not change a rational belief after\nBayesian updating implies uniqueness of Bayes rule. In fact, any updating rule\nis uniquely specified by this principle. This is true for the classical\nsetting, as well as settings with improper or continuous priors. We prove this\nresult and illustrate it with two examples.","main_category":"stat.ME","categories":"stat.ME,stat.OT","published":"2025-03-27T17:31:22Z"}
{"aid":"http://arxiv.org/abs/2503.21732v1","title":"SparseFlex: High-Resolution and Arbitrary-Topology 3D Shape Modeling","summary":"Creating high-fidelity 3D meshes with arbitrary topology, including open\nsurfaces and complex interiors, remains a significant challenge. Existing\nimplicit field methods often require costly and detail-degrading watertight\nconversion, while other approaches struggle with high resolutions. This paper\nintroduces SparseFlex, a novel sparse-structured isosurface representation that\nenables differentiable mesh reconstruction at resolutions up to $1024^3$\ndirectly from rendering losses. SparseFlex combines the accuracy of Flexicubes\nwith a sparse voxel structure, focusing computation on surface-adjacent regions\nand efficiently handling open surfaces. Crucially, we introduce a frustum-aware\nsectional voxel training strategy that activates only relevant voxels during\nrendering, dramatically reducing memory consumption and enabling\nhigh-resolution training. This also allows, for the first time, the\nreconstruction of mesh interiors using only rendering supervision. Building\nupon this, we demonstrate a complete shape modeling pipeline by training a\nvariational autoencoder (VAE) and a rectified flow transformer for high-quality\n3D shape generation. Our experiments show state-of-the-art reconstruction\naccuracy, with a ~82% reduction in Chamfer Distance and a ~88% increase in\nF-score compared to previous methods, and demonstrate the generation of\nhigh-resolution, detailed 3D shapes with arbitrary topology. By enabling\nhigh-resolution, differentiable mesh reconstruction and generation with\nrendering losses, SparseFlex significantly advances the state-of-the-art in 3D\nshape representation and modeling.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:46:42Z"}
{"aid":"http://arxiv.org/abs/2503.21756v1","title":"A Unified Framework for Diffusion Bridge Problems: Flow Matching and\n  Schr√∂dinger Matching into One","summary":"The bridge problem is to find an SDE (or sometimes an ODE) that bridges two\ngiven distributions. The application areas of the bridge problem are enormous,\namong which the recent generative modeling (e.g., conditional or unconditional\nimage generation) is the most popular. Also the famous Schr\\\"{o}dinger bridge\nproblem, a widely known problem for a century, is a special instance of the\nbridge problem. Two most popular algorithms to tackle the bridge problems in\nthe deep learning era are: (conditional) flow matching and iterative fitting\nalgorithms, where the former confined to ODE solutions, and the latter\nspecifically for the Schr\\\"{o}dinger bridge problem. The main contribution of\nthis article is in two folds: i) We provide concise reviews of these algorithms\nwith technical details to some extent; ii) We propose a novel unified\nperspective and framework that subsumes these seemingly unrelated algorithms\n(and their variants) into one. In particular, we show that our unified\nframework can instantiate the Flow Matching (FM) algorithm, the (mini-batch)\noptimal transport FM algorithm, the (mini-batch) Schr\\\"{o}dinger bridge FM\nalgorithm, and the deep Schr\\\"{o}dinger bridge matching (DSBM) algorithm as its\nspecial cases. We believe that this unified framework will be useful for\nviewing the bridge problems in a more general and flexible perspective, and in\nturn can help researchers and practitioners to develop new bridge algorithms in\ntheir fields.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-27T17:57:03Z"}
{"aid":"http://arxiv.org/abs/2503.21757v1","title":"Fwd2Bot: LVLM Visual Token Compression with Double Forward Bottleneck","summary":"In this work, we aim to compress the vision tokens of a Large Vision Language\nModel (LVLM) into a representation that is simultaneously suitable for (a)\ngenerative and (b) discriminative tasks, (c) is nearly lossless, and (d) is\nstorage-efficient. We propose a novel compression approach, called Fwd2Bot,\nthat uses the LVLM itself to compress the visual information in a task-agnostic\nmanner. At the core of Fwd2bot there exists a \"double-forward pass\" training\nstrategy, whereby, during the first forward pass, the LLM (of the LVLM) creates\na bottleneck by condensing the visual information into a small number of\nsummary tokens. Then, using the same LLM, the second forward pass processes the\nlanguage instruction(s) alongside the summary tokens, used as a direct\nreplacement for the image ones. The training signal is provided by two losses:\nan autoregressive one applied after the second pass that provides a direct\noptimization objective for compression, and a contrastive loss, applied after\nthe first pass, that further boosts the representation strength, especially for\ndiscriminative tasks. The training is further enhanced by stage-specific\nadapters. We accompany the proposed method by an in-depth ablation study.\nOverall, Fwd2Bot results in highly-informative compressed representations\nsuitable for both generative and discriminative tasks. For generative tasks, we\noffer a 2x higher compression rate without compromising the generative\ncapabilities, setting a new state-of-the-art result. For discriminative tasks,\nwe set a new state-of-the-art on image retrieval and compositionality.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-03-27T17:57:07Z"}
{"aid":"http://arxiv.org/abs/2503.21759v1","title":"Large Scale Structure and the Cosmic Web","summary":"The formation and evolution of galaxies cannot be separated from large scale\nstructure growth. Dark matter halos (and, therefore, galaxies) form and grow\nwithin the cosmic web - the classification of large-scale structure as distinct\nenvironments, namely voids, walls, filaments and nodes. Thanks to the rapid\ndevelopment of extragalactic spectroscopic redshift surveys and cosmological\nsimulations over the last two decades, we are now able to measure the impact of\nthe cosmic web on galaxies and halos in observations and in simulations. In\nthis chapter we summarise the state of play in our understanding of the link\nbetween dark matter halos, galaxies, and the cosmic web.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-03-27T17:57:19Z"}
{"aid":"http://arxiv.org/abs/2503.21767v1","title":"Semantic Consistent Language Gaussian Splatting for Point-Level\n  Open-vocabulary Querying","summary":"Open-vocabulary querying in 3D Gaussian Splatting aims to identify\nsemantically relevant regions within a 3D Gaussian representation based on a\ngiven text query. Prior work, such as LangSplat, addressed this task by\nretrieving these regions in the form of segmentation masks on 2D renderings.\nMore recently, OpenGaussian introduced point-level querying, which directly\nselects a subset of 3D Gaussians. In this work, we propose a point-level\nquerying method that builds upon LangSplat's framework. Our approach improves\nthe framework in two key ways: (a) we leverage masklets from the Segment\nAnything Model 2 (SAM2) to establish semantic consistent ground-truth for\ndistilling the language Gaussians; (b) we introduces a novel two-step querying\napproach that first retrieves the distilled ground-truth and subsequently uses\nthe ground-truth to query the individual Gaussians. Experimental evaluations on\nthree benchmark datasets demonstrate that the proposed method achieves better\nperformance compared to state-of-the-art approaches. For instance, our method\nachieves an mIoU improvement of +20.42 on the 3D-OVS dataset.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:05Z"}
{"aid":"http://arxiv.org/abs/2503.21770v1","title":"Visual Jenga: Discovering Object Dependencies via Counterfactual\n  Inpainting","summary":"This paper proposes a novel scene understanding task called Visual Jenga.\nDrawing inspiration from the game Jenga, the proposed task involves\nprogressively removing objects from a single image until only the background\nremains. Just as Jenga players must understand structural dependencies to\nmaintain tower stability, our task reveals the intrinsic relationships between\nscene elements by systematically exploring which objects can be removed while\npreserving scene coherence in both physical and geometric sense. As a starting\npoint for tackling the Visual Jenga task, we propose a simple, data-driven,\ntraining-free approach that is surprisingly effective on a range of real-world\nimages. The principle behind our approach is to utilize the asymmetry in the\npairwise relationships between objects within a scene and employ a large\ninpainting model to generate a set of counterfactuals to quantify the\nasymmetry.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:33Z"}
{"aid":"http://arxiv.org/abs/2503.23729v1","title":"Integral regularization PINNs for evolution equations","summary":"Evolution equations, including both ordinary differential equations (ODEs)\nand partial differential equations (PDEs), play a pivotal role in modeling\ndynamic systems. However, achieving accurate long-time integration for these\nequations remains a significant challenge. While physics-informed neural\nnetworks (PINNs) provide a mesh-free framework for solving PDEs, they often\nsuffer from temporal error accumulation, which limits their effectiveness in\ncapturing long-time behaviors. To alleviate this issue, we propose integral\nregularization PINNs (IR-PINNs), a novel approach that enhances temporal\naccuracy by incorporating an integral-based residual term into the loss\nfunction. This method divides the entire time interval into smaller\nsub-intervals and enforces constraints over these sub-intervals, thereby\nimproving the resolution and correlation of temporal dynamics. Furthermore,\nIR-PINNs leverage adaptive sampling to dynamically refine the distribution of\ncollocation points based on the evolving solution, ensuring higher accuracy in\nregions with sharp gradients or rapid variations. Numerical experiments on\nbenchmark problems demonstrate that IR-PINNs outperform original PINNs and\nother state-of-the-art methods in capturing long-time behaviors, offering a\nrobust and accurate solution for evolution equations.","main_category":"math.NA","categories":"math.NA,cs.LG,cs.NA","published":"2025-03-31T05:02:59Z"}
{"aid":"http://arxiv.org/abs/2503.23734v1","title":"Semantic Packet Aggregation and Repeated Transmission for Text-to-Image\n  Generation","summary":"Text-based communication is expected to be prevalent in 6G applications such\nas wireless AI-generated content (AIGC). Motivated by this, this paper\naddresses the challenges of transmitting text prompts over erasure channels for\na text-to-image AIGC task by developing the semantic segmentation and repeated\ntransmission (SMART) algorithm. SMART groups words in text prompts into\npackets, prioritizing the task-specific significance of semantics within these\npackets, and optimizes the number of repeated transmissions. Simulation results\nshow that SMART achieves higher similarities in received texts and generated\nimages compared to a character-level packetization baseline, while reducing\ncomputing latency by orders of magnitude compared to an exhaustive search\nbaseline.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T05:14:40Z"}
{"aid":"http://arxiv.org/abs/2503.23735v1","title":"Altermagnetism and Weak Ferromagnetism","summary":"Using a realistic model relevant to La$_2$CuO$_4$ and other altermagnetic\nperovskite oxides, we study interrelations between weak ferromagnetism (WF),\nanomalous Hall effect (AHE), and net orbital magnetization (OM). All of them\ncan be linked to the form of Dzyaloshinskii-Moriya (DM) interactions.\nNevertheless, while spin WF is induced by the DM vector components having the\nsame sign in all equivalent bonds, AHE and OM are related to alternating-sign\ncomponents, which do not contribute to any canting of spins. The microscopic\nmodel remains invariant under the symmetry operation $\\{ \\mathcal{S}|{\\bf t}\n\\}$, combining the shift ${\\bf t}$ of antiferromagnetically coupled sublattices\nto each other with the spin flip $\\mathcal{S}$. Thus, the band structure\nremains Kramers-degenerate, but the time-reversal symmetry is broken, providing\na possibility to realize AHE in antiferromagnetic substances. The altermagnetic\nsplitting of bands, breaking the $\\{ \\mathcal{S}|{\\bf t}\\}$ symmetry, does not\nplay a major role in the problem. More important is the orthorhombic strain,\nresponsible for finite values of AHE and OM.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-03-31T05:15:47Z"}
{"aid":"http://arxiv.org/abs/2503.23758v1","title":"Exact Solution of the Frustrated Potts Model with Next-Nearest-Neighbor\n  Interactions in One Dimension: An AI-Aided Discovery","summary":"The one-dimensional $J_1$-$J_2$ $q$-state Potts model is solved exactly for\narbitrary $q$, based on using OpenAI's latest reasoning model o3-mini-high to\nexactly solve the $q=3$ case. The exact results provide insights to outstanding\nphysical problems such as the stacking of atomic or electronic orders in\nlayered materials and the formation of a $T_c$-dome-shaped phase often seen in\nunconventional superconductors. The work is anticipated to fuel both the\nresearch in one-dimensional frustrated magnets for recently discovered\nfinite-temperature application potentials and the fast moving topic area of AI\nfor sciences.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,math-ph,math.MP","published":"2025-03-31T06:16:26Z"}
{"aid":"http://arxiv.org/abs/2503.23776v1","title":"VIDEX: A Disaggregated and Extensible Virtual Index for the Cloud and AI\n  Era","summary":"Virtual index, also known as hypothetical indexes, play a crucial role in\ndatabase query optimization. However, with the rapid advancement of cloud\ncomputing and AI-driven models for database optimization, traditional virtual\nindex approaches face significant challenges. Cloud-native environments often\nprohibit direct conducting query optimization process on production databases\ndue to stability requirements and data privacy concerns. Moreover, while AI\nmodels show promising progress, their integration with database systems poses\nchallenges in system complexity, inference acceleration, and model hot updates.\nIn this paper, we present VIDEX, a three-layer disaggregated architecture that\ndecouples database instances, the virtual index optimizer, and algorithm\nservices, providing standardized interfaces for AI model integration. Users can\nconfigure VIDEX by either collecting production statistics or by loading from a\nprepared file; this setup allows for high-accurate what-if analyses based on\nvirtual indexes, achieving query plans that are identical to those of the\nproduction instance. Additionally, users can freely integrate new AI-driven\nalgorithms into VIDEX. VIDEX has been successfully deployed at ByteDance,\nserving thousands of MySQL instances daily and over millions of SQL queries for\nindex optimization tasks.","main_category":"cs.DB","categories":"cs.DB","published":"2025-03-31T06:52:13Z"}
{"aid":"http://arxiv.org/abs/2503.23808v1","title":"Why does tinnitus vary with naps? A polysomnographic prospective study\n  exploring the somatosensory hypothesis","summary":"Background: Tinnitus, defined as the conscious awareness of a noise without\nany identifiable corresponding external acoustic source, can be modulated by\nvarious factors. Among these factors, tinnitus patients commonly report drastic\nincreases of tinnitus loudness following nap sleep. Previous studies have\nsuggested that this clinical pattern could be attributed to a somatosensory\nmodulation of tinnitus. To our knowledge, no polysomnographic study has been\ncarried out to assess this hypothesis. Methods: For this observational\nprospective study, 37 participants reporting frequent increases of tinnitus\nfollowing naps were recruited. They participated to six full-polysomnography\nnap attempts over two days. Audiological and kinesiologic tests were conducted\nbefore and after each nap attempt. Results: 197 naps were collected. Each nap\nat each time of day elicited an overall significant increase in tinnitus\nminimum masking level (MML). Each inter nap period elicited an overall\nsignificant decrease. Tinnitus modulations were found significantly correlated\nwith nap sleep duration (Visual numeric scale on tinnitus loudness, VNS-L, p <\n0.05), with snoring duration (MML, p < 0.001), with snoring average sound level\n(VNS on tinnitus intrusiveness, VNS-I, p < 0.05) and with sleep apnea count\n(VNS-I, p < 0.001). Conclusions: This study confirms objectively that tinnitus\nmay increase following naps. No association was found between these modulations\nand somatosensory modulations involving the temporomandibular joint and\ncervical areas. However, it may be possible that nap-induced tinnitus\nmodulations are a hidden form of somatosensory modulation as snoring and sleep\napnea events are often related to tensor veli palatini muscle dysfunction.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-03-31T07:42:33Z"}
{"aid":"http://arxiv.org/abs/2503.23835v1","title":"Disambiguate Gripper State in Grasp-Based Tasks: Pseudo-Tactile as\n  Feedback Enables Pure Simulation Learning","summary":"Grasp-based manipulation tasks are fundamental to robots interacting with\ntheir environments, yet gripper state ambiguity significantly reduces the\nrobustness of imitation learning policies for these tasks. Data-driven\nsolutions face the challenge of high real-world data costs, while simulation\ndata, despite its low costs, is limited by the sim-to-real gap. We identify the\nroot cause of gripper state ambiguity as the lack of tactile feedback. To\naddress this, we propose a novel approach employing pseudo-tactile as feedback,\ninspired by the idea of using a force-controlled gripper as a tactile sensor.\nThis method enhances policy robustness without additional data collection and\nhardware involvement, while providing a noise-free binary gripper state\nobservation for the policy and thus facilitating pure simulation learning to\nunleash the power of simulation. Experimental results across three real-world\ngrasp-based tasks demonstrate the necessity, effectiveness, and efficiency of\nour approach.","main_category":"cs.RO","categories":"cs.RO","published":"2025-03-31T08:29:17Z"}
{"aid":"http://arxiv.org/abs/2503.23837v1","title":"Transmission resonances in scattering by $Œ¥'$-like combs","summary":"We introduce a new exactly solvable model in quantum mechanics that describes\nthe propagation of particles through a potential field created by regularly\nspaced $\\delta'$-type point interactions, which model the localized dipoles\noften observed in crystal structures. We refer to the corresponding potentials\nas $\\delta'_\\theta$-combs, where the parameter $\\theta$ represents the contrast\nof the resonant wave at zero energy and determines the interface conditions in\nthe Hamiltonians. We explicitly calculate the scattering matrix for these\nsystems and prove that the transmission probability exhibits sharp resonance\npeaks while rapidly decaying at other frequencies. Consequently, Hamiltonians\nwith $\\delta'_\\theta$-comb potentials act as quantum filters, permitting\ntunnelling only for specific wave frequencies.","main_category":"math.SP","categories":"math.SP,math-ph,math.MP","published":"2025-03-31T08:33:37Z"}
{"aid":"http://arxiv.org/abs/2503.23858v1","title":"Incremental capacity-based multi-feature fusion model for predicting\n  state-of-health of lithium-ion batteries","summary":"Lithium-ion batteries have become an indispensable part of human industrial\nproduction and daily life. For the safe use, management and maintenance of\nlithium-ion batteries, the state of health (SOH) of lithium-ion batteries is an\nimportant indicator so that the SOH estimation is of significant practical\nvalue. In order to accurately predict SOH, this paper proposes a fusion\nprediction model which combines particle swarm optimization (PSO) algorithm,\nbi-directional long-short time memory network (BiLSTM) and adaptive boosting\n(AdaBoost) algorithm. In the proposed prediction model, indirect health\nindicators (HIs), which characterize battery degradation, are obtained with the\nhelp of incremental capacity analysis (ICA), and is fed into BiLSTM to extract\ntime-series features, whose parameters are optimized by employing PSO\nalgorithm. On this basis, the AdaBoost algorithm is applied to reduce the risk\nof overfitting the PSO-BiLSTM model. The study based on lithium-ion battery\ndata from Center for Advanced Life Cycle Engineering (CALCE) shows that the\nPSO-BiLSTM-AdaBoost model has higher accuracy, better robustness, and\ngeneralization ability.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-03-31T09:05:56Z"}
{"aid":"http://arxiv.org/abs/2503.23864v1","title":"Hybrid Random Concentrated Optimization Without Convexity Assumption","summary":"We propose a method to minimize a continuous function over a subset\n$\\mathcal{S}$ of high-dimensional space $\\mathbb{R}^K$ without assuming\nconvexity. The method alternates between Global Search (GS) to identify\ncandidates and Concentrated Search (CS) regimes to improve an eligible\ncandidate in $\\mathcal{S}$.Beyond the alternation between regimes, the\noriginality of the method lies in leveraging high dimensionality. We\ndemonstrate concentration properties under the $CS$ regime. In parallel, we\nshow that $GS$ reaches any point in finite time. Finally, two applications are\nproposed. The first is the reduction of the $L_1$ norm in the Lasso to\ndemonstrate the relevance of the method. In a second application, we compress\nneural network by pruning weights while maintaining performance. Our approach\nachieves significant weight reduction with minimal performance loss, offering\nan effective solution for network optimization.","main_category":"physics.data-an","categories":"physics.data-an","published":"2025-03-31T09:11:34Z"}
{"aid":"http://arxiv.org/abs/2503.23876v1","title":"Populations of evolved massive binary stars in the Small Magellanic\n  Cloud I: Predictions from detailed evolution models","summary":"Context. The majority of massive stars are born with a close binary\ncompanion. How this affects their evolution and fate is still largely\nuncertain, especially at low metallicity. Aims. We derive synthetic populations\nof massive post-interaction binary products and compare them with corresponding\nobserved populations in the Small Magellanic Cloud (SMC). Methods. We analyse\n53298 detailed binary evolutionary models computed with MESA. Our models\ninclude the physics of rotation, mass and angular momentum transfer, magnetic\ninternal angular momentum transport, and tidal spin-orbit coupling. They cover\ninitial primary masses of 5-100Msun, initial mass ratios of 0.3-0.95, and all\ninitial periods for which interaction is expected. They are evolved through the\nfirst mass transfer and the donor star death, a possible ensuing Be/X-ray\nbinary phase, and they end when the mass gainer leaves the main sequence.\nResults.In our fiducial synthetic population, 8% of the OB stars in the SMC are\npost-mass transfer systems, and 7% are merger products. In many of our models,\nthe mass gainers are spun up and form Oe/Be stars. While our model\nunderpredicts the number of Be/X-ray binaries in the SMC, it reproduces the\nmain features of their orbital period distribution and the observed number of\nSMC binary WR stars. We expect $\\sim$50 OB+BH binaries below and $\\sim$170\nabove 20d orbital period. The latter might produce merging double BHs. However,\ntheir progenitors, the predicted long-period WR+OB binaries, are not observed.\nConclusions. While the comparison with the observed SMC stars supports many\nphysics assumptions in our high-mass binary models, a better match of the large\nnumber of observed OBe stars and Be/X-ray binaries likely requires a lower\nmerger rate and/or a higher mass transfer efficiency during the first mass\ntransfer. The fate of the initially wide O star binaries remains uncertain.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA,astro-ph.HE","published":"2025-03-31T09:26:52Z"}
{"aid":"http://arxiv.org/abs/2503.23891v1","title":"Monodromy of Darboux transformations of polarised curves","summary":"We show that every finite type polarised curve in the conformal $2$-sphere\nwith a polynomial conserved quantity admits a resonance point, under a\nnon-orthogonality assumption on the conserved quantity. Using this fact, we\ndeduce that every finite type curve polarised by space form arc-length in the\nconformal $2$-sphere admits a resonance point, possibly on a multiple cover.","main_category":"math.DG","categories":"math.DG","published":"2025-03-31T09:42:15Z"}
{"aid":"http://arxiv.org/abs/2503.23896v1","title":"Feature learning from non-Gaussian inputs: the case of Independent\n  Component Analysis in high dimensions","summary":"Deep neural networks learn structured features from complex, non-Gaussian\ninputs, but the mechanisms behind this process remain poorly understood. Our\nwork is motivated by the observation that the first-layer filters learnt by\ndeep convolutional neural networks from natural images resemble those learnt by\nindependent component analysis (ICA), a simple unsupervised method that seeks\nthe most non-Gaussian projections of its inputs. This similarity suggests that\nICA provides a simple, yet principled model for studying feature learning.\nHere, we leverage this connection to investigate the interplay between data\nstructure and optimisation in feature learning for the most popular ICA\nalgorithm, FastICA, and stochastic gradient descent (SGD), which is used to\ntrain deep networks. We rigorously establish that FastICA requires at least\n$n\\gtrsim d^4$ samples to recover a single non-Gaussian direction from\n$d$-dimensional inputs on a simple synthetic data model. We show that vanilla\nonline SGD outperforms FastICA, and prove that the optimal sample complexity $n\n\\gtrsim d^2$ can be reached by smoothing the loss, albeit in a data-dependent\nway. We finally demonstrate the existence of a search phase for FastICA on\nImageNet, and discuss how the strong non-Gaussianity of said images compensates\nfor the poor sample complexity of FastICA.","main_category":"stat.ML","categories":"stat.ML,cond-mat.dis-nn,cond-mat.stat-mech,cs.LG,math.PR","published":"2025-03-31T09:46:47Z"}
{"aid":"http://arxiv.org/abs/2503.23899v1","title":"Rubrik's Cube: Testing a New Rubric for Evaluating Explanations on the\n  CUBE dataset","summary":"The performance and usability of Large-Language Models (LLMs) are driving\ntheir use in explanation generation tasks. However, despite their widespread\nadoption, LLM explanations have been found to be unreliable, making it\ndifficult for users to distinguish good from bad explanations. To address this\nissue, we present Rubrik's CUBE, an education-inspired rubric and a dataset of\n26k explanations, written and later quality-annotated using the rubric by both\nhumans and six open- and closed-source LLMs. The CUBE dataset focuses on two\nreasoning and two language tasks, providing the necessary diversity for us to\neffectively test our proposed rubric. Using Rubrik, we find that explanations\nare influenced by both task and perceived difficulty. Low quality stems\nprimarily from a lack of conciseness in LLM-generated explanations, rather than\ncohesion and word choice. The full dataset, rubric, and code will be made\navailable upon acceptance.","main_category":"cs.CL","categories":"cs.CL,I.2.7","published":"2025-03-31T09:48:59Z"}
{"aid":"http://arxiv.org/abs/2503.23937v1","title":"Electromagnetic multipole expansions and the logarithmic soft photon\n  theorem","summary":"We study the general structure of the electromagnetic field in the vicinity\nof spatial infinity. Starting from the general solution of the sourced Maxwell\nequations written in terms of multipole moments as obtained by Iyer and Damour,\nwe derive the expansion of the electromagnetic field perturbatively in the\nelectromagnetic coupling. At leading order, where the effect of long-range\nCoulombic interactions between charged particles is neglected, we discover\ninfinite sets of antipodal matching relations satisfied by the electromagnetic\nfield, which extend and sometimes correct previously known relations. At\nnext-to-leading order, electromagnetic tails resulting from these Coulombic\ninteractions appear, which affect the antipodal matching relations beyond those\nequivalent to the leading soft photon theorem. Moreover, new antipodal matching\nrelations arise, which we use to re-derive the classical logarithmic soft\nphoton theorem of Sahoo and Sen. Our analysis largely builds upon that of\nCampiglia and Laddha, although it invalidates the antipodal matching relation\nwhich they originally used in their derivation.","main_category":"hep-th","categories":"hep-th","published":"2025-03-31T10:35:22Z"}
{"aid":"http://arxiv.org/abs/2503.23966v1","title":"Machine Learning-assisted High-speed Combinatorial Optimization with\n  Ising Machines for Dynamically Changing Problems","summary":"Quantum or quantum-inspired Ising machines have recently shown promise in\nsolving combinatorial optimization problems in a short time. Real-world\napplications, such as time division multiple access (TDMA) scheduling for\nwireless multi-hop networks and financial trading, require solving those\nproblems sequentially where the size and characteristics change dynamically.\nHowever, using Ising machines involves challenges to shorten system-wide\nlatency due to the transfer of large Ising model or the cloud access and to\ndetermine the parameters for each problem. Here we show a combinatorial\noptimization method using embedded Ising machines, which enables solving\ndiverse problems at high speed without runtime parameter tuning. We customize\nthe algorithm and circuit architecture of the simulated bifurcation-based Ising\nmachine to compress the Ising model and accelerate computation and then built a\nmachine learning model to estimate appropriate parameters using extensive\ntraining data. In TDMA scheduling for wireless multi-hop networks, our\ndemonstration has shown that the sophisticated system can adapt to changes in\nthe problem and showed that it has a speed advantage over conventional methods.","main_category":"cs.ET","categories":"cs.ET,cs.LG","published":"2025-03-31T11:31:36Z"}
{"aid":"http://arxiv.org/abs/2503.23974v1","title":"Revealing the Low Temperature Phase of FAPbI$_3$ using Machine-Learned\n  Potential","summary":"FAPbI$_3$ is a material of interest for its potential in solar cell\napplications, driven by its remarkable optoelectronic properties. However, the\nlow-temperature phase of FAPbI$_3$ remains poorly understood, with open\nquestions surrounding its crystal structure, octahedral tilting, and the\narrangement of formamidinium (FA) cations. Using our trained machine-learned\npotential in combination with large-scale molecular dynamics simulations, we\nprovide a detailed investigation of this phase, uncovering its structural\ncharacteristics and dynamical behavior. Our analysis reveals the octahedral\ntilt pattern and sheds light on the rotational dynamics of FA cations in the\nlow temperature phase. Strikingly, we find that the FA cations become frozen in\na metastable configuration, unable to reach the thermodynamic ground state. By\ncomparing our simulated results with experimental nuclear magnetic resonance\n(NMR) and inelastic neutron scattering (INS) spectra, we demonstrate good\nagreement, further validating our findings. This phenomenon mirrors\nexperimental observations and offers a compelling explanation for the\nexperimental challenges in accessing the true ground state. These findings\nprovide critical insights into the fundamental physics of FAPbI$_3$ and its\nlow-temperature behavior, advancing our understanding of this technologically\nimportant material.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-31T11:36:16Z"}
{"aid":"http://arxiv.org/abs/2503.24008v1","title":"H2VU-Benchmark: A Comprehensive Benchmark for Hierarchical Holistic\n  Video Understanding","summary":"With the rapid development of multimodal models, the demand for assessing\nvideo understanding capabilities has been steadily increasing. However,\nexisting benchmarks for evaluating video understanding exhibit significant\nlimitations in coverage, task diversity, and scene adaptability. These\nshortcomings hinder the accurate assessment of models' comprehensive video\nunderstanding capabilities. To tackle this challenge, we propose a hierarchical\nand holistic video understanding (H2VU) benchmark designed to evaluate both\ngeneral video and online streaming video comprehension. This benchmark\ncontributes three key features:\n  Extended video duration: Spanning videos from brief 3-second clips to\ncomprehensive 1.5-hour recordings, thereby bridging the temporal gaps found in\ncurrent benchmarks. Comprehensive assessment tasks: Beyond traditional\nperceptual and reasoning tasks, we have introduced modules for\ncountercommonsense comprehension and trajectory state tracking. These additions\ntest the models' deep understanding capabilities beyond mere prior knowledge.\nEnriched video data: To keep pace with the rapid evolution of current AI\nagents, we have expanded first-person streaming video datasets. This expansion\nallows for the exploration of multimodal models' performance in understanding\nstreaming videos from a first-person perspective. Extensive results from H2VU\nreveal that existing multimodal large language models (MLLMs) possess\nsubstantial potential for improvement in our newly proposed evaluation tasks.\nWe expect that H2VU will facilitate advancements in video understanding\nresearch by offering a comprehensive and in-depth analysis of MLLMs.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T12:32:51Z"}
{"aid":"http://arxiv.org/abs/2503.24013v1","title":"You Cannot Feed Two Birds with One Score: the Accuracy-Naturalness\n  Tradeoff in Translation","summary":"The goal of translation, be it by human or by machine, is, given some text in\na source language, to produce text in a target language that simultaneously 1)\npreserves the meaning of the source text and 2) achieves natural expression in\nthe target language. However, researchers in the machine translation community\nusually assess translations using a single score intended to capture semantic\naccuracy and the naturalness of the output simultaneously. In this paper, we\nbuild on recent advances in information theory to mathematically prove and\nempirically demonstrate that such single-score summaries do not and cannot give\nthe complete picture of a system's true performance. Concretely, we prove that\na tradeoff exists between accuracy and naturalness and demonstrate it by\nevaluating the submissions to the WMT24 shared task. Our findings help explain\nwell-known empirical phenomena, such as the observation that optimizing\ntranslation systems for a specific accuracy metric (like BLEU) initially\nimproves the system's naturalness, while ``overfitting'' the system to the\nmetric can significantly degrade its naturalness. Thus, we advocate for a\nchange in how translations are evaluated: rather than comparing systems using a\nsingle number, they should be compared on an accuracy-naturalness plane.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T12:39:51Z"}
{"aid":"http://arxiv.org/abs/2503.24029v1","title":"Global Well-Posedness of the 3D Navier-Stokes Equations under\n  Multi-Level Logarithmically Improved Criteria","summary":"This paper extends our previous results on logarithmically improved\nregularity criteria for the three-dimensional Navier-Stokes equations by\nestablishing a comprehensive framework of multi-level logarithmic improvements.\nWe prove that if the initial data $u_0 \\in L^2(\\mathbb{R}^3)$ satisfies a\nnested logarithmically weakened condition\n$\\|(-\\Delta)^{s/2}u_0\\|_{L^q(\\mathbb{R}^3)} \\leq \\frac{C_0}{\\prod_{j=1}^{n} (1\n+ L_j(\\|u_0\\|_{\\dot{H}^s}))^{\\delta_j}}$ for some $s \\in (1/2, 1)$, where $L_j$\nrepresents $j$-fold nested logarithms, then the corresponding solution exists\nglobally in time and is unique. The proof introduces a novel sequence of\nincreasingly precise commutator estimates incorporating multiple layers of\nlogarithmic corrections. We establish the existence of a critical threshold\nfunction $\\Phi(s,q,\\{\\delta_j\\}_{j=1}^n)$ that completely characterizes the\nboundary between global regularity and potential singularity formation, with\nexplicit asymptotics as $s$ approaches the critical value $1/2$. This paper\nfurther provides a rigorous geometric characterization of potential singular\nstructures through refined multi-fractal analysis, showing that any singular\nset must have Hausdorff dimension bounded by $1 - \\sum_{j=1}^n\n\\frac{\\delta_j}{1+\\delta_j} \\cdot \\frac{1}{j+1}$. Our results constitute a\nsignificant advancement toward resolving the global regularity question for the\nNavier-Stokes equations, as we demonstrate that with properly calibrated\nsequences of nested logarithmic improvements, the gap to the critical case can\nbe systematically reduced.","main_category":"math.AP","categories":"math.AP","published":"2025-03-31T12:55:30Z"}
{"aid":"http://arxiv.org/abs/2503.24037v1","title":"Digital Nudges Using Emotion Regulation to Reduce Online Disinformation\n  Sharing","summary":"Online disinformation often provokes strong anger, driving social media users\nto spread it; however, few measures specifically target sharing behaviors\ndriven by this emotion to curb the spread of disinformation. This study aimed\nto evaluate whether digital nudges that encourage deliberation by drawing\nattention to emotional information can reduce sharing driven by strong anger\nassociated with online disinformation. We focused on emotion regulation, as a\nmethod for fostering deliberation, which is activated when individuals'\nattention is drawn to their current emotions. Digital nudges were designed to\ndisplay emotional information about disinformation and emotion regulation\nmessages. Among these, we found that distraction and perspective-taking nudges\nmay encourage deliberation in anger-driven sharing. To assess their\neffectiveness, existing nudges mimicking platform functions were used for\ncomparison. Participant responses were measured across four dimensions: sharing\nintentions, type of emotion, intensity of emotion, and authenticity. The\nresults showed that all digital nudges significantly reduced the sharing of\ndisinformation, with distraction nudges being the most effective. These\nfindings suggest that digital nudges addressing emotional responses can serve\nas an effective intervention against the spread disinformation driven by strong\nanger.","main_category":"cs.HC","categories":"cs.HC,cs.CR,cs.CY","published":"2025-03-31T13:01:05Z"}
{"aid":"http://arxiv.org/abs/2503.24046v1","title":"Contrasting exchange-field and spin-transfer torque driving mechanisms\n  in all-electric electron spin resonance","summary":"Understanding the coherent properties of electron spins driven by electric\nfields is crucial for their potential application in quantum-coherent\nnanoscience. In this work, we address two distinct driving mechanisms in\nelectric-field driven electron-spin resonance as implemented in scanning\ntunneling spectroscopy. We study the origin of the driving field using a single\norbital Anderson impurity, connected to polarized leads and biased by a voltage\nmodulated on resonance with a spin transition. By mapping the quantum master\nequation into a system of equations for the impurity spin, we identify two\ndistinct driving mechanisms. Below the charging thresholds of the impurity,\nelectron spin resonance is dominated by a magnetically exchange-driven\nmechanism or field-like torque. Conversely, above the charging threshold\nspin-transfer torque caused by the spin-polarized current through the impurity\ndrives the spin transition. Only the first mechanism enables coherent quantum\nspin control, while the second one leads to fast decoherence and spin\naccumulation towards a non-equilibrium steady-state. The electron spin\nresonance signals and spin dynamics vary significantly depending on which\ndriving mechanism dominates, highlighting the potential for optimizing\nquantum-coherent control in electrically driven quantum systems.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,quant-ph","published":"2025-03-31T13:10:22Z"}
{"aid":"http://arxiv.org/abs/2503.24056v1","title":"Moment polytopes of toric exponential families","summary":"We show that the moment polytope of a K\\\"ahler toric manifold, constructed as\nthe torification (in the sense of M. Molitor, K\\\"ahler toric manifolds from\ndually flat spaces, arXiv:2109.04839, 2021) of an exponential family defined on\na finite sample space, is the projection of a higher-dimensional simplex.","main_category":"math.DG","categories":"math.DG","published":"2025-03-31T13:17:20Z"}
{"aid":"http://arxiv.org/abs/2503.24057v1","title":"AMMSM: Adaptive Motion Magnification and Sparse Mamba for\n  Micro-Expression Recognition","summary":"Micro-expressions are typically regarded as unconscious manifestations of a\nperson's genuine emotions. However, their short duration and subtle signals\npose significant challenges for downstream recognition. We propose a multi-task\nlearning framework named the Adaptive Motion Magnification and Sparse Mamba\n(AMMSM) to address this. This framework aims to enhance the accurate capture of\nmicro-expressions through self-supervised subtle motion magnification, while\nthe sparse spatial selection Mamba architecture combines sparse activation with\nthe advanced Visual Mamba model to model key motion regions and their valuable\nrepresentations more effectively. Additionally, we employ evolutionary search\nto optimize the magnification factor and the sparsity ratios of spatial\nselection, followed by fine-tuning to improve performance further. Extensive\nexperiments on two standard datasets demonstrate that the proposed AMMSM\nachieves state-of-the-art (SOTA) accuracy and robustness.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T13:17:43Z"}
{"aid":"http://arxiv.org/abs/2503.24062v1","title":"Artificial Conversations, Real Results: Fostering Language Detection\n  with Synthetic Data","summary":"Collecting high-quality training data is essential for fine-tuning Large\nLanguage Models (LLMs). However, acquiring such data is often costly and\ntime-consuming, especially for non-English languages such as Italian. Recently,\nresearchers have begun to explore the use of LLMs to generate synthetic\ndatasets as a viable alternative. This study proposes a pipeline for generating\nsynthetic data and a comprehensive approach for investigating the factors that\ninfluence the validity of synthetic data generated by LLMs by examining how\nmodel performance is affected by metrics such as prompt strategy, text length\nand target position in a specific task, i.e. inclusive language detection in\nItalian job advertisements. Our results show that, in most cases and across\ndifferent metrics, the fine-tuned models trained on synthetic data consistently\noutperformed other models on both real and synthetic test datasets. The study\ndiscusses the practical implications and limitations of using synthetic data\nfor language detection tasks with LLMs.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-03-31T13:22:34Z"}
{"aid":"http://arxiv.org/abs/2503.24066v1","title":"Smooth and rough paths in mean derivative estimation for functional data","summary":"In this paper, in a multivariate setting we derive near optimal rates of\nconvergence in the minimax sense for estimating partial derivatives of the mean\nfunction for functional data observed under a fixed synchronous design over\nH\\\"older smoothness classes. We focus on the supremum norm since it corresponds\nto the visualisation of the estimation error, and is closely related to the\nconstruction of uniform confidence bands. In contrast to mean function\nestimation, for derivative estimation the smoothness of the paths of the\nprocesses is crucial for the rates of convergence. On the one hand, if the\npaths have higher-order smoothness than the order of the partial derivative to\nbe estimated, the parametric $\\sqrt n$ rate can be achieved under sufficiently\ndense design. On the other hand, for processes with rough paths of lower-order\nsmoothness, we show that the rates of convergence are necessarily slower than\nthe parametric rate, and determine a near-optimal rate at which estimation is\nstill possible. We implement a multivariate local polynomial derivative\nestimator and illustrate its finite-sample performance in a simulation as well\nas for two real-data sets. To assess the smoothness of the sample paths in the\napplications we further discuss a method based on comparing restricted\nestimates of the partial derivatives of the covariance kernel.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-03-31T13:24:48Z"}
{"aid":"http://arxiv.org/abs/2503.24071v1","title":"From Colors to Classes: Emergence of Concepts in Vision Transformers","summary":"Vision Transformers (ViTs) are increasingly utilized in various computer\nvision tasks due to their powerful representation capabilities. However, it\nremains understudied how ViTs process information layer by layer. Numerous\nstudies have shown that convolutional neural networks (CNNs) extract features\nof increasing complexity throughout their layers, which is crucial for tasks\nlike domain adaptation and transfer learning. ViTs, lacking the same inductive\nbiases as CNNs, can potentially learn global dependencies from the first layers\ndue to their attention mechanisms. Given the increasing importance of ViTs in\ncomputer vision, there is a need to improve the layer-wise understanding of\nViTs. In this work, we present a novel, layer-wise analysis of concepts encoded\nin state-of-the-art ViTs using neuron labeling. Our findings reveal that ViTs\nencode concepts with increasing complexity throughout the network. Early layers\nprimarily encode basic features such as colors and textures, while later layers\nrepresent more specific classes, including objects and animals. As the\ncomplexity of encoded concepts increases, the number of concepts represented in\neach layer also rises, reflecting a more diverse and specific set of features.\nAdditionally, different pretraining strategies influence the quantity and\ncategory of encoded concepts, with finetuning to specific downstream tasks\ngenerally reducing the number of encoded concepts and shifting the concepts to\nmore relevant categories.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-03-31T13:28:43Z"}
{"aid":"http://arxiv.org/abs/2503.24073v1","title":"Krylov complexity in quantum many-body scars of spin-1 models","summary":"Weak ergodicity breaking, particularly through quantum many-body scars\n(QMBS), has become a significant focus in many-body physics. Krylov state\ncomplexity quantifies the spread of quantum states within the Krylov basis and\nserves as a powerful diagnostic for analyzing nonergodic dynamics. In this\nwork, we study spin-one XXZ magnets and reveal nonergodic behavior tied to\nQMBS. For the XY model, the nematic N\\'eel state exhibits periodic revivals in\nKrylov complexity. In the generic XXZ model, we identify spin helix states as\nweakly ergodicity-breaking states, characterized by low entanglement and\nnonthermal dynamics. Across different scenarios, the Lanczos coefficients for\nscarred states display an elliptical pattern, reflecting a hidden SU(2) algebra\nthat enables analytical results for Krylov complexity and fidelity. These\nfindings, which exemplify the rare capability to characterize QMBS\nanalytically, are feasible with current experimental techniques and offer deep\ninsights into the nonergodic dynamics of interacting quantum systems.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-03-31T13:29:45Z"}
{"aid":"http://arxiv.org/abs/2503.24091v1","title":"4D mmWave Radar in Adverse Environments for Autonomous Driving: A Survey","summary":"Autonomous driving systems require accurate and reliable perception. However,\nadverse environments, such as rain, snow, and fog, can significantly degrade\nthe performance of LiDAR and cameras. In contrast, 4D millimeter-wave (mmWave)\nradar not only provides 3D sensing and additional velocity measurements but\nalso maintains robustness in challenging conditions, making it increasingly\nvaluable for autonomous driving. Recently, research on 4D mmWave radar under\nadverse environments has been growing, but a comprehensive survey is still\nlacking. To bridge this gap, this survey comprehensively reviews the current\nresearch on 4D mmWave radar under adverse environments. First, we present an\noverview of existing 4D mmWave radar datasets encompassing diverse weather and\nlighting scenarios. Next, we analyze methods and models according to different\nadverse conditions. Finally, the challenges faced in current studies and\npotential future directions are discussed for advancing 4D mmWave radar\napplications in harsh environments. To the best of our knowledge, this is the\nfirst survey specifically focusing on 4D mmWave radar in adverse environments\nfor autonomous driving.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T13:42:50Z"}
{"aid":"http://arxiv.org/abs/2503.24102v1","title":"Is LLM the Silver Bullet to Low-Resource Languages Machine Translation?","summary":"Low-Resource Languages (LRLs) present significant challenges in natural\nlanguage processing due to their limited linguistic resources and\nunderrepresentation in standard datasets. While recent advancements in Large\nLanguage Models (LLMs) and Neural Machine Translation (NMT) have substantially\nimproved translation capabilities for high-resource languages, performance\ndisparities persist for LRLs, particularly impacting privacy-sensitive and\nresource-constrained scenarios. This paper systematically evaluates the\nlimitations of current LLMs across 200 languages using benchmarks such as\nFLORES-200. We also explore alternative data sources, including news articles\nand bilingual dictionaries, and demonstrate how knowledge distillation from\nlarge pre-trained models can significantly improve smaller LRL translations.\nAdditionally, we investigate various fine-tuning strategies, revealing that\nincremental enhancements markedly reduce performance gaps on smaller LLMs.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T13:56:03Z"}
{"aid":"http://arxiv.org/abs/2503.24129v1","title":"It's a (Blind) Match! Towards Vision-Language Correspondence without\n  Parallel Data","summary":"The platonic representation hypothesis suggests that vision and language\nembeddings become more homogeneous as model and dataset sizes increase. In\nparticular, pairwise distances within each modality become more similar. This\nsuggests that as foundation models mature, it may become possible to match\nvision and language embeddings in a fully unsupervised fashion, i.e. without\nparallel data. We present the first feasibility study, and investigate\nconformity of existing vision and language foundation models in the context of\nunsupervised, or \"blind\", matching. First, we formulate unsupervised matching\nas a quadratic assignment problem and introduce a novel heuristic that\noutperforms previous solvers. We also develop a technique to find optimal\nmatching problems, for which a non-trivial match is very likely. Second, we\nconduct an extensive study deploying a range of vision and language models on\nfour datasets. Our analysis reveals that for many problem instances, vision and\nlanguage representations can be indeed matched without supervision. This\nfinding opens up the exciting possibility of embedding semantic knowledge into\nother modalities virtually annotation-free. As a proof of concept, we showcase\nan unsupervised classifier, which achieves non-trivial classification accuracy\nwithout any image-text annotation.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-03-31T14:14:25Z"}
{"aid":"http://arxiv.org/abs/2503.24134v1","title":"Moving mesh FSI approach for VIV simulation based on DG method with AMR\n  technique","summary":"Vortex-induced vibration (VIV) remains a fundamental yet computationally\n  challenging problem in computational fluid dynamics (CFD). This study\ndevelops a moving mesh Fluid-structure interaction (FSI) algorithm within a\nRunge-Kutta\n  Discontinuous Galerkin (RKDG) adaptive mesh refinement (AMR) framework. The\nviscous term in the compressible Navier-Stokes (NS) equations is discretized\nusing\n  the high-order Interior Penalty Discontinuous Galerkin (IPDG)\n  method. In addition to the above, key numerical advancements encompass\n  the rigorous derivation of the Lax-Friedrichs (L-F) numerical flux\nformulation\n  tailored for moving meshes, an enhanced AMR-driven nodal correction\n  methodology designed for curved surface geometries,\n  and the implementation of a ghost-node boundary condition treatment scheme\n  to address dynamic mesh motion. Numerical validation proceeds through three\nphases:\n  First, Couette flow simulations confirm the IPDG method's spatial\n  convergence order. Subsequent analysis of unsteady flow past a cylinder\n  demonstrate the AMR framework's efficacy in resolving vortex-dominated flow.\n  Finally, six VIV benchmark cases are simulated using third-order IPDG\ndiscretization,\n  establishing the proposed FSI algorithm's accuracy. Furthermore, synthetic\njets (SJs) flow control is investigated through\n  four frequency-variant SJs configurations. The results reveal that SJs can\nachieve completely\n  VIV suppression at a low actuation frequency, while higher actuation\n  frequencies reduce suppression efficiency due\n  to the energy of the SJs is more in the form of acoustic wave.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-03-31T14:17:53Z"}
{"aid":"http://arxiv.org/abs/2503.24147v1","title":"Net 3.2 Tbps 225 Gbaud PAM4 O-Band IM/DD 2 km Transmission Using FR8 and\n  DR8 with a CMOS 3 nm SerDes and TFLN Modulators","summary":"We report the first 3.2 and 4.2 Tbps (8 x 225Gbaud PAM4-8), IM/DD\ntransmission system using FR8 and DR8 configurations with TFLN modulators\ndriven by a 3nm SerDes under the HD-FEC threshold.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T14:33:17Z"}
{"aid":"http://arxiv.org/abs/2503.24150v1","title":"Learning a Canonical Basis of Human Preferences from Binary Ratings","summary":"Recent advances in generative AI have been driven by alignment techniques\nsuch as reinforcement learning from human feedback (RLHF). RLHF and related\ntechniques typically involve constructing a dataset of binary or ranked choice\nhuman preferences and subsequently fine-tuning models to align with these\npreferences. This paper shifts the focus to understanding the preferences\nencoded in such datasets and identifying common human preferences. We find that\na small subset of 21 preference categories (selected from a set of nearly 5,000\ndistinct preferences) captures >89% of preference variation across individuals.\nThis small set of preferences is analogous to a canonical basis of human\npreferences, similar to established findings that characterize human variation\nin psychology or facial recognition studies. Through both synthetic and\nempirical evaluations, we confirm that our low-rank, canonical set of human\npreferences generalizes across the entire dataset and within specific topics.\nWe further demonstrate our preference basis' utility in model evaluation, where\nour preference categories offer deeper insights into model alignment, and in\nmodel training, where we show that fine-tuning on preference-defined subsets\nsuccessfully aligns the model accordingly.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.HC","published":"2025-03-31T14:35:48Z"}
{"aid":"http://arxiv.org/abs/2503.24164v1","title":"SVLA: A Unified Speech-Vision-Language Assistant with Multimodal\n  Reasoning and Speech Generation","summary":"Large vision and language models show strong performance in tasks like image\ncaptioning, visual question answering, and retrieval. However, challenges\nremain in integrating speech, text, and vision into a unified model, especially\nfor spoken tasks. Speech generation methods vary (some produce speech\ndirectly), others through text (but their impact on quality is unclear).\nEvaluation often relies on automatic speech recognition, which may introduce\nbias. We propose SVLA, a unified speech vision language model based on a\ntransformer architecture that handles multimodal inputs and outputs. We train\nit on 38.2 million speech text image examples, including 64.1 hours of\nsynthetic speech. We also introduce Speech VQA Accuracy, a new metric for\nevaluating spoken responses. SVLA improves multimodal understanding and\ngeneration by better combining speech, vision, and language.","main_category":"cs.MM","categories":"cs.MM","published":"2025-03-31T14:46:34Z"}
{"aid":"http://arxiv.org/abs/2503.24167v1","title":"Relative solidity for biexact groups in measure equivalence","summary":"We demonstrate a relative solidity property for the product of a nonamenable\nbiexact group with an arbitrary infinite group in the measure equivalence\nsetting. Among other applications, we obtain the following unique product\ndecomposition for products of nonamenable biexact groups, strengthening\n\\cite{Sa09}: for any nonamenable biexact groups $\\Gamma_1,\\cdots, \\Gamma_n$, if\na product group $\\Lambda_1\\times \\Lambda_2$ is measure equivalent to\n$\\times_{k=1}^n\\Gamma_k$, then there exists a partition $T_1\\sqcup\nT_2=\\{1,\\dots, n\\}$ such that $\\Lambda_i$ is measure equivalent to\n$\\times_{k\\in T_i}\\Gamma_k$ for $i=1,2$.","main_category":"math.OA","categories":"math.OA,math.GR","published":"2025-03-31T14:48:48Z"}
{"aid":"http://arxiv.org/abs/2503.24187v1","title":"NeuRaLaTeX: A machine learning library written in pure LaTeX","summary":"In this paper, we introduce NeuRaLaTeX, which we believe to be the first deep\nlearning library written entirely in LaTeX. As part of your LaTeX document you\ncan specify the architecture of a neural network and its loss functions, define\nhow to generate or load training data, and specify training hyperparameters and\nexperiments. When the document is compiled, the LaTeX compiler will generate or\nload training data, train the network, run experiments, and generate figures.\nThis paper generates a random 100 point spiral dataset, trains a two layer MLP\non it, evaluates on a different random spiral dataset, produces plots and\ntables of results. The paper took 48 hours to compile and the entire source\ncode for NeuRaLaTeX is contained within the source code of the paper. We\npropose two new metrics: the Written In Latex (WIL) metric measures the\nproportion of a machine learning library that is written in pure LaTeX, while\nthe Source Code Of Method in Source Code of Paper (SCOMISCOP) metric measures\nthe proportion of a paper's implementation that is contained within the paper\nsource. We are state-of-the-art for both metrics, outperforming the ResNet and\nTransformer papers, as well as the PyTorch and Tensorflow libraries. Source\ncode, documentation, videos, crypto scams and an invitation to invest in the\ncommercialisation of NeuRaLaTeX are available at https://www.neuralatex.com","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T15:05:19Z"}
{"aid":"http://arxiv.org/abs/2503.24203v1","title":"Traffic Engineering in Large-scale Networks with Generalizable Graph\n  Neural Networks","summary":"Traffic engineering (TE) in large-scale computer networks has become a\nfundamental yet challenging problem, owing to the swift growth of global-scale\ncloud wide-area networks or backbone low-Earth-orbit satellite constellations.\nTo address the scalability issue of traditional TE algorithms, learning-based\napproaches have been proposed, showing potential of significant efficiency\nimprovement over state-of-the-art methods. Nevertheless, the intrinsic\nlimitations of existing learning-based methods hinder their practical\napplication: they are not generalizable across diverse topologies and network\nconditions, incur excessive training overhead, and do not respect link\ncapacities by default.\n  This paper proposes TELGEN, a novel TE algorithm that learns to solve TE\nproblems efficiently in large-scale networks, while achieving superior\ngeneralizability across diverse network conditions. TELGEN is based on the\nnovel idea of transforming the problem of \"predicting the optimal TE solution\"\ninto \"predicting the optimal TE algorithm\", which enables TELGEN to learn and\nefficiently approximate the end-to-end solving process of classical optimal TE\nalgorithms. The learned algorithm is agnostic to the exact network topology or\ntraffic patterns, and can efficiently solve TE problems given arbitrary inputs\nand generalize well to unseen topologies and demands.\n  We trained and evaluated TELGEN on random and real-world networks with up to\n5000 nodes and 106 links. TELGEN achieved less than 3% optimality gap while\nensuring feasibility in all cases, even when the test network had up to 20x\nmore nodes than the largest in training. It also saved up to 84% solving time\nthan classical optimal solver, and could reduce training time per epoch and\nsolving time by 2-4 orders of magnitude than latest learning algorithms on the\nlargest networks.","main_category":"cs.NI","categories":"cs.NI,cs.LG","published":"2025-03-31T15:21:22Z"}
{"aid":"http://arxiv.org/abs/2503.24204v1","title":"Many-to-Many Matching via Sparsity Controlled Optimal Transport","summary":"Many-to-many matching seeks to match multiple points in one set and multiple\npoints in another set, which is a basis for a wide range of data mining\nproblems. It can be naturally recast in the framework of Optimal Transport\n(OT). However, existing OT methods either lack the ability to accomplish\nmany-to-many matching or necessitate careful tuning of a regularization\nparameter to achieve satisfactory results. This paper proposes a novel\nmany-to-many matching method to explicitly encode many-to-many constraints\nwhile preventing the degeneration into one-to-one matching. The proposed method\nconsists of the following two components. The first component is the matching\nbudget constraints on each row and column of a transport plan, which specify\nhow many points can be matched to a point at most. The second component is the\ndeformed $q$-entropy regularization, which encourages a point to meet the\nmatching budget maximally. While the deformed $q$-entropy was initially\nproposed to sparsify a transport plan, we employ it to avoid the degeneration\ninto one-to-one matching. We optimize the objective via a penalty algorithm,\nwhich is efficient and theoretically guaranteed to converge. Experimental\nresults on various tasks demonstrate that the proposed method achieves good\nperformance by gleaning meaningful many-to-many matchings.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T15:22:02Z"}
{"aid":"http://arxiv.org/abs/2503.24209v1","title":"Optimal low-rank approximations for linear Gaussian inverse problems on\n  Hilbert spaces, Part II: posterior mean approximation","summary":"In this work, we construct optimal low-rank approximations for the Gaussian\nposterior distribution in linear Gaussian inverse problems. The parameter space\nis a separable Hilbert space of possibly infinite dimension, and the data space\nis assumed to be finite-dimensional. We consider various types of approximation\nfamilies for the posterior. We first consider approximate posteriors in which\nthe means vary among a class of either structure-preserving or\nstructure-ignoring low-rank transformations of the data, and in which the\nposterior covariance is kept fixed. We give necessary and sufficient conditions\nfor these approximating posteriors to be equivalent to the exact posterior, for\nall possible realisations of the data simultaneously. For such approximations,\nwe measure approximation error with the Kullback-Leibler, R\\'enyi and Amari\n$\\alpha$-divergences for $\\alpha\\in(0,1)$, and with the Hellinger distance, all\naveraged over the data distribution. With these losses, we find the optimal\napproximations and formulate an equivalent condition for their uniqueness,\nextending the work in finite dimensions of Spantini et al. (SIAM J. Sci.\nComput. 2015). We then consider joint approximation of the mean and covariance,\nby also varying the posterior covariance over the low-rank updates considered\nin Part I of this work. For the reverse Kullback-Leibler divergence, we show\nthat the separate optimal approximations of the mean and of the covariance can\nbe combined to yield an optimal joint approximation of the mean and covariance.\nIn addition, we interpret the joint approximation with the optimal\nstructure-ignoring approximate mean in terms of an optimal projector in\nparameter space.","main_category":"math.ST","categories":"math.ST,math.PR,stat.TH","published":"2025-03-31T15:26:48Z"}
{"aid":"http://arxiv.org/abs/2503.24246v1","title":"Quantum phase diagram of the extended spin-3/2 Kitaev-Heisenberg model:\n  A DMRG study","summary":"Recently there has been considerable excitement surrounding the promising\nrealization of high-spin Kitaev material, such as the quasi-2D compound CrI$_3$\nand CrGeTe$_3$. However, the stability of quantum spin liquids (QSL) against\nsingle ion anisotropy (SIA) in these materials and the global quantum phase\ndiagram of the extended spin-3/2 Kitaev model with finite SIA remain unclear.\nIn this study, we perform large-scale density matrix renormalization group\n(DMRG) to explore the quantum phase diagram of the generalized spin-3/2\nKitaev-Heisenberg (K-H) model accompanied with SIA $A_c$. In the $A_c=0$ limit,\nthe spin-3/2 K-H model exhibits a quantum phase diagram similar to that of a\nspin-1/2 system, including two QSLs around antiferromagnetic and ferromagnetic\nKitaev models. For models with finite $A_c$, we map out the quantum phase\ndiagram around two Kitaev points and observe distinct types of in-plane vortex\norders developed from these two QSL phases. Interestingly, series of nearly\ndegenerate vortex configurations are discovered in each vortex phases. Using\nlinear spin-wave theory, we demonstrate that these vortex configurations can be\nunderstood as a consequence of the quantum correction on a continuous family of\ndegenerate classical states.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-03-31T15:58:20Z"}
{"aid":"http://arxiv.org/abs/2503.24248v1","title":"Optimizing PCA for Health and Care Research: A Reliable Approach to\n  Component Selection","summary":"PCA is widely used in health and care research to analyze complex HD\ndatasets, such as patient health records, genetic data, and medical imaging. By\nreducing dimensionality, PCA helps identify key patterns and trends, which can\naid in disease diagnosis, treatment optimization, and the discovery of new\nbiomarkers. However, the primary goal of any dimensional reduction technique is\nto reduce the dimensionality in a data set while keeping the essential\ninformation and variability. There are a few ways to do this in practice, such\nas the Kaiser-Guttman criterion, Cattell's Scree Test, and the percent\ncumulative variance approach. Unfortunately, the results of these methods are\nentirely different. That means using inappropriate methods to find the optimal\nnumber of PCs retained in PCA may lead to misinterpreted and inaccurate results\nin PCA and PCA-related health and care research applications. This\ncontradiction becomes even more pronounced in HD settings where n < p, making\nit even more critical to determine the best approach. Therefore, it is\nnecessary to identify the issues of different techniques to select the optimal\nnumber of PCs retained in PCA. Kaiser-Guttman criterion retains fewer PCs,\ncausing overdispersion, while Cattell's scree test retains more PCs,\ncompromising reliability. The percentage of cumulative variation criterion\noffers greater stability, consistently selecting the optimal number of\ncomponents. Therefore, the Pareto chart, which shows both the cumulative\npercentage and the cut-off point for retained PCs, provides the most reliable\nmethod of selecting components, ensuring stability and enhancing PCA\neffectiveness, particularly in health-related research applications.","main_category":"stat.ME","categories":"stat.ME","published":"2025-03-31T15:58:50Z"}
{"aid":"http://arxiv.org/abs/2503.24252v1","title":"A BDG inequality for stochastic Volterra integrals","summary":"We establish Burkholder-Davis-Gundy-type inequalities for stochastic Volterra\nintegrals with a completely monotone convolution kernel, which may exhibit\nsingular behaviour at the origin. When the supremum is taken over a finite\ninterval, the upper bound depends linearly on the $L^\\gamma$-norm of the\nkernel, for any $\\gamma>2$. We demonstrate the utility of this inequality in\nquantifying the pathwise distance between two stochastic Volterra equations\nwith distinct kernels, with a particular emphasis on the multifactor Markovian\napproximation. For kernels that decay sufficiently fast, we derive an\nalternative inequality valid over an infinite time interval, providing\nuniform-in-time bounds for mean-reverting stochastic Volterra equations.\nFinally, we compare our findings with existing results in the literature.","main_category":"math.PR","categories":"math.PR","published":"2025-03-31T16:02:11Z"}
{"aid":"http://arxiv.org/abs/2503.24279v1","title":"Toward the effective 2-topos","summary":"A candidate for the effective 2-topos is proposed and shown to include the\neffective 1-topos as its subcategory of 0-types.","main_category":"math.CT","categories":"math.CT,math.LO","published":"2025-03-31T16:23:47Z"}
{"aid":"http://arxiv.org/abs/2503.24295v1","title":"Brazilian input to the European Strategy for Particle Physics Update","summary":"The Brazilian High-Energy Physics (HEP) community has expanded remarkably\nsince its first involvement at CERN and Fermilab in the 1980s. Its recent\norganization under the Brazilian Network for High-Energy Physics (RENAFAE),\nsince 2008, has further strengthened its scientific and technological goals,\nparticularly in detector instrumentation, computing, and industry partnerships.\nIn 2024, Brazil became an Associate Member State of CERN, opening new\nopportunities for deeper engagement in accelerator and detector R&D. This input\nto the 2026 update of the European Strategy for Particle Physics highlights\nBrazil's current participation in LHC experiments as well as ongoing\ndevelopments in detector and accelerator technology, and details the\ncommunity's view towards future colliders. The potential for expanded\nscientific and industrial collaborations between Brazil and CERN is also\ndiscussed.","main_category":"hep-ex","categories":"hep-ex","published":"2025-03-31T16:41:38Z"}
{"aid":"http://arxiv.org/abs/2503.24298v1","title":"Order Matters: On Parameter-Efficient Image-to-Video Probing for\n  Recognizing Nearly Symmetric Actions","summary":"We study parameter-efficient image-to-video probing for the unaddressed\nchallenge of recognizing nearly symmetric actions - visually similar actions\nthat unfold in opposite temporal order (e.g., opening vs. closing a bottle).\nExisting probing mechanisms for image-pretrained models, such as DinoV2 and\nCLIP, rely on attention mechanism for temporal modeling but are inherently\npermutation-invariant, leading to identical predictions regardless of frame\norder. To address this, we introduce Self-attentive Temporal Embedding Probing\n(STEP), a simple yet effective approach designed to enforce temporal\nsensitivity in parameter-efficient image-to-video transfer. STEP enhances\nself-attentive probing with three key modifications: (1) a learnable frame-wise\npositional encoding, explicitly encoding temporal order; (2) a single global\nCLS token, for sequence coherence; and (3) a simplified attention mechanism to\nimprove parameter efficiency. STEP outperforms existing image-to-video probing\nmechanisms by 3-15% across four activity recognition benchmarks with only 1/3\nof the learnable parameters. On two datasets, it surpasses all published\nmethods, including fully fine-tuned models. STEP shows a distinct advantage in\nrecognizing nearly symmetric actions, surpassing other probing mechanisms by\n9-19%. and parameter-heavier PEFT-based transfer methods by 5-15%. Code and\nmodels will be made publicly available.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T16:42:38Z"}
{"aid":"http://arxiv.org/abs/2503.24314v1","title":"Impact of Synchronization Offsets and CSI Feedback Delay in Distributed\n  MIMO Systems","summary":"The main challenges of distributed MIMO systems lie in achieving highly\naccurate synchronization and ensuring the availability of accurate channel\nstate information (CSI) at distributed nodes. This paper analytically examines\nthe effects of synchronization offsets and CSI feedback delays on system\ncapacity, providing insights into how these affect the coherent joint\ntransmission gain. The capacity expressions are first derived under ideal\nconditions, and the effects of synchronization offsets and feedback delays are\nsubsequently incorporated. This analysis can be applied to any distributed MIMO\narchitecture. A comprehensive study, including system models and simulations\nevaluating the analytical expressions, is presented to quantify the capacity\ndegradation caused by these factors. This study provides valuable insights into\nthe design and performance of distributed MIMO systems. The analysis shows that\ntime and frequency offsets, along with CSI feedback delay, cause inter-layer\ninterference. Additionally, time offsets result in inter-symbol interference.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T17:02:33Z"}
{"aid":"http://arxiv.org/abs/2503.24330v1","title":"Quantum algorithms for cooling: a simple case study","summary":"Preparation of low-energy quantum many-body states has a wide range of\napplications in quantum information processing and condensed matter physics.\nQuantum cooling algorithms offer a promising alternative to other methods\nbased, for instance, on variational and adiabatic principles, or on dissipative\nstate preparation. In this work, we investigate a set of cooling algorithms in\na simple, solvable fermionic model which allows us to identify the mechanisms\nwhich underlie the cooling process and, also, those which prevent it. We derive\nanalytical expressions for the cooling dynamics, steady states, and cooling\nrates in the weak coupling limit. We find that multi-frequency and randomized\ncycle strategies can significantly enhance the performance of the quantum\nalgorithm and circumvent some of the obstacles. We also analyze the effects of\nnoise and evaluate the conditions under which cooling remains feasible.\nFurthermore, we present optimized cooling protocols that can significantly\nenhance cooling performance in the presence of noise. Additionally, we compare\ncooling and dissipative state preparation and show that, in the model analyzed\nhere, cooling generally achieves lower energies and is more resilient to noise.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T17:19:12Z"}
{"aid":"http://arxiv.org/abs/2503.24344v1","title":"Local basis for interacting topological bands","summary":"The discovery of correlated states in moire materials has challenged the\nestablished methods of projecting interactions into a local Wannier basis due\nto topological obstructions that manifest in extended interactions. This\ndifficulty can sometimes be evaded by decomposing the band into a basis of\nextended itinerant states and a lattice of local states, using the heavy\nfermion prescription. We revisit this framework by systematically identifying\nthe dominant interaction channels guided by the eigenvalues of the projected\ndensity operator. This approach can be applied both to tight-binding and\ncontinuum models, allowing us to identify a hierarchy in interaction scales\nthat can be universally used to reduce the Hilbert space dimension and\ndetermine an appropriate local basis for modeling electronic correlations in\ninteracting topological materials.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-03-31T17:26:23Z"}
{"aid":"http://arxiv.org/abs/2503.24355v1","title":"Modified cosmology though spacetime thermodynamics and generalized\n  mass-to-horizon entropy","summary":"In this work we apply the gravity-thermodynamics approach for the case of\ngeneralized mass-to-horizon entropy, which is a two-parameter extension of\nBekenstein-Hawking entropy that arises from the extended mass-to-horizon\nrelation, that is in turn required in order to have consistency with the\nClausius relation. We extract the modified Friedmann equations and we obtain an\neffective dark energy sector arising from the novel terms. We derive analytical\nsolutions for the dark energy density parameter, the dark energy\nequation-of-state parameter, and the deceleration parameter, and we show that\nthe Universe exhibits the usual thermal history with the succession of matter\nand dark energy epochs. Additionally, depending on the value of the entropy\nparameters, the dark energy equation-of-state parameter can either lie in the\nphantom regime at high redshifts entering into the quintessence regime at small\nredshifts, or it can lie in the quintessence regime at high redshifts and\nexperience the phantom-divide crossing at small redshifts, while in the far\nfuture in all cases it asymptotically obtains the cosmological constant value\n$-1$. Finally, we perform observational confrontation with Supernova Type Ia\n(SNIa), Cosmic Chronometers (CC) and Baryonic Acoustic Oscillations (BAO)\ndatasets, showing that the scenario is in agreement with observations.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-th","published":"2025-03-31T17:35:35Z"}
{"aid":"http://arxiv.org/abs/2503.24379v1","title":"Any2Caption:Interpreting Any Condition to Caption for Controllable Video\n  Generation","summary":"To address the bottleneck of accurate user intent interpretation within the\ncurrent video generation community, we present Any2Caption, a novel framework\nfor controllable video generation under any condition. The key idea is to\ndecouple various condition interpretation steps from the video synthesis step.\nBy leveraging modern multimodal large language models (MLLMs), Any2Caption\ninterprets diverse inputs--text, images, videos, and specialized cues such as\nregion, motion, and camera poses--into dense, structured captions that offer\nbackbone video generators with better guidance. We also introduce Any2CapIns, a\nlarge-scale dataset with 337K instances and 407K conditions for\nany-condition-to-caption instruction tuning. Comprehensive evaluations\ndemonstrate significant improvements of our system in controllability and video\nquality across various aspects of existing video generation models. Project\nPage: https://sqwu.top/Any2Cap/","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T17:59:01Z"}
{"aid":"http://arxiv.org/abs/2503.24390v1","title":"Intertwining bulk and surface: the case of UTe$_2$","summary":"UTe$_2$ has been the focus of numerous experimental and theoretical studies\nin recent years, as it is recognized as an odd-parity bulk superconductor. Its\nsurface has also been probed, revealing charge density wave (CDW), pair density\nwave (PDW), and time-reversal symmetry breaking (TRSB). In this work, we\npropose that the interplay between the order parameters observed on the surface\nand in the bulk of UTe$_2$ may be crucial in explaining some of the unusual\nfeatures detected by surface probes in this material. Through a\nphenomenological analysis, we can account for three distinctive experimental\nsignatures observed on the surface of UTe$_2$: i) the apparent suppression of\nCDW order at the upper critical field of the bulk superconducting state; ii)\nthe magnetic field-induced imbalance of the Fourier peaks associated with the\nCDW; iii) the onset of TRSB at the bulk superconducting critical temperature\nand its field-trainability. Furthermore, we propose specific experimental\nchecks to validate our conjecture, which we believe could be promptly achieved.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.str-el","published":"2025-03-31T17:59:55Z"}
{"aid":"http://arxiv.org/abs/2503.24391v1","title":"Easi3R: Estimating Disentangled Motion from DUSt3R Without Training","summary":"Recent advances in DUSt3R have enabled robust estimation of dense point\nclouds and camera parameters of static scenes, leveraging Transformer network\narchitectures and direct supervision on large-scale 3D datasets. In contrast,\nthe limited scale and diversity of available 4D datasets present a major\nbottleneck for training a highly generalizable 4D model. This constraint has\ndriven conventional 4D methods to fine-tune 3D models on scalable dynamic video\ndata with additional geometric priors such as optical flow and depths. In this\nwork, we take an opposite path and introduce Easi3R, a simple yet efficient\ntraining-free method for 4D reconstruction. Our approach applies attention\nadaptation during inference, eliminating the need for from-scratch pre-training\nor network fine-tuning. We find that the attention layers in DUSt3R inherently\nencode rich information about camera and object motion. By carefully\ndisentangling these attention maps, we achieve accurate dynamic region\nsegmentation, camera pose estimation, and 4D dense point map reconstruction.\nExtensive experiments on real-world dynamic videos demonstrate that our\nlightweight attention adaptation significantly outperforms previous\nstate-of-the-art methods that are trained or finetuned on extensive dynamic\ndatasets. Our code is publicly available for research purpose at\nhttps://easi3r.github.io/","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T17:59:58Z"}
{"aid":"http://arxiv.org/abs/2504.01319v1","title":"Decoupled anisotropic Charge-Phonon Transport Enables Exceptional n-Type\n  Thermoelectric Performance in CuBiSCl$_2$","summary":"First-principles calculations demonstrate an exceptional decoupling of charge\nand thermal transport along the \\textit{a}-axis in CuBiSCl$_2$. The material\nachieves superior electron mobility (138 cm$^2$/V$\\cdot$s at 300 K) through\ndelocalized Bi-6\\textit{p}/S-3\\textit{p} networks while maintaining ultralow\nlattice thermal conductivity (0.40 W/mK at 300 K) via Cu-dominated anharmonic\nphonon scattering - both optimized along the same crystallographic direction.\nThis simultaneous optimization originates from the anisotropic bonding\nhierarchy where [BiSCl$_2$]$_n$ ribbons enable efficient charge transport along\n\\textit{a}-axis, while the soft vibrational modes associated with Cu atoms\nstrongly scatter heat-carrying phonons. The resulting high power factor (1.71\nmW/mK$^2$ at 700 K) and peak \\textit{ZT} of 1.57 establish CuBiSCl$_2$ as a\nmodel system that realizes the long-sought \"phonon glass-electron crystal\"\nparadigm through crystallographically engineered transport channels.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T03:10:17Z"}
{"aid":"http://arxiv.org/abs/2504.01320v1","title":"A link between covering and coefficient theorems for holomorphic\n  functions","summary":"Recently the author presented a new approach to solving the coefficient\nproblems for various classes of holomorphic functions $f(z) =\n\\sum\\limits_0^\\infty c_n z^n$, not necessarily univalent. This approach is\nbased on lifting the given polynomial coefficient functionals $J(f) =\nJ(c_{m_1}, \\dots, c_{m_s}), 2 < c_{m_1} < \\dots < c_{m_s} < \\infty$, onto the\nBers fiber space over universal Teichmuller space and applying the analytic and\ngeometric features of Teichm\\\"{u}ller spaces, especially the Bers isomorphism\ntheorem for Teichmuller spaces of punctured Riemann surfaces.\n  In this paper, we extend this approach to more general classes of functions.\nIn particular, this provides a strengthening of de Branges' theorem solving the\nBieberbach conjecture.","main_category":"math.CV","categories":"math.CV","published":"2025-04-02T03:12:22Z"}
{"aid":"http://arxiv.org/abs/2504.01321v1","title":"COST: Contrastive One-Stage Transformer for Vision-Language Small Object\n  Tracking","summary":"Transformer has recently demonstrated great potential in improving\nvision-language (VL) tracking algorithms. However, most of the existing VL\ntrackers rely on carefully designed mechanisms to perform the multi-stage\nmulti-modal fusion. Additionally, direct multi-modal fusion without alignment\nignores distribution discrepancy between modalities in feature space,\npotentially leading to suboptimal representations. In this work, we propose\nCOST, a contrastive one-stage transformer fusion framework for VL tracking,\naiming to learn semantically consistent and unified VL representations.\nSpecifically, we introduce a contrastive alignment strategy that maximizes\nmutual information (MI) between a video and its corresponding language\ndescription. This enables effective cross-modal alignment, yielding\nsemantically consistent features in the representation space. By leveraging a\nvisual-linguistic transformer, we establish an efficient multi-modal fusion and\nreasoning mechanism, empirically demonstrating that a simple stack of\ntransformer encoders effectively enables unified VL representations. Moreover,\nwe contribute a newly collected VL tracking benchmark dataset for small object\ntracking, named VL-SOT500, with bounding boxes and language descriptions. Our\ndataset comprises two challenging subsets, VL-SOT230 and VL-SOT270, dedicated\nto evaluating generic and high-speed small object tracking, respectively. Small\nobject tracking is notoriously challenging due to weak appearance and limited\nfeatures, and this dataset is, to the best of our knowledge, the first to\nexplore the usage of language cues to enhance visual representation for small\nobject tracking. Extensive experiments demonstrate that COST achieves\nstate-of-the-art performance on five existing VL tracking datasets, as well as\non our proposed VL-SOT500 dataset. Source codes and dataset will be made\npublicly available.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T03:12:38Z"}
{"aid":"http://arxiv.org/abs/2504.01324v1","title":"On Data Synthesis and Post-training for Visual Abstract Reasoning","summary":"This paper is a pioneering work attempting to address abstract visual\nreasoning (AVR) problems for large vision-language models (VLMs). We make a\ncommon LLaVA-NeXT 7B model capable of perceiving and reasoning about specific\nAVR problems, surpassing both open-sourced (e.g., Qwen-2-VL-72B) and\nclosed-sourced powerful VLMs (e.g., GPT-4o) with significant margin. This is a\ngreat breakthrough since almost all previous VLMs fail or show nearly random\nperformance on representative AVR benchmarks. Our key success is our innovative\ndata synthesis and post-training process, aiming to fully relieve the task\ndifficulty and elicit the model to learn, step by step. Our 7B model is also\nshown to be behave well on AVR without sacrificing common multimodal\ncomprehension abilities. We hope our paper could serve as an early effort in\nthis area and would inspire further research in abstract visual reasoning.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL","published":"2025-04-02T03:18:24Z"}
{"aid":"http://arxiv.org/abs/2504.01376v1","title":"On the dual structure of the Schr√∂dinger dynamics","summary":"This paper elucidates the dual structure of the Schr\\\"{o}dinger dynamics in\ntwo correlated stages: (1) We first derive the real-valued Schr\\\"{o}dinger\nequation from scratch without referring to classical mechanics, wave mechanics,\nnor optics, and thereby attain a concrete and clear interpretation of the\nSchr\\\"{o}dinger (wave) function. Beginning with a factorization of the density\ndistribution function of the particles to two component vectors in\nconfiguration space, we impose very simple conditions on them such as\ntranslational invariance of space-time and the conservation of flux under a\ngiven potential function. A real-valued path-integral is formulated as a Green\nfunction for the real-valued Schr\\\"{o}dinger equation. (2) We then study a\nquantum stochastic path dynamics in a manner compatible with the\nSchr\\\"{o}dinger equation. The relation between them is like the Langevin\ndynamics with the diffusion equation. Each quantum path describes a\n\\textquotedblleft trajectory\\textquotedblright\\ in configuration space\nrepresenting, for instance, a singly launched electron in the double-slit\nexperiment that leaves a spot one by one at the measurement board, while\naccumulated spots give rise to the fringe pattern as predicted by the absolute\nsquare of the Schr\\\"{o}dinger function. We start from the relationship between\nthe Ito stochastic differential equation, the Feynman-Kac formula, and the\nassociated parabolic partial differential equations, to one of which\\ the\nSchr\\\"{o}dinger equation is transformed. The physical significance of the\nquantum intrinsic stochasticity and the indirect correlation among the quantum\npaths and so on are discussed. The self-referential nonlinear interrelationship\nbetween the Schr\\\"{o}dinger functions (regarded as a whole) and the quantum\npaths (as its parts) is identified as the ultimate mystery in quantum dynamics.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T05:38:05Z"}
{"aid":"http://arxiv.org/abs/2504.01406v1","title":"A steady solution to the hydrodynamic equation and incommensurate\n  magnetization in a U(2) invariant superfluid","summary":"At the zero temperature limit, a one-dimensional steady solution to the\nhydrodynamic equation of a U(2) invariant superfluid is obtained. This solution\nreveals that the magnitude of magnetization is always directly proportional to\nthe particle number density. Furthermore, the problem can be interpreted as a\nparticle's motion in a central force field. It is demonstrated that the\nparticle's orbits are elliptical in shape, with a precession angle determined\nby a non-zero mass current. This suggests that the spatial periods of the three\ncomponent magnetizations are not commensurate. These findings indicate that the\ncoupling of mass superflow and magnetization distortions usually results in an\nincommensurate magnetization.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas","published":"2025-04-02T06:47:05Z"}
{"aid":"http://arxiv.org/abs/2504.01407v1","title":"TimeSearch: Hierarchical Video Search with Spotlight and Reflection for\n  Human-like Long Video Understanding","summary":"Large video-language models (LVLMs) have shown remarkable performance across\nvarious video-language tasks. However, they encounter significant challenges\nwhen processing long videos because of the large number of video frames\ninvolved. Downsampling long videos in either space or time can lead to visual\nhallucinations, making it difficult to accurately interpret long videos.\nMotivated by human hierarchical temporal search strategies, we propose\n\\textbf{TimeSearch}, a novel framework enabling LVLMs to understand long videos\nin a human-like manner. TimeSearch integrates two human-like primitives into a\nunified autoregressive LVLM: 1) \\textbf{Spotlight} efficiently identifies\nrelevant temporal events through a Temporal-Augmented Frame Representation\n(TAFR), explicitly binding visual features with timestamps; 2)\n\\textbf{Reflection} evaluates the correctness of the identified events,\nleveraging the inherent temporal self-reflection capabilities of LVLMs.\nTimeSearch progressively explores key events and prioritizes temporal search\nbased on reflection confidence. Extensive experiments on challenging long-video\nbenchmarks confirm that TimeSearch substantially surpasses previous\nstate-of-the-art, improving the accuracy from 41.8\\% to 51.5\\% on the LVBench.\nAdditionally, experiments on temporal grounding demonstrate that appropriate\nTAFR is adequate to effectively stimulate the surprising temporal grounding\nability of LVLMs in a simpler yet versatile manner, which improves mIoU on\nCharades-STA by 11.8\\%. The code will be released.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T06:47:19Z"}
{"aid":"http://arxiv.org/abs/2504.01408v1","title":"From Shadows to Safety: Occlusion Tracking and Risk Mitigation for Urban\n  Autonomous Driving","summary":"Autonomous vehicles (AVs) must navigate dynamic urban environments where\nocclusions and perception limitations introduce significant uncertainties. This\nresearch builds upon and extends existing approaches in risk-aware motion\nplanning and occlusion tracking to address these challenges. While prior\nstudies have developed individual methods for occlusion tracking and risk\nassessment, a comprehensive method integrating these techniques has not been\nfully explored. We, therefore, enhance a phantom agent-centric model by\nincorporating sequential reasoning to track occluded areas and predict\npotential hazards. Our model enables realistic scenario representation and\ncontext-aware risk evaluation by modeling diverse phantom agents, each with\ndistinct behavior profiles. Simulations demonstrate that the proposed approach\nimproves situational awareness and balances proactive safety with efficient\ntraffic flow. While these results underline the potential of our method,\nvalidation in real-world scenarios is necessary to confirm its feasibility and\ngeneralizability. By utilizing and advancing established methodologies, this\nwork contributes to safer and more reliable AV planning in complex urban\nenvironments. To support further research, our method is available as\nopen-source software at:\nhttps://github.com/TUM-AVS/OcclusionAwareMotionPlanning","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-02T06:48:50Z"}
{"aid":"http://arxiv.org/abs/2504.01447v1","title":"What KM3-230213A events may tell us about the neutrino mass and dark\n  matter","summary":"Within the framework of general $U(1)$ scenario, we demonstrate that the\nultra high energy neutrinos recently detected by KM3NeT could originate from a\ndecaying right handed neutrino dark matter (DM), with a mass of 440 PeV.\nConsidering DM production via freeze-in, we delineate the parameter space that\nsatisfies the observed relic abundance and also lies within the reach of\nmultiple gravitational wave detectors. Our study provides a testable new\nphysics scenario, enabled by multi-messenger astronomy.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO,astro-ph.HE","published":"2025-04-02T08:00:23Z"}
{"aid":"http://arxiv.org/abs/2504.01470v1","title":"Detecting Lip-Syncing Deepfakes: Vision Temporal Transformer for\n  Analyzing Mouth Inconsistencies","summary":"Deepfakes are AI-generated media in which the original content is digitally\naltered to create convincing but manipulated images, videos, or audio. Among\nthe various types of deepfakes, lip-syncing deepfakes are one of the most\nchallenging deepfakes to detect. In these videos, a person's lip movements are\nsynthesized to match altered or entirely new audio using AI models. Therefore,\nunlike other types of deepfakes, the artifacts in lip-syncing deepfakes are\nconfined to the mouth region, making them more subtle and, thus harder to\ndiscern. In this paper, we propose LIPINC-V2, a novel detection framework that\nleverages a combination of vision temporal transformer with multihead\ncross-attention to detect lip-syncing deepfakes by identifying spatiotemporal\ninconsistencies in the mouth region. These inconsistencies appear across\nadjacent frames and persist throughout the video. Our model can successfully\ncapture both short-term and long-term variations in mouth movement, enhancing\nits ability to detect these inconsistencies. Additionally, we created a new\nlip-syncing deepfake dataset, LipSyncTIMIT, which was generated using five\nstate-of-the-art lip-syncing models to simulate real-world scenarios. Extensive\nexperiments on our proposed LipSyncTIMIT dataset and two other benchmark\ndeepfake datasets demonstrate that our model achieves state-of-the-art\nperformance. The code and the dataset are available at\nhttps://github.com/skrantidatta/LIPINC-V2 .","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T08:24:06Z"}
{"aid":"http://arxiv.org/abs/2504.01475v1","title":"Optimal Control of an Interconnected SDE -Parabolic PDE System","summary":"In this paper, we design a controller for an interconnected system where a\nlinear Stochastic Differential Equation (SDE) is actuated through a linear\nparabolic heat equation. These dynamics arise in various applications, such as\ncoupled heat transfer systems and chemical reaction processes that are subject\nto disturbances. Our goal is to develop a computational method for\napproximating the controller that minimizes a quadratic cost associated with\nthe state of the SDE component. To achieve this, we first perform a change of\nvariables to shift the actuation inside the PDE domain and reformulate the\nsystem as a linear Stochastic Partial Differential Equation (SPDE). We use a\nspectral approximation of the Laplacian operator to discretize the coupled\ndynamics into a finite-dimensional SDE and compute the optimal control for this\napproximated system. The resulting control serves as an approximation of the\noptimal control for the original system. We then establish the convergence of\nthe approximated optimal control and the corresponding closed-loop dynamics to\ntheir infinite-dimensional counterparts. Numerical simulations are provided to\nillustrate the effectiveness of our approach.","main_category":"math.AP","categories":"math.AP,math.OC","published":"2025-04-02T08:29:04Z"}
{"aid":"http://arxiv.org/abs/2504.01485v1","title":"Diameter Shortcut Sets on Temporal Graphs","summary":"Shortcut sets are a vital instrument for reducing the diameter of a static\ngraph and, consequently, its shortest path complexity, which is relevant in\nnumerous subfields of graph theory. We explore the notion of shortcut sets in\ntemporal graphs, which incorporate a discrete time model into the graph,\nrendering each edge accessible exclusively at specific points in time. This not\nonly alters the underlying assumptions of regular graphs but also substantially\nincreases the complexity of path problems and reachability. In turn, a temporal\ngraph is often a much more realistic and accurate representation of a\nreal-world network. In this thesis we provide a definition for a shortcut set\nin a temporal graph and explore differences to classic shortcut sets. Utilizing\nthis definition, we show that temporal and regular shortcut sets yield the same\nresults on temporal paths, enabling the application of existing construction\nalgorithms for static shortcut sets on paths. The primary contribution of this\nthesis is a translation approach for general temporal graphs that utilizes the\nstatic expansion of a temporal graph, allowing the conversion of static\nshortcut sets into temporal shortcut sets, yielding similar results.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-02T08:38:21Z"}
{"aid":"http://arxiv.org/abs/2504.01492v1","title":"Nagaoka ferromagnetism in semiconductor artificial graphene","summary":"We present the emergence of Nagaoka ferromagnetism in semiconductor-based\nartificial graphene using high-precision variational and diffusion Monte Carlo\nmethods, complemented by exact diagonalization calculations of the extended\nHubbard model. Specifically, we analyze a realistic model of an armchair\nhexagonal geometry comprising $42$ lattice sites, nanopatterned on GaAs quantum\nwells with nearest-neighbor distance of $a = 50$ nm. Our results reveal a\ndistinct magnetic phase transition near $U/t \\approx 60$ driven by the\nabsence/addition of a single electron at half-filling where the ferromagnetic\nphase is further stabilized by Coulomb scattering terms.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.str-el","published":"2025-04-02T08:46:41Z"}
{"aid":"http://arxiv.org/abs/2504.01506v1","title":"MLKV: Efficiently Scaling up Large Embedding Model Training with\n  Disk-based Key-Value Storage","summary":"Many modern machine learning (ML) methods rely on embedding models to learn\nvector representations (embeddings) for a set of entities (embedding tables).\nAs increasingly diverse ML applications utilize embedding models and embedding\ntables continue to grow in size and number, there has been a surge in the\nad-hoc development of specialized frameworks targeted to train large embedding\nmodels for specific tasks. Although the scalability issues that arise in\ndifferent embedding model training tasks are similar, each of these frameworks\nindependently reinvents and customizes storage components for specific tasks,\nleading to substantial duplicated engineering efforts in both development and\ndeployment. This paper presents MLKV, an efficient, extensible, and reusable\ndata storage framework designed to address the scalability challenges in\nembedding model training, specifically data stall and staleness. MLKV augments\ndisk-based key-value storage by democratizing optimizations that were\npreviously exclusive to individual specialized frameworks and provides\neasy-to-use interfaces for embedding model training tasks. Extensive\nexperiments on open-source workloads, as well as applications in eBay's payment\ntransaction risk detection and seller payment risk detection, show that MLKV\noutperforms offloading strategies built on top of industrial-strength key-value\nstores by 1.6-12.6x. MLKV is open-source at https://github.com/llm-db/MLKV.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T08:57:01Z"}
{"aid":"http://arxiv.org/abs/2504.01517v1","title":"Cascade topologies in rare charm decays and implications for CP\n  violation","summary":"The CP violation observed in the hadronic decays of charmed mesons remains a\npuzzling open question for theorists. Calculations relying on the assumption of\ninelastic final-state interactions occurring between the pairs of pions and\nkaons fall short of the experimental value. It has been pointed out that a\nthird channel of four pions can leave imprints on the CP asymmetries of the\ntwo-body decays. At the same time, plenty of data are available for the $4\\pi$\ndecays of charmed mesons, as well as for the rare decays\n$D^0\\to\\pi^+\\pi^-\\ell^+\\ell^-$. With this motivation, we study the cascade\ntopology $D^0\\to a_1(1260)^+(\\to \\rho(770)^0\\pi^+)\\,\\pi^-$, which has been\nmeasured to contribute significantly to the $4\\pi$ decays, and estimate its\neffect on the branching ratio of the rare decays. We also explore the\npossibility of this topology contributing to the decay amplitude of\n$D^0\\to\\pi^+\\pi^-$ and by extension to the related CP asymmetry.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-02T09:03:15Z"}
{"aid":"http://arxiv.org/abs/2504.01518v1","title":"On 2-color partitions where one of the colors is multiples of $7^k$","summary":"In this work, we investigate the arithmetic properties of $p_{1,7^k}(n)$,\nwhich counts 2-color partitions of $n$ where one of the colors appears only in\nparts that are multiples of $7^k$. By constructing generating functions for\n$p_{1,7^k}(n)$ across specific arithmetic progressions, we establish a set of\nRamanujan-type infinite family of congruences modulo powers of $7$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-02T09:04:50Z"}
{"aid":"http://arxiv.org/abs/2504.01538v1","title":"AI-Newton: A Concept-Driven Physical Law Discovery System without Prior\n  Physical Knowledge","summary":"Current limitations in human scientific discovery necessitate a new research\nparadigm. While advances in artificial intelligence (AI) offer a highly\npromising solution, enabling AI to emulate human-like scientific discovery\nremains an open challenge. To address this, we propose AI-Newton, a\nconcept-driven discovery system capable of autonomously deriving physical laws\nfrom raw data -- without supervision or prior physical knowledge. The system\nintegrates a knowledge base and knowledge representation centered on physical\nconcepts, along with an autonomous discovery workflow. As a proof of concept,\nwe apply AI-Newton to a large set of Newtonian mechanics problems. Given\nexperimental data with noise, the system successfully rediscovers fundamental\nlaws, including Newton's second law, energy conservation and law of\ngravitation, using autonomously defined concepts. This achievement marks a\nsignificant step toward AI-driven autonomous scientific discovery.","main_category":"cs.AI","categories":"cs.AI,cs.LG,cs.SC,hep-ph,physics.class-ph","published":"2025-04-02T09:25:34Z"}
{"aid":"http://arxiv.org/abs/2504.01551v1","title":"Identifying Macro Causal Effects in C-DMGs","summary":"Causal effect identification using causal graphs is a fundamental challenge\nin causal inference. While extensive research has been conducted in this area,\nmost existing methods assume the availability of fully specified causal graphs.\nHowever, in complex domains such as medicine and epidemiology, complete causal\nknowledge is often unavailable, and only partial information about the system\nis accessible. This paper focuses on causal effect identification within\npartially specified causal graphs, with particular emphasis on cluster-directed\nmixed graphs (C-DMGs). These graphs provide a higher-level representation of\ncausal relationships by grouping variables into clusters, offering a more\npractical approach for handling complex systems. Unlike fully specified causal\ngraphs, C-DMGs can contain cycles, which complicate their analysis and\ninterpretation. Furthermore, their cluster-based nature introduces new\nchallenges, as it gives rise to two distinct types of causal effects, macro\ncausal effects and micro causal effects, with different properties. In this\nwork, we focus on macro causal effects, which describe the effects of entire\nclusters on other clusters. We establish that the do-calculus is both sound and\ncomplete for identifying these effects in C-DMGs. Additionally, we provide a\ngraphical characterization of non-identifiability for macro causal effects in\nthese graphs.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-02T09:48:27Z"}
{"aid":"http://arxiv.org/abs/2504.01578v1","title":"Entanglement in the symmetric subspace: mapping multipartite to\n  bipartite states","summary":"We propose a technique to investigate multipartite entanglement in the\nsymmetric subspace. Our approach is to map an $N$-qubit symmetric state onto a\nbipartite symmetric state of higher local dimension. We show that this mapping\npreserves separability and allows to characterize the entanglement of the\noriginal multipartite state. In particular, we provide several bounds to\nestimate the symmetric tensor rank and geometric measure of entanglement.\nAdditionally, we identify multipartite symmetric states whose entanglement\noutperforms that of previously known candidates for maximally entangled\nsymmetric states. Finally, we reveal the existence of entangled symmetric\nsubspaces, where all bipartite states are entangled.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T10:31:18Z"}
{"aid":"http://arxiv.org/abs/2504.01589v1","title":"Text Speaks Louder than Vision: ASCII Art Reveals Textual Biases in\n  Vision-Language Models","summary":"Vision-language models (VLMs) have advanced rapidly in processing multimodal\ninformation, but their ability to reconcile conflicting signals across\nmodalities remains underexplored. This work investigates how VLMs process ASCII\nart, a unique medium where textual elements collectively form visual patterns,\npotentially creating semantic-visual conflicts. We introduce a novel evaluation\nframework that systematically challenges five state-of-the-art models\n(including GPT-4o, Claude, and Gemini) using adversarial ASCII art, where\ncharacter-level semantics deliberately contradict global visual patterns. Our\nexperiments reveal a strong text-priority bias: VLMs consistently prioritize\ntextual information over visual patterns, with visual recognition ability\ndeclining dramatically as semantic complexity increases. Various mitigation\nattempts through visual parameter tuning and prompt engineering yielded only\nmodest improvements, suggesting that this limitation requires\narchitectural-level solutions. These findings uncover fundamental flaws in how\ncurrent VLMs integrate multimodal information, providing important guidance for\nfuture model development while highlighting significant implications for\ncontent moderation systems vulnerable to adversarial examples.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T10:47:07Z"}
{"aid":"http://arxiv.org/abs/2504.01593v1","title":"Integrating experimental feedback improves generative models for\n  biological sequences","summary":"Generative probabilistic models have shown promise in designing artificial\nRNA and protein sequences but often suffer from high rates of false positives,\nwhere sequences predicted as functional fail experimental validation. To\naddress this critical limitation, we explore the impact of reintegrating\nexperimental feedback into the model design process. We propose a\nlikelihood-based reintegration scheme, which we test through extensive\ncomputational experiments on both RNA and protein datasets, as well as through\nwet-lab experiments on the self-splicing ribozyme from the group I intron RNA\nfamily where our approach demonstrates particular efficacy. We show that\nintegrating recent experimental data enhances the model's capacity of\ngenerating functional sequences (e.g. from 6.7\\% to 63.7\\% of active designs at\n45 mutations). This feedback-driven approach thus provides a significant\nimprovement in the design of biomolecular sequences by directly tackling the\nfalse-positive challenge.","main_category":"q-bio.BM","categories":"q-bio.BM,physics.bio-ph,q-bio.QM","published":"2025-04-02T10:57:53Z"}
{"aid":"http://arxiv.org/abs/2504.01594v1","title":"Anticipating Degradation: A Predictive Approach to Fault Tolerance in\n  Robot Swarms","summary":"An active approach to fault tolerance is essential for robot swarms to\nachieve long-term autonomy. Previous efforts have focused on responding to\nspontaneous electro-mechanical faults and failures. However, many faults occur\ngradually over time. Waiting until such faults have manifested as failures\nbefore addressing them is both inefficient and unsustainable in a variety of\nscenarios. This work argues that the principles of predictive maintenance, in\nwhich potential faults are resolved before they hinder the operation of the\nswarm, offer a promising means of achieving long-term fault tolerance. This is\na novel approach to swarm fault tolerance, which is shown to give a comparable\nor improved performance when tested against a reactive approach in almost all\ncases tested.","main_category":"cs.RO","categories":"cs.RO,cs.MA","published":"2025-04-02T10:59:10Z"}
{"aid":"http://arxiv.org/abs/2504.01615v1","title":"The Mini-SiTian Array: A Pathfinder for the SiTian Project","summary":"The Mini-SiTian Array serves as a pathfinder for the SiTian project, which\naims to survey the entire sky in $gri$ bands every 30 minutes, reaching a\nlimiting magnitude of 21. This special issue features 11 papers covering the\ndesign, operation, data reduction, and early scientific results from two years\nof Mini-SiTian observations. The insights gained from these pathfinder\nexperiments represent a significant milestone toward the full realization of\nthe SiTian project.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-02T11:26:27Z"}
{"aid":"http://arxiv.org/abs/2504.01621v1","title":"Two-photon microscopy using picosecond pulses from four-wave mixing in a\n  Yb-doped photonic crystal fiber","summary":"Two-photon microscopy (TPM) enables deep tissue imaging but requires\nexcitation pulses that have a large product of average and peak power,\ntypically supplied by femtosecond solid-state lasers. However, these lasers are\nbulky and femtosecond pulses require careful dispersion management to avoid\npulse broadening, particularly when delivery fibers are used. Here we present a\ncompact, fiber-based picosecond laser source operating at 790 nm for TPM using\na ytterbium-doped photonic crystal fiber (Yb-doped PCF). The Yb-doped PCF\nsimultaneously amplifies 1064 nm input pulses and efficiently converts them to\n790 nm via four-wave mixing, generating pulses with a peak power of up to ~3.8\nkW. The source has a variable repetition rate (1.48 MHz-14.78 MHz), enabling\nthe two-photon excitation fluorescence signal to be maximized in the presence\nof excitation saturation. We benchmark our picosecond laser source against a\nfemtosecond Ti:Sapphire laser for TPM of stained Convallaria majalis samples\nand demonstrate comparable fluorescence signal when the two-photon excitation\nconditions are matched.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-02T11:30:04Z"}
{"aid":"http://arxiv.org/abs/2504.01642v1","title":"Spanning clique subdivisions in pseudorandom graphs","summary":"In this paper, we study the appearance of a spanning subdivision of a clique\nin graphs satisfying certain pseudorandom conditions. Specifically, we show the\nfollowing three results. Firstly, that there are constants $C>0$ and $c\\in\n(0,1]$ such that, whenever $d/\\lambda\\ge C$, every $(n,d,\\lambda)$-graph\ncontains a spanning subdivision of $K_t$ for all $2\\le t \\le\n\\min\\{cd,c\\sqrt{\\frac{n}{\\log n}}\\}$. Secondly, that there are constants $C>0$\nand $c\\in (0,1]$ such that, whenever $d/\\lambda\\ge C\\log^3n$, every\n$(n,d,\\lambda)$-graph contains a spanning nearly-balanced subdivision of $K_t$\nfor all $2\\le t \\le \\min\\{cd,c\\sqrt{\\frac{n}{\\log^3n}}\\}$. Finally, we show\nthat for every $\\mu>0$, there are constants $c,\\varepsilon\\in (0,1]$ and\n$n_0\\in \\mathbb N$ such that, whenever $n\\ge n_0$, every $n$-vertex graph with\nminimum degree at least $\\mu n$ and no bipartite holes of size $\\varepsilon n$\ncontains a spanning nearly-balanced subdivision of $K_t$ for all $2\\le t \\le\nc\\sqrt{n}$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-02T11:46:24Z"}
{"aid":"http://arxiv.org/abs/2504.01666v1","title":"CLIP-SLA: Parameter-Efficient CLIP Adaptation for Continuous Sign\n  Language Recognition","summary":"Continuous sign language recognition (CSLR) focuses on interpreting and\ntranscribing sequences of sign language gestures in videos. In this work, we\npropose CLIP sign language adaptation (CLIP-SLA), a novel CSLR framework that\nleverages the powerful pre-trained visual encoder from the CLIP model to sign\nlanguage tasks through parameter-efficient fine-tuning (PEFT). We introduce two\nvariants, SLA-Adapter and SLA-LoRA, which integrate PEFT modules into the CLIP\nvisual encoder, enabling fine-tuning with minimal trainable parameters. The\neffectiveness of the proposed frameworks is validated on four datasets:\nPhoenix2014, Phoenix2014-T, CSL-Daily, and Isharah-500, where both CLIP-SLA\nvariants outperformed several SOTA models with fewer trainable parameters.\nExtensive ablation studies emphasize the effectiveness and flexibility of the\nproposed methods with different vision-language models for CSLR. These findings\nshowcase the potential of adapting large-scale pre-trained models for scalable\nand efficient CSLR, which pave the way for future advancements in sign language\nunderstanding.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T12:15:33Z"}
{"aid":"http://arxiv.org/abs/2504.01672v1","title":"A flexible framework for early power and timing comparison of\n  time-multiplexed CGRA kernel executions","summary":"At the intersection between traditional CPU architectures and more\nspecialized options such as FPGAs or ASICs lies the family of reconfigurable\nhardware architectures, termed Coarse-Grained Reconfigurable Arrays (CGRAs).\nCGRAs are composed of a 2-dimensional array of processing elements (PE),\ntightly integrated with each other, each capable of performing arithmetic and\nlogic operations. The vast design space of CGRA implementations poses a\nchallenge, which calls for fast exploration tools to prune it in advance of\ntime-consuming syntheses. The proposed tool aims to simplify this process by\nsimulating kernel execution and providing a characterization framework. The\nestimator returns energy and latency values otherwise only available through a\ntime-consuming post-synthesis simulation, allowing for instantaneous\ncomparative analysis between different kernels and hardware configurations.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-02T12:21:09Z"}
{"aid":"http://arxiv.org/abs/2504.01678v1","title":"Second-order cone programming for distributionally robust compliance\n  optimization of trusses considering input distribution uncertainty","summary":"Reliability-based design optimization (RBDO) is a methodology for designing\nstructures under the consideration for uncertainty with the assumption that the\ninput distribution is completely known. In practical engineering, the number of\ninput data is often limited, which can damage the validity of the optimal\nresults obtained by RBDO. Confidence-based design optimization (CBDO) has been\nproposed to account for the uncertainty of the input distribution. However,\nthis approach faces challenges, computational cost and accuracy when dealing\nwith highly nonlinear performance constraints. In this paper, we consider the\ncompliance minimization problem of truss structures with uncertain external\nforces. Armed with the advanced risk measure, conditional Value-at-Risk (CVaR),\nwe formulate a bi-objective optimization problem for the worst-case expected\nvalue and the worst-case CVaR of compliance, which allows us to account for the\ntail risk of performance functions not addressed in CBDO. Employing kernel\ndensity estimation for estimation of the input distribution allows us to\neliminate the need for modeling the input distribution. We show that this\nproblem reduces to a second-order cone programming when assigning either\nuniform kernel or triangular kernel. Finally, through numerical experiments, we\nobtain the Pareto front for the bi-objective optimization problem of the\nworst-case expected value and CVaR of compliance of truss structures, and\nconfirm the changes in the Pareto solutions.","main_category":"math.OC","categories":"math.OC","published":"2025-04-02T12:26:23Z"}
{"aid":"http://arxiv.org/abs/2504.01709v1","title":"How chiral vibrations drive molecular rotation","summary":"We analyze two simple model planar molecules: an ionic molecule with D3\nsymmetry and a covalent molecule with D6 symmetry. Both symmetries allow the\nexistence of chiral molecular orbitals and normal modes that are coupled to\neach other in a Jahn-Teller manner, invariant under U (1) symmetry with\ngenerator a pseudo angular momentum. In the ionic molecule, the chiral mode\npossesses an electric dipole but lacks physical angular momentum, whereas, in\nthe covalent molecule, the situation is reversed. In spite of that, we show\nthat in both cases the chiral modes can be excited by a circularly polarized\nlight and are subsequently able to induce rotational motion of the entire\nmolecule. We further discuss the potential extension of our findings to the\ncase of crystalline bulk samples.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-02T13:15:59Z"}
{"aid":"http://arxiv.org/abs/2504.01733v1","title":"Epistemic Skills: Reasoning about Knowledge and Oblivion","summary":"This paper presents a class of epistemic logics that captures the dynamics of\nacquiring knowledge and descending into oblivion, while incorporating concepts\nof group knowledge. The approach is grounded in a system of weighted models,\nintroducing an ``epistemic skills'' metric to represent the epistemic\ncapacities tied to knowledge updates. Within this framework, knowledge\nacquisition is modeled as a process of upskilling, whereas oblivion is\nrepresented as a consequence of downskilling. The framework further enables\nexploration of ``knowability'' and ``forgettability,'' defined as the potential\nto gain knowledge through upskilling and to lapse into oblivion through\ndownskilling, respectively. Additionally, it supports a detailed analysis of\nthe distinctions between epistemic de re and de dicto expressions. The\ncomputational complexity of the model checking and satisfiability problems is\nexamined, offering insights into their theoretical foundations and practical\nimplications.","main_category":"cs.AI","categories":"cs.AI,cs.CC,cs.LO","published":"2025-04-02T13:41:42Z"}
{"aid":"http://arxiv.org/abs/2504.01742v1","title":"Doctor: Optimizing Container Rebuild Efficiency by Instruction\n  Re-Orchestration","summary":"Containerization has revolutionized software deployment, with Docker leading\nthe way due to its ease of use and consistent runtime environment. As Docker\nusage grows, optimizing Dockerfile performance, particularly by reducing\nrebuild time, has become essential for maintaining efficient CI/CD pipelines.\nHowever, existing optimization approaches primarily address single builds\nwithout considering the recurring rebuild costs associated with modifications\nand evolution, limiting long-term efficiency gains. To bridge this gap, we\npresent Doctor, a method for improving Dockerfile build efficiency through\ninstruction re-ordering that addresses key challenges: identifying instruction\ndependencies, predicting future modifications, ensuring behavioral equivalence,\nand managing the optimization computational complexity. We developed a\ncomprehensive dependency taxonomy based on Dockerfile syntax and a historical\nmodification analysis to prioritize frequently modified instructions. Using a\nweighted topological sorting algorithm, Doctor optimizes instruction order to\nminimize future rebuild time while maintaining functionality. Experiments on\n2,000 GitHub repositories show that Doctor improves 92.75% of Dockerfiles,\nreducing rebuild time by an average of 26.5%, with 12.82% of files achieving\nover a 50% reduction. Notably, 86.2% of cases preserve functional similarity.\nThese findings highlight best practices for Dockerfile management, enabling\ndevelopers to enhance Docker efficiency through informed optimization\nstrategies.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-02T13:53:35Z"}
{"aid":"http://arxiv.org/abs/2504.01752v1","title":"A Two-Timescale Approach for Wireless Federated Learning with Parameter\n  Freezing and Power Control","summary":"Federated learning (FL) enables distributed devices to train a shared machine\nlearning (ML) model collaboratively while protecting their data privacy.\nHowever, the resource-limited mobile devices suffer from intensive\ncomputation-and-communication costs of model parameters. In this paper, we\nobserve the phenomenon that the model parameters tend to be stabilized long\nbefore convergence during training process. Based on this observation, we\npropose a two-timescale FL framework by joint optimization of freezing\nstabilized parameters and controlling transmit power for the unstable\nparameters to balance the energy consumption and convergence. First, we analyze\nthe impact of model parameter freezing and unreliable transmission on the\nconvergence rate. Next, we formulate a two-timescale optimization problem of\nparameter freezing percentage and transmit power to minimize the model\nconvergence error subject to the energy budget. To solve this problem, we\ndecompose it into parallel sub-problems and decompose each sub-problem into two\ndifferent timescales problems using the Lyapunov optimization method. The\noptimal parameter freezing and power control strategies are derived in an\nonline fashion. Experimental results demonstrate the superiority of the\nproposed scheme compared with the benchmark schemes.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T14:05:45Z"}
{"aid":"http://arxiv.org/abs/2504.01767v1","title":"Leveraging Embedding Techniques in Multimodal Machine Learning for\n  Mental Illness Assessment","summary":"The increasing global prevalence of mental disorders, such as depression and\nPTSD, requires objective and scalable diagnostic tools. Traditional clinical\nassessments often face limitations in accessibility, objectivity, and\nconsistency. This paper investigates the potential of multimodal machine\nlearning to address these challenges, leveraging the complementary information\navailable in text, audio, and video data. Our approach involves a comprehensive\nanalysis of various data preprocessing techniques, including novel chunking and\nutterance-based formatting strategies. We systematically evaluate a range of\nstate-of-the-art embedding models for each modality and employ Convolutional\nNeural Networks (CNNs) and Bidirectional LSTM Networks (BiLSTMs) for feature\nextraction. We explore data-level, feature-level, and decision-level fusion\ntechniques, including a novel integration of Large Language Model (LLM)\npredictions. We also investigate the impact of replacing Multilayer Perceptron\nclassifiers with Support Vector Machines. We extend our analysis to severity\nprediction using PHQ-8 and PCL-C scores and multi-class classification\n(considering co-occurring conditions). Our results demonstrate that\nutterance-based chunking significantly improves performance, particularly for\ntext and audio modalities. Decision-level fusion, incorporating LLM\npredictions, achieves the highest accuracy, with a balanced accuracy of 94.8%\nfor depression and 96.2% for PTSD detection. The combination of CNN-BiLSTM\narchitectures with utterance-level chunking, coupled with the integration of\nexternal LLM, provides a powerful and nuanced approach to the detection and\nassessment of mental health conditions. Our findings highlight the potential of\nMMML for developing more accurate, accessible, and personalized mental\nhealthcare tools.","main_category":"eess.AS","categories":"eess.AS,cs.AI,cs.CV","published":"2025-04-02T14:19:06Z"}
{"aid":"http://arxiv.org/abs/2504.01772v1","title":"Adaptation of Moreau-Yosida regularization to the modulus of convexity","summary":"We study a generalization of Moreau-Yosida regularization that is adapted to\nthe geometry of Banach spaces where the dual space is uniformly convex with\nmodulus of convexity of power type. Important properties for regularized convex\nfunctions are given, in particular strong monotonicity of the subdifferential\nof their convex conjugate and H\\\"older-continuity of their gradient.","main_category":"math.FA","categories":"math.FA,math-ph,math.MP","published":"2025-04-02T14:31:08Z"}
{"aid":"http://arxiv.org/abs/2504.01808v1","title":"Coloring of graphs without long odd holes","summary":"A {\\em hole} is an induced cycle of length at least 4, a $k$-hole is a hole\nof length $k$, and an {\\em odd hole} is a hole of odd length. Let $\\ell\\ge 2$\nbe an integer. Let ${\\cal A}_{\\ell}$ be the family of graphs of girth at least\n$2\\ell$ and having no odd holes of length at least $2\\ell+3$, let ${\\cal\nB}_{\\ell}$ be the triangle-free graphs which have no 5-holes and no odd holes\nof length at least $2\\ell+3$, and let ${\\cal G}_{\\ell}$ be the family of graphs\nof girth $2\\ell+1$ and have no odd hole of length at least $2\\ell+5$.\nChudnovsky {\\em et al.} \\cite{CSS2016} proved that every graph in ${\\cal\nA}_{2}$ is 58000-colorable, and every graph in ${\\cal B}_{\\ell}$ is\n$(\\ell+1)4^{\\ell-1}$-colorable. Lan and liu \\cite{LL2023} showed that for\n$\\ell\\geq3$, every graph in ${\\cal G}_{\\ell}$ is 4-colorable. It is not known\nwhether there exists a small constant $c$ such that graphs of ${\\cal G}_2$ are\n$c$-colorable. In this paper, we show that every graph in ${\\cal G}_2$ is\n1456-colorable, and every graph in ${\\cal A}_{3}$ is 4-colorable. We also show\nthat every 7-hole free graph in ${\\cal B}_{\\ell}$ is $(12\\ell+8)$-colorable.","main_category":"math.CO","categories":"math.CO","published":"2025-04-02T15:12:42Z"}
{"aid":"http://arxiv.org/abs/2504.01817v1","title":"Multi-actuator lens systems for turbulence correction in free-space\n  optical communications","summary":"The implementation of efficient free-space channels is fundamental for both\nclassical and quantum Free-Space Optical (FSO) communication. This can be\nchallenging for fibre-coupled receivers, due to the time variant inhomogeneity\nof the refractive index that can cause strong fluctuations in the power coupled\ninto the Single-Mode Fiber (SMF), and requires the use of Adaptive Optics (AO)\nsystems to correct the atmospheric induced aberrations. In this work, we\npresent two adaptive optic systems, one using a Fast-Steering Prism (FSP) for\nthe correction of tip-tilt and a second one based on a Multi-Actuator\ndeformable Lens (MAL), capable of correcting up to the third order of Zernike's\npolynomials. We test both systems at telecom wavelength both with artificial\nturbulence in the laboratory and on a free-space channel, demonstrating their\neffectiveness in increasing the fibre coupling efficiency.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-02T15:21:58Z"}
{"aid":"http://arxiv.org/abs/2504.01827v1","title":"What is AI, what is it not, how we use it in physics and how it\n  impacts... you","summary":"Artificial Intelligence (AI) and Machine Learning (ML) have been prevalent in\nparticle physics for over three decades, shaping many aspects of High Energy\nPhysics (HEP) analyses. As AI's influence grows, it is essential for physicists\n$\\unicode{x2013}$ as both researchers and informed citizens $\\unicode{x2013}$\nto critically examine its foundations, misconceptions, and impact. This paper\nexplores AI definitions, examines how ML differs from traditional programming,\nand provides a brief review of AI/ML applications in HEP, highlighting\npromising trends such as Simulation-Based Inference, uncertainty-aware machine\nlearning, and Fast ML for anomaly detection. Beyond physics, it also addresses\nthe broader societal harms of AI systems, underscoring the need for responsible\nengagement. Finally, it stresses the importance of adapting research practices\nto an evolving AI landscape, ensuring that physicists not only benefit from the\nlatest tools but also remain at the forefront of innovation.","main_category":"physics.soc-ph","categories":"physics.soc-ph,cs.LG,hep-ex","published":"2025-04-02T15:35:43Z"}
{"aid":"http://arxiv.org/abs/2504.01842v1","title":"shapr: Explaining Machine Learning Models with Conditional Shapley\n  Values in R and Python","summary":"This paper introduces the shapr package, a versatile tool for generating\nShapley value explanations for machine learning and statistical regression\nmodels in both R and Python. The package emphasizes conditional Shapley value\nestimates, providing a comprehensive range of approaches for accurately\ncapturing feature dependencies, which is crucial for correct model\ninterpretation and lacking in similar software. In addition to regular tabular\ndata, the shapr R-package includes specialized functionality for explaining\ntime series forecasts. The package offers a minimal set of user functions with\nsensible defaults for most use cases while providing extensive flexibility for\nadvanced users to fine-tune computations. Additional features include\nparallelized computations, iterative estimation with convergence detection, and\nrich visualization tools. shapr also extends its functionality to compute\ncausal and asymmetric Shapley values when causal information is available. In\naddition, we introduce the shaprpy Python library, which brings core\ncapabilities of shapr to the Python ecosystem. Overall, the package aims to\nenhance the interpretability of predictive models within a powerful and\nuser-friendly framework.","main_category":"cs.LG","categories":"cs.LG,stat.CO","published":"2025-04-02T15:47:30Z"}
{"aid":"http://arxiv.org/abs/2504.01846v1","title":"Many neighbors little entanglement: A curious scaling in the\n  variable-range extended Ising model","summary":"We study the two-point correlation functions and the bipartite entanglement\nin the ground state of the exactly-solvable variable-range extended Ising model\nof qubits in the presence of a transverse field on a one-dimensional lattice.\nWe introduce the variation in the range of interaction by varying the\ncoordination number, $\\mathcal{Z}$, of each qubit, where the interaction\nstrength between a pair of qubits at a distance $r$ varies as $\\sim\nr^{-\\alpha}$. We show that the algebraic nature of the correlation functions is\npresent only up to $r=\\mathcal{Z}$, above which it exhibits short-range\nexponential scaling. We also show that at the critical point, the bipartite\nentanglement exhibits a power-law decrease ($\\sim\\mathcal{Z}^{-\\gamma}$) with\nincreasing coordination number irrespective of the partition size and the value\nof $\\alpha$ for $\\alpha>1$. We further consider a sudden quench of the system\nstarting from the ground state of the infinite-field limit of the system\nHamiltonian via turning on the critical Hamiltonian, and demonstrate that the\nlong-time averaged bipartite entanglement exhibits a qualitatively similar\nvariation ($\\sim\\mathcal{Z}^{-\\gamma}$) with $\\mathcal{Z}$.","main_category":"quant-ph","categories":"quant-ph,cond-mat.str-el","published":"2025-04-02T15:54:52Z"}
{"aid":"http://arxiv.org/abs/2504.01866v1","title":"From Code Generation to Software Testing: AI Copilot with Context-Based\n  RAG","summary":"The rapid pace of large-scale software development places increasing demands\non traditional testing methodologies, often leading to bottlenecks in\nefficiency, accuracy, and coverage. We propose a novel perspective on software\ntesting by positing bug detection and coding with fewer bugs as two\ninterconnected problems that share a common goal, which is reducing bugs with\nlimited resources. We extend our previous work on AI-assisted programming,\nwhich supports code auto-completion and chatbot-powered Q&A, to the realm of\nsoftware testing. We introduce Copilot for Testing, an automated testing system\nthat synchronizes bug detection with codebase updates, leveraging context-based\nRetrieval Augmented Generation (RAG) to enhance the capabilities of large\nlanguage models (LLMs). Our evaluation demonstrates a 31.2% improvement in bug\ndetection accuracy, a 12.6% increase in critical test coverage, and a 10.5%\nhigher user acceptance rate, highlighting the transformative potential of\nAI-driven technologies in modern software development practices.","main_category":"cs.SE","categories":"cs.SE,cs.AI,cs.PL","published":"2025-04-02T16:20:05Z"}
{"aid":"http://arxiv.org/abs/2504.01868v1","title":"Focal Mechanism Uncertainty Quantification In Ground Motion Simulations\n  Of Le Teil Earthquake","summary":"Ensuring the seismic safety of nuclear power plants (NPPs) is essential,\nespecially for facilities that rely on base isolation to reduce earthquake\nimpacts. For understanding the seismic response, accurate models are key to\npredict the ground motions, which are generally sensitive to various factors,\nincluding earthquake source parameters like the focal mechanism, i.e., strike,\ndip, and rake angles. This study examines how uncertainties in these parameters\naffect ground motion predictions. The analysis is based on the SMATCH\nbenchmark, which provides a standardized approach for evaluating the seismic\nresponse of the Cruas-Meysse NPP in France during the Mw 4.9 Le-Teil earthquake\nof 2019. A set of 27 3D high-fidelity numerical simulations was performed using\na spectral-element method, each incorporating different focal mechanism\nvariations. These simulations provide an effective approach for investigating\nthe factors behind the exceptional ground motion observed during this event. To\nquantify uncertainty, the simulated ground motions were compared to recorded\ndata using two well-established goodness-of-fit criteria: one assessing\ntime-frequency domain characteristics and another focusing on the\ncharacterization of the ground motion signals by intensity measures. Results\nhighlight the significant influence of focal mechanism variability on ground\nmotion predictions, especially on the rake angle, which showed the strongest\ncorrelation with wave and intensity measures.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-02T16:22:46Z"}
{"aid":"http://arxiv.org/abs/2504.01869v1","title":"Buggin: Automatic intrinsic bugs classification model using NLP and ML","summary":"Recent studies have shown that bugs can be categorized into intrinsic and\nextrinsic types. Intrinsic bugs can be backtracked to specific changes in the\nversion control system (VCS), while extrinsic bugs originate from external\nchanges to the VCS and lack a direct bug-inducing change. Using only intrinsic\nbugs to train bug prediction models has been reported as beneficial to improve\nthe performance of such models. However, there is currently no automated\napproach to identify intrinsic bugs. To bridge this gap, our study employs\nNatural Language Processing (NLP) techniques to automatically identify\nintrinsic bugs. Specifically, we utilize two embedding techniques, seBERT and\nTF-IDF, applied to the title and description text of bug reports. The resulting\nembeddings are fed into well-established machine learning algorithms such as\nSupport Vector Machine, Logistic Regression, Decision Tree, Random Forest, and\nK-Nearest Neighbors. The primary objective of this paper is to assess the\nperformance of various NLP and machine learning techniques in identifying\nintrinsic bugs using the textual information extracted from bug reports. The\nresults demonstrate that both seBERT and TF-IDF can be effectively utilized for\nintrinsic bug identification. The highest performance scores were achieved by\ncombining TF-IDF with the Decision Tree algorithm and utilizing the bug titles\n(yielding an F1 score of 78%). This was closely followed by seBERT, Support\nVector Machine, and bug titles (with an F1 score of 77%). In summary, this\npaper introduces an innovative approach that automates the identification of\nintrinsic bugs using textual information derived from bug reports.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-02T16:23:08Z"}
{"aid":"http://arxiv.org/abs/2504.01900v1","title":"Physical Modeling of Saturated Common Mode Choke","summary":"Common mode chokes (CMCs) are conventional circuit elements performing\nseveral tasks, including noise suppression, hindering electromagnetic\ninterference, providing signal integrity, and circuit protection. Much as they\nare widely used, their fundamental construction and description are often\nqualitative and lack an understanding of the underlying physical principles. We\ndiscuss the behavior of a commercial CMC based on the physical description of\nthe superparamagnetic core and parasitic circuit elements. The results are\nvalidated using a DC bias current and an external magnetic field, which affect\nthe magnetic properties. The behavior of the CMCs in the strongly non-linear\nregime is also described.","main_category":"physics.app-ph","categories":"physics.app-ph,cond-mat.mtrl-sci","published":"2025-04-02T16:58:47Z"}
{"aid":"http://arxiv.org/abs/2504.01901v1","title":"Ross3D: Reconstructive Visual Instruction Tuning with 3D-Awareness","summary":"The rapid development of Large Multimodal Models (LMMs) for 2D images and\nvideos has spurred efforts to adapt these models for interpreting 3D scenes.\nHowever, the absence of large-scale 3D vision-language datasets has posed a\nsignificant obstacle. To address this issue, typical approaches focus on\ninjecting 3D awareness into 2D LMMs by designing 3D input-level scene\nrepresentations. This work provides a new perspective. We introduce\nreconstructive visual instruction tuning with 3D-awareness (Ross3D), which\nintegrates 3D-aware visual supervision into the training procedure.\nSpecifically, it incorporates cross-view and global-view reconstruction. The\nformer requires reconstructing masked views by aggregating overlapping\ninformation from other views. The latter aims to aggregate information from all\navailable views to recover Bird's-Eye-View images, contributing to a\ncomprehensive overview of the entire scene. Empirically, Ross3D achieves\nstate-of-the-art performance across various 3D scene understanding benchmarks.\nMore importantly, our semi-supervised experiments demonstrate significant\npotential in leveraging large amounts of unlabeled 3D vision-only data.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL,cs.RO","published":"2025-04-02T16:59:55Z"}
{"aid":"http://arxiv.org/abs/2504.01905v1","title":"Accelerating IoV Intrusion Detection: Benchmarking GPU-Accelerated vs\n  CPU-Based ML Libraries","summary":"The Internet of Vehicles (IoV) may face challenging cybersecurity attacks\nthat may require sophisticated intrusion detection systems, necessitating a\nrapid development and response system. This research investigates the\nperformance advantages of GPU-accelerated libraries (cuML) compared to\ntraditional CPU-based implementations (scikit-learn), focusing on the speed and\nefficiency required for machine learning models used in IoV threat detection\nenvironments. The comprehensive evaluations conducted employ four machine\nlearning approaches (Random Forest, KNN, Logistic Regression, XGBoost) across\nthree distinct IoV security datasets (OTIDS, GIDS, CICIoV2024). Our findings\ndemonstrate that GPU-accelerated implementations dramatically improved\ncomputational efficiency, with training times reduced by a factor of up to 159\nand prediction speeds accelerated by up to 95 times compared to traditional CPU\nprocessing, all while preserving detection accuracy. This remarkable\nperformance breakthrough empowers researchers and security specialists to\nharness GPU acceleration for creating faster, more effective threat detection\nsystems that meet the urgent real-time security demands of today's connected\nvehicle networks.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CR","published":"2025-04-02T17:04:53Z"}
{"aid":"http://arxiv.org/abs/2504.01918v1","title":"Long-eared digraphs","summary":"Let $H$ be a subdigraph of a digraph $D$. An ear of $H$ in $D$ is a path or a\ncycle in $D$ whose ends lie in $H$ but whose internal vertices do not. An\n\\emph{ear decomposition} of a strong digraph $D$ is a nested sequence\n$(D_0,D_1,\\ldots , D_k)$ of strong subdigraphs of $D$ such that: 1) $D_0$ is a\ncycle, 2) $D_{i+1} = D_i\\cup P_i$, where $P_i$ is an ear of $D_i$ in $D$, for\nevery $i\\in \\{0,1,\\ldots,k-1\\}$, and 3) $D_k=D$.\n  In this work, the $\\mathcal{LE}_i$ is defined as the family of strong\ndigraphs, with an ear decomposition such that every ear has a length of at\nleast $i\\geq 1$. It is proved that Seymour's second Neighborhood Conjecture and\nthe Laborde, Payan, and Soung conjecture, are true in the family\n$\\mathcal{LE}_2$, and the Small quasi-kernel conjecture is true for digraphs in\n$\\mathcal{LE}_3$. Also, some sufficient conditions for a strong nonseparable\ndigraph in $\\mathcal{LE}_2$ with a kernel to imply that the previous\n(following) subdigraph in the ear decomposition has a kernel too, are\npresented. It is proved that digraphs in $\\mathcal{LE}_2$ have a chromatic\nnumber at most 3, and a dichromatic number 2 or 3. Finally, the oriented\nchromatic number of asymmetrical digraphs in $\\mathcal{LE}_3$ is bounded by 6,\nand it is shown that the oriented chromatic number of asymmetrical digraphs in\n$\\mathcal{LE}_2$ is not bounded.","main_category":"math.CO","categories":"math.CO","published":"2025-04-02T17:22:44Z"}
{"aid":"http://arxiv.org/abs/2504.01940v1","title":"Strengthening Multi-Robot Systems for SAR: Co-Designing Robotics and\n  Communication Towards 6G","summary":"This paper presents field-tested use cases from Search and Rescue (SAR)\nmissions, highlighting the co-design of mobile robots and communication systems\nto support Edge-Cloud architectures based on 5G Standalone (SA). The main goal\nis to contribute to the effective cooperation of multiple robots and first\nresponders. Our field experience includes the development of Hybrid Wireless\nSensor Networks (H-WSNs) for risk and victim detection, smartphones integrated\ninto the Robot Operating System (ROS) as Edge devices for mission requests and\npath planning, real-time Simultaneous Localization and Mapping (SLAM) via\nMulti-Access Edge Computing (MEC), and implementation of Uncrewed Ground\nVehicles (UGVs) for victim evacuation in different navigation modes. These\nexperiments, conducted in collaboration with actual first responders,\nunderscore the need for intelligent network resource management, balancing\nlow-latency and high-bandwidth demands. Network slicing is key to ensuring\ncritical emergency services are performed despite challenging communication\nconditions. The paper identifies architectural needs, lessons learned, and\nchallenges to be addressed by 6G technologies to enhance emergency response\ncapabilities.","main_category":"cs.RO","categories":"cs.RO,cs.NI","published":"2025-04-02T17:47:11Z"}
{"aid":"http://arxiv.org/abs/2504.01943v1","title":"OpenCodeReasoning: Advancing Data Distillation for Competitive Coding","summary":"Since the advent of reasoning-based large language models, many have found\ngreat success from distilling reasoning capabilities into student models. Such\ntechniques have significantly bridged the gap between reasoning and standard\nLLMs on coding tasks. Despite this, much of the progress on distilling\nreasoning models remains locked behind proprietary datasets or lacks details on\ndata curation, filtering and subsequent training. To address this, we construct\na superior supervised fine-tuning (SFT) dataset that we use to achieve\nstate-of-the-art coding capability results in models of various sizes. Our\ndistilled models use only SFT to achieve 61.8% on LiveCodeBench and 24.6% on\nCodeContests, surpassing alternatives trained with reinforcement learning. We\nthen perform analysis on the data sources used to construct our dataset, the\nimpact of code execution filtering, and the importance of instruction/solution\ndiversity. We observe that execution filtering negatively affected benchmark\naccuracy, leading us to prioritize instruction diversity over solution\ncorrectness. Finally, we also analyze the token efficiency and reasoning\npatterns utilized by these models. We will open-source these datasets and\ndistilled models to the community.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T17:50:31Z"}
{"aid":"http://arxiv.org/abs/2504.01958v1","title":"Individual halo bias in models of $f(R)$ gravity","summary":"Halo bias links the statistical properties of the spatial distribution of\ndark matter halos to those of the underlying dark matter field, providing\ninsights into clustering properties in both general relativity (GR) and\nmodified-gravity scenarios such as $f(R)$ models. While the primary halo\nmass-dependent bias has been studied in detailed, the secondary bias, which\naccounts for the additional dependencies on other internal halo properties, can\noffer a sensitive probe for testing gravity beyond the $\\Lambda$CDM model. To\nquantify any potential deviations between $\\Lambda$CDM and $f(R)$ gravity\nmodels in halo clustering, at both the primary and secondary level, as well as\nin the distributions of halo properties in the cosmic web. Using $N$-body\nsimulations of $f(R)$ gravity models, we assess the scaling relations and the\nprimary and secondary bias signals of halo populations on the basis of a\nhalo-by-halo estimator of large-scale effective bias. Our analysis is performed\nusing halo number density as the independent variable. The relative difference\nin the effective bias between the $f(R)$ models and $\\Lambda$CDM is sensitive,\nalbeit slightly, to the power index of modified gravity. The largest deviations\nfrom GR are measured for low-mass halos, where the average bias at fixed number\ndensity decreases by up to 5\\% for fixed scaling indices. We also show that the\nscaling relations for some environmental properties, including neighbour\nstatistics, Mach number and local overdensity, exhibit small but non-negligible\ndeviations (~3-5\\%) from GR for a wide range of number densities. Our results\nalso suggests that the properties of halos in sheets and voids show the largest\ndepartures from GR (> 10\\% in some cases). In terms of secondary bias, we do\nnot find any statistically significant deviations with respect to $\\Lambda$CDM\nfor any of the properties explored in this work.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-02T17:59:40Z"}
{"aid":"http://arxiv.org/abs/2504.02222v1","title":"APSeg: Auto-Prompt Model with Acquired and Injected Knowledge for\n  Nuclear Instance Segmentation and Classification","summary":"Nuclear instance segmentation and classification provide critical\nquantitative foundations for digital pathology diagnosis. With the advent of\nthe foundational Segment Anything Model (SAM), the accuracy and efficiency of\nnuclear segmentation have improved significantly. However, SAM imposes a strong\nreliance on precise prompts, and its class-agnostic design renders its\nclassification results entirely dependent on the provided prompts. Therefore,\nwe focus on generating prompts with more accurate localization and\nclassification and propose \\textbf{APSeg}, \\textbf{A}uto-\\textbf{P}rompt model\nwith acquired and injected knowledge for nuclear instance \\textbf{Seg}mentation\nand classification. APSeg incorporates two knowledge-aware modules: (1)\nDistribution-Guided Proposal Offset Module (\\textbf{DG-POM}), which learns\ndistribution knowledge through density map guided, and (2) Category Knowledge\nSemantic Injection Module (\\textbf{CK-SIM}), which injects morphological\nknowledge derived from category descriptions. We conducted extensive\nexperiments on the PanNuke and CoNSeP datasets, demonstrating the effectiveness\nof our approach. The code will be released upon acceptance.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-03T02:28:51Z"}
{"aid":"http://arxiv.org/abs/2504.02228v1","title":"Stochastic positivity-preserving symplectic splitting methods for\n  stochastic Lotka--Volterra predator-prey model","summary":"In this paper, we present two stochastic positive-preserving symplectic\nmethods for the stochastic Lotka-Volterra predator-prey model driven by a\nmultiplicative noise. To inherit the intrinsic characteristic of the original\nsystem, the stochastic Lie--Trotter splitting method and the stochastic Strang\nsplitting method are introduced, which are proved to preserve the positivity of\nthe numerical solution and possess the discrete stochastic symplectic\nconservation law as well. By deriving the uniform boundedness of the $p$-th\nmoment of the numerical solution, we prove that the strong convergence orders\nof these two methods are both one in the $L^2(\\Omega)$-norm. Finally, we\nvalidate the theoretical results through two and four dimensional numerical\nexamples.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-03T02:49:40Z"}
{"aid":"http://arxiv.org/abs/2504.02231v1","title":"AC-LoRA: Auto Component LoRA for Personalized Artistic Style Image\n  Generation","summary":"Personalized image generation allows users to preserve styles or subjects of\na provided small set of images for further image generation. With the\nadvancement in large text-to-image models, many techniques have been developed\nto efficiently fine-tune those models for personalization, such as Low Rank\nAdaptation (LoRA). However, LoRA-based methods often face the challenge of\nadjusting the rank parameter to achieve satisfactory results. To address this\nchallenge, AutoComponent-LoRA (AC-LoRA) is proposed, which is able to\nautomatically separate the signal component and noise component of the LoRA\nmatrices for fast and efficient personalized artistic style image generation.\nThis method is based on Singular Value Decomposition (SVD) and dynamic\nheuristics to update the hyperparameters during training. Superior performance\nover existing methods in overcoming model underfitting or overfitting problems\nis demonstrated. The results were validated using FID, CLIP, DINO, and\nImageReward, achieving an average of 9% improvement.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-03T02:56:01Z"}
{"aid":"http://arxiv.org/abs/2504.02240v1","title":"Measurement of charged hadron multiplicity in Au+Au collisions at\n  $\\sqrt{\\text{s}_{\\text{NN}}} = 200$ GeV with the sPHENIX detector","summary":"The pseudorapidity distribution of charged hadrons produced in Au+Au\ncollisions at a center-of-mass energy of $\\sqrt{s_\\mathrm{NN}} = 200$ GeV is\nmeasured using data collected by the sPHENIX detector. Charged hadron yields\nare extracted by counting cluster pairs in the inner and outer layers of the\nIntermediate Silicon Tracker, with corrections applied for detector acceptance,\nreconstruction efficiency, combinatorial pairs, and contributions from\nsecondary decays. The measured distributions cover $|\\eta| < 1.1$ across\nvarious centralities, and the average pseudorapidity density of charged hadrons\nat mid-rapidity is compared to predictions from Monte Carlo heavy-ion event\ngenerators. This result, featuring full azimuthal coverage at mid-rapidity, is\nconsistent with previous experimental measurements at the Relativistic Heavy\nIon Collider, thereby supporting the broader sPHENIX physics program.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-04-03T03:13:21Z"}
{"aid":"http://arxiv.org/abs/2504.02245v1","title":"Traffic Flow Data Completion and Anomaly Diagnosis via Sparse and\n  Low-Rank Tensor Optimization","summary":"Spatiotemporal traffic time series, such as traffic speed data, collected\nfrom sensing systems are often incomplete, with considerable corruption and\nlarge amounts of missing values. A vast amount of data conceals implicit data\nstructures, which poses significant challenges for data recovery issues, such\nas mining the potential spatio-temporal correlations of data and identifying\nabnormal data. In this paper, we propose a Tucker decomposition-based sparse\nlow-rank high-order tensor optimization model (TSLTO) for data imputation and\nanomaly diagnosis. We decompose the traffic tensor data into low-rank and\nsparse tensors, and establish a sparse low-rank high-order tensor optimization\nmodel based on Tucker decomposition. By utilizing tools of non-smooth analysis\nfor tensor functions, we explore the optimality conditions of the proposed\ntensor optimization model and design an ADMM optimization algorithm for solving\nthe model. Finally, numerical experiments are conducted on both synthetic data\nand a real-world dataset: the urban traffic speed dataset of Guangzhou.\nNumerical comparisons with several representative existing algorithms\ndemonstrate that our proposed approach achieves higher accuracy and efficiency\nin traffic flow data recovery and anomaly diagnosis tasks.","main_category":"math.OC","categories":"math.OC,cs.NA,math.NA","published":"2025-04-03T03:21:30Z"}
{"aid":"http://arxiv.org/abs/2504.02267v1","title":"Third-Order Spontaneous Parametric Down Conversion in Dielectric\n  Nonlinear Resonant Metasurfaces","summary":"We propose a general scheme to investigate photon triplet generation (PTG)\nvia third-order spontaneous parametric downconversion (TOSPDC) in $\\chi^{(3)}$\nnonlinear structures. Our approach leverages the quantum-classical\ncorrespondence between TOSPDC and its reverse classical process, three-wave\nsum-frequency generation (TSFG), to efficiently estimate the PTG rate. We apply\nthis framework to nonlinear metasurfaces supporting quasi-bound states in the\ncontinuum (qBICs) in the optical range. From numerical analysis of\nnon-collinear TSFG with degenerate input waves at qBIC wavelengths, we predict\nwavelength-tunable three-photon emission with spatio-angular correlations.\nThese findings establish a novel method for modelling TOSPDC and also highlight\nthe potential of nonlinear resonant metasurfaces as compact free-space photon\ntriplet sources with quantum state control.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-03T04:26:50Z"}
{"aid":"http://arxiv.org/abs/2504.02283v1","title":"Ga$_2$O$_3$ TCAD Mobility Parameter Calibration using Simulation\n  Augmented Machine Learning with Physics Informed Neural Network","summary":"In this paper, we demonstrate the possibility of performing automatic\nTechnology Computer-Aided-Design (TCAD) parameter calibration using machine\nlearning, verified with experimental data. The machine only needs to be trained\nby TCAD data. Schottky Barrier Diode (SBD) fabricated with emerging\nultra-wide-bandgap material, Gallium Oxide (Ga$_2$O$_3$), is measured and its\ncurrent-voltage (IV) is used for Ga$_2$O$_3$ Philips Unified Mobility (PhuMob)\nmodel parameters, effective anode workfunction, and ambient temperature\nextraction (7 parameters). A machine comprised of an autoencoder (AE) and a\nneural network (NN) (AE-NN) is used. Ga$_2$O$_3$ PhuMob parameters are\nextracted from the noisy experimental curves. TCAD simulation with the\nextracted parameters shows that the quality of the parameters is as good as an\nexpert's calibration at the pre-turned-on regime but not in the on-state\nregime. By using a simple physics-informed neural network (PINN) (AE-PINN), the\nmachine performs as well as the human expert in all regimes.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T05:09:43Z"}
{"aid":"http://arxiv.org/abs/2504.02307v1","title":"Solving adhesive rough contact problems with Atomic Force Microscope\n  data","summary":"This study presents an advanced numerical framework that integrates\nexperimentally acquired Atomic Force Microscope (AFM) data into high-fidelity\nsimulations for adhesive rough contact problems, bridging the gap between\nexperimental physics and computational mechanics. The proposed approach extends\nthe eMbedded Profile for Joint Roughness (MPJR) interface finite element method\nto incorporate both surface topography and spatially varying adhesion\nproperties, imported directly from AFM measurements. The adhesion behavior is\nmodeled using a modified Lennard-Jones potential, which is locally\nparameterized based on the AFM-extracted adhesion peak force and energy\ndissipation data. The effectiveness of this method is demonstrated through 2D\nand 3D finite element simulations of a heterogeneous PS-LDPE (polystyrene\nmatrix with low-density polyethylene inclusions) sample, where the bulk elastic\nproperties are also experimentally characterized via AFM. The results highlight\nthe significance of accounting for both surface adhesion variability and\nmaterial bulk heterogeneity in accurately predicting contact responses.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-03T06:32:06Z"}
{"aid":"http://arxiv.org/abs/2504.02312v1","title":"OmniCam: Unified Multimodal Video Generation via Camera Control","summary":"Camera control, which achieves diverse visual effects by changing camera\nposition and pose, has attracted widespread attention. However, existing\nmethods face challenges such as complex interaction and limited control\ncapabilities. To address these issues, we present OmniCam, a unified multimodal\ncamera control framework. Leveraging large language models and video diffusion\nmodels, OmniCam generates spatio-temporally consistent videos. It supports\nvarious combinations of input modalities: the user can provide text or video\nwith expected trajectory as camera path guidance, and image or video as content\nreference, enabling precise control over camera motion. To facilitate the\ntraining of OmniCam, we introduce the OmniTr dataset, which contains a large\ncollection of high-quality long-sequence trajectories, videos, and\ncorresponding descriptions. Experimental results demonstrate that our model\nachieves state-of-the-art performance in high-quality camera-controlled video\ngeneration across various metrics.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-03T06:38:30Z"}
{"aid":"http://arxiv.org/abs/2504.02315v1","title":"On $\\rm GL_3$ Fourier coefficients over values of mixed powers","summary":"Let $A_{\\pi}(n,1)$ be the $(n,1)$-th Fourier coefficient of the Hecke-Maass\ncusp form $\\pi$ for $\\rm SL_3(\\mathbb{Z})$ and $ \\omega(x)$ be a smooth\ncompactly supported function. In this paper, we prove a nontrivial upper bound\nfor the sum $$\\sum_{n_1,\\cdots,n_\\ell,n_{\\ell+1}\\in\\mathbb{Z}^+ \\atop\nn=n_1^r+\\cdots+n_{\\ell}^r+n_{\\ell+1}^s} A_{\\pi}(n,1)\\omega\\left(n/X\\right),$$\nwhere $r\\geq2$, $s\\geq 2$ and $\\ell\\geq 2^{r-1}$ are integers.","main_category":"math.NT","categories":"math.NT","published":"2025-04-03T06:43:21Z"}
{"aid":"http://arxiv.org/abs/2504.02320v1","title":"$Œ≤$-decay properties of some astrophysically important Sc-isotopes","summary":"In the late progressive stages of heavy stars, electron capture and\n$\\beta^\\pm$-decay are the governing processes. The weak rates are essential\ninputs for modeling the stages of high-mass stars before supernova explosions.\nAs per results obtained from previous simulations, weak rates of Scandium\nisotopes contribute substantially in changing the lepton-to-baryon ratio\n($Y_e$) of the nuclear matter in the core. In the present analysis, we report\nimportant $\\beta^-$-decay properties of crucial Sc isotopes in an astrophysical\nenvironment with mass numbers $49 \\leq A \\leq 54$. The investigation includes\nGamow-Teller (GT) strength distributions, terrestrial half-lives, and stellar\nrates of electron capture (EC) and $\\beta^-$-decay reactions. The calculations\nare performed using the proton-neutron (pn) quasi-particle random phase\napproximation (QRPA) model over a wide temperature range ($10^7$-$3 \\times\n10^{10}$ K) and density range ($10^1 - 10^{11}$ g/cm$^3$). Additionally, we\ncompare our calculated results with available experimental and theoretical\ndata. A good agreement is observed between our calculated half-lives and\nexperimentally measured values. Our weak $\\beta^-$-decay and EC rates are\ncompared with those from the Independent-Particle Model (IPM) and Large-Scale\nShell Model (LSSM). At high stellar temperatures and densities, our calculated\n$\\beta^-$-decay rates are smaller than those from the other models.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-03T06:47:40Z"}
{"aid":"http://arxiv.org/abs/2504.02337v1","title":"LPA3D: 3D Room-Level Scene Generation from In-the-Wild Images","summary":"Generating realistic, room-level indoor scenes with semantically plausible\nand detailed appearances from in-the-wild images is crucial for various\napplications in VR, AR, and robotics. The success of NeRF-based generative\nmethods indicates a promising direction to address this challenge. However,\nunlike their success at the object level, existing scene-level generative\nmethods require additional information, such as multiple views, depth images,\nor semantic guidance, rather than relying solely on RGB images. This is because\nNeRF-based methods necessitate prior knowledge of camera poses, which is\nchallenging to approximate for indoor scenes due to the complexity of defining\nalignment and the difficulty of globally estimating poses from a single image,\ngiven the unseen parts behind the camera. To address this challenge, we\nredefine global poses within the framework of Local-Pose-Alignment (LPA) -- an\nanchor-based multi-local-coordinate system that uses a selected number of\nanchors as the roots of these coordinates. Building on this foundation, we\nintroduce LPA-GAN, a novel NeRF-based generative approach that incorporates\nspecific modifications to estimate the priors of camera poses under LPA. It\nalso co-optimizes the pose predictor and scene generation processes. Our\nablation study and comparisons with straightforward extensions of NeRF-based\nobject generative methods demonstrate the effectiveness of our approach.\nFurthermore, visual comparisons with other techniques reveal that our method\nachieves superior view-to-view consistency and semantic normality.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T07:18:48Z"}
{"aid":"http://arxiv.org/abs/2504.02360v1","title":"On graded going-down domains, II","summary":"In this paper we consider the graded going-down property of graded integral\ndomains in pullbacks. It then enables us to give original examples of these\ndomains.","main_category":"math.AC","categories":"math.AC","published":"2025-04-03T07:51:21Z"}
{"aid":"http://arxiv.org/abs/2504.02366v1","title":"Non-Koszulness in a family of properads","summary":"Proving Koszulness of a properad can be very hard, but sometimes one can look\nat its Koszul complex to look for obstructions for Koszulness. In this paper,\nwe present a method and tools to prove non-Koszulness of many properads in a\nfamily of quadratic properads. We illustrate this method on a family of\nassociative and coassociative properads with one quadratic compatibility\nrelation.","main_category":"math.AT","categories":"math.AT","published":"2025-04-03T07:56:48Z"}
{"aid":"http://arxiv.org/abs/2504.02373v1","title":"HPGN: Hybrid Priors-Guided Network for Compressed Low-Light Image\n  Enhancement","summary":"In practical applications, conventional methods generate large volumes of\nlow-light images that require compression for efficient storage and\ntransmission. However, most existing methods either disregard the removal of\npotential compression artifacts during the enhancement process or fail to\nestablish a unified framework for joint task enhancement of images with varying\ncompression qualities. To solve this problem, we propose the hybrid\npriors-guided network (HPGN), which enhances compressed low-light images by\nintegrating both compression and illumination priors. Our approach fully\nutilizes the JPEG quality factor (QF) and DCT quantization matrix (QM) to guide\nthe design of efficient joint task plug-and-play modules. Additionally, we\nemploy a random QF generation strategy to guide model training, enabling a\nsingle model to enhance images across different compression levels.\nExperimental results confirm the superiority of our proposed method.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-03T08:06:24Z"}
{"aid":"http://arxiv.org/abs/2504.02423v1","title":"Quantum effects in piezoelectric semiconductor plasmas : Solitons and\n  transmission feasibility","summary":"A study of the coupling between lattice ion vibrations and electron waves in\na piezoelectric semiconductor quantum plasma is presented. The nonlinearities\nhave been analyzed, and solitons have been studied. The theory is built using\nthe quantum hydrodynamic (QHD) model, incorporating the effects of Fermi\npressure, quantum Bohm potential, and exchange-correlation potentials. The\ndispersion relation for the coupling is established. A set of nonlinear\nevolution equations has been derived using the two-time scale theory, and a\nsoliton solution for the coupled nonlinear evolution equations is obtained\nusing the modified quantum Zakharov equations. The solitons are found to have a\ncusp profile. It is also found that the solitons' field amplitude increases\nsignificantly with particle density and coupling strength in piezoelectric\nsemiconductor quantum plasmas.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-03T09:24:38Z"}
{"aid":"http://arxiv.org/abs/2504.02427v1","title":"Stochastic domination and lifts of random variables in percolation\n  theory","summary":"Consider some matrix waiting for its coefficients to be written. For each\ncolumn, sample independently one Bernoulli random variable of some parameter\n$p$. Seeing all this and possibly using extra randomness, Alice then chooses\none spot in each column, in any way she wants. When the Bernoulli random\nvariable of some column is equal to 1, the number 1 is written in the chosen\nspot. When the Bernoulli random variable of a column is 0, nothing is done on\nthis column. We prove that, using extra randomness, it is possible for Bob to\nfill the empty spots with well chosen 0's and 1's so that the entries of the\nmatrix are independent Bernoulli random variables of parameter $p$. We\ninvestigate various generalisations and variations of this problem, and use\nthis result to revisit and generalise (nonstrict) monotonicity of the\npercolation threshold $p_c$ with respect to some sort of graph-quotienting,\nnamely fibrations.\n  In a second part, which is independent of the first one, we revisit strict\nmonotonicity of $p_c$ with respect to fibrations, a result that naturally\nrequires more assumptions than its nonstrict counterpart. We reprove the\nbond-percolation case of the result of Martineau--Severo without resorting to\nessential enhancements, using couplings instead.","main_category":"math.PR","categories":"math.PR,math.CO","published":"2025-04-03T09:31:59Z"}
{"aid":"http://arxiv.org/abs/2504.02436v1","title":"SkyReels-A2: Compose Anything in Video Diffusion Transformers","summary":"This paper presents SkyReels-A2, a controllable video generation framework\ncapable of assembling arbitrary visual elements (e.g., characters, objects,\nbackgrounds) into synthesized videos based on textual prompts while maintaining\nstrict consistency with reference images for each element. We term this task\nelements-to-video (E2V), whose primary challenges lie in preserving the\nfidelity of each reference element, ensuring coherent composition of the scene,\nand achieving natural outputs. To address these, we first design a\ncomprehensive data pipeline to construct prompt-reference-video triplets for\nmodel training. Next, we propose a novel image-text joint embedding model to\ninject multi-element representations into the generative process, balancing\nelement-specific consistency with global coherence and text alignment. We also\noptimize the inference pipeline for both speed and output stability. Moreover,\nwe introduce a carefully curated benchmark for systematic evaluation, i.e, A2\nBench. Experiments demonstrate that our framework can generate diverse,\nhigh-quality videos with precise element control. SkyReels-A2 is the first\nopen-source commercial grade model for the generation of E2V, performing\nfavorably against advanced closed-source commercial models. We anticipate\nSkyReels-A2 will advance creative applications such as drama and virtual\ne-commerce, pushing the boundaries of controllable video generation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T09:50:50Z"}
{"aid":"http://arxiv.org/abs/2504.02439v1","title":"Estimating Scene Flow in Robot Surroundings with Distributed\n  Miniaturized Time-of-Flight Sensors","summary":"Tracking motions of humans or objects in the surroundings of the robot is\nessential to improve safe robot motions and reactions. In this work, we present\nan approach for scene flow estimation from low-density and noisy point clouds\nacquired from miniaturized Time of Flight (ToF) sensors distributed on the\nrobot body. The proposed method clusters points from consecutive frames and\napplies Iterative Closest Point (ICP) to estimate a dense motion flow, with\nadditional steps introduced to mitigate the impact of sensor noise and\nlow-density data points. Specifically, we employ a fitness-based classification\nto distinguish between stationary and moving points and an inlier removal\nstrategy to refine geometric correspondences. The proposed approach is\nvalidated in an experimental setup where 24 ToF are used to estimate the\nvelocity of an object moving at different controlled speeds. Experimental\nresults show that the method consistently approximates the direction of the\nmotion and its magnitude with an error which is in line with sensor noise.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-03T09:57:51Z"}
{"aid":"http://arxiv.org/abs/2504.02441v1","title":"Cognitive Memory in Large Language Models","summary":"This paper examines memory mechanisms in Large Language Models (LLMs),\nemphasizing their importance for context-rich responses, reduced\nhallucinations, and improved efficiency. It categorizes memory into sensory,\nshort-term, and long-term, with sensory memory corresponding to input prompts,\nshort-term memory processing immediate context, and long-term memory\nimplemented via external databases or structures. The text-based memory section\ncovers acquisition (selection and summarization), management (updating,\naccessing, storing, and resolving conflicts), and utilization (full-text\nsearch, SQL queries, semantic search). The KV cache-based memory section\ndiscusses selection methods (regularity-based summarization, score-based\napproaches, special token embeddings) and compression techniques (low-rank\ncompression, KV merging, multimodal compression), along with management\nstrategies like offloading and shared attention mechanisms. Parameter-based\nmemory methods (LoRA, TTT, MoE) transform memories into model parameters to\nenhance efficiency, while hidden-state-based memory approaches (chunk\nmechanisms, recurrent transformers, Mamba model) improve long-text processing\nby combining RNN hidden states with current methods. Overall, the paper offers\na comprehensive analysis of LLM memory mechanisms, highlighting their\nsignificance and future research directions.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-03T09:58:19Z"}
{"aid":"http://arxiv.org/abs/2504.02449v1","title":"Strongly regular graphs with parameters (85,14,3,2) do not exist","summary":"We investigate the second smallest unresolved feasible set of parameters of\nstrongly regular graphs, $(v,k,\\lambda,\\mu)=(85,14,3,2)$. Using the\nclassification of cubic graphs of small degree, we restrict possible local\nstructure of such a graph $G$. After that, we exhaustively enumerate possible\nneighbourhoods of a maximal $3$-clique of $G$ and check them against a variety\nof conditions, including the combinatorial ones, coming from $\\lambda=3$ and\n$\\mu=2$, as well as the linear algebra ones, utilising the Euclidean\nrepresentation of $G$. These conditions yield contradiction in all cases, and\nhence, no $\\mathrm{srg}(85,14,3,2)$ exists.","main_category":"math.CO","categories":"math.CO","published":"2025-04-03T10:13:09Z"}
{"aid":"http://arxiv.org/abs/2504.02451v1","title":"ConMo: Controllable Motion Disentanglement and Recomposition for\n  Zero-Shot Motion Transfer","summary":"The development of Text-to-Video (T2V) generation has made motion transfer\npossible, enabling the control of video motion based on existing footage.\nHowever, current methods have two limitations: 1) struggle to handle\nmulti-subjects videos, failing to transfer specific subject motion; 2) struggle\nto preserve the diversity and accuracy of motion as transferring to subjects\nwith varying shapes. To overcome these, we introduce \\textbf{ConMo}, a\nzero-shot framework that disentangle and recompose the motions of subjects and\ncamera movements. ConMo isolates individual subject and background motion cues\nfrom complex trajectories in source videos using only subject masks, and\nreassembles them for target video generation. This approach enables more\naccurate motion control across diverse subjects and improves performance in\nmulti-subject scenarios. Additionally, we propose soft guidance in the\nrecomposition stage which controls the retention of original motion to adjust\nshape constraints, aiding subject shape adaptation and semantic transformation.\nUnlike previous methods, ConMo unlocks a wide range of applications, including\nsubject size and position editing, subject removal, semantic modifications, and\ncamera motion simulation. Extensive experiments demonstrate that ConMo\nsignificantly outperforms state-of-the-art methods in motion fidelity and\nsemantic consistency. The code is available at\nhttps://github.com/Andyplus1/ConMo.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T10:15:52Z"}
{"aid":"http://arxiv.org/abs/2504.02458v1","title":"Retrieval-Augmented Purifier for Robust LLM-Empowered Recommendation","summary":"Recently, Large Language Model (LLM)-empowered recommender systems have\nrevolutionized personalized recommendation frameworks and attracted extensive\nattention. Despite the remarkable success, existing LLM-empowered RecSys have\nbeen demonstrated to be highly vulnerable to minor perturbations. To mitigate\nthe negative impact of such vulnerabilities, one potential solution is to\nemploy collaborative signals based on item-item co-occurrence to purify the\nmalicious collaborative knowledge from the user's historical interactions\ninserted by attackers. On the other hand, due to the capabilities to expand\ninsufficient internal knowledge of LLMs, Retrieval-Augmented Generation (RAG)\ntechniques provide unprecedented opportunities to enhance the robustness of\nLLM-empowered recommender systems by introducing external collaborative\nknowledge. Therefore, in this paper, we propose a novel framework (RETURN) by\nretrieving external collaborative signals to purify the poisoned user profiles\nand enhance the robustness of LLM-empowered RecSys in a plug-and-play manner.\nSpecifically, retrieval-augmented perturbation positioning is proposed to\nidentify potential perturbations within the users' historical sequences by\nretrieving external knowledge from collaborative item graphs. After that, we\nfurther retrieve the collaborative knowledge to cleanse the perturbations by\nusing either deletion or replacement strategies and introduce a robust ensemble\nrecommendation strategy to generate final robust predictions. Extensive\nexperiments on three real-world datasets demonstrate the effectiveness of the\nproposed RETURN.","main_category":"cs.IR","categories":"cs.IR,cs.AI","published":"2025-04-03T10:22:30Z"}
{"aid":"http://arxiv.org/abs/2504.02468v1","title":"Enhancing Compton telescope imaging with maximum a posteriori\n  estimation: a modified Richardson-Lucy algorithm for the Compton Spectrometer\n  and Imager","summary":"We present a modified Richardson-Lucy (RL) algorithm tailored for image\nreconstruction in MeV gamma-ray observations, focusing on its application to\nthe upcoming Compton Spectrometer and Imager (COSI) mission. Our method\naddresses key challenges in MeV gamma-ray astronomy by incorporating Bayesian\npriors for sparseness and smoothness while optimizing background components\nsimultaneously. We introduce a novel sparsity term suitable for Poisson-sampled\ndata in addition to a smoothness prior, allowing for flexible reconstruction of\nboth point sources and extended emission. The performance of the algorithm is\nevaluated using simulated three-month COSI observations of gamma-ray lines of\n$^{44}$Ti (1.157 MeV), $^{26}$Al (1.809 MeV), and positron annihilation (0.511\nMeV), respectively, representing various spatial features. Our results\ndemonstrate significant improvements over conventional RL methods, particularly\nin suppressing artificial structures in point source reconstructions and\nretaining diffuse spatial structures. This work represents an important step\ntowards establishing a robust data analysis for studying nucleosynthesis,\npositron annihilation, and other high-energy phenomena in our Galaxy.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.HE","published":"2025-04-03T10:39:16Z"}
{"aid":"http://arxiv.org/abs/2504.02477v1","title":"Multimodal Fusion and Vision-Language Models: A Survey for Robot Vision","summary":"Robot vision has greatly benefited from advancements in multimodal fusion\ntechniques and vision-language models (VLMs). We systematically review the\napplications of multimodal fusion in key robotic vision tasks, including\nsemantic scene understanding, simultaneous localization and mapping (SLAM), 3D\nobject detection, navigation and localization, and robot manipulation. We\ncompare VLMs based on large language models (LLMs) with traditional multimodal\nfusion methods, analyzing their advantages, limitations, and synergies.\nAdditionally, we conduct an in-depth analysis of commonly used datasets,\nevaluating their applicability and challenges in real-world robotic scenarios.\nFurthermore, we identify critical research challenges such as cross-modal\nalignment, efficient fusion strategies, real-time deployment, and domain\nadaptation, and propose future research directions, including self-supervised\nlearning for robust multimodal representations, transformer-based fusion\narchitectures, and scalable multimodal frameworks. Through a comprehensive\nreview, comparative analysis, and forward-looking discussion, we provide a\nvaluable reference for advancing multimodal perception and interaction in\nrobotic vision. A comprehensive list of studies in this survey is available at\nhttps://github.com/Xiaofeng-Han-Res/MF-RV.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-03T10:53:07Z"}
{"aid":"http://arxiv.org/abs/2504.02493v1","title":"On zero-divisor graph of the ring of Gaussian integers modulo $2^n$","summary":"For a commutative ring $R$, the zero-divisor graph of $R$ is a simple graph\nwith the vertex set as the set of all zero-divisors of $R$ and two distinct\nvertices $x$ and $y$ are adjacent if and only if $xy = 0$. This article\nattempts to predict the structure of the zero-divisor graph of the ring of\nGaussian integers modulo $2$ to the power $n$ and determine the size, chromatic\nnumber, clique number, independence number, and matching through associate\nclasses of divisors of $2^n$ in $\\mathbb{Z}_{2^n}[i]$. In addition, a few\ntopological indices of the corresponding zero-divisor graph, are obtained.","main_category":"math.AC","categories":"math.AC,math.CO,math.NT","published":"2025-04-03T11:15:59Z"}
{"aid":"http://arxiv.org/abs/2504.02502v1","title":"Berry-Esseen bounds for step-reinforced random walks","summary":"We study both the positively and negatively step-reinforced random walks with\nparameter $p$. For a step distribution $\\mu$ with finite second moment, the\npositively step-reinforced random walk with $p\\in [1/2,1)$ and the negatively\nstep-reinforced random walk with $p\\in (0,1)$ converge to a normal distribution\nunder suitable normalization. In this work, we obtain the rates of convergence\nto normality for both cases under the assumption that $\\mu$ has a finite third\nmoment. In the proofs, we establish a Berry-Esseen bound for general\nfunctionals of independent random variables, utilize the randomly weighted sum\nrepresentations of step-reinforced random walks, and apply special comparison\narguments to quantify the Kolmogorov distance between a mixed normal\ndistribution and its corresponding normal distribution.","main_category":"math.PR","categories":"math.PR","published":"2025-04-03T11:35:20Z"}
{"aid":"http://arxiv.org/abs/2504.02507v1","title":"ZClip: Adaptive Spike Mitigation for LLM Pre-Training","summary":"Training large language models (LLMs) presents numerous challenges, including\ngradient instability and loss spikes. These phenomena can lead to catastrophic\ndivergence, requiring costly checkpoint restoration and data batch skipping.\nTraditional gradient clipping techniques, such as constant or norm-based\nmethods, fail to address these issues effectively due to their reliance on\nfixed thresholds or heuristics, leading to inefficient learning and requiring\nfrequent manual intervention. In this work, we propose ZClip, an adaptive\ngradient clipping algorithm that dynamically adjusts the clipping threshold\nbased on statistical properties of gradient norms over time. Unlike prior\nreactive strategies, ZClip proactively adapts to training dynamics without\nmaking any prior assumptions on the scale and the temporal evolution of\ngradient norms. At its core, it leverages z-score-based anomaly detection to\nidentify and mitigate large gradient spikes, preventing malignant loss spikes\nwhile not interfering with convergence otherwise. Our code is available at:\nhttps://github.com/bluorion-com/ZClip.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-03T11:41:55Z"}
{"aid":"http://arxiv.org/abs/2504.02532v1","title":"Polynomial Bounds for the Graph Minor Structure Theorem","summary":"The Graph Minor Structure Theorem, originally proven by Robertson and Seymour\n[JCTB, 2003], asserts that there exist functions $f_1, f_2 \\colon \\mathbb{N}\n\\to \\mathbb{N}$ such that for every non-planar graph $H$ with $t := |V(H)|$,\nevery $H$-minor-free graph can be obtained via the clique-sum operation from\ngraphs which embed into surfaces where $H$ does not embed after deleting at\nmost $f_1(t)$ many vertices with up to at most $t^2-1$ many ``vortices'' which\nare of ``depth'' at most $f_2(t)$. In the proof presented by Robertson and\nSeymour the functions $f_1$ and $f_2$ are non-constructive. Kawarabayashi,\nThomas, and Wollan [arXiv, 2020] found a new proof showing that $f_1(t), f_2(t)\n\\in 2^{\\mathbf{poly}(t)}$. While believing that this bound was the best their\nmethods could achieve, Kawarabayashi, Thomas, and Wollan conjectured that $f_1$\nand $f_2$ can be improved to be polynomials.\n  In this paper we confirm their conjecture and prove that $f_1(t), f_2(t) \\in\n\\mathbf{O}(t^{2300})$. Our proofs are fully constructive and yield a\npolynomial-time algorithm that either finds $H$ as a minor in a graph $G$ or\nproduces a clique-sum decomposition for $G$ as above.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-03T12:35:45Z"}
{"aid":"http://arxiv.org/abs/2504.02533v1","title":"ARCANE: Adaptive RISC-V Cache Architecture for Near-memory Extensions","summary":"Modern data-driven applications expose limitations of von Neumann\narchitectures - extensive data movement, low throughput, and poor energy\nefficiency. Accelerators improve performance but lack flexibility and require\ndata transfers. Existing compute in- and near-memory solutions mitigate these\nissues but face usability challenges due to data placement constraints. We\npropose a novel cache architecture that doubles as a tightly-coupled\ncompute-near-memory coprocessor. Our \\riscv cache controller executes custom\ninstructions from the host CPU using vector operations dispatched to\nnear-memory vector processing units within the cache memory subsystem. This\narchitecture abstracts memory synchronization and data mapping from application\nsoftware while offering software-based \\isa extensibility. Our implementation\nshows $30\\times$ to $84\\times$ performance improvement when operating on 8-bit\ndata over the same system with a traditional cache when executing a worst-case\n32-bit CNN workload, with only $41.3\\%$ area overhead.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-03T12:36:01Z"}
{"aid":"http://arxiv.org/abs/2504.02541v1","title":"$Œõ$CDM from broken diffeomorphisms","summary":"We present a simple field theory model with reduced invariance under\ndiffeomorphisms whose energy-momentum tensor is identical to the sum of\npressureless irrotational matter and a cosmological constant. The model action\nis built from a single scalar field with a canonical kinetic term without any\npotential or Lagrange multiplier terms. The coupling to gravity is realized\nthrough a particular transverse diffeomorphism invariant volume element. The\ncorresponding sound speed is exactly zero in any background geometry and the\nmodel is dynamically identical to $\\Lambda$CDM. By restoring the full\ndiffeomorphism invariance through the introduction of Stueckelberg-like fields,\nwe obtain an equivalent local scalar-vector theory.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO","published":"2025-04-03T12:43:15Z"}
{"aid":"http://arxiv.org/abs/2504.02566v1","title":"Local Flow Estimation at the top of the Earth's Core using Physics\n  Informed Neural Networks","summary":"The Earth's main geomagnetic field arises from the constant motion of the\nfluid outer core. By assuming that the field changes are advection-dominated,\nthe fluid motion at the core surface can be related to the secular variation of\nthe geomagnetic field. The majority of existing core flow models are global,\nshowing features such as an eccentric planetary gyre, with some evidence of\nrapid regional changes. By construction, the flow defined at any location by\nsuch a model depends on all magnetic field variations across the entire\ncore-mantle boundary making it challenging to interpret local structures in the\nflow as due to specific local changes in magnetic field. Here we present an\nalternative strategy in which we construct regional flow models that rely only\non local secular changes. We use a novel technique based on machine learning\ntermed Physics-Informed Neural Networks (PINNs), in which we seek a regional\nflow model that simultaneously fits both the local magnetic field variation and\ndynamical conditions assumed satisfied by the flow. Although we present results\nusing the Tangentially Geostrophic flow constraint, we set out a modelling\nframework for which the physics constraint can be easily changed by altering a\nsingle line of code. After validating the PINN-based method on synthetic flows,\nwe apply our method to the CHAOS-8.1 geomagnetic field model, itself based on\ndata from Swarm. Constructing a global mosaic of regional flows, we reproduce\nthe planetary gyre, providing independent evidence that the strong secular\nchanges at high latitude and in equatorial regions are part of the same global\nfeature. Our models also corroborate regional changes in core flows over the\nlast decade. Furthermore, our models endorse the existence of a dynamic high\nlatitude jet, which began accelerating around 2005 but has been weakening since\n2017.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-04-03T13:27:45Z"}
{"aid":"http://arxiv.org/abs/2504.02569v1","title":"Fluorine production in He-burning regions of massive stars during cosmic\n  history","summary":"The origin of fluorine is still a debated question. AGB stars synthesise this\nelement and likely contribute significantly to its synthesis in the present-day\nUniverse. However, it is not clear whether other sources contribute, especially\nin the early Universe. We discuss variations of the surface abundances of\nfluorine coming from our massive star models and compare them with available\npresent-day observations. We compute the contribution of massive stars in\nproducing 19F over metallicities covering the whole cosmic history. We used\nmodels in the mass range of 9Msol < Mini < 300Msol at metallicities from Pop\nIII up to super-solar while accounting for the required nuclear network to\nfollow the evolution of 19F during the core H- and He-burning phases. Results\nfrom models with and without rotational mixing are presented. We find that\nrotating models predict a slight depletion of fluorine at their surface at the\nend of the MS phase. In more advanced evolutionary phases, only models with an\ninitial mass larger than 25Msol at metallicities Z > 0.014 show phases where\nthe abundance of fluorine is enhanced. This occurs when the star is a WR star\nof the WC type. WC stars can show surface abundances of fluorine ten times\nlarger than their initial abundance. However, we obtained that the winds of\nmassive stars at metallicities larger than Z=0.006 do not significantly\ncontribute to fluorine production, confirming previous findings. In contrast,\nvery metal-poor rapidly rotating massive star models may be important sources\nof fluorine through the mass expelled at the time of their SN explosion.\nObservations of WC stars at solar or super-solar metallicities may provide very\ninteresting indications on the nuclear pathways that lead to fluorine\nproduction in massive stars. The possibility of observing fluorine-rich CEMPs\nis also a way to put constrains in present models at very low metallicities.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-03T13:36:04Z"}
{"aid":"http://arxiv.org/abs/2504.02583v1","title":"Ram√≠rez's problems and fibers on well approximable set of systems of\n  affine forms","summary":"We show that badly approximable matrices are exactly those that, for any\ninhomogeneous parameter, can not be inhomogeneous approximated at every\nmonotone divergent rate, which generalizes Ram\\'irez's result (2018). We also\nestablish some metrical results of the fibers on well approximable set of\nsystems of affine forms, which gives answer to two of Ram\\'irez's problems\n(2018). Furthermore, we prove that badly approximable systems are exactly those\nthat, can not be approximated at each monotone convergent rate {\\psi}.\nMoreover, we study the topological structure of the set of approximation\nfunctions.","main_category":"math.NT","categories":"math.NT,math.CA","published":"2025-04-03T13:49:12Z"}
{"aid":"http://arxiv.org/abs/2504.02590v1","title":"LexPam: Legal Procedure Awareness-Guided Mathematical Reasoning","summary":"The legal mathematical reasoning ability of LLMs is crucial when applying\nthem to real-world scenarios, as it directly affects the credibility of the\nLLM. While existing legal LLMs can perform general judicial question answering,\ntheir legal mathematical reasoning capabilities have not been trained.\nOpen-domain reasoning models, though able to generate detailed calculation\nsteps, do not follow the reasoning logic required for legal scenarios.\nAdditionally, there is currently a lack of legal mathematical reasoning\ndatasets to help validate and enhance LLMs' reasoning abilities in legal\ncontexts. To address these issues, we propose the first Chinese legal\nMathematical Reasoning Dataset, LexNum, which includes three common legal\nmathematical reasoning scenarios: economic compensation, work injury\ncompensation, and traffic accident compensation. Based on LexNum, we tested the\nperformance of existing legal LLMs and reasoning LLMs, and introduced LexPam, a\nreinforcement learning algorithm guided by legal procedural awareness to train\nLLMs, enhancing their mathematical reasoning abilities in legal scenarios.\nExperiments on tasks in the three legal scenarios show that the performance of\nexisting legal LLMs and reasoning models in legal mathematical reasoning tasks\nis unsatisfactory. LexPam can enhance the LLM's ability in these tasks.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T13:54:53Z"}
{"aid":"http://arxiv.org/abs/2504.02618v1","title":"Variational Online Mirror Descent for Robust Learning in Schr√∂dinger\n  Bridge","summary":"Sch\\\"odinger bridge (SB) has evolved into a universal class of probabilistic\ngenerative models. In practice, however, estimated learning signals are often\nuncertain, and the reliability promised by existing methods is often based on\nspeculative optimal-case scenarios. Recent studies regarding the Sinkhorn\nalgorithm through mirror descent (MD) have gained attention, revealing\ngeometric insights into solution acquisition of the SB problems. In this paper,\nwe propose a variational online MD (OMD) framework for the SB problems, which\nprovides further stability to SB solvers. We formally prove convergence and a\nregret bound for the novel OMD formulation of SB acquisition. As a result, we\npropose a simulation-free SB algorithm called Variational Mirrored\nSchr\\\"odinger Bridge (VMSB) by utilizing the Wasserstein-Fisher-Rao geometry of\nthe Gaussian mixture parameterization for Schr\\\"odinger potentials. Based on\nthe Wasserstein gradient flow theory, the algorithm offers tractable learning\ndynamics that precisely approximate each OMD step. In experiments, we validate\nthe performance of the proposed VMSB algorithm across an extensive suite of\nbenchmarks. VMSB consistently outperforms contemporary SB solvers on a range of\nSB problems, demonstrating the robustness predicted by our theory.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-03T14:18:47Z"}
{"aid":"http://arxiv.org/abs/2504.02622v1","title":"Exploring undercurrents of learning tensions in an LLM-enhanced\n  landscape: A student-centered qualitative perspective on LLM vs Search","summary":"Large language models (LLMs) are transforming how students learn by providing\nreadily available tools that can quickly augment or complete various learning\nactivities with non-trivial performance. Similar paradigm shifts have occurred\nin the past with the introduction of search engines and Wikipedia, which\nreplaced or supplemented traditional information sources such as libraries and\nbooks. This study investigates the potential for LLMs to represent the next\nshift in learning, focusing on their role in information discovery and\nsynthesis compared to existing technologies, such as search engines. Using a\nwithin-subjects, counterbalanced design, participants learned new topics using\na search engine (Google) and an LLM (ChatGPT). Post-task follow-up interviews\nexplored students' reflections, preferences, pain points, and overall\nperceptions. We present analysis of their responses that show nuanced insights\ninto when, why, and how students prefer LLMs over search engines, offering\nimplications for educators, policymakers, and technology developers navigating\nthe evolving educational landscape.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-03T14:21:09Z"}
{"aid":"http://arxiv.org/abs/2504.02653v1","title":"Online and Offline Space-Filling Input Design for Nonlinear System\n  Identification: A Receding Horizon Control-Based Approach","summary":"The effectiveness of data-driven techniques heavily depends on the input\nsignal used to generate the estimation data. However, a significant research\ngap exists in the field of input design for nonlinear dynamic system\nidentification. In particular, existing methods largely overlook the\nminimization of the generalization error, i.e., model inaccuracies in regions\nnot covered by the estimation dataset. This work addresses this gap by\nproposing an input design method that embeds a novel optimality criterion\nwithin a receding horizon control (RHC)-based optimization framework. The\ndistance-based optimality criterion induces a space-filling design within a\nuser-defined region of interest in a surrogate model's input space, requiring\nonly minimal prior knowledge. Additionally, the method is applicable both\nonline, where model parameters are continuously updated based on process\nobservations, and offline, where a fixed model is employed. The space-filling\nperformance of the proposed strategy is evaluated on an artificial example and\ncompared to state-of-the-art methods, demonstrating superior efficiency in\nexploring process operating spaces.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-03T14:50:52Z"}
{"aid":"http://arxiv.org/abs/2504.02661v1","title":"Complete Classification of the Symmetry Group of $L_p$-Minkowski Problem\n  on the Sphere","summary":"In Convex Geometry, a core topic is the $L_p$-Minkowski problem\n  \\begin{equation}\\label{e0.1}\n  \\det(\\nabla^2h+hI)=fh^{p-1}, \\ \\ \\forall X\\in{\\mathbb{S}}^n, \\ \\ \\forall p\\in\n\\mathbb{R}\n  \\end{equation} of Monge-Amp\\`{e}re type. By the transformation\n$u(x)=h(X)\\sqrt{1+|x|^2}$ and semi-spherical projection, equation \\eqref{e0.1}\ncan be reformulated by the Monge-Amp\\`{e}re type equation\n  \\begin{equation}\\label{e0.2}\n  \\det D^2u=(1+|x|^2)^{-\\frac{p+n+1}{2}}u^{p-1}, \\ \\ \\forall\nx\\in{\\mathbb{R}}^n, \\ \\ \\forall p\\in \\mathbb{R}\n  \\end{equation} on the Euclidean space. In this paper, we will firstly\ndetermine the symmetric groups of $n$-dimensional fully nonlinear equation\n\\eqref{e0.2} without asymptotic growth assumption. After proving several key\nresolution lemmas, we thus completely classify the symmetric groups of the\n$L_p$-Minkowski problem. Our method develops the Lie theory to fully nonlinear\nPDEs in Convex Geometry.","main_category":"math.AP","categories":"math.AP,math.DG","published":"2025-04-03T14:57:14Z"}
{"aid":"http://arxiv.org/abs/2504.02688v1","title":"Handover and SINR-Aware Path Optimization in 5G-UAV mmWave Communication\n  using DRL","summary":"Path planning and optimization for unmanned aerial vehicles (UAVs)-assisted\nnext-generation wireless networks is critical for mobility management and\nensuring UAV safety and ubiquitous connectivity, especially in dense urban\nenvironments with street canyons and tall buildings. Traditional statistical\nand model-based techniques have been successfully used for path optimization in\ncommunication networks. However, when dynamic channel propagation\ncharacteristics such as line-of-sight (LOS), interference, handover, and\nsignal-to-interference and noise ratio (SINR) are included in path\noptimization, statistical and model-based path planning solutions become\nobsolete since they cannot adapt to the dynamic and time-varying wireless\nchannels, especially in the mmWave bands. In this paper, we propose a novel\nmodel-free actor-critic deep reinforcement learning (AC-DRL) framework for path\noptimization in UAV-assisted 5G mmWave wireless networks, which combines four\nimportant aspects of UAV communication: \\textit{flight time, handover,\nconnectivity and SINR}. We train an AC-RL agent that enables a UAV connected to\na gNB to determine the optimal path to a desired destination in the shortest\npossible time with minimal gNB handover, while maintaining connectivity and the\nhighest possible SINR. We train our model with data from a powerful ray tracing\ntool called Wireless InSite, which uses 3D images of the propagation\nenvironment and provides data that closely resembles the real propagation\nenvironment. The simulation results show that our system has superior\nperformance in tracking high SINR compared to other selected RL algorithms.","main_category":"cs.NI","categories":"cs.NI,cs.LG,eess.SP","published":"2025-04-03T15:28:04Z"}
{"aid":"http://arxiv.org/abs/2504.02695v1","title":"Mind the Gap? Not for SVP Hardness under ETH!","summary":"We prove new hardness results for fundamental lattice problems under the\nExponential Time Hypothesis (ETH). Building on a recent breakthrough by\nBitansky et al. [BHIRW24], who gave a polynomial-time reduction from\n$\\mathsf{3SAT}$ to the (gap) $\\mathsf{MAXLIN}$ problem-a class of CSPs with\nlinear equations over finite fields-we derive ETH-hardness for several lattice\nproblems.\n  First, we show that for any $p \\in [1, \\infty)$, there exists an explicit\nconstant $\\gamma > 1$ such that $\\mathsf{CVP}_{p,\\gamma}$ (the $\\ell_p$-norm\napproximate Closest Vector Problem) does not admit a $2^{o(n)}$-time algorithm\nunless ETH is false. Our reduction is deterministic and proceeds via a direct\nreduction from (gap) $\\mathsf{MAXLIN}$ to $\\mathsf{CVP}_{p,\\gamma}$.\n  Next, we prove a randomized ETH-hardness result for $\\mathsf{SVP}_{p,\\gamma}$\n(the $\\ell_p$-norm approximate Shortest Vector Problem) for all $p > 2$. This\nresult relies on a novel property of the integer lattice $\\mathbb{Z}^n$ in the\n$\\ell_p$ norm and a randomized reduction from $\\mathsf{CVP}_{p,\\gamma}$ to\n$\\mathsf{SVP}_{p,\\gamma'}$.\n  Finally, we improve over prior reductions from $\\mathsf{3SAT}$ to\n$\\mathsf{BDD}_{p, \\alpha}$ (the Bounded Distance Decoding problem), yielding\nbetter ETH-hardness results for $\\mathsf{BDD}_{p, \\alpha}$ for any $p \\in [1,\n\\infty)$ and $\\alpha > \\alpha_p^{\\ddagger}$, where $\\alpha_p^{\\ddagger}$ is an\nexplicit threshold depending on $p$.\n  We additionally observe that prior work implies ETH hardness for the gap\nminimum distance problem ($\\gamma$-$\\mathsf{MDP}$) in codes.","main_category":"cs.CC","categories":"cs.CC,cs.CR,cs.DS","published":"2025-04-03T15:32:32Z"}
{"aid":"http://arxiv.org/abs/2504.02696v1","title":"The Tension between Trust and Oversight in Long-term Relationships","summary":"A principal continually decides whether to approve resource allocations to an\nagent, who exerts private effort to remain eligible. The principal must perform\ncostly inspections to determine the agent's eligibility. We characterize Markov\nPerfect Equilibria and analyze the paths of trust and oversight that emerge\nfrom the dynamic interplay of effort and oversight. At high trust levels,\neffort is an intertemporal substitute to oversight, which leads to unique\ninterior effort choices and random inspections. At low trust levels, effort is\nan intertemporal complement to oversight, which may create a coordination\nproblem, leading to equilibrium multiplicity. Voluntary disclosure can mitigate\nthis coordination issue.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-03T15:32:41Z"}
{"aid":"http://arxiv.org/abs/2504.02711v1","title":"Anisotropy analysis of bamboo and tooth using 4-angle polarization\n  micro-spectroscopy","summary":"To investigate the anisotropic properties of biomaterials, two distinct\nclasses are considered: polymer-based (e.g., cellulose in plants) and\ncrystalline-based (e.g., enamel in teeth), each demonstrating distinct\nstructural and functional characteristics. Four-angle polarization (4-pol.)\nspectral mapping of sub-1 {\\mu}m bamboo slices was carried out in the mid-IR\nspectral range (2.5-20 {\\mu}m) to reveal the 3D organization of the chemical\nbonding of cellulose using the key characteristic absorption bands associated\nwith C-O-C and C-N vibrational modes. The longitudinal and transverse microtome\nslices revealed a switch between the presence and absence of dichroism in\nparenchyma cell walls and vascular bundles. The cell wall showed continuous\nalignment of the C-O-C stretching vibrational mode (8.6 {\\mu}m/1163 cm-1) down\nto the pixel resolution of ~ 4 {\\mu}m (the step size in imaging) in the\ntransverse slice; the cell wall thickness is ~ 1 {\\mu}m. Thin microtomed slices\nof a tooth were measured in transmission and reflection modes. The single-point\nreflection measurements, performed using two perpendicular orientations,\nrevealed orientational anisotropy in the enamel, which was absent in the dentin\nregion. High sub-diffraction limited lateral resolution was numerically\nvalidated using a simplified-model of a Gaussian beam reading out material\npixels with a defined orientation of absorption. It is shown that the\norientation of small ~ {\\lambda}/10 ~ 1 {\\mu}m objects can be revealed using a\nfocal spot of ~ {\\lambda}/NA ~ 20 {\\mu}m, defining the diffraction limit for\nthe objective lens with a numerical aperture NA ~ 0.5.","main_category":"physics.bio-ph","categories":"physics.bio-ph,physics.med-ph","published":"2025-04-03T15:51:43Z"}
{"aid":"http://arxiv.org/abs/2504.02713v1","title":"Web3DB: Web 3.0 RDBMS for Individual Data Ownership","summary":"This paper introduces Web3DB, a decentralized relational database management\nsystem (RDBMS) designed to align with the principles of Web 3.0, addressing\ncritical shortcomings of traditional centralized DBMS, such as data privacy,\nsecurity vulnerabilities, and single points of failure. Several similar systems\nhave been proposed, but they are not compatible with the legacy systems based\non RDBMS. Motivated by the necessity for enhanced data sovereignty and the\ndecentralization of data control, Web3DB leverages blockchain technology for\nfine-grained access control and utilizes decentralized data storage. This\nsystem leverages a novel, modular architecture that contributes to enhanced\nflexibility, scalability, and user-centric functionality. Central to the Web3DB\ninnovation is its decentralized query execution, which uses cryptographic\nsortition and blockchain verification to ensure secure and fair query\nprocessing across network nodes. The motivation for integrating relational\ndatabases within decentralized DBMS primarily stems from the need to combine\nthe robustness and ease of use of relational database structures with the\nbenefits of decentralization. This paper outlines the architecture of Web3DB,\nits practical implementation, and the system's ability to support SQL-like\noperations on relational data, manage multi-tenancy, and facilitate open data\nsharing, setting new standards for decentralized databases in the Web 3.0 era.","main_category":"cs.DB","categories":"cs.DB,cs.DC","published":"2025-04-03T15:52:39Z"}
{"aid":"http://arxiv.org/abs/2504.02730v1","title":"HQViT: Hybrid Quantum Vision Transformer for Image Classification","summary":"Transformer-based architectures have revolutionized the landscape of deep\nlearning. In computer vision domain, Vision Transformer demonstrates remarkable\nperformance on par with or even surpassing that of convolutional neural\nnetworks. However, the quadratic computational complexity of its self-attention\nmechanism poses challenges for classical computing, making model training with\nhigh-dimensional input data, e.g., images, particularly expensive. To address\nsuch limitations, we propose a Hybrid Quantum Vision Transformer (HQViT), that\nleverages the principles of quantum computing to accelerate model training\nwhile enhancing model performance. HQViT introduces whole-image processing with\namplitude encoding to better preserve global image information without\nadditional positional encoding. By leveraging quantum computation on the most\ncritical steps and selectively handling other components in a classical way, we\nlower the cost of quantum resources for HQViT. The qubit requirement is\nminimized to $O(log_2N)$ and the number of parameterized quantum gates is only\n$O(log_2d)$, making it well-suited for Noisy Intermediate-Scale Quantum\ndevices. By offloading the computationally intensive attention coefficient\nmatrix calculation to the quantum framework, HQViT reduces the classical\ncomputational load by $O(T^2d)$. Extensive experiments across various computer\nvision datasets demonstrate that HQViT outperforms existing models, achieving a\nmaximum improvement of up to $10.9\\%$ (on the MNIST 10-classification task)\nover the state of the art. This work highlights the great potential to combine\nquantum and classical computing to cope with complex image classification\ntasks.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-03T16:13:34Z"}
{"aid":"http://arxiv.org/abs/2504.02736v1","title":"Parity violation as enforced symmetry breaking in 3D fermionic\n  topological order","summary":"Symmetry can be intrinsically broken in topological phases due to inherent\nincompatibilities, a phenomenon known as enforced symmetry breaking (ESB) in\nthe framework of topological order. In our previous work, we developed a\nsystematic framework to understand ESB within 2D invertible topological order.\nMeanwhile, the origin of parity violation in the Standard Model remains one of\nthe most profound mysteries in physics, with no clear explanation to date. In\nthis study, we explore the ESB of parity symmetry by three-dimensional\nfermionic topological order (fTO), offering potential insights into the origins\nof parity violation. As the simplest example, here we consider an fTO related\nto the intrinsic interacting fermionic SPT phase protected by $Z_2^f\\times\nZ_2\\times Z_8$ symmetry in three dimensions. We show that time-reversal\nsymmetry (TRS) with ${T}^2=1$ on physical fermions is incompatible with such\nfTO; then, through the so-called crystalline equivalence principle, we show\nthat the parity symmetry is also incompatible with it. In comparison,\nconventional TRS with ${T}^2={P}_f$ remains compatible to this fTO. We also\ndiscuss a general framework to study the ESB phenomenon for 3D fTO.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.supr-con,hep-ph,hep-th","published":"2025-04-03T16:23:36Z"}
{"aid":"http://arxiv.org/abs/2504.02738v1","title":"Inequivalence of the low-density insulating state and quantum Hall\n  insulating states in a strongly correlated two-dimensional electron system","summary":"We find that the behaviors of the voltage-current characteristics as one\nenters the low-density insulating state and integer quantum Hall insulating\nstates in the ultra-clean two-dimensional electron system in SiGe/Si/SiGe\nquantum wells are qualitatively different. The double-threshold voltage-current\ncurves, representative of electron solid formation at low densities, are not\nobserved in the quantum Hall regime, which does not confirm the existence of a\nquasi-particle quantum Hall Wigner solid and indicates that quasi-particles\nnear integer filling do not form an independent subsystem.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mes-hall","published":"2025-04-03T16:24:54Z"}
{"aid":"http://arxiv.org/abs/2504.02744v1","title":"The Ordering Principle and Dependent Choice","summary":"We introduce finite support iterations of symmetric systems, and use them to\nprovide a strongly modernized proof of David Pincus' classical result that the\naxiom of dependent choice is independent over ZF with the ordering principle\ntogether with a failure of the axiom of choice.","main_category":"math.LO","categories":"math.LO","published":"2025-04-03T16:31:05Z"}
{"aid":"http://arxiv.org/abs/2504.02765v1","title":"Robot-Led Vision Language Model Wellbeing Assessment of Children","summary":"This study presents a novel robot-led approach to assessing children's mental\nwellbeing using a Vision Language Model (VLM). Inspired by the Child\nApperception Test (CAT), the social robot NAO presented children with pictorial\nstimuli to elicit their verbal narratives of the images, which were then\nevaluated by a VLM in accordance with CAT assessment guidelines. The VLM's\nassessments were systematically compared to those provided by a trained\npsychologist. The results reveal that while the VLM demonstrates moderate\nreliability in identifying cases with no wellbeing concerns, its ability to\naccurately classify assessments with clinical concern remains limited.\nMoreover, although the model's performance was generally consistent when\nprompted with varying demographic factors such as age and gender, a\nsignificantly higher false positive rate was observed for girls, indicating\npotential sensitivity to gender attribute. These findings highlight both the\npromise and the challenges of integrating VLMs into robot-led assessments of\nchildren's wellbeing.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-03T17:02:09Z"}
{"aid":"http://arxiv.org/abs/2504.02770v1","title":"Efficient Algorithms for Cardinality Estimation and Conjunctive Query\n  Evaluation With Simple Degree Constraints","summary":"Cardinality estimation and conjunctive query evaluation are two of the most\nfundamental problems in database query processing. Recent work proposed,\nstudied, and implemented a robust and practical information-theoretic\ncardinality estimation framework. In this framework, the estimator is the\ncardinality upper bound of a conjunctive query subject to\n``degree-constraints'', which model a rich set of input data statistics. For\ngeneral degree constraints, computing this bound is computationally hard.\nResearchers have naturally sought efficiently computable relaxed upper bounds\nthat are as tight as possible. The polymatroid bound is the tightest among\nthose relaxed upper bounds. While it is an open question whether the\npolymatroid bound can be computed in polynomial-time in general, it is known to\nbe computable in polynomial-time for some classes of degree constraints.\n  Our focus is on a common class of degree constraints called simple degree\nconstraints. Researchers had not previously determined how to compute the\npolymatroid bound in polynomial time for this class of constraints. Our first\nmain result is a polynomial time algorithm to compute the polymatroid bound\ngiven simple degree constraints. Our second main result is a polynomial-time\nalgorithm to compute a ``proof sequence'' establishing this bound. This proof\nsequence can then be incorporated in the PANDA-framework to give a faster\nalgorithm to evaluate a conjunctive query. In addition, we show computational\nlimitations to extending our results to broader classes of degree constraints.\nFinally, our technique leads naturally to a new relaxed upper bound called the\n{\\em flow bound}, which is computationally tractable.","main_category":"cs.DB","categories":"cs.DB,cs.DS","published":"2025-04-03T17:06:39Z"}
{"aid":"http://arxiv.org/abs/2504.02774v1","title":"Component-wise Krasnosel'skii type fixed point theorem in product spaces\n  and applications","summary":"We present a version of Krasnosel'skii fixed point theorem for operators\nacting on Cartesian products of normed linear spaces, under cone-compression\nand cone-expansion conditions of norm type. Our approach, based on the fixed\npoint index theory in cones, guarantees the existence of a coexistence fixed\npoint - that is, one with nontrivial components. As an application, we prove\nthe existence of periodic solutions with strictly positive components for a\nsystem of second-order differential equations. In particular, we address cases\ninvolving singular nonlinearities and hybrid terms, characterized by sublinear\nbehavior in one component and superlinear behavior in the other.","main_category":"math.FA","categories":"math.FA,math.CA","published":"2025-04-03T17:14:48Z"}
{"aid":"http://arxiv.org/abs/2504.02790v1","title":"Dynamic Treewidth in Logarithmic Time","summary":"We present a dynamic data structure that maintains a tree decomposition of\nwidth at most $9k+8$ of a dynamic graph with treewidth at most $k$, which is\nupdated by edge insertions and deletions. The amortized update time of our data\nstructure is $2^{O(k)} \\log n$, where $n$ is the number of vertices. The data\nstructure also supports maintaining any ``dynamic programming scheme'' on the\ntree decomposition, providing, for example, a dynamic version of Courcelle's\ntheorem with $O_{k}(\\log n)$ amortized update time; the $O_{k}(\\cdot)$ notation\nhides factors that depend on $k$. This improves upon a result of Korhonen,\nMajewski, Nadara, Pilipczuk, and Soko{\\l}owski [FOCS 2023], who gave a similar\ndata structure but with amortized update time $2^{k^{O(1)}} n^{o(1)}$.\nFurthermore, our data structure is arguably simpler.\n  Our main novel idea is to maintain a tree decomposition that is ``downwards\nwell-linked'', which allows us to implement local rotations and analysis\nsimilar to those for splay trees.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-03T17:37:46Z"}
{"aid":"http://arxiv.org/abs/2504.02793v1","title":"A Framework for Situating Innovations, Opportunities, and Challenges in\n  Advancing Vertical Systems with Large AI Models","summary":"Large artificial intelligence (AI) models have garnered significant attention\nfor their remarkable, often \"superhuman\", performance on standardized\nbenchmarks. However, when these models are deployed in high-stakes verticals\nsuch as healthcare, education, and law, they often reveal notable limitations.\nFor instance, they exhibit brittleness to minor variations in input data,\npresent contextually uninformed decisions in critical settings, and undermine\nuser trust by confidently producing or reproducing inaccuracies. These\nchallenges in applying large models necessitate cross-disciplinary innovations\nto align the models' capabilities with the needs of real-world applications. We\nintroduce a framework that addresses this gap through a layer-wise abstraction\nof innovations aimed at meeting users' requirements with large models. Through\nmultiple case studies, we illustrate how researchers and practitioners across\nvarious fields can operationalize this framework. Beyond modularizing the\npipeline of transforming large models into useful \"vertical systems\", we also\nhighlight the dynamism that exists within different layers of the framework.\nFinally, we discuss how our framework can guide researchers and practitioners\nto (i) optimally situate their innovations (e.g., when vertical-specific\ninsights can empower broadly impactful vertical-agnostic innovations), (ii)\nuncover overlooked opportunities (e.g., spotting recurring problems across\nverticals to develop practically useful foundation models instead of chasing\nbenchmarks), and (iii) facilitate cross-disciplinary communication of critical\nchallenges (e.g., enabling a shared vocabulary for AI developers, domain\nexperts, and human-computer interaction scholars).","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.CY,cs.HC","published":"2025-04-03T17:40:11Z"}
{"aid":"http://arxiv.org/abs/2504.02794v1","title":"MENA: Multimodal Epistemic Network Analysis for Visualizing Competencies\n  and Emotions","summary":"The need to improve geriatric care quality presents a challenge that requires\ninsights from stakeholders. While simulated trainings can boost competencies,\nextracting meaningful insights from these practices to enhance simulation\neffectiveness remains a challenge. In this study, we introduce Multimodal\nEpistemic Network Analysis (MENA), a novel framework for analyzing caregiver\nattitudes and emotions in an Augmented Reality setting and exploring how the\nawareness of a virtual geriatric patient (VGP) impacts these aspects. MENA\nenhances the capabilities of Epistemic Network Analysis by detecting positive\nemotions, enabling visualization and analysis of complex relationships between\ncaregiving competencies and emotions in dynamic caregiving practices. The\nframework provides visual representations that demonstrate how participants\nprovided more supportive care and engaged more effectively in person-centered\ncaregiving with aware VGP. This method could be applicable in any setting that\ndepends on dynamic interpersonal interactions, as it visualizes connections\nbetween key elements using network graphs and enables the direct comparison of\nmultiple networks, thereby broadening its implications across various fields.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-03T17:40:49Z"}
{"aid":"http://arxiv.org/abs/2504.02795v1","title":"Greedy Regular Convolutions","summary":"We introduce a class of convolutions on arithmetical functions that are\nregular in the sense of of Narkiewicz, homogeneous in the sense of Burnett et\nal, and bounded, in the sense that there exists a common finite bound for the\nrank of primitive numbers. Among these \"greedy convolutions\" the unitary\nconvolution and the \"ternary convolution\" are particularly interesting: they\nare the only regular, homogeneous convolutions where each primitive number have\nthe same finite rank. While the greedy convolution of length 3, also described\nin detail, has primitive numbers of rank 3 and rank 1, it is still special in\nthat the set of primitives can be generated by a simple recursive procedure\nthat we name selective sifting.","main_category":"math.NT","categories":"math.NT","published":"2025-04-03T17:41:11Z"}
{"aid":"http://arxiv.org/abs/2504.02811v1","title":"An Assessment of the CO2 Emission Reduction Potential of Residential\n  Load Management in Developing and Developed Countries","summary":"Intermittent renewable energies are increasingly dominating electricity grids\nand are forecasted to be the main force driving out fossil fuels from the grid\nin most major economies until 2040. However, grids based on intermittent\nrenewables are challenged by diurnal and seasonal mismatch between supply of\nsun and wind and demand for electricity, including for heat pumps and electric\ntwo and four wheelers. Load management and demand response measures promise to\nadjust for this mismatch, utilizing information- and price-based approaches to\nsteer demand towards times with high supply of intermittent renewables. Here,\nwe systematically review the literature estimating CO2 savings from residential\nload management in developing and developed nations. We find that load\nmanagement holds high potential, locally differentiated with energy mix\n(including the respective share of renewables and fossils), climate zone, and\nthe regulatory environment and price mechanism. Most identified studies suggest\na mitigation potential between 1 and 20%. Load management becomes more relevant\nwith higher shares of intermittent renewables, and when electricity prices are\nhigh. Importantly, load management aligns consumers' financial incentives with\nclimate change mitigation, thus rendering accompanying strategies politically\nfeasible. We summarize key regulatory steps to facilitate load management in\neconomies and to realize relevant consumer surplus and mitigation potential.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-03T17:55:12Z"}
{"aid":"http://arxiv.org/abs/2504.02814v1","title":"Convergence of the Markovian iteration for coupled FBSDEs via a\n  differentiation approach","summary":"In this paper, we investigate the Markovian iteration method for solving\ncoupled forward-backward stochastic differential equations (FBSDEs) featuring a\nfully coupled forward drift, meaning the drift term explicitly depends on both\nthe forward and backward processes. An FBSDE system typically involves three\nstochastic processes: the forward process $X$, the backward process $Y$\nrepresenting the solution, and the $Z$ process corresponding to the scaled\nderivative of $Y$. Prior research by Bender and Zhang (2008) has established\nconvergence results for iterative schemes dealing with $Y$-coupled FBSDEs.\nHowever, extending these results to equations with $Z$ coupling poses\nsignificant challenges, especially in uniformly controlling the Lipschitz\nconstant of the decoupling fields across iterations and time steps within a\nfixed-point framework.\n  To overcome this issue, we propose a novel differentiation-based method for\nhandling the $Z$ process. This approach enables improved management of the\nLipschitz continuity of decoupling fields, facilitating the well-posedness of\nthe discretized FBSDE system with fully coupled drift. We rigorously prove the\nconvergence of our Markovian iteration method in this more complex setting.\nFinally, numerical experiments confirm our theoretical insights, showcasing the\neffectiveness and accuracy of the proposed methodology.","main_category":"math.NA","categories":"math.NA,cs.NA,math.PR,q-fin.CP","published":"2025-04-03T17:56:36Z"}
{"aid":"http://arxiv.org/abs/2504.02826v1","title":"Envisioning Beyond the Pixels: Benchmarking Reasoning-Informed Visual\n  Editing","summary":"Large Multi-modality Models (LMMs) have made significant progress in visual\nunderstanding and generation, but they still face challenges in General Visual\nEditing, particularly in following complex instructions, preserving appearance\nconsistency, and supporting flexible input formats. To address this gap, we\nintroduce RISEBench, the first benchmark for evaluating Reasoning-Informed\nviSual Editing (RISE). RISEBench focuses on four key reasoning types: Temporal,\nCausal, Spatial, and Logical Reasoning. We curate high-quality test cases for\neach category and propose an evaluation framework that assesses Instruction\nReasoning, Appearance Consistency, and Visual Plausibility with both human\njudges and an LMM-as-a-judge approach. Our experiments reveal that while\nGPT-4o-Native significantly outperforms other open-source and proprietary\nmodels, even this state-of-the-art system struggles with logical reasoning\ntasks, highlighting an area that remains underexplored. As an initial effort,\nRISEBench aims to provide foundational insights into reasoning-aware visual\nediting and to catalyze future research. Though still in its early stages, we\nare committed to continuously expanding and refining the benchmark to support\nmore comprehensive, reliable, and scalable evaluations of next-generation\nmultimodal systems. Our code and data will be released at\nhttps://github.com/PhoenixZ810/RISEBench.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T17:59:56Z"}
{"aid":"http://arxiv.org/abs/2504.04726v1","title":"Can LLM-Driven Hard Negative Sampling Empower Collaborative Filtering?\n  Findings and Potentials","summary":"Hard negative samples can accelerate model convergence and optimize decision\nboundaries, which is key to improving the performance of recommender systems.\nAlthough large language models (LLMs) possess strong semantic understanding and\ngeneration capabilities, systematic research has not yet been conducted on how\nto generate hard negative samples effectively. To fill this gap, this paper\nintroduces the concept of Semantic Negative Sampling and exploreshow to\noptimize LLMs for high-quality, hard negative sampling. Specifically, we design\nan experimental pipeline that includes three main modules, profile generation,\nsemantic negative sampling, and semantic alignment, to verify the potential of\nLLM-driven hard negative sampling in enhancing the accuracy of collaborative\nfiltering (CF). Experimental results indicate that hard negative samples\ngenerated based on LLMs, when semantically aligned and integrated into CF, can\nsignificantly improve CF performance, although there is still a certain gap\ncompared to traditional negative sampling methods. Further analysis reveals\nthat this gap primarily arises from two major challenges: noisy samples and\nlack of behavioral constraints. To address these challenges, we propose a\nframework called HNLMRec, based on fine-tuning LLMs supervised by collaborative\nsignals. Experimental results show that this framework outperforms traditional\nnegative sampling and other LLM-driven recommendation methods across multiple\ndatasets, providing new solutions for empowering traditional RS with LLMs.\nAdditionally, we validate the excellent generalization ability of the LLM-based\nsemantic negative sampling method on new datasets, demonstrating its potential\nin alleviating issues such as data sparsity, popularity bias, and the problem\nof false hard negative samples. Our implementation code is available at\nhttps://github.com/user683/HNLMRec.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-07T04:39:45Z"}
{"aid":"http://arxiv.org/abs/2504.04737v1","title":"TathyaNyaya and FactLegalLlama: Advancing Factual Judgment Prediction\n  and Explanation in the Indian Legal Context","summary":"In the landscape of Fact-based Judgment Prediction and Explanation (FJPE),\nreliance on factual data is essential for developing robust and realistic\nAI-driven decision-making tools. This paper introduces TathyaNyaya, the largest\nannotated dataset for FJPE tailored to the Indian legal context, encompassing\njudgments from the Supreme Court of India and various High Courts. Derived from\nthe Hindi terms \"Tathya\" (fact) and \"Nyaya\" (justice), the TathyaNyaya dataset\nis uniquely designed to focus on factual statements rather than complete legal\ntexts, reflecting real-world judicial processes where factual data drives\noutcomes. Complementing this dataset, we present FactLegalLlama, an\ninstruction-tuned variant of the LLaMa-3-8B Large Language Model (LLM),\noptimized for generating high-quality explanations in FJPE tasks. Finetuned on\nthe factual data in TathyaNyaya, FactLegalLlama integrates predictive accuracy\nwith coherent, contextually relevant explanations, addressing the critical need\nfor transparency and interpretability in AI-assisted legal systems. Our\nmethodology combines transformers for binary judgment prediction with\nFactLegalLlama for explanation generation, creating a robust framework for\nadvancing FJPE in the Indian legal domain. TathyaNyaya not only surpasses\nexisting datasets in scale and diversity but also establishes a benchmark for\nbuilding explainable AI systems in legal analysis. The findings underscore the\nimportance of factual precision and domain-specific tuning in enhancing\npredictive performance and interpretability, positioning TathyaNyaya and\nFactLegalLlama as foundational resources for AI-assisted legal decision-making.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.IR,cs.LG","published":"2025-04-07T05:27:32Z"}
{"aid":"http://arxiv.org/abs/2504.04740v1","title":"Enhancing Compositional Reasoning in Vision-Language Models with\n  Synthetic Preference Data","summary":"Compositionality, or correctly recognizing scenes as compositions of atomic\nvisual concepts, remains difficult for multimodal large language models\n(MLLMs). Even state of the art MLLMs such as GPT-4o can make mistakes in\ndistinguishing compositions like \"dog chasing cat\" vs \"cat chasing dog\". While\non Winoground, a benchmark for measuring such reasoning, MLLMs have made\nsignificant progress, they are still far from a human's performance. We show\nthat compositional reasoning in these models can be improved by elucidating\nsuch concepts via data, where a model is trained to prefer the correct caption\nfor an image over a close but incorrect one. We introduce SCRAMBLe: Synthetic\nCompositional Reasoning Augmentation of MLLMs with Binary preference Learning,\nan approach for preference tuning open-weight MLLMs on synthetic preference\ndata generated in a fully automated manner from existing image-caption data.\nSCRAMBLe holistically improves these MLLMs' compositional reasoning\ncapabilities which we can see through significant improvements across multiple\nvision language compositionality benchmarks, as well as smaller but significant\nimprovements on general question answering tasks. As a sneak peek, SCRAMBLe\ntuned Molmo-7B model improves on Winoground from 49.5% to 54.8% (best reported\nto date), while improving by ~1% on more general visual question answering\ntasks. Code for SCRAMBLe along with tuned models and our synthetic training\ndataset is available at https://github.com/samarth4149/SCRAMBLe.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T05:35:34Z"}
{"aid":"http://arxiv.org/abs/2504.04743v1","title":"AnyArtisticGlyph: Multilingual Controllable Artistic Glyph Generation","summary":"Artistic Glyph Image Generation (AGIG) differs from current\ncreativity-focused generation models by offering finely controllable\ndeterministic generation. It transfers the style of a reference image to a\nsource while preserving its content. Although advanced and promising, current\nmethods may reveal flaws when scrutinizing synthesized image details, often\nproducing blurred or incorrect textures, posing a significant challenge. Hence,\nwe introduce AnyArtisticGlyph, a diffusion-based, multilingual controllable\nartistic glyph generation model. It includes a font fusion and embedding\nmodule, which generates latent features for detailed structure creation, and a\nvision-text fusion and embedding module that uses the CLIP model to encode\nreferences and blends them with transformation caption embeddings for seamless\nglobal image generation. Moreover, we incorporate a coarse-grained\nfeature-level loss to enhance generation accuracy. Experiments show that it\nproduces natural, detailed artistic glyph images with state-of-the-art\nperformance. Our project will be open-sourced on\nhttps://github.com/jiean001/AnyArtisticGlyph to advance text generation\ntechnology.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T05:37:39Z"}
{"aid":"http://arxiv.org/abs/2504.04761v1","title":"WLPCM Approach for Great Lakes Regulation","summary":"This study develops a water-level management model for the Great Lakes using\na predictive control framework. Requirement 1: Historical data (pre-2019)\nrevealed consistent monthly water-level patterns. A simulated annealing\nalgorithm optimized flow control via the Moses-Saunders Dam and Compensating\nWorks to align levels with multi-year benchmarks. Requirement 2: A Water Level\nPredictive Control Model (WLPCM) integrated delayed differential equations\n(DDEs) and model predictive control (MPC) to account for inflow/outflow\ndynamics and upstream time lags. Natural variables (e.g., precipitation) were\nmodeled via linear regression, while dam flow rates were optimized over 6-month\nhorizons with feedback adjustments for robustness. Requirement 3: Testing WLPCM\non 2017 data successfully mitigated Ottawa River flooding, outperforming\nhistorical records. Sensitivity analysis via the Sobol method confirmed model\nresilience to parameter variations. Requirement 4: Ice-clogging was identified\nas the most impactful natural variable (via RMSE-based sensitivity tests),\nfollowed by snowpack and precipitation. Requirement 5: Stakeholder demands\n(e.g., flood prevention, ecological balance) were incorporated into a fitness\nfunction. Compared to Plan 2014, WLPCM reduced catastrophic high levels in Lake\nOntario and excessive St. Lawrence River flows by prioritizing long-term\noptimization. Key innovations include DDE-based predictive regulation,\nreal-time feedback loops, and adaptive control under extreme conditions. The\nframework balances hydrological dynamics, stakeholder needs, and uncertainty\nmanagement, offering a scalable solution for large freshwater systems.","main_category":"math.OC","categories":"math.OC","published":"2025-04-07T06:21:22Z"}
{"aid":"http://arxiv.org/abs/2504.04767v1","title":"Extended URDF: Accounting for parallel mechanism in robot description","summary":"Robotic designs played an important role in recent advances by providing\npowerful robots with complex mechanics. Many recent systems rely on parallel\nactuation to provide lighter limbs and allow more complex motion. However,\nthese emerging architectures fall outside the scope of most used description\nformats, leading to difficulties when designing, storing, and sharing the\nmodels of these systems. This paper introduces an extension to the widely used\nUnified Robot Description Format (URDF) to support closed-loop kinematic\nstructures. Our approach relies on augmenting URDF with minimal additional\ninformation to allow more efficient modeling of complex robotic systems while\nmaintaining compatibility with existing design and simulation frameworks. This\nmethod sets the basic requirement for a description format to handle parallel\nmechanisms efficiently. We demonstrate the applicability of our approach by\nproviding an open-source collection of parallel robots, along with tools for\ngenerating and parsing this extended description format. The proposed extension\nsimplifies robot modeling, reduces redundancy, and improves usability for\nadvanced robotic applications.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T06:42:27Z"}
{"aid":"http://arxiv.org/abs/2504.04769v1","title":"Scalable simulation of random quantum circuits using projected\n  entangled-pair states","summary":"Classical simulation of a programmable quantum processor is crucial in\nidentifying the threshold of a quantum advantage. We use the simple update of\nprojected entangled-pair states (PEPSs) in the Vidal gauge to simulate the\nstates of random quantum circuits (RQCs), which center around recent quantum\nadvantage claims. Applied to square lattices of qubits akin to state-of-the-art\nsuperconducting processors, our PEPS simulation is exact for circuit depths\nless than $D_\\mathrm{tr}$ = $\\beta\\log_2\\chi$, where $\\chi$ is the maximum bond\ndimension and $2 \\lesssim \\beta \\lesssim 4$ depends on the choice of two-qubit\ngates, independent of the qubit number $n$. We find the universal scaling\nbehaviors of the state fidelity by performing large-scale simulations for $n\n\\leq 10^{4}$ or $\\chi \\leq 128$ on a conventional CPU. Our method has\ncomputational cost scaling polynomially with $n$ for circuit depth $D =O(\\log\nn)$ and is more advantageous than matrix product state (MPS) approaches if $n$\nis large. This work underscores PEPSs as a scalable tool for benchmarking\nquantum algorithms, with future potential for sampling applications using\nadvanced contraction techniques.","main_category":"quant-ph","categories":"quant-ph,physics.comp-ph","published":"2025-04-07T06:47:48Z"}
{"aid":"http://arxiv.org/abs/2504.04776v1","title":"Drastic softening of Pd nanoparticles induced by hydrogen cycling","summary":"Single crystalline faceted Pd nanoparticles attached to a sapphire substrate\nwere fabricated employing the solid state dewetting method. The as-dewetted\nnanoparticles tested in compression exhibited all features of dislocation\nnucleation-controlled plasticity, including the size effect on strength and\nultrahigh compressive strength reaching up to 11 GPa. Hydrogen cycling of\nas-dewetted Pd nanoparticles resulted in their drastic softening and in change\nof the deformation mode. This softening effect was correlated with the high\ndensity of glissile dislocations observed in the cycled particles. This work\ndemonstrates that the nanomechanical behavior of hydride-forming metals can be\nmanipulated by hydrogen cycling.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-07T07:09:10Z"}
{"aid":"http://arxiv.org/abs/2504.04779v1","title":"Black hole destabilization via trapped quasi-normal modes","summary":"In the presence of non-minimal gravitational couplings, matter field\nperturbations on a static black hole spacetime may develop unphysical poles in\ntheir linearized equations. Physical solutions confined in the domain between\nthe event horizon and a pole satisfy a boundary value problem, although with\nboundary conditions which are different from standard quasi-normal modes. We\nrefer to them as \"trapped quasi-normal modes\". Focusing on a Schwarzschild\nblack hole in Einstein-Proca theory, we find that trapped quasi-normal modes\naccurately capture the behavior of perturbations under time evolution. In\nparticular, axial-vector modes are unstable, with a growth rate that increases\nwith multipole number. More interestingly, we uncover a new instability that\naffects monopole perturbations. These results confirm the existence of a novel\ndestabilization mechanism of black holes by non-minimally coupled vector\nfields, with potential implications to well-studied models of modified gravity\nand cosmology based on vector particles.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-07T07:14:36Z"}
{"aid":"http://arxiv.org/abs/2504.04786v1","title":"Dynamic fabrication method of SNAP microresonators","summary":"Surface Nanoscale Axial Photonics (SNAP) technology has demonstrated the\nrecord subangstrom fabrication precision of optical microresonators and\nresonant photonic circuits at the optical fiber surface. However, fabrication\nerrors arising from fluctuations of temperature, inscription parameters,\nalignment inconsistencies, and other factors did not allow researchers to\nachieve the subangstrom precision without sophisticated postprocessing. Here we\nshow that the key fabrication method of SNAP structures -- CO$_2$ laser beam\noptical fiber annealing -- suffers from significant fiber displacements which\nmay introduce a few percent fabrication errors. To suppress the effects of\nmisalignment, we develop a dynamic fabrication method employing a translating\nbeam exposure and demonstrate its excellent precision. The effective fiber\nradius variation of $\\sim 10 $nm is introduced with an error of $\\sim 0.1\n$angstrom. We suggest that the remaining fabrication errors can be attributed\nto laser power fluctuations.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-07T07:31:13Z"}
{"aid":"http://arxiv.org/abs/2504.04787v1","title":"Dynamic Vision Mamba","summary":"Mamba-based vision models have gained extensive attention as a result of\nbeing computationally more efficient than attention-based models. However,\nspatial redundancy still exists in these models, represented by token and block\nredundancy. For token redundancy, we analytically find that early token pruning\nmethods will result in inconsistency between training and inference or\nintroduce extra computation for inference. Therefore, we customize token\npruning to fit the Mamba structure by rearranging the pruned sequence before\nfeeding it into the next Mamba block. For block redundancy, we allow each image\nto select SSM blocks dynamically based on an empirical observation that the\ninference speed of Mamba-based vision models is largely affected by the number\nof SSM blocks. Our proposed method, Dynamic Vision Mamba (DyVM), effectively\nreduces FLOPs with minor performance drops. We achieve a reduction of 35.2\\%\nFLOPs with only a loss of accuracy of 1.7\\% on Vim-S. It also generalizes well\nacross different Mamba vision model architectures and different vision tasks.\nOur code will be made public.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T07:31:28Z"}
{"aid":"http://arxiv.org/abs/2504.04813v1","title":"Generalized Fermi-Dirac Distribution of Exclusive Fermions","summary":"A system of exclusive fermions occurs when two fermions of opposite spin are\nprohibited from occupying the same quantum level. We derive the distribution of\nexclusive fermions via the employment of the grand canonical ensemble. Salient\nfeatures of its statistical properties, compared to the free electron gases,\ninclude: larger Fermi energy, higher degeneracy pressure, but the same Pauli\nparamagnetism and Landau diamagnetism. In particular, higher degeneracy\npressure leads to an inflation of the Chandrasekhar limit to 1.6 times when\napplied to white dwarf stars and neutron stars.","main_category":"math-ph","categories":"math-ph,astro-ph.SR,cond-mat.stat-mech,math.MP","published":"2025-04-07T08:08:57Z"}
{"aid":"http://arxiv.org/abs/2504.04842v1","title":"FantasyTalking: Realistic Talking Portrait Generation via Coherent\n  Motion Synthesis","summary":"Creating a realistic animatable avatar from a single static portrait remains\nchallenging. Existing approaches often struggle to capture subtle facial\nexpressions, the associated global body movements, and the dynamic background.\nTo address these limitations, we propose a novel framework that leverages a\npretrained video diffusion transformer model to generate high-fidelity,\ncoherent talking portraits with controllable motion dynamics. At the core of\nour work is a dual-stage audio-visual alignment strategy. In the first stage,\nwe employ a clip-level training scheme to establish coherent global motion by\naligning audio-driven dynamics across the entire scene, including the reference\nportrait, contextual objects, and background. In the second stage, we refine\nlip movements at the frame level using a lip-tracing mask, ensuring precise\nsynchronization with audio signals. To preserve identity without compromising\nmotion flexibility, we replace the commonly used reference network with a\nfacial-focused cross-attention module that effectively maintains facial\nconsistency throughout the video. Furthermore, we integrate a motion intensity\nmodulation module that explicitly controls expression and body motion\nintensity, enabling controllable manipulation of portrait movements beyond mere\nlip motion. Extensive experimental results show that our proposed approach\nachieves higher quality with better realism, coherence, motion intensity, and\nidentity preservation. Ours project page:\nhttps://fantasy-amap.github.io/fantasy-talking/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T08:56:01Z"}
{"aid":"http://arxiv.org/abs/2504.04853v1","title":"Charmonium-nucleon femtoscopic correlation function","summary":"This study investigates the femtoscopic correlation functions of\ncharmonium-nucleon pairs, utilizing the lattice QCD phase shifts provided by\nthe HAL QCD Collaboration. A model-independent formalism is employed to\ntransform scattering phase shifts directly into momentum correlation functions,\nthereby circumventing the approximations inherent in traditional methods, such\nas the Lednick\\'y-Lyuboshits model. The $J/\\psi$-$p$ correlation functions,\nincluding spin-averaged and partial-wave results, are predicted using\nnear-physical pion mass lattice results. The $\\eta_c$-$p$ correlation function\nis calculated for the first time. The derived correlation functions provide\ncritical references for future experiments, such as those at the LHC, where\nhigh-precision measurements of charmonium-nucleon correlations could unveil\nvaluable insights into non-perturbative QCD dynamics.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-07T09:10:58Z"}
{"aid":"http://arxiv.org/abs/2504.04860v1","title":"Stochastic differential equations driven by fractional Brownian motion:\n  dependence on the Hurst parameter","summary":"Stochastic models with fractional Brownian motion as source of randomness\nhave become popular since the early 2000s. Fractional Brownian motion (fBm) is\na Gaussian process, whose covariance depends on the so-called Hurst parameter\n$H\\in (0,1)$. Consequently, stochastic models with fBm also depend on the Hurst\nparameter $H$, and the stability of these models with respect to $H$ is an\ninteresting and important question. In recent years, the continuous (or even\nsmoother) dependence on the Hurst parameter has been studied for several\nstochastic models, including stochastic integrals with respect to fBm,\nstochastic differential equations (SDEs) driven by fBm and also stochastic\npartial differential equations with fractional noise, for different topologies,\ne.g., in law or almost surely, and for finite and infinite time horizons. In\nthis manuscript, we give an overview of these results with a particular focus\non SDE models.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T09:17:59Z"}
{"aid":"http://arxiv.org/abs/2504.04923v1","title":"Truncated sequential guaranteed estimation for the Cox-Ingersoll-Ross\n  models","summary":"The drift sequential parameter estimation problems for the Cox-Ingersoll-Ross\n(CIR) processes under the limited duration of observation are studied.\nTruncated sequential estimation methods for both scalar and {two}-dimensional\nparameter cases are proposed. In the non-asymptotic setting, for the proposed\ntruncated estimators, the properties of guaranteed mean-square estimation\naccuracy are established. In the asymptotic formulation, when the observation\ntime tends to infinity, it is shown that the proposed sequential procedures are\nasymptotically optimal among all possible sequential and non-sequential\nestimates with an average estimation time less than the fixed observation\nduration. It also turned out that asymptotically, without degrading the\nestimation quality, they significantly reduce the observation duration compared\nto classical non-sequential maximum likelihood estimations based on a fixed\nobservation duration.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-07T11:04:47Z"}
{"aid":"http://arxiv.org/abs/2504.04931v1","title":"The $L_{p}$ dual Christoffel-Minkowski problem for $1<p<q\\leq k+1$ with\n  $1\\leq k\\leq n$","summary":"In this paper, we investigate an $L_{p}$ Christoffel-Minkowski-type problem\nthat prescribes a class of $L_p$ geometric measures, which are mixtures of the\n$k$-th area measure and the $q$-th dual curvature measure. By establishing a\ngradient estimate, we obtain the existence of an even, smooth, strictly convex\nsolution to this problem for $1 < p < q \\leq k + 1$, where $1 \\leq k \\leq n$\nand $n \\geq 1$.","main_category":"math.AP","categories":"math.AP,math.DG","published":"2025-04-07T11:15:36Z"}
{"aid":"http://arxiv.org/abs/2504.04935v1","title":"RCCFormer: A Robust Crowd Counting Network Based on Transformer","summary":"Crowd counting, which is a key computer vision task, has emerged as a\nfundamental technology in crowd analysis and public safety management. However,\nchallenges such as scale variations and complex backgrounds significantly\nimpact the accuracy of crowd counting. To mitigate these issues, this paper\nproposes a robust Transformer-based crowd counting network, termed RCCFormer,\nspecifically designed for background suppression and scale awareness. The\nproposed method incorporates a Multi-level Feature Fusion Module (MFFM), which\nmeticulously integrates features extracted at diverse stages of the backbone\narchitecture. It establishes a strong baseline capable of capturing intricate\nand comprehensive feature representations, surpassing traditional baselines.\nFurthermore, the introduced Detail-Embedded Attention Block (DEAB) captures\ncontextual information and local details through global self-attention and\nlocal attention along with a learnable manner for efficient fusion. This\nenhances the model's ability to focus on foreground regions while effectively\nmitigating background noise interference. Additionally, we develop an Adaptive\nScale-Aware Module (ASAM), with our novel Input-dependent Deformable\nConvolution (IDConv) as its fundamental building block. This module dynamically\nadapts to changes in head target shapes and scales, significantly improving the\nnetwork's capability to accommodate large-scale variations. The effectiveness\nof the proposed method is validated on the ShanghaiTech Part_A and Part_B,\nNWPU-Crowd, and QNRF datasets. The results demonstrate that our RCCFormer\nachieves excellent performance across all four datasets, showcasing\nstate-of-the-art outcomes.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T11:19:05Z"}
{"aid":"http://arxiv.org/abs/2504.04937v1","title":"Hybrid Control Barrier Functions for Nonholonomic Multi-Agent Systems","summary":"This paper addresses the problem of guaranteeing safety of multiple\ncoordinated agents moving in dynamic environments. It has recently been shown\nthat this problem can be efficiently solved through the notion of Control\nBarrier Functions (CBFs). However, for nonholonomic vehicles that are required\nto keep positive speeds, existing CBFs lose their validity. To overcome this\nlimitation, we propose a hybrid formulation based on synergistic CBFs (SCBFs),\nwhich leverages a discrete switching mechanism to avoid configurations that\nwould render the CBF invalid. Unlike existing approaches, our method ensures\nsafety in the presence of moving obstacles and inter-agent interactions while\nrespecting nonzero speed restrictions. We formally analyze the feasibility of\nthe constraints with respect to actuation limits, and the efficacy of the\nsolution is demonstrated in simulation of a multi-agent coordination problem in\nthe presence of moving obstacles.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-07T11:20:38Z"}
{"aid":"http://arxiv.org/abs/2504.04940v1","title":"Fine tuning generative adversarial networks with universal force fields:\n  application to two-dimensional topological insulators","summary":"Despite rapid growth in use cases for generative artificial intelligence, its\nability to design purpose built crystalline materials remains in a nascent\nphase. At the moment inverse design is generally accomplished by either\nconstraining the training data set or producing a vast number of samples from a\ngenerator network and constraining the output via post-processing. We show that\na general adversarial network trained to produce crystal structures from a\nlatent space can be fine tuned through the introduction of advanced graph\nneural networks as discriminators, including a universal force field, to\nintrinsically bias the network towards generation of target materials. This is\nexemplified utilizing two-dimensional topological insulators as a sample target\nspace. While a number of two-dimensional topological insulators have been\npredicted, the size of the band-gap, a measure of topological protection,\nremains a concern in most candidate compounds. The resulting generative network\nis shown to yield novel topological insulators.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.dis-nn,cond-mat.mes-hall","published":"2025-04-07T11:25:44Z"}
{"aid":"http://arxiv.org/abs/2504.04943v1","title":"Emergence of microbial host dormancy during a persistent virus epidemic","summary":"We study a minimal stochastic individual-based model for a microbial\npopulation challenged by a persistent (lytic) virus epidemic. We focus on the\nsituation in which the resident microbial host population and the virus\npopulation are in stable coexistence upon arrival of a single new ``mutant''\nhost individual. We assume that this mutant is capable of switching to a\nreversible state of dormancy upon contact with virions as a means of avoiding\ninfection by the virus. At the same time, we assume that this new dormancy\ntrait comes with a cost, namely a reduced individual reproduction rate. We\nprove that there is a non-trivial range of parameters where the mutants can\nnevertheless invade the resident population with strictly positive probability\n(bounded away from 0) in the large population limit. Given the reduced\nreproductive rate, such an invasion would be impossible in the absence of\neither the dormancy trait or the virus epidemic. We explicitly characterize the\nparameter regime where this emergence of a (costly) host dormancy trait is\npossible, determine the success probability of a single invader and the typical\namount of time it takes the successful mutants to reach a macroscopic\npopulation size. We conclude this study by an investigation of the fate of the\npopulation after the successful emergence of a dormancy trait. Heuristic\narguments and simulations suggest that after successful invasion, either both\nhost types and the virus will reach coexistence, or the mutants will drive the\nresident hosts to extinction while the virus will stay in the system.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T11:30:42Z"}
{"aid":"http://arxiv.org/abs/2504.04972v1","title":"Sub-diffusive behavior of a recurrent Axis-Driven Random Walk","summary":"We study the second order of the number of excursions of a simple random walk\nwith a bias that drives a return toward the origin along the axes introduced by\nP. Andreoletti and P. Debs \\cite{AndDeb3}. This is a crucial step toward\nderiving the asymptotic behavior of these walks, whose limit is explicit and\nreveals various characteristics of the process: the invariant probability\nmeasure of the extracted coordinates away from the axes, the 1-stable\ndistribution arising from the tail distribution of entry times on the axes, and\nfinally, the presence of a Bessel process of dimension 3, which implies that\nthe trajectory can be interpreted as a random path conditioned to stay within a\nsingle quadrant.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T11:58:11Z"}
{"aid":"http://arxiv.org/abs/2504.04982v1","title":"Transforming Future Data Center Operations and Management via Physical\n  AI","summary":"Data centers (DCs) as mission-critical infrastructures are pivotal in\npowering the growth of artificial intelligence (AI) and the digital economy.\nThe evolution from Internet DC to AI DC has introduced new challenges in\noperating and managing data centers for improved business resilience and\nreduced total cost of ownership. As a result, new paradigms, beyond the\ntraditional approaches based on best practices, must be in order for future\ndata centers. In this research, we propose and develop a novel Physical AI\n(PhyAI) framework for advancing DC operations and management. Our system\nleverages the emerging capabilities of state-of-the-art industrial products and\nour in-house research and development. Specifically, it presents three core\nmodules, namely: 1) an industry-grade in-house simulation engine to simulate DC\noperations in a highly accurate manner, 2) an AI engine built upon NVIDIA\nPhysicsNemo for the training and evaluation of physics-informed machine\nlearning (PIML) models, and 3) a digital twin platform built upon NVIDIA\nOmniverse for our proposed 5-tier digital twin framework. This system presents\na scalable and adaptable solution to digitalize, optimize, and automate future\ndata center operations and management, by enabling real-time digital twins for\nfuture data centers. To illustrate its effectiveness, we present a compelling\ncase study on building a surrogate model for predicting the thermal and airflow\nprofiles of a large-scale DC in a real-time manner. Our results demonstrate its\nsuperior performance over traditional time-consuming Computational Fluid\nDynamics/Heat Transfer (CFD/HT) simulation, with a median absolute temperature\nprediction error of 0.18 {\\deg}C. This emerging approach would open doors to\nseveral potential research directions for advancing Physical AI in future DC\noperations.","main_category":"cs.AI","categories":"cs.AI,cs.DC","published":"2025-04-07T12:09:22Z"}
{"aid":"http://arxiv.org/abs/2504.04995v1","title":"The universal crossover from thermodynamics and dynamics of\n  supercritical RN-AdS black hole","summary":"We study the properties of supercritical Reissner-Nordstr\\\"om Anti-de Sitter\n(RN-AdS) black holes in the extended phase space with the pressure defines as\nthe cosmological constant. Supercritical black holes exist in the region where\nboth temperature and pressure exceed the critical point, known as the\nsupercritical region. The conventional view states that black holes in this\nregime are indistinguishable between large and small phases. However, recent\nresearch reveals that the supercritical regime exhibits universal gas-like and\nliquid-like phase separation, which shed light on the study on the\nsupercritical region of RN-AdS black holes in the extended phase space. In this\nwork, we calculate the thermodynamic potential and quasinormal modes (QNMs) of\nRN-AdS black holes, and identify transition curves between two different states\nin supercritical region using thermodynamic and dynamic methods. On one hand,\nwe find the thermodynamic crossover curve (Widom line) by defining the scaled\nvariance $\\Omega$ (a higher-order derivative of Gibbs free energy). On the\nother hand, we identify the dynamic crossover curve (Frenkel line) by analyzing\ntransitions between distinct QNM decay modes.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-ph,hep-th","published":"2025-04-07T12:24:23Z"}
{"aid":"http://arxiv.org/abs/2504.05010v1","title":"Some analogues of isoperimetric inequality","summary":"The discrete isoperimetric inequality states that among all n -gons with a\nfixed area, the regular n -gon has the least perimeter. We prove analogues of\nthe discrete isoperimetric inequality (involving circumradius or inradius) for\ncyclic and tangential polygons in hyperbolic geometry, considering both single\nand multiple polygons. Furthermore, we establish two versions of the\nisoperimetric inequality for multiple polygons in hyperbolic geometry with some\nrestriction on their area or perimeter.","main_category":"math.GT","categories":"math.GT","published":"2025-04-07T12:37:48Z"}
{"aid":"http://arxiv.org/abs/2504.05012v1","title":"Descriptive Complexity of Sensitivity of Cellular Automata","summary":"We study the computational complexity of determining whether a cellular\nautomaton is sensitive to initial conditions. We show that this problem is\n$\\Pi^0_2$-complete in dimension 1 and $\\Sigma^0_3$-complete in dimension 2 and\nhigher. This solves a question posed by Sablik and Theyssier.","main_category":"math.DS","categories":"math.DS,cs.CC,math.LO","published":"2025-04-07T12:38:07Z"}
{"aid":"http://arxiv.org/abs/2504.05015v1","title":"PVASS Reachability is Decidable","summary":"Reachability in pushdown vector addition systems with states (PVASS) is among\nthe longest standing open problems in Theoretical Computer Science. We show\nthat the problem is decidable in full generality. Our decision procedure is\nsimilar in spirit to the KLMST algorithm for VASS reachability, but works over\nobjects that support an elaborate form of procedure summarization as known from\npushdown reachability.","main_category":"cs.LO","categories":"cs.LO,cs.FL,F.1.1","published":"2025-04-07T12:40:18Z"}
{"aid":"http://arxiv.org/abs/2504.05019v1","title":"Mixture-of-Personas Language Models for Population Simulation","summary":"Advances in Large Language Models (LLMs) paved the way for their emerging\napplications in various domains, such as human behavior simulations, where LLMs\ncould augment human-generated data in social science research and machine\nlearning model training. However, pretrained LLMs often fail to capture the\nbehavioral diversity of target populations due to the inherent variability\nacross individuals and groups. To address this, we propose \\textit{Mixture of\nPersonas} (MoP), a \\textit{probabilistic} prompting method that aligns the LLM\nresponses with the target population. MoP is a contextual mixture model, where\neach component is an LM agent characterized by a persona and an exemplar\nrepresenting subpopulation behaviors. The persona and exemplar are randomly\nchosen according to the learned mixing weights to elicit diverse LLM responses\nduring simulation. MoP is flexible, requires no model finetuning, and is\ntransferable across base models. Experiments for synthetic data generation show\nthat MoP outperforms competing methods in alignment and diversity metrics.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-07T12:43:05Z"}
{"aid":"http://arxiv.org/abs/2504.05046v1","title":"MotionPRO: Exploring the Role of Pressure in Human MoCap and Beyond","summary":"Existing human Motion Capture (MoCap) methods mostly focus on the visual\nsimilarity while neglecting the physical plausibility. As a result, downstream\ntasks such as driving virtual human in 3D scene or humanoid robots in real\nworld suffer from issues such as timing drift and jitter, spatial problems like\nsliding and penetration, and poor global trajectory accuracy. In this paper, we\nrevisit human MoCap from the perspective of interaction between human body and\nphysical world by exploring the role of pressure. Firstly, we construct a\nlarge-scale human Motion capture dataset with Pressure, RGB and Optical sensors\n(named MotionPRO), which comprises 70 volunteers performing 400 types of\nmotion, encompassing a total of 12.4M pose frames. Secondly, we examine both\nthe necessity and effectiveness of the pressure signal through two challenging\ntasks: (1) pose and trajectory estimation based solely on pressure: We propose\na network that incorporates a small kernel decoder and a long-short-term\nattention module, and proof that pressure could provide accurate global\ntrajectory and plausible lower body pose. (2) pose and trajectory estimation by\nfusing pressure and RGB: We impose constraints on orthographic similarity along\nthe camera axis and whole-body contact along the vertical axis to enhance the\ncross-attention strategy to fuse pressure and RGB feature maps. Experiments\ndemonstrate that fusing pressure with RGB features not only significantly\nimproves performance in terms of objective metrics, but also plausibly drives\nvirtual humans (SMPL) in 3D scene. Furthermore, we demonstrate that\nincorporating physical perception enables humanoid robots to perform more\nprecise and stable actions, which is highly beneficial for the development of\nembodied artificial intelligence. Project page is available at:\nhttps://nju-cite-mocaphumanoid.github.io/MotionPRO/","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:17:24Z"}
{"aid":"http://arxiv.org/abs/2504.05049v1","title":"CMaP-SAM: Contraction Mapping Prior for SAM-driven Few-shot Segmentation","summary":"Few-shot segmentation (FSS) aims to segment new classes using few annotated\nimages. While recent FSS methods have shown considerable improvements by\nleveraging Segment Anything Model (SAM), they face two critical limitations:\ninsufficient utilization of structural correlations in query images, and\nsignificant information loss when converting continuous position priors to\ndiscrete point prompts. To address these challenges, we propose CMaP-SAM, a\nnovel framework that introduces contraction mapping theory to optimize position\npriors for SAM-driven few-shot segmentation. CMaP-SAM consists of three key\ncomponents: (1) a contraction mapping module that formulates position prior\noptimization as a Banach contraction mapping with convergence guarantees. This\nmodule iteratively refines position priors through pixel-wise structural\nsimilarity, generating a converged prior that preserves both semantic guidance\nfrom reference images and structural correlations in query images; (2) an\nadaptive distribution alignment module bridging continuous priors with SAM's\nbinary mask prompt encoder; and (3) a foreground-background decoupled\nrefinement architecture producing accurate final segmentation masks. Extensive\nexperiments demonstrate CMaP-SAM's effectiveness, achieving state-of-the-art\nperformance with 71.1 mIoU on PASCAL-$5^i$ and 56.1 on COCO-$20^i$ datasets.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:19:16Z"}
{"aid":"http://arxiv.org/abs/2504.05065v1","title":"Quantitative Supermartingale Certificates","summary":"We introduce a general methodology for quantitative model checking and\ncontrol synthesis with supermartingale certificates. We show that every\nspecification that is invariant to time shifts admits a stochastic invariant\nthat bounds its probability from below; for systems with general state space,\nthe stochastic invariant bounds this probability as closely as desired; for\nsystems with finite state space, it quantifies it exactly. Our result enables\nthe extension of every certificate for the almost-sure satisfaction of\nshift-invariant specifications to its quantitative counterpart, ensuring\ncompleteness up to an approximation in the general case and exactness in the\nfinite-state case. This generalises and unifies existing supermartingale\ncertificates for quantitative verification and control under reachability,\nsafety, reach-avoidance, and stability specifications, as well as asymptotic\nbounds on accrued costs and rewards. Furthermore, our result provides the first\nsupermartingale certificate for computing upper and lower bounds on the\nprobability of satisfying $\\omega$-regular and linear temporal logic\nspecifications. We present an algorithm for quantitative $\\omega$-regular\nverification and control synthesis based on our method and demonstrate its\npractical efficacy on several infinite-state examples.","main_category":"cs.LO","categories":"cs.LO,cs.SY,eess.SY","published":"2025-04-07T13:34:40Z"}
{"aid":"http://arxiv.org/abs/2504.05068v1","title":"Global approximations to the error function of real argument for\n  vectorized computation","summary":"The error function of real argument can be uniformly approximated to a given\naccuracy by a single closed-form expression for the whole variable range either\nin terms of addition, multiplication, division, and square root operations\nonly, or also using the exponential function. The coefficients have been\ntabulated for up to 128-bit precision. Tests of a computer code implementation\nusing the standard single- and double-precision floating-point arithmetic show\ngood performance and vectorizability.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-07T13:36:28Z"}
{"aid":"http://arxiv.org/abs/2504.05074v1","title":"On the Performance of an Explainable Language Model on PubMedQA","summary":"Large language models (LLMs) have shown significant abilities in retrieving\nmedical knowledge, reasoning over it and answering medical questions comparably\nto physicians. However, these models are not interpretable, hallucinate, are\ndifficult to maintain and require enormous compute resources for training and\ninference. In this paper, we report results from Gyan, an explainable language\nmodel based on an alternative architecture, on the PubmedQA data set. The Gyan\nLLM is a compositional language model and the model is decoupled from\nknowledge. Gyan is trustable, transparent, does not hallucinate and does not\nrequire significant training or compute resources. Gyan is easily transferable\nacross domains. Gyan-4.3 achieves SOTA results on PubmedQA with 87.1% accuracy\ncompared to 82% by MedPrompt based on GPT-4 and 81.8% by Med-PaLM 2 (Google and\nDeepMind). We will be reporting results for other medical data sets - MedQA,\nMedMCQA, MMLU - Medicine in the future.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T13:42:02Z"}
{"aid":"http://arxiv.org/abs/2504.05077v1","title":"Transforming Ridesharing: Harnessing Role Flexibility and HOV\n  Integration for Enhanced Mobility Solutions","summary":"While dynamic ridesharing has been extensively studied, there remains a\nsignificant research gap in exploring role flexibility within the many-to-many\nridesharing scheme, where the system allows for several pickups for drivers and\nmultiple transfers for riders. Previous works have predominantly assumed that\nall participants own a car and have focused on one-to-one arrangements.\nAdditionally, there is a scarcity of research on integrating High Occupancy\nVehicle (HOV) lanes and mathematical modelling. This study addresses these gaps\nby presenting a novel Mixed Integer Linear Programming (MILP) model that allows\nfor role flexibility irrespective of car ownership and considers the\nimplications of HOV lanes. Computational analysis highlights the benefits of\nincorporating role flexibility and accommodating non-car-owning participants in\nmany-to-many ridesharing systems. Yet, excessive role shifts may create\nimbalances, impacting service to non-car owners. Further research should\nexplore these correlations.","main_category":"math.OC","categories":"math.OC","published":"2025-04-07T13:45:19Z"}
{"aid":"http://arxiv.org/abs/2504.05089v1","title":"Climplicit: Climatic Implicit Embeddings for Global Ecological Tasks","summary":"Deep learning on climatic data holds potential for macroecological\napplications. However, its adoption remains limited among scientists outside\nthe deep learning community due to storage, compute, and technical expertise\nbarriers. To address this, we introduce Climplicit, a spatio-temporal\ngeolocation encoder pretrained to generate implicit climatic representations\nanywhere on Earth. By bypassing the need to download raw climatic rasters and\ntrain feature extractors, our model uses x1000 fewer disk space and\nsignificantly reduces computational needs for downstream tasks. We evaluate our\nClimplicit embeddings on biomes classification, species distribution modeling,\nand plant trait regression. We find that linear probing our Climplicit\nembeddings consistently performs better or on par with training a model from\nscratch on downstream tasks and overall better than alternative geolocation\nencoding models.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:58:55Z"}
{"aid":"http://arxiv.org/abs/2504.05110v1","title":"Stochastic storage models in theoretical physics problems","summary":"Stochastic storage models based on essentially non-Gaussian noise are\nconsidered. The stochastic description of physical systems based on stochastic\nstorage models is associated with generalized Poisson (or shot) noise, in which\nthe jump values can be quite large. Stochastic storage models have a direct\nphysical meaning: some elements enter the system and leave it. Storage\nprocesses fit into the general scheme of dynamic systems subject to the\nadditive influence of a random process. The main relationships of storage\nmodels are described, and the possibilities of applying the mathematical\nprovisions of stochastic storage processes to various physical problems are\nindicated. A number of examples of applying the stochastic storage model are\nconsidered.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-07T14:15:18Z"}
{"aid":"http://arxiv.org/abs/2504.05122v1","title":"DoCIA: An Online Document-Level Context Incorporation Agent for Speech\n  Translation","summary":"Document-level context is crucial for handling discourse challenges in\ntext-to-text document-level machine translation (MT). Despite the increased\ndiscourse challenges introduced by noise from automatic speech recognition\n(ASR), the integration of document-level context in speech translation (ST)\nremains insufficiently explored. In this paper, we develop DoCIA, an online\nframework that enhances ST performance by incorporating document-level context.\nDoCIA decomposes the ST pipeline into four stages. Document-level context is\nintegrated into the ASR refinement, MT, and MT refinement stages through\nauxiliary LLM (large language model)-based modules. Furthermore, DoCIA\nleverages document-level information in a multi-level manner while minimizing\ncomputational overhead. Additionally, a simple yet effective determination\nmechanism is introduced to prevent hallucinations from excessive refinement,\nensuring the reliability of the final results. Experimental results show that\nDoCIA significantly outperforms traditional ST baselines in both sentence and\ndiscourse metrics across four LLMs, demonstrating its effectiveness in\nimproving ST performance.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T14:26:49Z"}
{"aid":"http://arxiv.org/abs/2504.05128v1","title":"Kinetic study of compressible Rayleigh-Taylor instability with\n  time-varying acceleration","summary":"Rayleigh-Taylor (RT) instability commonly arises in compressible systems with\ntime-dependent acceleration in practical applications. To capture the complex\ndynamics of such systems, a two-component discrete Boltzmann method is\ndeveloped to systematically investigate the compressible RT instability driven\nby variable acceleration. Specifically, the effects of different acceleration\nperiods, amplitudes, and phases are systematically analyzed. The simulation\nresults are interpreted from three key perspectives: the density gradient,\nwhich characterizes the spatial variation in density; the thermodynamic\nnon-equilibrium strength, which quantifies the system's deviation from local\nthermodynamic equilibrium; and the fraction of non-equilibrium regions, which\ncaptures the spatial distribution of non-equilibrium behaviors. Notably, the\nfluid system exhibits rich and diverse dynamic patterns resulting from the\ninterplay of multiple competing physical mechanisms, including time-dependent\nacceleration, RT instability, diffusion, and dissipation effects. These\nfindings provide deeper insights into the evolution and regulation of\ncompressible RT instability under complex driving conditions.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-07T14:32:33Z"}
{"aid":"http://arxiv.org/abs/2504.05158v1","title":"Leveraging Label Potential for Enhanced Multimodal Emotion Recognition","summary":"Multimodal emotion recognition (MER) seeks to integrate various modalities to\npredict emotional states accurately. However, most current research focuses\nsolely on the fusion of audio and text features, overlooking the valuable\ninformation in emotion labels. This oversight could potentially hinder the\nperformance of existing methods, as emotion labels harbor rich, insightful\ninformation that could significantly aid MER. We introduce a novel model called\nLabel Signal-Guided Multimodal Emotion Recognition (LSGMER) to overcome this\nlimitation. This model aims to fully harness the power of emotion label\ninformation to boost the classification accuracy and stability of MER.\nSpecifically, LSGMER employs a Label Signal Enhancement module that optimizes\nthe representation of modality features by interacting with audio and text\nfeatures through label embeddings, enabling it to capture the nuances of\nemotions precisely. Furthermore, we propose a Joint Objective Optimization(JOO)\napproach to enhance classification accuracy by introducing the\nAttribution-Prediction Consistency Constraint (APC), which strengthens the\nalignment between fused features and emotion categories. Extensive experiments\nconducted on the IEMOCAP and MELD datasets have demonstrated the effectiveness\nof our proposed LSGMER model.","main_category":"cs.SD","categories":"cs.SD,cs.AI,eess.AS","published":"2025-04-07T15:00:34Z"}
{"aid":"http://arxiv.org/abs/2504.05196v1","title":"Universal Lymph Node Detection in Multiparametric MRI with Selective\n  Augmentation","summary":"Robust localization of lymph nodes (LNs) in multiparametric MRI (mpMRI) is\ncritical for the assessment of lymphadenopathy. Radiologists routinely measure\nthe size of LN to distinguish benign from malignant nodes, which would require\nsubsequent cancer staging. Sizing is a cumbersome task compounded by the\ndiverse appearances of LNs in mpMRI, which renders their measurement difficult.\nFurthermore, smaller and potentially metastatic LNs could be missed during a\nbusy clinical day. To alleviate these imaging and workflow problems, we propose\na pipeline to universally detect both benign and metastatic nodes in the body\nfor their ensuing measurement. The recently proposed VFNet neural network was\nemployed to identify LN in T2 fat suppressed and diffusion weighted imaging\n(DWI) sequences acquired by various scanners with a variety of exam protocols.\nWe also use a selective augmentation technique known as Intra-Label LISA (ILL)\nto diversify the input data samples the model sees during training, such that\nit improves its robustness during the evaluation phase. We achieved a\nsensitivity of $\\sim$83\\% with ILL vs. $\\sim$80\\% without ILL at 4 FP/vol.\nCompared with current LN detection approaches evaluated on mpMRI, we show a\nsensitivity improvement of $\\sim$9\\% at 4 FP/vol.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-07T15:46:43Z"}
{"aid":"http://arxiv.org/abs/2504.05221v1","title":"Apparent fractional charge signatures in PbTe quantum dots due to\n  capacitively coupled charge trap dynamics","summary":"We report the observation of fractional shifts in the experimental stability\ndiagrams of PbTe nanowire quantum dots. Although this behavior may appear to\nsuggest fractional charge transport, akin to that reported in the fractional\nquantum Hall regime, the quasi-one-dimensionality of the system and absence of\nan applied magnetic field indicate that the presence of fractional charges is\nhighly unlikely. We instead attribute these effects to the presence of one or\nmore spurious dots, or charge traps, capacitively coupled to the primary dot.\nOur findings illustrate how signatures of fractional charge transport may be\nreplicated through trivial mesoscopic Coulombic effects.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-07T16:08:20Z"}
{"aid":"http://arxiv.org/abs/2504.05232v1","title":"Discovery of the 7-ring PAH Cyanocoronene (C$_{24}$H$_{11}$CN) in GOTHAM\n  Observations of TMC-1","summary":"We present the synthesis and laboratory rotational spectroscopy of the 7-ring\npolycyclic aromatic hydrocarbon (PAH) cyanocoronene (C$_{24}$H$_{11}$CN) using\na laser-ablation assisted cavity-enhanced Fourier transform microwave\nspectrometer. A total of 71 transitions were measured and assigned between\n6.8--10.6\\,GHz. Using these assignments, we searched for emission from\ncyanocoronene in the GBT Observations of TMC-1: Hunting Aromatic Molecules\n(GOTHAM) project observations of the cold dark molecular cloud TMC-1 using the\n100\\,m Green Bank Telescope (GBT). We detect a number of individually resolved\ntransitions in ultrasensitive X-band observations and perform a Markov Chain\nMonte Carlo analysis to derive best-fit parameters, including a total column\ndensity of $N(\\mathrm{C}_{24}\\mathrm{H}_{11}\\mathrm{CN}) = 2.69^{+0.26}_{-0.23}\n\\times 10^{12}\\,\\mathrm{cm}^{-2}$ at a temperature of\n$6.05^{+0.38}_{-0.37}\\,$K. A spectral stacking and matched filtering analysis\nprovides a robust 17.3$\\,\\sigma$ significance to the overall detection. The\nderived column density is comparable to that of cyano-substituted naphthalene,\nacenaphthylene, and pyrene, defying the trend of decreasing abundance with\nincreasing molecular size and complexity found for carbon chains. We discuss\nthe implications of the detection for our understanding of interstellar PAH\nchemistry and highlight major open questions and next steps.","main_category":"astro-ph.GA","categories":"astro-ph.GA,physics.chem-ph","published":"2025-04-07T16:15:54Z"}
{"aid":"http://arxiv.org/abs/2504.05234v1","title":"Precision DIS thrust predictions for HERA and EIC","summary":"We present predictions for the DIS 1-jettiness event shape $\\tau_1^b$, or DIS\nthrust, using the framework of Soft Collinear Effective Theory (SCET) for\nfactorization, resummation of large logarithms, and rigorous treatment of\nnonperturbative power corrections, matched to fixed-order QCD away from the\nresummation region. Our predictions reach\nnext-to-next-to-next-to-leading-logarithmic (N$^3$LL) accuracy in resummed\nperturbation theory, matched to $O(\\alpha_s^2)$ fixed-order QCD calculations\nobtained using the program NLOJet++. We include a rigorous treatment of\nhadronization corrections, which are universal across different event shapes\nand kinematic variables $x$ and $Q$ at leading power, and supplement them with\na systematic scheme to remove $O(\\Lambda_\\textrm{QCD})$ renormalon ambiguities\nin their definition. The framework of SCET allows us to connect smoothly the\nnonperturbative, resummation, and fixed-order regions, whose relative\nimportance varies with $x$ and $Q$, and to rigorously estimate theoretical\nuncertainties, across a broad range of $x$ and $Q$ covering existing\nexperimental results from HERA as well as expected new measurements from the\nupcoming Electron-Ion-Collider (EIC). Our predictions will serve as an\nimportant benchmark for the EIC program, enabling the precise determination of\nthe QCD strong coupling $\\alpha_s$ and the universal nonperturbative first\nmoment parameter $\\Omega_1$.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-07T16:19:36Z"}
{"aid":"http://arxiv.org/abs/2504.05237v1","title":"Measuring R√©nyi entropy using a projected Loschmidt echo","summary":"We present efficient and practical protocols to measure the second R\\'enyi\nentropy (RE), whose exponential is known as the purity. We achieve this by\nestablishing a direct connection to a Loschmidt echo (LE) type measurement\nsequence, applicable to quantum many-body systems. Notably, our approach does\nnot rely on random-noise averaging, a feature that can be extended to protocols\nto measure out-of-time-order correlation functions (OTOCs), as we demonstrate.\nBy way of example, we show that our protocols can be practically implemented in\nsuperconducting qubit-based platforms, as well as in cavity-QED trapped\nultra-cold gases.","main_category":"quant-ph","categories":"quant-ph,cond-mat.quant-gas,cond-mat.stat-mech,hep-th","published":"2025-04-07T16:21:53Z"}
{"aid":"http://arxiv.org/abs/2504.05243v1","title":"Boundedness of polarized log Calabi-Yau fibrations with bounded bases","summary":"We investigate the boundedness problem for log Calabi-Yau fibrations whose\nbases and general fibers are bounded. We prove that the total spaces of log\nCalabi-Yau fibrations are bounded in codimension one after fixing some natural\ninvariants. We also prove that the total spaces are bounded if, in addition,\nthe irregularity of the general fibers vanishes. Then we apply our results to\nthe boundedness problem for stable minimal models and fibered Calabi-Yau\nvarieties.","main_category":"math.AG","categories":"math.AG","published":"2025-04-07T16:28:38Z"}
{"aid":"http://arxiv.org/abs/2504.05271v1","title":"AnomalousNet: A Hybrid Approach with Attention U-Nets and Change Point\n  Detection for Accurate Characterization of Anomalous Diffusion in Video Data","summary":"Anomalous diffusion occurs in a wide range of systems, including protein\ntransport within cells, animal movement in complex habitats, pollutant\ndispersion in groundwater, and nanoparticle motion in synthetic materials.\nAccurately estimating the anomalous diffusion exponent and the diffusion\ncoefficient from the particle trajectories is essential to distinguish between\nsub-diffusive, super-diffusive, or normal diffusion regimes. These estimates\nprovide a deeper insight into the underlying dynamics of the system,\nfacilitating the identification of particle behaviors and the detection of\nchanges in diffusion states. However, analyzing short and noisy video data,\nwhich often yield incomplete and heterogeneous trajectories, poses a\nsignificant challenge for traditional statistical approaches. We introduce a\ndata-driven method that integrates particle tracking, an attention\n  U-Net architecture, and a change-point detection algorithm to address these\nissues. This approach not only infers the anomalous diffusion parameters with\nhigh accuracy but also identifies temporal transitions between different\nstates, even in the presence of noise and limited temporal resolution. Our\nmethodology demonstrated strong performance in the 2nd Anomalous Diffusion\n(AnDi) Challenge benchmark within the top submissions for video tasks.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-07T17:08:17Z"}
{"aid":"http://arxiv.org/abs/2504.05274v1","title":"Aggregating time-series and image data: functors and double functors","summary":"Aggregation of time-series or image data over subsets of the domain is a\nfundamental task in data science. We show that many known aggregation\noperations can be interpreted as (double) functors on appropriate (double)\ncategories. Such functorial aggregations are amenable to parallel\nimplementation via straightforward extensions of Blelloch's parallel scan\nalgorithm. In addition to providing a unified viewpoint on existing operations,\nit allows us to propose new aggregation operations for time-series and image\ndata.","main_category":"math.CT","categories":"math.CT,cs.LG","published":"2025-04-07T17:12:20Z"}
{"aid":"http://arxiv.org/abs/2504.05276v1","title":"Enhancing LLM-Based Short Answer Grading with Retrieval-Augmented\n  Generation","summary":"Short answer assessment is a vital component of science education, allowing\nevaluation of students' complex three-dimensional understanding. Large language\nmodels (LLMs) that possess human-like ability in linguistic tasks are\nincreasingly popular in assisting human graders to reduce their workload.\nHowever, LLMs' limitations in domain knowledge restrict their understanding in\ntask-specific requirements and hinder their ability to achieve satisfactory\nperformance. Retrieval-augmented generation (RAG) emerges as a promising\nsolution by enabling LLMs to access relevant domain-specific knowledge during\nassessment. In this work, we propose an adaptive RAG framework for automated\ngrading that dynamically retrieves and incorporates domain-specific knowledge\nbased on the question and student answer context. Our approach combines\nsemantic search and curated educational sources to retrieve valuable reference\nmaterials. Experimental results in a science education dataset demonstrate that\nour system achieves an improvement in grading accuracy compared to baseline LLM\napproaches. The findings suggest that RAG-enhanced grading systems can serve as\nreliable support with efficient performance gains.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T17:17:41Z"}
{"aid":"http://arxiv.org/abs/2504.05630v1","title":"A new discrimination measure for assessing predictive performance of\n  non-linear survival models","summary":"Non-linear survival models are flexible models in which the proportional\nhazard assumption is not required. This poses difficulties in their evaluation.\nWe introduce a new discrimination measure, time-dependent Uno's C-index, to\nassess the discrimination performance of non-linear survival models. This is an\nunbiased version of Antolini's time-dependent concordance. We prove convergence\nof both measures employing Nolan and Pollard's results on U-statistics. We\nexplore the relationship between these measures and, in particular, the bias of\nAntolini's concordance in the presence of censoring using simulated data. We\ndemonstrate the value of time-dependent Uno's C-index for the evaluation of\nmodels trained on censored real data and for model tuning.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-08T03:11:43Z"}
{"aid":"http://arxiv.org/abs/2504.05645v1","title":"A Study of Multiple Molecular Lines at the 3 mm Band toward Gas\n  Infalling Sources","summary":"The study of multiple molecular spectral lines in gas infalling sources can\nprovide the physical and chemical properties of these sources and help us\nestimate their evolutionary stages. We report line detections within the 3 mm\nband using the FTS wide-sideband mode of the IRAM 30 m telescope toward 20\ngas-infalling sources. Using XCLASS, we identify the emission lines of up to 22\nmolecular species (including a few isotopologues) and one hydrogen radio\nrecombination line in these sources. H$^{13}$CO$^+$, HCO$^+$, HCN, HNC,\nc-C$_3$H$_2$, and CCH lines are detected in 15 sources. We estimate the\nrotation temperatures and column densities of these molecular species using the\nLTE radiative transfer model, and compare the molecular abundances of these\nsources with those from nine high-mass star-forming regions reported in\nprevious studies and with those from the chemical model. Our results suggest\nthat G012.79-0.20, G012.87-0.22 clump A and B, and G012.96-0.23 clump A may be\nin the high-mass protostellar object stage, while sources with fewer detected\nspecies may be in the earlier evolutionary stage. Additionally, the CCH and\nc-C$_3$H$_2$ column densities in our sources reveal a linear correlation, with\na ratio of N(CCH)/N(c-C$_3$H$_2$) = 89.2$\\pm$5.6, which is higher than the\nratios reported in the literature. When considering only sources with lower\ncolumn densities, this ratio decreases to 29.0$\\pm$6.1, consistent with those\nof diffuse clouds. Furthermore, a comparison between the N(CCH)/N(c-C$_3$H$_2$)\nratio and the sources' physical parameters reveals a correlation, with sources\nexhibiting higher ratios tending to have higher kinetic temperatures and H$_2$\ncolumn densities.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-08T03:40:53Z"}
{"aid":"http://arxiv.org/abs/2504.05648v1","title":"The stochastic Navier-Stokes equations with general $L^{3}$ data","summary":"We consider the stochastic Navier-Stokes equations with multiplicative noise\nwith critical initial data. Assuming that the initial data $u_0$ belongs to the\ncritical space $L^{3}$ almost surely, we construct a unique local-in-time\nprobabilistically strong solution. We also prove an analogous result for data\nin the critical space~$H^\\frac{1}{2}$.","main_category":"math.PR","categories":"math.PR,math.AP","published":"2025-04-08T03:52:54Z"}
{"aid":"http://arxiv.org/abs/2504.05719v1","title":"Mental Geometry","summary":"This article illustrates pedagogy through training in the handling of\nabstractions. Mental arithmetic is not limited to numerical calculation; one\ncan mentally calculate primitives and simplify analytical expressions. Even if\nthere is software that does this very well, this training retains its\npedagogical value. Can we go further and consider geometric mental arithmetic:\nmentally proceeding with transformations of simple figures allowing the\ncalculation of areas or volumes? It turns out that the intuition that allowed\nArchimedes to obtain his main geometric results, if we take only the ideas\nwithout the old-fashioned style, provides the opportunity for a pleasant and\nquite rich mental game that I present here in the form of a short narrative\ndialogue, not a philosophical tale because it does not bring any thesis, simply\na story to be classified among the invitations to exercise the mind. It starts\nwith the area of a triangle and ends with Guldin's two theorems.","main_category":"math.HO","categories":"math.HO,math.MG","published":"2025-04-08T06:39:13Z"}
{"aid":"http://arxiv.org/abs/2504.05721v1","title":"Graph product and the stability of circulant graphs","summary":"A graph $\\Gamma$ is said to be stable if $\\mathrm{Aut}(\\Gamma\\times\nK_2)\\cong\\mathrm{Aut}(\\Gamma)\\times \\mathbb{Z}_{2}$ and unstable otherwise. If\nan unstable graph is connected, non-bipartite and any two of its distinct\nvertices have different neighborhoods, then it is called nontrivially unstable.\nWe establish conditions guaranteeing the instability of various graph products,\nincluding direct products, direct product bundles, Cartesian products, strong\nproducts, semi-strong products, and lexicographic products. Inspired by a\ncondition for the instability of direct product bundles, we propose a new\nsufficient condition for circulant graphs to be unstable. This condition yields\ninfinitely many nontrivially unstable circulant graphs that do not satisfy any\npreviously established instability conditions for circulant graphs.","main_category":"math.CO","categories":"math.CO","published":"2025-04-08T06:42:11Z"}
{"aid":"http://arxiv.org/abs/2504.05743v1","title":"Causal Portfolio Optimization: Principles and Sensitivity-Based\n  Solutions","summary":"Fundamental and necessary principles for achieving efficient portfolio\noptimization based on asset and diversification dynamics are presented. The\nCommonality Principle is a necessary and sufficient condition for identifying\noptimal drivers of a portfolio in terms of its diversification dynamics. The\nproof relies on the Reichenbach Common Cause Principle, along with the fact\nthat the sensitivities of portfolio constituents with respect to the common\ncausal drivers are themselves causal. A conformal map preserves idiosyncratic\ndiversification from the unconditional setting while optimizing systematic\ndiversification on an embedded space of these sensitivities. Causal\nmethodologies for combinatorial driver selection are presented, such as the use\nof Bayesian networks and correlation-based algorithms from Reichenbach's\nprinciple. Limitations of linear models in capturing causality are discussed,\nand included for completeness alongside more advanced models such as neural\nnetworks. Portfolio optimization methods are presented that map risk from the\nsensitivity space to other risk measures of interest. Finally, the work\nintroduces a novel risk management framework based on Common Causal Manifolds,\nincluding both theoretical development and experimental validation. The\nsensitivity space is predicted along the common causal manifold, which is\nmodeled as a causal time system. Sensitivities are forecasted using SDEs\ncalibrated to data previously extracted from neural networks to move along the\nmanifold via its tangent bundles. An optimization method is then proposed that\naccumulates information across future predicted tangent bundles on the common\ncausal time system manifold. It aggregates sensitivity-based distance metrics\nalong the trajectory to build a comprehensive sensitivity distance matrix. This\nmatrix enables trajectory-wide optimal diversification, taking into account\nfuture dynamics.","main_category":"q-fin.PM","categories":"q-fin.PM","published":"2025-04-08T07:21:40Z"}
{"aid":"http://arxiv.org/abs/2504.05754v1","title":"Dispersion-corrected Machine Learning Potentials for 2D van der Waals\n  Materials","summary":"Machine-learned interatomic potentials (MLIPs) based on message passing\nneural networks hold promise to enable large-scale atomistic simulations of\ncomplex materials with ab initio accuracy. A number of MLIPs trained on\nenergies and forces from density functional theory (DFT) calculations employing\nsemi-local exchange-correlation (xc) functionals have recently been introduced.\nHere, we benchmark the performance of six dispersion-corrected MLIPs on a\ndataset of van der Waals heterobilayers containing between 4 and 300 atoms in\nthe moir\\'e cell. Using various structure similarity metrics, we compare the\nrelaxed heterostructures to the ground truth DFT results. With some notable\nexceptions, the model precisions are comparable to the uncertainty on the DFT\nresults stemming from the choice of xc-functional. We further explore how the\nstructural inaccuracies propagate to the electronic properties, and find\nexcellent performance with average errors on band energies as low as 35 meV.\nOur results demonstrate that recent MLIPs after dispersion corrections are on\npar with DFT for general vdW heterostructures, and thus justify their\napplication to complex and experimentally relevant 2D materials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T07:35:53Z"}
{"aid":"http://arxiv.org/abs/2504.05765v1","title":"Probabilistic Process Discovery with Stochastic Process Trees","summary":"In order to obtain a stochastic model that accounts for the stochastic\naspects of the dynamics of a business process, usually the following steps are\ntaken. Given an event log, a process tree is obtained through a process\ndiscovery algorithm, i.e., a process tree that is aimed at reproducing, as\naccurately as possible, the language of the log. The process tree is then\ntransformed into a Petri net that generates the same set of sequences as the\nprocess tree. In order to capture the frequency of the sequences in the event\nlog, weights are assigned to the transitions of the Petri net, resulting in a\nstochastic Petri net with a stochastic language in which each sequence is\nassociated with a probability. In this paper we show that this procedure has\nunfavorable properties. First, the weights assigned to the transitions of the\nPetri net have an unclear role in the resulting stochastic language. We will\nshow that a weight can have multiple, ambiguous impact on the probability of\nthe sequences generated by the Petri net. Second, a number of different Petri\nnets with different number of transitions can correspond to the same process\ntree. This means that the number of parameters (the number of weights) that\ndetermines the stochastic language is not well-defined. In order to avoid these\nambiguities, in this paper, we propose to add stochasticity directly to process\ntrees. The result is a new formalism, called stochastic process trees, in which\nthe number of parameters and their role in the associated stochastic language\nis clear and well-defined.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T07:46:06Z"}
{"aid":"http://arxiv.org/abs/2504.05780v1","title":"Magnetic Memory Driven by Orbital Current","summary":"Spin-orbitronics, based on both spin and orbital angular momentum, presents a\npromising pathway for energy-efficient memory and logic devices. Recent studies\nhave demonstrated the emergence of orbital currents in light transition metals\nsuch as Ti, Cr, and Zr, broadening the scope of spin-orbit torque (SOT). In\nparticular, the orbital Hall effect, which arises independently of spin-obit\ncoupling, has shown potential for enhancing torque efficiency in spintronic\ndevices. However, the direct integration of orbital current into magnetic\nrandom-access memory (MRAM) remains unexplored. In this work, we design a light\nmetal/heavy metal/ferromagnet multilayer structure and experimentally\ndemonstrate magnetization switching by orbital current. Furthermore, we have\nrealized a robust SOT-MRAM cell by incorporating a reference layer that is\npinned by a synthetic antiferromagnetic structure. We observed a tunnel\nmagnetoresistance of 66%, evident in both magnetic field and current-driven\nswitching processes. Our findings underscore the potential for employing\norbital current in designing next-generation spintronic devices.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T08:03:31Z"}
{"aid":"http://arxiv.org/abs/2504.05787v1","title":"Finiteness properties of asymptotically rigid handlebody groups","summary":"We introduce asymptotically rigid mapping class groups of handlebodies and\ndetermine their finiteness properties, which vary depending on the space of\nends of the underlying handlebody. As it turns out, in some cases, the homology\nof these groups coincides with the stable homology of handlebody groups, as\nstudied by Hatcher and Wahl.","main_category":"math.GT","categories":"math.GT,math.GR","published":"2025-04-08T08:13:15Z"}
{"aid":"http://arxiv.org/abs/2504.05795v1","title":"Robust Fusion Controller: Degradation-aware Image Fusion with\n  Fine-grained Language Instructions","summary":"Current image fusion methods struggle to adapt to real-world environments\nencompassing diverse degradations with spatially varying characteristics. To\naddress this challenge, we propose a robust fusion controller (RFC) capable of\nachieving degradation-aware image fusion through fine-grained language\ninstructions, ensuring its reliable application in adverse environments.\nSpecifically, RFC first parses language instructions to innovatively derive the\nfunctional condition and the spatial condition, where the former specifies the\ndegradation type to remove, while the latter defines its spatial coverage.\nThen, a composite control priori is generated through a multi-condition\ncoupling network, achieving a seamless transition from abstract language\ninstructions to latent control variables. Subsequently, we design a hybrid\nattention-based fusion network to aggregate multi-modal information, in which\nthe obtained composite control priori is deeply embedded to linearly modulate\nthe intermediate fused features. To ensure the alignment between language\ninstructions and control outcomes, we introduce a novel language-feature\nalignment loss, which constrains the consistency between feature-level gains\nand the composite control priori. Extensive experiments on publicly available\ndatasets demonstrate that our RFC is robust against various composite\ndegradations, particularly in highly challenging flare scenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T08:22:55Z"}
{"aid":"http://arxiv.org/abs/2504.05834v1","title":"Elongation-Induced Segregation in Periodically Textured Microfluidic\n  Channels","summary":"We numerically investigate the motion of elongated microparticles in\nmicrofluidic channels at low Reynolds numbers. In channels with smooth walls,\nasymmetric initial conditions -- including particle orientation and lateral\nposition -- lead to continuous variations in particle trajectories, potentially\nexhibiting repeated behavior depending on the channel geometry and initial\nconditions. However, we find that introducing periodically textured walls\ninduces alignment of the particle with the channel centerline within a specific\nrange of texture wavelengths. This occurs as the textured pattern disrupts the\nuniformity of the flow, creating localized high-velocity nodes that repeatedly\nguide the particle toward the centerline as it moves downstream. Notably, the\ncharacteristic length scale over which this alignment forms reduces with\nincreasing particle elongation and diverges with increasing Reynolds number.\nOur findings reveal that elongation-induced alignment can be leveraged for\nmicrofluidic filtering applications, enabling the efficient separation of\nmicroparticles based on their geometric properties. This work opens new avenues\nfor designing microfluidic devices tailored for high-precision particle\nsorting, with broad implications for biomedical and industrial applications.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cond-mat.stat-mech,physics.comp-ph","published":"2025-04-08T09:17:23Z"}
{"aid":"http://arxiv.org/abs/2504.05856v1","title":"Analyzing type Ia supernovae near-infrared light curves with Principal\n  Component Analysis","summary":"Type Ia supernovae (SNeIa), the thermonuclear explosions of C/O white dwarf\nstars in binary systems, are phenomena that remain poorly understood. The\ncomplexity of their progenitor systems, explosion physics and intrinsic\ndiversity poses not only challenges for their understanding as astrophysical\nobjects, but also for their standardization and use as cosmological probes.\nNear-infrared (NIR) observations offer a promising avenue for studying the\nphysics of SNeIa and for reducing systematic uncertainties in distance\nestimations, as they exhibit lower dust extinction and smaller dispersion in\npeak luminosity than optical bands. Here, Principal Component Analysis (PCA) is\napplied to a sample of SNeIa with well-sampled NIR (YJH-band) light curves to\nidentify the dominant components of their variability and constrain physical\nunderlying properties. The theoretical models of Kasen2006 are used for the\nphysical interpretation of the PCA components, where we found the 56Ni mass to\ndescribe the dominant variability. Other factors, such as mixing and\nmetallicity, were found to contribute significantly as well. However, some\ndifferences are found between the components of the NIR bands which may be\nattributed to differences in the explosion aspects they each trace.\nAdditionally, the PCA components are compared to various light-curve\nparameters, identifying strong correlations between some components and peak\nbrightness in both the NIR and optical bands, particularly in the Y band. When\napplying PCA to NIR color curves, we found interesting correlations with the\nhost-galaxy mass, where SNeIa with redder NIR colors are predominantly found in\nless massive galaxies. We also investigate the potential for improved\nstandardization in the Y band by incorporating PCA coefficients as correction\nparameters, leading to a reduction in the scatter of the intrinsic luminosity\nof SNeIa.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-08T09:35:33Z"}
{"aid":"http://arxiv.org/abs/2504.05857v1","title":"Towards an AI-Driven Video-Based American Sign Language Dictionary:\n  Exploring Design and Usage Experience with Learners","summary":"Searching for unfamiliar American Sign Language (ASL) signs is challenging\nfor learners because, unlike spoken languages, they cannot type a text-based\nquery to look up an unfamiliar sign. Advances in isolated sign recognition have\nenabled the creation of video-based dictionaries, allowing users to submit a\nvideo and receive a list of the closest matching signs. Previous HCI research\nusing Wizard-of-Oz prototypes has explored interface designs for ASL\ndictionaries. Building on these studies, we incorporate their design\nrecommendations and leverage state-of-the-art sign-recognition technology to\ndevelop an automated video-based dictionary. We also present findings from an\nobservational study with twelve novice ASL learners who used this dictionary\nduring video-comprehension and question-answering tasks. Our results address\nhuman-AI interaction challenges not covered in previous WoZ research, including\nrecording and resubmitting signs, unpredictable outputs, system latency, and\nprivacy concerns. These insights offer guidance for designing and deploying\nvideo-based ASL dictionary systems.","main_category":"cs.HC","categories":"cs.HC,cs.AI","published":"2025-04-08T09:35:46Z"}
{"aid":"http://arxiv.org/abs/2504.05886v1","title":"Learning strategies for optimised fitness in a model of cyclic dominance","summary":"A major problem in evolutionary biology is how species learn and adapt under\nthe constraint of environmental conditions and competition of other species.\nModels of cyclic dominance provide simplified settings in which such questions\ncan be addressed using methods from theoretical physics. We investigate how a\nprivileged (\"smart\") species optimises its population by adopting advantageous\nstrategies in one such model. We use a reinforcement learning algorithm, which\nsuccessfully identifies optimal strategies based on a survival-of-the-weakest\neffect, including directional incentives to avoid predators. We also\ncharacterise the steady-state behaviour of the system in the presence of the\nsmart species and compare with the symmetric case where all species are\nequivalent.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,q-bio.PE","published":"2025-04-08T10:22:25Z"}
{"aid":"http://arxiv.org/abs/2504.05887v1","title":"Jointly-optimized Trajectory Generation and Camera Control for 3D\n  Coverage Planning","summary":"This work proposes a jointly optimized trajectory generation and camera\ncontrol approach, enabling an autonomous agent, such as an unmanned aerial\nvehicle (UAV) operating in 3D environments, to plan and execute coverage\ntrajectories that maximally cover the surface area of a 3D object of interest.\nSpecifically, the UAV's kinematic and camera control inputs are jointly\noptimized over a rolling planning horizon to achieve complete 3D coverage of\nthe object. The proposed controller incorporates ray-tracing into the planning\nprocess to simulate the propagation of light rays, thereby determining the\nvisible parts of the object through the UAV's camera. This integration enables\nthe generation of precise look-ahead coverage trajectories. The coverage\nplanning problem is formulated as a rolling finite-horizon optimal control\nproblem and solved using mixed-integer programming techniques. Extensive\nreal-world and synthetic experiments validate the performance of the proposed\napproach.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-08T10:23:37Z"}
{"aid":"http://arxiv.org/abs/2504.05904v1","title":"Intrinsic Saliency Guided Trunk-Collateral Network for Unsupervised\n  Video Object Segmentation","summary":"Recent unsupervised video object segmentation (UVOS) methods predominantly\nadopt the motion-appearance paradigm. Mainstream motion-appearance approaches\nuse either the two-encoder structure to separately encode motion and appearance\nfeatures, or the single-encoder structure for joint encoding. However, these\nmethods fail to properly balance the motion-appearance relationship.\nConsequently, even with complex fusion modules for motion-appearance\nintegration, the extracted suboptimal features degrade the models' overall\nperformance. Moreover, the quality of optical flow varies across scenarios,\nmaking it insufficient to rely solely on optical flow to achieve high-quality\nsegmentation results. To address these challenges, we propose the Intrinsic\nSaliency guided Trunk-Collateral Net}work (ISTC-Net), which better balances the\nmotion-appearance relationship and incorporates model's intrinsic saliency\ninformation to enhance segmentation performance. Specifically, considering that\noptical flow maps are derived from RGB images, they share both commonalities\nand differences. We propose a novel Trunk-Collateral structure. The shared\ntrunk backbone captures the motion-appearance commonality, while the collateral\nbranch learns the uniqueness of motion features. Furthermore, an Intrinsic\nSaliency guided Refinement Module (ISRM) is devised to efficiently leverage the\nmodel's intrinsic saliency information to refine high-level features, and\nprovide pixel-level guidance for motion-appearance fusion, thereby enhancing\nperformance without additional input. Experimental results show that ISTC-Net\nachieved state-of-the-art performance on three UVOS datasets (89.2% J&F on\nDAVIS-16, 76% J on YouTube-Objects, 86.4% J on FBMS) and four standard video\nsalient object detection (VSOD) benchmarks with the notable increase,\ndemonstrating its effectiveness and superiority over previous methods.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-08T11:02:14Z"}
{"aid":"http://arxiv.org/abs/2504.05922v1","title":"Thawed Gaussian Ehrenfest dynamics at conical intersections: When can a\n  single mean-field trajectory capture internal conversion?","summary":"The thawed Gaussian Ehrenfest dynamics is a single-trajectory method that\npartially includes both nuclear quantum and electronically nonadiabatic effects\nby combining the thawed Gaussian wavepacket dynamics with Ehrenfest dynamics.\nFirst, we demonstrate the improvement over the parent methods in a\nmultidimensional system consisting of vertically displaced harmonic potentials\nwith constant diabatic couplings, for which the thawed Gaussian Ehrenfest\ndynamics is exact. Then, we show that single-trajectory mean-field methods\ncompletely fail to capture electronic population transfer in the vicinity of\nconical intersections between potential energy surfaces associated with\nelectronic states of different symmetry (i.e., belonging to different\nirreducible representations of the molecular point group). The underlying cause\nof this limitation suggests that the thawed Gaussian Ehrenfest dynamics can be\nuseful for studying nonadiabatic dynamics close to conical intersections of\nelectronic states of the same symmetry, which have been understudied owing to\nthe difficulty in locating them. Using a model of this type of intersection, we\ncompare the thawed Gaussian Ehrenfest dynamics with exact quantum dynamics and\nfind that the approximate mean-field approach yields a molecular wavefunction\nthat remains qualitatively similar to the exact one even after crossing and\nrecrossing the conical intersection.","main_category":"physics.chem-ph","categories":"physics.chem-ph,quant-ph","published":"2025-04-08T11:27:20Z"}
{"aid":"http://arxiv.org/abs/2504.05924v1","title":"A Control-Oriented Simplified Single Particle Model with Grouped\n  Parameter and Sensitivity Analysis for Lithium-Ion Batteries","summary":"Lithium-ion batteries are widely used in transportation, energy storage, and\nconsumer electronics, driving the need for reliable battery management systems\n(BMS) for state estimation and control. The Single Particle Model (SPM)\nbalances computational efficiency and accuracy but faces challenges in\nparameter estimation due to numerous parameters. Current SPM models using\nparabolic approximation introduce intermediate variables and hard to do\nparameter grouping. This study presents a control-oriented SPM reformulation\nthat employs parameter grouping and parabolic approximation to simplify model\nparameters while using average and surface lithium-ion concentrations as model\noutput. By parameter grouping, the original 17 parameters were reduced to 9\ngrouped parameters. The reformulated model achieves a reduced-order ordinary\ndifferential equation form while maintaining mathematical accuracy equivalent\nto the pre-grouped discretized SPM. Through Sobol sensitivity analysis under\nvarious current profiles, the grouped parameters were reduced from 9 to 6\nhighly sensitive parameters. Results demonstrate that estimating these 6\nparameters achieves comparable practical accuracy to estimating all 9\nparameters, with faster convergence. This control-oriented SPM enhances BMS\napplications by facilitating state estimation and control while reducing\nparameter estimation requirements.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-08T11:28:40Z"}
{"aid":"http://arxiv.org/abs/2504.05930v1","title":"Totally equimodular matrices: decomposition and triangulation","summary":"Totally equimodular matrices generalize totally unimodular matrices and arise\nin the context of box-total dual integral polyhedra. This work further explores\nthe parallels between these two classes and introduces foundational building\nblocks for constructing totally equimodular matrices. Consequently, we present\na decomposition theorem for totally equimodular matrices of full row rank.\n  Building on this decomposition theorem, we prove that simplicial cones whose\ngenerators form the rows of a totally equimodular matrix sa\\-tisfy strong\nintegrality decomposition properties. More precisely, we provide the Hilbert\nbasis for these cones and construct regular unimodular Hilbert triangulations\nin most cases. We conjecture that cases not covered here do not exist.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-08T11:40:59Z"}
{"aid":"http://arxiv.org/abs/2504.05954v1","title":"Unsupervised Location Mapping for Narrative Corpora","summary":"This work presents the task of unsupervised location mapping, which seeks to\nmap the trajectory of an individual narrative on a spatial map of locations in\nwhich a large set of narratives take place. Despite the fundamentality and\ngenerality of the task, very little work addressed the spatial mapping of\nnarrative texts. The task consists of two parts: (1) inducing a ``map'' with\nthe locations mentioned in a set of texts, and (2) extracting a trajectory from\na single narrative and positioning it on the map. Following recent advances in\nincreasing the context length of large language models, we propose a pipeline\nfor this task in a completely unsupervised manner without predefining the set\nof labels. We test our method on two different domains: (1) Holocaust\ntestimonies and (2) Lake District writing, namely multi-century literature on\ntravels in the English Lake District. We perform both intrinsic and extrinsic\nevaluations for the task, with encouraging results, thereby setting a benchmark\nand evaluation practices for the task, as well as highlighting challenges.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-08T12:06:47Z"}
{"aid":"http://arxiv.org/abs/2504.05968v1","title":"Security Vulnerabilities in Ethereum Smart Contracts: A Systematic\n  Analysis","summary":"Smart contracts are a secure and trustworthy application that plays a vital\nrole in decentralized applications in various fields such as insurance,the\ninternet, and gaming. However, in recent years, smart contract security\nbreaches have occurred frequently, and due to their financial properties, they\nhave caused huge economic losses, such as the most famous security incident\n\"The DAO\" which caused a loss of over \\$60 million in Ethereum. This has drawn\na lot of attention from all sides. Writing a secure smart contract is now a\ncritical issue.This paper focuses on Ether smart contracts and explains the\nmain components of Ether, smart contract architecture and mechanism.The\nenvironment used in this paper is the Ethernet environment, using remix online\ncompilation platform and Solidity language, according to the four security\nevents of American Chain, The DAO, Parity and KotET, the principles of integer\noverflow attack, reentrant attack, access control attack and denial of service\nattack are studied and analyzed accordingly, and the scenarios of these\nvulnerabilities are reproduced, and the measures to prevent them are given.\nFinally, preventive measures are given. In addition, the principles of short\naddress attack, early transaction attack and privileged function exposure\nattack are also introduced in detail, and security measures are proposed.As\nvulnerabilities continue to emerge, their classification will also evolve. The\nanalysis and research of the current vulnerabilities are also to lay a solid\nfoundation for avoiding more vulnerabilities.","main_category":"cs.CR","categories":"cs.CR,D.2.4","published":"2025-04-08T12:25:34Z"}
{"aid":"http://arxiv.org/abs/2504.05969v1","title":"Extension of derivations to forms","summary":"The problem of extending derivations of a field $F$ to an $F-$algebra $B$ is\nwidely studied in commutative algebra and non-commutative ring theory. For\nexample, every derivation of $F$ extends to $B$ if $B$ is a separable algebraic\nextension or a central simple algebra over $F.$ We unify and generalize these\nresults by showing that a derivation $d$ of $F$ with the field of constants $C$\nextends to a finite dimensional algebra $B$ if $B$ is a form of some\n$C-$algebra having a smooth automorphism scheme $\\rm G$. Furthermore, we show\nthat the set of derivations of $B$ that extend the derivation $d$ of $F$ is in\nbijection with the set of derivations $\\delta$ such that $(Y,\\delta)$ is a\ndifferential $\\rm G_F-$torsor where $Y$ is the $\\rm G_F-$torsor corresponding\nto $B$.","main_category":"math.RA","categories":"math.RA","published":"2025-04-08T12:26:52Z"}
{"aid":"http://arxiv.org/abs/2504.05974v1","title":"The Higgs trilinear coupling in the SMEFT at the HL-LHC and the FCC-ee","summary":"Motivated by the updated HL-LHC projections for Higgs pair production from\nATLAS and CMS and by the release of the FCC-ee Feasibility Study, we critically\nrevisit the sensitivity of the global SMEFT analysis to deformations of the\nHiggs self-coupling modifier $\\kappa_3$. To this end, we quantify the impact of\nSMEFT operators modifying double Higgs production at the LHC and single Higgs\nproduction, including loop corrections, at the FCC-ee, and include\nRenormalisation Group Evolution throughout. We demonstrate that significantly\nimproving on the legacy HL-LHC constraints on $\\kappa_3$ at the FCC-ee is not\npossible without the $\\sqrt{s}=365$ GeV run; that individual and marginalised\ndeterminations are similar at the HL-LHC while differing by up to a factor 3 at\nthe FCC-ee; and that quadratic EFT corrections cannot be neglected. Overall,\nthe combination of HL-LHC and FCC-ee data offers unique potential to pin down\nthe Higgs self-coupling with $\\sim$$15\\%$ precision.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-08T12:30:44Z"}
{"aid":"http://arxiv.org/abs/2504.05991v1","title":"On non-local exchange and scattering operators in domain decomposition\n  methods","summary":"We study non-local exchange and scattering operators arising in domain\ndecomposition algorithms for solving elliptic problems on domains in\n$\\mathbb{R}^2$. Motivated by recent formulations of the Optimized Schwarz\nMethod introduced by Claeys, we rigorously analyze the behavior of a family of\nnon-local exchange operators $\\Pi_\\gamma$, defined in terms of boundary\nintegral operators associated to the fundamental solution for $-\\Delta +\n\\gamma^{-2}$, with $\\gamma > 0$. Our first main result establishes precise\nestimates comparing $\\Pi_\\gamma$ to its local counterpart $\\Pi_0$ as $\\gamma\n\\to 0$, providing a quantitative bridge between the classical and non-local\nformulations of the Optimized Schwarz Method. In addition, we investigate the\ncorresponding scattering operators, proving norm estimates that relate them to\ntheir classical analogues through a detailed analysis of the associated\nDirichlet-to-Neumann operators. Our results clarify the relationship between\nclassical and non-local formulations of domain decomposition methods and yield\nnew insights that are essential for the analysis of these algorithms,\nparticularly in the presence of cross points and for domains with curvilinear\npolygonal boundaries.","main_category":"math.NA","categories":"math.NA,cs.NA,math.AP","published":"2025-04-08T12:54:54Z"}
{"aid":"http://arxiv.org/abs/2504.06004v1","title":"FedFeat+: A Robust Federated Learning Framework Through Federated\n  Aggregation and Differentially Private Feature-Based Classifier Retraining","summary":"In this paper, we propose the FedFeat+ framework, which distinctively\nseparates feature extraction from classification. We develop a two-tiered model\ntraining process: following local training, clients transmit their weights and\nsome features extracted from the feature extractor from the final local epochs\nto the server. The server aggregates these models using the FedAvg method and\nsubsequently retrains the global classifier utilizing the shared features. The\nclassifier retraining process enhances the model's understanding of the\nholistic view of the data distribution, ensuring better generalization across\ndiverse datasets. This improved generalization enables the classifier to\nadaptively influence the feature extractor during subsequent local training\nepochs. We establish a balance between enhancing model accuracy and\nsafeguarding individual privacy through the implementation of differential\nprivacy mechanisms. By incorporating noise into the feature vectors shared with\nthe server, we ensure that sensitive data remains confidential. We present a\ncomprehensive convergence analysis, along with theoretical reasoning regarding\nperformance enhancement and privacy preservation. We validate our approach\nthrough empirical evaluations conducted on benchmark datasets, including\nCIFAR-10, CIFAR-100, MNIST, and FMNIST, achieving high accuracy while adhering\nto stringent privacy guarantees. The experimental results demonstrate that the\nFedFeat+ framework, despite using only a lightweight two-layer CNN classifier,\noutperforms the FedAvg method in both IID and non-IID scenarios, achieving\naccuracy improvements ranging from 3.92 % to 12.34 % across CIFAR-10,\nCIFAR-100, and Fashion-MNIST datasets.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T13:12:38Z"}
{"aid":"http://arxiv.org/abs/2504.06010v1","title":"Latent Multimodal Reconstruction for Misinformation Detection","summary":"Multimodal misinformation, such as miscaptioned images, where captions\nmisrepresent an image's origin, context, or meaning, poses a growing challenge\nin the digital age. To support fact-checkers, researchers have been focusing on\ncreating datasets and developing methods for multimodal misinformation\ndetection (MMD). Due to the scarcity of large-scale annotated MMD datasets,\nrecent studies leverage synthetic training data via out-of-context\nimage-caption pairs or named entity manipulations; altering names, dates, and\nlocations. However, these approaches often produce simplistic misinformation\nthat fails to reflect real-world complexity, limiting the robustness of\ndetection models trained on them. Meanwhile, despite recent advancements, Large\nVision-Language Models (LVLMs) remain underutilized for generating diverse,\nrealistic synthetic training data for MMD. To address this gap, we introduce\n\"MisCaption This!\", a training dataset comprising LVLM-generated miscaptioned\nimages. Additionally, we introduce \"Latent Multimodal Reconstruction\" (LAMAR),\na network trained to reconstruct the embeddings of truthful captions, providing\na strong auxiliary signal to the detection process. To optimize LAMAR, we\nexplore different training strategies (end-to-end training and large-scale\npre-training) and integration approaches (direct, mask, gate, and attention).\nExtensive experiments show that models trained on \"MisCaption This!\" generalize\nbetter on real-world misinformation, while LAMAR sets new state-of-the-art on\nboth NewsCLIPpings and VERITE benchmarks; highlighting the potential of\nLVLM-generated data and reconstruction-based approaches for advancing MMD. We\nrelease our code at:\nhttps://github.com/stevejpapad/miscaptioned-image-reconstruction","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-08T13:16:48Z"}
{"aid":"http://arxiv.org/abs/2504.06031v1","title":"Virtual Agent Tutors in Sheltered Workshops: A Feasibility Study on\n  Attention Training for Individuals with Intellectual Disabilities","summary":"In this work, we evaluate the feasibility of socially assistive virtual\nagent-based cognitive training for people with intellectual disabilities (ID)\nin a sheltered workshop. The Robo- Camp system, originally developed for\nchildren with Attention Deficit Hyperactivity Disorder (ADHD), is adapted based\non the results of a pilot study in which we identified barriers and collected\nfeedback from workshop staff. In a subsequent study, we investigate the aspects\nof usability, technical reliability, attention training capabilities and\nnovelty effect in the feasibility of integrating the RoboCamp system.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-08T13:34:51Z"}
{"aid":"http://arxiv.org/abs/2504.06039v1","title":"Enhanced Anomaly Detection for Capsule Endoscopy Using Ensemble Learning\n  Strategies","summary":"Capsule endoscopy is a method to capture images of the gastrointestinal tract\nand screen for diseases which might remain hidden if investigated with standard\nendoscopes. Due to the limited size of a video capsule, embedding AI models\ndirectly into the capsule demands careful consideration of the model size and\nthus complicates anomaly detection in this field. Furthermore, the scarcity of\navailable data in this domain poses an ongoing challenge to achieving effective\nanomaly detection. Thus, this work introduces an ensemble strategy to address\nthis challenge in anomaly detection tasks in video capsule endoscopies,\nrequiring only a small number of individual neural networks during both the\ntraining and inference phases. Ensemble learning combines the predictions of\nmultiple independently trained neural networks. This has shown to be highly\neffective in enhancing both the accuracy and robustness of machine learning\nmodels. However, this comes at the cost of higher memory usage and increased\ncomputational effort, which quickly becomes prohibitive in many real-world\napplications. Instead of applying the same training algorithm to each\nindividual network, we propose using various loss functions, drawn from the\nanomaly detection field, to train each network. The methods are validated on\nthe two largest publicly available datasets for video capsule endoscopy images,\nthe Galar and the Kvasir-Capsule dataset. We achieve an AUC score of 76.86% on\nthe Kvasir-Capsule and an AUC score of 76.98% on the Galar dataset. Our\napproach outperforms current baselines with significantly fewer parameters\nacross all models, which is a crucial step towards incorporating artificial\nintelligence into capsule endoscopies.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T13:39:39Z"}
{"aid":"http://arxiv.org/abs/2504.06049v1","title":"Directed LS category and directed parametrized topological complexity","summary":"We introduce and study a parametrized analogue of the directed topological\ncomplexity, originally developed by Goubault, Farber, and Sagnier. We establish\nthe fibrewise basic dihomotopy invariance of directed parametrized topological\ncomplexity and explore its relationship with the parametrized topological\ncomplexity. In addition, we introduce the concept of the directed\nLusternik$-$Schnirelmann (LS) category, prove its basic dihomotopy invariance,\nand investigate its connections with both directed topological complexity and\ndirected parametrized topological complexity. As an application, we show that\nthe directed LS category of the directed spheres is equal to two.","main_category":"math.AT","categories":"math.AT","published":"2025-04-08T13:47:09Z"}
{"aid":"http://arxiv.org/abs/2504.06054v1","title":"Thermodynamic formalism for Quasi-Morphisms: Bounded Cohomology and\n  Statistics","summary":"For a compact negatively curved space, we develop a notion of thermodynamic\nformalism and apply it to study the space of quasi-morphisms of its fundamental\ngroup modulo boundedness. We prove that this space is Banach isomorphic to the\nspace of Bowen functions corresponding to the associated Gromov geodesic flow,\nmodulo a weak notion of Livsic cohomology.\n  The results include that each such unbounded quasi-morphism is associated\nwith a unique invariant measure for the flow, and this measure uniquely\ncharacterizes the cohomology class. As a consequence, we establish the Central\nLimit Theorem for any unbounded quasi-morphism with respect to Markov measures,\nthe invariance principle, and the Bernoulli property of the associated\nequilibrium state.","main_category":"math.DS","categories":"math.DS,math.GT","published":"2025-04-08T13:59:30Z"}
{"aid":"http://arxiv.org/abs/2504.06062v1","title":"A characterization of quasi-homogeneity in terms of liftable vector\n  fields","summary":"We prove under certain conditions that any stable unfolding of a\nquasi-homogeneous map-germ with finite singularity type is substantial. We then\nprove that if an equidimensional map-germ is finitely determined, of corank 1,\nand either it admits a minimal stable unfolding or it is of multipliticy 3,\nthen it admits a substantial unfolding if and only if it is quasi-homogeneous.\nBased on this we pose the following conjecture: a finitely determined map-germ\nis quasi-homogeneous if and only if it admits a substantial unfolding.","main_category":"math.AG","categories":"math.AG,math.DS","published":"2025-04-08T14:07:28Z"}
{"aid":"http://arxiv.org/abs/2504.06083v1","title":"Security Analysis of Thumbnail-Preserving Image Encryption and a New\n  Framework","summary":"As a primary encryption primitive balancing the privacy and searchability of\ncloud storage images, thumbnail preserving encryption (TPE) enables users to\nquickly identify the privacy personal image on the cloud and request this image\nfrom the owner through a secure channel. In this paper, we have found that two\ndifferent plaintext images may produce the same thumbnail. It results in the\nfailure of search strategy because the collision of thumbnail occurs. To\naddress this serious security issues, we conduct an in-depth analysis on the\ncollision probabilities of thumbnails, and then propose a new TPE framework,\ncalled multi-factor thumbnail preserving encryption (MFTPE). It starts from the\ncollision probability of two blocks, extend to the probabilities of two images\nand ultimately to N images. Then, we in detail describe three specific MFTPE\nconstructions preserving different combinations of factors, i.e., the sum and\nthe geometric mean, the sum and the range, and the sum and the weighted mean.\nThe theoretical and experimental results demonstrate that the proposed MFTPE\nreduces the probability of thumbnails, exhibits strong robustness, and also\neffectively resists face detection and noise attacks.","main_category":"cs.CR","categories":"cs.CR,cs.MM","published":"2025-04-08T14:24:43Z"}
{"aid":"http://arxiv.org/abs/2504.06123v1","title":"Equating quantum imaginary time evolution, Riemannian gradient flows,\n  and stochastic implementations","summary":"We identify quantum imaginary time evolution as a Riemannian gradient flow on\nthe unitary group. We develop an upper bound for the error between the two\nevolutions that can be controlled through the step size of the Riemannian\ngradient descent which minimizes the energy of the system. We discuss\nimplementations through adaptive quantum algorithms and present a stochastic\nRiemannian gradient descent algorithm in which each step is efficiently\nimplementable on a quantum computer. We prove that for a sufficiently small\nstep size, the stochastic evolution concentrates around the imaginary time\nevolution, thereby providing performance guarantees for cooling the system\nthrough stochastic Riemannian gradient descent.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T15:17:05Z"}
{"aid":"http://arxiv.org/abs/2504.06126v1","title":"Accelerating Vehicle Routing via AI-Initialized Genetic Algorithms","summary":"Vehicle Routing Problems (VRP) are an extension of the Traveling Salesperson\nProblem and are a fundamental NP-hard challenge in combinatorial optimization.\nSolving VRP in real-time at large scale has become critical in numerous\napplications, from growing markets like last-mile delivery to emerging\nuse-cases like interactive logistics planning. Such applications involve\nsolving similar problem instances repeatedly, yet current state-of-the-art\nsolvers treat each instance on its own without leveraging previous examples. We\nintroduce a novel optimization framework that uses a reinforcement learning\nagent - trained on prior instances - to quickly generate initial solutions,\nwhich are then further optimized by genetic algorithms. Our framework,\nEvolutionary Algorithm with Reinforcement Learning Initialization (EARLI),\nconsistently outperforms current state-of-the-art solvers across various time\nscales. For example, EARLI handles vehicle routing with 500 locations within\n1s, 10x faster than current solvers for the same solution quality, enabling\napplications like real-time and interactive routing. EARLI can generalize to\nnew data, as demonstrated on real e-commerce delivery data of a previously\nunseen city. Our hybrid framework presents a new way to combine reinforcement\nlearning and genetic algorithms, paving the road for closer interdisciplinary\ncollaboration between AI and optimization communities towards real-time\noptimization in diverse domains.","main_category":"cs.LG","categories":"cs.LG,cs.NE","published":"2025-04-08T15:21:01Z"}
{"aid":"http://arxiv.org/abs/2504.06148v1","title":"V-MAGE: A Game Evaluation Framework for Assessing Visual-Centric\n  Capabilities in Multimodal Large Language Models","summary":"Recent advancements in Multimodal Large Language Models (MLLMs) have led to\nsignificant improvements across various multimodal benchmarks. However, as\nevaluations shift from static datasets to open-world, dynamic environments,\ncurrent game-based benchmarks remain inadequate because they lack\nvisual-centric tasks and fail to assess the diverse reasoning skills required\nfor real-world decision-making. To address this, we introduce Visual-centric\nMultiple Abilities Game Evaluation (V-MAGE), a game-based evaluation framework\ndesigned to assess visual reasoning capabilities of MLLMs. V-MAGE features five\ndiverse games with 30+ handcrafted levels, testing models on core visual skills\nsuch as positioning, trajectory tracking, timing, and visual memory, alongside\nhigher-level reasoning like long-term planning and deliberation. We use V-MAGE\nto evaluate leading MLLMs, revealing significant challenges in their visual\nperception and reasoning. In all game environments, the top-performing MLLMs,\nas determined by Elo rating comparisons, exhibit a substantial performance gap\ncompared to humans. Our findings highlight critical limitations, including\nvarious types of perceptual errors made by the models, and suggest potential\navenues for improvement from an agent-centric perspective, such as refining\nagent strategies and addressing perceptual inaccuracies. Code is available at\nhttps://github.com/CSU-JPG/V-MAGE.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T15:43:01Z"}
{"aid":"http://arxiv.org/abs/2504.06162v1","title":"A distributional approach to nonlocal curvature flows","summary":"In \\cite{CMP17} a novel distributional approach has been introduced to\nprovide a well-posed formulation of a class of crystalline mean curvature\nflows. In this paper, such an approach is extended to the nonlocal setting.\nApplications include the fractional mean curvature flow and the Minkowski flow;\ni.e., the geometric flow generated by the $(N-1)$-dimensional Minkowski\npre-content.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T15:58:49Z"}
{"aid":"http://arxiv.org/abs/2504.06174v1","title":"On Soft Clustering For Correlation Estimators: Model Uncertainty,\n  Differentiability, and Surrogates","summary":"Properly estimating correlations between objects at different spatial scales\nnecessitates $\\mathcal{O}(n^2)$ distance calculations. For this reason, most\nwidely adopted packages for estimating correlations use clustering algorithms\nto approximate local trends. However, methods for quantifying the error\nintroduced by this clustering have been understudied. In response, we present\nan algorithm for estimating correlations that is probabilistic in the way that\nit clusters objects, enabling us to quantify the uncertainty caused by\nclustering simply through model inference. These soft clustering assignments\nenable correlation estimators that are theoretically differentiable with\nrespect to their input catalogs. Thus, we also build a theoretical framework\nfor differentiable correlation functions and describe their utility in\ncomparison to existing surrogate models. Notably, we find that repeated\nnormalization and distance function calls slow gradient calculations and that\nsparse Jacobians destabilize precision, pointing towards either approximate or\nsurrogate methods as a necessary solution to exact gradients from correlation\nfunctions. To that end, we close with a discussion of surrogate models as\nproxies for correlation functions. We provide an example that demonstrates the\nefficacy of surrogate models to enable gradient-based optimization of\nastrophysical model parameters, successfully minimizing a correlation function\noutput. Our numerical experiments cover science cases across cosmology, from\npoint spread function (PSF) modeling efforts to gravitational simulations to\ngalaxy intrinsic alignment (IA).","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-08T16:18:39Z"}
{"aid":"http://arxiv.org/abs/2504.06195v1","title":"Accuracy Enhancement in Refractive Index Sensing via Full-Spectrum\n  Machine Learning Modeling","summary":"We present a full-spectrum machine learning framework for refractive index\nsensing using simulated absorption spectra from meta-grating structures\ncomposed of titanium or silicon nanorods under TE and TM polarizations. Linear\nregression was applied to 80 principal components extracted from each spectrum,\nand model performance was assessed using five-fold cross-validation, simulating\nreal-world biosensing scenarios where unknown patient samples are predicted\nbased on standard calibration data. Titanium-based structures, dominated by\nbroadband intensity changes, yielded the lowest mean squared errors and the\nhighest accuracy improvements: up to a 6065-fold reduction compared to the best\nsingle-feature model. In contrast, silicon-based structures, governed by narrow\nresonances, showed more modest gains due to spectral nonlinearity that limits\nthe effectiveness of global linear models. We also show that even the best\nsingle-wavelength predictor is identified through data-driven analysis, not\nvisual selection, highlighting the value of automated feature preselection.\nThese findings demonstrate that spectral shape plays a key role in modeling\nperformance and that full-spectrum linear approaches are especially effective\nfor intensity-modulated index sensors.","main_category":"physics.optics","categories":"physics.optics,physics.med-ph,q-bio.QM","published":"2025-04-08T16:37:53Z"}
{"aid":"http://arxiv.org/abs/2504.06201v1","title":"Quantum Annealing for Combinatorial Optimization: A Benchmarking Study","summary":"Quantum annealing (QA) has the potential to significantly improve solution\nquality and reduce time complexity in solving combinatorial optimization\nproblems compared to classical optimization methods. However, due to the\nlimited number of qubits and their connectivity, the QA hardware did not show\nsuch an advantage over classical methods in past benchmarking studies. Recent\nadvancements in QA with more than 5,000 qubits, enhanced qubit connectivity,\nand the hybrid architecture promise to realize the quantum advantage. Here, we\nuse a quantum annealer with state-of-the-art techniques and benchmark its\nperformance against classical solvers. To compare their performance, we solve\nover 50 optimization problem instances represented by large and dense\nHamiltonian matrices using quantum and classical solvers. The results\ndemonstrate that a state-of-the-art quantum solver has higher accuracy\n(~0.013%) and a significantly faster problem-solving time (~6,561x) than the\nbest classical solver. Our results highlight the advantages of leveraging QA\nover classical counterparts, particularly in hybrid configurations, for\nachieving high accuracy and substantially reduced problem solving time in\nlarge-scale real-world optimization problems.","main_category":"quant-ph","categories":"quant-ph,cs.CE","published":"2025-04-08T16:43:24Z"}
{"aid":"http://arxiv.org/abs/2504.06219v1","title":"Can Performant LLMs Be Ethical? Quantifying the Impact of Web Crawling\n  Opt-Outs","summary":"The increasing adoption of web crawling opt-outs by copyright holders of\nonline content raises critical questions about the impact of data compliance on\nlarge language model (LLM) performance. However, little is known about how\nthese restrictions (and the resultant filtering of pretraining datasets) affect\nthe capabilities of models trained using these corpora. In this work, we\nconceptualize this effect as the $\\textit{data compliance gap}$ (DCG), which\nquantifies the performance difference between models trained on datasets that\ncomply with web crawling opt-outs, and those that do not. We measure the data\ncompliance gap in two settings: pretraining models from scratch and continual\npretraining from existing compliant models (simulating a setting where\ncopyrighted data could be integrated later in pretraining). Our experiments\nwith 1.5B models show that, as of January 2025, compliance with web data\nopt-outs does not degrade general knowledge acquisition (close to 0\\% DCG).\nHowever, in specialized domains such as biomedical research, excluding major\npublishers leads to performance declines. These findings suggest that while\ngeneral-purpose LLMs can be trained to perform equally well using fully open\ndata, performance in specialized domains may benefit from access to\nhigh-quality copyrighted sources later in training. Our study provides\nempirical insights into the long-debated trade-off between data compliance and\ndownstream model performance, informing future discussions on AI training\npractices and policy decisions.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-08T17:08:06Z"}
{"aid":"http://arxiv.org/abs/2504.06220v1","title":"Earth-Adapter: Bridge the Geospatial Domain Gaps with Mixture of\n  Frequency Adaptation","summary":"Parameter-Efficient Fine-Tuning (PEFT) is a technique that allows us to adapt\npowerful Foundation Models (FMs) to diverse downstream tasks while preserving\nand unleashing their inherent capabilities. However, we have observed that\nexisting PEFT methods, which are often designed with natural imagery in mind,\nstruggle when applied to Remote Sensing (RS) scenarios. This is primarily due\nto their inability to handle artifact influences, a problem particularly severe\nin RS image features. To tackle this challenge, we introduce Earth-Adapter, the\nfirst PEFT method specifically designed for RS artifacts conquering.\nEarth-Adapter introduces a novel Mixture of Frequency Adaptation process that\ncombines a Mixture of Adapter (MoA) with Discrete Fourier Transformation (DFT).\nBy utilizing DFT, Earth-Adapter can decompose features into different frequency\ncomponents, precisely separating artifacts from original features. The MoA then\ndynamically assigns weights to each adapter expert, allowing for the\ncombination of features across various frequency domains. These\nsimple-yet-effective approaches enable Earth-Adapter to more efficiently\novercome the disturbances caused by artifacts than previous PEFT methods,\nsignificantly enhancing the FMs' performance on RS scenarios. Experiments on\nDomain Adaptation (DA), and Domain Generalization (DG) semantic segmentation\nbenchmarks showcase the Earth-Adapter's effectiveness. Compared with baseline\nRein, Earth-Adapter significantly improves 9.0% mIoU in DA and 3.1% mIoU in DG\nbenchmarks. Our code will be released at\nhttps://github.com/VisionXLab/Earth-Adapter.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T17:09:33Z"}
{"aid":"http://arxiv.org/abs/2504.06229v1","title":"Continuous-variable spatio-spectral quantum networks in nonlinear\n  photonic lattices","summary":"Multiplexing information in different degrees of freedom and use of\nintegrated and fiber-optic components are natural solutions to the scalability\nbottleneck in optical quantum communications and computing. However, for\nbulk-optics systems, where size, cost, stability, and reliability are factors,\nthis remains either impractical or highly challenging to implement. In this\npaper we present a framework to engineer continuous-variable entanglement\nproduced through nondegenerate spontaneous parametric down-conversion in\n\\chi^(2) nonlinear photonic lattices in spatial and spectral degrees of freedom\nthat can solve the scalability challenge. We show how spatio-spectral pump\nshaping produce cluster states that are naturally distributable in quantum\ncommunication networks and a resource for measurement-based quantum computing.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-08T17:24:00Z"}
{"aid":"http://arxiv.org/abs/2504.06267v1","title":"Prethermalization of light and matter in cavity-coupled Rydberg arrays","summary":"We explore the dynamics of two-dimensional Rydberg atom arrays coupled to a\nsingle-mode optical cavity, employing nonequilibrium diagrammatic techniques to\ncapture nonlinearities and fluctuations beyond mean-field theory. We discover a\nnovel prethermalization regime driven by the interplay between short-range\nRydberg interactions and long-range photon-mediated interactions. In this\nregime, matter and light equilibrate at distinct - and in some cases opposite -\neffective temperatures, resembling the original concept of prethermalization\nfrom particle physics. Our results establish strongly correlated AMO platforms\nas tools to investigate fundamental questions in statistical mechanics,\nincluding quantum thermalization in higher-dimensional systems.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,quant-ph","published":"2025-04-08T17:59:59Z"}
{"aid":"http://arxiv.org/abs/2504.06560v1","title":"NeedleInATable: Exploring Long-Context Capability of Large Language\n  Models towards Long-Structured Tables","summary":"Processing structured tabular data, particularly lengthy tables, constitutes\na fundamental yet challenging task for large language models (LLMs). However,\nexisting long-context benchmarks primarily focus on unstructured text,\nneglecting the challenges of long and complex structured tables. To address\nthis gap, we introduce NeedleInATable (NIAT), a novel task that treats each\ntable cell as a \"needle\" and requires the model to extract the target cell\nunder different queries. Evaluation results of mainstream LLMs on this\nbenchmark show they lack robust long-table comprehension, often relying on\nsuperficial correlations or shortcuts for complex table understanding tasks,\nrevealing significant limitations in processing intricate tabular data. To this\nend, we propose a data synthesis method to enhance models' long-table\ncomprehension capabilities. Experimental results show that our synthesized\ntraining data significantly enhances LLMs' performance on the NIAT task,\noutperforming both long-context LLMs and long-table agent methods. This work\nadvances the evaluation of LLMs' genuine long-structured table comprehension\ncapabilities and paves the way for progress in long-context and table\nunderstanding applications.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T03:46:56Z"}
{"aid":"http://arxiv.org/abs/2504.06573v1","title":"Mutation Cycles from Reddening Sequences","summary":"Given two quivers, each with a reddening sequence, we show how to construct a\nplethora of mutation cycles. We give several examples, including a\ngeneralization of the construction of long mutation cycles in earlier work by\nthe second author. We also give new results on the reddening sequences of\ncertain mutation-acyclic quivers and forks, classifying them in some cases.","main_category":"math.CO","categories":"math.CO","published":"2025-04-09T04:21:51Z"}
{"aid":"http://arxiv.org/abs/2504.06594v1","title":"Machine Learning for Extrapolating No-Core Shell Model Results to\n  Infinite Basis","summary":"We utilize the machine learning to extrapolate to the infinite model space\nthe no-core shell model (NCSM) results for the energies and rms radii of the\n6He ground state and 6Li lowest states. The extrapolated energies and rms radii\nconverge as the NCSM results from larger model spaces are included in the\ntraining dataset for ensemble of artificial neural networks thus enabling an\naccurate predictions for these observables.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-09T05:42:41Z"}
{"aid":"http://arxiv.org/abs/2504.06598v1","title":"Stochastic Ray Tracing of 3D Transparent Gaussians","summary":"3D Gaussian splatting has recently been widely adopted as a 3D representation\nfor novel-view synthesis, relighting, and text-to-3D generation tasks, offering\nrealistic and detailed results through a collection of explicit 3D Gaussians\ncarrying opacities and view-dependent colors. However, efficient rendering of\nmany transparent primitives remains a significant challenge. Existing\napproaches either rasterize the 3D Gaussians with approximate sorting per view\nor rely on high-end RTX GPUs to exhaustively process all ray-Gaussian\nintersections (bounding Gaussians by meshes). This paper proposes a stochastic\nray tracing method to render 3D clouds of transparent primitives. Instead of\nprocessing all ray-Gaussian intersections in sequential order, each ray\ntraverses the acceleration structure only once, randomly accepting and shading\na single intersection (or N intersections, using a simple extension). This\napproach minimizes shading time and avoids sorting the Gaussians along the ray\nwhile minimizing the register usage and maximizing parallelism even on low-end\nGPUs. The cost of rays through the Gaussian asset is comparable to that of\nstandard mesh-intersection rays. While our method introduces noise, the shading\nis unbiased, and the variance is slight, as stochastic acceptance is\nimportance-sampled based on accumulated opacity. The alignment with the Monte\nCarlo philosophy simplifies implementation and easily integrates our method\ninto a conventional path-tracing framework.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-09T05:49:05Z"}
{"aid":"http://arxiv.org/abs/2504.06600v1","title":"Automated Business Process Analysis: An LLM-Based Approach to Value\n  Assessment","summary":"Business processes are fundamental to organizational operations, yet their\noptimization remains challenging due to the timeconsuming nature of manual\nprocess analysis. Our paper harnesses Large Language Models (LLMs) to automate\nvalue-added analysis, a qualitative process analysis technique that aims to\nidentify steps in the process that do not deliver value. To date, this\ntechnique is predominantly manual, time-consuming, and subjective. Our method\noffers a more principled approach which operates in two phases: first,\ndecomposing high-level activities into detailed steps to enable granular\nanalysis, and second, performing a value-added analysis to classify each step\naccording to Lean principles. This approach enables systematic identification\nof waste while maintaining the semantic understanding necessary for qualitative\nanalysis. We develop our approach using 50 business process models, for which\nwe collect and publish manual ground-truth labels. Our evaluation, comparing\nzero-shot baselines with more structured prompts reveals (a) a consistent\nbenefit of structured prompting and (b) promising performance for both tasks.\nWe discuss the potential for LLMs to augment human expertise in qualitative\nprocess analysis while reducing the time and subjectivity inherent in manual\napproaches.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.SE","published":"2025-04-09T05:52:50Z"}
{"aid":"http://arxiv.org/abs/2504.06617v1","title":"Spectrum radii of trees","summary":"For any positive integer $r$ and positive number $\\alpha$, let ${\\mathscr\nW}_r(\\alpha)$ denote the set of positive numbers defined recursively:\n$\\alpha\\in {\\mathscr W}_r(\\alpha)$, and for any multi-set $\\{q_i\\in {\\mathscr\nW}_r(\\alpha): 1\\le i\\le s\\}$, where $1\\le s<r$,\n$\\beta:=\\alpha-\\sum\\limits_{i=1}^sq_i^{-1}$ belongs to ${\\mathscr W}_r(\\alpha)$\nas long as $\\beta>0$. We first show that there exists a tree $T$ such that its\nmaximum degree $\\Delta(T)$ is at most $r$ and its spectrum radius $\\lambda(T)$\nis equal to $\\alpha$ if and only if $\\alpha^{-1}\\in {\\mathscr W}_r(\\alpha)$. It\nfollows that the set of spectrum radii of non-trivial trees is exactly the set\nof positive numbers $\\alpha$ such that $\\alpha^{-1}\\in {\\mathscr\nW}_{\\lfloor\\alpha^2\\rfloor}(\\alpha)$. Applying this conclusion, we then prove\nthat for any positive integers $r$ and $k$, there exists a tree $T$ with\n$\\Delta(T)=r$ and $\\lambda(T)=\\sqrt k$ if and only if $\\frac 14 k+1<r\\le k$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-09T06:30:32Z"}
{"aid":"http://arxiv.org/abs/2504.06621v1","title":"Computation of shape Taylor expansions","summary":"Shape derivative is an important analytical tool for studying scattering\nproblems involving perturbations in scatterers. Many applications, including\ninverse scattering, optimal design, and uncertainty quantification, are based\non shape derivatives. However, computing high order shape derivatives is\nchallenging due to the complexity of shape calculus. This work introduces a\ncomprehensive method for computing shape Taylor expansions in two dimensions\nusing recurrence formulas. The approach is developed under sound-soft,\nsound-hard, impedance, and transmission boundary conditions. Additionally, we\napply the shape Taylor expansion to uncertainty quantification in wave\nscattering, enabling high order moment estimation for the scattered field under\nrandom boundary perturbations. Numerical examples are provided to illustrate\nthe effectiveness of the shape Taylor expansion in achieving high order\napproximations.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-09T06:42:21Z"}
{"aid":"http://arxiv.org/abs/2504.06654v1","title":"Finiteness of projective pluricanonical representation for automorphisms\n  of complex manifolds","summary":"We study the action of the group of bimeromorphic automorphisms\n$\\mathrm{Bim}(X)$ of a compact complex manifold $X$ on the image of the\npluricanonical map, which we call the projective pluricanonical representation\nof this group. If $X$ is a Moishezon variety, then the image of\n$\\mathrm{Bim}(X)$ via such a representation is a finite group by a classical\nresult due to Deligne and Ueno. We prove that this image is a finite group\nunder the assumption that for the Kodaira dimension $\\kappa(X)$ of $X$ we have\n$\\kappa(X)=\\dim X-1$. To this aim, we prove a version of the canonical bundle\nformula in relative dimension $1$ which works for a proper morphism from a\ncomplex variety to a projective variety. In particular, this establishes the\nanalytic version of Prokhorov--Shokurov conjecture in relative dimension $1$.\nAlso, we observe that the analytic version of this conjecture does not hold in\nrelative dimension $2$.","main_category":"math.AG","categories":"math.AG","published":"2025-04-09T07:45:16Z"}
{"aid":"http://arxiv.org/abs/2504.06659v1","title":"Bridging the Gap Between Preference Alignment and Machine Unlearning","summary":"Despite advances in Preference Alignment (PA) for Large Language Models\n(LLMs), mainstream methods like Reinforcement Learning with Human Feedback\n(RLHF) face notable challenges. These approaches require high-quality datasets\nof positive preference examples, which are costly to obtain and computationally\nintensive due to training instability, limiting their use in low-resource\nscenarios. LLM unlearning technique presents a promising alternative, by\ndirectly removing the influence of negative examples. However, current research\nhas primarily focused on empirical validation, lacking systematic quantitative\nanalysis. To bridge this gap, we propose a framework to explore the\nrelationship between PA and LLM unlearning. Specifically, we introduce a\nbi-level optimization-based method to quantify the impact of unlearning\nspecific negative examples on PA performance. Our analysis reveals that not all\nnegative examples contribute equally to alignment improvement when unlearned,\nand the effect varies significantly across examples. Building on this insight,\nwe pose a crucial question: how can we optimally select and weight negative\nexamples for unlearning to maximize PA performance? To answer this, we propose\na framework called Unlearning to Align (U2A), which leverages bi-level\noptimization to efficiently select and unlearn examples for optimal PA\nperformance. We validate the proposed method through extensive experiments,\nwith results confirming its effectiveness.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-09T07:49:08Z"}
{"aid":"http://arxiv.org/abs/2504.06669v1","title":"NLP Security and Ethics, in the Wild","summary":"As NLP models are used by a growing number of end-users, an area of\nincreasing importance is NLP Security (NLPSec): assessing the vulnerability of\nmodels to malicious attacks and developing comprehensive countermeasures\nagainst them. While work at the intersection of NLP and cybersecurity has the\npotential to create safer NLP for all, accidental oversights can result in\ntangible harm (e.g., breaches of privacy or proliferation of malicious models).\nIn this emerging field, however, the research ethics of NLP have not yet faced\nmany of the long-standing conundrums pertinent to cybersecurity, until now. We\nthus examine contemporary works across NLPSec, and explore their engagement\nwith cybersecurity's ethical norms. We identify trends across the literature,\nultimately finding alarming gaps on topics like harm minimization and\nresponsible disclosure. To alleviate these concerns, we provide concrete\nrecommendations to help NLP researchers navigate this space more ethically,\nbridging the gap between traditional cybersecurity and NLP ethics, which we\nframe as ``white hat NLP''. The goal of this work is to help cultivate an\nintentional culture of ethical research for those working in NLP Security.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-09T08:12:34Z"}
{"aid":"http://arxiv.org/abs/2504.06671v1","title":"Defects in Silicon Carbide as Quantum Qubits: Recent Advances in Defect\n  Engineering","summary":"This review provides an overview of defects in silicon carbide (SiC) with\npotential applications as quantum qubits. It begins with a brief introduction\nto quantum qubits and existing qubit platforms, outlining the essential\ncriteria a defect must meet to function as a viable qubit. The focus then\nshifts to the most promising defects in SiC, notably the silicon vacancy (VSi)\nand divacancy (VC-VSi). A key challenge in utilizing these defects for quantum\napplications is their precise and controllable creation. Various fabrication\ntechniques, including irradiation, ion implantation, femtosecond laser\nprocessing, and focused ion beam methods, have been explored to create these\ndefects. Designed as a beginner-friendly resource, this review aims to support\nearly-career experimental researchers entering the field of SiC-related quantum\nqubits. Providing an introduction to defect-based qubits in SiC offers valuable\ninsights into fabrication strategies, recent progress, and the challenges that\nlie ahead.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,quant-ph","published":"2025-04-09T08:13:58Z"}
{"aid":"http://arxiv.org/abs/2504.06702v1","title":"Consensus-based qubit configuration optimization for variational\n  algorithms on neutral atom quantum systems","summary":"In this work, we report an algorithm that is able to tailor qubit\ninteractions for individual variational quantum algorithm problems. Here, the\nalgorithm leverages the unique ability of a neutral atom tweezer platform to\nrealize arbitrary qubit position configurations. These configurations determine\nthe degree of entanglement available to a variational quantum algorithm via the\ninteratomic interactions. Good configurations will accelerate pulse\noptimization convergence and help mitigate barren plateaus. As gradient-based\napproaches are ineffective for position optimization due to the divergent\n$R^{-6}$ nature of neutral atom interactions, we opt to use a consensus-based\nalgorithm to optimize the qubit positions. By sampling the configuration space\ninstead of using gradient information, the consensus-based algorithm is able to\nsuccessfully optimize the positions, yielding adapted variational quantum\nalgorithm ansatzes that lead to both faster convergence and lower errors. In\nthis work, we show that these optimized configurations generally result in\nlarge improvements in the system's ability to solve ground state minimization\nproblems for both random Hamiltonians and small molecules.","main_category":"quant-ph","categories":"quant-ph,physics.atom-ph","published":"2025-04-09T09:07:49Z"}
{"aid":"http://arxiv.org/abs/2504.06704v1","title":"CAT: Circular-Convolutional Attention for Sub-Quadratic Transformers","summary":"Transformers have driven remarkable breakthroughs in natural language\nprocessing and computer vision, yet their standard attention mechanism still\nimposes O(N^2) complexity, hindering scalability to longer sequences. We\nintroduce Circular-convolutional ATtention (CAT), a Fourier-based approach that\nefficiently applies circular convolutions to reduce complexity without\nsacrificing representational power. CAT achieves O(NlogN) computations,\nrequires fewer learnable parameters by streamlining fully-connected layers, and\nintroduces no heavier operations, resulting in consistent accuracy improvements\nand about a 10% speedup in naive PyTorch implementations on large-scale\nbenchmarks such as ImageNet-1k and WikiText-103. Grounded in an\nengineering-isomorphism framework, CAT's design not only offers practical\nefficiency and ease of implementation but also provides insights to guide the\ndevelopment of next-generation, high-performance Transformer architectures.\nFinally, our ablation studies highlight the key conditions underlying CAT's\nsuccess, shedding light on broader principles for scalable attention\nmechanisms.","main_category":"cs.LG","categories":"cs.LG,cs.CL,cs.CV","published":"2025-04-09T09:08:26Z"}
{"aid":"http://arxiv.org/abs/2504.06707v1","title":"Phase transition of the kinetic Justh-Krishnaprasad type model for\n  nematic alignment","summary":"We present a stochastic Justh-Krishnaprasad flocking model and study the\nphase transition of the Vlasov-McKean-Fokker-Planck (VMFP) equation, which can\nbe obtained in the mean-field limit. To describe the alignment, we use order\nparameters in terms of the distribution function of the kinetic model. For the\nconstant noise case, we study the well-posedness of the VMFP equation on the\ntorus. Based on regularity, we show that the phenomenon of phase transition is\nonly related to the ratio between the strengths of noise and coupling. In\nparticular, for the low-noise case, we derive an exponential convergence to the\nvon-Mises type equilibrium, which shows a strong evidence for the nematic\nalignment. The multiplicative noise is also studied to obtain a non-symmetric\nequilibrium with two different peaks on the torus.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T09:09:24Z"}
{"aid":"http://arxiv.org/abs/2504.06708v1","title":"Transport of electrolytes across nanochannels: the role of slip","summary":"We characterize the electrokinetic flow due to the transport of electrolytes\nembedded in nanochannels of varying cross-section with inhomogeneous slip on\ntheir walls, modeled as an effective slip length on the channel wall. We show\nthat, within linear response and Debye-Huckel regime, the transport\ncoefficients, and so the fluxes, can be significantly improved by the presence\nof a hydrophobic surface coating located at the narrowest section of the\nnanochannel. Our model indicates that the enhancement is larger when\nconsidering electric conductive walls in comparison to dielectric microchannel\nwalls, and it is produced by a synergy between the entropic effects due to the\ngeometry and the presence of the slip boundary layer. Our results show that a\ntailored hydrophobic coating design can be an effective strategy to improve\ntransport properties in the broad areas of lab-on-a-chip, biophysics, and blue\nenergy harvesting and energy conversion technologies.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cond-mat.soft","published":"2025-04-09T09:09:52Z"}
{"aid":"http://arxiv.org/abs/2504.06718v1","title":"Ice-Breakers, Turn-Takers and Fun-Makers: Exploring Robots for Groups\n  with Teenagers","summary":"Successful, enjoyable group interactions are important in public and personal\ncontexts, especially for teenagers whose peer groups are important for\nself-identity and self-esteem. Social robots seemingly have the potential to\npositively shape group interactions, but it seems difficult to effect such\nimpact by designing robot behaviors solely based on related (human interaction)\nliterature. In this article, we take a user-centered approach to explore how\nteenagers envisage a social robot \"group assistant\". We engaged 16 teenagers in\nfocus groups, interviews, and robot testing to capture their views and\nreflections about robots for groups. Over the course of a two-week summer\nschool, participants co-designed the action space for such a robot and\nexperienced working with/wizarding it for 10+ hours. This experience further\naltered and deepened their insights into using robots as group assistants. We\nreport results regarding teenagers' views on the applicability and use of a\nrobot group assistant, how these expectations evolved throughout the study, and\ntheir repeat interactions with the robot. Our results indicate that each group\nmoves on a spectrum of need for the robot, reflected in use of the robot more\n(or less) for ice-breaking, turn-taking, and fun-making as the situation\ndemanded.","main_category":"cs.RO","categories":"cs.RO,cs.HC","published":"2025-04-09T09:19:24Z"}
{"aid":"http://arxiv.org/abs/2504.06730v1","title":"PETNet -- Coincident Particle Event Detection using Spiking Neural\n  Networks","summary":"Spiking neural networks (SNN) hold the promise of being a more biologically\nplausible, low-energy alternative to conventional artificial neural networks.\nTheir time-variant nature makes them particularly suitable for processing\ntime-resolved, sparse binary data. In this paper, we investigate the potential\nof leveraging SNNs for the detection of photon coincidences in positron\nemission tomography (PET) data. PET is a medical imaging technique based on\ninjecting a patient with a radioactive tracer and detecting the emitted\nphotons. One central post-processing task for inferring an image of the tracer\ndistribution is the filtering of invalid hits occurring due to e.g. absorption\nor scattering processes. Our approach, coined PETNet, interprets the detector\nhits as a binary-valued spike train and learns to identify photon coincidence\npairs in a supervised manner. We introduce a dedicated multi-objective loss\nfunction and demonstrate the effects of explicitly modeling the detector\ngeometry on simulation data for two use-cases. Our results show that PETNet can\noutperform the state-of-the-art classical algorithm with a maximal coincidence\ndetection $F_1$ of 95.2%. At the same time, PETNet is able to predict photon\ncoincidences up to 36 times faster than the classical approach, highlighting\nthe great potential of SNNs in particle physics applications.","main_category":"cs.LG","categories":"cs.LG,hep-ex","published":"2025-04-09T09:38:45Z"}
{"aid":"http://arxiv.org/abs/2504.06733v1","title":"Timing the Escape of a Caged Electron","summary":"Charge transfer is fundamentally dependent on the overlap of the orbitals\ncomprising the transport pathway. This has key implications for molecular,\nnanoscale, and quantum technologies, for which delocalization (and decoherence)\nrates are essential figures of merit. Here, we apply the core hole clock\ntechnique - an energy-domain variant of ultrafast spectroscopy - to probe the\ndelocalization of a photoexcited electron inside a closed molecular cage,\nnamely the Ar 2p54s1 state of Ar@C60. Despite marginal frontier orbital mixing\nin the ground configuration, almost 80% of the excited state density is found\noutside the buckyball due to the formation of a markedly diffuse hybrid\norbital. Far from isolating the intracage excitation, the surrounding fullerene\nis instead a remarkably efficient conduit for electron transfer: we measure\ncharacteristic delocalization times of 6.6 $\\pm$ 0.3 fs and $\\lesssim$ 500\nattoseconds, respectively, for a 3D Ar@C60 film and a 2D monolayer on Ag(111).","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-09T09:45:23Z"}
{"aid":"http://arxiv.org/abs/2504.06746v1","title":"Adaptive Human-Robot Collaborative Missions using Hybrid Task Planning","summary":"Producing robust task plans in human-robot collaborative missions is a\ncritical activity in order to increase the likelihood of these missions\ncompleting successfully. Despite the broad research body in the area, which\nconsiders different classes of constraints and uncertainties, its applicability\nis confined to relatively simple problems that can be comfortably addressed by\nthe underpinning mathematically-based or heuristic-driven solver engines. In\nthis paper, we introduce a hybrid approach that effectively solves the task\nplanning problem by decomposing it into two intertwined parts, starting with\nthe identification of a feasible plan and followed by its uncertainty\naugmentation and verification yielding a set of Pareto optimal plans. To\nenhance its robustness, adaptation tactics are devised for the evolving system\nrequirements and agents' capabilities. We demonstrate our approach through an\nindustrial case study involving workers and robots undertaking activities\nwithin a vineyard, showcasing the benefits of our hybrid approach both in the\ngeneration of feasible solutions and scalability compared to native planners.","main_category":"cs.MA","categories":"cs.MA,cs.RO","published":"2025-04-09T10:07:15Z"}
{"aid":"http://arxiv.org/abs/2504.06770v1","title":"Measuring and predicting galaxy assembly bias across galaxy samples","summary":"One of the most important effects shaping small-scale galaxy clustering is\ngalaxy assembly bias, which refers to the dependence of galaxy clustering on\nhalo properties. We investigate this effect using galaxy samples selected\naccording to stellar mass, r-band magnitude, and broad-band colors from the\nlargest hydrodynamical simulation of the IllustrisTNG suite. We find that\ngalaxy assembly bias depends strongly upon the selection criteria, number\ndensity, and redshift of the sample, increasing or decreasing the clustering by\nas much as 25%. Interestingly, no single secondary halo property fully captures\nthe strength of this effect for any galaxy population. Therefore, empirical\napproaches modeling galaxy assembly bias as a function of a single halo\nproperty cannot reproduce predictions from hydrodynamical simulations. We then\nstudy how galaxy assembly bias emerges from the interplay of halo assembly bias\n-- the dependence of halo clustering on properties other than mass -- and\noccupancy variation -- the correlation between galaxy occupation and secondary\nhalo properties -- and provide an analytical expression that predicts the\namount of galaxy assembly bias caused by any halo property. This expression\nfacilitates understanding the dependence of galaxy assembly bias on halo\nproperties and enables the straightforward incorporation of this effect into\nhalo model approaches.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.GA","published":"2025-04-09T10:48:08Z"}
{"aid":"http://arxiv.org/abs/2504.06772v1","title":"Towards Efficient Roadside LiDAR Deployment: A Fast Surrogate Metric\n  Based on Entropy-Guided Visibility","summary":"The deployment of roadside LiDAR sensors plays a crucial role in the\ndevelopment of Cooperative Intelligent Transport Systems (C-ITS). However, the\nhigh cost of LiDAR sensors necessitates efficient placement strategies to\nmaximize detection performance. Traditional roadside LiDAR deployment methods\nrely on expert insight, making them time-consuming. Automating this process,\nhowever, demands extensive computation, as it requires not only visibility\nevaluation but also assessing detection performance across different LiDAR\nplacements. To address this challenge, we propose a fast surrogate metric, the\nEntropy-Guided Visibility Score (EGVS), based on information gain to evaluate\nobject detection performance in roadside LiDAR configurations. EGVS leverages\nTraffic Probabilistic Occupancy Grids (TPOG) to prioritize critical areas and\nemploys entropy-based calculations to quantify the information captured by\nLiDAR beams. This eliminates the need for direct detection performance\nevaluation, which typically requires extensive labeling and computational\nresources. By integrating EGVS into the optimization process, we significantly\naccelerate the search for optimal LiDAR configurations. Experimental results\nusing the AWSIM simulator demonstrate that EGVS strongly correlates with\nAverage Precision (AP) scores and effectively predicts object detection\nperformance. This approach offers a computationally efficient solution for\nroadside LiDAR deployment, facilitating scalable smart infrastructure\ndevelopment.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-09T10:53:03Z"}
{"aid":"http://arxiv.org/abs/2504.06812v1","title":"Semi-classical geometric tensor in multiparameter quantum information","summary":"The quantum geometric tensor (QGT) captures the variations of quantum states\nwith parameters, serving as a central concept in modern quantum physics. Its\nreal part, the quantum Fisher information matrix (QFIM), has a\nmeasurement-dependent counterpart that links statistics to distinguishability.\nHowever, an analogous extension for the QGT is hindered by the fundamental\ninaccessibility of its imaginary part through measurement probabilities. Here\nwe introduce a counterpart to the QGT that includes measurement operators,\ntermed the \\textit{semi-classical} geometric tensor (SCGT). We show that the\nSCGT provides a lower bound to the QGT that is tight for pure states. Moreover,\nwe use the SCGT to derive sharp multiparameter information bounds and discuss\nextensions of the Berry phase.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-09T12:06:57Z"}
{"aid":"http://arxiv.org/abs/2504.06819v1","title":"Developing Modular Grasping and Manipulation Pipeline Infrastructure to\n  Streamline Performance Benchmarking","summary":"The robot manipulation ecosystem currently faces issues with integrating\nopen-source components and reproducing results. This limits the ability of the\ncommunity to benchmark and compare the performance of different solutions to\none another in an effective manner, instead relying on largely holistic\nevaluations. As part of the COMPARE Ecosystem project, we are developing\nmodular grasping and manipulation pipeline infrastructure in order to\nstreamline performance benchmarking. The infrastructure will be used towards\nthe establishment of standards and guidelines for modularity and improved\nopen-source development and benchmarking. This paper provides a high-level\noverview of the architecture of the pipeline infrastructure, experiments\nconducted to exercise it during development, and future work to expand its\nmodularity.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-09T12:24:42Z"}
{"aid":"http://arxiv.org/abs/2504.06826v1","title":"Long-period double-lined eclipsing binaries: the system V454 Aur with\n  the secondary eclipse caused by the occultation of the hotter component","summary":"We present the results of our study of the long-period eclipsing binary star\n\\Aur. The results are based on spectroscopic data obtained with the UFES\n\\'echelle spectrograph and photometric observations from TESS. The derived\nradial velocity curve is based on 17 spectra obtained between 2021 and 2023,\ncovering all orbital phases of this binary system. The orbital period\ndetermined from TESS data, $P = 27.019803 \\pm 0.000003$ days, agrees within\nuncertainties with the period established in previous studies. The model\nconstructed for the TESS photometric light curve achieves a precision of\n0.01\\%. The effective temperatures of both components, as well as the system\nmetallicity, were directly derived from the spectra and are $T_\\mathrm{eff, A}\n= 6250 \\pm 50$\\,K, $T_\\mathrm{eff, B} = 5855 \\pm 50$\\,K, and $\\mathrm{[Fe/H]} =\n-0.10 \\pm 0.08$, respectively. Our analysis of the photometric and\nspectroscopic data allowed us to directly compute the luminosities of the\ncomponents, $L_A = 1.82\\,L_\\odot$ and $L_B = 1.07\\,L_\\odot$, their radii, $R_A\n= 1.15\\,R_\\odot$ and $R_B = 1.00\\,R_\\odot$, and their masses, $M_A =\n1.137\\,M_\\odot$ and $M_B = 1.023\\,M_\\odot$, with uncertainties below 1\\%.\nComparison with evolutionary tracks indicates that the system's age is $1.18\n\\pm 0.10$\\,Gyr, and both components are still on the main sequence. The \\Aur\\\nsystem is particularly interesting due to the partial eclipse of the primary\ncomponent, which results in the ``inversion'' of the primary and secondary\nminima in the photometric light curve.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-09T12:34:35Z"}
{"aid":"http://arxiv.org/abs/2504.06843v1","title":"Integrating Cognitive Processing Signals into Language Models: A Review\n  of Advances, Applications and Future Directions","summary":"Recently, the integration of cognitive neuroscience in Natural Language\nProcessing (NLP) has gained significant attention. This article provides a\ncritical and timely overview of recent advancements in leveraging cognitive\nsignals, particularly Eye-tracking (ET) signals, to enhance Language Models\n(LMs) and Multimodal Large Language Models (MLLMs). By incorporating\nuser-centric cognitive signals, these approaches address key challenges,\nincluding data scarcity and the environmental costs of training large-scale\nmodels. Cognitive signals enable efficient data augmentation, faster\nconvergence, and improved human alignment. The review emphasises the potential\nof ET data in tasks like Visual Question Answering (VQA) and mitigating\nhallucinations in MLLMs, and concludes by discussing emerging challenges and\nresearch trends.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-09T13:01:48Z"}
{"aid":"http://arxiv.org/abs/2504.06862v1","title":"Dynamics of critical cascades in interdependent networks","summary":"The collapse of interdependent networks, as well as similar avalanche\nphenomena, is driven by cascading failures. At the critical point, the cascade\nbegins as a critical branching process, where each failing node (element)\ntriggers, on average, the failure of one other node. As nodes continue to fail,\nthe network becomes increasingly fragile and the branching factor grows. If the\nfailure process does not reach extinction during its critical phase, the\nnetwork undergoes an abrupt collapse. Here, we implement the analogy between\nthis dynamic and birth-death processes to derive new analytical results and\nsignificantly optimize numerical calculations. Using this approach, we analyze\nthree key aspects of the dynamics: the probability of collapse, the duration of\navalanches, and the length of the cascading plateau phase preceding a collapse.\nThis analysis quantifies how system size and the intensity of the initial\ntriggering event influence these characteristics.","main_category":"physics.soc-ph","categories":"physics.soc-ph,q-bio.PE","published":"2025-04-09T13:12:43Z"}
{"aid":"http://arxiv.org/abs/2504.06878v1","title":"CRYSIM: Prediction of Symmetric Structures of Large Crystals with\n  GPU-based Ising Machines","summary":"Solving black-box optimization problems with Ising machines is increasingly\ncommon in materials science. However, their application to crystal structure\nprediction (CSP) is still ineffective due to symmetry agnostic encoding of\natomic coordinates. We introduce CRYSIM, an algorithm that encodes the space\ngroup, the Wyckoff positions combination, and coordinates of independent atomic\nsites as separate variables. This encoding reduces the search space\nsubstantially by exploiting the symmetry in space groups. When CRYSIM is\ninterfaced to Fixstars Amplify, a GPU-based Ising machine, its prediction\nperformance was competitive with CALYPSO and Bayesian optimization for crystals\ncontaining more than 150 atoms in a unit cell. Although it is not realistic to\ninterface CRYSIM to current small-scale quantum devices, it has the potential\nto become the standard CSP algorithm in the coming quantum age.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cs.LG","published":"2025-04-09T13:33:48Z"}
{"aid":"http://arxiv.org/abs/2504.06888v1","title":"The Singular CR Yamabe Problem and Hausdorff Dimension","summary":"We consider a compact pseudo-hermitian manifold (M,\\theta, J), that is a\nmanifold equipped with a contact form \\theta and CR structure J. We consider a\nconformal deformation of the contact form to obtain a complete, singular\ncontact form and a corresponding Yamabe problem. We estimate then the Hausdorff\ndimension of the singular set. The conformal geometry analog of this result is\ndue to R. Schoen and S. -T. Yau. Results of this type have their origin in work\nby Huber for Riemann surfaces. In the second part of our paper we investigate\nthe CR developing map for three dimensional CR manifolds. We establish the\ninjectivity of the developing map essentially using the same strategy as Schoen\nand Yau for the conformal case which is based on the positive mass theorem.\nHigher dimensional analogs of Huber's theorem in the conformal case for Q\ncurvature are due to Alice Chang, Jie Qing and P. Yang.","main_category":"math.DG","categories":"math.DG","published":"2025-04-09T13:49:53Z"}
{"aid":"http://arxiv.org/abs/2504.06897v1","title":"MedSegFactory: Text-Guided Generation of Medical Image-Mask Pairs","summary":"This paper presents MedSegFactory, a versatile medical synthesis framework\nthat generates high-quality paired medical images and segmentation masks across\nmodalities and tasks. It aims to serve as an unlimited data repository,\nsupplying image-mask pairs to enhance existing segmentation tools. The core of\nMedSegFactory is a dual-stream diffusion model, where one stream synthesizes\nmedical images and the other generates corresponding segmentation masks. To\nensure precise alignment between image-mask pairs, we introduce Joint\nCross-Attention (JCA), enabling a collaborative denoising paradigm by dynamic\ncross-conditioning between streams. This bidirectional interaction allows both\nrepresentations to guide each other's generation, enhancing consistency between\ngenerated pairs. MedSegFactory unlocks on-demand generation of paired medical\nimages and segmentation masks through user-defined prompts that specify the\ntarget labels, imaging modalities, anatomical regions, and pathological\nconditions, facilitating scalable and high-quality data generation. This new\nparadigm of medical image synthesis enables seamless integration into diverse\nmedical imaging workflows, enhancing both efficiency and accuracy. Extensive\nexperiments show that MedSegFactory generates data of superior quality and\nusability, achieving competitive or state-of-the-art performance in 2D and 3D\nsegmentation tasks while addressing data scarcity and regulatory constraints.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-09T13:56:05Z"}
{"aid":"http://arxiv.org/abs/2504.06946v1","title":"Uniqueness of Lp Minkowski problem in the supercritical range","summary":"The uniqueness of the $L_p$-Minkowski problem has been a long standing\nproblem in convex geometry. In the groundbreaking paper by\nBrendle-Choi-Daskalopoulos (Acta Math, {\\bf219}, 2017), a full uniqueness\nresult was shown for the subcritical exponents $p\\in(-n-1,1]$. In the\nsupercritical range, the uniqueness problem is much more complicated, even in\nthe planar case $n=1$. One of the famous results was shown by Andrews (J. Amer.\nMath. Soc., {\\bf16}, 2003), where he established that the uniqueness holds in\nthe range $p\\in(-7,-2)$ and fails to hold for the other supercritical exponents\n$p\\in(-\\infty,-7)$. In this paper, we study the same uniqueness problem in the\nfull supercritical range $p\\in(-2n-5,-n-1)$ for all higher dimensional cases\n$n\\geq2$. We will prove that for $p\\in(-2n-5,-n-1)$, the unique strongly\nsymmetric solution is given by the unit sphere ${\\mathbb{S}}^n$. The uniqueness\nrange $(-2n-5,-n-1)$ is optimal due to our recent preprint (arXiv: 2104.07426)\njoint with J. Lu and Y.N. Liu, where we have constructed non-spherical strongly\nsymmetric solutions for all $p\\in(-\\infty,-2n-5)$. When considering general\nsolutions without symmetricity assumption, the uniqueness set $\\Gamma$ of $p$\nfor which the uniqueness holds, is shown to be both relatively open and closed\nin the full interval $(-2n-5,-n-1)$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T14:53:18Z"}
{"aid":"http://arxiv.org/abs/2504.06948v1","title":"An improved quantum algorithm for linear autonomous differential\n  equations via Pad√© approximation","summary":"We propose a novel quantum algorithm for solving linear autonomous ordinary\ndifferential equations (ODEs) using the Pad\\'e approximation. For linear\nautonomous ODEs, the discretized solution can be represented by a product of\nmatrix exponentials. The proposed algorithm approximates the matrix exponential\nby the diagonal Pad\\'e approximation, which is then encoded into a large,\nblock-sparse linear system and solved via quantum linear system algorithms\n(QLSA). The detailed quantum circuit is given based on quantum oracle access to\nthe matrix, the inhomogeneous term, and the initial state. The complexity of\nthe proposed algorithm is analyzed. Compared to the method based on Taylor\napproximation, which approximates the matrix exponential using a $k$-th order\nTaylor series, the proposed algorithm improves the approximation order $k$ from\ntwo perspectives: 1) the explicit complexity dependency on $k$ is improved, and\n2) a smaller $k$ suffices for the same precision. Numerical experiments\ndemonstrate the advantages of the proposed algorithm comparing to other related\nalgorithms.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T14:54:27Z"}
{"aid":"http://arxiv.org/abs/2504.06957v1","title":"A Comparison of Deep Learning Methods for Cell Detection in Digital\n  Cytology","summary":"Accurate and efficient cell detection is crucial in many biomedical image\nanalysis tasks. We evaluate the performance of several Deep Learning (DL)\nmethods for cell detection in Papanicolaou-stained cytological Whole Slide\nImages (WSIs), focusing on accuracy of predictions and computational\nefficiency. We examine recentoff-the-shelf algorithms as well as\ncustom-designed detectors, applying them to two datasets: the CNSeg Dataset and\nthe Oral Cancer (OC) Dataset. Our comparison includes well-established\nsegmentation methods such as StarDist, Cellpose, and the Segment Anything Model\n2 (SAM2), alongside centroid-based Fully Convolutional Regression Network\n(FCRN) approaches. We introduce a suitable evaluation metric to assess the\naccuracy of predictions based on the distance from ground truth positions. We\nalso explore the impact of dataset size and data augmentation techniques on\nmodel performance. Results show that centroid-based methods, particularly the\nImproved Fully Convolutional Regression Network (IFCRN) method, outperform\nsegmentation-based methods in terms of both detection accuracy and\ncomputational efficiency. This study highlights the potential of centroid-based\ndetectors as a preferred option for cell detection in resource-limited\nenvironments, offering faster processing times and lower GPU memory usage\nwithout compromising accuracy.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T15:08:12Z"}
{"aid":"http://arxiv.org/abs/2504.06965v1","title":"A Deep Single Image Rectification Approach for Pan-Tilt-Zoom Cameras","summary":"Pan-Tilt-Zoom (PTZ) cameras with wide-angle lenses are widely used in\nsurveillance but often require image rectification due to their inherent\nnonlinear distortions. Current deep learning approaches typically struggle to\nmaintain fine-grained geometric details, resulting in inaccurate rectification.\nThis paper presents a Forward Distortion and Backward Warping Network\n(FDBW-Net), a novel framework for wide-angle image rectification. It begins by\nusing a forward distortion model to synthesize barrel-distorted images,\nreducing pixel redundancy and preventing blur. The network employs a pyramid\ncontext encoder with attention mechanisms to generate backward warping flows\ncontaining geometric details. Then, a multi-scale decoder is used to restore\ndistorted features and output rectified images. FDBW-Net's performance is\nvalidated on diverse datasets: public benchmarks, AirSim-rendered PTZ camera\nimagery, and real-scene PTZ camera datasets. It demonstrates that FDBW-Net\nachieves SOTA performance in distortion rectification, boosting the\nadaptability of PTZ cameras for practical visual applications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T15:19:38Z"}
{"aid":"http://arxiv.org/abs/2504.06984v1","title":"Weak Signals and Heavy Tails: Machine-learning meets Extreme Value\n  Theory","summary":"The masses of data now available have opened up the prospect of discovering\nweak signals using machine-learning algorithms, with a view to predictive or\ninterpretation tasks. As this survey of recent results attempts to show,\nbringing multivariate extreme value theory and statistical learning theory\ntogether in a common, non-parametric and non-asymptotic framework makes it\npossible to design and analyze new methods for exploiting the scarce\ninformation located in distribution tails in these purposes. This article\nreviews recently proved theoretical tools for establishing guarantees for\nsupervised or unsupervised algorithms learning from a fraction of extreme data.\nThese are mainly exponential maximal deviation inequalities tailored to\nlow-probability regions and concentration results for stochastic processes\nempirically describing the behavior of extreme observations, their dependence\nstructure in particular. Under appropriate assumptions of regular variation,\nseveral illustrative applications are then examined: classification,\nregression, anomaly detection, model selection via cross-validation. For these,\ngeneralization results are established inspired by the classical bounds in\nstatistical learning theory. In the same spirit, it is also shown how to adapt\nthe popular high-dimensional lasso technique in the context of extreme values\nfor the covariates with generalization guarantees.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-09T15:41:40Z"}
{"aid":"http://arxiv.org/abs/2504.06986v1","title":"Solving \"pseudo-injective\" polynomial equations over finite dynamical\n  systems","summary":"We consider the semiring of abstract finite dynamical systems up to\nisomorphism, with the operations of alternative and synchronous execution. We\ncontinue searching for efficient algorithms for solving polynomial equations of\nthe form $P(X) = B$, with a constant side B, with the goal of decomposing\ncomplex behaviors into simpler systems. Taking inspiration from the\ncharacterization of injective polynomials P over dynamical systems, which is\nbased on a condition on the lengths of limit cycles of their coefficients, we\nintroduce a more general notion of pseudo-injectivity by relaxing this\nconstraint. We prove that the associated equations can be solved efficiently,\neven in certain cases where the input is encoded in an exponentially more\ncompact way.","main_category":"cs.DM","categories":"cs.DM,math.DS","published":"2025-04-09T15:49:39Z"}
{"aid":"http://arxiv.org/abs/2504.07003v1","title":"The FitzHugh-Nagumo system on undulated cylinders: spontaneous\n  symmetrization and effective system","summary":"We consider the FitzHugh-Nagumo system on undulated cylindrical surfaces\nmodeling nerve axons. We show that for sufficiently small radii and for initial\nconditions close to radially symmetrical ones, (i) the solutions converge to\ntheir radial averages, and (ii) the latter averages can be approximated by\nsolutions of a 1+1 dimensional ('radial') system (the effective system)\ninvolving the surface radius function in its coefficients. This perhaps\nexplains why solutions of the original 1+1 dimensional FitzHugh-Nagumo system\nagree so well with experimental data on electrical impulse propagation.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T16:22:58Z"}
{"aid":"http://arxiv.org/abs/2504.07020v1","title":"Computably discrete represented spaces","summary":"In computable topology, a represented space is called computably discrete if\nits equality predicate is semidecidable. While any such space is classically\nisomorphic to an initial segment of the natural numbers, the\ncomputable-isomorphism types of computably discrete represented spaces exhibit\na rich structure. We show that the widely studied class of computably\nenumerable equivalence relations (ceers) corresponds precisely to the\ncomputably Quasi-Polish computably discrete spaces. We employ computably\ndiscrete spaces to exhibit several separating examples in computable topology.\nWe construct a computably discrete computably Quasi-Polish space admitting no\ndecidable properties, a computably discrete and computably Hausdorff\nprecomputably Quasi-Polish space admitting no computable injection into the\nnatural numbers, a two-point space which is computably Hausdorff but not\ncomputably discrete, and a two-point space which is computably discrete but not\ncomputably Hausdorff. We further expand an example due to Weihrauch that\nseparates computably regular spaces from computably normal spaces.","main_category":"math.LO","categories":"math.LO,cs.LO,math.GN","published":"2025-04-09T16:36:11Z"}
{"aid":"http://arxiv.org/abs/2504.07022v1","title":"Evaluating Retrieval Augmented Generative Models for Document Queries in\n  Transportation Safety","summary":"Applications of generative Large Language Models LLMs are rapidly expanding\nacross various domains, promising significant improvements in workflow\nefficiency and information retrieval. However, their implementation in\nspecialized, high-stakes domains such as hazardous materials transportation is\nchallenging due to accuracy and reliability concerns. This study evaluates the\nperformance of three fine-tuned generative models, ChatGPT, Google's Vertex AI,\nand ORNL Retrieval Augmented Generation augmented LLaMA 2 and LLaMA in\nretrieving regulatory information essential for hazardous material\ntransportation compliance in the United States. Utilizing approximately 40\npublicly available federal and state regulatory documents, we developed 100\nrealistic queries relevant to route planning and permitting requirements.\nResponses were qualitatively rated based on accuracy, detail, and relevance,\ncomplemented by quantitative assessments of semantic similarity between model\noutputs. Results demonstrated that the RAG-augmented LLaMA models significantly\noutperformed Vertex AI and ChatGPT, providing more detailed and generally\naccurate information, despite occasional inconsistencies. This research\nintroduces the first known application of RAG in transportation safety,\nemphasizing the need for domain-specific fine-tuning and rigorous evaluation\nmethodologies to ensure reliability and minimize the risk of inaccuracies in\nhigh-stakes environments.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T16:37:03Z"}
{"aid":"http://arxiv.org/abs/2504.07031v1","title":"Identifying Key Challenges of Hardness-Based Resampling","summary":"Performance gap across classes remains a persistent challenge in machine\nlearning, often attributed to variations in class hardness. One way to quantify\nclass hardness is through sample complexity - the minimum number of samples\nrequired to effectively learn a given class. Sample complexity theory suggests\nthat class hardness is driven by differences in the amount of data required for\ngeneralization. That is, harder classes need substantially more samples to\nachieve generalization. Therefore, hardness-based resampling is a promising\napproach to mitigate these performance disparities. While resampling has been\nstudied extensively in data-imbalanced settings, its impact on balanced\ndatasets remains unexplored.\n  This raises the fundamental question whether resampling is effective because\nit addresses data imbalance or hardness imbalance. We begin addressing this\nquestion by introducing class imbalance into balanced datasets and evaluate its\neffect on performance disparities. We oversample hard classes and undersample\neasy classes to bring hard classes closer to their sample complexity\nrequirements while maintaining a constant dataset size for fairness. We\nestimate class-level hardness using the Area Under the Margin (AUM) hardness\nestimator and leverage it to compute resampling ratios. Using these ratios, we\nperform hardness-based resampling on the well-known CIFAR-10 and CIFAR-100\ndatasets.\n  Contrary to theoretical expectations, our results show that hardness-based\nresampling does not meaningfully affect class-wise performance disparities. To\nexplain this discrepancy, we conduct detailed analyses to identify key\nchallenges unique to hardness-based imbalance, distinguishing it from\ntraditional data-based imbalance. Our insights help explain why theoretical\nsample complexity expectations fail to translate into practical performance\ngains and we provide guidelines for future research.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T16:45:57Z"}
{"aid":"http://arxiv.org/abs/2504.07035v1","title":"Classification results for totally real surfaces of nearly K√§hler\n  $\\mathbb{C}P^3$","summary":"Totally real surfaces in the nearly K\\\"ahler $\\mathbb{C}P^3$ are investigated\nand are completely classified under various additional assumptions, resulting\nin multiple new examples. Among others, the classification includes totally\nreal surfaces that are extrinsically homogeneous; or minimal; or totally\numbilical; or Codazzi-like (including parallel and non-parallel examples).","main_category":"math.DG","categories":"math.DG","published":"2025-04-09T16:51:40Z"}
{"aid":"http://arxiv.org/abs/2504.07042v1","title":"Towards a Higher Roofline for Matrix-Vector Multiplication in\n  Matrix-Free HOSFEM","summary":"The high-order/spectral finite element method (HOSFEM) is a widely used\nnumerical method for solving PDEs, with its performance primarily relying on\naxhelm, a matrix-free kernel for element-local matrix-vector multiplications.\nIn axhelm, geometric factors account for over half of memory access but\nminimally contribute to computational workload. This imbalance significantly\nconstrains the performance roofline, indicating that further optimization of\ntensor contraction, the core computation in axhelm, yields only minimal\nimprovements. To overcome this bottleneck, we propose a low-cost on-the-fly\nrecalculation of geometric factors for trilinear elements, thereby unlocking\nsubstantial potential for optimizing tensor contraction. The proposed approach\nis implemented in Nekbone, a standard HOSFEM benchmark. With optimizations such\nas merging scalar factors, partial recalculation, Tensor Core acceleration, and\nconstant memory utilization, performance reaches 85%-100% of the higher\nroofline. The optimized kernels achieve speedups of 1.74x-4.10x on NVIDIA A100\nand 1.99x-3.77x on DCU K100. This leads to a 1.12x-1.40x speedup for Nekbone.","main_category":"cs.PF","categories":"cs.PF,cs.MS","published":"2025-04-09T17:00:05Z"}
{"aid":"http://arxiv.org/abs/2504.07055v1","title":"$Œ†$-NeSy: A Possibilistic Neuro-Symbolic Approach","summary":"In this article, we introduce a neuro-symbolic approach that combines a\nlow-level perception task performed by a neural network with a high-level\nreasoning task performed by a possibilistic rule-based system. The goal is to\nbe able to derive for each input instance the degree of possibility that it\nbelongs to a target (meta-)concept. This (meta-)concept is connected to\nintermediate concepts by a possibilistic rule-based system. The probability of\neach intermediate concept for the input instance is inferred using a neural\nnetwork. The connection between the low-level perception task and the\nhigh-level reasoning task lies in the transformation of neural network outputs\nmodeled by probability distributions (through softmax activation) into\npossibility distributions. The use of intermediate concepts is valuable for the\nexplanation purpose: using the rule-based system, the classification of an\ninput instance as an element of the (meta-)concept can be justified by the fact\nthat intermediate concepts have been recognized.\n  From the technical side, our contribution consists of the design of efficient\nmethods for defining the matrix relation and the equation system associated\nwith a possibilistic rule-based system. The corresponding matrix and equation\nare key data structures used to perform inferences from a possibilistic\nrule-based system and to learn the values of the rule parameters in such a\nsystem according to a training data sample. Furthermore, leveraging recent\nresults on the handling of inconsistent systems of fuzzy relational equations,\nan approach for learning rule parameters according to multiple training data\nsamples is presented. Experiments carried out on the MNIST addition problems\nand the MNIST Sudoku puzzles problems highlight the effectiveness of our\napproach compared with state-of-the-art neuro-symbolic ones.","main_category":"cs.AI","categories":"cs.AI,cs.LG,cs.LO","published":"2025-04-09T17:16:23Z"}
{"aid":"http://arxiv.org/abs/2504.07072v1","title":"Kaleidoscope: In-language Exams for Massively Multilingual Vision\n  Evaluation","summary":"The evaluation of vision-language models (VLMs) has mainly relied on\nEnglish-language benchmarks, leaving significant gaps in both multilingual and\nmulticultural coverage. While multilingual benchmarks have expanded, both in\nsize and languages, many rely on translations of English datasets, failing to\ncapture cultural nuances. In this work, we propose Kaleidoscope, as the most\ncomprehensive exam benchmark to date for the multilingual evaluation of\nvision-language models. Kaleidoscope is a large-scale, in-language multimodal\nbenchmark designed to evaluate VLMs across diverse languages and visual inputs.\nKaleidoscope covers 18 languages and 14 different subjects, amounting to a\ntotal of 20,911 multiple-choice questions. Built through an open science\ncollaboration with a diverse group of researchers worldwide, Kaleidoscope\nensures linguistic and cultural authenticity. We evaluate top-performing\nmultilingual vision-language models and find that they perform poorly on\nlow-resource languages and in complex multimodal scenarios. Our results\nhighlight the need for progress on culturally inclusive multimodal evaluation\nframeworks.","main_category":"cs.CL","categories":"cs.CL,cs.CV","published":"2025-04-09T17:43:16Z"}
{"aid":"http://arxiv.org/abs/2504.07083v1","title":"GenDoP: Auto-regressive Camera Trajectory Generation as a Director of\n  Photography","summary":"Camera trajectory design plays a crucial role in video production, serving as\na fundamental tool for conveying directorial intent and enhancing visual\nstorytelling. In cinematography, Directors of Photography meticulously craft\ncamera movements to achieve expressive and intentional framing. However,\nexisting methods for camera trajectory generation remain limited: Traditional\napproaches rely on geometric optimization or handcrafted procedural systems,\nwhile recent learning-based methods often inherit structural biases or lack\ntextual alignment, constraining creative synthesis. In this work, we introduce\nan auto-regressive model inspired by the expertise of Directors of Photography\nto generate artistic and expressive camera trajectories. We first introduce\nDataDoP, a large-scale multi-modal dataset containing 29K real-world shots with\nfree-moving camera trajectories, depth maps, and detailed captions in specific\nmovements, interaction with the scene, and directorial intent. Thanks to the\ncomprehensive and diverse database, we further train an auto-regressive,\ndecoder-only Transformer for high-quality, context-aware camera movement\ngeneration based on text guidance and RGBD inputs, named GenDoP. Extensive\nexperiments demonstrate that compared to existing methods, GenDoP offers better\ncontrollability, finer-grained trajectory adjustments, and higher motion\nstability. We believe our approach establishes a new standard for\nlearning-based cinematography, paving the way for future advancements in camera\ncontrol and filmmaking. Our project website:\nhttps://kszpxxzmc.github.io/GenDoP/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T17:56:01Z"}
{"aid":"http://arxiv.org/abs/2504.07092v1","title":"Are We Done with Object-Centric Learning?","summary":"Object-centric learning (OCL) seeks to learn representations that only encode\nan object, isolated from other objects or background cues in a scene. This\napproach underpins various aims, including out-of-distribution (OOD)\ngeneralization, sample-efficient composition, and modeling of structured\nenvironments. Most research has focused on developing unsupervised mechanisms\nthat separate objects into discrete slots in the representation space,\nevaluated using unsupervised object discovery. However, with recent\nsample-efficient segmentation models, we can separate objects in the pixel\nspace and encode them independently. This achieves remarkable zero-shot\nperformance on OOD object discovery benchmarks, is scalable to foundation\nmodels, and can handle a variable number of slots out-of-the-box. Hence, the\ngoal of OCL methods to obtain object-centric representations has been largely\nachieved. Despite this progress, a key question remains: How does the ability\nto separate objects within a scene contribute to broader OCL objectives, such\nas OOD generalization? We address this by investigating the OOD generalization\nchallenge caused by spurious background cues through the lens of OCL. We\npropose a novel, training-free probe called $\\textbf{Object-Centric\nClassification with Applied Masks (OCCAM)}$, demonstrating that\nsegmentation-based encoding of individual objects significantly outperforms\nslot-based OCL methods. However, challenges in real-world applications remain.\nWe provide the toolbox for the OCL community to use scalable object-centric\nrepresentations, and focus on practical applications and fundamental questions,\nsuch as understanding object perception in human cognition. Our code is\navailable $\\href{https://github.com/AlexanderRubinstein/OCCAM}{here}$.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-09T17:59:05Z"}
{"aid":"http://arxiv.org/abs/2504.07430v1","title":"Nonlinear Optimal Guidance for Intercepting Moving Targets","summary":"This paper introduces a nonlinear optimal guidance framework for guiding a\npursuer to intercept a moving target, with an emphasis on real-time generation\nof optimal feedback control for a nonlinear optimal control problem. Initially,\nconsidering the target moves without maneuvering, we derive the necessary\noptimality conditions using Pontryagin's Maximum Principle. These conditions\nreveal that each extremal trajectory is uniquely determined by two scalar\nparameters. Analyzing the geometric property of the parameterized extremal\ntrajectories not only leads to an additional necessary condition but also\nallows to establish a sufficient condition for local optimality. This enables\nthe generation of a dataset containing at least locally optimal trajectories.\nBy studying the properties of the optimal feedback control, the size of the\ndataset is reduced significantly, allowing training a lightweight neural\nnetwork to predict the optimal guidance command in real time. Furthermore, the\nperformance of the neural network is enhanced by incorporating the target's\nacceleration, making it suitable for intercepting both uniformly moving and\nmaneuvering targets. Finally, numerical simulations validate the proposed\nnonlinear optimal guidance framework, demonstrating its better performance over\nexisting guidance laws.","main_category":"math.OC","categories":"math.OC","published":"2025-04-10T03:52:24Z"}
{"aid":"http://arxiv.org/abs/2504.07443v1","title":"Optoelectronic properties of self-trapped holes in orthorhombic Ga2O3\n  and its alloys","summary":"We investigated the influence of valence band holes on the optoelectronic\nproperties of orthorhombic k-Ga2O3 and its alloys with Al and In. Our hybrid\ndensity functional theory calculations show that self-trapped holes (STHs)\nlocalize on oxygen atoms within a single unit cell and exhibit \\emph{p}-orbital\ncharacteristics. The inclusion of isoelectronic dopants such as Al and In\nreduces but does not remove the absorption of visible light due to STH\nformation. The combination of a positive STH formation energy, large lattice\ndistortions, and emergent acceptor levels, coupled with the observed\nred-shifted, visible spectrum, emergent absorption peaks, implies that\nalternative doping/alloying strategies are necessary to achieve effective\np-type conductivity in orthorhombic k-Ga2O3.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-10T04:20:23Z"}
{"aid":"http://arxiv.org/abs/2504.07461v1","title":"Achilles Heel of Distributed Multi-Agent Systems","summary":"Multi-agent system (MAS) has demonstrated exceptional capabilities in\naddressing complex challenges, largely due to the integration of multiple large\nlanguage models (LLMs). However, the heterogeneity of LLMs, the scalability of\nquantities of LLMs, and local computational constraints pose significant\nchallenges to hosting these models locally. To address these issues, we propose\na new framework termed Distributed Multi-Agent System (DMAS). In DMAS,\nheterogeneous third-party agents function as service providers managed remotely\nby a central MAS server and each agent offers its services through API\ninterfaces. However, the distributed nature of DMAS introduces several concerns\nabout trustworthiness. In this paper, we study the Achilles heel of distributed\nmulti-agent systems, identifying four critical trustworthiness challenges: free\nriding, susceptibility to malicious attacks, communication inefficiencies, and\nsystem instability. Extensive experiments across seven frameworks and four\ndatasets reveal significant vulnerabilities of the DMAS. These attack\nstrategies can lead to a performance degradation of up to 80% and attain a 100%\nsuccess rate in executing free riding and malicious attacks. We envision our\nwork will serve as a useful red-teaming tool for evaluating future multi-agent\nsystems and spark further research on trustworthiness challenges in distributed\nmulti-agent systems.","main_category":"cs.MA","categories":"cs.MA","published":"2025-04-10T05:16:11Z"}
{"aid":"http://arxiv.org/abs/2504.07466v1","title":"Personalized and Demand-Based Education Concept: Practical Tools for\n  Control Engineers","summary":"This paper presents a personalized lecture concept using educational blocks\nand its demonstrative application in a new university lecture. Higher education\nfaces daily challenges: deep and specialized knowledge is available from\neverywhere and accessible to almost everyone. University lecturers of\nspecialized master courses confront the problem that their lectures are either\ntoo boring or too complex for the attending students. Additionally, curricula\nare changing more rapidly than they have in the past 10-30 years. The German\neducation system comprises different educational forms, with universities\nproviding less practical content. Consequently, many university students do not\nobtain the practical skills they should ideally gain through university\nlectures. Therefore, in this work, a new lecture concept is proposed based on\nthe extension of the just-in-time teaching paradigm: Personalized and\nDemand-Based Education. This concept includes: 1) an initial assessment of\nstudents' backgrounds, 2) selecting the appropriate educational blocks, and 3)\ncollecting ongoing feedback during the semester. The feedback was gathered via\nPingo, ensuring anonymity for the students. Our concept was exemplarily tested\nin the new lecture \"Practical Tools for Control Engineers\" at the Karlsruhe\nInstitute of Technology. The initial results indicate that our proposed concept\ncould be beneficial in addressing the current challenges in higher education.","main_category":"eess.SY","categories":"eess.SY,cs.RO,cs.SY,K.3.1","published":"2025-04-10T05:34:37Z"}
{"aid":"http://arxiv.org/abs/2504.07468v1","title":"Novel Pooling-based VGG-Lite for Pneumonia and Covid-19 Detection from\n  Imbalanced Chest X-Ray Datasets","summary":"This paper proposes a novel pooling-based VGG-Lite model in order to mitigate\nclass imbalance issues in Chest X-Ray (CXR) datasets. Automatic Pneumonia\ndetection from CXR images by deep learning model has emerged as a prominent and\ndynamic area of research, since the inception of the new Covid-19 variant in\n2020. However, the standard Convolutional Neural Network (CNN) models encounter\nchallenges associated with class imbalance, a prevalent issue found in many\nmedical datasets. The innovations introduced in the proposed model architecture\ninclude: (I) A very lightweight CNN model, `VGG-Lite', is proposed as a base\nmodel, inspired by VGG-16 and MobileNet-V2 architecture. (II) On top of this\nbase model, we leverage an ``Edge Enhanced Module (EEM)\" through a parallel\nbranch, consisting of a ``negative image layer\", and a novel custom pooling\nlayer ``2Max-Min Pooling\". This 2Max-Min Pooling layer is entirely novel in\nthis investigation, providing more attention to edge components within\npneumonia CXR images. Thus, it works as an efficient spatial attention module\n(SAM). We have implemented the proposed framework on two separate CXR datasets.\nThe first dataset is obtained from a readily available source on the internet,\nand the second dataset is a more challenging CXR dataset, assembled by our\nresearch team from three different sources. Experimental results reveal that\nour proposed framework has outperformed pre-trained CNN models, and three\nrecent trend existing models ``Vision Transformer\", ``Pooling-based Vision\nTransformer (PiT)'' and ``PneuNet\", by substantial margins on both datasets.\nThe proposed framework VGG-Lite with EEM, has achieved a macro average of 95%\naccuracy, 97.1% precision, 96.1% recall, and 96.6% F1 score on the ``Pneumonia\nImbalance CXR dataset\", without employing any pre-processing technique.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-10T05:38:46Z"}
{"aid":"http://arxiv.org/abs/2504.07471v1","title":"Traversal Learning Coordination For Lossless And Efficient Distributed\n  Learning","summary":"In this paper, we introduce Traversal Learning (TL), a novel approach\ndesigned to address the problem of decreased quality encountered in popular\ndistributed learning (DL) paradigms such as Federated Learning (FL), Split\nLearning (SL), and SplitFed Learning (SFL). Traditional FL experiences from an\naccuracy drop during aggregation due to its averaging function, while SL and\nSFL face increased loss due to the independent gradient updates on each split\nnetwork. TL adopts a unique strategy where the model traverses the nodes during\nforward propagation (FP) and performs backward propagation (BP) on the\norchestrator, effectively implementing centralized learning (CL) principles\nwithin a distributed environment. The orchestrator is tasked with generating\nvirtual batches and planning the sequential node visits of the model during FP,\naligning them with the ordered index of the data within these batches. We\nconducted experiments on six datasets representing diverse characteristics\nacross various domains. Our evaluation demonstrates that TL is on par with\nclassic CL approaches in terms of accurate inference, thereby offering a viable\nand robust solution for DL tasks. TL outperformed other DL methods and improved\naccuracy by 7.85% for independent and identically distributed (IID) datasets,\nmacro F1-score by 1.06% for non-IID datasets, accuracy by 2.60% for text\nclassification, and AUC by 3.88% and 4.54% for medical and financial datasets,\nrespectively. By effectively preserving data privacy while maintaining\nperformance, TL represents a significant advancement in DL methodologies.","main_category":"cs.LG","categories":"cs.LG,cs.DC","published":"2025-04-10T05:48:57Z"}
{"aid":"http://arxiv.org/abs/2504.07488v1","title":"Mass-subcritical Half-Wave Equation with mixed nonlinearities: existence\n  and non-existence of ground states","summary":"We consider the problem of existence of constrained minimizers for the\nfocusing mass-subcritical Half-Wave equation with a defocusing mass-subcritical\nperturbation. We show the existence of a critical mass such that minimizers do\nexist for any mass larger than or equal to the critical one, and do not exist\nbelow it. At the dynamical level, in the one dimensional case, we show that the\nground states are orbitally stable.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP","published":"2025-04-10T06:43:17Z"}
{"aid":"http://arxiv.org/abs/2504.07497v1","title":"Quantum Determinant Estimation","summary":"A quantum algorithm for computing the determinant of a unitary matrix $U\\in\nU(N)$ is given. The algorithm requires no preparation of eigenstates of $U$ and\nestimates the phase of the determinant to $t$ binary digits accuracy with\n$\\mathcal{O}(N\\log^2 N+t^2)$ operations and $tN$ controlled applications of\n$U^{2^m}$ with $m=0,\\ldots,t-1$. For an orthogonal matrix $O\\in O(N)$ the\nalgorithm can determine with certainty the sign of the determinant using\n$\\mathcal{O}(N\\log^2 N)$ operations and $N$ controlled applications of $O$. An\nextension of the algorithm to contractions is discussed.","main_category":"quant-ph","categories":"quant-ph,hep-lat","published":"2025-04-10T06:53:37Z"}
{"aid":"http://arxiv.org/abs/2504.07503v1","title":"Event Signal Filtering via Probability Flux Estimation","summary":"Events offer a novel paradigm for capturing scene dynamics via asynchronous\nsensing, but their inherent randomness often leads to degraded signal quality.\nEvent signal filtering is thus essential for enhancing fidelity by reducing\nthis internal randomness and ensuring consistent outputs across diverse\nacquisition conditions. Unlike traditional time series that rely on fixed\ntemporal sampling to capture steady-state behaviors, events encode transient\ndynamics through polarity and event intervals, making signal modeling\nsignificantly more complex. To address this, the theoretical foundation of\nevent generation is revisited through the lens of diffusion processes. The\nstate and process information within events is modeled as continuous\nprobability flux at threshold boundaries of the underlying irradiance\ndiffusion. Building on this insight, a generative, online filtering framework\ncalled Event Density Flow Filter (EDFilter) is introduced. EDFilter estimates\nevent correlation by reconstructing the continuous probability flux from\ndiscrete events using nonparametric kernel smoothing, and then resamples\nfiltered events from this flux. To optimize fidelity over time, spatial and\ntemporal kernels are employed in a time-varying optimization framework. A fast\nrecursive solver with O(1) complexity is proposed, leveraging state-space\nmodels and lookup tables for efficient likelihood computation. Furthermore, a\nnew real-world benchmark Rotary Event Dataset (RED) is released, offering\nmicrosecond-level ground truth irradiance for full-reference event filtering\nevaluation. Extensive experiments validate EDFilter's performance across tasks\nlike event filtering, super-resolution, and direct event-based blob tracking.\nSignificant gains in downstream applications such as SLAM and video\nreconstruction underscore its robustness and effectiveness.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T07:03:08Z"}
{"aid":"http://arxiv.org/abs/2504.07504v1","title":"On Ihara's lemma for definite unitary groups","summary":"Clozel, Harris, and Taylor proposed a conjectural generalized Ihara's lemma\nfor definite unitary groups. In this paper, we prove their conjecture over\nbanal coefficients under some conditions. As an application, we prove a\nlevel-raising result for automorphic forms associated to definite unitary\ngroups.","main_category":"math.NT","categories":"math.NT,math.RT","published":"2025-04-10T07:03:27Z"}
{"aid":"http://arxiv.org/abs/2504.07520v1","title":"Stability and Convergence of Strang Splitting Method for the Allen-Cahn\n  Equation with Homogeneous Neumann Boundary Condition","summary":"The Strang splitting method has been widely used to solve nonlinear\nreaction-diffusion equations, with most theoretical convergence analysis\nassuming periodic boundary conditions. However, such analysis presents\nadditional challenges for the case of homogeneous Neumann boundary condition.\nIn this work the Strang splitting method with variable time steps is\ninvestigated for solving the Allen--Cahn equation with homogeneous Neumann\nboundary conditions. Uniform $H^k$-norm stability is established under the\nassumption that the initial condition $u^0$ belongs to the Sobolev space\n$H^k(\\Omega)$ with integer $k\\ge 0$, using the Gagliardo--Nirenberg\ninterpolation inequality and the Sobolev embedding inequality. Furthermore,\nrigorous convergence analysis is provided in the $H^k$-norm for initial\nconditions $u^0 \\in H^{k+6}(\\Omega)$, based on the uniform stability. Several\nnumerical experiments are conducted to verify the theoretical results,\ndemonstrating the effectiveness of the proposed method.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-10T07:33:42Z"}
{"aid":"http://arxiv.org/abs/2504.07525v1","title":"Non triviality of the percolation threshold and Gumbel fluctuations for\n  Branching Interlacements","summary":"We consider the model of Branching Interlacements, introduced by Zhu, which\nis a natural analogue of Sznitman's Random Interlacements model, where the\nrandom walk trajectories are replaced by ranges of some suitable tree-indexed\nrandom walks. We first prove a basic decorrelation inequality for events\ndepending on the state of the field on distinct boxes. We then show that in all\nrelevant dimensions, the vacant set undergoes a nontrivial phase transition\nregarding the existence of an infinite connected component. Finally we obtain\nthe Gumbel fluctuations for the cover level of finite sets, which is analogous\nto Belius' result in the setting of Random Interlacements.","main_category":"math.PR","categories":"math.PR","published":"2025-04-10T07:46:21Z"}
{"aid":"http://arxiv.org/abs/2504.07526v1","title":"Computing gradient vector fields with Morse sequences","summary":"We rely on the framework of Morse sequences to enable the direct computation\nof gradient vector fields on simplicial complexes. A Morse sequence is a\nfiltration from a subcomplex L to a complex K via elementary expansions and\nfillings, naturally encoding critical and regular simplexes. Maximal increasing\nand minimal decreasing schemes allow constructing these sequences, and are\nlinked to algorithms like Random Discrete Morse and Coreduction. Extending the\napproach to cosimplicial complexes (S = K \\ L), we define operations --\nreductions, perforations, coreductions, and coperforations -- for efficient\ncomputation. We further generalize to F -sequences, which are Morse sequences\nweighted by an arbitrary stack function F , and provide algorithms to compute\nmaximal and minimal sequences. A particular case is when the stack function is\ngiven through a vertex map, as it is common in topological data analysis. We\nshow that we retrieve existing methods when the vertex map is injective; in\nthis case, the complex partitions into lower stars, facilitating parallel\nprocessing. Thus, this paper proposes simple, flexible, and computationally\nefficient approaches to obtain Morse sequences from arbitrary stack functions,\nallowing to generalize previous approaches dedicated to computing gradient\nvector fields from injective vertex maps.","main_category":"cs.DM","categories":"cs.DM,math.AT","published":"2025-04-10T07:48:31Z"}
{"aid":"http://arxiv.org/abs/2504.07531v1","title":"A taxonomy of epistemic injustice in the context of AI and the case for\n  generative hermeneutical erasure","summary":"Whether related to machine learning models' epistemic opacity, algorithmic\nclassification systems' discriminatory automation of testimonial prejudice, the\ndistortion of human beliefs via the 'hallucinations' of generative AI, the\ninclusion of the global South in global AI governance, the execution of\nbureaucratic violence via algorithmic systems, or located in the interaction\nwith conversational artificial agents epistemic injustice related to AI is a\ngrowing concern. Based on a proposed general taxonomy of epistemic injustice,\nthis paper first sketches a taxonomy of the types of epistemic injustice in the\ncontext of AI, relying on the work of scholars from the fields of philosophy of\ntechnology, political philosophy and social epistemology. Secondly, an\nadditional perspective on epistemic injustice in the context of AI: generative\nhermeneutical erasure. I argue that this injustice that can come about through\nthe application of Large Language Models (LLMs) and contend that generative AI,\nwhen being deployed outside of its Western space of conception, can have\neffects of conceptual erasure, particularly in the epistemic domain, followed\nby forms of conceptual disruption caused by a mismatch between AI system and\nthe interlocutor in terms of conceptual frameworks. AI systems' 'view from\nnowhere' epistemically inferiorizes non-Western epistemologies and thereby\ncontributes to the erosion of their epistemic particulars, gradually\ncontributing to hermeneutical erasure. This work's relevance lies in proposal\nof a taxonomy that allows epistemic injustices to be mapped in the AI domain\nand the proposal of a novel form of AI-related epistemic injustice.","main_category":"cs.AI","categories":"cs.AI,cs.CY,K.4","published":"2025-04-10T07:54:47Z"}
{"aid":"http://arxiv.org/abs/2504.07535v1","title":"The v-numbers of Stanley-Reisner ideals from the viewpoint of Alexander\n  dual complexes","summary":"We express the v-number of the Stanley-Reisner ideal in terms of its\nAlexander dual complex and prove that the v-number of a cover ideal is just two\nless than the initial degree of the its syzygy module. We give some relation\nbetween the v-number of the Stanley-Reisner ideal and the Serre-depth of the\nquotient ring of the second symbolic power of the Stanley-Reisner ideal of its\nAlexander dual. We also show that the v-number of the Stanley-Reisner ideal of\na 2-pure simplicial complex is equal to the dimension of its Stanley-Reisner\nring.","main_category":"math.AC","categories":"math.AC","published":"2025-04-10T08:01:59Z"}
{"aid":"http://arxiv.org/abs/2504.07576v1","title":"An exceptional story: Symmetries and dualities between Maximal\n  supergravity and General relativity","summary":"We present the historical path from General relativity to the construction of\nMaximal $\\mathcal{N}_4 = 8$ Supergravity with a detour in D=10 and 11\ndimensions. The supergravities obtained by toric dimensional reduction and/or\nby reducing the number of supersymmetry generators have large exceptional\nduality symmetry groups and exhibit a remarkably uniform pattern across all\nvalues of $\\mathcal{N}_D$ and D. In particular (bosonic) General relativity\nfits in as the simplest case and anchors us to the Real world. Dimensional\nreduction to 2 dimensions brings us to affine Kac-Moody groups and their\nsemi-direct products with a real form of the Witt algebra: there is \"integrable\nMagics\". Integrability of 4D Gravity and of its reduction to 2D is considered\nwith their \"Twisted self-duality\". Hyperbolic Kac-Moody symmetries appear after\nreduction to 1D: this leads to \"chaotic Magics\". We then discover\n\"Borcherds\"-Kac-Moody symmetries that allow us to rewrite in any dimension all\nmatter equations of motion as Twisted self-duality: \"Algebraic geometric\nMagics\". Finally a \"BF\" metasymmetry $\\Sigma$ exchanges negative quartets of\nFermionic dimensions with Bosonic ones inside two Magic triangles. A third\nubiquitous triangle of symmetries from Invariant theory resists unification\ndespite its strong resemblance to the others. The prospective remarks include\nseven Challenges.","main_category":"hep-th","categories":"hep-th","published":"2025-04-10T09:20:24Z"}
{"aid":"http://arxiv.org/abs/2504.07586v1","title":"A perspective on totally geodesic submanifolds of the symmetric space\n  $G_2/SO(4)$","summary":"We provide an independent proof of the classification of the maximal totally\ngeodesic submanifolds of the symmetric spaces $G_2$ and $G_2/SO(4)$, jointly\nwith very natural descriptions of all of these submanifolds. The description of\nthe totally geodesic submanifolds of $G_2$ is in terms of (1) principal\nsubalgebras of $\\mathfrak{g}_2$; (2) stabilizers of nonzero points of\n$\\mathbb{R}^7$; (3) stabilizers of associative subalgebras; (4) the set of\norder two elements in $G_2$ (and its translations). The space $G_2/SO(4)$ is\nidentified with the set of associative subalgebras of $\\mathbb{R}^7$ and its\nmaximal totally geodesic submanifolds can be described as the associative\nsubalgebras adapted to a fixed principal subalgebra, the associative\nsubalgebras orthogonal to a fixed nonzero vector, the associative subalgebras\ncontaining a fixed nonzero vector, and the associative subalgebras intersecting\nboth a fixed associative subalgebra and its orthogonal. A second description is\nincluded in terms of Grassmannians, the advantage of which is that the\nassociated Lie triple systems are easily described in matrix form.","main_category":"math.DG","categories":"math.DG","published":"2025-04-10T09:28:50Z"}
{"aid":"http://arxiv.org/abs/2504.07592v1","title":"Hardness of 4-Colourings G-Colourable Graphs","summary":"We study the complexity of a class of promise graph homomorphism problems.\nFor a fixed graph H, the H-colouring problem is to decide whether a given graph\nhas a homomorphism to H. By a result of Hell and Ne\\v{s}et\\v{r}il, this problem\nis NP-hard for any non-bipartite loop-less graph H. Brakensiek and Guruswami\n[SODA 2018] conjectured the hardness extends to promise graph homomorphism\nproblems as follows: fix a pair of non-bipartite loop-less graphs G, H such\nthat there is a homomorphism from G to H, it is NP-hard to distinguish between\ngraphs that are G-colourable and those that are not H-colourable. We confirm\nthis conjecture in the cases when both G and H are 4-colourable. This is a\ncommon generalisation of previous results of Khanna, Linial, and Safra [Comb.\n20(3): 393-415 (2000)] and of Krokhin and Opr\\v{s}al [FOCS 2019]. The result is\nobtained by combining the algebraic approach to promise constraint satisfaction\nwith methods of topological combinatorics and equivariant obstruction theory.","main_category":"cs.CC","categories":"cs.CC,math.AT,math.CO","published":"2025-04-10T09:44:53Z"}
{"aid":"http://arxiv.org/abs/2504.07599v1","title":"Tuning chirality amplitude at ultrafast timescales","summary":"Chirality is a fundamental symmetry concept describing discrete states, i.e.,\nleft-handed, right-handed, or achiral, and existing at disparate scales and in\nmany categories of scientific fields. Even though symmetry breaking is\nindispensable for describing qualitatively distinct phenomena, symmetry cannot\nquantitatively predict measurable quantities. One can continuously distort an\nobject, introducing the concept of chirality amplitude, similar to representing\nmagnetization as the amplitude of time-reversal symmetry breaking. Considering\nthe role of magnetization in emergent phenomena with time-reversal symmetry\nbreaking, chirality amplitude is intuitively a key quantity for controlling\nchirality-related emergent phenomena. Here, we propose two types of chiral\nlattice distortions and demonstrate the tunability of their amplitude in\nultrafast timescales. Resonant X-ray diffraction with circular polarization is\nan established technique to measure crystal chirality directly. We quantify the\nultrafast change in chirality amplitude in real time after an optical\nexcitation. Using instead a THz excitation, we observe oscillations in the\nresonant diffraction intensities corresponding to specific phonon frequencies.\nThis indicates the creation of additional asymmetry, which could also be\ndescribed as an enhancement in chirality amplitude. Our proposed concept of\nchirality amplitude and its ultrafast control may lead to a unique approach to\ncontrol chirality-induced emergent phenomena in ultrafast timescales.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-10T09:52:13Z"}
{"aid":"http://arxiv.org/abs/2504.07613v1","title":"Power spectrum of the CODEX clusters","summary":"Aims. We analyze the clustering of galaxy clusters in a large contiguous\nsample, the Constrain Dark Energy with X-ray (CODEX) sample. We construct a\nlikelihood for cosmological parameters by comparing the measured clustering\nsignal and a theoretical prediction, and use this to obtain parameter\nconstraints. Methods. We measured the three multipole moments (monopole,\nquadrupole, and hexadecapole, $\\ell = 0, 2, 4$) of the power spectrum of a\nsubset of the CODEX clusters. To fully model cluster clustering, we also\ndetermined the expected clustering bias of the sample using estimates for the\ncluster masses and a mass-to-bias model calibrated using N-body simulations. We\nestimated the covariance matrix of the measured power spectrum multipoles using\na set of simulated dark-matter halo catalogs. Combining all these ingredients,\nwe performed a Markov chain Monte Carlo sampling of cosmological parameters\n$\\Omega_m$ and $\\sigma_8$ to obtain their posterior. Results. We found the\nCODEX clustering signal to be consistent with an earlier X-ray selected cluster\nsample, the REFLEX II sample. We also found that the measured power spectrum\nmultipoles are compatible with the predicted, bias-scaled linear matter power\nspectrum when the cosmological parameters determined by the Planck satellite\nare assumed. Furthermore, we found the marginalized parameter constraints of\n$\\Omega_m = 0.24^{+0.06}_{-0.04}$ and $\\sigma_8 = 1.13^{+0.43}_{-0.24}$. The\nfull 2D posterior is consistent, for example, with the Planck cosmology within\nthe 68% confidence region.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-10T10:04:24Z"}
{"aid":"http://arxiv.org/abs/2504.07626v1","title":"Upper bounds of focusing light through multimode fibers","summary":"Wavefront shaping enables precise control of light propagation through\nmultimode fibers, facilitating diffraction-limited focusing for applications\nsuch as high-resolution single-fiber imaging and high-power fiber amplifiers.\nWhile the theoretical intensity enhancement at the focal point is dictated by\nthe number of input degrees of freedom, practical constraints such as\nphase-only modulation and experimental noise impose significant limitations.\nDespite its importance, the upper bounds of enhancement under these constraints\nremain largely unexplored. In this work, we establish a theoretical framework\nto predict the fundamental limits of intensity enhancement with phase-only\nmodulation in the presence of noise-induced phase errors, and we experimentally\ndemonstrate wavefront shaping that approaches these limits. Our experimental\nresults confirm an enhancement factor of 5,000 in a large-core multimode fiber,\napproaching the theoretical upper bound, enabled by noise-tolerant wavefront\nshaping. These findings provide key insights into the limits of phase-only\ncontrol in multimode fibers, with profound implications for single-fiber\nimaging, optical communication, high-power broad-area fiber amplification, and\nbeyond.","main_category":"physics.optics","categories":"physics.optics,physics.app-ph","published":"2025-04-10T10:24:08Z"}
{"aid":"http://arxiv.org/abs/2504.07635v1","title":"Generative Artificial Intelligence for Internet of Things Computing: A\n  Systematic Survey","summary":"The integration of Generative Artificial Intelligence (GenAI) within the\nInternet of Things (IoT) is garnering considerable interest. This growing\nattention stems from the continuous evolution and widespread adoption they are\nboth having individually, enough to spontaneously reshape numerous sectors,\nincluding Healthcare, Manufacturing, and Smart Cities. Hence, their increasing\npopularity has catalyzed further extensive research for understanding the\npotential of the duo GenAI-IoT, how they interplay, and to which extent their\nsynergy can innovate the state-of-the-art in their individual scenarios.\nHowever, despite the increasing prominence of GenAI for IoT Computing, much of\nthe existing research remains focused on specific, narrowly scoped\napplications. This fragmented approach highlights the need for a more\ncomprehensive analysis of the potential, challenges, and implications of GenAI\nintegration within the broader IoT ecosystem. This survey exactly aims to\naddress this gap by providing a holistic overview of the opportunities, issues,\nand considerations arising from the convergence of these mainstream paradigms.\nOur contribution is realized through a systematic literature review following\nthe PRISMA methodology. A comparison framework is presented, and well-defined\nresearch questions are outlined to comprehensively explore the past, present,\nand future directions of GenAI integration with IoT Computing, offering\nvaluable insights for both experts and newcomers.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-10T10:32:18Z"}
{"aid":"http://arxiv.org/abs/2504.07654v1","title":"ms-Mamba: Multi-scale Mamba for Time-Series Forecasting","summary":"The problem of Time-series Forecasting is generally addressed by recurrent,\nTransformer-based and the recently proposed Mamba-based architectures. However,\nexisting architectures generally process their input at a single temporal\nscale, which may be sub-optimal for many tasks where information changes over\nmultiple time scales. In this paper, we introduce a novel architecture called\nMulti-scale Mamba (ms-Mamba) to address this gap. ms-Mamba incorporates\nmultiple temporal scales by using multiple Mamba blocks with different sampling\nrates ($\\Delta$s). Our experiments on many benchmarks demonstrate that ms-Mamba\noutperforms state-of-the-art approaches, including the recently proposed\nTransformer-based and Mamba-based models.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-10T11:06:57Z"}
{"aid":"http://arxiv.org/abs/2504.07661v1","title":"Unveiling the Impact of Multimodal Features on Chinese Spelling\n  Correction: From Analysis to Design","summary":"The Chinese Spelling Correction (CSC) task focuses on detecting and\ncorrecting spelling errors in sentences. Current research primarily explores\ntwo approaches: traditional multimodal pre-trained models and large language\nmodels (LLMs). However, LLMs face limitations in CSC, particularly\nover-correction, making them suboptimal for this task. While existing studies\nhave investigated the use of phonetic and graphemic information in multimodal\nCSC models, effectively leveraging these features to enhance correction\nperformance remains a challenge. To address this, we propose the Multimodal\nAnalysis for Character Usage (\\textbf{MACU}) experiment, identifying potential\nimprovements for multimodal correctison. Based on empirical findings, we\nintroduce \\textbf{NamBert}, a novel multimodal model for Chinese spelling\ncorrection. Experiments on benchmark datasets demonstrate NamBert's superiority\nover SOTA methods. We also conduct a comprehensive comparison between NamBert\nand LLMs, systematically evaluating their strengths and limitations in CSC. Our\ncode and model are available at https://github.com/iioSnail/NamBert.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T11:19:09Z"}
{"aid":"http://arxiv.org/abs/2504.07667v1","title":"S2R-HDR: A Large-Scale Rendered Dataset for HDR Fusion","summary":"The generalization of learning-based high dynamic range (HDR) fusion is often\nlimited by the availability of training data, as collecting large-scale HDR\nimages from dynamic scenes is both costly and technically challenging. To\naddress these challenges, we propose S2R-HDR, the first large-scale\nhigh-quality synthetic dataset for HDR fusion, with 24,000 HDR samples. Using\nUnreal Engine 5, we design a diverse set of realistic HDR scenes that encompass\nvarious dynamic elements, motion types, high dynamic range scenes, and\nlighting. Additionally, we develop an efficient rendering pipeline to generate\nrealistic HDR images. To further mitigate the domain gap between synthetic and\nreal-world data, we introduce S2R-Adapter, a domain adaptation designed to\nbridge this gap and enhance the generalization ability of models. Experimental\nresults on real-world datasets demonstrate that our approach achieves\nstate-of-the-art HDR reconstruction performance. Dataset and code will be\navailable at https://openimaginglab.github.io/S2R-HDR.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T11:39:56Z"}
{"aid":"http://arxiv.org/abs/2504.07709v1","title":"Integrated Sensing and Communications for Pinching-Antenna Systems\n  (PASS)","summary":"An integrated sensing and communication (ISAC) design for pinching antenna\nsystems (PASS) is proposed, where the pinching antennas are deployed for\nestablishing reliable line-of-sight communication and sensing links. More\nparticularly, a separated ISAC design is proposed for the two-waveguide PASS,\nwhere one waveguide is used to emit the joint communication and sensing signals\nwhile the other waveguide is used to receive the reflected echo signals. Based\non this framework, a penalty-based alternating optimization algorithm is\nproposed to maximize the illumination power as well as ensure the communication\nquality-of-service requirement. Numerical results demonstrate that 1) the\nproposed PASS-ISAC scheme outperforms the other baseline schemes, and 2) the\nconsidered equal power allocation model achieves a performance comparable to\nthe optimal power allocation.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-10T12:58:46Z"}
{"aid":"http://arxiv.org/abs/2504.07714v1","title":"Quasi-Periodic Pulsations in Ionospheric TEC Synchronized with Solar\n  Flare EUV Emission","summary":"The extreme ultraviolet (EUV) and X-ray radiation emitted during solar flares\nhas been shown to significantly increase the electron density of the Earth's\nionosphere. During flares, quasi-periodic pulsations (QPPs) in X-ray flux\noriginating in the corona have previously been linked to subsequent pulsations\nin the Earth's ionospheric D-region. Similar pulsations have been detected in\nchromospheric EUV emission, although their impact on the Earth's ionosphere has\nnot previously been investigated. Here, for the first time, synchronous\npulsations were detected in solar EUV emission and ionospheric Total Electron\nContent (TEC) measurements. Using wavelet and periodogram analysis, we detect\nQPPs with approximately 85 second periods in chromospheric EUV emission lines\n(He II 304 \\AA{}, C III 977 \\AA{} and H I 972 \\AA{}) from the Solar Dynamics\nObservatory Extreme Ultraviolet Variability Experiment (SDO/EVE) during the\nimpulsive phase of an X5.4 flare on March 7, 2012. These lines contribute to\nionization in the ionospheric E- and F-regions, resulting in subsequent\nvariations of electron density with the same periodicity, which was detected in\nTEC measurements. This work demonstrates that the Earth's ionosphere is\nresponsive to fine-scale fluctuations in EUV emission during flares, with a\ntime delay of approximately 30 seconds found. These findings may have\napplications in atmospheric modelling and solar-terrestrial studies, including\nthe calculation of ionospheric recombination rates.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP","published":"2025-04-10T13:05:45Z"}
{"aid":"http://arxiv.org/abs/2504.07725v1","title":"Approximation Algorithms for Connected Maximum Coverage, Minimum\n  Connected Set Cover, and Node-Weighted Group Steiner Tree","summary":"In the Connected Budgeted maximum Coverage problem (CBC), we are given a\ncollection of subsets $\\mathcal{S}$, defined over a ground set $X$, and an\nundirected graph $G=(V,E)$, where each node is associated with a set of\n$\\mathcal{S}$. Each set in $\\mathcal{S}$ has a different cost and each element\nof $X$ gives a different prize. The goal is to find a subcollection\n$\\mathcal{S}'\\subseteq \\mathcal{S}$ such that $\\mathcal{S}'$ induces a\nconnected subgraph in $G$, the total cost of the sets in $\\mathcal{S}'$ does\nnot exceed a budget $B$, and the total prize of the elements covered by\n$\\mathcal{S}'$ is maximized. The Directed rooted Connected Budgeted maximum\nCoverage problem (DCBC) is a generalization of CBC where the underlying graph\n$G$ is directed and in the subgraph induced by $\\mathcal{S}'$ in $G$ must be an\nout-tree rooted at a given node.\n  The current best algorithms achieve approximation ratios that are linear in\nthe size of $G$ or depend on $B$. In this paper, we provide two algorithms for\nCBC and DCBC that guarantee approximation ratios of\n$O\\left(\\frac{\\log^2|X|}{\\epsilon^2}\\right)$ and\n$O\\left(\\frac{\\sqrt{|V|}\\log^2|X|}{\\epsilon^2}\\right)$, resp., with a budget\nviolation of a factor $1+\\epsilon$, where $\\epsilon\\in (0,1]$.\n  Our algorithms imply improved approximation factors of other related\nproblems. For the particular case of DCBC where the prize function is additive,\nwe improve from $O\\left(\\frac{1}{\\epsilon^2}|V|^{2/3}\\log|V|\\right)$ to\n$O\\left(\\frac{1}{\\epsilon^2}|V|^{1/2}\\log^2|V|\\right)$. For the minimum\nconnected set cover, a minimization version of CBC, and its directed variant,\nwe obtain approximation factors of $O(\\log^3|X|)$ and $O(\\sqrt{|V|}\\log^3|X|)$,\nresp. For the Node-Weighted Group Steiner Tree and and its directed variant, we\nobtain approximation factors of $O(\\log^3k)$ and $O(\\sqrt{|V|}\\log^3k)$, resp.,\nwhere $k$ is the number of groups.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-10T13:18:22Z"}
{"aid":"http://arxiv.org/abs/2504.07730v1","title":"Thermodynamics of Reissner-nordstorm black bounce black hole","summary":"Our study focuses on the thermodynamics of Reissner-nordstorm black bounce\nblack hole,we have determined the thermodynamic parameters including entropy,\nmass, temperature, heat capacity and free energies and investigated how those\nparameters are related to entropy and for some insights we additionally focused\non the P V isotherm and the logarithmic correction to the entropy.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-10T13:27:49Z"}
{"aid":"http://arxiv.org/abs/2504.07737v1","title":"Statistics of power and efficiency for collisional Brownian engines","summary":"Collisional Brownian engines have attracted significant attention due to\ntheir simplicity, experimental accessibility, and amenability to exact\nanalytical solutions. While previous research has predominantly focused on\noptimizing mean values of power and efficiency, the joint statistical\nproperties of these performance metrics remain largely unexplored. Using\nstochastic thermodynamics, we investigate the joint probability distributions\nof power and efficiency for collisional Brownian engines, revealing how\nthermodynamic fluctuations influence the probability of observing values\nexceeding their respective mean maxima. Our conditional probability analysis\ndemonstrates that when power fluctuates above its maximum mean value, the\nprobability of achieving high efficiency increases substantially, suggesting\nfluctuation regimes where the classical power-efficiency trade-off can be\nprobabilistically overcome. Notably, our framework extends to a broader class\nof engines, as the essential features of the statistics of the system are fully\ndetermined by the Onsager coefficients. Our results contribute to a deeper\nunderstanding of the role of fluctuations in Brownian engines, highlighting how\nstochastic behavior can enable performance beyond traditional thermodynamic\nbounds.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-10T13:29:46Z"}
{"aid":"http://arxiv.org/abs/2504.07746v1","title":"Upper semi-continuity of metric entropy for $\\mathcal{C}^{1,Œ±}$\n  diffeomorphisms","summary":"We prove that for $\\mathcal{C}^{1,\\alpha}$ diffeomorphisms on a compact\nmanifold $M$ with ${\\rm dim} M\\leq 3$, if an invariant measure $\\mu$ is a\ncontinuity point of the sum of positive Lyapunov exponents, then $\\mu$ is an\nupper semi-continuity point of the entropy map. This gives several\nconsequences, such as the upper-semi continuity of dimensions of measures for\nsurface diffeomorphisms. Furthermore, we know the continuity of dimensions for\nmeasures of maximal entropy.","main_category":"math.DS","categories":"math.DS","published":"2025-04-10T13:41:37Z"}
{"aid":"http://arxiv.org/abs/2504.07758v1","title":"PIDSR:ComplementaryPolarizedImageDemosaicingandSuper-Resolution","summary":"Polarization cameras can capture multiple polarized images with different\npolarizer angles in a single shot, bringing convenience to polarization-based\ndownstream tasks. However, their direct outputs are color-polarization filter\narray (CPFA) raw images, requiring demosaicing to reconstruct full-resolution,\nfull-color polarized images; unfortunately, this necessary step introduces\nartifacts that make polarization-related parameters such as the degree of\npolarization (DoP) and angle of polarization (AoP) prone to error. Besides,\nlimited by the hardware design, the resolution of a polarization camera is\noften much lower than that of a conventional RGB camera. Existing polarized\nimage demosaicing (PID) methods are limited in that they cannot enhance\nresolution, while polarized image super-resolution (PISR) methods, though\ndesigned to obtain high-resolution (HR) polarized images from the demosaicing\nresults, tend to retain or even amplify errors in the DoP and AoP introduced by\ndemosaicing artifacts. In this paper, we propose PIDSR, a joint framework that\nperforms complementary Polarized Image Demosaicing and Super-Resolution,\nshowing the ability to robustly obtain high-quality HR polarized images with\nmore accurate DoP and AoP from a CPFA raw image in a direct manner. Experiments\nshow our PIDSR not only achieves state-of-the-art performance on both synthetic\nand real data, but also facilitates downstream tasks.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-10T13:56:33Z"}
{"aid":"http://arxiv.org/abs/2504.07774v1","title":"Bondi Mass, Memory Effect And Balance Law of Polyhomogeneous Spacetime","summary":"Spacetimes with metrics admitting an expansion in terms of a combination of\npowers of 1/r and ln r are known as polyhomogeneous spacetimes. The asymptotic\nbehaviour of the Newman-Penrose quantities for these spacetimes is presented\nunder certain gauges. The Bondi mass is revisited via the Iyer-Wald formalism.\nThe memory effect of the gravitational radiation in the polyhomogeneous\nspacetimes is also discussed. It is found that the appearance of the\nlogarithmic terms does not affect the balance law and it remains unchanged as\nthe one of spacetimes with metrics admitting an expansion in terms of powers of\n1/r.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-10T14:14:25Z"}
{"aid":"http://arxiv.org/abs/2504.07777v1","title":"Adaptive Detection of Fast Moving Celestial Objects Using a Mixture of\n  Experts and Physical-Inspired Neural Network","summary":"Fast moving celestial objects are characterized by velocities across the\ncelestial sphere that significantly differ from the motions of background\nstars. In observational images, these objects exhibit distinct shapes,\ncontrasting with the typical appearances of stars. Depending on the\nobservational method employed, these celestial entities may be designated as\nnear-Earth objects or asteroids. Historically, fast moving celestial objects\nhave been observed using ground-based telescopes, where the relative stability\nof stars and Earth facilitated effective image differencing techniques\nalongside traditional fast moving celestial object detection and classification\nalgorithms. However, the growing prevalence of space-based telescopes, along\nwith their diverse observational modes, produces images with different\nproperties, rendering conventional methods less effective. This paper presents\na novel algorithm for detecting fast moving celestial objects within star\nfields. Our approach enhances state-of-the-art fast moving celestial object\ndetection neural networks by transforming them into physical-inspired neural\nnetworks. These neural networks leverage the point spread function of the\ntelescope and the specific observational mode as prior information; they can\ndirectly identify moving fast moving celestial objects within star fields\nwithout requiring additional training, thereby addressing the limitations of\ntraditional techniques. Additionally, all neural networks are integrated using\nthe mixture of experts technique, forming a comprehensive fast moving celestial\nobject detection algorithm. We have evaluated our algorithm using simulated\nobservational data that mimics various observations carried out by space based\ntelescope scenarios and real observation images. Results demonstrate that our\nmethod effectively detects fast moving celestial objects across different\nobservational modes.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.EP,cs.CV,cs.LG,physics.optics","published":"2025-04-10T14:15:30Z"}
{"aid":"http://arxiv.org/abs/2504.07810v1","title":"Nonlocal Retinex-Based Variational Model and its Deep Unfolding Twin for\n  Low-Light Image Enhancement","summary":"Images captured under low-light conditions present significant limitations in\nmany applications, as poor lighting can obscure details, reduce contrast, and\nhide noise. Removing the illumination effects and enhancing the quality of such\nimages is crucial for many tasks, such as image segmentation and object\ndetection. In this paper, we propose a variational method for low-light image\nenhancement based on the Retinex decomposition into illumination, reflectance,\nand noise components. A color correction pre-processing step is applied to the\nlow-light image, which is then used as the observed input in the decomposition.\nMoreover, our model integrates a novel nonlocal gradient-type fidelity term\ndesigned to preserve structural details. Additionally, we propose an automatic\ngamma correction module. Building on the proposed variational approach, we\nextend the model by introducing its deep unfolding counterpart, in which the\nproximal operators are replaced with learnable networks. We propose\ncross-attention mechanisms to capture long-range dependencies in both the\nnonlocal prior of the reflectance and the nonlocal gradient-based constraint.\nExperimental results demonstrate that both methods compare favorably with\nseveral recent and state-of-the-art techniques across different datasets. In\nparticular, despite not relying on learning strategies, the variational model\noutperforms most deep learning approaches both visually and in terms of quality\nmetrics.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T14:48:26Z"}
{"aid":"http://arxiv.org/abs/2504.07857v1","title":"$B$ meson semileptonic decays from lattice QCD","summary":"$B$ processes are a rich source of potential anomalies that could lead to the\ndiscovery of BSM physics. The long-standing tension between the inclusive and\nthe exclusive determinations of the CKM matrix elements $|V_{xb}|$, or the\ncurrent tensions in the $R(D)$-$R(D^\\ast)$ plane are some examples of active\nareas of research where we might find signals of new physics. Heavy-to-heavy\n$B$ semileptonic decays, $B_{(s)}\\to D^{(\\ast)}_{(s)}\\ell\\nu$, and in\nparticular, decays with a vector product ($D^\\ast_{(s)}$) are especially\ninteresting from an experimental point of view, but experiment and theory must\nwalk together in order to reach conclusions in the intensity frontier. In this\nreview I talk about the current status of the lattice-QCD calculations of the\n$B\\to D^{\\ast}\\ell\\nu$ form factors at non-zero recoil, I discuss the\nimplications they have for the determination of $B$ anomalies, and finally I\ngive some hints of what we can expect from future calculations.","main_category":"hep-ph","categories":"hep-ph,hep-lat","published":"2025-04-10T15:32:23Z"}
{"aid":"http://arxiv.org/abs/2504.07873v1","title":"Spectral Periodic Differential Operators of Odd Order","summary":"In this paper, we establish a condition on the coefficients of the\ndifferential operators L generated by an ordinary differential expression of\nodd order with periodic, complex-valued coefficients, under which the operator\nL is a spectral operator.","main_category":"math.SP","categories":"math.SP","published":"2025-04-10T15:46:53Z"}
{"aid":"http://arxiv.org/abs/2504.07898v1","title":"How do Large Language Models Understand Relevance? A Mechanistic\n  Interpretability Perspective","summary":"Recent studies have shown that large language models (LLMs) can assess\nrelevance and support information retrieval (IR) tasks such as document ranking\nand relevance judgment generation. However, the internal mechanisms by which\noff-the-shelf LLMs understand and operationalize relevance remain largely\nunexplored. In this paper, we systematically investigate how different LLM\nmodules contribute to relevance judgment through the lens of mechanistic\ninterpretability. Using activation patching techniques, we analyze the roles of\nvarious model components and identify a multi-stage, progressive process in\ngenerating either pointwise or pairwise relevance judgment. Specifically, LLMs\nfirst extract query and document information in the early layers, then process\nrelevance information according to instructions in the middle layers, and\nfinally utilize specific attention heads in the later layers to generate\nrelevance judgments in the required format. Our findings provide insights into\nthe mechanisms underlying relevance assessment in LLMs, offering valuable\nimplications for future research on leveraging LLMs for IR tasks.","main_category":"cs.IR","categories":"cs.IR,cs.CL,cs.LG","published":"2025-04-10T16:14:55Z"}
{"aid":"http://arxiv.org/abs/2504.07899v1","title":"Dislocation Patterning as a Mechanism for Flat Band Formation","summary":"We compute the second-order correction to the electronic dispersion relation\nof a free electron gas interacting with an effective electron-dislocation\npotential, derived from a modern quantized theory of dislocations. Our results\ndemonstrate that dislocation patterning induces anisotropic flat bands in the\nelectronic dispersion under specific strain fields and directions, referred to\nas ``magic'' parameters. These flat bands acquire non-zero curvature as the\nstrain or direction deviates from these magic parameters.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,quant-ph","published":"2025-04-10T16:18:35Z"}
{"aid":"http://arxiv.org/abs/2504.07915v1","title":"Detecting changes in space-varying parameters of local Poisson point\n  processes","summary":"Recent advances in local models for point processes have highlighted the need\nfor flexible methodologies to account for the spatial heterogeneity of external\ncovariates influencing process intensity. In this work, we introduce\ntessellated spatial regression, a novel framework that extends segmented\nregression models to spatial point processes, with the aim of detecting abrupt\nchanges in the effect of external covariates onto the process intensity.\n  Our approach consists of two main steps. First, we apply a spatial\nsegmentation algorithm to geographically weighted regression estimates,\ngenerating different tessellations that partition the study area into regions\nwhere model parameters can be assumed constant. Next, we fit log-linear Poisson\nmodels in which covariates interact with the tessellations, enabling\nregion-specific parameter estimation and classical inferential procedures, such\nas hypothesis testing on regression coefficients.\n  Unlike geographically weighted regression, our approach allows for discrete\nchanges in regression coefficients, making it possible to capture abrupt\nspatial variations in the effect of real-valued spatial covariates.\nFurthermore, the method naturally addresses the problem of locating and\nquantifying the number of detected spatial changes.\n  We validate our methodology through simulation studies and applications to\ntwo examples where a model with region-wise parameters seems appropriate and to\nan environmental dataset of earthquake occurrences in Greece.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-10T17:23:32Z"}
{"aid":"http://arxiv.org/abs/2504.07927v1","title":"Zero-Shot Low-dose CT Denoising via Sinogram Flicking","summary":"Many low-dose CT imaging methods rely on supervised learning, which requires\na large number of paired noisy and clean images. However, obtaining paired\nimages in clinical practice is challenging. To address this issue, zero-shot\nself-supervised methods train denoising networks using only the information\nwithin a single image, such as ZS-N2N. However, these methods often employ\ndownsampling operations that degrade image resolution. Additionally, the\ntraining dataset is inherently constrained to the image itself. In this paper,\nwe propose a zero-shot low-dose CT imaging method based on sinogram flicking,\nwhich operates within a single image but generates many copies via random\nconjugate ray matching. Specifically, two conjugate X-ray pencil beams measure\nthe same path; their expected values should be identical, while their noise\nlevels vary during measurements. By randomly swapping portions of the conjugate\nX-rays in the sinogram domain, we generate a large set of sinograms with\nconsistent content but varying noise patterns. When displayed dynamically,\nthese sinograms exhibit a flickering effect due to their identical structural\ncontent but differing noise patterns-hence the term sinogram flicking. We train\nthe network on pairs of sinograms with the same content but different noise\ndistributions using a lightweight model adapted from ZS-NSN. This process is\nrepeated to obtain the final results. A simulation study demonstrates that our\nmethod outperforms state-of-the-art approaches such as ZS-N2N.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-10T17:42:01Z"}
{"aid":"http://arxiv.org/abs/2504.07931v1","title":"Quantum Speed Limit in Driven-dissipative Systems","summary":"Every quantum operation that takes a system from one state to another is\nknown to have bounds on operation time, due to Heisenberg uncertainty\nprinciple. In open quantum systems (OQS), such bounds have been principally\naffected by system environment coupling. In the recent past, drives on OQS have\nshown to give rise to drive-induced dissipation (DID). In this work, we\ninvestigate how DID affects the quantum speed limits. To this end, we use a\nrecently-reported quantum master equation that takes into account environment\nfluctuations and provide a closed form estimate of drive-induced dissipation.\nOn such a system, we use Gradient Ascent Pulse Engineering (GRAPE) to find\noptimal route to move from an initial state to a desired final state. Our key\nresult is that there exists an optimal evolution time that maximizes fidelity.\nThis work enables robust quantum control in open systems, addressing a key\nchallenge in scaling quantum technologies. By improving fidelity and\nefficiency, our method advances practical quantum computing under realistic\ndissipative conditions.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-10T17:46:43Z"}
{"aid":"http://arxiv.org/abs/2504.07934v1","title":"SoTA with Less: MCTS-Guided Sample Selection for Data-Efficient Visual\n  Reasoning Self-Improvement","summary":"In this paper, we present an effective method to enhance visual reasoning\nwith significantly fewer training samples, relying purely on self-improvement\nwith no knowledge distillation. Our key insight is that the difficulty of\ntraining data during reinforcement fine-tuning (RFT) is critical. Appropriately\nchallenging samples can substantially boost reasoning capabilities even when\nthe dataset is small. Despite being intuitive, the main challenge remains in\naccurately quantifying sample difficulty to enable effective data filtering. To\nthis end, we propose a novel way of repurposing Monte Carlo Tree Search (MCTS)\nto achieve that. Starting from our curated 70k open-source training samples, we\nintroduce an MCTS-based selection method that quantifies sample difficulty\nbased on the number of iterations required by the VLMs to solve each problem.\nThis explicit step-by-step reasoning in MCTS enforces the model to think longer\nand better identifies samples that are genuinely challenging. We filter and\nretain 11k samples to perform RFT on Qwen2.5-VL-7B-Instruct, resulting in our\nfinal model, ThinkLite-VL. Evaluation results on eight benchmarks show that\nThinkLite-VL improves the average performance of Qwen2.5-VL-7B-Instruct by 7%,\nusing only 11k training samples with no knowledge distillation. This\nsignificantly outperforms all existing 7B-level reasoning VLMs, and our fairly\ncomparable baselines that use classic selection methods such as accuracy-based\nfiltering. Notably, on MathVista, ThinkLite-VL-7B achieves the SoTA accuracy of\n75.1, surpassing Qwen2.5-VL-72B, GPT-4o, and O1. Our code, data, and model are\navailable at https://github.com/si0wang/ThinkLite-VL.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:49:05Z"}
{"aid":"http://arxiv.org/abs/2504.07960v1","title":"VisualCloze: A Universal Image Generation Framework via Visual\n  In-Context Learning","summary":"Recent progress in diffusion models significantly advances various image\ngeneration tasks. However, the current mainstream approach remains focused on\nbuilding task-specific models, which have limited efficiency when supporting a\nwide range of different needs. While universal models attempt to address this\nlimitation, they face critical challenges, including generalizable task\ninstruction, appropriate task distributions, and unified architectural design.\nTo tackle these challenges, we propose VisualCloze, a universal image\ngeneration framework, which supports a wide range of in-domain tasks,\ngeneralization to unseen ones, unseen unification of multiple tasks, and\nreverse generation. Unlike existing methods that rely on language-based task\ninstruction, leading to task ambiguity and weak generalization, we integrate\nvisual in-context learning, allowing models to identify tasks from visual\ndemonstrations. Meanwhile, the inherent sparsity of visual task distributions\nhampers the learning of transferable knowledge across tasks. To this end, we\nintroduce Graph200K, a graph-structured dataset that establishes various\ninterrelated tasks, enhancing task density and transferable knowledge.\nFurthermore, we uncover that our unified image generation formulation shared a\nconsistent objective with image infilling, enabling us to leverage the strong\ngenerative priors of pre-trained infilling models without modifying the\narchitectures.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:59:42Z"}
{"aid":"http://arxiv.org/abs/2504.07961v1","title":"Geo4D: Leveraging Video Generators for Geometric 4D Scene Reconstruction","summary":"We introduce Geo4D, a method to repurpose video diffusion models for\nmonocular 3D reconstruction of dynamic scenes. By leveraging the strong dynamic\nprior captured by such video models, Geo4D can be trained using only synthetic\ndata while generalizing well to real data in a zero-shot manner. Geo4D predicts\nseveral complementary geometric modalities, namely point, depth, and ray maps.\nIt uses a new multi-modal alignment algorithm to align and fuse these\nmodalities, as well as multiple sliding windows, at inference time, thus\nobtaining robust and accurate 4D reconstruction of long videos. Extensive\nexperiments across multiple benchmarks show that Geo4D significantly surpasses\nstate-of-the-art video depth estimation methods, including recent methods such\nas MonST3R, which are also designed to handle dynamic scenes.","main_category":"cs.CV","categories":"cs.CV,I.4.5","published":"2025-04-10T17:59:55Z"}
{"aid":"http://arxiv.org/abs/2504.09925v1","title":"FUSION: Fully Integration of Vision-Language Representations for Deep\n  Cross-Modal Understanding","summary":"We introduce FUSION, a family of multimodal large language models (MLLMs)\nwith a fully vision-language alignment and integration paradigm. Unlike\nexisting methods that primarily rely on late-stage modality interaction during\nLLM decoding, our approach achieves deep, dynamic integration throughout the\nentire processing pipeline. To this end, we propose Text-Guided Unified Vision\nEncoding, incorporating textual information in vision encoding to achieve\npixel-level integration. We further design Context-Aware Recursive Alignment\nDecoding that recursively aggregates visual features conditioned on textual\ncontext during decoding, enabling fine-grained, question-level semantic\nintegration. To guide feature mapping and mitigate modality discrepancies, we\ndevelop Dual-Supervised Semantic Mapping Loss. Additionally, we construct a\nSynthesized Language-Driven Question-Answer (QA) dataset through a new data\nsynthesis method, prioritizing high-quality QA pairs to optimize text-guided\nfeature integration. Building on these foundations, we train FUSION at two\nscales-3B, 8B-and demonstrate that our full-modality integration approach\nsignificantly outperforms existing methods with only 630 vision tokens.\nNotably, FUSION 3B surpasses Cambrian-1 8B and Florence-VL 8B on most\nbenchmarks. FUSION 3B continues to outperform Cambrian-1 8B even when limited\nto 300 vision tokens. Our ablation studies show that FUSION outperforms\nLLaVA-NeXT on over half of the benchmarks under same configuration without\ndynamic resolution, highlighting the effectiveness of our approach. We release\nour code, model weights, and dataset. https://github.com/starriver030515/FUSION","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T06:33:29Z"}
{"aid":"http://arxiv.org/abs/2504.09943v1","title":"The Tropical Atmosphere of Jupiter - Shallow Weather, Deep Plumes, and\n  Vortices","summary":"Towering storms, swirling clouds, and vortices are the cloud tops\nmanifestation of complex weather systems shaping the atmosphere of Jupiter. We\nuse observations from Juno's MicroWave Radiometer (MWR), the Very Large Array\n(VLA) and the Hubble Space Telescope (HST) to probe for the first time the\ndepth and impact of weather on Jupiter. We use ammonia, the main source of\nopacity at radio wavelengths on Jupiter, as the tracer for the weather by\nfitting ammonia anomalies to the MWR brightness temperature variations. We show\nthat the majority of the weather on Jupiter is confined to regions where the\nclouds are forming. Both the South Equatorial Belt and the Equatorial Zone have\nsurprisingly shallow weather systems (P < 2 bar), and even in the North\nEquatorial Belt most of the ammonia variations is above the water condensation\nlevel (P ~ 6 bar). This confirms that the water condensation layer plays a\ncrucial role in controlling the dynamics and the weather on Jupiter. However,\nthe shallow nature of the weather cannot explain the deep-seated depletion down\nto 30 bar that the Juno mission has revealed. We do find three features,\nhowever, that extend below the water condensation layer: a vortex in the\nnorthern hemisphere reaching down to 30 bar, an ammonia plume down to 20-30\nbars, and the signature of precipitation down to 20 bar. This work highlights\nthe interplay of large-scale processes (vortices, plumes) and small-scale\nprocesses (storms) are responsible for shaping the atmospheric makeup of\nJupiter.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-14T07:09:39Z"}
{"aid":"http://arxiv.org/abs/2504.09983v1","title":"DeepCompile: A Compiler-Driven Approach to Optimizing Distributed Deep\n  Learning Training","summary":"The increasing scale of deep learning models has led to the development of\nvarious parallelization strategies for distributed training across\naccelerators. For example, fully sharded approaches like DeepSpeed ZeRO-3 and\nFSDP partition the parameters of each layer across multiple GPUs and gather\nthem through communication when needed. These methods rely on optimizations\nsuch as prefetching, which initiates communication early to overlap it with\ncomputation and reduce communication overhead, and unsharding, which retains as\nmany parameters in their unsharded form as possible to reduce communication\nvolume. Although the timing of prefetching should be adjusted in response to\ndynamic memory usage during execution, these systems lack the flexibility to\ncontrol it, which limits the benefits of prefetching. Moreover, they cannot\nanticipate how memory usage will change after prefetching is applied, making it\ndifficult to combine it effectively with other optimizations such as\nunsharding. We present DeepCompile, which compiles user-defined models into\ncomputation graphs and applies a sequence of profiling-guided optimization\npasses for distributed training. Taking dynamic memory usage into account,\nthese passes flexibly insert, reorder, or remove operations to improve\ncommunication-computation overlap, reduce memory pressure, and coordinate\nmultiple optimizations in a unified manner. To evaluate the effectiveness of\nthis design, we implemented a fully sharded approach like ZeRO-3 and FSDP on\ntop of DeepCompile, along with three optimizations: proactive prefetching,\nselective unsharding, and adaptive offloading. We evaluate DeepCompile on the\ntraining of Llama 3 70B and Mixtral 8x7B MoE models. DeepCompile achieves up to\n1.28x and 1.54x performance improvements over ZeRO-3 and FSDP baselines,\nrespectively, and up to a 7.01x throughput increase with limited GPU resources,\nusing offloading.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-14T08:51:23Z"}
{"aid":"http://arxiv.org/abs/2504.09984v1","title":"On Precomputation and Caching in Information Retrieval Experiments with\n  Pipeline Architectures","summary":"Modern information retrieval systems often rely on multiple components\nexecuted in a pipeline. In a research setting, this can lead to substantial\nredundant computations (e.g., retrieving the same query multiple times for\nevaluating different downstream rerankers). To overcome this, researchers take\ncached \"result\" files as inputs, which represent the output of another\npipeline. However, these result files can be brittle and can cause a disconnect\nbetween the conceptual design of the pipeline and its logical implementation.\nTo overcome both the redundancy problem (when executing complete pipelines) and\nthe disconnect problem (when relying on intermediate result files), we describe\nour recent efforts to improve the caching capabilities in the open-source\nPyTerrier IR platform. We focus on two main directions: (1) automatic implicit\ncaching of common pipeline prefixes when comparing systems and (2) explicit\ncaching of operations through a new extension package, pyterrier-caching. These\napproaches allow for the best of both worlds: pipelines can be fully expressed\nend-to-end, while also avoiding redundant computations between pipelines.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-14T08:51:35Z"}
{"aid":"http://arxiv.org/abs/2504.09987v1","title":"Gravitational metamaterials from optical properties of spacetime media","summary":"Gravitational optical properties are here investigated under the hypothesis\nof spherically-symmetric spacetimes behaving as media. To do so, we first\nconsider two different definitions of the refractive index, $n_O$, of a\nspacetime medium and show how to pass from one definition to another by means\nof a coordinate transformation. Accordingly, the corresponding physical role of\n$n_O$ is discussed by virtue of the Misner-Sharp mass and the redshift\ndefinition. Afterwards, we discuss the inclusion of the electromagnetic fields\nand the equivalence with nonlinear effects induced by geometry. Accordingly,\nthe infrared and ultraviolet gravity regimes are thus discussed, obtaining\nbounds from the Solar System, neutron stars and white dwarfs, respectively. To\ndo so, we also investigate the Snell's law and propose how to possibly\ndistinguish regular solutions from black holes. As a consequence of our recipe,\nwe speculate on the existence of \\emph{gravitational metamaterials}, whose\nrefractive index may be negative and explore the corresponding physical\nimplications, remarking that $n_O<0$ may lead to invisible optical properties,\nas light is bent in the opposite direction compared to what occurs in ordinary\ncases. Further, we conjecture that gravitational metamaterials exhibit a\nparticle-like behavior, contributing to dark matter and propose three toy\nmodels, highlighting possible advantages and limitations of their use. Finally,\nwe suggest that such particle-like configurations can be ``dressed\" by\ninteraction, giving rise to \\emph{geometric quasiparticles}. We thus construct\nmodifications of the quantum propagator as due to nonminimal couplings between\ncurvature and external matter-like fields, finding the corresponding effective\nmass through a boson mixing mechanism.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-14T08:51:56Z"}
{"aid":"http://arxiv.org/abs/2504.10012v1","title":"EBAD-Gaussian: Event-driven Bundle Adjusted Deblur Gaussian Splatting","summary":"While 3D Gaussian Splatting (3D-GS) achieves photorealistic novel view\nsynthesis, its performance degrades with motion blur. In scenarios with rapid\nmotion or low-light conditions, existing RGB-based deblurring methods struggle\nto model camera pose and radiance changes during exposure, reducing\nreconstruction accuracy. Event cameras, capturing continuous brightness changes\nduring exposure, can effectively assist in modeling motion blur and improving\nreconstruction quality. Therefore, we propose Event-driven Bundle Adjusted\nDeblur Gaussian Splatting (EBAD-Gaussian), which reconstructs sharp 3D\nGaussians from event streams and severely blurred images. This method jointly\nlearns the parameters of these Gaussians while recovering camera motion\ntrajectories during exposure time. Specifically, we first construct a blur loss\nfunction by synthesizing multiple latent sharp images during the exposure time,\nminimizing the difference between real and synthesized blurred images. Then we\nuse event stream to supervise the light intensity changes between latent sharp\nimages at any time within the exposure period, supplementing the light\nintensity dynamic changes lost in RGB images. Furthermore, we optimize the\nlatent sharp images at intermediate exposure times based on the event-based\ndouble integral (EDI) prior, applying consistency constraints to enhance the\ndetails and texture information of the reconstructed images. Extensive\nexperiments on synthetic and real-world datasets show that EBAD-Gaussian can\nachieve high-quality 3D scene reconstruction under the condition of blurred\nimages and event stream inputs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T09:17:00Z"}
{"aid":"http://arxiv.org/abs/2504.10035v1","title":"TT3D: Table Tennis 3D Reconstruction","summary":"Sports analysis requires processing large amounts of data, which is\ntime-consuming and costly. Advancements in neural networks have significantly\nalleviated this burden, enabling highly accurate ball tracking in sports\nbroadcasts. However, relying solely on 2D ball tracking is limiting, as it\ndepends on the camera's viewpoint and falls short of supporting comprehensive\ngame analysis. To address this limitation, we propose a novel approach for\nreconstructing precise 3D ball trajectories from online table tennis match\nrecordings. Our method leverages the underlying physics of the ball's motion to\nidentify the bounce state that minimizes the reprojection error of the ball's\nflying trajectory, hence ensuring an accurate and reliable 3D reconstruction. A\nkey advantage of our approach is its ability to infer ball spin without relying\non human pose estimation or racket tracking, which are often unreliable or\nunavailable in broadcast footage. We developed an automated camera calibration\nmethod capable of reliably tracking camera movements. Additionally, we adapted\nan existing 3D pose estimation model, which lacks depth motion capture, to\naccurately track player movements. Together, these contributions enable the\nfull 3D reconstruction of a table tennis rally.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T09:37:47Z"}
{"aid":"http://arxiv.org/abs/2504.10047v1","title":"Vibrational structure and symmetry in $^{110-116}$Cd","summary":"We show that a vibrational interpretation and good U(5) symmetry are\nmaintained for the majority of low-lying normal states in\n$^{110,112,114,116}$Cd isotopes, consistent with the empirical data. The\nobserved deviations from this paradigm are properly treated by an interacting\nboson model Hamiltonian which breaks the U(5) symmetry in selected non-yrast\nstates, while securing a weak mixing with coexisting SO(6)-like intruder\nstates. The results demonstrate the relevance of the U(5) partial dynamical\nsymmetry notion to this series of isotopes.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-14T09:53:30Z"}
{"aid":"http://arxiv.org/abs/2504.10048v1","title":"Multi-Object Grounding via Hierarchical Contrastive Siamese Transformers","summary":"Multi-object grounding in 3D scenes involves localizing multiple objects\nbased on natural language input. While previous work has primarily focused on\nsingle-object grounding, real-world scenarios often demand the localization of\nseveral objects. To tackle this challenge, we propose Hierarchical Contrastive\nSiamese Transformers (H-COST), which employs a Hierarchical Processing strategy\nto progressively refine object localization, enhancing the understanding of\ncomplex language instructions. Additionally, we introduce a Contrastive Siamese\nTransformer framework, where two networks with the identical structure are\nused: one auxiliary network processes robust object relations from ground-truth\nlabels to guide and enhance the second network, the reference network, which\noperates on segmented point-cloud data. This contrastive mechanism strengthens\nthe model' s semantic understanding and significantly enhances its ability to\nprocess complex point-cloud data. Our approach outperforms previous\nstate-of-the-art methods by 9.5% on challenging multi-object grounding\nbenchmarks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T09:53:48Z"}
{"aid":"http://arxiv.org/abs/2504.10067v1","title":"Undermining Federated Learning Accuracy in EdgeIoT via Variational Graph\n  Auto-Encoders","summary":"EdgeIoT represents an approach that brings together mobile edge computing\nwith Internet of Things (IoT) devices, allowing for data processing close to\nthe data source. Sending source data to a server is bandwidth-intensive and may\ncompromise privacy. Instead, federated learning allows each device to upload a\nshared machine-learning model update with locally processed data. However, this\ntechnique, which depends on aggregating model updates from various IoT devices,\nis vulnerable to attacks from malicious entities that may inject harmful data\ninto the learning process. This paper introduces a new attack method targeting\nfederated learning in EdgeIoT, known as data-independent model manipulation\nattack. This attack does not rely on training data from the IoT devices but\ninstead uses an adversarial variational graph auto-encoder (AV-GAE) to create\nmalicious model updates by analyzing benign model updates intercepted during\ncommunication. AV-GAE identifies and exploits structural relationships between\nbenign models and their training data features. By manipulating these\nstructural correlations, the attack maximizes the training loss of the\nfederated learning system, compromising its overall effectiveness.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T10:09:38Z"}
{"aid":"http://arxiv.org/abs/2504.10087v1","title":"Joint Localization and Synchronization in Downlink Distributed MIMO","summary":"We investigate joint localization and synchronization in the downlink of a\ndistributed multiple-input-multiple-output (D-MIMO) system, aiming to estimate\nthe position and phase offset of a single-antenna user equipment (UE) using\ndownlink transmissions of multiple phase-synchronized, multi-antenna access\npoints (APs). We propose two transmission protocols: sequential (P1) and\nsimultaneous (P2) AP transmissions, together with the ML estimators that either\nleverage (coherent estimator) or disregard phase information (non-coherent\nestimator). Simulation results reveal that downlink D-MIMO holds significant\npotential for high-accuracy localization while showing that P2 provides\nsuperior localization performance and reduced transmission latency.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T10:47:05Z"}
{"aid":"http://arxiv.org/abs/2504.10103v1","title":"Numerical approach for solving problems arising from polynomial analysis","summary":"This paper deals with the use of numerical methods based on random root\nsampling techniques to solve some theoretical problems arising in the analysis\nof polynomials. These methods are proved to be practical and give solutions\nwhere traditional methods might fall short.","main_category":"math.NA","categories":"math.NA,cs.NA,math.CA","published":"2025-04-14T11:13:11Z"}
{"aid":"http://arxiv.org/abs/2504.10104v1","title":"Automated next-to-leading order QCD and electroweak predictions of\n  photon-photon processes in ultraperipheral collisions","summary":"We present automated next-to-leading order QCD and/or electroweak (EW)\npredictions for photon-photon processes in ultraperipheral high-energy\ncollisions of protons and ions, extending the capabilities of the\n\\textsc{MadGraph5\\_aMC@NLO} framework together in combination with the\n\\ttt{gamma-UPC} code. Key aspects of this extension are discussed. We compute\nQCD and/or EW quantum corrections for several phenomenologically interesting\nprocesses at LHC and FCC-hh energies.","main_category":"hep-ph","categories":"hep-ph,hep-ex,nucl-ex,nucl-th","published":"2025-04-14T11:13:50Z"}
{"aid":"http://arxiv.org/abs/2504.10108v1","title":"A Photometric Comparison of B and Be stars using Gaia DR3","summary":"Previous studies have observed significant photometric differences between\nnon-emission B-type and classical Be stars, however the precise mechanism\nresponsible for these differences is unclear. This study combines the Bright\nStar Catalogue with Tycho and Gaia photometry to create a homogeneous sample of\n1015 of the closest and brightest B and Be-type field stars with 90 per cent of\nobjects at distances < 500pc. Due to their proximity, the extinction towards\nthese objects is very low, ensuring we minimise any obfuscation in the\nreddening correction and final photometry. We present our findings in both\nTycho and Gaia photometry through colour magnitude diagrams and present\nintrinsic colours and absolute magnitudes for each spectral type. We find Be\nstars are on average ~0.5 magnitudes brighter in both Gaia $G$ and Tycho V$_T$\ncompared to non-emission B stars of the same spectral type. Additionally, we\nfind tentative evidence that Be stars are redder in Gaia B$_P$$-$R$_P$,\nparticularly for the earlier types, but have similar Tycho B$_T$$-$V$_T$\ncolours. We test the effects of gravitational darkening due to rapid rotation\nand binarity on the photometry of our sample and find both to be insufficient\nto explain the observed photometric differences between B and Be stars. We\nconclude that the most likely mechanism responsible for the observed\nphotometric differences is the combined effect of the circumstellar disc and\nstellar evolution up the Main Sequence, with the disc dominating early-types\nand evolution dominating late type stars.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-14T11:15:45Z"}
{"aid":"http://arxiv.org/abs/2504.10110v1","title":"Eigengap Sparsity for Covariance Parsimony","summary":"Covariance estimation is a central problem in statistics. An important issue\nis that there are rarely enough samples $n$ to accurately estimate the $p (p+1)\n/ 2$ coefficients in dimension $p$. Parsimonious covariance models are\ntherefore preferred, but the discrete nature of model selection makes inference\ncomputationally challenging. In this paper, we propose a relaxation of\ncovariance parsimony termed \"eigengap sparsity\" and motivated by the good\naccuracy-parsimony tradeoff of eigenvalue-equalization in covariance matrices.\nThis new penalty can be included in a penalized-likelihood framework that we\npropose to solve with a projected gradient descent on a monotone cone. The\nalgorithm turns out to resemble an isotonic regression of mutually-attracted\nsample eigenvalues, drawing an interesting link between covariance parsimony\nand shrinkage.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-14T11:18:02Z"}
{"aid":"http://arxiv.org/abs/2504.10118v1","title":"Stochastic Multigrid Minimization for Ptychographic Phase Retrieval","summary":"We propose a novel stochastic multigrid minimization method for ptychographic\nphase retrieval. In our formulation, the challenging nonconvex and ill-posed\ninverse problem is recast as the iterative minimization of a quadratic\nsurrogate model that majorizes the original objective function. Our general\nframework encompasses the Ptychographic Iterative Engine (PIE) family of\nalgorithms. By efficiently solving the surrogate problem using a multigrid\nmethod, our approach delivers significant improvements in both convergence\nspeed and reconstruction quality compared with conventional PIE techniques.","main_category":"math.NA","categories":"math.NA,cs.NA,math.OC","published":"2025-04-14T11:28:20Z"}
{"aid":"http://arxiv.org/abs/2504.10125v1","title":"An initial-boundary corrected splitting method for diffusion-reaction\n  problems","summary":"Strang splitting is a widely used second-order method for solving\ndiffusion-reaction problems. However, its convergence order is often reduced to\norder $1$ for Dirichlet boundary conditions and to order $1.5$ for Neumann and\nRobin boundary conditions, leading to lower accuracy and reduced efficiency. In\nthis paper, we propose a new splitting approach, called an initial-boundary\ncorrected splitting, which avoids order reduction while improving computational\nefficiency for a wider range of applications. In contrast to the corrections\nproposed in the literature, it does not require the computation of correction\nterms that depend on the boundary conditions and boundary data. Through\nrigorous analytical convergence analysis and numerical experiments, we\ndemonstrate the improved accuracy and performance of the proposed method.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-14T11:32:33Z"}
{"aid":"http://arxiv.org/abs/2504.10138v1","title":"$k$-Fibonacci numbers that are palindromic concatenations of two\n  distinct Repdigits","summary":"Let $k\\ge 2$ and $\\{F_n^{(k)}\\}_{n\\geq 2-k}$ be the sequence of\n$k$--generalized Fibonacci numbers whose first $k$ terms are $0,\\ldots,0,0,1$\nand each term afterwards is the sum of the preceding $k$ terms. In this paper,\nwe determine all $k$-Fibonacci numbers that are palindromic concatenations of\ntwo distinct repdigits.","main_category":"math.NT","categories":"math.NT","published":"2025-04-14T11:52:33Z"}
{"aid":"http://arxiv.org/abs/2504.10156v1","title":"The missing elements in the telegraph equations","summary":"The conventional modeling of transmission lines relies on the classical\ntelegraph equations, originally formulated over 150 years ago. These equations\nare typically derived by representing the line as an assembly of infinitesimal\ninductive, capacitive, and resistive elements. However, this formulation is\nfundamentally flawed, as a transmission line cannot be accurately described\nthrough a discretized model of infinitesimal lumped components. Instead, a more\nrigorous approach should derive the governing equations directly from Maxwells\nequations in conjunction with Ohms law. This paper presents such a derivation\nand introduces a corrected formulation, herein referred to as the Trump\nEquations.","main_category":"physics.gen-ph","categories":"physics.gen-ph","published":"2025-04-14T12:12:43Z"}
{"aid":"http://arxiv.org/abs/2504.10160v1","title":"MT-R1-Zero: Advancing LLM-based Machine Translation via R1-Zero-like\n  Reinforcement Learning","summary":"Large-scale reinforcement learning (RL) methods have proven highly effective\nin enhancing the reasoning abilities of large language models (LLMs),\nparticularly for tasks with verifiable solutions such as mathematics and\ncoding. However, applying this idea to machine translation (MT), where outputs\nare flexibly formatted and difficult to automatically evaluate with explicit\nrules, remains underexplored. In this work, we introduce MT-R1-Zero, the first\nopen-source adaptation of the R1-Zero RL framework for MT without supervised\nfine-tuning or cold-start. We propose a rule-metric mixed reward mechanism to\nguide LLMs towards improved translation quality via emergent reasoning. On the\nWMT 24 English-Chinese benchmark, our MT-R1-Zero-3B-Mix achieves competitive\nperformance, surpassing TowerInstruct-7B-v0.2 by an average of 1.26 points.\nMeanwhile, our MT-R1-Zero-7B-Mix attains a high average score of 62.25 across\nall metrics, placing it on par with advanced proprietary models such as GPT-4o\nand Claude-3.5-Sonnet, while the MT-R1-Zero-7B-Sem variant achieves\nstate-of-the-art scores on semantic metrics. Moreover, our work exhibits strong\ngeneralization capabilities on out-of-distribution MT tasks, robustly\nsupporting multilingual and low-resource settings. Extensive analysis of model\nbehavior across different initializations and reward metrics offers pioneering\ninsight into the critical role of reward design, LLM adaptability, training\ndynamics, and emergent reasoning patterns within the R1-Zero paradigm for MT.\nOur code is available at https://github.com/fzp0424/MT-R1-Zero.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-14T12:14:18Z"}
{"aid":"http://arxiv.org/abs/2504.10166v1","title":"Fact-Checking with Contextual Narratives: Leveraging Retrieval-Augmented\n  LLMs for Social Media Analysis","summary":"We propose CRAVE (Cluster-based Retrieval Augmented Verification with\nExplanation); a novel framework that integrates retrieval-augmented Large\nLanguage Models (LLMs) with clustering techniques to address fact-checking\nchallenges on social media. CRAVE automatically retrieves multimodal evidence\nfrom diverse, often contradictory, sources. Evidence is clustered into coherent\nnarratives, and evaluated via an LLM-based judge to deliver fact-checking\nverdicts explained by evidence summaries. By synthesizing evidence from both\ntext and image modalities and incorporating agent-based refinement, CRAVE\nensures consistency and diversity in evidence representation. Comprehensive\nexperiments demonstrate CRAVE's efficacy in retrieval precision, clustering\nquality, and judgment accuracy, showcasing its potential as a robust\ndecision-support tool for fact-checkers.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-14T12:21:27Z"}
{"aid":"http://arxiv.org/abs/2504.10171v1","title":"Kullback-Leibler excess risk bounds for exponential weighted aggregation\n  in Generalized linear models","summary":"Aggregation methods have emerged as a powerful and flexible framework in\nstatistical learning, providing unified solutions across diverse problems such\nas regression, classification, and density estimation. In the context of\ngeneralized linear models (GLMs), where responses follow exponential family\ndistributions, aggregation offers an attractive alternative to classical\nparametric modeling. This paper investigates the problem of sparse aggregation\nin GLMs, aiming to approximate the true parameter vector by a sparse linear\ncombination of predictors. We prove that an exponential weighted aggregation\nscheme yields a sharp oracle inequality for the Kullback-Leibler risk with\nleading constant equal to one, while also attaining the minimax-optimal rate of\naggregation. These results are further enhanced by establishing\nhigh-probability bounds on the excess risk.","main_category":"math.ST","categories":"math.ST,stat.ML,stat.TH","published":"2025-04-14T12:25:11Z"}
{"aid":"http://arxiv.org/abs/2504.10178v1","title":"MSCoT: Structured Chain-of-Thought Generation for Multiple Programming\n  Languages","summary":"With the rapid development of code intelligence, the application of multiple\nprogramming languages is becoming increasingly widespread. However, most\nexisting code generation models mainly focus on a single or a few programming\nlanguages, resulting in unsatisfactory performance in a multilingual\nenvironment. Chain-of-Thought (CoT) reasoning can significantly improve the\nperformance of the model without the need for retraining or fine-tuning the\ncode generation model by reasonably decomposing complex code generation tasks\ninto multiple subtasks and gradually deriving solutions for each subtask.\nNevertheless, the existing CoT generation methods mainly concentrate on Python\ncode, and the performance on other programming languages remains unclear. To\nfill this gap, we first constructed a CoT generation dataset for 12 programming\nlanguages through multi-agent technology. On this basis, we proposed a CoT\ngeneration method MSCoT applicable to multiple programming languages. By\nintroducing CoT into the code generation large model, the performance of the\ncode generation large model in a multilingual environment can be improved.\nThrough large-scale empirical research, we compared the generalization\nabilities of MSCoT and the existing CoT generation methods on multiple\nprogramming languages and proved the effectiveness of MSCoT for multiple\nprogramming languages. In addition, we also designed a human study to prove the\nquality of the CoT generated by MSCoT. Finally, we opensourced the model and\ndataset of MSCoT to promote the research on CoT generation for multiple\nprogramming languages.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-14T12:30:47Z"}
{"aid":"http://arxiv.org/abs/2504.10185v1","title":"LLM Unlearning Reveals a Stronger-Than-Expected Coreset Effect in\n  Current Benchmarks","summary":"Large language model unlearning has become a critical challenge in ensuring\nsafety and controlled model behavior by removing undesired data-model\ninfluences from the pretrained model while preserving general utility.\nSignificant recent efforts have been dedicated to developing LLM unlearning\nbenchmarks such as WMDP (Weapons of Mass Destruction Proxy) and MUSE (Machine\nUnlearning Six-way Evaluation), facilitating standardized unlearning\nperformance assessment and method comparison. Despite their usefulness, we\nuncover for the first time a novel coreset effect within these benchmarks.\nSpecifically, we find that LLM unlearning achieved with the original (full)\nforget set can be effectively maintained using a significantly smaller subset\n(functioning as a \"coreset\"), e.g., as little as 5% of the forget set, even\nwhen selected at random. This suggests that LLM unlearning in these benchmarks\ncan be performed surprisingly easily, even in an extremely low-data regime. We\ndemonstrate that this coreset effect remains strong, regardless of the LLM\nunlearning method used, such as NPO (Negative Preference Optimization) and RMU\n(Representation Misdirection Unlearning), the popular ones in these benchmarks.\nThe surprisingly strong coreset effect is also robust across various data\nselection methods, ranging from random selection to more sophisticated\nheuristic approaches. We explain the coreset effect in LLM unlearning through a\nkeyword-based perspective, showing that keywords extracted from the forget set\nalone contribute significantly to unlearning effectiveness and indicating that\ncurrent unlearning is driven by a compact set of high-impact tokens rather than\nthe entire dataset. We further justify the faithfulness of coreset-unlearned\nmodels along additional dimensions, such as mode connectivity and robustness to\njailbreaking attacks. Codes are available at\nhttps://github.com/OPTML-Group/MU-Coreset.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-14T12:38:37Z"}
{"aid":"http://arxiv.org/abs/2504.10195v1","title":"Simulation of TOPCon/PERC Hybrid Bottom Structure for Perovskite/Silicon\n  Tandem Solar Cells using Quokka3","summary":"This work emphasizes the potential of perovskite/silicon tandem solar cells\nfor increased power conversion efficiencies. By employing crystalline silicon\n(c-Si) as the bottom cell, particularly with p-type PERC technology, there are\ncost-effective and advantageous physical properties. However, traditional\nphosphorus-doped emitters in PERC Si bottom cells are hindered by high surface\nrecombination, which limits their performance. This research introduces a novel\nhybrid PERC/TOPCon structure that integrates a phosphorus-doped poly-Si (n+\nTOPCon) layer as the front emitter to address these challenges. Numerical\nsimulations using Quokka3 confirmed the feasibility of the design, focusing on\noptimizing the rear side metallization to enhance implied open-circuit voltage\n(Voc) and fill factor (FF). A two-step process systematically varied local\ncontact openings to examine their impact on performance metrics. Results\nhighlighted optimal rear metallization parameters, achieving optimal metal\nfractions approximately 2%. This innovative approach demonstrates the\neffectiveness of combining TOPCon and PERC technologies for bottom cells in\ntandem structures, providing valuable insights into their development and\noptimization. The study underscores the potential of the hybrid PERC/TOPCon\nstructure in enhancing the functionality and efficiency of perovskite/silicon\ntandem solar cells.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-14T12:56:45Z"}
{"aid":"http://arxiv.org/abs/2504.10204v1","title":"Cohomological obstructions to equivariant unirationality","summary":"We study cohomological obstructions to equivariant unirationality, with\nspecial regard to actions of finite groups on del Pezzo surfaces and Fano\nthreefolds.","main_category":"math.AG","categories":"math.AG","published":"2025-04-14T13:12:54Z"}
{"aid":"http://arxiv.org/abs/2504.10235v1","title":"Eccentric mergers of binary Proca stars","summary":"We present a numerical relativity study of eccentric mergers of equal-mass\nrotating $\\bar m=1$ Proca stars, focusing on their gravitational-wave (GW)\nemission. By systematically varying key binary parameters, such as the initial\norbital boost, which determines the orbital angular momentum, and the relative\nphase between the stars, we examine how the internal phase structure of the\nProca field influences the merger dynamics and the properties of the emitted\nGWs. Our simulations demonstrate that the relative phase has paramount impact\non the post-merger evolution, resulting in prompt black hole formation\naccompanied by a transient Proca remnant, the formation of a hypermassive $\\bar\nm=1$ Proca star or even the emergence of a dynamically-unstable spinning $\\bar\nm=2$ Proca star. Under certain conditions, the GW signal exhibits significant\nodd-modes (e.g., the $\\ell=m=3$ mode) that are absent in conventional black\nhole mergers, potentially serving as unique signatures of these exotic objects.\nOur findings offer new insights into the phenomenology of bosonic star mergers\nand the potential astrophysical role of ultralight bosonic fields.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-14T13:59:33Z"}
{"aid":"http://arxiv.org/abs/2504.10253v1","title":"TinyverseGP: Towards a Modular Cross-domain Benchmarking Framework for\n  Genetic Programming","summary":"Over the years, genetic programming (GP) has evolved, with many proposed\nvariations, especially in how they represent a solution. Being essentially a\nprogram synthesis algorithm, it is capable of tackling multiple problem\ndomains. Current benchmarking initiatives are fragmented, as the different\nrepresentations are not compared with each other and their performance is not\nmeasured across the different domains. In this work, we propose a unified\nframework, dubbed TinyverseGP (inspired by tinyGP), which provides support to\nmultiple representations and problem domains, including symbolic regression,\nlogic synthesis and policy search.","main_category":"cs.NE","categories":"cs.NE,cs.LG,cs.SC","published":"2025-04-14T14:14:27Z"}
{"aid":"http://arxiv.org/abs/2504.10277v1","title":"RealHarm: A Collection of Real-World Language Model Application Failures","summary":"Language model deployments in consumer-facing applications introduce numerous\nrisks. While existing research on harms and hazards of such applications\nfollows top-down approaches derived from regulatory frameworks and theoretical\nanalyses, empirical evidence of real-world failure modes remains underexplored.\nIn this work, we introduce RealHarm, a dataset of annotated problematic\ninteractions with AI agents built from a systematic review of publicly reported\nincidents. Analyzing harms, causes, and hazards specifically from the\ndeployer's perspective, we find that reputational damage constitutes the\npredominant organizational harm, while misinformation emerges as the most\ncommon hazard category. We empirically evaluate state-of-the-art guardrails and\ncontent moderation systems to probe whether such systems would have prevented\nthe incidents, revealing a significant gap in the protection of AI\napplications.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.CL,cs.CR","published":"2025-04-14T14:44:41Z"}
{"aid":"http://arxiv.org/abs/2504.10279v1","title":"Elastic Planetoids","summary":"Modeling the internal structure of self-gravitating solid and liquid bodies\npresents a challenge, as existing approaches are often limited to either overly\nsimplistic constant-density approximations or more complex numerical equations\nof state. We present a detailed analysis of a tractable and physically\nmotivated model for perfectly elastic, spherically symmetric self-gravitating\nbodies in hydrostatic equilibrium. The model employs a logarithmic equation of\nstate (logotropic EOS) with a non-zero initial density and constant bulk\nmodulus. Importantly, scaling properties of the model allow all solutions to be\nderived from a single, universal solution of an ordinary differential equation,\nresembling the Lane-Emden and Chandrasekhar models. The model provides new\ninsights into stability issues and reveals oscillatory asymptotic behavior in\nthe mass-radius relation, including the existence of both a maximum mass and a\nmaximum radius. We derive useful, simple analytical approximations for key\nproperties, such as central overdensity, moment of inertia, binding energy, and\ngravitational potential, applicable to small, metallic bodies like asteroids\nand moons. These new approximations could aid future research, including space\nmining and the scientific characterization of small Solar System bodies.","main_category":"astro-ph.EP","categories":"astro-ph.EP,cond-mat.mtrl-sci,physics.space-ph","published":"2025-04-14T14:45:38Z"}
{"aid":"http://arxiv.org/abs/2504.10282v1","title":"Optimal Execution in Intraday Energy Markets under Hawkes Processes with\n  Transient Impact","summary":"This paper investigates optimal execution strategies in intraday energy\nmarkets through a mutually exciting Hawkes process model. Calibrated to data\nfrom the German intraday electricity market, the model effectively captures key\nempirical features, including intra-session volatility, distinct intraday\nmarket activity patterns, and the Samuelson effect as gate closure approaches.\nBy integrating a transient price impact model with a bivariate Hawkes process\nto model the market order flow, we derive an optimal trading trajectory for\nenergy companies managing large volumes, accounting for the specific trading\npatterns in these markets. A back-testing analysis compares the proposed\nstrategy against standard benchmarks such as Time-Weighted Average Price (TWAP)\nand Volume-Weighted Average Price (VWAP), demonstrating substantial cost\nreductions across various hourly trading products in intraday energy markets.","main_category":"q-fin.TR","categories":"q-fin.TR","published":"2025-04-14T14:51:18Z"}
{"aid":"http://arxiv.org/abs/2504.10294v1","title":"Ankle Exoskeletons in Walking and Load-Carrying Tasks: Insights into\n  Biomechanics and Human-Robot Interaction","summary":"Background: Lower limb exoskeletons can enhance quality of life, but\nwidespread adoption is limited by the lack of frameworks to assess their\nbiomechanical and human-robot interaction effects, which are essential for\ndeveloping adaptive and personalized control strategies. Understanding impacts\non kinematics, muscle activity, and HRI dynamics is key to achieve improved\nusability of wearable robots. Objectives: We propose a systematic methodology\nevaluate an ankle exoskeleton's effects on human movement during walking and\nload-carrying (10 kg front pack), focusing on joint kinematics, muscle\nactivity, and HRI torque signals. Materials and Methods: Using Xsens MVN\n(inertial motion capture), Delsys EMG, and a unilateral exoskeleton, three\nexperiments were conducted: (1) isolated dorsiflexion/plantarflexion; (2) gait\nanalysis (two subjects, passive/active modes); and (3) load-carrying under\nassistance. Results and Conclusions: The first experiment confirmed that the\nHRI sensor captured both voluntary and involuntary torques, providing\ndirectional torque insights. The second experiment showed that the device\nslightly restricted ankle range of motion (RoM) but supported normal gait\npatterns across all assistance modes. The exoskeleton reduced muscle activity,\nparticularly in active mode. HRI torque varied according to gait phases and\nhighlighted reduced synchronization, suggesting a need for improved support.\nThe third experiment revealed that load-carrying increased GM and TA muscle\nactivity, but the device partially mitigated user effort by reducing muscle\nactivity compared to unassisted walking. HRI increased during load-carrying,\nproviding insights into user-device dynamics. These results demonstrate the\nimportance of tailoring exoskeleton evaluation methods to specific devices and\nusers, while offering a framework for future studies on exoskeleton\nbiomechanics and HRI.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T15:05:02Z"}
{"aid":"http://arxiv.org/abs/2504.10310v1","title":"Existence of Nonequilibrium Glasses in the Degenerate Stealthy\n  Hyperuniform Ground-State Manifold","summary":"Stealthy interactions are an emerging class of nontrivial, bounded\nlong-ranged oscillatory pair potentials with classical ground states that can\nbe disordered, hyperuniform, and infinitely degenerate. Their hybrid\ncrystal-liquid nature endows them with novel physical properties with\nadvantages over their crystalline counterparts. Here, we show the existence of\nnonequilibrium hard-sphere glasses within this unusual ground-state manifold as\nthe stealthiness parameter $\\chi$ tends to zero that are remarkably\nconfigurationally extremely close to hyperuniform 3D maximally random jammed\n(MRJ) sphere packings. The latter are prototypical glasses since they are\nmaximally disordered, perfectly rigid, and perfectly nonergodic. Our\noptimization procedure, which leverages the maximum cardinality of the infinite\nground-state set, not only guarantees that our packings are hyperuniform with\nthe same structure-factor scaling exponent as the MRJ state, but they share\nother salient structural attributes, including a packing fraction of $0.638$, a\nmean contact number per particle of 6, gap exponent of $0.44(1)$, and pair\ncorrelation functions $g_2(r)$ and structures factors $S(k)$ that are virtually\nidentical to one another for all $r$ and $k$, respectively. Moreover, we\ndemonstrate that stealthy hyperuniform packings can be created within the\ndisordered regime ($0 < \\chi <1/2$) with heretofore unattained maximal packing\nfractions. As $\\chi$ increases from zero, they always form interparticle\ncontacts, albeit with sparser contact networks as $\\chi$ increases from zero,\nresulting in linear polymer-like chains of contacting particles with\nincreasingly shorter chain lengths. The capacity to generate ultradense\nstealthy hyperuniform packings for all $\\chi$ opens up new materials\napplications in optics and acoustics.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.stat-mech,physics.comp-ph","published":"2025-04-14T15:19:03Z"}
{"aid":"http://arxiv.org/abs/2504.10340v1","title":"Forecasting from Clinical Textual Time Series: Adaptations of the\n  Encoder and Decoder Language Model Families","summary":"Clinical case reports encode rich, temporal patient trajectories that are\noften underexploited by traditional machine learning methods relying on\nstructured data. In this work, we introduce the forecasting problem from\ntextual time series, where timestamped clinical findings--extracted via an\nLLM-assisted annotation pipeline--serve as the primary input for prediction. We\nsystematically evaluate a diverse suite of models, including fine-tuned\ndecoder-based large language models and encoder-based transformers, on tasks of\nevent occurrence prediction, temporal ordering, and survival analysis. Our\nexperiments reveal that encoder-based models consistently achieve higher F1\nscores and superior temporal concordance for short- and long-horizon event\nforecasting, while fine-tuned masking approaches enhance ranking performance.\nIn contrast, instruction-tuned decoder models demonstrate a relative advantage\nin survival analysis, especially in early prognosis settings. Our sensitivity\nanalyses further demonstrate the importance of time ordering, which requires\nclinical time series construction, as compared to text ordering, the format of\nthe text inputs that LLMs are classically trained on. This highlights the\nadditional benefit that can be ascertained from time-ordered corpora, with\nimplications for temporal tasks in the era of widespread LLM use.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T15:48:56Z"}
{"aid":"http://arxiv.org/abs/2504.10350v1","title":"Benchmarking 3D Human Pose Estimation Models Under Occlusions","summary":"This paper addresses critical challenges in 3D Human Pose Estimation (HPE) by\nanalyzing the robustness and sensitivity of existing models to occlusions,\ncamera position, and action variability. Using a novel synthetic dataset,\nBlendMimic3D, which includes diverse scenarios with multi-camera setups and\nseveral occlusion types, we conduct specific tests on several state-of-the-art\nmodels. Our study focuses on the discrepancy in keypoint formats between common\ndatasets such as Human3.6M, and 2D datasets such as COCO, commonly used for 2D\ndetection models and frequently input of 3D HPE models. Our work explores the\nimpact of occlusions on model performance and the generality of models trained\nexclusively under standard conditions. The findings suggest significant\nsensitivity to occlusions and camera settings, revealing a need for models that\nbetter adapt to real-world variability and occlusion scenarios. This research\ncontributed to ongoing efforts to improve the fidelity and applicability of 3D\nHPE systems in complex environments.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:00:25Z"}
{"aid":"http://arxiv.org/abs/2504.10354v1","title":"The diagonal and Hadamard grade of hypergeometric functions","summary":"Diagonals of rational functions are an important class of functions arising\nin number theory, algebraic geometry, combinatorics, and physics. In this paper\nwe study the diagonal grade of a function $f$, which is defined to be the\nsmallest $n$ such that $f$ is the diagonal of a rational function in variables\n$x_0,\\dots, x_n$. We relate the diagonal grade of a function to the nilpotence\nof the associated differential equation. This allows us to determine the\ndiagonal grade of many hypergeometric functions and answer affirmatively the\noutstanding question on the existence of functions with diagonal grade greater\nthan $2$. In particular, we show that\n$\\prescript{}{n}F_{n-1}(\\frac{1}{2},\\dots, \\frac{1}{2};1\\dots,1 \\mid x)$ has\ndiagonal grade $n$ for each $n\\geq 1$. Our method also applies to the\ngenerating function of the Ap\\'ery sequence, which we find to have diagonal\ngrade $3$. We also answer related questions on Hadamard grades posed by\nAllouche and Mend\\`es France. For example, we show that\n$\\prescript{}{n}F_{n-1}(\\frac{1}{2},\\dots, \\frac{1}{2};1\\dots,1 \\mid x)$ has\nHadamard grade $n$ for all $n\\geq 1$.","main_category":"math.CO","categories":"math.CO,math-ph,math.AG,math.MP,math.NT","published":"2025-04-14T16:03:32Z"}
{"aid":"http://arxiv.org/abs/2504.10358v1","title":"FingER: Content Aware Fine-grained Evaluation with Reasoning for\n  AI-Generated Videos","summary":"Recent advances in video generation have posed great challenges in the\nassessment of AI-generated content, particularly with the emergence of\nincreasingly sophisticated models. The various inconsistencies and defects\nobserved in such videos are inherently complex, making overall scoring\nnotoriously difficult. In this paper, we emphasize the critical importance of\nintegrating fine-grained reasoning into video evaluation, and we propose\n$\\textbf{F}$ing$\\textbf{ER}$, a novel entity-level reasoning evaluation\nframework that first automatically generates $\\textbf{F}$ine-grained\n$\\textbf{E}$ntity-level questions, and then answers those questions by a\n$\\textbf{R}$easoning model with scores, which can be subsequently weighted\nsummed to an overall score for different applications. Specifically, we\nleverage LLMs to derive entity-level questions across five distinct\nperspectives, which (i) often focus on some specific entities of the content,\nthereby making answering or scoring much easier by MLLMs, and (ii) are more\ninterpretable. Then we construct a FingER dataset, consisting of approximately\n3.3k videos and corresponding 60k fine-grained QA annotations, each with\ndetailed reasons. Based on that, we further investigate various training\nprotocols to best incentivize the reasoning capability of MLLMs for correct\nanswer prediction. Extensive experiments demonstrate that a reasoning model\ntrained using Group Relative Policy Optimization (GRPO) with a cold-start\nstrategy achieves the best performance. Notably, our model surpasses existing\nmethods by a relative margin of $11.8\\%$ on GenAI-Bench and $5.5\\%$ on\nMonetBench with only 3.3k training videos, which is at most one-tenth of the\ntraining samples utilized by other methods. Our code and dataset will be\nreleased soon.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-14T16:07:16Z"}
{"aid":"http://arxiv.org/abs/2504.10364v1","title":"Widely FSR tunable high Q-factor microresonators formed at the\n  intersection of straight optical fibers","summary":"We present a new class of high-Q tunable microresonators formed at the\nintersection of two straight silica optical fibers, whose free spectral range\n(FSR) can be widely tuned by fiber rotation. The proposed configuration avoids\nthe limitations of traditional monolithic microresonators that lack FSR\ntunability required for a wide range of photonic applications. Using small\nrotation angles (1-15 mrad), we demonstrate a tunability of the FSR from 2 pm\nto 10 pm, enabled by microscale fiber displacements that reshape the resonator\nprofile over millimeter scales. The proposed approach minimizes mechanical\nstress, supports miniaturization, and is suitable for integration with MEMS. It\npaves the way for the fabrication of tunable delay lines, ultralow repetition\nrate broadband frequency comb generators, and nonlocal optofluidic sensors on a\nchip.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-14T16:10:08Z"}
{"aid":"http://arxiv.org/abs/2504.10375v1","title":"PG-DPIR: An efficient plug-and-play method for high-count\n  Poisson-Gaussian inverse problems","summary":"Poisson-Gaussian noise describes the noise of various imaging systems thus\nthe need of efficient algorithms for Poisson-Gaussian image restoration. Deep\nlearning methods offer state-of-the-art performance but often require\nsensor-specific training when used in a supervised setting. A promising\nalternative is given by plug-and-play (PnP) methods, which consist in learning\nonly a regularization through a denoiser, allowing to restore images from\nseveral sources with the same network. This paper introduces PG-DPIR, an\nefficient PnP method for high-count Poisson-Gaussian inverse problems, adapted\nfrom DPIR. While DPIR is designed for white Gaussian noise, a naive adaptation\nto Poisson-Gaussian noise leads to prohibitively slow algorithms due to the\nabsence of a closed-form proximal operator. To address this, we adapt DPIR for\nthe specificities of Poisson-Gaussian noise and propose in particular an\nefficient initialization of the gradient descent required for the proximal step\nthat accelerates convergence by several orders of magnitude. Experiments are\nconducted on satellite image restoration and super-resolution problems.\nHigh-resolution realistic Pleiades images are simulated for the experiments,\nwhich demonstrate that PG-DPIR achieves state-of-the-art performance with\nimproved efficiency, which seems promising for on-ground satellite processing\nchains.","main_category":"cs.CV","categories":"cs.CV,cs.LG,eess.IV","published":"2025-04-14T16:23:15Z"}
{"aid":"http://arxiv.org/abs/2504.10378v1","title":"Cosmogenic Neutrino Point Source and KM3-230213A","summary":"Cosmogenic neutrinos (CNs) are produced by ultra-high energy cosmic rays\n(UHECRs) interacting with cosmic background radiation. We investigated the\nproperties of CN point/extended sources, i.e, the neutrino spectrum, and\nangular profile as functions of time, by assuming that UHECR sources are\ntransient events, such as gamma-ray bursts. The properties depend much on the\nintergalactic magnetic field (IGMF), but the angular extent is in general\nsub-degree, within which the CN flux can overshoot the diffuse CN flux in early\ntime. The nearby CN point sources could be detected for the low IGMF case by\nfuture neutrino telescopes. The recent KM3-230213A event is possible to account\nfor by a nearby transient CN source, rather than diffuse CN emission.\nObservations of CN point sources will provide a chance to search for UHECR\nsources.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-14T16:24:52Z"}
{"aid":"http://arxiv.org/abs/2504.10390v1","title":"Teacher Motion Priors: Enhancing Robot Locomotion over Challenging\n  Terrain","summary":"Achieving robust locomotion on complex terrains remains a challenge due to\nhigh dimensional control and environmental uncertainties. This paper introduces\na teacher prior framework based on the teacher student paradigm, integrating\nimitation and auxiliary task learning to improve learning efficiency and\ngeneralization. Unlike traditional paradigms that strongly rely on\nencoder-based state embeddings, our framework decouples the network design,\nsimplifying the policy network and deployment. A high performance teacher\npolicy is first trained using privileged information to acquire generalizable\nmotion skills. The teacher's motion distribution is transferred to the student\npolicy, which relies only on noisy proprioceptive data, via a generative\nadversarial mechanism to mitigate performance degradation caused by\ndistributional shifts. Additionally, auxiliary task learning enhances the\nstudent policy's feature representation, speeding up convergence and improving\nadaptability to varying terrains. The framework is validated on a humanoid\nrobot, showing a great improvement in locomotion stability on dynamic terrains\nand significant reductions in development costs. This work provides a practical\nsolution for deploying robust locomotion strategies in humanoid robots.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-14T16:36:56Z"}
{"aid":"http://arxiv.org/abs/2504.10394v1","title":"Digits of pi: limits to the seeming randomness II","summary":"According to a popular belief, the decimal digits of mathematical constants\nsuch as {\\pi} behave like statistically independent random variables, each\ntaking the values 0, 1, 2, 3, 4, 5, 6, 7, 8, and 9 with equal probability of\n1/10. If this is the case, then, in particular, the decimal representations of\nthese constants should tend to satisfy the central limit theorem (CLT) and the\nlaw of the iterated logarithm (LIL). The paper presents the results of a direct\nstatistical analysis of the decimal representations of 12 mathematical\nconstants with respect to the central limit theorem (CLT) and the law of the\niterated logarithm (LIL). The first billion digits of each constant were\nanalyzed, with ten billion digits examined in the case of {\\pi}. Within these\nlimits, no evidence was found to suggest that the digits of these constants\nsatisfy CLT or LIL.","main_category":"math.NT","categories":"math.NT","published":"2025-04-14T16:42:47Z"}
{"aid":"http://arxiv.org/abs/2504.10395v1","title":"Better Coherence, Better Height: Fusing Physical Models and Deep\n  Learning for Forest Height Estimation from Interferometric SAR Data","summary":"Estimating forest height from Synthetic Aperture Radar (SAR) images often\nrelies on traditional physical models, which, while interpretable and\ndata-efficient, can struggle with generalization. In contrast, Deep Learning\n(DL) approaches lack physical insight. To address this, we propose CoHNet - an\nend-to-end framework that combines the best of both worlds: DL optimized with\nphysics-informed constraints. We leverage a pre-trained neural surrogate model\nto enforce physical plausibility through a unique training loss. Our\nexperiments show that this approach not only improves forest height estimation\naccuracy but also produces meaningful features that enhance the reliability of\npredictions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:44:08Z"}
{"aid":"http://arxiv.org/abs/2504.10402v1","title":"Can spacetime torsion source an extremely red-tilted cosmological GW\n  background?","summary":"In the presence of spacetime torsion, any generic $f(R)$ model of gravity is\nconformally dual to a scalar-tensor theory augmented with a second rank\nantisymmetric massless degree of freedom. We investigate the stochastic\ngravitational wave background (SGWB) that may be sourced directly at the second\norder by such a torsional field, treated perturbatively during an epoch of\ncanonical, single-field, slow-roll inflation. The resulting second-order\ninduced SGWB, which dominates over the primary inflationary GW background at\nall scales, peaks only at ultra-low frequencies, and is found to be extremely\nred-tilted with an effective tensor spectral index $\\alpha_{\\rm T}\\sim-6$ on\nmatter-dominated scales. The signal is potentially within the reach of upcoming\nindirect GW probes on very large scales $k\\lesssim10^{-2}\\:\\textrm{Mpc}^{-1}$,\ni.e., next-generation CMB experiments like the LiteBIRD. In the near future,\nobservation of such a markedly red-tilted SGWB on CMB scales could hence\nprovide a novel and unique clue in favour of torsional gravity during the\ninflationary era.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-14T16:52:22Z"}
{"aid":"http://arxiv.org/abs/2504.10403v1","title":"Satellite Federated Fine-Tuning for Foundation Models in Space Computing\n  Power Networks","summary":"Advancements in artificial intelligence (AI) and low-earth orbit (LEO)\nsatellites have promoted the application of large remote sensing foundation\nmodels for various downstream tasks. However, direct downloading of these\nmodels for fine-tuning on the ground is impeded by privacy concerns and limited\nbandwidth. Satellite federated learning (FL) offers a solution by enabling\nmodel fine-tuning directly on-board satellites and aggregating model updates\nwithout data downloading. Nevertheless, for large foundation models, the\ncomputational capacity of satellites is insufficient to support effective\non-board fine-tuning in traditional satellite FL frameworks. To address these\nchallenges, we propose a satellite-ground collaborative federated fine-tuning\nframework. The key of the framework lies in how to reasonably decompose and\nallocate model components to alleviate insufficient on-board computation\ncapabilities. During fine-tuning, satellites exchange intermediate results with\nground stations or other satellites for forward propagation and back\npropagation, which brings communication challenges due to the special\ncommunication topology of space transmission networks, such as intermittent\nsatellite-ground communication, short duration of satellite-ground\ncommunication windows, and unstable inter-orbit inter-satellite links (ISLs).\nTo reduce transmission delays, we further introduce tailored communication\nstrategies that integrate both communication and computing resources.\nSpecifically, we propose a parallel intra-orbit communication strategy, a\ntopology-aware satellite-ground communication strategy, and a\nlatency-minimalization inter-orbit communication strategy to reduce space\ncommunication costs. Simulation results demonstrate significant reductions in\ntraining time with improvements of approximately 33%.","main_category":"cs.LG","categories":"cs.LG,cs.DC,cs.NI","published":"2025-04-14T16:52:34Z"}
{"aid":"http://arxiv.org/abs/2504.10414v1","title":"HUMOTO: A 4D Dataset of Mocap Human Object Interactions","summary":"We present Human Motions with Objects (HUMOTO), a high-fidelity dataset of\nhuman-object interactions for motion generation, computer vision, and robotics\napplications. Featuring 736 sequences (7,875 seconds at 30 fps), HUMOTO\ncaptures interactions with 63 precisely modeled objects and 72 articulated\nparts. Our innovations include a scene-driven LLM scripting pipeline creating\ncomplete, purposeful tasks with natural progression, and a mocap-and-camera\nrecording setup to effectively handle occlusions. Spanning diverse activities\nfrom cooking to outdoor picnics, HUMOTO preserves both physical accuracy and\nlogical task flow. Professional artists rigorously clean and verify each\nsequence, minimizing foot sliding and object penetrations. We also provide\nbenchmarks compared to other datasets. HUMOTO's comprehensive full-body motion\nand simultaneous multi-object interactions address key data-capturing\nchallenges and provide opportunities to advance realistic human-object\ninteraction modeling across research domains with practical applications in\nanimation, robotics, and embodied AI systems. Project:\nhttps://jiaxin-lu.github.io/humoto/ .","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:59:29Z"}
{"aid":"http://arxiv.org/abs/2504.10420v1","title":"Role of Coulomb-nuclear breakup of 6,7Li projectiles with heavy deformed\n  232Th target","summary":"The significance of both Coulomb and nuclear couplings and their interference\neffects in the breakup processes of 6,7Li with a non-spherical nucleus 232Th\nhas been evaluated. The continuum discretized coupled channel(CDCC)\ncalculations are carried out in a nonstandard way, using short-range imaginary\npotentials for the fragment-target interaction at energies close to the Coulomb\nbarrier. The present calculations employing short-range imaginary potentials\nexhibit better agreement with the experimental elastic scattering angular\ndistributions than those using standard systematic value (0.78xWSPP ) used to\ndescribe elastic scattering. Including the excitation of the 232Th inelastic\nshows significant coupling effects on the elastic scattering below the barrier\nenergies compared to higher incident energies. Subsequently, the CDCC framework\nwas used to analyze the nuclear, Coulomb, and total breakup predictions\nseparately. The breakup cross sections for the 6Li+232Th system are greater\nthan those for the 7Li+232Th system across various energies. The present study\npredicts destructive Coulomb-nuclear interference in the breakup processes\ninvolving both 6Li and 7Li projectile nuclei with the deformed 232Th target.\nAdditionally, the breakup reaction cross-sections are compared with\nexperimentally measured fusion cross-sections near the barrier energies for\nboth 6,7Li+232Th systems.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-14T17:07:28Z"}
{"aid":"http://arxiv.org/abs/2504.10429v1","title":"Out of the box approach to Black hole Information paradox","summary":"Suppose a black hole forms from a pure quantum state $\\ket{\\psi}$. The black\nhole information loss paradox arises from semiclassical arguments suggesting\nthat, even in a closed system, the process of black hole formation and\nevaporation evolves a pure state into a mixed state. Resolution to the paradox\ntypically demands violation of quantum mechanics or relativity in domains where\nthey should hold. Instead, I propose that in a complete theory of quantum\ngravity, any region $\\mathcal{U}$ that could collapse into a black hole should\nalready be described by a mixed state, thus bypassing the paradox entirely. To\nthat end, I present a model in which the universe is in a quantum\nerror-corrected state, such that any local black hole appears mixed and encodes\nno information locally.","main_category":"gr-qc","categories":"gr-qc,hep-th,quant-ph","published":"2025-04-14T17:19:57Z"}
{"aid":"http://arxiv.org/abs/2504.10433v1","title":"MonoDiff9D: Monocular Category-Level 9D Object Pose Estimation via\n  Diffusion Model","summary":"Object pose estimation is a core means for robots to understand and interact\nwith their environment. For this task, monocular category-level methods are\nattractive as they require only a single RGB camera. However, current methods\nrely on shape priors or CAD models of the intra-class known objects. We propose\na diffusion-based monocular category-level 9D object pose generation method,\nMonoDiff9D. Our motivation is to leverage the probabilistic nature of diffusion\nmodels to alleviate the need for shape priors, CAD models, or depth sensors for\nintra-class unknown object pose estimation. We first estimate coarse depth via\nDINOv2 from the monocular image in a zero-shot manner and convert it into a\npoint cloud. We then fuse the global features of the point cloud with the input\nimage and use the fused features along with the encoded time step to condition\nMonoDiff9D. Finally, we design a transformer-based denoiser to recover the\nobject pose from Gaussian noise. Extensive experiments on two popular benchmark\ndatasets show that MonoDiff9D achieves state-of-the-art monocular\ncategory-level 9D object pose estimation accuracy without the need for shape\npriors or CAD models at any stage. Our code will be made public at\nhttps://github.com/CNJianLiu/MonoDiff9D.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-14T17:21:10Z"}
{"aid":"http://arxiv.org/abs/2504.10438v1","title":"Streaming Democratized: Ease Across the Latency Spectrum with Delayed\n  View Semantics and Snowflake Dynamic Tables","summary":"Streaming data pipelines remain challenging and expensive to build and\nmaintain, despite significant advancements in stronger consistency, event time\nsemantics, and SQL support over the last decade. Persistent obstacles continue\nto hinder usability, such as the need for manual incrementalization, semantic\ndiscrepancies across SQL implementations, and the lack of enterprise-grade\noperational features. While the rise of incremental view maintenance (IVM) as a\nway to integrate streaming with databases has been a huge step forward,\ntransaction isolation in the presence of IVM remains underspecified, leaving\nthe maintenance of application-level invariants as a painful exercise for the\nuser. Meanwhile, most streaming systems optimize for latencies of 100 ms to 3\nsec, whereas many practical use cases are well-served by latencies ranging from\nseconds to tens of minutes.\n  We present delayed view semantics (DVS), a conceptual foundation that bridges\nthe semantic gap between streaming and databases, and introduce Dynamic Tables,\nSnowflake's declarative streaming transformation primitive designed to\ndemocratize analytical stream processing. DVS formalizes the intuition that\nstream processing is primarily a technique to eagerly compute derived results\nasynchronously, while also addressing the need to reason about the resulting\nsystem end to end. Dynamic Tables then offer two key advantages: ease of use\nthrough DVS, enterprise-grade features, and simplicity; as well as scalable\ncost efficiency via IVM with an architecture designed for diverse latency\nrequirements.\n  We first develop extensions to transaction isolation that permit the\npreservation of invariants in streaming applications. We then detail the\nimplementation challenges of Dynamic Tables and our experience operating it at\nscale. Finally, we share insights into user adoption and discuss our vision for\nthe future of stream processing.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-14T17:29:56Z"}
{"aid":"http://arxiv.org/abs/2504.10457v1","title":"Holographic Entanglement Entropy in the FLRW Universe","summary":"We compute a holographic entanglement entropy via Ryu--Takayanagi\nprescription in the three-dimensional Friedmann--Lema\\^itre--Robertson--Walker\nuniverse. We consider two types of holographic scenarios analogous to the\nstatic patch holography and the half de Sitter holography, in which the\nholographic boundary is timelike and placed in the bulk. We find in general\nthat the strong subadditivity can be satisfied only in the former type and in\naddition the holographic boundary has to fit inside the apparent horizon. Also,\nfor the universe filled with an ideal fluid of constant equation of state\n$w<-1$, the condition is sharpened as that the holographic boundary has to fit\ninside the event horizon instead. These conditions provide a necessary\ncondition for the dual quantum field theory to be standard and compatible with\nthe strong subadditivity.","main_category":"hep-th","categories":"hep-th,astro-ph.CO,gr-qc","published":"2025-04-14T17:44:34Z"}
{"aid":"http://arxiv.org/abs/2504.10461v1","title":"Layered Multirate Control of Constrained Linear Systems","summary":"Layered control architectures have been a standard paradigm for efficiently\nmanaging complex constrained systems. A typical architecture consists of: i) a\nhigher layer, where a low-frequency planner controls a simple model of the\nsystem, and ii) a lower layer, where a high-frequency tracking controller\nguides a detailed model of the system toward the output of the higher-layer\nmodel. A fundamental problem in this layered architecture is the design of\nplanners and tracking controllers that guarantee both higher- and lower-layer\nsystem constraints are satisfied. Toward addressing this problem, we introduce\na principled approach for layered multirate control of linear systems subject\nto output and input constraints. Inspired by discrete-time simulation\nfunctions, we propose a streamlined control design that guarantees the\nlower-layer system tracks the output of the higher-layer system with computable\nprecision. Using this design, we derive conditions and present a method for\npropagating the constraints of the lower-layer system to the higher-layer\nsystem. The propagated constraints are integrated into the design of an\narbitrary planner that can handle higher-layer system constraints. Our\nframework ensures that the output constraints of the lower-layer system are\nsatisfied at all high-level time steps, while respecting its input constraints\nat all low-level time steps. We apply our approach in a scenario of motion\nplanning, highlighting its critical role in ensuring collision avoidance.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-14T17:48:34Z"}
{"aid":"http://arxiv.org/abs/2504.10830v1","title":"Radiation Footprint Control in Cell-Free Cooperative ISAC: Optimal Joint\n  BS Activation and Beamforming Coordination","summary":"Coordinated beamforming across distributed base stations (BSs) in cell-free\narchitectures can efficiently support integrated sensing and communication\n(ISAC) users by improving resource sharing and reducing conflicts in the\nspatial domain. However, coordinating numerous BSs within the ISAC network\nposes risks of generating substantial interference for other networks sharing\nthe spectrum, while also increasing operational costs from power consumption\nand signaling overhead. Therefore, in this paper, we propose an\ninterference-suppressed and cost-optimized cell-free ISAC network by\nopportunistically and cooperatively orchestrating distributed radio resources\nto address competing sensing and communication (S\\&C) demands. Specifically, we\nconceive a radiation footprint control mechanism that autonomously suppresses\ninterference across the entire signal propagation space to safeguard other\nnetworks without exchanging signaling. Then, we propose joint BS activation and\nbeamforming coordination to dynamically activate appropriate BSs and\norchestrate their spatial beams for service provisioning. Building upon this\nframework, we formulate a cost-efficient utility maximization problem that\nconsiders individual S\\&C demands and location-dependent radiation footprint\nconstraints. Since this results in a non-convex optimization problem, we\ndevelop a monotonic optimization embedded branch-and-bound (MO-BRB) algorithm\nto find the optimal solution. Additionally, we apply a low-complexity iterative\nmethod to obtain near-optimal solutions. Finally, simulation results validate\nthe effectiveness of the proposed algorithms.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-15T03:14:05Z"}
{"aid":"http://arxiv.org/abs/2504.10837v1","title":"Elastocaloric signature of the excitonic instability in Ta$_2$NiSe$_5$","summary":"On cooling through a temperature $T_S$ of around 324 K, Ta$_2$NiSe$_5$\nundergoes a transition from a semimetallic state to one with a gapped\nelectronic spectrum which is suspected to be an excitonic insulator. However,\nat this transition the structure also changes, from orthorhombic to monoclinic,\nleaving open the question of whether it is driven primarily by excitonic\nordering or by a lattice instability. A lattice instability of this symmetry\nwould correspond to softening of a B$_{2g}$ optical or acoustic phonon mode.\nHere, we report that elastocaloric measurements of Ta$_2$NiSe$_5$ with induced\nB$_{2g}$ strain reveal a thermodynamic susceptibility described by a\nCurie-Weiss law with a Curie temperature $T^*$ of 298 K. The fact that $T^*$ is\nclose to $T_S$ rules out the possibility that the B$_{2g}$ acoustic mode is\nresponsible for the transition. Since prior Raman measurements have shown\nminimal softening of the B$_{2g}$ optical mode as well, our finding strengthens\nthe case that the transition is largely excitonic in nature. Our work\nunderscores the potential of using strain as a tool for separating electronic\nand lattice contributions in phase transitions.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-15T03:38:21Z"}
{"aid":"http://arxiv.org/abs/2504.10846v1","title":"Mosaic: Client-driven Account Allocation Framework in Sharded\n  Blockchains","summary":"Recent account allocation studies in sharded blockchains are typically\nminer-driven, requiring miners to perform global optimizations for all accounts\nto enhance system-wide performance. This forces each miner to maintain a\ncomplete copy of the entire ledger, resulting in significant storage,\ncommunication, and computation overhead.\n  In this work, we explore an alternative research direction by proposing\nMosaic, the first client-driven framework for distributed, lightweight local\noptimization. Rather than relying on miners to allocate all accounts, Mosaic\nenables clients to independently execute a local algorithm to determine their\nresiding shards. Clients can submit migration requests to a beacon chain when\nrelocation is necessary. Mosaic naturally addresses key limitations of\nminer-driven approaches, including the lack of miner incentives and the\nsignificant overhead. While clients are flexible to adopt any algorithm for\nshard allocation, we design and implement a reference algorithm, Pilot, to\nguide them. Clients execute Pilot to maximize their own benefits, such as\nreduced transaction fees and confirmation latency.\n  On a real-world Ethereum dataset, we implement and evaluate Pilot against\nstate-of-the-art miner-driven global optimization solutions. The results\ndemonstrate that Mosaic significantly enhances computational efficiency,\nachieving a four-order-of-magnitude reduction in computation time, with the\nreduced input data size from 1.44 GB to an average of 228.66 bytes per account.\nDespite these efficiency gains, Pilot introduces only about a 5% increase in\nthe cross-shard ratio and maintains approximately 98% of the system throughput,\ndemonstrating a minimal trade-off in overall effectiveness.","main_category":"cs.DC","categories":"cs.DC,cs.DB,cs.GT","published":"2025-04-15T04:07:09Z"}
{"aid":"http://arxiv.org/abs/2504.10854v1","title":"LVLM_CSP: Accelerating Large Vision Language Models via Clustering,\n  Scattering, and Pruning for Reasoning Segmentation","summary":"Large Vision Language Models (LVLMs) have been widely adopted to guide vision\nfoundation models in performing reasoning segmentation tasks, achieving\nimpressive performance. However, the substantial computational overhead\nassociated with LVLMs presents a new challenge. The primary source of this\ncomputational cost arises from processing hundreds of image tokens. Therefore,\nan effective strategy to mitigate such overhead is to reduce the number of\nimage tokens, a process known as image token pruning. Previous studies on image\ntoken pruning for LVLMs have primarily focused on high level visual\nunderstanding tasks, such as visual question answering and image captioning. In\ncontrast, guiding vision foundation models to generate accurate visual masks\nbased on textual queries demands precise semantic and spatial reasoning\ncapabilities. Consequently, pruning methods must carefully control individual\nimage tokens throughout the LVLM reasoning process. Our empirical analysis\nreveals that existing methods struggle to adequately balance reductions in\ncomputational overhead with the necessity to maintain high segmentation\naccuracy. In this work, we propose LVLM_CSP, a novel training free visual token\npruning method specifically designed for LVLM based reasoning segmentation\ntasks. LVLM_CSP consists of three stages: clustering, scattering, and pruning.\nInitially, the LVLM performs coarse-grained visual reasoning using a subset of\nselected image tokens. Next, fine grained reasoning is conducted, and finally,\nmost visual tokens are pruned in the last stage. Extensive experiments\ndemonstrate that LVLM_CSP achieves a 65% reduction in image token inference\nFLOPs with virtually no accuracy degradation, and a 70% reduction with only a\nminor 1% drop in accuracy on the 7B LVLM.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T04:27:15Z"}
{"aid":"http://arxiv.org/abs/2504.10859v1","title":"A Sublinear Algorithm for Path Feasibility Among Rectangular Obstacles","summary":"The problem of finding a path between two points while avoiding obstacles is\ncritical in robotic path planning. We focus on the feasibility problem:\ndetermining whether such a path exists. We model the robot as a query-specific\nrectangular object capable of moving parallel to its sides. The obstacles are\naxis-aligned, rectangular, and may overlap. Most previous works only consider\nnondisjoint rectangular objects and point-sized or statically sized robots. Our\napproach introduces a novel technique leveraging generalized Gabriel graphs and\nconstructs a data structure to facilitate online queries regarding path\nfeasibility with varying robot sizes in sublinear time. To efficiently handle\nfeasibility queries, we propose an online algorithm utilizing sweep line to\nconstruct a generalized Gabriel graph under the $L_\\infty$ norm, capturing key\ngap constraints between obstacles. We utilize a persistent disjoint-set union\ndata structure to efficiently determine feasibility queries in\n$\\mathcal{O}(\\log n)$ time and $\\mathcal{O}(n)$ total space.","main_category":"cs.CG","categories":"cs.CG,cs.RO","published":"2025-04-15T04:40:25Z"}
{"aid":"http://arxiv.org/abs/2504.10875v1","title":"Emergence of Creativity and Individuality in Music: Insights from\n  Brain's Statistical Learning and its Embodied Mechanisms","summary":"Music is a universal feature of human culture, linked to embodied cognitive\nfunctions that drive learning, action, and the emergence of creativity and\nindividuality. Evidence highlights the critical role of statistical learning an\nimplicit cognitive process of the brain in musical creativity and\nindividuality. Despite its significance, the precise neural and computational\nmechanisms underpinning these dynamic and embodied cognitive processes re-main\npoorly understood. This paper discusses how individuality and creativity emerge\nwithin the framework of the brain's statistical learning, drawing on a series\nof neural and computational studies. This work offers perspectives on the\nmechanisms driving the heterogeneous nature of statistical learning abilities\nand embodied mechanisms and provides a framework to explain the paradoxical\nphenomenon where individuals with specific cognitive traits that limit certain\nperceptual abilities excel in creative domains.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-04-15T05:09:07Z"}
{"aid":"http://arxiv.org/abs/2504.10878v1","title":"Large Language Model-Informed Feature Discovery Improves Prediction and\n  Interpretation of Credibility Perceptions of Visual Content","summary":"In today's visually dominated social media landscape, predicting the\nperceived credibility of visual content and understanding what drives human\njudgment are crucial for countering misinformation. However, these tasks are\nchallenging due to the diversity and richness of visual features. We introduce\na Large Language Model (LLM)-informed feature discovery framework that\nleverages multimodal LLMs, such as GPT-4o, to evaluate content credibility and\nexplain its reasoning. We extract and quantify interpretable features using\ntargeted prompts and integrate them into machine learning models to improve\ncredibility predictions. We tested this approach on 4,191 visual social media\nposts across eight topics in science, health, and politics, using credibility\nratings from 5,355 crowdsourced workers. Our method outperformed zero-shot\nGPT-based predictions by 13 percent in R2, and revealed key features like\ninformation concreteness and image format. We discuss the implications for\nmisinformation mitigation, visual credibility, and the role of LLMs in social\nscience.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-15T05:11:40Z"}
{"aid":"http://arxiv.org/abs/2504.10943v1","title":"Drivers and barriers of adopting shared micromobility: a latent class\n  clustering model on the attitudes towards shared micromobility as part of\n  public transport trips in the Netherlands","summary":"Shared micromobility (SMM) is often cited as a solution to the first/last\nmile problem of public transport (train) travel, yet when implemented, they\noften do not get adopted by a broader travelling public. A large part of\nbehavioural adoption is related to peoples' attitudes and perceptions. In this\npaper, we develop an adjusted behavioural framework, based on the UTAUT2\ntechnology acceptance framework. We carry out an exploratory factor analysis\n(EFA) to obtain attitudinal factors which we then use to perform a latent class\ncluster analysis (LCCA), with the goal of studying the potential adoption of\nSMM and to assess the various drivers and barriers as perceived by different\nuser groups. Our findings suggest there are six distinct user groups with\nvarying intention to use shared micromobility: Progressives, Conservatives,\nHesitant participants, Bold innovators, Anxious observers and Skilled sceptics.\nBold innovators and Progressives tend to be the most open to adopting SMM and\nare also able to do so. Hesitant participants would like to, but find it\ndifficult or dangerous to use, while Skilled sceptics are capable and\nconfident, but have limited intention of using it. Conservatives and Anxious\nobservers are most negative about SMM, finding it difficult to use and\ndangerous. In general, factors relating to technological savviness,\nease-of-use, physical safety and societal perception seem to be the biggest\nbarriers to wider adoption. Younger, highly educated males are the group most\nlikely and open to using shared micromobility, while older individuals with\nlower incomes and a lower level of education tend to be the least likely.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-15T07:46:19Z"}
{"aid":"http://arxiv.org/abs/2504.10950v1","title":"Unveiling Challenges for LLMs in Enterprise Data Engineering","summary":"Large Language Models (LLMs) have demonstrated significant potential for\nautomating data engineering tasks on tabular data, giving enterprises a\nvaluable opportunity to reduce the high costs associated with manual data\nhandling. However, the enterprise domain introduces unique challenges that\nexisting LLM-based approaches for data engineering often overlook, such as\nlarge table sizes, more complex tasks, and the need for internal knowledge. To\nbridge these gaps, we identify key enterprise-specific challenges related to\ndata, tasks, and background knowledge and conduct a comprehensive study of\ntheir impact on recent LLMs for data engineering. Our analysis reveals that\nLLMs face substantial limitations in real-world enterprise scenarios, resulting\nin significant accuracy drops. Our findings contribute to a systematic\nunderstanding of LLMs for enterprise data engineering to support their adoption\nin industry.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-15T07:57:05Z"}
{"aid":"http://arxiv.org/abs/2504.10957v1","title":"When is Task Vector Provably Effective for Model Editing? A\n  Generalization Analysis of Nonlinear Transformers","summary":"Task arithmetic refers to editing the pre-trained model by adding a weighted\nsum of task vectors, each of which is the weight update from the pre-trained\nmodel to fine-tuned models for certain tasks. This approach recently gained\nattention as a computationally efficient inference method for model editing,\ne.g., multi-task learning, forgetting, and out-of-domain generalization\ncapabilities. However, the theoretical understanding of why task vectors can\nexecute various conceptual operations remains limited, due to the highly\nnon-convexity of training Transformer-based models. To the best of our\nknowledge, this paper provides the first theoretical characterization of the\ngeneralization guarantees of task vector methods on nonlinear Transformers. We\nconsider a conceptual learning setting, where each task is a binary\nclassification problem based on a discriminative pattern. We theoretically\nprove the effectiveness of task addition in simultaneously learning a set of\nirrelevant or aligned tasks, as well as the success of task negation in\nunlearning one task from irrelevant or contradictory tasks. Moreover, we prove\nthe proper selection of linear coefficients for task arithmetic to achieve\nguaranteed generalization to out-of-domain tasks. All of our theoretical\nresults hold for both dense-weight parameters and their low-rank\napproximations. Although established in a conceptual setting, our theoretical\nfindings were validated on a practical machine unlearning task using the large\nlanguage model Phi-1.5 (1.3B).","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-15T08:04:39Z"}
{"aid":"http://arxiv.org/abs/2504.10973v1","title":"Early Detection of Cognitive Impairment in Elderly using a Passive\n  FPVS-EEG BCI and Machine Learning -- Extended Version","summary":"Early dementia diagnosis requires biomarkers sensitive to both structural and\nfunctional brain changes. While structural neuroimaging biomarkers have\nprogressed significantly, objective functional biomarkers of early cognitive\ndecline remain a critical unmet need. Current cognitive assessments often rely\non behavioral responses, making them susceptible to factors like effort,\npractice effects, and educational background, thereby hindering early and\naccurate detection. This work introduces a novel approach, leveraging a\nlightweight convolutional neural network (CNN) to infer cognitive impairment\nlevels directly from electroencephalography (EEG) data. Critically, this method\nemploys a passive fast periodic visual stimulation (FPVS) paradigm, eliminating\nthe need for explicit behavioral responses or task comprehension from the\nparticipant. This passive approach provides an objective measure of working\nmemory function, independent of confounding factors inherent in active\ncognitive tasks, and offers a promising new avenue for early and unbiased\ndetection of cognitive decline.","main_category":"q-bio.NC","categories":"q-bio.NC,cs.HC,cs.LG,J.3","published":"2025-04-15T08:34:13Z"}
{"aid":"http://arxiv.org/abs/2504.10980v1","title":"Planar Hall effect in ultrathin topological insulator films","summary":"The planar Hall effect (PHE), previously observed in Weyl and Dirac\nsemimetals due to the chiral anomaly, emerges with a different origin in\ntopological insulators (TIs), where in-plane magnetic fields induce resistivity\nanisotropy. In strictly two-dimensional TIs, PHE is generally suppressed due to\nthe inability of the out-of-plane Berry curvature to couple to the in-plane\nband velocity of the charge carriers. Here, we demonstrate that in ultrathin TI\nfilms, a quasi-two-dimensional system, intersurface tunneling coupling with\nin-plane magnetization induces electronic anisotropy, enabling a finite PHE. In\naddition, we reveal that strong in-plane magnetization can stabilize the\nthickness-dependent quantum anomalous Hall effect, typically associated with\nout-of-plane magnetization. These insights advance the understanding of\nmagnetic topological phases, paving the way for next-generation spintronic\ndevices and magnetic sensing technologies.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-15T08:45:02Z"}
{"aid":"http://arxiv.org/abs/2504.10987v1","title":"Leveraging Vertical Public-Private Split for Improved Synthetic Data\n  Generation","summary":"Differentially Private Synthetic Data Generation (DP-SDG) is a key enabler of\nprivate and secure tabular-data sharing, producing artificial data that carries\nthrough the underlying statistical properties of the input data. This typically\ninvolves adding carefully calibrated statistical noise to guarantee individual\nprivacy, at the cost of synthetic data quality. Recent literature has explored\nscenarios where a small amount of public data is used to help enhance the\nquality of synthetic data. These methods study a horizontal public-private\npartitioning which assumes access to a small number of public rows that can be\nused for model initialization, providing a small utility gain. However,\nrealistic datasets often naturally consist of public and private attributes,\nmaking a vertical public-private partitioning relevant for practical synthetic\ndata deployments. We propose a novel framework that adapts horizontal\npublic-assisted methods into the vertical setting. We compare this framework\nagainst our alternative approach that uses conditional generation, highlighting\ninitial limitations of public-data assisted methods and proposing future\nresearch directions to address these challenges.","main_category":"cs.LG","categories":"cs.LG,cs.CR","published":"2025-04-15T08:59:03Z"}
{"aid":"http://arxiv.org/abs/2504.10990v1","title":"Mathematical Analysis of the PDE Model for the Consensus-based\n  Optimization","summary":"In this paper, we develop an analytical framework for the partial\ndifferential equation underlying the consensus-based optimization model. The\nmain challenge arises from the nonlinear, nonlocal nature of the consensus\npoint, coupled with a diffusion term that is both singular and degenerate. By\nemploying a regularization procedure in combination with a compactness\nargument, we establish the global existence and uniqueness of weak solutions in\n$L^\\infty(0,T;L^1\\cap L^\\infty(\\mathbb{R}^d))$. Furthermore, we show that the\nweak solutions exhibit improved $H^2$-regularity when the initial data is\nregular.","main_category":"math.AP","categories":"math.AP,math.OC","published":"2025-04-15T09:02:36Z"}
{"aid":"http://arxiv.org/abs/2504.11016v1","title":"Heating reduction as collective action: Impact on attitudes, behavior\n  and energy consumption in a Polish field experiment","summary":"Heating and hot water usage account for nearly 80% of household energy\nconsumption in the European Union. In order to reach the EU New Deal goals, new\npolicies to reduce heat energy consumption are indispensable. However, research\ntargeting reductions concentrates either on technical building interventions\nwithout considerations of people's behavior, or psychological interventions\nwith no technical interference. Such interventions can be promising, but their\ntrue potential for scaling up can only be realized by testing approaches that\nintegrate behavioral and technical solutions in tandem rather than in\nisolation. In this research, we study a mix of psychological and technical\ninterventions targeting heating and hot water demand among students in Polish\nuniversity dormitories. We evaluate effects on building energy consumption,\nbehavioral spillovers and on social beliefs and attitudes in a pre-post\nquasi-experimental mixed-method field study in three student dormitories. Our\nfindings reveal that the most effective approaches to yield energy savings were\na direct, collectively framed request to students to reduce thermostat settings\nfor the environment, and an automated technical adjustment of the heating curve\ntemperature. Conversely, interventions targeting domestic hot water had\nunintended effects, including increased energy use and negative spillovers,\nsuch as higher water consumption. Further, we find that informing students\nabout their active, collective participation had a positive impact on perceived\nsocial norms. Our findings highlight the importance of trialing interventions\nin controlled real-world settings to understand the interplay between technical\nsystems, behaviors, and social impacts to enable scalable, evidence-based\npolicies driving an effective and sustainable energy transition.","main_category":"cs.ET","categories":"cs.ET,cs.CY","published":"2025-04-15T09:41:37Z"}
{"aid":"http://arxiv.org/abs/2504.11047v1","title":"Hints for a Geon from Causal Dynamic Triangulations","summary":"The existence of geons, physical states of self-bound gravitons, has long\nbeen proposed. In the context of four-dimensional causal dynamical\ntriangulation simulations we investigate this possibility by measuring\ncurvature-curvature correlators of different gravitational operators. We find a\nbehavior consistent with a massive state, independent of the operators\nconsidered, over a certain distance window. While at most a hint, this is\ntantalizing due to its possible implications for dark matter or (primordial)\nblack holes. We also find indications that the phase of rapid expansion of the\nobtained de Sitter universe impacts the mass, and relates to quantum\nfluctuations of space-time.","main_category":"hep-lat","categories":"hep-lat,gr-qc,hep-ph,hep-th","published":"2025-04-15T10:23:06Z"}
{"aid":"http://arxiv.org/abs/2504.11052v1","title":"Weyl-mediated Ruderman-Kittel-Kasuya-Yosida interaction revisited:\n  imaginary-time formalism and finite temperature effects","summary":"Noncentrosymmetric magnetic Weyl semimetals provide a platform for\ninvestigating the interplay among magnetism, inversion symmetry breaking, and\ntopologically nontrivial Weyl fermions. The Weyl-mediated\nRuderman-Kittel-Kasuya-Yosida (RKKY) interaction may be related to the magnetic\norders observed in rare-earth magnetic Weyl semimetals. Previous studies of\nRKKY interaction between magnetic impurities in Weyl semimetals found\nHeisenberg, Ising-like, and Dzyaloshinskii-Moriya (DM) types of interactions.\nHowever, different range functions are obtained in the literature. In this\nwork, we calculate the Weyl-mediated RKKY interaction by using the\ndivergence-free imaginary-time formalism and obtain exact analytical results at\nfinite temperature. The discrepancies among zero temperature range functions in\nthe literature are resolved. At nonzero temperature, the interaction strength\ndecays exponentially in the long distance limit. But in the short distance\nlimit, the DM interaction shows a thermal enhancement, an effect persists up to\nhigher temperature for shorter distance. This provides a mechanism stabilizing\nthe helical order observed in rare-earth magnetic Weyl semimetals.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-15T10:39:59Z"}
{"aid":"http://arxiv.org/abs/2504.11060v1","title":"Goos-H√§nchen Shift and Photonic Spin Hall Effect in Semi-Dirac\n  Material Heterostructures","summary":"We investigate the photonic spin Hall effect (PSHE) and the Goos-H\\\"anchen\nshift (GH shift) in semi-Dirac\n  materials. Through theoretical modeling, we demonstrate that the anisotropic\ndielectric function in semi-Dirac\n  materials play a critical role in determining the magnitude and polarity of\nthese optical displacements. Further more, by utilizing the unidirectional\ndrift of massless Dirac electrons in Semi-Dirac materials, we systematically\n  reveal how the drift velocity and direction modulate the behavior of optical\ndisplacements. The results indicate\n  that semi-Dirac materials provide a versatile platform for controlling\nspin-dependent photonic phenomena with\n  their material anisotropy and carrier transport. This work opens a new avenue\nfor designing advanced photonic\n  devices with tunable optical responses, particularly with significant\napplication potential in quantum information\n  processing and topological photonics.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-15T10:48:19Z"}
{"aid":"http://arxiv.org/abs/2504.11061v1","title":"Synthesis and characterization of gold-coated nanodiamonds through green\n  chemistry as potential radiosensitizers for proton therapy","summary":"In this work the synthesis and characterization of novel gold-nanodiamond\nnanoparticles was performed. The synthesis was based on the reduction of gold\nonto the different types of nanodiamond (annealed or annealed and oxidized, 50\nor 230 nm) using root extracts of Nympheaea alba as a reducing agent. These\ngold-coated nanodiamonds were characterized by UV-Vis, PXRD, DLS,\nzeta-potential, PIXE, Raman, SEM, and TEM, assessing particle size, stability,\nand gold coating effectiveness. Cellular studies in the A549 and Panc1 cancer\ncell lines assessed uptake, cytotoxicity, and colony formation to evaluate\nNDAu's biological activity. NDAu demonstrated strong cellular uptake and\ncytotoxic effects in A549 and Panc1 cell lines, reducing cell survival in\nclonogenic assay. Futher research in the capabilites of these nanoparticles for\nproton therapy will be performed.","main_category":"hep-ex","categories":"hep-ex,cond-mat.mtrl-sci","published":"2025-04-15T10:49:51Z"}
{"aid":"http://arxiv.org/abs/2504.11085v1","title":"TD-Suite: All Batteries Included Framework for Technical Debt\n  Classification","summary":"Recognizing that technical debt is a persistent and significant challenge\nrequiring sophisticated management tools, TD-Suite offers a comprehensive\nsoftware framework specifically engineered to automate the complex task of its\nclassification within software projects. It leverages the advanced natural\nlanguage understanding of state-of-the-art transformer models to analyze\ntextual artifacts, such as developer discussions in issue reports, where subtle\nindicators of debt often lie hidden.\n  TD-Suite provides a seamless end-to-end pipeline, managing everything from\ninitial data ingestion and rigorous preprocessing to model training, thorough\nevaluation, and final inference. This allows it to support both straightforward\nbinary classification (debt or no debt) and more valuable, identifying specific\ncategories like code, design, or documentation debt, thus enabling more\ntargeted management strategies.\n  To ensure the generated models are robust and perform reliably on real-world,\noften imbalanced, datasets, TD-Suite incorporates critical training\nmethodologies: k-fold cross-validation assesses generalization capability,\nearly stopping mechanisms prevent overfitting to the training data, and class\nweighting strategies effectively address skewed data distributions. Beyond core\nfunctionality, and acknowledging the growing importance of sustainability, the\nframework integrates tracking and reporting of carbon emissions associated with\nthe computationally intensive model training process.\n  It also features a user-friendly Gradio web interface in a Docker container\nsetup, simplifying model interaction, evaluation, and inference.","main_category":"cs.SE","categories":"cs.SE,cs.LG","published":"2025-04-15T11:31:17Z"}
{"aid":"http://arxiv.org/abs/2504.11090v1","title":"Towards global equity in political polarization research","summary":"With a folk understanding that political polarization refers to\nsocio-political divisions within a society, many have proclaimed that we are\nmore divided than ever. In this account, polarization has been blamed for\npopulism, the erosion of social cohesion, the loss of trust in the institutions\nof democracy, legislative dysfunction, and the collective failure to address\nexistential risks such as Covid-19 or climate change. However, at a global\nscale there is surprisingly little academic literature which conclusively\nsupports these claims, with half of all studies being U.S.-focused. Here, we\nprovide an overview of the global state of research on polarization,\nhighlighting insights that are robust across countries, those unique to\nspecific contexts, and key gaps in the literature. We argue that addressing\nthese gaps is urgent, but has been hindered thus far by systemic and cultural\nbarriers, such as regionally stratified restrictions on data access and\nmisaligned research incentives. If continued cross-disciplinary inertia means\nthat these disparities are left unaddressed, we see a substantial risk that\ncountries will adopt policies to tackle polarization based on inappropriate\nevidence, risking flawed decision-making and the weakening of democratic\ninstitutions.","main_category":"cs.SI","categories":"cs.SI,physics.soc-ph","published":"2025-04-15T11:34:12Z"}
{"aid":"http://arxiv.org/abs/2504.11092v1","title":"Vivid4D: Improving 4D Reconstruction from Monocular Video by Video\n  Inpainting","summary":"Reconstructing 4D dynamic scenes from casually captured monocular videos is\nvaluable but highly challenging, as each timestamp is observed from a single\nviewpoint. We introduce Vivid4D, a novel approach that enhances 4D monocular\nvideo synthesis by augmenting observation views - synthesizing multi-view\nvideos from a monocular input. Unlike existing methods that either solely\nleverage geometric priors for supervision or use generative priors while\noverlooking geometry, we integrate both. This reformulates view augmentation as\na video inpainting task, where observed views are warped into new viewpoints\nbased on monocular depth priors. To achieve this, we train a video inpainting\nmodel on unposed web videos with synthetically generated masks that mimic\nwarping occlusions, ensuring spatially and temporally consistent completion of\nmissing regions. To further mitigate inaccuracies in monocular depth priors, we\nintroduce an iterative view augmentation strategy and a robust reconstruction\nloss. Experiments demonstrate that our method effectively improves monocular 4D\nscene reconstruction and completion.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T11:38:14Z"}
{"aid":"http://arxiv.org/abs/2504.11095v1","title":"Magnetotransport and activation energy of the surface states in Cd3As2\n  thin films","summary":"Recent experiments performed the magnetotransport measurements in\n(001)-oriented Cd$_3$As$_2$ thin films and attributed the magnetotransport\nproperties to the surface states. In this paper, by using an effective model to\ndescribe the surface states, we analyze the Landau bands and then calculate the\nmagnetoconductivities and magnetoresistivities. From these results, the\nfeatures of two-dimensional quantum Hall effect of the surface states can be\ncaptured. More importantly, we reveal that the activation energy is determined\nby the Hall plateau width, which can explain the experimental observations that\nthe activation energies at odd plateaus are larger than those at even plateaus.\nWe also analyze the roles played by the structural inversion symmetry breaking\nand impurity scatterings in the magnetotransport, and suggest that their\ncombined effects would lead to the absence of some Hall plateaus.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-15T11:40:31Z"}
{"aid":"http://arxiv.org/abs/2504.11139v1","title":"Non-stabilizerness in open XXZ spin chains: Universal scaling and\n  dynamics","summary":"Magic, or non-stabilizerness, is a crucial quantum resource, yet its dynamics\nin open quantum systems remain largely unexplored. We investigate magic in the\nopen XXZ spin chain under either boundary gain and loss, or bulk dephasing\nusing the stabilizer R\\'enyi entropy $M_2$. To enable scalable simulations of\nlarge systems, we develop a novel, highly efficient algorithm for computing\n$M_2$ within the matrix product states formalism while maintaining constant\nbond dimension--an advancement over existing methods. For boundary driving, we\nuncover universal scaling laws, $M_2(t) \\sim t^{1/z}$, linked to the dynamical\nexponent $z$ for several distinct universality classes. We also disentangle\nclassical and quantum contributions to magic by introducing a mean-field\napproximation for magic, thus emphasizing the prominent role of quantum\ncritical fluctuations in non-stabilizerness. For bulk dephasing, dissipation\ncan transiently enhance magic before suppressing it, and drive it to a\nnontrivial steady-state value. These findings position magic as a powerful\ndiagnostic tool for probing universality and dynamics in open quantum systems.","main_category":"quant-ph","categories":"quant-ph,cond-mat.str-el","published":"2025-04-15T12:41:52Z"}
{"aid":"http://arxiv.org/abs/2504.11143v1","title":"Taming Consistency Distillation for Accelerated Human Image Animation","summary":"Recent advancements in human image animation have been propelled by video\ndiffusion models, yet their reliance on numerous iterative denoising steps\nresults in high inference costs and slow speeds. An intuitive solution involves\nadopting consistency models, which serve as an effective acceleration paradigm\nthrough consistency distillation. However, simply employing this strategy in\nhuman image animation often leads to quality decline, including visual\nblurring, motion degradation, and facial distortion, particularly in dynamic\nregions. In this paper, we propose the DanceLCM approach complemented by\nseveral enhancements to improve visual quality and motion continuity at\nlow-step regime: (1) segmented consistency distillation with an auxiliary\nlight-weight head to incorporate supervision from real video latents,\nmitigating cumulative errors resulting from single full-trajectory generation;\n(2) a motion-focused loss to centre on motion regions, and explicit injection\nof facial fidelity features to improve face authenticity. Extensive qualitative\nand quantitative experiments demonstrate that DanceLCM achieves results\ncomparable to state-of-the-art video diffusion models with a mere 2-4 inference\nsteps, significantly reducing the inference burden without compromising video\nquality. The code and models will be made publicly available.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T12:44:53Z"}
{"aid":"http://arxiv.org/abs/2504.11156v1","title":"A preliminary cosmological analysis of stellar population synthesis of\n  galaxies released by LAMOST LRS DR11","summary":"The evolution of the universe together with the galaxies is one of the\nfundamental issues that we humans are most interested in. Both the observations\nof tidal streams from SDSS and the theory of $\\Lambda$CDM support the\nhierarchical merging theory. The study of high redshift celestial bodies\ncontributes to a more in-depth study of cosmology. The LAMOST low resolution\nsearch catalog DR11 v1.0 has released 11,939,296 spectra, including 11,581,542\nstars, 275,302 galaxies, and 82,452 quasars, and so on. The data of 28,780\nstellar population synthesis of galaxies and some high redshift quasars are\nused to do a preliminary statistical research. We selected the data with small\nerrors for analysis and obtained some basic statistical conclusions. Older\ngalaxies have relatively larger stellar velocity dispersions. The larger the\nmetallicity, the greater the stellar velocity dispersion. These statistical\nresults are reasonable and consistent with previous work. Because the stellar\nvelocity dispersion is driven by the total mass of a galaxy at the first order\nand more massive galaxies have older ages and greater metallicities. The\nspectra of high redshift quasars show clear Gunn-Peterson trough and\nLyman-$\\alpha$ forest. The identified emission lines and high redshift\ncelestial spectra released by LAMOST can be used for cosmological research.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-15T13:01:48Z"}
{"aid":"http://arxiv.org/abs/2504.11157v1","title":"Similarity Constrained CC2 for Efficient Coupled Cluster Nonadiabatic\n  Dynamics","summary":"Despite their high accuracy, standard coupled cluster models cannot be used\nfor nonadiabatic molecular dynamics simulations because they yield unphysical\ncomplex excitation energies at conical intersections between same-symmetry\nexcited states. On the other hand, similarity constrained coupled cluster\ntheory has enabled the application of coupled cluster theory in such dynamics\nsimulations. Here, we present a similarity constrained perturbative doubles\n(SCC2) model with same-symmetry excited-state conical intersections that\nexhibit correct topography, topology, and real excitation energies. This is\nachieved while retaining the favorable computational scaling of the standard\nCC2 model. We illustrate the model for conical intersections in hypofluorous\nacid and thymine, and compare its performance with other methods. The results\ndemonstrate that conical intersections between excited states can be described\ncorrectly and efficiently at the SCC2 level. We therefore expect that the SCC2\nmodel will enable coupled cluster nonadiabatic dynamics simulations for large\nmolecular systems.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-15T13:04:06Z"}
{"aid":"http://arxiv.org/abs/2504.11165v1","title":"YOLO-RS: Remote Sensing Enhanced Crop Detection Methods","summary":"With the rapid development of remote sensing technology, crop classification\nand health detection based on deep learning have gradually become a research\nhotspot. However, the existing target detection methods show poor performance\nwhen dealing with small targets in remote sensing images, especially in the\ncase of complex background and image mixing, which is difficult to meet the\npractical application requirementsite. To address this problem, a novel target\ndetection model YOLO-RS is proposed in this paper. The model is based on the\nlatest Yolov11 which significantly enhances the detection of small targets by\nintroducing the Context Anchor Attention (CAA) mechanism and an efficient\nmulti-field multi-scale feature fusion network. YOLO-RS adopts a bidirectional\nfeature fusion strategy in the feature fusion process, which effectively\nenhances the model's performance in the detection of small targets. Small\ntarget detection. Meanwhile, the ACmix module at the end of the model backbone\nnetwork solves the category imbalance problem by adaptively adjusting the\ncontrast and sample mixing, thus enhancing the detection accuracy in complex\nscenes. In the experiments on the PDT remote sensing crop health detection\ndataset and the CWC crop classification dataset, YOLO-RS improves both the\nrecall and the mean average precision (mAP) by about 2-3\\% or so compared with\nthe existing state-of-the-art methods, while the F1-score is also significantly\nimproved. Moreover, the computational complexity of the model only increases by\nabout 5.2 GFLOPs, indicating its significant advantages in both performance and\nefficiency. The experimental results validate the effectiveness and application\npotential of YOLO-RS in the task of detecting small targets in remote sensing\nimages.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T13:13:22Z"}
{"aid":"http://arxiv.org/abs/2504.11174v1","title":"Algorithmic thresholds in combinatorial optimization depend on the time\n  scaling","summary":"In the last decades, many efforts have focused on analyzing typical-case\nhardness in optimization and inference problems. Some recent work has pointed\nout that polynomial algorithms exist, running with a time that grows more than\nlinearly with the system size, which can do better than linear algorithms,\nfinding solutions to random problems in a wider range of parameters. However, a\ntheory for polynomial and superlinear algorithms is in general lacking. In this\npaper, we examine the performance of the Simulated Annealing algorithm, a\nstandard, versatile, and robust choice for solving optimization and inference\nproblems, in the prototypical random $K$-Sat problem. For the first time, we\nshow that the algorithmic thresholds depend on the time scaling of the\nalgorithm with the size of the system. Indeed, one can identify not just one,\nbut different thresholds for linear, quadratic, cubic regimes (and so on). This\nobservation opens new directions in studying the typical case hardness in\noptimization problems.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn","published":"2025-04-15T13:27:57Z"}
{"aid":"http://arxiv.org/abs/2504.11184v1","title":"A simple, robust and cost-effective method to achieve dispersion\n  matching in swept source OCT","summary":"Optical path length and dispersion matching in both measurement and reference\narms of an OCT system is critical for achieving bandwidth-limited axial\nresolution. To minimize or eliminate dispersion mismatch, most, if not all,\nfiber-based OCT realisations employ a reference arm configuration that is as\nclosely identical to the measurement arm as possible. This typically includes a\ncollimator, dispersion compensating material (or sometimes a set of lenses), as\nwell as a mirror (or retro-reflector) mounted on a translation stage. However,\nthis solution makes the total instrument cost higher and the setup bulkier than\nnecessary and it also renders the reference arm mechanically unstable. Here, a\nsimple yet robust, low-cost reference arm setup is presented and its ability to\ncompensate for measurement arm dispersion is demonstrated. We use a single-mode\nfiber cleaved and polished perpendicular to the fiber axis to construct the\nreference arm. The length and material of the fibre is determined by\nconsidering the optical path length and dispersion of the measurement arm.\nExperimental images demonstrate the operation of the novel reference arm in our\nSwept-source Optical Coherence Tomography.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-15T13:40:50Z"}
{"aid":"http://arxiv.org/abs/2504.11186v1","title":"Benchmarking Next-Generation Reasoning-Focused Large Language Models in\n  Ophthalmology: A Head-to-Head Evaluation on 5,888 Items","summary":"Recent advances in reasoning-focused large language models (LLMs) mark a\nshift from general LLMs toward models designed for complex decision-making, a\ncrucial aspect in medicine. However, their performance in specialized domains\nlike ophthalmology remains underexplored. This study comprehensively evaluated\nand compared the accuracy and reasoning capabilities of four newly developed\nreasoning-focused LLMs, namely DeepSeek-R1, OpenAI o1, o3-mini, and Gemini 2.0\nFlash-Thinking. Each model was assessed using 5,888 multiple-choice\nophthalmology exam questions from the MedMCQA dataset in zero-shot setting.\nQuantitative evaluation included accuracy, Macro-F1, and five text-generation\nmetrics (ROUGE-L, METEOR, BERTScore, BARTScore, and AlignScore), computed\nagainst ground-truth reasonings. Average inference time was recorded for a\nsubset of 100 randomly selected questions. Additionally, two board-certified\nophthalmologists qualitatively assessed clarity, completeness, and reasoning\nstructure of responses to differential diagnosis questions.O1 (0.902) and\nDeepSeek-R1 (0.888) achieved the highest accuracy, with o1 also leading in\nMacro-F1 (0.900). The performance of models across the text-generation metrics\nvaried: O3-mini excelled in ROUGE-L (0.151), o1 in METEOR (0.232), DeepSeek-R1\nand o3-mini tied for BERTScore (0.673), DeepSeek-R1 (-4.105) and Gemini 2.0\nFlash-Thinking (-4.127) performed best in BARTScore, while o3-mini (0.181) and\no1 (0.176) led AlignScore. Inference time across the models varied, with\nDeepSeek-R1 being slowest (40.4 seconds) and Gemini 2.0 Flash-Thinking fastest\n(6.7 seconds). Qualitative evaluation revealed that DeepSeek-R1 and Gemini 2.0\nFlash-Thinking tended to provide detailed and comprehensive intermediate\nreasoning, whereas o1 and o3-mini displayed concise and summarized\njustifications.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-15T13:42:34Z"}
{"aid":"http://arxiv.org/abs/2504.11210v1","title":"Differentiating Formation Models with New Dynamical Masses for the PDS\n  70 Protoplanets","summary":"Hot- and cold-start planet formation models predict differing luminosities\nfor the young, bright planets that direct imaging surveys are most sensitive\nto. However, precise mass estimates are required to distinguish between these\nmodels observationally. The presence of two directly imaged planets, PDS 70 b\nand c, in the PDS 70 protoplanetary disk provides us a unique opportunity for\ndynamical mass measurements, since the masses for these planets are currently\npoorly constrained. Fitting orbital parameters to new astrometry of these\nplanets, taken with VLTI/GRAVITY in the $K$~band, we find $2\\sigma$ dynamical\nupper mass limits of 4.9 $M_{\\rm Jup}$ for b and 13.6 $M_{\\rm Jup}$ for c.\nAdding astrometry from the newly proposed planet candidate PDS 70 d into our\nmodel, we determine $2\\sigma$ dynamical upper mass limits of 5.3 $M_{\\rm Jup}$,\n7.5 $M_{\\rm Jup}$ and 2.2 $M_{\\rm Jup}$ for b, c, and the candidate d\nrespectively. However, $N$-body analysis of the orbits fit in this case suggest\nthat the inclusion of $d$ makes the system unstable. Using the upper mass\nlimits for b and c we rule out the coldest-start formation models for both\nplanets, calculating minimum post-formation entropies ($S_i$) of 9.5 $k_{\\rm\nB}/{\\rm baryon}$ and 8.4 $k_{\\rm B}/{\\rm baryon}$ respectively. This places PDS\n70 b and c on the growing list of directly-imaged planets inconsistent with\ncold-start formation.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-15T14:12:38Z"}
{"aid":"http://arxiv.org/abs/2504.11212v1","title":"SDFs from Unoriented Point Clouds using Neural Variational Heat\n  Distances","summary":"We propose a novel variational approach for computing neural Signed Distance\nFields (SDF) from unoriented point clouds. To this end, we replace the commonly\nused eikonal equation with the heat method, carrying over to the neural domain\nwhat has long been standard practice for computing distances on discrete\nsurfaces. This yields two convex optimization problems for whose solution we\nemploy neural networks: We first compute a neural approximation of the\ngradients of the unsigned distance field through a small time step of heat flow\nwith weighted point cloud densities as initial data. Then we use it to compute\na neural approximation of the SDF. We prove that the underlying variational\nproblems are well-posed. Through numerical experiments, we demonstrate that our\nmethod provides state-of-the-art surface reconstruction and consistent SDF\ngradients. Furthermore, we show in a proof-of-concept that it is accurate\nenough for solving a PDE on the zero-level set.","main_category":"math.NA","categories":"math.NA,cs.LG,cs.NA","published":"2025-04-15T14:13:54Z"}
{"aid":"http://arxiv.org/abs/2504.11235v1","title":"Guided Wave-Based Structural Awareness Under Varying Operating States\n  via Manifold Representations","summary":"Guided wave-based structural health monitoring (SHM) remains a powerful\nstrategy for identifying early-stage defects and safeguarding vital aerospace\nstructures. Yet, its practical use is often hindered by the enormous,\nhigh-dimensional data streams produced by sensor arrays operating at megahertz\nsampling rates, coupled with the added complexity of shifts in environmental\nand operational conditions (EOCs). Studies have explored various\ndata-compression approaches that retain critical diagnostic details in a\nlower-dimensional latent space. While conventional techniques can streamline\ndimensionality to some extent, they do not always capture the nonlinear\ninteractions typical of guided waves. Manifold learning, as illustrated by\nDiffusion Maps, tackles these nonlinearities by deriving low-dimensional\nembeddings directly from wave signals, minimizing the need for manual feature\nextraction. In parallel, developments in deep learning -- particularly\nautoencoders -- provide an encoder-decoder model for both data compression and\nreconstruction. Convolutional autoencoders (CAEs) and variational autoencoders\n(VAEs) have been particularly effective for guided wave applications. However,\ncurrent methods can still struggle to maintain accurate state estimation under\nchanging EOCs, and they are often limited to a single task. In response, the\nproposed framework adopts a two-fold strategy: it compresses high-dimensional\nsignals into lower-dimensional representations and then leverages those\nrepresentations to both estimate structural states and reconstruct the original\ndata, even as conditions vary. Applied to two real-world SHM use-cases, this\nintegrated method has proven its ability to preserve and retrieve key damage\nsignatures under noise, shifting operational parameters, and other complicating\nfactors.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-15T14:38:30Z"}
{"aid":"http://arxiv.org/abs/2504.11260v1","title":"$QQ$-systems and tropical geometry","summary":"We investigate the system of polynomial equations, known as $QQ$-systems,\nwhich are closely related to the so-called Bethe ansatz equations of the XXZ\nspin chain, using the methods of tropical geometry.","main_category":"math.AG","categories":"math.AG,hep-th,math-ph,math.MP,math.QA,math.RT","published":"2025-04-15T14:59:26Z"}
{"aid":"http://arxiv.org/abs/2504.11339v1","title":"Optimal and Scalable Augmented Lagrangian preconditioners for Fictitious\n  Domain problems","summary":"We present optimal and scalable preconditioning techniques to solve linear\nsystems of equations with a block two-by-two and three-by-three structure\narising from fictitious domain problems and from finite element discretizations\nof immersed boundary methods. In particular, we propose two augmented\nLagrangian-based preconditioners to accelerate the convergence of iterative\nsolvers for these two classes of linear. We consider two relevant examples to\nillustrate the performance of these preconditioners when used in conjunction\nwith flexible GMRES: the Poisson and the Stokes fictitious domain problems. A\nspectral analysis is established for both exact and inexact versions of these\npreconditioners. We show the effectiveness of the proposed approach and the\nrobustness of our preconditioning strategy through extensive numerical tests in\nboth two and three dimensions.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-15T16:12:51Z"}
{"aid":"http://arxiv.org/abs/2504.11343v1","title":"A Minimalist Approach to LLM Reasoning: from Rejection Sampling to\n  Reinforce","summary":"Reinforcement learning (RL) has become a prevailing approach for fine-tuning\nlarge language models (LLMs) on complex reasoning tasks. Among recent methods,\nGRPO stands out for its empirical success in training models such as\nDeepSeek-R1, yet the sources of its effectiveness remain poorly understood. In\nthis work, we revisit GRPO from a reinforce-like algorithm perspective and\nanalyze its core components. Surprisingly, we find that a simple rejection\nsampling baseline, RAFT, which trains only on positively rewarded samples,\nyields competitive performance than GRPO and PPO. Our ablation studies reveal\nthat GRPO's main advantage arises from discarding prompts with entirely\nincorrect responses, rather than from its reward normalization. Motivated by\nthis insight, we propose Reinforce-Rej, a minimal extension of policy gradient\nthat filters both entirely incorrect and entirely correct samples.\nReinforce-Rej improves KL efficiency and stability, serving as a lightweight\nyet effective alternative to more complex RL algorithms. We advocate RAFT as a\nrobust and interpretable baseline, and suggest that future advances should\nfocus on more principled designs for incorporating negative samples, rather\nthan relying on them indiscriminately. Our findings provide guidance for future\nwork in reward-based LLM post-training.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL,stat.ML","published":"2025-04-15T16:15:02Z"}
{"aid":"http://arxiv.org/abs/2504.11348v1","title":"Circuit metaconstruction in logspace for Rice-like complexity lower\n  bounds in ANs and SGRs","summary":"A new proof technique combining finite model theory and dynamical systems has\nrecently been introduced to obtain general complexity lower bounds on any\nquestion one may formulate on the dynamics (seen as a graph) of a given\nautomata network (AN). ANs are abstract finite dynamical systems of interacting\nentities whose evolution rules are encoded as circuits, hence the study also\napplies to succinct graph representations (SGRs). In this article, we detail\nthe construction of circuits to obtain general complexity lower bounds\n(metareduction) and show that the reduction is feasible in logarithmic space.","main_category":"cs.CC","categories":"cs.CC","published":"2025-04-15T16:20:22Z"}
{"aid":"http://arxiv.org/abs/2504.11355v1","title":"Neural Networks for on-chip Model Predictive Control: a Method to Build\n  Optimized Training Datasets and its application to Type-1 Diabetes","summary":"Training Neural Networks (NNs) to behave as Model Predictive Control (MPC)\nalgorithms is an effective way to implement them in constrained embedded\ndevices. By collecting large amounts of input-output data, where inputs\nrepresent system states and outputs are MPC-generated control actions, NNs can\nbe trained to replicate MPC behavior at a fraction of the computational cost.\nHowever, although the composition of the training data critically influences\nthe final NN accuracy, methods for systematically optimizing it remain\nunderexplored. In this paper, we introduce the concept of Optimally-Sampled\nDatasets (OSDs) as ideal training sets and present an efficient algorithm for\ngenerating them. An OSD is a parametrized subset of all the available data that\n(i) preserves existing MPC information up to a certain numerical resolution,\n(ii) avoids duplicate or near-duplicate states, and (iii) becomes saturated or\ncomplete. We demonstrate the effectiveness of OSDs by training NNs to replicate\nthe University of Virginia's MPC algorithm for automated insulin delivery in\nType-1 Diabetes, achieving a four-fold improvement in final accuracy. Notably,\ntwo OSD-trained NNs received regulatory clearance for clinical testing as the\nfirst NN-based control algorithm for direct human insulin dosing. This\nmethodology opens new pathways for implementing advanced optimizations on\nresource-constrained embedded platforms, potentially revolutionizing how\ncomplex algorithms are deployed.","main_category":"eess.SY","categories":"eess.SY,cs.AI,cs.SY","published":"2025-04-15T16:25:06Z"}
{"aid":"http://arxiv.org/abs/2504.11356v1","title":"Dimension preserving set-valued approximation and decomposition via\n  metric sum","summary":"In the literature, the Minkowski-sum and the metric-sum of compact sets are\nhighlighted. While the first is associative, the latter is not. But the major\ndrawback of the Minkowski combination is that, by increasing the number of\nsummands, this leads to convexification. The present article is uncovered in\ntwo folds: The initial segment presents a novel approach to approximate a\ncontinuous set-valued function with compact images via a fractal approach using\nthe metric linear combination of sets. The other segment contains the dimension\nanalysis of the distance set of graph of set-valued function and solving the\ncelebrated distance set conjecture. In the end, a decomposition of any\ncontinuous convex compact set-valued function is exhibited that preserves the\nHausdorff dimension, so this will serve as a method for dealing with\ncomplicated set-valued functions.","main_category":"math.DS","categories":"math.DS","published":"2025-04-15T16:25:29Z"}
{"aid":"http://arxiv.org/abs/2504.11381v1","title":"RankAlign: A Ranking View of the Generator-Validator Gap in Large\n  Language Models","summary":"Although large language models (LLMs) have become generally more capable and\naccurate across many tasks, some fundamental sources of unreliability remain in\ntheir behavior. One key limitation is their inconsistency at reporting the the\nsame information when prompts are changed. In this paper, we consider the\ndiscrepancy between a model's generated answer and their own verification of\nthat answer, the generator-validator gap. We define this gap in a more\nstringent way than prior work: we expect correlation of scores from a generator\nand a validator over the entire set of candidate answers. We show that\naccording to this measure, a large gap exists in various settings, including\nquestion answering, lexical semantics tasks, and next-word prediction. We then\npropose RankAlign, a ranking-based training method, and show that it\nsignificantly closes the gap by 31.8% on average, surpassing all baseline\nmethods. Moreover, this approach generalizes well to out-of-domain tasks and\nlexical items.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-15T16:53:31Z"}
{"aid":"http://arxiv.org/abs/2504.11396v1","title":"Property Inheritance for Subtensors in Tensor Train Decompositions","summary":"Tensor dimensionality reduction is one of the fundamental tools for modern\ndata science. To address the high computational overhead, fiber-wise sampled\nsubtensors that preserve the original tensor rank are often used in designing\nefficient and scalable tensor dimensionality reduction. However, the theory of\nproperty inheritance for subtensors is still underdevelopment, that is, how the\nessential properties of the original tensor will be passed to its subtensors.\nThis paper theoretically studies the property inheritance of the two key tensor\nproperties, namely incoherence and condition number, under the tensor train\nsetting. We also show how tensor train rank is preserved through fiber-wise\nsampling. The key parameters introduced in theorems are numerically evaluated\nunder various settings. The results show that the properties of interest can be\nwell preserved to the subtensors formed via fiber-wise sampling. Overall, this\npaper provides several handy analytic tools for developing efficient tensor\nanalysis","main_category":"cs.IT","categories":"cs.IT,math.IT,stat.ML","published":"2025-04-15T17:10:38Z"}
{"aid":"http://arxiv.org/abs/2504.11405v1","title":"Size-Frequency Distribution of Terrestrial Leftover Planetesimals and\n  S-complex Implanted Asteroids","summary":"The isotopic composition of meteorites linked to S-complex asteroids has been\nused to suggest that these asteroids originated in the terrestrial planet's\nregion, i.e., within 1.5 au, and later got implanted into the main asteroid\nbelt (MAB). Dynamical models of planet formation support this view. Yet, it\nremains to be demonstrated whether the currently observed size-frequency\ndistribution (SFD) of S-complex bodies in the MAB can be reproduced via this\nimplantation process. Here we studied the evolution of the SFD of planetesimals\nduring the accretion of terrestrial planets with the code LIPAD\nself-consistently accounting for growth and fragmentation of planetesimals. In\nour simulations we vary the initial surface density of planetesimals, the\ngaseous disk lifetime, and the power slope of the initial planetesimals' SFD.\nWe compared the final SFDs of leftover planetesimals in the terrestrial planet\nregion with the SFD of observed S-complex MAB objects (D $>$ 100km). We found\nthat the SFDs of our planetesimal populations and that of S-complex MAB objects\nshow very similar cumulative power index (i.e., q $\\approx$ 3.15 in\nN($>$D)$~\\propto$ D$^{-q}$) for slopes in the diameter range 100 km $<$ D $<$\n400 km by the end of our simulations. Our results support the hypothesis of\nS-complex MAB implantation from the terrestrial planet forming region, assuming\nimplantation is size-independent, and implies that implantation efficiency is\nsmaller than $\\mathcal{O}$(10$^{\\rm -2}$--10$^{\\rm -4}$) to avoid\nover-implantation of (4) Vesta-sized objects or larger.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-15T17:19:57Z"}
{"aid":"http://arxiv.org/abs/2504.11408v1","title":"Five dimensional rotating and Quintessence black hole and their shadows","summary":"We present a new five-dimensional rotating quintessence black hole solution.\nTo obtain this, we employ the $5D$ version of the Janis Newman algorithm, which\nincorporates the Hopf bifurcation. The variation of the quintessence parameter\n$w_q$ causes the geometry to transition from a regular rotating universe\nsurrounded by a cosmological horizon to a singular rotating geometry, which can\nrepresent a naked singularity, a singular extremal black hole, or a singular\nblack hole with both an inner and an outer (event) horizon. We have also\ndetermined the properties of the ergosphere. For the study of the shadow, we\nfollowed a novel approach in which the $2D$ shadow observed by humans\ncorresponds to cross-sections of the $3D$ shadow. We analyzed how quintessence\naffects both the size and shape of the black hole shadow, showing that\nincreasing the quintessence strength reduces the shadow radius, contrary to the\nknown results in $4D$. We also propose a speculative methodology to test the\nshadow behavior in five-dimensional scenarios, in light of the constraints\nprovided by the Event Horizon Telescope (EHT) concerning the shadow of the\nfour-dimensional supermassive black hole M87. We identify scenarios in which\nthe theoretical $5D$ results could be consistent with these observational\nconstraints. Finally, we determine the energy conditions required to support\nthe solution.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-15T17:26:18Z"}
{"aid":"http://arxiv.org/abs/2504.11426v1","title":"A Dual-Space Framework for General Knowledge Distillation of Large\n  Language Models","summary":"Knowledge distillation (KD) is a promising solution to compress large\nlanguage models (LLMs) by transferring their knowledge to smaller models.\nDuring this process, white-box KD methods usually minimize the distance between\nthe output distributions of the teacher model and the student model to transfer\nmore information. However, we reveal that the current white-box KD framework\nexhibits two limitations: a) bridging probability distributions from different\noutput spaces will limit the similarity between the teacher model and the\nstudent model; b) this framework cannot be applied to LLMs with different\nvocabularies. One of the root causes for these limitations is that the\ndistributions from the teacher and the student for KD are output by different\nprediction heads, which yield distributions in different output spaces and\ndimensions. Therefore, in this paper, we propose a dual-space knowledge\ndistillation (DSKD) framework that unifies the prediction heads of the teacher\nand the student models for KD. Specifically, we first introduce two projectors\nwith ideal initialization to project the teacher/student hidden states into the\nstudent/teacher representation spaces. After this, the hidden states from\ndifferent models can share the same head and unify the output spaces of the\ndistributions. Furthermore, we develop an exact token alignment (ETA) algorithm\nto align the same tokens in two differently-tokenized sequences. Based on the\nabove, our DSKD framework is a general KD framework that supports both\noff-policy and on-policy KD, and KD between any two LLMs regardless of their\nvocabularies. Extensive experiments on instruction-following, mathematical\nreasoning, and code generation benchmarks show that DSKD significantly\noutperforms existing methods based on the current white-box KD framework and\nsurpasses other cross-tokenizer KD methods for LLMs with different\nvocabularies.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-15T17:38:47Z"}
{"aid":"http://arxiv.org/abs/2504.11431v1","title":"Masculine Defaults via Gendered Discourse in Podcasts and Large Language\n  Models","summary":"Masculine defaults are widely recognized as a significant type of gender\nbias, but they are often unseen as they are under-researched. Masculine\ndefaults involve three key parts: (i) the cultural context, (ii) the masculine\ncharacteristics or behaviors, and (iii) the reward for, or simply acceptance\nof, those masculine characteristics or behaviors. In this work, we study\ndiscourse-based masculine defaults, and propose a twofold framework for (i) the\nlarge-scale discovery and analysis of gendered discourse words in spoken\ncontent via our Gendered Discourse Correlation Framework (GDCF); and (ii) the\nmeasurement of the gender bias associated with these gendered discourse words\nin LLMs via our Discourse Word-Embedding Association Test (D-WEAT). We focus\nour study on podcasts, a popular and growing form of social media, analyzing\n15,117 podcast episodes. We analyze correlations between gender and discourse\nwords -- discovered via LDA and BERTopic -- to automatically form gendered\ndiscourse word lists. We then study the prevalence of these gendered discourse\nwords in domain-specific contexts, and find that gendered discourse-based\nmasculine defaults exist in the domains of business, technology/politics, and\nvideo games. Next, we study the representation of these gendered discourse\nwords from a state-of-the-art LLM embedding model from OpenAI, and find that\nthe masculine discourse words have a more stable and robust representation than\nthe feminine discourse words, which may result in better system performance on\ndownstream tasks for men. Hence, men are rewarded for their discourse patterns\nwith better system performance by one of the state-of-the-art language models\n-- and this embedding disparity is a representational harm and a masculine\ndefault.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.CY,cs.LG,cs.SI","published":"2025-04-15T17:41:54Z"}
{"aid":"http://arxiv.org/abs/2504.11442v1","title":"TextArena","summary":"TextArena is an open-source collection of competitive text-based games for\ntraining and evaluation of agentic behavior in Large Language Models (LLMs). It\nspans 57+ unique environments (including single-player, two-player, and\nmulti-player setups) and allows for easy evaluation of model capabilities via\nan online-play system (against humans and other submitted models) with\nreal-time TrueSkill scores. Traditional benchmarks rarely assess dynamic social\nskills such as negotiation, theory of mind, and deception, creating a gap that\nTextArena addresses. Designed with research, community and extensibility in\nmind, TextArena emphasizes ease of adding new games, adapting the framework,\ntesting models, playing against the models, and training models. Detailed\ndocumentation of environments, games, leaderboard, and examples are available\non https://github.com/LeonGuertler/TextArena and https://www.textarena.ai/.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG,cs.MA","published":"2025-04-15T17:55:20Z"}
{"aid":"http://arxiv.org/abs/2504.11447v1","title":"Diffusion Distillation With Direct Preference Optimization For Efficient\n  3D LiDAR Scene Completion","summary":"The application of diffusion models in 3D LiDAR scene completion is limited\ndue to diffusion's slow sampling speed. Score distillation accelerates\ndiffusion sampling but with performance degradation, while post-training with\ndirect policy optimization (DPO) boosts performance using preference data. This\npaper proposes Distillation-DPO, a novel diffusion distillation framework for\nLiDAR scene completion with preference aligment. First, the student model\ngenerates paired completion scenes with different initial noises. Second, using\nLiDAR scene evaluation metrics as preference, we construct winning and losing\nsample pairs. Such construction is reasonable, since most LiDAR scene metrics\nare informative but non-differentiable to be optimized directly. Third,\nDistillation-DPO optimizes the student model by exploiting the difference in\nscore functions between the teacher and student models on the paired completion\nscenes. Such procedure is repeated until convergence. Extensive experiments\ndemonstrate that, compared to state-of-the-art LiDAR scene completion diffusion\nmodels, Distillation-DPO achieves higher-quality scene completion while\naccelerating the completion speed by more than 5-fold. Our method is the first\nto explore adopting preference learning in distillation to the best of our\nknowledge and provide insights into preference-aligned distillation. Our code\nis public available on https://github.com/happyw1nd/DistillationDPO.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T17:57:13Z"}
{"aid":"http://arxiv.org/abs/2504.11756v1","title":"AQETuner: Reliable Query-level Configuration Tuning for Analytical Query\n  Engines","summary":"Modern analytical query engines (AQEs) are essential for large-scale data\nanalysis and processing. These systems usually provide numerous query-level\ntunable knobs that significantly affect individual query performance. While\nseveral studies have explored automatic DBMS configuration tuning, they have\nseveral limitations to handle query-level tuning. Firstly, they fail to capture\nhow knobs influence query plans, which directly affect query performance.\nSecondly, they overlook query failures during the tuning processing, resulting\nin low tuning efficiency. Thirdly, they struggle with cold-start problems for\nnew queries, leading to prolonged tuning time. To address these challenges, we\npropose AQETuner, a novel Bayesian Optimization-based system tailored for\nreliable query-level knob tuning in AQEs. AQETuner first applies the attention\nmechanisms to jointly encode the knobs and plan query, effectively identifying\nthe impact of knobs on plan nodes. Then, AQETuner employs a dual-task Neural\nProcess to predict both query performance and failures, leveraging their\ninteractions to guide the tuning process. Furthermore, AQETuner utilizes\nParticle Swarm Optimization to efficiently generate high-quality samples in\nparallel during the initial tuning stage for the new queries. Experimental\nresults show that AQETuner significantly outperforms existing methods, reducing\nquery latency by up to 23.7% and query failures by up to 51.2%.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-16T04:18:25Z"}
{"aid":"http://arxiv.org/abs/2504.11763v1","title":"Extended Short- and Long-Range Mesh Learning for Fast and Generalized\n  Garment Simulation","summary":"3D garment simulation is a critical component for producing cloth-based\ngraphics. Recent advancements in graph neural networks (GNNs) offer a promising\napproach for efficient garment simulation. However, GNNs require extensive\nmessage-passing to propagate information such as physical forces and maintain\ncontact awareness across the entire garment mesh, which becomes computationally\ninefficient at higher resolutions. To address this, we devise a novel GNN-based\nmesh learning framework with two key components to extend the message-passing\nrange with minimal overhead, namely the Laplacian-Smoothed Dual Message-Passing\n(LSDMP) and the Geodesic Self-Attention (GSA) modules. LSDMP enhances\nmessage-passing with a Laplacian features smoothing process, which efficiently\npropagates the impact of each vertex to nearby vertices. Concurrently, GSA\nintroduces geodesic distance embeddings to represent the spatial relationship\nbetween vertices and utilises attention mechanisms to capture global mesh\ninformation. The two modules operate in parallel to ensure both short- and\nlong-range mesh modelling. Extensive experiments demonstrate the\nstate-of-the-art performance of our method, requiring fewer layers and lower\ninference latency.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T04:56:01Z"}
{"aid":"http://arxiv.org/abs/2504.11769v1","title":"Sliding Block Martingale based Multi-hop Delay QoS Analysis","summary":"With the growing density of wireless networks and demand for multi-hop\ntransmissions, precise delay Quality of Service (QoS) analysis has become a\ncritical challenge. This paper introduces a multi-hop delay QoS analysis\nframework based on the sliding block martingale, addressing the loose boundary\nissue of prior methods that rely on service process martingales and min-plus\ntransformations. By constructing a sliding block martingale with a window, we\ncapture both long-term trends and short-term fluctuations in the backlog,\neliminating the reliance on the generalized incremental property. The framework\nredefines delay unreliability events using cascading attributes, deriving a\nmore compact Delay Unreliability Probability Boundary (DUPB). To improve the\nefficiency of solving the key parameter $\\theta$, we propose a Micrometric\nIntervals based Supermartingale Upcrossing Estimate Theorem, quantifying the\nupper bound of event occurrence frequency to constrain the solution space of\n$\\theta$. Simulations based on the 3GPP UMa/UMi channel model validate the\nframework's effectiveness. Results show that in 2-7 hop scenarios, the maximum\ndeviation between theoretical boundaries and Monte Carlo simulations is $4.116\n\\times 10^{-5}$, with a lower RMSE than existing methods. Iteration count and\nCPU time for solving $\\theta$ are reduced by $59\\%-72\\%$ and $60.6\\%-70.5\\%$,\nrespectively, improving analysis efficiency. Furthermore, the derived minimum\nservice rate for multi-hop queues offers a valuable reference for resource\nallocation. The framework demonstrates high accuracy, scalability, and\npracticality in complex multi-hop networks.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-16T05:13:53Z"}
{"aid":"http://arxiv.org/abs/2504.11779v1","title":"Multimodal Spatio-temporal Graph Learning for Alignment-free RGBT Video\n  Object Detection","summary":"RGB-Thermal Video Object Detection (RGBT VOD) can address the limitation of\ntraditional RGB-based VOD in challenging lighting conditions, making it more\npractical and effective in many applications.\n  However, similar to most RGBT fusion tasks, it still mainly relies on\nmanually aligned multimodal image pairs.\n  In this paper, we propose a novel Multimodal Spatio-temporal Graph learning\nNetwork (MSGNet) for alignment-free RGBT VOD problem by leveraging the robust\ngraph representation learning model.\n  Specifically, we first design an Adaptive Partitioning Layer (APL) to\nestimate the corresponding regions of the Thermal image within the RGB image\n(high-resolution), achieving a preliminary inexact alignment.\n  Then, we introduce the Spatial Sparse Graph Learning Module (S-SGLM) which\nemploys a sparse information passing mechanism on the estimated inexact\nalignment to achieve reliable information interaction between different\nmodalities.\n  Moreover, to fully exploit the temporal cues for RGBT VOD problem, we\nintroduce Hybrid Structured Temporal Modeling (HSTM), which involves a Temporal\nSparse Graph Learning Module (T-SGLM) and Temporal Star Block (TSB). T-SGLM\naims to filter out some redundant information between adjacent frames by\nemploying the sparse aggregation mechanism on the temporal graph. Meanwhile,\nTSB is dedicated to achieving the complementary learning of local spatial\nrelationships.\n  Extensive comparative experiments conducted on both the aligned dataset\nVT-VOD50 and the unaligned dataset UVT-VOD2024 demonstrate the effectiveness\nand superiority of our proposed method. Our project will be made available on\nour website for free public access.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T05:32:59Z"}
{"aid":"http://arxiv.org/abs/2504.11788v1","title":"Enhancing Web Agents with Explicit Rollback Mechanisms","summary":"With recent advancements in large language models, web agents have been\ngreatly improved. However, dealing with complex and dynamic web environments\nrequires more advanced planning and search abilities. Previous studies usually\nadopt a greedy one-way search strategy, which may struggle to recover from\nerroneous states. In this work, we enhance web agents with an explicit rollback\nmechanism, enabling the agent to revert back to a previous state in its\nnavigation trajectory. This mechanism gives the model the flexibility to\ndirectly control the search process, leading to an effective and efficient web\nnavigation method. We conduct experiments on two live web navigation benchmarks\nwith zero-shot and fine-tuning settings. The results demonstrate the\neffectiveness of our proposed approach.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-16T05:41:20Z"}
{"aid":"http://arxiv.org/abs/2504.11793v1","title":"Selective Attention Federated Learning: Improving Privacy and Efficiency\n  for Clinical Text Classification","summary":"Federated Learning (FL) faces major challenges regarding communication\noverhead and model privacy when training large language models (LLMs),\nespecially in healthcare applications. To address these, we introduce Selective\nAttention Federated Learning (SAFL), a novel approach that dynamically\nfine-tunes only those transformer layers identified as attention-critical. By\nemploying attention patterns to determine layer importance, SAFL significantly\nreduces communication bandwidth and enhances differential privacy resilience.\nEvaluations on clinical NLP benchmarks (i2b2 Clinical Concept Extraction and\nMIMIC-III discharge summaries) demonstrate that SAFL achieves competitive\nperformance with centralized models while substantially improving communication\nefficiency and privacy preservation.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-16T05:59:29Z"}
{"aid":"http://arxiv.org/abs/2504.11874v1","title":"Factor-MCLS: Multi-agent learning system with reward factor matrix and\n  multi-critic framework for dynamic portfolio optimization","summary":"Typical deep reinforcement learning (DRL) agents for dynamic portfolio\noptimization learn the factors influencing portfolio return and risk by\nanalyzing the output values of the reward function while adjusting portfolio\nweights within the training environment. However, it faces a major limitation\nwhere it is difficult for investors to intervene in the training based on\ndifferent levels of risk aversion towards each portfolio asset. This difficulty\narises from another limitation: existing DRL agents may not develop a thorough\nunderstanding of the factors responsible for the portfolio return and risk by\nonly learning from the output of the reward function. As a result, the strategy\nfor determining the target portfolio weights is entirely dependent on the DRL\nagents themselves. To address these limitations, we propose a reward factor\nmatrix for elucidating the return and risk of each asset in the portfolio.\nAdditionally, we propose a novel learning system named Factor-MCLS using a\nmulti-critic framework that facilitates learning of the reward factor matrix.\nIn this way, our DRL-based learning system can effectively learn the factors\ninfluencing portfolio return and risk. Moreover, based on the critic networks\nwithin the multi-critic framework, we develop a risk constraint term in the\ntraining objective function of the policy function. This risk constraint term\nallows investors to intervene in the training of the DRL agent according to\ntheir individual levels of risk aversion towards the portfolio assets.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-16T08:51:09Z"}
{"aid":"http://arxiv.org/abs/2504.11921v1","title":"On 5-point conformal block with level 2 degenerate field insertion and\n  its AGT dual","summary":"In this paper, we develop and explore recursive methods to investigate the 2d\nCFT 5-point conformal block with a level 2 degenerate insertion, as well as its\nAGT dual, by solving the BPZ differential equation. First, we represent the\nsolution of the differential equation as a double series expansion. On the\n2-node quiver gauge theory side, this corresponds to the instanton series. We\nthen demonstrate that the expansion coefficients are uniquely determined by a\nrecursion relation. Inspired by the approach initiated in a paper by D. Gaiotto\nand J. Teschner, we partially resum this series and show that the result can be\nelegantly expressed in terms of a single hypergeometric function and its\nderivative. This new representation makes it straightforward to relate\ndifferent asymptotic regions. As a by-product, this provides us a simple\nderivation of fusion and braiding coefficients.\n  We describe the subtle procedure of merging the degenerate field with the\noutgoing state, thereby obtaining a generic 4-point block, which on the gauge\ntheory side corresponds to the partition function of $SU(2)$ gauge theory with\nfour massive hypermultiplets in the $\\Omega$-background.\n  Finally, we performed several nontrivial checks, which confirm our results.","main_category":"hep-th","categories":"hep-th","published":"2025-04-16T09:56:43Z"}
{"aid":"http://arxiv.org/abs/2504.11946v1","title":"R-Meshfusion: Reinforcement Learning Powered Sparse-View Mesh\n  Reconstruction with Diffusion Priors","summary":"Mesh reconstruction from multi-view images is a fundamental problem in\ncomputer vision, but its performance degrades significantly under sparse-view\nconditions, especially in unseen regions where no ground-truth observations are\navailable. While recent advances in diffusion models have demonstrated strong\ncapabilities in synthesizing novel views from limited inputs, their outputs\noften suffer from visual artifacts and lack 3D consistency, posing challenges\nfor reliable mesh optimization. In this paper, we propose a novel framework\nthat leverages diffusion models to enhance sparse-view mesh reconstruction in a\nprincipled and reliable manner. To address the instability of diffusion\noutputs, we propose a Consensus Diffusion Module that filters unreliable\ngenerations via interquartile range (IQR) analysis and performs variance-aware\nimage fusion to produce robust pseudo-supervision. Building on this, we design\nan online reinforcement learning strategy based on the Upper Confidence Bound\n(UCB) to adaptively select the most informative viewpoints for enhancement,\nguided by diffusion loss. Finally, the fused images are used to jointly\nsupervise a NeRF-based model alongside sparse-view ground truth, ensuring\nconsistency across both geometry and appearance. Extensive experiments\ndemonstrate that our method achieves significant improvements in both geometric\nquality and rendering quality.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T10:23:59Z"}
{"aid":"http://arxiv.org/abs/2504.11949v1","title":"Flow Intelligence: Robust Feature Matching via Temporal Signature\n  Correlation","summary":"Feature matching across video streams remains a cornerstone challenge in\ncomputer vision. Increasingly, robust multimodal matching has garnered interest\nin robotics, surveillance, remote sensing, and medical imaging. While\ntraditional rely on detecting and matching spatial features, they break down\nwhen faced with noisy, misaligned, or cross-modal data. Recent deep learning\nmethods have improved robustness through learned representations, but remain\nconstrained by their dependence on extensive training data and computational\ndemands. We present Flow Intelligence, a paradigm-shifting approach that moves\nbeyond spatial features by focusing on temporal motion patterns exclusively.\nInstead of detecting traditional keypoints, our method extracts motion\nsignatures from pixel blocks across consecutive frames and extract temporal\nmotion signatures between videos. These motion-based descriptors achieve\nnatural invariance to translation, rotation, and scale variations while\nremaining robust across different imaging modalities. This novel approach also\nrequires no pretraining data, eliminates the need for spatial feature\ndetection, enables cross-modal matching using only temporal motion, and it\noutperforms existing methods in challenging scenarios where traditional\napproaches fail. By leveraging motion rather than appearance, Flow Intelligence\nenables robust, real-time video feature matching in diverse environments.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T10:25:20Z"}
{"aid":"http://arxiv.org/abs/2504.11953v1","title":"Novel-view X-ray Projection Synthesis through Geometry-Integrated Deep\n  Learning","summary":"X-ray imaging plays a crucial role in the medical field, providing essential\ninsights into the internal anatomy of patients for diagnostics, image-guided\nprocedures, and clinical decision-making. Traditional techniques often require\nmultiple X-ray projections from various angles to obtain a comprehensive view,\nleading to increased radiation exposure and more complex clinical processes.\nThis paper explores an innovative approach using the DL-GIPS model, which\nsynthesizes X-ray projections from new viewpoints by leveraging a single\nexisting projection. The model strategically manipulates geometry and texture\nfeatures extracted from an initial projection to match new viewing angles. It\nthen synthesizes the final projection by merging these modified geometry\nfeatures with consistent texture information through an advanced image\ngeneration process. We demonstrate the effectiveness and broad applicability of\nthe DL-GIPS framework through lung imaging examples, highlighting its potential\nto revolutionize stereoscopic and volumetric imaging by minimizing the need for\nextensive data acquisition.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-16T10:30:08Z"}
{"aid":"http://arxiv.org/abs/2504.11955v1","title":"Revisiting Unimodular Quantum Cosmology","summary":"The quantization of unimodular gravity in minisuperspace leads to a time\nevolution of states generated by the Hamiltonian, as in usual quantum\nmechanics. We revisit the analysis made in Ref. \\cite{unruh}, extending it to\nphantom scalar fields. It is argued that only in this case a non-trivial\nevolution for the scalar field can be obtained. The behavior of the scale\nfactor presents a bounce followed by a de Sitter expansion, reproducing the\nquantum cosmological scenario in General Relativity when the source is given by\na cosmological term described by the Schutz variable. The analysis is extended\nto the Brans-Dicke scalar tensor theory.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-16T10:31:35Z"}
{"aid":"http://arxiv.org/abs/2504.11956v1","title":"The Conserved Effective Stress Tensor of Gravitational Wave","summary":"We present a detailed study of the effective stress tensor of gravitational\nwave (GW) as the source for the background Einstein equation and examine three\ncandidates in literature. The second order perturbed Einstein tensor\n$G^{(2)}_{\\mu\\nu}$, up to a coefficient, proposed by Brill, Hartle, and\nIsaacson, has long been known to be covariantly nonconserved with respect to\nthe background spacetime. We observe that $G^{(2)}_{\\mu\\nu}$ is not a true\ntensor on the background spacetime. More importantly, we find that, by\nexpressing $G^{(2)}_{\\mu\\nu}$ in terms of the perturbed Hilbert-Einstein\nactions,\n  the nonconserved part of $G^{(2)}_{\\mu\\nu}$ is actually canceled out by the\nperturbed fluid stress tensors in the back-reaction equation, or is vanishing\nin absence of fluid. The remaining part of $G^{(2)}_{\\mu\\nu}$ is just the\nconserved effective stress tensor $\\tau_{\\mu\\nu}$ proposed by Ford and Parker.\nAs the main result, we derive $\\tau_{\\mu\\nu}$ for a general curved spacetime by\nvarying the GW action and show its conservation using the equation of GW. The\nstress tensor $T_{\\text{MT}}^{\\mu\\nu}$ proposed by MacCallum and Taub was based\non an action $J_2$. We derive $T_{\\text{MT}}^{\\mu\\nu}$ and find that it is\nnonconserved, and that $J_2$ does not give the correct GW equation in presence\nof matter. The difficulty with $J_2$ is due to a background Ricci tensor term,\nwhich should be also canceled out by the fluid term or vanishing in absence of\nfluid. We also demonstrate these three candidates in a flat Robertson-Walker\nspacetime. The conserved $\\tau_{\\mu\\nu}$ has a positive energy density\nspectrum, and is adequate for the back-reaction in a perturbation scheme, while\nthe two nonconserved stress tensors have a negative spectrum at long\nwavelengths and are unphysical.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-16T10:38:43Z"}
{"aid":"http://arxiv.org/abs/2504.11978v1","title":"On the Intersection and Composition properties of conditional\n  independence","summary":"Compositional graphoids are fundamental discrete structures which appear in\nprobabilistic reasoning, particularly in the area of graphical models. They are\nsemigraphoids which satisfy the Intersection and Composition properties. These\nimportant properties, however, are not enjoyed by general probability\ndistributions. We survey what is known in terms of sufficient conditions for\nIntersection and Composition and derive a set of new sufficient conditions in\nthe context of discrete random variables based on conditional information\ninequalities for Shannon entropies.","main_category":"cs.IT","categories":"cs.IT,math.IT,math.ST,stat.TH","published":"2025-04-16T11:17:41Z"}
{"aid":"http://arxiv.org/abs/2504.11983v1","title":"Non-orientable Exceptional Points in Twisted Boundary Systems","summary":"Non-orientable manifolds, such as the M\\\"obius strip and the Klein bottle,\ndefy conventional geometric intuition through their twisted boundary\nconditions. As a result, topological defects on non-orientable manifolds give\nrise to novel physical phenomena. We study the adiabatic transport of\nexceptional points (EPs) along non-orientable closed loops and uncover distinct\ntopological responses arising from the lack of global orientation. Notably, we\ndemonstrate that the cyclic permutation of eigenstates across an EP depends\nsensitively on the loop orientation, yielding inequivalent braid\nrepresentations for clockwise and counterclockwise encirclement; this is a\nfeature unique to non-orientable geometries. Orientation-dependent geometric\nquantities, such as the winding number, cannot be consistently defined due to\nthe absence of a global orientation. However, when a boundary is introduced,\nsuch quantities become well defined within the local interior, even though the\nglobal manifold remains non-orientable. We further demonstrate the adiabatic\nevolution of EPs and the emergence of orientation-sensitive observables in a\nKlein Brillouin zone, described by an effective non-Hermitian Hamiltonian that\npreserves momentum-space glide symmetry. Finally, we numerically implement\nthese ideas in a microdisk cavity with embedded scatterers using synthetic\nmomenta.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mes-hall,quant-ph","published":"2025-04-16T11:26:05Z"}
{"aid":"http://arxiv.org/abs/2504.11997v1","title":"A Computationally Efficient Algorithm for Infinite-Horizon\n  Average-Reward Linear MDPs","summary":"We study reinforcement learning in infinite-horizon average-reward settings\nwith linear MDPs. Previous work addresses this problem by approximating the\naverage-reward setting by discounted setting and employing a value\niteration-based algorithm that uses clipping to constrain the span of the value\nfunction for improved statistical efficiency. However, the clipping procedure\nrequires computing the minimum of the value function over the entire state\nspace, which is prohibitive since the state space in linear MDP setting can be\nlarge or even infinite. In this paper, we introduce a value iteration method\nwith efficient clipping operation that only requires computing the minimum of\nvalue functions over the set of states visited by the algorithm. Our algorithm\nenjoys the same regret bound as the previous work while being computationally\nefficient, with computational complexity that is independent of the size of the\nstate space.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-16T11:47:41Z"}
{"aid":"http://arxiv.org/abs/2504.12003v1","title":"Inclusion of an Inverse Magnetic Hysteresis Model into the Space-Time\n  Finite Element Method for Magnetoquasistatics","summary":"In this note we discuss the numerical solution of the eddy current\napproximation of the Maxwell equations using the simple Pragmatic Algebraic\nModel to include hysteresis effects. In addition to the more standard\ntime-stepping approach we propose a space-time finite element method which\nallows both for parallelization and adaptivity simultaneously in space and\ntime. Numerical experiments confirm both approaches yield the same numerical\nresults.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-16T11:56:42Z"}
{"aid":"http://arxiv.org/abs/2504.12016v1","title":"Active Human Feedback Collection via Neural Contextual Dueling Bandits","summary":"Collecting human preference feedback is often expensive, leading recent works\nto develop principled algorithms to select them more efficiently. However,\nthese works assume that the underlying reward function is linear, an assumption\nthat does not hold in many real-life applications, such as online\nrecommendation and LLM alignment. To address this limitation, we propose\nNeural-ADB, an algorithm based on the neural contextual dueling bandit\nframework that provides a principled and practical method for collecting human\npreference feedback when the underlying latent reward function is non-linear.\nWe theoretically show that when preference feedback follows the\nBradley-Terry-Luce model, the worst sub-optimality gap of the policy learned by\nNeural-ADB decreases at a sub-linear rate as the preference dataset increases.\nOur experimental results on problem instances derived from synthetic preference\ndatasets further validate the effectiveness of Neural-ADB.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-16T12:16:10Z"}
{"aid":"http://arxiv.org/abs/2504.12042v1","title":"Diverse regular spacetimes using a parametrised density profile","summary":"We explore the construction of diverse regular spacetimes (black holes and\ndefects) in General Relativity (GR) using a generic parametrised density\nprofile (the Dekel-Zhao profile), which includes, for specific parameter\nchoices, various well-known examples usually studied in the context of dark\nmatter halos. Our solutions, in the Schwarzschild gauge, include new regular\nblack holes as well as non-singular solutions representing spacetime defects.\nFor a sub-class of metrics, a TOV equation approach with a chosen equation of\nstate works. The status of the energy conditions and the issue of geodesic\ncompleteness are explored in detail. We also provide possible Lagrangian\ndensity constructions for the matter energy-momentum tensors. Further, we study\nthe shadow radius of the new regular black holes, and compare our findings with\navailable observational results from the EHT collaboration. Finally, for the\ndefect solution, we present a model for a stable star (a gravastar) by explicit\nuse of the junction conditions and obtain relevant consequences highlighting\nits characteristic features.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-16T12:56:31Z"}
{"aid":"http://arxiv.org/abs/2504.12067v1","title":"LO2: Microservice API Anomaly Dataset of Logs and Metrics","summary":"Context. Microservice-based systems have gained significant attention over\nthe past years. A critical factor for understanding and analyzing the behavior\nof these systems is the collection of monitoring data such as logs, metrics,\nand traces. These data modalities can be used for anomaly detection and root\ncause analysis of failures. In particular, multi-modal methods utilizing\nseveral types of this data at once have gained traction in the research\ncommunity since these three modalities capture different dimensions of system\nbehavior. Aim. We provide a dataset that supports research on anomaly detection\nand architectural degradation in microservice systems. We generate a\ncomprehensive dataset of logs, metrics, and traces from a production\nmicroservice system to enable the exploration of multi-modal fusion methods\nthat integrate multiple data modalities. Method. We dynamically tested the\nvarious APIs of the MS-based system, implementing the OAuth2.0 protocol using\nthe Locust tool. For each execution of the prepared test suite, we collect logs\nand performance metrics for correct and erroneous calls with data labeled\naccording to the error triggered during the call. Contributions. We collected\napproximately 657,000 individual log files, totaling over two billion log\nlines. In addition, we collected more than 45 million individual metric files\nthat contain 485 unique metrics. We provide an initial analysis of logs,\nidentify key metrics through PCA, and discuss challenges in collecting traces\nfor this system. Moreover, we highlight the possibilities for making a more\nfine-grained version of the data set. This work advances anomaly detection in\nmicroservice systems using multiple data sources.","main_category":"cs.SE","categories":"cs.SE,cs.DC,cs.NI","published":"2025-04-16T13:21:56Z"}
{"aid":"http://arxiv.org/abs/2504.12081v1","title":"QCD$_2$ 't Hooft model: 2-flavour mesons spectrum","summary":"We continue analytical study of the meson mass spectrum in the large-$N_c$\ntwo-dimensional QCD, known as the 't Hooft model, by addressing the most\ngeneral case of quarks with unequal masses. Based on our previous work, we\ndevelop non-perturbative methods to compute spectral sums and systematically\nderive large-$n$ WKB expansion of the spectrum. Furthermore, we examine the\nbehavior of these results in various asymptotic regimes, including the chiral,\nheavy quark, and heavy-light limits, and establish a precise coincidence with\nknown analytical and numerical results obtained through alternative approaches.","main_category":"hep-th","categories":"hep-th,hep-ph,math-ph,math.MP","published":"2025-04-16T13:42:10Z"}
{"aid":"http://arxiv.org/abs/2504.12086v1","title":"Neural Contextual Bandits Under Delayed Feedback Constraints","summary":"This paper presents a new algorithm for neural contextual bandits (CBs) that\naddresses the challenge of delayed reward feedback, where the reward for a\nchosen action is revealed after a random, unknown delay. This scenario is\ncommon in applications such as online recommendation systems and clinical\ntrials, where reward feedback is delayed because the outcomes or results of a\nuser's actions (such as recommendations or treatment responses) take time to\nmanifest and be measured. The proposed algorithm, called Delayed NeuralUCB,\nuses an upper confidence bound (UCB)-based exploration strategy. Under the\nassumption of independent and identically distributed sub-exponential reward\ndelays, we derive an upper bound on the cumulative regret over a T-length\nhorizon. We further consider a variant of the algorithm, called Delayed\nNeuralTS, that uses Thompson Sampling-based exploration. Numerical experiments\non real-world datasets, such as MNIST and Mushroom, along with comparisons to\nbenchmark approaches, demonstrate that the proposed algorithms effectively\nmanage varying delays and are well-suited for complex real-world scenarios.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-16T13:47:25Z"}
{"aid":"http://arxiv.org/abs/2504.12092v1","title":"Virtually structured illumination for terahertz super-resolution imaging","summary":"We demonstrate structured illumination super-resolution imaging in the\nTerahertz (THz) frequency band using the Virtually Structured Detection (VSD)\nmethod. Leveraging our previously reported high-speed, high-sensitivity\natomic-based THz imager, we achieve a resolution enhancement of 74(3)% at 0.55\nTHz, without the aid of deconvolution methods. We show a high-speed THz imaging\nsystem is compatible with the use of advanced optical techniques, with\npotential disruptive effects on applications requiring both high speed and high\nspatial resolution imaging in the THz range.","main_category":"physics.optics","categories":"physics.optics,physics.atom-ph","published":"2025-04-16T13:54:33Z"}
{"aid":"http://arxiv.org/abs/2504.12093v1","title":"The Tripod High-Speed Quantum Memory As a Beam Splitter with Arbitrary\n  Splitting Ratios","summary":"The utilisation of a quantum memory cell as a beam splitter with arbitrary\ncoefficients is demonstrated theoretically. For such a beam splitter, an\ninput-output matrix is derived. We investigate the high-speed quantum memory\nbased on the tripod-type atomic levels and transitions.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-16T13:57:35Z"}
{"aid":"http://arxiv.org/abs/2504.12109v1","title":"Self-Supervised Traversability Learning with Online Prototype Adaptation\n  for Off-Road Autonomous Driving","summary":"Achieving reliable and safe autonomous driving in off-road environments\nrequires accurate and efficient terrain traversability analysis. However, this\ntask faces several challenges, including the scarcity of large-scale datasets\ntailored for off-road scenarios, the high cost and potential errors of manual\nannotation, the stringent real-time requirements of motion planning, and the\nlimited computational power of onboard units. To address these challenges, this\npaper proposes a novel traversability learning method that leverages\nself-supervised learning, eliminating the need for manual annotation. For the\nfirst time, a Birds-Eye View (BEV) representation is used as input, reducing\ncomputational burden and improving adaptability to downstream motion planning.\nDuring vehicle operation, the proposed method conducts online analysis of\ntraversed regions and dynamically updates prototypes to adaptively assess the\ntraversability of the current environment, effectively handling dynamic scene\nchanges. We evaluate our approach against state-of-the-art benchmarks on both\npublic datasets and our own dataset, covering diverse seasons and geographical\nlocations. Experimental results demonstrate that our method significantly\noutperforms recent approaches. Additionally, real-world vehicle experiments\nshow that our method operates at 10 Hz, meeting real-time requirements, while a\n5.5 km autonomous driving experiment further validates the generated\ntraversability cost maps compatibility with downstream motion planning.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-16T14:17:31Z"}
{"aid":"http://arxiv.org/abs/2504.12115v1","title":"GripMap: An Efficient, Spatially Resolved Constraint Framework for\n  Offline and Online Trajectory Planning in Autonomous Racing","summary":"Conventional trajectory planning approaches for autonomous vehicles often\nassume a fixed vehicle model that remains constant regardless of the vehicle's\nlocation. This overlooks the critical fact that the tires and the surface are\nthe two force-transmitting partners in vehicle dynamics; while the tires stay\nwith the vehicle, surface conditions vary with location. Recognizing these\nchallenges, this paper presents a novel framework for spatially resolving\ndynamic constraints in both offline and online planning algorithms applied to\nautonomous racing. We introduce the GripMap concept, which provides a spatial\nresolution of vehicle dynamic constraints in the Frenet frame, allowing\nadaptation to locally varying grip conditions. This enables compensation for\nlocation-specific effects, more efficient vehicle behavior, and increased\nsafety, unattainable with spatially invariant vehicle models. The focus is on\nlow storage demand and quick access through perfect hashing. This framework\nproved advantageous in real-world applications in the presented form.\nExperiments inspired by autonomous racing demonstrate its effectiveness. In\nfuture work, this framework can serve as a foundational layer for developing\nfuture interpretable learning algorithms that adjust to varying grip conditions\nin real-time.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-16T14:25:29Z"}
{"aid":"http://arxiv.org/abs/2504.12130v1","title":"Dynamics of localized states in the stochastic discrete nonlinear\n  Schr√∂dinger equation","summary":"We reconsider the dynamics of localized states in the deterministic and\nstochastic discrete nonlinear Schr\\\"odinger equation. Localized initial\nconditions disperse if the strength of the nonlinear part drops below a\nthreshold. Localized states are unstable in a noisy environment. As expected,\nan infinite temperature state emerges when multiplicative noise is applied,\nwhile additive noise yields unbounded dynamics since conservation of\nnormalization is violated.","main_category":"nlin.PS","categories":"nlin.PS,cond-mat.stat-mech","published":"2025-04-16T14:44:40Z"}
{"aid":"http://arxiv.org/abs/2504.12144v1","title":"PINNs for Solving Unsteady Maxwell's Equations: Convergence Issues and\n  Comparative Assessment with Compact Schemes","summary":"Physics-Informed Neural Networks (PINNs) have recently emerged as a promising\nalternative for solving partial differential equations, offering a mesh-free\nframework that incorporates physical laws directly into the learning process.\nIn this study, we explore the application of PINNs for solving unsteady\nMaxwell's equations and compare their performance with two established\nnumerical methods: the Finite-Difference Time-Domain (FDTD) method and a\ncompact Pade scheme with filtering. Three benchmark problems are considered,\nranging from 1D free-space wave propagation to 2D Gaussian pulses in periodic\nand dielectric media. We assess the effectiveness of convergence-enhancing\nstrategies for PINNs, including random Fourier features, spatio-temporal\nperiodicity, and temporal causality training. An ablation study highlights that\narchitectural choices must align with the underlying physics. Additionally, we\nemploy a Neural Tangent Kernel framework to examine the spatio-temporal\nconvergence behavior of PINNs. Results show that convergence rates correlate\nwith error over time but not in space, revealing a limitation in how training\ndynamics allocate learning effort. Overall, this study demonstrates that PINNs,\nwhen properly configured, can match or surpass traditional solvers in accuracy\nand flexibility, though challenges remain in addressing spatial inhomogeneity\nand adapting training to localized complexity.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-04-16T14:56:17Z"}
{"aid":"http://arxiv.org/abs/2504.12158v1","title":"What is a monoid?","summary":"In many situations one encounters a notion that resembles that of a monoid.\nIt consists of a carrier and two operations that resemble a unit and a\nmultiplication, subject to three equations that resemble associativity and left\nand right unital laws. The question then arises whether this notion in fact\nthat of a monoid in a suitable sense. Category theorists have answered this\nquestion by providing a notion of monoid in a monoidal category, or more\ngenerally in a multicategory. While this encompasses many examples, it is\nunsuitable in other cases, such as the notion of relative monad, and the\nmodelling of call-by-push-value sequencing. In each of these examples, the\nleftmost and/or the rightmost factor of a multiplication or associativity law\nseems to be distinguished. To include such examples, we generalize the\nmulticategorical framework in two stages. Firstly, we move to the framework of\na left-skew multicategory (due to Bourke and Lack), which generalizes both\nmulticategory and left-skew monoidal category. The notion of monoid in this\nframework encompasses examples where only the leftmost factor is distinguished,\nsuch as the notion of relative monad. Secondly, we consider monoids in the\nnovel framework of a bi-skew multicategory. This encompasses examples where\nboth the leftmost and the rightmost factor are distinguished, such as the\nnotion of a category on a span, and the modelling of call-by-push-value\nsequencing. In the bi-skew framework (which is the most general), we give a\ncoherence result saying that a monoid corresponds to an unbiased monoid, i.e. a\nmap from the unit bi-skew multicategory.","main_category":"math.CT","categories":"math.CT,cs.PL,F.3.2","published":"2025-04-16T15:04:48Z"}
{"aid":"http://arxiv.org/abs/2504.12173v1","title":"Computational Exploration of Inclined Magnetic Fields and Variable\n  Thermal Flux Effects on the Flow of Dusty Hybrid Nanofluid around\n  Stretching/Shrinking Wedge","summary":"This extensive investigation explores the influence of inclined magnetic\nfields and radiative non-linear heat flux on the behavior of dusty hybrid\nnanofluids over stretching/shrinking wedges. Employing $Cu$-$SiO_2$ as a hybrid\nnanoparticle composition and ethylene glycol $(EG)$ as the base liquid, the\nstudy investigates the fluid's response to a uniform magnetic field. The\ngoverning partial differential equations and associated boundary conditions are\nadeptly transformed into ordinary differential equations using appropriate\ntransformations and then non-dimensionalized. Numerical simulations are\nexecuted using MATLAB and the bvp-4c solver. The outcomes offer a profound\ninsight into thermofluid dynamics in industrial applications featuring\nintricate fluid flows, evaluating the influence of magnetic parameters on\ndiverse fluid types, including nanofluids and dusty hybrid nanofluids.\nFurthermore, the investigation analyzes the impact of heat production and\nabsorption on both vertical and horizontal plates, studying the significance of\nthe velocity ratio factor in relation to the drag coefficient and local Nusselt\nnumber under thermal conditions of generation and absorption.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-16T15:25:46Z"}
{"aid":"http://arxiv.org/abs/2504.12203v1","title":"Modality-Independent Explainable Detection of Inaccurate Organ\n  Segmentations Using Denoising Autoencoders","summary":"In radiation therapy planning, inaccurate segmentations of organs at risk can\nresult in suboptimal treatment delivery, if left undetected by the clinician.\nTo address this challenge, we developed a denoising autoencoder-based method to\ndetect inaccurate organ segmentations. We applied noise to ground truth organ\nsegmentations, and the autoencoders were tasked to denoise them. Through the\napplication of our method to organ segmentations generated on both MR and CT\nscans, we demonstrated that the method is independent of imaging modality. By\nproviding reconstructions, our method offers visual information about\ninaccurate regions of the organ segmentations, leading to more explainable\ndetection of suboptimal segmentations. We compared our method to existing\napproaches in the literature and demonstrated that it achieved superior\nperformance for the majority of organs.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-16T15:53:40Z"}
{"aid":"http://arxiv.org/abs/2504.12223v1","title":"Superspecial representations of Weyl groups","summary":"We define a subset of the set of special representations of a Weyl group.\nThis subset contains at most one representation.","main_category":"math.RT","categories":"math.RT","published":"2025-04-16T16:15:43Z"}
{"aid":"http://arxiv.org/abs/2504.12239v1","title":"The Discovery of Two Quadruple Star Systems with the Second and Third\n  Shortest Outer Periods","summary":"We present the discovery of two quadruple star systems -- TIC 285853156 and\nTIC 392229331 -- each consisting of two bound eclipsing binary stars. Among the\nmost compact quadruples known, TIC 392229331 and TIC 285853156 have the second\nand third shortest outer orbital periods (145 days and 152 days, respectively)\nafter BU Canis Minoris (122 days, Pribulla et al. 2023). We demonstrate that\nboth systems are long-term dynamically stable despite substantial outer orbital\neccentricities (0.33 for TIC 285853156 and 0.56 for TIC 392229331). We\npreviously reported these systems in Kostov et al. (2022) and Kostov et al.\n(2024) as 2+2 hierarchical quadruple candidates producing two sets of primary\nand secondary eclipses in TESS data, as well as prominent eclipse timing\nvariations on both binary components. We combine all available TESS data and\nnew spectroscopic observations into a comprehensive photodynamical model,\nproving that the component binary stars are gravitationally bound in both\nsystems and finding accurate stellar and orbital parameters for both systems,\nincluding very precise determinations of the outer periods. TIC 285853156 and\nTIC 392229331 represent the latest addition to the small population of\nwell-characterized proven quadruple systems dynamically interacting on\ndetectable timescales.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-16T16:44:33Z"}
{"aid":"http://arxiv.org/abs/2504.12256v1","title":"FLIP Reasoning Challenge","summary":"Over the past years, advances in artificial intelligence (AI) have\ndemonstrated how AI can solve many perception and generation tasks, such as\nimage classification and text writing, yet reasoning remains a challenge. This\npaper introduces the FLIP dataset, a benchmark for evaluating AI reasoning\ncapabilities based on human verification tasks on the Idena blockchain. FLIP\nchallenges present users with two orderings of 4 images, requiring them to\nidentify the logically coherent one. By emphasizing sequential reasoning,\nvisual storytelling, and common sense, FLIP provides a unique testbed for\nmultimodal AI systems. Our experiments evaluate state-of-the-art models,\nleveraging both vision-language models (VLMs) and large language models (LLMs).\nResults reveal that even the best open-sourced and closed-sourced models\nachieve maximum accuracies of 75.5% and 77.9%, respectively, in zero-shot\nsettings, compared to human performance of 95.3%. Captioning models aid\nreasoning models by providing text descriptions of images, yielding better\nresults than when using the raw images directly, 69.6% vs. 75.2% for Gemini 1.5\nPro. Combining the predictions from 15 models in an ensemble increases the\naccuracy to 85.2%. These findings highlight the limitations of existing\nreasoning models and the need for robust multimodal benchmarks like FLIP. The\nfull codebase and dataset will be available at\nhttps://github.com/aplesner/FLIP-Reasoning-Challenge.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-16T17:07:16Z"}
{"aid":"http://arxiv.org/abs/2504.12293v1","title":"Exceptional times when bigeodesics exist in dynamical last passage\n  percolation","summary":"It is believed that, under very general conditions, doubly infinite geodesics\n(or bigeodesics) do not exist for planar first and last passage percolation\n(LPP) models. However, if one endows the model with a natural dynamics, thereby\ngradually perturbing the geometry, then it is plausible that there could exist\na non-trivial set of exceptional times $\\mathscr{T}$ at which such bigeodesics\nexist, and the objective of this paper is to investigate this set. For\ndynamical exponential LPP, we obtain an $\\Omega( 1/\\log n)$ lower bound on the\nprobability that there exists a random time $t\\in [0,1]$ at which a geodesic of\nlength $n$ passes through the origin at its midpoint -- note that this is\nslightly short of proving the non-triviality of the set $\\mathscr{T}$ which\nwould instead require an $\\Omega(1)$ lower bound. In the other direction,\nworking with a dynamical version of Brownian LPP, we show that the average\ntotal number of changes that a geodesic of length $n$ accumulates in unit time\nis at most $n^{5/3+o(1)}$; using this, we establish that the Hausdorff\ndimension of $\\mathscr{T}$ is a.s. upper bounded by $1/2$. Further, for a fixed\nangle $\\theta$, we show that the set $\\mathscr{T}^\\theta\\subseteq \\mathscr{T}$\nof exceptional times at which a $\\theta$-directed bigeodesic exists a.s. has\nHausdorff dimension zero. We provide a list of open questions.","main_category":"math.PR","categories":"math.PR","published":"2025-04-16T17:56:01Z"}
{"aid":"http://arxiv.org/abs/2504.12631v1","title":"Geometry-preserving Numerical Scheme for Riemannian Stochastic\n  Differential Equations","summary":"Stochastic differential equations (SDEs) on Riemannian manifolds have\nnumerous applications in system identification and control. However,\ngeometry-preserving numerical methods for simulating Riemannian SDEs remain\nrelatively underdeveloped. In this paper, we propose the Exponential\nEuler-Maruyama (Exp-EM) scheme for approximating solutions of SDEs on\nRiemannian manifolds. The Exp-EM scheme is both geometry-preserving and\ncomputationally tractable. We establish a strong convergence rate of\n$\\mathcal{O}(\\delta^{\\frac{1 - \\epsilon}{2}})$ for the Exp-EM scheme, which\nextends previous results obtained for specific manifolds to a more general\nsetting. Numerical simulations are provided to illustrate our theoretical\nfindings.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-17T04:14:00Z"}
{"aid":"http://arxiv.org/abs/2504.12641v1","title":"Hodge Dual Gauge Symmetry in Minimal Einstein-Aether Theory","summary":"Einstein-aether gravity is a theory that breaks the local Lorentz symmetry by\nintroducing a preferred direction via a vector field, which is considered to\nplay the role of an aether. The theory is identified by four coupling constants\nbetween the aether and gravity. Minimal Einstein-aether is the special case in\nwhich only one of the couplings is non-zero. We show that the aether vector\nfield in its minimal version is Hodge dual to a gauge field. The gauge symmetry\nin the dual description has been known for decades and has been used to\nimplement a cosmological constant into the Lagrangian. As a result, solutions\nto the well-established gauge theory can be transferred into the minimal\nEinstein-aether theory straightforwardly. On the other hand, some of the\nproposed solutions to the minimal Einstein-aether theory could be discarded as\npure gauges of the vanishing aether. We prove as a theorem that this holds true\nfor all divergence-less aether fields.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-17T04:58:15Z"}
{"aid":"http://arxiv.org/abs/2504.12689v1","title":"HSS-IAD: A Heterogeneous Same-Sort Industrial Anomaly Detection Dataset","summary":"Multi-class Unsupervised Anomaly Detection algorithms (MUAD) are receiving\nincreasing attention due to their relatively low deployment costs and improved\ntraining efficiency. However, the real-world effectiveness of MUAD methods is\nquestioned due to limitations in current Industrial Anomaly Detection (IAD)\ndatasets. These datasets contain numerous classes that are unlikely to be\nproduced by the same factory and fail to cover multiple structures or\nappearances. Additionally, the defects do not reflect real-world\ncharacteristics. Therefore, we introduce the Heterogeneous Same-Sort Industrial\nAnomaly Detection (HSS-IAD) dataset, which contains 8,580 images of\nmetallic-like industrial parts and precise anomaly annotations. These parts\nexhibit variations in structure and appearance, with subtle defects that\nclosely resemble the base materials. We also provide foreground images for\nsynthetic anomaly generation. Finally, we evaluate popular IAD methods on this\ndataset under multi-class and class-separated settings, demonstrating its\npotential to bridge the gap between existing datasets and real factory\nconditions. The dataset is available at\nhttps://github.com/Qiqigeww/HSS-IAD-Dataset.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T06:31:26Z"}
{"aid":"http://arxiv.org/abs/2504.12718v1","title":"TUMLS: Trustful Fully Unsupervised Multi-Level Segmentation for Whole\n  Slide Images of Histology","summary":"Digital pathology, augmented by artificial intelligence (AI), holds\nsignificant promise for improving the workflow of pathologists. However,\nchallenges such as the labor-intensive annotation of whole slide images (WSIs),\nhigh computational demands, and trust concerns arising from the absence of\nuncertainty estimation in predictions hinder the practical application of\ncurrent AI methodologies in histopathology. To address these issues, we present\na novel trustful fully unsupervised multi-level segmentation methodology\n(TUMLS) for WSIs. TUMLS adopts an autoencoder (AE) as a feature extractor to\nidentify the different tissue types within low-resolution training data. It\nselects representative patches from each identified group based on an\nuncertainty measure and then does unsupervised nuclei segmentation in their\nrespective higher-resolution space without using any ML algorithms. Crucially,\nthis solution integrates seamlessly into clinicians workflows, transforming the\nexamination of a whole WSI into a review of concise, interpretable cross-level\ninsights. This integration significantly enhances and accelerates the workflow\nwhile ensuring transparency. We evaluated our approach using the UPENN-GBM\ndataset, where the AE achieved a mean squared error (MSE) of 0.0016.\nAdditionally, nucleus segmentation is assessed on the MoNuSeg dataset,\noutperforming all unsupervised approaches with an F1 score of 77.46% and a\nJaccard score of 63.35%. These results demonstrate the efficacy of TUMLS in\nadvancing the field of digital pathology.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-17T07:48:05Z"}
{"aid":"http://arxiv.org/abs/2504.12785v1","title":"New developments in MatCont: delay equation importer and Lyapunov\n  exponents","summary":"MatCont is a powerful toolbox for numerical bifurcation analysis focussing on\nsmooth ODEs. A user can study equilibria, periodic and connecting orbits, and\ntheir stability and bifurcations. Here, we report on additional features in\nversion 7p6. The first is a delay equation importer enabling MatCont users to\nstudy a much larger class of models, namely delay equations with finite delay\n(including delay differential and renewal equations). This importer translates\nthe delay equation into a system of ODEs using a pseudospectral approximation\nwith an order specified by the user. We also implemented Lyapunov exponent\ncomputations, event functions for Poincar\\'e maps, and enhanced homoclinic\ncontinuation. We demonstrate these features with test cases, such as the\nMackey-Glass equation and a renewal equation, and provide additional examples\nin online tutorials.","main_category":"math.DS","categories":"math.DS","published":"2025-04-17T09:33:27Z"}
{"aid":"http://arxiv.org/abs/2504.12786v1","title":"Magnetized black holes in Kaluza-Klein theory and the Kerr/CFT\n  correspondence","summary":"In this work, we examine the Kerr/CFT correspondence for magnetized black\nholes arising from Kaluza--Klein theory, demonstrating that Kerr/CFT holography\npersists beyond the traditional Einstein--Maxwell framework. Notably, unlike in\nthe Einstein--Maxwell case, the massless neutral scalar field equation here is\nfully separable into radial and angular parts. This separability reveals a\nhidden conformal symmetry in the near--horizon, low--frequency regime,\nproviding further support for the robustness of Kerr/CFT dualities in extended\ngravitational theories.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-17T09:33:54Z"}
{"aid":"http://arxiv.org/abs/2504.12790v1","title":"Empirically Evaluating the Use of Bytecode for Diversity-Based Test Case\n  Prioritisation","summary":"Regression testing assures software correctness after changes but is\nresource-intensive. Test Case Prioritisation (TCP) mitigates this by ordering\ntests to maximise early fault detection. Diversity-based TCP prioritises\ndissimilar tests, assuming they exercise different system parts and uncover\nmore faults. Traditional static diversity-based TCP approaches (i.e., methods\nthat utilise the dissimilarity of tests), like the state-of-the-art FAST\napproach, rely on textual diversity from test source code, which is effective\nbut inefficient due to its relative verbosity and redundancies affecting\nsimilarity calculations. This paper is the first to study bytecode as the basis\nof diversity in TCP, leveraging its compactness for improved efficiency and\naccuracy. An empirical study on seven Defects4J projects shows that bytecode\ndiversity improves fault detection by 2.3-7.8% over text-based TCP. It is also\n2-3 orders of magnitude faster in one TCP approach and 2.5-6 times faster in\nFAST-based TCP. Filtering specific bytecode instructions improves efficiency up\nto fourfold while maintaining effectiveness, making bytecode diversity a\nsuperior static approach.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-17T09:40:49Z"}
{"aid":"http://arxiv.org/abs/2504.12791v1","title":"Probing the topological protection of edge states in multilayer tungsten\n  ditelluride with the superconducting proximity effect","summary":"The topology of WTe2, a transition metal dichalcogenide with large spin-orbit\ninteractions, is thought to combine type II Weyl semimetal and second-order\ntopological insulator (SOTI) character. The SOTI character should endow WTe2\nmultilayer crystals with topologically protected helical states at its hinges,\nand, indeed, 1D states have been detected thanks to Josephson interferometry.\nHowever, the immunity to backscattering conferred to those states by their\nhelical nature has so far not been tested. To probe the topological protection\nof WTe2 edge states, we have fabricated Superconducting Quantum Interference\nDevices (SQUIDs) in which the supercurrent through a junction on the crystal\nedge interferes with the supercurrent through a junction in the bulk of the\ncrystal. We find behaviors ranging from a Symmetric SQUID pattern to asymmetric\nSQUID patterns, including one in which the modulation by magnetic field reveals\na sawtooth-like supercurrent versus phase relation for the edge junction,\ndemonstrating that the supercurrent at the edge is carried by ballistic\nchannels over 600 nm, a tell-tale sign of the SOTI character of WTe2.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-17T09:43:04Z"}
{"aid":"http://arxiv.org/abs/2504.12817v1","title":"Explainable Scene Understanding with Qualitative Representations and\n  Graph Neural Networks","summary":"This paper investigates the integration of graph neural networks (GNNs) with\nQualitative Explainable Graphs (QXGs) for scene understanding in automated\ndriving. Scene understanding is the basis for any further reactive or proactive\ndecision-making. Scene understanding and related reasoning is inherently an\nexplanation task: why is another traffic participant doing something, what or\nwho caused their actions? While previous work demonstrated QXGs' effectiveness\nusing shallow machine learning models, these approaches were limited to\nanalysing single relation chains between object pairs, disregarding the broader\nscene context. We propose a novel GNN architecture that processes entire graph\nstructures to identify relevant objects in traffic scenes. We evaluate our\nmethod on the nuScenes dataset enriched with DriveLM's human-annotated\nrelevance labels. Experimental results show that our GNN-based approach\nachieves superior performance compared to baseline methods. The model\neffectively handles the inherent class imbalance in relevant object\nidentification tasks while considering the complete spatial-temporal\nrelationships between all objects in the scene. Our work demonstrates the\npotential of combining qualitative representations with deep learning\napproaches for explainable scene understanding in autonomous driving systems.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.CV","published":"2025-04-17T10:21:30Z"}
{"aid":"http://arxiv.org/abs/2504.12822v1","title":"Miura transformation in bidifferential calculus and a vectorial Darboux\n  transformation for the Fokas-Lenells equation","summary":"Using a general result of bidifferential calculus and recent results of other\nauthors, a vectorial binary Darboux transformation is derived for the first\nmember of the \"negative\" part of the potential Kaup-Newell hierarchy, which is\na system of two coupled Fokas-Lenells equations. Miura transformations are\nfound from the latter to the first member of the negative part of the AKNS\nhierarchy and also to its \"pseudodual\". The reduction to the Fokas-Lenells\nequation is implemented and exact solutions with a plane wave seed generated.","main_category":"nlin.SI","categories":"nlin.SI,math-ph,math.MP","published":"2025-04-17T10:32:39Z"}
{"aid":"http://arxiv.org/abs/2504.12832v1","title":"Physics of an AMOC Overshoot in a Box Model","summary":"Recently the global average temperature has temporarily exceeded the\n1.5{\\deg}C goal of the Paris Agreement, and so an overshoot of various climate\ntipping elements becomes increasingly likely. In this study we analyze the\nphysical processes of an overshoot of the Atlantic Meridional Overturning\nCirculation (AMOC), one of the major tipping elements, using a conceptual box\nmodel. Here either the atmospheric temperature above the North Atlantic, or the\nfreshwater forcing into the North Atlantic overshoot their respective critical\nboundaries. In both cases a higher forcing rate can prevent a collapse of the\nAMOC, since a higher rate of forcing causes initially a fresher North Atlantic,\nwhich in turn results in a higher northward transport by the subtropical gyre\nsupplementing the salinity loss in time. For small exceedance amplitudes the\nAMOC is still resilient as the forcing rates can be low and so other state\nvariables outside of the North Atlantic can adjust. Contrarily, for larger\novershoots the trajectories are dynamically similar and we find a lower limit\nin volume and exceedance time for respectively freshwater and temperature\nforcing in order to prevent a collapse. Moreover, for a large overshoot an\nincreased air-sea temperature coupling has a destabilizing effect, while the\nreverse holds for an overshoot close to the tipping point. The understanding of\nthe physics of the AMOC overshoot behavior is important for interpreting\nresults of Earth System Models and for evaluating the effects of mitigation and\nintervention strategies.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-17T10:46:21Z"}
{"aid":"http://arxiv.org/abs/2504.12835v1","title":"Kinetic simulated annealing optimization with entropy-based cooling rate","summary":"We present a modified simulated annealing method with a dynamical choice of\nthe cooling temperature. The latter is determined via a closed-loop control and\nis proven to yield exponential decay of the entropy of the particle system. The\nanalysis is carried out through kinetic equations for interacting particle\nsystems describing the simulated annealing method in an extended phase space.\nDecay estimates are derived under the quasi-invariant scaling of the resulting\nsystem of Boltzmann-type equations to assess the consistency with their\nmean-field limit. Numerical results are provided to illustrate and support the\ntheoretical findings.","main_category":"math.OC","categories":"math.OC,nlin.AO","published":"2025-04-17T10:50:24Z"}
{"aid":"http://arxiv.org/abs/2504.12841v1","title":"ALT: A Python Package for Lightweight Feature Representation in Time\n  Series Classification","summary":"We introduce ALT, an open-source Python package created for efficient and\naccurate time series classification (TSC). The package implements the adaptive\nlaw-based transformation (ALT) algorithm, which transforms raw time series data\ninto a linearly separable feature space using variable-length shifted time\nwindows. This adaptive approach enhances its predecessor, the linear law-based\ntransformation (LLT), by effectively capturing patterns of varying temporal\nscales. The software is implemented for scalability, interpretability, and ease\nof use, achieving state-of-the-art performance with minimal computational\noverhead. Extensive benchmarking on real-world datasets demonstrates the\nutility of ALT for diverse TSC tasks in physics and related domains.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV,cs.MS,stat.ML","published":"2025-04-17T10:57:29Z"}
{"aid":"http://arxiv.org/abs/2504.12843v1","title":"Quadratic subproduct systems, free products, and their C*-algebras","summary":"Motivated by the interplay between quadratic algebras, noncommutative\ngeometry, and operator theory, we introduce the notion of quadratic subproduct\nsystems of Hilbert spaces. Specifically, we study the subproduct systems\ninduced by a finite number of complex quadratic polynomials in noncommuting\nvariables, and describe their Toeplitz and Cuntz--Pimsner algebras. Inspired by\nthe theory of graded associative algebras, we define a free product operation\nin the category of subproduct systems and show that this corresponds to the\nreduced free product of the Toeplitz algebras. Finally, we obtain results about\nthe K-theory of the Toeplitz and Cuntz--Pimsner algebras of a large class of\nquadratic subproduct systems.","main_category":"math.OA","categories":"math.OA","published":"2025-04-17T10:57:58Z"}
{"aid":"http://arxiv.org/abs/2504.12846v1","title":"Timing via Pinwheel Double Categories","summary":"We discuss string diagrams for timed process theories -- represented by\nduoidally-graded symmetric strict monoidal categories -- built upon the string\ndiagrams of pinwheel double categories.","main_category":"math.CT","categories":"math.CT,cs.LO","published":"2025-04-17T11:02:52Z"}
{"aid":"http://arxiv.org/abs/2504.12867v1","title":"EmoVoice: LLM-based Emotional Text-To-Speech Model with Freestyle Text\n  Prompting","summary":"Human speech goes beyond the mere transfer of information; it is a profound\nexchange of emotions and a connection between individuals. While Text-to-Speech\n(TTS) models have made huge progress, they still face challenges in controlling\nthe emotional expression in the generated speech. In this work, we propose\nEmoVoice, a novel emotion-controllable TTS model that exploits large language\nmodels (LLMs) to enable fine-grained freestyle natural language emotion\ncontrol, and a phoneme boost variant design that makes the model output phoneme\ntokens and audio tokens in parallel to enhance content consistency, inspired by\nchain-of-thought (CoT) and modality-of-thought (CoM) techniques. Besides, we\nintroduce EmoVoice-DB, a high-quality 40-hour English emotion dataset featuring\nexpressive speech and fine-grained emotion labels with natural language\ndescriptions. EmoVoice achieves state-of-the-art performance on the English\nEmoVoice-DB test set using only synthetic training data, and on the Chinese\nSecap test set using our in-house data. We further investigate the reliability\nof existing emotion evaluation metrics and their alignment with human\nperceptual preferences, and explore using SOTA multimodal LLMs GPT-4o-audio and\nGemini to assess emotional speech. Demo samples are available at\nhttps://anonymous.4open.science/r/EmoVoice-DF55. Dataset, code, and checkpoints\nwill be released.","main_category":"eess.AS","categories":"eess.AS,cs.AI,cs.CL","published":"2025-04-17T11:50:04Z"}
{"aid":"http://arxiv.org/abs/2504.12880v1","title":"Can Masked Autoencoders Also Listen to Birds?","summary":"Masked Autoencoders (MAEs) pretrained on AudioSet fail to capture the\nfine-grained acoustic characteristics of specialized domains such as\nbioacoustic monitoring. Bird sound classification is critical for assessing\nenvironmental health, yet general-purpose models inadequately address its\nunique acoustic challenges. To address this, we introduce Bird-MAE, a\ndomain-specialized MAE pretrained on the large-scale BirdSet dataset. We\nexplore adjustments to pretraining, fine-tuning and utilizing frozen\nrepresentations. Bird-MAE achieves state-of-the-art results across all BirdSet\ndownstream tasks, substantially improving multi-label classification\nperformance compared to the general-purpose Audio-MAE baseline. Additionally,\nwe propose prototypical probing, a parameter-efficient method for leveraging\nMAEs' frozen representations. Bird-MAE's prototypical probes outperform linear\nprobing by up to 37\\% in MAP and narrow the gap to fine-tuning to approximately\n3\\% on average on BirdSet.","main_category":"cs.LG","categories":"cs.LG,cs.SD,eess.AS","published":"2025-04-17T12:13:25Z"}
{"aid":"http://arxiv.org/abs/2504.12916v1","title":"Exact Learning Dynamics of In-Context Learning in Linear Transformers\n  and Its Application to Non-Linear Transformers","summary":"Transformer models exhibit remarkable in-context learning (ICL), adapting to\nnovel tasks from examples within their context, yet the underlying mechanisms\nremain largely mysterious. Here, we provide an exact analytical\ncharacterization of ICL emergence by deriving the closed-form stochastic\ngradient descent (SGD) dynamics for a simplified linear transformer performing\nregression tasks. Our analysis reveals key properties: (1) a natural separation\nof timescales directly governed by the input data's covariance structure,\nleading to staged learning; (2) an exact description of how ICL develops,\nincluding fixed points corresponding to learned algorithms and conservation\nlaws constraining the dynamics; and (3) surprisingly nonlinear learning\nbehavior despite the model's linearity. We hypothesize this phenomenology\nextends to non-linear models. To test this, we introduce theory-inspired\nmacroscopic measures (spectral rank dynamics, subspace stability) and use them\nto provide mechanistic explanations for (1) the sudden emergence of ICL in\nattention-only networks and (2) delayed generalization (grokking) in modular\narithmetic models. Our work offers an exact dynamical model for ICL and\ntheoretically grounded tools for analyzing complex transformer training.","main_category":"cs.LG","categories":"cs.LG,cond-mat.dis-nn","published":"2025-04-17T13:05:33Z"}
{"aid":"http://arxiv.org/abs/2504.12934v1","title":"Quantifying walkable accessibility to urban services: An application to\n  Florence, Italy","summary":"The concept of quality of life in urban settings is increasingly associated\nto the accessibility of amenities within a short walking distance for\nresidents. However, this narrative still requires thorough empirical\ninvestigation to evaluate the practical implications, benefits, and challenges.\nIn this work, we propose a novel methodology for evaluating urban accessibility\nto services, with an application to the city of Florence, Italy. Our approach\ninvolves identifying the accessibility of essential services from residential\nbuildings within a 10-minute walking distance, employing a rigorous spatial\nanalysis process and open-source geospatial data. As a second contribution, we\nextend the concept of 10-minute accessibility within a network theory framework\nand apply a clustering algorithm to identify urban communities based on shared\naccess to essential services. Finally, we explore the dimension of functional\nredundancy. Our proposed metrics represent a step forward towards an accurate\nassessment of the adherence to the 10-minute city model and offer a valuable\ntool for place-based policies aimed at addressing spatial disparities in urban\ndevelopment.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-17T13:28:21Z"}
{"aid":"http://arxiv.org/abs/2504.12940v1","title":"A study of Andromeda to improve our knowledge on the evolution and dust\n  production by AGB stars","summary":"We study the AGB population of the galaxy M31, based on available HST and\nSpitzer data,\n  to characterize the individual sources in terms of mass, metallicity and\nformation epoch\n  of the progenitors. Particular attention is dedicated to the derivation of\nthe dust\n  production rate of the stars, in the attempt of determining the global\ncurrent dust production\n  rate of the galaxy, divided between the silicates and the carbonaceous dust\ncontributions.\n  We use results from stellar evolution modelling complemented by the\ndescription of the\n  dust formation process in the wind, to be used in a population synthesis\napproach, based on\n  the star formation history and age-metallicity relationship obtained in\nprevious investigations.\n  The comparison between the results from synthetic modelling and the data\navailable are used\n  for the characterization of AGB stars in M31.\n  We find that the bulk of the AGB population of M31 is composed by low-mass\nstars of\n  different metallicity formed between 6 Gyr and 14 Gyr ago, with an\nadditional, significant\n  contribution from the progeny of 1.7-2.5Msun stars formed during the\nsecondary peak\n  in the star formation, which occurred between 1 and 2 Gyr ago. The dust\nproduction rate of the\n  galaxy is mostly provided by carbon stars, whose contribution is of the order\nof\n  4x10^{-4} Msun/yr, completed by silicates production from massive AGB stars,\n  occurring at a rate of 6x10^{-5} Msun/yr. The implications of the present\n  results on the reliability of AGB modelling are also commented.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-04-17T13:38:03Z"}
{"aid":"http://arxiv.org/abs/2504.12944v1","title":"A Bi-Objective MDP Design approach to redundancy allocation with dynamic\n  maintenance for a parallel system","summary":"The reliability of a system can be improved by the addition of redundant\nelements, giving rise to the well-known redundancy allocation problem (RAP),\nwhich can be seen as a design problem. We propose a novel extension to the RAP\ncalled the Bi-Objective Integrated Design and Dynamic Maintenance Problem\n(BO-IDDMP) which allows for future dynamic maintenance decisions to be\nincorporated. This leads to a problem with first-stage redundancy design\ndecisions and a second-stage sequential decision problem. To the best of our\nknowledge, this is the first use of a continuous-time Markov Decision Process\nDesign framework to formulate a problem with non-trivial dynamics, as well as\nits first use alongside bi-objective optimization. A general heuristic\noptimization methodology for two-stage bi-objective programmes is developed,\nwhich is then applied to the BO-IDDMP. The efficiency and accuracy of our\nmethodology are demonstrated against an exact optimization formulation. The\nheuristic is shown to be orders of magnitude faster, and in only 2 out of 42\ncases fails to find one of the Pareto-optimal solutions found by the exact\nmethod. The inclusion of dynamic maintenance policies is shown to yield\nstronger and better-populated Pareto fronts, allowing more flexibility for the\ndecision-maker. The impacts of varying parameters unique to our problem are\nalso investigated.","main_category":"math.OC","categories":"math.OC","published":"2025-04-17T13:45:14Z"}
{"aid":"http://arxiv.org/abs/2504.12955v1","title":"Systemic risk mitigation in supply chains through network rewiring","summary":"The networked nature of supply chains makes them susceptible to systemic\nrisk, where local firm failures can propagate through firm interdependencies\nthat can lead to cascading supply chain disruptions. The systemic risk of\nsupply chains can be quantified and is closely related to the topology and\ndynamics of supply chain networks (SCN). How different network properties\ncontribute to this risk remains unclear. Here, we ask whether systemic risk can\nbe significantly reduced by strategically rewiring supplier-customer links. In\ndoing so, we understand the role of specific endogenously emerged network\nstructures and to what extent the observed systemic risk is a result of\nfundamental properties of the dynamical system. We minimize systemic risk\nthrough rewiring by employing a method from statistical physics that respects\nfirm-level constraints to production. Analyzing six specific subnetworks of the\nnational SCNs of Ecuador and Hungary, we demonstrate that systemic risk can be\nconsiderably mitigated by 16-50% without reducing the production output of\nfirms. A comparison of network properties before and after rewiring reveals\nthat this risk reduction is achieved by changing the connectivity in\nnon-trivial ways. These results suggest that actual SCN topologies carry\nunnecessarily high levels of systemic risk. We discuss the possibility of\ndevising policies to reduce systemic risk through minimal, targeted\ninterventions in supply chain networks through market-based incentives.","main_category":"econ.GN","categories":"econ.GN,physics.soc-ph,q-fin.EC","published":"2025-04-17T13:59:01Z"}
{"aid":"http://arxiv.org/abs/2504.12967v1","title":"Krysalis Hand: A Lightweight, High-Payload, 18-DoF Anthropomorphic\n  End-Effector for Robotic Learning and Dexterous Manipulation","summary":"This paper presents the Krysalis Hand, a five-finger robotic end-effector\nthat combines a lightweight design, high payload capacity, and a high number of\ndegrees of freedom (DoF) to enable dexterous manipulation in both industrial\nand research settings. This design integrates the actuators within the hand\nwhile maintaining an anthropomorphic form. Each finger joint features a\nself-locking mechanism that allows the hand to sustain large external forces\nwithout active motor engagement. This approach shifts the payload limitation\nfrom the motor strength to the mechanical strength of the hand, allowing the\nuse of smaller, more cost-effective motors. With 18 DoF and weighing only 790\ngrams, the Krysalis Hand delivers an active squeezing force of 10 N per finger\nand supports a passive payload capacity exceeding 10 lbs. These characteristics\nmake Krysalis Hand one of the lightest, strongest, and most dexterous robotic\nend-effectors of its kind. Experimental evaluations validate its ability to\nperform intricate manipulation tasks and handle heavy payloads, underscoring\nits potential for industrial applications as well as academic research. All\ncode related to the Krysalis Hand, including control and teleoperation, is\navailable on the project GitHub repository:\nhttps://github.com/Soltanilara/Krysalis_Hand","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-17T14:19:26Z"}
{"aid":"http://arxiv.org/abs/2504.12974v1","title":"L-systems with Multiplication Operator and c-Entropy","summary":"In this note, we utilize the concepts of c-entropy and the dissipation\ncoefficient in connection with canonical L-systems based on the multiplication\n(by a scalar) operator. Additionally, we examine the coupling of such L-systems\nand derive explicit formulas for the associated c-entropy and dissipation\ncoefficient. In this context, we also introduce the concept of a skew-adjoint\nL-system and analyze its coupling with the original L-system.","main_category":"math.SP","categories":"math.SP","published":"2025-04-17T14:27:10Z"}
{"aid":"http://arxiv.org/abs/2504.12978v1","title":"X-ray linear dichroic orientation tomography: reconstruction of\n  nanoscale three-dimensional orientation fields","summary":"Properties in crystalline and ordered materials tend to be anisotropic, with\ntheir orientation affecting the macroscopic behavior and functionality of\nmaterials. The ability to image the orientation of anisotropic material\nproperties in three dimensions (3D) is fundamental for the understanding and\nfunctionality-driven development of novel materials. With the development of X\nray linear dichroic orientation tomography (XL DOT), it is now possible to\nnon-destructively map three-dimensional (3D) orientation fields in\nmicrometer-sized samples. In this work, we present the iterative,\ngradient-based reconstruction algorithm behind XL DOT that can be used to map\norientations based on linear dichroism in 3D. As linear dichroism can be\nexhibited by a broad spectrum of materials, XL DOT can be used to map, for\nexample, crystal orientations as well as ferroic alignment, such as\nferroelectric and antiferromagnetic order. We demonstrate the robustness of\nthis technique for orientation fields that exhibit smoothly varying and\ngranular configurations, and subsequently identify and discuss optimal\ngeometries for experimental data acquisition and optimal conditions for the\nreconstruction. We anticipate that this technique will be instrumental in\nenabling a deeper understanding of the relationship between material structures\nand their functionality, quantifying, for example, the orientation of charge\ndistributions and magnetic anisotropies at the nanoscale in a wide variety of\nsystems - from functional to energy materials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-17T14:31:25Z"}
{"aid":"http://arxiv.org/abs/2504.12987v1","title":"Global regularity for the Dirichlet problem of Monge-Amp√®re equation\n  in convex polytopes","summary":"We study the Dirichlet problem for Monge-Amp\\`ere equation in bounded convex\npolytopes. We give sharp conditions for the existence of global $C^2$ and\n$C^{2,\\alpha}$ convex solutions provided that a global $C^2$, convex\nsubsolution exists.","main_category":"math.AP","categories":"math.AP","published":"2025-04-17T14:50:08Z"}
{"aid":"http://arxiv.org/abs/2504.12998v1","title":"Automated Generation of Commit Messages in Software Repositories","summary":"Commit messages are crucial for documenting software changes, aiding in\nprogram comprehension and maintenance. However, creating effective commit\nmessages is often overlooked by developers due to time constraints and varying\nlevels of documentation skills. Our research presents an automated approach to\ngenerate commit messages using Machine Learning (ML) and Natural Language\nProcessing (NLP) by developing models that use techniques such as Logistic\nRegression with TF-IDF and Word2Vec, as well as more sophisticated methods like\nLSTM. We used the dataset of code changes and corresponding commit messages\nthat was used by Liu et al., which we used to train and evaluate ML/NLP models\nand was chosen because it is extensively used in previous research, also for\ncomparability in our study. The objective was to explore which ML/NLP\ntechniques generate the most effective, clear, and concise commit messages that\naccurately reflect the code changes. We split the dataset into training,\nvalidation, and testing sets and used these sets to evaluate the performance of\neach model using qualitative and quantitative evaluation methods. Our results\nreveal a spectrum of effectiveness among these models, with the highest BLEU\nscore achieved being 16.82, showcasing the models' capability in automating a\nclear and concise commit message generation. Our paper offers insights into the\ncomparative effectiveness of different machine learning models for automating\ncommit message generation in software development, aiming to enhance the\noverall practice of code documentation. The source code is available at\nhttps://doi.org/10.5281/zenodo.10888106.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-17T15:08:05Z"}
{"aid":"http://arxiv.org/abs/2504.13000v1","title":"Tree-Line graphs and their quantum walks","summary":"For a simple graph $\\Gamma$, a (bipartite)tree-line graph and a tree-graph of\n$\\Gamma$ can be defined. With a (bipartite)tree-line graph constructed by the\nfunction $(b)\\ell$, we study the continuous quantum walk on $(b)\\ell ^n\n\\Gamma$. An equitable partition of a bipartite tree-line graph is obtained by\nits corresponding derived tree graph. This paper also examines quantum walks on\nderived graphs, whose vertices represent their basis state.","main_category":"math.CO","categories":"math.CO","published":"2025-04-17T15:10:49Z"}
{"aid":"http://arxiv.org/abs/2504.13005v1","title":"Knot Floer homology of positive braids","summary":"We compute the next-to-top term of knot Floer homology for positive braid\nlinks. The rank is 1 for any prime positive braid knot. We give some examples\nof fibered positive links that are not positive braids.","main_category":"math.GT","categories":"math.GT","published":"2025-04-17T15:15:06Z"}
{"aid":"http://arxiv.org/abs/2504.13009v1","title":"Sequential ejections of plasma blobs due to unbraiding of tangled loops\n  in the solar atmosphere","summary":"Nanoflares, which are consequences of braids in tangled magnetic fields, are\nan important candidate to heat the solar corona to million degrees. However,\ntheir observational evidence is sparse and many of their observational\ncharacteristics are yet to be discovered. With the high-resolution observations\ntaken by the Extreme Ultraviolet Imager onboard the Solar Orbiter, here we\nstudy a series of ejections of plasma blobs resulted from a braided magnetic\nloops in the upper transition region and reveal some critical characteristics\nof such processes. The cores of these ejections have a size of about 700\\,km, a\nduration less than 1 minute and a speed of about 90\\,\\kms. An important\ncharacteristic is that these plasma blobs are apparently constrained by the\npost-reconnection magnetic loops, along which they show an extension of up to\nabout 2\\,000\\,km. The propagation of unbraiding nodes along the main axis of\nthe tangled loops has a speed of about 45\\,\\kms. The separation angles between\nthe post-reconnection loops and the main axis of the tangled loops are about\n30\\degree. The observations from the Atmospheric Imaging Assembly reveal that\nthe braiding loops are upper transition region structures. Based on these\nobservations, the typical magnetic free energy producing a blob is estimated to\nbe about $3.4\\times10^{23}$\\,erg, well in the nano-flare regime, while the\nkinematic energy of a blob is about $2.3\\times10^{23}$\\,erg, suggesting that a\nmajority of magnetic free energy in a magnetic braid is likely transferred into\nkinematic energy.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-17T15:16:17Z"}
{"aid":"http://arxiv.org/abs/2504.13012v1","title":"Hopf Exceptional Points","summary":"Exceptional points at which eigenvalues and eigenvectors of non-Hermitian\nmatrices coalesce are ubiquitous in the description of a wide range of\nplatforms from photonic or mechanical metamaterials to open quantum systems.\nHere, we introduce a class of Hopf exceptional points (HEPs) that are protected\nby the Hopf invariants (including the higher-dimensional generalizations) and\nwhich exhibit phenomenology sharply distinct from conventional exceptional\npoints. Saliently, owing to their $\\mathbb{Z}_2$ topological invariant related\nto the Witten anomaly, three-fold HEPs and symmetry-protected five-fold HEPs\nact as their own ``antiparticles\". Furthermore, based on higher homotopy groups\nof spheres, we predict the existence of multifold HEPs and symmetry-protected\nHEPs with non-Hermitian topology captured by a range of finite groups (such as\n$\\mathbb{Z}_3$, $\\mathbb{Z}_{12}$, or $\\mathbb{Z}_{24}$) beyond the periodic\ntable of Bernard-LeClair symmetry classes.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,physics.optics,quant-ph","published":"2025-04-17T15:19:05Z"}
{"aid":"http://arxiv.org/abs/2504.13016v1","title":"ORIS allocation to minimize the outage probability in a multi-user VLC\n  scenario","summary":"Visible Light Communication (VLC) is a promising solution to address the\ngrowing demand for wireless data, leveraging the widespread use of\nlight-emitting diodes (LEDs) as transmitters. However, its deployment is\nchallenged by link blockages that cause connectivity outages. Optical\nreconfigurable intelligent surfaces (ORISs) have recently emerged as a solution\nto mitigate these disruptions. This work considers a multi-user VLC system and\ninvestigates the optimal association of ORISs to LEDs and users to minimize the\noutage probability while limiting the number of ORISs used. Numerical results\nfrom our proposed optimization algorithm demonstrate that using ORISs can\nreduce the outage probability by up to 85% compared to a no-ORIS scenario.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-17T15:24:25Z"}
{"aid":"http://arxiv.org/abs/2504.13027v1","title":"Competing Bosonic Reactions: Insight from Exactly Solvable\n  Time-Dependent Models","summary":"We discuss the progress on exactly solvable multistate Landau-Zener models\nfrom a perspective of their application to competing reactions of particle\ncreation from a false vacuum. Such models generally predict that, even with\nidentical initial conditions, and for nearly the same other particle\nparameters, a quantum coherent evolution results in a final particle\ndistribution with significant asymmetry. We use an exact solution of the driven\nbosonic Tavis-Cummings model for two reaction pathways in order to quantify\nthis effect, reveal a corresponding phase transition, and identify its\nuniversality class.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech,gr-qc,hep-th","published":"2025-04-17T15:38:04Z"}
{"aid":"http://arxiv.org/abs/2504.13029v1","title":"Three-dimensional canonical quantum plasmonics for finite media: exact\n  solution in terms of the classical Green tensor","summary":"This article presents a comprehensive three-dimensional canonical\nquantization to treat quantum plasmonics for finite metallic or dielectric\nmedia of arbitrary shape. We use a microscopic model for the dissipative and\ndispersive medium coupled with the electromagnetic field, which is justified by\nthe fact that if one integrates the degrees of freedom of the medium, one\nobtains the macroscopic Maxwell equations. Its quantization features a\nHamiltonian formulation having the form of two infinite harmonic oscillators\ncharacterized by a double continuum. The diagonalized Hamiltonian is quantized\nby the correspondence principle, introducing creation-annihilation operators in\na bosonic Fock space. The diagonal quantum Hamiltonian is the sum of two terms\ncorresponding to the two continua. The physical observables, like, e.g., the\nelectric field, are also the sum of two terms corresponding to the two\ncontinua, one of which had been omitted in the literature geared for an\ninfinite bulk medium. In a second step, we show that the electric field\noperator can by written as linear combinations of the creation-annihilation\noperators with coefficients that satisfy integral equations of Fredholm type.\nWe show that the solution of these equations can be expressed in terms of the\nclassical Green tensor of the medium satisfying the Sommerfeld radiation\ncondition. Finally, we consider the Purcell effect for the spontaneous emission\nof an atom close to the medium. We show that through an exact compensation of\nsome terms, the Purcell factor for the system with the double continuum is\nproportional to the imaginary part of the Green tensor, which defines the local\ndensity of states. This result has the same form as the one obtained in the\nliterature for bulk systems that involve a single continuum and a small\ndissipative background extending to infinity, and can be seen as a\njustification of this approach.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T15:39:29Z"}
{"aid":"http://arxiv.org/abs/2504.13032v1","title":"InstructRAG: Leveraging Retrieval-Augmented Generation on Instruction\n  Graphs for LLM-Based Task Planning","summary":"Recent advancements in large language models (LLMs) have enabled their use as\nagents for planning complex tasks. Existing methods typically rely on a\nthought-action-observation (TAO) process to enhance LLM performance, but these\napproaches are often constrained by the LLMs' limited knowledge of complex\ntasks. Retrieval-augmented generation (RAG) offers new opportunities by\nleveraging external databases to ground generation in retrieved information. In\nthis paper, we identify two key challenges (enlargability and transferability)\nin applying RAG to task planning. We propose InstructRAG, a novel solution\nwithin a multi-agent meta-reinforcement learning framework, to address these\nchallenges. InstructRAG includes a graph to organize past instruction paths\n(sequences of correct actions), an RL-Agent with Reinforcement Learning to\nexpand graph coverage for enlargability, and an ML-Agent with Meta-Learning to\nimprove task generalization for transferability. The two agents are trained\nend-to-end to optimize overall planning performance. Our experiments on four\nwidely used task planning datasets demonstrate that InstructRAG significantly\nenhances performance and adapts efficiently to new tasks, achieving up to a\n19.2% improvement over the best existing approach.","main_category":"cs.AI","categories":"cs.AI,cs.IR","published":"2025-04-17T15:41:39Z"}
{"aid":"http://arxiv.org/abs/2504.13033v1","title":"Practical Application of the Quantum Carleman Lattice Boltzmann Method\n  in Industrial CFD Simulations","summary":"Computational Fluid Dynamics simulations are crucial in industrial\napplications but require extensive computational resources, particularly for\nextreme turbulent regimes. While classical digital approaches remain the\nstandard, quantum computing promises a breakthrough by enabling a more\nefficient encoding of large-scale simulations with a limited number of qubits.\n  This work presents a practical numerical assessment of a hybrid\nquantum-classical approach to CFD based on the Lattice Boltzmann Method (LBM).\nThe inherently non-linear LBM equations are linearized via a Carleman expansion\nand solved using the quantum Harrow Hassidim Lloyd algorithm (HHL). We evaluate\nthis method on three benchmark cases featuring different boundary conditions,\nperiodic, bounceback, and moving wall, using statevector emulation on\nhigh-performance computing resources.\n  Our results confirm the validity of the approach, achieving median error\nfidelities on the order of $10^{-3}$ and success probabilities sufficient for\npractical quantum state sampling. Notably, the spectral properties of small\nlattice systems closely approximate those of larger ones, suggesting a pathway\nto mitigate one of HHL's bottlenecks: eigenvalue pre-evaluation.","main_category":"quant-ph","categories":"quant-ph,physics.comp-ph,physics.flu-dyn","published":"2025-04-17T15:41:48Z"}
{"aid":"http://arxiv.org/abs/2504.13035v1","title":"Prototypes are Balanced Units for Efficient and Effective Partially\n  Relevant Video Retrieval","summary":"In a retrieval system, simultaneously achieving search accuracy and\nefficiency is inherently challenging. This challenge is particularly pronounced\nin partially relevant video retrieval (PRVR), where incorporating more diverse\ncontext representations at varying temporal scales for each video enhances\naccuracy but increases computational and memory costs. To address this\ndichotomy, we propose a prototypical PRVR framework that encodes diverse\ncontexts within a video into a fixed number of prototypes. We then introduce\nseveral strategies to enhance text association and video understanding within\nthe prototypes, along with an orthogonal objective to ensure that the\nprototypes capture a diverse range of content. To keep the prototypes\nsearchable via text queries while accurately encoding video contexts, we\nimplement cross- and uni-modal reconstruction tasks. The cross-modal\nreconstruction task aligns the prototypes with textual features within a shared\nspace, while the uni-modal reconstruction task preserves all video contexts\nduring encoding. Additionally, we employ a video mixing technique to provide\nweak guidance to further align prototypes and associated textual\nrepresentations. Extensive evaluations on TVR, ActivityNet-Captions, and\nQVHighlights validate the effectiveness of our approach without sacrificing\nefficiency.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-17T15:43:29Z"}
{"aid":"http://arxiv.org/abs/2504.13057v1","title":"Covariate balancing estimation and model selection for\n  difference-in-differences approach","summary":"In causal inference, remarkable progress has been made in\ndifference-in-differences (DID) approaches to estimate the average effect of\ntreatment on the treated (ATT). Of these, the semiparametric DID (SDID)\napproach incorporates a propensity score analysis into the DID setup. Supposing\nthat the ATT is a function of covariates, we estimate it by weighting the\ninverse of the propensity score. As one method to make the estimation robust to\nthe propensity score modeling, we incorporate covariate balancing. Then, by\nattentively constructing the moment conditions used in the covariate balancing,\nwe show that the proposed estimator has doubly robustness. In addition to the\nestimation, model selection is also addressed. In practice, covariate selection\nis an essential task in statistical analysis, but even in the basic setting of\nthe SDID approach, there are no reasonable information criteria. Therefore, we\nderive a model selection criterion as an asymptotically bias-corrected\nestimator of risk based on the loss function used in the SDID estimation. As a\nresult, we show that a penalty term is derived that is considerably different\nfrom almost twice the number of parameters that often appears in AIC-type\ninformation criteria. Numerical experiments show that the proposed method\nestimates the ATT robustly compared to the method using propensity scores given\nby the maximum likelihood estimation (MLE), and that the proposed criterion\nclearly reduces the risk targeted in the SDID approach compared to the\nintuitive generalization of the existing information criterion. In addition,\nreal data analysis confirms that there is a large difference between the\nresults of the proposed method and the existing method.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-17T16:11:42Z"}
{"aid":"http://arxiv.org/abs/2504.13070v1","title":"A quadratic estimator view of the transfer function correction in\n  intensity mapping surveys","summary":"In single dish neutral hydrogen (HI) intensity mapping, signal separation\nmethods such as Principal Component Analysis (PCA) are used to clean the\nastrophysical foregrounds. PCA induces a signal loss in the estimated power\nspectrum, which can be corrected by a transfer function (TF). By injecting mock\nsignals of HI into the data and performing the PCA cleaning, we can use the\ncleaned mock HI signal to cross-correlate with the original mock, and estimate\nthe signal loss as a TF, $T(\\vec{k})$. As expected, a correction of\n${T}(\\vec{k})^{-1}$ restores the cross-power between the HI and optical\ngalaxies. However, contrary to intuition, the HI auto-power also requires a\n${T}(\\vec{k})^{-1}$ correction, not ${T}(\\vec{k})^{-2}$. The\n${T}(\\vec{k})^{-1}$ correction is only known empirically through simulations.\nIn this Letter, we show that the ${T}(\\vec{k})^{-1}$ correction in auto-power\nis universal, and can be analytically proven using the quadratic estimator\nformalism through window function normalisation. The normalisation can also be\nused to determine the TF correction for any type of linear process. Using the\nwindow function, we demonstrate that PCA induces mode-mixing in the power\nspectrum estimation, which may lead to biases in the model inference.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-17T16:31:14Z"}
{"aid":"http://arxiv.org/abs/2504.13073v1","title":"Topological defect engineering enables size and shape control in\n  self-assembly","summary":"The self-assembly of complex structures from engineered subunits is a major\ngoal of nanotechnology, but controlling their size becomes increasingly\ndifficult in larger assemblies. Existing strategies present significant\nchallenges, among which are the use of multiple subunit types or the precise\ncontrol of their shape and mechanics. Here we introduce an alternative approach\nbased on identical subunits whose interactions promote crystals, but also favor\ncrystalline defects. We theoretically show that topological restrictions on the\nscope of these defects in large assemblies imply that the assembly size is\ncontrolled by the magnitude of the defect-inducing interaction. Using DNA\norigami, we experimentally demonstrate both size and shape control in\ntwo-dimensional disk- and fiber-like assemblies. Our basic concept of defect\nengineering could be generalized well beyond these simple examples, and thus\nprovide a broadly applicable scheme to control self-assembly.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-17T16:35:44Z"}
{"aid":"http://arxiv.org/abs/2504.13084v1","title":"Proca theory of four-dimensional regularized Gauss-Bonnet gravity and\n  black holes with primary hair","summary":"We introduce a novel, well-defined four-dimensional regularized Gauss-Bonnet\ntheory of gravity by applying a dimensional regularization procedure. The\nresulting theory is a vector-tensor theory within the generalized Proca class.\nWe then consider the static spherically symmetric solutions of this theory and\nfind black hole solutions that acquire primary hair. Notably, one of the\nintegration constants associated with the Proca field is not manifest in the\noriginal metric, but under a disformal transformation of the seed solution, it\nemerges as a second, independent primary hair. This additional hair acts as an\neffective cosmological constant in the disformed geometry, even in the absence\nof a bare cosmological constant term. We further generalize these black hole\nsolutions to include electromagnetic charges and effects related to the\nscalar-tensor counterparts of the regularized Gauss-Bonnet theory. We discuss\nthe implications of our findings to observations.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-17T16:51:57Z"}
{"aid":"http://arxiv.org/abs/2504.13093v1","title":"A lattice point counting approach for the study of the number of\n  self-avoiding walks on $\\mathbb{Z}^{d}$","summary":"We reduce the problem of counting self-avoiding walks in the square lattice\nto a problem of counting the number of integral points in multidimensional\ndomains. We obtain an asymptotic estimate of the number of self-avoiding walks\nof length $n$ in the square lattice. This new formalism gives a natural and\nunified setting in order to study the properties the number of self-avoidings\nwalks in the lattice $\\mathbb{Z}^{d}$ of any dimension $d\\geq 2$.","main_category":"math.PR","categories":"math.PR,math.CO,math.NT","published":"2025-04-17T16:59:16Z"}
{"aid":"http://arxiv.org/abs/2504.13106v1","title":"Intersection of non-degenerate Hermitian variety and cubic hypersurface","summary":"Edoukou, Ling and Xing in 2010, conjectured that in\n\\mathbb{P}^n(\\mathbb{F}_{q^2}), n \\geq 3, the maximum number of common points\nof a non-degenerate Hermitian variety \\mathcal{U}_n and a hypersurface of\ndegree d is achieved only when the hypersurface is a union of d distinct\nhyperplanes meeting in a common linear space \\Pi_{n-2} of codimension 2 such\nthat \\Pi_{n-2} \\cap \\mathcal{U}_n is a non-degenerate Hermitian variety.\nFurthermore, these d hyperplanes are tangent to \\mathcal{U}_n if n is odd and\nnon-tangent if n is even. In this paper, we show that the conjecture is true\nfor d = 3 and q \\geq 7.","main_category":"math.AG","categories":"math.AG","published":"2025-04-17T17:19:04Z"}
{"aid":"http://arxiv.org/abs/2504.13137v1","title":"Integral formulas for hypersurfaces in cones and related questions","summary":"We discuss the validity of Minkowski integral identities for hypersurfaces\ninside a cone, intersecting the boundary of the cone orthogonally. In doing so\nwe correct a formula provided in [3]. Then we study rigidity results for\nconstant mean curvature graphs proving the precise statement of a result given\nin [9] and [10]. Finally we provide an integral estimate for stable constant\nmean curvature hypersurfaces in cones.","main_category":"math.AP","categories":"math.AP","published":"2025-04-17T17:48:27Z"}
{"aid":"http://arxiv.org/abs/2504.13151v1","title":"MIB: A Mechanistic Interpretability Benchmark","summary":"How can we know whether new mechanistic interpretability methods achieve real\nimprovements? In pursuit of meaningful and lasting evaluation standards, we\npropose MIB, a benchmark with two tracks spanning four tasks and five models.\nMIB favors methods that precisely and concisely recover relevant causal\npathways or specific causal variables in neural language models. The circuit\nlocalization track compares methods that locate the model components - and\nconnections between them - most important for performing a task (e.g.,\nattribution patching or information flow routes). The causal variable\nlocalization track compares methods that featurize a hidden vector, e.g.,\nsparse autoencoders (SAEs) or distributed alignment search (DAS), and locate\nmodel features for a causal variable relevant to the task. Using MIB, we find\nthat attribution and mask optimization methods perform best on circuit\nlocalization. For causal variable localization, we find that the supervised DAS\nmethod performs best, while SAE features are not better than neurons, i.e.,\nstandard dimensions of hidden vectors. These findings illustrate that MIB\nenables meaningful comparisons of methods, and increases our confidence that\nthere has been real progress in the field.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-17T17:55:45Z"}
{"aid":"http://arxiv.org/abs/2504.13156v1","title":"Gravitational wave anisotropies from axion inflation","summary":"An important prediction of inflation is the production of a primordial\nstochastic gravitational wave background. Observing this background is\nchallenging due to the weakness of the signal and the simultaneous presence of\nan astrophysical background generated by many unresolved late-time sources. One\npossible way to distinguish between the two is to examine their anisotropies.\nIn this paper we calculate the primordial correlation function of gravitational\nwave anisotropies in the cosmological background generated by axion inflation,\nwhere the inflaton is a pseudo-Nambu-Goldstone boson coupled to gauge fields.\nIn this scenario, tensor modes arise not only from the standard amplification\nof vacuum fluctuations present in any inflationary model, but also from the\ninverse decay process of the produced gauge fields. The correlator of\ngravitational wave anisotropies consists therefore of two main components: the\ncontribution from vacuum tensor modes and the contribution from tensor modes\nsourced by the gauge fields. Our analysis shows that, while the former,\npreviously studied in the literature, is negligible, the one arising from the\nsourced tensor modes, normalized by the fractional energy density at\ninterferometer frequencies, can reach values as large as\n$\\mathcal{O}(10^{-1})$. This result shows that axion inflation can generate\nlarge anisotropies with the potential to be observed by gravitational wave\ndetectors within a reasonable time frame.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph,hep-th","published":"2025-04-17T17:56:58Z"}
{"aid":"http://arxiv.org/abs/2504.13161v1","title":"CLIMB: CLustering-based Iterative Data Mixture Bootstrapping for\n  Language Model Pre-training","summary":"Pre-training datasets are typically collected from web content and lack\ninherent domain divisions. For instance, widely used datasets like Common Crawl\ndo not include explicit domain labels, while manually curating labeled datasets\nsuch as The Pile is labor-intensive. Consequently, identifying an optimal\npre-training data mixture remains a challenging problem, despite its\nsignificant benefits for pre-training performance. To address these challenges,\nwe propose CLustering-based Iterative Data Mixture Bootstrapping (CLIMB), an\nautomated framework that discovers, evaluates, and refines data mixtures in a\npre-training setting. Specifically, CLIMB embeds and clusters large-scale\ndatasets in a semantic space and then iteratively searches for optimal mixtures\nusing a smaller proxy model and a predictor. When continuously trained on 400B\ntokens with this mixture, our 1B model exceeds the state-of-the-art\nLlama-3.2-1B by 2.0%. Moreover, we observe that optimizing for a specific\ndomain (e.g., Social Sciences) yields a 5% improvement over random sampling.\nFinally, we introduce ClimbLab, a filtered 1.2-trillion-token corpus with 20\nclusters as a research playground, and ClimbMix, a compact yet powerful\n400-billion-token dataset designed for efficient pre-training that delivers\nsuperior performance under an equal token budget. We analyze the final data\nmixture, elucidating the characteristics of an optimal data mixture. Our data\nis available at: https://research.nvidia.com/labs/lpr/climb/","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-17T17:58:13Z"}
{"aid":"http://arxiv.org/abs/2504.13178v1","title":"Aligning Constraint Generation with Design Intent in Parametric CAD","summary":"We adapt alignment techniques from reasoning LLMs to the task of generating\nengineering sketch constraints found in computer-aided design (CAD) models.\nEngineering sketches consist of geometric primitives (e.g. points, lines)\nconnected by constraints (e.g. perpendicular, tangent) that define the\nrelationships between them. For a design to be easily editable, the constraints\nmust effectively capture design intent, ensuring the geometry updates\npredictably when parameters change. Although current approaches can generate\nCAD designs, an open challenge remains to align model outputs with design\nintent, we label this problem `design alignment'. A critical first step towards\naligning generative CAD models is to generate constraints which fully-constrain\nall geometric primitives, without over-constraining or distorting sketch\ngeometry. Using alignment techniques to train an existing constraint generation\nmodel with feedback from a constraint solver, we are able to fully-constrain\n93% of sketches compared to 34% when using a na\\\"ive supervised fine-tuning\n(SFT) baseline and only 8.9% without alignment. Our approach can be applied to\nany existing constraint generation model and sets the stage for further\nresearch bridging alignment strategies between the language and design domains.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T17:59:54Z"}
{"aid":"http://arxiv.org/abs/2504.14849v1","title":"Language Models for Materials Discovery and Sustainability: Progress,\n  Challenges, and Opportunities","summary":"Significant advancements have been made in one of the most critical branches\nof artificial intelligence: natural language processing (NLP). These\nadvancements are exemplified by the remarkable success of OpenAI's GPT-3.5/4\nand the recent release of GPT-4.5, which have sparked a global surge of\ninterest akin to an NLP gold rush. In this article, we offer our perspective on\nthe development and application of NLP and large language models (LLMs) in\nmaterials science. We begin by presenting an overview of recent advancements in\nNLP within the broader scientific landscape, with a particular focus on their\nrelevance to materials science. Next, we examine how NLP can facilitate the\nunderstanding and design of novel materials and its potential integration with\nother methodologies. To highlight key challenges and opportunities, we delve\ninto three specific topics: (i) the limitations of LLMs and their implications\nfor materials science applications, (ii) the creation of a fully automated\nmaterials discovery pipeline, and (iii) the potential of GPT-like tools to\nsynthesize existing knowledge and aid in the design of sustainable materials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-21T04:03:32Z"}
{"aid":"http://arxiv.org/abs/2504.14852v1","title":"APIRAT: Integrating Multi-source API Knowledge for Enhanced Code\n  Translation with LLMs","summary":"Code translation is an essential task in software migration, multilingual\ndevelopment, and system refactoring. Recent advancements in large language\nmodels (LLMs) have demonstrated significant potential in this task. However,\nprior studies have highlighted that LLMs often struggle with domain-specific\ncode, particularly in resolving cross-lingual API mappings. To tackle this\nchallenge, we propose APIRAT, a novel code translation method that integrates\nmulti-source API knowledge. APIRAT employs three API knowledge augmentation\ntechniques, including API sequence retrieval, API sequence back-translation,\nand API mapping, to guide LLMs to translating code, ensuring both the correct\nstructure of API sequences and the accurate usage of individual APIs. Extensive\nexperiments on two public datasets, CodeNet and AVATAR, indicate that APIRAT\nsignificantly surpasses existing LLM-based methods, achieving improvements in\ncomputational accuracy ranging from 4% to 15.1%. Additionally, our evaluation\nacross different LLMs showcases the generalizability of APIRAT. An ablation\nstudy further confirms the individual contributions of each API knowledge\ncomponent, underscoring the effectiveness of our approach.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-21T04:24:49Z"}
{"aid":"http://arxiv.org/abs/2504.14864v1","title":"Radiative Transitions for the Ground and Excited Charmonia States","summary":"In this work, we have investigated the physical properties like decay\nconstants, radiative transitions, decay widths, and branching ratios for the\nground and radially excited charmonia states. For the numerical calculations,\nwe have adopted the light-front quark model (LFQM). We have studied\n$\\chi_{c0}\\rightarrow J{/}\\psi+\\gamma $ and\n$\\psi(2S)\\rightarrow\\chi_{c0}+\\gamma$, $h_c(1P)\\rightarrow\\eta_c(1S)+\\gamma $,\nand $\\eta_c(2S)\\rightarrow h_c(1P)+\\gamma $ transitions in this work. We have\nalso demonstrated the behavior of the transition form factors (TFFs) for the\n$h_c(1P)\\rightarrow\\eta_c(1S)+\\gamma $ and\n$\\psi(2S)\\rightarrow\\chi_{c0}+\\gamma$ decays in this model. Using the TFFs\nresults, we have calculated the decay widths and branching ratios for these\ntransitions. Our numerical results of decay constants, decay widths, and\nbranching ratios are overall in good agreement with available experimental,\ntheoretical and lattice simulation data.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-21T05:22:46Z"}
{"aid":"http://arxiv.org/abs/2504.14877v1","title":"Collaborative Enhancement Network for Low-quality Multi-spectral Vehicle\n  Re-identification","summary":"The performance of multi-spectral vehicle Re-identification (ReID) is\nsignificantly degraded when some important discriminative cues in visible, near\ninfrared and thermal infrared spectra are lost. Existing methods generate or\nenhance missing details in low-quality spectra data using the high-quality one,\ngenerally called the primary spectrum, but how to justify the primary spectrum\nis a challenging problem. In addition, when the quality of the primary spectrum\nis low, the enhancement effect would be greatly degraded, thus limiting the\nperformance of multi-spectral vehicle ReID. To address these problems, we\npropose the Collaborative Enhancement Network (CoEN), which generates a\nhigh-quality proxy from all spectra data and leverages it to supervise the\nselection of primary spectrum and enhance all spectra features in a\ncollaborative manner, for robust multi-spectral vehicle ReID. First, to\nintegrate the rich cues from all spectra data, we design the Proxy Generator\n(PG) to progressively aggregate multi-spectral features. Second, we design the\nDynamic Quality Sort Module (DQSM), which sorts all spectra data by measuring\ntheir correlations with the proxy, to accurately select the primary spectra\nwith the highest correlation. Finally, we design the Collaborative Enhancement\nModule (CEM) to effectively compensate for missing contents of all spectra by\ncollaborating the primary spectra and the proxy, thereby mitigating the impact\nof low-quality primary spectra. Extensive experiments on three benchmark\ndatasets are conducted to validate the efficacy of the proposed approach\nagainst other multi-spectral vehicle ReID methods. The codes will be released\nat https://github.com/yongqisun/CoEN.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T06:07:32Z"}
{"aid":"http://arxiv.org/abs/2504.14909v1","title":"A Novel FFA-Based Storage Ring Design with an Internal Target for\n  Heavy-Ion Beams Undergoing Stochastic Charge State Conversions","summary":"A heavy-ion storage ring with an energy recovery internal target(ERIT) is\nsuitable for rare production reactions. The most onerous obstacle to the stable\noperation of this ring is a phenomenon of stochastic charge state\nconversions(SCSC) of the ions in the beam caused by the collision with the\ntarget. This phenomenon causes a rapid increase in the beam emittance. To solve\nthis problem, we have developed a method to match the closed orbits and beta\nfunctions of the beams in different charge states at the production target\nlocation in the scaling FFA ring. In this paper, we show through 6D beam\ntracking simulations that the FFA ring with modulated $k$ suppresses the\nemittance growth even in the presence of SCSC, and it can accumulate the beam\nover 600 turns effectively.","main_category":"physics.acc-ph","categories":"physics.acc-ph,nucl-ex","published":"2025-04-21T07:27:27Z"}
{"aid":"http://arxiv.org/abs/2504.14918v1","title":"Monopoles at Future Neutrino Detectors","summary":"We investigate the potential of future neutrino experiments, DUNE and\nHyper-Kamiokande, to probe magnetic monopoles via Callan-Rubakov (CR)\nprocesses. We consider both relativistic and non-relativistic monopoles and\nfocus on two primary detection signatures: high-energy antiproton production\nand proton decay catalysis. For relativistic monopoles, our analysis of the CR\nprocess indicates antiproton production with energies near 900 GeV and we find\nthat both experiments can provide limits on the fluxes an order of magnitude\nbelow the Parker bound (approximately $\\Phi \\lesssim\n10^{-16}\\,\\mathrm{cm^{-2}\\,s^{-1}\\,sr^{-1}}$). For non-relativistic monopoles,\nwe recast the experimental sensitivity to proton decay catalysis and obtain\nupper limits on the monopole flux of $\\Phi \\lesssim 2.3 \\times\n10^{-23}\\,\\mathrm{cm^{-2}\\,s^{-1}\\,sr^{-1}}$ for Hyper-Kamiokande and $\\Phi\n\\lesssim 1.1 \\times 10^{-22}\\,\\mathrm{cm^{-2}\\,s^{-1}\\,sr^{-1}}$ for DUNE.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-21T07:35:35Z"}
{"aid":"http://arxiv.org/abs/2504.14928v1","title":"EducationQ: Evaluating LLMs' Teaching Capabilities Through Multi-Agent\n  Dialogue Framework","summary":"Large language models (LLMs) increasingly serve as educational tools, yet\nevaluating their teaching capabilities remains challenging due to the\nresource-intensive, context-dependent, and methodologically complex nature of\nteacher-student interactions. We introduce EducationQ, a multi-agent dialogue\nframework that efficiently assesses teaching capabilities through simulated\ndynamic educational scenarios, featuring specialized agents for teaching,\nlearning, and evaluation. Testing 14 LLMs across major AI Organizations\n(OpenAI, Meta, Google, Anthropic, and others) on 1,498 questions spanning 13\ndisciplines and 10 difficulty levels reveals that teaching effectiveness does\nnot correlate linearly with model scale or general reasoning capabilities -\nwith some smaller open-source models outperforming larger commercial\ncounterparts in teaching contexts. This finding highlights a critical gap in\ncurrent evaluations that prioritize knowledge recall over interactive pedagogy.\nOur mixed-methods evaluation, combining quantitative metrics with qualitative\nanalysis and expert case studies, identifies distinct pedagogical strengths\nemployed by top-performing models (e.g., sophisticated questioning strategies,\nadaptive feedback mechanisms). Human expert evaluations show 78% agreement with\nour automated qualitative analysis of effective teaching behaviors, validating\nour methodology. EducationQ demonstrates that LLMs-as-teachers require\nspecialized optimization beyond simple scaling, suggesting next-generation\neducational AI prioritize targeted enhancement of specific pedagogical\neffectiveness.","main_category":"cs.AI","categories":"cs.AI,cs.CE,cs.CL,cs.CY,cs.HC","published":"2025-04-21T07:48:20Z"}
{"aid":"http://arxiv.org/abs/2504.14934v1","title":"On negative eigenvalues of 1D Schr√∂dinger operators with\n  $Œ¥'$-like potentials","summary":"We study the asymptotic behavior of the discrete spectrum of one-dimensional\nSchr\\\"odinger operators with $\\delta'$-like potentials, which are used to\nconstruct exactly solvable models for localized dipoles in quantum mechanics.\nAlthough these operators converge in the norm resolvent topology to a limiting\noperator that is bounded from below, we prove that they can possess a finite\nbut arbitrarily large number of discrete eigenvalues that diverge to negative\ninfinity as the regularization parameter tends to zero. This phenomenon\nillustrates a spectral instability of Schr\\\"odinger operators with these\nsingular potentials.","main_category":"math.SP","categories":"math.SP,math-ph,math.MP","published":"2025-04-21T07:54:05Z"}
{"aid":"http://arxiv.org/abs/2504.14969v1","title":"Evaluating LLMs on Chinese Topic Constructions: A Research Proposal\n  Inspired by Tian et al. (2024)","summary":"This paper proposes a framework for evaluating large language models (LLMs)\non Chinese topic constructions, focusing on their sensitivity to island\nconstraints. Drawing inspiration from Tian et al. (2024), we outline an\nexperimental design for testing LLMs' grammatical knowledge of Mandarin syntax.\nWhile no experiments have been conducted yet, this proposal aims to provide a\nfoundation for future studies and invites feedback on the methodology.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-21T08:56:23Z"}
{"aid":"http://arxiv.org/abs/2504.15007v1","title":"Shifts in Doctors' Eye Movements Between Real and AI-Generated Medical\n  Images","summary":"Eye-tracking analysis plays a vital role in medical imaging, providing key\ninsights into how radiologists visually interpret and diagnose clinical cases.\nIn this work, we first analyze radiologists' attention and agreement by\nmeasuring the distribution of various eye-movement patterns, including saccades\ndirection, amplitude, and their joint distribution. These metrics help uncover\npatterns in attention allocation and diagnostic strategies. Furthermore, we\ninvestigate whether and how doctors' gaze behavior shifts when viewing\nauthentic (Real) versus deep-learning-generated (Fake) images. To achieve this,\nwe examine fixation bias maps, focusing on first, last, short, and longest\nfixations independently, along with detailed saccades patterns, to quantify\ndifferences in gaze distribution and visual saliency between authentic and\nsynthetic images.","main_category":"cs.CV","categories":"cs.CV,cs.HC","published":"2025-04-21T10:13:59Z"}
{"aid":"http://arxiv.org/abs/2504.15029v1","title":"Story of an architecturally suggestive polyhedron: from medieval trade\n  to Renaissance art and modern design","summary":"We describe a balance weight dated to the Early Islamic Period from the Hecht\nMuseum at the University of Haifa (Israel) Its polyhedral shape was attributed\nto a truncated elongated octagonal bipyramid. To our knowledge, the earliest\nRenaissance book containing the image of this polyhedron is \"La Pratica di\nProspettiva\" published in 1596 by Florentine architect and perspective artist\nLorenzo Sirigatti. We described an outline of Sirigatti life and the importance\nof his book for scientists and artists, Galileo Galilei among them. We depict\nexamples of lamps and lanterns in European cities shaped as the truncated\nelongated octagonal bipyramid, as well as a drawing by Raphael with a lantern\nof a similar form. Finally, we discussed why the artist chose this particular\npolyhedron for his drawing.","main_category":"math.HO","categories":"math.HO","published":"2025-04-21T11:33:41Z"}
{"aid":"http://arxiv.org/abs/2504.15072v1","title":"Rhythm of Opinion: A Hawkes-Graph Framework for Dynamic Propagation\n  Analysis","summary":"The rapid development of social media has significantly reshaped the dynamics\nof public opinion, resulting in complex interactions that traditional models\nfail to effectively capture. To address this challenge, we propose an\ninnovative approach that integrates multi-dimensional Hawkes processes with\nGraph Neural Network, modeling opinion propagation dynamics among nodes in a\nsocial network while considering the intricate hierarchical relationships\nbetween comments. The extended multi-dimensional Hawkes process captures the\nhierarchical structure, multi-dimensional interactions, and mutual influences\nacross different topics, forming a complex propagation network. Moreover,\nrecognizing the lack of high-quality datasets capable of comprehensively\ncapturing the evolution of public opinion dynamics, we introduce a new dataset,\nVISTA. It includes 159 trending topics, corresponding to 47,207 posts, 327,015\nsecond-level comments, and 29,578 third-level comments, covering diverse\ndomains such as politics, entertainment, sports, health, and medicine. The\ndataset is annotated with detailed sentiment labels across 11 categories and\nclearly defined hierarchical relationships. When combined with our method, it\noffers strong interpretability by linking sentiment propagation to the comment\nhierarchy and temporal evolution. Our approach provides a robust baseline for\nfuture research.","main_category":"cs.SI","categories":"cs.SI,cs.CL","published":"2025-04-21T13:02:30Z"}
{"aid":"http://arxiv.org/abs/2504.15109v1","title":"New Heintze-Karcher type inequalities in sub-static warped product\n  manifolds","summary":"In this paper, we prove Heintze-Karcher type inequalities involving the\nshifted mean curvature for smooth bounded domains in certain sub-static warped\nproduct manifolds. In particular, we prove a Heintze-Karcher-type inequality\nfor non mean-convex domains in the hyperbolic space. As applications, we obtain\nuniqueness results for hypersurfaces satisfying a class of curvature equations.","main_category":"math.DG","categories":"math.DG","published":"2025-04-21T14:02:09Z"}
{"aid":"http://arxiv.org/abs/2504.15132v1","title":"Investigating Youth's Technical and Ethical Understanding of Generative\n  Language Models When Engaging in Construction and Deconstruction Activities","summary":"The widespread adoption of generative artificial intelligence/machine\nlearning (AI/ML) technologies has increased the need to support youth in\ndeveloping AI/ML literacies. However, most work has centered on preparing young\npeople to use these systems, with less attention to how they can participate in\ndesigning and evaluating them. This study investigates how engaging young\npeople in the design and auditing of generative language models (GLMs) may\nfoster the development of their understanding of how these systems work from\nboth technical and ethical perspectives. The study takes an in-pieces approach\nto investigate novices' conceptions of GLMs. Such an approach supports the\nanalysis of how technical and ethical conceptions evolve and relate to each\nother. I am currently conducting a series of participatory design workshops\nwith sixteen ninth graders (ages 14-15) in which they will (a) build GLMs from\na data-driven perspective that glassboxes how data shapes model performance and\n(b) audit commercial GLMs by repeatedly and systematically querying them to\ndraw inferences about their behaviors. I will analyze participants'\ninteractions to identify ethical and technical conceptions they may exhibit\nwhile designing and auditing GLMs. I will also conduct clinical interviews and\nuse microgenetic knowledge analysis and ordered network analysis to investigate\nhow participants' ethical and technical conceptions of GLMs relate to each\nother and change after the workshop. The study will contribute (a) evidence of\nhow engaging youth in design and auditing activities may support the\ndevelopment of ethical and technical understanding of GLMs and (b) an inventory\nof novice design and auditing practices that may support youth's technical and\nethical understanding of GLMs.","main_category":"cs.HC","categories":"cs.HC,cs.CY","published":"2025-04-21T14:30:16Z"}
{"aid":"http://arxiv.org/abs/2504.15163v1","title":"Survey of Loss Augmented Knowledge Tracing","summary":"The training of artificial neural networks is heavily dependent on the\ncareful selection of an appropriate loss function. While commonly used loss\nfunctions, such as cross-entropy and mean squared error (MSE), generally\nsuffice for a broad range of tasks, challenges often emerge due to limitations\nin data quality or inefficiencies within the learning process. In such\ncircumstances, the integration of supplementary terms into the loss function\ncan serve to address these challenges, enhancing both model performance and\nrobustness. Two prominent techniques, loss regularization and contrastive\nlearning, have been identified as effective strategies for augmenting the\ncapacity of loss functions in artificial neural networks.\n  Knowledge tracing is a compelling area of research that leverages predictive\nartificial intelligence to facilitate the automation of personalized and\nefficient educational experiences for students. In this paper, we provide a\ncomprehensive review of the deep learning-based knowledge tracing (DKT)\nalgorithms trained using advanced loss functions and discuss their improvements\nover prior techniques. We discuss contrastive knowledge tracing algorithms,\nsuch as Bi-CLKT, CL4KT, SP-CLKT, CoSKT, and prediction-consistent DKT,\nproviding performance benchmarks and insights into real-world deployment\nchallenges. The survey concludes with future research directions, including\nhybrid loss strategies and context-aware modeling.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-21T15:09:40Z"}
{"aid":"http://arxiv.org/abs/2504.15166v1","title":"Simulating biochemical reactions: The Linear Noise Approximation can\n  capture non-linear dynamics","summary":"There is a plethora of highly stochastic non-linear dynamical systems in\nfields such as molecular biology, chemistry, epidemiology, and ecology. Yet,\nnone of the currently available stochastic models are both accurate and\ncomputationally efficient for long-term predictions of large systems. The\nLinear Noise Approximation (LNA) model for biochemical reaction networks is\nanalytically tractable, which makes it computationally efficient for\nsimulation, analysis, and inference. However, it is only accurate for linear\nsystems and short-time transitions. Other methods can achieve greater accuracy\nacross a wider range of systems, including non-linear ones, but lack analytical\ntractability. This paper seeks to challenge the prevailing view by\ndemonstrating that the Linear Noise Approximation can indeed capture non-linear\ndynamics after certain modifications. We introduce a new framework that\nutilises centre manifold theory allowing us to identify simple interventions to\nthe LNA that do not significantly compromise its computational efficiency. We\ndevelop specific algorithms for systems that exhibit oscillations or\nbi-stability and demonstrate their accuracy and computational efficiency across\nmultiple examples.","main_category":"q-bio.QM","categories":"q-bio.QM,math.PR,physics.chem-ph,q-bio.MN","published":"2025-04-21T15:16:30Z"}
{"aid":"http://arxiv.org/abs/2504.15206v1","title":"How Global Calibration Strengthens Multiaccuracy","summary":"Multiaccuracy and multicalibration are multigroup fairness notions for\nprediction that have found numerous applications in learning and computational\ncomplexity. They can be achieved from a single learning primitive: weak\nagnostic learning. Here we investigate the power of multiaccuracy as a learning\nprimitive, both with and without the additional assumption of calibration. We\nfind that multiaccuracy in itself is rather weak, but that the addition of\nglobal calibration (this notion is called calibrated multiaccuracy) boosts its\npower substantially, enough to recover implications that were previously known\nonly assuming the stronger notion of multicalibration.\n  We give evidence that multiaccuracy might not be as powerful as standard weak\nagnostic learning, by showing that there is no way to post-process a\nmultiaccurate predictor to get a weak learner, even assuming the best\nhypothesis has correlation $1/2$. Rather, we show that it yields a restricted\nform of weak agnostic learning, which requires some concept in the class to\nhave correlation greater than $1/2$ with the labels. However, by also requiring\nthe predictor to be calibrated, we recover not just weak, but strong agnostic\nlearning.\n  A similar picture emerges when we consider the derivation of hardcore\nmeasures from predictors satisfying multigroup fairness notions. On the one\nhand, while multiaccuracy only yields hardcore measures of density half the\noptimal, we show that (a weighted version of) calibrated multiaccuracy achieves\noptimal density.\n  Our results yield new insights into the complementary roles played by\nmultiaccuracy and calibration in each setting. They shed light on why\nmultiaccuracy and global calibration, although not particularly powerful by\nthemselves, together yield considerably stronger notions.","main_category":"cs.LG","categories":"cs.LG,cs.CC","published":"2025-04-21T16:22:44Z"}
{"aid":"http://arxiv.org/abs/2504.15211v1","title":"Position: Bayesian Statistics Facilitates Stakeholder Participation in\n  Evaluation of Generative AI","summary":"The evaluation of Generative AI (GenAI) systems plays a critical role in\npublic policy and decision-making, yet existing methods are often limited by\nreliance on benchmark-driven, point-estimate comparisons that fail to capture\nuncertainty and broader societal impacts. This paper argues for the use of\nBayesian statistics as a principled framework to address these challenges.\nBayesian methods enable the integration of domain expertise through prior\nelicitation, allow for continuous learning from new data, and provide robust\nuncertainty quantification via posterior inference. We demonstrate how Bayesian\ninference can be applied to GenAI evaluation, particularly in incorporating\nstakeholder perspectives to enhance fairness, transparency, and reliability.\nFurthermore, we discuss Bayesian workflows as an iterative process for model\nvalidation and refinement, ensuring robust assessments of GenAI systems in\ndynamic, real-world contexts.","main_category":"cs.AI","categories":"cs.AI,stat.AP","published":"2025-04-21T16:31:15Z"}
{"aid":"http://arxiv.org/abs/2504.15234v1","title":"Equivariant quasisymmetry and noncrossing partitions","summary":"We introduce a definition of ``equivariant quasisymmetry'' for polynomials in\ntwo sets of variables. Using this definition we define quasisymmetric\ngeneralizations of the theory of double Schur and double Schubert polynomials\nthat we call double fundamental polynomials and double forest polynomials,\nwhere the subset of ``noncrossing partitions'' plays the role of $S_n$. In\nsubsequent work we will show this combinatorics is governed by a new geometric\nconstruction we call the ``quasisymmetric flag variety'' which plays the same\nrole for equivariant quasisymmetry as the usual flag variety plays in the\nclassical story.","main_category":"math.CO","categories":"math.CO,math.AG","published":"2025-04-21T17:09:52Z"}
{"aid":"http://arxiv.org/abs/2504.15260v1","title":"Joint Knowledge and Power Management for Secure Semantic Communication\n  Networks","summary":"Recently, semantic communication (SemCom) has shown its great superiorities\nin resource savings and information exchanges. However, while its unique\nbackground knowledge guarantees accurate semantic reasoning and recovery,\nsemantic information security-related concerns are introduced at the same time.\nSince the potential eavesdroppers may have the same background knowledge to\naccurately decrypt the private semantic information transmitted between legal\nSemCom users, this makes the knowledge management in SemCom networks rather\nchallenging in joint consideration with the power control. To this end, this\npaper focuses on jointly addressing three core issues of power allocation,\nknowledge base caching (KBC), and device-to-device (D2D) user pairing (DUP) in\nsecure SemCom networks. We first develop a novel performance metric, namely\nsemantic secrecy throughput (SST), to quantify the information security level\nthat can be achieved at each pair of D2D SemCom users. Next, an SST\nmaximization problem is formulated subject to secure SemCom-related delay and\nreliability constraints. Afterward, we propose a security-aware resource\nmanagement solution using the Lagrange primal-dual method and a two-stage\nmethod. Simulation results demonstrate our proposed solution nearly doubles the\nSST performance and realizes less than half of the queuing delay performance\ncompared to different benchmarks.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-21T17:39:59Z"}
{"aid":"http://arxiv.org/abs/2504.15264v1","title":"Sunflowers and Ramsey problems for restricted intersections","summary":"Extremal problems on set systems with restricted intersections have been an\nimportant part of combinatorics in the last 70 year. In this paper, we study\nthe following Ramsey version of these problems. Given a set $L\\subseteq\n\\{0,\\dots,k-1\\}$ and a family $\\mathcal{F}$ of $k$-element sets which does not\ncontain a sunflower with $m$ petals whose kernel size is in $L$, how large a\nsubfamily of $\\mathcal{F}$ can we find in which no pair has intersection size\nin $L$? We give matching upper and lower bounds, determining the dependence on\n$m$ for all $k$ and $L$. This problem also finds applications in quantum\ncomputing.\n  As an application of our techniques, we also obtain a variant of F\\\"uredi's\ncelebrated semilattice lemma, which is a key tool in the powerful delta-system\nmethod. We prove that one cannot remove the double-exponential dependency on\nthe uniformity in F\\\"uredi's result, however, we provide an alternative with\nsignificantly better, single-exponential dependency on the parameters, which is\nstill strong enough for most applications of the delta-system method.","main_category":"math.CO","categories":"math.CO,cs.DM,quant-ph","published":"2025-04-21T17:46:21Z"}
{"aid":"http://arxiv.org/abs/2504.15593v1","title":"Inverse Drexhage effect in Epsilon-Near-Zero Substrates","summary":"The Drexhage effect, caused by interference between a dipole and its image\nformed in a substrate, modifies the local density of optical states of quantum\nemitters which can either enhance or suppress their spontaneous emission rate\ndepending on the dipole orientation and distance from the substrate. Here, we\nshow that for an epsilon-near-zero (ENZ) substrate, the observed orientation\nand distance dependence of the spontaneous emission rate is reversed compared\nto metals. This inverse Drexhage effect is studied for ideal ENZ and real ENZ\nsubstrates compared with ideal and real metallic substrates. ENZ metamaterials\nconsisting of a subwavelength metal-dielectric stack are shown to exhibit the\nconventional Drexhage effects due to the large optical losses associated with\nthese materials. Our results could find applications in quantum sensing,\nquantum information, and energy-efficient optoelectronic devices.","main_category":"physics.optics","categories":"physics.optics,quant-ph","published":"2025-04-22T05:14:05Z"}
{"aid":"http://arxiv.org/abs/2504.15594v1","title":"Analytical Softmax Temperature Setting from Feature Dimensions for\n  Model- and Domain-Robust Classification","summary":"In deep learning-based classification tasks, the softmax function's\ntemperature parameter $T$ critically influences the output distribution and\noverall performance. This study presents a novel theoretical insight that the\noptimal temperature $T^*$ is uniquely determined by the dimensionality of the\nfeature representations, thereby enabling training-free determination of $T^*$.\nDespite this theoretical grounding, empirical evidence reveals that $T^*$\nfluctuates under practical conditions owing to variations in models, datasets,\nand other confounding factors. To address these influences, we propose and\noptimize a set of temperature determination coefficients that specify how $T^*$\nshould be adjusted based on the theoretical relationship to feature\ndimensionality. Additionally, we insert a batch normalization layer immediately\nbefore the output layer, effectively stabilizing the feature space. Building on\nthese coefficients and a suite of large-scale experiments, we develop an\nempirical formula to estimate $T^*$ without additional training while also\nintroducing a corrective scheme to refine $T^*$ based on the number of classes\nand task complexity. Our findings confirm that the derived temperature not only\naligns with the proposed theoretical perspective but also generalizes\neffectively across diverse tasks, consistently enhancing classification\nperformance and offering a practical, training-free solution for determining\n$T^*$.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-22T05:14:38Z"}
{"aid":"http://arxiv.org/abs/2504.15625v1","title":"Comprehensive List Generation for Multi-Generator Reranking","summary":"Reranking models solve the final recommendation lists that best fulfill\nusers' demands. While existing solutions focus on finding parametric models\nthat approximate optimal policies, recent approaches find that it is better to\ngenerate multiple lists to compete for a ``pass'' ticket from an evaluator,\nwhere the evaluator serves as the supervisor who accurately estimates the\nperformance of the candidate lists. In this work, we show that we can achieve a\nmore efficient and effective list proposal with a multi-generator framework and\nprovide empirical evidence on two public datasets and online A/B tests. More\nimportantly, we verify that the effectiveness of a generator is closely related\nto how much it complements the views of other generators with sufficiently\ndifferent rerankings, which derives the metric of list comprehensiveness. With\nthis intuition, we design an automatic complementary generator-finding\nframework that learns a policy that simultaneously aligns the users'\npreferences and maximizes the list comprehensiveness metric. The experimental\nresults indicate that the proposed framework can further improve the\nmulti-generator reranking performance.","main_category":"cs.IR","categories":"cs.IR,H.3.3","published":"2025-04-22T06:34:57Z"}
{"aid":"http://arxiv.org/abs/2504.15639v1","title":"A remark for characterizing blowup introduced by Giga and Kohn","summary":"Giga and Kohn studied the blowup solutions for the equation $v_{t} - \\Delta v\n- |v|^{p - 1} v = 0 $ and characterized the asymptotic behavior of $v$ near a\nsingularity. In the proof, they reduced the problem to a Liouville theorem for\nthe equation $\\Delta u - \\frac{1}{2} x \\cdot \\nabla u + |u|^{p - 1} u - \\beta u\n= 0$ where $\\beta = \\frac{1}{p - 1}$ and $|u|$ is bounded. This article is a\nremark for their work and we will show when $u \\geq 0$, the boundedness\ncondition for $|u|$ can be removed.","main_category":"math.AP","categories":"math.AP","published":"2025-04-22T06:57:02Z"}
{"aid":"http://arxiv.org/abs/2504.15707v1","title":"RePOPE: Impact of Annotation Errors on the POPE Benchmark","summary":"Since data annotation is costly, benchmark datasets often incorporate labels\nfrom established image datasets. In this work, we assess the impact of label\nerrors in MSCOCO on the frequently used object hallucination benchmark POPE. We\nre-annotate the benchmark images and identify an imbalance in annotation errors\nacross different subsets. Evaluating multiple models on the revised labels,\nwhich we denote as RePOPE, we observe notable shifts in model rankings,\nhighlighting the impact of label quality. Code and data are available at\nhttps://github.com/YanNeu/RePOPE .","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-22T08:47:59Z"}
{"aid":"http://arxiv.org/abs/2504.15723v1","title":"Structure-Preserving Zero-Shot Image Editing via Stage-Wise Latent\n  Injection in Diffusion Models","summary":"We propose a diffusion-based framework for zero-shot image editing that\nunifies text-guided and reference-guided approaches without requiring\nfine-tuning. Our method leverages diffusion inversion and timestep-specific\nnull-text embeddings to preserve the structural integrity of the source image.\nBy introducing a stage-wise latent injection strategy-shape injection in early\nsteps and attribute injection in later steps-we enable precise, fine-grained\nmodifications while maintaining global consistency. Cross-attention with\nreference latents facilitates semantic alignment between the source and\nreference. Extensive experiments across expression transfer, texture\ntransformation, and style infusion demonstrate state-of-the-art performance,\nconfirming the method's scalability and adaptability to diverse image editing\nscenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T09:18:16Z"}
{"aid":"http://arxiv.org/abs/2504.15732v1","title":"Integral Artin motives II: Perverse motives and Artin Vanishing Theorem","summary":"In this text, we are mainly interested in the existence of the perverse\nmotivic t-structures on the category of Artin \\'etale motives with integral\ncoefficients. We construct the perverse homotopy t-structure which is the best\npossible approximation to a perverse t-structure on Artin motives with rational\ncoefficients. The heart of this t-structure has properties similar to those of\nthe category of perverse sheaves and contains the Ayoub-Zucker motive. With\nintegral coefficients, we construct the perverse motivic t-structure on Artin\nmotives when the base scheme is of dimension at most $2$ and show that it\ncannot exist in dimension $4$. This construction relies notably on a an\nanalogue for Artin motives of the Artin Vanishing Theorem.","main_category":"math.AG","categories":"math.AG","published":"2025-04-22T09:25:27Z"}
{"aid":"http://arxiv.org/abs/2504.15740v1","title":"CaRoSaC: A Reinforcement Learning-Based Kinematic Control of\n  Cable-Driven Parallel Robots by Addressing Cable Sag through Simulation","summary":"This paper introduces the Cable Robot Simulation and Control (CaRoSaC)\nFramework, which integrates a simulation environment with a model-free\nreinforcement learning control methodology for suspended Cable-Driven Parallel\nRobots (CDPRs), accounting for cable sag. Our approach seeks to bridge the\nknowledge gap of the intricacies of CDPRs due to aspects such as cable sag and\nprecision control necessities by establishing a simulation platform that\ncaptures the real-world behaviors of CDPRs, including the impacts of cable sag.\nThe framework offers researchers and developers a tool to further develop\nestimation and control strategies within the simulation for understanding and\npredicting the performance nuances, especially in complex operations where\ncable sag can be significant. Using this simulation framework, we train a\nmodel-free control policy in Reinforcement Learning (RL). This approach is\nchosen for its capability to adaptively learn from the complex dynamics of\nCDPRs. The policy is trained to discern optimal cable control inputs, ensuring\nprecise end-effector positioning. Unlike traditional feedback-based control\nmethods, our RL control policy focuses on kinematic control and addresses the\ncable sag issues without being tethered to predefined mathematical models. We\nalso demonstrate that our RL-based controller, coupled with the flexible cable\nsimulation, significantly outperforms the classical kinematics approach,\nparticularly in dynamic conditions and near the boundary regions of the\nworkspace. The combined strength of the described simulation and control\napproach offers an effective solution in manipulating suspended CDPRs even at\nworkspace boundary conditions where traditional approach fails, as proven from\nour experiments, ensuring that CDPRs function optimally in various applications\nwhile accounting for the often neglected but critical factor of cable sag.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-22T09:45:06Z"}
{"aid":"http://arxiv.org/abs/2504.15742v1","title":"Proving Cypher Query Equivalence","summary":"Graph database systems store graph data as nodes and relationships, and\nutilize graph query languages (e.g., Cypher) for efficiently querying graph\ndata. Proving the equivalence of graph queries is an important foundation for\noptimizing graph query performance, ensuring graph query reliability, etc.\nAlthough researchers have proposed many SQL query equivalence provers for\nrelational database systems, these provers cannot be directly applied to prove\nthe equivalence of graph queries. The difficulty lies in the fact that graph\nquery languages (e.g., Cypher) adopt significantly different data models\n(property graph model vs. relational model) and query patterns (graph pattern\nmatching vs. tabular tuple calculus) from SQL.\n  In this paper, we propose GraphQE, an automated prover to determine whether\ntwo Cypher queries are semantically equivalent. We design a U-semiring based\nCypher algebraic representation to model the semantics of Cypher queries. Our\nCypher algebraic representation is built on the algebraic structure of\nunbounded semirings, and can sufficiently express nodes and relationships in\nproperty graphs and complex Cypher queries. Then, determining the equivalence\nof two Cypher queries is transformed into determining the equivalence of the\ncorresponding Cypher algebraic representations, which can be verified by SMT\nsolvers. To evaluate the effectiveness of GraphQE, we construct a dataset\nconsisting of 148 pairs of equivalent Cypher queries. Among them, we have\nsuccessfully proven 138 pairs of equivalent Cypher queries, demonstrating the\neffectiveness of GraphQE.","main_category":"cs.DB","categories":"cs.DB,cs.SE","published":"2025-04-22T09:45:37Z"}
{"aid":"http://arxiv.org/abs/2504.15753v1","title":"Markov Kernels, Distances and Optimal Control: A Parable of Linear\n  Quadratic Non-Gaussian Distribution Steering","summary":"For a controllable linear time-varying (LTV) pair\n$(\\boldsymbol{A}_t,\\boldsymbol{B}_t)$ and $\\boldsymbol{Q}_{t}$ positive\nsemidefinite, we derive the Markov kernel for the It\\^{o} diffusion\n${\\mathrm{d}}\\boldsymbol{x}_{t}=\\boldsymbol{A}_{t}\\boldsymbol{x}_t {\\mathrm{d}}\nt + \\sqrt{2}\\boldsymbol{B}_{t}{\\mathrm{d}}\\boldsymbol{w}_{t}$ with an\naccompanying killing of probability mass at rate\n$\\frac{1}{2}\\boldsymbol{x}^{\\top}\\boldsymbol{Q}_{t}\\boldsymbol{x}$. This Markov\nkernel is the Green's function for an associated linear\nreaction-advection-diffusion partial differential equation. Our result\ngeneralizes the recently derived kernel for the special case\n$\\left(\\boldsymbol{A}_t,\\boldsymbol{B}_t\\right)=\\left(\\boldsymbol{0},\\boldsymbol{I}\\right)$,\nand depends on the solution of an associated Riccati matrix ODE. A consequence\nof this result is that the linear quadratic non-Gaussian Schr\\\"{o}dinger bridge\nis exactly solvable. This means that the problem of steering a controlled LTV\ndiffusion from a given non-Gaussian distribution to another over a fixed\ndeadline while minimizing an expected quadratic cost can be solved using\ndynamic Sinkhorn recursions performed with the derived kernel. Our derivation\nfor the\n$\\left(\\boldsymbol{A}_t,\\boldsymbol{B}_t,\\boldsymbol{Q}_t\\right)$-parametrized\nkernel pursues a new idea that relies on finding a state-time dependent\ndistance-like functional given by the solution of a deterministic optimal\ncontrol problem. This technique breaks away from existing methods, such as\ngeneralizing Hermite polynomials or Weyl calculus, which have seen limited\nsuccess in the reaction-diffusion context. Our technique uncovers a new\nconnection between Markov kernels, distances, and optimal control. This\nconnection is of interest beyond its immediate application in solving the\nlinear quadratic Schr\\\"{o}dinger bridge problem.","main_category":"math.OC","categories":"math.OC,cs.LG,cs.SY,eess.SY,math.PR,math.ST,stat.TH","published":"2025-04-22T10:07:43Z"}
{"aid":"http://arxiv.org/abs/2504.15756v1","title":"DSDNet: Raw Domain Demoir√©ing via Dual Color-Space Synergy","summary":"With the rapid advancement of mobile imaging, capturing screens using\nsmartphones has become a prevalent practice in distance learning and conference\nrecording. However, moir\\'e artifacts, caused by frequency aliasing between\ndisplay screens and camera sensors, are further amplified by the image signal\nprocessing pipeline, leading to severe visual degradation. Existing sRGB domain\ndemoir\\'eing methods struggle with irreversible information loss, while recent\ntwo-stage raw domain approaches suffer from information bottlenecks and\ninference inefficiency. To address these limitations, we propose a single-stage\nraw domain demoir\\'eing framework, Dual-Stream Demoir\\'eing Network (DSDNet),\nwhich leverages the synergy of raw and YCbCr images to remove moir\\'e while\npreserving luminance and color fidelity. Specifically, to guide luminance\ncorrection and moir\\'e removal, we design a raw-to-YCbCr mapping pipeline and\nintroduce the Synergic Attention with Dynamic Modulation (SADM) module. This\nmodule enriches the raw-to-sRGB conversion with cross-domain contextual\nfeatures. Furthermore, to better guide color fidelity, we develop a\nLuminance-Chrominance Adaptive Transformer (LCAT), which decouples luminance\nand chrominance representations. Extensive experiments demonstrate that DSDNet\noutperforms state-of-the-art methods in both visual quality and quantitative\nevaluation, and achieves an inference speed $\\mathrm{\\textbf{2.4x}}$ faster\nthan the second-best method, highlighting its practical advantages. We provide\nan anonymous online demo at https://xxxxxxxxdsdnet.github.io/DSDNet/.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-22T10:09:33Z"}
{"aid":"http://arxiv.org/abs/2504.15758v1","title":"Observability conditions for neural state-space models with eigenvalues\n  and their roots of unity","summary":"We operate through the lens of ordinary differential equations and control\ntheory to study the concept of observability in the context of neural\nstate-space models and the Mamba architecture. We develop strategies to enforce\nobservability, which are tailored to a learning context, specifically where the\nhidden states are learnable at initial time, in conjunction to over its\ncontinuum, and high-dimensional. We also highlight our methods emphasize\neigenvalues, roots of unity, or both. Our methods effectuate computational\nefficiency when enforcing observability, sometimes at great scale. We formulate\nobservability conditions in machine learning based on classical control theory\nand discuss their computational complexity. Our nontrivial results are\nfivefold. We discuss observability through the use of permutations in neural\napplications with learnable matrices without high precision. We present two\nresults built upon the Fourier transform that effect observability with high\nprobability up to the randomness in the learning. These results are worked with\nthe interplay of representations in Fourier space and their eigenstructure,\nnonlinear mappings, and the observability matrix. We present a result for Mamba\nthat is similar to a Hautus-type condition, but instead employs an argument\nusing a Vandermonde matrix instead of eigenvectors. Our final result is a\nshared-parameter construction of the Mamba system, which is computationally\nefficient in high exponentiation. We develop a training algorithm with this\ncoupling, showing it satisfies a Robbins-Monro condition under certain\northogonality, while a more classical training procedure fails to satisfy a\ncontraction with high Lipschitz constant.","main_category":"cs.LG","categories":"cs.LG,cs.SY,eess.SY,math.DS,math.OC","published":"2025-04-22T10:10:52Z"}
{"aid":"http://arxiv.org/abs/2504.15778v1","title":"A Stochastic Lattice Model for Convective Self-aggregation Incorporating\n  Longwave Radiative Effect","summary":"Self-aggregation of tropical convection is a universal feature observed in a\ndiverse range of atmospheric environments. Several preceding models\nconceptualized the self-aggregation of convection as a phase transition driven\nby collisions between cold pool gust fronts. However, self-aggregation may also\nbe influenced by various physical processes, such as surface fluxes, radiation,\nand moisture perturbations in the planetary boundary layer, and it remains\nunclear which process plays a dominant role. In this study, we develop a simple\nstochastic lattice model for the pattern formation of deep convection, inspired\nby the two-dimensional Ising model. Here, in addition to the process of cold\npool collisions, which have an effect of triggering new convection, we\nincorporate the process of clear-sky radiative cooling that has an effect of\nsuppressing deep convection as an interaction between clouds. Our results show\nthat by amplifying the intensity of the clear-sky radiative cooling effect, the\ntransition from a quasi-uniform to an inhomogeneous cloud field can be\nreproduced. The model also successfully explains the dependence of\nself-aggregation on several model parameters, such as the experimental domain\nsize and the characteristic size of cold pools. Furthermore, by varying the\ndistance over which the subsidence induced by radiative cooling extends, we\nsucceed in capturing a pattern formation that closely resembles the convective\nclusters observed in the real atmosphere and three-dimensional numerical model\nsimulations.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-22T10:38:33Z"}
{"aid":"http://arxiv.org/abs/2504.15782v1","title":"Model-based Metric 3D Shape and Motion Reconstruction of Wild Bottlenose\n  Dolphins in Drone-Shot Videos","summary":"We address the problem of estimating the metric 3D shape and motion of wild\ndolphins from monocular video, with the aim of assessing their body condition.\nWhile considerable progress has been made in reconstructing 3D models of\nterrestrial quadrupeds, aquatic animals remain unexplored due to the difficulty\nof observing them in their natural underwater environment. To address this, we\npropose a model-based approach that incorporates a transmission model to\naccount for water-induced occlusion. We apply our method to video captured\nunder different sea conditions. We estimate mass and volume, and compare our\nresults to a manual 2D measurements-based method.","main_category":"cs.CV","categories":"cs.CV,cs.GR","published":"2025-04-22T10:47:29Z"}
{"aid":"http://arxiv.org/abs/2504.15786v1","title":"Satellite to GroundScape -- Large-scale Consistent Ground View\n  Generation from Satellite Views","summary":"Generating consistent ground-view images from satellite imagery is\nchallenging, primarily due to the large discrepancies in viewing angles and\nresolution between satellite and ground-level domains. Previous efforts mainly\nconcentrated on single-view generation, often resulting in inconsistencies\nacross neighboring ground views. In this work, we propose a novel cross-view\nsynthesis approach designed to overcome these challenges by ensuring\nconsistency across ground-view images generated from satellite views. Our\nmethod, based on a fixed latent diffusion model, introduces two conditioning\nmodules: satellite-guided denoising, which extracts high-level scene layout to\nguide the denoising process, and satellite-temporal denoising, which captures\ncamera motion to maintain consistency across multiple generated views. We\nfurther contribute a large-scale satellite-ground dataset containing over\n100,000 perspective pairs to facilitate extensive ground scene or video\ngeneration. Experimental results demonstrate that our approach outperforms\nexisting methods on perceptual and temporal metrics, achieving high\nphotorealism and consistency in multi-view outputs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T10:58:42Z"}
{"aid":"http://arxiv.org/abs/2504.15789v1","title":"Doubly-charmed pentaquark states in a mass splitting model","summary":"Concentrating on the mass differences relative to $P_{\\psi}^{N}(4312)^+$, we\nsystematically investigate the spectra of doubly-charmed pentaquark states in\nthe compact $ccqq\\bar{q}$ ($q=u, d, s$) configuration. The assumption that the\nobserved $P_{\\psi}^{N}(4312)^+$ is a compact hidden-charm pentaquark with\n$I(J^P)=\\frac12(\\frac32^-)$ is adopted. We also study the properties of strong\ndecays within a simple rearrangement scheme. The results indicate that the\n$I(J^P)=\\frac12(\\frac12^-)$ $ccnn\\bar{n}$ with $I_{nn}=0$ where $n$ denotes $u$\nor $d$ quark, $I(J^P)=0(\\frac12^-)$ $ccnn\\bar{s}$, and $I(J^P)=0(\\frac12^-)$\n$ccns\\bar{n}$ ground states should be stable.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-22T11:03:34Z"}
{"aid":"http://arxiv.org/abs/2504.15818v1","title":"Uniqueness of Parisi measures for enriched convex vector spin glass","summary":"In the PDE approach to mean-field spin glasses, it has been observed that the\nfree energy of convex spin glass models could be enriched by adding an extra\nparameter in its definition, and that the thermodynamic limit of the enriched\nfree energy satisfies a partial differential equation. This parameter can be\nthought of as a matrix-valued path, and the usual free energy is recovered by\nsetting this parameter to be the constant path taking only the value $0$.\nFurthermore, the enriched free energy can be expressed using a variational\nformula, which is a natural extension of the Parisi formula for the usual free\nenergy. For models with scalar spins the Parisi formula can be expressed as an\noptimization problem over a convex set, and it was shown in [arXiv:1402.5132]\nthat this problem has a unique optimizer thanks to a strict convexity property.\nFor models with vector spins, the Parisi formula cannot easily be written as a\nconvex optimization problem. In this paper, we generalize the uniqueness of\nParisi measures proven in [arXiv:1402.5132] to the enriched free energy of\nmodels with vector spins when the extra parameter is a strictly increasing\npath. Our approach relies on a Gateaux differentiability property of the free\nenergy and the envelope theorem.","main_category":"math.PR","categories":"math.PR,math.AP","published":"2025-04-22T12:03:46Z"}
{"aid":"http://arxiv.org/abs/2504.15827v1","title":"DualOptim: Enhancing Efficacy and Stability in Machine Unlearning with\n  Dual Optimizers","summary":"Existing machine unlearning (MU) approaches exhibit significant sensitivity\nto hyperparameters, requiring meticulous tuning that limits practical\ndeployment. In this work, we first empirically demonstrate the instability and\nsuboptimal performance of existing popular MU methods when deployed in\ndifferent scenarios. To address this issue, we propose Dual Optimizer\n(DualOptim), which incorporates adaptive learning rate and decoupled momentum\nfactors. Empirical and theoretical evidence demonstrates that DualOptim\ncontributes to effective and stable unlearning. Through extensive experiments,\nwe show that DualOptim can significantly boost MU efficacy and stability across\ndiverse tasks, including image classification, image generation, and large\nlanguage models, making it a versatile approach to empower existing MU\nalgorithms.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-22T12:18:26Z"}
{"aid":"http://arxiv.org/abs/2504.15828v1","title":"Circularity and repetitiveness in non-injective DF0L systems","summary":"We study circularity in DF0L systems, a generalization of D0L systems. We\nfocus on two different types of circularity, called weak and strong\ncircularity. When the morphism is injective on the language of the system, the\ntwo notions are equivalent, but they may differ otherwise. Our main result\nshows that failure of weak circularity implies unbounded repetitiveness, and\nthat unbounded repetitiveness implies failure of strong circularity. This\nextends previous work by the second and third authors for injective systems. To\nhelp motivate this work, we also give examples of non-injective but strongly\ncircular systems.","main_category":"cs.DM","categories":"cs.DM","published":"2025-04-22T12:20:34Z"}
{"aid":"http://arxiv.org/abs/2504.15830v1","title":"Predictive Synthesis of Control Barrier Functions and its Application to\n  Time-Varying Constraints","summary":"This paper presents a systematic method for synthesizing a Control Barrier\nFunction (CBF) that encodes predictive information into a CBF. Unlike other\nmethods, the synthesized CBF can account for changes and time-variations in the\nconstraints even when constructed for time-invariant constraints. This avoids\nrecomputing the CBF when the constraint specifications change. The method\nprovides an explicit characterization of the extended class K function {\\alpha}\nthat determines the dynamic properties of the CBF, and {\\alpha} can even be\nexplicitly chosen as a design parameter in the controller synthesis. The\nresulting CBF further accounts for input constraints, and its values can be\ndetermined at any point without having to compute the CBF over the entire\ndomain. The synthesis method is based on a finite horizon optimal control\nproblem inspired by Hamilton-Jacobi reachability analysis and does not rely on\na nominal control law. The synthesized CBF is time-invariant if the constraints\nare. The method poses mild assumptions on the controllability of the dynamic\nsystem and assumes the knowledge of at least a subset of some control invariant\nset. The paper provides a detailed analysis of the properties of the\nsynthesized CBF, including its application to time-varying constraints. A\nsimulation study applies the proposed approach to various dynamic systems in\nthe presence of time-varying constraints. The paper is accompanied by an online\navailable parallelized implementation of the proposed synthesis method.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-22T12:21:16Z"}
{"aid":"http://arxiv.org/abs/2504.15832v1","title":"Restoring of quantum state transferred along XY-spin chain and\n  entanglement evolution","summary":"We propose a protocol restoring the state transferred along the spin chain\ngoverned by the XY-Hamiltonian. Such dynamics does not preserve the excitation\nnumber and leads to mixing multiple-quantum coherence matrices of orders having\nthe same parities. Depending on the initial state, this results in\n  generating ether all possible or only even-order multiple-quantum coherence\nmatrices. Restoring is established via the special unitary transformation\napplied to the receiver side of the chain (extended receiver). An example of\nrestoring $\\pm1$ and $\\pm 2$-order coherence matrices in two-qubit state\ntransfer is considered. Entanglement transfer in such process is also studied\nand possibility of its amplification is demonstrated.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-22T12:25:01Z"}
{"aid":"http://arxiv.org/abs/2504.15851v1","title":"Sensitivity analysis for parametric nonlinear programming: A tutorial","summary":"This tutorial provides an overview of the current state-of-the-art in the\nsensitivity analysis for nonlinear programming. Building upon the fundamental\nwork of Fiacco, it derives the sensitivity of primal-dual solutions for regular\nnonlinear programs and explores the extent to which Fiacco's framework can be\nextended to degenerate nonlinear programs with non-unique dual solutions. The\nsurvey ends with a discussion on how to adapt the sensitivity analysis for\nconic programs and approximate solutions obtained from interior-point\nalgorithms.","main_category":"math.OC","categories":"math.OC","published":"2025-04-22T12:45:36Z"}
{"aid":"http://arxiv.org/abs/2504.15853v1","title":"DFT exploration of pressure dependent physical properties of the\n  recently discovered La3Ni2O7 superconductor","summary":"The recent discovery of superconductivity in Ruddlesden-Popper bilayer\nnickelate La3Ni2O7 under pressure has drawn a lot of interest. La3Ni2O7 is\nisostructural with cuprates in some respect. Investigation of its properties\nwill undoubtedly provide new insights into high-Tc superconductivity. In the\npresent work, we study structural, mechanical, elastic, optoelectronic,\nthermophysical properties, and Fermi surface topology of La3Ni2O7 under\npressure within the range of 30-40 GPa employing the density functional theory\n(DFT). The calculated structural parameters agree well with the earlier\nexperimental findings. The structural, mechanical, and thermodynamical\nstability is justified across the entire pressure range. The computed elastic\nmoduli classify the compound as ductile, and the material's ductility is\nlargely unaffected by pressure. The compound has a high level of machinability\nindex and dry lubricity. The electronic band structure reveals metallic feature\nof La3Ni2O7. The Debye temperature, thermal conductivity, and melting\ntemperature increase with increasing pressure, but in an anomalous manner. The\ncharacteristic peaks in refractive index, reflectivity, and photoconductivity\nexhibit a small shift towards higher energy for all polarizations of the\nelectric field vector with increasing pressure. The investigated material might\nbe a good ultraviolet radiation absorber and can be used as an anti-reflection\nsystem. Moreover, the pressure dependent electronic density of states at the\nFermi level, pressure induced negligible variations in the repulsive Coulomb\npseudopotential, and the changes in the Debye temperature have been used to\nexplore the effect of pressure on the superconducting transition temperature in\nthis study.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.mtrl-sci","published":"2025-04-22T12:49:03Z"}
{"aid":"http://arxiv.org/abs/2504.15858v1","title":"Positive-tone Nanolithography of Antimony Trisulfide with Femtosecond\n  Laser Wet-etching","summary":"Antimony trisulfide ($Sb_{2}S_{3}$), as an emerging material for integrated\nphotonic devices, has attracted significant attention due to its high index,\nlow loss, and phase-changing property in the optical regime. However,\nconventional lithography-based fabrication methods involve complex,\ntime-consuming, multistep processes, rendering the photonic application of\n$Sb_{2}S_{3}$ challenging. Here, we demonstrate that positive-tone fabrication\nof $Sb_{2}S_{3}$ nanostructures using wet-etch femtosecond laser processing, a\nstraightforward technique for the engraving of micro- and nanoscale structures,\ncan address major fabrication challenges. The patterning mechanism and factors\ninfluencing resolution of $Sb_{2}S_{3}$ thin film structures deposited on\nquartz (transmissive) and gold (reflective) substrates are experimentally\ninvestigated and supported by theoretical modelling. Using this approach, the\nsmallest linewidth fabricated is measured at 178 nm. Consequently, multiple\ntest patterns are demonstrated showing versatile functionalities. Functional\nFresnel Zone Plates (FZPs) with varying focal length are fabricated and\ncharacterized. This study provides a significantly simplified approach for\nrealizing $Sb_{2}S_{3}$ based integrated photonic devices.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mtrl-sci,physics.ins-det","published":"2025-04-22T12:53:43Z"}
{"aid":"http://arxiv.org/abs/2504.15899v1","title":"RaSCL: Radar to Satellite Crossview Localization","summary":"GNSS is unreliable, inaccurate, and insufficient in many real-time autonomous\nfield applications. In this work, we present a GNSS-free global localization\nsolution that contains a method of registering imaging radar on the ground with\noverhead RGB imagery, with joint optimization of relative poses from odometry\nand global poses from our overhead registration. Previous works have used\nvarious combinations of ground sensors and overhead imagery, and different\nfeature extraction and matching methods. These include various handcrafted and\ndeep-learning-based methods for extracting features from overhead imagery. Our\nwork presents insights on extracting essential features from RGB overhead\nimages for effective global localization against overhead imagery using only\nground radar and a single georeferenced initial guess. We motivate our method\nby evaluating it on datasets in diverse geographic conditions and robotic\nplatforms, including on an Unmanned Surface Vessel (USV) as well as urban and\nsuburban driving datasets.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-22T13:41:04Z"}
{"aid":"http://arxiv.org/abs/2504.15925v1","title":"Improving robustness and training efficiency of machine-learned\n  potentials by incorporating short-range empirical potentials","summary":"Machine learning force fields (MLFFs) are powerful tools for materials\nmodeling, but their performance is often limited by training dataset quality,\nparticularly the lack of rare event configurations. This limitation undermines\ntheir accuracy and robustness in long-time and large-scale molecular dynamics\nsimulations. In this work, we present a hybrid MLFF framework that integrates\nan empirical short-range repulsive potential and demonstrates improved\nrobustness and training efficiency. Using solid electrolyte\nLi$_7$La$_3$Zr$_2$O$_{12}$ (LLZO) as a model system, we show that purely\ndata-driven MLFFs fail to prevent unphysical atomistic clustering in extended\nsimulations due to inadequate short-range repulsion. In contrast, the hybrid\nforce field eliminates these artifacts, enabling stable long-time simulations,\nwhich are critical for studying various properties of LLZO. The hybrid\nframework also reduces the need for extensive active learning and performs well\nwith just 25 training configurations. By combining physics-driven constraints\nwith data-driven flexibility, this approach is compatible with most existing\nMLFF architectures and establishes a universal paradigm for developing robust,\ntraining-efficient force fields for complex material systems.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-22T14:12:45Z"}
{"aid":"http://arxiv.org/abs/2504.15927v1","title":"New Recipe for Semi-supervised Community Detection: Clique Annealing\n  under Crystallization Kinetics","summary":"Semi-supervised community detection methods are widely used for identifying\nspecific communities due to the label scarcity. Existing semi-supervised\ncommunity detection methods typically involve two learning stages learning in\nboth initial identification and subsequent adjustment, which often starts from\nan unreasonable community core candidate. Moreover, these methods encounter\nscalability issues because they depend on reinforcement learning and generative\nadversarial networks, leading to higher computational costs and restricting the\nselection of candidates. To address these limitations, we draw a parallel\nbetween crystallization kinetics and community detection to integrate the\nspontaneity of the annealing process into community detection. Specifically, we\nliken community detection to identifying a crystal subgrain (core) that expands\ninto a complete grain (community) through a process similar to annealing. Based\non this finding, we propose CLique ANNealing (CLANN), which applies kinetics\nconcepts to community detection by integrating these principles into the\noptimization process to strengthen the consistency of the community core.\nSubsequently, a learning-free Transitive Annealer was employed to refine the\nfirst-stage candidates by merging neighboring cliques and repositioning the\ncommunity core, enabling a spontaneous growth process that enhances\nscalability. Extensive experiments on \\textbf{43} different network settings\ndemonstrate that CLANN outperforms state-of-the-art methods across multiple\nreal-world datasets, showcasing its exceptional efficacy and efficiency in\ncommunity detection.","main_category":"cs.SI","categories":"cs.SI,cs.AI","published":"2025-04-22T14:17:15Z"}
{"aid":"http://arxiv.org/abs/2504.15938v1","title":"Differentiable graph neural network simulator for forward and inverse\n  modeling of multi-layered slope system with multiple material properties","summary":"Graph neural network simulators (GNS) have emerged as a computationally\nefficient tool for simulating granular flows. Previous efforts have been\nlimited to simplified geometries and material characterizations, typically\nconsidering only friction angle, which does not reflect the complexity of\nrealistic geotechnical systems such as slopes encountered in engineering\npractice. This study introduces a differentiable GNS framework designed for\nmulti-layered slope systems comprising both forward and inverse modeling\ncomponents. The forward component relies on a fine-tuned GNS that incorporates\nboth friction angle and cohesion. Its performance is demonstrated through\ncolumn collapse and multi-layered slope runout simulations, where GNS\nreplicates multi-material flow dynamics while achieving up to 145x\ncomputational speedup over the Material Point Method (MPM). The inverse\nmodeling component leverages the trained GNS, reverse-mode automatic\ndifferentiation, and L-BFGS-B optimization to infer material properties from a\ntarget runout geometry. Its performance is demonstrated by back-calculating the\nmaterial strengths that led to failure-induced runout in a dam system composed\nof multiple materials. Results are obtained within minutes and show good\nagreement with the target strength values. The framework introduced in this\nstudy provides an efficient approach for forward runout assessments and inverse\nstrength back-calculation in realistic slope systems.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-04-22T14:28:30Z"}
{"aid":"http://arxiv.org/abs/2504.15983v1","title":"W-PCA Based Gradient-Free Proxy for Efficient Search of Lightweight\n  Language Models","summary":"The demand for efficient natural language processing (NLP) systems has led to\nthe development of lightweight language models. Previous work in this area has\nprimarily focused on manual design or training-based neural architecture search\n(NAS) methods. Recently, zero-shot NAS methods have been proposed for\nevaluating language models without the need for training. However, prevailing\napproaches to zero-shot NAS often face challenges such as biased evaluation\nmetrics and computational inefficiencies. In this paper, we introduce\nweight-weighted PCA (W-PCA), a novel zero-shot NAS method specifically tailored\nfor lightweight language models. Our approach utilizes two evaluation proxies:\nthe parameter count and the number of principal components with cumulative\ncontribution exceeding $\\eta$ in the feed-forward neural (FFN) layer.\nAdditionally, by eliminating the need for gradient computations, we optimize\nthe evaluation time, thus enhancing the efficiency of designing and evaluating\nlightweight language models. We conduct a comparative analysis on the GLUE and\nSQuAD datasets to evaluate our approach. The results demonstrate that our\nmethod significantly reduces training time compared to one-shot NAS methods and\nachieves higher scores in the testing phase compared to previous\nstate-of-the-art training-based methods. Furthermore, we perform ranking\nevaluations on a dataset sampled from the FlexiBERT search space. Our approach\nexhibits superior ranking correlation and further reduces solving time compared\nto other zero-shot NAS methods that require gradient computation.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-22T15:33:01Z"}
{"aid":"http://arxiv.org/abs/2504.15985v1","title":"Modeling and Forecasting Realized Volatility with Multivariate\n  Fractional Brownian Motion","summary":"A multivariate fractional Brownian motion (mfBm) with component-wise Hurst\nexponents is used to model and forecast realized volatility. We investigate the\ninterplay between correlation coefficients and Hurst exponents and propose a\nnovel estimation method for all model parameters, establishing consistency and\nasymptotic normality of the estimators. Additionally, we develop a\ntime-reversibility test, which is typically not rejected by real volatility\ndata. When the data-generating process is a time-reversible mfBm, we derive\noptimal forecasting formulae and analyze their properties. A key insight is\nthat an mfBm with different Hurst exponents and non-zero correlations can\nreduce forecasting errors compared to a one-dimensional model. Consistent with\noptimal forecasting theory, out-of-sample forecasts using the time-reversible\nmfBm show improvements over univariate fBm, particularly when the estimated\nHurst exponents differ significantly. Empirical results demonstrate that\nmfBm-based forecasts outperform the (vector) HAR model.","main_category":"q-fin.ST","categories":"q-fin.ST","published":"2025-04-22T15:38:31Z"}
{"aid":"http://arxiv.org/abs/2504.15999v1","title":"Infinitely many collisions between a recurrent simple random walk and\n  arbitrary many transient random walks in a subballistic random environment","summary":"We consider $d$ random walks $\\big(S_n^{(j)}\\big)_{n\\in\\mathbb{N}}$, $1\\leq j\n\\leq d$, in the same random environment $\\omega$ in $\\mathbb{Z}$, and a\nrecurrent simple random walk $(Z_n)_{n\\in\\mathbb{N}}$ on $\\mathbb{Z}$. We\nassume that, conditionally on the environment $\\omega$, all the random walks\nare independent and start from even initial locations. Our assumption on the\nlaw of the environment is such that a single random walk in the environment\n$\\omega$ is transient to the right but subballistic, with parameter\n$0<\\kappa<1/2$. We show that - for every value of $d$ - there are almost surely\ninfinitely many times for which all these random walks,\n$(Z_n)_{n\\in\\mathbb{N}}$ and $\\big(S_n^{(j)}\\big)_{n\\in\\mathbb{N}}$, $1\\leq j\n\\leq d$, are simultaneously at the same location, even though one of them is\nrecurrent and the $d$ others ones are transient.","main_category":"math.PR","categories":"math.PR","published":"2025-04-22T16:05:11Z"}
{"aid":"http://arxiv.org/abs/2504.16014v1","title":"Probing New Physics Through CP Violation in $B_{(s)}\\to VŒº^+Œº^-$\n  Decays","summary":"Rare decays of the kind $B\\to K^*\\mu^+\\mu^-$ and $B_s\\to \\phi\\mu^+\\mu^-$ are\nkey players for testing the Standard Model. The current experimental data for\ntheir decay rates and angular observables show tensions with the theoretical\npredictions that may be indications of New Physics. We present a strategy to\nextract the relevant short-distance coefficients in the presence of new sources\nof CP violation, utilizing a synergy with $B\\to K\\mu^+\\mu^-$ decays. Using the\ncurrent data as a guideline, we illustrate the new method to determine the\ncomplex coefficients $C_9^{(\\prime)}$ and $C_{10}^{(\\prime)}$ using only four\nangular observables. Interestingly, the current experimental picture leaves\nsignificant room for CP-violating New Physics. We discuss also the link to\nleptonic $B^0_s\\to\\mu^+\\mu^-$ decays. We are looking forward to the\nimplementation of these strategies at the future high-precision frontier of\nflavour physics.","main_category":"hep-ph","categories":"hep-ph,hep-th","published":"2025-04-22T16:26:17Z"}
{"aid":"http://arxiv.org/abs/2504.16024v1","title":"EnsAI: An Emulator for Atmospheric Chemical Ensembles","summary":"Ensemble-based methods for data assimilation and emission inversions are a\npopular way to encode flow-dependency within the model error covariance. While\nmost ensemble methods do not require the use of an adjoint model, the need to\nrepeatedly run a geophysical model to generate the ensemble can be a\nsignificant computational burden. In this paper, we introduce EnsAI, a new\nAI-based ensemble generation system for atmospheric chemical constituents. When\ntrained on an existing ensemble for ammonia generated by the GEM-MACH air\nquality model, it was shown that the ensembles produced by EnsAI can accurately\nreproduce the meteorology-dependent features of the original ensemble, while\ngenerating the ensemble 3,300 times faster than the original GEM-MACH ensemble.\nWhile EnsAI requires an upfront cost for generating an ensemble used for\ntraining, as well as the training itself, the long term computational savings\ncan greatly exceed these initial computational costs. When used in an emissions\ninversion system, EnsAI produced similar inversion results to those in which\nthe original GEM-MACH ensemble was used while using significantly less\ncomputational resources.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-22T16:41:26Z"}
{"aid":"http://arxiv.org/abs/2504.16041v1","title":"Muon Optimizer Accelerates Grokking","summary":"This paper investigates the impact of different optimizers on the grokking\nphenomenon, where models exhibit delayed generalization. We conducted\nexperiments across seven numerical tasks (primarily modular arithmetic) using a\nmodern Transformer architecture. The experimental configuration systematically\nvaried the optimizer (Muon vs. AdamW) and the softmax activation function\n(standard softmax, stablemax, and sparsemax) to assess their combined effect on\nlearning dynamics. Our empirical evaluation reveals that the Muon optimizer,\ncharacterized by its use of spectral norm constraints and second-order\ninformation, significantly accelerates the onset of grokking compared to the\nwidely used AdamW optimizer. Specifically, Muon reduced the mean grokking epoch\nfrom 153.09 to 102.89 across all configurations, a statistically significant\ndifference (t = 5.0175, p = 6.33e-08). This suggests that the optimizer choice\nplays a crucial role in facilitating the transition from memorization to\ngeneralization.","main_category":"cs.LG","categories":"cs.LG,cs.AI,I.2","published":"2025-04-22T17:08:09Z"}
{"aid":"http://arxiv.org/abs/2504.16392v1","title":"Joint Topology and Power Optimization for Multi-UAV Collaborative Secure\n  Communication","summary":"In this paper, we investigate an unmanned aerial vehicle (UAV)-enabled secure\ncommunication scenario that a cluster of UAVs performs a virtual non-uniform\nlinear array (NULA) to communicate with a base station (BS) in the presence of\neavesdroppers (Eves). Our goal is to design the UAV topology, trajectory, and\nprecoding to maximize the system channel capacity. To this end, we convert the\noriginal problem into equivalent two-stage problems. Specifically, we first try\nto maximize the channel gain by meticulously designing the UAV topology. We\nthen study the joint optimization of the trajectory and precoding for total\ntransmit power minimization while satisfying the constraints on providing\nquality of service (QoS) assurance to the BS, the leakage tolerance to Eves,\nthe per-UAV transmit power, the initial/final locations, and the cylindrical\nno-fly zones. For the UAV topology design, we prove that the topology follows\nthe Fekete-point distribution. The design of trajectory and precoding is\nformulated as a non-convex optimization problem which is generally intractable.\nSubsequently, the non-convex constraints are converted into convex terms, and a\ndouble-loop search algorithm is proposed to solve the transmit power\nminimization problem. Introduce random rotation offsets so as to perform a\ndynamic stochastic channel to enhance the security. Numerical results\ndemonstrate the superiority of the proposed method in promoting capacity.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-23T03:39:02Z"}
{"aid":"http://arxiv.org/abs/2504.16409v1","title":"A Molecular Dynamics Study of Size Effects for Critical Resolved Shear\n  Stress in Nickel Superalloys","summary":"We present in this work a molecular dynamics study of a size effect relating\nto the volume fraction of gamma-prime precipitate of edge dislocation motion in\na simple model of Nickel superalloys. We model the superalloy as periodically\nspaced cubic gamma-prime precipitates inside a uniform gamma matrix. We then\nanalyze the motion of paired edge dislocations in the gamma phase when subject\nto an external shear stress for various volume fractions of the gamma-prime\nprecipitate for a wide range of temperatures, from 300 K to 700 K. While the\nvariation of dislocation velocity is not significant, the critical resolved\nshear stress is found to exhibit a power law dependence on the volume fraction\nof the gamma-prime precipitate with two distinct regimes which have similar\nexponent but markedly different prefactors; we also observe that this\ntwo-regime behavior remains true across a wide range of temperatures. We\npresent a detailed analysis of this behavior and reduce it to a linear\ndependence of the critical resolved shear stress on the length of the\ngamma-prime precipitate along the direction of dislocation motion. We further\nidentify the critical length scale underlying the transition between the two\nobserved regimes as the total core width of the paired dislocations in a pure\ngamma-prime system, which includes in addition to the complex stacking fault\nseparating the partials of the paired dislocations the width of the anti-phase\nboundary that is formed between the super-dislocations. The results presented\nin this work provides new details on the strengthening effect of gamma-prime\nprecipitates in nickel superalloys and also has important implications for\nlarger scale dislocation dynamics studies for nickel superalloys.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-23T04:24:03Z"}
{"aid":"http://arxiv.org/abs/2504.16428v1","title":"Energy Rates Due to Weak Decay Rates of Vanadium Isotopes in Stellar\n  Environment","summary":"The neutrino cooling and gamma heating rates are considered as an important\ninput needed to study the final phases of the evolution of high-mass stars. The\nweak-interaction mediated processes, namely the $\\beta$-decay and electron\ncapture, significantly change the lepton to baryon ratio and accelerate the\ncontraction of the core. The emission of resulting neutrinos/antineutrinos\ntends to cool the stellar core. On the other hand, gamma rays are produced\nbecause of electron capture and $\\beta$-decay to excited states in daughter\nnuclei. These gamma rays heat the core and contribute to an increase of entropy\nwhich may cause convection to occur.\n  In the present work, the weak-interaction heating and cooling rates on a\nchain of twenty-two isotopes of vanadium having mass in the range $43-64$ have\nbeen estimated using the proton-neutron quasiparticle random phase\napproximation theory. The rates have been computed for the temperature ranging\nfrom ($10^{7} - 3 \\times 10^{10}$)\\;K and for the density range\n($10-10^{11}$)\\;g/cm$^{3}$. Our calculated neutrino energy loss rates have also\nbeen compared with the previously reported rates calculated using other\ntheoretical models. At high stellar temperatures, our rates are larger by 1-2\norders of magnitude as compared to previous results.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-23T05:25:42Z"}
{"aid":"http://arxiv.org/abs/2504.16438v1","title":"Private Federated Learning using Preference-Optimized Synthetic Data","summary":"In practical settings, differentially private Federated learning (DP-FL) is\nthe dominant method for training models from private, on-device client data.\nRecent work has suggested that DP-FL may be enhanced or outperformed by methods\nthat use DP synthetic data (Wu et al., 2024; Hou et al., 2024). The primary\nalgorithms for generating DP synthetic data for FL applications require careful\nprompt engineering based on public information and/or iterative private client\nfeedback. Our key insight is that the private client feedback collected by\nprior DP synthetic data methods (Hou et al., 2024; Xie et al., 2024) can be\nviewed as a preference ranking. Our algorithm, Preference Optimization for\nPrivate Client Data (POPri) harnesses client feedback using preference\noptimization algorithms such as Direct Preference Optimization (DPO) to\nfine-tune LLMs to generate high-quality DP synthetic data. To evaluate POPri,\nwe release LargeFedBench, a new federated text benchmark for uncontaminated LLM\nevaluations on federated client data. POPri substantially improves the utility\nof DP synthetic data relative to prior work on LargeFedBench datasets and an\nexisting benchmark from Xie et al. (2024). POPri closes the gap between\nnext-token prediction accuracy in the fully-private and non-private settings by\nup to 68%, compared to 52% for prior synthetic data methods, and 10% for\nstate-of-the-art DP federated learning methods. The code and data are available\nat https://github.com/meiyuw/POPri.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CR,cs.DC","published":"2025-04-23T05:57:20Z"}
{"aid":"http://arxiv.org/abs/2504.16468v1","title":"HAQA: A Hardware-Guided and Fidelity-Aware Strategy for Efficient Qubit\n  Mapping Optimization","summary":"Quantum algorithms rely on quantum computers for implementation, but the\nphysical connectivity constraints of modern quantum processors impede the\nefficient realization of quantum algorithms. Qubit mapping, a critical\ntechnology for practical quantum computing applications, directly determines\nthe execution efficiency and feasibility of algorithms on superconducting\nquantum processors. Existing mapping methods overlook intractable quantum\nhardware fidelity characteristics, reducing circuit execution quality. They\nalso exhibit prolonged solving times or even failure to complete when handling\nlarge-scale quantum architectures, compromising efficiency. To address these\nchallenges, we propose a novel qubit mapping method HAQA. HAQA first introduces\na community-based iterative region identification strategy leveraging hardware\nconnection topology, achieving effective dimensionality reduction of mapping\nspace. This strategy avoids global search procedures, with complexity analysis\ndemonstrating quadratic polynomial-level acceleration. Furthermore, HAQA\nimplements a hardware-characteristic-based region evaluation mechanism,\nenabling quantitative selection of mapping regions based on fidelity metrics.\nThis approach effectively integrates hardware fidelity information into the\nmapping process, enabling fidelity-aware qubit allocation. Experimental results\ndemonstrate that HAQA significantly improves solving speed and fidelity while\nensuring solution quality. When applied to state-of-the-art quantum mapping\ntechniques Qsynth-v2 and TB-OLSQ2, HAQA achieves acceleration ratios of 632.76\nand 286.87 respectively, while improving fidelity by up to 52.69% and 238.28%","main_category":"quant-ph","categories":"quant-ph,cs.ET","published":"2025-04-23T07:27:27Z"}
{"aid":"http://arxiv.org/abs/2504.16479v1","title":"The Dance of Atoms-De Novo Protein Design with Diffusion Model","summary":"The de novo design of proteins refers to creating proteins with specific\nstructures and functions that do not naturally exist. In recent years, the\naccumulation of high-quality protein structure and sequence data and\ntechnological advancements have paved the way for the successful application of\ngenerative artificial intelligence (AI) models in protein design. These models\nhave surpassed traditional approaches that rely on fragments and\nbioinformatics. They have significantly enhanced the success rate of de novo\nprotein design, and reduced experimental costs, leading to breakthroughs in the\nfield. Among various generative AI models, diffusion models have yielded the\nmost promising results in protein design. In the past two to three years, more\nthan ten protein design models based on diffusion models have emerged. Among\nthem, the representative model, RFDiffusion, has demonstrated success rates in\n25 protein design tasks that far exceed those of traditional methods, and other\nAI-based approaches like RFjoint and hallucination. This review will\nsystematically examine the application of diffusion models in generating\nprotein backbones and sequences. We will explore the strengths and limitations\nof different models, summarize successful cases of protein design using\ndiffusion models, and discuss future development directions.","main_category":"q-bio.BM","categories":"q-bio.BM,cs.AI","published":"2025-04-23T07:45:00Z"}
{"aid":"http://arxiv.org/abs/2504.16490v1","title":"Microscopic theory of the inverse Faraday effect in a multiorbital\n  model: Role of orbital magnetic moment and electric dipole","summary":"We theoretically investigate the inverse Faraday effect (IFE), a phenomenon\nwhere circularly-polarized light induces a magnetic moment, in a multiorbital\nmetallic system. We demonstrate that the total magnetic moment can be\ndecomposed into several contributions in multiorbital tight-binding models. In\nparticular, we reveal that the electric dipole moment of Wannier orbitals also\ncontributes to the orbital magnetic moment, which is not included in the\nconventional expression for the orbital magnetic moment in lattice systems. To\naccount for all possible contributions, we adopt an $s$-$p$ tight-binding\nsystem as a minimal model for the IFE. Using an analytical approach based on\nthe Schrieffer-Wolff transformation, we clarify the physical origins of these\ncontributions. Additionally, we quantitatively evaluate each contribution on an\nequal footing through a numerical approach based on the Floquet formalism. Our\nresults reveal that the orbital magnetic moment exhibits a significantly larger\nresponse compared to the spin magnetic moment, with all contributions to the\norbital magnetic moment being comparable in magnitude. These findings highlight\nthe essential role of orbital degrees of freedom in the IFE.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.str-el","published":"2025-04-23T08:04:22Z"}
{"aid":"http://arxiv.org/abs/2504.16508v1","title":"Nondestructive beam envelope measurements using beam position monitors\n  for low-beta heavy ion beams in superconducting linear accelerator","summary":"In superconducting linear accelerators (linacs), accurately monitoring beam\ndynamics is essential for minimizing beam losses and ensuring stable\noperations. However, destructive diagnostics must be avoided in superconducting\nsections to prevent the occurrence of particulates and outgassing, rendering\ndirect measurements of the beam envelope particularly challenging. This study\npresents a non-destructive method that uses beam position monitors (BPMs) to\nestimate the transverse beam envelope based on measurements of the quadrupole\nmoment of the beam distribution. Although this concept was originally proposed\nin the 1980s, its application, especially to hadron beams, has been limited\nbecause of low signal sensitivity and the accuracy constraints associated with\nconventional BPM geometries. To overcome these challenges, we employed\n$\\cos{2\\theta}$-type BPMs, which offer improved sensitivity to quadrupole\ncomponents and are well-suited for low-$\\beta$ heavy ion beams. This method was\napplied to the heavy ion beams in the superconducting RIKEN linac (SRILAC), for\nwhich data from eight BPMs were combined with transfer matrix calculations and\nsupplemental wire scanner data. The resulting beam envelope estimates exhibited\ngood agreement with conventional quadrupole scan results, demonstrating the\nfeasibility of this technique for routine, non-destructive beam monitoring in\nsuperconducting accelerator sections.","main_category":"physics.acc-ph","categories":"physics.acc-ph","published":"2025-04-23T08:35:42Z"}
{"aid":"http://arxiv.org/abs/2504.16528v1","title":"Quantitative Strategy Templates","summary":"This paper presents (permissive) \\emph{Quantitative Strategy Templates}\n(QaSTels) to succinctly represent infinitely many winning strategies in\ntwo-player energy and mean-payoff games. This transfers the recently introduced\nconcept of \\emph{Permissive (qualitative) Strategy Templates} (PeSTels) for\n$\\omega$-regular games to games with quantitative objectives. We provide the\ntheoretical and algorithmic foundations of (i) QaSTel synthesis, and (ii) their\n(incremental) combination with PeSTels for games with mixed quantitative and\nqualitative objectives. Using a prototype implementation of our synthesis\nalgorithms, we demonstrate empirically that QaSTels extend the advantageous\nproperties of strategy templates over single winning strategies -- known from\nPeSTels -- to games with (additional) quantitative objectives. This includes\n(i) the enhanced robustness of strategies due to their runtime-adaptability,\nand (ii) the compositionality of templates w.r.t. incrementally arriving\nobjectives. We use control-inspired examples to illustrate these superior\nproperties of QaSTels for CPS design.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-23T08:53:10Z"}
{"aid":"http://arxiv.org/abs/2504.16538v1","title":"Streetscape Analysis with Generative AI (SAGAI): Vision-Language\n  Assessment and Mapping of Urban Scenes","summary":"Streetscapes are an essential component of urban space. Their assessment is\npresently either limited to morphometric properties of their mass skeleton or\nrequires labor-intensive qualitative evaluations of visually perceived\nqualities. This paper introduces SAGAI: Streetscape Analysis with Generative\nArtificial Intelligence, a modular workflow for scoring street-level urban\nscenes using open-access data and vision-language models. SAGAI integrates\nOpenStreetMap geometries, Google Street View imagery, and a lightweight version\nof the LLaVA model to generate structured spatial indicators from images via\ncustomizable natural language prompts. The pipeline includes an automated\nmapping module that aggregates visual scores at both the point and street\nlevels, enabling direct cartographic interpretation. It operates without\ntask-specific training or proprietary software dependencies, supporting\nscalable and interpretable analysis of urban environments. Two exploratory case\nstudies in Nice and Vienna illustrate SAGAI's capacity to produce geospatial\noutputs from vision-language inference. The initial results show strong\nperformance for binary urban-rural scene classification, moderate precision in\ncommercial feature detection, and lower estimates, but still informative, of\nsidewalk width. Fully deployable by any user, SAGAI can be easily adapted to a\nwide range of urban research themes, such as walkability, safety, or urban\ndesign, through prompt modification alone.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-23T09:08:06Z"}
{"aid":"http://arxiv.org/abs/2504.16547v1","title":"Generation of Phonons with Angular Momentum During Ultrafast\n  Demagnetization","summary":"A major question in the field of femtosecond laser-induced demagnetization is\nwhereto the angular momentum lost by the electrons is transferred. Recent\nultrafast electron diffraction measurements [Tauchert \\textit{et al.}, Nature\n{\\bf 602}, 73 (2022)] suggest that this angular momentum is transferred to the\nrotational motion of atoms on a sub-picosecond timescale, but a theory\nconfirmation of this proposition has yet to be given. Here we investigate the\ncoupled electron-nuclear dynamics during ultrafast demagnetization of L1$_0$\nFePt, using Ehrenfest nuclear dynamics simulations combined with the\ntime-dependent density functional theory (TDDFT) framework. We demonstrate that\natomic rotations appear, i.e., the generation of phonons carrying finite\nangular momentum following ultrafast demagnetization. We further show that both\nultrafast demagnetization and the generation of phonons with angular momentum\narise from symmetry constraints imposed by the spin-orbit coupling, thus\nproviding insight in spin-phonon interaction at ultrafast timescales.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.atom-ph","published":"2025-04-23T09:23:31Z"}
{"aid":"http://arxiv.org/abs/2504.16548v1","title":"Exploring human-SAV interaction using large language models: The impact\n  of psychological ownership and anthropomorphism on user experience","summary":"There has been extensive prior work exploring how psychological factors such\nas anthropomorphism affect the adoption of shared autonomous vehicles (SAVs).\nHowever, limited research has been conducted on how prompt strategies in large\nlanguage model (LLM)-powered SAV User Interfaces (UIs) affect users'\nperceptions, experiences, and intentions to adopt such technology. In this\nwork, we investigate how conversational UIs powered by LLMs drive these\npsychological factors and psychological ownership, the sense of possession a\nuser may come to feel towards an entity or object they may not legally own. We\ndesigned four SAV UIs with varying levels of anthropomorphic characteristics\nand psychological ownership triggers. Quantitative measures of psychological\nownership, anthropomorphism, quality of service, disclosure tendency, sentiment\nof SAV responses, and overall acceptance were collected after participants\ninteracted with each SAV. Qualitative feedback was also gathered regarding the\nexperience of psychological ownership during the interactions. The results\nindicate that an SAV conversational UI designed to be more anthropomorphic and\nto induce psychological ownership improved users' perceptions of the SAV's\nhuman-like qualities and improved the sentiment of responses compared to a\ncontrol condition. These findings provide practical guidance for designing\nLLM-based conversational UIs that enhance user experience and adoption of SAVs.","main_category":"cs.HC","categories":"cs.HC,cs.AI,cs.ET","published":"2025-04-23T09:25:22Z"}
{"aid":"http://arxiv.org/abs/2504.16555v1","title":"Confidence Sequences for Generalized Linear Models via Regret Analysis","summary":"We develop a methodology for constructing confidence sets for parameters of\nstatistical models via a reduction to sequential prediction. Our key\nobservation is that for any generalized linear model (GLM), one can construct\nan associated game of sequential probability assignment such that achieving low\nregret in the game implies a high-probability upper bound on the excess\nlikelihood of the true parameter of the GLM. This allows us to develop a scheme\nthat we call online-to-confidence-set conversions, which effectively reduces\nthe problem of proving the desired statistical claim to an algorithmic\nquestion. We study two varieties of this conversion scheme: 1) analytical\nconversions that only require proving the existence of algorithms with low\nregret and provide confidence sets centered at the maximum-likelihood estimator\n2) algorithmic conversions that actively leverage the output of the online\nalgorithm to construct confidence sets (and may be centered at other,\nadaptively constructed point estimators). The resulting methodology recovers\nall state-of-the-art confidence set constructions within a single framework,\nand also provides several new types of confidence sets that were previously\nunknown in the literature.","main_category":"math.ST","categories":"math.ST,cs.LG,stat.ML,stat.TH","published":"2025-04-23T09:32:40Z"}
{"aid":"http://arxiv.org/abs/2504.16566v1","title":"Optically detected and radio wave-controlled spin chemistry in\n  cryptochrome","summary":"Optically addressable spin systems, such as nitrogen-vacancy (NV) centers in\ndiamond, have been widely studied for quantum sensing applications. In this\nwork, we demonstrate that flavin-based cryptochrome proteins, which generate\nradical pairs upon optical excitation, also exhibit optically detected magnetic\nresonance. We further show that this optical spin interface is tunable by the\nprotein structure. These findings establish radical pairs in proteins as a\nnovel platform for optically addressable spin systems and magnetic field\nsensors. Additionally, the ability to control spin transitions introduces a new\nclass of biophysical tools that hold promise for enabling multiplexed\nfluorescence microscopy. Importantly, due to the spin-selective nature of\nradical pair chemistry, the results lay the groundwork for radiofrequency-based\nmanipulation of biological systems.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T09:45:30Z"}
{"aid":"http://arxiv.org/abs/2504.16584v1","title":"Case Study: Fine-tuning Small Language Models for Accurate and Private\n  CWE Detection in Python Code","summary":"Large Language Models (LLMs) have demonstrated significant capabilities in\nunderstanding and analyzing code for security vulnerabilities, such as Common\nWeakness Enumerations (CWEs). However, their reliance on cloud infrastructure\nand substantial computational requirements pose challenges for analyzing\nsensitive or proprietary codebases due to privacy concerns and inference costs.\nThis work explores the potential of Small Language Models (SLMs) as a viable\nalternative for accurate, on-premise vulnerability detection. We investigated\nwhether a 350-million parameter pre-trained code model (codegen-mono) could be\neffectively fine-tuned to detect the MITRE Top 25 CWEs specifically within\nPython code. To facilitate this, we developed a targeted dataset of 500\nexamples using a semi-supervised approach involving LLM-driven synthetic data\ngeneration coupled with meticulous human review. Initial tests confirmed that\nthe base codegen-mono model completely failed to identify CWEs in our samples.\nHowever, after applying instruction-following fine-tuning, the specialized SLM\nachieved remarkable performance on our test set, yielding approximately 99%\naccuracy, 98.08% precision, 100% recall, and a 99.04% F1-score. These results\nstrongly suggest that fine-tuned SLMs can serve as highly accurate and\nefficient tools for CWE detection, offering a practical and privacy-preserving\nsolution for integrating advanced security analysis directly into development\nworkflows.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-23T10:05:27Z"}
{"aid":"http://arxiv.org/abs/2504.16592v1","title":"Algorithmic Pricing and Algorithmic Collusion","summary":"The rise of algorithmic pricing in online retail platforms has attracted\nsignificant interest in how autonomous software agents interact under\ncompetition. This article explores the potential emergence of algorithmic\ncollusion - supra-competitive pricing outcomes that arise without explicit\nagreements - as a consequence of repeated interactions between learning agents.\nMost of the literature focuses on oligopoly pricing environments modeled as\nrepeated Bertrand competitions, where firms use online learning algorithms to\nadapt prices over time. While experimental research has demonstrated that\nspecific reinforcement learning algorithms can learn to maintain prices above\ncompetitive equilibrium levels in simulated environments, theoretical\nunderstanding of when and why such outcomes occur remains limited. This work\nhighlights the interdisciplinary nature of this challenge, which connects\ncomputer science concepts of online learning with game-theoretical literature\non equilibrium learning. We examine implications for the Business & Information\nSystems Engineering (BISE) community and identify specific research\nopportunities to address challenges of algorithmic competition in digital\nmarketplaces.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-23T10:18:57Z"}
{"aid":"http://arxiv.org/abs/2504.16599v1","title":"A two-dimensional swarmalator model with higher-order interactions","summary":"We study a simple two-dimensional swarmalator model that incorporates\nhigher-order phase interactions, uncovering a diverse range of collective\nstates. The latter include spatially coherent and gas-like configurations,\nneither of which appear in models with only pairwise interactions.\nAdditionally, we discover bistability between various states, a phenomenon that\narises directly from the inclusion of higher-order interactions. By analyzing\nseveral of these emergent states analytically, both for identical and\nnonidentical populations of swarmalators, we gain deeper insights into their\nunderlying mechanisms and stability conditions. Our findings broaden the\nunderstanding of swarmalator dynamics and open new avenues for exploring\ncomplex collective behaviors in systems governed by higher-order interactions.","main_category":"nlin.AO","categories":"nlin.AO,math-ph,math.MP","published":"2025-04-23T10:28:13Z"}
{"aid":"http://arxiv.org/abs/2504.16617v1","title":"Security Science (SecSci), Basic Concepts and Mathematical Foundations","summary":"This textbook compiles the lecture notes from security courses taught at\nOxford in the 2000s, at Royal Holloway in the 2010s, and currently in Hawaii.\nThe early chapters are suitable for a first course in security. The middle\nchapters have been used in advanced courses. Towards the end there are also\nsome research problems.","main_category":"cs.CR","categories":"cs.CR,cs.CY,cs.IT,cs.SI,math.IT,math.LO","published":"2025-04-23T11:04:17Z"}
{"aid":"http://arxiv.org/abs/2504.16618v1","title":"The quantum spin Brauer category","summary":"We introduce a diagrammatic braided monoidal category, the quantum spin\nBrauer category, together with a full functor to the category of\nfinite-dimensional, type $1$ modules for $U_q(\\mathfrak{so}(N))$ or\n$U_q(\\mathfrak{o}(N))$. This functor becomes essentially surjective after\npassing to the idempotent completion. The quantum spin Brauer category can be\nthought of as a quantum version of the spin Brauer category introduced\npreviously by the authors. Alternatively, it is an enlargement of the Kauffman\ncategory, obtained by adding a generating object corresponding to the quantum\nspin module.","main_category":"math.QA","categories":"math.QA,math.RT","published":"2025-04-23T11:06:25Z"}
{"aid":"http://arxiv.org/abs/2504.16622v1","title":"Cognitive Silicon: An Architectural Blueprint for Post-Industrial\n  Computing Systems","summary":"Autonomous AI systems reveal foundational limitations in deterministic,\nhuman-authored computing architectures. This paper presents Cognitive Silicon:\na hypothetical full-stack architectural framework projected toward 2035,\nexploring a possible trajectory for cognitive computing system design. The\nproposed architecture would integrate symbolic scaffolding, governed memory,\nruntime moral coherence, and alignment-aware execution across\nsilicon-to-semantics layers. Our design grammar has emerged from dialectical\nco-design with LLMs under asymmetric epistemic conditions--creating structured\nfriction to expose blind spots and trade-offs. The envisioned framework would\nestablish mortality as a natural consequence of physical constraints,\nnon-copyable tacit knowledge, and non-cloneable identity keys as\ncognitive-embodiment primitives. Core tensions (trust/agency,\nscaffolding/emergence, execution/governance) would function as central\narchitectural pressures rather than edge cases. The architecture theoretically\nconverges with the Free Energy Principle, potentially offering a formal account\nof how cognitive systems could maintain identity through prediction error\nminimization across physical and computational boundaries. The resulting\nframework aims to deliver a morally tractable cognitive infrastructure that\ncould maintain human-alignment through irreversible hardware constraints and\nidentity-bound epistemic mechanisms resistant to replication or subversion.","main_category":"cs.AI","categories":"cs.AI,cs.CY","published":"2025-04-23T11:24:30Z"}
{"aid":"http://arxiv.org/abs/2504.16626v1","title":"Solvability of elliptic homogeneous linear equations with measure data\n  in weighted Lebesgue spaces","summary":"Let $A(D)$ be an elliptic homogeneous linear differential operator with\ncomplex constant coefficients, $ \\mu $ be a vector-valued Borel measure and $w$\nbe a positive locally integrable function on $\\mathbb{R}^N$. In this work, we\npresent sufficient conditions on $\\mu$ and $w$ for the existence of solutions\nin the weighted Lebesgue spaces $L^p_w$ for the equation $A^{*}(D)f=\\mu$, for $\n1\\leq p<\\infty $. Those conditions are related to a certain control of the\nRiesz potential of the measure $\\mu$. We also present sufficient conditions for\nthe solvability when $p=\\infty$ adding a canceling condition on the operator.\nOur method is based on a new weighted $L^1$ Stein-Weiss type inequality on\nmeasures for a special class of vector fields.","main_category":"math.AP","categories":"math.AP","published":"2025-04-23T11:33:46Z"}
{"aid":"http://arxiv.org/abs/2504.16648v1","title":"FAST Observation and Results for Core Collapse Globular Cluster M15 and\n  NGC 6517","summary":"Radio astronomy is part of radio science that developed rapidly in recent\ndecades. In the research of radio astronomy, pulsars have always been an\nenduring popular research target. To find and observe more pulsars, large radio\ntelescopes have been built all over the world. In this paper, we present our\nstudies on pulsars in M15 and NGC 6517 with FAST, including monitoring pulsars\nin M15 and new pulsar discoveries in NGC 6517. All the previously known pulsars\nin M15 were detected without no new discoveries. Among them, M15C was still\ndetectable by FAST, while it is assumed to fade out due to precession [1]. In\nNGC 6517, new pulsars were continues to be discovered and all of them are tend\nto be isolated pulsars. Currently, the number of pulsars in NGC 6517 is 17,\nmuch more than the predicted before [2].","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-23T12:10:04Z"}
{"aid":"http://arxiv.org/abs/2504.16650v1","title":"Small Alfv√©n Number Limit for the Global-in-time Solutions of\n  Incompressible MHD Equations with General Initial Data","summary":"The small Alfv\\'en number (denoted by $\\varepsilon$) limit (one type of large\nparameter limits, i.e. singular limits) in magnetohydrodynamic (abbr. MHD)\nequations was first proposed by Klainerman--Majda in (Comm. Pure Appl. Math.\n34: 481--524, 1981). Recently Ju--Wang--Xu mathematically verified that the\n\\emph{local-in-time} solutions of three-dimensional (abbr. 3D) ideal (i.e. the\nabsence of the dissipative terms) incompressible MHD equations with general\ninitial data in $\\mathbb{T}^3$ (i.e. a spatially periodic domain) tend to a\nsolution of 2D ideal MHD equations in the distribution sense as $\\varepsilon\\to\n0$ by Schochet's fast averaging method in (J. Differential Equations, 114:\n476--512, 1994). In this paper, we revisit the small Alfv\\'en number limit in\n$\\mathbb{R}^n$ with $n=2$, $3$, and develop another approach, motivated by\nCai--Lei's energy method in (Arch. Ration. Mech. Anal. 228: 969--993, 2018), to\nestablish a new conclusion that the \\emph{global-in-time} solutions of\nincompressible MHD equations (including the viscous resistive case) with\ngeneral initial data converge to zero as $\\varepsilon\\to 0$ for any given\ntime-space variable $(x,t)$ with $t>0$. In addition, we find that the large\nperturbation solutions and vanishing phenomenon of the nonlinear interactions\nalso exist in the \\emph{viscous resistive} MHD equations for small Alfv\\'en\nnumbers, and thus extend Bardos et al.'s results of the \\emph{ideal} MHD\nequations in (Trans Am Math Soc 305: 175--191, 1988).","main_category":"math.AP","categories":"math.AP","published":"2025-04-23T12:10:45Z"}
{"aid":"http://arxiv.org/abs/2504.16653v1","title":"Photo-generated charge-transfer excitons in NiO revealed by ultrafast\n  time-resolved resonant inelastic x-ray scattering","summary":"Strong electronic correlation can lead to insulating behavior and to the\nopening of large optical gaps, even in materials with partly filled valence\nshells. Although the non-equilibrium optical response encodes both local (quasi\natomic) and collective (long range) responses, optical spectroscopy is usually\nmore sensitive to the latter. Resonant x-ray techniques are better suited to\ninvestigate the quasi-atomic properties of correlated solids. Using\ntime-resolved resonant inelastic x-ray scattering (RIXS), here we study the\nultrafast non-equilibrium processes in NiO following photo-excitation by\nultraviolet photons with energy exceeding the optical gap. We observe the\ncreation of charge-transfer excitons that decay with a time constant of about\n2\\,ps, while itinerant photo-doping persists for tens of picoseconds. Following\nour discovery, which establishes time-resolved high-resolution RIXS as a\npowerful tool for the study of transient phenomena in condensed matter, the\npossible presence of charge-transfer excitons will need to be considered when\ninterpreting optical pump-probe experiments on correlated quantum materials.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-23T12:19:33Z"}
{"aid":"http://arxiv.org/abs/2504.16655v1","title":"WiFi based Human Fall and Activity Recognition using Transformer based\n  Encoder Decoder and Graph Neural Networks","summary":"Human pose estimation and action recognition have received attention due to\ntheir critical roles in healthcare monitoring, rehabilitation, and assistive\ntechnologies. In this study, we proposed a novel architecture named Transformer\nbased Encoder Decoder Network (TED Net) designed for estimating human skeleton\nposes from WiFi Channel State Information (CSI). TED Net integrates\nconvolutional encoders with transformer based attention mechanisms to capture\nspatiotemporal features from CSI signals. The estimated skeleton poses were\nused as input to a customized Directed Graph Neural Network (DGNN) for action\nrecognition. We validated our model on two datasets: a publicly available multi\nmodal dataset for assessing general pose estimation, and a newly collected\ndataset focused on fall related scenarios involving 20 participants.\nExperimental results demonstrated that TED Net outperformed existing approaches\nin pose estimation, and that the DGNN achieves reliable action classification\nusing CSI based skeletons, with performance comparable to RGB based systems.\nNotably, TED Net maintains robust performance across both fall and non fall\ncases. These findings highlight the potential of CSI driven human skeleton\nestimation for effective action recognition, particularly in home environments\nsuch as elderly fall detection. In such settings, WiFi signals are often\nreadily available, offering a privacy preserving alternative to vision based\nmethods, which may raise concerns about continuous camera monitoring.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T12:22:24Z"}
{"aid":"http://arxiv.org/abs/2504.16668v1","title":"Efficient Data Valuation Approximation in Federated Learning: A\n  Sampling-based Approach","summary":"Federated learning paradigm to utilize datasets across multiple data\nproviders. In FL, cross-silo data providers often hesitate to share their\nhigh-quality dataset unless their data value can be fairly assessed. Shapley\nvalue (SV) has been advocated as the standard metric for data valuation in FL\ndue to its desirable properties. However, the computational overhead of SV is\nprohibitive in practice, as it inherently requires training and evaluating an\nFL model across an exponential number of dataset combinations. Furthermore,\nexisting solutions fail to achieve high accuracy and efficiency, making\npractical use of SV still out of reach, because they ignore choosing suitable\ncomputation scheme for approximation framework and overlook the property of\nutility function in FL. We first propose a unified stratified-sampling\nframework for two widely-used schemes. Then, we analyze and choose the more\npromising scheme under the FL linear regression assumption. After that, we\nidentify a phenomenon termed key combinations, where only limited dataset\ncombinations have a high-impact on final data value. Building on these\ninsights, we propose a practical approximation algorithm, IPSS, which\nstrategically selects high-impact dataset combinations rather than evaluating\nall possible combinations, thus substantially reducing time cost with minor\napproximation error. Furthermore, we conduct extensive evaluations on the FL\nbenchmark datasets to demonstrate that our proposed algorithm outperforms a\nseries of representative baselines in terms of efficiency and effectiveness.","main_category":"cs.LG","categories":"cs.LG,cs.DB","published":"2025-04-23T12:36:20Z"}
{"aid":"http://arxiv.org/abs/2504.16670v1","title":"Open Source Software Lifecycle Classification: Developing Wrangling\n  Techniques for Complex Sociotechnical Systems","summary":"Open source software is a rapidly evolving center for distributed work, and\nunderstanding the characteristics of this work across its different contexts is\nvital for informing policy, economics, and the design of enabling software. The\nsteep increase in open source projects and corporate participation have\ntransformed a peripheral, cottage industry component of the global technology\necosystem into a large, infinitely complex \"technology parts supplier\" wired\ninto every corner of contemporary life. The lack of theory and tools for\nbreaking this complexity down into identifiable project types or strategies for\nunderstanding them more systematically is incommensurate with current industry,\nsociety, and developer needs. This paper reviews previous attempts to classify\nopen source software and other organizational ecosystems, using open source\nscientific software ecosystems in contrast with those found in corporatized\nopen source software. It then examines the divergent and sometimes conflicting\npurposes that may exist for classifying open source projects and how these\ncompeting interests impede our progress in developing a comprehensive\nunderstanding of how open source software projects and companies operate.\nFinally, we will present an empirical, mixed-methods study demonstrating how to\nclassify open-source projects by their lifecycle position. This is the first\nstep forward, advancing our scientific and practical knowledge of open source\nsoftware through the lens of dynamic and evolving open source genres. It\nconcludes with examples and a proposed path forward.","main_category":"cs.SE","categories":"cs.SE,cs.HC,H.4","published":"2025-04-23T12:37:53Z"}
{"aid":"http://arxiv.org/abs/2504.16675v1","title":"A Novel Sparse Sum and Difference Co-Array With Low Redundancy and\n  Enhanced DOF for Non-Circular Signals","summary":"Array structures based on the sum and difference co-arrays provide more\ndegrees of freedom (DOF). However, since the growth of DOF is limited by a\nsingle case of sum and difference co-arrays, the paper aims to design a sparse\nlinear array (SLA) with higher DOF via exploring different cases of\nsecond-order cumulants. We present a mathematical framework based on\nsecond-order cumulant to devise a second-order extended co-array (SO-ECA) and\ndefine the redundancy of SO-ECA. Based on SO-ECA, a novel array is proposed,\nnamely low redundancy sum and difference array (LR-SDA), which can provide\nclosed-form expressions for the sensor positions and enhance DOF in order to\nresolve more signal sources in the direction of arrival (DOA) estimation of\nnon-circular (NC) signals. For LR-SDA, the maximum DOF under the given number\nof total physical sensors can be derived and the SO-ECA of LR-SDA is hole-free.\nFurther, the corresponding necessary and sufficient conditions of signal\nreconstruction for LR-SDA are derived. Additionally, the redundancy and weight\nfunction of LR-SDA are defined, and the lower band of the redundancy for LR-SDA\nis derived. The proposed LR-SDA achieves higher DOF and lower redundancy than\nthose of existing DCAs designed based on sum and difference co-arrays.\nNumerical simulations are conducted to verify the superiority of LR-SDA on DOA\nestimation performance and enhanced DOF over other existing DCAs.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-23T12:45:06Z"}
{"aid":"http://arxiv.org/abs/2504.16697v1","title":"On deciding transcendence of power series","summary":"It is well known that algebraic power series are differentially finite\n(D-finite): they satisfy linear differential equations with polynomial\ncoefficients. The converse problem, whether a given D-finite power series is\nalgebraic or transcendental, is notoriously difficult. We prove that this\nproblem is decidable: we give two theoretical algorithms and a transcendence\ntest that is efficient in practice.","main_category":"math.NT","categories":"math.NT,cs.SC,math.CA","published":"2025-04-23T13:28:05Z"}
{"aid":"http://arxiv.org/abs/2504.16708v1","title":"Density of rational languages under shift invariant measures","summary":"We study density of rational languages under shift invariant probability\nmeasures on spaces of two-sided infinite words, which generalizes the classical\nnotion of density studied in formal languages and automata theory. The density\nfor a language is defined as the limit in average (if it exists) of the\nprobability that a word of a given length belongs to the language. We establish\nthe existence of densities for all rational languages under all shift invariant\nmeasures. We also give explicit formulas under certain conditions, in\nparticular when the language is aperiodic. Our approach combines tools and\nideas from semigroup theory and ergodic theory.","main_category":"cs.FL","categories":"cs.FL","published":"2025-04-23T13:39:02Z"}
{"aid":"http://arxiv.org/abs/2504.16721v1","title":"Spectrum of cones of non-reduced plane curves with ordinary\n  singularities","summary":"We give a simple proof of the assertion claiming that the spectrum of the\ncone of a non-reduced plane curve can be determined only by its multiplicities\nalong local irreducible components at each singular point as well as those\nalong global ones together with the degrees of the latter (where the relation\nbetween global components and singular points is not needed) if the associated\nreduced plane curve have only ordinary singularities (for instance a line\narrangement). Note that the last condition is strictly weaker than local\nhomogeneity. As a corollary we can also get a simple proof of a formula which\nis equivalent to the one obtained earlier by the second-named author.","main_category":"math.AG","categories":"math.AG","published":"2025-04-23T13:51:18Z"}
{"aid":"http://arxiv.org/abs/2504.16722v1","title":"PMG: Progressive Motion Generation via Sparse Anchor Postures Curriculum\n  Learning","summary":"In computer animation, game design, and human-computer interaction,\nsynthesizing human motion that aligns with user intent remains a significant\nchallenge. Existing methods have notable limitations: textual approaches offer\nhigh-level semantic guidance but struggle to describe complex actions\naccurately; trajectory-based techniques provide intuitive global motion\ndirection yet often fall short in generating precise or customized character\nmovements; and anchor poses-guided methods are typically confined to synthesize\nonly simple motion patterns. To generate more controllable and precise human\nmotions, we propose \\textbf{ProMoGen (Progressive Motion Generation)}, a novel\nframework that integrates trajectory guidance with sparse anchor motion\ncontrol. Global trajectories ensure consistency in spatial direction and\ndisplacement, while sparse anchor motions only deliver precise action guidance\nwithout displacement. This decoupling enables independent refinement of both\naspects, resulting in a more controllable, high-fidelity, and sophisticated\nmotion synthesis. ProMoGen supports both dual and single control paradigms\nwithin a unified training process. Moreover, we recognize that direct learning\nfrom sparse motions is inherently unstable, we introduce \\textbf{SAP-CL (Sparse\nAnchor Posture Curriculum Learning)}, a curriculum learning strategy that\nprogressively adjusts the number of anchors used for guidance, thereby enabling\nmore precise and stable convergence. Extensive experiments demonstrate that\nProMoGen excels in synthesizing vivid and diverse motions guided by predefined\ntrajectory and arbitrary anchor frames. Our approach seamlessly integrates\npersonalized motion with structured guidance, significantly outperforming\nstate-of-the-art methods across multiple control scenarios.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-23T13:51:42Z"}
{"aid":"http://arxiv.org/abs/2504.16730v1","title":"Extremal divisors on moduli spaces of K3 surfaces","summary":"We establish numerical criteria for when a Noether-Lefschetz divisor on a\nmoduli space of quasi-polarized K3 surfaces $F_{2d}$, or more generally on an\northogonal modular variety, generates an extremal ray in the cone of\npseudoeffective divisors. In particular, for all d, we exhibit many extremal\nrays of the cone of pseudoeffective divisors of both $F_{2d}$ and any normal\nprojective $\\mathbb{Q}$-factorial compactification of $F_{2d}$ lying over its\nBaily-Borel compactification.","main_category":"math.AG","categories":"math.AG,math.NT","published":"2025-04-23T14:01:41Z"}
{"aid":"http://arxiv.org/abs/2504.16735v1","title":"An Expressive Coalgebraic Modal Logic for Cellular Automata","summary":"Cellular automata provide models of parallel computation based on cells,\nwhose connectivity is given by an action of a monoid on the cells. At each step\nin the computation, every cell is decorated with a state that evolves in\ndiscrete steps according to a local update rule, which determines the next\nstate of a cell based on its neighbour's states. In this paper, we consider a\ncoalgebraic view on cellular automata, which does not require typical\nrestrictions, such as uniform neighbourhood connectivity and uniform local\nrules. Using the coalgebraic view, we devise a behavioural equivalence for\ncellular automata and a modal logic to reason about their behaviour. We then\nprove a Hennessy-Milner style theorem, which states that pairs of cells satisfy\nthe same modal formulas exactly if they are identified under cellular\nbehavioural equivalence.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-23T14:05:29Z"}
{"aid":"http://arxiv.org/abs/2504.16736v1","title":"A Survey of AI Agent Protocols","summary":"The rapid development of large language models (LLMs) has led to the\nwidespread deployment of LLM agents across diverse industries, including\ncustomer service, content generation, data analysis, and even healthcare.\nHowever, as more LLM agents are deployed, a major issue has emerged: there is\nno standard way for these agents to communicate with external tools or data\nsources. This lack of standardized protocols makes it difficult for agents to\nwork together or scale effectively, and it limits their ability to tackle\ncomplex, real-world tasks. A unified communication protocol for LLM agents\ncould change this. It would allow agents and tools to interact more smoothly,\nencourage collaboration, and triggering the formation of collective\nintelligence. In this paper, we provide a systematic overview of existing\ncommunication protocols for LLM agents. We classify them into four main\ncategories and make an analysis to help users and developers select the most\nsuitable protocols for specific applications. Additionally, we conduct a\ncomparative performance analysis of these protocols across key dimensions such\nas security, scalability, and latency. Finally, we explore future challenges,\nsuch as how protocols can adapt and survive in fast-evolving environments, and\nwhat qualities future protocols might need to support the next generation of\nLLM agent ecosystems. We expect this work to serve as a practical reference for\nboth researchers and engineers seeking to design, evaluate, or integrate robust\ncommunication infrastructures for intelligent agents.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-23T14:07:26Z"}
{"aid":"http://arxiv.org/abs/2504.16737v1","title":"Scaling limints for supercritical nearly unstable Hawkes processes with\n  hheavy tail","summary":"In this paper, we establish the asymptotic behavior of {\\it supercritical}\nnearly unstable Hawkes processes with a power law kernel. We find that, the\nHawkes process in our context admits a similar equation to that in\n\\cite{MR3563196} for {\\it subcritical} case. In particular, the rescaled Hawkes\nprocess $(Z^n_{nt}/n^{2\\alpha})_{t\\in[0,1]}$ converges in law to a kind of\nintegrated fractional Cox Ingersoll Ross process with different coefficients\nfrom that in \\cite{MR3563196}, as $n$ tends to infinity.","main_category":"math.PR","categories":"math.PR","published":"2025-04-23T14:08:53Z"}
{"aid":"http://arxiv.org/abs/2504.16741v1","title":"Search Timelines: Visualizing Search History to Enable Cross-Session\n  Exploratory Search","summary":"Purpose: The timespan over which exploratory searching can occur, as well as\nthe scope and volume of the search activities undertaken, can make it difficult\nfor searchers to remember key details about their search activities. These\ndifficulties are present both in the midst of searching as well as when\nresuming a search that spans multiple sessions. In this paper, we present a\nsearch interface designed to support cross-session exploratory search in a\npublic digital library context. Methods: Search Timelines provides a\nvisualization of current and past search activities via a dynamic timeline of\nthe search activity (queries and saved resources). This timeline is presented\nat two levels of detail. An overview timeline is provided alongside the search\nresults in a typical search engine results page design. A detailed timeline is\nprovided in the workspace, where searchers can review the history of their\nsearch activities and their saved resources. A controlled laboratory study was\nconducted to compare this approach to a baseline interface modelled after a\ntypical public digital library search/workspace interface. Results:\nParticipants who used Search Timelines reported higher levels of user\nengagement, usability, and perceived knowledge gain, during an initial search\nsession and when resuming the search after a 7-8 day interval. This came at the\nexpense of the searchers taking more time to complete the search task, which we\nview as positive evidence of engagement in cross-session exploratory search\nprocesses. Conclusion: Search Timelines serves as an example of how lightweight\nvisualization approaches can be used to enhance typical search interface\ndesigns to support exploratory search. The results highlight the value of\nproviding persistent representations of past search activities within the\nsearch interface.","main_category":"cs.HC","categories":"cs.HC,cs.IR","published":"2025-04-23T14:10:36Z"}
{"aid":"http://arxiv.org/abs/2504.16745v1","title":"Frequency-Compensated Network for Daily Arctic Sea Ice Concentration\n  Prediction","summary":"Accurately forecasting sea ice concentration (SIC) in the Arctic is critical\nto global ecosystem health and navigation safety. However, current methods\nstill is confronted with two challenges: 1) these methods rarely explore the\nlong-term feature dependencies in the frequency domain. 2) they can hardly\npreserve the high-frequency details, and the changes in the marginal area of\nthe sea ice cannot be accurately captured. To this end, we present a\nFrequency-Compensated Network (FCNet) for Arctic SIC prediction on a daily\nbasis. In particular, we design a dual-branch network, including branches for\nfrequency feature extraction and convolutional feature extraction. For\nfrequency feature extraction, we design an adaptive frequency filter block,\nwhich integrates trainable layers with Fourier-based filters. By adding\nfrequency features, the FCNet can achieve refined prediction of edges and\ndetails. For convolutional feature extraction, we propose a high-frequency\nenhancement block to separate high and low-frequency information. Moreover,\nhigh-frequency features are enhanced via channel-wise attention, and temporal\nattention unit is employed for low-frequency feature extraction to capture\nlong-range sea ice changes. Extensive experiments are conducted on a\nsatellite-derived daily SIC dataset, and the results verify the effectiveness\nof the proposed FCNet. Our codes and data will be made public available at:\nhttps://github.com/oucailab/FCNet .","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-23T14:15:48Z"}
{"aid":"http://arxiv.org/abs/2504.16782v1","title":"Graph2Nav: 3D Object-Relation Graph Generation to Robot Navigation","summary":"We propose Graph2Nav, a real-time 3D object-relation graph generation\nframework, for autonomous navigation in the real world. Our framework fully\ngenerates and exploits both 3D objects and a rich set of semantic relationships\namong objects in a 3D layered scene graph, which is applicable to both indoor\nand outdoor scenes. It learns to generate 3D semantic relations among objects,\nby leveraging and advancing state-of-the-art 2D panoptic scene graph works into\nthe 3D world via 3D semantic mapping techniques. This approach avoids previous\ntraining data constraints in learning 3D scene graphs directly from 3D data. We\nconduct experiments to validate the accuracy in locating 3D objects and\nlabeling object-relations in our 3D scene graphs. We also evaluate the impact\nof Graph2Nav via integration with SayNav, a state-of-the-art planner based on\nlarge language models, on an unmanned ground robot to object search tasks in\nreal environments. Our results demonstrate that modeling object relations in\nour scene graphs improves search efficiency in these navigation tasks.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-23T14:58:56Z"}
{"aid":"http://arxiv.org/abs/2504.16791v1","title":"Radiometer Calibration using Machine Learning","summary":"Radiometers are crucial instruments in radio astronomy, forming the primary\ncomponent of nearly all radio telescopes. They measure the intensity of\nelectromagnetic radiation, converting this radiation into electrical signals. A\nradiometer's primary components are an antenna and a Low Noise Amplifier (LNA),\nwhich is the core of the ``receiver'' chain. Instrumental effects introduced by\nthe receiver are typically corrected or removed during calibration. However,\nimpedance mismatches between the antenna and receiver can introduce unwanted\nsignal reflections and distortions. Traditional calibration methods, such as\nDicke switching, alternate the receiver input between the antenna and a\nwell-characterised reference source to mitigate errors by comparison. Recent\nadvances in Machine Learning (ML) offer promising alternatives. Neural\nnetworks, which are trained using known signal sources, provide a powerful\nmeans to model and calibrate complex systems where traditional analytical\napproaches struggle. These methods are especially relevant for detecting the\nfaint sky-averaged 21-cm signal from atomic hydrogen at high redshifts. This is\none of the main challenges in observational Cosmology today. Here, for the\nfirst time, we introduce and test a machine learning-based calibration\nframework capable of achieving the precision required for radiometric\nexperiments aiming to detect the 21-cm line.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.CO,cs.AI","published":"2025-04-23T15:10:25Z"}
{"aid":"http://arxiv.org/abs/2504.16793v1","title":"A self-avoiding curve associated with sums of digits","summary":"For each $n\\in N ^{\\ast }$, we write $s_{n}=\\left( 1,\\ldots ,1,0\\right) $\nwith $n$ times $1$. For each $a \\in N$, we consider the binary representation\n$\\left( a_{i}\\right) _{i\\in -N }$ of $a$ with $a_{i}=0$ for nearly each $i$; we\ndenote by $\\alpha _{n}(a)$ the number of integers $i$ such that $\\left( a_{i},\n\\ldots ,a_{i+n} \\right) =s_{n}$. We consider the curve $C_{n}=\\left(\nS_{n,k}\\right) _{k\\in N ^{\\ast }}$ which consists of consecutive segments of\nlength $1$ such that, for each $k$, $S_{n,k+1}$ is obtained from $S_{n,k}$ by\nturning right if $k+\\alpha _{n}(k)-\\alpha _{n}(k-1)$ is even and left\notherwise. $C_{1}$ is self-avoiding since it is the curve associated to the\nalternating folding sequence. In [1], M. Mend\\`es France and J. Shallit\nconjectured that the curves $C_{n}$ for $n\\geq 2$ are also self-avoiding. In\nthe present paper, we show that this property is true for $n=2$. We also prove\nthat $C_{2}$ has some properties similar to those which were shown in [2], [3]\nand [4] for folding curves.","main_category":"math.CO","categories":"math.CO","published":"2025-04-23T15:13:11Z"}
{"aid":"http://arxiv.org/abs/2504.16818v1","title":"Rediscussion of eclipsing binaries. Paper XXIV. The delta Scuti pulsator\n  V596 Pup (formerly known as VV Pyx)","summary":"V596 Pup is a detached eclipsing binary containing two A1 V stars in a 4.596\nd period orbit with a small eccentricity and apsidal motion, previously\ndesignated as VV Pyxidis. We use new light curves from the Transiting Exoplanet\nSurvey Satellite (TESS) and published radial velocities to determine the\nphysical properties of the component stars. We find masses of 2.098 +/- 0.021\nMsun and 2.091 +/- 0.018 Msun, and radii of 2.179 +/- 0.008 Rsun and 2.139 +/-\n0.007 Rsun. The measured distance to the system is affected by the light from a\nnearby companion star; we obtain 178.4 +/- 2.5 pc. The properties of the system\nare best matched by theoretical predictions for a subsolar metallicity of Z =\n0.010 and an age of 570 Myr. We measure seven significant pulsation frequencies\nfrom the light curve, six of which are consistent with delta Scuti pulsations\nand one of which is likely of slowly-pulsating B-star type.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-23T15:37:29Z"}
{"aid":"http://arxiv.org/abs/2504.16824v1","title":"Nurturing Language Proficiency in Spanish.speaking children Through\n  digital competence","summary":"This article explores into the intricate design and meticulous construction\nof a digital platform aimed at revolutionizing early-age English education,\nparticularly for Spanish-speaking children. The focus of this work used an\ninnovative methodologies, vibrant and engaging visuals, and a comprehensive\napproach to phonics. The principles of usability, accessibility, and\nuser-centered design are intricately woven into every facet of the platform's\narchitecture.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-23T15:41:12Z"}
{"aid":"http://arxiv.org/abs/2504.16826v1","title":"Modeling a Non-Singular Universe with Late-Time Acceleration through a\n  Novel Inhomogeneous Barotropic Equation of State","summary":"In this study, we investigated the effects of incorporating barotropic fluids\non cosmological solutions within the general relativity (GR) framework. We\nproposed a modified version of the barotropic fluid with the EoS, $p=\\zeta _0\n\\rho +\\zeta _1 \\rho \\left(t-t_0\\right){}^{-2 n}$, where $\\zeta_0$, $\\zeta_1$,\n$t_0$ and $n$ are some constants. Our goal is to explore if this type of EoS\nmight help explain the universe's development, concentrating on the scenario\nwhere the universe bounces instead of singularities. Interestingly the generic\nsolutions derived from our model are sufficiently adaptable to illustrate the\nbounce scenario, cosmic inflation and late-time dark-energy behaviour. The\nparameters $\\zeta_0$, $\\zeta_1$, $t_0$, and $n$ define the universe's phase in\nthis non-singular solution. We investigated several elements of cosmic\ndevelopment, including as the energy density, deceleration parameter, and\nenergy conditions, in order to validate our model. Stability analysis showed\nthat the perturbations approach to zero as the time evolves, indicating the\nmodel is stable under scalar perturbation. Additionally, we looked at the\nstatefinder diagnostics and Hubble flow dynamics to get more understanding of\nthe model's dark energy and inflationary behaviour, respectively. Additionally,\nwe conducted a study of the models' relevance to the observational datasets\nfrom BAO, DESI and Pantheon+SH0ES.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-23T15:43:02Z"}
{"aid":"http://arxiv.org/abs/2504.16832v1","title":"GreenMind: A Next-Generation Vietnamese Large Language Model for\n  Structured and Logical Reasoning","summary":"Chain-of-Thought (CoT) is a robust approach for tackling LLM tasks that\nrequire intermediate reasoning steps prior to generating a final answer. In\nthis paper, we present GreenMind-Medium-14B-R1, the Vietnamese reasoning model\ninspired by the finetuning strategy based on Group Relative Policy\nOptimization. We also leverage a high-quality Vietnamese synthesized reasoning\ndataset and design two reward functions to tackle the main limitations of this\ntechnique: (i) language mixing, where we explicitly detect the presence of\nbiased language characters during the process of sampling tokens, and (ii) we\nleverage Sentence Transformer-based models to ensure that the generated\nreasoning content maintains factual correctness and does not distort the final\noutput. Experimental results on the Vietnamese dataset from the VLSP 2023\nChallenge demonstrate that our model outperforms prior works and enhances\nlinguistic consistency in its responses. Furthermore, we extend our evaluation\nto SeaExam-a multilingual multiple-choice dataset, showing the effectiveness of\nour reasoning method compared to few-shot prompting techniques.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-23T15:48:55Z"}
{"aid":"http://arxiv.org/abs/2504.16837v1","title":"Approximating Optimal Labelings for Temporal Connectivity","summary":"In a temporal graph the edge set dynamically changes over time according to a\nset of time-labels associated with each edge that indicates at which time-steps\nthe edge is available. Two vertices are connected if there is a path connecting\nthem in which the edges are traversed in increasing order of their labels. We\nstudy the problem of scheduling the availability time of the edges of a\ntemporal graph in such a way that all pairs of vertices are connected within a\ngiven maximum allowed time $a$ and the overall number of labels is minimized.\n  The problem, known as \\emph{Minimum Aged Labeling} (MAL), has several\napplications in logistics, distribution scheduling, and information spreading\nin social networks, where carefully choosing the time-labels can significantly\nreduce infrastructure costs, fuel consumption, or greenhouse gases.\n  The problem MAL has previously been proved to be NP-complete on undirected\ngraphs and \\APX-hard on directed graphs. In this paper, we extend our knowledge\non the complexity and approximability of MAL in several directions. We first\nshow that the problem cannot be approximated within a factor better than\n$O(\\log n)$ when $a\\geq 2$, unless $\\text{P} = \\text{NP}$, and a factor better\nthan $2^{\\log ^{1-\\epsilon} n}$ when $a\\geq 3$, unless $\\text{NP}\\subseteq\n\\text{DTIME}(2^{\\text{polylog}(n)})$, where $n$ is the number of vertices in\nthe graph. Then we give a set of approximation algorithms that, under some\nconditions, almost match these lower bounds. In particular, we show that the\napproximation depends on a relation between $a$ and the diameter of the input\ngraph.\n  We further establish a connection with a foundational optimization problem on\nstatic graphs called \\emph{Diameter Constrained Spanning Subgraph} (DCSS) and\nshow that our hardness results also apply to DCSS.","main_category":"cs.DS","categories":"cs.DS,cs.AI","published":"2025-04-23T16:00:33Z"}
{"aid":"http://arxiv.org/abs/2504.16842v1","title":"Bertrand Menu Competition","summary":"We study a variation of the price competition model a la Bertrand, in which\nfirms must offer menus of contracts that obey monotonicity constraints, e.g.,\nwages that rise with worker productivity to comport with equal pay legislation.\nWhile such constraints limit firms' ability to undercut their competitors, we\nshow that Bertrand's classic result still holds: competition drives firm\nprofits to zero and leads to efficient allocations without rationing. Our\nfindings suggest that Bertrand's logic extends to a broader variety of markets,\nincluding labor and product markets that are subject to real-world constraints\non pricing across workers and products.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-23T16:06:09Z"}
{"aid":"http://arxiv.org/abs/2504.16844v1","title":"Boundary anomalous dimensions from BCFT: O($N$)-symmetric $œÜ^{2n}$\n  theories with a boundary and higher-derivative generalizations","summary":"We investigate the $\\phi^{2n}$ deformations of the O($N$)-symmetric\n(generalized) free theories with a flat boundary, where $n\\geqslant 2$ is an\ninteger. The generalized free theories refer to the $\\Box^k$ free scalar\ntheories with a higher-derivative kinetic term, which is related to the\nmulticritical generalizations of the Lifshitz type. We assume that the\n(generalized) free theories and the deformed theories have boundary conformal\nsymmetry and O($N$) global symmetry. The leading anomalous dimensions of some\nboundary operators are derived from the bulk multiplet recombination and\nanalyticity constraints. We find that the $\\epsilon^{1/2}$ expansion in the\n$\\phi^6$-tricritical version of the special transition extends to other\nmulticritical cases with larger odd integer $n$, and most of the higher\nderivative cases involve a noninteger power expansion in $\\epsilon$. Using the\nanalytic bootstrap, we further verify that the multiplet-recombination results\nare consistent with boundary crossing symmetry.","main_category":"hep-th","categories":"hep-th,cond-mat.stat-mech","published":"2025-04-23T16:08:28Z"}
{"aid":"http://arxiv.org/abs/2504.16855v1","title":"Monte Carlo Planning with Large Language Model for Text-Based Game\n  Agents","summary":"Text-based games provide valuable environments for language-based autonomous\nagents. However, planning-then-learning paradigms, such as those combining\nMonte Carlo Tree Search (MCTS) and reinforcement learning (RL), are notably\ntime-consuming due to extensive iterations. Additionally, these algorithms\nperform uncertainty-driven exploration but lack language understanding and\nreasoning abilities. In this paper, we introduce the Monte Carlo planning with\nDynamic Memory-guided Large language model (MC-DML) algorithm. MC-DML leverages\nthe language understanding and reasoning capabilities of Large Language Models\n(LLMs) alongside the exploratory advantages of tree search algorithms.\nSpecifically, we enhance LLMs with in-trial and cross-trial memory mechanisms,\nenabling them to learn from past experiences and dynamically adjust action\nevaluations during planning. We conduct experiments on a series of text-based\ngames from the Jericho benchmark. Our results demonstrate that the MC-DML\nalgorithm significantly enhances performance across various games at the\ninitial planning phase, outperforming strong contemporary methods that require\nmultiple iterations. This demonstrates the effectiveness of our algorithm,\npaving the way for more efficient language-grounded planning in complex\nenvironments.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-23T16:23:15Z"}
{"aid":"http://arxiv.org/abs/2504.16869v1","title":"Geometry of Cells Sensible to Curvature and Their Receptive Profiles","summary":"We propose a model of the functional architecture of curvature sensible cells\nin the visual cortex that associates curvature with scale. The feature space of\norientation and position is naturally enhanced via its oriented prolongation,\nyielding a 4-dimensional manifold endowed with a canonical Engel structure.\nThis structure encodes position, orientation, signed curvature, and scale. We\nassociate an open submanifold of the prolongation with the quasi-regular\nrepresentation of the similitude group SIM (2), and find left-invariant\ngenerators for the Engel structure. Finally, we use the generators of the Engel\nstructure to characterize curvature-sensitive receptive profiles .","main_category":"q-bio.NC","categories":"q-bio.NC,math.DG","published":"2025-04-23T16:44:25Z"}
{"aid":"http://arxiv.org/abs/2504.16889v1","title":"Characterization of a GAGG detector for neutron measurements in\n  underground laboratories","summary":"In rare events experiments, such as those devoted to the direct search of\ndark matter, a precise knowledge of the environmental gamma and neutron\nbackgrounds is crucial for reaching the design experiment sensitivity. The\nneutron component is often poorly known due to the lack of a scalable detector\ntechnology for the precise measurement of low-flux neutron spectra.\nGd$_3$Al$_2$Ga$_3$O$_{12}$ (GAGG) is a newly developed, high-density\nscintillating crystal with a high gadolinium content, which could allow to\nexploit the high $(n,\\gamma)$ cross section of $^{155}$Gd and $^{157}$Gd for\nneutron measurements in underground environments. GAGG crystals feature a high\nscintillation light yield, good timing performance, and the capability of\nparticle identification via pulse-shape discrimination. In a low-background\nenvironment, the distinctive signature produced by neutron capture on\ngadolinium, namely a $\\beta/\\gamma$ cascade releasing up to 9 MeV of total\nenergy, and the efficient particle identification provided by GAGG could yield\na background-free neutron capture signal. In this work, we present the\ncharacterization of a first GAGG detector prototype in terms of particle\ndiscrimination performance, intrinsic radioactive contamination, and neutron\nresponse.","main_category":"physics.ins-det","categories":"physics.ins-det,nucl-ex","published":"2025-04-23T17:08:26Z"}
{"aid":"http://arxiv.org/abs/2504.16901v1","title":"Characterizing fragments of collection principle in set theory with\n  model theoretic properties","summary":"We prove some model theoretic equivalent forms of variants of collection\nprinciple in set theory on models of a very weak set theory.","main_category":"math.LO","categories":"math.LO","published":"2025-04-23T17:27:17Z"}
{"aid":"http://arxiv.org/abs/2504.16907v1","title":"BadVideo: Stealthy Backdoor Attack against Text-to-Video Generation","summary":"Text-to-video (T2V) generative models have rapidly advanced and found\nwidespread applications across fields like entertainment, education, and\nmarketing. However, the adversarial vulnerabilities of these models remain\nrarely explored. We observe that in T2V generation tasks, the generated videos\noften contain substantial redundant information not explicitly specified in the\ntext prompts, such as environmental elements, secondary objects, and additional\ndetails, providing opportunities for malicious attackers to embed hidden\nharmful content. Exploiting this inherent redundancy, we introduce BadVideo,\nthe first backdoor attack framework tailored for T2V generation. Our attack\nfocuses on designing target adversarial outputs through two key strategies: (1)\nSpatio-Temporal Composition, which combines different spatiotemporal features\nto encode malicious information; (2) Dynamic Element Transformation, which\nintroduces transformations in redundant elements over time to convey malicious\ninformation. Based on these strategies, the attacker's malicious target\nseamlessly integrates with the user's textual instructions, providing high\nstealthiness. Moreover, by exploiting the temporal dimension of videos, our\nattack successfully evades traditional content moderation systems that\nprimarily analyze spatial information within individual frames. Extensive\nexperiments demonstrate that BadVideo achieves high attack success rates while\npreserving original semantics and maintaining excellent performance on clean\ninputs. Overall, our work reveals the adversarial vulnerability of T2V models,\ncalling attention to potential risks and misuse. Our project page is at\nhttps://wrt2000.github.io/BadVideo2025/.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-23T17:34:48Z"}
{"aid":"http://arxiv.org/abs/2504.17234v1","title":"Scene Perceived Image Perceptual Score (SPIPS): combining global and\n  local perception for image quality assessment","summary":"The rapid advancement of artificial intelligence and widespread use of\nsmartphones have resulted in an exponential growth of image data, both real\n(camera-captured) and virtual (AI-generated). This surge underscores the\ncritical need for robust image quality assessment (IQA) methods that accurately\nreflect human visual perception. Traditional IQA techniques primarily rely on\nspatial features - such as signal-to-noise ratio, local structural distortions,\nand texture inconsistencies - to identify artifacts. While effective for\nunprocessed or conventionally altered images, these methods fall short in the\ncontext of modern image post-processing powered by deep neural networks (DNNs).\nThe rise of DNN-based models for image generation, enhancement, and restoration\nhas significantly improved visual quality, yet made accurate assessment\nincreasingly complex. To address this, we propose a novel IQA approach that\nbridges the gap between deep learning methods and human perception. Our model\ndisentangles deep features into high-level semantic information and low-level\nperceptual details, treating each stream separately. These features are then\ncombined with conventional IQA metrics to provide a more comprehensive\nevaluation framework. This hybrid design enables the model to assess both\nglobal context and intricate image details, better reflecting the human visual\nprocess, which first interprets overall structure before attending to\nfine-grained elements. The final stage employs a multilayer perceptron (MLP) to\nmap the integrated features into a concise quality score. Experimental results\ndemonstrate that our method achieves improved consistency with human perceptual\njudgments compared to existing IQA models.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T04:06:07Z"}
{"aid":"http://arxiv.org/abs/2504.17262v1","title":"Hilbert Transform Technique for Analyzing Mode I Crack Growth in an Pre-\n  Stressed Monoclinic Crystalline Strip Under Punch Pressure","summary":"The crux of the present study is to analyze the Mode I crack propagation\nbehavior in a pre-stressed monoclinic crystalline strip of finite thickness and\ninfinite extent. The investigation focuses on the effects of collinear Griffith\ncracks and dynamic punch loading induced by plane wave propagation. The cracks\nare assumed to be in motion, and a Galilean transformation is employed to\nformulate the problem within a moving coordinate system. The boundary value\nproblem is transformed into a system of coupled Cauchy-type singular integral\nequations, which are solved analytically using the Hilbert transform method.\nThis approach yields elegant closed-form solutions for both the stress\nintensity factor and the crack opening displacement. The study considers two\nmonoclinic crystalline materials, Lithium Niobate and Lithium Tantalate, and\ncompares their behavior with that of an isotropic material to assess the role\nof material anisotropy. Numerical simulations and graphical analysis are\nperformed for the crystalline materials with monoclinic symmetry to evaluate\nthe influence of crack velocity, punch loading, material anisotropy, initial\nstress, and crack geometry on the fracture parameters. As a special case, the\nsystem is analyzed under the action of point loading from the punch pressure,\nand a comparative assessment is conducted between point loading and constant\nnormal punch pressure. The results unveil critical insights into the dynamic\nfracture behavior of anisotropic materials under localized loading. This\nunderstanding enhances failure prediction in high-precision fields such as\ngeomechanics, MEMS, surface acoustic devices, and biosensors.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-24T05:45:21Z"}
{"aid":"http://arxiv.org/abs/2504.17295v1","title":"AI-Enhanced Business Process Automation: A Case Study in the Insurance\n  Domain Using Object-Centric Process Mining","summary":"Recent advancements in Artificial Intelligence (AI), particularly Large\nLanguage Models (LLMs), have enhanced organizations' ability to reengineer\nbusiness processes by automating knowledge-intensive tasks. This automation\ndrives digital transformation, often through gradual transitions that improve\nprocess efficiency and effectiveness. To fully assess the impact of such\nautomation, a data-driven analysis approach is needed - one that examines how\ntraditional and AI-enhanced process variants coexist during this transition.\nObject-Centric Process Mining (OCPM) has emerged as a valuable method that\nenables such analysis, yet real-world case studies are still needed to\ndemonstrate its applicability. This paper presents a case study from the\ninsurance sector, where an LLM was deployed in production to automate the\nidentification of claim parts, a task previously performed manually and\nidentified as a bottleneck for scalability. To evaluate this transformation, we\napply OCPM to assess the impact of AI-driven automation on process scalability.\nOur findings indicate that while LLMs significantly enhance operational\ncapacity, they also introduce new process dynamics that require further\nrefinement. This study also demonstrates the practical application of OCPM in a\nreal-world setting, highlighting its advantages and limitations.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-24T06:43:29Z"}
{"aid":"http://arxiv.org/abs/2504.17304v1","title":"You Are What You Bought: Generating Customer Personas for E-commerce\n  Applications","summary":"In e-commerce, user representations are essential for various applications.\nExisting methods often use deep learning techniques to convert customer\nbehaviors into implicit embeddings. However, these embeddings are difficult to\nunderstand and integrate with external knowledge, limiting the effectiveness of\napplications such as customer segmentation, search navigation, and product\nrecommendations. To address this, our paper introduces the concept of the\ncustomer persona. Condensed from a customer's numerous purchasing histories, a\ncustomer persona provides a multi-faceted and human-readable characterization\nof specific purchase behaviors and preferences, such as Busy Parents or Bargain\nHunters.\n  This work then focuses on representing each customer by multiple personas\nfrom a predefined set, achieving readable and informative explicit user\nrepresentations. To this end, we propose an effective and efficient solution\nGPLR. To ensure effectiveness, GPLR leverages pre-trained LLMs to infer\npersonas for customers. To reduce overhead, GPLR applies LLM-based labeling to\nonly a fraction of users and utilizes a random walk technique to predict\npersonas for the remaining customers. We further propose RevAff, which provides\nan absolute error $\\epsilon$ guarantee while improving the time complexity of\nthe exact solution by a factor of at least\n$O(\\frac{\\epsilon\\cdot|E|N}{|E|+N\\log N})$, where $N$ represents the number of\ncustomers and products, and $E$ represents the interactions between them. We\nevaluate the performance of our persona-based representation in terms of\naccuracy and robustness for recommendation and customer segmentation tasks\nusing three real-world e-commerce datasets. Most notably, we find that\nintegrating customer persona representations improves the state-of-the-art\ngraph convolution-based recommendation model by up to 12% in terms of NDCG@K\nand F1-Score@K.","main_category":"cs.IR","categories":"cs.IR,cs.AI","published":"2025-04-24T06:59:16Z"}
{"aid":"http://arxiv.org/abs/2504.17321v1","title":"Dargana: fine-tuning EarthPT for dynamic tree canopy mapping from space","summary":"We present Dargana, a fine-tuned variant of the EarthPT time-series\nfoundation model that achieves specialisation using <3% of its pre-training\ndata volume and 5% of its pre-training compute. Dargana is fine-tuned to\ngenerate regularly updated classification of tree canopy cover at 10m\nresolution, distinguishing conifer and broadleaved tree types. Using Cornwall,\nUK, as a test case, the model achieves a pixel-level ROC-AUC of 0.98 and a\nPR-AUC of 0.83 on unseen satellite imagery. Dargana can identify fine\nstructures like hedgerows and coppice below the training sample limit, and can\ntrack temporal changes to canopy cover such as new woodland establishment. Our\nresults demonstrate how pre-trained Large Observation Models like EarthPT can\nbe specialised for granular, dynamic land cover monitoring from space,\nproviding a valuable, scalable tool for natural capital management and\nconservation.","main_category":"physics.geo-ph","categories":"physics.geo-ph,cs.LG","published":"2025-04-24T07:23:27Z"}
{"aid":"http://arxiv.org/abs/2504.17342v1","title":"Fr√©chet Distance in Unweighted Planar Graphs","summary":"The Fr\\'echet distance is a distance measure between trajectories in the\nplane or walks in a graph G. Given constant-time shortest path queries in a\ngraph G, the Discrete Fr\\'echet distance $F_G(P, Q)$ between two walks P and Q\ncan be computed in $O(|P| \\cdot |Q|)$ time using a dynamic program. Driemel,\nvan der Hoog, and Rotenberg [SoCG'22] show that for weighted planar graphs this\napproach is likely tight, as there can be no strongly subquadratic algorithm to\ncompute a $1.01$-approximation of $F_G(P, Q)$ unless the Orthogonal Vector\nHypothesis (OVH) fails.\n  Such quadratic-time conditional lower bounds are common to many Fr\\'echet\ndistance variants. However, they can be circumvented by assuming that the input\ncomes from some well-behaved class: There exist\n$(1+\\varepsilon)$-approximations, both in weighted graphs and in Rd, that take\nnear-linear time for $c$-packed or $\\kappa$-straight walks in the graph. In Rd,\nthere also exists a near-linear time algorithm to compute the Fr\\'echet\ndistance whenever all input edges are long compared to the distance.\n  We consider computing the Fr\\'echet distance in unweighted planar graphs. We\nshow that there exist no 1.25-approximations of the discrete Fr\\'echet distance\nbetween two disjoint simple paths in an unweighted planar graph in strongly\nsubquadratic time, unless OVH fails. This improves the previous lower bound,\nboth in terms of generality and approximation factor. We subsequently show that\nadding graph structure circumvents this lower bound: If the graph is a regular\ntiling with unit-weighted edges, then there exists an $\\tilde{O}( (|P| +\n|Q|)^{1.5})$-time algorithm to compute $D_F(P, Q)$. Our result has natural\nimplications in the plane, as it allows us to define a new class of\nwell-behaved curves that facilitate $(1+\\varepsilon)$-approximations of their\ndiscrete Fr\\'echet distance in subquadratic time.","main_category":"cs.CG","categories":"cs.CG","published":"2025-04-24T07:59:39Z"}
{"aid":"http://arxiv.org/abs/2504.17347v1","title":"Analysis and Mitigation of Data injection Attacks against Data-Driven\n  Control","summary":"This paper investigates the impact of false data injection attacks on\ndata-driven control systems. Specifically, we consider an adversary injecting\nfalse data into the sensor channels during the learning phase. When the\noperator seeks to learn a stable state-feedback controller, we propose an\nattack strategy capable of misleading the operator into learning an unstable\nfeedback gain. We also investigate the effects of constant-bias injection\nattacks on data-driven linear quadratic regulation (LQR). Finally, we explore\npotential mitigation strategies and support our findings with numerical\nexamples.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-24T08:08:51Z"}
{"aid":"http://arxiv.org/abs/2504.17356v1","title":"Comprehend, Divide, and Conquer: Feature Subspace Exploration via\n  Multi-Agent Hierarchical Reinforcement Learning","summary":"Feature selection aims to preprocess the target dataset, find an optimal and\nmost streamlined feature subset, and enhance the downstream machine learning\ntask. Among filter, wrapper, and embedded-based approaches, the reinforcement\nlearning (RL)-based subspace exploration strategy provides a novel objective\noptimization-directed perspective and promising performance. Nevertheless, even\nwith improved performance, current reinforcement learning approaches face\nchallenges similar to conventional methods when dealing with complex datasets.\nThese challenges stem from the inefficient paradigm of using one agent per\nfeature and the inherent complexities present in the datasets. This observation\nmotivates us to investigate and address the above issue and propose a novel\napproach, namely HRLFS. Our methodology initially employs a Large Language\nModel (LLM)-based hybrid state extractor to capture each feature's mathematical\nand semantic characteristics. Based on this information, features are\nclustered, facilitating the construction of hierarchical agents for each\ncluster and sub-cluster. Extensive experiments demonstrate the efficiency,\nscalability, and robustness of our approach. Compared to contemporary or the\none-feature-one-agent RL-based approaches, HRLFS improves the downstream ML\nperformance with iterative feature subspace exploration while accelerating\ntotal run time by reducing the number of agents involved.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-24T08:16:36Z"}
{"aid":"http://arxiv.org/abs/2504.17357v1","title":"Observation of the Einstein-de Haas Effect in a Bose-Einstein condensate","summary":"The Einstein-de Haas effect is a phenomenon in which angular momentum is\ntransferred from microscopic spins to mechanical rotation of a rigid body.\nHere, we report the first observation of the Einstein-de Haas effect in a\nspinor-dipolar Bose-Einstein condensate where quantized vortices emerge in\ndepolarized spinor components through coherent angular-momentum transfer from\nmicroscopic atomic spins to macroscopic quantized circulation. Experimental\nresults clearly show that the spherical symmetry of the condensate is\ndynamically broken into the axisymmetry by an intrinsic magnetic dipole-dipole\ninteraction.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas","published":"2025-04-24T08:16:43Z"}
{"aid":"http://arxiv.org/abs/2504.17362v1","title":"Probing molecular concentration in cell nuclei with Brillouin microscopy","summary":"Cell volume is controlled by osmotic regulation of the fluid content, via\nwater efflux through the cell membrane. The rate of this process is controlled\nby the ability of the liquid to move through the meshwork of solid elements\nwithin the cell. While such dynamics have been interpreted in the frame of the\nporoelastic theory in the cytoplasm, the behavior of the nucleus remains\nunknown due to a lack of technique to probe it. Brillouin light scattering\n(BLS) allows to interrogate the sound velocity and attenuation of a sample in a\nnon-contact manner, thus revealing the dynamic response of the material. In\ncells, such data were initially interpreted as the viscoelastic response of the\nactin meshwork, but later studies pointed out the importance of water content.\nTo resolve this lack of consensus in the interpretation of the hypersonic data\nobtained from BLS spectra, and investigate the possible poroelastic nature of\nthe nucleus, we vary the relative volume fraction of intracellular water and\nsolid network by applying osmotic compressions to single cells. In the nucleus,\nwe observe a non-linear increase in the sound velocity and attenuation with\nincreasing osmotic pressure that we fit to a poroelastic model, providing an\nestimate of the friction coefficient between the water phase and the network.\nBy comparing BLS data to volume measurements, our approach demonstrates clearly\nthat Brillouin microscopy actually provides a measure of molecular\nconcentration in living cells","main_category":"physics.bio-ph","categories":"physics.bio-ph,cond-mat.soft,q-bio.QM","published":"2025-04-24T08:23:40Z"}
{"aid":"http://arxiv.org/abs/2504.17366v1","title":"LiveLongBench: Tackling Long-Context Understanding for Spoken Texts from\n  Live Streams","summary":"Long-context understanding poses significant challenges in natural language\nprocessing, particularly for real-world dialogues characterized by speech-based\nelements, high redundancy, and uneven information density. Although large\nlanguage models (LLMs) achieve impressive results on existing benchmarks, these\ndatasets fail to reflect the complexities of such texts, limiting their\napplicability to practical scenarios. To bridge this gap, we construct the\nfirst spoken long-text dataset, derived from live streams, designed to reflect\nthe redundancy-rich and conversational nature of real-world scenarios. We\nconstruct tasks in three categories: retrieval-dependent, reasoning-dependent,\nand hybrid. We then evaluate both popular LLMs and specialized methods to\nassess their ability to understand long-contexts in these tasks. Our results\nshow that current methods exhibit strong task-specific preferences and perform\npoorly on highly redundant inputs, with no single method consistently\noutperforming others. We propose a new baseline that better handles redundancy\nin spoken text and achieves strong performance across tasks. Our findings\nhighlight key limitations of current methods and suggest future directions for\nimproving long-context understanding. Finally, our benchmark fills a gap in\nevaluating long-context spoken language understanding and provides a practical\nfoundation for developing real-world e-commerce systems. The code and benchmark\nare available at https://github.com/Yarayx/livelongbench.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-24T08:27:48Z"}
{"aid":"http://arxiv.org/abs/2504.17388v1","title":"Computing-heightened low-cost high-dimensional controlled-SUM gates","summary":"Qudit-based quantum gates offer several advantages over qubit-based\ncounterparts, such as higher information density, the ability to address more\ncomplex problems, and richer quantum operations. In this paper, we present\nthree realistic protocols for implementing a 4$\\times$4-dimensional (16D)\ntwo-qudit controlled-SUM (CSUM) gate, where the 4D control qudit and 4D target\nqudit are encoded in the polarization degree of freedom (DoF) and spatial DoF\nof two photons, respectively. The first protocol is implemented exclusively\nusing linear optical elements without auxiliary resources, making it feasible\nwith current optical technologies and achieving an efficiency of 1/9. The\nsecond protocol utilizes photon scattering by a microcavity-quantum-dot system,\nenabling the 16D CSUM gate to operate deterministically without postselection.\nThe third protocol introduces an error-heralded mechanism based on the second\nprotocol, theoretically achieving unity fidelity. Moreover, all protocols\noperate without ancillary photons, offering the advantages of compact circuits\nand low cost while further promoting the development of high-dimensional\nquantum computation.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-24T09:13:26Z"}
{"aid":"http://arxiv.org/abs/2504.17399v1","title":"S2S-Net: Addressing the Domain Gap of Heterogeneous Sensor Systems in\n  LiDAR-Based Collective Perception","summary":"Collective Perception (CP) has emerged as a promising approach to overcome\nthe limitations of individual perception in the context of autonomous driving.\nVarious approaches have been proposed to realize collective perception;\nhowever, the Sensor2Sensor domain gap that arises from the utilization of\ndifferent sensor systems in Connected and Automated Vehicles (CAVs) remains\nmostly unaddressed. This is primarily due to the paucity of datasets containing\nheterogeneous sensor setups among the CAVs. The recently released SCOPE\ndatasets address this issue by providing data from three different LiDAR\nsensors for each CAV. This study is the first to tackle the Sensor2Sensor\ndomain gap in vehicle to vehicle (V2V) collective perception. First, we present\nour sensor-domain robust architecture S2S-Net. Then an in-depth analysis of the\nSensor2Sensor domain adaptation capabilities of S2S-Net on the SCOPE dataset is\nconducted. S2S-Net demonstrates the capability to maintain very high\nperformance in unseen sensor domains and achieved state-of-the-art results on\nthe SCOPE dataset.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-24T09:38:59Z"}
{"aid":"http://arxiv.org/abs/2504.17426v1","title":"Towards Leveraging Large Language Model Summaries for Topic Modeling in\n  Source Code","summary":"Understanding source code is a topic of great interest in the software\nengineering community, since it can help programmers in various tasks such as\nsoftware maintenance and reuse. Recent advances in large language models (LLMs)\nhave demonstrated remarkable program comprehension capabilities, while\ntransformer-based topic modeling techniques offer effective ways to extract\nsemantic information from text. This paper proposes and explores a novel\napproach that combines these strengths to automatically identify meaningful\ntopics in a corpus of Python programs. Our method consists in applying topic\nmodeling on the descriptions obtained by asking an LLM to summarize the code.\nTo assess the internal consistency of the extracted topics, we compare them\nagainst topics inferred from function names alone, and those derived from\nexisting docstrings. Experimental results suggest that leveraging LLM-generated\nsummaries provides interpretable and semantically rich representation of code\nstructure. The promising results suggest that our approach can be fruitfully\napplied in various software engineering tasks such as automatic documentation\nand tagging, code search, software reorganization and knowledge discovery in\nlarge repositories.","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-24T10:30:40Z"}
{"aid":"http://arxiv.org/abs/2504.17432v1","title":"Breaking the Modality Barrier: Universal Embedding Learning with\n  Multimodal LLMs","summary":"The Contrastive Language-Image Pre-training (CLIP) framework has become a\nwidely used approach for multimodal representation learning, particularly in\nimage-text retrieval and clustering. However, its efficacy is constrained by\nthree key limitations: (1) text token truncation, (2) isolated image-text\nencoding, and (3) deficient compositionality due to bag-of-words behavior.\nWhile recent Multimodal Large Language Models (MLLMs) have demonstrated\nsignificant advances in generalized vision-language understanding, their\npotential for learning transferable multimodal representations remains\nunderexplored.In this work, we present UniME (Universal Multimodal Embedding),\na novel two-stage framework that leverages MLLMs to learn discriminative\nrepresentations for diverse downstream tasks. In the first stage, we perform\ntextual discriminative knowledge distillation from a powerful LLM-based teacher\nmodel to enhance the embedding capability of the MLLM\\'s language component. In\nthe second stage, we introduce hard negative enhanced instruction tuning to\nfurther advance discriminative representation learning. Specifically, we\ninitially mitigate false negative contamination and then sample multiple hard\nnegatives per instance within each batch, forcing the model to focus on\nchallenging samples. This approach not only improves discriminative power but\nalso enhances instruction-following ability in downstream tasks. We conduct\nextensive experiments on the MMEB benchmark and multiple retrieval tasks,\nincluding short and long caption retrieval and compositional retrieval. Results\ndemonstrate that UniME achieves consistent performance improvement across all\ntasks, exhibiting superior discriminative and compositional capabilities.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T10:51:52Z"}
{"aid":"http://arxiv.org/abs/2504.17451v1","title":"Functional $K$ Sample Problem via Multivariate Optimal Measure\n  Transport-Based Permutation Test","summary":"The null hypothesis of equality of distributions of functional data coming\nfrom $K$ samples is considered. The proposed test statistic is multivariate and\nits components are based on pairwise Cram\\'{e}r von Mises comparisons of\nempirical characteristic functionals. The significance of the test statistic is\nevaluated via the novel multivariate permutation test, where the final single\n$p$-value is computed using the discrete optimal measure transport. The\nmethodology is illustrated by real data on cumulative intraday returns of\nBitcoin.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-24T11:30:46Z"}
{"aid":"http://arxiv.org/abs/2504.17459v1","title":"A representation of range decreasing group homomorphisms","summary":"The method of range decreasing group homomorphisms can be applied to study\nvarious maps between mapping spaces, includin holomorphic maps, group\nhomomorphisms, linear maps, semigroup homomorphisms, Lie algebra homomorphisms\nand algebra homomorphisms [Z1, Z2]. Previous studies on range decreasing group\nhomomorphisms have primarily focused on specific subsets of mapping groups. In\nthis paper, we provide a characterization of a general range decreasing group\nhomomorphism applicable to the entire mapping group. As applications, we\ncompute a particular class of homomorphisms between mapping groups and identify\nall range decreasing group homomorphisms defined on specific mapping groups.","main_category":"math.GR","categories":"math.GR,math.DG","published":"2025-04-24T11:44:36Z"}
{"aid":"http://arxiv.org/abs/2504.17485v1","title":"Leakage at zero temperature from changes in chemical potential in\n  Majorana qubits","summary":"Building a fault-tolerant quantum computer requires physical qubits with\nexceptionally low error rates. Majorana-based tetron qubits are predicted to\nexhibit error rates that decrease exponentially with inverse temperature and\nlength of each topological superconducting wire in the tetron. In contrast to\nthis prediction, we show that errors arising from small variations in the\nchemical potential grow linearly with tetron length at zero temperature. These\nerrors stem from leakage into excited quasiparticle states, which ultimately\npoison Majorana modes at opposite ends of the tetron, causing errors. We\nfurther demonstrate that the dynamics of this leakage is captured by the half\nLandau-Zener effect, which dictates its dependence on key system parameters\nsuch as the superconducting gap, chemical potential variations, and dynamic\nchanges in the spatial profile of Majorana modes. These results motivate\nfurther investigations into the impact of leakage on qubit performance and\npotential mitigation strategies.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall","published":"2025-04-24T12:22:31Z"}
{"aid":"http://arxiv.org/abs/2504.17501v1","title":"Surface morphology and thickness variation estimation of zeolites via\n  electron ptychography","summary":"Zeolites, as representative porous materials, possess intricate\nthree-dimensional frameworks that endow them with high surface areas and\nremarkable catalytic properties. There are a few factors that give a huge\ninfluence on the catalytic properties, including the size and connectivity of\nthese three-dimensional channels and atomic level defects. In additional to\nthat, the surface morphology and thickness variation of zeolites particles are\nessential to their catalytic performances as well. However, it is a significant\nchallenge to characterize these macroscopic properties of zeolites using\nconventional techniques due to their sensitivity to electron beams. In this\nstudy, we introduce surface-adaptive electron ptychography, an advanced\napproach based on multi-slice electron ptychography, which enables\nhigh-precision reconstruction of both local atomic configurations and global\nstructural features in zeolite nanoparticles. By adaptively optimizing probe\ndefocus and slice thickness during the reconstruction process, SAEP\nsuccessfully resolves surface morphology, thickness variations and atomic\nstructure simultaneously. This integrated framework facilitates a direct and\nintuitive correlation between zeolite channel structures and particle\nthickness. Our findings open new pathways for large-scale, comprehensive\nstructure property analysis of beam-sensitive porous materials, deepening the\nunderstanding of their catalytic behavior.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-24T12:42:55Z"}
{"aid":"http://arxiv.org/abs/2504.17504v1","title":"On systems disjoint from all minimal systems","summary":"Recently, G\\'{o}rska, Lema\\'{n}czyk, and de la Rue characterized the class of\nautomorphisms disjoint from all ergodic automorphisms. Inspired by their work,\nwe provide several characterizations of systems that are disjoint from all\nminimal systems.\n  For a topological dynamical system $(X,T)$, it is disjoint from all minimal\nsystems if and only if there exist minimal subsets $(M_i)_{i\\in\\mathbb{N}}$ of\n$X$ whose union is dense in $X$ and each of them is disjoint from $X$ (we also\nprovide a measure-theoretical analogy of the result). For a semi-simple system\n$(X,T)$, it is disjoint from all minimal systems if and only if there exists a\ndense $G_{\\delta}$ set $\\Omega$ in $X \\times X$ such that for every pair\n$(x_1,x_2) \\in \\Omega$, the subsystems $\\overline{\\mathcal{O}}(x_1,T)$ and\n$\\overline{\\mathcal{O}}(x_2,T)$ are disjoint. Furthermore, for a general system\na characterization similar to the ergodic case is obtained.","main_category":"math.DS","categories":"math.DS","published":"2025-04-24T12:48:40Z"}
{"aid":"http://arxiv.org/abs/2504.17514v1","title":"Secure Network Function Computation for Linear Functions, Part II:\n  Target-Function Security","summary":"In this Part II of a two-part paper, we put forward secure network function\ncomputation, where in a directed acyclic network, a sink node is required to\ncompute a target function of which the inputs are generated as source messages\nat multiple source nodes, while a wiretapper, who can access any one but not\nmore than one wiretap set in a given collection of wiretap sets, is not allowed\nto obtain any information about a security function of the source messages. In\nPart I of the two-part paper, we have investigated securely computing linear\nfunctions with the wiretapper who can eavesdrop any edge subset up to a certain\nsize r, referred to as the security level, where the security function is the\nidentity function. The notion of this security is called source security. In\nthe current paper, we consider another interesting model which is the same as\nthe above one except that the security function is identical to the target\nfunction, i.e., we need to protect the information on the target function from\nbeing leaked to the wiretapper. The notion of this security is called\ntarget-function security. We first prove a non-trivial upper bound on the\nsecure computing capacity, which is applicable to arbitrary network topologies\nand arbitrary security levels. In particular, when the security level r is\nequal to 0, the upper bound reduces to the computing capacity without security\nconsideration. Further, from an algebraic point of view, we prove two\nequivalent conditions for target-function security and source security for the\nexistence of the corresponding linear function-computing secure network codes.\nWith them, for any linear function over a given finite field, we develop a code\nconstruction of linear secure network codes for target-function security and\nthus obtain a lower bound on the secure computing capacity; and also generalize\nthe code construction developed in Part I for source security.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-24T12:57:20Z"}
{"aid":"http://arxiv.org/abs/2504.17540v1","title":"An Explainable Nature-Inspired Framework for Monkeypox Diagnosis:\n  Xception Features Combined with NGBoost and African Vultures Optimization\n  Algorithm","summary":"The recent global spread of monkeypox, particularly in regions where it has\nnot historically been prevalent, has raised significant public health concerns.\nEarly and accurate diagnosis is critical for effective disease management and\ncontrol. In response, this study proposes a novel deep learning-based framework\nfor the automated detection of monkeypox from skin lesion images, leveraging\nthe power of transfer learning, dimensionality reduction, and advanced machine\nlearning techniques. We utilize the newly developed Monkeypox Skin Lesion\nDataset (MSLD), which includes images of monkeypox, chickenpox, and measles, to\ntrain and evaluate our models. The proposed framework employs the Xception\narchitecture for deep feature extraction, followed by Principal Component\nAnalysis (PCA) for dimensionality reduction, and the Natural Gradient Boosting\n(NGBoost) algorithm for classification. To optimize the model's performance and\ngeneralization, we introduce the African Vultures Optimization Algorithm (AVOA)\nfor hyperparameter tuning, ensuring efficient exploration of the parameter\nspace. Our results demonstrate that the proposed AVOA-NGBoost model achieves\nstate-of-the-art performance, with an accuracy of 97.53%, F1-score of 97.72%\nand an AUC of 97.47%. Additionally, we enhance model interpretability using\nGrad-CAM and LIME techniques, providing insights into the decision-making\nprocess and highlighting key features influencing classification. This\nframework offers a highly precise and efficient diagnostic tool, potentially\naiding healthcare providers in early detection and diagnosis, particularly in\nresource-constrained environments.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG,eess.IV","published":"2025-04-24T13:32:11Z"}
{"aid":"http://arxiv.org/abs/2504.17558v1","title":"Quasi-particle residue and charge of the one-dimensional Fermi polaron","summary":"We consider a mobile impurity coupled to an ideal Fermi gas in one spatial\ndimension through an attractive contact interaction. We calculate the\nquasi-particle residue $Z$ exactly, based on Bethe Ansatz and diagrammatic\nMonte Carlo methods, and with varational Ansatz up to one particle-hole\nexcitation of the Fermi sea. We find that the exact quasi-particle residue\nvanishes in the thermodynamic limit as a power law in the number of particles,\nconsistent with the Luttinger-liquid paradigm and the breakdown of Fermi-liquid\ntheory. The variational Ansatz, however, predicts a finite value of $Z$, even\nin the thermodynamic limit. We also study how the presence of the impurity\naffects the density of the spin-up sea by calculating the pair correlation\nfunction. Subtracting the homogeneous background and integrating over all\ndistances gives the charge $Q$. This charge turns out to grow continuously from\n0 at zero coupling to 1 in the strong-coupling limit. The varational Ansatz\npredicts $Q=0$ at all couplings. So, although the variational Ansatz has been\nshown to be remarkably accurate for the energy and the effective mass, it fails\neven qualitatively when predicting $Z$ and the pair correlation function in the\nthermodynamic limit.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,cond-mat.str-el,cond-mat.supr-con","published":"2025-04-24T13:50:46Z"}
{"aid":"http://arxiv.org/abs/2504.17575v1","title":"A Multi-Agent, Laxity-Based Aggregation Strategy for Cost-Effective\n  Electric Vehicle Charging and Local Transformer Overload Prevention","summary":"The rapid electrification of transportation, driven by stringent\ndecarbonization targets and supportive policies, poses significant challenges\nfor distribution system operators (DSOs). When numerous electric vehicles (EVs)\ncharge concurrently, local transformers risk overloading - a problem that\ncurrent tariff-based strategies do not adequately address. This paper\nintroduces an aggregator-based coordination mechanism that shifts EV charging\nfrom congested to underutilized periods using a rule-based scheduling\nalgorithm. Unlike conventional methods that depend on complex real-time pricing\nsignals or optimization-heavy solutions, the aggregator approach uses a simple\nyet effective \"laxity\" measure to prioritize charging flexibility. To assess\ntechnical and economic viability, a multi-agent simulation was developed to\nreplicate residential user behavior and DSO constraints under the use of a 400\nkVA low-voltage transformer. The results indicate that overloads are completely\neliminated with minimal inconvenience to users, whose increased charging costs\nare offset by the aggregator at an annual total of under DKK 6000 -\nsignificantly lower than the cost of infrastructure reinforcement. This study\ncontributes by (i) quantifying the compensation needed to prevent large-scale\noverloads, (ii) presenting a replicable, computationally feasible, rule-based\naggregator model for DSOs, and (iii) comparing aggregator solutions to costly\ntransformer upgrades, underscoring the aggregator's role as a viable tool for\nfuture distribution systems.","main_category":"cs.MA","categories":"cs.MA","published":"2025-04-24T14:04:35Z"}
{"aid":"http://arxiv.org/abs/2504.17578v1","title":"Advancing CMA-ES with Learning-Based Cooperative Coevolution for\n  Scalable Optimization","summary":"Recent research in Cooperative Coevolution~(CC) have achieved promising\nprogress in solving large-scale global optimization problems. However, existing\nCC paradigms have a primary limitation in that they require deep expertise for\nselecting or designing effective variable decomposition strategies. Inspired by\nadvancements in Meta-Black-Box Optimization, this paper introduces LCC, a\npioneering learning-based cooperative coevolution framework that dynamically\nschedules decomposition strategies during optimization processes. The\ndecomposition strategy selector is parameterized through a neural network,\nwhich processes a meticulously crafted set of optimization status features to\ndetermine the optimal strategy for each optimization step. The network is\ntrained via the Proximal Policy Optimization method in a reinforcement learning\nmanner across a collection of representative problems, aiming to maximize the\nexpected optimization performance. Extensive experimental results demonstrate\nthat LCC not only offers certain advantages over state-of-the-art baselines in\nterms of optimization effectiveness and resource consumption, but it also\nexhibits promising transferability towards unseen problems.","main_category":"cs.LG","categories":"cs.LG,cs.NE","published":"2025-04-24T14:09:22Z"}
{"aid":"http://arxiv.org/abs/2504.17580v1","title":"Linear Test Approach to Global Controllability of Higher-Order Nonlinear\n  Dispersive Equations with Finite-Dimensional Control","summary":"We investigate a class of higher-order nonlinear dispersive equations posed\non the circle, subject to additive forcing by a finite-dimensional control. Our\nmain objective is to establish approximate controllability by using the\ncontrollability of the inviscid Burgers system, linearized around a suitably\nconstructed trajectory. In contrast to earlier approaches based on Lie\nalgebraic techniques, our method offers a more concise proof and sheds new\nlight on the structure of the control. Although the approach necessitates a\nhigher-dimensional control space, both the structure and dimension of the\ncontrol remain uniform with respect to the order of the dispersive equation and\nthe control time.","main_category":"math.AP","categories":"math.AP,math.OC","published":"2025-04-24T14:10:48Z"}
{"aid":"http://arxiv.org/abs/2504.17587v1","title":"Enhancing gravitational-wave detection: a machine learning pipeline\n  combination approach with robust uncertainty quantification","summary":"Gravitational-wave data from advanced-era interferometric detectors consists\nof background Gaussian noise, frequent transient artefacts, and rare\nastrophysical signals. Multiple search algorithms exist to detect the signals\nfrom compact binary coalescences, but their varying performance complicates\ninterpretation. We present a machine learning-driven approach that combines\nresults from individual pipelines and utilises conformal prediction to provide\nrobust, calibrated uncertainty quantification. Using simulations, we\ndemonstrate improved detection efficiency and apply our model to GWTC-3,\nenhancing confidence in multi-pipeline detections, such as the sub-threshold\nbinary neutron star candidate GW200311_103121.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE","published":"2025-04-24T14:18:09Z"}
{"aid":"http://arxiv.org/abs/2504.17592v1","title":"Well-posed Questions for Ill-posed Inverse Problems: a Note in Memory of\n  Pierre Sabatier","summary":"Professor Pierre Sabatier contributed much to the study of inverse problems\nin theory and practice. Two of these contributions were a focus on theory that\nactually supports practice, and the identification of well-posed aspects of\ninverse problems that may quite ill-posed. This paper illustrates these two\nthemes in the context of Electrical Impedance Tomography (EIT), which is both\nvery ill-posed and very practical. We show that for a highly constrained\nversion of this inverse problem, in which a small elliptical inclusion in a\nhomogeneous background is to be identified, optimization of the experimental\ndesign (that is, electrode locations) vastly improves the stability of the\nsolution.","main_category":"math.AP","categories":"math.AP","published":"2025-04-24T14:21:53Z"}
{"aid":"http://arxiv.org/abs/2504.17600v1","title":"Model Choice Matters for Age Inference on the Red Giant Branch","summary":"Galactic archaeology relies on accurate stellar parameters to reconstruct the\ngalaxy's history, including information on stellar ages. While the precision of\ndata has improved significantly in recent years, stellar models used for age\ninference have not improved at a similar rate. In fact, different models yield\nnotably different age predictions for the same observational data. In this\npaper, we assess the difference in age predictions of various widely used model\ngrids for stars along the red giant branch. Using open source software, we\nconduct a comparison of four different evolution grids and we find that age\nestimations become less reliable if stellar mass is not known, with differences\noccasionally exceeding $80\\%$. Additionally, we note significant disagreements\nin the models' age estimations at non-solar metallicity. Finally, we present a\nmethod for including theoretical uncertainties from stellar evolutionary tracks\nin age inferences of red giants, aimed at improving the accuracy of age\nestimation techniques used in the galactic archaeology community.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA,astro-ph.IM","published":"2025-04-24T14:26:17Z"}
{"aid":"http://arxiv.org/abs/2504.17602v1","title":"Scalar-Induced Gravitational Waves from self-resonant preheating in\n  $Œ±$-attractor models","summary":"After the inflationary phase, the universe enters the preheating phase,\nduring which the inflaton field rolls down its potential and oscillates. When\nthe potential significantly deviates from a parabolic shape at its minimum,\nthese oscillations trigger an instability in the scalar perturbations, leading\nto their amplification. This phenomenon, known as self-resonance, has important\nimplications in cosmology. Notably, since scalar perturbations couple to tensor\nperturbations at second order in the equations of motion, this amplification\nresults in the production of Gravitational Waves (GWs), referred to as\nScalar-Induced Gravitational Waves (SIGWs). In this study, we investigate the\nproduction of SIGWs during the preheating phase for a class of inflationary\nmodels known as $\\alpha$-attractors, characterized by a single parameter\n$\\alpha$. We focus on small values of this parameter, specifically $\\alpha \\sim\nO(10^{-1} - 10^{-4})$, where the self-resonance effect is particularly\npronounced. We obtain lower bounds on this parameter, $\\log_{10}(\\alpha)>-3.54$\nfor the T-model and $\\log_{10}(\\alpha)>-3.17$ for the E-model, based on the\nenergy density of SIGWs constrained by Big Bang nucleosynthesis, which\nultimately translates into lower bounds on the tensor-to-scalar ratio,\n$r>9.61\\times10^{-7}$ for the T-model and $r>2.25\\times10^{-6}$ for the\nE-model.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-24T14:27:44Z"}
{"aid":"http://arxiv.org/abs/2504.17613v1","title":"TarDiff: Target-Oriented Diffusion Guidance for Synthetic Electronic\n  Health Record Time Series Generation","summary":"Synthetic Electronic Health Record (EHR) time-series generation is crucial\nfor advancing clinical machine learning models, as it helps address data\nscarcity by providing more training data. However, most existing approaches\nfocus primarily on replicating statistical distributions and temporal\ndependencies of real-world data. We argue that fidelity to observed data alone\ndoes not guarantee better model performance, as common patterns may dominate,\nlimiting the representation of rare but important conditions. This highlights\nthe need for generate synthetic samples to improve performance of specific\nclinical models to fulfill their target outcomes. To address this, we propose\nTarDiff, a novel target-oriented diffusion framework that integrates\ntask-specific influence guidance into the synthetic data generation process.\nUnlike conventional approaches that mimic training data distributions, TarDiff\noptimizes synthetic samples by quantifying their expected contribution to\nimproving downstream model performance through influence functions.\nSpecifically, we measure the reduction in task-specific loss induced by\nsynthetic samples and embed this influence gradient into the reverse diffusion\nprocess, thereby steering the generation towards utility-optimized data.\nEvaluated on six publicly available EHR datasets, TarDiff achieves\nstate-of-the-art performance, outperforming existing methods by up to 20.4% in\nAUPRC and 18.4% in AUROC. Our results demonstrate that TarDiff not only\npreserves temporal fidelity but also enhances downstream model performance,\noffering a robust solution to data scarcity and class imbalance in healthcare\nanalytics.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-24T14:36:10Z"}
{"aid":"http://arxiv.org/abs/2504.17620v1","title":"Reverse energy flows: the physical mechanism underling dramatic drop of\n  loss in hollow-core fibers","summary":"Hollow-core fibers (HCFs) with claddings composed of silica glass capillaries\nhave recently attracted a great deal of attention following the demonstration\nof optical loss levels lower than those of conventional telecommunication\nfibers. It is well established already that optical losses in HCFs are highly\nsensitive to both the wavelength and the geometry of the cladding capillaries.\nThe underlying physical mechanisms behind reducing loss with the change of HCF\ndesign parameters while keeping the same fiber structure are not yet fully\nunderstood. In this work, we investigate the relationship between light\nlocalization and corresponding decrease of losses in HCFs and the distribution\nof reverse energy fluxes in air-core modes. We show here that the shape of the\ncapillaries plays a crucial role in controlling radial energy backflows that\ninfluence light confinement and the energy leakage from air-core modes of HCFs.\nThrough numerical modeling, we demonstrate that optimizing the capillary\ngeometry to tailor the distribution of reverse radial energy fluxes leads to a\nsubstantial reduction in transmission losses even in fibers with relatively\nsimple cladding structures. Consideration of the energy flows and observed\noccurrences of vortex of the Poynting vector allows us to a draw an interesting\ninterdisciplinary analogy with the hydrodynamical system with suppressed\nbackward flow - Tesla valve. We believe that combination of singular optics and\nenergy fluxes analysis provides valuable physical insight into the mechanisms\ngoverning waveguiding in HCFs offering a pathway toward novel designs with\nminimized leakage loss.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-24T14:44:23Z"}
{"aid":"http://arxiv.org/abs/2504.17630v1","title":"Geometry-induced asymmetric level coupling","summary":"Tailoring energy levels in quantum systems via Hamiltonian control parameters\nis essential for designing quantum thermodynamic devices and materials.\nHowever, conventional methods for manipulating finite-size systems, such as\ntuning external fields or system size, typically lead to uniform spectral\nshifts, limiting precise control. A recently introduced technique, called the\nsize-invariant shape transformation, overcomes this by introducing a new\ncontrol parameter that deforms the potential landscape without altering system\nsize, enabling nonuniform level scaling. This shape parameter gives rise to\nquantum shape effects in confined systems, conceptually distinct from quantum\nsize effects. We explore the limits of this phenomenon by asking: what is the\nminimal system in which such spectral behavior can emerge? We show that even a\ntwo-level system can exhibit thermodynamic consequences of quantum shape\neffects, including spontaneous transitions into lower-entropy states, a feature\nabsent in classical thermodynamics for non-interacting systems. We identify the\norigin as geometry-induced asymmetric level coupling, where the ground-state\nenergy and level spacing respond oppositely to shape changes. This extends to\nmany-level systems, where the thermally averaged level spacing and ground-state\nenergy evolve in opposite directions. We construct spontaneity maps revealing\nenergy- and entropy-driven spontaneous processes. These behaviors emerge under\nquasistatic, isothermal deformations and show how geometry alone can induce\nthermodynamic effects typically exclusive to interacting or open systems. Our\nresults offer a broadly applicable route to spectral gap control in quantum\ntechnologies.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall,cond-mat.stat-mech","published":"2025-04-24T14:58:44Z"}
{"aid":"http://arxiv.org/abs/2504.17660v1","title":"Effortless, Simulation-Efficient Bayesian Inference using Tabular\n  Foundation Models","summary":"Simulation-based inference (SBI) offers a flexible and general approach to\nperforming Bayesian inference: In SBI, a neural network is trained on synthetic\ndata simulated from a model and used to rapidly infer posterior distributions\nfor observed data. A key goal for SBI is to achieve accurate inference with as\nfew simulations as possible, especially for expensive simulators. In this work,\nwe address this challenge by repurposing recent probabilistic foundation models\nfor tabular data: We show how tabular foundation models -- specifically TabPFN\n-- can be used as pre-trained autoregressive conditional density estimators for\nSBI. We propose Neural Posterior Estimation with Prior-data Fitted Networks\n(NPE-PF) and show that it is competitive with current SBI approaches in terms\nof accuracy for both benchmark tasks and two complex scientific inverse\nproblems. Crucially, it often substantially outperforms them in terms of\nsimulation efficiency, sometimes requiring orders of magnitude fewer\nsimulations. NPE-PF eliminates the need for inference network selection,\ntraining, and hyperparameter tuning. We also show that it exhibits superior\nrobustness to model misspecification and can be scaled to simulation budgets\nthat exceed the context size limit of TabPFN. NPE-PF provides a new direction\nfor SBI, where training-free, general-purpose inference models offer efficient,\neasy-to-use, and flexible solutions for a wide range of stochastic inverse\nproblems.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-24T15:29:39Z"}
{"aid":"http://arxiv.org/abs/2504.17664v1","title":"On Multivariate Financial Time Series Classification","summary":"This article investigates the use of Machine Learning and Deep Learning\nmodels in multivariate time series analysis within financial markets. It\ncompares small and big data approaches, focusing on their distinct challenges\nand the benefits of scaling. Traditional methods such as SVMs are contrasted\nwith modern architectures like ConvTimeNet. The results show the importance of\nusing and understanding Big Data in depth in the analysis and prediction of\nfinancial time series.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-24T15:33:00Z"}
{"aid":"http://arxiv.org/abs/2504.17671v1","title":"Data-Driven Calibration of Prediction Sets in Large Vision-Language\n  Models Based on Inductive Conformal Prediction","summary":"This study addresses the critical challenge of hallucination mitigation in\nLarge Vision-Language Models (LVLMs) for Visual Question Answering (VQA) tasks\nthrough a Split Conformal Prediction (SCP) framework. While LVLMs excel in\nmulti-modal reasoning, their outputs often exhibit hallucinated content with\nhigh confidence, posing risks in safety-critical applications. We propose a\nmodel-agnostic uncertainty quantification method that integrates dynamic\nthreshold calibration and cross-modal consistency verification. By partitioning\ndata into calibration and test sets, the framework computes nonconformity\nscores to construct prediction sets with statistical guarantees under\nuser-defined risk levels ($\\alpha$). Key innovations include: (1) rigorous\ncontrol of \\textbf{marginal coverage} to ensure empirical error rates remain\nstrictly below $\\alpha$; (2) dynamic adjustment of prediction set sizes\ninversely with $\\alpha$, filtering low-confidence outputs; (3) elimination of\nprior distribution assumptions and retraining requirements. Evaluations on\nbenchmarks (ScienceQA, MMMU) with eight LVLMs demonstrate that SCP enforces\ntheoretical guarantees across all $\\alpha$ values. The framework achieves\nstable performance across varying calibration-to-test split ratios,\nunderscoring its robustness for real-world deployment in healthcare, autonomous\nsystems, and other safety-sensitive domains. This work bridges the gap between\ntheoretical reliability and practical applicability in multi-modal AI systems,\noffering a scalable solution for hallucination detection and uncertainty-aware\ndecision-making.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-24T15:39:46Z"}
{"aid":"http://arxiv.org/abs/2504.17675v1","title":"Optimized Cloud Resource Allocation Using Genetic Algorithms for Energy\n  Efficiency and QoS Assurance","summary":"Cloud computing environments demand dynamic and efficient resource management\nto ensure optimal performance, reduced energy consumption, and adherence to\nService Level Agreements (SLAs). This paper presents a Genetic Algorithm\n(GA)-based approach for Virtual Machine (VM) placement and consolidation,\naiming to minimize power usage while maintaining QoS constraints. The proposed\nmethod dynamically adjusts VM allocation based on real-time workload\nvariations, outperforming traditional heuristics such as First Fit Decreasing\n(FFD) and Best Fit Decreasing (BFD). Experimental results show notable\nreductions in energy consumption, VM migrations, SLA violation rates, and\nexecution time. A correlation heatmap further illustrates strong relationships\namong these key performance indicators, confirming the effectiveness of our\napproach in optimizing cloud resource utilization.","main_category":"cs.DC","categories":"cs.DC,cs.AI","published":"2025-04-24T15:45:40Z"}
{"aid":"http://arxiv.org/abs/2504.17678v1","title":"MindFlow: A Network Traffic Anomaly Detection Model Based on MindSpore","summary":"With the wide application of IoT and industrial IoT technologies, the network\nstructure is becoming more and more complex, and the traffic scale is growing\nrapidly, which makes the traditional security protection mechanism face serious\nchallenges in dealing with high-frequency, diversified, and stealthy\ncyber-attacks. To address this problem, this study proposes MindFlow, a\nmulti-dimensional dynamic traffic prediction and anomaly detection system\ncombining convolutional neural network (CNN) and bi-directional long and\nshort-term memory network (BiLSTM) architectures based on the MindSpore\nframework, and conducts systematic experiments on the NF-BoT-IoT dataset. The\nexperimental results show that the proposed model achieves 99% in key metrics\nsuch as accuracy, precision, recall and F1 score, effectively verifying its\naccuracy and robustness in network intrusion detection.","main_category":"cs.CY","categories":"cs.CY","published":"2025-04-24T15:48:02Z"}
{"aid":"http://arxiv.org/abs/2504.17684v1","title":"Evaluating the Vulnerability of ML-Based Ethereum Phishing Detectors to\n  Single-Feature Adversarial Perturbations","summary":"This paper explores the vulnerability of machine learning models to simple\nsingle-feature adversarial attacks in the context of Ethereum fraudulent\ntransaction detection. Through comprehensive experimentation, we investigate\nthe impact of various adversarial attack strategies on model performance\nmetrics. Our findings, highlighting how prone those techniques are to simple\nattacks, are alarming, and the inconsistency in the attacks' effect on\ndifferent algorithms promises ways for attack mitigation. We examine the\neffectiveness of different mitigation strategies, including adversarial\ntraining and enhanced feature selection, in enhancing model robustness and show\ntheir effectiveness.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-24T15:54:56Z"}
{"aid":"http://arxiv.org/abs/2504.17695v1","title":"PICO: Reconstructing 3D People In Contact with Objects","summary":"Recovering 3D Human-Object Interaction (HOI) from single color images is\nchallenging due to depth ambiguities, occlusions, and the huge variation in\nobject shape and appearance. Thus, past work requires controlled settings such\nas known object shapes and contacts, and tackles only limited object classes.\nInstead, we need methods that generalize to natural images and novel object\nclasses. We tackle this in two main ways: (1) We collect PICO-db, a new dataset\nof natural images uniquely paired with dense 3D contact on both body and object\nmeshes. To this end, we use images from the recent DAMON dataset that are\npaired with contacts, but these contacts are only annotated on a canonical 3D\nbody. In contrast, we seek contact labels on both the body and the object. To\ninfer these given an image, we retrieve an appropriate 3D object mesh from a\ndatabase by leveraging vision foundation models. Then, we project DAMON's body\ncontact patches onto the object via a novel method needing only 2 clicks per\npatch. This minimal human input establishes rich contact correspondences\nbetween bodies and objects. (2) We exploit our new dataset of contact\ncorrespondences in a novel render-and-compare fitting method, called PICO-fit,\nto recover 3D body and object meshes in interaction. PICO-fit infers contact\nfor the SMPL-X body, retrieves a likely 3D object mesh and contact from PICO-db\nfor that object, and uses the contact to iteratively fit the 3D body and object\nmeshes to image evidence via optimization. Uniquely, PICO-fit works well for\nmany object categories that no existing method can tackle. This is crucial to\nenable HOI understanding to scale in the wild. Our data and code are available\nat https://pico.is.tue.mpg.de.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T16:03:11Z"}
{"aid":"http://arxiv.org/abs/2504.17709v1","title":"Fault Diagnosis in New Wind Turbines using Knowledge from Existing\n  Turbines by Generative Domain Adaptation","summary":"Intelligent condition monitoring of wind turbines is essential for reducing\ndowntimes. Machine learning models trained on wind turbine operation data are\ncommonly used to detect anomalies and, eventually, operation faults. However,\ndata-driven normal behavior models (NBMs) require a substantial amount of\ntraining data, as NBMs trained with scarce data may result in unreliable fault\ndiagnosis. To overcome this limitation, we present a novel generative deep\nlearning approach to make SCADA samples from one wind turbine lacking training\ndata resemble SCADA data from wind turbines with representative training data.\nThrough CycleGAN-based domain mapping, our method enables the application of an\nNBM trained on an existing wind turbine to one with severely limited data. We\ndemonstrate our approach on field data mapping SCADA samples across 7\nsubstantially different WTs. Our findings show significantly improved fault\ndiagnosis in wind turbines with scarce data. Our method achieves the most\nsimilar anomaly scores to an NBM trained with abundant data, outperforming NBMs\ntrained on scarce training data with improvements of +10.3% in F1-score when 1\nmonth of training data is available and +16.8% when 2 weeks are available. The\ndomain mapping approach outperforms conventional fine-tuning at all considered\ndegrees of data scarcity, ranging from 1 to 8 weeks of training data. The\nproposed technique enables earlier and more reliable fault diagnosis in newly\ninstalled wind farms, demonstrating a novel and promising research direction to\nimprove anomaly detection when faced with training data scarcity.","main_category":"cs.LG","categories":"cs.LG,cs.SY,eess.SY","published":"2025-04-24T16:14:04Z"}
{"aid":"http://arxiv.org/abs/2504.17715v1","title":"Operational experience and performance of the Silicon Vertex Detector\n  after the first long shutdown of Belle II","summary":"In 2024, the Belle II experiment resumed data taking after the Long Shutdown\n1, which was required to install a two-layer pixel detector and upgrade\naccelerator components. We describe the challenges of this shutdown and the\noperational experience thereafter. With new data, the silicon-strip vertex\ndetector (SVD) confirmed the high hit efficiency, the large signal-to-noise\nratio, and the excellent cluster position resolution. In the coming years, the\nSuperKEKB peak luminosity is expected to increase to its target value,\nresulting in a larger SVD occupancy caused by beam background. Considerable\nefforts have been made to improve SVD reconstruction software by exploiting the\nexcellent SVD hit-time resolution to determine the collision time and reject\noff-time particle hits. A novel procedure to group SVD hits event-by-event,\nbased on their time, has been developed using the grouping information during\nreconstruction, significantly reducing the fake rate while preserving the\ntracking efficiency. The front-end chip (APV25) is operated in the multi-peak\nmode, which reads six samples. A 3/6-mixed acquisition mode, based on the\ntiming precision of the trigger, reduces background occupancy, trigger\ndead-time, and data size. Studies of the radiation damage show that the SVD\nperformance will not seriously degrade during the lifetime of the detector,\ndespite moderate radiation-induced increases in sensor current and strip noise.","main_category":"physics.ins-det","categories":"physics.ins-det,hep-ex","published":"2025-04-24T16:17:21Z"}
{"aid":"http://arxiv.org/abs/2504.17718v1","title":"Recursive feasibility for stochastic MPC and the rationale behind fixing\n  flat tires","summary":"In this paper, we address the problem of designing stochastic model\npredictive control (SMPC) schemes for linear systems affected by unbounded\ndisturbances. The contribution of the paper is rooted in a measured-state\ninitialization strategy. First, due to the nonzero probability of violating\nchance-constraints in the case of unbounded noise, we introduce\nellipsoidal-based probabilistic reachable sets and we include constraint\nrelaxations to recover recursive feasibility conditioned to the measured state.\nSecond, we prove that the solution of this novel SMPC scheme guarantees\nclosed-loop chance constraints satisfaction under minimum relaxation. Last, we\ndemonstrate that, in expectation, the need of relaxing the constraints vanishes\nover time, which leads the closed-loop trajectories steered towards the\nunconstrained LQR invariant region. This novel SMPC scheme is proven to satisfy\nthe recursive feasibility conditioned to the state realization, and its\nsuperiority with respect to open-loop initialization schemes is shown through\nnumerical examples.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-24T16:26:22Z"}
{"aid":"http://arxiv.org/abs/2504.17720v1","title":"Multilingual Performance Biases of Large Language Models in Education","summary":"Large language models (LLMs) are increasingly being adopted in educational\nsettings. These applications expand beyond English, though current LLMs remain\nprimarily English-centric. In this work, we ascertain if their use in education\nsettings in non-English languages is warranted. We evaluated the performance of\npopular LLMs on four educational tasks: identifying student misconceptions,\nproviding targeted feedback, interactive tutoring, and grading translations in\nsix languages (Hindi, Arabic, Farsi, Telugu, Ukrainian, Czech) in addition to\nEnglish. We find that the performance on these tasks somewhat corresponds to\nthe amount of language represented in training data, with lower-resource\nlanguages having poorer task performance. Although the models perform\nreasonably well in most languages, the frequent performance drop from English\nis significant. Thus, we recommend that practitioners first verify that the LLM\nworks well in the target language for their educational task before deployment.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-24T16:32:31Z"}
{"aid":"http://arxiv.org/abs/2504.17722v1","title":"What makes a good public EV charging station? A revealed preference\n  study","summary":"To determine the optimal locations for electric vehicle charging stations,\noptimisation models need to predict which charging stations users will select.\nWe estimate discrete choice models to predict the usage of charging stations\nusing only readily available information for charging network operators. Our\nparameter values are estimated from a unique, revealed preferences dataset of\ncharging sessions in Montreal, Quebec. We find that user distance to stations,\nproximity to home areas, and the number of outlets at each station are\nsignificant factors for predicting station usage. Additionally, amenities near\ncharging stations have a neutral effect overall, with some users demonstrating\nstrong preference or aversion for these locations. High variability among the\npreferences of users highlight the importance of models which incorporate panel\neffects. Moreover, integrating mixed logit models within the optimization of\ncharging station network design yields high-quality solutions, even when\nevaluated under other model specifications.","main_category":"math.OC","categories":"math.OC","published":"2025-04-24T16:34:13Z"}
{"aid":"http://arxiv.org/abs/2504.17731v1","title":"Synchronization of Quasi-Particle Excitations in a Quantum Gas with\n  Cavity-Mediated Interactions","summary":"Driven-dissipative quantum systems can undergo transitions from stationary to\ndynamical phases, reflecting the emergence of collective non-equilibrium\nbehavior. We study such a transition in a Bose-Einstein condensate coupled to\nan optical cavity and develop a cavity-assisted Bragg spectroscopy technique to\nresolve its collective modes. We observe dissipation-induced synchronization at\nthe quasiparticle level, where two roton-like modes coalesce at an exceptional\npoint. This reveals how dissipation microscopically drives collective dynamics\nand signals a precursor to a dynamical phase transition.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,physics.atom-ph,quant-ph","published":"2025-04-24T16:44:07Z"}
{"aid":"http://arxiv.org/abs/2504.17740v1","title":"Embedding Empirical Distributions for Computing Optimal Transport Maps","summary":"Distributional data have become increasingly prominent in modern signal\nprocessing, highlighting the necessity of computing optimal transport (OT) maps\nacross multiple probability distributions. Nevertheless, recent studies on\nneural OT methods predominantly focused on the efficient computation of a\nsingle map between two distributions. To address this challenge, we introduce a\nnovel approach to learning transport maps for new empirical distributions.\nSpecifically, we employ the transformer architecture to produce embeddings from\ndistributional data of varying length; these embeddings are then fed into a\nhypernetwork to generate neural OT maps. Various numerical experiments were\nconducted to validate the embeddings and the generated OT maps. The model\nimplementation and the code are provided on\nhttps://github.com/jiangmingchen/HOTET.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-24T16:52:48Z"}
{"aid":"http://arxiv.org/abs/2504.17758v1","title":"First study of neutrino angle reconstruction using quasielastic-like\n  interactions in MicroBooNE","summary":"We investigate the expected precision of the reconstructed neutrino direction\nusing a {\\nu}{\\mu}-argon quasielastic-like event topology with one muon and one\nproton in the final state and the reconstruction capabilities of the MicroBooNE\nliquid argon time projection chamber. This direction is of importance in the\ncontext of DUNE sub-GeV atmospheric oscillation studies. MicroBooNE allows for\na data-driven quantification of this resolution by investigating the deviation\nof the reconstructed muon-proton system orientation with respect to the\nwell-known direction of neutrinos originating from the Booster Neutrino Beam\nwith an exposure of 1.3 x 1021 protons on target. Using simulation studies, we\nderive the expected sub-GeV DUNE atmospheric-neutrino reconstructed simulated\nspectrum by developing a reweighting scheme as a function of the true neutrino\nenergy. We further report flux-integrated single- and double-differential cross\nsection measurements of charged-current {\\nu}{\\mu} quasielastic-like scattering\non argon as a function of the muon-proton system angle using the full\nMicroBooNE data sets. We also demonstrate the sensitivity of these results to\nnuclear effects and final state hadronic reinteraction modeling.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-24T17:20:49Z"}
{"aid":"http://arxiv.org/abs/2504.17768v1","title":"The Sparse Frontier: Sparse Attention Trade-offs in Transformer LLMs","summary":"Sparse attention offers a promising strategy to extend long-context\ncapabilities in Transformer LLMs, yet its viability, its efficiency-accuracy\ntrade-offs, and systematic scaling studies remain unexplored. To address this\ngap, we perform a careful comparison of training-free sparse attention methods\nat varying model scales, sequence lengths, and sparsity levels on a diverse\ncollection of long-sequence tasks-including novel ones that rely on natural\nlanguage while remaining controllable and easy to evaluate. Based on our\nexperiments, we report a series of key findings: 1) an isoFLOPS analysis\nreveals that for very long sequences, larger and highly sparse models are\npreferable to smaller and dense ones. 2) The level of sparsity attainable while\nstatistically guaranteeing accuracy preservation is higher during decoding than\nprefilling, and correlates with model size in the former. 3) There is no clear\nstrategy that performs best across tasks and phases, with different units of\nsparsification or budget adaptivity needed for different scenarios. Even\nmoderate sparsity levels often result in significant performance degradation on\nat least one task, highlighting that sparse attention is not a universal\nsolution. 4) We introduce and validate novel scaling laws specifically tailored\nfor sparse attention, providing evidence that our findings are likely to hold\ntrue beyond our range of experiments. Through these insights, we demonstrate\nthat sparse attention is a key tool to enhance the capabilities of Transformer\nLLMs for processing longer sequences, but requires careful evaluation of\ntrade-offs for performance-sensitive applications.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-24T17:39:25Z"}
{"aid":"http://arxiv.org/abs/2504.17791v1","title":"LiDPM: Rethinking Point Diffusion for Lidar Scene Completion","summary":"Training diffusion models that work directly on lidar points at the scale of\noutdoor scenes is challenging due to the difficulty of generating fine-grained\ndetails from white noise over a broad field of view. The latest works\naddressing scene completion with diffusion models tackle this problem by\nreformulating the original DDPM as a local diffusion process. It contrasts with\nthe common practice of operating at the level of objects, where vanilla DDPMs\nare currently used. In this work, we close the gap between these two lines of\nwork. We identify approximations in the local diffusion formulation, show that\nthey are not required to operate at the scene level, and that a vanilla DDPM\nwith a well-chosen starting point is enough for completion. Finally, we\ndemonstrate that our method, LiDPM, leads to better results in scene completion\non SemanticKITTI. The project page is https://astra-vision.github.io/LiDPM .","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-24T17:59:59Z"}
