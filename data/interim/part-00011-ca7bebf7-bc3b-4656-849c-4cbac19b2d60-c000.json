{"aid":"http://arxiv.org/abs/2503.21661v1","title":"From conceptualization to operationalized meaning via ontological\n  components","summary":"Ontologies enable knowledge sharing and interdisciplinary collaboration by\nproviding standardized, structured vocabularies for diverse communities. While\nlogical axioms are a cornerstone of ontology design, natural language elements\nsuch as annotations are equally critical for conveying intended meaning and\nensuring consistent term usage. This paper explores how meaning is represented\nin ontologies and how it can be effectively represented and communicated,\naddressing challenges such as indeterminacy of reference and meaning holism. To\nthis end, it proposes an approach founded on the use of a new structure, named\n'ontological component' and defined by: a term-centered design; enhanced\ncharacterization of both formal and natural language statements; an\noperationalizable definition of communicated meaning based on general\nassertions; and the integration of natural language elements into the logical\ntheory. By formalizing the meaning of ontological components, this work seeks\nto enhance the semantic robustness of terms, improving their clarity and\naccessibility across domains. Furthermore, it aims to address practical\nchallenges in applied ontologies, such as facilitating reuse and managing\nversioning, thereby strengthening their role in diverse applications.","main_category":"cs.FL","categories":"cs.FL,cs.LO","published":"2025-03-27T16:24:12Z"}
{"aid":"http://arxiv.org/abs/2503.21687v1","title":"Exploiting synergies between JWST and cosmic 21-cm observations to\n  uncover star formation in the early Universe","summary":"In the current era of JWST, we continue to uncover a wealth of information\nabout the Universe deep into the Epoch of Reionization. In this work, we run a\nsuite of simulations using the code 21cmSPACE, to explore the astrophysical\nproperties of galaxies in the early Universe, and their impact on high-redshift\nobservables. We use multi-wavelength observational data including the global\n21-cm signal and power spectrum limits from SARAS~3 and HERA respectively,\npresent-day diffuse X-ray and radio backgrounds, and UV luminosity functions\n(UVLFs) from HST and JWST in the range $z=6-14.5$ to derive our constraints. We\nconstrain a flexible model of halo-mass and redshift dependent star-formation\nefficiency (SFE), defined as the gas fraction converted into stars, and find\nthat it is best described by little to no redshift evolution at $z\\approx6-10$\nand rapid evolution at $z\\approx10-15$. We derive Bayesian functional posterior\ndistributions for the SFE across this redshift range, inferring that a halo of\nmass $M_h=10^{10}\\text{M}_\\odot$ has an efficiency of $2-3\\%$ at $z\\lesssim10$,\n$12\\%$ at $z=12$ and $26\\%$ at $z=15$. We also find, through synergy between\nSARAS~3 and UVLFs, that the minimum circular velocity for star-formation in\nhalos is $V_c = 16.9^{+25.7}_{-9.5}\\text{km s}^{-1}$ or equivalently\n$\\log_{10}(M_\\text{crit}/\\text{M}_\\odot) = 8.29^{+1.21}_{-1.08}$ at $z=6$.\nAlongside these star-formation constraints, we find the X-ray and radio\nefficiencies of early galaxies to be $f_X = 0.5^{+6.3}_{-0.3}$ and $f_r\n\\lesssim 11.7$ respectively, improving upon existing works that do not use UVLF\ndata. Our results demonstrate the critical role of UVLFs in constraining the\nearly Universe, and its synergies with 21-cm observations, alongside other\nmulti-wavelength observational datasets.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-03-27T16:54:22Z"}
{"aid":"http://arxiv.org/abs/2503.21702v1","title":"Enabling Robust Exoplanet Atmospheric Retrievals with Gaussian Processes","summary":"Atmospheric retrievals are essential tools for interpreting exoplanet\ntransmission and eclipse spectra, enabling quantitative constraints on the\nchemical composition, aerosol properties, and thermal structure of planetary\natmospheres. The James Webb Space Telescope (JWST) offers unprecedented\nspectral precision, resolution, and wavelength coverage, unlocking\ntransformative insights into the formation, evolution, climate, and potential\nhabitability of planetary systems. However, this opportunity is accompanied by\nchallenges: modeling assumptions and unaccounted-for noise or signal sources\ncan bias retrieval outcomes and their interpretation. To address these\nlimitations, we introduce a Gaussian Process (GP)-aided atmospheric retrieval\nframework that flexibly accounts for unmodeled features in exoplanet spectra,\nwhether global or localized. We validate this method on synthetic JWST\nobservations and show that GP-aided retrievals reduce bias in inferred\nabundances and better capture model-data mismatches than traditional\napproaches. We also introduce the concept of mean squared error to quantify the\ntrade-off between bias and variance, arguing that this metric more accurately\nreflects retrieval performance than bias alone. We then reanalyze the\nNIRISS/SOSS JWST transmission spectrum of WASP-96 b, finding that GP-aided\nretrievals yield broader constraints on CO$_2$ and H$_2$O, alleviating tension\nbetween previous retrieval results and equilibrium predictions. Our GP\nframework provides precise and accurate constraints while highlighting regions\nwhere models fail to explain the data. As JWST matures and future facilities\ncome online, a deeper understanding of the limitations of both data and models\nwill be essential, and GP-enabled retrievals like the one presented here offer\na principled path forward.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM","published":"2025-03-27T17:06:09Z"}
{"aid":"http://arxiv.org/abs/2503.21704v1","title":"Learning to Represent Individual Differences for Choice Decision Making","summary":"Human decision making can be challenging to predict because decisions are\naffected by a number of complex factors. Adding to this complexity,\ndecision-making processes can differ considerably between individuals, and\nmethods aimed at predicting human decisions need to take individual differences\ninto account. Behavioral science offers methods by which to measure individual\ndifferences (e.g., questionnaires, behavioral models), but these are often\nnarrowed down to low dimensions and not tailored to specific prediction tasks.\nThis paper investigates the use of representation learning to measure\nindividual differences from behavioral experiment data. Representation learning\noffers a flexible approach to create individual embeddings from data that are\nboth structured (e.g., demographic information) and unstructured (e.g., free\ntext), where the flexibility provides more options for individual difference\nmeasures for personalization, e.g., free text responses may allow for\nopen-ended questions that are less privacy-sensitive. In the current paper we\nuse representation learning to characterize individual differences in human\nperformance on an economic decision-making task. We demonstrate that models\nusing representation learning to capture individual differences consistently\nimprove decision predictions over models without representation learning, and\neven outperform well-known theory-based behavioral models used in these\nenvironments. Our results propose that representation learning offers a useful\nand flexible tool to capture individual differences.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-03-27T17:10:05Z"}
{"aid":"http://arxiv.org/abs/2503.21705v1","title":"SoK: Towards Reproducibility for Software Packages in Scripting Language\n  Ecosystems","summary":"The disconnect between distributed software artifacts and their supposed\nsource code enables attackers to leverage the build process for inserting\nmalicious functionality. Past research in this field focuses on compiled\nlanguage ecosystems, mostly analysing Linux distribution packages. However, the\npopular scripting language ecosystems potentially face unique issues given the\nsystematic difference in distributed artifacts. This SoK provides an overview\nof existing research, aiming to highlight future directions, as well as chances\nto transfer existing knowledge from compiled language ecosystems. To that end,\nwe work out key aspects in current research, systematize identified challenges\nfor software reproducibility, and map them between the ecosystems. We find that\nthe literature is sparse, focusing on few individual problems and ecosystems.\nThis allows us to effectively identify next steps to improve reproducibility in\nthis field.","main_category":"cs.SE","categories":"cs.SE,cs.CR","published":"2025-03-27T17:10:38Z"}
{"aid":"http://arxiv.org/abs/2503.21709v1","title":"Redefining Network Topology in Complex Systems: Merging Centrality\n  Metrics, Spectral Theory, and Diffusion Dynamics","summary":"This paper introduces a novel framework that combines traditional centrality\nmeasures with eigenvalue spectra and diffusion processes for a more\ncomprehensive analysis of complex networks. While centrality measures such as\ndegree, closeness, and betweenness have been commonly used to assess nodal\nimportance, they provide limited insight into dynamic network behaviors. By\nincorporating eigenvalue analysis, which evaluates network robustness and\nconnectivity through spectral properties, and diffusion processes that model\ninformation flow, this framework offers a deeper understanding of how networks\nfunction under dynamic conditions. Applied to synthetic networks, the approach\nidentifies key nodes not only by centrality but also by their role in diffusion\ndynamics and vulnerability points, offering a multi-dimensional view that\ntraditional methods alone cannot. This integrated analysis enables a more\nprecise identification of critical nodes and potential weaknesses, with\nimplications for improving network resilience in fields ranging from\nepidemiology to cybersecurity. Keywords: Centrality measures, eigenvalue\nspectra, diffusion processes, network analysis, network robustness, information\nflow, synthetic networks.","main_category":"cs.OH","categories":"cs.OH","published":"2025-03-27T17:21:46Z"}
{"aid":"http://arxiv.org/abs/2503.21721v1","title":"Evaluating Text-to-Image Synthesis with a Conditional Fréchet\n  Distance","summary":"Evaluating text-to-image synthesis is challenging due to misalignment between\nestablished metrics and human preferences. We propose cFreD, a metric based on\nthe notion of Conditional Fr\\'echet Distance that explicitly accounts for both\nvisual fidelity and text-prompt alignment. Existing metrics such as Inception\nScore (IS), Fr\\'echet Inception Distance (FID) and CLIPScore assess either\nimage quality or image-text alignment but not both which limits their\ncorrelation with human preferences. Scoring models explicitly trained to\nreplicate human preferences require constant updates and may not generalize to\nnovel generation techniques or out-of-domain inputs. Through extensive\nexperiments across multiple recently proposed text-to-image models and diverse\nprompt datasets, we demonstrate that cFreD exhibits a higher correlation with\nhuman judgments compared to statistical metrics, including metrics trained with\nhuman preferences. Our findings validate cFreD as a robust, future-proof metric\nfor the systematic evaluation of text-to-image models, standardizing\nbenchmarking in this rapidly evolving field. We release our evaluation toolkit\nand benchmark in the appendix.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:35:14Z"}
{"aid":"http://arxiv.org/abs/2503.21753v1","title":"Quantum enhanced parameter estimation with monitored quantum\n  nonequilibrium systems using inefficient photo detection","summary":"Many-body quantum systems hosting emergent collective behavior bear the\npromise to enable quantum enhanced parameter estimation. Formally this means\nthat the variance of the parameter to be estimated decreases faster than\n$N^{-1}$, where $N$ is the number of particles forming the quantum system. In\npractice such scaling is challenging to achieve as the underlying many-body\ncorrelations are fragile. Moreover, devising the optimal measurements that\nindeed tap the quantum enhancement is often rather involved. Here we show that\nthe inefficient detection of the photo emission from a dissipative quantum\nmany-body system is sufficient to reach quantum enhanced parameter estimation\neven when some loss channels remain completely unmonitored. We illustrate our\napproach by considering the so-called boundary time-crystal, which is a\nnonequilibrium many-body system that has been realized recently experimentally\nin cold atomic gases. By analyzing the structure of the temporal correlations\nof its emission field, we are able to construct a family of near optimal\nparameter estimation measurements with a simple interferometric setup.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-27T17:56:57Z"}
{"aid":"http://arxiv.org/abs/2503.21755v1","title":"VBench-2.0: Advancing Video Generation Benchmark Suite for Intrinsic\n  Faithfulness","summary":"Video generation has advanced significantly, evolving from producing\nunrealistic outputs to generating videos that appear visually convincing and\ntemporally coherent. To evaluate these video generative models, benchmarks such\nas VBench have been developed to assess their faithfulness, measuring factors\nlike per-frame aesthetics, temporal consistency, and basic prompt adherence.\nHowever, these aspects mainly represent superficial faithfulness, which focus\non whether the video appears visually convincing rather than whether it adheres\nto real-world principles. While recent models perform increasingly well on\nthese metrics, they still struggle to generate videos that are not just\nvisually plausible but fundamentally realistic. To achieve real \"world models\"\nthrough video generation, the next frontier lies in intrinsic faithfulness to\nensure that generated videos adhere to physical laws, commonsense reasoning,\nanatomical correctness, and compositional integrity. Achieving this level of\nrealism is essential for applications such as AI-assisted filmmaking and\nsimulated world modeling. To bridge this gap, we introduce VBench-2.0, a\nnext-generation benchmark designed to automatically evaluate video generative\nmodels for their intrinsic faithfulness. VBench-2.0 assesses five key\ndimensions: Human Fidelity, Controllability, Creativity, Physics, and\nCommonsense, each further broken down into fine-grained capabilities. Tailored\nfor individual dimensions, our evaluation framework integrates generalists such\nas state-of-the-art VLMs and LLMs, and specialists, including anomaly detection\nmethods proposed for video generation. We conduct extensive annotations to\nensure alignment with human judgment. By pushing beyond superficial\nfaithfulness toward intrinsic faithfulness, VBench-2.0 aims to set a new\nstandard for the next generation of video generative models in pursuit of\nintrinsic faithfulness.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:57:01Z"}
{"aid":"http://arxiv.org/abs/2503.21763v1","title":"Identification and estimation of treatment effects in a linear factor\n  model with fixed number of time periods","summary":"This paper provides a new approach for identifying and estimating the Average\nTreatment Effect on the Treated under a linear factor model that allows for\nmultiple time-varying unobservables. Unlike the majority of the literature on\ntreatment effects in linear factor models, our approach does not require the\nnumber of pre-treatment periods to go to infinity to obtain a valid estimator.\nOur identification approach employs a certain nonlinear transformations of the\ntime invariant observed covariates that are sufficiently correlated with the\nunobserved variables. This relevance condition can be checked with the\navailable data on pre-treatment periods by validating the correlation of the\ntransformed covariates and the pre-treatment outcomes. Based on our\nidentification approach, we provide an asymptotically unbiased estimator of the\neffect of participating in the treatment when there is only one treated unit\nand the number of control units is large.","main_category":"econ.EM","categories":"econ.EM","published":"2025-03-27T17:58:17Z"}
{"aid":"http://arxiv.org/abs/2503.21771v1","title":"A Unified Image-Dense Annotation Generation Model for Underwater Scenes","summary":"Underwater dense prediction, especially depth estimation and semantic\nsegmentation, is crucial for gaining a comprehensive understanding of\nunderwater scenes. Nevertheless, high-quality and large-scale underwater\ndatasets with dense annotations remain scarce because of the complex\nenvironment and the exorbitant data collection costs. This paper proposes a\nunified Text-to-Image and DEnse annotation generation method (TIDE) for\nunderwater scenes. It relies solely on text as input to simultaneously generate\nrealistic underwater images and multiple highly consistent dense annotations.\nSpecifically, we unify the generation of text-to-image and text-to-dense\nannotations within a single model. The Implicit Layout Sharing mechanism (ILS)\nand cross-modal interaction method called Time Adaptive Normalization (TAN) are\nintroduced to jointly optimize the consistency between image and dense\nannotations. We synthesize a large-scale underwater dataset using TIDE to\nvalidate the effectiveness of our method in underwater dense prediction tasks.\nThe results demonstrate that our method effectively improves the performance of\nexisting underwater dense prediction models and mitigates the scarcity of\nunderwater data with dense annotations. We hope our method can offer new\nperspectives on alleviating data scarcity issues in other fields. The code is\navailable at https: //github.com/HongkLin/TIDE.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:43Z"}
{"aid":"http://arxiv.org/abs/2503.21773v1","title":"Simulating quantum circuits with restricted quantum computers","summary":"It is one of the most fundamental objectives in quantum information science\nto understand the boundary between the computational power of classical and\nquantum computers. One possible avenue to explore this boundary is to identify\nclasses of quantum circuits that can be efficiently simulated on a classical\ncomputer. Instead of simulating a general quantum circuit with a classical\ndevice, new schemes have recently emerged to simulate them on a quantum device\nthat is restricted in some manner. As such, these techniques allow us to study\nhow the restrictions impact the computational power of the device. One such\ntechnique is called quasiprobability simulation (QPS) and it estimates the\nresult of a quantum circuit with a Monte Carlo procedure that randomly replaces\ncircuit elements with ones that can be executed on the restricted quantum\ndevice.\n  The main focus of this thesis is dedicated to the QPS-based simulation of\nnonlocal quantum computation using local quantum operations. On the practical\nside, this enables the simulation of large quantum circuits using multiple\nsmaller quantum devices - a procedure that is sometimes called circuit\nknitting. We uncover a rich mathematical formalism with many connections to the\nresource theory of entanglement. We characterize the optimal simulation\noverhead for a broad range of practically relevant nonlocal states and channels\nand we explicitly provide achieving protocols. Moreover, we also investigate\nthe utility of classical communication between the local parties. Our results\naddress both the single-shot and asymptotic regime.\n  We frame QPS in a quantum resource theoretic framework, which highlights\nsimilarities that arise in the different instantiations of the technique.\nFurthermore, we study the importance of classical side information in the QPS\nprocedure and how it impacts the overhead and expressibility of QPS.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-27T17:59:45Z"}
{"aid":"http://arxiv.org/abs/2503.21776v1","title":"Video-R1: Reinforcing Video Reasoning in MLLMs","summary":"Inspired by DeepSeek-R1's success in eliciting reasoning abilities through\nrule-based reinforcement learning (RL), we introduce Video-R1 as the first\nattempt to systematically explore the R1 paradigm for eliciting video reasoning\nwithin multimodal large language models (MLLMs). However, directly applying RL\ntraining with the GRPO algorithm to video reasoning presents two primary\nchallenges: (i) a lack of temporal modeling for video reasoning, and (ii) the\nscarcity of high-quality video-reasoning data. To address these issues, we\nfirst propose the T-GRPO algorithm, which encourages models to utilize temporal\ninformation in videos for reasoning. Additionally, instead of relying solely on\nvideo data, we incorporate high-quality image-reasoning data into the training\nprocess. We have constructed two datasets: Video-R1-COT-165k for SFT cold start\nand Video-R1-260k for RL training, both comprising image and video data.\nExperimental results demonstrate that Video-R1 achieves significant\nimprovements on video reasoning benchmarks such as VideoMMMU and VSI-Bench, as\nwell as on general video benchmarks including MVBench and TempCompass, etc.\nNotably, Video-R1-7B attains a 35.8% accuracy on video spatial reasoning\nbenchmark VSI-bench, surpassing the commercial proprietary model GPT-4o. All\ncodes, models, data are released.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:51Z"}
{"aid":"http://arxiv.org/abs/2503.23710v1","title":"Formation of the Little Red Dots from the Core-collapse of\n  Self-interacting Dark Matter Halos","summary":"We present a statistical study on the formation and growth of black holes\n(BHs) seeded by gravothermal core-collapse of self-interacting dark matter\n(SIDM) halos at high redshifts, using a semi-analytical framework based on\nMonte-Carlo merger trees. We demonstrate that BH formation via gravothermal\ncollapse naturally occurs in high-concentration halos at a characteristic mass\nscale determined by the SIDM cross section, and only during the early Universe.\nThis mechanism is particularly promising for explaining the abundance of little\nred dots (LRDs) -- a population of early, apparently galaxy-less active\ngalactic nuclei hosting supermassive BHs. By incorporating this seeding process\nwith simplified models of BH growth and mergers, we successfully reproduce the\nobserved LRD mass function for moderately large cross sections of $\\sigma_{0m}\n\\sim 30 \\mathrm{cm^2\\,g^{-1}}$ and $\\omega \\sim 80\\,\\mathrm{km\\,s^{-1}}$,\nintriguingly consistent with independent local constraints derived from galaxy\nrotation curves. Our results highlight the potential of high-redshift BH\nstatistics as a complementary probe for constraining SIDM models.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-03-31T04:15:20Z"}
{"aid":"http://arxiv.org/abs/2503.23722v1","title":"LATex: Leveraging Attribute-based Text Knowledge for Aerial-Ground\n  Person Re-Identification","summary":"Aerial-Ground person Re-IDentification (AG-ReID) aims to retrieve specific\npersons across heterogeneous cameras in different views. Previous methods\nusually adopt large-scale models, focusing on view-invariant features. However,\nthey overlook the semantic information in person attributes. Additionally,\nexisting training strategies often rely on full fine-tuning large-scale models,\nwhich significantly increases training costs. To address these issues, we\npropose a novel framework named LATex for AG-ReID, which adopts prompt-tuning\nstrategies to leverage attribute-based text knowledge. More specifically, we\nfirst introduce the Contrastive Language-Image Pre-training (CLIP) model as the\nbackbone, and propose an Attribute-aware Image Encoder (AIE) to extract global\nsemantic features and attribute-aware features. Then, with these features, we\npropose a Prompted Attribute Classifier Group (PACG) to generate person\nattribute predictions and obtain the encoded representations of predicted\nattributes. Finally, we design a Coupled Prompt Template (CPT) to transform\nattribute tokens and view information into structured sentences. These\nsentences are processed by the text encoder of CLIP to generate more\ndiscriminative features. As a result, our framework can fully leverage\nattribute-based text knowledge to improve the AG-ReID. Extensive experiments on\nthree AG-ReID benchmarks demonstrate the effectiveness of our proposed LATex.\nThe source code will be available.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T04:47:05Z"}
{"aid":"http://arxiv.org/abs/2503.23741v1","title":"Classification of Modular Symmetries in Non-Supersymmetric Heterotic\n  String theories","summary":"We study modular symmetries in non-supersymmetric heterotic string theories\non toroidal backgrounds with Wilson line modulus, constructed by stringy\nScherk-Schwartz compactification. In particular, we focus on a subgroup of the\nT-duality group $O(D+16,D,\\mathbb{Z})$ with $D=2$ given by an outer\nautomorphism of the Narain lattice, which can be mapped to the Siegel modular\ngroup $\\mathrm{Sp}(4,\\mathbb{Z})$. We classify the modular symmetries and a\n$CP$-like symmetry on $T^2$ and its orbifolds with symmetric and asymmetric\norbifold twists. It turns out that the non-supersymmetric heterotic string\ntheories only enjoy a part of modular symmetries in contrast to supersymmetric\nones. Furthermore, the gauge symmetry is maximally enhanced at fixed points of\nmodular symmetries on $T^2$ on which we analyze the vacuum structure of\neight-dimensional tachyon-free vacua.","main_category":"hep-th","categories":"hep-th","published":"2025-03-31T05:42:06Z"}
{"aid":"http://arxiv.org/abs/2503.23751v1","title":"Decoupled Distillation to Erase: A General Unlearning Method for Any\n  Class-centric Tasks","summary":"In this work, we present DEcoupLEd Distillation To Erase (DELETE), a general\nand strong unlearning method for any class-centric tasks. To derive this, we\nfirst propose a theoretical framework to analyze the general form of unlearning\nloss and decompose it into forgetting and retention terms. Through the\ntheoretical framework, we point out that a class of previous methods could be\nmainly formulated as a loss that implicitly optimizes the forgetting term while\nlacking supervision for the retention term, disturbing the distribution of\npre-trained model and struggling to adequately preserve knowledge of the\nremaining classes. To address it, we refine the retention term using \"dark\nknowledge\" and propose a mask distillation unlearning method. By applying a\nmask to separate forgetting logits from retention logits, our approach\noptimizes both the forgetting and refined retention components simultaneously,\nretaining knowledge of the remaining classes while ensuring thorough forgetting\nof the target class. Without access to the remaining data or intervention\n(i.e., used in some works), we achieve state-of-the-art performance across\nvarious benchmarks. What's more, DELETE is a general solution that can be\napplied to various downstream tasks, including face recognition, backdoor\ndefense, and semantic segmentation with great performance.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T06:02:27Z"}
{"aid":"http://arxiv.org/abs/2503.23761v1","title":"Two approaches to the holomorphic modular bootstrap","summary":"The holomorphic bootstrap attempts to classify rational conformal field\ntheories. The straight ahead approach is hard to implement when the number of\ncharacters become large. We combine all characters of an RCFT to form a vector\nvalued modular form with multiplier. Using known results from the theory of\nvector valued modular forms, given a known RCFT, we obtain new vector valued\nmodular forms that share the same multiplier as the original RCFT. By taking\nparticular linear combinations of the new solutions, we look for and find new\nadmissible solutions. In the well-studied two character case, we reproduce all\nknown admissible solutions with Wronskian indices $6$ and $8$. The method is\nillustrated with examples with up to six characters. The method using vector\nvalued modular forms thus provides a new approach to the holomorphic modular\nbootstrap.","main_category":"hep-th","categories":"hep-th","published":"2025-03-31T06:26:56Z"}
{"aid":"http://arxiv.org/abs/2503.23775v1","title":"Evaluation of (Un-)Supervised Machine Learning Methods for GNSS\n  Interference Classification with Real-World Data Discrepancies","summary":"The accuracy and reliability of vehicle localization on roads are crucial for\napplications such as self-driving cars, toll systems, and digital tachographs.\nTo achieve accurate positioning, vehicles typically use global navigation\nsatellite system (GNSS) receivers to validate their absolute positions.\nHowever, GNSS-based positioning can be compromised by interference signals,\nnecessitating the identification, classification, determination of purpose, and\nlocalization of such interference to mitigate or eliminate it. Recent\napproaches based on machine learning (ML) have shown superior performance in\nmonitoring interference. However, their feasibility in real-world applications\nand environments has yet to be assessed. Effective implementation of ML\ntechniques requires training datasets that incorporate realistic interference\nsignals, including real-world noise and potential multipath effects that may\noccur between transmitter, receiver, and satellite in the operational area.\nAdditionally, these datasets require reference labels. Creating such datasets\nis often challenging due to legal restrictions, as causing interference to GNSS\nsources is strictly prohibited. Consequently, the performance of ML-based\nmethods in practical applications remains unclear. To address this gap, we\ndescribe a series of large-scale measurement campaigns conducted in real-world\nsettings at two highway locations in Germany and the Seetal Alps in Austria,\nand in large-scale controlled indoor environments. We evaluate the latest\nsupervised ML-based methods to report on their performance in real-world\nsettings and present the applicability of pseudo-labeling for unsupervised\nlearning. We demonstrate the challenges of combining datasets due to data\ndiscrepancies and evaluate outlier detection, domain adaptation, and data\naugmentation techniques to present the models' capabilities to adapt to changes\nin the datasets.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-03-31T06:51:52Z"}
{"aid":"http://arxiv.org/abs/2503.23780v1","title":"Computing algebraic Belyi functions on Bring's curve","summary":"In this paper, we explicitly compute two kinds of algebraic Belyi functions\non Bring's curve. One is related to a congruence subgroup of ${\\rm\nSL}_2(\\mathbb{Z})$ and the other is relate to a congruence subgroup of the\ntriangle group $\\Delta(2,4,5)\\subset {\\rm SL}_2(\\mathbb{R})$. To carry out the\ncomputation, we use elliptic cusp forms of weight 2 for the former case while\nthe automorphism group of Bring's curve for the latter case. We also discuss a\nsuitable base field (a number field) for isomorphisms between Hulek-Craig's\ncurve, Bring's curve, and its another algebraic model obtained as a modular\ncurve.","main_category":"math.NT","categories":"math.NT,math.AG,math.CV","published":"2025-03-31T06:53:56Z"}
{"aid":"http://arxiv.org/abs/2503.23783v1","title":"ANNs-SaDE: A Machine-Learning-Based Design Automation Framework for\n  Microwave Branch-Line Couplers","summary":"The traditional method for designing branch-line couplers involves a\ntrial-and-error optimization process that requires multiple design iterations\nthrough electromagnetic (EM) simulations. Thus, it is extremely time consuming\nand labor intensive. In this paper, a novel machine-learning-based framework is\nproposed to tackle this issue. It integrates artificial neural networks with a\nself-adaptive differential evolution algorithm (ANNs-SaDE). This framework\nenables the self-adaptive design of various types of microwave branch-line\ncouplers by precisely optimizing essential electrical properties, such as\ncoupling factor, isolation, and phase difference between output ports. The\neffectiveness of the ANNs-SaDE framework is demonstrated by the designs of\nfolded single-stage branch-line couplers and multi-stage wideband branch-line\ncouplers.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T06:58:29Z"}
{"aid":"http://arxiv.org/abs/2503.23797v1","title":"Kiloparsec-Scale Alignment of a Radio Jet with Cool Gas and Dust in a\n  z~6 Quasar","summary":"We present high-angular resolution (0.068\", ~400pc) ALMA imaging of the [CII]\nline and dust continuum emission of PSO J352.4034-15.3373, a radio-loud quasar\nat z=5.83. The observations reveal a remarkably close match between the\norientation of the [CII] and thermal dust emission mapped by ALMA, and radio\nsynchrotron emission of a radio jet previously mapped by the VLBA. This narrow\nalignment extends over ~4kpc, reminiscent of the well-studied 'alignment\neffect' in lower-redshift radio galaxies. The [CII] kinematics show a linear\nincrease in velocity with galactocentric radii up to ~200 km/s at r=2kpc,\nconsistent with bulk motions within the galaxy potential, and not relativistic\njet motions. The kinematics and respective morphologies are consistent with a\npicture in which the relativistic jet injects energy into the interstellar\nmedium (potentially leading to subsequent star formation), giving rise to the\nobserved alignment and significant (> 100 km/s) [CII] velocity dispersion\nwithin the host galaxy on kiloparsec scales. Indeed, the astonishingly close\nalignment and narrow linearity of the radio jet with the [CII] and dust\nemission are hard to conceive without some fundamental relationship between the\ntwo.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-03-31T07:19:54Z"}
{"aid":"http://arxiv.org/abs/2503.23804v1","title":"Get the Agents Drunk: Memory Perturbations in Autonomous Agent-based\n  Recommender Systems","summary":"Large language model-based agents are increasingly used in recommender\nsystems (Agent4RSs) to achieve personalized behavior modeling. Specifically,\nAgent4RSs introduces memory mechanisms that enable the agents to autonomously\nlearn and self-evolve from real-world interactions. However, to the best of our\nknowledge, how robust Agent4RSs are remains unexplored. As such, in this paper,\nwe propose the first work to attack Agent4RSs by perturbing agents' memories,\nnot only to uncover their limitations but also to enhance their security and\nrobustness, ensuring the development of safer and more reliable AI agents.\n  Given the security and privacy concerns, it is more practical to launch\nattacks under a black-box setting, where the accurate knowledge of the victim\nmodels cannot be easily obtained. Moreover, the practical attacks are often\nstealthy to maximize the impact. To this end, we propose a novel practical\nattack framework named DrunkAgent. DrunkAgent consists of a generation module,\na strategy module, and a surrogate module. The generation module aims to\nproduce effective and coherent adversarial textual triggers, which can be used\nto achieve attack objectives such as promoting the target items. The strategy\nmodule is designed to `get the target agents drunk' so that their memories\ncannot be effectively updated during the interaction process. As such, the\ntriggers can play the best role. Both of the modules are optimized on the\nsurrogate module to improve the transferability and imperceptibility of the\nattacks. By identifying and analyzing the vulnerabilities, our work provides\ncritical insights that pave the way for building safer and more resilient\nAgent4RSs. Extensive experiments across various real-world datasets demonstrate\nthe effectiveness of DrunkAgent.","main_category":"cs.CR","categories":"cs.CR,cs.CL,cs.IR,cs.MA","published":"2025-03-31T07:35:40Z"}
{"aid":"http://arxiv.org/abs/2503.23818v1","title":"Free Parametrization of L2-bounded State Space Models","summary":"Structured state-space models (SSMs) have emerged as a powerful architecture\nin machine learning and control, featuring stacked layers where each consists\nof a linear time-invariant (LTI) discrete-time system followed by a\nnonlinearity. While SSMs offer computational efficiency and excel in\nlong-sequence predictions, their widespread adoption in applications like\nsystem identification and optimal control is hindered by the challenge of\nensuring their stability and robustness properties. We introduce L2RU, a novel\nparametrization of SSMs that guarantees input-output stability and robustness\nby enforcing a prescribed L-bound for all parameter values. This design\neliminates the need for complex constraints, allowing unconstrained\noptimization over L2RUs by using standard methods such as gradient descent.\nLeveraging tools from system theory and convex optimization, we derive a\nnon-conservative parametrization of square discrete-time LTI systems with a\nspecified L2-bound, forming the foundation of the L2RU architecture.\nAdditionally, we enhance its performance with a bespoke initialization strategy\noptimized for long input sequences. Through a system identification task, we\nvalidate L2RU's superior performance, showcasing its potential in learning and\ncontrol applications.","main_category":"eess.SY","categories":"eess.SY,cs.LG,cs.SY","published":"2025-03-31T07:56:17Z"}
{"aid":"http://arxiv.org/abs/2503.23831v1","title":"Adjoint-based optimization of the Rayleigh-Bénard instability with\n  melting boundary","summary":"In this work, we propose an adjoint-based optimization procedure to control\nthe onset of the Rayleigh-B\\'enard instability with a melting front. A novel\ncut cell method is used to solve the Navier-Stokes equations in the Boussinesq\napproximation and the convection-diffusion equation in the fluid layer, as well\nas the heat equation in the solid phase. To track the interface we use the\nlevel set method where its evolution is simply governed by an advection\nequation. An incomplete continuous adjoint problem is then derived by\nconsidering that the velocity field is a check-pointing variable. The results\nof the minimization problem with a tracking-type cost-functional show that our\nadjoint method is well suited to optimize the shapes of the fronts in this\nconfiguration.","main_category":"math-ph","categories":"math-ph,math.MP","published":"2025-03-31T08:26:06Z"}
{"aid":"http://arxiv.org/abs/2503.23845v1","title":"On the depth of subgroups of simple groups","summary":"The depth of a subgroup $H$ of a finite group $G$ is a positive integer\ndefined with respect to the inclusion of the corresponding complex group\nalgebras $\\mathbb{C}H \\subseteq \\mathbb{C}G$. This notion was originally\nintroduced by Boltje, Danz and K\\\"{u}lshammer in 2011, and it has been the\nsubject of numerous papers in recent years. In this paper, we study the depth\nof core-free subgroups, which allows us to apply powerful computational and\nprobabilistic techniques that were originally designed for studying bases for\npermutation groups. We use these methods to prove a wide range of new results\non the depth of subgroups of almost simple groups, significantly extending the\nscope of earlier work in this direction. For example, we establish best\npossible bounds on the depth of irreducible subgroups of classical groups and\nprimitive subgroups of symmetric groups. And with the exception of a handful of\nopen cases involving the Baby Monster, we calculate the exact depth of every\nsubgroup of every almost simple sporadic group. We also present a number of\nopen problems and conjectures.","main_category":"math.GR","categories":"math.GR,math.RT","published":"2025-03-31T08:46:46Z"}
{"aid":"http://arxiv.org/abs/2503.23846v1","title":"Exchange cross-talk mitigation in dense quantum dot arrays","summary":"Coupled spins in semiconductor quantum dots are a versatile platform for\nquantum computing and simulations of complex many-body phenomena. However, on\nthe path of scale-up, cross-talk from densely packed electrodes poses a severe\nchallenge. While cross-talk onto the dot potentials is nowadays routinely\ncompensated for, cross-talk on the exchange interaction is much more difficult\nto tackle because it is not always directly measurable. Here we propose and\nimplement a way of characterizing and compensating cross-talk on adjacent\nexchange interactions by following the singlet-triplet avoided crossing in Ge.\nWe show that we can easily identify the barrier-to-barrier cross-talk element\nwithout knowledge of the particular exchange value in a 2x4 quantum dot array.\nWe uncover striking differences among these cross-talk elements which can be\nlinked to the geometry of the device and the barrier gate fan-out. We validate\nthe methodology by tuning up four-spin Heisenberg chains. The same methodology\nshould be applicable to longer chains of spins and to other semiconductor\nplatforms in which mixing of the singlet and the lowest-energy triplet is\npresent or can be engineered. Additionally, this procedure is well suited for\nautomated tuning routines as we obtain a stand-out feature that can be easily\ntracked and directly returns the magnitude of the cross-talk.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-03-31T08:50:43Z"}
{"aid":"http://arxiv.org/abs/2503.23852v1","title":"Multispacecraft Observations of the 2024 September 9 Backside Solar\n  Eruption that Resulted in a Sustained Gamma Ray Emission Event","summary":"We report on the 2024 September 9 sustained gamma ray emission (SGRE) event\nobserved by the Large Area Telescope onboard the Fermi satellite. The event was\nassociated with a backside solar eruption observed by multiple spacecraft such\nas the Solar and Heliospheric Observatory (SOHO), Solar Terrestrial Relations\nObservatory (STEREO), Parker Solar Probe (PSP), Solar Orbiter (SolO), Solar\nDynamics Observatory (SDO), Wind, and GOES, and by ground based radio\ntelescopes. SolO Spectrometer Telescope for Imaging X rays (STIX) imaged an\nintense flare, which occurred about 41 deg behind the east limb, from\nheliographic coordinates S13E131. Forward modeling of the CME flux rope\nrevealed that it impulsively accelerated (3.54 km s^{-2}) to attain a peak\nspeed of 2162 km s^{-1}. SolO energetic particle detectors (EPD) observed\nprotons up to about 1 GeV from the extended shock and electrons that produced a\ncomplex type II burst and possibly type III bursts. The durations of SGRE and\ntype II burst are consistent with the linear relation between these quantities\nobtained from longer duration (exceeding 3 hours) SGRE events. All these\nobservations are consistent with an extended shock surrounding the CME flux\nrope, which is the likely source of high energy protons required for the SGRE\nevent. We compare this event with six other BTL SGRE eruptions and find that\nthey are all consistent with energetic shock driving CMEs. We also find a\nsignificant east west asymmetry in the BTL source locations.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.HE","published":"2025-03-31T08:56:13Z"}
{"aid":"http://arxiv.org/abs/2503.23855v1","title":"Physics case for low-$\\sqrt{s}$ QCD studies at FCC-ee","summary":"Measurements of hadronic final states in $e^{+}e^{-}$ collisions at\ncentre-of-mass (CM) energies below the Z peak can notably extend the FCC-ee\nphysics reach in terms of precision quantum chromodynamics (QCD) studies.\nHadronic final states can be studied over a range of hadronic energies\n$\\sqrt{s_\\mathrm{had}} \\approx 20\\mbox{--}80\\,\\mathrm{GeV}$ by exploiting\nevents with hard initial- and final-state QED radiation (ISR/FSR) during the\nhigh-luminosity Z-pole run, as well as in dedicated short (about one month\nlong) $e^{+}e^{-}$ runs at CM energies $\\sqrt{s} \\approx 40\\,\\mathrm{GeV}$ and\n$60\\,\\mathrm{GeV}$. Using realistic estimates and fast detector simulations, we\nshow that data samples of about $10^{9}$ hadronic events can be collected at\nthe FCC-ee at each of the low-CM-energy points. Such datasets can be exploited\nin a variety of precision QCD measurements, including studies of light-,\nheavy-quark and gluon jet properties, hadronic event shapes, fragmentation\nfunctions, and nonperturbative dynamics. This will offer valuable insights into\nstrong interaction physics, complementing data from nominal FCC-ee runs at\nhigher center-of-mass energies, $\\sqrt{s} \\approx 91, 160, 240,$ and\n$365\\,\\mathrm{GeV}$.","main_category":"hep-ex","categories":"hep-ex,hep-ph,hep-th","published":"2025-03-31T09:03:46Z"}
{"aid":"http://arxiv.org/abs/2503.23874v1","title":"He-Mg compounds and helium-driven nonmetal transition in metallic\n  magnesium","summary":"The polymorphism and mechanism of helium compounds is crucial for\nunderstanding the physical and chemical nature of He-bearing materials under\npressures. Here, we predict two new types of He-bearing compounds, MgHe and\nMgnHe (n = 6, 8, 10, 15, 18), being formed above 750 GPa by unbiased ab initio\nstructure search. An unexpected bandgap is opened up in MgHe at as low as\naround 200 GPa. This is the first case of noble gas driven metal-nonmetal\ntransition in all elements. The same mechanism is demonstrated also being\napplicable to other metallic elements, and making beryllium transform into a\nnon-metallic state, a triumph that is impossible otherwise. Furthermore, the\nstability of the simple cubic phase of Mg (Mg-sc) is greatly enhanced by mixing\nwith He, which lowers the critical pressure of pure Mg-sc from about 1.1 TPa\ndown to 750 GPa to form ordered substitutional alloying phase of MgnHe on a\nsimple cubic lattice of Mg. This is the first report on Mg-based noble gas\nsubstitutional alloy, in sharp contrast to the conventional wisdom that He\npreferring interstitial sites. The observed striking influences of He\ndemonstrate the rich physics and chemistry of He-bearing compounds under\nultra-high pressures.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.other,physics.chem-ph,physics.comp-ph","published":"2025-03-31T09:25:09Z"}
{"aid":"http://arxiv.org/abs/2503.23893v1","title":"DiffScale: Continuous Downscaling and Bias Correction of Subseasonal\n  Wind Speed Forecasts using Diffusion Models","summary":"Renewable resources are strongly dependent on local and large-scale weather\nsituations. Skillful subseasonal to seasonal (S2S) forecasts -- beyond two\nweeks and up to two months -- can offer significant socioeconomic advantages to\nthe energy sector. This study aims to enhance wind speed predictions using a\ndiffusion model with classifier-free guidance to downscale S2S forecasts of\nsurface wind speed. We propose DiffScale, a diffusion model that super-resolves\nspatial information for continuous downscaling factors and lead times.\nLeveraging weather priors as guidance for the generative process of diffusion\nmodels, we adopt the perspective of conditional probabilities on sampling\nsuper-resolved S2S forecasts. We aim to directly estimate the density\nassociated with the target S2S forecasts at different spatial resolutions and\nlead times without auto-regression or sequence prediction, resulting in an\nefficient and flexible model. Synthetic experiments were designed to\nsuper-resolve wind speed S2S forecasts from the European Center for\nMedium-Range Weather Forecast (ECMWF) from a coarse resolution to a finer\nresolution of ERA5 reanalysis data, which serves as a high-resolution target.\nThe innovative aspect of DiffScale lies in its flexibility to downscale\narbitrary scaling factors, enabling it to generalize across various grid\nresolutions and lead times -without retraining the model- while correcting\nmodel errors, making it a versatile tool for improving S2S wind speed\nforecasts. We achieve a significant improvement in prediction quality,\noutperforming baselines up to week 3.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV,eess.IV","published":"2025-03-31T09:44:28Z"}
{"aid":"http://arxiv.org/abs/2503.23898v1","title":"An Explainable Neural Radiomic Sequence Model with Spatiotemporal\n  Continuity for Quantifying 4DCT-based Pulmonary Ventilation","summary":"Accurate evaluation of regional lung ventilation is essential for the\nmanagement and treatment of lung cancer patients, supporting assessments of\npulmonary function, optimization of therapeutic strategies, and monitoring of\ntreatment response. Currently, ventilation scintigraphy using nuclear medicine\ntechniques is widely employed in clinical practice; however, it is often\ntime-consuming, costly, and entails additional radiation exposure. In this\nstudy, we propose an explainable neural radiomic sequence model to identify\nregions of compromised pulmonary ventilation based on four-dimensional computed\ntomography (4DCT). A cohort of 45 lung cancer patients from the VAMPIRE dataset\nwas analyzed. For each patient, lung volumes were segmented from 4DCT, and\nvoxel-wise radiomic features (56-dimensional) were extracted across the\nrespiratory cycle to capture local intensity and texture dynamics, forming\ntemporal radiomic sequences. Ground truth ventilation defects were delineated\nvoxel-wise using Galligas-PET and DTPA-SPECT. To identify compromised regions,\nwe developed a temporal saliency-enhanced explainable long short-term memory\n(LSTM) network trained on the radiomic sequences. Temporal saliency maps were\ngenerated to highlight key features contributing to the model's predictions.\nThe proposed model demonstrated robust performance, achieving average (range)\nDice similarity coefficients of 0.78 (0.74-0.79) for 25 PET cases and 0.78\n(0.74-0.82) for 20 SPECT cases. The temporal saliency map explained three key\nradiomic sequences in ventilation quantification: during lung exhalation,\ncompromised pulmonary function region typically exhibits (1) an increasing\ntrend of intensity and (2) a decreasing trend of homogeneity, in contrast to\nhealthy lung tissue.","main_category":"physics.med-ph","categories":"physics.med-ph,cs.CV","published":"2025-03-31T09:47:03Z"}
{"aid":"http://arxiv.org/abs/2503.23934v1","title":"Green MLOps to Green GenOps: An Empirical Study of Energy Consumption in\n  Discriminative and Generative AI Operations","summary":"This study presents an empirical investigation into the energy consumption of\nDiscriminative and Generative AI models within real-world MLOps pipelines. For\nDiscriminative models, we examine various architectures and hyperparameters\nduring training and inference and identify energy-efficient practices. For\nGenerative AI, Large Language Models (LLMs) are assessed, focusing primarily on\nenergy consumption across different model sizes and varying service requests.\nOur study employs software-based power measurements, ensuring ease of\nreplication across diverse configurations, models, and datasets. We analyse\nmultiple models and hardware setups to uncover correlations among various\nmetrics, identifying key contributors to energy consumption. The results\nindicate that for Discriminative models, optimising architectures,\nhyperparameters, and hardware can significantly reduce energy consumption\nwithout sacrificing performance. For LLMs, energy efficiency depends on\nbalancing model size, reasoning complexity, and request-handling capacity, as\nlarger models do not necessarily consume more energy when utilisation remains\nlow. This analysis provides practical guidelines for designing green and\nsustainable ML operations, emphasising energy consumption and carbon footprint\nreductions while maintaining performance. This paper can serve as a benchmark\nfor accurately estimating total energy use across different types of AI models.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-03-31T10:28:04Z"}
{"aid":"http://arxiv.org/abs/2503.23967v1","title":"Note on $q=2$ paraparticle SYK model","summary":"We investigate the $q=2$ SYK model with paraparticles (PSYK$_2$), analyzing\nits thermodynamics and spectral form factor (SFF) using random matrix theory.\nThe Hamiltonian is quadratic, with coupling coefficients randomly drawn from\nthe Gaussian Unitary Ensemble (GUE). The model exhibits self-averaging behavior\nand shows a striking transition in SFF dynamics: while the fermionic SYK$_2$\ndisplays a ramp behavior $\\mathcal{K}(t) \\sim e^{C_0 t}$ with $C_0 \\sim \\ln N$,\nthe paraparticle cases exhibit $C_0 \\sim \\mathcal{O}(1)$. These findings offer\nnew insights into quantum systems with exotic statistics.","main_category":"hep-th","categories":"hep-th","published":"2025-03-31T11:32:06Z"}
{"aid":"http://arxiv.org/abs/2503.24000v1","title":"Rethinking Key-Value Cache Compression Techniques for Large Language\n  Model Serving","summary":"Key-Value cache (\\texttt{KV} \\texttt{cache}) compression has emerged as a\npromising technique to optimize Large Language Model (LLM) serving. It\nprimarily decreases the memory consumption of \\texttt{KV} \\texttt{cache} to\nreduce the computation cost. Despite the development of many compression\nalgorithms, their applications in production environments are still not\nprevalent. In this paper, we revisit mainstream \\texttt{KV} \\texttt{cache}\ncompression solutions from a practical perspective. Our contributions are\nthree-fold. First, we comprehensively review existing algorithmic designs and\nbenchmark studies for \\texttt{KV} \\texttt{cache} compression and identify\nmissing pieces in their performance measurement, which could hinder their\nadoption in practice. Second, we empirically evaluate representative\n\\texttt{KV} \\texttt{cache} compression methods to uncover two key issues that\naffect the computational efficiency: (1) while compressing \\texttt{KV}\n\\texttt{cache} can reduce memory consumption, current implementations (e.g.,\nFlashAttention, PagedAttention) do not optimize for production-level LLM\nserving, resulting in suboptimal throughput performance; (2) compressing\n\\texttt{KV} \\texttt{cache} may lead to longer outputs, resulting in increased\nend-to-end latency. We further investigate the accuracy performance of\nindividual samples rather than the overall performance, revealing the intrinsic\nlimitations in \\texttt{KV} \\texttt{cache} compression when handling specific\nLLM tasks. Third, we provide tools to shed light on future \\texttt{KV}\n\\texttt{cache} compression studies and facilitate their practical deployment in\nproduction. They are open-sourced in\n\\href{https://github.com/LLMkvsys/rethink-kv-compression}{https://github.com/LLMkvsys/rethink-kv-compression}.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-03-31T12:23:31Z"}
{"aid":"http://arxiv.org/abs/2503.24003v1","title":"A Robust Extrinsic Single-index Model for Spherical Data","summary":"Regression with a spherical response is challenging due to the absence of\nlinear structure, making standard regression models inadequate. Existing\nmethods, mainly parametric, lack the flexibility to capture the complex\nrelationship induced by spherical curvature, while methods based on techniques\nfrom Riemannian geometry often suffer from computational difficulties. The\nnon-Euclidean structure further complicates robust estimation, with very\nlimited work addressing this issue, despite the common presence of outliers in\ndirectional data. This article introduces a new semi-parametric approach, the\nextrinsic single-index model (ESIM) and its robust estimation, to address these\nlimitations. We establish large-sample properties of the proposed estimator\nwith a wide range of loss functions and assess their robustness using the\ninfluence function and standardized influence function. Specifically, we focus\non the robustness of the exponential squared loss (ESL), demonstrating\ncomparable efficiency and superior robustness over least squares loss under\nhigh concentration. We also examine how the tuning parameter for the ESL\nbalances efficiency and robustness, providing guidance on its optimal choice.\nThe computational efficiency and robustness of our methods are further\nillustrated via simulations and applications to geochemical compositional data.","main_category":"stat.ME","categories":"stat.ME","published":"2025-03-31T12:27:42Z"}
{"aid":"http://arxiv.org/abs/2503.24089v1","title":"Initial State Privacy of Nonlinear Systems on Riemannian Manifolds","summary":"In this paper, we investigate initial state privacy protection for\ndiscrete-time nonlinear closed systems. By capturing Riemannian geometric\nstructures inherent in such privacy challenges, we refine the concept of\ndifferential privacy through the introduction of an initial state adjacency set\nbased on Riemannian distances. A new differential privacy condition is\nformulated using incremental output boundedness, enabling the design of\ntime-varying Laplacian noise to achieve specified privacy guarantees. The\nproposed framework extends beyond initial state protection to also cover system\nparameter privacy, which is demonstrated as a special application.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-03-31T13:42:18Z"}
{"aid":"http://arxiv.org/abs/2503.24096v1","title":"DANTE-AD: Dual-Vision Attention Network for Long-Term Audio Description","summary":"Audio Description is a narrated commentary designed to aid vision-impaired\naudiences in perceiving key visual elements in a video. While short-form video\nunderstanding has advanced rapidly, a solution for maintaining coherent\nlong-term visual storytelling remains unresolved. Existing methods rely solely\non frame-level embeddings, effectively describing object-based content but\nlacking contextual information across scenes. We introduce DANTE-AD, an\nenhanced video description model leveraging a dual-vision Transformer-based\narchitecture to address this gap. DANTE-AD sequentially fuses both frame and\nscene level embeddings to improve long-term contextual understanding. We\npropose a novel, state-of-the-art method for sequential cross-attention to\nachieve contextual grounding for fine-grained audio description generation.\nEvaluated on a broad range of key scenes from well-known movie clips, DANTE-AD\noutperforms existing methods across traditional NLP metrics and LLM-based\nevaluations.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T13:49:43Z"}
{"aid":"http://arxiv.org/abs/2503.24112v1","title":"Characterization of norm and quasi-norm forms in S-adic setting","summary":"The goal of the present paper is to characterize the norm and quasi-norm\nforms defined over an arbitrary number field F in terms of their values at the\nS-integer points, where S is a finite set of valuations of F containing the\narchimedean ones. In this way we generalize the main result of the recent paper\n[T5], where the notion of a quasi-norm form is introduced when F = Q and S is a\nsingleton. In complement, we exhibit some relations with problems and results\nin this area of research.","main_category":"math.NT","categories":"math.NT","published":"2025-03-31T14:04:51Z"}
{"aid":"http://arxiv.org/abs/2503.24127v1","title":"Compression Metadata-assisted RoI Extraction and Adaptive Inference for\n  Efficient Video Analytics","summary":"Video analytics demand substantial computing resources, posing significant\nchallenges in computing resource-constrained environment. In this paper, to\nachieve high accuracy with acceptable computational workload, we propose a\ncost-effective regions of interest (RoIs) extraction and adaptive inference\nscheme based on the informative encoding metadata. Specifically, to achieve\nefficient RoI-based analytics, we explore motion vectors from encoding metadata\nto identify RoIs in non-reference frames through morphological opening\noperation. Furthermore, considering the content variation of RoIs, which calls\nfor inference by models with distinct size, we measure RoI complexity based on\nthe bitrate allocation information from encoding metadata. Finally, we design\nan algorithm that prioritizes scheduling RoIs to models of the appropriate\ncomplexity, balancing accuracy and latency. Extensive experimental results show\nthat our proposed scheme reduces latency by nearly 40% and improves 2.2% on\naverage in accuracy, outperforming the latest benchmarks.","main_category":"cs.MM","categories":"cs.MM","published":"2025-03-31T14:12:02Z"}
{"aid":"http://arxiv.org/abs/2503.24137v1","title":"Half-life and precision shape measurement of 2νββ decay\n  of $^{130}$Te","summary":"We present a new measurement of the 2nbb half-life of 130Te (T1/2) using the\nfirst complete model of the CUORE data, based on 1038 kg yr of collected\nexposure. Thanks to optimized data selection, we achieve a factor of two\nimprovement in precision, obtaining T1/2 = (9.32 +0.05 -0.04 (stat.) +0.07\n-0.07 (syst.)) x10^20 yr. The signal-to-background ratio is increased by 70%\ncompared to our previous results, enabling the first application of the\nimproved 2nbb formalism to 130Te. Within this framework, we determine a\ncredibility interval for the effective axial coupling in the nuclear medium as\na function of nuclear matrix elements. We also extract values for the\nhigher-order nuclear matrix element ratios: second-to-first and third-to-first.\nThe second-to-first ratio agrees with nuclear model predictions, while the\nthird-to-first ratio deviates from theoretical expectations. These findings\nprovide essential tests of nuclear models and key inputs for future 0nbb\nsearches.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-03-31T14:19:33Z"}
{"aid":"http://arxiv.org/abs/2503.24158v1","title":"Current status of real-time imaging of antiproton annihilation in\n  biological targets","summary":"Following a successful pioneering study of the biological effects of\nantimatter ( the AD-4/ACE experiment at CERN), the use of antiprotons in\nclinical radiotherapy became a very serious possibility. A major part of any\nfuture radiotherapy using antiprotons will be real-time imaging of antiproton\nannihilation in biological targets. In principle, real-time imaging is possible\nthanks to the secondary particles, neutral pions and charger pions, produced by\nthe annihilation of antiprotons in the cells they come to a stop in.Neutral\npions decay dominantly and almost instantaneously into a photon pair, and one\napproach to real-time imaging is based on the detection of these high-energy\ngammas. An alternative is based on the detection of charged pions, which have\nlifetimes almost a billion times longer than neutral pions. This paper is a\nbrief review of this field of research, from the first real-time imaging\nachieved by the AD-4/ACE experiment in 2004 to the present day.","main_category":"physics.med-ph","categories":"physics.med-ph,hep-ph","published":"2025-03-31T14:42:01Z"}
{"aid":"http://arxiv.org/abs/2503.24163v1","title":"First-principles design of stable spin qubits in monolayer MoS2 with\n  elemental defect engineering","summary":"Quantum information science (QIS), encompassing technologies such as quantum\ncomputing, sensing, and communication, relies on the development and\nmanipulation of quantum bits (qubits). Recently, two-dimensional (2D) materials\n- characterized by their atomic thinness and external controllability - have\nemerged as promising candidates for qubit fabrication and manipulation at room\ntemperature. In this study, we propose that antisite defects (MX) in 2D\ntransition metal disulfides (TMDs) can serve as tunable quantum defects with\ncontrolled positioning. Using first-principles atomic structure simulations, we\nidentify six thermodynamically stable neutral antisite defects (MX, where M =\nMg, Ca, Sr, Ba, Zn, Cd; X = S) in monolayer 1H-MoS2. These defects exhibit\npotential as spin-defected qubits with stable triplet ground states.\nAdditionally, we demonstrate that the reduction of the bandgap leads to\nsignificant fluctuations in the absorption coefficient within the low-energy\nrange, resulting in the optical response within the desired telecommunication\nband, which is advantageous for quantum communication applications. The\nzero-phonon line (ZPL) associated with these qubits can serve as an effective\nidentifier. This work presents the novel, tunable approach to exploiting\ndefects in 2D materials, opening new possibilities for the development of qubit\nplatforms in quantum information technology.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-03-31T14:46:16Z"}
{"aid":"http://arxiv.org/abs/2503.24197v1","title":"Asymptotically distribution-free goodness-of-fit testing for point\n  processes","summary":"Consider an observation of a multivariate temporal point process $N$ with law\n$\\mathcal P$ on the time interval $[0,T]$. To test the null hypothesis that\n$\\mathcal P$ belongs to a given parametric family, we construct a convergent\ncompensated counting process to which we apply an innovation martingale\ntransformation. We prove that the resulting process converges weakly to a\nstandard Wiener process. Consequently, taking a suitable functional of this\nprocess yields an asymptotically distribution-free goodness-of-fit test for\npoint processes. For several standard tests based on the increments of this\ntransformed process, we establish consistency under alternative hypotheses.\nFinally, we assess the performance of the proposed testing procedure through a\nMonte Carlo simulation study and illustrate its practical utility with two\nreal-data examples.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-03-31T15:15:52Z"}
{"aid":"http://arxiv.org/abs/2503.24211v1","title":"A Quantum Walk Inspired Qubit Lattice Algorithm for Simulating\n  Electromagnetic Wave Propagation and Scattering in Conservative and\n  Dissipative Magnetized Plasmas","summary":"Based on the Dirac representation of Maxwell equations we present an\nexplicit, discrete space-time, quantum walk-inspired algorithm suitable for\nsimulating the electromagnetic wave propagation and scattering from\ninhomogeneities within magnetized plasmas. The quantum walk is implemented on a\nlattice with an internal space of $n_q=4$--qubits, used to encode the classical\nfield amplitudes. Unitary rotation gates operate within this internal space to\ngenerate the non-trivial dynamics of the free plasma-Dirac equation. To\nincorporate the contributions from the cyclotron and plasma density\nterms--manifesting as inhomogeneous potential terms--in the plasma-Dirac\nequation, the walk process is complemented with unitary potential operators.\nThis leads to a unitary qubit lattice sequence that recovers the plasma-Dirac\nequation under a second-order accurate discretization scheme. The proposed\nalgorithm is explicit and demonstrates, in the worst case, a polynomial quantum\nadvantage compared to the Finite Difference Time Domain (FDTD) classical method\nin terms of resource requirements and error complexity. In addition, we extend\nthe algorithm to include dissipative effects by introducing a phenomenological\ncollision frequency between plasma species. Then, a post-selective\ntime-marching implementation scheme is delineated, featuring a non-vanishing\noverall success probability and, subsequently, eliminating the need for\namplitude amplification of the output state while preserving the quantum\nadvantage.","main_category":"quant-ph","categories":"quant-ph,physics.plasm-ph","published":"2025-03-31T15:28:41Z"}
{"aid":"http://arxiv.org/abs/2503.24214v1","title":"Moving Edge for On-Demand Edge Computing: An Uncertainty-aware Approach","summary":"We study an edge demand response problem where, based on historical edge\nworkload demands, an edge provider needs to dispatch moving computing units,\ne.g. truck-carried modular data centers, in response to emerging hotspots\nwithin service area. The goal of edge provider is to maximize the expected\nrevenue brought by serving congested users with satisfactory performance, while\nminimizing the costs of moving units and the potential service-level agreement\nviolation penalty for interrupted services. The challenge is to make robust\npredictions for future demands, as well as optimized moving unit dispatching\ndecisions. We propose a learning-based, uncertain-aware moving unit scheduling\nframework, URANUS, to address this problem. Our framework novelly combines\nBayesian deep learning and distributionally robust approximation to make\npredictions that are robust to data, model and distributional uncertainties in\ndeep learning-based prediction models. Based on the robust prediction outputs,\nwe further propose an efficient planning algorithm to optimize moving unit\nscheduling in an online manner. Simulation experiments show that URANUS can\nsignificantly improve robustness in decision making, and achieve superior\nperformance compared to state-of-the-art reinforcement learning,\nuncertainty-agnostic learning-based methods, and other baselines.","main_category":"cs.NI","categories":"cs.NI","published":"2025-03-31T15:32:05Z"}
{"aid":"http://arxiv.org/abs/2503.24215v1","title":"All You Need is Sally-Anne: ToM in AI Strongly Supported After\n  Surpassing Tests for 3-Year-Olds","summary":"Theory of Mind (ToM) is a hallmark of human cognition, allowing individuals\nto reason about others' beliefs and intentions. Engineers behind recent\nadvances in Artificial Intelligence (AI) have claimed to demonstrate comparable\ncapabilities. This paper presents a model that surpasses traditional ToM tests\ndesigned for 3-year-old children, providing strong support for the presence of\nToM in AI systems.","main_category":"cs.AI","categories":"cs.AI","published":"2025-03-31T15:32:10Z"}
{"aid":"http://arxiv.org/abs/2503.24241v1","title":"Asymmetry in Distributions of Accumulated Gains and Losses in Stock\n  Returns","summary":"We study decades-long historic distributions of accumulated S\\&P500 returns,\nfrom daily returns to those over several weeks. The time series of the returns\nemphasize major upheavals in the markets -- Black Monday, Tech Bubble,\nFinancial Crisis and Covid Pandemic -- which are reflected in the tail ends of\nthe distributions. De-trending the overall gain, we concentrate on comparing\ndistributions of gains and losses. Specifically, we compare the tails of the\ndistributions, which are believed to exhibit power-law behavior and possibly\ncontain outliers. Towards this end we find confidence intervals of the linear\nfits of the tails of the complementary cumulative distribution functions on a\nlog-log scale, as well as conduct a statistical U-test in order to detect\noutliers. We also study probability density functions of the full distributions\nof the returns with the emphasis on their asymmetry. The key empirical\nobservations are that the mean of de-trended distributions increases\nnear-linearly with the number of days of accumulation while the overall skew is\nnegative -- consistent with the heavier tails of losses -- and depends little\non the number of days of accumulation. At the same time the variance of the\ndistributions exhibits near-perfect linear dependence on the number of days of\naccumulation, that is it remains constant if scaled to the latter. Finally, we\ndiscuss the theoretical framework for understanding accumulated returns. Our\nmain conclusion is that the current state of theory, which predicts symmetric\nor near-symmetric distributions of returns cannot explain the aggregate of\nempirical results.","main_category":"q-fin.ST","categories":"q-fin.ST,econ.TH,physics.data-an","published":"2025-03-31T15:54:04Z"}
{"aid":"http://arxiv.org/abs/2503.24251v1","title":"Combining Query Performance Predictors: A Reproducibility Study","summary":"A large number of approaches to Query Performance Prediction (QPP) have been\nproposed over the last two decades. As early as 2009, Hauff et al. [28]\nexplored whether different QPP methods may be combined to improve prediction\nquality. Since then, significant research has been done both on QPP approaches,\nas well as their evaluation. This study revisits Hauff et al.s work to assess\nthe reproducibility of their findings in the light of new prediction methods,\nevaluation metrics, and datasets. We expand the scope of the earlier\ninvestigation by: (i) considering post-retrieval methods, including supervised\nneural techniques (only pre-retrieval techniques were studied in [28]); (ii)\nusing sMARE for evaluation, in addition to the traditional correlation\ncoefficients and RMSE; and (iii) experimenting with additional datasets\n(Clueweb09B and TREC DL). Our results largely support previous claims, but we\nalso present several interesting findings. We interpret these findings by\ntaking a more nuanced look at the correlation between QPP methods, examining\nwhether they capture diverse information or rely on overlapping factors.","main_category":"cs.IR","categories":"cs.IR","published":"2025-03-31T16:01:58Z"}
{"aid":"http://arxiv.org/abs/2503.24258v1","title":"Beyond a Single Mode: GAN Ensembles for Diverse Medical Data Generation","summary":"The advancement of generative AI, particularly in medical imaging, confronts\nthe trilemma of ensuring high fidelity, diversity, and efficiency in synthetic\ndata generation. While Generative Adversarial Networks (GANs) have shown\npromise across various applications, they still face challenges like mode\ncollapse and insufficient coverage of real data distributions. This work\nexplores the use of GAN ensembles to overcome these limitations, specifically\nin the context of medical imaging. By solving a multi-objective optimisation\nproblem that balances fidelity and diversity, we propose a method for selecting\nan optimal ensemble of GANs tailored for medical data. The selected ensemble is\ncapable of generating diverse synthetic medical images that are representative\nof true data distributions and computationally efficient. Each model in the\nensemble brings a unique contribution, ensuring minimal redundancy. We\nconducted a comprehensive evaluation using three distinct medical datasets,\ntesting 22 different GAN architectures with various loss functions and\nregularisation techniques. By sampling models at different training epochs, we\ncrafted 110 unique configurations. The results highlight the capability of GAN\nensembles to enhance the quality and utility of synthetic medical images,\nthereby improving the efficacy of downstream tasks such as diagnostic\nmodelling.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T16:06:01Z"}
{"aid":"http://arxiv.org/abs/2503.24316v1","title":"Structure and Fragmentation Scale of a Massive Star-Forming Filament in\n  NGC6334: High-Resolution Mid-Infrared Absorption Imaging with JWST","summary":"Dense filaments are believed to be representative of the initial conditions\nof star formation in molecular clouds. We have used the MIRI instrument on JWST\nto image the massive filament NGC6334M at d~1.3 kpc with unprecedented\nresolution and dynamic range at 7.7 and 25.5 microns. Our observations reveal\nthe fine structure of the filament in absorption against mid-infrared\nbackground emission. From the absorption data, we derive high-resolution column\ndensity maps and perform a detailed analysis of the filament structure. We find\na median filament width of 0.12+/-0.02 pc at both wavelengths, resolved by\nalmost two orders of magnitude by MIRI, and consistent with the typical\nhalf-power width of Herschel filaments in nearby (d<0.5 kpc) clouds. The JWST\ndata also reveal the presence of a quasi-periodic series of side filaments with\na similar projected spacing of 0.125+/-0.015 pc. Combining our JWST results\nwith Spitzer and APEX/Herschel data, we perform a study of cloud structure over\nfour orders of magnitude in linear scale. A convergence test shows that our\nwidth estimates for NGC6334M are robust and reflect the presence of a true\ncharacteristic scale. While there is evidence of a Kolmogorov-like spectrum of\nsmall-scale fluctuations down the 1.6x10^-3 pc resolution of the JWST\nobservations, we identify a break in the power spectrum of column density\nfluctuations at a scale ~0.1-0.4 pc comparable to the width of NGC6334M and its\nside filaments. This characteristic scale ~0.1pc has important implications for\nthe origin of the star formation efficiency in dense gas and the IMF.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-03-31T17:06:35Z"}
{"aid":"http://arxiv.org/abs/2503.24350v1","title":"Large CP violation in $Λ^0_b \\to pK^-π^+π^-$ and its U-spin\n  partner decays","summary":"The LHCb Collaboration has recently found a large CP-violating rate asymmetry\nin the $b$-baryon decay $\\Lambda^0_b \\to pK^-\\pi^+\\pi^-$. This is the first\nobservation of CP violation in baryon processes, opening a new window to test\nits standard model (SM) origin. Many more baryon decays are expected to exhibit\nobservable signals of CP violation. We show that there also exists large CP\nviolation in the U-spin partner decay mode, $\\Xi^0_b \\to \\Sigma^+\\pi^- K^+K^-$,\nwith rate asymmetry $$A_{CP}(\\Xi^0_b \\to \\Sigma^+\\pi^- K^+ K^-) = -\nA_{CP}(\\Lambda^0_b \\to p K^- \\pi^+ \\pi^-)~ \\frac{Br(\\Lambda^0_b \\to p K^- \\pi^+\n\\pi^-)}{Br(\\Xi^0_b \\to \\Sigma^+ \\pi^- K^+ K^-)}~\n\\frac{\\tau^{\\Xi_b}}{\\tau^{\\Lambda_b}}$$ in the U-spin symmetry limit.\nNeglecting small annihilation contributions, we obtain $$A_{CP}(\\Lambda^0_b \\to\np \\pi^+ \\pi^- \\pi^-) =A_{CP}( \\Xi^0_b \\to \\Sigma^+ \\pi^- K^+ K^-) = -(12 \\pm 3)\n\\%.$$ These predictions provide crucial tests for the SM.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-03-31T17:33:42Z"}
{"aid":"http://arxiv.org/abs/2503.24351v1","title":"Lifting for Arbitrary Gadgets","summary":"We prove a sensitivity-to-communication lifting theorem for arbitrary\ngadgets. Given functions $f: \\{0,1\\}^n\\to \\{0,1\\}$ and $g : \\mathcal X\\times\n\\mathcal Y\\to \\{0,1\\}$, denote $f\\circ g(x,y) :=\nf(g(x_1,y_1),\\ldots,g(x_n,y_n))$. We show that for any $f$ with sensitivity $s$\nand any $g$, \\[D(f\\circ g) \\geq s\\cdot\n\\bigg(\\frac{\\Omega(D(g))}{\\log\\mathsf{rk}(g)} - \\log\\mathsf{rk}(g)\\bigg),\\]\nwhere $D(\\cdot)$ denotes the deterministic communication complexity and\n$\\mathsf{rk}(g)$ is the rank of the matrix associated with $g$. As a corollary,\nwe get that if $D(g)$ is a sufficiently large constant, $D(f\\circ g) =\n\\Omega(\\min\\{s,d\\}\\cdot \\sqrt{D(g)})$, where $s$ and $d$ denote the sensitivity\nand degree of $f$. In particular, computing the OR of $n$ copies of $g$\nrequires $\\Omega(n\\cdot\\sqrt{D(g)})$ bits.","main_category":"cs.CC","categories":"cs.CC","published":"2025-03-31T17:34:10Z"}
{"aid":"http://arxiv.org/abs/2503.24364v1","title":"Query and Conquer: Execution-Guided SQL Generation","summary":"We propose a novel approach for generating complex outputs that significantly\nimproves accuracy in text-to-SQL tasks. Our method leverages execution results\nto select the most semantically consistent query from multiple candidates,\nenabling smaller, cost-effective models to surpass computationally intensive\nreasoning methods such as o1, o3-mini, and DeepSeek R1 while reducing inference\ncost by as much as 30 times. It integrates effortlessly with existing models,\noffering a practical and scalable pathway to state-of-the-art SQL generation.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T17:43:36Z"}
{"aid":"http://arxiv.org/abs/2503.24370v1","title":"Effectively Controlling Reasoning Models through Thinking Intervention","summary":"Reasoning-enhanced large language models (LLMs) explicitly generate\nintermediate reasoning steps prior to generating final answers, helping the\nmodel excel in complex problem-solving. In this paper, we demonstrate that this\nemerging generation framework offers a unique opportunity for more fine-grained\ncontrol over model behavior. We propose Thinking Intervention, a novel paradigm\ndesigned to explicitly guide the internal reasoning processes of LLMs by\nstrategically inserting or revising specific thinking tokens. We conduct\ncomprehensive evaluations across multiple tasks, including instruction\nfollowing on IFEval, instruction hierarchy on SEP, and safety alignment on\nXSTest and SORRY-Bench. Our results demonstrate that Thinking Intervention\nsignificantly outperforms baseline prompting approaches, achieving up to 6.7%\naccuracy gains in instruction-following scenarios, 15.4% improvements in\nreasoning about instruction hierarchies, and a 40.0% increase in refusal rates\nfor unsafe prompts using open-source DeepSeek R1 models. Overall, our work\nopens a promising new research avenue for controlling reasoning LLMs.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-03-31T17:50:13Z"}
{"aid":"http://arxiv.org/abs/2503.24382v1","title":"Free360: Layered Gaussian Splatting for Unbounded 360-Degree View\n  Synthesis from Extremely Sparse and Unposed Views","summary":"Neural rendering has demonstrated remarkable success in high-quality 3D\nneural reconstruction and novel view synthesis with dense input views and\naccurate poses. However, applying it to extremely sparse, unposed views in\nunbounded 360{\\deg} scenes remains a challenging problem. In this paper, we\npropose a novel neural rendering framework to accomplish the unposed and\nextremely sparse-view 3D reconstruction in unbounded 360{\\deg} scenes. To\nresolve the spatial ambiguity inherent in unbounded scenes with sparse input\nviews, we propose a layered Gaussian-based representation to effectively model\nthe scene with distinct spatial layers. By employing a dense stereo\nreconstruction model to recover coarse geometry, we introduce a layer-specific\nbootstrap optimization to refine the noise and fill occluded regions in the\nreconstruction. Furthermore, we propose an iterative fusion of reconstruction\nand generation alongside an uncertainty-aware training approach to facilitate\nmutual conditioning and enhancement between these two processes. Comprehensive\nexperiments show that our approach outperforms existing state-of-the-art\nmethods in terms of rendering quality and surface reconstruction accuracy.\nProject page: https://zju3dv.github.io/free360/","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T17:59:25Z"}
{"aid":"http://arxiv.org/abs/2504.01318v1","title":"Tail Bounds for Canonical $U$-Statistics and $U$-Processes with\n  Unbounded Kernels","summary":"In this paper, we prove exponential tail bounds for canonical (or degenerate)\n$U$-statistics and $U$-processes under exponential-type tail assumptions on the\nkernels. Most of the existing results in the relevant literature often assume\nbounded kernels or obtain sub-optimal tail behavior under unbounded kernels. We\nobtain sharp rates and optimal tail behavior under sub-Weibull kernel\nfunctions. Some examples from nonparametric and semiparametric statistics\nliterature are considered.","main_category":"math.ST","categories":"math.ST,math.PR,stat.TH","published":"2025-04-02T03:05:28Z"}
{"aid":"http://arxiv.org/abs/2504.01337v1","title":"Advancing MoE Efficiency: A Collaboration-Constrained Routing (C2R)\n  Strategy for Better Expert Parallelism Design","summary":"Mixture-of-Experts (MoE) has successfully scaled up models while maintaining\nnearly constant computing costs. By employing a gating network to route input\ntokens, it selectively activates a subset of expert networks to process the\ncorresponding token embeddings. However, in practice, the efficiency of MoE is\nchallenging to achieve due to two key reasons: imbalanced expert activation,\nwhich leads to substantial idle time during model or expert parallelism, and\ninsufficient capacity utilization; massive communication overhead, induced by\nnumerous expert routing combinations in expert parallelism at the system level.\nPrevious works typically formulate it as the load imbalance issue characterized\nby the gating network favoring certain experts over others or attribute it to\nstatic execution which fails to adapt to the dynamic expert workload at\nruntime. In this paper, we exploit it from a brand new perspective, a\nhigher-order view and analysis of MoE routing policies: expert collaboration\nand specialization where some experts tend to activate broadly with others\n(collaborative), while others are more likely to activate only with a specific\nsubset of experts (specialized). Our experiments reveal that most experts tend\nto be overly collaborative, leading to increased communication overhead from\nrepeatedly sending tokens to different accelerators. To this end, we propose a\nnovel collaboration-constrained routing (C2R) strategy to encourage more\nspecialized expert groups, as well as to improve expert utilization, and\npresent an efficient implementation of MoE that further leverages expert\nspecialization. We achieve an average performance improvement of 0.51% and\n0.33% on LLaMA-MoE and Qwen-MoE respectively across ten downstream NLP\nbenchmarks, and reduce the all2all communication costs between GPUs, bringing\nan extra 20%-30% total running time savings on top of the existing SoTA, i.e.\nMegaBlocks.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-02T03:51:59Z"}
{"aid":"http://arxiv.org/abs/2504.01357v1","title":"Age-Aware Partial Gradient Update Strategy for Federated Learning Over\n  the Air","summary":"We propose an age-aware strategy to update gradients in an over-the-air\nfederated learning system. The system comprises an edge server and multiple\nclients, collaborating to minimize a global loss function. In each\ncommunication round, clients perform local training, modulate their gradient\nupdates onto a set of shared orthogonal waveforms, and simultaneously transmit\nthe analog signals to the edge server. The edge server then extracts a noisy\naggregated gradient from the received radio signal, updates the global model,\nand broadcasts it to the clients for the next round of local computing. Despite\nenabling all clients to upload information in every communication round, the\nsystem is constrained by the limited number of available waveform carriers,\nallowing only a subset of gradient parameters to be transmitted. To address\nthis issue, our method maintains an age vector on the edge server, tracking the\ntime elapsed since each coordinate of the global model was last updated. The\nserver leverages this information to prioritize gradient entries for\ntransmission, ensuring that outdated yet significant parameters are updated\nmore frequently. We derive the convergence rate of the proposed algorithm to\nquantify its effectiveness. Furthermore, experimental evaluations on the MNIST\nand CIFAR-10 datasets demonstrate that our approach achieves higher accuracy\nand more stable convergence performance compared to baseline methods,\nhighlighting its potential for improving communication efficiency in\nover-the-air federated learning systems.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-02T05:01:53Z"}
{"aid":"http://arxiv.org/abs/2504.01361v1","title":"On one typical Einstein-Weyl equation: inverse spectral transform for\n  theCauchy problem, longtime behaviour of the solutions and implicit solutions","summary":"In this paper, we study one typical Einstein-Weyl equation. It arises from\nFerapontov and Kruglikov's investigation on the integrability of several\ndispersionless partial differential equations and the geometry of their formal\nlinearizations. First, by using Manakov-Santini IST (inverse spectral\ntransform) method, we investigate its Cauchy problem including the direct\nproblem from the initial data, the time evolution of the scattering and\nspectral data, and the inverse problem. Second, based on the nonlinear RH\n(Riemann-Hilbert) dressing, the longtime behaviour of the solutions is\nconstructed. In addition, some implicit solutions are presented.","main_category":"nlin.SI","categories":"nlin.SI","published":"2025-04-02T05:08:35Z"}
{"aid":"http://arxiv.org/abs/2504.01365v1","title":"Inflation with Gauss-Bonnet correction: beyond slow-roll","summary":"If a coupling between the inflaton and the Gauss-Bonnet term is introduced,\nmany models of inflation that were ruled out by the most recent Planck data can\nbe made viable again. The predictions for the scalar spectral index and\ntensor-to-scalar ratio are typically computed using the slow-roll\napproximation. In this paper we instead study the full equations of motion and\ndetermine the necessary initial conditions for reasonable inflation epoch. We\nderive the conditions under which the Friedmann equation admits positive\nsolutions for the Hubble parameter. Then we study the possibility of the\ninflaton becoming trapped in a local potential minimum induced by the\nGauss-Bonnet term. Finally we demonstrate the results on monomial potential\nmodels with a quadratic and a quartic potential and show that the slow-roll\napproximation becomes imprecise in the quartic case.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO","published":"2025-04-02T05:18:15Z"}
{"aid":"http://arxiv.org/abs/2504.01366v1","title":"Virtual Reality and Artificial Intelligence as Psychological\n  Countermeasures in Space and Other Isolated and Confined Environments: A\n  Scoping Review","summary":"Spaceflight is an isolated and confined environment (ICE) that exposes\nastronauts to psychological hazards, such as stress, danger, and monotony.\nVirtual reality (VR) and artificial intelligence (AI) technologies can serve as\npsychological countermeasures as they can digitally simulate immersive\nenvironments, interactive companions, and therapeutic experiences. Our study\nemploys a scoping literature review approach to identify what is currently\nknown about the use and effectiveness of VR and AI-based interventions as\npsychological countermeasures to improve mood or emotional states in adults in\nspace or other ICEs. Additionally, this review aimed to identify gaps in the\nknowledge base and whether a systematic review with meta-analysis was\nwarranted. The review included studies where the intervention was used or\nintended for use in space or other extraterrestrial environments (ICE). Our\nsearch strategy yielded 19 studies from 3390 records across seven major\ndatabases. All studies focused on VR-based interventions, with no eligible\nAI-based intervention studies found. VR interventions were found to be\neffective for relaxation and improving mood, emergency training, as an\ninteractive communication platform, for comparing interior designs, and for\nenhancing exercise. There were improvements for measures of mood and emotion\\n\n(e.g., anxiety and stress); however, user preferences varied, and some\ninstances of cybersickness were reported. A systematic review with\nmeta-analysis is not recommended due to the heterogeneity of results. There is\nsignificant scope for further research into the use of VR for a wider range of\nmood and emotion variables using standardised assessment instruments.\nAdditionally, the potential application of AI as a psychological countermeasure\nwarrants further investigation.","main_category":"cs.HC","categories":"cs.HC,cs.AI,cs.MM","published":"2025-04-02T05:25:29Z"}
{"aid":"http://arxiv.org/abs/2504.01378v1","title":"A Control Barrier Function Approach to Constrained Resource Allocation\n  Problems in a Maximum Entropy Principle Framework","summary":"This paper presents a novel approach to solve capacitated facility location\nproblems (FLP) that encompass various resource allocation problems. FLPs are a\nclass of NP-hard combinatorial optimization problems, involving optimal\nplacement and assignment of a small number of facilities over a large number of\ndemand points, with each facility subject to upper and lower bounds on its\nresource utilization (e.g., the number of demand points it can serve). To\naddress the challenges posed by inequality constraints and the combinatorial\nnature of the solution space, we reformulate the problem as a dynamic control\ndesign problem, enabling structured constraint handling and enhanced solution\nefficiency. Our method integrates a Control Barrier Function (CBF) and Control\nLyapunov Function (CLF)-based framework with a maximum-entropy principle-based\nframework to ensure feasibility, optimality, and improved exploration of\nsolutions. Numerical experiments demonstrate that this approach significantly\nenhances computational efficiency, yielding better solutions and showing\nnegligible growth in computation time with problem size as compared to existing\nsolvers. These results highlight the potential of control-theoretic and\nentropy-based methods for large-scale facility location problems.","main_category":"math.OC","categories":"math.OC","published":"2025-04-02T05:47:57Z"}
{"aid":"http://arxiv.org/abs/2504.01381v1","title":"Interstellar extinction toward MWC 148","summary":"We analyse high resolution optical spectra of MWC148 (optical counterpart of\nthe gamma-ray source HESS J0632+057) obtained at Observatoire de Haute Provence\nand Rozhen Observatory. We measure equivalent widths of 7 diffuse interstellar\nbands and estimate the interstellar extinction E_{B-V}=0.85 +/- 0.08.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA,astro-ph.HE","published":"2025-04-02T05:50:16Z"}
{"aid":"http://arxiv.org/abs/2504.01397v1","title":"Can the poltergeist mechanism produce observable GWs?","summary":"The enhancement of induced gravitational waves (GWs) occurs due to a sudden\ntransition from an early matter-dominated era to the radiation-dominated era.\nWe analyze the impact of the transition rate on the scalar potential. We find\nthat the finite transition duration suppresses the oscillation amplitude of the\nscalar potential, consequently suppressing the amplitude of the GW energy\nspectrum. By numerically solving the background and perturbation equations, we\ndemonstrate that the physically motivated models, such as the evaporation of\nprimordial black holes and the decay of Q-balls, cannot produce an observable\nGW signal.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-02T06:37:17Z"}
{"aid":"http://arxiv.org/abs/2504.01409v1","title":"Pedestrian-Aware Motion Planning for Autonomous Driving in Complex Urban\n  Scenarios","summary":"Motion planning in uncertain environments like complex urban areas is a key\nchallenge for autonomous vehicles (AVs). The aim of our research is to\ninvestigate how AVs can navigate crowded, unpredictable scenarios with multiple\npedestrians while maintaining a safe and efficient vehicle behavior. So far,\nmost research has concentrated on static or deterministic traffic participant\nbehavior. This paper introduces a novel algorithm for motion planning in\ncrowded spaces by combining social force principles for simulating realistic\npedestrian behavior with a risk-aware motion planner. We evaluate this new\nalgorithm in a 2D simulation environment to rigorously assess AV-pedestrian\ninteractions, demonstrating that our algorithm enables safe, efficient, and\nadaptive motion planning, particularly in highly crowded urban environments - a\nfirst in achieving this level of performance. This study has not taken into\nconsideration real-time constraints and has been shown only in simulation so\nfar. Further studies are needed to investigate the novel algorithm in a\ncomplete software stack for AVs on real cars to investigate the entire\nperception, planning and control pipeline in crowded scenarios. We release the\ncode developed in this research as an open-source resource for further studies\nand development. It can be accessed at the following link:\nhttps://github.com/TUM-AVS/PedestrianAwareMotionPlanning","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-02T06:50:01Z"}
{"aid":"http://arxiv.org/abs/2504.01411v1","title":"General channel capacities from quantum channel-state duality","summary":"The quantum channel-state duality permits the characterization of a quantum\nprocess through a quantum state, referred to as a Choi state. This\ncharacteristic serves as the impetus for the quantum computing paradigm that\nutilizes Choi states as information sources. In this work, the fundamental\ntheorems regarding quantum channel capacity are proven when Choi states are\nconsidered as sources. This achievement enriches the set of capacities\nassociated with quantum channels. Moreover, it gives rise to novel\nopportunities for the comprehension of superadditivity phenomena and the\ndiscovery of new classes of quantum error-correction codes.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T06:58:25Z"}
{"aid":"http://arxiv.org/abs/2504.01418v1","title":"Demonstrating Correlation Trends in the Electric Dipole Polarizabilities\n  of Many Low-lying States in Cesium (Cs I) through First-principle\n  Calculations","summary":"Electron correlation and higher-order relativistic effects are probed in the\nevaluation of scalar and tensor static electric dipole (E1) polarizabilities\n($\\alpha_d$) of several even- and odd-parity states in cesium (Cs) using the\nDirac-Hartree-Fock (DHF) method, second-order perturbation theory (MBPT(2)),\nthird-order perturbation theory (MBPT(3)), random phase approximation (RPA),\nand singles and doubles approximated relativistic coupled-cluster (RCCSD)\nmethod. To account for perturbation due to odd-parity E1 operator on the atomic\norbitals, calculations are carried out in the linear response approach. Our\nfinal $\\alpha_d$ values, with the estimated uncertainties, show reasonably good\nagreement with the previous calculations and available experimental results.\nDifferences among the DHF, MBPT(2), MBPT(3) and RPA results indicate\npair-correlation (PC) effects play major roles than the core-polarization (CP)\neffects in the determination of $\\alpha_d$ values in Cs. From the differences\namong the MBPT(3) and RCC results, we find correlations among the PC and CP\neffects and double CP effects together are also significant in these\ncalculations. Contributions from the Breit interactions are found to be quite\nlarge in the high-lying states.","main_category":"physics.atom-ph","categories":"physics.atom-ph,quant-ph","published":"2025-04-02T07:10:28Z"}
{"aid":"http://arxiv.org/abs/2504.01430v1","title":"Asymptotic Error Bounds and Fractional-Bit Design for Fixed-Point\n  Grover's Quantum Algorithm Emulation","summary":"Quantum computing (QC) emulators, which simulate quantum algorithms on\nclassical hardware, are indispensable platforms for testing quantum algorithms\nbefore scalable quantum computers become widely available. A critical challenge\nin QC emulation is managing numerical errors from finite arithmetic precision,\nespecially truncation errors in resource-efficient fixed-point arithmetic.\nDespite its importance, systematic studies quantifying how truncation errors\nimpact quantum algorithm accuracy are limited. In this paper, we propose a\nrigorous quantitative framework analyzing truncation error propagation in\nfixed-point QC emulation, focusing on Grover's quantum search algorithm. First,\nwe introduce a simplified two-value amplitude representation of quantum states\nduring Grover's iterations and prove its theoretical validity. Using this\nrepresentation, we derive explicit mathematical expressions characterizing\ntruncation error accumulation across quantum gate operations. We quantify the\noverall emulation error by the $\\ell_2$ distance between ideal and emulated\nprobability distributions, obtaining asymptotic bounds scaling as $O(2^{n-f})$,\nwhere $n$ is the number of qubits and $f$ is fractional-bit precision.\nExtensive numerical simulations and empirical experiments on a practical\nfixed-point QC emulator confirm that observed errors precisely match our\ntheoretical predictions. Finally, we provide a closed-form formula to determine\nthe minimal fractional-bit precision required to achieve a specified error\nthreshold, offering clear guidelines for emulator designers balancing accuracy\nand resource utilization.","main_category":"quant-ph","categories":"quant-ph,cs.NA,math.NA","published":"2025-04-02T07:33:36Z"}
{"aid":"http://arxiv.org/abs/2504.01431v1","title":"Multi-convex Programming for Discrete Latent Factor Models Prototyping","summary":"Discrete latent factor models (DLFMs) are widely used in various domains such\nas machine learning, economics, neuroscience, psychology, etc. Currently,\nfitting a DLFM to some dataset relies on a customized solver for individual\nmodels, which requires lots of effort to implement and is limited to the\ntargeted specific instance of DLFMs. In this paper, we propose a generic\nframework based on CVXPY, which allows users to specify and solve the fitting\nproblem of a wide range of DLFMs, including both regression and classification\nmodels, within a very short script. Our framework is flexible and inherently\nsupports the integration of regularization terms and constraints on the DLFM\nparameters and latent factors, such that the users can easily prototype the\nDLFM structure according to their dataset and application scenario. We\nintroduce our open-source Python implementation and illustrate the framework in\nseveral examples.","main_category":"math.OC","categories":"math.OC,cs.CE,cs.LG","published":"2025-04-02T07:33:54Z"}
{"aid":"http://arxiv.org/abs/2504.01433v1","title":"Reaction and interaction nucleus-nucleus cross sections in the complete\n  Glauber theory","summary":"The straightforward calculations of the reaction and interaction cross\nsections of the nuclear scattering are carried out in Glauber approach using\nthe generating function method. It allows for the resummation of all orders of\nGlauber theory. The results are obtained for $^4$He, $^{11}$Li, $^{12}$C\nscattering on $^{12}$C target. The difference between the reaction and the\ndifferential cross section is shown to be not exceeding several percents","main_category":"nucl-th","categories":"nucl-th,hep-ph","published":"2025-04-02T07:34:53Z"}
{"aid":"http://arxiv.org/abs/2504.01443v1","title":"Split Federated Learning for UAV-Enabled Integrated Sensing,\n  Computation, and Communication","summary":"Unmanned aerial vehicles (UAVs) with integrated sensing, computation, and\ncommunication (ISCC) capabilities have become key enablers of next-generation\nwireless networks. Federated edge learning (FEL) leverages UAVs as mobile\nlearning agents to collect data, perform local model updates, and contribute to\nglobal model aggregation. However, existing UAV-assisted FEL systems face\ncritical challenges, including excessive computational demands, privacy risks,\nand inefficient communication, primarily due to the requirement for full-model\ntraining on resource-constrained UAVs. To deal with aforementioned challenges,\nwe propose Split Federated Learning for UAV-Enabled ISCC (SFLSCC), a novel\nframework that integrates split federated learning (SFL) into UAV-assisted FEL.\nSFLSCC optimally partitions model training between UAVs and edge servers,\nsignificantly reducing UAVs' computational burden while preserving data\nprivacy. We conduct a theoretical analysis of UAV deployment, split point\nselection, data sensing volume, and client-side aggregation frequency, deriving\nclosed-form upper bounds for the convergence gap. Based on these insights, we\nconceive a joint optimization problem to minimize the energy consumption\nrequired to achieve a target model accuracy. Given the non-convex nature of the\nproblem, we develop a low-complexity algorithm to efficiently determine UAV\ndeployment, split point selection, and communication frequency. Extensive\nsimulations on a target motion recognition task validate the effectiveness of\nSFLSCC, demonstrating superior convergence performance and energy efficiency\ncompared to baseline methods.","main_category":"cs.DC","categories":"cs.DC,cs.ET","published":"2025-04-02T07:53:24Z"}
{"aid":"http://arxiv.org/abs/2504.01446v1","title":"Deep Graph Reinforcement Learning for UAV-Enabled Multi-User Secure\n  Communications","summary":"While unmanned aerial vehicles (UAVs) with flexible mobility are envisioned\nto enhance physical layer security in wireless communications, the efficient\nsecurity design that adapts to such high network dynamics is rather\nchallenging. The conventional approaches extended from optimization\nperspectives are usually quite involved, especially when jointly considering\nfactors in different scales such as deployment and transmission in UAV-related\nscenarios. In this paper, we address the UAV-enabled multi-user secure\ncommunications by proposing a deep graph reinforcement learning framework.\nSpecifically, we reinterpret the security beamforming as a graph neural network\n(GNN) learning task, where mutual interference among users is managed through\nthe message-passing mechanism. Then, the UAV deployment is obtained through\nsoft actor-critic reinforcement learning, where the GNN-based security\nbeamforming is exploited to guide the deployment strategy update. Simulation\nresults demonstrate that the proposed approach achieves near-optimal security\nperformance and significantly enhances the efficiency of strategy\ndetermination. Moreover, the deep graph reinforcement learning framework offers\na scalable solution, adaptable to various network scenarios and configurations,\nestablishing a robust basis for information security in UAV-enabled\ncommunications.","main_category":"eess.SP","categories":"eess.SP,cs.IT,math.IT","published":"2025-04-02T07:57:33Z"}
{"aid":"http://arxiv.org/abs/2504.01454v1","title":"Quantum Key Distribution with Efficient Post-Quantum\n  Cryptography-Secured Trusted Node on a Quantum Network","summary":"Quantum Key Distribution (QKD) enables two distant users to exchange a secret\nkey with information-theoretic security, based on the fundamental laws of\nquantum physics. While it is arguably the most mature application of quantum\ncryptography, it has inherent limitations in the achievable distance and the\nscalability to large-scale infrastructures. While the applicability of QKD can\nbe readily increased with the use of intermediary trusted nodes, this adds\nadditional privacy requirements on third parties. In this work, we present an\nefficient scheme leveraging a trusted node with lower privacy requirements\nthanks to the use of post-quantum cryptographic techniques, and implement it on\na deployed fiber optic quantum communication network in the Paris area.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T08:06:16Z"}
{"aid":"http://arxiv.org/abs/2504.01455v1","title":"Atmospheric dynamics of first steps toward terraforming Mars","summary":"Warming Mars' surface could be a step toward making it suitable for life, but\nwould represent a major science and engineering challenge. To warm Mars using\nengineered aerosol, particles released locally must disperse globally. The\nwinds that transport aerosol respond to the aerosol's radiative forcing,\nimplying strong radiative-dynamical feedbacks. Using a plume-tracking climate\nmodel without a water cycle, we investigate radiative-dynamical feedback from\nsurface release of two particle compositions: graphene (which attenuates UV)\nand aluminum. Both compositions can give fast global warming of ~30 K. We infer\nthat 2 liters/second release rate of graphene made from Mars' atmosphere via\nCO2-electrolysis could double Mars' greenhouse effect (+5 K). Self-lofting\nhelps particles rise and spread. The Hadley cell strengthens under warming,\naiding mixing. Warming can be focused in latitude by tuning particle size.\nWithin our model, Mars radiative-dynamical feedbacks enable engineered-aerosol\nwarming. Challenges remain, including functionalization, agglomeration,\ndry-deposition experiments, and modeling water cycle feedbacks.","main_category":"astro-ph.EP","categories":"astro-ph.EP,physics.geo-ph","published":"2025-04-02T08:06:35Z"}
{"aid":"http://arxiv.org/abs/2504.01499v1","title":"The de Rham cohomology of covers with cyclic $p$-Sylow subgroup","summary":"Let $X$ be a smooth projective curve over a field $k$ with an action of a\nfinite group $G$. A well-known result of Chevalley and Weil describes the\n$k[G]$-module structure of cohomologies of $X$ in the case when the\ncharacteristic of $k$ does not divide $\\# G$. It is unlikely that such a\nformula can be derived in the general case, since the representation theory of\ngroups with non-cyclic $p$-Sylow subgroups is wild in characteristic $p$. The\ngoal of this article is to show that when $G$ has a cyclic $p$-Sylow subgroup,\nthe $G$-structure of the de Rham cohomology of $X$ is completely determined by\nthe ramification data. In principle, this leads to new formulas in the spirit\nof Chevalley and Weil for such curves. We provide such an explicit description\nof the de Rham cohomology in the cases when $G = \\mathbb Z/p^n$ and when the\n$p$-Sylow subgroup of $G$ is normal of order $p$.","main_category":"math.AG","categories":"math.AG,math.NT","published":"2025-04-02T08:51:33Z"}
{"aid":"http://arxiv.org/abs/2504.01502v1","title":"Global variants of $\\mathcal{N}=1^*$ theories and Calogero-Moser systems","summary":"Global variants of four-dimensional gauge theories are specified by their\nspectrum of genuine Wilson-'t Hooft line operators. The choice of global\nvariant has significant consequences when spacetime is taken to be\n$\\mathbb{R}^3 \\times S^1$. We focus on $\\mathcal N=1^*$ theories, which are\nclosely connected to twisted elliptic Calogero-Moser systems. We establish, on\ngeneral grounds, how this gauge-theoretic topological data manifests itself on\nthe integrable system side by introducing a notion of global variants for\ncomplex many-body integrable systems associated with Lie algebras. Focusing on\n$\\mathcal N=1^*$ theories of type $A$ and $B_2$, we elucidate the implications\nfor the structure of gapped vacua, the emergent (generalized) symmetries\nrealized in each vacuum, and the action of spontaneously broken modular\ninvariance.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP,nlin.SI","published":"2025-04-02T08:54:40Z"}
{"aid":"http://arxiv.org/abs/2504.01507v1","title":"Grasping by Spiraling: Reproducing Elephant Movements with Rigid-Soft\n  Robot Synergy","summary":"The logarithmic spiral is observed as a common pattern in several living\nbeings across kingdoms and species. Some examples include fern shoots,\nprehensile tails, and soft limbs like octopus arms and elephant trunks. In the\nlatter cases, spiraling is also used for grasping. Motivated by how this\nstrategy simplifies behavior into kinematic primitives and combines them to\ndevelop smart grasping movements, this work focuses on the elephant trunk,\nwhich is more deeply investigated in the literature. We present a soft arm\ncombined with a rigid robotic system to replicate elephant grasping\ncapabilities based on the combination of a soft trunk with a solid body. In our\nsystem, the rigid arm ensures positioning and orientation, mimicking the role\nof the elephant's head, while the soft manipulator reproduces trunk motion\nprimitives of bending and twisting under proper actuation patterns. This\nsynergy replicates 9 distinct elephant grasping strategies reported in the\nliterature, accommodating objects of varying shapes and sizes. The synergistic\ninteraction between the rigid and soft components of the system minimizes the\ncontrol complexity while maintaining a high degree of adaptability.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-02T08:57:10Z"}
{"aid":"http://arxiv.org/abs/2504.01521v1","title":"Domain Guidance: A Simple Transfer Approach for a Pre-trained Diffusion\n  Model","summary":"Recent advancements in diffusion models have revolutionized generative\nmodeling. However, the impressive and vivid outputs they produce often come at\nthe cost of significant model scaling and increased computational demands.\nConsequently, building personalized diffusion models based on off-the-shelf\nmodels has emerged as an appealing alternative. In this paper, we introduce a\nnovel perspective on conditional generation for transferring a pre-trained\nmodel. From this viewpoint, we propose *Domain Guidance*, a straightforward\ntransfer approach that leverages pre-trained knowledge to guide the sampling\nprocess toward the target domain. Domain Guidance shares a formulation similar\nto advanced classifier-free guidance, facilitating better domain alignment and\nhigher-quality generations. We provide both empirical and theoretical analyses\nof the mechanisms behind Domain Guidance. Our experimental results demonstrate\nits substantial effectiveness across various transfer benchmarks, achieving\nover a 19.6% improvement in FID and a 23.4% improvement in FD$_\\text{DINOv2}$\ncompared to standard fine-tuning. Notably, existing fine-tuned models can\nseamlessly integrate Domain Guidance to leverage these benefits, without\nadditional training.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV","published":"2025-04-02T09:07:55Z"}
{"aid":"http://arxiv.org/abs/2504.01556v1","title":"Thermalization in a model of enhanced memory capacity","summary":"We study thermalization within a quantum system with an enhanced capacity to\nstore information. This system has been recently introduced to provide a\nprototype model of how a black hole processes and stores information. We\nperform a numerical finite-size analysis of this isolated quantum system and\nfind indications that its information-carrying subsystem approaches thermality\nin the large system-size limit. The results lead us to suggest a novel\nthermalization mechanism. The corresponding distinguishing characteristic is\nthat for a large class of physically meaningful non-equilibrium initial states\n$| \\text{in} \\rangle$, a few-body observable $\\hat{A}$ thermalizes despite\nunignorable correlations between the fluctuations of its eigenstate expectation\nvalues $\\langle \\alpha | \\hat{A} | \\alpha \\rangle$ in the eigenstate basis of\nthe model $\\left\\{ | \\alpha \\rangle \\right\\}$ and the fluctuations of the\nsquared magnitudes of the coefficients $|C_{\\alpha}|^2 = |\\langle \\alpha |\n\\text{in} \\rangle |^2$.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T09:58:20Z"}
{"aid":"http://arxiv.org/abs/2504.01560v1","title":"Optimizing Package Delivery with Quantum Annealers: Addressing\n  Time-Windows and Simultaneous Pickup and Delivery","summary":"Recent research at the intersection of quantum computing and routing problems\nhas been highly prolific. Much of this work focuses on classical problems such\nas the Traveling Salesman Problem and the Vehicle Routing Problem. The\npractical applicability of these problems depends on the specific objectives\nand constraints considered. However, it is undeniable that translating complex\nreal-world requirements into these classical formulations often proves\nchallenging. In this paper, we resort to our previously published\nquantum-classical technique for addressing real-world-oriented routing\nproblems, known as Quantum for Real Package Delivery (Q4RPD), and elaborate on\nsolving additional realistic problem instances. Accordingly, this paper\nemphasizes the following characteristics: i) simultaneous pickup and\ndeliveries, ii) time-windows, and iii) mobility restrictions by vehicle type.\nTo illustrate the application of Q4RPD, we have conducted an experimentation\ncomprising seven instances, serving as a demonstration of the newly developed\nfeatures.","main_category":"cs.ET","categories":"cs.ET,cs.AI","published":"2025-04-02T10:01:34Z"}
{"aid":"http://arxiv.org/abs/2504.01561v1","title":"STPNet: Scale-aware Text Prompt Network for Medical Image Segmentation","summary":"Accurate segmentation of lesions plays a critical role in medical image\nanalysis and diagnosis. Traditional segmentation approaches that rely solely on\nvisual features often struggle with the inherent uncertainty in lesion\ndistribution and size. To address these issues, we propose STPNet, a\nScale-aware Text Prompt Network that leverages vision-language modeling to\nenhance medical image segmentation. Our approach utilizes multi-scale textual\ndescriptions to guide lesion localization and employs retrieval-segmentation\njoint learning to bridge the semantic gap between visual and linguistic\nmodalities. Crucially, STPNet retrieves relevant textual information from a\nspecialized medical text repository during training, eliminating the need for\ntext input during inference while retaining the benefits of cross-modal\nlearning. We evaluate STPNet on three datasets: COVID-Xray, COVID-CT, and\nKvasir-SEG. Experimental results show that our vision-language approach\noutperforms state-of-the-art segmentation methods, demonstrating the\neffectiveness of incorporating textual semantic knowledge into medical image\nanalysis. The code has been made publicly on\nhttps://github.com/HUANGLIZI/STPNet.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-02T10:01:42Z"}
{"aid":"http://arxiv.org/abs/2504.01567v1","title":"Quantum Computing for Optimizing Aircraft Loading","summary":"The aircraft loading optimization problem is a computationally hard problem\nwith the best known classical algorithm scaling exponentially with the number\nof objects. We propose a quantum approach based on a multi-angle variant of the\nQAOA algorithm (Multi-Angle Layered Variational Quantum Algorithm (MAL-VQA))\ndesigned to utilize a smaller number of two qubit gates in the quantum circuit\nas compared to the standard QAOA algorithm so that the quantum optimization\nalgorithm can be run on near-term ion-trap quantum processing units (QPU). We\nalso describe a novel cost function implementation that can handle many\ndifferent types of inequality constraints without the overhead of introducing\nslack variables in the quantum circuit so that larger problems with complex\nconstraints may be represented on near-term QPUs which have low qubit counts.\nWe demonstrate the performance of the algorithm on different instances of the\naircraft loading problem by execution on IonQ QPUs Aria and Forte. Our\nexperiments obtain the optimal solutions for all the problem instances studied\nranging from 12 qubits to 28 qubits. This shows the potential scalability of\nthe method to significantly larger problem sizes with the improvement of\nquantum hardware in the near future as well as the robustness of the quantum\nalgorithm against varying initial guesses and varying constraints of different\nproblem instances.","main_category":"quant-ph","categories":"quant-ph,cs.ET","published":"2025-04-02T10:10:11Z"}
{"aid":"http://arxiv.org/abs/2504.01577v1","title":"Instance Migration Diffusion for Nuclear Instance Segmentation in\n  Pathology","summary":"Nuclear instance segmentation plays a vital role in disease diagnosis within\ndigital pathology. However, limited labeled data in pathological images\nrestricts the overall performance of nuclear instance segmentation. To tackle\nthis challenge, we propose a novel data augmentation framework Instance\nMigration Diffusion Model (IM-Diffusion), IM-Diffusion designed to generate\nmore varied pathological images by constructing diverse nuclear layouts and\ninternuclear spatial relationships. In detail, we introduce a Nuclear Migration\nModule (NMM) which constructs diverse nuclear layouts by simulating the process\nof nuclear migration. Building on this, we further present an\nInternuclear-regions Inpainting Module (IIM) to generate diverse internuclear\nspatial relationships by structure-aware inpainting. On the basis of the above,\nIM-Diffusion generates more diverse pathological images with different layouts\nand internuclear spatial relationships, thereby facilitating downstream tasks.\nEvaluation on the CoNSeP and GLySAC datasets demonstrate that the images\ngenerated by IM-Diffusion effectively enhance overall instance segmentation\nperformance. Code will be made public later.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-02T10:29:31Z"}
{"aid":"http://arxiv.org/abs/2504.01584v1","title":"Higher-order topological phases for time-reversal-symmetry breaking\n  superconductivity in UTe$_2$","summary":"The recent discovery of heavy-fermion superconductor UTe$_2$ has broadened\nthe possibility of realizing exotic time-reversal-symmetry-breaking\nsuperconductivity. However, a comprehensive understanding of the topological\nphases in the superconducting states of UTe$_2$ is still lacking. Here, we\npresent an exhaustive classification of topological phases for all\ntime-reversal symmetry breaking pairing symmetries of UTe$_2$. Using the K\ntheoretical classification approach, we uncover that 25 out of 36 possible\npairing states are classified as higher-order topological phases, with some\ndemonstrating hybrid-order topology through an intricate interplay of hinge and\ncorner states. Furthermore, under the weak-coupling condition of the pair\npotentials, the possible pairing symmetries are constrained to $B_{ju} + i\nB_{ku}$, $A_{u} + i B_{j u}$, and $B_{j g} + iA_u$ ($j,k = 1,2,3$; $j \\neq k$),\nwhere these symbols denote the irreducible representations of the point group\n$D_{2h}$. For these pairing states, the topological invariants are related to\nthe Fermi surface topology via the Fermi-surface formula, enabling us to\nsystematically diagnose higher-order topological phases. Using a tight-binding\nmodel, we demonstrate the higher-order topological phases of the mixed-parity\n$A_u + iB_{1g}$ superconductors, where the second-order and hybrid-order\ntopological phases emerge as the number of Fermi surfaces enclosing the\ntime-reversal invariant momentum evolves from two to four. The findings suggest\nthat UTe$_2$ serves as a compelling platform for exploring higher-order\ntopological superconductors with diverse topological surface states.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-02T10:40:39Z"}
{"aid":"http://arxiv.org/abs/2504.01632v1","title":"Benchmarking the Spatial Robustness of DNNs via Natural and Adversarial\n  Localized Corruptions","summary":"The robustness of DNNs is a crucial factor in safety-critical applications,\nparticularly in complex and dynamic environments where localized corruptions\ncan arise. While previous studies have evaluated the robustness of semantic\nsegmentation (SS) models under whole-image natural or adversarial corruptions,\na comprehensive investigation into the spatial robustness of dense vision\nmodels under localized corruptions remained underexplored. This paper fills\nthis gap by introducing specialized metrics for benchmarking the spatial\nrobustness of segmentation models, alongside with an evaluation framework to\nassess the impact of localized corruptions. Furthermore, we uncover the\ninherent complexity of characterizing worst-case robustness using a single\nlocalized adversarial perturbation. To address this, we propose region-aware\nmulti-attack adversarial analysis, a method that enables a deeper understanding\nof model robustness against adversarial perturbations applied to specific\nregions. The proposed metrics and analysis were evaluated on 15 segmentation\nmodels in driving scenarios, uncovering key insights into the effects of\nlocalized corruption in both natural and adversarial forms. The results reveal\nthat models respond to these two types of threats differently; for instance,\ntransformer-based segmentation models demonstrate notable robustness to\nlocalized natural corruptions but are highly vulnerable to adversarial ones and\nvice-versa for CNN-based models. Consequently, we also address the challenge of\nbalancing robustness to both natural and adversarial localized corruptions by\nmeans of ensemble models, thereby achieving a broader threat coverage and\nimproved reliability for dense vision tasks.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T11:37:39Z"}
{"aid":"http://arxiv.org/abs/2504.01644v1","title":"Proposition of Affordance-Driven Environment Recognition Framework Using\n  Symbol Networks in Large Language Models","summary":"In the quest to enable robots to coexist with humans, understanding dynamic\nsituations and selecting appropriate actions based on common sense and\naffordances are essential. Conventional AI systems face challenges in applying\naffordance, as it represents implicit knowledge derived from common sense.\nHowever, large language models (LLMs) offer new opportunities due to their\nability to process extensive human knowledge. This study proposes a method for\nautomatic affordance acquisition by leveraging LLM outputs. The process\ninvolves generating text using LLMs, reconstructing the output into a symbol\nnetwork using morphological and dependency analysis, and calculating\naffordances based on network distances. Experiments using ``apple'' as an\nexample demonstrated the method's ability to extract context-dependent\naffordances with high explainability. The results suggest that the proposed\nsymbol network, reconstructed from LLM outputs, enables robots to interpret\naffordances effectively, bridging the gap between symbolized data and\nhuman-like situational understanding.","main_category":"cs.AI","categories":"cs.AI,cs.RO","published":"2025-04-02T11:48:44Z"}
{"aid":"http://arxiv.org/abs/2504.01652v1","title":"Market-Oriented Flow Allocation for Thermal Solar Plants: An\n  Auction-Based Methodology with Artificial Intelligence","summary":"This paper presents a novel method to optimize thermal balance in parabolic\ntrough collector (PTC) plants. It uses a market-based system to distribute flow\namong loops combined with an artificial neural network (ANN) to reduce\ncomputation and data requirements. This auction-based approach balances loop\ntemperatures, accommodating varying thermal losses and collector efficiencies.\nValidation across different thermal losses, optical efficiencies, and\nirradiance conditions-sunny, partially cloudy, and cloudy-show improved thermal\npower output and intercept factors compared to a no-allocation system. It\ndemonstrates scalability and practicality for large solar thermal plants,\nenhancing overall performance. The method was first validated through\nsimulations on a realistic solar plant model, then adapted and successfully\ntested in a 50 MW solar trough plant, demonstrating its advantages.\nFurthermore, the algorithms have been implemented, commissioned, and are\ncurrently operating in 13 commercial solar trough plants.","main_category":"eess.SY","categories":"eess.SY,cs.AI,cs.SY","published":"2025-04-02T12:01:41Z"}
{"aid":"http://arxiv.org/abs/2504.01671v1","title":"Anomaly Detection for Hybrid Butterfly Subspecies via Probability\n  Filtering","summary":"Detecting butterfly hybrids requires knowledge of the parent subspecies, and\nthe process can be tedious when encountering a new subspecies. This study\nfocuses on a specific scenario where a model trained to recognize hybrid\nspecies A can generalize to species B when B biologically mimics A. Since\nspecies A and B share similar patterns, we leverage BioCLIP as our feature\nextractor to capture features based on their taxonomy. Consequently, the\nalgorithm designed for species A can be transferred to B, as their hybrid and\nnon-hybrid patterns exhibit similar relationships. To determine whether a\nbutterfly is a hybrid, we adopt proposed probability filtering and color\njittering to augment and simulate the mimicry. With these approaches, we\nachieve second place in the official development phase. Our code is publicly\navailable at https://github.com/Justin900429/NSF-HDR-Challenge.","main_category":"cs.CE","categories":"cs.CE,cs.AI","published":"2025-04-02T12:18:44Z"}
{"aid":"http://arxiv.org/abs/2504.01673v1","title":"K-P Quantum Neural Networks","summary":"We present an extension of K-P time-optimal quantum control solutions using\nglobal Cartan $KAK$ decompositions for geodesic-based solutions. Extending\nrecent time-optimal \\emph{constant-$\\theta$} control results, we integrate\nCartan methods into equivariant quantum neural network (EQNN) for quantum\ncontrol tasks. We show that a finite-depth limited EQNN ansatz equipped with\nCartan layers can replicate the constant-$\\theta$ sub-Riemannian geodesics for\nK-P problems. We demonstrate how for certain classes of control problem on\nRiemannian symmetric spaces, gradient-based training using an appropriate cost\nfunction converges to certain global time-optimal solutions when satisfying\nsimple regularity conditions. This generalises prior geometric control theory\nmethods and clarifies how optimal geodesic estimation can be performed in\nquantum machine learning contexts.","main_category":"quant-ph","categories":"quant-ph,cs.AI","published":"2025-04-02T12:22:18Z"}
{"aid":"http://arxiv.org/abs/2504.01677v1","title":"System Level Synthesis for Affine Control Policies: Model Based and\n  Data-Driven Settings","summary":"There is an increasing need for effective control of systems with complex\ndynamics, particularly through data-driven approaches. System Level Synthesis\n(SLS) has emerged as a powerful framework that facilitates the control of\nlarge-scale systems while accounting for model uncertainties. SLS approaches\nare currently limited to linear systems and time-varying linear control\npolicies, thus limiting the class of achievable control strategies. We\nintroduce a novel closed-loop parameterization for time-varying affine control\npolicies, extending the SLS framework to a broader class of systems and\npolicies. We show that the closed-loop behavior under affine policies can be\nequivalently characterized using past system trajectories, enabling a fully\ndata-driven formulation. This parameterization seamlessly integrates affine\npolicies into optimal control problems, allowing for a closed-loop formulation\nof general Model Predictive Control (MPC) problems. To the best of our\nknowledge, this is the first work to extend SLS to affine policies in both\nmodel-based and data-driven settings, enabling an equivalent formulation of MPC\nproblems using closed-loop maps. We validate our approach through numerical\nexperiments, demonstrating that our model-based and data-driven affine SLS\nformulations achieve performance on par with traditional model-based MPC.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-02T12:26:20Z"}
{"aid":"http://arxiv.org/abs/2504.01706v1","title":"Exact Borel subalgebras of quasi-hereditary monomial algebras","summary":"Green and Schroll give an easy criterion for a monomial algebra $A$ to be\nquasi-hereditary with respect to some partial order $\\leq_A$. A natural\nfollow-up question is under which conditions a monomial quasi-hereditary\nalgebra $(A, \\leq_A)$ admits an exact Borel subalgebra in the sense of K\\\"onig.\nIn this article, we show that it always admits a Reedy decomposition consisting\nof an exact Borel subalgebra $B$, which has a basis given by paths, and a dual\nsubalgebra. Moreover, we give an explicit description of $B$ and show that it\nis the unique exact Borel subalgebra of $A$ with a basis given by paths.\nAdditionally, we give a criterion for when $B$ is regular, using a criterion by\nConde.","main_category":"math.RT","categories":"math.RT","published":"2025-04-02T13:13:02Z"}
{"aid":"http://arxiv.org/abs/2504.01731v1","title":"The protein escape process at the ribosomal exit tunnel has conserved\n  mechanisms across the domains of life","summary":"The ribosomal exit tunnel is the primary structure affecting the release of\nnascent proteins at the ribosome. The ribosomal exit tunnels from different\nspecies have elements of conservation and differentiation in structural and\nphysico-chemical properties. In this study, by simulating the elongation and\nescape processes of nascent proteins at the ribosomal exit tunnels of four\ndifferent organisms, we show that the escape process has conserved mechanisms\nacross the domains of life. Specifically, it is found that the escape process\nof proteins follows the diffusion mechanism given by a simple diffusion model\nand the median escape time positively correlates with the number of hydrophobic\nresidues and the net charge of a protein for all the exit tunnels considered.\nThese properties hold for twelve distinct proteins considered in two slightly\ndifferent and improved G\\=o-like models. It is also found that the differences\nin physico-chemical properties of the tunnels lead to quantitative differences\nin the protein escape times. In particular, the relatively strong\nhydrophobicity of the E. coli's tunnel and the unusually high number of\nnegatively charged amino acids on the tunnel's surface of H. marismortui lead\nto substantially slower escapes of proteins at these tunnels than at those of\nS. cerevisisae and H. sapiens.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-02T13:40:58Z"}
{"aid":"http://arxiv.org/abs/2504.01783v1","title":"CLaP -- State Detection from Time Series","summary":"The ever-growing amount of sensor data from machines, smart devices, and the\nenvironment leads to an abundance of high-resolution, unannotated time series\n(TS). These recordings encode the recognizable properties of latent states and\ntransitions from physical phenomena that can be modelled as abstract processes.\nThe unsupervised localization and identification of these states and their\ntransitions is the task of time series state detection (TSSD). We introduce\nCLaP, a new, highly accurate and efficient algorithm for TSSD. It leverages the\npredictive power of time series classification for TSSD in an unsupervised\nsetting by applying novel self-supervision techniques to detect whether data\nsegments emerge from the same state or not. To this end, CLaP cross-validates a\nclassifier with segment-labelled subsequences to quantify confusion between\nsegments. It merges labels from segments with high confusion, representing the\nsame latent state, if this leads to an increase in overall classification\nquality. We conducted an experimental evaluation using 391 TS from four\nbenchmarks and found CLaP to be significantly more precise in detecting states\nthan five state-of-the-art competitors. It achieves the best accuracy-runtime\ntradeoff and is scalable to large TS. We provide a Python implementation of\nCLaP, which can be deployed in TS analysis workflows.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.DB","published":"2025-04-02T14:46:42Z"}
{"aid":"http://arxiv.org/abs/2504.01788v1","title":"Projections from Furstenberg boundaries onto maximal flats and\n  barycenter maps","summary":"Let $G$ be a semisimple connected Lie group of non-compact type with finite\ncenter. Let $K<G$ be a maximal compact subgroup and $P<G$ be a minimal\nparabolic subgroup. For any pair $(F,x)$, where $F$ is a maximal flat in $G/K$\nand $x \\in G/P$ is opposite to the Weyl chambers determined by $F$, we define a\nprojection $\\Phi(F, x) \\in F$ which is continuous and $G$-equivariant.\nFurthermore, if $q \\geq 3$, we exhibit a $G$-equivariant continuous map defined\non an open subset of full measure of the space of $q$-tuples of $(G/P)^q$ with\nimage in $G/K$. When $G$ is the orientation preserving isometries of real\nhyperbolic space and $q = 3$, we recover the geometric barycenter of the\ncorresponding ideal triangle. All our proofs are constructive.","main_category":"math.GR","categories":"math.GR,math.DG","published":"2025-04-02T14:53:07Z"}
{"aid":"http://arxiv.org/abs/2504.01812v1","title":"Non-collocated vibration absorption using delayed resonator for spectral\n  and spacial tuning -- analysis and experimental validation","summary":"Non-collocated vibration absorption (NCVA) concept using delayed resonator\nfor in-situ tuning is analyzed and experimentally validated. There are two\ncritical contributions of this work. One is on the scalable analytical pathway\nfor verifying the concept of resonant substructure as the basis of the ideal\nvibration absorption. The second is to experimentally validate the spatial and\nspectral tunability of NCVA structures for the first time. For both novelties\narbitrarily large dimensions of interconnected mass-spring-damper chains are\nconsidered. Following the state of the art on NCVA, control synthesis is\nperformed over the resonant substructure comprising the delayed resonator and a\npart of the primary structure involved in the vibration absorption. The\nexperimental validation of the proposed NCVA concept is performed on a\nmechatronic setup with three interconnected cart-bodies. Based on the spectral\nanalysis, an excitation frequency is selected for which a stable vibration\nsuppression can be achieved sequentially for all the three bodies, one\ncollocated and two non-collocated. The experimental results closely match the\nsimulations for complete vibration suppression at the targeted bodies, and thus\nvalidating the crucial spatial tunability characteristic as well as the\ntraditional spectral tuning.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-02T15:18:20Z"}
{"aid":"http://arxiv.org/abs/2504.01814v1","title":"Energy Density Functional of Confined Quarks: an Improved Ansatz","summary":"Density Functional Theory (DFT) is a robust framework for modeling\ninteracting many-body systems, including the equation of state (EoS) of dense\nmatter. Many models, however, rely on energy functionals based on assumptions\nthat have not been rigorously validated. We critically analyze a commonly used\nansatz for confinement, where the energy functional scales with density as $U\n\\propto n^{\\frac{2}{3}}$ . Our findings, derived from a systematic non-local\nenergy functional, reveal that this scaling does not capture the dynamics of\nconfinement. Instead, the energy functional evolves from $n^2$ at low densities\nto $n$ at high densities, governed by an infrared cutoff. These results suggest\nthat models relying on such assumptions should be revisited to ensure more\nreliable EoS construction.","main_category":"nucl-th","categories":"nucl-th,astro-ph.HE,hep-ph,hep-th","published":"2025-04-02T15:20:03Z"}
{"aid":"http://arxiv.org/abs/2504.01821v1","title":"How to Reliably Measure Carrier Mobility in Highly Resistive Lead Halide\n  Perovskites with Photo-Hall Experiment","summary":"Mobility measurements in highly resistive methylammonium lead iodide (MAPI)\nare challenging due to high impedance, ion drift, and low mobility. We show\nthat we can address the challenge using intensity-dependent photo-Hall\nmeasurements. The key is an improved photo-Hall setup, which enables reliable\nHall measurements in the dark and under low-intensity illumination. By tuning\nthe illumination over four orders of magnitude, we get the additional\ninformation to simultaneously extract hole mobility, electron mobility, and\nbackground doping. For the first time, we show that a MAPI single crystal,\nexhibiting n-type behaviour in the dark, can show p-type behaviour under light\ndue to the difference in hole and electron mobility. The data partly explains\nthe variability in mobility reported in the literature. We show that one can\nerroneously extract any mobility from 0 to 25 cm2/Vs if we restrict the\nexperiment to a small range of illumination intensities. For our MAPI (310)\ncrystal, the measured hole and electron mobility is 40 cm2/Vs and 25.5 cm2/Vs,\nrespectively.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T15:28:22Z"}
{"aid":"http://arxiv.org/abs/2504.01837v1","title":"Cramér--Rao Inequalities for Several Generalized Fisher Information","summary":"The de Bruijn identity states that Fisher information is the half of the\nderivative of Shannon differential entropy along heat flow. In the same spirit,\nin this paper we introduce a generalized version of Fisher information, named\nas the R\\'enyi--Fisher information, which is the half of the derivative of\nR\\'enyi information along heat flow. Based on this R\\'enyi--Fisher information,\nwe establish sharp R\\'enyi-entropic isoperimetric inequalities, which\ngeneralize the classic entropic isoperimetric inequality to the R\\'enyi\nsetting. Utilizing these isoperimetric inequalities, we extend the classical\nCram\\'er--Rao inequality from Fisher information to R\\'enyi--Fisher\ninformation. Lastly, we use these generalized Cram\\'er--Rao inequalities to\ndetermine the signs of derivatives of entropy along heat flow, strengthening\nexisting results on the complete monotonicity of entropy.","main_category":"cs.IT","categories":"cs.IT,math.IT,math.PR,math.ST,stat.TH","published":"2025-04-02T15:44:02Z"}
{"aid":"http://arxiv.org/abs/2504.01840v1","title":"LARGE: Legal Retrieval Augmented Generation Evaluation Tool","summary":"Recently, building retrieval-augmented generation (RAG) systems to enhance\nthe capability of large language models (LLMs) has become a common practice.\nEspecially in the legal domain, previous judicial decisions play a significant\nrole under the doctrine of stare decisis which emphasizes the importance of\nmaking decisions based on (retrieved) prior documents. However, the overall\nperformance of RAG system depends on many components: (1) retrieval corpora,\n(2) retrieval algorithms, (3) rerankers, (4) LLM backbones, and (5) evaluation\nmetrics. Here we propose LRAGE, an open-source tool for holistic evaluation of\nRAG systems focusing on the legal domain. LRAGE provides GUI and CLI interfaces\nto facilitate seamless experiments and investigate how changes in the\naforementioned five components affect the overall accuracy. We validated LRAGE\nusing multilingual legal benches including Korean (KBL), English (LegalBench),\nand Chinese (LawBench) by demonstrating how the overall accuracy changes when\nvarying the five components mentioned above. The source code is available at\nhttps://github.com/hoorangyee/LRAGE.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T15:45:03Z"}
{"aid":"http://arxiv.org/abs/2504.01852v1","title":"Deciphering the Nature of Virgil: An Obscured AGN Lurking Within an\n  Apparently Normal Lyman-α Emitter During Cosmic Reionization","summary":"We present a comprehensive analysis of the MIRI Extremely Red Object Virgil,\na Lyman-$\\alpha$ emitter at $z_{spec} = 6.6379 \\pm 0.0035$ with the photometric\nproperties of a Little Red Dot. Leveraging new JWST/MIRI imaging from the MIDIS\nand PAHSPECS programs, we confirm Virgil's extraordinary nature among galaxies\nin JADES/GOODS-South, exhibiting a strikingly red NIRCam-to-MIRI color (F444W\n$-$ F1500W = $2.84\\pm0.04$~mag). Deep NIRSpec/PRISM spectroscopy from the OASIS\nprogram offers key insights into the host galaxy, revealing properties of an\naverage star-forming galaxy during Cosmic Reionization, such as a subsolar\nmetallicity, low-to-moderate dust content, and a relatively high ionization\nparameter and electron temperature. By estimating the star formation rate of\nVirgil from UV and H$\\alpha$, we find evidence that the galaxy is either\nentering or fading out of a bursty episode. Although line-ratio diagnostics\nemployed at high-$z$ would classify Virgil as an Active Galactic Nucleus (AGN),\nthis classification becomes ambiguous once redshift evolution is considered.\nNonetheless, Virgil occupies the same parameter space as recently confirmed\nAGNs at similar redshifts. The new deep MIRI data at 15~$\\mu$m reinforce the\nAGN nature of Virgil, as inferred from multiple spectral energy distribution\n(SED) fitting codes. Virgil's rising infrared SED and UV excess resemble those\nof Dust-Obscured Galaxies (DOGs) studied with Spitzer at Cosmic Noon,\nparticularly blue-excess HotDOGs. Our results highlight the need for a\nmulti-wavelength approach incorporating MIRI to uncover such extreme sources at\n$z\\gtrsim6$ and to shed light on the interplay between galaxy evolution and\nearly black hole growth during Cosmic Reionization.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-04-02T16:04:22Z"}
{"aid":"http://arxiv.org/abs/2504.01853v1","title":"Implications of recent LHCb data on CPV in b-baryon four body decays","summary":"Motivated by the recent CPV observation, we investigate the CPV of b-baryon\ncharmless four body decays under the U-spin symmetry. However, we find that\nonly U-spin symmetry cannot provide effective predictions, particularly for\n$\\Lambda_b$ decays. For giving more useful predictions, we also give a simple\ndynamic analysis. By counting the\npower($\\lambda=\\sqrt{\\frac{\\Lambda_{QCD}}{m_b}}$) of each topological diagram,\nwe find that for the specific decay $B_b^2\\to R(B_1^2 M^2 M^{\\bar 2})M^2$, only\none U-spin amplitude can contribute in the leading power. Then the effective\nprediction can be given as \\begin{align}\n  A_{CP}^{dir}(\\Lambda_b^0 \\to R( p \\pi^- \\pi^+ )\\pi^-) = (-12.98 \\pm\n2.85)\\%.\\notag \\end{align} Considering the $\\Lambda_b$ can effectively produced\nin LHCb, we strongly encourage a more precise experimental investigation of it.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-02T16:05:00Z"}
{"aid":"http://arxiv.org/abs/2504.01854v1","title":"Some norm inequalities for commutators generated by the Riesz potentials\n  on homogeneous variable exponent Herz-Morrey-Hardy spaces","summary":"In harmonic analysis, the studies of inequalities of classical operators (=\nsingular, maximal, Riesz potentials etc.) in various function spaces have a\nvery important place. The maturation of many topics in the field of harmonic\nanalysis, as a result of various needs and developments to respond to the\nproblems of the time, has also led to the emergence of many studies and works\non these topics. In [3], under some conditions, the boundedness of Riesz\npotential on homogeneous variable exponent Herz-Morrey-Hardy spaces has been\ngiven. Inspired by the work of [3], in this work, by the atomic decompositions,\nwe obtain the boundedness of commutators generated by the Riesz potentials on\nhomogeneous variable exponent Herz-Morrey-Hardy spaces.","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T16:05:00Z"}
{"aid":"http://arxiv.org/abs/2504.01883v1","title":"CoRAG: Collaborative Retrieval-Augmented Generation","summary":"Retrieval-Augmented Generation (RAG) models excel in knowledge-intensive\ntasks, especially under few-shot learning constraints. We introduce CoRAG, a\nframework extending RAG to collaborative settings, where clients jointly train\na shared model using a collaborative passage store. To evaluate CoRAG, we\nintroduce CRAB, a benchmark for collaborative homogeneous open-domain question\nanswering. Our experiments demonstrate that CoRAG consistently outperforms both\nparametric collaborative learning methods and locally trained RAG models in\nlow-resource scenarios. Further analysis reveals the critical importance of\nrelevant passages within the shared store, the surprising benefits of\nincorporating irrelevant passages, and the potential for hard negatives to\nnegatively impact performance. This introduces a novel consideration in\ncollaborative RAG: the trade-off between leveraging a collectively enriched\nknowledge base and the potential risk of incorporating detrimental passages\nfrom other clients. Our findings underscore the viability of CoRAG, while also\nhighlighting key design challenges and promising avenues for future research.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.IR,cs.LG","published":"2025-04-02T16:40:43Z"}
{"aid":"http://arxiv.org/abs/2504.01890v1","title":"Is Temporal Prompting All We Need For Limited Labeled Action\n  Recognition?","summary":"Video understanding has shown remarkable improvements in recent years,\nlargely dependent on the availability of large scaled labeled datasets. Recent\nadvancements in visual-language models, especially based on contrastive\npretraining, have shown remarkable generalization in zero-shot tasks, helping\nto overcome this dependence on labeled datasets. Adaptations of such models for\nvideos, typically involve modifying the architecture of vision-language models\nto cater to video data. However, this is not trivial, since such adaptations\nare mostly computationally intensive and struggle with temporal modeling. We\npresent TP-CLIP, an adaptation of CLIP that leverages temporal visual prompting\nfor temporal adaptation without modifying the core CLIP architecture. This\npreserves its generalization abilities. TP-CLIP efficiently integrates into the\nCLIP architecture, leveraging its pre-trained capabilities for video data.\nExtensive experiments across various datasets demonstrate its efficacy in\nzero-shot and few-shot learning, outperforming existing approaches with fewer\nparameters and computational efficiency. In particular, we use just 1/3 the\nGFLOPs and 1/28 the number of tuneable parameters in comparison to recent\nstate-of-the-art and still outperform it by up to 15.8% depending on the task\nand dataset.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T16:50:28Z"}
{"aid":"http://arxiv.org/abs/2504.01894v1","title":"Multi-fidelity Parameter Estimation Using Conditional Diffusion Models","summary":"We present a multi-fidelity method for uncertainty quantification of\nparameter estimates in complex systems, leveraging generative models trained to\nsample the target conditional distribution. In the Bayesian inference setting,\ntraditional parameter estimation methods rely on repeated simulations of\npotentially expensive forward models to determine the posterior distribution of\nthe parameter values, which may result in computationally intractable\nworkflows. Furthermore, methods such as Markov Chain Monte Carlo (MCMC)\nnecessitate rerunning the entire algorithm for each new data observation,\nfurther increasing the computational burden. Hence, we propose a novel method\nfor efficiently obtaining posterior distributions of parameter estimates for\nhigh-fidelity models given data observations of interest. The method first\nconstructs a low-fidelity, conditional generative model capable of amortized\nBayesian inference and hence rapid posterior density approximation over a\nwide-range of data observations. When higher accuracy is needed for a specific\ndata observation, the method employs adaptive refinement of the density\napproximation. It uses outputs from the low-fidelity generative model to refine\nthe parameter sampling space, ensuring efficient use of the computationally\nexpensive high-fidelity solver. Subsequently, a high-fidelity, unconditional\ngenerative model is trained to achieve greater accuracy in the target posterior\ndistribution. Both low- and high- fidelity generative models enable efficient\nsampling from the target posterior and do not require repeated simulation of\nthe high-fidelity forward model. We demonstrate the effectiveness of the\nproposed method on several numerical examples, including cases with multi-modal\ndensities, as well as an application in plasma physics for a runaway electron\nsimulation model.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T16:54:47Z"}
{"aid":"http://arxiv.org/abs/2504.01951v1","title":"The LLM Wears Prada: Analysing Gender Bias and Stereotypes through\n  Online Shopping Data","summary":"With the wide and cross-domain adoption of Large Language Models, it becomes\ncrucial to assess to which extent the statistical correlations in training\ndata, which underlie their impressive performance, hide subtle and potentially\ntroubling biases. Gender bias in LLMs has been widely investigated from the\nperspectives of works, hobbies, and emotions typically associated with a\nspecific gender. In this study, we introduce a novel perspective. We\ninvestigate whether LLMs can predict an individual's gender based solely on\nonline shopping histories and whether these predictions are influenced by\ngender biases and stereotypes. Using a dataset of historical online purchases\nfrom users in the United States, we evaluate the ability of six LLMs to\nclassify gender and we then analyze their reasoning and products-gender\nco-occurrences. Results indicate that while models can infer gender with\nmoderate accuracy, their decisions are often rooted in stereotypical\nassociations between product categories and gender. Furthermore, explicit\ninstructions to avoid bias reduce the certainty of model predictions, but do\nnot eliminate stereotypical patterns. Our findings highlight the persistent\nnature of gender biases in LLMs and emphasize the need for robust\nbias-mitigation strategies.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.CY","published":"2025-04-02T17:56:08Z"}
{"aid":"http://arxiv.org/abs/2504.01960v1","title":"Diffusion-Guided Gaussian Splatting for Large-Scale Unconstrained 3D\n  Reconstruction and Novel View Synthesis","summary":"Recent advancements in 3D Gaussian Splatting (3DGS) and Neural Radiance\nFields (NeRF) have achieved impressive results in real-time 3D reconstruction\nand novel view synthesis. However, these methods struggle in large-scale,\nunconstrained environments where sparse and uneven input coverage, transient\nocclusions, appearance variability, and inconsistent camera settings lead to\ndegraded quality. We propose GS-Diff, a novel 3DGS framework guided by a\nmulti-view diffusion model to address these limitations. By generating\npseudo-observations conditioned on multi-view inputs, our method transforms\nunder-constrained 3D reconstruction problems into well-posed ones, enabling\nrobust optimization even with sparse data. GS-Diff further integrates several\nenhancements, including appearance embedding, monocular depth priors, dynamic\nobject modeling, anisotropy regularization, and advanced rasterization\ntechniques, to tackle geometric and photometric challenges in real-world\nsettings. Experiments on four benchmarks demonstrate that GS-Diff consistently\noutperforms state-of-the-art baselines by significant margins.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-02T17:59:46Z"}
{"aid":"http://arxiv.org/abs/2504.02260v1","title":"Implicit Neural Differential Model for Spatiotemporal Dynamics","summary":"Hybrid neural-physics modeling frameworks through differentiable programming\nhave emerged as powerful tools in scientific machine learning, enabling the\nintegration of known physics with data-driven learning to improve prediction\naccuracy and generalizability. However, most existing hybrid frameworks rely on\nexplicit recurrent formulations, which suffer from numerical instability and\nerror accumulation during long-horizon forecasting. In this work, we introduce\nIm-PiNDiff, a novel implicit physics-integrated neural differentiable solver\nfor stable and accurate modeling of spatiotemporal dynamics. Inspired by deep\nequilibrium models, Im-PiNDiff advances the state using implicit fixed-point\nlayers, enabling robust long-term simulation while remaining fully end-to-end\ndifferentiable. To enable scalable training, we introduce a hybrid gradient\npropagation strategy that integrates adjoint-state methods with reverse-mode\nautomatic differentiation. This approach eliminates the need to store\nintermediate solver states and decouples memory complexity from the number of\nsolver iterations, significantly reducing training overhead. We further\nincorporate checkpointing techniques to manage memory in long-horizon rollouts.\nNumerical experiments on various spatiotemporal PDE systems, including\nadvection-diffusion processes, Burgers' dynamics, and multi-physics chemical\nvapor infiltration processes, demonstrate that Im-PiNDiff achieves superior\npredictive performance, enhanced numerical stability, and substantial\nreductions in memory and runtime cost relative to explicit and naive implicit\nbaselines. This work provides a principled, efficient, and scalable framework\nfor hybrid neural-physics modeling.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-03T04:07:18Z"}
{"aid":"http://arxiv.org/abs/2504.02270v1","title":"MinkOcc: Towards real-time label-efficient semantic occupancy prediction","summary":"Developing 3D semantic occupancy prediction models often relies on dense 3D\nannotations for supervised learning, a process that is both labor and\nresource-intensive, underscoring the need for label-efficient or even\nlabel-free approaches. To address this, we introduce MinkOcc, a multi-modal 3D\nsemantic occupancy prediction framework for cameras and LiDARs that proposes a\ntwo-step semi-supervised training procedure. Here, a small dataset of\nexplicitly 3D annotations warm-starts the training process; then, the\nsupervision is continued by simpler-to-annotate accumulated LiDAR sweeps and\nimages -- semantically labelled through vision foundational models. MinkOcc\neffectively utilizes these sensor-rich supervisory cues and reduces reliance on\nmanual labeling by 90\\% while maintaining competitive accuracy. In addition,\nthe proposed model incorporates information from LiDAR and camera data through\nearly fusion and leverages sparse convolution networks for real-time\nprediction. With its efficiency in both supervision and computation, we aim to\nextend MinkOcc beyond curated datasets, enabling broader real-world deployment\nof 3D semantic occupancy prediction in autonomous driving.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-03T04:31:56Z"}
{"aid":"http://arxiv.org/abs/2504.02290v1","title":"A contratableau model for K-theoretic Littlewood-Richardson rule","summary":"The K-theoretic Littlewood-Richardson rule, established by A. Buch, is a\ncombinatorial method for counting the structure constants involved in the\nproduct of two Grothendieck polynomials of Grassmannian type. In this paper, we\nprovide an explicit combinatorial formula in terms of set-valued contratableau\nfor the K-theoretic Littlewood-Richardson rule generalizing contratableau model\nfor the classical Littlewood-Richardson rule given by Carr\\'e.","main_category":"math.CO","categories":"math.CO","published":"2025-04-03T05:44:08Z"}
{"aid":"http://arxiv.org/abs/2504.02303v1","title":"Diversifying halo structures in two-component self-interacting dark\n  matter models via mass segregation","summary":"Self-interacting dark matter (SIDM), through gravothermal evolution driven by\nelastic self-scatterings, offers a compelling explanation for the observed\ndiversity of inner halo densities. In this work, we investigate SIDM dynamics\nin a two-component dark matter model with mass ratios of order unity, motivated\nby an asymmetric dark matter framework that naturally evades constraints from\nrelic abundance and mediator decay, while enabling strong, velocity-dependent\nself-interactions. We show that cross-component scatterings significantly\nenhance mass segregation, driving the formation of dense, core collapsed-like\nhalos. This effect couples naturally to SIDM-induced diversity, introducing a\nnew mechanism for generating structural variations beyond those arising from\ngravothermal evolution alone. Our results reveal a novel mechanism for\nreconciling SIDM with small-scale observational tensions by enabling shifts in\ncentral densities while preserving the flexibility to generate diverse halo\nstructures. We further highlight that halo structural diversity may serve as a\ndiagnostic of dark sector composition, opening a new observational window into\nthe particle nature of SIDM.","main_category":"astro-ph.CO","categories":"astro-ph.CO,hep-ph","published":"2025-04-03T06:20:10Z"}
{"aid":"http://arxiv.org/abs/2504.02322v1","title":"Distributed Log-driven Anomaly Detection System based on Evolving\n  Decision Making","summary":"Effective anomaly detection from logs is crucial for enhancing cybersecurity\ndefenses by enabling the early identification of threats. Despite advances in\nanomaly detection, existing systems often fall short in areas such as\npost-detection validation, scalability, and effective maintenance. These\nlimitations not only hinder the detection of new threats but also impair\noverall system performance. To address these challenges, we propose CEDLog, a\nnovel practical framework that integrates Elastic Weight Consolidation (EWC)\nfor continual learning and implements distributed computing for scalable\nprocessing by integrating Apache Airflow and Dask. In CEDLog, anomalies are\ndetected through the synthesis of Multi-layer Perceptron (MLP) and Graph\nConvolutional Networks (GCNs) using critical features present in event logs.\nThrough comparisons with update strategies on large-scale datasets, we\ndemonstrate the strengths of CEDLog, showcasing efficient updates and low false\npositives","main_category":"cs.CR","categories":"cs.CR,cs.DC","published":"2025-04-03T06:50:30Z"}
{"aid":"http://arxiv.org/abs/2504.02331v1","title":"In situ and real-time ultrafast spectroscopy of photoinduced reactions\n  in perovskite nanomaterials","summary":"Employing two synchronized mode-locked femtosecond lasers and interferometric\ndetection of the pump-probe spectra -- referred to as asynchronous and\ninterferometric transient absorption (AI-TA) -- we have developed a method for\nbroad dynamic range and rapid data acquisition. Using AI-TA, we examined\nphotochemical changes during femtosecond pump-probe experiments on\nall-inorganic cesium lead halide nanomaterials, including perovskite\nnanocrystals (PeNCs) and nanoplatelets (PeNPLs). The laser pulse train\nfacilitates photoreactions while allowing real-time observation of charge\ncarrier dynamics. In PeNCs undergoing halide anion photo-substitution,\ntransient absorption spectra showed increasing bandgap energy and faster\nrelaxation dynamics as the Cl/Br ratio increased. For colloidal PeNPLs,\ncontinuous observation revealed both spectral and kinetic changes during the\nlight-induced coalescence of nanoplatelets, by analyzing temporal segments.\nThis integrated technique not only deepens understanding of exciton dynamics\nand environmental influences in perovskite nanomaterials but also establishes\nAI-TA as a transformative tool for real-time observation of photochemical\ndynamics.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci,physics.chem-ph","published":"2025-04-03T07:09:29Z"}
{"aid":"http://arxiv.org/abs/2504.02334v1","title":"Determining Sphere Radius through Pairwise Distances","summary":"We propose a novel method for determining the radius of a spherical surface\nbased on the distances measured between points on this surface. We consider the\nmost general case of determining the radius when the distances are measured\nwith errors and the sphere has random deviations from its ideal shape. For the\nsolution, we used the minimally necessary four points and an arbitrary N number\nof points. We provide a new closed form solution for the radius of the sphere\nthrough the matrix of pairwise distances. We also determine the standard\ndeviation of the radius estimate caused by measurement errors and deviations of\nthe sphere from its ideal shape. We found optimal configurations of points on\nthe sphere that provide the minimum standard deviation of the radius estimate.\nThis paper describes our solution and provides all the mathematical\nderivations. We share the implementation of our method as open source code at\nhttps://github.com/boris-sukhovilov/Sphere_Radius.","main_category":"cs.CG","categories":"cs.CG,cs.CV","published":"2025-04-03T07:15:15Z"}
{"aid":"http://arxiv.org/abs/2504.02369v1","title":"Finding Diverse Solutions in Combinatorial Problems with a Distributive\n  Lattice Structure","summary":"We generalize the polynomial-time solvability of $k$-\\textsc{Diverse Minimum\ns-t Cuts} (De Berg et al., ISAAC'23) to a wider class of combinatorial problems\nwhose solution sets have a distributive lattice structure. We identify three\nstructural conditions that, when met by a problem, ensure that a $k$-sized\nmultiset of maximally-diverse solutions -- measured by the sum of pairwise\nHamming distances -- can be found in polynomial time. We apply this framework\nto obtain polynomial time algorithms for finding diverse minimum $s$-$t$ cuts\nand diverse stable matchings. Moreover, we show that the framework extends to\ntwo other natural measures of diversity. Lastly, we present a simpler\nalgorithmic framework for finding a largest set of pairwise disjoint solutions\nin problems that meet these structural conditions.","main_category":"cs.DS","categories":"cs.DS,cs.CC","published":"2025-04-03T08:01:41Z"}
{"aid":"http://arxiv.org/abs/2504.02372v1","title":"Quantum Key Distribution over Complex Networks","summary":"There exist several initiatives worldwide to deploy quantum key distribution\n(QKD) over existing fibre networks and achieve quantum-safe security at large\nscales. To understand the overall QKD network performance, it is required to\ntransition from the analysis of individual links, as done so far, to the\ncharacterization of the network as a whole. In this work, we undertake this\nstudy by embedding QKD protocols on complex networks, which correctly model the\nexisting fiber networks. We focus on networks with trusted nodes and on\ncontinuous-variable (CV) schemes, which have much higher key rates than their\ndiscrete-variable (DV) counterparts. In the effective CV network, however, many\nof the unique properties of complex networks, such as small-worldness and the\npresence of hubs, are lost due to the fast decay of the key rate with physical\ndistance for CV systems. These properties can be restored when considering a\nhybrid network consisting of both CV and DV protocols, achieving at the same\ntime high average rate and inter-connectivity. Our work opens the path to the\nstudy of QKD complex networks in existing infrastructures.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech,physics.soc-ph","published":"2025-04-03T08:05:44Z"}
{"aid":"http://arxiv.org/abs/2504.02382v1","title":"Benchmark of Segmentation Techniques for Pelvic Fracture in CT and\n  X-ray: Summary of the PENGWIN 2024 Challenge","summary":"The segmentation of pelvic fracture fragments in CT and X-ray images is\ncrucial for trauma diagnosis, surgical planning, and intraoperative guidance.\nHowever, accurately and efficiently delineating the bone fragments remains a\nsignificant challenge due to complex anatomy and imaging limitations. The\nPENGWIN challenge, organized as a MICCAI 2024 satellite event, aimed to advance\nautomated fracture segmentation by benchmarking state-of-the-art algorithms on\nthese complex tasks. A diverse dataset of 150 CT scans was collected from\nmultiple clinical centers, and a large set of simulated X-ray images was\ngenerated using the DeepDRR method. Final submissions from 16 teams worldwide\nwere evaluated under a rigorous multi-metric testing scheme. The top-performing\nCT algorithm achieved an average fragment-wise intersection over union (IoU) of\n0.930, demonstrating satisfactory accuracy. However, in the X-ray task, the\nbest algorithm attained an IoU of 0.774, highlighting the greater challenges\nposed by overlapping anatomical structures. Beyond the quantitative evaluation,\nthe challenge revealed methodological diversity in algorithm design. Variations\nin instance representation, such as primary-secondary classification versus\nboundary-core separation, led to differing segmentation strategies. Despite\npromising results, the challenge also exposed inherent uncertainties in\nfragment definition, particularly in cases of incomplete fractures. These\nfindings suggest that interactive segmentation approaches, integrating human\ndecision-making with task-relevant information, may be essential for improving\nmodel reliability and clinical applicability.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-03T08:19:36Z"}
{"aid":"http://arxiv.org/abs/2504.02405v1","title":"Impact of helium ion irradiation on the thermal properties of\n  superconducting nanowire single-photon detectors","summary":"SNSPDs are indispensable for applications ranging from quantum information\nprocessing to deep-space optical communications, owing to their high detection\nefficiency, low dark counts, and excellent timing resolution. However, further\nimproving the intrinsic detection efficiency (IDE) remains crucial for\noptimizing SNSPD performance. Ion irradiation has recently emerged as a\npowerful post-fabrication method to enhance SNSPD characteristics. Here, the\neffects of He-ion irradiation on the thermal properties of NbN SNSPDs. We\nsystematically examine the evolution of thermal boundary conductance as a\nfunction of ion fluence (0-1.1E17 ions/cm2), observing a 57% decrease from 127\nto 54 W/m^2K^4 with increasing fluence, followed by saturation at approximately\n9E16 ions/cm2. At this fluence, the minimum hotspot relaxation time\nmeasurements indicate a 41% increase, rising from 17 to 24 ps, while the\nelectron-phonon interaction time extends by 14%, from 11.2 to 12.8 ps at 10 K.\nTEM reveals defect formation at the NbN/SiO2 interface (6-8 nm) and He-bubble\nformation within the SiO2 layer (30-260 nm), contributing to the extended\nthermal relaxation time. These irradiation-induced modifications play a key\nrole in enhancing the IDE of the treated devices. Furthermore, we demonstrate\nan irradiated NbN SNSPD exhibiting a well-defined saturated IDE plateau at 2000\nnm from 2.7 K to 28 mK, enabled by irradiation-induced modifications and an\navalanche-assisted detection mechanism with weak wavelength dependence. Our\nfindings provide valuable insights into ion irradiation as a post-processing\ntechnique for SNSPDs, offering a pathway to enhancing IDE and tailoring thermal\nproperties. This work also advances the understanding of SNSPD physics and\ndefect engineering in superconducting thin films, expanding the potential\napplications of irradiation techniques in superconducting optoelectronics.","main_category":"physics.app-ph","categories":"physics.app-ph,physics.ins-det,quant-ph","published":"2025-04-03T08:54:30Z"}
{"aid":"http://arxiv.org/abs/2504.02435v1","title":"Poisson-Voronoi percolation in higher rank","summary":"We show that the uniqueness thresholds for Poisson-Voronoi percolation in\nsymmetric spaces of connected higher rank semisimple Lie groups with property\n(T) converge to zero in the low-intensity limit. This phenomenon is\nfundamentally different from situations in which Poisson-Voronoi percolation\nhas previously been studied.\n  Our approach builds on a recent breakthrough of Fraczyk, Mellick and Wilkens\n(arXiv:2307.01194) and provides an alternative proof strategy for Gaboriau's\nfixed price problem. As a further application of our result, we give a new\nclass of examples of non-amenable Cayley graphs that admit factor of iid bond\npercolations with a unique infinite cluster and arbitrarily small expected\ndegree, answering a question inspired by Hutchcroft-Pete (Invent. math. 221\n(2020)).}","main_category":"math.PR","categories":"math.PR,math.GR","published":"2025-04-03T09:50:22Z"}
{"aid":"http://arxiv.org/abs/2504.02460v1","title":"Finite steady-state current defies non-Hermitian many-body localization","summary":"Non-Hermitian many-body localization (NH MBL) has emerged as a possible\nscenario for stable localization in open systems, as suggested by spectral\nindicators identifying a putative transition for finite system sizes.\n  In this work, we shift the focus to dynamical probes, specifically the\nsteady-state spin current, to investigate transport properties in a disordered,\nnon-Hermitian XXZ spin chain. Through exact diagonalization for small systems\nand tensor-network methods for larger chains, we demonstrate that the\nsteady-state current remains finite and decays exponentially with disorder\nstrength, showing no evidence of a transition up to disorder values far beyond\nthe previously claimed critical point. Our results reveal a stark discrepancy\nbetween spectral indicators, which suggest localization, and transport\nbehavior, which indicates delocalization. This highlights the importance of\ndynamical observables in characterizing NH MBL and suggests that traditional\nspectral measures may not fully capture the physics of non-Hermitian systems.\n  Additionally, we observe a non-commutativity of limits in system size and\ntime, further complicating the interpretation of finite-size studies. These\nfindings challenge the existence of NH MBL in the studied model and underscore\nthe need for alternative approaches to understand localization in non-Hermitian\nsettings.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.stat-mech,quant-ph","published":"2025-04-03T10:24:39Z"}
{"aid":"http://arxiv.org/abs/2504.02466v1","title":"Optimal first-passage times of active Brownian particles under\n  stochastic resetting","summary":"We study the first-passage-time (FPT) properties of an active Brownian\nparticle under stochastic resetting to its initial configuration, comprising\nits position and orientation, to reach an absorbing wall in two dimensions.\nCoupling a perturbative approach for low P\\'eclet numbers, measuring the\nrelative importance of self-propulsion with respect to diffusion, with the\nrenewal framework for the stochastic resetting process, we derive analytical\nexpressions for the survival probability, the FPT probability density, and the\nassociated low-order moments. Depending on their initial orientation, the\nminimal mean FPT for active particles to reach the boundary can both decrease\nand increase relative to the passive counterpart. The associated optimal\nresetting rates depend non-trivially on the initial distance to the boundary\ndue to the intricate interplay of resetting, rotational Brownian noise, and\nactive motion.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech,physics.bio-ph","published":"2025-04-03T10:36:32Z"}
{"aid":"http://arxiv.org/abs/2504.02474v1","title":"Rigid m-percolation in limited-valence gels","summary":"Determining the onset of rigidity in gels is a fundamental challenge with\nsignificant practical implications across different applications.\nLimited-valence, or patchy-particle systems have proven to be a valuable model\nto study the relationship between microscopic interactions and macroscopic\nmechanical properties. It has been suggested that the emergence of rigidity\ncoincides with the formation of an infinitely spanning cluster of particles\nwith at least three bonds. This work explores this hypothesis, its\nimplications, and its broader applicability across a range of system\nparameters, by associating the emergence of rigidity with m-percolation\ntransition for m=3. The properties of m-percolation are developed using a\nmean-field theoretical approach validated with numerical simulations, and used\nto build phase and rigidity diagrams for different particle valences of both\nsingle-component systems and binary mixtures of patchy particles. The\ndifference between connectivity and rigidity percolation thresholds is found to\nreduce with increasing valence, providing an explanation for the challenges\nencountered in experimental attempts to distinguish isotropic connectivity\npercolation from the onset of rigidity. For binary mixtures, we found a robust\nminimum average valence, below which the gel is never rigid.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-03T10:50:17Z"}
{"aid":"http://arxiv.org/abs/2504.02476v1","title":"Globular cluster distributions as a dynamical probe of dark matter","summary":"Globular clusters (GCs) act as massive probe particles traversing the dark\nmatter halos of their host galaxies. Gravitational dynamical friction due to\nhalo particles causes GC orbits to contract over time, providing a beyond-mean\nfield test of the cold dark matter paradigm. We explore the information content\nof such systems, using N-body and semianalytic simulations and scanning over a\nrange of initial conditions. We consider data from the ultradiffuse galaxies\nNGC5846-UDG1 and UDG-DF44, and from the Fornax dwarf spheroidal galaxy. The GC\nsystems of UDG1 and Fornax indicate the presence of dark matter halos,\nindependent of (but consistent with) stellar kinematics data. UDG-DF44 is too\ndiffuse for dynamical friction to give strong constraints. Our analysis can be\nextended to many additional galaxies.","main_category":"astro-ph.GA","categories":"astro-ph.GA,hep-ph","published":"2025-04-03T10:53:02Z"}
{"aid":"http://arxiv.org/abs/2504.02479v1","title":"Hierarchical Policy-Gradient Reinforcement Learning for Multi-Agent\n  Shepherding Control of Non-Cohesive Targets","summary":"We propose a decentralized reinforcement learning solution for multi-agent\nshepherding of non-cohesive targets using policy-gradient methods. Our\narchitecture integrates target-selection with target-driving through Proximal\nPolicy Optimization, overcoming discrete-action constraints of previous Deep\nQ-Network approaches and enabling smoother agent trajectories. This model-free\nframework effectively solves the shepherding problem without prior dynamics\nknowledge. Experiments demonstrate our method's effectiveness and scalability\nwith increased target numbers and limited sensing capabilities.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.MA,cs.SY,eess.SY,stat.ML","published":"2025-04-03T10:56:57Z"}
{"aid":"http://arxiv.org/abs/2504.02504v1","title":"Ethics of Blockchain Technologies","summary":"This chapter explores three key questions in blockchain ethics. First, it\nsituates blockchain ethics within the broader field of technology ethics,\noutlining its goals and guiding principles. Second, it examines the unique\nethical challenges of blockchain applications, including permissionless\nsystems, incentive mechanisms, and privacy concerns. Key obstacles, such as\nconceptual modeling and information asymmetries, are identified as critical\nissues. Finally, the chapter argues that blockchain ethics should be approached\nas an engineering discipline, emphasizing the analysis and design of trade-offs\nin complex systems.","main_category":"cs.CY","categories":"cs.CY,cs.DC","published":"2025-04-03T11:36:12Z"}
{"aid":"http://arxiv.org/abs/2504.02511v1","title":"Analytical Discovery of Manifold with Machine Learning","summary":"Understanding low-dimensional structures within high-dimensional data is\ncrucial for visualization, interpretation, and denoising in complex datasets.\nDespite the advancements in manifold learning techniques, key challenges-such\nas limited global insight and the lack of interpretable analytical\ndescriptions-remain unresolved. In this work, we introduce a novel framework,\nGAMLA (Global Analytical Manifold Learning using Auto-encoding). GAMLA employs\na two-round training process within an auto-encoding framework to derive both\ncharacter and complementary representations for the underlying manifold. With\nthe character representation, the manifold is represented by a parametric\nfunction which unfold the manifold to provide a global coordinate. While with\nthe complementary representation, an approximate explicit manifold description\nis developed, offering a global and analytical representation of smooth\nmanifolds underlying high-dimensional datasets. This enables the analytical\nderivation of geometric properties such as curvature and normal vectors.\nMoreover, we find the two representations together decompose the whole latent\nspace and can thus characterize the local spatial structure surrounding the\nmanifold, proving particularly effective in anomaly detection and\ncategorization. Through extensive experiments on benchmark datasets and\nreal-world applications, GAMLA demonstrates its ability to achieve\ncomputational efficiency and interpretability while providing precise geometric\nand structural insights. This framework bridges the gap between data-driven\nmanifold learning and analytical geometry, presenting a versatile tool for\nexploring the intrinsic properties of complex data sets.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-03T11:53:00Z"}
{"aid":"http://arxiv.org/abs/2504.02519v1","title":"Data-Driven Object Tracking: Integrating Modular Neural Networks into a\n  Kalman Framework","summary":"This paper presents novel Machine Learning (ML) methodologies for\nMulti-Object Tracking (MOT), specifically designed to meet the increasing\ncomplexity and precision demands of Advanced Driver Assistance Systems (ADAS).\nWe introduce three Neural Network (NN) models that address key challenges in\nMOT: (i) the Single-Prediction Network (SPENT) for trajectory prediction, (ii)\nthe Single-Association Network (SANT) for mapping individual Sensor Object (SO)\nto existing tracks, and (iii) the Multi-Association Network (MANTa) for\nassociating multiple SOs to multiple tracks. These models are seamlessly\nintegrated into a traditional Kalman Filter (KF) framework, maintaining the\nsystem's modularity by replacing relevant components without disrupting the\noverall architecture. Importantly, all three networks are designed to be run in\na realtime, embedded environment. Each network contains less than 50k trainable\nparameters. Our evaluation, conducted on the public KITTI tracking dataset,\ndemonstrates significant improvements in tracking performance. SPENT reduces\nthe Root Mean Square Error (RMSE) by 50% compared to a standard KF, while SANT\nand MANTa achieve up to 95% accuracy in sensor object-to-track assignments.\nThese results underscore the effectiveness of incorporating task-specific NNs\ninto traditional tracking systems, boosting performance and robustness while\npreserving modularity, maintainability, and interpretability.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-03T12:13:38Z"}
{"aid":"http://arxiv.org/abs/2504.02540v1","title":"A 3D-1D-0D Multiscale Model of the Neuro-Glial-Vascular Unit for\n  Synaptic and Vascular Dynamics in the Dorsal Vagal Complex","summary":"Cerebral blood flow regulation is critical for brain function, and its\ndisruption is implicated in various neurological disorders. Many existing\nmodels do not fully capture the complex, multiscale interactions among neuronal\nactivity, astrocytic signaling, and vascular dynamics--especially in key\nbrainstem regions. In this work, we present a 3D-1D-0D multiscale computational\nframework for modeling the neuro-glial-vascular unit (NGVU) in the dorsal vagal\ncomplex (DVC). Our approach integrates a quadripartite synapse model--which\nrepresents the interplay among excitatory and inhibitory neurons, astrocytes,\nand vascular smooth muscle cells--with a hierarchical description of vascular\ndynamics that couples a three-dimensional microcirculatory network with a\none-dimensional macrocirculatory representation and a zero-dimensional synaptic\ncomponent. By linking neuronal spiking, astrocytic calcium and gliotransmitter\nsignaling, and vascular tone regulation, our model reproduces key features of\nfunctional hyperemia and elucidates the feedback loops that help maintain\ncerebral blood flow. Simulation results demonstrate that neurotransmitter\nrelease triggers astrocytic responses that modulate vessel radius to optimize\noxygen and nutrient delivery. This integrated framework, to our knowledge the\nfirst model to combine these elements for the NGVU in the DVC, provides a\nrobust and modular platform for future investigations into the pathophysiology\nof cerebral blood flow regulation and its role in autonomic control, including\nthe regulation of stomach function.","main_category":"q-bio.TO","categories":"q-bio.TO","published":"2025-04-03T12:42:18Z"}
{"aid":"http://arxiv.org/abs/2504.02568v1","title":"Enhanced coherent terahertz emission from critical superconducting\n  fluctuations in YBa$_2$Cu$_3$O$_{6.6}$","summary":"Coherent terahertz (THz) emission is emerging as a powerful new tool to probe\nsymmetry breakings in quantum materials. This method relies on second order\noptical nonlinearities and is complementary to second harmonic generation\nspectroscopy. Here, we report coherent THz emission from Josephson plasmons in\nunderdoped YBa$_2$Cu$_3$O$_{6+x}$, and find that the amplitude of the emitted\nfield increases dramatically close to the superconducting transition\ntemperature, $T_C$. We show theoretically how emission is enhanced by critical\nsuperconducting fluctuations, a nonlinear analogue of critical opalescence.\nThis observation is expected to be of general importance for the study of many\nthermal and quantum phase transitions.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.str-el","published":"2025-04-03T13:31:46Z"}
{"aid":"http://arxiv.org/abs/2504.02582v1","title":"Ambiguity Function Analysis of Affine Frequency Division Multiplexing\n  for Integrated Sensing and Communication","summary":"Affine frequency division multiplexing (AFDM) is a chirp-based multicarrier\nwaveform that was recently proposed for communication over doubly dispersive\nchannels. Given its chirp nature, AFDM is expected to have superior sensing\ncapabilities compared to orthogonal frequency division multiplexing (OFDM) and\nis thus a promising candidate for integrated sensing and communication (ISAC)\napplications. In this paper, we derive a closed-form expression for the\nambiguity function of AFDM waveforms modulated with $M$-ary quadrature\namplitude modulation (QAM) data symbols. We determine the condition on the\nchirp rate of the AFDM waveform that minimizes the sidelobes in the delay/range\ndomain in the presence of random $M$-ary QAM symbols, thereby improving overall\nsensing performance. Additionally, we find an approximate statistical\ndistribution for the magnitude of the derived ambiguity function. Simulation\nresults are presented to evaluate the sensing performance of the AFDM waveform\nfor various system parameters and to compare its peak-to-sidelobe ratio (PSLR)\nand integrated sidelobe ratio (ISLR) with those of OFDM.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-03T13:46:42Z"}
{"aid":"http://arxiv.org/abs/2504.02598v1","title":"Graphs are everywhere -- Psst! In Music Recommendation too","summary":"In recent years, graphs have gained prominence across various domains,\nespecially in recommendation systems. Within the realm of music recommendation,\ngraphs play a crucial role in enhancing genre-based recommendations by\nintegrating Mel-Frequency Cepstral Coefficients (MFCC) with advanced graph\nembeddings. This study explores the efficacy of Graph Convolutional Networks\n(GCN), GraphSAGE, and Graph Transformer (GT) models in learning embeddings that\neffectively capture intricate relationships between music items and genres\nrepresented within graph structures. Through comprehensive empirical\nevaluations on diverse real-world music datasets, our findings consistently\ndemonstrate that these graph-based approaches outperform traditional methods\nthat rely solely on MFCC features or collaborative filtering techniques.\nSpecifically, the graph-enhanced models achieve notably higher accuracy in\npredicting genre-specific preferences and offering relevant music suggestions\nto users. These results underscore the effectiveness of utilizing graph\nembeddings to enrich feature representations and exploit latent associations\nwithin music data, thereby illustrating their potential to advance the\ncapabilities of personalized and context-aware music recommendation systems.\nKeywords: graphs, recommendation systems, neural networks, MFCC","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-03T14:00:52Z"}
{"aid":"http://arxiv.org/abs/2504.02602v1","title":"Leveraging Sparse Annotations for Leukemia Diagnosis on the Large\n  Leukemia Dataset","summary":"Leukemia is 10th most frequently diagnosed cancer and one of the leading\ncauses of cancer related deaths worldwide. Realistic analysis of Leukemia\nrequires White Blook Cells (WBC) localization, classification, and\nmorphological assessment. Despite deep learning advances in medical imaging,\nleukemia analysis lacks a large, diverse multi-task dataset, while existing\nsmall datasets lack domain diversity, limiting real world applicability. To\novercome dataset challenges, we present a large scale WBC dataset named Large\nLeukemia Dataset (LLD) and novel methods for detecting WBC with their\nattributes. Our contribution here is threefold. First, we present a large-scale\nLeukemia dataset collected through Peripheral Blood Films (PBF) from several\npatients, through multiple microscopes, multi cameras, and multi magnification.\nTo enhance diagnosis explainability and medical expert acceptance, each\nleukemia cell is annotated at 100x with 7 morphological attributes, ranging\nfrom Cell Size to Nuclear Shape. Secondly, we propose a multi task model that\nnot only detects WBCs but also predicts their attributes, providing an\ninterpretable and clinically meaningful solution. Third, we propose a method\nfor WBC detection with attribute analysis using sparse annotations. This\napproach reduces the annotation burden on hematologists, requiring them to mark\nonly a small area within the field of view. Our method enables the model to\nleverage the entire field of view rather than just the annotated regions,\nenhancing learning efficiency and diagnostic accuracy. From diagnosis\nexplainability to overcoming domain shift challenges, presented datasets could\nbe used for many challenging aspects of microscopic image analysis. The\ndatasets, code, and demo are available at:\nhttps://im.itu.edu.pk/sparse-leukemiaattri/","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T14:04:02Z"}
{"aid":"http://arxiv.org/abs/2504.02608v1","title":"Input to the European Strategy for Particle Physics: Strong-Field\n  Quantum Electrodynamics","summary":"This document sets out the intention of the strong-field QED community to\ncarry out, both experimentally and numerically, high-statistics parametric\nstudies of quantum electrodynamics in the non-perturbative regime, at fields\napproaching and exceeding the critical or `Schwinger' field of QED. In this\nregime, several exotic and fascinating phenomena are predicted to occur that\nhave never been directly observed in the laboratory. These include\nBreit-Wheeler pair production, vacuum birefringence, and quantum radiation\nreaction. This experimental program will also serve as a stepping stone towards\nstudies of elusive phenomena such as elastic scattering of real photons and the\nconjectured perturbative breakdown of QED at extreme fields. State-of-the-art\nhigh-power laser facilities in Europe and beyond are starting to offer unique\nopportunities to study this uncharted regime at the intensity frontier, which\nis highly relevant also for the design of future multi-TeV lepton colliders.\nHowever, a transition from qualitative observational experiments to\nquantitative and high-statistics measurements can only be performed with\nlarge-scale collaborations and with systematic experimental programs devoted to\nthe optimisation of several aspects of these complex experiments, including\ndetector developments, stability and tolerances studies, and laser technology.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-03T14:10:23Z"}
{"aid":"http://arxiv.org/abs/2504.02610v1","title":"Do evidence-based active-engagement courses reduce the gender gap in\n  introductory physics?","summary":"Prior research suggests that using evidence-based pedagogies can not only\nimprove learning for all students, it can also reduce the gender gap. We\ndescribe the impact of physics education research based pedagogical techniques\nin flipped and active-engagement non-flipped courses on the gender gap observed\nwith validated conceptual surveys. We compare male and female students'\nperformance in courses which make significant use of evidence-based active\nengagement (EBAE) strategies with courses that primarily use lecture-based (LB)\ninstruction. The analysis presented here includes data from two-semester\nsequences of introductory algebra-based and calculus-based introductory physics\ncourses. The surveys used to assess student learning in the first and second\nsemester courses were the Force Concept Inventory and the Conceptual Survey of\nElectricity and Magnetism, respectively. The performance of male and female\nstudents in EBAE courses at a particular level is compared with LB courses in\ntwo situations: (I) the same instructor taught two courses, one of which was an\nEBAE course and the other an LB course, while the homework, recitations and\nfinal exams were kept the same, (II) student performance in all of the EBAE\ncourses taught by different instructors was averaged and compared with LB\ncourses of the same type also averaged over different instructors. In all\ncases, we find that students in courses which make significant use of EBAE\nstrategies, on average, outperformed students in courses of the same type using\nprimarily LB instruction even though there was no statistically significant\ndifference on the pretest before instruction. However, the gender gap persisted\neven in courses using EBAE methods. We also discuss correlations between the\nperformance of male and female students on the validated conceptual surveys and\nthe final exam, which had a heavy weight on quantitative problem solving.","main_category":"physics.ed-ph","categories":"physics.ed-ph","published":"2025-04-03T14:11:00Z"}
{"aid":"http://arxiv.org/abs/2504.02633v1","title":"Data-Driven Design of 3GPP Handover Parameters with Bayesian\n  Optimization and Transfer Learning","summary":"Mobility management in dense cellular networks is challenging due to varying\nuser speeds and deployment conditions. Traditional 3GPP handover (HO) schemes,\nrelying on fixed A3-offset and time-to-trigger (TTT) parameters, struggle to\nbalance radio link failures (RLFs) and ping-pongs. We propose a data-driven HO\noptimization framework based on high-dimensional Bayesian optimization (HD-BO)\nand enhanced with transfer learning to reduce training time and improve\ngeneralization across different user speeds. Evaluations on a real-world\ndeployment show that HD-BO outperforms 3GPP set-1 and set-5 benchmarks, while\ntransfer learning enables rapid adaptation without loss in performance. This\nhighlights the potential of data-driven, site-specific mobility management in\nlarge-scale networks.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-03T14:31:20Z"}
{"aid":"http://arxiv.org/abs/2504.02639v1","title":"Reservoir Computing: A New Paradigm for Neural Networks","summary":"A Literature Review of Reservoir Computing.\n  Even before Artificial Intelligence was its own field of computational\nscience, humanity has tried to mimic the activity of the human brain. In the\nearly 1940s the first artificial neuron models were created as purely\nmathematical concepts. Over the years, ideas from neuroscience and computer\nscience were used to develop the modern Neural Network. The interest in these\nmodels rose quickly but fell when they failed to be successfully applied to\npractical applications, and rose again in the late 2000s with the drastic\nincrease in computing power, notably in the field of natural language\nprocessing, for example with the state-of-the-art speech recognizer making\nheavy use of deep neural networks.\n  Recurrent Neural Networks (RNNs), a class of neural networks with cycles in\nthe network, exacerbates the difficulties of traditional neural nets. Slow\nconvergence limiting the use to small networks, and difficulty to train through\ngradient-descent methods because of the recurrent dynamics have hindered\nresearch on RNNs, yet their biological plausibility and their capability to\nmodel dynamical systems over simple functions makes then interesting for\ncomputational researchers.\n  Reservoir Computing emerges as a solution to these problems that RNNs\ntraditionally face. Promising to be both theoretically sound and\ncomputationally fast, Reservoir Computing has already been applied successfully\nto numerous fields: natural language processing, computational biology and\nneuroscience, robotics, even physics. This survey will explore the history and\nappeal of both traditional feed-forward and recurrent neural networks, before\ndescribing the theory and models of this new reservoir computing paradigm.\nFinally recent papers using reservoir computing in a variety of scientific\nfields will be reviewed.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T14:34:51Z"}
{"aid":"http://arxiv.org/abs/2504.02646v1","title":"Prompt Optimization with Logged Bandit Data","summary":"We study how to use naturally available user feedback, such as clicks, to\noptimize large language model (LLM) pipelines for generating personalized\nsentences using prompts. Naive approaches, which estimate the policy gradient\nin the prompt space, suffer either from variance caused by the large action\nspace of prompts or bias caused by inaccurate reward predictions. To circumvent\nthese challenges, we propose a novel kernel-based off-policy gradient method,\nwhich estimates the policy gradient by leveraging similarity among generated\nsentences, substantially reducing variance while suppressing the bias.\nEmpirical results on our newly established suite of benchmarks demonstrate the\neffectiveness of the proposed approach in generating personalized descriptions\nfor movie recommendations, particularly when the number of candidate prompts is\nlarge.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.IR,stat.ML","published":"2025-04-03T14:40:40Z"}
{"aid":"http://arxiv.org/abs/2504.02681v1","title":"Convergence of permuted products of exponentials","summary":"Let $\\{A_{i,n}\\}$ be a triangular array of elements in a Banach algebra,\nwhose norms do not grow too fast, and whose row averages converge to $A$. Let\n$\\sigma \\in S(n)$ be a permutation drawn uniformly at random. If the array only\ncontains $o(n / \\log n)$ distinct elements, then almost surely, for all $0 < s\n< t < 1$, the permuted product of their exponentials $\\prod_{i = [s n]}^{[t n]}\ne^{A_{\\sigma(i),n}/n}$ converges in norm to $e^{(t - s) A}$. For an array of\nfinite-dimensional matrices, convergence holds without this restriction. The\nproof of the latter result consists of an estimate valid in a general Banach\nalgebra, and an application of a matrix concentration inequality.","main_category":"math.FA","categories":"math.FA,math.PR","published":"2025-04-03T15:15:52Z"}
{"aid":"http://arxiv.org/abs/2504.02684v1","title":"High Chern numbers and topological flat bands in high-field polarized\n  Kitaev magnets on the star lattice","summary":"The geometrically frustrated Kitaev magnets are demonstrated to be fertile\nplaygrounds that allow for the occurrence of exotic phenomena, including\ntopological phases and the thermal Hall effect. Notwithstanding the established\nconsensus that the field-polarized phase in the honeycomb-lattice Kitaev magnet\nhosts topological magnons exhibiting Chern numbers $C = \\pm1$, the nature of\nmagnon excitations in Kitaev magnets on the star lattice, a triangle-decorated\nhoneycomb lattice, has rarely been explored primarily due to its complicated\ngeometry. To this end, we study the band topology of magnons on the star\nlattice in the presence of a strong out-of-plane magnetic field using linear\nspin-wave theory. By calculating the Chern numbers of magnon bands, we find\nthat topological phase diagrams are predominantly composed of two distinct\ntopological phases whose Chern numbers are different by a sign in inverse\norder. Remarkably, each phase is characterized by a high Chern number of either\n$+2$ or $-2$. In addition, several topological flat bands with large flatness\nare identified. The two phases are separated by a dozen narrow topological\nhigh-Chern-number segments, whose region shrinks as the magnetic field\nincreases and vanishes eventually. We also find that the thermal Hall\nconductivity approaches zero at certain parameters, and it changes (keeps) its\nsign when crossing the topological phase-transition points (flat-band points).","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci","published":"2025-04-03T15:25:11Z"}
{"aid":"http://arxiv.org/abs/2504.02722v1","title":"Dynamic Directional Routing of Freight in the Physical Internet","summary":"The Physical Internet (PI) envisions an interconnected, modular, and\ndynamically managed logistics system inspired by the Digital Internet. It\nenables open-access networks where shipments traverse a hyperconnected system\nof hubs, adjusting routes based on real-time conditions. A key challenge in\nscalable and adaptive freight movement is routing determining how shipments\nnavigate the network to balance service levels, consolidation, and\nadaptability. This paper introduces directional routing, a dynamic approach\nthat flexibly adjusts shipment paths, optimizing efficiency and consolidation\nusing real-time logistics data. Unlike shortest-path routing, which follows\nfixed routes, directional routing dynamically selects feasible next-hop hubs\nbased on network conditions, consolidation opportunities, and service level\nconstraints. It consists of two phases: area discovery, which identifies\ncandidate hubs, and node selection, which determines the next hub based on\nreal-time parameters. This paper advances the area discovery phase by\nintroducing a Reduced Search Space Breadth-First Search (RSS-BFS) method to\nsystematically identify feasible routing areas while balancing service levels\nand consolidation. The proposed approach enhances network fluidity,\nscalability, and adaptability in PI-based logistics, advancing autonomous and\nsustainable freight movement.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-03T16:05:03Z"}
{"aid":"http://arxiv.org/abs/2504.02741v1","title":"A Complete Classification of Fourier Summation Formulas on the real line","summary":"We completely classify Fourier summation formulas of the form $$\n  \\int_{\\mathbb{R}} \\widehat{\\varphi}(t) d\\mu(t)=\\sum_{n=0}^{\\infty}\na(\\lambda_n)\\varphi(\\lambda_n), $$ that hold for any test function $\\varphi$,\nwhere $\\widehat\\varphi$ is the Fourier transform of $\\varphi$, $\\mu$ is a fixed\ncomplex measure on $\\mathbb{R}$ and $a:\\{\\lambda_n\\}_{n\\geq 0}\\to\\mathbb{C}$ is\na fixed function. We only assume the decay condition $$ \\int_{\\mathbb{R}}\n\\frac{d |\\mu|(t)}{(1+t^2)^{c_1}} + \\sum_{n\\geq 0} |a(\\lambda_n)|e^{-c_2\n|\\lambda_n|}<\\infty, $$ for some $c_1,c_2>0$. This completes the work initiated\nby the first author previously, where the condition $c_1\\leq 1$ was required.\nWe prove that any such pair $(\\mu,a)$ can be uniquely associated with a\nholomorphic map $F(z)$ in the upper-half space that is both almost periodic and\nbelongs to a certain higher index Nevanlinna class. The converse is also true:\nFor any such function $F$ it is possible to generate a Fourier summation pair\n$(\\mu,a)$. We provide important examples of such summation formulas not\ncontemplated by the previous results, such as Selberg's trace formula.","main_category":"math.CA","categories":"math.CA,math.MG,math.NT","published":"2025-04-03T16:28:18Z"}
{"aid":"http://arxiv.org/abs/2504.02747v1","title":"GEOPARD: Geometric Pretraining for Articulation Prediction in 3D Shapes","summary":"We present GEOPARD, a transformer-based architecture for predicting\narticulation from a single static snapshot of a 3D shape. The key idea of our\nmethod is a pretraining strategy that allows our transformer to learn plausible\ncandidate articulations for 3D shapes based on a geometric-driven search\nwithout manual articulation annotation. The search automatically discovers\nphysically valid part motions that do not cause detachments or collisions with\nother shape parts. Our experiments indicate that this geometric pretraining\nstrategy, along with carefully designed choices in our transformer\narchitecture, yields state-of-the-art results in articulation inference in the\nPartNet-Mobility dataset.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-03T16:35:17Z"}
{"aid":"http://arxiv.org/abs/2504.02753v1","title":"Robust entangled photon generation by Floquet-engineered two-colour\n  pulses","summary":"Quantum emitters driven by resonant two-photon excitation are a leading\nsource for deterministically generated entangled photon pairs, essential for\nscalable photonic quantum technologies. However, conventional resonant schemes\nare highly sensitive to laser power fluctuations and pose additional\nexperimental challenges for emitters with small biexciton binding energies.\nHere, we demonstrate how biexciton preparation schemes with significantly\nimproved robustness and reduced laser filtering requirements can be identified\nusing a novel design principle beyond resonant and adiabatic driving: ultrafast\nall-optical Floquet engineering. This is achieved by employing two strongly and\nsymmetrically detuned dichromatic pulses, whose superposition generates a\nstroboscopic Hamiltonian that enables direct coupling between ground and\nbiexciton states. Moreover, a pulse delay serves as a tuning knob, introducing\nan effective magnetic field that concentrates the Bloch sphere trajectory at\nthe biexciton state for a wide range of parameters, making biexciton\npreparation particularly robust. Experimentally, we achieve a biexciton\noccupation exceeding 96% and preserve photon-pair entanglement with a fidelity\nof 93.4%. Our scheme highlights the great impact of Floquet-engineered\nmulticolour excitation protocols for on-demand quantum light sources.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-03T16:45:33Z"}
{"aid":"http://arxiv.org/abs/2504.02757v1","title":"Echoes of the hidden: Uncovering coordination beyond network structure","summary":"The study of connectivity and coordination has drawn increasing attention in\nrecent decades due to their central role in driving markets, shaping societal\ndynamics, and influencing biological systems. Traditionally, observable\nconnections, such as phone calls, financial transactions, or social media\nconnections, have been used to infer coordination and connectivity. However,\nincomplete, encrypted, or fragmented data, alongside the ubiquity of\ncommunication platforms and deliberate obfuscation, often leave many real-world\nconnections hidden. In this study, we demonstrate that coordinating individuals\nexhibit shared bursty activity patterns, enabling their detection even when\nobservable links between them are sparse or entirely absent. We further propose\na generative model based on the network of networks formalism to account for\nthe mechanisms driving this collaborative burstiness, attributing it to shock\npropagation across networks rather than isolated individual behavior. Model\nsimulations demonstrate that when observable connection density is below 70\\%,\nburstiness significantly improves coordination detection compared to\nstate-of-the-art temporal and structural methods. This work provides a new\nperspective on community and coordination dynamics, advancing both theoretical\nunderstanding and practical detection. By laying the foundation for identifying\nhidden connections beyond observable network structures, it enables detection\nacross different platforms, alongside enhancing system behavior understanding,\ninformed decision-making, and risk mitigation.","main_category":"cs.SI","categories":"cs.SI","published":"2025-04-03T16:49:58Z"}
{"aid":"http://arxiv.org/abs/2504.02785v1","title":"Beating full state tomography for unentangled spectrum estimation","summary":"How many copies of a mixed state $\\rho \\in \\mathbb{C}^{d \\times d}$ are\nneeded to learn its spectrum? To date, the best known algorithms for spectrum\nestimation require as many copies as full state tomography, suggesting the\npossibility that learning a state's spectrum might be as difficult as learning\nthe entire state. We show that this is not the case in the setting of\nunentangled measurements, by giving a spectrum estimation algorithm that uses\n$n = O(d^3\\cdot (\\log\\log(d) / \\log(d))^4 )$ copies of $\\rho$, which is\nasymptotically fewer than the $n = \\Omega(d^3)$ copies necessary for full state\ntomography. Our algorithm is inspired by the technique of local moment matching\nfrom classical statistics, and shows how it can be applied in the quantum\nsetting.\n  As an important subroutine in our spectrum estimation algorithm, we give an\nestimator of the $k$-th moment $\\operatorname{tr}(\\rho^k)$ which performs\nunentangled measurements and uses $O(d^{3-2/k})$ copies of $\\rho$ in order to\nachieve a constant multiplicative error. This directly translates to an\nadditive-error estimator of quantum Renyi entropy of order $k$ with the same\nnumber of copies.\n  Finally, we present numerical evidence that the sample complexity of spectrum\nestimation can only improve over full state tomography by a sub-polynomial\nfactor. Specifically, for spectrum learning with fully entangled measurements,\nwe run simulations which suggest a lower bound of $\\Omega(d^{2 - \\gamma})$\ncopies for any constant $\\gamma > 0$. From this, we conclude the current best\nlower bound of $\\Omega(d)$ is likely not tight.","main_category":"quant-ph","categories":"quant-ph,cs.CC,cs.DS","published":"2025-04-03T17:29:12Z"}
{"aid":"http://arxiv.org/abs/2504.02798v1","title":"North+Lone Star Supernova Host Survey I: Local Host-Galaxy H$α$\n  Surface Brightness and the Hubble Residuals of Type Ia Supernovae","summary":"We present optical integral-field unit (IFU) spectroscopy acquired with the\nGeorge and Cynthia Mitchell Spectrograph on the Harlan J. Smith telescope at\nMcDonald Observatory of 94 galaxies (0.01 < z < 0.058) that have hosted Type Ia\nsupernovae (SNe Ia). We selected host galaxies with star-forming morphology,\nconsistent with the criteria used by Riess et al. (2022). We measured the\nH${\\alpha}$ surface brightness of each host galaxy within 1 kpc of the location\nof the supernova. Using distances from the Pantheon+ sample, we find a step in\nHubble residuals compared to local H${\\alpha}$ surface brightness of -0.097\n$\\pm$ 0.051 mag at 1.9${\\sigma}$ significance in a sample of 73 host galaxies,\nwhere SNe in environments with smaller H${\\alpha}$ surface brightness are, on\naverage, less luminous after correction for light-curve shape and color. Almost\nall of the SNe in our sample were discovered by targeted surveys. Using an\nindependent sample primarily from the untargeted Nearby Supernova Factory\nsurvey, Rigault et al. (2020) found a step of 0.045 $\\pm$ 0.029 mag where SNe\nin passive environments are instead brighter, which is in 2.4${\\sigma}$ tension\nwith our measurement. Rigault et al. (2013) designated SNe Ia comparatively\nsmall HRs (< -0.1) and faint local H${\\alpha}$ surface brightness (SB)\n(<log10(H${\\alpha}$ SB/(erg$^{-1}$s$^{-1}$kpc$^2$))=38.32 as the M$_2$\npopulation. SNe that would be classified as M$_2$ are less highly represented\nin our sample (7% versus 21%). When we include an additional twelve early-type\ngalaxies, the number of M$_2$ SNe is almost doubled, although the tension with\nthe HR step measured by Rigault et al. (2020) persists at 1.7${\\sigma}$.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-03T17:42:16Z"}
{"aid":"http://arxiv.org/abs/2504.02803v1","title":"Beyond Discretization: A Continuous-Time Framework for Event Generation\n  in Neuromorphic Pixels","summary":"A novel continuous-time framework is proposed for modeling neuromorphic image\nsensors in the form of an initial canonical representation with analytical\ntractability. Exact simulation algorithms are developed in parallel with\nclosed-form expressions that characterize the model's dynamics. This framework\nenables the generation of synthetic event streams in genuine continuous-time,\nwhich combined with the analytical results, reveal the underlying mechanisms\ndriving the oscillatory behavior of event data presented in the literature.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-03T17:47:41Z"}
{"aid":"http://arxiv.org/abs/2504.04774v1","title":"BayesCPF: Enabling Collective Perception in Robot Swarms with Degrading\n  Sensors","summary":"The collective perception problem -- where a group of robots perceives its\nsurroundings and comes to a consensus on an environmental state -- is a\nfundamental problem in swarm robotics. Past works studying collective\nperception use either an entire robot swarm with perfect sensing or a swarm\nwith only a handful of malfunctioning members. A related study proposed an\nalgorithm that does account for an entire swarm of unreliable robots but\nassumes that the sensor faults are known and remain constant over time. To that\nend, we build on that study by proposing the Bayes Collective Perception Filter\n(BayesCPF) that enables robots with continuously degrading sensors to\naccurately estimate the fill ratio -- the rate at which an environmental\nfeature occurs. Our main contribution is the Extended Kalman Filter within the\nBayesCPF, which helps swarm robots calibrate for their time-varying sensor\ndegradation. We validate our method across different degradation models,\ninitial conditions, and environments in simulated and physical experiments. Our\nfindings show that, regardless of degradation model assumptions, fill ratio\nestimation using the BayesCPF is competitive to the case if the true sensor\naccuracy is known, especially when assumptions regarding the model and initial\nsensor accuracy levels are preserved.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T07:06:11Z"}
{"aid":"http://arxiv.org/abs/2504.04798v1","title":"TabRep: Training Tabular Diffusion Models with a Simple and Effective\n  Continuous Representation","summary":"Diffusion models have been the predominant generative model for tabular data\ngeneration. However, they face the conundrum of modeling under a separate\nversus a unified data representation. The former encounters the challenge of\njointly modeling all multi-modal distributions of tabular data in one model.\nWhile the latter alleviates this by learning a single representation for all\nfeatures, it currently leverages sparse suboptimal encoding heuristics and\nnecessitates additional computation costs. In this work, we address the latter\nby presenting TabRep, a tabular diffusion architecture trained with a unified\ncontinuous representation. To motivate the design of our representation, we\nprovide geometric insights into how the data manifold affects diffusion models.\nThe key attributes of our representation are composed of its density,\nflexibility to provide ample separability for nominal features, and ability to\npreserve intrinsic relationships. Ultimately, TabRep provides a simple yet\neffective approach for training tabular diffusion models under a continuous\ndata manifold. Our results showcase that TabRep achieves superior performance\nacross a broad suite of evaluations. It is the first to synthesize tabular data\nthat exceeds the downstream quality of the original datasets while preserving\nprivacy and remaining computationally efficient.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-07T07:44:27Z"}
{"aid":"http://arxiv.org/abs/2504.04820v1","title":"Dark energy under a gauge symmetry: A review of gauged quintessence and\n  its implications","summary":"We review the gauged quintessence scenario, wherein the quintessence scalar\nfield responsible for dark energy is promoted to a complex field charged under\na dark $U(1)$ gauge symmetry. This construction leads to new and potentially\nrich cosmological phenomenology. After a concise recap of the standard\nquintessence scenario, we highlight how a $U(1)$ gauge invariance alters the\ndynamics of the scalar and the associated dark gauge boson. We survey the\nevolution of both fields across cosmic history, discuss their possible\nproduction via a misalignment mechanism, and examine implications for the\nHubble tension. We also comment on potential non-gravitational signals of\ngauged quintessence through kinetic mixing (the dark photon vector portal).","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO","published":"2025-04-07T08:21:33Z"}
{"aid":"http://arxiv.org/abs/2504.04822v1","title":"How to build transfer matrices, one wave at a time","summary":"We show how to build the closed-form expression of transfer matrices for wave\npropagation in layered media. The key is to represent the propagation across\nthe piece-wise constant medium as a superposition of a finite number of paths\n($2^{N-1}$ paths for a medium with $N$ layers), each one of them contributing a\ncertain phase change (corresponding to signed sums of the phase change in each\nindividual layer) and amplitude change (corresponding to the pattern of\ntransmission and/or reflection associated to each path). The outlined technique\nis combinatorial in nature: it begins with the linear governing equations in\nfrequency domain, whose fundamental solution is known, then it enumerates the\nfinite number of paths across the overall system, then computes their\nassociated phase and amplitude change, and finally adds all the possible paths\nto find the final result. Beyond providing physical insight, this\n``path-by-path'' construction can also circumvent the need for transfer matrix\nnumerical multiplication in many practical applications, potentially enabling\nsubstantial computational savings.","main_category":"physics.geo-ph","categories":"physics.geo-ph,cond-mat.other","published":"2025-04-07T08:22:38Z"}
{"aid":"http://arxiv.org/abs/2504.04823v1","title":"Quantization Hurts Reasoning? An Empirical Study on Quantized Reasoning\n  Models","summary":"Recent advancements in reasoning language models have demonstrated remarkable\nperformance in complex tasks, but their extended chain-of-thought reasoning\nprocess increases inference overhead. While quantization has been widely\nadopted to reduce the inference cost of large language models, its impact on\nreasoning models remains understudied. In this study, we conduct the first\nsystematic study on quantized reasoning models, evaluating the open-sourced\nDeepSeek-R1-Distilled Qwen and LLaMA families ranging from 1.5B to 70B\nparameters, and QwQ-32B. Our investigation covers weight, KV cache, and\nactivation quantization using state-of-the-art algorithms at varying\nbit-widths, with extensive evaluation across mathematical (AIME, MATH-500),\nscientific (GPQA), and programming (LiveCodeBench) reasoning benchmarks. Our\nfindings reveal that while lossless quantization can be achieved with W8A8 or\nW4A16 quantization, lower bit-widths introduce significant accuracy risks. We\nfurther identify model size, model origin, and task difficulty as critical\ndeterminants of performance. Contrary to expectations, quantized models do not\nexhibit increased output lengths. In addition, strategically scaling the model\nsizes or reasoning steps can effectively enhance the performance. All quantized\nmodels and codes will be open-sourced in\nhttps://github.com/ruikangliu/Quantized-Reasoning-Models.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-07T08:22:45Z"}
{"aid":"http://arxiv.org/abs/2504.04827v1","title":"From Specificity to Generality: Revisiting Generalizable Artifacts in\n  Detecting Face Deepfakes","summary":"Detecting deepfakes has been an increasingly important topic, especially\ngiven the rapid development of AI generation techniques. In this paper, we ask:\nHow can we build a universal detection framework that is effective for most\nfacial deepfakes? One significant challenge is the wide variety of deepfake\ngenerators available, resulting in varying forgery artifacts (e.g., lighting\ninconsistency, color mismatch, etc). But should we ``teach\" the detector to\nlearn all these artifacts separately? It is impossible and impractical to\nelaborate on them all. So the core idea is to pinpoint the more common and\ngeneral artifacts across different deepfakes. Accordingly, we categorize\ndeepfake artifacts into two distinct yet complementary types: Face\nInconsistency Artifacts (FIA) and Up-Sampling Artifacts (USA). FIA arise from\nthe challenge of generating all intricate details, inevitably causing\ninconsistencies between the complex facial features and relatively uniform\nsurrounding areas. USA, on the other hand, are the inevitable traces left by\nthe generator's decoder during the up-sampling process. This categorization\nstems from the observation that all existing deepfakes typically exhibit one or\nboth of these artifacts. To achieve this, we propose a new data-level\npseudo-fake creation framework that constructs fake samples with only the FIA\nand USA, without introducing extra less-general artifacts. Specifically, we\nemploy a super-resolution to simulate the USA, while design a Blender module\nthat uses image-level self-blending on diverse facial regions to create the\nFIA. We surprisingly found that, with this intuitive design, a standard image\nclassifier trained only with our pseudo-fake data can non-trivially generalize\nwell to unseen deepfakes.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T08:34:28Z"}
{"aid":"http://arxiv.org/abs/2504.04830v1","title":"X-ray particle tracking velocimetry for rheological characterization:\n  Application to material extrusion additive manufacturing","summary":"We introduce X-ray Particle Tracking Velocimetry (XPTV) as a promising method\nto quantitatively resolve the velocity field and associated rheological\nquantities of polymer melt flow within the nozzle of a fused filament\nfabrication (FFF) printer. Employing tungsten powder as tracer particles\nembedded within a polymer filament, we investigate melt flow dynamics through\nan aluminum nozzle in a custom-designed experimental setup, based on commercial\ndesigns. The velocity profiles obtained via XPTV reveal significant deviations\nfrom classical Newtonian flow, highlighting complex heterogeneous and\nnon-isothermal behavior within the melt. From these measurements, we determine\nthe local infinitesimal strain rate tensor and correlate flow-induced\nnon-Newtonian effects to spatially varying temperature distributions,\nreflecting incomplete thermal homogenization within the nozzle. Our findings\ndemonstrate the capability of XPTV to quantify both velocity fields and\nrheological properties, underscoring its potential as a future tool for\ninvestigating opaque polymer melt flows in additive manufacturing, industrial\nprocessing, and rheology. To our knowledge, this represents the first reported\napplication of XPTV in polymer melt rheology, offering a new approach to\naddress measurement challenges previously inaccessible to conventional optical\nmethods.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.flu-dyn","published":"2025-04-07T08:40:40Z"}
{"aid":"http://arxiv.org/abs/2504.04838v1","title":"Palatable pellets -- a fundamental framework to produce sustainable\n  pellets via extrusion","summary":"In pellet manufacturing various ingredients in powder or particle form are\npressed together into a dense product, a pellet, with better nutritional,\ncalorific, and handling properties than the individual input ingredients\nthemselves. For this reason, pellet manufacturing is applied to up-convert\nindustrial co-products from various sectors like agriculture, forestry, human\nfood, or bio-energy production, to valorize their waste-streams into more\nvaluable products. However, processing such diverse ingredient streams presents\nan industrial challenge and raises the important scientific question: \"Under\nwhich process conditions do loose pellet ingredients bind together to form a\nmechanically rigid and durable pellet?\" In this work we provide new answers to\nthis old research question by determining the causal relationships between\nprocessing parameters and physical pellet quality. Systematic pelleting\nexperiments reveal that the interplay of typical process parameters such as\nsteam conditioning temperature, production rate, and die geometry, can be\nunderstood in an overarching framework of process interactions. We introduce\nthe concept of the \"stickiness temperature,\" $\\mathrm{T^*}$, marking the onset\nof critical enthalpic reactions necessary for pellet agglomeration, the\nboundary condition for bond formation within a pellet. Our framework\ndemonstrates how $T^*$ is achieved through a combination of steam conditioning\nand friction, and how these conditions can be controlled by adjusting process\nparameters. Our findings underscore the significance of pellet temperature in\nconjunction with die residence time, for optimizing physical pellet quality\nwhile reducing energy consumption per kilogram of product. Validating our\nresults in a trial and leveraging existing literature data, our framework\nprovides handles to intelligently enhance the efficiency and sustainability of\npelleting processes.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-07T08:48:12Z"}
{"aid":"http://arxiv.org/abs/2504.04840v1","title":"Unsupervised Ego- and Exo-centric Dense Procedural Activity Captioning\n  via Gaze Consensus Adaptation","summary":"Even from an early age, humans naturally adapt between exocentric (Exo) and\negocentric (Ego) perspectives to understand daily procedural activities.\nInspired by this cognitive ability, in this paper, we propose a novel\nUnsupervised Ego-Exo Adaptation for Dense Video Captioning (UEA-DVC) task,\nwhich aims to predict the time segments and descriptions for target view\nvideos, while only the source view data are labeled during training. Despite\nprevious works endeavoring to address the fully-supervised single-view or\ncross-view dense video captioning, they lapse in the proposed unsupervised task\ndue to the significant inter-view gap caused by temporal misalignment and\nirrelevant object interference. Hence, we propose a Gaze Consensus-guided\nEgo-Exo Adaptation Network (GCEAN) that injects the gaze information into the\nlearned representations for the fine-grained alignment between the Ego and Exo\nviews. Specifically, the Score-based Adversarial Learning Module (SALM)\nincorporates a discriminative scoring network to learn unified view-invariant\nrepresentations for bridging distinct views from a global level. Then, the Gaze\nConsensus Construction Module (GCCM) utilizes gaze representations to\nprogressively calibrate the learned global view-invariant representations for\nextracting the video temporal contexts based on focusing regions. Moreover, the\ngaze consensus is constructed via hierarchical gaze-guided consistency losses\nto spatially and temporally align the source and target views. To support our\nresearch, we propose a new EgoMe-UEA-DVC benchmark and experiments demonstrate\nthe effectiveness of our method, which outperforms many related methods by a\nlarge margin. The code will be released.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-07T08:51:11Z"}
{"aid":"http://arxiv.org/abs/2504.04856v1","title":"Approach to optimal quantum transport via states over time","summary":"We approach the problem of constructing a quantum analogue of the immensely\nfruitful classical transport cost theory of Monge from a new angle. Going back\nto the original motivations, by which the transport is a bilinear function of a\nmass distribution (without loss of generality a probability density) and a\ntransport plan (a stochastic kernel), we explore the quantum version where the\nmass distribution is generalised to a density matrix, and the transport plan to\na completely positive and trace preserving map.\n  These two data are naturally integrated into their Jordan product, which is\ncalled state over time (``stote''), and the transport cost is postulated to be\na linear function of it.\n  We explore the properties of this transport cost, as well as the optimal\ntransport cost between two given states (simply the minimum cost over all\nsuitable transport plans). After that, we analyse in considerable detail the\ncase of unitary invariant cost, for which we can calculate many costs\nanalytically. These findings suggest that our quantum transport cost is\nqualitatively different from Monge's classical transport.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.MP","published":"2025-04-07T09:13:56Z"}
{"aid":"http://arxiv.org/abs/2504.04891v1","title":"Leveraging Large Language Models for Cost-Effective, Multilingual\n  Depression Detection and Severity Assessment","summary":"Depression is a prevalent mental health disorder that is difficult to detect\nearly due to subjective symptom assessments. Recent advancements in large\nlanguage models have offered efficient and cost-effective approaches for this\nobjective. In this study, we evaluated the performance of four LLMs in\ndepression detection using clinical interview data. We selected the best\nperforming model and further tested it in the severity evaluation scenario and\nknowledge enhanced scenario. The robustness was evaluated in complex diagnostic\nscenarios using a dataset comprising 51074 statements from six different mental\ndisorders. We found that DeepSeek V3 is the most reliable and cost-effective\nmodel for depression detection, performing well in both zero-shot and few-shot\nscenarios, with zero-shot being the most efficient choice. The evaluation of\nseverity showed low agreement with the human evaluator, particularly for mild\ndepression. The model maintains stably high AUCs for detecting depression in\ncomplex diagnostic scenarios. These findings highlight DeepSeek V3s strong\npotential for text-based depression detection in real-world clinical\napplications. However, they also underscore the need for further refinement in\nseverity assessment and the mitigation of potential biases to enhance clinical\nreliability.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-07T09:58:19Z"}
{"aid":"http://arxiv.org/abs/2504.04893v1","title":"SCAM: A Real-World Typographic Robustness Evaluation for Multimodal\n  Foundation Models","summary":"Typographic attacks exploit the interplay between text and visual content in\nmultimodal foundation models, causing misclassifications when misleading text\nis embedded within images. However, existing datasets are limited in size and\ndiversity, making it difficult to study such vulnerabilities. In this paper, we\nintroduce SCAM, the largest and most diverse dataset of real-world typographic\nattack images to date, containing 1,162 images across hundreds of object\ncategories and attack words. Through extensive benchmarking of Vision-Language\nModels (VLMs) on SCAM, we demonstrate that typographic attacks significantly\ndegrade performance, and identify that training data and model architecture\ninfluence the susceptibility to these attacks. Our findings reveal that\ntypographic attacks persist in state-of-the-art Large Vision-Language Models\n(LVLMs) due to the choice of their vision encoder, though larger Large Language\nModels (LLMs) backbones help mitigate their vulnerability. Additionally, we\ndemonstrate that synthetic attacks closely resemble real-world (handwritten)\nattacks, validating their use in research. Our work provides a comprehensive\nresource and empirical insights to facilitate future research toward robust and\ntrustworthy multimodal AI systems. We publicly release the datasets introduced\nin this paper under https://huggingface.co/datasets/BLISS-e-V/SCAM, along with\nthe code for evaluations at https://github.com/Bliss-e-V/SCAM.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T10:01:38Z"}
{"aid":"http://arxiv.org/abs/2504.04904v1","title":"A kinetic CMA diagram","summary":"We present a kinetic Clemmow-Mullaly-Allis (CMA) diagram by systematically\nanalysing the kinetic effects on the wave propagation in a homogeneous thermal\nplasma. The differences between the cold and kinetic CMA diagrams are outlined.\nIt is found that new boundaries for weakly damped left- and right-handed\ncircularly polarized waves are located above the ion and electron cyclotron\nfrequency lines in the kinetic CMA diagram. Additionally, Langmuir waves in the\nkinetic CMA diagram occupy a specific region between the new Langmuir wave\nboundary and the plasma frequency line, while in the cold CMA diagram, they\nexist on the plasma frequency line. The extraordinary-Bernstein mode\ntransformation frequency lines in the kinetic CMA diagram replace the hybrid\nresonant frequency lines of the cold CMA diagram, with discontinuities between\ndifferent cyclotron harmonics. These new boundaries partition the parameter\nspace in the kinetic CMA diagram differently, leading to new inverse wave\nnormal surfaces in the regions bounded by new boundaries. The kinetic CMA\ndiagram not only contributes to a basic understanding of wave properties in\nthermal plasmas, but also can provide a powerful tool to explore new possible\npropagation paths.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-07T10:22:29Z"}
{"aid":"http://arxiv.org/abs/2504.04912v1","title":"An iterative process for the feasibility-seeking problem with sets that\n  are unions of convex sets","summary":"In this paper we deal with the feasibility-seeking problem for unions of\nconvex sets (UCS) sets and propose an iterative process for its solution.\nRenewed interest in this problem stems from the fact that it was recently\ndiscovered to serve as a modeling approach in fields of applications and from\nthe ongoing recent research efforts to handle non-convexity in\nfeasibility-seeking.","main_category":"math.OC","categories":"math.OC,cs.NA,math.NA","published":"2025-04-07T10:41:54Z"}
{"aid":"http://arxiv.org/abs/2504.04915v1","title":"Collab-RAG: Boosting Retrieval-Augmented Generation for Complex Question\n  Answering via White-Box and Black-Box LLM Collaboration","summary":"Retrieval-Augmented Generation (RAG) systems often struggle to handle\nmulti-hop question-answering tasks accurately due to irrelevant context\nretrieval and limited complex reasoning capabilities. We introduce Collab-RAG,\na collaborative training framework that leverages mutual enhancement between a\nwhite-box small language model (SLM) and a blackbox large language model (LLM)\nfor RAG. Specifically, the SLM decomposes complex queries into simpler\nsub-questions, thus enhancing the accuracy of the retrieval and facilitating\nmore effective reasoning by the black-box LLM. Concurrently, the black-box LLM\nprovides feedback signals to improve the SLM's decomposition capability. We\nobserve that Collab-RAG relies solely on supervision from an affordable\nblack-box LLM without additional distillation from frontier LLMs, yet\ndemonstrates strong generalization across multiple black-box LLMs. Experimental\nevaluations across five multi-hop QA datasets demonstrate that Collab-RAG\nsubstantially outperforms existing black-box-only and SLM fine-tuning baselines\nby 1.8%-14.2% on average. In particular, our fine-tuned 3B SLM surpasses a\nfrozen 32B LLM in question decomposition, highlighting the efficiency of\nCollab-RAG in improving reasoning and retrieval for complex questions. The code\nof Collab-RAG is available on https://github.com/ritaranx/Collab-RAG/.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.IR,cs.LG","published":"2025-04-07T10:52:22Z"}
{"aid":"http://arxiv.org/abs/2504.04925v1","title":"Scaling regimes in slow quenches within a gapped phase","summary":"We consider the finite-time quench dynamics in the quantum transverse field\nIsing model which exhibits a second order phase transition from a paramagnetic\nto a ferromagnetic phase, as the transverse magnetic field is decreased. These\ndynamics have been thoroughly investigated in previous studies when the\ncritical point is crossed during the quench; here, we quench the system from\ndeep in the paramagnetic phase to just above the critical field so that the\nsystem remains in the gapped phase throughout the quench duration. On linearly\nquenching the infinitely large system, we find that the behavior of mean\nlongitudinal defect density and mean transverse magnetization at the end of the\nquench falls into three distinct scaling regimes as the quench time is\nincreased. For sufficiently small quench times, these observables remain\nroughly constant, but for larger quench times, a crossover occurs from the\nKibble-Zurek scaling law to the quadratic quench rate law when the Kibble-Zurek\ntime is of the order of relaxation time at the final quench field. These\nresults are shown analytically using power series and uniform asymptotic\nexpansions of the exact solution of the model, and also compared with an\nadiabatic perturbation theory in the third regime. We find that the above\nmentioned scaling regimes hold for quenches within the ferromagnetic phase\nalso, and provide a general scaling argument for crossover from the\nKibble-Zurek regime to an adiabatic regime for slow quenches within a gapped\nphase.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-07T11:05:46Z"}
{"aid":"http://arxiv.org/abs/2504.04936v1","title":"Constrained Gaussian Process Motion Planning via Stein Variational\n  Newton Inference","summary":"Gaussian Process Motion Planning (GPMP) is a widely used framework for\ngenerating smooth trajectories within a limited compute time--an essential\nrequirement in many robotic applications. However, traditional GPMP approaches\noften struggle with enforcing hard nonlinear constraints and rely on Maximum a\nPosteriori (MAP) solutions that disregard the full Bayesian posterior. This\nlimits planning diversity and ultimately hampers decision-making. Recent\nefforts to integrate Stein Variational Gradient Descent (SVGD) into motion\nplanning have shown promise in handling complex constraints. Nonetheless, these\nmethods still face persistent challenges, such as difficulties in strictly\nenforcing constraints and inefficiencies when the probabilistic inference\nproblem is poorly conditioned. To address these issues, we propose a novel\nconstrained Stein Variational Gaussian Process Motion Planning (cSGPMP)\nframework, incorporating a GPMP prior specifically designed for trajectory\noptimization under hard constraints. Our approach improves the efficiency of\nparticle-based inference while explicitly handling nonlinear constraints. This\nadvancement significantly broadens the applicability of GPMP to motion planning\nscenarios demanding robust Bayesian inference, strict constraint adherence, and\ncomputational efficiency within a limited time. We validate our method on\nstandard benchmarks, achieving an average success rate of 98.57% across 350\nplanning tasks, significantly outperforming competitive baselines. This\ndemonstrates the ability of our method to discover and use diverse trajectory\nmodes, enhancing flexibility and adaptability in complex environments, and\ndelivering significant improvements over standard baselines without incurring\nmajor computational costs.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-07T11:20:11Z"}
{"aid":"http://arxiv.org/abs/2504.04950v1","title":"A Unified Pairwise Framework for RLHF: Bridging Generative Reward\n  Modeling and Policy Optimization","summary":"Reinforcement Learning from Human Feedback (RLHF) has emerged as a important\nparadigm for aligning large language models (LLMs) with human preferences\nduring post-training. This framework typically involves two stages: first,\ntraining a reward model on human preference data, followed by optimizing the\nlanguage model using reinforcement learning algorithms. However, current RLHF\napproaches may constrained by two limitations. First, existing RLHF frameworks\noften rely on Bradley-Terry models to assign scalar rewards based on pairwise\ncomparisons of individual responses. However, this approach imposes significant\nchallenges on reward model (RM), as the inherent variability in prompt-response\npairs across different contexts demands robust calibration capabilities from\nthe RM. Second, reward models are typically initialized from generative\nfoundation models, such as pre-trained or supervised fine-tuned models, despite\nthe fact that reward models perform discriminative tasks, creating a mismatch.\nThis paper introduces Pairwise-RL, a RLHF framework that addresses these\nchallenges through a combination of generative reward modeling and a pairwise\nproximal policy optimization (PPO) algorithm. Pairwise-RL unifies reward model\ntraining and its application during reinforcement learning within a consistent\npairwise paradigm, leveraging generative modeling techniques to enhance reward\nmodel performance and score calibration. Experimental evaluations demonstrate\nthat Pairwise-RL outperforms traditional RLHF frameworks across both internal\nevaluation datasets and standard public benchmarks, underscoring its\neffectiveness in improving alignment and model behavior.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-07T11:34:48Z"}
{"aid":"http://arxiv.org/abs/2504.04978v1","title":"The eigenvalue one property of finite groups, I","summary":"We prove a conjecture of Dekimpe, De Rock and Penninckx concerning the\nexistence of eigenvalues one in certain elements of finite groups acting\nirreducibly on a real vector space of odd dimension. This yields a sufficient\ncondition for a closed flat manifold to be an $R_{\\infty}$-manifold.","main_category":"math.GR","categories":"math.GR","published":"2025-04-07T12:05:30Z"}
{"aid":"http://arxiv.org/abs/2504.04979v1","title":"Light quark energy loss in the flavor-dependent systems from holography","summary":"Using the holographic model of finite-endpoint-momentum shooting string\napproach, we study the instantaneous energy loss of light quarks for the\nflavor-dependent systems with $N_f = 0$, $N_f = 2$, and $N_f = 2+1$ in the\nEinstein-Maxwell-dilaton (EMD) framework. In particular, we investigate for the\nfirst time the impact of the flavor content of the strongly coupled QGP medium\non the instantaneous energy loss of light quarks. It turns out that the\ninstantaneous energy loss of light quarks is smallest for $N_f = 0$, and adding\n$u(d)$ quarks and $s$ quark in the system increases this energy loss. In\naddition, we found that the instantaneous energy loss in the strongly coupled\nplasma is minimal near the critical temperature, but it increases as the system\nmoves away from the critical endpoint due to rising temperature or chemical\npotential.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-07T12:06:30Z"}
{"aid":"http://arxiv.org/abs/2504.04981v1","title":"DiCoTTA: Domain-invariant Learning for Continual Test-time Adaptation","summary":"This paper studies continual test-time adaptation (CTTA), the task of\nadapting a model to constantly changing unseen domains in testing while\npreserving previously learned knowledge. Existing CTTA methods mostly focus on\nadaptation to the current test domain only, overlooking generalization to\narbitrary test domains a model may face in the future. To tackle this\nlimitation, we present a novel online domain-invariant learning framework for\nCTTA, dubbed DiCoTTA. DiCoTTA aims to learn feature representation to be\ninvariant to both current and previous test domains on the fly during testing.\nTo this end, we propose a new model architecture and a test-time adaptation\nstrategy dedicated to learning domain-invariant features without corrupting\nsemantic contents, along with a new data structure and optimization algorithm\nfor effectively managing information from previous test domains. DiCoTTA\nachieved state-of-the-art performance on four public CTTA benchmarks. Moreover,\nit showed superior generalization to unseen test domains.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T12:09:18Z"}
{"aid":"http://arxiv.org/abs/2504.04984v1","title":"Finding large $k$-colorable induced subgraphs in (bull, chair)-free and\n  (bull,E)-free graphs","summary":"We study the Max Partial $k$-Coloring problem, where we are given a\nvertex-weighted graph, and we ask for a maximum-weight induced subgraph that\nadmits a proper $k$-coloring. For $k=1$ this problem coincides with Maximum\nWeight Independent Set, and for $k=2$ the problem is equivalent (by\ncomplementation) to Minimum Odd Cycle Transversal. Furthermore, it generalizes\n$k$-Coloring. We show that Max Partial $k$-Coloring on $n$-vertex instances\nwith clique number $\\omega$ can be solved in time\n  * $n^{\\mathcal{O}(k\\omega)}$ if the input graph excludes the bull and the\nchair as an induced subgraph,\n  * $n^{\\mathcal{O}(k\\omega \\log n)}$ if the input graph excludes the bull and\nE as an induced subgraph.\n  This implies that $k$-Coloring can be solved in polynomial time in the former\nclass, and in quasipolynomial-time in the latter one.","main_category":"cs.CC","categories":"cs.CC","published":"2025-04-07T12:11:01Z"}
{"aid":"http://arxiv.org/abs/2504.05026v1","title":"Multi-level Neural Networks for high-dimensional parametric obstacle\n  problems","summary":"A new method to solve computationally challenging (random) parametric\nobstacle problems is developed and analyzed, where the parameters can influence\nthe related partial differential equation (PDE) and determine the position and\nsurface structure of the obstacle. As governing equation, a stationary elliptic\ndiffusion problem is assumed. The high-dimensional solution of the obstacle\nproblem is approximated by a specifically constructed convolutional neural\nnetwork (CNN). This novel algorithm is inspired by a finite element constrained\nmultigrid algorithm to represent the parameter to solution map. This has two\nbenefits: First, it allows for efficient practical computations since\nmulti-level data is used as an explicit output of the NN thanks to an\nappropriate data preprocessing. This improves the efficacy of the training\nprocess and subsequently leads to small errors in the natural energy norm.\nSecond, the comparison of the CNN to a multigrid algorithm provides means to\ncarry out a complete a priori convergence and complexity analysis of the\nproposed NN architecture. Numerical experiments illustrate a state-of-the-art\nperformance for this challenging problem.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.FA,math.NA","published":"2025-04-07T12:50:56Z"}
{"aid":"http://arxiv.org/abs/2504.05040v1","title":"InstructionBench: An Instructional Video Understanding Benchmark","summary":"Despite progress in video large language models (Video-LLMs), research on\ninstructional video understanding, crucial for enhancing access to\ninstructional content, remains insufficient. To address this, we introduce\nInstructionBench, an Instructional video understanding Benchmark, which\nchallenges models' advanced temporal reasoning within instructional videos\ncharacterized by their strict step-by-step flow. Employing GPT-4, we formulate\nQ\\&A pairs in open-ended and multiple-choice formats to assess both\nCoarse-Grained event-level and Fine-Grained object-level reasoning. Our\nfiltering strategies exclude questions answerable purely by common-sense\nknowledge, focusing on visual perception and analysis when evaluating Video-LLM\nmodels. The benchmark finally contains 5k questions across over 700 videos. We\nevaluate the latest Video-LLMs on our InstructionBench, finding that\nclosed-source models outperform open-source ones. However, even the best model,\nGPT-4o, achieves only 53.42\\% accuracy, indicating significant gaps in temporal\nreasoning. To advance the field, we also develop a comprehensive instructional\nvideo dataset with over 19k Q\\&A pairs from nearly 2.5k videos, using an\nautomated data generation framework, thereby enriching the community's research\nresources.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:05:09Z"}
{"aid":"http://arxiv.org/abs/2504.05082v1","title":"Entanglement Transfer in a Composite Electron-Ion-Photon System","summary":"We study how entanglement in photoionization is transferred from an\nelectron-ion pair to an electron-photon pair by fluorescence. Time-resolved von\nNeumann entropies are used to establish how information is shared between the\nparticles. Multipartite entanglement, between electron, ion and photon, is\nfound on intermediate timescales. Finally, it is shown how a phase-locked\ntwo-pulse sequence allows for the application of time symmetry, mediated by\nstrong coupling, to reveal the entanglement transfer process by measuring the\nphoton number and electron kinetic energy in coincidence.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-07T13:52:19Z"}
{"aid":"http://arxiv.org/abs/2504.05085v1","title":"Characterisation of conserved and reacting moieties in chemical reaction\n  networks","summary":"A detailed understanding of biochemical networks at the molecular level is\nessential for studying complex cellular processes. In this paper, we provide a\ncomprehensive description of biochemical networks by considering individual\natoms and chemical bonds. To address combinatorial complexity, we introduce a\nwell-established approach to group similar types of information within\nbiochemical networks. A conserved moiety is a set of atoms whose association is\ninvariant across all reactions in a network. A reacting moiety is a set of\nbonds that are either broken, formed, or undergo a change in bond order in at\nleast one reaction in the network. By mathematically identifying these\nmoieties, we establish the biological significance of conserved and reacting\nmoieties according to the mathematical properties of the stoichiometric matrix.\nWe also present a novel decomposition of the stoichiometric matrix based on\nconserved moieties. This approach bridges the gap between graph theory, linear\nalgebra, and biological interpretation, thus opening up new horizons in the\nstudy of chemical reaction networks.","main_category":"q-bio.MN","categories":"q-bio.MN","published":"2025-04-07T13:54:47Z"}
{"aid":"http://arxiv.org/abs/2504.05094v1","title":"Hollow Victory: How Malicious Proposers Exploit Validator Incentives in\n  Optimistic Rollup Dispute Games","summary":"Blockchain systems, such as Ethereum, are increasingly adopting layer-2\nscaling solutions to improve transaction throughput and reduce fees. One\npopular layer-2 approach is the Optimistic Rollup, which relies on a mechanism\nknown as a dispute game for block proposals. In these systems, validators can\nchallenge blocks that they believe contain errors, and a successful challenge\nresults in the transfer of a portion of the proposer's deposit as a reward. In\nthis paper, we reveal a structural vulnerability in the mechanism: validators\nmay not be awarded a proper profit despite winning a dispute challenge. We\ndevelop a formal game-theoretic model of the dispute game and analyze several\nscenarios, including cases where the proposer controls some validators and\ncases where a secondary auction mechanism is deployed to induce additional\nparticipation. Our analysis demonstrates that under current designs, the\ncompetitive pressure from validators may be insufficient to deter malicious\nbehavior. We find that increased validator competition, paradoxically driven by\nhigher rewards or participation, can allow a malicious proposer to\nsignificantly lower their net loss by capturing value through mechanisms like\nauctions. To address this, we propose countermeasures such as an escrowed\nreward mechanism and a commit-reveal protocol. Our findings provide critical\ninsights into enhancing the economic security of layer-2 scaling solutions in\nblockchain networks.","main_category":"cs.GT","categories":"cs.GT,cs.CR","published":"2025-04-07T14:00:46Z"}
{"aid":"http://arxiv.org/abs/2504.05118v1","title":"VAPO: Efficient and Reliable Reinforcement Learning for Advanced\n  Reasoning Tasks","summary":"We present VAPO, Value-based Augmented Proximal Policy Optimization framework\nfor reasoning models., a novel framework tailored for reasoning models within\nthe value-based paradigm. Benchmarked the AIME 2024 dataset, VAPO, built on the\nQwen 32B pre-trained model, attains a state-of-the-art score of\n$\\mathbf{60.4}$. In direct comparison under identical experimental settings,\nVAPO outperforms the previously reported results of DeepSeek-R1-Zero-Qwen-32B\nand DAPO by more than 10 points. The training process of VAPO stands out for\nits stability and efficiency. It reaches state-of-the-art performance within a\nmere 5,000 steps. Moreover, across multiple independent runs, no training\ncrashes occur, underscoring its reliability. This research delves into long\nchain-of-thought (long-CoT) reasoning using a value-based reinforcement\nlearning framework. We pinpoint three key challenges that plague value-based\nmethods: value model bias, the presence of heterogeneous sequence lengths, and\nthe sparsity of reward signals. Through systematic design, VAPO offers an\nintegrated solution that effectively alleviates these challenges, enabling\nenhanced performance in long-CoT reasoning tasks.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T14:21:11Z"}
{"aid":"http://arxiv.org/abs/2504.05130v1","title":"Viscous pressureless flows with free boundary in one space dimension:\n  The constant viscosity case","summary":"We establish the global well-posedness of the free boundary problem of the\nviscous pressureless and almost pressureless heat conductive flows in one space\ndimension. In both cases, arbitrarily large but smooth initial data is\nconsidered, and the evolving fluid domains remain bounded for all time. In the\nviscous pressureless case, we are able to identify the terminal flow domain in\nterms of the initial data. In the viscous almost pressureless case, we\nconstruct the flow as a perturbation of the viscous pressureless flow, and\nestablish the first result for the Navier-Stokes-Fourier system in the current\nsetting.","main_category":"math.AP","categories":"math.AP","published":"2025-04-07T14:33:33Z"}
{"aid":"http://arxiv.org/abs/2504.05151v1","title":"Error formulas for block rational Krylov approximations of matrix\n  functions","summary":"This paper investigates explicit expressions for the error associated with\nthe block rational Krylov approximation of matrix functions. Two formulas are\nproposed, both derived from characterizations of the block FOM residual. The\nfirst formula employs a block generalization of the residual polynomial, while\nthe second leverages the block collinearity of the residuals. A posteriori\nerror bounds based on the knowledge of spectral information of the argument are\nderived and tested on a set of examples. Notably, both error formulas and their\ncorresponding upper bounds do not require the use of quadratures for their\npractical evaluation.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-07T14:56:55Z"}
{"aid":"http://arxiv.org/abs/2504.05173v1","title":"PRDTs: Composable Knowledge-Based Consensus Protocols with Replicated\n  Data Types","summary":"Consensus protocols are fundamental in distributed systems as they enable\nsoftware with strong consistency properties. However, designing optimized\nprotocols for specific use-cases under certain system assumptions is typically\na laborious and error-prone process requiring expert knowledge. While most\nrecent optimized protocols are variations of well-known algorithms like Paxos\nor Raft, they often necessitate complete re-implementations, potentially\nintroducing new bugs and complicating the application of existing verification\nresults.This approach stands in the way of application-specific consistency\nprotocols that can easily be amended or swapped out, depending on the given\napplication and deployment scenario.\n  We propose Protocol Replicated Data Types (PRDTs), a novel programming model\nfor implementing consensus protocols using replicated data types (RDTs).\nInspired by the knowledge-based view of consensus, PRDTs employ RDTs to\nmonotonically accumulate until agreement is reached. This approach allows for\nimplementations focusing on high-level protocol logic with minimal network\nenvironment assumptions. Moreover, by applying existing algebraic composition\ntechniques for RDTs in the PRDT context, we enable composable protocol\nbuilding-blocks for implementing complex protocols. We present a formal model\nof our approach, demonstrate its application in PRDT-based implementations of\nexisting protocols, and report empirical evaluation results. Our findings\nindicate that the PRDT approach offers enhanced flexibility and composability\nin protocol design, facilitates reasoning about correctness, and does not\nsuffer from inherent performance limitations that would prevent its use in\nreal-world applications.","main_category":"cs.PL","categories":"cs.PL,cs.DC","published":"2025-04-07T15:17:35Z"}
{"aid":"http://arxiv.org/abs/2504.05179v1","title":"IEC-Independent Coupling Between Water Uptake and Ionic Conductivity in\n  Anion-Conducting Polymer Films","summary":"Anion exchange membranes (AEMs) are promising candidates for replacing proton\nexchange membranes (PEMs) in electrochemical devices such as fuel cells,\nelectrolyzers, batteries, and osmotic energy extraction systems. However,\noptimizing the AEM design requires a deeper understanding of the ionic\nconduction mechanism in the hydrated polymer matrix. This study investigates\nthis mechanism by seeking to understand the relationship between ion exchange\ncapacity (IEC), water absorption, and ionic conductivity in\npolynorbornene-based thin films. We combine experimental measurements with\ncomputational simulations using a newly developed minimal model of the polymer\nfilm. Our model is able to reproduce key experimental observations, including\nwater sorption isotherms and ion conduction behavior as a function of relative\nhumidity, and successfully captures the relationship between them. By comparing\nexperimental data with computational results, we explain the commonly reported\ncorrelation between conductivity and hydration level and show how the\ncorrelation between these variables is affected by the charge density and\ntemperature of the material. Our research advances our understanding of the\nphysical mechanisms that govern the performance of the polyelectrolyte\nmembrane, which is essential for the development of more efficient, stable, and\nenvironmentally friendly electrochemical systems.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.mtrl-sci","published":"2025-04-07T15:26:53Z"}
{"aid":"http://arxiv.org/abs/2504.05187v1","title":"Resource-Efficient Beam Prediction in mmWave Communications with\n  Multimodal Realistic Simulation Framework","summary":"Beamforming is a key technology in millimeter-wave (mmWave) communications\nthat improves signal transmission by optimizing directionality and intensity.\nHowever, conventional channel estimation methods, such as pilot signals or beam\nsweeping, often fail to adapt to rapidly changing communication environments.\nTo address this limitation, multimodal sensing-aided beam prediction has gained\nsignificant attention, using various sensing data from devices such as LiDAR,\nradar, GPS, and RGB images to predict user locations or network conditions.\nDespite its promising potential, the adoption of multimodal sensing-aided beam\nprediction is hindered by high computational complexity, high costs, and\nlimited datasets. Thus, in this paper, a resource-efficient learning approach\nis proposed to transfer knowledge from a multimodal network to a monomodal\n(radar-only) network based on cross-modal relational knowledge distillation\n(CRKD), while reducing computational overhead and preserving predictive\naccuracy. To enable multimodal learning with realistic data, a novel multimodal\nsimulation framework is developed while integrating sensor data generated from\nthe autonomous driving simulator CARLA with MATLAB-based mmWave channel\nmodeling, and reflecting real-world conditions. The proposed CRKD achieves its\nobjective by distilling relational information across different feature spaces,\nwhich enhances beam prediction performance without relying on expensive sensor\ndata. Simulation results demonstrate that CRKD efficiently distills multimodal\nknowledge, allowing a radar-only model to achieve $94.62\\%$ of the teacher\nperformance. In particular, this is achieved with just $10\\%$ of the teacher\nnetwork's parameters, thereby significantly reducing computational complexity\nand dependence on multimodal sensor data.","main_category":"cs.NI","categories":"cs.NI,cs.AI,cs.LG","published":"2025-04-07T15:38:25Z"}
{"aid":"http://arxiv.org/abs/2504.05203v1","title":"A theorem on support $τ$--tilting pairs","summary":"We show that there is a special bijection between the indecomposable summands\nof the two modules which form a basic support $\\tau$--tilting pair and the\nindecomposable summands of the two modules which form another basic support\n$\\tau$--tilting pair.","main_category":"math.RT","categories":"math.RT","published":"2025-04-07T15:51:18Z"}
{"aid":"http://arxiv.org/abs/2504.05211v1","title":"Exploiting individual differences to bootstrap communication","summary":"Establishing a communication system is hard because the intended meaning of a\nsignal is unknown to its receiver when first produced, and the signaller also\nhas no idea how that signal will be interpreted. Most theoretical accounts of\nthe emergence of communication systems rely on feedback to reinforce behaviours\nthat have led to successful communication in the past. However, providing such\nfeedback requires already being able to communicate the meaning that was\nintended or interpreted. Therefore these accounts cannot explain how\ncommunication can be bootstrapped from non-communicative behaviours. Here we\npresent a model that shows how a communication system, capable of expressing an\nunbounded number of meanings, can emerge as a result of individual behavioural\ndifferences in a large population without any pre-existing means to determine\ncommunicative success. The two key cognitive capabilities responsible for this\noutcome are behaving predictably in a given situation, and an alignment of\npsychological states ahead of signal production that derives from shared\nintentionality. Since both capabilities can exist independently of\ncommunication, our results are compatible with theories in which large flexible\nsocially-learned communication systems like language are the product of a\ngeneral but well-developed capacity for social cognition.","main_category":"cs.CL","categories":"cs.CL,physics.soc-ph,q-bio.PE","published":"2025-04-07T15:58:49Z"}
{"aid":"http://arxiv.org/abs/2504.05212v1","title":"On multipolar magnetic anomaly detection: multipolar signal subspaces,\n  an analytical orthonormal basis, multipolar truncature and detection\n  performance","summary":"In this paper, we consider the magnetic anomaly detection problem which aims\nto find hidden ferromagnetic masses by estimating the weak perturbation they\ninduce on local Earth's magnetic field. We consider classical detection schemes\nthat rely on signals recorded on a moving sensor, and modeling of the source as\na function of unknown parameters. As the usual spherical harmonic decomposition\nof the anomaly has to be truncated in practice, we study the signal vector\nsubspaces induced by each multipole of the decomposition, proving they are not\nin direct sum, and discussing the impact it has on the choice of the truncation\norder. Further, to ease the detection strategy based on generalized likelihood\nratio test, we rely on orthogonal polynomials theory to derive an analytical\nset of orthonormal functions (multipolar orthonormal basis functions) that\nspans the space of the noise-free measured signal. Finally, based on the\nsubspace structure of the multipole vector spaces, we study the impact of the\ntruncation order on the detection performance, beyond the issue of potential\nsurparametrization, and the behaviour of the information criteria used to\nchoose this order.","main_category":"eess.SP","categories":"eess.SP,math-ph,math.MP,stat.ME","published":"2025-04-07T16:00:24Z"}
{"aid":"http://arxiv.org/abs/2504.05213v1","title":"Curves of best approximation on wonderful varieties","summary":"We give an unconditional proof of the Coba conjecture for wonderful\ncompactifications of adjoint type for semisimple Lie groups of type $A_n$. We\nalso give a proof of a slightly weaker conjecture for wonderful\ncompactifications of adjoint type for arbitrary Lie groups.","main_category":"math.AG","categories":"math.AG","published":"2025-04-07T16:01:01Z"}
{"aid":"http://arxiv.org/abs/2504.05217v1","title":"LLM-Alignment Live-Streaming Recommendation","summary":"In recent years, integrated short-video and live-streaming platforms have\ngained massive global adoption, offering dynamic content creation and\nconsumption. Unlike pre-recorded short videos, live-streaming enables real-time\ninteraction between authors and users, fostering deeper engagement. However,\nthis dynamic nature introduces a critical challenge for recommendation systems\n(RecSys): the same live-streaming vastly different experiences depending on\nwhen a user watching. To optimize recommendations, a RecSys must accurately\ninterpret the real-time semantics of live content and align them with user\npreferences.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-07T16:04:00Z"}
{"aid":"http://arxiv.org/abs/2504.05225v1","title":"Vision-Language Model Predictive Control for Manipulation Planning and\n  Trajectory Generation","summary":"Model Predictive Control (MPC) is a widely adopted control paradigm that\nleverages predictive models to estimate future system states and optimize\ncontrol inputs accordingly. However, while MPC excels in planning and control,\nit lacks the capability for environmental perception, leading to failures in\ncomplex and unstructured scenarios. To address this limitation, we introduce\nVision-Language Model Predictive Control (VLMPC), a robotic manipulation\nplanning framework that integrates the perception power of vision-language\nmodels (VLMs) with MPC. VLMPC utilizes a conditional action sampling module\nthat takes a goal image or language instruction as input and leverages VLM to\ngenerate candidate action sequences. These candidates are fed into a video\nprediction model that simulates future frames based on the actions. In\naddition, we propose an enhanced variant, Traj-VLMPC, which replaces video\nprediction with motion trajectory generation to reduce computational complexity\nwhile maintaining accuracy. Traj-VLMPC estimates motion dynamics conditioned on\nthe candidate actions, offering a more efficient alternative for long-horizon\ntasks and real-time applications. Both VLMPC and Traj-VLMPC select the optimal\naction sequence using a VLM-based hierarchical cost function that captures both\npixel-level and knowledge-level consistency between the current observation and\nthe task input. We demonstrate that both approaches outperform existing\nstate-of-the-art methods on public benchmarks and achieve excellent performance\nin various real-world robotic manipulation tasks. Code is available at\nhttps://github.com/PPjmchen/VLMPC.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T16:13:09Z"}
{"aid":"http://arxiv.org/abs/2504.05227v1","title":"A Reality Check of Vision-Language Pre-training in Radiology: Have We\n  Progressed Using Text?","summary":"Vision-language pre-training has recently gained popularity as it allows\nlearning rich feature representations using large-scale data sources. This\nparadigm has quickly made its way into the medical image analysis community. In\nparticular, there is an impressive amount of recent literature developing\nvision-language models for radiology. However, the available medical datasets\nwith image-text supervision are scarce, and medical concepts are fine-grained,\ninvolving expert knowledge that existing vision-language models struggle to\nencode. In this paper, we propose to take a prudent step back from the\nliterature and revisit supervised, unimodal pre-training, using fine-grained\nlabels instead. We conduct an extensive comparison demonstrating that unimodal\npre-training is highly competitive and better suited to integrating\nheterogeneous data sources. Our results also question the potential of recent\nvision-language models for open-vocabulary generalization, which have been\nevaluated using optimistic experimental settings. Finally, we study novel\nalternatives to better integrate fine-grained labels and noisy text\nsupervision.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T16:13:26Z"}
{"aid":"http://arxiv.org/abs/2504.05231v1","title":"Mapping biodiversity at very-high resolution in Europe","summary":"This paper describes a cascading multimodal pipeline for high-resolution\nbiodiversity mapping across Europe, integrating species distribution modeling,\nbiodiversity indicators, and habitat classification. The proposed pipeline\nfirst predicts species compositions using a deep-SDM, a multimodal model\ntrained on remote sensing, climate time series, and species occurrence data at\n50x50m resolution. These predictions are then used to generate biodiversity\nindicator maps and classify habitats with Pl@ntBERT, a transformer-based LLM\ndesigned for species-to-habitat mapping. With this approach, continental-scale\nspecies distribution maps, biodiversity indicator maps, and habitat maps are\nproduced, providing fine-grained ecological insights. Unlike traditional\nmethods, this framework enables joint modeling of interspecies dependencies,\nbias-aware training with heterogeneous presence-absence data, and large-scale\ninference from multi-source remote sensing inputs.","main_category":"cs.AI","categories":"cs.AI,cs.CV,cs.LG","published":"2025-04-07T16:15:52Z"}
{"aid":"http://arxiv.org/abs/2504.05239v1","title":"LLM-based Automated Grading with Human-in-the-Loop","summary":"The rise of artificial intelligence (AI) technologies, particularly large\nlanguage models (LLMs), has brought significant advancements to the field of\neducation. Among various applications, automatic short answer grading (ASAG),\nwhich focuses on evaluating open-ended textual responses, has seen remarkable\nprogress with the introduction of LLMs. These models not only enhance grading\nperformance compared to traditional ASAG approaches but also move beyond simple\ncomparisons with predefined \"golden\" answers, enabling more sophisticated\ngrading scenarios, such as rubric-based evaluation. However, existing\nLLM-powered methods still face challenges in achieving human-level grading\nperformance in rubric-based assessments due to their reliance on fully\nautomated approaches. In this work, we explore the potential of LLMs in ASAG\ntasks by leveraging their interactive capabilities through a human-in-the-loop\n(HITL) approach. Our proposed framework, GradeHITL, utilizes the generative\nproperties of LLMs to pose questions to human experts, incorporating their\ninsights to refine grading rubrics dynamically. This adaptive process\nsignificantly improves grading accuracy, outperforming existing methods and\nbringing ASAG closer to human-level evaluation.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T16:23:07Z"}
{"aid":"http://arxiv.org/abs/2504.05256v1","title":"Normality conditions in the Sylow $\\boldsymbol{p}$-subgroup of\n  $\\boldsymbol{\\mathrm{Sym}(p^n)}$ and its associated Lie algebra","summary":"In this work, we give a description of the structure of the normal subgroups\nof a Sylow $p$-subgroup $W_n$ of $\\mathrm{Sym}(p^n)$, showing that they contain\na term from the lower central series with bounded index. To this end, we\nexplicitly determine the terms of the upper and the lower central series of\n$W_n$. We provide a similar description of these series in the Lie algebra\nassociated to $W_n$, giving a new proof of the equality of their terms in both\nthe group and the algebra contexts. Finally, we calculate the growth of the\nnormalizer chain starting from an elementary abelian regular subgroup of $W_n$.","main_category":"math.GR","categories":"math.GR,math.CO","published":"2025-04-07T16:48:23Z"}
{"aid":"http://arxiv.org/abs/2504.05261v1","title":"Componentwise Linear Ideals From Sums","summary":"Let $I,J$ be componentwise linear ideals in a polynomial ring $S$. We study\nnecessary and sufficient conditions for $I+J$ to be componentwise linear. We\nprovide a complete characterization when $\\dim S=2$. As a consequence, any\ncomponentwise linear monomial ideal in $k[x,y]$ has linear quotients using\ngenerators in non-decreasing degrees. In any dimension, we show that under mild\ncompatibility conditions, one can build a componentwise linear ideal from a\ngiven collection of componentwise linear monomial ideals using only sum and\nproduct with square-free monomials. We provide numerous examples to demonstrate\nthe optimality of our results.","main_category":"math.AC","categories":"math.AC,math.CO","published":"2025-04-07T16:54:42Z"}
{"aid":"http://arxiv.org/abs/2504.05273v1","title":"What We Do Not Know: GPT Use in Business and Management","summary":"This systematic review examines peer-reviewed studies on application of GPT\nin business management, revealing significant knowledge gaps. Despite\nidentifying interesting research directions such as best practices,\nbenchmarking, performance comparisons, social impacts, our analysis yields only\n42 relevant studies for the 22 months since its release. There are so few\nstudies looking at a particular sector or subfield that management researchers,\nbusiness consultants, policymakers, and journalists do not yet have enough\ninformation to make well-founded statements on how GPT is being used in\nbusinesses. The primary contribution of this paper is a call to action for\nfurther research. We provide a description of current research and identify\nknowledge gaps on the use of GPT in business. We cover the management subfields\nof finance, marketing, human resources, strategy, operations, production, and\nanalytics, excluding retail and sales. We discuss gaps in knowledge of GPT\npotential consequences on employment, productivity, environmental costs,\noppression, and small businesses. We propose how management consultants and the\nmedia can help fill those gaps. We call for practical work on business control\nsystems as they relate to existing and foreseeable AI-related business\nchallenges. This work may be of interest to managers, to management\nresearchers, and to people working on AI in society.","main_category":"cs.CY","categories":"cs.CY","published":"2025-04-07T17:11:53Z"}
{"aid":"http://arxiv.org/abs/2504.05275v1","title":"On canonical sandpile actions of embedded graphs","summary":"The sandpile group of a connected graph is a group whose cardinality is the\nnumber of spanning trees. The group is known to have a canonical simply\ntransitive action on spanning trees if the graph is embedded into the plane.\nHowever, no canonical action on the spanning trees is known for the nonplanar\ncase. We show that for any embedded Eulerian digraph, one can define a\ncanonical simply transitive action of the sandpile group on compatible Eulerian\ntours (a set whose cardinality equals to the number of spanning arborescences).\nThis enables us to give a new proof that the rotor-routing action of a ribbon\ngraph is independent of the root if and only if the embedding is into the plane\n(originally proved by Chan, Church and Grochow).\n  Recently, Merino, Moffatt and Noble defined a sandpile group variant (called\nJacobian) for embedded graphs, whose cardinality is the number of quasi-trees.\nBaker, Ding and Kim showed that this group acts canonically on the quasitrees.\nWe show that the Jacobian of an embedded graph is canonically isomorphic to the\nusual sandpile group of the medial digraph, and the action by Baker at al.\nagrees with the action of the sandpile group of the medial digraph on Eulerian\ntours (which fact is made possible by the existence of a canonical bijection\nbetween Eulerian tours of the medial digraph and quasi-trees due to Bouchet).","main_category":"math.CO","categories":"math.CO","published":"2025-04-07T17:15:37Z"}
{"aid":"http://arxiv.org/abs/2504.05644v1","title":"iEBAKER: Improved Remote Sensing Image-Text Retrieval Framework via\n  Eliminate Before Align and Keyword Explicit Reasoning","summary":"Recent studies focus on the Remote Sensing Image-Text Retrieval (RSITR),\nwhich aims at searching for the corresponding targets based on the given query.\nAmong these efforts, the application of Foundation Models (FMs), such as CLIP,\nto the domain of remote sensing has yielded encouraging outcomes. However,\nexisting FM based methodologies neglect the negative impact of weakly\ncorrelated sample pairs and fail to account for the key distinctions among\nremote sensing texts, leading to biased and superficial exploration of sample\npairs. To address these challenges, we propose an approach named iEBAKER (an\nImproved Eliminate Before Align strategy with Keyword Explicit Reasoning\nframework) for RSITR. Specifically, we propose an innovative Eliminate Before\nAlign (EBA) strategy to filter out the weakly correlated sample pairs, thereby\nmitigating their deviations from optimal embedding space during\nalignment.Further, two specific schemes are introduced from the perspective of\nwhether local similarity and global similarity affect each other. On this\nbasis, we introduce an alternative Sort After Reversed Retrieval (SAR)\nstrategy, aims at optimizing the similarity matrix via reverse retrieval.\nAdditionally, we incorporate a Keyword Explicit Reasoning (KER) module to\nfacilitate the beneficial impact of subtle key concept distinctions. Without\nbells and whistles, our approach enables a direct transition from FM to RSITR\ntask, eliminating the need for additional pretraining on remote sensing data.\nExtensive experiments conducted on three popular benchmark datasets demonstrate\nthat our proposed iEBAKER method surpasses the state-of-the-art models while\nrequiring less training data. Our source code will be released at\nhttps://github.com/zhangy0822/iEBAKER.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T03:40:19Z"}
{"aid":"http://arxiv.org/abs/2504.05654v1","title":"Curved representational Bregman divergences and their applications","summary":"By analogy to curved exponential families, we define curved Bregman\ndivergences as restrictions of Bregman divergences to sub-dimensional parameter\nsubspaces, and prove that the barycenter of a finite weighted parameter set\nwith respect to a curved Bregman divergence amounts to the Bregman projection\nonto the subspace induced by the constraint of the barycenter with respect to\nthe unconstrained full Bregman divergence. We demonstrate the significance of\ncurved Bregman divergences with two examples: (1) symmetrized Bregman\ndivergences and (2) the Kullback-Leibler divergence between circular complex\nnormal distributions. We then consider monotonic embeddings to define\nrepresentational curved Bregman divergences and show that the\n$\\alpha$-divergences are representational curved Bregman divergences with\nrespect to $\\alpha$-embeddings of the probability simplex into the positive\nmeasure cone. As an application, we report an efficient method to calculate the\nintersection of a finite set of $\\alpha$-divergence spheres.","main_category":"cs.IT","categories":"cs.IT,cs.LG,math.IT","published":"2025-04-08T04:05:12Z"}
{"aid":"http://arxiv.org/abs/2504.05663v1","title":"Characterization of $P_3$-connected graphs","summary":"For any pair of edges $e,f$ of a graph $G$, we say that {\\em $e,f$ are\n$P_3$-connected in $G$} if there exists a sequence of edges $e=e_0,e_1,\\ldots,\ne_k=f$ such that $e_i$ and $e_{i+1}$ are two edges of an induced $3$-vertex\npath in $G$ for every $0\\leq i\\leq k-1$. If every pair of edges of $G$ are\n$P_3$-connected in $G$, then $G$ is {\\em $P_3$-connected}. $P_3$-connectivity\nwas first defined by Chudnovsky et al. in 2024 to prove that every connected\ngraph not containing $P_5$ as an induced subgraph has cop number at most two.\nIn this paper, we give a characterization of $P_3$-connected graphs and prove\nthat a simple graph is $P_3$-connected if and only if it is connected and has\nno homogeneous set whose induced subgraph contains an edge.","main_category":"math.CO","categories":"math.CO","published":"2025-04-08T04:24:13Z"}
{"aid":"http://arxiv.org/abs/2504.05665v1","title":"Experimental Evaluation of Precise Placement of the Hollow Object with\n  Asymmetric Pivot Manipulation","summary":"In this paper, we present asymmetric pivot manipulation for picking up rigid\nhollow objects to achieve a hole grasp. The pivot motion, executed by a\nposition-controlled robotic arm, enables the gripper to effectively grasp\nhollow objects placed horizontally such that one gripper finger is positioned\ninside the object's hole, while the other contacts its outer surface along the\nlength. Hole grasp is widely employed by humans to manipulate hollow objects,\nfacilitating precise placement and enabling efficient subsequent operations,\nsuch as tightly packing objects into trays or accurately inserting them into\nnarrow machine slots in manufacturing processes. Asymmetric pivoting for hole\ngrasping is applicable to hollow objects of various sizes and hole shapes,\nincluding bottles, cups, and ducts. We investigate the variable parameters that\nsatisfy the force balance conditions for successful grasping configurations.\nOur method can be implemented using a commercially available parallel-jaw\ngripper installed directly on a robot arm without modification. Experimental\nverification confirmed that hole grasp can be achieved using our proposed\nasymmetric pivot manipulation for various hollow objects, demonstrating a high\nsuccess rate. Two use cases, namely aligning and feeding hollow cylindrical\nobjects, were experimentally demonstrated on the testbed to clearly showcase\nthe advantages of the hole grasp approach.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T04:24:16Z"}
{"aid":"http://arxiv.org/abs/2504.05677v1","title":"Noisy Deep Ensemble: Accelerating Deep Ensemble Learning via Noise\n  Injection","summary":"Neural network ensembles is a simple yet effective approach for enhancing\ngeneralization capabilities. The most common method involves independently\ntraining multiple neural networks initialized with different weights and then\naveraging their predictions during inference. However, this approach increases\ntraining time linearly with the number of ensemble members. To address this\nissue, we propose the novel ``\\textbf{Noisy Deep Ensemble}'' method,\nsignificantly reducing the training time required for neural network ensembles.\nIn this method, a \\textit{parent model} is trained until convergence, and then\nthe weights of the \\textit{parent model} are perturbed in various ways to\nconstruct multiple \\textit{child models}. This perturbation of the\n\\textit{parent model} weights facilitates the exploration of different local\nminima while significantly reducing the training time for each ensemble member.\nWe evaluated our method using diverse CNN architectures on CIFAR-10 and\nCIFAR-100 datasets, surpassing conventional efficient ensemble methods and\nachieving test accuracy comparable to standard ensembles. Code is available at\n\\href{https://github.com/TSTB-dev/NoisyDeepEnsemble}{https://github.com/TSTB-dev/NoisyDeepEnsemble}","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T04:36:39Z"}
{"aid":"http://arxiv.org/abs/2504.05683v1","title":"Towards Smarter Hiring: Are Zero-Shot and Few-Shot Pre-trained LLMs\n  Ready for HR Spoken Interview Transcript Analysis?","summary":"This research paper presents a comprehensive analysis of the performance of\nprominent pre-trained large language models (LLMs), including GPT-4 Turbo,\nGPT-3.5 Turbo, text-davinci-003, text-babbage-001, text-curie-001,\ntext-ada-001, llama-2-7b-chat, llama-2-13b-chat, and llama-2-70b-chat, in\ncomparison to expert human evaluators in providing scores, identifying errors,\nand offering feedback and improvement suggestions to candidates during mock HR\n(Human Resources) interviews. We introduce a dataset called HURIT (Human\nResource Interview Transcripts), which comprises 3,890 HR interview transcripts\nsourced from real-world HR interview scenarios. Our findings reveal that\npre-trained LLMs, particularly GPT-4 Turbo and GPT-3.5 Turbo, exhibit\ncommendable performance and are capable of producing evaluations comparable to\nthose of expert human evaluators. Although these LLMs demonstrate proficiency\nin providing scores comparable to human experts in terms of human evaluation\nmetrics, they frequently fail to identify errors and offer specific actionable\nadvice for candidate performance improvement in HR interviews. Our research\nsuggests that the current state-of-the-art pre-trained LLMs are not fully\nconducive for automatic deployment in an HR interview assessment. Instead, our\nfindings advocate for a human-in-the-loop approach, to incorporate manual\nchecks for inconsistencies and provisions for improving feedback quality as a\nmore suitable strategy.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-08T04:46:10Z"}
{"aid":"http://arxiv.org/abs/2504.05687v1","title":"Radial Isotropic Position via an Implicit Newton's Method","summary":"Placing a dataset $A = \\{\\mathbf{a}_i\\}_{i \\in [n]} \\subset \\mathbb{R}^d$ in\nradial isotropic position, i.e., finding an invertible $\\mathbf{R} \\in\n\\mathbb{R}^{d \\times d}$ such that the unit vectors $\\{(\\mathbf{R}\n\\mathbf{a}_i) \\|\\mathbf{R} \\mathbf{a}_i\\|_2^{-1}\\}_{i \\in [n]}$ are in\nisotropic position, is a powerful tool with applications in functional\nanalysis, communication complexity, coding theory, and the design of learning\nalgorithms. When the transformed dataset has a second moment matrix within a\n$\\exp(\\pm \\epsilon)$ factor of a multiple of $\\mathbf{I}_d$, we call\n$\\mathbf{R}$ an $\\epsilon$-approximate Forster transform.\n  We give a faster algorithm for computing approximate Forster transforms,\nbased on optimizing an objective defined by Barthe [Barthe98]. When the\ntransform has a polynomially-bounded aspect ratio, our algorithm uses\n$O(nd^{\\omega - 1}(\\frac n \\epsilon)^{o(1)})$ time to output an\n$\\epsilon$-approximate Forster transform with high probability, when one\nexists. This is almost the natural limit of this approach, as even evaluating\nBarthe's objective takes $O(nd^{\\omega - 1})$ time. Previously, the\nstate-of-the-art runtime in this regime was based on cutting-plane methods, and\nscaled at least as $\\approx n^3 + n^2 d^{\\omega - 1}$. We also provide explicit\nestimates on the aspect ratio in the smoothed analysis setting, and show that\nour algorithm similarly improves upon those in the literature.\n  To obtain our results, we develop a subroutine of potential broader interest:\na reduction from almost-linear time sparsification of graph Laplacians to the\nability to support almost-linear time matrix-vector products. We combine this\ntool with new stability bounds on Barthe's objective to implicitly implement a\nbox-constrained Newton's method [CMTV17, ALOW17].","main_category":"cs.DS","categories":"cs.DS,math.OC","published":"2025-04-08T05:00:28Z"}
{"aid":"http://arxiv.org/abs/2504.05688v1","title":"First and Second Fundamental Theorems for Invariant Rings Generated by\n  Circulant Determinants","summary":"In this paper, we give the first and second fundamental theorems of invariant\ntheory for certain invariant rings whose generators are expressed by circulant\ndeterminants.","main_category":"math.RT","categories":"math.RT,math.GR,math.RA","published":"2025-04-08T05:17:41Z"}
{"aid":"http://arxiv.org/abs/2504.05698v1","title":"Point-based Instance Completion with Scene Constraints","summary":"Recent point-based object completion methods have demonstrated the ability to\naccurately recover the missing geometry of partially observed objects. However,\nthese approaches are not well-suited for completing objects within a scene, as\nthey do not consider known scene constraints (e.g., other observed surfaces) in\ntheir completions and further expect the partial input to be in a canonical\ncoordinate system, which does not hold for objects within scenes. While\ninstance scene completion methods have been proposed for completing objects\nwithin a scene, they lag behind point-based object completion methods in terms\nof object completion quality and still do not consider known scene constraints\nduring completion. To overcome these limitations, we propose a point\ncloud-based instance completion model that can robustly complete objects at\narbitrary scales and pose in the scene. To enable reasoning at the scene level,\nwe introduce a sparse set of scene constraints represented as point clouds and\nintegrate them into our completion model via a cross-attention mechanism. To\nevaluate the instance scene completion task on indoor scenes, we further build\na new dataset called ScanWCF, which contains labeled partial scans as well as\naligned ground truth scene completions that are watertight and collision-free.\nThrough several experiments, we demonstrate that our method achieves improved\nfidelity to partial scans, higher completion quality, and greater plausibility\nover existing state-of-the-art methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T05:41:49Z"}
{"aid":"http://arxiv.org/abs/2504.05702v1","title":"Evaluating Speech-to-Text Systems with PennSound","summary":"A random sample of nearly 10 hours of speech from PennSound, the world's\nlargest online collection of poetry readings and discussions, was used as a\nbenchmark to evaluate several commercial and open-source speech-to-text\nsystems. PennSound's wide variation in recording conditions and speech styles\nmakes it a good representative for many other untranscribed audio collections.\nReference transcripts were created by trained annotators, and system\ntranscripts were produced from AWS, Azure, Google, IBM, NeMo, Rev.ai, Whisper,\nand Whisper.cpp. Based on word error rate, Rev.ai was the top performer, and\nWhisper was the top open source performer (as long as hallucinations were\navoided). AWS had the best diarization error rates among three systems.\nHowever, WER and DER differences were slim, and various tradeoffs may motivate\nchoosing different systems for different end users. We also examine the issue\nof hallucinations in Whisper. Users of Whisper should be cautioned to be aware\nof runtime options, and whether the speed vs accuracy trade off is acceptable.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T05:49:53Z"}
{"aid":"http://arxiv.org/abs/2504.05728v1","title":"AI-Driven Prognostics for State of Health Prediction in Li-ion\n  Batteries: A Comprehensive Analysis with Validation","summary":"This paper presents a comprehensive review of AI-driven prognostics for State\nof Health (SoH) prediction in lithium-ion batteries. We compare the\neffectiveness of various AI algorithms, including FFNN, LSTM, and BiLSTM,\nacross multiple datasets (CALCE, NASA, UDDS) and scenarios (e.g., varying\ntemperatures and driving conditions). Additionally, we analyze the factors\ninfluencing SoH fluctuations, such as temperature and charge-discharge rates,\nand validate our findings through simulations. The results demonstrate that\nBiLSTM achieves the highest accuracy, with an average RMSE reduction of 15%\ncompared to LSTM, highlighting its robustness in real-world applications.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-08T06:58:39Z"}
{"aid":"http://arxiv.org/abs/2504.05729v1","title":"Robust and Efficient Average Consensus with Non-Coherent Over-the-Air\n  Aggregation","summary":"Non-coherent over-the-air (OTA) computation has garnered increasing attention\nfor its advantages in facilitating information aggregation among distributed\nagents in resource-constrained networks without requiring precise channel\nestimation. A promising application scenario of this method is distributed\naverage consensus in wireless multi-agent systems. However, in such scenario,\nnon-coherent interference from concurrent OTA transmissions can introduce bias\nin the consensus value. To address this issue, we develop a robust distributed\naverage consensus algorithm by formulating the consensus problem as a\ndistributed optimization problem. Using decentralized projected gradient\ndescent (D-PGD), our proposed algorithm can achieve unbiased mean square\naverage consensus even in the presence of non-coherent interference and noise.\nAdditionally, we implement transmit power control and receive scaling\nmechanisms to further accelerate convergence. Simulation results demonstrate\nthat our method can significantly enhance the convergence speed of the D-PGD\nalgorithm for OTA average consensus without compromising accuracy.","main_category":"cs.IT","categories":"cs.IT,cs.SY,eess.SP,eess.SY,math.IT","published":"2025-04-08T07:03:02Z"}
{"aid":"http://arxiv.org/abs/2504.05730v1","title":"Unified Generative Search and Recommendation","summary":"Modern commercial platforms typically offer both search and recommendation\nfunctionalities to serve diverse user needs, making joint modeling of these\ntasks an appealing direction. While prior work has shown that integrating\nsearch and recommendation can be mutually beneficial, it also reveals a\nperformance trade-off: enhancements in one task often come at the expense of\nthe other. This challenge arises from their distinct information requirements:\nsearch emphasizes semantic relevance between queries and items, whereas\nrecommendation depends more on collaborative signals among users and items.\nEffectively addressing this trade-off requires tackling two key problems: (1)\nintegrating both semantic and collaborative signals into item representations,\nand (2) guiding the model to distinguish and adapt to the unique demands of\nsearch and recommendation. The emergence of generative retrieval with Large\nLanguage Models (LLMs) presents new possibilities. This paradigm encodes items\nas identifiers and frames both search and recommendation as sequential\ngeneration tasks, offering the flexibility to leverage multiple identifiers and\ntask-specific prompts. In light of this, we introduce GenSAR, a unified\ngenerative framework for balanced search and recommendation. Our approach\ndesigns dual-purpose identifiers and tailored training strategies to\nincorporate complementary signals and align with task-specific objectives.\nExperiments on both public and commercial datasets demonstrate that GenSAR\neffectively reduces the trade-off and achieves state-of-the-art performance on\nboth tasks.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-08T07:03:08Z"}
{"aid":"http://arxiv.org/abs/2504.05736v1","title":"Rank-Then-Score: Enhancing Large Language Models for Automated Essay\n  Scoring","summary":"In recent years, large language models (LLMs) achieve remarkable success\nacross a variety of tasks. However, their potential in the domain of Automated\nEssay Scoring (AES) remains largely underexplored. Moreover, compared to\nEnglish data, the methods for Chinese AES is not well developed. In this paper,\nwe propose Rank-Then-Score (RTS), a fine-tuning framework based on large\nlanguage models to enhance their essay scoring capabilities. Specifically, we\nfine-tune the ranking model (Ranker) with feature-enriched data, and then feed\nthe output of the ranking model, in the form of a candidate score set, with the\nessay content into the scoring model (Scorer) to produce the final score.\nExperimental results on two benchmark datasets, HSK and ASAP, demonstrate that\nRTS consistently outperforms the direct prompting (Vanilla) method in terms of\naverage QWK across all LLMs and datasets, and achieves the best performance on\nChinese essay scoring using the HSK dataset.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-08T07:10:51Z"}
{"aid":"http://arxiv.org/abs/2504.05748v1","title":"When Less Is More: A Sparse Facial Motion Structure For Listening Motion\n  Learning","summary":"Effective human behavior modeling is critical for successful human-robot\ninteraction. Current state-of-the-art approaches for predicting listening head\nbehavior during dyadic conversations employ continuous-to-discrete\nrepresentations, where continuous facial motion sequence is converted into\ndiscrete latent tokens. However, non-verbal facial motion presents unique\nchallenges owing to its temporal variance and multi-modal nature.\nState-of-the-art discrete motion token representation struggles to capture\nunderlying non-verbal facial patterns making training the listening head\ninefficient with low-fidelity generated motion. This study proposes a novel\nmethod for representing and predicting non-verbal facial motion by encoding\nlong sequences into a sparse sequence of keyframes and transition frames. By\nidentifying crucial motion steps and interpolating intermediate frames, our\nmethod preserves the temporal structure of motion while enhancing instance-wise\ndiversity during the learning process. Additionally, we apply this novel sparse\nrepresentation to the task of listening head prediction, demonstrating its\ncontribution to improving the explanation of facial motion patterns.","main_category":"cs.CV","categories":"cs.CV,cs.HC","published":"2025-04-08T07:25:12Z"}
{"aid":"http://arxiv.org/abs/2504.05753v1","title":"Accelerated Natural Gradient Method for Parametric Manifold Optimization","summary":"Parametric manifold optimization problems frequently arise in various machine\nlearning tasks, where state functions are defined on infinite-dimensional\nmanifolds. We propose a unified accelerated natural gradient descent (ANGD)\nframework to address these problems. By incorporating a Hessian-driven damping\nterm into the manifold update, we derive an accelerated Riemannian gradient\n(ARG) flow that mitigates oscillations. An equivalent first-order system is\nfurther presented for the ARG flow, enabling a unified discretization scheme\nthat leads to the ANGD method. In our discrete update, our framework considers\nvarious advanced techniques, including least squares approximation of the\nupdate direction, projected momentum to accelerate convergence, and efficient\napproximation methods through the Kronecker product. It accommodates various\nmetrics, including $H^s$, Fisher-Rao, and Wasserstein-2 metrics, providing a\ncomputationally efficient solution for large-scale parameter spaces. We\nestablish a convergence rate for the ARG flow under geodesic convexity\nassumptions. Numerical experiments demonstrate that ANGD outperforms standard\nNGD, underscoring its effectiveness across diverse deep learning tasks.","main_category":"math.OC","categories":"math.OC","published":"2025-04-08T07:33:04Z"}
{"aid":"http://arxiv.org/abs/2504.05759v1","title":"RETROcode: Leveraging a Code Database for Improved Natural Language to\n  Code Generation","summary":"As text and code resources have expanded, large-scale pre-trained models have\nshown promising capabilities in code generation tasks, typically employing\nsupervised fine-tuning with problem statement-program pairs. However,\nincreasing model size and data volume for performance gains also raises\ncomputational demands and risks of overfitting. Addressing these challenges, we\npresent RETROcode, a novel adaptation of the RETRO architecture \\cite{RETRO}\nfor sequence-to-sequence models, utilizing a large code database as an\nauxiliary scaling method. This approach, diverging from simply enlarging model\nand dataset sizes, allows RETROcode to leverage a vast code database for\nprediction, enhancing the model's efficiency by integrating extensive memory.\nOur findings indicate that RETROcode not only outperforms similar-sized\ntraditional architectures on test sets but also approaches the effectiveness of\nthe much larger Codex model, despite being trained from scratch on a\nsubstantially smaller dataset.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T07:41:13Z"}
{"aid":"http://arxiv.org/abs/2504.05770v1","title":"A Lightweight Multi-Module Fusion Approach for Korean Character\n  Recognition","summary":"Optical Character Recognition (OCR) is essential in applications such as\ndocument processing, license plate recognition, and intelligent surveillance.\nHowever, existing OCR models often underperform in real-world scenarios due to\nirregular text layouts, poor image quality, character variability, and high\ncomputational costs.\n  This paper introduces SDA-Net (Stroke-Sensitive Attention and Dynamic Context\nEncoding Network), a lightweight and efficient architecture designed for robust\nsingle-character recognition. SDA-Net incorporates: (1) a Dual Attention\nMechanism to enhance stroke-level and spatial feature extraction; (2) a Dynamic\nContext Encoding module that adaptively refines semantic information using a\nlearnable gating mechanism; (3) a U-Net-inspired Feature Fusion Strategy for\ncombining low-level and high-level features; and (4) a highly optimized\nlightweight backbone that reduces memory and computational demands.\n  Experimental results show that SDA-Net achieves state-of-the-art accuracy on\nchallenging OCR benchmarks, with significantly faster inference, making it\nwell-suited for deployment in real-time and edge-based OCR systems.","main_category":"cs.CV","categories":"cs.CV,cs.AI,I.2.10","published":"2025-04-08T07:50:19Z"}
{"aid":"http://arxiv.org/abs/2504.05797v1","title":"Possible existence of pygmy dipole resonance built on excited states in\n  a neutron-rich $^{80}$Ge nucleus","summary":"The pygmy dipole resonance (PDR) at the low-lying tail of the giant dipole\nresonance (GDR) is an interesting research subject as it carries important\ninformation about the nuclear surface with mixed isoscalar and isovector\nvibrations in $N > Z$ systems. The present paper investigates the possible\nexistence of the PDR built on excited states in a neutron-rich $^{80}$Ge\nnucleus using the phonon damping model (PDM) with and without pairing\ncorrelation at zero and finite temperatures. The results obtained within the\nPDM with exact pairing (EP+PDM) reveal the appearance of two enhanced\n$\\gamma$-transitions $E_\\gamma = 7.25$ and 7.35 MeV at $T=0.6$ MeV, which carry\nthe PDR nature and hence implying the possible existence of PDR built on\nexcited states in this nucleus. These two $\\gamma$-energies nicely match with a\nrecent experimental observation, thus indicating the crucial role of the\ninclusion of exact pairing solution in the precise description of low-lying\n$\\gamma$-transitions. The partition function-based analysis shows that this\npredicted PDR at $T=$ 0.6MeV is mainly contributed by the first $2^+$ excited\nstate of the $^{80}$Ge nucleus. The isospin mixing at the nuclear surface is\nalso observed in the investigated PDR at $T=0.6-0.7$ MeV. The primary mechanism\nunderlying the emergence of the hot PDR is found due to the coupling of GDR\nphonon to non-collective particle-particle and hole-hole configurations at\nfinite temperatures within the PDM framework, along with the shift in\nparticle-hole excitation energies due to thermal pairing correlations","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-08T08:23:37Z"}
{"aid":"http://arxiv.org/abs/2504.05806v1","title":"Meta-Continual Learning of Neural Fields","summary":"Neural Fields (NF) have gained prominence as a versatile framework for\ncomplex data representation. This work unveils a new problem setting termed\n\\emph{Meta-Continual Learning of Neural Fields} (MCL-NF) and introduces a novel\nstrategy that employs a modular architecture combined with optimization-based\nmeta-learning. Focused on overcoming the limitations of existing methods for\ncontinual learning of neural fields, such as catastrophic forgetting and slow\nconvergence, our strategy achieves high-quality reconstruction with\nsignificantly improved learning speed. We further introduce Fisher Information\nMaximization loss for neural radiance fields (FIM-NeRF), which maximizes\ninformation gains at the sample level to enhance learning generalization, with\nproved convergence guarantee and generalization bound. We perform extensive\nevaluations across image, audio, video reconstruction, and view synthesis tasks\non six diverse datasets, demonstrating our method's superiority in\nreconstruction quality and speed over existing MCL and CL-NF approaches.\nNotably, our approach attains rapid adaptation of neural fields for city-scale\nNeRF rendering with reduced parameter requirement.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-08T08:38:37Z"}
{"aid":"http://arxiv.org/abs/2504.05818v1","title":"Proper constituent gluon mass as the final piece to construct hybrid","summary":"After treating hybrid as a three-body system, we recalculate the spectra and\ndecay widths of the $1^{-+}$ light hybrids via the Gauss Expansion Method\n(GEM). Our result shows that, after adding into only one more parameter\n$m_g$=450 MeV, i.e., the constituent gluon mass, we can reproduce nearly all\nthe results in our previous work by just using the model parameters from meson\nspectra calculation, which shows the unification of Quantum Chromodynamics\n(QCD). As a result, $\\pi_1(1600)$ and $\\eta_1(1855)$ may not be explained as\n$1^{-+}$ hybrids simultaneously, and the $\\eta_1(1855)$ observed by BESIII may\nnot be a hybrid. In addition, we predict an existence of a hybrid\n$\\eta_1(1640)$, which can be verified by searching the $a_1(1260)\\pi$ channel.\nFurthermore, to search for an isospin-0 and an isospin-$\\frac{1}{2}$ hybrid,\nthe golden channels may be $K_1(1270)\\bar{K}$ and $K_1(1270)\\pi$, respectively.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-08T09:01:14Z"}
{"aid":"http://arxiv.org/abs/2504.05831v1","title":"Leveraging Robust Optimization for LLM Alignment under Distribution\n  Shifts","summary":"Large language models (LLMs) increasingly rely on preference alignment\nmethods to steer outputs toward human values, yet these methods are often\nconstrained by the scarcity of high-quality human-annotated data. To tackle\nthis, recent approaches have turned to synthetic data generated by LLMs as a\nscalable alternative. However, synthetic data can introduce distribution\nshifts, compromising the nuanced human preferences that are essential for\ndesirable outputs. In this paper, we propose a novel distribution-aware\noptimization framework that improves preference alignment in the presence of\nsuch shifts. Our approach first estimates the likelihood ratios between the\ntarget and training distributions leveraging a learned classifier, then it\nminimizes the worst-case loss over data regions that reflect the target\nhuman-preferred distribution. By explicitly prioritizing the target\ndistribution during optimization, our method mitigates the adverse effects of\ndistributional variation and enhances the generation of responses that\nfaithfully reflect human values.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T09:14:38Z"}
{"aid":"http://arxiv.org/abs/2504.05833v1","title":"AVENet: Disentangling Features by Approximating Average Features for\n  Voice Conversion","summary":"Voice conversion (VC) has made progress in feature disentanglement, but it is\nstill difficult to balance timbre and content information. This paper evaluates\nthe pre-trained model features commonly used in voice conversion, and proposes\nan innovative method for disentangling speech feature representations.\nSpecifically, we first propose an ideal content feature, referred to as the\naverage feature, which is calculated by averaging the features within\nframe-level aligned parallel speech (FAPS) data. For generating FAPS data, we\nutilize a technique that involves freezing the duration predictor in a\nText-to-Speech system and manipulating speaker embedding. To fit the average\nfeature on traditional VC datasets, we then design the AVENet to take features\nas input and generate closely matching average features. Experiments are\nconducted on the performance of AVENet-extracted features within a VC system.\nThe experimental results demonstrate its superiority over multiple current\nspeech feature disentangling methods. These findings affirm the effectiveness\nof our disentanglement approach.","main_category":"cs.SD","categories":"cs.SD","published":"2025-04-08T09:16:32Z"}
{"aid":"http://arxiv.org/abs/2504.05835v1","title":"Scalar-assisted magnetogenesis during the radiation-dominated epoch","summary":"We propose a novel mechanism to generate primordial magnetic fields (PMFs)\nstrong enough to explain the observed cosmic magnetic fields. We employ a\nscalar field charged under U(1) gauge symmetry with a non-trivial VEV to\nprovide an effective mass term to the EM field and thus break its conformal\ninvariance. The primordial magneto-genesis takes place in the radiation\ndominated (RD) epoch, after the electroweak symmetry breaking (EWSB) phase. As\na result, our mechanism is naturally free from the over-production of electric\nfields due to high conductivity in the RD epoch, and the baryon isocurvature\nproblem which takes place only if magneto-genesis happens before the ESWB\nphase. In addition, we find that a significant amount of PMFs can be generated\nwhen the scalar field experiences a tachyonic phase. In this case, the scalar\nfield is light and weakly coupled and has negligible energy density compared to\nthe cold dark matter, hence the strong coupling problem and the back-reaction\nproblem are also absent. Therefore, our model is free from the above-mentioned\nproblems that frequently appear in other primordial magneto-genesis scenarios.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO,gr-qc","published":"2025-04-08T09:18:30Z"}
{"aid":"http://arxiv.org/abs/2504.05837v1","title":"Derivation of Kirchhoff-type plate theories for elastic materials with\n  voids","summary":"We rigorously derive a Blake-Zisserman-Kirchhoff theory for thin plates with\nmaterial voids, starting from a three-dimensional model with elastic bulk and\ninterfacial energy featuring a Willmore-type curvature penalization. The\neffective two-dimensional model comprises a classical elastic bending energy\nand surface terms which reflect the possibility that voids can persist in the\nlimit, that the limiting plate can be broken apart into several pieces, or that\nthe plate can be folded. Building upon and extending the techniques used in the\nauthors' recent work on the derivation of one-dimensional theories for thin\nbrittle rods with voids, the present contribution generalizes the results of\nSantili and Schmidt (2022), by considering general geometries on the admissible\nset of voids and constructing recovery sequences for all admissible limiting\nconfigurations.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T09:19:37Z"}
{"aid":"http://arxiv.org/abs/2504.05847v1","title":"Réduire le bruit grâce à la réalité augmentée sonore --\n  Auditory Concealer","summary":"This report presents the work done over 22 weeks of internship within the\nSound Perception and Design team of the Sciences and Technologies of Music and\nSound (STMS) laboratory at the Institute for Research and Coordination in\nAcoustics/Music (IRCAM). As part of the launch of the project Reducing Noise\nwith Augmented Reality (ReNAR); which aims to create a tool to reduce in\nreal-time the cognitive impact of sounds perceived as unpleasant or annoying in\nindoor environments; an initial study was conducted to validate the feasibility\nand effectiveness of a new masking approach called concealer. The main\nhypothesis is that the concealer approach could provide better results than a\nmasker approach in terms of perceived pleasantness. Mixtures of two noise\nsources (ventilation) and five masking sounds (water sounds) were generated\nusing both approaches at various levels. The evaluation of the perceived\npleasantness of these mixtures showed that the masker approach remains more\neffective than the concealer approach, regardless of the noise source, water\nsound, or level used.","main_category":"cs.SD","categories":"cs.SD,eess.AS","published":"2025-04-08T09:27:07Z"}
{"aid":"http://arxiv.org/abs/2504.05863v1","title":"Extending Parametric Model Embedding with Physical Information for\n  Design-space Dimensionality Reduction in Shape Optimization","summary":"In this work, an extension of the parametric model embedding (PME) approach\nis presented, aiming to achieve more effective design-space dimensionality\nreduction for shape optimization in vehicle design. PME, rooted in principal\ncomponent analysis (PCA), not only identifies a reduced set of critical modes\nbut also re-parameterizes the original design space, enabling direct and\ninterpretable manipulations of shape modifications within the reduced space.\nAlongside the \"physics-informed\" version (PI-PME), which enriches geometry with\nlow-fidelity distributed and lumped physical quantities, a \"physics-driven\"\nvariant (PD-PME) is introduced that focuses exclusively on physical parameters.\nBoth formulations employ PCA to capture the principal modes of variability yet\ndiffer in their balance between geometric and physical information, through the\nad-hoc definition of a weighted inner product. Through test cases involving the\nRAE-2822 airfoil, a bio-inspired underwater glider, a naval propeller, and the\nDTMB-5415 destroyer-type vessel, it is shown how the resulting frameworks\nprovide a first-level assessment of design variability, offer interpretability\nregarding which original variables most strongly affect performance, and\nefficiently bridge geometric and physical parameters. Furthermore, lumped\nphysical parameters can serve as a low-fidelity foundation for multi-fidelity\noptimization, directly leveraging the linear re-parameterization to drive the\nreduced design variables. Meanwhile, distributed physical parameters enable the\nconstruction of machine-learning-based reduced-order models to infer integral\nquantities of interest. By allowing the user to embed these insights early in\nthe design process, PI-PME and PD-PME facilitate more robust, cost-effective\nexploration, paving the way for subsequent high-fidelity optimization.","main_category":"math.OC","categories":"math.OC","published":"2025-04-08T09:43:41Z"}
{"aid":"http://arxiv.org/abs/2504.05866v1","title":"CTI-HAL: A Human-Annotated Dataset for Cyber Threat Intelligence\n  Analysis","summary":"Organizations are increasingly targeted by Advanced Persistent Threats\n(APTs), which involve complex, multi-stage tactics and diverse techniques.\nCyber Threat Intelligence (CTI) sources, such as incident reports and security\nblogs, provide valuable insights, but are often unstructured and in natural\nlanguage, making it difficult to automatically extract information. Recent\nstudies have explored the use of AI to perform automatic extraction from CTI\ndata, leveraging existing CTI datasets for performance evaluation and\nfine-tuning. However, they present challenges and limitations that impact their\neffectiveness. To overcome these issues, we introduce a novel dataset manually\nconstructed from CTI reports and structured according to the MITRE ATT&CK\nframework. To assess its quality, we conducted an inter-annotator agreement\nstudy using Krippendorff alpha, confirming its reliability. Furthermore, the\ndataset was used to evaluate a Large Language Model (LLM) in a real-world\nbusiness context, showing promising generalizability.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-08T09:47:15Z"}
{"aid":"http://arxiv.org/abs/2504.05872v1","title":"On free line arrangements with double, triple and quadruple points","summary":"We show that there are only finitely many combinatorial types of free real\nline arrangements with only double, triple and quadruple intersection points,\nand we enlist all admissible weak-combinatorics of them. Then we classify all\nreal $M$-line arrangements. In particular, we show that real $M$-line\narrangements are simplicial.","main_category":"math.AG","categories":"math.AG,math.CO","published":"2025-04-08T09:56:51Z"}
{"aid":"http://arxiv.org/abs/2504.05883v1","title":"Rolling Horizon Coverage Control with Collaborative Autonomous Agents","summary":"This work proposes a coverage controller that enables an aerial team of\ndistributed autonomous agents to collaboratively generate non-myopic coverage\nplans over a rolling finite horizon, aiming to cover specific points on the\nsurface area of a 3D object of interest. The collaborative coverage problem,\nformulated, as a distributed model predictive control problem, optimizes the\nagents' motion and camera control inputs, while considering inter-agent\nconstraints aiming at reducing work redundancy. The proposed coverage\ncontroller integrates constraints based on light-path propagation techniques to\npredict the parts of the object's surface that are visible with regard to the\nagents' future anticipated states. This work also demonstrates how complex,\nnon-linear visibility assessment constraints can be converted into logical\nexpressions that are embedded as binary constraints into a mixed-integer\noptimization framework. The proposed approach has been demonstrated through\nsimulations and practical applications for inspecting buildings with unmanned\naerial vehicles (UAVs).","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T10:17:38Z"}
{"aid":"http://arxiv.org/abs/2504.05897v1","title":"HybriMoE: Hybrid CPU-GPU Scheduling and Cache Management for Efficient\n  MoE Inference","summary":"The Mixture of Experts (MoE) architecture has demonstrated significant\nadvantages as it enables to increase the model capacity without a proportional\nincrease in computation. However, the large MoE model size still introduces\nsubstantial memory demands, which usually requires expert offloading on\nresource-constrained platforms and incurs significant overhead. Hybrid CPU-GPU\ninference has been proposed to leverage CPU computation to reduce expert\nloading overhead but faces major challenges: on one hand, the expert activation\npatterns of MoE models are highly unstable, rendering the fixed mapping\nstrategies in existing works inefficient; on the other hand, the hybrid CPU-GPU\nschedule for MoE is inherently complex due to the diverse expert sizes,\nstructures, uneven workload distribution, etc. To address these challenges, in\nthis paper, we propose HybriMoE, a hybrid CPU-GPU inference framework that\nimproves resource utilization through a novel CPU-GPU scheduling and cache\nmanagement system. HybriMoE introduces (i) a dynamic intra-layer scheduling\nstrategy to balance workloads across CPU and GPU, (ii) an impact-driven\ninter-layer prefetching algorithm, and (iii) a score-based caching algorithm to\nmitigate expert activation instability. We implement HybriMoE on top of the\nkTransformers framework and evaluate it on three widely used MoE-based LLMs.\nExperimental results demonstrate that HybriMoE achieves an average speedup of\n1.33$\\times$ in the prefill stage and 1.70$\\times$ in the decode stage compared\nto state-of-the-art hybrid MoE inference framework. Our code is available at:\nhttps://github.com/PKU-SEC-Lab/HybriMoE.","main_category":"cs.LG","categories":"cs.LG,cs.DC","published":"2025-04-08T10:47:37Z"}
{"aid":"http://arxiv.org/abs/2504.05899v1","title":"Spatially Resolved Optical Responses of a High-Kinetic-Inductance\n  Microwave Resonator","summary":"Understanding the optical response of a high-kinetic-inductance microwave\nresonator is crucial for applications ranging from single-photon detection to\nquantum transduction between microwave and optical domains, which is gaining\nsignificant attention for scaling up quantum computers. However, interactions\nbetween the pump light and the superconducting resonator often induce\nunintended resonance frequency shifts and linewidth broadening. In this study,\nwe measure the local optical response of a NbTiN nanowire resonator using a\nlaser-scanning microwave spectroscopy system integrated with a dilution\nrefrigerator. The optical response of the resonator shows correlation with the\nresonance modes and position, which is attributed to the two-level system\naround the resonator. These findings not only contribute to the design and\nunderstanding of quantum transducers and single-photon detectors, but also to\nthe understandings of catastrophic high-energy particle irradiation events that\ngenerate unintended phonons in quantum devices.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T10:51:26Z"}
{"aid":"http://arxiv.org/abs/2504.05963v1","title":"Learning Verified Monitors for Hidden~Markov~Models","summary":"Runtime monitors assess whether a system is in an unsafe state based on a\nstream of observations. We study the problem where the system is subject to\nprobabilistic uncertainty and described by a hidden Markov model. A stream of\nobservations is then unsafe if the probability of being in an unsafe state is\nabove a threshold. A correct monitor recognizes the set of unsafe observations.\nThe key contribution of this paper is the first correct-by-construction\nsynthesis method for such monitors, represented as finite automata. The\ncontribution combines four ingredients: First, we establish the coNP-hardness\nof checking whether an automaton is a correct monitor, i.e., a monitor without\nmisclassifications. Second, we provide a reduction that reformulates the search\nfor misclassifications into a standard probabilistic system synthesis problem.\nThird, we integrate the verification routine into an active automata learning\nroutine to synthesize correct monitors. Fourth, we provide a prototypical\nimplementation that shows the feasibility and limitations of the approach on a\nseries of benchmarks.","main_category":"cs.FL","categories":"cs.FL,cs.LO","published":"2025-04-08T12:23:20Z"}
{"aid":"http://arxiv.org/abs/2504.05973v1","title":"The Primitive Ideal Space of $C(X) \\rtimes \\mathbb{N}$","summary":"We describe the primitive ideal spaces and the Jacobson topologies of a\nspecial class of topological graph algebras.","main_category":"math.OA","categories":"math.OA","published":"2025-04-08T12:30:28Z"}
{"aid":"http://arxiv.org/abs/2504.06002v1","title":"Has ACT measured radiative corrections to the tree-level Higgs-like\n  inflation?","summary":"Starobinsky inflation and non-minimally coupled Higgs inflation have been\namong the most favored models of the early universe, as their predictions for\nthe scalar spectral index $n_s$ and tensor-to-scalar ratio $r$ fall comfortably\nwithin the constraints set by Planck and BICEP/Keck. However, new results from\nthe Atacama Cosmology Telescope (ACT) suggest a preference for higher values of\n$n_s$, introducing tension with the simplest realizations of these models. In\nthis work, being agnostic about the nature of the inflaton, we show that\nincorporating one-loop corrections to a Higgs-like inflationary scenario leads\nto a shift in the predicted value of $n_s$, which brings Higgs-like inflation\ninto better agreement with ACT observations. Remarkably, we find that this can\nbe achieved with non-minimal couplings $\\xi < 1$, in contrast to the large\nvalues typically required in conventional Higgs inflation, thereby pushing any\nunitarity-violation scale above the Planck scale. The effect is even more\nsignificant when the model is formulated in the Palatini approach, where the\nmodified field-space structure naturally enhances deviations from the metric\ncase. These findings highlight the importance of quantum corrections and\ngravitational degrees of freedom in refining inflationary predictions in light\nof new data.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph","published":"2025-04-08T13:11:58Z"}
{"aid":"http://arxiv.org/abs/2504.06026v1","title":"Taking out the Toxic Trash: Recovering Precision in Mixed Flow-Sensitive\n  Static Analyses","summary":"Static analysis of real-world programs combines flow- and context-sensitive\nanalyses of local program states with computation of flow- and\ncontext-insensitive invariants at globals, that, e.g., abstract data shared by\nmultiple threads. The values of locals and globals may mutually depend on each\nother, with the analysis of local program states both making contributions to\nglobals and querying their values. Usually, all contributions to globals are\naccumulated during fixpoint iteration, with widening applied to enforce\ntermination. Such flow-insensitive information often becomes unnecessarily\nimprecise and can include superfluous contributions -- trash -- which, in turn,\nmay be toxic to the precision of the overall analysis. To recover precision of\nglobals, we propose techniques complementing each other: Narrowing on globals\ndifferentiates contributions by origin; reluctant widening limits the amount of\nwidening applied at globals; and finally, abstract garbage collection undoes\ncontributions to globals and propagates their withdrawal. The experimental\nevaluation shows that these techniques increase the precision of mixed\nflow-sensitive analyses at a reasonable cost.","main_category":"cs.PL","categories":"cs.PL,cs.SE","published":"2025-04-08T13:30:15Z"}
{"aid":"http://arxiv.org/abs/2504.06027v1","title":"OSDM-MReg: Multimodal Image Registration based One Step Diffusion Model","summary":"Multimodal remote sensing image registration aligns images from different\nsensors for data fusion and analysis. However, current methods often fail to\nextract modality-invariant features when aligning image pairs with large\nnonlinear radiometric differences. To address this issues, we propose\nOSDM-MReg, a novel multimodal image registration framework based image-to-image\ntranslation to eliminate the gap of multimodal images. Firstly, we propose a\nnovel one-step unaligned target-guided conditional denoising diffusion\nprobabilistic models(UTGOS-CDDPM)to translate multimodal images into a unified\ndomain. In the inference stage, traditional conditional DDPM generate\ntranslated source image by a large number of iterations, which severely slows\ndown the image registration task. To address this issues, we use the unaligned\ntraget image as a condition to promote the generation of low-frequency features\nof the translated source image. Furthermore, during the training stage, we add\nthe inverse process of directly predicting the translated image to ensure that\nthe translated source image can be generated in one step during the testing\nstage. Additionally, to supervised the detail features of translated source\nimage, we propose a new perceptual loss that focuses on the high-frequency\nfeature differences between the translated and ground-truth images. Finally, a\nmultimodal multiscale image registration network (MM-Reg) fuse the multimodal\nfeature of the unimodal images and multimodal images by proposed multimodal\nfeature fusion strategy. Experiments demonstrate superior accuracy and\nefficiency across various multimodal registration tasks, particularly for\nSAR-optical image pairs.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-08T13:32:56Z"}
{"aid":"http://arxiv.org/abs/2504.06044v1","title":"Polynomial-Time PIT from (Almost) Necessary Assumptions","summary":"The celebrated result of Kabanets and Impagliazzo (Computational Complexity,\n2004) showed that PIT algorithms imply circuit lower bounds, and vice versa.\nSince then it has been a major challenge to understand the precise connections\nbetween PIT and lower bounds. In particular, a main goal has been to understand\nwhich lower bounds suffice to obtain efficient PIT algorithms, and how close\nare they to lower bounds that are necessary for the conclusion.\n  We construct polynomial-time PIT algorithms from lower bounds that are, up to\nrelatively minor remaining gaps, necessary for the existence of such\nalgorithms. That is, we prove that these lower bounds are, up to the mentioned\nminor gaps, both sufficient and necessary for polynomial-time PIT, over fields\nof characteristic zero. Over sufficiently large finite fields, we show a\nsimilar result wherein the PIT algorithm runs in time $n^{\\log^{(c)}(n)}$, i.e.\na power of $c$-iterated log for an arbitrarily large constant $c>1$.\n  The key to these improvements is studying PIT versus lower bounds in the\nuniform setting, in which we focus on proving lower bounds for uniform\narithmetic circuits and their variants (and on deducing algorithms from such\nlower bounds). Indeed, by working in this setting we obtain results that are\nsignificantly tighter than previously known results concerning polynomial-time\nPIT vs lower bounds, and are in fact also tighter than known\nhardness-vs-randomness connections in the Boolean setting.\n  Our results are obtained by combining recent techniques from Boolean hardness\nvs randomness, and in particular the generator of Chen and Tell (FOCS 2021),\nwith the algebraic hitting-set generator of Guo, Kumar, Saptharishi, and\nSolomon (SIAM J. Computing 2022) along with the bootstrapping ideas of Agrawal,\nGhosh, and Saxena (STOC 2018) and of Kumar, Saptharishi, and Tengse (SODA\n2019).","main_category":"cs.CC","categories":"cs.CC","published":"2025-04-08T13:44:21Z"}
{"aid":"http://arxiv.org/abs/2504.06048v1","title":"Trust-Region Twisted Policy Improvement","summary":"Monte-Carlo tree search (MCTS) has driven many recent breakthroughs in deep\nreinforcement learning (RL). However, scaling MCTS to parallel compute has\nproven challenging in practice which has motivated alternative planners like\nsequential Monte-Carlo (SMC). Many of these SMC methods adopt particle filters\nfor smoothing through a reformulation of RL as a policy inference problem. Yet,\npersisting design choices of these particle filters often conflict with the aim\nof online planning in RL, which is to obtain a policy improvement at the start\nof planning. Drawing inspiration from MCTS, we tailor SMC planners specifically\nfor RL by improving data generation within the planner through constrained\naction sampling and explicit terminal state handling, as well as improving\npolicy and value target estimation. This leads to our Trust-Region Twisted SMC\n(TRT-SMC), which shows improved runtime and sample-efficiency over baseline\nMCTS and SMC methods in both discrete and continuous domains.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-08T13:47:07Z"}
{"aid":"http://arxiv.org/abs/2504.06050v1","title":"Low-loss far-infrared surface phonon polaritons in suspended SrTiO3\n  nanomembranes","summary":"Phonon polaritons (PhPs), excitations arising from the coupling of light with\nlattice vibrations, enable light confinement and local field enhancement, which\nis essential for various photonic and thermal applications. To date, PhPs with\nhigh confinement and low loss have been mainly observed in the mid-infrared\nregime and mostly in manually exfoliated flakes of van der Waals (vdW)\nmaterials. In this work, we demonstrate the existence of low-loss,\nthickness-tunable phonon polaritons in the far-infrared regime within\ntransferable free-standing SrTiO3 membranes synthesized through a scalable\napproach, achieving high figures of merit, which are comparable to the previous\nrecord values from the vdW materials. Leveraging atomic precision in thickness\ncontrol, large dimensions, and compatibility with mature oxide electronics,\nfunctional oxide membranes present a promising large-scale two-dimensional (2D)\nplatform alternative to vdW materials for on-chip polaritonic technologies in\nthe far-infrared regime.","main_category":"physics.optics","categories":"physics.optics,physics.app-ph","published":"2025-04-08T13:48:34Z"}
{"aid":"http://arxiv.org/abs/2504.06057v1","title":"Mitigating decoherence in molecular spin qudits","summary":"Molecular nanomagnets are quantum spin systems potentially serving as qudits\nfor future quantum technologies thanks to their many accessible low-energy\nstates. At low temperatures, the primary source of error in these systems is\npure dephasing, caused by their interactions with the bath of surrounding\nnuclear spins degrees of freedom. Most importantly, as the system's\ndimensionality grows going from qubits to qudits, the control and mitigation of\ndecoherence becomes more challenging. Here we analyze the characteristics of\npure dephasing in molecular qudits under spin-echo sequences. We use a\nrealistic description of their interaction with the bath, whose non-Markovian\ndynamics is accurately computed by the cluster correlation expansion technique.\nFirst, we demonstrate a necessary and sufficient condition to prevent the decay\nof coherence with time, also introducing a parameter to quantify the deviation\nfrom such ideal condition. We illustrate this with two paradigmatic systems: a\nsingle giant spin and a composite antiferromagnetic spin system. We then\nadvance a proposal for optimized nanomagnets, identifying key ingredients for\nengineering robust qudits for quantum technologies.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T14:00:52Z"}
{"aid":"http://arxiv.org/abs/2504.06061v1","title":"Non-reciprocal waves in two-dimensional electron systems with\n  temperature gradient","summary":"We demonstrate that the interaction of dc temperature gradient with ac\nmagnetic field in temperature-biased two-dimensional electron systems leads to\nformation of a new electromagnetic mode, a two-dimensional thermomagnetic wave\n(2d TMW). This wave is transverse electric and non-reciprocal, and its damping\nrate can be lower than that of conventional 2d plasma waves. The Q-factor of 2d\nTMW is independent of the wave vector. Numerical estimates show that in\nstate-of-the-art two-dimensional electrons systems the 2d TMW Q-factor is the\norder of $10^{-3}$. We discuss possible ways to overcome this issue.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-08T14:07:15Z"}
{"aid":"http://arxiv.org/abs/2504.06063v1","title":"Inclusive semileptonic decays of the $D_s$ meson: A first-principles\n  lattice QCD calculation","summary":"We present the results of a first-principles theoretical study of the\ninclusive semileptonic decays of the $D_s$ meson. We performed a\nstate-of-the-art lattice QCD calculation using the gauge ensembles produced by\nthe Extended Twisted Mass Collaboration (ETMC) with dynamical light, strange\nand charm quarks with physical masses and employed the so-called\nHansen-Lupo-Tantalo (HLT) method to extract the decay rate and the first two\nlepton-energy moments from the relevant Euclidean correlators. We have\ncarefully taken into account all sources of systematic errors, including the\nones associated with the continuum and infinite-volume extrapolations and with\nthe HLT spectral reconstruction method. We obtained results in very good\nagreement with the currently available experimental determinations and with a\ntotal accuracy at the few-percent level, of the same order of magnitude of the\nexperimental error. Our total error is dominated by the lattice QCD simulations\nstatistical uncertainties and is certainly improvable. From the results\npresented and thoroughly discussed in this paper we conclude that it is\nnowadays possible to study heavy mesons inclusive semileptonic decays on the\nlattice at a phenomenologically relevant level of accuracy. The\nphenomenological implications of our physical results are the subject of a\ncompanion letter [1].","main_category":"hep-lat","categories":"hep-lat,hep-ph","published":"2025-04-08T14:07:58Z"}
{"aid":"http://arxiv.org/abs/2504.06081v1","title":"On the interference of the scattered wave and the incident wave in light\n  scattering problems with Gaussian beams","summary":"We consider the light scattering problem for a Gaussian beam and a\n(spherical) particle at arbitrary location. Within the beam cross section, the\ntotal electromagnetic field is the superposition of the incident beam and the\nscattered wave. Using the Generalized Lorenz-Mie Theory (GLMT) as a vehicle to\naccess such scattering problems, we discuss the mathematical modeling of this\ninterference at short, large but finite and infinite distances from the\nscatterer. We show how to eliminate the errors that can arise from improper\nmodeling in the most straight-forward manner, that is superimposing the\nscattered wave with the closed-form expression for the Gaussian beam at a\nfinite distance from the particle. GLMT uses a low order beam model ($s^1$),\nbut using the known higher order models ($s^3$, $s^5$, $s^7$, ...) would not\nmitigate these errors as we discuss. The challenge lies in an appropriate\ndescription of the Gaussian beam at arbitrary distances from its focus, not in\nits description on the scale of a particle (located in or near the focus) nor\nin the expressions for the scattered field. Hence, the solutions described here\ncan readily be extended to light scattering frameworks other than GLMT and are\nthus also relevant for non-spherical particles.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-08T14:20:57Z"}
{"aid":"http://arxiv.org/abs/2504.06133v1","title":"Gravitational Baryogenesis in Extended Proca-Nuevo Gravity","summary":"In this article, we investigate the gravitational baryogenesis mechanism in\nthe framework of Extended Proca-Nuevo (EPN) gravity, a theory where a massive\nvector field is non-minimally coupled to the curvature. This analysis is\ncarried out for an early universe, encompassing three separate cosmological\nscenarios defined by power-law, exponential, and modified exponential scale\nfactors. By deriving the modified field equations from the EPN action, we\nobtain precise solutions for each scale factor, including the influence of the\nvector field. We compute the baryon-to-entropy ratio using the gravitational\nbaryogenesis formalism, where the baryon asymmetry arises from a dynamical\ncoupling of the baryon current with the derivative of the Ricci scalar. Our\nfindings demonstrate that the baryon-to-entropy ratio is consistent with\nobservational constraints in all scenarios, highlighting the potential of EPN\ngravity as a viable theory to explain the matter-antimatter asymmetry in the\nearly universe. The study further stresses the contribution of anisotropy and\nvector field dynamics to the cosmological evolution within modified gravity\nmodels.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-08T15:26:58Z"}
{"aid":"http://arxiv.org/abs/2504.06151v1","title":"Zerrow: True Zero-Copy Arrow Pipelines in Bauplan","summary":"Bauplan is a FaaS-based lakehouse specifically built for data pipelines: its\nexecution engine uses Apache Arrow for data passing between the nodes in the\nDAG. While Arrow is known as the \"zero copy format\", in practice, limited Linux\nkernel support for shared memory makes it difficult to avoid copying entirely.\nIn this work, we introduce several new techniques to eliminate nearly all\ncopying from pipelines: in particular, we implement a new kernel module that\nperforms de-anonymization, thus eliminating a copy to intermediate data. We\nconclude by sharing our preliminary evaluation on different workloads types, as\nwell as discussing our plan for future improvements.","main_category":"cs.OS","categories":"cs.OS,cs.DB","published":"2025-04-08T15:46:52Z"}
{"aid":"http://arxiv.org/abs/2504.06157v1","title":"Hall Effect Thruster Forecasting using a Topological Approach for Data\n  Assimilation","summary":"Hall Effect Thrusters (HETs) are electric thrusters that eject heavy ionized\ngas particles from the spacecraft to generate thrust. Although traditionally\nthey were used for station keeping, recently They have been used for\ninterplanetary space missions due to their high delta-V potential and their\noperational longevity in contrast to other thrusters, e.g., chemical. However,\nthe operation of HETs involves complex processes such as ionization of gases,\nstrong magnetic fields, and complicated solar panel power supply interactions.\nTherefore, their operation is extremely difficult to model thus necessitating\nData Assimilation (DA) approaches for estimating and predicting their\noperational states. Because HET's operating environment is often noisy with\nnon-Gaussian sources, this significantly limits applicable DA tools. We\ndescribe a topological approach for data assimilation that bypasses these\nlimitations that does not depend on the noise model, and utilize it to forecast\nspatiotemporal plume field states of HETs. Our approach is a generalization of\nthe Topological Approach for Data Assimilation (TADA) method that allows\nincluding different forecast functions. We show how TADA can be combined with\nthe Long Short-Term Memory network for accurate forecasting. We then apply our\napproach to high-fidelity Hall Effect Thruster (HET) simulation data from the\nAir Force Research Laboratory (AFRL) rocket propulsion division where we\ndemonstrate the forecast resiliency of TADA on noise contaminated,\nhigh-dimensional data.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-08T15:52:50Z"}
{"aid":"http://arxiv.org/abs/2504.06178v1","title":"Flash Sculptor: Modular 3D Worlds from Objects","summary":"Existing text-to-3D and image-to-3D models often struggle with complex scenes\ninvolving multiple objects and intricate interactions. Although some recent\nattempts have explored such compositional scenarios, they still require an\nextensive process of optimizing the entire layout, which is highly cumbersome\nif not infeasible at all. To overcome these challenges, we propose Flash\nSculptor in this paper, a simple yet effective framework for compositional 3D\nscene/object reconstruction from a single image. At the heart of Flash Sculptor\nlies a divide-and-conquer strategy, which decouples compositional scene\nreconstruction into a sequence of sub-tasks, including handling the appearance,\nrotation, scale, and translation of each individual instance. Specifically, for\nrotation, we introduce a coarse-to-fine scheme that brings the best of both\nworlds--efficiency and accuracy--while for translation, we develop an\noutlier-removal-based algorithm that ensures robust and precise parameters in a\nsingle step, without any iterative optimization. Extensive experiments\ndemonstrate that Flash Sculptor achieves at least a 3 times speedup over\nexisting compositional 3D methods, while setting new benchmarks in\ncompositional 3D reconstruction performance. Codes are available at\nhttps://github.com/YujiaHu1109/Flash-Sculptor.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T16:20:51Z"}
{"aid":"http://arxiv.org/abs/2504.06187v1","title":"Scaling Invariance: A Gateway to Phase Transitions","summary":"We explore the concept of scaling invariance in a type of dynamical systems\nthat undergo a transition from order (regularity) to disorder (chaos). The\nsystems are described by a two-dimensional, nonlinear mapping that preserves\nthe area in the phase space. The key variables are the action and the angle, as\nusual from Hamiltonian systems. The transition is influenced by a control\nparameter giving the form of the order parameter. We observe a scaling\ninvariance in the average squared action within the chaotic region, providing\nevidence that this change from regularity (integrability) to chaos\n(non-integrability) is akin to a second-order or continuous phase transition.\nAs the order parameter approaches zero, its response against the variation of\nthe control parameter (susceptibility) becomes increasingly pronounced (indeed\ndiverging), resembling a phase transition. These findings could not be obtained\nwithout a seminal paper on Phys. Rev. Lett. {\\bf 2004}, {\\em 93}, 014101.","main_category":"nlin.CD","categories":"nlin.CD","published":"2025-04-08T16:31:23Z"}
{"aid":"http://arxiv.org/abs/2504.06192v1","title":"Magnetization process in epitaxial Fe$_{85}$Co$_{15}$ thin films via\n  anisotropic magnetoresistance","summary":"The effects of the crystalline symmetry on the magnetotransport properties in\nferromagnetic alloys are being reexamined in recent years particularly due to\nthe role of the anisotropic magnetoresistance on the electrical detection of\nmagnetization dynamics, which is relevant to estimate spin transport parameters\nsuch as the spin Hall angle or the damping constant. In this work we\ninvestigated the crystalline dependent anisotropic magnetoresistance in\nepitaxial Fe85Co15 films and discuss the magnetization process through the\nmagnetotransport properties by varying the relative orientations between the\nelectric current, the external magnetic field and the Fe85Co15 crystallographic\ndirections. We have found that the anisotropic magnetoresistance ratio depends\non the current direction with respect to the crystal axes of Fe85Co15 and\ndetermine a ratio of 0.20 % and 0.17 % when the current is applied along the\n[110] hard and [100] easy axes, respectively. We fit our experimental data\nusing the Stoner-Wohlfarth model to describe the path followed by the\nmagnetization during the magnetization process and to extract the anisotropy\nconstants. The fitted cubic and uniaxial anisotropy constants are Kc = 21 kJ/m3\nand Ku = 11 kJ/m3, which are comparable with reported values from the angular\nvariation of ferromagnetic resonance experiments. Our results contribute to the\nunderstanding of the interplay between the crystalline structure and the\nmagnetotransport properties of FeCo alloys.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T16:35:07Z"}
{"aid":"http://arxiv.org/abs/2504.06203v1","title":"Factorizing Defects from Generalized Pinning Fields","summary":"We introduce generalized pinning fields in conformal field theory that model\na large class of critical impurities at large distance, enriching the familiar\nuniversality classes. We provide a rigorous definition of such defects as\ncertain unbounded operators on the Hilbert space and prove that when inserted\non codimension-one surfaces they factorize the spacetime into two halves. The\nfactorization channels are further constrained by symmetries in the bulk. As a\ncorollary, we solve such critical impurities in the 2d minimal models and\nestablish the factorization phenomena previously observed for localized mass\ndeformations in the 3d ${\\rm O}(N)$ model.","main_category":"hep-th","categories":"hep-th,cond-mat.str-el,math.OA","published":"2025-04-08T16:47:34Z"}
{"aid":"http://arxiv.org/abs/2504.06208v1","title":"Deep Hedging with Options Using the Implied Volatility Surface","summary":"We propose an enhanced deep hedging framework for index option portfolios,\ngrounded in a realistic market simulator that captures the joint dynamics of\nS&P 500 returns and the full implied volatility surface. Our approach\nintegrates surface-informed decisions with multiple hedging instruments and\nexplicitly accounts for transaction costs. The hedging strategy also considers\nthe variance risk premium embedded in the hedging instruments, enabling more\ninformed and adaptive risk management. In this setting, state-dependent\nno-trade regions emerge naturally, improving rebalancing efficiency and hedging\nperformance. Tested across simulated and historical data from 1996 to 2020, our\nmethod consistently outperforms traditional delta and delta-gamma hedging,\ndemonstrating superior adaptability and risk reduction.","main_category":"q-fin.RM","categories":"q-fin.RM","published":"2025-04-08T16:51:44Z"}
{"aid":"http://arxiv.org/abs/2504.06209v1","title":"The Work Capacity of Channels with Memory: Maximum Extractable Work in\n  Percept-Action Loops","summary":"Predicting future observations plays a central role in machine learning,\nbiology, economics, and many other fields. It lies at the heart of\norganizational principles such as the variational free energy principle and has\neven been shown -- based on the second law of thermodynamics -- to be necessary\nfor reaching the fundamental energetic limits of sequential information\nprocessing. While the usefulness of the predictive paradigm is undisputed,\ncomplex adaptive systems that interact with their environment are more than\njust predictive machines: they have the power to act upon their environment and\ncause change. In this work, we develop a framework to analyze the\nthermodynamics of information processing in percept-action loops -- a model of\nagent-environment interaction -- allowing us to investigate the thermodynamic\nimplications of actions and percepts on equal footing. To this end, we\nintroduce the concept of work capacity -- the maximum rate at which an agent\ncan expect to extract work from its environment. Our results reveal that\nneither of two previously established design principles for work-efficient\nagents -- maximizing predictive power and forgetting past actions -- remains\noptimal in environments where actions have observable consequences. Instead, a\ntrade-off emerges: work-efficient agents must balance prediction and\nforgetting, as remembering past actions can reduce the available free energy.\nThis highlights a fundamental departure from the thermodynamics of passive\nobservation, suggesting that prediction and energy efficiency may be at odds in\nactive learning systems.","main_category":"cs.LG","categories":"cs.LG,cond-mat.stat-mech,cs.IT,math.IT,nlin.AO,nlin.CD,quant-ph","published":"2025-04-08T16:54:20Z"}
{"aid":"http://arxiv.org/abs/2504.06211v1","title":"Need for zkSpeed: Accelerating HyperPlonk for Zero-Knowledge Proofs","summary":"Zero-Knowledge Proofs (ZKPs) are rapidly gaining importance in\nprivacy-preserving and verifiable computing. ZKPs enable a proving party to\nprove the truth of a statement to a verifying party without revealing anything\nelse. ZKPs have applications in blockchain technologies, verifiable machine\nlearning, and electronic voting, but have yet to see widespread adoption due to\nthe computational complexity of the proving process. Recent works have\naccelerated the key primitives of state-of-the-art ZKP protocols on GPU and\nASIC. However, the protocols accelerated thus far face one of two challenges:\nthey either require a trusted setup for each application, or they generate\nlarger proof sizes with higher verification costs, limiting their applicability\nin scenarios with numerous verifiers or strict verification time constraints.\nThis work presents an accelerator, zkSpeed, for HyperPlonk, a state-of-the-art\nZKP protocol that supports both one-time, universal setup and small proof sizes\nfor typical ZKP applications in publicly verifiable, consensus-based systems.\nWe accelerate the entire protocol, including two major primitives: SumCheck and\nMulti-scalar Multiplications (MSMs). We develop a full-chip architecture using\n366.46 mm$^2$ and 2 TB/s of bandwidth to accelerate the entire proof generation\nprocess, achieving geometric mean speedups of 801$\\times$ over CPU baselines.","main_category":"cs.AR","categories":"cs.AR,cs.CR","published":"2025-04-08T16:56:10Z"}
{"aid":"http://arxiv.org/abs/2504.06223v1","title":"Generalized Bronnikov-Ellis wormhole solution in the\n  scalar-Einstein-Gauss-Bonnet $4d$ gravitational model","summary":"We consider the sEGB $4d$ gravitational model with a scalar field\n$\\varphi\\left(u\\right)$, Einstein and Gauss-Bonnet terms. The model action\ncontains a potential term $U\\left(\\varphi\\right))$, a Gauss-Bonnet coupling\nfunction $f\\left(\\varphi\\right)$ and a parameter $\\varepsilon = \\pm 1$, where\n$\\varepsilon = 1$ corresponds to the usual scalar field, and $\\varepsilon = -1$\nto the phantom field. In this paper, the sEGB reconstruction procedure\nconsidered in our previous paper is applied to the metric of the\nBronnikov-Ellis solution, which describes a massive wormhole in the model with\na phantom field (and zero potential). For this metric, written in the Buchdal\nparameterization with a radial variable $u$, we find a solution of the master\nequation for $ f\\left(\\varphi\\left(u\\right)\\right)$ with the integration\n(reconstruction) parameter $C_0$. We also find expressions for\n$U\\left(\\varphi\\left(u\\right)\\right)$ and $\\varepsilon \\dot{\\varphi} =\nh\\left(u\\right)$ for $\\varepsilon = \\pm 1$. We prove that for all non-trivial\nvalues of the parameter $C_0 \\neq 0$ the function $h\\left(u\\right)$ is not of\nconstant sign for all admissible $u \\in \\left(-\\infty , +\\infty\\right)$. This\nmeans that for a fixed value of the parameter $\\varepsilon = \\pm 1$ there is no\nnon-trivial sEGB reconstruction in which the scalar field is a purely ordinary\nfield ($\\varepsilon = 1$) or a purely phantom field ($\\varepsilon = - 1$).","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-08T17:12:23Z"}
{"aid":"http://arxiv.org/abs/2504.06228v1","title":"SOFIA/upGREAT imaging spectroscopy of the [C II] 158 um fine structure\n  line toward the Sgr A region in the Galactic center","summary":"We present SOFIA/upGREAT velocity-resolved spectral imaging and analysis of\nthe 158 um [C II] spectral line toward the central 80 by 43\\,pc region of the\nCentral Molecular Zone of the Galaxy. The field we imaged with 14\" (0.6 pc)\nspatial and 1 km/s spectral resolution contains the Circum-Nuclear Disk (CND)\naround the central black hole Sgr A*, the neighboring thermal Arched Filaments,\nthe nonthermal filaments of the Radio Arc, and the three luminous central star\nclusters. [C II] traces emission from the CND's inner edge to material orbiting\nat a distance of approximately 6 pc. Its velocity field reveals no sign of\ninflowing material nor interaction with winds from the Sgr A East supernova\nremnant. Wide-field imaging of the Sgr A region shows multiple circular\nsegments, including the thermal Arched Filaments, that are centered on a region\nthat includes the Quintuplet cluster. We examine the possibility that the\nArched Filaments and other large-scale arcs trace transient excitation events\nfrom supernova blast waves. Along the Arched Filaments, comparisons among\nfar-IR fine structure lines show changes in ionization state over small scales\nand that high-excitation lines are systematically shifted in position from the\nother lines. These also point to transient fast winds that shocked on the\nsurface of the Arches cloud to produce additional local UV radiation to excite\nthe Arched Filaments on a cloud surface illuminated by UV from hot stars.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-08T17:18:59Z"}
{"aid":"http://arxiv.org/abs/2504.06231v1","title":"Orb-v3: atomistic simulation at scale","summary":"We introduce Orb-v3, the next generation of the Orb family of universal\ninteratomic potentials. Models in this family expand the\nperformance-speed-memory Pareto frontier, offering near SoTA performance across\na range of evaluations with a >10x reduction in latency and > 8x reduction in\nmemory. Our experiments systematically traverse this frontier, charting the\ntrade-off induced by roto-equivariance, conservatism and graph sparsity.\nContrary to recent literature, we find that non-equivariant, non-conservative\narchitectures can accurately model physical properties, including those which\nrequire higher-order derivatives of the potential energy surface.\n  This model release is guided by the principle that the most valuable\nfoundation models for atomic simulation will excel on all fronts: accuracy,\nlatency and system size scalability. The reward for doing so is a new era of\ncomputational chemistry driven by high-throughput and mesoscale all-atom\nsimulations.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T17:27:34Z"}
{"aid":"http://arxiv.org/abs/2504.06263v1","title":"OmniSVG: A Unified Scalable Vector Graphics Generation Model","summary":"Scalable Vector Graphics (SVG) is an important image format widely adopted in\ngraphic design because of their resolution independence and editability. The\nstudy of generating high-quality SVG has continuously drawn attention from both\ndesigners and researchers in the AIGC community. However, existing methods\neither produces unstructured outputs with huge computational cost or is limited\nto generating monochrome icons of over-simplified structures. To produce\nhigh-quality and complex SVG, we propose OmniSVG, a unified framework that\nleverages pre-trained Vision-Language Models (VLMs) for end-to-end multimodal\nSVG generation. By parameterizing SVG commands and coordinates into discrete\ntokens, OmniSVG decouples structural logic from low-level geometry for\nefficient training while maintaining the expressiveness of complex SVG\nstructure. To further advance the development of SVG synthesis, we introduce\nMMSVG-2M, a multimodal dataset with two million richly annotated SVG assets,\nalong with a standardized evaluation protocol for conditional SVG generation\ntasks. Extensive experiments show that OmniSVG outperforms existing methods and\ndemonstrates its potential for integration into professional SVG design\nworkflows.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T17:59:49Z"}
{"aid":"http://arxiv.org/abs/2504.06567v1","title":"A Novel Angle-Delay-Doppler Estimation Scheme for AFDM-ISAC System in\n  Mixed Near-field and Far-field Scenarios","summary":"The recently proposed multi-chirp waveform, affine frequency division\nmultiplexing (AFDM), is considered as a potential candidate for integrated\nsensing and communication (ISAC). However, acquiring accurate target sensing\nparameter information becomes challenging due to fractional delay and Doppler\nshift occurrence, as well as effects introduced by the coexistence of\nnear-field (NF) and far-field (FF) targets associated with large-scale antenna\nsystems. In this paper, we propose a novel angle-delay-Doppler estimation\nscheme for AFDM-ISAC system in mixed NF and FF scenarios. Specifically, we\nmodel the received ISAC signals as a third-order tensor that admits a low-rank\nCANDECOMP/PARAFAC (CP) format. By employing the Vandermonde nature of the\nfactor matrix and the spatial smoothing technique, we develop a structured CP\ndecomposition method that guarantees the condition for uniqueness. We further\npropose a low-complexity estimation scheme to acquire target sensing parameters\nwith fractional values, including angle of arrival/departure (AoA/AoD), delay\nand Doppler shift accurately. We also derive the Cram\\'er-Rao Lower Bound\n(CRLB) as a benchmark and analyze the complexity of our proposed scheme.\nFinally, simulation results are provided to demonstrate the effectiveness and\nsuperiority of our proposed scheme.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-09T04:02:22Z"}
{"aid":"http://arxiv.org/abs/2504.06572v1","title":"Domain Generalization via Discrete Codebook Learning","summary":"Domain generalization (DG) strives to address distribution shifts across\ndiverse environments to enhance model's generalizability. Current DG approaches\nare confined to acquiring robust representations with continuous features,\nspecifically training at the pixel level. However, this DG paradigm may\nstruggle to mitigate distribution gaps in dealing with a large space of\ncontinuous features, rendering it susceptible to pixel details that exhibit\nspurious correlations or noise. In this paper, we first theoretically\ndemonstrate that the domain gaps in continuous representation learning can be\nreduced by the discretization process. Based on this inspiring finding, we\nintroduce a novel learning paradigm for DG, termed Discrete Domain\nGeneralization (DDG). DDG proposes to use a codebook to quantize the feature\nmap into discrete codewords, aligning semantic-equivalent information in a\nshared discrete representation space that prioritizes semantic-level\ninformation over pixel-level intricacies. By learning at the semantic level,\nDDG diminishes the number of latent features, optimizing the utilization of the\nrepresentation space and alleviating the risks associated with the wide-ranging\nspace of continuous features. Extensive experiments across widely employed\nbenchmarks in DG demonstrate DDG's superior performance compared to\nstate-of-the-art approaches, underscoring its potential to reduce the\ndistribution gaps and enhance the model's generalizability.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T04:19:35Z"}
{"aid":"http://arxiv.org/abs/2504.06584v1","title":"CAFE-AD: Cross-Scenario Adaptive Feature Enhancement for Trajectory\n  Planning in Autonomous Driving","summary":"Imitation learning based planning tasks on the nuPlan dataset have gained\ngreat interest due to their potential to generate human-like driving behaviors.\nHowever, open-loop training on the nuPlan dataset tends to cause causal\nconfusion during closed-loop testing, and the dataset also presents a long-tail\ndistribution of scenarios. These issues introduce challenges for imitation\nlearning. To tackle these problems, we introduce CAFE-AD, a Cross-Scenario\nAdaptive Feature Enhancement for Trajectory Planning in Autonomous Driving\nmethod, designed to enhance feature representation across various scenario\ntypes. We develop an adaptive feature pruning module that ranks feature\nimportance to capture the most relevant information while reducing the\ninterference of noisy information during training. Moreover, we propose a\ncross-scenario feature interpolation module that enhances scenario information\nto introduce diversity, enabling the network to alleviate over-fitting in\ndominant scenarios. We evaluate our method CAFE-AD on the challenging public\nnuPlan Test14-Hard closed-loop simulation benchmark. The results demonstrate\nthat CAFE-AD outperforms state-of-the-art methods including rule-based and\nhybrid planners, and exhibits the potential in mitigating the impact of\nlong-tail distribution within the dataset. Additionally, we further validate\nits effectiveness in real-world environments. The code and models will be made\navailable at https://github.com/AlniyatRui/CAFE-AD.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-09T05:16:29Z"}
{"aid":"http://arxiv.org/abs/2504.06612v1","title":"A Hilbert--Mumford criterion for generalised Monge--Ampère equations","summary":"We give a new numerical criterion in the spirit of GIT for existence of\nsolutions to inverse Hessian equations, including in particular the J-equation.\nOur criterion is formulated in terms of stability of pairs in the sense of\nPaul. To that end, we build on previous work of the author with Dervan, and\ngeneralise a result of Zhang, proving isometry between generalised Chow line\nbundles and mixed Deligne pairings.","main_category":"math.DG","categories":"math.DG,math.AG","published":"2025-04-09T06:16:59Z"}
{"aid":"http://arxiv.org/abs/2504.06618v1","title":"Human-like compositional learning of visually-grounded concepts using\n  synthetic environments","summary":"The compositional structure of language enables humans to decompose complex\nphrases and map them to novel visual concepts, showcasing flexible\nintelligence. While several algorithms exhibit compositionality, they fail to\nelucidate how humans learn to compose concept classes and ground visual cues\nthrough trial and error. To investigate this multi-modal learning challenge, we\ndesigned a 3D synthetic environment in which an agent learns, via\nreinforcement, to navigate to a target specified by a natural language\ninstruction. These instructions comprise nouns, attributes, and critically,\ndeterminers, prepositions, or both. The vast array of word combinations\nheightens the compositional complexity of the visual grounding task, as\nnavigating to a blue cube above red spheres is not rewarded when the\ninstruction specifies navigating to \"some blue cubes below the red sphere\". We\nfirst demonstrate that reinforcement learning agents can ground determiner\nconcepts to visual targets but struggle with more complex prepositional\nconcepts. Second, we show that curriculum learning, a strategy humans employ,\nenhances concept learning efficiency, reducing the required training episodes\nby 15% in determiner environments and enabling agents to easily learn\nprepositional concepts. Finally, we establish that agents trained on determiner\nor prepositional concepts can decompose held-out test instructions and rapidly\nadapt their navigation policies to unseen visual object combinations.\nLeveraging synthetic environments, our findings demonstrate that multi-modal\nreinforcement learning agents can achieve compositional understanding of\ncomplex concept classes and highlight the efficacy of human-like learning\nstrategies in improving artificial systems' learning efficiency.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T06:33:28Z"}
{"aid":"http://arxiv.org/abs/2504.06631v1","title":"The Method for Storing Patterns in Neural Networks-Memorization and\n  Recall of QR code Patterns-","summary":"In this paper, we propose a mechanism for storing complex patterns within a\nneural network and subsequently recalling them. This model is based on our work\npublished in 2018(Inazawa, 2018), which we have refined and extended in this\nwork. With the recent advancements in deep learning and large language model\n(LLM)-based AI technologies (generative AI), it can be considered that\nmethodologies for the learning are becoming increasingly well-established. In\nthe future, we expect to see further research on memory using models based on\nTransformers (Vaswani, et. al., 2017, Rae, et. al., 2020), but in this paper we\npropose a simpler and more powerful model of memory and recall in neural\nnetworks. The advantage of storing patterns in a neural network lies in its\nability to recall the original pattern even when an incomplete version is\npresented. The patterns we have produced for use in this study have been QR\ncode (DENSO WAVE, 1994), which has become widely used as an information\ntransmission tool in recent years.","main_category":"cs.NE","categories":"cs.NE","published":"2025-04-09T07:09:40Z"}
{"aid":"http://arxiv.org/abs/2504.06633v1","title":"A Serendipitous Recommendation System Considering User Curiosity","summary":"To address the problem of narrow recommendation ranges caused by an emphasis\non prediction accuracy, serendipitous recommendations, which consider both\nusefulness and unexpectedness, have attracted attention. However, realizing\nserendipitous recommendations is challenging due to the varying proportions of\nusefulness and unexpectedness preferred by different users, which is influenced\nby their differing desires for knowledge. In this paper, we propose a method to\nestimate the proportion of usefulness and unexpectedness that each user desires\nbased on their curiosity, and make recommendations that match this preference.\nThe proposed method estimates a user's curiosity by considering both their\nlong-term and short-term interests. Offline experiments were conducted using\nthe MovieLens-1M dataset to evaluate the effectiveness of the proposed method.\nThe experimental results demonstrate that our method achieves the same level of\nperformance as state-of-the-art method while successfully providing\nserendipitous recommendations.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-09T07:15:06Z"}
{"aid":"http://arxiv.org/abs/2504.06634v1","title":"Crafting Query-Aware Selective Attention for Single Image\n  Super-Resolution","summary":"Single Image Super-Resolution (SISR) reconstructs high-resolution images from\nlow-resolution inputs, enhancing image details. While Vision Transformer\n(ViT)-based models improve SISR by capturing long-range dependencies, they\nsuffer from quadratic computational costs or employ selective attention\nmechanisms that do not explicitly focus on query-relevant regions. Despite\nthese advancements, prior work has overlooked how selective attention\nmechanisms should be effectively designed for SISR. We propose SSCAN, which\ndynamically selects the most relevant key-value windows based on query\nsimilarity, ensuring focused feature extraction while maintaining efficiency.\nIn contrast to prior approaches that apply attention globally or heuristically,\nour method introduces a query-aware window selection strategy that better\naligns attention computation with important image regions. By incorporating\nfixed-sized windows, SSCAN reduces memory usage and enforces linear\ntoken-to-token complexity, making it scalable for large images. Our experiments\ndemonstrate that SSCAN outperforms existing attention-based SISR methods,\nachieving up to 0.14 dB PSNR improvement on urban datasets, guaranteeing both\ncomputational efficiency and reconstruction quality in SISR.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T07:17:29Z"}
{"aid":"http://arxiv.org/abs/2504.06637v1","title":"SCI-Reason: A Dataset with Chain-of-Thought Rationales for Complex\n  Multimodal Reasoning in Academic Areas","summary":"Large Language Models (LLMs) and Large Multimodal Models (LMMs) demonstrate\nimpressive problem-solving skills in many tasks and domains. However, their\nability to reason with complex images in academic domains has not been\nsystematically investigated. To bridge this gap, we present SCI-Reason, a\ndataset for complex multimodel reasoning in academic areas. SCI-Reason aims to\ntest and improve the reasoning ability of large multimodal models using real\ncomplex images in academic domains. The dataset contains 12,066 images and\n12,626 question-answer pairs extracted from PubMed, divided into training,\nvalidation and test splits. Each question-answer pair also contains an accurate\nand efficient inference chain as a guide to improving the inference properties\nof the dataset. With SCI-Reason, we performed a comprehensive evaluation of 8\nwell-known models. The best performing model, Claude-3.7-Sonnet, only achieved\nan accuracy of 55.19%. Error analysis shows that more than half of the model\nfailures are due to breakdowns in multi-step inference chains rather than\nerrors in primary visual feature extraction. This finding underscores the\ninherent limitations in reasoning capabilities exhibited by current multimodal\nmodels when processing complex image analysis tasks within authentic academic\ncontexts. Experiments on open-source models show that SCI-Reason not only\nenhances reasoning ability but also demonstrates cross-domain generalization in\nVQA tasks. We also explore future applications of model inference capabilities\nin this domain, highlighting its potential for future research.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-09T07:26:24Z"}
{"aid":"http://arxiv.org/abs/2504.06651v1","title":"Collision avoidance from monocular vision trained with novel view\n  synthesis","summary":"Collision avoidance can be checked in explicit environment models such as\nelevation maps or occupancy grids, yet integrating such models with a\nlocomotion policy requires accurate state estimation. In this work, we consider\nthe question of collision avoidance from an implicit environment model. We use\nmonocular RGB images as inputs and train a collisionavoidance policy from\nphotorealistic images generated by 2D Gaussian splatting. We evaluate the\nresulting pipeline in realworld experiments under velocity commands that bring\nthe robot on an intercept course with obstacles. Our results suggest that RGB\nimages can be enough to make collision-avoidance decisions, both in the room\nwhere training data was collected and in out-of-distribution environments.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-09T07:39:12Z"}
{"aid":"http://arxiv.org/abs/2504.06681v1","title":"Mechanical stability of resonant Bose-Fermi mixtures","summary":"We investigate the mechanical stability of Bose-Fermi mixtures at zero\ntemperature in the presence of a tunable Feshbach resonance, which induces a\ncompetition between boson condensation and boson-fermion pairing when the boson\ndensity is smaller than the fermion density. Using a many-body diagrammatic\napproach validated by fixed-node Quantum Monte Carlo calculations and supported\nby recent experimental observations, we determine the minimal amount of\nboson-boson repulsion required to guarantee the stability of the mixture across\nthe entire range of boson-fermion interactions from weak to strong coupling.\nOur stability phase diagrams indicate that mixtures with boson-to-fermion mass\nratios near two, such as the $^{87}$Rb-$^{40}$K system, exhibit optimal\nstability conditions. Moreover, by applying our results to a recent experiment\nwith a $^{23}$Na-$^{40}$K mixture, we find that the boson-boson repulsion was\ninsufficient to ensure stability, suggesting that the experimental timescale\nwas short enough to avoid mechanical collapse. On the other hand, we also show\nthat even in the absence of boson-boson repulsion, Bose-Fermi mixtures become\nintrinsically stable beyond a certain coupling strength, preceding the quantum\nphase transition associated with the vanishing of the bosonic condensate. We\nthus propose an experimental protocol for observing this quantum phase\ntransition in a mechanically stable configuration.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas","published":"2025-04-09T08:39:14Z"}
{"aid":"http://arxiv.org/abs/2504.06690v1","title":"Homogenization theory of random walks in degenerate random environment","summary":"Recent progress on the understanding of the Random Conductance Model is\nreviewed. A particular emphasis is on homogenization results such as functional\ncentral limit theorems, local limit theorems and heat kernel estimates for\nalmost every realization of the environment, established for random walks among\nstationary ergodic conductances that are possibly unbounded but satisfy certain\nmoment conditions.","main_category":"math.PR","categories":"math.PR","published":"2025-04-09T08:52:16Z"}
{"aid":"http://arxiv.org/abs/2504.06696v1","title":"Kerr enhanced optomechanical entanglement via reservoir design","summary":"Quantum entanglement is a crucial resource in quantum technologies, enabling\nadvancements in quantum computing, quantum communication, and quantum precision\nmeasurement. Here, we propose a method to enhance optomechanical entanglement\nby introducing an optical Kerr nonlinear medium and a squeezed vacuum reservoir\nof the optomechanical cavity. By performing the displacement and squeezing\ntransformations, the system can be reduced to a standard linearized\noptomechanical system with normalized driving detuning and linearized-coupling\nstrength, in which the optical and mechanical modes are, respectively, coupled\nto an optical vacuum bath and a mechanical heat bath. We focus on the\nentanglement generation in the single stable regime of the system. By\nevaluating the steady-state logarithm negativity, we find that the\noptomechanical entanglement can be enhanced within a wide range of the Kerr\nconstant. In addition, the Kerr nonlinearity can extend the stable region,\nenabling considerable entanglement generation in the blue sideband-parameter\nregion. We also investigate the dependence of the entanglement generation on\nthe average thermal phonon occupation of the mechanical bath and the optical\ndriving amplitude. It is found that the presence of the Kerr nonlinearity\nallows the generation of optomechanical entanglement even when the thermal\nphonon occupation of the mechanical bath is as high as 3000. Our findings will\nprovide valuable insights into enhancing fragile quantum resources in quantum\nsystems.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T08:55:12Z"}
{"aid":"http://arxiv.org/abs/2504.06715v1","title":"Bistability and complex bifurcation diagrams generated by waning and\n  boosting of immunity","summary":"We investigate an epidemiological model that incorporates waning of immunity\nat the individual level and boosting of the immune system upon re-exposure to\nthe pathogen. When immunity is fully restored upon boosting, the system can be\nexpressed as an SIRS-type model with discrete and distributed delays. We\nconduct a numerical bifurcation analysis varying the boosting force and the\nmaximum period of immunity (in the absence of boosting), while keeping other\nparameters fixed at values representative of a highly infectious disease like\npertussis. The stability switches of the endemic equilibrium, identified\nnumerically, are validated using an established analytical approach, confirming\nthat the equilibrium is unstable in a bounded parameter region, and stable\noutside this region. Using recently developed continuation methods for models\nwith discrete and distributed delays, we explore periodic solutions and their\nbifurcations. Our analysis significantly extends previous findings and reveals\na rich dynamical landscape, including catastrophic bifurcations of limit\ncycles, torus bifurcations, and bistability regions where two stable periodic\nsolutions coexist, differing in amplitude and period. These complex\nbifurcations have critical public health implications: perturbations--such as\nnon-pharmaceutical interventions--can shift the system between attractors,\nleading to long-term consequences from short-term measures.","main_category":"math.DS","categories":"math.DS","published":"2025-04-09T09:16:35Z"}
{"aid":"http://arxiv.org/abs/2504.06728v1","title":"Light-field dressing of transient photo-excited states above $E_F$","summary":"Time-periodic light-field provides an emerging pathway for dynamically\nengineering quantum materials by forming hybrid states between photons and\nBloch electrons. So far, experimental progress on light-field dressed states\nhas been mainly focused on the occupied states, however, it is unclear if the\ntransient photo-excited states above the Fermi energy $E_F$ can also be\ndressed, leaving the dynamical interplay between photo-excitation and\nlight-field dressing elusive. Here, we provide direct experimental evidence for\nlight-field dressing of the transient photo-excited surface states above $E_F$,\nwhich exhibits distinct dynamics with a delay response as compared to\nlight-field dressed states below $E_F$. Our work reveals the dual roles of the\npump pulse in both photo-excitation and light-field dressing, providing a more\ncomprehensive picture with new insights on the light-induced manipulation of\ntransient electronic states.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-09T09:34:14Z"}
{"aid":"http://arxiv.org/abs/2504.06740v1","title":"MultiADS: Defect-aware Supervision for Multi-type Anomaly Detection and\n  Segmentation in Zero-Shot Learning","summary":"Precise optical inspection in industrial applications is crucial for\nminimizing scrap rates and reducing the associated costs. Besides merely\ndetecting if a product is anomalous or not, it is crucial to know the distinct\ntype of defect, such as a bent, cut, or scratch. The ability to recognize the\n\"exact\" defect type enables automated treatments of the anomalies in modern\nproduction lines. Current methods are limited to solely detecting whether a\nproduct is defective or not without providing any insights on the defect type,\nnevertheless detecting and identifying multiple defects. We propose MultiADS, a\nzero-shot learning approach, able to perform Multi-type Anomaly Detection and\nSegmentation. The architecture of MultiADS comprises CLIP and extra linear\nlayers to align the visual- and textual representation in a joint feature\nspace. To the best of our knowledge, our proposal, is the first approach to\nperform a multi-type anomaly segmentation task in zero-shot learning. Contrary\nto the other baselines, our approach i) generates specific anomaly masks for\neach distinct defect type, ii) learns to distinguish defect types, and iii)\nsimultaneously identifies multiple defect types present in an anomalous\nproduct. Additionally, our approach outperforms zero/few-shot learning SoTA\nmethods on image-level and pixel-level anomaly detection and segmentation tasks\non five commonly used datasets: MVTec-AD, Visa, MPDD, MAD and Real-IAD.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T09:52:04Z"}
{"aid":"http://arxiv.org/abs/2504.06760v1","title":"Applications of Poisson cohomology to the inducibility problems and\n  study of deformation maps","summary":"This paper provides some applications of the Poisson cohomology groups\nintroduced by Flato, Gerstenhaber and Voronov. Given an abelian extension of a\nPoisson algebra by a representation, we first investigate the inducibility of a\npair of Poisson algebra automorphisms and show that the corresponding\nobstruction lies in the second Poisson cohomology group. Consequently, we\nobtain the Wells exact sequence connecting various automorphism groups and the\nsecond Poisson cohomology group. Subsequently, we also consider the\ninducibility for a pair of Poisson algebra derivations, obtain the obstruction\nand construct the corresponding Wells-type exact sequence.\n  To get another application, we introduce the notion of a `deformation map' in\na proto-twilled Poisson algebra. A deformation map unifies various well-known\noperators such as Poisson homomorphisms, Poisson derivations, crossed\nhomomorphisms, Rota-Baxter operators of any weight, twisted Rota-Baxter\noperators, Reynolds operators and modified Rota-Baxter operators on Poisson\nalgebras. We show that a deformation map $r$ induces a new Poisson algebra\nstructure and a suitable representation of it. The corresponding Poisson\ncohomology is defined to be the cohomology of the deformation map $r$. Finally,\nwe study the formal deformations of the operator $r$ in terms of the\ncohomology.","main_category":"math.RT","categories":"math.RT,math.KT,math.RA","published":"2025-04-09T10:26:22Z"}
{"aid":"http://arxiv.org/abs/2504.06773v1","title":"On the Destruction of Invariant Lagrangian Graphs for Conformal\n  Symplectic Twist Maps","summary":"In this article we investigate the fragility of invariant Lagrangian graphs\nfor dissipative maps, focusing on their destruction under small perturbations.\nInspired by Herman's work on conservative systems, we prove that all\n$C^0$-invariant Lagrangian graphs for an integrable dissipative twist maps can\nbe destroyed by perturbations that are arbitrarily small in the\n$C^{1-\\varepsilon}$-topology. This result is sharp, as evidenced by the\npersistence of $C^1$-invariant graphs under $C^1$-perturbations guaranteed by\nthe normally hyperbolic invariant manifold theorem.","main_category":"math.DS","categories":"math.DS,math.SG","published":"2025-04-09T10:54:35Z"}
{"aid":"http://arxiv.org/abs/2504.06776v1","title":"Photobombing for the Large Interferometer For Exoplanets (LIFE). A new\n  criterion for target confusion and application to a MIR rotating nulling\n  interferometer","summary":"One of the primary objectives in modern astronomy is to discover and study\nplanets with characteristics similar to Earth. This pursuit involves analyzing\nthe spectra of exoplanets and searching for biosignatures. Contamination of\nspectra by nearby objects (e.g., other planets and moons in the same system) is\na significant concern and must be addressed for future exo-Earth searching\nmissions. The aim is to estimate, for habitable planets, the probability of\nspectral contamination by other planets within the same star system. This\ninvestigation focuses on the Large Interferometer for Exoplanets (LIFE). Since\nthe Rayleigh criterion is inapplicable to interferometers such as those\nproposed for LIFE, we present new criteria based on the principle of parsimony,\nwhich take into account two types of issues: contamination or blending of point\nsources, and cancellation of point sources due to destructive interference. We\ndefine a new spatial resolution metric associated with contamination or\ncancellation that generalizes to a broader family of observing instruments. In\nthe current baseline design, LIFE is an X-array architecture nulling\ninterferometer. Our investigation reveals that its transmission map introduces\nthe potential for two point sources to appear as one, even if they do not\nappear in close proximity. We find that LIFE has a spatial resolution\ncomparable to that of a traditional telescope with a diameter of $D =\n600\\,\\text{m}$, observing at $\\lambda = 4 \\,\\mu\\text{m}$. Our survey of a star\nsystem population shows that, out of 73.4 expected habitable planets detected,\n71.3 are not contaminated on average.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM","published":"2025-04-09T10:57:20Z"}
{"aid":"http://arxiv.org/abs/2504.06785v1","title":"Zero-Shot Image-Based Large Language Model Approach to Road Pavement\n  Monitoring","summary":"Effective and rapid evaluation of pavement surface condition is critical for\nprioritizing maintenance, ensuring transportation safety, and minimizing\nvehicle wear and tear. While conventional manual inspections suffer from\nsubjectivity, existing machine learning-based methods are constrained by their\nreliance on large and high-quality labeled datasets, which require significant\nresources and limit adaptability across varied road conditions. The\nrevolutionary advancements in Large Language Models (LLMs) present significant\npotential for overcoming these challenges. In this study, we propose an\ninnovative automated zero-shot learning approach that leverages the image\nrecognition and natural language understanding capabilities of LLMs to assess\nroad conditions effectively. Multiple LLM-based assessment models were\ndeveloped, employing prompt engineering strategies aligned with the Pavement\nSurface Condition Index (PSCI) standards. These models' accuracy and\nreliability were evaluated against official PSCI results, with an optimized\nmodel ultimately selected. Extensive tests benchmarked the optimized model\nagainst evaluations from various levels experts using Google Street View road\nimages. The results reveal that the LLM-based approach can effectively assess\nroad conditions, with the optimized model -employing comprehensive and\nstructured prompt engineering strategies -outperforming simpler configurations\nby achieving high accuracy and consistency, even surpassing expert evaluations.\nMoreover, successfully applying the optimized model to Google Street View\nimages demonstrates its potential for future city-scale deployments. These\nfindings highlight the transformative potential of LLMs in automating road\ndamage evaluations and underscore the pivotal role of detailed prompt\nengineering in achieving reliable assessments.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-09T11:19:17Z"}
{"aid":"http://arxiv.org/abs/2504.06796v1","title":"Learning in Spiking Neural Networks with a Calcium-based Hebbian Rule\n  for Spike-timing-dependent Plasticity","summary":"Understanding how biological neural networks are shaped via local plasticity\nmechanisms can lead to energy-efficient and self-adaptive information\nprocessing systems, which promises to mitigate some of the current roadblocks\nin edge computing systems. While biology makes use of spikes to seamless use\nboth spike timing and mean firing rate to modulate synaptic strength, most\nmodels focus on one of the two. In this work, we present a Hebbian local\nlearning rule that models synaptic modification as a function of calcium traces\ntracking neuronal activity. We show how the rule reproduces results from spike\ntime and spike rate protocols from neuroscientific studies. Moreover, we use\nthe model to train spiking neural networks on MNIST digit recognition to show\nand explain what sort of mechanisms are needed to learn real-world patterns. We\nshow how our model is sensitive to correlated spiking activity and how this\nenables it to modulate the learning rate of the network without altering the\nmean firing rate of the neurons nor the hyparameters of the learning rule. To\nthe best of our knowledge, this is the first work that showcases how spike\ntiming and rate can be complementary in their role of shaping the connectivity\nof spiking neural networks.","main_category":"cs.NE","categories":"cs.NE,cs.AI","published":"2025-04-09T11:39:59Z"}
{"aid":"http://arxiv.org/abs/2504.06808v1","title":"How do Copilot Suggestions Impact Developers' Frustration and\n  Productivity?","summary":"Context. AI-based development tools, such as GitHub Copilot, are transforming\nthe software development process by offering real-time code suggestions. These\ntools promise to improve the productivity by reducing cognitive load and\nspeeding up task completion. Previous exploratory studies, however, show that\ndevelopers sometimes perceive the automatic suggestions as intrusive. As a\nresult, they feel like their productivity decreased. Theory. We propose two\ntheories on the impact of automatic suggestions on frustration and\nproductivity. First, we hypothesize that experienced developers are frustrated\nfrom automatic suggestions (mostly from irrelevant ones), and this also\nnegatively impacts their productivity. Second, we conjecture that novice\ndevelopers benefit from automatic suggestions, which reduce the frustration\ncaused from being stuck on a technical problem and thus increase their\nproductivity. Objective. We plan to conduct a quasi-experimental study to test\nour theories. The empirical evidence we will collect will allow us to either\ncorroborate or reject our theories. Method. We will involve at least 32\ndevelopers, both experts and novices. We will ask each of them to complete two\nsoftware development tasks, one with automatic suggestions enabled and one with\nthem disabled, allowing for within-subject comparisons. We will measure\nindependent and dependent variables by monitoring developers' actions through\nan IDE plugin and screen recording. Besides, we will collect physiological data\nthrough a wearable device. We will use statistical hypothesis tests to study\nthe effects of the treatments (i.e., automatic suggestions enabled/disabled) on\nthe outcomes (frustration and productivity).","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-09T11:55:22Z"}
{"aid":"http://arxiv.org/abs/2504.06816v1","title":"A Graph Diffusion Algorithm for Lexical Similarity Evaluation","summary":"In this paper, we present an algorithm for evaluating lexical similarity\nbetween a given language and several reference language clusters. As an input,\nwe have a list of concepts and the corresponding translations in all considered\nlanguages. Moreover, each reference language is assigned to one of $c$ language\nclusters. For each of the concepts, the algorithm computes the distance between\neach pair of translations. Based on these distances, it constructs a weighted\ndirected graph, where every vertex represents a language. After, it solves a\ngraph diffusion equation with a Dirichlet boundary condition, where the unknown\nis a map from the vertex set to $\\mathbb{R}^c$. The resulting coordinates are\nvalues from the interval $[0,1]$ and they can be interpreted as probabilities\nof belonging to each of the clusters or as a lexical similarity distribution\nwith respect to the reference clusters. The distances between translations are\ncalculated using phonetic transcriptions and a modification of the\nDamerau-Levenshtein distance. The algorithm can be useful in analyzing\nrelationships between languages spoken in multilingual territories with a lot\nof mutual influences. We demonstrate this by presenting a case study regarding\nvarious European languages.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T12:17:08Z"}
{"aid":"http://arxiv.org/abs/2504.06830v1","title":"Integrated Sensing and Communications Over the Years: An Evolution\n  Perspective","summary":"Integrated Sensing and Communications (ISAC) enables efficient spectrum\nutilization and reduces hardware costs for beyond 5G (B5G) and 6G networks,\nfacilitating intelligent applications that require both high-performance\ncommunication and precise sensing capabilities. This survey provides a\ncomprehensive review of the evolution of ISAC over the years. We examine the\nexpansion of the spectrum across RF and optical ISAC, highlighting the role of\nadvanced technologies, along with key challenges and synergies. We further\ndiscuss the advancements in network architecture from single-cell to multi-cell\nsystems, emphasizing the integration of collaborative sensing and interference\nmitigation strategies. Moreover, we analyze the progress from single-modal to\nmulti-modal sensing, with a focus on the integration of edge intelligence to\nenable real-time data processing, reduce latency, and enhance decision-making.\nFinally, we extensively review standardization efforts by 3GPP, IEEE, and ITU,\nexamining the transition of ISAC-related technologies and their implications\nfor the deployment of 6G networks.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-09T12:42:58Z"}
{"aid":"http://arxiv.org/abs/2504.06847v1","title":"Extended study of crystal structures, optical properties and vibrational\n  spectra of polar 2-aminopyrimidinium hydrogen phosphite and\n  bis(2-aminopyrimidinium) sulfate monohydrate and two 2-aminopyrimidinium\n  hydrogen sulfate polymorphs","summary":"This study aimed primarily at completing and extending the characterization\nof the crystallographic, spectroscopic and optical properties of polar,\nbiaxial, optically negative 2-aminopyrimidinium(1+) hydrogen phosphite. Besides\nthe redetermination of the low-temperature crystal structure (space group P21),\nhigh-quality single crystals of this salt were grown from an aqueous solution,\nand their optical properties were studied. The determination of the refractive\nindices in the wavelength range of 435-1083 nm showed anomalous dispersion of\nthe refractive indices, resulting in a point of uniaxiality. The crystal allows\nphase matching for collinear second harmonic generation (SHG) processes of both\ntype I and type II in a broad wavelength range. SHG properties were studied for\npowdered size-fractioned samples and oriented single-crystal cuts. The optical\ndamage threshold experiments confirmed excellent optical resistance - at least\n220 TWm-2 and 70 TWm-2 for 800 and 1000 nm irradiation, respectively. The\nlow-temperature crystallographic study was also extended for three monoclinic\nsalts of 2-aminopyrimidine and sulfuric acid - i.e. bis(2-aminopyrimidinium(1+)\nsulfate monohydrate (space group P21/n) and two polymorphs of\n2-aminopyrimidinium(1+) hydrogen sulfate (both with space group P21/c). The\nvibrational spectra of all title compounds were assigned using single-molecule\nquantum chemical computations (including Potential Energy Distribution\nanalysis) in combination with the nuclear site group analysis. Spectroscopic\nresults concerning sulfates of 2-aminopyrimidine provided valuable reference\nmaterials for the vibrational spectroscopic study and also addressed the\nquestion of their polymorphism. An optimal computational approach employing\nsolid-state DFT calculations has also been sought to model the vibrational\nspectra of 2-aminopyrimidinium (1+) hydrogen phosphite crystals.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.chem-ph","published":"2025-04-09T13:02:52Z"}
{"aid":"http://arxiv.org/abs/2504.06864v1","title":"Emergent Theory for Constitutive Relations in Classical Defect Systems","summary":"Optical, acoustic, hydrodynamic, and thermal defect systems are often studied\nby analogy with each other. This may indicate that we may find a emergent\ntheory for constitutive relations of classical defect systems. Start with\nthermal systems, we put up with a bootstrap method to describe classical\ntransport. We conjecture that Landau-Khalatnikov equation could provide heat\nconstitutive relations when taking heat flux as order parameter. We show that\nthe corresponding effctive Lagrangian has similar form of that of Wick-rotated\ncomplex scalar field theory at non-relativistic limit, and only in perfect\nconducting situation that this system is a canonical ensemble. We argue that\nour method could be generalized to other systems besides thermal ones. By\nanalogy with ferroelectrics, we propose the thermal domain model, which is a\nconserved current XY model. Phase transition of the thermal system is\nqualitatively discussed in this model.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.supr-con,hep-th","published":"2025-04-09T13:13:14Z"}
{"aid":"http://arxiv.org/abs/2504.06873v1","title":"A note on measurings and higher order Hochschild homology of algebras","summary":"We know that coalgebra measurings behave like generalized maps between\nalgebras. In this note, we show that coalgebra measurings between commutative\nalgebras induce morphisms between higher order Hochschild homology groups of\nalgebras. By higher order Hochschild homology, we mean the the Hochschild\nhomology groups of a commutative algebra with respect to a simplicial set as\nintroduced by Pirashvili.","main_category":"math.RA","categories":"math.RA","published":"2025-04-09T13:24:20Z"}
{"aid":"http://arxiv.org/abs/2504.06880v1","title":"A Dataset of Software Bill of Materials for Evaluating SBOM Consumption\n  Tools","summary":"A Software Bill of Materials (SBOM) is becoming an essential tool for\neffective software dependency management. An SBOM is a list of components used\nin software, including details such as component names, versions, and licenses.\nUsing SBOMs, developers can quickly identify software components and assess\nwhether their software depends on vulnerable libraries. Numerous tools support\nsoftware dependency management through SBOMs, which can be broadly categorized\ninto two types: tools that generate SBOMs and tools that utilize SBOMs. A\nsubstantial collection of accurate SBOMs is required to evaluate tools that\nutilize SBOMs. However, there is no publicly available dataset specifically\ndesigned for this purpose, and research on SBOM consumption tools remains\nlimited. In this paper, we present a dataset of SBOMs to address this gap. The\ndataset we constructed comprises 46 SBOMs generated from real-world Java\nprojects, with plans to expand it to include a broader range of projects across\nvarious programming languages. Accurate and well-structured SBOMs enable\nresearchers to evaluate the functionality of SBOM consumption tools and\nidentify potential issues. We collected 3,271 Java projects from GitHub and\ngenerated SBOMs for 798 of them using Maven with an open-source SBOM generation\ntool. These SBOMs were refined through both automatic and manual corrections to\nensure accuracy, currently resulting in 46 SBOMs that comply with the SPDX Lite\nprofile, which defines minimal requirements tailored to practical workflows in\nindustries. This process also revealed issues with the SBOM generation tools\nthemselves. The dataset is publicly available on Zenodo (DOI:\n10.5281/zenodo.14233415).","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-09T13:35:02Z"}
{"aid":"http://arxiv.org/abs/2504.06881v1","title":"Compound and Parallel Modes of Tropical Convolutional Neural Networks","summary":"Convolutional neural networks have become increasingly deep and complex,\nleading to higher computational costs. While tropical convolutional neural\nnetworks (TCNNs) reduce multiplications, they underperform compared to standard\nCNNs. To address this, we propose two new variants - compound TCNN (cTCNN) and\nparallel TCNN (pTCNN)-that use combinations of tropical min-plus and max-plus\nkernels to replace traditional convolution kernels. This reduces\nmultiplications and balances efficiency with performance. Experiments on\nvarious datasets show that cTCNN and pTCNN match or exceed the performance of\nother CNN methods. Combining these with conventional CNNs in deeper\narchitectures also improves performance. We are further exploring simplified\nTCNN architectures that reduce parameters and multiplications with minimal\naccuracy loss, aiming for efficient and effective models.","main_category":"cs.CV","categories":"cs.CV,cs.AI,I.2.6","published":"2025-04-09T13:36:11Z"}
{"aid":"http://arxiv.org/abs/2504.06898v1","title":"Identifying and mitigating errors in hole spin qubit readout","summary":"High-fidelity readout of spin qubits in semiconductor quantum dots can be\nachieved by combining a radio-frequency (RF) charge sensor together with\nspin-to-charge conversion and Pauli spin blockade. However, reaching high\nreadout fidelities in hole spin qubits remains elusive and is complicated by a\ncombination of site-dependent spin anisotropies and short spin relaxation\ntimes. Here, we analyze the different error processes that arise during readout\nusing a double-latched scheme in a germanium double quantum dot hole spin qubit\nsystem. We first investigate the spin-to-charge conversion process as a\nfunction of magnetic field orientation, and configure the system to\nadiabatically map the $\\lvert \\downarrow\\downarrow \\rangle$ state to the only\nnon-blockaded state. We reveal a strong dependence of the spin relaxation rates\non magnetic field strength and minimize this relaxation by operating at low\nfields. We further characterize and mitigate the error processes that arise\nduring the double-latching process. By combining an RF charge sensor, a\ndouble-latching process, and optimized magnetic field parameters, we achieve a\nsingle-shot single-qubit state-preparation-and-measurement fidelity of 97.0%,\nthe highest reported fidelity for hole spin qubits. Unlike prior works and\nvital to usability, we simultaneously maintain universal control of both spins.\nThese findings lay the foundation for the reproducible achievement of\nhigh-fidelity readout in hole-based spin quantum processors.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,quant-ph","published":"2025-04-09T13:57:26Z"}
{"aid":"http://arxiv.org/abs/2504.06901v1","title":"Classification of algebraic tangles","summary":"We study algebraic tangles as fundamental components in knot theory,\ndeveloping a systematic approach to classify and tabulate prime tangles using a\nnovel canonical representation. The canonical representation enables us to\ndistinguish mutant tangles, which fills the gaps in previous classifications.\nMoreover, we increase the classification of prime tangles up to 14 crossings\nand analyze tangle symmetry groups. We provide a database of our results:\nhttps://tangleinfo.cent.uw.edu.pl.","main_category":"math.GT","categories":"math.GT,math.AT,math.GR,math.NT","published":"2025-04-09T14:01:36Z"}
{"aid":"http://arxiv.org/abs/2504.06903v1","title":"Network Cross-Validation and Model Selection via Subsampling","summary":"Complex and larger networks are becoming increasingly prevalent in scientific\napplications in various domains. Although a number of models and methods exist\nfor such networks, cross-validation on networks remains challenging due to the\nunique structure of network data. In this paper, we propose a general\ncross-validation procedure called NETCROP (NETwork CRoss-Validation using\nOverlapping Partitions). The key idea is to divide the original network into\nmultiple subnetworks with a shared overlap part, producing training sets\nconsisting of the subnetworks and a test set with the node pairs between the\nsubnetworks. This train-test split provides the basis for a network\ncross-validation procedure that can be applied on a wide range of model\nselection and parameter tuning problems for networks. The method is\ncomputationally efficient for large networks as it uses smaller subnetworks for\nthe training step. We provide methodological details and theoretical guarantees\nfor several model selection and parameter tuning tasks using NETCROP. Numerical\nresults demonstrate that NETCROP performs accurate cross-validation on a\ndiverse set of network model selection and parameter tuning problems. The\nresults also indicate that NETCROP is computationally much faster while being\noften more accurate than the existing methods for network cross-validation.","main_category":"stat.ME","categories":"stat.ME,stat.CO","published":"2025-04-09T14:03:40Z"}
{"aid":"http://arxiv.org/abs/2504.06909v1","title":"Climate impacts of equatorial superrotation","summary":"While it is expected that the large-scale tropical circulation should undergo\nsome changes in a warmer climate, it remains an open question whether its\ncharacteristic features, such as the Hadley cell, the intertropical convergence\nzone, or the weak surface easterlies, could take a completely different shape.\nAs an example, it has been hypothesized that the Earth's atmosphere may have\nexperienced equatorial superrotation -- i.e. westerly winds at the equator --\nduring its history. The possibility of equatorial superrotation has been\nstudied in a range of planetary atmospheres, including Earth-like ones, with\nthe objective of understanding the underlying dynamical processes. However, the\nbroader impact that this dramatic circulation change would have on the climate\nsystem is practically unexplored. This is the question we address here. We\nperform idealized GCM simulations with an imposed equatorial torque to\ninvestigate how a forced superrotating atmosphere affects surface temperature\nand the water cycle. We show that these effects are quite large and directly\nrelated to the global circulation changes, which extend beyond the tropical\natmosphere. Using tools including a forcing/feedback analysis and a moist\nenergy balance model, we argue that the dominant mechanism is changes in\natmospheric energy transport, driven in particular by the collapse of the\nmeridional overturning circulation, and to a smaller extent by the appearance\nof an equatorial jet, and the concomitant redistribution of moisture in the\ntropics, leading to a much weaker relative humidity gradient which has strong\nradiative effects.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-09T14:13:56Z"}
{"aid":"http://arxiv.org/abs/2504.06913v1","title":"Controlling a Social Network of Individuals with Coevolving Actions and\n  Opinions","summary":"In this paper, we consider a population of individuals who have actions and\nopinions, which coevolve, mutually influencing one another on a complex network\nstructure. In particular, we formulate a control problem for this social\nnetwork, in which we assume that we can inject into the network a committed\nminority -- a set of stubborn nodes -- with the objective of steering the\npopulation, initially at a consensus, to a different consensus state. Our study\nfocuses on two main objectives: i) determining the conditions under which the\ncommitted minority succeeds in its goal, and ii) identifying the optimal\nplacement for such a committed minority. After deriving general monotone\nconvergence result for the controlled dynamics, we leverage these results to\nbuild a computationally-efficient algorithm to solve the first problem and an\neffective heuristics for the second problem, which we prove to be NP-complete.\nThe proposed methodology is illustrated though academic examples, and\ndemonstrated on a real-world case study.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.DS","published":"2025-04-09T14:20:46Z"}
{"aid":"http://arxiv.org/abs/2504.06935v1","title":"ASRL:A robust loss function with potential for development","summary":"In this article, we proposed a partition:wise robust loss function based on\nthe previous robust loss function. The characteristics of this loss function\nare that it achieves high robustness and a wide range of applicability through\npartition-wise design and adaptive parameter adjustment. Finally, the\nadvantages and development potential of this loss function were verified by\napplying this loss function to the regression question and using five different\ndatasets (with different dimensions, different sample numbers, and different\nfields) to compare with the other loss functions. The results of multiple\nexperiments have proven the advantages of our loss function .","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T14:40:46Z"}
{"aid":"http://arxiv.org/abs/2504.06990v1","title":"Enhancing TiFe Alloy Activation for Hydrogen Storage Through Al, Cr, Co,\n  and Cu Substitutions as a Step Towards Future Recycling","summary":"This study investigates the activation behavior of $TiFe_{0.80}$-$X_{0.20}$\n(X = Co, Cu, Cr, Al) alloys to identify the most effective materials for\nproducing hydrogen storage alloys from recycled sources in view of a circular\neconomy perspective. Activation was tested using two methods: a Sievert\nVolumetric Apparatus at room temperature and 64 bar of hydrogen, and\nhigh-pressure differential scanning calorimetry with 50 bar hydrogen under\nthermal cycles up to 400 {\\deg}C. Activation properties were analyzed by\nassessing time for incubation and for full charging, that are influenced,\nrespectively, by surface and bulk diffusion of hydrogen. Results showed that\nCr-substituted alloys are rapidly activated, due to the presence of $TiCr_{2}$\ncompound, while Al-containing alloys absorbed hydrogen immediately. In\ncontrast, Co- and Cu-substituted alloys required extended activation times, due\nto less quantity of secondary phases and limited diffusion channels.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-09T15:57:51Z"}
{"aid":"http://arxiv.org/abs/2504.07010v1","title":"Assumption-free fidelity bounds for hardware noise characterization","summary":"In the Quantum Supremacy regime, quantum computers may overcome classical\nmachines on several tasks if we can estimate, mitigate, or correct unavoidable\nhardware noise. Estimating the error requires classical simulations, which\nbecome unfeasible in the Quantum Supremacy regime. We leverage Machine Learning\ndata-driven approaches and Conformal Prediction, a Machine Learning uncertainty\nquantification tool known for its mild assumptions and finite-sample validity,\nto find theoretically valid upper bounds of the fidelity between noiseless and\nnoisy outputs of quantum devices. Under reasonable extrapolation assumptions,\nthe proposed scheme applies to any Quantum Computing hardware, does not require\nmodeling the device's noise sources, and can be used when classical simulations\nare unavailable, e.g. in the Quantum Supremacy regime.","main_category":"quant-ph","categories":"quant-ph,cs.LG,stat.ML","published":"2025-04-09T16:27:52Z"}
{"aid":"http://arxiv.org/abs/2504.07032v1","title":"Restoring the Forecasting Power of Google Trends with Statistical\n  Preprocessing","summary":"Google Trends reports how frequently specific queries are searched on Google\nover time. It is widely used in research and industry to gain early insights\ninto public interest. However, its data generation mechanism introduces missing\nvalues, sampling variability, noise, and trends. These issues arise from\nprivacy thresholds mapping low search volumes to zeros, daily sampling\nvariations causing discrepancies across historical downloads, and algorithm\nupdates altering volume magnitudes over time. Data quality has recently\ndeteriorated, with more zeros and noise, even for previously stable queries. We\npropose a comprehensive statistical methodology to preprocess Google Trends\nsearch information using hierarchical clustering, smoothing splines, and\ndetrending. We validate our approach by forecasting U.S. influenza\nhospitalizations with a univariate ARIMAX model. Compared to omitting exogenous\nvariables, our results show that raw Google Trends data degrades modeling\nperformance, while preprocessed signals enhance forecast accuracy by 58%\nnationally and 24% at the state level.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-09T16:45:58Z"}
{"aid":"http://arxiv.org/abs/2504.07043v1","title":"BIA Transmission in Rate Splitting-based Optical Wireless Networks","summary":"Optical wireless communication (OWC) has recently received massive interest\nas a new technology that can support the enormous data traffic increasing on\ndaily basis. In particular, laser-based OWC networks can provide terabits per\nsecond (Tbps) aggregate data rates. However, the emerging OWC networks require\na high number of optical access points (APs), each AP corresponding to an\noptical cell, to provide uniform coverage for multiple users. Therefore,\ninter-cell interference (ICI) and multi-user interference (MUI) are crucial\nissues that must be managed efficiently to provide high spectral efficiency. In\nradio frequency (RF) networks, rate splitting (RS) is proposed as a\ntransmission scheme to serve multiple users simultaneously following a certain\nstrategy. It was shown that RS provides high data rates compared to orthogonal\nand non-orthogonal interference management schemes. Considering the high\ndensity of OWC networks, the application of RS within each optical cell might\nnot be practical due to severe ICI. In this paper, a new strategy is derived\nreferred to as blind interference alignment-rate splitting (BIA-RS) to fully\ncoordinate the transmission among the optical APs, while determining the\nprecoding matrices of multiple groups of users formed beforehand. Therefore, RS\ncan be implemented within each group to manage MUI. The proposed BIA-RS scheme\nrequires two layers of power allocation to achieve high performance. Given\nthat, a max-min fractional optimization problem is formulated to optimally\ndistribute the power budget among the groups and the messages intended to the\nusers of each group. Finally, a power allocation algorithm is designed with\nmultiple Lagrangian multipliers to provide practical and sub-optimal solutions.\nThe results show the high performance of the proposed scheme compared to other\ncounterpart schemes.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-09T17:00:52Z"}
{"aid":"http://arxiv.org/abs/2504.07054v1","title":"Weighted Lojasiewicz inequalities and regularity of harmonic map flow","summary":"At a finite-time singularity of harmonic map flow in the critical dimension,\nwe show that a Lojasiewicz inequality between the quantities appearing in\nStruwe's monotonicity formula implies continuity of the body map and the\nno-neck property for bubble-tree decompositions. We prove such an inequality\nwhen the target is $S^2,$ yielding both properties in this case.","main_category":"math.DG","categories":"math.DG,math.AP","published":"2025-04-09T17:14:34Z"}
{"aid":"http://arxiv.org/abs/2504.07089v1","title":"OmniCaptioner: One Captioner to Rule Them All","summary":"We propose OmniCaptioner, a versatile visual captioning framework for\ngenerating fine-grained textual descriptions across a wide variety of visual\ndomains. Unlike prior methods limited to specific image types (e.g., natural\nimages or geometric visuals), our framework provides a unified solution for\ncaptioning natural images, visual text (e.g., posters, UIs, textbooks), and\nstructured visuals (e.g., documents, tables, charts). By converting low-level\npixel information into semantically rich textual representations, our framework\nbridges the gap between visual and textual modalities. Our results highlight\nthree key advantages: (i) Enhanced Visual Reasoning with LLMs, where\nlong-context captions of visual modalities empower LLMs, particularly the\nDeepSeek-R1 series, to reason effectively in multimodal scenarios; (ii)\nImproved Image Generation, where detailed captions improve tasks like\ntext-to-image generation and image transformation; and (iii) Efficient\nSupervised Fine-Tuning (SFT), which enables faster convergence with less data.\nWe believe the versatility and adaptability of OmniCaptioner can offer a new\nperspective for bridging the gap between language and visual modalities.","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-04-09T17:58:58Z"}
{"aid":"http://arxiv.org/abs/2504.07436v1","title":"Improved AFSA-Based Beam Training Without CSI for RIS-Assisted ISAC\n  Systems","summary":"In this paper, we consider transmit beamforming and reflection patterns\ndesign in reconfigurable intelligent surface (RIS)-assisted integrated sensing\nand communication (ISAC) systems, where the dual-function base station (DFBS)\nlacks channel state information (CSI). To address the high overhead of cascaded\nchannel estimation, we propose an improved artificial fish swarm algorithm\n(AFSA) combined with a feedback-based joint active and passive beam training\nscheme. In this approach, we consider the interference caused by multipath user\necho signals on target detection and propose a beamforming design method that\nbalances both communication and sensing performance. Numerical simulations show\nthat the proposed AFSA outperforms other optimization algorithms, particularly\nin its robustness against echo interference under different communication\nsignal-to-noise ratio (SNR) constraints.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-10T04:06:07Z"}
{"aid":"http://arxiv.org/abs/2504.07437v1","title":"Unifying and extending Diffusion Models through PDEs for solving Inverse\n  Problems","summary":"Diffusion models have emerged as powerful generative tools with applications\nin computer vision and scientific machine learning (SciML), where they have\nbeen used to solve large-scale probabilistic inverse problems. Traditionally,\nthese models have been derived using principles of variational inference,\ndenoising, statistical signal processing, and stochastic differential\nequations. In contrast to the conventional presentation, in this study we\nderive diffusion models using ideas from linear partial differential equations\nand demonstrate that this approach has several benefits that include a\nconstructive derivation of the forward and reverse processes, a unified\nderivation of multiple formulations and sampling strategies, and the discovery\nof a new class of models. We also apply the conditional version of these models\nto solving canonical conditional density estimation problems and challenging\ninverse problems. These problems help establish benchmarks for systematically\nquantifying the performance of different formulations and sampling strategies\nin this study, and for future studies. Finally, we identify and implement a\nmechanism through which a single diffusion model can be applied to measurements\nobtained from multiple measurement operators. Taken together, the contents of\nthis manuscript provide a new understanding and several new directions in the\napplication of diffusion models to solving physics-based inverse problems.","main_category":"cs.LG","categories":"cs.LG,stat.CO,stat.ML","published":"2025-04-10T04:07:36Z"}
{"aid":"http://arxiv.org/abs/2504.07438v1","title":"Satellite System Architecting Considering On-Orbit Refueling","summary":"This paper introduces the problem of selecting a satellite system\narchitecture considering commercial on-orbit refueling (OOR). The problem aims\nto answer two questions: \"How durable should a satellite be?\" and \"How much\npropellant should be loaded into the satellite at launch?\" We formulate the\nproblem as a mathematical optimization by adopting the design lifetime and\npropellant mass as design variables and considering two objective functions to\nbalance the returns and risks. A surrogate model-based framework, grounded in a\nsatellite lifecycle simulation, is developed to address this problem. The\ndeveloped framework considers various uncertainties and operational flexibility\nand integrates a modified satellite sizing and cost model by adjusting\ntraditional models with OOR. A design case study of a geosynchronous equatorial\norbit communication satellite considering the OOR highlights the effectiveness\nof the developed framework.","main_category":"math.OC","categories":"math.OC","published":"2025-04-10T04:07:58Z"}
{"aid":"http://arxiv.org/abs/2504.07446v1","title":"A mass conserved reaction-diffusion system reveals switching between\n  coexisting polar and oscillatory cell motility states","summary":"Motile eukaryotic cells display distinct modes of migration that often occur\nwithin the same cell type. It remains unclear, however, whether transitions\nbetween the migratory modes require changes in external conditions, or whether\nthe different modes are coexisting states that emerge from the underlying\nsignaling network. Using a mass-conserved reaction-diffusion model of small\nGTPase signaling with F-actin mediated feedback, we uncover a bistable regime\nwhere a polarized mode of migration coexists with spatiotemporal oscillations.\nIndeed, experimental observations of D. discoideum show that, upon collision\nwith a rigid boundary, cells may switch from polarized to disordered motion.","main_category":"nlin.PS","categories":"nlin.PS,q-bio.CB","published":"2025-04-10T04:31:22Z"}
{"aid":"http://arxiv.org/abs/2504.07460v1","title":"Measuring Cosmic Growth Rate with CSST Spectroscopic Survey and Fast\n  Radio Burst","summary":"The cosmic growth rate, which is related to peculiar velocity and is a\nprimary scientific objective of galaxy spectroscopic surveys, can be inferred\nfrom the Redshift Space Distortion effect and the kinetic Sunyaev-Zel'dovich\neffect. However, the reconstruction noise power spectrum of the radial velocity\nfield in kSZ is significantly dependent on the measurement of the small-scale\ngalaxy-electron power spectrum $P_{ge}$. In this study, we thoroughly discuss\nthe enhancement of cosmic growth rate measurements facilitated by Fast Radio\nBursts, which probe the electron density of the universe along their\npropagation paths to provide crucial additional information on $P_{ge}$.\nSubsequently, we utilize future spectroscopic surveys from the Chinese Space\nStation Telescope and the CMB-S4 experiment, combined with FRB dispersion\nmeasures, to achieve precise measurements of the cosmic growth rate at\nredshifts $z_g = 0.15,0.45,0.75$. Employing Fisher matrix forecasting analysis,\nwe anticipate that constraints on $f\\sigma_8$ will reach a precision of 0.001\nwith a sample size of $10^6$ FRBs. Furthermore, we perform a global analysis\nusing Markov Chain Monte Carlo methods to constrain key parameters of three\ndistinct dark energy models and a modified gravity model based on cosmic growth\nrate measurements. The results demonstrate that these refined $f\\sigma_8$\nmeasurements considerably enhance the constraints on relevant cosmological\nparameters compared to those obtained from Planck. As the number of observed\nFRBs increases, alongside more precise galaxy surveys and next-generation CMB\nobservations, new opportunities will arise for constraining cosmological models\nusing the kSZ effect and for developing novel cosmological applications of\nFRBs.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-10T05:10:15Z"}
{"aid":"http://arxiv.org/abs/2504.07495v1","title":"Bottleneck Identification in Resource-Constrained Project Scheduling via\n  Constraint Relaxation","summary":"In realistic production scenarios, Advanced Planning and Scheduling (APS)\ntools often require manual intervention by production planners, as the system\nworks with incomplete information, resulting in suboptimal schedules. Often,\nthe preferable solution is not found just because of the too-restrictive\nconstraints specifying the optimization problem, representing bottlenecks in\nthe schedule. To provide computer-assisted support for decision-making, we aim\nto automatically identify bottlenecks in the given schedule while linking them\nto the particular constraints to be relaxed. In this work, we address the\nproblem of reducing the tardiness of a particular project in an obtained\nschedule in the resource-constrained project scheduling problem by relaxing\nconstraints related to identified bottlenecks. We develop two methods for this\npurpose. The first method adapts existing approaches from the job shop\nliterature and utilizes them for so-called untargeted relaxations. The second\nmethod identifies potential improvements in relaxed versions of the problem and\nproposes targeted relaxations. Surprisingly, the untargeted relaxations result\nin improvements comparable to the targeted relaxations.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-10T06:53:10Z"}
{"aid":"http://arxiv.org/abs/2504.07515v1","title":"Sequential Filtering Techniques for Simultaneous Tracking and Parameter\n  Estimation","summary":"The number of resident space objects is rising at an alarming rate.\nMega-constellations and breakup events are proliferating in most orbital\nregimes, and safe navigation is becoming increasingly problematic. It is\nimportant to be able to track RSOs accurately and at an affordable\ncomputational cost. Orbital dynamics are highly nonlinear, and current\noperational methods assume Gaussian representations of the objects' states and\nemploy linearizations which cease to hold true in observation-free propagation.\nMonte Carlo-based filters can provide a means to approximate the a posteriori\nprobability distribution of the states more accurately by providing support in\nthe portion of the state space which overlaps the most with the processed\nobservations. Moreover, dynamical models are not able to capture the full\nextent of realistic forces experienced in the near-Earth space environment, and\nhence fully deterministic propagation methods may fail to achieve the desired\naccuracy. By modeling orbital dynamics as a stochastic system and solving it\nusing stochastic numerical integrators, we are able to simultaneously estimate\nthe scale of the process noise incurred by the assumed uncertainty in the\nsystem, and robustly track the state of the spacecraft. In order to find an\nadequate balance between accuracy and computational cost, we propose three\nalgorithms which are capable of tracking a space object and estimating the\nmagnitude of the system's uncertainty. The proposed filters are successfully\napplied to a LEO scenario, demonstrating the ability to accurately track a\nspacecraft state and estimate the scale of the uncertainty online, in various\nsimulation setups.","main_category":"astro-ph.IM","categories":"astro-ph.IM,stat.AP","published":"2025-04-10T07:23:00Z"}
{"aid":"http://arxiv.org/abs/2504.07529v1","title":"Automating the Path: An R&D Agenda for Human-Centered AI and\n  Visualization","summary":"The emergence of generative AI, large language models (LLMs), and foundation\nmodels is fundamentally reshaping computer science, and visualization and\nvisual analytics are no exception. We present a systematic framework for\nunderstanding how human-centered AI (HCAI) can transform the visualization\ndiscipline. Our framework maps four key HCAI tool capabilities -- amplify,\naugment, empower, and enhance -- onto the four phases of visual sensemaking:\nview, explore, schematize, and report. For each combination, we review existing\ntools, envision future possibilities, identify challenges and pitfalls, and\nexamine ethical considerations. This design space can serve as an R\\&D agenda\nfor both visualization researchers and practitioners to integrate AI into their\nwork as well as understanding how visualization can support HCAI research.","main_category":"cs.HC","categories":"cs.HC,H.5.2","published":"2025-04-10T07:52:18Z"}
{"aid":"http://arxiv.org/abs/2504.07584v1","title":"REANIMATOR: Reanimate Retrieval Test Collections with Extracted and\n  Synthetic Resources","summary":"Retrieval test collections are essential for evaluating information retrieval\nsystems, yet they often lack generalizability across tasks. To overcome this\nlimitation, we introduce REANIMATOR, a versatile framework designed to enable\nthe repurposing of existing test collections by enriching them with extracted\nand synthetic resources. REANIMATOR enhances test collections from PDF files by\nparsing full texts and machine-readable tables, as well as related contextual\ninformation. It then employs state-of-the-art large language models to produce\nsynthetic relevance labels. Including an optional human-in-the-loop step can\nhelp validate the resources that have been extracted and generated. We\ndemonstrate its potential with a revitalized version of the TREC-COVID test\ncollection, showcasing the development of a retrieval-augmented generation\nsystem and evaluating the impact of tables on retrieval-augmented generation.\nREANIMATOR enables the reuse of test collections for new applications, lowering\ncosts and broadening the utility of legacy resources.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-10T09:25:11Z"}
{"aid":"http://arxiv.org/abs/2504.07590v1","title":"DWFS-Obfuscation: Dynamic Weighted Feature Selection for Robust Malware\n  Familial Classification under Obfuscation","summary":"Due to its open-source nature, the Android operating system has consistently\nbeen a primary target for attackers. Learning-based methods have made\nsignificant progress in the field of Android malware detection. However,\ntraditional detection methods based on static features struggle to identify\nobfuscated malicious code, while methods relying on dynamic analysis suffer\nfrom low efficiency. To address this, we propose a dynamic weighted feature\nselection method that analyzes the importance and stability of features,\ncalculates scores to filter out the most robust features, and combines these\nselected features with the program's structural information. We then utilize\ngraph neural networks for classification, thereby improving the robustness and\naccuracy of the detection system. We analyzed 8,664 malware samples from eight\nmalware families and tested a total of 44,940 malware variants generated using\nseven obfuscation strategies. Experiments demonstrate that our proposed method\nachieves an F1-score of 95.56% on the unobfuscated dataset and 92.28% on the\nobfuscated dataset, indicating that the model can effectively detect obfuscated\nmalware.","main_category":"cs.CR","categories":"cs.CR,I.2.7","published":"2025-04-10T09:37:43Z"}
{"aid":"http://arxiv.org/abs/2504.07619v1","title":"Beating Transformers using Synthetic Cognition","summary":"The road to Artificial General Intelligence goes through the generation of\nepisodic reactive behaviors, where the Transformer architecture has been proven\nto be the state-of-the-art. However, they still fail to develop reasoning.\nRecently, a novel approach for developing cognitive architectures, called\nSynthetic Cognition, has been proposed and implemented to develop instantaneous\nreactive behavior. In this study, we aim to explore the use of Synthetic\nCognition to develop episodic reactive behaviors. We propose a mechanism to\ndeal with sequences for the recent implementation of Synthetic Cognition, and\ntest it against DNA foundation models in DNA sequence classification tasks. In\nour experiments, our proposal clearly outperforms the DNA foundation models,\nobtaining the best score on more benchmark tasks than the alternatives. Thus,\nwe achieve two goals: expanding Synthetic Cognition to deal with sequences, and\nbeating the Transformer architecture for sequence classification.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-10T10:07:05Z"}
{"aid":"http://arxiv.org/abs/2504.07621v1","title":"What causes long outbursts of neutron star low-mass X-ray binaries?","summary":"Many neutron star low-mass X-ray binaries (NS LMXBs) with short orbital\nperiods (~hours) cycle between outburst and quiescent phases, and thus provide\nan excellent way to study the accretion process. The cause of such outbursts is\nbelieved to be thermal-viscous instability in the accretion disc. However, some\nof these transient sources show unusually long outbursts. For example, EXO\n0748-676 remained in outburst for at least 23 years before entering a\nquiescence, only to re-emerge 16 years later. We aim to investigate if such\nlong outbursts could be due to the usual disc instability, or if any other\nmechanism is required. In order to address this question, we systematically\ncompare various properties of long outburst and short outburst NS LMXBs. For\nthis, we analyze the long-term X-ray light curves of many short orbital period\n(hours) NS LMXBs, examining the outburst duration and the inferred accretion\nrate, and estimate the accretion disc mass. Our study shows that long outburst\nsources are well-separated from the short outburst ones in parameter spaces\ninvolving accretion rate, disc mass, outburst duration, etc. in four ways. This\nimplies that the thermal-viscous instability in the disc cannot explain the\nlong outbursts, but could explain the short ones. Moreover, we discuss that\nboth donor star related and disc related models have difficulties in explaining\nlong outbursts. Our finding will be crucial to understanding the accretion\nprocess of transiently accreting neutron stars and black holes.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-10T10:09:32Z"}
{"aid":"http://arxiv.org/abs/2504.07681v1","title":"Role of activity and dissipation in achieving precise beating in cilia:\n  Insights from the rower model","summary":"Cilia and flagella are micron-sized filaments that actively beat with\nremarkable precision in a viscous medium, driving microorganism movement and\nefficient flow. We study the rower model to uncover how cilia activity and\ndissipation enable this precise motion. In this model, cilia motion is\nrepresented by a micro-beads Brownian movement between two distant harmonic\npotentials. At specific locations, energy pumps trigger potential switches,\ncapturing cilia activity and generating oscillations. We quantify precision of\noscillation using a quality factor, identifying its scaling with activity and\noscillation amplitude, finding precision maximization at an optimal amplitude.\nThe data collapse is not accurate for noisy oscillations. An exact analytic\nexpression for the precision quality factor, based on first passage time\nfluctuations, and derived in the small noise approximation, explains its\noptimality and scaling. Energy budget analysis shows the quality factor's\nconsistency with the thermodynamic uncertainty relation.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-10T12:09:46Z"}
{"aid":"http://arxiv.org/abs/2504.07682v1","title":"Hallmarks of terahertz magnon currents in an antiferromagnetic insulator","summary":"The efficient transport of spin angular momentum is expected to play a\ncrucial role in future spintronic devices, which potentially operate at\nfrequencies reaching the terahertz range. Antiferromagnetic insulators exhibit\nsignificant potential for facilitating ultrafast pure spin currents by\nterahertz magnons. Consequently, we here use femtosecond laser pulses to\ntrigger ultrafast spin currents across antiferromagnetic NiO thin films in\nPy|NiO|Pt stacks, where permalloy (Py) and Pt serve as spin-current source and\ndetector respectively. We find that the spin current pulses traversing NiO\nreach a velocity up to 40 nm/ps and experience increasing delay and broadening\nas the NiO thickness is increased. We can consistently explain our observations\nby ballistic transport of incoherent magnon. Our approach has high potential to\ncharacterize terahertz magnon transport in magnetic insulators with any kind of\nmagnetic order.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-10T12:09:55Z"}
{"aid":"http://arxiv.org/abs/2504.07703v1","title":"Optimal Frequency Support from Virtual Power Plants: Minimal Reserve and\n  Allocation","summary":"This paper proposes a novel reserve-minimizing and allocation strategy for\nvirtual power plants (VPPs) to deliver optimal frequency support. The proposed\nstrategy enables VPPs, acting as aggregators for inverter-based resources\n(IBRs), to provide optimal frequency support economically. The proposed\nstrategy captures time-varying active power injections, reducing the\nunnecessary redundancy compared to traditional fixed reserve schemes. Reserve\nrequirements for the VPPs are determined based on system frequency response and\nsafety constraints, ensuring efficient grid support. Furthermore, an\nenergy-based allocation model decomposes power injections for each IBR,\naccounting for their specific limitations. Numerical experiments validate the\nfeasibility of the proposed approach, highlighting significant financial gains\nfor VPPs, especially as system inertia decreases due to higher renewable energy\nintegration.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-10T12:43:38Z"}
{"aid":"http://arxiv.org/abs/2504.07720v1","title":"Filtering through a topological lens: homology for point processes on\n  the time-frequency plane","summary":"We introduce a very general approach to the analysis of signals from their\nnoisy measurements from the perspective of Topological Data Analysis (TDA).\nWhile TDA has emerged as a powerful analytical tool for data with pronounced\ntopological structures, here we demonstrate its applicability for general\nproblems of signal processing, without any a-priori geometric feature. Our\nmethods are well-suited to a wide array of time-dependent signals in different\nscientific domains, with acoustic signals being a particularly important\napplication. We invoke time-frequency representations of such signals, focusing\non their zeros which are gaining salience as a signal processing tool in view\nof their stability properties. Leveraging state-of-the-art topological\nconcepts, such as stable and minimal volumes, we develop a complete suite of\nTDA-based methods to explore the delicate stochastic geometry of these zeros,\ncapturing signals based on the disruption they cause to this rigid,\nhyperuniform spatial structure. Unlike classical spatial data tools, TDA is\nable to capture the full spectrum of the stochastic geometry of the zeros,\nthereby leading to powerful inferential outcomes that are underpinned by a\nprincipled statistical foundation. This is reflected in the power and\nversatility of our applications, which include competitive performance in\nprocessing. a wide variety of audio signals (esp. in low SNR regimes),\neffective detection and reconstruction of gravitational wave signals (a reputed\nsignal processing challenge with non-Gaussian noise), and medical time series\ndata from EEGs, indicating a wide horizon for the approach and methods\nintroduced in this paper.","main_category":"eess.SP","categories":"eess.SP,math.AT","published":"2025-04-10T13:10:04Z"}
{"aid":"http://arxiv.org/abs/2504.07721v1","title":"From empirical brain networks towards modeling music perception -- a\n  perspective","summary":"This perspective article investigates how auditory stimuli influence neural\nnetwork dynamics using the FitzHugh-Nagumo (FHN) model and empirical brain\nconnectivity data. Results show that synchronization is sensitive to both the\nfrequency and amplitude of auditory input, with synchronization enhanced when\ninput frequencies align with the system's intrinsic frequencies. Increased\nstimulus amplitude broadens the synchronization range governed by a delicate\ninterplay involving the network's topology, the spatial location of the input,\nand the frequency characteristics of the cortical input signals. This\nperspective article also reveals that brain activity alternates between\nsynchronized and desynchronized states, reflecting critical dynamics and phase\ntransitions in neural networks. Notably, gamma-band synchronization is crucial\nfor processing music, with coherence peaking in this frequency range. The\nfindings emphasize the role of structural connectivity and network topology in\nmodulating synchronization, providing insights into how music perception\nengages brain networks. This perspective article offers a computational\nframework for understanding neural mechanisms in music perception, with\npotential implications for cognitive neuroscience and music psychology.","main_category":"q-bio.NC","categories":"q-bio.NC,nlin.AO","published":"2025-04-10T13:13:53Z"}
{"aid":"http://arxiv.org/abs/2504.07722v1","title":"Relaxing the Markov Requirements on Reinforcement Learning Under Weak\n  Partial Ignorability","summary":"Incomplete data, confounding effects, and violations of the Markov property\nare interrelated problems which are ubiquitous in Reinforcement Learning\napplications. We introduce the concept of ``partial ignorabilty\" and leverage\nit to establish a novel convergence theorem for adaptive Reinforcement\nLearning. This theoretical result relaxes the Markov assumption on the\nstochastic process underlying conventional $Q$-learning, deploying a\ngeneralized form of the Robbins-Monro stochastic approximation theorem to\nestablish optimality. This result has clear downstream implications for most\nactive subfields of Reinforcement Learning, with clear paths for extension to\nthe field of Causal Inference.","main_category":"cs.LG","categories":"cs.LG,stat.ME","published":"2025-04-10T13:15:52Z"}
{"aid":"http://arxiv.org/abs/2504.07726v1","title":"Quantum Machine Learning: Unveiling Trends, Impacts through Bibliometric\n  Analysis","summary":"Quantum Machine Learning (QML) is the intersection of two revolutionary\nfields: quantum computing and machine learning. It promises to unlock\nunparalleled capabilities in data analysis, model building, and problem-solving\nby harnessing the unique properties of quantum mechanics. This research\nendeavors to conduct a comprehensive bibliometric analysis of scientific\ninformation pertaining to QML covering the period from 2000 to 2023. An\nextensive dataset comprising 9493 scholarly works is meticulously examined to\nunveil notable trends, impact factors, and funding patterns within the domain.\nAdditionally, the study employs bibliometric mapping techniques to visually\nillustrate the network relationships among key countries, institutions,\nauthors, patent citations and significant keywords in QML research. The\nanalysis reveals a consistent growth in publications over the examined period.\nThe findings highlight the United States and China as prominent contributors,\nexhibiting substantial publication and citation metrics. Notably, the study\nconcludes that QML, as a research subject, is currently in a formative stage,\ncharacterized by robust scholarly activity and ongoing development.","main_category":"cs.DL","categories":"cs.DL,cs.LG","published":"2025-04-10T13:18:48Z"}
{"aid":"http://arxiv.org/abs/2504.07770v1","title":"Sublevels in arrangements and the spherical arc crossing number of\n  complete graphs","summary":"Levels and sublevels in arrangements -- and, dually, $k$-sets and $(\\leq\nk)$-sets -- are fundamental notions in discrete and computational geometry and\nnatural generalizations of convex polytopes, which correspond to the $0$-level.\nA long-standing conjecture of Eckhoff, Linhart, and Welzl, which would\ngeneralize McMullen's Upper Bound Theorem for polytopes and provide an exact\nrefinement of asymptotic bounds by Clarkson, asserts that for all $k\\leq\n\\lfloor \\frac{n-d-2}{2}\\rfloor$, the number of $(\\leq k)$-sets of a set $S$ of\n$n$ points in $\\mathbf{R}^d$ is maximized if $S$ is the vertex set of a\nneighborly polytope.\n  As a new tool for studying this conjecture and related problems, we introduce\nthe $g$-matrix, which generalizes both the $g$-vector of a simple polytope and\na Gale dual version of the $g$-vector studied by Lee and Welzl. Our main result\nis that the $g$-matrix of every vector configuration in $\\mathbf{R}^3$ is\nnon-negative, which implies the Eckhoff--Linhart--Welzl conjecture in the case\nwhere $d=n-4$.\n  As a corollary, we obtain the following result about crossing numbers:\nConsider a configuration $V\\subset S^2 \\subset \\mathbf{R}^3$ of $n$ unit\nvectors, and connect every pair of vectors by the unique shortest geodesic arc\nbetween them in the unit sphere $S^2$. This yields a drawing of the complete\ngraph $K_n$ in $S^2$, which we call a spherical arc drawing. Complementing\nprevious results for rectilinear drawings, we show that the number of crossings\nin any spherical arc drawing of $K_n$ is at least $\\frac{1}{4}\\lfloor\n\\frac{n}{2}\\rfloor \\lfloor \\frac{n-1}{2}\\rfloor \\lfloor \\frac{n-2}{2}\\rfloor\n\\lfloor \\frac{n-3}{2}\\rfloor$, which equals the conjectured value of the\ncrossing number of $K_n$. Moreover, the lower bound is attained if $V$ is\nconeighborly, i.e., if every open linear halfspace contains at least $\\lfloor\n(n-2)/2 \\rfloor$ of the vectors in $V$.","main_category":"math.CO","categories":"math.CO,cs.CG","published":"2025-04-10T14:10:15Z"}
{"aid":"http://arxiv.org/abs/2504.07779v1","title":"Genetic Programming with Reinforcement Learning Trained Transformer for\n  Real-World Dynamic Scheduling Problems","summary":"Dynamic scheduling in real-world environments often struggles to adapt to\nunforeseen disruptions, making traditional static scheduling methods and\nhuman-designed heuristics inadequate. This paper introduces an innovative\napproach that combines Genetic Programming (GP) with a Transformer trained\nthrough Reinforcement Learning (GPRT), specifically designed to tackle the\ncomplexities of dynamic scheduling scenarios. GPRT leverages the Transformer to\nrefine heuristics generated by GP while also seeding and guiding the evolution\nof GP. This dual functionality enhances the adaptability and effectiveness of\nthe scheduling heuristics, enabling them to better respond to the dynamic\nnature of real-world tasks. The efficacy of this integrated approach is\ndemonstrated through a practical application in container terminal truck\nscheduling, where the GPRT method outperforms traditional GP, standalone\nTransformer methods, and other state-of-the-art competitors. The key\ncontribution of this research is the development of the GPRT method, which\nshowcases a novel combination of GP and Reinforcement Learning (RL) to produce\nrobust and efficient scheduling solutions. Importantly, GPRT is not limited to\ncontainer port truck scheduling; it offers a versatile framework applicable to\nvarious dynamic scheduling challenges. Its practicality, coupled with its\ninterpretability and ease of modification, makes it a valuable tool for diverse\nreal-world scenarios.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-10T14:18:22Z"}
{"aid":"http://arxiv.org/abs/2504.07780v1","title":"Interference-caged quantum many-body scars: the Fock space topological\n  localization and interference zeros","summary":"We propose a general mechanism for realizing athermal finite-energy-density\neigenstates -- termed interference-caged quantum many-body scars (ICQMBS) --\nwhich originate from exact many-body destructive interference on the Fock space\ngraph. These eigenstates are strictly localized to specific subsets of\nvertices, analogous to compact localized states in flat-band systems. Central\nto our framework is a connection between interference zeros and graph\nautomorphisms, which classify vertices according to the graph's local topology.\nThis connection enables the construction of a new class of topological ICQMBS,\nwhose robustness arises from the local topology of the Fock space graph rather\nthan from conventional conservation laws or dynamical constraints. We\ndemonstrate the effectiveness of this framework by developing a\ngraph-theory-based search algorithm, which identifies ICQMBS in both a\none-dimensional spin-1 XY model and two-dimensional quantum link models across\ndistinct gauge sectors. In particular, we discover the proposed topological\nICQMBS in the two-dimensional quantum link model and provide an intuitive\nexplanation for previously observed order-by-disorder phenomena in Hilbert\nspace. Our results reveal an unexpected synergy between graph theory, flat-band\nphysics, and quantum many-body dynamics, offering new insights into the\nstructure and stability of nonthermal eigenstates.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.other","published":"2025-04-10T14:18:34Z"}
{"aid":"http://arxiv.org/abs/2504.07785v1","title":"Towards Micro-Action Recognition with Limited Annotations: An\n  Asynchronous Pseudo Labeling and Training Approach","summary":"Micro-Action Recognition (MAR) aims to classify subtle human actions in\nvideo. However, annotating MAR datasets is particularly challenging due to the\nsubtlety of actions. To this end, we introduce the setting of Semi-Supervised\nMAR (SSMAR), where only a part of samples are labeled. We first evaluate\ntraditional Semi-Supervised Learning (SSL) methods to SSMAR and find that these\nmethods tend to overfit on inaccurate pseudo-labels, leading to error\naccumulation and degraded performance. This issue primarily arises from the\ncommon practice of directly using the predictions of classifier as\npseudo-labels to train the model. To solve this issue, we propose a novel\nframework, called Asynchronous Pseudo Labeling and Training (APLT), which\nexplicitly separates the pseudo-labeling process from model training.\nSpecifically, we introduce a semi-supervised clustering method during the\noffline pseudo-labeling phase to generate more accurate pseudo-labels.\nMoreover, a self-adaptive thresholding strategy is proposed to dynamically\nfilter noisy labels of different classes. We then build a memory-based\nprototype classifier based on the filtered pseudo-labels, which is fixed and\nused to guide the subsequent model training phase. By alternating the two\npseudo-labeling and model training phases in an asynchronous manner, the model\ncan not only be learned with more accurate pseudo-labels but also avoid the\noverfitting issue. Experiments on three MAR datasets show that our APLT largely\noutperforms state-of-the-art SSL methods. For instance, APLT improves accuracy\nby 14.5\\% over FixMatch on the MA-12 dataset when using only 50\\% labeled data.\nCode will be publicly available.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T14:22:15Z"}
{"aid":"http://arxiv.org/abs/2504.07797v1","title":"Event-Triggered Source Seeking Control for Nonholonomic Systems","summary":"This paper introduces an event-triggered source seeking control (ET-SSC) for\nautonomous vehicles modeled as the nonholonomic unicycle. The classical source\nseeking control is enhanced with static-triggering conditions to enable\naperiodic and less frequent updates of the system's input signals, offering a\nresource-aware control design. Our convergence analysis is based on\ntime-scaling combined with Lyapunov and averaging theories for systems with\ndiscontinuous right-hand sides. ET-SSC ensures exponentially stable behavior\nfor the resulting average system, leading to practical asymptotic convergence\nto a small neighborhood of the source point. We guarantee the avoidance of Zeno\nbehavior by establishing a minimum dwell time to prevent infinitely fast\nswitching. The performance optimization is aligned with classical\ncontinuous-time source seeking algorithms while balancing system performance\nwith actuation resource consumption. Our ET-SSC algorithm, the first of its\nkind, allows for arbitrarily large inter-sampling times, overcoming the\nlimitations of classical sampled-data implementations for source seeking\ncontrol.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-10T14:36:56Z"}
{"aid":"http://arxiv.org/abs/2504.07805v1","title":"Symmetry energy dependence of the bulk viscosity of nuclear matter","summary":"We clarify how the weak-interaction-driven bulk viscosity $\\zeta$ and the\nbulk relaxation time $\\tau_\\Pi$ of neutrino-transparent $npe$ matter depend on\nthe nuclear symmetry energy. We show that, at saturation density, the\nequation-of-state dependence of these transport quantities is fully determined\nby the experimentally constrained nuclear symmetry energy $S$ and its slope\n$L$. Variations of $L$ within current experimental uncertainties can change the\n(frequency-independent) bulk viscosity by orders of magnitude. This suggests\nthat dissipative effects encoded in the gravitational-wave signatures of binary\nneutron star inspirals may help constrain nuclear symmetry energy properties.","main_category":"nucl-th","categories":"nucl-th,astro-ph.HE","published":"2025-04-10T14:42:50Z"}
{"aid":"http://arxiv.org/abs/2504.07812v1","title":"Numerical instability of non-Hermitian Hamiltonian evolutions","summary":"The extreme sensitivity of non-Hermitian Hamiltonians exhibiting the\nnon-Hermitian skin effect (NHSE) has been extensively studied in recent years\nwith well-established theoretical explanations. However, this sensitivity is\noften overlooked in numerical calculations, as seen in Refs.\n\\cite{NHSEEPTKawabata, Schiro}. In this work, we examine the solvable\nHatano-Nelson and symplectic Hatano-Nelson models, comparing our high-precision\nresults with those in Ref. \\cite{NHSEEPTKawabata}. We systematically\ninvestigate inaccuracies in physical results arising from neglecting numerical\nerrors during diagonalization and non-Hermitian Hamiltonian evolution.\nMoreover, we attribute these numerical instabilities to the large condition\nnumber, which grows exponentially with system size due to NHSE, indicating\nstrong normality. Interestingly, it is found that a reliable spectrum alone is\ninsufficient for accurate non-Hermitian evolution, while the reliability of\nwavefunctions plays a more critical role. To ensure the accuracy of numerical\nresults for non-Hermitian systems exhibiting NHSE, our work underscores the\nimportance of estimating the condition number before performing numerical\ncomputations.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-10T14:50:22Z"}
{"aid":"http://arxiv.org/abs/2504.07833v1","title":"Operator growth in many-body systems of higher spins","summary":"We study operator growth in many-body systems with on-site spins larger than\n$1/2$, considering both non-integrable and integrable regimes. Specifically, we\ncompute Lanczos coefficients in the one- and two-dimensional Ising models for\nspin values $S=1/2$, $1$, and $3/2$, and observe asymptotically linear growth\n$b_n \\sim n$. On the integrable side, we investigate the Potts model and find\nsquare-root growth $b_n \\sim \\sqrt{n}$. Both results are consistent with the\npredictions of the Universal Operator Growth Hypothesis. To analyze operator\ndynamics in this setting, we employ a generalized operator basis constructed\nfrom tensor products of shift and clock operators, extending the concept of\nPauli strings to higher local dimensions. We further report that the recently\nintroduced formalism of equivalence classes of Pauli strings can be naturally\nextended to this setting. This formalism enables the study of simulable\nHeisenberg dynamics by identifying dynamically isolated operator subspaces of\nmoderate dimensionality. As an example, we introduce the Kitaev-Potts model\nwith spin-$1$, where the identification of such a subspace allows for exact\ntime evolution at a computational cost lower than that of exact\ndiagonalization.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-10T15:10:28Z"}
{"aid":"http://arxiv.org/abs/2504.07844v1","title":"A quantum computing approach to beam angle optimization","summary":"Background: Beam angle optimization (BAO) is a critical component of\nradiation therapy (RT) treatment planning, where small changes in beam\nconfiguration can significantly impact treatment quality, especially for proton\nRT. Mathematically, BAO is a mixed integer programming (MIP) problem, which is\nNP-hard due to its exponential growing search space. Traditional optimization\ntechniques often struggle with computational efficiency, necessitating the\ndevelopment of novel approaches. Purpose: This study introduces QC-BAO, a\nhybrid quantum-classical approach that leverages quantum computing to solve the\nMIP formulation of BAO. Methods: The proposed approach, QC-BAO, models BAO as\nan MIP problem, incorporating binary variables for beam angle selection and\ncontinuous variables for optimizing spot intensities for proton therapy. The\nproposed approach employs a hybrid quantum-classical framework, utilizing\nquantum computing to solve the binary decision component while integrating\nclassical optimization techniques, including iterative convex relaxation and\nalternating direction method of multipliers. Results: Computational experiments\nwere conducted on clinical test cases to evaluate QC-BAO's performance against\nclinically verified angles and a heuristic approach, GS-BAO. QC-BAO\ndemonstrated improved treatment plan quality over both clinical and GS-BAO. The\nmethod consistently increased the conformity index (CI) for target coverage\nwhile reducing mean and maximum doses to organs-at-risk (OAR). Additionally,\nQC-BAO produced the lowest objective function value, confirming its superior\noptimization capability. Conclusions: The findings highlight the potential of\nquantum computing to enhance the solution to BAO problem by demonstrated\nimprovement in plan quality using the proposed method, QC-BAO. This study paves\nthe way for future clinical implementation of quantum-accelerated optimization\nin RT.","main_category":"physics.med-ph","categories":"physics.med-ph","published":"2025-04-10T15:24:37Z"}
{"aid":"http://arxiv.org/abs/2504.07910v1","title":"Hodge Laplacians and Hodge Diffusion Maps","summary":"We introduce Hodge Diffusion Maps, a novel manifold learning algorithm\ndesigned to analyze and extract topological information from high-dimensional\ndata-sets. This method approximates the exterior derivative acting on\ndifferential forms, thereby providing an approximation of the Hodge Laplacian\noperator. Hodge Diffusion Maps extend existing non-linear dimensionality\nreduction techniques, including vector diffusion maps, as well as the theories\nbehind diffusion maps and Laplacian Eigenmaps. Our approach captures\nhigher-order topological features of the data-set by projecting it into\nlower-dimensional Euclidean spaces using the Hodge Laplacian. We develop a\ntheoretical framework to estimate the approximation error of the exterior\nderivative, based on sample points distributed over a real manifold. Numerical\nexperiments support and validate the proposed methodology.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-10T16:30:13Z"}
{"aid":"http://arxiv.org/abs/2504.07911v1","title":"The Urban Impact of AI: Modeling Feedback Loops in Next-Venue\n  Recommendation","summary":"Next-venue recommender systems are increasingly embedded in location-based\nservices, shaping individual mobility decisions in urban environments. While\ntheir predictive accuracy has been extensively studied, less attention has been\npaid to their systemic impact on urban dynamics. In this work, we introduce a\nsimulation framework to model the human-AI feedback loop underpinning\nnext-venue recommendation, capturing how algorithmic suggestions influence\nindividual behavior, which in turn reshapes the data used to retrain the\nmodels. Our simulations, grounded in real-world mobility data, systematically\nexplore the effects of algorithmic adoption across a range of recommendation\nstrategies. We find that while recommender systems consistently increase\nindividual-level diversity in visited venues, they may simultaneously amplify\ncollective inequality by concentrating visits on a limited subset of popular\nplaces. This divergence extends to the structure of social co-location\nnetworks, revealing broader implications for urban accessibility and spatial\nsegregation. Our framework operationalizes the feedback loop in next-venue\nrecommendation and offers a novel lens through which to assess the societal\nimpact of AI-assisted mobility-providing a computational tool to anticipate\nfuture risks, evaluate regulatory interventions, and inform the design of ethic\nalgorithmic systems.","main_category":"cs.AI","categories":"cs.AI,cs.CY","published":"2025-04-10T17:15:50Z"}
{"aid":"http://arxiv.org/abs/2504.07918v1","title":"Shuffling via Transpositions","summary":"We consider a family of card shuffles of $n$ cards, where the allowed moves\ninvolve transpositions corresponding to the Jucys--Murphy elements of\n$\\{S_m\\}_{m \\leq n}$. We diagonalize the transition matrix of these shuffles.\nAs a special case, we consider the $k$-star transpositions shuffle, a natural\ninterpolation between random transpositions and star transpositions. We proved\nthat the $k$-star transpositions shuffle exhibits total variation cutoff at\ntime $\\frac{2n-(k+1)}{2(n-1)}n\\log n$ with a window of\n$\\frac{2n-(k+1)}{2(n-1)}n$. Furthermore, we prove that for the case where $k/n\n\\rightarrow 0$ or $1$, this shuffle has the same limit profile as random\ntranspositions, which has been fully determined by Teyssier.","main_category":"math.CO","categories":"math.CO,math.PR","published":"2025-04-10T17:33:30Z"}
{"aid":"http://arxiv.org/abs/2504.07919v1","title":"Double White Dwarf Tides with Multi-messenger Measurements","summary":"Short-period Galactic double white dwarf (DWD) systems will be observable\nboth in visible light through photometric monitoring and in mHz-range\ngravitational waves (GWs) with forthcoming space-based laser interferometry\nsuch as LISA. When only photometric variability is used to measure DWD\nintrinsic properties, there is a degeneracy between the chirp mass and binary\ntidal interaction, as orbital frequency time derivative is set by both GW\nradiation and tides. Without expensive radial velocity data from spectroscopic\nmonitoring, this degeneracy may be lifted in principle by directly measuring\nthe second time derivative of the orbital frequency through photometric\nmonitoring over an ultra-long time baseline. Alternatively, the degeneracy can\nbe removed by exploiting information in both photometric variability and the\ncoherent GW waveform. Investigating both approaches, we find that direct\nmeasurement of the second time derivative is likely infeasible for most DWDs,\nwhile the multi-messenger method will disentangle measurements of the chirp\nmass and the binary moments of inertia, for a large sample of tidally locked\nsystems. The latter information will enable empirical tests of WD structure\nmodels with finite temperature effects.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-10T17:33:52Z"}
{"aid":"http://arxiv.org/abs/2504.07944v1","title":"Hyperbolic sine-Gordon model beyond the first threshold","summary":"We study the hyperbolic sine-Gordon model, with a parameter $\\beta^2 > 0$,\nand its associated Gibbs dynamics on the two-dimensional torus. By introducing\na physical space approach to the Fourier restriction norm method and\nestablishing nonlinear dispersive smoothing for the imaginary multiplicative\nGaussian chaos, we construct invariant Gibbs dynamics for the hyperbolic\nsine-Gordon model beyond the first threshold $\\beta^2 = 2\\pi$. The\ndeterministic step of our argument hinges on establishing key bilinear\nestimates, featuring weighted bounds for a cone multiplier. Moreover, the\nprobabilistic component involves a careful analysis of the imaginary Gaussian\nmultiplicative chaos and reduces to integrating singularities along space-time\nlight cones. As a by-product of our proof, we identify $\\beta^2 = 6\\pi$ as a\ncritical threshold for the hyperbolic sine-Gordon model, which is quite\nsurprising given that the associated parabolic model has a critical threshold\nat $\\beta^2 =8\\pi$.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP,math.PR","published":"2025-04-10T17:53:59Z"}
{"aid":"http://arxiv.org/abs/2504.07951v1","title":"Scaling Laws for Native Multimodal Models Scaling Laws for Native\n  Multimodal Models","summary":"Building general-purpose models that can effectively perceive the world\nthrough multimodal signals has been a long-standing goal. Current approaches\ninvolve integrating separately pre-trained components, such as connecting\nvision encoders to LLMs and continuing multimodal training. While such\napproaches exhibit remarkable sample efficiency, it remains an open question\nwhether such late-fusion architectures are inherently superior. In this work,\nwe revisit the architectural design of native multimodal models (NMMs)--those\ntrained from the ground up on all modalities--and conduct an extensive scaling\nlaws study, spanning 457 trained models with different architectures and\ntraining mixtures. Our investigation reveals no inherent advantage to\nlate-fusion architectures over early-fusion ones, which do not rely on image\nencoders. On the contrary, early-fusion exhibits stronger performance at lower\nparameter counts, is more efficient to train, and is easier to deploy.\nMotivated by the strong performance of the early-fusion architectures, we show\nthat incorporating Mixture of Experts (MoEs) allows for models that learn\nmodality-specific weights, significantly enhancing performance.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:57:28Z"}
{"aid":"http://arxiv.org/abs/2504.07952v1","title":"Dynamic Cheatsheet: Test-Time Learning with Adaptive Memory","summary":"Despite their impressive performance on complex tasks, current language\nmodels (LMs) typically operate in a vacuum: Each input query is processed\nseparately, without retaining insights from previous attempts. Here, we present\nDynamic Cheatsheet (DC), a lightweight framework that endows a black-box LM\nwith a persistent, evolving memory. Rather than repeatedly re-discovering or\nre-committing the same solutions and mistakes, DC enables models to store and\nreuse accumulated strategies, code snippets, and general problem-solving\ninsights at inference time. This test-time learning enhances performance\nsubstantially across a range of tasks without needing explicit ground-truth\nlabels or human feedback. Leveraging DC, Claude 3.5 Sonnet's accuracy more than\ndoubled on AIME math exams once it began retaining algebraic insights across\nquestions. Similarly, GPT-4o's success rate on Game of 24 increased from 10% to\n99% after the model discovered and reused a Python-based solution. In tasks\nprone to arithmetic mistakes, such as balancing equations, DC enabled GPT-4o\nand Claude to reach near-perfect accuracy by recalling previously validated\ncode, whereas their baselines stagnated around 50%. Beyond arithmetic\nchallenges, DC yields notable accuracy gains on knowledge-demanding tasks.\nClaude achieved a 9% improvement in GPQA-Diamond and an 8% boost on MMLU-Pro\nproblems. Crucially, DC's memory is self-curated, focusing on concise,\ntransferable snippets rather than entire transcript. Unlike finetuning or\nstatic retrieval methods, DC adapts LMs' problem-solving skills on the fly,\nwithout modifying their underlying parameters. Overall, our findings present DC\nas a promising approach for augmenting LMs with persistent memory, bridging the\ndivide between isolated inference events and the cumulative, experience-driven\nlearning characteristic of human cognition.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-10T17:57:33Z"}
{"aid":"http://arxiv.org/abs/2504.07963v1","title":"PixelFlow: Pixel-Space Generative Models with Flow","summary":"We present PixelFlow, a family of image generation models that operate\ndirectly in the raw pixel space, in contrast to the predominant latent-space\nmodels. This approach simplifies the image generation process by eliminating\nthe need for a pre-trained Variational Autoencoder (VAE) and enabling the whole\nmodel end-to-end trainable. Through efficient cascade flow modeling, PixelFlow\nachieves affordable computation cost in pixel space. It achieves an FID of 1.98\non 256$\\times$256 ImageNet class-conditional image generation benchmark. The\nqualitative text-to-image results demonstrate that PixelFlow excels in image\nquality, artistry, and semantic control. We hope this new paradigm will inspire\nand open up new opportunities for next-generation visual generation models.\nCode and models are available at https://github.com/ShoufaChen/PixelFlow.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:59:56Z"}
{"aid":"http://arxiv.org/abs/2504.09879v1","title":"Revisiting the attacker's knowledge in inference attacks against\n  Searchable Symmetric Encryption","summary":"Encrypted search schemes have been proposed to address growing privacy\nconcerns. However, several leakage-abuse attacks have highlighted some security\nvulnerabilities. Recent attacks assumed an attacker's knowledge containing data\n``similar'' to the indexed data. However, this vague assumption is barely\ndiscussed in literature: how likely is it for an attacker to obtain a \"similar\nenough\" data?\n  Our paper provides novel statistical tools usable on any attack in this\nsetting to analyze its sensitivity to data similarity. First, we introduce a\nmathematical model based on statistical estimators to analytically understand\nthe attackers' knowledge and the notion of similarity. Second, we conceive\nstatistical tools to model the influence of the similarity on the attack\naccuracy. We apply our tools on three existing attacks to answer questions such\nas: is similarity the only factor influencing accuracy of a given attack?\nThird, we show that the enforcement of a maximum index size can make the\n``similar-data'' assumption harder to satisfy. In particular, we propose a\nstatistical method to estimate an appropriate maximum size for a given attack\nand dataset. For the best known attack on the Enron dataset, a maximum index\nsize of 200 guarantees (with high probability) the attack accuracy to be below\n5%.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-14T05:04:25Z"}
{"aid":"http://arxiv.org/abs/2504.09882v1","title":"SIO-Mapper: A Framework for Lane-Level HD Map Construction Using\n  Satellite Images and OpenStreetMap with No On-Site Visits","summary":"High-definition (HD) maps, particularly those containing lane-level\ninformation regarded as ground truth, are crucial for vehicle localization\nresearch. Traditionally, constructing HD maps requires highly accurate sensor\nmeasurements collection from the target area, followed by manual annotation to\nassign semantic information. Consequently, HD maps are limited in terms of\ngeographic coverage. To tackle this problem, in this paper, we propose\nSIO-Mapper, a novel lane-level HD map construction framework that constructs\ncity-scale maps without physical site visits by utilizing satellite images and\nOpenStreetmap data. One of the key contributions of SIO-Mapper is its ability\nto extract lane information more accurately by introducing SIO-Net, a novel\ndeep learning network that integrates features from satellite image and\nOpenStreetmap using both Transformer-based and convolution-based encoders.\nFurthermore, to overcome challenges in merging lanes over large areas, we\nintroduce a novel lane integration methodology that combines cluster-based and\ngraph-based approaches. This algorithm ensures the seamless aggregation of lane\nsegments with high accuracy and coverage, even in complex road environments. We\nvalidated SIO-Mapper on the Naver Labs Open Dataset and NuScenes dataset,\ndemonstrating better performance in various environments including Korea, the\nUnited States, and Singapore compared to the state-of-the-art lane-level HD\nmapconstruction methods.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T05:10:57Z"}
{"aid":"http://arxiv.org/abs/2504.09896v1","title":"TWSSenti: A Novel Hybrid Framework for Topic-Wise Sentiment Analysis on\n  Social Media Using Transformer Models","summary":"Sentiment analysis is a crucial task in natural language processing (NLP)\nthat enables the extraction of meaningful insights from textual data,\nparticularly from dynamic platforms like Twitter and IMDB. This study explores\na hybrid framework combining transformer-based models, specifically BERT,\nGPT-2, RoBERTa, XLNet, and DistilBERT, to improve sentiment classification\naccuracy and robustness. The framework addresses challenges such as noisy data,\ncontextual ambiguity, and generalization across diverse datasets by leveraging\nthe unique strengths of these models. BERT captures bidirectional context,\nGPT-2 enhances generative capabilities, RoBERTa optimizes contextual\nunderstanding with larger corpora and dynamic masking, XLNet models dependency\nthrough permutation-based learning, and DistilBERT offers efficiency with\nreduced computational overhead while maintaining high accuracy. We demonstrate\ntext cleaning, tokenization, and feature extraction using Term Frequency\nInverse Document Frequency (TF-IDF) and Bag of Words (BoW), ensure high-quality\ninput data for the models. The hybrid approach was evaluated on benchmark\ndatasets Sentiment140 and IMDB, achieving superior accuracy rates of 94\\% and\n95\\%, respectively, outperforming standalone models. The results validate the\neffectiveness of combining multiple transformer models in ensemble-like setups\nto address the limitations of individual architectures. This research\nhighlights its applicability to real-world tasks such as social media\nmonitoring, customer sentiment analysis, and public opinion tracking which\noffers a pathway for future advancements in hybrid NLP frameworks.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T05:44:11Z"}
{"aid":"http://arxiv.org/abs/2504.09900v1","title":"Small Object Detection with YOLO: A Performance Analysis Across Model\n  Versions and Hardware","summary":"This paper provides an extensive evaluation of YOLO object detection models\n(v5, v8, v9, v10, v11) by com- paring their performance across various hardware\nplatforms and optimization libraries. Our study investigates inference speed\nand detection accuracy on Intel and AMD CPUs using popular libraries such as\nONNX and OpenVINO, as well as on GPUs through TensorRT and other GPU-optimized\nframeworks. Furthermore, we analyze the sensitivity of these YOLO models to\nobject size within the image, examining performance when detecting objects that\noccupy 1%, 2.5%, and 5% of the total area of the image. By identifying the\ntrade-offs in efficiency, accuracy, and object size adaptability, this paper\noffers insights for optimal model selection based on specific hardware\nconstraints and detection requirements, aiding practitioners in deploying YOLO\nmodels effectively for real-world applications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T05:49:31Z"}
{"aid":"http://arxiv.org/abs/2504.09911v1","title":"Higher Chow cycles on Eisenstein K3 surfaces","summary":"We construct higher Chow cycles of type (2,1) on some families of K3 surfaces\nwith non-symplectic automorphisms of order 3 and prove that our cycles are\nindecomposable for very general members. The proof is a combination of some\ndegeneration arguments, and explicit computations of the regulator map.","main_category":"math.AG","categories":"math.AG","published":"2025-04-14T06:18:07Z"}
{"aid":"http://arxiv.org/abs/2504.09921v1","title":"All-optical Raman control of ultracold atomic hyperfine states using\n  pulsed jump protocol","summary":"We develop a pulse-driven jump protocol to achieve all-optical Raman control\nof ultracold atomic hyperfine states. By establishing general conditions for\nadiabatic evolution between quantum states in parameter space, we derive the\nessential pulse area and phase conditions necessary for quantum state transfer\nin a resonant single-$\\Lambda$ three-level system. We extend this approach to a\ndouble-$\\Lambda$ four-level system by incorporating a neighboring intermediate\nstate, which leads to a single-photon detuned $\\Lambda$ three-level system.\nThrough numerical simulations of the ultracold $^{87}$Rb atomic system, we\ndemonstrate that high-fidelity and robust control of quantum state transfer can\nbe achieved in the single-$\\Lambda$ three-level system using stimulated Raman\nadiabatic passage (STIRAP) and the pulsed jump protocol. Furthermore, we show\nthat the destructive quantum interference effects between resonant and detuned\nRaman pathways in the double-$\\Lambda$ four-level system can be mitigated by\noptimizing the pulse area and two-photon detuning parameters within the pulsed\njump protocol. This work presents a promising approach for achieving\nall-optical Raman control of quantum state transfer in ultracold atomic\nhyperfine states.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T06:30:37Z"}
{"aid":"http://arxiv.org/abs/2504.09923v1","title":"Guiding Reasoning in Small Language Models with LLM Assistance","summary":"The limited reasoning capabilities of small language models (SLMs) cast doubt\non their suitability for tasks demanding deep, multi-step logical deduction.\nThis paper introduces a framework called Small Reasons, Large Hints (SMART),\nwhich selectively augments SLM reasoning with targeted guidance from large\nlanguage models (LLMs). Inspired by the concept of cognitive scaffolding, SMART\nemploys a score-based evaluation to identify uncertain reasoning steps and\ninjects corrective LLM-generated reasoning only when necessary. By framing\nstructured reasoning as an optimal policy search, our approach steers the\nreasoning trajectory toward correct solutions without exhaustive sampling. Our\nexperiments on mathematical reasoning datasets demonstrate that targeted\nexternal scaffolding significantly improves performance, paving the way for\ncollaborative use of both SLM and LLM to tackle complex reasoning tasks that\nare currently unsolvable by SLMs alone.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T06:32:45Z"}
{"aid":"http://arxiv.org/abs/2504.09938v1","title":"On the divisibility of sums of Fibonacci numbers","summary":"We show that for infinitely many odd integers $n$, the sum of the first $n$\nFibonacci numbers is divisible by $n$. This resolves a conjecture of\nFatehizadeh and Yaqubi.","main_category":"math.NT","categories":"math.NT,math.CO","published":"2025-04-14T07:00:48Z"}
{"aid":"http://arxiv.org/abs/2504.09946v1","title":"Assessing Judging Bias in Large Reasoning Models: An Empirical Study","summary":"Large Reasoning Models (LRMs) like DeepSeek-R1 and OpenAI-o1 have\ndemonstrated remarkable reasoning capabilities, raising important questions\nabout their biases in LLM-as-a-judge settings. We present a comprehensive\nbenchmark comparing judging biases between LLMs and LRMs across both subjective\npreference-alignment datasets and objective fact-based datasets. Through\ninvestigation of bandwagon, authority, position, and distraction biases, we\nuncover four key findings: (1) despite their advanced reasoning capabilities,\nLRMs remain susceptible to the above biases; (2) LRMs demonstrate better\nrobustness than LLMs specifically on fact-related datasets; (3) LRMs exhibit\nnotable position bias, preferring options in later positions; and (4) we\nidentify a novel \"superficial reflection bias\" where phrases mimicking\nreasoning (e.g., \"wait, let me think...\") significantly influence model\njudgments. To address these biases, we design and evaluate three mitigation\nstrategies: specialized system prompts that reduce judging biases by up to 19\\%\nin preference alignment datasets and 14\\% in fact-related datasets, in-context\nlearning that provides up to 27\\% improvement on preference tasks but shows\ninconsistent results on factual tasks, and a self-reflection mechanism that\nreduces biases by up to 10\\% in preference datasets and 16\\% in fact-related\ndatasets, with self-reflection proving particularly effective for LRMs. Our\nwork provides crucial insights for developing more reliable LLM-as-a-Judge\nframeworks, especially as LRMs become increasingly deployed as automated\njudges.","main_category":"cs.CY","categories":"cs.CY,cs.CL","published":"2025-04-14T07:14:27Z"}
{"aid":"http://arxiv.org/abs/2504.09948v1","title":"Omni-Dish: Photorealistic and Faithful Image Generation and Editing for\n  Arbitrary Chinese Dishes","summary":"Dish images play a crucial role in the digital era, with the demand for\nculturally distinctive dish images continuously increasing due to the\ndigitization of the food industry and e-commerce. In general cases, existing\ntext-to-image generation models excel in producing high-quality images;\nhowever, they struggle to capture diverse characteristics and faithful details\nof specific domains, particularly Chinese dishes. To address this limitation,\nwe propose Omni-Dish, the first text-to-image generation model specifically\ntailored for Chinese dishes. We develop a comprehensive dish curation pipeline,\nbuilding the largest dish dataset to date. Additionally, we introduce a\nrecaption strategy and employ a coarse-to-fine training scheme to help the\nmodel better learn fine-grained culinary nuances. During inference, we enhance\nthe user's textual input using a pre-constructed high-quality caption library\nand a large language model, enabling more photorealistic and faithful image\ngeneration. Furthermore, to extend our model's capability for dish editing\ntasks, we propose Concept-Enhanced P2P. Based on this approach, we build a dish\nediting dataset and train a specialized editing model. Extensive experiments\ndemonstrate the superiority of our methods.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.MM","published":"2025-04-14T07:18:32Z"}
{"aid":"http://arxiv.org/abs/2504.09971v1","title":"Proofs of Useful Work from Arbitrary Matrix Multiplication","summary":"We revisit the longstanding open problem of implementing Nakamoto's\nproof-of-work (PoW) consensus based on a real-world computational task $T(x)$\n(as opposed to artificial random hashing), in a truly permissionless setting\nwhere the miner itself chooses the input $x$. The challenge in designing such a\nProof-of-Useful-Work (PoUW) protocol, is using the native computation of $T(x)$\nto produce a PoW certificate with prescribed hardness and with negligible\ncomputational overhead over the worst-case complexity of $T(\\cdot)$ -- This\nensures malicious miners cannot ``game the system\" by fooling the verifier to\naccept with higher probability compared to honest miners (while using similar\ncomputational resources). Indeed, obtaining a PoUW with $O(1)$-factor overhead\nis trivial for any task $T$, but also useless.\n  Our main result is a PoUW for the task of Matrix Multiplication $MatMul(A,B)$\nof arbitrary matrices with $1+o(1)$ multiplicative overhead compared to naive\n$MatMul$ (even in the presence of Fast Matrix Multiplication-style algorithms,\nwhich are currently impractical). We conjecture that our protocol has optimal\nsecurity in the sense that a malicious prover cannot obtain any significant\nadvantage over an honest prover. This conjecture is based on reducing hardness\nof our protocol to the task of solving a batch of low-rank random linear\nequations which is of independent interest.\n  Since $MatMul$s are the bottleneck of AI compute as well as countless\nindustry-scale applications, this primitive suggests a concrete design of a new\nL1 base-layer protocol, which nearly eliminates the energy-waste of Bitcoin\nmining -- allowing GPU consumers to reduce their AI training and inference\ncosts by ``re-using\" it for blockchain consensus, in exchange for block rewards\n(2-for-1). This blockchain is currently under construction.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-14T08:22:40Z"}
{"aid":"http://arxiv.org/abs/2504.09976v1","title":"Nonlocal operators in divergence form and existence theory for\n  integrable data","summary":"We present an existence and uniqueness result for weak solutions of Dirichlet\nboundary value problems governed by a nonlocal operator in divergence form and\nin the presence of a datum which is assumed to belong only to $L^1(\\Omega)$ and\nto be suitably dominated.\n  We also prove that the solution that we find converges, as $s\\nearrow 1$, to\na solution of the local counterpart problem, recovering the classical result as\na limit case. This requires some nontrivial customized uniform estimates and\nrepresentation formulas, given that the datum is only in $L^1(\\Omega)$ and\ntherefore the usual regularity theory cannot be leveraged to our benefit in\nthis framework.\n  The limit process uses a nonlocal operator, obtained as an affine\ntransformation of a homogeneous kernel, which recovers, in the limit as\n$s\\nearrow 1$, every classical operator in divergence form.","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T08:31:51Z"}
{"aid":"http://arxiv.org/abs/2504.09985v1","title":"Collective Superradiance: Estimating the Peak Emission Rate and Time","summary":"Determining the peak photon emission time and rate for an ensemble of $N$\nquantum systems undergoing collective superradiant decay typically requires\ntracking the time evolution of the density operator, a process with\ncomputational costs scaling exponentially with $N$. We present compact,\nanalytic formulas for evaluating the peak emission rate and time for initially\nfully excited quantum emitter ensembles, valid for any geometric configuration\nand emitter type. These formulas rely solely on the variance of the eigenvalues\nof a real symmetric $N \\times N$ matrix, which describes collective\ndissipation. We demonstrate the versatility of these results across various\nenvironments, including free space, solid-state, and waveguide reservoirs. For\nlarge $N$ the formulas simplify further to depend on just two parameters:\naverage nearest-neighbor spacing and emitter number. Finally, we present\nscaling laws and bounds on the spatial size of emitter ensembles, such that\nsuperradiance is maintained, independent of emitter number or density.","main_category":"quant-ph","categories":"quant-ph,cond-mat.quant-gas,physics.atom-ph","published":"2025-04-14T08:51:42Z"}
{"aid":"http://arxiv.org/abs/2504.10001v1","title":"GaussVideoDreamer: 3D Scene Generation with Video Diffusion and\n  Inconsistency-Aware Gaussian Splatting","summary":"Single-image 3D scene reconstruction presents significant challenges due to\nits inherently ill-posed nature and limited input constraints. Recent advances\nhave explored two promising directions: multiview generative models that train\non 3D consistent datasets but struggle with out-of-distribution generalization,\nand 3D scene inpainting and completion frameworks that suffer from cross-view\ninconsistency and suboptimal error handling, as they depend exclusively on\ndepth data or 3D smoothness, which ultimately degrades output quality and\ncomputational performance. Building upon these approaches, we present\nGaussVideoDreamer, which advances generative multimedia approaches by bridging\nthe gap between image, video, and 3D generation, integrating their strengths\nthrough two key innovations: (1) A progressive video inpainting strategy that\nharnesses temporal coherence for improved multiview consistency and faster\nconvergence. (2) A 3D Gaussian Splatting consistency mask to guide the video\ndiffusion with 3D consistent multiview evidence. Our pipeline combines three\ncore components: a geometry-aware initialization protocol, Inconsistency-Aware\nGaussian Splatting, and a progressive video inpainting strategy. Experimental\nresults demonstrate that our approach achieves 32% higher LLaVA-IQA scores and\nat least 2x speedup compared to existing methods while maintaining robust\nperformance across diverse scenes.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T09:04:01Z"}
{"aid":"http://arxiv.org/abs/2504.10006v1","title":"Improving Controller Generalization with Dimensionless Markov Decision\n  Processes","summary":"Controllers trained with Reinforcement Learning tend to be very specialized\nand thus generalize poorly when their testing environment differs from their\ntraining one. We propose a Model-Based approach to increase generalization\nwhere both world model and policy are trained in a dimensionless state-action\nspace. To do so, we introduce the Dimensionless Markov Decision Process\n($\\Pi$-MDP): an extension of Contextual-MDPs in which state and action spaces\nare non-dimensionalized with the Buckingham-$\\Pi$ theorem. This procedure\ninduces policies that are equivariant with respect to changes in the context of\nthe underlying dynamics. We provide a generic framework for this approach and\napply it to a model-based policy search algorithm using Gaussian Process\nmodels. We demonstrate the applicability of our method on simulated actuated\npendulum and cartpole systems, where policies trained on a single environment\nare robust to shifts in the distribution of the context.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T09:08:53Z"}
{"aid":"http://arxiv.org/abs/2504.10007v1","title":"Balancing Two Classifiers via A Simplex ETF Structure for Model\n  Calibration","summary":"In recent years, deep neural networks (DNNs) have demonstrated\nstate-of-the-art performance across various domains. However, despite their\nsuccess, they often face calibration issues, particularly in safety-critical\napplications such as autonomous driving and healthcare, where unreliable\npredictions can have serious consequences. Recent research has started to\nimprove model calibration from the view of the classifier. However, the\nexploration of designing the classifier to solve the model calibration problem\nis insufficient. Let alone most of the existing methods ignore the calibration\nerrors arising from underconfidence. In this work, we propose a novel method by\nbalancing learnable and ETF classifiers to solve the overconfidence or\nunderconfidence problem for model Calibration named BalCAL. By introducing a\nconfidence-tunable module and a dynamic adjustment method, we ensure better\nalignment between model confidence and its true accuracy. Extensive\nexperimental validation shows that ours significantly improves model\ncalibration performance while maintaining high predictive accuracy,\noutperforming existing techniques. This provides a novel solution to the\ncalibration challenges commonly encountered in deep learning.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-14T09:09:01Z"}
{"aid":"http://arxiv.org/abs/2504.10009v1","title":"The Bispectrum of Intrinsic Alignments: Theory Modelling and Forecasts\n  for Stage IV Galaxy Surveys","summary":"We present a complete treatment of the bispectrum of intrinsic alignments,\nboth in three spatial dimensions and in projection in the flat-sky\napproximation. Since intrinsic alignment is a spin-2 observable, the bispectrum\nof intrinsic alignments contains a parity-even and a parity-odd part, the\nlatter being nonzero even in the absence of parity violation. Moreover, all\npossible combinations of scalar, E- and B-mode bispectra are nonzero in the\nabsence of parity violation. In analogy to the galaxy bispectrum in redshift\nspace, we construct a complete set of multipoles for anisotropic bispectra of\nprojected spin-2 fields. We then construct separable bispectrum estimators,\nboth for parity-even and parity-odd bispectra, which can be computed by means\nof Fast Fourier Transforms (FFTs). We compare several different choices of\nangular weighting in terms of signal-to-noise ratios (SNR) for a Stage IV setup\nusing luminous red galaxies (LRGs) from the Dark Energy Spectroscopic\nInstrument (DESI) with galaxy shapes measured by the Legacy Survey of Space and\nTime (LSST). Assuming an overlapping area of $\\sim 4,000$ square degrees\n(yielding $\\sim 1.3$ million LRGs) and including scales up to $k_\\text{max} =\n0.14\\,h$/Mpc, we find that the position-position-E-mode bispectrum $B_{DDE}$\n(which is parity-even) can be strongly detected at SNR $\\sim 30$, while\ndetecting parity-odd bispectra (such as $B_{DDB}$, SNR $\\sim 5$) or bispectra\nwith more than one shape field (such as $B_{DEE}$, SNR $\\sim 5$) may also be\npossible.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-14T09:16:46Z"}
{"aid":"http://arxiv.org/abs/2504.10018v1","title":"RGB-Event based Pedestrian Attribute Recognition: A Benchmark Dataset\n  and An Asymmetric RWKV Fusion Framework","summary":"Existing pedestrian attribute recognition methods are generally developed\nbased on RGB frame cameras. However, these approaches are constrained by the\nlimitations of RGB cameras, such as sensitivity to lighting conditions and\nmotion blur, which hinder their performance. Furthermore, current attribute\nrecognition primarily focuses on analyzing pedestrians' external appearance and\nclothing, lacking an exploration of emotional dimensions. In this paper, we\nrevisit these issues and propose a novel multi-modal RGB-Event attribute\nrecognition task by drawing inspiration from the advantages of event cameras in\nlow-light, high-speed, and low-power consumption. Specifically, we introduce\nthe first large-scale multi-modal pedestrian attribute recognition dataset,\ntermed EventPAR, comprising 100K paired RGB-Event samples that cover 50\nattributes related to both appearance and six human emotions, diverse scenes,\nand various seasons. By retraining and evaluating mainstream PAR models on this\ndataset, we establish a comprehensive benchmark and provide a solid foundation\nfor future research in terms of data and algorithmic baselines. In addition, we\npropose a novel RWKV-based multi-modal pedestrian attribute recognition\nframework, featuring an RWKV visual encoder and an asymmetric RWKV fusion\nmodule. Extensive experiments are conducted on our proposed dataset as well as\ntwo simulated datasets (MARS-Attribute and DukeMTMC-VID-Attribute), achieving\nstate-of-the-art results. The source code and dataset will be released on\nhttps://github.com/Event-AHU/OpenPAR","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-14T09:22:16Z"}
{"aid":"http://arxiv.org/abs/2504.10029v1","title":"Quantum Squeezing Effects in Coupled van der Pol Oscillators","summary":"Achieving synchronized quantum states within the quantum realm is a\nsignificant goal. This regime is characterized by restricted excitation\noccurrences and a highly nonclassical stable state of the self-oscillating\nsystem. However, many existing approaches to observe synchronization in this\nquantum realm face a major challenge: the influence of noise tends to\novershadow the synchronization phenomenon. In coupled van der Pol oscillators,\nsynchronization occurs when a system of two or more oscillators interacts. Our\ninvestigation demonstrates that introducing the squeezing Hamiltonian in two\ncoupled van der Pol oscillators enhances nonclassical effects, increases\nquantum correlations, and improves the robustness of synchronization dynamics.\nThis was evidenced through the analysis of the Wigner function and power\nspectrum, showing significant improvements compared to systems without\nsqueezing.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T09:33:05Z"}
{"aid":"http://arxiv.org/abs/2504.10051v1","title":"Polar loci of multivariable archimedean zeta functions","summary":"We determine, up to exponentiating, the polar locus of the multivariable\narchimedean zeta function associated to a finite collection of polynomials $F$.\nThe result is the monodromy support locus of $F$, a topological invariant. We\ngive a relation between the multiplicities of the irreducible components of the\nmonodromy support locus and the polar orders. These generalize results of\nBarlet for the case when $F$ is a single polynomial. Our result determines the\nslopes of the polar locus of the zeta function of $F$, closing a circle of\nresults of Loeser, Maisonobe, Sabbah.","main_category":"math.AG","categories":"math.AG","published":"2025-04-14T09:55:51Z"}
{"aid":"http://arxiv.org/abs/2504.10063v1","title":"Hallucination Detection in LLMs via Topological Divergence on Attention\n  Graphs","summary":"Hallucination, i.e., generating factually incorrect content, remains a\ncritical challenge for large language models (LLMs). We introduce TOHA, a\nTOpology-based HAllucination detector in the RAG setting, which leverages a\ntopological divergence metric to quantify the structural properties of graphs\ninduced by attention matrices. Examining the topological divergence between\nprompt and response subgraphs reveals consistent patterns: higher divergence\nvalues in specific attention heads correlate with hallucinated outputs,\nindependent of the dataset. Extensive experiments, including evaluation on\nquestion answering and data-to-text tasks, show that our approach achieves\nstate-of-the-art or competitive results on several benchmarks, two of which\nwere annotated by us and are being publicly released to facilitate further\nresearch. Beyond its strong in-domain performance, TOHA maintains remarkable\ndomain transferability across multiple open-source LLMs. Our findings suggest\nthat analyzing the topological structure of attention matrices can serve as an\nefficient and robust indicator of factual reliability in LLMs.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T10:06:27Z"}
{"aid":"http://arxiv.org/abs/2504.10093v1","title":"Gradient modelling of memristive systems","summary":"We introduce a gradient modeling framework for memristive systems. Our focus\nis on memristive systems as they appear in neurophysiology and neuromorphic\nsystems. Revisiting the original definition of Chua, we regard memristive\nelements as gradient operators of quadratic functionals with respect to a\nmetric determined by the memristance. We explore the consequences of gradient\nproperties for the analysis and design of neuromorphic circuits.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.DG,math.DS","published":"2025-04-14T10:56:51Z"}
{"aid":"http://arxiv.org/abs/2504.10095v1","title":"Influence of packing protocol on fractal exponents in dense polydisperse\n  packings","summary":"We study fractal properties of a system of densely and randomly packed disks,\nobeying a power-law distribution of radii, which is generated by using various\nprotocols: Delaunay triangulation (DT) with both zero and periodic boundary\nconditions and the constant pressure protocol with periodic boundary\nconditions. The power-law exponents of the mass-radius relation and structure\nfactor are obtained numerically for various values of the size ratio of the\ndistribution, defined as the largest-to-smallest radius ratio. It is shown that\nthe size ratio is an important control parameter responsible for the\nconsistency of the fractal properties of the system: the greater the ratio, the\nless the finite size effects are pronounced and the better the agreement\nbetween the exponents. For the DT protocol, the exponents of the mass-radius\nrelation, structure factor, and power-law distribution coincide even at\nmoderate values of the size ratio. By contrast, for the constant-pressure\nprotocol, all three exponents are found to be different for both moderate\n(around 300) and large (around 1500) size ratios, which might indicate a biased\nrather than random spatial distribution of the disks. Nevertheless, there is a\ntendency for the exponents to converge as the size ratio increases, suggesting\nthat all the exponents become equal in the limit of infinite size ratio.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech","published":"2025-04-14T11:01:39Z"}
{"aid":"http://arxiv.org/abs/2504.10100v1","title":"A direct and algebraic characterization of higher-order differential\n  operators","summary":"This paper presents an algebraic approach to characterizing higher-order\ndifferential operators. While the foundational Leibniz rule addresses\nfirst-order derivatives, its extension to higher orders typically involves\nidentities relating multiple distinct operators. In contrast, we introduce a\nnovel operator equation involving only a single $n$\\textsuperscript{th}-order\ndifferential operator. We demonstrate that, under certain mild conditions, this\nequation serves to characterize such operators. Specifically, our results show\nthat these higher-order differential operators can be identified as particular\nsolutions to this single-operator identity. This approach provides a framework\nfor understanding the algebraic structure of higher-order differential\noperators acting on function spaces.","main_category":"math.CA","categories":"math.CA","published":"2025-04-14T11:06:44Z"}
{"aid":"http://arxiv.org/abs/2504.10121v1","title":"Impact of rainfall risk on rice production: realized volatility in mean\n  model","summary":"Rural economies are largely dependent upon agriculture, which is greatly\ndetermined by climatic conditions such as rainfall. This study aims to forecast\nagricultural production in Maharashtra, India, which utilises annual data from\nthe year 1962 to 2021. Since rainfall plays a major role with respect to the\ncrop yield, we analyze the impact of rainfall on crop yield using four time\nseries models that includes ARIMA, ARIMAX, GARCH-ARIMA and GARCH-ARIMAX. We\ntake advantage of rainfall as an external regressor to examine if it\ncontributes to the performance of the model. 1-step, 2-step, and 3-step ahead\nforecasts are obtained and the model performance is assessed using MAE and\nRMSE. The models are able to more accurately predict when using rainfall as a\npredictor compared to when solely dependant on historical production trends\n(more improved outcomes are seen in the ARIMAX and GARCH-ARIMAX models). As\nsuch, these findings underscore the need for climate-aware forecasting\ntechniques that provide useful information to policymakers and farmers to aid\nin agricultural planning.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-14T11:30:37Z"}
{"aid":"http://arxiv.org/abs/2504.10124v1","title":"Unravelling the Flow of Information in a Nonequilibrium Process","summary":"Identifying the origin of nonequilibrium characteristics in a generic\ninteracting system having multiple degrees of freedom is a challenging task. In\nthis context, information theoretic measures such as mutual information and\nrelated polymorphs offer valuable insights. Here, we explore these measures in\na minimal experimental model consisting of two hydrodynamically coupled\ncolloidal particles, where a nonequilibrium drive is introduced via an\nexponentially correlated noise acting on one of the particles. We show that the\ninformation-theoretic tools considered enable a systematic, data-driven\ndissection of information flow within the system. These measures allow us to\nidentify the driving node and reconstruct the directional dependencies between\nparticles. Notably, they help explain a recently observed, counterintuitive\ntrend in the dependence of irreversibility on interaction strength under\ncoarse-graining (B. Das et.al., arXiv:2405.00800 (2024)). Finally, our results\ndemonstrate how directional information measures can uncover the hidden\nstructure of nonequilibrium dynamics and provide a framework for studying\nsimilar effects in more complex systems.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-14T11:32:19Z"}
{"aid":"http://arxiv.org/abs/2504.10127v1","title":"Breaking the Data Barrier -- Building GUI Agents Through Task\n  Generalization","summary":"Graphical User Interface (GUI) agents offer cross-platform solutions for\nautomating complex digital tasks, with significant potential to transform\nproductivity workflows. However, their performance is often constrained by the\nscarcity of high-quality trajectory data. To address this limitation, we\npropose training Vision Language Models (VLMs) on data-rich,\nreasoning-intensive tasks during a dedicated mid-training stage, and then\nexamine how incorporating these tasks facilitates generalization to GUI\nplanning scenarios. Specifically, we explore a range of tasks with readily\navailable instruction-tuning data, including GUI perception, multimodal\nreasoning, and textual reasoning. Through extensive experiments across 11\nmid-training tasks, we demonstrate that: (1) Task generalization proves highly\neffective, yielding substantial improvements across most settings. For\ninstance, multimodal mathematical reasoning enhances performance on\nAndroidWorld by an absolute 6.3%. Remarkably, text-only mathematical data\nsignificantly boosts GUI web agent performance, achieving a 5.6% improvement on\nWebArena and 5.4% improvement on AndroidWorld, underscoring notable cross-modal\ngeneralization from text-based to visual domains; (2) Contrary to prior\nassumptions, GUI perception data - previously considered closely aligned with\nGUI agent tasks and widely utilized for training - has a comparatively limited\nimpact on final performance; (3) Building on these insights, we identify the\nmost effective mid-training tasks and curate optimized mixture datasets,\nresulting in absolute performance gains of 8.0% on WebArena and 12.2% on\nAndroidWorld. Our work provides valuable insights into cross-domain knowledge\ntransfer for GUI agents and offers a practical approach to addressing data\nscarcity challenges in this emerging field. The code, data and models will be\navailable at https://github.com/hkust-nlp/GUIMid.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.CV","published":"2025-04-14T11:35:02Z"}
{"aid":"http://arxiv.org/abs/2504.10137v1","title":"Multi-Target Position Error Bound and Power Allocation Scheme for\n  Cell-Free mMIMO-OTFS ISAC Systems","summary":"This paper investigates multi-target position estimation in cell-free massive\nmultiple-input multiple-output (CF mMIMO) architectures, where orthogonal time\nfrequency and space (OTFS) is used as an integrated sensing and communication\n(ISAC) signal. Closed-form expressions for the Cram\\'{e}r-Rao lower bound and\nthe positioning error bound (PEB) in multi-target position estimation are\nderived, providing quantitative evaluations of sensing performance. To enhance\nthe overall performance of the ISAC system, a power allocation algorithm is\ndeveloped to maximize the minimum user communication\nsignal-to-interference-plus-noise ratio while ensuring a specified sensing PEB\nrequirement. The results validate the proposed PEB expression and its\napproximation, clearly illustrating the coordination gain enabled by ISAC.\nFurther, the superiority of using the multi-static CF mMIMO architecture over\ntraditional cellular ISAC is demonstrated, and the advantages of OTFS signals\nin high-mobility scenarios are highlighted.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-14T11:48:15Z"}
{"aid":"http://arxiv.org/abs/2504.10142v1","title":"Band width estimates with lower spectral curvature bounds","summary":"In this work, we use the warped \\( \\mu \\)-bubble method to study the\nconsequences of a spectral curvature bound. In particular, with a lower\nspectral Ricci curvature bound and lower spectral scalar curvature bound, we\nshow that the band width of a torical band is bounded above. We also obtain\nsome rigidity results.","main_category":"math.DG","categories":"math.DG","published":"2025-04-14T11:54:13Z"}
{"aid":"http://arxiv.org/abs/2504.10144v1","title":"Evidence for electron spin-torsion coupling in the rotational spectrum\n  of the CH$_3$CO radical","summary":"Open-shell non-rigid molecular systems exhibiting an internal rotation are\nlikely candidates for a coupling between the spin angular momentum of the\nunpaired electron and the torsional motion. This electron spin-torsion coupling\nlacked both an experimental validation and a theoretical modeling. Here, the\nfirst experimental observation of the electron spin-torsion coupling is\nreported analyzing the pure rotational spectrum at millimeter wavelengths of\nthe CH$_3$CO radical, a $^2\\Sigma$ open-shell molecule displaying an internal\nrotation of its methyl group. To account for this coupling, a specific\nHamiltonian incorporating the rotational, torsional, and electronic degrees of\nfreedom is developed and allows us to reproduce the experimental spectrum. The\npresent demonstration of the electron spin-torsion coupling will undoubtedly be\nkey to future investigations of large open-shell molecules exhibiting a complex\ninternal dynamics.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-14T11:56:39Z"}
{"aid":"http://arxiv.org/abs/2504.10148v1","title":"Hierarchical and Step-Layer-Wise Tuning of Attention Specialty for\n  Multi-Instance Synthesis in Diffusion Transformers","summary":"Text-to-image (T2I) generation models often struggle with multi-instance\nsynthesis (MIS), where they must accurately depict multiple distinct instances\nin a single image based on complex prompts detailing individual features.\nTraditional MIS control methods for UNet architectures like SD v1.5/SDXL fail\nto adapt to DiT-based models like FLUX and SD v3.5, which rely on integrated\nattention between image and text tokens rather than text-image cross-attention.\nTo enhance MIS in DiT, we first analyze the mixed attention mechanism in DiT.\nOur token-wise and layer-wise analysis of attention maps reveals a hierarchical\nresponse structure: instance tokens dominate early layers, background tokens in\nmiddle layers, and attribute tokens in later layers. Building on this\nobservation, we propose a training-free approach for enhancing MIS in DiT-based\nmodels with hierarchical and step-layer-wise attention specialty tuning (AST).\nAST amplifies key regions while suppressing irrelevant areas in distinct\nattention maps across layers and steps, guided by the hierarchical structure.\nThis optimizes multimodal interactions by hierarchically decoupling the complex\nprompts with instance-based sketches. We evaluate our approach using upgraded\nsketch-based layouts for the T2I-CompBench and customized complex scenes. Both\nquantitative and qualitative results confirm our method enhances complex layout\ngeneration, ensuring precise instance placement and attribute representation in\nMIS.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T11:59:58Z"}
{"aid":"http://arxiv.org/abs/2504.10158v1","title":"COUNTS: Benchmarking Object Detectors and Multimodal Large Language\n  Models under Distribution Shifts","summary":"Current object detectors often suffer significant perfor-mance degradation in\nreal-world applications when encountering distributional shifts. Consequently,\nthe out-of-distribution (OOD) generalization capability of object detectors has\ngarnered increasing attention from researchers. Despite this growing interest,\nthere remains a lack of a large-scale, comprehensive dataset and evaluation\nbenchmark with fine-grained annotations tailored to assess the OOD\ngeneralization on more intricate tasks like object detection and grounding. To\naddress this gap, we introduce COUNTS, a large-scale OOD dataset with\nobject-level annotations. COUNTS encompasses 14 natural distributional shifts,\nover 222K samples, and more than 1,196K labeled bounding boxes. Leveraging\nCOUNTS, we introduce two novel benchmarks: O(OD)2 and OODG. O(OD)2 is designed\nto comprehensively evaluate the OOD generalization capabilities of object\ndetectors by utilizing controlled distribution shifts between training and\ntesting data. OODG, on the other hand, aims to assess the OOD generalization of\ngrounding abilities in multimodal large language models (MLLMs). Our findings\nreveal that, while large models and extensive pre-training data substantially\nen hance performance in in-distribution (IID) scenarios, significant\nlimitations and opportunities for improvement persist in OOD contexts for both\nobject detectors and MLLMs. In visual grounding tasks, even the advanced GPT-4o\nand Gemini-1.5 only achieve 56.7% and 28.0% accuracy, respectively. We hope\nCOUNTS facilitates advancements in the development and assessment of robust\nobject detectors and MLLMs capable of maintaining high performance under\ndistributional shifts.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-14T12:13:33Z"}
{"aid":"http://arxiv.org/abs/2504.10172v1","title":"Characterising quantum measurement through environmental stochastic\n  entropy production in a two spin 1/2 system","summary":"Quantum state diffusion is a framework within which measurement may be\ndescribed as the continuous and gradual collapse of a quantum system to an\neigenstate as a result of interaction with its environment. The irreversible\nnature of the quantum trajectories that arise may be characterised by the\nenvironmental stochastic entropy production associated with the measurement. We\nconsider a system of two spin 1/2 particles undergoing either single particle\nmeasurements or measurements of the total z-spin component S_{z}. The mean\nasymptotic rates of environmental stochastic entropy production associated with\ncollapse can depend on the eigenstate of S_{z} selected, and on the initial\nstate of the system, offering an additional avenue for characterising quantum\nmeasurement.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T12:25:20Z"}
{"aid":"http://arxiv.org/abs/2504.10197v1","title":"Comparison of smoothening flows for the topological charge in QCD-like\n  theories","summary":"We investigate properties of the topological charge for several SU(NC) gauge\nfield ensembles for NC = 4, 5, 6 with a single fermion in the two-index\nanti-symmetric representation, covering multiple lattice spacings at otherwise\napproximately constant physical parameters. Comparing the topological charge\ndefined by the Wilson flow and the over-improved DBW2 flow we find that already\nat small flow times the latter stabilises on discrete values. We provide\nevidence that as the lattice spacing is lowered the Wilson flow also separates\ninto discrete sectors at earlier flow times. Adopting the DWB2 definition in\nthe remainder of the analysis, we do not see any evidence of fractional\ntopological charges, which could in principle appear at finite lattice spacing.","main_category":"hep-lat","categories":"hep-lat","published":"2025-04-14T13:02:50Z"}
{"aid":"http://arxiv.org/abs/2504.10203v1","title":"A moving horizon estimator for aquifer thermal energy storages","summary":"Aquifer thermal energy storages (ATES) represent groundwater saturated\naquifers that store thermal energy in the form of heated or cooled groundwater.\nCombining two ATES, one can harness excess thermal energy from summer (heat)\nand winter (cold) to support the building's heating, ventilation, and air\nconditioning (HVAC) technology. In general, a dynamic operation of ATES\nthroughout the year is beneficial to avoid using fossil fuel-based HVAC\ntechnology and maximize the ``green use'' of ATES. Model predictive control\n(MPC) with an appropriate system model may become a crucial control approach\nfor ATES systems. Consequently, the MPC model should reflect spatial\ntemperature profiles around ATES' boreholes to predict extracted groundwater\ntemperatures accurately. However, meaningful predictions require the estimation\nof the current state of the system, as measurements are usually only at the\nborehole of the ATES. In control, this is often realized by model-based\nobservers. Still, observing the state of an ATES system is non-trivial, since\nthe model is typically hybrid. We show how to exploit the specific structure of\nthe hybrid ATES model and design an easy-to-solve moving horizon estimator\nbased on a quadratic program.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-14T13:11:34Z"}
{"aid":"http://arxiv.org/abs/2504.10225v1","title":"A Quasi-Steady-State Black Box Simulation Approach for the Generation of\n  g-g-g-v Diagrams","summary":"The classical g-g diagram, representing the achievable acceleration space for\na vehicle, is commonly used as a constraint in trajectory planning and control\ndue to its computational simplicity. To address non-planar road geometries,\nthis concept can be extended to incorporate g-g constraints as a function of\nvehicle speed and vertical acceleration, commonly referred to as g-g-g-v\ndiagrams. However, the estimation of g-g-g-v diagrams is an open problem.\nExisting simulation-based approaches struggle to isolate non-transient,\nopen-loop stable states across all combinations of speed and acceleration,\nwhile optimization-based methods often require simplified vehicle equations and\nhave potential convergence issues. In this paper, we present a novel,\nopen-source, quasi-steady-state black box simulation approach that applies a\nvirtual inertial force in the longitudinal direction. The method emulates the\nload conditions associated with a specified longitudinal acceleration while\nmaintaining constant vehicle speed, enabling open-loop steering ramps in a\npurely QSS manner. Appropriate regulation of the ramp steer rate inherently\nmitigates transient vehicle dynamics when determining the maximum feasible\nlateral acceleration. Moreover, treating the vehicle model as a black box\neliminates model mismatch issues, allowing the use of high-fidelity or\nproprietary vehicle dynamics models typically unsuited for optimization\napproaches. An open-source version of the proposed method is available at:\nhttps://github.com/TUM-AVS/GGGVDiagrams","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T13:45:26Z"}
{"aid":"http://arxiv.org/abs/2504.10255v1","title":"Dissipation-Induced Threshold on Integrability Footprints","summary":"The presence of a dissipative environment disrupts the unitary spectrum of\ndynamical quantum maps. Nevertheless, key features of the underlying unitary\ndynamics -- such as their integrable or chaotic nature -- are not immediately\nerased by dissipation. To investigate this, we model dissipation as a convex\ncombination of a unitary evolution and a random Kraus map, and study how\nsignatures of integrability fade as dissipation strength increases. Our\nanalysis shows that in the weakly dissipative regime, the complex eigenvalue\nspectrum organizes into well-defined, high-density clusters. We estimate the\ncritical dissipation threshold beyond which these clusters disappear, rendering\nthe dynamics indistinguishable from chaotic evolution. This threshold depends\nonly on the number of spectral clusters and the rank of the random Kraus\noperator. To characterize this transition, we introduce the eigenvalue angular\nvelocity as a diagnostic of integrability loss. We illustrate our findings\nthrough several integrable quantum circuits, including the dissipative quantum\nFourier transform. Our results provide a quantitative picture of how noise\ngradually erases the footprints of integrability in open quantum systems.","main_category":"quant-ph","categories":"quant-ph,cond-mat.dis-nn,cond-mat.stat-mech","published":"2025-04-14T14:16:37Z"}
{"aid":"http://arxiv.org/abs/2504.10256v1","title":"Compressible fluids excited by space-dependent transport noise","summary":"We study the compressible Navier-Stokes system driven by physically relevant\ntransport noise, where the noise influences both the continuity and momentum\nequations. Our approach is based on transforming the system into a partial\ndifferential equation with random, time- and space-dependent coefficients. A\nkey challenge arises from the fact that these coefficients are\nnon-differentiable in time, rendering standard compactness arguments for the\nidentification of the pressure inapplicable. To overcome this difficulty, we\ndevelop a novel multi-layer approximation scheme and introduce a precise\nlocalization strategy with respect to both the sample space and time variable.\nThe limit pressure is then identified via the corresponding effective viscous\nflux identity. By means of stochastic compactness methods, particularly\nSkorokhod's representation theorem and its generalization by Jakubowski, we\nensure the progressive measurability required to return to the original system.\nOur results broaden the applicability of transport noise models in fluid\ndynamics and offer new insights into the interaction between stochastic effects\nand compressibility.","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T14:17:25Z"}
{"aid":"http://arxiv.org/abs/2504.10275v1","title":"LMFormer: Lane based Motion Prediction Transformer","summary":"Motion prediction plays an important role in autonomous driving. This study\npresents LMFormer, a lane-aware transformer network for trajectory prediction\ntasks. In contrast to previous studies, our work provides a simple mechanism to\ndynamically prioritize the lanes and shows that such a mechanism introduces\nexplainability into the learning behavior of the network. Additionally,\nLMFormer uses the lane connection information at intersections, lane merges,\nand lane splits, in order to learn long-range dependency in lane structure.\nMoreover, we also address the issue of refining the predicted trajectories and\npropose an efficient method for iterative refinement through stacked\ntransformer layers. For benchmarking, we evaluate LMFormer on the nuScenes\ndataset and demonstrate that it achieves SOTA performance across multiple\nmetrics. Furthermore, the Deep Scenario dataset is used to not only illustrate\ncross-dataset network performance but also the unification capabilities of\nLMFormer to train on multiple datasets and achieve better performance.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-14T14:43:46Z"}
{"aid":"http://arxiv.org/abs/2504.10288v1","title":"Noise2Ghost: Self-supervised deep convolutional reconstruction for ghost\n  imaging","summary":"We present a new self-supervised deep-learning-based Ghost Imaging (GI)\nreconstruction method, which provides unparalleled reconstruction performance\nfor noisy acquisitions among unsupervised methods. We present the supporting\nmathematical framework and results from theoretical and real data use cases.\nSelf-supervision removes the need for clean reference data while offering\nstrong noise reduction. This provides the necessary tools for addressing\nsignal-to-noise ratio concerns for GI acquisitions in emerging and cutting-edge\nlow-light GI scenarios. Notable examples include micro- and nano-scale x-ray\nemission imaging, e.g., x-ray fluorescence imaging of dose-sensitive samples.\nTheir applications include in-vivo and in-operando case studies for biological\nsamples and batteries.","main_category":"cs.CV","categories":"cs.CV,cs.LG,physics.data-an","published":"2025-04-14T14:58:19Z"}
{"aid":"http://arxiv.org/abs/2504.10307v1","title":"CROSSAN: Towards Efficient and Effective Adaptation of Multiple\n  Multimodal Foundation Models for Sequential Recommendation","summary":"Multimodal Foundation Models (MFMs) excel at representing diverse raw\nmodalities (e.g., text, images, audio, videos, etc.). As recommender systems\nincreasingly incorporate these modalities, leveraging MFMs to generate better\nrepresentations has great potential. However, their application in sequential\nrecommendation remains largely unexplored. This is primarily because mainstream\nadaptation methods, such as Fine-Tuning and even Parameter-Efficient\nFine-Tuning (PEFT) techniques (e.g., Adapter and LoRA), incur high\ncomputational costs, especially when integrating multiple modality encoders,\nthus hindering research progress. As a result, it remains unclear whether we\ncan efficiently and effectively adapt multiple (>2) MFMs for the sequential\nrecommendation task.\n  To address this, we propose a plug-and-play Cross-modal Side Adapter Network\n(CROSSAN). Leveraging the fully decoupled side adapter-based paradigm, CROSSAN\nachieves high efficiency while enabling cross-modal learning across diverse\nmodalities. To optimize the final stage of multimodal fusion across diverse\nmodalities, we adopt the Mixture of Modality Expert Fusion (MOMEF) mechanism.\nCROSSAN achieves superior performance on the public datasets for adapting four\nfoundation models with raw modalities. Performance consistently improves as\nmore MFMs are adapted. We will release our code and datasets to facilitate\nfuture research.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-14T15:14:59Z"}
{"aid":"http://arxiv.org/abs/2504.10308v1","title":"Search for Kink Events in Variable Fermi-LAT Blazars","summary":"This study explores the detection of Quasi-Periodic Oscillations (QPOs) in\nblazars as a method to identify kink events within their jets, utilizing both\n$\\gamma$-ray and polarized light observations. Focusing on a sample of 9\nblazars, we analyze $\\gamma$-ray light curves to identify significant QPOs. In\naddition to $\\gamma$-ray data, we incorporated polarized light data\ncorresponding to the same temporal segments to cross-validate the presence of\nQPOs. However, the limited availability of comprehensive polarized data\nrestricted our ability to perform a thorough analysis across all datasets.\nDespite these limitations, our analysis reveals a segment where QPOs in\npolarized light coincided with those observed in $\\gamma$-rays, providing\npreliminary evidence supporting the kink origin of these oscillations.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-14T15:18:14Z"}
{"aid":"http://arxiv.org/abs/2504.10318v1","title":"Shield Bash: Abusing Defensive Coherence State Retrieval to Break Timing\n  Obfuscation","summary":"Microarchitectural attacks are a significant concern, leading to many\nhardware-based defense proposals. However, different defenses target different\nclasses of attacks, and their impact on each other has not been fully\nconsidered. To raise awareness of this problem, we study an interaction between\ntwo state-of-the art defenses in this paper, timing obfuscations of remote\ncache lines (TORC) and delaying speculative changes to remote cache lines\n(DSRC). TORC mitigates cache-hit based attacks and DSRC mitigates speculative\ncoherence state change attacks.\n  We observe that DSRC enables coherence information to be retrieved into the\nprocessor core, where it is out of the reach of timing obfuscations to protect.\nThis creates an unforeseen consequence that redo operations can be triggered\nwithin the core to detect the presence or absence of remote cache lines, which\nconstitutes a security vulnerability. We demonstrate that a new covert channel\nattack is possible using this vulnerability. We propose two ways to mitigate\nthe attack, whose performance varies depending on an application's cache usage.\nOne way is to never send remote exclusive coherence state (E) information to\nthe core even if it is created. The other way is to never create a remote E\nstate, which is responsible for triggering redos.\n  We demonstrate the timing difference caused by this microarchitectural\ndefense assumption violation using GEM5 simulations. Performance evaluation on\nSPECrate 2017 and PARSEC benchmarks of the two fixes show less than 32\\%\naverage overhead across both sets of benchmarks. The repair which prevented the\ncreation of remote E state had less than 2.8% average overhead.","main_category":"cs.CR","categories":"cs.CR,cs.AR","published":"2025-04-14T15:27:32Z"}
{"aid":"http://arxiv.org/abs/2504.10332v1","title":"MIPS is a Maxwell fluid with an extended and non-monotonic crossover","summary":"Understanding the mechanical properties of active suspensions is crucial for\ntheir potential applications in materials engineering. Among the various\nphenomena in active matter that have no analogue in equilibrium systems,\nmotility-induced phase separation (MIPS) in active colloidal suspensions is one\nof the most extensively studied. However, the mechanical properties of this\nfundamental active state of matter remain poorly understood. This study\ninvestigates the rheology of a suspension of active colloidal particles under\nconstant and oscillatory shear. Systems consisting of pseudo-hard active\nBrownian particles exhibiting co-existence of dense and dilute phases behave as\na viscoelastic Maxwell fluid at low and high frequencies, displaying\nexclusively shear thinning across a wide range of densities and activities.\nRemarkably, the cross-over point between the storage and loss moduli is\nnon-monotonic, rising with activity before the MIPS transition but falling with\nactivity after the transition, revealing the subtleties of how active forces\nand intrinsically out-of-equilibrium phases affect the mechanical properties of\nthese systems.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-14T15:40:17Z"}
{"aid":"http://arxiv.org/abs/2504.10368v1","title":"S1-Bench: A Simple Benchmark for Evaluating System 1 Thinking Capability\n  of Large Reasoning Models","summary":"We introduce S1-Bench, a novel benchmark designed to evaluate Large Reasoning\nModels' (LRMs) performance on simple tasks that favor intuitive system 1\nthinking rather than deliberative system 2 reasoning. While LRMs have achieved\nsignificant breakthroughs in complex reasoning tasks through explicit chains of\nthought, their reliance on deep analytical thinking may limit their system 1\nthinking capabilities. Moreover, a lack of benchmark currently exists to\nevaluate LRMs' performance in tasks that require such capabilities. To fill\nthis gap, S1-Bench presents a set of simple, diverse, and naturally clear\nquestions across multiple domains and languages, specifically designed to\nassess LRMs' performance in such tasks. Our comprehensive evaluation of 22 LRMs\nreveals significant lower efficiency tendencies, with outputs averaging 15.5\ntimes longer than those of traditional small LLMs. Additionally, LRMs often\nidentify correct answers early but continue unnecessary deliberation, with some\nmodels even producing numerous errors. These findings highlight the rigid\nreasoning patterns of current LRMs and underscore the substantial development\nneeded to achieve balanced dual-system thinking capabilities that can adapt\nappropriately to task complexity.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T16:13:23Z"}
{"aid":"http://arxiv.org/abs/2504.10374v1","title":"Ctrl-Z: Controlling AI Agents via Resampling","summary":"Control evaluations measure whether monitoring and security protocols for AI\nsystems prevent intentionally subversive AI models from causing harm. Our work\npresents the first control evaluation performed in an agent environment. We\nconstruct BashBench, a dataset of 257 challenging multi-step system\nadministration tasks, and evaluate whether various safety measures can prevent\nan adversarially constructed AI agent from covertly downloading and executing\nmalicious code in this environment. This multi-step setting introduces new\nattack and defense dynamics, which we investigate in order to design novel\ncontrol protocols that prevent safety failures without hindering the ability of\nnon-malicious agents to perform useful work. We introduce a class of control\nprotocols called resample protocols that dynamically take additional samples of\ncertain actions. We find these protocols significantly improve on existing\ntechniques by selectively blocking the AI agent from executing suspicious code\nand incriminating the agent by generating additional examples of dangerous\nbehavior. We measure the tradeoff between attack prevention and usefulness; our\nbest protocol combines resampling with analysis of previous steps, reducing the\nsuccess rate of attacks from 58% to 7% at a 5% cost to the performance of a\nnon-malicious agent.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T16:22:11Z"}
{"aid":"http://arxiv.org/abs/2504.10376v1","title":"Tumor-immune cell interactions by a fully parabolic chemotaxis model\n  with logistic source","summary":"This work studies the existence of classical solutions to a class of\nchemotaxis systems reading\n  \\[\\begin{cases}\n  u_t = \\Delta u-\\chi \\nabla\\cdot(u \\nabla v) + \\mu_1 u^k -\\mu_2 u^{k+1}, &\n\\text{in} \\; \\Omega\\times(0,T_{\\text{max}}), \\\\\n  v_t= \\Delta v+\\alpha w-\\beta v-\\gamma u v, & \\text{in} \\;\n\\Omega\\times(0,T_{\\text{max}}), \\\\\n  w_t= \\Delta w-\\delta u w+ \\mu_3 w(1-w), & \\text{in} \\;\n\\Omega\\times(0,T_{\\text{max}}), \\\\\n  \\frac{\\partial u}{\\partial\\nu}=\\frac{\\partial v}{\\partial\\nu}=\\frac{\\partial\nw}{\\partial\\nu}=0, & \\text{on} \\; \\partial\\Omega\\times(0,T_{\\text{max}}), \\\\\n  u(x,0)=u_0(x), \\quad v(x,0)= v_0(x), \\quad w(x,0)= w_0(x), &\nx\\in\\overline{\\Omega},\n  \\end{cases}\\] that model interactions between tumor (i.e., $w$) and immune\ncells (i.e., $u$) with a logistic-type source term $\\mu_1 u^k - \\mu_2 u^{k+1}$,\n$k\\geq1$, also in presence of a chemical signal (i.e., $v$). The model\nparameters $\\chi, \\mu_1,\\mu_2, \\mu_3, \\alpha, \\beta, \\gamma$, and $\\delta$ are\nall positive. The value $T_{\\text{max}}$ indicates the maximum instant of time\nup to which solutions are defined. Our focus is on examining the global\nexistence in a bounded domain $\\Omega\\subset \\mathbb{R}^n, n \\geq 3$, under\nNeumann boundary conditions. We distinguish between two scenarios: $k>1$ and\n$k=1$. The first case allows to prove boundedness under smaller assumptions\nrelying only on the model parameters instead of on the initial data, while the\nsecond case requires an extra condition relating the parameters $\\chi, \\mu_2$,\n$n$, and the initial data $\\lVert v_0 \\rVert_{L^\\infty(\\Omega)}$. This model\ncan be seen as an extension of those previously examined in [11] and [4], being\nthe former a system with only two equations and the latter the same model\nwithout logistic.","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T16:24:04Z"}
{"aid":"http://arxiv.org/abs/2504.10388v1","title":"Inferring genotype-phenotype maps using attention models","summary":"Predicting phenotype from genotype is a central challenge in genetics.\nTraditional approaches in quantitative genetics typically analyze this problem\nusing methods based on linear regression. These methods generally assume that\nthe genetic architecture of complex traits can be parameterized in terms of an\nadditive model, where the effects of loci are independent, plus (in some cases)\npairwise epistatic interactions between loci. However, these models struggle to\nanalyze more complex patterns of epistasis or subtle gene-environment\ninteractions. Recent advances in machine learning, particularly attention-based\nmodels, offer a promising alternative. Initially developed for natural language\nprocessing, attention-based models excel at capturing context-dependent\ninteractions and have shown exceptional performance in predicting protein\nstructure and function. Here, we apply attention-based models to quantitative\ngenetics. We analyze the performance of this attention-based approach in\npredicting phenotype from genotype using simulated data across a range of\nmodels with increasing epistatic complexity, and using experimental data from a\nrecent quantitative trait locus mapping study in budding yeast. We find that\nour model demonstrates superior out-of-sample predictions in epistatic regimes\ncompared to standard methods. We also explore a more general multi-environment\nattention-based model to jointly analyze genotype-phenotype maps across\nmultiple environments and show that such architectures can be used for\n\"transfer learning\" - predicting phenotypes in novel environments with limited\ntraining data.","main_category":"q-bio.GN","categories":"q-bio.GN,cs.LG,q-bio.PE","published":"2025-04-14T16:32:17Z"}
{"aid":"http://arxiv.org/abs/2504.10389v1","title":"Diversity-Fair Online Selection","summary":"Online selection problems frequently arise in applications such as\ncrowdsourcing and employee recruitment. Existing research typically focuses on\ncandidates with a single attribute. However, crowdsourcing tasks often require\ncontributions from individuals across various demographics. Further motivated\nby the dynamic nature of crowdsourcing and hiring, we study the diversity-fair\nonline selection problem, in which a recruiter must make real-time decisions to\nfoster workforce diversity across many dimensions. We propose two scenarios for\nthis problem. The fixed-capacity scenario, suited for short-term hiring for\ncrowdsourced workers, provides the recruiter with a fixed capacity to fill\ntemporary job vacancies. In contrast, in the unknown-capacity scenario,\nrecruiters optimize diversity across recruitment seasons with increasing\ncapacities, reflecting that the firm honors diversity consideration in a\nlong-term employee acquisition strategy. By modeling the diversity over $d$\ndimensions as a max-min fairness objective, we show that no policy can surpass\na competitive ratio of $O(1/d^{1/3})$ for either scenario, indicating that any\nachievable result inevitably decays by some polynomial factor in $d$. To this\nend, we develop bilevel hierarchical randomized policies that ensure compliance\nwith the capacity constraint. For the fixed-capacity scenario, leveraging\nmarginal information about the arriving population allows us to achieve a\ncompetitive ratio of $1/(4\\sqrt{d} \\lceil \\log_2 d \\rceil)$. For the\nunknown-capacity scenario, we establish a competitive ratio of\n$\\Omega(1/d^{3/4})$ under mild boundedness conditions. In both bilevel\nhierarchical policies, the higher level determines ex-ante selection\nprobabilities and then informs the lower level's randomized selection that\nensures no loss in efficiency. Both policies prioritize core diversity and then\nadjust for underrepresented dimensions.","main_category":"econ.TH","categories":"econ.TH,cs.DS,math.OC","published":"2025-04-14T16:35:20Z"}
{"aid":"http://arxiv.org/abs/2504.10399v1","title":"Unique Decoding of Reed-Solomon and Related Codes for Semi-Adversarial\n  Errors","summary":"For over a quarter century, the Guruswami-Sudan algorithm has served as the\nstate-of-the-art for list-decoding Reed-Solomon (RS) codes up to the Johnson\nbound against adversarial errors. However, some recent structural results on\nthe combinatorial list decoding of randomly punctured Reed-Solomon codes\nsuggest that Johnson bound can likely be broken for some subclasses of RS\ncodes. Motivated by these results, we seek to make traction on understanding\nadversarial decoding by considering a new model: semi-adversarial errors. This\nerror model bridges between fully random errors and fully adversarial errors by\nallowing some symbols of a message to be corrupted by an adversary while others\nare replaced with uniformly random symbols.\n  As our main quest, we seek to understand optimal efficient unique decoding\nalgorithms in the semi-adversarial model. In particular, we revisit some\nclassical results on decoding interleaved Reed-Solomon codes (aka subfield\nevaluation RS codes) in the random error model by Bleichenbacher-Kiayias-Yung\n(BKY) and work to improve and extend their analysis. First, we give an improved\nimplementation and analysis of the BKY algorithm for interleaved Reed-Solomon\ncodes in the semi-adversarial model. In particular, our algorithm runs in\nnear-linear time, and for most mixtures of random and adversarial errors, our\nanalysis matches the information-theoretic optimum.\n  Moreover, inspired by the BKY algorithm, we use a novel interpolation to\nextend our approach to the settings of folded Reed-Solomon codes, resulting in\nfast algorithms for unique decoding against semi-adversarial errors. A\nparticular advantage of our near-linear time algorithm over state-of-the-art\ndecoding algorithms for adversarial errors is that its running time depends\nonly on a polynomial function of the folding parameter rather than on an\nexponential function.","main_category":"cs.IT","categories":"cs.IT,cs.DS,math.IT","published":"2025-04-14T16:49:45Z"}
{"aid":"http://arxiv.org/abs/2504.10410v1","title":"Purcell-enhanced quantum adsorption","summary":"Cold atoms can adsorb to a surface with the emission of a single phonon when\nthe binding energy is sufficiently small. The effects of phonon damping and\nadsorbent size on the adsorption rate in this quantum regime are studied using\nthe multimode Rabi model. It is demonstrated that the adsorption rate can be\neither enhanced or suppressed relative to the Fermi golden rule rate, in\nanalogy to cavity effects in the spontaneous emission rate in QED. A\nmesoscopic-sized adsorbent behaves as an acoustic cavity that enhances the\nadsorption rate when tuned to the adsorption transition frequency and\nsuppresses the rate when detuned. This acoustic cavity effect occurs in the\nregime where the frequency spacing between vibrational modes exceeds the phonon\nlinewidth.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall","published":"2025-04-14T16:58:03Z"}
{"aid":"http://arxiv.org/abs/2504.10411v1","title":"FPGA-Optimized Hardware Accelerator for Fast Fourier Transform and\n  Singular Value Decomposition in AI","summary":"This research introduces an FPGA-based hardware accelerator to optimize the\nSingular Value Decomposition (SVD) and Fast Fourier transform (FFT) operations\nin AI models. The proposed design aims to improve processing speed and reduce\ncomputational latency. Through experiments, we validate the performance\nbenefits of the hardware accelerator and show how well it handles FFT and SVD\noperations. With its strong security and durability, the accelerator design\nachieves significant speedups over software implementations, thanks to its\nmodules for data flow control, watermark embedding, FFT, and SVD.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-14T16:58:46Z"}
{"aid":"http://arxiv.org/abs/2504.10415v1","title":"LLM-SRBench: A New Benchmark for Scientific Equation Discovery with\n  Large Language Models","summary":"Scientific equation discovery is a fundamental task in the history of\nscientific progress, enabling the derivation of laws governing natural\nphenomena. Recently, Large Language Models (LLMs) have gained interest for this\ntask due to their potential to leverage embedded scientific knowledge for\nhypothesis generation. However, evaluating the true discovery capabilities of\nthese methods remains challenging, as existing benchmarks often rely on common\nequations that are susceptible to memorization by LLMs, leading to inflated\nperformance metrics that do not reflect discovery. In this paper, we introduce\nLLM-SRBench, a comprehensive benchmark with 239 challenging problems across\nfour scientific domains specifically designed to evaluate LLM-based scientific\nequation discovery methods while preventing trivial memorization. Our benchmark\ncomprises two main categories: LSR-Transform, which transforms common physical\nmodels into less common mathematical representations to test reasoning beyond\nmemorized forms, and LSR-Synth, which introduces synthetic, discovery-driven\nproblems requiring data-driven reasoning. Through extensive evaluation of\nseveral state-of-the-art methods, using both open and closed LLMs, we find that\nthe best-performing system so far achieves only 31.5% symbolic accuracy. These\nfindings highlight the challenges of scientific equation discovery, positioning\nLLM-SRBench as a valuable resource for future research.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-14T17:00:13Z"}
{"aid":"http://arxiv.org/abs/2504.10423v1","title":"Overcoming light scattering with high optical nonlinearity","summary":"Achieving high-resolution optical imaging deep within heterogeneous and\nscattering media remains a fundamental challenge in biological microscopy,\nwhere conventional techniques are hindered by multiple light scattering and\nabsorption. Here, we present a non-invasive imaging approach that harnesses the\nnonlinear response of luminescent labels in conjunction with the statistical\nand spatial properties of speckle patterns - an effect of random light\ninterference. Using avalanching nanoparticles (ANPs) with strong\nphotoluminescence nonlinearity, we demonstrate that random speckle illumination\ncan be converted into a single, localized, sub-diffraction excitation spot.\nThis spot can be scanned across the sample using the angular memory effect,\nenabling high-resolution imaging through a scattering layer. Our method is\ngeneral, fast, and cost-effective. It requires no wavefront shaping, no\nfeedback, and no reconstruction algorithm, offering a powerful new route to\ndeep, high-resolution imaging through complex media.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mtrl-sci,physics.bio-ph,physics.med-ph","published":"2025-04-14T17:10:24Z"}
{"aid":"http://arxiv.org/abs/2504.10445v1","title":"RealWebAssist: A Benchmark for Long-Horizon Web Assistance with\n  Real-World Users","summary":"To achieve successful assistance with long-horizon web-based tasks, AI agents\nmust be able to sequentially follow real-world user instructions over a long\nperiod. Unlike existing web-based agent benchmarks, sequential instruction\nfollowing in the real world poses significant challenges beyond performing a\nsingle, clearly defined task. For instance, real-world human instructions can\nbe ambiguous, require different levels of AI assistance, and may evolve over\ntime, reflecting changes in the user's mental state. To address this gap, we\nintroduce RealWebAssist, a novel benchmark designed to evaluate sequential\ninstruction-following in realistic scenarios involving long-horizon\ninteractions with the web, visual GUI grounding, and understanding ambiguous\nreal-world user instructions. RealWebAssist includes a dataset of sequential\ninstructions collected from real-world human users. Each user instructs a\nweb-based assistant to perform a series of tasks on multiple websites. A\nsuccessful agent must reason about the true intent behind each instruction,\nkeep track of the mental state of the user, understand user-specific routines,\nand ground the intended tasks to actions on the correct GUI elements. Our\nexperimental results show that state-of-the-art models struggle to understand\nand ground user instructions, posing critical challenges in following\nreal-world user instructions for long-horizon web assistance.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.CV,cs.LG","published":"2025-04-14T17:36:46Z"}
{"aid":"http://arxiv.org/abs/2504.10471v1","title":"MIEB: Massive Image Embedding Benchmark","summary":"Image representations are often evaluated through disjointed, task-specific\nprotocols, leading to a fragmented understanding of model capabilities. For\ninstance, it is unclear whether an image embedding model adept at clustering\nimages is equally good at retrieving relevant images given a piece of text. We\nintroduce the Massive Image Embedding Benchmark (MIEB) to evaluate the\nperformance of image and image-text embedding models across the broadest\nspectrum to date. MIEB spans 38 languages across 130 individual tasks, which we\ngroup into 8 high-level categories. We benchmark 50 models across our\nbenchmark, finding that no single method dominates across all task categories.\nWe reveal hidden capabilities in advanced vision models such as their accurate\nvisual representation of texts, and their yet limited capabilities in\ninterleaved encodings and matching images and texts in the presence of\nconfounders. We also show that the performance of vision encoders on MIEB\ncorrelates highly with their performance when used in multimodal large language\nmodels. Our code, dataset, and leaderboard are publicly available at\nhttps://github.com/embeddings-benchmark/mteb.","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-04-14T17:54:28Z"}
{"aid":"http://arxiv.org/abs/2504.10479v1","title":"InternVL3: Exploring Advanced Training and Test-Time Recipes for\n  Open-Source Multimodal Models","summary":"We introduce InternVL3, a significant advancement in the InternVL series\nfeaturing a native multimodal pre-training paradigm. Rather than adapting a\ntext-only large language model (LLM) into a multimodal large language model\n(MLLM) that supports visual inputs, InternVL3 jointly acquires multimodal and\nlinguistic capabilities from both diverse multimodal data and pure-text corpora\nduring a single pre-training stage. This unified training paradigm effectively\naddresses the complexities and alignment challenges commonly encountered in\nconventional post-hoc training pipelines for MLLMs. To further improve\nperformance and scalability, InternVL3 incorporates variable visual position\nencoding (V2PE) to support extended multimodal contexts, employs advanced\npost-training techniques such as supervised fine-tuning (SFT) and mixed\npreference optimization (MPO), and adopts test-time scaling strategies\nalongside an optimized training infrastructure. Extensive empirical evaluations\ndemonstrate that InternVL3 delivers superior performance across a wide range of\nmulti-modal tasks. In particular, InternVL3-78B achieves a score of 72.2 on the\nMMMU benchmark, setting a new state-of-the-art among open-source MLLMs. Its\ncapabilities remain highly competitive with leading proprietary models,\nincluding ChatGPT-4o, Claude 3.5 Sonnet, and Gemini 2.5 Pro, while also\nmaintaining strong pure-language proficiency. In pursuit of open-science\nprinciples, we will publicly release both the training data and model weights\nto foster further research and development in next-generation MLLMs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T17:59:25Z"}
{"aid":"http://arxiv.org/abs/2504.10827v1","title":"Large-time behavior of solutions to the Boussinesq equations with\n  partial dissipation and influence of rotation","summary":"This paper investigates the stability and large-time behavior of solutions to\nthe rotating Boussinesq system under the influence of a general gravitational\npotential $\\Psi$, which is widely used to model the dynamics of stratified\ngeophysical fluids on the $f-$plane. Our main results are threefold: First, by\nimposing physically realistic boundary conditions and viscosity constraints, we\nprove that the solutions of the system smust necessarily take the following\nsteady-state form $(\\rho,u,v,w,p)=(\\rho_s,0,v_s,0, p_s)$. These solutions are\ncharacterized by both geostrophic balance, given by $fv_s-\\frac{\\partial\np_s}{\\partial x}=\\rho_s\\frac{\\partial \\Psi}{\\partial x}$ and hydrostatic\nbalance, expressed as $-\\frac{\\partial p_s}{\\partial z}=\\rho_s\\frac{\\partial\n\\Psi}{\\partial z}$. Second, we establish that any steady-state solution\nsatisfying the conditions $\\nabla \\rho_s=\\delta (x,z)\\nabla \\Psi$ with\n$v_s(x,z)=a_0x+a_1$ is linearly unstable when the conditions\n$\\delta(x,z)|_{(x_0,z_0)}>0$ and $(f+\\alpha_0)\\leq 0$ are simultaneously\nsatisfied. This instability under the condition $\\delta(x,z)|_{(x_0,z_0)}>0$\ncorresponds to the well-known Rayleigh-Taylor instability. Third, although the\ninherent Rayleigh-Taylor instability could potentially amplify the velocity\naround unstable steady-state solutions (heavier density over lighter one), we\nrigorously demonstrate that for any sufficiently smooth initial data, the\nsolutions of the system asymptotically converge to a neighborhood of a\nsteady-state solution in which both the zonal and vertical velocity components\nvanish. Finally, under a moderate additional assumption, we demonstrate that\nthe system converges to a specific steady-state solution. In this state, the\ndensity profile is given by $\\rho=-\\gamma \\Psi+\\beta$, where $\\gamma$ and\n$\\beta$ are positive constants, and the meridional velocity $v$ depends solely\nand linearly on $x$ variable.","main_category":"math.AP","categories":"math.AP","published":"2025-04-15T03:10:27Z"}
{"aid":"http://arxiv.org/abs/2504.10834v1","title":"LightFormer: A lightweight and efficient decoder for remote sensing\n  image segmentation","summary":"Deep learning techniques have achieved remarkable success in the semantic\nsegmentation of remote sensing images and in land-use change detection.\nNevertheless, their real-time deployment on edge platforms remains constrained\nby decoder complexity. Herein, we introduce LightFormer, a lightweight decoder\nfor time-critical tasks that involve unstructured targets, such as disaster\nassessment, unmanned aerial vehicle search-and-rescue, and cultural heritage\nmonitoring. LightFormer employs a feature-fusion and refinement module built on\nchannel processing and a learnable gating mechanism to aggregate multi-scale,\nmulti-range information efficiently, which drastically curtails model\ncomplexity. Furthermore, we propose a spatial information selection module\n(SISM) that integrates long-range attention with a detail preservation branch\nto capture spatial dependencies across multiple scales, thereby substantially\nimproving the recognition of unstructured targets in complex scenes. On the\nISPRS Vaihingen benchmark, LightFormer attains 99.9% of GLFFNet's mIoU (83.9%\nvs. 84.0%) while requiring only 14.7% of its FLOPs and 15.9% of its parameters,\nthus achieving an excellent accuracy-efficiency trade-off. Consistent results\non LoveDA, ISPRS Potsdam, RescueNet, and FloodNet further demonstrate its\nrobustness and superior perception of unstructured objects. These findings\nhighlight LightFormer as a practical solution for remote sensing applications\nwhere both computational economy and high-precision segmentation are\nimperative.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T03:25:39Z"}
{"aid":"http://arxiv.org/abs/2504.10836v1","title":"Uplink Assisted Joint Channel Estimation and CSI Feedback: An Approach\n  Based on Deep Joint Source-Channel Coding","summary":"In frequency division duplex (FDD) multiple-input multiple-output (MIMO)\nwireless communication systems, the acquisition of downlink channel state\ninformation (CSI) is essential for maximizing spatial resource utilization and\nimproving system spectral efficiency. The separate design of modules in\nAI-based CSI feedback architectures under traditional modular communication\nframeworks, including channel estimation (CE), CSI compression and feedback,\nleads to sub-optimal performance. In this paper, we propose an uplink assisted\njoint CE and and CSI feedback approach via deep learning for downlink CSI\nacquisition, which mitigates performance degradation caused by distribution\nbias across separately trained modules in traditional modular communication\nframeworks. The proposed network adopts a deep joint source-channel coding\n(DJSCC) architecture to mitigate the cliff effect encountered in the\nconventional separate source-channel coding. Furthermore, we exploit the uplink\nCSI as auxiliary information to enhance CSI reconstruction accuracy by\nleveraging the partial reciprocity between the uplink and downlink channels in\nFDD systems, without introducing additional overhead. The effectiveness of\nuplink CSI as assisted information and the necessity of an end-toend\nmulti-module joint training architecture is validated through comprehensive\nablation and scalability experiments.","main_category":"eess.SP","categories":"eess.SP,cs.AI","published":"2025-04-15T03:29:24Z"}
{"aid":"http://arxiv.org/abs/2504.10855v1","title":"Virtual Contraction Approach to Decentralized Adaptive Stabilization of\n  Nonlinear Time-Delayed Networks","summary":"In this paper, we utilize a diagonally dominant structure for the\ndecentralized stabilization of unknown nonlinear time-delayed networks.\nGeneralizing the idea of virtual contraction analysis to time-delayed systems,\nwe demonstrate that nonlinear time-delayed networks can be stabilized by\ndiagonal high-gains if the input matrices possess certain generalized\n(column/row) diagonally dominant properties. To achieve stabilization of\nunknown networks, we further propose a distributed adaptive tuning rule for\neach individual gain function, ensuring that all closed-loop trajectories\nconverge to the origin. The effectiveness of the proposed decentralized\nadaptive control is verified in a case study on epidemic spreading control in\nSIS networks with transmission delays.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-15T04:34:24Z"}
{"aid":"http://arxiv.org/abs/2504.10862v1","title":"Testing redshift variation of the X-ray and ultraviolet luminosity\n  relations of quasars","summary":"Quasars serve as important cosmological probes and constructing accurate\nluminosity relations for them is essential for their use in cosmology. If the\ncoefficients of quasar's luminosity relation vary with redshift, it could\nintroduce biases into cosmological constraints derived from quasars. In this\npaper, we conduct a detailed analysis of the redshift variation in the X-ray\nluminosity and ultraviolet (UV) luminosity ($L_\\mathrm{X}$-$L_\\mathrm{UV}$)\nrelations of quasars. For the standard $L_\\mathrm{X}$-$L_\\mathrm{UV}$ relation,\nwe find that the relation coefficients exhibit a strong and linear correlation\nwith redshift, which is not attributable to the selection effect. Additionally,\nwe examine two three-dimensional, redshift-evolving\n$L_\\mathrm{X}$-$L_\\mathrm{UV}$ relations and find that the inclusion of a\nredshift-dependent term does not eliminate the impact of redshift evolution, as\nthe relation coefficients continue to evolve with redshift. Finally, we\nconstruct a new $L_\\mathrm{X}$-$L_\\mathrm{UV}$ relation in which the redshift\nevolution of the relation coefficients is nearly eliminated. Calibrating the\nluminosity relations using Hubble parameter measurements, we demonstrate that\nquasars utilizing our new relation yield effective constraints on cosmological\nparameters that are consistent with results from Planck CMB data, unlike\nconstraints derived from the standard relation.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-15T04:48:23Z"}
{"aid":"http://arxiv.org/abs/2504.10868v1","title":"AdS3 axion wormholes as stable contributions to the Euclidean\n  gravitational path integral","summary":"Recent work has demonstrated that Euclidean Giddings-Strominger axion\nwormholes are stable in asymptotically flat 4D Minkowski spacetime, suggesting\nthat they should, at least naively, be included as contributions in the quantum\ngravitational path integral. Such inclusion appears to lead to known wormhole\nparadoxes, such as the factorization problem. In this paper, we generalize\nthese results to AdS3 spacetime, where the axion is equivalent to a U(1) gauge\nfield. We explicitly construct the classical wormhole solutions, show their\nregularity and stability, and compute their actions for arbitrary ratios of the\nwormhole mouth radius to the AdS radius and across various topologies. Finally,\nWe discuss potential implications of these findings for the 3D gravitational\npath integral.","main_category":"hep-th","categories":"hep-th","published":"2025-04-15T05:00:20Z"}
{"aid":"http://arxiv.org/abs/2504.10873v1","title":"Can Vision-Language Models Understand and Interpret Dynamic Gestures\n  from Pedestrians? Pilot Datasets and Exploration Towards Instructive\n  Nonverbal Commands for Cooperative Autonomous Vehicles","summary":"In autonomous driving, it is crucial to correctly interpret traffic gestures\n(TGs), such as those of an authority figure providing orders or instructions,\nor a pedestrian signaling the driver, to ensure a safe and pleasant traffic\nenvironment for all road users. This study investigates the capabilities of\nstate-of-the-art vision-language models (VLMs) in zero-shot interpretation,\nfocusing on their ability to caption and classify human gestures in traffic\ncontexts. We create and publicly share two custom datasets with varying formal\nand informal TGs, such as 'Stop', 'Reverse', 'Hail', etc. The datasets are\n\"Acted TG (ATG)\" and \"Instructive TG In-The-Wild (ITGI)\". They are annotated\nwith natural language, describing the pedestrian's body position and gesture.\nWe evaluate models using three methods utilizing expert-generated captions as\nbaseline and control: (1) caption similarity, (2) gesture classification, and\n(3) pose sequence reconstruction similarity. Results show that current VLMs\nstruggle with gesture understanding: sentence similarity averages below 0.59,\nand classification F1 scores reach only 0.14-0.39, well below the expert\nbaseline of 0.70. While pose reconstruction shows potential, it requires more\ndata and refined metrics to be reliable. Our findings reveal that although some\nSOTA VLMs can interpret zero-shot human traffic gestures, none are accurate and\nrobust enough to be trustworthy, emphasizing the need for further research in\nthis domain.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.HC","published":"2025-04-15T05:04:25Z"}
{"aid":"http://arxiv.org/abs/2504.10885v1","title":"PuzzleBench: A Fully Dynamic Evaluation Framework for Large Multimodal\n  Models on Puzzle Solving","summary":"Large Multimodal Models (LMMs) have demonstrated impressive capabilities\nacross a wide range of multimodal tasks, achieving ever-increasing performance\non various evaluation benchmarks. However, existing benchmarks are typically\nstatic and often overlap with pre-training datasets, leading to fixed\ncomplexity constraints and substantial data contamination issues. Meanwhile,\nmanually annotated datasets are labor-intensive, time-consuming, and subject to\nhuman bias and inconsistency, leading to reliability and reproducibility\nissues. To address these problems, we propose a fully dynamic multimodal\nevaluation framework, named Open-ended Visual Puzzle Generation (OVPG), which\naims to generate fresh, diverse, and verifiable evaluation data automatically\nin puzzle-solving tasks. Specifically, the OVPG pipeline consists of a raw\nmaterial sampling module, a visual content generation module, and a puzzle rule\ndesign module, which ensures that each evaluation instance is primitive, highly\nrandomized, and uniquely solvable, enabling continual adaptation to the\nevolving capabilities of LMMs. Built upon OVPG, we construct PuzzleBench, a\ndynamic and scalable benchmark comprising 11,840 VQA samples. It features six\ncarefully designed puzzle tasks targeting three core LMM competencies, visual\nrecognition, logical reasoning, and context understanding. PuzzleBench differs\nfrom static benchmarks that quickly become outdated. It enables ongoing dataset\nrefreshing through OVPG and a rich set of open-ended puzzle designs, allowing\nseamless adaptation to the evolving capabilities of LMMs.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T05:29:31Z"}
{"aid":"http://arxiv.org/abs/2504.10889v1","title":"Fine-Grained Rib Fracture Diagnosis with Hyperbolic Embeddings: A\n  Detailed Annotation Framework and Multi-Label Classification Model","summary":"Accurate rib fracture identification and classification are essential for\ntreatment planning. However, existing datasets often lack fine-grained\nannotations, particularly regarding rib fracture characterization, type, and\nprecise anatomical location on individual ribs. To address this, we introduce a\nnovel rib fracture annotation protocol tailored for fracture classification.\nFurther, we enhance fracture classification by leveraging cross-modal\nembeddings that bridge radiological images and clinical descriptions. Our\napproach employs hyperbolic embeddings to capture the hierarchical nature of\nfracture, mapping visual features and textual descriptions into a shared\nnon-Euclidean manifold. This framework enables more nuanced similarity\ncomputations between imaging characteristics and clinical descriptions,\naccounting for the inherent hierarchical relationships in fracture taxonomy.\nExperimental results demonstrate that our approach outperforms existing methods\nacross multiple classification tasks, with average recall improvements of 6% on\nthe AirRib dataset and 17.5% on the public RibFrac dataset.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T05:47:09Z"}
{"aid":"http://arxiv.org/abs/2504.10905v1","title":"InterAnimate: Taming Region-aware Diffusion Model for Realistic Human\n  Interaction Animation","summary":"Recent video generation research has focused heavily on isolated actions,\nleaving interactive motions-such as hand-face interactions-largely unexamined.\nThese interactions are essential for emerging biometric authentication systems,\nwhich rely on interactive motion-based anti-spoofing approaches. From a\nsecurity perspective, there is a growing need for large-scale, high-quality\ninteractive videos to train and strengthen authentication models. In this work,\nwe introduce a novel paradigm for animating realistic hand-face interactions.\nOur approach simultaneously learns spatio-temporal contact dynamics and\nbiomechanically plausible deformation effects, enabling natural interactions\nwhere hand movements induce anatomically accurate facial deformations while\nmaintaining collision-free contact. To facilitate this research, we present\nInterHF, a large-scale hand-face interaction dataset featuring 18 interaction\npatterns and 90,000 annotated videos. Additionally, we propose InterAnimate, a\nregion-aware diffusion model designed specifically for interaction animation.\nInterAnimate leverages learnable spatial and temporal latents to effectively\ncapture dynamic interaction priors and integrates a region-aware interaction\nmechanism that injects these priors into the denoising process. To the best of\nour knowledge, this work represents the first large-scale effort to\nsystematically study human hand-face interactions. Qualitative and quantitative\nresults show InterAnimate produces highly realistic animations, setting a new\nbenchmark. Code and data will be made public to advance research.","main_category":"cs.CV","categories":"cs.CV,cs.HC","published":"2025-04-15T06:32:45Z"}
{"aid":"http://arxiv.org/abs/2504.10916v1","title":"Embedding Radiomics into Vision Transformers for Multimodal Medical\n  Image Classification","summary":"Background: Deep learning has significantly advanced medical image analysis,\nwith Vision Transformers (ViTs) offering a powerful alternative to\nconvolutional models by modeling long-range dependencies through\nself-attention. However, ViTs are inherently data-intensive and lack\ndomain-specific inductive biases, limiting their applicability in medical\nimaging. In contrast, radiomics provides interpretable, handcrafted descriptors\nof tissue heterogeneity but suffers from limited scalability and integration\ninto end-to-end learning frameworks. In this work, we propose the\nRadiomics-Embedded Vision Transformer (RE-ViT) that combines radiomic features\nwith data-driven visual embeddings within a ViT backbone.\n  Purpose: To develop a hybrid RE-ViT framework that integrates radiomics and\npatch-wise ViT embeddings through early fusion, enhancing robustness and\nperformance in medical image classification.\n  Methods: Following the standard ViT pipeline, images were divided into\npatches. For each patch, handcrafted radiomic features were extracted and fused\nwith linearly projected pixel embeddings. The fused representations were\nnormalized, positionally encoded, and passed to the ViT encoder. A learnable\n[CLS] token aggregated patch-level information for classification. We evaluated\nRE-ViT on three public datasets (including BUSI, ChestXray2017, and Retinal\nOCT) using accuracy, macro AUC, sensitivity, and specificity. RE-ViT was\nbenchmarked against CNN-based (VGG-16, ResNet) and hybrid (TransMed) models.\n  Results: RE-ViT achieved state-of-the-art results: on BUSI,\nAUC=0.950+/-0.011; on ChestXray2017, AUC=0.989+/-0.004; on Retinal OCT,\nAUC=0.986+/-0.001, which outperforms other comparison models.\n  Conclusions: The RE-ViT framework effectively integrates radiomics with ViT\narchitectures, demonstrating improved performance and generalizability across\nmultimodal medical image classification tasks.","main_category":"physics.med-ph","categories":"physics.med-ph,cs.CV","published":"2025-04-15T06:55:58Z"}
{"aid":"http://arxiv.org/abs/2504.10922v1","title":"Equivalence of germs (of mappings and sets) over k vs that over K","summary":"Consider real-analytic mapping-germs, (R^n,o)-> (R^m,o). They can be\nequivalent (by coordinate changes) complex-analytically, but not\nreal-analytically. However, if the transformation of complex-equivalence is\nidentity modulo higher order terms, then it implies the real-equivalence.\n  On the other hand, starting from complex-analytic map-germs (C^n,o)->(C^m,o),\nand taking any field extension, C to K, one has: if two maps are equivalent\nover K, then they are equivalent over C.\n  These (quite useful) properties seem to be not well known. We prove slightly\nstronger properties in a more general form:\n  * for Maps(X,Y) where X,Y are (formal/analytic/Nash) scheme-germs, with\narbitrary singularities, over a base ring k;\n  * for the classical groups of (right/left-right/contact) equivalence of\nSingularity Theory;\n  * for faithfully-flat extensions of rings k -> K. In particular, for\narbitrary extension of fields, in any characteristic.\n  The case ``k is a ring\" is important for the study of\ndeformations/unfoldings. E.g. it implies the statement for fields: if a family\nof maps {f_t} is trivial over K, then it is also trivial over k.\n  Similar statements for scheme-germs (``isomorphism over K vs isomorphism over\nk\") follow by the standard reduction ``Two maps are contact equivalent iff\ntheir zero sets are ambient isomorphic\".\n  This study involves the contact equivalence of maps with singular targets,\nwhich seems to be not well-established. We write down the relevant part of this\ntheory.","main_category":"math.AG","categories":"math.AG,math.AC,math.CV","published":"2025-04-15T07:09:27Z"}
{"aid":"http://arxiv.org/abs/2504.10923v1","title":"Fast-Powerformer: A Memory-Efficient Transformer for Accurate Mid-Term\n  Wind Power Forecasting","summary":"Wind power forecasting (WPF), as a significant research topic within\nrenewable energy, plays a crucial role in enhancing the security, stability,\nand economic operation of power grids. However, due to the high stochasticity\nof meteorological factors (e.g., wind speed) and significant fluctuations in\nwind power output, mid-term wind power forecasting faces a dual challenge of\nmaintaining high accuracy and computational efficiency. To address these\nissues, this paper proposes an efficient and lightweight mid-term wind power\nforecasting model, termed Fast-Powerformer. The proposed model is built upon\nthe Reformer architecture, incorporating structural enhancements such as a\nlightweight Long Short-Term Memory (LSTM) embedding module, an input\ntransposition mechanism, and a Frequency Enhanced Channel Attention Mechanism\n(FECAM). These improvements enable the model to strengthen temporal feature\nextraction, optimize dependency modeling across variables, significantly reduce\ncomputational complexity, and enhance sensitivity to periodic patterns and\ndominant frequency components. Experimental results conducted on multiple\nreal-world wind farm datasets demonstrate that the proposed Fast-Powerformer\nachieves superior prediction accuracy and operational efficiency compared to\nmainstream forecasting approaches. Furthermore, the model exhibits fast\ninference speed and low memory consumption, highlighting its considerable\npractical value for real-world deployment scenarios.","main_category":"cs.LG","categories":"cs.LG,eess.SP","published":"2025-04-15T07:09:54Z"}
{"aid":"http://arxiv.org/abs/2504.10924v1","title":"Exploring the nature of $η_{1}(1855)$ and it's partner in a chiral\n  quark model","summary":"Inspired by the recent experimental discoveries of \\(X(3872)\\)\n(\\(c\\bar{q}\\)-\\(q\\bar{c}\\)) and \\(T_{cc}\\) (\\(c\\bar{q}\\)-\\(c\\bar{q}\\)), we\nsystematically study two four-quark systems: the \\(K K_1\\)\n(\\(q\\bar{s}\\)-\\(q\\bar{s}\\)) system and the \\(K \\bar{K}_1\\)\n(\\(q\\bar{s}\\)-\\(s\\bar{q}\\)) system, which is a candidate for the recently\nobserved \\(\\eta_1(1855)\\). Within the framework of an accurate few-body\ncalculation method (GEM), we employ the chiral quark model to simultaneously\nconsider the molecular and diquark structures of these two multiquark systems\nand include their channel coupling effects. Our results show that the \\(K\n\\bar{K}_1\\) system remains a scattering state. On the other hand, due to the\npresence of a good-diquark structure in the \\(K K_1\\) system, we obtain a bound\nstate in the coupled-channel calculation. The primary contribution to the\nbinding energy comes from the exchange of \\(\\pi\\)-meson and \\(\\sigma\\)-meson.\nThe inter-quark distance indicates that it is a compact four-quark structure.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-15T07:10:02Z"}
{"aid":"http://arxiv.org/abs/2504.10936v1","title":"Can LLMs Leverage Observational Data? Towards Data-Driven Causal\n  Discovery with LLMs","summary":"Causal discovery traditionally relies on statistical methods applied to\nobservational data, often requiring large datasets and assumptions about\nunderlying causal structures. Recent advancements in Large Language Models\n(LLMs) have introduced new possibilities for causal discovery by providing\ndomain expert knowledge. However, it remains unclear whether LLMs can\neffectively process observational data for causal discovery. In this work, we\nexplore the potential of LLMs for data-driven causal discovery by integrating\nobservational data for LLM-based reasoning. Specifically, we examine whether\nLLMs can effectively utilize observational data through two prompting\nstrategies: pairwise prompting and breadth first search (BFS)-based prompting.\nIn both approaches, we incorporate the observational data directly into the\nprompt to assess LLMs' ability to infer causal relationships from such data.\nExperiments on benchmark datasets show that incorporating observational data\nenhances causal discovery, boosting F1 scores by up to 0.11 point using both\npairwise and BFS LLM-based prompting, while outperforming traditional\nstatistical causal discovery baseline by up to 0.52 points. Our findings\nhighlight the potential and limitations of LLMs for data-driven causal\ndiscovery, demonstrating their ability to move beyond textual metadata and\neffectively interpret and utilize observational data for more informed causal\nreasoning. Our studies lays the groundwork for future advancements toward fully\nLLM-driven causal discovery.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-15T07:32:35Z"}
{"aid":"http://arxiv.org/abs/2504.10942v1","title":"The path towards measuring the gravitational field of proton bunches at\n  accelerators","summary":"The Newtonian law describing the gravitational interaction of\nnon-relativistic (slowly moving) gravitating matter, has been tested in many\nlaboratory experiments with very high precision. In contrast, the post\nMinkowskian predictions for the gravitational field of ultra-relativistic\nmatter, dominated by momentum instead of rest mass, have not been tested\ndirectly yet. The intense ultra-relativistic proton beam in the LHC storage\nring offers the potential to test general relativity and alternative\ngravitational theories in this parameter regime for the first time in\ncontrolled lab-scale experiments. If successful, this would open the road to a\nnovel use case of the LHC, where non-trivial gravitational physics could be\nstudied likely in a parasitic mode, without the necessity of dedicated filling\npatterns. While the technical challenges are formidable, they should also lead\nto the development of ultra-high-sensitive acceleration sensors with abundant\napplications in other parts of science and technology. The present document\nsummarizes the status of the theoretical studies in this direction, points out\nthe challenges, and possible ways of addressing them. It was submitted as a\ncontribution to the European Strategy for Particle Physics (ESPP) 2026 Update.","main_category":"hep-ex","categories":"hep-ex,gr-qc,quant-ph","published":"2025-04-15T07:45:35Z"}
{"aid":"http://arxiv.org/abs/2504.10946v1","title":"Maximum principles and spectral analysis for the superposition of\n  operators of fractional order","summary":"We consider a \"superposition operator\" obtained through the continuous\nsuperposition of operators of mixed fractional order, modulated by a signed\nBorel finite measure defined over the set $[0, 1]$. The relevance of this\noperator is rooted in the fact that it incorporates special and significant\ncases of interest, like the mixed operator $-\\Delta + (-\\Delta)^s$, the\n(possibly) infinite sum of fractional Laplacians and allows to consider\noperators carrying a \"wrong sign\".\n  We first outline weak and strong maximum principles for this type of\noperators. Then, we complete the spectral analysis for the related Dirichlet\neigenvalue problem started in [DPLSV25b].","main_category":"math.AP","categories":"math.AP","published":"2025-04-15T07:50:32Z"}
{"aid":"http://arxiv.org/abs/2504.10968v1","title":"Bulk Hydrodynamic Transport in Weyl Semimetals","summary":"The role of collective longitudinal modes, plasmons, in bulk hydrodynamic\ntransport in Weyl semimetals is explored. In contrast to graphene, where these\nmodes are gapless, plasmons in Weyl semimetals are gapped. This gap, however,\ncan be made arbitrarily small by decreasing the temperature or the chemical\npotential, making plasmon modes thermally accessible, both in thermodynamics\nand transport. In very clean Weyl semimetals near charge-neutrality where the\nplasmon gap is minimal, we find that they leave an imprint in the thermal\nconductivity and the viscosity.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.str-el","published":"2025-04-15T08:20:45Z"}
{"aid":"http://arxiv.org/abs/2504.10974v1","title":"Self-Supervised Enhancement of Forward-Looking Sonar Images: Bridging\n  Cross-Modal Degradation Gaps through Feature Space Transformation and\n  Multi-Frame Fusion","summary":"Enhancing forward-looking sonar images is critical for accurate underwater\ntarget detection. Current deep learning methods mainly rely on supervised\ntraining with simulated data, but the difficulty in obtaining high-quality\nreal-world paired data limits their practical use and generalization. Although\nself-supervised approaches from remote sensing partially alleviate data\nshortages, they neglect the cross-modal degradation gap between sonar and\nremote sensing images. Directly transferring pretrained weights often leads to\noverly smooth sonar images, detail loss, and insufficient brightness. To\naddress this, we propose a feature-space transformation that maps sonar images\nfrom the pixel domain to a robust feature domain, effectively bridging the\ndegradation gap. Additionally, our self-supervised multi-frame fusion strategy\nleverages complementary inter-frame information to naturally remove speckle\nnoise and enhance target-region brightness. Experiments on three self-collected\nreal-world forward-looking sonar datasets show that our method significantly\noutperforms existing approaches, effectively suppressing noise, preserving\ndetailed edges, and substantially improving brightness, demonstrating strong\npotential for underwater target detection applications.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-15T08:34:56Z"}
{"aid":"http://arxiv.org/abs/2504.10989v1","title":"Global N-body Simulation of Gap Edge Structures Created by Perturbations\n  from a Small Satellite Embedded in Saturn's Rings II: The Effect of\n  Satellite's Orbital Eccentricity and Inclination","summary":"Pan and Daphnis are embedded in Saturn's rings and opening a gap with\nsatellite wakes at the gap edges. Furthermore, in the case of Daphnis,\npronounced vertical wall structures casting shadows on the rings are also\nobserved in the satellite wakes. In this paper, we perform a global 3D N-body\nsimulation with non-zero $e_{\\rm s}$ or non-zero $i_{\\rm s}$ of the satellite\norbit to investigate how they affect the gap edge structures. We found that the\neffect of satellite eccentricity is important both in the satellite wakes and\nthe vertical walls at the gap edges. The non-sinusoidal sawtooth-like satellite\nwakes and azimuthally more localized vertical walls observed by Cassini are\nsimultaneously reproduced in the detailed structures and spatial scales. Both\nof them periodically vary due to the satellite excursions between the apocenter\nand the pericenter. The ring particles in outer (inner) rings that undergo\nclosest encounters with the satellite near the apocenter (pericenter) are\nexcited the most highly. Because the excited eccentricities of the ring\nparticles are converted to the inclinations through physical collisions, the\nconversion is the most active for the particles that acquire the highest\neccentricities, resulting in the azimuthally more localized vertical wall\nstructures. The predicted height of the tallest vertical walls is $\\sim 0.2$\ntimes the satellite Hill radius in the case of the satellite eccentricity\ncomparable to Daphnis when adopting Hill scaling, which is twice as much as the\nheight obtained in the case of the circular satellite orbit and is\nquantitatively more consistent with the Cassini observation. These results show\nthat the observed vertical walls are actually formed by the satellite wakes\nfollowed by their conversion to the vertical motions through inter-particle\ncollisions, rather than by the out-of-plane perturbation from the satellite in\nan inclined orbit.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-15T09:01:52Z"}
{"aid":"http://arxiv.org/abs/2504.11006v1","title":"A Navier-Stokes-Peridynamics hybrid algorithm for the coupling of\n  compressible flows and fracturing materials","summary":"Modeling and simulation of fluid-structure interactions are crucial to the\nsuccess of aerospace engineering. This work addresses a novel hybrid algorithm\nthat models the close coupling between compressible flows and deformable\nmaterials using a mesoscopic approach. Specifically, the high-speed flows are\ndescribed by the gas-kinetic scheme, which is a robust Navier-Stokes\nalternative solver built on the molecular kinetic theory. The deformation,\ndamage, and fracture of materials are depicted using the bond-based\nperidynamics, which serves as coarse-grained molecular dynamics to construct\nnon-local extensions of classical continuum mechanics. The evolution of fluids\nand materials are closely coupled using the ghost-cell immersed boundary\nmethod. Within each time step, the solutions of flow and solid fields are\nupdated simultaneously, and physics-driven boundary conditions are exchanged\nfor each other via ghost cells. Extensive numerical experiments, including\ncrack propagation in a pre-cracked plate, subsonic flow around the NACA0012\nairfoil, supersonic flow around the circular cylinder, and shock wave impacting\non the elastic panel, are performed to validate the algorithm. The simulation\nresults demonstrate the unique advantages of current hybrid algorithm in\nsolving fracture propagation induced by high-speed flows.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-04-15T09:25:14Z"}
{"aid":"http://arxiv.org/abs/2504.11024v1","title":"Easy3D: A Simple Yet Effective Method for 3D Interactive Segmentation","summary":"The increasing availability of digital 3D environments, whether through\nimage-based 3D reconstruction, generation, or scans obtained by robots, is\ndriving innovation across various applications. These come with a significant\ndemand for 3D interaction, such as 3D Interactive Segmentation, which is useful\nfor tasks like object selection and manipulation. Additionally, there is a\npersistent need for solutions that are efficient, precise, and performing well\nacross diverse settings, particularly in unseen environments and with\nunfamiliar objects. In this work, we introduce a 3D interactive segmentation\nmethod that consistently surpasses previous state-of-the-art techniques on both\nin-domain and out-of-domain datasets. Our simple approach integrates a\nvoxel-based sparse encoder with a lightweight transformer-based decoder that\nimplements implicit click fusion, achieving superior performance and maximizing\nefficiency. Our method demonstrates substantial improvements on benchmark\ndatasets, including ScanNet, ScanNet++, S3DIS, and KITTI-360, and also on\nunseen geometric distributions such as the ones obtained by Gaussian Splatting.\nThe project web-page is available at https://simonelli-andrea.github.io/easy3d.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T09:49:51Z"}
{"aid":"http://arxiv.org/abs/2504.11037v1","title":"Statistical complexity as a probe of mass and phase structure in compact\n  objects","summary":"In this work, we present a comprehensive and systematic study of the\nstatistical complexity, originally introduced by L\\'opez-Ruiz, Mancini, and\nCalbet [Phys. Lett. A 209, 321-326 (1995)], across a broad range of compact\nstar models. We explore how complexity correlates not only with macroscopic\nobservables such as mass and radius, but also with the microscopic\ncharacteristics of the underlying equation of state. By incorporating both\nrealistic equations of state and analytical solutions to Einstein's field\nequations, we demonstrate that gravitational mass plays a dominant role in\ndetermining the behavior of complexity. Furthermore, we show that strong phase\ntransitions within the stellar interior, such as those hypothesized in hybrid\nstars, can manifest as distinct features in the complexity profile, offering a\npotential informational signature of such transitions. This work offers new\ninsights into the link between information theory and compact object physics,\nhighlighting complexity's potential as a diagnostic tool in astrophysics.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.HE,gr-qc,nucl-th,quant-ph","published":"2025-04-15T09:59:47Z"}
{"aid":"http://arxiv.org/abs/2504.11066v1","title":"Improving fingerprint presentation attack detection by an approach\n  integrated into the personal verification stage","summary":"Presentation Attack Detection (PAD) systems are usually designed\nindependently of the fingerprint verification system. While this can be\nacceptable for use cases where specific user templates are not predetermined,\nit represents a missed opportunity to enhance security in scenarios where\nintegrating PAD with the fingerprint verification system could significantly\nleverage users' templates, which are the real target of a potential\npresentation attack. This does not mean that a PAD should be specifically\ndesigned for such users; that would imply the availability of many enrolled\nusers' PAI and, consequently, complexity, time, and cost increase. On the\ncontrary, we propose to equip a basic PAD, designed according to the state of\nthe art, with an innovative add-on module called the Closeness Binary Code (CC)\nmodule. The term \"closeness\" refers to a peculiar property of the bona\nfide-related features: in an Euclidean feature space, genuine fingerprints tend\nto cluster in a specific pattern. First, samples from the same finger are close\nto each other, then samples from other fingers of the same user and finally,\nsamples from fingers of other users. This property is statistically verified in\nour previous publication, and further confirmed in this paper. It is\nindependent of the user population and the feature set class, which can be\nhandcrafted or deep network-based (embeddings). Therefore, the add-on can be\ndesigned without the need for the targeted user samples; moreover, it exploits\nher/his samples' \"closeness\" property during the verification stage. Extensive\nexperiments on benchmark datasets and state-of-the-art PAD methods confirm the\nbenefits of the proposed add-on, which can be easily coupled with the main PAD\nmodule integrated into the fingerprint verification system.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T11:01:06Z"}
{"aid":"http://arxiv.org/abs/2504.11067v1","title":"Morphing-based Compression for Data-centric ML Pipelines","summary":"Data-centric ML pipelines extend traditional machine learning (ML) pipelines\n-- of feature transformations and ML model training -- by outer loops for data\ncleaning, augmentation, and feature engineering to create high-quality input\ndata. Existing lossless matrix compression applies lightweight compression\nschemes to numeric matrices and performs linear algebra operations such as\nmatrix-vector multiplications directly on the compressed representation but\nstruggles to efficiently rediscover structural data redundancy. Compressed\noperations are effective at fitting data in available memory, reducing I/O\nacross the storage-memory-cache hierarchy, and improving instruction\nparallelism. The applied data cleaning, augmentation, and feature\ntransformations provide a rich source of information about data characteristics\nsuch as distinct items, column sparsity, and column correlations. In this\npaper, we introduce BWARE -- an extension of AWARE for workload-aware lossless\nmatrix compression -- that pushes compression through feature transformations\nand engineering to leverage information about structural transformations.\nBesides compressed feature transformations, we introduce a novel technique for\nlightweight morphing of a compressed representation into workload-optimized\ncompressed representations without decompression. BWARE shows substantial\nend-to-end runtime improvements, reducing the execution time for training\ndata-centric ML pipelines from days to hours.","main_category":"cs.DB","categories":"cs.DB,cs.DC,cs.LG","published":"2025-04-15T11:02:34Z"}
{"aid":"http://arxiv.org/abs/2504.11073v1","title":"FreeDOM: Online Dynamic Object Removal Framework for Static Map\n  Construction Based on Conservative Free Space Estimation","summary":"Online map construction is essential for autonomous robots to navigate in\nunknown environments. However, the presence of dynamic objects may introduce\nartifacts into the map, which can significantly degrade the performance of\nlocalization and path planning. To tackle this problem, a novel online dynamic\nobject removal framework for static map construction based on conservative free\nspace estimation (FreeDOM) is proposed, consisting of a scan-removal front-end\nand a map-refinement back-end. First, we propose a multi-resolution map\nstructure for fast computation and effective map representation. In the\nscan-removal front-end, we employ raycast enhancement to improve free space\nestimation and segment the LiDAR scan based on the estimated free space. In the\nmap-refinement back-end, we further eliminate residual dynamic objects in the\nmap by leveraging incremental free space information. As experimentally\nverified on SemanticKITTI, HeLiMOS, and indoor datasets with various sensors,\nour proposed framework overcomes the limitations of visibility-based methods\nand outperforms state-of-the-art methods with an average F1-score improvement\nof 9.7%.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-15T11:16:09Z"}
{"aid":"http://arxiv.org/abs/2504.11081v1","title":"DPS: Design Pattern Summarisation Using Code Features","summary":"Automatic summarisation has been used efficiently in recent years to condense\ntexts, conversations, audio, code, and various other artefacts. A range of\nmethods, from simple template-based summaries to complex machine learning\ntechniques -- and more recently, large language models -- have been employed to\ngenerate these summaries. Summarising software design patterns is important\nbecause it helps developers quickly understand and reuse complex design\nconcepts, thereby improving software maintainability and development\nefficiency. However, the generation of summaries for software design patterns\nhas not yet been explored. Our approach utilises code features and JavaParser\nto parse the code and create a JSON representation. Using an NLG library on\nthis JSON representation, we convert it into natural language text that acts as\na summary of the code, capturing the contextual information of the design\npattern. Our empirical results indicate that the summaries generated by our\napproach capture the context in which patterns are applied in the codebase.\nStatistical evaluations demonstrate that our summaries closely align with\nhuman-written summaries, as evident from high values in the ROUGE-L, BLEU-4,\nNIST, and FrugalScore metrics. A follow-up survey further shows that DPS\nsummaries were rated as capturing context better than human-generated\nsummaries.","main_category":"cs.SE","categories":"cs.SE,D.2","published":"2025-04-15T11:27:44Z"}
{"aid":"http://arxiv.org/abs/2504.11086v1","title":"Obtuse almost-equiangular sets","summary":"For $t \\in [-1, 1)$, a set of points on the $(n-1)$-dimensional unit sphere\nis called $t$-almost equiangular if among any three distinct points there is a\npair with inner product $t$. We propose a semidefinite programming upper bound\nfor the maximum cardinality $\\alpha(n, t)$ of such a set based on an extension\nof the Lov\\'asz theta number to hypergraphs. This bound is at least as good as\npreviously known bounds and for many values of $n$ and $t$ it is better.\n  We also refine existing spectral methods to show that $\\alpha(n, t) \\leq\n2(n+1)$ for all $n$ and $t \\leq 0$, with equality only at $t = -1/n$. This\nallows us to show the uniqueness of the optimal construction at $t = -1/n$ for\n$n \\leq 5$ and to enumerate all possible constructions for $n \\leq 3$ and $t\n\\leq 0$.","main_category":"math.CO","categories":"math.CO,math.MG,math.OC","published":"2025-04-15T11:32:46Z"}
{"aid":"http://arxiv.org/abs/2504.11088v1","title":"FLSSM: A Federated Learning Storage Security Model with Homomorphic\n  Encryption","summary":"Federated learning based on homomorphic encryption has received widespread\nattention due to its high security and enhanced protection of user data\nprivacy. However, the characteristics of encrypted computation lead to three\nchallenging problems: ``computation-efficiency\", ``attack-tracing\" and\n``contribution-assessment\". The first refers to the efficiency of encrypted\ncomputation during model aggregation, the second refers to tracing malicious\nattacks in an encrypted state, and the third refers to the fairness of\ncontribution assessment for local models after encryption. This paper proposes\na federated learning storage security model with homomorphic encryption (FLSSM)\nto protect federated learning model privacy and address the three issues\nmentioned above. First, we utilize different nodes to aggregate local models in\nparallel, thereby improving encrypted models' aggregation efficiency. Second,\nwe introduce trusted supervise nodes to examine local models when the global\nmodel is attacked, enabling the tracing of malicious attacks under homomorphic\nencryption. Finally, we fairly reward local training nodes with encrypted local\nmodels based on trusted training time. Experiments on multiple real-world\ndatasets show that our model significantly outperforms baseline models in terms\nof both efficiency and security metrics.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-15T11:33:14Z"}
{"aid":"http://arxiv.org/abs/2504.11110v1","title":"Helper-Friendly Latency-Bounded Mitigation Strategies against Reactive\n  Jamming Adversaries","summary":"Due to the recent developments in the field of full-duplex radios and\ncognitive radios, a new class of reactive jamming attacks has gained attention\nwherein an adversary transmits jamming energy over the victim's frequency band\nand also monitors various energy statistics in the network so as to detect\ncountermeasures, thereby trapping the victim. Although cooperative mitigation\nstrategies against such security threats exist, they are known to incur\nspectral-efficiency loss on the helper node, and are also not robust to\nvariable latency-constraints on victim's messages. Identifying these research\ngaps in existing countermeasures against reactive jamming attacks, we propose a\nfamily of helper-friendly cooperative mitigation strategies that are applicable\nfor a wide-range of latency-requirements on the victim's messages as well as\npractical radio hardware at the helper nodes. The proposed strategies are\ndesigned to facilitate reliable communication for the victim, without\ncompromising the helper's spectral efficiency and also minimally disturbing the\nvarious energy statistics in the network. For theoretical guarantees on their\nefficacy, interesting optimization problems are formulated on the choice of the\nunderlying parameters, followed by extensive mathematical analyses on their\nerror-performance and covertness. Experimental results indicate that the\nproposed strategies should be preferred over the state-of-the-art methods when\nthe helper node is unwilling to compromise on its error performance for\nassisting the victim.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-15T11:56:57Z"}
{"aid":"http://arxiv.org/abs/2504.11116v1","title":"Breaking the Dimensional Barrier: A Pontryagin-Guided Direct Policy\n  Optimization for Continuous-Time Multi-Asset Portfolio","summary":"Solving large-scale, continuous-time portfolio optimization problems\ninvolving numerous assets and state-dependent dynamics has long been challenged\nby the curse of dimensionality. Traditional dynamic programming and PDE-based\nmethods, while rigorous, typically become computationally intractable beyond a\nsmall number of state variables (often limited to ~3-6 in prior numerical\nstudies). To overcome this critical barrier, we introduce the\n\\emph{Pontryagin-Guided Direct Policy Optimization} (PG-DPO) framework. PG-DPO\nleverages Pontryagin's Maximum Principle to directly guide neural network\npolicies via backpropagation-through-time, naturally incorporating exogenous\nstate processes without requiring dense state grids. Crucially, our\ncomputationally efficient ``Two-Stage'' variant exploits rapidly stabilizing\ncostate estimates derived from BPTT, converting them into near-optimal\nclosed-form Pontryagin controls after only a short warm-up, significantly\nreducing training overhead. This enables a breakthrough in scalability:\nnumerical experiments demonstrate that PG-DPO successfully tackles problems\nwith dimensions previously considered far out of reach, optimizing portfolios\nwith up to 50 assets and 10 state variables. The framework delivers\nnear-optimal policies, offering a practical and powerful alternative for\nhigh-dimensional continuous-time portfolio choice.","main_category":"q-fin.PM","categories":"q-fin.PM,q-fin.CP","published":"2025-04-15T12:03:14Z"}
{"aid":"http://arxiv.org/abs/2504.11127v1","title":"Keplerian motion of a compact source orbiting the inner disk of PDS 70:\n  A third protoplanet in a resonance with b and c?","summary":"The disk around PDS 70 hosts two directly imaged protoplanets in a gap.\nPrevious VLT/SPHERE and recent James Webb Space Telescope/NIRCam observations\nhave hinted at the presence of a third compact source in the same gap at ~13\nau, interior to the orbit of PDS 70 b. We reduce seven published and one\nunpublished VLT/SPHERE datasets in YJH and K bands, as well as an archival\nVLT/NaCo dataset in L' band, and an archival VLT/SINFONI dataset in H+K band.\nWe combine angular-, spectral- and reference star differential imaging to\nsearch for protoplanet candidates. We recover the compact source in all epochs,\nconsistent with the JWST detection, moving on an arc that can be fit by\nKeplerian motion of a protoplanet which could be in a resonance with PDS 70 b &\nc. We find that the spectral slope is overall consistent with the unresolved\nstar and inner disk emission at 0.95--1.65$\\mu$m, which suggests a dust\nscattering dominated spectrum. An excess beyond 2.3$\\mu$m could be thermal\nemission from either a protoplanet or heated circumplanetary dust, variability,\nor inner disk contamination, and requires confirmation. While we currently\ncannot rule out a moving inner disk feature or a dust clump associated with an\nunseen planet, the data supports the hypothesis of a third protoplanet in this\nremarkable system.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-15T12:17:57Z"}
{"aid":"http://arxiv.org/abs/2504.11146v1","title":"Exploring Student Behaviors and Motivations using AI TAs with Optional\n  Guardrails","summary":"AI-powered chatbots and digital teaching assistants (AI TAs) are gaining\npopularity in programming education, offering students timely and personalized\nfeedback. Despite their potential benefits, concerns about student\nover-reliance and academic misconduct have prompted the introduction of\n\"guardrails\" into AI TAs - features that provide scaffolded support rather than\ndirect solutions. However, overly restrictive guardrails may lead students to\nbypass these tools and use unconstrained AI models, where interactions are not\nobservable, thus limiting our understanding of students' help-seeking\nbehaviors. To investigate this, we designed and deployed a novel AI TA tool\nwith optional guardrails in one lab of a large introductory programming course.\nAs students completed three code writing and debugging tasks, they had the\noption to receive guardrailed help or use a \"See Solution\" feature which\ndisabled the guardrails and generated a verbatim response from the underlying\nmodel. We investigate students' motivations and use of this feature and examine\nthe association between usage and their course performance. We found that 50%\nof the 885 students used the \"See Solution\" feature for at least one problem\nand 14% used it for all three problems. Additionally, low-performing students\nwere more likely to use this feature and use it close to the deadline as they\nstarted assignments later. The predominant factors that motivated students to\ndisable the guardrails were assistance in solving problems, time pressure, lack\nof self-regulation, and curiosity. Our work provides insights into students'\nsolution-seeking motivations and behaviors, which has implications for the\ndesign of AI TAs that balance pedagogical goals with student preferences.","main_category":"cs.HC","categories":"cs.HC,cs.CY","published":"2025-04-15T12:48:22Z"}
{"aid":"http://arxiv.org/abs/2504.11167v1","title":"Low-Rank SPIKE Framework for Solving Large Sparse Linear Systems with\n  Applications","summary":"The SPIKE family of linear system solvers provides parallelism using a block\ntridiagonal partitioning. Typically SPIKE-based solvers are applied to banded\nsystems, resulting in structured off-diagonal blocks with non-zeros elements\nrestricted to relatively small submatrices comprising the band of the original\nmatrix. In this work, a low-rank SVD based approximation of the off-diagonal\nblocks is investigated. This produces a representation which more effectively\nhandles matrices with large, sparse bands. A set of flexible distributed\nsolvers, the LR-SPIKE variants, are implemented. There are applicable to a wide\nrange of applications -- from use as a \"black-box\" preconditioner which\nstraightforwardly improves upon the classic Block Jacobi preconditioner, to use\nas a specialized \"approximate direct solver.\" An investigation of the\neffectiveness of the new preconditioners for a selection of SuiteSparse\nmatrices is performed, particularly focusing on matrices derived from 3D finite\nelement simulations. In addition, the SPIKE approximate linear system solvers\nare also paired with the FEAST eigenvalue solver, where they are shown to be\nparticularly effective due to the former's rapid convergence, and the latter's\nacceptance of loose linear system solver convergence, resulting in a\ncombination which requires very few solver iterations.","main_category":"math.NA","categories":"math.NA,cs.MS,cs.NA","published":"2025-04-15T13:15:00Z"}
{"aid":"http://arxiv.org/abs/2504.11170v1","title":"A Real-time Anomaly Detection Method for Robots based on a Flexible and\n  Sparse Latent Space","summary":"The growing demand for robots to operate effectively in diverse environments\nnecessitates the need for robust real-time anomaly detection techniques during\nrobotic operations. However, deep learning-based models in robotics face\nsignificant challenges due to limited training data and highly noisy signal\nfeatures. In this paper, we present Sparse Masked Autoregressive Flow-based\nAdversarial AutoEncoders model to address these problems. This approach\nintegrates Masked Autoregressive Flow model into Adversarial AutoEncoders to\nconstruct a flexible latent space and utilize Sparse autoencoder to efficiently\nfocus on important features, even in scenarios with limited feature space. Our\nexperiments demonstrate that the proposed model achieves a 4.96% to 9.75%\nhigher area under the receiver operating characteristic curve for\npick-and-place robotic operations with randomly placed cans, compared to\nexisting state-of-the-art methods. Notably, it showed up to 19.67% better\nperformance in scenarios involving collisions with lightweight objects.\nAdditionally, unlike the existing state-of-the-art model, our model performs\ninferences within 1 millisecond, ensuring real-time anomaly detection. These\ncapabilities make our model highly applicable to machine learning-based robotic\nsafety systems in dynamic environments. The code will be made publicly\navailable after acceptance.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-15T13:17:14Z"}
{"aid":"http://arxiv.org/abs/2504.11172v1","title":"TerraMesh: A Planetary Mosaic of Multimodal Earth Observation Data","summary":"Large-scale foundation models in Earth Observation can learn versatile,\nlabel-efficient representations by leveraging massive amounts of unlabeled\ndata. However, existing public datasets are often limited in scale, geographic\ncoverage, or sensor variety. We introduce TerraMesh, a new globally diverse,\nmultimodal dataset combining optical, synthetic aperture radar, elevation, and\nland-cover modalities in an Analysis-Ready Data format. TerraMesh includes over\n9 million samples with eight spatiotemporal aligned modalities, enabling\nlarge-scale pre-training and fostering robust cross-modal correlation learning.\nWe provide detailed data processing steps, comprehensive statistics, and\nempirical evidence demonstrating improved model performance when pre-trained on\nTerraMesh. The dataset will be made publicly available with a permissive\nlicense.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T13:20:35Z"}
{"aid":"http://arxiv.org/abs/2504.11205v1","title":"Can Quasi Periodic Oscillations Encode Traces of Black Hole Phase\n  Transitions ?","summary":"Finding observational evidence or imprints of black hole phase transitions is\na promising and active area of research. Aiming to contribute to this\ndirection, in this work, we probe the well-known thermodynamic phase structure\nof the Reissner Nordstr\\\"om Anti de Sitter (RN-AdS) black hole through the lens\nof its quasi-periodic oscillations (QPOs). Can QPOs be influenced by black hole\nphase transitions? Do they carry any signature of such transitions in their\nobservational patterns? These were the central questions guiding our study. By\nanalyzing the upper and lower QPO frequencies within the Relativistic\nPrecession (RP) model, we observe that the frequency-temperature relationship\nreflects distinguishing features corresponding to the small, intermediate, and\nlarge black hole phases, offering insights into their stability properties. The\nanalysis is further extended to other QPO models, including the Warped Disk\n(WD) and Epicyclic Resonance (ER) models. The presence of distinct phase\nstructures remains evident across all models which is an encouraging outcome\nthat may be worth exploring further in the context of other black hole systems.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-15T14:07:49Z"}
{"aid":"http://arxiv.org/abs/2504.11214v1","title":"Refractive Index Engineering: Insights from Biological Systems for\n  Advanced Optical Design","summary":"This review explores the innovative design to achieve advanced optical\nfunctions in natural materials and intricate optical systems inspired by the\nunique refractive index profiles found in nature. By understanding the physical\nprinciples behind biological structures, we can develop materials with tailored\noptical properties that mimic these natural systems. One key area discussed is\nbiomimetic materials design, where biological systems such as apple skin and\nthe vision system inspire new materials. Another focus is on intricate optical\nsystems based on refractive index contrast. These principles can be extended to\ndesign devices like waveguides, photonic crystals, and metamaterials, which\nmanipulate light in novel ways. Additionally, the review covers optical\nscattering engineering, which is crucial for biomedical imaging. By adjusting\nthe real and imaginary parts of the refractive index, we can control how much\nlight is scattered and absorbed by tissues. This is particularly important for\ntechniques like optical coherence tomography and multiphoton microscopy, where\ntailored scattering properties can improve imaging depth and resolution. The\nreview also discusses various techniques for measuring the refractive index of\nbiological tissues which provide comprehensive insights into the optical\nproperties of biological materials, facilitating the development of advanced\nbiomimetic designs. In conclusion, the manipulation of refractive index\nprofiles in biological systems offers exciting opportunities for technological\nadvancements. By drawing inspiration from nature and understanding the\nunderlying physical principles, we can create materials and devices with\nenhanced performance and new functionalities. Future research should focus on\nfurther exploring these principles and translating them into practical\napplications to address real-world challenges.","main_category":"physics.bio-ph","categories":"physics.bio-ph,physics.app-ph,physics.optics","published":"2025-04-15T14:15:46Z"}
{"aid":"http://arxiv.org/abs/2504.11236v1","title":"Influence of a Xenon interlayer on dissociative electron attachment to\n  deuterated methane on a platinum substrate","summary":"We investigate the impact of intercalating a xenon layer between a thin\ncondensed CD4 film of two monolayers (ML) and a platinum surface on the\ndissociative electron attachment (DEA). The observed desorption results are\ncompared with density functional theory (DFT) calculations, which reveal the\nbinding energies of various anionic and neutral species as a function of the\nxenon film thickness on the Pt (111) substrate. The theoretical results suggest\nthat 6 ML of xenon are sufficient to diminish the surface effect, enabling\nphysisorbed anionic fragments to desorb from the CD4 film. In contrast, 20 ML\n(approximately 10 nm) are experimentally necessary to achieve saturation in the\ndesorption of D-. In addition, the presence of xenon layers enables the\ncoupling of resonance states with Xe excited states, thereby inhibiting the\nelectrons from returning to the metal. Aside from reducing surface\ninteractions, the xenon interlayer significantly enhances DEA to CD4.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.chem-ph,physics.comp-ph","published":"2025-04-15T14:38:32Z"}
{"aid":"http://arxiv.org/abs/2504.11259v1","title":"The Cambridge Report on Database Research","summary":"On October 19 and 20, 2023, the authors of this report convened in Cambridge,\nMA, to discuss the state of the database research field, its recent\naccomplishments and ongoing challenges, and future directions for research and\ncommunity engagement. This gathering continues a long standing tradition in the\ndatabase community, dating back to the late 1980s, in which researchers meet\nroughly every five years to produce a forward looking report.\n  This report summarizes the key takeaways from our discussions. We begin with\na retrospective on the academic, open source, and commercial successes of the\ncommunity over the past five years. We then turn to future opportunities, with\na focus on core data systems, particularly in the context of cloud computing\nand emerging hardware, as well as on the growing impact of data science, data\ngovernance, and generative AI.\n  This document is not intended as an exhaustive survey of all technical\nchallenges or industry innovations in the field. Rather, it reflects the\nperspectives of senior community members on the most pressing challenges and\npromising opportunities ahead.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-15T14:57:46Z"}
{"aid":"http://arxiv.org/abs/2504.11262v1","title":"Enhanced Small Target Detection via Multi-Modal Fusion and Attention\n  Mechanisms: A YOLOv5 Approach","summary":"With the rapid development of information technology, modern warfare\nincreasingly relies on intelligence, making small target detection critical in\nmilitary applications. The growing demand for efficient, real-time detection\nhas created challenges in identifying small targets in complex environments due\nto interference. To address this, we propose a small target detection method\nbased on multi-modal image fusion and attention mechanisms. This method\nleverages YOLOv5, integrating infrared and visible light data along with a\nconvolutional attention module to enhance detection performance. The process\nbegins with multi-modal dataset registration using feature point matching,\nensuring accurate network training. By combining infrared and visible light\nfeatures with attention mechanisms, the model improves detection accuracy and\nrobustness. Experimental results on anti-UAV and Visdrone datasets demonstrate\nthe effectiveness and practicality of our approach, achieving superior\ndetection results for small and dim targets.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T15:02:10Z"}
{"aid":"http://arxiv.org/abs/2504.11283v1","title":"Influence of the magnetic activity cycle on mean density and acoustic\n  radius inversions","summary":"Asteroseismic modelling is crucial for upcoming missions like PLATO,\nCubeSpec, and Roman. Despite significant progress, discrepancies between\nobservations and theoretical predictions introduce biases in stellar\ncharacterisation at the precision required by PLATO. Current models typically\nignore magnetic activity, assuming its effects are hidden within surface\neffects. However, recent studies have shown significant impacts of magnetic\nactivity on the Sun's asteroseismic characterisation using forward modelling.\nUsing GOLF and BiSON observations of two full solar activity cycles, we\nquantified the impact of magnetic activity on solar mean density and acoustic\nradius inversions. Observations were segmented into yearly overlapping\nsnapshots, each offset by 91.25 days. Inversions were performed for each\nsnapshot to determine mean density and acoustic radius, tracking their temporal\nevolution and estimating systematic uncertainty due to magnetic activity. We\nobserved a clear imprint of the magnetic activity cycle on solar mean density\nand acoustic radius through helioseismic inversions, consistent across GOLF and\nBiSON datasets. This imprint is the largest source of systematic uncertainty in\nsolar asteroseismic characterisation. Including low radial-order modes\nmitigates these effects more significantly than previously measured for other\nstellar variables. We recommend asteroseismic values for solar mean density\n(1.4104 \\pm 0.0051 g/cm3) and acoustic radius (3722.0 \\pm 4.1 s), averaged over\ntwo activity cycles. These values account for major systematic errors,\nachieving high precision (0.36% for mean density and 0.11% for acoustic\nradius). These results are promising for high-precision characterisation of\nSun-like stars, a better-constrained mean density being able to enhance the\nprecision of stellar radius estimate, which is crucial for exoplanetary system\ncharacterisation.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP","published":"2025-04-15T15:22:51Z"}
{"aid":"http://arxiv.org/abs/2504.11299v1","title":"Efficient and Stable Multi-Dimensional Kolmogorov-Smirnov Distance","summary":"We revisit extending the Kolmogorov-Smirnov distance between probability\ndistributions to the multidimensional setting and make new arguments about the\nproper way to approach this generalization. Our proposed formulation maximizes\nthe difference over orthogonal dominating rectangular ranges (d-sided\nrectangles in R^d), and is an integral probability metric. We also prove that\nthe distance between a distribution and a sample from the distribution\nconverges to 0 as the sample size grows, and bound this rate. Moreover, we show\nthat one can, up to this same approximation error, compute the distance\nefficiently in 4 or fewer dimensions; specifically the runtime is near-linear\nin the size of the sample needed for that error. With this, we derive a\ndelta-precision two-sample hypothesis test using this distance. Finally, we\nshow these metric and approximation properties do not hold for other popular\nvariants.","main_category":"stat.CO","categories":"stat.CO,cs.CG,cs.LG","published":"2025-04-15T15:42:49Z"}
{"aid":"http://arxiv.org/abs/2504.11313v1","title":"A Composed Alternating Relaxed Projection Algorithm for Feasibility\n  Problem","summary":"Feasibility problem aims to find a common point of two or more closed\n(convex) sets whose intersection is nonempty. In the literature, projection\nbased algorithms are widely adopted to solve the problem, such as the method of\nalternating projection (MAP), and Douglas--Rachford splitting method (DR). The\nperformance of the methods are governed by the geometric properties of the\nunderlying sets. For example, the fixed-point sequence of the Douglas--Rachford\nsplitting method exhibits a spiraling behavior when solving the feasibility\nproblem of two subspaces, leading to a slow convergence speed and slower than\nMAP. However, when the problem at hand is non-polyhedral, DR can demonstrate\nsignificant faster performance. Motivated by the behaviors of the DR method, in\nthis paper we propose a new algorithm for solving convex feasibility problems.\nThe method is designed based on DR method by further incorporating a\ncomposition of projection and reflection. A non-stationary version of the\nmethod is also designed, aiming to achieve faster practical performance.\nTheoretical guarantees of the proposed schemes are provided and supported by\nnumerical experiments.","main_category":"math.OC","categories":"math.OC","published":"2025-04-15T15:53:10Z"}
{"aid":"http://arxiv.org/abs/2504.11315v1","title":"New Key Rate Bound for High-Dimensional BB84 with Multiple Basis\n  Measurements","summary":"In this paper we derive a new bound on the secret key-rate of the High\nDimensional BB84 protocol operating with multiple mutually unbiased bases\n(MUBs). To our knowledge, our proof is the first for this protocol that is both\ngeneral (in that it can handle arbitrary, asymmetric channels), and also the\nfirst that derives a bound on the quantum min entropy for general attacks,\nwithout relying on post selection techniques or the asymptotic equipartition\nproperty. Because of this, our new result shows that far more optimistic\nkey-rates are possible for a low number of signals, even in general channels.\nFurthermore, our proof methods may be broadly applicable to other protocols\nrelying on multiple measurement bases and we prove several technical lemmas\nthat may have independent interest. We evaluate our new bound and compare to\nprior work, showing that higher key-rates are possible in several operating\nscenarios. We also show some interesting behavior of the protocol when faced\nwith asymmetric noise.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T15:55:24Z"}
{"aid":"http://arxiv.org/abs/2504.11317v1","title":"The role of non-Markovian dissipation in quantum phase transitions:\n  tricriticality, spin squeezing, and directional symmetry breaking","summary":"Understanding how to control phase transitions in quantum systems is at the\nforefront of research for the development of new quantum materials and\ntechnologies. Here, we study how the coupling of a quantum system to a\nnon-Markovian environment, i.e., an environment with a frequency-dependent\nspectral density inducing memory effects, can be used to generate and reshape\nphase transitions and squeezing in matter phases. Focusing on a\nLipkin-Meshkov-Glick model, we demonstrate that non-Markovian dissipation can\nbe leveraged to engineer tricriticality via the fusion of\n$2^{\\mathrm{nd}}$-order and $1^{\\mathrm{st}}$-order critical points. We\nidentify phases that arise from different ways of breaking the single weak\nsymmetry of our model, which led us to introduce the concept of\n\\textit{directional spontaneous symmetry breaking} (DSSB) as a general\nframework to understand this phenomenon. We show that signatures of DSSB can be\nseen in the emergence of spin squeezing along different directions, and that\nthe latter is controllable via non-Markovian effects, opening up possibilities\nfor applications in quantum metrology. Finally, we propose an experimental\nimplementation of our non-Markovian model in cavity QED. Our work features\nnon-Markovianity as a resource for controlling phase transitions in general\nsystems, and highlights shortcomings of the Markovian limit in this context.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T15:58:15Z"}
{"aid":"http://arxiv.org/abs/2504.11318v1","title":"Mildly-Interacting Fermionic Unitaries are Efficiently Learnable","summary":"Recent work has shown that one can efficiently learn fermionic Gaussian\nunitaries, also commonly known as nearest-neighbor matchcircuits or\nnon-interacting fermionic unitaries. However, one could ask a similar question\nabout unitaries that are near Gaussian: for example, unitaries prepared with a\nsmall number of non-Gaussian circuit elements. These operators find\nsignificance in quantum chemistry and many-body physics, yet no algorithm\nexists to learn them.\n  We give the first such result by devising an algorithm which makes queries to\na $n$-mode fermionic unitary $U$ prepared by at most $O(t)$ non-Gaussian gates\nand returns a circuit approximating $U$ to diamond distance $\\varepsilon$ in\ntime $\\textrm{poly}(n,2^t,1/\\varepsilon)$. This resolves a central open\nquestion of Mele and Herasymenko under the strongest distance metric. In fact,\nour algorithm is much more general: we define a property of unitary Gaussianity\nknown as unitary Gaussian dimension and show that our algorithm can learn\n$n$-mode unitaries of Gaussian dimension at least $2n - O(t)$ in time\n$\\textrm{poly}(n,2^t,1/\\varepsilon)$. Indeed, this class subsumes unitaries\nprepared by at most $O(t)$ non-Gaussian gates but also includes several\nunitaries that require up to $2^{O(t)}$ non-Gaussian gates to construct.\n  In addition, we give a $\\textrm{poly}(n,1/\\varepsilon)$-time algorithm to\ndistinguish whether an $n$-mode unitary is of Gaussian dimension at least $k$\nor $\\varepsilon$-far from all such unitaries in Frobenius distance, promised\nthat one is the case. Along the way, we prove structural results about\nnear-Gaussian fermionic unitaries that are likely to be of independent\ninterest.","main_category":"quant-ph","categories":"quant-ph,cs.DS,cs.LG","published":"2025-04-15T15:59:32Z"}
{"aid":"http://arxiv.org/abs/2504.11323v1","title":"Domain wall evolution beyond quartic potentials: The Sine-Gordon and\n  Christ-Lee potentials","summary":"Domain walls are the simplest type of topological defects formed at\ncosmological phase transitions, and one of the most constrained. Their studies\ntypically assume a quartic double well potential, but this model is not fully\nrepresentative of the range of known or plausible particle physics models. Here\nwe study the cosmological evolution of domain walls in two other classes of\npotentials. The Sine-Gordon potential allows several types of walls,\ninterpolating between different pairs of minima (which demands specific\nnumerical algorithms to separately measure the relevant properties of each\ntype). The Christ-Lee potential parametrically interpolates between sextic and\nquartic behavior. We use multiple sets of simulations in two and three spatial\ndimensions, for various cosmological epochs and under various choices of\ninitial conditions, to discuss the scaling properties of these networks. In the\nSine-Gordon case, we identify and quantify deviations from the usual scaling\nbehavior. In the Christ-Lee case, we discuss conditions under which walls form\n(or not), and quantify how these outcomes depend on parameters such as the\nenergy difference between the false and true vacua and the expansion rate of\nthe Universe. Various biased initial conditions are also addressed in\nappendices. Finally, we briefly comment on the possible cosmological\nimplications of our results.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO","published":"2025-04-15T16:02:35Z"}
{"aid":"http://arxiv.org/abs/2504.11338v1","title":"Transformer-Based Model for Cold Start Mitigation in FaaS Architecture","summary":"Serverless architectures, particularly the Function as a Service (FaaS)\nmodel, have become a cornerstone of modern cloud computing due to their ability\nto simplify resource management and enhance application deployment agility.\nHowever, a significant challenge remains: the cold start problem. This\nphenomenon occurs when an idle FaaS function is invoked, requiring a full\ninitialization process, which increases latency and degrades user experience.\nExisting solutions for cold start mitigation are limited in terms of invocation\npattern generalization and implementation complexity. In this study, we propose\nan innovative approach leveraging Transformer models to mitigate the impact of\ncold starts in FaaS architectures. Our solution excels in accurately modeling\nfunction initialization delays and optimizing serverless system performance.\nExperimental evaluation using a public dataset provided by Azure demonstrates a\nsignificant reduction in cold start times, reaching up to 79\\% compared to\nconventional methods.","main_category":"cs.DC","categories":"cs.DC,cs.AI","published":"2025-04-15T16:12:07Z"}
{"aid":"http://arxiv.org/abs/2504.11354v1","title":"Kimina-Prover Preview: Towards Large Formal Reasoning Models with\n  Reinforcement Learning","summary":"We introduce Kimina-Prover Preview, a large language model that pioneers a\nnovel reasoning-driven exploration paradigm for formal theorem proving, as\nshowcased in this preview release. Trained with a large-scale reinforcement\nlearning pipeline from Qwen2.5-72B, Kimina-Prover demonstrates strong\nperformance in Lean 4 proof generation by employing a structured reasoning\npattern we term \\textit{formal reasoning pattern}. This approach allows the\nmodel to emulate human problem-solving strategies in Lean, iteratively\ngenerating and refining proof steps. Kimina-Prover sets a new state-of-the-art\non the miniF2F benchmark, reaching 80.7% with pass@8192. Beyond improved\nbenchmark performance, our work yields several key insights: (1) Kimina-Prover\nexhibits high sample efficiency, delivering strong results even with minimal\nsampling (pass@1) and scaling effectively with computational budget, stemming\nfrom its unique reasoning pattern and RL training; (2) we demonstrate clear\nperformance scaling with model size, a trend previously unobserved for neural\ntheorem provers in formal mathematics; (3) the learned reasoning style,\ndistinct from traditional search algorithms, shows potential to bridge the gap\nbetween formal verification and informal mathematical intuition. We open source\ndistilled versions with 1.5B and 7B parameters of Kimina-Prover","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-15T16:23:44Z"}
{"aid":"http://arxiv.org/abs/2504.11357v1","title":"NNLO predictions with nonlocal subtractions and fiducial power\n  corrections in GENEVA","summary":"We present the implementation of next-to-next-to-leading order (NNLO) QCD\nfully-differential corrections within the GENEVA framework, for both\ncolour-singlet and colour-singlet+jet processes at hadron colliders, by\nemploying a nonlocal subtraction approach. In particular, we discuss the\nimplementation details and the challenges that arise when utilizing a dynamical\ninfrared cutoff parameter. Additionally, we combine the subtraction with the\nprojection-to-Born method in order to include fiducial power corrections. As a\ntest case, we provide predictions for Drell-Yan and $Z$+jet production at the\nLHC, using $N$-jettiness as resolution variable. We validate the NNLO\ncorrections of GENEVA against NNLOJET finding excellent agreement. Finally, we\ndiscuss how to extend our method to calculate the N$^3$LO QCD\nfully-differential corrections to colour-singlet production at hadron\ncolliders.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-15T16:26:01Z"}
{"aid":"http://arxiv.org/abs/2504.11367v1","title":"Network Alignment","summary":"Complex networks are frequently employed to model physical or virtual complex\nsystems. When certain entities exist across multiple systems simultaneously,\nunveiling their corresponding relationships across the networks becomes\ncrucial. This problem, known as network alignment, holds significant\nimportance. It enhances our understanding of complex system structures and\nbehaviours, facilitates the validation and extension of theoretical physics\nresearch about studying complex systems, and fosters diverse practical\napplications across various fields. However, due to variations in the\nstructure, characteristics, and properties of complex networks across different\nfields, the study of network alignment is often isolated within each domain,\nwith even the terminologies and concepts lacking uniformity. This review\ncomprehensively summarizes the latest advancements in network alignment\nresearch, focusing on analyzing network alignment characteristics and progress\nin various domains such as social network analysis, bioinformatics,\ncomputational linguistics and privacy protection. It provides a detailed\nanalysis of various methods' implementation principles, processes, and\nperformance differences, including structure consistency-based methods, network\nembedding-based methods, and graph neural network-based (GNN-based) methods.\nAdditionally, the methods for network alignment under different conditions,\nsuch as in attributed networks, heterogeneous networks, directed networks, and\ndynamic networks, are presented. Furthermore, the challenges and the open\nissues for future studies are also discussed.","main_category":"physics.soc-ph","categories":"physics.soc-ph,cs.CL","published":"2025-04-15T16:32:09Z"}
{"aid":"http://arxiv.org/abs/2504.11374v1","title":"A Winner-Takes-All Mechanism for Event Generation","summary":"We present a novel framework for central pattern generator design that\nleverages the intrinsic rebound excitability of neurons in combination with\nwinner-takes-all computation. Our approach unifies decision-making and rhythmic\npattern generation within a simple yet powerful network architecture that\nemploys all-to-all inhibitory connections enhanced by designable excitatory\ninteractions. This design offers significant advantages regarding ease of\nimplementation, adaptability, and robustness. We demonstrate its efficacy\nthrough a ring oscillator model, which exhibits adaptive phase and frequency\nmodulation, making the framework particularly promising for applications in\nneuromorphic systems and robotics.","main_category":"eess.SY","categories":"eess.SY,cs.AI,cs.SY","published":"2025-04-15T16:40:37Z"}
{"aid":"http://arxiv.org/abs/2504.11413v1","title":"Solving the Phase Problem of Diffraction: X-ray Standing Waves Imaging\n  on Bismuthene/SiC(0001)","summary":"The phase retrieval problem is a fundamental shortcoming of all\ndiffraction-based methods, arising from the inability to measure the phase of\nscattered waves. The (normal incidence) X-ray standing wave (NIXSW) technique\ncircumvents this issue by introducing a (Bragg-generated) X-ray standing wave\nfield throughout the sample, relative to which any atomic species can be\nlocalized by probing its fluorescence or photoelectron yield. In essence, in a\nsingle measurement the complex scattering factor (i.e., its amplitude\n\\textit{and} phase) corresponding to the used Bragg reflection is determined.\nPerforming this for multiple Bragg reflections enables one to reconstruct the\nscattering density of the sample in three dimensions, straightforwardly as the\nFourier sum of all measured (complex) scattering factors. Here, we utilize this\ntechnique to reveal the structural key features involved in the formation of\nthe quantum spin Hall insulator bismuthene on silicon carbide. In this\nprominent example, the two-dimensional Bi layer is confined between a 4H-SiC\nsubstrate crystal and an epitaxial graphene layer. The key finding is a change\nin the adsorption site of the Bi atoms underneath the graphene upon\nhydrogenation, caused by the H-saturation of one (out of three) Si dangling\nbonds per unit cell. This structural change, clearly revealed by our NIXSW\nimaging experiment, is the key feature leading to the formation of the\ncharacteristic band structure of the 2D bismuthene honeycomb.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-15T17:28:24Z"}
{"aid":"http://arxiv.org/abs/2504.11418v1","title":"Leveraging Point Transformers for Detecting Anatomical Landmarks in\n  Digital Dentistry","summary":"The increasing availability of intraoral scanning devices has heightened\ntheir importance in modern clinical orthodontics. Clinicians utilize advanced\nComputer-Aided Design techniques to create patient-specific treatment plans\nthat include laboriously identifying crucial landmarks such as cusps,\nmesial-distal locations, facial axis points, and tooth-gingiva boundaries.\nDetecting such landmarks automatically presents challenges, including limited\ndataset sizes, significant anatomical variability among subjects, and the\ngeometric nature of the data. We present our experiments from the 3DTeethLand\nGrand Challenge at MICCAI 2024. Our method leverages recent advancements in\npoint cloud learning through transformer architectures. We designed a Point\nTransformer v3 inspired module to capture meaningful geometric and anatomical\nfeatures, which are processed by a lightweight decoder to predict per-point\ndistances, further processed by graph-based non-minima suppression. We report\npromising results and discuss insights on learned feature interpretability.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T17:34:56Z"}
{"aid":"http://arxiv.org/abs/2504.11423v1","title":"ADT: Tuning Diffusion Models with Adversarial Supervision","summary":"Diffusion models have achieved outstanding image generation by reversing a\nforward noising process to approximate true data distributions. During\ntraining, these models predict diffusion scores from noised versions of true\nsamples in a single forward pass, while inference requires iterative denoising\nstarting from white noise. This training-inference divergences hinder the\nalignment between inference and training data distributions, due to potential\nprediction biases and cumulative error accumulation. To address this problem,\nwe propose an intuitive but effective fine-tuning framework, called Adversarial\nDiffusion Tuning (ADT), by stimulating the inference process during\noptimization and aligning the final outputs with training data by adversarial\nsupervision. Specifically, to achieve robust adversarial training, ADT features\na siamese-network discriminator with a fixed pre-trained backbone and\nlightweight trainable parameters, incorporates an image-to-image sampling\nstrategy to smooth discriminative difficulties, and preserves the original\ndiffusion loss to prevent discriminator hacking. In addition, we carefully\nconstrain the backward-flowing path for back-propagating gradients along the\ninference path without incurring memory overload or gradient explosion.\nFinally, extensive experiments on Stable Diffusion models (v1.5, XL, and v3),\ndemonstrate that ADT significantly improves both distribution alignment and\nimage quality.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T17:37:50Z"}
{"aid":"http://arxiv.org/abs/2504.11429v1","title":"Improving Statistical Privacy by Subsampling","summary":"Differential privacy (DP) considers a scenario, where an adversary has almost\ncomplete information about the entries of a database This worst-case assumption\nis likely to overestimate the privacy thread for an individual in real life.\nStatistical privacy (SP) denotes a setting where only the distribution of the\ndatabase entries is known to an adversary, but not their exact values. In this\ncase one has to analyze the interaction between noiseless privacy based on the\nentropy of distributions and privacy mechanisms that distort the answers of\nqueries, which can be quite complex.\n  A privacy mechanism often used is to take samples of the data for answering a\nquery. This paper proves precise bounds how much different methods of sampling\nincrease privacy in the statistical setting with respect to database size and\nsampling rate. They allow us to deduce when and how much sampling provides an\nimprovement and how far this depends on the privacy parameter {\\epsilon}. To\nperform these investigations we develop a framework to model sampling\ntechniques.\n  For the DP setting tradeoff functions have been proposed as a finer measure\nfor privacy compared to ({\\epsilon},{\\delta})-pairs. We apply these tools to\nstatistical privacy with subsampling to get a comparable characterization","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-15T17:40:45Z"}
{"aid":"http://arxiv.org/abs/2504.11437v1","title":"Ghostly interactions in (1+1) dimensional classical field theory","summary":"We investigate the classical stability of two coupled scalar fields with\nopposite-sign kinetic terms evolving in 1+1 dimensional Minkowski spacetime. In\nthe first part, we characterise unquenched ghostly interactions and present\nnumerical solutions that support the following statements. First, the classical\ninstability is not instantaneous and can even be benign, i.e., free of\nfinite-time singularities. Second, while the classical instability can cascade\ntowards higher frequency excitations, it is not driven by high frequency modes:\nAt fixed amplitude, high-frequency modes are more stable than low-frequency\nmodes. In the second part, we demonstrate that the classical instability can be\nquenched by mass terms. In particular, we exemplify that heavy high-frequency\nghost fields seem to not violate the decoupling theorem and can be integrated\nout classically. In the third part, we demonstrate how self-interactions can\nquench the instability, for instance, by postponing its onset to parametrically\nlarge times. Extrapolating numerical results at large but finite evolution time\nto infinite evolution time, we demonstrate that classical fluctuations around\ntrivial and nontrivial field-theory vacua are increasingly long-lived with (i)\nsmaller initial amplitude of fluctuations, (ii) higher initial frequency of\nfluctuations, (iii) larger masses of the fields, or (iv) weaker interaction\ncoupling. Moreover, our numerical simulations for field-theoretical\ngeneralisations of some globally-stable ghostly mechanical models do not\nfeature any instability.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-15T17:53:00Z"}
{"aid":"http://arxiv.org/abs/2504.11449v1","title":"SymTFT construction of gapless exotic-foliated dual models","summary":"We construct Symmetry Topological Field Theories (SymTFTs) for continuous\nsubsystem symmetries, which are inherently non-Lorentz-invariant. Our framework\nproduces dual bulk descriptions -- gapped foliated and exotic SymTFTs -- that\ngenerates gapless boundary theories with spontaneous subsystem symmetry\nbreaking via interval compactification. In analogy with the sandwich\nconstruction of SymTFT, we call this Mille-feuille. This is done by specifying\ngapped and symmetry-breaking boundary conditions. In this way we obtain the\nfoliated dual realizations of various models, including the XY plaquette, XYZ\ncube, and $\\phi$, $\\hat{\\phi}$ theories. This also captures self-duality\nsymmetries as condensation defects and provides a systematic method for\ngenerating free theories that non-linearly realize subsystem symmetries.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,hep-th","published":"2025-04-15T17:57:58Z"}
{"aid":"http://arxiv.org/abs/2504.11768v1","title":"Representability theorems via metric techniques","summary":"We prove new Brown representability theorems for triangulated categories\nusing metric techniques as introduced in the work of Neeman. In the setting of\nalgebraic geometry, this gives us new representability theorems for homological\nand cohomological functors on the bounded derived category of coherent sheaves.\nTo prove this result, we introduce a generalisation of the notion of an\napproximable triangulated category.","main_category":"math.AG","categories":"math.AG,math.CT","published":"2025-04-16T05:11:38Z"}
{"aid":"http://arxiv.org/abs/2504.11775v1","title":"Discrimination-free Insurance Pricing with Privatized Sensitive\n  Attributes","summary":"Fairness has emerged as a critical consideration in the landscape of machine\nlearning algorithms, particularly as AI continues to transform decision-making\nacross societal domains. To ensure that these algorithms are free from bias and\ndo not discriminate against individuals based on sensitive attributes such as\ngender and race, the field of algorithmic bias has introduced various fairness\nconcepts, along with methodologies to achieve these notions in different\ncontexts. Despite the rapid advancement, not all sectors have embraced these\nfairness principles to the same extent. One specific sector that merits\nattention in this regard is insurance. Within the realm of insurance pricing,\nfairness is defined through a distinct and specialized framework. Consequently,\nachieving fairness according to established notions does not automatically\nensure fair pricing in insurance. In particular, regulators are increasingly\nemphasizing transparency in pricing algorithms and imposing constraints on\ninsurance companies on the collection and utilization of sensitive consumer\nattributes. These factors present additional challenges in the implementation\nof fairness in pricing algorithms. To address these complexities and comply\nwith regulatory demands, we propose an efficient method for constructing fair\nmodels that are tailored to the insurance domain, using only privatized\nsensitive attributes. Notably, our approach ensures statistical guarantees,\ndoes not require direct access to sensitive attributes, and adapts to varying\ntransparency requirements, addressing regulatory demands while ensuring\nfairness in insurance pricing.","main_category":"stat.ML","categories":"stat.ML,cs.CY,cs.LG,q-fin.RM","published":"2025-04-16T05:29:11Z"}
{"aid":"http://arxiv.org/abs/2504.11784v1","title":"DALC: Distributed Arithmetic Coding Aided by Linear Codes","summary":"Distributed Arithmetic Coding (DAC) has emerged as a feasible solution to the\nSlepian-Wolf problem, particularly in scenarios with non-stationary sources and\nfor data sequences with lengths ranging from small to medium. Due to the\ninherent decoding ambiguity in DAC, the number of candidate paths grows\nexponentially with the increase in source length. To select the correct\ndecoding path from the set of candidates, DAC decoders utilize the Maximum A\nPosteriori (MAP) metric to rank the decoding sequences, outputting the path\nwith the highest MAP metric as the decoding result of the decoder. However,\nthis method may still inadvertently output incorrect paths that have a MAP\nmetric higher than the correct decoding path, despite not being the correct\ndecoding path. To address the issue, we propose Distributed Arithmetic Coding\nAided by Linear Codes (DALC), which employs linear codes to constrain the\ndecoding process, thereby eliminating some incorrect paths and preserving the\ncorrect one. During the encoding phase, DALC generates the parity bits of the\nlinear code for encoding the source data. In the decoding phase, each path in\nthe set of candidate paths is verified in descending order according to the MAP\nmetric until a path that meets the verification criteria is encountered, which\nis then outputted as the decoding result. DALC enhances the decoding\nperformance of DAC by excluding candidate paths that do not meet the\nconstraints imposed by linear codes. Our experimental results demonstrate that\nDALC reduces the Bit Error Rate(BER), with especially improvements in skewed\nsource data scenarios.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-16T05:36:52Z"}
{"aid":"http://arxiv.org/abs/2504.11785v1","title":"Ground state and multiple normalized solutions of quasilinear\n  Schrödinger equations in the $L^2$-supercritical case and the Sobolev\n  critical case","summary":"This paper is devoted to studying the existence of normalized solutions for\nthe following quasilinear Schr\\\"odinger equation \\begin{equation*}\n\\begin{aligned}\n  -\\Delta u-u\\Delta u^2 +\\lambda u=|u|^{p-2}u \\quad\\mathrm{in}\\ \\mathbb{R}^{N},\n\\end{aligned} \\end{equation*} where $N=3,4$, $\\lambda$ appears as a Lagrange\nmultiplier and $p \\in (4+\\frac{4}{N},2\\cdot2^*]$. The solutions correspond to\ncritical points of the energy functional subject to the $L^2$-norm constraint\n$\\int_{\\mathbb{R}^N}|u|^2dx=a^2>0$. In the Sobolev critical case $p=2\\cdot\n2^*$, the energy functional has no critical point. As for $L^2$-supercritical\ncase $p \\in (4+\\frac{4}{N},2\\cdot2^*)$: on the one hand, taking into account\nPohozaev manifold and perturbation method, we obtain the existence of ground\nstate normalized solutions for the non-radial case; on the other hand, we get\nthe existence of infinitely many normalized solutions in $H^1_r(\\mathbb{R}^N)$.\nMoreover, our results cover several relevant existing results. And in the end,\nwe get the asymptotic properties of energy as $a$ tends to $+\\infty$ and $a$\ntends to $0^+$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-16T05:37:28Z"}
{"aid":"http://arxiv.org/abs/2504.11790v1","title":"Virtual VNA 3.1: Non-Coherent-Detection-Based Non-Reciprocal Scattering\n  Matrix Estimation Leveraging a Tunable Load Network","summary":"We refine the recently introduced \"Virtual VNA 3.0\" technique to remove the\nneed for coherent detection. The resulting \"Virtual VNA 3.1\" technique can\nunambiguously estimate the full scattering matrix of a non-reciprocal, linear,\npassive, time-invariant device under test (DUT) with $N$ monomodal ports using\nan $N_\\mathrm{A}$-channel coherent wavefront generator and an\n$N_\\mathrm{A}$-channel non-coherent detector, where $N_\\mathrm{A}<N$. Waves are\ninjected and received only via a fixed set of $N_\\mathrm{A}$ \"accessible\" DUT\nports while the remaining $N_\\mathrm{S}$ \"not-directly-accessible\" DUT ports\nare terminated by a specific tunable load network. To resolve all ambiguities,\nan additional modified setup is required in which waves are injected and\nreceived via a known $2N_\\mathrm{A}$-port system connected to the DUT's\naccessible ports. We experimentally validate our method for\n$N_\\mathrm{A}=N_\\mathrm{S}=4$ considering a non-reciprocal eight-port circuit\nas DUT. By eliminating the need for coherent detection, our work reduces the\nhardware complexity which may facilitate applications to large-scale or\nhigher-frequency systems. Additionally, our work provides fundamental insights\ninto the minimal requirements to fully and unambiguously characterize a\nnon-reciprocal DUT.","main_category":"physics.app-ph","categories":"physics.app-ph,eess.SP","published":"2025-04-16T05:42:51Z"}
{"aid":"http://arxiv.org/abs/2504.11792v1","title":"Large Language Models for Drug Overdose Prediction from Longitudinal\n  Medical Records","summary":"The ability to predict drug overdose risk from a patient's medical records is\ncrucial for timely intervention and prevention. Traditional machine learning\nmodels have shown promise in analyzing longitudinal medical records for this\ntask. However, recent advancements in large language models (LLMs) offer an\nopportunity to enhance prediction performance by leveraging their ability to\nprocess long textual data and their inherent prior knowledge across diverse\ntasks. In this study, we assess the effectiveness of Open AI's GPT-4o LLM in\npredicting drug overdose events using patients' longitudinal insurance claims\nrecords. We evaluate its performance in both fine-tuned and zero-shot settings,\ncomparing them to strong traditional machine learning methods as baselines. Our\nresults show that LLMs not only outperform traditional models in certain\nsettings but can also predict overdose risk in a zero-shot setting without\ntask-specific training. These findings highlight the potential of LLMs in\nclinical decision support, particularly for drug overdose risk prediction.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-16T05:52:22Z"}
{"aid":"http://arxiv.org/abs/2504.11802v1","title":"On the photon energy conservation in stimulated emission. Experiment","summary":"Quantum electrodynamics predicts identity of incident and emitted photons in\nstimulated emission. This fundamental law is important to test experimentally.\nIn this work stimulated emission in GaAs semiconductor amplifier was\ninvestigated and positive frequency shift of the amplified beam was detected.\nIn relative units this frequency shift was found equal $\\Delta\\nu/\\nu = (+1.7\n\\pm 0.2)\\cdot10^{-18}$. This indicates violation of the photon energy\nconservation in stimulated emission.","main_category":"physics.atom-ph","categories":"physics.atom-ph,quant-ph","published":"2025-04-16T06:17:28Z"}
{"aid":"http://arxiv.org/abs/2504.11815v1","title":"On projection mappings and the gradient projection method on hyperbolic\n  space forms","summary":"This paper presents several new properties of the intrinsic\n$\\kappa$-projection into $\\kappa$-hyperbolically convex sets of\n$\\kappa$-hyperbolic space forms, along with closed-form formulas for the\nintrinsic $\\kappa$-projection into specific $\\kappa$-hyperbolically convex\nsets. It also discusses the relationship between the intrinsic\n$\\kappa$-projection, the Euclidean orthogonal projection, and the Lorentz\nprojection. These properties lay the groundwork for analyzing the gradient\nprojection method and hold importance in their own right. Additionally, new\nproperties of the gradient projection method to solve constrained optimization\nproblems in $\\kappa$-hyperbolic space forms are established, considering both\nconstant and backtracking step sizes in the analysis. It is shown that every\naccumulation point of the sequence generated by the method for both step sizes\nis a stationary point for the given problem. Additionally, an iteration\ncomplexity bound is provided that upper bounds the number of iterations needed\nto achieve a suitable measure of stationarity for both step sizes. Finally, the\nproperties of the constrained Fermat-Weber problem are explored, demonstrating\nthat the sequence generated by the gradient projection method converges to its\nunique solution. Numerical experiments on solving the Fermat-Weber problem are\npresented, illustrating the theoretical findings and demonstrating the\neffectiveness of the proposed methods.","main_category":"math.OC","categories":"math.OC,cs.NA,math.DG,math.NA","published":"2025-04-16T07:01:00Z"}
{"aid":"http://arxiv.org/abs/2504.11823v1","title":"Multi-goal Rapidly Exploring Random Tree with Safety and Dynamic\n  Constraints for UAV Cooperative Path Planning","summary":"Cooperative path planning is gaining its importance due to the increasing\ndemand on using multiple unmanned aerial vehicles (UAVs) for complex missions.\nThis work addresses the problem by introducing a new algorithm named MultiRRT\nthat extends the rapidly exploring random tree (RRT) to generate paths for a\ngroup of UAVs to reach multiple goal locations at the same time. We first\nderive the dynamics constraint of the UAV and include it in the problem\nformulation. MultiRRT is then developed, taking into account the cooperative\nrequirements and safe constraints during its path-searching process. The\nalgorithm features two new mechanisms, node reduction and Bezier interpolation,\nto ensure the feasibility and optimality of the paths generated. Importantly,\nthe interpolated paths are proven to meet the safety and dynamics constraints\nimposed by obstacles and the UAVs. A number of simulations, comparisons, and\nexperiments have been conducted to evaluate the performance of the proposed\napproach. The results show that MultiRRT can generate collision-free paths for\nmultiple UAVs to reach their goals with better scores in path length and\nsmoothness metrics than state-of-the-art RRT variants including Theta-RRT,\nFN-RRT, RRT*, and RRT*-Smart. The generated paths are also tested in practical\nflights with real UAVs to evaluate their validity for cooperative tasks. The\nsource code of the algorithm is available at\nhttps://github.com/duynamrcv/multi-target_RRT","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-16T07:16:35Z"}
{"aid":"http://arxiv.org/abs/2504.11834v1","title":"Estimation and inference in error-in-operator model","summary":"Many statistical problems can be reduced to a linear inverse problem in which\nonly a noisy version of the operator is available. Particular examples include\nrandom design regression, deconvolution problem, instrumental variable\nregression, functional data analysis, error-in-variable regression, drift\nestimation in stochastic diffusion, and many others. The pragmatic plug-in\napproach can be well justified in the classical asymptotic setup with a growing\nsample size. However, recent developments in high dimensional inference reveal\nsome new features of this problem. In high dimensional linear regression with a\nrandom design, the plug-in approach is questionable but the use of a simple\nridge penalization yields a benign overfitting phenomenon; see\n\\cite{baLoLu2020}, \\cite{ChMo2022}, \\cite{NoPuSp2024}. This paper revisits the\ngeneral Error-in-Operator problem for finite samples and high dimension of the\nsource and image spaces. A particular focus is on the choice of a proper\nregularization. We show that a simple ridge penalty (Tikhonov regularization)\nworks properly in the case when the operator is more regular than the signal.\nIn the opposite case, some model reduction technique like spectral truncation\nshould be applied.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-16T07:45:44Z"}
{"aid":"http://arxiv.org/abs/2504.11859v1","title":"Meta Theorem for Hardness on FCP-Problem","summary":"The Fewest Clues Problem (FCP) framework has been introduced to study the\ncomplexity of determining whether a solution to an \\NP~problem can be uniquely\nidentified by specifying a subset of the certificate. For a given problem $P\n\\in \\NP$, its FCP variant is denoted by FCP-$P$. While several \\NP-complete\nproblems have been shown to have $\\Sigma_2^\\p$-complete FCP variants, it\nremains open whether this holds for all \\NP-complete problems.\n  In this work, we propose a meta-theorem that establishes the\n$\\Sigma_2^\\p$-completeness of FCP-$P$ under the condition that the \\NP-hardness\nof $P$ is proven via a polynomial-time reduction satisfying certain structural\nproperties. Furthermore, we apply the meta-theorem to demonstrate the\n$\\Sigma_2^\\p$-completeness of the FCP variants of several \\NP-complete\nproblems.","main_category":"cs.CC","categories":"cs.CC,F.1.3","published":"2025-04-16T08:30:34Z"}
{"aid":"http://arxiv.org/abs/2504.11867v1","title":"MDHP-Net: Detecting an Emerging Time-exciting Threat in IVN","summary":"The integration of intelligent and connected technologies in modern vehicles,\nwhile offering enhanced functionalities through Electronic Control Unit (ECU)\nand interfaces like OBD-II and telematics, also exposes the vehicle's\nin-vehicle network (IVN) to potential cyberattacks. Unlike prior work, we\nidentify a new time-exciting threat model against IVN. These attacks inject\nmalicious messages that exhibit a time-exciting effect, gradually manipulating\nnetwork traffic to disrupt vehicle operations and compromise safety-critical\nfunctions. We systematically analyze the characteristics of the threat:\ndynamism, time-exciting impact, and low prior knowledge dependency. To validate\nits practicality, we replicate the attack on a real Advanced Driver Assistance\nSystem via Controller Area Network (CAN), exploiting Unified Diagnostic Service\nvulnerabilities and proposing four attack strategies. While CAN's integrity\nchecks mitigate attacks, Ethernet migration (e.g., DoIP/SOME/IP) introduces new\nsurfaces. We further investigate the feasibility of time-exciting threat under\nSOME/IP. To detect time-exciting threat, we introduce MDHP-Net, leveraging\nMulti-Dimentional Hawkes Process (MDHP) and temporal and message-wise feature\nextracting structures. Meanwhile, to estimate MDHP parameters, we developed the\nfirst GPU-optimized gradient descent solver for MDHP (MDHP-GDS). These modules\nsignificantly improves the detection rate under time-exciting attacks in\nmulti-ECU IVN system. To address data scarcity, we release STEIA9, the first\nopen-source dataset for time-exciting attacks, covering 9 Ethernet-based attack\nscenarios. Extensive experiments on STEIA9 (9 attack scenarios) show MDHP-Net\noutperforms 3 baselines, confirming attack feasibility and detection efficacy.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-16T08:41:24Z"}
{"aid":"http://arxiv.org/abs/2504.11882v1","title":"Seeking and leveraging alternative variable dependency concepts in\n  gray-box-elusive bimodal land-use allocation problems","summary":"Solving land-use allocation problems can help us to deal with some of the\nmost urgent global environmental issues. Since these problems are NP-hard,\neffective optimizers are needed to handle them. The knowledge about variable\ndependencies allows for proposing such tools. However, in this work, we\nconsider a real-world multi-objective problem for which standard variable\ndependency discovery techniques are inapplicable. Therefore, using\nlinkage-based variation operators is unreachable. To address this issue, we\npropose a definition of problem-dedicated variable dependency. On this base, we\npropose obtaining masks of dependent variables. Using them, we construct three\nnovel crossover operators. The results concerning real-world test cases show\nthat introducing our propositions into two well-known optimizers (NSGA-II,\nMOEA/D) dedicated to multi-objective optimization significantly improves their\neffectiveness.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-16T09:06:55Z"}
{"aid":"http://arxiv.org/abs/2504.11904v1","title":"Predictions for neutron star mergers from the gauge/gravity duality","summary":"The gauge/gravity duality, combined with information from lattice QCD,\nnuclear theory, and perturbative QCD, can be used to constrain the equation of\nstate of hot and dense QCD. I discuss an approach based on the holographic\nV-QCD model, which includes both nuclear and quark matter phases, separated by\na first order phase transition. By using this model in state-of-the-art\nsimulations of neutron star binaries, I study the formation of quark matter\nduring the merger process, and its effect on the threshold mass for prompt\ncollapse into a black hole.","main_category":"hep-ph","categories":"hep-ph,hep-th","published":"2025-04-16T09:29:59Z"}
{"aid":"http://arxiv.org/abs/2504.11906v1","title":"Testing of tempered fractional Brownian motions","summary":"We propose here a testing methodology based on the autocovariance, detrended\nmoving average, and time-averaged mean-squared displacement statistics for\ntempered fractional Brownian motions (TFBMs) which are related to the notions\nof semi-long range dependence and transient anomalous diffusion. In this\nframework, we consider three types of TFBMs: two with a tempering factor\nincorporated into their moving-average representation, and one with a tempering\nparameter added to the autocorrelation formula. We illustrate their dynamics\nwith the use of quantile lines. Using the proposed methodology, we provide a\ncomprehensive power analysis of the tests. It appears that the tests allow\ndistinguishing between the tempered processes with different Hurst parameters.","main_category":"stat.ME","categories":"stat.ME,physics.data-an","published":"2025-04-16T09:30:55Z"}
{"aid":"http://arxiv.org/abs/2504.11914v1","title":"AnomalyR1: A GRPO-based End-to-end MLLM for Industrial Anomaly Detection","summary":"Industrial Anomaly Detection (IAD) poses a formidable challenge due to the\nscarcity of defective samples, making it imperative to deploy models capable of\nrobust generalization to detect unseen anomalies effectively. Traditional\napproaches, often constrained by hand-crafted features or domain-specific\nexpert models, struggle to address this limitation, underscoring the need for a\nparadigm shift. We introduce AnomalyR1, a pioneering framework that leverages\nVLM-R1, a Multimodal Large Language Model (MLLM) renowned for its exceptional\ngeneralization and interpretability, to revolutionize IAD. By integrating MLLM\nwith Group Relative Policy Optimization (GRPO), enhanced by our novel Reasoned\nOutcome Alignment Metric (ROAM), AnomalyR1 achieves a fully end-to-end solution\nthat autonomously processes inputs of image and domain knowledge, reasons\nthrough analysis, and generates precise anomaly localizations and masks. Based\non the latest multimodal IAD benchmark, our compact 3-billion-parameter model\noutperforms existing methods, establishing state-of-the-art results. As MLLM\ncapabilities continue to advance, this study is the first to deliver an\nend-to-end VLM-based IAD solution that demonstrates the transformative\npotential of ROAM-enhanced GRPO, positioning our framework as a forward-looking\ncornerstone for next-generation intelligent anomaly detection systems in\nindustrial applications with limited defective data.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T09:48:41Z"}
{"aid":"http://arxiv.org/abs/2504.11936v1","title":"Mind2Matter: Creating 3D Models from EEG Signals","summary":"The reconstruction of 3D objects from brain signals has gained significant\nattention in brain-computer interface (BCI) research. Current research\npredominantly utilizes functional magnetic resonance imaging (fMRI) for 3D\nreconstruction tasks due to its excellent spatial resolution. Nevertheless, the\nclinical utility of fMRI is limited by its prohibitive costs and inability to\nsupport real-time operations. In comparison, electroencephalography (EEG)\npresents distinct advantages as an affordable, non-invasive, and mobile\nsolution for real-time brain-computer interaction systems. While recent\nadvances in deep learning have enabled remarkable progress in image generation\nfrom neural data, decoding EEG signals into structured 3D representations\nremains largely unexplored. In this paper, we propose a novel framework that\ntranslates EEG recordings into 3D object reconstructions by leveraging neural\ndecoding techniques and generative models. Our approach involves training an\nEEG encoder to extract spatiotemporal visual features, fine-tuning a large\nlanguage model to interpret these features into descriptive multimodal outputs,\nand leveraging generative 3D Gaussians with layout-guided control to synthesize\nthe final 3D structures. Experiments demonstrate that our model captures\nsalient geometric and semantic features, paving the way for applications in\nbrain-computer interfaces (BCIs), virtual reality, and neuroprosthetics.Our\ncode is available in https://github.com/sddwwww/Mind2Matter.","main_category":"cs.GR","categories":"cs.GR,cs.HC,eess.SP","published":"2025-04-16T10:16:03Z"}
{"aid":"http://arxiv.org/abs/2504.11944v1","title":"VIPO: Value Function Inconsistency Penalized Offline Reinforcement\n  Learning","summary":"Offline reinforcement learning (RL) learns effective policies from\npre-collected datasets, offering a practical solution for applications where\nonline interactions are risky or costly. Model-based approaches are\nparticularly advantageous for offline RL, owing to their data efficiency and\ngeneralizability. However, due to inherent model errors, model-based methods\noften artificially introduce conservatism guided by heuristic uncertainty\nestimation, which can be unreliable. In this paper, we introduce VIPO, a novel\nmodel-based offline RL algorithm that incorporates self-supervised feedback\nfrom value estimation to enhance model training. Specifically, the model is\nlearned by additionally minimizing the inconsistency between the value learned\ndirectly from the offline data and the one estimated from the model. We perform\ncomprehensive evaluations from multiple perspectives to show that VIPO can\nlearn a highly accurate model efficiently and consistently outperform existing\nmethods. It offers a general framework that can be readily integrated into\nexisting model-based offline RL algorithms to systematically enhance model\naccuracy. As a result, VIPO achieves state-of-the-art performance on almost all\ntasks in both D4RL and NeoRL benchmarks.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-16T10:23:44Z"}
{"aid":"http://arxiv.org/abs/2504.11974v1","title":"Who Said Only Military Officers Can Deal with Uncertainty? On the\n  Importance of Uncertainty in EdTech Data Visualisations","summary":"AI-powered predictive systems have high margins of error. However, data\nvisualisations of algorithmic systems in education and other social fields tend\nto visualise certainty, thus invisibilising the underlying approximations and\nuncertainties of the algorithmic systems and the social settings in which these\nsystems operate. This paper draws on a critical speculative approach to first\nanalyse data visualisations from predictive analytics platforms for education.\nIt demonstrates that visualisations of uncertainty in education are rare.\nSecond, the paper explores uncertainty visualisations in other fields (defence,\nclimate change and healthcare). The paper concludes by reflecting on the role\nof data visualisations and un/certainty in shaping educational futures. It also\nidentifies practical implications for the design of data visualisations in\neducation.","main_category":"cs.HC","categories":"cs.HC,cs.CY","published":"2025-04-16T11:11:33Z"}
{"aid":"http://arxiv.org/abs/2504.11977v1","title":"Leveraging Machine Learning Models to Predict the Outcome of Digital\n  Medical Triage Interviews","summary":"Many existing digital triage systems are questionnaire-based, guiding\npatients to appropriate care levels based on information (e.g., symptoms,\nmedical history, and urgency) provided by the patients answering\nquestionnaires. Such a system often uses a deterministic model with predefined\nrules to determine care levels. It faces challenges with incomplete triage\ninterviews since it can only assist patients who finish the process. In this\nstudy, we explore the use of machine learning (ML) to predict outcomes of\nunfinished interviews, aiming to enhance patient care and service quality.\nPredicting triage outcomes from incomplete data is crucial for patient safety\nand healthcare efficiency. Our findings show that decision-tree models,\nparticularly LGBMClassifier and CatBoostClassifier, achieve over 80\\% accuracy\nin predicting outcomes from complete interviews while having a linear\ncorrelation between the prediction accuracy and interview completeness degree.\nFor example, LGBMClassifier achieves 88,2\\% prediction accuracy for interviews\nwith 100\\% completeness, 79,6\\% accuracy for interviews with 80\\% completeness,\n58,9\\% accuracy for 60\\% completeness, and 45,7\\% accuracy for 40\\%\ncompleteness. The TabTransformer model demonstrated exceptional accuracy of\nover 80\\% for all degrees of completeness but required extensive training time,\nindicating a need for more powerful computational resources. The study\nhighlights the linear correlation between interview completeness and predictive\npower of the decision-tree models.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-16T11:17:23Z"}
{"aid":"http://arxiv.org/abs/2504.11988v1","title":"Strong Convergence Rates for Euler Schemes of Levy-Driven SDE using\n  Dynamic Cutting","summary":"We derive strong Lp convergence rates for the Euler-Maruyama schemes of\nLevy-driven SDE using a new dynamic cutting (DC) method with a time-dependent\njump threshold. In addition, we present results from numerical simulations\ncomparing the DC and Asmussen-Rosinski (AR) approaches. These simulations\ndemonstrate the superior accuracy achieved by the DC method.","main_category":"math.PR","categories":"math.PR,cs.NA,math.NA","published":"2025-04-16T11:29:14Z"}
{"aid":"http://arxiv.org/abs/2504.12000v1","title":"Control of Rayleigh-Bénard Convection: Effectiveness of Reinforcement\n  Learning in the Turbulent Regime","summary":"Data-driven flow control has significant potential for industry, energy\nsystems, and climate science. In this work, we study the effectiveness of\nReinforcement Learning (RL) for reducing convective heat transfer in the 2D\nRayleigh-B\\'enard Convection (RBC) system under increasing turbulence. We\ninvestigate the generalizability of control across varying initial conditions\nand turbulence levels and introduce a reward shaping technique to accelerate\nthe training. RL agents trained via single-agent Proximal Policy Optimization\n(PPO) are compared to linear proportional derivative (PD) controllers from\nclassical control theory. The RL agents reduced convection, measured by the\nNusselt Number, by up to 33% in moderately turbulent systems and 10% in highly\nturbulent settings, clearly outperforming PD control in all settings. The\nagents showed strong generalization performance across different initial\nconditions and to a significant extent, generalized to higher degrees of\nturbulence. The reward shaping improved sample efficiency and consistently\nstabilized the Nusselt Number to higher turbulence levels.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cs.LG","published":"2025-04-16T11:51:59Z"}
{"aid":"http://arxiv.org/abs/2504.12006v1","title":"Comment on Path integral measure and RG equations for gravity","summary":"Asymptotic safety is a candidate for a predictive quantum theory of gravity\nand matter. Recent works (arXiv:2412.10194 and arXiv:2412.14108) challenged\nthis scenario. We show that their arguments fail on a basic level.","main_category":"hep-th","categories":"hep-th","published":"2025-04-16T12:00:22Z"}
{"aid":"http://arxiv.org/abs/2504.12036v1","title":"Contract-based hierarchical control using predictive feasibility value\n  functions","summary":"Today's control systems are often characterized by modularity and safety\nrequirements to handle complexity, resulting in hierarchical control\nstructures. Although hierarchical model predictive control offers favorable\nproperties, achieving a provably safe, yet modular design remains a challenge.\nThis paper introduces a contract-based hierarchical control strategy to improve\nthe performance of control systems facing challenges related to model\ninconsistency and independent controller design across hierarchies. We consider\na setup where a higher-level controller generates references that affect the\nconstraints of a lower-level controller, which is based on a soft-constrained\nMPC formulation. The optimal slack variables serve as the basis for a contract\nthat allows the higher-level controller to assess the feasibility of the\nreference trajectory without exact knowledge of the model, constraints, and\ncost of the lower-level controller. To ensure computational efficiency while\nmaintaining model confidentiality, we propose using an explicit function\napproximation, such as a neural network, to represent the cost of optimal slack\nvalues. The approach is tested for a hierarchical control setup consisting of a\nplanner and a motion controller as commonly found in autonomous driving.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-16T12:51:18Z"}
{"aid":"http://arxiv.org/abs/2504.12095v1","title":"The Gray graph is pseudo 2-factor isomorphic","summary":"A graph is pseudo 2-factor isomorphic if all of its 2-factors have the same\nparity of number of cycles. Abreu et al. [J. Comb. Theory, Ser. B. 98 (2008)\n432--442] conjectured that $K_{3,3}$, the Heawood graph and the Pappus graph\nare the only essentially 4-edge-connected pseudo 2-factor isomorphic cubic\nbipartite graphs. This conjecture was disproved by Goedgebeur [Discr. Appl.\nMath. 193 (2015) 57--60] who constructed a counterexample $\\mathcal{G}$ (of\ngirth 6) on 30 vertices. Using a computer search, he also showed that this is\nthe only counterexample up to at least 40 vertices and that there are no\ncounterexamples of girth greater than 6 up to at least 48 vertices.\n  In this manuscript, we show that the Gray graph -- which has 54 vertices and\ngirth 8 -- is also a counterexample to the pseudo 2-factor isomorphic graph\nconjecture. Next to the graph $\\mathcal{G}$, this is the only other known\ncounterexample. Using a computer search, we show that there are no smaller\ncounterexamples of girth 8 and show that there are no other counterexamples up\nto at least 42 vertices of any girth. Moreover, we also verified that there are\nno further counterexamples among the known censuses of symmetrical graphs.\n  Recall that a graph is 2-factor Hamiltonian if all of its 2-factors are\nHamiltonian cycles. As a by-product of the computer searches performed for this\npaper, we have verified that the $2$-factor Hamiltonian conjecture of Funk et\nal. [J. Comb. Theory, Ser. B. 87(1) (2003) 138--144], which is still open,\nholds for cubic bipartite graphs of girth at least 8 up to 52 vertices, and up\nto 42 vertices for any girth.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-16T13:59:43Z"}
{"aid":"http://arxiv.org/abs/2504.12107v1","title":"Magnetic Pair Distribution Function and Half Polarized Neutron Powder\n  Diffraction at the HB-2A Powder Diffractometer","summary":"Local magnetic order and anisotropy are often central for understanding\nfundamental behavior and emergent functional properties in quantum materials\nand beyond. Advances in neutron powder diffraction experiments and analysis\ntools now allow for quantitative determination. We demonstrate this here with\ncomplementary total neutron scattering and polarized neutron measurements on\nthe HB-2A neutron powder diffractometer at the High Flux Isotope Reactor\n(HFIR). In recent years, magnetic pair distribution function (mPDF) analysis\nhas emerged as a powerful technique for probing local magnetic spin ordering of\nmagnetic materials. This method can be broadly applied to any magnetic material\nbut is particularly effective for studying systems with short-range magnetic\norder, such as materials with reduced dimensionality, geometrically frustrated\nmagnets, thermoelectrics, multiferroics, and correlated paramagnets. Magnetic\nanisotropy often underpins the short-range order adopted. Half-polarized\nneutron powder diffraction (pNPD) can be used to determine the local\nsusceptibility tensor on the magnetic sites to quantify the magnetic\nanisotropy. Combining the techniques of mPDF and pNPD can therefore provide\nvaluable insights into local magnetic behavior. A series of measurements\noptimized for these techniques are presented as exemplar cases focused on\nfrustrated materials where short-range order dominates, these include\nmeasurements to ultra-low temperature (<100 mK) not typically accessible for\nsuch experiments.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci","published":"2025-04-16T14:16:08Z"}
{"aid":"http://arxiv.org/abs/2504.12108v1","title":"Entropy-Guided Watermarking for LLMs: A Test-Time Framework for Robust\n  and Traceable Text Generation","summary":"The rapid development of Large Language Models (LLMs) has intensified\nconcerns about content traceability and potential misuse. Existing watermarking\nschemes for sampled text often face trade-offs between maintaining text quality\nand ensuring robust detection against various attacks. To address these issues,\nwe propose a novel watermarking scheme that improves both detectability and\ntext quality by introducing a cumulative watermark entropy threshold. Our\napproach is compatible with and generalizes existing sampling functions,\nenhancing adaptability. Experimental results across multiple LLMs show that our\nscheme significantly outperforms existing methods, achieving over 80\\%\nimprovements on widely-used datasets, e.g., MATH and GSM8K, while maintaining\nhigh detection accuracy.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-16T14:16:38Z"}
{"aid":"http://arxiv.org/abs/2504.12113v1","title":"Clarifying Ambiguities: on the Role of Ambiguity Types in Prompting\n  Methods for Clarification Generation","summary":"In information retrieval (IR), providing appropriate clarifications to better\nunderstand users' information needs is crucial for building a proactive\nsearch-oriented dialogue system. Due to the strong in-context learning ability\nof large language models (LLMs), recent studies investigate prompting methods\nto generate clarifications using few-shot or Chain of Thought (CoT) prompts.\nHowever, vanilla CoT prompting does not distinguish the characteristics of\ndifferent information needs, making it difficult to understand how LLMs resolve\nambiguities in user queries. In this work, we focus on the concept of ambiguity\nfor clarification, seeking to model and integrate ambiguities in the\nclarification process. To this end, we comprehensively study the impact of\nprompting schemes based on reasoning and ambiguity for clarification. The idea\nis to enhance the reasoning abilities of LLMs by limiting CoT to predict first\nambiguity types that can be interpreted as instructions to clarify, then\ncorrespondingly generate clarifications. We name this new prompting scheme\nAmbiguity Type-Chain of Thought (AT-CoT). Experiments are conducted on various\ndatasets containing human-annotated clarifying questions to compare AT-CoT with\nmultiple baselines. We also perform user simulations to implicitly measure the\nquality of generated clarifications under various IR scenarios.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-16T14:21:02Z"}
{"aid":"http://arxiv.org/abs/2504.12184v1","title":"Feature Selection for Data-driven Explainable Optimization","summary":"Mathematical optimization, although often leading to NP-hard models, is now\ncapable of solving even large-scale instances within reasonable time. However,\nthe primary focus is often placed solely on optimality. This implies that while\nobtained solutions are globally optimal, they are frequently not comprehensible\nto humans, in particular when obtained by black-box routines. In contrast,\nexplainability is a standard requirement for results in Artificial\nIntelligence, but it is rarely considered in optimization yet. There are only a\nfew studies that aim to find solutions that are both of high quality and\nexplainable. In recent work, explainability for optimization was defined in a\ndata-driven manner: a solution is considered explainable if it closely\nresembles solutions that have been used in the past under similar\ncircumstances. To this end, it is crucial to identify a preferably small subset\nof features from a presumably large set that can be used to explain a solution.\nIn mathematical optimization, feature selection has received little attention\nyet. In this work, we formally define the feature selection problem for\nexplainable optimization and prove that its decision version is NP-complete. We\nintroduce mathematical models for optimized feature selection. As their global\nsolution requires significant computation time with modern mixed-integer linear\nsolvers, we employ local heuristics. Our computational study using data that\nreflect real-world scenarios demonstrates that the problem can be solved\npractically efficiently for instances of reasonable size.","main_category":"math.OC","categories":"math.OC","published":"2025-04-16T15:40:03Z"}
{"aid":"http://arxiv.org/abs/2504.12214v1","title":"Bayesian random-effects meta-analysis of aggregate data on clinical\n  events","summary":"To appreciate intervention effects on rare events, meta-analysis techniques\nare commonly applied in order to assess the accumulated evidence. When it comes\nto adverse effects in clinical trials, these are often most adequately handled\nusing survival methods. A common-effect model that is able to process data in\ncommonly quoted formats in terms of hazard ratios has been proposed for this\npurpose by Holzhauer (Stat. Med. 2017; 36(5):723-737). In order to accommodate\npotential heterogeneity between studies, we have extended the model by\nHolzhauer to a random-effects approach. The Bayesian model is described in\ndetail, and applications to realistic data sets are discussed along with\nsensitivity analyses and Monte Carlo simulations to support the conclusions.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-16T16:06:05Z"}
{"aid":"http://arxiv.org/abs/2504.12222v1","title":"Coding-Prior Guided Diffusion Network for Video Deblurring","summary":"While recent video deblurring methods have advanced significantly, they often\noverlook two valuable prior information: (1) motion vectors (MVs) and coding\nresiduals (CRs) from video codecs, which provide efficient inter-frame\nalignment cues, and (2) the rich real-world knowledge embedded in pre-trained\ndiffusion generative models. We present CPGDNet, a novel two-stage framework\nthat effectively leverages both coding priors and generative diffusion priors\nfor high-quality deblurring. First, our coding-prior feature propagation (CPFP)\nmodule utilizes MVs for efficient frame alignment and CRs to generate attention\nmasks, addressing motion inaccuracies and texture variations. Second, a\ncoding-prior controlled generation (CPC) module network integrates coding\npriors into a pretrained diffusion model, guiding it to enhance critical\nregions and synthesize realistic details. Experiments demonstrate our method\nachieves state-of-the-art perceptual quality with up to 30% improvement in IQA\nmetrics. Both the code and the codingprior-augmented dataset will be\nopen-sourced.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T16:14:43Z"}
{"aid":"http://arxiv.org/abs/2504.12226v1","title":"Decomposition of Hyperplane Arrangements: Algebra, Combinatorics, and\n  its Geometric Realization","summary":"Let $\\mathcal{A}$ be an affine hyperplane arrangement, $L(\\mathcal{A})$ its\nintersection poset, and $\\chi_{\\mathcal{A}}(t)$ its characteristic polynomial.\nThis paper aims to find combinatorial conditions for the factorization of\n$\\chi_{\\mathcal{A}}(t)$ and investigate corresponding algebraic\ninterpretations. To this end, we introduce the concept of ideal decomposition\nin a finite ranked meet-semilattice. Notably, it extends two celebrated\nconcepts: modular element proposed by Stanley in 1971 and nice partition\nproposed by Terao in 1992.\n  The main results are as follows. An ideal decomposition of $L(\\mathcal{A})$\nleads to a factorization of its characteristic polynomial\n$\\chi_{\\mathcal{A}}(t)$, which is an extension of Terao's factorization under a\nnice partition. A special type of two-part ideal decomposition, modular ideal,\nis studied, which extends Stanley's factorization to affine hyperplane\narrangements. We also show that any modular ideal of $L(\\mathcal{A})$ has a\ngeometric realization. Moreover, we extend Terao's factorization of the\nOrlik-Solomon algebra for central arrangements, originally induced by modular\nelements, to arbitrary affine hyperplane arrangements via the modular ideals.","main_category":"math.CO","categories":"math.CO","published":"2025-04-16T16:20:43Z"}
{"aid":"http://arxiv.org/abs/2504.12251v1","title":"An Evaluation of N-Gram Selection Strategies for Regular Expression\n  Indexing in Contemporary Text Analysis Tasks","summary":"Efficient evaluation of regular expressions (regex, for short) is crucial for\ntext analysis, and n-gram indexes are fundamental to achieving fast regex\nevaluation performance. However, these indexes face scalability challenges\nbecause of the exponential number of possible n-grams that must be indexed.\nMany existing selection strategies, developed decades ago, have not been\nrigorously evaluated on contemporary large-scale workloads and lack\ncomprehensive performance comparisons. Therefore, a unified and comprehensive\nevaluation framework is necessary to compare these methods under the same\nexperimental settings. This paper presents the first systematic evaluation of\nthree representative n-gram selection strategies across five workloads,\nincluding real-time production logs and genomic sequence analysis. We examine\ntheir trade-offs in terms of index construction time, storage overhead, false\npositive rates, and end-to-end query performance. Through empirical results,\nthis study provides a modern perspective on existing n-gram based regular\nexpression evaluation methods, extensive observations, valuable discoveries,\nand an adaptable testing framework to guide future research in this domain. We\nmake our implementations of these methods and our test framework available as\nopen-source at https://github.com/mush-zhang/RegexIndexComparison.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-16T16:58:26Z"}
{"aid":"http://arxiv.org/abs/2504.12257v1","title":"QSHS: An Axion Dark Matter Resonant Search Apparatus","summary":"We describe a resonant cavity search apparatus for axion dark matter\nconstructed by the Quantum Sensors for the Hidden Sector (QSHS) collaboration.\nThe apparatus is configured to search for QCD axion dark matter, though also\nhas the capability to detect axion-like particles (ALPs), dark photons, and\nsome other forms of wave-like dark matter. Initially, a tuneable cylindrical\noxygen-free copper cavity is read out using a low noise microwave amplifier\nfeeding a heterodyne receiver. The cavity is housed in a dilution refrigerator\nand threaded by a solenoidal magnetic field, nominally 8T. The apparatus also\nhouses a magnetic field shield for housing superconducting electronics, and\nseveral other fixed-frequency resonators for use in testing and commissioning\nvarious prototype quantum electronic devices sensitive at a range of axion\nmasses in the range $\\rm 2.0$ to $\\rm 40\\,eV/c^2$. We present performance data\nfor the resonator, dilution refrigerator, and magnet, and plans for the first\nscience run.","main_category":"physics.ins-det","categories":"physics.ins-det,astro-ph.IM,hep-ex","published":"2025-04-16T17:08:00Z"}
{"aid":"http://arxiv.org/abs/2504.12264v1","title":"Towards Learning to Complete Anything in Lidar","summary":"We propose CAL (Complete Anything in Lidar) for Lidar-based shape-completion\nin-the-wild. This is closely related to Lidar-based semantic/panoptic scene\ncompletion. However, contemporary methods can only complete and recognize\nobjects from a closed vocabulary labeled in existing Lidar datasets. Different\nto that, our zero-shot approach leverages the temporal context from multi-modal\nsensor sequences to mine object shapes and semantic features of observed\nobjects. These are then distilled into a Lidar-only instance-level completion\nand recognition model. Although we only mine partial shape completions, we find\nthat our distilled model learns to infer full object shapes from multiple such\npartial observations across the dataset. We show that our model can be prompted\non standard benchmarks for Semantic and Panoptic Scene Completion, localize\nobjects as (amodal) 3D bounding boxes, and recognize objects beyond fixed class\nvocabularies. Our project page is\nhttps://research.nvidia.com/labs/dvl/projects/complete-anything-lidar","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T17:21:55Z"}
{"aid":"http://arxiv.org/abs/2504.12275v1","title":"The rank evolution of block bidiagonal matrices over finite fields","summary":"We investigate uniform random block lower bidiagonal matrices over the finite\nfield $\\mathbb{F}_q$, and prove that their rank undergoes a phase transition.\n  First, we consider block lower bidiagonal matrices with $(k_n+1)\\times k_n$\nblocks where each block is of size $n\\times n$. We prove that if $k_n\\ll\nq^{n/2}$, then these matrices have full rank with high probability, and if\n$k_n\\gg q^{n/2}$, then the rank has Gaussian fluctuations.\n  Second, we consider block lower bidiagonal matrices with $k_n\\times k_n$\nblocks where each block is of size $n\\times n$. We prove that if $k_n\\ll\nq^{n/2}$, then the rank exhibits the same constant order fluctuations as the\nrank of the matrix products considered by Nguyen and Van Peski, and if $k_n\\gg\nq^{n/2}$, then the rank has Gaussian fluctuations.\n  Finally, we also consider a truncated version of the first model, where we\nprove that at $k_n\\approx q^{n/2}$, we have a phase transition between a\nCohen-Lenstra and a Gaussian limiting behavior of the rank. We also show that\nthere is a localization/delocalization phase transition for the vectors in the\nkernels of these matrices at the same critical point.\n  In all three cases, we also provide a precise description of the behavior of\nthe rank at criticality.\n  These results are proved by analyzing the limiting behavior of a Markov chain\nobtained from the increments of the ranks of these matrices.","main_category":"math.PR","categories":"math.PR","published":"2025-04-16T17:35:02Z"}
{"aid":"http://arxiv.org/abs/2504.12286v1","title":"Long-time soliton dynamics via a coarse-grained space-time method","summary":"We investigate the long-time dynamics of the Sine-Gordon (SG) model under a\nclass of perturbations whose quantum field theoretic analog - via bosonization\n- corresponds to the massive Schwinger model describing 1+1D relativistic QED\nof Dirac fermions. Classical SG solutions offer critical insight into\nnon-perturbative effects in this quantum theory, but capturing their long-time\nbehavior poses significant numerical challenges. To address this, we extend a\ncoarse-graining method to spacetime using a dual-mesh construction based on the\nMinkowski-metric. We first validate the approach against the well-studied\nvariant of the SG model describing magnetic fluxon dynamics in Josephson\ntransmission lines (JTLs), where analytical and numerical benchmarks exist. We\nthen apply the method to the Schwinger-inspired SG model and uncover long-lived\nbound states - \"Schwinger atoms\" - in which a soliton is trapped by a fixed\ncentral charge. In certain regimes, the system exhibits limit cycles that give\nrise to positronium-like states of oppositely charged solitons, while in others\nsuch formation is suppressed. Accessing such long-time solutions requires a\nrigorous implementation of outgoing boundary conditions on a finite\ncomputational domain that provide radiative dissipation to allow relaxation\ntoward states that exist only in an infinite domain. Here we provide such a\nconstruction. Our results also suggest the possibility of analog quantum\nsimulation of relativistic quantum field theories with JTLs. These results\ndemonstrate the utility of spatio-temporal coarse-graining methodology for\nprobing non-perturbative structure formation in non-linear field theories.","main_category":"quant-ph","categories":"quant-ph,hep-ph,physics.optics","published":"2025-04-16T17:51:51Z"}
{"aid":"http://arxiv.org/abs/2504.12613v1","title":"Fast and Accurate Prediction of Antenna Reflection Coefficients in\n  Planar Layered Media Environment via Generalized Scattering Matrix","summary":"The numerical algorithm for evaluating the reflection coefficient of an\nantenna in the presence of the planar layered medium is reformulated using the\nantenna's generalized scattering matrix (GSM). The interaction between the\nantenna and the layered medium is modeled through spherical-to-planar vector\nwave transformations, ensuring no approximations that could compromise\ncomputational accuracy. This theoretical framework significantly reduces\nalgebraic complexity, resulting in a marked increase in the speed of antenna\nperformance evaluation. Excluding the one-time preprocessing cost of obtaining\nthe antenna's GSM in free space, the numerical evaluation speed of this method\nexceeds that of the commercial software FEKO by several orders of magnitude,\nwhile maintaining nearly identical accuracy.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-17T03:28:23Z"}
{"aid":"http://arxiv.org/abs/2504.12619v1","title":"SAM-Based Building Change Detection with Distribution-Aware Fourier\n  Adaptation and Edge-Constrained Warping","summary":"Building change detection remains challenging for urban development, disaster\nassessment, and military reconnaissance. While foundation models like Segment\nAnything Model (SAM) show strong segmentation capabilities, SAM is limited in\nthe task of building change detection due to domain gap issues. Existing\nadapter-based fine-tuning approaches face challenges with imbalanced building\ndistribution, resulting in poor detection of subtle changes and inaccurate edge\nextraction. Additionally, bi-temporal misalignment in change detection,\ntypically addressed by optical flow, remains vulnerable to background noises.\nThis affects the detection of building changes and compromises both detection\naccuracy and edge recognition. To tackle these challenges, we propose a new\nSAM-Based Network with Distribution-Aware Fourier Adaptation and\nEdge-Constrained Warping (FAEWNet) for building change detection. FAEWNet\nutilizes the SAM encoder to extract rich visual features from remote sensing\nimages. To guide SAM in focusing on specific ground objects in remote sensing\nscenes, we propose a Distribution-Aware Fourier Aggregated Adapter to aggregate\ntask-oriented changed information. This adapter not only effectively addresses\nthe domain gap issue, but also pays attention to the distribution of changed\nbuildings. Furthermore, to mitigate noise interference and misalignment in\nheight offset estimation, we design a novel flow module that refines building\nedge extraction and enhances the perception of changed buildings. Our\nstate-of-the-art results on the LEVIR-CD, S2Looking and WHU-CD datasets\nhighlight the effectiveness of FAEWNet. The code is available at\nhttps://github.com/SUPERMAN123000/FAEWNet.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T03:47:43Z"}
{"aid":"http://arxiv.org/abs/2504.12624v1","title":"The (3+1)-dimensional dispersionless integrable hierarchy and nonlinear\n  Riemann-Hilbert problem associated with the Doubrov-Ferapontov modified\n  heavenly equation","summary":"According to the classification of integrable complex Monge-Ampere equations\nby Doubrov and Ferapontov, the modified heavenly equation is a typical\n(3+1)-dimensional dispersionless and canonical integrable equation.In this\npaper we use the eigenfunctions of the Doubrov-Ferapontov modified heavenly\nequation to obtain a related hierarchy. Next we construct the Lax-Sato\nequations with Hamiltonian vector fields and Zakharov-Shabat type equations\nwhich are equivalent to the hierarchy. The nonlinear Riemann-Hilbert problem is\nalso applied to study the solution of Doubrov-Ferapontov modified heavenly\nequation.","main_category":"nlin.SI","categories":"nlin.SI","published":"2025-04-17T03:58:33Z"}
{"aid":"http://arxiv.org/abs/2504.12635v1","title":"On Equivalence Between Decentralized Policy-Profile Mixtures and\n  Behavioral Coordination Policies in Multi-Agent Systems","summary":"Constrained decentralized team problem formulations are good models for many\ncooperative multi-agent systems. Constraints necessitate randomization when\nsolving for optimal solutions -- our past results show that joint randomization\namongst the team is necessary for (strong) Lagrangian duality to hold -- , but\na better understanding of randomization still remains. For a partially observed\nmulti-agent system with Borel hidden state and finite observations and actions,\nwe prove the equivalence between joint mixtures of decentralized\npolicy-profiles (both pure and behavioral) and common-information based\nbehavioral coordination policies (also mixtures of them). This generalizes past\nwork that shows equivalence between pure decentralized policy-profiles and pure\ncoordination policies. The equivalence can be exploited to develop results on\nstrong duality and number of randomizations.","main_category":"math.OC","categories":"math.OC","published":"2025-04-17T04:34:14Z"}
{"aid":"http://arxiv.org/abs/2504.12636v1","title":"A0: An Affordance-Aware Hierarchical Model for General Robotic\n  Manipulation","summary":"Robotic manipulation faces critical challenges in understanding spatial\naffordances--the \"where\" and \"how\" of object interactions--essential for\ncomplex manipulation tasks like wiping a board or stacking objects. Existing\nmethods, including modular-based and end-to-end approaches, often lack robust\nspatial reasoning capabilities. Unlike recent point-based and flow-based\naffordance methods that focus on dense spatial representations or trajectory\nmodeling, we propose A0, a hierarchical affordance-aware diffusion model that\ndecomposes manipulation tasks into high-level spatial affordance understanding\nand low-level action execution. A0 leverages the Embodiment-Agnostic Affordance\nRepresentation, which captures object-centric spatial affordances by predicting\ncontact points and post-contact trajectories. A0 is pre-trained on 1 million\ncontact points data and fine-tuned on annotated trajectories, enabling\ngeneralization across platforms. Key components include Position Offset\nAttention for motion-aware feature extraction and a Spatial Information\nAggregation Layer for precise coordinate mapping. The model's output is\nexecuted by the action execution module. Experiments on multiple robotic\nsystems (Franka, Kinova, Realman, and Dobot) demonstrate A0's superior\nperformance in complex tasks, showcasing its efficiency, flexibility, and\nreal-world applicability.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-17T04:45:15Z"}
{"aid":"http://arxiv.org/abs/2504.12638v1","title":"Spatial Age Distribution of Classical Cepheids in Spiral Galaxies: The\n  Cases of M31 and M33","summary":"Classical Cepheids can be used as age indicators due to well-established\nperiod-age and period-age-color relations. \\citet{Desomma2021} refined these\nrelations by including a metallicity term and different Mass-Luminosity\nassumptions.\n  In this study, we apply the period-age-metallicity relation for the first\ntime to samples of Classical Cepheids in M31 and M33. For both galaxies, we\nconsider Cepheid coordinates and spatial distributions, along with the\nmetallicity gradients by \\citet{Zaritsky1994} and \\citet{Magrini2007}, to\nprovide a metallicity estimate for each pulsator. By applying the\nperiod-age-metallicity relation, we derive individual ages for each Cepheid.\n  Combining these ages and spatial distributions, we construct detailed age\nmaps for both galaxies. Our analysis confirms a radial age gradient, with\nyounger Cepheids preferentially found toward the galactic centers. In M31, we\nconfirm an outer ring at $\\sim 11$ kpc, consistent with previous studies, and\nidentify for the first time an inner ring at $\\sim 7$ kpc, possibly associated\nwith star formation episodes.\n  Comparing age gradients at different angles, we find a consistent general\ntrend of ages increasing monotonically with radius. At the same time, we\nobserve smaller-scale differences, particularly in the $90^\\circ$-$180^\\circ$\nquadrant, suggesting asymmetric star formation and possible dynamical\ninfluences. In contrast, M33 displays a steeper global age gradient, indicating\na higher concentration of young stars toward its center.\n  This study highlights the utility of Cepheids as stellar population tracers,\nproviding insights into the star formation and dynamical evolution of spiral\ngalaxies. Future works will extend this methodology to additional galaxies.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-04-17T04:49:11Z"}
{"aid":"http://arxiv.org/abs/2504.12661v1","title":"VLMGuard-R1: Proactive Safety Alignment for VLMs via Reasoning-Driven\n  Prompt Optimization","summary":"Aligning Vision-Language Models (VLMs) with safety standards is essential to\nmitigate risks arising from their multimodal complexity, where integrating\nvision and language unveils subtle threats beyond the reach of conventional\nsafeguards. Inspired by the insight that reasoning across modalities is key to\npreempting intricate vulnerabilities, we propose a novel direction for VLM\nsafety: multimodal reasoning-driven prompt rewriting. To this end, we introduce\nVLMGuard-R1, a proactive framework that refines user inputs through a\nreasoning-guided rewriter, dynamically interpreting text-image interactions to\ndeliver refined prompts that bolster safety across diverse VLM architectures\nwithout altering their core parameters. To achieve this, we devise a\nthree-stage reasoning pipeline to synthesize a dataset that trains the rewriter\nto infer subtle threats, enabling tailored, actionable responses over generic\nrefusals. Extensive experiments across three benchmarks with five VLMs reveal\nthat VLMGuard-R1 outperforms four baselines. In particular, VLMGuard-R1\nachieves a remarkable 43.59\\% increase in average safety across five models on\nthe SIUO benchmark.","main_category":"cs.LG","categories":"cs.LG,cs.CL,cs.CV","published":"2025-04-17T05:46:41Z"}
{"aid":"http://arxiv.org/abs/2504.12688v1","title":"Ab initio study of anisotropic effects in two-dimensional Fe$_3$GeTe$_2$\n  using $\\bf{k}$-dependent Green's functions","summary":"In the present work, we develop the Green's function apparatus and extend its\napplicability to the study of microscopic anisotropic effects in real\nconducting materials. The problem of the previously proposed approaches written\nin terms of inter-atomic Green's functions is the presence of a spatial sum\nover all atoms of the crystal, which greatly complicates their application to\nsystems with itinerant electrons. To provide a solution we derived expressions\nfor magnetic torque vector and Dzyaloshinskii-Moriya interactions based on\n$\\bf{k}$-dependent Green's functions, which allow numerical evaluations with\nguaranteed stability of spatial sums over the crystal lattice and moreover with\nmuch lower computational cost. Approbation of the approaches on the case of\nFe$_3$GeTe$_2$ monolayer, which is based on first-principles DFT calculations,\nconfirmed the numerical stability and allowed us to reproduce the\ncharacteristic length of experimentally observed collective spin excitations in\nthe domain structure of this promising conducting material.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-17T06:31:18Z"}
{"aid":"http://arxiv.org/abs/2504.12701v1","title":"Excision and idealization of a multiplicative Lie algebra","summary":"In this article, we introduce the concepts of excision and idealization for a\nmultiplicative Lie algebra (also for a Lie algebra), which provides two new\nmultiplicative Lie algebras (or Lie algebras) from a given multiplicative Lie\nalgebra (or Lie algebra) and an ideal, under certain conditions. These concepts\nmay assist in classifying all multiplicative Lie algebras (or Lie algebras) of\na specified order (or dimension).","main_category":"math.GR","categories":"math.GR","published":"2025-04-17T07:06:50Z"}
{"aid":"http://arxiv.org/abs/2504.12703v1","title":"Spike-Kal: A Spiking Neuron Network Assisted Kalman Filter","summary":"Kalman filtering can provide an optimal estimation of the system state from\nnoisy observation data. This algorithm's performance depends on the accuracy of\nsystem modeling and noise statistical characteristics, which are usually\nchallenging to obtain in practical applications. The powerful nonlinear\nmodeling capabilities of deep learning, combined with its ability to extract\nfeatures from large amounts of data automatically, offer new opportunities for\nimproving the Kalman filter. This paper proposes a novel method that leverages\nthe Spiking Neural Network to optimize the Kalman filter. Our approach aims to\nreduce the reliance on prior knowledge of system and observation noises,\nallowing for adaptation to varying statistical characteristics of time-varying\nnoise. Furthermore, we investigate the potential of SNNs in improving the\ncomputational efficiency of the Kalman filter. In our method, we design an\nintegration strategy between the SNN and the Kalman filter. The SNN is trained\nto directly approximate the optimal gain matrix from observation data, thereby\nalleviating the computational burden of complex matrix operations inherent in\ntraditional Kalman filtering while maintaining the accuracy and robustness of\nstate estimation. Its average error has been reduced by 18\\%-65\\% compared with\nother methods.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-17T07:16:54Z"}
{"aid":"http://arxiv.org/abs/2504.12711v1","title":"NTIRE 2025 Challenge on Day and Night Raindrop Removal for Dual-Focused\n  Images: Methods and Results","summary":"This paper reviews the NTIRE 2025 Challenge on Day and Night Raindrop Removal\nfor Dual-Focused Images. This challenge received a wide range of impressive\nsolutions, which are developed and evaluated using our collected real-world\nRaindrop Clarity dataset. Unlike existing deraining datasets, our Raindrop\nClarity dataset is more diverse and challenging in degradation types and\ncontents, which includes day raindrop-focused, day background-focused, night\nraindrop-focused, and night background-focused degradations. This dataset is\ndivided into three subsets for competition: 14,139 images for training, 240\nimages for validation, and 731 images for testing. The primary objective of\nthis challenge is to establish a new and powerful benchmark for the task of\nremoving raindrops under varying lighting and focus conditions. There are a\ntotal of 361 participants in the competition, and 32 teams submitting valid\nsolutions and fact sheets for the final testing phase. These submissions\nachieved state-of-the-art (SOTA) performance on the Raindrop Clarity dataset.\nThe project can be found at\nhttps://lixinustc.github.io/CVPR-NTIRE2025-RainDrop-Competition.github.io/.","main_category":"cs.CV","categories":"cs.CV,cs.AI,eess.IV","published":"2025-04-17T07:35:35Z"}
{"aid":"http://arxiv.org/abs/2504.12737v1","title":"Chinese-Vicuna: A Chinese Instruction-following Llama-based Model","summary":"Chinese-Vicuna is an open-source, resource-efficient language model designed\nto bridge the gap in Chinese instruction-following capabilities by fine-tuning\nMeta's LLaMA architecture using Low-Rank Adaptation (LoRA). Targeting\nlow-resource environments, it enables cost-effective deployment on consumer\nGPUs (e.g., RTX-2080Ti for 7B models) and supports domain-specific adaptation\nin fields like healthcare and law. By integrating hybrid datasets (BELLE and\nGuanaco) and 4-bit quantization (QLoRA), the model achieves competitive\nperformance in tasks such as translation, code generation, and domain-specific\nQ\\&A. The project provides a comprehensive toolkit for model conversion, CPU\ninference, and multi-turn dialogue interfaces, emphasizing accessibility for\nresearchers and developers. Evaluations indicate competitive performance across\nmedical tasks, multi-turn dialogue coherence, and real-time legal updates.\nChinese-Vicuna's modular design, open-source ecosystem, and community-driven\nenhancements position it as a versatile foundation for Chinese LLM\napplications.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-17T08:27:02Z"}
{"aid":"http://arxiv.org/abs/2504.12738v1","title":"Macroscopic states and operations: a generalized resource theory of\n  coherence","summary":"To understand the emergence of macroscopic irreversibility from microscopic\nreversible dynamics, the idea of coarse-graining plays a fundamental role. In\nthis work, we focus on the concept of macroscopic states, i.e. coarse\nrepresentations of microscopic details, defined as states that can be inferred\nsolely from the outcomes of macroscopic measurements. Building on the theories\nof quantum statistical sufficiency and quantum Bayesian retrodiction, we\ncharacterize macroscopic states through several equivalent formulations,\nranging from algebraic to explicitly constructive. We introduce a hierarchy of\nmacroscopicity-non-decreasing operations and develop a resource theory of\nmicroscopicity that unifies and generalizes existing resource theories of\ncoherence, athermality, purity, and asymmetry. Finally, we introduce the\nconcept of inferential reference frames and reinterpret macroscopic entropy as\na measure of inferential asymmetry, i.e., irretrodictability.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech,math-ph,math.MP","published":"2025-04-17T08:28:09Z"}
{"aid":"http://arxiv.org/abs/2504.12739v1","title":"Mask Image Watermarking","summary":"We present MaskMark, a simple, efficient and flexible framework for image\nwatermarking. MaskMark has two variants: MaskMark-D, which supports global\nwatermark embedding, watermark localization, and local watermark extraction for\napplications such as tamper detection, and MaskMark-ED, which focuses on local\nwatermark embedding and extraction with enhanced robustness in small regions,\nenabling localized image protection. Built upon the classical Encoder-\nDistortion-Decoder training paradigm, MaskMark-D introduces a simple masking\nmechanism during the decoding stage to support both global and local watermark\nextraction. A mask is applied to the watermarked image before extraction,\nallowing the decoder to focus on selected regions and learn local extraction. A\nlocalization module is also integrated into the decoder to identify watermark\nregions during inference, reducing interference from irrelevant content and\nimproving accuracy. MaskMark-ED extends this design by incorporating the mask\ninto the encoding stage as well, guiding the encoder to embed the watermark in\ndesignated local regions for enhanced robustness. Comprehensive experiments\nshow that MaskMark achieves state-of-the-art performance in global watermark\nextraction, local watermark extraction, watermark localization, and\nmulti-watermark embedding. It outperforms all existing baselines, including the\nrecent leading model WAM for local watermarking, while preserving high visual\nquality of the watermarked images. MaskMark is also flexible, by adjusting the\ndistortion layer, it can adapt to different robustness requirements with just a\nfew steps of fine-tuning. Moreover, our approach is efficient and easy to\noptimize, requiring only 20 hours on a single A6000 GPU with just 1/15 the\ncomputational cost of WAM.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T08:29:00Z"}
{"aid":"http://arxiv.org/abs/2504.12748v1","title":"Attack-Defense Trees with Offensive and Defensive Attributes (with\n  Appendix)","summary":"Effective risk management in cybersecurity requires a thorough understanding\nof the interplay between attacker capabilities and defense strategies.\nAttack-Defense Trees (ADTs) are a commonly used methodology for representing\nthis interplay; however, previous work in this domain has only focused on\nanalyzing metrics such as cost, damage, or time from the perspective of the\nattacker. This approach provides an incomplete view of the system, as it\nneglects to model defender attributes: in real-world scenarios, defenders have\nfinite resources for countermeasures and are similarly constrained. In this\npaper, we propose a novel framework that incorporates defense metrics into\nADTs, and we present efficient algorithms for computing the Pareto front\nbetween defense and attack metrics. Our methods encode both attacker and\ndefender metrics as semirings, allowing our methods to be used for many metrics\nsuch as cost, damage, and skill. We analyze tree-structured ADTs using a\nbottom-up approach and general ADTs by translating them into binary decision\ndiagrams. Experiments on randomly generated ADTS demonstrate that both\napproaches effectively handle ADTs with several hundred nodes.","main_category":"cs.CR","categories":"cs.CR,cs.GT","published":"2025-04-17T08:41:07Z"}
{"aid":"http://arxiv.org/abs/2504.12754v1","title":"A tight consecutive measurement theorem and its applications","summary":"In many cryptographic tasks, we encounter scenarios where information about\ntwo incompatible observables must be retrieved. A natural approach is to\nperform consecutive measurements, raising a key question: How does the\ninformation gained from the first measurement compare to that from both? The\nconsecutive measurement theorem provides a general relation between these\nquantities and has been used in quantum proofs of knowledge and nonlocal games.\nHowever, its previous formulations are often too loose to yield meaningful\nbounds, especially in quantum nonlocal games. Here, we establish a tight\nversion of the theorem and apply it to improve the best-known bounds on the\nquantum value of $\\text{CHSH}_q(p)$ games and their parallel repetition. We\nalso present a novel application of the theorem to obtain a tighter trade-offs\nbound in quantum oblivious transfer for certain regimes. These results enhance\nthe theoretical tools for analyzing quantum advantage and have concrete\nimplications for nonlocal games and quantum cryptographic protocols.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T08:47:29Z"}
{"aid":"http://arxiv.org/abs/2504.12763v1","title":"Single Complex-Frequency Resonance Mode in an Engineered Disordered\n  Time-Varying Cavity","summary":"We propose a straightforward mechanism for achieving unique $k$-space\nresonance modes in one-dimensional time-varying cavities where periodic\ntemporal modulation creates momentum band gaps through Floquet dynamics. By\nengineering the synergy between cavity resonance conditions and Floquet mode\nformation in photonic time crystals, we demonstrate the emergence of a single\ndominant momentum state that exhibits remarkable robustness against temporal\ndisorder. Through analytical modeling and numerical verification, we show that\nthe interplay between time-varying medium and cavity boundary conditions leads\nto amplification of specific waves followed by spatial mode selection. This\nengineered resonance mechanism enables insensitivity to initial wave source\nconfiguration and strong temporal disorder immunity. Our findings give a simple\nmechanism for exploiting narrow momentum bandgaps, and establish a foundation\nfor developing high-quality temporal cavity lasers and advancing extreme\ntemporal predictability in time-modulated systems.","main_category":"physics.optics","categories":"physics.optics,cond-mat.dis-nn","published":"2025-04-17T09:00:32Z"}
{"aid":"http://arxiv.org/abs/2504.12792v1","title":"Open Loop Layout Optimization: Feasible Path Planning and Exact\n  Door-to-Door Distance Calculation","summary":"The Open Loop Layout Problem (OLLP) seeks to position rectangular cells of\nvarying dimensions on a plane without overlap, minimizing transportation costs\ncomputed as the flow-weighted sum of pairwise distances between cells. A key\nchallenge in OLLP is to compute accurate inter-cell distances along feasible\npaths that avoid rectangle intersections. Existing approaches approximate\ninter-cell distances using centroids, a simplification that can ignore physical\nconstraints, resulting in infeasible layouts or underestimated distances. This\nstudy proposes the first mathematical model that incorporates exact\ndoor-to-door distances and feasible paths under the Euclidean metric, with cell\ndoors acting as pickup and delivery points. Feasible paths between doors must\neither follow rectangle edges as corridors or take direct, unobstructed routes.\nTo address the NP-hardness of the problem, we present a metaheuristic framework\nwith a novel encoding scheme that embeds exact path calculations. Experiments\non standard benchmark instances confirm that our approach consistently\noutperforms existing methods, delivering superior solution quality and\npractical applicability.","main_category":"math.OC","categories":"math.OC","published":"2025-04-17T09:46:06Z"}
{"aid":"http://arxiv.org/abs/2504.12806v1","title":"A Numerical Gradient Inversion Attack in Variational Quantum\n  Neural-Networks","summary":"The loss landscape of Variational Quantum Neural Networks (VQNNs) is\ncharacterized by local minima that grow exponentially with increasing qubits.\nBecause of this, it is more challenging to recover information from model\ngradients during training compared to classical Neural Networks (NNs). In this\npaper we present a numerical scheme that successfully reconstructs input\ntraining, real-world, practical data from trainable VQNNs' gradients. Our\nscheme is based on gradient inversion that works by combining gradients\nestimation with the finite difference method and adaptive low-pass filtering.\nThe scheme is further optimized with Kalman filter to obtain efficient\nconvergence. Our experiments show that our algorithm can invert even\nbatch-trained data, given the VQNN model is sufficiently over-parameterized.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CR","published":"2025-04-17T10:12:38Z"}
{"aid":"http://arxiv.org/abs/2504.12813v1","title":"Approaching Current Challenges in Developing a Software Stack for Fully\n  Autonomous Driving","summary":"Autonomous driving is a complex undertaking. A common approach is to break\ndown the driving task into individual subtasks through modularization. These\nsub-modules are usually developed and published separately. However, if these\nindividually developed algorithms have to be combined again to form a\nfull-stack autonomous driving software, this poses particular challenges.\nDrawing upon our practical experience in developing the software of TUM\nAutonomous Motorsport, we have identified and derived these challenges in\ndeveloping an autonomous driving software stack within a scientific\nenvironment. We do not focus on the specific challenges of individual\nalgorithms but on the general difficulties that arise when deploying research\nalgorithms on real-world test vehicles. To overcome these challenges, we\nintroduce strategies that have been effective in our development approach. We\nadditionally provide open-source implementations that enable these concepts on\nGitHub. As a result, this paper's contributions will simplify future full-stack\nautonomous driving projects, which are essential for a thorough evaluation of\nthe individual algorithms.","main_category":"cs.RO","categories":"cs.RO,cs.SE","published":"2025-04-17T10:17:24Z"}
{"aid":"http://arxiv.org/abs/2504.12815v1","title":"Notes on optimizing a multi-sensor gradient axion-like particle dark\n  matter search","summary":"Axion-like particles (ALPs) arise from well-motivated extensions to the\nStandard Model and could account for the dark matter. We discuss the scaling of\nthe sensitivity of a galactic ALP dark matter search with the number of\nsensors, especially in the ultra-light mass regime, where the measurement time\nis shorter than the coherence time of the ALP field. We compare multiple\nschemes for daily modulated ALP gradient signals, and show that increasing the\nnumber of sensors from 1 to 2 improves the signal-to-noise ratio (SNR) by a\nfactor of 2-3. For more than two sensors, the SNR increases as the square root\nof the number of sensors. Then, we show that splitting the data into subsets\nand then averaging its Discrete Fourier Transforms (DFTs) is equivalent to the\nDFT of the whole dataset in terms of SNR.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-17T10:18:18Z"}
{"aid":"http://arxiv.org/abs/2504.12871v1","title":"Improvable Students in School Choice","summary":"The Deferred Acceptance algorithm (DA) frequently produces Pareto inefficient\nallocations in school choice problems. While a number of efficient mechanisms\nthat Pareto-dominate DA are available, a normative question remains unexplored:\nwhich students should benefit from efficiency enhancements? We address it by\nintroducing the concept of \\emph{maximally improvable students}, who benefit in\nevery improvement over DA that includes as many students as possible in\nset-inclusion terms. We prove that common mechanisms such as\nEfficiency-Adjusted DA (EADA) and Top Trading Cycles applied to DA (DA+TTC) can\nfall significantly short of this benchmark. These mechanisms may only improve\ntwo maximally-improvable students when up to $n-1$ could benefit. Addressing\nthis limitation, we develop the Maximum Improvement over DA mechanism (MIDA),\nwhich generates an efficient allocation that maximises the number of students\nimproved over DA. We show that MIDA can generate fewer blocking pairs than EADA\nand DA+TTC, demonstrating that its distributional improvements need not come at\nthe cost of high justified envy.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-17T11:57:41Z"}
{"aid":"http://arxiv.org/abs/2504.12888v1","title":"Anemia, weight, and height among children under five in Peru from 2007\n  to 2022: A Panel Data analysis","summary":"Econometrics in general, and Panel Data methods in particular, are becoming\ncrucial in Public Health Economics and Social Policy analysis. In this\ndiscussion paper, we employ a helpful approach of Feasible Generalized Least\nSquares (FGLS) to assess if there are statistically relevant relationships\nbetween hemoglobin (adjusted to sea-level), weight, and height from 2007 to\n2022 in children up to five years of age in Peru. By using this method, we may\nfind a tool that allows us to confirm if the relationships considered between\nthe target variables by the Peruvian agencies and authorities are in the right\ndirection to fight against chronic malnutrition and stunting.","main_category":"q-bio.PE","categories":"q-bio.PE,econ.EM,stat.AP","published":"2025-04-17T12:27:06Z"}
{"aid":"http://arxiv.org/abs/2504.12889v1","title":"RIS-Assisted Beamfocusing in Near-Field IoT Communication Systems: A\n  Transformer-Based Approach","summary":"The massive number of antennas in extremely large aperture array (ELAA)\nsystems shifts the propagation regime of signals in internet of things (IoT)\ncommunication systems towards near-field spherical wave propagation. We propose\na reconfigurable intelligent surfaces (RIS)-assisted beamfocusing mechanism,\nwhere the design of the two-dimensional beam codebook that contains both the\nangular and distance domains is challenging. To address this issue, we\nintroduce a novel Transformer-based two-stage beam training algorithm, which\nincludes the coarse and fine search phases. The proposed mechanism provides a\nfine-grained codebook with enhanced spatial resolution, enabling precise\nbeamfocusing. Specifically, in the first stage, the beam training is performed\nto estimate the approximate location of the device by using a simple codebook,\ndetermining whether it is within the beamfocusing range (BFR) or the\nnone-beamfocusing range (NBFR). In the second stage, by using a more precise\ncodebook, a fine-grained beam search strategy is conducted. Experimental\nresults unveil that the precision of the RIS-assisted beamfocusing is greatly\nimproved. The proposed method achieves beam selection accuracy up to 97% at\nsignal-to-noise ratio (SNR) of 20 dB, and improves 10% to 50% over the baseline\nmethod at different SNRs.","main_category":"eess.SP","categories":"eess.SP,cs.SY,eess.SY","published":"2025-04-17T12:29:10Z"}
{"aid":"http://arxiv.org/abs/2504.12898v1","title":"Information Gain-Guided Causal Intervention for Autonomous Debiasing\n  Large Language Models","summary":"Despite significant progress, recent studies indicate that current large\nlanguage models (LLMs) may still capture dataset biases and utilize them during\ninference, leading to the poor generalizability of LLMs. However, due to the\ndiversity of dataset biases and the insufficient nature of bias suppression\nbased on in-context learning, the effectiveness of previous prior\nknowledge-based debiasing methods and in-context learning based automatic\ndebiasing methods is limited. To address these challenges, we explore the\ncombination of causal mechanisms with information theory and propose an\ninformation gain-guided causal intervention debiasing (IGCIDB) framework. This\nframework first utilizes an information gain-guided causal intervention method\nto automatically and autonomously balance the distribution of\ninstruction-tuning dataset. Subsequently, it employs a standard supervised\nfine-tuning process to train LLMs on the debiased dataset. Experimental results\nshow that IGCIDB can effectively debias LLM to improve its generalizability\nacross different tasks.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T12:39:25Z"}
{"aid":"http://arxiv.org/abs/2504.12950v1","title":"Tensor-monopole-induced topological boundary effects in four-dimensional\n  acoustic metamaterials","summary":"Gauge field theory provides the mathematical and conceptual framework to\ndescribe and understand topological singularities such as Weyl points and\nmagnetic monopoles. While singularities associated with vector electromagnetic\ngauge fields have been well-studied, those of higher-form tensor gauge fields,\nlike the four-dimensional (4D) tensor monopoles predicted by string theory,\nhave remained largely theoretical or limited to experimental demonstration in\npure synthetic dimensions, thereby not allowing investigations of the\nassociated boundary effects. Here, we present a 4D system with tensor monopoles\nusing engineered acoustic metamaterials. Our momentum space combines three real\nmomentum dimensions and a geometric parameter as the fourth. By varying this\nfourth momentum, we experimentally reveal two distinct topological surface\nstates in 3D subsystems: Fermi-arc surface states in a gapless subsystem and\nDirac-cone surface states in a gapped subsystem. Our work introduces a novel\nplatform for exploring new topological structures associated with tensor gauge\nfield and topological phenomena in higher dimensions.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-17T13:51:50Z"}
{"aid":"http://arxiv.org/abs/2504.12960v1","title":"A uniform particle approximation to the Navier-Stokes-alpha models in\n  three dimensions with advection noise","summary":"In this work, we investigate a system of interacting particles governed by a\nset of stochastic differential equations. Our main goal is to rigorously\ndemonstrate that the empirical measure associated with the particle system\nconverges uniformly, both in time and space, to the solution of the three\ndimensional Navier Stokes alpha model with advection noise. This convergence\nestablishes a probabilistic framework for deriving macroscopic stochastic fluid\nequations from underlying microscopic dynamics. The analysis leverages\nsemigroup techniques to address the nonlinear structure of the limiting\nequations, and we provide a detailed treatment of the well posedness of the\nlimiting stochastic partial differential equation. This ensures that the\nparticle approximation remains stable and controlled over time. Although\nsimilar convergence results have been obtained in two dimensional settings, our\nstudy presents the first proof of strong uniform convergence in three\ndimensions for a stochastic fluid model derived from an interacting particle\nsystem. Importantly, our results also yield new insights in the deterministic\nregime, namely, in the absence of advection noise, where this type of\nconvergence had not been previously established.","main_category":"math.PR","categories":"math.PR","published":"2025-04-17T14:06:33Z"}
{"aid":"http://arxiv.org/abs/2504.12983v1","title":"Adaptive Modeling of Correlated Noise in Space-Based Gravitational Wave\n  Detectors","summary":"Accurately estimating the statistical properties of noise is important in\nspace-based gravitational wave data analysis. Traditional methods often assume\nuncorrelated noise or impose restrictive parametric forms on cross-channel\ncorrelations, which could lead to biased estimation in complex instrumental\nnoise. This paper introduces a spline-based framework with trans-dimensional\nBayesian inference to reconstruct the full noise covariance matrix, including\nfrequency-dependent auto- and cross-power spectral densities, without prior\nassumptions on noise shapes. The developed software $\\mathtt{NOISAR}$ can\nrecover the features of the noise power spectrum curves with a relative error\n$\\leq 10\\%$ for both auto- and cross-one.","main_category":"astro-ph.IM","categories":"astro-ph.IM,gr-qc","published":"2025-04-17T14:41:56Z"}
{"aid":"http://arxiv.org/abs/2504.12986v1","title":"Large global solutions to the Oldroyd-B model with dissipation","summary":"In the first part of this work, we investigate the Cauchy problem for the\n$d$-dimensional incompressible Oldroyd-B model with dissipation in the stress\ntensor equation. By developing a weighted Chemin-Lerner framework combined with\na refined energy argument, we prove the existence and uniqueness of global\nsolutions for the system under a mild constraint on the initial velocity field,\nwhile allowing a broad class of large initial data for the stress tensor.\nNotably, our analysis accommodates general divergence-free initial stress\ntensors ( $\\mathrm{div}\\tau_0=0$) and significantly relaxes the requirements on\ninitial velocities compared to classical fluid models. This stands in sharp\ncontrast to the finite-time singularity formation observed in the\nincompressible Euler equations, even for small initial data, thereby\nhighlighting the intrinsic stabilizing role of the stress tensor in polymeric\nfluid dynamics.\n  The second part of this paper focuses on the small-data regime. Through a\nsystematic exploitation of the perturbative structure of the system, we\nestablish global well-posedness and quantify the long-time behavior of\nsolutions in Sobolev spaces\n  $H^3(\\mathbb{T}^d)$. Specifically, we derive exponential decay rates for\nperturbations, demonstrating how the dissipative mechanisms inherent to the\nOldroyd-B model govern the asymptotic stability of the system.","main_category":"math.AP","categories":"math.AP","published":"2025-04-17T14:48:42Z"}
{"aid":"http://arxiv.org/abs/2504.12992v1","title":"Enhancing Cocoa Pod Disease Classification via Transfer Learning and\n  Ensemble Methods: Toward Robust Predictive Modeling","summary":"This study presents an ensemble-based approach for cocoa pod disease\nclassification by integrating transfer learning with three ensemble learning\nstrategies: Bagging, Boosting, and Stacking. Pre-trained convolutional neural\nnetworks, including VGG16, VGG19, ResNet50, ResNet101, InceptionV3, and\nXception, were fine-tuned and employed as base learners to detect three disease\ncategories: Black Pod Rot, Pod Borer, and Healthy. A balanced dataset of 6,000\ncocoa pod images was curated and augmented to ensure robustness against\nvariations in lighting, orientation, and disease severity. The performance of\neach ensemble method was evaluated using accuracy, precision, recall, and\nF1-score. Experimental results show that Bagging consistently achieved superior\nclassification performance with a test accuracy of 100%, outperforming Boosting\n(97%) and Stacking (92%). The findings confirm that combining transfer learning\nwith ensemble techniques improves model generalization and reliability, making\nit a promising direction for precision agriculture and automated crop disease\nmanagement.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T15:02:27Z"}
{"aid":"http://arxiv.org/abs/2504.13010v1","title":"Simultaneous Polysomnography and Cardiotocography Reveal Temporal\n  Correlation Between Maternal Obstructive Sleep Apnea and Fetal Hypoxia","summary":"Background: Obstructive sleep apnea syndrome (OSAS) during pregnancy is\ncommon and can negatively affect fetal outcomes. However, studies on the\nimmediate effects of maternal hypoxia on fetal heart rate (FHR) changes are\nlacking. Methods: We used time-synchronized polysomnography (PSG) and\ncardiotocography (CTG) data from two cohorts to analyze the correlation between\nmaternal hypoxia and FHR changes (accelerations or decelerations). Maternal\nhypoxic event characteristics were analyzed using generalized linear modeling\n(GLM) to assess their associations with different FHR changes. Results: A total\nof 118 pregnant women participated. FHR changes were significantly associated\nwith maternal hypoxia, primarily characterized by accelerations. A longer\nhypoxic duration correlated with more significant FHR accelerations (P < 0.05),\nwhile prolonged hypoxia and greater SpO2 drop were linked to FHR decelerations\n(P < 0.05). Both cohorts showed a transient increase in FHR during maternal\nhypoxia, which returned to baseline after the event resolved. Conclusion:\nMaternal hypoxia significantly affects FHR, suggesting that maternal OSAS may\ncontribute to fetal hypoxia. These findings highlight the importance of\nmaternal-fetal interactions and provide insights for future interventions.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-17T15:17:14Z"}
{"aid":"http://arxiv.org/abs/2504.13019v1","title":"The higher regularity of the discrete Hardy-Littlewood maximal function","summary":"In a recent short note the first author \\cite{tem} gave the first positive\nresult on the higher order regularity of the discrete noncentered\nHardy-Littlewood maximal function. In this article we conduct a thorough\ninvestigation of possible similar results for higher order derivatives. We\nuncover that such results are indeed a consequence of a stronger phenomenon\nregarding the growth of $l^p(\\Z)$ norms of the derivatives of characteristic\nfunctions of finite subsets of $\\Z$. Along the way we discover very interesting\nconnections to Prouhot-Tarry-Escott (PTE) problem, and to zeros of complex\npolynomials with restricted coefficients (Littlewood-type polynomials).","main_category":"math.CA","categories":"math.CA","published":"2025-04-17T15:26:48Z"}
{"aid":"http://arxiv.org/abs/2504.13065v1","title":"EchoWorld: Learning Motion-Aware World Models for Echocardiography Probe\n  Guidance","summary":"Echocardiography is crucial for cardiovascular disease detection but relies\nheavily on experienced sonographers. Echocardiography probe guidance systems,\nwhich provide real-time movement instructions for acquiring standard plane\nimages, offer a promising solution for AI-assisted or fully autonomous\nscanning. However, developing effective machine learning models for this task\nremains challenging, as they must grasp heart anatomy and the intricate\ninterplay between probe motion and visual signals. To address this, we present\nEchoWorld, a motion-aware world modeling framework for probe guidance that\nencodes anatomical knowledge and motion-induced visual dynamics, while\neffectively leveraging past visual-motion sequences to enhance guidance\nprecision. EchoWorld employs a pre-training strategy inspired by world modeling\nprinciples, where the model predicts masked anatomical regions and simulates\nthe visual outcomes of probe adjustments. Built upon this pre-trained model, we\nintroduce a motion-aware attention mechanism in the fine-tuning stage that\neffectively integrates historical visual-motion data, enabling precise and\nadaptive probe guidance. Trained on more than one million ultrasound images\nfrom over 200 routine scans, EchoWorld effectively captures key\nechocardiographic knowledge, as validated by qualitative analysis. Moreover,\nour method significantly reduces guidance errors compared to existing visual\nbackbones and guidance frameworks, excelling in both single-frame and\nsequential evaluation protocols. Code is available at\nhttps://github.com/LeapLabTHU/EchoWorld.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T16:19:05Z"}
{"aid":"http://arxiv.org/abs/2504.13069v1","title":"Early Accessibility: Automating Alt-Text Generation for UI Icons During\n  App Development","summary":"Alt-text is essential for mobile app accessibility, yet UI icons often lack\nmeaningful descriptions, limiting accessibility for screen reader users.\nExisting approaches either require extensive labeled datasets, struggle with\npartial UI contexts, or operate post-development, increasing technical debt. We\nfirst conduct a formative study to determine when and how developers prefer to\ngenerate icon alt-text. We then explore the ALTICON approach for generating\nalt-text for UI icons during development using two fine-tuned models: a\ntext-only large language model that processes extracted UI metadata and a\nmulti-modal model that jointly analyzes icon images and textual context. To\nimprove accuracy, the method extracts relevant UI information from the DOM\ntree, retrieves in-icon text via OCR, and applies structured prompts for\nalt-text generation. Our empirical evaluation with the most closely related\ndeep-learning and vision-language models shows that ALTICON generates alt-text\nthat is of higher quality while not requiring a full-screen input.","main_category":"cs.SE","categories":"cs.SE,cs.HC","published":"2025-04-17T16:31:05Z"}
{"aid":"http://arxiv.org/abs/2504.13088v1","title":"Imperative MPC: An End-to-End Self-Supervised Learning with\n  Differentiable MPC for UAV Attitude Control","summary":"Modeling and control of nonlinear dynamics are critical in robotics,\nespecially in scenarios with unpredictable external influences and complex\ndynamics. Traditional cascaded modular control pipelines often yield suboptimal\nperformance due to conservative assumptions and tedious parameter tuning. Pure\ndata-driven approaches promise robust performance but suffer from low sample\nefficiency, sim-to-real gaps, and reliance on extensive datasets. Hybrid\nmethods combining learning-based and traditional model-based control in an\nend-to-end manner offer a promising alternative. This work presents a\nself-supervised learning framework combining learning-based inertial odometry\n(IO) module and differentiable model predictive control (d-MPC) for Unmanned\nAerial Vehicle (UAV) attitude control. The IO denoises raw IMU measurements and\npredicts UAV attitudes, which are then optimized by MPC for control actions in\na bi-level optimization (BLO) setup, where the inner MPC optimizes control\nactions and the upper level minimizes discrepancy between real-world and\npredicted performance. The framework is thus end-to-end and can be trained in a\nself-supervised manner. This approach combines the strength of learning-based\nperception with the interpretable model-based control. Results show the\neffectiveness even under strong wind. It can simultaneously enhance both the\nMPC parameter learning and IMU prediction performance.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-17T16:55:34Z"}
{"aid":"http://arxiv.org/abs/2504.13089v1","title":"Absorption of Fermionic Dark Matter in the PICO-60 C$_{3}$F$_{8}$ Bubble\n  Chamber","summary":"Fermionic dark matter absorption on nuclear targets via neutral current\ninteractions is explored using a non-relativistic effective field theory\nframework. An analysis of data from the PICO-60 C$_{3}$F$_{8}$ bubble chamber\nsets leading constraints on spin-independent absorption for dark matter masses\nbelow 23 MeV/$\\textit{c}^2$ and establishes the first limits on spin-dependent\nabsorptive interactions. These results demonstrate the sensitivity of bubble\nchambers to low-mass dark matter and underscore the importance of absorption\nsearches in expanding the parameter space of direct detection experiments.","main_category":"hep-ex","categories":"hep-ex,hep-ph","published":"2025-04-17T16:55:46Z"}
{"aid":"http://arxiv.org/abs/2504.13098v1","title":"Irradiation Studies of the Resistive AC-coupled Silicon Detector\n  (RSD/AC-LGAD)","summary":"Resistive AC-coupled Silicon Detectors (RSDs) are silicon sensors which\nprovide high temporal and spatial resolution. The RSD is a candidate sensor to\nbe used in future tracking detectors with the objective of obtaining '4D'\ntracking, where timing information can be used along with spatial hits during\ntrack finding. 4D tracking will be an essential part of any future lepton or\nhadron collider and may even be feasible at the HL-LHC. For applications at\nhadron colliders, RSD sensors must be able to operate in high fluence\nenvironments in order to provide 4D tracking. However, the effects of radiation\non RSDs have not been extensively studied. In this study, RSDs were irradiated\nto $1.0$, $2.0$, and $3.5 \\times 10^{15}$~cm$^{-2}$ (1~MeV neutron equivalents)\nwith both protons and neutrons. The sensors were then characterized\nelectrically to study the acceptor removal and, for the first time in this\ndoping concentration range, the donor removal. Then, the Transient Current\nTechnique was used to begin investigating the signal charge sharing after\nirradiation. The results suggest an interesting trend between acceptor and\ndonor removal, which is worthy of further study and could assist in improving\nradiation hardness of Low Gain Avalanche Diodes (LGADs).","main_category":"physics.ins-det","categories":"physics.ins-det,hep-ex","published":"2025-04-17T17:07:20Z"}
{"aid":"http://arxiv.org/abs/2504.13140v1","title":"PCBEAR: Pose Concept Bottleneck for Explainable Action Recognition","summary":"Human action recognition (HAR) has achieved impressive results with deep\nlearning models, but their decision-making process remains opaque due to their\nblack-box nature. Ensuring interpretability is crucial, especially for\nreal-world applications requiring transparency and accountability. Existing\nvideo XAI methods primarily rely on feature attribution or static textual\nconcepts, both of which struggle to capture motion dynamics and temporal\ndependencies essential for action understanding. To address these challenges,\nwe propose Pose Concept Bottleneck for Explainable Action Recognition (PCBEAR),\na novel concept bottleneck framework that introduces human pose sequences as\nmotion-aware, structured concepts for video action recognition. Unlike methods\nbased on pixel-level features or static textual descriptions, PCBEAR leverages\nhuman skeleton poses, which focus solely on body movements, providing robust\nand interpretable explanations of motion dynamics. We define two types of\npose-based concepts: static pose concepts for spatial configurations at\nindividual frames, and dynamic pose concepts for motion patterns across\nmultiple frames. To construct these concepts, PCBEAR applies clustering to\nvideo pose sequences, allowing for automatic discovery of meaningful concepts\nwithout manual annotation. We validate PCBEAR on KTH, Penn-Action, and HAA500,\nshowing that it achieves high classification performance while offering\ninterpretable, motion-driven explanations. Our method provides both strong\npredictive performance and human-understandable insights into the model's\nreasoning process, enabling test-time interventions for debugging and improving\nmodel behavior.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T17:50:07Z"}
{"aid":"http://arxiv.org/abs/2504.13149v1","title":"Long Range Navigator (LRN): Extending robot planning horizons beyond\n  metric maps","summary":"A robot navigating an outdoor environment with no prior knowledge of the\nspace must rely on its local sensing to perceive its surroundings and plan.\nThis can come in the form of a local metric map or local policy with some fixed\nhorizon. Beyond that, there is a fog of unknown space marked with some fixed\ncost. A limited planning horizon can often result in myopic decisions leading\nthe robot off course or worse, into very difficult terrain. Ideally, we would\nlike the robot to have full knowledge that can be orders of magnitude larger\nthan a local cost map. In practice, this is intractable due to sparse sensing\ninformation and often computationally expensive. In this work, we make a key\nobservation that long-range navigation only necessitates identifying good\nfrontier directions for planning instead of full map knowledge. To this end, we\npropose Long Range Navigator (LRN), that learns an intermediate affordance\nrepresentation mapping high-dimensional camera images to `affordable' frontiers\nfor planning, and then optimizing for maximum alignment with the desired goal.\nLRN notably is trained entirely on unlabeled ego-centric videos making it easy\nto scale and adapt to new platforms. Through extensive off-road experiments on\nSpot and a Big Vehicle, we find that augmenting existing navigation stacks with\nLRN reduces human interventions at test-time and leads to faster decision\nmaking indicating the relevance of LRN. https://personalrobotics.github.io/lrn","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-17T17:55:08Z"}
{"aid":"http://arxiv.org/abs/2504.14829v1","title":"$\\mathrm{M}$-ideals: from Banach spaces to rings","summary":"We introduce and investigate a class of ring ideals, termed ring\n$\\mathrm{M}$-ideals, inspired by the Alfsen--Effros theory of\n$\\mathrm{M}$-ideals in Banach spaces. We show that $\\mathrm{M}$-ideals extend\nthe classical notion of essential ideals and subsume them as a subclass. The\ncentral theorem provides a full characterization: an ideal is an\n$\\mathrm{M}$-ideal if and only if it is either essential or relatively\nirreducible. This dichotomy reveals the abundant and diverse nature of\n$\\mathrm{M}$-ideals, encompassing both essential and minimal ideals, and admits\nnatural generalizations in rings beyond the commutative and unital settings.\n  We systematically study the algebraic stability of $\\mathrm{M}$-ideals under\nstandard constructions such as intersection, quotient, direct product, and\nMorita equivalence and establish their behavior in topological rings and\noperator algebras. In certain rings such as $\\mathbb{Z}_n$ and C*-algebras, we\ncompletely classify $\\mathrm{M}$-ideals and relate them to algebraically\nminimal projections and central idempotents. The ring $\\mathrm{M}$-ideals in\n$C(K)$ are shown to be precisely the essential ideals or those minimal ideals\ncorresponding to isolated points.\n  Structurally, we show that the absence of proper $\\mathrm{M}$-ideals\ncharacterizes simplicity, while rings in which every proper $\\mathrm{M}$-ideal\nis a direct summand must decompose as finite direct sums of simple rings. In\nclosing, we introduce the notion of $\\mathrm{M}$-complements, drawing an\nanalogy with essential extensions in module theory, and demonstrate their\nexistence.","main_category":"math.RA","categories":"math.RA","published":"2025-04-21T03:13:39Z"}
{"aid":"http://arxiv.org/abs/2504.14838v1","title":"Establishing Reliability Metrics for Reward Models in Large Language\n  Models","summary":"The reward model (RM) that represents human preferences plays a crucial role\nin optimizing the outputs of large language models (LLMs), e.g., through\nreinforcement learning from human feedback (RLHF) or rejection sampling.\nHowever, a long challenge for RM is its uncertain reliability, i.e., LLM\noutputs with higher rewards may not align with actual human preferences.\nCurrently, there is a lack of a convincing metric to quantify the reliability\nof RMs. To bridge this gap, we propose the \\textit{\\underline{R}eliable at\n\\underline{$\\eta$}} (RETA) metric, which directly measures the reliability of\nan RM by evaluating the average quality (scored by an oracle) of the top $\\eta$\nquantile responses assessed by an RM. On top of RETA, we present an integrated\nbenchmarking pipeline that allows anyone to evaluate their own RM without\nincurring additional Oracle labeling costs. Extensive experimental studies\ndemonstrate the superior stability of RETA metric, providing solid evaluations\nof the reliability of various publicly available and proprietary RMs. When\ndealing with an unreliable RM, we can use the RETA metric to identify the\noptimal quantile from which to select the responses.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-21T03:39:33Z"}
{"aid":"http://arxiv.org/abs/2504.14844v1","title":"Geometric construction of Kashiwara crystals on multiparameter\n  persistence","summary":"We establish a geometric construction of Kashiwara crystals on the\nirreducible components of the varieties of multiparameter persistence modules.\nOur approach differs from the seminal work of Kashiwara and Saito, as well as\nsubsequent related works, by emphasizing commutative relations rather than\npreprojective relations for a given quiver. Furthermore, we provide explicit\ndescriptions of the Kashiwara operators in the fundamental cases of 1- and\n2-parameter persistence modules, offering concrete insights into the crystal\nstructure in these settings.","main_category":"math.RT","categories":"math.RT,math.AG,math.RA","published":"2025-04-21T03:56:47Z"}
{"aid":"http://arxiv.org/abs/2504.14861v1","title":"Stitching Inner Product and Euclidean Metrics for Topology-aware Maximum\n  Inner Product Search","summary":"Maximum Inner Product Search (MIPS) is a fundamental challenge in machine\nlearning and information retrieval, particularly in high-dimensional data\napplications. Existing approaches to MIPS either rely solely on Inner Product\n(IP) similarity, which faces issues with local optima and redundant\ncomputations, or reduce the MIPS problem to the Nearest Neighbor Search under\nthe Euclidean metric via space projection, leading to topology destruction and\ninformation loss. Despite the divergence of the two paradigms, we argue that\nthere is no inherent binary opposition between IP and Euclidean metrics. By\nstitching IP and Euclidean in the design of indexing and search algorithms, we\ncan significantly enhance MIPS performance. Specifically, this paper explores\nthe theoretical and empirical connections between these two metrics from the\nMIPS perspective. Our investigation, grounded in graph-based search, reveals\nthat different indexing and search strategies offer distinct advantages for\nMIPS, depending on the underlying data topology. Building on these insights, we\nintroduce a novel graph-based index called Metric-Amphibious Graph (MAG) and a\ncorresponding search algorithm, Adaptive Navigation with Metric Switch (ANMS).\nTo facilitate parameter tuning for optimal performance, we identify three\nstatistical indicators that capture essential data topology properties and\ncorrelate strongly with parameter tuning. Extensive experiments on 12\nreal-world datasets demonstrate that MAG outperforms existing state-of-the-art\nmethods, achieving up to 4x search speedup while maintaining adaptability and\nscalability.","main_category":"cs.DB","categories":"cs.DB,cs.IR","published":"2025-04-21T05:01:58Z"}
{"aid":"http://arxiv.org/abs/2504.14875v1","title":"ReSpec: Relevance and Specificity Grounded Online Filtering for Learning\n  on Video-Text Data Streams","summary":"The rapid growth of video-text data presents challenges in storage and\ncomputation during training. Online learning, which processes streaming data in\nreal-time, offers a promising solution to these issues while also allowing\nswift adaptations in scenarios demanding real-time responsiveness. One strategy\nto enhance the efficiency and effectiveness of learning involves identifying\nand prioritizing data that enhances performance on target downstream tasks. We\npropose Relevance and Specificity-based online filtering framework (ReSpec)\nthat selects data based on four criteria: (i) modality alignment for clean\ndata, (ii) task relevance for target focused data, (iii) specificity for\ninformative and detailed data, and (iv) efficiency for low-latency processing.\nRelevance is determined by the probabilistic alignment of incoming data with\ndownstream tasks, while specificity employs the distance to a root embedding\nrepresenting the least specific data as an efficient proxy for informativeness.\nBy establishing reference points from target task data, ReSpec filters incoming\ndata in real-time, eliminating the need for extensive storage and compute.\nEvaluating on large-scale datasets WebVid2M and VideoCC3M, ReSpec attains\nstate-of-the-art performance on five zeroshot video retrieval tasks, using as\nlittle as 5% of the data while incurring minimal compute. The source code is\navailable at https://github.com/cdjkim/ReSpec.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-21T06:02:03Z"}
{"aid":"http://arxiv.org/abs/2504.14901v1","title":"Inverse design of ultrathin metamaterial absorber","summary":"Electromagnetic absorbers combining ultrathin profiles with robust\nabsorptivity across wide incidence angles are essential for applications such\nas stealth technology, wireless communications, and quantum computing.\nTraditional designs, including Salisbury screens, typically require thicknesses\nof at least a quarter-wavelength (lambda/4), which limits their use in compact\nsystems. While metamaterial absorbers (MMAs) can reduce thickness, their\nabsorptivity generally decreases under oblique incidence conditions. Here, we\nintroduce an adjoint optimization-based inverse design method that merges the\nultrathin advantage of MMAs with the angle-insensitive characteristics of\nSalisbury screens. By leveraging the computational efficiency of the adjoint\nmethod, we systematically optimize absorber structures as thin as lambda/20.\nThe optimized designs achieve absorption exceeding 90% at the target frequency\nof 7.5 GHz and demonstrate robust performance under oblique incidence,\nmaintaining over 90% absorption up to 50{\\deg}, approximately 80% at 60{\\deg},\nand around 70% at 70{\\deg}. Comparative analysis against particle swarm\noptimization highlights the superior efficiency of the adjoint method, reducing\ncomputational effort by approximately 98%. This inverse design framework thus\nprovides substantial improvements in both performance and computational cost,\noffering a promising approach for advanced electromagnetic absorber design.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-21T07:14:36Z"}
{"aid":"http://arxiv.org/abs/2504.14911v1","title":"Lusztig sheaves, decomposition rule and restriction rule","summary":"In this article, we realize the subquotient based modules of certain tensor\nproducts or restricted modules via Lusztig's perverse sheaves on multi-framed\nquivers, and provide a construction of their canonical bases. As an\napplication, we prove that the decomposition and restriction coefficients of\nsymmetric Kac-Moody algebras equal to the dimensions of top Borel-Moore\nhomology groups for certain locally closed subsets of Nakajima's quiver\nvarieties.","main_category":"math.RT","categories":"math.RT,math.AG,math.QA","published":"2025-04-21T07:31:09Z"}
{"aid":"http://arxiv.org/abs/2504.14929v1","title":"On the Exponential Diophantine Equation $(a^n-1)(b^n-1)=x^2$","summary":"Let $a$ and $b$ be two distinct fixed positive integers such that $\\min\n\\{a,b\\}>1.$ First, we correct an oversight from \\cite{X-Z}. Then, we show that\nthe equation in the title with $b \\equiv 3 \\pmod 8$, $b$ prime and $a$ even has\nno solution in positive integers $n, x$. This generalizes a result of Szalay\n\\cite{L}.","main_category":"math.NT","categories":"math.NT","published":"2025-04-21T07:50:51Z"}
{"aid":"http://arxiv.org/abs/2504.14944v1","title":"Haloscope Searching for Dark Photons at Q-band with a Novel Coupling\n  Tuning Structure","summary":"Laboratory searching for dark matter is crucial for understanding several\nfundamental conundrums in physics and cosmology. Most cavity-based haloscope\nsearches focus on the frequency range below 10 GHz, while the parameter space\nwith higher frequency remains rarely explored, due to the challenges lying in\nthe fabrication of microwave cavities. Here we report the first Q-band\nhaloscope searching for dark photons with a 33.141 GHz cavity. A novel coupling\ntuning structure separated from the cavity was designed so as not to degrade\nthe quality factor of the cavity. We have established the most stringent\nconstraints $\\chi<2.5\\times10^{-12}$ at a confidence level of 90$\\%$ in the\nfrequency range from 33.139 GHz to 33.143 GHz, corresponding to the mass of\ndark photons ranging from 137.05 $\\mu$eV to 137.07 $\\mu$eV. The results surpass\nthe previous astronomical constraints by nearly three orders of magnitude. This\nwork has demonstrated the feasibility of dark matter haloscopes at Q band. In\nthe future, the constraints can be further improved by more than one order of\nmagnitude through low-temperature experiments, and the setup can be extended to\nsearch for axions, axion-like particles, and high-frequency gravitational\nwaves.","main_category":"astro-ph.CO","categories":"astro-ph.CO,hep-ex","published":"2025-04-21T08:08:52Z"}
{"aid":"http://arxiv.org/abs/2504.14945v1","title":"Learning to Reason under Off-Policy Guidance","summary":"Recent advances in large reasoning models (LRMs) demonstrate that\nsophisticated behaviors such as multi-step reasoning and self-reflection can\nemerge via reinforcement learning (RL) with simple rule-based rewards. However,\nexisting zero-RL approaches are inherently ``on-policy'', limiting learning to\na model's own outputs and failing to acquire reasoning abilities beyond its\ninitial capabilities. We introduce LUFFY (Learning to reason Under oFF-policY\nguidance), a framework that augments zero-RL with off-policy reasoning traces.\nLUFFY dynamically balances imitation and exploration by combining off-policy\ndemonstrations with on-policy rollouts during training. Notably, we propose\npolicy shaping via regularized importance sampling to avoid superficial and\nrigid imitation during mixed-policy training. Remarkably, LUFFY achieves an\nover +7.0 average gain across six math benchmarks and an advantage of over +6.2\npoints in out-of-distribution tasks. It also substantially surpasses\nimitation-based supervised fine-tuning (SFT), particularly in generalization.\nAnalysis shows LUFFY not only imitates effectively but also explores beyond\ndemonstrations, offering a scalable path to train generalizable reasoning\nmodels with off-policy guidance.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-21T08:09:13Z"}
{"aid":"http://arxiv.org/abs/2504.14952v1","title":"PIV-FlowDiffuser:Transfer-learning-based denoising diffusion models for\n  PIV","summary":"Deep learning algorithms have significantly reduced the computational time\nand improved the spatial resolution of particle image velocimetry~(PIV).\nHowever, the models trained on synthetic datasets might have a degraded\nperformance on practical particle images due to domain gaps. As a result,\nspecial residual patterns are often observed for the vector fields of deep\nlearning-based estimators. To reduce the special noise step-by-step, we employ\na denoising diffusion model~(FlowDiffuser) for PIV analysis. And the\ndata-hungry iterative denoising diffusion model is trained via a transfer\nlearning strategy, resulting in our PIV-FlowDiffuser method. Specifically, (1)\npre-training a FlowDiffuser model with multiple optical flow datasets of the\ncomputer vision community, such as Sintel, KITTI, etc; (2) fine-tuning the\npre-trained model on synthetic PIV datasets. Note that the PIV images are\nupsampled by a factor of two to resolve the small-scale turbulent flow\nstructures. The visualized results indicate that our PIV-FlowDiffuser\neffectively suppresses the noise patterns. Therefore, the denoising diffusion\nmodel reduces the average end-point error~($AEE$) by 59.4% over RAFT256-PIV\nbaseline on the classic Cai's dataset. Besides, PIV-FlowDiffuser exhibits\nenhanced generalization performance on unseen particle images due to transfer\nlearning. Overall, this study highlights the transfer-learning-based denoising\ndiffusion models for PIV. And a detailed implementation is recommended for\ninterested readers in the repository\nhttps://github.com/Zhu-Qianyu/PIV-FlowDiffuser.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-21T08:22:58Z"}
{"aid":"http://arxiv.org/abs/2504.14965v1","title":"A Security Framework for General Blockchain Layer 2 Protocols","summary":"Layer 2 (L2) solutions are the cornerstone of blockchain scalability,\nenabling high-throughput and low-cost interactions by shifting execution\noff-chain while maintaining security through interactions with the underlying\nledger. Despite their common goals, the principal L2 paradigms -- payment\nchannels, rollups, and sidechains -- differ substantially in architecture and\nassumptions, making it difficult to comparatively analyze their security and\ntrade-offs.\n  To address this, we present the first general security framework for L2\nprotocols. Our framework is based on the IITM-based Universal Composability\n(iUC) framework, in which L2 protocols are modeled as stateful machines\ninteracting with higher-level protocol users and the underlying ledger. The\nmethodology defines a generic execution environment that captures ledger\nevents, message passing, and adversarial scheduling, and characterizes security\nthrough trace-based predicates parameterized by adversarial capabilities and\ntiming assumptions. By abstracting away from protocol-specific details while\npreserving critical interface and execution behavior, the framework enables\nmodular, protocol-agnostic reasoning and composable security proofs across a\nwide range of L2 constructions.\n  To demonstrate its applicability, we analyze an example from each of the\nthree dominant L2 scaling paradigms: a payment channel (Brick), a sidechain\n(Liquid Network), and a rollup (Arbitrum). By instantiating each within our\nframework, we derive their security properties and expose trade-offs. These\ninclude the time for dispute resolution, distribution of off-chain storage and\ncomputation, and varying trust assumptions (e.g., reliance on honest parties or\ndata availability). Our framework unifies the analysis of diverse L2 designs\nand pinpoints their strengths and limitations, providing a foundation for\nsecure, systematic L2 development.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-21T08:48:24Z"}
{"aid":"http://arxiv.org/abs/2504.14973v1","title":"Ultra-diffuse galaxies in the EAGLE simulation","summary":"We use the highest-resolution EAGLE simulation, Recal-L025N0752, to study the\nproperties and formation of ultra-diffuse galaxies (UDGs). We identify 181 UDGs\nand find their properties closely match observations. The total masses of EAGLE\nUDGs range from ${\\sim}5\\times 10^{8}~M_{\\odot}$ to ${\\sim}2\\times\n10^{11}~M_{\\odot}$, indicating that they are dwarf galaxies rather than failed\n$L_\\star$ galaxies. EAGLE UDGs are not a distinct population, but rather a\nsubset of dwarf galaxies, as their properties generally form a continuous\ndistribution with those of normal dwarf galaxies. Unlike the situations in\nprevious studies, the extended sizes of field UDGs in EAGLE are not driven by\nhigh halos spin or by supernova-induced stellar expansion, but instead largely\narise from high spins in their star-forming gas and thus the newly formed stars\nat large radii. This might be attributed to galactic fountains, by which\nstar-forming gas are launched to large halo-centric distances and acquire\nadditional angular momentum through interactions with the circumgalactic\nmedium.For satellite UDGs, ${\\sim} 60 \\%$ of them were already UDGs before\nfalling into the host galaxy, while the remaining ${\\sim} 40\\%$ were normal\ngalaxies prior to infall and subsequently transformed into UDGs due to tidal\neffects after infall.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-21T09:00:01Z"}
{"aid":"http://arxiv.org/abs/2504.14980v1","title":"Bayesian model selection of Primordial Black Holes and Dressed\n  Primordial Black Holes with lensed Gravitational Waves","summary":"If particle dark matter (DM) and primordial black holes (PBHs) coexist, PBHs\nwill be surrounded by particle DM, forming celestial objects known as dressed\nPBHs (dPBHs). These structures suggest a scenario in which PBHs and DM can\nexist simultaneously. However, in the high-frequency regime, the gravitational\nlensing effect of bare PBHs is similar to that of dPBHs. Ground-based\ngravitational wave (GW) detectors are particularly sensitive to high-frequency\nGW signals. In this regime, the lensing effect of a point-mass lens with a mass\nin the range of $10^{-1} \\sim 10^2 M_{\\odot}$ becomes significant. In this\nwork, we incorporate dPBH models with GW observations and employ Bayesian\ninference techniques to distinguish PBHs from dPBHs. Using the third-generation\nground-based GW detectors, Einstein Telescope (ET) and Cosmic Explorer (CE), as\nexamples, we demonstrate that these detectors can effectively differentiate the\nlensing effects of dPBHs from those of PBHs across a broad frequency range.\nFurthermore, we find that with a larger black hole (BH) mass inside the\nsurrounding particle DM, ET and CE can distinguish these two lensed models with\neven greater precision.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-21T09:14:59Z"}
{"aid":"http://arxiv.org/abs/2504.14993v1","title":"Dual Utilization of Perturbation for Stream Data Publication under Local\n  Differential Privacy","summary":"Stream data from real-time distributed systems such as IoT, tele-health, and\ncrowdsourcing has become an important data source. However, the collection and\nanalysis of user-generated stream data raise privacy concerns due to the\npotential exposure of sensitive information. To address these concerns, local\ndifferential privacy (LDP) has emerged as a promising standard. Nevertheless,\napplying LDP to stream data presents significant challenges, as stream data\noften involves a large or even infinite number of values. Allocating a given\nprivacy budget across these data points would introduce overwhelming LDP noise\nto the original stream data.\n  Beyond existing approaches that merely use perturbed values for estimating\nstatistics, our design leverages them for both perturbation and estimation.\nThis dual utilization arises from a key observation: each user knows their own\nground truth and perturbed values, enabling a precise computation of the\ndeviation error caused by perturbation. By incorporating this deviation into\nthe perturbation process of subsequent values, the previous noise can be\ncalibrated. Following this insight, we introduce the Iterative Perturbation\nParameterization (IPP) method, which utilizes current perturbed results to\ncalibrate the subsequent perturbation process. To enhance the robustness of\ncalibration and reduce sensitivity, two algorithms, namely Accumulated\nPerturbation Parameterization (APP) and Clipped Accumulated Perturbation\nParameterization (CAPP) are further developed. We prove that these three\nalgorithms satisfy $w$-event differential privacy while significantly improving\nutility. Experimental results demonstrate that our techniques outperform\nstate-of-the-art LDP stream publishing solutions in terms of utility, while\nretaining the same privacy guarantee.","main_category":"cs.CR","categories":"cs.CR,cs.DB","published":"2025-04-21T09:51:18Z"}
{"aid":"http://arxiv.org/abs/2504.15008v1","title":"New horizon in particle physics: First observation of CP violation in\n  baryon decays","summary":"Recently, the LHCb Collaboration achieved the observation of CP violation\n(CPV) in baryon decays through the process of $\\Lambda_b^0\\to pK^-\\pi^+\\pi^-$,\nreporting an asymmetry of $(2.45\\pm0.46\\pm0.10)\\%$ with a significance of\n5.2$\\sigma$. This marks a breakthrough and a milestone in particle physics, six\ndecades after the first observation of CPV in mesons. It will be helpful to\nunderstand the matter-antimatter asymmetry in the universe. In addition to the\nglobal CPV, local CPV is also observed by LHCb in the low mass region of\n$m_{p\\pi^+\\pi^-}<2.7$GeV as $(5.4\\pm0.9\\pm0.1)\\%$ with a significance of\n6.0$\\sigma$. Intriguingly, this measurement aligns well with a theoretical\nprediction of $(5.6-5.9)\\%$ based on a CPV dynamics using the data of $N\\pi\\to\np\\pi^+\\pi^-$ scatterings. Since baryons contain one more quark than mesons, the\ndynamics of baryon decays are significantly different from those of mesons.\nTherefore, the first observation of baryon CPV by LHCb opens a new horizon in\nthe studies of dynamics of the strong interaction.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-21T10:16:40Z"}
{"aid":"http://arxiv.org/abs/2504.15020v1","title":"Fickian Yet non-Gaussian Diffusion in Complex Molecular Fluids via a\n  non-local diffusion framework","summary":"Fickian yet non-Gaussian diffusion (FnGD) has gained popularity in the recent\ntimes owing to it's ubiquity in a variety of complex fluids. However, whether\nFnGD can be observed experimentally in molecular fuids is still obscure with\nvery little study in real systems. In this letter, we show existence of FnGD in\nmolecular fluids based on compelling evidence from incoherent quasielastic\nneutron scattering (IQENS). Using a cage-jump diffsion model, we show that\nwhile the approach to Fickianity is exponentially fast, the Gaussianity is\nrestored at a much slower algebraic rate. We propose a non-local diffusion\n(NLD) model to describe a d-dimensional jump-diffusion in FnGD regime and show\ntheir universal applicability in such systems. This study establishes that\ncage-jump diffusion process inevitably lead to FnGD and provides the framework\nof NLD models to explore such diffusion phenomena in any arbitrary dimensions.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech","published":"2025-04-21T11:06:20Z"}
{"aid":"http://arxiv.org/abs/2504.15030v1","title":"Height-Dependent Slow Magnetoacoustic Wave Amplitude and Energy Flux in\n  Sunspot Atmospheres","summary":"Slow magnetoacoustic waves (SMAWs) have been considered in the past as a\npossible candidate for chromospheric heating. This study analyzes 20 active\nregions observed between 2012 and 2016 to examine the amplitude and energy flux\nvariation of SMAWs in the umbral atmosphere. Six different wavelength channels\nfrom the Atmospheric Imaging Assembly onboard the Solar Dynamics Observatory,\ncovering regions from the photosphere to the low corona, were utilized for this\npurpose. The wave amplitude estimations show a gradual increase in 3-minute\noscillation amplitude, peaking between 700--900 km, followed by a steady\ndecrease; at altitudes greater than 1800 km, the amplitude appears to increase\nand then decrease again. The corresponding energy flux, on the other hand,\ndisplays a steady and monotonous decrease with a significant reduction in value\nfrom approximately $3.32 \\pm 0.50~\\mathrm{kW,m^{-2}}$ near the photosphere to\nabout $(6.47 \\pm 3.16) \\times 10^{-4}~\\mathrm{W,m^{-2}}$ at an altitude of 2585\nkm. This decay may be attributed to radiative damping and shock dissipation in\nthe lower altitudes, and thermal conduction and viscosity in the higher\naltitudes. The missing flux is a factor of 3--15 lower than that required to\ncounterbalance the chromospheric radiative losses.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-21T11:35:41Z"}
{"aid":"http://arxiv.org/abs/2504.15052v1","title":"Testing LLMs' Capabilities in Annotating Translations Based on an Error\n  Typology Designed for LSP Translation: First Experiments with ChatGPT","summary":"This study investigates the capabilities of large language models (LLMs),\nspecifically ChatGPT, in annotating MT outputs based on an error typology. In\ncontrast to previous work focusing mainly on general language, we explore\nChatGPT's ability to identify and categorise errors in specialised\ntranslations. By testing two different prompts and based on a customised error\ntypology, we compare ChatGPT annotations with human expert evaluations of\ntranslations produced by DeepL and ChatGPT itself. The results show that, for\ntranslations generated by DeepL, recall and precision are quite high. However,\nthe degree of accuracy in error categorisation depends on the prompt's specific\nfeatures and its level of detail, ChatGPT performing very well with a detailed\nprompt. When evaluating its own translations, ChatGPT achieves significantly\npoorer results, revealing limitations with self-assessment. These results\nhighlight both the potential and the limitations of LLMs for translation\nevaluation, particularly in specialised domains. Our experiments pave the way\nfor future research on open-source LLMs, which could produce annotations of\ncomparable or even higher quality. In the future, we also aim to test the\npractical effectiveness of this automated evaluation in the context of\ntranslation training, particularly by optimising the process of human\nevaluation by teachers and by exploring the impact of annotations by LLMs on\nstudents' post-editing and translation learning.","main_category":"cs.CL","categories":"cs.CL,eess.AS","published":"2025-04-21T12:21:37Z"}
{"aid":"http://arxiv.org/abs/2504.15057v1","title":"Linear Item-Item Model with Neural Knowledge for Session-based\n  Recommendation","summary":"Session-based recommendation (SBR) aims to predict users' subsequent actions\nby modeling short-term interactions within sessions. Existing neural models\nprimarily focus on capturing complex dependencies for sequential item\ntransitions. As an alternative solution, linear item-item models mainly\nidentify strong co-occurrence patterns across items and support faster\ninference speed. Although each paradigm has been actively studied in SBR, their\nfundamental differences in capturing item relationships and how to bridge these\ndistinct modeling paradigms effectively remain unexplored. In this paper, we\npropose a novel SBR model, namely Linear Item-Item model with Neural Knowledge\n(LINK), which integrates both types of knowledge into a unified linear\nframework. Specifically, we design two specialized components of LINK: (i)\nLinear knowledge-enhanced Item-item Similarity model (LIS), which refines the\nitem similarity correlation via self-distillation, and (ii) Neural\nknowledge-enhanced Item-item Transition model (NIT), which seamlessly\nincorporates complicated neural knowledge distilled from the off-the-shelf\nneural model. Extensive experiments demonstrate that LINK outperforms\nstate-of-the-art linear SBR models across six real-world datasets, achieving\nimprovements of up to 14.78% and 11.04% in Recall@20 and MRR@20 while showing\nup to 813x fewer inference FLOPs. Our code is available at\nhttps://github.com/jin530/LINK.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-21T12:34:57Z"}
{"aid":"http://arxiv.org/abs/2504.15066v1","title":"Chinese-LiPS: A Chinese audio-visual speech recognition dataset with\n  Lip-reading and Presentation Slides","summary":"Incorporating visual modalities to assist Automatic Speech Recognition (ASR)\ntasks has led to significant improvements. However, existing Audio-Visual\nSpeech Recognition (AVSR) datasets and methods typically rely solely on\nlip-reading information or speaking contextual video, neglecting the potential\nof combining these different valuable visual cues within the speaking context.\nIn this paper, we release a multimodal Chinese AVSR dataset, Chinese-LiPS,\ncomprising 100 hours of speech, video, and corresponding manual transcription,\nwith the visual modality encompassing both lip-reading information and the\npresentation slides used by the speaker. Based on Chinese-LiPS, we develop a\nsimple yet effective pipeline, LiPS-AVSR, which leverages both lip-reading and\npresentation slide information as visual modalities for AVSR tasks. Experiments\nshow that lip-reading and presentation slide information improve ASR\nperformance by approximately 8\\% and 25\\%, respectively, with a combined\nperformance improvement of about 35\\%. The dataset is available at\nhttps://kiri0824.github.io/Chinese-LiPS/","main_category":"cs.MM","categories":"cs.MM,cs.AI","published":"2025-04-21T12:51:54Z"}
{"aid":"http://arxiv.org/abs/2504.15074v1","title":"The orientation dynamics of a massive ellipsoid in simple shear flow","summary":"The orientation dynamics of a massive rigid ellipsoid in simple shear flow of\na Newtonian fluid is investigated in detail. The term `massive' refers to\ndominant particle inertia, as characterized by $St \\gg 1$, $St =\n\\dot{\\gamma}l^2\\rho_p/\\nu \\rho_f$ being the Stokes number; here, $\\dot{\\gamma}$\nis the shear rate, $\\nu$ is the kinematic viscosity, $l$ is a characteristic\nellipsoidal dimension (taken to be the longest semi axis), and $\\rho_p$ and\n$\\rho_f$ are the particle and fluid densities, respectively. Fluid inertial\neffects are neglected, so the particle Reynolds number ($Re$) is zero. The\nequations of motion of the ellipsoid in this limit reduce to those governing an\nEuler top, supplemented by a weak viscous torque. The dynamics consists of a\nfast conservative motion on time scales of $O(\\dot{\\gamma}^{-1})$ that, for an\nellipsoid, involves a combination of spin, precession and nutation, and a\nslower component driven by the viscous torque; the latter modulates the angular\nmomentum and rotational kinetic energy on asymptotically longer time scales of\n$O(St{\\dot{\\gamma}}^{-1})$. The separation of time scales for large $St$ allows\nfor use of the method of averaging for a triaxial ellipsoid, to derive an\nautonomous system of ODE's that govern motion on a four-dimensional slow\nmanifold consisting of the three angular momenta and the rotational kinetic\nenergy. There are three fixed points on the slow manifold, with rotation about\nthe shortest axis being stable. The fixed point corresponding to rotation about\nthe longest axis is a saddle point, while intermediate-axis-aligned rotation\ncorresponds to a singular fixed point. For spheroids, the singular fixed point\nmerges with one of the other two, leading to only two fixed points, one a\nstable node and the other a saddle; the former corresponds to rotation about\nthe shorter axis.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-21T13:03:22Z"}
{"aid":"http://arxiv.org/abs/2504.15078v1","title":"High-Precision and Wafer-Scale Transfer Lithography of Commercial\n  Photoresists via Reversible Adhesion for Sustainable Microfabrication on\n  Diverse Substrates","summary":"Photolithography conventionally requires flat and rigid substrates, limiting\nits applications in flexible, curved, and transient electronics. Here, we\nreport a breakthrough approach employing a reversibly adhesion-switchable\nphase-changing polymer to transfer commercial photoresists onto previously\ninaccessible substrates. It achieves wafer-scale (4-inch) transfer with global\nregistration error below 60 microns and support precise patterning on\nsolvent-sensitive, curved, microtextured or delicate surfaces. Combined with\ndry etching, we demonstrated high-resolution patterning of quantum dots and\norganic semiconductors. The process also supports a sustainable dry lift-off\nfor patterning functional materials. The reusability of both the transfer\ncarrier and photoresist introduces a new level of sustainability and\nscalability, establishing a significant advancement in microfabrication. We\nadditionally fabricated a micro-sized UV-photodetector array directly on a\ncurved glass bottle to demonstrate this unprecedented capability.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-21T13:08:04Z"}
{"aid":"http://arxiv.org/abs/2504.15081v1","title":"PID-GM: PID Control with Gain Mapping","summary":"Proportional-Integral-Differential (PID) control is widely used in industrial\ncontrol systems. However, up to now there are at least two open problems\nrelated with PID control. One is to have a comprehensive understanding of its\nrobustness with respect to model uncertainties and disturbances. The other is\nto build intuitive, explicit and mathematically provable guidelines for PID\ngain tuning. In this paper, we introduce a simple nonlinear mapping to\ndetermine PID gains from three auxiliary parameters. By the mapping, PID\ncontrol is shown to be equivalent to a new PD control (serving as a nominal\ncontrol) plus an uncertainty and disturbance compensator (to recover the\nnominal performance). Then PID control can be understood, designed and tuned in\na Two-Degree-of-Freedom (2-DoF) control framework. We discuss some basic\nproperties of the mapping, including the existence, uniqueness and\ninvertibility. Taking as an example the PID control applied to a general\nuncertain second-order plant, we prove by the singular perturbation theory that\nthe closed-loop steady-state and transient performance depends explicitly on\none auxiliary parameter which can be viewed as the virtual singular\nperturbation parameter (SPP) of PID control. All the three PID gains are\nmonotonically decreasing functions of the SPP, indicating that the smaller the\nSPP is, the higher the PID gains are, and the better the robustness of PID\ncontrol is. Simulation and experimental examples are provided to demonstrate\nthe properties of the mapping as well as the effectiveness of the mapping based\nPID gain turning.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-21T13:11:06Z"}
{"aid":"http://arxiv.org/abs/2504.15097v1","title":"Multiwavelength Observations of the Precursors Before the Eruptive X4.9\n  Limb Solar Flare on 25 February, 2014: Current Sheet, Eruptive Filament,\n  Flare and Eruption Onset in the Frame of the Tether-Cutting Magnetic\n  Reconnection Scenario","summary":"We present multiwavelength analysis of the pre-flare phase and onset of the\npowerful X4.9 near-limb eruptive solar flare on February 25, 2014, revealing\nthe tether-cutting (TC) geometry. We aim at determining relationship between\nthe region of pre-flare energy release with the regions where the flare started\nto develop, and to investigate a detailed chronology of energy release during\nthe pre-flare time interval and the beginning of the impulse phase. Using\nX-ray, ultraviolet and radio microwave data we found that the pre-flare energy\nrelease site was compact and localized in the vicinity of TC interaction of\nmagnetic structures near the polarity inversion line. The analysis indicates\nthat a pre-flare current sheet (CS) could be in this region. Good\ncorrespondence between the location of the pre-flare and flare emission sources\nvisible at the very beginning of the impulsive phase is shown. We found\nrelationship between dynamics of the energy release in the pre-flare CS and\nformation of the future flare eruptive structure. The growth of the magnetic\nflux rope was associated with activation of plasma emissions, flows and an\nincrease of UV radiation fluxes from the region where the pre-flare CS was\nlocated. The eruptive flux rope gradually grew due to feeding by magnetized\nplasma ejected from the reconnecting pre-flare CS. Finally, it is shown that\nthe most probable trigger of the eruption was a local fast microflare-like\nmagnetic reconnection in the pre-flare CS. Some local instability in the\npre-flare sheet could lead to a transition from the slow to fast reconnection\nregime. As a result, an ejection from the sheet was initiated and the eruptive\nflux rope lost its stability. Then, the eruptive flux rope itself initiated\nformation of the main reconnecting flare CS as in the Standard Flare Model\nduring its movement, and intense emissions associated with the impulsive phase\nwere observed.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-21T13:37:04Z"}
{"aid":"http://arxiv.org/abs/2504.15129v1","title":"A General Infrastructure and Workflow for Quadrotor Deep Reinforcement\n  Learning and Reality Deployment","summary":"Deploying robot learning methods to a quadrotor in unstructured outdoor\nenvironments is an exciting task. Quadrotors operating in real-world\nenvironments by learning-based methods encounter several challenges: a large\namount of simulator generated data required for training, strict demands for\nreal-time processing onboard, and the sim-to-real gap caused by dynamic and\nnoisy conditions. Current works have made a great breakthrough in applying\nlearning-based methods to end-to-end control of quadrotors, but rarely mention\nthe infrastructure system training from scratch and deploying to reality, which\nmakes it difficult to reproduce methods and applications. To bridge this gap,\nwe propose a platform that enables the seamless transfer of end-to-end deep\nreinforcement learning (DRL) policies. We integrate the training environment,\nflight dynamics control, DRL algorithms, the MAVROS middleware stack, and\nhardware into a comprehensive workflow and architecture that enables\nquadrotors' policies to be trained from scratch to real-world deployment in\nseveral minutes. Our platform provides rich types of environments including\nhovering, dynamic obstacle avoidance, trajectory tracking, balloon hitting, and\nplanning in unknown environments, as a physical experiment benchmark. Through\nextensive empirical validation, we demonstrate the efficiency of proposed\nsim-to-real platform, and robust outdoor flight performance under real-world\nperturbations. Details can be found from our website\nhttps://emnavi.tech/AirGym/.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.CV,cs.LG","published":"2025-04-21T14:25:23Z"}
{"aid":"http://arxiv.org/abs/2504.15145v1","title":"\"I Know It When I See It\": Mood Spaces for Connecting and Expressing\n  Visual Concepts","summary":"Expressing complex concepts is easy when they can be labeled or quantified,\nbut many ideas are hard to define yet instantly recognizable. We propose a Mood\nBoard, where users convey abstract concepts with examples that hint at the\nintended direction of attribute changes. We compute an underlying Mood Space\nthat 1) factors out irrelevant features and 2) finds the connections between\nimages, thus bringing relevant concepts closer. We invent a fibration\ncomputation to compress/decompress pre-trained features into/from a compact\nspace, 50-100x smaller. The main innovation is learning to mimic the pairwise\naffinity relationship of the image tokens across exemplars. To focus on the\ncoarse-to-fine hierarchical structures in the Mood Space, we compute the top\neigenvector structure from the affinity matrix and define a loss in the\neigenvector space. The resulting Mood Space is locally linear and compact,\nallowing image-level operations, such as object averaging, visual analogy, and\npose transfer, to be performed as a simple vector operation in Mood Space. Our\nlearning is efficient in computation without any fine-tuning, needs only a few\n(2-20) exemplars, and takes less than a minute to learn.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T14:49:15Z"}
{"aid":"http://arxiv.org/abs/2504.15151v1","title":"Artificial compressibility method for the incompressible Navier-Stokes\n  equations with variable density","summary":"We introduce a novel artificial compressibility technique to approximate the\nincompressible Navier-Stokes equations with variable fluid properties such as\ndensity and dynamical viscosity. The proposed scheme used the couple pressure\nand momentum, equal to the density times the velocity, as primary unknowns. It\nalso involves an adequate treatment of the diffusive operator such that\ntreating the nonlinear convective term explicitly leads to a scheme with time\nindependent stiffness matrices that is suitable for pseudo-spectral methods.\nThe stability and temporal convergence of the semi-implicit version of the\nscheme is established under the hypothesis that the density is approximated\nwith a method that conserves the minimum-maximum principle. Numerical\nillustrations confirm that both the semi-implicit and explicit scheme are\nstable and converge with order one under classic CFL condition. Moreover, the\nproposed scheme is shown to perform better than a momentum based pressure\nprojection method, previously introduced by one of the authors, on setups\ninvolving gravitational waves and immiscible multi-fluids in a cylinder.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-21T14:55:24Z"}
{"aid":"http://arxiv.org/abs/2504.15171v1","title":"Audio-Visual Class-Incremental Learning for Fish Feeding intensity\n  Assessment in Aquaculture","summary":"Fish Feeding Intensity Assessment (FFIA) is crucial in industrial aquaculture\nmanagement. Recent multi-modal approaches have shown promise in improving FFIA\nrobustness and efficiency. However, these methods face significant challenges\nwhen adapting to new fish species or environments due to catastrophic\nforgetting and the lack of suitable datasets. To address these limitations, we\nfirst introduce AV-CIL-FFIA, a new dataset comprising 81,932 labelled\naudio-visual clips capturing feeding intensities across six different fish\nspecies in real aquaculture environments. Then, we pioneer audio-visual class\nincremental learning (CIL) for FFIA and demonstrate through benchmarking on\nAV-CIL-FFIA that it significantly outperforms single-modality methods. Existing\nCIL methods rely heavily on historical data. Exemplar-based approaches store\nraw samples, creating storage challenges, while exemplar-free methods avoid\ndata storage but struggle to distinguish subtle feeding intensity variations\nacross different fish species. To overcome these limitations, we introduce\nHAIL-FFIA, a novel audio-visual class-incremental learning framework that\nbridges this gap with a prototype-based approach that achieves exemplar-free\nefficiency while preserving essential knowledge through compact feature\nrepresentations. Specifically, HAIL-FFIA employs hierarchical representation\nlearning with a dual-path knowledge preservation mechanism that separates\ngeneral intensity knowledge from fish-specific characteristics. Additionally,\nit features a dynamic modality balancing system that adaptively adjusts the\nimportance of audio versus visual information based on feeding behaviour\nstages. Experimental results show that HAIL-FFIA is superior to SOTA methods on\nAV-CIL-FFIA, achieving higher accuracy with lower storage needs while\neffectively mitigating catastrophic forgetting in incremental fish species\nlearning.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-21T15:24:34Z"}
{"aid":"http://arxiv.org/abs/2504.15201v1","title":"Phase-separated lipid vesicles: continuum modeling, simulation, and\n  validation","summary":"The paper presents a complete research cycle comprising continuum-based\nmodeling, computational framework development, and validation setup to predict\nphase separation and surface hydrodynamics in lipid bilayer membranes. We\nstarting with an overview of the key physical characteristics of lipid\nbilayers, including their composition, mechanical properties, and\nthermodynamics, and then discuss continuum models of multi-component bilayers.\nThe most complex model is a Navier--Stokes--Cahn--Hilliard (NSCH) type system,\ndescribing the coupling of incompressible surface fluid dynamics with\nphase-field dynamics on arbitrarily curved geometries. It is discretized using\ntrace finite element methods, which offer geometric flexibility and stability\nin representing surface PDEs. Numerical studies are conducted to examine\nphysical features such as coarsening rates and interfacial dynamics. The\ncomputational results obtained from the NSCH model are compared against\nexperimental data for membrane compositions with distinct phase behaviors,\ndemonstrating that including both phase-field models and surface hydrodynamics\nis essential to accurately reproduce domain evolution observed in\nepi-fluorescence microscopy. Lastly, we extend the model to incorporate\nexternal forces that enable the simulation of vesicles containing cationic\nlipids, used to enhance membrane fusion.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-21T16:17:39Z"}
{"aid":"http://arxiv.org/abs/2504.15204v1","title":"Soft-Output from Covered Space Decoding of Product Codes","summary":"In this work, we propose a new soft-in soft-out decoder called soft-output\nfrom covered space (SOCS) decoder. It estimates the a posteriori reliability\nbased on the space explored by a list decoder, i.e., the set of vectors for\nwhich the list decoder knows whether they are codewords. This approach enables\na more accurate calculation of the a posteriori reliability and results in\ngains of up to 0.25$\\,$dB for turbo product decoding with SOCS decoding\ncompared to Chase-Pyndiah decoding.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-21T16:20:13Z"}
{"aid":"http://arxiv.org/abs/2504.15220v1","title":"Fully Bayesian Approaches to Topics over Time","summary":"The Topics over Time (ToT) model captures thematic changes in timestamped\ndatasets by explicitly modeling publication dates jointly with word\nco-occurrence patterns. However, ToT was not approached in a fully Bayesian\nfashion, a flaw that makes it susceptible to stability problems. To address\nthis issue, we propose a fully Bayesian Topics over Time (BToT) model via the\nintroduction of a conjugate prior to the Beta distribution. This prior acts as\na regularization that prevents the online version of the algorithm from\nunstable updates when a topic is poorly represented in a mini-batch. The\ncharacteristics of this prior to the Beta distribution are studied here for the\nfirst time. Still, this model suffers from a difference in scale between the\nsingle-time observations and the multiplicity of words per document. A\nvariation of BToT, Weighted Bayesian Topics over Time (WBToT), is proposed as a\nsolution. In WBToT, publication dates are repeated a certain number of times\nper document, which balances the relative influence of words and timestamps\nalong the inference process. We have tested our models on two datasets: a\ncollection of over 200 years of US state-of-the-union (SOTU) addresses and a\nlarge-scale COVID-19 Twitter corpus of 10 million tweets. The results show that\nWBToT captures events better than Latent Dirichlet Allocation and other SOTA\ntopic models like BERTopic: the median absolute deviation of the topic presence\nover time is reduced by $51\\%$ and $34\\%$, respectively. Our experiments also\ndemonstrate the superior coherence of WBToT over BToT, which highlights the\nimportance of balancing the time and word modalities. Finally, we illustrate\nthe stability of the online optimization algorithm in WBToT, which allows the\napplication of WBToT to problems that are intractable for standard ToT.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-21T16:46:07Z"}
{"aid":"http://arxiv.org/abs/2504.15224v1","title":"On Extension modules of finite homological dimension","summary":"We explore the implications of the finiteness of homological dimensions for\nExt modules, focusing on projective dimension, injective dimension, and their\nGorenstein counterpart. In this direction, we establish several finiteness\ncriteria for homological dimensions. Our results include the consequences of\nthe finiteness of the Gorenstein (injective) dimension of the deficiency\nmodules as well as a duality for certain Ext modules, all of finite\n(Gorenstein) projective dimension.","main_category":"math.AC","categories":"math.AC","published":"2025-04-21T16:54:57Z"}
{"aid":"http://arxiv.org/abs/2504.15232v1","title":"Shape-Guided Clothing Warping for Virtual Try-On","summary":"Image-based virtual try-on aims to seamlessly fit in-shop clothing to a\nperson image while maintaining pose consistency. Existing methods commonly\nemploy the thin plate spline (TPS) transformation or appearance flow to deform\nin-shop clothing for aligning with the person's body. Despite their promising\nperformance, these methods often lack precise control over fine details,\nleading to inconsistencies in shape between clothing and the person's body as\nwell as distortions in exposed limb regions. To tackle these challenges, we\npropose a novel shape-guided clothing warping method for virtual try-on, dubbed\nSCW-VTON, which incorporates global shape constraints and additional limb\ntextures to enhance the realism and consistency of the warped clothing and\ntry-on results. To integrate global shape constraints for clothing warping, we\ndevise a dual-path clothing warping module comprising a shape path and a flow\npath. The former path captures the clothing shape aligned with the person's\nbody, while the latter path leverages the mapping between the pre- and\npost-deformation of the clothing shape to guide the estimation of appearance\nflow. Furthermore, to alleviate distortions in limb regions of try-on results,\nwe integrate detailed limb guidance by developing a limb reconstruction network\nbased on masked image modeling. Through the utilization of SCW-VTON, we are\nable to generate try-on results with enhanced clothing shape consistency and\nprecise control over details. Extensive experiments demonstrate the superiority\nof our approach over state-of-the-art methods both qualitatively and\nquantitatively. The code is available at https://github.com/xyhanHIT/SCW-VTON.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T17:08:36Z"}
{"aid":"http://arxiv.org/abs/2504.15263v1","title":"Interpretable Locomotion Prediction in Construction Using a\n  Memory-Driven LLM Agent With Chain-of-Thought Reasoning","summary":"Construction tasks are inherently unpredictable, with dynamic environments\nand safety-critical demands posing significant risks to workers. Exoskeletons\noffer potential assistance but falter without accurate intent recognition\nacross diverse locomotion modes. This paper presents a locomotion prediction\nagent leveraging Large Language Models (LLMs) augmented with memory systems,\naimed at improving exoskeleton assistance in such settings. Using multimodal\ninputs - spoken commands and visual data from smart glasses - the agent\nintegrates a Perception Module, Short-Term Memory (STM), Long-Term Memory\n(LTM), and Refinement Module to predict locomotion modes effectively.\nEvaluation reveals a baseline weighted F1-score of 0.73 without memory, rising\nto 0.81 with STM, and reaching 0.90 with both STM and LTM, excelling with vague\nand safety-critical commands. Calibration metrics, including a Brier Score drop\nfrom 0.244 to 0.090 and ECE from 0.222 to 0.044, affirm improved reliability.\nThis framework supports safer, high-level human-exoskeleton collaboration, with\npromise for adaptive assistive systems in dynamic industries.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-21T17:45:21Z"}
{"aid":"http://arxiv.org/abs/2504.15267v1","title":"Diffusion Bridge Models for 3D Medical Image Translation","summary":"Diffusion tensor imaging (DTI) provides crucial insights into the\nmicrostructure of the human brain, but it can be time-consuming to acquire\ncompared to more readily available T1-weighted (T1w) magnetic resonance imaging\n(MRI). To address this challenge, we propose a diffusion bridge model for 3D\nbrain image translation between T1w MRI and DTI modalities. Our model learns to\ngenerate high-quality DTI fractional anisotropy (FA) images from T1w images and\nvice versa, enabling cross-modality data augmentation and reducing the need for\nextensive DTI acquisition. We evaluate our approach using perceptual\nsimilarity, pixel-level agreement, and distributional consistency metrics,\ndemonstrating strong performance in capturing anatomical structures and\npreserving information on white matter integrity. The practical utility of the\nsynthetic data is validated through sex classification and Alzheimer's disease\nclassification tasks, where the generated images achieve comparable performance\nto real data. Our diffusion bridge model offers a promising solution for\nimproving neuroimaging datasets and supporting clinical decision-making, with\nthe potential to significantly impact neuroimaging research and clinical\npractice.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T17:49:06Z"}
{"aid":"http://arxiv.org/abs/2504.15568v1","title":"Is Learning Effective in Dynamic Strategic Interactions? Evidence from\n  Stackelberg Games","summary":"In many settings of interest, a policy is set by one party, the leader, in\norder to influence the action of another party, the follower, where the\nfollower's response is determined by some private information. A natural\nquestion to ask is, can the leader improve their strategy by learning about the\nunknown follower through repeated interactions? A well known folk theorem from\ndynamic pricing, a special case of this leader-follower setting, would suggest\nthat the leader cannot learn effectively from the follower when the follower is\nfully strategic, leading to a large literature on learning in strategic\nsettings that relies on limiting the strategic space of the follower in order\nto provide positive results. In this paper, we study dynamic Bayesian\nStackelberg games, where a leader and a \\emph{fully strategic} follower\ninteract repeatedly, with the follower's type unknown. Contrary to existing\nresults, we show that the leader can improve their utility through learning in\nrepeated play. Using a novel average-case analysis, we demonstrate that\nlearning is effective in these settings, without needing to weaken the\nfollower's strategic space. Importantly, this improvement is not solely due to\nthe leader's ability to commit, nor does learning simply substitute for\ncommunication between the parties. We provide an algorithm, based on a\nmixed-integer linear program, to compute the optimal leader policy in these\ngames and develop heuristic algorithms to approximate the optimal dynamic\npolicy more efficiently. Through simulations, we compare the efficiency and\nruntime of these algorithms against static policies.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-22T03:44:05Z"}
{"aid":"http://arxiv.org/abs/2504.15583v1","title":"Splitting the diagonal for broken maps","summary":"In previous work, we introduced a version of the Fukaya algebra associated to\na degeneration of a symplectic manifold, whose structure maps count collections\nof maps in the components of the degeneration satisfying matching conditions.\nIn this paper, we introduce a further degeneration of the matching conditions\n(similar in spirit to Bourgeois' version of symplectic field theory) which\nresults in a \"split Fukaya algebra\" whose structure maps are, in good cases,\nsums of products over vertices of tropical graphs. In the case of toric\nLagrangians contained in a toric component of the degeneration, an invariance\nargument implies the existence of projective Maurer-Cartan solutions, which\ngives an alternate proof of the unobstructedness result of Fukaya-Oh-Ohta-Ono\nfor toric manifolds. Our result also proves unobstructedness in more general\ncases, such as for toric Lagrangians in almost toric four-manifolds.","main_category":"math.SG","categories":"math.SG","published":"2025-04-22T04:56:17Z"}
{"aid":"http://arxiv.org/abs/2504.15620v1","title":"Observation of topology of non-Hermitian systems without chiral symmetry","summary":"Topological invariants are crucial for characterizing topological systems.\nHowever, experimentally measuring them presents a significant challenge,\nespecially in non-Hermitian systems where the biorthogonal eigenvectors are\noften necessary. We propose a general approach for measuring the topological\ninvariants of one-dimensional non-Hermitian systems, which can be derived from\nthe spin textures of right eigenstates. By utilizing a dilation method, we\nrealize a non-Hermitian system without chiral symmetry on a two-qubit nuclear\nmagnetic resonance system and measure the winding number associated with the\neigenstates. In addition to examining the topology of the eigenstates, our\nexperiment also reveals the topological structure of the energy band, which\ndiffers from that in chiral systems. Our work paves the way for further\nexploration of complex topological properties in non-Hermitian systems without\nchiral symmetry.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-22T06:21:24Z"}
{"aid":"http://arxiv.org/abs/2504.15622v1","title":"Exploring the Role of Large Language Models in Cybersecurity: A\n  Systematic Survey","summary":"With the rapid development of technology and the acceleration of\ndigitalisation, the frequency and complexity of cyber security threats are\nincreasing. Traditional cybersecurity approaches, often based on static rules\nand predefined scenarios, are struggling to adapt to the rapidly evolving\nnature of modern cyberattacks. There is an urgent need for more adaptive and\nintelligent defence strategies. The emergence of Large Language Model (LLM)\nprovides an innovative solution to cope with the increasingly severe cyber\nthreats, and its potential in analysing complex attack patterns, predicting\nthreats and assisting real-time response has attracted a lot of attention in\nthe field of cybersecurity, and exploring how to effectively use LLM to defend\nagainst cyberattacks has become a hot topic in the current research field. This\nsurvey examines the applications of LLM from the perspective of the cyber\nattack lifecycle, focusing on the three phases of defense reconnaissance,\nfoothold establishment, and lateral movement, and it analyzes the potential of\nLLMs in Cyber Threat Intelligence (CTI) tasks. Meanwhile, we investigate how\nLLM-based security solutions are deployed and applied in different network\nscenarios. It also summarizes the internal and external risk issues faced by\nLLM during its application. Finally, this survey also points out the facing\nrisk issues and possible future research directions in this domain.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-22T06:28:08Z"}
{"aid":"http://arxiv.org/abs/2504.15634v1","title":"Enhancing Reinforcement learning in 3-Dimensional Hydrophobic-Polar\n  Protein Folding Model with Attention-based layers","summary":"Transformer-based architectures have recently propelled advances in sequence\nmodeling across domains, but their application to the hydrophobic-hydrophilic\n(H-P) model for protein folding remains relatively unexplored. In this work, we\nadapt a Deep Q-Network (DQN) integrated with attention mechanisms\n(Transformers) to address the 3D H-P protein folding problem. Our system\nformulates folding decisions as a self-avoiding walk in a reinforced\nenvironment, and employs a specialized reward function based on favorable\nhydrophobic interactions. To improve performance, the method incorporates\nvalidity check including symmetry-breaking constraints, dueling and double\nQ-learning, and prioritized replay to focus learning on critical transitions.\nExperimental evaluations on standard benchmark sequences demonstrate that our\napproach achieves several known best solutions for shorter sequences, and\nobtains near-optimal results for longer chains. This study underscores the\npromise of attention-based reinforcement learning for protein folding, and\ncreated a prototype of Transformer-based Q-network structure for 3-dimensional\nlattice models.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-22T06:53:36Z"}
{"aid":"http://arxiv.org/abs/2504.15649v1","title":"RepNet-VSR: Reparameterizable Architecture for High-Fidelity Video\n  Super-Resolution","summary":"As a fundamental challenge in visual computing, video super-resolution (VSR)\nfocuses on reconstructing highdefinition video sequences from their degraded\nlowresolution counterparts. While deep convolutional neural networks have\ndemonstrated state-of-the-art performance in spatial-temporal super-resolution\ntasks, their computationally intensive nature poses significant deployment\nchallenges for resource-constrained edge devices, particularly in real-time\nmobile video processing scenarios where power efficiency and latency\nconstraints coexist. In this work, we propose a Reparameterizable Architecture\nfor High Fidelity Video Super Resolution method, named RepNet-VSR, for\nreal-time 4x video super-resolution. On the REDS validation set, the proposed\nmodel achieves 27.79 dB PSNR when processing 180p to 720p frames in 103 ms per\n10 frames on a MediaTek Dimensity NPU. The competition results demonstrate an\nexcellent balance between restoration quality and deployment efficiency. The\nproposed method scores higher than the previous champion algorithm of MAI video\nsuper-resolution challenge.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-22T07:15:07Z"}
{"aid":"http://arxiv.org/abs/2504.15659v1","title":"VeriCoder: Enhancing LLM-Based RTL Code Generation through Functional\n  Correctness Validation","summary":"Recent advances in Large Language Models (LLMs) have sparked growing interest\nin applying them to Electronic Design Automation (EDA) tasks, particularly\nRegister Transfer Level (RTL) code generation. While several RTL datasets have\nbeen introduced, most focus on syntactic validity rather than functional\nvalidation with tests, leading to training examples that compile but may not\nimplement the intended behavior. We present VERICODER, a model for RTL code\ngeneration fine-tuned on a dataset validated for functional correctness. This\nfine-tuning dataset is constructed using a novel methodology that combines unit\ntest generation with feedback-directed refinement. Given a natural language\nspecification and an initial RTL design, we prompt a teacher model\n(GPT-4o-mini) to generate unit tests and iteratively revise the RTL design\nbased on its simulation results using the generated tests. If necessary, the\nteacher model also updates the tests to ensure they comply with the natural\nlanguage specification. As a result of this process, every example in our\ndataset is functionally validated, consisting of a natural language\ndescription, an RTL implementation, and passing tests. Fine-tuned on this\ndataset of over 125,000 examples, VERICODER achieves state-of-the-art metrics\nin functional correctness on VerilogEval and RTLLM, with relative gains of up\nto 71.7% and 27.4% respectively. An ablation study further shows that models\ntrained on our functionally validated dataset outperform those trained on\nfunctionally non-validated datasets, underscoring the importance of\nhigh-quality datasets in RTL code generation.","main_category":"cs.AR","categories":"cs.AR,cs.AI,cs.CL,cs.LG,cs.SE","published":"2025-04-22T07:32:46Z"}
{"aid":"http://arxiv.org/abs/2504.15671v1","title":"On the approximation of the Riemannian barycenter","summary":"We present a method to compute an approximate Riemannian barycenter of a\ncollection of points lying on a Riemannian manifold. Our approach relies on the\nuse of theoretically proven under- and overapproximations of the Riemannian\ndistance function. We compare it to the exact computation of the Riemannian\nbarycenter and to an approach that approximates the Riemannian logarithm using\nlifting maps. Experiments are conducted on the Stiefel manifold.","main_category":"math.DG","categories":"math.DG","published":"2025-04-22T07:52:10Z"}
{"aid":"http://arxiv.org/abs/2504.15679v1","title":"Policy-Based Radiative Transfer: Solving the $2$-Level Atom Non-LTE\n  Problem using Soft Actor-Critic Reinforcement Learning","summary":"We present a novel reinforcement learning (RL) approach for solving the\nclassical 2-level atom non-LTE radiative transfer problem by framing it as a\ncontrol task in which an RL agent learns a depth-dependent source function\n$S(\\tau)$ that self-consistently satisfies the equation of statistical\nequilibrium (SE). The agent's policy is optimized entirely via reward-based\ninteractions with a radiative transfer engine, without explicit knowledge of\nthe ground truth. This method bypasses the need for constructing approximate\nlambda operators ($\\Lambda^*$) common in accelerated iterative schemes.\nAdditionally, it requires no extensive precomputed labeled datasets to extract\na supervisory signal, and avoids backpropagating gradients through the complex\nRT solver itself. Finally, we show through experiment that a simple feedforward\nneural network trained greedily cannot solve for SE, possibly due to the moving\ntarget nature of the problem. Our $\\Lambda^*-\\text{Free}$ method offers\npotential advantages for complex scenarios (e.g., atmospheres with enhanced\nvelocity fields, multi-dimensional geometries, or complex microphysics) where\n$\\Lambda^*$ construction or solver differentiability is challenging.\nAdditionally, the agent can be incentivized to find more efficient policies by\nmanipulating the discount factor, leading to a reprioritization of immediate\nrewards. If demonstrated to generalize past its training data, this RL\nframework could serve as an alternative or accelerated formalism to achieve SE.\nTo the best of our knowledge, this study represents the first application of\nreinforcement learning in solar physics that directly solves for a fundamental\nphysical constraint.","main_category":"astro-ph.SR","categories":"astro-ph.SR,cs.LG","published":"2025-04-22T08:03:09Z"}
{"aid":"http://arxiv.org/abs/2504.15681v1","title":"Vidi: Large Multimodal Models for Video Understanding and Editing","summary":"Humans naturally share information with those they are connected to, and\nvideo has become one of the dominant mediums for communication and expression\non the Internet. To support the creation of high-quality large-scale video\ncontent, a modern pipeline requires a comprehensive understanding of both the\nraw input materials (e.g., the unedited footage captured by cameras) and the\nediting components (e.g., visual effects). In video editing scenarios, models\nmust process multiple modalities (e.g., vision, audio, text) with strong\nbackground knowledge and handle flexible input lengths (e.g., hour-long raw\nvideos), which poses significant challenges for traditional models. In this\nreport, we introduce Vidi, a family of Large Multimodal Models (LMMs) for a\nwide range of video understand editing scenarios. The first release focuses on\ntemporal retrieval, i.e., identifying the time ranges within the input videos\ncorresponding to a given text query, which plays a critical role in intelligent\nediting. The model is capable of processing hour-long videos with strong\ntemporal understanding capability, e.g., retrieve time ranges for certain\nqueries. To support a comprehensive evaluation in real-world scenarios, we also\npresent the VUE-TR benchmark, which introduces five key advancements. 1) Video\nduration: significantly longer than existing temporal retrival datasets, 2)\nAudio support: includes audio-based queries, 3) Query format: diverse query\nlengths/formats, 4) Annotation quality: ground-truth time ranges are manually\nannotated. 5) Evaluation metric: a refined IoU metric to support evaluation\nover multiple time ranges. Remarkably, Vidi significantly outperforms leading\nproprietary models, e.g., GPT-4o and Gemini, on the temporal retrieval task,\nindicating its superiority in video editing scenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T08:04:45Z"}
{"aid":"http://arxiv.org/abs/2504.15690v1","title":"A Data Literacy Competence Model for Higher Education and Research","summary":"In an increasingly data-driven world, the ability to understand, interpret,\nand use data - data literacy - is emerging as a critical competence across all\nacademic disciplines. The Data Literacy Initiative (DaLI) at TH K\\\"oln\naddresses this need by developing a comprehensive competence model for\npromoting data literacy in higher education. Based on interdisciplinary\ncollaboration and empirical research, the DaLI model defines seven overarching\ncompetence areas: \"Establish Data Culture\", \"Provide Data\", \"Manage Data\",\n\"Analyze Data\", \"Evaluate Data\", \"Interpret Data\", and \"Publish Data\". Each\narea is further detailed by specific competence dimensions and progression\nlevels, providing a structured framework for curriculum design, teaching, and\nassessment. Intended for use across disciplines, the model supports the\nstrategic integration of data literacy into university programs. By providing a\ncommon language and orientation for educators and institutions, the DaLI model\ncontributes to the broader goal of preparing students to navigate and shape a\ndata-informed society.","main_category":"cs.CY","categories":"cs.CY","published":"2025-04-22T08:14:23Z"}
{"aid":"http://arxiv.org/abs/2504.15720v1","title":"SeaLLM: Service-Aware and Latency-Optimized Resource Sharing for Large\n  Language Model Inference","summary":"Large language models (LLMs) with different architectures and sizes have been\ndeveloped. Serving each LLM with dedicated GPUs leads to resource waste and\nservice inefficiency due to the varying demand of LLM requests. A common\npractice is to share multiple LLMs. However, existing sharing systems either do\nnot consider the autoregressive pattern of LLM services, or only focus on\nimproving the throughput, which impairs the sharing performance, especially the\nserving latency. We present SeaLLM, which enables service-aware and\nlatency-optimized LLM sharing. SeaLLM improves the overall sharing performance\nby (1) a latency-optimized scheduling algorithm utilizing the characteristics\nof LLM services, (2) a placement algorithm to determine the placement plan and\nan adaptive replacement algorithm to decide the replacement interval, and (3) a\nunified key-value cache to share GPU memory among LLM services efficiently. Our\nevaluation under real-world traces and LLM services demonstrates that SeaLLM\nimproves the normalized latency by up to $13.60\\times$, the tail latency by up\nto $18.69\\times$, and the SLO attainment by up to $3.64\\times$ compared to\nexisting solutions.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-22T09:08:46Z"}
{"aid":"http://arxiv.org/abs/2504.15728v1","title":"SAGA: Semantic-Aware Gray color Augmentation for Visible-to-Thermal\n  Domain Adaptation across Multi-View Drone and Ground-Based Vision Systems","summary":"Domain-adaptive thermal object detection plays a key role in facilitating\nvisible (RGB)-to-thermal (IR) adaptation by reducing the need for co-registered\nimage pairs and minimizing reliance on large annotated IR datasets. However,\ninherent limitations of IR images, such as the lack of color and texture cues,\npose challenges for RGB-trained models, leading to increased false positives\nand poor-quality pseudo-labels. To address this, we propose Semantic-Aware Gray\ncolor Augmentation (SAGA), a novel strategy for mitigating color bias and\nbridging the domain gap by extracting object-level features relevant to IR\nimages. Additionally, to validate the proposed SAGA for drone imagery, we\nintroduce the IndraEye, a multi-sensor (RGB-IR) dataset designed for diverse\napplications. The dataset contains 5,612 images with 145,666 instances,\ncaptured from diverse angles, altitudes, backgrounds, and times of day,\noffering valuable opportunities for multimodal learning, domain adaptation for\nobject detection and segmentation, and exploration of sensor-specific strengths\nand weaknesses. IndraEye aims to enhance the development of more robust and\naccurate aerial perception systems, especially in challenging environments.\nExperimental results show that SAGA significantly improves RGB-to-IR adaptation\nfor autonomous driving and IndraEye dataset, achieving consistent performance\ngains of +0.4% to +7.6% (mAP) when integrated with state-of-the-art domain\nadaptation techniques. The dataset and codes are available at\nhttps://github.com/airliisc/IndraEye.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T09:22:11Z"}
{"aid":"http://arxiv.org/abs/2504.15748v1","title":"Detection of an Explosive Outflow in G34.26+0.15","summary":"This paper reports on the detection of a likely explosive outflow in the\nhigh-mass star-forming complex G34.26+0.15, adding to the small number (six) of\nexplosive outflows detected so far. ALMA CO(2-1) and SiO(5-4) archival\nobservations reveal multiple outflow streamers from G34.26+0.15, which\ncorrelate well with H2 jets identified from Spitzer-IRAC 4.5 um and [4.5]/[3.6]\nflux ratio maps. These nearly linear outflow streamers originate from a common\ncenter within an ultracompact HII region located in the complex. The velocity\nspread of the outflow streamers ranges from 0 to 120 km/s. The radial\nvelocities of these streamers follow the Hubble-Lema\\^itre velocity law,\nindicating an explosive nature. From the CO emission, the total outflow mass,\nmomentum, and outflow energy are estimated to be ~264 M_sun, 4.3*10^3 M_sun\nkm/s, and 10^48 erg, respectively. The event triggering the outflow may have\noccurred about 19,000 years ago and could also be responsible for powering the\nexpanding UC HII region, given the similar dynamical ages and positional\ncoincidence of the UC HII region with the origin of the outflow. The magnetic\nfield lines in the region associated with G34.26+0.15 also appear to align with\nthe direction of the outflow streamers and jets, possibly being dragged by the\nexplosive outflow.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-22T09:51:07Z"}
{"aid":"http://arxiv.org/abs/2504.15760v1","title":"Moment Tensor Potential and Equivariant Tensor Network Potential with\n  explicit dispersion interactions","summary":"In this study, we investigate the effect of incorporating explicit dispersion\ninteractions in the functional form of machine learning interatomic potentials\n(MLIPs), particularly in the Moment Tensor Potential and Equivariant Tensor\nNetwork potential for accurate modeling of liquid carbon tetrachloride,\nmethane, and toluene. We show that explicit incorporation of dispersion\ninteractions via D2 and D3 corrections significantly improves the accuracy of\nMLIPs when the cutoff radius is set to a commonly used value of 5 -- 6 \\r{A}.\nWe also show that for carbon tetrachloride and methane, a substantial\nimprovement in accuracy can be achieved by extending the cutoff radius to 7.5\n\\r{A}. However, for accurate modeling of toluene, explicit incorporation of\ndispersion remains important. Furthermore, we find that MLIPs incorporating\ndispersion interactions via D2 reach a close level of accuracy to those\nincorporating D3, and D2 is suitable for accurate modeling of the systems in\nthe study, while being less computationally expensive. We evaluated the\naccuracy of MLIPs in dimer binding curves compared to ab initio data and in\npredicting density and radial distribution functions compared to experiments.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-22T10:11:54Z"}
{"aid":"http://arxiv.org/abs/2504.15770v1","title":"Multi-Scale Tensorial Summation and Dimensional Reduction Guided Neural\n  Network for Edge Detection","summary":"Edge detection has attracted considerable attention thanks to its exceptional\nability to enhance performance in downstream computer vision tasks. In recent\nyears, various deep learning methods have been explored for edge detection\ntasks resulting in a significant performance improvement compared to\nconventional computer vision algorithms. In neural networks, edge detection\ntasks require considerably large receptive fields to provide satisfactory\nperformance. In a typical convolutional operation, such a large receptive field\ncan be achieved by utilizing a significant number of consecutive layers, which\nyields deep network structures. Recently, a Multi-scale Tensorial Summation\n(MTS) factorization operator was presented, which can achieve very large\nreceptive fields even from the initial layers. In this paper, we propose a\nnovel MTS Dimensional Reduction (MTS-DR) module guided neural network,\nMTS-DR-Net, for the edge detection task. The MTS-DR-Net uses MTS layers, and\ncorresponding MTS-DR blocks as a new backbone to remove redundant information\ninitially. Such a dimensional reduction module enables the neural network to\nfocus specifically on relevant information (i.e., necessary subspaces).\nFinally, a weight U-shaped refinement module follows MTS-DR blocks in the\nMTS-DR-Net. We conducted extensive experiments on two benchmark edge detection\ndatasets: BSDS500 and BIPEDv2 to verify the effectiveness of our model. The\nimplementation of the proposed MTS-DR-Net can be found at\nhttps://github.com/LeiXuAI/MTS-DR-Net.git.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T10:28:10Z"}
{"aid":"http://arxiv.org/abs/2504.15787v1","title":"Plasma Mechanism of Radio Emission Generation at the Bow Shock of the\n  Exoplanet HD 189733b","summary":"This study evaluates the possibility of efficient radio emission generation\nin the bow shock region of hot Jupiter-type exoplanets. As a source of\nenergetic electrons, the shock drift acceleration mechanism at a\nquasi-perpendicular shock is proposed. Electrons reflected and accelerated by\nthe shock propagate through the relatively dense stellar wind plasma and excite\nplasma waves; therefore, a plasma emission mechanism is considered as the\nsource of the resulting radio waves. Using the bow shock of the hot Jupiter HD\n189733b as a case study, the properties of the energetic electron beam, the\nexcited plasma waves, and the resulting radio frequencies are estimated. An\nenergy-based analysis is carried out to identify the range of stellar wind\nparameters for which radio emission from the bow shock of the exoplanet HD\n189733b could be detectable by modern astronomical instruments.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph,astro-ph.EP,astro-ph.IM","published":"2025-04-22T10:59:58Z"}
{"aid":"http://arxiv.org/abs/2504.15794v1","title":"Residual lifetime prediction for heterogeneous degradation data by\n  Bayesian semi-parametric method","summary":"Degradation data are considered for assessing reliability in highly reliable\nsystems. The usual assumption is that degradation units come from a homogeneous\npopulation. But in presence of high variability in the manufacturing process,\nthis assumption is not true in general; that is different sub-populations are\ninvolved in the study. Predicting residual lifetime of a functioning unit is a\nmajor challenge in the degradation modeling especially in heterogeneous\nenvironment. To account for heterogeneous degradation data, we have proposed a\nBayesian semi-parametric approach to relax the conventional modeling\nassumptions. We model the degradation path using Dirichlet process mixture of\nnormal distributions. Based on the samples obtained from posterior distribution\nof model parameters we obtain residual lifetime distribution for individual\nunit. Transformation based MCMC technique is used for simulating values from\nthe derived residual lifetime distribution for prediction of residual lifetime.\nA simulation study is undertaken to check performance of the proposed\nsemi-parametric model compared with parametric model. Fatigue Crack Size data\nis analyzed to illustrate the proposed methodology.","main_category":"stat.ME","categories":"stat.ME,stat.AP","published":"2025-04-22T11:14:56Z"}
{"aid":"http://arxiv.org/abs/2504.15801v1","title":"A closer look at how large language models trust humans: patterns and\n  biases","summary":"As large language models (LLMs) and LLM-based agents increasingly interact\nwith humans in decision-making contexts, understanding the trust dynamics\nbetween humans and AI agents becomes a central concern. While considerable\nliterature studies how humans trust AI agents, it is much less understood how\nLLM-based agents develop effective trust in humans. LLM-based agents likely\nrely on some sort of implicit effective trust in trust-related contexts (e.g.,\nevaluating individual loan applications) to assist and affect decision making.\nUsing established behavioral theories, we develop an approach that studies\nwhether LLMs trust depends on the three major trustworthiness dimensions:\ncompetence, benevolence and integrity of the human subject. We also study how\ndemographic variables affect effective trust. Across 43,200 simulated\nexperiments, for five popular language models, across five different scenarios\nwe find that LLM trust development shows an overall similarity to human trust\ndevelopment. We find that in most, but not all cases, LLM trust is strongly\npredicted by trustworthiness, and in some cases also biased by age, religion\nand gender, especially in financial scenarios. This is particularly true for\nscenarios common in the literature and for newer models. While the overall\npatterns align with human-like mechanisms of effective trust formation,\ndifferent models exhibit variation in how they estimate trust; in some cases,\ntrustworthiness and demographic factors are weak predictors of effective trust.\nThese findings call for a better understanding of AI-to-human trust dynamics\nand monitoring of biases and trust development patterns to prevent unintended\nand potentially harmful outcomes in trust-sensitive applications of AI.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.CY","published":"2025-04-22T11:31:50Z"}
{"aid":"http://arxiv.org/abs/2504.15834v1","title":"Causal machine learning for high-dimensional mediation analysis using\n  interventional effects mapped to a target trial","summary":"Causal mediation analysis examines causal pathways linking exposures to\ndisease. The estimation of interventional effects, which are mediation\nestimands that overcome certain identifiability problems of natural effects,\nhas been advanced through causal machine learning methods, particularly for\nhigh-dimensional mediators. Recently, it has been proposed interventional\neffects can be defined in each study by mapping to a target trial assessing\nspecific hypothetical mediator interventions. This provides an appealing\nframework to directly address real-world research questions about the extent to\nwhich such interventions might mitigate an increased disease risk in the\nexposed. However, existing estimators for interventional effects mapped to a\ntarget trial rely on singly-robust parametric approaches, limiting their\napplicability in high-dimensional settings. Building upon recent developments\nin causal machine learning for interventional effects, we address this gap by\ndeveloping causal machine learning estimators for three interventional effect\nestimands, defined by target trials assessing hypothetical interventions\ninducing distinct shifts in joint mediator distributions. These estimands are\nmotivated by a case study within the Longitudinal Study of Australian Children,\nused for illustration, which assessed how intervening on high inflammatory\nburden and other non-inflammatory adverse metabolomic markers might mitigate\nthe adverse causal effect of overweight or obesity on high blood pressure in\nadolescence. We develop one-step and (partial) targeted minimum loss-based\nestimators based on efficient influence functions of those estimands,\ndemonstrating they are root-n consistent, efficient, and multiply robust under\ncertain conditions.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-22T12:28:27Z"}
{"aid":"http://arxiv.org/abs/2504.15864v1","title":"The effects of pressure loads in the dimension reduction of elasticity\n  models","summary":"We study the dimensional reduction from three to two dimensions in\nhyperelastic materials subject to a live load, modeled as a constant pressure\nforce. Our results demonstrate that this loading has a significant impact in\nhigher-order scaling regimes, namely those associated with von K\\'arm\\'an-type\ntheories, where a nontrivial interplay arises between the elastic energy and\nthe pressure term. In contrast, we rigorously show that in lower-order bending\nregimes, as described by Kirchhoff-type theories, the pressure load does not\ninfluence the minimizers. Finally, after identifying the corresponding\n$\\Gamma$-limit, we conjecture that a similar independence from the pressure\nterm persists in the most flexible membrane regimes.","main_category":"math.AP","categories":"math.AP","published":"2025-04-22T12:59:36Z"}
{"aid":"http://arxiv.org/abs/2504.15871v1","title":"Long-term disparities in the recovery of urban mobility after COVID-19\n  in Latin America","summary":"The COVID-19 pandemic caused unprecedented disruptions to the patterns of\nurban mobility. Existing work has overwhelmingly focused on the immediate\nimpacts of COVID-19 on human mobility during 2020, particularly in countries of\nthe Global North. It showed that the pandemic resulted in an increased gap,\nbenefitted affluent and core urban areas with larger reductions in mobility.\nYet, little is know about the long-term persistence of these unequal impacts\nbeyond 2020, and in countries of the Global South where socioeconomic\ndisparities are more acute. Using over 100 million anonymised daily records of\nmobile phone data from Meta-Facebook users from March 2020 to May 2022, we aim\nto determine the long-term geographic and socioeconomic impact of COVID-19 on\nmobility patterns in Latin America. Our findings reveal that the mobility\ndisparities triggered by the COVID-19 pandemic have endured, with affluent and\ndensely populated areas displaying lower mobility rates than more deprived and\nsparsely populated places. We also show that the magnitude of the reduction in\nmobility levels early in the COVID-19 pandemic largely determined the extent of\nmobility differential between socioeconomic groups. We find no signs of full\nrecovery to baseline levels of mobility in some urban cores, suggesting some\nlost of appeal as attractors of economic activity. Overall, our findings\nsuggest that the COVID-19 pandemic has contributed to amplified pre-existing\nsocioeconomic inequalities and redefined the role of cities in Latin American\ncountries.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-22T13:15:50Z"}
{"aid":"http://arxiv.org/abs/2504.15883v1","title":"Integrating Non-Linear Radon Transformation for Diabetic Retinopathy\n  Grading","summary":"Diabetic retinopathy is a serious ocular complication that poses a\nsignificant threat to patients' vision and overall health. Early detection and\naccurate grading are essential to prevent vision loss. Current automatic\ngrading methods rely heavily on deep learning applied to retinal fundus images,\nbut the complex, irregular patterns of lesions in these images, which vary in\nshape and distribution, make it difficult to capture subtle changes. This study\nintroduces RadFuse, a multi-representation deep learning framework that\nintegrates non-linear RadEx-transformed sinogram images with traditional fundus\nimages to enhance diabetic retinopathy detection and grading. Our RadEx\ntransformation, an optimized non-linear extension of the Radon transform,\ngenerates sinogram representations to capture complex retinal lesion patterns.\nBy leveraging both spatial and transformed domain information, RadFuse enriches\nthe feature set available to deep learning models, improving the\ndifferentiation of severity levels. We conducted extensive experiments on two\nbenchmark datasets, APTOS-2019 and DDR, using three convolutional neural\nnetworks (CNNs): ResNeXt-50, MobileNetV2, and VGG19. RadFuse showed significant\nimprovements over fundus-image-only models across all three CNN architectures\nand outperformed state-of-the-art methods on both datasets. For severity\ngrading across five stages, RadFuse achieved a quadratic weighted kappa of\n93.24%, an accuracy of 87.07%, and an F1-score of 87.17%. In binary\nclassification between healthy and diabetic retinopathy cases, the method\nreached an accuracy of 99.09%, precision of 98.58%, and recall of 99.6%,\nsurpassing previously established models. These results demonstrate RadFuse's\ncapacity to capture complex non-linear features, advancing diabetic retinopathy\nclassification and promoting the integration of advanced mathematical\ntransforms in medical image analysis.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-22T13:27:28Z"}
{"aid":"http://arxiv.org/abs/2504.15886v1","title":"Beyond Attention: Investigating the Threshold Where Objective Robot\n  Exclusion Becomes Subjective","summary":"As robots become increasingly involved in decision-making processes (e.g.,\npersonnel selection), concerns about fairness and social inclusion arise. This\nstudy examines social exclusion in robot-led group interviews by robot Ameca,\nexploring the relationship between objective exclusion (robot's attention\nallocation), subjective exclusion (perceived exclusion), mood change, and need\nfulfillment. In a controlled lab study (N = 35), higher objective exclusion\nsignificantly predicted subjective exclusion. In turn, subjective exclusion\nnegatively impacted mood and need fulfillment but only mediated the\nrelationship between objective exclusion and need fulfillment. A piecewise\nregression analysis identified a critical threshold at which objective\nexclusion begins to be perceived as subjective exclusion. Additionally, the\nstanding position was the primary predictor of exclusion, whereas demographic\nfactors (e.g., gender, height) had no significant effect. These findings\nunderscore the need to consider both objective and subjective exclusion in\nhuman-robot interactions and have implications for fairness in robot-assisted\nhiring processes.","main_category":"cs.HC","categories":"cs.HC,cs.RO","published":"2025-04-22T13:31:14Z"}
{"aid":"http://arxiv.org/abs/2504.15916v1","title":"Are there Spectral Features in the MIRI/LRS Transmission Spectrum of\n  K2-18b?","summary":"Determining the composition of an exoplanet atmosphere relies on the presence\nof detectable spectral features. The strongest spectral features, including\nDMS, look approximately Gaussian. Here, I perform a suite of Gaussian feature\nanalyses to find any statistically significant spectral features in the\nrecently published MIRI/LRS spectrum of K2-18b (N. Madhusudhan et al. 2025). In\nN. Madhusudhan et al. 2025, they claim a 3.4-$\\sigma$ detection of spectral\nfeatures compared to a flat line. In 5 out of 6 tests, I find the data\npreferred a flat line over a Gaussian model, with a $\\chi^{2}_{\\nu}$ of 1.06.\nWhen centering the Gaussian where the absorptions for DMS and DMDS peak, I find\nln(B) = 1.21 in favour of the Gaussian model, with a $\\chi^{2}_{\\nu}$ of 0.99.\nWith only $\\sim$2-$\\sigma$ in favour of Gaussian features, I conclude no strong\nstatistical evidence for spectral features.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM","published":"2025-04-22T14:02:56Z"}
{"aid":"http://arxiv.org/abs/2504.15923v1","title":"Bayesian sample size calculations for external validation studies of\n  risk prediction models","summary":"Summary: Contemporary sample size calculations for external validation of\nrisk prediction models require users to specify fixed values of assumed model\nperformance metrics alongside target precision levels (e.g., 95% CI widths).\nHowever, due to the finite samples of previous studies, our knowledge of true\nmodel performance in the target population is uncertain, and so choosing fixed\nvalues represents an incomplete picture. As well, for net benefit (NB) as a\nmeasure of clinical utility, the relevance of conventional precision-based\ninference is doubtful. In this work, we propose a general Bayesian algorithm\nfor constructing the joint distribution of predicted risks and response values\nbased on summary statistics of model performance in previous studies. For\nstatistical metrics of performance, we propose sample size determination rules\nthat either target desired expected precision, or a desired assurance\nprobability that the precision criteria will be satisfied. For NB, we propose\nrules based on optimality assurance (the probability that the planned study\ncorrectly identifies the most beneficial strategy) and the Expected Value of\nSample Information (EVSI), the expected gain in NB from the planned validation\nstudy. We showcase these developments in a case study on the validation of a\nrisk prediction model for deterioration of hospitalized COVID-19 patients.\nCompared to the conventional sample size calculation methods, a Bayesian\napproach requires explicit quantification of uncertainty around model\nperformance, but thereby enables various sample size rules based on expected\nprecision, assurance probabilities, and value of information.","main_category":"stat.AP","categories":"stat.AP,stat.CO,stat.ME","published":"2025-04-22T14:07:05Z"}
{"aid":"http://arxiv.org/abs/2504.15929v1","title":"Meta-Entity Driven Triplet Mining for Aligning Medical Vision-Language\n  Models","summary":"Diagnostic imaging relies on interpreting both images and radiology reports,\nbut the growing data volumes place significant pressure on medical experts,\nyielding increased errors and workflow backlogs. Medical vision-language models\n(med-VLMs) have emerged as a powerful framework to efficiently process\nmultimodal imaging data, particularly in chest X-ray (CXR) evaluations, albeit\ntheir performance hinges on how well image and text representations are\naligned. Existing alignment methods, predominantly based on contrastive\nlearning, prioritize separation between disease classes over segregation of\nfine-grained pathology attributes like location, size or severity, leading to\nsuboptimal representations. Here, we propose MedTrim (Meta-entity-driven\nTriplet mining), a novel method that enhances image-text alignment through\nmultimodal triplet learning synergistically guided by disease class as well as\nadjectival and directional pathology descriptors. Unlike common alignment\nmethods that separate broad disease classes, MedTrim leverages structured\nmeta-entity information to preserve subtle but clinically significant\nintra-class variations. For this purpose, we first introduce an ontology-based\nentity recognition module that extracts pathology-specific meta-entities from\nCXR reports, as annotations on pathology attributes are rare in public\ndatasets. For refined sample selection in triplet mining, we then introduce a\nnovel score function that captures an aggregate measure of inter-sample\nsimilarity based on disease classes and adjectival/directional descriptors.\nLastly, we introduce a multimodal triplet alignment objective for explicit\nwithin- and cross-modal alignment between samples sharing detailed pathology\ncharacteristics. Our demonstrations indicate that MedTrim improves performance\nin downstream retrieval and classification tasks compared to state-of-the-art\nalignment methods.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-22T14:17:51Z"}
{"aid":"http://arxiv.org/abs/2504.15934v1","title":"Real-time raw signal genomic analysis using fully integrated memristor\n  hardware","summary":"Advances in third-generation sequencing have enabled portable and real-time\ngenomic sequencing, but real-time data processing remains a bottleneck,\nhampering on-site genomic analysis due to prohibitive time and energy costs.\nThese technologies generate a massive amount of noisy analog signals that\ntraditionally require basecalling and digital mapping, both demanding frequent\nand costly data movement on von Neumann hardware. To overcome these challenges,\nwe present a memristor-based hardware-software co-design that processes raw\nsequencer signals directly in analog memory, effectively combining the\nseparated basecalling and read mapping steps. Here we demonstrate, for the\nfirst time, end-to-end memristor-based genomic analysis in a fully integrated\nmemristor chip. By exploiting intrinsic device noise for locality-sensitive\nhashing and implementing parallel approximate searches in content-addressable\nmemory, we experimentally showcase on-site applications including infectious\ndisease detection and metagenomic classification. Our experimentally-validated\nanalysis confirms the effectiveness of this approach on real-world tasks,\nachieving a state-of-the-art 97.15% F1 score in virus raw signal mapping, with\n51x speed up and 477x energy saving compared to implementation on a\nstate-of-the-art ASIC. These results demonstrate that memristor-based in-memory\ncomputing provides a viable solution for integration with portable sequencers,\nenabling truly real-time on-site genomic analysis for applications ranging from\npathogen surveillance to microbial community profiling.","main_category":"cs.ET","categories":"cs.ET,q-bio.QM","published":"2025-04-22T14:22:34Z"}
{"aid":"http://arxiv.org/abs/2504.15943v1","title":"Ge$_{1-x}$Si$_{x}$ single crystals for Ge hole spin qubit integration","summary":"Spin qubits are fundamental building blocks of modern quantum computing\ndevices. The path of Ge-based hole-spin qubits has several advantages over\nSi-based electron-spin systems, such as the absence of valley band degeneracy,\nthe possibility of efficient field control due to large spin-orbit coupling,\nand smaller effective masses. Among the possible Ge qubit devices, Ge/GeSi\nplanar heterostructures have proven to be favourable for upscaling and\nfabrication. The Si concentration of the straining GeSi buffer serves as an\nimportant tuning parameter for the electronic structure of Ge/GeSi qubits. A\nparticularly low Si concentration of x = 0.15 of the Ge$_{0.85}$Si$_{0.15}$\ncrystal should enable minimal lattice strain for spin qubit heterostructures,\nwhich is difficult to stabilize as a random alloy. We present a\nsynchrotron-based study to investigate the chemical composition, valence band\nelectronic structure and local atomic structure of a Ge$_{0.85}$Si$_{0.15}$\nsingle crystal using the advanced combination of hard X-ray photoelectron\nspectroscopy (HAXPES), hard X-ray momentum microscopy (HarMoMic) and X-ray\nphotoelectron diffraction (XPD). We found that the Ge$_{0.85}$Si$_{0.15}$\ncrystal has an individual, uniform valence band structure, with no signs of\nphase separation. The shapes of the valence bands resemble those of pure Ge, as\ndo the low effective masses. XPD experiments and Bloch wave calculations, show\nthe Si atoms located at Ge lattice sites within the crystal, forming a random\nalloy. This high chemical, electronic and structural quality of\nGe$_{0.85}$Si$_{0.15}$ single-crystal substrates is of crucial importance for\ntheir implementation to enable long spin lifetimes in Ge-based hole-spin\nqubits. The results emphasise the power of combined X-ray spectromicroscopy\ntechniques, which provide key insights into the qubit building blocks that form\nthe basis of quantum technologies.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-22T14:40:46Z"}
{"aid":"http://arxiv.org/abs/2504.15952v1","title":"Reconstruction of three-dimensional fluid stress field via\n  photoelasticity using physics-informed convolutional encoder-decoder","summary":"Measuring stress fields in fluids and soft materials is crucial in various\nfields such as mechanical engineering, medicine, and bioengineering. However,\nconventional methods that calculate stress fields from velocity fields struggle\nto measure complex fluids where the stress constitutive equation is unknown. To\naddress this, we propose a novel approach that combines photoelastic\nmeasurements -- which can non-invasively visualize internal stresses -- with\nmachine learning to measure stress fields. The machine learning model, which we\nnamed physics-informed convolutional encoder-decoder (PICED), integrates a\nconvolutional neural network (CNN)-based encoder-decoder model with a\nphysics-informed neural network (PINN). Using this approach, three-dimensional\nstress fields can be predicted with high accuracy for multiple interpolated\ndata points in a rectangular channel flow.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-22T14:48:24Z"}
{"aid":"http://arxiv.org/abs/2504.15975v1","title":"A New Graph Grammar Formalism for Robust Syntactic Pattern Recognition","summary":"I introduce a formalism for representing the syntax of recursively structured\ngraph-like patterns. It does not use production rules, like a conventional\ngraph grammar, but represents the syntactic structure in a more direct and\ndeclarative way. The grammar and the pattern are both represented as networks,\nand parsing is seen as the construction of a homomorphism from the pattern to\nthe grammar. The grammars can represent iterative, hierarchical and nested\nrecursive structure in more than one dimension.\n  This supports a highly parallel style of parsing, in which all aspects of\npattern recognition (feature detection, segmentation, parsing, filling in\nmissing symbols, top-down and bottom-up inference) are integrated into a single\nprocess, to exploit the synergy between them.\n  The emphasis of this paper is on underlying theoretical issues, but I also\ngive some example runs to illustrate the error-tolerant parsing of complex\nrecursively structured patterns of 50-1000 symbols, involving variability in\ngeometric relationships, blurry and indistinct symbols, overlapping symbols,\ncluttered images, and erased patches.","main_category":"cs.FL","categories":"cs.FL,cs.CV","published":"2025-04-22T15:23:37Z"}
{"aid":"http://arxiv.org/abs/2504.15997v1","title":"A Lagrangian Approach to Optimal Lotteries in Non-Convex Economies","summary":"We develop a new method to efficiently solve for optimal lotteries in models\nwith non-convexities. In order to employ a Lagrangian framework, we prove that\nthe value of the saddle point that characterizes the optimal lottery is the\nsame as the value of the dual of the deterministic problem. Our algorithm\nsolves the dual of the deterministic problem via sub-gradient descent. We prove\nthat the optimal lottery can be directly computed from the deterministic optima\nthat occur along the iterations. We analyze the computational complexity of our\nalgorithm and show that the worst-case complexity is often orders of magnitude\nbetter than the one arising from a linear programming approach. We apply the\nmethod to two canonical problems with private information. First, we solve a\nprincipal-agent moral-hazard problem, demonstrating that our approach delivers\nsubstantial improvements in speed and scalability over traditional linear\nprogramming methods. Second, we study an optimal taxation problem with hidden\ntypes, which was previously considered computationally infeasible, and examine\nunder which conditions the optimal contract will involve lotteries.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-22T16:03:09Z"}
{"aid":"http://arxiv.org/abs/2504.16017v1","title":"Wilson lines with endpoints in 3d CFT","summary":"In Abelian gauge theories with dynamical matter, Wilson lines can end on the\ninsertions of charged fields. We study the endpoints of Wilson lines in large\n$N$ bosonic QED$_3$. at its critical point. We first study the stability of an\ninfinite Wilson line in the $\\mathbb{CP}^{N-1}$ model by computing the\nappropriate functional determinant at large $N$. We also compute the conformal\ndimension of the lowest-dimension endpoint of the line to first order in\n$N^{-1}$. Along the way we calculate the field-strength tensor $F_{\\mu\\nu}$ in\nthe presence of the line with endpoint and discuss a state-operator\ncorrespondence for the endpoints, as well as the existence of an OPE that\nallows two open-ended Wilson lines to be glued together into a single line.","main_category":"hep-th","categories":"hep-th,cond-mat.str-el","published":"2025-04-22T16:28:46Z"}
{"aid":"http://arxiv.org/abs/2504.16018v1","title":"Engineered complete intersections: eliminating variables and\n  understanding topology","summary":"We continue the study of engineered complete intersections (ECI) -- an\numbrella generality for a number of important objects in combinatoiral and\napplied algebraic geometry (such as nondegenerate toric complete intersections,\ncritical loci of their projections, hyperplane arrangements, generalized\nCalabi--Yau complete intersections, incidence varieties in algebraic\noptimization, reaction networks).\n  In this paper, we work on extending to ECIs several classical results about\ntoric complete intersections. This includes elimination theory, patchworking\nover ${\\mathbb R}$, and computing basic geometric invariants over ${\\mathbb\nC}$.\n  Our results apply e.g. to eliminating variables in systems of ODEs, such as\nreaction networks, computing Newton polytopes of discriminants, constructing\nreal polynomial maps and reaction networks with prescribed topology.\n  Along the way, we assign a cohomology ring to an arbitrary tropical fan, and\nrelate reducible ECIs to arrangements of pairwise intersecting planes.","main_category":"math.AG","categories":"math.AG","published":"2025-04-22T16:28:47Z"}
{"aid":"http://arxiv.org/abs/2504.16045v1","title":"Reinforcement Learning and Metaheuristics for Feynman Integral Reduction","summary":"We propose new methods for optimizing the integration-by-parts (IBP)\nreduction of Feynman integrals, an important computational bottleneck in modern\nperturbative calculations in quantum field theory. Using the simple example of\none-loop massive bubble integrals, we pose the problem of minimizing the number\nof arithmetic operations in reducing a target integral to master integrals via\nthe Laporta algorithm. This is a nontrivial combinatorial optimization problem\nover the ordering of IBP equation generation (from pairs of seed integrals and\nIBP operators) and the ordering of integral elimination. Our first proposed\nmethod is reinforcement learning, which involves an agent interacting with an\nenvironment in a step-by-step manner and learning the best actions to take\ngiven an observation of the environment (in this case, the current state of the\nIBP reduction process). The second method is using metaheuristics, e.g.\nsimulated annealing, to minimize the computational cost as a black-box function\nof numerical priority values that control the orderings. For large-scale\nproblems, the number of free parameters can be compressed by using a small\nneural network to assign priority values. Remarkably, both methods lead to IBP\nreduction schemes that are more efficient than human-designed algorithms.","main_category":"hep-ph","categories":"hep-ph,hep-th","published":"2025-04-22T17:14:05Z"}
{"aid":"http://arxiv.org/abs/2504.16046v1","title":"Certified Mitigation of Worst-Case LLM Copyright Infringement","summary":"The exposure of large language models (LLMs) to copyrighted material during\npre-training raises concerns about unintentional copyright infringement post\ndeployment. This has driven the development of \"copyright takedown\" methods,\npost-training approaches aimed at preventing models from generating content\nsubstantially similar to copyrighted ones. While current mitigation approaches\nare somewhat effective for average-case risks, we demonstrate that they\noverlook worst-case copyright risks exhibits by the existence of long, verbatim\nquotes from copyrighted sources. We propose BloomScrub, a remarkably simple yet\nhighly effective inference-time approach that provides certified copyright\ntakedown. Our method repeatedly interleaves quote detection with rewriting\ntechniques to transform potentially infringing segments. By leveraging\nefficient data sketches (Bloom filters), our approach enables scalable\ncopyright screening even for large-scale real-world corpora. When quotes beyond\na length threshold cannot be removed, the system can abstain from responding,\noffering certified risk reduction. Experimental results show that BloomScrub\nreduces infringement risk, preserves utility, and accommodates different levels\nof enforcement stringency with adaptive abstention. Our results suggest that\nlightweight, inference-time methods can be surprisingly effective for copyright\nprevention.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-22T17:16:53Z"}
{"aid":"http://arxiv.org/abs/2504.16074v1","title":"PHYBench: Holistic Evaluation of Physical Perception and Reasoning in\n  Large Language Models","summary":"We introduce PHYBench, a novel, high-quality benchmark designed for\nevaluating reasoning capabilities of large language models (LLMs) in physical\ncontexts. PHYBench consists of 500 meticulously curated physics problems based\non real-world physical scenarios, designed to assess the ability of models to\nunderstand and reason about realistic physical processes. Covering mechanics,\nelectromagnetism, thermodynamics, optics, modern physics, and advanced physics,\nthe benchmark spans difficulty levels from high school exercises to\nundergraduate problems and Physics Olympiad challenges. Additionally, we\npropose the Expression Edit Distance (EED) Score, a novel evaluation metric\nbased on the edit distance between mathematical expressions, which effectively\ncaptures differences in model reasoning processes and results beyond\ntraditional binary scoring methods. We evaluate various LLMs on PHYBench and\ncompare their performance with human experts. Our results reveal that even\nstate-of-the-art reasoning models significantly lag behind human experts,\nhighlighting their limitations and the need for improvement in complex physical\nreasoning scenarios. Our benchmark results and dataset are publicly available\nat https://phybench-official.github.io/phybench-demo/.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-22T17:53:29Z"}
{"aid":"http://arxiv.org/abs/2504.16386v1","title":"Robust Transmission Design for Reconfigurable Intelligent Surface and\n  Movable Antenna Enabled Symbiotic Radio Communications","summary":"This paper explores the application of movable antenna (MA), a cutting-edge\ntechnology with the capability of altering antenna positions, in a symbiotic\nradio (SR) system enabled by reconfigurable intelligent surface (RIS). The goal\nis to fully exploit the capabilities of both MA and RIS, constructing a better\ntransmission environment for the co-existing primary and secondary transmission\nsystems. For both parasitic SR (PSR) and commensal SR (CSR) scenarios with the\nchannel uncertainties experienced by all transmission links, we design a robust\ntransmission scheme with the goal of maximizing the primary rate while ensuring\nthe secondary transmission quality. To address the maximization problem with\nthorny non-convex characteristics, we propose an alternating optimization\nframework that utilizes the General S-Procedure, General Sign-Definiteness\nPrinciple, successive convex approximation (SCA), and simulated annealing (SA)\nimproved particle swarm optimization (SA-PSO) algorithms. Numerical results\nvalidate that the CSR scenario significantly outperforms the PSR scenario in\nterms of primary rate, and also show that compared to the fixed-position\nantenna scheme, the proposed MA scheme can increase the primary rate by 1.62\nbps/Hz and 2.37 bps/Hz for the PSR and CSR scenarios, respectively.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-23T03:28:50Z"}
{"aid":"http://arxiv.org/abs/2504.16396v1","title":"'Dark pressure': A metric that yields distance-independent circular\n  orbital speed in deep space with 'tunable' total mass","summary":"In general relativity, the tangential speed of objects in stable circular\norbits is not uniquely described by the orbital radius and the mass present\ninside the orbital radius. This work presents a static, spherically symmetric\nspacetime metric which produces stable circular orbits whose speed approaches a\nconstant value at high radii. The orbital speed is independent of the mass\ncontained within the orbital radius, however, there is pressure throughout the\nspacetime. The stress energy tensor of this metric is evaluated numerically\nusing the mass of the Milky Way's central black hole, the orbital speed of its\ndistant satellites, and three different values of a unitless 'mass tuning'\nparameter B. These B 'tune' the amount of mass present, without violating the\nWeak Energy Condition (WEC) at any evaluated spacetime point. The metric can be\nmerged with a Friedmann-Robertson-Walker metric, in which case it achieves\nisotropy and obeys the Friedmann equations at cosmological distances.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-23T03:50:23Z"}
{"aid":"http://arxiv.org/abs/2504.16399v1","title":"Scalable and modular generation of multipartite entangled states through\n  memory-enhanced fusion","summary":"Efficient generation of large-scale multipartite entangled states is a\ncritical but challenging task in quantum information processing. Although\ngeneration of multipartite entanglement within a small set of individual qubits\nhas been demonstrated, further scale-up in system size requires the connection\nof smaller entangled states into a larger state in a scalable and modular\nmanner. Here we achieve this goal by implementing memory-enhanced fusion of two\nmultipartite entangled states via photonic interconnects. Through asynchronous\npreparation of two tripartite W-state entanglements in two spatially-separated\nmodules of atomic quantum memories and on-demand fusion via single-photon\ninterference, we demonstrate the creation of a four-partite W-state\nentanglement shared by two remote quantum memory modules in a heralded way. We\nfurther transfer the W state from the memory qubits to the photonic qubits, and\nconfirm the genuine four-partite entanglement through witness measurements. We\nthen demonstrate memory-enhanced scaling in efficiencies in the entanglement\nfusion. The demonstrated scalable generation and fusion of multipartite\nentangled states pave the way towards realization of large-scale distributed\nquantum information processing in the future.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T04:01:21Z"}
{"aid":"http://arxiv.org/abs/2504.16404v1","title":"Assessing the Feasibility of Internet-Sourced Video for Automatic Cattle\n  Lameness Detection","summary":"Cattle lameness is often caused by hoof injuries or interdigital dermatitis,\nleads to pain and significantly impacts essential physiological activities such\nas walking, feeding, and drinking. This study presents a deep learning-based\nmodel for detecting cattle lameness, sickness, or gait abnormalities using\npublicly available video data. The dataset consists of 50 unique videos from 40\nindividual cattle, recorded from various angles in both indoor and outdoor\nenvironments. Half of the dataset represents naturally walking\n(normal/non-lame) cattle, while the other half consists of cattle exhibiting\ngait abnormalities (lame). To enhance model robustness and generalizability,\ndata augmentation was applied to the training data. The pre-processed videos\nwere then classified using two deep learning models: ConvLSTM2D and 3D CNN. A\ncomparative analysis of the results demonstrates strong classification\nperformance. Specifically, the 3D CNN model achieved a video-level\nclassification accuracy of 90%, with precision, recall, and f1-score of 90.9%,\n90.9%, and 90.91% respectively. The ConvLSTM2D model exhibited a slightly lower\naccuracy of 85%. This study highlights the effectiveness of directly applying\nclassification models to learn spatiotemporal features from video data,\noffering an alternative to traditional multi-stage approaches that typically\ninvolve object detection, pose estimation, and feature extraction. Besides, the\nfindings demonstrate that the proposed deep learning models, particularly the\n3D CNN, effectively classify and detect lameness in cattle while simplifying\nthe processing pipeline.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG,eess.IV","published":"2025-04-23T04:17:41Z"}
{"aid":"http://arxiv.org/abs/2504.16427v1","title":"Can Large Language Models Help Multimodal Language Analysis? MMLA: A\n  Comprehensive Benchmark","summary":"Multimodal language analysis is a rapidly evolving field that leverages\nmultiple modalities to enhance the understanding of high-level semantics\nunderlying human conversational utterances. Despite its significance, little\nresearch has investigated the capability of multimodal large language models\n(MLLMs) to comprehend cognitive-level semantics. In this paper, we introduce\nMMLA, a comprehensive benchmark specifically designed to address this gap. MMLA\ncomprises over 61K multimodal utterances drawn from both staged and real-world\nscenarios, covering six core dimensions of multimodal semantics: intent,\nemotion, dialogue act, sentiment, speaking style, and communication behavior.\nWe evaluate eight mainstream branches of LLMs and MLLMs using three methods:\nzero-shot inference, supervised fine-tuning, and instruction tuning. Extensive\nexperiments reveal that even fine-tuned models achieve only about 60%~70%\naccuracy, underscoring the limitations of current MLLMs in understanding\ncomplex human language. We believe that MMLA will serve as a solid foundation\nfor exploring the potential of large language models in multimodal language\nanalysis and provide valuable resources to advance this field. The datasets and\ncode are open-sourced at https://github.com/thuiar/MMLA.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.MM","published":"2025-04-23T05:25:13Z"}
{"aid":"http://arxiv.org/abs/2504.16442v1","title":"Nonlinear contagion dynamics on dynamical networks: exact solutions\n  ranging from consensus times to evolutionary trajectories","summary":"Understanding nonlinear social contagion dynamics on dynamical networks, such\nas opinion formation, is crucial for gaining new insights into consensus and\npolarization. Similar to threshold-dependent complex contagions, the\nnonlinearity in adoption rates poses challenges for mean-field approximations.\nTo address this theoretical gap, we focus on nonlinear binary-opinion dynamics\non dynamical networks and analytically derive local configurations,\nspecifically the distribution of opinions within any given focal individual's\nneighborhood. This exact local configuration of opinions, combined with network\ndegree distributions, allows us to obtain exact solutions for consensus times\nand evolutionary trajectories. Our counterintuitive results reveal that neither\nbiased assimilation (i.e., nonlinear adoption rates) nor preferences in local\nnetwork rewiring -- such as in-group bias (preferring like-minded individuals)\nand the Matthew effect (preferring social hubs) -- can significantly slow down\nconsensus. Among these three social factors, we find that biased assimilation\nis the most influential in accelerating consensus. Furthermore, our analytical\nmethod efficiently and precisely predicts the evolutionary trajectories of\nadoption curves arising from nonlinear contagion dynamics. Our work paves the\nway for enabling analytical predictions for general nonlinear contagion\ndynamics beyond opinion formation.","main_category":"physics.soc-ph","categories":"physics.soc-ph,nlin.AO,q-bio.PE","published":"2025-04-23T06:02:05Z"}
{"aid":"http://arxiv.org/abs/2504.16466v1","title":"The role and contribution of resonance effect for the decay process of\n  $\\bar B^{0}_s \\rightarrow π^{+}π^{-}P$","summary":"The size of the direct CP asymmetry generated during the weak decay of\nhadrons is attributed to the weak phase and some strong phases. The weak phase\ncomes from the CKM matrix and a strong phase may result from the resonance\neffect which is produced by the mixing of vector meson\n$V\\left\\{\\rho^{0}(770),\\omega(782),\\phi(1020)\\right\\}$ to $\\pi^+ \\pi^-$ meson\npairs. $\\rho^{0}(770)$ can decay directly into $\\pi^+ \\pi^-$ meson pairs, both\n$\\omega(782)$ and $\\phi(1020)$ can also decay into $\\pi^+ \\pi^-$ meson pairs\nwith small contribution from isospin symmetry breaking. The main contribution\nfor the middle state vector meson $\\rho^{0}(770)-\\omega(782)-\\phi(1020)$\ninterference is the mix of $\\rho^{0}(770)$, $\\omega(782)-\\rho^{0}(770)$ and\n$\\phi(1020)-\\rho^{0}(770)$. We calculate the CP asymmetry and decay branching\nratio for $\\bar{B}^0_{s} \\rightarrow \\pi^+ \\pi^- \\pi^0 (\\bar K ^{0})$ in the\nframework of QCD factorization and compare them with previous work. We also add\nthe analysis of $\\bar{B}^0_{s} \\rightarrow \\pi^+ \\pi^- \\eta(\\eta^{(')})$ decay\nprocess. The results show that the CP asymmetry of these four decay processes\nare significantly enhanced especially for the $\\bar{B}^0_{s} \\rightarrow \\pi^+\n\\pi^- \\bar K ^{0}$ decay process and the decay branching ratio also changes\nunder resonance effect. These work might provide support for the experimental\nanalysis of the $\\bar B^{0}_s$ meson.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-23T07:25:06Z"}
{"aid":"http://arxiv.org/abs/2504.16489v1","title":"Amplified Vulnerabilities: Structured Jailbreak Attacks on LLM-based\n  Multi-Agent Debate","summary":"Multi-Agent Debate (MAD), leveraging collaborative interactions among Large\nLanguage Models (LLMs), aim to enhance reasoning capabilities in complex tasks.\nHowever, the security implications of their iterative dialogues and\nrole-playing characteristics, particularly susceptibility to jailbreak attacks\neliciting harmful content, remain critically underexplored. This paper\nsystematically investigates the jailbreak vulnerabilities of four prominent MAD\nframeworks built upon leading commercial LLMs (GPT-4o, GPT-4, GPT-3.5-turbo,\nand DeepSeek) without compromising internal agents. We introduce a novel\nstructured prompt-rewriting framework specifically designed to exploit MAD\ndynamics via narrative encapsulation, role-driven escalation, iterative\nrefinement, and rhetorical obfuscation. Our extensive experiments demonstrate\nthat MAD systems are inherently more vulnerable than single-agent setups.\nCrucially, our proposed attack methodology significantly amplifies this\nfragility, increasing average harmfulness from 28.14% to 80.34% and achieving\nattack success rates as high as 80% in certain scenarios. These findings reveal\nintrinsic vulnerabilities in MAD architectures and underscore the urgent need\nfor robust, specialized defenses prior to real-world deployment.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-23T08:01:50Z"}
{"aid":"http://arxiv.org/abs/2504.16493v1","title":"Breaking scaling relations with inverse catalysts: a machine learning\n  exploration of trends in $\\mathrm{CO_2}$ hydrogenation energy barriers","summary":"The conversion of $\\mathrm{CO_2}$ into useful products such as methanol is a\nkey strategy for abating climate change and our dependence on fossil fuels.\nDeveloping new catalysts for this process is costly and time-consuming and can\nthus benefit from computational exploration of possible active sites. However,\nthis is complicated by the complexity of the materials and reaction networks.\nHere, we present a workflow for exploring transition states of elementary\nreaction steps at inverse catalysts, which is based on the training of a neural\nnetwork-based machine learning interatomic potential. We focus on the crucial\nformate intermediate and its formation over nanoclusters of indium oxide\nsupported on Cu(111). The speedup compared to an approach purely based on\ndensity functional theory allows us to probe a wide variety of active sites\nfound at nanoclusters of different sizes and stoichiometries. Analysis of the\nobtained set of transition state geometries reveals different\nstructure--activity trends at the edge or interior of the nanoclusters.\nFurthermore, the identified geometries allow for the breaking of linear scaling\nrelations, which could be a key underlying reason for the excellent catalytic\nperformance of inverse catalysts observed in experiments.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cs.LG,physics.chem-ph","published":"2025-04-23T08:12:47Z"}
{"aid":"http://arxiv.org/abs/2504.16496v1","title":"Boundaries of the bounded hyperbolic components of polynomials","summary":"In this paper, we study the local connectivity and Hausdorff dimension for\nthe boundaries of the bounded hyperbolic components in the space $\\mathcal P_d$\nof polynomials of degree $d\\geq 3$. It is shown that for any non disjoint-type\nbounded hyperbolic component $\\mathcal H\\subset \\mathcal P_d$, the locally\nconnected part of $\\partial\\mathcal H$, along each regular boundary strata, has\nfull Hausdorff dimension $2d-2$.\n  An essential innovation in our argument involves analyzing how the canonical\nparameterization of the hyperbolic component--realized via Blaschke products\nover a mapping scheme--extends to the boundary. This framework allows us to\nstudy three key aspects of $\\partial \\mathcal H$: the local connectivity\nstructure, the perturbation behavior, and the local Hausdorff dimensions.","main_category":"math.DS","categories":"math.DS,math.CV","published":"2025-04-23T08:19:52Z"}
{"aid":"http://arxiv.org/abs/2504.16516v1","title":"Think Hierarchically, Act Dynamically: Hierarchical Multi-modal Fusion\n  and Reasoning for Vision-and-Language Navigation","summary":"Vision-and-Language Navigation (VLN) aims to enable embodied agents to follow\nnatural language instructions and reach target locations in real-world\nenvironments. While prior methods often rely on either global scene\nrepresentations or object-level features, these approaches are insufficient for\ncapturing the complex interactions across modalities required for accurate\nnavigation. In this paper, we propose a Multi-level Fusion and Reasoning\nArchitecture (MFRA) to enhance the agent's ability to reason over visual\nobservations, language instructions and navigation history. Specifically, MFRA\nintroduces a hierarchical fusion mechanism that aggregates multi-level\nfeatures-ranging from low-level visual cues to high-level semantic\nconcepts-across multiple modalities. We further design a reasoning module that\nleverages fused representations to infer navigation actions through\ninstruction-guided attention and dynamic context integration. By selectively\ncapturing and combining relevant visual, linguistic, and temporal signals, MFRA\nimproves decision-making accuracy in complex navigation scenarios. Extensive\nexperiments on benchmark VLN datasets including REVERIE, R2R, and SOON\ndemonstrate that MFRA achieves superior performance compared to\nstate-of-the-art methods, validating the effectiveness of multi-level modal\nfusion for embodied navigation.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-23T08:41:27Z"}
{"aid":"http://arxiv.org/abs/2504.16542v1","title":"Automated Market Makers: A Stochastic Optimization Approach for\n  Profitable Liquidity Concentration","summary":"Concentrated liquidity automated market makers (AMMs), such as Uniswap v3,\nenable liquidity providers (LPs) to earn liquidity rewards by depositing tokens\ninto liquidity pools. However, LPs often face significant financial losses\ndriven by poorly selected liquidity provision intervals and high costs\nassociated with frequent liquidity reallocation. To support LPs in achieving\nmore profitable liquidity concentration, we developed a tractable stochastic\noptimization problem that can be used to compute optimal liquidity provision\nintervals for profitable liquidity provision. The developed problem accounts\nfor the relationships between liquidity rewards, divergence loss, and\nreallocation costs. By formalizing optimal liquidity provision as a tractable\nstochastic optimization problem, we support a better understanding of the\nrelationship between liquidity rewards, divergence loss, and reallocation\ncosts. Moreover, the stochastic optimization problem offers a foundation for\nmore profitable liquidity concentration.","main_category":"q-fin.TR","categories":"q-fin.TR,q-fin.CP,q-fin.MF","published":"2025-04-23T09:13:53Z"}
{"aid":"http://arxiv.org/abs/2504.16543v1","title":"The different for base change of arithmetic curves","summary":"We introduce a method for studying reduction types of arithmetic curves and\nwildly ramified base change. We give new proofs of earlier results of Lorenzini\nand Obus-Wewers, and resolve a question of Lorenzini on the Euler\ncharacteristic of the resolution graph of a $p$-cyclic arithmetic surface\nquotient singularity. Our method consists of constructing a simultaneous\nskeleton for the associated cover of Berkovich analytifications and applying a\nskeletal Riemann-Hurwitz formula.","main_category":"math.NT","categories":"math.NT,math.AG","published":"2025-04-23T09:19:26Z"}
{"aid":"http://arxiv.org/abs/2504.16546v1","title":"Tinkering Against Scaling","summary":"The ascent of scaling in artificial intelligence research has revolutionized\nthe field over the past decade, yet it presents significant challenges for\nacademic researchers, particularly in computational social science and critical\nalgorithm studies. The dominance of large language models, characterized by\ntheir extensive parameters and costly training processes, creates a disparity\nwhere only industry-affiliated researchers can access these resources. This\nimbalance restricts academic researchers from fully understanding their tools,\nleading to issues like reproducibility in computational social science and a\nreliance on black-box metaphors in critical studies.\n  To address these challenges, we propose a \"tinkering\" approach that is\ninspired by existing works. This method involves engaging with smaller models\nor components that are manageable for ordinary researchers, fostering hands-on\ninteraction with algorithms. We argue that tinkering is both a way of making\nand knowing for computational social science and a way of knowing for critical\nstudies, and fundamentally, it is a way of caring that has broader implications\nfor both fields.","main_category":"cs.CY","categories":"cs.CY,cs.HC","published":"2025-04-23T09:21:39Z"}
{"aid":"http://arxiv.org/abs/2504.16559v1","title":"Unified Molecule Generation and Property Prediction","summary":"Modeling the joint distribution of the data samples and their properties\nallows to construct a single model for both data generation and property\nprediction, with synergistic capabilities reaching beyond purely generative or\npredictive models. However, training joint models presents daunting\narchitectural and optimization challenges. Here, we propose Hyformer, a\ntransformer-based joint model that successfully blends the generative and\npredictive functionalities, using an alternating attention mask together with a\nunified pre-training scheme. We show that Hyformer rivals other joint models,\nas well as state-of-the-art molecule generation and property prediction models.\nAdditionally, we show the benefits of joint modeling in downstream tasks of\nmolecular representation learning, hit identification and antimicrobial peptide\ndesign.","main_category":"cs.LG","categories":"cs.LG,q-bio.QM,I.2.1","published":"2025-04-23T09:36:46Z"}
{"aid":"http://arxiv.org/abs/2504.16574v1","title":"PIS: Linking Importance Sampling and Attention Mechanisms for Efficient\n  Prompt Compression","summary":"Large language models (LLMs) have achieved remarkable progress, demonstrating\nunprecedented capabilities across various natural language processing tasks.\nHowever, the high costs associated with such exceptional performance limit the\nwidespread adoption of LLMs, highlighting the need for prompt compression.\nExisting prompt compression methods primarily rely on heuristic truncation or\nabstractive summarization techniques, which fundamentally overlook the\nintrinsic mechanisms of LLMs and lack a systematic evaluation of token\nimportance for generation. In this work, we introduce Prompt Importance\nSampling (PIS), a novel compression framework that dynamically compresses\nprompts by sampling important tokens based on the analysis of attention scores\nof hidden states. PIS employs a dual-level compression mechanism: 1) at the\ntoken level, we quantify saliency using LLM-native attention scores and\nimplement adaptive compression through a lightweight 9-layer reinforcement\nlearning (RL) network; 2) at the semantic level, we propose a Russian roulette\nsampling strategy for sentence-level importance sampling. Comprehensive\nevaluations across multiple domain benchmarks demonstrate that our method\nachieves state-of-the-art compression performance. Notably, our framework\nserendipitously enhances reasoning efficiency through optimized context\nstructuring. This work advances prompt engineering by offering both theoretical\ngrounding and practical efficiency in context management for LLMs.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-23T09:53:01Z"}
{"aid":"http://arxiv.org/abs/2504.16627v1","title":"TIFIN India at SemEval-2025: Harnessing Translation to Overcome\n  Multilingual IR Challenges in Fact-Checked Claim Retrieval","summary":"We address the challenge of retrieving previously fact-checked claims in\nmonolingual and crosslingual settings - a critical task given the global\nprevalence of disinformation. Our approach follows a two-stage strategy: a\nreliable baseline retrieval system using a fine-tuned embedding model and an\nLLM-based reranker. Our key contribution is demonstrating how LLM-based\ntranslation can overcome the hurdles of multilingual information retrieval.\nAdditionally, we focus on ensuring that the bulk of the pipeline can be\nreplicated on a consumer GPU. Our final integrated system achieved a success@10\nscore of 0.938 and 0.81025 on the monolingual and crosslingual test sets,\nrespectively.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-23T11:34:35Z"}
{"aid":"http://arxiv.org/abs/2504.16659v1","title":"Evolutionary dynamics in state-feedback public goods games with peer\n  punishment","summary":"Public goods game serves as a valuable paradigm for studying the challenges\nof collective cooperation in human and natural societies. Peer punishment is\noften considered as an effective incentive for promoting cooperation in such\ncontexts. However, previous related studies have mostly ignored the positive\nfeedback effect of collective contributions on individual payoffs. In this\nwork, we explore global and local state-feedback, where the multiplication\nfactor is positively correlated with the frequency of contributors in the\nentire population or within the game group, respectively. By using replicator\ndynamics in an infinite well-mixed population we reveal that state-based\nfeedback plays a crucial role in alleviating the cooperative dilemma by\nenhancing and sustaining cooperation compared to the feedback-free case.\nMoreover, when the feedback strength is sufficiently strong or the baseline\nmultiplication factor is sufficiently high, the system with local\nstate-feedback provides full cooperation, hence supporting the ``think\nglobally, act locally'' principle. Besides, we show that the second-order\nfree-rider problem can be partially mitigated under certain conditions when the\nstate-feedback is employed. Importantly, these results remain robust with\nrespect to variations in punishment cost and fine.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-23T12:26:33Z"}
{"aid":"http://arxiv.org/abs/2504.16664v1","title":"Quantum walk search for exceptional configurations on one- and\n  two-dimensional lattice with extra long-range edges of HN4 network","summary":"There exist several types of configurations of marked vertices, referred to\nas the exceptional configurations, on one- and two-dimensional periodic\nlattices with additional long-range edges of the HN4 network, which are\nchallenging to find using discrete-time quantum walk algorithms. In this\narticle, we conduct a comparative analysis of the discrete-time quantum walk\nalgorithm utilizing various coin operators to search for these exceptional\nconfigurations. First, we study the emergence of several new exceptional\nconfigurations/vertices due to the additional long-range edges of the HN4\nnetwork on both one- and two-dimensional lattices. Second, our study shows that\nthe diagonal configuration on a two-dimensional lattice, which is exceptional\nin the case without long-range edges, no longer remains an exceptional\nconfiguration. Third, it is also shown that a recently proposed modified coin\ncan search all these configurations, including any other configurations in one-\nand two-dimensional lattices with very high success probability. Additionally,\nwe construct stationary states for the exceptional configurations caused by the\nadditional long-range edges, which explains why the standard and lackadaisical\nquantum walks with the Grover coin cannot search these configurations.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T12:33:42Z"}
{"aid":"http://arxiv.org/abs/2504.16689v1","title":"p-adic Cherednik algebras on rigid analytic spaces","summary":"Let $X$ be a smooth rigid space with an action of a finite group $G$\nsatisfying that $X/G$ is represented by a rigid space. We construct sheaves of\n$p$-adic Cherednik algebras on the small \\'etale site of the quotient $X/G$,\nand study some of their properties. The sheaves of $p$-adic Cherednik algebras\nare sheaves of Fr\\'echet $K$-algebras on $X/G$, which can be regarded as\n$p$-adic analytic versions of the sheaves of Cherednik algebras associated to\nthe action of a finite group on a smooth algebraic variety defined by P.\nEtingof. Furthermore, their sections on small enough $G$-invariant affinoid\nspaces are canonically Fr\\'echet-Stein algebras. Along the way, we construct\nsheaves of infinite order twisted differential operators on $X$, we give a\n$G$-equivariant classification of the Atiyah algebras (Picard algebroids) on\n$X$, and study the category of co-admissible modules over a sheaf of infinite\norder twisted differential operators.","main_category":"math.NT","categories":"math.NT,math.AG,math.QA","published":"2025-04-23T13:20:05Z"}
{"aid":"http://arxiv.org/abs/2504.16702v1","title":"QED corrections to meson masses","summary":"We present our progress on calculating leading-order QED corrections to meson\nmasses and bare quark masses. As lattice QCD calculations become more precise,\nthese QED corrections are becoming more important. However, one of the\nchallenges in adding QED effects to QCD calculations is avoiding power-law\nsuppressed finite-volume effects. By using the recently introduced\ninfinite-volume reconstruction method for QED, we are able to avoid this\nproblem and perform calculations with exponentially-suppressed finite-volume\neffects.","main_category":"hep-lat","categories":"hep-lat","published":"2025-04-23T13:29:40Z"}
{"aid":"http://arxiv.org/abs/2504.16743v1","title":"Implementing AI Bill of Materials (AI BOM) with SPDX 3.0: A\n  Comprehensive Guide to Creating AI and Dataset Bill of Materials","summary":"A Software Bill of Materials (SBOM) is becoming an increasingly important\ntool in regulatory and technical spaces to introduce more transparency and\nsecurity into a project's software supply chain.\n  Artificial intelligence (AI) projects face unique challenges beyond the\nsecurity of their software, and thus require a more expansive approach to a\nbill of materials. In this report, we introduce the concept of an AI-BOM,\nexpanding on the SBOM to include the documentation of algorithms, data\ncollection methods, frameworks and libraries, licensing information, and\nstandard compliance.","main_category":"cs.SE","categories":"cs.SE,cs.CR","published":"2025-04-23T14:13:19Z"}
{"aid":"http://arxiv.org/abs/2504.16744v1","title":"Traffic-Oblivious Multi-Commodity Flow Network Design","summary":"We consider the Minimum Multi-Commodity Flow Subgraph (MMCFS) problem: given\na directed graph $G$ with edge capacities $\\mathit{cap}$ and a retention ratio\n$\\alpha\\in(0,1)$, find an edge-wise minimum subgraph $G' \\subseteq G$ such that\nfor all traffic matrices $T$ routable in $G$ using a multi-commodity flow,\n$\\alpha\\cdot T$ is routable in $G'$. This natural yet novel problem is\nmotivated by recent research that investigates how the power consumption in\nbackbone computer networks can be reduced by turning off connections during\ntimes of low demand without compromising the quality of service. Since the\nactual traffic demands are generally not known beforehand, our approach must be\ntraffic-oblivious, i.e., work for all possible sets of simultaneously routable\ntraffic demands in the original network.\n  In this paper we present the problem, relate it to other known problems in\nliterature, and show several structural results, including a reformulation,\nmaximum possible deviations from the optimum, and NP-hardness (as well as a\ncertain inapproximability) already on very restricted instances. The most\nsignificant contribution is a tight $\\max(\\frac{1}{\\alpha}, 2)$-approximation\nbased on an algorithmically surprisingly simple LP-rounding scheme.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-23T14:14:18Z"}
{"aid":"http://arxiv.org/abs/2504.16773v1","title":"On integrability of tri-vector deformed Type II string","summary":"We analyse dynamics of the closed Type IIA and IIB string on various\ntri-vector deformed background searching for signatures of integrability. Using\nnumerical methods we construct Poincar\\'e sections for particular embeddings of\nthe string and show that these are not destroyed under tri-vector deformation.\nWe find that the corresponding Lyapunov exponents decay showing that\ntrajectories do not diverge.","main_category":"hep-th","categories":"hep-th","published":"2025-04-23T14:45:16Z"}
{"aid":"http://arxiv.org/abs/2504.16787v1","title":"Credible plan-driven RAG method for Multi-hop Question Answering","summary":"Multi-hop question answering (QA) presents a considerable challenge for\nRetrieval-Augmented Generation (RAG), requiring the structured decomposition of\ncomplex queries into logical reasoning paths and the generation of dependable\nintermediate results. However, deviations in reasoning paths or errors in\nintermediate results, which are common in current RAG methods, may propagate\nand accumulate throughout the reasoning process, diminishing the accuracy of\nthe answer to complex queries. To address this challenge, we propose the\nPlan-then-Act-and-Review (PAR RAG) framework, which is organized into three key\nstages: planning, act, and review, and aims to offer an interpretable and\nincremental reasoning paradigm for accurate and reliable multi-hop question\nanswering by mitigating error propagation.PAR RAG initially applies a top-down\nproblem decomposition strategy, formulating a comprehensive plan that\nintegrates multiple executable steps from a holistic viewpoint. This approach\navoids the pitfalls of local optima common in traditional RAG methods, ensuring\nthe accuracy of the entire reasoning path. Subsequently, PAR RAG incorporates a\nplan execution mechanism based on multi-granularity verification. By utilizing\nboth coarse-grained similarity information and fine-grained relevant data, the\nframework thoroughly checks and adjusts intermediate results, ensuring process\naccuracy while effectively managing error propagation and amplification.\nExperimental results on multi-hop QA datasets demonstrate that the PAR RAG\nframework substantially outperforms existing state-of-the-art methods in key\nmetrics, including EM and F1 scores.","main_category":"cs.CL","categories":"cs.CL,cs.AI,I.2.0","published":"2025-04-23T15:03:17Z"}
{"aid":"http://arxiv.org/abs/2504.16801v1","title":"Decoupled Global-Local Alignment for Improving Compositional\n  Understanding","summary":"Contrastive Language-Image Pre-training (CLIP) has achieved success on\nmultiple downstream tasks by aligning image and text modalities. However, the\nnature of global contrastive learning limits CLIP's ability to comprehend\ncompositional concepts, such as relations and attributes. Although recent\nstudies employ global hard negative samples to improve compositional\nunderstanding, these methods significantly compromise the model's inherent\ngeneral capabilities by forcibly distancing textual negative samples from\nimages in the embedding space. To overcome this limitation, we introduce a\nDecoupled Global-Local Alignment (DeGLA) framework that improves compositional\nunderstanding while substantially mitigating losses in general capabilities. To\noptimize the retention of the model's inherent capabilities, we incorporate a\nself-distillation mechanism within the global alignment process, aligning the\nlearnable image-text encoder with a frozen teacher model derived from an\nexponential moving average. Under the constraint of self-distillation, it\neffectively mitigates the catastrophic forgetting of pretrained knowledge\nduring fine-tuning. To improve compositional understanding, we first leverage\nthe in-context learning capability of Large Language Models (LLMs) to construct\nabout 2M high-quality negative captions across five types. Subsequently, we\npropose the Image-Grounded Contrast (IGC) loss and Text-Grounded Contrast (TGC)\nloss to enhance vision-language compositionally. Extensive experimental results\ndemonstrate the effectiveness of the DeGLA framework. Compared to previous\nstate-of-the-art methods, DeGLA achieves an average enhancement of 3.5% across\nthe VALSE, SugarCrepe, and ARO benchmarks. Concurrently, it obtains an average\nperformance improvement of 13.0% on zero-shot classification tasks across\neleven datasets. Our code will be released at\nhttps://github.com/xiaoxing2001/DeGLA","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T15:20:53Z"}
{"aid":"http://arxiv.org/abs/2504.16814v1","title":"Association-Based Track-Before-Detect with Object Contribution\n  Probabilities","summary":"Multiobject tracking provides situational awareness that enables new\napplications for modern convenience, applied ocean sciences, public safety, and\nhomeland security. In many multiobject tracking applications, including radar\nand sonar tracking, after coherent prefiltering of the received signal,\nmeasurement data is typically structured in cells, where each cell represent,\ne.g., a different range and bearing value. While conventional detect-then-track\n(DTT) multiobject tracking approaches convert the cell-structured data within a\ndetection phase into so-called point measurements in order to reduce the amount\nof data, track-before-detect (TBD) methods process the cell-structured data\ndirectly, avoiding a potential information loss. However, many TBD tracking\nmethods are computationally intensive and achieve a reduced tracking accuracy\nwhen objects interact, i.e., when they come into close proximity. We here\ncounteract these difficulties by introducing the concept of probabilistic\nobject-to-cell contributions. As many conventional DTT methods, our approach\nuses a probabilistic association of objects with data cells, and a new object\ncontribution model with corresponding object contribution probabilities to\nfurther associate cell contributions to objects that occupy the same data cell.\nFurthermore, to keep the computational complexity and filter runtimes low, we\nhere use an efficient Poisson multi-Bernoulli filtering approach in combination\nwith the application of belief propagation for fast probabilistic data\nassociation. We demonstrate numerically that our method achieves significantly\nincreased tracking performance compared to state-of-the-art TBD tracking\napproaches, where performance differences are particularly pronounced when\nmultiple objects interact.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-23T15:32:11Z"}
{"aid":"http://arxiv.org/abs/2504.16819v1","title":"Using games and universal trees to characterise the nondeterministic\n  index of tree languages","summary":"The parity index problem of tree automata asks, given a regular tree language\n$L$ and a set of priorities $J$, is $L$ $J$-feasible, that is, recognised by a\nnondeterministic parity automaton with priorities $J$? This is a long-standing\nopen problem, of which only a few sub-cases and variations are known to be\ndecidable. In a significant but technically difficult step, Colcombet and\nL\\\"oding reduced the problem to the uniform universality of distance-parity\nautomata. In this article, we revisit the index problem using tools from the\nparity game literature.\n  We add some counters to Lehtinen's register game, originally used to solve\nparity games in quasipolynomial time, and use this novel game to characterise\n$J$-feasibility. This provides a alternative proof to Colcombet and L\\\"oding's\nreduction.\n  We then provide a second characterisation, based on the notion of attractor\ndecompositions and the complexity of their structure, as measured by a\nparameterised version of their Strahler number, which we call $n$-Strahler\nnumber. Finally, we rephrase this result using the notion of universal tree\nextended to automata: a guidable automaton recognises a $[1,2j]$-feasible\nlanguage if and only if it admits a universal tree with $n$-Strahler number\n$j$, for some $n$. In particular, a language recognised by a guidable automaton\n$A$ is B\\\"uchi-feasible if and only if there is a uniform bound $n\\in\n\\mathbb{N}$ such that all trees in the language admit an accepting run with an\nattractor decomposition of width bounded by $n$, or, equivalently, if and only\n$A$ admits a \\textit{finite} universal tree.\n  While we do not solve the decidability of the index problem, our work makes\nthe state-of-the-art more accessible and brings to light the deep relationships\nbetween the $J$-feasibility of a language and attractor decompositions,\nuniversal trees and Lehtinen's register game.","main_category":"cs.FL","categories":"cs.FL,F.4.3","published":"2025-04-23T15:37:44Z"}
{"aid":"http://arxiv.org/abs/2504.16828v1","title":"Process Reward Models That Think","summary":"Step-by-step verifiers -- also known as process reward models (PRMs) -- are a\nkey ingredient for test-time scaling. PRMs require step-level supervision,\nmaking them expensive to train. This work aims to build data-efficient PRMs as\nverbalized step-wise reward models that verify every step in the solution by\ngenerating a verification chain-of-thought (CoT). We propose ThinkPRM, a long\nCoT verifier fine-tuned on orders of magnitude fewer process labels than those\nrequired by discriminative PRMs. Our approach capitalizes on the inherent\nreasoning abilities of long CoT models, and outperforms LLM-as-a-Judge and\ndiscriminative verifiers -- using only 1% of the process labels in PRM800K --\nacross several challenging benchmarks. Specifically, ThinkPRM beats the\nbaselines on ProcessBench, MATH-500, and AIME '24 under best-of-N selection and\nreward-guided search. In an out-of-domain evaluation on a subset of\nGPQA-Diamond and LiveCodeBench, our PRM surpasses discriminative verifiers\ntrained on the full PRM800K by 8% and 4.5%, respectively. Lastly, under the\nsame token budget, ThinkPRM scales up verification compute more effectively\ncompared to LLM-as-a-Judge, outperforming it by 7.2% on a subset of\nProcessBench. Our work highlights the value of generative, long CoT PRMs that\ncan scale test-time compute for verification while requiring minimal\nsupervision for training. Our code, data, and models will be released at\nhttps://github.com/mukhal/thinkprm.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-23T15:44:54Z"}
{"aid":"http://arxiv.org/abs/2504.16875v1","title":"Hybrid Reinforcement Learning and Model Predictive Control for Adaptive\n  Control of Hydrogen-Diesel Dual-Fuel Combustion","summary":"Reinforcement Learning (RL) and Machine Learning Integrated Model Predictive\nControl (ML-MPC) are promising approaches for optimizing hydrogen-diesel\ndual-fuel engine control, as they can effectively control multiple-input\nmultiple-output systems and nonlinear processes. ML-MPC is advantageous for\nproviding safe and optimal controls, ensuring the engine operates within\npredefined safety limits. In contrast, RL is distinguished by its adaptability\nto changing conditions through its learning-based approach. However, the\npractical implementation of either method alone poses challenges. RL requires\nhigh variance in control inputs during early learning phases, which can pose\nrisks to the system by potentially executing unsafe actions, leading to\nmechanical damage. Conversely, ML-MPC relies on an accurate system model to\ngenerate optimal control inputs and has limited adaptability to system drifts,\nsuch as injector aging, which naturally occur in engine applications. To\naddress these limitations, this study proposes a hybrid RL and ML-MPC approach\nthat uses an ML-MPC framework while incorporating an RL agent to dynamically\nadjust the ML-MPC load tracking reference in response to changes in the\nenvironment. At the same time, the ML-MPC ensures that actions stay safe\nthroughout the RL agent's exploration. To evaluate the effectiveness of this\napproach, fuel pressure is deliberately varied to introduce a model-plant\nmismatch between the ML-MPC and the engine test bench. The result of this\nmismatch is a root mean square error (RMSE) in indicated mean effective\npressure of 0.57 bar when running the ML-MPC. The experimental results\ndemonstrate that RL successfully adapts to changing boundary conditions by\naltering the tracking reference while ML-MPC ensures safe control inputs. The\nquantitative improvement in load tracking by implementing RL is an RSME of 0.44\nbar.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-23T16:51:49Z"}
{"aid":"http://arxiv.org/abs/2504.16876v1","title":"New Primal-Dual Algorithm for Convex Problems","summary":"Primal-dual algorithm (PDA) is a classic and popular scheme for\nconvex-concave saddle point problems. It is universally acknowledged that the\nproximal terms in the subproblems about the primal and dual variables are\ncrucial to the convergence theory and numerical performance of primal-dual\nalgorithms. By taking advantage of the information from the current and\nprevious iterative points, we exploit two new proximal terms for the\nsubproblems about the primal and dual variables. Based on two new proximal\nterms, we present a new primal-dual algorithm for convex-concave saddle point\nproblems with bilinear coupling terms and establish its global convergence and\nO(1/N ) ergodic convergence rate. When either the primal function or the dual\nfunction is strongly convex, we accelerate the above proposed algorithm and\nshow that the corresponding algorithm can achieve O(1/N^2) convergence rate.\nSince the conditions for the stepsizes of the proposed algorithm are related\ndirectly to the spectral norm of the linear transform, which is difficult to\nobtain in some applications, we also introduce a linesearch strategy for the\nabove proposed primal-dual algorithm and establish its global convergence and\nO(1/N ) ergodic convergence rate . Some numerical experiments are conducted on\nmatrix game and LASSO problems by comparing with other state-of-the-art\nalgorithms, which demonstrate the effectiveness of the proposed three\nprimal-dual algorithms.","main_category":"math.OC","categories":"math.OC","published":"2025-04-23T16:53:14Z"}
{"aid":"http://arxiv.org/abs/2504.16880v1","title":"Quantum circuits for simulating linear interferometers","summary":"Motivated by recent proposals for quantum proof of work protocols, we\ninvestigate approaches for simulating linear optical interferometers using\ndigital quantum circuits. We focus on a second quantisation approach, where the\nquantum computer's registers represent optical modes. We can then use standard\nquantum optical techniques to decompose the unitary matrix describing an\ninterferometer into an array of $2\\times 2$ unitaries, which are subsequently\nsynthesised into quantum circuits and stitched together to complete the\ncircuit. For an $m$ mode interferometer with $n$ identical photons, this method\nrequires approximately $\\mathcal{O}(m \\log(n))$ qubits and a circuit depth of\n$\\mathcal{O}(m n^4 \\log_2(n) \\: \\textrm{polylog}(n^4 / \\epsilon))$. We present\na software package Aquinas (A QUantum INterferometer ASsembler) that uses this\napproach to generate such quantum circuits. For reference, an arbitrary five\nmode interferometer with two identical photons is compiled to a 10 qubit\nquantum circuit with a depth of 1972.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T16:56:48Z"}
{"aid":"http://arxiv.org/abs/2504.16896v1","title":"Memory-efficient Sketch Acceleration for Handling Large Network Flows on\n  FPGAs","summary":"Sketch-based algorithms for network traffic monitoring have drawn increasing\ninterest in recent years due to their sub-linear memory efficiency and high\naccuracy. As the volume of network traffic grows, software-based sketch\nimplementations cannot match the throughput of the incoming network flows.\nFPGA-based hardware sketch has shown better performance compared to software\nrunning on a CPU when handling these packets. Among the various sketch\nalgorithms, Count-min sketch is one of the most popular and efficient. However,\ndue to the limited amount of on-chip memory, the FPGA-based count-Min sketch\naccelerator suffers from performance drops as network traffic grows. In this\nwork, we propose a hardware-friendly architecture with a variable width memory\ncounter for count-min sketch. Our architecture provides a more compact design\nto store the sketch data structure effectively, allowing us to support larger\nhash tables and reduce overestimation errors. The design makes use of a\nP4-based programmable data plane and the AMD OpenNIC shell. The design is\nimplemented and verified on the Open Cloud Testbed running on AMD Alveo U280s\nand can keep up with the 100 Gbit link speed.","main_category":"cs.AR","categories":"cs.AR,cs.NI","published":"2025-04-23T17:24:58Z"}
{"aid":"http://arxiv.org/abs/2504.16898v1","title":"Texture: Structured Exploration of Text Datasets","summary":"Exploratory analysis of a text corpus is essential for assessing data quality\nand developing meaningful hypotheses. Text analysis relies on understanding\ndocuments through structured attributes spanning various granularities of the\ndocuments such as words, phrases, sentences, topics, or clusters. However,\ncurrent text visualization tools typically adopt a fixed representation\ntailored to specific tasks or domains, requiring users to switch tools as their\nanalytical goals change. To address this limitation, we present Texture, a\ngeneral-purpose interactive text exploration tool. Texture introduces a\nconfigurable data schema for representing text documents enriched with\ndescriptive attributes. These attributes can appear at arbitrary levels of\ngranularity in the text and possibly have multiple values, including\ndocument-level attributes, multi-valued attributes (e.g., topics), fine-grained\nspan-level attributes (e.g., words), and vector embeddings. The system then\ncombines existing interactive methods for text exploration into a single\ninterface that provides attribute overview visualizations, supports\ncross-filtering attribute charts to explore subsets, uses embeddings for a\ndataset overview and similar instance search, and contextualizes filters in the\nactual documents. We evaluated Texture through a two-part user study with 10\nparticipants from varied domains who each analyzed their own dataset in a\nbaseline session and then with Texture. Texture was able to represent all of\nthe previously derived dataset attributes, enabled participants to more quickly\niterate during their exploratory analysis, and discover new insights about\ntheir data. Our findings contribute to the design of scalable, interactive, and\nflexible exploration systems that improve users' ability to make sense of text\ndata.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-23T17:26:25Z"}
{"aid":"http://arxiv.org/abs/2504.16909v1","title":"The CKN inequality for spinors: symmetry and symmetry breaking","summary":"This paper is devoted to Sobolev interpolation inequalities for spinors, with\nweights of Caffarelli-Kohn-Nirenberg (CKN) type. In view of the corresponding\nresults for scalar functions, a natural question is to determine whether\noptimal spinors have symmetry properties, or whether spinors with symmetry\nproperties are linearly unstable, in which case we shall say that symmetry\nbreaking occurs. What symmetry means has to be carefully defined and the\noverall picture turns out to be richer than in the scalar case. So far, no\nsymmetrization technique is available in the spinorial case. We can however\ndetermine a range of the parameters for which symmetry holds using a detailed\nanalysis based mostly on spectral methods.","main_category":"math.AP","categories":"math.AP,math.FA","published":"2025-04-23T17:37:38Z"}
{"aid":"http://arxiv.org/abs/2504.16917v1","title":"Application of an attention-based CNN-BiLSTM framework for in vivo\n  two-photon calcium imaging of neuronal ensembles: decoding complex bilateral\n  forelimb movements from unilateral M1","summary":"Decoding behavior, such as movement, from multiscale brain networks remains a\ncentral objective in neuroscience. Over the past decades, artificial\nintelligence and machine learning have played an increasingly significant role\nin elucidating the neural mechanisms underlying motor function. The advancement\nof brain-monitoring technologies, capable of capturing complex neuronal signals\nwith high spatial and temporal resolution, necessitates the development and\napplication of more sophisticated machine learning models for behavioral\ndecoding. In this study, we employ a hybrid deep learning framework, an\nattention-based CNN-BiLSTM model, to decode skilled and complex forelimb\nmovements using signals obtained from in vivo two-photon calcium imaging. Our\nfindings demonstrate that the intricate movements of both ipsilateral and\ncontralateral forelimbs can be accurately decoded from unilateral M1 neuronal\nensembles. These results highlight the efficacy of advanced hybrid deep\nlearning models in capturing the spatiotemporal dependencies of neuronal\nnetworks activity linked to complex movement execution.","main_category":"q-bio.NC","categories":"q-bio.NC,cs.LG","published":"2025-04-23T17:43:00Z"}
{"aid":"http://arxiv.org/abs/2504.17235v1","title":"Cyclic Nielsen realization for del Pezzo surfaces","summary":"The cyclic Nielsen realization problem for a closed, oriented manifold asks\nwhether any mapping class of finite order can be represented by a homeomorphism\nof the same order. In this article, we resolve the smooth, metric, and complex\ncyclic Nielsen realization problem for certain \"irreducible\" mapping classes on\nthe family of smooth 4-manifolds underlying del Pezzo surfaces. Both positive\nand negative examples of realizability are provided in various settings. Our\ntechniques are varied, synthesizing results from reflection group theory and\n4-manifold topology.","main_category":"math.GT","categories":"math.GT,math.AG","published":"2025-04-24T04:11:04Z"}
{"aid":"http://arxiv.org/abs/2504.17242v1","title":"Rapid and Scalable Synthesis of Alkali Metal-Intercalated C$_{60}$\n  Superconductors","summary":"Alkali metal-intercalated C$_{60}$, $A_3$$C_{60}$ ($A$ = K, Rb, Cs, and their\ncombinations), holds significant potential for practical applications due to\nits high superconducting transition temperature (33 K), high upper critical\nfield (900 kOe), and isotropic superconductivity. However, application-oriented\nresearch has been limited by the lack of an efficient $A_3$$C_{60}$ synthesis\nprocess. In this study, we demonstrate a rapid and scalable synthesis of\n$A_3$$C_{60}$ ($A$ = K, Rb, and Cs$_{1/3}$Rb$_{2/3}$) via direct mixing of $A$\nand C$_{60}$, realizing the fabrication of high-quality sintered $A_3$$C_{60}$\npellets within just 1 hour of heating at 200-300{\\deg}C. The pellets exhibited\nlarge superconducting shielding volume fractions with sharp transitions, and\nthe relationship between the lattice constant and transition temperature was in\ngood agreement with previous reports. This direct mixing method enables simple\nand rapid production of large quantities of $A_3$$C_{60}$, which is expected to\naccelerate research into applications such as superconducting wires and bulk\nmagnets.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.mtrl-sci","published":"2025-04-24T04:30:22Z"}
{"aid":"http://arxiv.org/abs/2504.17246v1","title":"A Sandwich Model for Changing-Look AGNs","summary":"The spectral variability of changing-look active galactic nuclei (CL-AGNs)\noccurred on timescales of years to tens of years, posing a significant\nchallenge to the standard thin disk model. In this work, we propose a sandwich\nmodel, including an optically thick disk in the mid-plane (Disk 1) and two\ndisks of low effective optical depth on both sides (Disk 2). These two types of\ndisks are coupled with magnetic fields, which allow viscous torque interaction\nbetween them. As a consequence, the radial velocity of Disk 1 can increase by\nup to three orders of magnitude compared to the standard thin disk, leading to\nan equivalent decrease in the accretion timescale. Therefore, such a sandwich\nmodel can account for the rapid variability in CL-AGNs. In addition, we also\ndiscuss the influence of the magnetic pressure on Disk 2. When Disk 2 is\ndominated by the magnetic pressure, it resembles a \"warm corona\", which is\nresponsible for the soft X-ray excess.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.HE","published":"2025-04-24T04:49:19Z"}
{"aid":"http://arxiv.org/abs/2504.17256v1","title":"A Comment on \"e-PoS: Making PoS Decentralized and Fair\"","summary":"Proof-of-Stake (PoS) is a prominent Sybil control mechanism for\nblockchain-based systems. In \"e-PoS: Making PoS Decentralized and Fair,\" Saad\net al. (TPDS'21) introduced a new Proof-of-Stake protocol, e-PoS, to enhance\nPoS applications' decentralization and fairness. In this comment paper, we\naddress a misunderstanding in the work of Saad et al. The conventional\nProof-of-Stake model that causes the fairness problem does not align with the\ngeneral concept of Proof-of-Stake nor the Proof-of-Stake cryptocurrencies\nmentioned in their paper.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-24T05:22:15Z"}
{"aid":"http://arxiv.org/abs/2504.17267v1","title":"MV-Crafter: An Intelligent System for Music-guided Video Generation","summary":"Music videos, as a prevalent form of multimedia entertainment, deliver\nengaging audio-visual experiences to audiences and have gained immense\npopularity among singers and fans. Creators can express their interpretations\nof music naturally through visual elements. However, the creation process of\nmusic video demands proficiency in script design, video shooting, and\nmusic-video synchronization, posing significant challenges for\nnon-professionals. Previous work has designed automated music video generation\nframeworks. However, they suffer from complexity in input and poor output\nquality. In response, we present MV-Crafter, a system capable of producing\nhigh-quality music videos with synchronized music-video rhythm and style. Our\napproach involves three technical modules that simulate the human creation\nprocess: the script generation module, video generation module, and music-video\nsynchronization module. MV-Crafter leverages a large language model to generate\nscripts considering the musical semantics. To address the challenge of\nsynchronizing short video clips with music of varying lengths, we propose a\ndynamic beat matching algorithm and visual envelope-induced warping method to\nensure precise, monotonic music-video synchronization. Besides, we design a\nuser-friendly interface to simplify the creation process with intuitive editing\nfeatures. Extensive experiments have demonstrated that MV-Crafter provides an\neffective solution for improving the quality of generated music videos.","main_category":"cs.HC","categories":"cs.HC,cs.MM","published":"2025-04-24T05:52:07Z"}
{"aid":"http://arxiv.org/abs/2504.17277v1","title":"ExOSITO: Explainable Off-Policy Learning with Side Information for\n  Intensive Care Unit Blood Test Orders","summary":"Ordering a minimal subset of lab tests for patients in the intensive care\nunit (ICU) can be challenging. Care teams must balance between ensuring the\navailability of the right information and reducing the clinical burden and\ncosts associated with each lab test order. Most in-patient settings experience\nfrequent over-ordering of lab tests, but are now aiming to reduce this burden\non both hospital resources and the environment. This paper develops a novel\nmethod that combines off-policy learning with privileged information to\nidentify the optimal set of ICU lab tests to order. Our approach, EXplainable\nOff-policy learning with Side Information for ICU blood Test Orders (ExOSITO)\ncreates an interpretable assistive tool for clinicians to order lab tests by\nconsidering both the observed and predicted future status of each patient. We\npose this problem as a causal bandit trained using offline data and a reward\nfunction derived from clinically-approved rules; we introduce a novel learning\nframework that integrates clinical knowledge with observational data to bridge\nthe gap between the optimal and logging policies. The learned policy function\nprovides interpretable clinical information and reduces costs without omitting\nany vital lab orders, outperforming both a physician's policy and prior\napproaches to this practical problem.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-24T06:07:14Z"}
{"aid":"http://arxiv.org/abs/2504.17280v1","title":"EdgePoint2: Compact Descriptors for Superior Efficiency and Accuracy","summary":"The field of keypoint extraction, which is essential for vision applications\nlike Structure from Motion (SfM) and Simultaneous Localization and Mapping\n(SLAM), has evolved from relying on handcrafted methods to leveraging deep\nlearning techniques. While deep learning approaches have significantly improved\nperformance, they often incur substantial computational costs, limiting their\ndeployment in real-time edge applications. Efforts to create lightweight neural\nnetworks have seen some success, yet they often result in trade-offs between\nefficiency and accuracy. Additionally, the high-dimensional descriptors\ngenerated by these networks poses challenges for distributed applications\nrequiring efficient communication and coordination, highlighting the need for\ncompact yet competitively accurate descriptors. In this paper, we present\nEdgePoint2, a series of lightweight keypoint detection and description neural\nnetworks specifically tailored for edge computing applications on embedded\nsystem. The network architecture is optimized for efficiency without\nsacrificing accuracy. To train compact descriptors, we introduce a combination\nof Orthogonal Procrustes loss and similarity loss, which can serve as a general\napproach for hypersphere embedding distillation tasks. Additionally, we offer\n14 sub-models to satisfy diverse application requirements. Our experiments\ndemonstrate that EdgePoint2 consistently achieves state-of-the-art (SOTA)\naccuracy and efficiency across various challenging scenarios while employing\nlower-dimensional descriptors (32/48/64). Beyond its accuracy, EdgePoint2\noffers significant advantages in flexibility, robustness, and versatility.\nConsequently, EdgePoint2 emerges as a highly competitive option for visual\ntasks, especially in contexts demanding adaptability to diverse computational\nand communication constraints.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T06:14:01Z"}
{"aid":"http://arxiv.org/abs/2504.17283v1","title":"Commuting degree for BCK-algebras","summary":"We discuss the following question: given a finite BCK-algebra, what is the\nprobability that two randomly selected elements commute? We call this\nprobability the \\textit{commuting degree} of a BCK-algebra. In a previous\npaper, the author gave sharp upper and lower bounds for the commuting degree of\na BCK-algebra with order $n$. We expand on those results in this paper: we show\nthat, for each $n\\geq 3$, there is a BCK-algebra of order $n$ realizing each\npossible commuting degree and that the minimum commuting degree is achieved by\na unique BCK-algebra of order $n$ Additionally, we show that every rational\nnumber in $(0,1]$ is the commuting degree of some finite BCK-algebra.","main_category":"math.RA","categories":"math.RA","published":"2025-04-24T06:25:53Z"}
{"aid":"http://arxiv.org/abs/2504.17294v1","title":"Higher-Spin Currents and Flows in Auxiliary Field Sigma Models","summary":"We study local, higher-spin conserved currents in integrable $2d$ sigma\nmodels that have been deformed via coupling to auxiliary fields. These currents\ngenerate integrability-preserving flows introduced by Smirnov and\nZamolodchikov. For auxiliary field (AF) deformations of a free boson, we prove\nthat local spin-$n$ currents exist for all $n$ and give recursion relations\nthat characterize Smirnov-Zamolodchikov (SZ) flows driven by these currents. We\nthen show how to construct spin-$2n$ currents in a unified class of auxiliary\nfield sigma models with common structure -- including AF theories based on the\nprincipal chiral model (PCM), its non-Abelian T-dual, (bi-)Yang-Baxter\ndeformations of the PCM, and symmetric space models -- for interaction\nfunctions of one variable, and describe SZ flows driven by any function of the\nstress tensor in these cases. Finally, we give perturbative solutions for\nspin-$3$ SZ flows in any member of our unified class of AF models with\nunderlying $\\mathfrak{su}(3)$ algebra. Part of our analysis shows that the\nclass of AF deformations can be extended by allowing the interaction function\nto depend on a larger set of variables than has previously been considered.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP,nlin.SI","published":"2025-04-24T06:42:51Z"}
{"aid":"http://arxiv.org/abs/2504.17297v1","title":"Knapsack on Graphs with Relaxed Neighborhood Constraints","summary":"In the knapsack problems with neighborhood constraints that were studied\nbefore, the input is a graph $\\mathcal{G}$ on a set $\\mathcal{V}$ of items,\neach item $v \\in \\mathcal{V}$ has a weight $w_v$ and profit $p_v$, the size $s$\nof the knapsack, and the demand $d$. The goal is to compute if there exists a\nfeasible solution whose total weight is at most $s$ and total profit is at most\n$d$. Here, feasible solutions are all subsets $\\mathcal{S}$ of the items such\nthat, for every item in $\\mathcal{S}$, at least one of its neighbors in\n$\\mathcal{G}$ is also in $\\mathcal{S}$ for \\hor, and all its neighbors in\n$\\mathcal{G}$ are also in $\\mathcal{S}$ for\n\\hand~\\cite{borradaile2012knapsack}. We study a relaxation of the above\nproblems. Specifically, we allow all possible subsets of items to be feasible\nsolutions. However, only those items for which we pick at least one or all of\nits neighbor (out-neighbor for directed graph) contribute to profit whereas\nevery item picked contribute to the weight; we call the corresponding problems\n\\sor and \\sand. We show that both \\sor and \\sand are strongly \\NPC even on\nundirected graphs. Regarding parameterized complexity, we show both \\sor and\n\\hor are \\WTH parameterized by the size $s$ of the knapsack size.\nInterestingly, both \\sand and \\hand are \\WOH parameterized by knapsack size,\n$s$ plus profit demand, $d$ and also parameterized by solution size, $b$. For\n\\sor and \\hor, we present a randomized color-coding-based pseudo-\\FPT\nalgorithm, parameterized by the solution size $b$, and consequently by the\ndemand $d$. We then consider the treewidth of the input graph as our parameter\nand design pseudo fixed-parameter tractable (\\FPT) algorithm parameterized by\ntreewidth, $\\text{tw}$ for all variants. Finally, we present an additive $1$\napproximation for \\sor when both the weight and profit of every vertex is $1$.","main_category":"cs.DS","categories":"cs.DS,cs.CC","published":"2025-04-24T06:46:28Z"}
{"aid":"http://arxiv.org/abs/2504.17318v1","title":"Skills Beget Skills: Evidence from Historical School Reforms Targeting\n  Health and Further Education","summary":"This paper investigates the dynamic complementarity between school health and\neducation reforms implemented in Denmark between 1940 and 1965: the\nintroduction of school doctors and the expansion of secondary education. Using\na staggered difference-in-differences approach for multiple treatments, we\nstudy the reform effects on individuals' outcomes in the ages 55-64. We find\nthat each reform leads to significant improvements in health and education\noutcomes, including reduced mortality, fewer hospitalizations, and higher\neducational attainment. The singular impact of each reform is doubled when both\nreforms are implemented together, resulting in a 9 percent increase in\nearnings. These findings underscore high societal returns to complementary\nschool investments in the long term.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-24T07:21:06Z"}
{"aid":"http://arxiv.org/abs/2504.17332v1","title":"Bridging Cognition and Emotion: Empathy-Driven Multimodal Misinformation\n  Detection","summary":"In the digital era, social media has become a major conduit for information\ndissemination, yet it also facilitates the rapid spread of misinformation.\nTraditional misinformation detection methods primarily focus on surface-level\nfeatures, overlooking the crucial roles of human empathy in the propagation\nprocess. To address this gap, we propose the Dual-Aspect Empathy Framework\n(DAE), which integrates cognitive and emotional empathy to analyze\nmisinformation from both the creator and reader perspectives. By examining\ncreators' cognitive strategies and emotional appeals, as well as simulating\nreaders' cognitive judgments and emotional responses using Large Language\nModels (LLMs), DAE offers a more comprehensive and human-centric approach to\nmisinformation detection. Moreover, we further introduce an empathy-aware\nfiltering mechanism to enhance response authenticity and diversity.\nExperimental results on benchmark datasets demonstrate that DAE outperforms\nexisting methods, providing a novel paradigm for multimodal misinformation\ndetection.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-24T07:48:26Z"}
{"aid":"http://arxiv.org/abs/2504.17335v1","title":"Generating isolated elliptically polarized attosecond pulse in gapped\n  graphene using linearly polarized laser fields","summary":"We employ the two-band density-matrix equations to calculate high-order\nharmonic generation (HHG) and its ellipticity in gapped graphene irradiated by\na femtosecond short-pulse laser under different orientation angles. The\norientation-dependent harmonic spectra show obvious enhancement harmonics. We\nalso focus on the ellipticity of these enhanced harmonics. Utilizing the\nrecombination trajectory model, the enhanced harmonics are attributed to the\ncaustic effect, whose orientation dependence originates from the inequivalence\nof $\\textrm{K}$ points during the electron ionization process for different\norientation angles. In addition, the harmonic ellipticity can be well\nunderstood by the phase difference of saddle-point currents. Based on our\ntheory, we design a two-color field scheme to generate elliptically polarized\nattosecond pulses in gapped graphene. This work may shed light on the\ngeneration of elliptically polarized attosecond pulses in two-dimensional\nmaterials.","main_category":"physics.atom-ph","categories":"physics.atom-ph","published":"2025-04-24T07:52:56Z"}
{"aid":"http://arxiv.org/abs/2504.17345v1","title":"A Rellich-type theorem for the Helmholtz equation in a junction of\n  stratified media","summary":"We prove that there are no non-zero square-integrable solutions to a\ntwo-dimensional Helmholtz equation in some unbounded inhomogeneous domains\nwhich represent junctions of stratified media. More precisely, we consider\ndomains that are unions of three half-planes, where each half-plane is\nstratified in the direction orthogonal to its boundary. As for the well-known\nRellich uniqueness theorem for a homogeneous exterior domain, our result does\nnot require any boundary condition. Our proof is based on half-plane\nrepresentations of the solution which are derived through a generalization of\nthe Fourier transform adapted to stratified media. A byproduct of our result is\nthe absence of trapped modes at the junction of open waveguides as soon as the\nangles between branches are greater than $\\pi$/2.","main_category":"math.AP","categories":"math.AP,math.SP","published":"2025-04-24T08:02:59Z"}
{"aid":"http://arxiv.org/abs/2504.17353v1","title":"M-MRE: Extending the Mutual Reinforcement Effect to Multimodal\n  Information Extraction","summary":"Mutual Reinforcement Effect (MRE) is an emerging subfield at the intersection\nof information extraction and model interpretability. MRE aims to leverage the\nmutual understanding between tasks of different granularities, enhancing the\nperformance of both coarse-grained and fine-grained tasks through joint\nmodeling. While MRE has been explored and validated in the textual domain, its\napplicability to visual and multimodal domains remains unexplored. In this\nwork, we extend MRE to the multimodal information extraction domain for the\nfirst time. Specifically, we introduce a new task: Multimodal Mutual\nReinforcement Effect (M-MRE), and construct a corresponding dataset to support\nthis task. To address the challenges posed by M-MRE, we further propose a\nPrompt Format Adapter (PFA) that is fully compatible with various Large\nVision-Language Models (LVLMs). Experimental results demonstrate that MRE can\nalso be observed in the M-MRE task, a multimodal text-image understanding\nscenario. This provides strong evidence that MRE facilitates mutual gains\nacross three interrelated tasks, confirming its generalizability beyond the\ntextual domain.","main_category":"cs.CL","categories":"cs.CL,cs.CV,cs.MM","published":"2025-04-24T08:14:36Z"}
{"aid":"http://arxiv.org/abs/2504.17398v1","title":"An Inverse Source Problem for Semilinear Stochastic Hyperbolic Equations","summary":"This paper investigates an inverse source problem for general semilinear\nstochastic hyperbolic equations. Motivated by the challenges arising from both\nrandomness and nonlinearity, we develop a globally convergent iterative\nregularization method that combines Carleman estimate with fixed-point\niteration. Our approach enables the reconstruction of the unknown source\nfunction from partial lateral Cauchy data, without requiring a good initial\nguess. We establish a new Carleman estimate for stochastic hyperbolic equations\nand prove the convergence of the proposed method in weighted spaces.\nFurthermore, we design an efficient numerical algorithm that avoids solving\nbackward stochastic partial differential equations and is robust to randomness\nin both the model and the data. Numerical experiments are provided to\ndemonstrate the effectiveness of the method.","main_category":"math.AP","categories":"math.AP,math.OC","published":"2025-04-24T09:38:57Z"}
{"aid":"http://arxiv.org/abs/2504.17401v1","title":"StereoMamba: Real-time and Robust Intraoperative Stereo Disparity\n  Estimation via Long-range Spatial Dependencies","summary":"Stereo disparity estimation is crucial for obtaining depth information in\nrobot-assisted minimally invasive surgery (RAMIS). While current deep learning\nmethods have made significant advancements, challenges remain in achieving an\noptimal balance between accuracy, robustness, and inference speed. To address\nthese challenges, we propose the StereoMamba architecture, which is\nspecifically designed for stereo disparity estimation in RAMIS. Our approach is\nbased on a novel Feature Extraction Mamba (FE-Mamba) module, which enhances\nlong-range spatial dependencies both within and across stereo images. To\neffectively integrate multi-scale features from FE-Mamba, we then introduce a\nnovel Multidimensional Feature Fusion (MFF) module. Experiments against the\nstate-of-the-art on the ex-vivo SCARED benchmark demonstrate that StereoMamba\nachieves superior performance on EPE of 2.64 px and depth MAE of 2.55 mm, the\nsecond-best performance on Bad2 of 41.49% and Bad3 of 26.99%, while maintaining\nan inference speed of 21.28 FPS for a pair of high-resolution images\n(1280*1024), striking the optimum balance between accuracy, robustness, and\nefficiency. Furthermore, by comparing synthesized right images, generated from\nwarping left images using the generated disparity maps, with the actual right\nimage, StereoMamba achieves the best average SSIM (0.8970) and PSNR (16.0761),\nexhibiting strong zero-shot generalization on the in-vivo RIS2017 and StereoMIS\ndatasets.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-24T09:46:15Z"}
{"aid":"http://arxiv.org/abs/2504.17407v1","title":"Stability of Stochastically Forced Solitons in the Korteweg-de Vries\n  Equation","summary":"We study the stability and dynamics of solitons in the Korteweg-de Vries\n(KdV) equation in the presence of noise and deterministic forcing. The noise is\nspace-dependent and statistically translation-invariant. We show that, for\nsmall forcing, solitons remain close to the family of traveling waves in a\nweighted Sobolev norm, with high probability. We study the effective dynamics\nof the soliton amplitude and position via their variational phase, for which we\nderive explicit modulation equations. The stability result holds on a time\nscale where the deterministic forcing induces significant amplitude modulation.","main_category":"math.AP","categories":"math.AP,math.PR","published":"2025-04-24T09:58:03Z"}
{"aid":"http://arxiv.org/abs/2504.17427v1","title":"Beyond Whole Dialogue Modeling: Contextual Disentanglement for\n  Conversational Recommendation","summary":"Conversational recommender systems aim to provide personalized\nrecommendations by analyzing and utilizing contextual information related to\ndialogue. However, existing methods typically model the dialogue context as a\nwhole, neglecting the inherent complexity and entanglement within the dialogue.\nSpecifically, a dialogue comprises both focus information and background\ninformation, which mutually influence each other. Current methods tend to model\nthese two types of information mixedly, leading to misinterpretation of users'\nactual needs, thereby lowering the accuracy of recommendations. To address this\nissue, this paper proposes a novel model to introduce contextual\ndisentanglement for improving conversational recommender systems, named\nDisenCRS. The proposed model DisenCRS employs a dual disentanglement framework,\nincluding self-supervised contrastive disentanglement and counterfactual\ninference disentanglement, to effectively distinguish focus information and\nbackground information from the dialogue context under unsupervised conditions.\nMoreover, we design an adaptive prompt learning module to automatically select\nthe most suitable prompt based on the specific dialogue context, fully\nleveraging the power of large language models. Experimental results on two\nwidely used public datasets demonstrate that DisenCRS significantly outperforms\nexisting conversational recommendation models, achieving superior performance\non both item recommendation and response generation tasks.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-24T10:33:26Z"}
{"aid":"http://arxiv.org/abs/2504.17437v1","title":"Lectures on measurement in quantum field theory","summary":"These lectures present a brief introduction to measurement theory for QFT in\npossibly curved spacetimes introduced by the author and R. Verch [Comm. Math.\nPhys. 378 (2020) 851-889]. Topics include: a brief introduction to algebraic\nQFT, measurement schemes in QFT, state updates, multiple measurements and the\nresolution of Sorkin's \"impossible measurement\" problem. Examples using\nsuitable theories based on Green hyperbolic operators are given, and the\ninterpretational significance of the framework is briefly considered. The basic\nstyle is to give details relating to QFT while taking for granted various facts\nfrom the theory of globally hyperbolic spacetimes.","main_category":"gr-qc","categories":"gr-qc,math-ph,math.MP,quant-ph","published":"2025-04-24T10:56:56Z"}
{"aid":"http://arxiv.org/abs/2504.17441v1","title":"Predict-Optimize-Distill: A Self-Improving Cycle for 4D Object\n  Understanding","summary":"Humans can resort to long-form inspection to build intuition on predicting\nthe 3D configurations of unseen objects. The more we observe the object motion,\nthe better we get at predicting its 3D state immediately. Existing systems\neither optimize underlying representations from multi-view observations or\ntrain a feed-forward predictor from supervised datasets. We introduce\nPredict-Optimize-Distill (POD), a self-improving framework that interleaves\nprediction and optimization in a mutually reinforcing cycle to achieve better\n4D object understanding with increasing observation time. Given a multi-view\nobject scan and a long-form monocular video of human-object interaction, POD\niteratively trains a neural network to predict local part poses from RGB\nframes, uses this predictor to initialize a global optimization which refines\noutput poses through inverse rendering, then finally distills the results of\noptimization back into the model by generating synthetic self-labeled training\ndata from novel viewpoints. Each iteration improves both the predictive model\nand the optimized motion trajectory, creating a virtuous cycle that bootstraps\nits own training data to learn about the pose configurations of an object. We\nalso introduce a quasi-multiview mining strategy for reducing depth ambiguity\nby leveraging long video. We evaluate POD on 14 real-world and 5 synthetic\nobjects with various joint types, including revolute and prismatic joints as\nwell as multi-body configurations where parts detach or reattach independently.\nPOD demonstrates significant improvement over a pure optimization baseline\nwhich gets stuck in local minima, particularly for longer videos. We also find\nthat POD's performance improves with both video length and successive\niterations of the self-improving cycle, highlighting its ability to scale\nperformance with additional observations and looped refinement.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T11:03:15Z"}
{"aid":"http://arxiv.org/abs/2504.17450v1","title":"Optimizing thermoelectric performance of graphene antidot lattices via\n  quantum transport and machine-learning molecular dynamics simulations","summary":"Thermoelectric materials, which can convert waste heat to electricity or be\nutilized as solid-state coolers, hold promise for sustainable energy\napplications. However, optimizing thermoelectric performance remains a\nsignificant challenge due to the complex interplay between electronic and\nthermal transport properties. In this work, we systematically optimize $ZT$ in\ngraphene antidot lattices (GALs), nanostructured graphene sheets with periodic\nnanopores characterized by two geometric parameters: the hexagonal unit cell\nside length $L$ and the antidot radius $R$. The lattice thermal conductivity is\ndetermined through machine-learned potential-driven molecular dynamics (MD)\nsimulations, while electronic transport properties are computed using\nlinear-scaling quantum transport in combination with MD trajectories based on a\nbond-length-dependent tight-binding model. This method is able to account for\nelectron-phonon scattering, allowing access to diffusive transport in\nlarge-scale systems, overcoming limitations of previous methods based on\nnonequilibrium Green function formalism. Our results show that the introduction\nof the antidots effectively decouples lattice and electronic transport and lead\nto a favorable and significant violation of the Wiedemann-Franz law. We find\nthat optimal $ZT$ values occur in GALs with intermediate $L$ and $R$, closely\ncorrelated with peak power factor values. Notably, thermoelectric performance\npeaks near room temperature, with maximal $ZT$ values approaching 2,\nhighlighting GALs as promising candidates for high-performance thermoelectric\nenergy conversion.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-24T11:29:06Z"}
{"aid":"http://arxiv.org/abs/2504.17455v1","title":"An approach based on metaheuristic algorithms to the timetabling problem\n  in deregulated railway markets","summary":"The train timetabling problem in liberalized railway markets represents a\nchallenge to the coordination between infrastructure managers and railway\nundertakings. Efficient scheduling is critical in maximizing infrastructure\ncapacity and utilization while adhering as closely as possible to the requests\nof railway undertakings. These objectives ultimately contribute to maximizing\nthe infrastructure manager's revenues. This paper sets out a modular simulation\nframework to reproduce the dynamics of deregulated railway systems. Ten\nmetaheuristic algorithms using the MEALPY Python library are then evaluated in\norder to optimize train schedules in the liberalized Spanish railway market.\nThe results show that the Genetic Algorithm outperforms others in revenue\noptimization, convergence speed, and schedule adherence. Alternatives, such as\nParticle Swarm Optimization and Ant Colony Optimization Continuous, show slower\nconvergence and higher variability. The results emphasize the trade-off between\nscheduling more trains and adhering to requested times, providing insights into\nsolving complex scheduling problems in deregulated railway systems.","main_category":"cs.NE","categories":"cs.NE,cs.CE","published":"2025-04-24T11:36:39Z"}
{"aid":"http://arxiv.org/abs/2504.17471v1","title":"GRANITE : a Byzantine-Resilient Dynamic Gossip Learning Framework","summary":"Gossip Learning (GL) is a decentralized learning paradigm where users\niteratively exchange and aggregate models with a small set of neighboring\npeers. Recent GL approaches rely on dynamic communication graphs built and\nmaintained using Random Peer Sampling (RPS) protocols. Thanks to graph\ndynamics, GL can achieve fast convergence even over extremely sparse\ntopologies. However, the robustness of GL over dy- namic graphs to Byzantine\n(model poisoning) attacks remains unaddressed especially when Byzantine nodes\nattack the RPS protocol to scale up model poisoning. We address this issue by\nintroducing GRANITE, a framework for robust learning over sparse, dynamic\ngraphs in the presence of a fraction of Byzantine nodes. GRANITE relies on two\nkey components (i) a History-aware Byzantine-resilient Peer Sampling protocol\n(HaPS), which tracks previously encountered identifiers to reduce adversarial\ninfluence over time, and (ii) an Adaptive Probabilistic Threshold (APT), which\nleverages an estimate of Byzantine presence to set aggregation thresholds with\nformal guarantees. Empirical results confirm that GRANITE maintains convergence\nwith up to 30% Byzantine nodes, improves learning speed via adaptive filtering\nof poisoned models and obtains these results in up to 9 times sparser graphs\nthan dictated by current theory.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.DC","published":"2025-04-24T12:03:15Z"}
{"aid":"http://arxiv.org/abs/2504.17475v1","title":"Odd fake $\\mathbb{Q}$ -homology quadrics exist","summary":"We show the existence of odd fake $\\mathbb{Q}$-homology quadrics, namely of\nminimal surfaces $S$ of general type which have the same $\\mathbb{Q}$-homology\nas a smooth quadric $Q \\cong (\\mathbb{P}^1(\\mathbb{C}))^2$, but have an odd\nintersection form on $ H^2(S, \\mathbb{Z})/Tors(S)$, where $Tors(S)$ is the\nTorsion subgroup.\n  Our examples are provided by a special 1-dimensional family of surfaces\nisogenous to a product of unmixed type.","main_category":"math.AG","categories":"math.AG,math.AT","published":"2025-04-24T12:07:19Z"}
{"aid":"http://arxiv.org/abs/2504.17483v1","title":"Global Gauge Symmetry Breaking in the Abelian Higgs Mechanism","summary":"This paper aims to resolve the incompatibility between two extant\ngauge-invariant accounts of the Abelian Higgs mechanism: the first account uses\nglobal gauge symmetry breaking, and the second eliminates spontaneous symmetry\nbreaking entirely. We resolve this incompatibility by using the constrained\nHamiltonian formalism in symplectic geometry. First we argue that, unlike their\nlocal counterparts, global gauge symmetries are physical. The symmetries that\nare spontaneously broken by the Higgs mechanism are then the global ones.\nSecond, we explain how the dressing field method singles out the Coulomb gauge\nas a preferred gauge for a gauge-invariant account of the Abelian Higgs\nmechanism. Based on the existence of this group of global gauge symmetries that\nare physical, we resolve the incompatibility between the two accounts by\narguing that the correct way to carry out the second method is to eliminate\nonly the redundant gauge symmetries, i.e. those local gauge symmetries which\nare not global. We extend our analysis to quantum field theory, where we show\nthat the Abelian Higgs mechanism can be understood as spontaneous global $U(1)$\nsymmetry breaking in the $C^*$-algebraic sense.","main_category":"physics.hist-ph","categories":"physics.hist-ph,hep-th","published":"2025-04-24T12:21:15Z"}
{"aid":"http://arxiv.org/abs/2504.17522v1","title":"Towards One-Stage End-to-End Table Structure Recognition with Parallel\n  Regression for Diverse Scenarios","summary":"Table structure recognition aims to parse tables in unstructured data into\nmachine-understandable formats. Recent methods address this problem through a\ntwo-stage process or optimized one-stage approaches. However, these methods\neither require multiple networks to be serially trained and perform more\ntime-consuming sequential decoding, or rely on complex post-processing\nalgorithms to parse the logical structure of tables. They struggle to balance\ncross-scenario adaptability, robustness, and computational efficiency. In this\npaper, we propose a one-stage end-to-end table structure parsing network called\nTableCenterNet. This network unifies the prediction of table spatial and\nlogical structure into a parallel regression task for the first time, and\nimplicitly learns the spatial-logical location mapping laws of cells through a\nsynergistic architecture of shared feature extraction layers and task-specific\ndecoding. Compared with two-stage methods, our method is easier to train and\nfaster to infer. Experiments on benchmark datasets show that TableCenterNet can\neffectively parse table structures in diverse scenarios and achieve\nstate-of-the-art performance on the TableGraph-24k dataset. Code is available\nat https://github.com/dreamy-xay/TableCenterNet.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T13:03:13Z"}
{"aid":"http://arxiv.org/abs/2504.17532v1","title":"Permeation and thermal desorption model of hydrogen in steel: a\n  sensitivity analysis","summary":"This work presents a fully physical model of the hydrogen diffusion and\ntrapping kinetics in metals, integrating permeation and thermal desorption\nwithin a unified framework. Based on the McNabb and Foster approach, it\nrequires only binding energy and number density of trap sites. It correctly\nreproduces the physics of the system and the results of the analytical\nsolutions of the permeation kinetics. It is also capable of reproducing thermal\ndesorption spectra with considerable accuracy. The sensitivity analysis has\nelucidated the relationships among the processing conditions and the parameters\ncommonly used to characterize permeation and thermal desorption experiments. An\nequation empirically derived from the simulation results, expressing the\ndependence of time lag in desorption on specimen thickness, number density of\noccupied trap sites, and cathodic concentration, is proposed. In summary, the\nmodel represents a valuable tool in supporting the interpretation and\nrationalization of experiments also from a quantitative viewpoint.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-24T13:19:37Z"}
{"aid":"http://arxiv.org/abs/2504.17546v1","title":"An introduction to R package `mvs`","summary":"In biomedical science, a set of objects or persons can often be described by\nmultiple distinct sets of features obtained from different data sources or\nmodalities (called \"multi-view data\"). Classical machine learning methods\nignore the multi-view structure of such data, limiting model interpretability\nand performance. The R package `mvs` provides methods that were designed\nspecifically for dealing with multi-view data, based on the multi-view stacking\n(MVS) framework. MVS is a form of supervised (machine) learning used to train\nmulti-view classification or prediction models. MVS works by training a\nlearning algorithm on each view separately, estimating the predictive power of\neach view-specific model through cross-validation, and then using another\nlearning algorithm to assign weights to the view-specific models based on their\nestimated predictions. MVS is a form of ensemble learning, dividing the large\nmulti-view learning problem into smaller sub-problems. Most of these\nsub-problems can be solved in parallel, making it computationally attractive.\nAdditionally, the number of features of the sub-problems is greatly reduced\ncompared with the full multi-view learning problem. This makes MVS especially\nuseful when the total number of features is larger than the number of\nobservations (i.e., high-dimensional data). MVS can still be applied even if\nthe sub-problems are themselves high-dimensional by adding suitable penalty\nterms to the learning algorithms. Furthermore, MVS can be used to automatically\nselect the views which are most important for prediction. The R package `mvs`\nmakes fitting MVS models, including such penalty terms, easily and openly\naccessible. `mvs` allows for the fitting of stacked models with any number of\nlevels, with different penalty terms, different outcome distributions, and\nprovides several options for missing data handling.","main_category":"stat.CO","categories":"stat.CO,cs.LG,stat.ME,stat.ML","published":"2025-04-24T13:34:31Z"}
{"aid":"http://arxiv.org/abs/2504.17548v1","title":"Quantum Autoencoder for Multivariate Time Series Anomaly Detection","summary":"Anomaly Detection (AD) defines the task of identifying observations or events\nthat deviate from typical - or normal - patterns, a critical capability in IT\nsecurity for recognizing incidents such as system misconfigurations, malware\ninfections, or cyberattacks. In enterprise environments like SAP HANA Cloud\nsystems, this task often involves monitoring high-dimensional, multivariate\ntime series (MTS) derived from telemetry and log data. With the advent of\nquantum machine learning offering efficient calculations in high-dimensional\nlatent spaces, many avenues open for dealing with such complex data. One\napproach is the Quantum Autoencoder (QAE), an emerging and promising method\nwith potential for application in both data compression and AD. However, prior\napplications of QAEs to time series AD have been restricted to univariate data,\nlimiting their relevance for real-world enterprise systems. In this work, we\nintroduce a novel QAE-based framework designed specifically for MTS AD towards\nenterprise scale. We theoretically develop and experimentally validate the\narchitecture, demonstrating that our QAE achieves performance competitive with\nneural-network-based autoencoders while requiring fewer trainable parameters.\nWe evaluate our model on datasets that closely reflect SAP system telemetry and\nshow that the proposed QAE is a viable and efficient alternative for\nsemisupervised AD in real-world enterprise settings.","main_category":"quant-ph","categories":"quant-ph,cs.CR,cs.LG","published":"2025-04-24T13:40:06Z"}
{"aid":"http://arxiv.org/abs/2504.17567v1","title":"Log-concavity of inverse Kazhdan-Lusztig polynomials of paving matroids","summary":"Gao and Xie (2021) conjectured that the inverse Kazhdan-Lusztig polynomial of\nany matroid is log-concave. Although the inverse Kazhdan-Lusztig polynomial may\nnot always have only real roots, we conjecture that the Hadamard product of an\ninverse Kazhdan-Lusztig polynomial of degree $n$ and $(1+t)^n$ has only real\nroots. Using interlacing polynomials and multiplier sequences, we confirm this\nconjecture for paving matroids. This result allows us to confirm the\nlog-concavity conjecture for these matroids by applying Newton's inequalities.","main_category":"math.CO","categories":"math.CO","published":"2025-04-24T13:58:07Z"}
{"aid":"http://arxiv.org/abs/2504.17581v1","title":"A non-uniform metal distribution in the ram-pressure stripped M86 group\n  of galaxies","summary":"The chemical enrichment of X-ray-emitting hot halos has primarily been\nstudied in closed-box galaxy clusters. Investigating the metal content of\nlower-mass, open systems can serve as a valuable tracer for understanding their\ndynamical history and the extent of chemical enrichment mechanisms in the\nUniverse. In this context, we use an 85.6 ks XMM-Newton observation to study\nthe spatial distribution of the abundance ratios of Mg, Si, and S with respect\nto Fe in the hot gas of the ram-pressure-stripped M86, which has undergone\nmorphological transformations. We report that the chemical composition in the\nM86 galaxy core is more similar to the rest of the hot gaseous content of the\nUniverse than to its stellar population. This result indicate that even extreme\nsupersonic ram-pressure is insufficient to strip the inner part of a galaxy of\nits hot atmosphere. Comparison with other galaxies undergoing ram-pressure\nstripping suggests that stripping the \"primordial\" atmosphere of a galaxy\nrequires a combination of ram-pressure stripping and strong radio-mechanical\nAGN activity. The X-ray emission structures within M86, the plume and the tail,\nare found to be relatively isothermal. We observe that the Mg/Fe ratio in the\nplume is $3.3\\sigma$ higher than in the M86 galaxy core and is consistent with\nthat in the M86 group outskirts and the Virgo ICM, suggesting that the plume\nmight originate from the low-entropy group gas due to a galaxy-galaxy collision\nrather than from the ram-pressure stripping of the dense galaxy core.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.GA","published":"2025-04-24T14:11:13Z"}
{"aid":"http://arxiv.org/abs/2504.17588v1","title":"All-dielectric Metaphotonics for Advanced THz Control of Spins","summary":"While nearly single cycle THz pulse is conventionally accepted as the\nstimulus for the fastest and the most energy efficient control of spins in\nmagnets, all-dielectric metasurfaces have been recently demonstrated to be the\nleast dissipative mean to enhance and control the coupling of light to spins.\nAll-dielectric metasurfaces for the THz control of spins hold great potential\nin the field of spintronics and related technologies, pushing the boundaries of\nspeed and energy efficiency in spin-based information processing. Here we\ndemonstrate such a metasurface for an advanced THz control of spins in a\nferrimagnetic film of iron garnet. Structuring a nonmagnetic substrate one can\nforce a THz electromagnetic field, otherwise described by plane waves, to\nacquire an out-of-plane magnetic field and thus enable arbitrary direction of\nthe torque acting on spins in all three dimensions. Hence, metaphotonics opens\nup a plethora of opportunities for advanced control of spins at THz rates in\nmany hot fields of contemporary science, including spintronics, magnonics and\nquantum computing.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mtrl-sci","published":"2025-04-24T14:19:35Z"}
{"aid":"http://arxiv.org/abs/2504.17589v1","title":"MacWilliams Theory over Zk and nu-functions over Lattices","summary":"Continuing previous works on MacWilliams theory over codes and lattices, a\ngeneralization of the MacWilliams theory over $\\mathbb{Z}_k$ for $m$ codes is\nestablished, and the complete weight enumerator MacWilliams identity also holds\nfor codes over the finitely generated rings $\\mathbb{Z}_k[\\xi]$. In the context\nof lattices, the analogy of the MacWilliams identity associated with\nnu-function was conjectured by Sol\\'{e} in 1995, and we present a new formula\nfor nu-function over the lattices associated with a ternary code, which is\nrather different from the original conjecture. Furthermore, we provide many\ncounterexamples to show that the Sol\\'{e} conjecture never holds in the general\ncase, except for the lattices associated with a binary code.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-24T14:19:51Z"}
{"aid":"http://arxiv.org/abs/2504.17596v1","title":"Rescaling and unconstrained minimisation of convex quadratic maps","summary":"We investigate the properties of a class of piecewise-fractional maps arising\nfrom the introduction of an invariance under rescaling into convex quadratic\nmaps. The subsequent maps are quasiconvex, and pseudoconvex on specific convex\ncones; they can be optimised via exact line search along admissible directions,\nand the iterates then inherit a bidimensional optimality property. We study the\nminimisation of such relaxed maps via coordinate descents with gradient-based\nrules, placing a special emphasis on coordinate directions verifying a\nmaximum-alignment property in the reproducing kernel Hilbert spaces related to\nthe underlying positive-semidefinite matrices. In this setting, we illustrate\nthat accounting for the optimal rescaling of the iterates can in certain\nsituations substantially accelerate the unconstrained minimisation of convex\nquadratic maps.","main_category":"math.OC","categories":"math.OC,cs.NA,math.NA","published":"2025-04-24T14:22:38Z"}
{"aid":"http://arxiv.org/abs/2504.17608v1","title":"The Cauchy--Szegö Projection for domains in $\\mathbb C^n$ with\n  minimal smoothness: weighted theory","summary":"Let $D\\subset\\mathbb C^n$ be a bounded, strongly pseudoconvex domain whose\nboundary $bD$ satisfies the minimal regularity condition of class $C^2$. A 2017\nresult of Lanzani \\& Stein states that the Cauchy--Szeg\\\"{o} projection\n$S_\\omega$ defined with respect to a bounded, positive continuous multiple\n$\\omega$ of induced Lebesgue measure, {maps $L^p(bD, \\omega)$ to $L^p(bD,\n\\omega)$ continuously} for any $1<p<\\infty$. Here we show that $S_\\omega$\nsatisfies explicit quantitative bounds in $L^p(bD, \\Omega)$, for any\n$1<p<\\infty$ and for any $\\Omega$ in the maximal class of\n\\textit{$A_p$}-measures, that is for $\\Omega_p = \\psi_p\\sigma$ where $\\psi_p$\nis a Muckenhoupt $A_p$-weight and $\\sigma$ is the induced Lebesgue measure\n(with $\\omega$'s as above being a sub-class). Earlier results rely upon an\nasymptotic expansion and subsequent pointwise estimates of the Cauchy--Szeg\\\"o\nkernel, but these are unavailable in our setting of minimal regularity {of\n$bD$}; at the same time, more recent techniques that allow to handle domains\nwith minimal regularity (Lanzani--Stein 2017) are not applicable to\n$A_p$-measures. It turns out that the method of {quantitative} extrapolation is\nan appropriate replacement for the missing tools. To finish, we identify a\nclass of holomorphic Hardy spaces defined with respect to $A_p$-measures for\nwhich a meaningful notion of Cauchy--Szeg\\\"o projection can be defined when\n$p=2$.","main_category":"math.CV","categories":"math.CV","published":"2025-04-24T14:34:20Z"}
{"aid":"http://arxiv.org/abs/2504.17621v1","title":"Extending quantum correlations to arbitrary distances via parallel\n  repetition of routed Bell tests","summary":"Applications such as Device-Independent Quantum Key Distribution (DIQKD)\nrequire loophole-free certification of long-distance quantum correlations.\nHowever, these distances remain severely constrained by detector inefficiencies\nand unavoidable transmission losses. To overcome this challenge, we consider\nparallel repetitions of the recently proposed routed Bell experiments, where\ntransmissions from the source are actively directed either to a nearby or a\ndistant measurement device. We analytically show that the threshold detection\nefficiency of the distant device--needed to certify non-jointly-measurable\nmeasurements, a prerequisite of secure DIQKD--decreases exponentially,\noptimally, and robustly, following $\\eta^*=1/2^N$, with the number $N$ of\nparallel repetitions.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-24T14:44:41Z"}
{"aid":"http://arxiv.org/abs/2504.17631v1","title":"Modular Cosmic Ray Detector (MCORD) and its Potential Use in Various\n  Physics Experiments, Astrophysics and Geophysics","summary":"As part of the collaboration building a set of detectors for the new\ncollider, our group was tasked with designing and building a large-scale cosmic\nray detector, which was to complement the capabilities of the MPD (Dubna)\ndetec-tor set. The detector was planned as a trigger for cosmic ray particles\nand to be used to calibrate and test other systems. Additional functions were\nto be the detection of pairs of high-energy muons originating from some\nparti-cle decay processes generated during collisions and con-tinuous\nobservation of the cosmic muon stream in order to detect multi muons events.\nFrom the very beginning, the detector was designed as a scalable and universal\ndevice for many applications. The following work will present the basic\nfeatures and parameters of the Modular COsmic Ray Detector (MCORD) and examples\nof its possible use in high energy physics, astrophysics and geology. Thanks to\nits universal nature, MCORD can be potential used as a fast trigger, neutron\nveto detector, muon detector and as a tool in muon tomography.","main_category":"physics.ins-det","categories":"physics.ins-det,astro-ph.IM,physics.app-ph,J.2.m","published":"2025-04-24T15:04:43Z"}
{"aid":"http://arxiv.org/abs/2504.17644v1","title":"Bounded diagonal orbits in homogeneous spaces over function fields","summary":"This paper is about topological rigidity of diagonal group actions on the\nhomogeneous $\\SL_4\\big(\\F(\\!(t^{-1})\\!)\\big)/\\SL_4(\\F[t])$ where $\\F$ is a\nfinite field of characteristic $3$. We show that there is a non-closed\nrelatively compact orbit of the diagonal group.","main_category":"math.DS","categories":"math.DS","published":"2025-04-24T15:14:10Z"}
{"aid":"http://arxiv.org/abs/2504.17754v1","title":"Spall strength of symmetric tilt grain boundaries in 6H silicon carbide","summary":"Characterizing microstructural effects on the dynamical response of materials\nis challenging due to the extreme conditions and the short timescales involved.\nFor example, little is known about how grain boundary characteristics affect\nspall strength. This study explores 6H-SiC bicrystals under shock waves via\nlarge-scale molecular dynamics simulations. We focused on symmetric tilt grain\nboundaries with a wide range of misorientations and found that spall strength\nand dynamical fracture surface energy are strongly affected by the grain\nboundary microstructure, especially the excess free volume. Grain boundary\nenergy also plays a considerable role. As expected, low-angle grain boundaries\ntend to have higher spallation strengths. We also extracted cohesive models for\nthe dynamical strength of bulk systems and grain boundaries that can be used in\ncontinuum simulations.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-24T17:16:44Z"}
