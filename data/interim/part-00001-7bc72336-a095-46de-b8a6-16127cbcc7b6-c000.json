{"aid":"http://arxiv.org/abs/2503.21656v1","title":"Logging the conformal life of Ramanujan's $Ï€$","summary":"In 1914, Ramanujan presented 17 infinite series for $1/\\pi$. We examine the\nphysics origin of these remarkable formulae by connecting them to 2D\nlogarithmic conformal field theories (LCFTs) which arise in various contexts\nsuch as the fractional quantum hall effect, percolation and polymers. In light\nof the LCFT connection, we investigate such infinite series in terms of the\nphysics data, i.e., the operator spectrum and OPE coefficients of the CFT and\nthe conformal block expansion. These considerations lead to novel\napproximations for $1/\\pi$. The rapid convergence of the Ramanujan series\nmotivates us to take advantage of the crossing symmetry of the LCFT correlators\nto find new and efficient representations. To achieve this, we use the\nparametric crossing symmetric dispersion relation which was recently developed\nfor string amplitudes. Quite strikingly, we find remarkable simplifications in\nthe new representations, where, in the Legendre relation, the entire\ncontribution to $1/\\pi$ comes from the logarithmic identity operator, hinting\nat a universal property of LCFTs. Additionally, the dispersive representation\ngives us a new handle on the double-lightcone limit.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-03-27T16:21:08Z"}
{"aid":"http://arxiv.org/abs/2503.21657v1","title":"Model Assembly Learning with Heterogeneous Layer Weight Merging","summary":"Model merging acquires general capabilities without extra data or training by\ncombining multiple models' parameters. Previous approaches achieve linear mode\nconnectivity by aligning parameters into the same loss basin using permutation\ninvariance. In this paper, we introduce Model Assembly Learning (MAL), a novel\nparadigm for model merging that iteratively integrates parameters from diverse\nmodels in an open-ended model zoo to enhance the base model's capabilities.\nUnlike previous works that require identical architectures, MAL allows the\nmerging of heterogeneous architectures and selective parameters across layers.\nSpecifically, the base model can incorporate parameters from different layers\nof multiple pre-trained models. We systematically investigate the conditions\nand fundamental settings of heterogeneous parameter merging, addressing all\npossible mismatches in layer widths between the base and target models.\nFurthermore, we establish key laws and provide practical guidelines for\neffectively implementing MAL.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-03-27T16:21:53Z"}
{"aid":"http://arxiv.org/abs/2503.21659v1","title":"InteractionMap: Improving Online Vectorized HDMap Construction with\n  Interaction","summary":"Vectorized high-definition (HD) maps are essential for an autonomous driving\nsystem. Recently, state-of-the-art map vectorization methods are mainly based\non DETR-like framework to generate HD maps in an end-to-end manner. In this\npaper, we propose InteractionMap, which improves previous map vectorization\nmethods by fully leveraging local-to-global information interaction in both\ntime and space. Firstly, we explore enhancing DETR-like detectors by explicit\nposition relation prior from point-level to instance-level, since map elements\ncontain strong shape priors. Secondly, we propose a key-frame-based\nhierarchical temporal fusion module, which interacts temporal information from\nlocal to global. Lastly, the separate classification branch and regression\nbranch lead to the problem of misalignment in the output distribution. We\ninteract semantic information with geometric information by introducing a novel\ngeometric-aware classification loss in optimization and a geometric-aware\nmatching cost in label assignment. InteractionMap achieves state-of-the-art\nperformance on both nuScenes and Argoverse2 benchmarks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T16:23:15Z"}
{"aid":"http://arxiv.org/abs/2503.21664v1","title":"Functions of bounded variation and Lipschitz algebras in metric measure\n  spaces","summary":"Given a unital algebra $\\mathscr A$ of locally Lipschitz functions defined\nover a metric measure space $({\\mathrm X},{\\mathsf d},\\mathfrak m)$, we study\ntwo associated notions of function of bounded variation and their relations:\nthe space ${\\mathrm BV}_{\\mathrm H}({\\mathrm X};\\mathscr A)$, obtained by\napproximating in energy with elements of $\\mathscr A$, and the space ${\\mathrm\nBV}_{\\mathrm W}({\\mathrm X};\\mathscr A)$, defined through an\nintegration-by-parts formula that involves derivations acting in duality with\n$\\mathscr A$. Our main result provides a sufficient condition on the algebra\n$\\mathscr A$ under which ${\\mathrm BV}_{\\mathrm H}({\\mathrm X};\\mathscr A)$\ncoincides with the standard metric BV space ${\\mathrm BV}_{\\mathrm H}({\\mathrm\nX})$, which corresponds to taking as $\\mathscr A$ the collection of all locally\nLipschitz functions. Our result applies to several cases of interest, for\nexample to Euclidean spaces and Riemannian manifolds equipped with the algebra\nof smooth functions, or to Banach and Wasserstein spaces equipped with the\nalgebra of cylinder functions. Analogous results for metric Sobolev spaces\n${\\mathrm H}^{1,p}$ of exponent $p\\in(1,\\infty)$ were previously obtained by\nseveral different authors.","main_category":"math.FA","categories":"math.FA,math.MG","published":"2025-03-27T16:32:47Z"}
{"aid":"http://arxiv.org/abs/2503.21665v1","title":"Non-quasicontinuous Newtonian functions and outer capacities based on\n  Banach function spaces","summary":"We construct various examples of Sobolev-type functions, defined via upper\ngradients in metric spaces, that fail to be quasicontinuous or weakly\nquasicontinuous. This is done with quasi-Banach function lattices $X$ as the\nfunction spaces defining the smoothness of the Sobolev-type functions. These\nresults are in contrast to the case $X=L^p$ with $1\\le p<\\infty$, where all\nSobolev-type functions in $N^p$ are known to be quasicontinuous, provided that\nthe underlying metric space $\\mathcal{P}$ is locally complete. In most of our\nexamples, $\\mathcal{P}$ is a compact subset of $\\mathbf{R}^2$ and $X=L^\\infty$.\nFour particular examples are the damped topologist's sine curve, the von Koch\nsnowflake curve, the Cantor ternary set and the Sierpi\\'nski carpet. We also\ndiscuss several related properties, such as whether the Sobolev capacity is an\nouter capacity, and how these properties are related. A fundamental role in\nthese considerations is played by the lack of the Vitali--Carath\\'eodory\nproperty.","main_category":"math.FA","categories":"math.FA","published":"2025-03-27T16:32:52Z"}
{"aid":"http://arxiv.org/abs/2503.21685v1","title":"Extracting Coupling-Mode Spectral Densities with Two-Dimensional\n  Electronic Spectroscopy","summary":"Methods for reconstructing the spectral density of a vibrational environment\nfrom experimental data can yield key insights into the impact of the\nenvironment on molecular function. Although such experimental methods exist,\nthey generally only access vibrational modes that couple diagonally to the\nelectron system. Here we present a method for extracting the spectral density\nof modes that couple to the transition between electronic states, using\ntwo-dimensional electronic spectroscopy. To demonstrate this, we use a\nprocess-tensor method that can simulate two-dimensional electronic spectroscopy\nmeasurements in a numerically exact way. To explain how the extraction works,\nwe also derive an approximate analytical solution, which illustrates that the\nnon-Markovianity of the environment plays an essential role in the existence of\nthe simulated signal.","main_category":"physics.chem-ph","categories":"physics.chem-ph,cond-mat.mes-hall,quant-ph","published":"2025-03-27T16:53:56Z"}
{"aid":"http://arxiv.org/abs/2503.21699v1","title":"MAVERIX: Multimodal Audio-Visual Evaluation Reasoning IndeX","summary":"Frontier models have either been language-only or have primarily focused on\nvision and language modalities. Although recent advancements in models with\nvision and audio understanding capabilities have shown substantial progress,\nthe field lacks a standardized evaluation framework for thoroughly assessing\ntheir cross-modality perception performance. We introduce MAVERIX~(Multimodal\nAudio-Visual Evaluation Reasoning IndeX), a novel benchmark with 700 videos and\n2,556 questions explicitly designed to evaluate multimodal models through tasks\nthat necessitate close integration of video and audio information. MAVERIX\nuniquely provides models with audiovisual tasks, closely mimicking the\nmultimodal perceptual experiences available to humans during inference and\ndecision-making processes. To our knowledge, MAVERIX is the first benchmark\naimed explicitly at assessing comprehensive audiovisual integration.\nExperiments with state-of-the-art models, including Gemini 1.5 Pro and o1, show\nperformance approaching human levels (around 70% accuracy), while human experts\nreach near-ceiling performance (95.1%). With standardized evaluation protocols,\na rigorously annotated pipeline, and a public toolkit, MAVERIX establishes a\nchallenging testbed for advancing audiovisual multimodal intelligence.","main_category":"cs.SD","categories":"cs.SD,cs.AI,cs.CV","published":"2025-03-27T17:04:33Z"}
{"aid":"http://arxiv.org/abs/2503.21701v1","title":"Machine Learning Assisted Modeling of Amorphous TiO$_2$-Doped GeO$_2$\n  for Advanced LIGO Mirror Coatings","summary":"The mechanical loss angle of amorphous TiO$_2$-doped GeO$_2$ can be lower\nthan 10$^{-4}$, making it a candidate for Laser Interferometer\nGravitational-wave Observatory (LIGO) mirror coatings. Amorphous oxides have\ncomplex atomic structures that are influenced by various factors, including\ndoping concentration, preparation, and thermal history, resulting in different\nmass densities and physical properties. Modeling at atomistic level enables\ncapturing these effects by generating atomic structure models according to\nexperimental conditions. In order to obtain reliable and physical amorphous\nmodels at an affordable cost, we develop classical and machine-learning\npotentials (MLP) to speed up simulations. First-principles calculations are\nused to train and validate MLP as well as validating structure models. To\nbetter reproduce properties such as elastic modulus, radial distribution\nfunction (RDF) and the variations in mass density of doped amorphous oxides,\ndensity functional theory (DFT) calculations are used to optimize the final\nmodels. We find that the mass densities of amorphous systems are correlated\nwith the total void volume. The experimental mass density matches the models\nwith the most symmetric potential energy wells under volume change. The elastic\nresponse of the metal-oxygen network is also studied. The 27\\% TiO$_2$ doped\nGeO$_2$ system shows the least number of large atom-atom distance changes,\nwhile for 44\\% TiO$_2$ doped GeO$_2$, a majority of Ti-O distances are\nsignificantly changed. In response to strains, the metal-oxygen network at low\nmass densities prefers to adjust bond angles, while at high mass densities, the\nadjustment is mainly done by changing atom-atom distance.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-27T17:05:07Z"}
{"aid":"http://arxiv.org/abs/2503.21713v1","title":"Investigating Experiential Effects in Online Chess using a Hierarchical\n  Bayesian Analysis","summary":"The presence or absence of winner-loser effects is a widely discussed\nphenomenon across both sports and psychology research. Investigation of such\neffects is often hampered by the limited availability of data. Online chess has\nexploded in popularity in recent years and provides vast amounts of data which\ncan be used to explore this question. With a hierarchical Bayesian regression\nmodel, we carefully investigate the presence of such experiential effects in\nonline chess. Using a large quantity of online chess data, we see little\nevidence for experiential effects that are consistent across all players, with\nsome individual players showing some evidence for such effects. Given the\nchallenging temporal nature of this data, we discuss several methods for\nassessing the suitability of our model and carefully check its validity.","main_category":"stat.AP","categories":"stat.AP","published":"2025-03-27T17:24:48Z"}
{"aid":"http://arxiv.org/abs/2503.21716v1","title":"Dynamics of Star Cluster Formation: The Effects of Ongoing Star\n  Formation and Stellar Feedback","summary":"We perform a high resolution zoom-in simulation of star cluster assembly\nincluding the merger of two sub-clusters with initial conditions taken from\nprevious large scale giant molecular cloud (GMC) simulations. We couple\nhydrodynamics to N-body dynamics to simulate the individual stars themselves,\nand the gas-rich environment in which they evolve. We include prescriptions for\nstar formation and stellar feedback and compare directly to previous\nsimulations of the same region without these prescriptions to determine their\nrole in shaping the dynamics inherited from the cluster assembly process. The\nstellar mass of the cluster grows through star formation within the cluster and\naccretion of new stars and star forming gas from a nearby filament. This growth\nresults in an enhancement in the cluster's rotation and anisotropic expansion\ncompared to simulations without star formation. We also analyze the internal\nkinematics of the cluster once it has lost most of its gas and find that the\nrotational velocity and the velocity anisotropy profiles are qualitatively\nsimilar to those expected of clusters that have undergone violent relaxation.\nAs well, rotation and anisotropic expansion are still present by the time of\ngas removal. This implies that evolution within the GMC was unable to\ncompletely erase the kinematics inherited by the merger.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-03-27T17:28:36Z"}
{"aid":"http://arxiv.org/abs/2503.21724v1","title":"Ram-pressure stripping caught in action in a forming galaxy cluster 3\n  billion years after the Big Bang","summary":"Galaxy clusters in the local Universe are dominated by massive quiescent\ngalaxies with old ages, formed at high redshifts. It is debated whether their\nquenching is driven by internal processes or environmental effects, which has\nbeen challenging due to the lack of observations during their peak formation\nepoch. Here we report clear evidence from ALMA of extended and elongated gas\ntails in nine galaxies in a forming cluster at z = 2.51. The distinct gas\ndistribution compared to the stellar emission probed by JWST, which is rather\nisolated without signatures of mergers or interactions, provides evidence of\nram-pressure stripping (RPS). This represents the most distant confirmed case\nof RPS, highlighting the critical role of environmental effects in gas removal\nat high redshifts, an often overlooked quenching pathway.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-03-27T17:36:57Z"}
{"aid":"http://arxiv.org/abs/2503.21725v1","title":"Low-noise environment for probing fundamental symmetries","summary":"We present the design and characterization of a low-noise environment for\nmeasuring the electron's electric dipole moment (EDM) with a beam of molecules.\nTo minimize magnetic Johnson noise from metals, the design features ceramic\nelectric field plates housed in a glass vacuum chamber. To suppress external\nmagnetic noise the apparatus is enclosed within a cylindrical four-layer\nmu-metal shield with a shielding factor exceeding $10^6$ in one radial\ndirection and $10^5$ in the other. Finite element modelling shows that the\ndifference between these shielding factors is due to imperfect joints between\nsections of mu-metal. Using atomic magnetometers to monitor the magnetic field\ninside the shield, we measure noise below 40 fT/$\\sqrt{{\\rm Hz}}$ at 1 Hz and\nabove, rising to 500 fT/$\\sqrt{{\\rm Hz}}$ at 0.1 Hz. Analytical and numerical\nstudies show that residual magnetic Johnson noise contributes approximately 13\nfT/$\\sqrt{{\\rm Hz}}$. The background magnetic field averaged along the beamline\nis maintained below 3 pT, with typical gradients of a few nT/m. An electric\nfield of 20 kV/cm is applied without discharges and with leakage currents below\n1 nA. Each magnetometer measures the magnetic field correlated with the\ndirection of the applied electric field with a precision of 0.11 fT in 104\nhours of data. These results demonstrate that the apparatus is suitable for\nmeasuring the electron EDM with precision at the $10^{-31}$ e cm level. The\ndesign principles and characterization techniques presented here are broadly\napplicable to precision measurements probing fundamental symmetries in\nmolecules, atoms, and neutrons.","main_category":"physics.atom-ph","categories":"physics.atom-ph","published":"2025-03-27T17:37:12Z"}
{"aid":"http://arxiv.org/abs/2503.21729v1","title":"ReaRAG: Knowledge-guided Reasoning Enhances Factuality of Large\n  Reasoning Models with Iterative Retrieval Augmented Generation","summary":"Large Reasoning Models (LRMs) exhibit remarkable reasoning abilities but rely\nprimarily on parametric knowledge, limiting factual accuracy. While recent\nworks equip reinforcement learning (RL)-based LRMs with retrieval capabilities,\nthey suffer from overthinking and lack robustness in reasoning, reducing their\neffectiveness in question answering (QA) tasks. To address this, we propose\nReaRAG, a factuality-enhanced reasoning model that explores diverse queries\nwithout excessive iterations. Our solution includes a novel data construction\nframework with an upper bound on the reasoning chain length. Specifically, we\nfirst leverage an LRM to generate deliberate thinking, then select an action\nfrom a predefined action space (Search and Finish). For Search action, a query\nis executed against the RAG engine, where the result is returned as observation\nto guide reasoning steps later. This process iterates until a Finish action is\nchosen. Benefiting from ReaRAG's strong reasoning capabilities, our approach\noutperforms existing baselines on multi-hop QA. Further analysis highlights its\nstrong reflective ability to recognize errors and refine its reasoning\ntrajectory. Our study enhances LRMs' factuality while effectively integrating\nrobust reasoning for Retrieval-Augmented Generation (RAG).","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-03-27T17:44:18Z"}
{"aid":"http://arxiv.org/abs/2503.21734v1","title":"Structure and Melting of Fe, MgO, SiO2, and MgSiO3 in Planets: Database,\n  Inversion, and Phase Diagram","summary":"We present globally inverted pressure-temperature (P-T) phase diagrams up to\n5,000 GPa for four fundamental planetary materials, Fe, MgO, SiO2, and MgSiO3,\nderived from logistic regression and supervised learning, together with an\nexperimental phase equilibria database. These new P-T phase diagrams provide a\nsolution to long-standing disputes about their melting curves. Their\nimplications extend to the melting and freezing of rocky materials in the\ninterior of giant planets and super-Earth exoplanets, contributing to the\nrefinement of their internal structure models.","main_category":"astro-ph.EP","categories":"astro-ph.EP,physics.data-an,physics.geo-ph","published":"2025-03-27T17:48:04Z"}
{"aid":"http://arxiv.org/abs/2503.21747v1","title":"CTRL-O: Language-Controllable Object-Centric Visual Representation\n  Learning","summary":"Object-centric representation learning aims to decompose visual scenes into\nfixed-size vectors called \"slots\" or \"object files\", where each slot captures a\ndistinct object. Current state-of-the-art object-centric models have shown\nremarkable success in object discovery in diverse domains, including complex\nreal-world scenes. However, these models suffer from a key limitation: they\nlack controllability. Specifically, current object-centric models learn\nrepresentations based on their preconceived understanding of objects, without\nallowing user input to guide which objects are represented. Introducing\ncontrollability into object-centric models could unlock a range of useful\ncapabilities, such as the ability to extract instance-specific representations\nfrom a scene. In this work, we propose a novel approach for user-directed\ncontrol over slot representations by conditioning slots on language\ndescriptions. The proposed ConTRoLlable Object-centric representation learning\napproach, which we term CTRL-O, achieves targeted object-language binding in\ncomplex real-world scenes without requiring mask supervision. Next, we apply\nthese controllable slot representations on two downstream vision language\ntasks: text-to-image generation and visual question answering. The proposed\napproach enables instance-specific text-to-image generation and also achieves\nstrong performance on visual question answering.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-03-27T17:53:50Z"}
{"aid":"http://arxiv.org/abs/2503.21750v1","title":"Optical control of orbital magnetism in magic angle twisted bilayer\n  graphene","summary":"Flat bands in graphene-based moir\\'e structures host a wide range of emerging\nstrongly correlated and topological phenomena. Optically probing and\ncontrolling them can reveal important information such as symmetry and\ndynamics, but have so far been challenging due to the small energy gap compared\nto optical wavelengths. Here, we report near infrared optical control of\norbital magnetism and associated anomalous Hall effects (AHE) in a magic angle\ntwisted bilayer graphene (MATBG) on monolayer WSe$_2$ device. We show that the\nproperties of the AHE, such as hysteresis and amplitude, can be controlled by\nlight near integer moir\\'e fillings, where spontaneous ferromagnetism exists.\nBy modulating the light helicity, we observe periodic modulation of the\ntransverse resistance in a wide range of fillings, indicating light induced\norbital magnetization through a large inverse Faraday effect. At the transition\nbetween metallic and AHE regimes, we also reveal large and random switching of\nthe Hall resistivity, which are attributed to optical control of percolating\ncluster of magnetic domains. Our results open the door to optical manipulation\nof correlation and topology in MATBG and related structures.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mes-hall","published":"2025-03-27T17:56:23Z"}
{"aid":"http://arxiv.org/abs/2503.21774v1","title":"Optimal Stepsize for Diffusion Sampling","summary":"Diffusion models achieve remarkable generation quality but suffer from\ncomputational intensive sampling due to suboptimal step discretization. While\nexisting works focus on optimizing denoising directions, we address the\nprincipled design of stepsize schedules. This paper proposes Optimal Stepsize\nDistillation, a dynamic programming framework that extracts theoretically\noptimal schedules by distilling knowledge from reference trajectories. By\nreformulating stepsize optimization as recursive error minimization, our method\nguarantees global discretization bounds through optimal substructure\nexploitation. Crucially, the distilled schedules demonstrate strong robustness\nacross architectures, ODE solvers, and noise schedules. Experiments show 10x\naccelerated text-to-image generation while preserving 99.4% performance on\nGenEval. Our code is available at https://github.com/bebebe666/OptimalSteps.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:46Z"}
{"aid":"http://arxiv.org/abs/2503.23681v1","title":"Universality of Shell Effects in Fusion-Fission Mass Distributions","summary":"We present the results of a broad, systematic study of heavy-ion induced\nfission mass distributions for every even-Z compound nucleus ($Z_\\mathrm{CN}$)\nfrom $^{144}$Gd to $^{212}$Th. We find systematic evidence of shell-driven\nstructure in every fission mass distribution. The change in shape of the mass\ndistributions with $Z_\\mathrm{CN}$ is consistent with the results of\nquantitative simultaneous fitting in mass and total kinetic energy,\ndemonstrating that fragment proton shell gaps at $Z_\\mathrm{FF} = 34, 36$ and\n$Z_\\mathrm{FF} = 44, 46$ are \\textit{both} major drivers of fission mass\ndistributions below the actinide region. The mass distributions show enhanced\nyields at mass symmetry for values of $Z_\\mathrm{CN}$ equal to two times these\nfavoured $Z_\\mathrm{FF}$ values. Thus, the same shell gaps that are drivers of\nmass-asymmetric fission also affect mass distributions at and near\nmass-symmetry. For all systems a second, more mass-asymmetric, fission mode is\nrequired to fit the fission mass distributions. If driven by a single shell\ngap, it appears to be in the light fragment around $Z_\\mathrm{FF} = 28, 30$.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-03-31T03:02:02Z"}
{"aid":"http://arxiv.org/abs/2503.23686v1","title":"Data-Driven Forecasting of High-Dimensional Transient and Stationary\n  Processes via Space-Time Projection","summary":"Space-Time Projection (STP) is introduced as a data-driven forecasting\napproach for high-dimensional and time-resolved data. The method computes\nextended space-time proper orthogonal modes from training data spanning a\nprediction horizon comprising both hindcast and forecast intervals. Forecasts\nare then generated by projecting the hindcast portion of these modes onto new\ndata, simultaneously leveraging their orthogonality and optimal correlation\nwith the forecast extension. Rooted in Proper Orthogonal Decomposition (POD)\ntheory, dimensionality reduction and time-delay embedding are intrinsic to the\napproach. For a given ensemble and fixed prediction horizon, the only tunable\nparameter is the truncation rank--no additional hyperparameters are required.\nThe hindcast accuracy serves as a reliable indicator for short-term forecast\naccuracy and establishes a lower bound on forecast errors. The efficacy of the\nmethod is demonstrated using two datasets: transient, highly anisotropic\nsimulations of supernova explosions in a turbulent interstellar medium, and\nexperimental velocity fields of a turbulent high-subsonic engineering flow. In\na comparative study with standard Long Short-Term Memory (LSTM) neural\nnetworks--acknowledging that alternative architectures or training strategies\nmay yield different outcomes--the method consistently provided more accurate\nforecasts. Considering its simplicity and robust performance, STP offers an\ninterpretable and competitive benchmark for forecasting high-dimensional\ntransient and chaotic processes, relying purely on spatiotemporal correlation\ninformation.","main_category":"cs.LG","categories":"cs.LG,astro-ph.GA,nlin.CD,physics.comp-ph,physics.data-an,physics.flu-dyn","published":"2025-03-31T03:36:59Z"}
{"aid":"http://arxiv.org/abs/2503.23697v1","title":"A Low-complexity Structured Neural Network to Realize States of\n  Dynamical Systems","summary":"Data-driven learning is rapidly evolving and places a new perspective on\nrealizing state-space dynamical systems. However, dynamical systems derived\nfrom nonlinear ordinary differential equations (ODEs) suffer from limitations\nin computational efficiency. Thus, this paper stems from data-driven learning\nto advance states of dynamical systems utilizing a structured neural network\n(StNN). The proposed learning technique also seeks to identify an optimal,\nlow-complexity operator to solve dynamical systems, the so-called Hankel\noperator, derived from time-delay measurements. Thus, we utilize the StNN based\non the Hankel operator to solve dynamical systems as an alternative to existing\ndata-driven techniques. We show that the proposed StNN reduces the number of\nparameters and computational complexity compared with the conventional neural\nnetworks and also with the classical data-driven techniques, such as Sparse\nIdentification of Nonlinear Dynamics (SINDy) and Hankel Alternative view of\nKoopman (HAVOK), which is commonly known as delay-Dynamic Mode\nDecomposition(DMD) or Hankel-DMD. More specifically, we present numerical\nsimulations to solve dynamical systems utilizing the StNN based on the Hankel\noperator beginning from the fundamental Lotka-Volterra model, where we compare\nthe StNN with the LEarning Across Dynamical Systems (LEADS), and extend our\nanalysis to highly nonlinear and chaotic Lorenz systems, comparing the StNN\nwith conventional neural networks, SINDy, and HAVOK. Hence, we show that the\nproposed StNN paves the way for realizing state-space dynamical systems with a\nlow-complexity learning algorithm, enabling prediction and understanding of\nfuture states.","main_category":"cs.LG","categories":"cs.LG,math.DS","published":"2025-03-31T03:52:38Z"}
{"aid":"http://arxiv.org/abs/2503.23699v1","title":"Vapor-mediated wetting and imbibition control on micropatterned surfaces","summary":"Wetting of micropatterned surfaces is ubiquitous in nature and key to many\ntechnological applications like spray cooling, inkjet printing, and\nsemiconductor processing. Overcoming the intrinsic, chemistry- and\ntopography-governed wetting behaviors often requires specific materials which\nlimits applicability. Here, we show that spreading and wicking of water\ndroplets on hydrophilic surface patterns can be controlled by the presence of\nthe vapor of another liquid with lower surface tension. We show that delayed\nwicking arises from Marangoni forces due to vapor condensation, competing with\nthe capillary wicking force of the surface topography. Thereby, macroscopic\ndroplets can be brought into an effective apparent wetting behavior, decoupled\nfrom the surface topography, but coexisting with a wicking film, cloaking the\npattern. We demonstrate how modulating the vapor concentration in space and\ntime may guide droplets across patterns and even extract imbibed liquids,\ndevising new strategies for coating, cleaning and drying of functional surface\ndesigns.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.flu-dyn","published":"2025-03-31T07:00:45Z"}
{"aid":"http://arxiv.org/abs/2503.23703v1","title":"Minimal solutions of tropical linear differential systems","summary":"We introduce and study minimal (with respect to inclusion) solutions of\nsystems of tropical linear differential equations. We describe the set of all\nminimal solutions for a single equation. It is shown that any tropical linear\ndifferential equation in a single unknown has either a solution or a solution\nat infinity. For a generic system of $n$ tropical linear differential equations\nin $n$ unknowns, upper and lower bounds on the number of minimal solutions are\nestablished. The upper bound involves inversions of a family of permutations\nwhich generalize inversions of a single permutation. For $n=1, 2$, we show that\nthe bounds are sharp.","main_category":"math.AG","categories":"math.AG,math.CO","published":"2025-03-31T04:00:24Z"}
{"aid":"http://arxiv.org/abs/2503.23715v1","title":"HOIGen-1M: A Large-scale Dataset for Human-Object Interaction Video\n  Generation","summary":"Text-to-video (T2V) generation has made tremendous progress in generating\ncomplicated scenes based on texts. However, human-object interaction (HOI)\noften cannot be precisely generated by current T2V models due to the lack of\nlarge-scale videos with accurate captions for HOI. To address this issue, we\nintroduce HOIGen-1M, the first largescale dataset for HOI Generation,\nconsisting of over one million high-quality videos collected from diverse\nsources. In particular, to guarantee the high quality of videos, we first\ndesign an efficient framework to automatically curate HOI videos using the\npowerful multimodal large language models (MLLMs), and then the videos are\nfurther cleaned by human annotators. Moreover, to obtain accurate textual\ncaptions for HOI videos, we design a novel video description method based on a\nMixture-of-Multimodal-Experts (MoME) strategy that not only generates\nexpressive captions but also eliminates the hallucination by individual MLLM.\nFurthermore, due to the lack of an evaluation framework for generated HOI\nvideos, we propose two new metrics to assess the quality of generated videos in\na coarse-to-fine manner. Extensive experiments reveal that current T2V models\nstruggle to generate high-quality HOI videos and confirm that our HOIGen-1M\ndataset is instrumental for improving HOI video generation. Project webpage is\navailable at https://liuqi-creat.github.io/HOIGen.github.io.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T04:30:34Z"}
{"aid":"http://arxiv.org/abs/2503.23718v1","title":"Detecting Functional Bugs in Smart Contracts through LLM-Powered and\n  Bug-Oriented Composite Analysis","summary":"Smart contracts are fundamental pillars of the blockchain, playing a crucial\nrole in facilitating various business transactions. However, these smart\ncontracts are vulnerable to exploitable bugs that can lead to substantial\nmonetary losses. A recent study reveals that over 80% of these exploitable\nbugs, which are primarily functional bugs, can evade the detection of current\ntools. The primary issue is the significant gap between understanding the\nhigh-level logic of the business model and checking the low-level\nimplementations in smart contracts. Furthermore, identifying deeply rooted\nfunctional bugs in smart contracts requires the automated generation of\neffective detection oracles based on various bug features. To address these\nchallenges, we design and implement PROMFUZZ, an automated and scalable system\nto detect functional bugs, in smart contracts. In PROMFUZZ, we first propose a\nnovel Large Language Model (LLM)-driven analysis framework, which leverages a\ndual-agent prompt engineering strategy to pinpoint potentially vulnerable\nfunctions for further scrutiny. We then implement a dual-stage coupling\napproach, which focuses on generating invariant checkers that leverage logic\ninformation extracted from potentially vulnerable functions. Finally, we design\na bug-oriented fuzzing engine, which maps the logical information from the\nhigh-level business model to the low-level smart contract implementations, and\nperforms the bug-oriented fuzzing on targeted functions. We compare PROMFUZZ\nwith multiple state-of-the-art methods. The results show that PROMFUZZ achieves\n86.96% recall and 93.02% F1-score in detecting functional bugs, marking at\nleast a 50% improvement in both metrics over state-of-the-art methods.\nMoreover, we perform an in-depth analysis on real-world DeFi projects and\ndetect 30 zero-day bugs. Up to now, 24 zero-day bugs have been assigned CVE\nIDs.","main_category":"cs.SE","categories":"cs.SE,cs.CR","published":"2025-03-31T04:39:51Z"}
{"aid":"http://arxiv.org/abs/2503.23726v1","title":"PDSL: Privacy-Preserved Decentralized Stochastic Learning with\n  Heterogeneous Data Distribution","summary":"In the paradigm of decentralized learning, a group of agents collaborates to\nlearn a global model using distributed datasets without a central server.\nHowever, due to the heterogeneity of the local data across the different\nagents, learning a robust global model is rather challenging. Moreover, the\ncollaboration of the agents relies on their gradient information exchange,\nwhich poses a risk of privacy leakage. In this paper, to address these issues,\nwe propose PDSL, a novel privacy-preserved decentralized stochastic learning\nalgorithm with heterogeneous data distribution. On one hand, we innovate in\nutilizing the notion of Shapley values such that each agent can precisely\nmeasure the contributions of its heterogeneous neighbors to the global learning\ngoal; on the other hand, we leverage the notion of differential privacy to\nprevent each agent from suffering privacy leakage when it contributes gradient\ninformation to its neighbors. We conduct both solid theoretical analysis and\nextensive experiments to demonstrate the efficacy of our PDSL algorithm in\nterms of privacy preservation and convergence.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T04:58:05Z"}
{"aid":"http://arxiv.org/abs/2503.23732v1","title":"Generalized Reflected BSDEs with RCLL Random Obstacles in a General\n  Filtration","summary":"This paper addresses the existence and uniqueness of solutions to Reflected\nGeneralized Backward Stochastic Differential Equations (GRBSDEs) within a\ngeneral filtration that supports a Brownian motion and an independent\ninteger-valued random measure. Our study focuses on cases where the given data\nsatisfy appropriate $\\mathbb{L}^2$-integrability conditions and the\ncoefficients satisfy a monotonicity assumption. Additionally, we establish a\nconnection between the solution and an optimal control problem over the set of\nstopping times.","main_category":"math.PR","categories":"math.PR","published":"2025-03-31T05:08:57Z"}
{"aid":"http://arxiv.org/abs/2503.23750v1","title":"Float Lattice Gas Automata: A connection between Molecular Dynamics and\n  Lattice Boltzmann Method for quantum computers","summary":"Building upon the Integer Lattice Gas Automata framework of Blommel\n\\textit{et al.} \\cite{PhysRevE.97.023310}, we introduce a simplified,\nfluctuation-free variant. This approach relies on floating-point numbers and\nclosely mirrors the Lattice Boltzmann Method (LBM), with the key distinction\nbeing a novel collision operator. This operator, derived from the ensemble\naverage of transition probabilities, generates nonlinear terms. We propose this\nnew Float Lattice Gas Automata (FLGA) collision as a computationally efficient\nalternative to traditional and quantum LBM implementations.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T06:02:16Z"}
{"aid":"http://arxiv.org/abs/2503.23752v1","title":"StrokeFusion: Vector Sketch Generation via Joint Stroke-UDF Encoding and\n  Latent Sequence Diffusion","summary":"In the field of sketch generation, raster-format trained models often produce\nnon-stroke artifacts, while vector-format trained models typically lack a\nholistic understanding of sketches, leading to compromised recognizability.\nMoreover, existing methods struggle to extract common features from similar\nelements (e.g., eyes of animals) appearing at varying positions across\nsketches. To address these challenges, we propose StrokeFusion, a two-stage\nframework for vector sketch generation. It contains a dual-modal sketch feature\nlearning network that maps strokes into a high-quality latent space. This\nnetwork decomposes sketches into normalized strokes and jointly encodes stroke\nsequences with Unsigned Distance Function (UDF) maps, representing sketches as\nsets of stroke feature vectors. Building upon this representation, our\nframework exploits a stroke-level latent diffusion model that simultaneously\nadjusts stroke position, scale, and trajectory during generation. This enables\nhigh-fidelity sketch generation while supporting stroke interpolation editing.\nExtensive experiments on the QuickDraw dataset demonstrate that our framework\noutperforms state-of-the-art techniques, validating its effectiveness in\npreserving structural integrity and semantic features. Code and models will be\nmade publicly available upon publication.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-03-31T06:03:03Z"}
{"aid":"http://arxiv.org/abs/2503.23757v1","title":"Time-Series Forecasting via Topological Information Supervised Framework\n  with Efficient Topological Feature Learning","summary":"Topological Data Analysis (TDA) has emerged as a powerful tool for extracting\nmeaningful features from complex data structures, driving significant\nadvancements in fields such as neuroscience, biology, machine learning, and\nfinancial modeling. Despite its success, the integration of TDA with\ntime-series prediction remains underexplored due to three primary challenges:\nthe limited utilization of temporal dependencies within topological features,\ncomputational bottlenecks associated with persistent homology, and the\ndeterministic nature of TDA pipelines restricting generalized feature learning.\nThis study addresses these challenges by proposing the Topological Information\nSupervised (TIS) Prediction framework, which leverages neural networks and\nConditional Generative Adversarial Networks (CGANs) to generate synthetic\ntopological features, preserving their distribution while significantly\nreducing computational time. We propose a novel training strategy that\nintegrates topological consistency loss to improve the predictive accuracy of\ndeep learning models. Specifically, we introduce two state-of-the-art models,\nTIS-BiGRU and TIS-Informer, designed to capture short-term and long-term\ntemporal dependencies, respectively. Comparative experimental results\ndemonstrate the superior performance of TIS models over conventional\npredictors, validating the effectiveness of integrating topological\ninformation. This work not only advances TDA-based time-series prediction but\nalso opens new avenues for utilizing topological features in deep learning\narchitectures.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T06:16:19Z"}
{"aid":"http://arxiv.org/abs/2503.23759v1","title":"Word Break on SLP-Compressed Texts","summary":"Word Break is a prototypical factorization problem in string processing:\nGiven a word $w$ of length $N$ and a dictionary $\\mathcal{D} = \\{d_1, d_2,\n\\ldots, d_{K}\\}$ of $K$ strings, determine whether we can partition $w$ into\nwords from $\\mathcal{D}$. We propose the first algorithm that solves the Word\nBreak problem over the SLP-compressed input text $w$. Specifically, we show\nthat, given the string $w$ represented using an SLP of size $g$, we can solve\nthe Word Break problem in $\\mathcal{O}(g \\cdot m^{\\omega} + M)$ time, where $m\n= \\max_{i=1}^{K} |d_i|$, $M = \\sum_{i=1}^{K} |d_i|$, and $\\omega \\geq 2$ is the\nmatrix multiplication exponent. We obtain our algorithm as a simple corollary\nof a more general result: We show that in $\\mathcal{O}(g \\cdot m^{\\omega} + M)$\ntime, we can index the input text $w$ so that solving the Word Break problem\nfor any of its substrings takes $\\mathcal{O}(m^2 \\log N)$ time (independent of\nthe substring length). Our second contribution is a lower bound: We prove that,\nunless the Combinatorial $k$-Clique Conjecture fails, there is no combinatorial\nalgorithm for Word Break on SLP-compressed strings running in $\\mathcal{O}(g\n\\cdot m^{2-\\epsilon} + M)$ time for any $\\epsilon > 0$.","main_category":"cs.DS","categories":"cs.DS","published":"2025-03-31T06:19:05Z"}
{"aid":"http://arxiv.org/abs/2503.23764v1","title":"WaveFormer: A 3D Transformer with Wavelet-Driven Feature Representation\n  for Efficient Medical Image Segmentation","summary":"Transformer-based architectures have advanced medical image analysis by\neffectively modeling long-range dependencies, yet they often struggle in 3D\nsettings due to substantial memory overhead and insufficient capture of\nfine-grained local features. We address these limi- tations with WaveFormer, a\nnovel 3D-transformer that: i) leverages the fundamental frequency-domain\nproperties of features for contextual rep- resentation, and ii) is inspired by\nthe top-down mechanism of the human visual recognition system, making it a\nbiologically motivated architec- ture. By employing discrete wavelet\ntransformations (DWT) at multiple scales, WaveFormer preserves both global\ncontext and high-frequency de- tails while replacing heavy upsampling layers\nwith efficient wavelet-based summarization and reconstruction. This\nsignificantly reduces the number of parameters, which is critical for\nreal-world deployment where compu- tational resources and training times are\nconstrained. Furthermore, the model is generic and easily adaptable to diverse\napplications. Evaluations on BraTS2023, FLARE2021, and KiTS2023 demonstrate\nperformance on par with state-of-the-art methods while offering substantially\nlower computational complexity.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T06:28:41Z"}
{"aid":"http://arxiv.org/abs/2503.23766v1","title":"Accelerating High-Efficiency Organic Photovoltaic Discovery via\n  Pretrained Graph Neural Networks and Generative Reinforcement Learning","summary":"Organic photovoltaic (OPV) materials offer a promising avenue toward\ncost-effective solar energy utilization. However, optimizing donor-acceptor\n(D-A) combinations to achieve high power conversion efficiency (PCE) remains a\nsignificant challenge. In this work, we propose a framework that integrates\nlarge-scale pretraining of graph neural networks (GNNs) with a GPT-2\n(Generative Pretrained Transformer 2)-based reinforcement learning (RL)\nstrategy to design OPV molecules with potentially high PCE. This approach\nproduces candidate molecules with predicted efficiencies approaching 21\\%,\nalthough further experimental validation is required. Moreover, we conducted a\npreliminary fragment-level analysis to identify structural motifs recognized by\nthe RL model that may contribute to enhanced PCE, thus providing design\nguidelines for the broader research community. To facilitate continued\ndiscovery, we are building the largest open-source OPV dataset to date,\nexpected to include nearly 3,000 donor-acceptor pairs. Finally, we discuss\nplans to collaborate with experimental teams on synthesizing and characterizing\nAI-designed molecules, which will provide new data to refine and improve our\npredictive and generative models.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T06:31:15Z"}
{"aid":"http://arxiv.org/abs/2503.23773v1","title":"Seasonal bias-correction of daily precipitation over France using a\n  stitch model designed for robust extremes representation","summary":"Highly resoluted and accurate daily precipitation data are required for\nimpact models to perform adequately and to correctly measure high-risk events'\nimpact. In order to produce such data, bias-correction is often needed. Most of\nthose statistical methods correct the probability distributions of daily\nprecipitation by modeling them using either empirical or parametric\ndistributions. A recent semi-parametric model based on a penalized Berk-Jones\n(BJ) statistical test which allows for an automatic and personalized splicing\nof parametric and nonparametric has been developed. This method, called\nStitch-BJ model, was found to be able to model daily precipitation correctly\nand showed interesting potential in a bias-correction setting. In the present\nstudy, we will consolidate these results by taking into account the seasonal\nproperties of daily precipitation in an out-of-sample context, and by\nconsidering dry days probabilities in our methodology. We evaluate the\nperformance of the Stitch-BJ method in this seasonal bias-correction setting\nagainst more classical models such as the Gamma, Exponentiated Weibull (ExpW),\nExtended Generalized Pareto (EGP) or empirical distributions. The Stitch-BJ\ndistribution was able to consistently perform as well or better than all the\nother models over the validation set, including the empirical distribution,\nwhich is often used due to its robustness.","main_category":"stat.AP","categories":"stat.AP","published":"2025-03-31T06:48:42Z"}
{"aid":"http://arxiv.org/abs/2503.23778v1","title":"Efficient defect healing of single-walled cabron nanotubes through $\n  \\mathrm{C}_{2}\\mathrm{H}_{2} $-assisted multiple-cycle treatment with air\n  exposure","summary":"Defects in single-walled carbon nanotubes (SWCNTs) degrade their\nmechanical,electrical, and thermal properties, limiting their potential\napplications. To realize the diverse applications of SWCNTs, it is essential to\nenhance their crystallinity through effective defect healing. However,\ntraditional thermal treatments typically require temperatures above\n1800{\\deg}C, which can alter the nanotube structure. Previously, defect healing\nof SWCNTs was achieved at a relatively low temperature of 1100{\\deg}C, using\nC$_{2}$H$_{2}$ assistance, but the efficiency was limited. In this study, we\ndeveloped a C$_{2}$H$_{2}$-assisted multiple-cycle process at an even lower\ntemperature of 1000{\\deg}C combined with air exposure, achieving highly\nefficient defect healing while preserving the nanotube structure. The\ncombination of multiple-cycle treatment and air exposure between cycles was\nfound to promote defect activation, suppress the formation of amorphous carbon,\nand enhance the effectiveness of defect healing. Additionally, we successfully\nhealed commercially available bulk-scale SWCNTs (super-growth SWCNTs), noting\nthat their healing behavior differed from lab-grown SWCNTs with smaller\ndiameters synthesized from nanodiamond. The efficient and structure-preserved\nhealing process developed in this study broadens the potential applications of\nhigh-quality SWCNTs, including flexible electronics, high-performance\ncomposites, and energy storage devices.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-31T06:53:11Z"}
{"aid":"http://arxiv.org/abs/2503.23785v1","title":"ObfusQate: Unveiling the First Quantum Program Obfuscation Framework","summary":"This paper introduces ObfusQate, a novel tool that conducts obfuscations\nusing quantum primitives to enhance the security of both classical and quantum\nprograms. We have designed and implemented two primary categories of\nobfuscations: quantum circuit level obfuscation and code level obfuscation,\nencompassing a total of eight distinct methods. Quantum circuit-level\nobfuscation leverages on quantum gates and circuits, utilizing strategies such\nas quantum gate hiding and identity matrices to construct complex,\nnon-intuitive circuits that effectively obscure core functionalities and resist\nreverse engineering, making the underlying code difficult to interpret.\nMeanwhile, code-level obfuscation manipulates the logical sequence of program\noperations through quantum-based opaque predicates, obfuscating execution paths\nand rendering program behavior more unpredictable and challenging to analyze.\nAdditionally, ObfusQate can be used to obfuscate malicious code segments,\nmaking them harder to detect and analyze. These advancements establish a\nfoundational framework for further exploration into the potential and\nlimitations of quantum-based obfuscation techniques, positioning ObfusQate as a\nvaluable tool for future developers to enhance code security in the evolving\nlandscape of software development. To the best of our knowledge, ObfusQate\nrepresents the pioneering work in developing an automated framework for\nimplementing obfuscations leveraging quantum primitives. Security evaluations\nshow that obfuscations by ObfusQate maintain code behavior with polynomial\noverheads in space and time complexities. We have also demonstrated an\noffensive use case by embedding a keylogger into Shor's algorithm and\nobfuscating it using ObfusQate. Our results show that current Large language\nmodels like GPT 4o, GPT o3 mini and Grok 3 were not able to identify the\nmalicious keylogger after obfuscation.","main_category":"cs.CR","categories":"cs.CR,cs.ET","published":"2025-03-31T07:02:25Z"}
{"aid":"http://arxiv.org/abs/2503.23787v1","title":"A rational cohomology which including that of a spin hyperelliptic\n  mapping class group","summary":"Let $\\mathfrak{G}=\\mathfrak{S}_{q} \\overleftrightarrow{\\times}\n\\mathfrak{S}_q$ be the $\\mathbb{Z}/2$-extension of the product of two symmetric\ngroups $\\mathfrak{S}_{q} \\times \\mathfrak{S}_q$. In this paper, we compute the\n$\\mathfrak{G}$-invariant part of the rational cohomology of the pure braid\ngroup $P_{n}$, where $n=2q$, denoted by $H^{*}(P_n)^{\\mathfrak{G}}$. As is\nknown classically, $H^{*}(P_n)^{\\mathfrak{G}}$ includes the rational cohomology\nof a spin hyperelliptic mapping class group, denoted by\n$H^*(\\mathcal{S}(\\Sigma_{g};c))$, where $2g+2=n=2q$.","main_category":"math.GT","categories":"math.GT","published":"2025-03-31T07:02:36Z"}
{"aid":"http://arxiv.org/abs/2503.23792v1","title":"When do firms sell high durability products? The case of light bulb\n  industry","summary":"This study empirically investigates firms' incentives on the choice of\nproduct durability, and its social optimality, by developing a dynamic\nstructural model of durable goods with forward-looking consumers and\noligopolistic multi-product firms. Based on the observations of the light bulb\nmarket, it specifies a model where firms produce multiple products with\ndifferent durability levels and set product prices based on dynamic incentives.\nIt proposes and applies novel estimation algorithms that alleviate the\ncomputational burden and data requirement for estimating demand and marginal\ncost parameters of dynamic demand models. Using light bulb market data in\nJapan, structural parameters are estimated. This study obtains the following\nresults. First, large firms have incentives to collude to eliminate high\ndurability incandescent lamps, though it is profitable to sell them for each\nfirm. In contrast, when they can collude on prices, they don't have incentives\nto eliminate high durability bulbs. Second, eliminating high durability\nincandescent lamps leads to larger producer and total surplus, though it leads\nto lower consumer surplus.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-03-31T07:13:44Z"}
{"aid":"http://arxiv.org/abs/2503.23802v1","title":"Herscovici Conjecture on Pebbling","summary":"Consider a configuration of pebbles on the vertices of a connected graph. A\npebbling move is to remove two pebbles from a vertex and to place one pebble at\nthe neighbouring vertex of the vertex from which the pebbles are removed.\n  For a positive integer $t$, with every configuration of $\\pi_t(G)$(least\npositive integer) pebbles, if we can transfer $t$ pebbles to any target through\na number of pebbling moves then $\\pi_t(G)$ is called the $t$-pebbling number of\n$G$.\n  We discuss the computation of the $t$-pebbling number, the $2t-$ pebbling\nproperty and Herscovici conjecture considering total graphs.\n  \\bigskip \\noindent Keywords: pebbling moves, $t$- pebbling number,\n$2t$-pebbling property, Herscovici conjecture, total graphs.","main_category":"math.CO","categories":"math.CO","published":"2025-03-31T07:25:26Z"}
{"aid":"http://arxiv.org/abs/2503.23803v1","title":"Thinking Longer, Not Larger: Enhancing Software Engineering Agents via\n  Scaling Test-Time Compute","summary":"Recent advancements in software engineering agents have demonstrated\npromising capabilities in automating program improvements. However, their\nreliance on closed-source or resource-intensive models introduces significant\ndeployment challenges in private environments, prompting a critical question:\n\\textit{How can personally deployable open-source LLMs achieve comparable code\nreasoning performance?}\n  To this end, we propose a unified Test-Time Compute scaling framework that\nleverages increased inference-time computation instead of larger models. Our\nframework incorporates two complementary strategies: internal TTC and external\nTTC. Internally, we introduce a \\textit{development-contextualized trajectory\nsynthesis} method leveraging real-world software repositories to bootstrap\nmulti-stage reasoning processes, such as fault localization and patch\ngeneration. We further enhance trajectory quality through rejection sampling,\nrigorously evaluating trajectories along accuracy and complexity. Externally,\nwe propose a novel \\textit{development-process-based search} strategy guided by\nreward models and execution verification. This approach enables targeted\ncomputational allocation at critical development decision points, overcoming\nlimitations of existing \"end-point only\" verification methods.\n  Evaluations on SWE-bench Verified demonstrate our \\textbf{32B model achieves\na 46\\% issue resolution rate}, surpassing significantly larger models such as\nDeepSeek R1 671B and OpenAI o1. Additionally, we provide the empirical\nvalidation of the test-time scaling phenomenon within SWE agents, revealing\nthat \\textbf{models dynamically allocate more tokens to increasingly\nchallenging problems}, effectively enhancing reasoning capabilities. We\npublicly release all training data, models, and code to facilitate future\nresearch. https://github.com/yingweima2022/SWE-Reasoner","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-03-31T07:31:32Z"}
{"aid":"http://arxiv.org/abs/2503.23811v1","title":"Did ChatGPT or Copilot use alter the style of internet news headlines? A\n  time series regression analysis","summary":"The release of advanced Large Language Models (LLMs) such as ChatGPT and\nCopilot is changing the way text is created and may influence the content that\nwe find on the web. This study investigated whether the release of these two\npopular LLMs coincided with a change in writing style in headlines and links on\nworldwide news websites. 175 NLP features were obtained for each text in a\ndataset of 451 million headlines/links. An interrupted time series analysis was\napplied for each of the 175 NLP features to evaluate whether there were any\nstatistically significant sustained changes after the release dates of ChatGPT\nand/or Copilot. There were a total of 44 features that did not appear to have\nany significant sustained change after the release of ChatGPT/Copilot. A total\nof 91 other features did show significant change with ChatGPT and/or Copilot\nalthough significance with earlier control LLM release dates (GPT-1/2/3,\nGopher) removed them from consideration. This initial analysis suggests these\nlanguage models may have had a limited impact on the style of individual news\nheadlines/links, with respect to only some NLP measures.","main_category":"cs.CL","categories":"cs.CL,cs.SI","published":"2025-03-31T07:44:26Z"}
{"aid":"http://arxiv.org/abs/2503.23817v1","title":"MVDRAM: Enabling GeMV Execution in Unmodified DRAM for Low-Bit LLM\n  Acceleration","summary":"General matrix-vector multiplication (GeMV) remains a critical latency\nbottleneck in large language model (LLM) inference, even with quantized low-bit\nmodels. Processing-Using-DRAM (PUD), an analog in-DRAM computing technique, has\nthe potential to repurpose on-device DRAM as a GeMV engine, offering additional\nhigh-throughput processing capabilities to widespread consumer devices without\nDRAM modifications. However, applying PUD to GeMV operations in the LLM\ninference pipeline incurs significant overheads $\\textit{before}$ and\n$\\textit{after}$ in-DRAM computation, diminishing the benefits of its\nhigh-throughput processing capabilities.\n  This paper presents MVDRAM, the first practical system to accelerate GeMV\noperations for low-bit LLM inference using unmodified DRAM. By leveraging the\ndata sharing patterns and mathematical linearity in GeMV operations, MVDRAM\norchestrates the processor and DRAM to eliminate the costs associated with\npre-arranging inputs and bit-transposition of outputs required in conventional\nPUD approaches. Our experimental evaluation with four DDR4 DRAM modules shows\nthat MVDRAM achieves comparable or even better inference speed than the\nprocessor-based implementation for GeMV operations in low-bit (under 4-bit)\nLLM. In particular, MVDRAM achieves up to 7.29$\\times$ speedup and 30.5$\\times$\nenergy efficiency for low-bit GeMV operations. For end-to-end LLM inference,\nMVDRAM achieves 2.18$\\times$ and 1.31$\\times$ throughput improvements, along\nwith 3.04$\\times$ and 2.35$\\times$ energy efficiency, for 2-bit and 4-bit\nquantized low-bit models, respectively. MVDRAM has the potential to redefine\nthe AI hardware landscape by demonstrating the feasibility of standard DRAM as\nan LLM accelerator.","main_category":"cs.AR","categories":"cs.AR,cs.DC","published":"2025-03-31T07:54:59Z"}
{"aid":"http://arxiv.org/abs/2503.23830v1","title":"OrchMLLM: Orchestrate Multimodal Data with Batch Post-Balancing to\n  Accelerate Multimodal Large Language Model Training","summary":"Multimodal large language models (MLLMs), such as GPT-4o, are garnering\nsignificant attention. During the exploration of MLLM training, we identified\nModality Composition Incoherence, a phenomenon that the proportion of a certain\nmodality varies dramatically across different examples. It exacerbates the\nchallenges of addressing mini-batch imbalances, which lead to uneven GPU\nutilization between Data Parallel (DP) instances and severely degrades the\nefficiency and scalability of MLLM training, ultimately affecting training\nspeed and hindering further research on MLLMs.\n  To address these challenges, we introduce OrchMLLM, a comprehensive framework\ndesigned to mitigate the inefficiencies in MLLM training caused by Modality\nComposition Incoherence. First, we propose Batch Post-Balancing Dispatcher, a\ntechnique that efficiently eliminates mini-batch imbalances in sequential data.\nAdditionally, we integrate MLLM Global Orchestrator into the training framework\nto orchestrate multimodal data and tackle the issues arising from Modality\nComposition Incoherence. We evaluate OrchMLLM across various MLLM sizes,\ndemonstrating its efficiency and scalability. Experimental results reveal that\nOrchMLLM achieves a Model FLOPs Utilization (MFU) of $41.6\\%$ when training an\n84B MLLM with three modalities on $2560$ H100 GPUs, outperforming Megatron-LM\nby up to $3.1\\times$ in throughput.","main_category":"cs.DC","categories":"cs.DC,cs.AI","published":"2025-03-31T08:24:23Z"}
{"aid":"http://arxiv.org/abs/2503.23834v1","title":"$q$-deformed rationals and irrationals","summary":"The concept of $q$-deformation, or ``$q$-analogue'' arises in many areas of\nmathematics. In algebra and representation theory, it is the origin of quantum\ngroups; $q$-deformations are important for knot invariants, combinatorial\nenumeration, discrete geometry, analysis, and many other parts of mathematics.\nIn mathematical physics, $q$-deformations are often understood as\n``quantizations''.\n  The recently introduced notion of a $q$-deformed real number is based on the\ngeometric idea of invariance by a modular group action. The goal of this\nlecture is to explain what is a $q$-rational and a $q$-irrational, demonstrate\nbeautiful properties of these objects, and describe their relations to many\ndifferent areas. We also tried to describe some applications of $q$-numbers.","main_category":"math.CO","categories":"math.CO,math.QA","published":"2025-03-31T08:28:41Z"}
{"aid":"http://arxiv.org/abs/2503.23851v1","title":"Revealing quantum phase string effect in doped Mott-insulator: a tensor\n  network state approach","summary":"We apply the fermionic tensor network (TN) state method to understand the\nstrongly correlated nature in a doped Mott insulator. We conduct a comparative\nstudy of the $\\sigma t$-$J$ model, in which the no-double-occupancy constraint\nremains unchanged but the quantum phase string effect associated with doped\nholes is precisely switched off. Thus, the ground state of the $\\sigma t$-$J$\nmodel can serve as a well-controlled reference state of the standard $t$-$J$\nmodel. In the absence of phase string, the spin long-range antiferromagnetic\n(AFM) order is found to be essentially decoupled from the doped holes, and the\nlatter contribute to a Fermi-liquid-like compressibility and a coherent\nsingle-particle propagation with a markedly reduced pairing tendency. In\ncontrast, our TN calculations of the $t$-$J$ model indicate that the AFM order\ndecreases much faster with doping and the single-particle propagation of doped\nholes gets substantially suppressed, concurrently with a much stronger charge\ncompressibility at small doping and a significantly amplified Cooper pairing\ntendencies. These findings demonstrate that quantum many-body interference from\nphase strings plays a pivotal role in the $t$-$J$ model, mediating long-range\nentanglement between spin and charge degrees of freedom.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-03-31T08:55:55Z"}
{"aid":"http://arxiv.org/abs/2503.23862v1","title":"Learned Image Compression and Restoration for Digital Pathology","summary":"Digital pathology images play a crucial role in medical diagnostics, but\ntheir ultra-high resolution and large file sizes pose significant challenges\nfor storage, transmission, and real-time visualization. To address these\nissues, we propose CLERIC, a novel deep learning-based image compression\nframework designed specifically for whole slide images (WSIs). CLERIC\nintegrates a learnable lifting scheme and advanced convolutional techniques to\nenhance compression efficiency while preserving critical pathological details.\nOur framework employs a lifting-scheme transform in the analysis stage to\ndecompose images into low- and high-frequency components, enabling more\nstructured latent representations. These components are processed through\nparallel encoders incorporating Deformable Residual Blocks (DRB) and Recurrent\nResidual Blocks (R2B) to improve feature extraction and spatial adaptability.\nThe synthesis stage applies an inverse lifting transform for effective image\nreconstruction, ensuring high-fidelity restoration of fine-grained tissue\nstructures. We evaluate CLERIC on a digital pathology image dataset and compare\nits performance against state-of-the-art learned image compression (LIC)\nmodels. Experimental results demonstrate that CLERIC achieves superior\nrate-distortion (RD) performance, significantly reducing storage requirements\nwhile maintaining high diagnostic image quality. Our study highlights the\npotential of deep learning-based compression in digital pathology, facilitating\nefficient data management and long-term storage while ensuring seamless\nintegration into clinical workflows and AI-assisted diagnostic systems. Code\nand models are available at: https://github.com/pnu-amilab/CLERIC.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T09:09:09Z"}
{"aid":"http://arxiv.org/abs/2503.23873v1","title":"Exploring In-Context Learning Capabilities of ChatGPT for Pathological\n  Speech Detection","summary":"Automatic pathological speech detection approaches have shown promising\nresults, gaining attention as potential diagnostic tools alongside costly\ntraditional methods. While these approaches can achieve high accuracy, their\nlack of interpretability limits their applicability in clinical practice. In\nthis paper, we investigate the use of multimodal Large Language Models (LLMs),\nspecifically ChatGPT-4o, for automatic pathological speech detection in a\nfew-shot in-context learning setting. Experimental results show that this\napproach not only delivers promising performance but also provides explanations\nfor its decisions, enhancing model interpretability. To further understand its\neffectiveness, we conduct an ablation study to analyze the impact of different\nfactors, such as input type and system prompts, on the final results. Our\nfindings highlight the potential of multimodal LLMs for further exploration and\nadvancement in automatic pathological speech detection.","main_category":"eess.AS","categories":"eess.AS,cs.SD","published":"2025-03-31T09:23:52Z"}
{"aid":"http://arxiv.org/abs/2503.23875v1","title":"GenSwarm: Scalable Multi-Robot Code-Policy Generation and Deployment via\n  Language Models","summary":"The development of control policies for multi-robot systems traditionally\nfollows a complex and labor-intensive process, often lacking the flexibility to\nadapt to dynamic tasks. This has motivated research on methods to automatically\ncreate control policies. However, these methods require iterative processes of\nmanually crafting and refining objective functions, thereby prolonging the\ndevelopment cycle. This work introduces \\textit{GenSwarm}, an end-to-end system\nthat leverages large language models to automatically generate and deploy\ncontrol policies for multi-robot tasks based on simple user instructions in\nnatural language. As a multi-language-agent system, GenSwarm achieves zero-shot\nlearning, enabling rapid adaptation to altered or unseen tasks. The white-box\nnature of the code policies ensures strong reproducibility and\ninterpretability. With its scalable software and hardware architectures,\nGenSwarm supports efficient policy deployment on both simulated and real-world\nmulti-robot systems, realizing an instruction-to-execution end-to-end\nfunctionality that could prove valuable for robotics specialists and\nnon-specialists alike.The code of the proposed GenSwarm system is available\nonline: https://github.com/WindyLab/GenSwarm.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.MA","published":"2025-03-31T09:26:34Z"}
{"aid":"http://arxiv.org/abs/2503.23878v1","title":"Populations of evolved massive binary stars in the Small Magellanic\n  Cloud II: Predictions from rapid binary evolution","summary":"Massive star evolution plays a crucial role in astrophysics but bares large\nuncertainties. This problem becomes more severe by the majority of massive\nstars being born in close binary systems, whose evolution is affected by the\ninteraction of their components. We want to constrain major uncertainties in\nmassive binary star evolution, in particular the efficiency and the stability\nof the first mass transfer phase. We use the rapid population synthesis code\nComBinE to generate synthetic populations of post-interaction binaries,\nassuming constant mass-transfer efficiency. We employ a new merger criterion\nthat adjusts self-consistently to any prescribed mass-transfer efficiency. We\ntailor our synthetic populations to be comparable to the expected binary\npopulations in the Small Magellanic Cloud (SMC). We find that the observed\npopulations of evolved massive binaries can not be reproduced with a single\nmass-transfer efficiency. Instead, a rather high efficiency (>50%) is needed to\nreproduce the number of Be stars and Be/X-ray binaries in the SMC, while a low\nefficiency (~10%) leads to a better agreement with the observed number of\nWolf-Rayet stars. We construct a corresponding mass-dependent mass-transfer\nefficiency recipe to produce our fiducial synthetic SMC post-interaction binary\npopulation. It reproduces the observed number and properties of the Be/X-ray\nand WR-binaries rather well, and is not in stark disagreement with the observed\nOBe star population. It further predicts two large, yet unobserved populations\nof OB+BH binaries, that is ~100 OB+BH systems with rather small orbital periods\n(<20 days) and ~40 longer period OBe+BH systems.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA,astro-ph.HE","published":"2025-03-31T09:27:04Z"}
{"aid":"http://arxiv.org/abs/2503.23881v1","title":"ExScene: Free-View 3D Scene Reconstruction with Gaussian Splatting from\n  a Single Image","summary":"The increasing demand for augmented and virtual reality applications has\nhighlighted the importance of crafting immersive 3D scenes from a simple\nsingle-view image. However, due to the partial priors provided by single-view\ninput, existing methods are often limited to reconstruct low-consistency 3D\nscenes with narrow fields of view from single-view input. These limitations\nmake them less capable of generalizing to reconstruct immersive scenes. To\naddress this problem, we propose ExScene, a two-stage pipeline to reconstruct\nan immersive 3D scene from any given single-view image. ExScene designs a novel\nmultimodal diffusion model to generate a high-fidelity and globally consistent\npanoramic image. We then develop a panoramic depth estimation approach to\ncalculate geometric information from panorama, and we combine geometric\ninformation with high-fidelity panoramic image to train an initial 3D Gaussian\nSplatting (3DGS) model. Following this, we introduce a GS refinement technique\nwith 2D stable video diffusion priors. We add camera trajectory consistency and\ncolor-geometric priors into the denoising process of diffusion to improve color\nand spatial consistency across image sequences. These refined sequences are\nthen used to fine-tune the initial 3DGS model, leading to better reconstruction\nquality. Experimental results demonstrate that our ExScene achieves consistent\nand immersive scene reconstruction using only single-view input, significantly\nsurpassing state-of-the-art baselines.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T09:33:22Z"}
{"aid":"http://arxiv.org/abs/2503.23882v1","title":"GLane3D : Detecting Lanes with Graph of 3D Keypoints","summary":"Accurate and efficient lane detection in 3D space is essential for autonomous\ndriving systems, where robust generalization is the foremost requirement for 3D\nlane detection algorithms. Considering the extensive variation in lane\nstructures worldwide, achieving high generalization capacity is particularly\nchallenging, as algorithms must accurately identify a wide variety of lane\npatterns worldwide. Traditional top-down approaches rely heavily on learning\nlane characteristics from training datasets, often struggling with lanes\nexhibiting previously unseen attributes. To address this generalization\nlimitation, we propose a method that detects keypoints of lanes and\nsubsequently predicts sequential connections between them to construct complete\n3D lanes. Each key point is essential for maintaining lane continuity, and we\npredict multiple proposals per keypoint by allowing adjacent grids to predict\nthe same keypoint using an offset mechanism. PointNMS is employed to eliminate\noverlapping proposal keypoints, reducing redundancy in the estimated BEV graph\nand minimizing computational overhead from connection estimations. Our model\nsurpasses previous state-of-the-art methods on both the Apollo and OpenLane\ndatasets, demonstrating superior F1 scores and a strong generalization capacity\nwhen models trained on OpenLane are evaluated on the Apollo dataset, compared\nto prior approaches.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T09:33:26Z"}
{"aid":"http://arxiv.org/abs/2503.23884v1","title":"Sampled-data and event-triggered control of globally Lipschitz\n  infinite-dimensional systems","summary":"We show that if a linear infinite-dimensional system is exponentially\nstabilizable by compact feedback, it is also stabilizable by means of a\nsampled-data feedback that is fed through a globally Lipschitz nonlinearity,\nprovided that the sector bound for the nonlinearity and the sampling time is\nsmall enough. Next we develop a switching-based event-triggered control scheme\nstabilizing the system with a reduced number of switching events. We\ndemonstrate our results on an example of finite-dimensional stabilization of a\nSturm-Liouville parabolic system.","main_category":"math.OC","categories":"math.OC","published":"2025-03-31T09:37:08Z"}
{"aid":"http://arxiv.org/abs/2503.23897v1","title":"Training-Free Text-Guided Image Editing with Visual Autoregressive Model","summary":"Text-guided image editing is an essential task that enables users to modify\nimages through natural language descriptions. Recent advances in diffusion\nmodels and rectified flows have significantly improved editing quality,\nprimarily relying on inversion techniques to extract structured noise from\ninput images. However, inaccuracies in inversion can propagate errors, leading\nto unintended modifications and compromising fidelity. Moreover, even with\nperfect inversion, the entanglement between textual prompts and image features\noften results in global changes when only local edits are intended. To address\nthese challenges, we propose a novel text-guided image editing framework based\non VAR (Visual AutoRegressive modeling), which eliminates the need for explicit\ninversion while ensuring precise and controlled modifications. Our method\nintroduces a caching mechanism that stores token indices and probability\ndistributions from the original image, capturing the relationship between the\nsource prompt and the image. Using this cache, we design an adaptive\nfine-grained masking strategy that dynamically identifies and constrains\nmodifications to relevant regions, preventing unintended changes. A token\nreassembling approach further refines the editing process, enhancing diversity,\nfidelity, and control. Our framework operates in a training-free manner and\nachieves high-fidelity editing with faster inference speeds, processing a 1K\nresolution image in as fast as 1.2 seconds. Extensive experiments demonstrate\nthat our method achieves performance comparable to, or even surpassing,\nexisting diffusion- and rectified flow-based approaches in both quantitative\nmetrics and visual quality. The code will be released.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T09:46:56Z"}
{"aid":"http://arxiv.org/abs/2503.23900v1","title":"Convergence of CalderÃ³n residuals","summary":"In this paper, we describe a framework to compute expected convergence rates\nfor residuals based on the Calder\\'on identities for general second order\ndifferential operators for which fundamental solutions are known. The idea is\nthat these rates could be used to validate implementations of boundary integral\noperators and allow to test operators separately by choosing solutions where\nparts of the Calder\\'on identities vanish. Our estimates rely on simple vector\nnorms, and thus avoid the use of hard-to-compute norms and the residual\ncomputation can be easily implemented in existing boundary element codes. We\ntest the proposed Calder\\'on residuals as debugging tool by introducing\nartificial errors into the Galerkin matrices of some of the boundary integral\noperators for the Laplacian and time-harmonic Maxwell's equations. From this,\nwe learn that our estimates are not sharp enough to always detect errors, but\nstill provide a simple and useful debugging tool in many situations.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-03-31T09:49:19Z"}
{"aid":"http://arxiv.org/abs/2503.23922v1","title":"Distributionally Robust Model Order Reduction for Linear Systems","summary":"In this paper, we investigate distributionally robust model order reduction\nfor linear, discrete-time, time-invariant systems. The external input is\nassumed to follow an uncertain distribution within a Wasserstein ambiguity set.\nWe begin by considering the case where the distribution is certain and\nformulate an optimization problem to obtain the reduced model. When the\ndistribution is uncertain, the interaction between the reduced-order model and\nthe distribution is modeled by a Stackelberg game. To ensure solvability, we\nfirst introduce the Gelbrich distance and demonstrate that the Stackelberg game\nwithin a Wasserstein ambiguity set is equivalent to that within a Gelbrich\nambiguity set. Then, we propose a nested optimization problem to solve the\nStackelberg game. Furthermore, the nested optimization problem is relaxed into\na nested convex optimization problem, ensuring computational feasibility.\nFinally, a simulation is presented to illustrate the effectiveness of the\nproposed method.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-03-31T10:13:12Z"}
{"aid":"http://arxiv.org/abs/2503.23928v1","title":"Superconducting Spin-Singlet QuBit in a Triangulene Spin Chain","summary":"Chains of triangular nanographene (triangulene), recently identified as\nrealizing the valence-bond solid phase of a spin-$1$ chain, offer a promising\nplatform for quantum information processing. We propose a superconducting\nspin-singlet qubit based on these chains grown on a superconducting substrate.\nUsing the numerical renormalization group (NRG), we find a manifold of two\nlowest-lying, isolated spin-singlet states that undergo an avoided crossing. A\nqubit utilizing these states is thus protected from random-field noise and\nquasi-particle poisoning. We also introduce a mesoscopic device architecture,\nbased on a triple quantum dot coupled to a superconducting junction, that\nquantum simulates the spin chain and enables control and readout of the qubit.\nAn effective two-level description of the device is validated using\ntime-dependent NRG.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.supr-con","published":"2025-03-31T10:23:17Z"}
{"aid":"http://arxiv.org/abs/2503.23935v1","title":"Nonparametric function-on-scalar regression using deep neural networks","summary":"We focus on nonlinear Function-on-Scalar regression, where the predictors are\nscalar variables, and the responses are functional data. Most existing studies\napproximate the hidden nonlinear relationships using linear combinations of\nbasis functions, such as splines. However, in classical nonparametric\nregression, it is known that these approaches lack adaptivity, particularly\nwhen the true function exhibits high spatial inhomogeneity or anisotropic\nsmoothness. To capture the complex structure behind data adaptively, we propose\na simple adaptive estimator based on a deep neural network model. The proposed\nestimator is straightforward to implement using existing deep learning\nlibraries, making it accessible for practical applications. Moreover, we derive\nthe convergence rates of the proposed estimator for the anisotropic Besov\nspaces, which consist of functions with varying smoothness across dimensions.\nOur theoretical analysis shows that the proposed estimator mitigates the curse\nof dimensionality when the true function has high anisotropic smoothness, as\nshown in the classical nonparametric regression. Numerical experiments\ndemonstrate the superior adaptivity of the proposed estimator, outperforming\nexisting methods across various challenging settings. Moreover, the proposed\nmethod is applied to analyze ground reaction force data in the field of sports\nmedicine, demonstrating more efficient estimation compared to existing\napproaches.","main_category":"stat.ME","categories":"stat.ME","published":"2025-03-31T10:34:50Z"}
{"aid":"http://arxiv.org/abs/2503.23938v1","title":"New results about aggregation functions of quasi-pseudometric modulars","summary":"In recent studies, Bibiloni-Femenias, Mi\\~{n}ana and Valero characterized the\nfunctions that aggregate a family of (quasi-)(pseudo)metric modulars defined\nover a fixed set $X$ into a single one. In this paper, we adopt a related but\ndifferent approach to examine those functions that allow us to define a\n(quasi-)(pseudo)metric modular in the Cartesian product of\n(quasi-)(pseudo)metric modular spaces. We base our research on the recent\ndevelopment of a general theory of aggregation functions between quantales.\nThis enables to shed light between the two different ways of aggregation\n(quasi-)(pseudo)metric modulars.","main_category":"math.GN","categories":"math.GN","published":"2025-03-31T10:38:24Z"}
{"aid":"http://arxiv.org/abs/2503.23940v1","title":"Operator limit of Wigner matrices I","summary":"We consider the Wigner matrix $W_{n}$ of dimension $n \\times n$ as $n \\to\n\\infty$. The objective of this paper is two folds: first we construct an\noperator $\\mathcal{W}$ on a suitable Hilbert space $\\mathcal{H}$ and then\ndefine a suitable notion of convergence such that the matrices $W_{n}$ converge\nin that notion of convergence to $\\mathcal{W}$. We further investigate some\nproperties of $\\mathcal{W}$ and $\\mathcal{H}$. We show that $\\mathcal{H}$ is a\nnontrivial extension of $L^{2}[0,1]$ with respect to the Lebesgue measure and\nthe spectral measure of $\\mathcal{W}$ at any function $f \\in L^{2}[0,1]$ is\nalmost surely the semicircular law.","main_category":"math.PR","categories":"math.PR,math-ph,math.FA,math.MP,math.ST,stat.TH","published":"2025-03-31T10:45:01Z"}
{"aid":"http://arxiv.org/abs/2503.23947v1","title":"Spectral-Adaptive Modulation Networks for Visual Perception","summary":"Recent studies have shown that 2D convolution and self-attention exhibit\ndistinct spectral behaviors, and optimizing their spectral properties can\nenhance vision model performance. However, theoretical analyses remain limited\nin explaining why 2D convolution is more effective in high-pass filtering than\nself-attention and why larger kernels favor shape bias, akin to self-attention.\nIn this paper, we employ graph spectral analysis to theoretically simulate and\ncompare the frequency responses of 2D convolution and self-attention within a\nunified framework. Our results corroborate previous empirical findings and\nreveal that node connectivity, modulated by window size, is a key factor in\nshaping spectral functions. Leveraging this insight, we introduce a\n\\textit{spectral-adaptive modulation} (SPAM) mixer, which processes visual\nfeatures in a spectral-adaptive manner using multi-scale convolutional kernels\nand a spectral re-scaling mechanism to refine spectral components. Based on\nSPAM, we develop SPANetV2 as a novel vision backbone. Extensive experiments\ndemonstrate that SPANetV2 outperforms state-of-the-art models across multiple\nvision tasks, including ImageNet-1K classification, COCO object detection, and\nADE20K semantic segmentation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T10:53:42Z"}
{"aid":"http://arxiv.org/abs/2503.23948v1","title":"AI2Agent: An End-to-End Framework for Deploying AI Projects as\n  Autonomous Agents","summary":"As AI technology advances, it is driving innovation across industries,\nincreasing the demand for scalable AI project deployment. However, deployment\nremains a critical challenge due to complex environment configurations,\ndependency conflicts, cross-platform adaptation, and debugging difficulties,\nwhich hinder automation and adoption. This paper introduces AI2Agent, an\nend-to-end framework that automates AI project deployment through\nguideline-driven execution, self-adaptive debugging, and case \\& solution\naccumulation. AI2Agent dynamically analyzes deployment challenges, learns from\npast cases, and iteratively refines its approach, significantly reducing human\nintervention. To evaluate its effectiveness, we conducted experiments on 30 AI\ndeployment cases, covering TTS, text-to-image generation, image editing, and\nother AI applications. Results show that AI2Agent significantly reduces\ndeployment time and improves success rates. The code and demo video are now\npublicly accessible.","main_category":"cs.AI","categories":"cs.AI","published":"2025-03-31T10:58:34Z"}
{"aid":"http://arxiv.org/abs/2503.23957v1","title":"Written in the Stars: How your (pens and) papers decide the fate of the\n  arXiverse","summary":"We all love the ecstasy that comes with submitting papers to journals or\narXiv. Some have described it as yeeting their back-breaking products of labor\ninto the void, wishing they could never deal with them ever again. The very act\nof yeeting papers onto arXiv contributes to the expansion of the arXiverse;\nhowever, we have yet to quantify our contribution to the cause. In this work, I\ninvestigate the expansion of the arXiverse using the arXiv astro-ph submission\ndata from 1992 to date. I coin the term \"the arXiverse constant\", $a_0$, to\nquantify the rate of expansion of the arXiverse. I find that astro-ph as a\nwhole has a positive $a_0$, but this does not always hold true for the six\nsubcategories of astro-ph. I then investigate the temporal changes in $a_0$ for\nthe astro-ph subcategories and astro-ph as a whole, from which I infer the fate\nof the arXiverse.","main_category":"physics.pop-ph","categories":"physics.pop-ph,astro-ph.CO,astro-ph.EP,astro-ph.GA,astro-ph.HE,astro-ph.IM,astro-ph.SR","published":"2025-03-31T11:15:30Z"}
{"aid":"http://arxiv.org/abs/2503.23958v1","title":"A Multi-Stage Auto-Context Deep Learning Framework for Tissue and Nuclei\n  Segmentation and Classification in H&E-Stained Histological Images of\n  Advanced Melanoma","summary":"Melanoma is the most lethal form of skin cancer, with an increasing incidence\nrate worldwide. Analyzing histological images of melanoma by localizing and\nclassifying tissues and cell nuclei is considered the gold standard method for\ndiagnosis and treatment options for patients. While many computerized\napproaches have been proposed for automatic analysis, most perform tissue-based\nanalysis and nuclei (cell)-based analysis as separate tasks, which might be\nsuboptimal.\n  In this work, using the PUMA challenge dataset, we proposed a novel\nmulti-stage deep learning approach by combining tissue and nuclei information\nin a unified framework based on the auto-context concept to perform\nsegmentation and classification in histological images of melanoma. Through\npre-training and further post-processing, our approach achieved second and\nfirst place rankings in the PUMA challenge, with average micro Dice tissue\nscore and summed nuclei F1-score of 73.40% for Track 1 and 63.48% for Track 2,\nrespectively. Our implementation for training and testing is available at:\nhttps://github.com/NimaTorbati/PumaSubmit","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T11:15:50Z"}
{"aid":"http://arxiv.org/abs/2503.23960v1","title":"Testing for integer integration in functional time series","summary":"We develop a statistical testing procedure to examine whether the\ncurve-valued time series of interest is integrated of order d for an integer d.\nThe proposed procedure can distinguish between integer-integrated time series\nand fractionally-integrated ones, and it has broad applicability in practice.\nMonte Carlo simulation experiments show that the proposed testing procedure\nperforms reasonably well. We apply our methodology to Canadian yield curve data\nand French sub-national age-specific mortality data. We find evidence that\nthese time series are mostly integrated of order one, while some have\nfractional orders exceeding or falling below one.","main_category":"stat.ME","categories":"stat.ME","published":"2025-03-31T11:20:38Z"}
{"aid":"http://arxiv.org/abs/2503.23973v1","title":"Odd Cuts in Bipartite Grafts II: Structure and Universality of Decapital\n  Distance Components","summary":"This paper is the second in a series of papers characterizing the maximum\npacking of \\( T \\)-cuts in bipartite grafts, following the first paper\n(N.~Kita, ``Tight cuts in bipartite grafts~I: Capital distance components,''\n{arXiv:2202.00192v2}, 2022). Given a graft $(G, T)$, a minimum join $F$, and a\nspecified vertex $r$ called the root, the distance components of $(G, T)$ are\ndefined as subgraphs of $G$ determined by the distances induced by $F$. A\ndistance component is called {\\em capital} if it contains the root; otherwise,\nit is called {\\em decapital}. In our first paper, we investigated the canonical\nstructure of capital distance components in bipartite grafts, which can be\ndescribed using the graft analogue of the Kotzig--Lov\\'asz decomposition. In\nthis paper, we provide the counterpart structure for the decapital distance\ncomponents. We also establish a necessary and sufficient condition for two\nvertices $r$ and $r'$ under which a decapital distance component with respect\nto root $r$ is also a decapital distance component with respect to root $r'$.\nAs a consequence, we obtain that the total number of decapital distance\ncomponents in a bipartite graft, taken over all choices of root, is equal to\ntwice the number of edges in a minimum join of the graft.","main_category":"math.CO","categories":"math.CO","published":"2025-03-31T11:36:02Z"}
{"aid":"http://arxiv.org/abs/2503.23975v1","title":"A Reactive Framework for Whole-Body Motion Planning of Mobile\n  Manipulators Combining Reinforcement Learning and SDF-Constrained Quadratic\n  Programmi","summary":"As an important branch of embodied artificial intelligence, mobile\nmanipulators are increasingly applied in intelligent services, but their\nredundant degrees of freedom also limit efficient motion planning in cluttered\nenvironments. To address this issue, this paper proposes a hybrid learning and\noptimization framework for reactive whole-body motion planning of mobile\nmanipulators. We develop the Bayesian distributional soft actor-critic\n(Bayes-DSAC) algorithm to improve the quality of value estimation and the\nconvergence performance of the learning. Additionally, we introduce a quadratic\nprogramming method constrained by the signed distance field to enhance the\nsafety of the obstacle avoidance motion. We conduct experiments and make\ncomparison with standard benchmark. The experimental results verify that our\nproposed framework significantly improves the efficiency of reactive whole-body\nmotion planning, reduces the planning time, and improves the success rate of\nmotion planning. Additionally, the proposed reinforcement learning method\nensures a rapid learning process in the whole-body planning task. The novel\nframework allows mobile manipulators to adapt to complex environments more\nsafely and efficiently.","main_category":"cs.RO","categories":"cs.RO","published":"2025-03-31T11:37:02Z"}
{"aid":"http://arxiv.org/abs/2503.24002v1","title":"A Simple BER Expression for FSO Systems with Weak Turbulence and\n  Pointing Errors","summary":"We develop a simple approximation for the average BER for an FSO system\nimpacted by weak turbulence and pointing errors. Numerical results show that\nthe proposed expression accurately predicts the true BER.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T12:27:24Z"}
{"aid":"http://arxiv.org/abs/2503.24011v1","title":"Simulations in Statistical Workflows","summary":"Simulations play important and diverse roles in statistical workflows, for\nexample, in model specification, checking, validation, and even directly in\nmodel inference. Over the past decades, the application areas and overall\npotential of simulations in statistical workflows have expanded significantly,\ndriven by the development of new simulation-based algorithms and exponentially\nincreasing computational resources. In this paper, we examine past and current\ntrends in the field and offer perspectives on how simulations may shape the\nfuture of statistical practice.","main_category":"stat.CO","categories":"stat.CO","published":"2025-03-31T12:38:21Z"}
{"aid":"http://arxiv.org/abs/2503.24012v1","title":"Tree-Guided $L_1$-Convex Clustering","summary":"Convex clustering is a modern clustering framework that guarantees globally\noptimal solutions and performs comparably to other advanced clustering methods.\nHowever, obtaining a complete dendrogram (clusterpath) for large-scale datasets\nremains computationally challenging due to the extensive costs associated with\niterative optimization approaches. To address this limitation, we develop a\nnovel convex clustering algorithm called Tree-Guided $L_1$-Convex Clustering\n(TGCC). We first focus on the fact that the loss function of $L_1$-convex\nclustering with tree-structured weights can be efficiently optimized using a\ndynamic programming approach. We then develop an efficient cluster fusion\nalgorithm that utilizes the tree structure of the weights to accelerate the\noptimization process and eliminate the issue of cluster splits commonly\nobserved in convex clustering. By combining the dynamic programming approach\nwith the cluster fusion algorithm, the TGCC algorithm achieves superior\ncomputational efficiency without sacrificing clustering performance.\nRemarkably, our TGCC algorithm can construct a complete clusterpath for $10^6$\npoints in $\\mathbb{R}^2$ within 15 seconds on a standard laptop without the\nneed for parallel or distributed computing frameworks. Moreover, we extend the\nTGCC algorithm to develop biclustering and sparse convex clustering algorithms.","main_category":"cs.LG","categories":"cs.LG,stat.CO","published":"2025-03-31T12:39:48Z"}
{"aid":"http://arxiv.org/abs/2503.24014v1","title":"Optimization of Layer Skipping and Frequency Scaling for Convolutional\n  Neural Networks under Latency Constraint","summary":"The energy consumption of Convolutional Neural Networks (CNNs) is a critical\nfactor in deploying deep learning models on resource-limited equipment such as\nmobile devices and autonomous vehicles. We propose an approach involving\nProportional Layer Skipping (PLS) and Frequency Scaling (FS). Layer skipping\nreduces computational complexity by selectively bypassing network layers,\nwhereas frequency scaling adjusts the frequency of the processor to optimize\nenergy use under latency constraints. Experiments of PLS and FS on ResNet-152\nwith the CIFAR-10 dataset demonstrated significant reductions in computational\ndemands and energy consumption with minimal accuracy loss. This study offers\npractical solutions for improving real-time processing in resource-limited\nsettings and provides insights into balancing computational efficiency and\nmodel performance.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T12:40:11Z"}
{"aid":"http://arxiv.org/abs/2503.24021v1","title":"IntelliCircos: A Data-driven and AI-powered Authoring Tool for Circos\n  Plots","summary":"Genomics data is essential in biological and medical domains, and\nbioinformatics analysts often manually create circos plots to analyze the data\nand extract valuable insights. However, creating circos plots is complex, as it\nrequires careful design for multiple track attributes and positional\nrelationships between them. Typically, analysts often seek inspiration from\nexisting circos plots, and they have to iteratively adjust and refine the plot\nto achieve a satisfactory final design, making the process both tedious and\ntime-intensive. To address these challenges, we propose IntelliCircos, an\nAI-powered interactive authoring tool that streamlines the process from initial\nvisual design to the final implementation of circos plots. Specifically, we\nbuild a new dataset containing 4396 circos plots with corresponding annotations\nand configurations, which are extracted and labeled from published papers. With\nthe dataset, we further identify track combination patterns, and utilize Large\nLanguage Model (LLM) to provide domain-specific design recommendations and\nconfiguration references to navigate the design of circos plots. We conduct a\nuser study with 8 bioinformatics analysts to evaluate IntelliCircos, and the\nresults demonstrate its usability and effectiveness in authoring circos plots.","main_category":"cs.HC","categories":"cs.HC","published":"2025-03-31T12:48:39Z"}
{"aid":"http://arxiv.org/abs/2503.24027v1","title":"Crossing Boundaries: Leveraging Semantic Divergences to Explore Cultural\n  Novelty in Cooking Recipes","summary":"Novelty modeling and detection is a core topic in Natural Language Processing\n(NLP), central to numerous tasks such as recommender systems and automatic\nsummarization. It involves identifying pieces of text that deviate in some way\nfrom previously known information. However, novelty is also a crucial\ndeterminant of the unique perception of relevance and quality of an experience,\nas it rests upon each individual's understanding of the world. Social factors,\nparticularly cultural background, profoundly influence perceptions of novelty\nand innovation. Cultural novelty arises from differences in salience and\nnovelty as shaped by the distance between distinct communities. While cultural\ndiversity has garnered increasing attention in artificial intelligence (AI),\nthe lack of robust metrics for quantifying cultural novelty hinders a deeper\nunderstanding of these divergences. This gap limits quantifying and\nunderstanding cultural differences within computational frameworks. To address\nthis, we propose an interdisciplinary framework that integrates knowledge from\nsociology and management. Central to our approach is GlobalFusion, a novel\ndataset comprising 500 dishes and approximately 100,000 cooking recipes\ncapturing cultural adaptation from over 150 countries. By introducing a set of\nJensen-Shannon Divergence metrics for novelty, we leverage this dataset to\nanalyze textual divergences when recipes from one community are modified by\nanother with a different cultural background. The results reveal significant\ncorrelations between our cultural novelty metrics and established cultural\nmeasures based on linguistic, religious, and geographical distances. Our\nfindings highlight the potential of our framework to advance the understanding\nand measurement of cultural diversity in AI.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T12:52:52Z"}
{"aid":"http://arxiv.org/abs/2503.24038v1","title":"Giant counter-rotating oscillations on the attosecond timescale","summary":"We predict an unexplored type of ultrastrong coupling between atoms and\nintense ultraviolet light that leads to giant population oscillations on the\nattosecond timescale. These counter-rotating oscillations can be of similar\namplitude as the elementary femtosecond Rabi oscillations between the two\nstrongly coupled states. The effect, which is beyond the two-level atom, is\nnon-reciprocal: It only affects the excited state, while the ground state is\nunaffected. We propose that two-photon Rabi oscillations (1s$^2$-1s3d) in\nhelium is suitable for the generation of this type of ultrastrong coupling with\nrealistic pulses. We use a combination of Floquet theory and effective\nHamiltonian theory to test our predictions against ab initio simulations.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T13:01:32Z"}
{"aid":"http://arxiv.org/abs/2503.24040v1","title":"Adventures in FRET and Specification","summary":"This paper gives an overview of previous work in which the authors used\nNASA's Formal Requirement Elicitation Tool (FRET) to formalise requirements. We\ndiscuss four case studies where we used FRET to capture the system's\nrequirements. These formalised requirements subsequently guided the case study\nspecifications in a combination of formal paradigms. For each case study we\nsummarise insights gained during this process, exploring the expressiveness and\nthe potential interoperability of these approaches. Our experience confirms\nFRET's suitability as a framework for the elicitation and understanding of\nrequirements and for providing traceability from requirements to specification.","main_category":"cs.SE","categories":"cs.SE","published":"2025-03-31T13:03:34Z"}
{"aid":"http://arxiv.org/abs/2503.24047v1","title":"Towards Scientific Intelligence: A Survey of LLM-based Scientific Agents","summary":"As scientific research becomes increasingly complex, innovative tools are\nneeded to manage vast data, facilitate interdisciplinary collaboration, and\naccelerate discovery. Large language models (LLMs) are now evolving into\nLLM-based scientific agents that automate critical tasks, ranging from\nhypothesis generation and experiment design to data analysis and simulation.\nUnlike general-purpose LLMs, these specialized agents integrate domain-specific\nknowledge, advanced tool sets, and robust validation mechanisms, enabling them\nto handle complex data types, ensure reproducibility, and drive scientific\nbreakthroughs. This survey provides a focused review of the architectures,\ndesign, benchmarks, applications, and ethical considerations surrounding\nLLM-based scientific agents. We highlight why they differ from general agents\nand the ways in which they advance research across various scientific fields.\nBy examining their development and challenges, this survey offers a\ncomprehensive roadmap for researchers and practitioners to harness these agents\nfor more efficient, reliable, and ethically sound scientific discovery.","main_category":"cs.AI","categories":"cs.AI,cs.MA","published":"2025-03-31T13:11:28Z"}
{"aid":"http://arxiv.org/abs/2503.24053v1","title":"ReaLM: Reliable and Efficient Large Language Model Inference with\n  Statistical Algorithm-Based Fault Tolerance","summary":"The demand for efficient large language model (LLM) inference has propelled\nthe development of dedicated accelerators. As accelerators are vulnerable to\nhardware faults due to aging, variation, etc, existing accelerator designs\noften reserve a large voltage margin or leverage algorithm-based fault\ntolerance (ABFT) techniques to ensure LLM inference correctness. However,\nprevious methods often overlook the inherent fault tolerance of LLMs, leading\nto high computation and energy overhead. To enable reliable yet efficient LLM\ninference, in this paper, we propose a novel algorithm/circuit co-design\nframework, dubbed ReaLM. For the first time, we systematically characterize the\nfault tolerance of LLMs by performing a large-scale error injection study of\nrepresentative LLMs and natural language understanding tasks. Then, we propose\na statistical ABFT algorithm that fully leverages the error robustness to\nminimize error recovery as much as possible. We also customize the error\ndetection circuits to enable a low-cost online collection of error statistics.\nExtensive experiments show that with only 1.42% circuit area and 1.79% power\noverhead, our ReaLM can reduce perplexity degradation from 18.54 to 0.29.\nCompared to existing methods, ReaLM consistently reduces recovery costs across\ndifferent operating voltages and improves energy efficiency by up to 35.83%\nwithout compromising LLM performance. Our error injection code is available at\nhttps://github.com/2000012835xt/ReaLM-DAC.","main_category":"cs.AR","categories":"cs.AR","published":"2025-03-31T13:15:03Z"}
{"aid":"http://arxiv.org/abs/2503.24055v1","title":"Effective Dynamics and Blow Up in a Model of Magnetic Relaxation","summary":"In this article we study a one dimensional model for Magnetic Relaxation.\nThis model was introduced by Moffatt and describes a low resistivity viscous\nplasma, in which the pressure and the inercia are much smaller than the\nmagnetic pressure. In the limit of resistivity $\\varepsilon\\rightarrow 0$, we\nprove the existence of two time scales for the evolution of the magnetic field:\na fast one for times of order $\\log(\\varepsilon^{-1})$ in which the resistivity\nplays no role and the energy is dissipated only via viscosity; and a slow one\nfor times of order $\\varepsilon^{-1}$ characterized by the influence of the\nresistivity. We show that in this second time scale, as $\\varepsilon\\rightarrow\n0$, the modulus of magnetic field approaches a function that depends only on\ntime. We also prove that, in this regime, the magnetic field\n$b_\\varepsilon(t,x)$ can be approximated as $\\varepsilon \\rightarrow 0$ by the\nsolution of a PDE whose solutions exhibit blow up for some choices of initial\ndata.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP,physics.plasm-ph","published":"2025-03-31T13:15:22Z"}
{"aid":"http://arxiv.org/abs/2503.24061v1","title":"Simple general magnification of circuit lower bounds","summary":"We construct so-called distinguishers, sparse matrices that retain some\nproperties of error correcting codes. They provide a technically and\nconceptually simple approach to magnification. We generalize and strengthen\nknown general (not problem specific) magnification results and in particular\nachieve magnification thresholds below known lower bounds. For example, we show\nthat fixed polynomial formula size lower bounds for NP are implied by slightly\nsuperlinear formula size lower bounds for approximating any sufficiently sparse\nproblem in NP. We also show that the thresholds achieved are sharp.\nAdditionally, our approach yields a uniform magnification result for the\nminimum circuit size problem. This seems to sidestep the localization barrier.","main_category":"cs.CC","categories":"cs.CC","published":"2025-03-31T13:21:56Z"}
{"aid":"http://arxiv.org/abs/2503.24078v1","title":"A Complete Epistemic Temporal Logic for Intelligent Agent","summary":"In this paper, we present a complete epistemic temporal logic, called BPICTL,\nwhich generalizes CTL by introducing epistemic modalities. A sound and complete\ninference system of BPICTL is given. We prove the finite model property of\nBPICTL. Furthermore, we present a model checking algorithm for BPICTL.","main_category":"cs.LO","categories":"cs.LO","published":"2025-03-31T13:33:30Z"}
{"aid":"http://arxiv.org/abs/2503.24086v1","title":"Distributed AC Optimal Power Flow: A Scalable Solution for Large-Scale\n  Problems","summary":"This paper introduces a novel distributed optimization framework for\nlarge-scale AC Optimal Power Flow (OPF) problems, offering both theoretical\nconvergence guarantees and rapid convergence in practice. By integrating\nsmoothing techniques and the Schur complement, the proposed approach addresses\nthe scalability challenges and reduces communication overhead in distributed AC\nOPF. Additionally, optimal network decomposition enables efficient parallel\nprocessing under the single program multiple data (SPMD) paradigm. Extensive\nsimulations on large-scale benchmarks across various operating scenarios\nindicate that the proposed framework outperforms the state-of-the-art\ncentralized solver IPOPT on modest hardware. This paves the way for more\nscalable and efficient distributed optimization in future power system\napplications.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-03-31T13:40:12Z"}
{"aid":"http://arxiv.org/abs/2503.24103v1","title":"Constructing Chayet-Garibaldi algebras from affine vertex algebras\n  (including the 3876-dimensional algebra for $E_8$)","summary":"In 2021, Maurice Chayet and Skip Garibaldi provided an explicit construction\nof a commutative non-associative algebra on the second smallest representation\nof $E_8$ (of dimension $3875$) adjoined with a unit. In fact, they define such\nan algebra $A(\\mathfrak{g})$ for each simple Lie algebra $\\mathfrak{g}$, in\nterms of explicit but ad-hoc formulas.\n  We discovered that their algebras $A(\\mathfrak{g})$ have a natural\ninterpretation in terms of affine vertex algebras, and their ad-hoc formulas\ntake an extremely simple form in this new interpretation. It is our hope that\nthis point of view will lead to a better understanding of this interesting\nclass of algebras.","main_category":"math.RA","categories":"math.RA,math.GR,math.RT","published":"2025-03-31T13:56:23Z"}
{"aid":"http://arxiv.org/abs/2503.24120v1","title":"Renormalized mechanics and stochastic thermodynamics of growing model\n  protocells","summary":"Uncovering the rules governing the nonequilibrium dynamics of the membranes\nthat define biological cells is of central importance to understanding the\nphysics of living systems. We theoretically and computationally investigate the\nbehavior of model protocells -- flexible quasispherical vesicles -- that\nexchange membrane constituents, internal volume, and heat with an external\nreservoir. The excess chemical potential and osmotic pressure difference\nimposed by the reservoir act as generalized thermodynamic driving forces that\nmodulate vesicle morphology. We identify an associated nonequilibrium\nmorphological transition between a weakly driven regime, in which growing\nvesicles remain quasispherical, and a strongly driven regime, in which vesicles\naccommodate rapid membrane uptake by developing surface wrinkles. This\ntransition emerges due to the renormalization of membrane mechanical properties\nby nonequilibrium driving. Further, using insights from stochastic\nthermodynamics we propose a minimal vesicle growth-shape law that remains\nrobust even in strongly driven, far-from-equilibrium regimes.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.bio-ph","published":"2025-03-31T14:08:15Z"}
{"aid":"http://arxiv.org/abs/2503.24124v1","title":"Effect of Interlayer Stacking on the Electronic Properties of\n  1$T$-TaS$_2$","summary":"Controlled stacking of van der Waals materials is a powerful tool for\nexploring the physics of quantum condensed matter. Given the small binding\nbetween layers, exploitation for engineering will require a breakthrough in\nstacking methodology, or an ability to take advantage of thicker defective\nstacks. Here we describe computational groundwork for the latter, using -- on\naccount of its promise for cold memory applications -- 1$T$-TaS$_2$ as a model\nsystem. Comparing recursive Hendricks-Teller calculations and Monte Carlo\nsimulations to published X-ray diffraction data, we obtain the key parameters\ndescribing the random stacking in mesoscopic flakes. These then regulate the\nelectronic structures via specification of the random stacks in dynamical\nmean-field theory simulations. Hubbard repulsion induces strongly correlated\nmetallic, band and Mott insulating layers, providing compelling evidence that\nelectronic properties follow from the coexistence of more than the metallic and\ninsulating planes associated by ordinary band theory.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-03-31T14:09:14Z"}
{"aid":"http://arxiv.org/abs/2503.24149v1","title":"Enhancing Trust in Inter-Organisational Data Sharing: Levels of\n  Assurance for Data Trustworthiness","summary":"As data is increasingly acknowledged as a highly valuable asset, much effort\nhas been put into investigating inter-organisational data sharing, aiming at\nutilising the value of formerly unused data. Moreover, most researchers agree,\nthat trust between actors is key for successful data sharing activities.\nHowever, existing research oftentimes focus on trust from a data provider\nperspective. Therefore, our work highlights the unbalanced view of trust,\naddressing it from a data consumer perspective. More specifically, our aim is\nto investigate trust enhancing measures on a data level, that is data\ntrustworthiness. We found, that existing data trustworthiness enhancing\nsolutions do not meet the requirements of the domain of inter-organisational\ndata sharing. Therefore, our study addresses this gap. Conducting a rigorous\ndesign science research approach, this work proposes a new Levels of Assurance\nfor Data Trustworthiness artifact. Built on existing artifacts, we demonstrate,\nhow it addresses the identified challenges within the domain appropriately. We\nfound that our novel approach requires more work to be suitable for adoption.\nStill, we are confident that our solution can increase consumer trust. We\nconclude by contributing to the body of design knowledge and emphasise the need\nfor more attention to be put into consumer trust.","main_category":"cs.SI","categories":"cs.SI,cs.CY,econ.GN,q-fin.EC","published":"2025-03-31T14:35:23Z"}
{"aid":"http://arxiv.org/abs/2503.24153v1","title":"Convexity of chance constraints for elliptical and skewed distributions\n  with copula structures dependent on decision variables","summary":"Chance constraints describe a set of given random inequalities depending on\nthe decision vector satisfied with a large enough probability. They are widely\nused in decision making under uncertain data in many engineering problems. This\npaper aims to derive the convexity of chance constraints with row dependent\nelliptical and skewed random variables via a copula depending on decision\nvectors. We obtain best thresholds of the $r$-concavity for any real number $r$\nand improve probability thresholds of the eventual convexity. We prove the\neventual convexity with elliptical distributions and a Gumbel-Hougaard copula\ndespite the copula's singularity near the origin. We determine the\n$\\alpha$-decreasing densities of generalized hyperbolic distributions by\nestimating the modified Bessel functions. By applying the $\\alpha$-decreasing\nproperty and a radial decomposition, we achieve the eventual convexity for\nthree types of skewed distributions. Finally, we provide an example to\nillustrate the eventual convexity of a feasible set containing the origin.","main_category":"math.OC","categories":"math.OC","published":"2025-03-31T14:38:27Z"}
{"aid":"http://arxiv.org/abs/2503.24157v1","title":"LLM4FS: Leveraging Large Language Models for Feature Selection and How\n  to Improve It","summary":"Recent advances in large language models (LLMs) have provided new\nopportunities for decision-making, particularly in the task of automated\nfeature selection. In this paper, we first comprehensively evaluate LLM-based\nfeature selection methods, covering the state-of-the-art DeepSeek-R1,\nGPT-o3-mini, and GPT-4.5. Then, we propose a novel hybrid strategy called\nLLM4FS that integrates LLMs with traditional data-driven methods. Specifically,\ninput data samples into LLMs, and directly call traditional data-driven\ntechniques such as random forest and forward sequential selection. Notably, our\nanalysis reveals that the hybrid strategy leverages the contextual\nunderstanding of LLMs and the high statistical reliability of traditional\ndata-driven methods to achieve excellent feature selection performance, even\nsurpassing LLMs and traditional data-driven methods. Finally, we point out the\nlimitations of its application in decision-making.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T14:40:31Z"}
{"aid":"http://arxiv.org/abs/2503.24165v1","title":"Predicting Targeted Therapy Resistance in Non-Small Cell Lung Cancer\n  Using Multimodal Machine Learning","summary":"Lung cancer is the primary cause of cancer death globally, with non-small\ncell lung cancer (NSCLC) emerging as its most prevalent subtype. Among NSCLC\npatients, approximately 32.3% have mutations in the epidermal growth factor\nreceptor (EGFR) gene. Osimertinib, a third-generation EGFR-tyrosine kinase\ninhibitor (TKI), has demonstrated remarkable efficacy in the treatment of NSCLC\npatients with activating and T790M resistance EGFR mutations. Despite its\nestablished efficacy, drug resistance poses a significant challenge for\npatients to fully benefit from osimertinib. The absence of a standard tool to\naccurately predict TKI resistance, including that of osimertinib, remains a\ncritical obstacle. To bridge this gap, in this study, we developed an\ninterpretable multimodal machine learning model designed to predict patient\nresistance to osimertinib among late-stage NSCLC patients with activating EGFR\nmutations, achieving a c-index of 0.82 on a multi-institutional dataset. This\nmachine learning model harnesses readily available data routinely collected\nduring patient visits and medical assessments to facilitate precision lung\ncancer management and informed treatment decisions. By integrating various data\ntypes such as histology images, next generation sequencing (NGS) data,\ndemographics data, and clinical records, our multimodal model can generate\nwell-informed recommendations. Our experiment results also demonstrated the\nsuperior performance of the multimodal model over single modality models\n(c-index 0.82 compared with 0.75 and 0.77), thus underscoring the benefit of\ncombining multiple modalities in patient outcome prediction.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-03-31T14:47:02Z"}
{"aid":"http://arxiv.org/abs/2503.24170v1","title":"Localization of operator-valued frames","summary":"We introduce a localization concept for operator-valued frames, where the\nquality of localization is measured by the associated operator-valued Gram\nmatrix belonging to some suitable Banach algebra. We prove that intrinsic\nlocalization of an operator-valued frame is preserved by its canonical dual.\nMoreover, we show that the series associated to the perfect reconstruction of\nan operator-valued frame converges not only in the underlying Hilbert space,\nbut also in a whole class of associated (quasi-)Banach spaces. Finally, we\napply our results to irregular Gabor g-frames.","main_category":"math.FA","categories":"math.FA","published":"2025-03-31T14:49:54Z"}
{"aid":"http://arxiv.org/abs/2503.24171v1","title":"Hamiltonian Dynamics Learning: A Scalable Approach to Quantum Process\n  Characterization","summary":"Quantum process characterization is a fundamental task in quantum information\nprocessing, yet conventional methods, such as quantum process tomography,\nrequire prohibitive resources and lack scalability. Here, we introduce an\nefficient quantum process learning method specifically designed for short-time\nHamiltonian dynamics. Our approach reconstructs an equivalent quantum circuit\nrepresentation from measurement data of unknown Hamiltonian evolution without\nrequiring additional assumptions and achieves polynomial sample and\ncomputational efficiency. Our results have broad applications in various\ndirections. We demonstrate applications in quantum machine learning, where our\nprotocol enables efficient training of variational quantum neural networks by\ndirectly learning unitary transformations. Additionally, it facilitates the\nprediction of quantum expectation values with provable efficiency and provides\na robust framework for verifying quantum computations and benchmarking\nrealistic noisy quantum hardware. This work establishes a new theoretical\nfoundation for practical quantum dynamics learning, paving the way for scalable\nquantum process characterization in both near-term and fault-tolerant quantum\ncomputing.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T14:50:00Z"}
{"aid":"http://arxiv.org/abs/2503.24181v1","title":"Computational challenges of 21st century Global Astrometry","summary":"Major advancements in space science and detector technology brought about a\nrevolution in global astrometry, the science of measuring distances and motions\nof stars in the Milky Way and in the local universe. From the first ESA\nastrometric mission HIPPARCOS of the early 80s to the current Gaia mission, the\ndata volume and computational complexity of the full reduction process has\nincreased by several orders of magnitude, requiring high-performance computing\nand data throughput. We review the principles and computational complexity of\ngeneral global astrometric models that lead to the statistical treatment of an\nextra-large, highly non-linear estimation problem. Some numerical aspects of\ninspecting Gaia's proper motions to find cosmological signals at all scales are\nalso addressed.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-03-31T14:58:40Z"}
{"aid":"http://arxiv.org/abs/2503.24191v1","title":"Output Constraints as Attack Surface: Exploiting Structured Generation\n  to Bypass LLM Safety Mechanisms","summary":"Content Warning: This paper may contain unsafe or harmful content generated\nby LLMs that may be offensive to readers. Large Language Models (LLMs) are\nextensively used as tooling platforms through structured output APIs to ensure\nsyntax compliance so that robust integration with existing softwares like agent\nsystems, could be achieved. However, the feature enabling functionality of\ngrammar-guided structured output presents significant security vulnerabilities.\nIn this work, we reveal a critical control-plane attack surface orthogonal to\ntraditional data-plane vulnerabilities. We introduce Constrained Decoding\nAttack (CDA), a novel jailbreak class that weaponizes structured output\nconstraints to bypass safety mechanisms. Unlike prior attacks focused on input\nprompts, CDA operates by embedding malicious intent in schema-level grammar\nrules (control-plane) while maintaining benign surface prompts (data-plane). We\ninstantiate this with a proof-of-concept Chain Enum Attack, achieves 96.2%\nattack success rates across proprietary and open-weight LLMs on five safety\nbenchmarks with a single query, including GPT-4o and Gemini-2.0-flash. Our\nfindings identify a critical security blind spot in current LLM architectures\nand urge a paradigm shift in LLM safety to address control-plane\nvulnerabilities, as current mechanisms focused solely on data-plane threats\nleave critical systems exposed.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-03-31T15:08:06Z"}
{"aid":"http://arxiv.org/abs/2503.24195v1","title":"Computational Orthodontic Force Simulation: A Review","summary":"In orthodontic treatment, the biological response of the tooth, periodontal\nligament, and bone complex to orthodontic force is crucial in influencing\ntreatment outcomes. The challenge lies in accurately measuring, estimating, and\npredicting these forces during clinical procedures. This review aims to fill\nthe gap in the literature by systematically summarizing existing research on\northodontic force simulation, examining common loading techniques and\ntechnologies, and discussing the potential for refining the orthodontic force\nsimulation process. The literature was comprehensively reviewed, with an\nemphasis on the exploration of the biological mechanism of tooth movement.\nStudies were categorized based on force-loading techniques for both fixed and\ninvisible orthodontic appliances. Finite element (FE) analysis stands out as\nthe predominant technique for orthodontic force simulation, with a significant\nfocus on fixed orthodontics but limited emphasis on invisible orthodontics.\nCurrent orthodontic force simulations tend to be fragmented, often considering\nonly the instantaneous response to applied forces. There exists an urgent\ndemand for a sophisticated analytical simulation model. Such a model, possibly\nleveraging advanced technologies like deep learning, holds the promise of\nforecasting orthodontic treatment outcomes with heightened precision and\nefficiency.","main_category":"physics.med-ph","categories":"physics.med-ph,cs.NA,math.NA","published":"2025-03-31T15:13:36Z"}
{"aid":"http://arxiv.org/abs/2503.24196v1","title":"Fermilab's Transition to Token Authentication","summary":"Fermilab is the first High Energy Physics institution to transition from\nX.509 user certificates to authentication tokens in production systems. All the\nexperiments that Fermilab hosts are now using JSON Web Token (JWT) access\ntokens in their grid jobs. Many software components have been either updated or\ncreated for this transition, and most of the software is available to others as\nopen source. The tokens are defined using the WLCG Common JWT Profile. Token\nattributes for all the tokens are stored in the Fermilab FERRY system which\ngenerates the configuration for the CILogon token issuer. High security-value\nrefresh tokens are stored in Hashicorp Vault configured by htvault-config, and\nJWT access tokens are requested by the htgettoken client through its\nintegration with HTCondor. The Fermilab job submission system jobsub was\nredesigned to be a lightweight wrapper around HTCondor. The grid workload\nmanagement system GlideinWMS which is also based on HTCondor was updated to use\ntokens for pilot job submission. For automated job submissions a managed tokens\nservice was created to reduce duplication of effort and knowledge of how to\nsecurely keep tokens active. The existing Fermilab file transfer tool ifdh was\nupdated to work seamlessly with tokens, as well as the Fermilab POMS\n(Production Operations Management System) which is used to manage automatic job\nsubmission and the RCDS (Rapid Code Distribution System) which is used to\ndistribute analysis code via the CernVM FileSystem. The dCache storage system\nwas reconfigured to accept tokens for authentication in place of X.509 proxy\ncertificates. As some services and sites have not yet implemented token\nsupport, proxy certificates are still sent with jobs for backwards\ncompatibility, but some experiments are beginning to transition to stop using\nthem.","main_category":"cs.DC","categories":"cs.DC","published":"2025-03-31T15:14:29Z"}
{"aid":"http://arxiv.org/abs/2503.24200v1","title":"KNO scaling in quark and gluon jets at the LHC","summary":"The Koba-Nielsen-Olesen (KNO) scaling of hadron multiplicity distributions,\nempirically confirmed to hold approximately in $e^+e^-$ collisions and Deep\nInelastic Scattering, has been observed to be violated in hadron-hadron\ncollisions. In this work, we show that the universality of KNO scaling can be\nextended to hadron-hadron collisions when restricted to QCD jets. We present a\ncomprehensive study of KNO scaling in QCD jets produced in proton-proton\ncollisions at the LHC. Using perturbative QCD calculations in the double\nlogarithmic approximation and PYTHIA simulations, we find that KNO scaling\napproximately holds for both quark and gluon jets across a broad jet $p_T$\nrange, from $0.1$ TeV to $2.5$ TeV, at both the parton and hadron levels.\nEspecially, we highlight characteristic differences between the KNO scaling\nfunctions of quark and gluon jets, with the quark-jet scaling function lying\nabove that of gluon jets at both low and high multiplicities. This distinction\nis essential for interpreting inclusive jet data at the LHC. Furthermore, we\npropose direct experimental tests of KNO scaling in QCD jets at the LHC through\nquark-gluon discrimination using jet substructure techniques, as demonstrated\nby applying energy correlation functions to PYTHIA-generated data.","main_category":"hep-ph","categories":"hep-ph,hep-ex,nucl-th","published":"2025-03-31T15:18:24Z"}
{"aid":"http://arxiv.org/abs/2503.24210v1","title":"DiET-GS: Diffusion Prior and Event Stream-Assisted Motion Deblurring 3D\n  Gaussian Splatting","summary":"Reconstructing sharp 3D representations from blurry multi-view images are\nlong-standing problem in computer vision. Recent works attempt to enhance\nhigh-quality novel view synthesis from the motion blur by leveraging\nevent-based cameras, benefiting from high dynamic range and microsecond\ntemporal resolution. However, they often reach sub-optimal visual quality in\neither restoring inaccurate color or losing fine-grained details. In this\npaper, we present DiET-GS, a diffusion prior and event stream-assisted motion\ndeblurring 3DGS. Our framework effectively leverages both blur-free event\nstreams and diffusion prior in a two-stage training strategy. Specifically, we\nintroduce the novel framework to constraint 3DGS with event double integral,\nachieving both accurate color and well-defined details. Additionally, we\npropose a simple technique to leverage diffusion prior to further enhance the\nedge details. Qualitative and quantitative results on both synthetic and\nreal-world data demonstrate that our DiET-GS is capable of producing\nsignificantly better quality of novel views compared to the existing baselines.\nOur project page is https://diet-gs.github.io","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.MM","published":"2025-03-31T15:27:07Z"}
{"aid":"http://arxiv.org/abs/2503.24213v1","title":"Closing the detection loophole in the triangle network with\n  high-dimensional photonic states","summary":"Bell nonlocality without input settings, e.g. in the triangle network, has\nbeen perceived to be particularly fragile, with low robustness to noise in\nphysical implementations. Here we show to the contrary that nonlocality based\non N00N states already for $N=2$ has an exceptionally high robustness to photon\nloss. For the dominant noise factor, single photon loss in the transmission\nchannels, we can certify noise robustness up to 10\\% loss, while for a\nrealistic noise model we use neural network-based heuristics to observe $\\sim\n50\\%$ robustness. Moreover we show that the robustness holds even for imperfect\nsources based on SPDC sources, where the heralding information of the sources\ncan be used to avoid any global post-processing of the outcomes, such as\ndiscarding rounds when photons fail to arrive, and thus demonstrate how the\ndetection loophole in the triangle network can be closed.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T15:31:34Z"}
{"aid":"http://arxiv.org/abs/2503.24220v1","title":"BAR-Analytics: A Web-based Platform for Analyzing Information Spreading\n  Barriers in News: Comparative Analysis Across Multiple Barriers and Events","summary":"This paper presents BAR-Analytics, a web-based, open-source platform designed\nto analyze news dissemination across geographical, economic, political, and\ncultural boundaries. Using the Russian-Ukrainian and Israeli-Palestinian\nconflicts as case studies, the platform integrates four analytical methods:\npropagation analysis, trend analysis, sentiment analysis, and temporal topic\nmodeling. Over 350,000 articles were collected and analyzed, with a focus on\neconomic disparities and geographical influences using metadata enrichment. We\nevaluate the case studies using coherence, sentiment polarity, topic frequency,\nand trend shifts as key metrics. Our results show distinct patterns in news\ncoverage: the Israeli-Palestinian conflict tends to have more negative\nsentiment with a focus on human rights, while the Russia-Ukraine conflict is\nmore positive, emphasizing election interference. These findings highlight the\ninfluence of political, economic, and regional factors in shaping media\nnarratives across different conflicts.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T15:36:55Z"}
{"aid":"http://arxiv.org/abs/2503.24221v1","title":"The Categories of Lubin-Tate and Drinfeld Bundles","summary":"For a finite extension $F$ of $\\mathbb{Q}_p$ and $n \\geq 1$, we show that the\ncategory of Lubin-Tate bundles on the $(n-1)$-dimensional Drinfeld symmetric\nspace is equivalent to the category of finite-dimensional smooth\nrepresentations of the group of units of the division algebra of invariant\n$1/n$ over $F$.","main_category":"math.NT","categories":"math.NT,math.AG,math.RT","published":"2025-03-31T15:37:25Z"}
{"aid":"http://arxiv.org/abs/2503.24224v1","title":"Simplified Cofactor Conditions for Cubic to Tetragonal, Orthorhombic,\n  and Monoclinic Phase Transformations","summary":"Cofactor Conditions (CCs) are geometric compatibility conditions\nmathematically derived from the crystallographic theory of martensitic phase\ntransformation. The CCs guarantee compatible interfaces between the austenite\nand the parallelled twin of the martensite with any volume fraction, yielding a\nwide range of microstructures during phase transformation. In recent times, CCs\nhave demonstrated tremendous applications in the rational design of low\nhysteresis/fatigue shape memory alloys and shape memory ceramics. In this\npaper, we present a simplified form of the CCs for Type I/II twins using the\neigenspace of transformation stretch tensor and twin axes. We further show the\nexplicit forms and visualizations of the simplified CCs for Cubic to\nTetragonal, Cubic to Orthorhombic, and Cubic to Monoclinic I/II phase\ntransformations. The simplified form has revealed a more straightforward\ncorrelation between the lattice parameters and the CCs, and thus provides a\nmore convenient tool for the rational design of phase-transforming materials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-31T15:38:23Z"}
{"aid":"http://arxiv.org/abs/2503.24234v1","title":"Beyond Gaussian Assumptions: A Nonlinear Generalization of Linear\n  Inverse Modeling","summary":"The Linear Inverse Model (LIM) is a class of data-driven methods that\nconstruct approximate linear stochastic models to represent complex\nobservational data. The stochastic forcing can be modeled using either Gaussian\nwhite noise or Ornstein-Uhlenbeck colored noise; the corresponding models are\ncalled White-LIM and Colored-LIM, respectively. Although LIMs are widely\napplied in climate sciences, they inherently approximate observed distributions\nas Gaussian, limiting their ability to capture asymmetries.\n  In this study, we extend LIMs to incorporate nonlinear dynamics, introducing\nWhite-nLIM and Colored-nLIM which allow for a more flexible and accurate\nrepresentation of complex dynamics from observations. The proposed methods not\nonly account for the nonlinear nature of the underlying system but also\neffectively capture the skewness of the observed distribution. Moreover, we\napply these methods to a lower-dimensional representation of ENSO and\ndemonstrate that both White-nLIM and Colored-nLIM successfully capture its\nnonlinear characteristic.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-03-31T15:46:06Z"}
{"aid":"http://arxiv.org/abs/2503.24235v1","title":"What, How, Where, and How Well? A Survey on Test-Time Scaling in Large\n  Language Models","summary":"As enthusiasm for scaling computation (data and parameters) in the\npretraining era gradually diminished, test-time scaling (TTS), also referred to\nas ``test-time computing'' has emerged as a prominent research focus. Recent\nstudies demonstrate that TTS can further elicit the problem-solving\ncapabilities of large language models (LLMs), enabling significant\nbreakthroughs not only in specialized reasoning tasks, such as mathematics and\ncoding, but also in general tasks like open-ended Q&A. However, despite the\nexplosion of recent efforts in this area, there remains an urgent need for a\ncomprehensive survey offering a systemic understanding. To fill this gap, we\npropose a unified, multidimensional framework structured along four core\ndimensions of TTS research: what to scale, how to scale, where to scale, and\nhow well to scale. Building upon this taxonomy, we conduct an extensive review\nof methods, application scenarios, and assessment aspects, and present an\norganized decomposition that highlights the unique functional roles of\nindividual techniques within the broader TTS landscape. From this analysis, we\ndistill the major developmental trajectories of TTS to date and offer hands-on\nguidelines for practical deployment. Furthermore, we identify several open\nchallenges and offer insights into promising future directions, including\nfurther scaling, clarifying the functional essence of techniques, generalizing\nto more tasks, and more attributions.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-03-31T15:46:15Z"}
{"aid":"http://arxiv.org/abs/2503.24244v1","title":"The 2-Token Theorem: Recognising History-Deterministic Parity Automata\n  Efficiently","summary":"History-determinism is a restricted notion of nondeterminism in automata,\nwhere the nondeterminism can be successfully resolved based solely on the\nprefix read so far. History-deterministic automata still allow for exponential\nsuccinctness in automata over infinite words compared to deterministic automata\n(Kuperberg and Skrzypczak, 2015), allow for canonical forms unlike\ndeterministic automata (Abu Radi and Kupferman, 2019 and 2020; Ehlers and\nSchewe, 2022), and retain some of the algorithmic properties of deterministic\nautomata, for example for reactive synthesis (Henzinger and Piterman, 2006;\nEhlers and Khalimov, 2024).\n  Despite the topic of history-determinism having received a lot of attention\nover the last decade, the complexity of deciding whether a parity automaton is\nhistory-deterministic has, up till now, remained open. We show that\nhistory-determinism for a parity automaton with a fixed parity index can be\nchecked in PTIME, thus improving upon the naive EXPTIME upper bound of\nHenzinger and Piterman that has stood since 2006. More precisely, we show that\nthe so-called 2-token game, which can be solved in PTIME for parity automata\nwith a fixed parity index, characterises history-determinism for parity\nautomata. This game was introduced by Bagnol and Kuperberg in 2018, who showed\nthat to decide if a B\\\"uchi automaton is history-determinism, it suffices to\nfind the winner of the 2-token game on it. They conjectured that this 2-token\ngame based characterisation extends to parity automata. Boker, Kuperberg,\nLehtinen, and Skrzypcak showed in 2020 that this conjecture holds for coB\\\"uchi\nautomata as well. We prove Bagnol and Kuperberg's conjecture that the winner of\nthe 2-token game characterises history-determinism on parity automata.","main_category":"cs.FL","categories":"cs.FL","published":"2025-03-31T15:57:44Z"}
{"aid":"http://arxiv.org/abs/2503.24247v1","title":"Unitary and non-unitary operators leverage perfect and imperfect single\n  qutrit teleportation","summary":"Teleportation, a novel scheme, initially posited by Bennett \\textit{et.al},\nhas been studied here in the context of sending a single qutrit from Alice to\nBob using two qutrit entangled channels as resources. In this paper we have\nconsidered two special two qutrit entangled states, which belong to $SU(3)$\ngroup, as useful resources for teleportation. For the successful teleportation,\nthese entangled states have been chosen as quantum channels shared between\nAlice and Bob. Another entangled basis of two qutrit states have been used as\nauxiliary states, which would help Alice to manipulate with her channel so that\nthe single qutrit she holds can be successfully teleported to Bob. Bob's\nchoices of measurement operators influence the retrieval of Alice's single\nqutrit.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T15:58:23Z"}
{"aid":"http://arxiv.org/abs/2503.24263v1","title":"The Physics of Conformal Cyclic Cosmology","summary":"According to conformal cyclic cosmology (CCC), the currently conventional\ndescription of the entire history of the universe (but without an initial\ninflationary phase) provides but one cosmic aeon of an unending sequence of\nsuch aeons, where the future conformal infinity of each aeon joins essentially\nsmoothly to the conformally stretched big bang of the next, across a spacelike\n3-surface, referred to as a crossover 3-surface. Whereas in previous accounts\nof CCC a detailed description of the physics of crossover had been somewhat\nproblematic, a novel idea is introduced here to show how crossover takes place\nnaturally during a temporal period of the universe that is dominated by\ngravitational waves referred to here as a gravitational wave epoch (GWE).\nAccordingly, the geometry at the crossover surface is conformally smooth,\nexcept at a discrete set of points, referred to as Hawking points, each\nrepresenting the final Hawking evaporation of the dominant black hole of a\ngalactic cluster in the earlier aeon. It is shown here (using 2-spinor and\ntwistor techniques) that there is a mass-energy conservation law that holds\nacross the crossover surface, showing that the rise of temperature within such\nHawking spots should be effectively determined by the total mass of the\npre-crossover galactic cluster involved. This rise of temperature on the CMB\nmap within Hawking spots is found to be in quantitative agreement with the\nmasses of the largest galactic clusters observed in our own aeon what suggests\nthat the physics in the previous aeon was, at least in the gravitational\nsector, similar to ours. A second observational feature, the actual angular\ndiameter of the Hawking spots seen in our CMB, which is about twice what should\nhave been expected, is associated to the presence of GWE just after the\ncrossover and before the start of the usual cosmological epochs.","main_category":"gr-qc","categories":"gr-qc","published":"2025-03-31T16:10:05Z"}
{"aid":"http://arxiv.org/abs/2503.24264v1","title":"Extended signatures and link concordance","summary":"The Levine-Tristram signature admits an n-variable extension for n-component\nlinks: it was first defined as an integer valued function on\n$(S^1\\setminus\\{1\\})^n$, and recently extended to the full torus $T^n$. The aim\nof the present article is to study and use this extended signature. First, we\nshow that it is constant on the connected components of the complement of the\nzero-locus of some renormalized Alexander polynomial. Then, we prove that the\nextended signature is a concordance invariant on an explicit dense subset of\n$T^n$. Finally, as an application, we present an infinite family of 3-component\nlinks with the following property: these links are not concordant to their\nmirror image, a fact that can be detected neither by the non-extended\nsignatures, nor by the multivariable Alexander polynomial, nor by the Milnor\ntriple linking number.","main_category":"math.GT","categories":"math.GT","published":"2025-03-31T16:10:21Z"}
{"aid":"http://arxiv.org/abs/2503.24267v1","title":"FakeScope: Large Multimodal Expert Model for Transparent AI-Generated\n  Image Forensics","summary":"The rapid and unrestrained advancement of generative artificial intelligence\n(AI) presents a double-edged sword: while enabling unprecedented creativity, it\nalso facilitates the generation of highly convincing deceptive content,\nundermining societal trust. As image generation techniques become increasingly\nsophisticated, detecting synthetic images is no longer just a binary task: it\nnecessitates interpretable, context-aware methodologies that enhance\ntrustworthiness and transparency. However, existing detection models primarily\nfocus on classification, offering limited explanatory insights into image\nauthenticity. In this work, we propose FakeScope, an expert multimodal model\n(LMM) tailored for AI-generated image forensics, which not only identifies\nAI-synthetic images with high accuracy but also provides rich, interpretable,\nand query-driven forensic insights. We first construct FakeChain dataset that\ncontains linguistic authenticity reasoning based on visual trace evidence,\ndeveloped through a novel human-machine collaborative framework. Building upon\nit, we further present FakeInstruct, the largest multimodal instruction tuning\ndataset containing 2 million visual instructions tailored to enhance forensic\nawareness in LMMs. FakeScope achieves state-of-the-art performance in both\nclosed-ended and open-ended forensic scenarios. It can distinguish synthetic\nimages with high accuracy while offering coherent and insightful explanations,\nfree-form discussions on fine-grained forgery attributes, and actionable\nenhancement strategies. Notably, despite being trained exclusively on\nqualitative hard labels, FakeScope demonstrates remarkable zero-shot\nquantitative capability on detection, enabled by our proposed token-based\nprobability estimation strategy. Furthermore, FakeScope exhibits strong\ngeneralization and in-the-wild ability, ensuring its applicability in\nreal-world scenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T16:12:48Z"}
{"aid":"http://arxiv.org/abs/2503.24271v1","title":"Enhancing Image Resolution of Solar Magnetograms: A Latent Diffusion\n  Model Approach","summary":"The spatial properties of the solar magnetic field are crucial to decoding\nthe physical processes in the solar interior and their interplanetary effects.\nHowever, observations from older instruments, such as the Michelson Doppler\nImager (MDI), have limited spatial or temporal resolution, which hinders the\nability to study small-scale solar features in detail. Super resolving these\nolder datasets is essential for uniform analysis across different solar cycles,\nenabling better characterization of solar flares, active regions, and magnetic\nnetwork dynamics. In this work, we introduce a novel diffusion model approach\nfor Super-Resolution and we apply it to MDI magnetograms to match the\nhigher-resolution capabilities of the Helioseismic and Magnetic Imager (HMI).\nBy training a Latent Diffusion Model (LDM) with residuals on downscaled HMI\ndata and fine-tuning it with paired MDI/HMI data, we can enhance the resolution\nof MDI observations from 2\"/pixel to 0.5\"/pixel. We evaluate the quality of the\nreconstructed images by means of classical metrics (e.g., PSNR, SSIM, FID and\nLPIPS) and we check if physical properties, such as the unsigned magnetic flux\nor the size of an active region, are preserved. We compare our model with\ndifferent variations of LDM and Denoising Diffusion Probabilistic models\n(DDPMs), but also with two deterministic architectures already used in the past\nfor performing the Super-Resolution task. Furthermore, we show with an analysis\nin the Fourier domain that the LDM with residuals can resolve features smaller\nthan 2\", and due to the probabilistic nature of the LDM, we can asses their\nreliability, in contrast with the deterministic models. Future studies aim to\nsuper-resolve the temporal scale of the solar MDI instrument so that we can\nalso have a better overview of the dynamics of the old events.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.IM,cs.LG","published":"2025-03-31T16:16:26Z"}
{"aid":"http://arxiv.org/abs/2503.24285v1","title":"Advanced Quantum Annealing Approach to Vehicle Routing Problems with\n  Time Windows","summary":"In this paper, we explore the potential for quantum annealing to solve\nrealistic routing problems. We focus on two NP-Hard problems, including the\nTraveling Salesman Problem with Time Windows and the Capacitated Vehicle\nRouting Problem with Time Windows. We utilize D-Wave's Quantum Annealer and\nConstrained Quadratic Model (CQM) solver within a hybrid framework to solve\nthese problems. We demonstrate that while the CQM solver effectively minimizes\nroute costs, it struggles to maintain time window feasibility as the problem\nsize increases. To address this limitation, we implement a heuristic method\nthat fixes infeasible solutions through a series of swapping operations.\nTesting on benchmark instances shows our method achieves promising results with\nan average optimality gap of 3.86%.","main_category":"cs.ET","categories":"cs.ET,quant-ph","published":"2025-03-31T16:32:40Z"}
{"aid":"http://arxiv.org/abs/2503.24308v1","title":"Johnson's contribution to the Discussion of `Statistical aspects of the\n  Covid-19 response' by Wood et al","summary":"This is a response to the paper \"Some statistical aspects of the Covid-19\nresponse\" by Wood et al, submitted to the discussion at the read paper meeting\nof the Royal Statistical Society on 10th April 2025.","main_category":"stat.AP","categories":"stat.AP","published":"2025-03-31T16:54:44Z"}
{"aid":"http://arxiv.org/abs/2503.24323v1","title":"Synthesis of europium-based crystals containing As or P by a flux\n  method: attempts to grow EuAgP single crystals","summary":"Europium-based materials are highly attractive due to their diverse range of\nphysical properties. In these studies, we aimed to synthesize single crystals\nof the potentially topological semimetallic compound EuAgP, which up to this\nday has only been obtained in polycrystalline form. The flux method was\nemployed for the syntheses, using fluxes such as: Bi, Sn, Pb, and In, in their\nvarious ratios. The purpose of using Bi flux was to try synthesizing an analog\nof EuAgAs single crystals, by fully substituting arsenic with phosphorus. The\nobtained crystals were characterized by x-ray diffraction and scanning electron\nmicroscopy. Despite many unsuccessful attempts to synthesize EuAgP single\ncrystals, the study provides valuable insights into how different fluxes and\ntheir ratios influence the final synthesis product. It also underscores the\ncomplexity of designing analogs between arsenides and phosphides.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-03-31T17:10:04Z"}
{"aid":"http://arxiv.org/abs/2503.24326v1","title":"Self-Supervised Pretraining for Aerial Road Extraction","summary":"Deep neural networks for aerial image segmentation require large amounts of\nlabeled data, but high-quality aerial datasets with precise annotations are\nscarce and costly to produce. To address this limitation, we propose a\nself-supervised pretraining method that improves segmentation performance while\nreducing reliance on labeled data. Our approach uses inpainting-based\npretraining, where the model learns to reconstruct missing regions in aerial\nimages, capturing their inherent structure before being fine-tuned for road\nextraction. This method improves generalization, enhances robustness to domain\nshifts, and is invariant to model architecture and dataset choice. Experiments\nshow that our pretraining significantly boosts segmentation accuracy,\nespecially in low-data regimes, making it a scalable solution for aerial image\nanalysis.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-03-31T17:14:08Z"}
{"aid":"http://arxiv.org/abs/2503.24328v1","title":"Contextual Preference Collaborative Measure Framework Based on Belief\n  System","summary":"To reduce the human intervention in the preference measure process,this\narticle proposes a preference collaborative measure framework based on an\nupdated belief system,which is also capable of improving the accuracy and\nefficiency of preferen-ce measure algorithms.Firstly,the distance of rules and\nthe average internal distance of rulesets are proposed for specifying the\nrelationship between the rules.For discovering the most representative\npreferences that are common in all users,namely common preference,a algorithm\nbased on average internal distance of ruleset,PRA algorithm,is proposed,which\naims to finish the discoveryprocess with minimum information loss\nrate.Furthermore,the concept of Common belief is proposed to update the belief\nsystem,and the common preferences are the evidences of updated belief\nsystem.Then,under the belief system,the proposed belief degree and deviation\ndegree are used to determine whether a rule confirms the belief system or not\nand classify the preference rules into two kinds(generalized or\npersonalized),and eventually filters out Top-K interesting rules relying on\nbelief degree and deviation degree.Based on above,a scalable interestingness\ncalculation framework that can apply various formulas is proposed for\naccurately calculating interestingness in different conditions.At last,IMCos\nalgorithm and IMCov algorithm are proposed as exemplars to verify the accuracy\nand efficiency of the framework by using weighted cosine similarity and\ncorrelation coefficients as belief degree.In experiments,the proposed\nalgorithms are compared to two state-of-the-art algorithms and the results show\nthat IMCos and IMCov outperform than the other two in most aspects.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-03-31T17:17:45Z"}
{"aid":"http://arxiv.org/abs/2503.24329v1","title":"Linear Reweighted Regularization Algorithms for Graph Matching Problem","summary":"The graph matching problem is a significant special case of the Quadratic\nAssignment Problem, with extensive applications in pattern recognition,\ncomputer vision, protein alignments and related fields. As the problem is\nNP-hard, relaxation and regularization techniques are frequently employed to\nimprove tractability. However, most existing regularization terms are\nnonconvex, posing optimization challenges. In this paper, we propose a linear\nreweighted regularizer framework for solving the relaxed graph matching\nproblem, preserving the convexity of the formulation. By solving a sequence of\nrelaxed problems with the linear reweighted regularization term, one can obtain\na sparse solution that, under certain conditions, theoretically aligns with the\noriginal graph matching problem's solution. Furthermore, we present a practical\nversion of the algorithm by incorporating the projected gradient method. The\nproposed framework is applied to synthetic instances, demonstrating promising\nnumerical results.","main_category":"math.OC","categories":"math.OC","published":"2025-03-31T17:18:38Z"}
{"aid":"http://arxiv.org/abs/2503.24333v1","title":"Mean field model of contagion processes in urban traffic networks","summary":"Theoretical arguments and empirical evidence for the emergence of macroscopic\nepidemic type behavior, in the form of Susceptible-Infected-Susceptible (SIS)\nor Susceptible-Infected-Recovered (SIR) processes in urban traffic congestion\nfrom microscopic network flows is given. Moreover, it's shown that the\nemergence of SIS/SIR implies a relationship between traffic flow and density,\nwhich is consistent with observations of the so called Fundamental Diagram of\nTraffic, which is a characteristic signature of vehicle movement phenomena that\nspans multiple scales. Our results provide a plausible explanation for this\nscale-spanning signature and put in more firm grounds recent findings that\nindicate that traffic congestion at the aggregate level can be modeled by\nsimple contagion dynamics.","main_category":"physics.soc-ph","categories":"physics.soc-ph,cond-mat.dis-nn","published":"2025-03-31T17:22:10Z"}
{"aid":"http://arxiv.org/abs/2503.24334v1","title":"Augmenting Expert Cognition in the Age of Generative AI: Insights from\n  Document-Centric Knowledge Work","summary":"As Generative AI (GenAI) capabilities expand, understanding how to preserve\nand develop human expertise while leveraging AI's benefits becomes increasingly\ncritical. Through empirical studies in two contexts -- survey article authoring\nin scholarly research and business document sensemaking -- we examine how\ndomain expertise shapes patterns of AI delegation and information processing\namong knowledge workers. Our findings reveal that while experts welcome AI\nassistance with repetitive information foraging tasks, they prefer to retain\ncontrol over complex synthesis and interpretation activities that require\nnuanced domain understanding. We identify implications for designing GenAI\nsystems that support expert cognition. These include enabling selective\ndelegation aligned with expertise levels, preserving expert agency over\ncritical analytical tasks, considering varying levels of domain expertise in\nsystem design, and supporting verification mechanisms that help users calibrate\ntheir reliance while deepening expertise. We discuss the inherent tension\nbetween reducing cognitive load through automation and maintaining the\ndeliberate practice necessary for expertise development. Lastly, we suggest\napproaches for designing systems that provide metacognitive support, moving\nbeyond simple task automation toward actively supporting expertise development.\nThis work contributes to our understanding of how to design AI systems that\naugment rather than diminish human expertise in document-centric workflows.","main_category":"cs.HC","categories":"cs.HC","published":"2025-03-31T17:22:20Z"}
{"aid":"http://arxiv.org/abs/2503.24338v1","title":"Spontaneous Emission from Electronic Metastable Resonance States","summary":"We demonstrate that calculating the spontaneous emission decay rate from\nmetastable resonance states (states with finite lifetimes embedded in the\ncontinuum) requires considering transitions to all continuum states, not just\nto lower states. This holds even when the lifetimes of the metastable states\nare very long and might be effectively considered as bound states in the\ncontinuum. However, employing complex-scaling transformations, this\ncomputationally prohibitive task becomes feasible by utilizing methods\noriginally designed for excited bound states for calculation of complex poles\nof the scattering matrix. As an illustrative example, these methods are applied\nto calculate the spontaneous emission decay rates of metastable resonance\nstates in a double-barrier potential. The rapid numerical convergence of this\napproach highlights a new avenue for studying spontaneous emission from\nmetastable states in real-life systems, particularly in many-electron systems,\nwhere calculation of the spontaneous emission decay rate from metastable\nresonances (e.g., autoionization states) is computationally difficult, if not\nimpossible, using the standard (Hermitian) formalism of quantum mechanics.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T17:24:32Z"}
{"aid":"http://arxiv.org/abs/2503.24343v1","title":"Early time solution as an alternative to the late time evolving dark\n  energy with DESI DR2 BAO","summary":"Recently the Dark Energy Spectroscopic Instrument (DESI) provided constraints\non the expansion history from their Data Release 2 (DR2). The DESI baryon\nacoustic oscillation (BAO) measurements are well described by a flat\n$\\Lambda$CDM model, but the preferred parameters are in mild ($2.3\\sigma$)\ntension with those determined from the cosmic microwave background (CMB). The\nDESI collaboration has already explored a variety of solutions to this tension\nrelying on variations in the late-time evolution of dark energy. Here we test\nan alternative -- the introduction of an ``early dark energy'' (EDE) component.\nWe find that EDE models can alleviate the tension, though they lead to\ndifferences in other cosmological parameters that have observational\nimplications. Particularly the EDE models that fit the acoustic datasets prefer\nlower $\\Omega_m$, higher $H_0$, $n_s$ and $\\sigma_8$ in contrast to the\nlate-time solutions. We discuss the current status and near-future prospects\nfor distinguishing amongst these solutions.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-03-31T17:26:10Z"}
{"aid":"http://arxiv.org/abs/2503.24347v1","title":"Entanglement Distribution in Lossy Quantum Networks","summary":"Entanglement distribution is essential for unlocking the potential of\ndistributed quantum information processing. We consider an $N$-partite network\nwhere entanglement is distributed via a central source over lossy channels, and\nnetwork participants cooperate to establish entanglement between any two chosen\nparties under local operations and classical communication (LOCC) constraints.\nWe develop a general mathematical framework to assess the optimal average\nbipartite entanglement shared in a lossy distribution, and introduce a\ntractable lower bound by optimizing over a subset of single-parameter LOCC\ntransformations. Our results show that probabilistically extracting Bell pairs\nfrom W states is more advantageous than deterministically extracting them from\nGHZ-like states in lossy networks, with this advantage increasing with network\nsize. We further extend our analysis analytically, proving that W states remain\nmore effective in large-scale networks. These findings offer valuable insights\ninto the practical deployment of near-term networks, revealing a fundamental\ntrade-off between deterministic entanglement distribution protocols and\nloss-sensitive resources.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T17:32:18Z"}
{"aid":"http://arxiv.org/abs/2503.24361v1","title":"Sim-and-Real Co-Training: A Simple Recipe for Vision-Based Robotic\n  Manipulation","summary":"Large real-world robot datasets hold great potential to train generalist\nrobot models, but scaling real-world human data collection is time-consuming\nand resource-intensive. Simulation has great potential in supplementing\nlarge-scale data, especially with recent advances in generative AI and\nautomated data generation tools that enable scalable creation of robot behavior\ndatasets. However, training a policy solely in simulation and transferring it\nto the real world often demands substantial human effort to bridge the reality\ngap. A compelling alternative is to co-train the policy on a mixture of\nsimulation and real-world datasets. Preliminary studies have recently shown\nthis strategy to substantially improve the performance of a policy over one\ntrained on a limited amount of real-world data. Nonetheless, the community\nlacks a systematic understanding of sim-and-real co-training and what it takes\nto reap the benefits of simulation data for real-robot learning. This work\npresents a simple yet effective recipe for utilizing simulation data to solve\nvision-based robotic manipulation tasks. We derive this recipe from\ncomprehensive experiments that validate the co-training strategy on various\nsimulation and real-world datasets. Using two domains--a robot arm and a\nhumanoid--across diverse tasks, we demonstrate that simulation data can enhance\nreal-world task performance by an average of 38%, even with notable differences\nbetween the simulation and real-world data. Videos and additional results can\nbe found at https://co-training.github.io/","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.LG","published":"2025-03-31T17:39:38Z"}
{"aid":"http://arxiv.org/abs/2503.24366v1","title":"StochasticSplats: Stochastic Rasterization for Sorting-Free 3D Gaussian\n  Splatting","summary":"3D Gaussian splatting (3DGS) is a popular radiance field method, with many\napplication-specific extensions. Most variants rely on the same core algorithm:\ndepth-sorting of Gaussian splats then rasterizing in primitive order. This\nensures correct alpha compositing, but can cause rendering artifacts due to\nbuilt-in approximations. Moreover, for a fixed representation, sorted rendering\noffers little control over render cost and visual fidelity. For example, and\ncounter-intuitively, rendering a lower-resolution image is not necessarily\nfaster. In this work, we address the above limitations by combining 3D Gaussian\nsplatting with stochastic rasterization. Concretely, we leverage an unbiased\nMonte Carlo estimator of the volume rendering equation. This removes the need\nfor sorting, and allows for accurate 3D blending of overlapping Gaussians. The\nnumber of Monte Carlo samples further imbues 3DGS with a way to trade off\ncomputation time and quality. We implement our method using OpenGL shaders,\nenabling efficient rendering on modern GPU hardware. At a reasonable visual\nquality, our method renders more than four times faster than sorted\nrasterization.","main_category":"cs.CV","categories":"cs.CV,cs.GR","published":"2025-03-31T17:46:18Z"}
{"aid":"http://arxiv.org/abs/2503.24367v1","title":"The structure and topology of an amorphous metal-organic framework","summary":"Amorphous metal-organic frameworks are an important emerging materials class\nthat combine the attractive physical properties of the amorphous state with the\nversatility of metal-organic framework (MOF) chemistry. The structures of\namorphous MOFs have largely been inferred by drawing analogies to crystalline\npolymorphs and inorganic glasses, but ultimately the validity of such\nstructural models has been challenging to establish either experimentally or\ncomputationally. Here we use a unified data-driven approach, combining\nexperimental scattering data and active machine learning for interatomic\npotentials, to determine the structure of an amorphous zeolitic imidazolate\nframework (a-ZIF) -- the canonical amorphous MOF. Our results reveal clear\ndifferences between the structure of a-ZIF and that of other amorphous\ntetrahedral networks, allowing us to invalidate the long-standing assumption\nthat these inorganic and hybrid glasses are topologically equivalent. To this\nend, we introduce a systematic notation for the network topology of amorphous\nsolids, building a bridge to the successful use of topology analysis in\ncrystalline MOFs and to materials informatics. Our work provides insights into\nthe structure and topology of the archetypal amorphous MOF and opens up new\navenues for modelling and understanding amorphous framework materials more\ngenerally.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.chem-ph","published":"2025-03-31T17:46:37Z"}
{"aid":"http://arxiv.org/abs/2503.24372v1","title":"A criterion on the free energy for log-Sobolev inequalities in\n  mean-field particle systems","summary":"For a class of mean-field particle systems, we formulate a criterion in terms\nof the free energy that implies uniform bounds on the log-Sobolev constant of\nthe associated Langevin dynamics. For certain double-well potentials with\nquadratic interaction, the criterion holds up to the critical temperature of\nthe model, and we also obtain precise asymptotics on the decay of the\nlog-Sobolev constant when approaching the critical point. The criterion also\napplies to ``diluted'' mean-field models defined on sufficiently dense,\npossibly random graphs. We further generalize the criterion to non-quadratic\ninteractions that admit a mode decomposition. The mode decomposition is\ndifferent from the scale decomposition of the Polchinski flow we used for\nshort-range spin systems.","main_category":"math.PR","categories":"math.PR,math-ph,math.FA,math.MP","published":"2025-03-31T17:53:00Z"}
{"aid":"http://arxiv.org/abs/2503.24374v1","title":"ERUPT: Efficient Rendering with Unposed Patch Transformer","summary":"This work addresses the problem of novel view synthesis in diverse scenes\nfrom small collections of RGB images. We propose ERUPT (Efficient Rendering\nwith Unposed Patch Transformer) a state-of-the-art scene reconstruction model\ncapable of efficient scene rendering using unposed imagery. We introduce\npatch-based querying, in contrast to existing pixel-based queries, to reduce\nthe compute required to render a target view. This makes our model highly\nefficient both during training and at inference, capable of rendering at 600\nfps on commercial hardware. Notably, our model is designed to use a learned\nlatent camera pose which allows for training using unposed targets in datasets\nwith sparse or inaccurate ground truth camera pose. We show that our approach\ncan generalize on large real-world data and introduce a new benchmark dataset\n(MSVS-1M) for latent view synthesis using street-view imagery collected from\nMapillary. In contrast to NeRF and Gaussian Splatting, which require dense\nimagery and precise metadata, ERUPT can render novel views of arbitrary scenes\nwith as few as five unposed input images. ERUPT achieves better rendered image\nquality than current state-of-the-art methods for unposed image synthesis\ntasks, reduces labeled data requirements by ~95\\% and decreases computational\nrequirements by an order of magnitude, providing efficient novel view synthesis\nfor diverse real-world scenes.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T17:53:05Z"}
{"aid":"http://arxiv.org/abs/2503.24380v1","title":"The fundamental localization phases in quasiperiodic systems: A unified\n  framework and exact results","summary":"The disordered quantum systems host three types of quantum states, the\nextended, localized, and critical, which bring up various distinct fundamental\nphases, including the pure phases and coexisting ones with mobility edges. The\nquantum phases involving critical states are of particular importance, but are\nless understood compared with the other ones, and the different phases have\nbeen separately studied in different quasiperiodic models. Here we propose a\nunified framework based on a spinful quasiperiodic system which unifies the\nrealizations of all the fundamental Anderson phases, %with or without mobility\nedges, with the exact and universal results being obtained for these distinct\nphases. Through the duality transformation and renormalization group method, we\nshow that the pure phases are obtained when the (emergent) chiral symmetry\npreserves in the proposed spin-1/2 quasiperiodic model, which provides a\ncriteria for the emergence of the pure phases or the coexisting ones with\nmobility edges. Further, we uncover a new universal mechanism for the critical\nstates that the emergence of such states is protected by the generalized\nincommensurate matrix element zeros in the spinful quasiperiodic model, as a\nnovel generalization of the quasiperiodic hopping zeros in the spinless\nsystems. We also show with the Avila's global theory the criteria of exact\nsolvability for the present unified quasiperiodic system, with which we\nidentify several new quasiperiodic models derived from the spinful system\nhosting exactly solvable Anderson phases. In particular, we reach a single\nmodel that hosts all the seven fundamental phases of Anderson localization.\nFinally, an experimental scheme is proposed to realize these models using\nquasiperiodic optical Raman lattices.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.mes-hall,cond-mat.stat-mech,quant-ph","published":"2025-03-31T17:59:02Z"}
{"aid":"http://arxiv.org/abs/2504.01328v1","title":"Slow-Fast Architecture for Video Multi-Modal Large Language Models","summary":"Balancing temporal resolution and spatial detail under limited compute budget\nremains a key challenge for video-based multi-modal large language models\n(MLLMs). Existing methods typically compress video representations using\npredefined rules before feeding them into the LLM, resulting in irreversible\ninformation loss and often ignoring input instructions. To address this, we\npropose a novel slow-fast architecture that naturally circumvents this\ntrade-off, enabling the use of more input frames while preserving spatial\ndetails. Inspired by how humans first skim a video before focusing on relevant\nparts, our slow-fast design employs a dual-token strategy: 1) \"fast\" visual\ntokens -- a compact set of compressed video features -- are fed into the LLM\nalongside text embeddings to provide a quick overview; 2) \"slow\" visual tokens\n-- uncompressed video features -- are cross-attended by text embeddings through\nspecially designed hybrid decoder layers, enabling instruction-aware extraction\nof relevant visual details with linear complexity. We conduct systematic\nexploration to optimize both the overall architecture and key components.\nExperiments show that our model significantly outperforms self-attention-only\nbaselines, extending the input capacity from 16 to 128 frames with just a 3%\nincrease in computation, and achieving a 16% average performance improvement\nacross five video understanding benchmarks. Our 7B model achieves\nstate-of-the-art performance among models of similar size. Furthermore, our\nslow-fast architecture is a plug-and-play design that can be integrated into\nother video MLLMs to improve efficiency and scalability.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T03:24:58Z"}
{"aid":"http://arxiv.org/abs/2504.01329v1","title":"Flexible and Explainable Graph Analysis for EEG-based Alzheimer's\n  Disease Classification","summary":"Alzheimer's Disease is a progressive neurological disorder that is one of the\nmost common forms of dementia. It leads to a decline in memory, reasoning\nability, and behavior, especially in older people. The cause of Alzheimer's\nDisease is still under exploration and there is no all-inclusive theory that\ncan explain the pathologies in each individual patient. Nevertheless, early\nintervention has been found to be effective in managing symptoms and slowing\ndown the disease's progression. Recent research has utilized\nelectroencephalography (EEG) data to identify biomarkers that distinguish\nAlzheimer's Disease patients from healthy individuals. Prior studies have used\nvarious machine learning methods, including deep learning and graph neural\nnetworks, to examine electroencephalography-based signals for identifying\nAlzheimer's Disease patients. In our research, we proposed a Flexible and\nExplainable Gated Graph Convolutional Network (GGCN) with Multi-Objective\nTree-Structured Parzen Estimator (MOTPE) hyperparameter tuning. This provides a\nflexible solution that efficiently identifies the optimal number of GGCN blocks\nto achieve the optimized precision, specificity, and recall outcomes, as well\nas the optimized area under the Receiver Operating Characteristic (AUC). Our\nfindings demonstrated a high efficacy with an over 0.9 Receiver Operating\nCharacteristic score, alongside precision, specificity, and recall scores in\ndistinguishing health control with Alzheimer's Disease patients in Moderate to\nSevere Dementia using the power spectrum density (PSD) of\nelectroencephalography signals across various frequency bands. Moreover, our\nresearch enhanced the interpretability of the embedded adjacency matrices,\nrevealing connectivity differences in frontal and parietal brain regions\nbetween Alzheimer's patients and healthy individuals.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T03:29:12Z"}
{"aid":"http://arxiv.org/abs/2504.01338v1","title":"FlowMotion: Target-Predictive Flow Matching for Realistic Text-Driven\n  Human Motion Generation","summary":"Achieving highly diverse and perceptually consistent 3D character animations\nwith natural motion and low computational costs remains a challenge in computer\nanimation. Existing methods often struggle to provide the nuanced complexity of\nhuman movement, resulting in perceptual inconsistencies and motion artifacts.\nTo tackle these issues, we introduce FlowMotion, a novel approach that\nleverages Conditional Flow Matching (CFM) for improved motion synthesis.\nFlowMotion incorporates an innovative training objective that more accurately\npredicts target motion, reducing the inherent jitter associated with CFM while\nenhancing stability, realism, and computational efficiency in generating\nanimations. This direct prediction approach enhances the perceptual quality of\nanimations by reducing erratic motion and aligning the training more closely\nwith the dynamic characteristics of human movement. Our experimental results\ndemonstrate that FlowMotion achieves higher balance between motion smoothness\nand generalization capability while maintaining the computational efficiency\ninherent in flow matching compared to state-of-the-art methods.","main_category":"cs.GR","categories":"cs.GR,cs.LG","published":"2025-04-02T03:55:21Z"}
{"aid":"http://arxiv.org/abs/2504.01340v1","title":"Local conformal symmetry and anomalies with antisymmetric tensor field","summary":"We consider the trace anomaly, which results from the integration of the\nmassless conformal fermion field with the background of metric and\nantisymmetric tensor fields. The non-local terms in the anomaly-induced\neffective action do not depend on the scheme of quantum calculations. On the\nother hand, total derivative terms in the anomaly and the corresponding local\npart of the induced action manifest scheme dependence and multiplicative\nanomaly.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-02T04:10:12Z"}
{"aid":"http://arxiv.org/abs/2504.01342v1","title":"Foundations and Evaluations in NLP","summary":"This memoir explores two fundamental aspects of Natural Language Processing\n(NLP): the creation of linguistic resources and the evaluation of NLP system\nperformance. Over the past decade, my work has focused on developing a\nmorpheme-based annotation scheme for the Korean language that captures\nlinguistic properties from morphology to semantics. This approach has achieved\nstate-of-the-art results in various NLP tasks, including part-of-speech\ntagging, dependency parsing, and named entity recognition. Additionally, this\nwork provides a comprehensive analysis of segmentation granularity and its\ncritical impact on NLP system performance. In parallel with linguistic resource\ndevelopment, I have proposed a novel evaluation framework, the jp-algorithm,\nwhich introduces an alignment-based method to address challenges in\npreprocessing tasks like tokenization and sentence boundary detection (SBD).\nTraditional evaluation methods assume identical tokenization and sentence\nlengths between gold standards and system outputs, limiting their applicability\nto real-world data. The jp-algorithm overcomes these limitations, enabling\nrobust end-to-end evaluations across a variety of NLP tasks. It enhances\naccuracy and flexibility by incorporating linear-time alignment while\npreserving the complexity of traditional evaluation metrics. This memoir\nprovides key insights into the processing of morphologically rich languages,\nsuch as Korean, while offering a generalizable framework for evaluating diverse\nend-to-end NLP systems. My contributions lay the foundation for future\ndevelopments, with broader implications for multilingual resource development\nand system evaluation.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T04:14:03Z"}
{"aid":"http://arxiv.org/abs/2504.01351v1","title":"Demonstration of Plate Analysis, an algorithm for precise relative\n  astrometry","summary":"Astrometry plays a crucial role in understanding the structure, dynamics, and\nevolution of celestial objects by providing precise measurements of their\npositions and motions. We propose a new approach to wide-field, relative\nastrometry, Plate Analysis. Plate Analysis is an innovative algorithm that\nestimates stellar coordinates and corrects geometric distortion based on\nprecise reference sources, without relying on dedicated calibration fields. It\nis implemented as a probabilistic framework using Stochastic Variational\nInference to efficiently optimize the numerous parameters involved in the\nmodel.\n  The methodology was tested through a simplified simulation designed after the\nGalactic center survey of the JASMINE mission. This simulation, called the\nJASMINE mini-mock survey, covered three years of observation with 100 satellite\norbits, providing a comprehensive dataset for evaluating the performance of\nPlate Analysis. Although the observation model incorporated more than 30,000\nparameters, the parameters were efficiently optimized through Plate Analysis.\nThe results showed that the estimated coordinates closely match the expected\nstellar motions, with an average positional error of about $70\\,\\mathrm{\\mu\nas}$. These findings validate the potential of Plate Analysis for precise\nwide-field astrometric applications, offering significant insights into\nimproving the accuracy of stellar dynamics measurements.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-02T04:51:21Z"}
{"aid":"http://arxiv.org/abs/2504.01363v1","title":"Embedding Higman-Thompson groups of unfolding trees into the Leavitt\n  path algebras","summary":"The isomorphism problem of regular Higman-Thompson groups was solved in\narXiv:1006.1759, via embedding it into the Leavitt algebra. In this paper, we\nwill expand these results to embed the Higman-Thompson groups of unfolding\ntrees of directed graphs into the Leavitt path algebra. This embedding allows\nus to show that any isomorphism of rooted Leavitt path algebras induces an\nisomorphism between Higman-Thompson groups.","main_category":"math.RA","categories":"math.RA,math.GR","published":"2025-04-02T05:13:00Z"}
{"aid":"http://arxiv.org/abs/2504.01371v1","title":"A simple schematic model for a cross section deficit in\n  $^{12}$C+$^{12}$C fusion reactions","summary":"A cross section deficit phenomenon has been observed in $^{12}$C+$^{12}$C\nfusion reactions at astrophysical energies, at which fusion cross sections are\nsuppressed in the off-resonance regions as compared to fusion cross sections\nfor the $^{12}$C+$^{13}$C system. I here construct a simple schematic model\nwhich simulates this phenomenon. The model consists of a random matrix\nHamiltonian based on the Gaussian Orthogonal Ensemble (GOE), which is coupled\nto an entrance channel Hamiltonian in the discrete basis representation. I show\nthat the transmission coefficients are almost unity when both the level density\nand the decay widths of the GOE configurations are large, realizing the strong\nabsorption regime. On the other hand, when these parameters are small, the\ntransmission coefficients are significantly structured as a function of energy.\nIn that situation, the transmission coefficients at resonance energies reach\nunity in this model, that is consistent with the experimental finding of the\ncross section deficit.","main_category":"nucl-th","categories":"nucl-th,nucl-ex","published":"2025-04-02T05:33:59Z"}
{"aid":"http://arxiv.org/abs/2504.01383v1","title":"v-CLR: View-Consistent Learning for Open-World Instance Segmentation","summary":"In this paper, we address the challenging problem of open-world instance\nsegmentation. Existing works have shown that vanilla visual networks are biased\ntoward learning appearance information, \\eg texture, to recognize objects. This\nimplicit bias causes the model to fail in detecting novel objects with unseen\ntextures in the open-world setting. To address this challenge, we propose a\nlearning framework, called view-Consistent LeaRning (v-CLR), which aims to\nenforce the model to learn appearance-invariant representations for robust\ninstance segmentation. In v-CLR, we first introduce additional views for each\nimage, where the texture undergoes significant alterations while preserving the\nimage's underlying structure. We then encourage the model to learn the\nappearance-invariant representation by enforcing the consistency between object\nfeatures across different views, for which we obtain class-agnostic object\nproposals using off-the-shelf unsupervised models that possess strong\nobject-awareness. These proposals enable cross-view object feature matching,\ngreatly reducing the appearance dependency while enhancing the\nobject-awareness. We thoroughly evaluate our method on public benchmarks under\nboth cross-class and cross-dataset settings, achieving state-of-the-art\nperformance. Project page: https://visual-ai.github.io/vclr","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T05:52:30Z"}
{"aid":"http://arxiv.org/abs/2504.01398v1","title":"Cause or Trigger? From Philosophy to Causal Modeling","summary":"Not much has been written about the role of triggers in the literature on\ncausal reasoning, causal modeling, or philosophy. In this paper, we focus on\ndescribing triggers and causes in the metaphysical sense and on\ncharacterizations that differentiate them from each other. We carry out a\nphilosophical analysis of these differences. From this, we formulate a\ndefinition that clearly differentiates triggers from causes and can be used for\ncausal reasoning in natural sciences. We propose a mathematical model and the\nCause-Trigger algorithm, which, based on given data to observable processes, is\nable to determine whether a process is a cause or a trigger of an effect. The\npossibility to distinguish triggers from causes directly from data makes the\nalgorithm a useful tool in natural sciences using observational data, but also\nfor real-world scenarios. For example, knowing the processes that trigger\ncauses of a tropical storm could give politicians time to develop actions such\nas evacuation the population. Similarly, knowing the triggers of processes that\ncause global warming could help politicians focus on effective actions. We\ndemonstrate our algorithm on the climatological data of two recent cyclones,\nFreddy and Zazu. The Cause-Trigger algorithm detects processes that trigger\nhigh wind speed in both storms during their cyclogenesis. The findings obtained\nagree with expert knowledge.","main_category":"cs.LG","categories":"cs.LG,stat.ME","published":"2025-04-02T06:37:48Z"}
{"aid":"http://arxiv.org/abs/2504.01404v1","title":"LLM4SZZ: Enhancing SZZ Algorithm with Context-Enhanced Assessment on\n  Large Language Models","summary":"The SZZ algorithm is the dominant technique for identifying bug-inducing\ncommits and serves as a foundation for many software engineering studies, such\nas bug prediction and static code analysis. Researchers have proposed many\nvariants to enhance the SZZ algorithm's performance since its introduction. The\nmajority of them rely on static techniques or heuristic assumptions, making\nthem easy to implement, but their performance improvements are often limited.\nRecently, a deep learning-based SZZ algorithm has been introduced to enhance\nthe original SZZ algorithm. However, it requires complex preprocessing and is\nrestricted to a single programming language. Additionally, while it enhances\nprecision, it sacrifices recall. Furthermore, most of variants overlook crucial\ninformation, such as commit messages and patch context, and are limited to\nbug-fixing commits involving deleted lines. The emergence of large language\nmodels (LLMs) offers an opportunity to address these drawbacks. In this study,\nwe investigate the strengths and limitations of LLMs and propose LLM4SZZ, which\nemploys two approaches (i.e., rank-based identification and context-enhanced\nidentification) to handle different types of bug-fixing commits. We determine\nwhich approach to adopt based on the LLM's ability to comprehend the bug and\nidentify whether the bug is present in a commit. The context-enhanced\nidentification provides the LLM with more context and requires it to find the\nbug-inducing commit among a set of candidate commits. In rank-based\nidentification, we ask the LLM to select buggy statements from the bug-fixing\ncommit and rank them based on their relevance to the root cause. Experimental\nresults show that LLM4SZZ outperforms all baselines across three datasets,\nimproving F1-score by 6.9% to 16.0% without significantly sacrificing recall.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-02T06:40:57Z"}
{"aid":"http://arxiv.org/abs/2504.01410v1","title":"The Interstellar Medium","summary":"The interstellar medium (ISM) is the material that fills the space between\nthe stars in all galaxies; it is a multi-phase medium in pressure equilibrium,\nwith densities and temperatures covering over 6 orders of magnitude. Although\naccounting for only a small fraction of the mass of any given galaxy, it is a\nvital component, since it holds the material responsible for galaxy growth\nthrough star formation. Studying the ISM requires careful observations at all\nwavelengths of the electromagnetic spectrum. This article describes the\nmulti-phase nature of the ISM, and then puts it in the context of galaxy\nevolution models, emphasising the importance of the cycling of baryons in and\nout of galaxies. Within this framework, the ISM plays a central role: it\nconnects the physical processes operating on very large physical- and\ntime-scales which control the accretion of gas onto galaxies, and the small\nscale processes that regulate star formation.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-02T06:52:57Z"}
{"aid":"http://arxiv.org/abs/2504.01414v1","title":"Balancing Subjectivity and Objectivity in Network Selection: A\n  Decision-Making Framework Towards Digital Twins","summary":"Selecting the optimal radio access technology (RAT) during vertical handovers\n(VHO) in heterogeneous wireless networks (HWNs) is critical. Multi-attribute\ndecision-making (MADM) is the most common approach used for network selection\n(NS) in HWNs. However, existing MADM-NS methods face two major challenges: the\nrank reversal problem (RRP), where the relative ranking of alternatives changes\nunexpectedly, and inefficient handling of user and/or service requirements.\nThese limitations result in suboptimal RAT selection and diminished quality of\nservice, which becomes particularly critical for time-sensitive applications.\nTo address these issues, we introduce in this work a novel weighting assignment\ntechnique called BWM-GWO, which integrates the Best-Worst Method (BWM) with the\nGrey Wolf Optimization (GWO) algorithm through a convex linear combination. The\nproposed framework achieves a balanced decision-making process by using BWM to\ncompute subjective weights that capture user/service preferences, while\nemploying GWO to derive objective weights aimed at minimizing RRP. The\ndevelopment and validation of this framework establish a digital model for NS\nin HWNs, marking the initial step toward realizing a digital twin (DT).\nExperimental results show that integrating the proposed BWM-GWO technique with\nMADM-NS reduces RRP occurrence by up to 71.3% while significantly improving\nuser and service satisfaction compared to benchmark approaches.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-02T07:06:58Z"}
{"aid":"http://arxiv.org/abs/2504.01417v1","title":"Hook fusion procedure for direct product of symmetric groups","summary":"In this work, we derive a new expression for the diagonal matrix elements of\nirreducible representations of the direct product group $S_r\\times S_s$ using\nGrime's hook fusion procedure for symmetric groups, which simplifies the fusion\nprocedure by reducing the number of auxiliary parameters needed. By extending\nthis approach to the product group setting, we provide a method for\nconstructing a complete set of orthogonal primitive idempotents.","main_category":"math.RT","categories":"math.RT","published":"2025-04-02T07:10:27Z"}
{"aid":"http://arxiv.org/abs/2504.01425v1","title":"Asymptotic stability and exponential stability for a class of impulsive\n  neutral differential equations with discrete and distributed delays","summary":"In this paper, we present sufficient conditions for asymptotic stability and\nexponential stability of a class of impulsive neutral differential equations\nwith discrete and distributed delays. Our approaches are based on the method\nusing fixed point theory, which do not resort to any Lyapunov functions or\nLyapunov functionals. Our conditions do not require the differentiability of\ndelays, nor do they ask for a fixed sign on the coefficient functions. Our\nresults improve some previous ones in the literature. Examples are given to\nillustrate our main results.","main_category":"math.DS","categories":"math.DS","published":"2025-04-02T07:22:03Z"}
{"aid":"http://arxiv.org/abs/2504.01442v1","title":"Coarse-to-Fine Semantic Communication Systems for Text Transmission","summary":"Achieving more powerful semantic representations and semantic understanding\nis one of the key problems in improving the performance of semantic\ncommunication systems. This work focuses on enhancing the semantic\nunderstanding of the text data to improve the effectiveness of semantic\nexchange. We propose a novel semantic communication system for text\ntransmission, in which the semantic understanding is enhanced by coarse-to-fine\nprocessing. Especially, a dual attention mechanism is proposed to capture both\nthe coarse and fine semantic information. Numerical experiments show the\nproposed system outperforms the benchmarks in terms of bilingual evaluation,\nsentence similarity, and robustness under various channel conditions.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-02T07:50:35Z"}
{"aid":"http://arxiv.org/abs/2504.01448v1","title":"LLM-VPRF: Large Language Model Based Vector Pseudo Relevance Feedback","summary":"Vector Pseudo Relevance Feedback (VPRF) has shown promising results in\nimproving BERT-based dense retrieval systems through iterative refinement of\nquery representations. This paper investigates the generalizability of VPRF to\nLarge Language Model (LLM) based dense retrievers. We introduce LLM-VPRF and\nevaluate its effectiveness across multiple benchmark datasets, analyzing how\ndifferent LLMs impact the feedback mechanism. Our results demonstrate that\nVPRF's benefits successfully extend to LLM architectures, establishing it as a\nrobust technique for enhancing dense retrieval performance regardless of the\nunderlying models. This work bridges the gap between VPRF with traditional\nBERT-based dense retrievers and modern LLMs, while providing insights into\ntheir future directions.","main_category":"cs.IR","categories":"cs.IR,cs.LG","published":"2025-04-02T08:02:01Z"}
{"aid":"http://arxiv.org/abs/2504.01453v1","title":"Tinnitus, lucid dreaming and awakening. An online survey and theoretical\n  implications","summary":"(1) Background: Tinnitus is the perception of phantom sound in the absence of\na corresponding external source. Previous studies reported that the presence of\ntinnitus is notably absent during dreams. This study aimed at replicating\nprevious findings regarding tinnitus-free dreams, while also gaining a deeper\nunderstanding of tinnitus manifestations during dreams and after awakening. (2)\nMethods: For this observational study, 195 tinnitus patients answered an online\nsurvey on the mutual-help community Siopi. (3) Results: 160 patients could\nrecall their dreams. Among them, 92.5% state they do not hear their tinnitus\nwhile dreaming. The rest (7.5%) report higher tinnitus burden, higher stress\nand more often exhibit objective tinnitus and/or tinnitus related to peripheral\nauditory pathology and/or drug intake. 13% of the participants frequently\nexperience lucid dreams. Among them, 36% could perceive their tinnitus during\nlucid dreams, and this was strongly associated with the concomitant perception\nof external sounds during lucid dreaming. While the majority of patients report\nperceiving their tinnitus instantly upon awakening, during nocturnal\nawakenings, 18% declared they could be awakened by their tinnitus and 9.8%\nmentioned that their tinnitus can temporarily cease. (4) Conclusions: Our\nfindings confirm the previous findings: tinnitus is rarely perceived during\ndreams. Remarkably, our study is the first to document the case of tinnitus\nduring lucid dreaming. 64% of these patients gain higher-order consciousness\nattributes while still experiencing a tinnitus-free state. Our observations\nsuggest that the presence or absence of gating of external auditory information\nduring dreams acts as a tinnitus on-off switch, refining the previously\nproposed integrative model of auditory phantom perception.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-04-02T08:06:00Z"}
{"aid":"http://arxiv.org/abs/2504.01456v1","title":"Multiscale exploration of SMACS J0723.3--7327's intracluster light and\n  past dynamical history","summary":"In this work an analysis of the intracluster light (ICL) in the galaxy\ncluster SMACS J0723.3-7327 (hereafter, SMACS J0723) using JWST/NIRCam deep\nimaging in six filters (F090W to F444W) is presented. The images were processed\nfor low surface brightness (LSB) science, with additional correction for\ninstrumental scattering in the short-wavelength channels, and analysed using\nwavelet-based decomposition. The ICL, brightest cluster galaxy (BCG), and\nsatellite galaxies were extracted and modelled, with 2D maps for each\ncomponent. ICL and ICL+BCG fractions, computed across all filters within a 400\nkpc radius, exhibit a flat trend with wavelength, averaging 28% and 34%,\nrespectively. Flux ratios between the BCG and the next brightest members\n(M$_{12}$, M$_{13}$ and M$_{14}$) also display minimal wavelength dependence.\nThese results indicate that SMACS J0723 is a dynamically evolved cluster with a\ndominant BCG and well-developed ICL. Five prominent ICL substructures are\nanalysed, contributing to 10-12% of the total ICL+BCG flux budget, slightly\nexceeding simulation predictions. Their short dynamical timescales suggest an\ninstantaneous ICL injection rate of several $10^3 L_{\\odot}\\,{\\rm yr}^{-1}$,\nconsistent with active dynamical assembly. These findings support a scenario\nwhere SMACS J0723's ICL growth is currently driven by galaxy mergers involving\nthe BCG and other bright satellites, rather than by the accretion of\npre-processed ICL from a recent cluster merger. However, extrapolating the\ncurrent injection rate to the cluster's lifetime indicates that additional\nmechanisms are required to match the growth observed in other clusters over\ncosmic times.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-02T08:10:05Z"}
{"aid":"http://arxiv.org/abs/2504.01460v1","title":"K2: On Optimizing Distributed Transactions in a Multi-region Data Store\n  with TrueTime Clocks (Extended Version)","summary":"TrueTime clocks (TTCs) that offer accurate and reliable time within limited\nuncertainty bounds have been increasingly implemented in many clouds.\nMulti-region data stores that seek decentralized synchronization for high\nperformance represent an ideal application of TTC. However, the co-designs\nbetween the two were often undervalued or failed to realize their full\npotential.\n  This paper proposes K2, a multi-region data store that intensely explores the\nopportunity of using TTC for distributed transactions. Compared to its pioneer,\nGoogle Spanner, K2 augments TTC's semantics in three core design pillars.\nFirst, K2 carries a new timestamp-generating scheme that is capable of\nproviding a small time uncertainty bound at scale. Second, K2 revitalizes\nexisting multi-version timestamp-ordered concurrency control to realize\nmulti-version properties for read-write transactions. Third, K2 introduces a\nnew TTC-based visibility control protocol that provides efficient reads at\nreplicas. Our evaluation shows that, K2 achieves an order of magnitude higher\ntransaction throughput relative to other practical geo-distributed transaction\nprotocols while ensuring a lower visibility delay at asynchronous replicas.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-02T08:17:11Z"}
{"aid":"http://arxiv.org/abs/2504.01471v1","title":"On the mean-field limit for the Vlasov-Poisson system","summary":"We present a probabilistic proof of the mean-field limit and propagation of\nchaos of a classical N-particle system in three dimensions with Coulomb\ninteraction force of the form $f^N(q)=\\pm\\frac{q}{|q|^3}$ and $N$-dependent\ncut-off at $|q|>N^{-\\frac{5}{12}+\\sigma}$ where $\\sigma>0$ can be chosen\narbitrarily small. This cut-off size is much smaller than the typical distance\nto the nearest neighbour. In particular, for typical initial data, we show\nconvergence of the Newtonian trajectories to the characteristics of the\nVlasov-Poisson system. The proof is based on a Gronwall estimate for the\nmaximal distance between the exact microscopic dynamics and the approximate\nmean-field dynamics. Thus our result leads to a derivation of the\nVlasov-Poisson equation from the microscopic $N$-particle dynamics with force\nterm arbitrary close to the physically relevant Coulomb force.","main_category":"math-ph","categories":"math-ph,math.DS,math.MP,physics.class-ph,G.3","published":"2025-04-02T08:24:18Z"}
{"aid":"http://arxiv.org/abs/2504.01476v1","title":"Enhanced Cross-modal 3D Retrieval via Tri-modal Reconstruction","summary":"Cross-modal 3D retrieval is a critical yet challenging task, aiming to\nachieve bi-directional retrieval between 3D and text modalities. Current\nmethods predominantly rely on a certain 3D representation (e.g., point cloud),\nwith few exploiting the 2D-3D consistency and complementary relationships,\nwhich constrains their performance. To bridge this gap, we propose to adopt\nmulti-view images and point clouds to jointly represent 3D shapes, facilitating\ntri-modal alignment (i.e., image, point, text) for enhanced cross-modal 3D\nretrieval. Notably, we introduce tri-modal reconstruction to improve the\ngeneralization ability of encoders. Given point features, we reconstruct image\nfeatures under the guidance of text features, and vice versa. With well-aligned\npoint cloud and multi-view image features, we aggregate them as multimodal\nembeddings through fine-grained 2D-3D fusion to enhance geometric and semantic\nunderstanding. Recognizing the significant noise in current datasets where many\n3D shapes and texts share similar semantics, we employ hard negative\ncontrastive training to emphasize harder negatives with greater significance,\nleading to robust discriminative embeddings. Extensive experiments on the\nText2Shape dataset demonstrate that our method significantly outperforms\nprevious state-of-the-art methods in both shape-to-text and text-to-shape\nretrieval tasks by a substantial margin.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T08:29:42Z"}
{"aid":"http://arxiv.org/abs/2504.01483v1","title":"GarmageNet: A Dataset and Scalable Representation for Generic Garment\n  Modeling","summary":"High-fidelity garment modeling remains challenging due to the lack of\nlarge-scale, high-quality datasets and efficient representations capable of\nhandling non-watertight, multi-layer geometries. In this work, we introduce\nGarmage, a neural-network-and-CG-friendly garment representation that\nseamlessly encodes the accurate geometry and sewing pattern of complex\nmulti-layered garments as a structured set of per-panel geometry images. As a\ndual-2D-3D representation, Garmage achieves an unprecedented integration of 2D\nimage-based algorithms with 3D modeling workflows, enabling high fidelity,\nnon-watertight, multi-layered garment geometries with direct compatibility for\nindustrial-grade simulations.Built upon this representation, we present\nGarmageNet, a novel generation framework capable of producing detailed\nmulti-layered garments with body-conforming initial geometries and intricate\nsewing patterns, based on user prompts or existing in-the-wild sewing patterns.\nFurthermore, we introduce a robust stitching algorithm that recovers per-vertex\nstitches, ensuring seamless integration into flexible simulation pipelines for\ndownstream editing of sewing patterns, material properties, and dynamic\nsimulations. Finally, we release an industrial-standard, large-scale,\nhigh-fidelity garment dataset featuring detailed annotations, vertex-wise\ncorrespondences, and a robust pipeline for converting unstructured production\nsewing patterns into GarmageNet standard structural assets, paving the way for\nlarge-scale, industrial-grade garment generation systems.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-02T08:37:32Z"}
{"aid":"http://arxiv.org/abs/2504.01489v1","title":"Test-Time Alignment for Tracking User Interest Shifts in Sequential\n  Recommendation","summary":"Sequential recommendation is essential in modern recommender systems, aiming\nto predict the next item a user may interact with based on their historical\nbehaviors. However, real-world scenarios are often dynamic and subject to\nshifts in user interests. Conventional sequential recommendation models are\ntypically trained on static historical data, limiting their ability to adapt to\nsuch shifts and resulting in significant performance degradation during\ntesting. Recently, Test-Time Training (TTT) has emerged as a promising\nparadigm, enabling pre-trained models to dynamically adapt to test data by\nleveraging unlabeled examples during testing. However, applying TTT to\neffectively track and address user interest shifts in recommender systems\nremains an open and challenging problem. Key challenges include how to capture\ntemporal information effectively and explicitly identifying shifts in user\ninterests during the testing phase. To address these issues, we propose\nT$^2$ARec, a novel model leveraging state space model for TTT by introducing\ntwo Test-Time Alignment modules tailored for sequential recommendation,\neffectively capturing the distribution shifts in user interest patterns over\ntime. Specifically, T$^2$ARec aligns absolute time intervals with\nmodel-adaptive learning intervals to capture temporal dynamics and introduce an\ninterest state alignment mechanism to effectively and explicitly identify the\nuser interest shifts with theoretical guarantees. These two alignment modules\nenable efficient and incremental updates to model parameters in a\nself-supervised manner during testing, enhancing predictions for online\nrecommendation. Extensive evaluations on three benchmark datasets demonstrate\nthat T$^2$ARec achieves state-of-the-art performance and robustly mitigates the\nchallenges posed by user interest shifts.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-02T08:42:30Z"}
{"aid":"http://arxiv.org/abs/2504.01501v1","title":"Vertex-Based Localization of ErdÅ‘s-Gallai Theorems for Paths and\n  Cycles","summary":"For a simple graph $G$, let $n$ and $m$ denote the number of vertices and\nedges in $G$, respectively. The Erd\\H{o}s-Gallai theorem for paths states that\nin a simple $P_k$-free graph, $m \\leq \\frac{n(k-1)}{2}$, where $P_k$ denotes a\npath with length $k$ (that is, with $k$ edges). In this paper, we generalize\nthis result as follows: For each $v \\in V(G)$, let $p(v)$ be the length of the\nlongest path that contains $v$. We show that \\[m \\leq \\sum_{v \\in V(G)}\n\\frac{p(v)}{2}\\] The Erd\\H{o}s-Gallai theorem for cycles states that in a\nsimple graph $G$ with circumference (that is, the length of the longest cycle)\nat most $k$, we have $m \\leq \\frac{k(n-1)}{2}$. We strengthen this result as\nfollows: For each $v \\in V(G)$, let $c(v)$ be the length of the longest cycle\nthat contains $v$, or $2$ if $v$ is not part of any cycle. We prove that \\[m\n\\leq \\left( \\sum_{v \\in V(G)} \\frac{c(v)}{2} \\right) - \\frac{c(u)}{2}\\] where\n$c(u)$ denotes the circumference of $G$. \\newline Furthermore, we characterize\nthe class of extremal graphs that attain equality in these bounds.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-02T08:52:28Z"}
{"aid":"http://arxiv.org/abs/2504.01513v1","title":"Laser Annealing of Transparent ZnO Thin Films: A Route to Improve\n  Electrical Conductivity and Oxygen Sensing Capabilities","summary":"The chemical deposition of high-performance Zinc Oxide (ZnO) thin films is\nchallenging, thus significant efforts have been devoted during the past decades\nto develop cost-effective, scalable fabrication methods in gas phase. This work\ndemonstrates how ultra-short-pulse Laser Beam Scanning (LBS) can be used to\nmodulate electrical conductivity in ZnO thin films deposited on soda-lime glass\nby Spatial Atomic Layer Deposition (SALD), a high-throughput, low-temperature\ndeposition technique suitable for large-area applications. By systematically\noptimizing laser parameters, including pulse energy and hatching distance,\nsignificant improvements in the electrical performance of 90 nm-thick ZnO films\nwere achieved. The optimization of the laser annealing parameters, 0.21\nuJ/pulse energy and a 1 micron hatching distance, yielded ZnO films with an\nelectrical resistivity of (9 +- 2) 10-2 Ohm cm, 3 orders of magnitude lower\nthan as deposited films. This result suggests that laser\npost-deposition-processing can play an important role in tailoring the\nproperties of ZnO thin films. Excessive laser intensity can compromise\nstructural integrity of the films, however, degrading their electrical\ntransport properties. Notably, the electrical resistance of laser-annealed ZnO\nfilms exhibited high sensitivity to oxygen concentration in the surrounding\natmosphere, suggesting exciting prospects for application in devices based on\ntransparent oxygen sensors. This study thus positions ultra-short pulsed laser\nannealing as a versatile post-deposition method for fine-tuning the properties\nof ZnO thin films, enabling their use in advanced optoelectronic and\ngas-sensing technologies, particularly on temperature-sensitive substrates.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T09:00:05Z"}
{"aid":"http://arxiv.org/abs/2504.01525v1","title":"Rapid Muon Tomography for Border Security","summary":"Cosmic-ray muon tomography is a promising technique for border security\napplications, leveraging highly penetrating cosmic-ray muons and their\ninteractions with various materials to generate 3D images of large and dense\nobjects, such as shipping containers. Using scattering and absorption of muons\nas they pass through dense cargo materials, muon tomography provides a viable\nsolution for customs and border security by enabling the verification of\nshipping container declarations and preventing illegal trafficking. In this\nstudy, we utilized Monte Carlo simulations to evaluate the effectiveness of\nmuon tomography for cargo characterization and contraband detection in various\nsmuggling scenarios. Our results demonstrate that muon tomography can offers a\nnovel approach to cargo inspection, moving beyond traditional 3D image\nreconstruction. Instead, it analyzes muon scattering and absorption rates in\nreal time during scanning, enabling the prompt detection of discrepancies\nbetween actual cargo contents and declared goods within just 10 to 20 seconds.\nThis method is particularly effective for cargo consisting of uniform loads\ncomposed of a single material or product, a common practice in shipping. Unlike\ntraditional X-ray radiography, which analyzes detailed 2D images, muon\ntomography begins evaluating scatter-absorption rates within the first few\nseconds of scanning. This early assessment enables cargo evaluation long before\na statistically reliable 3D image is formed, significantly improving scanning\nthroughput without disrupting trade flow.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-02T09:12:31Z"}
{"aid":"http://arxiv.org/abs/2504.01527v1","title":"Beyond Nearest Neighbor Interpolation in Data Augmentation","summary":"Avoiding the risk of undefined categorical labels using nearest neighbor\ninterpolation overlooks the risk of exacerbating pixel level annotation errors\nin data augmentation. To simultaneously avoid these risks, the author modified\nconvolutional neural networks data transformation functions by incorporating a\nmodified geometric transformation function to improve the quality of augmented\ndata by removing the reliance on nearest neighbor interpolation and integrating\na mean based class filtering mechanism to handle undefined categorical labels\nwith alternative interpolation algorithms. Experiments on semantic segmentation\ntasks using three medical image datasets demonstrated both qualitative and\nquantitative improvements with alternative interpolation algorithms.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T09:13:18Z"}
{"aid":"http://arxiv.org/abs/2504.01532v1","title":"Incorporating Coupling Knowledge into Echo State Networks for Learning\n  Spatiotemporally Chaotic Dynamics","summary":"Machine learning methods have shown promise in learning chaotic dynamical\nsystems, enabling model-free short-term prediction and attractor\nreconstruction. However, when applied to large-scale, spatiotemporally chaotic\nsystems, purely data-driven machine learning methods often suffer from\ninefficiencies, as they require a large learning model size and a massive\namount of training data to achieve acceptable performance. To address this\nchallenge, we incorporate the spatial coupling structure of the target system\nas an inductive bias in the network design. Specifically, we introduce\nphysics-guided clustered echo state networks, leveraging the efficiency of the\necho state networks as a base model. Experimental results on benchmark chaotic\nsystems demonstrate that our physics-informed method outperforms existing echo\nstate network models in learning the target chaotic systems. Additionally, our\nmodels exhibit robustness to noise in training data and remain effective even\nwhen prior coupling knowledge is imperfect. This approach has the potential to\nenhance other machine learning methods.","main_category":"nlin.CD","categories":"nlin.CD,cs.LG","published":"2025-04-02T09:19:33Z"}
{"aid":"http://arxiv.org/abs/2504.01533v1","title":"LightDefense: A Lightweight Uncertainty-Driven Defense against\n  Jailbreaks via Shifted Token Distribution","summary":"Large Language Models (LLMs) face threats from jailbreak prompts. Existing\nmethods for defending against jailbreak attacks are primarily based on\nauxiliary models. These strategies, however, often require extensive data\ncollection or training. We propose LightDefense, a lightweight defense\nmechanism targeted at white-box models, which utilizes a safety-oriented\ndirection to adjust the probabilities of tokens in the vocabulary, making\nsafety disclaimers appear among the top tokens after sorting tokens by\nprobability in descending order. We further innovatively leverage LLM's\nuncertainty about prompts to measure their harmfulness and adaptively adjust\ndefense strength, effectively balancing safety and helpfulness. The\neffectiveness of LightDefense in defending against 5 attack methods across 2\ntarget LLMs, without compromising helpfulness to benign user queries,\nhighlights its potential as a novel and lightweight defense mechanism,\nenhancing security of LLMs.","main_category":"cs.CR","categories":"cs.CR,cs.CY","published":"2025-04-02T09:21:26Z"}
{"aid":"http://arxiv.org/abs/2504.01535v1","title":"On Robust Empirical Likelihood for Nonparametric Regression with\n  Application to Regression Discontinuity Designs","summary":"Empirical likelihood serves as a powerful tool for constructing confidence\nintervals in nonparametric regression and regression discontinuity designs\n(RDD). The original empirical likelihood framework can be naturally extended to\nthese settings using local linear smoothers, with Wilks' theorem holding only\nwhen an undersmoothed bandwidth is selected. However, the generalization of\nbias-corrected versions of empirical likelihood under more realistic conditions\nis non-trivial and has remained an open challenge in the literature. This paper\nprovides a satisfactory solution by proposing a novel approach, referred to as\nrobust empirical likelihood, designed for nonparametric regression and RDD. The\ncore idea is to construct robust weights which simultaneously achieve bias\ncorrection and account for the additional variability introduced by the\nestimated bias, thereby enabling valid confidence interval construction without\nextra estimation steps involved. We demonstrate that the Wilks' phenomenon\nstill holds under weaker conditions in nonparametric regression, sharp and\nfuzzy RDD settings. Extensive simulation studies confirm the effectiveness of\nour proposed approach, showing superior performance over existing methods in\nterms of coverage probabilities and interval lengths. Moreover, the proposed\nprocedure exhibits robustness to bandwidth selection, making it a flexible and\nreliable tool for empirical analyses. The practical usefulness is further\nillustrated through applications to two real datasets.","main_category":"math.ST","categories":"math.ST,econ.EM,stat.ME,stat.TH","published":"2025-04-02T09:22:18Z"}
{"aid":"http://arxiv.org/abs/2504.01541v1","title":"Hyperbolic Diffusion Recommender Model","summary":"Diffusion models (DMs) have emerged as the new state-of-the-art family of\ndeep generative models. To gain deeper insights into the limitations of\ndiffusion models in recommender systems, we investigate the fundamental\nstructural disparities between images and items. Consequently, items often\nexhibit distinct anisotropic and directional structures that are less prevalent\nin images. However, the traditional forward diffusion process continuously adds\nisotropic Gaussian noise, causing anisotropic signals to degrade into noise,\nwhich impairs the semantically meaningful representations in recommender\nsystems.\n  Inspired by the advancements in hyperbolic spaces, we propose a novel\n\\textit{\\textbf{H}yperbolic} \\textit{\\textbf{D}iffusion}\n\\textit{\\textbf{R}ecommender} \\textit{\\textbf{M}odel} (named HDRM). Unlike\nexisting directional diffusion methods based on Euclidean space, the intrinsic\nnon-Euclidean structure of hyperbolic space makes it particularly well-adapted\nfor handling anisotropic diffusion processes. In particular, we begin by\nformulating concepts to characterize latent directed diffusion processes within\na geometrically grounded hyperbolic space. Subsequently, we propose a novel\nhyperbolic latent diffusion process specifically tailored for users and items.\nDrawing upon the natural geometric attributes of hyperbolic spaces, we impose\nstructural restrictions on the space to enhance hyperbolic diffusion\npropagation, thereby ensuring the preservation of the intrinsic topology of\nuser-item graphs. Extensive experiments on three benchmark datasets demonstrate\nthe effectiveness of HDRM.","main_category":"cs.IR","categories":"cs.IR,cs.AI","published":"2025-04-02T09:27:40Z"}
{"aid":"http://arxiv.org/abs/2504.01546v1","title":"From indirect to direct taxis by fast reaction limit","summary":"Many ecological population models consider taxis as the directed movement of\nanimals in response to a stimulus. The taxis is named direct if the animals are\nguided by the density gradient of some other population or indirect if they are\nguided by the density of a chemical secreted by individuals of the other\npopulation. Let $u$ and $v$ denote the densities of two populations and $w$ the\ndensity of the chemical secreted by individuals in the $v$ population. We\nconsider a bounded, open set $\\Omega \\subset \\mathbb{R}^N$ with regular\nboundary and prove that for the space dimension $N\\leq 2$ the solution to the\nLotka-Volterra competition model with repulsive indirect taxis and homogeneous\nNeumann boundary conditions\n  $$u_t - d_u\\Delta u = \\chi \\nabla \\cdot u \\nabla w +\\mu_1u(1-u-a_1v)\\,,$$\n  $$ v_t - d_v\\Delta v = \\mu_2v(1-v-a_2u)\\,,$$\n  $$\\varepsilon ( w_t - d_w\\Delta w )= v- w\\, , $$ converges to the solution of\nrepulsive direct-taxis model: $$ u_t - d_u\\Delta u = \\chi \\nabla \\cdot u \\nabla\nv +\\mu_1u(1-u-a_1v)\\,,$$ $$ v_t - d_v\\Delta v = \\mu_2v(1-v-a_2u)\\,$$ when\n$\\varepsilon\\longrightarrow 0$. For space dimension $N\\geq 3$ we use the\ncompactness argument to show that the result holds in some weak sense. A\nsimilar result is also proved for a typical prey-predator model with prey taxis\nand logistic growth of predators.","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T09:40:34Z"}
{"aid":"http://arxiv.org/abs/2504.01558v1","title":"Scalable Equivalence Checking and Verification of Shallow Quantum\n  Circuits","summary":"This paper concerns the problem of checking if two shallow (i.e.,\nconstant-depth) quantum circuits perform equivalent computations. Equivalence\nchecking is a fundamental correctness question -- needed, e.g., for ensuring\nthat transformations applied to a quantum circuit do not alter its behavior.\nFor quantum circuits, the problem is challenging because a straightforward\nrepresentation on a classical computer of each circuit's quantum state can\nrequire time and space that are exponential in the number of qubits $n$.\n  The paper presents decision procedures for two variants of the\nequivalence-checking problem. Both can be carried out on a classical computer\nin time and space that, for any fixed depth, is linear in $n$. Our critical\ninsight is that local projections are precise enough to completely characterize\nthe output state of a shallow quantum circuit. Instead of explicitly computing\nthe output state of a circuit, we generate a set of local projections that\nserve as constraints on the output state. Moreover, the circuit's output state\nis the unique quantum state that satisfies all the constraints.\n  Beyond equivalence checking, we show how to use the constraint representation\nto check a class of assertions, both statically and at run time. Our\nassertion-checking methods are sound and complete for assertions expressed as\nconjunctions of local projections.\n  Our experiments show that on a server equipped with 2 x\nIntel\\textsuperscript{\\textregistered} Xeon\\textsuperscript{\\textregistered}\nGold 6338 CPUs (128 threads total) and 1.0~TiB of RAM, running Ubuntu 20.04.6\nLTS, the constraint representation of a random 100-qubit circuit of depth 6 can\nbe computed in 19.8 seconds. For fixed inputs $\\ket{0}^{\\otimes 100}$,\nequivalence checking of {random} 100-qubit circuits of depth 3 takes 4.46\nseconds; for arbitrary inputs, it takes no more than 31.96 seconds.","main_category":"quant-ph","categories":"quant-ph,cs.PL","published":"2025-04-02T09:58:45Z"}
{"aid":"http://arxiv.org/abs/2504.01565v1","title":"Learning and criticality in a self-organizing model of connectome growth","summary":"The exploration of brain networks has reached an important milestone as\nrelatively large and reliable information has been gathered for connectomes of\ndifferent species. Analyses of connectome data sets reveal that the structural\nlength and the distributions of in- and out-node strengths follow heavy-tailed\nlognormal statistics, while the functional network properties exhibit powerlaw\ntails, suggesting that the brain operates close to a critical point where\ncomputational capabilities and sensitivity to stimulus is optimal. Because\nthese universal network features emerge from bottom-up (self-)organization, one\ncan pose the question of whether they can be modeled via a common framework,\nparticularly through the lens of criticality of statistical physical systems.\nHere, we simultaneously reproduce the powerlaw statistics of connectome edge\nweights and the lognormal distributions of node strengths from an\navalanche-type model with learning that operates on baseline networks that\nmimic the neuronal circuitry. We observe that the avalanches created by a\nsandpile-like model on simulated neurons connected by a hierarchical modular\nnetwork (HMN) produce robust powerlaw avalanche size distributions with\ncritical exponents of 3/2 characteristic of neuronal systems. Introducing\nHebbian learning, wherein neurons that `fire together, wire together,' recovers\nthe powerlaw distribution of edge weights and the lognormal distributions of\nnode degrees, comparable to those obtained from connectome data. Our results\nstrengthen the notion of a critical brain, one whose local interactions drive\nconnectivity and learning without a need for external intervention and precise\ntuning.","main_category":"physics.bio-ph","categories":"physics.bio-ph,cond-mat.dis-nn,cond-mat.stat-mech","published":"2025-04-02T10:07:43Z"}
{"aid":"http://arxiv.org/abs/2504.01570v1","title":"Density estimation via mixture discrepancy and moments","summary":"With the aim of generalizing histogram statistics to higher dimensional\ncases, density estimation via discrepancy based sequential partition (DSP) has\nbeen proposed [D. Li, K. Yang, W. Wong, Advances in Neural Information\nProcessing Systems (2016) 1099-1107] to learn an adaptive piecewise constant\napproximation defined on a binary sequential partition of the underlying\ndomain, where the star discrepancy is adopted to measure the uniformity of\nparticle distribution. However, the calculation of the star discrepancy is\nNP-hard and it does not satisfy the reflection invariance and rotation\ninvariance either. To this end, we use the mixture discrepancy and the\ncomparison of moments as a replacement of the star discrepancy, leading to the\ndensity estimation via mixture discrepancy based sequential partition (DSP-mix)\nand density estimation via moments based sequential partition (MSP),\nrespectively. Both DSP-mix and MSP are computationally tractable and exhibit\nthe reflection and rotation invariance. Numerical experiments in reconstructing\nthe $d$-D mixture of Gaussians and Betas with $d=2, 3, \\dots, 6$ demonstrate\nthat DSP-mix and MSP both run approximately ten times faster than DSP while\nmaintaining the same accuracy.","main_category":"stat.ML","categories":"stat.ML,cs.LG,physics.comp-ph,stat.ME","published":"2025-04-02T10:15:03Z"}
{"aid":"http://arxiv.org/abs/2504.01571v1","title":"Pro-DG: Procedural Diffusion Guidance for Architectural Facade\n  Generation","summary":"We present Pro-DG, a framework for procedurally controllable photo-realistic\nfacade generation that combines a procedural shape grammar with diffusion-based\nimage synthesis. Starting from a single input image, we reconstruct its facade\nlayout using grammar rules, then edit that structure through user-defined\ntransformations. As facades are inherently multi-hierarchical structures, we\nintroduce hierarchical matching procedure that aligns facade structures at\ndifferent levels which is used to introduce control maps to guide a generative\ndiffusion pipeline. This approach retains local appearance fidelity while\naccommodating large-scale edits such as floor duplication or window\nrearrangement. We provide a thorough evaluation, comparing Pro-DG against\ninpainting-based baselines and synthetic ground truths. Our user study and\nquantitative measurements indicate improved preservation of architectural\nidentity and higher edit accuracy. Our novel method is the first to integrate\nneuro-symbolically derived shape-grammars for modeling with modern generative\nmodel and highlights the broader potential of such approaches for precise and\ncontrollable image manipulation.","main_category":"cs.GR","categories":"cs.GR,cs.AI,cs.CV,cs.LG","published":"2025-04-02T10:16:19Z"}
{"aid":"http://arxiv.org/abs/2504.01582v1","title":"MERE: Hardware-Software Co-Design for Masking Cache Miss Latency in\n  Embedded Processors","summary":"Runahead execution is a technique to mask memory latency caused by irregular\nmemory accesses. By pre-executing the application code during occurrences of\nlong-latency operations and prefetching anticipated cache-missed data into the\ncache hierarchy, runahead effectively masks memory latency for subsequent cache\nmisses and achieves high prefetching accuracy; however, this technique has been\nlimited to superscalar out-of-order and superscalar in-order cores. For\nimplementation in scalar in-order cores, the challenges of\narea-/energy-constraint and severe cache contention remain.\n  Here, we build the first full-stack system featuring runahead, MERE, from SoC\nand a dedicated ISA to the OS and programming model. Through this deployment,\nwe show that enabling runahead in scalar in-order cores is possible, with\nminimal area and power overheads, while still achieving high performance. By\nre-constructing the sequential runahead employing a hardware/software co-design\napproach, the system can be implemented on a mature processor and SoC. Building\non this, an adaptive runahead mechanism is proposed to mitigate the severe\ncache contention in scalar in-order cores. Combining this, we provide a\ncomprehensive solution for embedded processors managing irregular workloads.\nOur evaluation demonstrates that the proposed MERE attains 93.5% of a 2-wide\nout-of-order core's performance while constraining area and power overheads\nbelow 5%, with the adaptive runahead mechanism delivering an additional 20.1%\nperformance gain through mitigating the severe cache contention issues.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-02T10:38:25Z"}
{"aid":"http://arxiv.org/abs/2504.01585v1","title":"Nonlinear Bandwidth and Bode Diagrams based on Scaled Relative Graphs","summary":"Scaled Relative Graphs (SRGs) provide a novel graphical frequency domain\nmethod for the analysis of nonlinear systems. In this paper, we use the\nrestriction of the SRG to particular input spaces to compute\nfrequency-dependent gain bounds for incrementally stable nonlinear systems.\nThis leads to a nonlinear (NL) generalization of the Bode diagram, where the\nsinusoidal, harmonic, and subharmonic inputs are considered separately. When\napplied to the analysis of the NL loop transfer and sensitivity, we define a\nnotion of bandwidth for both the open-loop and closed-loop, compatible with the\nLTI definitions. We illustrate the power of our method on the analysis of a DC\nmotor with a parasitic nonlinearity, verifying our results in simulations.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-02T10:41:49Z"}
{"aid":"http://arxiv.org/abs/2504.01595v1","title":"JWST MIRI reveals the diversity of nuclear mid-infrared spectra of\n  nearby type-2 quasars","summary":"Type-2 quasars (QSO2s) are active galactic nuclei (AGN) seen through a\nsignificant amount of dust and gas that obscures the central supermassive black\nhole and the broad line region. Here we present new mid-infrared spectra of the\ncentral kiloparsec of five optically-selected QSO2s at redshift z~0.1 obtained\nwith JWST/MIRI/MRS. These QSO2s belong to the QSOFEED sample and they have log\nLbol=45.5-46.0 erg/s, global SFRs that place them above the main sequence, and\npractically identical optical spectral shape and [OIII] luminosity, but their\nnuclear mid-infrared spectra exhibit an unexpected diversity of both continua\nand features. They show: 1) 9.7 micron silicate features going from emission\n(strength of S9.7=0.5) to relatively strong absorption (S9.7=-1.0) and 18 and\n23 micron silicates either in emission or flat. In addition, two of the QSO2s\nshow absorption bands of CO, H2O, and aliphatic grains, indicating different\nlevels of nuclear obscuration across the sample. 2) [NeV]/[NeII] ratios ranging\nfrom 0.1 to 2.1 and [NeIII]/[NeII] from 1.0 to 3.5, indicating different\ncoronal line and ionizing continuum strengths. 3) Warm molecular gas masses of\n1-4x10^7 Msun and warm-to-cold gas mass ratios of 1-2%, with molecular gas\nexcitation likely due to jet-induced shocks in J1430+1339, and to UV heating\nand/or turbulence in J1509+0434. 4) PAH emission features with equivalent\nwidths ranging from <0.002 to 0.075 micron, from which we measure a larger\ncontribution from neutral molecules (PAH 11.3/6.2=1.3-3.4) and SFRs<3-7\nMsun/yr. This unprecedented dataset allowed us to start exploring the role of\nvarious AGN and galaxy properties including ionizing continuum, obscuration,\nelectron density, and jet-ISM interactions on some of the spectral differences\nlisted above, but larger samples are now required to fully understand the\ndiversity of QSO2s' nuclear mid-infrared spectra.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-02T11:02:01Z"}
{"aid":"http://arxiv.org/abs/2504.01606v1","title":"Vers une modÃ©lisation de la confiance dans le renseignement sur les\n  menaces cyber","summary":"Cyber threat intelligence (CTI) is essential for effective system defense.\nCTI is a collection of information about current or past threats to a computer\nsystem. This information is gathered by an agent through observation, or based\non a set of sources. Building intelligence only makes sense if you have\nconfidence in it. To achieve this, it is necessary to estimate the confidence\nin each piece of information gathered, taking into account the different\ndimensions that can make it up: reliability of the source, competence,\nplausibility of the information, credibility of the information, for example.\nThe information gathered must then be combined with other information to\nconsolidate an agent's knowledge. Recent advances have been made in the theory\nunderlying the modeling of trust for decision-making based on uncertain\ninformation, notably by using multivalued logic. This approach makes it\npossible to deal with unknown values of trust-building parameters, or to easily\nintegrate dimensions. In this article we present the problem of CTI and CTI\ninformation sharing, and the reasons that led us to use a logic-based solution\nfor an initial implementation.","main_category":"cs.CR","categories":"cs.CR,cs.LO","published":"2025-04-02T11:17:26Z"}
{"aid":"http://arxiv.org/abs/2504.01629v1","title":"A 0.3\\% calibration of the W UMa-type contact binary luminosity based on\n  Gaia DR3","summary":"W Ursa Majoris (W UMa)-type contact binary systems (CBs) with\nperiod--luminosity (PL) relations are valuable distance indicators. The PL\nrelations of CBs are affected by metallicity. Here, we establish PL relations\nand period--luminosity--metallicity (PLZ) relations in nine bands from optical\nto mid-infrared ($BP$, $G$, $RP$, $J$, $H$, $K_S$, $W1$, $W2$, $W3$) and in\nfive Wesenheit bands based on Gaia DR3 parallaxes. The dispersion of PLZ\nrelations gradually decreases from the optical to mid-infrared bands, with the\nminimum dispersion of 0.138 mag. We fit the best PL relations for three bands\n($W1$, $W_{G,BP,RP}$, $W_{W1,BP,RP}$) under different parallax uncertainty\ncriteria and determine a parallax (after correction) zero point of\n$zp_\\varpi=24\\pm4$ $\\mu$as. After fixing the parallax zero point, we find that\nthe total zero errors of the PL and PLZ relation are smallest when the parallax\nuncertainty is less than 2\\%, resulting in a calibrated CB luminosity with an\naccuracy of 0.33\\%, which is more accurate than the classical Cepheids.\nFurthermore, by examining the absolute magnitude residuals in different\nmetallicity intervals, we find that the use of a linear metallicity effect is\nappropriate for CBs with different metallicities. These results indicate that\nCBs are excellent standard candles.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-02T11:36:46Z"}
{"aid":"http://arxiv.org/abs/2504.01630v1","title":"On the performance of the Euler-Maruyama scheme for multidimensional\n  SDEs with discontinuous drift coefficient","summary":"We study strong approximation of $d$-dimensional stochastic differential\nequations (SDEs) with a discontinuous drift coefficient. More precisely, we\nessentially assume that the drift coefficient is piecewise Lipschitz continuous\nwith an exceptional set $\\Theta\\subset \\mathbb{R}^d$ that is an orientable\n$C^4$-hypersurface of positive reach, the diffusion coefficient is assumed to\nbe Lipschitz continuous and, in a neighborhood of $\\Theta$, both coefficients\nare bounded and the diffusion coefficient has a non-degenerate portion\northogonal to $\\Theta$.\n  In recent years, a number of results have been proven in the literature for\nstrong approximation of such SDEs and, in particular, the performance of the\nEuler-Maruyama scheme was studied. For $d=1$ and finite $\\Theta$ it was shown\nthat the Euler-Maruyama scheme achieves an $L_p$-error rate of at least $1/2$\nfor all $p\\geq 1$ as in the classical case of Lipschitz continuous\ncoefficients. For $d>1$, it was only known so far, that the Euler-Maruyama\nscheme achieves an $L_2$-error rate of at least $1/4-$ if, additionally, the\ncoefficients $\\mu$ and $\\sigma$ are globally bounded.\n  In this article, we prove that in the above setting the Euler-Maruyama scheme\nin fact achieves an $L_{p}$-error rate of at least $1/2-$ for all\n$d\\in\\mathbb{N}$ and all $p\\geq 1$. The proof of this result is based on the\nwell-known approach of transforming such an SDE into an SDE with globally\nLipschitz continuous coefficients, a new It\\^{o} formula for a class of\nfunctions which are not globally $C^2$ and a detailed analysis of the expected\ntotal time that the actual position of the time-continuous Euler-Maruyama\nscheme and its position at the preceding time point on the underlying grid are\non 'different sides' of the hypersurface $\\Theta$.","main_category":"math.NA","categories":"math.NA,cs.NA,math.PR","published":"2025-04-02T11:37:06Z"}
{"aid":"http://arxiv.org/abs/2504.01635v1","title":"Control of Andreev Reflection via a Single-Molecule Orbital","summary":"Charge transport across a single-molecule junction fabricated from a\nnormal-metal tip, a phthalocyanine, and a conventional superconductor in a\nscanning tunneling microscope is explored as a function of the gradually closed\nvacuum gap. The phthalocyanine (2H-Pc) molecule and its\npyrrolichydrogen-abstracted derivative (Pc) exhibit vastly different behavior.\nAndreev reflection across the 2H-Pc contact exhibits a temporary enhancement\nthat diminishes with increasing conductance. The hybridization of 2H-Pc with\nthe tip at contact formation gives rise to a Kondo-screened molecular magnetic\nmoment. In contrast, the single-Pc junction lacks Andreev reflection in the\nsame conductance range. Spectroscopies and supporting nonequilibrium Green\nfunction calculations highlight the importance of a molecular orbital close to\nthe Fermi energy for Andreev reflection.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.supr-con","published":"2025-04-02T11:40:55Z"}
{"aid":"http://arxiv.org/abs/2504.01636v1","title":"Dataset and Methodology for Material Identification and virtual s-SNOM\n  Using AFM Phase Approach Curves","summary":"Atomic force microscopy (AFM) phase approach-curves have significant\npotential for nanoscale material characterization, however, the availability of\nrobust datasets and automated analysis tools has been limited. In this paper,\nwe introduce a novel methodology for material identification using a\nhigh-dimensional dataset consisting of AFM phase approach-curves collected from\nfive distinct materials: silicon, silicon dioxide, platinum, silver, and gold.\nEach measurement comprises 50 phase values obtained at progressively increasing\ntip-sample distances, resulting in 50x50x50 voxel images that represent phase\nvariations at different depths. Using this dataset, we compare k-nearest\nneighbors (KNN), random forest (RF), and feedforward neural network (FNN)\nmethods for material segmentation. Our results indicate that the FNN provides\nthe highest accuracy and F1 score, outperforming more traditional approaches.\nFinally, we demonstrate the practical value of these segmented maps by\ngenerating virtual scattering-type scanning near-field optical microscopy\n(s-SNOM) images, highlighting how AFM phase approach-curves can be leveraged to\nproduce detailed, predictive tools for nanoscale optical analysis.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-02T11:42:03Z"}
{"aid":"http://arxiv.org/abs/2504.01637v1","title":"LLM-mediated Dynamic Plan Generation with a Multi-Agent Approach","summary":"Planning methods with high adaptability to dynamic environments are crucial\nfor the development of autonomous and versatile robots. We propose a method for\nleveraging a large language model (GPT-4o) to automatically generate networks\ncapable of adapting to dynamic environments. The proposed method collects\nenvironmental \"status,\" representing conditions and goals, and uses them to\ngenerate agents. These agents are interconnected on the basis of specific\nconditions, resulting in networks that combine flexibility and generality. We\nconducted evaluation experiments to compare the networks automatically\ngenerated with the proposed method with manually constructed ones, confirming\nthe comprehensiveness of the proposed method's networks and their higher\ngenerality. This research marks a significant advancement toward the\ndevelopment of versatile planning methods applicable to robotics, autonomous\nvehicles, smart systems, and other complex environments.","main_category":"cs.AI","categories":"cs.AI,cs.RO","published":"2025-04-02T11:42:49Z"}
{"aid":"http://arxiv.org/abs/2504.01638v1","title":"Convex Computations for Controlled Safety Invariant Sets of Black-box\n  Discrete-time Dynamical Systems","summary":"Identifying controlled safety invariant sets (CSISs) is essential in\nsafety-critical applications. This paper tackles the problem of identifying\nCSISs for black-box discrete-time systems, where the model is unknown and only\nlimited simulation data is accessible. Traditionally, a CSIS is defined as a\nsubset of a safe set, encompassing initial states for which a control input\nexists that keeps the system within the set at the next time step-this is\nreferred to as the one-step invariance property. However, the requirement for\none-step invariance can be equivalently translated into a stricter condition of\n``always-invariance'', meaning that there exist control inputs capable of\nkeeping the system within this set indefinitely. Such a condition may prove\noverly stringent or impractical for black-box systems, where predictions can\nbecome unreliable beyond a single time step or a limited number of finite time\nsteps. To overcome the challenges posed by black-box systems, we reformulate\nthe one-step invariance property in a ``Probably Approximately Correct'' (PAC)\nsense. This approach allows us to assess the probability that a control input\nexists to keep the system within the CSIS at the next time step, with a\npredefined level of confidence. If the system successfully remains within the\nset at the next time step, we can then reapply the invariance evaluation to the\nnew state, thereby facilitating a recursive assurance of invariance. Our method\nemploys barrier functions and scenario optimization, resulting in a linear\nprogramming method to estimate PAC CSISs. Finally, the effectiveness of our\napproach is demonstrated on several examples.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-02T11:43:03Z"}
{"aid":"http://arxiv.org/abs/2504.01645v1","title":"How to write competitive proposals and job applications","summary":"Writing proposals and job applications is arguably one of the most important\ntasks in the career of a scientist. The proposed ideas must be scientifically\ncompelling, but how a proposal is planned, written, and presented can make an\nenormous difference. This Perspective is the third in a series aimed at\ntraining the writing skills of professional astronomers. In the first two\npapers we concentrated on the writing of papers, here we concentrate on how\nproposals and job applications can be optimally written and presented. We\ndiscuss how to select where to propose or apply, how to optimise your writing,\nand add notes on the potential use of artificial intelligence tools. This guide\nis aimed primarily at more junior researchers, but we hope that our\nobservations and suggestions may also be helpful for more experienced\napplicants, as well as for reviewers and funding agencies.","main_category":"astro-ph.IM","categories":"astro-ph.IM,physics.ed-ph","published":"2025-04-02T11:53:45Z"}
{"aid":"http://arxiv.org/abs/2504.01651v1","title":"Nonlinear electrodynamic black holes and their role in testing modified\n  theories of gravity","summary":"The nature of black holes (BHs) and potential deviations from General\nRelativity (GR) remain key questions in astrophysics. Nonlinear electrodynamics\n(NED) offers a mechanism for constructing regular BHs that evade singularities.\nWe perform a geometrical and observational analysis of NED-inspired BHs,\nconstraining the magnetic parameter via Bayesian inference using EHT data,\nobtaining \\( q = 0.98^{+0.09}_{-0.08} \\) for M87* and \\( q = 1.10\\pm0.10 \\) for\nSgr A*. Deviations from Schwarzschild BHs manifest in horizon structure, shadow\nproperties, and lensing effects. We analyze BH shadows under plasma conditions,\nidentifying imprints of NED on strong-field processes. Future observations from\nLISA, next-generation X-ray telescopes, and EHT will further constrain these\ndeviations and provide tests for alternative gravity theories.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-02T12:00:35Z"}
{"aid":"http://arxiv.org/abs/2504.01655v1","title":"Q-Adapt: Adapting LMM for Visual Quality Assessment with Progressive\n  Instruction Tuning","summary":"The rapid advancement of Large Multi-modal Foundation Models (LMM) has paved\nthe way for the possible Explainable Image Quality Assessment (EIQA) with\ninstruction tuning from two perspectives: overall quality explanation, and\nattribute-wise perception answering. However, existing works usually overlooked\nthe conflicts between these two types of perception explanations during joint\ninstruction tuning, leading to insufficient perception understanding. To\nmitigate this, we propose a new paradigm for perception-oriented instruction\ntuning, i.e., Q-Adapt, which aims to eliminate the conflicts and achieve the\nsynergy between these two EIQA tasks when adapting LMM, resulting in enhanced\nmulti-faceted explanations of IQA. Particularly, we propose a progressive\ninstruction tuning strategy by dividing the adaption process of LMM for EIQA\ninto two stages, where the first stage empowers the LMM with universal\nperception knowledge tailored for two tasks using an efficient transfer\nlearning strategy, i.e., LoRA, and the second stage introduces the\ninstruction-adaptive visual prompt tuning to dynamically adapt visual features\nfor the different instructions from two tasks. In this way, our proposed\nQ-Adapt can achieve a lightweight visual quality evaluator, demonstrating\ncomparable performance and, in some instances, superior results across\nperceptual-related benchmarks and commonly-used IQA databases. The source code\nis publicly available at https://github.com/yeppp27/Q-Adapt.","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-02T12:02:57Z"}
{"aid":"http://arxiv.org/abs/2504.01660v1","title":"STRAUSS: Sonification Tools & Resources for Analysis Using Sound\n  Synthesis","summary":"Sonification, or conveying data using non-verbal audio, is a relatively niche\nbut growing approach for presenting data across multiple specialist domains\nincluding astronomy, climate science, and beyond. The STRAUSS Python package\naims to provide such a tool, which builds upon previous approaches to provide a\npowerful means to explore different ways of expressing data, with fine control\nover the output audio and its format. STRAUSS is a free, open source (FOSS)\npackage, designed to allow flexible and effective sonification to be integrated\ninto data workflows, in analogy to widely used visualisation packages. The\nremit of STRAUSS is broad; it is intended to be able to bridge between ad-hoc\nsolutions for sonifying very particular datasets, and highly technical\ncompositional and sound-design tools that are not optimised for sonification,\nor may have a steep learning curve. The code offers a range of approaches to\nsonification for a variety of contexts (e.g. science education, science\ncommunication, technical data analysis, etc). To this end, STRAUSS is packaged\nwith a number of examples of different sonification approaches, and preset\nconfigurations to support \"low-barrier, high-ceiling\" approach. STRAUSS has\nbeen used to produce both educational resources and analysis tools.","main_category":"astro-ph.IM","categories":"astro-ph.IM,physics.data-an","published":"2025-04-02T12:12:30Z"}
{"aid":"http://arxiv.org/abs/2504.01664v1","title":"Preparation of conditionally-squeezed states in qubit-oscillator systems","summary":"Inspired by recent advances in the manipulation of superconducting circuits\ncoupled to mechanical modes in the quantum regime, we propose a protocol for\ngenerating superpositions of orthogonally squeezed states in a quantum harmonic\noscillator. The protocol relies on a quadratic coupling between the oscillator\nand a qubit, and is conceptually similar to methods used for preparing cat\nstates in qubit-oscillator systems. We numerically evaluate the robustness of\nthe state-preparation scheme in the presence of decoherence, considering\nenvironmental coupling for both the harmonic oscillator and the qubit. As a\npotential application, we introduce a quantum error-correcting code based on\nconditionally-squeezed states and analyze its error-mitigation properties.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T12:15:08Z"}
{"aid":"http://arxiv.org/abs/2504.01667v1","title":"Testing Low-Resource Language Support in LLMs Using Language Proficiency\n  Exams: the Case of Luxembourgish","summary":"Large Language Models (LLMs) have become an increasingly important tool in\nresearch and society at large. While LLMs are regularly used all over the world\nby experts and lay-people alike, they are predominantly developed with\nEnglish-speaking users in mind, performing well in English and other\nwide-spread languages while less-resourced languages such as Luxembourgish are\nseen as a lower priority. This lack of attention is also reflected in the\nsparsity of available evaluation tools and datasets. In this study, we\ninvestigate the viability of language proficiency exams as such evaluation\ntools for the Luxembourgish language. We find that large models such as\nChatGPT, Claude and DeepSeek-R1 typically achieve high scores, while smaller\nmodels show weak performances. We also find that the performances in such\nlanguage exams can be used to predict performances in other NLP tasks.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T12:16:14Z"}
{"aid":"http://arxiv.org/abs/2504.01670v1","title":"Introduction to dimensional reduction of fermions","summary":"We present a comprehensive pedagogical introduction to the dimensional\nreduction protocol (DRP), a versatile framework for analyzing instabilities and\ncritical points in interacting fermionic systems. The DRP simplifies the study\nof many-body problems by systematically reducing their effective spatial\ndimension while retaining essential physics. This method works for electron\ngases in a diverse array of settings: in any number of spatial dimensions, in\nthe presence of Zeeman fields, with spin-orbit coupling, including repulsive or\nattractive interactions. Focusing on two-point correlation functions, the DRP\nidentifies a minimal subspace relevant for capturing analytic properties,\nfacilitating efficient computation of critical phenomena in electronic systems.\nThis work outlines the assumptions, proof, and applications of the DRP,\nemphasizing its simplicity and broad applicability for future studies in\ncorrelated electron physics.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-02T12:17:49Z"}
{"aid":"http://arxiv.org/abs/2504.01676v1","title":"Satellite Edge Artificial Intelligence with Large Models: Architectures\n  and Technologies","summary":"Driven by the growing demand for intelligent remote sensing applications,\nlarge artificial intelligence (AI) models pre-trained on large-scale unlabeled\ndatasets and fine-tuned for downstream tasks have significantly improved\nlearning performance for various downstream tasks due to their generalization\ncapabilities. However, many specific downstream tasks, such as extreme weather\nnowcasting (e.g., downburst and tornado), disaster monitoring, and battlefield\nsurveillance, require real-time data processing. Traditional methods via\ntransferring raw data to ground stations for processing often cause significant\nissues in terms of latency and trustworthiness. To address these challenges,\nsatellite edge AI provides a paradigm shift from ground-based to on-board data\nprocessing by leveraging the integrated communication-and-computation\ncapabilities in space computing power networks (Space-CPN), thereby enhancing\nthe timeliness, effectiveness, and trustworthiness for remote sensing\ndownstream tasks. Moreover, satellite edge large AI model (LAM) involves both\nthe training (i.e., fine-tuning) and inference phases, where a key challenge\nlies in developing computation task decomposition principles to support\nscalable LAM deployment in resource-constrained space networks with\ntime-varying topologies. In this article, we first propose a satellite\nfederated fine-tuning architecture to split and deploy the modules of LAM over\nspace and ground networks for efficient LAM fine-tuning. We then introduce a\nmicroservice-empowered satellite edge LAM inference architecture that\nvirtualizes LAM components into lightweight microservices tailored for\nmulti-task multimodal inference. Finally, we discuss the future directions for\nenhancing the efficiency and scalability of satellite edge LAM, including\ntask-oriented communication, brain-inspired computing, and satellite edge AI\nnetwork optimization.","main_category":"cs.LG","categories":"cs.LG,cs.DC,cs.NI,eess.SP","published":"2025-04-02T12:25:57Z"}
{"aid":"http://arxiv.org/abs/2504.01682v1","title":"A result on certain sums of element orders in finite groups","summary":"Given a finite group $G$ of order $p^nm$, where $p$ is a prime and $p\\nmid\nm$, we denote by $\\psi_p(G)$ the sum of orders of $p$-parts of elements in $G$.\nIn the current note, we prove that $\\psi_p(G)\\leq\\psi_p(C_{p^nm})$, where\n$C_{p^nm}$ is the cyclic group of order $p^nm$, and the equality holds if and\nonly if $G$ is $p$-nilpotent of a particular type. A generalization of this\nresult is also presented.","main_category":"math.GR","categories":"math.GR","published":"2025-04-02T12:29:27Z"}
{"aid":"http://arxiv.org/abs/2504.01688v1","title":"Enhancing European Cooperation in the Search for Dark Matter","summary":"The search for dark matter is an exciting topic that is pursued in different\ncommunities over a wide range of masses and using a variety of experimental\napproaches. The result is a strongly correlated matrix of activities across\nEurope and beyond, both on the experimental and the theoretical side. We\nsuggest to encourage and foster the collaboration of the involved institutions\non technical, scientific and organisational level, in order to realise the\nsynergies that are required to increase the impact of dark matter research and\nto cope with the increasing experiment sizes. The suggested network -- loosely\ntitled \"DMInfraNet\" -- could be realised as a new initiative of the European\nstrategy or be based on existing structures like iDMEu or DRD. The network can\nalso serve as a nucleus for future joint funding proposals.","main_category":"hep-ex","categories":"hep-ex,hep-ph","published":"2025-04-02T12:36:28Z"}
{"aid":"http://arxiv.org/abs/2504.01689v1","title":"InvFussion: Bridging Supervised and Zero-shot Diffusion for Inverse\n  Problems","summary":"Diffusion Models have demonstrated remarkable capabilities in handling\ninverse problems, offering high-quality posterior-sampling-based solutions.\nDespite significant advances, a fundamental trade-off persists, regarding the\nway the conditioned synthesis is employed: Training-based methods achieve high\nquality results, while zero-shot approaches trade this with flexibility. This\nwork introduces a framework that combines the best of both worlds -- the strong\nperformance of supervised approaches and the flexibility of zero-shot methods.\nThis is achieved through a novel architectural design that seamlessly\nintegrates the degradation operator directly into the denoiser. In each block,\nour proposed architecture applies the degradation operator on the network\nactivations and conditions the output using the attention mechanism, enabling\nadaptation to diverse degradation scenarios while maintaining high performance.\nOur work demonstrates the versatility of the proposed architecture, operating\nas a general MMSE estimator, a posterior sampler, or a Neural Posterior\nPrincipal Component estimator. This flexibility enables a wide range of\ndownstream tasks, highlighting the broad applicability of our framework. The\nproposed modification of the denoiser network offers a versatile, accurate, and\ncomputationally efficient solution, demonstrating the advantages of dedicated\nnetwork architectures for complex inverse problems. Experimental results on the\nFFHQ and ImageNet datasets demonstrate state-of-the-art posterior-sampling\nperformance, surpassing both training-based and zero-shot alternatives.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T12:40:57Z"}
{"aid":"http://arxiv.org/abs/2504.01696v1","title":"On anticyclotomic Selmer groups of elliptic curves","summary":"Let $p\\geq5$ be a prime number and let $K$ be an imaginary quadratic field\nwhere $p$ is unramified. Under mild technical assumptions, in this paper we\nprove the non-existence of non-trivial finite $\\Lambda$-submodules of\nPontryagin duals of signed Selmer groups of a $p$-supersingular rational\nelliptic curve over the anticyclotomic $\\mathbb Z_p$-extension of $K$, where\n$\\Lambda$ is the corresponding Iwasawa algebra. In particular, we work under\nthe assumption that our plus/minus Selmer groups have $\\Lambda$-corank $1$, so\nthey are not $\\Lambda$-cotorsion. Our main theorem extends to the supersinular\ncase analogous non-existence results by Bertolini in the ordinary setting;\nfurthermore, since we cover the case where $p$ is inert in $K$, we refine\nprevious results of Hatley-Lei-Vigni, which deal with $p$-supersingular\nelliptic curves under the assumption that $p$ splits in $K$.","main_category":"math.NT","categories":"math.NT,math.AG","published":"2025-04-02T12:55:15Z"}
{"aid":"http://arxiv.org/abs/2504.01718v1","title":"A Novel Dynamic Epidemic Model for Successive Opinion Diffusion in\n  Social Networks","summary":"This paper proposes a dynamic epidemic model for successive opinion diffusion\nin social networks, extending the SHIMR model. It incorporates dynamic\ndecision-making influenced by social distances and captures accumulative\nopinion diffusion caused by interrelated rumors. The model reflects the impact\nof rumor spread on social network structures. Simulations validate its\neffectiveness in explaining phenomena like the echo chamber effect and provide\ninsights into opinion diffusion dynamics, with implications for understanding\nsocial polarization and network evolution.","main_category":"cs.SI","categories":"cs.SI","published":"2025-04-02T13:26:30Z"}
{"aid":"http://arxiv.org/abs/2504.01722v1","title":"{GSR4B}: Biomass Map Super-Resolution with Sentinel-1/2 Guidance","summary":"Accurate Above-Ground Biomass (AGB) mapping at both large scale and high\nspatio-temporal resolution is essential for applications ranging from climate\nmodeling to biodiversity assessment, and sustainable supply chain monitoring.\nAt present, fine-grained AGB mapping relies on costly airborne laser scanning\nacquisition campaigns usually limited to regional scales. Initiatives such as\nthe ESA CCI map attempt to generate global biomass products from diverse\nspaceborne sensors but at a coarser resolution. To enable global,\nhigh-resolution (HR) mapping, several works propose to regress AGB from HR\nsatellite observations such as ESA Sentinel-1/2 images. We propose a novel way\nto address HR AGB estimation, by leveraging both HR satellite observations and\nexisting low-resolution (LR) biomass products. We cast this problem as Guided\nSuper-Resolution (GSR), aiming at upsampling LR biomass maps (sources) from\n$100$ to $10$ m resolution, using auxiliary HR co-registered satellite images\n(guides). We compare super-resolving AGB maps with and without guidance,\nagainst direct regression from satellite images, on the public BioMassters\ndataset. We observe that Multi-Scale Guidance (MSG) outperforms direct\nregression both for regression ($-780$ t/ha RMSE) and perception ($+2.0$ dB\nPSNR) metrics, and better captures high-biomass values, without significant\ncomputational overhead. Interestingly, unlike the RGB+Depth setting they were\noriginally designed for, our best-performing AGB GSR approaches are those that\nmost preserve the guide image texture. Our results make a strong case for\nadopting the GSR framework for accurate HR biomass mapping at scale. Our code\nand model weights are made publicly available\n(https://github.com/kaankaramanofficial/GSR4B).","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T13:28:27Z"}
{"aid":"http://arxiv.org/abs/2504.01741v1","title":"Quantum Quintom Cosmology","summary":"This work applies the principles of quantum cosmology to examine models\nincorporating a quintom field. Specifically, three distinct models are\nanalyzed: a simplified toy model, a model featuring an exponential quintom\npotential, and one where the quintom field is coupled with a negative\ncosmological constant. For each case, we study the classical trajectories\nwithin the configuration space, present solutions to the Wheeler-DeWitt\nequation in quantum cosmology, and discuss physical interpretations and\nconsequences. A key focus is the behavior of wave packets in the minisuperspace\nframework. Notably, the correspondence principle (connection between classical\nand quantum solutions) is also demonstrated.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-02T13:52:26Z"}
{"aid":"http://arxiv.org/abs/2504.01746v1","title":"Spans of quantum-inequality projections","summary":"A hereditarily atomic von Neumann algebra $A$ is a $W^*$ product of matrix\nalgebras, regarded as the underlying function algebra of a quantum set.\nProjections in $A\\overline{\\otimes}A^{\\circ}$ are interpreted as quantum binary\nrelations on $A$, with the supremum of all $p\\otimes (1-p)$ representing\nquantum inequality. We prove that the symmetrized weak$^*$-closed linear span\nof all such quantum-inequality projections is precisely the symmetric summand\nof the joint kernel of multiplication and opposite multiplication, a result\nvalid without the symmetrization qualification for plain matrix algebras. The\nproof exploits the symmetries of the spaces involved under the compact unitary\ngroup of $A$, and related results include a classification of those von Neumann\nalgebras (hereditarily atomic or not) for which the unitary group operates\njointly continuously with respect to the weak$^*$ topology.","main_category":"math.OA","categories":"math.OA,math.FA,math.QA,math.RA,math.RT","published":"2025-04-02T13:57:34Z"}
{"aid":"http://arxiv.org/abs/2504.01750v1","title":"Probing the Distance Duality Relation with Machine Learning and Recent\n  Data","summary":"The distance duality relation (DDR) relates two independent ways of measuring\ncosmological distances, namely the angular diameter distance and the luminosity\ndistance. These can be measured with baryon acoustic oscillations (BAO) and\nType Ia supernovae (SNe Ia), respectively. Here, we use recent DESI DR1,\nPantheon+, SH0ES and DES-SN5YR data to test this fundamental relation. We\nemploy a parametrised approach and also use model-independent Generic\nAlgorithms (GA), which are a machine learning method where functions evolve\nloosely based on biological evolution. When we use DESI and Pantheon+ data\nwithout Cepheid calibration or big bang nucleosynthesis (BBN), there is a\n$2\\sigma$ violation of the DDR in the parametrised approach. Then, we add\nhigh-redshift BBN data and the low-redshift SH0ES Cepheid calibration. This\nreflects the Hubble tension since both data sets are in tension in the standard\ncosmological model $\\Lambda$CDM. In this case, we find a significant violation\nof the DDR in the parametrised case at $6\\sigma$. Replacing the Pantheon+ SNe\nIa data by DES-SN5YR, we find similar results. For the model-independent\napproach, we find no deviation in the uncalibrated case and a small deviation\nwith BBN and Cepheids which remains at 1$\\sigma$. This shows the importance of\nconsidering model-independent approaches for the DDR.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-02T14:02:12Z"}
{"aid":"http://arxiv.org/abs/2504.01755v1","title":"Bridge the Gap between SNN and ANN for Image Restoration","summary":"Models of dense prediction based on traditional Artificial Neural Networks\n(ANNs) require a lot of energy, especially for image restoration tasks.\nCurrently, neural networks based on the SNN (Spiking Neural Network) framework\nare beginning to make their mark in the field of image restoration, especially\nas they typically use less than 10\\% of the energy of ANNs with the same\narchitecture. However, training an SNN is much more expensive than training an\nANN, due to the use of the heuristic gradient descent strategy. In other words,\nthe process of SNN's potential membrane signal changing from sparse to dense is\nvery slow, which affects the convergence of the whole model.To tackle this\nproblem, we propose a novel distillation technique, called asymmetric framework\n(ANN-SNN) distillation, in which the teacher is an ANN and the student is an\nSNN. Specifically, we leverage the intermediate features (feature maps) learned\nby the ANN as hints to guide the training process of the SNN. This approach not\nonly accelerates the convergence of the SNN but also improves its final\nperformance, effectively bridging the gap between the efficiency of the SNN and\nthe superior learning capabilities of ANN. Extensive experimental results show\nthat our designed SNN-based image restoration model, which has only 1/300 the\nnumber of parameters of the teacher network and 1/50 the energy consumption of\nthe teacher network, is as good as the teacher network in some denoising tasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T14:12:06Z"}
{"aid":"http://arxiv.org/abs/2504.01759v1","title":"Hidden Markov Model Filtering with Equal Exit Probabilities","summary":"Hidden Markov Models (HMMs) provide a rigorous framework for inference in\ndynamic environments. In this work, we study the alpha-HMM algorithm motivated\nby the optimal online filtering formulation in settings where the true state\nevolves as a Markov chain with equal exit probabilities. We quantify the\ndynamics of the algorithm in stationary environments, revealing a trade-off\nbetween inference and adaptation, showing how key parameters and the quality of\nobservations affect performance. Comprehensive theoretical analysis on the\nnonlinear dynamical system that governs the evolution of the log-belief ratio\nover time and numerical experiments demonstrate that the proposed approach\neffectively balances adaptation and inference performance.","main_category":"eess.SY","categories":"eess.SY,cs.SY,stat.AP","published":"2025-04-02T14:16:13Z"}
{"aid":"http://arxiv.org/abs/2504.01761v1","title":"Non-parametric Quantile Regression and Uniform Inference with Unknown\n  Error Distribution","summary":"This paper studies the non-parametric estimation and uniform inference for\nthe conditional quantile regression function (CQRF) with covariates exposed to\nmeasurement errors. We consider the case that the distribution of the\nmeasurement error is unknown and allowed to be either ordinary or super smooth.\nWe estimate the density of the measurement error by the repeated measurements\nand propose the deconvolution kernel estimator for the CQRF. We derive the\nuniform Bahadur representation of the proposed estimator and construct the\nuniform confidence bands for the CQRF, uniformly in the sense for all\ncovariates and a set of quantile indices, and establish the theoretical\nvalidity of the proposed inference. A data-driven approach for selecting the\ntuning parameter is also included. Monte Carlo simulations and a real data\napplication demonstrate the usefulness of the proposed method.","main_category":"stat.ME","categories":"stat.ME,econ.EM","published":"2025-04-02T14:16:39Z"}
{"aid":"http://arxiv.org/abs/2504.01762v1","title":"A First-Order Linear Energy Stable Scheme for the Cahn-Hilliard Equation\n  with Dynamic Boundary Conditions under the Effect of Hyperbolic Relaxation","summary":"In this paper we focus on the Cahn-Hilliard equation with dynamic boundary\nconditions, by adding two hyperbolic relaxation terms to the system. We verify\nthat the energy of the total system is decreasing with time. By adding two\nstabilization terms, we have constructed a first-order temporal accuracy\nnumerical scheme, which is linear and energy stable. Then we prove that the\nscheme is of first-order in time by the error estimates. At last we carry out\nenough numerical results to validate the the temporal convergence and the\nenergy stability of such scheme. Moreover, we have present the differences of\nthe numerical results with and without the hyperbolic terms, which show that\nthe hyperbolic terms can help the total energy decreasing slowly.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-02T14:16:42Z"}
{"aid":"http://arxiv.org/abs/2504.01763v1","title":"Fully-gapped superconductivity with rotational symmetry breaking in\n  pressurized kagome metal CsV$_3$Sb$_5$","summary":"The discovery of the kagome metal CsV$_3$Sb$_5$ has generated significant\ninterest in its complex physical properties, particularly its superconducting\nbehavior under different pressures, though its nature remains debated. Here, we\nperformed low-temperature, high-pressure $^{121/123}$Sb nuclear quadrupole\nresonance (NQR) measurements to explore the superconducting pairing symmetry in\nCsV$_3$Sb$_5$. At ambient pressure, we found that the spin-lattice relaxation\nrate 1/$T_1$ exhibits a kink at $T \\sim$ 0.4 $T_\\textrm{c}$ within the\nsuperconducting state and follows a $T^3$ variation as temperature further\ndecreases. This suggests the presence of two superconducting gaps with line\nnodes in the smaller one. As pressure increases beyond $P_{\\rm c} \\sim 1.85$\nGPa, where the charge-density wave phase is completely suppressed, 1/$T_1$\nshows no Hebel-Slichter peak just below $T_\\textrm{c}$, and decreases rapidly,\neven faster than $T^5$, indicating that the gap is fully opened for pressures\nabove $P_{\\rm c}$. In this high pressure region, the angular dependence of the\nin-plane upper critical magnetic field $H_{\\rm c2}$ breaks the $C_6$ rotational\nsymmetry. We propose the $s+id$ pairing at $P > P_{\\rm c}$ which explains both\nthe 1/$T_1$ and $H_{\\rm c2}$ behaviors. Our findings indicate that\nCsV$_3$Sb$_5$ is an unconventional superconductor and its superconducting state\nis even more exotic at high pressures.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.str-el","published":"2025-04-02T14:17:47Z"}
{"aid":"http://arxiv.org/abs/2504.01764v1","title":"Dual-stream Transformer-GCN Model with Contextualized Representations\n  Learning for Monocular 3D Human Pose Estimation","summary":"This paper introduces a novel approach to monocular 3D human pose estimation\nusing contextualized representation learning with the Transformer-GCN\ndual-stream model. Monocular 3D human pose estimation is challenged by depth\nambiguity, limited 3D-labeled training data, imbalanced modeling, and\nrestricted model generalization. To address these limitations, our work\nintroduces a groundbreaking motion pre-training method based on contextualized\nrepresentation learning. Specifically, our method involves masking 2D pose\nfeatures and utilizing a Transformer-GCN dual-stream model to learn\nhigh-dimensional representations through a self-distillation setup. By focusing\non contextualized representation learning and spatial-temporal modeling, our\napproach enhances the model's ability to understand spatial-temporal\nrelationships between postures, resulting in superior generalization.\nFurthermore, leveraging the Transformer-GCN dual-stream model, our approach\neffectively balances global and local interactions in video pose estimation.\nThe model adaptively integrates information from both the Transformer and GCN\nstreams, where the GCN stream effectively learns local relationships between\nadjacent key points and frames, while the Transformer stream captures\ncomprehensive global spatial and temporal features. Our model achieves\nstate-of-the-art performance on two benchmark datasets, with an MPJPE of 38.0mm\nand P-MPJPE of 31.9mm on Human3.6M, and an MPJPE of 15.9mm on MPI-INF-3DHP.\nFurthermore, visual experiments on public datasets and in-the-wild videos\ndemonstrate the robustness and generalization capabilities of our approach.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T14:17:57Z"}
{"aid":"http://arxiv.org/abs/2504.01770v1","title":"$\\mathbf{Î³^{(*)} + N(940)\\frac{1}{2}^+ \\to N(1520)\\frac{3}{2}^{-}}$\n  helicity amplitudes and transition form factors","summary":"We recently reported new results on the $\\gamma^{(*)} + N(940)\\frac{1}{2}^+\n\\to \\Delta(1700)\\frac{3}{2}^{-}$ transition form factors using a\nsymmetry-preserving treatment of a vector$\\,\\otimes\\,$vector contact\ninteraction (SCI) within a coupled formalism based on the Dyson-Schwinger,\nBethe-Salpeter, and Faddeev equations. In this work, we extend our\ninvestigation to the $\\gamma^{(*)} + N(940)\\frac{1}{2}^+ \\to\nN(1520)\\frac{3}{2}^{-}$ transition. Our computed transition form factors show\nreasonable agreement with experimental data at large photon virtualities.\nHowever, deviations emerge at low $Q^2$, where experimental results exhibit a\nsharper variation than theoretical predictions. This discrepancy is expected,\nas these continuum QCD analyses account only for the quark-core of baryons,\nwhile low photon virtualities are dominated by meson cloud effects. We\nanticipate that these analytical predictions, based on the simplified SCI\nframework, will serve as a valuable benchmark for more refined studies and\nQCD-based truncations that incorporate quark angular momentum and the\ncontributions of scalar and vector diquarks.","main_category":"hep-ph","categories":"hep-ph,hep-ex,hep-lat,hep-th,nucl-th","published":"2025-04-02T14:28:48Z"}
{"aid":"http://arxiv.org/abs/2504.01778v1","title":"A quantitative theory and atomistic simulation study on the soft-sphere\n  crystal-melt interfacial properties: II. Interfacial free energies","summary":"This study proposes a new method for predicting the crystal-melt interfacial\nfree energy ($\\gamma$) using the Ginzburg-Landau (GL) model, enhanced by\natomistic simulation data for more accurate density wave profiles. The analysis\nfocuses on the soft-sphere system governed by an inverse power potential that\nstabilizes both BCC and FCC phases. Equilibrium molecular dynamics (MD)\nsimulations are used to obtain density wave amplitude distributions, which\nserve as inputs for the GL model to predict $\\gamma$ and its anisotropy. The\npredicted $\\gamma$ values exhibit strong agreement with prior benchmark\nsimulation experimental studies, particularly for FCC crystal-melt interfaces\n(CMIs). The GL models for the CMI $\\gamma$ are proved to be both\ncomputationally efficient and reasonably valid, offering quantitative\npredictions of $\\gamma$ while providing insights into the factors controlling\nits magnitude and anisotropy. Key improvement is suggested for the variational\nprocedure used in the two-mode CMI free energy functionals, and potential\nupgrades to the GL model are also proposed to further enhance predictive\naccuracy.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T14:40:02Z"}
{"aid":"http://arxiv.org/abs/2504.01780v1","title":"Finiteness and duality of cohomology of $(\\varphi,Î“)$-modules and\n  the 6-functor formalism of locally analytic representations","summary":"Finiteness and duality of cohomology of families of\n$(\\varphi,\\Gamma)$-modules were proved by Kedlaya-Pottharst-Xiao. In this\npaper, we study solid locally analytic representations introduced by Rodrigues\nJacinto-Rodr\\'iguez Camargo in terms of analytic stacks and 6-functor\nformalisms, which are developed by Clausen-Scholze, Heyer-Mann, respectively.\nBy using this, we will provide a generalization of the result of\nKedlaya-Pottharst-Xiao, giving a new proof for cases already proved there.","main_category":"math.NT","categories":"math.NT","published":"2025-04-02T14:45:45Z"}
{"aid":"http://arxiv.org/abs/2504.01786v1","title":"BlenderGym: Benchmarking Foundational Model Systems for Graphics Editing","summary":"3D graphics editing is crucial in applications like movie production and game\ndesign, yet it remains a time-consuming process that demands highly specialized\ndomain expertise. Automating this process is challenging because graphical\nediting requires performing a variety of tasks, each requiring distinct skill\nsets. Recently, vision-language models (VLMs) have emerged as a powerful\nframework for automating the editing process, but their development and\nevaluation are bottlenecked by the lack of a comprehensive benchmark that\nrequires human-level perception and presents real-world editing complexity. In\nthis work, we present BlenderGym, the first comprehensive VLM system benchmark\nfor 3D graphics editing. BlenderGym evaluates VLM systems through code-based 3D\nreconstruction tasks. We evaluate closed- and open-source VLM systems and\nobserve that even the state-of-the-art VLM system struggles with tasks\nrelatively easy for human Blender users. Enabled by BlenderGym, we study how\ninference scaling techniques impact VLM's performance on graphics editing\ntasks. Notably, our findings reveal that the verifier used to guide the scaling\nof generation can itself be improved through inference scaling, complementing\nrecent insights on inference scaling of LLM generation in coding and math\ntasks. We further show that inference compute is not uniformly effective and\ncan be optimized by strategically distributing it between generation and\nverification.","main_category":"cs.GR","categories":"cs.GR,cs.LG","published":"2025-04-02T14:51:45Z"}
{"aid":"http://arxiv.org/abs/2504.01796v1","title":"A New Approach to the Nonparametric Behrens-Fisher Problem with\n  Compatible Confidence Intervals","summary":"We propose a new test to address the nonparametric Behrens-Fisher problem\ninvolving different distribution functions in the two samples. Our procedure\ntests the null hypothesis $\\mathcal{H}_0: \\theta = \\frac{1}{2}$, where $\\theta\n= P(X<Y) + \\frac{1}{2}P(X=Y)$ denotes the Mann-Whitney effect. No restrictions\non the underlying distributions of the data are imposed with the trivial\nexception of one-point distributions. The method is based on evaluating the\nratio of the variance $\\sigma_N^2$ of the Mann-Whitney effect estimator\n$\\widehat{\\theta}$ to its theoretical maximum, as derived from the\nBirnbaum-Klose inequality. Through simulations, we demonstrate that the\nproposed test effectively controls the type-I error rate under various\nconditions, including small sample sizes, unbalanced designs, and different\ndata-generating mechanisms. Notably, it provides better control of the type-1\nerror rate compared to the widely used Brunner-Munzel test, particularly at\nsmall significance levels such as $\\alpha \\in \\{0.01, 0.005\\}$. Additionally,\nwe derive range-preserving compatible confidence intervals, showing that they\noffer improved coverage over those compatible to the Brunner-Munzel test.\nFinally, we illustrate the application of our method in a clinical trial\nexample.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-02T15:03:01Z"}
{"aid":"http://arxiv.org/abs/2504.01797v1","title":"Rethinking industrial artificial intelligence: a unified foundation\n  framework","summary":"Recent advancement in industrial artificial intelligence (AI) is reshaping\nthe industry, driving smarter manufacturing, predictive maintenance, and\nintelligent decision-making. However, existing approaches often focus primarily\non algorithms and models, overlooking the importance of systematically\nintegrating domain knowledge, data, and models to ensure more comprehensive and\neffective AI solutions. Therefore, the effective development and deployment of\nIndustrial AI solutions require a more comprehensive and systematic approach.\nTo address this gap, this paper summarizes previous research and rethinks the\nrole of industrial AI and presents a unified industrial AI foundation framework\ncomprising three core modules: knowledge module, data module, and model module.\nThese modules help to extend and enhance the industrial AI methodology\nplatform, supporting various industrial applications. In addition, a case study\non rotating machinery diagnosis demonstrates the framework's effectiveness, and\nseveral future directions are highlighted for the development of the industrial\nAI foundation framework.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-02T15:05:32Z"}
{"aid":"http://arxiv.org/abs/2504.01799v1","title":"A discussion on the origin of the sub-PeV Galactic gamma-ray emission","summary":"Galactic diffuse gamma-ray flux measured by the Tibet AS{\\gamma} experiment\nand the total Galactic gamma-ray flux measured by Large High Altitude Air\nShower Observatory (LHAASO) are found to be consistent, within the statistical\nand systematic uncertainties, for the inner Galactic Plane region in the\nsub-PeV energy range (E > 10^14 eV). The result suggests that the sub-PeV\nGalactic gamma-ray flux is dominated by the diffuse emission. On the other\nhand, the LHAASO observations suggest that the sub-PeV gamma-ray sources\npresented in the first LHAASO catalog possibly give a significant contribution\nto the total sub-PeV Galactic gamma-ray emission ($\\approx$ 60%). However, the\nestimate must be regarded as a conservative upper limit. In fact, current\ngamma-ray observations imply that many of the sub-PeV gamma-ray sources\ndetected by LHAASO have a cutoff or significant softening in their energy\nspectra in the several tens of TeV energy range, and the resolved-source\ncontribution to the total sub-PeV Galactic gamma-ray emission should be much\nlower than the above estimate. More sophisticated discussion about the origin\nof the sub-PeV Galactic gamma-ray emission requires detailed spectral studies\nof the individual gamma-ray sources and an accurate estimate of the\ncontamination of the source fluxes from the diffuse emission.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-02T15:09:22Z"}
{"aid":"http://arxiv.org/abs/2504.01800v1","title":"Motility and rotation of multi-timescale microswimmers in linear\n  background flows","summary":"Microswimming cells and robots exhibit diverse behaviours due to both their\nswimming and their environment. One of the core environmental features\nimpacting inertialess swimming is background flows. While the influence of\nselect flows, particularly shear flows, have been extensively investigated,\nthese are special cases. Here, we examine inertialess swimmers in more general\nflows, specifically general linear planar flows that may also possess rapid\noscillations. Relatively weak symmetry constraints are imposed on the swimmer\nto ensure planarity and to reduce complexity. A further constraint reflecting\ncommon observation is imposed, namely that the swimmer is inefficient, which we\nsuitably define. This introduces two separate timescales: a fast timescale\nassociated with swimmer actuation, and a second timescale associated with net\nswimmer movement, with inefficiency dictating that this latter timescale is\nmuch slower, allowing for a multiple timescale simplification of the governing\nequations. With the exception of mathematically precise edge cases, we find\nthat the behaviour of the swimmer is dictated by two parameter groupings, both\nof which measure balances between the angular velocity and rate of strain of\nthe background flow. While the measures of flow angular velocity and strain\nrates that primarily govern the rotational dynamics are modulated by swimmer\nproperties, the primary features of the translational motion are determined\nsolely by a ratio of flow angular velocity to strain rate. Hence, a simple\nclassification of the swimmer dynamics emerges. For example, this illustrates\nthe limited extent to which, and how, microswimmers may control their\norientations and trajectories in flows.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-02T15:09:50Z"}
{"aid":"http://arxiv.org/abs/2504.01804v1","title":"US National Input to the European Strategy Update for Particle Physics","summary":"In this document we summarize the output of the US community planning\nexercises for particle physics that were performed between 2020 and 2023 and\ncomment upon progress made since then towards our common scientific goals. This\ndocument leans heavily on the formal report of the Particle Physics Project\nPrioritization Panel and other recent US planning documents, often quoting them\nverbatim to retain the community consensus.","main_category":"hep-ex","categories":"hep-ex,nucl-ex","published":"2025-04-02T15:12:04Z"}
{"aid":"http://arxiv.org/abs/2504.01809v1","title":"Detector Response to Gravitational Wave Polarizations in Gravitational\n  Quantum Field Theory","summary":"We present an analysis of gravitational wave polarization modes within\nGravitational Quantum Field Theory (GQFT), a unified theoretical framework\nreconciling general relativity and quantum field theory. Our study focuses on\nfive fundamental polarization states predicted in GQFT: two tensor ($+,\n\\times$), two vector (x, y), and one scalar (breathing) mode, focusing on their\ndistinctive detection signatures in space-based interferometers like LISA and\nTaiji. Using first-order orbital dynamics in the Solar System Barycenter frame,\nwe identify three novel observational features: (1) characteristic interference\npatterns between polarization modes, (2) distinctive null-point signatures\nenabling mode discrimination, and (3) sky-position-dependent optimal detection\nwindows. Our approach provides complete sky coverage through polarization\nmapping while remaining fully compatible with existing mission designs, notably\navoiding the need for challenging direct breathing-mode measurements. The\nresults are presented through comprehensive sky maps, offering both theoretical\ninsights into gravitational wave polarization and practical tools for future\ndetector networks. This work establishes a new paradigm for testing fundamental\ngravity theories through their unique polarization fingerprints, with\nparticular relevance for upcoming multi-messenger gravitational wave astronomy.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE","published":"2025-04-02T15:15:45Z"}
{"aid":"http://arxiv.org/abs/2504.01816v1","title":"Random Phase Approximation Correlation Energy using Real-Space Density\n  Functional Perturbation Theory","summary":"We present a real-space method for computing the random phase approximation\n(RPA) correlation energy within Kohn-Sham density functional theory, leveraging\nthe low-rank nature of the frequency-dependent density response operator. In\nparticular, we employ a cubic scaling formalism based on density functional\nperturbation theory that circumvents the calculation of the response function\nmatrix, instead relying on the ability to compute its product with a vector\nthrough the solution of the associated Sternheimer linear systems. We develop a\nlarge-scale parallel implementation of this formalism using the subspace\niteration method in conjunction with the spectral quadrature method, while\nemploying the Kronecker product-based method for the application of the Coulomb\noperator and the conjugate orthogonal conjugate gradient method for the\nsolution of the linear systems. We demonstrate convergence with respect to key\nparameters and verify the method's accuracy by comparing with planewave\nresults. We show that the framework achieves good strong scaling to many\nthousands of processors, reducing the time to solution for a lithium hydride\nsystem with 128 electrons to around 150 seconds on 4608 processors.","main_category":"physics.comp-ph","categories":"physics.comp-ph,cond-mat.mtrl-sci,physics.chem-ph","published":"2025-04-02T15:21:51Z"}
{"aid":"http://arxiv.org/abs/2504.01829v1","title":"Revealed Bayesian Persuasion","summary":"When is random choice generated by a decision maker (DM) who is\nBayesian-persuaded by a sender? In this paper, I consider a DM whose\nstate-dependent preferences are known to an analyst, yet chooses stochastically\nas a function of the state. I provide necessary and sufficient conditions for\nthe dataset to be consistent with the DM being Bayesian persuaded by an\nunobserved sender who generates a distribution of signals to ex-ante optimize\nthe sender's expected payoff.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-02T15:38:24Z"}
{"aid":"http://arxiv.org/abs/2504.01838v1","title":"Prompting Medical Vision-Language Models to Mitigate Diagnosis Bias by\n  Generating Realistic Dermoscopic Images","summary":"Artificial Intelligence (AI) in skin disease diagnosis has improved\nsignificantly, but a major concern is that these models frequently show biased\nperformance across subgroups, especially regarding sensitive attributes such as\nskin color. To address these issues, we propose a novel generative AI-based\nframework, namely, Dermatology Diffusion Transformer (DermDiT), which leverages\ntext prompts generated via Vision Language Models and multimodal text-image\nlearning to generate new dermoscopic images. We utilize large vision language\nmodels to generate accurate and proper prompts for each dermoscopic image which\nhelps to generate synthetic images to improve the representation of\nunderrepresented groups (patient, disease, etc.) in highly imbalanced datasets\nfor clinical diagnoses. Our extensive experimentation showcases the large\nvision language models providing much more insightful representations, that\nenable DermDiT to generate high-quality images. Our code is available at\nhttps://github.com/Munia03/DermDiT","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T15:44:12Z"}
{"aid":"http://arxiv.org/abs/2504.01841v1","title":"Garbage Collection for Rust: The Finalizer Frontier","summary":"Rust is a non-Garbage Collected (GCed) language, but the lack of GC makes\nexpressing data-structures that require shared ownership awkward, inefficient,\nor both. In this paper we explore a new design for, and implementation of, GC\nin Rust, called Alloy. Unlike previous approaches to GC in Rust, Alloy maps\nexisting Rust destructors to finalizers: this makes GC in Rust natural to use\nbut introduces surprising soundness, performance, and ergonomic problems. Alloy\nprovides solutions for each of these problems.","main_category":"cs.PL","categories":"cs.PL,D.3","published":"2025-04-02T15:46:58Z"}
{"aid":"http://arxiv.org/abs/2504.01845v1","title":"Dust environment of long-period comet C/2023 A3 (Tsuchinshan-ATLAS)","summary":"We present a characterization of the dust environment of long-period comet\nC/2023 A3 (Tsuchinshan-ATLAS) by analyzing an extensive dataset, including dust\ntail images and photometric measurements, from 10 au pre-perihelion to 1.6 au\npost-perihelion, using our forward Monte Carlo code. For this analysis, we\ncombine pre-perihelion images from the Zwicky Transient Facility with\npost-perihelion images from the Sierra Nevada Observatory (IAA-CSIC, Granada,\nSpain), along with both amateur and professional photometric measurements,\nincluding Af$\\rho$ and magnitude data. We find that the dust loss rate\nincreases monotonically from the assumed start of activity at a heliocentric\ndistance of approximately 15 au down to 4 au inbound, where the comet exhibits\na notable decrease in dust production by about one order of magnitude.\nFollowing this period of reduced activity, the dust production rate rises again\ntoward perihelion, reaching a peak production rate of 10$^5$ kg s$^{-1}$. The\nsize distribution of the particles follows a power law, with its index\ndecreasing toward perihelion, along with a reduction in the minimum particle\nradius, leading to both brightness and dust mass being dominated by small\nparticles at perihelion. The particle speeds exhibit a dependence on\nheliocentric distance ($r_h$) that closely follows the classical $r_h^{-0.5}$\nlaw near perihelion but deviates at larger heliocentric distances. We\ndemonstrate that the dependence of particle speeds on the cosine of the solar\nzenith angle at the emission point plays a significant role in shaping the\nsynthetic dust tails and in the formation of a dark stripe along the tail axis\nobserved in high spatial resolution images near the comet's perihelion.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-02T15:50:16Z"}
{"aid":"http://arxiv.org/abs/2504.01858v1","title":"Investigating the Variable Continuum Lags in PG 2130+099","summary":"Broadband photometric reverberation mapping (RM) provides a measure of the\nsize of the continuum-emitting region in active galactic nuclei (AGN). Previous\nmonitoring campaigns of PG 2130+099 disagree as to whether the continuum\nemitting region size is consistent with that predicted for a standard optically\nthick geometrically thin accretion disk. We present $\\sim$6 months of\nobservations from several robotic telescopes, providing the highest cadence and\nwidest wavelength coverage photometric RM study of PG 2130+099 to date. Our\nresults indicate that inferred size of the continuum-emitting region in PG\n2130+099, like many recently observed AGN, is larger than the simplest\npredictions for an irradiated geometrically thin, optically thick accretion\ndisk. We also perform a flux-flux analysis, finding a variable spectrum broadly\nconsistent with a disk, and a constant component with enhanced\n$\\textit{i}$-band emission, potentially due to H$\\alpha$. We find some evidence\nof increasing lag with luminosity, but previous lag measurements are too\nuncertain to be definitive.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.HE","published":"2025-04-02T16:10:36Z"}
{"aid":"http://arxiv.org/abs/2504.01864v1","title":"On the $W$-entropy and Shannon entropy power on RCD$(K, N)$ and RCD$(K,\n  n, N)$ spaces","summary":"In this paper, we prove the $W$-entropy formula and its monotonicity for the\nheat flow on RCD$(K, N)$ and RCD$(K, n, N)$ spaces $(X, d, \\mu)$, where $K\\in\n\\mathbb{R}$, $n$ is the geometric dimension of $(X, d, \\mu)$ and $N\\geq n$. We\nalso prove the $K$-concavity of the Shannon entropy power on RCD$(K, N)$\nspaces. As an application, we derive the Shannon entropy isoperimetric\ninequality and the Stam logarithmic Sobolev inequality on RCD$(0, N)$ spaces\nwith maximal volume growth condition. Finally, we prove the rigidity theorem\nfor the Stam logarithmic Sobolev inequality with sharp constant on\nnoncollapsing RCD$(0, N)$ spaces.","main_category":"math.FA","categories":"math.FA,math.MG,math.PR","published":"2025-04-02T16:15:50Z"}
{"aid":"http://arxiv.org/abs/2504.01876v1","title":"The TELOS Collaboration Approach to Reproducibility and Open Science","summary":"The TELOS Collaboration is committed to producing and analysing lattice data\nreproducibly, and sharing its research openly. In this document, we set out the\nways that we make this happen, where there is scope for improvement, and how we\nplan to achieve this. This is intended to work both as a statement of policy,\nand a guide to practice for those beginning to work with us. Some details and\nrecommendations are specific to the context in which the Collaboration works\n(such as references to requirements imposed by funders in the United Kingdom);\nhowever, most recommendations may serve as a template for other collaborations\nlooking to make their own work reproducible. Full tutorials on every aspect of\nreproducibility are beyond the scope of this document, but we refer to other\nresources for further information.","main_category":"hep-lat","categories":"hep-lat","published":"2025-04-02T16:32:29Z"}
{"aid":"http://arxiv.org/abs/2504.01897v1","title":"Threshold for Fault-tolerant Quantum Advantage with the Quantum\n  Approximate Optimization Algorithm","summary":"Optimization is often cited as a promising application of quantum computers.\nHowever, the low degree of provable quantum speedups has led prior rigorous\nend-to-end resource analyses to conclude that a quantum computer is unlikely to\nsurpass classical state-of-the-art on optimization problems under realistic\nassumptions. In this work, we compile and analyze the Quantum Approximate\nOptimization Algorithm (QAOA) combined with Amplitude Amplification (AA)\napplied to random 8-SAT at the satisfiability threshold. Our compilation\ninvolves careful optimization of circuits for Hamiltonian simulation, which may\nbe of independent interest. We use the analytical scaling of the\ntime-to-solution for QAOA identified by PRX Quantum 5, 030348 (2024) and find\nthat with QAOA depth $p=623$, QAOA+AA achieves a crossover with\nstate-of-the-art classical heuristics at 179 variables and 14.99 hours of\nruntime when executed on a surface-code-based fault-tolerant quantum computer\nwith 73.91 million physical qubits, a physical error rate of $10^{-3}$, and a\n$1~\\mu$s code cycle time. Notably, we allow the classical solver to be\nparallelized as long as its total energy consumption is equal to that required\nfor decoding in the surface code. We further show that this restriction on\nclassical solver energy consumption can be relaxed given optimistic but\nplausible reductions in physical error rates and fault-tolerance overheads,\nenabling a crossover of 2.94 hours using 8.88 million physical qubits against a\nclassical solver running on a supercomputer with $725,760$ CPU cores. These\nfindings support the hypothesis that large-scale fault-tolerant quantum\ncomputers will be useful for optimization.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T16:57:28Z"}
{"aid":"http://arxiv.org/abs/2504.01899v1","title":"Recovery Reductions in the Random Noise Model via Group Theory: Insights\n  into NP-Complete and Fine-Grained Problems","summary":"We introduce and initiate the study of a new model of reductions called the\nrandom noise model. In this model, the truth table $T_f$ of the function $f$ is\ncorrupted on a randomly chosen $\\delta$-fraction of instances. A randomized\nalgorithm $A$ is a $\\left(t, \\delta, 1-\\varepsilon\\right)$-recovery reduction\nfor $f$ if:\n  1. With probability $1-\\varepsilon$ over the choice of $\\delta$-fraction\ncorruptions, given access to the corrupted truth table, the algorithm $A$\ncomputes $f(\\phi)$ correctly with probability at least $2/3$ on every input\n$\\phi$.\n  2. The algorithm $A$ runs in time $O(t)$.\n  We believe this model, which is a natural relaxation of average-case\ncomplexity, both has practical motivations and is mathematically interesting.\n  Pointing towards this, we show the existence of robust deterministic\npolynomial-time recovery reductions with the highest tolerable noise level for\nmany of the canonical NP-complete problems - SAT, kSAT, kCSP, CLIQUE and more.\nOur recovery reductions are optimal for non-adaptive algorithms under\ncomplexity-theoretic assumptions. Notably, all our recovery reductions follow\nas corollaries of one black box algorithm based on group theory and permutation\ngroup algorithms. This suggests that recovery reductions in the random noise\nmodel are important to the study of the structure of NP-completeness.\n  Furthermore, we establish recovery reductions with optimal parameters for\nOrthogonal Vectors and Parity $k$-Clique problems. These problems exhibit\nstructural similarities to NP-complete problems, with Orthogonal Vectors\nadmitting a $2^{0.5n}$-time reduction from kSAT on $n$ variables and Parity\n$k$-Clique, a subexponential-time reduction from 3SAT. This further highlights\nthe relevance of our model to the study of NP-completeness.","main_category":"cs.CC","categories":"cs.CC","published":"2025-04-02T16:58:07Z"}
{"aid":"http://arxiv.org/abs/2504.01902v1","title":"Graphically Speaking: Unmasking Abuse in Social Media with Conversation\n  Insights","summary":"Detecting abusive language in social media conversations poses significant\nchallenges, as identifying abusiveness often depends on the conversational\ncontext, characterized by the content and topology of preceding comments.\nTraditional Abusive Language Detection (ALD) models often overlook this\ncontext, which can lead to unreliable performance metrics. Recent Natural\nLanguage Processing (NLP) methods that integrate conversational context often\ndepend on limited and simplified representations, and report inconsistent\nresults. In this paper, we propose a novel approach that utilize graph neural\nnetworks (GNNs) to model social media conversations as graphs, where nodes\nrepresent comments, and edges capture reply structures. We systematically\ninvestigate various graph representations and context windows to identify the\noptimal configuration for ALD. Our GNN model outperform both context-agnostic\nbaselines and linear context-aware methods, achieving significant improvements\nin F1 scores. These findings demonstrate the critical role of structured\nconversational context and establish GNNs as a robust framework for advancing\ncontext-aware abusive language detection.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-02T17:03:37Z"}
{"aid":"http://arxiv.org/abs/2504.01913v1","title":"Representing Flow Fields with Divergence-Free Kernels for Reconstruction","summary":"Accurately reconstructing continuous flow fields from sparse or indirect\nmeasurements remains an open challenge, as existing techniques often suffer\nfrom oversmoothing artifacts, reliance on heterogeneous architectures, and the\ncomputational burden of enforcing physics-informed losses in implicit neural\nrepresentations (INRs). In this paper, we introduce a novel flow field\nreconstruction framework based on divergence-free kernels (DFKs), which\ninherently enforce incompressibility while capturing fine structures without\nrelying on hierarchical or heterogeneous representations. Through qualitative\nanalysis and quantitative ablation studies, we identify the matrix-valued\nradial basis functions derived from Wendland's $\\mathcal{C}^4$ polynomial\n(DFKs-Wen4) as the optimal form of analytically divergence-free approximation\nfor velocity fields, owing to their favorable numerical properties, including\ncompact support, positive definiteness, and second-order differentiablility.\nExperiments across various reconstruction tasks, spanning data compression,\ninpainting, super-resolution, and time-continuous flow inference, has\ndemonstrated that DFKs-Wen4 outperform INRs and other divergence-free\nrepresentations in both reconstruction accuracy and computational efficiency\nwhile requiring the fewest trainable parameters.","main_category":"cs.GR","categories":"cs.GR,cs.LG","published":"2025-04-02T17:13:59Z"}
{"aid":"http://arxiv.org/abs/2504.01915v1","title":"Overcoming Deceptiveness in Fitness Optimization with Unsupervised\n  Quality-Diversity","summary":"Policy optimization seeks the best solution to a control problem according to\nan objective or fitness function, serving as a fundamental field of engineering\nand research with applications in robotics. Traditional optimization methods\nlike reinforcement learning and evolutionary algorithms struggle with deceptive\nfitness landscapes, where following immediate improvements leads to suboptimal\nsolutions. Quality-diversity (QD) algorithms offer a promising approach by\nmaintaining diverse intermediate solutions as stepping stones for escaping\nlocal optima. However, QD algorithms require domain expertise to define\nhand-crafted features, limiting their applicability where characterizing\nsolution diversity remains unclear. In this paper, we show that unsupervised QD\nalgorithms - specifically the AURORA framework, which learns features from\nsensory data - efficiently solve deceptive optimization problems without domain\nexpertise. By enhancing AURORA with contrastive learning and periodic\nextinction events, we propose AURORA-XCon, which outperforms all traditional\noptimization baselines and matches, in some cases even improving by up to 34%,\nthe best QD baseline with domain-specific hand-crafted features. This work\nestablishes a novel application of unsupervised QD algorithms, shifting their\nfocus from discovering novel solutions toward traditional optimization and\nexpanding their potential to domains where defining feature spaces poses\nchallenges.","main_category":"cs.NE","categories":"cs.NE,cs.RO","published":"2025-04-02T17:18:21Z"}
{"aid":"http://arxiv.org/abs/2504.01926v1","title":"Pairing Anderson motives via formal residues in the Frobenius\n  endomorphism","summary":"Anderson modules form a generalization of Drinfeld modules and are commonly\nunderstood as the counterpart of abelian varieties but with function field\ncoefficients. In an attempt to study their ``motivic theory'', two objects of\nsemilinear algebra are attached to an Anderson module: its motive and its dual\nmotive. While the former is better suited to follow the analogy with\nGrothendieck motives, the latter has proven much useful in the study of\ntranscendence questions in positive characteristic. Despite sharing similar\ndefinitions, the relationship between motives and dual motives has remained\nnebulous. Over perfect fields, it was only proved recently by the second author\nthat the finite generation of the motive is equivalent to the finite generation\nof the dual motive, answering a long-standing open question in function field\narithmetic (the ``abelian equals $A$-finite'' theorem). This work constructs a\nperfect pairing among the motive and the dual motive of an Anderson module,\nwith values in a module of differentials, thus answering a question raised by\nHartl and Juschka. Our construction involves taking the residue of certain\nformal power series in the Frobenius endomorphism. Although it may seem\npeculiar, this pairing is natural and compatible with base change. It also\ncomes with several new consequences in function field arithmetic; for example,\nwe generalize the ``abelian equals A-finite'' theorem to a large class of\nalgebras, including fields, perfect algebras and noetherian regular domains.","main_category":"math.AG","categories":"math.AG","published":"2025-04-02T17:37:05Z"}
{"aid":"http://arxiv.org/abs/2504.01944v1","title":"Graphon games and an idealized limit of large network games","summary":"Graphon games are a class of games with a continuum of agents, introduced to\napproximate the strategic interactions in large network games. The first result\nof this study is an equilibrium existence theorem in graphon games, under the\nsame conditions as those in network games. We prove the existence of an\nequilibrium in a graphon game with an infinite-dimensional strategy space,\nunder the continuity and quasi-concavity of the utility functions. The second\nresult characterizes Nash equilibria in graphon games as the limit points of\nasymptotic Nash equilibria in large network games. If a sequence of large\nnetwork games converges to a graphon game, any convergent sequence of\nasymptotic Nash equilibria in these large network games also converges to a\nNash equilibrium of the graphon game. In addition, for any graphon game and its\nequilibrium, there exists a sequence of large network games that converges to\nthe graphon game and has asymptotic Nash equilibria converging to the\nequilibrium. These results suggest that the concept of a graphon game is an\nidealized limit of large network games as the number of players tends to\ninfinity.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-02T17:51:15Z"}
{"aid":"http://arxiv.org/abs/2504.01946v1","title":"Asynchronous Traffic Shaping and Redundancy: Avoiding Unbounded\n  Latencies in In-Car Networks","summary":"Time-Sensitive Networking (TSN) enhances Ethernet based In-Vehicle Networks\n(IVNs) with real-time capabilities. Different traffic shaping algorithms have\nbeen proposed for time-critical communication, of which the Asynchronous\nTraffic Shaper (ATS) is an upcoming candidate. However, recent research has\nshown that ATS can introduce unbounded latencies when shaping traffic from\nnon-FIFO systems. This impacts the applicability of ATS in IVNs, as these\nnetworks often use redundancy mechanisms that can cause non-FIFO behavior. In\nthis paper, we approach the problem of accumulated delays from ATS by analyzing\nthe scenarios that generate latency and by devising placement and\nconfigurations of ATS schedulers to prevent this behavior. Our solution\nsuccessfully mitigates problematic preconditions that lead to unbounded delays,\nwhich we evaluate in simulations. Through a realistic IVN simulation case\nstudy, we demonstrate the occurrence of unbounded latencies and validate the\neffectiveness of our approach in avoiding them.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-02T17:53:37Z"}
{"aid":"http://arxiv.org/abs/2504.01947v1","title":"Efficient Federated Learning Tiny Language Models for Mobile Network\n  Feature Prediction","summary":"In telecommunications, Autonomous Networks (ANs) automatically adjust\nconfigurations based on specific requirements (e.g., bandwidth) and available\nresources. These networks rely on continuous monitoring and intelligent\nmechanisms for self-optimization, self-repair, and self-protection, nowadays\nenhanced by Neural Networks (NNs) to enable predictive modeling and pattern\nrecognition. Here, Federated Learning (FL) allows multiple AN cells - each\nequipped with NNs - to collaboratively train models while preserving data\nprivacy. However, FL requires frequent transmission of large neural data and\nthus an efficient, standardized compression strategy for reliable\ncommunication. To address this, we investigate NNCodec, a Fraunhofer\nimplementation of the ISO/IEC Neural Network Coding (NNC) standard, within a\nnovel FL framework that integrates tiny language models (TLMs) for various\nmobile network feature prediction (e.g., ping, SNR or band frequency). Our\nexperimental results on the Berlin V2X dataset demonstrate that NNCodec\nachieves transparent compression (i.e., negligible performance loss) while\nreducing communication overhead to below 1%, showing the effectiveness of\ncombining NNC with FL in collaboratively learned autonomous mobile networks.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.DC,eess.SP","published":"2025-04-02T17:54:06Z"}
{"aid":"http://arxiv.org/abs/2504.01954v1","title":"Towards Unified Referring Expression Segmentation Across Omni-Level\n  Visual Target Granularities","summary":"Referring expression segmentation (RES) aims at segmenting the entities'\nmasks that match the descriptive language expression. While traditional RES\nmethods primarily address object-level grounding, real-world scenarios demand a\nmore versatile framework that can handle multiple levels of target granularity,\nsuch as multi-object, single object or part-level references. This introduces\ngreat challenges due to the diverse and nuanced ways users describe targets.\nHowever, existing datasets and models mainly focus on designing grounding\nspecialists for object-level target localization, lacking the necessary data\nresources and unified frameworks for the more practical multi-grained RES. In\nthis paper, we take a step further towards visual granularity unified RES task.\nTo overcome the limitation of data scarcity, we introduce a new\nmulti-granularity referring expression segmentation (MRES) task, alongside the\nRefCOCOm benchmark, which includes part-level annotations for advancing\nfiner-grained visual understanding. In addition, we create MRES-32M, the\nlargest visual grounding dataset, comprising over 32.2M masks and captions\nacross 1M images, specifically designed for part-level vision-language\ngrounding. To tackle the challenges of multi-granularity RES, we propose\nUniRES++, a unified multimodal large language model that integrates\nobject-level and part-level RES tasks. UniRES++ incorporates targeted designs\nfor fine-grained visual feature exploration. With the joint model architecture\nand parameters, UniRES++ achieves state-of-the-art performance across multiple\nbenchmarks, including RefCOCOm for MRES, gRefCOCO for generalized RES, and\nRefCOCO, RefCOCO+, RefCOCOg for classic RES. To foster future research into\nmulti-grained visual grounding, our RefCOCOm benchmark, MRES-32M dataset and\nmodel UniRES++ will be publicly available at\nhttps://github.com/Rubics-Xuan/MRES.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T17:58:05Z"}
{"aid":"http://arxiv.org/abs/2504.01956v1","title":"VideoScene: Distilling Video Diffusion Model to Generate 3D Scenes in\n  One Step","summary":"Recovering 3D scenes from sparse views is a challenging task due to its\ninherent ill-posed problem. Conventional methods have developed specialized\nsolutions (e.g., geometry regularization or feed-forward deterministic model)\nto mitigate the issue. However, they still suffer from performance degradation\nby minimal overlap across input views with insufficient visual information.\nFortunately, recent video generative models show promise in addressing this\nchallenge as they are capable of generating video clips with plausible 3D\nstructures. Powered by large pretrained video diffusion models, some pioneering\nresearch start to explore the potential of video generative prior and create 3D\nscenes from sparse views. Despite impressive improvements, they are limited by\nslow inference time and the lack of 3D constraint, leading to inefficiencies\nand reconstruction artifacts that do not align with real-world geometry\nstructure. In this paper, we propose VideoScene to distill the video diffusion\nmodel to generate 3D scenes in one step, aiming to build an efficient and\neffective tool to bridge the gap from video to 3D. Specifically, we design a\n3D-aware leap flow distillation strategy to leap over time-consuming redundant\ninformation and train a dynamic denoising policy network to adaptively\ndetermine the optimal leap timestep during inference. Extensive experiments\ndemonstrate that our VideoScene achieves faster and superior 3D scene\ngeneration results than previous video diffusion models, highlighting its\npotential as an efficient tool for future video to 3D applications. Project\nPage: https://hanyang-21.github.io/VideoScene","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T17:59:21Z"}
{"aid":"http://arxiv.org/abs/2504.01957v1","title":"GaussianLSS -- Toward Real-world BEV Perception: Depth Uncertainty\n  Estimation via Gaussian Splatting","summary":"Bird's-eye view (BEV) perception has gained significant attention because it\nprovides a unified representation to fuse multiple view images and enables a\nwide range of down-stream autonomous driving tasks, such as forecasting and\nplanning. Recent state-of-the-art models utilize projection-based methods which\nformulate BEV perception as query learning to bypass explicit depth estimation.\nWhile we observe promising advancements in this paradigm, they still fall short\nof real-world applications because of the lack of uncertainty modeling and\nexpensive computational requirement. In this work, we introduce GaussianLSS, a\nnovel uncertainty-aware BEV perception framework that revisits\nunprojection-based methods, specifically the Lift-Splat-Shoot (LSS) paradigm,\nand enhances them with depth un-certainty modeling. GaussianLSS represents\nspatial dispersion by learning a soft depth mean and computing the variance of\nthe depth distribution, which implicitly captures object extents. We then\ntransform the depth distribution into 3D Gaussians and rasterize them to\nconstruct uncertainty-aware BEV features. We evaluate GaussianLSS on the\nnuScenes dataset, achieving state-of-the-art performance compared to\nunprojection-based methods. In particular, it provides significant advantages\nin speed, running 2.5x faster, and in memory efficiency, using 0.3x less memory\ncompared to projection-based methods, while achieving competitive performance\nwith only a 0.4% IoU difference.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T17:59:38Z"}
{"aid":"http://arxiv.org/abs/2504.01961v1","title":"Learning from Streaming Video with Orthogonal Gradients","summary":"We address the challenge of representation learning from a continuous stream\nof video as input, in a self-supervised manner. This differs from the standard\napproaches to video learning where videos are chopped and shuffled during\ntraining in order to create a non-redundant batch that satisfies the\nindependently and identically distributed (IID) sample assumption expected by\nconventional training paradigms. When videos are only available as a continuous\nstream of input, the IID assumption is evidently broken, leading to poor\nperformance. We demonstrate the drop in performance when moving from shuffled\nto sequential learning on three tasks: the one-video representation learning\nmethod DoRA, standard VideoMAE on multi-video datasets, and the task of future\nvideo prediction. To address this drop, we propose a geometric modification to\nstandard optimizers, to decorrelate batches by utilising orthogonal gradients\nduring training. The proposed modification can be applied to any optimizer --\nwe demonstrate it with Stochastic Gradient Descent (SGD) and AdamW. Our\nproposed orthogonal optimizer allows models trained from streaming videos to\nalleviate the drop in representation learning performance, as evaluated on\ndownstream tasks. On three scenarios (DoRA, VideoMAE, future prediction), we\nshow our orthogonal optimizer outperforms the strong AdamW in all three\nscenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T17:59:57Z"}
{"aid":"http://arxiv.org/abs/2504.02215v1","title":"Frequency Dependent Magnetic Susceptibility and the $q^2$ effective\n  conductivity tensor","summary":"We apply a microscopic formalism for the calculation of material response\nproperties to the problem of the generalization of a first-principles, i.e\nbased on the energy spectrum and geometric properties of the Bloch functions,\nderivation of the AC magnetic susceptibility. We find that the AC\nsusceptibility forms only a part of the $q^2$ -- where $q$ is the wavevector of\nthe applied field -- effective conductivity tensor, and many additional\nresponse tensors characterizing both electric and magnetic multipole moments\nresponse to electromagnetic fields and their derivatives must be included to\ncreate the full gauge-invariant response. As was seen with the DC magnetic\nsusceptibility and optical activity (characterized by the linear in $q$\ncontribution to the conductivity) one must be careful with the diagonal\nelements of the Berry connection. To our knowledge this is the only derivation\nof such a result general for crystalline insulators, with both `atomic like'\ncontributions and `itinerant contributions' due to overlap of atomic orbitals\nand non-flat bands. Additionally, quantities familiar from quantum geometry\nlike the Berry connection, curvature, and quantum metric appear extensively.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-03T02:09:18Z"}
{"aid":"http://arxiv.org/abs/2504.02219v1","title":"Experimental evidence of non-equilibrium phase separation in\n  supercritical fluids","summary":"Supercritical fluids (SCFs) have long been considered homogeneous and\nstructureless, yet recent studies suggest the existence of transient,\nliquid-like clusters under dynamic processes. In this study, we provide\nexperimental evidence of semi-stable non-equilibrium phase separation in SCFs\nthrough opacity measurements and small-angle neutron scattering (SANS). By\ninvestigating the thermophysical properties of helium, argon, and krypton\nduring adiabatic expansion, we show that cooling dynamics vary significantly\namong species, influencing cluster formation. Neutron scattering measurements\nreveal distinct variations in signal intensity, supporting that the clusters\nslowly dissolve into the background with a surprisingly long time scale of tens\nof minutes. Given that SCFs in industrial applications frequently experience\ndynamic, non-equilibrium conditions rather than in strict thermodynamic\nequilibrium, our results provide crucial insights with potential implications\nfor advanced material processing, energy systems, and chemical engineering.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-03T02:20:59Z"}
{"aid":"http://arxiv.org/abs/2504.02225v1","title":"Twisted second moment of modular $L$-functions to a fixed modulus","summary":"We study asymptotically the twisted second moment of the family of modular\n$L$-functions to a fixed modulus. As an application, we establish sharp lower\nbounds for all real $k \\geq 0$ and sharp upper bounds for $k$ in the range $0\n\\leq k \\leq 1$ for the $2k$-th moment of these $L$-functions on the critical\nline.","main_category":"math.NT","categories":"math.NT","published":"2025-04-03T02:46:48Z"}
{"aid":"http://arxiv.org/abs/2504.02227v1","title":"VEGAS: Towards Visually Explainable and Grounded Artificial Social\n  Intelligence","summary":"Social Intelligence Queries (Social-IQ) serve as the primary multimodal\nbenchmark for evaluating a model's social intelligence level. While impressive\nmultiple-choice question(MCQ) accuracy is achieved by current solutions,\nincreasing evidence shows that they are largely, and in some cases entirely,\ndependent on language modality, overlooking visual context. Additionally, the\nclosed-set nature further prevents the exploration of whether and to what\nextent the reasoning path behind selection is correct. To address these\nlimitations, we propose the Visually Explainable and Grounded Artificial Social\nIntelligence (VEGAS) model. As a generative multimodal model, VEGAS leverages\nopen-ended answering to provide explainable responses, which enhances the\nclarity and evaluation of reasoning paths. To enable visually grounded\nanswering, we propose a novel sampling strategy to provide the model with more\nrelevant visual frames. We then enhance the model's interpretation of these\nframes through Generalist Instruction Fine-Tuning (GIFT), which aims to: i)\nlearn multimodal-language transformations for fundamental emotional social\ntraits, and ii) establish multimodal joint reasoning capabilities. Extensive\nexperiments, comprising modality ablation, open-ended assessments, and\nsupervised MCQ evaluations, consistently show that VEGAS effectively utilizes\nvisual information in reasoning to produce correct and also credible answers.\nWe expect this work to of fer a new perspective on Social-IQ and advance the\ndevelopment of human-like social AI.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-03T02:48:21Z"}
{"aid":"http://arxiv.org/abs/2504.02229v1","title":"Identify Main-sequence Binaries from the Chinese Space Station Telescope\n  Survey with Machine Learning. II. Based on Gaia and GALEX","summary":"The statistical characteristics of double main-sequence (MS) binaries are\nessential for investigating star formation, binary evolution, and population\nsynthesis. Our previous study proposed a machine learning-based method to\nidentify MS binaries from MS single stars using mock data from the Chinese\nSpace Station Telescope (CSST). We further utilized detection efficiencies and\nan empirical mass ratio distribution to estimate the binary fraction within the\nsample. To further validate the effectiveness of this method, we conducted a\nmore realistic sample simulation, incorporating additional factors such as\nmetallicity, extinction, and photometric errors from CSST simulations. The\ndetection efficiency for binaries with mass ratios between 0.2 and 0.7 reached\nover 80%. We performed a detailed observational validation using the data\nselected from the Gaia Sky Survey and Galaxy Evolution Explorer. The detection\nefficiency for MS binaries in the observed sample was 65%. The binary fraction\ncan be inferred with high precision for a set of observed samples, based on\naccurate empirical mass ratio distribution.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-03T02:50:00Z"}
{"aid":"http://arxiv.org/abs/2504.02233v1","title":"Testing independence and conditional independence in high dimensions via\n  coordinatewise Gaussianization","summary":"We propose new statistical tests, in high-dimensional settings, for testing\nthe independence of two random vectors and their conditional independence given\na third random vector. The key idea is simple, i.e., we first transform each\ncomponent variable to standard normal via its marginal empirical distribution,\nand we then test for independence and conditional independence of the\ntransformed random vectors using appropriate $L_\\infty$-type test statistics.\nWhile we are testing some necessary conditions of the independence or the\nconditional independence, the new tests outperform the 13 frequently used\ntesting methods in a large scale simulation comparison. The advantage of the\nnew tests can be summarized as follows: (i) they do not require any moment\nconditions, (ii) they allow arbitrary dependence structures of the components\namong the random vectors, and (iii) they allow the dimensions of random vectors\ndiverge at the exponential rates of the sample size. The critical values of the\nproposed tests are determined by a computationally efficient multiplier\nbootstrap procedure. Theoretical analysis shows that the sizes of the proposed\ntests can be well controlled by the nominal significance level, and the\nproposed tests are also consistent under certain local alternatives. The finite\nsample performance of the new tests is illustrated via extensive simulation\nstudies and a real data application.","main_category":"stat.ME","categories":"stat.ME,math.ST,stat.TH","published":"2025-04-03T02:59:52Z"}
{"aid":"http://arxiv.org/abs/2504.02249v1","title":"Stock Price Prediction Using Triple Barrier Labeling and Raw OHLCV Data:\n  Evidence from Korean Markets","summary":"This paper demonstrates that deep learning models trained on raw OHLCV\n(open-high-low-close-volume) data can achieve comparable performance to\ntraditional machine learning models using technical indicators for stock price\nprediction in Korean markets. While previous studies have emphasized the\nimportance of technical indicators and feature engineering, we show that a\nsimple LSTM network trained on raw OHLCV data alone can match the performance\nof sophisticated ML models that incorporate technical indicators. Using a\ndataset of Korean stocks from 2006 to 2024, we optimize the triple barrier\nlabeling parameters to achieve balanced label proportions with a 29-day window\nand 9\\% barriers. Our experiments reveal that LSTM networks achieve similar\nperformance to traditional machine learning models like XGBoost, despite using\nonly raw OHLCV data without any technical indicators. Furthermore, we identify\nthat the optimal window size varies with model hidden size, with a\nconfiguration of window size 100 and hidden size 8 yielding the best\nperformance. Additionally, our results confirm that using full OHLCV data\nprovides better predictive accuracy compared to using only close price or close\nprice with volume. These findings challenge conventional approaches to feature\nengineering in financial forecasting and suggest that simpler approaches\nfocusing on raw data and appropriate model selection may be more effective than\ncomplex feature engineering strategies.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-03T03:30:50Z"}
{"aid":"http://arxiv.org/abs/2504.02250v1","title":"Designing Effective Human-Swarm Interaction Interfaces: Insights from a\n  User Study on Task Performance","summary":"In this paper, we present a systematic method of design for human-swarm\ninteraction interfaces, combining theoretical insights with empirical\nevaluation. We first derive ten design principles from existing literature,\napply them to key information dimensions identified through goal-directed task\nanalysis and developed a tablet-based interface for a target search task. We\nthen conducted a user study with 31 participants where humans were required to\nguide a robotic swarm to a target in the presence of three types of hazards\nthat pose a risk to the robots: Distributed, Moving, and Spreading. Performance\nwas measured based on the proximity of the robots to the target and the number\nof deactivated robots at the end of the task. Results indicate that at least\none robot was bought closer to the target in 98% of tasks, demonstrating the\ninterface's success fulfilling the primary objective of the task. Additionally,\nin nearly 67% of tasks, more than 50% of the robots reached the target.\nMoreover, particularly better performance was noted in moving hazards.\nAdditionally, the interface appeared to help minimize robot deactivation, as\nevidenced by nearly 94% of tasks where participants managed to keep more than\n50% of the robots active, ensuring that most of the swarm remained operational.\nHowever, its effectiveness varied across hazards, with robot deactivation being\nlowest in distributed hazard scenarios, suggesting that the interface provided\nthe most support in these conditions.","main_category":"cs.HC","categories":"cs.HC,cs.RO","published":"2025-04-03T03:38:13Z"}
{"aid":"http://arxiv.org/abs/2504.02253v1","title":"On energy-momentum tensor for gravitational waves in $f(R)$ gravity","summary":"The classical Isaacson's procedure for describing back-reaction of the\naveraged energy-momentum for high frequency gravitational waves is generalized\nto $f(R)$ gravity case. From the beginning it is assumed that an initial\nbackground could be arbitrary one. By next steps it is restricted to de Sitter\nspace that is a novelty for the study of a back-reaction in $f(R)$ gravity.\nConsideration of the de Sitter space as a background spacetime allows us to\nprovide the averaging procedure completely. Using the results on the de Sitter\nspace and generalizing the Isaacson procedure, we construct the averaged\nenergy-momentum on an additionally curved (averaged) background. Relations of\nparameters, which preserve the de Sitter picture, and which disturb it are\ngiven. Our results generalize results of previous authors who use flat\n(Minkowski) spacetime as the beginning background in $f(R)$ gravity.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-03T03:42:33Z"}
{"aid":"http://arxiv.org/abs/2504.02274v1","title":"Extended Hybridization Expansion Solver for Impurity Models with\n  Retarded Interactions","summary":"We extend the continuous-time hybridization expansion solver to a general\nform, where the hybridization function and retarded interaction are treated on\nequal footing. Correlation functions can now be directly obtained via\nfunctional derivatives with respect to the bosonic propagators, similar to the\nmeasurement of Green's functions. We devise a combinatorial scheme of measuring\nthe correlation function, whose efficiency partially emulates that of the\nGreen's function measurement. The algorithm and numerical methods are validated\nthrough application to an impurity model involving both electron-phonon\ncoupling and exchange interactions, a case where the previous hybridization\nexpansion algorithm is not applicable. Our improvement of the hybridization\nexpansion solver promotes its applicability in studies of electron-phonon\ncoupling, the extended dynamical mean field theory, and the dual boson method.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci","published":"2025-04-03T04:49:35Z"}
{"aid":"http://arxiv.org/abs/2504.02275v1","title":"Enhancing Customer Contact Efficiency with Graph Neural Networks in\n  Credit Card Fraud Detection Workflow","summary":"Credit card fraud has been a persistent issue since the last century, causing\nsignificant financial losses to the industry. The most effective way to prevent\nfraud is by contacting customers to verify suspicious transactions. However,\nwhile these systems are designed to detect fraudulent activity, they often\nmistakenly flag legitimate transactions, leading to unnecessary declines that\ndisrupt the user experience and erode customer trust. Frequent false positives\ncan frustrate customers, resulting in dissatisfaction, increased complaints,\nand a diminished sense of security. To address these limitations, we propose a\nfraud detection framework incorporating Relational Graph Convolutional Networks\n(RGCN) to enhance the accuracy and efficiency of identifying fraudulent\ntransactions. By leveraging the relational structure of transaction data, our\nmodel reduces the need for direct customer confirmation while maintaining high\ndetection performance. Our experiments are conducted using the IBM credit card\ntransaction dataset to evaluate the effectiveness of this approach.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T04:50:45Z"}
{"aid":"http://arxiv.org/abs/2504.02282v1","title":"Complete Minimal Surfaces in $\\mathbb{R}^4$ with Three Embedded Planar\n  Ends","summary":"In this paper, we study complete minimal surfaces in $\\mathbb{R}^4$ with\nthree embedded planar ends parallel to those of the union of the Lagrangian\ncatenoid and the plane passing through its waist circle. We show that any\ncomplete, oriented, immersed minimal surface in $\\mathbb{R}^4$ of finite total\ncurvature with genus $1$ and three such ends must be $J$-holomorphic for some\nalmost complex structure $J$. Under the additional assumptions of embeddedness\nand at least $8$ symmetries, we prove that the number of symmetries must be\neither $8$ or $12$, and in each case, the surface is uniquely determined up to\nrigid motions and scalings. Furthermore, we establish a nonexistence result for\ngenus $g\\geq2$ when the surface is embedded and has at least $4(g+1)$\nsymmetries. Our approach is based on a modification of the method of Costa and\nHoffman-Meeks in the setting of $\\mathbb{R}^4$, utilizing the generalized\nWeierstrass representation.","main_category":"math.DG","categories":"math.DG","published":"2025-04-03T05:08:10Z"}
{"aid":"http://arxiv.org/abs/2504.02284v1","title":"Non-perturbative heavy quark diffusion coefficients in a weakly\n  magnetized thermal QCD medium","summary":"In this work, the perturbative and non-perturbative contributions to the\nheavy quark (HQ) momentum ($\\kappa$) as well as spatial ($D_s$) diffusion\ncoefficients are computed in a weak background magnetic field. The formalism\nadopted here involves calculation of the in-medium potential of the HQ in a\nweak magnetic field, which then serves as a proxy for the resummed gluon\npropagator in the calculation of HQ self-energy ($\\Sigma$). The self-energy\ndetermines the scattering rate of HQs with light thermal partons, which is\nsubsequently used to evaluate $\\kappa$ and $D_s$. It is observed that\nnon-perturbative effects play a dominant role at low temperature. The spatial\ndiffusion coefficient $2\\pi T D_s$, exhibits good agreement with recent LQCD\nresults. These findings can be applied to calculate the heavy quark directed\nflow at RHIC and LHC energies. An extension of this formalism to the case of\nfinite HQ momentum has also been attempted.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-03T05:11:06Z"}
{"aid":"http://arxiv.org/abs/2504.02292v1","title":"Unifying Different Theories of Conformal Prediction","summary":"This paper presents a unified framework for understanding the methodology and\ntheory behind several different methods in the conformal prediction literature,\nwhich includes standard conformal prediction (CP), weighted conformal\nprediction (WCP), nonexchangeable conformal prediction (NexCP), and\nrandomly-localized conformal prediction (RLCP), among others. At the crux of\nour framework is the idea that conformal methods are based on revealing partial\ninformation about the data at hand, and positing a conditional distribution for\nthe data given the partial information. Different methods arise from different\nchoices of partial information, and of the corresponding (approximate)\nconditional distribution. In addition to recovering and unifying existing\nresults, our framework leads to both new theoretical guarantees for existing\nmethods, and new extensions of the conformal methodology.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-03T05:46:26Z"}
{"aid":"http://arxiv.org/abs/2504.02299v1","title":"Asymmetric graph alignment and the phase transition for asymmetric tree\n  correlation testing","summary":"Graph alignment - identifying node correspondences between two graphs - is a\nfundamental problem with applications in network analysis, biology, and privacy\nresearch. While substantial progress has been made in aligning correlated\nErd\\H{o}s-R\\'enyi graphs under symmetric settings, real-world networks often\nexhibit asymmetry in both node numbers and edge densities. In this work, we\nintroduce a novel framework for asymmetric correlated Erd\\H{o}s-R\\'enyi graphs,\ngeneralizing existing models to account for these asymmetries. We conduct a\nrigorous theoretical analysis of graph alignment in the sparse regime, where\nlocal neighborhoods exhibit tree-like structures. Our approach leverages tree\ncorrelation testing as the central tool in our polynomial-time algorithm,\nMPAlign, which achieves one-sided partial alignment under certain conditions.\n  A key contribution of our work is characterizing these conditions under which\nasymmetric tree correlation testing is feasible: If two correlated graphs $G$\nand $G'$ have average degrees $\\lambda s$ and $\\lambda s'$ respectively, where\n$\\lambda$ is their common density and $s,s'$ are marginal correlation\nparameters, their tree neighborhoods can be aligned if $ss' > \\alpha$, where\n$\\alpha$ denotes Otter's constant and $\\lambda$ is supposed large enough. The\nfeasibility of this tree comparison problem undergoes a sharp phase transition\nsince $ss' \\leq \\alpha$ implies its impossibility. These new results on tree\ncorrelation testing allow us to solve a class of random subgraph isomorphism\nproblems, resolving an open problem in the field.","main_category":"cs.IT","categories":"cs.IT,cs.DS,math.IT","published":"2025-04-03T06:10:00Z"}
{"aid":"http://arxiv.org/abs/2504.02306v1","title":"Lepton emission rates of 43-64V isotopes under stellar conditions","summary":"In astrophysical conditions prevalent during the late times of stellar\nevolution, lepton ($e^-$ and $e^+$) emission processes compete with the\ncorresponding lepton capture processes. Prior to the collapse, lepton emissions\nsignificantly affect the cooling of the core and reduce its entropy. Therefore,\nthe lepton emission rates for Fe-group nuclei serve as an important input for\ncore-collapse simulations of high-mass stars.\n  From earlier simulation studies, isotopes of vanadium (V) have great\nastrophysical significance in regard to their weak-decay rates, which\nsubstantially affect $Y_e$ (fraction of lepton to baryon number) during the\nfinal developmental stages of massive stars. The current study involves the\ncomputation of the weak lepton emission (LE) rates for V isotopes by employing\nthe improved deformed proton-neutron Quasi-particle Random Phase Approximation\n(pn-QRPA) model. The mass numbers of the selected isotopes range from 43 to 64.\nThe LE rates on these isotopes have been estimated for a broad spectrum of\ndensity and temperature under astrophysical conditions. The ranges considered\nfor density and temperature are $10^1$ to $10^{11}$ (g/cm$^3$) and $10^7$ to $3\n\\times 10^{11}$ (K), respectively.\n  The lepton emission rates from the present study were also compared to the\nrates previously estimated by using the independent-particle model (IPM) and\nlarge-scale shell model (LSSM). IPM rates are generally bigger than QRPA rates,\nwhile LSSM rates overall show a good comparison with the reported rates.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-03T06:31:19Z"}
{"aid":"http://arxiv.org/abs/2504.02321v1","title":"On shallow feedforward neural networks with inputs from a topological\n  space","summary":"We study feedforward neural networks with inputs from a topological space\n(TFNNs). We prove a universal approximation theorem for shallow TFNNs, which\ndemonstrates their capacity to approximate any continuous function defined on\nthis topological space. As an application, we obtain an approximative version\nof Kolmogorov's superposition theorem for compact metric spaces.","main_category":"cs.LG","categories":"cs.LG,math.FA","published":"2025-04-03T06:48:46Z"}
{"aid":"http://arxiv.org/abs/2504.02335v1","title":"Evaluating and Enhancing Segmentation Model Robustness with Metamorphic\n  Testing","summary":"Image segmentation is critical for applications such as medical imaging,\naugmented reality, and video surveillance. However, segmentation models often\nlack robustness, making them vulnerable to adversarial perturbations from\nsubtle image distortions. In this work, we propose SegRMT, a metamorphic\ntesting approach that leverages genetic algorithms (GA) to optimize sequences\nof spatial and spectral transformations while preserving image fidelity via a\npredefined PSNR threshold. Using the Cityscapes dataset, our method generates\nadversarial examples that effectively challenge the DeepLabV3 segmentation\nmodel. Our experiments show that SegRMT reduces DeepLabV3's mean Intersection\nover Union (mIoU) to 6.4%, outperforming other adversarial baselines that\ndecrease mIoU to between 8.5% and 21.7%. Furthermore, when used for adversarial\ntraining, SegRMT boosts model performance, achieving mIoU improvements up to\n73% on dedicated adversarial datasets and increasing cross-adversarial mIoU to\n53.8%, compared to only 2%-10% for other methods. These findings demonstrate\nthat SegRMT not only simulates realistic image distortions but also enhances\nthe robustness of segmentation models, making it a valuable tool for ensuring\nreliable performance in safety-critical applications.","main_category":"cs.CV","categories":"cs.CV,cs.SE","published":"2025-04-03T07:15:45Z"}
{"aid":"http://arxiv.org/abs/2504.02338v1","title":"Coronal and chromospheric activity of Teegarden's star","summary":"Teegarden's star is a late-type M-dwarf planet host, typically showing only\nrather low levels of activity. In this paper we present an extensive\ncharacterisation of this activity at photospheric, chromospheric, and coronal\nlevels. We specifically investigated TESS observations of Teegarden's star,\nwhich showed two very large flares with an estimated flare fluence between\n10$^{29}$ and 10$^{32}$\\,erg comparable to the largest solar flares. We\nfurthermore analysed nearly 300 CARMENES spectra and 11 ESPRESSO spectra\ncovering all the usually used chromospheric lines in the optical from the\n\\ion{Ca}{ii} H \\& K lines at 3930\\,\\AA\\, to the \\ion{He}{i} infrared triplet at\n10830\\,\\AA. These lines show different behaviour: The \\ion{He}{i} infrared\ntriplet is the only one absent in all spectra, some lines show up only during\nflares, and others are always present and highly variable. Specifically, the\nH$\\alpha$ line is more or less filled in during quiescence; however, the higher\nBalmer lines are still observed in emission. Many chromospheric lines show a\ncorrelation with H$\\alpha$ variability, which, in addition to stochastic\nbehaviour, also shows systematic behaviour on different timescales including\nthe rotation period. Moreover, we found several flares and also report hints of\nan erupting prominence, which may have led to a coronal mass ejection. Finally,\nwe present X-ray observations of Teegarden's star (i.e. a discovery pointing\nobtained with the \\emph{Chandra} observatory) and an extensive study with the\n\\emph{XMM-Newton} observatory; when these two large flares were observed, one\nof them showed clear signatures of the Neupert effect, suggesting the\nproduction of hard X-rays in the system.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-03T07:18:54Z"}
{"aid":"http://arxiv.org/abs/2504.02341v1","title":"Bergman spaces on algebraic curves","summary":"A theorem of Wiegerinck asserts that the Bergman space of an open subset of\nthe complex numbers is either infinite-dimensional or trivial. Recently, this\nhas been generalized to holomorphic vector bundles over the projective line by\nthe third author and later to vector bundles over any compact Riemann surface\nby Gallagher, Gupta and Vivas.\n  In the present paper we extend the above results to the case of certain\nsingular metrics associated to divisors on a Riemann surface. As corollaries we\nobtain versions of Wiegerinck's theorem for both projective and affine\nalgebraic curves.","main_category":"math.CV","categories":"math.CV","published":"2025-04-03T07:20:23Z"}
{"aid":"http://arxiv.org/abs/2504.02345v1","title":"SemiISP/SemiIE: Semi-Supervised Image Signal Processor and Image\n  Enhancement Leveraging One-to-Many Mapping sRGB-to-RAW","summary":"DNN-based methods have been successful in Image Signal Processor (ISP) and\nimage enhancement (IE) tasks. However, the cost of creating training data for\nthese tasks is considerably higher than for other tasks, making it difficult to\nprepare large-scale datasets. Also, creating personalized ISP and IE with\nminimal training data can lead to new value streams since preferred image\nquality varies depending on the person and use case. While semi-supervised\nlearning could be a potential solution in such cases, it has rarely been\nutilized for these tasks. In this paper, we realize semi-supervised learning\nfor ISP and IE leveraging a RAW image reconstruction (sRGB-to-RAW) method.\nAlthough existing sRGB-to-RAW methods can generate pseudo-RAW image datasets\nthat improve the accuracy of RAW-based high-level computer vision tasks such as\nobject detection, their quality is not sufficient for ISP and IE tasks that\nrequire precise image quality definition. Therefore, we also propose a\nsRGB-to-RAW method that can improve the image quality of these tasks. The\nproposed semi-supervised learning with the proposed sRGB-to-RAW method\nsuccessfully improves the image quality of various models on various datasets.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T07:28:16Z"}
{"aid":"http://arxiv.org/abs/2504.02346v1","title":"Repositioning, Ride-matching, and Abandonment in On-demand Ride-hailing\n  Platforms: A Mean Field Game Approach","summary":"The on-demand ride-hailing industry has experienced rapid growth,\ntransforming transportation norms worldwide. Despite improvements in efficiency\nover traditional taxi services, significant challenges remain, including\ndrivers' strategic repositioning behavior, customer abandonment, and\ninefficiencies in dispatch algorithms. To address these issues, we introduce a\ncomprehensive mean field game model that systematically analyzes the dynamics\nof ride-hailing platforms by incorporating driver repositioning across multiple\nregions, customer abandonment behavior, and platform dispatch algorithms. Using\nthis framework, we identify all possible mean field equilibria as the\nKarush-Kuhn-Tucker (KKT) points of an associated optimization problem. Our\nanalysis reveals the emergence of multiple equilibria, including the\ninefficient \"Wild Goose Chase\" one, characterized by drivers pursuing distant\nrequests, leading to suboptimal system performance. To mitigate these\ninefficiencies, we propose a novel two-matching-radius nearest-neighbor\ndispatch algorithm that eliminates undesirable equilibria and ensures a unique\nmean field equilibrium for multi-region systems. The algorithm dynamically\nadjusts matching radii based on driver supply rates, optimizing pick-up times\nand waiting times for drivers while maximizing request completion rates.\nNumerical experiments and simulation results show that our proposed algorithm\nreduces customer abandonment, minimizes waiting times for both customers and\ndrivers, and improves overall platform efficiency.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-03T07:31:08Z"}
{"aid":"http://arxiv.org/abs/2504.02351v1","title":"Agglomerating Large Vision Encoders via Distillation for VFSS\n  Segmentation","summary":"The deployment of foundation models for medical imaging has demonstrated\nconsiderable success. However, their training overheads associated with\ndownstream tasks remain substantial due to the size of the image encoders\nemployed, and the inference complexity is also significantly high. Although\nlightweight variants have been obtained for these foundation models, their\nperformance is constrained by their limited model capacity and suboptimal\ntraining strategies. In order to achieve an improved tradeoff between\ncomplexity and performance, we propose a new framework to improve the\nperformance of low complexity models via knowledge distillation from multiple\nlarge medical foundation models (e.g., MedSAM, RAD-DINO, MedCLIP), each\nspecializing in different vision tasks, with the goal to effectively bridge the\nperformance gap for medical image segmentation tasks. The agglomerated model\ndemonstrates superior generalization across 12 segmentation tasks, whereas\nspecialized models require explicit training for each task. Our approach\nachieved an average performance gain of 2\\% in Dice coefficient compared to\nsimple distillation.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-03T07:38:09Z"}
{"aid":"http://arxiv.org/abs/2504.02358v1","title":"Interference trapping of populations in a semi-infinite\n  coupled-resonator waveguide","summary":"We study the energy structure and dynamics of a two-level emitter (2LE)\nlocally coupled to a semi-infinite one-dimensional (1D) coupled-resonator array\n(CRA). The energy spectrum in the single-excitation subspace features a\ncontinuous band with scattering states, discrete levels with bound states, and\na quantum phase transition characterized by the change of the number of bound\nstates. The number of bound states is revealed by the behavior of the\nexcited-state population at long times with quantum beat, residual oscillation,\na constant with either non-zero or zero.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-03T07:45:42Z"}
{"aid":"http://arxiv.org/abs/2504.02359v1","title":"First observation of ultra-long-range azimuthal correlations in low\n  multiplicity pp and p-Pb collisions at the LHC","summary":"This study presents the first observation of ultra-long-range two-particle\nazimuthal correlations with pseudorapidity separation of ($|\\Delta \\eta| >\n5.0$) in proton-proton (pp) and ($|\\Delta \\eta| > 6.5$) in proton-lead (p-Pb)\ncollisions at the LHC, down to and below the minimum-bias multiplicity.\nTwo-particle correlation coefficients (${V}_{2\\Delta}$) are measured after\nremoving non-flow (jets and resonance decays) contributions using the\ntemplate-fit method across various multiplicity classes, providing novel\ninsights into the origin of long-range correlations in small systems.\nComparisons with the 3D-Glauber + MUSIC + UrQMD hydrodynamic model reveal\nsignificant discrepancies at low multiplicities, indicating possible dynamics\nbeyond typical hydrodynamic behavior. Initial-state models based on the Color\nGlass Condensate framework generate only short-range correlations, while PYTHIA\nsimulations implemented with the string-shoving mechanism also fail to describe\nthese ultra-long-range correlations. The results challenge existing paradigms\nand question the underlying mechanisms in low-multiplicity pp and p-Pb\ncollisions. The findings impose significant constraints on models describing\ncollective phenomena in small collision systems and advance the understanding\nof origin of long-range correlations at Large Hadron Collider (LHC) energies.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-03T07:46:09Z"}
{"aid":"http://arxiv.org/abs/2504.02361v1","title":"MG-Gen: Single Image to Motion Graphics Generation with Layer\n  Decomposition","summary":"General image-to-video generation methods often produce suboptimal animations\nthat do not meet the requirements of animated graphics, as they lack active\ntext motion and exhibit object distortion. Also, code-based animation\ngeneration methods typically require layer-structured vector data which are\noften not readily available for motion graphic generation. To address these\nchallenges, we propose a novel framework named MG-Gen that reconstructs data in\nvector format from a single raster image to extend the capabilities of\ncode-based methods to enable motion graphics generation from a raster image in\nthe framework of general image-to-video generation. MG-Gen first decomposes the\ninput image into layer-wise elements, reconstructs them as HTML format data and\nthen generates executable JavaScript code for the reconstructed HTML data. We\nexperimentally confirm that \\ours{} generates motion graphics while preserving\ntext readability and input consistency. These successful results indicate that\ncombining layer decomposition and animation code generation is an effective\nstrategy for motion graphics generation.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-03T07:52:12Z"}
{"aid":"http://arxiv.org/abs/2504.02362v1","title":"Brightness Perceiving for Recursive Low-Light Image Enhancement","summary":"Due to the wide dynamic range in real low-light scenes, there will be large\ndifferences in the degree of contrast degradation and detail blurring of\ncaptured images, making it difficult for existing end-to-end methods to enhance\nlow-light images to normal exposure. To address the above issue, we decompose\nlow-light image enhancement into a recursive enhancement task and propose a\nbrightness-perceiving-based recursive enhancement framework for high dynamic\nrange low-light image enhancement. Specifically, our recursive enhancement\nframework consists of two parallel sub-networks: Adaptive Contrast and Texture\nenhancement network (ACT-Net) and Brightness Perception network (BP-Net). The\nACT-Net is proposed to adaptively enhance image contrast and details under the\nguidance of the brightness adjustment branch and gradient adjustment branch,\nwhich are proposed to perceive the degradation degree of contrast and details\nin low-light images. To adaptively enhance images captured under different\nbrightness levels, BP-Net is proposed to control the recursive enhancement\ntimes of ACT-Net by exploring the image brightness distribution properties.\nFinally, in order to coordinate ACT-Net and BP-Net, we design a novel\nunsupervised training strategy to facilitate the training procedure. To further\nvalidate the effectiveness of the proposed method, we construct a new dataset\nwith a broader brightness distribution by mixing three low-light datasets.\nCompared with eleven existing representative methods, the proposed method\nachieves new SOTA performance on six reference and no reference metrics.\nSpecifically, the proposed method improves the PSNR by 0.9 dB compared to the\nexisting SOTA method.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-03T07:53:33Z"}
{"aid":"http://arxiv.org/abs/2504.02371v1","title":"Schur roots and tilting modules of acyclic quivers over commutative\n  rings","summary":"Let $Q$ be a finite acyclic quiver and $A_Q$ the cluster algebra of $Q$. It\nis well-known that for each field $k$, the additive equivalence classes of\nsupport tilting $kQ$-modules correspond bijectively with the clusters of $A_Q$.\nThe aim of this paper is to generalize this result to any ring indecomposable\ncommutative Noetherian ring $R$, that is, the additive equivalence classes of\n2-term silting complexes of $RQ$ correspond bijectively with the clusters of\n$A_Q$. As an application, for a Dynkin quiver $Q$, we prove that the torsion\nclasses of $\\mathrm{mod} RQ$ corresponds bijectively with the order preserving\nmaps from $\\mathrm{Spec} R$ to the set of clusters.","main_category":"math.RT","categories":"math.RT,math.AC,math.RA","published":"2025-04-03T08:04:24Z"}
{"aid":"http://arxiv.org/abs/2504.02375v1","title":"A Comparative Study of MINLP and MPVC Formulations for Solving Complex\n  Nonlinear Decision-Making Problems in Aerospace Applications","summary":"High-level decision-making for dynamical systems often involves performance\nand safety specifications that are activated or deactivated depending on\nconditions related to the system state and commands. Such decision-making\nproblems can be naturally formulated as optimization problems where these\nconditional activations are regulated by discrete variables. However, solving\nthese problems can be challenging numerically, even on powerful computing\nplatforms, especially when the dynamics are nonlinear. In this work, we\nconsider decision-making for nonlinear systems where certain constraints, as\nwell as possible terms in the cost function, are activated or deactivated\ndepending on the system state and commands. We show that these problems can be\nformulated either as mixed-integer nonlinear programs (MINLPs) or as\nmathematical programs with vanishing constraints (MPVCs), where the former\nformulation involves discrete decision variables, whereas the latter relies on\ncontinuous variables subject to structured nonconvex constraints. We discuss\nthe different solution methods available for both formulations and demonstrate\nthem on optimal trajectory planning problems in various aerospace applications.\nFinally, we compare the strengths and weaknesses of the MINLP and MPVC\napproaches through a focused case study on powered descent guidance with\ndivert-feasible regions.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-03T08:08:52Z"}
{"aid":"http://arxiv.org/abs/2504.02392v1","title":"Identifying misclassified meteor showers in the IAU MDC database.\n  Reclassification Proposal","summary":"The study of meteoroid streams reveals the full complexity of these\nstructures. At present, we have no objective method of deciding whether the\nparameters of the observed meteoroid stream represent a further solution to an\nalready known object or whether they relate to a new discovery. As result, the\nMeteor Data Center (MDC) database of the International Astronomical Union (IAU)\ncontains duplicates and false duplicates of the meteor showers.\n  It is desirable to detect questionable cases and, if possible, correct their\nstatus, thereby contributing to the improvement of the content of the IAU MDC\ndatabase. The correct content of the MDC database is important in its\napplications, for example, in assessing the threat from meteoroids to Earth's\nartificial satellites.\n  Two approaches were used, in the first the internal compatibility of\ngeocentric and heliocentric parameters representing a given flux was verified.\nIn the second, a comparison of two or more solutions of the same stream was\nmade in as much detail as possible. Fifty-six streams were verified, for which\nclear suspicion of misclassification was established in our earlier work.\n  For 43 streams, the misclassification was confirmed, with a proposal to\nchange their status in the MDC to autonomous. In the remaining 13 cases, it was\nproposed to leave their status unchanged.\n  Although we do not consider it 'definitive', our study clearly shows that\nrepeated misclassification of new meteoroid flux solutions has occurred in the\npast. Correction of these cases will significantly improve the content of the\nMDC database. As an additional product, based on the approach proposed in this\nand our earlier work, relevant procedures have been proposed, which, available\non the MDC database website, will make it possible to compare new meteoroid\ndata with the contents of the database, thereby avoiding errors in their\nclassification.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM","published":"2025-04-03T08:37:52Z"}
{"aid":"http://arxiv.org/abs/2504.02393v1","title":"Revealing the microscopic mechanism of deuteron formation at the LHC","summary":"The formation of light (anti)nuclei with mass number A of a few units (e.g.,\nd, $^3$He, and $^4$He) in high-energy hadronic collisions presents a\nlongstanding mystery in nuclear physics [1,2]. It is not clear how nuclei bound\nby a few MeV can emerge in environments characterized by temperatures above 100\nMeV [3-5], about 100,000 times hotter than the center of the Sun. Despite\nextensive studies, this question remained unanswered. The ALICE Collaboration\nnow addresses it with a novel approach using deuteron-pion momentum\ncorrelations in proton-proton (pp) collisions at the Large Hadron Collider\n(LHC). Our results provide model-independent evidence that about 80% of the\nobserved (anti)deuterons are produced in nuclear fusion reactions [6] following\nthe decay of short-lived resonances, such as the $\\Delta (1232)$. These\nfindings resolve a crucial gap in our understanding of nucleosynthesis in\nhadronic collisions. Beyond answering the fundamental question on how nuclei\nare formed in hadronic collisions, the results can be employed in the modeling\nof the production of light and heavy nuclei in cosmic rays [7] and dark matter\ndecays [8,9].","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-03T08:40:57Z"}
{"aid":"http://arxiv.org/abs/2504.02400v1","title":"The model example of wave equation with oscillating scale-invariant\n  damping","summary":"We analyze a simple example of wave equation with a time-dependent damping\nterm, whose coefficient decays at infinity at the scale-invariant rate and\nincludes an oscillatory component that is integrable but not absolutely\nintegrable.\n  We show that the oscillations in the damping coefficient induce a resonance\neffect with a fundamental solution of the elastic term, altering the energy\ndecay rate of solutions. In particular, some solutions exhibit slower decay\ncompared to the case without the oscillatory component.\n  Our proof relies on Fourier analysis and a representation of solutions in\npolar coordinates, reducing the problem to a detailed study of the asymptotic\nbehavior of solutions to a family of ordinary differential equations and\nsuitable oscillatory integrals.","main_category":"math.AP","categories":"math.AP","published":"2025-04-03T08:50:23Z"}
{"aid":"http://arxiv.org/abs/2504.02410v1","title":"Limits of group algebras for growing symmetric groups and wreath\n  products","summary":"Let $S(\\infty)$ denote the infinite symmetric group formed by the finitary\npermutations of the set of natural numbers; this is a countable group. We\nintroduce its virtual group algebra, a completion of the conventional group\nalgebra $\\mathbb C[S(\\infty)]$. The virtual group algebra is obtained by taking\nlarge-$n$ limits of the finite-dimensional group algebras $\\mathbb C[S(n)]$ in\nthe so-called tame representations of $S(\\infty)$. We establish a connection\nwith the centralizer construction of Molev-Olshanski [J. Algebra, 237 (2001),\n302-341; arXiv:math/0002165] and Drinfeld-Lusztig degenerate affine Hecke\nalgebras. This makes it possible to describe the structure of the virtual group\nalgebra. Then we extend the results to wreath products $G\\wr S(\\infty)$ with\narbitrary finite groups $G$.","main_category":"math.RT","categories":"math.RT,math.RA","published":"2025-04-03T09:00:58Z"}
{"aid":"http://arxiv.org/abs/2504.02411v1","title":"Adapting Large Language Models for Multi-Domain\n  Retrieval-Augmented-Generation","summary":"Retrieval-Augmented Generation (RAG) enhances LLM factuality, but\nmulti-domain applications face challenges like lack of diverse benchmarks and\npoor out-of-domain generalization. The first contribution of this work is to\nintroduce a diverse benchmark comprising a variety of question-answering tasks\nfrom 8 sources and covering 13 domains. Our second contribution consists in\nsystematically testing out-of-domain generalization for typical RAG tuning\nstrategies. While our findings reveal that standard fine-tuning fails to\ngeneralize effectively, we show that sequence-level distillation with\nteacher-generated labels improves out-of-domain performance by providing more\ncoherent supervision. Our findings highlight key strategies for improving\nmulti-domain RAG robustness.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T09:03:40Z"}
{"aid":"http://arxiv.org/abs/2504.02412v1","title":"Bridging the Theoretical Gap in Randomized Smoothing","summary":"Randomized smoothing has become a leading approach for certifying adversarial\nrobustness in machine learning models. However, a persistent gap remains\nbetween theoretical certified robustness and empirical robustness accuracy.\nThis paper introduces a new framework that bridges this gap by leveraging\nLipschitz continuity for certification and proposing a novel, less conservative\nmethod for computing confidence intervals in randomized smoothing. Our approach\ntightens the bounds of certified robustness, offering a more accurate\nreflection of model robustness in practice. Through rigorous experimentation we\nshow that our method improves the robust accuracy, compressing the gap between\nempirical findings and previous theoretical results. We argue that\ninvestigating local Lipschitz constants and designing ad-hoc confidence\nintervals can further enhance the performance of randomized smoothing. These\nresults pave the way for a deeper understanding of the relationship between\nLipschitz continuity and certified robustness.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-03T09:05:49Z"}
{"aid":"http://arxiv.org/abs/2504.02429v1","title":"A Multi-Level Sentiment Analysis Framework for Financial Texts","summary":"Existing financial sentiment analysis methods often fail to capture the\nmulti-faceted nature of risk in bond markets due to their single-level approach\nand neglect of temporal dynamics. We propose Multi-Level Sentiment Analysis\nbased on pre-trained language models (PLMs) and large language models (LLMs), a\nnovel framework that systematically integrates firm-specific micro-level\nsentiment, industry-specific meso-level sentiment, and duration-aware smoothing\nto model the latency and persistence of textual impact. Applying our framework\nto the comprehensive Chinese bond market corpus constructed by us (2013-2023,\n1.39M texts), we extracted a daily composite sentiment index. Empirical results\nshow statistically measurable improvements in credit spread forecasting when\nincorporating sentiment (3.25% MAE and 10.96% MAPE reduction), with sentiment\nshifts closely correlating with major social risk events and firm-specific\ncrises. This framework provides a more nuanced understanding of sentiment\nacross different market levels while accounting for the temporal evolution of\nsentiment effects.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-03T09:35:07Z"}
{"aid":"http://arxiv.org/abs/2504.02440v1","title":"HGFormer: Topology-Aware Vision Transformer with HyperGraph Learning","summary":"The computer vision community has witnessed an extensive exploration of\nvision transformers in the past two years. Drawing inspiration from traditional\nschemes, numerous works focus on introducing vision-specific inductive biases.\nHowever, the implicit modeling of permutation invariance and fully-connected\ninteraction with individual tokens disrupts the regional context and spatial\ntopology, further hindering higher-order modeling. This deviates from the\nprinciple of perceptual organization that emphasizes the local groups and\noverall topology of visual elements. Thus, we introduce the concept of\nhypergraph for perceptual exploration. Specifically, we propose a\ntopology-aware vision transformer called HyperGraph Transformer (HGFormer).\nFirstly, we present a Center Sampling K-Nearest Neighbors (CS-KNN) algorithm\nfor semantic guidance during hypergraph construction. Secondly, we present a\ntopology-aware HyperGraph Attention (HGA) mechanism that integrates hypergraph\ntopology as perceptual indications to guide the aggregation of global and\nunbiased information during hypergraph messaging. Using HGFormer as visual\nbackbone, we develop an effective and unitive representation, achieving\ndistinct and detailed scene depictions. Empirical experiments show that the\nproposed HGFormer achieves competitive performance compared to the recent SoTA\ncounterparts on various visual benchmarks. Extensive ablation and visualization\nstudies provide comprehensive explanations of our ideas and contributions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T09:58:01Z"}
{"aid":"http://arxiv.org/abs/2504.02443v1","title":"Language-Integrated Recursive Queries","summary":"Performance-critical industrial applications, including large-scale program,\nnetwork, and distributed system analyses, rely on fixed-point computations. The\nintroduction of recursive common table expressions (CTEs) using the WITH\nRECURSIVE keyword in SQL:1999 extended the ability of relational database\nsystems to handle fixed-point computations, unlocking significant performance\nadvantages by allowing computation to move closer to the data. Yet with\nrecursion, SQL becomes a Turing-complete programming language and, with that,\nunrecoverable safety and correctness risks. SQL itself lacks a fixed semantics,\nas the SQL specification is written in natural language, full of ambiguities\nthat database vendors resolve in divergent ways. As a result, reasoning about\nthe correctness of recursive SQL programs must rely on isolated mathematical\nproperties of queries rather than wrestling a unified formal model out of a\nlanguage with notoriously inconsistent semantics. To address these challenges,\nwe propose a calculus that automatically derives mathematical properties from\nembedded recursive queries and, depending on the database backend, rejects\nqueries that may lead to the three classes of recursive query errors - database\nerrors, incorrect results, and non-termination. We introduce TyQL, a practical\nimplementation in Scala for safe, recursive language-integrated query. Using\nNamed-Tuples and type-level pattern matching, TyQL ensures query portability\nand safety, showing no performance penalty compared to raw SQL strings while\nunlocking a three-orders-of-magnitude speedup over non-recursive SQL queries.","main_category":"cs.PL","categories":"cs.PL","published":"2025-04-03T09:58:52Z"}
{"aid":"http://arxiv.org/abs/2504.02452v1","title":"Thermo-optic bistability in 2D all-dielectric resonators","summary":"We consider thermo-optic bistability in resonant excitation of high-quality\nmodes in two-dimensional dielectric resonators. We develop a coupled-mode\ntheory approach which account for the frequency shift due to a temperature\ndependent dielectric permittivity. The model is applied to rectangular and\nhexagonal resonators supporting an isolated high-quality resonant mode. The\nresults are verified in comparison with straightforward finite-element\nsimulations. It is shown that the model accurately describes the effect\nbistabily which occurs under variation of the angle of incidence or the\nintensity of the incident wave. In particular, it is demonstrated that\nvariation of the incident angle can optimize the coupling between the resonator\nand the incident waves leading to bistabily with low intensity incident waves\n$W_0 = 0.35 {\\rm \\mu W/\\mu m}^2$. The bistability threshold is shown to be\nextremely sensitive to the imaginary part of the dielectric permittivity\n$\\epsilon''$.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-03T10:16:28Z"}
{"aid":"http://arxiv.org/abs/2504.02470v1","title":"Impact of Global Warming on Extreme Rainfall in Taiwan","summary":"The relationship between global warming and extreme rainfalls in Taiwan was\nexamined in this study. Taiwan rainfall data from TCCIP, a project led by MOST,\nwere analyzed. North Hemisphere reference temperature data from NCEI led by\nNOAA. The yearly maximum of daily rainfall was focused on and the PGEV model,\nas proposed by Olafsdottir et al. \\citep{olafsdottir2021extreme}, was used to\nfit the extreme values and make inferences. The PGEV model integrates the\nGeneral Extreme Value (GEV) and Peak over Threshold (PoT) approaches, which are\ncommonly used to analyze extreme data. Relative intensity and return value were\nused to show the connection between temperature and extreme rainfall.\n  Results indicated that the intensity of extreme rainfall in Taiwan increases\nas the temperature rises. However, the effects of global warming on the\nfrequency and intensity of extreme rainfalls varied by region. In the north and\nsouth regions, the frequency of extreme rainfalls changed, while in the center\nand east regions, the intensity of extreme rainfalls changed. Furthermore,\naccording to the return value analysis, extreme rainfalls are likely to occur\nmore frequently in the future.\n  To account for differences between locations, Gaussian Process was used to\nsmooth the results obtained using the PGEV model. In addition, simulations\nusing the Gaussian copula and Gaussian Process were conducted to determine the\nquantile confidence intervals for each PGEV model. The simulations showed that\nall tests comparing with models with and without covariates are significant.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-03T10:44:32Z"}
{"aid":"http://arxiv.org/abs/2504.02473v1","title":"Adaptive path planning for efficient object search by UAVs in\n  agricultural fields","summary":"This paper presents an adaptive path planner for object search in\nagricultural fields using UAVs. The path planner uses a high-altitude coverage\nflight path and plans additional low-altitude inspections when the detection\nnetwork is uncertain. The path planner was evaluated in an offline simulation\nenvironment containing real-world images. We trained a YOLOv8 detection network\nto detect artificial plants placed in grass fields to showcase the potential of\nour path planner. We evaluated the effect of different detection certainty\nmeasures, optimized the path planning parameters, investigated the effects of\nlocalization errors and different numbers of objects in the field. The YOLOv8\ndetection confidence worked best to differentiate between true and false\npositive detections and was therefore used in the adaptive planner. The optimal\nparameters of the path planner depended on the distribution of objects in the\nfield, when the objects were uniformly distributed, more low-altitude\ninspections were needed compared to a non-uniform distribution of objects,\nresulting in a longer path length. The adaptive planner proved to be robust\nagainst localization uncertainty. When increasing the number of objects, the\nflight path length increased, especially when the objects were uniformly\ndistributed. When the objects were non-uniformly distributed, the adaptive path\nplanner yielded a shorter path than a low-altitude coverage path, even with\nhigh number of objects. Overall, the presented adaptive path planner allowed to\nfind non-uniformly distributed objects in a field faster than a coverage path\nplanner and resulted in a compatible detection accuracy. The path planner is\nmade available at https://github.com/wur-abe/uav_adaptive_planner.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-03T10:47:31Z"}
{"aid":"http://arxiv.org/abs/2504.02478v1","title":"MG-MotionLLM: A Unified Framework for Motion Comprehension and\n  Generation across Multiple Granularities","summary":"Recent motion-aware large language models have demonstrated promising\npotential in unifying motion comprehension and generation. However, existing\napproaches primarily focus on coarse-grained motion-text modeling, where text\ndescribes the overall semantics of an entire motion sequence in just a few\nwords. This limits their ability to handle fine-grained motion-relevant tasks,\nsuch as understanding and controlling the movements of specific body parts. To\novercome this limitation, we pioneer MG-MotionLLM, a unified motion-language\nmodel for multi-granular motion comprehension and generation. We further\nintroduce a comprehensive multi-granularity training scheme by incorporating a\nset of novel auxiliary tasks, such as localizing temporal boundaries of motion\nsegments via detailed text as well as motion detailed captioning, to facilitate\nmutual reinforcement for motion-text modeling across various levels of\ngranularity. Extensive experiments show that our MG-MotionLLM achieves superior\nperformance on classical text-to-motion and motion-to-text tasks, and exhibits\npotential in novel fine-grained motion comprehension and editing tasks. Project\npage: CVI-SZU/MG-MotionLLM","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T10:53:41Z"}
{"aid":"http://arxiv.org/abs/2504.02480v1","title":"Graph Attention-Driven Bayesian Deep Unrolling for Dual-Peak\n  Single-Photon Lidar Imaging","summary":"Single-photon Lidar imaging offers a significant advantage in 3D imaging due\nto its high resolution and long-range capabilities, however it is challenging\nto apply in noisy environments with multiple targets per pixel. To tackle these\nchallenges, several methods have been proposed. Statistical methods demonstrate\ninterpretability on the inferred parameters, but they are often limited in\ntheir ability to handle complex scenes. Deep learning-based methods have shown\nsuperior performance in terms of accuracy and robustness, but they lack\ninterpretability or they are limited to a single-peak per pixel. In this paper,\nwe propose a deep unrolling algorithm for dual-peak single-photon Lidar\nimaging. We introduce a hierarchical Bayesian model for multiple targets and\npropose a neural network that unrolls the underlying statistical method. To\nsupport multiple targets, we adopt a dual depth maps representation and exploit\ngeometric deep learning to extract features from the point cloud. The proposed\nmethod takes advantages of statistical methods and learning-based methods in\nterms of accuracy and quantifying uncertainty. The experimental results on\nsynthetic and real data demonstrate the competitive performance when compared\nto existing methods, while also providing uncertainty information.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-03T10:57:26Z"}
{"aid":"http://arxiv.org/abs/2504.02481v1","title":"Revealing the harmonic structure of nuclear two-body correlations in\n  high-energy heavy-ion collisions","summary":"Smashing nuclei at ultrarelativistic speeds and analyzing the momentum\ndistribution of outgoing debris provides a powerful method to probe the\nmany-body properties of the incoming nuclear ground states. Within a\nperturbative description of initial-state fluctuations in the quark-gluon\nplasma, we express the measurement of anisotropic flow in ultra-central\nheavy-ion collisions as the quantum-mechanical average of a specific set of\noperators measuring the harmonic structure of the two-body azimuthal\ncorrelations among nucleons in the colliding states. These observables shed a\nnew light on spatial correlations in atomic nuclei, while enabling us to test\nthe complementary pictures of nuclear structure delivered by low- and\nhigh-energy experiments on the basis of state-of-the-art theoretical approaches\nrooted in quantum chromodynamics.","main_category":"nucl-th","categories":"nucl-th,hep-ex,hep-ph,nucl-ex","published":"2025-04-03T10:59:21Z"}
{"aid":"http://arxiv.org/abs/2504.02482v1","title":"Berry-Esseen bound for the Moment Estimation of the fractional\n  Ornstein-Uhlenbeck model under fixed step size discrete observations","summary":"Let the Ornstein-Uhlenbeck process $\\{X_t,\\,t\\geq 0\\}$ driven by a fractional\nBrownian motion $B^H$ described by $d X_t=-\\theta X_t dt+ d B_t^H,\\, X_0=0$\nwith known parameter $H\\in (0,\\frac34)$ be observed at discrete time instants\n$t_k=kh, k=1,2,\\dots, n $. If $\\theta>0$ and if the step size $h>0$ is\narbitrarily fixed, we derive Berry-Ess\\'{e}en bound for the ergodic type\nestimator (or say the moment estimator) $\\hat{\\theta}_n$, i.e., the Kolmogorov\ndistance between the distribution of $\\sqrt{n}(\\hat{\\theta}_n-\\theta)$ and its\nlimit distribution is bounded by a constant $C_{\\theta, H,h}$ times\n$n^{-\\frac12}$ and $ n^{4H-3}$ when $H\\in (0,\\,\\frac58]$ and $H\\in\n(\\frac58,\\,\\frac34)$, respectively. This result greatly improve the previous\nresult in literature where $h$ is forced to go zero. Moreover, we extend the\nBerry-Esseen bound to the Ornstein-Uhlenbeck model driven by a lot of Gaussian\nnoises such as the sub-bifractional Brownian motion and others. A few ideas of\nthe present paper come from Haress and Hu (2021), Sottinen and Viitasaari\n(2018), and Chen and Zhou (2021).","main_category":"math.PR","categories":"math.PR","published":"2025-04-03T11:01:35Z"}
{"aid":"http://arxiv.org/abs/2504.02494v1","title":"Semiconductor Wafer Map Defect Classification with Tiny Vision\n  Transformers","summary":"Semiconductor wafer defect classification is critical for ensuring high\nprecision and yield in manufacturing. Traditional CNN-based models often\nstruggle with class imbalances and recognition of the multiple overlapping\ndefect types in wafer maps. To address these challenges, we propose ViT-Tiny, a\nlightweight Vision Transformer (ViT) framework optimized for wafer defect\nclassification. Trained on the WM-38k dataset. ViT-Tiny outperforms its\nViT-Base counterpart and state-of-the-art (SOTA) models, such as MSF-Trans and\nCNN-based architectures. Through extensive ablation studies, we determine that\na patch size of 16 provides optimal performance. ViT-Tiny achieves an F1-score\nof 98.4%, surpassing MSF-Trans by 2.94% in four-defect classification,\nimproving recall by 2.86% in two-defect classification, and increasing\nprecision by 3.13% in three-defect classification. Additionally, it\ndemonstrates enhanced robustness under limited labeled data conditions, making\nit a computationally efficient and reliable solution for real-world\nsemiconductor defect detection.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-03T11:18:00Z"}
{"aid":"http://arxiv.org/abs/2504.02506v1","title":"Secrecy Performance of a Keyhole-based Multi-user System with Multiple\n  Eavesdroppers","summary":"This paper investigates the secrecy performance of a keyhole-aided multi-user\ncommunication network in the presence of multiple eavesdroppers. The\ncommunication happens through the same keyhole for legitimate users and\neavesdroppers. In this context, the secrecy performance is evaluated for a user\nscheduling technique by obtaining the exact closed-form expression of secrecy\noutage probability (SOP). Further, a simplified asymptotic SOP expression is\nderived assuming high signal-to-noise ratio (SNR) scenario for a better\nunderstanding of the impact of system parameters. The effect of the keyhole\nparameters, number of users, number of eavesdroppers, and threshold secrecy\nrate on the SOP performance are also investigated for the considered system\nmodel. In the high-SNR regime, the asymptotic SOP saturates to a constant value\nand does not depend on the keyhole parameter and the channel parameter of the\nsource-to-keyhole channel.","main_category":"eess.SP","categories":"eess.SP,cs.SY,eess.SY","published":"2025-04-03T11:38:08Z"}
{"aid":"http://arxiv.org/abs/2504.02509v1","title":"A Memory-Augmented LLM-Driven Method for Autonomous Merging of 3D\n  Printing Work Orders","summary":"With the rapid development of 3D printing, the demand for personalized and\ncustomized production on the manufacturing line is steadily increasing.\nEfficient merging of printing workpieces can significantly enhance the\nprocessing efficiency of the production line. Addressing the challenge, a Large\nLanguage Model (LLM)-driven method is established in this paper for the\nautonomous merging of 3D printing work orders, integrated with a\nmemory-augmented learning strategy. In industrial scenarios, both device and\norder features are modeled into LLM-readable natural language prompt templates,\nand develop an order-device matching tool along with a merging interference\nchecking module. By incorporating a self-memory learning strategy, an\nintelligent agent for autonomous order merging is constructed, resulting in\nimproved accuracy and precision in order allocation. The proposed method\neffectively leverages the strengths of LLMs in industrial applications while\nreducing hallucination.","main_category":"cs.AI","categories":"cs.AI,cs.RO","published":"2025-04-03T11:50:29Z"}
{"aid":"http://arxiv.org/abs/2504.02523v1","title":"Denoising medium resolution stellar spectra with U-Net convolutional\n  neural networks","summary":"We investigated the use of a U-Net convolutional neural network for denoising\nsimulated medium-resolution spectroscopic observations of stars. Simulated\nspectra were generated under realistic observational conditions resembling the\nSubaru Prime Focus Spectrograph (PFS). We found that our U-Net model\neffectively captured spectral features, achieving an average relative error of\naround $1\\%$ across a broad range of stellar parameters, despite a limited\ntraining set of only $1000$ observations and a relatively short training\nperiod. Although U-Net did not reach the performance previously demonstrated by\nfully-connected denoising autoencoders (DAEs) consisting of dense layers and\ntrained extensively on larger datasets, it outperformed dense networks trained\nunder similarly constrained conditions. These results indicate that the U-Net\narchitecture offers rapid, robust feature learning and may be particularly\nadvantageous in scenarios involving initial denoising, subsequently refined by\nmore accurate, but otherwise slower deep-learning models.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.SR","published":"2025-04-03T12:27:14Z"}
{"aid":"http://arxiv.org/abs/2504.02526v1","title":"Improving User Experience with FAICO: Towards a Framework for AI\n  Communication in Human-AI Co-Creativity","summary":"How AI communicates with humans is crucial for effective human-AI\nco-creation. However, many existing co-creative AI tools cannot communicate\neffectively, limiting their potential as collaborators. This paper introduces\nour initial design of a Framework for designing AI Communication (FAICO) for\nco-creative AI based on a systematic review of 107 full-length papers. FAICO\npresents key aspects of AI communication and their impacts on user experience\nto guide the design of effective AI communication. We then show actionable ways\nto translate our framework into two practical tools: design cards for designers\nand a configuration tool for users. The design cards enable designers to\nconsider AI communication strategies that cater to a diverse range of users in\nco-creative contexts, while the configuration tool empowers users to customize\nAI communication based on their needs and creative workflows. This paper\ncontributes new insights within the literature on human-AI co-creativity and\nHuman-Computer Interaction, focusing on designing AI communication to enhance\nuser experience.","main_category":"cs.HC","categories":"cs.HC,cs.AI","published":"2025-04-03T12:29:53Z"}
{"aid":"http://arxiv.org/abs/2504.02530v1","title":"Statistical parameter identification of mixed-mode patterns from a\n  single experimental snapshot","summary":"Parameter identification in pattern formation models from a single\nexperimental snapshot is challenging, as traditional methods often require\nknowledge of initial conditions or transient dynamics -- data that are\nfrequently unavailable in experimental settings. In this study, we extend the\nrecently developed statistical approach, Correlation Integral Likelihood (CIL)\nmethod to enable robust parameter identification from a single snapshot of an\nexperimental pattern. Using the chlorite-iodite-malonic acid (CIMA) reaction --\na well-studied system that produces Turing patterns -- as a test case, we\naddress key experimental challenges such as measurement noise, model-data\ndiscrepancies, and the presence of mixed-mode patterns, where different spatial\nstructures (e.g., coexisting stripes and dots) emerge under the same\nconditions. Numerical experiments demonstrate that our method accurately\nestimates model parameters, even with incomplete or noisy data. This approach\nlays the groundwork for future applications in developmental biology, chemical\nreaction modelling, and other systems with heterogeneous output.","main_category":"math.AP","categories":"math.AP","published":"2025-04-03T12:33:56Z"}
{"aid":"http://arxiv.org/abs/2504.02537v1","title":"Blockchain and Distributed Ledger Technologies for Cyberthreat\n  Intelligence Sharing","summary":"Cyberthreat intelligence sharing is a critical aspect of cybersecurity, and\nit is essential to understand its definition, objectives, benefits, and impact\non society. Blockchain and Distributed Ledger Technology (DLT) are emerging\ntechnologies that have the potential to transform intelligence sharing. This\npaper aims to provide a comprehensive understanding of intelligence sharing and\nthe role of blockchain and DLT in enhancing it. The paper addresses questions\nrelated to the definition, objectives, benefits, and impact of intelligence\nsharing and provides a review of the existing literature. Additionally, the\npaper explores the challenges associated with blockchain and DLT and their\npotential impact on security and privacy. The paper also discusses the use of\nDLT and blockchain in security and intelligence sharing and highlights the\nassociated challenges and risks. Furthermore, the paper examines the potential\nimpact of a National Cybersecurity Strategy on addressing cybersecurity risks.\nFinally, the paper explores the experimental set up required for implementing\nblockchain and DLT for intelligence sharing and discusses the curricular\nramifications of intelligence sharing.","main_category":"cs.CR","categories":"cs.CR,cs.DC","published":"2025-04-03T12:38:42Z"}
{"aid":"http://arxiv.org/abs/2504.02544v1","title":"Fourier Sliced-Wasserstein Embedding for Multisets and Measures","summary":"We present the Fourier Sliced-Wasserstein (FSW) embedding - a novel method to\nembed multisets and measures over $\\mathbb{R}^d$ into Euclidean space.\n  Our proposed embedding approximately preserves the sliced Wasserstein\ndistance on distributions, thereby yielding geometrically meaningful\nrepresentations that better capture the structure of the input. Moreover, it is\ninjective on measures and bi-Lipschitz on multisets - a significant advantage\nover prevalent methods based on sum- or max-pooling, which are provably not\nbi-Lipschitz, and, in many cases, not even injective. The required output\ndimension for these guarantees is near-optimal: roughly $2 N d$, where $N$ is\nthe maximal input multiset size.\n  Furthermore, we prove that it is impossible to embed distributions over\n$\\mathbb{R}^d$ into Euclidean space in a bi-Lipschitz manner. Thus, the metric\nproperties of our embedding are, in a sense, the best possible.\n  Through numerical experiments, we demonstrate that our method yields superior\nmultiset representations that improve performance in practical learning tasks.\nSpecifically, we show that (a) a simple combination of the FSW embedding with\nan MLP achieves state-of-the-art performance in learning the (non-sliced)\nWasserstein distance; and (b) replacing max-pooling with the FSW embedding\nmakes PointNet significantly more robust to parameter reduction, with only\nminor performance degradation even after a 40-fold reduction.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-03T12:51:40Z"}
{"aid":"http://arxiv.org/abs/2504.02550v1","title":"Enhanced Permeability Estimation in Microporous Rocks Using a Hybrid\n  Macropore-Darcy Approach","summary":"This study presents a novel workflow for constructing hybrid macropore-Darcy\nmodels from micro-CT images of microporous rocks. In our approach, macropore\nnetworks are extracted using established methods, while the microporosity is\ncharacterised through segmented phase classification and incorporated into the\nmodel as Darcy cells. Effectively, Darcy cells capture the micro scale\nconnectivity variations that are missing in the macroscopic networks. This dual\nentity model thus incorporates both the conventional macroscopic pore structure\nand the critical flow pathways present in the under-resolved microporous\nregions. The proposed workflow is rigorously validated by comparing the\npermeability estimates with direct numerical simulation (DNS) results and\nexperimental measurements. Our findings demonstrate that this hybrid approach\nreliably reproduces fluid flow behaviour in complex porous media while\nsignificantly reducing computational demands, offering a promising tool for\nadvanced groundwater modelling and water resource management.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-03T13:05:31Z"}
{"aid":"http://arxiv.org/abs/2504.02551v1","title":"Human-Centered Development of an Explainable AI Framework for Real-Time\n  Surgical Risk Surveillance","summary":"Background: Artificial Intelligence (AI) clinical decision support (CDS)\nsystems have the potential to augment surgical risk assessments, but successful\nadoption depends on an understanding of end-user needs and current workflows.\nThis study reports the initial co-design of MySurgeryRisk, an AI CDS tool to\npredict the risk of nine post-operative complications in surgical patients.\nMethods: Semi-structured focus groups and interviews were held as co-design\nsessions with perioperative physicians at a tertiary academic hospital in the\nSoutheastern United States. Participants were read a surgical vignette and\nasked questions to elicit an understanding of their current decision-making\npractices before being introduced to the MySurgeryRisk prototype web interface.\nThey were asked to provide feedback on the user interface and system features.\nSession transcripts were qualitatively coded, after which thematic analysis\ntook place. Results: Data saturation was reached after 20 surgeons and\nanesthesiologists from varying career stages participated across 11 co-design\nsessions. Thematic analysis resulted in five themes: (1) decision-making\ncognitive processes, (2) current approach to decision-making, (3) future\napproach to decision-making with MySurgeryRisk, (4) feedback on current\nMySurgeryRisk prototype, and (5) trustworthy considerations. Conclusion:\nClinical providers perceived MySurgeryRisk as a promising CDS tool that factors\nin a large volume of data and is computed in real-time without any need for\nmanual input. Participants provided feedback on the design of the interface and\nimaged applications of the tool in the clinical workflow. However, its\nsuccessful implementation will depend on its actionability and explainability\nof model outputs, integration into current electronic systems, and calibration\nof trust among end-users.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-03T13:05:46Z"}
{"aid":"http://arxiv.org/abs/2504.02561v1","title":"Digital Twins for Internet of Battlespace Things (IoBT) Coalitions","summary":"This paper presents a new framework for integrating Digital Twins (DTs)\nwithin Internet of battlespace Things (IoBT) coalitions. We introduce a novel\nthree-tier architecture that enables efficient coordination and management of\nDT models across coalition partners while addressing key challenges in\ninteroperability, security, and resource allocation. The architecture comprises\nspecialized controllers at each tier: Digital Twin Coalition Partner (DTCP)\ncontrollers managing individual coalition partners' DT resources, a central\nDigital Twin Coalition(DTC) controller orchestrating cross-partner\ncoordination, and Digital Twin Coalition Mission (DTCP) controllers handling\nmission-specific DT interactions. We propose a hybrid approach for DT model\nplacement across edge devices, tactical nodes, and cloud infrastructure,\noptimizing performance while maintaining security and accessibility. The\narchitecture leverages software-defined networking principles for dynamic\nresource allocation and slice management, enabling efficient sharing of\ncomputational and network resources between DT operations and primary IoBT\nfunctions. Our proposed framework aims to provide a robust foundation for\ndeploying and managing Digital Twins in coalition warfare, enhancing\nsituational awareness, decision-making capabilities, and operational\neffectiveness while ensuring secure and interoperable operations across diverse\ncoalition partners.","main_category":"cs.NI","categories":"cs.NI,cs.SY,eess.SY","published":"2025-04-03T13:23:44Z"}
{"aid":"http://arxiv.org/abs/2504.02574v1","title":"Quasi-periodic moirÃ© patterns and dimensional localization in\n  three-dimensional quasi-moirÃ© crystals","summary":"Recent advances in spin-dependent optical lattices [Meng et al., Nature\n\\textbf{615}, 231 (2023)] have enabled the experimental implementation of two\nsuperimposed three-dimensional lattices, presenting new opportunities to\ninvestigate \\textit{three-dimensional moir\\'{e} physics} in ultracold atomic\ngases. This work studies the moir\\'{e} physics of atoms within a spin-dependent\ncubic lattice with relative twists along different directions. It is discovered\nthat dimensionality significantly influences the low-energy moir\\'{e} physics.\nFrom a geometric perspective, this manifests in the observation that moir\\'{e}\npatterns, generated by rotating lattices along different axes, can exhibit\neither periodic or quasi-periodic behavior--a feature not present in\ntwo-dimensional systems. We develop a low-energy effective theory applicable to\nsystems with arbitrary rotation axes and small rotation angles. This theory\nelucidates the emergence of quasi-periodicity in three dimensions and\ndemonstrates its correlation with the arithmetic properties of the rotation\naxes. Numerical analyses reveal that these quasi-periodic moir\\'{e} potentials\ncan lead to distinctive dimensional localization behaviors of atoms,\nmanifesting as localized wave functions in planar or linear configurations.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas","published":"2025-04-03T13:38:03Z"}
{"aid":"http://arxiv.org/abs/2504.02581v1","title":"Quantitative assessment of biological dynamics with aggregate data","summary":"We develop and apply a learning framework for parameter estimation in initial\nvalue problems that are assessed only indirectly via aggregate data such as\nsample means and/or variances. Our comprehensive framework follows Bayesian\nprinciples and consists of specialized Markov chain Monte Carlo computational\nschemes that rely on modified Hamiltonian Monte Carlo to align with summary\nstatistic constraints and a novel elliptical slice sampler adapted to the\nparameters of biological models. We benchmark our methods with synthetic data\non microbial growth in batch culture and test them on real growth curve data\nfrom laboratory replication experiments on $\\textit{Prochlorococcus}$ microbes.\nThe results indicate that our learning framework can utilize experimental or\nhistorical data and lead to robust parameter estimation and data assimilation\nin ODE models of biological dynamics that outperform least-squares fitting.","main_category":"q-bio.QM","categories":"q-bio.QM","published":"2025-04-03T13:45:10Z"}
{"aid":"http://arxiv.org/abs/2504.02587v1","title":"Rethinking RL Scaling for Vision Language Models: A Transparent,\n  From-Scratch Framework and Comprehensive Evaluation Scheme","summary":"Reinforcement learning (RL) has recently shown strong potential in improving\nthe reasoning capabilities of large language models and is now being actively\nextended to vision-language models (VLMs). However, existing RL applications in\nVLMs often rely on heavily engineered frameworks that hinder reproducibility\nand accessibility, while lacking standardized evaluation protocols, making it\ndifficult to compare results or interpret training dynamics. This work\nintroduces a transparent, from-scratch framework for RL in VLMs, offering a\nminimal yet functional four-step pipeline validated across multiple models and\ndatasets. In addition, a standardized evaluation scheme is proposed to assess\ntraining dynamics and reflective behaviors. Extensive experiments on visual\nreasoning tasks uncover key empirical findings: response length is sensitive to\nrandom seeds, reflection correlates with output length, and RL consistently\noutperforms supervised fine-tuning (SFT) in generalization, even with\nhigh-quality data. These findings, together with the proposed framework, aim to\nestablish a reproducible baseline and support broader engagement in RL-based\nVLM research.","main_category":"cs.LG","categories":"cs.LG,cs.CL,cs.CV","published":"2025-04-03T13:53:28Z"}
{"aid":"http://arxiv.org/abs/2504.02591v1","title":"State-Space Model Inspired Multiple-Input Multiple-Output Spiking\n  Neurons","summary":"In spiking neural networks (SNNs), the main unit of information processing is\nthe neuron with an internal state. The internal state generates an output spike\nbased on its component associated with the membrane potential. This spike is\nthen communicated to other neurons in the network. Here, we propose a general\nmultiple-input multiple-output (MIMO) spiking neuron model that goes beyond\nthis traditional single-input single-output (SISO) model in the SNN literature.\nOur proposed framework is based on interpreting the neurons as state-space\nmodels (SSMs) with linear state evolutions and non-linear spiking activation\nfunctions. We illustrate the trade-offs among various parameters of the\nproposed SSM-inspired neuron model, such as the number of hidden neuron states,\nthe number of input and output channels, including single-input multiple-output\n(SIMO) and multiple-input single-output (MISO) models. We show that for SNNs\nwith a small number of neurons with large internal state spaces, significant\nperformance gains may be obtained by increasing the number of output channels\nof a neuron. In particular, a network with spiking neurons with multiple-output\nchannels may achieve the same level of accuracy with the baseline with the\ncontinuous-valued communications on the same reference network architecture.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T13:55:11Z"}
{"aid":"http://arxiv.org/abs/2504.02594v1","title":"Hofstadter butterflies in phononic structures: commensurate spectra,\n  wave localization and metal-insulator transitions","summary":"We present a new simple and easy-to-implement one-dimensional phononic system\nwhose spectrum exactly corresponds to the Hofstadter butterfly when a parameter\nis modulated. The system consists of masses that are coupled by linear springs\nand are mounted on flexural beams whose cross section (and, hence, stiffness)\nis modulated. We show that this system is the simplest version possible to\nachieve the Hofstadter butterfly exactly; in particular, the local resonances\ndue to the beams are an essential component for this. We examine the various\napproaches to producing spectral butterflies, including Bloch spectra for\nrational parameter choices, resonances of finite-sized systems and transmission\ncoefficients of sections of finite length. For finite-size systems, we study\nthe localisation of the modes by calculating the inverse participation ratio,\nand detect a phase transition characterised by a critical value of the\nstiffness modulation amplitude, where the state of the system changes from\nmainly extended to localised, corresponding to a metal-insulator phase\ntransition. The obtained results offer a practical strategy to realize\nexperimentally a system with similar dynamical properties. The transmission\ncoefficient for sections of finite length is benchmarked through the comparison\nwith Bloch spectra of the same finite-sized systems. The numerical results for\nthe transmission spectra confirms the evidence of a phase transition in the\ndynamical state of the system. Our approach opens significant new perspectives\nin order to design mechanical systems able to support phase transitions in\ntheir vibrational properties.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-03T13:55:49Z"}
{"aid":"http://arxiv.org/abs/2504.02603v1","title":"Plasmonic Su-Schrieffer-Heeger chains with strong coupling amplitudes","summary":"Plasmonic many-particle systems with precisely tuned resonances and coupling\nstrengths can exhibit emergent collective properties governed by universal\nprinciples. In one-dimensional chains with alternating couplings, known as\nSu-Schrieffer-Heeger (SSH) systems, this includes the formation of\ntopologically protected mid-gap modes whose intensities localize at the chain's\nends. This subwavelength localization at optical frequencies is crucial for\nachieving strong coupling of mid-gap modes to two-level systems under ambient\nconditions, extending topological protection to hybrid light-matter states.\nHere, we have fabricated SSH chains from plasmonic nanoslit resonators with\nstrong inter-resonator coupling. The alternating distance between the nanoslit\nresonators is controlled with sub-nanometer precision, enabling accurate\nprediction and experimental observation of topologically protected mid-gap\nmodes via photoemission electron microscopy (PEEM). Our results open the path\ntowards experimental realizations of two-dimensional photonic metasurfaces\nexhibiting higher-order topological modes that can be strongly coupled to\nsingle emitters and quantum materials at ambient conditions.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mes-hall","published":"2025-04-03T14:05:17Z"}
{"aid":"http://arxiv.org/abs/2504.02605v1","title":"Multi-SWE-bench: A Multilingual Benchmark for Issue Resolving","summary":"The task of issue resolving is to modify a codebase to generate a patch that\naddresses a given issue. However, existing benchmarks, such as SWE-bench, focus\nalmost exclusively on Python, making them insufficient for evaluating Large\nLanguage Models (LLMs) across diverse software ecosystems. To address this, we\nintroduce a multilingual issue-resolving benchmark, called Multi-SWE-bench,\ncovering Java, TypeScript, JavaScript, Go, Rust, C, and C++. It includes a\ntotal of 1,632 high-quality instances, which were carefully annotated from\n2,456 candidates by 68 expert annotators, ensuring that the benchmark can\nprovide an accurate and reliable evaluation. Based on Multi-SWE-bench, we\nevaluate a series of state-of-the-art models using three representative methods\n(Agentless, SWE-agent, and OpenHands) and present a comprehensive analysis with\nkey empirical insights. In addition, we launch a Multi-SWE-RL open-source\ncommunity, aimed at building large-scale reinforcement learning (RL) training\ndatasets for issue-resolving tasks. As an initial contribution, we release a\nset of 4,723 well-structured instances spanning seven programming languages,\nlaying a solid foundation for RL research in this domain. More importantly, we\nopen-source our entire data production pipeline, along with detailed tutorials,\nencouraging the open-source community to continuously contribute and expand the\ndataset. We envision our Multi-SWE-bench and the ever-growing Multi-SWE-RL\ncommunity as catalysts for advancing RL toward its full potential, bringing us\none step closer to the dawn of AGI.","main_category":"cs.SE","categories":"cs.SE,cs.AI,cs.CL","published":"2025-04-03T14:06:17Z"}
{"aid":"http://arxiv.org/abs/2504.02612v1","title":"Fine-Tuning Visual Autoregressive Models for Subject-Driven Generation","summary":"Recent advances in text-to-image generative models have enabled numerous\npractical applications, including subject-driven generation, which fine-tunes\npretrained models to capture subject semantics from only a few examples. While\ndiffusion-based models produce high-quality images, their extensive denoising\nsteps result in significant computational overhead, limiting real-world\napplicability. Visual autoregressive~(VAR) models, which predict next-scale\ntokens rather than spatially adjacent ones, offer significantly faster\ninference suitable for practical deployment. In this paper, we propose the\nfirst VAR-based approach for subject-driven generation. However, na\\\"{\\i}ve\nfine-tuning VAR leads to computational overhead, language drift, and reduced\ndiversity. To address these challenges, we introduce selective layer tuning to\nreduce complexity and prior distillation to mitigate language drift.\nAdditionally, we found that the early stages have a greater influence on the\ngeneration of subject than the latter stages, which merely synthesize local\ndetails. Based on this finding, we propose scale-wise weighted tuning, which\nprioritizes coarser resolutions for promoting the model to focus on the\nsubject-relevant information instead of local details. Extensive experiments\nvalidate that our method significantly outperforms diffusion-based baselines\nacross various metrics and demonstrates its practical usage.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T14:12:55Z"}
{"aid":"http://arxiv.org/abs/2504.02627v1","title":"Incorporating the ChEES Criterion into Sequential Monte Carlo Samplers","summary":"Markov chain Monte Carlo (MCMC) methods are a powerful but computationally\nexpensive way of performing non-parametric Bayesian inference. MCMC proposals\nwhich utilise gradients, such as Hamiltonian Monte Carlo (HMC), can better\nexplore the parameter space of interest if the additional hyper-parameters are\nchosen well. The No-U-Turn Sampler (NUTS) is a variant of HMC which is\nextremely effective at selecting these hyper-parameters but is slow to run and\nis not suited to GPU architectures. An alternative to NUTS, Change in the\nEstimator of the Expected Square HMC (ChEES-HMC) was shown not only to run\nfaster than NUTS on GPU but also sample from posteriors more efficiently.\nSequential Monte Carlo (SMC) samplers are another sampling method which instead\noutput weighted samples from the posterior. They are very amenable to\nparallelisation and therefore being run on GPUs while having additional\nflexibility in their choice of proposal over MCMC. We incorporate (ChEEs-HMC)\nas a proposal into SMC samplers and demonstrate competitive but faster\nperformance than NUTS on a number of tasks.","main_category":"stat.CO","categories":"stat.CO,cs.LG,cs.SY,eess.SY,stat.ML","published":"2025-04-03T14:25:19Z"}
{"aid":"http://arxiv.org/abs/2504.02628v1","title":"Towards Computation- and Communication-efficient Computational Pathology","summary":"Despite the impressive performance across a wide range of applications,\ncurrent computational pathology models face significant diagnostic efficiency\nchallenges due to their reliance on high-magnification whole-slide image\nanalysis. This limitation severely compromises their clinical utility,\nespecially in time-sensitive diagnostic scenarios and situations requiring\nefficient data transfer. To address these issues, we present a novel\ncomputation- and communication-efficient framework called Magnification-Aligned\nGlobal-Local Transformer (MAGA-GLTrans). Our approach significantly reduces\ncomputational time, file transfer requirements, and storage overhead by\nenabling effective analysis using low-magnification inputs rather than\nhigh-magnification ones. The key innovation lies in our proposed magnification\nalignment (MAGA) mechanism, which employs self-supervised learning to bridge\nthe information gap between low and high magnification levels by effectively\naligning their feature representations. Through extensive evaluation across\nvarious fundamental CPath tasks, MAGA-GLTrans demonstrates state-of-the-art\nclassification performance while achieving remarkable efficiency gains: up to\n10.7 times reduction in computational time and over 20 times reduction in file\ntransfer and storage requirements. Furthermore, we highlight the versatility of\nour MAGA framework through two significant extensions: (1) its applicability as\na feature extractor to enhance the efficiency of any CPath architecture, and\n(2) its compatibility with existing foundation models and\nhistopathology-specific encoders, enabling them to process low-magnification\ninputs with minimal information loss. These advancements position MAGA-GLTrans\nas a particularly promising solution for time-sensitive applications,\nespecially in the context of intraoperative frozen section diagnosis where both\naccuracy and efficiency are paramount.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-03T14:25:19Z"}
{"aid":"http://arxiv.org/abs/2504.02635v1","title":"Continuous two-valued discrete-time dynamical systems and actions of\n  two-valued groups","summary":"We study continuous 2-valued dynamical systems with discrete time (dynamics)\non $\\mathbb{C}$. The main question addressed is whether a 2-valued dynamics can\nbe defined by the action of a 2-valued group. We construct a class of strongly\ninvertible continuous 2-valued dynamics on $\\mathbb{C}$ such that none of these\ndynamics can be given by the action of any 2-valued group. We also construct an\nexample of a continuous 2-valued dynamics on $\\mathbb{C}$ that is not strongly\ninvertible but can be defined by the action of a 2-valued group.","main_category":"math.GR","categories":"math.GR,math.DS,math.GT","published":"2025-04-03T14:32:54Z"}
{"aid":"http://arxiv.org/abs/2504.02644v1","title":"Solving the Paint Shop Problem with Flexible Management of Multi-Lane\n  Buffers Using Reinforcement Learning and Action Masking","summary":"In the paint shop problem, an unordered incoming sequence of cars assigned to\ndifferent colors has to be reshuffled with the objective of minimizing the\nnumber of color changes. To reshuffle the incoming sequence, manufacturers can\nemploy a first-in-first-out multi-lane buffer system allowing store and\nretrieve operations. So far, prior studies primarily focused on simple decision\nheuristics like greedy or simplified problem variants that do not allow full\nflexibility when performing store and retrieve operations. In this study, we\npropose a reinforcement learning approach to minimize color changes for the\nflexible problem variant, where store and retrieve operations can be performed\nin an arbitrary order. After proving that greedy retrieval is optimal, we\nincorporate this finding into the model using action masking. Our evaluation,\nbased on 170 problem instances with 2-8 buffer lanes and 5-15 colors, shows\nthat our approach reduces color changes compared to existing methods by\nconsiderable margins depending on the problem size. Furthermore, we demonstrate\nthe robustness of our approach towards different buffer sizes and imbalanced\ncolor distributions.","main_category":"cs.LG","categories":"cs.LG,math.OC","published":"2025-04-03T14:37:40Z"}
{"aid":"http://arxiv.org/abs/2504.02652v1","title":"Optimizing Resource Allocation to Mitigate the Risk of Disruptive Events\n  in Homeland Security and Emergency Management","summary":"Homeland security in the United States faces a daunting task due to the\nmultiple threats and hazards that can occur. Natural disasters, human-caused\nincidents such as terrorist attacks, and technological failures can result in\nsignificant damage, fatalities, injuries, and economic losses. The increasing\nfrequency and severity of disruptive events in the United States highlight the\nurgent need for effectively allocating resources in homeland security and\nemergency preparedness. This article presents an optimization-based decision\nsupport model to help homeland security policymakers identify and select\nprojects that best mitigate the risk of threats and hazards while satisfying a\nbudget constraint. The model incorporates multiple hazards, probabilistic risk\nassessments, and multidimensional consequences and integrates historical data\nand publicly available sources to evaluate and select the most effective risk\nmitigation projects and optimize resource allocation across various disaster\nscenarios. We apply this model to the state of Iowa, considering 16 hazards,\nsix types of consequences, and 52 mitigation projects. Our results demonstrate\nhow different budget levels influence project selection, emphasizing\ncost-effective solutions that maximize risk reduction. Sensitivity analysis\nexamines the robustness of project selection under varying effectiveness\nassumptions and consequence estimations. The findings offer critical insights\nfor policymakers in homeland security and emergency management and provide a\nbasis for more efficient resource allocation and improved disaster resilience.","main_category":"cs.CY","categories":"cs.CY,math.OC","published":"2025-04-03T14:49:15Z"}
{"aid":"http://arxiv.org/abs/2504.02654v1","title":"SymDQN: Symbolic Knowledge and Reasoning in Neural Network-based\n  Reinforcement Learning","summary":"We propose a learning architecture that allows symbolic control and guidance\nin reinforcement learning with deep neural networks. We introduce SymDQN, a\nnovel modular approach that augments the existing Dueling Deep Q-Networks\n(DuelDQN) architecture with modules based on the neuro-symbolic framework of\nLogic Tensor Networks (LTNs). The modules guide action policy learning and\nallow reinforcement learning agents to display behaviour consistent with\nreasoning about the environment. Our experiment is an ablation study performed\non the modules. It is conducted in a reinforcement learning environment of a\n5x5 grid navigated by an agent that encounters various shapes, each associated\nwith a given reward. The underlying DuelDQN attempts to learn the optimal\nbehaviour of the agent in this environment, while the modules facilitate shape\nrecognition and reward prediction. We show that our architecture significantly\nimproves learning, both in terms of performance and the precision of the agent.\nThe modularity of SymDQN allows reflecting on the intricacies and complexities\nof combining neural and symbolic approaches in reinforcement learning.","main_category":"cs.AI","categories":"cs.AI,cs.LO,cs.NE,I.2.6","published":"2025-04-03T14:51:11Z"}
{"aid":"http://arxiv.org/abs/2504.02656v1","title":"Covering spiky annuli by planks","summary":"Answering Tarski's plank problem, Bang showed in 1951 that it is impossible\nto cover a convex body $K$ by planks whose total width is less than the minimal\nwidth $w(K)$ of $K$. In 2003, A. Bezdek asked whether the same statement holds\nif one is required to cover only the annulus obtained from $K$ by removing a\nhomothetic copy contained within. He showed that if $K$ is the unit square,\nthen saving width in a plank covering is not possible, provided that the\nhomothety factor is sufficiently small. White and Wisewell in 2006\ncharacterized polygons that possess this property. We generalize their\nconstructive result by showing that if $K$ is a convex disc or a convex body in\n3-space that is spiky in a minimal width direction, then for every $\\varepsilon\n\\in (0,1)$ it is possible to cut a homothetic copy $\\varepsilon K$ from the\ninterior of $K$ so that the remaining annulus can be covered by planks whose\ntotal width is strictly less than $w(K)$.","main_category":"math.MG","categories":"math.MG","published":"2025-04-03T14:51:26Z"}
{"aid":"http://arxiv.org/abs/2504.02657v1","title":"Backward DVCS in a Sullivan process","summary":"Mesons' internal structure and dynamics may be accessed through hard\nexclusive electroproduction processes such as deeply virtual Compton scattering\nin both near forward and near backward kinematics. With the help of the\nSullivan process which allows us to use a nucleon target as a quasi-real $\\pi$\nmeson emitter, we study backward scattering in the framework of collinear QCD\nfactorization where pion-to-photon transition distribution amplitudes describe\nthe photon content of the $\\pi$ meson. We present a model of these TDAs based\non the overlap of lightfront wave functions primarily developed for generalized\nparton distributions, using a previously developed pion lightfront wave\nfunction and deriving a new model for the lightfront wave functions of the\nphoton. This leads us to an estimate of the cross-sections for JLab energies.\nWe conclude that deeply virtual $ep\\rightarrow e\\gamma M n$ processes, in\nbackward kinematics, may be experimentally discovered in the near future.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-03T14:52:59Z"}
{"aid":"http://arxiv.org/abs/2504.02659v1","title":"Spectropolarimetry for Discerning Geometry and Structure in\n  Circumstellar Media of Hot Massive Stars","summary":"Spectropolarimetric techniques are a mainstay of astrophysical inquiry,\nranging from Solar System objects to the Cosmic Background Radiation. This\nreview highlights applications of stellar polarimetry for massive hot stars,\nparticularly in the context of ultraviolet (UV) spaceborne missions. The\nprevalence of binarity in the massive star population and uncertainties\nregarding the degree of rotational criticality among hot stars raises important\nquestions about stellar interactions, interior structure, and even the\nlifetimes of evolutionary phases. These uncertainties have consequences for\nstellar population synthesis calculations. Spectropolarimetry is a key tool for\nextracting information about stellar and binary geometries. We review\nmethodologies involving electron scattering in circumstellar envelopes; gravity\ndarkening from rapid rotation; spectral line effects including the (a) \"line\neffect\", (b) Ohman effect, and (c) Hanle effect; and the imprint of\ninterstellar polarization on measurements. Finally, we describe the Polstar UV\nspectropolarimetric SMEX mission concept as one means for employing these\ndiagnostics to clarify the state of high rotation and its impacts for massive\nstars.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA,astro-ph.IM","published":"2025-04-03T14:56:08Z"}
{"aid":"http://arxiv.org/abs/2504.02663v1","title":"Development of Automated Data Quality Assessment and Evaluation Indices\n  by Analytical Experience","summary":"The societal need to leverage third-party data has driven the\ndata-distribution market and increased the importance of data quality\nassessment (DQA) in data transactions between organizations. However, DQA\nrequires expert knowledge of raw data and related data attributes, which\nhinders consensus-building in data purchasing. This study focused on the\ndifferences in DQAs between experienced and inexperienced data handlers. We\nperformed two experiments: The first was a questionnaire survey involving 41\nparticipants with varying levels of data-handling experience, who evaluated 12\ndata samples using 10 predefined indices with and without quality metadata\ngenerated by the automated tool. The second was an eye-tracking experiment to\nreveal the viewing behavior of participants during data evaluation. It was\nrevealed that using quality metadata generated by the automated tool can reduce\nmisrecognition in DQA. While experienced data handlers rated the quality\nmetadata highly, semi-experienced users gave it the lowest ratings. This study\ncontributes to enhancing data understanding within organizations and promoting\nthe distribution of valuable data by proposing an automated tool to support\nDQAs.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-03T15:03:08Z"}
{"aid":"http://arxiv.org/abs/2504.02664v1","title":"How humans evaluate AI systems for person detection in automatic train\n  operation: Not all misses are alike","summary":"If artificial intelligence (AI) is to be applied in safety-critical domains,\nits performance needs to be evaluated reliably. The present study aimed to\nunderstand how humans evaluate AI systems for person detection in automatic\ntrain operation. In three experiments, participants saw image sequences of\npeople moving in the vicinity of railway tracks. A simulated AI had highlighted\nall detected people, sometimes correctly and sometimes not. Participants had to\nprovide a numerical rating of the AI's performance and then verbally explain\ntheir rating. The experiments varied several factors that might influence human\nratings: the types and plausibility of AI mistakes, the number of affected\nimages, the number of people present in an image, the position of people\nrelevant to the tracks, and the methods used to elicit human evaluations. While\nall these factors influenced human ratings, some effects were unexpected or\ndeviated from normative standards. For instance, the factor with the strongest\nimpact was people's position relative to the tracks, although participants had\nexplicitly been instructed that the AI could not process such information.\nTaken together, the results suggest that humans may sometimes evaluate more\nthan the AI's performance on the assigned task. Such mismatches between AI\ncapabilities and human expectations should be taken into consideration when\nconducting safety audits of AI systems.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-03T15:05:57Z"}
{"aid":"http://arxiv.org/abs/2504.02665v1","title":"Finite groups whose maximal subgroups have almost odd index","summary":"A recurring theme in finite group theory is understanding how the structure\nof a finite group is determined by the arithmetic properties of group\ninvariants. There are results in the literature determining the structure of\nfinite groups whose irreducible character degrees, conjugacy class sizes or\nindices of maximal subgroups are odd. These results have been extended to\ninclude those finite groups whose character degrees or conjugacy class sizes\nare not divisible by $4$. In this paper, we determine the structure of finite\ngroups whose maximal subgroups have index not divisible by $4$. As a\nconsequence, we obtain some new $2$-nilpotency criteria.","main_category":"math.GR","categories":"math.GR","published":"2025-04-03T15:06:42Z"}
{"aid":"http://arxiv.org/abs/2504.02668v1","title":"Two-Stage nnU-Net for Automatic Multi-class Bi-Atrial Segmentation from\n  LGE-MRIs","summary":"Late gadolinium enhancement magnetic resonance imaging (LGE-MRI) is used to\nvisualise atrial fibrosis and scars, providing important information for\npersonalised atrial fibrillation (AF) treatments. Since manual analysis and\ndelineations of these images can be both labour-intensive and subject to\nvariability, we develop an automatic pipeline to perform segmentation of the\nleft atrial (LA) cavity, the right atrial (RA) cavity, and the wall of both\natria on LGE-MRI. Our method is based on a two-stage nnU-Net architecture,\ncombining 2D and 3D convolutional networks, and incorporates adaptive histogram\nequalisation to improve tissue contrast in the input images and morphological\noperations on the output segmentation maps. We achieve Dice similarity\ncoefficients of 0.92 +/- 0.03, 0.93 +/- 0.03, 0.71 +/- 0.05 and 95% Hausdorff\ndistances of (3.89 +/- 6.67) mm, (4.42 +/- 1.66) mm and (3.94 +/- 1.83) mm for\nLA, RA, and wall, respectively. The accurate delineation of the LA, RA and the\nmyocardial wall is the first step in analysing atrial structure in\ncardiovascular patients, especially those with AF. This can allow clinicians to\nprovide adequate and personalised treatment plans in a timely manner.","main_category":"eess.IV","categories":"eess.IV","published":"2025-04-03T15:08:33Z"}
{"aid":"http://arxiv.org/abs/2504.02670v1","title":"Affordable AI Assistants with Knowledge Graph of Thoughts","summary":"Large Language Models (LLMs) are revolutionizing the development of AI\nassistants capable of performing diverse tasks across domains. However, current\nstate-of-the-art LLM-driven agents face significant challenges, including high\noperational costs and limited success rates on complex benchmarks like GAIA. To\naddress these issues, we propose the Knowledge Graph of Thoughts (KGoT), an\ninnovative AI assistant architecture that integrates LLM reasoning with\ndynamically constructed knowledge graphs (KGs). KGoT extracts and structures\ntask-relevant knowledge into a dynamic KG representation, iteratively enhanced\nthrough external tools such as math solvers, web crawlers, and Python scripts.\nSuch structured representation of task-relevant knowledge enables low-cost\nmodels to solve complex tasks effectively. For example, KGoT achieves a 29%\nimprovement in task success rates on the GAIA benchmark compared to Hugging\nFace Agents with GPT-4o mini, while reducing costs by over 36x compared to\nGPT-4o. Improvements for recent reasoning models are similar, e.g., 36% and\n37.5% for Qwen2.5-32B and Deepseek-R1-70B, respectively. KGoT offers a\nscalable, affordable, and high-performing solution for AI assistants.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.IR,cs.LG","published":"2025-04-03T15:11:55Z"}
{"aid":"http://arxiv.org/abs/2504.02686v1","title":"Degrees and prime power order zeros of characters of symmetric and\n  alternating groups","summary":"We show that the $p$-part of the degree of an irreducible character of a\nsymmetric group is completely determined by the set of vanishing elements of\n$p$-power order. As a corollary we deduce that the set of zeros of prime power\norder controls the degree of such a character. The same problem is analysed for\nalternating groups, where we show that when $p=2$ this data can only be\ndetermined up to two possibilities. We prove analogous statements for the\ndefect of the $p$-block containing the character and for the $p$-height of the\ncharacter.","main_category":"math.RT","categories":"math.RT,math.GR","published":"2025-04-03T15:27:25Z"}
{"aid":"http://arxiv.org/abs/2504.02703v1","title":"Uncovering shifts in the history of Physics education: a systematic,\n  NLP-based, thematic analysis of articles from The Physics Teacher and Physics\n  Education journals (1966-2019)","summary":"This study explores the thematic evolution of articles in The Physics Teacher\nand Physics Education journals, over a critical period in modern history, from\nthe Cold War era to the pre-pandemic world (1966 - 2019). Using an NLP-based\ninductive topic modeling approach, we identify recurring themes that have\nshaped the physics education literature, including content-based topics,\nteaching methodologies, laboratory practices, curriculum development, and the\ninfluence of Physics Education Research (PER). Our findings reveal both\noverarching trends and distinct thematic preferences between the journals.\nPhysics Education has historically emphasized curriculum structures, social\naspects of education, and interdisciplinary connections, whereas The Physics\nTeacher has focused more on pedagogical strategies, demonstrations, and\npractical teaching tools. Over the past three decades, both journals have\nincreasingly incorporated discussions on technology, computation, and\nPER-driven instructional practices. By tracing these developments over five\ndecades, this study provides a broader perspective on how physics education has\nresponded to changing educational priorities, technological advancements, and\nresearch developments.","main_category":"physics.ed-ph","categories":"physics.ed-ph","published":"2025-04-03T15:38:34Z"}
{"aid":"http://arxiv.org/abs/2504.02704v1","title":"EvoChain: A Framework for Tracking and Visualizing Smart Contract\n  Evolution","summary":"Tracking the evolution of smart contracts is challenging due to their\nimmutable nature and complex upgrade mechanisms. We introduce EvoChain, a\ncomprehensive framework and dataset designed to track and visualize smart\ncontract evolution. Building upon data from our previous empirical study,\nEvoChain models contract relationships using a Neo4j graph database and\nprovides an interactive web interface for exploration. The framework consists\nof a data layer, an API layer, and a user interface layer. EvoChain allows\nstakeholders to analyze contract histories, upgrade paths, and associated\nvulnerabilities by leveraging these components. Our dataset encompasses\napproximately 1.3 million upgradeable proxies and nearly 15,000 historical\nversions, enhancing transparency and trust in blockchain ecosystems by\nproviding an accessible platform for understanding smart contract evolution.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-03T15:41:48Z"}
{"aid":"http://arxiv.org/abs/2504.02706v1","title":"Learning quantum Gibbs states locally and efficiently","summary":"Learning the Hamiltonian underlying a quantum many-body system in thermal\nequilibrium is a fundamental task in quantum learning theory and experimental\nsciences. To learn the Gibbs state of local Hamiltonians at any inverse\ntemperature $\\beta$, the state-of-the-art provable algorithms fall short of the\noptimal sample and computational complexity, in sharp contrast with the\nlocality and simplicity in the classical cases. In this work, we present a\nlearning algorithm that learns each local term of a $n$-qubit $D$-dimensional\nHamiltonian to an additive error $\\epsilon$ with sample complexity\n$\\tilde{O}\\left(\\frac{e^{\\mathrm{poly}(\\beta)}}{\\beta^2\\epsilon^2}\\right)\\log(n)$.\nThe protocol uses parallelizable local quantum measurements that act within\nbounded regions of the lattice and near-linear-time classical post-processing.\nThus, our complexity is near optimal with respect to $n,\\epsilon$ and is\npolynomially tight with respect to $\\beta$. We also give a learning algorithm\nfor Hamiltonians with bounded interaction degree with sample and time\ncomplexities of similar scaling on $n$ but worse on $\\beta, \\epsilon$. At the\nheart of our algorithm is the interplay between locality, the\nKubo-Martin-Schwinger condition, and the operator Fourier transform at\narbitrary temperatures.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-03T15:42:23Z"}
{"aid":"http://arxiv.org/abs/2504.02717v1","title":"Clustering in a preferential attachment network with triangles","summary":"We study a generalization of the affine preferential attachment model where\ntriangles are randomly added to the graph. We show that the model exhibits an\nasymptotically power-law degree distribution with adjustable parameter\n$\\gamma\\in (1,\\infty)$, and positive clustering. However, the clustering\nbehaviour depends on how it is measured. With high probability, the average\nlocal clustering coefficient remains positive, independently of $\\gamma$,\nwhereas the expectation of the global clustering coefficient does not vanish\nonly when $\\gamma>3$.","main_category":"math.PR","categories":"math.PR","published":"2025-04-03T16:02:27Z"}
{"aid":"http://arxiv.org/abs/2504.02725v1","title":"ERPO: Advancing Safety Alignment via Ex-Ante Reasoning Preference\n  Optimization","summary":"Recent advancements in large language models (LLMs) have accelerated progress\ntoward artificial general intelligence, yet their potential to generate harmful\ncontent poses critical safety challenges. Existing alignment methods often\nstruggle to cover diverse safety scenarios and remain vulnerable to adversarial\nattacks. In this work, we propose Ex-Ante Reasoning Preference Optimization\n(ERPO), a novel safety alignment framework that equips LLMs with explicit\npreemptive reasoning through Chain-of-Thought and provides clear evidence for\nsafety judgments by embedding predefined safety rules. Specifically, our\napproach consists of three stages: first, equipping the model with Ex-Ante\nreasoning through supervised fine-tuning (SFT) using a constructed reasoning\nmodule; second, enhancing safety, usefulness, and efficiency via Direct\nPreference Optimization (DPO); and third, mitigating inference latency with a\nlength-controlled iterative preference optimization strategy. Experiments on\nmultiple open-source LLMs demonstrate that ERPO significantly enhances safety\nperformance while maintaining response efficiency.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T16:07:38Z"}
{"aid":"http://arxiv.org/abs/2504.02727v1","title":"Effect of new healthy and live food supplement on Anemia disease in\n  Wistar rats","summary":"Anemia is a decrease in hemoglobin and red blood cells and due to a decrease\nin hemoglobin, oxygen carrying capacity reduce. In this disease, the red blood\ncell the amount and volume decrease. In this research, healthy and live food\npowder were synthesized by a green route. This organic biomaterial was named\nNBS. The NBS healthy and live food powder has various vitamins, macro and micro\nmolecules, and ingredients. Twenty Wistar rats were randomly divided into 4\nequal groups, including control and treatment groups 1, 2 and 3. Nutritional\nsupplements for healthy living were administered orally via gavage to rats in\ngroups 1, 2, and 3 at 12.5, 25, and 50 mg/ kg, respectively, and within a\nperiod of 20 days, one day in between. There was no intervention in the control\ngroup in order to reach baseline blood factors. At the end of the study, blood\nsamples were taken from the heart, including blood-red blood cells, hemoglobin,\nhematocrit and platelets using a fully automated blood cell counting machine.\nThe results showed that the new dietary supplement reduced the level of\nhematocrit and platelets in the studied rats. The healthy and live food\nsupplement at a concentration of 50 mg / kg increased blood levels compared to\nthe control group. The results of this study showed that the use of healthy and\nlive food supplement increased blood factors compared to the control group.","main_category":"q-bio.CB","categories":"q-bio.CB","published":"2025-04-03T16:11:14Z"}
{"aid":"http://arxiv.org/abs/2504.02735v1","title":"Pushing the Limit of PPG Sensing in Sedentary Conditions by Addressing\n  Poor Skin-sensor Contact","summary":"Photoplethysmography (PPG) is a widely used non-invasive technique for\nmonitoring cardiovascular health and various physiological parameters on\nconsumer and medical devices. While motion artifacts are well-known challenges\nin dynamic settings, suboptimal skin-sensor contact in sedentary conditions - a\ncritical issue often overlooked in existing literature - can distort PPG signal\nmorphology, leading to the loss or shift of essential waveform features and\ntherefore degrading sensing performance. In this work, we propose CP-PPG, a\nnovel approach that transforms Contact Pressure-distorted PPG signals into ones\nwith the ideal morphology. CP-PPG incorporates a novel data collection\napproach, a well-crafted signal processing pipeline, and an advanced deep\nadversarial model trained with a custom PPG-aware loss function. We validated\nCP-PPG through comprehensive evaluations, including 1) morphology\ntransformation performance on our self-collected dataset, 2) downstream\nphysiological monitoring performance on public datasets, and 3) in-the-wild\nperformance. Extensive experiments demonstrate substantial and consistent\nimprovements in signal fidelity (Mean Absolute Error: 0.09, 40% improvement\nover the original signal) as well as downstream performance across all\nevaluations in Heart Rate (HR), Heart Rate Variability (HRV), Respiration Rate\n(RR), and Blood Pressure (BP) estimation (on average, 21% improvement in HR;\n41-46% in HRV; 6% in RR; and 4-5% in BP). These findings highlight the critical\nimportance of addressing skin-sensor contact issues for accurate and dependable\nPPG-based physiological monitoring. Furthermore, CP-PPG can serve as a generic,\nplug-in API to enhance PPG signal quality.","main_category":"cs.HC","categories":"cs.HC,cs.LG","published":"2025-04-03T16:22:15Z"}
{"aid":"http://arxiv.org/abs/2504.02742v1","title":"Quantum synchronization blockade induced by nonreciprocal coupling","summary":"Recently, the synchronization of coupled quantum oscillators has attracted a\ngreat deal of interest. Synchronization requires driven constituents, and in\nsuch systems, the coupling can be designed to be nonreciprocal.\nNonreciprocally-coupled oscillators exhibit a rich variety of behavior\nincluding active traveling-wave type states. In this work, we study the\ninterplay of three competing synchronization mechanisms in a setup of two\nnonreciprocally-coupled quantum van der Pol oscillators. One of the oscillators\nis driven externally which induces phase locking. A dissipative interaction\nleads to anti-phase locking, whereas a coherent interaction nurtures bistable\nphase locking and active states. We approximate the phase diagram of the\nquantum case by evaluating the synchronization measure of a perturbation\nexpansion of the steady state. Furthermore, we study the phase diagrams of two\nand three oscillators in the mean-field limit and find highly nontrivial active\nstates.","main_category":"quant-ph","categories":"quant-ph,nlin.PS","published":"2025-04-03T16:29:32Z"}
{"aid":"http://arxiv.org/abs/2504.02756v1","title":"Stability of acoustic streaming jets","summary":"We study the stability of a steady Eckart streaming jet that is acoustically\nforced at one end of a closed cylindrical cavity and impinges the wall at the\nother end, where a recirculation forms. This configuration generically\nrepresents industrial processes where acoustic forcing offers a contactless\nmeans of stirring or controlling confined flows. Successfully doing so,\nhowever, requires sufficient insight into the topology of the acoustically\nforced flow. This raises the question of whether the base acoustic streaming\njet is stable and, when not, of which alternative states emerge. Using Linear\nStability Analysis (LSA) and three-dimensional nonlinear simulations, we\nidentify the instability mechanisms and determine the nature of the\nbifurcations that ensue. We show that the ratio $C_R$ between the cavity and\nthe maximum beam radii determines the dominant unstable mode. For $4 \\leq C_R\n\\leq 6$, a non-oscillatory perturbation rooted in the jet impingement triggers\na supercritical bifurcation. For $C_R = 3$, the flow destabilises through a\nsubcritical non-oscillatory bifurcation. Further reducing $C_R$ increases the\nshear within the flow, and gradually relocates the instability in the shear\nlayer between impingement-induced vortices: for $C_R = 2$, an unstable\ntravelling wave grows out of a subcritical bifurcation, which becomes\nsupercritical for $C_R=1$. For each geometry, the nonlinear 3D simulations\nvalidate the LSA, identify the saturated nonlinear state and its stability.\nThis study offers fundamental insight into the stability of acoustically-driven\nflows in general, but also opens possible pathways to either induce turbulence\nacoustically, or to avoid it in realistic configurations.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-03T16:49:37Z"}
{"aid":"http://arxiv.org/abs/2504.02758v1","title":"ALMA uncovers optically thin and multi-component CO gas in the\n  outflowing circumnuclear disk of NGC1068","summary":"Active galactic nuclei (AGNs) influence their host galaxies through winds and\njets that can drive molecular outflows, traceable with CO line emissions using\nthe Atacama Large Millimeter Array (ALMA). Recent studies leveraging ALMA data\nhave proposed a three-dimensional outflow geometry in the nearby Seyfert II\ngalaxy NGC 1068, a key target for AGN unification theories. Using ALMA\nobservations of CO(2-1), CO(3-2), and CO(6-5) transitions at roughly 0.1\narcseconds (approximately 7 parsecs) resolution, we analyzed the temperature,\ndensity, and kinematics of NGC 1068's circumnuclear disk (CND), focusing on the\nmolecular outflow. Through local thermodynamic equilibrium (LTE) analysis, we\nderived column densities and rotational temperatures, indicating optically thin\ngas and CO-to-H2 (XCO) conversion factors between 4.8 and 9.6 times smaller\nthan the Milky Way value. The inferred molecular mass outflow rate is mostly\nbelow 5.5 solar masses per year, with the dominant contribution northeast of\nthe AGN. After subtracting the rotation curve of the CND, we modeled averaged\nline profiles in each region using single and multi-component Gaussian fits.\nSeveral profiles within or near the AGN wind bicone required multiple\ncomponents with significant velocity shifts, suggesting multi-component complex\noutflow kinematics. We observe lateral variation in CO kinematics along the AGN\nwind bicone and a misalignment between the molecular and ionized outflow\ndirections. These results imply that the dynamic impact of the ionized AGN wind\non the molecular gas in the CND may be limited. However, the molecular outflow\nshows a complex, asymmetric structure.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-03T16:53:14Z"}
{"aid":"http://arxiv.org/abs/2504.02760v1","title":"Topological groupoids with involution and real algebraic stacks","summary":"To a topological groupoid endowed with an involution, we associate a\ntopological groupoid of fixed points, generalizing the fixed-point subspace of\na topological space with involution. We prove that when the topological\ngroupoid with involution arises from a Deligne-Mumford stack over $\\mathbb{R}$,\nthis fixed locus coincides with the real locus of the stack. This provides a\ntopological framework to study real algebraic stacks, and in particular real\nmoduli spaces. Finally, we propose a Smith-Thom type conjecture in this\nsetting, generalizing the Smith-Thom inequality for topological spaces endowed\nwith an involution.","main_category":"math.AG","categories":"math.AG,math.AT,math.GN","published":"2025-04-03T16:54:46Z"}
{"aid":"http://arxiv.org/abs/2504.02766v1","title":"On Composable and Parametric Uncertainty in Systems Co-Design","summary":"Optimizing the design of complex systems requires navigating interdependent\ndecisions, heterogeneous components, and multiple objectives. Our monotone\ntheory of co-design offers a compositional framework for addressing this\nchallenge, modeling systems as Design Problems (DPs), representing trade-offs\nbetween functionalities and resources within partially ordered sets. While\ncurrent approaches model uncertainty using intervals, capturing worst- and\nbest-case bounds, they fail to express probabilistic notions such as risk and\nconfidence. These limitations hinder the applicability of co-design in domains\nwhere uncertainty plays a critical role. In this paper, we introduce a unified\nframework for composable uncertainty in co-design, capturing intervals,\ndistributions, and parametrized models. This extension enables reasoning about\nrisk-performance trade-offs and supports advanced queries such as experiment\ndesign, learning, and multi-stage decision making. We demonstrate the\nexpressiveness and utility of the framework via a numerical case study on the\nuncertainty-aware co-design of task-driven Unmanned Aerial Vehicle (UAV).","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-03T17:02:32Z"}
{"aid":"http://arxiv.org/abs/2504.02775v1","title":"TailedCore: Few-Shot Sampling for Unsupervised Long-Tail Noisy Anomaly\n  Detection","summary":"We aim to solve unsupervised anomaly detection in a practical challenging\nenvironment where the normal dataset is both contaminated with defective\nregions and its product class distribution is tailed but unknown. We observe\nthat existing models suffer from tail-versus-noise trade-off where if a model\nis robust against pixel noise, then its performance deteriorates on tail class\nsamples, and vice versa. To mitigate the issue, we handle the tail class and\nnoise samples independently. To this end, we propose TailSampler, a novel class\nsize predictor that estimates the class cardinality of samples based on a\nsymmetric assumption on the class-wise distribution of embedding similarities.\nTailSampler can be utilized to sample the tail class samples exclusively,\nallowing to handle them separately. Based on these facets, we build a\nmemory-based anomaly detection model TailedCore, whose memory both well\ncaptures tail class information and is noise-robust. We extensively validate\nthe effectiveness of TailedCore on the unsupervised long-tail noisy anomaly\ndetection setting, and show that TailedCore outperforms the state-of-the-art in\nmost settings.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-03T17:14:57Z"}
{"aid":"http://arxiv.org/abs/2504.02782v1","title":"GPT-ImgEval: A Comprehensive Benchmark for Diagnosing GPT4o in Image\n  Generation","summary":"The recent breakthroughs in OpenAI's GPT4o model have demonstrated\nsurprisingly good capabilities in image generation and editing, resulting in\nsignificant excitement in the community. This technical report presents the\nfirst-look evaluation benchmark (named GPT-ImgEval), quantitatively and\nqualitatively diagnosing GPT-4o's performance across three critical dimensions:\n(1) generation quality, (2) editing proficiency, and (3) world\nknowledge-informed semantic synthesis. Across all three tasks, GPT-4o\ndemonstrates strong performance, significantly surpassing existing methods in\nboth image generation control and output quality, while also showcasing\nexceptional knowledge reasoning capabilities. Furthermore, based on the\nGPT-4o's generated data, we propose a classification-model-based approach to\ninvestigate the underlying architecture of GPT-4o, where our empirical results\nsuggest the model consists of an auto-regressive (AR) combined with a\ndiffusion-based head for image decoding, rather than the VAR-like\narchitectures. We also provide a complete speculation on GPT-4o's overall\narchitecture. In addition, we conduct a series of analyses to identify and\nvisualize GPT-4o's specific limitations and the synthetic artifacts commonly\nobserved in its image generation. We also present a comparative study of\nmulti-round image editing between GPT-4o and Gemini 2.0 Flash, and discuss the\nsafety implications of GPT-4o's outputs, particularly their detectability by\nexisting image forensic models. We hope that our work can offer valuable\ninsight and provide a reliable benchmark to guide future research, foster\nreproducibility, and accelerate innovation in the field of image generation and\nbeyond. The codes and datasets used for evaluating GPT-4o can be found at\nhttps://github.com/PicoTrex/GPT-ImgEval.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T17:23:16Z"}
{"aid":"http://arxiv.org/abs/2504.02788v1","title":"Pivoting technique for the circle homeomorphism group","summary":"We adapt Gou{\\\"e}zel's pivoting technique to the circle homeomorphism group.\nAs an application, we give different proofs of Gilabert Vio's probabilistic\nTits alternative and Malicet's exponential synchronization.","main_category":"math.DS","categories":"math.DS,math.GT,math.PR","published":"2025-04-03T17:32:18Z"}
{"aid":"http://arxiv.org/abs/2504.02813v1","title":"Regularity and bounded $t$-structures for algebraic stacks","summary":"Our work shows (the expected) cohomological characterization for regularity\nof (Noetherian) algebraic stacks; such a stack is regular if and only if all\ncomplexes with bounded and coherent cohomology are perfect. This naturally\nenables us to extend various statements known for schemes to algebraic stacks.\nIn particular, the conjectures by Antieau--Gepner--Heller and Bondal--Van den\nBergh, both resolved for schemes by Neeman, are proven for suitable algebraic\nstacks.","main_category":"math.AG","categories":"math.AG,math.AC","published":"2025-04-03T17:55:36Z"}
{"aid":"http://arxiv.org/abs/2504.02815v1","title":"Logarithmic entanglement lightcone from eigenstate correlations in the\n  many-body localised phase","summary":"We investigate the operator entanglement of the time-evolution operator\nthrough the framework of eigenstate correlations. Focusing on strongly\ndisordered quantum many-body systems in the many-body localised (MBL) regime,\nwe analyse the operator entanglement across various spatiotemporal cuts,\nrevealing the logarithmic lightcone of entanglement spreading. We demonstrate\nthat this logarithmic lightcone arises directly from a hierarchy of\nenergyscales and lengthscales encoded in eigenstate correlations. By\ncharacterising the statistics of these hierarchical scales, we develop a\nmicroscopic theory for the spatiotemporal structure of entanglement spreading\nin MBL systems -- without invoking phenomenological constructs such as\n$\\ell$-bits. This approach reveals the fundamental connection between\neigenstate correlations and the emergent entanglement structure in MBL systems.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.quant-gas,cond-mat.stat-mech,quant-ph","published":"2025-04-03T17:57:10Z"}
{"aid":"http://arxiv.org/abs/2504.02820v1","title":"Excitation of the Glashow resonance without neutrino beams","summary":"The $s$-channel process $\\bar\\nu_ee^-\\rightarrow W^-$(on-shell) is now\nreferred to as the Glashow resonance and being searched for at kilometer-scale\nneutrino ice/water detectors like IceCube, Baikal-GVD or KM3NeT. After over a\ndecade of observations, IceCube has recorded only a few relevant neutrino\nevents such that further exploration yet remains necessary for unambiguous\nconfirmation of the existence of this resonant interaction. Meanwhile, its\nexperimental discovery would provide an additional important test of the\nStandard Model. One might therefore ask: are there reactions with the Glashow\nresonance that would not necessitate having initial (anti)neutrino beams? This\narticle suggests a surprisingly positive answer to the question $-$ namely,\nthat the process may proceed in electron-positron collisions at accelerator\nenergies, occurring as $e^+e^-\\rightarrow W^-\\rho(770)^+$. Although the\nresonance appears somewhat disguised, the underlying physics is transparent,\nquite resembling the well known radiative return: emission of $\\rho^+$ from the\ninitial state converts the incident $e^+$ into $\\bar\\nu_e$. Likewise, the CP\nconjugate channel, $\\nu_e e^+\\rightarrow W^+$, takes the form\n$e^+e^-\\rightarrow W^+\\rho(770)^-$. Similar reactions with muons are also\npossible. Within this viewpoint, future high-luminosity lepton colliders seem\nto be promising for excitation of the Glashow resonance in laboratory\nconditions.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-03T17:58:20Z"}
{"aid":"http://arxiv.org/abs/2504.02821v1","title":"Sparse Autoencoders Learn Monosemantic Features in Vision-Language\n  Models","summary":"Sparse Autoencoders (SAEs) have recently been shown to enhance\ninterpretability and steerability in Large Language Models (LLMs). In this\nwork, we extend the application of SAEs to Vision-Language Models (VLMs), such\nas CLIP, and introduce a comprehensive framework for evaluating monosemanticity\nin vision representations. Our experimental results reveal that SAEs trained on\nVLMs significantly enhance the monosemanticity of individual neurons while also\nexhibiting hierarchical representations that align well with expert-defined\nstructures (e.g., iNaturalist taxonomy). Most notably, we demonstrate that\napplying SAEs to intervene on a CLIP vision encoder, directly steer output from\nmultimodal LLMs (e.g., LLaVA) without any modifications to the underlying\nmodel. These findings emphasize the practicality and efficacy of SAEs as an\nunsupervised approach for enhancing both the interpretability and control of\nVLMs.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-03T17:58:35Z"}
{"aid":"http://arxiv.org/abs/2504.02823v1","title":"STING-BEE: Towards Vision-Language Model for Real-World X-ray Baggage\n  Security Inspection","summary":"Advancements in Computer-Aided Screening (CAS) systems are essential for\nimproving the detection of security threats in X-ray baggage scans. However,\ncurrent datasets are limited in representing real-world, sophisticated threats\nand concealment tactics, and existing approaches are constrained by a\nclosed-set paradigm with predefined labels. To address these challenges, we\nintroduce STCray, the first multimodal X-ray baggage security dataset,\ncomprising 46,642 image-caption paired scans across 21 threat categories,\ngenerated using an X-ray scanner for airport security. STCray is meticulously\ndeveloped with our specialized protocol that ensures domain-aware, coherent\ncaptions, that lead to the multi-modal instruction following data in X-ray\nbaggage security. This allows us to train a domain-aware visual AI assistant\nnamed STING-BEE that supports a range of vision-language tasks, including scene\ncomprehension, referring threat localization, visual grounding, and visual\nquestion answering (VQA), establishing novel baselines for multi-modal learning\nin X-ray baggage security. Further, STING-BEE shows state-of-the-art\ngeneralization in cross-domain settings. Code, data, and models are available\nat https://divs1159.github.io/STING-BEE/.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-03T17:59:12Z"}
{"aid":"http://arxiv.org/abs/2504.04717v1","title":"Beyond Single-Turn: A Survey on Multi-Turn Interactions with Large\n  Language Models","summary":"Recent advancements in large language models (LLMs) have revolutionized their\nability to handle single-turn tasks, yet real-world applications demand\nsophisticated multi-turn interactions. This survey provides a comprehensive\nreview of recent advancements in evaluating and enhancing multi-turn\ninteractions in LLMs. Focusing on task-specific scenarios, from instruction\nfollowing in diverse domains such as math and coding to complex conversational\nengagements in roleplay, healthcare, education, and even adversarial jailbreak\nsettings, we systematically examine the challenges of maintaining context,\ncoherence, fairness, and responsiveness over prolonged dialogues. The paper\norganizes current benchmarks and datasets into coherent categories that reflect\nthe evolving landscape of multi-turn dialogue evaluation. In addition, we\nreview a range of enhancement methodologies under multi-turn settings,\nincluding model-centric strategies (contextual learning, supervised\nfine-tuning, reinforcement learning, and new architectures), external\nintegration approaches (memory-augmented, retrieval-based methods, and\nknowledge graph), and agent-based techniques for collaborative interactions.\nFinally, we discuss open challenges and propose future directions for research\nto further advance the robustness and effectiveness of multi-turn interactions\nin LLMs. Related resources and papers are available at\nhttps://github.com/yubol-cmu/Awesome-Multi-Turn-LLMs.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-07T04:00:08Z"}
{"aid":"http://arxiv.org/abs/2504.04718v1","title":"T1: Tool-integrated Self-verification for Test-time Compute Scaling in\n  Small Language Models","summary":"Recent studies have demonstrated that test-time compute scaling effectively\nimproves the performance of small language models (sLMs). However, prior\nresearch has mainly examined test-time compute scaling with an additional\nlarger model as a verifier, leaving self-verification by sLMs underexplored. In\nthis work, we investigate whether sLMs can reliably self-verify their outputs\nunder test-time scaling. We find that even with knowledge distillation from\nlarger verifiers, sLMs struggle with verification tasks requiring memorization,\nsuch as numerical calculations and fact-checking. To address this limitation,\nwe propose Tool-integrated self-verification (T1), which delegates\nmemorization-heavy verification steps to external tools, such as a code\ninterpreter. Our theoretical analysis shows that tool integration reduces\nmemorization demands and improves test-time scaling performance. Experiments on\nthe MATH benchmark demonstrate that, with T1, a Llama-3.2 1B model under\ntest-time scaling outperforms the significantly larger Llama-3.1 8B model.\nMoreover, T1 generalizes effectively to both mathematical (MATH500) and\nmulti-domain knowledge-intensive tasks (MMLU-Pro). Our findings highlight the\npotential of tool integration to substantially improve the self-verification\nabilities of sLMs.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-07T04:01:17Z"}
{"aid":"http://arxiv.org/abs/2504.04725v1","title":"Prethermalization in Fermi-Pasta-Ulam-Tsingou chains","summary":"The observation of the Fermi-Pasta-Ulam-Tsingou (FPUT) paradox, namely the\nlack of equipartition in the evolution of a normal mode in a nonlinear chain on\nunexpectedly long times, is arguably the most famous numerical experiment in\nthe history of physics. Since seventy years after its publication, most studies\nin FPUT chains still focus on long wavelength initial states similar to the\noriginal paper. It is shown here that all characteristic features of the FPUT\nparadox are rendered even more striking if short(er) wavelength modes are\nevolved instead. Since not every normal mode leads to equipartition, we also\nprovide a simple technique to predict which modes, and in what order, are\nexcited starting from an initial mode (root) in $\\alpha$-FPUT chains. The\nexcitation sequences associated with a root are then shown to spread energy at\ndifferent speeds, leading to prethermalization regimes that become longer as a\nfunction of mode excitation number. This effect is visible in observables such\nas mode energies and spectral entropies and, surprisingly, also in the time\nevolution of invariant quantities such as Lyapunov times and Kolmogorov-Sinai\nentropies. Our findings generalize the original FPUT experiment, provide an\noriginal look at the paradox's source, and enrich the vast literature dedicated\nto studying equipartition in classical many-body systems.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,nlin.CD","published":"2025-04-07T04:36:42Z"}
{"aid":"http://arxiv.org/abs/2504.04727v1","title":"Regression Model for Measurement of Wound Dimensions by Webcam Scanners\n  and Time-of-Flight Sensors","summary":"One use of image processing is for medical equipment such as wound\nidentification. This technology is carried out non-invasively by taking images\nso as to avoid direct touch with the wound thereby reducing the possibility of\ninfection. The images obtained using the RGB camera will be used for color\nsegmentation which will measure the wound dimensions. However, the image data\nis in the form of a raster, the distance will affect the pixel size. Therefore,\nit is necessary to consider the distance of the camera measurement to the\nobject. The time-of-flight (ToF) method with a lidar sensor is used to\ncalculate the distance of the camera to the object. It is necessary to\ncalculate the ratio of the distance to the number of pixels obtained so that\nthe value is always consistent. This study analyzed the use of appropriate\nratios and regression systems on a webcam and a lidar sensor for measuring\nwound dimensions. The results of the study show that there is a regression\nmodel with a second-order polynomial relationship for the distance and number\nof pixels obtained consistently with an error value of less than 5% which shows\nvery good results","main_category":"physics.comp-ph","categories":"physics.comp-ph,physics.ins-det","published":"2025-04-07T04:42:20Z"}
{"aid":"http://arxiv.org/abs/2504.04732v1","title":"Inverse++: Vision-Centric 3D Semantic Occupancy Prediction Assisted with\n  3D Object Detection","summary":"3D semantic occupancy prediction aims to forecast detailed geometric and\nsemantic information of the surrounding environment for autonomous vehicles\n(AVs) using onboard surround-view cameras. Existing methods primarily focus on\nintricate inner structure module designs to improve model performance, such as\nefficient feature sampling and aggregation processes or intermediate feature\nrepresentation formats. In this paper, we explore multitask learning by\nintroducing an additional 3D supervision signal by incorporating an additional\n3D object detection auxiliary branch. This extra 3D supervision signal enhances\nthe model's overall performance by strengthening the capability of the\nintermediate features to capture small dynamic objects in the scene, and these\nsmall dynamic objects often include vulnerable road users, i.e. bicycles,\nmotorcycles, and pedestrians, whose detection is crucial for ensuring driving\nsafety in autonomous vehicles. Extensive experiments conducted on the nuScenes\ndatasets, including challenging rainy and nighttime scenarios, showcase that\nour approach attains state-of-the-art results, achieving an IoU score of 31.73%\nand a mIoU score of 20.91% and excels at detecting vulnerable road users (VRU).\nThe code will be made available at:https://github.com/DanielMing123/Inverse++","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-07T05:08:22Z"}
{"aid":"http://arxiv.org/abs/2504.04734v1","title":"Teaching Data Science Students to Sketch Privacy Designs through\n  Heuristics (Extended Technical Report)","summary":"Recent studies reveal that experienced data practitioners often draw sketches\nto facilitate communication around privacy design concepts. However, there is\nlimited understanding of how we can help novice students develop such\ncommunication skills. This paper studies methods for lowering novice data\nscience students' barriers to creating high-quality privacy sketches. We first\nconducted a need-finding study (N=12) to identify barriers students face when\nsketching privacy designs. We then used a human-centered design approach to\nguide the method development, culminating in three simple, text-based\nheuristics. Our user studies with 24 data science students revealed that simply\npresenting three heuristics to the participants at the beginning of the study\ncan enhance the coverage of privacy-related design decisions in sketches,\nreduce the mental effort required for creating sketches, and improve the\nreadability of the final sketches.","main_category":"cs.HC","categories":"cs.HC,cs.CR,cs.CY","published":"2025-04-07T05:12:21Z"}
{"aid":"http://arxiv.org/abs/2504.04739v1","title":"MedGNN: Capturing the Links Between Urban Characteristics and Medical\n  Prescriptions","summary":"Understanding how urban socio-demographic and environmental factors relate\nwith health is essential for public health and urban planning. However,\ntraditional statistical methods struggle with nonlinear effects, while machine\nlearning models often fail to capture geographical (nearby areas being more\nsimilar) and topological (unequal connectivity between places) effects in an\ninterpretable way. To address this, we propose MedGNN, a spatio-topologically\nexplicit framework that constructs a 2-hop spatial graph, integrating\npositional and locational node embeddings with urban characteristics in a graph\nneural network. Applied to MEDSAT, a comprehensive dataset covering over 150\nenvironmental and socio-demographic factors and six prescription outcomes\n(depression, anxiety, diabetes, hypertension, asthma, and opioids) across 4,835\nGreater London neighborhoods, MedGNN improved predictions by over 25% on\naverage compared to baseline methods. Using depression prescriptions as a case\nstudy, we analyzed graph embeddings via geographical principal component\nanalysis, identifying findings that: align with prior research (e.g., higher\nantidepressant prescriptions among older and White populations), contribute to\nongoing debates (e.g., greenery linked to higher and NO2 to lower\nprescriptions), and warrant further study (e.g., canopy evaporation correlated\nwith fewer prescriptions). These results demonstrate MedGNN's potential, and\nmore broadly, of carefully applied machine learning, to advance\ntransdisciplinary public health research.","main_category":"cs.LG","categories":"cs.LG,cs.CY","published":"2025-04-07T05:35:16Z"}
{"aid":"http://arxiv.org/abs/2504.04744v1","title":"Grounding 3D Object Affordance with Language Instructions, Visual\n  Observations and Interactions","summary":"Grounding 3D object affordance is a task that locates objects in 3D space\nwhere they can be manipulated, which links perception and action for embodied\nintelligence. For example, for an intelligent robot, it is necessary to\naccurately ground the affordance of an object and grasp it according to human\ninstructions. In this paper, we introduce a novel task that grounds 3D object\naffordance based on language instructions, visual observations and\ninteractions, which is inspired by cognitive science. We collect an Affordance\nGrounding dataset with Points, Images and Language instructions (AGPIL) to\nsupport the proposed task. In the 3D physical world, due to observation\norientation, object rotation, or spatial occlusion, we can only get a partial\nobservation of the object. So this dataset includes affordance estimations of\nobjects from full-view, partial-view, and rotation-view perspectives. To\naccomplish this task, we propose LMAffordance3D, the first multi-modal,\nlanguage-guided 3D affordance grounding network, which applies a\nvision-language model to fuse 2D and 3D spatial features with semantic\nfeatures. Comprehensive experiments on AGPIL demonstrate the effectiveness and\nsuperiority of our method on this task, even in unseen experimental settings.\nOur project is available at https://sites.google.com/view/lmaffordance3d.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.RO","published":"2025-04-07T05:38:23Z"}
{"aid":"http://arxiv.org/abs/2504.04751v1","title":"Unsupervised Estimation of Nonlinear Audio Effects: Comparing\n  Diffusion-Based and Adversarial approaches","summary":"Accurately estimating nonlinear audio effects without access to paired\ninput-output signals remains a challenging problem.This work studies\nunsupervised probabilistic approaches for solving this task. We introduce a\nmethod, novel for this application, based on diffusion generative models for\nblind system identification, enabling the estimation of unknown nonlinear\neffects using black- and gray-box models. This study compares this method with\na previously proposed adversarial approach, analyzing the performance of both\nmethods under different parameterizations of the effect operator and varying\nlengths of available effected recordings.Through experiments on guitar\ndistortion effects, we show that the diffusion-based approach provides more\nstable results and is less sensitive to data availability, while the\nadversarial approach is superior at estimating more pronounced distortion\neffects. Our findings contribute to the robust unsupervised blind estimation of\naudio effects, demonstrating the potential of diffusion models for system\nidentification in music technology.","main_category":"eess.AS","categories":"eess.AS,cs.AI","published":"2025-04-07T05:56:51Z"}
{"aid":"http://arxiv.org/abs/2504.04757v1","title":"The Complexity of Maximal Common Subsequence Enumeration","summary":"Frequent pattern mining is widely used to find ``important'' or\n``interesting'' patterns in data. While it is not easy to mathematically define\nsuch patterns, maximal frequent patterns are promising candidates, as frequency\nis a natural indicator of relevance and maximality helps to summarize the\noutput. As such, their mining has been studied on various data types, including\nitemsets, graphs, and strings. The complexity of mining maximal frequent\nitemsets and subtrees has been thoroughly investigated (e.g., [Boros et al.,\n2003], [Uno et al., 2004]) in the literature. On the other hand, while the idea\nof mining frequent subsequences in sequential data was already introduced in\nthe seminal paper [Agrawal et al., 1995], the complexity of the problem is\nstill open.\n  In this paper, we investigate the complexity of the maximal common\nsubsequence enumeration problem, which is both an important special case of\nmaximal frequent subsequence mining and a generalization of the classic longest\ncommon subsequence (LCS) problem. We show the hardness of enumerating maximal\ncommon subsequences between multiple strings, ruling out the possibility of an\n\\emph{output-polynomial time} enumeration algorithm under $P \\neq NP$, that is,\nan algorithm that runs in time ${\\rm poly}(|\\mathcal I| + N)$, where $|\\mathcal\nI|$ and $N$ are the size of the input and number of output solutions,\nrespectively. To circumvent this intractability, we also investigate the\nparameterized complexity of the problem, and show several results when the\nalphabet size, the number of strings, and the length of a string are taken into\naccount as parameters.","main_category":"cs.DS","categories":"cs.DS,cs.CC","published":"2025-04-07T06:11:33Z"}
{"aid":"http://arxiv.org/abs/2504.04760v1","title":"The spin measurement of the black hole SLX 1746-331 using Insight-HXMT\n  observations","summary":"We present an X-ray spectral analysis of a black hole X-ray binary SLX\n1746-331 during the 2023 outburst using five \\textit{Insight}-HXMT\nobservations. We jointly use the reflection model \\texttt{relxillcp} and the\ngeneral relativistic thermal thin disk model \\texttt{kerrbb} to fit the spectra\nfrom 2 - 100 keV. By jointly fitting the five spectra, we constrained the black\nhole mass to be $M=5.8\\pm 0.3 M_{\\odot}$ and dimensionless spin parameter to be\n$a_{*}=0.88^{+0.01}_{-0.02}$ (90 percent statistical confidence). The\nreflection model shows that SLX 1746-331 is a high-inclination system with the\ninclination angle $i=63.7^{+1.3}_{-1.0}$ degrees, the accretion disk has a\ndensity $\\rm{log}N\\sim 16 ~\\rm cm^{-3}$. In addition, with the different\nreflection model \\texttt{relxilllp}, which assumes a lamp-post geometry corona,\nwe still give similar results.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.SR","published":"2025-04-07T06:14:48Z"}
{"aid":"http://arxiv.org/abs/2504.04764v1","title":"Enhancing Leaf Disease Classification Using GAT-GCN Hybrid Model","summary":"Agriculture plays a critical role in the global economy, providing\nlivelihoods and ensuring food security for billions. As innovative agricultural\npractices become more widespread, the risk of crop diseases has increased,\nhighlighting the urgent need for efficient, low-intervention disease\nidentification methods. This research presents a hybrid model combining Graph\nAttention Networks (GATs) and Graph Convolution Networks (GCNs) for leaf\ndisease classification. GCNs have been widely used for learning from\ngraph-structured data, and GATs enhance this by incorporating attention\nmechanisms to focus on the most important neighbors. The methodology integrates\nsuperpixel segmentation for efficient feature extraction, partitioning images\ninto meaningful, homogeneous regions that better capture localized features.\nThe authors have employed an edge augmentation technique to enhance the\nrobustness of the model. The edge augmentation technique has introduced a\nsignificant degree of generalization in the detection capabilities of the\nmodel. To further optimize training, weight initialization techniques are\napplied. The hybrid model is evaluated against the individual performance of\nthe GCN and GAT models and the hybrid model achieved a precision of 0.9822,\nrecall of 0.9818, and F1-score of 0.9818 in apple leaf disease classification,\na precision of 0.9746, recall of 0.9744, and F1-score of 0.9743 in potato leaf\ndisease classification, and a precision of 0.8801, recall of 0.8801, and\nF1-score of 0.8799 in sugarcane leaf disease classification. These results\ndemonstrate the robustness and performance of the model, suggesting its\npotential to support sustainable agricultural practices through precise and\neffective disease detection. This work is a small step towards reducing the\nloss of crops and hence supporting sustainable goals of zero hunger and life on\nland.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T06:31:38Z"}
{"aid":"http://arxiv.org/abs/2504.04768v1","title":"Strong approximation and central limit theorems for multiscale\n  stochastic gene networks","summary":"We study a mutliscale jump process introduced in a work by Crudu, Debussche,\nMuller and Radulescu. Using an adequate coupling, we are able to prove the\nstrong convergence, for the uniform topology, to a piecewise deterministic\nMarkov process. Under some additional regularity, we also obtain a central\nlimit theorem and prove that the fluctuations of the continuous scale converge,\nin a weaker sense, to the solution of a stochastic differential equation.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T06:46:30Z"}
{"aid":"http://arxiv.org/abs/2504.04775v1","title":"Low-Count X-ray Polarimetry using the Bayesian Approach Reveals Fast\n  Polarization Angle Variations","summary":"X-ray polarimetry of accreting compact object has revealed fast time\nvariations in the polarization angle (PA), suggesting that the geometry and/or\noptical depth of the corona is changing rapidly. This prompts investigations\ninto how fast such variability can be. Conventionally, the data are often\nbinned to examine the time variability such that the measurement in each bin is\nabove the minimum detectable polarization (MDP). Here we demonstrate that this\nis unnecessary, and even below the MDP, one can infer the posterior\ndistribution of PA reliably using the Bayesian approach and still be able to\nplace useful constraints on the physics in many cases. With this approach, we\ndiscovered that the PA variation in one of the Imaging X-ray Polarimetry\nExplorer (IXPE) observations of GX 13+1 is not following a linear rotation mode\nas suggested previously. Instead, the PA swings between two discrete angles,\nsuggesting that there are two emitting components, e.g., the boundary layer and\nthe spreading layer, competing with each other. Also in one of the observations\nof GX 13+1 and Sco X-1, the PA is found to vary in correlation with the source\ncount rate, indicating that the mass accretion rate is shaping the corona\nproperties. Also, during the IXPE observation of Sco X-1, the PA in highest\nflux level seems to deviate from the averaged value and appear to be consistent\nwith previous measurement results with PolarLight and OSO-8.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-07T07:09:08Z"}
{"aid":"http://arxiv.org/abs/2504.04788v1","title":"Parametrically driven Kerr temporal soliton crystals","summary":"We theoretically investigate the excitation, dynamics of parametrically\ndriven soliton crystals and their resulting frequency combs in doubly resonant\ncavities with quadratic and cubic nonlinearities. We demonstrate that soliton\ncrystal states act as strong attractors, where pump depletion and pump phase\nplay crucial roles in their stabilization by ensuring equal soliton spacing and\ncoherence. The number of solitons is primarily determined by driving strength.\nAdditionally, we identify a novel nonlinear state in parametric soliton\ncrystals in which circulating solitons periodically alternate their intensities\nand group velocities, a phenomenon we term the soliton-pursuing states.\nFurthermore, due to the phase-selective nature of the optical parametric\nprocess, we show how different configurations of soliton phases influence the\noptical frequency combs, which may enable generating odd harmonic combs.","main_category":"physics.optics","categories":"physics.optics,nlin.PS","published":"2025-04-07T07:32:23Z"}
{"aid":"http://arxiv.org/abs/2504.04789v1","title":"Multimodal Agricultural Agent Architecture (MA3): A New Paradigm for\n  Intelligent Agricultural Decision-Making","summary":"As a strategic pillar industry for human survival and development, modern\nagriculture faces dual challenges: optimizing production efficiency and\nachieving sustainable development. Against the backdrop of intensified climate\nchange leading to frequent extreme weather events, the uncertainty risks in\nagricultural production systems are increasing exponentially. To address these\nchallenges, this study proposes an innovative \\textbf{M}ultimodal\n\\textbf{A}gricultural \\textbf{A}gent \\textbf{A}rchitecture (\\textbf{MA3}),\nwhich leverages cross-modal information fusion and task collaboration\nmechanisms to achieve intelligent agricultural decision-making. This study\nconstructs a multimodal agricultural agent dataset encompassing five major\ntasks: classification, detection, Visual Question Answering (VQA), tool\nselection, and agent evaluation. We propose a unified backbone for sugarcane\ndisease classification and detection tools, as well as a sugarcane disease\nexpert model. By integrating an innovative tool selection module, we develop a\nmultimodal agricultural agent capable of effectively performing tasks in\nclassification, detection, and VQA. Furthermore, we introduce a\nmulti-dimensional quantitative evaluation framework and conduct a comprehensive\nassessment of the entire architecture over our evaluation dataset, thereby\nverifying the practicality and robustness of MA3 in agricultural scenarios.\nThis study provides new insights and methodologies for the development of\nagricultural agents, holding significant theoretical and practical\nimplications. Our source code and dataset will be made publicly available upon\nacceptance.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T07:32:41Z"}
{"aid":"http://arxiv.org/abs/2504.04793v1","title":"X-class flare on Dec 31, 2023, observed by the Solar Ultraviolet Imaging\n  Telescope on board Aditya-L1","summary":"We present the multi-wavelength study of the ejection of a plasma blob from\nthe limb flare SOL2023-12-31T21:36:00 from NOAA 13536 observed by the Solar\nUltraviolet Imaging Telescope (SUIT) on board Aditya-L1. We use SUIT\nobservations along with those from Atmospheric Imaging Assembly (AIA) on board\nSDO and Spectrometer/Telescope for Imaging X-rays (STIX) on board Solar Orbiter\nto infer the kinematics and thermal nature of the ejected blob and its\nconnection to the associated flare. The observations show that the flare was\ncomprised of two eruptions. The blob was ejected during the first eruption and\nlater accelerated to velocities over 1500 km/s measured at a maximum projected\nheight of ~ 178 Mm from the Sun's surface. The acceleration of the ejected\nplasma blob is co-temporal with the bursty appearance of the hard X-ray light\ncurve recorded by STIX. Radio spectrogram observations from STEREO-A/WAVES and\nRSTN reveal type III bursts at the same time, indicative of magnetic\nreconnection. DEM analysis using AIA observations suggests the plasma blob is\ncomprised of cooler and denser plasma in comparison to the ambient corona. To\nthe best of our knowledge, this is the first observation of such a plasma blob\nin the NUV, providing crucial measurements for eruption thermodynamics.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-07T07:37:36Z"}
{"aid":"http://arxiv.org/abs/2504.04794v1","title":"Enhancing Trust in AI Marketplaces: Evaluating On-Chain Verification of\n  Personalized AI models using zk-SNARKs","summary":"The rapid advancement of artificial intelligence (AI) has brought about\nsophisticated models capable of various tasks ranging from image recognition to\nnatural language processing. As these models continue to grow in complexity,\nensuring their trustworthiness and transparency becomes critical, particularly\nin decentralized environments where traditional trust mechanisms are absent.\nThis paper addresses the challenge of verifying personalized AI models in such\nenvironments, focusing on their integrity and privacy. We propose a novel\nframework that integrates zero-knowledge succinct non-interactive arguments of\nknowledge (zk-SNARKs) with Chainlink decentralized oracles to verify AI model\nperformance claims on blockchain platforms. Our key contribution lies in\nintegrating zk-SNARKs with Chainlink oracles to securely fetch and verify\nexternal data to enable trustless verification of AI models on a blockchain.\nOur approach addresses the limitations of using unverified external data for AI\nverification on the blockchain while preserving sensitive information of AI\nmodels and enhancing transparency. We demonstrate our methodology with a linear\nregression model predicting Bitcoin prices using on-chain data verified on the\nSepolia testnet. Our results indicate the framework's efficacy, with key\nmetrics including proof generation taking an average of 233.63 seconds and\nverification time of 61.50 seconds. This research paves the way for transparent\nand trustless verification processes in blockchain-enabled AI ecosystems,\naddressing key challenges such as model integrity and model privacy protection.\nThe proposed framework, while exemplified with linear regression, is designed\nfor broader applicability across more complex AI models, setting the stage for\nfuture advancements in transparent AI verification.","main_category":"cs.CR","categories":"cs.CR,cs.DC","published":"2025-04-07T07:38:29Z"}
{"aid":"http://arxiv.org/abs/2504.04799v1","title":"Topological SchrÃ¶dinger Bridge Matching","summary":"Given two boundary distributions, the Schr\\\"odinger Bridge (SB) problem seeks\nthe ``most likely`` random evolution between them with respect to a reference\nprocess. It has revealed rich connections to recent machine learning methods\nfor generative modeling and distribution matching. While these methods perform\nwell in Euclidean domains, they are not directly applicable to topological\ndomains such as graphs and simplicial complexes, which are crucial for data\ndefined over network entities, such as node signals and edge flows. In this\nwork, we propose the Topological Schr\\\"odinger Bridge problem (TSBP) for\nmatching signal distributions on a topological domain. We set the reference\nprocess to follow some linear tractable topology-aware stochastic dynamics such\nas topological heat diffusion. For the case of Gaussian boundary distributions,\nwe derive a closed-form topological SB (TSB) in terms of its time-marginal and\nstochastic differential. In the general case, leveraging the well-known result,\nwe show that the optimal process follows the forward-backward topological\ndynamics governed by some unknowns. Building on these results, we develop\nTSB-based models for matching topological signals by parameterizing the\nunknowns in the optimal process as (topological) neural networks and learning\nthem through likelihood training. We validate the theoretical results and\ndemonstrate the practical applications of TSB-based models on both synthetic\nand real-world networks, emphasizing the role of topology. Additionally, we\ndiscuss the connections of TSB-based models to other emerging models, and\noutline future directions for topological signal matching.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-07T07:45:21Z"}
{"aid":"http://arxiv.org/abs/2504.04818v1","title":"SUEDE:Shared Unified Experts for Physical-Digital Face Attack Detection\n  Enhancement","summary":"Face recognition systems are vulnerable to physical attacks (e.g., printed\nphotos) and digital threats (e.g., DeepFake), which are currently being studied\nas independent visual tasks, such as Face Anti-Spoofing and Forgery Detection.\nThe inherent differences among various attack types present significant\nchallenges in identifying a common feature space, making it difficult to\ndevelop a unified framework for detecting data from both attack modalities\nsimultaneously. Inspired by the efficacy of Mixture-of-Experts (MoE) in\nlearning across diverse domains, we explore utilizing multiple experts to learn\nthe distinct features of various attack types. However, the feature\ndistributions of physical and digital attacks overlap and differ. This suggests\nthat relying solely on distinct experts to learn the unique features of each\nattack type may overlook shared knowledge between them. To address these\nissues, we propose SUEDE, the Shared Unified Experts for Physical-Digital Face\nAttack Detection Enhancement. SUEDE combines a shared expert (always activated)\nto capture common features for both attack types and multiple routed experts\n(selectively activated) for specific attack types. Further, we integrate CLIP\nas the base network to ensure the shared expert benefits from prior visual\nknowledge and align visual-text representations in a unified space. Extensive\nresults demonstrate SUEDE achieves superior performance compared to\nstate-of-the-art unified detection methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T08:17:54Z"}
{"aid":"http://arxiv.org/abs/2504.04821v1","title":"A Customized SAT-based Solver for Graph Coloring","summary":"We introduce ZykovColor, a novel SAT-based algorithm to solve the graph\ncoloring problem working on top of an encoding that mimics the Zykov tree. Our\nmethod is based on an approach of H\\'ebrard and Katsirelos (2020) that employs\na propagator to enforce transitivity constraints, incorporate lower bounds for\nsearch tree pruning, and enable inferred propagations. We leverage the recently\nintroduced IPASIR-UP interface for CaDiCal to implement these techniques with a\nSAT solver. Furthermore, we propose new features that take advantage of the\nunderlying SAT solver. These include modifying the integrated decision strategy\nwith vertex domination hints and using incremental bottom-up search that allows\nto reuse learned clauses from previous calls. Additionally, we integrate a more\nefficient clique computation to improve the lower bounds during the search. We\nvalidate the effectiveness of each new feature through an experimental\nanalysis. ZykovColor outperforms other state-of-the-art graph coloring\nimplementations on the DIMACS benchmark set. Further experiments on random\nErd\\H{o}s-R\\'enyi graphs show that our new approach dominates state-of-the-art\nSAT-based methods for both very sparse and highly dense graphs.","main_category":"cs.DM","categories":"cs.DM,cs.AI,cs.DS,cs.LO,G.2.2","published":"2025-04-07T08:22:00Z"}
{"aid":"http://arxiv.org/abs/2504.04826v1","title":"A structure and asymptotic preserving scheme for the quasineutral limit\n  of the Vlasov-Poisson system","summary":"In this work, we propose a new numerical method for the Vlasov-Poisson system\nthat is both asymptotically consistent and stable in the quasineutral regime,\ni.e. when the Debye length is small compared to the characteristic spatial\nscale of the physical domain. Our approach consists in reformulating the\nVlasov-Poisson system as a hyperbolic problem by applying a spectral expansion\nin the basis of Hermite functions in the velocity space and in designing a\nstructure-preserving scheme for the time and spatial variables. Through this\nHermite formulation, we establish a convergence result for the electric field\ntoward its quasineutral limit together with optimal error estimates. Following\nthis path, we then propose a fully discrete numerical method for the\nVlasov-Poisson system, inspired by the approach in arXiv:2306.14605 , and\nrigorously prove that it is uniformly consistent in the quasineutral limit\nregime. Finally, we present several numerical simulations to illustrate the\nbehavior of the proposed scheme. These results demonstrate the capability of\nour method to describe quasineutral plasmas and confirm the theoretical\nfindings: stability and asymptotic preservation.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-07T08:32:13Z"}
{"aid":"http://arxiv.org/abs/2504.04835v1","title":"Inland Waterway Object Detection in Multi-environment: Dataset and\n  Approach","summary":"The success of deep learning in intelligent ship visual perception relies\nheavily on rich image data. However, dedicated datasets for inland waterway\nvessels remain scarce, limiting the adaptability of visual perception systems\nin complex environments. Inland waterways, characterized by narrow channels,\nvariable weather, and urban interference, pose significant challenges to object\ndetection systems based on existing datasets. To address these issues, this\npaper introduces the Multi-environment Inland Waterway Vessel Dataset (MEIWVD),\ncomprising 32,478 high-quality images from diverse scenarios, including sunny,\nrainy, foggy, and artificial lighting conditions. MEIWVD covers common vessel\ntypes in the Yangtze River Basin, emphasizing diversity, sample independence,\nenvironmental complexity, and multi-scale characteristics, making it a robust\nbenchmark for vessel detection. Leveraging MEIWVD, this paper proposes a\nscene-guided image enhancement module to improve water surface images based on\nenvironmental conditions adaptively. Additionally, a parameter-limited dilated\nconvolution enhances the representation of vessel features, while a multi-scale\ndilated residual fusion method integrates multi-scale features for better\ndetection. Experiments show that MEIWVD provides a more rigorous benchmark for\nobject detection algorithms, and the proposed methods significantly improve\ndetector performance, especially in complex multi-environment scenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T08:45:00Z"}
{"aid":"http://arxiv.org/abs/2504.04848v1","title":"Some remarks on almost locally uniformly rotund points","summary":"We study the relations between different notions of almost locally uniformly\nrotund points that appear in literature. We show that every non-reflexive\nBanach space admits an equivalent norm having a point in the corresponding unit\nsphere which is not almost locally uniformly rotund, and which is strongly\nexposed by all its supporting functionals. This result is in contrast with a\ncharacterization due to P. Bandyopadhyay, D. Huang, and B.-L. Lin from 2004. We\nalso show that such a characterization remains true in reflexive Banach spaces.","main_category":"math.FA","categories":"math.FA","published":"2025-04-07T09:03:25Z"}
{"aid":"http://arxiv.org/abs/2504.04850v1","title":"An Efficient Approach for Cooperative Multi-Agent Learning Problems","summary":"In this article, we propose a centralized Multi-Agent Learning framework for\nlearning a policy that models the simultaneous behavior of multiple agents that\nneed to coordinate to solve a certain task. Centralized approaches often suffer\nfrom the explosion of an action space that is defined by all possible\ncombinations of individual actions, known as joint actions. Our approach\naddresses the coordination problem via a sequential abstraction, which\novercomes the scalability problems typical to centralized methods. It\nintroduces a meta-agent, called \\textit{supervisor}, which abstracts joint\nactions as sequential assignments of actions to each agent. This sequential\nabstraction not only simplifies the centralized joint action space but also\nenhances the framework's scalability and efficiency. Our experimental results\ndemonstrate that the proposed approach successfully coordinates agents across a\nvariety of Multi-Agent Learning environments of diverse sizes.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T09:03:35Z"}
{"aid":"http://arxiv.org/abs/2504.04851v1","title":"Nonlinear Phase Gates as Airy Transforms of the Wigner Function","summary":"Low-order nonlinear phase gates allow the construction of versatile\nhigher-order nonlinearities for bosonic systems and grant access to continuous\nvariable quantum simulations of many unexplored aspects of nonlinear quantum\ndynamics. The resulting nonlinear transformations produce, even with small\nstrength, multiple regions of negativity in the Wigner function and thus show\nan immediate departure from classical phase space. Towards the development of\nrealistic, bounded versions of these gates we show that the action of a\nquartic-bounded cubic gate on an arbitrary multimode quantum state in phase\nspace can be understood as an Airy transform of the Wigner function. This\ntoolbox generalises the symplectic transformations associated with Gaussian\noperations and allows for the practical calculation, analysis and\ninterpretation of explicit Wigner functions and the quantum non-Gaussian\nphenomena resulting from bounded nonlinear potentials.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-07T09:07:56Z"}
{"aid":"http://arxiv.org/abs/2504.04867v1","title":"FedSAUC: A Similarity-Aware Update Control for Communication-Efficient\n  Federated Learning in Edge Computing","summary":"Federated learning is a distributed machine learning framework to\ncollaboratively train a global model without uploading privacy-sensitive data\nonto a centralized server. Usually, this framework is applied to edge devices\nsuch as smartphones, wearable devices, and Internet of Things (IoT) devices\nwhich closely collect information from users. However, these devices are mostly\nbattery-powered. The update procedure of federated learning will constantly\nconsume the battery power and the transmission bandwidth. In this work, we\npropose an update control for federated learning, FedSAUC, by considering the\nsimilarity of users' behaviors (models). At the server side, we exploit\nclustering algorithms to group devices with similar models. Then we select some\nrepresentatives for each cluster to update information to train the model. We\nalso implemented a testbed prototyping on edge devices for validating the\nperformance. The experimental results show that this update control will not\naffect the training accuracy in the long run.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-07T09:21:43Z"}
{"aid":"http://arxiv.org/abs/2504.04871v1","title":"Characteristics of Ge-doped Multi-Mode Fibers in Total Ionizing Dose","summary":"Purpose: The fiber optical links in 850 nm band with Ge-doped multi-mode (MM)\nfibers are well developed for data transmission at 10 Gbps and higher. The\napplications in nuclear environments require radiation resistance. The\ncharacteristics of Ge-doped MM fibers are investigated for Radiation Induced\nAttenuation (RIA) in Total Ionizing Dose (TID).\n  Methods: Commercial samples of Ge-doped MM fibers were irradiated in Go-60\ngamma rays at dose rates of 5 to 1.4k Gy(SiO2)/hr. The fiber samples were\npackaged in water tanks maintained at constant temperatures in the range of -15\nto 45 degC. The optical power transmitted through the fibers were recorded in\nirradiation, and in annealing when the source was shielded. The measurements of\nRIA in time are analyzed for dose rate and temperature dependences.\n  Results: Ge-doped fiber samples of OM2 to OM4 grades were investigated for\nattenuation of optical power in radiation ionizing dose. Depending on the\nfabrication technology, two of the fiber types show radiation resistance with\nthe RIAs of 0.2 dB/m and 0.05 dB/m, respectively, for the TID of 300 kGy(SiO2).\nAt low dose rate of 5 Gy/hr, the RIA increases steadily and the annealing of\nlow density ionizing defects does not cause notable deviation. At 1.4 kGy/hr\nthe accumulated defects result to twice higher RIA during irradiation, and is\nworsen to a factor three in cold temperature. However, once the source is\nshielded the recovery is effective in a few hours.\n  Conclusion: The telecom products of 850 nm Ge-doped MM fibers provide high\nspeed communication in distances of a few hundred meters. The industrial\nfabrication methods provide fibers that can endure radiation ionizing dose for\napplications in nuclear instrumentation.","main_category":"physics.med-ph","categories":"physics.med-ph,hep-ex","published":"2025-04-07T09:26:05Z"}
{"aid":"http://arxiv.org/abs/2504.04874v1","title":"Futureproof Static Memory Planning","summary":"The NP-complete combinatorial optimization task of assigning offsets to a set\nof buffers with known sizes and lifetimes so as to minimize total memory usage\nis called dynamic storage allocation (DSA). Existing DSA implementations bypass\nthe theoretical state-of-the-art algorithms in favor of either fast but\nwasteful heuristics, or memory-efficient approaches that do not scale beyond\none thousand buffers. The \"AI memory wall\", combined with deep neural networks'\nstatic architecture, has reignited interest in DSA. We present idealloc, a\nlow-fragmentation, high-performance DSA implementation designed for\nmillion-buffer instances. Evaluated on a novel suite of particularly hard\nbenchmarks from several domains, idealloc ranks first against four production\nimplementations in terms of a joint effectiveness/robustness criterion.","main_category":"cs.OS","categories":"cs.OS,cs.AI,cs.PL","published":"2025-04-07T09:28:54Z"}
{"aid":"http://arxiv.org/abs/2504.04877v1","title":"SoK: LLM-based Log Parsing","summary":"Log data, generated by software systems, provides crucial insights for tasks\nlike monitoring, root cause analysis, and anomaly detection. Due to the vast\nvolume of logs, automated log parsing is essential to transform semi-structured\nlog messages into structured representations. Traditional log parsing\ntechniques often require manual configurations, such as defining log formats or\nlabeling data, which limits scalability and usability. Recent advances in large\nlanguage models (LLMs) have introduced the new research field of LLM-based log\nparsing, offering potential improvements in automation and adaptability.\nDespite promising results, there is no structured overview of these approaches\nsince this is a relatively new research field with the earliest advances\npublished in late 2023. This paper systematically reviews 29 LLM-based log\nparsing methods, comparing their capabilities, limitations, and reliance on\nmanual effort. We analyze the learning and prompt-engineering paradigms\nemployed, efficiency- and effectiveness-enhancing techniques, and the role of\nLLMs in the parsing process. We aggregate the results of the survey in a large\ntable comprising the characterizing features of LLM-based log parsing\napproaches and derive the general process of LLM-based log parsing,\nincorporating all reviewed approaches in a single flow chart. Additionally, we\nbenchmark seven open-source LLM-based log parsers on public datasets and\ncritically assess their reproducibility. Our findings summarize the advances of\nthis new research field and provide insights for researchers and practitioners\nseeking efficient and user-friendly log parsing solutions, with all code and\nresults made publicly available for transparency.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-07T09:41:04Z"}
{"aid":"http://arxiv.org/abs/2504.04879v1","title":"Mixed memories in Hopfield networks","summary":"We consider the class of Hopfield models of associative memory with\nactivation function $F$ and state space $\\{-1,1\\}^N$, where each vertex of the\ncube describes a configuration of $N$ binary neurons. $M$ randomly chosen\nconfigurations, called patterns, are stored using an energy function designed\nto make them local minima. If they are, which is known to depend on how $M$\nscales with $N$, then they can be retrieved using a dynamics that decreases the\nenergy. However, storing the patterns in the energy function also creates\nunintended local minima, and thus false memories. Although this has been known\nsince the earliest work on the subject, it has only been supported by numerical\nsimulations and non-rigorous calculations, except in elementary cases.\n  Our results are twofold. For a generic function $F$, we explicitly construct\na set of configurations, called mixed memories, whose properties are intended\nto characterise the local minima of the energy function. For three prominent\nmodels, namely the classical, the dense and the modern Hopfield models,\nobtained for quadratic, polynomial and exponential functions $F$ respectively,\nwe give conditions on the growth rate of $M$ which guarantee that, as $N$\ndiverges, mixed memories are fixed points of the retrieval dynamics and thus\nexact minima of the energy. We conjecture that in this regime, all local minima\nare mixed memories.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T09:41:49Z"}
{"aid":"http://arxiv.org/abs/2504.04880v1","title":"Investigation of the baryon time-like electromagnetic form factors in\n  the electron-positron annihilation reactions","summary":"Based on the experimental measurements of the electron-positron annihilation\nreactions into a baryon ($B$) and anti-baryon ($\\bar{B}$) pair, the\nelectromagnetic form factors of hyperons in the time-like region can be\ninvestigated within the vector meson dominance model. The theoretical model\nparameters are determined by fitting them to the total cross sections of the\nprocess $e^+e^-\\to B \\bar{B}$, and it is found that the current experimental\ndata on the baryon electromagnetic form factors in the time-like region can be\nwell reproduced. In addition to the total cross sections, the electromagnetic\nform factors $G_E$ and $G_M$, and the charge radii of those baryons are also\nestimated, which are in agreement with the experimental data. On the other\nhand, we have also investigated the nonmonotonic behavior of the time-like\nbaryon electromagnetic form factors, and it is found that the previously\nproposed periodic behaviour of the nucleon time-like electromagnetic form\nfactor is not confirmed. However, we do observe the nonmonotonic structures in\nthe line shape of the baryon effective form factors or the ratio $|G_E/G_M|$\nfor the charmed baryon $\\Lambda^+_c$. These features can be naturally explained\nby incorporating contributions from excited vector states. More precise\nmeasurements of the $e^+e^-\\to B \\bar{B}$ reaction offer a valuable opportunity\nto probe the properties of excited vector states, which are at present poorly\nknown. Additionally, comprehensive theoretical and experimental studies of\nbaryon timelike electromagnetic form factors can provide critical insights into\nthe underlying mechanisms of electron-positron annihilation processes.","main_category":"hep-ph","categories":"hep-ph,hep-ex,nucl-ex,nucl-th","published":"2025-04-07T09:42:07Z"}
{"aid":"http://arxiv.org/abs/2504.04890v1","title":"Stellar isotropic model in the symmetric teleparallel equivalent of\n  general relativity theory","summary":"Recently, the theory of symmetric teleparallel equivalent of general\nrelativity (STEGR) has gained much interest in the cosmology and astrophysics\ncommunity. Within this theory, we discuss the method of deriving a stellar\nisotropic model. In this respect, we implement the equations of motion of STEGR\ntheory to a spacetime that is symmetric in a spherical manner, resulting in a\nset of nonlinear differential equations with more unknowns than equations. To\nsolve this issue, we assume a special form of $g_{tt}$, and suppose a null\nvalue of the anisotropy to obtain the form of $g_{rr}$. We then investigate the\npossibility of obtaining an isotropic stellar model consistent with\nobservational data. To test the stability of our model, we apply the adiabatic\nindex and the Tolman-Oppenheimer-Volkoff equation. Furthermore, we examine our\nmodel using different observed values of radii and masses of pulsars, showing\nthat all of them fit in a consistent way.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-07T09:57:34Z"}
{"aid":"http://arxiv.org/abs/2504.04892v1","title":"Recent progress on second-order elliptic and parabolic equations in\n  double divergence form","summary":"This article presents a comprehensive overview and supplement to recent\ndevelopments in second-order elliptic partial differential equations formulated\nin double divergence form, along with an exploration of their parabolic\ncounterparts.","main_category":"math.AP","categories":"math.AP","published":"2025-04-07T10:00:22Z"}
{"aid":"http://arxiv.org/abs/2504.04899v1","title":"Achieving precision in measuring birefringence characteristics of a\n  periodically-poled Lithium Niobate waveguide","summary":"The refraction of light in an optical medium is not only a subject of\nfundamental interest, but the refractive index also plays a crucial role in\napplications involving integrated and non-linear optics. One such application\nis photon-pair generation in waveguides with second-order non-linearity. The\nspectral properties of the generated photon pairs are governed by the effective\ngroup refractive indices of the interacting modes, which normally are\ncalculated via Sellmeier's equations for bulk crystals. However, in integrated\noptics, the effective group refractive indices experienced by the propagating\nmodes can differ from those in bulk materials. Therefore, we present an\naccurate, in-situ measurement technique for determining the birefringence\ncharacteristics of a structure with high reflective end facets by performing a\nFourier transformation of the light transmission spectrum and apply this method\nto a periodically-poled Lithium Niobate waveguide resonator in the telecom\nwavelength range. We directly predict important spectral figures of merit of\nthe photon-pair generation process, which depend on the optical path length\ndifference that can be resolved with a high precision of more than 16 standard\ndeviations.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-07T10:15:03Z"}
{"aid":"http://arxiv.org/abs/2504.04910v1","title":"Fault Localisation in Infinite-Dimensional Linear Electrical Networks","summary":"We present a novel fault localisation methodology for linear time-invariant\nelectrical networks with infinite-dimensional edge dynamics and uncertain fault\ndynamics. The theory accommodates instability and also bounded propagation\ndelays in the network. The goal is to estimate the location of a fault along a\ngiven network edge, using sensors positioned arbitrarily throughout the\nnetwork. Passive faults of unknown impedance are considered, along with stable\nfaults of known impedance. To illustrate the approach, we tackle a significant\nuse-case: a multi-conductor transmission line, with dynamics modelled by the\nTelegrapher's equation, subject to a line-to-ground fault. Frequency-domain\ninsights are used to reformulate the general fault localisation problem into a\nnon-convex scalar optimisation problem, of which the true fault location is\nguaranteed to be a global minimiser. Numerical experiments are run to quantify\nlocalisation performance over a range of fault resistances.","main_category":"eess.SY","categories":"eess.SY,cs.SY,eess.SP,math.DS","published":"2025-04-07T10:40:25Z"}
{"aid":"http://arxiv.org/abs/2504.04911v1","title":"IterMask3D: Unsupervised Anomaly Detection and Segmentation with\n  Test-Time Iterative Mask Refinement in 3D Brain MR","summary":"Unsupervised anomaly detection and segmentation methods train a model to\nlearn the training distribution as 'normal'. In the testing phase, they\nidentify patterns that deviate from this normal distribution as 'anomalies'. To\nlearn the `normal' distribution, prevailing methods corrupt the images and\ntrain a model to reconstruct them. During testing, the model attempts to\nreconstruct corrupted inputs based on the learned 'normal' distribution.\nDeviations from this distribution lead to high reconstruction errors, which\nindicate potential anomalies. However, corrupting an input image inevitably\ncauses information loss even in normal regions, leading to suboptimal\nreconstruction and an increased risk of false positives. To alleviate this, we\npropose IterMask3D, an iterative spatial mask-refining strategy designed for 3D\nbrain MRI. We iteratively spatially mask areas of the image as corruption and\nreconstruct them, then shrink the mask based on reconstruction error. This\nprocess iteratively unmasks 'normal' areas to the model, whose information\nfurther guides reconstruction of 'normal' patterns under the mask to be\nreconstructed accurately, reducing false positives. In addition, to achieve\nbetter reconstruction performance, we also propose using high-frequency image\ncontent as additional structural information to guide the reconstruction of the\nmasked area. Extensive experiments on the detection of both synthetic and\nreal-world imaging artifacts, as well as segmentation of various pathological\nlesions across multiple MRI sequences, consistently demonstrate the\neffectiveness of our proposed method.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-07T10:41:23Z"}
{"aid":"http://arxiv.org/abs/2504.04916v1","title":"Age-of-information minimization under energy harvesting and\n  non-stationary environment","summary":"This work focuses on minimizing the age of information for multiple energy\nharvesting sources that sample data and transmit it to a sink node. At each\ntime, the central scheduler selects one of the sources to probe the quality of\nits channel to the sink node, and then the assessed channel quality is utilized\nto determine whether a source will sample and send the packet. For a single\nsource case, we assume that the probed channel quality is known at each time\ninstant, model the problem of AoI minimization as a Markov decision process,\nand prove the optimal sampling policy threshold structure. We then use this\nthreshold structure and propose an AEC-SW-UCRL2 algorithm to handle unknown and\ntime varying energy harvesting rate and channel statistics, motivated by the\npopular SWUCRL2 algorithm for non stationary reinforcement learning. This\nalgorithm is applicable when an upper bound is available for the total\nvariation of each of these quantities over a time horizon. Furthermore, in\nsituations where these variation budgets are not accessible, we introduce the\nAEC-BORL algorithm, motivated by the well known BORL algorithm. For the\nmultiple source case, we demonstrate that the AoI minimization problem can be\nformulated as a constrained MDP, which can be relaxed using a Lagrange\nmultiplier and decoupled into sub problems across source nodes. We also derive\nWhittle index based source scheduling policy for probing and an optimal\nthreshold policy for source sampling. We next leverage this Whittle index and\nthreshold structure to develop the WIT-SW-UCRL2 algorithm for unknown time\nvarying energy harvesting rates and channel statistics under their respective\nvariation budgets. Moreover, we also proposed a Whittle index and threshold\nbased bandit over reinforcement learning (WIT-BORL) algorithm for unknown\nvariation budgets. Finally, we numerically demonstrate the efficacy of our\nalgorithms.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-07T10:53:53Z"}
{"aid":"http://arxiv.org/abs/2504.04917v1","title":"Modeling the circumstellar interaction around SN 2004gq","summary":"The relationship between the mass-loss history and final evolutionary stage\nof massive stars and the properties of the observable supernova (SN) is still\nunder debate. This is especially true for stripped-envelope (Type Ib/c) SNe,\nwhere the progenitor ejects a considerably large amount of material during its\nevolution, which can lead to a circumstellar medium relatively close to the\nexploding star. Moreover, when the star explodes as a SN, this matter may\ncontribute significantly to the generated luminosity because of the\ninteraction. However, the trace of this circumstellar interaction can only be\ninvestigated for a couple of Type Ib/c SNe, and the nature of a close (within\naround $10^{15}$ cm) circumstellar matter (CSM) has also been largely\nunexplored for these objects.\n  Here, we present the results of our radio and bolometric light curve (LC)\nanalysis related to SN 2004gq. We describe a combined model that explains the\nunusual LC properties of this event and supports the circumstellar interaction\nscenario. For that, we computed the quasi-bolometric LC of the SN and fit this\nwith a multicomponent model to gain information on the progenitor and the\nsurrounding circumstellar medium. We also analyzed the available radio LCs\n(taken at 1.4,\\ 4.9 and 8.5 GHz) of SN 2004gq to verify our estimated average\nmass-loss rate, which is one of the most crucial physical properties related to\nCSM models.\n  We infer reasonable parameters for SN 2004gq using radioactive decay and\nmagnetar energy input. To power the entire LC, we must also add an extra energy\nsource related to the CSM. We determine the most essential parameter of this\nmedium: the average mass-loss rate from both LC and radio data fitting. We find\nthat the suggested hidden circumstellar interaction is a viable mechanism that\nprovides the required energy deficiency and that it can be estimated using a\nsimple semi-analytic model.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.SR","published":"2025-04-07T10:59:47Z"}
{"aid":"http://arxiv.org/abs/2504.04918v1","title":"Constitution or Collapse? Exploring Constitutional AI with Llama 3-8B","summary":"As language models continue to grow larger, the cost of acquiring\nhigh-quality training data has increased significantly. Collecting human\nfeedback is both expensive and time-consuming, and manual labels can be noisy,\nleading to an imbalance between helpfulness and harmfulness. Constitutional AI,\nintroduced by Anthropic in December 2022, uses AI to provide feedback to\nanother AI, greatly reducing the need for human labeling. However, the original\nimplementation was designed for a model with around 52 billion parameters, and\nthere is limited information on how well Constitutional AI performs with\nsmaller models, such as LLaMA 3-8B. In this paper, we replicated the\nConstitutional AI workflow using the smaller LLaMA 3-8B model. Our results show\nthat Constitutional AI can effectively increase the harmlessness of the model,\nreducing the Attack Success Rate in MT-Bench by 40.8%. However, similar to the\noriginal study, increasing harmlessness comes at the cost of helpfulness. The\nhelpfulness metrics, which are an average of the Turn 1 and Turn 2 scores,\ndropped by 9.8% compared to the baseline. Additionally, we observed clear signs\nof model collapse in the final DPO-CAI model, indicating that smaller models\nmay struggle with self-improvement due to insufficient output quality, making\neffective fine-tuning more challenging. Our study suggests that, like reasoning\nand math ability, self-improvement is an emergent property.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T11:01:25Z"}
{"aid":"http://arxiv.org/abs/2504.04919v1","title":"Distorted Sounds: Unlocking the Physics of Modern Music","summary":"In the production of modern music, the musical characteristics of the guitar\nor keyboard amplifier play an integral role in the creative process. This\narticle explores the physics of music with an emphasis on the role of\ndistortion in the amplification. In particular, we derive and illustrate how a\ndistorted amplifier creates new musical notes that are not played by the\nmusician, greatly simplifying the playing technique. In providing a\ncomprehensive understanding, we commence with a discussion of the physics of\nmusic, highlighting the harmonic series and its relation to pleasing harmonies.\nThis is placed in the context of the standard music notation of intervals and\ntheir relation to note frequency ratios. We then discuss the problems of tuning\nan instrument and why the equal temperament of standard guitar tuners is\nincompatible with good sounding music when amplifier distortion is involved.\nDrawing on the basic trigonometric identities for angle sums and differences,\nwe show how the nonlinear amplification of a distorted amplifier, generates new\nnotes not played by the musician. Here the importance of setting your guitar\ntuner aside and using your ear to tune is emphasised. We close with a\ndiscussion of how humans decipher musical notes and why some highly distorted\nguitar chords give the impression of low notes that are not actually there.\nThis article will be of assistance to students interested in the physics of\nmusic and lecturers seeking fascinating and relevant applications of\nmathematical trigonometric relations and physics to capture the attention of\ntheir students.","main_category":"physics.pop-ph","categories":"physics.pop-ph","published":"2025-04-07T11:01:46Z"}
{"aid":"http://arxiv.org/abs/2504.04921v1","title":"Expectations vs Reality -- A Secondary Study on AI Adoption in Software\n  Testing","summary":"In the software industry, artificial intelligence (AI) has been utilized more\nand more in software development activities. In some activities, such as\ncoding, AI has already been an everyday tool, but in software testing\nactivities AI it has not yet made a significant breakthrough. In this paper,\nthe objective was to identify what kind of empirical research with industry\ncontext has been conducted on AI in software testing, as well as how AI has\nbeen adopted in software testing practice. To achieve this, we performed a\nsystematic mapping study of recent (2020 and later) studies on AI adoption in\nsoftware testing in the industry, and applied thematic analysis to identify\ncommon themes and categories, such as the real-world use cases and benefits, in\nthe found papers. The observations suggest that AI is not yet heavily utilized\nin software testing, and still relatively few studies on AI adoption in\nsoftware testing have been conducted in the industry context to solve\nreal-world problems. Earlier studies indicated there was a noticeable gap\nbetween the actual use cases and actual benefits versus the expectations, which\nwe analyzed further. While there were numerous potential use cases for AI in\nsoftware testing, such as test case generation, code analysis, and intelligent\ntest automation, the reported actual implementations and observed benefits were\nlimited. In addition, the systematic mapping study revealed a potential problem\nwith false positive search results in online databases when using the search\nstring \"artificial intelligence\".","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-07T11:03:54Z"}
{"aid":"http://arxiv.org/abs/2504.04922v1","title":"Real-time tuneable bright bonding plasmonic modes in Ga nanostructures","summary":"The precise control of nanogaps is crucial for plasmonic nanoassemblies,\nwhere plasmon hybridization is highly sensitive to gap size and geometry. This\nsensitivity enables fine-tuning of the resonance wavelength and near-field\nenhancement, offering the potential for advanced optical applications. However,\nconventional lithographic techniques for gap modulation are constrained to\ndiscrete values and face challenges in achieving nanometer order of\nseparations. Such limitations hinder the comprehensive study of plasmon\ncoupling across varying interaction regimes. Overcoming these challenges is\nessential for advancing nanoplasmonic research and its practical applications.\nHerein, we demonstrate a tuneable plasmonic device in which real-time\ntunability of this hybridization mode is achieved via manipulation of the\ninter-droplet gap of liquid metal nanoparticles by macroscopic physical\ndeformation. In particular, we show that the optical spectra obtained from the\nsample shift towards higher energy on the application of a linear strain,\nresulting in an increase of inter-droplet gaps leading to a direct probing of\nthe bright modes in situ. Our method thus offers a novel means of exploring the\nfundamental concept of real-time tuneable plasmon hybridization as well as\ntuning of nanoparticle assembly with any desired gap in a controlled manner.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-07T11:04:39Z"}
{"aid":"http://arxiv.org/abs/2504.04926v1","title":"Coupling of AlfvÃ©n and magnetosonic waves in rotating Hall\n  magnetoplasmas","summary":"We study the linear theory of magnetohydrodynamic (MHD) waves, namely the\nAlfv{\\'e}n and the fast and slow magnetosonic modes in a rotating Hall-MHD\nplasma with the effects of the obliqueness of the external magnetic field and\nthe Coriolis force and show that these waves can be coupled either by the\ninfluence of the Coriolis force or the Hall effects. To this end, we derive a\ngeneral form of the linear dispersion relation for these coupled modes by the\ncombined influence of the Coriolis force and the Hall effects and analyze\nnumerically their characteristics in three different plasma-$\\beta$ regimes:\n$\\beta\\sim1$, $\\beta>1$, and $\\beta<1$, including some particular cases. We\nshow that while the coupling between the Alfv{\\'e}n and the fast magnetosonic\nmodes is strong in the low-$\\beta$ $(\\beta\\lesssim1)$ regime and the wave\ndispersion appears in the form of a thumb curve, in the high-$\\beta~(\\beta>1)$\nregime, the strong coupling can occur between the Alfv{\\'e}n and the slow\nmagnetosonic modes and the dispersion appears in the form of a teardrop curve.\nSwitching of the coupling in the regime of $\\beta\\sim1$ can occur, i.e.,\ninstead of a thumb curve, a teardrop curve appears when the obliqueness of\npropagation and rotational angle are close to $70^\\circ$ or more (but less than\n$90^\\circ$). Implications of our results to solar and fusion plasmas are\nbriefly discussed.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-07T11:07:20Z"}
{"aid":"http://arxiv.org/abs/2504.04933v1","title":"Deformation of the Heisenberg-Weyl algebra and the Lie superalgebra\n  $\\mathfrak{osp}\\left( {1|2} \\right)$: exact solution for the quantum harmonic\n  oscillator with a position-dependent mass","summary":"We propose a new deformation of the quantum harmonic oscillator\nHeisenberg-Weyl algebra with a parameter $a>-1$. This parameter is introduced\nthrough the replacement of the homogeneous mass $m_0$ in the definition of the\nmomentum operator $\\hat p_x$ as well as in the creation-annihilation operators\n$\\hat a^\\pm$ with a mass varying with position $x$. The realization of such a\ndeformation is shown through the exact solution of the corresponding\nSchr\\\"odinger equation for the non-relativistic quantum harmonic oscillator\nwithin the canonical approach. The obtained analytical expression of the energy\nspectrum consists of an infinite number of equidistant levels, whereas the\nwavefunctions of the stationary states of the problem under construction are\nexpressed through the Hermite polynomials. Then, the Heisenberg-Weyl algebra\ndeformation is generalized to the case of the Lie superalgebra\n$\\mathfrak{osp}\\left( {1|2} \\right)$. It is shown that the realization of such\na generalized superalgebra can be performed for the parabose quantum harmonic\noscillator problem, the mass of which possesses a behavior completely\noverlapping with the position-dependent mass of the canonically deformed\nharmonic oscillator problem. This problem is solved exactly for both even and\nodd stationary states. It is shown that the energy spectrum of the deformed\nparabose oscillator is still equidistant, however, both even and odd state\nwavefunctions are now expressed through the Laguerre polynomials. Some basic\nlimit relations recovering the canonical harmonic oscillator with constant mass\nare also discussed briefly.","main_category":"quant-ph","categories":"quant-ph,cond-mat.other,math-ph,math.MP","published":"2025-04-07T11:18:38Z"}
{"aid":"http://arxiv.org/abs/2504.04944v1","title":"Multiobjective Optimization under Uncertainties using Conditional Pareto\n  Fronts","summary":"In this work, we propose a novel method to tackle the problem of\nmultiobjective optimization under parameteric uncertainties, by considering the\nConditional Pareto Sets and Conditional Pareto Fronts. Based on those\nquantities we can define the probability of coverage of the Conditional Pareto\nSet which can be interpreted as the probability for a design to be optimal in\nthe Pareto sense. Due to the computational cost of such an approach, we\nintroduce an Active Learning method based on Gaussian Process Regression in\norder to improve the estimation of this probability, which relies on a\nreformulation of the EHVI. We illustrate those methods on a few toy problems of\nmoderate dimension, and on the problem of designing a cabin to highlight the\ndifferences in solutions brought by different formulations of the problem.","main_category":"math.OC","categories":"math.OC","published":"2025-04-07T11:30:53Z"}
{"aid":"http://arxiv.org/abs/2504.04947v1","title":"Phase transitions in swarm optimization algorithms","summary":"Natural systems often exhibit chaotic behavior in their space-time evolution.\nSystems transiting between chaos and order manifest a potential to compute, as\nshown with cellular automata and artificial neural networks. We demonstrate\nthat swarms optimisation algorithms also exhibit transitions from chaos,\nanalogous to motion of gas molecules, when particles explore solution space\ndisorderly, to order, when particles follow a leader, similar to molecules\npropagating along diffusion gradients in liquid solutions of reagents. We\nanalyse these `phase-like' transitions in swarm optimization algorithms using\nrecurrence quantification analysis and Lempel-Ziv complexity estimation. We\ndemonstrate that converging and non-converging iterations of the optimization\nalgorithms are statistically different in a view of applied chaos, complexity\nand predictability estimating indicators.","main_category":"physics.comp-ph","categories":"physics.comp-ph,nlin.CD,physics.data-an","published":"2025-04-07T11:33:49Z"}
{"aid":"http://arxiv.org/abs/2504.04954v1","title":"GOTHAM: Graph Class Incremental Learning Framework under Weak\n  Supervision","summary":"Graphs are growing rapidly, along with the number of distinct label\ncategories associated with them. Applications like e-commerce, healthcare,\nrecommendation systems, and various social media platforms are rapidly moving\ntowards graph representation of data due to their ability to capture both\nstructural and attribute information. One crucial task in graph analysis is\nnode classification, where unlabeled nodes are categorized into predefined\nclasses. In practice, novel classes appear incrementally sometimes with just a\nfew labels (seen classes) or even without any labels (unseen classes), either\nbecause they are new or haven't been explored much. Traditional methods assume\nabundant labeled data for training, which isn't always feasible. We investigate\na broader objective: \\emph{Graph Class Incremental Learning under Weak\nSupervision (GCL)}, addressing this challenge by meta-training on base classes\nwith limited labeled instances. During the incremental streams, novel classes\ncan have few-shot or zero-shot representation. Our proposed framework GOTHAM\nefficiently accommodates these unlabeled nodes by finding the closest prototype\nrepresentation, serving as class representatives in the attribute space. For\nText-Attributed Graphs (TAGs), our framework additionally incorporates semantic\ninformation to enhance the representation. By employing teacher-student\nknowledge distillation to mitigate forgetting, GOTHAM achieves promising\nresults across various tasks. Experiments on datasets such as Cora-ML, Amazon,\nand OBGN-Arxiv showcase the effectiveness of our approach in handling evolving\ngraph data under limited supervision. The repository is available here:\n\\href{https://github.com/adityashahane10/GOTHAM--Graph-based-Class-Incremental-Learning-Framework-under-Weak-Supervision}{\\small\n\\textcolor{blue}{Code}}","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T11:39:13Z"}
{"aid":"http://arxiv.org/abs/2504.04955v1","title":"The Short-spacing Interferometer Array for Global 21-cm Signal Detection\n  (SIGMA): Design of the Antennas and Layout","summary":"Numerous experiments have been designed to investigate the Cosmic Dawn (CD)\nand Epoch of Reionization (EoR) by examining redshifted 21-cm emissions from\nneutral hydrogen. Detecting the global spectrum of redshifted 21-cm signals is\ntypically achieved through single-antenna experiments. However, this global\n21-cm signal is deeply embedded in foreground emissions, which are about four\norders of magnitude stronger. Extracting this faint signal is a significant\nchallenge, requiring highly precise instrumental calibration. Additionally,\naccurately modelling receiver noise in single-antenna experiments is inherently\ncomplex. An alternative approach using a short-spacing interferometer is\nexpected to alleviate these difficulties because the noise in different\nreceivers is uncorrelated and averages to zero upon cross-correlation. The\nShort-spacing Interferometer array for Global 21-cm Signal detection (SIGMA) is\nan upcoming experiment aimed at detecting the global CD/EoR signal using this\napproach. We describe the SIGMA system with a focus on optimal antenna design\nand layout, and propose a framework to address cross-talk between antennas in\nfuture calibrations. The SIGMA system is intended to serve as a prototype to\ngain a better understanding of the system's instrumental effects and to\noptimize its performance further.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-07T11:42:30Z"}
{"aid":"http://arxiv.org/abs/2504.04956v1","title":"REWIND: Real-Time Egocentric Whole-Body Motion Diffusion with\n  Exemplar-Based Identity Conditioning","summary":"We present REWIND (Real-Time Egocentric Whole-Body Motion Diffusion), a\none-step diffusion model for real-time, high-fidelity human motion estimation\nfrom egocentric image inputs. While an existing method for egocentric\nwhole-body (i.e., body and hands) motion estimation is non-real-time and\nacausal due to diffusion-based iterative motion refinement to capture\ncorrelations between body and hand poses, REWIND operates in a fully causal and\nreal-time manner. To enable real-time inference, we introduce (1) cascaded\nbody-hand denoising diffusion, which effectively models the correlation between\negocentric body and hand motions in a fast, feed-forward manner, and (2)\ndiffusion distillation, which enables high-quality motion estimation with a\nsingle denoising step. Our denoising diffusion model is based on a modified\nTransformer architecture, designed to causally model output motions while\nenhancing generalizability to unseen motion lengths. Additionally, REWIND\noptionally supports identity-conditioned motion estimation when identity prior\nis available. To this end, we propose a novel identity conditioning method\nbased on a small set of pose exemplars of the target identity, which further\nenhances motion estimation quality. Through extensive experiments, we\ndemonstrate that REWIND significantly outperforms the existing baselines both\nwith and without exemplar-based identity conditioning.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-07T11:44:11Z"}
{"aid":"http://arxiv.org/abs/2504.04975v1","title":"Geometric quantization of generalized Hirzebruch fibrations","summary":"Hirzebruch surfaces, defined as the projectivization of line bundles over\n$\\C\\mathbb{P}^1$, support a toric action and thus represent an infinite class\nof symplectic toric manifolds of complex dimension 2. In this paper, an\ninfinite class of toric manifolds given as projective bundles over\n$\\mathbb{C}\\mathbb{P}^d$ will be constructed for every complex dimension $d$\nand it will be shown that each manifold supports a symplectic structure. With\nthe toric and symplectic structure of the manifolds at our disposal, we then\nstudy their geometric quantization and how it relates to different values of\nthe twisting parameter of the fibrations.","main_category":"math.SG","categories":"math.SG","published":"2025-04-07T12:04:15Z"}
{"aid":"http://arxiv.org/abs/2504.04996v1","title":"Laplacian eigenvalues for large negative Robin parameters on domains\n  with outward peaks","summary":"We study the asymptotic behavior of individual eigenvalues of the Laplacian\nin domains with outward peaks for large negative Robin parameters. A large\nclass of cross-sections is allowed, and the resulting asymptotic expansions\nreflect both the sharpness of the peak and the geometric shape of its\ncross-section. The results are an extension of previous works dealing with\npeaks whose cross-sections are balls.","main_category":"math.AP","categories":"math.AP,math.SP","published":"2025-04-07T12:24:29Z"}
{"aid":"http://arxiv.org/abs/2504.05030v1","title":"AsyReC: A Multimodal Graph-based Framework for Spatio-Temporal\n  Asymmetric Dyadic Relationship Classification","summary":"Dyadic social relationships, which refer to relationships between two\nindividuals who know each other through repeated interactions (or not), are\nshaped by shared spatial and temporal experiences. Current computational\nmethods for modeling these relationships face three major challenges: (1) the\nfailure to model asymmetric relationships, e.g., one individual may perceive\nthe other as a friend while the other perceives them as an acquaintance, (2)\nthe disruption of continuous interactions by discrete frame sampling, which\nsegments the temporal continuity of interaction in real-world scenarios, and\n(3) the limitation to consider periodic behavioral cues, such as rhythmic\nvocalizations or recurrent gestures, which are crucial for inferring the\nevolution of dyadic relationships. To address these challenges, we propose\nAsyReC, a multimodal graph-based framework for asymmetric dyadic relationship\nclassification, with three core innovations: (i) a triplet graph neural network\nwith node-edge dual attention that dynamically weights multimodal cues to\ncapture interaction asymmetries (addressing challenge 1); (ii) a clip-level\nrelationship learning architecture that preserves temporal continuity, enabling\nfine-grained modeling of real-world interaction dynamics (addressing challenge\n2); and (iii) a periodic temporal encoder that projects time indices onto\nsine/cosine waveforms to model recurrent behavioral patterns (addressing\nchallenge 3). Extensive experiments on two public datasets demonstrate\nstate-of-the-art performance, while ablation studies validate the critical role\nof asymmetric interaction modeling and periodic temporal encoding in improving\nthe robustness of dyadic relationship classification in real-world scenarios.\nOur code is publicly available at: https://github.com/tw-repository/AsyReC.","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-07T12:52:23Z"}
{"aid":"http://arxiv.org/abs/2504.05042v1","title":"Lattice packing of spheres in high dimensions using a stochastically\n  evolving ellipsoid","summary":"We prove that in any dimension $n$ there exists an origin-symmetric ellipsoid\n${\\mathcal{E}} \\subset {\\mathbb{R}}^n$ of volume $ c n^2 $ that contains no\npoints of ${\\mathbb{Z}}^n$ other than the origin, where $c > 0$ is a universal\nconstant. Equivalently, there exists a lattice sphere packing in\n${\\mathbb{R}}^n$ whose density is at least $cn^2 \\cdot 2^{-n}$. Previously\nknown constructions of sphere packings in ${\\mathbb{R}}^n$ had densities of the\norder of magnitude of $n \\cdot 2^{-n}$, up to logarithmic factors. Our proof\nutilizes a stochastically evolving ellipsoid that accumulates at least $c n^2$\nlattice points on its boundary, while containing no lattice points in its\ninterior except for the origin.","main_category":"math.MG","categories":"math.MG,math.NT,math.PR","published":"2025-04-07T13:09:05Z"}
{"aid":"http://arxiv.org/abs/2504.05044v1","title":"Fluctuation for interacting particle systems with common noise","summary":"We consider the asymptotic behavior of the fluctuation process for large\nstochastic systems of interacting particles driven by both idiosyncratic and\ncommon noise with an interaction kernel \\(k \\in L^2(\\R^d) \\cap\nL^\\infty(\\R^d)\\). Our analysis relies on uniform relative entropy estimates and\nKolmogorov's compactness criterion to establish tightness and convergence of\nthe fluctuation process. In this framework, an extension of the exponential law\nof large numbers is used to derive the necessary uniform estimates, while a\nconditional Fubini theorem is employed in the identification of the limit in\nthe presence of common noise. We demonstrate that the fluctuation process\nconverges in distribution to the unique solution of a linear stochastic\nevolution equation. This work extends previous fluctuation results beyond the\nclassical Lipschitz framework.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T13:12:55Z"}
{"aid":"http://arxiv.org/abs/2504.05048v1","title":"Secure Communications for All Users in Low-Resolution IRS-aided Systems\n  Under Imperfect and Unknown CSI","summary":"Provisioning secrecy for all users, given the heterogeneity and uncertainty\nof their channel conditions, locations, and the unknown location of the\nattacker/eavesdropper, is challenging and not always feasible. This work takes\nthe first step to guarantee secrecy for all users where a low resolution\nintelligent reflecting surfaces (IRS) is used to enhance legitimate users'\nreception and thwart the potential eavesdropper (Eve) from intercepting. In\nreal-life scenarios, due to hardware limitations of the IRS' passive reflective\nelements (PREs), the use of a full-resolution (continuous) phase shift (CPS) is\nimpractical. In this paper, we thus consider a more practical case where the\nphase shift (PS) is modeled by a low-resolution (quantized) phase shift (QPS)\nwhile addressing the phase shift error (PSE) induced by the imperfect channel\nstate information (CSI). To that end, we aim to maximize the minimum secrecy\nrate (SR) among all users by jointly optimizing the transmitter's beamforming\nvector and the IRS's passive reflective elements (PREs) under\nperfect/imperfect/unknown CSI. The resulting optimization problem is non-convex\nand even more complicated under imperfect/unknown CSI.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-07T13:18:03Z"}
{"aid":"http://arxiv.org/abs/2504.05052v1","title":"Assess Space-Based Solar Power in European-Scale Power System\n  Decarbonization","summary":"Meeting net-zero targets remains formidable as terrestrial renewables grapple\nwith intermittency and regional variability. Here, we integrate space-based\nsolar power (SBSP) -- a potential near-constant, orbital solar technology --\ninto a high-resolution, Europe-wide capacity-expansion and dispatch model to\nquantify its contribution under net-zero constraints. We examine two advanced\nSBSP designs: (1) a near-baseload, low Technology Readiness Level (TRL) concept\n(heliostat-based Representative Design RD1) and (2) a partially intermittent,\nhigher-TRL concept (planar-based RD2), both drawing on NASA's 2050 cost and\nperformance projections. Our results show that RD1 can reduce total system\ncosts by 7--15%, displace up to 80% of intermittent wind and solar, and cut\nbattery usage by over 70%, if it meets its forecast cost reductions -- though\nlong-duration storage (e.g., hydrogen) remains essential for seasonal\nbalancing. By contrast, RD2 is economically unattractive at its projected 2050\ncosts. Through extensive sensitivity analyses, we identify cost thresholds at\nwhich SBSP shifts from cost-prohibitive to complementary and ultimately to a\ndominant baseload technology. Specifically, RD1 becomes complementary at\nroughly 14x and dominant at 9x the 2050 solar PV capital cost, benefiting from\nits continuous power generation. Meanwhile, RD2 must achieve even lower cost\nlevels (9x to be complementary and 6x to dominate) and would rely on\nshort-duration storage to mitigate its partial intermittency. These findings\nprovide quantified techno-economic benchmarks and reveal alternative net-zero\npathways, offering critical guidance for policymakers and industry stakeholders\nseeking large-scale, centrally coordinated renewable solutions with non- or\nlow-intermittency.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-07T13:21:01Z"}
{"aid":"http://arxiv.org/abs/2504.05084v1","title":"Speech-to-Trajectory: Learning Human-Like Verbal Guidance for Robot\n  Motion","summary":"Full integration of robots into real-life applications necessitates their\nability to interpret and execute natural language directives from untrained\nusers. Given the inherent variability in human language, equivalent directives\nmay be phrased differently, yet require consistent robot behavior. While Large\nLanguage Models (LLMs) have advanced language understanding, they often falter\nin handling user phrasing variability, rely on predefined commands, and exhibit\nunpredictable outputs. This letter introduces the Directive Language Model\n(DLM), a novel speech-to-trajectory framework that directly maps verbal\ncommands to executable motion trajectories, bypassing predefined phrases. DLM\nutilizes Behavior Cloning (BC) on simulated demonstrations of human-guided\nrobot motion. To enhance generalization, GPT-based semantic augmentation\ngenerates diverse paraphrases of training commands, labeled with the same\nmotion trajectory. DLM further incorporates a diffusion policy-based trajectory\ngeneration for adaptive motion refinement and stochastic sampling. In contrast\nto LLM-based methods, DLM ensures consistent, predictable motion without\nextensive prompt engineering, facilitating real-time robotic guidance. As DLM\nlearns from trajectory data, it is embodiment-agnostic, enabling deployment\nacross diverse robotic platforms. Experimental results demonstrate DLM's\nimproved command generalization, reduced dependence on structured phrasing, and\nachievement of human-like motion.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T13:54:08Z"}
{"aid":"http://arxiv.org/abs/2504.05092v1","title":"Distortions in Periodicity Analysis of Blazars: The Impact of Flares","summary":"Blazars, a unique class of active galactic nuclei, exhibit highly variable\nemission across the electromagnetic spectrum. This variability frequently\nmanifests as intense flaring events, sparking an ongoing debate in recent\nliterature about whether these flares exhibit periodic behavior in certain\nsources. However, many blazars also show clear signs of stochastic,\nuncorrelated flares that do not follow a regular pattern. This paper explores\nhow the presence of one such of these stochastic flares can distort an\nintrinsically periodic pattern of emission in blazars. Our results demonstrate\nthat, depending on the specific circumstances, the deviations in significance\nand periods can exceed 100\\%. Sometimes, these deviations can be so severe that\nthey eliminate any evidence of a periodic pattern. These findings highlight the\ndramatic impact that flares can have on periodicity searches. To confront this\nchallenge, we propose an innovative approach, the Singular Spectrum Analysis\nmethod, which appears more robust against the effects of flares. As an\nalternative solution, we also propose the sigma clipping technique to mitigate\nthe impact of flares. This framework offers a valuable foundation for analyzing\nperiodicity in similar astrophysical sources that are also subject to\nstochastic flaring events.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-07T14:00:34Z"}
{"aid":"http://arxiv.org/abs/2504.05093v1","title":"Flexible Estimation of the Heterogeneous Non-Parametric Component in a\n  Relative Survival Cure Model","summary":"Estimating the cure fraction in a diseased population, especially in the\npresence of competing mortality causes, is crucial for both patients and\nclinicians. It offers a valuable measure for monitoring and interpreting trends\nin disease outcomes. When information on the cause of death is unavailable or\nunreliable, the Relative Survival (RS) framework is the preferred approach for\nestimating Net Survival, which represents survival in a hypothetical scenario\nwhere the disease of interest is the only possible cause of death. In the\ncontext of cancer, RS often reaches a plateau, indicating that a portion of\ndiagnosed patients is cured, as they have the same risk of dying as a\ncomparable group of healthy individuals with similar demographic\ncharacteristics. Classical RS cure models use logistic regression to estimate\nthe fraction of cured patients. However, this functional form is somewhat\narbitrary, and misspecifying it can severely distort the resulting cure\nindicators. Consequently, evaluations of the efficacy of cancer treatments at\nthe population level could be inaccurate, leading to biased decision-making\nregarding patient care. In this paper, we address this issue by relaxing the\nparametric assumption and considering flexible functions of the covariates\nwithin the framework of \\textit{Generalized Models} and \\textit{Neural\nNetworks}. We design an EM algorithm for these RS cure models and conduct a\nsimulation study to compare our proposals with the classical approach. We apply\nour methodology to a real-world dataset from a historical Italian cancer\nregistry. The results demonstrate that our proposed models outperform the\nclassical approach and provide valuable insights into the survival outcomes of\nItalian colon cancer patients.","main_category":"stat.ME","categories":"stat.ME,stat.AP","published":"2025-04-07T14:00:37Z"}
{"aid":"http://arxiv.org/abs/2504.05095v1","title":"Dust Growth in ALMA Rings: II. Dusty Rossby Wave Instability","summary":"Annular substructures serve as ideal venues for planetesimal formation. In\nthis series, we investigate the linear stage of dust growth within rings. The\nfirst paper examines the global streaming instability, while this study focuses\non the dusty Rossby wave instability (DRWI). We perform a linear analysis of\nthe two-fluid equations on a background pressure bump, representing annular\nsubstructures. The spectral code \\textsc{Dedalus} is used to solve the linear\neigenvalue problem. We identify two distinct DRWI modes: Type I, which\noriginates from dust-modified gas RWI, and Type II, which results from dust-gas\ncoupling. These modes never coexist for a given azimuthal wavenumber $\\ky$, but\ntransition between each other as $\\ky$ varies. Type I modes are driven by the\nadvection of background vorticity, whereas Type II modes involve two primary\nwaves: Rossby waves, driven by advection, and thin waves, driven by dust-gas\ndrag. Finally, we assess the relevance of DRWI in ALMA rings using DSHARP\nsources. Our findings suggest that Type I modes could explain the absence of\nazimuthal asymmetries in many ALMA disks, whereas Type II modes are entirely\nabsent in all eight observed rings, implying that unresolved narrow rings or\nalternative mechanisms may play a role in dust growth within annular\nsubstructures.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-07T14:01:02Z"}
{"aid":"http://arxiv.org/abs/2504.05097v1","title":"State Tuning: State-based Test-Time Scaling on RWKV-7","summary":"Test-time scaling has emerged as a prominent research direction in machine\nlearning, enabling models to enhance their expressive capabilities during\ninference.Transformers, renowned for striking a delicate balance between\nefficiency and expressiveness, have benefited from test-time scaling techniques\nthat leverage an expanding key-value (KV) cache to significantly improve\nperformance.In this paper, we introduce a novel state-based approach to\ntest-time scaling, which we term state tuning, tailored to the RNN-based RWKV-7\nmodel.By exploiting the unique strengths of RWKV-7, our method achieves\nstate-of-the-art performance on the target task without altering the model's\npre-trained weights. Our approach centers on three key innovations. First, we\ndevelop an observer framework that allows a smaller model to replicate and\nlearn the state dynamics of the RWKV-7 model. Second, we employ a kernel method\nto dynamically upscale the state size, enhancing the model's capacity to\ncapture intricate patterns. Third, we integrate Decorrelated Backpropagation\n(DBP) to optimize the upscaled state matrix, thereby improving convergence and\nexpressivity. By tuning only the state matrix, we demonstrate that a smaller\nmodel can outperform larger models on the given task. This method preserves the\nefficiency of the original RWKV-7 architecture while harnessing the power of\ntest-time scaling to deliver superior results. Our findings underscore the\npotential of state tuning as an effective strategy for advancing model\nperformance in resource-constrained settings. Our code is\nhttps://github.com/TorchRWKV/flash-linear-attention.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-07T14:04:30Z"}
{"aid":"http://arxiv.org/abs/2504.05098v1","title":"Shelling and Sinking Graphs on the Sphere","summary":"We describe a promising approach to efficiently morph spherical graphs,\nextending earlier approaches of Awartani and Henderson [Trans. AMS 1987] and\nKobourov and Landis [JGAA 2006]. Specifically, we describe two methods to morph\nshortest-path triangulations of the sphere by moving their vertices along\nlongitudes into the southern hemisphere; we call a triangulation sinkable if\nsuch a morph exists. Our first method generalizes a longitudinal shelling\nconstruction of Awartani and Henderson; a triangulation is sinkable if a\nspecific orientation of its dual graph is acyclic. We describe a simple\npolynomial-time algorithm to find a longitudinally shellable rotation of a\ngiven spherical triangulation, if one exists; we also construct a spherical\ntriangulation that has no longitudinally shellable rotation. Our second method\nis based on a linear-programming characterization of sinkability. By\nidentifying its optimal basis, we show that this linear program can be solved\nin $O(n^{\\omega/2})$ time, where $\\omega$ is the matrix-multiplication\nexponent, assuming the underlying linear system is non-singular. Finally, we\npose several conjectures and describe experimental results that support them.","main_category":"cs.CG","categories":"cs.CG","published":"2025-04-07T14:04:56Z"}
{"aid":"http://arxiv.org/abs/2504.05104v1","title":"AI for Climate Finance: Agentic Retrieval and Multi-Step Reasoning for\n  Early Warning System Investments","summary":"Tracking financial investments in climate adaptation is a complex and\nexpertise-intensive task, particularly for Early Warning Systems (EWS), which\nlack standardized financial reporting across multilateral development banks\n(MDBs) and funds. To address this challenge, we introduce an LLM-based agentic\nAI system that integrates contextual retrieval, fine-tuning, and multi-step\nreasoning to extract relevant financial data, classify investments, and ensure\ncompliance with funding guidelines. Our study focuses on a real-world\napplication: tracking EWS investments in the Climate Risk and Early Warning\nSystems (CREWS) Fund. We analyze 25 MDB project documents and evaluate multiple\nAI-driven classification methods, including zero-shot and few-shot learning,\nfine-tuned transformer-based classifiers, chain-of-thought (CoT) prompting, and\nan agent-based retrieval-augmented generation (RAG) approach. Our results show\nthat the agent-based RAG approach significantly outperforms other methods,\nachieving 87\\% accuracy, 89\\% precision, and 83\\% recall. Additionally, we\ncontribute a benchmark dataset and expert-annotated corpus, providing a\nvaluable resource for future research in AI-driven financial tracking and\nclimate finance transparency.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T14:11:11Z"}
{"aid":"http://arxiv.org/abs/2504.05113v1","title":"Minimal Reduction Type and Affine Springer Fibers","summary":"We extend a result of Yun on minimal reduction types to the parahoric case.\nThis implies a uniqueness property for 2-special representations appearing in\nthe cohomology of certain affine Springer fibers. Using this, we settle a\nconjecture of Lusztig on strata in a reductive group.","main_category":"math.RT","categories":"math.RT","published":"2025-04-07T14:15:55Z"}
{"aid":"http://arxiv.org/abs/2504.05119v1","title":"Balancing Robustness and Efficiency in Embedded DNNs Through Activation\n  Function Selection","summary":"Machine learning-based embedded systems for safety-critical applications,\nsuch as aerospace and autonomous driving, must be robust to perturbations\ncaused by soft errors. As transistor geometries shrink and voltages decrease,\nmodern electronic devices become more susceptible to background radiation,\nincreasing the concern about failures produced by soft errors. The resilience\nof deep neural networks (DNNs) to these errors depends not only on target\ndevice technology but also on model structure and the numerical representation\nand arithmetic precision of their parameters. Compression techniques like\npruning and quantization, used to reduce memory footprint and computational\ncomplexity, alter both model structure and representation, affecting soft error\nrobustness. In this regard, although often overlooked, the choice of activation\nfunctions (AFs) impacts not only accuracy and trainability but also\ncompressibility and error resilience. This paper explores the use of bounded\nAFs to enhance robustness against parameter perturbations, while evaluating\ntheir effects on model accuracy, compressibility, and computational load with a\ntechnology-agnostic approach. We focus on encoder-decoder convolutional models\ndeveloped for semantic segmentation of hyperspectral images with application to\nautonomous driving systems. Experiments are conducted on an AMD-Xilinx's KV260\nSoM.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.AR,cs.CV,eess.IV","published":"2025-04-07T14:21:31Z"}
{"aid":"http://arxiv.org/abs/2504.05120v1","title":"The intersections of the lower central series and the subgroups of\n  finite p-index of Generalized Baumslag-Solitar tree groups","summary":"For a Generalized Baumslag-Solitar group $G$ with underling graph a tree, we\ncalculate the intersection $\\gamma_{\\omega}(G)$ of the lower central series and\nthe intersection $(N_{p})_{\\omega}(G)$ of the subgroups of finite index some\npower of a prime $p$.","main_category":"math.GR","categories":"math.GR","published":"2025-04-07T14:25:59Z"}
{"aid":"http://arxiv.org/abs/2504.05123v1","title":"On order polytopes of crown posets","summary":"We study the order polytope of the crown poset. We provide explicit formulas\nfor its $f$-vector, give a recursive formula for its Ehrhart polynomial in\nterms of the Ehrhart polynomial of zigzags, and give a combinatorial\ninterpretation for the coefficients of the $h^*$-polynomial in terms of the\ncyclic swap statistic on cyclically alternating permutations.","main_category":"math.CO","categories":"math.CO","published":"2025-04-07T14:27:07Z"}
{"aid":"http://arxiv.org/abs/2504.05127v1","title":"Transitivity of the pure Hurwitz classes of quadratic post-critically\n  finite polynomials","summary":"We prove that for two post-critically finite quadratic polynomials $f,g$,\nthere is a mapping class $\\phi$ of the sphere with finitely many marked points\nsuch that $f\\phi$ and $g$ are pure Hurwitz equivalent.","main_category":"math.DS","categories":"math.DS,math.GR,math.GT","published":"2025-04-07T14:30:37Z"}
{"aid":"http://arxiv.org/abs/2504.05129v1","title":"Superconductivity, Anomalous Hall Effect, and Stripe Order in\n  Rhombohedral Hexalayer Graphene","summary":"We report the discovery of a unique superconducting phase in rhombohedral\nhexalayer graphene characterized by its simultaneous emergence with both the\nanomalous Hall effect and stripe charge order. The onset of stripe charge order\nis revealed through angle-resolved transport measurements, which show thermally\nactivated insulating behavior along one axis and highly conductive transport\nalong the orthogonal direction. Superconductivity develops exclusively along\nthe high-conductivity axis, giving rise to a one-dimensional-like\nsuperconducting channel. This superconducting state exhibits first-order\ntransitions under an out-of-plane magnetic field, consistent with a chiral\norder parameter that breaks time-reversal symmetry. Most remarkably, thermally\ndriven superconducting transitions display pronounced hysteresis-an uncommon\nphenomenon that reflects the complex interplay among stripe formation, broken\ntime-reversal symmetry, and superconductivity. Together, these results uncover\na previously unidentified quantum phase: a chiral superconductor embedded\nwithin an anomalous Hall crystal.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.str-el,cond-mat.supr-con","published":"2025-04-07T14:33:00Z"}
{"aid":"http://arxiv.org/abs/2504.05133v1","title":"Control and Transient Spectroscopy of Engineered Spin-Cavity Back-Action","summary":"We present an experimental arrangement that permits engineering of cavity\nback-action on a mesoscopic spin ensemble. By coupling a superconducting\nthin-film Nb microstrip resonator to a Trityl OX63 electron spin sample, we\naccess different regimes of spin-cavity dynamics by designing the ensemble\nsize, effective coupling strength, cavity temperature, and spin saturation. We\nperformed transient spectroscopy measurements under continuous microwave drive\nin the strong radiation damping regime. These measurements exhibit a long-lived\nplateau response that distinguishes important features of spin-cavity models,\nsuch as the radiation damping Bloch equations and Maxwell-Bloch equations. We\ndemonstrate control of the plateau response through adjustment of temperature,\nmicrowave drive power, and variable spin saturation. The presented experimental\narrangement serves as a robust system to explore the space of spin-cavity\ndynamics and develop new quantum devices that harness the complexity of\nmesoscopic spin ensembles coherently interacting with high quality factor\ncavities.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall,physics.app-ph","published":"2025-04-07T14:36:45Z"}
{"aid":"http://arxiv.org/abs/2504.05140v1","title":"Unifying Physics- and Data-Driven Modeling via Novel Causal\n  Spatiotemporal Graph Neural Network for Interpretable Epidemic Forecasting","summary":"Accurate epidemic forecasting is crucial for effective disease control and\nprevention. Traditional compartmental models often struggle to estimate\ntemporally and spatially varying epidemiological parameters, while deep\nlearning models typically overlook disease transmission dynamics and lack\ninterpretability in the epidemiological context. To address these limitations,\nwe propose a novel Causal Spatiotemporal Graph Neural Network (CSTGNN), a\nhybrid framework that integrates a Spatio-Contact SIR model with Graph Neural\nNetworks (GNNs) to capture the spatiotemporal propagation of epidemics.\nInter-regional human mobility exhibits continuous and smooth spatiotemporal\npatterns, leading to adjacent graph structures that share underlying mobility\ndynamics. To model these dynamics, we employ an adaptive static connectivity\ngraph to represent the stable components of human mobility and utilize a\ntemporal dynamics model to capture fluctuations within these patterns. By\nintegrating the adaptive static connectivity graph with the temporal dynamics\ngraph, we construct a dynamic graph that encapsulates the comprehensive\nproperties of human mobility networks. Additionally, to capture temporal trends\nand variations in infectious disease spread, we introduce a temporal\ndecomposition model to handle temporal dependence. This model is then\nintegrated with a dynamic graph convolutional network for epidemic forecasting.\nWe validate our model using real-world datasets at the provincial level in\nChina and the state level in Germany. Extensive studies demonstrate that our\nmethod effectively models the spatiotemporal dynamics of infectious diseases,\nproviding a valuable tool for forecasting and intervention strategies.\nFurthermore, analysis of the learned parameters offers insights into disease\ntransmission mechanisms, enhancing the interpretability and practical\napplicability of our model.","main_category":"cs.LG","categories":"cs.LG,physics.soc-ph,q-bio.QM,stat.ML","published":"2025-04-07T14:46:11Z"}
{"aid":"http://arxiv.org/abs/2504.05141v1","title":"EffOWT: Transfer Visual Language Models to Open-World Tracking\n  Efficiently and Effectively","summary":"Open-World Tracking (OWT) aims to track every object of any category, which\nrequires the model to have strong generalization capabilities. Trackers can\nimprove their generalization ability by leveraging Visual Language Models\n(VLMs). However, challenges arise with the fine-tuning strategies when VLMs are\ntransferred to OWT: full fine-tuning results in excessive parameter and memory\ncosts, while the zero-shot strategy leads to sub-optimal performance. To solve\nthe problem, EffOWT is proposed for efficiently transferring VLMs to OWT.\nSpecifically, we build a small and independent learnable side network outside\nthe VLM backbone. By freezing the backbone and only executing backpropagation\non the side network, the model's efficiency requirements can be met. In\naddition, EffOWT enhances the side network by proposing a hybrid structure of\nTransformer and CNN to improve the model's performance in the OWT field.\nFinally, we implement sparse interactions on the MLP, thus reducing parameter\nupdates and memory costs significantly. Thanks to the proposed methods, EffOWT\nachieves an absolute gain of 5.5% on the tracking metric OWTA for unknown\ncategories, while only updating 1.3% of the parameters compared to full\nfine-tuning, with a 36.4% memory saving. Other metrics also demonstrate obvious\nimprovement.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T14:47:58Z"}
{"aid":"http://arxiv.org/abs/2504.05142v1","title":"Discrete-to-continuum limits of semilinear stochastic evolution\n  equations in Banach spaces","summary":"We study the convergence of semilinear parabolic stochastic evolution\nequations, posed on a sequence of Banach spaces approximating a limiting space\nand driven by additive white noise projected onto the former spaces. Under\nappropriate uniformity and convergence conditions on the linear operators,\nnonlinear drifts and initial data, we establish convergence of the associated\nmild solution processes when lifted to a common state space. Our framework is\napplied to the case where the limiting problem is a stochastic partial\ndifferential equation whose linear part is a generalized Whittle-Mat\\'ern\noperator on a manifold $\\mathcal{M}$, discretized by a sequence of graphs\nconstructed from a point cloud. In this setting, we obtain\ndiscrete-to-continuum convergence of solutions lifted to the spaces\n$L^q(\\mathcal{M})$ for $q \\in [2,\\infty]$.","main_category":"math.PR","categories":"math.PR,math.AP","published":"2025-04-07T14:48:18Z"}
{"aid":"http://arxiv.org/abs/2504.05145v1","title":"Topological full groups arising from Cuntz and Cuntz-Toeplitz algebras\n  and their crossed products","summary":"In this paper, we investigate the topological full groups arising from the\nCuntz and Cuntz-Toeplitz algebras and their crossed products with the Cartan\nsubalgebras of Cuntz and Cuntz-Toeplitz algebras. We study the normal subgroups\nand abelianization of these groups and completely determine the KMS states of\nthe reduced crossed products with respect to some canonical gauge actions.","main_category":"math.OA","categories":"math.OA","published":"2025-04-07T14:49:32Z"}
{"aid":"http://arxiv.org/abs/2504.05155v1","title":"Phonon properties and unconventional heat transfer in quasi-2D\n  $Bi_2O_2Se$ crystal","summary":"Bi2O2Se belongs to a group of quasi-2D semiconductors that can replace\nsilicon in future high-speed/low-power electronics. However, the correlation\nbetween crystal/band structure and other physical properties still eludes\nunderstanding: carrier mobility increases non-intuitively with carrier\nconcentration; the observed $T^2$ temperature dependence of resistivity lacks\nexplanation. Moreover, a very high relative out-of-plane permittivity of about\n150 has been reported in the literature. A proper explanation for such a high\npermittivity is still lacking. We have performed infrared (IR) reflectivity and\nRaman scattering experiments on a large perfect single crystal with defined\nmosaicity, carrier concentration and mobility. Five of the eight phonons\nallowed by factor group theory have been observed and their symmetries\ndetermined. The IR spectra show that the permittivity measured in the\ntetragonal plane is as high as ${\\epsilon}_r{\\approx}500$, and this high value\nis due to a strong polar phonon with a low frequency of ~34 $cm^{-1}$ (~1 THz).\nSuch an unusually high permittivity allows the screening of charge defects,\nleading to the observation of high electron mobility at low temperatures. It\nalso allows effective modulation doping providing a platform for high\nperformance 2D electronics. DFT calculations suggest the existence of a very\nlow frequency acoustic phonon ~14 $cm^{-1}$ (~0.4 THz). Both the low frequency\nphonons cause anomalous phonon DOS, which is reflected in the unconventional\ntemperature dependence of the heat capacity, $c_M{\\approx}T^{3.5}$. The\ntemperature-dependent, two-component group velocity is proposed to explains the\nunusual temperature dependence of the thermal conductivity,\n${\\kappa}{\\approx}T^{1.5}$","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-07T14:58:41Z"}
{"aid":"http://arxiv.org/abs/2504.05160v1","title":"Some new functionals related to free boundary minimal submanifolds","summary":"The metrics induced on free boundary minimal surfaces in geodesic balls in\nthe upper unit hemisphere and hyperbolic space can be characterized as critical\nmetrics for the functionals $\\Theta_{r,i}$ and $\\Omega_{r,i}$, introduced\nrecently by Lima, Menezes and the second author. In this paper, we generalize\nthis characterization to free boundary minimal submanifolds of higher dimension\nin the same spaces. We also introduce some functionals of the form different\nfrom $\\Theta_{r,i}$ and show that the critical metrics for them are the metrics\ninduced by free boundary minimal immersions into a geodesic ball in the upper\nunit hemisphere. In the case of surfaces, these functionals are bounded from\nabove and not bounded from below. Moreover, the canonical metric on a geodesic\ndisk in a 3-ball in the upper unit hemisphere is maximal for this functional on\nthe set of all Riemannian metric of the topological disk.","main_category":"math.DG","categories":"math.DG","published":"2025-04-07T15:02:34Z"}
{"aid":"http://arxiv.org/abs/2504.05172v1","title":"Attention-Based Multi-Scale Temporal Fusion Network for Uncertain-Mode\n  Fault Diagnosis in Multimode Processes","summary":"Fault diagnosis in multimode processes plays a critical role in ensuring the\nsafe operation of industrial systems across multiple modes. It faces a great\nchallenge yet to be addressed - that is, the significant distributional\ndifferences among monitoring data from multiple modes make it difficult for the\nmodels to extract shared feature representations related to system health\nconditions. In response to this problem, this paper introduces a novel method\ncalled attention-based multi-scale temporal fusion network. The multi-scale\ndepthwise convolution and gated recurrent unit are employed to extract\nmulti-scale contextual local features and long-short-term features. A temporal\nattention mechanism is designed to focus on critical time points with higher\ncross-mode shared information, thereby enhancing the accuracy of fault\ndiagnosis. The proposed model is applied to Tennessee Eastman process dataset\nand three-phase flow facility dataset. The experiments demonstrate that the\nproposed model achieves superior diagnostic performance and maintains a small\nmodel size.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-07T15:16:22Z"}
{"aid":"http://arxiv.org/abs/2504.05176v1","title":"Cellular Network Design for UAV Corridors via Data-driven\n  High-dimensional Bayesian Optimization","summary":"We address the challenge of designing cellular networks for uncrewed aerial\nvehicles (UAVs) corridors through a novel data-driven approach. We assess\nmultiple state-of-the-art high-dimensional Bayesian optimization (HD-BO)\ntechniques to jointly optimize the cell antenna tilts and half-power beamwidth\n(HPBW). We find that some of these approaches achieve over 20dB gains in median\nSINR along UAV corridors, with negligible degradation to ground user\nperformance. Furthermore, we explore the HD-BO's capabilities in terms of model\ngeneralization via transfer learning, where data from a previously observed\nscenario source is leveraged to predict the optimal solution for a new scenario\ntarget. We provide examples of scenarios where such transfer learning is\nsuccessful and others where it fails. Moreover, we demonstrate that HD-BO\nenables multi-objective optimization, identifying optimal design trade-offs\nbetween data rates on the ground versus UAV coverage reliability. We observe\nthat aiming to provide UAV coverage across the entire sky can lower the rates\nfor ground users compared to setups specifically optimized for UAV corridors.\nFinally, we validate our approach through a case study in a real-world cellular\nnetwork, where HD-BO identifies optimal and non-obvious antenna configurations\nthat result in more than double the rates along 3D UAV corridors with\nnegligible ground performance loss.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-07T15:20:14Z"}
{"aid":"http://arxiv.org/abs/2504.05181v1","title":"Lightweight and Direct Document Relevance Optimization for Generative\n  Information Retrieval","summary":"Generative information retrieval (GenIR) is a promising neural retrieval\nparadigm that formulates document retrieval as a document identifier (docid)\ngeneration task, allowing for end-to-end optimization toward a unified global\nretrieval objective. However, existing GenIR models suffer from token-level\nmisalignment, where models trained to predict the next token often fail to\ncapture document-level relevance effectively. While reinforcement\nlearning-based methods, such as reinforcement learning from relevance feedback\n(RLRF), aim to address this misalignment through reward modeling, they\nintroduce significant complexity, requiring the optimization of an auxiliary\nreward function followed by reinforcement fine-tuning, which is computationally\nexpensive and often unstable. To address these challenges, we propose direct\ndocument relevance optimization (DDRO), which aligns token-level docid\ngeneration with document-level relevance estimation through direct optimization\nvia pairwise ranking, eliminating the need for explicit reward modeling and\nreinforcement learning. Experimental results on benchmark datasets, including\nMS MARCO document and Natural Questions, show that DDRO outperforms\nreinforcement learning-based methods, achieving a 7.4% improvement in MRR@10\nfor MS MARCO and a 19.9% improvement for Natural Questions. These findings\nhighlight DDRO's potential to enhance retrieval effectiveness with a simplified\noptimization approach. By framing alignment as a direct optimization problem,\nDDRO simplifies the ranking optimization pipeline of GenIR models while\noffering a viable alternative to reinforcement learning-based methods.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.DL,cs.LG,H.3.3","published":"2025-04-07T15:27:37Z"}
{"aid":"http://arxiv.org/abs/2504.05185v1","title":"Concise Reasoning via Reinforcement Learning","summary":"Despite significant advancements in large language models (LLMs), a major\ndrawback of reasoning models is their enormous token usage, which increases\ncomputational cost, resource requirements, and response time. In this work, we\nrevisit the core principles of reinforcement learning (RL) and, through\nmathematical analysis, demonstrate that the tendency to generate lengthy\nresponses arises inherently from RL-based optimization during training. This\nfinding questions the prevailing assumption that longer responses inherently\nimprove reasoning accuracy. Instead, we uncover a natural correlation between\nconciseness and accuracy that has been largely overlooked. Moreover, we show\nthat introducing a secondary phase of RL post-training, using a small set of\nproblems and limited resources, can significantly reduce a model's chain of\nthought while maintaining or even enhancing accuracy. Finally, we validate our\nconclusions through extensive experimental results.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T15:35:54Z"}
{"aid":"http://arxiv.org/abs/2504.05189v1","title":"Influence of pore-confined water on the thermal expansion of a\n  zinc-based metal-organic framework","summary":"Understanding the reversible intercalation of guest molecules into\nmetal-organic frameworks is crucial for advancing their design for practical\napplications. In this work, we explore the impact of H$_{\\mathrm{2}}\\!$O as a\nguest molecule on the thermal expansion of the zinc-based metal-organic\nframework GUT-2. Dehydration is achieved by thermal treatment of hydrated\nGUT-2. Rietveld refinement performed on temperature-dependent X-ray powder\ndiffraction data confirms the reversible structural transformation.\nAdditionally, it allows the determination of anisotropic thermal expansion\ncoefficients for both phases. The hydrated form exhibits near-zero thermal\nexpansion along the polymer chain direction, moderate expansion In the\ndirection of predominantly hydrogen bonds, and the highest expansion in the\ndirection with only Van der Waals bonding. Upon activation, the removal of\nH$_{\\mathrm{2}}\\!$O molecules triggers a doubling of the thermal expansion\ncoefficient in the direction, where the hydrogen bonds have been removed.\nRegarding the dynamics of the process, thermal activation in air occurs within\n6 hours at a temperature of 50{\\deg}C and takes only 30 minutes when heating to\n90{\\deg}C. In contrast, full rehydration under standard lab conditions (30 %\nrelative humidity) requires two days. During the activation/dehydration\nprocesses no change of the widths of the X-ray diffraction peaks is observed,\nwhich shows that the underlying crystal structures remains fully intact during\nthe transition processes. Fitting the transformations by the Avrami equation\nreveals a quasi one-dimensional evolution of the dehydrated areas for the\nactivation process and a more intricate, predominantly two-dimensional\nmechanism for the rehydration.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-07T15:41:29Z"}
{"aid":"http://arxiv.org/abs/2504.05192v1","title":"CHIME/FRB Outriggers: Design Overview","summary":"The Canadian Hydrogen Intensity Mapping Experiment (CHIME) has emerged as the\nworld's premier facility for studying fast radio bursts (FRBs) through its fast\ntransient search backend CHIME/FRB\\@. The CHIME/FRB Outriggers project will\naugment this high detection rate of 2--3 FRBs per day with the ability to\nprecisely localize them using very long baseline interferometry (VLBI). Using\nthree strategically located stations in North America and deploying recently\ndeveloped synoptic VLBI observing techniques, the Outriggers will provide $\\sim\n50$~milliarcsecond localization precision for the majority of detected FRBs.\nThis paper presents an overview of the design and implementation of the\nOutriggers, covering their geographic distribution, structural design, and\nobservational capabilities. We detail the scientific objectives driving the\nproject, including the characterization of FRB populations, host galaxy\ndemographics, and the use of FRBs as cosmological probes. We also discuss the\ncalibration strategies available to mitigate ionospheric and instrumental\neffects, ensuring high-precision localization. With two stations currently in\nscience operations, and the third in commissioning, the CHIME/FRB Outriggers\nproject is poised to become a cornerstone of the FRB field, offering\nunprecedented insights into this enigmatic cosmic phenomenon.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.IM","published":"2025-04-07T15:42:23Z"}
{"aid":"http://arxiv.org/abs/2504.05194v1","title":"A general framework for quasi-isometries in symbolic dynamics beyond\n  groups","summary":"We introduce an algebraic structure which encodes a collection of countable\ngraphs through a set of states, generators and relations. For these structures,\nwhich we call blueprints, we provide a general framework for symbolic dynamics\nunder a partial monoid action, and for transferring invariants of their\nsymbolic dynamics through quasi-isometries. In particular, we show that the\nundecidability of the domino problem, the existence of strongly aperiodic\nsubshifts of finite type, and the existence of subshifts of finite type without\ncomputable points are all quasi-isometry invariants for finitely presented\nblueprints. As an application of this model, we show that a variant of the\ndomino problem for geometric tilings of $\\mathbb{R}^d$ is undecidable for $d\n\\geq 2$ on any underlying tiling space with finite local complexity.","main_category":"math.DS","categories":"math.DS,math.CO,math.MG","published":"2025-04-07T15:43:02Z"}
{"aid":"http://arxiv.org/abs/2504.05198v1","title":"Bayesian estimation of causal effects from observational categorical\n  data","summary":"We present a Bayesian procedure for estimation of pairwise intervention\neffects in a high-dimensional system of categorical variables. We assume that\nwe have observational data generated from an unknown causal Bayesian network\nfor which there are no latent confounders. Most of the existing methods\ndeveloped for this setting assume that the underlying model is linear Gaussian,\nincluding the Bayesian IDA (BIDA) method that we build upon in this work. By\ncombining a Bayesian backdoor estimator with model averaging, we obtain a\nposterior over the intervention distributions of a cause-effect pair that can\nbe expressed as a mixture over stochastic linear combinations of Dirichlet\ndistributions. Although there is no closed-form expression for the posterior\ndensity, it is straightforward to produce Monte Carlo approximations of target\nquantities through direct sampling, and we also derive closed-form expressions\nfor a few selected moments. To scale up the proposed procedure, we employ\nMarkov Chain Monte Carlo (MCMC), which also enables us to use more efficient\nadjustment sets compared to the current exact BIDA. Finally, we use\nJensen-Shannon divergence to define a novel causal effect based on a set of\nintervention distributions in the general categorical setting. We compare our\nmethod to the original IDA method and existing Bayesian approaches in numerical\nsimulations and show that categorical BIDA performs favorably against the\nexisting alternative methods in terms of producing point estimates and\ndiscovering strong effects.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-07T15:49:36Z"}
{"aid":"http://arxiv.org/abs/2504.05199v1","title":"Equivalence Theorems and Double-Copy Structure in Scattering Amplitudes\n  of Massive Kaluza-Klein States with Matter Interactions","summary":"We investigate the scattering amplitudes of massive Kaluza-Klein (KK) states\nin compactified five-dimensional warped gauge and gravity theories. Focusing on\ntree-level $2\\to2$ processes, we analyze the leading-order amplitudes involving\nbulk KK matter fields and KK gauge/gravitational Goldstone bosons. By imposing\nthe gauge theory equivalence theorem (GAET) and the gravitational equivalence\ntheorem (GRET) within warped KK theories, we systematically reconstruct the\nleading-order amplitudes for physical KK gauge bosons and gravitons, thereby\ncircumventing the intricate energy cancellations inherent in physical\namplitudes. Within this framework, the correspondence between GAET and GRET\narises as a direct manifestation of the leading-order double-copy relation in\nthe high-energy expansion. This connection provides a foundation for extending\nthe BCJ double-copy construction to four-point amplitudes involving bulk KK\nmatter fields, allowing for a systematic derivation of the corresponding\ngravitational amplitudes while consistently incorporating KK matter fields at\nleading order.","main_category":"hep-th","categories":"hep-th","published":"2025-04-07T15:50:19Z"}
{"aid":"http://arxiv.org/abs/2504.05209v1","title":"Detailed $SU(3)$ Flavour Symmetry Analysis of Charmless Two-Body\n  $B$-Meson Decays Including Factorizable Corrections","summary":"We study the decays of $B_{(s)}$ mesons into light pseudoscalar mesons under\nthe $SU(3)$ flavour symmetry. Assuming exact $SU(3)$ symmetry at the level of\nthe amplitudes leads to a simple parameterization. Using the available\nexperimental data and, for the first time, mixing effects in the $B_s^0$\ndecays, we find that the data cannot be described with this assumption. We\nimprove this parametrization by including {\\it factorizable}\n$SU(3)_\\mathrm{F}$-breaking effects. This new approach allows for an excellent\ndescription of the data, with a fit $p$ value of $32.3\\%$. We provide posterior\npredictions for all observables and identify several decay channels that would\nsignificantly impact our analysis. Finally, we briefly compare our results with\nthe predictions of QCD factorization, paving the way to a more detailed\nanalysis which could provide insights into QCD effects at low energy scales.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-07T15:58:14Z"}
{"aid":"http://arxiv.org/abs/2504.05210v1","title":"A moving target in AI-assisted decision-making: Dataset shift, model\n  updating, and the problem of update opacity","summary":"Machine learning (ML) systems are vulnerable to performance decline over time\ndue to dataset shift. To address this problem, experts often suggest that ML\nsystems should be regularly updated to ensure ongoing performance stability.\nSome scholarly literature has begun to address the epistemic and ethical\nchallenges associated with different updating methodologies. Thus far, however,\nlittle attention has been paid to the impact of model updating on the\nML-assisted decision-making process itself, particularly in the AI ethics and\nAI epistemology literatures. This article aims to address this gap in the\nliterature. It argues that model updating introduces a new sub-type of opacity\ninto ML-assisted decision-making -- update opacity -- that occurs when users\ncannot understand how or why an update has changed the reasoning or behaviour\nof an ML system. This type of opacity presents a variety of distinctive\nepistemic and safety concerns that available solutions to the black box problem\nin ML are largely ill-equipped to address. A variety of alternative strategies\nmay be developed or pursued to address the problem of update opacity more\ndirectly, including bi-factual explanations, dynamic model reporting, and\nupdate compatibility. However, each of these strategies presents its own risks\nor carries significant limitations. Further research will be needed to address\nthe epistemic and safety concerns associated with model updating and update\nopacity going forward.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.HC,cs.LG","published":"2025-04-07T15:58:23Z"}
{"aid":"http://arxiv.org/abs/2504.05215v1","title":"Quasinormal modes and absorption cross-section of a Bardeen black hole\n  surrounded by perfect fluid dark matter in four dimensions","summary":"In this paper we study quasinormal modes and absorption cross sections for\nthe $(1+3)$-dimensional Bardeen black hole surrounded by perfect fluid dark\nmatter. Studies of the massless scalar field is already done in\n\\cite{Sun:2023slzl}. Hence, in this paper we will focus on the massive scalar\nfield perturbations and massless Dirac field perturbations. To compute the\nquasinormal modes we use the semi-analytical 3rd-order WKB method, which has\nbeen shown to be one of the best approaches when the effective potential is\nadequate and when $n < \\ell$ and $n < \\lambda$. We have also utilized the\nP\\\"oschl-Teller method to compare the valus obtained using the WKB approach. We\nhave computed quasinormal frequencies by varying various parameters of the\ntheory such as the mass of the scalar field $\\mu$, dark matter parameter\n$\\alpha$ and the magnetic charge $g$. We have summarized our solutions in\ntables and figures for clarity. As for the absorption cross section, we used\nthird order WKB approach to compute reflection, transmission coefficients and\npartial absorption cross sections. Graphs are presented to demonstrate the\nbehavior of the above quantities when the dark matter parameter and mass of the\nmassive scalar field are varied.","main_category":"gr-qc","categories":"gr-qc,astro-ph.SR,hep-th","published":"2025-04-07T16:02:22Z"}
{"aid":"http://arxiv.org/abs/2504.05219v1","title":"An ensemble deep learning approach to detect tumors on Mohs micrographic\n  surgery slides","summary":"Mohs micrographic surgery (MMS) is the gold standard technique for removing\nhigh risk nonmelanoma skin cancer however, intraoperative histopathological\nexamination demands significant time, effort, and professionality. The\nobjective of this study is to develop a deep learning model to detect basal\ncell carcinoma (BCC) and artifacts on Mohs slides. A total of 731 Mohs slides\nfrom 51 patients with BCCs were used in this study, with 91 containing tumor\nand 640 without tumor which was defined as non-tumor. The dataset was employed\nto train U-Net based models that segment tumor and non-tumor regions on the\nslides. The segmented patches were classified as tumor, or non-tumor to produce\npredictions for whole slide images (WSIs). For the segmentation phase, the deep\nlearning model success was measured using a Dice score with 0.70 and 0.67\nvalue, area under the curve (AUC) score with 0.98 and 0.96 for tumor and\nnon-tumor, respectively. For the tumor classification, an AUC of 0.98 for\npatch-based detection, and AUC of 0.91 for slide-based detection was obtained\non the test dataset. We present an AI system that can detect tumors and\nnon-tumors in Mohs slides with high success. Deep learning can aid Mohs\nsurgeons and dermatopathologists in making more accurate decisions.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-07T16:05:42Z"}
{"aid":"http://arxiv.org/abs/2504.05220v1","title":"Leveraging LLMs for Utility-Focused Annotation: Reducing Manual Effort\n  for Retrieval and RAG","summary":"Retrieval models typically rely on costly human-labeled query-document\nrelevance annotations for training and evaluation. To reduce this cost and\nleverage the potential of Large Language Models (LLMs) in relevance judgments,\nwe aim to explore whether LLM-generated annotations can effectively replace\nhuman annotations in training retrieval models. Retrieval usually emphasizes\nrelevance, which indicates \"topic-relatedness\" of a document to a query, while\nin RAG, the value of a document (or utility) depends on how it contributes to\nanswer generation. Recognizing this mismatch, some researchers use LLM\nperformance on downstream tasks with documents as labels, but this approach\nrequires manual answers for specific tasks, leading to high costs and limited\ngeneralization. In another line of work, prompting LLMs to select useful\ndocuments as RAG references eliminates the need for human annotation and is not\ntask-specific. If we leverage LLMs' utility judgments to annotate retrieval\ndata, we may retain cross-task generalization without human annotation in\nlarge-scale corpora. Therefore, we investigate utility-focused annotation via\nLLMs for large-scale retriever training data across both in-domain and\nout-of-domain settings on the retrieval and RAG tasks. To reduce the impact of\nlow-quality positives labeled by LLMs, we design a novel loss function, i.e.,\nDisj-InfoNCE. Our experiments reveal that: (1) Retrievers trained on\nutility-focused annotations significantly outperform those trained on human\nannotations in the out-of-domain setting on both tasks, demonstrating superior\ngeneralization capabilities. (2) LLM annotation does not replace human\nannotation in the in-domain setting. However, incorporating just 20%\nhuman-annotated data enables retrievers trained with utility-focused\nannotations to match the performance of models trained entirely with human\nannotations.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.CL","published":"2025-04-07T16:05:52Z"}
{"aid":"http://arxiv.org/abs/2504.05228v1","title":"NoveltyBench: Evaluating Creativity and Diversity in Language Models","summary":"Language models have demonstrated remarkable capabilities on standard\nbenchmarks, yet they struggle increasingly from mode collapse, the inability to\ngenerate diverse and novel outputs. Our work introduces NoveltyBench, a\nbenchmark specifically designed to evaluate the ability of language models to\nproduce multiple distinct and high-quality outputs. NoveltyBench utilizes\nprompts curated to elicit diverse answers and filtered real-world user queries.\nEvaluating 20 leading language models, we find that current state-of-the-art\nsystems generate significantly less diversity than human writers. Notably,\nlarger models within a family often exhibit less diversity than their smaller\ncounterparts, challenging the notion that capability on standard benchmarks\ntranslates directly to generative utility. While prompting strategies like\nin-context regeneration can elicit diversity, our findings highlight a\nfundamental lack of distributional diversity in current models, reducing their\nutility for users seeking varied responses and suggesting the need for new\ntraining and evaluation paradigms that prioritize creativity alongside quality.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T16:14:23Z"}
{"aid":"http://arxiv.org/abs/2504.05235v1","title":"IAEmu: Learning Galaxy Intrinsic Alignment Correlations","summary":"The intrinsic alignments (IA) of galaxies, a key contaminant in weak lensing\nanalyses, arise from correlations in galaxy shapes driven by tidal interactions\nand galaxy formation processes. Accurate IA modeling is essential for robust\ncosmological inference, but current approaches rely on perturbative methods\nthat break down on nonlinear scales or on expensive simulations. We introduce\nIAEmu, a neural network-based emulator that predicts the galaxy\nposition-position ($\\xi$), position-orientation ($\\omega$), and\norientation-orientation ($\\eta$) correlation functions and their uncertainties\nusing mock catalogs based on the halo occupation distribution (HOD) framework.\nCompared to simulations, IAEmu achieves ~3% average error for $\\xi$ and ~5% for\n$\\omega$, while capturing the stochasticity of $\\eta$ without overfitting. The\nemulator provides both aleatoric and epistemic uncertainties, helping identify\nregions where predictions may be less reliable. We also demonstrate\ngeneralization to non-HOD alignment signals by fitting to IllustrisTNG\nhydrodynamical simulation data. As a fully differentiable neural network, IAEmu\nenables $\\sim$10,000$\\times$ speed-ups in mapping HOD parameters to correlation\nfunctions on GPUs, compared to CPU-based simulations. This acceleration\nfacilitates inverse modeling via gradient-based sampling, making IAEmu a\npowerful surrogate model for galaxy bias and IA studies with direct\napplications to Stage IV weak lensing surveys.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.GA,cs.LG","published":"2025-04-07T16:19:50Z"}
{"aid":"http://arxiv.org/abs/2504.05242v1","title":"Spectral correlations of dynamical Resonance Fluorescence","summary":"Frequency-filtered photon correlations have been proven to be extremely\nuseful in grasping how the detection process alters photon statistics.\nHarnessing the spectral correlations also permits refinement of the emission\nand unraveling of previously hidden strong correlations in a plethora of\nquantum-optical systems under continuous-wave excitation. In this work, we\ninvestigate such correlations for time-dependent excitation and develop a\nmethodology to compute efficiently time-integrated correlations, which are at\nthe heart of the photon-counting theory, and subsequently apply it to analyze\nthe photon emission of pulsed systems. By combining this formalism with the\nsensor method -- which facilitates frequency-resolved correlations -- we\ndemonstrate how spectral filtering enhances single-photon purity and suppresses\nmulti-photon noise in time-bin-encoded quantum states. Specifically, filtering\nthe central spectral peak of a dynamically driven two-level system boosts\ntemporal coherence and improves the fidelity of time-bin entanglement\npreparation, even under conditions favoring multi-photon emission. These\nresults establish spectral filtering as a critical tool for tailoring photon\nstatistics in pulsed quantum light sources.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-07T16:27:13Z"}
{"aid":"http://arxiv.org/abs/2504.05244v1","title":"Behind the Spotlight: A systematic assessment of outshining using NIRCam\n  medium-bands in the JADES Origins Field","summary":"The spatial resolution and sensitivity of JWST's NIRCam instrument has\nrevolutionised our ability to probe the internal structure of early galaxies.\nBy leveraging deep medium-band imaging in the Jades Origins Field, we assemble\ncomprehensive spectral energy distributions (SEDs) using 19 photometric bands\nfor over 200 high-redshift galaxies ($z \\geq 4.5$). We present an analysis of\nthis sample with particular emphasis on investigating the \"outshining\"\nphenomenon, which can bias the inferred stellar populations by masking the\npresence of evolved stellar populations ($\\geq$ 100 Myr) with the light of\nbright, young O and B-type stars. We address this problem by performing\nspatially-resolved SED-fitting of both binned and full pixel-by-pixel\nphotometry, which we compare to the traditional integrated approach. We find\nevidence for systematic underestimation of stellar mass in low-mass galaxies\n($\\leq 10^9 \\rm M_\\odot$) with bursty star formation, which can exceed a factor\nof 10 in individual cases, but on average is typically a factor of 1.25-2.5,\ndepending on the binning methodology and SFH model used. The observed mass\noffset correlates with burstiness (SFR$_{10 \\ \\rm Myr}$/SFR$_{100 \\ \\rm Myr}$)\nand sSFR, such that galaxies with recently rising SFHs have larger mass\noffsets. The integrated SFH models which produce the most consistent stellar\nmasses are the double power-law and non-parametric `continuity' models,\nalthough no integrated model fully reproduces all resolved SFHs. We apply an\noutshining correction factor to the Stellar Mass Function at $z=7$, finding\nlittle impact within the uncertainties. We conclude that outshining can be\nimportant in individual low-mass galaxies, but the overall impact is limited\nand should be considered alongside other systematic SED fitting effects.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-07T16:30:31Z"}
{"aid":"http://arxiv.org/abs/2504.05253v1","title":"Contour Integration Underlies Human-Like Vision","summary":"Despite the tremendous success of deep learning in computer vision, models\nstill fall behind humans in generalizing to new input distributions. Existing\nbenchmarks do not investigate the specific failure points of models by\nanalyzing performance under many controlled conditions. Our study\nsystematically dissects where and why models struggle with contour integration\n-- a hallmark of human vision -- by designing an experiment that tests object\nrecognition under various levels of object fragmentation. Humans (n=50) perform\nat high accuracy, even with few object contours present. This is in contrast to\nmodels which exhibit substantially lower sensitivity to increasing object\ncontours, with most of the over 1,000 models we tested barely performing above\nchance. Only at very large scales ($\\sim5B$ training dataset size) do models\nbegin to approach human performance. Importantly, humans exhibit an integration\nbias -- a preference towards recognizing objects made up of directional\nfragments over directionless fragments. We find that not only do models that\nshare this property perform better at our task, but that this bias also\nincreases with model training dataset size, and training models to exhibit\ncontour integration leads to high shape bias. Taken together, our results\nsuggest that contour integration is a hallmark of object vision that underlies\nobject recognition performance, and may be a mechanism learned from data at\nscale.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T16:45:06Z"}
{"aid":"http://arxiv.org/abs/2504.05263v1","title":"An X-ray and Optical Study of the Dwarf Nova Candidate OGLE-BLG-DN-0064","summary":"The source OGLE-BLG-DN-0064 (hereafter OGLE64) was classified as a potential\ndwarf nova based on its regular outburst activity revealed by the OGLE optical\nsurvey. In this paper, we investigate the X-ray and optical emissions from the\nsource OGLE64 based on archival Chandra and Swift X-ray data and our optical\nobservations with the 6-m BTA telescope at the Special Astrophysical\nObservatory of the Russian Academy of Sciences. OGLE64 shows an X-ray\nluminosity $ L_X \\approx 1.6 \\times 10^{32} \\, \\text{erg s}^{-1} $ and a high\nX-ray-to-optical flux ratio $ F_X / F_{\\text{opt}} \\approx 1.5$, typical for\naccreting white dwarfs. The X-ray spectrum of OGLE64 is better fitted by the\nmodels of a power law with a photon index $\\Gamma \\approx 1.9$ and an optically\nthin plasma with a temperature $ kT \\approx 6.4 \\, \\text{keV} $. The optical\nspectrum shows hydrogen and neutral helium emission lines, in some of which a\ndouble-peaked structure is observed. An analysis of the outburst activity of\nOGLE64, based on data from the OGLE, ZTF, ATLAS, and ASAS-SN optical surveys,\nhas revealed superoutbursts with a characteristic supercycle $ P_{\\text{super}}\n\\approx 400 \\, \\text{days} $. We found no significant variability in either the\nX-ray or optical light curves of OGLE64 that could be associated with the\nchange in the visibility conditions for the emitting regions at different\norbital phases. Our estimates of the orbital period of the system by indirect\nmethods show that the period probably lies in the range $ P_{\\text{orb}} \\sim\n1.5 - 3.5 \\, \\text{h} $. The properties of the X-ray and optical emissions from\nOGLE64 lead us to conclude that the system is an SU UMa-type dwarf nova.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.SR","published":"2025-04-07T16:58:06Z"}
{"aid":"http://arxiv.org/abs/2504.05264v1","title":"Existence and characterizations of hyper-dual group inverse","summary":"Motivated by the recent work of Xiao and Zhong [AIMS Math. 9 (2024),\n35125--35150: MR4840882], we propose a generalized inverse for a hyper-dual\nmatrix called hyper-dual group generalized inverse (HDGGI). Under certain\nnecessary and sufficient conditions, we establish the existence of the HDGGI of\na hyper-dual matrix. We then show that the HDGGI is unique (whenever exists).\nThe HDGGI is then used to solve a linear hyper-dual system. We also exploit\nsome sufficient conditions under which the reverse and forward-order laws for a\nparticular form of the HDGGI and HDMPGI hold. We also discuss the least-squares\nproperties of hyper-dual group inverse. Using the definition of dual matrix of\norder $n$, we finally establish necessary and sufficient condition for the\nexistence of the group inverse of a dual matrix of order $n$.","main_category":"math.RA","categories":"math.RA,math.AC,math.FA","published":"2025-04-07T16:58:21Z"}
{"aid":"http://arxiv.org/abs/2504.05265v1","title":"From Sparse Signal to Smooth Motion: Real-Time Motion Generation with\n  Rolling Prediction Models","summary":"In extended reality (XR), generating full-body motion of the users is\nimportant to understand their actions, drive their virtual avatars for social\ninteraction, and convey a realistic sense of presence. While prior works\nfocused on spatially sparse and always-on input signals from motion\ncontrollers, many XR applications opt for vision-based hand tracking for\nreduced user friction and better immersion. Compared to controllers, hand\ntracking signals are less accurate and can even be missing for an extended\nperiod of time. To handle such unreliable inputs, we present Rolling Prediction\nModel (RPM), an online and real-time approach that generates smooth full-body\nmotion from temporally and spatially sparse input signals. Our model generates\n1) accurate motion that matches the inputs (i.e., tracking mode) and 2)\nplausible motion when inputs are missing (i.e., synthesis mode). More\nimportantly, RPM generates seamless transitions from tracking to synthesis, and\nvice versa. To demonstrate the practical importance of handling noisy and\nmissing inputs, we present GORP, the first dataset of realistic sparse inputs\nfrom a commercial virtual reality (VR) headset with paired high quality body\nmotion ground truth. GORP provides >14 hours of VR gameplay data from 28 people\nusing motion controllers (spatially sparse) and hand tracking (spatially and\ntemporally sparse). We benchmark RPM against the state of the art on both\nsynthetic data and GORP to highlight how we can bridge the gap for real-world\napplications with a realistic dataset and by handling unreliable input signals.\nOur code, pretrained models, and GORP dataset are available in the project\nwebpage.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T17:00:34Z"}
{"aid":"http://arxiv.org/abs/2504.05266v1","title":"Differential forms: Lagrange interpolation, sampling and approximation\n  on polynomial admissible integral k-meshes","summary":"In this work we address the problem of interpolating and approximating\ndifferential forms starting from data defined by integration. We show that many\naspects of nodal interpolation can naturally be carried to this more general\nframework; in contrast, some of them require the introduction of geometric and\nmeasure theoretic hypotheses. After characterizing the norms of the operators\ninvolved, we introduce the concept of admissible integral k-mesh, which allows\nfor the construction of robust approximation schemes, and is used to extract\ninterpolation sets with high stability properties. To this end, the concepts of\nFekete currents and Leja sequences of currents are formalized, and a numerical\nscheme for their approximation is proposed.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-07T17:04:51Z"}
{"aid":"http://arxiv.org/abs/2504.05268v1","title":"Performance and Complexity Analysis of Terahertz-Band MIMO Detection","summary":"Achieving terabit-per-second (Tbps) data rates in terahertz (THz)-band\ncommunications requires bridging the complexity gap in baseband transceiver\ndesign. This work addresses the signal processing challenges associated with\ndata detection in THz multiple-input multiple-output (MIMO) systems. We begin\nby analyzing the trade-offs between performance and complexity across various\ndetection schemes and THz channel models, demonstrating significant complexity\nreduction by leveraging spatial parallelizability over subspaces of correlated\nTHz MIMO channels. We derive accurate detection error probability bounds by\naccounting for THz-specific channel models and mismatches introduced by\nsubspace decomposition. Building on this, we propose a subspace detector that\nintegrates layer sorting, QR decomposition, and channel-matrix puncturing to\nbalance performance loss and parallelizability. Furthermore, we introduce a\nchannel-matrix reuse strategy for wideband THz MIMO detection. Simulations over\naccurate, ill-conditioned THz channels show that efficient parallelizability\nachieves multi-dB performance gains, while wideband reuse strategies offer\ncomputational savings with minimal performance degradation.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-07T17:06:07Z"}
{"aid":"http://arxiv.org/abs/2504.05272v1","title":"The Standard Model tested with neutrinos","summary":"The Standard Model (SM) of particle physics effectively explains most\nobserved phenomena, though some anomalies, especially in the neutrino sector,\nsuggest the need for extensions. In this work, we perform the first global fit\nof elastic neutrino-nucleus and neutrino-electron scattering data to further\ntest the SM within a consistent framework. Our results on the neutrino charge\nradius, the only non-zero electromagnetic property of neutrinos in the SM, show\nno significant deviation, indicating no large beyond the SM flavor-dependent\neffects for electron and muon neutrinos. By incorporating solar neutrino data\nfrom dark matter direct detection experiments, we also place the most stringent\nconstraints on the tau neutrino charge radius obtained from neutrino scattering\nexperiments. Additionally, we determine updated constraints on the vector and\naxial-vector neutrino-electron neutral current couplings, adjusting for\nflavor-dependent effects and for the different experimental momentum transfers.\nThe global analysis reveals two allowed solutions: one close to the SM\nprediction, and a degenerate solution that is favored. We show that future dark\nmatter detectors could achieve sufficient precision to resolve the degeneracy.\nAs we move toward the precision era, this work demonstrates the crucial need to\nproperly account for flavor- and momentum-dependent effects to avoid\nmisinterpretations of the data.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-07T17:08:28Z"}
{"aid":"http://arxiv.org/abs/2504.05280v1","title":"Dimensionality Enhanced Out-of-Plane Spin Currents in NbIrTe$_4$ for\n  Efficient Field-Free Switching of Perpendicular Magnetization","summary":"Efficient generation of out-of-plane (OOP) spin currents is crucial for\nadvanced spintronic memory applications. However, the theoretical understanding\nand experimental implementation of robust OOP spin currents for high-density\nand low-power magnetization switching remain significant challenges of\nspintronics. Here, we demonstrate that transitioning NbIrTe$_4$ from a\ntwo-dimensional quantum spin Hall insulator to a three-dimensional type-II Weyl\nsemimetal markedly enhances OOP spin current generation. The bulk topological\nWeyl semimetal nature of NbIrTe$_4$, characterized by its Weyl cone,\nsignificantly enhances the OOP spin Berry curvature, enabling an unprecedented\nOOP spin Hall conductivity exceeding $10^5\\hbar/2e$ $\\Omega^{-1}m^{-1} $. This\nenhancement, surpassing the in-plane component by more than fourfold, enables\nefficient and field-free spin-orbit torque (SOT) switching of perpendicular\nmagnetization with a low current density of 1.4 MA/cm$^2$. The improved spin\nHall conductivity reduces the overall power consumption by more than two orders\nof magnitude compared to existing systems, such as heavy metals. Our findings\nhighlight the pivotal role of dimensionality in harnessing robust OOP spin\ncurrents in topological Weyl semimetals, paving the way for the development of\nhigh-density, low-power spintronic memory technologies.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-07T17:29:56Z"}
{"aid":"http://arxiv.org/abs/2504.05288v1","title":"LiveVQA: Live Visual Knowledge Seeking","summary":"We introduce LiveVQA, an automatically collected dataset of latest visual\nknowledge from the Internet with synthesized VQA problems. LiveVQA consists of\n3,602 single- and multi-hop visual questions from 6 news websites across 14\nnews categories, featuring high-quality image-text coherence and authentic\ninformation. Our evaluation across 15 MLLMs (e.g., GPT-4o, Gemma-3, and\nQwen-2.5-VL family) demonstrates that stronger models perform better overall,\nwith advanced visual reasoning capabilities proving crucial for complex\nmulti-hop questions. Despite excellent performance on textual problems, models\nwith tools like search engines still show significant gaps when addressing\nvisual questions requiring latest visual knowledge, highlighting important\nareas for future research.","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-04-07T17:39:31Z"}
{"aid":"http://arxiv.org/abs/2504.05297v1","title":"Eigenvalue-Based Randomness Test for Residual Diagnostics in Panel Data\n  Models","summary":"This paper introduces the Eigenvalue-Based Randomness (EBR) test - a novel\napproach rooted in the Tracy-Widom law from random matrix theory - and applies\nit to the context of residual analysis in panel data models. Unlike traditional\nmethods, which target specific issues like cross-sectional dependence or\nautocorrelation, the EBR test simultaneously examines multiple assumptions by\nanalyzing the largest eigenvalue of a symmetrized residual matrix. Monte Carlo\nsimulations demonstrate that the EBR test is particularly robust in detecting\nnot only standard violations such as autocorrelation and linear cross-sectional\ndependence (CSD) but also more intricate non-linear and non-monotonic\ndependencies, making it a comprehensive and highly flexible tool for enhancing\nthe reliability of panel data analyses.","main_category":"stat.ME","categories":"stat.ME,econ.EM,stat.AP,stat.CO","published":"2025-04-07T17:52:36Z"}
{"aid":"http://arxiv.org/abs/2504.05299v1","title":"SmolVLM: Redefining small and efficient multimodal models","summary":"Large Vision-Language Models (VLMs) deliver exceptional performance but\nrequire significant computational resources, limiting their deployment on\nmobile and edge devices. Smaller VLMs typically mirror design choices of larger\nmodels, such as extensive image tokenization, leading to inefficient GPU memory\nusage and constrained practicality for on-device applications.\n  We introduce SmolVLM, a series of compact multimodal models specifically\nengineered for resource-efficient inference. We systematically explore\narchitectural configurations, tokenization strategies, and data curation\noptimized for low computational overhead. Through this, we identify key design\nchoices that yield substantial performance gains on image and video tasks with\nminimal memory footprints.\n  Our smallest model, SmolVLM-256M, uses less than 1GB GPU memory during\ninference and outperforms the 300-times larger Idefics-80B model, despite an\n18-month development gap. Our largest model, at 2.2B parameters, rivals\nstate-of-the-art VLMs consuming twice the GPU memory. SmolVLM models extend\nbeyond static images, demonstrating robust video comprehension capabilities.\n  Our results emphasize that strategic architectural optimizations, aggressive\nyet efficient tokenization, and carefully curated training data significantly\nenhance multimodal performance, facilitating practical, energy-efficient\ndeployments at significantly smaller scales.","main_category":"cs.AI","categories":"cs.AI,cs.CV","published":"2025-04-07T17:58:57Z"}
{"aid":"http://arxiv.org/abs/2504.05300v1","title":"Dimension-Free Convergence of Diffusion Models for Approximate Gaussian\n  Mixtures","summary":"Diffusion models are distinguished by their exceptional generative\nperformance, particularly in producing high-quality samples through iterative\ndenoising. While current theory suggests that the number of denoising steps\nrequired for accurate sample generation should scale linearly with data\ndimension, this does not reflect the practical efficiency of widely used\nalgorithms like Denoising Diffusion Probabilistic Models (DDPMs). This paper\ninvestigates the effectiveness of diffusion models in sampling from complex\nhigh-dimensional distributions that can be well-approximated by Gaussian\nMixture Models (GMMs). For these distributions, our main result shows that DDPM\ntakes at most $\\widetilde{O}(1/\\varepsilon)$ iterations to attain an\n$\\varepsilon$-accurate distribution in total variation (TV) distance,\nindependent of both the ambient dimension $d$ and the number of components $K$,\nup to logarithmic factors. Furthermore, this result remains robust to score\nestimation errors. These findings highlight the remarkable effectiveness of\ndiffusion models in high-dimensional settings given the universal approximation\ncapability of GMMs, and provide theoretical insights into their practical\nsuccess.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.NA,math.ST,stat.ML,stat.TH","published":"2025-04-07T17:59:07Z"}
{"aid":"http://arxiv.org/abs/2504.05303v1","title":"InteractVLM: 3D Interaction Reasoning from 2D Foundational Models","summary":"We introduce InteractVLM, a novel method to estimate 3D contact points on\nhuman bodies and objects from single in-the-wild images, enabling accurate\nhuman-object joint reconstruction in 3D. This is challenging due to occlusions,\ndepth ambiguities, and widely varying object shapes. Existing methods rely on\n3D contact annotations collected via expensive motion-capture systems or\ntedious manual labeling, limiting scalability and generalization. To overcome\nthis, InteractVLM harnesses the broad visual knowledge of large Vision-Language\nModels (VLMs), fine-tuned with limited 3D contact data. However, directly\napplying these models is non-trivial, as they reason only in 2D, while\nhuman-object contact is inherently 3D. Thus we introduce a novel\nRender-Localize-Lift module that: (1) embeds 3D body and object surfaces in 2D\nspace via multi-view rendering, (2) trains a novel multi-view localization\nmodel (MV-Loc) to infer contacts in 2D, and (3) lifts these to 3D.\nAdditionally, we propose a new task called Semantic Human Contact estimation,\nwhere human contact predictions are conditioned explicitly on object semantics,\nenabling richer interaction modeling. InteractVLM outperforms existing work on\ncontact estimation and also facilitates 3D reconstruction from an in-the wild\nimage. Code and models are available at https://interactvlm.is.tue.mpg.de.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T17:59:33Z"}
{"aid":"http://arxiv.org/abs/2504.05632v1","title":"Reasoning Towards Fairness: Mitigating Bias in Language Models through\n  Reasoning-Guided Fine-Tuning","summary":"Recent advances in large-scale generative language models have shown that\nreasoning capabilities can significantly improve model performance across a\nvariety of tasks. However, the impact of reasoning on a model's ability to\nmitigate stereotypical responses remains largely underexplored. In this work,\nwe investigate the crucial relationship between a model's reasoning ability and\nfairness, and ask whether improved reasoning capabilities can mitigate harmful\nstereotypical responses, especially those arising due to shallow or flawed\nreasoning. We conduct a comprehensive evaluation of multiple open-source LLMs,\nand find that larger models with stronger reasoning abilities exhibit\nsubstantially lower stereotypical bias on existing fairness benchmarks.\nBuilding on this insight, we introduce ReGiFT -- Reasoning Guided Fine-Tuning,\na novel approach that extracts structured reasoning traces from advanced\nreasoning models and infuses them into models that lack such capabilities. We\nuse only general-purpose reasoning and do not require any fairness-specific\nsupervision for bias mitigation. Notably, we see that models fine-tuned using\nReGiFT not only improve fairness relative to their non-reasoning counterparts\nbut also outperform advanced reasoning models on fairness benchmarks. We also\nanalyze how variations in the correctness of the reasoning traces and their\nlength influence model fairness and their overall performance. Our findings\nhighlight that enhancing reasoning capabilities is an effective,\nfairness-agnostic strategy for mitigating stereotypical bias caused by\nreasoning flaws.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-08T03:21:51Z"}
{"aid":"http://arxiv.org/abs/2504.05638v1","title":"TAGC: Optimizing Gradient Communication in Distributed Transformer\n  Training","summary":"The increasing complexity of large language models (LLMs) necessitates\nefficient training strategies to mitigate the high computational costs\nassociated with distributed training. A significant bottleneck in this process\nis gradient synchronization across multiple GPUs, particularly in the\nzero-redundancy parallelism mode. In this paper, we introduce Transformer-Aware\nGradient Compression (TAGC), an optimized gradient compression algorithm\ndesigned specifically for transformer-based models. TAGC extends the lossless\nhomomorphic compression method by adapting it for sharded models and\nincorporating transformer-specific optimizations, such as layer-selective\ncompression and dynamic sparsification. Our experimental results demonstrate\nthat TAGC accelerates training by up to 15% compared to the standard Fully\nSharded Data Parallel (FSDP) approach, with minimal impact on model quality. We\nintegrate TAGC into the PyTorch FSDP framework, the implementation is publicly\navailable at https://github.com/ipolyakov/TAGC.","main_category":"cs.LG","categories":"cs.LG,cs.DC","published":"2025-04-08T03:33:39Z"}
{"aid":"http://arxiv.org/abs/2504.05641v1","title":"Testing black holes in a perfect fluid dark matter environment using\n  quasinormal modes","summary":"This research explores the quasinormal modes (QNMs) characteristics of\ncharged black holes in a perfect fluid dark matter (PFDM) environment. Based on\nthe Event Horizon Telescope (EHT) observations of the M87* black hole shadow,\nwe implemented necessary constraints on the parameter\nspace($a/M$,$\\lambda/M$).We found that for lower values of the magnetic charge\nparameter, the effective range of the PFDM parameter is approximately between\n-0.2 and 0, while as the magnetic charge parameter increases, this effective\nrange gradually extends toward more negative values. Then through sixth-order\nWKB method and time-domain method, we systematically analyzed the quasinormal\noscillation spectra under scalar field and electromagnetic field perturbations.\nThe results reveal that: the magnetic charge $a$ and PFDM parameters $\\lambda$\nmodulate the effective potential barrier of black hole spacetime, profoundly\ninfluencing the response frequency and energy dissipation characteristics of\nexternal perturbations. The consistently negative imaginary part of QNMs across\nthe entire physical parameter domain substantiates the dynamical stability of\nthe investigated system. Moreover, we discovered differences in the parameter\nvariation sensitivity between scalar field and electromagnetic field\nperturbations, providing a theoretical basis for distinguishing different field\ndisturbances. These results not only unveil the modulation mechanisms of\nelectromagnetic interactions and dark matter distribution on black hole\nspacetime structures but also offer potential observational evidence for future\ngravitational wave detection and black hole environment identification.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-08T03:36:50Z"}
{"aid":"http://arxiv.org/abs/2504.05642v1","title":"Leveraging Prompt-Tuning for Bengali Grammatical Error Explanation Using\n  Large Language Models","summary":"We propose a novel three-step prompt-tuning method for Bengali Grammatical\nError Explanation (BGEE) using state-of-the-art large language models (LLMs)\nsuch as GPT-4, GPT-3.5 Turbo, and Llama-2-70b. Our approach involves\nidentifying and categorizing grammatical errors in Bengali sentences,\ngenerating corrected versions of the sentences, and providing natural language\nexplanations for each identified error. We evaluate the performance of our BGEE\nsystem using both automated evaluation metrics and human evaluation conducted\nby experienced Bengali language experts. Our proposed prompt-tuning approach\nshows that GPT-4, the best performing LLM, surpasses the baseline model in\nautomated evaluation metrics, with a 5.26% improvement in F1 score and a 6.95%\nimprovement in exact match. Furthermore, compared to the previous baseline,\nGPT-4 demonstrates a decrease of 25.51% in wrong error type and a decrease of\n26.27% in wrong error explanation. However, the results still lag behind the\nhuman baseline.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T03:38:01Z"}
{"aid":"http://arxiv.org/abs/2504.05649v1","title":"POD: Predictive Object Detection with Single-Frame FMCW LiDAR Point\n  Cloud","summary":"LiDAR-based 3D object detection is a fundamental task in the field of\nautonomous driving. This paper explores the unique advantage of Frequency\nModulated Continuous Wave (FMCW) LiDAR in autonomous perception. Given a single\nframe FMCW point cloud with radial velocity measurements, we expect that our\nobject detector can detect the short-term future locations of objects using\nonly the current frame sensor data and demonstrate a fast ability to respond to\nintermediate danger. To achieve this, we extend the standard object detection\ntask to a novel task named predictive object detection (POD), which aims to\npredict the short-term future location and dimensions of objects based solely\non current observations. Typically, a motion prediction task requires\nhistorical sensor information to process the temporal contexts of each object,\nwhile our detector's avoidance of multi-frame historical information enables a\nmuch faster response time to potential dangers. The core advantage of FMCW\nLiDAR lies in the radial velocity associated with every reflected point. We\npropose a novel POD framework, the core idea of which is to generate a virtual\nfuture point using a ray casting mechanism, create virtual two-frame point\nclouds with the current and virtual future frames, and encode these two-frame\nvoxel features with a sparse 4D encoder. Subsequently, the 4D voxel features\nare separated by temporal indices and remapped into two Bird's Eye View (BEV)\nfeatures: one decoded for standard current frame object detection and the other\nfor future predictive object detection. Extensive experiments on our in-house\ndataset demonstrate the state-of-the-art standard and predictive detection\nperformance of the proposed POD framework.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T03:53:28Z"}
{"aid":"http://arxiv.org/abs/2504.05661v1","title":"Online Bernstein-von Mises theorem","summary":"Online learning is an inferential paradigm in which parameters are updated\nincrementally from sequentially available data, in contrast to batch learning,\nwhere the entire dataset is processed at once. In this paper, we assume that\nmini-batches from the full dataset become available sequentially. The Bayesian\nframework, which updates beliefs about unknown parameters after observing each\nmini-batch, is naturally suited for online learning. At each step, we update\nthe posterior distribution using the current prior and new observations, with\nthe updated posterior serving as the prior for the next step. However, this\nrecursive Bayesian updating is rarely computationally tractable unless the\nmodel and prior are conjugate. When the model is regular, the updated posterior\ncan be approximated by a normal distribution, as justified by the Bernstein-von\nMises theorem. We adopt a variational approximation at each step and\ninvestigate the frequentist properties of the final posterior obtained through\nthis sequential procedure. Under mild assumptions, we show that the accumulated\napproximation error becomes negligible once the mini-batch size exceeds a\nthreshold depending on the parameter dimension. As a result, the sequentially\nupdated posterior is asymptotically indistinguishable from the full posterior.","main_category":"math.ST","categories":"math.ST,stat.TH,G.3","published":"2025-04-08T04:22:56Z"}
{"aid":"http://arxiv.org/abs/2504.05666v1","title":"Contraction and concentration of measures with applications to\n  theoretical neuroscience","summary":"We investigate the asymptotic behavior of probability measures associated\nwith stochastic dynamical systems featuring either globally contracting or\n$B_{r}$-contracting drift terms. While classical results often assume constant\ndiffusion and gradient-based drifts, we extend the analysis to spatially\ninhomogeneous diffusion and non-integrable vector fields. We establish\nsufficient conditions for the existence and uniqueness of stationary measures\nunder global contraction, showing that convergence is preserved when the\ncontraction rate dominates diffusion inhomogeneity. For systems contracting\nonly outside of a compact set and with constant diffusion, we demonstrate mass\nconcentration near the minima of an associated non-convex potential, like in\nmultistable regimes. The theoretical findings are illustrated through Hopfield\nnetworks, highlighting implications for memory retrieval dynamics in noisy\nenvironments.","main_category":"math.DS","categories":"math.DS,math-ph,math.AP,math.MP","published":"2025-04-08T04:24:39Z"}
{"aid":"http://arxiv.org/abs/2504.05670v1","title":"Dual Boost-Driven Graph-Level Clustering Network","summary":"Graph-level clustering remains a pivotal yet formidable challenge in graph\nlearning. Recently, the integration of deep learning with representation\nlearning has demonstrated notable advancements, yielding performance\nenhancements to a certain degree. However, existing methods suffer from at\nleast one of the following issues: 1. the original graph structure has noise,\nand 2. during feature propagation and pooling processes, noise is gradually\naggregated into the graph-level embeddings through information propagation.\nConsequently, these two limitations mask clustering-friendly information,\nleading to suboptimal graph-level clustering performance. To this end, we\npropose a novel Dual Boost-Driven Graph-Level Clustering Network (DBGCN) to\nalternately promote graph-level clustering and filtering out interference\ninformation in a unified framework. Specifically, in the pooling step, we\nevaluate the contribution of features at the global and optimize them using a\nlearnable transformation matrix to obtain high-quality graph-level\nrepresentation, such that the model's reasoning capability can be improved.\nMoreover, to enable reliable graph-level clustering, we first identify and\nsuppress information detrimental to clustering by evaluating similarities\nbetween graph-level representations, providing more accurate guidance for\nmulti-view fusion. Extensive experiments demonstrated that DBGCN outperforms\nthe state-of-the-art graph-level clustering methods on six benchmark datasets.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-08T04:32:46Z"}
{"aid":"http://arxiv.org/abs/2504.05679v1","title":"Event-based Civil Infrastructure Visual Defect Detection: ev-CIVIL\n  Dataset and Benchmark","summary":"Small Unmanned Aerial Vehicle (UAV) based visual inspections are a more\nefficient alternative to manual methods for examining civil structural defects,\noffering safe access to hazardous areas and significant cost savings by\nreducing labor requirements. However, traditional frame-based cameras, widely\nused in UAV-based inspections, often struggle to capture defects under low or\ndynamic lighting conditions. In contrast, Dynamic Vision Sensors (DVS), or\nevent-based cameras, excel in such scenarios by minimizing motion blur,\nenhancing power efficiency, and maintaining high-quality imaging across diverse\nlighting conditions without saturation or information loss. Despite these\nadvantages, existing research lacks studies exploring the feasibility of using\nDVS for detecting civil structural defects.Moreover, there is no dedicated\nevent-based dataset tailored for this purpose. Addressing this gap, this study\nintroduces the first event-based civil infrastructure defect detection dataset,\ncapturing defective surfaces as a spatio-temporal event stream using DVS.In\naddition to event-based data, the dataset includes grayscale intensity image\nframes captured simultaneously using an Active Pixel Sensor (APS). Both data\ntypes were collected using the DAVIS346 camera, which integrates DVS and APS\nsensors.The dataset focuses on two types of defects: cracks and spalling, and\nincludes data from both field and laboratory environments. The field dataset\ncomprises 318 recording sequences,documenting 458 distinct cracks and 121\ndistinct spalling instances.The laboratory dataset includes 362 recording\nsequences, covering 220 distinct cracks and 308 spalling instances.Four\nrealtime object detection models were evaluated on it to validate the dataset\neffectiveness.The results demonstrate the dataset robustness in enabling\naccurate defect detection and classification,even under challenging lighting\nconditions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T04:44:33Z"}
{"aid":"http://arxiv.org/abs/2504.05686v1","title":"kNN-SVC: Robust Zero-Shot Singing Voice Conversion with Additive\n  Synthesis and Concatenation Smoothness Optimization","summary":"Robustness is critical in zero-shot singing voice conversion (SVC). This\npaper introduces two novel methods to strengthen the robustness of the kNN-VC\nframework for SVC. First, kNN-VC's core representation, WavLM, lacks harmonic\nemphasis, resulting in dull sounds and ringing artifacts. To address this, we\nleverage the bijection between WavLM, pitch contours, and spectrograms to\nperform additive synthesis, integrating the resulting waveform into the model\nto mitigate these issues. Second, kNN-VC overlooks concatenative smoothness, a\nkey perceptual factor in SVC. To enhance smoothness, we propose a new distance\nmetric that filters out unsuitable kNN candidates and optimize the summing\nweights of the candidates during inference. Although our techniques are built\non the kNN-VC framework for implementation convenience, they are broadly\napplicable to general concatenative neural synthesis models. Experimental\nresults validate the effectiveness of these modifications in achieving robust\nSVC. Demo: http://knnsvc.com Code: https://github.com/SmoothKen/knn-svc","main_category":"cs.SD","categories":"cs.SD,cs.AI,cs.LG,cs.MM,eess.AS","published":"2025-04-08T04:59:56Z"}
{"aid":"http://arxiv.org/abs/2504.05689v1","title":"Separator Injection Attack: Uncovering Dialogue Biases in Large Language\n  Models Caused by Role Separators","summary":"Conversational large language models (LLMs) have gained widespread attention\ndue to their instruction-following capabilities. To ensure conversational LLMs\nfollow instructions, role separators are employed to distinguish between\ndifferent participants in a conversation. However, incorporating role\nseparators introduces potential vulnerabilities. Misusing roles can lead to\nprompt injection attacks, which can easily misalign the model's behavior with\nthe user's intentions, raising significant security concerns. Although various\nprompt injection attacks have been proposed, recent research has largely\noverlooked the impact of role separators on safety. This highlights the\ncritical need to thoroughly understand the systemic weaknesses in dialogue\nsystems caused by role separators. This paper identifies modeling weaknesses\ncaused by role separators. Specifically, we observe a strong positional bias\nassociated with role separators, which is inherent in the format of dialogue\nmodeling and can be triggered by the insertion of role separators. We further\ndevelop the Separators Injection Attack (SIA), a new orthometric attack based\non role separators. The experiment results show that SIA is efficient and\nextensive in manipulating model behavior with an average gain of 18.2% for\nmanual methods and enhances the attack success rate to 100% with automatic\nmethods.","main_category":"cs.CL","categories":"cs.CL,cs.CR","published":"2025-04-08T05:20:56Z"}
{"aid":"http://arxiv.org/abs/2504.05696v1","title":"Diabetic Retinopathy Detection Based on Convolutional Neural Networks\n  with SMOTE and CLAHE Techniques Applied to Fundus Images","summary":"Diabetic retinopathy (DR) is one of the major complications in diabetic\npatients' eyes, potentially leading to permanent blindness if not detected\ntimely. This study aims to evaluate the accuracy of artificial intelligence\n(AI) in diagnosing DR. The method employed is the Synthetic Minority\nOver-sampling Technique (SMOTE) algorithm, applied to identify DR and its\nseverity stages from fundus images using the public dataset \"APTOS 2019\nBlindness Detection.\" Literature was reviewed via ScienceDirect, ResearchGate,\nGoogle Scholar, and IEEE Xplore. Classification results using Convolutional\nNeural Network (CNN) showed the best performance for the binary classes normal\n(0) and DR (1) with an accuracy of 99.55%, precision of 99.54%, recall of\n99.54%, and F1-score of 99.54%. For the multiclass classification No_DR (0),\nMild (1), Moderate (2), Severe (3), Proliferate_DR (4), the accuracy was\n95.26%, precision 95.26%, recall 95.17%, and F1-score 95.23%. Evaluation using\nthe confusion matrix yielded results of 99.68% for binary classification and\n96.65% for multiclass. This study highlights the significant potential in\nenhancing the accuracy of DR diagnosis compared to traditional human analysis","main_category":"eess.IV","categories":"eess.IV,cs.CV,cs.LG,q-bio.NC","published":"2025-04-08T05:38:53Z"}
{"aid":"http://arxiv.org/abs/2504.05706v1","title":"SEVERE++: Evaluating Benchmark Sensitivity in Generalization of Video\n  Representation Learning","summary":"Continued advances in self-supervised learning have led to significant\nprogress in video representation learning, offering a scalable alternative to\nsupervised approaches by removing the need for manual annotations. Despite\nstrong performance on standard action recognition benchmarks, video\nself-supervised learning methods are largely evaluated under narrow protocols,\ntypically pretraining on Kinetics-400 and fine-tuning on similar datasets,\nlimiting our understanding of their generalization in real world scenarios. In\nthis work, we present a comprehensive evaluation of modern video\nself-supervised models, focusing on generalization across four key downstream\nfactors: domain shift, sample efficiency, action granularity, and task\ndiversity. Building on our prior work analyzing benchmark sensitivity in\nCNN-based contrastive learning, we extend the study to cover state-of-the-art\ntransformer-based video-only and video-text models. Specifically, we benchmark\n12 transformer-based methods (7 video-only, 5 video-text) and compare them to\n10 CNN-based methods, totaling over 1100 experiments across 8 datasets and 7\ndownstream tasks. Our analysis shows that, despite architectural advances,\ntransformer-based models remain sensitive to downstream conditions. No method\ngeneralizes consistently across all factors, video-only transformers perform\nbetter under domain shifts, CNNs outperform for fine-grained tasks, and\nvideo-text models often underperform despite large scale pretraining. We also\nfind that recent transformer models do not consistently outperform earlier\napproaches. Our findings provide a detailed view of the strengths and\nlimitations of current video SSL methods and offer a unified benchmark for\nevaluating generalization in video representation learning.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T06:00:28Z"}
{"aid":"http://arxiv.org/abs/2504.05708v1","title":"Thermodynamic supercriticality and complex phase diagram for the AdS\n  black hole","summary":"In this study, we extend the application of the Lee-Yang phase transition\ntheorem to the realm of AdS black hole thermodynamics, thereby deriving a\ncomprehensive complex phase diagram for such systems. Our research augments\nextant studies on black hole thermodynamic phase diagrams, particularly in the\nregime above the critical point, by delineating the Widom line of AdS black\nholes. This boundary segregates the supercritical domain of the phase diagram\ninto two disparate zones. As the system traverses the thermodynamic crossover\nwithin the supercritical region, it undergoes a transition from one\nsupercritical phase to another, while maintaining the continuity of its\nthermodynamic state functions. This behavior is fundamentally different from\nthat below the critical point, where crossing the coexistence line results in\ndiscontinuities of thermodynamic state functions. The Widom line enables a\nthermodynamic crossover between single-phase states without traversing the\nspinodal that emerges in the critical region.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-08T06:03:39Z"}
{"aid":"http://arxiv.org/abs/2504.05712v1","title":"How I Learned to Stop Worrying and Love ChatGPT","summary":"In the dynamic landscape of software engineering, the emergence of\nChatGPT-generated code signifies a distinctive and evolving paradigm in\ndevelopment practices. We delve into the impact of interactions with ChatGPT on\nthe software development process, specifically analysing its influence on\nsource code changes. Our emphasis lies in aligning code with ChatGPT\nconversations, separately analysing the user-provided context of the code and\nthe extent to which the resulting code has been influenced by ChatGPT.\nAdditionally, employing survival analysis techniques, we examine the longevity\nof ChatGPT-generated code segments in comparison to lines written\ntraditionally. The goal is to provide valuable insights into the transformative\nrole of ChatGPT in software development, illuminating its implications for code\nevolution and sustainability within the ecosystem.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-08T06:13:16Z"}
{"aid":"http://arxiv.org/abs/2504.05714v1","title":"Mass spectrum of S-wave mesons in the relativistic independent quark\n  model","summary":"The confining strength or model parameters and constituent quark masses are\nreparametrized for predicting the ground state meson masses. We analyzed these\nfrom the hyperfine splitting of $S$-wave heavy-flavored, heavy-light and light\n(except non-strange) mesons in the framework of a relativistic independent\nquark (RIQ) model with one gluon exchange and centre-of-mass correction. These\nmesons with spin parity $J^P=0^-$ and $1^-$, the masses obtained are in\naccordance with the experimental physical masses. The results will serve as\ngood complementary tools in further study of hadron dynamics and will behave as\na foundation for the higher excited and exotic states of hadrons.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-08T06:25:04Z"}
{"aid":"http://arxiv.org/abs/2504.05716v1","title":"Single-Agent vs. Multi-Agent LLM Strategies for Automated Student\n  Reflection Assessment","summary":"We explore the use of Large Language Models (LLMs) for automated assessment\nof open-text student reflections and prediction of academic performance.\nTraditional methods for evaluating reflections are time-consuming and may not\nscale effectively in educational settings. In this work, we employ LLMs to\ntransform student reflections into quantitative scores using two assessment\nstrategies (single-agent and multi-agent) and two prompting techniques\n(zero-shot and few-shot). Our experiments, conducted on a dataset of 5,278\nreflections from 377 students over three academic terms, demonstrate that the\nsingle-agent with few-shot strategy achieves the highest match rate with human\nevaluations. Furthermore, models utilizing LLM-assessed reflection scores\noutperform baselines in both at-risk student identification and grade\nprediction tasks. These findings suggest that LLMs can effectively automate\nreflection assessment, reduce educators' workload, and enable timely support\nfor students who may need additional assistance. Our work emphasizes the\npotential of integrating advanced generative AI technologies into educational\npractices to enhance student engagement and academic success.","main_category":"cs.LG","categories":"cs.LG,cs.CY","published":"2025-04-08T06:34:15Z"}
{"aid":"http://arxiv.org/abs/2504.05733v1","title":"The evolution of a curve induced by the Pohlmeyer-Lund-Regge equation","summary":"This paper investigates the evolution of space curves governed by the\nPohlmeyer-Lund-Regge (PLR) equation, an integrable extension of the sine-Gordon\nequation. We examine a specific type of curve evolution, known as the\nLund-Regge evolution, and derive its representation in the Frenet frame. We\nshow the Frenet frame evolution aligns with the Lax system of the PLR equation\nand develop a construction method for curve families via the Sym formula. In\nconclusion, we describe the Lund-Regge evolution corresponding to Date's\nmulti-soliton solutions to the PLR equation, with illustrations of curves and\nsurfaces.","main_category":"math.DG","categories":"math.DG,nlin.SI","published":"2025-04-08T07:07:32Z"}
{"aid":"http://arxiv.org/abs/2504.05744v1","title":"Influence of doping on non-equilibrium carrier dynamics in graphene","summary":"Controlling doping is key to optimizing graphene for high-speed electronic\nand optoelectronic devices. However, its impact on non-equilibrium carrier\nlifetimes remains debated. Here, we systematically tune the doping level of\nquasi-freestanding epitaxial graphene on SiC(0001) via potassium deposition and\nprobe its ultrafast carrier dynamics directly in the band structure using time-\nand angle-resolved photoemission spectroscopy (trARPES). We find that increased\ndoping lowers both the peak electronic temperature and the cooling rate of\nDirac carriers, which we attribute to higher electronic heat capacity and\nreduced phonon emission phase space. Comparing quasi-freestanding graphene with\ngraphene on a carbon buffer layer reveals faster relaxation in the latter,\nlikely due to additional phonon modes being available for heat dissipation.\nThese findings offer new insights for optimizing graphene in electronic and\nphotonic technologies.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-08T07:23:10Z"}
{"aid":"http://arxiv.org/abs/2504.05768v1","title":"Temporal Dynamic Embedding for Irregularly Sampled Time Series","summary":"In several practical applications, particularly healthcare, clinical data of\neach patient is individually recorded in a database at irregular intervals as\nrequired. This causes a sparse and irregularly sampled time series, which makes\nit difficult to handle as a structured representation of the prerequisites of\nneural network models. We therefore propose temporal dynamic embedding (TDE),\nwhich enables neural network models to receive data that change the number of\nvariables over time. TDE regards each time series variable as an embedding\nvector evolving over time, instead of a conventional fixed structured\nrepresentation, which causes a critical missing problem. For each time step,\nTDE allows for the selective adoption and aggregation of only observed variable\nsubsets and represents the current status of patient based on current\nobservations. The experiment was conducted on three clinical datasets:\nPhysioNet 2012, MIMIC-III, and PhysioNet 2019. The TDE model performed\ncompetitively or better than the imputation-based baseline and several recent\nstate-of-the-art methods with reduced training runtime.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-08T07:49:22Z"}
{"aid":"http://arxiv.org/abs/2504.05773v1","title":"Simultaneous Multiphoton-Multiatom Processes in Atomic Gases under Laser\n  Fields","summary":"We investigate simultaneous multiphoton-multiatom processes in atomic gases\nexposed to laser fields under specific frequency conditions, where multiple\natoms are simultaneously excited through the absorption of one laser photon\neach. These processes represent natural high-order quantum electrodynamics\n(QED) effects that occur independently of inter-atomic interactions. A\ncharacteristic length scale emerges, governing the physical range over which\nthese phenomena manifest. We propose experiments to demonstrate the fundamental\naspects of these collective QED processes.","main_category":"physics.atom-ph","categories":"physics.atom-ph,cond-mat.quant-gas","published":"2025-04-08T07:52:46Z"}
{"aid":"http://arxiv.org/abs/2504.05776v1","title":"Quantifying uncertainty in inverse scattering problems set in layered\n  environments","summary":"The attempt to solve inverse scattering problems often leads to optimization\nand sampling problems that require handling moderate to large amounts of\npartial differential equations acting as constraints. We focus here on\ndetermining inclusions in a layered medium from the measurement of wave fields\non the surface, while quantifying uncertainty and addressing the effect of wave\nsolver quality. Inclusions are characterized by a few parameters describing\ntheir material properties and shapes. We devise algorithms to estimate the most\nlikely configurations by optimizing cost functionals with Bayesian\nregularizations and wave constraints. In particular, we design an automatic\nLevenberg-Marquardt-Fletcher type scheme based on the use of algorithmic\ndifferentiation and adaptive finite element meshes for time dependent wave\nequation constraints with changing inclusions. In synthetic tests with a single\nfrequency, this scheme converges in few iterations for increasing noise levels.\nTo attain a global view of other possible high probability configurations and\nasymmetry effects we resort to parallelizable affine invariant Markov Chain\nMonte Carlo methods, at the cost of solving a few million wave problems. This\nforces the use of prefixed meshes. While the optimal configurations remain\nsimilar, we encounter additional high probability inclusions influenced by the\nprior information, the noise level and the layered structure, effect that can\nbe reduced by considering more frequencies. We analyze the effect on the\ncalculations of working with adaptive and fixed meshes, under a simple choice\nof non-reflecting boundary conditions in truncated layered domains for which we\nestablish wellposedness and convergence results.","main_category":"math.NA","categories":"math.NA,cs.NA,math.OC,physics.comp-ph,physics.data-an,physics.geo-ph","published":"2025-04-08T07:57:36Z"}
{"aid":"http://arxiv.org/abs/2504.05779v1","title":"FASR-Net: Unsupervised Shadow Removal Leveraging Inherent Frequency\n  Priors","summary":"Shadow removal is challenging due to the complex interaction of geometry,\nlighting, and environmental factors. Existing unsupervised methods often\noverlook shadow-specific priors, leading to incomplete shadow recovery. To\naddress this issue, we propose a novel unsupervised Frequency Aware Shadow\nRemoval Network (FASR-Net), which leverages the inherent frequency\ncharacteristics of shadow regions. Specifically, the proposed Wavelet Attention\nDownsampling Module (WADM) integrates wavelet-based image decomposition and\ndeformable attention, effectively breaking down the image into frequency\ncomponents to enhance shadow details within specific frequency bands. We also\nintroduce several new loss functions for precise shadow-free image\nreproduction: a frequency loss to capture image component details, a\nbrightness-chromaticity loss that references the chromaticity of shadow-free\nregions, and an alignment loss to ensure smooth transitions between shadowed\nand shadow-free regions. Experimental results on the AISTD and SRD datasets\ndemonstrate that our method achieves superior shadow removal performance.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T08:00:58Z"}
{"aid":"http://arxiv.org/abs/2504.05793v1","title":"Negotiating Strict Latency Limits for Dynamic Real-Time Services in\n  Vehicular Time-Sensitive Networks","summary":"Future vehicles are expected to dynamically deploy in-vehicle applications\nwithin a Service-Oriented Architecture (SOA). Critical services operate under\nhard real-time constraints, which Time-Sensitive Networking (TSN) complements\non the in-vehicle Ethernet layer. TSN ensures deterministic communication\nbetween critical services and its Credit-Based Shaper (CBS) supports dynamic\nresource reservations. However, the dynamic nature of service deployment\nchallenges network resource configuration, since any new reservation may change\nthe latency of already validated flows. In addition, standard methods of\nworst-case latency analysis for CBS have been found incorrect, and current TSN\nstream reservation procedures lack mechanisms to signal application layer\nQuality-of-Service (QoS) requirements or verify deadlines. In this paper, we\npropose a QoS negotiation scheme within the automotive SOA that interacts with\nthe TSN network controller to reserve resources while ensuring latency bounds.\nWe comparatively evaluate reservation schemes using worst-case analysis and\nsimulations of a realistic In-Vehicle Network (IVN) for demonstrating their\nimpact on QoS guarantees, resource utilization, and setup times. We find that\nonly a reservation scheme utilizing per-queue delay budgets and network\ncalculus provides valid configurations and guarantees acceptable latency bounds\nthroughout the IVN. The proposed service negotiation mechanism efficiently\nestablishes 450 vehicular network reservations in just 11ms.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-08T08:22:32Z"}
{"aid":"http://arxiv.org/abs/2504.05802v1","title":"Mass-Spring Models for Passive Keyword Spotting: A Springtronics\n  Approach","summary":"Mechanical systems played a foundational role in computing history, and have\nregained interest due to their unique properties, such as low damping and the\nability to process mechanical signals without transduction. However, recent\nefforts have primarily focused on elementary computations, implemented in\nsystems based on pre-defined reservoirs, or in periodic systems such as arrays\nof buckling beams. Here, we numerically demonstrate a passive mechanical system\n-- in the form of a nonlinear mass-spring model -- that tackles a real-world\nbenchmark for keyword spotting in speech signals. The model is organized in a\nhierarchical architecture combining feature extraction and continuous-time\nconvolution, with each individual stage tailored to the physics of the\nconsidered mass-spring systems. For each step in the computation, a subsystem\nis designed by combining a small set of low-order polynomial potentials. These\npotentials act as fundamental components that interconnect a network of masses.\nIn analogy to electronic circuit design, where complex functional circuits are\nconstructed by combining basic components into hierarchical designs, we refer\nto this framework as springtronics. We introduce springtronic systems with\nhundreds of degrees of freedom, achieving speech classification accuracy\ncomparable to existing sub-mW electronic systems.","main_category":"cs.SD","categories":"cs.SD,cond-mat.dis-nn,eess.AS","published":"2025-04-08T08:31:19Z"}
{"aid":"http://arxiv.org/abs/2504.05805v1","title":"Why is Normalization Necessary for Linear Recommenders?","summary":"Despite their simplicity, linear autoencoder (LAE)-based models have shown\ncomparable or even better performance with faster inference speed than neural\nrecommender models. However, LAEs face two critical challenges: (i) popularity\nbias, which tends to recommend popular items, and (ii) neighborhood bias, which\noverly focuses on capturing local item correlations. To address these issues,\nthis paper first analyzes the effect of two existing normalization methods for\nLAEs, i.e., random-walk and symmetric normalization. Our theoretical analysis\nreveals that normalization highly affects the degree of popularity and\nneighborhood biases among items. Inspired by this analysis, we propose a\nversatile normalization solution, called Data-Adaptive Normalization (DAN),\nwhich flexibly controls the popularity and neighborhood biases by adjusting\nitem- and user-side normalization to align with unique dataset characteristics.\nOwing to its model-agnostic property, DAN can be easily applied to various\nLAE-based models. Experimental results show that DAN-equipped LAEs consistently\nimprove existing LAE-based models across six benchmark datasets, with\nsignificant gains of up to 128.57% and 12.36% for long-tail items and unbiased\nevaluations, respectively. Refer to our code in https://github.com/psm1206/DAN.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-08T08:37:32Z"}
{"aid":"http://arxiv.org/abs/2504.05811v1","title":"Effects of strange molecular partners of $P_c$ states in $Î³p \\to K\n  Î£$ reactions","summary":"Our previous studies revealed evidence of the strange molecular partners of\n$P_c$ states, $N(2080)3/2^-$ and $N(2270)3/2^-$, in the $\\gamma p \\to K^{*+}\n\\Sigma^0 / K^{*0} \\Sigma^+$ and $\\gamma p \\to \\phi p$ reactions. Motivated by\nthe differential cross-section data for $\\gamma p \\to K^+ \\Sigma^0$ from CLAS\n2010, which exhibits some bump structures at $W \\approx$ 1875, 2080 and 2270\nMeV, we extend our previous analysis by investigating the effects of\n$N(1535)1/2^-$, $N(1875)3/2^-$, $N(2080)1/2^- \\&\\ 3/2^-$ and $N(2270)1/2^- ,\n3/2^- \\&\\ 5/2^-$, as strange partners of $P_c$ molecular states, in the\nreactions $\\gamma p \\to K^+ \\Sigma^0$ and $\\gamma p \\to K^0 \\Sigma^+$. The\ntheoretical model employed in this study utilizes an effective Lagrangian\napproach in the tree-level Born approximation. It contains the contributions\nfrom $s$-channel with exchanges of $N$, $\\Delta$, $N^*$ (including the hadronic\nmolecules with hidden strangeness), and $\\Delta^*$; $t$-channel; $u$-channel;\nand the generalized contact term. The results corresponding to the final fitted\nparameters are in good agreement with all available experimental data of both\ncross-sections and polarization observables for $\\gamma p \\to K^+ \\Sigma^0$ and\n$\\gamma p \\to K^0 \\Sigma^+$. Notably, the $s$-channel exchanges of molecules\nsignificantly contribute to the bump structures in cross-sections for $\\gamma p\n\\to K \\Sigma$ at $W \\approx$ 1900, 2080 and 2270 MeV, and show considerable\ncoherence with contributions from $s$-channel exchanges of general resonances\nto construct the overall structures of cross-sections. More abundant\nexperiments, particularly for the reaction $\\gamma p \\to K^0 \\Sigma^+$, are\nnecessary to further strengthen the constraints on the theoretical models.","main_category":"nucl-th","categories":"nucl-th,hep-ph","published":"2025-04-08T08:48:25Z"}
{"aid":"http://arxiv.org/abs/2504.05815v1","title":"Parasite: A Steganography-based Backdoor Attack Framework for Diffusion\n  Models","summary":"Recently, the diffusion model has gained significant attention as one of the\nmost successful image generation models, which can generate high-quality images\nby iteratively sampling noise. However, recent studies have shown that\ndiffusion models are vulnerable to backdoor attacks, allowing attackers to\nenter input data containing triggers to activate the backdoor and generate\ntheir desired output. Existing backdoor attack methods primarily focused on\ntarget noise-to-image and text-to-image tasks, with limited work on backdoor\nattacks in image-to-image tasks. Furthermore, traditional backdoor attacks\noften rely on a single, conspicuous trigger to generate a fixed target image,\nlacking concealability and flexibility. To address these limitations, we\npropose a novel backdoor attack method called \"Parasite\" for image-to-image\ntasks in diffusion models, which not only is the first to leverage\nsteganography for triggers hiding, but also allows attackers to embed the\ntarget content as a backdoor trigger to achieve a more flexible attack.\n\"Parasite\" as a novel attack method effectively bypasses existing detection\nframeworks to execute backdoor attacks. In our experiments, \"Parasite\" achieved\na 0 percent backdoor detection rate against the mainstream defense frameworks.\nIn addition, in the ablation study, we discuss the influence of different\nhiding coefficients on the attack results. You can find our code at\nhttps://anonymous.4open.science/r/Parasite-1715/.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-08T08:53:47Z"}
{"aid":"http://arxiv.org/abs/2504.05844v1","title":"Adaptive Substructure-Aware Expert Model for Molecular Property\n  Prediction","summary":"Molecular property prediction is essential for applications such as drug\ndiscovery and toxicity assessment. While Graph Neural Networks (GNNs) have\nshown promising results by modeling molecules as molecular graphs, their\nreliance on data-driven learning limits their ability to generalize,\nparticularly in the presence of data imbalance and diverse molecular\nsubstructures. Existing methods often overlook the varying contributions of\ndifferent substructures to molecular properties, treating them uniformly. To\naddress these challenges, we propose ASE-Mol, a novel GNN-based framework that\nleverages a Mixture-of-Experts (MoE) approach for molecular property\nprediction. ASE-Mol incorporates BRICS decomposition and significant\nsubstructure awareness to dynamically identify positive and negative\nsubstructures. By integrating a MoE architecture, it reduces the adverse impact\nof negative motifs while improving adaptability to positive motifs.\nExperimental results on eight benchmark datasets demonstrate that ASE-Mol\nachieves state-of-the-art performance, with significant improvements in both\naccuracy and interpretability.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-08T09:25:03Z"}
{"aid":"http://arxiv.org/abs/2504.05845v1","title":"Eikonal boundary condition for level set method","summary":"In this paper, we propose to use the eikonal equation as a boundary condition\nwhen advective or normal flow equations in the level set formulation are solved\nnumerically on polyhedral meshes in the three-dimensional domain. Since the\nlevel set method can use a signed distance function as an initial condition,\nthe eikonal equation on the boundary is a suitable choice at the initial time.\nEnforcing the eikonal equation on the boundary for later times can eliminate\nthe need for inflow boundary conditions, which are typically required for\ntransport equations. In selected examples where exact solutions are available,\nwe compare the proposed method with the method using the exact Dirichlet\nboundary condition. The numerical results confirm that the use of the eikonal\nboundary condition provides comparable accuracy and robustness in surface\nevolution compared to the use of the exact Dirichlet boundary condition, which\nis generally not available. We also present numerical results of evolving a\ngeneral closed surface.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-08T09:25:19Z"}
{"aid":"http://arxiv.org/abs/2504.05851v1","title":"Identifying and Replicating Code Patterns Driving Performance\n  Regressions in Software Systems","summary":"Context: Performance regressions negatively impact execution time and memory\nusage of software systems. Nevertheless, there is a lack of systematic methods\nto evaluate the effectiveness of performance test suites. Performance mutation\ntesting, which introduces intentional defects (mutants) to measure and enhance\nfault-detection capabilities, is promising but underexplored. A key challenge\nis understanding if generated mutants accurately reflect real-world performance\nissues. Goal: This study evaluates and extends mutation operators for\nperformance testing. Its objectives include (i) collecting existing performance\nmutation operators, (ii) introducing new operators from real-world code changes\nthat impact performance, and (iii) evaluating these operators on real-world\nsystems to see if they effectively degrade performance. Method: To this aim, we\nwill (i) review the literature to identify performance mutation operators, (ii)\nconduct a mining study to extract patterns of code changes linked to\nperformance regressions, (iii) propose new mutation operators based on these\npatterns, and (iv) apply and evaluate the operators to assess their\neffectiveness in exposing performance degradations. Expected Outcomes: We aim\nto provide an enriched set of mutation operators for performance testing,\nhelping developers and researchers identify harmful coding practices and design\nbetter strategies to detect and prevent performance regressions.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-08T09:28:46Z"}
{"aid":"http://arxiv.org/abs/2504.05855v1","title":"Enhancing Coreference Resolution with Pretrained Language Models:\n  Bridging the Gap Between Syntax and Semantics","summary":"Large language models have made significant advancements in various natural\nlanguage processing tasks, including coreference resolution. However,\ntraditional methods often fall short in effectively distinguishing referential\nrelationships due to a lack of integration between syntactic and semantic\ninformation. This study introduces an innovative framework aimed at enhancing\ncoreference resolution by utilizing pretrained language models. Our approach\ncombines syntax parsing with semantic role labeling to accurately capture finer\ndistinctions in referential relationships. By employing state-of-the-art\npretrained models to gather contextual embeddings and applying an attention\nmechanism for fine-tuning, we improve the performance of coreference tasks.\nExperimental results across diverse datasets show that our method surpasses\nconventional coreference resolution systems, achieving notable accuracy in\ndisambiguating references. This development not only improves coreference\nresolution outcomes but also positively impacts other natural language\nprocessing tasks that depend on precise referential understanding.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-08T09:33:09Z"}
{"aid":"http://arxiv.org/abs/2504.05861v1","title":"Sparse Bounded Hop-Spanners for Geometric Intersection Graphs","summary":"We present new results on $2$- and $3$-hop spanners for geometric\nintersection graphs. These include improved upper and lower bounds for $2$- and\n$3$-hop spanners for many geometric intersection graphs in $\\mathbb{R}^d$. For\nexample, we show that the intersection graph of $n$ balls in $\\mathbb{R}^d$\nadmits a $2$-hop spanner of size $O^*\\left(n^{\\frac{3}{2}-\\frac{1}{2(2\\lfloor\nd/2\\rfloor +1)}}\\right)$ and the intersection graph of $n$ fat axis-parallel\nboxes in $\\mathbb{R}^d$ admits a $2$-hop spanner of size $O(n \\log^{d+1}n)$.\n  Furthermore, we show that the intersection graph of general semi-algebraic\nobjects in $\\mathbb{R}^d$ admits a $3$-hop spanner of size\n$O^*\\left(n^{\\frac{3}{2}-\\frac{1}{2(2D-1)}}\\right)$, where $D$ is a parameter\nassociated with the description complexity of the objects. For such families\n(or more specifically, for tetrahedra in $\\mathbb{R}^3$), we provide a lower\nbound of $\\Omega(n^{\\frac{4}{3}})$. For $3$-hop and axis-parallel boxes in\n$\\mathbb{R}^d$, we provide the upper bound $O(n \\log ^{d-1}n)$ and lower bound\n$\\Omega\\left(n (\\frac{\\log n}{\\log \\log n})^{d-2}\\right)$.","main_category":"cs.CG","categories":"cs.CG,cs.DM","published":"2025-04-08T09:40:14Z"}
{"aid":"http://arxiv.org/abs/2504.05864v1","title":"Tunable spin-orbit splitting in bilayer graphene/WSe$_2$ quantum devices","summary":"Bilayer graphene (BLG)-based quantum devices represent a promising platform\nfor emerging technologies such as quantum computing and spintronics. However,\ntheir intrinsically weak spin-orbit coupling (SOC) presents a challenge for\nspin and valley manipulation, as these applications operate more efficiently in\nthe presence of strong SOC. Integrating BLG with transition metal\ndichalcogenides (TMDs) significantly enhances SOC via proximity effects. While\nthis enhancement has been experimentally demonstrated in 2D-layered structures,\n1D and 0D-nanostructures in BLG/TMD remain unrealized, with open questions\nregarding device quality, SOC strength, and tunability. In this work, we\ninvestigate quantum point contacts and quantum dots in two BLG/WSe$_2$\nheterostructures with different stacking orders. Across multiple devices, we\ndemonstrate a reproducible enhancement of spin-orbit splitting\n($\\Delta_\\mathrm{SO}$) reaching values of up to $1.5\\mathrm{meV}$ - more than\none order of magnitude higher than in pristine bilayer graphene\n($\\Delta_\\mathrm{SO}=40-80\\mu\\mathrm{eV}$). Furthermore, we show that the\ninduced SOC can be tuned in situ from its maximum value to near-complete\nsuppression by varying the perpendicular electric field, thereby controlling\nlayer polarization. This enhancement and in situ tunability establish SOC as an\nefficient control mechanism for dynamic spin and valley manipulation.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-08T09:44:16Z"}
{"aid":"http://arxiv.org/abs/2504.05871v1","title":"Agent Guide: A Simple Agent Behavioral Watermarking Framework","summary":"The increasing deployment of intelligent agents in digital ecosystems, such\nas social media platforms, has raised significant concerns about traceability\nand accountability, particularly in cybersecurity and digital content\nprotection. Traditional large language model (LLM) watermarking techniques,\nwhich rely on token-level manipulations, are ill-suited for agents due to the\nchallenges of behavior tokenization and information loss during\nbehavior-to-action translation. To address these issues, we propose Agent\nGuide, a novel behavioral watermarking framework that embeds watermarks by\nguiding the agent's high-level decisions (behavior) through probability biases,\nwhile preserving the naturalness of specific executions (action). Our approach\ndecouples agent behavior into two levels, behavior (e.g., choosing to bookmark)\nand action (e.g., bookmarking with specific tags), and applies watermark-guided\nbiases to the behavior probability distribution. We employ a z-statistic-based\nstatistical analysis to detect the watermark, ensuring reliable extraction over\nmultiple rounds. Experiments in a social media scenario with diverse agent\nprofiles demonstrate that Agent Guide achieves effective watermark detection\nwith a low false positive rate. Our framework provides a practical and robust\nsolution for agent watermarking, with applications in identifying malicious\nagents and protecting proprietary agent systems.","main_category":"cs.AI","categories":"cs.AI,K.6.5","published":"2025-04-08T09:54:49Z"}
{"aid":"http://arxiv.org/abs/2504.05874v1","title":"Systematic Parameter Decision in Approximate Model Counting","summary":"This paper proposes a novel approach to determining the internal parameters\nof the hashing-based approximate model counting algorithm $\\mathsf{ApproxMC}$.\nIn this problem, the chosen parameter values must ensure that\n$\\mathsf{ApproxMC}$ is Probably Approximately Correct (PAC), while also making\nit as efficient as possible. The existing approach to this problem relies on\nheuristics; in this paper, we solve this problem by formulating it as an\noptimization problem that arises from generalizing $\\mathsf{ApproxMC}$'s\ncorrectness proof to arbitrary parameter values.\n  Our approach separates the concerns of algorithm soundness and optimality,\nallowing us to address the former without the need for repetitive case-by-case\nargumentation, while establishing a clear framework for the latter.\nFurthermore, after reduction, the resulting optimization problem takes on an\nexceptionally simple form, enabling the use of a basic search algorithm and\nproviding insight into how parameter values affect algorithm performance.\nExperimental results demonstrate that our optimized parameters improve the\nruntime performance of the latest $\\mathsf{ApproxMC}$ by a factor of 1.6 to\n2.4, depending on the error tolerance.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-08T09:58:41Z"}
{"aid":"http://arxiv.org/abs/2504.05877v1","title":"Threshold-less and Flexibly Tunable Frequency Comb via Floquet\n  Engineering","summary":"Frequency combs have revolutionized communication, metrology and\nspectroscopy. Numerous efforts have been dedicated to developing integrated\ncombs, predominantly relying on Pockels or Kerr mechanisms. In this work, we\npropose and demonstrate a new type of frequency comb-Floquet cavity frequency\ncomb-that does not rely on intrinsic non-linearity. By periodically modulating\nthe resonance frequency of a cavity, a giant-mode cavity with multiple equally\nspaced frequency components is created. The pump tone interacts with the\npre-modulated cavity, generating the output frequency comb. This approach\noffers a flexible tuning range and operates in a threshold-less manner,\nobviating the need to overcome nonlinear initiation thresholds. We implement\nthis on a microwave cavity optomechanical system on-chip. Compared to Kerr\noptomechanical combs, this approach efficiently generates comb with pump signal\nfar from the cavity's intrinsic frequency, and the power required for detection\nis reduced by approximately a factor of ($10^6$), providing a promising\nplatform for frequency comb generation.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall,physics.optics","published":"2025-04-08T10:05:20Z"}
{"aid":"http://arxiv.org/abs/2504.05881v1","title":"Actuarial Learning for Pension Fund Mortality Forecasting","summary":"For the assessment of the financial soundness of a pension fund, it is\nnecessary to take into account mortality forecasting so that longevity risk is\nconsistently incorporated into future cash flows. In this article, we employ\nmachine learning models applied to actuarial science ({\\it actuarial learning})\nto make mortality predictions for a relevant sample of pension funds'\nparticipants. Actuarial learning represents an emerging field that involves the\napplication of machine learning (ML) and artificial intelligence (AI)\ntechniques in actuarial science. This encompasses the use of algorithms and\ncomputational models to analyze large sets of actuarial data, such as\nregression trees, random forest, boosting, XGBoost, CatBoost, and neural\nnetworks (eg. FNN, LSTM, and MHA). Our results indicate that some ML/AI\nalgorithms present competitive out-of-sample performance when compared to the\nclassical Lee-Carter model. This may indicate interesting alternatives for\nconsistent liability evaluation and effective pension fund risk management.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-08T10:09:41Z"}
{"aid":"http://arxiv.org/abs/2504.05888v1","title":"UVG-VPC: Voxelized Point Cloud Dataset for Visual Volumetric Video-based\n  Coding","summary":"Point cloud compression has become a crucial factor in immersive visual media\nprocessing and streaming. This paper presents a new open dataset called UVG-VPC\nfor the development, evaluation, and validation of MPEG Visual Volumetric\nVideo-based Coding (V3C) technology. The dataset is distributed under its own\nnon-commercial license. It consists of 12 point cloud test video sequences of\ndiverse characteristics with respect to the motion, RGB texture, 3D geometry,\nand surface occlusion of the points. Each sequence is 10 seconds long and\ncomprises 250 frames captured at 25 frames per second. The sequences are\nvoxelized with a geometry precision of 9 to 12 bits, and the voxel color\nattributes are represented as 8-bit RGB values. The dataset also includes\nassociated normals that make it more suitable for evaluating point cloud\ncompression solutions. The main objective of releasing the UVG-VPC dataset is\nto foster the development of V3C technologies and thereby shape the future in\nthis field.","main_category":"cs.MM","categories":"cs.MM,cs.CV","published":"2025-04-08T10:27:53Z"}
{"aid":"http://arxiv.org/abs/2504.05907v1","title":"A Method for Generating Connected Erdos-Renyi Random Graphs","summary":"We propose a novel and exact algorithm for generating connected Erdos-Renyi\nrandom graphs $G(n, p)$. Our approach exploits a link between the distribution\nof exploration process trajectories and an inhomogeneous random walk. In\ncontrast to existing methods, our approach guarantees the correct distribution\nunder the connectivity condition and achieves $O(n^2)$ runtime in the sparse\ncase $p = c/n$. Furthermore, we show that our method can be extended to\nuniformly generate connected graphs $G(n, m)$ via an acceptance-rejection\nprocedure.","main_category":"cs.DS","categories":"cs.DS,cs.DM,cs.IT,math.CO,math.IT,math.PR","published":"2025-04-08T11:06:01Z"}
{"aid":"http://arxiv.org/abs/2504.05914v1","title":"High-Resource Translation:Turning Abundance into Accessibility","summary":"This paper presents a novel approach to constructing an English-to-Telugu\ntranslation model by leveraging transfer learning techniques and addressing the\nchallenges associated with low-resource languages. Utilizing the Bharat\nParallel Corpus Collection (BPCC) as the primary dataset, the model\nincorporates iterative backtranslation to generate synthetic parallel data,\neffectively augmenting the training dataset and enhancing the model's\ntranslation capabilities. The research focuses on a comprehensive strategy for\nimproving model performance through data augmentation, optimization of training\nparameters, and the effective use of pre-trained models. These methodologies\naim to create a robust translation system that can handle diverse sentence\nstructures and linguistic nuances in both English and Telugu. This work\nhighlights the significance of innovative data handling techniques and the\npotential of transfer learning in overcoming limitations posed by sparse\ndatasets in low-resource languages. The study contributes to the field of\nmachine translation and seeks to improve communication between English and\nTelugu speakers in practical contexts.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T11:09:51Z"}
{"aid":"http://arxiv.org/abs/2504.05915v1","title":"Quantum inverse scattering for time-dependent repulsive Hamiltonians","summary":"We study a multidimensional inverse scattering problem under the\ntime-dependent repulsive Hamiltonian. The time-dependent coefficient on the\nrepulsive term decays as the inverse square of time, which is the threshold\nbetween the standard free Schroedinger operator and the time-independent\nrepulsive Hamiltonian. Applying the Enss-Weder time-dependent method, we can\ndetermine uniquely the short-range potential functions with Coulomb-like\nsingularities from the velocity limit of the scattering operator.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T11:10:04Z"}
{"aid":"http://arxiv.org/abs/2504.05920v1","title":"Local Thermal Non-Equilibrium Models in Porous Media: A Comparative\n  Study of Conduction Effects","summary":"Instantaneous heat transfer between different phases is a common assumption\nfor modeling heat transfer in porous media, known as Local Thermal Equilibrium\n(LTE). This assumption may not hold in certain technical and environmental\napplications, especially in systems with large temperature gradients, large\ndifferences in thermal properties, or high velocities. Local Thermal\nNon-Equilibrium (LTNE) models aim to describe heat transfer processes when the\nLTE assumption may fail. In this work, we compare three continuum-scale models\nfrom the pore to the representative elementary volume (REV) scale.\nSpecifically, dual-network and REV-scale models are evaluated against a\npore-resolved model, which we perceive as a reference in the absence of\nexperimental results. Different effective models are used to obtain upscaled\nproperties on the REV scale and to compare resulting temperature profiles. The\nsystems investigated are fully saturated, consisting of one fluid and one solid\nphase. This study focuses on purely conductive systems without significant\ndifferences in thermal properties. Results show that LTE holds then for low\ninterfacial resistances. However, for large interfacial resistances, solid and\nfluid temperatures differ. The REV-scale model with effective parameters\nobtained by homogenization leads to similar results as the pore-resolved model,\nwhereas the dual-network model shows greater deviation due to its fixed spatial\nresolution. Among the evaluated effective parameter formulations for the\nREV-scale model, only the homogenization-based approach captures the LTNE\nbehavior, as it incorporates the interfacial heat transfer coefficient.\nConvection is relevant for most practical applications, and its impact will be\naddressed in a follow-up article.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-08T11:19:02Z"}
{"aid":"http://arxiv.org/abs/2504.05927v1","title":"A nongraphical obstacle problem for elastic curves","summary":"We study an obstacle problem for the length-penalized elastic bending energy\nfor open planar curves pinned at the boundary. We first consider the case\nwithout length penalization and investigate the role of global minimizers among\ngraph curves in our minimization problem for planar curves. In addition, for\nlarge values of the length-penalization parameter $\\lambda>0$, we expose an\nexplicit threshold parameter above which minimizers touch the obstacle,\nregardless of its shape. On contrary, for small values of $\\lambda>0$ we show\nthat the minimizers do not touch the obstacle, and they are given by an\nexplicit elastica.","main_category":"math.AP","categories":"math.AP,math.DG","published":"2025-04-08T11:33:14Z"}
{"aid":"http://arxiv.org/abs/2504.05929v1","title":"Cohomology and deformations of restricted Lie algebras and their\n  morphisms in positive characteristic","summary":"The main purpose of this paper is to study cohomology and develop a\ndeformation theory of restricted Lie algebras in positive characteristic $p>0$.\nIn the case $p\\geq3$, it is shown that the deformations of restricted Lie\nalgebras are controlled by the restricted cohomology introduced by Evans and\nFuchs. Moreover, we introduce a new cohomology that controls the deformations\nof restricted morphisms of restricted Lie algebras. In the case $p=2$, we\nprovide a full restricted cohomology complex with values in a restricted module\nand investigate its connections with formal deformations. Furthermore, we\nintroduce a full deformation cohomology that controls deformations of\nrestricted morphisms of restricted Lie algebras in characteristic $2$. As\nexample, we discuss restricted cohomology with adjoint coefficients of\nrestricted Heisenberg Lie algebras in characteristic $p\\geq 2$.","main_category":"math.RT","categories":"math.RT","published":"2025-04-08T11:36:31Z"}
{"aid":"http://arxiv.org/abs/2504.05931v1","title":"A stability phenomenon in Kazhdan-Lusztig combinatorics","summary":"We prove that, when $n$ goes to infinity, the expression, with respect to the\ndual Kazhdan-Lusztig basis, of the product\n$\\hat{\\underline{H}}_x\\underline{H}_y$ of elements of the dual and the usual\nKazhdan-Lusztig bases in the Hecke algebra of the symmetric group $S_n$\nstabilizes. As an application, we define the action of projective functors on\nthe principal block of category $\\mathcal{O}$ for $\\mathfrak{sl}_\\infty$ and\nshow that the subcategory of finite length objects is stable under this action.\nAs a bonus, we also prove that this latter block is Koszul, answering, for this\nblock, a question from \\cite{CP}.","main_category":"math.RT","categories":"math.RT","published":"2025-04-08T11:42:32Z"}
{"aid":"http://arxiv.org/abs/2504.05937v1","title":"On the Hamilton-Jacobi approach to inflation beyond slow roll","summary":"The Hamilton-Jacobi approach is a powerful tool to describe super-Hubble\ndynamics during cosmological inflation in a non-linear way. A key assumption of\nthis framework is to neglect anisotropic perturbations on large scales. We show\nthat neglecting the anisotropic sector in the momentum constraint corresponds\nto discarding the non-adiabatic mode of scalar-field perturbations at large\nscales. Consequently, the Hamilton-Jacobi approach cannot be used to describe\nthe evolution of large-scale perturbations during inflation beyond slow roll,\nwhen non-adiabatic fluctuations play an important role on super-Hubble scales\ndue to the absence of an attractor trajectory. As an example, we analyse the\ncase of cosmological perturbations during a phase of ultra-slow-roll inflation.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-08T11:52:44Z"}
{"aid":"http://arxiv.org/abs/2504.05938v1","title":"Umbral oscillations in the photosphere. A comprehensive statistical\n  study","summary":"It is well-known that the global acoustic oscillations of the Sun's\natmosphere can excite resonance modes within large-scale magnetic\nconcentrations. These structures are conduits of energy between the different\nlayers of the solar atmosphere, and understanding their dynamics can explain\nthe processes behind coronal heating and solar wind acceleration. In this work,\nwe studied the Doppler velocity spectrum of more than a thousand large-scale\nmagnetic structures (i.e., sunspots) in the solar photosphere that crossed near\nthe disk centre of the Sun. We exploited the excellent stability and\nseeing-free conditions of the Helioseismic and Magnetic Imager (HMI) instrument\nonboard the Solar Dynamics Observatory (SDO) to cover nearly seven years of\nobservations, providing the most comprehensive statistical analysis of its\nkind. Here, we show that the power spectra of the umbra of sunspots in the\nphotosphere is remarkably different from the one of quiet-Sun regions, with\nboth exhibiting a primary peak at 3.3 mHz, but the sunspot umbrae also\ndisplaying a closely packed series of secondary peaks in the $4-6$~mHz band.\nUnderstanding the origin of such peaks is a challenging task. Here, we explore\nseveral possible explanations for the observed oscillations, all pointing\ntoward a potential resonant interaction within these structures and an unknown\ndriver. Our observational result provides further insight into the magnetic\nconnectivity between the different layers of the dynamic atmosphere of the Sun.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-08T11:53:49Z"}
{"aid":"http://arxiv.org/abs/2504.05940v1","title":"A Lorentz Covariant Matrix Model for Bosonic M2-Branes: Nambu Brackets\n  and Restricted Volume-Preserving Deformations","summary":"We propose a Lorentz covariant matrix model as a nonperturbative formulation\nof the bosonic M2-brane in M-theory. Unlike previous approaches relying on the\nlight-cone gauge or symmetry-based constructions, our model retains full\n11-dimensional Lorentz invariance by introducing a novel gauge-fixing condition\nthat restricts the symmetry of volume-preserving deformations (VPD) to a\nsubclass, which we call restricted VPD (RVPD). This restriction enables a\nconsistent matrix regularization of the Nambu bracket, bypassing the\nlong-standing obstructions related to the Leibniz rule and the Fundamental\nIdentity. The resulting model exhibits RVPD symmetry, admits particle-like and\nnoncommutative membrane solutions, and lays the foundation for a\nLorentz-invariant, nonperturbative matrix description of M2-branes. Our work\noffers a new paradigm for constructing Lorentz-invariant matrix models of\nmembranes, revisiting the algebraic structure underlying M-theory.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-04-08T11:55:46Z"}
{"aid":"http://arxiv.org/abs/2504.05941v1","title":"Self-sustained oscillations in discrete-time relay feedback systems","summary":"We study the problem of determining self-sustained oscillations in\ndiscrete-time linear time-invariant relay feedback systems. Concretely, we are\ninterested in predicting when such a system admits unimodal oscillations, i.e.,\nwhen the output has a single-peaked period. Under the assumption that the\nlinear system is stable and has an impulse response that is strictly\nmonotonically decreasing on its infinite support, we take a novel approach in\nusing the framework of total positivity to address our main question. It is\nshown that unimodal self-oscillations can only exist if the number of positive\nand negative elements in a period coincides. Based on this result, we derive\nconditions for the existence of such oscillations, determine bounds on their\nperiods, and address the question of uniqueness.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY,math.DS","published":"2025-04-08T11:56:40Z"}
{"aid":"http://arxiv.org/abs/2504.05942v1","title":"Higher-order meshless schemes for hyperbolic equations","summary":"We discuss the order, efficiency, stability and positivity of several\nmeshless schemes for linear scalar hyperbolic equations. Meshless schemes are\nGeneralised Finite Difference Methods (GFDMs) for arbitrary irregular grids in\nwhich there is no connectivity between the grid points. We propose a new\nMUSCL-like meshless scheme that uses a central stencil, with which we can\nachieve arbitrarily high orders, and compare it to existing meshless upwind\nschemes and meshless WENO schemes. The stability of the newly proposed scheme\nis guaranteed by an upwind reconstruction to the midpoints of the stencil. The\nnew meshless MUSCL scheme is also efficient due to the reuse of the GFDM\nsolution in the reconstruction. We combine the new MUSCL scheme with a\nMulti-dimensional Optimal Order Detection (MOOD) procedure to avoid spurious\noscillations at discontinuities. In one spatial dimension, our fourth order\nMUSCL scheme outperforms existing WENO and upwind schemes in terms of stability\nand accuracy. In two spatial dimensions, our MUSCL scheme achieves similar\naccuracy to an existing WENO scheme but is significantly more stable.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-08T11:57:01Z"}
{"aid":"http://arxiv.org/abs/2504.05944v1","title":"Laminar chaos in systems with random and chaotically time-varying delay","summary":"A type of chaos called laminar chaos was found in singularly perturbed\ndynamical systems with periodically [Phys. Rev. Lett. 120, 084102 (2018)] and\nquasiperiodically [Phys. Rev. E 107, 014205 (2023)] time-varying delay.\nCompared to high-dimensional turbulent chaos that is typically found in such\nsystems with large constant delay, laminar chaos is a very low-dimensional\nphenomenon. It is characterized by a time series with nearly constant laminar\nphases that are interrupted by irregular bursts, where the intensity level of\nthe laminar phases varies chaotically from phase to phase. In this paper, we\ndemonstrate that laminar chaos, and its generalizations, can also be observed\nin systems with random and chaotically time-varying delay. Moreover, while for\nperiodic and quasiperiodic delays the appearance of (generalized) laminar chaos\nand turbulent chaos depends in a fractal manner on the delay parameters, it\nturns out that short-time correlated random and chaotic delays lead to\n(generalized) laminar chaos in almost the whole delay parameter space, where\nthe properties of circle maps with quenched disorder play a crucial role. It\nfollows that introducing such a delay variation typically leads to a drastic\nreduction of the dimension of the chaotic attractor of the considered systems.\nWe investigate the dynamical properties and generalize the known methods for\ndetecting laminar chaos in experimental time series to random and chaotically\ntime-varying delay.","main_category":"nlin.CD","categories":"nlin.CD","published":"2025-04-08T11:57:49Z"}
{"aid":"http://arxiv.org/abs/2504.05949v1","title":"Sharp fractional Hardy's inequality for half-spaces in the Heisenberg\n  group","summary":"In this work we establish the following fractional Hardy's inequality\n  $$C\\int_{\\mathbb{H}^n_+}\\frac{|f(\\xi)|^p}{x_1^{sp+\\alpha}}d\\xi\\leq\n\\int_{\\mathbb{H}^n}\\int_{\\mathbb{H}^n}\\frac{|f(\\xi)-f(\\xi')|^p}{d({\\xi}^{-1}\\circ\n\\xi')^{Q+sp}|z'-z|^\\alpha}d\\xi'd\\xi,\\ \\ \\forall f\\in\nC_c^{\\infty}(\\mathbb{H}^n_+)$$\n  for the half-space\n$\\{\\xi=(x,y,t)=(x_1,\\ldots,x_n,y_1,\\ldots,y_n)\\in\\mathbb{H}^n:x_1>0\\}$ in the\nHeisenberg group $\\mathbb{H}^n$ without any restriction on parameters, and\ncompute the corresponding sharp constant. In a previous joint work, we\nestablished a variant of Hardy's inequality for the same half-space, but with\ncertain parameter restrictions. However, all integrals in that work were\nconsidered over half-spaces, and here the seminorm is taken over the entire\n$\\mathbb{H}^n$. Although this inequality holds for all values of the quantity\n$sp+\\alpha$, we are only able to compute the corresponding sharp constant when\n$sp+\\alpha>1$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T12:03:40Z"}
{"aid":"http://arxiv.org/abs/2504.05952v1","title":"Contrasting magnetism in VPS3 and CrI3 monolayers with the common\n  honeycomb S = 3/2 spin lattice","summary":"Two-dimensional (2D) magnetic materials are promising candidates for\nspintronics and quantum technologies. One extensively studied example is the\nferromagnetic (FM) CrI$_3$ monolayer with the honeycomb Cr$^{3+}$ ($t_{2g}^3$,\n$S$ = 3/2) spin lattice, while VPS$_3$ has a same honeycomb $S$ = 3/2 spin\nlattice (V$^{2+}$, $t_{2g}^3$) but displays N$\\acute{e}$el antiferromagnetism\n(AFM). In this work, we study the electronic structure and particularly the\ncontrasting magnetism of VPS$_3$ and CrI$_3$ monolayers. We find that VPS$_3$\nis a Mott-Hubbard insulator but CrI$_3$ is a charge-transfer insulator, and\ntherefore their magnetic exchange mechanisms are essentially different. The\nfirst nearest-neighbor (1NN) direct $d$-$d$ exchange dominates in VPS$_3$, thus\nleading to a strong antiferromagnetic (AF) coupling. However, the formation of\nvanadium vacancies, associated with instability of the low-valence V$^{2+}$\nions, suppresses the AF coupling and thus strongly reduces the N$\\acute{e}$el\ntemperature ($T_{\\text{N}}$) in line with the experimental observation. In\ncontrast, our results reveal that the major 1NN $d$-$p$-$d$ superexchanges in\nCrI$_3$ via different channels give rise to competing FM and AF couplings,\nultimately resulting in a weak FM coupling as observed experimentally. After\nrevisiting several important superexchange channels reported in the literature,\nbased on our MLWFs and tight-binding analyses, we note that some antiphase\ncontributions must be subtly and simultaneously considered, and thus we provide\na deeper insight into the FM coupling of CrI$_3$. Moreover, we identify and\ncompare the major contributions to the magnetic anisotropy, i.e., a weak shape\nanisotropy in VPS$_3$ and a relatively strong exchange anisotropy in CrI$_3$.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T12:06:05Z"}
{"aid":"http://arxiv.org/abs/2504.05955v1","title":"Fair Resource Allocation in UAV-based Semantic Communication System with\n  Fluid Antenna","summary":"In this paper, the problem of maximization of the minimum equivalent rate in\na unmanned-aerial-vehicle (UAV)-based multi-user semantic communication system\nis investigated. In the considered model, a multi-antenna UAV employs semantic\nextraction techniques to compress the data ready to be sent to the users, which\nare equipped with fluid antennas. Our aim is to jointly optimize the trajectory\nof the UAV, the transmit beamforming and the semantic compression rate at the\nUAV, as well as the selection of activated ports in fluid antenna system (FAS),\nto maximize the minimum equivalent transmission rate among all user. An\nalternating algorithm is designed to solve the problem. Simulation results\nvalidate the effectiveness of the proposed algorithm.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-08T12:10:55Z"}
{"aid":"http://arxiv.org/abs/2504.05976v1","title":"A Knowledge Base for Arts and Inclusion -- The Dataverse data archival\n  platform as a knowledge base management system enabling multimodal\n  accessibility","summary":"Creating an inclusive art environment requires engaging multiple senses for a\nfully immersive experience. Culture is inherently synesthetic, enriched by all\nsenses within a shared time and space. In an optimal synesthetic setting,\npeople of all abilities can connect meaningfully; when one sense is\ncompromised, other channels can be enhanced to compensate. This is the power of\nmultimodality. Digital technology is increasingly able to capture aspects of\nmultimodality. To document multimodality aspects of cultural practices and\nproducts for the long-term remains a challenge. Many artistic products from the\nperforming arts tend to be multimodal, and are often immersive, so only a\nmultimodal repository can offer a platform for this work. To our knowledge\nthere is no single, comprehensive repository with a knowledge base to serve\narts and disability. By knowledge base, we mean classifications, taxonomies, or\nontologies (in short, knowledge organisation systems). This paper presents\ninnovative ways to develop a knowledge base which capture multimodal features\nof archived representations of cultural assets, but also indicate various forms\nhow to interact with them including machine-readable description. We will\ndemonstrate how back-end and front-end applications, in a combined effort, can\nsupport accessible archiving and data management for complex digital objects\nborn out of artistic practices and make them available for wider audiences.","main_category":"cs.DL","categories":"cs.DL","published":"2025-04-08T12:33:12Z"}
{"aid":"http://arxiv.org/abs/2504.05980v1","title":"Langevin dynamics with generalized time-reversal symmetry","summary":"When analyzing the equilibrium properties of a stochastic process,\nidentifying the parity of the variables under time-reversal is imperative. This\ninitial step is required to assess the presence of detailed balance, and to\ncompute the entropy production rate, which is, otherwise, ambiguously defined.\nIn this work we deal with stochastic processes whose underlying time-reversal\nsymmetry cannot be reduced to the usual parity rules (namely, flip of the\nmomentum sign). We provide a systematic method to build equilibrium Langevin\ndynamics starting from their reversible deterministic counterparts: this\nstrategy can be applied, in particular, to all stable one-dimensional\nHamiltonian dynamics, exploiting the time-reversal symmetry unveiled in the\naction-angle framework. The case of the Lotka-Volterra model is discussed as an\nexample. We also show that other stochastic versions of this system violate\ntime-reversal symmetry and are, therefore, intrinsically out of equilibrium.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-08T12:36:30Z"}
{"aid":"http://arxiv.org/abs/2504.05981v1","title":"Arbitrary polarization retarders and polarization controllers,\n  constructed from sequences of half-wave and quarter-wave plates","summary":"We theoretically introduce several types of arbitrary polarization retarders\nconstructed from sequences of half-wave and quarter-wave plates, each rotated\nat specific angles. By integrating these arbitrary polarization retarders with\narbitrary polarization rotators, we develop a versatile device capable of\nperforming arbitrary-to-arbitrary polarization transformations. While some of\nthe proposed devices are documented in the literature, others are novel and, to\nthe best of our knowledge, have not been previously presented. The continuous\nadjustment of retardance and rotation in these devices is achieved by altering\nthe relative orientation of the wave plates in the sequence.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-08T12:38:10Z"}
{"aid":"http://arxiv.org/abs/2504.05987v1","title":"Learning-enhanced electronic skin for tactile sensing on deformable\n  surface based on electrical impedance tomography","summary":"Electrical Impedance Tomography (EIT)-based tactile sensors offer\ncost-effective and scalable solutions for robotic sensing, especially promising\nfor soft robots. However a major issue of EIT-based tactile sensors when\napplied in highly deformable objects is their performance degradation due to\nsurface deformations. This limitation stems from their inherent sensitivity to\nstrain, which is particularly exacerbated in soft bodies, thus requiring\ndedicated data interpretation to disentangle the parameter being measured and\nthe signal deriving from shape changes. This has largely limited their\npractical implementations. This paper presents a machine learning-assisted\ntactile sensing approach to address this challenge by tracking surface\ndeformations and segregating this contribution in the signal readout during\ntactile sensing. We first capture the deformations of the target object,\nfollowed by tactile reconstruction using a deep learning model specifically\ndesigned to process and fuse EIT data and deformation information. Validations\nusing numerical simulations achieved high correlation coefficients (0.9660 -\n0.9999), peak signal-to-noise ratios (28.7221 - 55.5264 dB) and low relative\nimage errors (0.0107 - 0.0805). Experimental validations, using a\nhydrogel-based EIT e-skin under various deformation scenarios, further\ndemonstrated the effectiveness of the proposed approach in real-world settings.\nThe findings could underpin enhanced tactile interaction in soft and highly\ndeformable robotic applications.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T12:49:54Z"}
{"aid":"http://arxiv.org/abs/2504.05990v1","title":"AI analysis of medical images at scale as a health disparities probe: a\n  feasibility demonstration using chest radiographs","summary":"Health disparities (differences in non-genetic conditions that influence\nhealth) can be associated with differences in burden of disease by groups\nwithin a population. Social determinants of health (SDOH) are domains such as\nhealth care access, dietary access, and economics frequently studied for\npotential association with health disparities. Evaluating SDOH-related\nphenotypes using routine medical images as data sources may enhance health\ndisparities research. We developed a pipeline for using quantitative measures\nautomatically extracted from medical images as inputs into health disparities\nindex calculations. Our study focused on the use case of two SDOH demographic\ncorrelates (sex and race) and data extracted from chest radiographs of 1,571\nunique patients. The likelihood of severe disease within the lung parenchyma\nfrom each image type, measured using an established deep learning model, was\nmerged into a single numerical image-based phenotype for each patient. Patients\nwere then separated into phenogroups by unsupervised clustering of the\nimage-based phenotypes. The health rate for each phenogroup was defined as the\nmedian image-based phenotype for each SDOH used as inputs to four\nimaging-derived health disparities indices (iHDIs): one absolute measure\n(between-group variance) and three relative measures (index of disparity, Theil\nindex, and mean log deviation). The iHDI measures demonstrated feasible values\nfor each SDOH demographic correlate, showing potential for medical images to\nserve as a novel probe for health disparities. Large-scale AI analysis of\nmedical images can serve as a probe for a novel data source for health\ndisparities research.","main_category":"physics.med-ph","categories":"physics.med-ph,cs.CV","published":"2025-04-08T12:53:14Z"}
{"aid":"http://arxiv.org/abs/2504.05993v1","title":"Strong Evidence That Abiogenesis Is a Rapid Process on Earth Analogs","summary":"The early start to life naively suggests that abiogenesis is a rapid process\non Earth-like planets. However, if evolution typically takes ~4Gyr to produce\nintelligent life-forms like us, then the limited lifespan of Earth's biosphere\n(~5-6Gyr) necessitates an early (and possibly highly atypical) start to our\nemergence - an example of the weak anthropic principle. Our previously proposed\nobjective Bayesian analysis of Earth's chronology culminated in a formula for\nthe minimum odds ratio between the fast and slow abiogenesis scenarios\n(relative to Earth's lifespan). Timing from microfossils (3.7Gya) yields 3:1\nodds in favor of rapid abiogenesis, whereas evidence from carbon isotopes\n(4.1Gya) gives 9:1, both below the canonical threshold of \"strong evidence\"\n(10:1). However, the recent result of a 4.2Gya LUCA pushes the odds over the\nthreshold for the first time (nominally 13:1). In fact, the odds ratio is >10:1\nfor all possible values of the biosphere's ultimate lifespan and speculative\nhypotheses of ancient civilizations. For the first time, we have formally\nstrong evidence that favors the hypothesis that life rapidly emerges in\nEarth-like conditions (although such environments may themselves be rare).","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-08T12:55:50Z"}
{"aid":"http://arxiv.org/abs/2504.05998v1","title":"Can gravity mediate the transmission of quantum information?","summary":"We propose an experiment to test the non-classicality of the gravitational\ninteraction. We consider two optomechanical systems that are perfectly\nisolated, except for a weak gravitational coupling. If a suitable resonance\ncondition is satisfied, an optical signal can be transmitted from one system to\nthe other over a narrow frequency band, a phenomenon that we call\ngravitationally induced transparency. In this framework, the challenging\nproblem of testing the quantum nature of gravity is mapped to the easier task\nof determining the non-classicality of the gravitationally-induced optical\nchannel: If the optical channel is not entanglement-breaking, then gravity must\nhave a quantum nature. This approach is applicable without making any\nassumption on the, currently unknown, correct model of gravity in the quantum\nregime. In the second part of this work, we model gravity as a quadratic\nHamiltonian interaction (e.g. a weak Newtonian force), resulting in a Gaussian\nthermal attenuator channel between the two systems. Depending on the strength\nof thermal noise, the system presents a sharp transition from an\nentanglement-breaking to a non-classical channel capable not only of\nentanglement preservation but also of asymptotically perfect quantum\ncommunication.","main_category":"quant-ph","categories":"quant-ph,gr-qc","published":"2025-04-08T13:03:58Z"}
{"aid":"http://arxiv.org/abs/2504.06003v1","title":"econSG: Efficient and Multi-view Consistent Open-Vocabulary 3D Semantic\n  Gaussians","summary":"The primary focus of most recent works on open-vocabulary neural fields is\nextracting precise semantic features from the VLMs and then consolidating them\nefficiently into a multi-view consistent 3D neural fields representation.\nHowever, most existing works over-trusted SAM to regularize image-level CLIP\nwithout any further refinement. Moreover, several existing works improved\nefficiency by dimensionality reduction of semantic features from 2D VLMs before\nfusing with 3DGS semantic fields, which inevitably leads to multi-view\ninconsistency. In this work, we propose econSG for open-vocabulary semantic\nsegmentation with 3DGS. Our econSG consists of: 1) A Confidence-region Guided\nRegularization (CRR) that mutually refines SAM and CLIP to get the best of both\nworlds for precise semantic features with complete and precise boundaries. 2) A\nlow dimensional contextual space to enforce 3D multi-view consistency while\nimproving computational efficiency by fusing backprojected multi-view 2D\nfeatures and follow by dimensional reduction directly on the fused 3D features\ninstead of operating on each 2D view separately. Our econSG shows\nstate-of-the-art performance on four benchmark datasets compared to the\nexisting methods. Furthermore, we are also the most efficient training among\nall the methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T13:12:31Z"}
{"aid":"http://arxiv.org/abs/2504.06008v1","title":"Impact of newly measured $Î²$\\nobreakdash-delayed neutron emitters\n  around \\myisoSimp{78}{Ni} on light element nucleosynthesis in the\n  neutrino-wind following a neutron star merger","summary":"Neutron emission probabilities and half-lives of 37 beta-delayed neutron\nemitters from 75Ni to 92Br were measured at the RIKEN Nishina Center in Japan,\nincluding 11 one-neutron and 13 two-neutron emission probabilities and 6\nhalf-lives measured for the first time, which supersede theoretical estimates.\nThese nuclei lie in the path of the weak r-process occurring in neutrino-driven\nwinds from the accretion disk formed after the merger of two neutron stars,\nsynthesizing elements in the A~80 abundance peak. The presence of such elements\ndominates the accompanying kilonova emission over the first few days and has\nbeen identified in the AT2017gfo event, associated with the gravitational wave\ndetection GW170817.\n  Abundance calculations based on over 17000 simulated trajectories describing\nthe evolution of matter properties in the merger outflows show that the new\ndata lead to an increase of 50-70 percent in the abundance of Y, Zr, Nb, and\nMo. This enhancement is large compared to the scatter of relative abundances\nobserved in old very metal-poor stars and is therefore significant in the\ncomparison with other possible astrophysical processes contributing to\nlight-element production.\n  These results underline the importance of including experimental decay data\nfor very neutron-rich beta-delayed neutron emitters into r-process models.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-04-08T13:16:41Z"}
{"aid":"http://arxiv.org/abs/2504.06015v1","title":"Robust Statistics vs. Machine Learning vs. Bayesian Inference: Insights\n  into Handling Faulty GNSS Measurements in Field Robotics","summary":"This paper presents research findings on handling faulty measurements (i.e.,\noutliers) of global navigation satellite systems (GNSS) for robot localization\nunder adverse signal conditions in field applications, where raw GNSS data are\nfrequently corrupted due to environmental interference such as multipath,\nsignal blockage, or non-line-of-sight conditions. In this context, we\ninvestigate three strategies applied specifically to GNSS pseudorange\nobservations: robust statistics for error mitigation, machine learning for\nfaulty measurement prediction, and Bayesian inference for noise distribution\napproximation. Since previous studies have provided limited insight into the\ntheoretical foundations and practical evaluations of these three methodologies\nwithin a unified problem statement (i.e., state estimation using ranging\nsensors), we conduct extensive experiments using real-world sensor data\ncollected in diverse urban environments. Our goal is to examine both\nestablished techniques and newly proposed methods, thereby advancing the\nunderstanding of how to handle faulty range measurements, such as GNSS, for\nrobust, long-term robot localization. In addition to presenting successful\nresults, this work highlights critical observations and open questions to\nmotivate future research in robust state estimation.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T13:21:04Z"}
{"aid":"http://arxiv.org/abs/2504.06021v1","title":"Memory-Modular Classification: Learning to Generalize with Memory\n  Replacement","summary":"We propose a novel memory-modular learner for image classification that\nseparates knowledge memorization from reasoning. Our model enables effective\ngeneralization to new classes by simply replacing the memory contents, without\nthe need for model retraining. Unlike traditional models that encode both world\nknowledge and task-specific skills into their weights during training, our\nmodel stores knowledge in the external memory of web-crawled image and text\ndata. At inference time, the model dynamically selects relevant content from\nthe memory based on the input image, allowing it to adapt to arbitrary classes\nby simply replacing the memory contents. The key differentiator that our\nlearner meta-learns to perform classification tasks with noisy web data from\nunseen classes, resulting in robust performance across various classification\nscenarios. Experimental results demonstrate the promising performance and\nversatility of our approach in handling diverse classification tasks, including\nzero-shot/few-shot classification of unseen classes, fine-grained\nclassification, and class-incremental classification.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T13:26:24Z"}
{"aid":"http://arxiv.org/abs/2504.06029v1","title":"Red giant component of the recurrent nova T Coronae Borealis","summary":"We performed simultaneous V band photometry and spectroscopic observations of\nthe recurrent nova T CrB and estimate the V band magnitude of the red giant. We\nfind for the red giant of T CrB apparent and absolute V-band magnitudes m_V =\n10.17 +/- 0.06 and M_V = +0.14 +/- 0.08, respectively. At the maximum of the\nellipsoidal variation when these values are obtained, its absolute V-band\nmagnitude is similar but fainter than the typical M4/5III giants. The data are\navailable on : zenodo.org/records/15174720","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-08T13:34:05Z"}
{"aid":"http://arxiv.org/abs/2504.06034v1","title":"Distance to M87 as the Mode of the Modulus Distribution","summary":"de Grijs and Bono (ApJS 2020, 246, 3) compiled a list of distances to M87\nfrom the literature published in the last 100 years. They reported the\narithmetic mean of the three most stable tracers (Cepheids, tip of the red\ngiant branch, and surface brightness fluctuations). The arithmetic mean is one\nof the measures of central tendency of a distribution; others are the median\nand mode. The three do not align for asymmetric distributions, which is the\ncase for the distance moduli $\\mu_0$ to M87. I construct a kernel density\ndistribution of the set of $\\mu_0$ and estimate the recommended distance to M87\nas its mode, obtaining $\\mu_0 =\n\\left(31.06~\\pm~0.001\\,\\textrm{(statistical)}\\,^{+0.04}_{-0.06}\\,\\textrm{(systematic)}\\right)$~mag,\ncorresponding to \\linebreak $D=16.29^{+0.30}_{-0.45}$~Mpc, which yields\nuncertainties smaller than those associated with the mean and median.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-08T13:35:55Z"}
{"aid":"http://arxiv.org/abs/2504.06037v1","title":"Confidence Regularized Masked Language Modeling using Text Length","summary":"Masked language modeling, which is a task to predict a randomly masked word\nin the input text, is an efficient language representation learning method.\nMasked language modeling ignores various words which people can think of for\nfilling in the masked position and calculates the loss with a single word.\nEspecially when the input text is short, the entropy of the word distribution\nthat can fill in the masked position can be high. This may cause the model to\nbe overconfident in the single answer. To address this issue, we propose a\nnovel confidence regularizer that controls regularizing strength dynamically by\nthe input text length. Experiments with GLUE and SQuAD datasets showed that our\nmethod achieves better accuracy and lower expected calibration error.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-08T13:37:08Z"}
{"aid":"http://arxiv.org/abs/2504.06043v1","title":"Hadronic molecules and multiquark states","summary":"In this text different theoretical approaches towards multi-quark states are\nintroduced, namely hadrocharmonia, compact tetraquarks and hadronic molecules.\nThe predictions derived from either of them are contrasted with current and\npossible future observations. The focus is on doubly heavy systems, but singly\nheavy and light systems are mentioned briefly as well.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-08T13:43:17Z"}
{"aid":"http://arxiv.org/abs/2504.06058v1","title":"Symbol Frequencies in Surjective Cellular Automata","summary":"We study the behavior of probability measures under iteration of a surjective\ncellular automaton. We solve the following question in the negative: if the\ninitial measure is ergodic and has full support, do all weak-* limit points of\nthe sequence of measures have full support as well? The initial measure of our\nsolution is not a product measure, and in this case the question remains open.\nTo this end, we present a tool for studying the frequencies of symbols in\npreimages of surjective cellular automata, and prove some basic results about\nit. % do we know they are nontrivial? :P However, we show that by itself it is\nnot enough to solve the stricter question in the positive.","main_category":"math.DS","categories":"math.DS","published":"2025-04-08T14:01:13Z"}
{"aid":"http://arxiv.org/abs/2504.06060v1","title":"Fast summation of fermionic Feynman diagrams beyond Bravais Lattices and\n  on-site Hubbard interactions","summary":"We designed new algorithms for summing bold-line Feynman diagrams in\narbitrary channels, where it can be readily modified for bare interaction\nseries as well. When applied to magnetic channel bold-line series with on-site\nHubbard interactions, the algorithm achieves competitive performance compared\nwith the state-of-art RPADet. We then generalize it beyond square lattice and\non-site Hubbard interactions and achieve better scaling in the number of sites\nwithin a unit cell, while there is substantial increase when there are more\ntypes of interactions. This work paves the way of diagrammatic Monte Carlo\nsimulations for real materials, holding the premise for a robust replacement of\nstate-of-art simulation tools in the thermodynamical limit.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-08T14:04:46Z"}
{"aid":"http://arxiv.org/abs/2504.06066v1","title":"The Quantum Double of Hopf Algebras Realized via Partial Dualization and\n  the Tensor Category of Its Representations","summary":"In this paper, we aim to study the (generalized) quantum double\n$K^{\\ast\\mathrm{cop}}\\bowtie_\\sigma H$ determined by a (skew) pairing between\nfinite-dimensional Hopf algebras $K^{\\ast\\mathrm{cop}}$ and $H$, especially the\ntensor category $\\mathsf{Rep}(K^{\\ast\\mathrm{cop}}\\bowtie_\\sigma H)$ of its\nfinite-dimensional representations. Specifically, we show that\n$K^{\\ast\\mathrm{cop}}\\bowtie_\\sigma H$ is a left partially dualized\n(quasi-)Hopf algebra of $K^\\mathrm{op}\\otimes H$, and use this formulation to\nestablish tensor equivalences from\n$\\mathsf{Rep}(K^{\\ast\\mathrm{cop}}\\bowtie_\\sigma H)$ to the categories\n${}^K_K\\mathcal{M}^K_H$ and ${}^{K^\\ast}_{K^\\ast}\\mathcal{M}^{H^\\ast}_{K^\\ast}$\nof two-sided two-cosided relative Hopf modules, as well as the category\n${}_H\\mathfrak{YD}^K$ of relative Yetter-Drinfeld modules.","main_category":"math.QA","categories":"math.QA,math.CT,math.RA","published":"2025-04-08T14:09:17Z"}
{"aid":"http://arxiv.org/abs/2504.06071v1","title":"On Onsager-type conjecture for the ElsÃ¤sser energies of the ideal\n  MHD equations","summary":"In this paper, we investigate the ideal magnetohydrodynamics (MHD) equations\non tours $\\TTT^d$. For $d=3$, we resolve the flexible part of Onsager-type\nconjecture for Els\\\"{a}sser energies of the ideal MHD equations. More\nprecisely, for \\(\\beta < 1/3\\), we construct weak solutions \\((u, b) \\in\nC^\\beta([0,T] \\times \\mathbb{T}^3)\\) with both the total energy dissipation and\nfailure of cross helicity conservation. The key idea of the proof relies on a\nsymmetry reduction that embeds the ideal MHD system into a 2$\\frac{1}{2}$D\nEuler flow and the Newton-Nash iteration technique recently developed in\n\\cite{GR}. For $d=2$, we show the non-uniqueness of H\\\"{o}lder-continuous weak\nsolutions with non-trivial magnetic fields. Specifically, for \\(\\beta < 1/5\\),\nthere exist infinitely many solutions \\((u, b) \\in C^\\beta([0,T] \\times\n\\mathbb{T}^2)\\) with the same initial data while satisfying the total energy\ndissipation with non-vanishing velocity and magnetic fields. The new ingredient\nis developing a spatial-separation-driven iterative scheme that incorporates\nthe magnetic field as a controlled perturbation within the convex integration\nframework for the velocity field, thereby providing sufficient oscillatory\nfreedom for Nash-type perturbations in the 2D setting. As a byproduct, we prove\nthat any H\\\"{o}lder-continuous Euler solution can be approximated by a sequence\nof $C^\\beta$-weak solutions for the ideal MHD equations in the $L^p$-topology\nfor $1\\le p<\\infty$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T14:11:11Z"}
{"aid":"http://arxiv.org/abs/2504.06080v1","title":"Two-Loop Renormalization of a Chiral $SU(2)$ Gauge Theory in Dimensional\n  Regularization with Non-Anticommuting $Î³_5$","summary":"Higher order calculations in chiral gauge theories such as the Electroweak\nStandard Model require a sound treatment of the notoriously problematic\n$\\gamma_5$-matrix in Dimensional Regularization (DReg). In the all-order\nconsistent BMHV scheme anticommutativity has to be sacrificed, resulting in\nspurious breakings of BRST invariance, the restoration of which necessitates\nfinite, symmetry-restoring counterterms. Following recent advances in\nsuccessfully applying this scheme to multi-loop calculations for Abelian\nmodels, we shall here present the first complete non-Abelian two-loop result\nfor the case of $SU(2)$, which is of particular interest to the Standard Model.\nWe provide the complete list of finite, two-loop symmetry restoring\ncounterterms and discuss intricacies of the non-Abelian implementation. Except\nfor one novel term, the finite counterterm action exhibits the same structure\nas at one-loop order.","main_category":"hep-ph","categories":"hep-ph,hep-th","published":"2025-04-08T14:20:22Z"}
{"aid":"http://arxiv.org/abs/2504.06085v1","title":"Contact embeddings of 3-dimensional contact groups","summary":"A 3-dimensional contact group is a 3-dimensional Lie group endowed with a\nleft-invariant contact structure. Making use of techniques from Riemannian\ngeometry, we prove that any simply connected 3-dimensional contact group not\nisomorphic to SU(2) satisfies a unique factorization property. As an\napplication, we develop a method to construct embeddings of 3-dimensional\nsimply connected contact groups into one among two model tight contact\nmanifolds.","main_category":"math.SG","categories":"math.SG,math.DG","published":"2025-04-08T14:25:46Z"}
{"aid":"http://arxiv.org/abs/2504.06090v1","title":"Low-Complexity SDP-ADMM for Physical-Layer Multicasting in Massive MIMO\n  Systems","summary":"There is a demand for the same data content from several user equipments\n(UEs) in many wireless communication applications. Physical-layer multicasting\ncombines the beamforming capability of massive MIMO (multiple-input\nmultiple-output) and the broadcast nature of the wireless channel to\nefficiently deliver the same data to a group of UEs using a single\ntransmission. This paper tackles the max-min fair (MMF) multicast beamforming\noptimization, which is an NP-hard problem. We develop an efficient semidefinite\nprogram-alternating direction method of multipliers (SDP-ADMM) algorithm to\nfind the near-global optimal rank-1 solution to the MMF multicast problem in a\nmassive MIMO system. Numerical results show that the proposed SDP-ADMM\nalgorithm exhibits similar spectral efficiency performance to state-of-the-art\nalgorithms running on standard SDP solvers at a vastly reduced computational\ncomplexity. We highlight that the proposed ADMM elimination procedure can be\nemployed as an effective low-complexity rank reduction method for other\nproblems utilizing semidefinite relaxation.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-08T14:30:44Z"}
{"aid":"http://arxiv.org/abs/2504.06093v1","title":"Coupling approaches with non-matching grids for classical linear\n  elasticity and bond-based peridynamic models in 1D","summary":"Local-nonlocal coupling approaches provide a means to combine the\ncomputational efficiency of local models and the accuracy of nonlocal models.\nTo facilitate the coupling of the two models, non-matching grids are often\ndesirable as nonlocal grids usually require a finer resolution than local\ngrids. In that case, it is often convenient to resort to interpolation\noperators so that models can exchange information in the overlap regions when\nnodes from the two grids do not coincide. This paper studies three existing\ncoupling approaches, namely 1) a method that enforces matching displacements in\nan overlap region, 2) a variant that enforces a constraint on the stresses\ninstead, and 3) a method that considers a variable horizon in the vicinity of\nthe interfaces. The effect of the interpolation order and of the grid ratio on\nthe performance of the three coupling methods with non-matching grids is\ncarefully studied on one-dimensional examples using polynomial manufactured\nsolutions. The numerical results show that the degree of the interpolants\nshould be chosen with care to avoid introducing additional modeling errors, or\nsimply minimize these errors, in the coupling approach.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-08T14:35:06Z"}
{"aid":"http://arxiv.org/abs/2504.06095v1","title":"Nonuniform-Tensor-Parallelism: Mitigating GPU failure impact for\n  Scaled-up LLM Training","summary":"LLM training is scaled up to 10Ks of GPUs by a mix of data-(DP) and\nmodel-parallel (MP) execution. Critical to achieving efficiency is\ntensor-parallel (TP; a form of MP) execution within tightly-coupled subsets of\nGPUs, referred to as a scale-up domain, and the larger the scale-up domain the\nbetter the performance. New datacenter architectures are emerging with more\nGPUs able to be tightly-coupled in a scale-up domain, such as moving from 8\nGPUs to 72 GPUs connected via NVLink. Unfortunately, larger scale-up domains\nincrease the blast-radius of failures, with a failure of single GPU potentially\nimpacting TP execution on the full scale-up domain, which can degrade overall\nLLM training throughput dramatically. With as few as 0.1% of GPUs being in a\nfailed state, a high TP-degree job can experience nearly 10% reduction in LLM\ntraining throughput. We propose nonuniform-tensor-parallelism (NTP) to mitigate\nthis amplified impact of GPU failures. In NTP, a DP replica that experiences\nGPU failures operates at a reduced TP degree, contributing throughput equal to\nthe percentage of still-functional GPUs. We also propose a rack-design with\nimproved electrical and thermal capabilities in order to sustain power-boosting\nof scale-up domains that have experienced failures; combined with NTP, this can\nallow the DP replica with the reduced TP degree (i.e., with failed GPUs) to\nkeep up with the others, thereby achieving near-zero throughput loss for\nlarge-scale LLM training.","main_category":"cs.DC","categories":"cs.DC,cs.LG","published":"2025-04-08T14:35:40Z"}
{"aid":"http://arxiv.org/abs/2504.06100v1","title":"Timescales for thermalization, quantum chaos, and self-averaging","summary":"This chapter discusses the conditions and timescales under which isolated\nmany-body quantum systems, initially far from equilibrium, ultimately reach\nthermal equilibrium. We also examine quantities that, during the relaxation\nprocess, exhibit dynamical manifestations of spectral correlations as in random\nmatrix theory and investigate how these manifestations affect their\nequilibration times. We refer to systems presenting these spectral correlations\nas chaotic quantum systems, although the correct term to be employed, whether\nchaotic or ergodic quantum systems, is debatable and both have limitations.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-08T14:44:37Z"}
{"aid":"http://arxiv.org/abs/2504.06105v1","title":"Uncertainty-Aware Hybrid Machine Learning in Virtual Sensors for Vehicle\n  Sideslip Angle Estimation","summary":"Precise vehicle state estimation is crucial for safe and reliable autonomous\ndriving. The number of measurable states and their precision offered by the\nonboard vehicle sensor system are often constrained by cost. For instance,\nmeasuring critical quantities such as the Vehicle Sideslip Angle (VSA) poses\nsignificant commercial challenges using current optical sensors. This paper\naddresses these limitations by focusing on the development of high-performance\nvirtual sensors to enhance vehicle state estimation for active safety. The\nproposed Uncertainty-Aware Hybrid Learning (UAHL) architecture integrates a\nmachine learning model with vehicle motion models to estimate VSA directly from\nonboard sensor data. A key aspect of the UAHL architecture is its focus on\nuncertainty quantification for individual model estimates and hybrid fusion.\nThese mechanisms enable the dynamic weighting of uncertainty-aware predictions\nfrom machine learning and vehicle motion models to produce accurate and\nreliable hybrid VSA estimates. This work also presents a novel dataset named\nReal-world Vehicle State Estimation Dataset (ReV-StED), comprising synchronized\nmeasurements from advanced vehicle dynamic sensors. The experimental results\ndemonstrate the superior performance of the proposed method for VSA estimation,\nhighlighting UAHL as a promising architecture for advancing virtual sensors and\nenhancing active safety in autonomous vehicles.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.LG","published":"2025-04-08T14:49:58Z"}
{"aid":"http://arxiv.org/abs/2504.06117v1","title":"Some Analytical Properties of Multivariate Fractal Functions in Lebesgue\n  Spaces","summary":"In this article, we focus on the construction of multivariate fractal\nfunctions in Lebesgue spaces along with some properties of associated fractal\noperator. First, we give a detailed construction of the fractal functions\nbelonging to Lebesgue spaces. Then, we give analytical properties of the\ndefined fractal operator in Lebesgue spaces. We end this article by showing the\nexistence of Schauder basis of the associated fractal functions for the space\n$\\mathcal{L}^q(I^n, \\mu_p)$.","main_category":"math.FA","categories":"math.FA","published":"2025-04-08T15:10:39Z"}
{"aid":"http://arxiv.org/abs/2504.06120v1","title":"Hyperbolic Category Discovery","summary":"Generalized Category Discovery (GCD) is an intriguing open-world problem that\nhas garnered increasing attention. Given a dataset that includes both labelled\nand unlabelled images, GCD aims to categorize all images in the unlabelled\nsubset, regardless of whether they belong to known or unknown classes. In GCD,\nthe common practice typically involves applying a spherical projection operator\nat the end of the self-supervised pretrained backbone, operating within\nEuclidean or spherical space. However, both of these spaces have been shown to\nbe suboptimal for encoding samples that possesses hierarchical structures. In\ncontrast, hyperbolic space exhibits exponential volume growth relative to\nradius, making it inherently strong at capturing the hierarchical structure of\nsamples from both seen and unseen categories. Therefore, we propose to tackle\nthe category discovery challenge in the hyperbolic space. We introduce HypCD, a\nsimple \\underline{Hyp}erbolic framework for learning hierarchy-aware\nrepresentations and classifiers for generalized \\underline{C}ategory\n\\underline{D}iscovery. HypCD first transforms the Euclidean embedding space of\nthe backbone network into hyperbolic space, facilitating subsequent\nrepresentation and classification learning by considering both hyperbolic\ndistance and the angle between samples. This approach is particularly helpful\nfor knowledge transfer from known to unknown categories in GCD. We thoroughly\nevaluate HypCD on public GCD benchmarks, by applying it to various baseline and\nstate-of-the-art methods, consistently achieving significant improvements.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T15:12:33Z"}
{"aid":"http://arxiv.org/abs/2504.06131v1","title":"FaceCloak: Learning to Protect Face Templates","summary":"Generative models can reconstruct face images from encoded representations\n(templates) bearing remarkable likeness to the original face raising security\nand privacy concerns. We present FaceCloak, a neural network framework that\nprotects face templates by generating smart, renewable binary cloaks. Our\nmethod proactively thwarts inversion attacks by cloaking face templates with\nunique disruptors synthesized from a single face template on the fly while\nprovably retaining biometric utility and unlinkability. Our cloaked templates\ncan suppress sensitive attributes while generalizing to novel feature\nextraction schemes and outperforms leading baselines in terms of biometric\nmatching and resiliency to reconstruction attacks. FaceCloak-based matching is\nextremely fast (inference time cost=0.28ms) and light-weight (0.57MB).","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T15:23:21Z"}
{"aid":"http://arxiv.org/abs/2504.06146v1","title":"Symmetry breaking in chaotic many-body quantum systems at finite\n  temperature","summary":"Recent work has shown that the entanglement of finite-temperature eigenstates\nin chaotic quantum many-body local Hamiltonians can be accurately described by\nan ensemble of random states with an internal $U(1)$ symmetry. We build upon\nthis result to investigate the universal symmetry-breaking properties of such\neigenstates. As a probe of symmetry breaking, we employ the entanglement\nasymmetry, a quantum information observable that quantifies the extent to which\nsymmetry is broken in a subsystem. This measure enables us to explore the finer\nstructure of finite-temperature eigenstates in terms of the $U(1)$-symmetric\nrandom state ensemble; in particular, the relation between the Hamiltonian and\nthe effective conserved charge in the ensemble. Our analysis is supported by\nanalytical calculations for the symmetric random states, as well as exact\nnumerical results for the Mixed-Field Ising spin-$1/2$ chain, a paradigmatic\nmodel of quantum chaoticity.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-08T15:41:54Z"}
{"aid":"http://arxiv.org/abs/2504.06147v1","title":"Noncommutative resolutions and CICY quotients from a non-abelian GLSM","summary":"We discuss a one-parameter non-abelian GLSM with gauge group $(U(1)\\times\nU(1)\\times U(1))\\rtimes\\mathbb{Z}_3$ and its associated Calabi-Yau phases. The\nlarge volume phase is a free $\\mathbb{Z}_3$-quotient of a codimension $3$\ncomplete intersection of degree-$(1,1,1)$ hypersurfaces in\n$\\mathbb{P}^2\\times\\mathbb{P}^2\\times\\mathbb{P}^2$. The associated Calabi-Yau\ndifferential operator has a second point of maximal unipotent monodromy,\nleading to the expectation that the other GLSM phase is geometric as well.\nHowever, the associated GLSM phase appears to be a hybrid model with continuous\nunbroken gauge symmetry and cubic superpotential, together with a Coulomb\nbranch. Using techniques from topological string theory and mirror symmetry we\ncollect evidence that the phase should correspond to a non-commutative\nresolution, in the sense of Katz-Klemm-Schimannek-Sharpe, of a codimension two\ncomplete intersection in weighted projective space with $63$ nodal points, for\nwhich a resolution has $\\mathbb{Z}_3$-torsion. We compute the associated\nGopakumar-Vafa invariants up to genus $11$, incorporating their torsion\nrefinement. We identify two integral symplectic bases constructed from\ntopological data of the mirror geometries in either phase.","main_category":"hep-th","categories":"hep-th","published":"2025-04-08T15:42:39Z"}
{"aid":"http://arxiv.org/abs/2504.06149v1","title":"An asymptotic preserving scheme for the M1model of non-local thermal\n  transport for two-dimensional structured and unstructured meshes","summary":"The M1 moment model for electronic transport is commonly used to describe\nnon-local thermal transport effects in laser-plasma simulations. In this\narticle, we propose a new asymptotic-preserving scheme based on the Unified Gas\nKinetic Scheme (UGKS) for this model in two-dimensional space. This finite\nvolume kinetic scheme follows the same approach as in our previous article and\nrelies on a moment closure, at the numerical scale, of the microscopic flux of\nUGKS. The method is developed for both structured and unstructured meshes, and\nseveral techniques are introduced to ensure accurate fluxes in the diffusion\nlimit. A second-order extension is also proposed. Several test cases validate\nthe different aspects of the scheme and demonstrate its efficiency in\nmultiscale simulations. In particular, the results demonstrate that this method\naccurately captures non-local thermal effects.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-08T15:46:14Z"}
{"aid":"http://arxiv.org/abs/2504.06150v1","title":"Direct measurement of broken time-reversal symmetry in centrosymmetric\n  and non-centrosymmetric atomically thin crystals with nonlinear Kerr rotation","summary":"Time-reversal symmetry, together with space-inversion symmetry, is one of the\ndefining properties of crystals, underlying phenomena such as magnetism,\ntopology and non-trivial spin textures. Transition metal dichalcogenides (TMDs)\nprovide an excellent tunable model system to study the interplay between\ntime-reversal and space-inversion symmetry, since both can be engineered on\ndemand by tuning the number of layers and via all-optical bandgap modulation.\nIn this work, we modulate and study time-reversal symmetry using third harmonic\nKerr rotation in mono- and bilayer TMDs. By illuminating the samples with\nelliptically polarized light, we achieve spin-selective bandgap modulation and\nconsequent breaking of time-reversal symmetry. The reduced symmetry modifies\nthe nonlinear susceptibility tensor, causing a rotation of the emitted third\nharmonic polarization. With this method, we are able to probe broken\ntime-reversal symmetry in both non-centrosymmetric (monolayer) and\ncentrosymmetric (bilayer) crystals. Furthermore, we discuss how the detected\nthird harmonic rotation angle directly links to the spin-valley locking in\nmonolayer TMDs and to the spin-valley-layer locking in bilayer TMDs. Thus, our\nresults define a powerful approach to study broken time-reversal symmetry in\ncrystals regardless of space-inversion symmetry, and shed light on the spin,\nvalley and layer coupling of atomically thin semiconductors.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-08T15:46:24Z"}
{"aid":"http://arxiv.org/abs/2504.06153v1","title":"A Large-Scale Analysis on Contextual Self-Supervised Video\n  Representation Learning","summary":"Self-supervised learning has emerged as a powerful paradigm for label-free\nmodel pretraining, particularly in the video domain, where manual annotation is\ncostly and time-intensive. However, existing self-supervised approaches employ\ndiverse experimental setups, making direct comparisons challenging due to the\nabsence of a standardized benchmark. In this work, we establish a unified\nbenchmark that enables fair comparisons across different methods. Additionally,\nwe systematically investigate five critical aspects of self-supervised learning\nin videos: (1) dataset size, (2) model complexity, (3) data distribution, (4)\ndata noise, and (5) feature representations. To facilitate this study, we\nevaluate six self-supervised learning methods across six network architectures,\nconducting extensive experiments on five benchmark datasets and assessing\nperformance on two distinct downstream tasks. Our analysis reveals key insights\ninto the interplay between pretraining strategies, dataset characteristics,\npretext tasks, and model architectures. Furthermore, we extend these findings\nto Video Foundation Models (ViFMs), demonstrating their relevance in\nlarge-scale video representation learning. Finally, leveraging these insights,\nwe propose a novel approach that significantly reduces training data\nrequirements while surpassing state-of-the-art methods that rely on 10% more\npretraining data. We believe this work will guide future research toward a\ndeeper understanding of self-supervised video representation learning and its\nbroader implications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T15:47:58Z"}
{"aid":"http://arxiv.org/abs/2504.06158v1","title":"Rethinking the Nested U-Net Approach: Enhancing Biomarker Segmentation\n  with Attention Mechanisms and Multiscale Feature Fusion","summary":"Identifying biomarkers in medical images is vital for a wide range of biotech\napplications. However, recent Transformer and CNN based methods often struggle\nwith variations in morphology and staining, which limits their feature\nextraction capabilities. In medical image segmentation, where data samples are\noften limited, state-of-the-art (SOTA) methods improve accuracy by using\npre-trained encoders, while end-to-end approaches typically fall short due to\ndifficulties in transferring multiscale features effectively between encoders\nand decoders. To handle these challenges, we introduce a nested UNet\narchitecture that captures both local and global context through Multiscale\nFeature Fusion and Attention Mechanisms. This design improves feature\nintegration from encoders, highlights key channels and regions, and restores\nspatial details to enhance segmentation performance. Our method surpasses SOTA\napproaches, as evidenced by experiments across four datasets and detailed\nablation studies. Code: https://github.com/saadwazir/ReN-UNet","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-08T15:53:46Z"}
{"aid":"http://arxiv.org/abs/2504.06159v1","title":"Enhancing Primary Teacher Training through Academic Portfolios in\n  Advanced Mathematics Courses","summary":"The gap between theory and practice in mathematics education, particularly in\nprimary-teacher education, necessitates innovative teaching methodologies. This\npaper explores the implementation of academic portfolios as a teaching\ninnovation in Algebra and Number Systems I and II courses within the primary\nteacher education programme at Pontificia Universidad Cat\\'olica de Chile. The\nmethodology involved integrating academic portfolios to align course content\nwith essential learning outcomes for future teaching roles. Implementation\nbegins with a negotiation between students and teachers to establish a learning\ncontract, followed by an overview of course rules, content, objectives,\nmaterials, and grading rubrics. Preliminary findings indicate that this\ninnovative method enhances engagement with mathematical concepts, improves\nassessment efficacy in teacher training, and may contribute to enhanced\npreparation of primary mathematics teachers. The study highlights the role of\nportfolios in making students active participants in their learning,\nsignificantly enhancing the educational experience of teacher candidates. These\nfindings suggest a promising avenue for future educational assessments and\nmethodologies in mathematics, indicating that academic portfolios can bridge\nthe gap between theoretical knowledge and practical applications in mathematics\nteacher education, potentially enhancing teacher preparation. While this study\nshows promising results, further research with larger samples and longer\ntimeframes would be beneficial to establish causality and long-term impacts.","main_category":"math.HO","categories":"math.HO","published":"2025-04-08T15:55:33Z"}
{"aid":"http://arxiv.org/abs/2504.06164v1","title":"Functional ItÃ´-formula and Taylor expansions for non-anticipative maps\n  of cÃ dlÃ g rough paths","summary":"We derive a functional It\\^o-formula for non-anticipative maps of rough\npaths, based on the approximation properties of the signature of c\\`adl\\`ag\nrough paths. This result is a functional extension of the It\\^o-formula for\nc\\`adl\\`ag rough paths (by Friz and Zhang (2018)), which coincides with the\nchange of variable formula formulated by Dupire (2009) whenever the\nfunctionals' representations, the notions of regularity, and the integration\nconcepts can be matched. Unlike these previous works, we treat the vertical\n(jump) pertubation via the Marcus transformation, which allows for\nincorporating path functionals where the second order vertical derivatives do\nnot commute, as is the case for typical signature functionals. As a byproduct,\nwe show that sufficiently regular non-anticipative maps admit a functional\nTaylor expansion in terms of the path's signature, leading to an important\ngeneralization of the recent results by Dupire and Tissot-Daguette (2022).","main_category":"math.PR","categories":"math.PR,math.CA,q-fin.MF","published":"2025-04-08T16:00:21Z"}
{"aid":"http://arxiv.org/abs/2504.06168v1","title":"Differential diffusion effects and super-adiabatic local temperature in\n  lean hydrogen-air turbulent flames","summary":"Analyzed in this paper are three-dimensional Direct Numerical Simulation\n(DNS) data obtained from seven statistically planar and one-dimensional, lean\ncomplex-chemistry hydrogen-air flames propagating in a box with forced\nturbulence. The simulation conditions cover a wide range of non-dimensional\nturbulent combustion characteristics. Specifically, root-mean-square turbulent\nvelocity is varied from 2.2 to 54 laminar flame speeds, integral length scale\nof turbulence is varied from 0.5 to 2.2 laminar flame thicknesses, Damk\\\"ohler\nand Karlovitz number are varied from 0.01 to 0.53 and from 10 to 1315,\nrespectively. Two equivalence ratios, 0.5 and 0.35, are explored. Turbulent\nburning velocities are evaluated for these seven low Lewis number flames and\nequidiffusion counterparts to six of them. Moreover, conditioned profiles of\ntemperature, fuel consumption and heat release rates and probabilities of\nfinding superadiabatic temperature are sampled from all seven low Lewis number\nflames. Analyses of obtained results show that both magnitude of superadiabatic\ntemperature and probability of finding it are decreased with increasing\nKarlovitz number Ka. However, significant influence of differential diffusion\neffects on local structure of flame reaction zones and bulk burning velocity is\nwell pronounced in all cases, even at Ka as high as 1315. Therefore, a decrease\nin magnitude of superadiabatic local temperature with increasing Karlovitz\nnumber or even negligible probability of finding such a high temperature at\nhigh Ka is not an evidence that differential diffusion effects play a minor\nrole under such conditions. The simulated mitigation of phenomenon of\nsuperadiabatic temperature at high Ka is attributed to intensification of\nturbulent mixing in local flame oxidation zones, rather than weakening\ndifferential diffusion effects in local flame reaction zones.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-08T16:07:14Z"}
{"aid":"http://arxiv.org/abs/2504.06171v1","title":"Generalized Ridge Regression: Applications to Nonorthogonal Linear\n  Regression Models","summary":"This paper analyzes the possibilities of using the generalized ridge\nregression to mitigate multicollinearity in a multiple linear regression model.\nFor this purpose, we obtain the expressions for the estimated variance, the\ncoefficient of variation, the coefficient of correlation, the variance\ninflation factor and the condition number. The results obtained are illustrated\nwith two numerical examples.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-08T16:16:31Z"}
{"aid":"http://arxiv.org/abs/2504.06173v1","title":"Multi-Modality Sensing in mmWave Beamforming for Connected Vehicles\n  Using Deep Learning","summary":"Beamforming techniques are considered as essential parts to compensate severe\npath losses in millimeter-wave (mmWave) communications. In particular, these\ntechniques adopt large antenna arrays and formulate narrow beams to obtain\nsatisfactory received powers. However, performing accurate beam alignment over\nnarrow beams for efficient link configuration by traditional standard defined\nbeam selection approaches, which mainly rely on channel state information and\nbeam sweeping through exhaustive searching, imposes computational and\ncommunications overheads. And, such resulting overheads limit their potential\nuse in vehicle-to-infrastructure (V2I) and vehicle-to-vehicle (V2V)\ncommunications involving highly dynamic scenarios. In comparison, utilizing\nout-of-band contextual information, such as sensing data obtained from sensor\ndevices, provides a better alternative to reduce overheads. This paper presents\na deep learning-based solution for utilizing the multi-modality sensing data\nfor predicting the optimal beams having sufficient mmWave received powers so\nthat the best V2I and V2V line-of-sight links can be ensured proactively. The\nproposed solution has been tested on real-world measured mmWave sensing and\ncommunication data, and the results show that it can achieve up to 98.19%\naccuracies while predicting top-13 beams. Correspondingly, when compared to\nexisting been sweeping approach, the beam sweeping searching space and time\noverheads are greatly shortened roughly by 79.67% and 91.89%, respectively\nwhich confirm a promising solution for beamforming in mmWave enabled\ncommunications.","main_category":"cs.NI","categories":"cs.NI,cs.AI,cs.ET,cs.LG,eess.SP","published":"2025-04-08T16:18:00Z"}
{"aid":"http://arxiv.org/abs/2504.06175v1","title":"Basic distillation with realistic noise","summary":"Entanglement distillation is a key component of modular quantum computing and\nlong-range quantum communications. However, this powerful tool to reduce noise\nin entangled states is difficult to realize in practice for two main reasons.\nFirst, operations used to carry out distillation inject noise they seek to\nremove. Second, the extent to which distillation can work under realistic\ndevice noise is less well-studied. In this work, we both simulate distillation\nusing a variety of device noise models and perform distillation experiments on\nfixed-frequency IBM devices. We find reasonable agreement between experimental\ndata and simulation done using Pauli and non-Pauli noise models. In our data we\nfind broad improvement when the metric of success for distillation is to\nimprove average Bell fidelity under effective global depolarizing noise, or\nremove coherent errors, or improve the Bell fidelity of mildly degraded Bell\npairs. We pave the way to obtain broad improvement from distillation under a\nstricter, but practically relevant, metric: distill non-local Bell pairs with\nhigher fidelity than possible to obtain with other available methods. Our\nresults also help understand metrics and requirements for quantum devices to\nuse entanglement distillation as a primitive for modular computing.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T16:18:53Z"}
{"aid":"http://arxiv.org/abs/2504.06184v1","title":"The two-loop Higgs impact factor","summary":"In the HEFT, we consider the Regge limit of the two-loop amplitudes for Higgs\nboson production in association with a jet, expanded to NNLL accuracy. We\ndiscuss the issue of the Regge cuts versus poles in this context, and determine\nfor the first time the Higgs impact factor at two-loop accuracy.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-08T16:24:57Z"}
{"aid":"http://arxiv.org/abs/2504.06185v1","title":"WoundAmbit: Bridging State-of-the-Art Semantic Segmentation and\n  Real-World Wound Care","summary":"Chronic wounds affect a large population, particularly the elderly and\ndiabetic patients, who often exhibit limited mobility and co-existing health\nconditions. Automated wound monitoring via mobile image capture can reduce\nin-person physician visits by enabling remote tracking of wound size. Semantic\nsegmentation is key to this process, yet wound segmentation remains\nunderrepresented in medical imaging research. To address this, we benchmark\nstate-of-the-art deep learning models from general-purpose vision, medical\nimaging, and top methods from public wound challenges. For fair comparison, we\nstandardize training, data augmentation, and evaluation, conducting\ncross-validationto minimize partitioning bias. We also assess real-world\ndeployment aspects, including generalization to an out-of-distribution wound\ndataset, computational efficiency, and interpretability. Additionally, we\npropose a reference object-based approach to convert AI-generated masks into\nclinically relevant wound size estimates, and evaluate this, along with mask\nquality, for the best models based on physician assessments. Overall, the\ntransformer-based TransNeXt showed the highest levels of generalizability.\nDespite variations in inference times, all models processed at least one image\nper second on the CPU, which is deemed adequate for the intended application.\nInterpretability analysis typically revealed prominent activations in wound\nregions, emphasizing focus on clinically relevant features. Expert evaluation\nshowed high mask approval for all analyzed models, with VWFormer and ConvNeXtS\nbackbone performing the best. Size retrieval accuracy was similar across\nmodels, and predictions closely matched expert annotations. Finally, we\ndemonstrate how our AI-driven wound size estimation framework, WoundAmbit, can\nbe integrated into a custom telehealth system. Our code will be made available\non GitHub upon publication.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-08T16:25:59Z"}
{"aid":"http://arxiv.org/abs/2504.06197v1","title":"Orthogonal polynomials with complex densities and quantum minimal\n  surfaces","summary":"We show that the discrete Painlev\\'e-type equations arising from quantum\nminimal surfaces are equations for recurrence coefficients of orthogonal\npolynomials for indefinite hermitian products. As a consequence we obtain an\nexplicit formula for the initial conditions leading to positive solutions.","main_category":"math-ph","categories":"math-ph,math.MP","published":"2025-04-08T16:41:12Z"}
{"aid":"http://arxiv.org/abs/2504.06199v1","title":"Resting State Functional Connectivity Patterns Associate with Alcohol\n  Use Disorder Characteristics: Insights from the Triple Network Model","summary":"Prolonged alcohol use results in neuroadaptations that mark more severe and\ntreatment-resistant alcohol use. The goal of this study was to identify\nfunctional connectivity brain patterns underlying Alcohol Use Disorder\n(AUD)-related characteristics in fifty-five adults (31 female) who endorsed\nheavy alcohol use. We hypothesized that resting-state functional connectivity\n(rsFC) of the Salience (SN), Frontoparietal (FPN), and Default Mode (DMN)\nnetworks would reflect self reported recent and lifetime alcohol use,\nlaboratory-based alcohol seeking, urgency, and sociodemographic characteristics\nrelated to AUD. To test our hypothesis, we combined the triple network model\n(TNM) of psychopathology with a multivariate data-driven approach, regularized\npartial least squares (rPLS), to unfold concurrent functional connectivity (FC)\npatterns and their association with AUD characteristics. We observed three\nconcurrent associations of interest: i) drinking and age-related cross\ncommunication between the SN and both the FPN and DMN; ii) family history\ndensity of AUD and urgency anticorrelations between the SN and FPN; and iii)\nalcohol seeking and sex-associated SN and DMN interactions. These findings\ndemonstrate the utility of combining theory- and data-driven approaches to\nuncover associations between resting-state functional substrates and\nAUD-related characteristics that could aid in the identification, development,\nand testing of novel treatment targets across preclinical and clinical models.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-04-08T16:42:45Z"}
{"aid":"http://arxiv.org/abs/2504.06204v1","title":"Spin Squeezing via One-Axis Twisting in a Quadrupolar NMR system under\n  relaxation effects","summary":"This study investigates spin squeezed states in nuclear magnetic resonance\n(NMR) quadrupolar systems with spins I = 3/2 and I = 7/2 at room temperature,\ntaking into account the effects of relaxation on the dynamics. The origin of\nspin squeezing is attributed to the interaction between the nuclear quadrupole\nmoment and the electric field gradients in the molecular environment. The\nformal description of the nonlinear operators responsible for spin squeezing is\nachieved using the spin angular momentum representation via the one-axis\ntwisting mechanism. This approach provides a framework for quantum control and\nmetrology over the spin squeezing process while accounting for the influence of\nrelaxation phenomena. Non-Cartesian angular momentum operators are proposed,\nwith their variance products catching the quantum effects during the dynamics.\nAn upper bound for the squeezing parameter and the Heisenberg uncertainty at\nthermal equilibrium are also predicted for any spin quantum number.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T16:47:41Z"}
{"aid":"http://arxiv.org/abs/2504.06207v1","title":"An experimental survey and Perspective View on Meta-Learning for\n  Automated Algorithms Selection and Parametrization","summary":"Considerable progress has been made in the recent literature studies to\ntackle the Algorithms Selection and Parametrization (ASP) problem, which is\ndiversified in multiple meta-learning setups. Yet there is a lack of surveys\nand comparative evaluations that critically analyze, summarize and assess the\nperformance of existing methods. In this paper, we provide an overview of the\nstate of the art in this continuously evolving field. The survey sheds light on\nthe motivational reasons for pursuing classifiers selection through\nmeta-learning. In this regard, Automated Machine Learning (AutoML) is usually\ntreated as an ASP problem under the umbrella of the democratization of machine\nlearning. Accordingly, AutoML makes machine learning techniques accessible to\ndomain scientists who are interested in applying advanced analytics but lack\nthe required expertise. It can ease the task of manually selecting ML\nalgorithms and tuning related hyperparameters. We comprehensively discuss the\ndifferent phases of classifiers selection based on a generic framework that is\nformed as an outcome of reviewing prior works. Subsequently, we propose a\nbenchmark knowledge base of 4 millions previously learned models and present\nextensive comparative evaluations of the prominent methods for classifiers\nselection based on 08 classification algorithms and 400 benchmark datasets. The\ncomparative study quantitatively assesses the performance of algorithms\nselection methods along while emphasizing the strengths and limitations of\nexisting studies.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-08T16:51:22Z"}
{"aid":"http://arxiv.org/abs/2504.06215v1","title":"Randomization Inference in Two-Sided Market Experiments","summary":"Randomized experiments are increasingly employed in two-sided markets, such\nas buyer-seller platforms, to evaluate treatment effects from marketplace\ninterventions. These experiments must reflect the underlying two-sided market\nstructure in their design (e.g., sellers and buyers), making them particularly\nchallenging to analyze. In this paper, we propose a randomization inference\nframework to analyze outcomes from such two-sided experiments. Our approach is\nfinite-sample valid under sharp null hypotheses for any test statistic and\nmaintains asymptotic validity under weak null hypotheses through\nstudentization. Moreover, we provide heuristic guidance for choosing among\nmultiple valid randomization tests to enhance statistical power, which we\ndemonstrate empirically. Finally, we demonstrate the performance of our\nmethodology through a series of simulation studies.","main_category":"stat.ME","categories":"stat.ME,econ.EM","published":"2025-04-08T17:00:42Z"}
{"aid":"http://arxiv.org/abs/2504.06218v1","title":"Role of mechanical effects on the excitation spectra of\n  microwave-dressed Rydberg states in a cold atomic cloud","summary":"We explore the excitation spectra of cold 87Rb atoms to the 55D_3/2 Rydberg\nstate in the presence of microwave (MW) radiation as a function of MW\nfrequency. The spectra reveal several features around the\ntransition-frequencies between adjacent Rydberg states. We argue that some of\nthese features are indicative of variations in the Rydberg excitation\nprobability while others result from the removal of atoms from the cold cloud\nas a consequence of a MW induced strong dipole-dipole inter-atomic force. Our\nclaim is supported by experimental observations and theoretical modeling.","main_category":"physics.atom-ph","categories":"physics.atom-ph,quant-ph","published":"2025-04-08T17:06:05Z"}
{"aid":"http://arxiv.org/abs/2504.06225v1","title":"Encoder-Decoder Gemma: Improving the Quality-Efficiency Trade-Off via\n  Adaptation","summary":"While decoder-only large language models (LLMs) have shown impressive\nresults, encoder-decoder models are still widely adopted in real-world\napplications for their inference efficiency and richer encoder representation.\nIn this paper, we study a novel problem: adapting pretrained decoder-only LLMs\nto encoder-decoder, with the goal of leveraging the strengths of both\napproaches to achieve a more favorable quality-efficiency trade-off. We argue\nthat adaptation not only enables inheriting the capability of decoder-only LLMs\nbut also reduces the demand for computation compared to pretraining from\nscratch. We rigorously explore different pretraining objectives and parameter\ninitialization/optimization techniques. Through extensive experiments based on\nGemma 2 (2B and 9B) and a suite of newly pretrained mT5-sized models (up to\n1.6B), we demonstrate the effectiveness of adaptation and the advantage of\nencoder-decoder LLMs. Under similar inference budget, encoder-decoder LLMs\nachieve comparable (often better) pretraining performance but substantially\nbetter finetuning performance than their decoder-only counterpart. For example,\nGemma 2B-2B outperforms Gemma 2B by $\\sim$7\\% after instruction tuning.\nEncoder-decoder adaptation also allows for flexible combination of\ndifferent-sized models, where Gemma 9B-2B significantly surpasses Gemma 2B-2B\nby $>$3\\%. The adapted encoder representation also yields better results on\nSuperGLUE. We will release our checkpoints to facilitate future research.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-08T17:13:41Z"}
{"aid":"http://arxiv.org/abs/2504.06226v1","title":"Signatures of Candidate States of $Î½=12/5$ in Shot Noise","summary":"Fractional quantum Hall (FQH) states are highly sought after because of their\nability to host non-abelian anyons, whose braiding statistics make them\nexcellent candidates for qubits in topological quantum computing. Multiple\ntheoretical studies on the $\\nu=\\frac{12}{5}$ FQH state predict various\nquasi-particle states hosted by the $\\frac{12}{5}$ plateau, which include\n$\\mathbb Z_3$ parafermions and Majorana modes. In this work, we provide a\nsystematic protocol to distinguish among four possible candidate wavefunctions\nof the $\\frac{12}{5}$ plateau using zero-frequency short noise experiments on a\nfilter-geometry. Qualitative comparisons of Fano-Factors provide a robust way\nto predict the candidate state across both the full and partial thermal\nequilibration regimes without prior knowledge of the experimental information,\nlike thermal equilibration length, to allow for more realistic experiments.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.str-el","published":"2025-04-08T17:13:55Z"}
{"aid":"http://arxiv.org/abs/2504.06233v1","title":"On the homology of special unitary groups over polynomial rings","summary":"In this work, we answer the homotopy invariance question for the ''smallest''\nnon-isotrivial group-scheme over $\\mathbb{P}^1$, obtaining a result, which is\nnot contained in previous works due to Knudson and Wendt. More explicitly, let\n$\\mathcal{G}=\\mathrm{SU}_{3,\\mathbb{P}^1}$ be the (non-isotrivial) non-split\ngroup-scheme over $\\mathbb{P}^1$ defined from the standard (isotropic)\nhermitian form in three variables. In this article, we prove that there exists\na natural homomorphism $\\mathrm{PGL}_2(F) \\to \\mathcal{G}(F[t])$ that induces\nisomorphisms $H_*(\\mathrm{PGL}_2(F), \\mathbb{Z}) \\to H_*(\\mathcal{G}(F[t]),\n\\mathbb{Z})$. Then we study the rational homology of\n$\\mathcal{G}(F[t,t^{-1}])$, by previously describing suitable fundamental\ndomains for certain arithmetic subgroups of $\\mathcal{G}$.","main_category":"math.KT","categories":"math.KT,math.GR,math.NT","published":"2025-04-08T17:30:56Z"}
{"aid":"http://arxiv.org/abs/2504.06239v1","title":"Canonical for Automated Theorem Proving in Lean","summary":"Canonical is a solver for type inhabitation in dependent type theory, that\nis, the problem of producing a term of a given type. We present a Lean tactic\nwhich invokes Canonical to generate proof terms and synthesize programs. The\ntactic supports higher-order and dependently-typed goals, structural recursion\nover indexed inductive types, and definitional equality. Canonical finds proofs\nfor 84% of Natural Number Game problems in 51 seconds total.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-08T17:36:10Z"}
{"aid":"http://arxiv.org/abs/2504.06240v1","title":"Dictionary-free Koopman Predictive Control for Autonomous Vehicles in\n  Mixed Traffic","summary":"Koopman Model Predictive Control (KMPC) and Data-EnablEd Predictive Control\n(DeePC) use linear models to approximate nonlinear systems and integrate them\nwith predictive control. Both approaches have recently demonstrated promising\nperformance in controlling Connected and Autonomous Vehicles (CAVs) in mixed\ntraffic. However, selecting appropriate lifting functions for the Koopman\noperator in KMPC is challenging, while the data-driven representation from\nWillems' fundamental lemma in DeePC must be updated to approximate the local\nlinearization when the equilibrium traffic state changes. In this paper, we\npropose a dictionary-free Koopman model predictive control (DF-KMPC) for CAV\ncontrol. In particular, we first introduce a behavioral perspective to identify\nthe optimal dictionary-free Koopman linear model. We then utilize an iterative\nalgorithm to compute a data-driven approximation of the dictionary-free Koopman\nrepresentation. Integrating this data-driven linear representation with\npredictive control leads to our DF-KMPC, which eliminates the need to select\nlifting functions and update the traffic equilibrium state. Nonlinear traffic\nsimulations show that DF-KMPC effectively mitigates traffic waves and improves\ntracking performance.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-08T17:40:54Z"}
{"aid":"http://arxiv.org/abs/2504.06242v1","title":"Addressing Relative Degree Issues in Control Barrier Function Synthesis\n  with Physics-Informed Neural Networks","summary":"In robotics, control barrier function (CBF)-based safety filters are commonly\nused to enforce state constraints. A critical challenge arises when the\nrelative degree of the CBF varies across the state space. This variability can\ncreate regions within the safe set where the control input becomes\nunconstrained. When implemented as a safety filter, this may result in\nchattering near the safety boundary and ultimately compromise system safety. To\naddress this issue, we propose a novel approach for CBF synthesis by\nformulating it as solving a set of boundary value problems. The solutions to\nthe boundary value problems are determined using physics-informed neural\nnetworks (PINNs). Our approach ensures that the synthesized CBFs maintain a\nconstant relative degree across the set of admissible states, thereby\npreventing unconstrained control scenarios. We illustrate the approach in\nsimulation and further verify it through real-world quadrotor experiments,\ndemonstrating its effectiveness in preserving desired system safety properties.","main_category":"eess.SY","categories":"eess.SY,cs.RO,cs.SY","published":"2025-04-08T17:41:43Z"}
{"aid":"http://arxiv.org/abs/2504.06244v1","title":"The distinction between Ice phases VII, VIII and X","summary":"Ice phases VII, VIII and X are all based on a body-centered cubic arrangement\nof molecules, the differences coming from molecular orientation. There is some\ndebate as to whether these should even be considered distinct phases. The\nstandard definition of a transition between distinct phases involves a\ndiscontinuity in any derivative of the free energy. This can be hard to prove\nexperimentally, and most previous theoretical works have been based on models\nwhich either have continuously differentiable free energies, or no\nstraightforward way to determine the free energy. Here we build a free energy\nmodel based on the common definitions of the phases ; ordered ice-VIII,\norientationally disordered ice VII and proton-disordered ice X. All transitions\nin this model might or might not be associated with a discontinuity in the\nspecific heat, depending on paramaterization. By comparing with data, we find\nthat a VII-X transition line exists, but it ends in a critical point hidden\nwithin the stability field of phase VIII. If the model is correct, there is a\ndiscontinuity between VII and X, so they are separate phases. We propose that\nthe hidden phase boundary might be demonstrated experimentally by compression\nof supercooled ice VII.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.mtrl-sci","published":"2025-04-08T17:43:42Z"}
{"aid":"http://arxiv.org/abs/2504.06252v1","title":"A systematic method to identify runaways from star clusters produced\n  from single-binary interactions: A case study of M67","summary":"One hypothesis for runaway stars (RSs) is that they are ejected from star\nclusters with high velocities relative to the cluster center-of-mass motion.\nThere are two competing mechanisms for their production: supernova-based\nejections in binaries, where one companion explodes, leaves no remnant, and\nlaunches the other companion at the instantaneous orbital velocity, and the\ndisintegration of triples (or higher-order multiples), which produces a\nrecoiled runaway binary (RB) and an RS. We search for RS candidates using data\nfrom the Gaia DR3 survey with a focus on triple disintegration since in this\ncase the product is always a binary and a single star that should be moving in\nopposite directions. We created a systematic methodology to look for candidate\nRS-RB runaway pairs produced from the disintegration of bound three-body\nsystems formed from single-binary interactions based on momentum conservation\nand causality. The method we use is general and can be applied to any cluster\nwith a 5D kinematic data set. We used our criteria to search for these pairs in\na 150 pc circular field of view surrounding the open cluster M67, which we used\nas a benchmark cluster to test the robustness of our method. Our results reveal\nonly one RS-RB pair that is consistent with all of our selection criteria out\nof an initial sample of $10^8$ pairs.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-08T17:57:10Z"}
{"aid":"http://arxiv.org/abs/2504.06253v1","title":"Solving General QUBOs with Warm-Start QAOA via a Reduction to Max-Cut","summary":"The Quantum Approximate Optimization Algorithm (QAOA) is a quantum algorithm\nthat finds approximate solutions to problems in combinatorial optimization,\nespecially those that can be formulated as a Quadratic Unconstrained Binary\nOptimization (QUBO) problem. In prior work, researchers have considered various\nways of \"warm-starting\" QAOA by constructing an initial quantum state using\nclassically-obtained solutions or information; these warm-starts typically\ncause QAOA to yield better approximation ratios at much lower circuit depths.\nFor the Max-Cut problem, one warm-start approaches constructs the initial state\nusing the high-dimensional vectors that are output from an SDP relaxation of\nthe corresponding Max-Cut problem. This work leverages these semidefinite\nwarmstarts for a broader class of problem instances by using a standard\nreduction that transforms any QUBO instance into a Max-Cut instance. We\nempirically compare this approach to a \"QUBO-relaxation\" approach that relaxes\nthe QUBO directly. Our results consider a variety of QUBO instances ranging\nfrom randomly generated QUBOs to QUBOs corresponding to specific problems such\nas the traveling salesman problem, maximum independent set, and portfolio\noptimization. We find that the best choice of warmstart approach is strongly\ndependent on the problem type.","main_category":"quant-ph","categories":"quant-ph,cs.DM,math.OC","published":"2025-04-08T17:57:12Z"}
{"aid":"http://arxiv.org/abs/2504.06256v1","title":"Transfer between Modalities with MetaQueries","summary":"Unified multimodal models aim to integrate understanding (text output) and\ngeneration (pixel output), but aligning these different modalities within a\nsingle architecture often demands complex training recipes and careful data\nbalancing. We introduce MetaQueries, a set of learnable queries that act as an\nefficient interface between autoregressive multimodal LLMs (MLLMs) and\ndiffusion models. MetaQueries connects the MLLM's latents to the diffusion\ndecoder, enabling knowledge-augmented image generation by leveraging the MLLM's\ndeep understanding and reasoning capabilities. Our method simplifies training,\nrequiring only paired image-caption data and standard diffusion objectives.\nNotably, this transfer is effective even when the MLLM backbone remains frozen,\nthereby preserving its state-of-the-art multimodal understanding capabilities\nwhile achieving strong generative performance. Additionally, our method is\nflexible and can be easily instruction-tuned for advanced applications such as\nimage editing and subject-driven generation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T17:58:47Z"}
{"aid":"http://arxiv.org/abs/2504.06260v1","title":"FEABench: Evaluating Language Models on Multiphysics Reasoning Ability","summary":"Building precise simulations of the real world and invoking numerical solvers\nto answer quantitative problems is an essential requirement in engineering and\nscience. We present FEABench, a benchmark to evaluate the ability of large\nlanguage models (LLMs) and LLM agents to simulate and solve physics,\nmathematics and engineering problems using finite element analysis (FEA). We\nintroduce a comprehensive evaluation scheme to investigate the ability of LLMs\nto solve these problems end-to-end by reasoning over natural language problem\ndescriptions and operating COMSOL Multiphysics$^\\circledR$, an FEA software, to\ncompute the answers. We additionally design a language model agent equipped\nwith the ability to interact with the software through its Application\nProgramming Interface (API), examine its outputs and use tools to improve its\nsolutions over multiple iterations. Our best performing strategy generates\nexecutable API calls 88% of the time. LLMs that can successfully interact with\nand operate FEA software to solve problems such as those in our benchmark would\npush the frontiers of automation in engineering. Acquiring this capability\nwould augment LLMs' reasoning skills with the precision of numerical solvers\nand advance the development of autonomous systems that can tackle complex\nproblems in the real world. The code is available at\nhttps://github.com/google/feabench","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.NA,math.NA","published":"2025-04-08T17:59:39Z"}
{"aid":"http://arxiv.org/abs/2504.06546v1","title":"Several new infinite families of NMDS codes with arbitrary dimensions\n  supporting $t$-designs","summary":"Near maximum distance separable (NMDS) codes, where both the code and its\ndual are almost maximum distance separable, play pivotal roles in combinatorial\ndesign theory and cryptographic applications. Despite progress in fixed\ndimensions (e.g., dimension 4 codes by Ding and Tang \\cite{Ding2020}),\nconstructing NMDS codes with arbitrary dimensions supporting $t$-designs\n($t\\geq 2$) has remained open. In this paper, we construct two infinite\nfamilies of NMDS codes over $\\mathbb{F}_q$ for any prime power $q$ with\nflexible dimensions and determine their weight distributions. Further, two\nadditional families with arbitrary dimensions over $\\mathbb{F}_{2^m}$\nsupporting $2$-designs and $3$-designs, and their weight distributions are\nobtained. Our results fully generalize prior fixed-dimension\nworks~\\cite{DingY2024,Heng2023,Heng20231,Xu2022}, and affirmatively settle the\nHeng-Wang conjecture \\cite{Heng2023} on the existence of NMDS codes with\nflexible parameters supporting $2$-designs.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-09T03:02:10Z"}
{"aid":"http://arxiv.org/abs/2504.06562v1","title":"FuseRL: Dense Preference Optimization for Heterogeneous Model Fusion","summary":"Heterogeneous model fusion enhances the performance of LLMs by integrating\nthe knowledge and capabilities of multiple structurally diverse models.\nHowever, existing approaches often rely solely on selecting the best output for\neach prompt from source models, which underutilizes their full potential due to\nlimited source knowledge and results in sparse optimization signals. To address\nthis limitation, we propose FuseRL, a novel two-stage framework comprising\nFuseSFT and FusePO to maximize the utilization of source LLMs. FuseSFT\nestablishes a robust initialization by integrating the strengths of\nheterogeneous source models through weighted supervised fine-tuning (SFT) on\ndiverse outputs for each prompt. FusePO optimizes weighted preferences based on\nthe outputs of multiple source models to enable superior alignment performance.\nExtensive experiments demonstrate the effectiveness of our framework across\nvarious preference alignment methods, including RLOO, DPO, and SimPO. Using\nLlama-3.1-8B-Instruct as the target model, our approach achieves\nstate-of-the-art performance among 8B LLMs on the AlpacaEval-2 and Arena-Hard\nbenchmarks. Further analysis suggests that FuseSFT regularizes the training\nprocess to reduce overfitting, while FusePO introduces dense and diverse\nsignals for preference optimization.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T03:51:53Z"}
{"aid":"http://arxiv.org/abs/2504.06568v1","title":"Relaxed Weak Accelerated Proximal Gradient Method: a Unified Framework\n  for Nesterov's Accelerations","summary":"This paper is devoted to the study of accelerated proximal gradient methods\nwhere the sequence that controls the momentum term doesn't follow Nesterov's\nrule. We propose a relaxed weak accelerated proximal gradient (R-WAPG) method,\na generic algorithm that unifies the convergence results for strongly convex\nand convex problems where the extrapolation constant is characterized by a\nsequence that is much weaker than Nesterov's rule. Our R-WAPG provides a\nunified framework for several notable Euclidean variants of FISTA and verifies\ntheir convergences. In addition, we provide the convergence rate of strongly\nconvex objective with a constant momentum term. Without using the idea of\nrestarting, we also reformulate R-WAPG as ``Free R-WAPG\" so that it doesn't\nrequire any parameter. Explorative numerical experiments were conducted to show\nits competitive advantages.","main_category":"math.OC","categories":"math.OC","published":"2025-04-09T04:05:54Z"}
{"aid":"http://arxiv.org/abs/2504.06571v1","title":"Double shape quantum phase transitions in the SU3-IBM (I) new\n  $Î³$-soft phase and the shape phase transition from the new $Î³$-soft\n  phase to the prolate shape","summary":"Shape quantum phase transition is an important topic in nuclear structure. In\nthis paper, we begin to study the shape quantum phase transition in the\nSU3-IBM. In this new proposed model, spherical-like spectra was found to\nresolve the spherical nucleus puzzle, which is a new $\\gamma$-soft rotational\nmode. In this paper, the shape phase transition along the new $\\gamma$-soft\nline is first discussed, and then the neighbouring case at the prolate side is\nalso studied. We find that double shape phase transitions occur along a single\nparameter path. The new $\\gamma$-softness is really a shape phase and the shape\nphase transition from the new $\\gamma$-soft phase to the prolate shape is\nfound. The experimental support is also found and $^{108}$Pd is the critical\nnucleus.","main_category":"nucl-th","categories":"nucl-th,nucl-ex","published":"2025-04-09T04:15:40Z"}
{"aid":"http://arxiv.org/abs/2504.06576v1","title":"Theoretical analysis for non-linear effects of magnetic fields on\n  unsteady boundary layer flows","summary":"This study investigates unsteady boundary layer phenomena in electrically\nconducting fluids subjected to static magnetic fields. Using a semi-explicit\nsimilarity transformation method, the momentum equation associated with the\nStokes stream function is solved. The nonlinear closed analytical solutions for\nboth stagnation flow and converging flow are derived. The results demonstrate\nthat the boundary layer structure incorporates similar shock and solitary wave\ncomponents which are promoted by Lorentz force. Under extreme magnetic fields,\nthe flow exhibits sine and cosine wave patterns, which are motivated by the\nstrong Lorentz force. An in-depth asymptotic analysis establishes the square\nroot scaling laws that quantify the growth of friction and flux with increasing\nmagnetic field strength. The boundary layer thickness scales inversely with the\nHartmann number, a consequence of dominant Lorentz force, which differs from\nthe conclusion of duct flow (Hunt 1965). These findings elucidate the physical\nmechanisms governing the nonlinear coupling between magnetic fields and the\ndynamics of the boundary layer.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-09T04:39:32Z"}
{"aid":"http://arxiv.org/abs/2504.06580v1","title":"Exploring Ordinal Bias in Action Recognition for Instructional Videos","summary":"Action recognition models have achieved promising results in understanding\ninstructional videos. However, they often rely on dominant, dataset-specific\naction sequences rather than true video comprehension, a problem that we define\nas ordinal bias. To address this issue, we propose two effective video\nmanipulation methods: Action Masking, which masks frames of frequently\nco-occurring actions, and Sequence Shuffling, which randomizes the order of\naction segments. Through comprehensive experiments, we demonstrate that current\nmodels exhibit significant performance drops when confronted with nonstandard\naction sequences, underscoring their vulnerability to ordinal bias. Our\nfindings emphasize the importance of rethinking evaluation strategies and\ndeveloping models capable of generalizing beyond fixed action patterns in\ndiverse instructional videos.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-09T05:03:51Z"}
{"aid":"http://arxiv.org/abs/2504.06582v1","title":"Harmful information spreading and its impact on vaccination campaigns\n  modeled through fractal-fractional operators","summary":"Despite the huge efforts to develop and administer vaccines worldwide to cope\nwith the COVID-19 pandemic, misinformation spreading through fake news in media\nand social networks about vaccination safety, make that people refuse to be\nvaccinated, which harms not only these people but also the whole population.\n  In this work, we model the effects of harmful information spreading in\nimmunization acquisition through vaccination. Our model is posed for several\nfractional derivative operators. We have conducted a comprehensive foundation\nanalysis of this model for the different fractional derivatives. Additionally,\nwe have incorporated a strength parameter that shows the combined impact of\nnonlinear and linear components within an epidemiological model. We have used\nthe second derivative of the Lyapunov function to ascertain the detection of\nwave patterns within the vaccination dynamics.","main_category":"math.DS","categories":"math.DS","published":"2025-04-09T05:04:17Z"}
{"aid":"http://arxiv.org/abs/2504.06583v1","title":"Aplicando diferencias finitas para resolver ecuaciones y sistemas de\n  ecuaciones diferenciales parciales sobre dominios planos irregulares\n  simplemente conexos y no conexos","summary":"Using exhaustion method and finite differences a new method to solve system\nof partial differential equations and is presented. This method allows design\nalgorithm to solve linear and nonlinear systems in irregular domains. Applying\nthis method to solve linear and nonlinear problems with prescribed conditions\nDirichlet over two-dimensional irregular domains are analyzed.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-09T05:05:04Z"}
{"aid":"http://arxiv.org/abs/2504.06592v1","title":"On Coalgebraic Product Constructions for Markov Chains and Automata","summary":"Verifying traces of systems is a central topic in formal verification. We\nstudy model checking of Markov chains (MCs) against temporal properties\nrepresented as (finite) automata. For instance, given an MC and a deterministic\nfinite automaton (DFA), a simple but practically useful model checking problem\nasks for the probability of traces on the MC that are accepted by the DFA. A\nstandard approach to solving this problem constructs a product MC of the given\nMC and DFA, reducing the task to a simple reachability probability problem on\nthe resulting product MC.\n  In this paper, on top of our recent development of coalgebraic framework, we\nfirst present a no-go theorem for product constructions, showing a case when we\ncannot do product constructions for model checking. Specifically, we show that\nthere are no coalgebraic product MCs of MCs and nondeterministic finite\nautomata for computing the probability of the accepting traces. This no-go\ntheorem is established via a characterisation of natural transformations\nbetween certain functors that determine the type of branching, including\nnondeterministic or probabilistic branching.\n  Second, we present a coalgebraic product construction of MCs and multiset\nfinite automata (MFAs) as a new instance within our framework. This\nconstruction addresses a model checking problem that asks for the expected\nnumber of accepting runs on MFAs over traces of MCs. The problem is reduced to\nsolving linear equations, which is solvable in polynomial-time under a\nreasonable assumption that ensures the finiteness of the solution.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-09T05:41:29Z"}
{"aid":"http://arxiv.org/abs/2504.06595v1","title":"Time-local stochastic equation of motion for solid ionic electrolytes","summary":"Numerical studies of ionic motion through solid electrolytes commonly involve\nstatic nudged-elastic band (NEB) methods or costly \\emph{ab initio} molecular\ndynamics (AIMD). Building on a time-local model of current carrier-electrolyte\ninteraction and incorporating thermal motion, we introduce an approach that is\nintermediate between the two well-established methodologies by treating the\nelectrolyte as an effective medium that interacts with the mobile particle.\nThrough this coupling, the thermally vibrating electrolyte imparts energy to\nthe charge carriers while also absorbing energy from them due to its own finite\nelasticity. Using a simple model system, we validate our approach through a\nseries of numerical simulations. Our methodology reproduces both dissipative\nand diffusive behavior, and helps link microscopic system parameters to\nmeasurable macroscopic properties.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-09T05:45:10Z"}
{"aid":"http://arxiv.org/abs/2504.06603v1","title":"Asymptotic Variance in the Central Limit Theorem for Multilevel\n  Markovian Stochastic Approximation","summary":"In this note we consider the finite-dimensional parameter estimation problem\nassociated to inverse problems. In such scenarios, one seeks to maximize the\nmarginal likelihood associated to a Bayesian model. This latter model is\nconnected to the solution of partial or ordinary differential equation. As\nsuch, there are two primary difficulties in maximizing the marginal likelihood\n(i) that the solution of differential equation is not always analytically\ntractable and (ii) neither is the marginal likelihood. Typically (i) is dealt\nwith using a numerical solution of the differential equation, leading to a\nnumerical bias and (ii) has been well studied in the literature using, for\ninstance, Markovian stochastic approximation. It is well-known that to reduce\nthe computational effort to obtain the maximal value of the parameter, one can\nuse a hierarchy of solutions of the differential equation and combine with\nstochastic gradient methods. Several approaches do exactly this. In this paper\nwe consider the asymptotic variance in the central limit theorem, associated to\nknown estimates and find bounds on the asymptotic variance in terms of the\nprecision of the solution of the differential equation. The significance of\nthese bounds are the that they provide missing theoretical guidelines on how to\nset simulation parameters; that is, these appear to be the first mathematical\nresults which help to run the methods efficiently in practice.","main_category":"math.NA","categories":"math.NA,cs.NA,stat.CO","published":"2025-04-09T05:59:40Z"}
{"aid":"http://arxiv.org/abs/2504.06614v1","title":"AgentFM: Role-Aware Failure Management for Distributed Databases with\n  LLM-Driven Multi-Agents","summary":"Distributed databases are critical infrastructures for today's large-scale\nsoftware systems, making effective failure management essential to ensure\nsoftware availability. However, existing approaches often overlook the role\ndistinctions within distributed databases and rely on small-scale models with\nlimited generalization capabilities. In this paper, we conduct a preliminary\nempirical study to emphasize the unique significance of different roles.\nBuilding on this insight, we propose AgentFM, a role-aware failure management\nframework for distributed databases powered by LLM-driven multi-agents. AgentFM\naddresses failure management by considering system roles, data roles, and task\nroles, with a meta-agent orchestrating these components. Preliminary\nevaluations using Apache IoTDB demonstrate the effectiveness of AgentFM and\nopen new directions for further research.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-09T06:18:24Z"}
{"aid":"http://arxiv.org/abs/2504.06616v1","title":"Search for Type IL Gamma-ray Bursts: Criterion, Results, Verification\n  and Physical Implication","summary":"As an interesting subclass of gamma-ray burst (GRB), Type IL GRB (such as GRB\n211211A and GRB 230307A) features a long-duration prompt emission but\noriginating from compact binary merger. The \"long duration\" emisison of Type IL\nGRB are dominately composed of the main burst, rather than the extended\nemission, differentiating them from the traditional \"long-short\" GRB (e.g., GRB\n060614). Previous study has reported several Type IL GRBs by visual inspection\nof their light curves. In this work, we established a detailed criterion to\nidentify Type IL GRBs by light curve, and then systematically searched the\narchival \\textit{Fermi}/GBM data with this criterion, resulting in a sample of\n5 type IL GRBs from January 1, 2014 to January 1, 2024, i.e. GRB 230307A, GRB\n211211A, GRB 200914A, GRB 200311A and GRB 170228A. Apart from the light curve\npattern, we find that the temporal and spectral properties of these 5 GRBs also\nsupport this classification. Interestingly, we find that the energy ratio\nbetween extended emission and main emission is almost constant ($\\sim0.7$, with\nsmall scattering) for these GRBs, which have strong implication on the\nmechanism of Type IL burst. We discuss theoretical models to interpret the\nprogenitor, central engine, and extended emission of these Type IL bursts.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-09T06:24:50Z"}
{"aid":"http://arxiv.org/abs/2504.06619v1","title":"Sufficient conditions for a graph with minimum degree to have a\n  component factor","summary":"Let $\\mathcal{T}_{\\frac{k}{r}}$ denote the set of trees $T$ such that\n$i(T-S)\\leq\\frac{k}{r}|S|$ for any $S\\subset V(T)$ and for any $e\\in E(T)$\nthere exists a set $S^{*}\\subset V(T)$ with\n$i((T-e)-S^{*})>\\frac{k}{r}|S^{*}|$, where $r<k$ are two positive integers. A\n$\\{C_{2i+1},T:1\\leq i<\\frac{r}{k-r},T\\in\\mathcal{T}_{\\frac{k}{r}}\\}$-factor of\na graph $G$ is a spanning subgraph of $G$, in which every component is\nisomorphic to an element in $\\{C_{2i+1},T:1\\leq\ni<\\frac{r}{k-r},T\\in\\mathcal{T}_{\\frac{k}{r}}\\}$. Let $A(G)$ and $Q(G)$ denote\nthe adjacency matrix and the signless Laplacian matrix of $G$, respectively.\nThe adjacency spectral radius and the signless Laplacian spectral radius of\n$G$, denoted by $\\rho(G)$ and $q(G)$, are the largest eigenvalues of $A(G)$ and\n$Q(G)$, respectively. In this paper, we study the connections between the\nspectral radius and the existence of a $\\{C_{2i+1},T:1\\leq\ni<\\frac{r}{k-r},T\\in\\mathcal{T}_{\\frac{k}{r}}\\}$-factor in a graph. We first\nestablish a tight sufficient condition involving the adjacency spectral radius\nto guarantee the existence of a $\\{C_{2i+1},T:1\\leq\ni<\\frac{r}{k-r},T\\in\\mathcal{T}_{\\frac{k}{r}}\\}$-factor in a graph. Then we\npropose a tight signless Laplacian spectral radius condition for the existence\nof a $\\{C_{2i+1},T:1\\leq\ni<\\frac{r}{k-r},T\\in\\mathcal{T}_{\\frac{k}{r}}\\}$-factor in a graph.","main_category":"math.CO","categories":"math.CO","published":"2025-04-09T06:35:29Z"}
{"aid":"http://arxiv.org/abs/2504.06620v1","title":"InstantSticker: Realistic Decal Blending via Disentangled Object\n  Reconstruction","summary":"We present InstantSticker, a disentangled reconstruction pipeline based on\nImage-Based Lighting (IBL), which focuses on highly realistic decal blending,\nsimulates stickers attached to the reconstructed surface, and allows for\ninstant editing and real-time rendering. To achieve stereoscopic impression of\nthe decal, we introduce shadow factor into IBL, which can be adaptively\noptimized during training. This allows the shadow brightness of surfaces to be\naccurately decomposed rather than baked into the diffuse color, ensuring that\nthe edited texture exhibits authentic shading. To address the issues of warping\nand blurriness in previous methods, we apply As-Rigid-As-Possible (ARAP)\nparameterization to pre-unfold a specified area of the mesh and use the local\nUV mapping combined with a neural texture map to enhance the ability to express\nhigh-frequency details in that area. For instant editing, we utilize the Disney\nBRDF model, explicitly defining material colors with 3-channel diffuse albedo.\nThis enables instant replacement of albedo RGB values during the editing\nprocess, avoiding the prolonged optimization required in previous approaches.\nIn our experiment, we introduce the Ratio Variance Warping (RVW) metric to\nevaluate the local geometric warping of the decal area. Extensive experimental\nresults demonstrate that our method surpasses previous decal blending methods\nin terms of editing quality, editing speed and rendering speed, achieving the\nstate-of-the-art.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T06:36:36Z"}
{"aid":"http://arxiv.org/abs/2504.06628v1","title":"Entropy Production in Non-Gaussian Active Matter: A Unified Fluctuation\n  Theorem and Deep Learning Framework","summary":"We present a general framework for deriving entropy production rates in\nactive matter systems driven by non-Gaussian active fluctuations. Employing the\nprobability flow equivalence technique, we rigorously derive an entropy\nproduction decomposition formula and demonstrate that the entropy production,\n$\\Delta s_\\mathrm{tot}$, satisfies the integral fluctuation theorem $\\langle\n\\exp[ -\\Delta s_\\mathrm{tot} + B_\\mathrm{act}] \\rangle = 1$ and the generalized\nsecond law of thermodynamics $\\langle \\Delta s_\\mathrm{tot}\\rangle \\geq\\langle\nB_\\mathrm{act}\\rangle$, where $B_\\mathrm{act}$ is a path-dependent random\nvariable associated with the active fluctuations. Our result holds generally\nfor arbitrary initial conditions, encompassing both steady-state and transient\nfinite-time regimes. In the limiting case where active fluctuations are absent\n(i.e., $B_\\mathrm{act} \\equiv 0$), the theorem reduces to the well-established\nresults in stochastic thermodynamics. Building on the theoretical foundation,\nwe propose a deep learning-based methodology to efficiently compute the entropy\nproduction, utilizing the L\\'{e}vy score function we proposed. To illustrate\nthe validity of this approach, we apply it to two representative systems: a\nBrownian particle in a periodic active bath and an active polymer system\nconsisting of an active Brownian particle cross-linker interacting with passive\nBrownian beads. Our results provide a unified framework for analyzing entropy\nproduction in active matter systems while offering practical computational\ntools for investigating complex nonequilibrium behaviors.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,math-ph,math.MP","published":"2025-04-09T07:02:02Z"}
{"aid":"http://arxiv.org/abs/2504.06629v1","title":"Rethinking LayerNorm in Image Restoration Transformers","summary":"This work investigates abnormal feature behaviors observed in image\nrestoration (IR) Transformers. Specifically, we identify two critical issues:\nfeature entropy becoming excessively small and feature magnitudes diverging up\nto a million-fold scale. We pinpoint the root cause to the per-token\nnormalization aspect of conventional LayerNorm, which disrupts essential\nspatial correlations and internal feature statistics. To address this, we\npropose a simple normalization strategy tailored for IR Transformers. Our\napproach applies normalization across the entire spatio-channel dimension,\neffectively preserving spatial correlations. Additionally, we introduce an\ninput-adaptive rescaling method that aligns feature statistics to the unique\nstatistical requirements of each input. Experimental results verify that this\ncombined strategy effectively resolves feature divergence, significantly\nenhancing both the stability and performance of IR Transformers across various\nIR tasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T07:06:44Z"}
{"aid":"http://arxiv.org/abs/2504.06642v1","title":"Current-Enabled Optical Conductivity of Collective Modes in\n  Unconventional Superconductors","summary":"We theoretically investigate the current-enabled linear optical conductivity\nof collective modes in superconductors with unconventional pairing symmetries.\nAfter deriving general formulas for the optical conductivity of a\nsuperconductor featuring multiple pairing channels and bands using the path\nintegral formalism, we apply these formulas to several models. Using a model of\ncompeting s- and d-wave pairing interactions, we find that several known\ncollective modes generate peaks in the optical conductivity upon injection of a\nsupercurrent. This includes single- and multiband versions of\nBardasis-Schrieffer modes, mixed-symmetry Bardasis-Schrieffer modes, and\nLeggett modes. Using a model for interband p-wave superconductivity with Rashba\nspin-orbit coupling, we find that in such a system Bardasis-Schrieffer modes\nare optically active even without introducing a supercurrent. In a p+ip chiral\nground state, these modes turn out to produce peaks in the longitudinal and\ntransverse optical conductivity. Other collective modes belonging to the chiral\np+ip order parameter turn out to be unaffected by the spin-orbit coupling but\ncontribute to the optical response when a supercurrent is introduced. These\nresults promise new avenues for the observation of collective modes in a\nvariety of superconducting systems, including multiband superconductors and\nsuperconductors that feature multiple pairing channels or multi-component order\nparameters, such as chiral p- or d-wave superconductors.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-09T07:32:42Z"}
{"aid":"http://arxiv.org/abs/2504.06653v1","title":"Hunting axion dark matter signatures in low-frequency terrestrial\n  magnetic fields","summary":"We show that Earth's natural environment can serve as a powerful probe for\nultralight axion dark matter. In the presence of global geomagnetic fields, the\naxions with masses ranging from $10^{-15}\\,{\\rm eV}-10^{-13}\\,{\\rm eV}$ induce\nelectromagnetic waves in the (sub-) extremely low-frequency band ($0.3-30\\,{\\rm\nHz}$) through the axion-photon coupling. We predict the amplitude of induced\nmagnetic fields in the Earth-ionosphere cavity, taking the finite conductivity\nof the atmosphere into account. This allows us to constrain the axion-photon\ncoupling parameter, $g_{\\rm a\\gamma}$, from the long-term monitoring data of\nthe low-frequency magnetic fields, resulting in a significant improvement from\nthe previous constraints down to $g_{\\rm a\\gamma} \\lesssim\n4\\times10^{-13}\\,{\\rm GeV}^{-1}$ for axion mass $\\sim 3 \\times 10^{-14}\\,{\\rm\neV}$.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO","published":"2025-04-09T07:42:28Z"}
{"aid":"http://arxiv.org/abs/2504.06665v1","title":"Rational points of bounded height on entire curves","summary":"Let $X$ be an affine or a projective variety defined over a number field $K$\nand $\\varphi:{\\bf C}\\to X({\\bf C})$ be a holomorphic map with Zariski dense\nimage. We estimate the number of rational points of height bounded by $H$ in\nthe image of a disk of radius $r$ in terms of the the Nevanlinna characteristic\nfunction of $\\varphi$ and $H$ in a way which generalize the classical\nBombieri--Pila estimate to expanding domains. In general this bound is\nexponential but we show that for many values of $H$ and $r$, the bound is\npolynomial.","main_category":"math.NT","categories":"math.NT,math.AG","published":"2025-04-09T07:58:58Z"}
{"aid":"http://arxiv.org/abs/2504.06680v1","title":"Deep Learning for Cardiovascular Risk Assessment: Proxy Features from\n  Carotid Sonography as Predictors of Arterial Damage","summary":"In this study, hypertension is utilized as an indicator of individual\nvascular damage. This damage can be identified through machine learning\ntechniques, providing an early risk marker for potential major cardiovascular\nevents and offering valuable insights into the overall arterial condition of\nindividual patients. To this end, the VideoMAE deep learning model, originally\ndeveloped for video classification, was adapted by finetuning for application\nin the domain of ultrasound imaging. The model was trained and tested using a\ndataset comprising over 31,000 carotid sonography videos sourced from the\nGutenberg Health Study (15,010 participants), one of the largest prospective\npopulation health studies. This adaptation facilitates the classification of\nindividuals as hypertensive or non-hypertensive (75.7% validation accuracy),\nfunctioning as a proxy for detecting visual arterial damage. We demonstrate\nthat our machine learning model effectively captures visual features that\nprovide valuable insights into an individual's overall cardiovascular health.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T08:38:17Z"}
{"aid":"http://arxiv.org/abs/2504.06683v1","title":"Hyperparameter Optimisation with Practical Interpretability and\n  Explanation Methods in Probabilistic Curriculum Learning","summary":"Hyperparameter optimisation (HPO) is crucial for achieving strong performance\nin reinforcement learning (RL), as RL algorithms are inherently sensitive to\nhyperparameter settings. Probabilistic Curriculum Learning (PCL) is a\ncurriculum learning strategy designed to improve RL performance by structuring\nthe agent's learning process, yet effective hyperparameter tuning remains\nchallenging and computationally demanding. In this paper, we provide an\nempirical analysis of hyperparameter interactions and their effects on the\nperformance of a PCL algorithm within standard RL tasks, including point-maze\nnavigation and DC motor control. Using the AlgOS framework integrated with\nOptuna's Tree-Structured Parzen Estimator (TPE), we present strategies to\nrefine hyperparameter search spaces, enhancing optimisation efficiency.\nAdditionally, we introduce a novel SHAP-based interpretability approach\ntailored specifically for analysing hyperparameter impacts, offering clear\ninsights into how individual hyperparameters and their interactions influence\nRL performance. Our work contributes practical guidelines and interpretability\ntools that significantly improve the effectiveness and computational\nfeasibility of hyperparameter optimisation in reinforcement learning.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-09T08:41:27Z"}
{"aid":"http://arxiv.org/abs/2504.06685v1","title":"Testing Multivariate Conditional Independence Using Exchangeable\n  Sampling and Sufficient Statistics","summary":"We consider testing multivariate conditional independence between a response\nY and a covariate vector X given additional variables Z. We introduce the\nMultivariate Sufficient Statistic Conditional Randomization Test (MS-CRT),\nwhich generates exchangeable copies of X by conditioning on sufficient\nstatistics of P(X|Z). MS-CRT requires no modelling assumption on Y and\naccommodates any test statistics, including those derived from complex\npredictive models. It relaxes the assumptions of standard conditional\nrandomization tests by allowing more unknown parameters in P(X|Z) than the\nsample size. MS-CRT avoids multiplicity corrections and effectively detects\njoint signals, even when individual components of X have only weak effects on Y\n. Our method extends to group selection with false discovery rate control. We\ndevelop efficient implementations for two important cases where P(X,Z) is\neither multivariate normal or belongs to a graphical model. For normal models,\nwe establish the minimax rate optimality. For graphical models, we demonstrate\nthe superior performance of our method compared to existing methods through\ncomprehensive simulations and real-data examples.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-09T08:42:18Z"}
{"aid":"http://arxiv.org/abs/2504.06689v1","title":"Les Houches 2023 -- Physics at TeV Colliders: Report on the Standard\n  Model Precision Wishlist","summary":"Les Houches returned to an in-person format in 2023 and the bi-yearly\ntradition of updating the standard model precision wishlist has continued. In\nthis work we review recent progress (since Les Houches 2021) in fixed-order\ncomputations for LHC applications. In addition, necessary ingredients for such\ncalculations such as parton distribution functions, amplitudes, and subtraction\nmethods are discussed. Finally, we indicate processes and missing higher-order\ncorrections that are required to reach the theoretical accuracy that matches\nthe anticipated experimental precision.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-09T08:50:05Z"}
{"aid":"http://arxiv.org/abs/2504.06706v1","title":"Learning-Inspired Fuzzy Logic Algorithms for Enhanced Control of\n  Oscillatory Systems","summary":"The transportation of sensitive equipment often suffers from vibrations\ncaused by terrain, weather, and motion speed, leading to inefficiencies and\npotential damage. To address this challenge, this paper explores an intelligent\ncontrol framework leveraging fuzzy logic, a foundational AI technique, to\nsuppress oscillations in suspension systems. Inspired by learning based\nmethodologies, the proposed approach utilizes fuzzy inference and Gaussian\nmembership functions to emulate adaptive, human like decision making. By\nminimizing the need for explicit mathematical models, the method demonstrates\nrobustness in both linear and nonlinear systems. Experimental validation\nhighlights the controllers ability to adapt to varying suspension lengths,\nreducing oscillation amplitudes and improving stability under dynamic\nconditions. This research bridges the gap between traditional control systems\nand learning inspired techniques, offering a scalable, data efficient solution\nfor modern transportation challenges","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-09T09:09:22Z"}
{"aid":"http://arxiv.org/abs/2504.06722v1","title":"Plastic tensor networks for interpretable generative modeling","summary":"A structural optimization scheme for a single-layer nonnegative adaptive\ntensor tree (NATT) that models a target probability distribution is proposed.\nThe NATT scheme, by construction, has the advantage that it is interpretable as\na probabilistic graphical model. We consider the NATT scheme and a recently\nproposed Born machine adaptive tensor tree (BMATT) optimization scheme and\ndemonstrate their effectiveness on a variety of generative modeling tasks where\nthe objective is to infer the hidden structure of a provided dataset. Our\nresults show that in terms of minimizing the negative log-likelihood, the\nsingle-layer scheme has model performance comparable to the Born machine\nscheme, though not better. The tasks include deducing the structure of binary\nbitwise operations, learning the internal structure of random Bayesian networks\ngiven only visible sites, and a real-world example related to hierarchical\nclustering where a cladogram is constructed from mitochondrial DNA sequences.\nIn doing so, we also show the importance of the choice of network topology and\nthe versatility of a least-mutual information criterion in selecting a\ncandidate structure for a tensor tree, as well as discuss aspects of these\ntensor tree generative models including their information content and\ninterpretability.","main_category":"cs.LG","categories":"cs.LG,cond-mat.stat-mech","published":"2025-04-09T09:23:11Z"}
{"aid":"http://arxiv.org/abs/2504.06725v1","title":"Using theory-driven Integrated Population Models to evaluate competitive\n  outcomes in stage-structured systems","summary":"Predicting competitive outcomes typically requires fitting dynamical models\nto data, from which interaction strengths and coexistence indicators such as\ninvasion criteria can be produced. Methods that allow to propagate parameter\nuncertainty are particularly indicated. These should ideally allow for\ncompetition between and within species at various life-stages, and make the\nbest out of multiple data sources, each of which can be relatively scarce by\nstatistical standards. Here, we embed a mathematical model of stage-structured\ncompetition between two species, producing analytical invasion criteria, into a\ntwo-species Integrated Population Model. The community-level IPM allows to\ncombine counts, capture-recapture, and fecundity data into a single statistical\nframework, and the Bayesian formulation of the IPM fully propagates parameter\nuncertainty into invasion criteria. Model fitting demonstrates that we can\ncorrectly predict coexistence through reciprocal invasion when present, but\nthat interaction strengths are not always estimable, depending on the prior\nchosen. Our competitive exclusion scenario is shown to be harder to identify,\nalthough our model allows to at least flag this scenario as uncertain rather\nthan mistakenly present it as coexistence. Our results confirm the importance\nof accounting for uncertainty in the prediction of competitive outcomes.","main_category":"q-bio.PE","categories":"q-bio.PE,stat.AP,stat.ME","published":"2025-04-09T09:30:21Z"}
{"aid":"http://arxiv.org/abs/2504.06734v1","title":"Locally Repairable Convertible Codes: Improved Lower Bound and General\n  Construction","summary":"In this paper, we consider the convertible code with locally repairable\nproperty. We present an improved lower bound on access cost associated with\n$(r,\\delta)$. Then, we provide a general construction of convertible codes with\noptimal access cost which shows that those codes can be with super-linear\nlength or maximum repairable property. Additionally, employing the known\nlocally repairable codes with super-linear length or maximum repairable\nproperty, we provide explicit constructions of convertible codes with\nsuper-linear length or maximum repairable property.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-09T09:46:08Z"}
{"aid":"http://arxiv.org/abs/2504.06737v1","title":"Urysohn width of hypersurfaces and positive macroscopic scalar curvature","summary":"We prove that if a complete Riemannian $n$-manifold with non-trivial\ncodimension 1 homology with $\\mathbb{Z}_2$-coefficients or\n$\\mathbb{Z}$-coefficients has positive macroscopic scalar curvature large\nenough, then it contains a non-nullhomologous hypersurface of small Urysohn\n$(n-2)$-width. This constitutes a macroscopic analogue of a theorem by\nBray--Brendle--Neves on the area of non-contractible 2-spheres in a closed\nRiemannian 3-manifold with positive scalar curvature. Our proof is based on an\nadaptation of Guth's macroscopic version of the Schoen-Yau descent argument.","main_category":"math.DG","categories":"math.DG","published":"2025-04-09T09:51:03Z"}
{"aid":"http://arxiv.org/abs/2504.06739v1","title":"Selective Kondo screening and strange metallicity by sliding Dirac\n  semimetals","summary":"Kondo screening of local moments in normal metals typically leads to\nhybridized conduction and valence bands separated by a Kondo gap, resulting in\nan insulating state at half-band filling. We show a dramatic change of this\nscenario in a Dirac-semimetal-based correlated system -- a bilayer honeycomb\nlattice heterostructure where the local moment lattice is stacked on a Dirac\nsemimetal breaking the inversion symmetry. This system is modeled by an\nextended Anderson honeycomb lattice involving the real-space dependence of\nmajor interlayer hybridization parameters on the relative sliding distance\nalong the armchair direction. First, we unveil the multiple Kondo scales and\nthe successive Kondo breakdown transitions in this correlated heterostructure\nunder sliding. Second, we demonstrate the existence of a genuine selective\nKondo screening phase which is stabilized near the A-B stack pattern and is\naccessible by applying the interlayer voltage. Third, we find a nearly flat\nhybridized band located concomitantly within the Kondo gap, resulting in an\nunprecedented metallic state at the half-band filling. This unconventional\nheavy fermion state is characterized by the violation of Luttinger theorem and\nthe appearance of a Van Hove singularity at the Fermi energy. The general\nsliding-driven band structure landscape and the implications of our results for\nthe broad context of multiorbital Kondo physics are briefly discussed.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-09T09:51:47Z"}
{"aid":"http://arxiv.org/abs/2504.06748v1","title":"Efficient Deployment of Spiking Neural Networks on SpiNNaker2 for DVS\n  Gesture Recognition Using Neuromorphic Intermediate Representation","summary":"Spiking Neural Networks (SNNs) are highly energy-efficient during inference,\nmaking them particularly suitable for deployment on neuromorphic hardware.\nTheir ability to process event-driven inputs, such as data from dynamic vision\nsensors (DVS), further enhances their applicability to edge computing tasks.\nHowever, the resource constraints of edge hardware necessitate techniques like\nweight quantization, which reduce the memory footprint of SNNs while preserving\naccuracy. Despite its importance, existing quantization methods typically focus\non synaptic weights quantization without taking account of other critical\nparameters, such as scaling neuron firing thresholds.\n  To address this limitation, we present the first benchmark for the DVS\ngesture recognition task using SNNs optimized for the many-core neuromorphic\nchip SpiNNaker2. Our study evaluates two quantization pipelines for fixed-point\ncomputations. The first approach employs post training quantization (PTQ) with\npercentile-based threshold scaling, while the second uses quantization aware\ntraining (QAT) with adaptive threshold scaling. Both methods achieve accurate\n8-bit on-chip inference, closely approximating 32-bit floating-point\nperformance. Additionally, our baseline SNNs perform competitively against\npreviously reported results without specialized techniques. These models are\ndeployed on SpiNNaker2 using the neuromorphic intermediate representation\n(NIR). Ultimately, we achieve 94.13% classification accuracy on-chip,\ndemonstrating the SpiNNaker2's potential for efficient, low-energy neuromorphic\ncomputing.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T10:09:29Z"}
{"aid":"http://arxiv.org/abs/2504.06749v1","title":"Evidence of star cluster migration and merger in dwarf galaxies","summary":"Nuclear star clusters (NSCs) are the densest stellar systems in the Universe.\nThey can be found at the center of all galaxy types, but tend to favor galaxies\nof intermediate stellar mass around 10$^9\\,$M$_{\\odot}$[1, 2]. Currently, two\nmain processes are under debate to explain their formation: in-situ\nstar-formation from gas infall[3] and migration and merging of globular\nclusters (GCs) caused by dynamical friction[4]. Studies[5-9] of NSC stellar\npopulations suggest that the former predominates in massive galaxies, the\nlatter prevails in dwarf galaxies, and both contribute equally at intermediate\nmass. However, up to now, no ongoing merger of GCs has yet been observed to\nconfirm this scenario. Here we report the serendipitous discovery of five dwarf\ngalaxies with complex nuclear regions, characterized by multiple nuclei and\ntidal tails, using high resolution images from the Hubble Space Telescope.\nThese structures have been reproduced in complementary N-body simulations,\nsupporting the interpretation that they result from migrating and merging of\nstar clusters. The small detection rate and short simulated timescales (below\n100 Myr) of this process may explain why this has not been observed previously.\nThis study highlights the need of large surveys with high resolution to fully\nmap the migration scenario steps.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-09T10:12:37Z"}
{"aid":"http://arxiv.org/abs/2504.06750v1","title":"Robust Capacity Expansion Modelling for Renewable Energy Systems under\n  Weather and Demand Uncertainty","summary":"Future greenhouse gas neutral energy systems will be dominated by variable\nrenewable energy technologies. However, renewable electricity generation from\nwind and solar technologies, as well as electricity demand, varies with the\nweather. This work addresses the problem of determining optimal capacities for\nrenewable technologies in energy systems that ensure sufficient electricity\nsupply when dealing with multi-year time-series data. An iterative algorithm is\nproposed that starts by optimising an arbitrary starting time-series, followed\nby adding additional constraints and reoptimising the modified optimisation\nproblem until sufficient energy supply is provided for all time--series, i.e.\nthe solution is robust to weather and demand variations. This is evaluated in a\ncomputational study on a German energy system model.The results show that the\niterative algorithm finds robust solutions for an increase of 2-2.5% in total\nannual cost for a simplified model in gurobipy and 2.9% for a model built in\nthe model framework ETHOS.FINE. Testing the feasibility for non robust\nsolutions showed that supply gaps occurred in at least some of the remaining\nyears. Based on the results of this work, ensuring feasibility within an energy\nsystem model for multiple time-series boils down to two factors: ensuring\nsufficient back-up capacity to overcome periods of high demand combined with\nlow electricity generation from wind and photovoltaic, and enforcing sufficient\ntotal annual electricity generation. Our proposed open source iterative\nalgorithm is able to ensure this. For general modelling, it is recommended to\ncheck for systematic effects of different years' time--series on energy system\nmodels especially for wind, but also for photovoltaics, include dark lull and\ncold period effects on generation and demand in time--series, and assess the\nfeasibility of energy system models using different time-series.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY,I.6","published":"2025-04-09T10:13:46Z"}
{"aid":"http://arxiv.org/abs/2504.06752v1","title":"Compass Control: Multi Object Orientation Control for Text-to-Image\n  Generation","summary":"Existing approaches for controlling text-to-image diffusion models, while\npowerful, do not allow for explicit 3D object-centric control, such as precise\ncontrol of object orientation. In this work, we address the problem of\nmulti-object orientation control in text-to-image diffusion models. This\nenables the generation of diverse multi-object scenes with precise orientation\ncontrol for each object. The key idea is to condition the diffusion model with\na set of orientation-aware \\textbf{compass} tokens, one for each object, along\nwith text tokens. A light-weight encoder network predicts these compass tokens\ntaking object orientation as the input. The model is trained on a synthetic\ndataset of procedurally generated scenes, each containing one or two 3D assets\non a plain background. However, direct training this framework results in poor\norientation control as well as leads to entanglement among objects. To mitigate\nthis, we intervene in the generation process and constrain the cross-attention\nmaps of each compass token to its corresponding object regions. The trained\nmodel is able to achieve precise orientation control for a) complex objects not\nseen during training and b) multi-object scenes with more than two objects,\nindicating strong generalization capabilities. Further, when combined with\npersonalization methods, our method precisely controls the orientation of the\nnew object in diverse contexts. Our method achieves state-of-the-art\norientation control and text alignment, quantified with extensive evaluations\nand a user study.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T10:15:15Z"}
{"aid":"http://arxiv.org/abs/2504.06753v1","title":"Detect All-Type Deepfake Audio: Wavelet Prompt Tuning for Enhanced\n  Auditory Perception","summary":"The rapid advancement of audio generation technologies has escalated the\nrisks of malicious deepfake audio across speech, sound, singing voice, and\nmusic, threatening multimedia security and trust. While existing\ncountermeasures (CMs) perform well in single-type audio deepfake detection\n(ADD), their performance declines in cross-type scenarios. This paper is\ndedicated to studying the alltype ADD task. We are the first to comprehensively\nestablish an all-type ADD benchmark to evaluate current CMs, incorporating\ncross-type deepfake detection across speech, sound, singing voice, and music.\nThen, we introduce the prompt tuning self-supervised learning (PT-SSL) training\nparadigm, which optimizes SSL frontend by learning specialized prompt tokens\nfor ADD, requiring 458x fewer trainable parameters than fine-tuning (FT).\nConsidering the auditory perception of different audio types,we propose the\nwavelet prompt tuning (WPT)-SSL method to capture type-invariant auditory\ndeepfake information from the frequency domain without requiring additional\ntraining parameters, thereby enhancing performance over FT in the all-type ADD\ntask. To achieve an universally CM, we utilize all types of deepfake audio for\nco-training. Experimental results demonstrate that WPT-XLSR-AASIST achieved the\nbest performance, with an average EER of 3.58% across all evaluation sets. The\ncode is available online.","main_category":"cs.SD","categories":"cs.SD,cs.AI","published":"2025-04-09T10:18:45Z"}
{"aid":"http://arxiv.org/abs/2504.06755v1","title":"FANeRV: Frequency Separation and Augmentation based Neural\n  Representation for Video","summary":"Neural representations for video (NeRV) have gained considerable attention\nfor their strong performance across various video tasks. However, existing NeRV\nmethods often struggle to capture fine spatial details, resulting in vague\nreconstructions. In this paper, we present a Frequency Separation and\nAugmentation based Neural Representation for video (FANeRV), which addresses\nthese limitations with its core Wavelet Frequency Upgrade Block.This block\nexplicitly separates input frames into high and low-frequency components using\ndiscrete wavelet transform, followed by targeted enhancement using specialized\nmodules. Finally, a specially designed gated network effectively fuses these\nfrequency components for optimal reconstruction. Additionally, convolutional\nresidual enhancement blocks are integrated into the later stages of the network\nto balance parameter distribution and improve the restoration of high-frequency\ndetails. Experimental results demonstrate that FANeRV significantly improves\nreconstruction performance and excels in multiple tasks, including video\ncompression, inpainting, and interpolation, outperforming existing NeRV\nmethods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T10:19:35Z"}
{"aid":"http://arxiv.org/abs/2504.06756v1","title":"Preservation of notion of C sets near zero over reals","summary":"There are several notions of largeness in a semigroup. N. Hindman and D.\nStrauss established that if $u,v \\in \\mathbb{N}$, $A$ is a $u \\times v$ matrix\nwith entries from $\\mathbb{Q}$ and $\\psi$ is a notion of a large set in\n$\\mathbb{N}$, then $\\{\\vec{x} \\in \\mathbb{N}^v: A\\vec{x} \\in \\psi^u \\}$ is\nlarge in $\\mathbb{N}^v$. Among the several notions of largeness, C sets\noccupies an important place of study because they exhibit strong combinatorial\nproperties. The analogous notion of C set appears for a dense subsemigroup $S$\nof $((0, \\infty),+)$ called a C-set near zero. These sets also have very rich\ncombinatorial structure. In this article, we investigate the above result for C\nsets near zero in $\\mathbb{R}^+$ when the matrix has real entries. We also\ndevelop a new characterisation of C-sets near zero in $\\mathbb{R}^+$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-09T10:19:57Z"}
{"aid":"http://arxiv.org/abs/2504.06762v1","title":"Matching and Edge Cover in Temporal Graphs","summary":"Temporal graphs are a special class of graphs for which a temporal component\nis added to edges, that is, each edge possesses a set of times at which it is\navailable and can be traversed. Many classical problems on graphs can be\ntranslated to temporal graphs, and the results may differ. In this paper, we\ndefine the Temporal Edge Cover and Temporal Matching problems and show that\nthey are NP-complete even when fixing the lifetime or when the underlying graph\nis a tree. We then describe two FPT algorithms, with parameters lifetime and\ntreewidth, that solve the two problems. We also find lower bounds for the\napproximation of the two problems and give two approximation algorithms which\nmatch these bounds. Finally, we discuss the differences between the problems in\nthe temporal and the static framework.","main_category":"cs.DS","categories":"cs.DS,cs.CC","published":"2025-04-09T10:33:10Z"}
{"aid":"http://arxiv.org/abs/2504.06763v1","title":"Convergence of a continuous Galerkin method for the Biot-Allard\n  poroelasticity system","summary":"We study a space-time finite element method for a system of poromechanics\nwith memory effects that are modeled by a convolution integral. In the\nliterature, the system is referred to as the Biot-Allard model. We recast the\nmodel as a first-order system in time, where the memory effects are transformed\ninto an auxiliary differential equation. This allows for a computationally\nefficient numerical scheme. The system is discretized by continuous Galerkin\nmethods in time and equal-order finite element methods in space. An optimal\norder error estimate is proved for the norm of the first-order energy of the\nunknowns of the system. The estimate is confirmed by numerical experiments.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-09T10:38:13Z"}
{"aid":"http://arxiv.org/abs/2504.06771v1","title":"AI, Help Me Think$\\unicode{x2014}$but for Myself: Assisting People in\n  Complex Decision-Making by Providing Different Kinds of Cognitive Support","summary":"How can we design AI tools that effectively support human decision-making by\ncomplementing and enhancing users' reasoning processes? Common\nrecommendation-centric approaches face challenges such as inappropriate\nreliance or a lack of integration with users' decision-making processes. Here,\nwe explore an alternative interaction model in which the AI outputs build upon\nusers' own decision-making rationales. We compare this approach, which we call\nExtendAI, with a recommendation-based AI. Participants in our mixed-methods\nuser study interacted with both AIs as part of an investment decision-making\ntask. We found that the AIs had different impacts, with ExtendAI integrating\nbetter into the decision-making process and people's own thinking and leading\nto slightly better outcomes. RecommendAI was able to provide more novel\ninsights while requiring less cognitive effort. We discuss the implications of\nthese and other findings along with three tensions of AI-assisted\ndecision-making which our study revealed.","main_category":"cs.HC","categories":"cs.HC,cs.AI","published":"2025-04-09T10:48:17Z"}
{"aid":"http://arxiv.org/abs/2504.06788v1","title":"FOREVER22: Insights into star formation and clustering properties of\n  protoclusters from simulations and JWST","summary":"Using cosmological hydrodynamic simulations with radiative transfer, we\ninvestigate star formation and overdensity ($\\delta$) in Coma-type cluster\nprogenitors from $z=14$ to 6. Our simulations reproduce observed $M_{\\rm\nstar}$-SFR relations and $\\delta$ at these redshifts. We find: (1) protocluster\n(PC) and mean-density field (MF) galaxies show similar $M_{\\rm star}$-SFR\nrelations, with PC galaxies extending to higher $M_{\\rm star}$ and SFR. (2)\nUV-bright PC galaxies ($M_{\\rm UV}\\lesssim -20$~mag) have $>2$ mag higher UV\nattenuation and shallower UV slopes than MF galaxies. (3) $\\delta$ increases\nwith redshift, depending on observational parameters (e.g., $\\delta\\sim50$ at\n$z=14$ to $\\delta\\sim3$ at $z=6$ for a search volume of $\\sim3000$~cMpc$^3$ and\na limiting magnitude of $M_{\\rm UV}=-17$~mag). These results indicate that\nenhanced star formation in PCs is driven by massive galaxy overdensity, not\nanomalously high specific SFR. While simulated $\\delta$ agrees with observed PC\ncandidates (potential Coma progenitors), some MF galaxies show comparable\n$\\delta$. We propose a robust PC identification method using both $\\delta$ and\n$M_{\\rm star}$ of the most massive member. Critical $M_{\\rm star}$ thresholds\nfor Coma progenitors are estimated ($10^{7.1}$ to $10^{10.2}$ M$_\\odot$ from\n$z=14$ to 6). Comparison with JWST observations suggests GS-z14-0 and GS-z14-1,\nthe current highest redshift holders, are likely progenitors of Coma-type\nclusters.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-04-09T11:20:49Z"}
{"aid":"http://arxiv.org/abs/2504.06790v1","title":"Analog Computing with Microwave Networks","summary":"Analog computing has been recently revived due to its potential for\nenergy-efficient and highly parallel computations. In this paper, we\ninvestigate analog computers that linearly process microwave signals, named\nmicrowave linear analog computers (MiLACs), and their applications in signal\nprocessing for communications. We model a MiLAC as a multiport microwave\nnetwork with tunable impedance components, which enables the execution of\nmathematical operations by reconfiguring the microwave network and applying\ninput signals at its ports. We demonstrate that a MiLAC can efficiently compute\nthe linear minimum mean square error (LMMSE) estimator, widely used in\nmultiple-input multiple-output (MIMO) communications beamforming and detection,\nwith remarkably low computational complexity, unachievable through digital\ncomputing. Specifically, the LMMSE estimator can be computed with complexity\ngrowing with the square of its input size, rather than the cube, with\nrevolutionary applications to gigantic MIMO beamforming and detection.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-09T11:29:39Z"}
{"aid":"http://arxiv.org/abs/2504.06791v1","title":"Beware of \"Explanations\" of AI","summary":"Understanding the decisions made and actions taken by increasingly complex AI\nsystem remains a key challenge. This has led to an expanding field of research\nin explainable artificial intelligence (XAI), highlighting the potential of\nexplanations to enhance trust, support adoption, and meet regulatory standards.\nHowever, the question of what constitutes a \"good\" explanation is dependent on\nthe goals, stakeholders, and context. At a high level, psychological insights\nsuch as the concept of mental model alignment can offer guidance, but success\nin practice is challenging due to social and technical factors. As a result of\nthis ill-defined nature of the problem, explanations can be of poor quality\n(e.g. unfaithful, irrelevant, or incoherent), potentially leading to\nsubstantial risks. Instead of fostering trust and safety, poorly designed\nexplanations can actually cause harm, including wrong decisions, privacy\nviolations, manipulation, and even reduced AI adoption. Therefore, we caution\nstakeholders to beware of explanations of AI: while they can be vital, they are\nnot automatically a remedy for transparency or responsible AI adoption, and\ntheir misuse or limitations can exacerbate harm. Attention to these caveats can\nhelp guide future research to improve the quality and impact of AI\nexplanations.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T11:31:08Z"}
{"aid":"http://arxiv.org/abs/2504.06803v1","title":"DyDiT++: Dynamic Diffusion Transformers for Efficient Visual Generation","summary":"Diffusion Transformer (DiT), an emerging diffusion model for visual\ngeneration, has demonstrated superior performance but suffers from substantial\ncomputational costs. Our investigations reveal that these costs primarily stem\nfrom the \\emph{static} inference paradigm, which inevitably introduces\nredundant computation in certain \\emph{diffusion timesteps} and \\emph{spatial\nregions}. To overcome this inefficiency, we propose \\textbf{Dy}namic\n\\textbf{Di}ffusion \\textbf{T}ransformer (DyDiT), an architecture that\n\\emph{dynamically} adjusts its computation along both \\emph{timestep} and\n\\emph{spatial} dimensions. Specifically, we introduce a \\emph{Timestep-wise\nDynamic Width} (TDW) approach that adapts model width conditioned on the\ngeneration timesteps. In addition, we design a \\emph{Spatial-wise Dynamic\nToken} (SDT) strategy to avoid redundant computation at unnecessary spatial\nlocations. TDW and SDT can be seamlessly integrated into DiT and significantly\naccelerates the generation process. Building on these designs, we further\nenhance DyDiT in three key aspects. First, DyDiT is integrated seamlessly with\nflow matching-based generation, enhancing its versatility. Furthermore, we\nenhance DyDiT to tackle more complex visual generation tasks, including video\ngeneration and text-to-image generation, thereby broadening its real-world\napplications. Finally, to address the high cost of full fine-tuning and\ndemocratize technology access, we investigate the feasibility of training DyDiT\nin a parameter-efficient manner and introduce timestep-based dynamic LoRA\n(TD-LoRA). Extensive experiments on diverse visual generation models, including\nDiT, SiT, Latte, and FLUX, demonstrate the effectiveness of DyDiT.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T11:48:37Z"}
{"aid":"http://arxiv.org/abs/2504.06805v1","title":"Robust Classification with Noisy Labels Based on Posterior Maximization","summary":"Designing objective functions robust to label noise is crucial for real-world\nclassification algorithms. In this paper, we investigate the robustness to\nlabel noise of an $f$-divergence-based class of objective functions recently\nproposed for supervised classification, herein referred to as $f$-PML. We show\nthat, in the presence of label noise, any of the $f$-PML objective functions\ncan be corrected to obtain a neural network that is equal to the one learned\nwith the clean dataset. Additionally, we propose an alternative and novel\ncorrection approach that, during the test phase, refines the posterior\nestimated by the neural network trained in the presence of label noise. Then,\nwe demonstrate that, even if the considered $f$-PML objective functions are not\nsymmetric, they are robust to symmetric label noise for any choice of\n$f$-divergence, without the need for any correction approach. This allows us to\nprove that the cross-entropy, which belongs to the $f$-PML class, is robust to\nsymmetric label noise. Finally, we show that such a class of objective\nfunctions can be used together with refined training strategies, achieving\ncompetitive performance against state-of-the-art techniques of classification\nwith label noise.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T11:52:51Z"}
{"aid":"http://arxiv.org/abs/2504.06809v1","title":"Modeling and analysis methods for early detection of leakage points in\n  gas transmission systems","summary":"Early detection of leaks in gas transmission systems is crucial for ensuring\nuninterrupted gas supply, enhancing operational efficiency, and minimizing\nenvironmental and economic risks. This study aims to develop an analytical\nmethod for accurately identifying leak locations in gas pipelines based on\nunsteady gas flow dynamics. A novel approach is proposed that utilizes pressure\nvariations at the inlet and outlet points to determine the minimum fixation\ntime (t = t1) required for real-time leak detection. Through mathematical\nmodeling and numerical analysis, the study demonstrates that the ratio of\npressure drops at different points along the pipeline can be effectively used\nto pinpoint leakage locations. The results indicate that the proposed method\nsignificantly improves detection accuracy and response time, making it a viable\nsolution for integration into gas pipeline monitoring and control systems.","main_category":"math.OC","categories":"math.OC","published":"2025-04-09T11:59:24Z"}
{"aid":"http://arxiv.org/abs/2504.06828v1","title":"New physics particles mixing with mesons: production in the\n  fragmentation chain","summary":"A class of extensions to the Standard Model adds hypothetical long-lived\nparticles (LLPs) that have mass- or kinetic-mixing with neutral mesons, such as\npions or rho mesons. The mixing can contribute significantly to the production\nof LLPs at proton accelerator experiments, and no consistent description of\nthese production modes exists in the literature. In this paper, we develop a\nframework for studying different LLPs - dark photons, vector mediators coupled\nto the baryon current, and axion-like particles with different coupling\npatterns. In particular, we implement the production mechanisms in\n\\texttt{PYTHIA8}, study how the overall flux and kinematic distributions depend\non the LLP's mass, and compare various sub-processes where the mixing\ncontributes - proton bremsstrahlung, meson decay, and production in the\nfragmentation chain. We find that our new description of LLP production\npredicts an integrated flux that differs from current approaches by one to two\norders of magnitude, and highlight the unavoidable theoretical uncertainties\ncoming from poor knowledge of the properties of heavy mesons.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-09T12:37:46Z"}
{"aid":"http://arxiv.org/abs/2504.06829v1","title":"Adaptive Locally Linear Embedding","summary":"Manifold learning techniques, such as Locally linear embedding (LLE), are\ndesigned to preserve the local neighborhood structures of high-dimensional data\nduring dimensionality reduction. Traditional LLE employs Euclidean distance to\ndefine neighborhoods, which can struggle to capture the intrinsic geometric\nrelationships within complex data. A novel approach, Adaptive locally linear\nembedding(ALLE), is introduced to address this limitation by incorporating a\ndynamic, data-driven metric that enhances topological preservation. This method\nredefines the concept of proximity by focusing on topological neighborhood\ninclusion rather than fixed distances. By adapting the metric based on the\nlocal structure of the data, it achieves superior neighborhood preservation,\nparticularly for datasets with complex geometries and high-dimensional\nstructures. Experimental results demonstrate that ALLE significantly improves\nthe alignment between neighborhoods in the input and feature spaces, resulting\nin more accurate and topologically faithful embeddings. This approach advances\nmanifold learning by tailoring distance metrics to the underlying data,\nproviding a robust solution for capturing intricate relationships in\nhigh-dimensional datasets.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-09T12:40:13Z"}
{"aid":"http://arxiv.org/abs/2504.06837v1","title":"Discrete-to-continuum limit for nonlinear reaction-diffusion systems via\n  EDP convergence for gradient systems","summary":"We investigate the convergence of spatial discretizations for\nreaction-diffusion systems with mass-action law satisfying a detailed balance\ncondition. Considering systems on the d-dimensional torus, we construct\nappropriate space-discrete processes and show convergence not only on the level\nof solutions, but also on the level of the gradient systems governing the\nevolutions. As an important step, we prove chain rule inequalities for the\nreaction-diffusion systems as well as their discretizations, featuring a\nnon-convex dissipation functional. The convergence is then obtained with\nvariational methods by building on the recently introduced notion of gradient\nsystems in continuity equation format.","main_category":"math.AP","categories":"math.AP,cs.NA,math-ph,math.DS,math.MP,math.NA","published":"2025-04-09T12:51:15Z"}
{"aid":"http://arxiv.org/abs/2504.06839v1","title":"Convergence to the equilibrium for the kinetic transport equation in the\n  two-dimensional periodic Lorentz Gas","summary":"We consider the Boltzmann-Grad limit of the two-dimensional periodic Lorentz\nGas. It has been proved in [6,14,4] that the time evolution of a probability\ndensity on $\\mathbb{R}^2\\times\\mathbb{T}^1\\ni(x,v)$ is obtained by extending\nthe phase space $\\mathbb{R}^2\\times\\mathbb{T}^1$ to\n$\\mathbb{R}^2\\times\\mathbb{T}^1\\times[0,+\\infty)\\times[-1,1]$, where\n$s\\in[0,+\\infty)$ represents the time to the next collision and $h\\in[-1,1]$\nthe corresponding impact parameter. Here we prove that under suitable\nconditions the time evolution of an initial datum in\n$L^p(\\mathbb{T}^2\\times\\mathbb{T}^1\\times[0,+\\infty)\\times[-1,1])$ converges to\nthe equilibrium state with respect to the $L^p$ norm ($^*$-weakly if\n$p=\\infty$). If $p=2$, or if the initial datum does not depend on $x$, we also\nget more precise estimates about the rate of the approach to the equilibrium.\nOur proof is based on the analysis of the long time behavior of the Fourier\ncoefficients of the solution.","main_category":"math-ph","categories":"math-ph,math.AP,math.MP","published":"2025-04-09T12:57:42Z"}
{"aid":"http://arxiv.org/abs/2504.06852v1","title":"Quantum controlling and the topological properties of the magnon\n  photo-transport in two-dimensional collinear ferromagnet","summary":"In our work, we study magnon transport induced by light through\nAharonov-Casher (AC) effect, including magnon spin photocurrent (MSPC) and\nmagnon energy photocurrent (MEPC). Firstly, we regard the effect of the\nelectric field on the magnon through the AC effect as a perturbation. Then we\nderived the expressions of MSPC and MEPC in two-dimensional collinear\nferromagnetic system. And we apply our theory to the two-dimension\nferromagnetic Hexagonal and Kagome lattice. We find that the optical frequency\nand the relaxation time of the material can be used to control the\nphoto-transport of magnons. In addition, under the condition of low light\nfrequncy and infinite relaxation time, the longitudinal magnon photo-transport\nis related to the topological property of the magnon system.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-09T13:06:39Z"}
{"aid":"http://arxiv.org/abs/2504.06853v1","title":"Magnetic ground state discrimination of a Polyradical Nanog-raphene\n  using Nickelocene-Functionalized Tips","summary":"Molecular magnets are a promising class of materials with exciting properties\nand applications. However, a profound understanding and application of such\nmaterials depends on the accurate detection of their electronic and magnetic\nproperties. Despite the availability of experimental techniques that can sense\nthe magnetic signal, the exact determination of the spin ground states and\nspatial distribution of exchange interaction of strongly correlated\nsingle-molecule magnets remains challenging. Here, we demonstrate that scanning\nprobe microscopy with a nickelocene-functionalized probe can distinguish\nbetween nearly degenerate multireference ground states of single-molecule\n{\\pi}-magnets and map their spatial distribution of the exchange interaction.\nThis method expands the already outstanding imaging capabilities of scanning\nprobe microscopy for characterizing the chemical and electronic structures of\nindividual molecules, paving the way for the study of strongly correlated\nmolecular magnets with unprecedented spatial resolution.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-04-09T13:07:03Z"}
{"aid":"http://arxiv.org/abs/2504.06855v1","title":"Compactified moduli spaces and Hecke correspondences for elliptic curves\n  with a prescribed $N$-torsion scheme","summary":"Given an integer $N \\geq 3$, we prove that for any ring $R$ and any finite\nlocally free $R$-group scheme $G$ which is fppf-locally (over $R$) isomorphic\nthe $N$-torsion subscheme of some elliptic curve $E/R$, there is a smooth\naffine curve $Y_G(N)$ parametrizing elliptic curves over $R$-schemes whose\n$N$-torsion subscheme is isomorphic to $G$. We also describe compactifications\n$X_G(N)$ of these curves when $R$ is a regular excellent Noetherian ring in\nwhich $N$ is invertible, as well as construct the Hecke correspondences they\nare endowed with. As an application, we show that the equations for $X_G(N)$\nfound over base fields for $N=7,8,9,11,13$ (by Halberstadt--Kraus,\nPoonen--Schaefer--Stoll, Chen and Fisher) are in fact valid over regular\nexcellent Noetherian bases that are $\\mathbb{Q}$-algebras. Finally, we describe\nin detail the equivalence of this construction with the point of view of Galois\ntwists that these authors use.","main_category":"math.NT","categories":"math.NT,math.AG","published":"2025-04-09T13:07:35Z"}
{"aid":"http://arxiv.org/abs/2504.06860v1","title":"Machine Learning (ML) based Reduced Order Modeling (ROM) for linear and\n  non-linear solid and structural mechanics","summary":"Multiple model reduction techniques have been proposed to tackle linear and\nnon linear problems. Intrusive model order reduction techniques exhibit high\naccuracy levels, however, they are rarely used as a standalone industrial tool,\nbecause of the required high level knowledge involved in the construction and\nusage of these techniques. Moreover, the computation time benefit is\ncompromised for highly nonlinear problems. On the other hand, non-intrusive\nmethods often struggle with accuracy in nonlinear cases, typically requiring a\nlarge design of experiment and a large number of snapshots achieve a reliable\nperformance. However, generating the stiffness matrix in a non-intrusive\napproach presents an optimal way to align accuracy with efficiency, allying the\nadvantages of both intrusive and non-intrusive methods.This work introduces a\nlightly intrusive model order reduction technique that employs machine learning\nwithin a Proper Orthogonal Decomposition framework to achieve this alliance. By\nleveraging outputs from commercial full-order models, this method constructs a\nreduced-order model that operates effectively without requiring expert user\nintervention. The proposed technique has the possibility to approximate linear\nnon affine as well as non linear terms. It is showcased for linear and\nnonlinear structural mechanics problems.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-09T13:11:05Z"}
{"aid":"http://arxiv.org/abs/2504.06869v1","title":"Grouping Strategies on Two-Phase Methods for Bi-objective Combinatorial\n  Optimization","summary":"Two-phase methods are commonly used to solve bi-objective combinatorial\noptimization problems. In the first phase, all extreme supported nondominated\npoints are generated through a dichotomic search. This phase also allows the\nidentification of search zones that may contain other nondominated points. The\nsecond phase focuses on exploring these search zones to locate the remaining\npoints, which typically accounts for most of the computational cost. Ranking\nalgorithms are frequently employed to explore each zone individually, but this\napproach leads to redundancies, causing multiple visits to the same solutions.\nTo mitigate these redundancies, we propose several strategies that group\nadjacent zones, allowing a single run of the ranking algorithm for the entire\ngroup. Additionally, we explore an implicit grouping approach based on a new\nconcept of coverage. Our experiments on the Bi-Objective Spanning Tree Problem\ndemonstrate the beneficial impact of these grouping strategies when combined\nwith coverage.","main_category":"cs.DS","categories":"cs.DS,cs.DM","published":"2025-04-09T13:19:26Z"}
{"aid":"http://arxiv.org/abs/2504.06876v1","title":"Anomalous transport models for fluid classification: insights from an\n  experimentally driven approach","summary":"In recent years, research and development in nanoscale science and technology\nhave grown significantly, with electrical transport playing a key role. A\nnatural challenge for its description is to shed light on anomalous behaviours\nobserved in a variety of low-dimensional systems. We use a synergistic\ncombination of experimental and mathematical modelling to explore the transport\nproperties of the electrical discharge observed within a micro-gap based sensor\nimmersed in fluids with different insulating properties. Data from laboratory\nexperiments are collected and used to inform and calibrate four mathematical\nmodels that comprise partial differential equations describing different kinds\nof transport, including anomalous diffusion: the Gaussian Model with Time\nDependent Diffusion Coefficient, the Porous Medium Equation, the\nKardar-Parisi-Zhang Equation and the Telegrapher Equation. Performance analysis\nof the models through data fitting reveals that the Gaussian Model with a\nTime-Dependent Diffusion Coefficient most effectively describes the observed\nphenomena. This model proves particularly valuable in characterizing the\ntransport properties of electrical discharges when the micro-electrodes are\nimmersed in a wide range of insulating as well as conductive fluids. Indeed, it\ncan suitably reproduce a range of behaviours spanning from clogging to bursts,\nallowing accurate and quite general fluid classification. Finally, we apply the\ndata-driven mathematical modeling approach to ethanol-water mixtures. The\nresults show the model's potential for accurate prediction, making it a\npromising method for analyzing and classifying fluids with unknown insulating\nproperties.","main_category":"q-bio.PE","categories":"q-bio.PE,physics.flu-dyn","published":"2025-04-09T13:26:47Z"}
{"aid":"http://arxiv.org/abs/2504.06877v1","title":"Dissipation and noise in strongly driven Josephson junctions","summary":"In circuit quantum electrodynamics systems, the quasiparticle-related losses\nin Josephson junctions are suppressed due to the gap in the superconducting\ndensity of states which is much higher than the typical energy of a microwave\nphoton. In this work, we show that a strong drive even at frequency lower than\nthe double superconducting gap enables dissipation in the junctions due to\nphoton-assisted breaking of the Cooper pairs. Both the decay rate and noise\nstrength associated with the losses are sensitive to the dc phase bias of the\njunction and can be tuned in a broad range by the amplitude and the frequency\nof the external driving field, making the suggested mechanism potentially\nattractive for designing tunable dissipative elements. Furthermore, pronounced\nmemory effects in the driven Josephson junctions render them perspective for\nboth theoretical and experimental study of non-Markovian physics in\nsuperconducting quantum circuits. We illustrate our theoretical findings by\nstudying the spectral properties and the steady state population of a low\nimpedance resonator coupled to the driven Josephson junction.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T13:31:18Z"}
{"aid":"http://arxiv.org/abs/2504.06882v1","title":"Brillouin Platycosms and Topological Phases","summary":"There exist ten distinct closed flat $3$D manifolds, known as platycosms,\nwhich hold significance in mathematics and have been postulated as potential\ngeometric models for our universe. In this work, we demonstrate their\nmanifestation as universes of Bloch particles, namely as momentum-space units\nreferred to as Brillouin platycosms, which are natural extensions of the\nBrillouin torus within a broader framework of projective crystallographic\nsymmetries. Moreover, we provide exact K-theoretical classifications of\ntopological insulators over these platycosms by the Atiyah-Hirzebruch spectral\nsequence, and formulate a complete set of topological invariants for their\nidentification. Topological phase transitions are generically characterized by\nWeyl semimetals, adhering to the generalized Nielsen-Ninomiya theorem: the\ntotal chirality number over a Brillouin platycosm is even (zero) if the\nplatycosm is non-orientable (orientable). Our work generalizes the notion of\nBrillouin torus to ten Brillouin platycosms and therefore fundamentally\ndiversifies the stages on which Block wavefunctions can perform their\ntopological dance.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-09T13:36:41Z"}
{"aid":"http://arxiv.org/abs/2504.06894v1","title":"AI-Driven Consensus: Modeling Multi-Agent Networks with Long-Range\n  Interactions through path-Laplacian Matrices","summary":"Extended connectivity in graphs can be analyzed through k-path Laplacian\nmatrices, which permit the capture of long-range interactions in various\nreal-world networked systems such as social, transportation, and multi-agent\nnetworks. In this work, we present several alternative methods based on machine\nlearning methods (LSTM, xLSTM, Transformer, XGBoost, and ConvLSTM) to predict\nthe final consensus value based on directed networks (Erd\\\"os-Renyi,\nWatts-Strogatz, and Barab\\'asi-Albert) and on the initial state. We highlight\nhow different k-hop interactions affect the performance of the tested methods.\nThis framework opens new avenues for analyzing multi-scale diffusion processes\nin large-scale, complex networks.","main_category":"cs.SI","categories":"cs.SI,cs.MA","published":"2025-04-09T13:53:57Z"}
{"aid":"http://arxiv.org/abs/2504.06895v1","title":"ColorizeDiffusion v2: Enhancing Reference-based Sketch Colorization\n  Through Separating Utilities","summary":"Reference-based sketch colorization methods have garnered significant\nattention due to their potential applications in the animation production\nindustry. However, most existing methods are trained with image triplets of\nsketch, reference, and ground truth that are semantically and spatially\nwell-aligned, while real-world references and sketches often exhibit\nsubstantial misalignment. This mismatch in data distribution between training\nand inference leads to overfitting, consequently resulting in spatial artifacts\nand significant degradation in overall colorization quality, limiting potential\napplications of current methods for general purposes. To address this\nlimitation, we conduct an in-depth analysis of the \\textbf{carrier}, defined as\nthe latent representation facilitating information transfer from reference to\nsketch. Based on this analysis, we propose a novel workflow that dynamically\nadapts the carrier to optimize distinct aspects of colorization. Specifically,\nfor spatially misaligned artifacts, we introduce a split cross-attention\nmechanism with spatial masks, enabling region-specific reference injection\nwithin the diffusion process. To mitigate semantic neglect of sketches, we\nemploy dedicated background and style encoders to transfer detailed reference\ninformation in the latent feature space, achieving enhanced spatial control and\nricher detail synthesis. Furthermore, we propose character-mask merging and\nbackground bleaching as preprocessing steps to improve foreground-background\nintegration and background generation. Extensive qualitative and quantitative\nevaluations, including a user study, demonstrate the superior performance of\nour proposed method compared to existing approaches. An ablation study further\nvalidates the efficacy of each proposed component.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T13:55:32Z"}
{"aid":"http://arxiv.org/abs/2504.06899v1","title":"SVTest: general purpose software for testing weakly random sources with\n  exemplary application to seismic data analysis enabling quantum amplification","summary":"Generating private randomness is essential for numerous applications ranging\nfrom security proofs to online banking. Consequently, the capacity of quantum\ndevices to amplify the privacy of a weak source of randomness, in cases\nunattainable by classical methods, constitutes a practical advantage. One of\nthe theoretical models of such weak sources are the so-called Santha-Vazirani\n(SV) sources; however, finding natural sources satisfying the SV model is a\nparamount challenge. In this article, we take three significant steps on the\nway to simplify this hard task. We begin with an in-depth analysis of the\nmathematical background for estimating the quality of a weak randomness source\nby providing a set of axioms that systematize the possible approaches to such\nestimation. We then develop software (SVTest) to estimate the parameter\ncharacterizing the source's randomness. The software is general-purpose, i.e.,\nit can test the randomness of any target sequence of bits. Later, we apply the\nsoftware to test seismic events (earthquakes and local noise) as potential\nsources of randomness. Our results demonstrate that seismic phenomena are\npossible sources of randomness, depending on the choice of discretization.\nTherefore, our work provides strong evidence of the potential of geophysical\nphenomena as a source of cryptographic resources, building an unprecedented\nbridge between both fields.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T13:58:34Z"}
{"aid":"http://arxiv.org/abs/2504.06905v1","title":"A Game Theoretic Treatment of Contagion in Trade Networks","summary":"Global trade of material goods involves the potential to create pathways for\nthe spread of infectious pathogens. One trade sector in which this synergy is\nclearly critical is that of wildlife trade networks. This highly complex system\ninvolves important and understudied bidirectional coupling between the economic\ndecision making of the stakeholders and the contagion dynamics on the emergent\ntrade network. While each of these components are independently well studied,\nthere is a meaningful gap in understanding the feedback dynamics that can arise\nbetween them. In the present study, we describe a general game theoretic model\nfor trade networks of goods susceptible to contagion. The primary result relies\non the acyclic nature of the trade network and shows that, through the course\nof trading with stochastic infections, the probability of infection converges\nto a directly computable fixed point. This allows us to compute best responses\nand thus identify equilibria in the game. We present ways to use this model to\ndescribe and evaluate trade networks in terms of global and individual risk of\ninfection under a wide variety of structural or individual modifications to the\ntrade network. In capturing the bidirectional coupling of the system, we\nprovide critical insight into the global and individual drivers and\nconsequences for risks of infection inherent in and arising from the global\nwildlife trade, and any economic trade network with associated contagion risks.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-09T14:07:24Z"}
{"aid":"http://arxiv.org/abs/2504.06915v1","title":"An Analysis of Temporal Dropout in Earth Observation Time Series for\n  Regression Tasks","summary":"Missing instances in time series data impose a significant challenge to deep\nlearning models, particularly in regression tasks. In the Earth Observation\nfield, satellite failure or cloud occlusion frequently results in missing\ntime-steps, introducing uncertainties in the predicted output and causing a\ndecline in predictive performance. While many studies address missing\ntime-steps through data augmentation to improve model robustness, the\nuncertainty arising at the input level is commonly overlooked. To address this\ngap, we introduce Monte Carlo Temporal Dropout (MC-TD), a method that\nexplicitly accounts for input-level uncertainty by randomly dropping time-steps\nduring inference using a predefined dropout ratio, thereby simulating the\neffect of missing data. To bypass the need for costly searches for the optimal\ndropout ratio, we extend this approach with Monte Carlo Concrete Temporal\nDropout (MC-ConcTD), a method that learns the optimal dropout distribution\ndirectly. Both MC-TD and MC-ConcTD are applied during inference, leveraging\nMonte Carlo sampling for uncertainty quantification. Experiments on three EO\ntime-series datasets demonstrate that MC-ConcTD improves predictive performance\nand uncertainty calibration compared to existing approaches. Additionally, we\nhighlight the advantages of adaptive dropout tuning over manual selection,\nmaking uncertainty quantification more robust and accessible for EO\napplications.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV","published":"2025-04-09T14:23:04Z"}
{"aid":"http://arxiv.org/abs/2504.06917v1","title":"Data Augmentation for Fake Reviews Detection in Multiple Languages and\n  Multiple Domains","summary":"With the growth of the Internet, buying habits have changed, and customers\nhave become more dependent on the online opinions of other customers to guide\ntheir purchases. Identifying fake reviews thus became an important area for\nNatural Language Processing (NLP) research. However, developing\nhigh-performance NLP models depends on the availability of large amounts of\ntraining data, which are often not available for low-resource languages or\ndomains. In this research, we used large language models to generate datasets\nto train fake review detectors. Our approach was used to generate fake reviews\nin different domains (book reviews, restaurant reviews, and hotel reviews) and\ndifferent languages (English and Chinese). Our results demonstrate that our\ndata augmentation techniques result in improved performance at fake review\ndetection for all domains and languages. The accuracy of our fake review\ndetection model can be improved by 0.3 percentage points on DeRev TEST, 10.9\npercentage points on Amazon TEST, 8.3 percentage points on Yelp TEST and 7.2\npercentage points on DianPing TEST using the augmented datasets.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T14:23:54Z"}
{"aid":"http://arxiv.org/abs/2504.06933v1","title":"Well-posedness of half-harmonic map heat flows for rough initial data","summary":"We adopt the Koch-Tataru theory for the Navier-Stokes equations, based on\nCarleson measure estimates, to develop a scaling-critical low-regularity\nframework for half-harmonic map heat flows. This nonlocal variant of the\nharmonic map heat flow has been studied recently in connection with free\nboundary minimal surfaces. We introduce a new class of initial data for the\nflow, broader than the conventional energy or Sobolev spaces considered in\nprevious work, for which we establish existence, uniqueness, and continuous\ndependence.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T14:38:13Z"}
{"aid":"http://arxiv.org/abs/2504.06937v1","title":"Finite Field Multiple Access III: from 2-ary to p-ary","summary":"This paper extends finite-field multiple-access (FFMA) techniques from binary\nto general $p$-ary source transmission. We introduce element-assemblage (EA)\ncodes over GF($p^m$), generalizing element-pair (EP) codes, and define two\nspecific types for ternary transmission: orthogonal EA codes and double\ncodeword EA (D-CWEA) codes. A unique sum-pattern mapping (USPM) constraint is\nproposed for the design of uniquely-decodable CWEA (UD-CWEA) codes, including\nadditive inverse D-CWEA (AI-D-CWEA) and basis decomposition D-CWEA (BD-D-CWEA)\ncodes. Moreover, we extend EP-coding to EA-coding, focusing on non-orthogonal\nCWEA (NO-CWEA) codes and their USPM constraint in the complex field.\nAdditionally, $p$-ary CWEA codes are constructed using a basis decomposition\nmethod, leveraging ternary decomposition for faster convergence and simplified\nencoder/decoder design. We present a comprehensive performance analysis of the\nproposed FFMA system from two complementary perspectives: channel capacity and\nerror performance. We demonstrate that equal power allocation (EPA) achieves\nthe theoretical channel capacity bound, while independently developing a\nrate-driven capacity alignment (CA) theorem based on the capacity-to-rate ratio\n(CRR) metric for error performance analysis. We then explore the multiuser\nfinite blocklength (FBL) characteristics of FFMA systems. Finally, a\ncomparative analysis of $p$-ary transmission systems against classical binary\nsystems is conducted, revealing that low-order $p$-ary systems (e.g., $p=3$)\noutperform binary systems at small loading factors, while higher-order systems\n(e.g., $p=257$) excel at larger loading factors. These findings highlight the\npotential of $p$-ary systems, although practical implementations may benefit\nfrom decomposing $p$-ary systems into ternary systems to manage complexity.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-09T14:41:36Z"}
{"aid":"http://arxiv.org/abs/2504.06938v1","title":"On the Compressibility of Integral Operators in Anisotropic Wavelet\n  Coordinates","summary":"The present article is concerned with the s*-compressibility of classical\nboundary integral operators in anisotropic wavelet coordinates. Having the\ns*-compressibility at hand, one can design adaptive wavelet algorithms which\nare asymptotically optimal, meaning that any target accuracy can be achieved at\na computational expense that stays proportional to the number of degrees of\nfreedom (within the setting determined by an underlying wavelet basis) that\nwould ideally be necessary for realising that target accuracy if full knowledge\nabout the unknown solution were given. As we consider here anisotropic wavelet\ncoordinates, we can achieve higher convergence rates compared to the standard,\nisotropic setting. Especially, edge singularities of anisotropic nature can be\nresolved.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-09T14:42:01Z"}
{"aid":"http://arxiv.org/abs/2504.06940v1","title":"More-efficient Quantum Multivariate Mean Value Estimator from\n  Generalized Grover Gate","summary":"In this work, we present an efficient algorithm for multivariate mean value\nestimation. Our algorithm outperforms previous work by polylog factors and\nnearly saturates the known lower bound. We find an algorithm that uses\n$O\\left(n \\log \\frac{d}{\\delta}\\right)$ to achieve precision\n$\\frac{\\sqrt{\\text{tr } \\Sigma}}{n}$ in $\\lVert \\rVert_\\infty$ norm and hence\n$\\frac{\\sqrt{d \\text{ tr } \\Sigma}}{n}$ in $\\lVert \\rVert_2$ norm, where $d$ is\nthe dimension and $\\Sigma$ is the covariance matrix. We also presented another\nalgorithm that uses smaller memory but costs an extra $d^\\frac{1}{4}$ in\ncomplexity. The idea originates from the previous observations that the Grover\ngate, when generalized to allow for arbitrary phases instead of $\\pm 1$,\nbecomes a good mean value estimator in some mathematical notion. The only\nremaining $\\log \\frac{d}{\\delta}$ as opposed to $\\log \\frac{1}{\\delta}$ is due\nto the phase estimation primitive we employed, which so far is the only major\nknown method to tackle the problem. Our results demonstrates that our\nmethodology with generalized Grover gate can be used locate the optimal\nalgorithm, without polylog overhead, for different taks relating to mean value\nestimation.","main_category":"quant-ph","categories":"quant-ph,cs.CC","published":"2025-04-09T14:48:23Z"}
{"aid":"http://arxiv.org/abs/2504.06941v1","title":"Proofs of two conjectures on congruences of overcubic partition triples","summary":"Let $\\overline{bt}(n)$ denote the number of overcubic partition triples of\n$n$. Nayaka, Dharmendra and Kumar proved some congruences modulo 8, 16 and 32\nfor $\\overline{bt}(n)$. Recently, Saikia and Sarma established some congruences\nmodulo 64 for $\\overline{bt}(n)$ by using both elementary techniques and the\ntheory of modular forms. In their paper, they also posed two conjectures on\ninfinite families of congruences modulo 64 and 128 for $\\overline{bt}(n)$. In\nthis paper, we confirm the two conjectures.","main_category":"math.NT","categories":"math.NT","published":"2025-04-09T14:49:16Z"}
{"aid":"http://arxiv.org/abs/2504.06945v1","title":"Generic deformation channels for critical Fermi surfaces including the\n  impact of collisions","summary":"This paper constitutes a sequel to our theoretical efforts to determine the\nnature of the generic low-energy deformations of the Fermi surface of a\nquantum-critical metal, which arises at the stable non-Fermi liquid (NFL) fixed\npoint of a quantum phase transition. The emergent critical Fermi surface,\narising right at the Ising-nematic quantum critical point (QCP), is a\nparadigmatic example where an NFL behaviour is induced by the strong\ninteractions of the fermionic degrees of freedom with those of the bosonic\norder parameter. It is an artifact of the bosonic modes becoming massless at\nthe QCP, thus undergoing Landau damping at the level of one-loop self-energy.\nWe resort to the well-tested formalism of the quantum Boltzmann equations\n(QBEs)for identifying the excitations. While in our earlier works, we have\nfocussed on the collisionless regime by neglecting the collision integral and\nassuming the bosons to be in equilibrium, here we embark on a full analysis. In\nparticular, we take into account the bosonic part of the QBEs. The final\nresults show that that the emergent modes are long-lived and robust against the\ndamping effects brought about the collision integral(s), exhibiting the same\nqualitative features as obtained from the no-collision approximations.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mes-hall,hep-th","published":"2025-04-09T14:52:45Z"}
{"aid":"http://arxiv.org/abs/2504.06949v1","title":"Adaptive Computation Pruning for the Forgetting Transformer","summary":"The recently proposed Forgetting Transformer (FoX) incorporates a forget gate\ninto softmax attention and has shown consistently better or on-par performance\ncompared to the standard RoPE-based Transformer. Notably, many attention heads\nin FoX tend to forget quickly, causing their output at each timestep to rely\nprimarily on the local context. Based on this observation, we propose Adaptive\nComputation Pruning (ACP) for FoX, a method that dynamically prunes\ncomputations involving input-output dependencies that are strongly decayed by\nthe forget gate. This is achieved using a dynamically set pruning threshold\nthat ensures that the pruned attention weights remain negligible. We apply ACP\nto language model pretraining with FoX and show it consistently reduces the\nnumber of FLOPs in softmax attention by around 70% across different model sizes\nand context lengths, resulting in a roughly 10% to 35% improvement in training\nthroughput. Furthermore, longer context lengths yield greater computational\nsavings. All these speed improvements are achieved without any performance\ndegradation. We also perform several analyses to provide deeper insights into\nour method, such as examining the pruning patterns and analyzing the\ndistribution of FLOP savings across different attention heads. Our code is\navailable at https://github.com/zhixuan-lin/arctic-fox.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-09T14:57:55Z"}
{"aid":"http://arxiv.org/abs/2504.06960v1","title":"Higher-Order Color Voronoi Diagrams and the Colorful Clarkson-Shor\n  Framework","summary":"Given a set $S$ of $n$ colored sites, each $s\\in S$ associated with a\ndistance-to-site function $\\delta_s \\colon \\mathbb{R}^2 \\to \\mathbb{R}$, we\nconsider two distance-to-color functions for each color: one takes the minimum\nof $\\delta_s$ for sites $s\\in S$ in that color and the other takes the maximum.\nThese two sets of distance functions induce two families of higher-order\nVoronoi diagrams for colors in the plane, namely, the minimal and maximal\norder-$k$ color Voronoi diagrams, which include various well-studied Voronoi\ndiagrams as special cases. In this paper, we derive an exact upper bound\n$4k(n-k)-2n$ on the total number of vertices in both the minimal and maximal\norder-$k$ color diagrams for a wide class of distance functions $\\delta_s$ that\nsatisfy certain conditions, including the case of point sites $S$ under convex\ndistance functions and the $L_p$ metric for any $1\\leq p \\leq\\infty$. For the\n$L_1$ (or, $L_\\infty$) metric, and other convex polygonal metrics, we show that\nthe order-$k$ minimal diagram of point sites has $O(\\min\\{k(n-k), (n-k)^2\\})$\ncomplexity, while its maximal counterpart has $O(\\min\\{k(n-k), k^2\\})$\ncomplexity. To obtain these combinatorial results, we extend the Clarkson--Shor\nframework to colored objects, and demonstrate its application to several\nfundamental geometric structures, including higher-order color Voronoi\ndiagrams, colored $j$-facets, and levels in the arrangements of piecewise\nlinear/algebraic curves/surfaces. We also present an iterative approach to\ncompute higher-order color Voronoi diagrams.","main_category":"cs.CG","categories":"cs.CG","published":"2025-04-09T15:12:28Z"}
{"aid":"http://arxiv.org/abs/2504.06964v1","title":"Thermodynamics of effective loop quantum black holes","summary":"We study the thermodynamics of a non-singular black hole model with effective\nquantum corrections motivated by Loop Quantum Gravity (LQG). The effective\ngeometry has a transition surface that connects trapped and anti-trapped\nregions with the same mass. There is a minimum mass for which the horizon\ntemperature and Komar energy are zero, and the black hole stops its Hawking\nevaporation. For horizons above this limit, we present the grey-body factors,\nemission spectra, and the mass loss rate, solving a one-dimensional\nSchrdinger-type equation with an effective short-range potential barrier for\nmassless fields of spins 0, 1/2, 1 and 2.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-09T15:19:03Z"}
{"aid":"http://arxiv.org/abs/2504.06967v1","title":"Optimal promotions of new products on networks","summary":"We present a novel methodology for analyzing the optimal promotion in the\nBass model for the spreading of new products on networks. For general networks\nwith $M$ nodes, the optimal promotion is the solution of $2^M-1$\nnonlinearly-coupled boundary-value problems. On structured networks, however,\nthe number of equations can be reduced to a manageable size which is amendable\nto simulations and analysis. This enables us to gain insight into the effect of\nthe network structure on optimal promotions. We find that the optimal\nadvertising strategy decreases with time, whereas the optimal boosting of peer\neffects increases from zero and then decreases. In low-degree networks, it is\noptimal to prioritize advertising over boosting peer effects, but this relation\nis flipped in high-degree networks. When the planning horizon is finite, the\noptimal promotion continues until the last minute, as opposed to an infinite\nplanning horizon where the optimal promotion decays to zero. Finally,\npromotions with short planning horizons can yield an order of magnitude higher\nincrease of profits, compared to those with long planning horizons.","main_category":"math.OC","categories":"math.OC,cs.SI","published":"2025-04-09T15:23:10Z"}
{"aid":"http://arxiv.org/abs/2504.06972v1","title":"Signatures of unconventional superconductivity near reentrant and\n  fractional quantum anomalous Hall insulators","summary":"Two-dimensional moir\\'e Chern bands provide an exceptional platform for\nexploring a variety of many-body electronic liquid and solid phases at zero\nmagnetic field within a lattice system. One particular intriguing possibility\nis that flat Chern bands can, in principle, support exotic superconducting\nphases together with fractional topological phases. Here, we report the\nobservation of integer and fractional quantum anomalous Hall effects, the\nreentrant quantum anomalous Hall effect, and superconductivity within the first\nmoir\\'e Chern band of twisted bilayer MoTe2. The superconducting phase emerges\nfrom a normal state exhibiting anomalous Hall effects and sustains an large\nperpendicular critical magnetic field. Our results present the first example of\nsuperconductivity emerging within a flat Chern band that simultaneously hosts\nfractional quantum anomalous effects, a phenomenon never observed in any other\nsystems. Our work expands the understanding of emergent quantum phenomena in\nmoir\\'e Chern bands, and offers a nearly ideal platform for engineering\nMajorana and parafermion zero modes in gate-controlled hybrid devices.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.supr-con","published":"2025-04-09T15:27:56Z"}
{"aid":"http://arxiv.org/abs/2504.06977v1","title":"Probing dipolar interactions between Rydberg atoms and ultracold polar\n  molecules","summary":"We probe resonant dipolar interactions between ultracold $^{40}$K$^{87}$Rb\nmolecules and Rydberg $^{87}$Rb atoms in an optically trapped ensemble. Through\nstate-selective ionization detection of the KRb molecules, we observe resonant\nenergy transfer at 2.227 GHz from Rydberg atoms to molecules under a tunable\nexternal electric field. We measure a broadening up to 3.5 MHz, for the Rb\nRydberg excitation spectrum, which matches a Monte Carlo simulation that\ndescribes a Rydberg atom and neighboring molecules evolving under a\ndipole-dipole interacting Hamiltonian. The demonstrated interspecies dipolar\ninteraction is a key ingredient for hybrid Rydberg-polar molecule systems,\nwhere the advantages of each system can be leveraged and combined.","main_category":"physics.atom-ph","categories":"physics.atom-ph,quant-ph","published":"2025-04-09T15:31:02Z"}
{"aid":"http://arxiv.org/abs/2504.06985v1","title":"M-theory boundaries beyond supersymmetry","summary":"The chiral worldvolume theory of an M-theory boundary (the so-called M9\nbrane) is uniquely determined by supersymmetry and anomaly inflow. In this\nbrief note we investigate whether alternative chiral boundary field contents\nmay be allowed by anomaly cancellation once supersymmetry is dropped. Even\nthen, anomaly inflow places stringent constraints on the gauge group $G$ and\nmatter content of the boundary worldvolume theory, which we determine\nexplicitly. We find the most general solution to these constraints in the case\nwhere all matter fields are of the same chirality, for all simple Lie algebras\nexcept $\\mathfrak{sp}_2$, $\\mathfrak{su}_{n\\leq5}$, and $\\mathfrak{so}_{n}$\nwith $7\\leq n\\leq 12$, and find no solutions other than the supersymmetric\n$E_8$ boundary of Ho\\v{r}ava and Witten. However, when we extend our search to\nallow for any chirality in the matter fields, we find one minimal solution with\ngauge group $G_2$, charged matter in the $\\mathsf{14}$, $\\mathsf{27}$ and\n$\\mathsf{77}$ representations, which satisfies all constraints in a non-trivial\nway. Therefore, it could in principle describe the low-energy theory of a novel\nnonsupersymmetric M-theory boundary condition, different from the\nHo\\v{r}ava-Witten proposal. We briefly discuss some consequences if this was\nindeed the case, such as the existence of a non-supersymmetric, exotic\n\"$G_2$-string\" CFT in 6d, and a novel, non-perturbative, heterotic-like 10d\nstring with gauge group $G_2\\times G_2$.","main_category":"hep-th","categories":"hep-th","published":"2025-04-09T15:45:46Z"}
{"aid":"http://arxiv.org/abs/2504.06987v1","title":"Enhancing Metabolic Syndrome Prediction with Hybrid Data Balancing and\n  Counterfactuals","summary":"Metabolic Syndrome (MetS) is a cluster of interrelated risk factors that\nsignificantly increases the risk of cardiovascular diseases and type 2\ndiabetes. Despite its global prevalence, accurate prediction of MetS remains\nchallenging due to issues such as class imbalance, data scarcity, and\nmethodological inconsistencies in existing studies. In this paper, we address\nthese challenges by systematically evaluating and optimizing machine learning\n(ML) models for MetS prediction, leveraging advanced data balancing techniques\nand counterfactual analysis. Multiple ML models, including XGBoost, Random\nForest, TabNet, etc., were trained and compared under various data balancing\ntechniques such as random oversampling (ROS), SMOTE, ADASYN, and CTGAN.\nAdditionally, we introduce MetaBoost, a novel hybrid framework that integrates\nSMOTE, ADASYN, and CTGAN, optimizing synthetic data generation through weighted\naveraging and iterative weight tuning to enhance the model's performance\n(achieving a 1.14% accuracy improvement over individual balancing techniques).\nA comprehensive counterfactual analysis is conducted to quantify feature-level\nchanges required to shift individuals from high-risk to low-risk categories.\nThe results indicate that blood glucose (50.3%) and triglycerides (46.7%) were\nthe most frequently modified features, highlighting their clinical significance\nin MetS risk reduction. Additionally, probabilistic analysis shows elevated\nblood glucose (85.5% likelihood) and triglycerides (74.9% posterior\nprobability) as the strongest predictors. This study not only advances the\nmethodological rigor of MetS prediction but also provides actionable insights\nfor clinicians and researchers, highlighting the potential of ML in mitigating\nthe public health burden of metabolic syndrome.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-09T15:51:10Z"}
{"aid":"http://arxiv.org/abs/2504.06992v1","title":"Constraining the $z \\sim 1$ IMF with {\\it HST} and {\\it JWST} lensed\n  stars in MACS J0416.1-2403","summary":"The understanding of galaxy properties and evolution is contingent on knowing\nthe initial mass function (IMF), and yet to date, the IMF is constrained only\nto local galaxies. Individual stars are now becoming routinely detected at\ncosmological distances, where luminous stars such as supergiants in background\ngalaxies critically lensed by galaxy clusters are temporarily further magnified\nby huge factors up to $10^{4}$ by intra-cluster stars, thus being detected as\ntransients. The detection rate of these events depends on the abundance of\nluminous stars in the background galaxy and is thus sensitive to the IMF and\nthe star formation history (SFH), especially for the blue supergiants detected\nas transients in the rest-frame UV/optical filters. As a proof of concept, we\nuse simple SFH and IMF models constrained by spectral energy distribution (SED)\nto see how well we can predict the {\\it HST} and {\\it JWST} transient detection\nrate in a lensed arc dubbed ``Spock'' ($z = 1.0054$). We find that demanding a\nsimultaneously fit of SED and rest-frame UV/optical transient detection rate\nplaces constraints on the IMF, independent of the assumed simple SFH model. We\nconclude our Bayesian likelihood analysis indicates that the data definitively\nprefer the ``Spock'' galaxy to have a Salpeter IMF ($\\alpha = 2.35$) rather\nthan a Top-heavy IMF ($\\alpha = 1$) -- what is thought to be the case in the\nearly universe -- given our methodology and assumptions with no clear excess of\nsupergiants above the standard IMF.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-09T15:58:36Z"}
{"aid":"http://arxiv.org/abs/2504.06997v1","title":"Cerebral blood flow monitoring using a deep learning implementation of\n  the two-layer DCS analytical model with a 512 512 SPAD array","summary":"Diffuse correlation spectroscopy (DCS) analyzes the autocorrelation function\nof photons scattered by red blood cells, enabling non-invasive, continuous\nmeasurement of deep tissue blood flow at the bedside. Multi-layer DCS models\n(two- and three-layer) enhance cerebral blood flow index (CBFi) sensitivity and\nmitigate interference from extracerebral tissues. However, these models require\nmultiple predefined parameters and are computationally intensive, making them\nimpractical for real-time bedside monitoring. To address this challenge, we\nintegrate a single-photon avalanche diode (SPAD) array with a deep learning\n(DL)-based approach trained on data generated by the two-layer analytical\nmodel. This method bypasses traditional model fitting, enabling real-time CBFi\nmonitoring while minimizing superficial tissue contamination. We first validate\nour approach using Monte Carlo-simulated test datasets, demonstrating superior\naccuracy in relative CBFi estimation (5.8% error vs. 19.1% for conventional\nfitting) and enhanced CBFi sensitivity (87.1% vs. 55.4%). Additionally, our\nmethod effectively isolates shallow blood flow changes and 750-fold faster than\nsingle-exponential fitting in a realistic scenario. We further evaluate the\nsystem in a healthy adult, achieving real-time CBFi monitoring and pulsatile\nwaveform recovery during a brain activity test using a 512 512 SPAD array\nsensor. These results highlight the potential of our approach for real-time\nbrain activity monitoring.","main_category":"physics.med-ph","categories":"physics.med-ph,physics.bio-ph","published":"2025-04-09T16:09:34Z"}
{"aid":"http://arxiv.org/abs/2504.06998v1","title":"A Krylov projection algorithm for large symmetric matrices with dense\n  spectra","summary":"We consider the approximation of $B^T (A+sI)^{-1} B$ for large s.p.d.\n$A\\in\\mathbb{R}^{n\\times n}$ with dense spectrum and $B\\in\\mathbb{R}^{n\\times\np}$, $p\\ll n$. We target the computations of Multiple-Input Multiple-Output\n(MIMO) transfer functions for large-scale discretizations of problems with\ncontinuous spectral measures, such as linear time-invariant (LTI) PDEs on\nunbounded domains. Traditional Krylov methods, such as the Lanczos or CG\nalgorithm, are known to be optimal for the computation of $(A+sI)^{-1}B$ with\nreal positive $s$, resulting in an adaptation to the distinctively discrete and\nnonuniform spectra. However, the adaptation is damped for matrices with dense\nspectra. It was demonstrated in [Zimmerling, Druskin, Simoncini, Journal of\nScientific Computing 103(1), 5 (2025)] that averaging Gau{\\ss} and Gau\\ss\n-Radau quadratures computed using the block-Lanczos method significantly\nreduces approximation errors for such problems. Here, we introduce an adaptive\nKre\\u{i}n-Nudelman extension to the (block) Lanczos recursions, allowing\nfurther acceleration at negligible $o(n)$ cost. Similar to the Gau\\ss -Radau\nquadrature, a low-rank modification is applied to the (block) Lanczos matrix.\nHowever, unlike the Gau\\ss -Radau quadrature, this modification depends on\n$\\sqrt{s}$ and can be considered in the framework of the Hermite-Pad\\'e\napproximants, which are known to be efficient for problems with branch-cuts,\nthat can be good approximations to dense spectral intervals. Numerical results\nfor large-scale discretizations of heat-diffusion and quasi-magnetostatic\nMaxwell's operators in unbounded domains confirm the efficiency of the proposed\napproach.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-09T16:09:34Z"}
{"aid":"http://arxiv.org/abs/2504.07017v1","title":"Adapting GT2-FLS for Uncertainty Quantification: A Blueprint Calibration\n  Strategy","summary":"Uncertainty Quantification (UQ) is crucial for deploying reliable Deep\nLearning (DL) models in high-stakes applications. Recently, General Type-2\nFuzzy Logic Systems (GT2-FLSs) have been proven to be effective for UQ,\noffering Prediction Intervals (PIs) to capture uncertainty. However, existing\nmethods often struggle with computational efficiency and adaptability, as\ngenerating PIs for new coverage levels $(\\phi_d)$ typically requires retraining\nthe model. Moreover, methods that directly estimate the entire conditional\ndistribution for UQ are computationally expensive, limiting their scalability\nin real-world scenarios. This study addresses these challenges by proposing a\nblueprint calibration strategy for GT2-FLSs, enabling efficient adaptation to\nany desired $\\phi_d$ without retraining. By exploring the relationship between\n$\\alpha$-plane type reduced sets and uncertainty coverage, we develop two\ncalibration methods: a lookup table-based approach and a derivative-free\noptimization algorithm. These methods allow GT2-FLSs to produce accurate and\nreliable PIs while significantly reducing computational overhead. Experimental\nresults on high-dimensional datasets demonstrate that the calibrated GT2-FLS\nachieves superior performance in UQ, highlighting its potential for scalable\nand practical applications.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T16:32:43Z"}
{"aid":"http://arxiv.org/abs/2504.07019v1","title":"Non-Hermitian Numerical Renormalization Group: Solution of the\n  non-Hermitian Kondo model","summary":"Non-Hermitian (NH) Hamiltonians describe open quantum systems, nonequilibrium\ndynamics, and dissipative processes. Although a rich range of single-particle\nNH physics has been uncovered, many-body phenomena in strongly correlated NH\nsystems have been far less well studied. The Kondo effect, an important\nparadigm for strong correlation physics, has recently been considered in the NH\nsetting. Here we develop a NH generalization of the numerical renormalization\ngroup (NRG) and use it to solve the NH Kondo model. Our non-perturbative\nsolution applies beyond weak coupling, and we uncover a nontrivial phase\ndiagram. The method is showcased by application to the NH pseudogap Kondo\nmodel, which we show supports a completely novel phase with a genuine NH stable\nfixed point and complex eigenspectrum. Our NH-NRG code, which can be used in\nregimes and for models inaccessible to, e.g., perturbative scaling and Bethe\nansatz, is provided open source.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,quant-ph","published":"2025-04-09T16:34:49Z"}
{"aid":"http://arxiv.org/abs/2504.07023v1","title":"Swinging small quantum systems out of available values of control\n  parameters","summary":"When a quantum system is prepared in its many-body ground state, it can be\nadiabatically driven to another ground state by changing its control parameter.\nHowever, relying on adiabaticity is experimentally unjustified. Moreover, the\ntarget value of the control parameter may occur outside the experimentally\naccessible range. The indicated target state, however, can still be reached\nwithin a clever protocol of temporal changes of the control parameter provided\nits decomposition into some basis is known. It turns out that such a protocol\ncan be obtained in the framework of the optimal control theory. In this paper,\nwe show how to apply such an optimization scheme to small quantum systems\ntreating interaction strength as the control parameter. We believe that the\nproposed approach can be creatively extended to various complex quantum\nsystems.","main_category":"quant-ph","categories":"quant-ph,cond-mat.quant-gas","published":"2025-04-09T16:37:49Z"}
{"aid":"http://arxiv.org/abs/2504.07030v1","title":"Decoherence effects in entangled fermion pairs at colliders","summary":"Recent measurements at the Large Hadron Collider have observed entanglement\nin the spins of $t\\bar t$ pairs. The effects of radiation, which are expected\nto lead to quantum decoherence and a reduction of entanglement, are generally\nneglected in such measurements. In this letter we calculate the effects of\ndecoherence from various different types of radiation for a maximally entangled\npair of fermions -- a bipartite system of qubits in a Bell state. We identify\nthe Kraus operators describing the evolution of the open quantum system with\nthe integrated Altarelli-Parisi splitting functions.","main_category":"quant-ph","categories":"quant-ph,hep-ex,hep-ph","published":"2025-04-09T16:44:25Z"}
{"aid":"http://arxiv.org/abs/2504.07039v1","title":"Microlensing at Cosmological Distances: Event Rate Predictions in the\n  Warhol Arc of MACS 0416","summary":"Highly magnified stars ($\\mu$ $>$ 100) are now outinely identified as\ntransient events at cosmological distances thanks to microlensing by\nintra-cluster stars near the critical curves of galaxy clusters. Using the {\\it\nJames Webb} Space Telescope (JWST) in combination with the {\\it Hubble} Space\nTelescope (HST), we outline here an analytical framework that is applied to the\nWarhol arc (at $z=0.94$) in the MACS 0416 galaxy cluster (at $z=0.396)$ where\nover a dozen microlensed stars have been detected to date. This method is\ngeneral and can be applied to other lensed arcs. Within this lensed galaxy we\nfit the spatially resolved SED spanned by eight JWST-NIRCam filters combined\nwith three ACS filters, for accurate lensed star predictions in 2D. With this\ntool we can generate 2D maps of microlensed stars for well resolved arcs in\ngeneral, including dependence on wavelength and limiting apparent magnitude,\nfor comparison with with planned cadenced campaigns for JWST and Hubble, for\nconstraining directly the IMF and the level of dark matter substructure.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.GA,astro-ph.SR","published":"2025-04-09T16:54:22Z"}
{"aid":"http://arxiv.org/abs/2504.07047v1","title":"Hydrogen-Mediated Control of Phase Formation and Microstructure\n  Evolution","summary":"Hydrogen is key in reducing greenhouse gas emissions in materials production.\nAt the same time, it significantly affects mechanical properties, often causing\nunwanted embrittlement. However, rather than solely addressing these\ndisadvantages, hydrogens inevitable role in sustainable metallurgy should be\nleveraged to create new and potentially superior materials. Here, we show that\nusing hydrogen in the form of metal hydrides introduces a barrier to mechanical\nalloying, stabilizing otherwise unattainable microstructures. Severe plastic\ndeformation of a composite of the high entropy alloy (HEA) TiVZrNbHf and Cu\nleads to amorphization while substituting the HEA by its hydride preserves the\ntwo-phase structure. Monte Carlo simulations confirm that the significantly\ndifferent hydrogen affinities, together with the restricted dislocation motion\nin the hydride, create a barrier to mechanical alloying. This hydride route\nenables new microstructural states, even in well-studied material systems. It\nopens an additional dimension in designing materials with diverging hydrogen\naffinities, offering tighter control over mechanical alloying.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-09T17:05:07Z"}
{"aid":"http://arxiv.org/abs/2504.07066v1","title":"Intertwining Josephson and Vortex Topologies in Conventional\n  Superconductors","summary":"Recent experimental advances have unveiled promising evidence of vortex-bound\nMajorana quasiparticles in multiple superconducting compounds. However,\ntheoretical progress in understanding these phenomena, especially from ab\ninitio approaches, has been limited by the computational complexity of\nsimulating vortex structures. To bridge this gap, we introduce the\nJosephson-vortex correspondence (JVC), a theoretical framework that\nsystematically maps the bound-state topological properties of vortices to those\nof $\\pi$-phase Josephson junctions in the same superconductor. This\ncorrespondence allows vortex phase diagrams to be constructed directly from\njunction calculations, thereby eliminating the need for large-scale vortex\ncalculations. We demonstrate the validity and predictive power of JVC across a\nvariety of effective models, and further extend the framework to the\nfirst-principles level. Applying our approach to 2M-WS$_2$ and Sr$_3$SnO, we\nidentify them as realistic, doping-tunable platforms for realizing vortex\nMajorana zero modes. Our theory will pave the way for ab initio Majorana\nmaterial discovery and design.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.mes-hall,cond-mat.str-el","published":"2025-04-09T17:31:34Z"}
{"aid":"http://arxiv.org/abs/2504.07070v1","title":"A Survey on Personalized and Pluralistic Preference Alignment in Large\n  Language Models","summary":"Personalized preference alignment for large language models (LLMs), the\nprocess of tailoring LLMs to individual users' preferences, is an emerging\nresearch direction spanning the area of NLP and personalization. In this\nsurvey, we present an analysis of works on personalized alignment and modeling\nfor LLMs. We introduce a taxonomy of preference alignment techniques, including\ntraining time, inference time, and additionally, user-modeling based methods.\nWe provide analysis and discussion on the strengths and limitations of each\ngroup of techniques and then cover evaluation, benchmarks, as well as open\nproblems in the field.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T17:39:58Z"}
{"aid":"http://arxiv.org/abs/2504.07071v1","title":"ASASSN-14dx: A cataclysmic variable harbouring a massive pulsating white\n  dwarf","summary":"We present the results of our study of ASASSN-14dx, a previously known but\npoorly characterised cataclysmic variable (CV). The source was observed as part\nof an ongoing high-time-resolution photometric survey of CVs, which revealed\nthat, in addition to the known 82.8min orbital period, it also exhibits other\ntransient periods, the strongest of which around 4 and 14 min. Here, we report\nour findings resulting from a multifaceted follow-up programme consisting of\noptical spectroscopy, spectropolarimetry, imaging polarimetry, and multicolour\nfast photometry. We find that the source displays complex optical variability,\nwhich is best explained by the presence of a massive white dwarf exhibiting\nnon-radial pulsations. An intermediate polar-like scenario involving a spinning\nmagnetic white dwarf can be ruled out based on the detected changes in the\nobserved periods. Based on our optical spectroscopy, we can constrain the mass\nand effective temperature of the white dwarf to be ~1.1 Msol and 16 100 K,\nrespectively. The overall intrinsic flux level of the source is unusually high,\nsuggesting that there remains significant residual emission from the accretion\ndisc and/or the white dwarf even ten years after the 2014 outburst. Finally, we\ncannot detect any spectroscopic signatures from the donor star, making\nASASSN-14dx a possible period bouncer system evolving towards a longer orbital\nperiod.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-09T17:40:24Z"}
{"aid":"http://arxiv.org/abs/2504.07073v1","title":"New empirical mass-loss recipe for UV radiation line-driven winds of hot\n  stars across various metallicities","summary":"The winds of massive stars remove a significant fraction of their mass,\nstrongly impacting their evolution. As a star evolves, the rate at which it\nloses mass changes. In stellar evolution codes, different mass-loss recipes are\nemployed for different evolutionary stages. The choice of the recipes is\nuser-dependent and the conditions for switching between them are poorly\ndefined. Focusing on hot stars, we aim to produce a physically motivated,\nempirically calibrated mass-loss recipe suitable for a wide range of\nmetallicities. We want to provide a ready-to-use universal recipe that\neliminates the need for switching between recipes for hot stars during stellar\nevolution calculations. We compile a sample of hot stars with reliable stellar\nand wind parameters in the Galaxy and the Magellanic Clouds. The sample is used\nto determine the dependence of the mass-loss rate on the basic stellar\nparameters. We find that independent of evolutionary stage and temperature, the\nwind mass-loss rate is a function of the electron-scattering Eddington\nparameter ($\\Gamma_e$) and metallicity (Z), being in line with expectations of\nradiation-driven wind theory. Our derived scaling relation provides an adequate\n($\\Delta$log($\\dot{M}$/(M$_\\odot$/yr)) = 0.43) and broadly applicable mass-loss\nrecipe for hot stars. The newly derived mass-loss recipe covers nearly the\nentire parameter space of hot stars with UV radiation-driven winds and\neliminates the need for interpolation between mass-loss formulae at different\nevolutionary stages when applied in stellar evolution models. Examples of\nstellar evolution calculations using our new recipe reveal that the predictions\non the ionizing fluxes and final fates of massive stars, especially at low\nmetallicity, differ significantly from models that use the standard mass-loss\nrates, impacting our understanding of stellar populations at low metallicity\nand in the young Universe.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-09T17:43:35Z"}
{"aid":"http://arxiv.org/abs/2504.07075v1","title":"Bound and Scattering States in a Spacetime with Dual Topological\n  Defects: Cosmic String and Global Monopole","summary":"This paper explores the relativistic quantum motion of scalar bosons in the\npresence of mixed topological defects: cosmic strings and global monopoles. The\nKlein-Gordon equation with generalized Coulomb potentials is analyzed in this\nbackground. The effects of these topological defects on the equations of\nmotion, phase shifts, and the S-matrix are examined in detail. Bound state\nsolutions are derived from the poles of the S-matrix. We provide analytical\nexpressions for the energy spectrum of bound states, with particular attention\nto how the parameters of scalar and vector potentials affect the behavior of\nthe system. Furthermore, we explore particular cases involving pure scalar,\nvector, and mixed scalar-vector potentials, showing how these scenarios impose\nparticular conditions on the existence of bound states. Our results indicate\nthat the solutions obtained associated with scattering and bound states depend\nsignificantly on the parameters of the topological defects.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-09T17:47:22Z"}
{"aid":"http://arxiv.org/abs/2504.07084v1","title":"A geometric ensemble method for Bayesian inference","summary":"Conventional approximations to Bayesian inference rely on either\napproximations by statistics such as mean and covariance or by point particles.\nRecent advances such as the ensemble Gaussian mixture filter have generalized\nthese notions to sums of parameterized distributions. This work presents a new\nmethodology for approximating Bayesian inference by sums of uniform\ndistributions on convex polytopes. The methodology presented herein is\ndeveloped from the simplest convex polytope filter that takes advantage of\nuniform prior and measurement uncertainty, to an operationally viable ensemble\nfilter with Kalmanized approximations to updating convex polytopes. Numerical\nresults on the Ikeda map show the viability of this methodology in the\nlow-dimensional setting, and numerical results on the Lorenz '96 equations\nsimilarly show viability in the high-dimensional setting.","main_category":"math.OC","categories":"math.OC,math.PR,stat.ME","published":"2025-04-09T17:56:58Z"}
{"aid":"http://arxiv.org/abs/2504.07090v1","title":"A Differentiable, End-to-End Forward Model for 21 cm Cosmology:\n  Estimating the Foreground, Instrument, and Signal Joint Posterior","summary":"We present a differentiable, end-to-end Bayesian forward modeling framework\nfor line intensity mapping cosmology experiments, with a specific focus on\nlow-frequency radio telescopes targeting the redshifted 21 cm line from neutral\nhydrogen as a cosmological probe. Our framework is capable of posterior density\nestimation of the cosmological signal jointly with foreground and telescope\nparameters at the field level. Our key aim is to be able to optimize the\nmodel's high-dimensional, non-linear, and ill-conditioned parameter space,\nwhile also sampling from it to perform robust uncertainty quantification within\na Bayesian framework. We show how a differentiable programming paradigm,\naccelerated by recent advances in machine learning software and hardware, can\nmake this computationally-demanding, end-to-end Bayesian approach feasible. We\ndemonstrate a proof-of-concept on a simplified signal recovery problem for the\nHydrogen Epoch of Reionization Array experiment, highlighting the framework's\nability to build confidence in early 21 cm signal detections even in the\npresence of poorly understood foregrounds and instrumental systematics. We use\na Hessian-preconditioned Hamiltonian Monte Carlo algorithm to efficiently\nsample our parameter space with a dimensionality approaching $N\\sim10^5$, which\nenables joint, end-to-end nuisance parameter marginalization over foreground\nand instrumental terms. Lastly, we introduce a new spherical harmonic formalism\nthat is a complete and orthogonal basis on the cut sky relevant to drift-scan\nradio surveys, which we call the spherical stripe harmonic formalism, and it's\nassociated three-dimensional basis, the spherical stripe Fourier-Bessel\nformalism.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.IM","published":"2025-04-09T17:59:03Z"}
{"aid":"http://arxiv.org/abs/2504.07098v1","title":"Nonhermitian topological zero modes at smooth domain walls: Exact\n  solutions","summary":"The bulk-boundary correspondence predicts the existence of boundary modes\nlocalized at the edges of topologically nontrivial systems. The wavefunctions\nof hermitian boundary modes can be obtained as the eigenmode of a modified\nJackiw-Rebbi equation. Recently, the bulk-boundary correspondence has been\nextended to nonhermitian systems, which describe physical phenomena such as\ngain and loss in open and non-equilibrium systems. Nonhermitian energy spectra\ncan be complex-valued and exhibit point gaps or line gaps in the complex plane,\nwhether the gaps can be continuously deformed into points or lines,\nrespectively. Specifically, line-gapped nonhermitian systems can be\ncontinuously deformed into hermitian gapped spectra. Here, we find the\nanalytical form of the wavefunctions of nonhermitian boundary modes with zero\nenergy localized at smooth domain boundaries between topologically distinct\nphases, by solving the generalized Jackiw-Rebbi equation in the nonhermitian\nregime. Moreover, we unveil a universal relation between the scalar fields and\nthe decay rate and oscillation wavelength of the boundary modes. This relation\nquantifies the bulk-boundary correspondence in nonhermitian line-gapped systems\nin terms of experimentally measurable physical quantities and is not affected\nby the details of the spatial dependence of the scalar fields. These findings\nshed some new light on the localization properties of boundary modes in\nnonhermitian and topologically nontrivial states of matter.","main_category":"hep-th","categories":"hep-th,cond-mat.mes-hall,cond-mat.quant-gas,cond-mat.supr-con","published":"2025-04-09T17:59:46Z"}
{"aid":"http://arxiv.org/abs/2504.07407v1","title":"Cech - de Rham Chern character on the stack of holomorphic vector\n  bundles","summary":"We provide a formula for the Chern character of a holomorphic vector bundle\nin the hyper-cohomology of the de Rham complex of holomorphic sheaves on a\ncomplex manifold. This Chern character can be thought of as a completion of the\nChern character in Hodge cohomology obtained as the trace of the exponential of\nthe Atiyah class, which is \\v{C}ech closed, to one that is \\v{C}ech-Del closed.\nSuch a completion is a key step toward lifting O'Brian-Toledo-Tong invariants\nof coherent sheaves from Hodge cohomology to de Rham cohomology. An alternate\napproach toward the same end goal, instead using simplicial differential forms\nand Green complexes, can be found in Hosgood's works [Ho1, Ho2]. In the\nalgebraic setting, and more generally for K\\\"{a}hler manifolds, where Hodge and\nde Rham cohomologies agree, such extensions are not necessary, whereas in the\nnon-K\\\"{a}hler, or equivariant settings the two theories differ. We provide our\nformulae as a map of simplicial presheaves, which readily extend the results to\nthe equivariant setting and beyond. This paper can be viewed as a sequel to\n[GMTZ1] which covered such a discussion in Hodge cohomology. As an aside, we\ngive a conceptual understanding of how formulas obtained by Bott and Tu for\nChern classes using transition functions and those from Chern-Weil theory using\nconnections, are part of a natural unifying story.","main_category":"math.AG","categories":"math.AG,math.AT","published":"2025-04-10T03:01:18Z"}
{"aid":"http://arxiv.org/abs/2504.07415v1","title":"Leveraging LLMs for Multimodal Retrieval-Augmented Radiology Report\n  Generation via Key Phrase Extraction","summary":"Automated radiology report generation (RRG) holds potential to reduce\nradiologists' workload, especially as recent advancements in large language\nmodels (LLMs) enable the development of multimodal models for chest X-ray (CXR)\nreport generation. However, multimodal LLMs (MLLMs) are resource-intensive,\nrequiring vast datasets and substantial computational cost for training. To\naddress these challenges, we propose a retrieval-augmented generation approach\nthat leverages multimodal retrieval and LLMs to generate radiology reports\nwhile mitigating hallucinations and reducing computational demands. Our method\nuses LLMs to extract key phrases from radiology reports, effectively focusing\non essential diagnostic information. Through exploring effective training\nstrategies, including image encoder structure search, adding noise to text\nembeddings, and additional training objectives, we combine complementary\npre-trained image encoders and adopt contrastive learning between text and\nsemantic image embeddings. We evaluate our approach on MIMIC-CXR dataset,\nachieving state-of-the-art results on CheXbert metrics and competitive RadGraph\nF1 metric alongside MLLMs, without requiring LLM fine-tuning. Our method\ndemonstrates robust generalization for multi-view RRG, making it suitable for\ncomprehensive clinical applications.","main_category":"cs.CV","categories":"cs.CV,cs.CL,cs.LG","published":"2025-04-10T03:14:01Z"}
{"aid":"http://arxiv.org/abs/2504.07416v1","title":"RadZero: Similarity-Based Cross-Attention for Explainable\n  Vision-Language Alignment in Radiology with Zero-Shot Multi-Task Capability","summary":"Recent advancements in multi-modal models have significantly improved\nvision-language alignment in radiology. However, existing approaches struggle\nto effectively utilize complex radiology reports for learning, rely on\nlow-resolution images, and offer limited interpretability in attention\nmechanisms. To address these challenges, we introduce RadZero, a novel\nsimilarity-based cross-attention framework for vision-language alignment in\nradiology with zero-shot multi-task capability. RadZero leverages large\nlanguage models to extract minimal semantic sentences from radiology reports\nand employs a multi-positive contrastive learning strategy to effectively\ncapture relationships between images and multiple relevant textual\ndescriptions. It also utilizes a pre-trained vision encoder with additional\ntrainable Transformer layers, allowing efficient high-resolution image\nprocessing. By computing similarity between text embeddings and local image\npatch features, RadZero enables zero-shot inference with similarity probability\nfor classification and pixel-level cross-modal similarity maps for grounding\nand segmentation. Experimental results on public chest radiograph benchmarks\nshow that RadZero outperforms state-of-the-art methods in zero-shot\nclassification, grounding, and segmentation. Furthermore, cross-modal\nsimilarity map analysis highlights its potential for improving explainability\nin vision-language alignment. Additionally, qualitative evaluation demonstrates\nRadZero's capability for open-vocabulary semantic segmentation, further\nvalidating its effectiveness in medical imaging.","main_category":"cs.CV","categories":"cs.CV,cs.CL,cs.LG","published":"2025-04-10T03:14:17Z"}
{"aid":"http://arxiv.org/abs/2504.07419v1","title":"Exploring Vulnerabilities and Concerns in Solana Smart Contracts","summary":"The Solana blockchain was created by Anatoly Yakovenko of Solana Labs and was\nintroduced in 2017, employing a novel transaction verification method. However,\nat the same time, the innovation process introduced some new security issues.\nThe frequent security incidents in smart contracts have not only caused\nenormous economic losses, but also undermined the credit system based on the\nblockchain. The security and reliability of smart contracts have become a new\nfocus of research both domestically and abroad. This paper studies the current\nstatus of security analysis of Solana by researching Solana smart contract\nsecurity analysis tools. This paper systematically sorts out the\nvulnerabilities existing in Solana smart contracts and gives examples of some\nvulnerabilities, summarizes the principles of security analysis tools, and\ncomprehensively summarizes and details the security analysis tools in Solana\nsmart contracts. The data of Solana smart contract security analysis tools are\ncollected and compared with Ethereum, and the differences are analyzed and some\ntools are selected for practical testing.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-10T03:25:20Z"}
{"aid":"http://arxiv.org/abs/2504.07420v1","title":"Emergency Communication: OTFS-Based Semantic Transmission with Diffusion\n  Noise Suppression","summary":"Due to their flexibility and dynamic coverage capabilities, Unmanned Aerial\nVehicles (UAVs) have emerged as vital platforms for emergency communication in\ndisaster-stricken areas. However, the complex channel conditions in high-speed\nmobile scenarios significantly impact the reliability and efficiency of\ntraditional communication systems. This paper presents an intelligent emergency\ncommunication framework that integrates Orthogonal Time Frequency Space (OTFS)\nmodulation, semantic communication, and a diffusion-based denoising module to\naddress these challenges. OTFS ensures robust communication under dynamic\nchannel conditions due to its superior anti-fading characteristics and\nadaptability to rapidly changing environments. Semantic communication further\nenhances transmission efficiency by focusing on key information extraction and\nreducing data redundancy. Moreover, a diffusion-based channel denoising module\nis proposed to leverage the gradual noise reduction process and statistical\nnoise modeling, optimizing the accuracy of semantic information recovery.\nExperimental results demonstrate that the proposed solution significantly\nimproves link stability and transmission performance in high-mobility UAV\nscenarios, achieving at least a 3dB SNR gain over existing methods.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-10T03:25:56Z"}
{"aid":"http://arxiv.org/abs/2504.07421v1","title":"AgentAda: Skill-Adaptive Data Analytics for Tailored Insight Discovery","summary":"We introduce AgentAda, the first LLM-powered analytics agent that can learn\nand use new analytics skills to extract more specialized insights. Unlike\nexisting methods that require users to manually decide which data analytics\nmethod to apply, AgentAda automatically identifies the skill needed from a\nlibrary of analytical skills to perform the analysis. This also allows AgentAda\nto use skills that existing LLMs cannot perform out of the box. The library\ncovers a range of methods, including clustering, predictive modeling, and NLP\ntechniques like BERT, which allow AgentAda to handle complex analytics tasks\nbased on what the user needs. AgentAda's dataset-to-insight extraction strategy\nconsists of three key steps: (I) a question generator to generate queries\nrelevant to the user's goal and persona, (II) a hybrid Retrieval-Augmented\nGeneration (RAG)-based skill matcher to choose the best data analytics skill\nfrom the skill library, and (III) a code generator that produces executable\ncode based on the retrieved skill's documentation to extract key patterns. We\nalso introduce KaggleBench, a benchmark of curated notebooks across diverse\ndomains, to evaluate AgentAda's performance. We conducted a human evaluation\ndemonstrating that AgentAda provides more insightful analytics than existing\ntools, with 48.78% of evaluators preferring its analyses, compared to 27.67%\nfor the unskilled agent. We also propose a novel LLM-as-a-judge approach that\nwe show is aligned with human evaluation as a way to automate insight quality\nevaluation at larger scale.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T03:27:25Z"}
{"aid":"http://arxiv.org/abs/2504.07428v1","title":"Task-oriented Age of Information for Remote Inference with Hybrid\n  Language Models","summary":"Large Language Models (LLMs) have revolutionized the field of artificial\nintelligence (AI) through their advanced reasoning capabilities, but their\nextensive parameter sets introduce significant inference latency, posing a\nchallenge to ensure the timeliness of inference results. While Small Language\nModels (SLMs) offer faster inference speeds with fewer parameters, they often\ncompromise accuracy on complex tasks. This study proposes a novel remote\ninference system comprising a user, a sensor, and an edge server that\nintegrates both model types alongside a decision maker. The system dynamically\ndetermines the resolution of images transmitted by the sensor and routes\ninference tasks to either an SLM or LLM to optimize performance. The key\nobjective is to minimize the Task-oriented Age of Information (TAoI) by jointly\nconsidering the accuracy and timeliness of the inference task. Due to the\nnon-uniform transmission time and inference time, we formulate this problem as\na Semi-Markov Decision Process (SMDP). By converting the SMDP to an equivalent\nMarkov decision process, we prove that the optimal control policy follows a\nthreshold-based structure. We further develop a relative policy iteration\nalgorithm leveraging this threshold property. Simulation results demonstrate\nthat our proposed optimal policy significantly outperforms baseline approaches\nin managing the accuracy-timeliness trade-off.","main_category":"cs.IT","categories":"cs.IT,cs.NI,math.IT","published":"2025-04-10T03:48:09Z"}
{"aid":"http://arxiv.org/abs/2504.07444v1","title":"Lorentz-Drude dipoles in the radiative limit and their modeling in\n  finite-difference time-domain methods","summary":"The Lorentz-Drude model for electric dipoles is a classical framework widely\nused in the study of dipole dynamics and light-matter interactions. Here we\nfocus on the behaviors of Lorentz-Drude dipoles when their radiative rate\ndominates their energy loss. We show that dipole radiation losses do not count\ntoward phenomenological dipole losses if the driving field is interpreted as\nthe total field at the dipole. In particular, if the dipole does not contain\nnon-radiative losses, then the Lorentz-Drude damping term should be removed.\nThis is verified by self-consistent implementations of point dipoles in\nfinite-difference time-domain simulations, which also provide a method to\ndirectly compute the transport properties of light when dipoles are present.","main_category":"physics.optics","categories":"physics.optics,physics.class-ph","published":"2025-04-10T04:24:54Z"}
{"aid":"http://arxiv.org/abs/2504.07445v1","title":"$L^p$ estimates for joint quasimodes of two pseudodifferential operators\n  whose characteristic sets have $k$-th order contact","summary":"On a smooth, compact, $n$-dimensional Riemannian manifold, we consider\nfunctions $u_h$ that are joint quasimodes of two semiclassical\npseudodifferential operators $p_1(x,hD)$ and $p_2(x,hD)$. We develop $L^p$\nestimates for $u_h$ when the characteristic sets of $p_1$ and $p_2$ meet with\n$k$-th order contact. This paper is the natural extension of the\ntwo-dimensional results from arXiv:1909.12559 to $n$ dimensions.","main_category":"math.AP","categories":"math.AP","published":"2025-04-10T04:30:45Z"}
{"aid":"http://arxiv.org/abs/2504.07450v1","title":"Synthetic CT Generation from Time-of-Flight Non-Attenutaion-Corrected\n  PET for Whole-Body PET Attenuation Correction","summary":"Positron Emission Tomography (PET) imaging requires accurate attenuation\ncorrection (AC) to account for photon loss due to tissue density variations. In\nPET/MR systems, computed tomography (CT), which offers a straightforward\nestimation of AC is not available. This study presents a deep learning approach\nto generate synthetic CT (sCT) images directly from Time-of-Flight (TOF)\nnon-attenuation corrected (NAC) PET images, enhancing AC for PET/MR. We first\nevaluated models pre-trained on large-scale natural image datasets for a\nCT-to-CT reconstruction task, finding that the pre-trained model outperformed\nthose trained solely on medical datasets. The pre-trained model was then\nfine-tuned using an institutional dataset of 35 TOF NAC PET and CT volume\npairs, achieving the lowest mean absolute error (MAE) of 74.49 HU and highest\npeak signal-to-noise ratio (PSNR) of 28.66 dB within the body contour region.\nVisual assessments demonstrated improved reconstruction of both bone and soft\ntissue structures from TOF NAC PET images. This work highlights the\neffectiveness of using pre-trained deep learning models for medical image\ntranslation tasks. Future work will assess the impact of sCT on PET attenuation\ncorrection and explore additional neural network architectures and datasets to\nfurther enhance performance and practical applications in PET imaging.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-10T04:49:41Z"}
{"aid":"http://arxiv.org/abs/2504.07454v1","title":"How Can Objects Help Video-Language Understanding?","summary":"How multimodal large language models (MLLMs) perceive the visual world\nremains a mystery. To one extreme, object and relation modeling may be\nimplicitly implemented with inductive biases, for example by treating objects\nas tokens. To the other extreme, empirical results reveal the surprising\nfinding that simply performing visual captioning, which tends to ignore spatial\nconfiguration of the objects, serves as a strong baseline for video\nunderstanding. We aim to answer the question: how can objects help\nvideo-language understanding in MLLMs? We tackle the question from the object\nrepresentation and adaptation perspectives. Specifically, we investigate the\ntrade-off between representation expressiveness (e.g., distributed versus\nsymbolic) and integration difficulty (e.g., data-efficiency when learning the\nadapters). Through extensive evaluations on five video question answering\ndatasets, we confirm that explicit integration of object-centric representation\nremains necessary, and the symbolic objects can be most easily integrated while\nbeing performant for question answering. We hope our findings can encourage the\ncommunity to explore the explicit integration of perception modules into MLLM\ndesign. Our code and models will be publicly released.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T04:59:28Z"}
{"aid":"http://arxiv.org/abs/2504.07455v1","title":"Explicit Morphisms in the Galois-Tukey Category","summary":"If the Continuum Hypothesis is false, it implies the existence of\ncardinalities between the integers and the real numbers. In studying these\n\"cardinal characteristics of the continuum\", it was discovered that many of the\nassociated inequalities can be interpreted as morphisms within the\n\"Galois-Tukey\" category. This thesis aims to reformulate traditional direct\nproofs of cardinal characteristic inequalities by making the underlying\nmorphisms explicit. New, purely categorical results are also discussed.","main_category":"math.LO","categories":"math.LO","published":"2025-04-10T05:00:16Z"}
{"aid":"http://arxiv.org/abs/2504.07482v1","title":"Tame categorical local Langlands correspondence","summary":"In one of our previous articles, we outlined the formulation of a version of\nthe categorical arithmetic local Langlands conjecture. The aims of this article\nare threefold. First, we provide a detailed account of one component of this\nconjecture: the local Langlands category. Second, we aim to prove this\nconjecture in the tame case for quasi-split unramified reductive groups.\nFinally, we will explore the first applications of such categorical\nequivalence.","main_category":"math.RT","categories":"math.RT,math.AG","published":"2025-04-10T06:24:41Z"}
{"aid":"http://arxiv.org/abs/2504.07493v1","title":"Quickest change detection for UAV-based sensing","summary":"This paper addresses the problem of quickest change detection (QCD) at two\nspatially separated locations monitored by a single unmanned aerial vehicle\n(UAV) equipped with a sensor. At any location, the UAV observes i.i.d. data\nsequentially in discrete time instants. The distribution of the observation\ndata changes at some unknown, arbitrary time and the UAV has to detect this\nchange in the shortest possible time. Change can occur at most at one location\nover the entire infinite time horizon. The UAV switches between these two\nlocations in order to quickly detect the change. To this end, we propose\nLocation Switching and Change Detection (LS-CD) algorithm which uses a repeated\none-sided sequential probability ratio test (SPRT) based mechanism for\nobservation-driven location switching and change detection. The primary goal is\nto minimize the worst-case average detection delay (WADD) while meeting\nconstraints on the average run length to false alarm (ARL2FA) and the UAV's\ntime-averaged energy consumption. We provide a rigorous theoretical analysis of\nthe algorithm's performance by using theory of random walk. Specifically, we\nderive tight upper and lower bounds to its ARL2FA and a tight upper bound to\nits WADD. In the special case of a symmetrical setting, our analysis leads to a\nnew asymptotic upper bound to the ARL2FA of the standard CUSUM algorithm, a\nnovel contribution not available in the literature, to our knowledge. Numerical\nsimulations demonstrate the efficacy of LS-CD.","main_category":"eess.SP","categories":"eess.SP,cs.SY,eess.SY","published":"2025-04-10T06:49:55Z"}
{"aid":"http://arxiv.org/abs/2504.07500v1","title":"Energy-Efficient UAV Replacement in Software-Defined UAV Networks","summary":"Unmanned Aerial Vehicles (UAVs) in networked environments face significant\nchallenges due to energy constraints and limited battery life, which\nnecessitate periodic replacements to maintain continuous operation. Efficiently\nmanaging the handover of data flows during these replacements is crucial to\navoid disruptions in communication and to optimize energy consumption. This\npaper addresses the complex issue of energy-efficient UAV replacement in\nsoftware-defined UAV network. We introduce a novel approach based on\nestablishing a strict total ordering relation for UAVs and data flows, allowing\nus to formulate the problem as an integer linear program. By utilizing the\nGurobi solver, we obtain optimal handover schedules for the tested problem\ninstances. Additionally, we propose a heuristic algorithm that significantly\nreduces computational complexity while maintaining near-optimal performance.\nThrough comprehensive simulations, we demonstrate that our heuristic offers\npractical and scalable solution, ensuring energy-efficient UAV replacement\nwhile minimizing network disruptions. Our results suggest that the proposed\napproach can enhance UAV battery life and improve overall network reliability\nin real-world applications.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-10T06:58:35Z"}
{"aid":"http://arxiv.org/abs/2504.07501v1","title":"Distance signless Laplacian spectral radius and tough graphs involving\n  minimun degree","summary":"Let $G=(V(G),E(G))$ be a simple graph, where $V(G)$ and $E(G)$ are the vertex\nset and the edge set of $G$, respectively. The number of components of $G$ is\ndenoted by $c(G)$. Let $t$ be a positive real number, and a connected graph $G$\nis $t$-tough if $t c(G-S)\\leq|S|$ for every vertex cut $S$ of $V(G)$. The\ntoughness of graph $G$, denoted by $\\tau(G)$, is the largest value of $t$ for\nwhich $G$ is $t$-tough. Recently, Fan, Lin and Lu [European J. Combin.\n110(2023), 103701] presented sufficient conditions based on the spectral radius\nfor graphs to be 1-tough with minimum degree $\\delta(G)$ and graphs to be\n$t$-tough with $t\\geq 1$ being an integer, respectively. In this paper, we\nestablish sufficient conditions in terms of the distance signless Laplacian\nspectral radius for graphs to be 1-tough with minimum degree $\\delta(G)$ and\ngraphs to be $t$-tough, where $\\frac{1}{t}$ is a positive integer. Moreover, we\nconsider the relationship between the distance signless Laplacian spectral\nradius and $t$-tough graphs in terms of the order $n$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-10T07:01:52Z"}
{"aid":"http://arxiv.org/abs/2504.07509v1","title":"Coexistence of topologically trivial and non-trivial Yu-Shiba-Rusinov\n  bands in magnetic atomic chains on a superconductor","summary":"Majorana zero modes (MZMs) have been proposed as a promising basis for\nMajorana qubits offering great potential for topological quantum computation.\nSuch modes may form at the ends of a magnetic atomic chain on a superconductor.\nTypically only a single MZM may be present at one end of the chain, but\nsymmetry may protect multiple MZMs at the same end. Here, we study the\ntopological properties of Yu-Shiba-Rusinov (YSR) bands of excitations in Mn\nchains constructed on a Nb(110) and on a Ta(110) substrate using\nfirst-principles calculations and scanning tunneling microscopy and\nspectroscopy experiments. We demonstrate that even and odd YSR states with\nrespect to mirroring on the symmetry plane containing the chain have different\ndispersions, and both of them may give rise to MZMs separately. Although the\nspin-orbit coupling leads to a hybridization between the bands, multiple MZMs\nmay still exist due to the mirror symmetry. These findings highlight the\ninfluence of symmetries on interpreting the spectroscopic signatures of\ncandidates for MZMs.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-10T07:11:26Z"}
{"aid":"http://arxiv.org/abs/2504.07516v1","title":"Enhancements for Developing a Comprehensive AI Fairness Assessment\n  Standard","summary":"As AI systems increasingly influence critical sectors like\ntelecommunications, finance, healthcare, and public services, ensuring fairness\nin decision-making is essential to prevent biased or unjust outcomes that\ndisproportionately affect vulnerable entities or result in adverse impacts.\nThis need is particularly pressing as the industry approaches the 6G era, where\nAI will drive complex functions like autonomous network management and\nhyper-personalized services. The TEC Standard for Fairness Assessment and\nRating of AI Systems provides guidelines for evaluating fairness in AI,\nfocusing primarily on tabular data and supervised learning models. However, as\nAI applications diversify, this standard requires enhancement to strengthen its\nimpact and broaden its applicability. This paper proposes an expansion of the\nTEC Standard to include fairness assessments for images, unstructured text, and\ngenerative AI, including large language models, ensuring a more comprehensive\napproach that keeps pace with evolving AI technologies. By incorporating these\ndimensions, the enhanced framework will promote responsible and trustworthy AI\ndeployment across various sectors.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.HC","published":"2025-04-10T07:24:23Z"}
{"aid":"http://arxiv.org/abs/2504.07523v1","title":"Lifetime-limited Gigahertz-frequency Mechanical Oscillators with\n  Millisecond Coherence Times","summary":"High-frequency mechanical oscillators with long coherence times are essential\nto realizing a variety of high-fidelity quantum sensors, transducers, and\nmemories. However, the unprecedented coherence times needed for quantum\napplications require exquisitely sensitive new techniques to probe the material\norigins of phonon decoherence and new strategies to mitigate decoherence in\nmechanical oscillators. Here, we combine non-invasive laser spectroscopy\ntechniques with materials analysis to identify key sources of phonon\ndecoherence in crystalline media. Using micro-fabricated high-overtone bulk\nacoustic-wave resonators ($\\mu$HBARs) as an experimental testbed, we identify\nphonon-surface interactions as the dominant source of phonon decoherence in\ncrystalline quartz; lattice distortion, subsurface damage, and high\nconcentration of elemental impurities near the crystal surface are identified\nas the likely causes. Removal of this compromised surface layer using an\noptimized polishing process is seen to greatly enhance coherence times,\nenabling $\\mu$HBARs with Q-factors of > 240 million at 12 GHz frequencies,\ncorresponding to > 6 ms phonon coherence times and record-level f-Q products.\nComplementary phonon linewidth and time-domain ringdown measurements, performed\nusing a new Brillouin-based pump-probe spectroscopy technique, reveal\nnegligible dephasing within these oscillators. Building on these results, we\nidentify a path to > 100 ms coherence times as the basis for high-frequency\nquantum memories. These findings clearly demonstrate that, with enhanced\ncontrol over surfaces, dissipation and noise can be significantly reduced in a\nwide range of quantum systems.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mtrl-sci","published":"2025-04-10T07:41:47Z"}
{"aid":"http://arxiv.org/abs/2504.07536v1","title":"Criteria for finite injective dimension of modules over a local ring","summary":"Let $R$ be a commutative Noetherian local ring. We prove that the finiteness\nof the injective dimension of a finitely generated $R$-module $C$ is determined\nby the existence of a Cohen--Macaulay module $M$ that satisfies an inequality\nconcerning multiplicity and type, together with the vanishing of finitely many\nExt modules. As applications, we recover a result of Rahmani and Taherizadeh\nand provide sufficient conditions for a finitely generated $R$-module to have\nfinite injective dimension.","main_category":"math.AC","categories":"math.AC","published":"2025-04-10T08:02:23Z"}
{"aid":"http://arxiv.org/abs/2504.07538v1","title":"A 950 MHz SIMT Soft Processor","summary":"Although modern FPGAs have a performance potential of a 1 GHz clock frequency\n- with both clock networks and embedded blocks such as memories and DSP Blocks\ncapable of these clock rates - user implementations approaching this speed are\nrarely realized in practice. This is especially true of complex designs such as\nsoft processors.\n  In this work we implement a soft GPGPU which exceeds 950 MHz in an Altera\nAgilex-7 FPGA. The architecture is a 32-bit fixed point Single Instruction,\nMultiple Thread (SIMT) design, with parameterized thread and register spaces.\nUp to 4096 threads and 64K registers can be specified by the user. In one\nexample, a processor with 16K registers and a 16KB shared memory required\napproximately 7K ALMs, 99 M20K memories, and 32 DSP Blocks.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-10T08:05:36Z"}
{"aid":"http://arxiv.org/abs/2504.07540v1","title":"PoGO: A Scalable Proof of Useful Work via Quantized Gradient Descent and\n  Merkle Proofs","summary":"We present a design called \\emph{Proof of Gradient Optimization} (PoGO) for\nblockchain consensus, where miners produce verifiable evidence of training\nlarge-scale machine-learning models. Building on previous work, we incorporate\n\\emph{quantized gradients} (4-bit precision) to reduce storage and computation\nrequirements, while still preserving the ability of verifiers to check that\nreal progress has been made on lowering the model's loss. Additionally, we\nemploy Merkle proofs over the full 32-bit model to handle large parameter sets\nand to enable random leaf checks with minimal on-chain data. We illustrate\nthese ideas using GPT-3 (175B parameters) as a reference example and also refer\nto smaller but high-performance models (e.g., \\emph{Gemma~3} with 27B\nparameters). We provide an empirical cost analysis showing that verification is\nsignificantly cheaper than training, thanks in part to quantization and\nsampling. We also discuss the necessity of longer block times (potentially\nhours) when incorporating meaningful training steps, the trade-offs when using\nspecialized GPU hardware, and how binary diffs may incrementally optimize\nupdates. Finally, we note that fine-tuning can be handled in a similar manner,\nmerely changing the dataset and the manner of sampling but preserving the\noverall verification flow. Our protocol allows verifiers to issue either\n\\emph{positive} or \\emph{negative} attestations; these are aggregated at\nfinalization to either confirm the update or slash the miner.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-10T08:09:34Z"}
{"aid":"http://arxiv.org/abs/2504.07541v1","title":"On the initial ideal of a generic artinian Gorenstein algebra","summary":"In this note we show that the initial ideal of the annihilator ideal of a\ngeneric form is generated by the largest possible monomials in each degree. We\nalso show that the initial ideal with respect to the degree reverse\nlexicographical ordering of the annihilator ideal of the complete symmetric\nform has this property, by determining a minimal Gr\\\"obner basis of it.\nMoreover, we determine the total Betti numbers for a class of strongly stable\nmonomial ideals and show that these numbers agree with those for the degree\nreverse lexicographical initial ideals of the ideal generated by a sufficiently\nlarge number of generic forms, and of the annihilator ideal of a generic form.","main_category":"math.AC","categories":"math.AC","published":"2025-04-10T08:10:14Z"}
{"aid":"http://arxiv.org/abs/2504.07551v1","title":"Topology optimization of decoupling feeding networks for antenna arrays","summary":"Near-field and radiation coupling between nearby radiating elements is\nunavoidable, and it is considered a limiting factor for applications in\nwireless communications and active sensing. This article proposes a\ndensity-based topology optimization approach to design decoupling networks for\nsuch systems. The decoupling networks are designed based on a multi-objective\noptimization problem with the radiating elements replaced by their time-domain\nimpulse response for efficient computations and to enable the solution of the\ndesign problem using gradient-based optimization methods. We use the\nadjoint-field method to compute the gradients of the optimization objectives.\nAdditionally, nonlinear filters are applied during the optimization procedure\nto impose minimum-size control on the optimized designs. We demonstrate the\nconcept by designing the decoupling network for a two-element planar antenna\narray; the antenna is designed in a separate optimization problem. The\noptimized decoupling networks provide a signal path that destructively\ninterferes with the coupling between the radiating elements while preserving\ntheir individual matching to the feeding ports. Compact decoupling networks\ncapable of suppressing the mutual coupling by more than 10 dB between two\nclosely separated planar antennas operating around 2.45 GHz are presented and\nvalidated experimentally.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-10T08:27:04Z"}
{"aid":"http://arxiv.org/abs/2504.07552v1","title":"Uniqueness of supercritical Gaussian multiplicative chaos","summary":"We show that, for general convolution approximations to a large class of\nlog-correlated Gaussian fields, the properly normalised supercritical Gaussian\nmultiplicative chaos measures converge stably to a nontrivial limit. This limit\ndepends on the choice of regularisation only through a multiplicative constant\nand can be characterised as an integrated atomic measure with a random\nintensity expressed in terms of the critical Gaussian multiplicative chaos.","main_category":"math.PR","categories":"math.PR,math-ph,math.MP","published":"2025-04-10T08:29:12Z"}
{"aid":"http://arxiv.org/abs/2504.07561v1","title":"Regular Black Hole Models in the Transition from Baryonic Matter to\n  Quark Matter","summary":"In this paper, we investigate gravitational collapse scenarios involving\nbaryonic matter transitioning into quark-gluon plasma under extreme\nastrophysical conditions, focusing on their implications for the formation of\nregular black holes. Standard gravitational collapse models inevitably predict\ncentral singularities, highlighting the limitations of classical general\nrelativity in extreme density regimes. By introducing a physically motivated,\ninhomogeneous transition rate between baryonic and quark matter, we demonstrate\nanalytically and numerically that it is possible to construct regular black\nhole solutions featuring a nonsingular de Sitter-like core. We further analyze\nthe observable consequences of these models, particularly emphasizing\nmodifications to the black hole shadow radius, which provide direct\nobservational constraints accessible through Event Horizon Telescope (EHT)\nmeasurements.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-10T08:46:40Z"}
{"aid":"http://arxiv.org/abs/2504.07563v1","title":"Post-Newtonian dynamics of compact binaries with mass transfer","summary":"Taking into account the mass transfer effect, we derive the equations of\nmotion of a compact binary system at the second-half post-Newtonian order.\nApplying such equations of motion to quasi-circular orbits, we obtain the time\nderivative of the orbital frequency, which is consistent with the angular\nmomentum balance equation. Numerical estimates of the phase of gravitational\nwaves are provided for typical mass transfer rates. Our result can be used to\nimprove the waveforms of gravitational waves emitted by compact binaries with\nmass transfer.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-10T08:49:57Z"}
{"aid":"http://arxiv.org/abs/2504.07569v1","title":"Wide Binaries from GAIA DR3 : testing GR vs MOND with realistic triple\n  modelling","summary":"We provide an updated test for modifications of gravity from a sample of\nwide-binary stars from GAIA DR3, and their sky-projected relative velocities.\nHere we extend on our earlier 2023 study, using several updated selection cuts\naimed at reducing contamination from triple systems with an undetected third\nstar. We also use improved mass estimates from FLAMES, and we add refinements\nto previous modelling of the triple and other populations and the\nmodel-fitting. We fit histograms of observed vs Newtonian velocity differences\nto a flexible mixture of binary + triple populations with realistic\neccentricity distributions, plus unbound flyby and random-chance populations.\nWe find as before that Newtonian models provide a significantly better fit than\nMOND, though improved understanding of the triple population is necessary to\nmake this fully decisive.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-04-10T09:00:49Z"}
{"aid":"http://arxiv.org/abs/2504.07570v1","title":"Exploring Human-Like Thinking in Search Simulations with Large Language\n  Models","summary":"Simulating user search behavior is a critical task in information retrieval,\nwhich can be employed for user behavior modeling, data augmentation, and system\nevaluation. Recent advancements in large language models (LLMs) have opened up\nnew possibilities for generating human-like actions including querying,\nbrowsing, and clicking. In this work, we explore the integration of human-like\nthinking into search simulations by leveraging LLMs to simulate users' hidden\ncognitive processes. Specifically, given a search task and context, we prompt\nLLMs to first think like a human before executing the corresponding action. As\nexisting search datasets do not include users' thought processes, we conducted\na user study to collect a new dataset enriched with users' explicit thinking.\nWe investigate the impact of incorporating such human-like thinking on\nsimulation performance and apply supervised fine-tuning (SFT) to teach LLMs to\nemulate both human thinking and actions. Our experiments span two dimensions in\nleveraging LLMs for user simulation: (1) with or without explicit thinking, and\n(2) with or without fine-tuning on the thinking-augmented dataset. The results\ndemonstrate the feasibility and potential of incorporating human-like thinking\nin user simulations, though performance improvements on some metrics remain\nmodest. We believe this exploration provides new avenues and inspirations for\nadvancing user behavior modeling in search simulations.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-10T09:04:58Z"}
{"aid":"http://arxiv.org/abs/2504.07575v1","title":"Explicit Uncertainty Modeling for Video Watch Time Prediction","summary":"In video recommendation, a critical component that determines the system's\nrecommendation accuracy is the watch-time prediction module, since how long a\nuser watches a video directly reflects personalized preferences. One of the key\nchallenges of this problem is the user's stochastic watch-time behavior. To\nimprove the prediction accuracy for such an uncertain behavior, existing\napproaches show that one can either reduce the noise through duration bias\nmodeling or formulate a distribution modeling task to capture the uncertainty.\nHowever, the uncontrolled uncertainty is not always equally distributed across\nusers and videos, inducing a balancing paradox between the model accuracy and\nthe ability to capture out-of-distribution samples. In practice, we find that\nthe uncertainty of the watch-time prediction model also provides key\ninformation about user behavior, which, in turn, could benefit the prediction\ntask itself. Following this notion, we derive an explicit uncertainty modeling\nstrategy for the prediction model and propose an adversarial optimization\nframework that can better exploit the user watch-time behavior. This framework\nhas been deployed online on an industrial video sharing platform that serves\nhundreds of millions of daily active users, which obtains a significant\nincrease in users' video watch time by 0.31% through the online A/B test.\nFurthermore, extended offline experiments on two public datasets verify the\neffectiveness of the proposed framework across various watch-time prediction\nbackbones.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-10T09:19:19Z"}
{"aid":"http://arxiv.org/abs/2504.07579v1","title":"Controlling Complex Systems","summary":"This chapter provides a comprehensive overview of controlling collective\nbehavior in complex systems comprising large ensembles of interacting dynamical\nagents. Building upon traditional control theory's foundation in individual\nsystems, we introduce tools designed to address the unique challenges of\ncoordinating networks that exhibit emergent phenomena, including consensus,\nsynchronization, and pattern formation. We analyze how local agent interactions\ngenerate macroscopic behaviors and investigate the fundamental role of network\ntopology in determining system dynamics. Inspired by natural systems, we\nemphasize control strategies that achieve global coordination through localized\ninterventions while considering practical implementation challenges. The\nchapter concludes by presenting novel frameworks for managing very large agent\nensembles and leveraging interacting networks for control purposes.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-10T09:21:09Z"}
{"aid":"http://arxiv.org/abs/2504.07587v1","title":"Renormalization group-like flows in randomly connected tensor networks","summary":"Randomly connected tensor networks (RCTN) are the dynamical systems defined\nby summing over all the possible networks of tensors. Because of the absence of\nfixed lattice structure, RCTN is not expected to have renormalization\nprocedures. In this paper, however, we consider RCTN with a real tensor, and it\nis proven that a Hamiltonian vector flow of a tensor model in the canonical\nformalism with a positive cosmological constant has the properties which a\nrenormalization group (RG) flow of RCTN would have: The flow has fixed points\non phase transition surfaces; every flow line is asymptotically terminated by\nfixed points at both ends, where an upstream fixed point has higher criticality\nthan a downstream one; the flow goes along phase transition surfaces; there\nexists a function which monotonically decreases along the flow, analogously to\nthe $a$- and $c$-functions of RG. A complete classification of fixed points is\ngiven. Although there are no cyclic flows in the strict sense, these exist, if\ninfinitesimal jumps are allowed near fixed points.","main_category":"hep-th","categories":"hep-th","published":"2025-04-10T09:30:04Z"}
{"aid":"http://arxiv.org/abs/2504.07588v1","title":"Jordan Decomposition for WBV-functions in Ordered Normed Spaces","summary":"In this paper, we define two relations one by orthogonality in vector\nlattices named as strong relation and the other by bounded linear functionals\nin normed spaces named as weak relation. It turns out that strong relation is\nan equivalence relation. We study some of the characterizations of these\nrelations. Given a non-zero element in a normed space, we construct an\nextensible cone which makes that normed space, an ordered normed space. This\nextensible cone induces the weak relation in the normed space. Later, we prove\na Jordan Decomposition Theorem in a normed space by the weak relation induced\nby the extensible cone.","main_category":"math.FA","categories":"math.FA","published":"2025-04-10T09:33:41Z"}
{"aid":"http://arxiv.org/abs/2504.07591v1","title":"On the Cox rings of some hypersurfaces","summary":"We introduce a cohomological method to compute Cox rings of hypersurfaces in\nthe ambient space P^1 x P^n, which is more direct than existing methods. We\nprove that smooth hypersurfaces defined by regular sequences of coefficients\nare Mori dream spaces, generalizing a result of Ottem. We also compute Cox\nrings of certain specialized examples. In particular, we compute Cox rings in\nthe well-studied family of Calabi--Yau threefolds of bidegree (2,4) in P^1 x\nP^3, determining explicitly how the Cox ring can jump discontinuously in a\nsmooth family.","main_category":"math.AG","categories":"math.AG","published":"2025-04-10T09:44:51Z"}
{"aid":"http://arxiv.org/abs/2504.07607v1","title":"Stochastic Smoothed Primal-Dual Algorithms for Nonconvex Optimization\n  with Linear Inequality Constraints","summary":"We propose smoothed primal-dual algorithms for solving stochastic and smooth\nnonconvex optimization problems with linear inequality constraints. Our\nalgorithms are single-loop and only require a single stochastic gradient based\non one sample at each iteration. A distinguishing feature of our algorithm is\nthat it is based on an inexact gradient descent framework for the Moreau\nenvelope, where the gradient of the Moreau envelope is estimated using one step\nof a stochastic primal-dual augmented Lagrangian method. To handle inequality\nconstraints and stochasticity, we combine the recently established global error\nbounds in constrained optimization with a Moreau envelope-based analysis of\nstochastic proximal algorithms. For obtaining $\\varepsilon$-stationary points,\nwe establish the optimal $O(\\varepsilon^{-4})$ sample complexity guarantee for\nour algorithms and provide extensions to stochastic linear constraints. We also\nshow how to improve this complexity to $O(\\varepsilon^{-3})$ by using variance\nreduction and the expected smoothness assumption. Unlike existing methods, the\niterations of our algorithms are free of subproblems, large batch sizes or\nincreasing penalty parameters and use dual variable updates to ensure\nfeasibility.","main_category":"math.OC","categories":"math.OC,cs.LG","published":"2025-04-10T09:59:43Z"}
{"aid":"http://arxiv.org/abs/2504.07608v1","title":"DUCA: Dynamic Universe Cosmological Analysis. I. The halo mass function\n  in dynamical dark energy cosmologies","summary":"The halo mass function (HMF) is fundamental for interpreting the number\ncounts of galaxy clusters, serving as a pivotal theoretical tool in cosmology.\nWith the advent of high-precision surveys such as LSST, eROSITA, DESI, and\nEuclid, accurate HMF modeling becomes indispensable to avoid systematic biases\nin cosmological parameter estimation from cluster cosmology. Moreover, these\nsurveys aim to shed light on the dark sector and uncover dark energy's puzzling\nnature, necessitating models that faithfully capture its features to ensure\nrobust parameter inference. We aim to construct a model for the HMF in\ndynamical dark energy cosmologies that preserves the accuracy achieved for the\nstandard $\\Lambda (\\nu)$CDM model of cosmology, while meeting the precision\nrequirements necessary for future cosmological surveys. Our approach models the\nHMF parameters as functions of the deceleration parameter at the turnaround, a\nquantity shown to encapsulate essential information regarding the impact of\ndynamical dark energy on structure formation. We calibrate the model using\nresults from a comprehensive suite of $N$-body simulations spanning various\ncosmological scenarios, ensuring sub-percent systematic accuracy. We present an\nHMF model tailored for dynamical dark energy cosmologies. The model is\ncalibrated following a Bayesian approach, and its uncertainty is characterized\nby a single parameter controlling its systematic error, which remains at the\nsub-percent level. This ensures that theoretical uncertainties from our model\nare subdominant relative to other error sources in future cluster number counts\nanalyses.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-10T09:59:51Z"}
{"aid":"http://arxiv.org/abs/2504.07610v1","title":"What Contributes to Affective Polarization in Networked Online\n  Environments? Evidence from an Agent-Based Model","summary":"Affective polarization, or, inter-party hostility, is increasingly recognized\nas a pervasive issue in democracies worldwide, posing a threat to social\ncohesion. The digital media ecosystem, now widely accessible and ever-present,\nhas often been implicated in accelerating this phenomenon. However, the precise\ncausal mechanisms responsible for driving affective polarization have been a\nsubject of extensive debate. While the concept of echo chambers, characterized\nby individuals ensconced within like-minded groups, bereft of\ncounter-attitudinal content, has long been the prevailing hypothesis,\naccumulating empirical evidence suggests a more nuanced picture. This study\naims to contribute to the ongoing debate by employing an agent-based model to\nillustrate how affective polarization is either fostered or hindered by\nindividual news consumption and dissemination patterns based on ideological\nalignment. To achieve this, we parameterize three key aspects: (1) The\naffective asymmetry of individuals' engagement with in-party versus out-party\ncontent, (2) The proportion of in-party members within one's social\nneighborhood, and (3) The degree of partisan bias among the elites within the\npopulation. Subsequently, we observe macro-level changes in affective\npolarization within the population under various conditions stipulated by these\nparameters. This approach allows us to explore the intricate dynamics of\naffective polarization within digital environments, shedding light on the\ninterplay between individual behaviors, social networks, and information\nexposure.","main_category":"cs.MA","categories":"cs.MA","published":"2025-04-10T10:00:50Z"}
{"aid":"http://arxiv.org/abs/2504.07611v1","title":"Conditional Conformal Risk Adaptation","summary":"Uncertainty quantification is becoming increasingly important in image\nsegmentation, especially for high-stakes applications like medical imaging.\nWhile conformal risk control generalizes conformal prediction beyond standard\nmiscoverage to handle various loss functions such as false negative rate, its\napplication to segmentation often yields inadequate conditional risk control:\nsome images experience very high false negative rates while others have\nnegligibly small ones. We develop Conformal Risk Adaptation (CRA), which\nintroduces a new score function for creating adaptive prediction sets that\nsignificantly improve conditional risk control for segmentation tasks. We\nestablish a novel theoretical framework that demonstrates a fundamental\nconnection between conformal risk control and conformal prediction through a\nweighted quantile approach, applicable to any score function. To address the\nchallenge of poorly calibrated probabilities in segmentation models, we\nintroduce a specialized probability calibration framework that enhances the\nreliability of pixel-wise inclusion estimates. Using these calibrated\nprobabilities, we propose Calibrated Conformal Risk Adaptation (CCRA) and a\nstratified variant (CCRA-S) that partitions images based on their\ncharacteristics and applies group-specific thresholds to further enhance\nconditional risk control. Our experiments on polyp segmentation demonstrate\nthat all three methods (CRA, CCRA, and CCRA-S) provide valid marginal risk\ncontrol and deliver more consistent conditional risk control across diverse\nimages compared to standard approaches, offering a principled approach to\nuncertainty quantification that is particularly valuable for high-stakes and\npersonalized segmentation applications.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-10T10:01:06Z"}
{"aid":"http://arxiv.org/abs/2504.07614v1","title":"Enhanced THz emission from spintronic emitters with Pt-Al alloys","summary":"Platinum (Pt) is the element with the largest spin Hall conductivity and is\nknown as the most efficient spin-to-charge conversion material in spintronic\nTHz emitters. By alloying with aluminum (Al), its resistivity can be\nsubstantially increased, exceeding $100\\,\\mu\\Omega$cm. While the spin Hall\nconductivity is reduced by alloying, the relative resistivity increase\nsurpasses the reduction of spin Hall conductivity and thereby enhances the spin\nHall angle. We make use of this mechanism to improve the commonly used Pt-based\nspintronic THz emitter and demonstrate that an increase of 67% in the THz\nemission amplitude can be achieved between 20\\% and 30\\% Al in Pt. We show that\nthe enhanced THz emission amplitude is driven by the enhanced multilayer\nimpedance due to the larger resistivity.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-10T10:05:03Z"}
{"aid":"http://arxiv.org/abs/2504.07618v1","title":"CTSR: Cartesian tensor-based sparse regression for data-driven discovery\n  of high-dimensional invariant governing equations","summary":"Accurate and concise governing equations are crucial for understanding system\ndynamics. Recently, data-driven methods such as sparse regression have been\nemployed to automatically uncover governing equations from data, representing a\nsignificant shift from traditional first-principles modeling. However, most\nexisting methods focus on scalar equations, limiting their applicability to\nsimple, low-dimensional scenarios, and failing to ensure rotation and\nreflection invariance without incurring significant computational cost or\nrequiring additional prior knowledge. This paper proposes a Cartesian\ntensor-based sparse regression (CTSR) technique to accurately and efficiently\nuncover complex, high-dimensional governing equations while ensuring\ninvariance. Evaluations on two two-dimensional (2D) and two three-dimensional\n(3D) test cases demonstrate that the proposed method achieves superior accuracy\nand efficiency compared to the conventional technique.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-10T10:06:29Z"}
{"aid":"http://arxiv.org/abs/2504.07620v1","title":"Equivariant recollements and singular equivalences","summary":"In this paper we investigate equivariant recollements of abelian (resp.\ntriangulated) categories. We first characterize when a recollement of abelian\n(resp. triangulated) categories induces an equivariant recollement, i.e. a\nrecollement between the corresponding equivariant abelian (resp. triangulated)\ncategories. We further investigate singular equivalences in the context of\nequivariant abelian recollements. In particular, we characterize when a\nsingular equivalence induced by the quotient functor in an abelian recollement\nlift to a singular equivalence induced by the equivariant quotient functor. As\napplications of our results: (i) we construct equivariant recollements for the\nderived category of a quasi-compact, quasi-separated scheme where the action is\ncoming from a subgroup of the automorphism group of the scheme and (ii) we\nderive new singular equivalences between certain skew group algebras.","main_category":"math.RT","categories":"math.RT,math.AG,math.CT,math.RA","published":"2025-04-10T10:08:23Z"}
{"aid":"http://arxiv.org/abs/2504.07623v1","title":"Joint Travel Route Optimization Framework for Platooning","summary":"Platooning represents an advanced driving technology designed to assist\ndrivers in traffic convoys of varying lengths, enhancing road safety, reducing\ndriver fatigue, and improving fuel efficiency. Sophisticated automated driving\nassistance systems have facilitated this innovation. Recent advancements in\nplatooning emphasize cooperative mechanisms within both centralized and\ndecentralized architectures enabled by vehicular communication technologies.\nThis study introduces a cooperative route planning optimization framework aimed\nat promoting the adoption of platooning through a centralized platoon formation\nstrategy at the system level. This approach is envisioned as a transitional\nphase from individual (ego) driving to fully collaborative driving.\nAdditionally, this research formulates and incorporates travel cost metrics\nrelated to fuel consumption, driver fatigue, and travel time, considering\nregulatory constraints on consecutive driving durations. The performance of\nthese cost metrics has been evaluated using Dijkstra's and A* shortest path\nalgorithms within a network graph framework. The results indicate that the\nproposed architecture achieves an average cost improvement of 14 % compared to\nindividual route planning for long road trips.","main_category":"cs.ET","categories":"cs.ET,cs.RO,cs.SY,eess.SY","published":"2025-04-10T10:13:20Z"}
{"aid":"http://arxiv.org/abs/2504.07631v1","title":"The super Alternative Daugavet property for Banach spaces","summary":"We introduce the super alternative Daugavet property (super ADP) which lies\nstrictly between the Daugavet property and the Alternative Daugavet property as\nfollows. A Banach space $X$ has the super ADP if for every element $x$ in the\nunit sphere and for every relatively weakly open subset $W$ of the unit ball\nintersecting the unit sphere, one can find an element $y\\in W$ and a modulus\none scalar $\\theta$ such that $\\|x+\\theta y\\|$ is almost two. It is known that\nspaces with the Daugavet property satisfy this condition, and that this\ncondition implies the Alternative Daugavet property. We first provide examples\nof super ADP spaces which fail the Daugavet property. We show that the norm of\na super ADP space is rough, hence the space cannot be Asplund, and we also\nprove that the space fails the point of continuity property (particularly, the\nRadon--Nikod\\'ym property). In particular, we get examples of spaces with the\nAlternative Daugavet property that fail the super ADP. For a better\nunderstanding of the differences between the super ADP, the Daugavet property,\nand the Alternative Daugavet property, we will also consider the localizations\nof these three properties and prove that they behave rather differently. As a\nconsequence, we provide characterizations of the super ADP for spaces of\nvector-valued continuous functions and of vector-valued integrable functions.","main_category":"math.FA","categories":"math.FA","published":"2025-04-10T10:25:23Z"}
{"aid":"http://arxiv.org/abs/2504.07632v1","title":"A Stochastic Ekman-Stokes Model for Coupled Ocean-Atmosphere-Wave\n  Dynamics","summary":"Accurate representation of atmosphere-ocean boundary layers, including the\ninterplay of turbulence, surface waves, and air-sea fluxes, remains a challenge\nin geophysical fluid dynamics, particularly for climate simulations. This study\nintroduces a stochastic coupled Ekman-Stokes model (SCESM) developed within the\nphysically consistent Location Uncertainty framework, explicitly incorporating\nrandom turbulent fluctuations and surface wave effects. The SCESM integrates\nestablished parameterizations for air-sea fluxes, turbulent viscosity, and\nStokes drift, and its performance is rigorously assessed through ensemble\nsimulations against LOTUS observational data. A performance ranking analysis\nquantifies the impact of different model components, highlighting the critical\nrole of explicit uncertainty representation in both oceanic and atmospheric\ndynamics for accurately capturing system variability. Wave-induced mixing terms\nimprove model performance, while wave-dependent surface roughness enhances\nair-sea fluxes but reduces the relative influence of wave-driven mixing. This\nfully coupled stochastic framework provides a foundation for advancing boundary\nlayer parameterizations in large-scale climate models.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-10T10:27:09Z"}
{"aid":"http://arxiv.org/abs/2504.07634v1","title":"Agent That Debugs: Dynamic State-Guided Vulnerability Repair","summary":"In recent years, more vulnerabilities have been discovered every day, while\nmanual vulnerability repair requires specialized knowledge and is\ntime-consuming. As a result, many detected or even published vulnerabilities\nremain unpatched, thereby increasing the exposure of software systems to\nattacks. Recent advancements in agents based on Large Language Models have\ndemonstrated their increasing capabilities in code understanding and\ngeneration, which can be promising to achieve automated vulnerability repair.\nHowever, the effectiveness of agents based on static information retrieval is\nstill not sufficient for patch generation. To address the challenge, we propose\na program repair agent called VulDebugger that fully utilizes both static and\ndynamic context, and it debugs programs in a manner akin to humans. The agent\ninspects the actual state of the program via the debugger and infers expected\nstates via constraints that need to be satisfied. By continuously comparing the\nactual state with the expected state, it deeply understands the root causes of\nthe vulnerabilities and ultimately accomplishes repairs. We experimentally\nevaluated VulDebugger on 50 real-life projects. With 60.00% successfully fixed,\nVulDebugger significantly outperforms state-of-the-art approaches for\nvulnerability repair.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-10T10:31:10Z"}
{"aid":"http://arxiv.org/abs/2504.07638v1","title":"Predicting the Lifespan of Industrial Printheads with Survival Analysis","summary":"Accurately predicting the lifespan of critical device components is essential\nfor maintenance planning and production optimization, making it a topic of\nsignificant interest in both academia and industry. In this work, we\ninvestigate the use of survival analysis for predicting the lifespan of\nproduction printheads developed by Canon Production Printing. Specifically, we\nfocus on the application of five techniques to estimate survival probabilities\nand failure rates: the Kaplan-Meier estimator, Cox proportional hazard model,\nWeibull accelerated failure time model, random survival forest, and gradient\nboosting. The resulting estimates are further refined using isotonic regression\nand subsequently aggregated to determine the expected number of failures. The\npredictions are then validated against real-world ground truth data across\nmultiple time windows to assess model reliability. Our quantitative evaluation\nusing three performance metrics demonstrates that survival analysis outperforms\nindustry-standard baseline methods for printhead lifespan prediction.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-10T10:38:13Z"}
{"aid":"http://arxiv.org/abs/2504.07639v1","title":"IntÃ©grale orbitale pondÃ©rÃ©e via l'induite de Lusztig-Spaltenstein\n  gÃ©nÃ©ralisÃ©e","summary":"In this article, we present two novel approaches to constructing weighted\norbital integrals of an inner form of a general linear group. Our method\nutilizes generalized Lustig-Spaltenstein induction. Furthermore, we will prove\nthat a weighted orbital integral on the Lie algebra constitutes a tempered\ndistribution. We also demonstrate that our new definitions and Arthur's\noriginal definition are consistent.","main_category":"math.RT","categories":"math.RT","published":"2025-04-10T10:38:30Z"}
{"aid":"http://arxiv.org/abs/2504.07643v1","title":"CollEX -- A Multimodal Agentic RAG System Enabling Interactive\n  Exploration of Scientific Collections","summary":"In this paper, we introduce CollEx, an innovative multimodal agentic\nRetrieval-Augmented Generation (RAG) system designed to enhance interactive\nexploration of extensive scientific collections. Given the overwhelming volume\nand inherent complexity of scientific collections, conventional search systems\noften lack necessary intuitiveness and interactivity, presenting substantial\nbarriers for learners, educators, and researchers. CollEx addresses these\nlimitations by employing state-of-the-art Large Vision-Language Models (LVLMs)\nas multimodal agents accessible through an intuitive chat interface. By\nabstracting complex interactions via specialized agents equipped with advanced\ntools, CollEx facilitates curiosity-driven exploration, significantly\nsimplifying access to diverse scientific collections and records therein. Our\nsystem integrates textual and visual modalities, supporting educational\nscenarios that are helpful for teachers, pupils, students, and researchers by\nfostering independent exploration as well as scientific excitement and\ncuriosity. Furthermore, CollEx serves the research community by discovering\ninterdisciplinary connections and complementing visual data. We illustrate the\neffectiveness of our system through a proof-of-concept application containing\nover 64,000 unique records across 32 collections from a local scientific\ncollection from a public university.","main_category":"cs.IR","categories":"cs.IR,cs.CL,cs.CV","published":"2025-04-10T10:44:19Z"}
{"aid":"http://arxiv.org/abs/2504.07653v1","title":"Optimum design of permeable diffractive lenses based on photon sieves","summary":"Photon sieves are permeable diffractive optical elements generated by open\napertures on a substrate. These elements are well suited for the monitoring of\nrunning fluids. Our analysis considers the fabrication constrains of the photon\nsieve and translate them into values of the optical parameters of the element.\nWhen used as focusing elements, or diffractive lenses, the spatial distribution\nof apertures can be designed to maximize the intensity at the focal plane and\nthe permeability of the device. This is done by defining a weighted merit\nfunction. The computation time of this merit function is key when applying\ndifferent strategies for the design, which often require a very large number of\ncalculations of this merit function. Then, besides using a reliable propagation\nmethod, we have included an analytic solution applicable for circular\napertures. Also, a geometrical merit function is proposed to simplify and\nreduce the computation even more. The methods proposed in this contribution are\ncompared in terms of the focused irradiance and permeability parameters,\nallowing an educated choice adapted to the given case or application. In this\ncontribution we analyze several methods to generate photon sieves in an optimum\nmanner. The resulted spatial distributions resemble the classical Fresnel zone\narrangement.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-10T11:00:25Z"}
{"aid":"http://arxiv.org/abs/2504.07664v1","title":"Data Requirement Goal Modeling for Machine Learning Systems","summary":"Machine Learning (ML) has been integrated into various software and systems.\nTwo main components are essential for training an ML model: the training data\nand the ML algorithm. Given the critical role of data in ML system development,\nit has become increasingly important to assess the quality of data attributes\nand ensure that the data meets specific requirements before its utilization.\nThis work proposes an approach to guide non-experts in identifying data\nrequirements for ML systems using goal modeling. In this approach, we first\ndevelop the Data Requirement Goal Model (DRGM) by surveying the white\nliterature to identify and categorize the issues and challenges faced by data\nscientists and requirement engineers working on ML-related projects. An initial\nDRGM was built to accommodate common tasks that would generalize across\nprojects. Then, based on insights from both white and gray literature, a\ncustomization mechanism is built to help adjust the tasks, KPIs, and goals'\nimportance of different elements within the DRGM. The generated model can aid\nits users in evaluating different datasets using GRL evaluation strategies. We\nthen validate the approach through two illustrative examples based on\nreal-world projects. The results from the illustrative examples demonstrate\nthat the data requirements identified by the proposed approach align with the\nrequirements of real-world projects, demonstrating the practicality and\neffectiveness of the proposed framework. The proposed dataset selection\ncustomization mechanism and the proposed DRGM are helpful in guiding\nnon-experts in identifying the data requirements for machine learning systems\ntailored to a specific ML problem. This approach also aids in evaluating\ndifferent dataset alternatives to choose the optimum dataset for the problem.\nFor future work, we recommend implementing tool support to generate the DRGM\nbased on a chatbot interface.","main_category":"cs.SE","categories":"cs.SE,cs.LG","published":"2025-04-10T11:30:25Z"}
{"aid":"http://arxiv.org/abs/2504.07665v1","title":"Chirality-induced selectivity of angular momentum by orbital Edelstein\n  effect in carbon nanotubes","summary":"Carbon nanotubes (CNTs) are promising materials exhibiting exceptional\nstrength, electrical conductivity, and thermal properties, making them\npromising for various technologies. Besides achiral configurations with a\nzigzag or armchair edge, there exist chiral CNTs with a broken inversion\nsymmetry. Here, we demonstrate that chiral CNTs exhibit chirality-induced\norbital selectivity (CIOS), which is caused by the orbital Edelstein effect and\ncould be detected as chirality-induced spin selectivity (CISS). We find that\nthe orbital Edelstein susceptibility is an odd function of the chirality angle\nof the nanotube and is proportional to its radius. For metallic CNTs close to\nthe Fermi level, the orbital Edelstein susceptibility increases quadratically\nwith energy. This makes the CISS and CIOS of metallic chiral nanotubes\nconveniently tunable by doping or applying a gate voltage, which allows for the\ngeneration of spin- and orbital-polarized currents. The possibility of\ngenerating large torques makes chiral CNTs interesting candidates for\ntechnological applications in spin-orbitronics and quantum computing.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-04-10T11:39:13Z"}
{"aid":"http://arxiv.org/abs/2504.07666v1","title":"On a fuzzy Landau Equation: Part I. A variational approach","summary":"This article is the first in a series of works on the fuzzy Landau equation,\nwhere particles interact through delocalised Coulomb collisions. Here, we\nestablish a variational characterisation that recasts the fuzzy Landau equation\nwithin the framework of GENERIC systems (General Equations for Non-Equilibrium\nReversible-Irreversible Coupling).","main_category":"math.AP","categories":"math.AP","published":"2025-04-10T11:39:35Z"}
{"aid":"http://arxiv.org/abs/2504.07674v1","title":"Is the atmospheric river operating at a self-organized criticality\n  state?","summary":"Atmospheric rivers (ARs) are essential components of the global hydrological\ncycle, with profound implications for water resources, extreme weather events,\nand climate dynamics. Yet, the statistical organization and underlying physical\nmechanisms of AR intensity and evolution remain poorly understood. Here we\napply methods from statistical physics to analyze the full life cycle of ARs\nand identify universal signatures of self-organized criticality (SOC). We\ndemonstrate that AR morphology exhibits nontrivial fractal geometry, while AR\nevent sizes, quantified via integrated water vapor transport, follow robust\npower-law distributions, displaying finite-size scaling. These scaling\nbehaviors persist under warming scenarios, suggesting that ARs operate near a\ncritical state as emergent, self-regulating systems. Concurrently, we observe a\nsystematic poleward migration and intensification of ARs, linked to\nthermodynamic amplification and dynamical reorganization. Our findings\nestablish a statistical physics framework for ARs, linking critical phenomena\nto the spatiotemporal structure of extreme events in a warming climate.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-04-10T11:55:22Z"}
{"aid":"http://arxiv.org/abs/2504.07685v1","title":"Context-Aware Monolingual Human Evaluation of Machine Translation","summary":"This paper explores the potential of context-aware monolingual human\nevaluation for assessing machine translation (MT) when no source is given for\nreference. To this end, we compare monolingual with bilingual evaluations (with\nsource text), under two scenarios: the evaluation of a single MT system, and\nthe comparative evaluation of pairwise MT systems. Four professional\ntranslators performed both monolingual and bilingual evaluations by assigning\nratings and annotating errors, and providing feedback on their experience. Our\nfindings suggest that context-aware monolingual human evaluation achieves\ncomparable outcomes to human bilingual evaluations, and suggest the feasibility\nand potential of monolingual evaluation as an efficient approach to assessing\nMT.","main_category":"cs.CL","categories":"cs.CL,cs.HC","published":"2025-04-10T12:13:58Z"}
{"aid":"http://arxiv.org/abs/2504.07686v1","title":"Measurements of Higgs boson production via gluon-gluon fusion and\n  vector-boson fusion using $H\\rightarrow WW^\\ast \\rightarrow \\ellÎ½\\ellÎ½$\n  decays in $pp$ collisions with the ATLAS detector and their effective field\n  theory interpretations","summary":"Higgs boson production cross-sections via gluon-gluon fusion and vector-boson\nfusion in proton-proton collisions are measured in the $H\\rightarrow WW^\\ast\n\\rightarrow \\ell\\nu\\ell\\nu$ decay channel. The Large Hadron Collider delivered\nproton-proton collisions at a centre-of-mass energy of $13\\,\\textrm{TeV}$\nbetween 2015 and 2018, which were recorded by the ATLAS detector, corresponding\nto an integrated luminosity of $140\\,\\textrm{fb}^{-1}$. The total\ncross-sections for Higgs boson production by gluon-gluon fusion and\nvector-boson fusion times the $H\\rightarrow WW^\\ast$ branching ratio are\nmeasured to be $12.4^{+1.3}_{-1.2}\\,\\textrm{pb}$ and\n$0.79^{+0.18}_{-0.16}\\,\\textrm{pb}$, respectively, in agreement with the\nStandard Model predictions. Higgs boson production is further characterised\nthrough measurements of Simplified Template Cross-Sections in a total of\nfifteen kinematic fiducial regions. A new scheme of kinematic fiducial regions\nhas been introduced to enhance the sensitivity to CP-violating effects in Higgs\nboson interactions. Both schemes are used to constrain CP-even and CP-odd\ndimension-six operators in the Standard Model effective field theory.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-10T12:15:04Z"}
{"aid":"http://arxiv.org/abs/2504.07693v1","title":"Molecular nature of hidden-charm pentaquark states $P_{c\\bar{c}s}$ with\n  strangeness $S=-1$","summary":"We investigate the hidden-charm pentaquark states with strangeness $S=-1$\n($P_{c\\bar{c}s}$) within an off-shell coupled-channel approach based on\neffective Lagrangians that respect heavy-quark spin symmetry, SU(3) flavor\nsymmetry, and hidden local symmetry. All relevant meson-baryon two-body\nchannels composed of low-lying anti-charmed mesons and singly-charmed baryons\nwith $S=-1$, as well as the $J/\\psi \\Lambda$ channel, are included. We find a\ntotal of eleven negative-parity states and three positive-parity states. AMong\nthe negative-parity states, the $P_{c\\bar{c}s}(4338)$ and $P_{c\\bar{c}s}(4459)$\ncan be naturally interpreted as $\\bar{D} \\Xi_c$ and $\\bar{D}^* \\Xi_c$ molecular\nstates, respectively. We identify a second state, $P_{c\\bar{c}s}(4472)$,\nlocated close to the $P_{c\\bar{c}s}(4459)$ but with different spin and width,\nwhich may correspond to the structure observed by the Belle Collaboration. Both\nstates are generated from the $\\bar{D}^* \\Xi_c$ channel and can be interpreted\nas spin partners. Their properties are consistent with recent experimental\nobservations, providing strong support for the molecular interpretation of the\n$P_{c\\bar{c}s}$ states. We also observe a two-pole structure near the\n$\\bar{D}_s^* \\Lambda_c$ and $\\bar{D}^* \\Xi_c'$ channel depending on\nspin-parity.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-10T12:26:39Z"}
{"aid":"http://arxiv.org/abs/2504.07710v1","title":"Constraining off-shell Higgs boson production and the Higgs boson total\n  width using $WW\\to \\ellÎ½\\ellÎ½$ final states with the ATLAS detector","summary":"A measurement of off-shell Higgs boson production is performed in the $H^{*}\n\\rightarrow WW$ channel. The measurement uses a proton-proton collision dataset\nwith an integrated luminosity of 140 fb$^{-1}$ collected at a centre-of-mass\nenergy of 13 TeV by the ATLAS detector at the Large Hadron Collider. Final\nstates in which both $W$ bosons decay leptonically are targeted, and events are\ncategorised based on the flavour of the final-state leptons, the jet\nmultiplicity, and the output of neural network-based classifiers. The data are\nfound to be compatible with the Standard Model expectation. An observed\n(expected) upper limit at 95% confidence level is set on the rate of off-shell\nHiggs boson production at a value of 3.4 (4.4) times the Standard Model\nprediction. These results are combined with the results from the measurement of\non-shell Higgs boson production with the same final states to obtain an\nobserved (expected) upper limit at 95% confidence level on the Higgs boson\ntotal width of 13.1 (17.3) MeV.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-10T13:01:31Z"}
{"aid":"http://arxiv.org/abs/2504.07711v1","title":"Merging Embedded Topics with Optimal Transport for Online Topic Modeling\n  on Data Streams","summary":"Topic modeling is a key component in unsupervised learning, employed to\nidentify topics within a corpus of textual data. The rapid growth of social\nmedia generates an ever-growing volume of textual data daily, making online\ntopic modeling methods essential for managing these data streams that\ncontinuously arrive over time. This paper introduces a novel approach to online\ntopic modeling named StreamETM. This approach builds on the Embedded Topic\nModel (ETM) to handle data streams by merging models learned on consecutive\npartial document batches using unbalanced optimal transport. Additionally, an\nonline change point detection algorithm is employed to identify shifts in\ntopics over time, enabling the identification of significant changes in the\ndynamics of text streams. Numerical experiments on simulated and real-world\ndata show StreamETM outperforming competitors.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-10T13:04:56Z"}
{"aid":"http://arxiv.org/abs/2504.07717v1","title":"PR-Attack: Coordinated Prompt-RAG Attacks on Retrieval-Augmented\n  Generation in Large Language Models via Bilevel Optimization","summary":"Large Language Models (LLMs) have demonstrated remarkable performance across\na wide range of applications, e.g., medical question-answering, mathematical\nsciences, and code generation. However, they also exhibit inherent limitations,\nsuch as outdated knowledge and susceptibility to hallucinations.\nRetrieval-Augmented Generation (RAG) has emerged as a promising paradigm to\naddress these issues, but it also introduces new vulnerabilities. Recent\nefforts have focused on the security of RAG-based LLMs, yet existing attack\nmethods face three critical challenges: (1) their effectiveness declines\nsharply when only a limited number of poisoned texts can be injected into the\nknowledge database, (2) they lack sufficient stealth, as the attacks are often\ndetectable by anomaly detection systems, which compromises their effectiveness,\nand (3) they rely on heuristic approaches to generate poisoned texts, lacking\nformal optimization frameworks and theoretic guarantees, which limits their\neffectiveness and applicability. To address these issues, we propose\ncoordinated Prompt-RAG attack (PR-attack), a novel optimization-driven attack\nthat introduces a small number of poisoned texts into the knowledge database\nwhile embedding a backdoor trigger within the prompt. When activated, the\ntrigger causes the LLM to generate pre-designed responses to targeted queries,\nwhile maintaining normal behavior in other contexts. This ensures both high\neffectiveness and stealth. We formulate the attack generation process as a\nbilevel optimization problem leveraging a principled optimization framework to\ndevelop optimal poisoned texts and triggers. Extensive experiments across\ndiverse LLMs and datasets demonstrate the effectiveness of PR-Attack, achieving\na high attack success rate even with a limited number of poisoned texts and\nsignificantly improved stealth compared to existing methods.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-10T13:09:50Z"}
{"aid":"http://arxiv.org/abs/2504.07718v1","title":"Multi-modal Reference Learning for Fine-grained Text-to-Image Retrieval","summary":"Fine-grained text-to-image retrieval aims to retrieve a fine-grained target\nimage with a given text query. Existing methods typically assume that each\ntraining image is accurately depicted by its textual descriptions. However,\ntextual descriptions can be ambiguous and fail to depict discriminative visual\ndetails in images, leading to inaccurate representation learning. To alleviate\nthe effects of text ambiguity, we propose a Multi-Modal Reference learning\nframework to learn robust representations. We first propose a multi-modal\nreference construction module to aggregate all visual and textual details of\nthe same object into a comprehensive multi-modal reference. The multi-modal\nreference hence facilitates the subsequent representation learning and\nretrieval similarity computation. Specifically, a reference-guided\nrepresentation learning module is proposed to use multi-modal references to\nlearn more accurate visual and textual representations. Additionally, we\nintroduce a reference-based refinement method that employs the object\nreferences to compute a reference-based similarity that refines the initial\nretrieval results. Extensive experiments are conducted on five fine-grained\ntext-to-image retrieval datasets for different text-to-image retrieval tasks.\nThe proposed method has achieved superior performance over state-of-the-art\nmethods. For instance, on the text-to-person image retrieval dataset RSTPReid,\nour method achieves the Rank1 accuracy of 56.2\\%, surpassing the recent CFine\nby 5.6\\%.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T13:09:52Z"}
{"aid":"http://arxiv.org/abs/2504.07728v1","title":"The Scaling Behaviors in Achieving High Reliability via\n  Chance-Constrained Optimization","summary":"We study the problem of resource provisioning under stringent reliability or\nservice level requirements, which arise in applications such as power\ndistribution, emergency response, cloud server provisioning, and regulatory\nrisk management. With chance-constrained optimization serving as a natural\nstarting point for modeling this class of problems, our primary contribution is\nto characterize how the optimal costs and decisions scale for a generic joint\nchance-constrained model as the target probability of satisfying the\nservice/reliability constraints approaches its maximal level. Beyond providing\ninsights into the behavior of optimal solutions, our scaling framework has\nthree key algorithmic implications. First, in distributionally robust\noptimization (DRO) modeling of chance constraints, we show that widely used\napproaches based on KL-divergences, Wasserstein distances, and moments heavily\ndistort the scaling properties of optimal decisions, leading to exponentially\nhigher costs. In contrast, incorporating marginal distributions or using\nappropriately chosen f-divergence balls preserves the correct scaling, ensuring\ndecisions remain conservative by at most a constant or logarithmic factor.\nSecond, we leverage the scaling framework to quantify the conservativeness of\ncommon inner approximations and propose a simple line search to refine their\nsolutions, yielding near-optimal decisions. Finally, given N data samples, we\ndemonstrate how the scaling framework enables the estimation of approximately\nPareto-optimal decisions with constraint violation probabilities significantly\nsmaller than the Omega(1/N)-barrier that arises in the absence of parametric\nassumptions","main_category":"math.OC","categories":"math.OC,math.PR,q-fin.RM","published":"2025-04-10T13:21:49Z"}
{"aid":"http://arxiv.org/abs/2504.07768v1","title":"Weighted special cycles on Rapoport--Zink spaces with almost self-dual\n  level","summary":"We introduce a ``vector valued'' version of special cycles on GSpin\nRapoport--Zink spaces with almost self-dual level in the context of the Kudla\nprogram, with certain linear invariance and local modularity features. They are\nlocal analogs of special cycles on GSpin Shimura varieties with almost\nself-dual parahoric level (e.g. Siegel threefolds with paramodular level). We\nestablish local arithmetic Siegel--Weil formulas relating arithmetic\nintersection numbers of these special cycles and derivatives of certain local\nWhittaker functions in any dimension. The proof is based on a reduction formula\nfor cyclic quadratic lattices.","main_category":"math.NT","categories":"math.NT","published":"2025-04-10T14:06:52Z"}
{"aid":"http://arxiv.org/abs/2504.07784v1","title":"The row left rank of quaternion unit gain graphs in terms of pendant\n  vertices","summary":"Let $\\widetilde{G}=(G,U(\\mathbb{Q}),\\varphi)$ be a quaternion unit gain graph\n(or $U(\\mathbb{Q})$-gain graph), where $G$ is the underlying graph of\n$\\widetilde{G}$, $U(\\mathbb{Q})=\\{q\\in \\mathbb{Q}: |q|=1\\}$ and\n$\\varphi:\\overrightarrow{E}\\rightarrow U(\\mathbb{Q})$ is the gain function such\nthat $\\varphi(e_{ij})=\\varphi(e_{ji})^{-1}=\\overline{\\varphi(e_{ji})}$ for any\nadjacent vertices $v_{i}$ and $v_{j}$. Let $A(\\widetilde{G})$ be the adjacency\nmatrix of $\\widetilde{G}$ and let $r(\\widetilde{G})$ be the row left rank of\n$\\widetilde{G}$. In this paper, we prove some lower bounds on the row left rank\nof $U(\\mathbb{Q})$-gain graphs in terms of pendant vertices. All corresponding\nextremal graphs are characterized.","main_category":"math.CO","categories":"math.CO","published":"2025-04-10T14:22:13Z"}
{"aid":"http://arxiv.org/abs/2504.07800v1","title":"A Systematic Approach to Hyperbolic Quantum Error Correction Codes","summary":"Hyperbolic quantum error correction codes (HQECCs) leverage the unique\ngeometric properties of hyperbolic space to enhance the capabilities and\nperformance of quantum error correction. By embedding qubits in hyperbolic\nlattices, HQECCs achieve higher encoding rates and improved error thresholds\ncompared to conventional Euclidean codes. Building on recent advances in\nhyperbolic crystallography, we present a systematic framework for constructing\nHQECCs. As a key component of this framework, we develop a novel algorithm for\ncomputing all plaquette cycles and logical operators associated with a given\nHQECC. To demonstrate the effectiveness of this approach, we utilize this\nframework to simulate two HQECCs based respectively on two relevant examples of\nhyperbolic tilings. In the process, we evaluate key code parameters such as\nencoding rate, error threshold, and code distance for different sub-lattices.\nThis work establishes a solid foundation for a systematic and comprehensive\nanalysis of HQECCs, paving the way for the practical implementation of HQECCs\nin the pursuit of robust quantum error correction strategies.","main_category":"quant-ph","categories":"quant-ph,cs.DS,math.AG,math.DG,math.GR","published":"2025-04-10T14:38:10Z"}
{"aid":"http://arxiv.org/abs/2504.07803v1","title":"A System for Comprehensive Assessment of RAG Frameworks","summary":"Retrieval Augmented Generation (RAG) has emerged as a standard paradigm for\nenhancing the factual accuracy and contextual relevance of Large Language\nModels (LLMs) by integrating retrieval mechanisms. However, existing evaluation\nframeworks fail to provide a holistic black-box approach to assessing RAG\nsystems, especially in real-world deployment scenarios. To address this gap, we\nintroduce SCARF (System for Comprehensive Assessment of RAG Frameworks), a\nmodular and flexible evaluation framework designed to benchmark deployed RAG\napplications systematically. SCARF provides an end-to-end, black-box evaluation\nmethodology, enabling a limited-effort comparison across diverse RAG\nframeworks. Our framework supports multiple deployment configurations and\nfacilitates automated testing across vector databases and LLM serving\nstrategies, producing a detailed performance report. Moreover, SCARF integrates\npractical considerations such as response coherence, providing a scalable and\nadaptable solution for researchers and industry professionals evaluating RAG\napplications. Using the REST APIs interface, we demonstrate how SCARF can be\napplied to real-world scenarios, showcasing its flexibility in assessing\ndifferent RAG frameworks and configurations. SCARF is available at GitHub\nrepository.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-10T14:41:34Z"}
{"aid":"http://arxiv.org/abs/2504.07809v1","title":"A Riemannian Gradient Descent Method for the Least Squares Inverse\n  Eigenvalue Problem","summary":"We address an algorithm for the least squares fitting of a subset of the\neigenvalues of an unknown Hermitian matrix lying an an affine subspace, called\nthe Lift and Projection (LP) method, due to Chen and Chu (SIAM Journal on\nNumerical Analysis, 33 (1996), pp.2417-2430). The LP method iteratively `lifts'\nthe current iterate onto the spectral constraint manifold then 'projects' onto\nthe solution's affine subspace. We prove that this is equivalent to a\nRiemannian Gradient Descent with respect to a natural Riemannian metric. This\ninsight allows us to derive a more efficient implementation, analyse more\nprecisely its global convergence properties, and naturally append additional\nconstraints to the problem. We provide several numerical experiments to\ndemonstrate the improvement in computation time, which can be more than an\norder of magnitude if the eigenvalue constraints are on the smallest\neigenvalues, the largest eigenvalues, or the eigenvalues closest to a given\nnumber. These experiments include an inverse eigenvalue problem arising in\nInelastic Neutron Scattering of Manganese-6, which requires the least squares\nfitting of 16 experimentally observed eigenvalues of a $32400\\times32400$\nsparse matrix from a 5-dimensional subspace of spin Hamiltonian matrices.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-10T14:47:16Z"}
{"aid":"http://arxiv.org/abs/2504.07816v1","title":"The effect of background matter on the spin oscillations of neutrinos\n  scattered by the supermassive black hole","summary":"We study spin oscillations of neutrinos in relativistic moving matter inside\nan accretion disk. These neutrinos are gravitationally scattered off a spinning\nKerr black hole surrounded by a thick accretion disk. The disk can co-rotate\nand counter-rotate with respect to BH spin. We perform numerical simulations of\nthe propagation of a large number of incoming test neutrinos. We briefly\ndiscuss our results.","main_category":"hep-ph","categories":"hep-ph,astro-ph.HE,gr-qc","published":"2025-04-10T14:52:51Z"}
{"aid":"http://arxiv.org/abs/2504.07819v1","title":"Testing Leptogenesis from Observable Gravitational Waves","summary":"Leptogenesis provides an elegant mechanism to explain the observed baryon\nasymmetry of the Universe (BAU), yet its experimental verification remains\nchallenging due to requirements of either extremely heavy right-handed\nneutrinos or precisely fine-tuned mass splittings. We adapt a solution by\nintroducing an extra scalar field that significantly enhances $CP$ asymmetry\nthrough loop-level contributions. This scalar extension not only facilitates\nsuccessful leptogenesis but also enables a strong first-order electroweak phase\ntransition, generating potentially observable gravitational waves (GWs). We\ndemonstrate a strong correlation between the generated BAU and the GW signal\nstrength, establishing a unique way to test the leptogenesis. We show that when\nthe model achieves a successful BAU, the resulting GW signal from EWPT can have\nsignal-to-noise ratio of $\\mathcal{O}(10^3)$ and $\\mathcal{O}(10^6)$ at the\nupcoming LISA and DECIGO experiments, respectively. This work presents a\nconcrete connection between successful leptogenesis and detectable GWs,\noffering a promising method for experimental testing of the leptogenesis\nmechanism through future GW observations.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-10T14:57:22Z"}
{"aid":"http://arxiv.org/abs/2504.07820v1","title":"Smoothed Distance Kernels for MMDs and Applications in Wasserstein\n  Gradient Flows","summary":"Negative distance kernels $K(x,y) := - \\|x-y\\|$ were used in the definition\nof maximum mean discrepancies (MMDs) in statistics and lead to favorable\nnumerical results in various applications. In particular, so-called slicing\ntechniques for handling high-dimensional kernel summations profit from the\nsimple parameter-free structure of the distance kernel. However, due to its\nnon-smoothness in $x=y$, most of the classical theoretical results, e.g. on\nWasserstein gradient flows of the corresponding MMD functional do not longer\nhold true. In this paper, we propose a new kernel which keeps the favorable\nproperties of the negative distance kernel as being conditionally positive\ndefinite of order one with a nearly linear increase towards infinity and a\nsimple slicing structure, but is Lipschitz differentiable now. Our construction\nis based on a simple 1D smoothing procedure of the absolute value function\nfollowed by a Riemann-Liouville fractional integral transform. Numerical\nresults demonstrate that the new kernel performs similarly well as the negative\ndistance kernel in gradient descent methods, but now with theoretical\nguarantees.","main_category":"stat.ML","categories":"stat.ML,cs.LG,math.FA,math.PR","published":"2025-04-10T14:57:33Z"}
{"aid":"http://arxiv.org/abs/2504.07824v1","title":"Go Figure: Transparency in neuroscience images preserves context and\n  clarifies interpretation","summary":"Visualizations are vital for communicating scientific results. Historically,\nneuroimaging figures have only depicted regions that surpass a given\nstatistical threshold. This practice substantially biases interpretation of the\nresults and subsequent meta-analyses, particularly towards non-reproducibility.\nHere we advocate for a \"transparent thresholding\" approach that not only\nhighlights statistically significant regions but also includes subthreshold\nlocations, which provide key experimental context. This balances the dual needs\nof distilling modeling results and enabling informed interpretations for modern\nneuroimaging. We present four examples that demonstrate the many benefits of\ntransparent thresholding, including: removing ambiguity, decreasing\nhypersensitivity to non-physiological features, catching potential artifacts,\nimproving cross-study comparisons, reducing non-reproducibility biases, and\nclarifying interpretations. We also demonstrate the many software packages that\nimplement transparent thresholding, several of which were added or streamlined\nrecently as part of this work. A point-counterpoint discussion addresses issues\nwith thresholding raised in real conversations with researchers in the field.\nWe hope that by showing how transparent thresholding can drastically improve\nthe interpretation (and reproducibility) of neuroimaging findings, more\nresearchers will adopt this method.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-04-10T15:01:41Z"}
{"aid":"http://arxiv.org/abs/2504.07825v1","title":"What the HellaSwag? On the Validity of Common-Sense Reasoning Benchmarks","summary":"Common-sense reasoning is a key language model capability because it\nencapsulates not just specific factual knowledge but rather general language\nand world understanding. Measuring common-sense reasoning, therefore, is\ncrucial for language models of different sizes and applications. One of the\nmost widely used benchmarks for evaluating such capabilities is HellaSwag;\nhowever, in this paper, we show that it has severe construct validity issues.\nThese issues range from basic ungrammaticality and numerous typos to misleading\nprompts or equally correct options. Furthermore, we show that if models are\nevaluated only on answer texts, or with \"Lorem ipsum dolor...\" instead of the\nquestion, more than 65% of model predictions remain the same, and this cannot\nbe attributed merely to contamination. Since benchmark scores are an essential\npart of model selection in both research and commercial applications, these\nvalidity issues can have severe consequences. In particular, knowing that\ntaking benchmark scores at face value is ubiquitous, inadequate evaluation\nleads to ill-informed decisions about models. In this paper, we thoroughly\ninvestigate critical validity issues posed by HellaSwag and illustrate them\nwith various evaluations using generative language models of different sizes.\nWe argue that this benchmark does not accurately measure common-sense reasoning\nand, therefore, should not be used for evaluation in its current state. Based\non the results of our study, we propose requirements that should be met by\nfuture common-sense reasoning benchmarks. In addition, we release GoldenSwag, a\ncorrected subset of HellaSwag, which, to our belief, facilitates acceptable\ncommon-sense reasoning evaluation.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T15:01:46Z"}
{"aid":"http://arxiv.org/abs/2504.07826v1","title":"MuSaRoNews: A Multidomain, Multimodal Satire Dataset from Romanian News\n  Articles","summary":"Satire and fake news can both contribute to the spread of false information,\neven though both have different purposes (one if for amusement, the other is to\nmisinform). However, it is not enough to rely purely on text to detect the\nincongruity between the surface meaning and the actual meaning of the news\narticles, and, often, other sources of information (e.g., visual) provide an\nimportant clue for satire detection. This work introduces a multimodal corpus\nfor satire detection in Romanian news articles named MuSaRoNews. Specifically,\nwe gathered 117,834 public news articles from real and satirical news sources,\ncomposing the first multimodal corpus for satire detection in the Romanian\nlanguage. We conducted experiments and showed that the use of both modalities\nimproves performance.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T15:02:59Z"}
{"aid":"http://arxiv.org/abs/2504.07827v1","title":"HarmonySeg: Tubular Structure Segmentation with Deep-Shallow Feature\n  Fusion and Growth-Suppression Balanced Loss","summary":"Accurate segmentation of tubular structures in medical images, such as\nvessels and airway trees, is crucial for computer-aided diagnosis,\nradiotherapy, and surgical planning. However, significant challenges exist in\nalgorithm design when faced with diverse sizes, complex topologies, and (often)\nincomplete data annotation of these structures. We address these difficulties\nby proposing a new tubular structure segmentation framework named HarmonySeg.\nFirst, we design a deep-to-shallow decoder network featuring flexible\nconvolution blocks with varying receptive fields, which enables the model to\neffectively adapt to tubular structures of different scales. Second, to\nhighlight potential anatomical regions and improve the recall of small tubular\nstructures, we incorporate vesselness maps as auxiliary information. These maps\nare aligned with image features through a shallow-and-deep fusion module, which\nsimultaneously eliminates unreasonable candidates to maintain high precision.\nFinally, we introduce a topology-preserving loss function that leverages\ncontextual and shape priors to balance the growth and suppression of tubular\nstructures, which also allows the model to handle low-quality and incomplete\nannotations. Extensive quantitative experiments are conducted on four public\ndatasets. The results show that our model can accurately segment 2D and 3D\ntubular structures and outperform existing state-of-the-art methods. External\nvalidation on a private dataset also demonstrates good generalizability.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-10T15:04:42Z"}
{"aid":"http://arxiv.org/abs/2504.07847v1","title":"An update-resilient Kalman filtering approach","summary":"We propose a new robust filtering paradigm considering the situation in which\nmodel uncertainty, described through an ambiguity set, is present only in the\nobservations. We derive the corresponding robust estimator, referred to as\nupdate-resilient Kalman filter, which appears to be novel compared to existing\nminimax game-based filtering approaches. Moreover, we characterize the\ncorresponding least favorable state space model and analyze the filter\nstability. Finally, some numerical examples show the effectiveness of the\nproposed estimator.","main_category":"math.OC","categories":"math.OC","published":"2025-04-10T15:26:48Z"}
{"aid":"http://arxiv.org/abs/2504.07848v1","title":"Opinion dynamics and the unpredictability of opinion trajectories in an\n  adaptive social network model","summary":"Understanding opinion dynamics in social networks is critical for predicting\nsocial behavior and detecting polarization. Traditional approaches often rely\non static snapshots of network states, which can obscure the underlying\ndynamics of opinion evolution. In this study, we introduce a dynamic framework\nthat quantifies the unpredictability of opinion trajectories using the\nnormalized Lempel-Ziv (nLZ) complexity. Our approach leverages an adaptive\nsocial network model where each node is characterized by three behavioral\nparameters - homophily, neophily, and social conformity - and where opinions\nevolve continuously according to a system of ordinary differential equations.\nThe results reveal distinct nLZ complexity signatures for each node type:\nhomophilic nodes exhibit consistently rising complexity, reflecting\nincreasingly unpredictable opinion shifts that are counterintuitive given their\ntendency for similarity; neophilic nodes maintain low and stable complexity,\nsuggesting that openness to novelty can, surprisingly, lead to stable opinion\ndynamics; and conformic nodes display a U-shaped complexity trend,\ntransitioning from early opinion stagnation to later unpredictability. In fully\nheterogeneous networks, modest interaction effects emerge, with slight shifts\nin the unpredictability of each faction's trajectories. These findings\nunderscore the importance of temporal analysis in uncovering hidden dynamical\npatterns, offering novel insights into the mechanisms underlying social\nadaptation and polarization.","main_category":"cs.SI","categories":"cs.SI,physics.soc-ph","published":"2025-04-10T15:27:06Z"}
{"aid":"http://arxiv.org/abs/2504.07849v1","title":"In itinere infections covertly undermine localized epidemic control in\n  metapopulations","summary":"Metapopulation models have traditionally assessed epidemic dynamics by\nemphasizing local in situ interactions within defined subpopulations, often\nneglecting transmission occurring during mobility phases in itinere. Here, we\nextend the Movement-Interaction-Return (MIR) metapopulation framework to\nexplicitly include contagions acquired during transit, considering agents\ntraveling along shared transportation networks. We reveal that incorporating in\nitinere contagion entails a notable reduction of the epidemic threshold and a\npronounced delocalization of the epidemic trajectory, particularly significant\nin early-stage outbreaks.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-10T15:27:32Z"}
{"aid":"http://arxiv.org/abs/2504.07852v1","title":"The signless Laplacian spectral TurÃ¡n problems for color-critical\n  graphs","summary":"The well-known Tur\\'{a}n theorem states that if $G$ is an $n$-vertex\n$K_{r+1}$-free graph, then $e(G)\\le e(T_{n,r})$, with equality if and only if\n$G$ is the $r$-partite Tur\\'{a}n graph $T_{n,r}$. A graph $F$ is called\ncolor-critical if it contains an edge whose deletion reduces its chromatic\nnumber. Extending the Tur\\'{a}n theorem, Simonovits (1968) proved that for any\ncolor-critical graph $F$ with $\\chi (F)=r+1$ and sufficiently large $n$, the\nTur\\'{a}n graph $T_{n,r}$ is the unique graph with maximum number of edges\namong all $n$-vertex $F$-free graphs. Subsequently, Nikiforov [Electron. J.\nCombin., 16 (1) (2009)] proved a spectral version of the Simonovits theorem in\nterms of the adjacency spectral radius. In this paper, we show an extension of\nthe Simonovits theorem for the signless Laplacian spectral radius. We prove\nthat for any color-critical graph $F$ with $\\chi (F)=r+1\\ge 4$ and sufficiently\nlarge $n$, if $G$ is an $F$-free graph on $n$ vertices, then $q(G)\\le\nq(T_{n,r})$, with equality if and only if $G=T_{n,r}$. Our approach is to\nestablish a signless Laplacian spectral version of the criterion of Keevash,\nLenz and Mubayi [SIAM J. Discrete Math., 28 (4) (2014)]. Consequently, we can\ndetermine the signless Laplacian spectral extremal graphs for generalized books\nand even wheels. As an application, our result gives an upper bound on the\ndegree power of an $F$-free graph. We show that if $n$ is sufficiently large\nand $G$ is an $F$-free graph on $n$ vertices with $m$ edges, then $\\sum_{v\\in\nV(G)} d^2(v) \\le 2(1- \\frac{1}{r})mn$, with equality if and only if $G$ is a\nregular Tur\\'{a}n graph $T_{n,r}$. This extends a result of Nikiforov and\nRousseau [J. Combin. Theory Ser B 92 (2004)].","main_category":"math.CO","categories":"math.CO","published":"2025-04-10T15:28:40Z"}
{"aid":"http://arxiv.org/abs/2504.07879v1","title":"Towards Sustainable Creativity Support: An Exploratory Study on Prompt\n  Based Image Generation","summary":"Creativity is a valuable human skill that has long been augmented through\nboth analog and digital tools. Recent progress in generative AI, such as image\ngeneration, provides a disruptive technological solution to supporting human\ncreativity further and helping humans generate solutions faster. While AI image\ngenerators can help to rapidly visualize ideas based on user prompts, the use\nof such AI systems has also been critiqued due to their considerable energy\nusage. In this paper, we report on a user study (N = 24) to understand whether\nenergy consumption can be reduced without impeding on the tool's perceived\ncreativity support. Our results highlight that, for example, a main effect of\n(image generation) condition on energy consumption, and index of creativity\nsupport per prompt but not per task, which seem mainly attributed to image\nquantity per prompt. We provide details of our analysis on the relation between\nenergy usage, creativity support, and prompting behavior, including attitudes\ntowards designing with AI and its environmental impact.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-10T15:55:14Z"}
{"aid":"http://arxiv.org/abs/2504.07880v1","title":"Sculpting the outer edge of accretion disks in pre-circumbinary binary\n  black hole systems","summary":"Binary black hole systems (BBHs) have become a vivid reality in astrophysics\nas stellar-mass black hole mergers are now detected through their related\ngravitational wave emission during the merger stage. If many studies were\nrecently dedicated to the last stages of BBH where black holes are surrounded\nby a circumbinary disk (CBD), the structure of these systems prior to the\nformation of the CBD remains mostly unexplored. The aim of the present article\nis to investigate the potential modifications induced by the presence of a\nsecondary black hole onto the structure of the accretion disk surrounding the\nprimary black hole. We performed 2D classical hydrodynamical simulations of an\naccretion disk surrounding the primary black hole while taking into account all\ngravitational effects induced by both the primary black hole and the secondary\nblack hole orbiting on circular orbits around the center of mass of the\nsystem.We report three main effects of the presence of a secondary black hole\norbiting a circular orbit beyond the outer edge of the accretion disk: 1/ the\nouter radius of the accretion disk is significantly reduced and its ratio to\nthe black hole separation is directly linked to only the mass ratio of the\nblack holes; 2/ two spiral arms are visible in the gas density structure of the\ndisk and 3/ the outer edge of the accretion disk exhibits an elliptical shape\nthat mainly depends on the mass ratio of the black holes. Our results show that\nan accretion disk orbiting a primary black hole in a pre-CBD BBH exhibits\nspecific features induced by the gravitational force generated by the presence\nof a secondary black hole beyond its outer edge. Such features, directly linked\nto the binary separation and mass ratio, has therefore the potential to help in\nthe search and identification of BBH in the pre-CBD stage.","main_category":"astro-ph.HE","categories":"astro-ph.HE,gr-qc","published":"2025-04-10T15:55:18Z"}
{"aid":"http://arxiv.org/abs/2504.07884v1","title":"CatCMA with Margin: Stochastic Optimization for Continuous, Integer, and\n  Categorical Variables","summary":"This study focuses on mixed-variable black-box optimization (MV-BBO),\naddressing continuous, integer, and categorical variables. Many real-world\nMV-BBO problems involve dependencies among these different types of variables,\nrequiring efficient methods to optimize them simultaneously. Recently,\nstochastic optimization methods leveraging the mechanism of the covariance\nmatrix adaptation evolution strategy have shown promising results in\nmixed-integer or mixed-category optimization. However, such methods cannot\nhandle the three types of variables simultaneously. In this study, we propose\nCatCMA with Margin (CatCMAwM), a stochastic optimization method for MV-BBO that\njointly optimizes continuous, integer, and categorical variables. CatCMAwM is\ndeveloped by incorporating a novel integer handling into CatCMA, a\nmixed-category black-box optimization method employing a joint distribution of\nmultivariate Gaussian and categorical distributions. The proposed integer\nhandling is carefully designed by reviewing existing integer handlings and\nfollowing the design principles of CatCMA. Even when applied to mixed-integer\nproblems, it stabilizes the marginal probability and improves the convergence\nperformance of continuous variables. Numerical experiments show that CatCMAwM\neffectively handles the three types of variables, outperforming\nstate-of-the-art Bayesian optimization methods and baselines that simply\nincorporate existing integer handlings into CatCMA.","main_category":"cs.NE","categories":"cs.NE","published":"2025-04-10T15:59:22Z"}
{"aid":"http://arxiv.org/abs/2504.07887v1","title":"Benchmarking Adversarial Robustness to Bias Elicitation in Large\n  Language Models: Scalable Automated Assessment with LLM-as-a-Judge","summary":"Large Language Models (LLMs) have revolutionized artificial intelligence,\ndriving advancements in machine translation, summarization, and conversational\nagents. However, their increasing integration into critical societal domains\nhas raised concerns about embedded biases, which can perpetuate stereotypes and\ncompromise fairness. These biases stem from various sources, including\nhistorical inequalities in training data, linguistic imbalances, and\nadversarial manipulation. Despite mitigation efforts, recent studies indicate\nthat LLMs remain vulnerable to adversarial attacks designed to elicit biased\nresponses. This work proposes a scalable benchmarking framework to evaluate LLM\nrobustness against adversarial bias elicitation. Our methodology involves (i)\nsystematically probing models with a multi-task approach targeting biases\nacross various sociocultural dimensions, (ii) quantifying robustness through\nsafety scores using an LLM-as-a-Judge approach for automated assessment of\nmodel responses, and (iii) employing jailbreak techniques to investigate\nvulnerabilities in safety mechanisms. Our analysis examines prevalent biases in\nboth small and large state-of-the-art models and their impact on model safety.\nAdditionally, we assess the safety of domain-specific models fine-tuned for\ncritical fields, such as medicine. Finally, we release a curated dataset of\nbias-related prompts, CLEAR-Bias, to facilitate systematic vulnerability\nbenchmarking. Our findings reveal critical trade-offs between model size and\nsafety, aiding the development of fairer and more robust future language\nmodels.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-10T16:00:59Z"}
{"aid":"http://arxiv.org/abs/2504.07890v1","title":"Stupendously Large Primordial Black Holes from the QCD axion","summary":"The inflationary diffusion of (pseudo-)scalar fields with discrete symmetries\ncan seed the formation of a gas of closed domain walls after inflation, when\nthe distance between degenerate minima in field space is not too far from the\ninflationary Hubble scale. Primordial black holes (PBHs) can then be formed\nonce sufficiently heavy domain walls re-enter the Hubble sphere. In this\nscenario, inflation determines a distinctive PBH mass distribution that is\nrather flat and can thus lead to a sizable total abundance of PBHs, while\navoiding some of the downsides of PBH formation from critical collapse. We show\nthat generic QCD axion models, with decay constant close to the inflationary\nHubble scale, can yield up to $1\\%$ of the dark matter (DM) today in the form\nof PBHs, while being compatible with isocurvature constraints from Cosmic\nMicrowave Background observations. This occurs for values of axion decay\nconstants around $f_a\\simeq 10^{8}~\\text{GeV}$, that is the region targeted by\naxion helioscopes and partially constrained by astrophysical observations. The\nresulting PBHs have \\textit{stupendously} large masses, above $10^{11}M_\\odot$,\nand their existence can be probed by Large Scale Structure observations. Larger\nPBH abundances can be generated by axion-like particles. Alternatively, in\nscenarios where isocurvature constraints can be relaxed, we find that the\ntotality of the DM can be produced by the QCD axion misalignment mechanism,\naccompanied by a ${\\cal O}(10^{-3})$ DM fraction in PBHs of masses\n$(10^5-10^6)~M_\\odot$. These can act as seeds for the formation of massive\nblack holes at large redshifts, as suggested by recent JWST observations.","main_category":"astro-ph.CO","categories":"astro-ph.CO,hep-ph","published":"2025-04-10T16:03:25Z"}
{"aid":"http://arxiv.org/abs/2504.07902v1","title":"Biased domain walls: faster annihilation, weaker gravitational waves","summary":"We study the evolution of domain wall networks and their phenomenological\nimplications in a model of a real scalar $\\chi$, where a $Z_2$-symmetry is\nslightly broken by a potential bias $V_{bias}$. It is demonstrated that the\nlatter triggers domain wall annihilation considerably earlier than previously\nthought. Namely, we observe that the scaling relation $t_{ann} \\propto\n1/V^{2/3}_{bias}$ for the annihilation time $t_{ann}$ fits to the simulation\ndata better than a commonly assumed $t_{ann} \\propto 1/V_{bias}$. As a result,\nthe energy density of gravitational waves produced by the network of biased\ndomain walls, for a given tiny $V_{bias}$, is suppressed compared to naive\nexpectations. The spectral shape of gravitational waves is similar to that\nresulting from unbiased domain walls, but with more power in the\nclose-to-maximum ultraviolet part. In the far ultraviolet region, the spectrum\nof gravitational waves becomes nearly flat; such a plateau has been recognized\nearlier in the case of unbiased walls. In our investigation we mainly focus on\nthe symmetry breaking potential $V_{breaking} \\propto \\chi^3$, and argue that\nno significant modifications of the domain walls evolution take place if one\nincludes higher powers of $\\chi$.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO,hep-th","published":"2025-04-10T16:26:08Z"}
{"aid":"http://arxiv.org/abs/2504.07920v1","title":"Directed Temporal Tree Realization for Periodic Public Transport: Easy\n  and Hard Cases","summary":"We study the complexity of the directed periodic temporal graph realization\nproblem. This work is motivated by the design of periodic schedules in public\ntransport with constraints on the quality of service. Namely, we require that\nthe fastest path between (important) pairs of vertices is upper bounded by a\nspecified maximum duration, encoded in an upper distance matrix $D$. While\nprevious work has considered the undirected version of the problem, the\napplication in public transport schedule design requires the flexibility to\nassign different departure times to the two directions of an edge. A problem\ninstance can only be feasible if all values of the distance matrix are at least\nshortest path distances. However, the task of realizing exact fastest path\ndistances in a periodic temporal graph is often too restrictive. Therefore, we\nintroduce a minimum slack parameter $k$ that describes a lower bound on the\nmaximum allowed waiting time on each path. We concentrate on tree topologies\nand provide a full characterization of the complexity landscape with respect to\nthe period $\\Delta$ and the minimum slack parameter~$k$, showing a sharp\nthreshold between NP-complete cases and cases which are always realizable. We\nalso provide hardness results for the special case of period $\\Delta = 2$ for\ngeneral directed and undirected graphs.","main_category":"cs.DS","categories":"cs.DS,cs.CC,cs.DM","published":"2025-04-10T17:36:23Z"}
{"aid":"http://arxiv.org/abs/2504.07921v1","title":"Note on the identification of total effect in Cluster-DAGs with cycles","summary":"In this note, we discuss the identifiability of a total effect in\ncluster-DAGs, allowing for cycles within the cluster-DAG (while still assuming\nthe associated underlying DAG to be acyclic). This is presented into two key\nresults: first, restricting the cluster-DAG to clusters containing at most four\nnodes; second, adapting the notion of d-separation. We provide a graphical\ncriterion to address the identifiability problem.","main_category":"math.ST","categories":"math.ST,cs.AI,stat.TH","published":"2025-04-10T17:39:43Z"}
{"aid":"http://arxiv.org/abs/2504.07923v1","title":"Trading Graph Neural Network","summary":"This paper proposes a new algorithm -- Trading Graph Neural Network (TGNN)\nthat can structurally estimate the impact of asset features, dealer features\nand relationship features on asset prices in trading networks. It combines the\nstrength of the traditional simulated method of moments (SMM) and recent\nmachine learning techniques -- Graph Neural Network (GNN). It outperforms\nexisting reduced-form methods with network centrality measures in prediction\naccuracy. The method can be used on networks with any structure, allowing for\nheterogeneity among both traders and assets.","main_category":"q-fin.TR","categories":"q-fin.TR,cs.LG,econ.GN,q-fin.EC,q-fin.PR","published":"2025-04-10T17:40:31Z"}
{"aid":"http://arxiv.org/abs/2504.07930v1","title":"Localization and Topology in Noncentrosymmetric Superconductors with\n  Disorder","summary":"The celebrated Kitaev chain reveals a captivating phase diagram in the\npresence of various disorders, encompassing multifractal states and topological\nAnderson phases. In this work, we investigate the localization and topological\nproperties of a dimerized topological noncentrosymmetric superconductor (NCS)\nunder quasiperiodic and Anderson disorders. Using both global and local\ncharacterization methods, we identify energy-dependent transitions from ergodic\nto multifractal and localized states. Extended multifractal regimes emerge from\nthe competition between dimerization, NCS order, and quasiperiodic modulation.\nThis interplay causes localization to occur preferentially in different energy\nbands depending on the disorder strength, with the lowest bands exhibiting the\nhighest sensitivity to parameter variations. We employ the real-space\npolarization method to compute the $\\mathbb{Z}_2$ topological invariant,\nrevealing alternating topological and trivial phases as the quasiperiodic\npotential increases, a behavior distinct from the typical topological Anderson\nphase diagram. Additionally, the topological states show remarkable robustness\nagainst Anderson disorder, providing new insights into topological phase\nstability in non-centrosymmetric systems. Finally, we propose a feasible\nexperimental scheme based on superconducting Josephson junctions, where\nNCS-like behavior can be engineered via spatially modulated supercurrents. Our\nfindings highlight the distinct roles of different disorder types in shaping\nlocalization and topology, providing insight into the engineering of Majorana\nzero modes and offering profound implications for topological quantum\nencryption schemes.","main_category":"cond-mat.other","categories":"cond-mat.other","published":"2025-04-10T17:45:28Z"}
{"aid":"http://arxiv.org/abs/2504.07936v1","title":"We Are All Creators: Generative AI, Collective Knowledge, and the Path\n  Towards Human-AI Synergy","summary":"Generative AI presents a profound challenge to traditional notions of human\nuniqueness, particularly in creativity. Fueled by neural network based\nfoundation models, these systems demonstrate remarkable content generation\ncapabilities, sparking intense debates about authorship, copyright, and\nintelligence itself. This paper argues that generative AI represents an\nalternative form of intelligence and creativity, operating through mathematical\npattern synthesis rather than biological understanding or verbatim replication.\nThe fundamental differences between artificial and biological neural networks\nreveal AI learning as primarily statistical pattern extraction from vast\ndatasets crystallized forms of collective human knowledge scraped from the\ninternet. This perspective complicates copyright theft narratives and\nhighlights practical challenges in attributing AI outputs to individual\nsources. Rather than pursuing potentially futile legal restrictions, we\nadvocate for human AI synergy. By embracing generative AI as a complementary\ntool alongside human intuition, context, and ethical judgment, society can\nunlock unprecedented innovation, democratize creative expression, and address\ncomplex challenges. This collaborative approach, grounded in realistic\nunderstanding of AIs capabilities and limitations, offers the most promising\npath forward. Additionally, recognizing these models as products of collective\nhuman knowledge raises ethical questions about accessibility ensuring equitable\naccess to these tools could prevent widening societal divides and leverage\ntheir full potential for collective benefit.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-10T17:50:17Z"}
{"aid":"http://arxiv.org/abs/2504.07945v1","title":"GenEAva: Generating Cartoon Avatars with Fine-Grained Facial Expressions\n  from Realistic Diffusion-based Faces","summary":"Cartoon avatars have been widely used in various applications, including\nsocial media, online tutoring, and gaming. However, existing cartoon avatar\ndatasets and generation methods struggle to present highly expressive avatars\nwith fine-grained facial expressions and are often inspired from real-world\nidentities, raising privacy concerns. To address these challenges, we propose a\nnovel framework, GenEAva, for generating high-quality cartoon avatars with\nfine-grained facial expressions. Our approach fine-tunes a state-of-the-art\ntext-to-image diffusion model to synthesize highly detailed and expressive\nfacial expressions. We then incorporate a stylization model that transforms\nthese realistic faces into cartoon avatars while preserving both identity and\nexpression. Leveraging this framework, we introduce the first expressive\ncartoon avatar dataset, GenEAva 1.0, specifically designed to capture 135\nfine-grained facial expressions, featuring 13,230 expressive cartoon avatars\nwith a balanced distribution across genders, racial groups, and age ranges. We\ndemonstrate that our fine-tuned model generates more expressive faces than the\nstate-of-the-art text-to-image diffusion model SDXL. We also verify that the\ncartoon avatars generated by our framework do not include memorized identities\nfrom fine-tuning data. The proposed framework and dataset provide a diverse and\nexpressive benchmark for future research in cartoon avatar generation.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-10T17:54:02Z"}
{"aid":"http://arxiv.org/abs/2504.07948v1","title":"Pushing the Accuracy Limit of Foundation Neural Network Models with\n  Quantum Monte Carlo Forces and Path Integrals","summary":"We propose an end-to-end integrated strategy for the production of highly\naccurate quantum chemistry (QC) synthetic datasets aimed at deriving atomistic\nFoundation Machine Learning (ML) Models. We first present a GPU-accelerated QC\ndatabase generation Exascale protocol able to produce the required energies and\nforces. A \"Jacob's Ladder\" approach leverages computationally-optimized layers\nof massively parallel high performance software with increasing accuracy to\ncompute: i) Density Functional Theory (DFT); ii) Quantum Monte Carlo (QMC);\niii) Selected Configuration Interaction (s-CI), within large volumes and\noptimized time-to-solution performances. Handling this ambitious computational\npipeline would be impossible without exascale computing resources, particularly\nfor the notoriously difficult and computationally intensive calculation of QMC\nforces and for the combination of multi-determinant QMC energies and forces\nusing selected CI wavefunctions methodologies. To our knowledge, this is the\nfirst time that such quantities are computed at such scale. We combine these\ndata with the FeNNix-Bio-1 foundation ML model to bridge the gap between highly\naccurate QC calculations and condensed-phase Molecular Dynamics (MD). We\ndemonstrate stable multi-ns simulations using the resulting beyond DFT accuracy\nfully reactive model coupled to full path integrals adaptive sampling quantum\ndynamics. A complete 1 million-atom plant virus solvated structure, including\nits full genetic material, is simulated using Ring-Polymer MD quantum dynamics\nalong as its response to acidification under physiological NaCl concentrations.\nThese new capabilities open the door to the possibility to monitor bond\nbreaking/creation and proton transfers chemical interactions taking place in\nbiosystems allowing us to reach a deeper understanding of their complex\ninternal machinery.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-10T17:55:09Z"}
{"aid":"http://arxiv.org/abs/2504.07949v1","title":"InteractAvatar: Modeling Hand-Face Interaction in Photorealistic Avatars\n  with Deformable Gaussians","summary":"With the rising interest from the community in digital avatars coupled with\nthe importance of expressions and gestures in communication, modeling natural\navatar behavior remains an important challenge across many industries such as\nteleconferencing, gaming, and AR/VR. Human hands are the primary tool for\ninteracting with the environment and essential for realistic human behavior\nmodeling, yet existing 3D hand and head avatar models often overlook the\ncrucial aspect of hand-body interactions, such as between hand and face. We\npresent InteracttAvatar, the first model to faithfully capture the\nphotorealistic appearance of dynamic hand and non-rigid hand-face interactions.\nOur novel Dynamic Gaussian Hand model, combining template model and 3D Gaussian\nSplatting as well as a dynamic refinement module, captures pose-dependent\nchange, e.g. the fine wrinkles and complex shadows that occur during\narticulation. Importantly, our hand-face interaction module models the subtle\ngeometry and appearance dynamics that underlie common gestures. Through\nexperiments of novel view synthesis, self reenactment and cross-identity\nreenactment, we demonstrate that InteracttAvatar can reconstruct hand and\nhand-face interactions from monocular or multiview videos with high-fidelity\ndetails and be animated with novel poses.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:55:43Z"}
{"aid":"http://arxiv.org/abs/2504.07953v1","title":"Free monad sequences and extension operations","summary":"In the first part of this article, we give an analysis of the free monad\nsequence in non-cocomplete categories, with the needed colimits explicitly\nparametrized. This enables us to state a more finely grained functoriality\nprinciple for free monad and monoid sequences.\n  In the second part, we deal with the problem of functorially extending via\npullback squares a category of maps along the category of coalgebras of an\nalgebraic weak factorization system. This generalizes the classical problem of\nextending a class of maps along the left class of a weak factorization system\nin the sense of pullback squares where the vertical maps are in the chosen\nclass and the bottom map is in the left class. Such situations arise in the\ncontext of model structures where one might wish to extend fibrations along\ntrivial cofibrations. We derive suitable conditions for the algebraic analogue\nof weak saturation of the extension problem, using the results of the first\npart to reduce the technical burden.","main_category":"math.CT","categories":"math.CT","published":"2025-04-10T17:58:02Z"}
{"aid":"http://arxiv.org/abs/2504.07964v1","title":"C3PO: Critical-Layer, Core-Expert, Collaborative Pathway Optimization\n  for Test-Time Expert Re-Mixing","summary":"Mixture-of-Experts (MoE) Large Language Models (LLMs) suffer from severely\nsub-optimal expert pathways-our study reveals that naive expert selection\nlearned from pretraining leaves a surprising 10-20% accuracy gap for\nimprovement. Motivated by this observation, we develop a novel class of\ntest-time optimization methods to re-weight or \"re-mixing\" the experts in\ndifferent layers jointly for each test sample. Since the test sample's ground\ntruth is unknown, we propose to optimize a surrogate objective defined by the\nsample's \"successful neighbors\" from a reference set of samples. We introduce\nthree surrogates and algorithms based on mode-finding, kernel regression, and\nthe average loss of similar reference samples/tasks. To reduce the cost of\noptimizing whole pathways, we apply our algorithms merely to the core experts'\nmixing weights in critical layers, which enjoy similar performance but save\nsignificant computation. This leads to \"Critical-Layer, Core-Expert,\nCollaborative Pathway Optimization (C3PO)\". We apply C3PO to two recent MoE\nLLMs and examine it on six widely-used benchmarks. It consistently improves the\nbase model by 7-15% in accuracy and outperforms widely used test-time learning\nbaselines, e.g., in-context learning and prompt/prefix tuning, by a large\nmargin. Moreover, C3PO enables MoE LLMs with 1-3B active parameters to\noutperform LLMs of 7-9B parameters, hence improving MoE's advantages on\nefficiency. Our thorough ablation study further sheds novel insights on\nachieving test-time improvement on MoE.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-10T17:59:56Z"}
