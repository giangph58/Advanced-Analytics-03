{"aid":"http://arxiv.org/abs/2503.21658v1","title":"Numerical Analysis of the Stability of Iron Dust Bunsen Flames","summary":"This article presents numerical simulations of the response of an iron dust\nBunsen flame to particle seeding changes. A validated numerical model is used\nto study the impact of particle seeding fluctuations on flame stability.\nSimulations are conducted for the Bunsen setup in the right-side up and up-side\ndown configuration. No significant differences in flame response are identified\nin flame stability between the right-side up and up-side down configurations.\nWe find that the Bunsen flame is surprisingly robust to abrupt changes in\nparticle loading. The sudden change in particle loading does not excite any\nintrinsic instabilities in the flame. Based on our results, the iron dust\nflames are robust to imposed fluctuations. We hypothesize that this is due to\nthe lack of a feedback mechanism between the burned temperature and the heat\nrelease rate. This mechanism is present in conventional, chemistry-driven,\ngaseous flames. However, such a mechanism is absent in iron dust flames because\nthe combustion of individual iron particles is limited by oxygen diffusion,\nwhich is insensitive to temperature.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-03-27T16:22:50Z"}
{"aid":"http://arxiv.org/abs/2503.21669v1","title":"Proton-Driven Plasma Wakefield Acceleration for Future HEP Colliders","summary":"We discuss the main elements of a collider facility based on proton-driven\nplasma wakefield acceleration. We show that very competitive luminosities could\nbe reached for high energy $e^+e^-$ colliders. A first set of parameters was\ndeveloped for a Higgs Factory indicating that such a scheme is indeed\npotentially feasible. There are clearly many challenges to the development of\nthis scheme, including novel RF acceleration modules and high precision and\nstrong magnets for the proton driver. Challenges in the plasma acceleration\nstage include the ability to accelerate positrons while maintaining necessary\nemittance and the energy transfer efficiency from the driver to the witness.\nSince many exciting applications would become available from our approach, its\ndevelopment should be pursued.","main_category":"physics.acc-ph","categories":"physics.acc-ph,hep-ex,physics.plasm-ph","published":"2025-03-27T16:36:33Z"}
{"aid":"http://arxiv.org/abs/2503.21671v1","title":"A Bespoke Design Approach to Low-Power Printed Microprocessors for\n  Machine Learning Applications","summary":"Printed electronics have gained significant traction in recent years,\npresenting a viable path to integrating computing into everyday items, from\ndisposable products to low-cost healthcare. However, the adoption of computing\nin these domains is hindered by strict area and power constraints, limiting the\neffectiveness of general-purpose microprocessors. This paper proposes a bespoke\nmicroprocessor design approach to address these challenges, by tailoring the\ndesign to specific applications and eliminating unnecessary logic. Targeting\nmachine learning applications, we further optimize core operations by\nintegrating a SIMD MAC unit supporting 4 precision configurations that boost\nthe efficiency of microprocessors. Our evaluation across 6 ML models and the\nlarge-scale Zero-Riscy core, shows that our methodology can achieve\nimprovements of 22.2%, 23.6%, and 33.79% in area, power, and speed,\nrespectively, without compromising accuracy. Against state-of-the-art printed\nprocessors, our approach can still offer significant speedups, but along with\nsome accuracy degradation. This work explores how such trade-offs can enable\nlow-power printed microprocessors for diverse ML applications.","main_category":"cs.AR","categories":"cs.AR","published":"2025-03-27T16:37:18Z"}
{"aid":"http://arxiv.org/abs/2503.21677v1","title":"A tale of two goals: leveraging sequentiality in multi-goal scenarios","summary":"Several hierarchical reinforcement learning methods leverage planning to\ncreate a graph or sequences of intermediate goals, guiding a lower-level\ngoal-conditioned (GC) policy to reach some final goals. The low-level policy is\ntypically conditioned on the current goal, with the aim of reaching it as\nquickly as possible. However, this approach can fail when an intermediate goal\ncan be reached in multiple ways, some of which may make it impossible to\ncontinue toward subsequent goals. To address this issue, we introduce two\ninstances of Markov Decision Process (MDP) where the optimization objective\nfavors policies that not only reach the current goal but also subsequent ones.\nIn the first, the agent is conditioned on both the current and final goals,\nwhile in the second, it is conditioned on the next two goals in the sequence.\nWe conduct a series of experiments on navigation and pole-balancing tasks in\nwhich sequences of intermediate goals are given. By evaluating policies trained\nwith TD3+HER on both the standard GC-MDP and our proposed MDPs, we show that,\nin most cases, conditioning on the next two goals improves stability and sample\nefficiency over other approaches.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-27T16:47:46Z"}
{"aid":"http://arxiv.org/abs/2503.21718v1","title":"Outlier dimensions favor frequent tokens in language model","summary":"We study last-layer outlier dimensions, i.e.dimensions that display extreme\nactivations for the majority of inputs. We show that outlier dimensions arise\nin many different modern language models, and trace their function back to the\nheuristic of constantly predicting frequent words. We further show how a model\ncan block this heuristic when it is not contextually appropriate, by assigning\na counterbalancing weight mass to the remaining dimensions, and we investigate\nwhich model parameters boost outlier dimensions and when they arise during\ntraining. We conclude that outlier dimensions are a specialized mechanism\ndiscovered by many distinct models to implement a useful token prediction\nheuristic.","main_category":"cs.CL","categories":"cs.CL,cs.AI,I.2.7","published":"2025-03-27T17:30:50Z"}
{"aid":"http://arxiv.org/abs/2503.21737v1","title":"High-intensity Voronoi percolation on manifolds","summary":"We study Voronoi percolation on a large class of $d$-dimensional Riemannian\nmanifolds, which includes hyperbolic space $\\mathbb{H}^d$ for $d\\geq 2$. We\nprove that as the intensity $\\lambda$ of the underlying Poisson point process\ntends to infinity, both critical parameters $p_c(M,\\lambda)$ and\n$p_u(M,\\lambda)$ converge to the Euclidean critical parameter\n$p_c(\\mathbb{R}^d)$. This extends a recent result of Hansen & M\\\"uller in the\nspecial case $M=\\mathbb{H}^2$ to a general class of manifolds of arbitrary\ndimension. A crucial step in our proof, which may be of independent interest,\nis to show that if $M$ is simply connected and one-ended, then embedded graphs\ninduced by a general class of tessellations on $M$ have connected minimal\ncutsets. In particular, this result applies to $\\varepsilon$-nets, allowing us\nto implement a \"fine-graining\" argument. We also develop an annealed way of\nexploring the Voronoi cells that we use to characterize the uniqueness phase.","main_category":"math.PR","categories":"math.PR","published":"2025-03-27T17:49:50Z"}
{"aid":"http://arxiv.org/abs/2503.21760v1","title":"MemInsight: Autonomous Memory Augmentation for LLM Agents","summary":"Large language model (LLM) agents have evolved to intelligently process\ninformation, make decisions, and interact with users or tools. A key capability\nis the integration of long-term memory capabilities, enabling these agents to\ndraw upon historical interactions and knowledge. However, the growing memory\nsize and need for semantic structuring pose significant challenges. In this\nwork, we propose an autonomous memory augmentation approach, MemInsight, to\nenhance semantic data representation and retrieval mechanisms. By leveraging\nautonomous augmentation to historical interactions, LLM agents are shown to\ndeliver more accurate and contextualized responses. We empirically validate the\nefficacy of our proposed approach in three task scenarios; conversational\nrecommendation, question answering and event summarization. On the LLM-REDIAL\ndataset, MemInsight boosts persuasiveness of recommendations by up to 14%.\nMoreover, it outperforms a RAG baseline by 34% in recall for LoCoMo retrieval.\nOur empirical results show the potential of MemInsight to enhance the\ncontextual performance of LLM agents across multiple tasks.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-27T17:57:28Z"}
{"aid":"http://arxiv.org/abs/2503.21766v1","title":"Stable-SCore: A Stable Registration-based Framework for 3D Shape\n  Correspondence","summary":"Establishing character shape correspondence is a critical and fundamental\ntask in computer vision and graphics, with diverse applications including\nre-topology, attribute transfer, and shape interpolation. Current dominant\nfunctional map methods, while effective in controlled scenarios, struggle in\nreal situations with more complex challenges such as non-isometric shape\ndiscrepancies. In response, we revisit registration-for-correspondence methods\nand tap their potential for more stable shape correspondence estimation. To\novercome their common issues including unstable deformations and the necessity\nfor careful pre-alignment or high-quality initial 3D correspondences, we\nintroduce Stable-SCore: A Stable Registration-based Framework for 3D Shape\nCorrespondence. We first re-purpose a foundation model for 2D character\ncorrespondence that ensures reliable and stable 2D mappings. Crucially, we\npropose a novel Semantic Flow Guided Registration approach that leverages 2D\ncorrespondence to guide mesh deformations. Our framework significantly\nsurpasses existing methods in challenging scenarios, and brings possibilities\nfor a wide array of real applications, as demonstrated in our results.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-27T17:59:02Z"}
{"aid":"http://arxiv.org/abs/2503.23679v1","title":"The Devil is in the Distributions: Explicit Modeling of Scene Content is\n  Key in Zero-Shot Video Captioning","summary":"Zero-shot video captioning requires that a model generate high-quality\ncaptions without human-annotated video-text pairs for training.\nState-of-the-art approaches to the problem leverage CLIP to extract\nvisual-relevant textual prompts to guide language models in generating\ncaptions. These methods tend to focus on one key aspect of the scene and build\na caption that ignores the rest of the visual input. To address this issue, and\ngenerate more accurate and complete captions, we propose a novel progressive\nmulti-granularity textual prompting strategy for zero-shot video captioning.\nOur approach constructs three distinct memory banks, encompassing noun phrases,\nscene graphs of noun phrases, and entire sentences. Moreover, we introduce a\ncategory-aware retrieval mechanism that models the distribution of natural\nlanguage surrounding the specific topics in question. Extensive experiments\ndemonstrate the effectiveness of our method with 5.7%, 16.2%, and 3.4%\nimprovements in terms of the main metric CIDEr on MSR-VTT, MSVD, and VATEX\nbenchmarks compared to existing state-of-the-art.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T03:00:19Z"}
{"aid":"http://arxiv.org/abs/2503.23705v1","title":"Steering Large Agent Populations using Mean-Field Schrodinger Bridges\n  with Gaussian Mixture Models","summary":"The Mean-Field Schrodinger Bridge (MFSB) problem is an optimization problem\naiming to find the minimum effort control policy to drive a McKean-Vlassov\nstochastic differential equation from one probability measure to another. In\nthe context of multiagent control, the objective is to control the\nconfiguration of a swarm of identical, interacting cooperative agents, as\ncaptured by the time-varying probability measure of their state. Available\nmethods for solving this problem for distributions with continuous support rely\neither on spatial discretizations of the problem's domain or on approximating\noptimal solutions using neural networks trained through stochastic optimization\nschemes. For agents following Linear Time-Varying dynamics, and for Gaussian\nMixture Model boundary distributions, we propose a highly efficient\nparameterization to approximate the solutions of the corresponding MFSB in\nclosed form, without any learning steps. Our proposed approach consists of a\nmixture of elementary policies, each solving a Gaussian-to-Gaussian Covariance\nSteering problem from the components of the initial to the components of the\nterminal mixture. Leveraging the semidefinite formulation of the Covariance\nSteering problem, our proposed solver can handle probabilistic hard constraints\non the system's state, while maintaining numerical tractability. We illustrate\nour approach on a variety of numerical examples.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-03-31T04:01:04Z"}
{"aid":"http://arxiv.org/abs/2503.23725v1","title":"Exploring Temporal Dynamics in Event-based Eye Tracker","summary":"Eye-tracking is a vital technology for human-computer interaction, especially\nin wearable devices such as AR, VR, and XR. The realization of high-speed and\nhigh-precision eye-tracking using frame-based image sensors is constrained by\ntheir limited temporal resolution, which impairs the accurate capture of rapid\nocular dynamics, such as saccades and blinks. Event cameras, inspired by\nbiological vision systems, are capable of perceiving eye movements with\nextremely low power consumption and ultra-high temporal resolution. This makes\nthem a promising solution for achieving high-speed, high-precision tracking\nwith rich temporal dynamics. In this paper, we propose TDTracker, an effective\neye-tracking framework that captures rapid eye movements by thoroughly modeling\ntemporal dynamics from both implicit and explicit perspectives. TDTracker\nutilizes 3D convolutional neural networks to capture implicit short-term\ntemporal dynamics and employs a cascaded structure consisting of a\nFrequency-aware Module, GRU, and Mamba to extract explicit long-term temporal\ndynamics. Ultimately, a prediction heatmap is used for eye coordinate\nregression. Experimental results demonstrate that TDTracker achieves\nstate-of-the-art (SOTA) performance on the synthetic SEET dataset and secured\nThird place in the CVPR event-based eye-tracking challenge 2025. Our code is\navailable at https://github.com/rhwxmx/TDTracker.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T04:57:13Z"}
{"aid":"http://arxiv.org/abs/2503.23730v1","title":"KOFFVQA: An Objectively Evaluated Free-form VQA Benchmark for Large\n  Vision-Language Models in the Korean Language","summary":"The recent emergence of Large Vision-Language Models(VLMs) has resulted in a\nvariety of different benchmarks for evaluating such models. Despite this, we\nobserve that most existing evaluation methods suffer from the fact that they\neither require the model to choose from pre-determined responses, sacrificing\nopen-endedness, or evaluate responses using a judge model, resulting in\nsubjective and unreliable evaluation. In addition, we observe a lack of\nbenchmarks for VLMs in the Korean language, which are necessary as a separate\nmetric from more common English language benchmarks, as the performance of\ngenerative language models can differ significantly based on the language being\nused. Therefore, we present KOFFVQA, a general-purpose free-form visual\nquestion answering benchmark in the Korean language for the evaluation of VLMs.\nOur benchmark consists of 275 carefully crafted questions each paired with an\nimage and grading criteria covering 10 different aspects of VLM performance.\nThe grading criteria eliminate the problem of unreliability by allowing the\njudge model to grade each response based on a pre-determined set of rules. By\ndefining the evaluation criteria in an objective manner, even a small\nopen-source model can be used to evaluate models on our benchmark reliably. In\naddition to evaluating a large number of existing VLMs on our benchmark, we\nalso experimentally verify that our method of using pre-existing grading\ncriteria for evaluation is much more reliable than existing methods. Our\nevaluation code is available at https://github.com/maum-ai/KOFFVQA","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL","published":"2025-03-31T05:04:25Z"}
{"aid":"http://arxiv.org/abs/2503.23731v1","title":"Investigation of intelligent barbell squat coaching system based on\n  computer vision and machine learning","summary":"Purpose: Research has revealed that strength training can reduce the\nincidence of chronic diseases and physical deterioration at any age. Therefore,\nhaving a movement diagnostic system is crucial for training alone. Hence, this\nstudy developed an artificial intelligence and computer vision-based barbell\nsquat coaching system with a real-time mode that immediately diagnoses the\nissue and provides feedback after each squat. In addition, a replay mode allows\nusers to examine their previous squats and check their comments. Initially,\nfour primary characteristics of the barbell squat were identified: body joint\nangles, dorsiflexion, the ratio of knee-to-hip movement, and barbell stability.\nMethods: We collect 8,151 squats from 77 participants, categorizing them as\ngood squats and six issues. Then, we trained the diagnosis models with three\nmachine-learning architectures. Furthermore, this research applied the SHapley\nAdditive exPlanations (SHAP) method to enhance the accuracy of issue prediction\nand reduce the computation time by feature selection. Results: The F1 score of\nthe six issues reached 86.86%, 69.01%, 77.42%, 90.74%, 95.83%, and 100%. Each\nsquat diagnosis took less than 0.5 seconds. Finally, this study examined the\nefficacy of the proposed system with two groups of participants trained with\nand without the system. Subsequently, participants trained with the system\nexhibited substantial improvements in their squat technique, as assessed both\nby the system itself and by a professional weightlifting coach. Conclusion:\nThis is a comprehensive study that integrates artificial intelligence, computer\nvision and multivariable processing technologies, aimed at building a\nreal-time, user-friendly barbell squat feedback and training system.","main_category":"cs.CV","categories":"cs.CV,cs.AI,eess.IV","published":"2025-03-31T05:08:52Z"}
{"aid":"http://arxiv.org/abs/2503.23740v1","title":"LANID: LLM-assisted New Intent Discovery","summary":"Task-oriented Dialogue Systems (TODS) often face the challenge of\nencountering new intents. New Intent Discovery (NID) is a crucial task that\naims to identify these novel intents while maintaining the capability to\nrecognize existing ones. Previous efforts to adapt TODS to new intents have\nstruggled with inadequate semantic representation or have depended on external\nknowledge, which is often not scalable or flexible. Recently, Large Language\nModels (LLMs) have demonstrated strong zero-shot capabilities; however, their\nscale can be impractical for real-world applications that involve extensive\nqueries. To address the limitations of existing NID methods by leveraging LLMs,\nwe propose LANID, a framework that enhances the semantic representation of\nlightweight NID encoders with the guidance of LLMs. Specifically, LANID employs\nthe $K$-nearest neighbors and Density-Based Spatial Clustering of Applications\nwith Noise (DBSCAN) algorithms to sample selective utterance pairs from the\ntraining set. It then queries an LLM to ascertain the relationships between\nthese pairs. The data produced from this process is utilized to design a\ncontrastive fine-tuning task, which is then used to train a small encoder with\na contrastive triplet loss. Our experimental results demonstrate the efficacy\nof the proposed method across three distinct NID datasets, surpassing strong\nbaselines in both unsupervised and semi-supervised settings. Our code is\navailable at https://github.com/floatSDSDS/LANID.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-03-31T05:34:32Z"}
{"aid":"http://arxiv.org/abs/2503.23769v1","title":"Acceleration Theorem for Low-Dimensional Electron Systems with\n  Off-Diagonal Effective Mass Components","summary":"The motion of electrons under homogeneously applied electric fields in\nlow-dimensional systems with non-zero off-diagonal effective mass (ODEM) is\nstudied. The equation describing the time evolution of a probability\ncoefficient of finding an electron in a subband is derived using the\nKrieger-Iafrate theory in the effective mass approximation. It is shown that an\nelectron can change subbands during free flight due to the ODEM-induced\ninter-subband transitions. By introducing an effective dispersion defined as a\nweighted average of the subband dispersions, it is also shown that the initial\nacceleration of an electron effectively follows the bulk dispersion relation.\nThe results obtained suggest that the transport properties of the quantized\nsystems when many subbands are occupied in the weak confinement limit approach\nthe values one would find without considering the quantization.","main_category":"physics.app-ph","categories":"physics.app-ph,cond-mat.mes-hall","published":"2025-03-31T06:40:52Z"}
{"aid":"http://arxiv.org/abs/2503.23772v1","title":"TransVFC: A Transformable Video Feature Compression Framework for\n  Machines","summary":"Nowadays, more and more video transmissions primarily aim at downstream\nmachine vision tasks rather than humans. While widely deployed Human Visual\nSystem (HVS) oriented video coding standards like H.265/HEVC and H.264/AVC are\nefficient, they are not the optimal approaches for Video Coding for Machines\n(VCM) scenarios, leading to unnecessary bitrate expenditure. The academic and\ntechnical exploration within the VCM domain has led to the development of\nseveral strategies, and yet, conspicuous limitations remain in their\nadaptability for multi-task scenarios. To address the challenge, we propose a\nTransformable Video Feature Compression (TransVFC) framework. It offers a\ncompress-then-transfer solution and includes a video feature codec and Feature\nSpace Transform (FST) modules. In particular, the temporal redundancy of video\nfeatures is squeezed by the codec through the scheme-based inter-prediction\nmodule. Then, the codec implements perception-guided conditional coding to\nminimize spatial redundancy and help the reconstructed features align with\ndownstream machine perception.After that, the reconstructed features are\ntransferred to new feature spaces for diverse downstream tasks by FST modules.\nTo accommodate a new downstream task, it only requires training one lightweight\nFST module, avoiding retraining and redeploying the upstream codec and\ndownstream task networks. Experiments show that TransVFC achieves high\nrate-task performance for diverse tasks of different granularities. We expect\nour work can provide valuable insights for video feature compression in\nmulti-task scenarios. The codes are at https://github.com/Ws-Syx/TransVFC.","main_category":"eess.IV","categories":"eess.IV","published":"2025-03-31T06:44:12Z"}
{"aid":"http://arxiv.org/abs/2503.23789v1","title":"Reviewing the fundamentals and best practices to characterize\n  microplastics using state-of-the-art quantum-cascade laser\n  reflectance-absorbance spectroscopy","summary":"Microplastic pollution studies depend on reliable identification of the\nsuspicious particles. Out of the various analytical techniques available to\ncharacterize them, infrared transflectance using a tuneable mid-IR quantum\ncascade laser is a high-throughput state-of-the-art imaging option,\nspecifically Agilent QCL-LDIR (Quantum Cascade Laser Direct Infrared imaging).\nIts conceptual grounds are reviewed, instrumental developments are discussed,\nalong with a review of applications and best practices to overcome\nobstacles/difficulties in routine measurements, namely: the spectral range, the\nvariation of some peak intensities with the particles size, effects of the size\nof the particles, processing speed, and avoiding the use of measurement\naliquots. Objective procedures to avoid too many false positives when\nidentifying spectra and to distinguish fibers and fragments are given. These\npractices open a path to QCL-LDIR measurement standardization and potential use\nfor microplastics monitoring, as requested by many governmental bodies in\ncharge of setting environmental protection rules.","main_category":"physics.ins-det","categories":"physics.ins-det","published":"2025-03-31T07:04:13Z"}
{"aid":"http://arxiv.org/abs/2503.23810v1","title":"Adaptive Attention-Based Model for 5G Radio-based Outdoor Localization","summary":"Radio-based localization in dynamic environments, such as urban and vehicular\nsettings, requires systems that can efficiently adapt to varying signal\nconditions and environmental changes. Factors such as multipath interference\nand obstructions introduce different levels of complexity that affect the\naccuracy of the localization. Although generalized models offer broad\napplicability, they often struggle to capture the nuances of specific\nenvironments, leading to suboptimal performance in real-world deployments. In\ncontrast, specialized models can be tailored to particular conditions, enabling\nmore precise localization by effectively handling domain-specific variations\nand noise patterns. However, deploying multiple specialized models requires an\nefficient mechanism to select the most appropriate one for a given scenario. In\nthis work, we develop an adaptive localization framework that combines shallow\nattention-based models with a router/switching mechanism based on a\nsingle-layer perceptron (SLP). This enables seamless transitions between\nspecialized localization models optimized for different conditions, balancing\naccuracy, computational efficiency, and robustness to environmental variations.\nWe design three low-complex localization models tailored for distinct\nscenarios, optimized for reduced computational complexity, test time, and model\nsize. The router dynamically selects the most suitable model based on real-time\ninput characteristics. The proposed framework is validated using real-world\nvehicle localization data collected from a massive MIMO base station (BS),\ndemonstrating its ability to seamlessly adapt to diverse deployment conditions\nwhile maintaining high localization accuracy.","main_category":"eess.SP","categories":"eess.SP,cs.LG","published":"2025-03-31T07:44:14Z"}
{"aid":"http://arxiv.org/abs/2503.23816v1","title":"Two-electron edge states in a double SSH-chain of quantum dots","summary":"We study an interacting two-body model with adjustable spin tunneling in the\ncontext of the double SSH chains for a quantum dot system. We discovered that\nvarying interaction strengths and spin tunneling significantly influence the\nproperties of correlated edge states in the energy spectrum obtained through\nexact diagonalization. We observe that stronger interactions lead to longer\ndecay lengths of these states. Conversely, the decay length decreases as the\ndifference in intracell or intercell tunneling increases. Importantly, the\ndecay length is strongly correlated with the dynamical behavior of two\nparticles; specifically, an increase in decay length corresponds to a decrease\nin motion frequency. This conclusion is supported by the observation of the\nexpectation value of coordinate operators of the particles.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-03-31T07:50:06Z"}
{"aid":"http://arxiv.org/abs/2503.23826v1","title":"Determinization of Min-Plus Weighted Automata is Decidable","summary":"We show that the determinization problem for min-plus (tropical) weighted\nautomata is decidable, thus resolving this long-standing open problem. In doing\nso, we develop a new toolbox for analyzing and reasoning about the\nrun-structure of nondeterministic automata.","main_category":"cs.FL","categories":"cs.FL,cs.LO","published":"2025-03-31T08:21:09Z"}
{"aid":"http://arxiv.org/abs/2503.23829v1","title":"Expanding RL with Verifiable Rewards Across Diverse Domains","summary":"Reinforcement learning (RL) with verifiable rewards (RLVR) has shown\npromising results in mathematical reasoning and coding tasks where\nwell-structured reference answers are available. However, its applicability to\nbroader domains remains underexplored. In this work, we study the extension of\nRLVR to more diverse domains such as medicine, chemistry, psychology, and\neconomics. We observe high agreement in binary judgments across different large\nlanguage models (LLMs) when objective reference answers exist, which challenges\nthe necessity of large-scale annotation for training domain-specific reward\nmodels. To address the limitations of binary rewards when handling unstructured\nreference answers, we further incorporate model-based soft scoring into RLVR to\nimprove its flexibility. Our experiments show that a distilled generative\nreward model can serve as an effective cross-domain verifier, providing\nreliable reward signals for RL without requiring domain-specific annotations.\nBy fine-tuning a base 7B model using various RL algorithms against our reward\nmodel, we obtain policies that outperform state-of-the-art open-source aligned\nLLMs such as Qwen2.5-72B-Instruct and DeepSeek-R1-Distill-Qwen-32B by a large\nmargin, across domains in free-form answer settings. This also strengthens\nRLVR's robustness and scalability, highlighting its potential for real-world\napplications with noisy or weak labels.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T08:22:49Z"}
{"aid":"http://arxiv.org/abs/2503.23867v1","title":"Experimental Measurement of Non-Hermitian Left Eigenvectors","summary":"The duality of left and right eigenvectors underpins the comprehensive\nunderstanding of many physical phenomena. In Hermitian systems, left and right\neigenvectors are simply Hermitian-conjugate pairs. Non-Hermitian eigenstates in\ncontrast, have left and right eigenvectors that are distinct from each other.\nHowever, despite the tremendous interest in non-Hermitian physics in recent\nyears, the roles of non-Hermitian left eigenvectors (LEVs) are still\ninadequately explored-their physical consequences and observable effects remain\nelusive, so much so that LEVs seem largely like an object of primarily\nmathematical purpose. In this study, we present a method based on the\nnon-Hermitian Green's function for directly retrieving both LEVs and REVs from\nexperimentally measured steady-state responses. We validate the effectiveness\nof this approach in two separate acoustic experiments: one characterizes the\nnon-Hermitian Berry phase, and the other measures extended topological modes.\nOur results not only unambiguously demonstrate observable effects related to\nnon-Hermitian LEVs, but also highlight the under-appreciated role of LEVs in\nnon-Hermitian phenomena.","main_category":"quant-ph","categories":"quant-ph,physics.class-ph","published":"2025-03-31T09:17:30Z"}
{"aid":"http://arxiv.org/abs/2503.23870v1","title":"A SAT-centered XAI method for Deep Learning based Video Understanding","summary":"This paper introduces a novel formal SAT-based explanation model for deep\nlearning in video understanding. The proposed method integrates SAT solving\ntechniques with the principles of formal explainable AI to address the\nlimitations of existing XAI techniques in this domain. By encoding deep\nlearning models and video data into a logical framework and formulating\nexplanation queries as satisfiability problems, the method aims to generate\nlogic-based explanations with formal guarantees. The paper details the\nconceptual framework, the process of encoding deep learning models and video\ndata, the formulation of \"Why?\" and \"Why not?\" questions, and a novel\narchitecture integrating a SAT solver with a deep learning video understanding\nmodel. While challenges related to computational complexity and the\nrepresentational power of propositional logic remain, the proposed approach\noffers a promising direction for enhancing the explainability of deep learning\nin the complex and critical domain of video understanding.","main_category":"cs.LO","categories":"cs.LO","published":"2025-03-31T09:20:06Z"}
{"aid":"http://arxiv.org/abs/2503.23879v1","title":"Network topology effects on the social circle polls","summary":"Election polls play a critical role in political discussions by probing\npublic opinion and enabling political parties to assess their performance\nbefore elections. However, traditional polling methods sometimes fail to\npredict election outcomes accurately, leading researchers to explore new\nmethodologies. One such approach is the \"social circle\" question, which asks\nrespondents about the voting preferences of their social contacts. This method\nleverages collective intelligence and has shown promise in improving predictive\naccuracy. Nevertheless, the influence of the social network's topology on the\neffectiveness of social circle polls remains unexplored. In this study, we\ndevelop a theoretical framework to analyse how social network structure affects\npolling accuracy. By simulating voter networks with varying levels of\npolarisation and connectivity, we assess the performance of both standard and\nsocial circle polling methods. Our findings indicate that while social circle\npolls generally outperform traditional approaches, certain network\ncharacteristics can introduce biases and undermine their performances,\nparticularly in polarised situations, which are increasingly frequent in the\ncurrent political landscape. To address these challenges, we propose a new\nestimator that combines information from both standard and social circle polls,\nimproving election outcome predictions. We demonstrate the applicability of our\nmethod using real-world polling data from the 2016 U.S. presidential election,\nshowcasing its practical utility and providing an estimate of the polarisation\nlevel in that society. This work establishes a foundation for enhancing polling\nmethodologies by assessing and integrating network features, which has\nsignificant implications for social and political research.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-03-31T09:28:09Z"}
{"aid":"http://arxiv.org/abs/2503.23880v1","title":"Can a ferroelectric diode be a selector-less, universal, non-volatile\n  memory?","summary":"Recent advances in silicon foundry-process compatible ferroelectric (FE) thin\nfilms have reinvigorated interest in FE-based non-volatile memory (NVM)\ndevices. Ferroelectric diodes (FeDs) are two-terminal NVM devices exhibiting\nrectifying current-voltage hysteretic characteristics that enable\nself-selecting designs critical for high-density memory. We examine progress in\nFeDs based on CMOS-compatible HZO, AlScN, and emerging van der Waals\nferroelectrics. While FeDs demonstrate promising ON/OFF ratios and\nrectification capabilities, they face persistent challenges including limited\nwrite-cycling endurance, elevated operating voltages, and insufficient read\ncurrents. We provide materials-focused strategies to enhance reliability and\nperformance of FeDs for energy-efficient electronic memory applications, with\nemphasis on their unique self-rectifying capabilities that eliminate the need\nfor selector elements in crossbar arrays for compute in memory applications.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-31T09:29:57Z"}
{"aid":"http://arxiv.org/abs/2503.23889v1","title":"Robust Predictive Routing for Internet of Vehicles Leveraging Both V2I\n  and V2V Links","summary":"With the developments of the Internet of Vehicles (IoV) from 4G to 5G,\nvehicle-to-infrastructure (V2I) communications are becoming attractive for\nvehicle users (VUEs) to obtain diverse cloud service through base stations\n(BSs). To tackle V2I link deterioration caused by blockage and out-of-coverage\ncases, multi-hop V2X routing with both vehicle-to-vehicle (V2V) and V2I links\nneeds to be investigated. However, traditional routing reacts to statistical or\nreal-time information, which may suffer link degradation during path switchover\nin fast-changing vehicular networks. Predictive routing protocols take timely\nactions by forecasting link connectivity, but they fail to satisfy specific QoS\nrequirements. Low robustness to link failures is also incurred without\nconsidering imperfect prediction. To build continual paths between VUEs and BSs\nfor QoS provision of cloud service, a robust predictive routing framework\n(ROPE) is proposed with three major components: 1) an early warning scheme\ndetects V2I link deterioration in advance via predicting vehicle mobility and\nlink signal strength to facilitate seamless path switchover; 2) a virtual\nrouting mechanism finds top3 paths that have the highest path strength and\nsatisfy the connectivity and hop count constraints based on the prediction\nresults to fulfill QoS requirements of cloud service; 3) a path verification\nprotocol checks availability and quality of the top3 paths shortly before\nswitchover and activates one qualified path for switchover to ensure routing\nrobustness. We implement ROPE in a simulation framework incorporating\nreal-world urban maps, microscopic traffic generation, geometry-based channel\nmodeling, and offline data analysis as well as online inference. Extensive\nsimulations demonstrate the superiority of ROPE over direct V2I communications\nand a connectivity-based predictive routing protocol under various scenarios.","main_category":"cs.NI","categories":"cs.NI","published":"2025-03-31T09:41:16Z"}
{"aid":"http://arxiv.org/abs/2503.23901v1","title":"Existence of periodic solution of a non-autonomous allelopathic\n  phytoplankton model with fear effect","summary":"In this paper, we consider a non-autonomous allelopathic phytoplankton\ncompetition ODE model, incorporating the influence of fear effects observed in\nnatural biological phenomena. Based on Mawhin's coincidence degree theory some\nsufficient conditions for existence of periodic solutions are obtained. We\nvalidate our findings through an illustrative example and numerical\nsimulations, showing that constant coefficients lead to steady-state dynamics,\nwhile periodic variations induce oscillatory behavior.","main_category":"math.DS","categories":"math.DS","published":"2025-03-31T09:50:32Z"}
{"aid":"http://arxiv.org/abs/2503.23902v1","title":"First-Principle Investigation On Chromium Decorated Graphene-based\n  Systems for Hydrogen Storage","summary":"Sorbent materials like Cr decorated 2D materials are explored among its\nstorage options. 2D material like graphene has been used as it has a high\nsurface to volume ratio. A comparative study is done with Cr adsorbed in\ndefect-free and single vacancy defect graphene systems. Ab-initio calculations\nare performed with and without Van der Waals interaction to check the hydrogen\nstorage efficiency. Efficiency is determined by calculating the binding energy\nof the system. The preferred range for binding energy for reversible hydrogen\nstorage, as determined by the Department of Energy, US, is between 0.2-0.6 eV.\nThis work also visualizes the thermal stability spectrum of the efficient\nmaterials at 300 K using molecular dynamics calculations, predicting their\nstability at room temperature.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-31T09:51:56Z"}
{"aid":"http://arxiv.org/abs/2503.23910v1","title":"Droplet breakup morphologies and the resultant size distribution in an\n  opposed-flow airstream at different Weber numbers","summary":"The present study investigates the morphology and breakup dynamics of a\nfreely falling drop in a vertical airstream using shadowgraphy and in-line\nholography. The in-line holography provides the temporal evolution of the\nvolumetric size distribution of child droplets formed during various\nfragmentation processes at different Weber numbers (We). The droplet undergoes\ndifferent fragmentation processes at significantly lower Weber numbers in\nopposed-flow configurations compared to cross-flow configurations. Our findings\nreveal distinct fragmentation modes, namely bag, bag-stamen, and dual-bag\nbreakup, observed at We=9.38, 16.9, and 18.9, respectively. At We = 9.38, the\ncombined effects of bag rupture, rim breakup, and node fragmentation generate\nchild droplets of varying sizes, driven by the interplay of the\nRayleigh-Plateau and Rayleigh-Taylor instabilities. At We = 16.9, the\ninteraction of aerodynamic and shear forces leads to bag-stamen fragmentation,\ncharacterized by forming a stamen-like structure along with the bag. Both bag\nand bag-stamen breakups result in tri-modal size distributions. However, at We\n= 16.9, fewer tiny droplets are produced compared to the bag breakup observed\nat lower Weber numbers. In contrast, at We = 18.9, a dual-bag breakup occurs,\nwhere both bags inflate and burst simultaneously. This process generates tiny\nchild droplets in the early stages, while larger child droplets form later due\nto the fragmentation of the rim and nodes, resulting in a bi-modal size\ndistribution. We have performed a theoretical analysis using a two-parameter\ngamma distribution, which satisfactorily predicts the size distributions\nobserved experimentally at different Weber numbers.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-03-31T10:02:22Z"}
{"aid":"http://arxiv.org/abs/2503.23911v1","title":"FineCausal: A Causal-Based Framework for Interpretable Fine-Grained\n  Action Quality Assessment","summary":"Action quality assessment (AQA) is critical for evaluating athletic\nperformance, informing training strategies, and ensuring safety in competitive\nsports. However, existing deep learning approaches often operate as black boxes\nand are vulnerable to spurious correlations, limiting both their reliability\nand interpretability. In this paper, we introduce FineCausal, a novel\ncausal-based framework that achieves state-of-the-art performance on the\nFineDiving-HM dataset. Our approach leverages a Graph Attention Network-based\ncausal intervention module to disentangle human-centric foreground cues from\nbackground confounders, and incorporates a temporal causal attention module to\ncapture fine-grained temporal dependencies across action stages. This\ndual-module strategy enables FineCausal to generate detailed spatio-temporal\nrepresentations that not only achieve state-of-the-art scoring performance but\nalso provide transparent, interpretable feedback on which features drive the\nassessment. Despite its strong performance, FineCausal requires extensive\nexpert knowledge to define causal structures and depends on high-quality\nannotations, challenges that we discuss and address as future research\ndirections. Code is available at https://github.com/Harrison21/FineCausal.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T10:02:29Z"}
{"aid":"http://arxiv.org/abs/2503.23912v1","title":"Certified Approximate Reachability (CARe): Formal Error Bounds on Deep\n  Learning of Reachable Sets","summary":"Recent approaches to leveraging deep learning for computing reachable sets of\ncontinuous-time dynamical systems have gained popularity over traditional\nlevel-set methods, as they overcome the curse of dimensionality. However, as\nwith level-set methods, considerable care needs to be taken in limiting\napproximation errors, particularly since no guarantees are provided during\ntraining on the accuracy of the learned reachable set. To address this\nlimitation, we introduce an epsilon-approximate Hamilton-Jacobi Partial\nDifferential Equation (HJ-PDE), which establishes a relationship between\ntraining loss and accuracy of the true reachable set. To formally certify this\napproximation, we leverage Satisfiability Modulo Theories (SMT) solvers to\nbound the residual error of the HJ-based loss function across the domain of\ninterest. Leveraging Counter Example Guided Inductive Synthesis (CEGIS), we\nclose the loop around learning and verification, by fine-tuning the neural\nnetwork on counterexamples found by the SMT solver, thus improving the accuracy\nof the learned reachable set. To the best of our knowledge, Certified\nApproximate Reachability (CARe) is the first approach to provide soundness\nguarantees on learned reachable sets of continuous dynamical systems.","main_category":"eess.SY","categories":"eess.SY,cs.LG,cs.SY,math.OC","published":"2025-03-31T10:02:57Z"}
{"aid":"http://arxiv.org/abs/2503.23914v1","title":"Scenarios for the Deployment of Automated Vehicles in Europe","summary":"The deployment of Automated Vehicles (AVs) is expected to address road\ntransport externalities (e.g., safety, traffic, environmental impact, etc.).\nFor this reason, a legal framework for their large-scale market introduction\nand deployment is currently being developed in the European Union. Despite the\nfirst steps towards road transport automation, the timeline for full automation\nand its potential economic benefits remains uncertain. The aim of this paper is\ntwofold. First, it presents a methodological framework to determine deployment\npathways of the five different levels of automation in EU27+UK to 2050 under\nthree scenarios (i.e., slow, medium baseline and fast) focusing on passenger\nvehicles. Second, it proposes an assessment of the economic impact of AVs\nthrough the calculation of the value-added. The method to define assumptions\nand uptake trajectories involves a comprehensive literature review, expert\ninterviews, and a model to forecast the new registrations of different levels\nof automation. In this way, the interviews provided insights that complemented\nthe literature and informed the design of assumptions and deployment\ntrajectories. The added-value assessment shows additional economic activity due\nto the introduction of automated technologies in all uptake scenarios.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-03-31T10:06:27Z"}
{"aid":"http://arxiv.org/abs/2503.23918v1","title":"Hint of $r\\simeq 0.01$ after DESI DR2 ?","summary":"In the report by BICEP and Keck collaborations, the tensor-to-scalar ratio is\n$r_{0.05}<0.036$ (95\\% C.L.) and $ <1.3\\sigma$ non-zero (with pre-DESI BAO\ndata). However, recent datasets have significantly shifted the bestfit values\nof relevant $\\Lambda$CDM cosmological parameters, and thus possibly alter the\namplitude of lensing B-mode spectrum, which would affect the search for $r$.\nHere, the joint analysis of Planck and BICEP/Keck data with DESI DR2 reveals\nthat the lower bound of $r_{0.05}$ is $2.0\\sigma$ and $2.1\\sigma$ non-zero for\nPantheonPlus and DES-Y5, respectively, and the bestfit $r$ is $r_{0.05}\\simeq\n0.01$. The results are consistent with those with DESI DR1, but slightly\nstrengthened. There might be still systematic uncertainties in B-mode\nmeasurements due to the foreground contamination, however, our work is to not\nsay what about the value of $r$, but emphasize that the detection for $r$ is\nmodel-dependent and depends potentially on our insight into the dark universe,\nhighlighting the important role of cosmological surveys in comprehending our\nvery early universe.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-03-31T10:08:04Z"}
{"aid":"http://arxiv.org/abs/2503.23950v1","title":"Plasmons in N-layer systems","summary":"In multilayer structures, the coupling between layers gives rise to unique\nplasmon modes, but analytic solutions are typically available only for bilayers\ndue to the increasing complexity as the number of layers increases. We\ninvestigate plasmons in multilayer structures, including the effects of\ninterlayer tunneling. By introducing the Coulomb eigenvector basis for\nmultilayer systems, which can be solved exactly using Kac-Murdock-Szeg\\H{o}\nToeplitz matrices, we analytically derive the long-wavelength plasmon\ndispersions both with and without interlayer tunneling. In the $N$-layer\nsystems, we find that, in the absence of interlayer tunneling, the out-of-phase\nacoustic or charge neutral plasmon modes with linear dispersions\n($\\omega_\\alpha\\propto q/\\sqrt{{1-\\cos{\\left(\\frac{\\alpha-1}{N}\\pi\\right)}}}$\nfor $\\alpha = 2, 3, \\cdots, N$) exist, while the in-phase classical plasmon\nmode exhibits its conventional dispersion ($\\omega_1\\propto \\sqrt{q}$). When\ninterlayer tunneling is present, the out-of-phase modes develop plasmon gaps\nthat are governed by specific interband transitions, whereas the classical mode\nremains unaffected. These findings have broad applicability to general\ncoupled-layer structures.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-03-31T11:02:44Z"}
{"aid":"http://arxiv.org/abs/2503.23962v1","title":"On the kernel of the Stieltjes derivative and the space of bounded\n  Stieltjes-differentiable functions","summary":"We investigate the existence and uniqueness of solutions to first-order\nStieltjes differential problems, focusing on the role of the Stieltjes\nderivative and its kernel. Unlike the classical case, the kernel of the\nStieltjes derivative operator is nontrivial, leading to non-uniqueness issues\nin Cauchy problems. We characterize this kernel by providing necessary and\nsufficient conditions for a function to have a zero Stieltjes derivative. To\naddress the implications of this nontrivial kernel, we introduce a function\nspace which serves as a suitable framework for studying Stieltjes differential\nproblems. We explore its topological structure and propose a metric that\nfacilitates the formulation of existence and uniqueness results. Our findings\ndemonstrate that solutions to first-order Stieltjes differential equations are,\nin general, not unique, underscoring the need for a refined analytical approach\nto such problems.","main_category":"math.CA","categories":"math.CA","published":"2025-03-31T11:22:02Z"}
{"aid":"http://arxiv.org/abs/2503.23969v1","title":"Electronic structure of UGe$_2$ at ambient pressure: comparison with\n  X-ray photoemission spectra","summary":"Based on experimental crystallographic data, electronic structure of UGe$_2$\nhave been calculated and compared with our results of X-ray photoelectron\nspectroscopy (XPS) measurements. We employed two different advanced full\npotential (FP) methods: FP-local-orbital (FPLO) and FP-linear augmented plane\nwaves (Wien2k) codes for non-magnetic and ferromagnetic states. Starting from\nthe local spin-density approximation (LSDA) or generalised gradient\napproximation (GGA), we verified either the orbital polarisation (OP)\ncorrection or the GGA+U approach for the U 5f-electrons, changing\nCoulomb-repulsion energies U in the range 0-4 eV. Satisfying agreement was\nachieved between experimental and our calculated magnetic moments using\nab-initio LSDA+OP and non-ab-initio GGA+U approaches, the latter for realistic\nU values of 2-3 eV. We proved by the LSDA+OP approach an existence of the Fermi\nsurface nesting vector along the a axis, possibly responsible for the triplet\nsuperconducting pairing. The calculated data reveal predominantly an itinerant\nU 5f-electron character of bands near the Fermi level, EF, with only small\ncontributions from the U 6d and Ge 4p states. The experimental XPS spectrum of\nvalence bands (VB) also contains the sharp main 5f-electron peak at EF, a wide\nhump (around -2 eV), and broad small peaks at higher energies. In the\ncalculated XPS spectrum, the width of the main 5f-electron peak varies between\n0.8 and 1.4 eV, depending on a method used in computations, but the hump\nremains unresolved. A newly observed asymmetric 1-eV satellite in the\nexperimental 4f-core XPS spectrum together with known 3-eV and 7-eV satellites\nsuggest dual behaviour of U-5f-electrons in UGe$_2$, the feature is inferred\nalso from the VB studies.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el,physics.comp-ph","published":"2025-03-31T11:34:09Z"}
{"aid":"http://arxiv.org/abs/2503.23980v1","title":"SALT: A Flexible Semi-Automatic Labeling Tool for General LiDAR Point\n  Clouds with Cross-Scene Adaptability and 4D Consistency","summary":"We propose a flexible Semi-Automatic Labeling Tool (SALT) for general LiDAR\npoint clouds with cross-scene adaptability and 4D consistency. Unlike recent\napproaches that rely on camera distillation, SALT operates directly on raw\nLiDAR data, automatically generating pre-segmentation results. To achieve this,\nwe propose a novel zero-shot learning paradigm, termed data alignment, which\ntransforms LiDAR data into pseudo-images by aligning with the training\ndistribution of vision foundation models. Additionally, we design a\n4D-consistent prompting strategy and 4D non-maximum suppression module to\nenhance SAM2, ensuring high-quality, temporally consistent presegmentation.\nSALT surpasses the latest zero-shot methods by 18.4% PQ on SemanticKITTI and\nachieves nearly 40-50% of human annotator performance on our newly collected\nlow-resolution LiDAR data and on combined data from three LiDAR types,\nsignificantly boosting annotation efficiency. We anticipate that SALT's\nopen-sourcing will catalyze substantial expansion of current LiDAR datasets and\nlay the groundwork for the future development of LiDAR foundation models. Code\nis available at https://github.com/Cavendish518/SALT.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-03-31T11:46:55Z"}
{"aid":"http://arxiv.org/abs/2503.23988v1","title":"Deep Learning Model Deployment in Multiple Cloud Providers: an\n  Exploratory Study Using Low Computing Power Environments","summary":"The deployment of Machine Learning models at cloud have grown by tech\ncompanies. Hardware requirements are higher when these models involve Deep\nLearning (DL) techniques and the cloud providers' costs may be a barrier. We\nexplore deploying DL models using for experiments the GECToR model, a DL\nsolution for Grammatical Error Correction, across three of the major cloud\nplatforms (AWS, Google Cloud, Azure). We evaluate real-time latency, hardware\nusage and cost at each cloud provider by 7 execution environments with 10\nexperiments reproduced. We found that while GPUs excel in performance, they had\nan average cost 300% higher than solutions without GPU. Our analysis also\nidentifies that processor cache size is crucial for cost-effective CPU\ndeployments, enabling over 50% of cost reduction compared to GPUs. This study\ndemonstrates the feasibility and affordability of cloud-based DL inference\nsolutions without GPUs, benefiting resource-constrained users like startups.","main_category":"cs.DC","categories":"cs.DC,cs.AI,cs.PF","published":"2025-03-31T11:58:37Z"}
{"aid":"http://arxiv.org/abs/2503.23999v1","title":"Foreign Direct Investment and Job Creation in EU Regions","summary":"This study examines the impact of foreign direct investment (FDI) on job\ncreation across 109 regions in the old EU member states from 2012 to 2023.\nUsing dynamic and spatial econometric models combined with a unique dataset of\nFDI projects, we find that increased FDI inflows significantly enhance regional\njob creation, but the relationship is nonlinear. Sectoral specialization plays\na crucial role, as more concentrated FDI inflows lead to higher employment\ngrowth. Furthermore, FDI-driven job creation exhibits significant spatial\nspillover effects. However, regions attracting high-value FDI jobs, such as\nthose in R&D and management, tend to experience slower overall employment\ngrowth.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-03-31T12:21:51Z"}
{"aid":"http://arxiv.org/abs/2503.24005v1","title":"Attraction of a jerk","summary":"Jerk plays a pivotal role in the thrilling experience of many amusemement\npark rides. In addition to exploring the physical aspect of jerks, we tackle\nthe empirical observation of an attractive force between passengers in the\npopular attraction, the spinning teacups. By modeling the complex system of\nrotating platforms, we show that pseudotorques induced by changing acceleration\nlead to jerky movements and an attractive interaction among riders. Our\nnumerical analysis confirms the empirical observations, highlighting the\nconnection between attraction and jerks.","main_category":"physics.class-ph","categories":"physics.class-ph,physics.pop-ph","published":"2025-03-31T12:30:57Z"}
{"aid":"http://arxiv.org/abs/2503.24031v1","title":"An ANN-Enhanced Approach for Flatness-Based Constrained Control of\n  Nonlinear Systems","summary":"Neural networks have proven practical for a synergistic combination of\nadvanced control techniques. This work analyzes the implementation of rectified\nlinear unit neural networks to achieve constrained control in differentially\nflat systems. Specifically, the class of flat systems enjoys the benefit of\nfeedback linearizability, i.e., the systems can be linearized by means of a\nproper variable transformation. However, the price for linearizing the dynamics\nis that the constraint descriptions are distorted geometrically. Our results\nshow that, by using neural networks, these constraints can be represented as a\nunion of polytopes, enabling the use of mixed-integer programming tools to\nguarantee constraint satisfaction. We further analyze the integration of the\ncharacterization into efficient settings such as control Lyapunov\nfunction-based and model predictive control (MPC). Interestingly, this\ndescription also allows us to explicitly compute the solution of the MPC\nproblem for the nonlinear system. Several examples are provided to illustrate\nthe effectiveness of our framework.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-03-31T12:57:13Z"}
{"aid":"http://arxiv.org/abs/2503.24035v1","title":"Using directed acyclic graphs to determine whether multiple imputation\n  or subsample multiple imputation estimates of an exposure-outcome association\n  are unbiased","summary":"Background: Missing data is a pervasive problem in epidemiology, with\ncomplete records analyses (CRA) or multiple imputation (MI) the most common\nmethods to deal with incomplete data. MI is valid when incomplete variables are\nindependent of response indicators, conditional on complete variables -\nhowever, this can be hard to assess with multiple incomplete variables.\nPrevious literature has shown that MI may be valid in subsamples of the data,\neven if not necessarily valid in the full dataset. Current guidance on how to\ndecide whether MI is appropriate is lacking.\n  Methods: We develop an algorithm that is sufficient to indicate when MI will\nestimate an exposure-outcome coefficient without bias and show how to implement\nthis using directed acyclic graphs (DAGs). We extend the algorithm to\ninvestigate whether MI applied to a subsample of the data, in which some\nvariables and complete and the remaining are imputed, will be unbiased for the\nsame estimand. We demonstrate the algorithm by applying it to several simple\nexamples and a more complex real-life example.\n  Conclusions: Multiple incomplete variables are common in practice. Assessing\nthe plausibility of each of CRA and MI estimating an exposure-outcome\nassociation without bias is crucial in analysing and interpreting results. Our\nalgorithm provides researchers with the tools to decide whether (and how) to\nuse MI in practice. Further work could focus on the likely size and direction\nof biases, and the impact of different missing data patterns.","main_category":"stat.ME","categories":"stat.ME","published":"2025-03-31T13:00:18Z"}
{"aid":"http://arxiv.org/abs/2503.24036v1","title":"Automated Discovery of Tactic Libraries for Interactive Theorem Proving","summary":"Enabling more concise and modular proofs is essential for advancing formal\nreasoning using interactive theorem provers (ITPs). Since many ITPs, such as\nRocq and Lean, use tactic-style proofs, learning higher-level custom tactics is\ncrucial for proof modularity and automation. This paper presents a novel\napproach to tactic discovery, which leverages Tactic Dependence Graphs (TDGs)\nto identify reusable proof strategies across multiple proofs. TDGs capture\nlogical dependencies between tactic applications while abstracting away\nirrelevant syntactic details, allowing for both the discovery of new tactics\nand the refactoring of existing proofs into more modular forms. We have\nimplemented this technique in a tool called TacMiner and compare it against an\nanti-unification-based approach Peano to tactic discovery. Our evaluation\ndemonstrates that TacMiner can learn 3x as many tactics as Peano and reduces\nthe size of proofs by 26% across all benchmarks. Furthermore, our evaluation\ndemonstrates the benefits of learning custom tactics for proof automation,\nallowing a state-of-the-art proof automation tool to achieve a relative\nincrease of 172% in terms of success rate.","main_category":"cs.PL","categories":"cs.PL","published":"2025-03-31T13:00:29Z"}
{"aid":"http://arxiv.org/abs/2503.24050v1","title":"A Deep Learning Framework for the Electronic Structure of Water: Towards\n  a Universal Model","summary":"Accurately modeling the electronic structure of water across scales, from\nindividual molecules to bulk liquid, remains a grand challenge. Traditional\ncomputational methods face a critical trade-off between computational cost and\nefficiency.We present an enhanced machine-learning Deep Kohn-Sham (DeePKS)\nmethod for improved electronic structure, DeePKS-ES, that overcomes this\ndilemma. By incorporating the Hamiltonian matrix and their eigenvalues and\neigenvectors into the loss function, we establish a universal model for water\nsystems, which can reproduce high-level hybrid functional (HSE06) electronic\nproperties from inexpensive generalized gradient approximation (PBE)\ncalculations. Validated across molecular clusters and liquid-phase simulations,\nour approach reliably predicts key electronic structure properties such as band\ngaps and density of states, as well as total energy and atomic forces. This\nwork bridges quantum-mechanical precision with scalable computation, offering\ntransformative opportunities for modeling aqueous systems in catalysis, climate\nscience, and energy storage.","main_category":"physics.chem-ph","categories":"physics.chem-ph,physics.atm-clus,physics.comp-ph","published":"2025-03-31T13:13:47Z"}
{"aid":"http://arxiv.org/abs/2503.24052v1","title":"Accelerated Airfoil Design Using Neural Network Approaches","summary":"In this paper, prediction of airfoil shape from targeted pressure\ndistribution (suction and pressure sides) and vice versa is demonstrated using\nboth Convolutional Neural Networks (CNNs) and Deep Neural Networks (DNNs)\ntechniques. The dataset is generated for 1600 airfoil shapes, with simulations\ncarried out at Reynolds numbers (Re) ranging from 10,000 and 90,00,000 and\nangles of attack (AoA) ranging from 0 to 15 degrees, ensuring the dataset\ncaptured diverse aerodynamic conditions. Five different CNN and DNN models are\ndeveloped depending on the input/output parameters. Results demonstrate that\nthe refined models exhibit improved efficiency, with the DNN model achieving a\nmulti-fold reduction in training time compared to the CNN model for complex\ndatasets consisting of varying airfoil, Re, and AoA. The predicted airfoil\nshapes/pressure distribution closely match the targeted values, validating the\neffectiveness of deep learning frameworks. However, the performance of CNN\nmodels is found to be better compared to DNN models. Lastly, a flying wing\naircraft model of wingspan >10 m is considered for the prediction of pressure\ndistribution along the chordwise. The proposed CNN and DNN models show\npromising results. This research underscores the potential of deep learning\nmodels accelerating aerodynamic optimization and advancing the design of\nhigh-performance airfoils.","main_category":"cs.LG","categories":"cs.LG,math-ph,math.MP,physics.app-ph,physics.flu-dyn,physics.space-ph","published":"2025-03-31T13:14:14Z"}
{"aid":"http://arxiv.org/abs/2503.24079v1","title":"Joint model for zero-inflated data combining fishery-dependent and\n  fishery-independent sources","summary":"Accurately identifying spatial patterns of species distribution is crucial\nfor scientific insight and societal benefit, aiding our understanding of\nspecies fluctuations. The increasing quantity and quality of ecological\ndatasets present heightened statistical challenges, complicating spatial\nspecies dynamics comprehension. Addressing the complex task of integrating\nmultiple data sources to enhance spatial fish distribution understanding in\nmarine ecology, this study introduces a pioneering five-layer Joint model. The\nmodel adeptly integrates fishery-independent and fishery-dependent data,\naccommodating zero-inflated data and distinct sampling processes. A\ncomprehensive simulation study evaluates the model performance across various\npreferential sampling scenarios and sample sizes, elucidating its advantages\nand challenges. Our findings highlight the model's robustness in estimating\npreferential parameters, emphasizing differentiation between presence-absence\nand biomass observations. Evaluation of estimation of spatial covariance and\nprediction performance underscores the model's reliability. Augmenting sample\nsizes reduces parameter estimation variability, aligning with the principle\nthat increased information enhances certainty. Assessing the contribution of\neach data source reveals successful integration, providing a comprehensive\nrepresentation of biomass patterns. Empirical validation within a real-world\ncontext further solidifies the model's efficacy in capturing species' spatial\ndistribution. This research advances methodologies for integrating diverse\ndatasets with different sampling natures further contributing to a more\ninformed understanding of spatial dynamics of marine species.","main_category":"stat.ME","categories":"stat.ME","published":"2025-03-31T13:33:58Z"}
{"aid":"http://arxiv.org/abs/2503.24093v1","title":"Active Reconfigurable Intelligent Surfaces: Circuit Modeling and\n  Reflection Amplification Optimization","summary":"Reconfigurable Intelligent Surfaces (RISs) constitute a promising emerging\ntechnology that enables wireless systems to control the propagation environment\nto enhance diverse communication objectives. To mitigate double-fading\nattenuation in RIS-aided links, the paradigm of active metamaterials capable of\namplifying their incident wave has emerged. In this paper, capitalizing on the\ninherent negative-resistance region of tunnel diodes, we propose their\nintegration into each RIS unit element to enable RISs with reflection\namplification entirely in the analog domain. We derive novel realistic\nphase-amplitude relationships and power constraints specific to this model,\naddressing gaps in the existing literature where amplitude limits are often\nchosen arbitrarily. This characterization of our active RIS unit elements is\nincorporated into two novel optimization frameworks targeting the spectral\nefficiency maximization of RIS-assisted Multiple-Input-Multiple-Output (MIMO)\nsystems, which are solved via an one-step approach and an iterative Alternating\nOptimization (AO) method. The former approach is used to initialize the AO\nframework, enhancing both its performance and convergence. Our numerical\ninvestigations emphasize the importance of accurately modeling phase-amplitude\ndependencies, and provide key insights into the impact of RIS-induced noise as\nwell as the trade-off between available power and the number of active\nelements.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T13:44:03Z"}
{"aid":"http://arxiv.org/abs/2503.24117v1","title":"Organizations, teams, and job mobility: A social microdynamics approach","summary":"The internal structures of large organizations determine much of what occurs\ninside including the way in which tasks are performed, the workers that perform\nthem, and the mobility of those workers within the organization. However,\nregarding this latter process, most of the theoretical and modeling approaches\nused to understand organizational worker mobility are highly stylized, using\nidealizations such as structureless organizations, indistinguishable workers,\nand a lack of social bonding of the workers. In this article, aided by a decade\nof precise, temporally resolved data of a large US government organization, we\nintroduce a new model to describe organizations as composites of teams within\nwhich individuals perform specific tasks and where social connections develop.\nBy tracking the personnel composition of organizational teams, we find that\nworkers that change jobs are highly influenced by preferring to reunite with\npast co-workers. In this organization, 34\\% of all moves lead to worker\nreunions, a percentage well-above expectation. We find that the greater the\ntime workers spend together or the smaller the team they share both increase\ntheir likelihood to reunite, supporting the notion of increased familiarity and\ntrust behind such reunions and the dominant role of social capital in the\nevolution of large organizations.","main_category":"cs.CE","categories":"cs.CE","published":"2025-03-31T14:07:28Z"}
{"aid":"http://arxiv.org/abs/2503.24121v1","title":"IMPACT: A Generic Semantic Loss for Multimodal Medical Image\n  Registration","summary":"Image registration is fundamental in medical imaging, enabling precise\nalignment of anatomical structures for diagnosis, treatment planning,\nimage-guided treatment or longitudinal monitoring. This work introduces IMPACT\n(Image Metric with Pretrained model-Agnostic Comparison for Transmodality\nregistration), a generic semantic similarity metric designed for seamless\nintegration into diverse image registration frameworks (such as Elastix and\nVoxelmorph). It compares deep learning-based features extracted from medical\nimages without requiring task-specific training, ensuring broad applicability\nacross various modalities. By leveraging the features of the large-scale\npretrained TotalSegmentator models and the ability to integrate Segment\nAnything Model (SAM) and other large-scale segmentation networks, this approach\noffers significant advantages. It provides robust, scalable, and efficient\nsolutions for multimodal image registration. The IMPACT loss was evaluated on\nfive challenging registration tasks involving thoracic CT/CBCT, and pelvic\nMR/CT datasets. Quantitative metrics, such as Target Registration Error and\nDice Similarity Coefficient, demonstrated significant improvements in\nanatomical alignment compared to baseline methods. Qualitative analyses further\nconfirmed the increased robustness of the proposed metric in the face of noise,\nartifacts, and modality variations. IMPACT's versatility and efficiency make it\na valuable tool for advancing registration performance in clinical and research\napplications, addressing critical challenges in multimodal medical imaging.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-03-31T14:08:21Z"}
{"aid":"http://arxiv.org/abs/2503.24125v1","title":"Evidence for the collective nature of radial flow in Pb+Pb collisions\n  with the ATLAS detector","summary":"Anisotropic flow and radial flow are two key probes of the expansion dynamics\nand properties of the quark-gluon plasma (QGP). While anisotropic flow has been\nextensively studied, radial flow, which governs the system's radial expansion,\nhas received less attention. Notably, experimental evidence for the global and\ncollective nature of radial flow has been lacking. This Letter presents the\nfirst measurement of transverse momentum ($p_{\\mathrm{T}}$) dependence of\nradial flow fluctuations ($v_0(p_{\\mathrm{T}})$) over $0.5<p_{\\mathrm{T}}<10$\nGeV, using a two-particle correlation method in Pb+Pb collisions at\n$\\sqrt{s_{\\mathrm{NN}}}=5.02$ TeV. The data reveal three key features\nsupporting the collective nature of radial flow: long-range correlation in\npseudorapidity, factorization in $p_{\\mathrm{T}}$, and centrality-independent\nshape in $p_{\\mathrm{T}}$. The comparison with a hydrodynamic model\ndemonstrates the sensitivity of $v_0(p_{\\mathrm{T}})$ to bulk viscosity, a\ncrucial transport property of the QGP. These findings establish a new, powerful\ntool for probing collective dynamics and properties of the QGP.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-03-31T14:10:55Z"}
{"aid":"http://arxiv.org/abs/2503.24138v1","title":"AI-Assisted Colonoscopy: Polyp Detection and Segmentation using\n  Foundation Models","summary":"In colonoscopy, 80% of the missed polyps could be detected with the help of\nDeep Learning models. In the search for algorithms capable of addressing this\nchallenge, foundation models emerge as promising candidates. Their zero-shot or\nfew-shot learning capabilities, facilitate generalization to new data or tasks\nwithout extensive fine-tuning. A concept that is particularly advantageous in\nthe medical imaging domain, where large annotated datasets for traditional\ntraining are scarce. In this context, a comprehensive evaluation of foundation\nmodels for polyp segmentation was conducted, assessing both detection and\ndelimitation. For the study, three different colonoscopy datasets have been\nemployed to compare the performance of five different foundation models,\nDINOv2, YOLO-World, GroundingDINO, SAM and MedSAM, against two benchmark\nnetworks, YOLOv8 and Mask R-CNN. Results show that the success of foundation\nmodels in polyp characterization is highly dependent on domain specialization.\nFor optimal performance in medical applications, domain-specific models are\nessential, and generic models require fine-tuning to achieve effective results.\nThrough this specialization, foundation models demonstrated superior\nperformance compared to state-of-the-art detection and segmentation models,\nwith some models even excelling in zero-shot evaluation; outperforming\nfine-tuned models on unseen data.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-03-31T14:20:53Z"}
{"aid":"http://arxiv.org/abs/2503.24155v1","title":"The Belle II Experiment at SuperKEKB -- Input to the European Particle\n  Physics Strategy","summary":"Belle II is an intensity-frontier experiment at the SuperKEKB collider in\nTsukuba, Japan. Over the coming decades, it will record the decays of billions\nof bottom mesons, charm hadrons, and tau leptons produced in 10 GeV\nelectron-positron collisions. The experiment's low-background environment and\nprecisely known kinematics enable high-precision measurements of hundreds of\nStandard Model (SM) parameters while probing for new particles at mass scales\nfar beyond the direct reach of high-energy colliders. We project Belle II's\nsensitivity for key measurements - where it will be uniquely positioned or\nworld-leading - over datasets ranging from 1 to 50 ab${}^{-1}$. By exploring\npreviously uncharted regions of non-SM parameter space with high precision,\nBelle II will either reveal new physics or set stringent constraints, guiding\nfuture experimental and theoretical efforts. Additionally, we outline near-term\nupgrades to the Belle II detector and SuperKEKB accelerator, which will enhance\nsensitivity in searches for new physics beyond the SM across flavor, tau,\nelectroweak, and dark sector physics. These improvements will ensure that Belle\nII remains both complementary to and competitive with the LHC and other\nexperiments.","main_category":"hep-ex","categories":"hep-ex,hep-ph","published":"2025-03-31T14:39:29Z"}
{"aid":"http://arxiv.org/abs/2503.24173v1","title":"Worldvolume fermion as baryon with homogeneous instantons in holographic\n  $\\mathrm{QCD}_{3}$","summary":"We investigate holographically the effective theory of the worldvolume\nfermion on the flavor branes in the D3/D7 model with homogeneously smeared\nD(-1)-branes. As a top-down approach in gauge-gravity duality, the D(-1)-branes\nare instantons and violate the CP symmetry in the dual theory. The background\ngeometry of this model contains black brane (deconfined geometry) and bubble\nD3-brane solutions (confined geometry), all with a non-zero Romand-Romand zero\nform as axion. The dual theories to the backgrounds are respectively the Super\nYang-Mills theory at finite temperature and three-dimensional confining\nYang-Mills theory, all with a Chern-Simons term induced by instantons. In the\nconfined geometry, we introduce a baryon vertex as a D5-brane wrapped on\n$S^{5}$, then identify the fermionic flux on the D7-brane as a baryonic\noperator. Afterwards, we study the spectrum and the holographic correlation\nfunction of the flavored fermion on the D7-branes. Remarkably, the fermionic\nspectrum is in agreement with the dispersion curves obtained from the confined\ncorrelation function, and the mass ratio of the lowest baryon and meson in our\nmodel is close to the associated experimental data. Moreover, the effective\ninteraction terms of the holographic baryon and meson are derived and all the\ncoupling constants take order of $N_{c}^{1/2}$ agreeing with the evaluation\nfrom the large N field theory. In the deconfined geometry, the holographic\ncorrelation function is also evaluated numerically while the fermion on\nD7-brane is identified to plasmino instead of baryon. The dispersion curves\nfrom the deconfined correlation function basically covers the results from the\nhard thermal loop approximation and may imply the instanton-induced interaction\nwith spin. Overall, this work constructs a holographic theory about baryonic\nfermion and mesonic boson with instantons or CP violation.","main_category":"hep-th","categories":"hep-th,hep-ph,nucl-th","published":"2025-03-31T14:51:40Z"}
{"aid":"http://arxiv.org/abs/2503.24186v1","title":"Annihilation of cohomology and (strong) generation of singularity\n  categories","summary":"Let R be a commutative Noetherian ring. We establish a close relationship\nbetween the (strong) generation of the singularity category of R, the\nnonvanishing of the annihilator of the singularity category of R, and the\nnonvanishing of the cohomological annihilator of modules. As an application, we\nprove that the singularity category of R has a strong generator if and only if\nthe annihilator of the singularity category of R is nonzero when R is a\nNoetherian domain with Krull dimension at most one. Furthermore, we relate the\ngeneration of the singularity category and the extension generation of the\nmodule category. Additionally, we introduce the notion of the co-cohomological\nannihilator of modules. If the category of finitely generated R-modules has a\nstrong generator, we show that the infinite injective dimension locus of a\nfinitely generated R-module M is closed, with the defining ideal given by the\nco-cohomological annihilator of M.","main_category":"math.AC","categories":"math.AC,math.RT","published":"2025-03-31T15:03:30Z"}
{"aid":"http://arxiv.org/abs/2503.24225v1","title":"Compressible N-phase fluid mixture models","summary":"Fluid mixture models are essential for describing a wide range of physical\nphenomena, including wave dynamics and spinodal decomposition. However, there\nis a lack of consensus in the modeling of compressible mixtures, with limited\nconnections between different classes of models. On the one hand, existing\ncompressible two-phase flow models accurately describe wave dynamics, but do\nnot incorporate phase separation mechanisms. On the other hand, phase-field\ntechnology in fluid dynamics consists of models incorporating spinodal\ndecomposition, however, a general phase-field theory for compressible mixtures\nremains largely undeveloped.\n  In this paper, we take an initial step toward bridging the gap between\ncompressible two-phase flow models and phase-field models by developing a\ntheory for compressible, isothermal N-phase mixtures. Our theory establishes a\nsystem of reduced complexity by formulating N mass balance laws alongside a\nsingle momentum balance law, thereby naturally extending the Navier-Stokes\nKorteweg model to N-phases and providing the Navier-Stokes\nCahn-Hilliard/Allen-Cahn model for compressible mixtures. Key aspects of the\nframework include its grounding in continuum mixture theory and its\npreservation of thermodynamic consistency despite its reduced complexity.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,math-ph,math.AP,math.MP","published":"2025-03-31T15:38:49Z"}
{"aid":"http://arxiv.org/abs/2503.24233v1","title":"Input from the SND@LHC collaboration to the 2026 Update to the European\n  Strategy for Particle Physics","summary":"By observing collider neutrino interactions of different flavours, the\nSND@LHC and Faser experiments have shown that the LHC can make interesting\ncontributions to neutrino physics. This document summarizes why the SND@LHC\nCollaboration intends to continue taking data at the High Luminosity LHC\n(HL-LHC). The upgraded detector will instrument the regions of both the\nneutrino vertex and the magnetized calorimeter with silicon microstrips. The\nuse of this technology will allow us to continue the physics program of the\ncurrent SND@LHC detector with higher statistics. It will also offer new\npossibilities. For instance, the magnetization of the hadron calorimeter will\nenable the separation between neutrinos and antineutrinos. This could lead to\nthe first direct observation of tau antineutrinos. The use of ultrafast timing\nlayers will enable triggers to be sent to ATLAS, potentially allowing the\nidentification of the charm quark pair that produced the neutrino interacting\nin the detector. Such tagging of the neutrino source would fulfill Pontecorvo\noriginal proposal of a tagged neutrino beam. The experiment will perform unique\nmeasurements with high energy neutrinos and will also provide a means to\nmeasure gluon parton distribution functions in a previously unexplored domain\n(Bjorkenx <10^-5). Furthermore, the technological advancements of the upgrade\nand the experience that will be gained in the areas of operation and data\nanalysis will play a crucial role in the design of the neutrino detector for\nthe SHiP experiment.","main_category":"hep-ex","categories":"hep-ex","published":"2025-03-31T15:45:38Z"}
{"aid":"http://arxiv.org/abs/2503.24243v1","title":"Music Information Retrieval on Representative Mexican Folk Vocal\n  Melodies Through MIDI Feature Extraction","summary":"This study analyzes representative Mexican folk vocal melodies using MIDI\nfeature extraction, examining ambitus, pitch-class entropy, and interval\ndistribution. It also explores the relationship between these features and song\npopularity, as measured by Spotify plays. The study employs MATLAB and the MIDI\nToolbox for extracting musical features and performing statistical analysis.\nThe findings reveal a significant variation in ambitus, with values ranging\nfrom 8 to 27 semitones, indicating a diverse compositional style and vocal\ndemand across the genre. The analysis of pitch-class entropy showcases a broad\nspectrum of melodic complexity, with Armando Manzanero's `Somos Novios'\ndisplaying the highest entropy, suggesting varied and complex melodic\nstructures, while traditional pieces like `La Bamba' exhibit lower entropy,\nindicating simpler, more repetitive patterns. The interval distribution\npredominantly features prime intervals (P1), major and minor seconds (M2, m2),\npointing to a compositional preference for close, contiguous intervals that\ncontribute to the melodies' accessibility and appeal. Statistical analysis do\nnot establish a significant correlation between the ambitus or entropy and the\nnumber of Spotify plays.","main_category":"cs.SD","categories":"cs.SD,cs.IR","published":"2025-03-31T15:57:28Z"}
{"aid":"http://arxiv.org/abs/2503.24253v1","title":"Deep Learning-Based Data Fusion of 6G Sensing and Inertial Information\n  for Target Positioning: Experimental Validation","summary":"The sixth-generation (6G) cellular technology will be deployed with a key\nfeature of Integrated Sensing and Communication (ISAC), allowing the cellular\nnetwork to map the environment through radar sensing on top of providing\ncommunication services. In this regard, the entire network can be considered as\na sensor with a broader Field of View (FoV) of the environment, assisting in\nboth the positioning of active and detection of passive targets. On the other\nhand, the non-3GPP sensors available on the target can provide additional\ninformation specific to the target that can be beneficially combined with ISAC\nsensing information to enhance the overall achievable positioning accuracy. In\nthis paper, we first study the performance of the ISAC system in terms of its\nachievable accuracy in positioning the mobile target in an indoor scenario.\nSecond, we study the performance gain achieved in the ISAC positioning accuracy\nafter fusing the information from the target's non-3GPP sensors. To this end,\nwe propose a novel data fusion solution based on the deep learning framework to\nfuse the information from ISAC and non-3GPP sensors.\n  We validate our proposed data fusion and positioning solution with a\nreal-world ISAC Proof-of-Concept (PoC) as the wireless infrastructure, an\nAutomated Guided Vehicle (AGV) as the target, and the Inertial Measurement Unit\n(IMU) sensor on the target as the non-3GPP sensor. The experimental results\nshow that our proposed solution achieves an average positioning error of\n$3~\\textrm{cm}$, outperforming the considered baselines.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T16:02:17Z"}
{"aid":"http://arxiv.org/abs/2503.24254v1","title":"PromoPlot: Covering open-access fees by filling wasted space in corner\n  plots","summary":"In an effort to reduce drain on grant funds and decrease unused space in\npublications, we have developed a Python package for inserting advertisements\ninto the space left empty by corner plots. This novel technique can allow\nauthors to reduce or eliminate publication charges for journals such as MNRAS\nand ApJ. In order to offset publication costs entirely, we recommend that\nauthors include anywhere from 200-700 corner plots per paper, with the exact\nnumber depending on the journal used. Finally, we discuss other opportunities\nto generate ad revenue through publications.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-03-31T16:02:37Z"}
{"aid":"http://arxiv.org/abs/2503.24256v1","title":"Ranked percolation model for the caking time of amorphous molecular\n  powders","summary":"When amorphous molecular powders are exposed to high humidity levels or\ntemperatures, the particle viscosity increases due to plasticization, promoting\nthe formation of sinter bridges between pairs of particles in contact. Over\ntime, these bridges facilitate particle agglomeration, eventually leading to\nthe formation of a macroscopic cake that alters the mechanical properties and\naffects product quality. In this work, we model the caking process of amorphous\npowders subjected to a temperature shock as a bond percolation problem and\ninvestigate how particle bed heterogeneities influence the percolation\nthreshold and, consequently, the expected caking times. Our findings indicate\nthat a slight dispersion in particle size lowers the percolation threshold\ncompared to a monodisperse bed or random percolation in polydisperse systems.\nFurthermore, we show that the expected caking time exhibits a non-monotonic\nbehavior with the size dispersion, initially decreasing for low dispersion\nvalues and increasing for higher values. These results provide insights into\nthe role of the particle size distribution on the caking dynamics of amorphous\nmolecular powders","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech","published":"2025-03-31T16:03:56Z"}
{"aid":"http://arxiv.org/abs/2503.24262v1","title":"New Statistical Framework for Extreme Error Probability in High-Stakes\n  Domains for Reliable Machine Learning","summary":"Machine learning is vital in high-stakes domains, yet conventional validation\nmethods rely on averaging metrics like mean squared error (MSE) or mean\nabsolute error (MAE), which fail to quantify extreme errors. Worst-case\nprediction failures can have substantial consequences, but current frameworks\nlack statistical foundations for assessing their probability. In this work a\nnew statistical framework, based on Extreme Value Theory (EVT), is presented\nthat provides a rigorous approach to estimating worst-case failures. Applying\nEVT to synthetic and real-world datasets, this method is shown to enable robust\nestimation of catastrophic failure probabilities, overcoming the fundamental\nlimitations of standard cross-validation. This work establishes EVT as a\nfundamental tool for assessing model reliability, ensuring safer AI deployment\nin new technologies where uncertainty quantification is central to\ndecision-making or scientific analysis.","main_category":"cs.LG","categories":"cs.LG,cs.AI,stat.ME,stat.ML","published":"2025-03-31T16:08:11Z"}
{"aid":"http://arxiv.org/abs/2503.24272v1","title":"Learning Velocity and Acceleration: Self-Supervised Motion Consistency\n  for Pedestrian Trajectory Prediction","summary":"Understanding human motion is crucial for accurate pedestrian trajectory\nprediction. Conventional methods typically rely on supervised learning, where\nground-truth labels are directly optimized against predicted trajectories. This\namplifies the limitations caused by long-tailed data distributions, making it\ndifficult for the model to capture abnormal behaviors. In this work, we propose\na self-supervised pedestrian trajectory prediction framework that explicitly\nmodels position, velocity, and acceleration. We leverage velocity and\nacceleration information to enhance position prediction through feature\ninjection and a self-supervised motion consistency mechanism. Our model\nhierarchically injects velocity features into the position stream. Acceleration\nfeatures are injected into the velocity stream. This enables the model to\npredict position, velocity, and acceleration jointly. From the predicted\nposition, we compute corresponding pseudo velocity and acceleration, allowing\nthe model to learn from data-generated pseudo labels and thus achieve\nself-supervised learning. We further design a motion consistency evaluation\nstrategy grounded in physical principles; it selects the most reasonable\npredicted motion trend by comparing it with historical dynamics and uses this\ntrend to guide and constrain trajectory generation. We conduct experiments on\nthe ETH-UCY and Stanford Drone datasets, demonstrating that our method achieves\nstate-of-the-art performance on both datasets.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-03-31T16:17:45Z"}
{"aid":"http://arxiv.org/abs/2503.24281v1","title":"Cylindrical boundary induced current in the cosmic string spacetime","summary":"In this paper we investigate the vacuum current associated with a charged\nbosonic field operator, induced by a cylindrical boundary in the idealized\ncosmic string spacetime. In this setup we assume that the cylindrical boundary\nis coaxial with the string, that by its turn carry a magnetic flux along its\ncore. In order to develop this analysis, we calculate the positive frequency\nWightman functions for both regions, inside and outside the boundary. Moreover,\nwe assume that the bosonic field obeys the Robin boundary condition on the\ncylindrical shell. Using this approach, the analytical expressions for the\nvacuum bosonic currents are presented in the form of the sum of boundary-free\nand boundary-induced parts. Because the boundary-free contribution is very well\nestablished in literature, our focus here is in the boundary-dependent part. As\nwe will see, our general results are presented in a cylindrically symmetric\nstatic structure. Some asymptotic behaviors for the boundary-induced vacuum\ncurrents are investigated in various limiting cases. In order to provide a\nbetter understanding of these currents, we provide some graphs exhibiting their\nbehavior as function of the distance to the string's core, and on the intensity\nof the magnetic flux running along it. These plots also present how the\nparameter associated with the planar angle deficit interfere in the intensity\nof the corresponding current.","main_category":"hep-th","categories":"hep-th","published":"2025-03-31T16:26:39Z"}
{"aid":"http://arxiv.org/abs/2503.24291v1","title":"Quark production in the bottom-up thermalization","summary":"We investigate the impact of quark production on bottom-up thermalization in\nheavy-ion collisions. First, we extend the parametric estimates of bottom-up\nthermalization in pure gluon systems by incorporating quark production in the\nweak-coupling (high-energy) limit. Our analysis reveals that quark production\ndoes not alter the qualitative features of the three-stage thermalization\nprocess in this limit. Furthermore, we obtain the scaling behavior of the quark\nnumber density over time at each stage. Then, by solving the Boltzmann equation\nin diffusion approximation (BEDA) for longitudinally boost-invariant systems,\nwe demonstrate how our detailed numerical simulations approach the predicted\nthree-stage thermalization picture as the strong coupling $\\alpha_s$ decreases.\nFinally, we carry out a detailed comparison of our BEDA results with those\nobtained by solving the QCD effective kinetic theory for intermediate values of\n$\\alpha_s$, observing remarkably good quantitative agreement between the two\napproaches.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-03-31T16:37:53Z"}
{"aid":"http://arxiv.org/abs/2503.24301v1","title":"QUADRO: A Hybrid Quantum Optimization Framework for Drone Delivery","summary":"Quantum computing holds transformative potential for optimizing large-scale\ndrone fleet operations, yet its near-term limitations necessitate hybrid\napproaches blending classical and quantum techniques. This work introduces\nQuantum Unmanned Aerial Delivery Routing Optimization (QUADRO), a novel hybrid\nframework addressing the Energy-Constrained Capacitated Unmanned Aerial Vehicle\nRouting Problem and the Unmanned Aerial Vehicle Scheduling Problem. By\nformulating these challenges as Quadratic Unconstrained Binary Optimization\nproblems, QUADRO leverages the Quantum Approximate Optimization Algorithm for\nrouting and scheduling, enhanced by classical heuristics and post-processing.\nWe minimize total transit time in routing, considering payload and battery\nconstraints, and optimize makespan scheduling across various drone fleets.\nEvaluated on adapted Augerat benchmarks (16-51 nodes), QUADRO competes against\nclassical and prior hybrid methods, achieving scalable solutions with fewer\nthan one hundred qubits. The proposed results underscore the viability of\nhybrid quantum-classical strategies for real-world drone logistics, paving the\nway for quantum-enhanced optimization in the Noisy Intermediate Scale Quantum\nera.","main_category":"cs.ET","categories":"cs.ET","published":"2025-03-31T16:44:42Z"}
{"aid":"http://arxiv.org/abs/2503.24311v1","title":"Selective Inference in Graphical Models via Maximum Likelihood","summary":"The graphical lasso is a widely used algorithm for fitting undirected\nGaussian graphical models. However, for inference on functionals of edge values\nin the learned graph, standard tools lack formal statistical guarantees, such\nas control of the type I error rate. In this paper, we introduce a selective\ninference method for asymptotically valid inference after graphical lasso\nselection with added randomization. We obtain a selective likelihood,\nconditional on the event of selection, through a change of variable on the\nknown density of the randomization variables. Our method enables interval\nestimation and hypothesis testing for a wide range of functionals of edge\nvalues in the learned graph using the conditional maximum likelihood estimate.\nOur numerical studies show that introducing a small amount of randomization:\n(i) greatly increases power and yields substantially shorter intervals compared\nto other conditional inference methods, including data splitting; (ii) ensures\nintervals of bounded length in high-dimensional settings where data splitting\nis infeasible due to insufficient samples for inference; (iii) enables\ninference for a wide range of inferential targets in the learned graph,\nincluding measures of node influence and connectivity between nodes.","main_category":"stat.ME","categories":"stat.ME,stat.AP,stat.CO","published":"2025-03-31T16:57:04Z"}
{"aid":"http://arxiv.org/abs/2503.24368v1","title":"Adapting Vision Foundation Models for Real-time Ultrasound Image\n  Segmentation","summary":"We propose a novel approach that adapts hierarchical vision foundation models\nfor real-time ultrasound image segmentation. Existing ultrasound segmentation\nmethods often struggle with adaptability to new tasks, relying on costly manual\nannotations, while real-time approaches generally fail to match\nstate-of-the-art performance. To overcome these limitations, we introduce an\nadaptive framework that leverages the vision foundation model Hiera to extract\nmulti-scale features, interleaved with DINOv2 representations to enhance visual\nexpressiveness. These enriched features are then decoded to produce precise and\nrobust segmentation. We conduct extensive evaluations on six public datasets\nand one in-house dataset, covering both cardiac and thyroid ultrasound\nsegmentation. Experiments show that our approach outperforms state-of-the-art\nmethods across multiple datasets and excels with limited supervision,\nsurpassing nnUNet by over 20\\% on average in the 1\\% and 10\\% data settings.\nOur method achieves $\\sim$77 FPS inference speed with TensorRT on a single GPU,\nenabling real-time clinical applications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T17:47:42Z"}
{"aid":"http://arxiv.org/abs/2503.24376v1","title":"Exploring the Effect of Reinforcement Learning on Video Understanding:\n  Insights from SEED-Bench-R1","summary":"Recent advancements in Chain of Thought (COT) generation have significantly\nimproved the reasoning capabilities of Large Language Models (LLMs), with\nreinforcement learning (RL) emerging as an effective post-training approach.\nMultimodal Large Language Models (MLLMs) inherit this reasoning potential but\nremain underexplored in tasks requiring both perception and logical reasoning.\nTo address this, we introduce SEED-Bench-R1, a benchmark designed to\nsystematically evaluate post-training methods for MLLMs in video understanding.\nIt includes intricate real-world videos and complex everyday planning tasks in\nthe format of multiple-choice questions, requiring sophisticated perception and\nreasoning. SEED-Bench-R1 assesses generalization through a three-level\nhierarchy: in-distribution, cross-environment, and cross-environment-task\nscenarios, equipped with a large-scale training dataset with easily verifiable\nground-truth answers. Using Qwen2-VL-Instruct-7B as a base model, we compare RL\nwith supervised fine-tuning (SFT), demonstrating RL's data efficiency and\nsuperior performance on both in-distribution and out-of-distribution tasks,\neven outperforming SFT on general video understanding benchmarks like\nLongVideoBench. Our detailed analysis reveals that RL enhances visual\nperception but often produces less logically coherent reasoning chains. We\nidentify key limitations such as inconsistent reasoning and overlooked visual\ncues, and suggest future improvements in base model reasoning, reward modeling,\nand RL robustness against noisy signals.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL,cs.LG","published":"2025-03-31T17:55:23Z"}
{"aid":"http://arxiv.org/abs/2504.01327v1","title":"Multi-wavelength properties of $z\\gtrsim 6$ LISA detectable events","summary":"We investigate the intrinsic and observational properties of $z\\gtrsim 6$\ngalaxies hosting coalescing massive black holes (MBHs) that gives rise to\ngravitational waves (GWs) detectable with the Laser Interferometer Space\nAntenna (LISA). We adopt a zoom-in cosmological hydrodynamical simulation of\ngalaxy formation and black hole (BH) co-evolution, zoomed-in on a $M_h \\sim\n10^{12}~\\rm M_{\\odot}$ dark matter halo at z = 6, which hosts a fast accreting\nsuper-massive black hole (SMBH) and a star-forming galaxy. Following the SMBH\nformation backward in time, we identify the merging events that concurred to\nits formation and we pick up the ones that are detectable with LISA. Among\nthese LISA detectable events (LDEs), we select those that, based on their\nintrinsic properties are expected to be bright in one or more electromagnetic\n(EM) bands. We post-process these events with dust radiative transfer\ncalculations to make predictions about their spectral energy distributions and\ncontinuum maps in the JWST to ALMA wavelength range. We compare the spectra\narising from galaxies hosting the merging MBHs with those arising from AGN\npowered by single accreting BHs. We find that it will be impossible to identify\nan LDE from the continuum SEDs because of the absence of specific imprints from\nthe merging MBHs. We also compute the profile of the H$_{\\rm \\alpha}$ line\narising from LDEs, considering the contribution from their star-forming regions\nand the accreting MBHs. We find that the presence of two accreting MBHs would\nbe difficult to infer even if both MBHs accrete at super-Eddington rates. We\nconclude that the combined detection of GW and EM signals from $z\\gtrsim 6$\nMBHs is challenging not only because of the poor sky-localization provided by\nLISA, but also because the loudest GW emitters are not massive enough to leave\nsignificant signatures in the emission lines arising from the broad line\nregion.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-02T03:24:35Z"}
{"aid":"http://arxiv.org/abs/2504.01375v1","title":"Simultaneous Pre-compensation for Bandwidth Limitation and Fiber\n  Dispersion in Cost-Sensitive IM/DD Transmission Systems","summary":"We propose a pre-compensation scheme for bandwidth limitation and fiber\ndispersion (pre-BL-EDC) based on the modified Gerchberg-Saxton (GS) algorithm.\nExperimental results demonstrate 1.0/1.0/2.0 dB gains compared to modified GS\npre-EDC for 20/28/32 Gbit/s bandwidth-limited systems.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-02T05:37:57Z"}
{"aid":"http://arxiv.org/abs/2504.01386v1","title":"DALIP: Distribution Alignment-based Language-Image Pre-Training for\n  Domain-Specific Data","summary":"Recently, Contrastive Language-Image Pre-training (CLIP) has shown promising\nperformance in domain-specific data (e.g., biology), and has attracted\nincreasing research attention. Existing works generally focus on collecting\nextensive domain-specific data and directly tuning the original CLIP models.\nIntuitively, such a paradigm takes no full consideration of the characteristics\nlying in domain-specific data (e.g., fine-grained nature of biological data)\nand so limits model capability, while mostly losing the original ability of\nCLIP in the general domain. In this paper, we propose a Distribution\nAlignment-based Language-Image Pre-Training (DALIP) method for biological data.\nSpecifically, DALIP optimizes CLIP models by matching the similarity between\nfeature distribution of image-text pairs instead of the original [cls] token,\nwhich can capture rich yet effective information inherent in image-text pairs\nas powerful representations, and so better cope with fine-grained nature of\nbiological data. Particularly, our DALIP efficiently approximates feature\ndistribution via its first- and second-order statistics, while presenting a\nMulti-head Brownian Distance Covariance (MBDC) module to acquire second-order\nstatistics of token features efficiently. Furthermore, we collect a new dataset\nfor plant domain (e.g., specific data in biological domain) comprising 10M\nplant data with 3M general-domain data (namely PlantMix-13M) according to data\nmixing laws. Extensive experiments show that DALIP clearly outperforms existing\nCLIP counterparts in biological domain, while well generalizing to remote\nsensing and medical imaging domains. Besides, our PlantMix-13M dataset further\nboosts performance of DALIP in plant domain, while preserving model ability in\ngeneral domain.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T05:56:57Z"}
{"aid":"http://arxiv.org/abs/2504.01387v1","title":"Derived McKay correspondence for real reflection groups of rank three","summary":"We describe the derived McKay correspondence for real reflection groups of\nrank $3$ in terms of a maximal resolution of the logarithmic pair consisting of\nthe quotient variety and the discriminant divisor with coefficient\n$\\frac{1}{2}$. As an application, we verify a conjecture by Polishchuk and Van\nden Bergh on the existence of a certain semiorthgonal decomposition of the\nequivariant derived category into the derived categories of affine spaces for\nany real reflection group of rank $3$.","main_category":"math.AG","categories":"math.AG","published":"2025-04-02T05:57:28Z"}
{"aid":"http://arxiv.org/abs/2504.01392v1","title":"Spatial-Filter-Bank-Based Neural Method for Multichannel Speech\n  Enhancement","summary":"The performance of deep learning-based multi-channel speech enhancement\nmethods often deteriorates when the geometric parameters of the microphone\narray change. Traditional approaches to mitigate this issue typically involve\ntraining on multiple microphone arrays, which can be costly. To address this\nchallenge, we focus on uniform circular arrays and propose the use of a spatial\nfilter bank to extract features that are approximately invariant to geometric\nparameters. These features are then processed by a two-stage conformer-based\nmodel (TSCBM) to enhance speech quality. Experimental results demonstrate that\nour proposed method can be trained on a fixed microphone array while\nmaintaining effective performance across uniform circular arrays with unseen\ngeometric configurations during applications.","main_category":"eess.AS","categories":"eess.AS","published":"2025-04-02T06:13:37Z"}
{"aid":"http://arxiv.org/abs/2504.01393v1","title":"Navigating the Uncharted Waters: A Gradual Approach to the Certification\n  and Integration of Maritime Autonomous Surface Ships (MASS) in Global\n  Maritime Operations","summary":"The integration of Maritime Autonomous Surface Ships (MASS) into global\nmaritime operations represents a transformative shift in the shipping industry,\npromising enhanced safety, efficiency, and cost-effectiveness. However, the\nwidespread adoption of autonomous ships necessitates a robust regulatory\nframework and rigorous certification processes to address the unique challenges\nposed by these advanced technologies. This paper proposes a gradual,\nmulti-stage approach to the certification and integration of MASS, beginning\nwith small-scale trials in controlled environments and progressing to\nlarge-scale international operations. Key considerations include the\ndevelopment of reliable control systems, cybersecurity measures, sensor\ntechnologies, and redundancy mechanisms to ensure safe and efficient\nnavigation. Additionally, the paper explores the economic and environmental\nimplications of autonomous shipping, as well as the evolving legal frameworks\nfor liability and compensation in the event of collisions. By adopting a\ncautious and methodical approach, the maritime industry can mitigate risks and\npave the way for the safe and sustainable integration of autonomous ships into\nglobal trade.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-02T06:19:21Z"}
{"aid":"http://arxiv.org/abs/2504.01396v1","title":"All Patches Matter, More Patches Better: Enhance AI-Generated Image\n  Detection via Panoptic Patch Learning","summary":"The exponential growth of AI-generated images (AIGIs) underscores the urgent\nneed for robust and generalizable detection methods. In this paper, we\nestablish two key principles for AIGI detection through systematic analysis:\n\\textbf{(1) All Patches Matter:} Unlike conventional image classification where\ndiscriminative features concentrate on object-centric regions, each patch in\nAIGIs inherently contains synthetic artifacts due to the uniform generation\nprocess, suggesting that every patch serves as an important artifact source for\ndetection. \\textbf{(2) More Patches Better}: Leveraging distributed artifacts\nacross more patches improves detection robustness by capturing complementary\nforensic evidence and reducing over-reliance on specific patches, thereby\nenhancing robustness and generalization. However, our counterfactual analysis\nreveals an undesirable phenomenon: naively trained detectors often exhibit a\n\\textbf{Few-Patch Bias}, discriminating between real and synthetic images based\non minority patches. We identify \\textbf{Lazy Learner} as the root cause:\ndetectors preferentially learn conspicuous artifacts in limited patches while\nneglecting broader artifact distributions. To address this bias, we propose the\n\\textbf{P}anoptic \\textbf{P}atch \\textbf{L}earning (PPL) framework, involving:\n(1) Random Patch Replacement that randomly substitutes synthetic patches with\nreal counterparts to compel models to identify artifacts in underutilized\nregions, encouraging the broader use of more patches; (2) Patch-wise\nContrastive Learning that enforces consistent discriminative capability across\nall patches, ensuring uniform utilization of all patches. Extensive experiments\nacross two different settings on several benchmarks verify the effectiveness of\nour approach.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T06:32:09Z"}
{"aid":"http://arxiv.org/abs/2504.01429v1","title":"Refining Interactions: Enhancing Anisotropy in Graph Neural Networks\n  with Language Semantics","summary":"The integration of Large Language Models (LLMs) with Graph Neural Networks\n(GNNs) has recently been explored to enhance the capabilities of Text Attribute\nGraphs (TAGs). Most existing methods feed textual descriptions of the graph\nstructure or neighbouring nodes' text directly into LLMs. However, these\napproaches often cause LLMs to treat structural information simply as general\ncontextual text, thus limiting their effectiveness in graph-related tasks. In\nthis paper, we introduce LanSAGNN (Language Semantic Anisotropic Graph Neural\nNetwork), a framework that extends the concept of anisotropic GNNs to the\nnatural language level. This model leverages LLMs to extract tailor-made\nsemantic information for node pairs, effectively capturing the unique\ninteractions within node relationships. In addition, we propose an efficient\ndual-layer LLMs finetuning architecture to better align LLMs' outputs with\ngraph tasks. Experimental results demonstrate that LanSAGNN significantly\nenhances existing LLM-based methods without increasing complexity while also\nexhibiting strong robustness against interference.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-02T07:32:45Z"}
{"aid":"http://arxiv.org/abs/2504.01438v1","title":"Precise Determination of Electric Quadrupole Moments and Isotope Shift\n  Constants of Yb$^+$ in Pursuance of Probing Fundamental Physics and Nuclear\n  Radii","summary":"Contemplating to register signature of a new vector boson unambiguously from\nthe measured non-linear isotope shift (IS) effects in three recent experiments\n[Phys. Rev. X {\\bf 12}, 021033 (2022); Phys. Rev. Lett. {\\bf 128}, 163201\n(2022) and Phys. Rev. Lett. {\\bf 134}, 063002 (2025)], very precise values of\nquadrupole moments and IS constants for the $6s ~ ^2S_{1/2} \\rightarrow 5d ~\n^2D_{3/2}$ and $6s ~ ^2S_{1/2} \\rightarrow 5d ~ ^2D_{5/2}$ clock transitions of\n$^{171}$Yb$^+$ are presented. This is accomplished by incorporating\ncontributions from the computationally challenging triply excited\nconfigurations through the relativistic coupled-cluster (RCC) theory. Testament\nof quality atomic wave functions of states of the above transitions, obtained\nusing the RCC theory, are gauged by comparing the calculated energies and\nmagnetic dipole hyperfine structure constants with their measurements. The\nimproved quadrupole moments from this work will be immensely useful to estimate\nquadrupole shifts of the clock transitions of Yb$^+$. Complementary approaches\nare employed to ascertain accuracy and comprehend roles of orbital relaxation\nand correlation effects in evaluating the IS constants. Combining these\nconstants with the IS measurements from Phys. Rev. Lett. {\\bf 128}, 163201\n(2022), differential nuclear charge radii of the Yb isotopes are inferred that\ndeviate by 6-7\\% from the literature data.","main_category":"physics.atom-ph","categories":"physics.atom-ph,nucl-th,physics.comp-ph","published":"2025-04-02T07:48:10Z"}
{"aid":"http://arxiv.org/abs/2504.01450v1","title":"CASCADE Your Datasets for Cross-Mode Knowledge Retrieval of Language\n  Models","summary":"Language models often struggle with cross-mode knowledge retrieval -- the\nability to access knowledge learned in one format (mode) when queried in\nanother. We demonstrate that models trained on multiple data sources (e.g.,\nWikipedia and TinyStories) exhibit significantly reduced accuracy when\nretrieving knowledge in a format different from its original training mode.\nThis paper quantitatively investigates this phenomenon through a controlled\nstudy of random token sequence memorization across different modes. We first\nexplore dataset rewriting as a solution, revealing that effective cross-mode\nretrieval requires prohibitively extensive rewriting efforts that follow a\nsigmoid-like relationship. As an alternative, we propose CASCADE, a novel\npretraining algorithm that uses cascading datasets with varying sequence\nlengths to capture knowledge at different scales. Our experiments demonstrate\nthat CASCADE outperforms dataset rewriting approaches, even when compressed\ninto a single model with a unified loss function. This work provides both\nqualitative evidence of cross-mode retrieval limitations and a practical\nsolution to enhance language models' ability to access knowledge independently\nof its presentational format.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-02T08:02:07Z"}
{"aid":"http://arxiv.org/abs/2504.01459v1","title":"Probabilistic Curriculum Learning for Goal-Based Reinforcement Learning","summary":"Reinforcement learning (RL) -- algorithms that teach artificial agents to\ninteract with environments by maximising reward signals -- has achieved\nsignificant success in recent years. These successes have been facilitated by\nadvances in algorithms (e.g., deep Q-learning, deep deterministic policy\ngradients, proximal policy optimisation, trust region policy optimisation, and\nsoft actor-critic) and specialised computational resources such as GPUs and\nTPUs. One promising research direction involves introducing goals to allow\nmultimodal policies, commonly through hierarchical or curriculum reinforcement\nlearning. These methods systematically decompose complex behaviours into\nsimpler sub-tasks, analogous to how humans progressively learn skills (e.g. we\nlearn to run before we walk, or we learn arithmetic before calculus). However,\nfully automating goal creation remains an open challenge. We present a novel\nprobabilistic curriculum learning algorithm to suggest goals for reinforcement\nlearning agents in continuous control and navigation tasks.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-02T08:15:16Z"}
{"aid":"http://arxiv.org/abs/2504.01464v1","title":"A Prefixed Patch Time Series Transformer for Two-Point Boundary Value\n  Problems in Three-Body Problems","summary":"Two-point boundary value problems for cislunar trajectories present\nsignificant challenges in circler restricted three body problem, making\ntraditional analytical methods like Lambert's problem inapplicable. This study\nproposes a novel approach using a prefixed patch time series Transformer model\nthat automates the solution of two-point boundary value problems from lunar\nflyby to arbitrary terminal conditions. Using prefix tokens of terminal\nconditions in our deep generative model enables solving boundary value problems\nin three-body dynamics. The training dataset consists of trajectories obtained\nthrough forward propagation rather than solving boundary value problems\ndirectly. The model demonstrates potential practical utility for preliminary\ntrajectory design in cislunar mission scenarios.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T08:22:03Z"}
{"aid":"http://arxiv.org/abs/2504.01491v1","title":"How to Define the Quality of Data? A Feature-Based Literature Survey","summary":"The digital transformation of our society is a constant challenge, as data is\ngenerated in almost every digital interaction. To use data effectively, it must\nbe of high quality. This raises the question: what exactly is data quality? A\nsystematic literature review of the existing literature shows that data quality\nis a multifaceted concept, characterized by a number of quality dimensions.\nHowever, the definitions of data quality vary widely. We used feature-oriented\ndomain analysis to specify a taxonomy of data quality definitions and to\nclassify the existing definitions. This allows us to identify research gaps and\nfuture topics.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-02T08:46:19Z"}
{"aid":"http://arxiv.org/abs/2504.01500v1","title":"The Polynomial Set Associated with a Fixed Number of Matrix-Matrix\n  Multiplications","summary":"We consider the problem of computing matrix polynomials $p(X)$, where $X$ is\na large matrix, with as few matrix-matrix multiplications as possible. More\nprecisely, let $ \\Pi_{2^{m}}^* $ represent the set of polynomials computable\nwith $m$ matrix-matrix multiplications, but with an arbitrary number of matrix\nadditions and scaling operations. We characterize this set through a tabular\nparameterization. By deriving equivalence transformations of the tabular\nrepresentation, we establish new methods that can be used to construct elements\nof $ \\Pi_{2^{m}}^* $ and determine general properties of the set. The\ntransformations allow us to eliminate variables and prove that the dimension is\nbounded by $m^2$. Numerical simulations suggest that this is a sharp bound.\nConsequently, we have identified a parameterization, which, to our knowledge,\nis the first minimal parameterization. Furthermore, we conduct a study using\ncomputational tools from algebraic geometry to determine the largest degree $d$\nsuch that all polynomials of that degree belong to $ \\Pi_{2^{m}}^* $, or its\nclosure. In many cases, the computational setup is constructive in the sense\nthat it can also be used to determine a specific evaluation scheme for a given\npolynomial.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-02T08:51:58Z"}
{"aid":"http://arxiv.org/abs/2504.01509v1","title":"PROPHET: An Inferable Future Forecasting Benchmark with Causal\n  Intervened Likelihood Estimation","summary":"Predicting future events stands as one of the ultimate aspirations of\nartificial intelligence. Recent advances in large language model (LLM)-based\nsystems have shown remarkable potential in forecasting future events, thereby\ngarnering significant interest in the research community. Currently, several\nbenchmarks have been established to evaluate the forecasting capabilities by\nformalizing the event prediction as a retrieval-augmented generation (RAG) and\nreasoning task. In these benchmarks, each prediction question is answered with\nrelevant retrieved news articles. However, because there is no consideration on\nwhether the questions can be supported by valid or sufficient supporting\nrationales, some of the questions in these benchmarks may be inherently\nnoninferable. To address this issue, we introduce a new benchmark, PROPHET,\nwhich comprises inferable forecasting questions paired with relevant news for\nretrieval. To ensure the inferability of the benchmark, we propose Causal\nIntervened Likelihood (CIL), a statistical measure that assesses inferability\nthrough causal inference. In constructing this benchmark, we first collected\nrecent trend forecasting questions and then filtered the data using CIL,\nresulting in an inferable benchmark for event prediction. Through extensive\nexperiments, we first demonstrate the validity of CIL and in-depth\ninvestigations into event prediction with the aid of CIL. Subsequently, we\nevaluate several representative prediction systems on PROPHET, drawing valuable\ninsights for future directions.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T08:57:42Z"}
{"aid":"http://arxiv.org/abs/2504.01524v1","title":"On the limitations for causal inference in Cox models with time-varying\n  treatment","summary":"When using the Cox model to analyze the effect of a time-varying treatment on\na survival outcome, treatment is commonly included, using only the current\nlevel as a time-dependent covariate. Such a model does not necessarily assume\nthat past treatment is not associated with the outcome (the Markov property),\nsince it is possible to model the hazard conditional on only the current\ntreatment value. However, modeling the hazard conditional on the full treatment\nhistory is required in order to interpret the results causally, and such a full\nmodel assumes the Markov property when only including current treatment. This\nis, for example, common in marginal structural Cox models. We demonstrate that\nrelying on the Markov property is problematic, since it only holds in\nunrealistic settings or if the treatment has no causal effect. This is the case\neven if there are no confounders and the true causal effect of treatment really\nonly depends on its current level. Further, we provide an example of a scenario\nwhere the Markov property is not fulfilled, but the Cox model that includes\nonly current treatment as a covariate is correctly specified. Transforming the\nresult to the survival scale does not give the true intervention-specific\nsurvival probabilities, showcasing that it is unclear how to make causal\nstatements from such models.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-02T09:10:48Z"}
{"aid":"http://arxiv.org/abs/2504.01528v1","title":"Analytical and Numerical Linear Analyses of Convection Revisited","summary":"We conduct linear analyses of convection in domains larger than the\ntemperature scale height. We employ both analytical and numerical methods in\nthese analyses. In the case excluding all dissipation, the typical time scale\nof convection is determined by the free fall time over the temperature scale\nheight. We quantitatively show the condition for the Boussinesq and\nWentzel-Kramers-Brillouin (WKB) approximations to be applicable. We provide a\nreassessment of the critical Rayleigh number, a key indicator of convection,\nand show that WKB approximation tends to underestimate the critical Rayleigh\nnumber, particularly when the temperature scale height is comparable to or\nsmaller than the domain height. We show clear explanation why both thermal\nconduction and viscosity are required for stabilizing negative entropy gradient\nmedium.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-02T09:13:31Z"}
{"aid":"http://arxiv.org/abs/2504.01530v1","title":"Predicting passenger injury distributions under uncertainty variables\n  using Gaussian process modeling with GHBMC","summary":"This work presents a Gaussian Process (GP) modeling method to predict\nstatistical characteristics of injury kinematics responses using Human Body\nModels (HBM) more accurately and efficiently. We validate the GHBMC model\nagainst a 50\\%tile male Post-Mortem Human Surrogate (PMHS) test. Using this\nvalidated model, we create various postured models and generate injury\nprediction data across different postures and personalized D-ring heights\nthrough parametric crash simulations. We then train the GP using this\nsimulation data, implementing a novel adaptive sampling approach to improve\naccuracy. The trained GP model demonstrates robustness by achieving target\nprediction accuracy at points with high uncertainty. The proposed method\nperforms continuous injury prediction for various crash scenarios using just 27\ncomputationally expensive simulation runs. This method can be effectively\napplied to designing highly reliable occupant restraint systems across diverse\ncrash conditions.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-02T09:17:39Z"}
{"aid":"http://arxiv.org/abs/2504.01540v1","title":"From Smør-re-brød to Subwords: Training LLMs on Danish, One\n  Morpheme at a Time","summary":"The best performing transformer-based language models use subword\ntokenization techniques, such as Byte-Pair-Encoding (BPE). However, these\napproaches often overlook linguistic principles, such as morphological\nsegmentation, which we believe is fundamental for understanding\nlanguage-specific word structure. In this study, we leverage an annotated\nDanish morphological dataset to train a semisupervised model for morphological\nsegmentation, enabling the development of tokenizers optimized for Danish\nmorphology. We evaluate four distinct tokenizers, including two custom\nmorphological tokenizers, by analyzing their performance in morphologically\nsegmenting Danish words. Additionally, we train two generative transformer\nmodels, \\textit{CerebrasGPT-111M} and \\textit{LLaMA-3.2 1B}, using these\ntokenizers and evaluate their downstream performance. Our findings reveal that\nour custom-developed tokenizers substantially enhance morphological\nsegmentation, achieving an F1 score of 58.84, compared to 39.28 achieved by a\nDanish BPE tokenizer. In downstream tasks, models trained with our\nmorphological tokenizers outperform those using BPE tokenizers across different\nevaluation metrics. These results highlight that incorporating Danish\nmorphological segmentation strategies into tokenizers leads to improved\nperformance in generative transformer models on Danish language","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T09:26:02Z"}
{"aid":"http://arxiv.org/abs/2504.01543v1","title":"Local Computation Algorithms for Knapsack: impossibility results, and\n  how to avoid them","summary":"Local Computation Algorithms (LCA), as introduced by Rubinfeld, Tamir, Vardi,\nand Xie (2011), are a type of ultra-efficient algorithms which, given access to\na (large) input for a given computational task, are required to provide fast\nquery access to a consistent output solution, without maintaining a state\nbetween queries. This paradigm of computation in particular allows for hugely\ndistributed algorithms, where independent instances of a given LCA provide\nconsistent access to a common output solution.\n  The past decade has seen a significant amount of work on LCAs, by and large\nfocusing on graph problems. In this paper, we initiate the study of Local\nComputation Algorithms for perhaps the archetypal combinatorial optimization\nproblem, Knapsack. We first establish strong impossibility results, ruling out\nthe existence of any non-trivial LCA for Knapsack as several of its\nrelaxations. We then show how equipping the LCA with additional access to the\nKnapsack instance, namely, weighted item sampling, allows one to circumvent\nthese impossibility results, and obtain sublinear-time and query LCAs. Our\npositive result draws on a connection to the recent notion of reproducibility\nfor learning algorithms (Impagliazzo, Lei, Pitassi, and Sorrell, 2022), a\nconnection we believe to be of independent interest for the design of LCAs.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-02T09:32:18Z"}
{"aid":"http://arxiv.org/abs/2504.01552v1","title":"Identity-Based Language Shift Modeling","summary":"The preservation of endangered languages is a widely discussed issue\nnowadays. Languages represent essential cultural heritage and can provide\nvaluable botanical, biological, and geographical information. Therefore, it is\nnecessary to develop efficient measures to preserve and revitalize endangered\nlanguages. However, the language shift process is complex and requires an\ninterdisciplinary approach, including mathematical modeling techniques. This\npaper develops a new mathematical model that extends previous works on this\ntopic. We introduce the factor of ethnic identity, which is a proxy for a more\ncomplex nexus of variables involved in an individual's self-identity and/or a\ngroup's identity. This proxy is socially constructed rather than solely\ninherited, shaped by community-determined factors, with language both indexing\nand creating the identity. In our model, we divide speakers into groups\ndepending on with which language they identify themselves with. Moreover, every\ngroup includes monolinguals and bilinguals. The proposed model naturally allows\nus to consider cases of language coexistence and describe a broader class of\nlinguistic situations. For example, the simulation results show that our model\ncan result in cyclic language dynamics, drawing a parallel to cell population\nmodels. In this way, the proposed mathematical model can serve as a useful tool\nfor developing efficient measures for language preservation and revitalization.","main_category":"physics.soc-ph","categories":"physics.soc-ph,cs.NA,math.NA","published":"2025-04-02T09:48:29Z"}
{"aid":"http://arxiv.org/abs/2504.01554v1","title":"8-DoFs Cable Driven Parallel Robots for Bimanual Teleportation","summary":"Teleoperation plays a critical role in intuitive robot control and imitation\nlearning, particularly for complex tasks involving mobile manipulators with\nredundant degrees of freedom (DoFs). However, most existing master controllers\nare limited to 6-DoF spatial control and basic gripper control, making them\ninsufficient for controlling high-DoF robots and restricting the operator to a\nsmall workspace. In this work, we present a novel, low-cost, high-DoF master\ncontroller based on Cable-Driven Parallel Robots (CDPRs), designed to overcome\nthese limitations. The system decouples translation and orientation control,\nfollowing a scalable 3 + 3 + n DoF structure: 3 DoFs for large-range\ntranslation using a CDPR, 3 DoFs for orientation using a gimbal mechanism, and\nn additional DoFs for gripper and redundant joint control. Its lightweight\ncable-driven design enables a large and adaptable workspace while minimizing\nactuator load. The end-effector remains stable without requiring continuous\nhigh-torque input, unlike most serial robot arms. We developed the first\ndual-arm CDPR-based master controller using cost-effective actuators and a\nsimple mechanical structure. In demonstrations, the system successfully\ncontrolled an 8-DoF robotic arm with a 2-DoF pan-tilt camera, performing tasks\nsuch as pick-and-place, knot tying, object sorting, and tape application. The\nresults show precise, versatile, and practical high-DoF teleoperation.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-02T09:54:16Z"}
{"aid":"http://arxiv.org/abs/2504.01557v1","title":"FastER: Fast On-Demand Entity Resolution in Property Graphs","summary":"Entity resolution (ER) is the problem of identifying and linking database\nrecords that refer to the same real-world entity. Traditional ER methods use\nbatch processing, which becomes impractical with growing data volumes due to\nhigh computational costs and lack of real-time capabilities. In many\napplications, users need to resolve entities for only a small portion of their\ndata, making full data processing unnecessary -- a scenario known as\n\"ER-on-demand\". This paper proposes FastER, an efficient ER-on-demand framework\nfor property graphs. Our approach uses graph differential dependencies (GDDs)\nas a knowledge encoding language to design effective filtering mechanisms that\nleverage both structural and attribute semantics of graphs. We construct a\nblocking graph from filtered subgraphs to reduce the number of candidate entity\npairs requiring comparison. Additionally, FastER incorporates Progressive\nProfile Scheduling (PPS), allowing the system to incrementally produce results\nthroughout the resolution process. Extensive evaluations on multiple benchmark\ndatasets demonstrate that FastER significantly outperforms state-of-the-art ER\nmethods in computational efficiency and real-time processing for on-demand\ntasks while ensuring reliability. We make FastER publicly available at:\nhttps://anonymous.4open.science/r/On_Demand_Entity_Resolution-9DFB","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-02T09:58:38Z"}
{"aid":"http://arxiv.org/abs/2504.01580v1","title":"The Basins Zoo","summary":"Research in multistable systems is a flourishing field with countless\nexamples and applications across scientific disciplines. I present a catalog of\nmultistable dynamical systems covering relevant fields of knowledge. This work\nis focused on providing a research tool to the community in the form classified\nexamples and computer code to reproduce basins of attraction. The companion\ncode to this article can be found at https://github.com/awage/BasinsCollection\nor https://doi.org/10.5281/zenodo.15124200.","main_category":"nlin.CD","categories":"nlin.CD","published":"2025-04-02T10:35:41Z"}
{"aid":"http://arxiv.org/abs/2504.01596v1","title":"DEPTHOR: Depth Enhancement from a Practical Light-Weight dToF Sensor and\n  RGB Image","summary":"Depth enhancement, which uses RGB images as guidance to convert raw signals\nfrom dToF into high-precision, dense depth maps, is a critical task in computer\nvision. Although existing super-resolution-based methods show promising results\non public datasets, they often rely on idealized assumptions like accurate\nregion correspondences and reliable dToF inputs, overlooking calibration errors\nthat cause misalignment and anomaly signals inherent to dToF imaging, limiting\nreal-world applicability. To address these challenges, we propose a novel\ncompletion-based method, named DEPTHOR, featuring advances in both the training\nstrategy and model architecture. First, we propose a method to simulate\nreal-world dToF data from the accurate ground truth in synthetic datasets to\nenable noise-robust training. Second, we design a novel network that\nincorporates monocular depth estimation (MDE), leveraging global depth\nrelationships and contextual information to improve prediction in challenging\nregions. On the ZJU-L5 dataset, our training strategy significantly enhances\ndepth completion models, achieving results comparable to depth super-resolution\nmethods, while our model achieves state-of-the-art results, improving Rel and\nRMSE by 27% and 18%, respectively. On a more challenging set of dToF samples we\ncollected, our method outperforms SOTA methods on preliminary stereo-based GT,\nimproving Rel and RMSE by 23% and 22%, respectively. Our Code is available at\nhttps://github.com/ShadowBbBb/Depthor","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T11:02:21Z"}
{"aid":"http://arxiv.org/abs/2504.01613v1","title":"The Mini-SiTian Array: Design and application of Master Control System","summary":"The SiTian Project represents a groundbreaking initiative in astronomy,\naiming to deploy a global network of telescopes, each with a 1-meter aperture,\nfor comprehensive time-domain sky surveys. The network's innovative\narchitecture features multiple observational nodes, each comprising three\nstrategically aligned telescopes equipped with filters. This design enables\nthree-color (g, r, i) channel imaging within each node, facilitating precise\nand coordinated observations. As a pathfinder to the full-scale project, the\nMini-SiTian Project serves as the scientific and technological validation\nplatform, utilizing three 30-centimeter aperture telescopes to validate the\nmethodologies and technologies planned for the broader SiTian network. This\npaper focuses on the development and implementation of the Master Control\nSystem (MCS),and the central command hub for the Mini-SiTian array. The MCS is\ndesigned to facilitate seamless communication with the SiTian Brain, the\nproject's central processing and decision-making unit, while ensuring accurate\ntask allocation, real-time status monitoring, and optimized observational\nworkflows. The system adopts a robust architecture that separates front-end and\nback-end functionalities.A key innovation of the MCS is its ability to\ndynamically adjust observation plans in response to transient source alerts,\nenabling rapid and coordinated scans of target sky regions...(abridged)","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-02T11:26:11Z"}
{"aid":"http://arxiv.org/abs/2504.01616v1","title":"The Mini-SiTian Array: Imaging Processing Pipeline","summary":"As a pathfinder of the SiTian project, the Mini-SiTian (MST) array, employed\nthree commercial CMOS cameras, represents a next-generation, cost-effective\noptical time-domain survey project. This paper focuses primarily on the precise\ndata processing pipeline designed for wide-field, CMOS-based devices, including\nthe removal of instrumental effects, astrometry, photometry, and flux\ncalibration. When applying this pipeline to approximately 3000 observations\ntaken in the Field 02 (f02) region by MST, the results demonstrate a remarkable\nastrometric precision of approximately 70--80\\,mas (about 0.1\\,pixel), an\nimpressive calibration accuracy of approximately 1\\,mmag in the MST zero\npoints, and a photometric accuracy of about 4\\,mmag for bright stars. Our\nstudies demonstrate that MST CMOS can achieve photometric accuracy comparable\nto that of CCDs, highlighting the feasibility of large-scale CMOS-based optical\ntime-domain surveys and their potential applications for cost optimization in\nfuture large-scale time-domain surveys, like the SiTian project.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.GA,astro-ph.SR","published":"2025-04-02T11:26:30Z"}
{"aid":"http://arxiv.org/abs/2504.01618v1","title":"The Mini-SiTian Array: Optical design","summary":"Time-domain astronomy is one of the most important areas. Large sky area,\ndeep-field, and short timescale are the priority of time-domain observations.\nSiTian is an ambitious ground-based project processing all sky optical\nmonitoring, aiming for sky-survey timescale of less than 1 day. It is developed\nby the Chinese Academy of Sciences, an integrated network of dozens of\n1-m-class telescopes deployed worldwide. The Mini-SiTian Telescope Array is\ncarried out for demonstrations on optical design, group scheduling, and\nsoftware pipeline developments, to overcome the high technical and financial\ndifficulties of SiTian project. One array contains three 300 mm F/3 telescope,\nwith FOV of 5 degrees over 400-1000 nm wavelength range. The Mini-SiTian\nTelescope Array is now under commissioning in Xinglong Observatory, and a\nperfect platform for technical research and educational purposes.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-02T11:26:36Z"}
{"aid":"http://arxiv.org/abs/2504.01640v1","title":"Controlling photo-excited electron-spin by light-polarization in\n  ultrafast-pumped altermagnets","summary":"Altermagnets (AMs) constitute a novel class of spin-compensated materials in\nwhich the symmetry connecting opposite-spin sublattices involves a spatial\nrotation. Here, we uncover a set of unique non-linear, light-driven properties\nthat set AMs apart from traditional ferro- and antiferromagnets. We demonstrate\ntheoretically that the polarization of an electromagnetic pulse that\nphoto-excites electrons and holes in an AM, controls the spin orientation of\nthese non-equilibrium charge carriers. For a d-wave AM model and a prototype\nmaterial, we show that very large post-pump spin polarizations may be attained\nby exploiting resonances. We show that this protocol also allows, in an AM, to\ndirectly probe the spin splitting of the electronic states in energy and\nmomentum space. Thus, it can be used to identify and characterize altermagnetic\nmaterials via ultrafast pump-probe Kerr/Faraday spectroscopy or spin- and\ntime-resolved ARPES. This opens up the possibility of devising ultrafast\noptical switches of non-equilibrium spin-polarization, finely tunable by\nadjusting the pump-pulse characteristics.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T11:43:45Z"}
{"aid":"http://arxiv.org/abs/2504.01665v1","title":"On products of sets of natural density one","summary":"In a previous work, Bettin, Koukoulopoulos, and Sanna prove that if two sets\nof natural numbers $A$ and $B$ have natural density $1$, then their product set\n$A \\cdot B := \\{ab : a \\in A, b \\in B\\}$ also has natural density $1$. They\nalso provide an effective rate and pose the question of determining the optimal\nrate. We make progress on this question by constructing a set $A$ of density 1\nsuch that $A\\cdot A$ has a ''large'' complement.","main_category":"math.NT","categories":"math.NT","published":"2025-04-02T12:15:22Z"}
{"aid":"http://arxiv.org/abs/2504.01703v1","title":"Computable Bounds on the Solution to Poisson's Equation for General\n  Harris Chains","summary":"Poisson's equation is fundamental to the study of Markov chains, and arises\nin connection with martingale representations and central limit theorems for\nadditive functionals, perturbation theory for stationary distributions, and\naverage reward Markov decision process problems. In this paper, we develop a\nnew probabilistic representation for the solution of Poisson's equation, and\nuse Lyapunov functions to bound this solution representation explicitly. In\ncontrast to most prior work on this problem, our bounds are computable. Our\ncontribution is closely connected to recent work of Herve and Ledoux (2025), in\nwhich they focus their study on a special class of Harris chains satisfying a\nparticular small set condition. However, our theory covers general Harris\nchains, and often provides a tighter bound. In addition to the new bound and\nrepresentation, we also develop a computable uniform bound on marginal\nexpectations for Harris chains, and a computable bound on the potential kernel\nrepresentation of the solution to Poisson's equation.","main_category":"math.PR","categories":"math.PR","published":"2025-04-02T13:06:09Z"}
{"aid":"http://arxiv.org/abs/2504.01712v1","title":"Method for Mitigating Attention to Inappropriate Content Based on\n  Attention Dynamics Model","summary":"The expansion of the attention economy has led to the growing issue of\ninappropriate content being posted by profit-driven users. Previous\ncountermeasures against inappropriate content have relied on moderation, which\nraises ethical concerns, or information diffusion control, which requires\nconsidering larger scale networks, including general users. This study proposes\nan imitation strategy as an intervention method that does not rely on\nmoderation and focuses on a relatively smaller scale competitive network of\ninformation disseminators rather than the entire social network. The imitation\nstrategy is a novel approach that utilizes increased competition among\ninformation disseminators through imitation to reduce attention to\ninappropriate content. Through theoretical analysis and numerical simulations,\nI demonstrate that the imitation strategy is more effective when nodes with\nhigher eigenvector centrality are selected as targets and nodes with lower\neigenvector centrality are chosen as imitators.","main_category":"cs.SI","categories":"cs.SI","published":"2025-04-02T13:20:25Z"}
{"aid":"http://arxiv.org/abs/2504.01716v1","title":"Studies of Hadronic Showers in SND@LHC","summary":"The SND@LHC experiment was built for observing neutrinos arising from LHC pp\ncollisions. The detector consists of two sections: a target instrumented with\nSciFi modules and a hadronic calorimeter/muon detector. Energetic $\\nu$N\ncollisions in the target produce hadronic showers. Reconstruction of the shower\ntotal energy requires an estimate of the fractions deposited in both the target\nand the calorimeter. In order to calibrate the SND@LHC response, a replica of\nthe detector was exposed to hadron beams with 100 to 300 GeV in the CERN SPS H8\ntest beam line in Summer 2023. This report describes the methods developed to\ntag the presence of a shower, to locate the shower origin in the target, and to\ncombine the target SciFi and the calorimeter signals so to measure the shower\ntotal energy.","main_category":"physics.ins-det","categories":"physics.ins-det,hep-ex","published":"2025-04-02T13:25:54Z"}
{"aid":"http://arxiv.org/abs/2504.01723v1","title":"Analytical Framework of Orbital Angular Momentum Beam in Misaligned\n  Detection","summary":"This work provides an analytical framework to model the detected orbital\nangular momentum (OAM) spectrum of an optical beam in the presence of tilt and\nlateral displacement in the impinging beam. We show how both tilt and\ndisplacement cause OAM sidebands following the same function, with both having\ntheir characteristic adimensional parameter related to the size and wavelength\nof the beam. We see how an increase in topological charge on the beam causes\nwider detected OAM distribution. Finally, we show how, in the case of both tilt\nand lateral displacement, we can tune the amount of OAM mode in the original\nmode by having a perpendicular direction for the tilt and off-axis\ndisplacement, causing the misalignment errors to interfere destructively.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-02T13:28:32Z"}
{"aid":"http://arxiv.org/abs/2504.01725v1","title":"Brillouin-enhanced four-wave mixing with optical chiral states","summary":"Brillouin-enhanced four-wave mixing - also known as Brillouin dynamic\ngratings - is an important nonlinear effect in photonics that couples four\nlight waves by travelling acoustic waves. The effect has received a lot of\nattention in the last few decades, especially for applications in fiber\nsensing, signal processing and optical delay lines. Here, we report\nBrillouin-enhanced four-wave mixing with optical chiral states (i.e. circular\npolarization and vortex states) in twisted photonic crystal fiber, by\nleveraging the topology-selective Brillouin effect. Phase-matching has the\nconsequence that the travelling acoustic gratings created by\ncircularly-polarized vortex pump and Stokes in the stimulated Brillouin\nscattering can be used to modulate a frequency-shifted probe, where the\npump/Stokes and probe have different circular polarization or topological\ncharges. We demonstrate cross-frequency selective information transfer and show\nthat the information is transferred only when pump and probe have opposite\ncircular polarization.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-02T13:31:57Z"}
{"aid":"http://arxiv.org/abs/2504.01727v1","title":"Acoustic Propagation/Refraction Through Diffuse Interface Models","summary":"We present a novel approach for simulating acoustic (pressure) wave\npropagation across different media separated by a diffuse interface through the\nuse of a weak compressibility formulation. Our method builds on our previous\nwork on an entropy-stable discontinuous Galerkin spectral element method for\nthe incompressible Navier-Stokes/Cahn-Hilliard system\n\\cite{manzanero2020entropyNSCH}, and incorporates a modified weak\ncompressibility formulation that allows different sound speeds in each phase.\nWe validate our method through numerical experiments, demonstrating spectral\nconvergence for acoustic transmission and reflection coefficients in one\ndimension and for the angle defined by Snell's law in two dimensions. Special\nattention is given to quantifying the modeling errors introduced by the width\nof the diffuse interface. Our results show that the method successfully\ncaptures the behavior of acoustic waves across interfaces, allowing exponential\nconvergence in transmitted waves. The transmitted angles in two dimensions are\naccurately captured for air-water conditions, up to the critical angle of\n$13^\\circ$. This work represents a step forward in modeling acoustic\npropagation in incompressible multiphase systems, with potential applications\nto marine aeroacoustics.","main_category":"math.NA","categories":"math.NA,cs.NA,physics.comp-ph,physics.flu-dyn","published":"2025-04-02T13:33:55Z"}
{"aid":"http://arxiv.org/abs/2504.01739v1","title":"Understanding Cross-Model Perceptual Invariances Through Ensemble\n  Metamers","summary":"Understanding the perceptual invariances of artificial neural networks is\nessential for improving explainability and aligning models with human vision.\nMetamers - stimuli that are physically distinct yet produce identical neural\nactivations - serve as a valuable tool for investigating these invariances. We\nintroduce a novel approach to metamer generation by leveraging ensembles of\nartificial neural networks, capturing shared representational subspaces across\ndiverse architectures, including convolutional neural networks and vision\ntransformers. To characterize the properties of the generated metamers, we\nemploy a suite of image-based metrics that assess factors such as semantic\nfidelity and naturalness. Our findings show that convolutional neural networks\ngenerate more recognizable and human-like metamers, while vision transformers\nproduce realistic but less transferable metamers, highlighting the impact of\narchitectural biases on representational invariances.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T13:51:19Z"}
{"aid":"http://arxiv.org/abs/2504.01771v1","title":"Enhancing Interpretability in Generative AI Through Search-Based Data\n  Influence Analysis","summary":"Generative AI models offer powerful capabilities but often lack transparency,\nmaking it difficult to interpret their output. This is critical in cases\ninvolving artistic or copyrighted content. This work introduces a\nsearch-inspired approach to improve the interpretability of these models by\nanalysing the influence of training data on their outputs. Our method provides\nobservational interpretability by focusing on a model's output rather than on\nits internal state. We consider both raw data and latent-space embeddings when\nsearching for the influence of data items in generated content. We evaluate our\nmethod by retraining models locally and by demonstrating the method's ability\nto uncover influential subsets in the training data. This work lays the\ngroundwork for future extensions, including user-based evaluations with domain\nexperts, which is expected to improve observational interpretability further.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-02T14:29:37Z"}
{"aid":"http://arxiv.org/abs/2504.01810v1","title":"Parametrized scissors congruence $K$-theory of manifolds and cobordism\n  categories","summary":"We construct a parametrized version of scissors congruence $K$-theory of\nmanifolds, which in particular gives a topologized version of the scissors\ncongruence $K$-theory of oriented manifolds, and we describe this spectrum as\nmediating between the cobordism category and usual algebraic $K$-theory of\nspaces. We show that on $\\pi_0$, the scissors congruence $K$-theory of oriented\nmanifolds agrees with a version of the cobordism category where we allow free\nboundaries.","main_category":"math.AT","categories":"math.AT,math.KT","published":"2025-04-02T15:16:00Z"}
{"aid":"http://arxiv.org/abs/2504.01880v1","title":"Partition function zeros of quantum many-body systems","summary":"We present a method for calculating the Yang-Lee partition function zeros of\na translationally invariant model of lattice fermions, exemplified by the\nHubbard model. The method rests on a theorem involving the single electron\nself-energy $\\Sigma_\\sigma(k, i \\omega_n)$ in the imaginary time Matsubara\nformulation. The theorem maps the Yang-Lee zeros to a set of wavevector and\nspin labeled virtual energies $\\xi_{k \\sigma}$. These, thermodynamically\nderived virtual energies, are solutions of equations involving the self-energy\nat corresponding $k\\sigma$'s. Examples of the method in simplified situations\nare provided.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.str-el","published":"2025-04-02T16:39:15Z"}
{"aid":"http://arxiv.org/abs/2504.01891v1","title":"Multi-stream Physics Hybrid Networks for solving Navier-Stokes equations","summary":"Understanding and solving fluid dynamics equations efficiently remains a\nfundamental challenge in computational physics. Traditional numerical solvers\nand physics-informed neural networks struggle to capture the full range of\nfrequency components in partial differential equation solutions, limiting their\naccuracy and efficiency. Here, we propose the Multi-stream Physics Hybrid\nNetwork, a novel neural architecture that integrates quantum and classical\nlayers in parallel to improve the accuracy of solving fluid dynamics equations,\nnamely Kovasznay flow problem. This approach decomposes the solution into\nseparate frequency components, each predicted by independent Parallel Hybrid\nNetworks, simplifying the training process and enhancing performance. We\nevaluated the proposed model against a comparable classical neural network, the\nMulti-stream Physics Classical Network, in both data-driven and physics-driven\nscenarios. Our results show that the Multi-stream Physics Hybrid Network\nachieves a reduction in root mean square error by 36% for velocity components\nand 41% for pressure prediction compared to the classical model, while using\n24% fewer trainable parameters. These findings highlight the potential of\nhybrid quantum-classical architectures for advancing computational fluid\ndynamics.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,physics.comp-ph,quant-ph","published":"2025-04-02T16:50:54Z"}
{"aid":"http://arxiv.org/abs/2504.01903v1","title":"STAR-1: Safer Alignment of Reasoning LLMs with 1K Data","summary":"This paper introduces STAR-1, a high-quality, just-1k-scale safety dataset\nspecifically designed for large reasoning models (LRMs) like DeepSeek-R1. Built\non three core principles -- diversity, deliberative reasoning, and rigorous\nfiltering -- STAR-1 aims to address the critical needs for safety alignment in\nLRMs. Specifically, we begin by integrating existing open-source safety\ndatasets from diverse sources. Then, we curate safety policies to generate\npolicy-grounded deliberative reasoning samples. Lastly, we apply a GPT-4o-based\nsafety scoring system to select training examples aligned with best practices.\nExperimental results show that fine-tuning LRMs with STAR-1 leads to an average\n40% improvement in safety performance across four benchmarks, while only\nincurring a marginal decrease (e.g., an average of 1.1%) in reasoning ability\nmeasured across five reasoning tasks. Extensive ablation studies further\nvalidate the importance of our design principles in constructing STAR-1 and\nanalyze its efficacy across both LRMs and traditional LLMs. Our project page is\nhttps://ucsc-vlaa.github.io/STAR-1.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-02T17:04:04Z"}
{"aid":"http://arxiv.org/abs/2504.01908v1","title":"Benchmarking Synthetic Tabular Data: A Multi-Dimensional Evaluation\n  Framework","summary":"Evaluating the quality of synthetic data remains a key challenge for ensuring\nprivacy and utility in data-driven research. In this work, we present an\nevaluation framework that quantifies how well synthetic data replicates\noriginal distributional properties while ensuring privacy. The proposed\napproach employs a holdout-based benchmarking strategy that facilitates\nquantitative assessment through low- and high-dimensional distribution\ncomparisons, embedding-based similarity measures, and nearest-neighbor distance\nmetrics. The framework supports various data types and structures, including\nsequential and contextual information, and enables interpretable quality\ndiagnostics through a set of standardized metrics. These contributions aim to\nsupport reproducibility and methodological consistency in benchmarking of\nsynthetic data generation techniques. The code of the framework is available at\nhttps://github.com/mostly-ai/mostlyai-qa.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-02T17:10:30Z"}
{"aid":"http://arxiv.org/abs/2504.01928v1","title":"Is the Reversal Curse a Binding Problem? Uncovering Limitations of\n  Transformers from a Basic Generalization Failure","summary":"Despite their impressive capabilities, LLMs exhibit a basic generalization\nfailure known as the Reversal Curse, where they struggle to learn reversible\nfactual associations. Understanding why this occurs could help identify\nweaknesses in current models and advance their generalization and robustness.\nIn this paper, we conjecture that the Reversal Curse in LLMs is a manifestation\nof the long-standing binding problem in cognitive science, neuroscience and AI.\nSpecifically, we identify two primary causes of the Reversal Curse stemming\nfrom transformers' limitations in conceptual binding: the inconsistency and\nentanglements of concept representations. We perform a series of experiments\nthat support these conjectures. Our exploration leads to a model design based\non JEPA (Joint-Embedding Predictive Architecture) that for the first time\nbreaks the Reversal Curse without side-stepping it with specialized data\naugmentation or non-causal masking, and moreover, generalization could be\nfurther improved by incorporating special memory layers that support\ndisentangled concept representations. We demonstrate that the skill of reversal\nunlocks a new kind of memory integration that enables models to solve\nlarge-scale arithmetic reasoning problems via parametric forward-chaining,\noutperforming frontier LLMs based on non-parametric memory and prolonged\nexplicit reasoning.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-02T17:38:03Z"}
{"aid":"http://arxiv.org/abs/2504.01934v1","title":"ILLUME+: Illuminating Unified MLLM with Dual Visual Tokenization and\n  Diffusion Refinement","summary":"We present ILLUME+ that leverages dual visual tokenization and a diffusion\ndecoder to improve both deep semantic understanding and high-fidelity image\ngeneration. Existing unified models have struggled to simultaneously handle the\nthree fundamental capabilities in a unified model: understanding, generation,\nand editing. Models like Chameleon and EMU3 utilize VQGAN for image\ndiscretization, due to the lack of deep semantic interaction, they lag behind\nspecialist models like LLaVA in visual understanding tasks. To mitigate this,\nLaViT and ILLUME employ semantic encoders for tokenization, but they struggle\nwith image editing due to poor texture preservation. Meanwhile, Janus series\ndecouples the input and output image representation, limiting their abilities\nto seamlessly handle interleaved image-text understanding and generation. In\ncontrast, ILLUME+ introduces a unified dual visual tokenizer, DualViTok, which\npreserves both fine-grained textures and text-aligned semantics while enabling\na coarse-to-fine image representation strategy for multimodal understanding and\ngeneration. Additionally, we employ a diffusion model as the image detokenizer\nfor enhanced generation quality and efficient super-resolution. ILLUME+ follows\na continuous-input, discrete-output scheme within the unified MLLM and adopts a\nprogressive training procedure that supports dynamic resolution across the\nvision tokenizer, MLLM, and diffusion decoder. This design allows for flexible\nand efficient context-aware image editing and generation across diverse tasks.\nILLUME+ (3B) exhibits competitive performance against existing unified MLLMs\nand specialized models across multimodal understanding, generation, and editing\nbenchmarks. With its strong performance, ILLUME+ provides a scalable and\nversatile foundation for future multimodal applications. Project Page:\nhttps://illume-unified-mllm.github.io/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T17:45:00Z"}
{"aid":"http://arxiv.org/abs/2504.01939v1","title":"Laboratory evaluation of a wearable instrumented headband for rotational\n  head kinematics measurement","summary":"Mild traumatic brain injuries (mTBI) are a highly prevalent condition with\nheterogeneous outcomes between individuals. A key factor governing brain tissue\ndeformation and the risk of mTBI is the rotational kinematics of the head.\nInstrumented mouthguards are a widely accepted method for measuring rotational\nhead motions, owing to their robust sensor-skull coupling. However, wearing\nmouthguards is not feasible in all situations, especially for long-term data\ncollection. Therefore, alternative wearable devices are needed. In this study,\nwe present an improved design and data processing scheme for an instrumented\nheadband. Our instrumented headband utilizes an array of inertial measurement\nunits (IMUs) and a new data-processing scheme based on continuous wavelet\ntransforms to address sources of error in the IMU measurements. The headband\nperformance was evaluated in the laboratory on an anthropomorphic test device,\nwhich was impacted with a soccer ball to replicate soccer heading. When\ncomparing the measured peak rotational velocities (PRV) and peak rotational\naccelerations (PRA) between the reference sensors and the headband for impacts\nto the front of the head, the correlation coefficients (r) were 0.80 and 0.63,\nand the normalized root mean square error (NRMSE) values were 0.20 and 0.28,\nrespectively. However, when considering all impact locations, r dropped to 0.42\nand 0.34 and NRMSE increased to 0.5 and 0.41 for PRV and PRA, respectively.\nThis new instrumented headband improves upon previous headband designs in\nreconstructing the rotational head kinematics resulting from frontal soccer\nball impacts, providing a potential alternative to instrumented mouthguards.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-02T17:47:07Z"}
{"aid":"http://arxiv.org/abs/2504.01950v1","title":"Nucleon scattering from lattice QCD","summary":"Recent results from lattice QCD on baryon resonances and meson-baryon,\nbaryon-baryon scattering are presented. Such scattering processes and\nresonances can be determined in lattice QCD by first obtaining the\nfinite-volume energy spectrum of stationary states involving meson-baryon and\nbaryon-baryon systems. A well-known quantization condition involving the\nscattering $K$-matrix and a complicated ``box matrix'' also yields a\nfinite-volume energy spectrum. By appropriately parametrizing the scattering\n$K$-matrix, the best fit values of the $K$-matrix parameters are those which\nproduce a finite-volume spectrum which best matches that obtained from lattice\nQCD. The $\\Delta$ resonance, a recent study of the two-pole nature of\nscattering near the $\\Lambda(1405)$, and $NN$ scattering in the $SU(3)$ flavor\nlimit are highlighted.","main_category":"hep-lat","categories":"hep-lat","published":"2025-04-02T17:55:19Z"}
{"aid":"http://arxiv.org/abs/2504.02212v1","title":"Decidabilities of local unitary equivalence for entanglement witnesses\n  and states","summary":"The problem of determining whether two states are equivalent by local unitary\n(LU) operations is important for quantum information processing. In this paper\nwe propose an alternative perspective to study this problem by comparing the\ndecidabilities of LU equivalence (also known as LU decidabilities for short)\nbetween entanglement witnesses and states. We introduce a relation between sets\nof Hermitian operators in terms of the LU decidability. Then we compare the LU\ndecidability for the set of entanglement witness to those decidabilities for\nseveral sets of states, and establish a hierarchy on LU decidabilities for\nthese sets. Moreover, we realize that the simultaneous LU (SLU) equivalence\nbetween tuples of mutually orthogonal projectors is crucial to LU equivalent\noperators. We reveal by examples that for two tuples of projectors, the partial\nSLU equivalence cannot ensure the overall SLU equivalence. Generally, we\npresent a necessary and sufficient condition such that two tuples of states are\nSLU equivalent.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-03T02:05:53Z"}
{"aid":"http://arxiv.org/abs/2504.02223v1","title":"Motivic homotopy theory with ramification filtrations","summary":"The aim of this paper is to connect two important and apparently unrelated\ntheories: motivic homotopy theory and ramification theory. We construct motivic\nhomotopy categories over a qcqs base scheme $S$, in which cohomology theories\nwith ramification filtrations are representable. Every such cohomology theory\nenjoys basic properties such as the Nisnevich descent, the cube-invariance, the\nblow-up invariance, the smooth blow-up excision, the Gysin sequence, the\nprojective bundle formula and the Thom isomorphism. In case $S$ is the spectrum\nof a perfect field, the cohomology of every reciprocity sheaf is upgraded to a\ncohomology theory with a ramification filtration represented in our categories.\nWe also address relations of our theory with other non-$\\mathbb{A}^1$-invariant\nmotivic homotopy theories such as the logarithmic motivic homotopy theory of\nBinda, Park, and {\\O}stv{\\ae}r and the theory of motivic spectra of\nAnnala-Iwasa.","main_category":"math.AG","categories":"math.AG,math.KT","published":"2025-04-03T02:37:57Z"}
{"aid":"http://arxiv.org/abs/2504.02237v1","title":"Super diffusive length dependent thermal conductivity in one-dimensional\n  materials with structural defects: longitudinal to transverse phonon\n  scattering leads to $κ\\propto L^{1/3}$ law","summary":"Structural defects in one-dimensional heat conductors couple longitudinal\n(stretching) and transverse (bending) vibrations. This coupling results in the\nscattering of longitudinal phonons to transverse phonons and backwards. We show\nthat the decay rate of longitudinal phonons due to this scattering scales with\ntheir frequencies as $\\omega^{3/2}$ within the long wavelength limit ($\\omega\n\\rightarrow 0$), which is more efficient scattering compared to the\ntraditionally considered Rayleigh scattering within the longitudinal band\n($\\omega^2$). This scattering results in temperature independent thermal\nconductivity depending on the size as $\\kappa \\propto L^{1/3}$ for sufficiently\nlong materials. This predicted length dependence is observed in nanowires,\nthough the temperature dependence is seen there possibly because of deviations\nfrom pure one-dimensional behavior. The significant effect of interaction of\nlongitudinal phonons with transverse phonons is consistent with the earlier\nobservations of a substantial suppression of thermal energy transport by kinks,\nobviously leading to such interaction, though anharmonic interaction can also\nbe significant.","main_category":"physics.chem-ph","categories":"physics.chem-ph,cond-mat.dis-nn","published":"2025-04-03T03:08:54Z"}
{"aid":"http://arxiv.org/abs/2504.02246v1","title":"C*: Unifying Programming and Verification in C","summary":"Ensuring the correct functionality of systems software, given its\nsafety-critical and low-level nature, is a primary focus in formal verification\nresearch and applications. Despite advances in verification tooling,\nconventional programmers are rarely involved in the verification of their own\ncode, resulting in higher development and maintenance costs for verified\nsoftware. A key barrier to programmer participation in verification practices\nis the disconnect of environments and paradigms between programming and\nverification practices, which limits accessibility and real-time verification.\n  We introduce C*, a proof-integrated language design for C programming. C*\nextends C with verification capabilities, powered by a symbolic execution\nengine and an LCF-style proof kernel. It enables real-time verification by\nallowing programmers to embed proof-code blocks alongside implementation code,\nfacilitating interactive updates to the current proof state. Its expressive and\nextensible proof support allows users to build reusable libraries of logical\ndefinitions, theorems, and programmable proof automation. Crucially, C* unifies\nimplementation and proof code development by using C as the common language.\n  We implemented a prototype of C* and evaluated it on a representative\nbenchmark of small C programs and a challenging real-world case study: the\nattach function of pKVM's buddy allocator. Our results demonstrate that C*\nsupports the verification of a broad subset of C programming idioms and\neffectively handles complex reasoning tasks in real-world scenarios.","main_category":"cs.PL","categories":"cs.PL,cs.SE","published":"2025-04-03T03:22:22Z"}
{"aid":"http://arxiv.org/abs/2504.02252v1","title":"Adapting World Models with Latent-State Dynamics Residuals","summary":"Simulation-to-reality reinforcement learning (RL) faces the critical\nchallenge of reconciling discrepancies between simulated and real-world\ndynamics, which can severely degrade agent performance. A promising approach\ninvolves learning corrections to simulator forward dynamics represented as a\nresidual error function, however this operation is impractical with\nhigh-dimensional states such as images. To overcome this, we propose ReDRAW, a\nlatent-state autoregressive world model pretrained in simulation and calibrated\nto target environments through residual corrections of latent-state dynamics\nrather than of explicit observed states. Using this adapted world model, ReDRAW\nenables RL agents to be optimized with imagined rollouts under corrected\ndynamics and then deployed in the real world. In multiple vision-based MuJoCo\ndomains and a physical robot visual lane-following task, ReDRAW effectively\nmodels changes to dynamics and avoids overfitting in low data regimes where\ntraditional transfer methods fail.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.RO","published":"2025-04-03T03:41:30Z"}
{"aid":"http://arxiv.org/abs/2504.02263v1","title":"MegaScale-Infer: Serving Mixture-of-Experts at Scale with Disaggregated\n  Expert Parallelism","summary":"Mixture-of-Experts (MoE) showcases tremendous potential to scale large\nlanguage models (LLMs) with enhanced performance and reduced computational\ncomplexity. However, its sparsely activated architecture shifts feed-forward\nnetworks (FFNs) from being compute-intensive to memory-intensive during\ninference, leading to substantially lower GPU utilization and increased\noperational costs. We present MegaScale-Infer, an efficient and cost-effective\nsystem for serving large-scale MoE models. MegaScale-Infer disaggregates\nattention and FFN modules within each model layer, enabling independent\nscaling, tailored parallelism strategies, and heterogeneous deployment for both\nmodules. To fully exploit disaggregation in the presence of MoE's sparsity,\nMegaScale-Infer introduces ping-pong pipeline parallelism, which partitions a\nrequest batch into micro-batches and shuttles them between attention and FFNs\nfor inference. Combined with distinct model parallelism for each module,\nMegaScale-Infer effectively hides communication overhead and maximizes GPU\nutilization. To adapt to disaggregated attention and FFN modules and minimize\ndata transmission overhead (e.g., token dispatch), MegaScale-Infer provides a\nhigh-performance M2N communication library that eliminates unnecessary\nGPU-to-CPU data copies, group initialization overhead, and GPU synchronization.\nExperimental results indicate that MegaScale-Infer achieves up to 1.90x higher\nper-GPU throughput than state-of-the-art solutions.","main_category":"cs.DC","categories":"cs.DC,cs.LG","published":"2025-04-03T04:20:44Z"}
{"aid":"http://arxiv.org/abs/2504.02286v1","title":"Moment Quantization for Video Temporal Grounding","summary":"Video temporal grounding is a critical video understanding task, which aims\nto localize moments relevant to a language description. The challenge of this\ntask lies in distinguishing relevant and irrelevant moments. Previous methods\nfocused on learning continuous features exhibit weak differentiation between\nforeground and background features. In this paper, we propose a novel\nMoment-Quantization based Video Temporal Grounding method (MQVTG), which\nquantizes the input video into various discrete vectors to enhance the\ndiscrimination between relevant and irrelevant moments. Specifically, MQVTG\nmaintains a learnable moment codebook, where each video moment matches a\ncodeword. Considering the visual diversity, i.e., various visual expressions\nfor the same moment, MQVTG treats moment-codeword matching as a clustering\nprocess without using discrete vectors, avoiding the loss of useful information\nfrom direct hard quantization. Additionally, we employ effective\nprior-initialization and joint-projection strategies to enhance the maintained\nmoment codebook. With its simple implementation, the proposed method can be\nintegrated into existing temporal grounding models as a plug-and-play\ncomponent. Extensive experiments on six popular benchmarks demonstrate the\neffectiveness and generalizability of MQVTG, significantly outperforming\nstate-of-the-art methods. Further qualitative analysis shows that our method\neffectively groups relevant features and separates irrelevant ones, aligning\nwith our goal of enhancing discrimination.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T05:21:14Z"}
{"aid":"http://arxiv.org/abs/2504.02295v1","title":"Dynamical Mordell-Lang problem for automorphisms of surfaces in positive\n  characteristic","summary":"We solve the dynamical Mordell-Lang problem in positive characteristic for\nautomorphisms of projective surfaces.","main_category":"math.DS","categories":"math.DS,math.AG,math.NT","published":"2025-04-03T05:57:49Z"}
{"aid":"http://arxiv.org/abs/2504.02301v1","title":"Synchronization in bus systems with partially overlapping routes","summary":"In an increasingly interconnected world, understanding congestion-related\nphenomena in transportation and their underlying mechanisms is crucial for\nimproving efficiency. As the transportation system becomes denser, different\nmodes of transportation have more opportunities to interact with each other,\ngiving rise to emergent dynamics that simple models cannot explain. In this\nstudy, we investigate the synchronized motion of indirectly coupled\ntransportation modes. We develop a numerical simulation model on a\none-dimensional periodic lattice, where each point represents a bus station. In\nthis system, two types of buses operate: multiple local buses with\nnon-overlapping routes, each serving a specific zone, and a single global bus\nthat partially overlaps with the routes of the local buses. We perform\nnumerical simulations to examine how close the arrival times of these buses are\nto each other -- that is, how synchronized their motions are. When the number\nof zones is two, three, or five, robust synchronization occurs not only between\nthe global bus and the local buses, but also among the local buses themselves.\nIn contrast, no synchronization is found for other numbers of zones. We\ndeveloped a mathematical model using self-consistent equations and found that\ntwo distinct arrival patterns at the terminals must be considered. A stability\nanalysis reveals which pattern is ultimately realized in the simulations. Our\nresults show that transportation modes can exhibit coherent motion even when\nsharing only partial or no direct route overlaps. This outcome highlights that\nemergent behavior depends not only on local interactions but is also strongly\nshaped by the system's overall structural configuration.","main_category":"physics.soc-ph","categories":"physics.soc-ph,nlin.AO","published":"2025-04-03T06:18:22Z"}
{"aid":"http://arxiv.org/abs/2504.02309v1","title":"A sharp upper bound for the number of connected sets in any grid graph","summary":"A connected set in a graph is a subset of vertices whose induced subgraph is\nconnected. Although counting the number of connected sets in a graph is\ngenerally a \\#P-complete problem, it remains an active area of research. In\n2020, Vince posed the problem of finding a formula for the number of connected\nsets in the $(n\\times n)$-grid graph. In this paper, we establish a sharp upper\nbound for the number of connected sets in any grid graph by using multistep\nrecurrence formulas, which further derives enumeration formulas for the numbers\nof connected sets in $(3\\times n)$- and $(4\\times n)$-grid graphs, thus solving\na special case of the general problem posed by Vince. In the process, we also\ndetermine the number of connected sets of $K_{m}\\times P_{n}$ by employing the\ntransfer matrix method, where $K_{m}\\times P_{n}$ is the Cartesian product of\nthe complete graph of order $m$ and the path of order $n$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-03T06:35:35Z"}
{"aid":"http://arxiv.org/abs/2504.02310v1","title":"Improving Harmful Text Detection with Joint Retrieval and External\n  Knowledge","summary":"Harmful text detection has become a crucial task in the development and\ndeployment of large language models, especially as AI-generated content\ncontinues to expand across digital platforms. This study proposes a joint\nretrieval framework that integrates pre-trained language models with knowledge\ngraphs to improve the accuracy and robustness of harmful text detection.\nExperimental results demonstrate that the joint retrieval approach\nsignificantly outperforms single-model baselines, particularly in low-resource\ntraining scenarios and multilingual environments. The proposed method\neffectively captures nuanced harmful content by leveraging external contextual\ninformation, addressing the limitations of traditional detection models. Future\nresearch should focus on optimizing computational efficiency, enhancing model\ninterpretability, and expanding multimodal detection capabilities to better\ntackle evolving harmful content patterns. This work contributes to the\nadvancement of AI safety, ensuring more trustworthy and reliable content\nmoderation systems.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T06:37:55Z"}
{"aid":"http://arxiv.org/abs/2504.02324v1","title":"Dynamic Assortment Selection and Pricing with Censored Preference\n  Feedback","summary":"In this study, we investigate the problem of dynamic multi-product selection\nand pricing by introducing a novel framework based on a \\textit{censored\nmultinomial logit} (C-MNL) choice model. In this model, sellers present a set\nof products with prices, and buyers filter out products priced above their\nvaluation, purchasing at most one product from the remaining options based on\ntheir preferences. The goal is to maximize seller revenue by dynamically\nadjusting product offerings and prices, while learning both product valuations\nand buyer preferences through purchase feedback. To achieve this, we propose a\nLower Confidence Bound (LCB) pricing strategy. By combining this pricing\nstrategy with either an Upper Confidence Bound (UCB) or Thompson Sampling (TS)\nproduct selection approach, our algorithms achieve regret bounds of\n$\\tilde{O}(d^{\\frac{3}{2}}\\sqrt{T/\\kappa})$ and\n$\\tilde{O}(d^{2}\\sqrt{T/\\kappa})$, respectively. Finally, we validate the\nperformance of our methods through simulations, demonstrating their\neffectiveness.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-03T06:56:08Z"}
{"aid":"http://arxiv.org/abs/2504.02348v1","title":"Rigorous results for timelike Liouville field theory","summary":"Liouville field theory has long been a cornerstone of two-dimensional quantum\nfield theory and quantum gravity, which has attracted much recent attention in\nthe mathematics literature. Timelike Liouville field theory is a version of\nLiouville field theory where the kinetic term in the action appears with a\nnegative sign, which makes it closer to a theory of quantum gravity than\nordinary (spacelike) Liouville field theory. Making sense of this \"wrong sign\"\nrequires a theory of Gaussian random variables with negative variance. Such a\ntheory is developed in this paper, and is used to prove the timelike DOZZ\nformula for the $3$-point correlation function when the parameters satisfy the\nso-called \"charge neutrality condition\". Expressions are derived also for the\n$k$-point correlation functions for all $k\\ge 3$, and it is shown that these\nfunctions approach the correct semiclassical limits as the coupling constant is\nsent to zero.","main_category":"math.PR","categories":"math.PR,hep-th,math-ph,math.MP","published":"2025-04-03T07:33:00Z"}
{"aid":"http://arxiv.org/abs/2504.02355v1","title":"Optical and magnetic response by design in GaAs quantum dots","summary":"Quantum networking technologies use spin qubits and their interface to single\nphotons as core components of a network node. This necessitates the ability to\nco-design the magnetic- and optical-dipole response of a quantum system. These\nproperties are notoriously difficult to design in many solid-state systems,\nwhere spin-orbit coupling and the crystalline environment for each qubit create\ninhomogeneity of electronic g-factors and optically active states. Here, we\nshow that GaAs quantum dots (QDs) obtained via the quasi-strain-free local\ndroplet etching epitaxy growth method provide spin and optical properties\npredictable from assuming the highest possible QD symmetry. Our measurements of\nelectron and hole g-tensors and of transition dipole moment orientations for\ncharged excitons agree with our predictions from a multiband k.p simulation\nconstrained only by a single atomic-force-microscopy reconstruction of QD\nmorphology. This agreement is verified across multiple wavelength-specific\ngrowth runs at different facilities within the range of 730 nm to 790 nm for\nthe exciton emission. Remarkably, our measurements and simulations track the\nin-plane electron g-factors through a zero-crossing from -0.1 to 0.3 and linear\noptical dipole moment orientations fully determined by an external magnetic\nfield. The robustness of our results demonstrates the capability to design -\nprior to growth - the properties of a spin qubit and its tunable optical\ninterface best adapted to a target magnetic and photonic environment with\ndirect application for high-quality spin-photon entanglement.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall","published":"2025-04-03T07:43:01Z"}
{"aid":"http://arxiv.org/abs/2504.02379v1","title":"The Spear and the Ring: Emergent Structures in Magnetic Colloidal\n  Suspensions","summary":"We study from a mathematical point of view the nanoparticle model of a\nmagnetic colloid, presented by G. Klughertz. Our objective is to obtain\nproperties of stable stationary structures that arise in the long-time limit\nfor the magnetic nanoparticles dynamics following this model. In this article,\nwe present a detailed study of two specific structures using techniques from\nthe calculus of variations. The first, called the spear, consists of a chain of\naligned particles interacting via a Lennard-Jones potential. We establish\nexistence and uniqueness results, derive bounds on the distances between\nneighboring particles, and provide a sharp asymptotic description as the number\nof particles tends to infinity. The second structure, the ring, features\nparticles uniformly distributed along a circle. We prove its existence and\nuniqueness and derive an explicit formula for its radius.","main_category":"math-ph","categories":"math-ph,math.MP,math.OC","published":"2025-04-03T08:16:38Z"}
{"aid":"http://arxiv.org/abs/2504.02383v1","title":"Reinforcement Learning for Solving the Pricing Problem in Column\n  Generation: Applications to Vehicle Routing","summary":"In this paper, we address the problem of Column Generation (CG) using\nReinforcement Learning (RL). Specifically, we use a RL model based on the\nattention-mechanism architecture to find the columns with most negative reduced\ncost in the Pricing Problem (PP). Unlike previous Machine Learning (ML)\napplications for CG, our model deploys an end-to-end mechanism as it\nindependently solves the pricing problem without the help of any heuristic. We\nconsider a variant of Vehicle Routing Problem (VRP) as a case study for our\nmethod. Through a set of experiments where our method is compared against a\nDynamic Programming (DP)-based heuristic for solving the PP, we show that our\nmethod solves the linear relaxation up to a reasonable objective gap within 9%\nin significantly shorter running times, up to over 300 times faster for\ninstances with 100 customers.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T08:22:19Z"}
{"aid":"http://arxiv.org/abs/2504.02389v1","title":"Response of magnetic particle to rotating magnetic field in viscoelastic\n  fluid","summary":"The rotational dynamics of a freely suspended ferromagnetic particle in\nviscoelastic fluid subjected to a rotating magnetic field is studied by\nexperiments and theory. Our result reveals that when the characteristic\nrelaxation time of the fluid is much smaller than the inverse critical field\nfrequency, the particle's rotation behavior aligns with that in Newtonian\nfluids. Increasing the relaxation time enhances the time-averaged rotation\nfrequency of the particle that undergo asynchronous rotation. Moreover, the\ncritical frequency is shown to scale linearly with the magnetic field intensity\nand inversely with the fluid's zero-shear viscosity. Our work is expected to\nguide precise manipulation of ferromagnetic particles in biomedical systems\nwhere viscoelastic environments dominate.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.flu-dyn","published":"2025-04-03T08:31:09Z"}
{"aid":"http://arxiv.org/abs/2504.02395v1","title":"The quasi-semantic competence of LLMs: a case study on the part-whole\n  relation","summary":"Understanding the extent and depth of the semantic competence of \\emph{Large\nLanguage Models} (LLMs) is at the center of the current scientific agenda in\nArtificial Intelligence (AI) and Computational Linguistics (CL). We contribute\nto this endeavor by investigating their knowledge of the \\emph{part-whole}\nrelation, a.k.a. \\emph{meronymy}, which plays a crucial role in lexical\norganization, but it is significantly understudied. We used data from\nConceptNet relations \\citep{speer2016conceptnet} and human-generated semantic\nfeature norms \\citep{McRae:2005} to explore the abilities of LLMs to deal with\n\\textit{part-whole} relations. We employed several methods based on three\nlevels of analysis: i.) \\textbf{behavioral} testing via prompting, where we\ndirectly queried the models on their knowledge of meronymy, ii.) sentence\n\\textbf{probability} scoring, where we tested models' abilities to discriminate\ncorrect (real) and incorrect (asymmetric counterfactual) \\textit{part-whole}\nrelations, and iii.) \\textbf{concept representation} analysis in vector space,\nwhere we proved the linear organization of the \\textit{part-whole} concept in\nthe embedding and unembedding spaces. These analyses present a complex picture\nthat reveals that the LLMs' knowledge of this relation is only partial. They\nhave just a ``\\emph{quasi}-semantic'' competence and still fall short of\ncapturing deep inferential properties.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T08:41:26Z"}
{"aid":"http://arxiv.org/abs/2504.02406v1","title":"Lifecycle Management of Trustworthy AI Models in 6G Networks: The REASON\n  Approach","summary":"Artificial Intelligence (AI) is expected to play a key role in 6G networks\nincluding optimising system management, operation, and evolution. This requires\nsystematic lifecycle management of AI models, ensuring their impact on services\nand stakeholders is continuously monitored. While current 6G initiatives\nintroduce AI, they often fall short in addressing end-to-end intelligence and\ncrucial aspects like trust, transparency, privacy, and verifiability.\nTrustworthy AI is vital, especially for critical infrastructures like 6G. This\npaper introduces the REASON approach for holistically addressing AI's native\nintegration and trustworthiness in future 6G networks. The approach comprises\nAI Orchestration (AIO) for model lifecycle management, Cognition (COG) for\nperformance evaluation and explanation, and AI Monitoring (AIM) for tracking\nand feedback. Digital Twin (DT) technology is leveraged to facilitate real-time\nmonitoring and scenario testing, which are essential for AIO, COG, and AIM. We\ndemonstrate this approach through an AI-enabled xAPP use case, leveraging a DT\nplatform to validate, explain, and deploy trustworthy AI models.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-03T08:56:29Z"}
{"aid":"http://arxiv.org/abs/2504.02432v1","title":"Robust Randomized Low-Rank Approximation with Row-Wise Outlier Detection","summary":"Robust low-rank approximation under row-wise adversarial corruption can be\nachieved with a single pass, randomized procedure that detects and removes\noutlier rows by thresholding their projected norms. We propose a scalable,\nnon-iterative algorithm that efficiently recovers the underlying low-rank\nstructure in the presence of row-wise adversarial corruption. By first\ncompressing the data with a Johnson Lindenstrauss projection, our approach\npreserves the geometry of clean rows while dramatically reducing\ndimensionality. Robust statistical techniques based on the median and median\nabsolute deviation then enable precise identification and removal of outlier\nrows with abnormally high norms. The subsequent rank-k approximation achieves\nnear-optimal error bounds with a one pass procedure that scales linearly with\nthe number of observations. Empirical results confirm that combining random\nsketches with robust statistics yields efficient, accurate decompositions even\nin the presence of large fractions of corrupted rows.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.NA","published":"2025-04-03T09:43:27Z"}
{"aid":"http://arxiv.org/abs/2504.02434v1","title":"Generalised Hajłasz-Besov spaces on $RD$-spaces","summary":"An $RD$ space is a doubling measure metric space $\\Omega$ with the additional\nproperty that it has a reverse doubling property. In this paper we introduce a\nnew class of Haj{\\l}asz-Besov spaces on $\\Omega$ and extend several results\nfrom classical theory, such as embeddings and Sobolev-type embeddings.","main_category":"math.FA","categories":"math.FA","published":"2025-04-03T09:50:15Z"}
{"aid":"http://arxiv.org/abs/2504.02450v1","title":"CHARMS: Cognitive Hierarchical Agent with Reasoning and Motion Styles","summary":"To address the current challenges of low intelligence and simplistic vehicle\nbehavior modeling in autonomous driving simulation scenarios, this paper\nproposes the Cognitive Hierarchical Agent with Reasoning and Motion Styles\n(CHARMS). The model can reason about the behavior of other vehicles like a\nhuman driver and respond with different decision-making styles, thereby\nimproving the intelligence and diversity of the surrounding vehicles in the\ndriving scenario. By introducing the Level-k behavioral game theory, the paper\nmodels the decision-making process of human drivers and employs deep\nreinforcement learning to train the models with diverse decision styles,\nsimulating different reasoning approaches and behavioral characteristics.\nBuilding on the Poisson cognitive hierarchy theory, this paper also presents a\nnovel driving scenario generation method. The method controls the proportion of\nvehicles with different driving styles in the scenario using Poisson and\nbinomial distributions, thus generating controllable and diverse driving\nenvironments. Experimental results demonstrate that CHARMS not only exhibits\nsuperior decision-making capabilities as ego vehicles, but also generates more\ncomplex and diverse driving scenarios as surrounding vehicles. We will release\ncode for CHARMS at https://github.com/WUTAD-Wjy/CHARMS.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.LG","published":"2025-04-03T10:15:19Z"}
{"aid":"http://arxiv.org/abs/2504.02457v1","title":"Size and shape of the trans-Neptunian object (470316) 2007 OC10:\n  Comparison with thermal data","summary":"The shapes of only 12 trans-Neptunian objects have been directly measured,\noffering crucial insights into their internal structure. These properties are\nstrongly connected to the processes that shaped the early Solar System, and\nprovide important clues about its evolution.\n  The aim of the present work is to characterise the size, shape, geometric\nalbedo, and beaming parameter of the TNO (470316) 2007 OC10 . We compared these\nvalues to the effective diameter and geometric albedo obtained from thermal\ndata by the TNOs are Cool survey. We also combined occultation and thermal data\nto constrain the size of a putative unresolved satellite.\n  We predicted an occultation of the star Gaia DR3 2727866328215869952 by 2007\nOC10 on 2022 August 22. Four stations detected the occultation. We implemented\nan elliptical shape model for the projection of 2007 OC10. Following a Bayesian\napproach, we obtained the posterior probability density in the model parameter\nspace using a Markov chain Monte Carlo method.\n  The elliptical limb of 2007 OC10 has semi-axes of $ 215^{+10}_{-7} \\times 141\n^{+24}_{-23}$ km, and thus the projected axis ratio is $b/a =\n0.58^{+0.16}_{-0.16}$. The area-equivalent diameter is $330^{+56}_{-55}$,km.\nFrom our own absolute magnitude value of $H_V = 5.40 \\pm 0.02$, the geometric\nalbedo is $p_V = 11.2 ^{+2.1}_{-5.0}$ %. Combining the occultation results with\nthermal data, we constrain the beaming parameter to $\\eta =\n1.42^{+0.75}_{-0.58}$. Occultation data reveal that the star is double. The\nsecondary star has a position angle with respect to the primary of\n$56^{+3}_{-17}$ degrees, has an angular separation of $57^{+4}_{-11}$ mas, and\nis $1.18^{+0.07}_{-0.07}$ magnitudes fainter than the primary.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-03T10:21:03Z"}
{"aid":"http://arxiv.org/abs/2504.02459v1","title":"A Physics-Informed Meta-Learning Framework for the Continuous Solution\n  of Parametric PDEs on Arbitrary Geometries","summary":"In this work, we introduce implicit Finite Operator Learning (iFOL) for the\ncontinuous and parametric solution of partial differential equations (PDEs) on\narbitrary geometries. We propose a physics-informed encoder-decoder network to\nestablish the mapping between continuous parameter and solution spaces. The\ndecoder constructs the parametric solution field by leveraging an implicit\nneural field network conditioned on a latent or feature code. Instance-specific\ncodes are derived through a PDE encoding process based on the second-order\nmeta-learning technique. In training and inference, a physics-informed loss\nfunction is minimized during the PDE encoding and decoding. iFOL expresses the\nloss function in an energy or weighted residual form and evaluates it using\ndiscrete residuals derived from standard numerical PDE methods. This approach\nresults in the backpropagation of discrete residuals during both training and\ninference.\n  iFOL features several key properties: (1) its unique loss formulation\neliminates the need for the conventional encode-process-decode pipeline\npreviously used in operator learning with conditional neural fields for PDEs;\n(2) it not only provides accurate parametric and continuous fields but also\ndelivers solution-to-parameter gradients without requiring additional loss\nterms or sensitivity analysis; (3) it can effectively capture sharp\ndiscontinuities in the solution; and (4) it removes constraints on the geometry\nand mesh, making it applicable to arbitrary geometries and spatial sampling\n(zero-shot super-resolution capability). We critically assess these features\nand analyze the network's ability to generalize to unseen samples across both\nstationary and transient PDEs. The overall performance of the proposed method\nis promising, demonstrating its applicability to a range of challenging\nproblems in computational mechanics.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T10:24:00Z"}
{"aid":"http://arxiv.org/abs/2504.02464v1","title":"CornerPoint3D: Look at the Nearest Corner Instead of the Center","summary":"3D object detection aims to predict object centers, dimensions, and rotations\nfrom LiDAR point clouds. Despite its simplicity, LiDAR captures only the near\nside of objects, making center-based detectors prone to poor localization\naccuracy in cross-domain tasks with varying point distributions. Meanwhile,\nexisting evaluation metrics designed for single-domain assessment also suffer\nfrom overfitting due to dataset-specific size variations. A key question\narises: Do we really need models to maintain excellent performance in the\nentire 3D bounding boxes after being applied across domains? Actually, one of\nour main focuses is on preventing collisions between vehicles and other\nobstacles, especially in cross-domain scenarios where correctly predicting the\nsizes is much more difficult. To address these issues, we rethink cross-domain\n3D object detection from a practical perspective. We propose two new metrics\nthat evaluate a model's ability to detect objects' closer-surfaces to the LiDAR\nsensor. Additionally, we introduce EdgeHead, a refinement head that guides\nmodels to focus more on learnable closer surfaces, significantly improving\ncross-domain performance under both our new and traditional BEV/3D metrics.\nFurthermore, we argue that predicting the nearest corner rather than the object\ncenter enhances robustness. We propose a novel 3D object detector, coined as\nCornerPoint3D, which is built upon CenterPoint and uses heatmaps to supervise\nthe learning and detection of the nearest corner of each object. Our proposed\nmethods realize a balanced trade-off between the detection quality of entire\nbounding boxes and the locating accuracy of closer surfaces to the LiDAR\nsensor, outperforming the traditional center-based detector CenterPoint in\nmultiple cross-domain tasks and providing a more practically reasonable and\nrobust cross-domain 3D object detection solution.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-03T10:33:43Z"}
{"aid":"http://arxiv.org/abs/2504.02465v1","title":"RASP: Revisiting 3D Anamorphic Art for Shadow-Guided Packing of\n  Irregular Objects","summary":"Recent advancements in learning-based methods have opened new avenues for\nexploring and interpreting art forms, such as shadow art, origami, and sketch\nart, through computational models. One notable visual art form is 3D Anamorphic\nArt in which an ensemble of arbitrarily shaped 3D objects creates a realistic\nand meaningful expression when observed from a particular viewpoint and loses\nits coherence over the other viewpoints. In this work, we build on insights\nfrom 3D Anamorphic Art to perform 3D object arrangement. We introduce RASP, a\ndifferentiable-rendering-based framework to arrange arbitrarily shaped 3D\nobjects within a bounded volume via shadow (or silhouette)-guided optimization\nwith an aim of minimal inter-object spacing and near-maximal occupancy.\nFurthermore, we propose a novel SDF-based formulation to handle inter-object\nintersection and container extrusion. We demonstrate that RASP can be extended\nto part assembly alongside object packing considering 3D objects to be \"parts\"\nof another 3D object. Finally, we present artistic illustrations of multi-view\nanamorphic art, achieving meaningful expressions from multiple viewpoints\nwithin a single ensemble.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-03T10:33:49Z"}
{"aid":"http://arxiv.org/abs/2504.02500v1","title":"An Overview of Josephson Junctions Based QPUs","summary":"Quantum processing units (QPUs) based on superconducting Josephson junctions\npromise significant advances in quantum computing. However, they face critical\nchallenges. Decoherence, scalability limitations, and error correction overhead\nhinder practical, fault-tolerant implementations. This paper investigates these\nissues by exploring both fundamental quantum phenomena and practical\nengineering challenges. We analyze key quantum mechanical principles such as\nsuperposition, entanglement, and decoherence that govern the behavior of\nsuperconducting qubits. We also discuss quantum tunneling, Cooper pair\nformation, and the operational mechanics of Josephson junctions in detail.\nAdditionally, we present a comparative analysis with alternative architectures,\nincluding ion trap and photonic systems. This comparison highlights the unique\nadvantages and trade-offs of Josephson junction-based QPUs. Our findings\nemphasize the critical role of material innovations and optimized control\ntechniques. These advances are essential for mitigating noise and decoherence\nand for realizing robust, scalable quantum computing.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cs.ET,quant-ph","published":"2025-04-03T11:26:52Z"}
{"aid":"http://arxiv.org/abs/2504.02508v1","title":"APHQ-ViT: Post-Training Quantization with Average Perturbation Hessian\n  Based Reconstruction for Vision Transformers","summary":"Vision Transformers (ViTs) have become one of the most commonly used\nbackbones for vision tasks. Despite their remarkable performance, they often\nsuffer significant accuracy drops when quantized for practical deployment,\nparticularly by post-training quantization (PTQ) under ultra-low bits.\nRecently, reconstruction-based PTQ methods have shown promising performance in\nquantizing Convolutional Neural Networks (CNNs). However, they fail when\napplied to ViTs, primarily due to the inaccurate estimation of output\nimportance and the substantial accuracy degradation in quantizing post-GELU\nactivations. To address these issues, we propose \\textbf{APHQ-ViT}, a novel PTQ\napproach based on importance estimation with Average Perturbation Hessian\n(APH). Specifically, we first thoroughly analyze the current approximation\napproaches with Hessian loss, and propose an improved average perturbation\nHessian loss. To deal with the quantization of the post-GELU activations, we\ndesign an MLP Reconstruction (MR) method by replacing the GELU function in MLP\nwith ReLU and reconstructing it by the APH loss on a small unlabeled\ncalibration set. Extensive experiments demonstrate that APHQ-ViT using linear\nquantizers outperforms existing PTQ methods by substantial margins in 3-bit and\n4-bit across different vision tasks. The source code is available at\nhttps://github.com/GoatWu/APHQ-ViT.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T11:48:56Z"}
{"aid":"http://arxiv.org/abs/2504.02547v1","title":"A smooth multi-group Gaussian Mixture Model for cellwise robust\n  covariance estimation","summary":"Are data groups which are pre-defined by expert opinions or medical diagnoses\ncorresponding to groups based on statistical modeling? For which reason might\nobservations be inconsistent? This contribution intends to answer both\nquestions by proposing a novel multi-group Gaussian mixture model that accounts\nfor the given group context while allowing high flexibility. This is achieved\nby assuming that the observations of a particular group originate not from a\nsingle distribution but from a Gaussian mixture of all group distributions.\nMoreover, the model provides robustness against cellwise outliers, thus against\natypical data cells of the observations. The objective function can be\nformulated as a likelihood problem and optimized efficiently. We also derive\nthe theoretical breakdown point of the estimators, an innovative result in this\ncontext to quantify the degree of robustness to cellwise outliers. Simulations\ndemonstrate the excellent performance and the advantages to alternative models\nand estimators. Applications from different areas illustrate the strength of\nthe method, particularly in investigating observations which are on the overlap\nof different groups.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-03T12:54:21Z"}
{"aid":"http://arxiv.org/abs/2504.02572v1","title":"Language Models reach higher Agreement than Humans in Historical\n  Interpretation","summary":"This paper compares historical annotations by humans and Large Language\nModels. The findings reveal that both exhibit some cultural bias, but Large\nLanguage Models achieve a higher consensus on the interpretation of historical\nfacts from short texts. While humans tend to disagree on the basis of their\npersonal biases, Large Models disagree when they skip information or produce\nhallucinations. These findings have significant implications for digital\nhumanities, enabling large-scale annotation and quantitative analysis of\nhistorical data. This offers new educational and research opportunities to\nexplore historical interpretations from different Language Models, fostering\ncritical thinking about bias.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T13:37:45Z"}
{"aid":"http://arxiv.org/abs/2504.02592v1","title":"Unified Equation for Massless Spin Particles and New Spin Coefficient\n  Definitions","summary":"We introduce a new definition for the spin coefficients $\\rho$, $\\mu$,\n$\\tau$, and $\\pi$, which are defined as the directional derivatives of the\nlogarithm of a generating function along the null tetrad ($l^{\\mu}$, $n^{\\mu}$,\n$m^{\\mu}$, $\\bar{m}^{\\mu}$), respectively. This is the first discovery that\nthese spin coefficients are interconnected through a generating function. Using\nthe newly defined spin coefficients, we find that the field equations for\nmassless particles with spins 0, 1/2, 1, 3/2, and 2 in arbitrary black hole\nspacetimes can be described by a single unified equation. This finding is\nparticularly surprising, as unifying these field equations is already a\nsignificant challenge in flat spacetime, let alone in the intricate spacetime\naround black holes. Consequently, this work will inevitably prompt a\nre-examination of the shared characteristics among various types of particles\nin black hole spacetimes. Meanwhile, we verify the correctness of the new\ndefinition for the spin coefficients, and provide the explicit form of the\nunified equation for nearly all known black hole backgrounds. This lays a solid\nfoundation for studying the behavior of massless spin particles in any black\nhole background.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-03T13:55:24Z"}
{"aid":"http://arxiv.org/abs/2504.02620v1","title":"Efficient Model Editing with Task-Localized Sparse Fine-tuning","summary":"Task arithmetic has emerged as a promising approach for editing models by\nrepresenting task-specific knowledge as composable task vectors. However,\nexisting methods rely on network linearization to derive task vectors, leading\nto computational bottlenecks during training and inference. Moreover,\nlinearization alone does not ensure weight disentanglement, the key property\nthat enables conflict-free composition of task vectors. To address this, we\npropose TaLoS which allows to build sparse task vectors with minimal\ninterference without requiring explicit linearization and sharing information\nacross tasks. We find that pre-trained models contain a subset of parameters\nwith consistently low gradient sensitivity across tasks, and that sparsely\nupdating only these parameters allows for promoting weight disentanglement\nduring fine-tuning. Our experiments prove that TaLoS improves training and\ninference efficiency while outperforming current methods in task addition and\nnegation. By enabling modular parameter editing, our approach fosters practical\ndeployment of adaptable foundation models in real-world applications.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL,cs.CV","published":"2025-04-03T14:20:06Z"}
{"aid":"http://arxiv.org/abs/2504.02630v1","title":"Grammar-based Ordinary Differential Equation Discovery","summary":"The understanding and modeling of complex physical phenomena through\ndynamical systems has historically driven scientific progress, as it provides\nthe tools for predicting the behavior of different systems under diverse\nconditions through time. The discovery of dynamical systems has been\nindispensable in engineering, as it allows for the analysis and prediction of\ncomplex behaviors for computational modeling, diagnostics, prognostics, and\ncontrol of engineered systems. Joining recent efforts that harness the power of\nsymbolic regression in this domain, we propose a novel framework for the\nend-to-end discovery of ordinary differential equations (ODEs), termed\nGrammar-based ODE Discovery Engine (GODE). The proposed methodology combines\nformal grammars with dimensionality reduction and stochastic search for\nefficiently navigating high-dimensional combinatorial spaces. Grammars allow us\nto seed domain knowledge and structure for both constraining, as well as,\nexploring the space of candidate expressions. GODE proves to be more sample-\nand parameter-efficient than state-of-the-art transformer-based models and to\ndiscover more accurate and parsimonious ODE expressions than both genetic\nprogramming- and other grammar-based methods for more complex inference tasks,\nsuch as the discovery of structural dynamics. Thus, we introduce a tool that\ncould play a catalytic role in dynamics discovery tasks, including modeling,\nsystem identification, and monitoring tasks.","main_category":"cs.LG","categories":"cs.LG,cs.CE,cs.SC","published":"2025-04-03T14:28:13Z"}
{"aid":"http://arxiv.org/abs/2504.02643v1","title":"A Dynamic, Ordinal Gaussian Process Item Response Theoretic Model","summary":"Social scientists are often interested in using ordinal indicators to\nestimate latent traits that change over time. Frequently, this is done with\nitem response theoretic (IRT) models that describe the relationship between\nthose latent traits and observed indicators. We combine recent advances in\nBayesian nonparametric IRT, which makes minimal assumptions on shapes of item\nresponse functions, and Gaussian process time series methods to capture dynamic\nstructures in latent traits from longitudinal observations. We propose a\ngeneralized dynamic Gaussian process item response theory (GD-GPIRT) as well as\na Markov chain Monte Carlo sampling algorithm for estimation of both latent\ntraits and response functions. We evaluate GD-GPIRT in simulation studies\nagainst baselines in dynamic IRT, and apply it to various substantive studies,\nincluding assessing public opinions on economy environment and congressional\nideology related to abortion debate.","main_category":"stat.ME","categories":"stat.ME,cs.LG","published":"2025-04-03T14:37:26Z"}
{"aid":"http://arxiv.org/abs/2504.02683v1","title":"Probing patchy reionisation with JWST: IGM opacity constraints from the\n  Lyman-$α$ forest of galaxies in legacy extragalactic fields","summary":"We present the first characterization of the Gunn-Peterson trough in\nhigh-redshift galaxies using public JWST NIRSpec spectroscopy. This enables us\nto derive the first galaxy-based IGM opacity measurements at the end of\nreionisation. Using galaxy spectra has several advantages over quasar spectra:\nit enables measurements of the IGM opacity in any extragalactic field over a\ncontinuous redshift range $4\\lesssim z\\lesssim 7$, as well as measurements of\nthe intrinsic Lyman-$\\beta$ opacity. Our novel constraints are in good\nagreement with state-of-the-art ground-based quasar Lyman-$\\alpha$ forest\nobservations, and will become competitive as the number of JWST $z>5$ galaxy\nspectra rapidly increases. We also provide the first constraints on the\nuncontaminated Lyman-$\\beta$ opacity at $5<z<6$. Finally, we demonstrate the\npower of JWST to connect the ionisation state of the IGM to the sources of\nreionisation in a single extragalactic field. We show that a previously\nreported galaxy overdensity and an excess of Lyman-$\\alpha$ emitters detected\nwith JWST in GOODS-South at $z=5.8-5.9$ coincides with an anomalously low IGM\nopacity to Lyman-$\\alpha$ at this redshift. The local photo-ionisation rate\nexcess can be fully accounted for by the cumulative ionising output of\n$M_{\\rm{UV}}\\lesssim -10$ galaxies in the overdensity, provided they have\n$\\log_{10}\\langle \\xi_{\\rm{ion}} f_{\\rm{esc}} / \\ [\\rm{erg}^{-1}\\rm{Hz}]\\rangle\n= 24.7$ (or equivalently $\\log_{10}\\xi_{\\rm{ion}} / \\\n[\\rm{erg}^{-1}\\rm{Hz}]=25.4$ and $f_{\\rm{esc}}=20\\%$). Overall, this\nbreakthrough offers a new way to connect the galaxy large-scale structure to\nthe state of the IGM, potentially enabling us to precisely identify the sources\nof reionisation.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-04-03T15:24:01Z"}
{"aid":"http://arxiv.org/abs/2504.02689v1","title":"Plasmon-interband hybridization and anomalous production of hot\n  electrons in aluminum nanoantennas","summary":"Strong coupling typically occurs between two separate objects or between an\nobject and its environment (such as an atom and a cavity). However, it can also\noccur between two different excitations within the same object, a situation\nthat has been much less studied. In this study, we observe strong coupling\nbetween localized surface plasmon resonances and the interband transition in\naluminum nanorods, as evidenced by optical spectroscopy and electron energy\nloss spectroscopy, and corroborated with numerical simulations. Strong coupling\nis observed between the interband transition and multiple orders of the surface\nplasmon mode, including dark ones. We also obtain experimental maps of the\nhybrid modes at the nanoscale. In each case, the associated Rabi energy, which\ncorresponds to the energy splitting between the two polaritonic branches, is\nobtained. Finally, a dedicated numerical model was employed to calculate the\nhot electron generation rate in the nanorods. The calculations demonstrate that\nefficient generation of hot electrons can be achieved in the near-infrared\nregion, when the interband transition is strongly coupled with a plasmon\nresonance. This high generation rate stems from the hybrid nature of the mode,\nas its plasmonic component provides a high absorption cross-section, while the\nIT part ensures efficient conversion to hot electrons. Consequently, aluminum\nnanorods represent an efficient source of hot electrons in the visible and\nnear-infrared regions, with potential applications in local photochemistry,\nphotodetection, and solar energy harvesting.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mes-hall","published":"2025-04-03T15:29:07Z"}
{"aid":"http://arxiv.org/abs/2504.02691v1","title":"Hong-Ou-Mandel interference of more than 10 indistinguishable atoms","summary":"When two indistinguishable bosons interfere at a beam splitter, they both\nexit through the same output port. This foundational quantum-mechanical\nphenomenon, known as the Hong-Ou-Mandel (HOM) effect, has become a cornerstone\nin the field of quantum information. It also extends to many indistinguishable\nparticles, resulting in complex interference patterns. However, despite of its\nfundamental and applied interest, the many-particle effect has only been\nobserved in notoriously lossy photonic systems, but a realization with atomic\nsystems has remained elusive until now. Here, we demonstrate HOM interference\nwith up to 12 indistinguishable neutral atoms in a system with negligible loss.\nOur single-particle counting clearly reveals parity oscillations, a bunching\nenvelope and genuine multi-partite entanglement, defining features of the\nmulti-particle HOM effect. Our technique offers the potential for scaling to\nmuch larger numbers, presenting promising applications in quantum information\nwith indistinguishable particles and Heisenberg-limited atom interferometry.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-03T15:30:05Z"}
{"aid":"http://arxiv.org/abs/2504.02719v1","title":"The Myth of Immutability: A Multivocal Review on Smart Contract\n  Upgradeability","summary":"The immutability of smart contracts on blockchain platforms like Ethereum\npromotes security and trustworthiness but presents challenges for updates, bug\nfixes, or adding new features post-deployment. These limitations can lead to\nvulnerabilities and outdated functionality, impeding the evolution and\nmaintenance of decentralized applications. Despite various upgrade mechanisms\nproposed in academic research and industry, a comprehensive analysis of their\ntrade-offs and practical implications is lacking. This study aims to\nsystematically identify, classify, and evaluate existing smart contract upgrade\nmechanisms, bridging the gap between theoretical concepts and practical\nimplementations. It introduces standardized terminology and evaluates the\ntrade-offs of different approaches using software quality attributes. We\nconducted a Multivocal Literature Review (MLR) to analyze upgrade mechanisms\nfrom both academic research and industry practice. We first establish a unified\ndefinition of smart contract upgradeability and identify core components\nessential for understanding the upgrade process. Based on this definition, we\nclassify existing methods into full upgrade and partial upgrade approaches,\nintroducing standardized terminology to harmonize the diverse terms used in the\nliterature. We then characterize each approach and assess its benefits and\nlimitations using software quality attributes such as complexity, flexibility,\nsecurity, and usability. The analysis highlights significant trade-offs among\nupgrade mechanisms, providing valuable insights into the benefits and\nlimitations of each approach. These findings guide developers and researchers\nin selecting mechanisms tailored to specific project requirements.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-03T16:02:46Z"}
{"aid":"http://arxiv.org/abs/2504.02726v1","title":"Constraining hot and cold nuclear matter properties from heavy-ion\n  collisions and deep-inelastic scattering","summary":"We perform a global analysis of deep-inelastic $e+p$ scattering data from\nHERA and transverse energy distributions in $p+p$ and $p+\\Pb$ collisions,\nalongside charged hadron multiplicities in $\\Pb+\\Pb$ collisions at\n$\\sqrt{s_{\\mathrm{NN}}} = 5.02\\;\\mathrm{TeV}$ from ALICE. Using a\nsaturation-based initial state model grounded in high-energy QCD, we determine\nthe early-time non-equilibrium shear viscosity to entropy density ratio\n$\\eta/s$ of the quark-gluon plasma. Our results provide new insights into the\nearly-time transport properties of nuclear matter under extreme conditions.","main_category":"nucl-th","categories":"nucl-th,hep-ph","published":"2025-04-03T16:10:25Z"}
{"aid":"http://arxiv.org/abs/2504.02729v1","title":"Vortex Flows in the Solar Atmosphere: Detection and Heating Mechanisms\n  in 3D MHD Numerical Simulations","summary":"Vortex flows are structures associated with the rotation of the plasma and/or\nthe magnetic field that are present throughout the solar atmosphere. In recent\nyears, their study has become increasingly important, as they are present on a\nwide variety of temporal and spatial scales and can connect several layers of\nthe solar atmosphere. In this work, we focused on the detection and analysis of\nthese structures in an automatic way. We use realistic 3D MHD numerical\nsimulations obtained with the Mancha3D code at different magnetic field\nconfigurations and spatial resolutions. The vortex detection has been performed\nusing the novel SWIRL code. We have been able to determine multiple structures\nassociated with small and large scale vortices that extend in height in our\nsimulations. We performed a statistical analysis of these structures,\nquantifying their number and typical sizes, as well as their temperature and\nheating profiles, confirming their importance in the energy transport.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-03T16:12:11Z"}
{"aid":"http://arxiv.org/abs/2504.02731v1","title":"How Election Shocks Move Markets: Evidence from Sectoral Stock Prices","summary":"This paper examines the effects of U.S. presidential election cycles on\nsectoral stock markets. Using a high-frequency identification approach, I\nconstruct a novel \"election shock'' series, which captures exogenous surprises\nin election probabilities. Aside from election outcomes, the largest shocks are\nassociated with events that are orthogonal to innovations in the macroeconomy,\ne.g., scandals and debates. These shocks have immediate effects on asset prices\nin sectors that are differentially impacted by the policy platforms of the two\nmajor U.S. political parties. In particular, shocks favoring Republican\n(Democratic) candidates increase (decrease) the asset prices in the energy and\ndefense sectors, while decreasing (increasing) prices in the clean energy\nsector. These effects persist overtime.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-03T16:13:46Z"}
{"aid":"http://arxiv.org/abs/2504.02752v1","title":"Anomalous vortex Hall effect in a ferromagnet/superconductor\n  heterostructure","summary":"The coexistence of superconductivity and ferromagnetism is a fascinating and\ncomplex phenomenon in condensed matter physics, as these two states are\ntypically mutually exclusive due to their competing spin configurations.\nHowever, the interplay between these two orders through the proximity effect\nhas been a subject of intense research as it opens up possibilities for novel\ntechnological applications. Here, we report the coexistence of\nsuperconductivity and ferromagnetism in superconducting\n{\\delta}-TaN/ferromagnetic CoFeB heterostructures grown by facing-target\nsputtering. Superconducting states are comprehensively investigated, with\nevidence of strong correlation between the superconducting and ferromagnetic\norder parameters. In particular, we observed an anomalous Hall signal without\nthe presence of the magnetic field in the mixed state of the superconducting\ntransition near the critical temperature. Systematic characterizations of the\nHall resistance under varying temperatures and magnetic fields attribute this\nbehavior to the vortex Hall effect (VHE), whereby superconducting vortices in\nthe mixed state undergo transverse motions near the critical temperature.\nUnlike previously reported VHEs in conventional type-II superconductors, the\nanomalous VHE in TaN is induced by the stray field in the underlying CoFeB\nlayers. The concurrency of strong spin-orbit coupling, the superconductivity in\nthe TaN layer, and the highly spin-polarized ferromagnetic ordering in the\nCoFeB layer offers new insights into proximity-induced vortex dynamics and the\ndesign of novel superconducting spintronic devices.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-03T16:43:07Z"}
{"aid":"http://arxiv.org/abs/2504.02755v1","title":"The MaNGA Dwarf Galaxy Sample (MaNDala): stellar profiles and gradients\n  characterization","summary":"We derived radial profiles and inner/outer gradients of various stellar\npopulation (SP) properties for 124 bright dwarf galaxies, $10^{7.53}\\leq\nM_*/M_\\odot\\leq 10^{9.06}$, from the MaNDala sample, using integral field\nspectroscopy observations. Given the complex structure of dwarf galaxies, we\nused four different methods to derive SP radial profiles: two based on\nconcentric elliptical rings, and two exploiting the spatially resolved data.\nFor each method, we applied four approaches to calculate the inner ($0 \\leq\nR/R_e \\leq 1$) and outer ($0.75 \\leq R/R_e \\leq 1.5$) gradients of: luminosity-\nand mass-weighted age and stellar metallicity, dust attenuation, $D_{n4000}$\nindex, stellar mass and star formation rate (SFR) surface densities, and\nspecific SFR. While the PSF has a minor impact on the SP gradients, the\nmethodology for characterizing radial profiles significantly affects them. At\nfixed property, differences in inner gradients from concentric rings methods\nare $\\sim0.05\\text{-}0.1 \\text{ dex/}R_e$, while outer gradients can reach\n$0.5\\text{-}1 \\text{ dex/}R_e$, relative to the median of all gradients of that\nproperty, $\\text{med}\\left(\\{\\nabla \\mathcal{G}\\}_i\\right)$. Spatially resolved\nmethods yield smaller differences, $\\lesssim0.1 \\text{ dex/}R_e$. For some SP\ngradients, e.g. $\\nabla_\\text{SFR}$, the dispersion among the methods is\ncomparable to $\\text{med}\\left(\\{\\nabla \\mathcal{G}\\}_i\\right)$. While it is\nnot possible to select a single preferred method for determining SP gradients,\nwe suggest to use $\\text{med}\\left(\\{\\nabla \\mathcal{G}\\}_i\\right)$ for each SP\nproperty. The resulting median age and metallicity suggest that, overall,\nbright dwarfs experienced moderate inside-out formation, and significant early\nSF from low-metallicity gas with outward radial migration of old SPs. The\nderived SP gradients provide strong constraints on feedback mechanisms in dwarf\ngalaxies.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-03T16:49:08Z"}
{"aid":"http://arxiv.org/abs/2504.02759v1","title":"Production of protons, deuterons and tritons in argon-nucleus\n  interactions at 3.2 AGeV","summary":"Results of the BM@N experiment at the Nuclotron/NICA complex on the\nproduction of protons, deuterons and tritons in interactions of an argon beam\nof 3.2 AGeV with fixed targets of C, Al, Cu, Sn and Pb are presented.\nTransverse mass spectra, rapidity distributions and multiplicities of protons,\ndeuterons and tritons are measured. The results are treated within a\ncoalescence approach and compared with predictions of theoretical models and\nwith other measurements","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-03T16:54:26Z"}
{"aid":"http://arxiv.org/abs/2504.02767v1","title":"How Deep Do Large Language Models Internalize Scientific Literature and\n  Citation Practices?","summary":"The spread of scientific knowledge depends on how researchers discover and\ncite previous work. The adoption of large language models (LLMs) in the\nscientific research process introduces a new layer to these citation practices.\nHowever, it remains unclear to what extent LLMs align with human citation\npractices, how they perform across domains, and may influence citation\ndynamics. Here, we show that LLMs systematically reinforce the Matthew effect\nin citations by consistently favoring highly cited papers when generating\nreferences. This pattern persists across scientific domains despite significant\nfield-specific variations in existence rates, which refer to the proportion of\ngenerated references that match existing records in external bibliometric\ndatabases. Analyzing 274,951 references generated by GPT-4o for 10,000 papers,\nwe find that LLM recommendations diverge from traditional citation patterns by\npreferring more recent references with shorter titles and fewer authors.\nEmphasizing their content-level relevance, the generated references are\nsemantically aligned with the content of each paper at levels comparable to the\nground truth references and display similar network effects while reducing\nauthor self-citations. These findings illustrate how LLMs may reshape citation\npractices and influence the trajectory of scientific discovery by reflecting\nand amplifying established trends. As LLMs become more integrated into the\nscientific research process, it is important to understand their role in\nshaping how scientific communities discover and build upon prior work.","main_category":"cs.DL","categories":"cs.DL,cs.AI,cs.LG,cs.SI","published":"2025-04-03T17:04:56Z"}
{"aid":"http://arxiv.org/abs/2504.02772v1","title":"Interpreting gravitational fields of Topologically Massive Gravity using\n  geodesic deviation","summary":"We study relative motion of nearby test particles in Topologically Massive\nGravity (TMG) in three spacetime dimensions, using the equation of geodesic\ndeviation. We show that, in a suitable reference frame, the influence of any\ngravitational field can be decomposed into transverse, longitudinal, and\nNewtonian components, which are directly related to the Cotton scalars of the\nNewman-Penrose-type. In particular, we prove that Cotton type N spacetimes\nexhibit a purely transverse gravitational effect on test particles, and can\nthus be reasonably interpreted as specific gravitational waves with a single\npolarization mode in TMG. The influence of the cosmological constant manifests\nitself as an isotropic effect. We also discuss the physical interpretation of\nspacetimes of specific algebraic types, as well as the influence of various\nmatter fields, namely pure radiation, perfect fluid, and electromagnetic field.\nAs an example, we provide an explicit analysis of TN-waves and pp-waves in\nthree-dimensional TMG.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-03T17:08:37Z"}
{"aid":"http://arxiv.org/abs/2504.02789v1","title":"A Framework for Robust Cognitive Evaluation of LLMs","summary":"Emergent cognitive abilities in large language models (LLMs) have been widely\nobserved, but their nature and underlying mechanisms remain poorly understood.\nA growing body of research draws on cognitive science to investigate LLM\ncognition, but standard methodologies and experimen-tal pipelines have not yet\nbeen established. To address this gap we develop CognitivEval, a framework for\nsystematically evaluating the artificial cognitive capabilities of LLMs, with a\nparticular emphasis on robustness in response collection. The key features of\nCognitivEval include: (i) automatic prompt permutations, and (ii) testing that\ngathers both generations and model probability estimates. Our experiments\ndemonstrate that these features lead to more robust experimental outcomes.\nUsing CognitivEval, we replicate five classic experiments in cognitive science,\nillustrating the framework's generalizability across various experimental tasks\nand obtaining a cognitive profile of several state of the art LLMs.\nCognitivEval will be released publicly to foster broader collaboration within\nthe cognitive science community.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T17:35:54Z"}
{"aid":"http://arxiv.org/abs/2504.02797v1","title":"Spline-based Transformers","summary":"We introduce Spline-based Transformers, a novel class of Transformer models\nthat eliminate the need for positional encoding. Inspired by workflows using\nsplines in computer animation, our Spline-based Transformers embed an input\nsequence of elements as a smooth trajectory in latent space. Overcoming\ndrawbacks of positional encoding such as sequence length extrapolation,\nSpline-based Transformers also provide a novel way for users to interact with\ntransformer latent spaces by directly manipulating the latent control points to\ncreate new latent trajectories and sequences. We demonstrate the superior\nperformance of our approach in comparison to conventional positional encoding\non a variety of datasets, ranging from synthetic 2D to large-scale real-world\ndatasets of images, 3D shapes, and animations.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-03T17:42:07Z"}
{"aid":"http://arxiv.org/abs/2504.02805v1","title":"The M31-M33 Interaction: Impact on M31's Center of Mass Motion and\n  Satellite Orbits","summary":"Inspired by recent studies of the Milky Way--LMC interaction and its\nimplications for the Milky Way's global dynamical history, we investigate how\nthe massive satellite galaxy M33 influences Andromeda's (M31) center of mass\n(COM) position and velocity as it passes through M31's halo. Using recent\n6-dimensional phase space measurements for both galaxies, we use backward\nintegration to revisit M33's orbital history in a massive M31 potential\n($3\\times10^{12}\\,M_{\\odot}$) for the first time. As previously concluded, we\nfind that a first infall orbit is still the most statistically significant\n($\\gtrsim$ 90%) orbital solution for M33, except for a high mass M31 combined\nwith M31 proper motions from HST (as opposed to Gaia), where there is a greater\nlikelihood (~65%) of a previous encounter. However, the minimum distance\nbetween M33 and M31 during this passage is typically $\\geq$ 100 kpc, two to\nthree times larger than the distance required to explain M33's warped stellar\nand gaseous disks. We quantify the magnitude and direction of M31's evolving\nCOM position ($R_{COM}$) and velocity ($V_{COM}$) owing to M33, finding\n$R_{COM}\\approx$100-150 kpc at maximum and $V_{COM}\\approx$20-40 km s$^{-1}$.\nFurthermore, we explore the implications of this phenomenon for the M31\nsatellite system, specifically whether M33's gravitational influence is linked\nto the lopsided distribution of M31 satellites and whether M33 significantly\nperturbs the orbits of other M31 satellites. While M33 alone may not explain\nthe lopsided nature of M31's satellite system, its dynamical impact is\nnon-negligible and must be accounted for in future dynamical studies of the M31\nsystem.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-03T17:51:15Z"}
{"aid":"http://arxiv.org/abs/2504.02807v1","title":"MegaMath: Pushing the Limits of Open Math Corpora","summary":"Mathematical reasoning is a cornerstone of human intelligence and a key\nbenchmark for advanced capabilities in large language models (LLMs). However,\nthe research community still lacks an open, large-scale, high-quality corpus\ntailored to the demands of math-centric LLM pre-training. We present MegaMath,\nan open dataset curated from diverse, math-focused sources through following\npractices: (1) Revisiting web data: We re-extracted mathematical documents from\nCommon Crawl with math-oriented HTML optimizations, fasttext-based filtering\nand deduplication, all for acquiring higher-quality data on the Internet. (2)\nRecalling Math-related code data: We identified high quality math-related code\nfrom large code training corpus, Stack-V2, further enhancing data diversity.\n(3) Exploring Synthetic data: We synthesized QA-style text, math-related code,\nand interleaved text-code blocks from web data or code data. By integrating\nthese strategies and validating their effectiveness through extensive\nablations, MegaMath delivers 371B tokens with the largest quantity and top\nquality among existing open math pre-training datasets.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-03T17:52:07Z"}
{"aid":"http://arxiv.org/abs/2504.02810v1","title":"Generative Evaluation of Complex Reasoning in Large Language Models","summary":"With powerful large language models (LLMs) demonstrating superhuman reasoning\ncapabilities, a critical question arises: Do LLMs genuinely reason, or do they\nmerely recall answers from their extensive, web-scraped training datasets?\nPublicly released benchmarks inevitably become contaminated once incorporated\ninto subsequent LLM training sets, undermining their reliability as faithful\nassessments. To address this, we introduce KUMO, a generative evaluation\nframework designed specifically for assessing reasoning in LLMs. KUMO\nsynergistically combines LLMs with symbolic engines to dynamically produce\ndiverse, multi-turn reasoning tasks that are partially observable and\nadjustable in difficulty. Through an automated pipeline, KUMO continuously\ngenerates novel tasks across open-ended domains, compelling models to\ndemonstrate genuine generalization rather than memorization. We evaluated 23\nstate-of-the-art LLMs on 5,000 tasks across 100 domains created by KUMO,\nbenchmarking their reasoning abilities against university students. Our\nfindings reveal that many LLMs have outperformed university-level performance\non easy reasoning tasks, and reasoning-scaled LLMs reach university-level\nperformance on complex reasoning challenges. Moreover, LLM performance on KUMO\ntasks correlates strongly with results on newly released real-world reasoning\nbenchmarks, underscoring KUMO's value as a robust, enduring assessment tool for\ngenuine LLM reasoning capabilities.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-03T17:54:18Z"}
{"aid":"http://arxiv.org/abs/2504.02822v1","title":"Do Two AI Scientists Agree?","summary":"When two AI models are trained on the same scientific task, do they learn the\nsame theory or two different theories? Throughout history of science, we have\nwitnessed the rise and fall of theories driven by experimental validation or\nfalsification: many theories may co-exist when experimental data is lacking,\nbut the space of survived theories become more constrained with more\nexperimental data becoming available. We show the same story is true for AI\nscientists. With increasingly more systems provided in training data, AI\nscientists tend to converge in the theories they learned, although sometimes\nthey form distinct groups corresponding to different theories. To\nmechanistically interpret what theories AI scientists learn and quantify their\nagreement, we propose MASS, Hamiltonian-Lagrangian neural networks as AI\nScientists, trained on standard problems in physics, aggregating training\nresults across many seeds simulating the different configurations of AI\nscientists. Our findings suggests for AI scientists switch from learning a\nHamiltonian theory in simple setups to a Lagrangian formulation when more\ncomplex systems are introduced. We also observe strong seed dependence of the\ntraining dynamics and final learned weights, controlling the rise and fall of\nrelevant theories. We finally demonstrate that not only can our neural networks\naid interpretability, it can also be applied to higher dimensional problems.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-03T17:58:44Z"}
{"aid":"http://arxiv.org/abs/2504.04721v1","title":"Bridging the Gap between Continuous and Informative Discrete\n  Representations by Random Product Quantization","summary":"Self-supervised learning has become a core technique in speech processing,\nbut the high dimensionality of its representations makes discretization\nessential for improving efficiency. However, existing discretization methods\nstill suffer from significant information loss, resulting in a notable\nperformance gap compared to continuous representations. To overcome these\nlimitations, we propose two quantization-based discretization methods: Product\nQuantization (PQ) and Random Product Quantization (RPQ). PQ partitions the\noriginal feature space into multiple subspaces and independently quantizes each\nsub-vector, producing a fused set of discrete units that retain diverse\ninformation from different subspaces, thus mitigating the loss associated with\nsingle-cluster quantization. RPQ further enhances representation diversity by\nrandomly sampling a fixed proportion of feature dimensions multiple times to\nconstruct sub-vectors, thereby better capturing the variability in the data\ndistribution. Theoretical analysis shows that RPQ reduces the correlation\ncoefficient rho (where 0 <= rho <= 1) between sub-quantizers. Its quantization\nerror is lower-bounded by the product of rho and epsilon-kms, where epsilon-kms\ndenotes the quantization error of a single K-means quantizer. Experimental\nresults on a combined dataset built from LibriSpeech and ML-SUPERB show that PQ\nand RPQ outperform standard K-means discretization, achieving relative\nimprovements of 21.8 percent and 20.0 percent in WER on LibriSpeech, and 24.1\npercent and 19.6 percent in CER on ML-SUPERB, respectively. Moreover, their\nperformance is competitive with, and in some cases even surpasses, that of\ncontinuous SSL representations.","main_category":"eess.AS","categories":"eess.AS","published":"2025-04-07T04:18:11Z"}
{"aid":"http://arxiv.org/abs/2504.04724v1","title":"Three-dimensional abruptly autofocusing by counter-propagating Airy\n  pulses with radial Airy beam profile","summary":"We report the experimental observation of a three-dimensional abruptly\nautofocusing effect by synthesizing a radially distributed Airy beam with two\ncounter-propagating Airy pulses in time. As the wave packet propagates in a\ndispersive medium, the radially distributed Airy beam converges inward to the\ncenter point. Two Airy pulses counter-propagate toward each other to merge to\nform a high peak power pulse. As the result, the high intensity emerges\nabruptly as the wave packet achieves three-dimensional focusing. This\nautofocusing effect is believed to have potential applications such as material\nmodification, plasma physics, nanoparticle manipulations, etc.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-07T04:26:51Z"}
{"aid":"http://arxiv.org/abs/2504.04745v1","title":"Can LLMs Interpret and Leverage Structured Linguistic Representations? A\n  Case Study with AMRs","summary":"This paper evaluates the ability of Large Language Models (LLMs) to leverage\ncontextual information in the form of structured linguistic representations.\nSpecifically, we examine the impact of encoding both short and long contexts\nusing Abstract Meaning Representation (AMR) structures across a diverse set of\nlanguage tasks. We perform our analysis using 8-bit quantized and\ninstruction-tuned versions of Llama 3.1 (8B), Phi-3, and Mistral 7B. Our\nresults indicate that, for tasks involving short contexts, augmenting the\nprompt with the AMR of the original language context often degrades the\nperformance of the underlying LLM. However, for tasks that involve long\ncontexts, such as dialogue summarization in the SAMSum dataset, this\nenhancement improves LLM performance, for example, by increasing the zero-shot\ncosine similarity score of Llama 3.1 from 66.2% to 76%. This improvement is\nmore evident in the newer and larger LLMs, but does not extend to the older or\nsmaller ones. In addition, we observe that LLMs can effectively reconstruct the\noriginal text from a linearized AMR, achieving a cosine similarity of 81.3% in\nthe best-case scenario.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T05:38:40Z"}
{"aid":"http://arxiv.org/abs/2504.04770v1","title":"Bidirectional Hierarchical Protein Multi-Modal Representation Learning","summary":"Protein representation learning is critical for numerous biological tasks.\nRecently, large transformer-based protein language models (pLMs) pretrained on\nlarge scale protein sequences have demonstrated significant success in\nsequence-based tasks. However, pLMs lack structural information. Conversely,\ngraph neural networks (GNNs) designed to leverage 3D structural information\nhave shown promising generalization in protein-related prediction tasks, but\ntheir effectiveness is often constrained by the scarcity of labeled structural\ndata. Recognizing that sequence and structural representations are\ncomplementary perspectives of the same protein entity, we propose a multimodal\nbidirectional hierarchical fusion framework to effectively merge these\nmodalities. Our framework employs attention and gating mechanisms to enable\neffective interaction between pLMs-generated sequential representations and\nGNN-extracted structural features, improving information exchange and\nenhancement across layers of the neural network. Based on the framework, we\nfurther introduce local Bi-Hierarchical Fusion with gating and global\nBi-Hierarchical Fusion with multihead self-attention approaches. Through\nextensive experiments on a diverse set of protein-related tasks, our method\ndemonstrates consistent improvements over strong baselines and existing fusion\ntechniques in a variety of protein representation learning benchmarks,\nincluding react (enzyme/EC classification), model quality assessment (MQA),\nprotein-ligand binding affinity prediction (LBA), protein-protein binding site\nprediction (PPBS), and B cell epitopes prediction (BCEs). Our method\nestablishes a new state-of-the-art for multimodal protein representation\nlearning, emphasizing the efficacy of BIHIERARCHICAL FUSION in bridging\nsequence and structural modalities.","main_category":"cs.LG","categories":"cs.LG,cs.AI,q-bio.MN","published":"2025-04-07T06:47:49Z"}
{"aid":"http://arxiv.org/abs/2504.04777v1","title":"Dispersion in Rotating Electron-Positron-Ion Quantum Plasma","summary":"Quantum plasmas in astrophysical environments are abundant due to extreme\nelectric, magnetic, and gravitational fields. These plasmas can be most clearly\nobserved in neutron stars, white dwarfs, brown dwarfs, red dwarfs, accretion\ndisks of black holes, pulsars, quasars, and more. This paper examines the\npropagation of electromagnetic waves in a three-component e-p-i quantum plasma\nwithin a rotating frame, considering the particles' spin, Fermi pressure, and\nquantum Bohm potential. Additionally, effects unique to this specific\nenvironment, such as rotation and gravity, are included. The dispersion of\nelectrons, ions, and positrons has been obtained separately, and their coupling\nhas been analyzed to understand the collective behavior. It has been noted that\nthe quantum effects of Fermi pressure and Bohm potential significantly\ninfluence particle dynamics.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-07T07:09:37Z"}
{"aid":"http://arxiv.org/abs/2504.04844v1","title":"Embracing Dynamics: Dynamics-aware 4D Gaussian Splatting SLAM","summary":"Simultaneous localization and mapping (SLAM) technology now has\nphotorealistic mapping capabilities thanks to the real-time high-fidelity\nrendering capability of 3D Gaussian splatting (3DGS). However, due to the\nstatic representation of scenes, current 3DGS-based SLAM encounters issues with\npose drift and failure to reconstruct accurate maps in dynamic environments. To\naddress this problem, we present D4DGS-SLAM, the first SLAM method based on\n4DGS map representation for dynamic environments. By incorporating the temporal\ndimension into scene representation, D4DGS-SLAM enables high-quality\nreconstruction of dynamic scenes. Utilizing the dynamics-aware InfoModule, we\ncan obtain the dynamics, visibility, and reliability of scene points, and\nfilter stable static points for tracking accordingly. When optimizing Gaussian\npoints, we apply different isotropic regularization terms to Gaussians with\nvarying dynamic characteristics. Experimental results on real-world dynamic\nscene datasets demonstrate that our method outperforms state-of-the-art\napproaches in both camera pose tracking and map quality.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-07T08:56:35Z"}
{"aid":"http://arxiv.org/abs/2504.04863v1","title":"Dynamic hysteresis model of grain-oriented ferromagnetic material using\n  neural operators","summary":"Accurately capturing the behavior of grain-oriented (GO) ferromagnetic\nmaterials is crucial for modeling the electromagnetic devices. In this paper,\nneural operator models, including Fourier neural operator (FNO), U-net combined\nFNO (U-FNO) and Deep operator network (DeepONet) are used to approximate the\ndynamic hysteresis models of GO steel. Furthermore, two types of data\naugmentation strategies including cyclic rolling augmentation and Gaussian data\naugmentation (GDA) are implemented to enhance the learning ability of models.\nWith the inclusion of these augmentation techniques, the optimized models\naccount for not only the peak values of the magnetic flux density but also the\neffects of different frequencies and phase shifts. The accuracy of all models\nis assessed using the L2-norm of the test data and the mean relative error\n(MRE) of calculated core losses. Each model performs well in different\nscenarios, but FNO consistently achieves the best performance across all cases.","main_category":"eess.SY","categories":"eess.SY,cond-mat.mtrl-sci,cs.SY,physics.data-an","published":"2025-04-07T09:19:23Z"}
{"aid":"http://arxiv.org/abs/2504.04864v1","title":"Statistical parametric simulation studies based on real data","summary":"Simulation studies are indispensable for evaluating and comparing statistical\nmethods. The most common simulation approach is parametric simulation, where\nthe data-generating mechanism (DGM) corresponds to a predefined parametric\nmodel from which observations are drawn. Many statistical simulation studies\naim to provide practical recommendations on a method's suitability for a given\napplication; however, parametric simulations in particular are frequently\ncriticized for being too simplistic and not reflecting reality. To overcome\nthis drawback, it is generally considered a sensible approach to employ real\ndata for constructing the parametric DGMs. However, while the concept of\nreal-data-based parametric DGMs is widely recognized, the specific ways in\nwhich DGM components are inferred from real data vary, and their implications\nmay not always be well understood. Additionally, researchers often rely on a\nlimited selection of real datasets, with the rationale for their selection\noften unclear. This paper addresses these issues by formally discussing how\ncomponents of parametric DGMs can be inferred from real data and how dataset\nselection can be performed more systematically. By doing so, we aim to support\nresearchers in conducting simulation studies with a lower risk of\novergeneralization and misinterpretation. We illustrate the construction of\nparametric DGMs based on a systematically selected set of real datasets using\ntwo examples: one on ordinal outcomes in randomized controlled trials and one\non differential gene expression analysis.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-07T09:19:28Z"}
{"aid":"http://arxiv.org/abs/2504.04868v1","title":"On Scenario Formalisms for Automated Driving","summary":"The concept of scenario and its many qualifications -- specifically logical\nand abstract scenarios -- have emerged as a foundational element in\nsafeguarding automated driving systems. However, the original linguistic\ndefinitions of the different scenario qualifications were often applied\nambiguously, leading to a divergence between scenario description languages\nproposed or standardized in practice and their terminological foundation. This\nresulted in confusion about the unique features as well as strengths and\nweaknesses of logical and abstract scenarios. To alleviate this, we give clear\nlinguistic definitions for the scenario qualifications concrete, logical, and\nabstract scenario and propose generic, unifying formalisms using curves,\nmappings to sets of curves, and temporal logics, respectively. We demonstrate\nthat these formalisms allow pinpointing strengths and weaknesses precisely by\ncomparing expressiveness, specification complexity, sampling, and monitoring of\nlogical and abstract scenarios. Our work hence enables the practitioner to\ncomprehend the different scenario qualifications and identify a suitable\nformalism.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T09:23:46Z"}
{"aid":"http://arxiv.org/abs/2504.04902v1","title":"Constructibility real degrees in the side-by-side Sacks model","summary":"We study the join-semilattice of constructibility real degrees in the\nside-by-side Sacks model, the model of set theory obtained by forcing with a\ncountable-support product of infinitely many Sacks forcings over the\nconstructible universe. In particular, we prove that in the side-by-side Sacks\nmodel the join-semilattice of constructibility real degrees is rigid, i.e. it\ndoes not have non-trivial automorphisms.","main_category":"math.LO","categories":"math.LO","published":"2025-04-07T10:21:17Z"}
{"aid":"http://arxiv.org/abs/2504.04905v1","title":"Null geodesics around a magnetized Kiselev black hole","summary":"A new magnetically charged Kiselev black hole solution is used to study the\nnull geodesics in this spacetime. We derive the equations of motion for the\nnull geodesics and analyze their properties, including the gravitational\nlensing effect. The 3D and equatorial plane orbits are discussed, with\nparticular attention given to the effect of quintessence. The deviations from\nthe Ernst black hole provide insights into the potential observational\nconsequences of dark energy in strong gravitational fields.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-07T10:24:54Z"}
{"aid":"http://arxiv.org/abs/2504.04924v1","title":"Inter-event Interval Microscopy for Event Cameras","summary":"Event cameras, an innovative bio-inspired sensor, differ from traditional\ncameras by sensing changes in intensity rather than directly perceiving\nintensity and recording these variations as a continuous stream of \"events\".\nThe intensity reconstruction from these sparse events has long been a\nchallenging problem. Previous approaches mainly focused on transforming\nmotion-induced events into videos or achieving intensity imaging for static\nscenes by integrating modulation devices at the event camera acquisition end.\nIn this paper, for the first time, we achieve event-to-intensity conversion\nusing a static event camera for both static and dynamic scenes in fluorescence\nmicroscopy. Unlike conventional methods that primarily rely on event\nintegration, the proposed Inter-event Interval Microscopy (IEIM) quantifies the\ntime interval between consecutive events at each pixel. With a fixed threshold\nin the event camera, the time interval can precisely represent the intensity.\nAt the hardware level, the proposed IEIM integrates a pulse light modulation\ndevice within a microscope equipped with an event camera, termed Pulse\nModulation-based Event-driven Fluorescence Microscopy.mAdditionally, we have\ncollected IEIMat dataset under various scenes including high dynamic range and\nhigh-speed scenarios. Experimental results on the IEIMat dataset demonstrate\nthat the proposed IEIM achieves superior spatial and temporal resolution, as\nwell as a higher dynamic range, with lower bandwidth compared to other methods.\nThe code and the IEIMat dataset will be made publicly available.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-07T11:05:13Z"}
{"aid":"http://arxiv.org/abs/2504.04960v1","title":"Sign-changing multi-peak standing waves of the NLSE with a point\n  interaction","summary":"Consider the following semilinear problem with a point interaction in\n$\\mathbb{R}^N$: \\[- \\Delta_\\alpha u + \\omega u = u |u|^{p - 2},\\] where $N \\in\n\\{2, 3\\}$; $\\omega > 0$; $- \\Delta_\\alpha$ denotes the Hamiltonian of point\ninteraction with inverse $s$-wave scattering length $- (4 \\pi \\alpha)^{- 1}$\nand we want to solve for $u \\colon \\mathbb{R}^N \\to \\mathbb{R}$. By means of\nLyapunov--Schmidt reduction, we prove that this problem has sign-changing\nmulti-peak solutions when either (1) $N = 2$, $\\alpha \\in \\mathbb{R}$, $p_* < p\n\\leq 3$ and $\\omega$ is sufficiently large or (2) $N = 3$, $0 < \\alpha <\n\\infty$, $p_* < p < 3$ and $\\omega$ is sufficiently small, where $2.45 < p_* :=\n\\frac{9 + \\sqrt{113}}{8} < 2.46$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-07T11:48:47Z"}
{"aid":"http://arxiv.org/abs/2504.04993v1","title":"Duality invariance of Faltings heights, Hodge line bundles and global\n  periods","summary":"We prove that an abelian variety and its dual over a global field have the\nsame Faltings height and, more precisely, have isomorphic Hodge line bundles,\nincluding their natural metrized bundle structures. More carefully treating\nreal places, we also show that these abelian varieties have the same real and\nglobal periods that appear in the Birch-Swinnerton-Dyer conjecture.","main_category":"math.NT","categories":"math.NT,math.AG","published":"2025-04-07T12:18:31Z"}
{"aid":"http://arxiv.org/abs/2504.05007v1","title":"Measuring the right thing: justifying metrics in AI impact assessments","summary":"AI Impact Assessments are only as good as the measures used to assess the\nimpact of these systems. It is therefore paramount that we can justify our\nchoice of metrics in these assessments, especially for difficult to quantify\nethical and social values. We present a two-step approach to ensure metrics are\nproperly motivated. First, a conception needs to be spelled out (e.g. Rawlsian\nfairness or fairness as solidarity) and then a metric can be fitted to that\nconception. Both steps require separate justifications, as conceptions can be\njudged on how well they fit with the function of, for example, fairness. We\nargue that conceptual engineering offers helpful tools for this step. Second,\nmetrics need to be fitted to a conception. We illustrate this process through\nan examination of competing fairness metrics to illustrate that here the\nadditional content that a conception offers helps us justify the choice for a\nspecific metric. We thus advocate that impact assessments are not only clear on\ntheir metrics, but also on the conceptions that motivate those metrics.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.ET","published":"2025-04-07T12:32:41Z"}
{"aid":"http://arxiv.org/abs/2504.05027v1","title":"Indistinguishability of unbounded components in the occupied and vacant\n  sets of Boolean models on symmetric spaces","summary":"We study Boolean models on Riemannian symmetric spaces driven by homogeneous\ninsertion- or deletion-tolerant point processes. We prove that in both the set\ncovered by the balls (the occupied set) and its complement (the vacant set),\none cannot distinguish unbounded components from each other by any isometry\ninvariant component property. This implies the uniqueness monotonicity for the\noccupied and vacant sets of Poisson-Boolean models and an equivalence of\nnon-uniqueness to the decay of connectivity for both sets. These results are\ncontinuum analogues of those by Lyons and Schramm arXiv:math/9811170. However,\nunlike the proof of the indistinguishability in arXiv:math/9811170, our proof\ndoes not rely on transience of unbounded components. We also prove the\nexistence of a percolation phase transition for independent Poisson-Boolean\nmodel on unbounded connected components of both occupied and vacant sets and\nshow transience of a random walk on the occupied set. Apart from some technical\ndifferences, we treat the occupied and the vacant sets of Boolean models within\na single framework.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T12:51:14Z"}
{"aid":"http://arxiv.org/abs/2504.05031v1","title":"Analog phase-sensitive time-reversal of optically-carried radiofrequency\n  signals","summary":"Achieving low-latency time-reversal of broadband radiofrequency signals is\ncrucial for reliable communications in dynamic, uncontrolled environments.\nHowever, existing approaches are either digitally assisted -- making broadband\nextension challenging -- or limited to amplitude modulation. In this work, we\nreport the very first experimental realization of a fully analog,\nphase-preserving time-reversal architecture for optically-carried\nradiofrequency signals. The method exploits the exceptional coherence\nproperties of rare-earth ion-doped materials, and leverages the\nwell-established photon echo mechanism, widely used in quantum technologies.\nWhile our demonstration is conducted with a modest bandwidth, we identify the\nfundamental cause of this limitation and propose solutions for future\nscalability.","main_category":"physics.optics","categories":"physics.optics,physics.atom-ph,quant-ph","published":"2025-04-07T12:52:41Z"}
{"aid":"http://arxiv.org/abs/2504.05034v1","title":"Dominating Hyperplane Regularization for Variable Selection in\n  Multivariate Count Regression","summary":"Identifying relevant factors that influence the multinomial counts in\ncompositional data is difficult in high dimensional settings due to the complex\nassociations and overdispersion. Multivariate count models such as the\nDirichlet-multinomial (DM), negative multinomial, and generalized DM\naccommodate overdispersion but are difficult to optimize due to their\nnon-concave likelihood functions. Further, for the class of regression models\nthat associate covariates to the multivariate count outcomes, variable\nselection becomes necessary as the number of potentially relevant factors\nbecomes large. The sparse group lasso (SGL) is a natural choice for\nregularizing these models. Motivated by understanding the associations between\nwater quality and benthic macroinvertebrate compositions in Canada's Athabasca\noil sands region, we develop dominating hyperplane regularization (DHR), a\nnovel method for optimizing regularized regression models with the SGL penalty.\nUnder the majorization-minimization framework, we show that applying DHR to a\nSGL penalty gives rise to a surrogate function that can be expressed as a\nweighted ridge penalty. Consequently, we prove that for multivariate count\nregression models with the SGL penalty, the optimization leads to an\niteratively reweighted Poisson ridge regression. We demonstrate stable\noptimization and high performance of our algorithm through simulation and real\nworld application to benthic macroinvertebrate compositions.","main_category":"stat.ME","categories":"stat.ME,stat.AP","published":"2025-04-07T12:56:43Z"}
{"aid":"http://arxiv.org/abs/2504.05036v1","title":"Hybrid Nitsche for distributed computing","summary":"We extend the distributed finite element method of [1], built upon model\norder reduction, to arbitrary polynomial degree using a hybrid Nitsche scheme.\nThis new method considerably simplifies the transformation of the finite\nelement system to the reduced basis for large problems. We prove that the error\nof the reduced Nitsche solution converges optimally with respect to the\napproximation order of the finite element spaces and linearly with respect to\nthe dimension reduction parameter $\\epsilon$. Numerical tests with nontrivial\ntetrahedral meshes using second-degree polynomial bases support the theoretical\nresults.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-07T12:57:06Z"}
{"aid":"http://arxiv.org/abs/2504.05037v1","title":"Optimizing flow control with ensemble Kalman method for mitigating\n  flow-induced vibration","summary":"The ensemble Kalman method is introduced for optimizing flow control\nstrategies in order to mitigate the flow-induced vibration of structures.\nDifferent types of control strategies such as passive control, open-loop active\ncontrol, and closed-loop active control are tested, showing the flexibility of\nthe method in flow control optimization. The ensemble Kalman method is first\ntested to mitigate vortex shedding of flows around a circular cylinder by\noptimizing the placement of small cylinders downstream. Further, the method is\nassessed to suppress shock buffeting over the NACA 0012 airfoil by optimizing\nthe movement of a compliant aileron. Our results for all test cases show that\nthe ensemble-based method can effectively find optimal control strategies that\nsignificantly reduce the vibrations of aerodynamic force, and can be a useful\nalternative for flow control optimization, due to its merits in\nnon-intrusiveness and ease of implementation.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-07T12:59:43Z"}
{"aid":"http://arxiv.org/abs/2504.05054v1","title":"Small-mass solutions in a two-dimensional logarithmic\n  chemotaxis-Navier-Stokes system with indirect nutrient consumption","summary":"This paper is concerned with the singular chemotaxis-fluid system with\nindirect nutrient consumption: $\n  n_{t}+u\\cdot\\nabla n=\\Delta n-\\nabla\\cdot(n S(x,n,v)\\cdot \\nabla v);\\\n  v_{t}+u\\cdot\\nabla v=\\Delta v-vw;\\\n  w_{t}+u\\cdot\\nabla w=\\Delta w-w+n;\\\n  u_t+(u\\cdot\\nabla) u=\\Delta u-\\nabla P+n\\nabla\\Phi;\\ \\nabla\\cdot u=0\\ $\n  in a smooth bounded domain $\\Omega\\subset\\mathbb{R}^2$\n  under no-flux/Neumann/Neumann/Dirichlet boundary conditions, where $\\Phi\\in\nW^{2,\\infty}(\\Omega)$, and $S: \\overline{\\Omega}\\times [0,\\infty) \\times\n(0,\\infty)\\rightarrow\\mathbb{R}^{2\\times 2}$ is a suitably smooth function that\nsatisfies $|S(x,n,v)|\\leq S_0(v) /v $ for all $(x,n,v) \\in \\Omega\\times\n(0,\\infty)^2$ with some nondecreasing $S_0: (0,\\infty)\\rightarrow(0,\\infty)$.\n  For all reasonably regular initial data with a smallness assumption merely\ninvolving the quantity $\\int_\\Omega n_0$,\n  it is shown that the problem possesses a globally bounded classical solution,\nwhich, inter alia, exponentially stabilizes\n  toward the spatially homogeneous state $(\n\\frac{1}{|\\Omega|}\\int_{\\Omega}n_0,0,\\frac{1}{|\\Omega|}\\int_{\\Omega}n_0,0)$\nwith respect to the norm in $L^\\infty(\\Omega)$.\n  This rigorously confirms that, at least in the two-dimensional setting, in\ncomparison to the direct mechanism of nutrient consumption, an indirect\nmechanism can induce much more regularity of solutions to the chemotaxis--fluid\nsystem even with a singular tensor-valued sensitivity.","main_category":"math.AP","categories":"math.AP","published":"2025-04-07T13:25:09Z"}
{"aid":"http://arxiv.org/abs/2504.05059v1","title":"MIAT: Maneuver-Intention-Aware Transformer for Spatio-Temporal\n  Trajectory Prediction","summary":"Accurate vehicle trajectory prediction is critical for safe and efficient\nautonomous driving, especially in mixed traffic environments with both\nhuman-driven and autonomous vehicles. However, uncertainties introduced by\ninherent driving behaviors -- such as acceleration, deceleration, and left and\nright maneuvers -- pose significant challenges for reliable trajectory\nprediction. We introduce a Maneuver-Intention-Aware Transformer (MIAT)\narchitecture, which integrates a maneuver intention awareness mechanism with\nspatiotemporal interaction modeling to enhance long-horizon trajectory\npredictions. We systematically investigate the impact of varying awareness of\nmaneuver intention on both short- and long-horizon trajectory predictions.\nEvaluated on the real-world NGSIM dataset and benchmarked against various\ntransformer- and LSTM-based methods, our approach achieves an improvement of up\nto 4.7% in short-horizon predictions and a 1.6% in long-horizon predictions\ncompared to other intention-aware benchmark methods. Moreover, by leveraging an\nintention awareness control mechanism, MIAT realizes an 11.1% performance boost\nin long-horizon predictions, with a modest drop in short-horizon performance.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-07T13:30:00Z"}
{"aid":"http://arxiv.org/abs/2504.05061v1","title":"Topology of circular orbits of charged particles in black holes with\n  multiple horizons","summary":"The study of the topological properties of circular orbits is opening up new\nperspectives for exploring the spacetime structure around black holes. In this\nwork, we investigate how the charged properties of particles affect the\ntopological characteristics of circular orbits for charged test particles in\nasymptotically flat, AdS, and dS black holes. Our findings demonstrate that the\ncharged properties not only influence the topological properties of timelike\ncircular orbits but also impact those of null circular orbits. Additionally, we\nexplore scenarios involving multiple horizons and find that for a multi-horizon\nblack hole, if a circular orbit can exist between two neighboring horizons,\nthere will always be both a null circular orbit and a timelike circular orbit.\nWhether these orbits are stable or unstable depends on the potential function.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-07T13:33:31Z"}
{"aid":"http://arxiv.org/abs/2504.05091v1","title":"Morse Index Theorem for Sturm-Liouville Operators on the Real Line","summary":"The classical Morse index theorem establishes a fundamental connection\nbetween the Morse index-the number of negative eigenvalues that characterize\nkey spectral properties of linear self-adjoint differential operators-and the\ncount of corresponding conjugate points. In this paper, we extend these\nfoundational results to the Sturm-Liouville operator on $\\mathbb{R}$. In\nparticular, for autonomous Lagrangian systems, we employ a geometric argument\nto derive a lower bound for the Morse index. As concrete applications, we\nestablish a criterion for detecting instability in traveling waves within\ngradient reaction-diffusion systems.","main_category":"math.DS","categories":"math.DS","published":"2025-04-07T14:00:13Z"}
{"aid":"http://arxiv.org/abs/2504.05111v1","title":"Theory of quantum-enhanced interferometry with general Markovian light\n  sources","summary":"Quantum optical systems comprising quantum emitters interacting with\nengineered optical modes generate non-classical states of light that can be\nused as resource states for quantum-enhanced interferometry. However, outside\nof well-controlled systems producing either single-mode states (e.g. Fock\nstates or squeezed states) or highly symmetric multi-mode states (e.g.\nsuperradiant states), their potential for quantum advantage remains\nuncharacterized. In this work, we develop a framework to analyze quantum\nenhanced interferometry with general Markovian quantum light sources. First, we\nshow how to compute the quantum Fisher Information (QFI) of the photons emitted\nby a source efficiently by just tracking its internal dynamics and without\nexplicitly computing the state of the emitted photons. We then use this\nrelationship to elucidate the connection between the level structure and\nspectrum of the source to a potential quantum advantage in interferometry.\nFinally, we analyze optimal measurement protocols that can be used to achieve\nthis quantum advantage with experimentally available optical elements. In\nparticular, we show that tunable optical elements with Kerr non-linearity can\nalways be harnessed to implement the optimal measurement for any given source.\nSimultaneously, we also outline general conditions under which linear optics\nand photodetection is enough to implement the optimal measurement.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-07T14:15:36Z"}
{"aid":"http://arxiv.org/abs/2504.05114v1","title":"From Sound Workflow Nets to LTL$_f$ Declarative Specifications by\n  Casting Three Spells","summary":"In process management, effective behavior modeling is essential for\nunderstanding execution dynamics and identifying potential issues. Two\ncomplementary paradigms have emerged in the pursuit of this objective: the\nimperative approach, representing all allowed runs of a system in a graph-based\nmodel, and the declarative one, specifying the rules that a run must not\nviolate in a constraint-based specification. Extensive studies have been\nconducted on the synergy and comparisons of the two paradigms. To date, though,\nwhether a declarative specification could be systematically derived from an\nimperative model such that the original behavior was fully preserved (and if\nso, how) remained an unanswered question. In this paper, we propose a\nthree-fold contribution. (1) We introduce a systematic approach to synthesize\ndeclarative process specifications from safe and sound Workflow nets. (2) We\nprove behavioral equivalence of the input net with the output specification,\nalongside related guarantees. (3) We experimentally demonstrate the scalability\nand compactness of our encoding through tests conducted with synthetic and\nreal-world testbeds.","main_category":"cs.LO","categories":"cs.LO,cs.FL","published":"2025-04-07T14:17:34Z"}
{"aid":"http://arxiv.org/abs/2504.05143v1","title":"Taming Double-Spending in Offline Payments with Reputation-Weighted Loan\n  Networks","summary":"Blockchain solutions typically assume a synchronous network to ensure\nconsistency and achieve consensus. In contrast, offline transaction systems aim\nto enable users to agree on and execute transactions without assuming bounded\ncommunication delays when interacting with the blockchain. Most existing\noffline payment schemes depend on trusted hardware wallets that are assumed to\nbe secure and tamper-proof. While this work introduces Overdraft, a novel\noffline payment system that shifts the reliance from hardware to users\nthemselves. Overdraft allows potential payment receivers to assess the\nlikelihood of being paid, allowing them to accept transactions with confidence\nor deny them. Overdraft achieves this by maintaining a loan network that is\nweighted by online reputation. This loan network contains time-limited\nagreements where users pledge to cover another user's payment if necessary. For\nexample, when a payer lacks sufficient funds at the moment of commitment.\nOffline users rely on the last known view of the loan network -- which they had\naccess to when last online -- to determine whether to participate in an offline\ntransaction. This view is used to estimate the probability of eventual payment,\npossibly using multiple loans. Once online again, users commit their\ntransactions to the blockchain with any conflicts being resolved\ndeterministically. Overdraft incorporates incentives for users and is designed\nto be resilient against Sybil attacks. As a proof of concept, we implemented\nOverdraft as an Ethereum Solidity smart contract and deployed it on the Sepolia\ntestnet to evaluate its performance.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-07T14:48:19Z"}
{"aid":"http://arxiv.org/abs/2504.05156v1","title":"Blending Queries and Conversations: Understanding Tactics, Trust,\n  Verification, and System Choice in Web Search and Chat Interactions","summary":"This paper presents a user study (N=22) where participants used an interface\ncombining Web Search and a Generative AI-Chat feature to solve health-related\ninformation tasks. We study how people behaved with the interface, why they\nbehaved in certain ways, and what the outcomes of these behaviours were. A\nthink-aloud protocol captured their thought processes during searches. Our\nfindings suggest that GenAI is neither a search panacea nor a major regression\ncompared to standard Web Search interfaces. Qualitative and quantitative\nanalyses identified 78 tactics across five categories and provided insight into\nhow and why different interface features were used. We find evidence that\npre-task confidence and trust both influenced which interface feature was used.\nIn both systems, but particularly when using the chat feature, trust was often\nmisplaced in favour of ease-of-use and seemingly perfect answers, leading to\nincreased confidence post-search despite having incorrect results. We discuss\nwhat our findings mean in the context of our defined research questions and\noutline several open questions for future research.","main_category":"cs.HC","categories":"cs.HC,cs.IR","published":"2025-04-07T14:59:55Z"}
{"aid":"http://arxiv.org/abs/2504.05180v1","title":"BRIDGES: Bridging Graph Modality and Large Language Models within EDA\n  Tasks","summary":"While many EDA tasks already involve graph-based data, existing LLMs in EDA\nprimarily either represent graphs as sequential text, or simply ignore\ngraph-structured data that might be beneficial like dataflow graphs of RTL\ncode. Recent studies have found that LLM performance suffers when graphs are\nrepresented as sequential text, and using additional graph information\nsignificantly boosts performance. To address these challenges, we introduce\nBRIDGES, a framework designed to incorporate graph modality into LLMs for EDA\ntasks. BRIDGES integrates an automated data generation workflow, a solution\nthat combines graph modality with LLM, and a comprehensive evaluation suite.\nFirst, we establish an LLM-driven workflow to generate RTL and netlist-level\ndata, converting them into dataflow and netlist graphs with function\ndescriptions. This workflow yields a large-scale dataset comprising over\n500,000 graph instances and more than 1.5 billion tokens. Second, we propose a\nlightweight cross-modal projector that encodes graph representations into\ntext-compatible prompts, enabling LLMs to effectively utilize graph data\nwithout architectural modifications. Experimental results demonstrate 2x to 10x\nimprovements across multiple tasks compared to text-only baselines, including\naccuracy in design retrieval, type prediction and perplexity in function\ndescription, with negligible computational overhead (<1% model weights increase\nand <30% additional runtime overhead). Even without additional LLM finetuning,\nour results outperform text-only by a large margin. We plan to release BRIDGES,\nincluding the dataset, models, and training flow.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-07T15:27:32Z"}
{"aid":"http://arxiv.org/abs/2504.05184v1","title":"MSA-UNet3+: Multi-Scale Attention UNet3+ with New Supervised\n  Prototypical Contrastive Loss for Coronary DSA Image Segmentation","summary":"The accurate segmentation of coronary Digital Subtraction Angiography (DSA)\nimages is essential for diagnosing and treating coronary artery diseases.\nDespite advances in deep learning-based segmentation, challenges such as low\ncontrast, noise, overlapping structures, high intra-class variance, and class\nimbalance limit precise vessel delineation. To overcome these limitations, we\npropose the MSA-UNet3+: a Multi-Scale Attention enhanced UNet3+ architecture\nfor coronary DSA image segmentation. The framework combined Multi-Scale Dilated\nBottleneck (MSD-Bottleneck) with Contextual Attention Fusion Module (CAFM),\nwhich not only enhances multi-scale feature extraction but also preserve\nfine-grained details, and improve contextual understanding. Furthermore, we\npropose a new Supervised Prototypical Contrastive Loss (SPCL), which combines\nsupervised and prototypical contrastive learning to minimize class imbalance\nand high intra-class variance by focusing on hard-to-classified background\nsamples. Experiments carried out on a private coronary DSA dataset demonstrate\nthat MSA-UNet3+ outperforms state-of-the-art methods, achieving a Dice\ncoefficient of 87.73%, an F1-score of 87.78%, and significantly reduced Average\nSurface Distance (ASD) and Average Contour Distance (ACD). The developed\nframework provides clinicians with precise vessel segmentation, enabling\naccurate identification of coronary stenosis and supporting informed diagnostic\nand therapeutic decisions. The code will be released at the following GitHub\nprofile link https://github.com/rayanmerghani/MSA-UNet3plus.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T15:35:30Z"}
{"aid":"http://arxiv.org/abs/2504.05188v1","title":"Breakdown of Bulk-Radiation Correspondence in Radiative Photonic\n  Lattices","summary":"The topological characteristics of energy bands in crystalline systems are\nencapsulated in the Berry curvature of the bulk Bloch states. In photonic\ncrystal slabs, far-field emission from guided resonances naturally provides a\nnon-invasive way to probe the embedded wavefunctions, raising the question of\nhow the information carried by escaping photons relates to the band topology.\nWe develop a non-Hermitian model to describe the guided and leaky modes of\nphotonic crystal slabs with long-range couplings and non-local responses.\nWithin this framework, radiation Berry curvature is defined from the far-field\npolarization and compared to the conventional bulk Berry curvature of the\ncrystal Bloch modes. We investigate this bulk-radiation correspondence in the\nvicinity of the $\\Gamma$-point of the square lattice and the $K$-point of the\nhoneycomb lattice. The results show that the comparability between the bulk\ntopology and the radiation topology is not universal; the validity is\ncontingent upon the specific bulk Bloch states. Notably, the correspondence\ncompletely breaks down surrounding the far-field singularities, while it can\nhold in smooth regions under special symmetry conditions, e.g., rotational\nsymmetry. Besides, net Berry curvature concentration is captured at the valleys\nof the non-local honeycomb lattice, facilitating further exploration on\ngeneralized topological phases in photonic lattices beyond the regimes with\nlocalized couplings and Hermiticity.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mes-hall","published":"2025-04-07T15:40:02Z"}
{"aid":"http://arxiv.org/abs/2504.05216v1","title":"Unleashing the Power of LLMs in Dense Retrieval with Query Likelihood\n  Modeling","summary":"Dense retrieval is a crucial task in Information Retrieval (IR) and is the\nfoundation for downstream tasks such as re-ranking. Recently, large language\nmodels (LLMs) have shown compelling semantic understanding capabilities and are\nappealing to researchers studying dense retrieval. LLMs, as decoder-style\ngenerative models, are competent at language generation while falling short on\nmodeling global information due to the lack of attention to tokens afterward.\nInspired by the classical word-based language modeling approach for IR, i.e.,\nthe query likelihood (QL) model, we seek to sufficiently utilize LLMs'\ngenerative ability by QL maximization. However, instead of ranking documents\nwith QL estimation, we introduce an auxiliary task of QL maximization to yield\na better backbone for contrastively learning a discriminative retriever. We\nname our model as LLM-QL. To condense global document semantics to a single\nvector during QL modeling, LLM-QL has two major components, Attention Stop (AS)\nand Input Corruption (IC). AS stops the attention of predictive tokens to\nprevious tokens until the ending token of the document. IC masks a portion of\ntokens in the input documents during prediction. Experiments on MSMARCO show\nthat LLM-QL can achieve significantly better performance than other LLM-based\nretrievers and using QL estimated by LLM-QL for ranking outperforms word-based\nQL by a large margin.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.CL","published":"2025-04-07T16:03:59Z"}
{"aid":"http://arxiv.org/abs/2504.05229v1","title":"FinGrAct: A Framework for FINe-GRrained Evaluation of ACTionability in\n  Explainable Automatic Fact-Checking","summary":"The field of explainable Automatic Fact-Checking (AFC) aims to enhance the\ntransparency and trustworthiness of automated fact-verification systems by\nproviding clear and comprehensible explanations. However, the effectiveness of\nthese explanations depends on their actionability --their ability to empower\nusers to make informed decisions and mitigate misinformation. Despite\nactionability being a critical property of high-quality explanations, no prior\nresearch has proposed a dedicated method to evaluate it. This paper introduces\nFinGrAct, a fine-grained evaluation framework that can access the web, and it\nis designed to assess actionability in AFC explanations through well-defined\ncriteria and an evaluation dataset. FinGrAct surpasses state-of-the-art (SOTA)\nevaluators, achieving the highest Pearson and Kendall correlation with human\njudgments while demonstrating the lowest ego-centric bias, making it a more\nrobust evaluation approach for actionability evaluation in AFC.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T16:14:27Z"}
{"aid":"http://arxiv.org/abs/2504.05251v1","title":"Rationalizing dynamic choices","summary":"An analyst observes an agent take a sequence of actions. The analyst does not\nhave access to the agent's information and ponders whether the observed actions\ncould be justified through a rational Bayesian model with a known utility\nfunction. We show that the observed actions cannot be justified if and only if\nthere is a single deviation argument that leaves the agent better off,\nregardless of the information. The result is then extended to allow for\ndistributions over possible action sequences. Four applications are presented:\nmonotonicity of rationalization with risk aversion, a potential rejection of\nthe Bayesian model with observable data, feasible outcomes in dynamic\ninformation design, and partial identification of preferences without\nassumptions on information.","main_category":"econ.TH","categories":"econ.TH,econ.EM","published":"2025-04-07T16:43:26Z"}
{"aid":"http://arxiv.org/abs/2504.05252v1","title":"Topological Hall effect in ferromagnetic Weyl semimetal Mn$_5$Ge$_3$\n  originating in competing dipolar interaction and magnetocrystalline\n  anisotropy","summary":"We report the anomalous and topological Hall effect of the ferromagnetic Weyl\nsemimetal Mn$_5$Ge$_3$. We observe a significant anisotropic anomalous Hall\neffect (AHE) due to nonzero Berry curvature in the momentum space, such that\nthe anomalous Hall conductivity (AHC) is 965 S/cm for the $xy$-plane and 233\nS/cm for the $zx$-plane of the single crystal. The band structure calculations\npredict several Weyl and nodal points span across the momentum space, gapped\nout under the spin-orbit coupling effect, leading to significant $k$-space\nBerry curvature and large AHC. Experimentally, we also demonstrate a sizeable\ntopological Hall effect that is originated by the non-coplanar chiral spin\nstructure due to the competition between the out-of-plane uniaxial\nmagnetocrystalline anisotropy and the dipole-dipole interaction between two Mn\nsublattices. This study hints at the importance of dipole-dipole interactions\nin producing the skyrmion lattice in Mn$_5$Ge$_3$.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-07T16:44:26Z"}
{"aid":"http://arxiv.org/abs/2504.05291v1","title":"Using Physiological Measures, Gaze, and Facial Expressions to Model\n  Human Trust in a Robot Partner","summary":"With robots becoming increasingly prevalent in various domains, it has become\ncrucial to equip them with tools to achieve greater fluency in interactions\nwith humans. One of the promising areas for further exploration lies in human\ntrust. A real-time, objective model of human trust could be used to maximize\nproductivity, preserve safety, and mitigate failure. In this work, we attempt\nto use physiological measures, gaze, and facial expressions to model human\ntrust in a robot partner. We are the first to design an in-person, human-robot\nsupervisory interaction study to create a dedicated trust dataset. Using this\ndataset, we train machine learning algorithms to identify the objective\nmeasures that are most indicative of trust in a robot partner, advancing trust\nprediction in human-robot interactions. Our findings indicate that a\ncombination of sensor modalities (blood volume pulse, electrodermal activity,\nskin temperature, and gaze) can enhance the accuracy of detecting human trust\nin a robot partner. Furthermore, the Extra Trees, Random Forest, and Decision\nTrees classifiers exhibit consistently better performance in measuring the\nperson's trust in the robot partner. These results lay the groundwork for\nconstructing a real-time trust model for human-robot interaction, which could\nfoster more efficient interactions between humans and robots.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T17:45:17Z"}
{"aid":"http://arxiv.org/abs/2504.05626v1","title":"Remarks on the locality of generalized global symmetries","summary":"We examine generalized global symmetries as a kind of compactly supported\ncohomology, and so are led to revisit questions about the locality of quantum\nfield theory, following Segal. Physics naturally suggests a generalization of\nfactorization algebras, aimed at capturing nonperturbative information, and we\nexplain how higher group symmetries offer examples of this generalization,\nproviding an extension of the nonabelian Poincar\\'e duality of Salvatore and\nLurie. Finally, we explore how continuous generalized symmetries and anomalies\ncan be cast in this framework.","main_category":"math-ph","categories":"math-ph,hep-th,math.AT,math.MP","published":"2025-04-08T03:02:00Z"}
{"aid":"http://arxiv.org/abs/2504.05647v1","title":"Phase transitions of the Erdős-Gyárfás function","summary":"Given positive integers $p,q$. For any integer $k\\ge2$, an edge coloring of\nthe complete $k$-graph $K_n^{(k)}$ is said to be a $(p,q)$-coloring if every\ncopy of $K_p^{(k)}$ receives at least $q$ colors. The Erd\\H{o}s-Gy\\'{a}rf\\'{a}s\nfunction $f_k(n,p,q)$ is the minimum number of colors that are needed for\n$K_n^{(k)}$ to have a $(p,q)$-coloring.\n  Conlon, Fox, Lee and Sudakov (\\emph{IMRN, 2015}) conjectured that for any\npositive integers $p, k$ and $i$ with $k\\ge3$ and $1\\le i<k$,\n$f_k(n,p,{{p-i}\\choose{k-i}})=(\\log_{(i-1)}n)^{o(1)}$, where $\\log_{(i)}n$ is\nan iterated $i$-fold logarithm in $n$. It has been verified to be true for\n$k=3, p=4, i=1$ by Conlon et. al (\\emph{IMRN, 2015}), for $k=3, p=5, i=2$ by\nMubayi (\\emph{JGT, 2016}), and for all $k\\ge 4, p=k+1,i=1$ by B. Janzer and O.\nJanzer (\\emph{JCTB, 2024}). In this paper, we give new constructions and show\nthat this conjecture holds for infinitely many new cases, i.e., it holds for\nall $k\\ge4$, $p=k+2$ and $i=k-1$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-08T03:49:05Z"}
{"aid":"http://arxiv.org/abs/2504.05699v1","title":"Spacetime Models for Cosmology","summary":"I revisit Roberto Torretti's \"Spacetime Models for the World\" [SHPMP 31\n(2):171-186 (2000)] in the light of more recent work in (philosophy of)\ncosmology. I discuss the motivations for FLRW spacetimes as a natural starting\npoint for inquiry, and I suggest contemporary cosmologists can avoid the\nrationalism that Torretti attributes to Einstein's early work in relativistic\ncosmology. I then discuss the senses in which FLRW models are idealized, and I\nshow how those idealizations (and partial de-idealizations) have contributed to\nour understanding of the universe.","main_category":"physics.hist-ph","categories":"physics.hist-ph,gr-qc","published":"2025-04-08T05:42:20Z"}
{"aid":"http://arxiv.org/abs/2504.05715v1","title":"On the evidence of a dark matter density spike around the primary black\n  hole in OJ 287","summary":"The central engine of blazar OJ~287 is arguably the most notable supermassive\nblack hole (SMBH) binary candidate that emits nano-Hertz (nHz) gravitational\nwaves. This inference is mainly due to our ability to predict and successfully\nmonitor certain quasi-periodic doubly peaked high brightness flares with a\nperiod of $\\sim$12 years from this blazer. The use of post-Newtonian accurate\nSMBH binary orbital description that includes the effects of higher order GW\nemission turned out to be a crucial ingredient for accurately predicting the\nepochs of such Bremsstrahlung flares in our SMBH binary central engine\ndescription for OJ~287. It was very recently argued that one should include the\neffects of dynamical friction, induced by certain dark matter density spikes\naround the primary SMBH, to explain the {\\it observed} decay of SMBH binary\norbit in OJ~287. Invoking binary pulsar timing-based arguments, measurements,\nand OJ~287's orbital description, we show that observationally relevant SMBH\nbinary orbital dynamics in OJ~287 are insensitive to dark matter-induced\ndynamical friction effects. This implies that we could only provide an upper\nbound on the spike index parameter rather than obtaining an observationally\nderived value, as argued by \\cite{Chan2024}.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.GA,gr-qc","published":"2025-04-08T06:26:50Z"}
{"aid":"http://arxiv.org/abs/2504.05755v1","title":"Unraveling Human-AI Teaming: A Review and Outlook","summary":"Artificial Intelligence (AI) is advancing at an unprecedented pace, with\nclear potential to enhance decision-making and productivity. Yet, the\ncollaborative decision-making process between humans and AI remains\nunderdeveloped, often falling short of its transformative possibilities. This\npaper explores the evolution of AI agents from passive tools to active\ncollaborators in human-AI teams, emphasizing their ability to learn, adapt, and\noperate autonomously in complex environments. This paradigm shifts challenges\ntraditional team dynamics, requiring new interaction protocols, delegation\nstrategies, and responsibility distribution frameworks. Drawing on Team\nSituation Awareness (SA) theory, we identify two critical gaps in current\nhuman-AI teaming research: the difficulty of aligning AI agents with human\nvalues and objectives, and the underutilization of AI's capabilities as genuine\nteam members. Addressing these gaps, we propose a structured research outlook\ncentered on four key aspects of human-AI teaming: formulation, coordination,\nmaintenance, and training. Our framework highlights the importance of shared\nmental models, trust-building, conflict resolution, and skill adaptation for\neffective teaming. Furthermore, we discuss the unique challenges posed by\nvarying team compositions, goals, and complexities. This paper provides a\nfoundational agenda for future research and practical design of sustainable,\nhigh-performing human-AI teams.","main_category":"cs.HC","categories":"cs.HC,cs.AI,econ.GN,q-fin.EC","published":"2025-04-08T07:37:25Z"}
{"aid":"http://arxiv.org/abs/2504.05777v1","title":"Monte-Carlo based model for the extraction of oil from oil-water\n  mixtures using wetting and surface acoustic waves","summary":"This work presents a Monte Carlo (MC) based microscopic model for simulating\nthe extraction of oil from oil-in-water emulsions under the influence of\nsurface acoustic waves (SAWs). The proposed model is a two-dimensional\nIsing-lattice gas model that employs Kawasaki dynamics to mimic the\ninteractions between oil, water, and air, as well as external forces such as\ngravity and acoustic stress. By incorporating both acoustic streaming and\nacoustic radiation pressure, the model captures key experimental observations,\nincluding selective oil extraction and droplet motion under SAW excitation. The\nresults highlight the critical role of acoustic radiation pressure in enabling\noil film formation and detachment, governed by the balance between capillary\nand acoustic stresses. The study provides qualitative agreement with\nexperimental findings and offers insights into the essential mechanisms driving\nacoustowetting-induced phase separation, demonstrating the utility of discrete\nmodeling for complex fluid dynamics problems.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-08T07:59:18Z"}
{"aid":"http://arxiv.org/abs/2504.05778v1","title":"Residual U-Net for accurate and efficient prediction of hemodynamics in\n  two-dimensional asymmetric stenosis","summary":"This study presents residual U-Net (U-ResNet), a deep learning surrogate\nmodel for predicting hemodynamic fields in two-dimensional asymmetric stenotic\nchannels at Reynolds numbers ranging from 200 to 800. By integrating residual\nconnections with multi-scale feature extraction, U-ResNet achieves exceptional\naccuracy while significantly reducing computational costs compared to\ncomputational fluid dynamics (CFD) approaches. Comprehensive evaluation against\nU-Net, Fourier Neural Operator (FNO), and U-Net enhanced Fourier Neural\nOperator demonstrates U-ResNet's superior performance in capturing sharp\nhemodynamic gradients and complex flow features. Notably, U-ResNet demonstrates\nrobust generalization to interpolated Reynolds numbers without retraining - a\ncapability rarely achieved in existing models. The model's non-dimensional\nformulation ensures scalability across vessel sizes and anatomical locations,\nenhancing its applicability to diverse clinical scenarios. Statistical analysis\nof prediction errors reveals that U-ResNet maintains substantially narrower\nerror distributions compared to spectral methods, confirming its reliability\nfor critical hemodynamic assessment. These advances position U-ResNet as a\npromising tool for real-time clinical decision support, treatment planning, and\nmedical device optimization, with future work focusing on extension to\nthree-dimensional geometries and integration with patient-specific data.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,physics.bio-ph,physics.comp-ph","published":"2025-04-08T07:59:19Z"}
{"aid":"http://arxiv.org/abs/2504.05781v1","title":"Building Proactive and Instant-Reactive Safety Designs to Address\n  Harassment in Social Virtual Reality","summary":"Social Virtual Reality (VR) games offer immersive socialization experiences\nbut pose significant challenges of harassment. Common solutions, such as\nreporting and moderation, address harassment after it happens but fail to\nprevent or stop harassment in the moment. In this study, we explore and design\nproactive and instant-reactive safety designs to mitigate harassment in social\nVR. Proactive designs prevent harassment from occurring, while instant-reactive\ndesigns minimize harm during incidents. We explore three directions for design:\nuser-initiated personal bubbles, clarifying social norms, and encouraging\nbystander intervention. Through an iterative process, we first conducted a\nformative interview study to determine design goals for making these features\neffective, fit user needs, and robust to manipulation. We then implemented\nPuffer, an integrated safety system that includes a suite of proactive and\ninstant-reactive features, as a social VR prototype. From an evaluation using\nsimulated scenarios with participants, we find evidence that Puffer can help\nprotect players during emergencies, foster prosocial norms, and create more\npositive social interactions. We conclude by discussing how system safety\nfeatures can be designed to complement existing proactive and instant-reactive\nstrategies, particularly for people with marginalized identities.","main_category":"cs.HC","categories":"cs.HC,cs.CY","published":"2025-04-08T08:05:11Z"}
{"aid":"http://arxiv.org/abs/2504.05782v1","title":"MDK12-Bench: A Multi-Discipline Benchmark for Evaluating Reasoning in\n  Multimodal Large Language Models","summary":"Multimodal reasoning, which integrates language and visual cues into problem\nsolving and decision making, is a fundamental aspect of human intelligence and\na crucial step toward artificial general intelligence. However, the evaluation\nof multimodal reasoning capabilities in Multimodal Large Language Models\n(MLLMs) remains inadequate. Most existing reasoning benchmarks are constrained\nby limited data size, narrow domain coverage, and unstructured knowledge\ndistribution. To close these gaps, we introduce MDK12-Bench, a\nmulti-disciplinary benchmark assessing the reasoning capabilities of MLLMs via\nreal-world K-12 examinations. Spanning six disciplines (math, physics,\nchemistry, biology, geography, and information science), our benchmark\ncomprises 140K reasoning instances across diverse difficulty levels from\nprimary school to 12th grade. It features 6,827 instance-level knowledge point\nannotations based on a well-organized knowledge structure, detailed answer\nexplanations, difficulty labels and cross-year partitions, providing a robust\nplatform for comprehensive evaluation. Additionally, we present a novel dynamic\nevaluation framework to mitigate data contamination issues by bootstrapping\nquestion forms, question types, and image styles during evaluation. Extensive\nexperiment on MDK12-Bench reveals the significant limitation of current MLLMs\nin multimodal reasoning. The findings on our benchmark provide insights into\nthe development of the next-generation models. Our data and codes are available\nat https://github.com/LanceZPF/MDK12.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-08T08:06:53Z"}
{"aid":"http://arxiv.org/abs/2504.05783v1","title":"Video Flow as Time Series: Discovering Temporal Consistency and\n  Variability for VideoQA","summary":"Video Question Answering (VideoQA) is a complex video-language task that\ndemands a sophisticated understanding of both visual content and temporal\ndynamics. Traditional Transformer-style architectures, while effective in\nintegrating multimodal data, often simplify temporal dynamics through\npositional encoding and fail to capture non-linear interactions within video\nsequences. In this paper, we introduce the Temporal Trio Transformer (T3T), a\nnovel architecture that models time consistency and time variability. The T3T\nintegrates three key components: Temporal Smoothing (TS), Temporal Difference\n(TD), and Temporal Fusion (TF). The TS module employs Brownian Bridge for\ncapturing smooth, continuous temporal transitions, while the TD module\nidentifies and encodes significant temporal variations and abrupt changes\nwithin the video content. Subsequently, the TF module synthesizes these\ntemporal features with textual cues, facilitating a deeper contextual\nunderstanding and response accuracy. The efficacy of the T3T is demonstrated\nthrough extensive testing on multiple VideoQA benchmark datasets. Our results\nunderscore the importance of a nuanced approach to temporal modeling in\nimproving the accuracy and depth of video-based question answering.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-08T08:08:03Z"}
{"aid":"http://arxiv.org/abs/2504.05789v1","title":"Leveraging Synthetic Adult Datasets for Unsupervised Infant Pose\n  Estimation","summary":"Human pose estimation is a critical tool across a variety of healthcare\napplications. Despite significant progress in pose estimation algorithms\ntargeting adults, such developments for infants remain limited. Existing\nalgorithms for infant pose estimation, despite achieving commendable\nperformance, depend on fully supervised approaches that require large amounts\nof labeled data. These algorithms also struggle with poor generalizability\nunder distribution shifts. To address these challenges, we introduce SHIFT:\nLeveraging SyntHetic Adult Datasets for Unsupervised InFanT Pose Estimation,\nwhich leverages the pseudo-labeling-based Mean-Teacher framework to compensate\nfor the lack of labeled data and addresses distribution shifts by enforcing\nconsistency between the student and the teacher pseudo-labels. Additionally, to\npenalize implausible predictions obtained from the mean-teacher framework, we\nincorporate an infant manifold pose prior. To enhance SHIFT's self-occlusion\nperception ability, we propose a novel visibility consistency module for\nimproved alignment of the predicted poses with the original image. Extensive\nexperiments on multiple benchmarks show that SHIFT significantly outperforms\nexisting state-of-the-art unsupervised domain adaptation (UDA) pose estimation\nmethods by 5% and supervised infant pose estimation methods by a margin of 16%.\nThe project page is available at: https://sarosijbose.github.io/SHIFT.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T08:13:38Z"}
{"aid":"http://arxiv.org/abs/2504.05798v1","title":"A Simple yet Highly Accurate Prediction-Correction Algorithm for\n  Time-Varying Optimization","summary":"This paper proposes a simple yet highly accurate prediction-correction\nalgorithm, SHARP, for unconstrained time-varying optimization problems. Its\nprediction is based on an extrapolation derived from the Lagrange interpolation\nof past solutions. Since this extrapolation can be computed without Hessian\nmatrices or even gradients, the computational cost is low. To ensure the\nstability of the prediction, the algorithm includes an acceptance condition\nthat rejects the prediction when the update is excessively large. The proposed\nmethod achieves a tracking error of $O(h^{p})$, where $h$ is the sampling\nperiod, assuming that the $p$th derivative of the target trajectory is bounded\nand the convergence of the correction step is locally linear. We also prove\nthat the method can track a trajectory of stationary points even if the\nobjective function is non-convex. Numerical experiments demonstrate the high\naccuracy of the proposed algorithm.","main_category":"math.OC","categories":"math.OC","published":"2025-04-08T08:26:24Z"}
{"aid":"http://arxiv.org/abs/2504.05808v1","title":"Fast Sphericity and Roundness approximation in 2D and 3D using Local\n  Thickness","summary":"Sphericity and roundness are fundamental measures used for assessing object\nuniformity in 2D and 3D images. However, using their strict definition makes\ncomputation costly. As both 2D and 3D microscopy imaging datasets grow larger,\nthere is an increased demand for efficient algorithms that can quantify\nmultiple objects in large volumes. We propose a novel approach for extracting\nsphericity and roundness based on the output of a local thickness algorithm.\nFor sphericity, we simplify the surface area computation by modeling objects as\nspheroids/ellipses of varying lengths and widths of mean local thickness. For\nroundness, we avoid a complex corner curvature determination process by\napproximating it with local thickness values on the contour/surface of the\nobject. The resulting methods provide an accurate representation of the exact\nmeasures while being significantly faster than their existing implementations.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T08:40:50Z"}
{"aid":"http://arxiv.org/abs/2504.05819v1","title":"Nonparametric local polynomial regression for functional covariates","summary":"We consider nonparametric regression with functional covariates, that is,\nthey are elements of an infinite-dimensional Hilbert space. A locally\npolynomial estimator is constructed, where an orthonormal basis and various\ntuning parameters remain to be selected. We provide a general asymptotic upper\nbound on the estimation error and show that this procedure achieves polynomial\nconvergence rates under appropriate tuning and supersmoothness of the\nregression function. Such polynomial convergence rates have usually been\nconsidered to be non-attainable in nonparametric functional regression without\nany additional strong structural constraints such as linearity of the\nregression function.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-08T09:02:02Z"}
{"aid":"http://arxiv.org/abs/2504.05826v1","title":"Work statistics and thermal phase transitions","summary":"The investigation of nonequilibrium thermodynamics in quantum many-body\nsystems underscores the importance of quantum work, which differs from its\nclassical counterpart due to its statistical nature. Recent studies have shown\nthat quantum work can serve as an effective indicator of quantum phase\ntransitions in systems subjected to sudden quenches. However, the potential of\nquantum work to identify thermal phase transitions remains largely unexplored.\nIn this paper, we examine several types of thermal phase transitions in a\nsudden-quench hard-core boson model, including Ising, three-state Potts, and\nBerezinskii-Kosterlitz-Thouless transitions. Through finite-size scaling\nanalysis, we conclude that work statistics can also characterize the critical\nbehaviors of thermal phase transitions in generic many-body systems. Our\ninvestigation paves the way for applying work statistics to characterize\ncritical behavior in many-body systems, with implications that may extend to\nbroader contexts.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-08T09:08:01Z"}
{"aid":"http://arxiv.org/abs/2504.05858v1","title":"Structural and Electrical Transport Properties of NASICON type\n  Na$_{3}$Zr$_{2-x}$Ti$_{x}$Si$_2$PO$_{\\rm 12}$ ($x=$ 0.1-0.4) Solid\n  Electrolyte Materials","summary":"We report the structural, resistivity, impedance, and dielectric studies of\nisovalent substituted Na$_{3}$Zr$_{2-x}$Ti$_{x}$Si$_2$PO$_{\\rm 12}$ ($x=$\n0.1--0.4) NASICON type solid electrolyte materials. The Rietveld refinement of\nXRD patterns shows the monoclinic phase with space group of C 2/c for all the\nsamples. The resistivity analysis shows the Arrhenius-type thermal conduction\nwith an increase in activation energy with doping is explained based on\ndecreased unit cell volume. We use Maxwell-Wagner-Sillars (MWS) relaxation and\nspace charge or interfacial polarization models to explain the frequency and\ntemperature-dependent variations of electric permittivity. The double\nrelaxation peaks in the dielectric loss data show the two types of relaxation\nmechanisms of different activation energy. The real ($\\epsilon^{'}$) and\nimaginary ($\\epsilon^{''}$) parts of permittivity are fitted using the modified\nCole-Cole equation, including the conductivity term, which show the non-Debye\ntype relaxation over the measured frequency and temperature range. The\nimpedance analysis shows the contributions from grain and grain boundary\nrelaxation. The fitting performed using the impedance and constant-phase\nelement (CPE) confirm the non-Debye type relaxation. Moreover, the electric\nmodulus analysis confirms the ionic nature having thermally activated\nrelaxation and the modulus scaling analysis shows a similar type of relaxation\nin the measured temperature range. The modified power law is used to understand\nthe frequency dependence of {\\it a.c.} conductivity data. The temperature\ndependence of exponent ($s$) in modified power law suggests the change in the\nconduction mechanism from near small polaron tunneling (NSPT) to correlated\nbarrier hopping (CBH) above room temperature. The larger values of\n$\\epsilon$$_{r}$ indicate these materials as a potential candidate for\ncharge-storage devices.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T09:36:05Z"}
{"aid":"http://arxiv.org/abs/2504.05878v1","title":"KAN-SAM: Kolmogorov-Arnold Network Guided Segment Anything Model for\n  RGB-T Salient Object Detection","summary":"Existing RGB-thermal salient object detection (RGB-T SOD) methods aim to\nidentify visually significant objects by leveraging both RGB and thermal\nmodalities to enable robust performance in complex scenarios, but they often\nsuffer from limited generalization due to the constrained diversity of\navailable datasets and the inefficiencies in constructing multi-modal\nrepresentations. In this paper, we propose a novel prompt learning-based RGB-T\nSOD method, named KAN-SAM, which reveals the potential of visual foundational\nmodels for RGB-T SOD tasks. Specifically, we extend Segment Anything Model 2\n(SAM2) for RGB-T SOD by introducing thermal features as guiding prompts through\nefficient and accurate Kolmogorov-Arnold Network (KAN) adapters, which\neffectively enhance RGB representations and improve robustness. Furthermore, we\nintroduce a mutually exclusive random masking strategy to reduce reliance on\nRGB data and improve generalization. Experimental results on benchmarks\ndemonstrate superior performance over the state-of-the-art methods.","main_category":"cs.MM","categories":"cs.MM,cs.CV","published":"2025-04-08T10:07:02Z"}
{"aid":"http://arxiv.org/abs/2504.05901v1","title":"Improvement Ergodic Theory For The Infinite Word\n  $\\mathfrak{F}=\\mathfrak{F}_{b}:=\\left({ }_{b} f_{n}\\right)_{n \\geqslant 0}$\n  on Fibonacci Density","summary":"The paper explores combinatorial properties of Fibonacci words and their\ngeneralizations within the framework of combinatorics on words. These infinite\nsequences, measures the diversity of subwords in Fibonacci words, showing\nnon-decreasing growth for infinite sequences. Extends factor analysis to\narithmetic progressions of symbols, highlighting generalized pattern\ndistributions. Recent results link Sturmian sequences (including Fibonacci\nwords) to unbounded binomial complexity and gap inequivalence, with\nimplications for formal language theory and automata. This work underscores the\ninterplay between substitution rules, algebraic number theory, and\ncombinatorial complexity in infinite words, providing tools for applications in\nfractal geometry and theoretical computer science.","main_category":"math.CO","categories":"math.CO","published":"2025-04-08T10:56:16Z"}
{"aid":"http://arxiv.org/abs/2504.05912v1","title":"Financial resilience of agricultural and food production companies in\n  Spain: A compositional cluster analysis of the impact of the Ukraine-Russia\n  war (2021-2023)","summary":"This study analyzes the financial resilience of agricultural and food\nproduction companies in Spain amid the Ukraine-Russia war using cluster\nanalysis based on financial ratios. This research utilizes centered log-ratios\nto transform financial ratios for compositional data analysis. The dataset\ncomprises financial information from 1197 firms in Spain's agricultural and\nfood sectors over the period 2021-2023. The analysis reveals distinct clusters\nof firms with varying financial performance, characterized by metrics of\nsolvency and profitability. The results highlight an increase in resilient\nfirms by 2023, underscoring sectoral adaptation to the conflict's economic\nchallenges. These findings together provide insights for stakeholders and\npolicymakers to improve sectorial stability and strategic planning.","main_category":"q-fin.ST","categories":"q-fin.ST,stat.AP","published":"2025-04-08T11:08:51Z"}
{"aid":"http://arxiv.org/abs/2504.05935v1","title":"Stabilization of solutions of the controlled non-local continuity\n  equation","summary":"Non-local continuity equation describes an infinite system of identical\nparticles, which interact with each other through the common field. Solution of\nthis equation is a probability measure that stands for spatial distribution of\nparticles. The paper is concerned with stabilization of this solution in the\ncase of controlled dynamic. By generalizing methods used control-Lyapunov\nfunction to the case of Wasserstein spaces, we construct a feedback strategy\nthat provides local stabilization, i.e. leads the trajectory to a small\nneighbourhood of stabilization target. Based on this strategy, we construct a\nfeedback that makes global stabilization, i.e. leads the trajectory infinitely\nclose to stabilization target.","main_category":"math.DS","categories":"math.DS,math.OC","published":"2025-04-08T11:48:09Z"}
{"aid":"http://arxiv.org/abs/2504.05997v1","title":"Note on the Universality of Parameterized IQP Circuits with Hidden Units\n  for Generating Probability Distributions","summary":"In a series of recent works, an interesting quantum generative model based on\nparameterized instantaneous polynomial quantum (IQP) circuits has emerged as\nthey can be trained efficiently classically using any loss function that\ndepends only on the expectation values of observables of the model. The model\nis proven not to be universal for generating arbitrary distributions, but it is\nsuspected that marginals can be - much like Boltzmann machines achieve\nuniversality by utilizing hidden (traced-out in quantum jargon) layers. In this\nshort note, we provide two simple proofs of this fact. The first is\nnear-trivial and asymptotic, and the second shows universality can be achieved\nwith a reasonable number of additional qubits.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T13:03:23Z"}
{"aid":"http://arxiv.org/abs/2504.06009v1","title":"Linear time-and-space-invariant relaxation systems","summary":"This paper generalizes the physical property of relaxation from linear\ntime-invariant (LTI) to linear time-and-space-invariant (LTSI) systems. It is\nshown that the defining features of relaxation -- complete monotonicity,\npassivity, and memory-based storage -- carry over seamlessly to the\nspatio-temporal domain. An LTSI system is shown to be of relaxation type if and\nonly if its associated spatio-temporal Hankel operator is cyclically monotone.\nThis implies the existence of an intrinsic quadratic storage functional defined\nuniquely by past inputs, independently of any state-space realization. As in\nthe LTI case, LTSI relaxation systems are shown to be those systems for which\nthe state-space concept of storage coincides with the input-output concept of\nfading memory functional.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY,math.DS","published":"2025-04-08T13:16:47Z"}
{"aid":"http://arxiv.org/abs/2504.06014v1","title":"Sparse Reconstruction of Multi-Dimensional Kinetic Distributions","summary":"In the present work, we propose a novel method for reconstruction of\nmulti-dimensional kinetic distributions, based on their representation as a\nmixture of Dirac delta functions. The representation is found as a solution of\nan optimization problem. Different target functionals are considered, with a\nfocus on sparsity-promoting regularization terms. The proposed algorithm\nguarantees non-negativity of the distribution by construction, and avoids an\nexponential dependence of the computational cost on the dimensionality of the\nproblem.\n  Numerical comparisons with other classical methods for reconstruction of\nkinetic distributions are provided for model problems, and the role of the\ndifferent parameters governing the optimization problem is studied.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-04-08T13:19:27Z"}
{"aid":"http://arxiv.org/abs/2504.06035v1","title":"Cosmic inflation in non-perturbative quantum gravity","summary":"String field theory motivated infinite-derivative models lead to non-local\ngravity modifications which form a promising class of quantum gravity\ncandidates. In this paper we investigate effects of non-locality on the\nthree-point function (the bi-spectrum) during cosmic inflation. The study is\ndone in an Einstein frame with an infinite-derivative scalar field Lagrangian\nminimally coupled to the Einstein-Hilbert term. A non-local generalization of\nthe Mukhanov-Sasaki equation is derived. Infinite-derivative operators present\nin this equation lead to an appearance of infinitely many new background\ninduced states in the perturbation spectrum during inflation with complex\nmasses on top of a usual nearly massless inflaton. On contrary to a flat\nbackground such states can be classically stable in a de Sitter space-time.\nThis helps preserving observational constraints on the scalar power-spectrum.\nWe proceed by studying a particular configuration assuming that the generalized\nMukhanov-Sasaki equation gives rise to an inflaton and one pair of new states\nwith complex conjugate masses as perturbative degrees of freedom. The\ncorresponding scalar bi-spectrum is computed numerically in squeezed and\nequilateral limits. We use the latest observational constraints on amplitude of\nthe bi-spectrum $f_{NL}$ from Planck 2018 dataset as a guideline for possible\nvalues of masses of new emerging states. We find that $f_{NL}$ is non-trivially\nsensitive to the values of complex masses and this can reduce the parameter\nspace of gravity modifications. In particular we find that the amplitude of the\nsqueezed limit gets easily enhanced while of the equilateral limit can stay\nlike in a local single-field model of inflation. We end up discussing open\nquestions relevant for this class of models of inflation.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-th","published":"2025-04-08T13:36:28Z"}
{"aid":"http://arxiv.org/abs/2504.06067v1","title":"GPU-accelerated Evolutionary Many-objective Optimization Using\n  Tensorized NSGA-III","summary":"NSGA-III is one of the most widely adopted algorithms for tackling\nmany-objective optimization problems. However, its CPU-based design severely\nlimits scalability and computational efficiency. To address the limitations, we\npropose {TensorNSGA-III}, a fully tensorized implementation of NSGA-III that\nleverages GPU parallelism for large-scale many-objective optimization. Unlike\nconventional GPU-accelerated evolutionary algorithms that rely on heuristic\napproximations to improve efficiency, TensorNSGA-III maintains the exact\nselection and variation mechanisms of NSGA-III while achieving significant\nacceleration. By reformulating the selection process with tensorized data\nstructures and an optimized caching strategy, our approach effectively\neliminates computational bottlenecks inherent in traditional CPU-based and\nna\\\"ive GPU implementations. Experimental results on widely used numerical\nbenchmarks show that TensorNSGA-III achieves speedups of up to $3629\\times$\nover the CPU version of NSGA-III. Additionally, we validate its effectiveness\nin multiobjective robotic control tasks, where it discovers diverse and\nhigh-quality behavioral solutions. Furthermore, we investigate the critical\nrole of large population sizes in many-objective optimization and demonstrate\nthe scalability of TensorNSGA-III in such scenarios. The source code is\navailable at https://github.com/EMI-Group/evomo","main_category":"cs.NE","categories":"cs.NE","published":"2025-04-08T14:09:23Z"}
{"aid":"http://arxiv.org/abs/2504.06068v1","title":"A Liouville-type property for degenerate-elliptic equations modeled on\n  Hörmander vector fields","summary":"We obtain Liouville type theorems for degenerate elliptic equation with a\ndrift term and a potential. The diffusion is driven by H\\\"ormander operators.\nWe show that the conditions imposed on the coefficients of the operator are\noptimal. Indeed, when they fail we prove that infinitely many bounded solutions\nexist.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T14:09:48Z"}
{"aid":"http://arxiv.org/abs/2504.06070v1","title":"PINP: Physics-Informed Neural Predictor with latent estimation of fluid\n  flows","summary":"Accurately predicting fluid dynamics and evolution has been a long-standing\nchallenge in physical sciences. Conventional deep learning methods often rely\non the nonlinear modeling capabilities of neural networks to establish mappings\nbetween past and future states, overlooking the fluid dynamics, or only\nmodeling the velocity field, neglecting the coupling of multiple physical\nquantities. In this paper, we propose a new physics-informed learning approach\nthat incorporates coupled physical quantities into the prediction process to\nassist with forecasting. Central to our method lies in the discretization of\nphysical equations, which are directly integrated into the model architecture\nand loss function. This integration enables the model to provide robust,\nlong-term future predictions. By incorporating physical equations, our model\ndemonstrates temporal extrapolation and spatial generalization capabilities.\nExperimental results show that our approach achieves the state-of-the-art\nperformance in spatiotemporal prediction across both numerical simulations and\nreal-world extreme-precipitation nowcasting benchmarks.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-08T14:11:01Z"}
{"aid":"http://arxiv.org/abs/2504.06106v1","title":"A ROS2-based software library for inverse dynamics computation","summary":"Inverse dynamics computation is a critical component in robot control,\nplanning and simulation, enabling the calculation of joint torques required to\nachieve a desired motion. This paper presents a ROS2-based software library\ndesigned to solve the inverse dynamics problem for robotic systems. The library\nis built around an abstract class with three concrete implementations: one for\nsimulated robots and two for real UR10 and Franka robots. This contribution\naims to provide a flexible, extensible, robot-agnostic solution to inverse\ndynamics, suitable for both simulation and real-world scenarios involving\nplanning and control applications. The related software is available at\nhttps://github.com/ros2-gbp/ros2-gbp-github-org/issues/732.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T14:50:17Z"}
{"aid":"http://arxiv.org/abs/2504.06125v1","title":"Robo-taxi Fleet Coordination at Scale via Reinforcement Learning","summary":"Fleets of robo-taxis offering on-demand transportation services, commonly\nknown as Autonomous Mobility-on-Demand (AMoD) systems, hold significant promise\nfor societal benefits, such as reducing pollution, energy consumption, and\nurban congestion. However, orchestrating these systems at scale remains a\ncritical challenge, with existing coordination algorithms often failing to\nexploit the systems' full potential. This work introduces a novel\ndecision-making framework that unites mathematical modeling with data-driven\ntechniques. In particular, we present the AMoD coordination problem through the\nlens of reinforcement learning and propose a graph network-based framework that\nexploits the main strengths of graph representation learning, reinforcement\nlearning, and classical operations research tools. Extensive evaluations across\ndiverse simulation fidelities and scenarios demonstrate the flexibility of our\napproach, achieving superior system performance, computational efficiency, and\ngeneralizability compared to prior methods. Finally, motivated by the need to\ndemocratize research efforts in this area, we release publicly available\nbenchmarks, datasets, and simulators for network-level coordination alongside\nan open-source codebase designed to provide accessible simulation platforms and\nestablish a standardized validation process for comparing methodologies. Code\navailable at: https://github.com/StanfordASL/RL4AMOD","main_category":"cs.LG","categories":"cs.LG,cs.SY,eess.SY","published":"2025-04-08T15:19:41Z"}
{"aid":"http://arxiv.org/abs/2504.06127v1","title":"Optimal classification with outcome performativity","summary":"I consider the problem of classifying individual behavior in a simple setting\nof outcome performativity where the behavior the algorithm seeks to classify is\nitself dependent on the algorithm. I show in this context that the most\naccurate classifier is either a threshold or a negative threshold rule. A\nthreshold rule offers the \"good\" classification to those individuals whose\noutcome likelihoods are greater than some cutpoint, while a negative threshold\nrule offers the \"good\" outcome to those whose outcome likelihoods are less than\nsome cutpoint. While seemingly pathological, I show that a negative threshold\nrule can be the most accurate classifier when outcomes are performative. I\nprovide an example of such a classifier, and extend the analysis to more\ngeneral algorithm objectives, allowing the algorithm to differentially weigh\nfalse negatives and false positives, for example.","main_category":"econ.TH","categories":"econ.TH,cs.GT","published":"2025-04-08T15:21:02Z"}
{"aid":"http://arxiv.org/abs/2504.06132v1","title":"Stochastic numerical approximation for nonlinear Fokker-Planck equations\n  with singular kernels","summary":"This paper studies the convergence rate of the Euler-Maruyama scheme for\nsystems of interacting particles used to approximate solutions of nonlinear\nFokker-Planck equations with singular interaction kernels, such as the\nKeller-Segel model. We derive explicit error estimates in the large-particle\nlimit for two objects: the empirical measure of the interacting particle system\nand the density distribution of a single particle. Specifically, under certain\nassumptions on the interaction kernel and initial conditions, we show that the\nconvergence rate of both objects towards solutions of the corresponding\nnonlinear FokkerPlanck equation depends polynomially on N (the number of\nparticles) and on h (the discretization step). The analysis shows that the\nscheme converges despite singularities in the drift term. To the best of our\nknowledge, there are no existing results in the literature of such kind for the\nsingular kernels considered in this work.","main_category":"math.PR","categories":"math.PR,cs.NA,math.NA","published":"2025-04-08T15:24:44Z"}
{"aid":"http://arxiv.org/abs/2504.06205v1","title":"HRMedSeg: Unlocking High-resolution Medical Image segmentation via\n  Memory-efficient Attention Modeling","summary":"High-resolution segmentation is critical for precise disease diagnosis by\nextracting micro-imaging information from medical images. Existing\ntransformer-based encoder-decoder frameworks have demonstrated remarkable\nversatility and zero-shot performance in medical segmentation. While\nbeneficial, they usually require huge memory costs when handling large-size\nsegmentation mask predictions, which are expensive to apply to real-world\nscenarios. To address this limitation, we propose a memory-efficient framework\nfor high-resolution medical image segmentation, called HRMedSeg. Specifically,\nwe first devise a lightweight gated vision transformer (LGViT) as our image\nencoder to model long-range dependencies with linear complexity. Then, we\ndesign an efficient cross-multiscale decoder (ECM-Decoder) to generate\nhigh-resolution segmentation masks. Moreover, we utilize feature distillation\nduring pretraining to unleash the potential of our proposed model. Extensive\nexperiments reveal that HRMedSeg outperforms state-of-the-arts in diverse\nhigh-resolution medical image segmentation tasks. In particular, HRMedSeg uses\nonly 0.59GB GPU memory per batch during fine-tuning, demonstrating low training\ncosts. Besides, when HRMedSeg meets the Segment Anything Model (SAM), our\nHRMedSegSAM takes 0.61% parameters of SAM-H. The code is available at\nhttps://github.com/xq141839/HRMedSeg.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-08T16:48:57Z"}
{"aid":"http://arxiv.org/abs/2504.06221v1","title":"Quantum-stabilized states in magnetic dipolar quantum gases","summary":"A decade ago, a universal stabilization mechanism driven by quantum\nfluctuations was discovered in ultracold Bose gases of highly magnetic atoms.\nThis mechanism prevents these systems from collapsing and instead allows exotic\nstates of matter to arise, including ultradilute quantum droplets, crystallized\nquantum states, and specifically supersolids. We review the experimental and\ntheoretical progress in understanding these quantum-stabilized states, their\nemergence, and intriguing properties.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,cond-mat.stat-mech,physics.atom-ph,quant-ph","published":"2025-04-08T17:10:11Z"}
{"aid":"http://arxiv.org/abs/2504.06234v1","title":"Observing radio transients with Phased ALMA: Pulses from the Galactic\n  Centre magnetar","summary":"Radio transients, such as pulsars and Fast Radio Bursts (FRBs), are primarily\ndetected at centimetre radio wavelengths, where higher luminosities are found.\nHowever, observations of sources in dense environments are heavily affected by\npropagation effects which may hinder a detection. Millimetre wave observations\nbypass this complication but require the largest radio telescopes to compensate\nfor the lower flux densities. When used in phased mode, the ALMA radio\ntelescope provides an equivalent dish size of 84m, being the most sensitive\ninstrument at mm/sub mm. With its high time resolution it offers a unique\nopportunity to study radio transients in an unexplored window. We study the\nGalactic Centre (GC) magnetar, PSR J1745$-$2900, as a laboratory for magnetars\nin complex magneto-turbulent environments and to link with FRBs. We showcase\nthe potential of ALMA in phased mode to observe radio transients and to\nachieve, for some sources, the first ever detections outside the cm wave range.\nWe studied the GC magnetar using ALMA archival data of Sgr A* at Band 3 from\nthe 2017 GMVA campaign. We searched in intensity and classified the pulses\nbased on their circular and linear polarisation properties and arrival phase.\nWe detected eight pulses with energies in the range of 10$^{29}$ erg. We\nconstructed its cumulative energy distribution and we fit a power law, where\nthe event rate scales with energy as $R \\propto E^{\\gamma}$. The result is an\nexponent of $\\gamma = -2.4 \\pm 0.1$. With the $\\gamma -$value and the system\nproperties of phased ALMA, we estimate that over 160 known pulsars could be\ndetected by ALMA. For repeating FRBs, observing during their peak activity\nwindow could lead to several detections. We expect that ALMA's lower frequency\nbands with polarisation capabilities, will serve as a pioneer on mm wave\nsearches for pulsars and to study complex environments involving radio\ntransients.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-08T17:32:05Z"}
{"aid":"http://arxiv.org/abs/2504.06249v1","title":"Electronic Structure Guided Inverse Design Using Generative Models","summary":"The electronic structure of a material fundamentally determines its\nunderlying physical, and by extension, its functional properties. Consequently,\nthe ability to identify or generate materials with desired electronic\nproperties would enable the design of tailored functional materials.\nTraditional approaches relying on human intuition or exhaustive computational\nscreening of known materials remain inefficient and resource-prohibitive for\nthis task. Here, we introduce DOSMatGen, the first instance of a machine\nlearning method which generates crystal structures that match a given desired\nelectronic density of states. DOSMatGen is an E(3)-equivariant joint diffusion\nframework, and utilizes classifier-free guidance to accurately condition the\ngenerated materials on the density of states. Our experiments find this\napproach can successfully yield materials which are both stable and match\nclosely with the desired density of states. Furthermore, this method is highly\nflexible and allows for finely controlled generation which can target specific\ntemplates or even individual sites within a material. This method enables a\nmore physics-driven approach to designing new materials for applications\nincluding catalysts, photovoltaics, and superconductors.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T17:54:49Z"}
{"aid":"http://arxiv.org/abs/2504.06570v1","title":"Data quality or data quantity? Prioritizing data collection under\n  distribution shift with the data usefulness coefficient","summary":"Researchers often have access to multiple data sources of varying quality.\nFor example, in psychology, a researcher may decide between running an\nexperiment on an online platform or on a representative sample of the\npopulation of interest. Collecting a representative sample will result in\nhigher quality data but is often more expensive. This raises the question of\nhow to optimally prioritize data collection under resource constraints. We\nstudy this question in a setting where the distribution shift arises through\nmany independent random changes in the population. We introduce a \"data\nusefulness coefficient\" (DUC) and show that it allows us to predict how much\nthe risk of empirical risk minimization would decrease if a specific data set\nwere added to the training data. An advantage of our procedure is that it does\nnot require access to any outcome data $Y$. Instead, we rely on a random shift\nassumption, which implies that the strength of covariate ($X$) shift is\npredictive of the shift in $Y \\mid X$. We also derive methods for sampling\nunder budget and size constraints. We demonstrate the benefits of data\ncollection based on DUC and our optimal sampling strategy in several numerical\nexperiments.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-09T04:11:22Z"}
{"aid":"http://arxiv.org/abs/2504.06585v1","title":"Sim-to-Real of Humanoid Locomotion Policies via Joint Torque Space\n  Perturbation Injection","summary":"This paper proposes a novel alternative to existing sim-to-real methods for\ntraining control policies with simulated experiences. Prior sim-to-real methods\nfor legged robots mostly rely on the domain randomization approach, where a\nfixed finite set of simulation parameters is randomized during training.\nInstead, our method adds state-dependent perturbations to the input joint\ntorque used for forward simulation during the training phase. These\nstate-dependent perturbations are designed to simulate a broader range of\nreality gaps than those captured by randomizing a fixed set of simulation\nparameters. Experimental results show that our method enables humanoid\nlocomotion policies that achieve greater robustness against complex reality\ngaps unseen in the training domain.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-09T05:25:57Z"}
{"aid":"http://arxiv.org/abs/2504.06586v1","title":"Diversity-aware Dual-promotion Poisoning Attack on Sequential\n  Recommendation","summary":"Sequential recommender systems (SRSs) excel in capturing users' dynamic\ninterests, thus playing a key role in various industrial applications. The\npopularity of SRSs has also driven emerging research on their security aspects,\nwhere data poisoning attack for targeted item promotion is a typical example.\nExisting attack mechanisms primarily focus on increasing the ranks of target\nitems in the recommendation list by injecting carefully crafted interactions\n(i.e., poisoning sequences), which comes at the cost of demoting users' real\npreferences. Consequently, noticeable recommendation accuracy drops are\nobserved, restricting the stealthiness of the attack. Additionally, the\ngenerated poisoning sequences are prone to substantial repetition of target\nitems, which is a result of the unitary objective of boosting their overall\nexposure and lack of effective diversity regularizations. Such homogeneity not\nonly compromises the authenticity of these sequences, but also limits the\nattack effectiveness, as it ignores the opportunity to establish sequential\ndependencies between the target and many more items in the SRS. To address the\nissues outlined, we propose a Diversity-aware Dual-promotion Sequential\nPoisoning attack method named DDSP for SRSs. Specifically, by theoretically\nrevealing the conflict between recommendation and existing attack objectives,\nwe design a revamped attack objective that promotes the target item while\nmaintaining the relevance of preferred items in a user's ranking list. We\nfurther develop a diversity-aware, auto-regressive poisoning sequence\ngenerator, where a re-ranking method is in place to sequentially pick the\noptimal items by integrating diversity constraints.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-09T05:28:41Z"}
{"aid":"http://arxiv.org/abs/2504.06608v1","title":"A Cross-Domain Few-Shot Learning Method Based on Domain Knowledge\n  Mapping","summary":"In task-based few-shot learning paradigms, it is commonly assumed that\ndifferent tasks are independently and identically distributed (i.i.d.).\nHowever, in real-world scenarios, the distribution encountered in few-shot\nlearning can significantly differ from the distribution of existing data. Thus,\nhow to effectively leverage existing data knowledge to enable models to quickly\nadapt to class variations under non-i.i.d. assumptions has emerged as a key\nresearch challenge. To address this challenge, this paper proposes a new\ncross-domain few-shot learning approach based on domain knowledge mapping,\napplied consistently throughout the pre-training, training, and testing phases.\nIn the pre-training phase, our method integrates self-supervised and supervised\nlosses by maximizing mutual information, thereby mitigating mode collapse.\nDuring the training phase, the domain knowledge mapping layer collaborates with\na domain classifier to learn both domain mapping capabilities and the ability\nto assess domain adaptation difficulty. Finally, this approach is applied\nduring the testing phase, rapidly adapting to domain variations through\nmeta-training tasks on support sets, consequently enhancing the model's\ncapability to transfer domain knowledge effectively. Experimental validation\nconducted across six datasets from diverse domains demonstrates the\neffectiveness of the proposed method.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T06:11:55Z"}
{"aid":"http://arxiv.org/abs/2504.06625v1","title":"Decoupling spin relaxation and chemical kinetics in radical pair\n  magnetism: A master equation study","summary":"A leading theory for the biological effects of low-intensity magnetic fields\nis the spin-chemical Radical Pair Mechanism. This mechanism is best described\nby the master equation for the density matrix of an open quantum system, which\nincludes terms for Hamiltonian evolution, thermal spin relaxation, and chemical\nkinetics. In this study, we have found a solution to this equation for a\nsimplified radical pair model and shown that a significant magnetic effect\noccurs when the following condition is met: $\\gamma H \\tau \\gtrsim 1 + \\kappa\n\\tau$, where $\\gamma$ is the gyromagnetic ratio of the electron, $H$ is the\nmagnetic field strength, $\\tau$ is the relaxation time, and $\\kappa$ is the\nrate of chemical kinetics.","main_category":"physics.bio-ph","categories":"physics.bio-ph,quant-ph","published":"2025-04-09T06:52:41Z"}
{"aid":"http://arxiv.org/abs/2504.06630v1","title":"Two-Axis planar Hall magnetic field sensors with sub nanoTesla\n  resolution","summary":"Planar Hall effect (PHE) magnetic sensors are attractive for various\napplications where the field resolution is required in the range of sub-nano\nTesla or in Pico Tesla. Here we present a detailed noise study of the PHE\nsensors consisting of two or three intersecting ellipses. It can be used to\nmeasure two axes of the magnetic field in the sensor plane in particular along\nthe two perpendicular easy axes in the overlapping region for two intersecting\nellipses and three easy axes at an angle of 60 degrees for three crossing\nellipses. Thus, for each remanent magnetic state in the overlap area, the\nsensor can measure the vector component of the magnetic field perpendicular to\nthe direction of the remanent magnetization. The two field components are\nmeasured with a field resolution less than 200 pT/sqrt(Hz) at 10 Hz and 350\npT/sqrt(Hz) at 1 Hz in the same region, while maintaining a similar size and\nnoise level of a single-axis sensor. Furthermore, we discuss here the possible\nroute for future improvement of the field resolution","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-09T07:07:27Z"}
{"aid":"http://arxiv.org/abs/2504.06648v1","title":"Semiclassical concentration estimates for Berezin-Toeplitz quasimodes\n  for regular energies","summary":"The purpose of this article is to prove sharp $L^p$ bounds for quasimodes of\nBerezin-Toeplitz operators. We consider examples with explicit computations and\na general situation on compact spaces and $\\Cm^n$. In both cases the eigenvalue\nis a regular value of the operator symbol. We then use the link between\npseudodifferential and Berezin-Toeplitz operators to obtain an $L^p$ bound of\nthe FBI transform of quasimodes of pseudodifferential operators.","main_category":"math.CV","categories":"math.CV,math.SG,math.SP","published":"2025-04-09T07:36:30Z"}
{"aid":"http://arxiv.org/abs/2504.06655v1","title":"Identifying the Nano Interface Through Phase","summary":"The quantum dots (QD) interface in solution can play significant roles in\nelectron transfer dynamics for quantum dots-sensitized solar cells and\ndifferent biological, environmental, and industrial systems. Here, we predict\nan avenue to identify the contribution of the quantum dots interface created\nstatic electric field on the nonlinear optical response (NLO) due to four-wave\nmixing (FWM), especially for the nanoparticles where surface contribution is\nhigh. We implement a way to disentangle the FWM response in QDs originating\nfrom the three incoming oscillating laser fields (NLOoscillating) and a\ncontribution (NLOstatic) arising from the three oscillating laser fields and\nthe static electric field caused by the interface. Advanced two-dimensional\nelectronic spectroscopy (2DES) employs phase-resolved heterodyne techniques\nwhere FWM response is measured in a particular phase-matched direction, and the\nresponse is distinctively phase sensitive. Theoretical analysis shows\nalteration in the interface can introduce phase variation in the NLOstatic\nsignal, resulting in a distinct change in the 2D-spectra. Our studies establish\na range of ionic strength, which can be important to untwine the usual NLO\nsignal (NLOoscillating) from the NLO (NLOstatic) contributed by the interface\nof quantum dots. This analysis may open up the possibility to study the\ndifferent kinds of dynamics occurring specifically in the interface and also\nwill pave the path towards different ion interactions through phase change in\n2D spectra, and enormous scope will be employing deep learning-assisted phase\nrecognition.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-09T07:45:26Z"}
{"aid":"http://arxiv.org/abs/2504.06656v1","title":"Machine Learning in the Hunt for Heavy Charged Higgs Bosons at\n  Gamma-Gamma Colliders in the Type III Two Higgs Doublet Model","summary":"We conduct a detailed exploration of charged Higgs boson masses $M_{H^{\\pm}}$\nwithin the range of $100-190~GeV$. This investigation is grounded in the\nbenchmark points that comply with experimental constraints, allowing us to\nsystematically account for uncertainties inherent in the analysis. Our results\nindicate significant production prospects for the process $H^{+}H^{-}\n\\rightarrow \\tau \\nu_{\\tau} \\tau \\nu_{\\tau}$, which could provide essential\ninsights into the properties of $H^{\\pm}$ bosons. By examining these decay\nchannels, we aim to illuminate the interplay between the charged Higgs boson\nand the established Standard Model. The research uses machine learning methods\nlike Boosted Decision Trees (BDT) and Multilayer Perceptrons (MLP), as well as\nLikelihood and LikelihoodD, to improve the identification of heavy charged\nHiggs bosons compared to Standard Model backgrounds at a 3.0 TeV $\\gamma\\gamma$\ncollider with an integrated luminosity of $\\mathcal{L}_{int}=3000~fb^{-1}$.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-09T07:46:27Z"}
{"aid":"http://arxiv.org/abs/2504.06663v1","title":"Spectroscopic diagnostics of high-temperature plasma in stellar corona\n  using Fe XXIV--XXVI K-shell lines with XRISM","summary":"The RS CVn type binary star GT Mus was observed during its quiescence using\nthe Resolve X-ray microcalorimeter spectrometer onboard XRISM. The main and\nsatellite lines of the Fe XXIV--XXVI K-shell transitions were resolved for the\nfirst time from stellar sources. We conducted line ratio analysis to\ninvestigate any deviations from collisional onization equilibrium (CIE) and\nMaxwell electron energy distribution with a single-temperature. By using five\ncombinations of direct excitation lines and dielectronic recombination\nsatellite lines in three line complexes (Fe He$\\alpha$, Ly$\\alpha$, and\nHe$\\beta$), we found that the plasma is well characterized by two-temperature\nthermal plasmas with temperatures of 1.7 and 4.3 keV, which is consistent with\na thermal broadening of Fe XXV and the broadband fitting results in the 1.7--10\nkeV band. Other forms of deviation from a single-temperature plasma, such as\ndifferent ionization and electron temperatures or the $\\kappa$ distribution for\nthe electron energy distributions, are not favored, which is reasonable for\nstellar coronae at quiescence. This study demonstrates the utility of the Fe\nK-shell line ratio diagnostics to probe plasma conditions using X-ray\nmicrocalorimeters.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.SR","published":"2025-04-09T07:56:38Z"}
{"aid":"http://arxiv.org/abs/2504.06668v1","title":"A Novel Nonlinear Fertility Catastrophe Model Based on Thom's\n  Differential Equations of Morphogenesis","summary":"A novel fertility model based on Thom's nonlinear differential equations of\nmorphogenesis is presented, utilizing a three-dimensional catastrophe surface\nto capture the interaction between latent non-catastrophic fertility factors\nand catastrophic shocks. The model incorporates key socioeconomic and\nenvironmental variables and is applicable at macro-, meso-, and\nmicro-demographic levels, addressing global fertility declines, regional\npopulation disparities, and micro-level phenomena such as teenage pregnancies.\nThis approach enables a comprehensive analysis of reproductive health at\naggregate, sub-national, and age-group-specific levels. An agent-based model\nfor teenage pregnancy is described to illustrate how latent factors -- such as\neducation, contraceptive use, and parental guidance -- interact with\ncatastrophic shocks like socioeconomic deprivation, violence, and substance\nabuse. The bifurcation set analysis shows how minor shifts in socioeconomic\nconditions can lead to significant changes in fertility rates, revealing\ncritical points in fertility transitions. By integrating Thom's morphogenesis\nequations with traditional fertility theory, this paper proposes a\ngroundbreaking approach to understanding fertility dynamics, offering valuable\ninsights for the development of public health policies that address both stable\nfertility patterns and abrupt demographic shifts.","main_category":"physics.soc-ph","categories":"physics.soc-ph,math.DS","published":"2025-04-09T08:09:38Z"}
{"aid":"http://arxiv.org/abs/2504.06691v1","title":"Wake instability of a fixed spherical droplet with a high drop-to-fluid\n  viscosity ratio","summary":"Direct numerical simulations of a uniform flow past a fixed spherical droplet\nare performed to investigate the parameter range within which the axisymmetric\nflow becomes unstable due to an external flow bifurcation. The hydrodynamics is\ngoverned by three dimensionless numbers: the viscosity ratio, $\\mu^\\ast$, and\nthe external and internal Reynolds numbers, $\\Rey^e$ and $\\Rey^i$,\nrespectively. The drop-to-fluid density ratio is related to these parameters as\n$\\rho^\\ast=\\mu^\\ast \\Rey^i/\\Rey^e$. This study focuses on highly viscous\ndroplets with $\\mu^\\ast \\geq 5$, where wake instability is driven by the\nvorticity flux transferred from the droplet surface into the surrounding fluid.\nBy analysing the wake structure, we confirm that the onset of the external\nbifurcation is linked to the tilting of the azimuthal vorticity, $\\omega_\\phi$,\nin the wake and that the bifurcation occurs once the isocontours of\n$\\omega_\\phi$ align nearly perpendicular to the symmetry axis. We propose an\nempirical criterion for predicting the onset of the external bifurcation,\nformulated in terms of the maximum vorticity on the external side of the\ndroplet surface. This criterion is applicable for sufficiently high $\\Rey^i$\nand holds over a wide range of $\\mu^\\ast$ and $\\Rey^e$. Additionally, we\nexamine the bifurcation sequence for two specific external Reynolds numbers,\n$\\Rey^e=300$ and $\\Rey^e=500$, and show that, beyond a critical viscosity\nratio, the axisymmetric wake first transitions to a steady planar-symmetric\nstate before undergoing a secondary Hopf bifurcation. Finally, we highlight the\ninfluence of $\\Rey^i$ on external bifurcation and show that, at moderate\n$\\Rey^i$, wake instability may set in at a lower vorticity threshold than\npredicted by our criterion. These findings provide new insights into the\nexternal flow bifurcation of viscous droplets.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-09T08:53:06Z"}
{"aid":"http://arxiv.org/abs/2504.06697v1","title":"\"Sorry for bugging you so much.\" Exploring Developers' Behavior Towards\n  Privacy-Compliant Implementation","summary":"While protecting user data is essential, software developers often fail to\nfulfill privacy requirements. However, the reasons why they struggle with\nprivacy-compliant implementation remain unclear. Is it due to a lack of\nknowledge, or is it because of insufficient support? To provide foundational\ninsights in this field, we conducted a qualitative 5-hour programming study\nwith 30 professional software developers implementing 3 privacy-sensitive\nprogramming tasks that were designed with GDPR compliance in mind. To explore\nif and how developers implement privacy requirements, participants were divided\ninto 3 groups: control, privacy prompted, and privacy expert-supported. After\ntask completion, we conducted follow-up interviews. Alarmingly, almost all\nparticipants submitted non-GDPR-compliant solutions (79/90). In particular,\nnone of the 3 tasks were solved privacy-compliant by all 30 participants, with\nthe non-prompted group having the lowest number of 3 out of 30\nprivacy-compliant solution attempts. Privacy prompting and expert support only\nslightly improved participants' submissions, with 6/30 and 8/30\nprivacy-compliant attempts, respectively. In fact, all participants reported\nsevere issues addressing common privacy requirements such as purpose\nlimitation, user consent, or data minimization. Counterintuitively, although\nmost developers exhibited minimal confidence in their solutions, they rarely\nsought online assistance or contacted the privacy expert, with only 4 out of 10\nexpert-supported participants explicitly asking for compliance confirmation.\nInstead, participants often relied on existing implementations and focused on\nimplementing functionality and security first.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-09T08:59:17Z"}
{"aid":"http://arxiv.org/abs/2504.06713v1","title":"Almost everywhere convergence of the convolution type Laguerre\n  expansions","summary":"For a fixed d-tuple $\\alpha=(\\alpha_1,...,\\alpha_d)\\in(-1,\\infty)^d$,\nconsider the product space $\\mathbb{R}_+^d:=(0,\\infty)^d$ equipped with\nEuclidean distance $\\arrowvert \\cdot \\arrowvert$ and the measure\n$d\\mu_{\\alpha}(x)=x_1^{2\\alpha_1+1}\\cdot\\cdot\\cdot\nx_{d}^{\\alpha_d}dx_1\\cdot\\cdot\\cdot dx_d$. We consider the Laguerre operator\n$L_{\\alpha}=-\\Delta+\\sum_{i=1}^{d}\\frac{2\\alpha_j+1}{x_j}\\frac{d}{dx_j}+\\arrowvert\nx\\arrowvert^2$ which is a compact, positive, self-adjoint operator on\n$L^2(\\mathbb{R}_+^d,d\\mu_{\\alpha}(x))$. In this paper, we study almost\neverywhere convergence of the Bochner-Riesz means associated with $L_\\alpha$\nwhich is defined by\n$S_R^{\\lambda}(L_\\alpha)f(x)=\\sum_{n=0}^{\\infty}(1-\\frac{e_n}{R^2})_{+}^{\\lambda}P_nf(x)$.\nHere $e_n$ is n-th eigenvalue of $L_{\\alpha}$, and $P_nf(x)$ is the n-th\nLaguerre spectral projection operator. This corresponds to the convolution-type\nLaguerre expansions introduced in Thangavelu's lecture \\cite{TS3}. For $2\\leq\np<\\infty$, we prove that $$\\lim_{R\\rightarrow\\infty}\nS_R^{\\lambda}(L_\\alpha)f=f\\,\\,\\,\\,-a.e.$$ for all $f\\in\nL^p(\\mathbb{R}_+^d,d\\mu_{\\alpha}(x))$, provided that\n$\\lambda>\\lambda(\\alpha,p)/2$, where\n$\\lambda(\\alpha,p)=\\max\\{2(\\arrowvert\\alpha\\arrowvert_1+d)(1/2-1/p)-1/2,0\\}$,\nand $\\arrowvert\\alpha\\arrowvert_1:=\\sum_{j=1}^{d}\\alpha_{j}$. Conversely, if\n$2\\arrowvert\\alpha\\arrowvert_{1}+2d>1$, we will show the convergence generally\nfails if $\\lambda<\\lambda(\\alpha,p)/2$ in the sense that there is an $f\\in\nL^p(\\mathbb{R}_+^d,d\\mu_{\\alpha}(x))$ for\n$(4\\arrowvert\\alpha\\arrowvert_{1}+4d)/(2\\arrowvert\\alpha\\arrowvert_{1}+2d-1)<\np$ such that the convergence fails. When\n$2\\arrowvert\\alpha\\arrowvert_{1}+2d\\leq1$, our results show that a.e.\nconvergence holds for $f\\in L^p(\\mathbb{R}_+^d,d\\mu_{\\alpha}(x))$ with $p\\geq\n2$ whenever $\\lambda>0$.","main_category":"math.FA","categories":"math.FA","published":"2025-04-09T09:15:18Z"}
{"aid":"http://arxiv.org/abs/2504.06726v1","title":"On the Vinogradov bound by the Diophantine type","summary":"In this article, we give an asymptotic bound for the exponential sum of the\nM\\\"obius function $\\sum_{n \\le x} \\mu(n) e(\\alpha n)$ for a fixed irrational\nnumber $\\alpha\\in\\mathbb{R}$. This exponential sum was originally studied by\nDavenport and he obtained an asymptotic bound of $x(\\log x)^{-A}$ for any\n$A\\ge0$. Our bound depends on the irrationality exponent $\\eta$ of $\\alpha$. If\n$\\eta \\le 5/2$, we obtain a bound of $x^{4/5 + \\varepsilon}$ and, when $\\eta\n\\ge 5/2$, then our bound becomes $x^{(2\\eta-1)/2\\eta + \\varepsilon}$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-09T09:31:12Z"}
{"aid":"http://arxiv.org/abs/2504.06738v1","title":"EDIT: Enhancing Vision Transformers by Mitigating Attention Sink through\n  an Encoder-Decoder Architecture","summary":"In this paper, we propose EDIT (Encoder-Decoder Image Transformer), a novel\narchitecture designed to mitigate the attention sink phenomenon observed in\nVision Transformer models. Attention sink occurs when an excessive amount of\nattention is allocated to the [CLS] token, distorting the model's ability to\neffectively process image patches. To address this, we introduce a\nlayer-aligned encoder-decoder architecture, where the encoder utilizes\nself-attention to process image patches, while the decoder uses cross-attention\nto focus on the [CLS] token. Unlike traditional encoder-decoder framework,\nwhere the decoder depends solely on high-level encoder representations, EDIT\nallows the decoder to extract information starting from low-level features,\nprogressively refining the representation layer by layer. EDIT is naturally\ninterpretable demonstrated through sequential attention maps, illustrating the\nrefined, layer-by-layer focus on key image features. Experiments on ImageNet-1k\nand ImageNet-21k, along with transfer learning tasks, show that EDIT achieves\nconsistent performance improvements over DeiT3 models. These results highlight\nthe effectiveness of EDIT's design in addressing attention sink and improving\nvisual feature extraction.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-09T09:51:41Z"}
{"aid":"http://arxiv.org/abs/2504.06741v1","title":"Large Scale Supervised Pretraining For Traumatic Brain Injury\n  Segmentation","summary":"The segmentation of lesions in Moderate to Severe Traumatic Brain Injury\n(msTBI) presents a significant challenge in neuroimaging due to the diverse\ncharacteristics of these lesions, which vary in size, shape, and distribution\nacross brain regions and tissue types. This heterogeneity complicates\ntraditional image processing techniques, resulting in critical errors in tasks\nsuch as image registration and brain parcellation. To address these challenges,\nthe AIMS-TBI Segmentation Challenge 2024 aims to advance innovative\nsegmentation algorithms specifically designed for T1-weighted MRI data, the\nmost widely utilized imaging modality in clinical practice. Our proposed\nsolution leverages a large-scale multi-dataset supervised pretraining approach\ninspired by the MultiTalent method. We train a Resenc L network on a\ncomprehensive collection of datasets covering various anatomical and\npathological structures, which equips the model with a robust understanding of\nbrain anatomy and pathology. Following this, the model is fine-tuned on\nmsTBI-specific data to optimize its performance for the unique characteristics\nof T1-weighted MRI scans and outperforms the baseline without pretraining up to\n2 Dice points.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T09:52:45Z"}
{"aid":"http://arxiv.org/abs/2504.06743v1","title":"Kinematic formulas in convex geometry for non-compact groups","summary":"We generalize classical kinematic formulas for convex bodies in a real vector\nspace $V$ to the setting of non-compact Lie groups admitting a Cartan\ndecomposition. Specifically, let $G$ be a closed linear group with Cartan\ndecomposition $G \\cong K \\times \\exp(\\mathfrak{p}_0)$, where $K$ is a maximal\ncompact subgroup acting transitively on the unit sphere. For $K$-invariant\ncontinuous valuations on convex bodies, we establish an integral geometric-type\nformula for $\\overline{G} = G \\ltimes V$. Key to our approach is the\nintroduction of a Gaussian measure on $\\mathfrak{p}_0$, which ensures\nconvergence of the non-compact part of the integral. In the special case $K =\nO(n)$, we recover a Hadwiger-type formula involving intrinsic volumes, with\nexplicit constants $c_j$ computed via a Weyl integration formula.","main_category":"math.MG","categories":"math.MG","published":"2025-04-09T09:59:28Z"}
{"aid":"http://arxiv.org/abs/2504.06759v1","title":"Rhombohedral graphite junctions as a platform for continuous tuning\n  between topologically trivial and non-trivial electronic phases","summary":"Manipulating the topological properties of quantum states can provide a way\nto protect them against disorder. However, typically, changing the topology of\nelectronic states in a crystalline material is challenging because their nature\nis underpinned by chemical composition and lattice symmetry that are difficult\nto modify. We propose junctions between rhombohedral graphite crystals as a\nplatform that enables smooth transition between topologically trivial and\nnon-trivial regimes distinguished by the absence or presence of topological\njunction states. By invoking an analogy with the Su-Schrieffer-Heeger model,\nthe appearance of topological states is related to the symmetry of the atomic\nstacking at the interface between the crystals. The possibility to explore both\nthe topological and non-topological phases is provided by sliding the crystals\nwith respect to each other.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.other","published":"2025-04-09T10:23:15Z"}
{"aid":"http://arxiv.org/abs/2504.06784v1","title":"Modified gravity realizations of quintom dark energy after DESI DR2","summary":"We investigate the realization of quintom scenario for dynamical dark energy\nwithin modified gravity theories that can efficiently fit the recent\nobservational datasets. Starting from a general effective field theory\nformulation of dark energy in metric-affine geometry, we derive the background\naction in unitary gauge and we demonstrate how both $f(T)$ and $f(Q)$ gravity\ncan naturally realize quintom behavior through appropriate forms and parameter\nchoices. Additionally, using the Gaussian process reconstruction of the latest\nDESI DR2 BAO data combined with SNe and CMB observations, we extract the\nreconstructed dark-energy equation-of-state parameter, showing that it exhibits\nquintom-type evolution, crossing the phantom divide from below. Moreover,\nthrough detailed parameter estimations and application of information criteria,\nwe compare the model with the quadratic one. Our results show that, due to its\nrich structure, modified gravity stands as one of the main candidates for the\nrealization of the data-favoured dynamical dark energy.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-09T11:17:20Z"}
{"aid":"http://arxiv.org/abs/2504.06787v1","title":"Communicating complex statistical models to a public health audience:\n  translating science into action with the FARSI approach","summary":"Background. Effectively communicating complex statistical model outputs is a\nmajor challenge in public health. This study introduces the FARSI approach\n(Fast, Accessible, Reliable, Secure, Informative) as a framework to enhance the\ntranslation of intricate statistical findings into actionable insights for\npolicymakers and stakeholders. We apply this framework in a real-world case\nstudy on chronic disease monitoring in Italy.\n  Methods. The FARSI framework outlines key principles for developing\nuser-friendly tools that improve the translation of statistical results. We\napplied these principles to create an open-access web application using R\nShiny, designed to communicate chronic disease prevalence estimates from a\nBayesian spatio-temporal logistic model. The case study highlights the\nimportance of an intuitive design for fast accessibility, validated data and\nexpert feedback for reliability, aggregated data for security, and insights\ninto prevalence population subgroups, which were previously unobservable, for\ninformativeness.\n  Results. The web application enables stakeholders to explore disease\nprevalence across populations and geographical area through dynamic\nvisualizations. It facilitates public health monitoring by, for instance,\nidentifying disparities at the local level and assessing risk factors such as\nsmoking. Its user-friendly interface enhances accessibility, making statistical\nfindings more actionable. Conclusions. The FARSI framework provides a\nstructured approach to improving the communication of complex research\nfindings. By making statistical models more accessible and interpretable, it\nsupports evidence-based decision-making in public health and increases the\nsocietal impact of research.","main_category":"stat.OT","categories":"stat.OT,stat.AP,stat.ME","published":"2025-04-09T11:20:12Z"}
{"aid":"http://arxiv.org/abs/2504.06800v1","title":"A Meaningful Perturbation Metric for Evaluating Explainability Methods","summary":"Deep neural networks (DNNs) have demonstrated remarkable success, yet their\nwide adoption is often hindered by their opaque decision-making. To address\nthis, attribution methods have been proposed to assign relevance values to each\npart of the input. However, different methods often produce entirely different\nrelevance maps, necessitating the development of standardized metrics to\nevaluate them. Typically, such evaluation is performed through perturbation,\nwherein high- or low-relevance regions of the input image are manipulated to\nexamine the change in prediction. In this work, we introduce a novel approach,\nwhich harnesses image generation models to perform targeted perturbation.\nSpecifically, we focus on inpainting only the high-relevance pixels of an input\nimage to modify the model's predictions while preserving image fidelity. This\nis in contrast to existing approaches, which often produce out-of-distribution\nmodifications, leading to unreliable results. Through extensive experiments, we\ndemonstrate the effectiveness of our approach in generating meaningful rankings\nacross a wide range of models and attribution methods. Crucially, we establish\nthat the ranking produced by our metric exhibits significantly higher\ncorrelation with human preferences compared to existing approaches,\nunderscoring its potential for enhancing interpretability in DNNs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T11:46:41Z"}
{"aid":"http://arxiv.org/abs/2504.06822v1","title":"Investigation of triply heavy spin-3/2 baryons in their ground and\n  excited states","summary":"We calculate the masses and residues of triply heavy baryons with spin-3/2,\nincluding $\\Omega^*_{ccc}$, $\\Omega^*_{ccb}$, $\\Omega^*_{bbc}$ and\n$\\Omega^*_{bbb}$, using the QCD sum rules method. Our calculations primarily\nfocus on obtaining the masses of the first three resonances, that is, the\nground state (1S), the first orbital excited state (1P), and the first radial\nexcited state (2S), for the mentioned baryons. We additionally determine the\nresidues of these baryons, which serve as key parameters for studying their\npossible decay channels and interactions with other particles. To achieve\nhigher accuracy compared to previous studies, we consider nonperturbative\noperators up to eight mass dimensions. We present our calculated outcomes in\ntwo distinct energy schemes, referred to as pole and $\\mathrm{\\overline{MS}}$.\nGiven the absence of experimental data for these states, we compare our results\nwith previous theoretical calculations that are reported in relevant studies\nemploying various approaches. These results may provide valuable insights for\nexperimental groups searching for the triply heavy baryons.","main_category":"hep-ph","categories":"hep-ph,hep-ex,hep-lat","published":"2025-04-09T12:29:10Z"}
{"aid":"http://arxiv.org/abs/2504.06832v1","title":"On a Characterization of Spartan Graphs","summary":"The eternal vertex cover game is played between an attacker and a defender on\nan undirected graph $G$. The defender identifies $k$ vertices to position\nguards on to begin with. The attacker, on their turn, attacks an edge $e$, and\nthe defender must move a guard along $e$ to defend the attack. The defender may\nmove other guards as well, under the constraint that every guard moves at most\nonce and to a neighboring vertex. The smallest number of guards required to\ndefend attacks forever is called the eternal vertex cover number of $G$,\ndenoted $evc(G)$.\n  For any graph $G$, $evc(G)$ is at least the vertex cover number of $G$,\ndenoted $mvc(G)$. A graph is Spartan if $evc(G) = mvc(G)$. It is known that a\nbipartite graph is Spartan if and only if every edge belongs to a perfect\nmatching. We show that the only K\\\"onig graphs that are Spartan are the\nbipartite Spartan graphs. We also give new lower bounds for $evc(G)$,\ngeneralizing a known lower bound based on cut vertices. We finally show a new\nmatching-based characterization of all Spartan graphs.","main_category":"cs.DM","categories":"cs.DM,math.CO","published":"2025-04-09T12:47:29Z"}
{"aid":"http://arxiv.org/abs/2504.06840v1","title":"Interference Mitigation and Spectral Efficiency Enhancement in a\n  Multi-BD Symbiotic Radio","summary":"This study presents a framework designed to mitigate direct-link interference\n(DLI) and inter-backscatter device interference (IBDI) in multi-backscatter\northogonal frequency division multiplexing (OFDM)-based symbiotic radio (SR)\nsystems. The framework employs OFDM signal designs with strategic allocation of\nnull subcarriers and incorporates two backscatter modulation techniques: on-off\nfrequency shift keying (OFSK) and multiple frequency shift keying (MFSK) for\nsymbiotic backscatter communication (SBC). Additionally, we propose\nFully-Orthogonal and Semi-Orthogonal multiple access schemes to facilitate SBC\nalongside primary communication. The Fully-Orthogonal scheme maintains\northogonality between direct link and SBC signals, thereby ensuring\ninterference-free SBC, albeit at a reduced spectral efficiency. In contrast,\nthe Semi-Orthogonal schemes eliminate IBDI but permit partial DLI, striking a\nbalance between reliability and spectral efficiency. To address the partial DLI\ninherent in Semi-Orthogonal schemes, successive interference cancellation (SIC)\nis employed at the receiver, enhancing SBC reliability. To tackle channel\nestimation challenges in SBC within the SR system, we implement non-coherent\ndetection techniques at the receiver. The performance of the proposed system is\nevaluated based on average bit error rate (BER) and sum-rate metrics,\ndemonstrating the effectiveness of our schemes. We provide analytical results\nfor the system's detection performance under both proposed modulation\ntechniques and multiple access schemes, which are subsequently validated\nthrough extensive simulations. These simulations indicate a notable error-rate\nreduction of up to $10^{-3}$ at $20$ dB with the Fully-Orthogonal scheme with\nMFSK.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-09T12:57:58Z"}
{"aid":"http://arxiv.org/abs/2504.06846v1","title":"Solid-State Maser with Microwatt Output Power at Moderate Cryogenic\n  Temperatures","summary":"Solid-state masers are uniquely positioned to serve as ultra-low phase noise\nmicrowave sources due to their exceptionally low noise temperatures. However,\ntheir practical application has been historically limited by low output power\nand the need for deep cryogenic cooling. In this work, we present a novel\ndesign for a continuous-wave diamond-based maser oscillator operating at about\n14.5 GHz and moderate cryogenic temperatures (about 180 K), achieving output\npower levels exceeding -30 dBm (1 microW). This performance represents a\ntwo-orders-of-magnitude improvement over previous diamond or ruby-based maser\noscillators.Our system integrates a high-Q (about 2460) compact metallic\nmicrowave cavity with optically pumped (111)-oriented NV-rich diamond crystals.\nThe cavity supports efficient light coupling and thermal dissipation, enabling\nsustained high-power optical excitation (>1 W) using cost-effective green LEDs.\nWe demonstrate stable maser operation with good spectral quality and validate\nits output through both frequency- and time-domain analysis with phase noise\ndata when operated in \"free running\" mode. Additionally, we provide phase noise\nestimations based on Leeson's model and show that, when coupled to a high-Q\nexternal resonator, such masers could approach thermally limited phase noise\nlevels. These predictions suggest strong potential for diamond masers to\noutperform traditional ruby-based or similar maser systems, especially given\ntheir ability to operate at higher temperatures using rugged, He-free Stirling\ncoolers. Despite current limitations related to frequency stability and jitter,\nthis work establishes diamond-based masers as promising candidates for\nnext-generation ultra-low phase noise microwave oscillators. Further\nengineering optimization - particularly in field stability, thermal regulation,\nand feedback locking - will be key to unlocking their full potential.","main_category":"cond-mat.other","categories":"cond-mat.other","published":"2025-04-09T13:02:43Z"}
{"aid":"http://arxiv.org/abs/2504.06886v1","title":"High-order fluctuations of temperature in hot QCD matter","summary":"We study the temperature fluctuations in hot quantum chromodynamics (QCD)\nmatter. A new thermodynamic state function is introduced to describe the mean\ntransverse momentum fluctuations of charged particles in heavy-ion collisions,\nenabling analytic expressions for the temperature fluctuations of different\norders. This formalism is applied to the QCD thermodynamics described by a 2+1\nflavor low energy effective field theory within the functional renormalization\ngroup approach. It is found that the temperature fluctuations are suppressed\nremarkably as the matter is evolved from the phase of hadron resonance gas to\nthe quark-gluon plasma phase with increasing temperature or baryon chemical\npotential, which is attributed to the significant increase of the heat capacity\nof matter. Furthermore, the same mechanism leads to a negative skewness in the\ntemperature fluctuations.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-09T13:42:59Z"}
{"aid":"http://arxiv.org/abs/2504.06891v1","title":"Helioseismic inference of the solar radiative opacity","summary":"The Sun is the most studied of all stars, and thus constitutes a benchmark\nfor stellar models. However, our vision of the Sun is still incomplete, as\nillustrated by the current debate on its chemical composition. The problem\nreaches far beyond chemical abundances and is intimately linked to microscopic\nand macroscopic physical ingredients of solar models such as radiative opacity,\nfor which experimental results have been recently measured that still await\ntheoretical explanations. We present opacity profiles derived from helioseismic\ninferences and compare them with detailed theoretical computations of\nindividual element contributions using three different opacity computation\ncodes, in a complementary way to experimental results. We find that our seismic\nopacity is about 10% higher than theoretical values used in current solar\nmodels around 2 million degrees, but lower by 35% than some recent available\ntheoretical values. Using the Sun as a laboratory of fundamental physics, we\nshow that quantitative comparisons between various opacity tables are required\nto understand the origin of the discrepancies between reported helioseismic,\ntheoretical and experimental opacity values.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP","published":"2025-04-09T13:51:42Z"}
{"aid":"http://arxiv.org/abs/2504.06920v1","title":"S-EO: A Large-Scale Dataset for Geometry-Aware Shadow Detection in\n  Remote Sensing Applications","summary":"We introduce the S-EO dataset: a large-scale, high-resolution dataset,\ndesigned to advance geometry-aware shadow detection. Collected from diverse\npublic-domain sources, including challenge datasets and government providers\nsuch as USGS, our dataset comprises 702 georeferenced tiles across the USA,\neach covering 500x500 m. Each tile includes multi-date, multi-angle WorldView-3\npansharpened RGB images, panchromatic images, and a ground-truth DSM of the\narea obtained from LiDAR scans. For each image, we provide a shadow mask\nderived from geometry and sun position, a vegetation mask based on the NDVI\nindex, and a bundle-adjusted RPC model. With approximately 20,000 images, the\nS-EO dataset establishes a new public resource for shadow detection in remote\nsensing imagery and its applications to 3D reconstruction. To demonstrate the\ndataset's impact, we train and evaluate a shadow detector, showcasing its\nability to generalize, even to aerial images. Finally, we extend EO-NeRF - a\nstate-of-the-art NeRF approach for satellite imagery - to leverage our shadow\npredictions for improved 3D reconstructions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T14:25:35Z"}
{"aid":"http://arxiv.org/abs/2504.06924v1","title":"Longitudinal Assessment of Lung Lesion Burden in CT","summary":"In the U.S., lung cancer is the second major cause of death. Early detection\nof suspicious lung nodules is crucial for patient treatment planning,\nmanagement, and improving outcomes. Many approaches for lung nodule\nsegmentation and volumetric analysis have been proposed, but few have looked at\nlongitudinal changes in total lung tumor burden. In this work, we trained two\n3D models (nnUNet) with and without anatomical priors to automatically segment\nlung lesions and quantified total lesion burden for each patient. The 3D model\nwithout priors significantly outperformed ($p < .001$) the model trained with\nanatomy priors. For detecting clinically significant lesions $>$ 1cm, a\nprecision of 71.3\\%, sensitivity of 68.4\\%, and F1-score of 69.8\\% was\nachieved. For segmentation, a Dice score of 77.1 $\\pm$ 20.3 and Hausdorff\ndistance error of 11.7 $\\pm$ 24.1 mm was obtained. The median lesion burden was\n6.4 cc (IQR: 2.1, 18.1) and the median volume difference between manual and\nautomated measurements was 0.02 cc (IQR: -2.8, 1.2). Agreements were also\nevaluated with linear regression and Bland-Altman plots. The proposed approach\ncan produce a personalized evaluation of the total tumor burden for a patient\nand facilitate interval change tracking over time.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-09T14:30:43Z"}
{"aid":"http://arxiv.org/abs/2504.06953v1","title":"Exact Ground States of Two Dimensional $\\pm J$ Spin Glasses","summary":"We derive exact analytical expressions for the ground-state energy and\nentropy of the two-dimensional $\\pm J$ Ising spin glass, uncovering a nested\nhierarchy of frustrations. Each level in this hierarchy contributes through the\nkernel and pseudo-determinant of effective operators, capturing the energy and\nentropy, respectively. At leading order, the structure coincides with geometric\nplaquette frustrations, while subleading corrections arise from magnetic\nadjacency matrices defined on percolated clusters in the dual lattice. Our\nresults, supported by numerical simulations, provide a systematic framework for\nanalyzing spin-glass ground states and offer new insight into glass order in\nfinite dimensions.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.stat-mech","published":"2025-04-09T14:59:02Z"}
{"aid":"http://arxiv.org/abs/2504.07001v1","title":"Leveraging GCN-based Action Recognition for Teleoperation in Daily\n  Activity Assistance","summary":"Caregiving of older adults is an urgent global challenge, with many older\nadults preferring to age in place rather than enter residential care. However,\nproviding adequate home-based assistance remains difficult, particularly in\ngeographically vast regions. Teleoperated robots offer a promising solution,\nbut conventional motion-mapping teleoperation imposes unnatural movement\nconstraints on operators, leading to muscle fatigue and reduced usability. This\npaper presents a novel teleoperation framework that leverages action\nrecognition to enable intuitive remote robot control. Using our simplified\nSpatio-Temporal Graph Convolutional Network (S-ST-GCN), the system recognizes\nhuman actions and executes corresponding preset robot trajectories, eliminating\nthe need for direct motion synchronization. A finite-state machine (FSM) is\nintegrated to enhance reliability by filtering out misclassified actions. Our\nexperiments demonstrate that the proposed framework enables effortless operator\nmovement while ensuring accurate robot execution. This proof-of-concept study\nhighlights the potential of teleoperation with action recognition for enabling\ncaregivers to remotely assist older adults during activities of daily living\n(ADLs). Future work will focus on improving the S-ST-GCN's recognition accuracy\nand generalization, integrating advanced motion planning techniques to further\nenhance robotic autonomy in older adult care, and conducting a user study to\nevaluate the system's telepresence and ease of control.","main_category":"cs.RO","categories":"cs.RO,cs.HC","published":"2025-04-09T16:14:55Z"}
{"aid":"http://arxiv.org/abs/2504.07012v1","title":"Assessing dominance in survival functions: A test for right-censored\n  data","summary":"This paper proposes a new statistical test to assess the dominance of\nsurvival functions in the presence of right-censored data. Traditional methods,\nsuch as the log-rank test, are inadequate for determining whether one survival\nfunction consistently dominates another, especially when survival curves cross.\nThe proposed test is based on the supremum of the difference between\nKaplan-Meier estimators and allows for distinguishing between dominance and\ncrossing survival curves. The paper presents the test's asymptotic properties,\nalong with simulations and applications to real datasets. The results\ndemonstrate that the test has high sensitivity for detecting crossings and\ndominance compared to conventional methods.","main_category":"stat.ME","categories":"stat.ME,math.ST,stat.TH","published":"2025-04-09T16:30:39Z"}
{"aid":"http://arxiv.org/abs/2504.07013v1","title":"Thin Coalgebraic Behaviours Are Inductive","summary":"Coalgebras for analytic functors uniformly model graph-like systems where the\nsuccessors of a state may admit certain symmetries. Examples of successor\nstructure include ordered tuples, cyclic lists and multisets. Motivated by\ngoals in automata-based verification and results on thin trees, we introduce\nthin coalgebras as those coalgebras with only countably many infinite paths\nfrom each state. Our main result is an inductive characterisation of thinness\nvia an initial algebra. To this end, we develop a syntax for thin behaviours\nand capture with a single equation when two terms represent the same thin\nbehaviour. Finally, for the special case of polynomial functors, we retrieve\nfrom our syntax the notion of Cantor-Bendixson rank of a thin tree.","main_category":"cs.FL","categories":"cs.FL","published":"2025-04-09T16:31:07Z"}
{"aid":"http://arxiv.org/abs/2504.07024v1","title":"Data Augmentation and Hyperparameter Tuning for Low-Resource MFA","summary":"A continued issue for those working with computational tools and endangered\nand under-resourced languages is the lower accuracy of results for languages\nwith smaller amounts of data. We attempt to ameliorate this issue by using data\naugmentation methods to increase corpus size, comparing augmentation to\nhyperparameter tuning for multilingual forced alignment. Unlike text\naugmentation methods, audio augmentation does not lead to substantially\nincreased performance. Hyperparameter tuning, on the other hand, results in\nsubstantial improvement without (for this amount of data) infeasible additional\ntraining time. For languages with small to medium amounts of training data,\nthis is a workable alternative to adapting models from high-resource languages.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T16:38:45Z"}
{"aid":"http://arxiv.org/abs/2504.07029v1","title":"Distilling Textual Priors from LLM to Efficient Image Fusion","summary":"Multi-modality image fusion aims to synthesize a single, comprehensive image\nfrom multiple source inputs. Traditional approaches, such as CNNs and GANs,\noffer efficiency but struggle to handle low-quality or complex inputs. Recent\nadvances in text-guided methods leverage large model priors to overcome these\nlimitations, but at the cost of significant computational overhead, both in\nmemory and inference time. To address this challenge, we propose a novel\nframework for distilling large model priors, eliminating the need for text\nguidance during inference while dramatically reducing model size. Our framework\nutilizes a teacher-student architecture, where the teacher network incorporates\nlarge model priors and transfers this knowledge to a smaller student network\nvia a tailored distillation process. Additionally, we introduce spatial-channel\ncross-fusion module to enhance the model's ability to leverage textual priors\nacross both spatial and channel dimensions. Our method achieves a favorable\ntrade-off between computational efficiency and fusion quality. The distilled\nnetwork, requiring only 10\\% of the parameters and inference time of the\nteacher network, retains 90\\% of its performance and outperforms existing SOTA\nmethods. Extensive experiments demonstrate the effectiveness of our approach.\nThe implementation will be made publicly available as an open-source resource.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T16:44:19Z"}
{"aid":"http://arxiv.org/abs/2504.07034v1","title":"Low Regularity of Self-Similar Solutions of Two-Dimensional Riemann\n  problems with Shocks for the Isentropic Euler system","summary":"We are concerned with the low regularity of self-similar solutions of\ntwo-dimensional Riemann problems for the isentropic Euler system. We establish\na general framework for the analysis of the local regularity of such solutions\nfor a class of two-dimensional Riemann problems for the isentropic Euler\nsystem, which includes the regular shock reflection problem, the Prandtl\nreflection problem, the Lighthill diffraction problem, and the four-shock\nRiemann problem. We prove that it is not possible that both the density and the\nvelocity are in $H^1$ in the subsonic domain for the self-similar solutions of\nthese problems in general. This indicates that the self-similar solutions of\nthe Riemann problems with shocks for the isentropic Euler system are of much\nmore complicated structure than those for the Euler system for potential flow;\nin particular, the density and the velocity are not necessarily continuous in\nthe subsonic domain. The proof is based on a regularization of the isentropic\nEuler system to derive the transport equation for the vorticity, a\nrenormalization argument extended to the case of domains with boundary, and\nDiPerna-Lions-type commutator estimates.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP,nlin.PS,physics.flu-dyn","published":"2025-04-09T16:48:12Z"}
{"aid":"http://arxiv.org/abs/2504.07037v1","title":"VQE calculations on a NISQ era trapped ion quantum computer using a\n  multireference unitary coupled cluster ansatz: application to the BeH$_2$\n  insertion problem","summary":"In this study, we employ the variational quantum eigensolver algorithm with a\nmultireference unitary coupled cluster ansatz to report the ground state energy\nof the BeH$_2$ molecule in a geometry where strong correlation effects are\nsignificant. We consider the two most important determinants in the\nconstruction of the reference state for our ansatz. Furthermore, in order to\ncarry out our intended 12-qubit computation on a noisy intermediate scale\nquantum era trapped ion hardware (the commercially available IonQ Forte-I), we\nperform a series of resource reduction techniques to a. decrease the number of\ntwo-qubit gates by 99.84% (from 12515 to 20 two-qubit gates) relative to the\nunoptimized circuit, and b. reduce the number of measurements via the idea of\nsupercliques, while losing 2.69% in the obtained ground state energy (with\nerror mitigation and post-selection) relative to that computed classically for\nthe same resource-optimized problem setting.","main_category":"physics.chem-ph","categories":"physics.chem-ph,physics.atom-ph,quant-ph","published":"2025-04-09T16:52:37Z"}
{"aid":"http://arxiv.org/abs/2504.07056v1","title":"The Lyman-alpha and Continuum Origins Survey I: Survey description and\n  Ly$α$ imaging","summary":"Understanding the mechanisms driving the escape of ionizing or Lyman\ncontinuum (LyC) emission from the interstellar medium of galaxies is necessary\nto constrain the evolution of Reionization, and the sources responsible for it.\nWhile progress has been made into identifying the global galaxy properties\nlinked to the escape fraction of ionizing radiation, f$_{esc}^{LyC}$, little is\ncurrently known about how spatially resolved galaxy properties impact this\nparameter. We present Hubble Space Telescope (HST) imaging data obtained as\npart of the Lyman $\\alpha$ and Continuum Origins Survey (LaCOS). LaCOS consists\nof HST imaging in 5 filters covering rest-frame optical and UV bands for a\nsubsample of 42 galaxies in the Low redshift Lyman Continuum Survey, 22 being\nLyman continuum emitters ($f_{esc}^{LyC}=0.01-0.49$). These data allow for\ninvestigations of the connection between sub-kpc stellar and nebular\nproperties, including Ly$\\alpha$ emission, and $f_{esc}^{LyC}$. Here, we\ndescribe the sample selection, observations and data reduction methods.\nAdditionally, we present results on the link between global and resolved\nLy$\\alpha$ photometry and $f_{esc}^{LyC}$. We find similar trends between\nglobal photometric observables ($L_{Ly\\alpha}$, $EW_{Ly\\alpha}$,\n$f_{esc}^{Ly\\alpha}$, $r_{50}$, $\\Sigma_{SFR}$) and $f_{esc}^{LyC}$ as\npreviously found with spectroscopy, but the correlations generally show a\nslightly smaller degree of correlations. However, we do find strong\ncorrelations between Ly$\\alpha$ observables ($L_{Ly\\alpha}$,$EW_{Ly\\alpha}$)\nand $f_{esc}^{LyC}$ when measured in a small aperture around the brightest UV\nsource in each galaxy. We interpret these results as evidence that LyC photons\nescaping on the line-of-sight are contributed by a small number of UV-bright\ncompact regions in most galaxies in our sample.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-04-09T17:16:55Z"}
{"aid":"http://arxiv.org/abs/2504.07077v1","title":"Machine Learning Approach towards Quantum Error Mitigation for Accurate\n  Molecular Energetics","summary":"Despite significant efforts, the realization of the hybrid quantum-classical\nalgorithms has predominantly been confined to proof-of-principles, mainly due\nto the hardware noise. With fault-tolerant implementation being a long-term\ngoal, going beyond small molecules with existing error mitigation (EM)\ntechniques with current noisy intermediate scale quantum (NISQ) devices has\nbeen a challenge. That being said, statistical learning methods are promising\napproaches to learning the noise and its subsequent mitigation. We devise a\ngraph neural network and regression-based machine learning (ML) architecture\nfor practical realization of EM techniques for molecular Hamiltonian without\nthe requirement of the exponential overhead. Given the short coherence time of\nthe quantum hardware, the ML model is trained with either ideal or mitigated\nexpectation values over a judiciously chosen ensemble of shallow sub-circuits\nadhering to the native hardware architecture. The hardware connectivity network\nis mapped to a directed graph which encodes the information of the native gate\nnoise profile to generate the features for the neural network. The training\ndata is generated on-the-fly during ansatz construction thus removing the\ncomputational overhead. We demonstrate orders of magnitude improvements in\npredicted energy over a few strongly correlated molecules.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T17:49:09Z"}
{"aid":"http://arxiv.org/abs/2504.07081v1","title":"Self-Steering Language Models","summary":"While test-time reasoning enables language models to tackle complex tasks,\nsearching or planning in natural language can be slow, costly, and error-prone.\nBut even when LMs struggle to emulate the precise reasoning steps needed to\nsolve a problem, they often excel at describing its abstract structure--both\nhow to verify solutions and how to search for them. This paper introduces\nDisCIPL, a method for \"self-steering\" LMs where a Planner model generates a\ntask-specific inference program that is executed by a population of Follower\nmodels. Our approach equips LMs with the ability to write recursive search\nprocedures that guide LM inference, enabling new forms of verifiable and\nefficient reasoning. When instantiated with a small Follower (e.g.,\nLlama-3.2-1B), DisCIPL matches (and sometimes outperforms) much larger models,\nincluding GPT-4o and o1, on challenging constrained generation tasks. In\ndecoupling planning from execution, our work opens up a design space of\nhighly-parallelized Monte Carlo inference strategies that outperform standard\nbest-of-N sampling, require no finetuning, and can be implemented automatically\nby existing LMs.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-09T17:54:22Z"}
{"aid":"http://arxiv.org/abs/2504.07408v1","title":"AI Coding with Few-Shot Prompting for Thematic Analysis","summary":"This paper explores the use of large language models (LLMs), here represented\nby GPT 3.5-Turbo to perform coding for a thematic analysis. Coding is highly\nlabor intensive, making it infeasible for most researchers to conduct\nexhaustive thematic analyses of large corpora. We utilize few-shot prompting\nwith higher quality codes generated on semantically similar passages to enhance\nthe quality of the codes while utilizing a cheap, more easily scalable model.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T03:02:15Z"}
{"aid":"http://arxiv.org/abs/2504.07412v1","title":"Toda-type presentations for the quantum K theory of partial flag\n  varieties","summary":"We prove a determinantal, Toda-type, presentation for the equivariant K\ntheory of a partial flag variety $\\mathrm{Fl}(r_1, \\ldots, r_k;n)$. The proof\nrelies on pushing forward the Toda presentation obtained by Maeno, Naito and\nSagaki for the complete flag variety $\\mathrm{Fl}(n)$, via Kato's\n$\\mathrm{K}_T(\\mathrm{pt})$-algebra homomorphism from the quantum K ring of\n$\\mathrm{Fl}(n)$ to that of $\\mathrm{Fl}(r_1, \\ldots, r_k;n)$. Starting instead\nfrom the Whitney presentation for $\\mathrm{Fl}(n)$, we show that the same\npush-forward technique gives a recursive formula for polynomial representatives\nof quantum K Schubert classes in any partial flag variety which do not depend\non quantum parameters. In an appendix, we include another proof of the Toda\npresentation for the equivariant quantum K ring of $\\mathrm{Fl}(n)$, following\nAnderson, Chen, and Tseng, which is based on the fact that the $\\mathrm{K}$\ntheoretic $J$-function is an eigenfunction of the finite difference Toda\nHamiltonians.","main_category":"math.AG","categories":"math.AG,math.CO,math.RT","published":"2025-04-10T03:06:06Z"}
{"aid":"http://arxiv.org/abs/2504.07414v1","title":"Decomposition-Based Optimal Bounds for Privacy Amplification via\n  Shuffling","summary":"Shuffling has been shown to amplify differential privacy guarantees, offering\na stronger privacy-utility trade-off. To characterize and compute this\namplification, two fundamental analytical frameworks have been proposed: the\nprivacy blanket by Balle et al. (CRYPTO 2019) and the clone paradigm (including\nboth the standard clone and stronger clone) by Feldman et al. (FOCS 2021, SODA\n2023). All these methods rely on decomposing local randomizers.\n  In this work, we introduce a unified analysis framework--the general clone\nparadigm--which encompasses all possible decompositions. We identify the\noptimal decomposition within the general clone paradigm. Moreover, we develop a\nsimple and efficient algorithm to compute the exact value of the optimal\nprivacy amplification bounds via Fast Fourier Transform. Experimental results\ndemonstrate that the computed upper bounds for privacy amplification closely\napproximate the lower bounds, highlighting the tightness of our approach.\nFinally, using our algorithm, we conduct the first systematic analysis of the\njoint composition of LDP protocols in the shuffle model.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-10T03:11:17Z"}
{"aid":"http://arxiv.org/abs/2504.07422v1","title":"The Role of Machine Learning in Reducing Healthcare Costs: The Impact of\n  Medication Adherence and Preventive Care on Hospitalization Expenses","summary":"This study reveals the important role of prevention care and medication\nadherence in reducing hospitalizations. By using a structured dataset of 1,171\npatients, four machine learning models Logistic Regression, Gradient Boosting,\nRandom Forest, and Artificial Neural Networks are applied to predict five-year\nhospitalization risk, with the Gradient Boosting model achieving the highest\naccuracy of 81.2%. The result demonstrated that patients with high medication\nadherence and consistent preventive care can reduce 38.3% and 37.7% in\nhospitalization risk. The finding also suggests that targeted preventive care\ncan have positive Return on Investment (ROI), and therefore ML models can\neffectively direct personalized interventions and contribute to long-term\nmedical savings.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CY","published":"2025-04-10T03:28:42Z"}
{"aid":"http://arxiv.org/abs/2504.07435v1","title":"Opportunity-Cost-Driven Reward Mechanisms for Crowd-Sourced Computing\n  Platforms","summary":"This paper introduces a game-theoretic model tailored for reward distribution\non crowd-sourced computing platforms. It explores a repeated game framework\nwhere miners, as computation providers, decide their computation power\ncontribution in each round, guided by the platform's designed reward\ndistribution mechanism. The reward for each miner in every round is based on\nthe platform's randomized task payments and the miners' computation\ntranscripts. Specifically, it defines Opportunity-Cost-Driven Incentive\nCompatibility (OCD-IC) and Dynamic OCD-IC (DOCD-IC) for scenarios where\nstrategic miners might allocate some computation power to more profitable\nactivities, such as Bitcoin mining. The platform must also achieve Budget\nBalance (BB), aiming for a non-negative total income over the long term. This\npaper demonstrates that traditional Pay-Per-Share (PPS) reward schemes require\nassumptions about task demand and miners' opportunity costs to ensure OCD-IC\nand BB, yet they fail to satisfy DOCD-IC. The paper then introduces\nPay-Per-Share with Subsidy (PPSS), a new reward mechanism that allows the\nplatform to provide subsidies to miners, thus eliminating the need for\nassumptions on opportunity cost to achieve OCD-IC, DOCD-IC, and long-term BB.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-10T04:05:48Z"}
{"aid":"http://arxiv.org/abs/2504.07452v1","title":"Laboratory Three-dimensional X-ray Micro-beam Laue Diffraction","summary":"The development of three-dimensional (3D) non-destructive X-ray\ncharacterization techniques in home laboratories is essential for enabling many\nmore researchers to perform 3D characterization daily, overcoming the\nlimitations imposed by competitive and scarce access to synchrotron facilities.\nRecent efforts have focused on techniques such as laboratory diffraction\ncontrast tomography (LabDCT), which allows 3D characterization of\nrecrystallized grains with sizes larger than 15-20 $\\mu$m, offering a boundary\nresolution of approximately 5$\\mu$m using commercial X-ray computed tomography\n(CT) systems. To enhance the capabilities of laboratory instruments, we have\ndeveloped a new laboratory-based 3D X-ray micro-beam diffraction\n(Lab-3D$\\mu$XRD) technique. Lab-3D$\\mu$XRD combines the use of a focused\npolychromatic beam with a scanning-tomographic data acquisition routine to\nenable depth-resolved crystallographic orientation characterization. This work\npresents the first realization of Lab-3D$\\mu$XRD, including hardware\ndevelopment through the integration of a newly developed Pt-coated twin\nparaboloidal capillary X-ray focusing optics into a conventional X-ray $\\mu$CT\nsystem, as well as the development of data acquisition and processing software.\nThe results are validated through comparisons with LabDCT and synchrotron phase\ncontrast tomography. The findings clearly demonstrate the feasibility of\nLab-3D$\\mu$XRD, particularly in detecting smaller grains and providing\nintragranular information. Finally, we discuss future directions for developing\nLab-3D$\\mu$XRD into a versatile tool for studying materials with smaller grain\nsizes and high defect densities, including the potential of combining it with\nLabDCT and $\\mu$CT for multiscale and multimodal microstructural\ncharacterization.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-10T04:53:58Z"}
{"aid":"http://arxiv.org/abs/2504.07473v1","title":"Standard $t$-structures","summary":"We provide a general construction of induced $t$-structures, that generalizes\nstandard $t$-structures for $\\infty$-categories of sheaves. More precisely,\ngiven a presentable $\\infty$-category $\\mathcal{X}$ and a presentable stable\n$\\infty$-category $\\mathcal{E}$ equipped with an accessible $t$-structure $\\tau\n= (\\mathcal{E}_{\\geq 0}, \\mathcal{E}_{\\leq 0})$, we show that $\\mathcal{X}\n\\otimes \\mathcal{E}$ is equipped with a canonical $t$-structure whose\ncoconnective part is given in $\\mathcal{X} \\otimes \\mathcal{E}_{\\leq 0}$. When\n$\\mathcal{X}$ is an $\\infty$-topos, we give a more explicit description of the\nconnective part as well.","main_category":"math.CT","categories":"math.CT,math.AT","published":"2025-04-10T05:55:43Z"}
{"aid":"http://arxiv.org/abs/2504.07485v1","title":"Rendering Large Volume Datasets in Unreal Engine 5: A Survey","summary":"In this technical report, we discuss several approaches to in-core rendering\nof large volumetric datasets in Unreal Engine 5 (UE5). We explore the following\nmethods: the TBRayMarcher Plugin, the Niagara Fluids Plugin , and various\napproaches using Sparse Volume Textures (SVT), with a particular focus on\nHeterogeneous Volumes (HV). We found the HV approach to be the most promising.\nThe biggest challenge we encountered with other approaches was the need to\nchunk datasets so that each fits into volume textures smaller than one\ngigavoxel. While this enables display of the entire dataset at reasonable frame\nrates, it introduces noticeable artifacts at chunk borders due to incorrect\nlighting, as each chunk lacks information about its neighbors. After addressing\nsome (signed) int32 overflows in the Engine's SVT-related source code by\nconverting them to to (unsigned) uint32 or int64, the SVT-based HV system\nallows us to render sparse datasets up to 32k x 32k x 16k voxels, provided the\ncompressed tile data (including MIP data and padding for correct interpolation)\ndoes not exceed 4 gigavoxels. In the future, we intend to extend the existing\nSVT streaming functionality to support out-of-core rendering, in order to\neventually overcome VRAM limitations, graphics API constraints, and the\nperformance issues associated with 64-bit arithmetic in GPU shaders.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-10T06:42:19Z"}
{"aid":"http://arxiv.org/abs/2504.07494v1","title":"Apt-Serve: Adaptive Request Scheduling on Hybrid Cache for Scalable LLM\n  Inference Serving","summary":"Large language model (LLM) inference serving systems are essential to various\nLLM-based applications. As demand for LLM services continues to grow, scaling\nthese systems to handle high request rates while meeting latency Service-Level\nObjectives (SLOs), referred to as effective throughput, becomes critical.\nHowever, existing systems often struggle to improve effective throughput,\nprimarily due to a significant decline in Time To First Token (TTFT) SLO\nattainment. We identify two major causes of this bottleneck: (1)\nmemory-intensive KV cache that limits batch size expansion under GPU memory\nconstraints, and (2) rigid batch composition enforced by the default\nFirst-Come-First-Serve scheduling policy. In this paper, we introduce\nApt-Serve, a scalable framework designed to enhance effective throughput in LLM\ninference serving. Apt-Serve features a new hybrid cache scheme that combines\nKV cache with a memory-efficient hidden cache for reusable input hidden state\nvectors, allowing large batch sizes and improving request concurrency. Based on\nthe hybrid cache, Apt-Serve employs an adaptive runtime scheduling mechanism\nthat dynamically optimizes batch composition. We formally define the adaptive\nscheduling optimization problem and propose an efficient algorithm with\ntheoretical guarantees. Extensive evaluations on three real-world datasets and\nLLMs ranging from 13B to 66B parameters demonstrate that Apt-Serve achieves up\nto 8.8x improvement in effective throughput compared to the state-of-the-art\ninference serving systems.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-10T06:51:23Z"}
{"aid":"http://arxiv.org/abs/2504.07496v1","title":"Modular Control of Discrete Event System for Modeling and Mitigating\n  Power System Cascading Failures","summary":"Cascading failures in power systems caused by sequential tripping of\ncomponents are a serious concern as they can lead to complete or partial\nshutdowns, disrupting vital services and causing damage and inconvenience. In\nprior work, we developed a new approach for identifying and preventing\ncascading failures in power systems. The approach uses supervisory control\ntechnique of discrete event systems (DES) by incorporating both on-line\nlookahead control and forcible events. In this paper, we use modular\nsupervisory control of DES to reduce computation complexity and increase the\nrobustness and reliability of control. Modular supervisory control allows us to\npredict and mitigate cascading failures in power systems more effectively. We\nimplemented the proposed control technique on a simulation platform developed\nin MATLAB and applied the proposed DES controller. The calculations of modular\nsupervisory control of DES are performed using an external tool and imported\ninto the MATLAB platform. We conduct simulation studies for the IEEE 30-bus,\n118-bus and 300-bus systems, and the results demonstrate the effectiveness of\nour proposed approach.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-10T06:53:35Z"}
{"aid":"http://arxiv.org/abs/2504.07499v1","title":"Digital quantum simulation of the Su-Schrieffer-Heeger model using a\n  parameterized quantum circuit","summary":"We perform digital quantum simulations of the noninteracting\nSu-Schrieffer-Heeger (SSH) model using a parameterized quantum circuit. The\ncircuit comprises two main components: the first prepares the initial state\nfrom the product state $|0\\rangle^{\\otimes L}$, where $L$ is the system size;\nthe second consists of $M$ layers of brick-wall unitaries simulating time\nevolution. The evolution times, encoded as the rotation angles of quantum gates\nin the second part, are optimized variationally to minimize the energy. The SSH\nmodel exhibits two distinct topological phases, depending on the relative\nstrengths of inter- and intra-cell hopping amplitudes. We investigate the\nevolution of the energy, entanglement entropy, and mutual information towards\ntopologically trivial and nontrivial ground states. Our results find the\nfollows: (i) When the initial and target ground states belong to the same\ntopological phase, the variational energy decreases exponentially, the\nentanglement entropy quickly saturates in a system-size-independent manner, and\nthe mutual information remains spatially localized, as the number of layers\nincreases. (ii) When the initial and target ground states belong to different\ntopological phases, the variational energy decreases polynomially, the\nentanglement entropy initially grows logarithmically before decreasing, and the\nmutual information spreads ballistically across the entire system, with\nincreasing the number of layers. Furthermore, by calculating the polarization,\nwe identify a topological phase transition occurring at an intermediate circuit\nlayer when the initial and final target states lie in different topological\ncharacters. Finally, we experimentally confirm this topological phase\ntransition in an 18-site system using 19 qubits on a trapped-ion quantum\ncomputer provided by Quantinuum.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-10T06:54:10Z"}
{"aid":"http://arxiv.org/abs/2504.07506v1","title":"Normalized solutions to mixed dispersion nonlinear Schrödinger system\n  with coupled nonlinearity","summary":"In this paper, we consider the existence of normalized solutions for the\nfollowing biharmonic nonlinear Schr\\\"{o}dinger system\n  \\[ \\begin{aligned}\n  \\begin{cases}\n  &\\Delta^2u+\\alpha_{1}\\Delta u+\\lambda u=\\beta r_{1}|u|^{r_{1}-2}|v|^{r_{2}} u\n&&\\text{ in } \\mathbb{R}^{N},\n  & \\Delta^2v+\\alpha_{2}\\Delta v+\\lambda v=\\beta r_{2}|u|^{r_{1}}|v|^{r_{2}-2}\nv && \\text{ in } \\mathbb{R}^{N},\\\\ & \\int_{\\mathbb{R}^{N}} (u^{2}+v^{2}){\\rm d}\nx=\\rho^{2},&&\n  \\end{cases} \\end{aligned}\n  \\]\n  where $\\Delta^2u=\\Delta(\\Delta u)$ is the biharmonic operator, $\\alpha_{1}$,\n$\\alpha_{2}$, $\\beta>0$, $r_{1}$, $r_{2}>1$, $N\\geq 1$. $\\rho^2$ stands for the\nprescribed mass, and $\\lambda\\in\\mathbb{R}$ arises as a Lagrange multiplier.\nSuch single constraint permits mass transformation in two materials. When\n$r_{1}+r_{2}\\in\\left(2,2+\\frac{8}{N}\\right]$, we obtain a dichotomy result for\nthe existence of nontrivial ground states. Especially when $\\alpha_1=\\alpha_2$,\nthe ground state exists for all $\\rho>0$ if and only if\n$r_1+r_2<\\min\\left\\{\\max\\left\\{4, 2+\\frac{8}{N+1}\\right\\},\n2+\\frac{8}{N}\\right\\}$. When $r_{1}+r_{2}\\in\\left(2+\\frac{8}{N},\n\\frac{2N}{(N-4)^{+}}\\right)$ and $N\\geq 2$, we obtain the existence of radial\nnontrivial mountain pass solution for small $\\rho>0$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-10T07:08:19Z"}
{"aid":"http://arxiv.org/abs/2504.07524v1","title":"DGOcc: Depth-aware Global Query-based Network for Monocular 3D Occupancy\n  Prediction","summary":"Monocular 3D occupancy prediction, aiming to predict the occupancy and\nsemantics within interesting regions of 3D scenes from only 2D images, has\ngarnered increasing attention recently for its vital role in 3D scene\nunderstanding. Predicting the 3D occupancy of large-scale outdoor scenes from\n2D images is ill-posed and resource-intensive. In this paper, we present\n\\textbf{DGOcc}, a \\textbf{D}epth-aware \\textbf{G}lobal query-based network for\nmonocular 3D \\textbf{Occ}upancy prediction. We first explore prior depth maps\nto extract depth context features that provide explicit geometric information\nfor the occupancy network. Then, in order to fully exploit the depth context\nfeatures, we propose a Global Query-based (GQ) Module. The cooperation of\nattention mechanisms and scale-aware operations facilitates the feature\ninteraction between images and 3D voxels. Moreover, a Hierarchical Supervision\nStrategy (HSS) is designed to avoid upsampling the high-dimension 3D voxel\nfeatures to full resolution, which mitigates GPU memory utilization and time\ncost. Extensive experiments on SemanticKITTI and SSCBench-KITTI-360 datasets\ndemonstrate that the proposed method achieves the best performance on monocular\nsemantic occupancy prediction while reducing GPU and time overhead.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T07:44:55Z"}
{"aid":"http://arxiv.org/abs/2504.07533v1","title":"Quantitative uniqueness of continuation for the Schrödinger equation :\n  explicit dependence on the potential","summary":"We demonstrate a quantitative version of the usual properties related to\nunique continuation from an interior datum for the Schr\\\"odinger equation with\nbounded or unbounded potential. The inequalities we establish have constants\nthat explicitly depend on the potential. We also indicate how the\nabove-mentioned inequalities can be extended to elliptic equations with bounded\nor unbounded first-order derivatives. The case of unique continuation from\nCauchy data is also considered.","main_category":"math.AP","categories":"math.AP","published":"2025-04-10T07:59:04Z"}
{"aid":"http://arxiv.org/abs/2504.07545v1","title":"Convexity Helps Iterated Search in 3D","summary":"Inspired by the classical fractional cascading technique, we introduce new\ntechniques to speed up the following type of iterated search in 3D: The input\nis a graph $\\mathbf{G}$ with bounded degree together with a set $H_v$ of 3D\nhyperplanes associated with every vertex of $v$ of $\\mathbf{G}$. The goal is to\nstore the input such that given a query point $q\\in \\mathbb{R}^3$ and a\nconnected subgraph $\\mathbf{H}\\subset \\mathbf{G}$, we can decide if $q$ is\nbelow or above the lower envelope of $H_v$ for every $v\\in \\mathbf{H}$. We show\nthat using linear space, it is possible to answer queries in roughly $O(\\log n\n+ |\\mathbf{H}|\\sqrt{\\log n})$ time which improves trivial bound of\n$O(|\\mathbf{H}|\\log n)$ obtained by using planar point location data\nstructures. Our data structure can in fact answer more general queries (it\ncombines with shallow cuttings) and it even works when $\\mathbf{H}$ is given\none vertex at a time. We show that this has a number of new applications and in\nparticular, we give improved solutions to a set of natural data structure\nproblems that up to our knowledge had not seen any improvements.\n  We believe this is a very surprising result because obtaining similar results\nfor the planar point location problem was known to be impossible.","main_category":"cs.CG","categories":"cs.CG","published":"2025-04-10T08:20:36Z"}
{"aid":"http://arxiv.org/abs/2504.07548v1","title":"On the variety of solutions of 1-dimensional nonlinear eigenvalue\n  problems","summary":"Second order nonlinear eigenvalue problems are considered for which the\nspectrum is an interval. The boundary conditions are of Robin and Dirichlet\ntype. The shape and the number of solutions are discussed by means of a phase\nplane analysis. A new type of asymmetric solutions are discovered. Some\nnumerical illustrations are given.","main_category":"math.DS","categories":"math.DS","published":"2025-04-10T08:23:38Z"}
{"aid":"http://arxiv.org/abs/2504.07557v1","title":"Using LLMs for Analyzing AIS Data","summary":"Recent research in Large Language Models (LLMs), has had a profound impact\nacross various fields, including mobility data science. This paper explores the\nand experiment with different approaches to using LLMs for analyzing AIS data.\nWe propose a set of carefully designed queries to assess the reasoning\ncapabilities of LLMs in this kind of tasks. Further, we experiment with four\ndifferent methods: (1) using LLMs as a natural language interface to a spatial\ndatabase, (2) reasoning on raw data, (3) reasoning on compressed trajectories,\nand (4) reasoning on semantic trajectories. We investigate the strengths and\nweaknesses for the four methods, and discuss the findings. The goal is to\nprovide valuable insights for both researchers and practitioners on selecting\nthe most appropriate LLM-based method depending on their specific data analysis\nobjectives.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-10T08:38:39Z"}
{"aid":"http://arxiv.org/abs/2504.07578v1","title":"Privacy-Preserving Vertical K-Means Clustering","summary":"Clustering is a fundamental data processing task used for grouping records\nbased on one or more features. In the vertically partitioned setting, data is\ndistributed among entities, with each holding only a subset of those features.\nA key challenge in this scenario is that computing distances between records\nrequires access to all distributed features, which may be privacy-sensitive and\ncannot be directly shared with other parties. The goal is to compute the joint\nclusters while preserving the privacy of each entity's dataset. Existing\nsolutions using secret sharing or garbled circuits implement privacy-preserving\nvariants of Lloyd's algorithm but incur high communication costs, scaling as\nO(nkt), where n is the number of data points, k the number of clusters, and t\nthe number of rounds. These methods become impractical for large datasets or\nseveral parties, limiting their use to LAN settings only. On the other hand, a\ndifferent line of solutions rely on differential privacy (DP) to outsource the\nlocal features of the parties to a central server. However, they often\nsignificantly degrade the utility of the clustering outcome due to excessive\nnoise. In this work, we propose a novel solution based on homomorphic\nencryption and DP, reducing communication complexity to O(n+kt). In our method,\nparties securely outsource their features once, allowing a computing party to\nperform clustering operations under encryption. DP is applied only to the\nclusters' centroids, ensuring privacy with minimal impact on utility. Our\nsolution clusters 100,000 two-dimensional points into five clusters using only\n73MB of communication, compared to 101GB for existing works, and completes in\njust under 3 minutes on a 100Mbps network, whereas existing works take over 1\nday. This makes our solution practical even for WAN deployments, all while\nmaintaining accuracy comparable to plaintext k-means algorithms.","main_category":"cs.CR","categories":"cs.CR,cs.LG","published":"2025-04-10T09:20:56Z"}
{"aid":"http://arxiv.org/abs/2504.07595v1","title":"High-Level Synthesis using SDF-AP, Template Haskell, QuasiQuotes, and\n  GADTs to Generate Circuits from Hierarchical Input Specification","summary":"FPGAs provide highly parallel and customizable hardware solutions but are\ntraditionally programmed using low-level Hardware Description Languages (HDLs)\nlike VHDL and Verilog. These languages have a low level of abstraction and\nrequire engineers to manage control and scheduling manually. High-Level\nSynthesis (HLS) tools attempt to lift this level of abstraction by translating\nC/C++ code into hardware descriptions, but their reliance on imperative\nparadigms leads to challenges in deriving parallelism due to pointer aliasing\nand sequential execution models.\n  Functional programming, with its inherent purity, immutability, and\nparallelism, presents a more natural abstraction for FPGA design. Existing\nfunctional hardware description tools such as Clash enable high-level circuit\ndescriptions but lack automated scheduling and control mechanisms. Prior work\nby Folmer introduced a framework integrating SDF-AP graphs into Haskell for\nautomatic hardware generation, but it lacked hierarchy and reusability.\n  This paper extends that framework by introducing hierarchical pattern\nspecification, enabling structured composition and scalable parallelism. Key\ncontributions include: (1) automatic hardware generation, where both data and\ncontrol paths are derived from functional specifications with hierarchical\npatterns, (2) parameterized buffers using GADTs, eliminating the need for\nmanual buffer definitions and facilitating component reuse, and (3) provision\nof a reference \"golden model\" that can be simulated in the integrated\nenvironment for validation.\n  The core focus of this paper is on methodology. But we also evaluate our\napproach against Vitis HLS, comparing both notation and resulting hardware\narchitectures. Experimental results demonstrate that our method provides\ngreater transparency in resource utilization and scheduling, often\noutperforming Vitis in both scheduling and predictability.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-10T09:48:22Z"}
{"aid":"http://arxiv.org/abs/2504.07657v1","title":"Single-Pixel Imaging Technology in Holographic Microscopy","summary":"We propose a holographic microscopy method based on single-pixel imaging\ntechnology (HM-SPI). We used a holographic microscopy method based on in-line\nGabor holography. In single-pixel imaging technology, cyclic binary masks and\namplitude-phase masks are used instead of cyclic Hadamard masks. These masks\nare generated using the quadratic residue and twin-prime techniques. Numerical\nresults are presented for both cases. Unlike the traditional approach of using\nDMD technology, our model considers a photodetector as a single-pixel detector.\nWe propose a method based on the fast Fourier transform (FFT) algorithm to\nreconstruct the original field, which has a computational complexity of\nO(NlogN). This approach opens up prospects for the development of compact\nholographic systems capable of operating across a wide spectral range and under\nlimited computational resources.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-10T11:15:46Z"}
{"aid":"http://arxiv.org/abs/2504.07675v1","title":"Low-Complexity Optimization of Antenna Switching Schemes for Dynamic\n  Channel Sounding","summary":"Understanding wireless channels is crucial for the design of wireless\nsystems. For mobile communication, sounders and antenna arrays with short\nmeasurement times are required to simultaneously capture the dynamic and\nspatial channel characteristics. Switched antenna arrays are an attractive\noption that can overcome the high cost of real arrays and the long measurement\ntimes of virtual arrays. Optimization of the switching sequences is then\nessential to avoid aliasing and increase the accuracy of channel parameter\nestimates. This paper provides a novel and comprehensive analysis of the design\nof switching sequences. We first review the conventional spatio-temporal\nambiguity function, extend it to dual-polarized antenna arrays, and analyze its\nprohibitive complexity when designing for ultra-massive antenna arrays. We thus\npropose a new method that uses the Fisher information matrix to tackle the\nestimation accuracy. We also propose to minimize the ambiguity by choosing a\nswitching sequence that minimizes side lobes in its Fourier spectrum. In this\nsense, we divide the sequence design problem into Fourier-based ambiguity\nreduction and Fisher-based accuracy improvement, and coin the resulting design\napproach as Fourier-Fisher. Simulations and measurements show that the\nFourier-Fisher approach achieves identical performance and significantly lower\ncomputational complexity than that of the conventional ambiguity-based\napproach.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-10T11:56:37Z"}
{"aid":"http://arxiv.org/abs/2504.07677v1","title":"Localization Meets Uncertainty: Uncertainty-Aware Multi-Modal\n  Localization","summary":"Reliable localization is critical for robot navigation in complex indoor\nenvironments. In this paper, we propose an uncertainty-aware localization\nmethod that enhances the reliability of localization outputs without modifying\nthe prediction model itself. This study introduces a percentile-based rejection\nstrategy that filters out unreliable 3-DoF pose predictions based on aleatoric\nand epistemic uncertainties the network estimates. We apply this approach to a\nmulti-modal end-to-end localization that fuses RGB images and 2D LiDAR data,\nand we evaluate it across three real-world datasets collected using a\ncommercialized serving robot. Experimental results show that applying stricter\nuncertainty thresholds consistently improves pose accuracy. Specifically, the\nmean position error is reduced by 41.0%, 56.7%, and 69.4%, and the mean\norientation error by 55.6%, 65.7%, and 73.3%, when applying 90%, 80%, and 70%\nthresholds, respectively. Furthermore, the rejection strategy effectively\nremoves extreme outliers, resulting in better alignment with ground truth\ntrajectories. To the best of our knowledge, this is the first study to\nquantitatively demonstrate the benefits of percentile-based uncertainty\nrejection in multi-modal end-to-end localization tasks. Our approach provides a\npractical means to enhance the reliability and accuracy of localization systems\nin real-world deployments.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-10T12:07:24Z"}
{"aid":"http://arxiv.org/abs/2504.07680v1","title":"Synthetic Fluency: Hallucinations, Confabulations, and the Creation of\n  Irish Words in LLM-Generated Translations","summary":"This study examines hallucinations in Large Language Model (LLM) translations\ninto Irish, specifically focusing on instances where the models generate novel,\nnon-existent words. We classify these hallucinations within verb and noun\ncategories, identifying six distinct patterns among the latter. Additionally,\nwe analyse whether these hallucinations adhere to Irish morphological rules and\nwhat linguistic tendencies they exhibit. Our findings show that while both\nGPT-4.o and GPT-4.o Mini produce similar types of hallucinations, the Mini\nmodel generates them at a significantly higher frequency. Beyond\nclassification, the discussion raises speculative questions about the\nimplications of these hallucinations for the Irish language. Rather than\nseeking definitive answers, we offer food for thought regarding the increasing\nuse of LLMs and their potential role in shaping Irish vocabulary and linguistic\nevolution. We aim to prompt discussion on how such technologies might influence\nlanguage over time, particularly in the context of low-resource,\nmorphologically rich languages.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T12:08:47Z"}
{"aid":"http://arxiv.org/abs/2504.07687v1","title":"FMNV: A Dataset of Media-Published News Videos for Fake News Detection","summary":"News media, particularly video-based platforms, have become deeply embedded\nin daily life, concurrently amplifying risks of misinformation dissemination.\nConsequently, multimodal fake news detection has garnered significant research\nattention. However, existing datasets predominantly comprise user-generated\nvideos characterized by crude editing and limited public engagement, whereas\nprofessionally crafted fake news videos disseminated by media outlets often\npolitically or virally motivated pose substantially greater societal harm. To\naddress this gap, we construct FMNV, a novel dataset exclusively composed of\nnews videos published by media organizations. Through empirical analysis of\nexisting datasets and our curated collection, we categorize fake news videos\ninto four distinct types. Building upon this taxonomy, we employ Large Language\nModels (LLMs) to automatically generate deceptive content by manipulating\nauthentic media-published news videos. Furthermore, we propose FMNVD, a\nbaseline model featuring a dual-stream architecture integrating CLIP and Faster\nR-CNN for video feature extraction, enhanced by co-attention mechanisms for\nfeature refinement and multimodal aggregation. Comparative experiments\ndemonstrate both the generalization capability of FMNV across multiple\nbaselines and the superior detection efficacy of FMNVD. This work establishes\ncritical benchmarks for detecting high-impact fake news in media ecosystems\nwhile advancing methodologies for cross-modal inconsistency analysis.","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-10T12:16:32Z"}
{"aid":"http://arxiv.org/abs/2504.07698v1","title":"Proactive User Information Acquisition via Chats on User-Favored Topics","summary":"Chat-oriented dialogue systems designed to provide tangible benefits, such as\nsharing the latest news or preventing frailty in senior citizens, often require\nProactive acquisition of specific user Information via chats on user-faVOred\nTopics (PIVOT). This study proposes the PIVOT task, designed to advance the\ntechnical foundation for these systems. In this task, a system needs to acquire\nthe answers of a user to predefined questions without making the user feel\nabrupt while engaging in a chat on a predefined topic. We found that even\nrecent large language models (LLMs) show a low success rate in the PIVOT task.\nWe constructed a dataset suitable for the analysis to develop more effective\nsystems. Finally, we developed a simple but effective system for this task by\nincorporating insights obtained through the analysis of this dataset.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T12:32:16Z"}
{"aid":"http://arxiv.org/abs/2504.07705v1","title":"Electroweak baryogenesis in 2HDM without EDM cancellation","summary":"We study two Higgs doublet models with successful electroweak baryogenesis\nbut without cancellations of electric dipole moments (EDMs). For the\nbaryogenesis, additional scalar bosons are favored to couple mainly with the\ntop quark with CP violations. However, if they also couple to light fermions of\nthe Standard Model, the model is limited severely by EDMs, and additional CP\nphases irrelevant to the baryogenesis are often introduced to cancel the\ncontributions to the EDMs. Alternatively, we consider a scenario where the\nlight-fermion couplings are suppressed to avoid the constraints. In our\nscenario, it is found that the leading contributions arise in the top-quark\nEDMs at the two-loop level. They induce the electron, neutron, and proton EDMs\nvia radiative corrections. Since there is no additional CP-violating phase,\nthey are correlated with the baryon asymmetry. We show that our scenario is\ncompatible with the current experimental bounds and is within the scope of\nfuture EDM experiments.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-10T12:47:10Z"}
{"aid":"http://arxiv.org/abs/2504.07724v1","title":"MRD-RAG: Enhancing Medical Diagnosis with Multi-Round\n  Retrieval-Augmented Generation","summary":"In recent years, accurately and quickly deploying medical large language\nmodels (LLMs) has become a significant trend. Among these, retrieval-augmented\ngeneration (RAG) has garnered significant attention due to its features of\nrapid deployment and privacy protection. However, existing medical RAG\nframeworks still have shortcomings. Most existing medical RAG frameworks are\ndesigned for single-round question answering tasks and are not suitable for\nmulti-round diagnostic dialogue. On the other hand, existing medical\nmulti-round RAG frameworks do not consider the interconnections between\npotential diseases to inquire precisely like a doctor. To address these issues,\nwe propose a Multi-Round Diagnostic RAG (MRD-RAG) framework that mimics the\ndoctor's diagnostic process. This RAG framework can analyze diagnosis\ninformation of potential diseases and accurately conduct multi-round diagnosis\nlike a doctor. To evaluate the effectiveness of our proposed frameworks, we\nconduct experiments on two modern medical datasets and two traditional Chinese\nmedicine datasets, with evaluations by GPT and human doctors on different\nmethods. The results indicate that our RAG framework can significantly enhance\nthe diagnostic performance of LLMs, highlighting the potential of our approach\nin medical diagnosis. The code and data can be found in our project website\nhttps://github.com/YixiangCh/MRD-RAG/tree/master.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T13:17:51Z"}
{"aid":"http://arxiv.org/abs/2504.07742v1","title":"Gradient-based Sample Selection for Faster Bayesian Optimization","summary":"Bayesian optimization (BO) is an effective technique for black-box\noptimization. However, its applicability is typically limited to\nmoderate-budget problems due to the cubic complexity in computing the Gaussian\nprocess (GP) surrogate model. In large-budget scenarios, directly employing the\nstandard GP model faces significant challenges in computational time and\nresource requirements. In this paper, we propose a novel approach,\ngradient-based sample selection Bayesian Optimization (GSSBO), to enhance the\ncomputational efficiency of BO. The GP model is constructed on a selected set\nof samples instead of the whole dataset. These samples are selected by\nleveraging gradient information to maintain diversity and representation. We\nprovide a theoretical analysis of the gradient-based sample selection strategy\nand obtain explicit sublinear regret bounds for our proposed framework.\nExtensive experiments on synthetic and real-world tasks demonstrate that our\napproach significantly reduces the computational cost of GP fitting in BO while\nmaintaining optimization performance comparable to baseline methods.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-10T13:38:15Z"}
{"aid":"http://arxiv.org/abs/2504.07744v1","title":"MMLA: Multi-Environment, Multi-Species, Low-Altitude Aerial Footage\n  Dataset","summary":"Real-time wildlife detection in drone imagery is critical for numerous\napplications, including animal ecology, conservation, and biodiversity\nmonitoring. Low-altitude drone missions are effective for collecting\nfine-grained animal movement and behavior data, particularly if missions are\nautomated for increased speed and consistency. However, little work exists on\nevaluating computer vision models on low-altitude aerial imagery and\ngeneralizability across different species and settings. To fill this gap, we\npresent a novel multi-environment, multi-species, low-altitude aerial footage\n(MMLA) dataset. MMLA consists of drone footage collected across three diverse\nenvironments: Ol Pejeta Conservancy and Mpala Research Centre in Kenya, and The\nWilds Conservation Center in Ohio, which includes five species: Plains zebras,\nGrevy's zebras, giraffes, onagers, and African Painted Dogs. We comprehensively\nevaluate three YOLO models (YOLOv5m, YOLOv8m, and YOLOv11m) for detecting\nanimals. Results demonstrate significant performance disparities across\nlocations and species-specific detection variations. Our work highlights the\nimportance of evaluating detection algorithms across different environments for\nrobust wildlife monitoring applications using drones.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T13:40:27Z"}
{"aid":"http://arxiv.org/abs/2504.07752v1","title":"Linear relations between face numbers of levels in arrangements","summary":"We study linear relations between face numbers of levels in arrangements. Let\n$V = \\{ v_1, \\ldots, v_n \\} \\subset \\mathbf{R}^{r}$ be a vector configuration\nin general position, and let $\\mathcal{A}(V)$ be polar dual arrangement of\nhemispheres in the $d$-dimensional unit sphere $S^d$, where $d=r-1$. For $0\\leq\ns \\leq d$ and $0 \\leq t \\leq n$, let $f_{s,t}(V)$ denote the number of faces of\n\\emph{level} $t$ and dimension $d-s$ in the arrangement $\\mathcal{A}(V)$ (these\ncorrespond to partitions $V=V_-\\sqcup V_0 \\sqcup V_+$ by linear hyperplanes\nwith $|V_0|=s$ and $|V_-|=t$). We call the matrix $f(V):=[f_{s,t}(V)]$ the\n\\emph{$f$-matrix} of $V$.\n  Completing a long line of research on linear relations between face numbers\nof levels in arrangements, we determine, for every $n\\geq r \\geq 1$, the affine\nspace $\\mathfrak{F}_{n,r}$ spanned by the $f$-matrices of configurations of $n$\nvectors in general position in $\\mathbf{R}^r$; moreover, we determine the\nsubspace $\\mathfrak{F}^0_{n,r} \\subset \\mathfrak{F}_{n,r}$ spanned by all\n\\emph{pointed} vector configurations (i.e., such that $V$ is contained in some\nopen linear halfspace), which correspond to point sets in $\\mathbf{R}^d$. This\ngeneralizes the classical fact that the Dehn--Sommerville relations generate\nall linear relations between the face numbers of simple polytopes (the faces at\nlevel $0$) and answers a question posed by Andrzejak and Welzl in 2003.\n  The key notion for the statements and the proofs of our results is the\n$g$-matrix of a vector configuration, which determines the $f$-matrix and\ngeneralizes the classical $g$-vector of a polytope.\n  By Gale duality, we also obtain analogous results for partitions of vector\nconfigurations by sign patterns of nontrivial linear dependencies, and for\n\\emph{Radon partitions} of point sets in $\\mathbf{R}^d$.","main_category":"math.CO","categories":"math.CO,cs.CG","published":"2025-04-10T13:48:10Z"}
{"aid":"http://arxiv.org/abs/2504.07753v1","title":"Virtual-mask Informed Prior for Sparse-view Dual-Energy CT\n  Reconstruction","summary":"Sparse-view sampling in dual-energy computed tomography (DECT) significantly\nreduces radiation dose and increases imaging speed, yet is highly prone to\nartifacts. Although diffusion models have demonstrated potential in effectively\nhandling incomplete data, most existing methods in this field focus on the\nimage do-main and lack global constraints, which consequently leads to\ninsufficient reconstruction quality. In this study, we propose a dual-domain\nvirtual-mask in-formed diffusion model for sparse-view reconstruction by\nleveraging the high inter-channel correlation in DECT. Specifically, the study\ndesigns a virtual mask and applies it to the high-energy and low-energy data to\nperform perturbation operations, thus constructing high-dimensional tensors\nthat serve as the prior information of the diffusion model. In addition, a\ndual-domain collaboration strategy is adopted to integrate the information of\nthe randomly selected high-frequency components in the wavelet domain with the\ninformation in the projection domain, for the purpose of optimizing the global\nstruc-tures and local details. Experimental results indicated that the present\nmethod exhibits excellent performance across multiple datasets.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-10T13:54:26Z"}
{"aid":"http://arxiv.org/abs/2504.07755v1","title":"Renormalization and blow ups for the nonlinear Schrödinger equation","summary":"Existence of finite-time blow ups in the classical one-dimensional nonlinear\nSchr\\\"odinger equation (NLS)\n  (1) i \\partial_t u + u_{x x} + |u|^{2r} u = 0, u(x,0) = u_0(x)\n  has been one of the central problems in the studies of the singularity\nformation in the PDEs.\n  We revisit this problem using an approach based on the ideas borrowed from\nDynamical Systems.\n  To that end, we reformulate the initial value problem for (1), with r \\in\n\\mathbb{N}, r \\ge 1, as a fixed point problem for a certain renormalization\noperator, and use the ideas of apriori bounds to prove existence of a\nrenormalization fixed point. Existence of such fixed points leads to existence\nof self-similar solutions of the form\n  u(x,t) = (T-t)^{-{1 \\over 2 r}} U((T-t)^{-{1 \\over 2}} x),\n  whose L^{2 r +2}-norms are bounded up-to a finite time T and whose energy\nblows up at T.","main_category":"math.AP","categories":"math.AP","published":"2025-04-10T13:55:08Z"}
{"aid":"http://arxiv.org/abs/2504.07764v1","title":"A note on extendable sets of colorings and rooted minors","summary":"DeVos and Seymour (2003) proved that for every set $C$ of 3-colorings of a\nset $X$ of vertices, there exists a plane graph $G$ with vertices of $X$\nincident with the outer face such that a 3-coloring of $X$ extends to a\n3-coloring of $G$ if and only if it belongs to $C$. We prove a generalization\nof this claim for $k$-colorings of $X$-rooted-$K_{k+1}$-minor-free\n$K_{k+2}$-minor-free graphs.","main_category":"math.CO","categories":"math.CO","published":"2025-04-10T14:03:41Z"}
{"aid":"http://arxiv.org/abs/2504.07769v1","title":"Inflection Point Inflation in Supergravity","summary":"In this paper, we study the inflection point inflation generated by a\npolynomial superpotential and a canonical K\\\"ahler potential under the\nsupergravity framework, where only one chiral superfield is needed. We find\nthat the special form of the scalar potential limits the inflationary Hubble\nparameter to values $\\lesssim 10^{10}\\, \\textrm{GeV}$ and the inflaton mass to\n$\\lesssim 10^{11} \\, \\textrm{GeV}$. We obtain analytic results for small field\ncases and present numerical results for large field ones. We find the\ntensor-to-scalar ratio $r<10^{-8}$ is always suppressed in these models, while\nthe running of spectral index $\\alpha\\approx \\mathcal{O}(-10^{-3})$ may be\ntestable in next-generation CMB experiments. We also discuss the possible\neffects of SUSY breaking Polonyi term presented in the superpotential where we\nfind a general upper bound for the SUSY breaking scale for a given value of the\nHubble parameter.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-10T14:08:14Z"}
{"aid":"http://arxiv.org/abs/2504.07776v1","title":"SlimSpeech: Lightweight and Efficient Text-to-Speech with Slim Rectified\n  Flow","summary":"Recently, flow matching based speech synthesis has significantly enhanced the\nquality of synthesized speech while reducing the number of inference steps. In\nthis paper, we introduce SlimSpeech, a lightweight and efficient speech\nsynthesis system based on rectified flow. We have built upon the existing\nspeech synthesis method utilizing the rectified flow model, modifying its\nstructure to reduce parameters and serve as a teacher model. By refining the\nreflow operation, we directly derive a smaller model with a more straight\nsampling trajectory from the larger model, while utilizing distillation\ntechniques to further enhance the model performance. Experimental results\ndemonstrate that our proposed method, with significantly reduced model\nparameters, achieves comparable performance to larger models through one-step\nsampling.","main_category":"cs.SD","categories":"cs.SD,cs.AI","published":"2025-04-10T14:15:18Z"}
{"aid":"http://arxiv.org/abs/2504.07792v1","title":"Breaking the Barriers: Video Vision Transformers for Word-Level Sign\n  Language Recognition","summary":"Sign language is a fundamental means of communication for the deaf and\nhard-of-hearing (DHH) community, enabling nuanced expression through gestures,\nfacial expressions, and body movements. Despite its critical role in\nfacilitating interaction within the DHH population, significant barriers\npersist due to the limited fluency in sign language among the hearing\npopulation. Overcoming this communication gap through automatic sign language\nrecognition (SLR) remains a challenge, particularly at a dynamic word-level,\nwhere temporal and spatial dependencies must be effectively recognized. While\nConvolutional Neural Networks have shown potential in SLR, they are\ncomputationally intensive and have difficulties in capturing global temporal\ndependencies between video sequences. To address these limitations, we propose\na Video Vision Transformer (ViViT) model for word-level American Sign Language\n(ASL) recognition. Transformer models make use of self-attention mechanisms to\neffectively capture global relationships across spatial and temporal\ndimensions, which makes them suitable for complex gesture recognition tasks.\nThe VideoMAE model achieves a Top-1 accuracy of 75.58% on the WLASL100 dataset,\nhighlighting its strong performance compared to traditional CNNs with 65.89%.\nOur study demonstrates that transformer-based architectures have great\npotential to advance SLR, overcome communication barriers and promote the\ninclusion of DHH individuals.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T14:27:25Z"}
{"aid":"http://arxiv.org/abs/2504.07823v1","title":"A new look into the atmospheric composition of WASP-39 b","summary":"Being one of the first exoplanets observed by the James Webb Space Telescope\n(JWST), WASP-39 b has become an iconic target and many transit spectra recorded\nwith different instruments (NIRISS, NIRCAM, NIRSpec G395H, NIRSpec PRISM and\nMIRI) are currently available, allowing in-depth studies of its atmosphere. We\npresent here a novel approach to interpret WASP-39 b's transit spectroscopic\ndata, consisting of a multi-step process where ab initio equilibrium chemistry\nmodels and blind retrievals are used iteratively to find physically robust,\noptimal solutions. Following this approach, we have identified a new scenario\nto explain WASP-39 b's atmospheric composition, in which silicon-based\nchemistry plays a major role. In this scenario, SiO may explain the spectral\nabsorption at 4.1 $\\mu$m, currently interpreted as being due to SO$_2$. SiO and\nthe other gas species identified by the retrieval models, i.e. H$_2$O, CO$_2$,\nNa and K, are consistent with an atmosphere in chemical equilibrium with a\ntemperature-pressure profile constrained by H$_2$O and CO$_2$ absorption bands.\nIn addition, silicate clouds and hazes can produce the spectral features\nobserved by MIRI in the spectral window 5-12 $\\mu$m. While we advocate the need\nfor more data, possibly at higher spectral resolution, to confirm our results\nfor WASP-39 b's atmospheric composition, we highlight a refined atmospheric\nretrieval strategy with pre-selection and post-reconstruction to guide the next\ngeneration of transit spectroscopy.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-10T15:01:28Z"}
{"aid":"http://arxiv.org/abs/2504.07850v1","title":"Probabilistic Multi-Criteria Decision-Making for Circularity Performance\n  of Modern Methods of Construction Products","summary":"The construction industry faces increasingly more significant pressure to\nreduce resource consumption, minimise waste, and enhance environmental\nperformance. Towards the transition to a circular economy in the construction\nindustry, one of the challenges is the lack of a standardised assessment\nframework and methods to measure circularity at the product level. To support a\nmore sustainable and circular construction industry through robust and enhanced\nscenario analysis, this paper integrates probabilistic analysis into the\ncoupled assessment framework; this research addresses uncertainties associated\nwith multiple criteria and diverse stakeholders in the construction industry to\nenable more robust decision-making support on both circularity and\nsustainability performance. By demonstrating the application in three\nreal-world MMC products, the proposed framework offers a novel approach to\nsimultaneously assess the circularity and sustainability of MMC products with\nrobustness and objectiveness.","main_category":"math.NA","categories":"math.NA,cs.NA,stat.AP","published":"2025-04-10T15:27:34Z"}
{"aid":"http://arxiv.org/abs/2504.07865v1","title":"Equidistribution in 2-Nilpotent Polish Groups and triple restricted\n  sumsets","summary":"The aim of this paper is to establish a Ratner-type equidistribution theorem\nfor orbits on homogeneous spaces associated with \\(2\\)-nilpotent locally\ncompact Polish groups under the action of a countable discrete abelian group.\nWe apply this result to establish the existence of triple restricted sumsets in\nsubsets of positive density in arbitrary countable discrete abelian groups,\nsubject to a necessary finiteness condition.","main_category":"math.DS","categories":"math.DS,math.CO","published":"2025-04-10T15:40:48Z"}
{"aid":"http://arxiv.org/abs/2504.07876v1","title":"Quintessence models in the late Universe","summary":"Scalar-tensor theories have shown great potential in inducing tailored\nmodifications compared to cosmic evolution in the $\\Lambda$CDM model. We\nreconsider quintessence models in this work in the context of three driving\npotentials. We center the action of these models in the late Universe which\nleaves early $\\Lambda$CDM cosmology unchanged. The effects show the potential\nof producing a faster expanding cosmology with a high Hubble constant. The\nmodels are constrained using the cosmic chronometer data, Pantheon plus, and\ntransversal baryonic acoustic oscillation data.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-10T15:51:18Z"}
{"aid":"http://arxiv.org/abs/2504.07886v1","title":"Conformal product structures on compact Einstein manifolds","summary":"In this note we generalize our previous result, stating that if $(M_1,g_1)$\nand $(M_2,g_2)$ are compact Riemannian manifolds, then any Einstein metric on\nthe product $M:=M_1\\times M_2$ of the form $g=e^{2f_1}g_1+e^{2f_2}g_2$, with\n$f_1\\in C^\\infty(M_2)$ and $f_2\\in C^\\infty(M_1\\times M_2)$, is a warped\nproduct metric. Namely, we show that the same conclusion holds if we replace\nthe assumption that the manifold $M$ is globally the product of two compact\nmanifolds by the weaker assumption that $M$ is compact and carries a conformal\nproduct structure.","main_category":"math.DG","categories":"math.DG","published":"2025-04-10T15:59:50Z"}
{"aid":"http://arxiv.org/abs/2504.07891v1","title":"SpecReason: Fast and Accurate Inference-Time Compute via Speculative\n  Reasoning","summary":"Recent advances in inference-time compute have significantly improved\nperformance on complex tasks by generating long chains of thought (CoTs) using\nLarge Reasoning Models (LRMs). However, this improved accuracy comes at the\ncost of high inference latency due to the length of generated reasoning\nsequences and the autoregressive nature of decoding. Our key insight in\ntackling these overheads is that LRM inference, and the reasoning that it\nembeds, is highly tolerant of approximations: complex tasks are typically\nbroken down into simpler steps, each of which brings utility based on the\nsemantic insight it provides for downstream steps rather than the exact tokens\nit generates. Accordingly, we introduce SpecReason, a system that automatically\naccelerates LRM inference by using a lightweight model to (speculatively) carry\nout simpler intermediate reasoning steps and reserving the costly base model\nonly to assess (and potentially correct) the speculated outputs. Importantly,\nSpecReason's focus on exploiting the semantic flexibility of thinking tokens in\npreserving final-answer accuracy is complementary to prior speculation\ntechniques, most notably speculative decoding, which demands token-level\nequivalence at each step. Across a variety of reasoning benchmarks, SpecReason\nachieves 1.5-2.5$\\times$ speedup over vanilla LRM inference while improving\naccuracy by 1.0-9.9\\%. Compared to speculative decoding without SpecReason,\ntheir combination yields an additional 19.4-44.2\\% latency reduction. We\nopen-source SpecReason at https://github.com/ruipeterpan/specreason.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-10T16:05:19Z"}
{"aid":"http://arxiv.org/abs/2504.07892v1","title":"Orbit design for mitigating interstellar scattering effects in\n  Earth-space VLBI observations of Sgr A*","summary":"(abridged) The black hole Sagittarius A* (Sgr A*) is a prime target for\nnext-generation Earth-space very-long-baseline interferometry missions such as\nthe Black Hole Explorer (BHEX), which aims to probe baselines of the order of\n20 G$\\lambda$. At these baselines, Sgr A* observations will be affected by the\ndiffractive scattering effects from the interstellar medium (ISM). Therefore,\nwe study how different parameter choices for turbulence in the ISM affect\nBHEX's observational capabilities to probe strong lensing features of Sgr A*.\nBy using a simple geometric model of concentric Gaussian rings for Sgr A*'s\nphoton ring signal and observing at 320 GHz, we find that the BHEX-ALMA\nbaseline has the required sensitivity to observe Sgr A* for a broad range of\nvalues of the power-law index of density fluctuations in the ISM and the inner\nscale of turbulence. For other baselines with moderate sensitivities, a strong\nneed for observations at shorter scales of $\\approx$ 13.5 G$\\lambda$ is\nidentified. For this purpose, an orbit migration scheme is proposed. It is\nmodeled using both chemical propulsion (CP)-based Hohmann transfers and\nelectric propulsion (EP)-based orbit raising with the result that a CP-based\ntransfer can be performed in a matter of hours, but with a significantly higher\nfuel requirement as compared to EP, which however requires a transfer time of\naround 6 weeks. The consequences of these orbits for probing Sgr A*'s spacetime\nis studied by quantifying the spatial resolution, temporal resolution and the\nangular sampling of the photon ring signal in the Fourier coverage of each of\nthese orbits. We show that higher orbits isolate spacetime features while\nsacrificing both, signal lost to scattering and temporal resolution, but gain\ngreater access to the morphology of the photon ring.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.IM","published":"2025-04-10T16:06:14Z"}
{"aid":"http://arxiv.org/abs/2504.07903v1","title":"Spectral delineation of Markov Generators: Classical vs Quantum","summary":"The celebrated theorem of Perron and Frobenius implies that spectra of\nclassical Markov operators, represented by stochastic matrices, are restricted\nto the unit disk. This property holds also for spectra of quantum stochastic\nmaps (quantum channels), which describe quantum Markovian evolution in discrete\ntime. Moreover, the spectra of stochastic $N \\times N$ matrices are\nadditionally restricted to a subset of the unit disk, called Karpelevi\\u{c}\nregion, the shape of which depends on $N$. We address the question of whether\nthe spectra of generators, which induce Markovian evolution in continuous time,\ncan be bound in a similar way. We propose a rescaling that allows us to answer\nthis question affirmatively. The eigenvalues of the rescaled classical\ngenerators are confined to the modified Karpelevi\\u{c} regions, whereas the\neigenvalues of the rescaled quantum generators fill the entire unit disk.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,quant-ph","published":"2025-04-10T16:26:10Z"}
{"aid":"http://arxiv.org/abs/2504.07905v1","title":"From Winter Storm Thermodynamics to Wind Gust Extremes: Discovering\n  Interpretable Equations from Data","summary":"Reliably identifying and understanding temporal precursors to extreme wind\ngusts is crucial for early warning and mitigation. This study proposes a simple\ndata-driven approach to extract key predictors from a dataset of historical\nextreme European winter windstorms and derive simple equations linking these\nprecursors to extreme gusts over land. A major challenge is the limited\ntraining data for extreme events, increasing the risk of model overfitting.\nTesting various mitigation strategies, we find that combining dimensionality\nreduction, careful cross-validation, feature selection, and a nonlinear\ntransformation of maximum wind gusts informed by Generalized Extreme Value\ndistributions successfully reduces overfitting. These measures yield\ninterpretable equations that generalize across regions while maintaining\nsatisfactory predictive skill. The discovered equations reveal the association\nbetween a steady drying low-troposphere before landfall and wind gust intensity\nin Northwestern Europe.","main_category":"physics.ao-ph","categories":"physics.ao-ph,stat.AP","published":"2025-04-10T16:28:22Z"}
{"aid":"http://arxiv.org/abs/2504.07913v1","title":"Optimal Control For Anti-Abeta Treatment in Alzheimer's Disease using a\n  Reaction-Diffusion Model","summary":"Alzheimer's disease is a progressive neurodegenerative disorder that\nsignificantly impairs patient survival and quality of life. While current\npharmacological treatments aim to slow disease progression, they remain\ninsufficient in halting cognitive decline. Mathematical modeling has emerged as\na powerful tool for understanding the dynamics of AD and optimizing treatment\nstrategies. However, most existing models focus on temporal dynamics using\nordinary differential equation-based approaches, often neglecting the critical\nrole of spatial heterogeneity in disease progression.\n  In this study, we employ a spatially explicit reaction-diffusion model to\ndescribe amyloid-beta (A beta) dynamics in the brain, incorporating treatment\noptimization while accounting for potential side effects. Our objective is to\nminimize amyloid-beta plaque concentration while balancing therapeutic efficacy\nagainst adverse effects, such as amyloid-related imaging abnormalities (ARIA).\nUnder specific assumptions, we establish the well-posedness and uniqueness of\nthe optimal solution. We employ numerical methods based on the Finite Element\nMethod to compute personalized treatment strategies, leveraging real patient\namyloid-beta positron emission tomography (PET) scan data.\n  Our results demonstrate that optimal treatment strategies outperform constant\ndosing regimens, achieving significant reductions in amyloid burden while\nminimizing side effects. By integrating spatial dynamics and personalized\ntreatment planning, our framework offers a novel approach to refining\ntherapeutic interventions for Alzheimer's disease.","main_category":"math.OC","categories":"math.OC","published":"2025-04-10T17:22:09Z"}
{"aid":"http://arxiv.org/abs/2504.07917v1","title":"SKK groups of manifolds and non-unitary invertible TQFTs","summary":"This work considers the computation of controllable cut-and-paste groups\n$\\mathrm{SKK}^{\\xi}_n$ of manifolds with tangential structure $\\xi:B_n\\to\nBO_n$. To this end, we apply the work of Galatius-Madsen-Tillman-Weiss, Genauer\nand Schommer-Pries, who showed that for a wide range of structures $\\xi$ these\ngroups fit into a short exact sequence that relates them to bordism groups of\n$\\xi$-manifolds with kernel generated by the disc-bounding $\\xi$-sphere. The\norder of this sphere can be computed by knowing the possible values of the\nEuler characteristic of $\\xi$-manifolds. We are thus led to address two key\nquestions: the existence of $\\xi$-manifolds with odd Euler characteristic of a\ngiven dimension and conditions for the exact sequence to admit a splitting. We\nresolve these questions in a wide range of cases.\n  $\\mathrm{SKK}$ groups are of interest in physics as they play a role in the\nclassification of non-unitary invertible topological quantum field theories,\nwhich classify anomalies and symmetry protected topological (SPT) phases of\nmatter. Applying our topological results, we give a complete classification of\nnon-unitary invertible topological quantum field theories in the tenfold way in\ndimensions 1-5.","main_category":"math.AT","categories":"math.AT,math-ph,math.GT,math.MP","published":"2025-04-10T17:32:26Z"}
{"aid":"http://arxiv.org/abs/2504.07928v1","title":"Riemann zeros and the KKR determinant","summary":"We transform the counting function for the Riemann zeros into a\nKorringa-Kohn-Rostoker (KKR) determinant, assisted by Krein's theorem. This is\nbased on our observation that the function derived from a few methods can all\nbe recast into two terms: one corresponds to the scattering phase, and the\nother is similar to structure constants related to the Green function. We also\ndiscuss the possible physical realizations. Our method provides a new physical\npathway towards the solution of the Riemann hypothesis.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-10T17:43:43Z"}
{"aid":"http://arxiv.org/abs/2504.07929v1","title":"Market-Based Portfolio Selection","summary":"We show that Markowitz's (1952) decomposition of a portfolio variance as a\nquadratic form in the variables of the relative amounts invested into the\nsecurities, which has been the core of classical portfolio theory for more than\n70 years, is valid only in the approximation when all trade volumes with all\nsecurities of the portfolio are assumed constant. We derive the market-based\nportfolio variance and its decomposition by its securities, which accounts for\nthe impact of random trade volumes and is a polynomial of the 4th degree in the\nvariables of the relative amounts invested into the securities. To do that, we\ntransform the time series of market trades with the securities of the portfolio\nand obtain the time series of trades with the portfolio as a single market\nsecurity. The time series of market trades determine the market-based means and\nvariances of prices and returns of the portfolio in the same form as the means\nand variances of any market security. The decomposition of the market-based\nvariance of returns of the portfolio by its securities follows from the\nstructure of the time series of market trades of the portfolio as a single\nsecurity. The market-based decompositions of the portfolio's variances of\nprices and returns could help the managers of multi-billion portfolios and the\ndevelopers of large market and macroeconomic models like BlackRock's Aladdin,\nJP Morgan, and the U.S. Fed adjust their models and forecasts to the reality of\nrandom markets.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC,q-fin.GN,q-fin.PM,q-fin.PR","published":"2025-04-10T17:44:57Z"}
{"aid":"http://arxiv.org/abs/2504.07933v1","title":"Geometric and Dosimetric Validation of Deformable Image Registration for\n  Prostate MR-guided Adaptive Radiotherapy","summary":"Objective: Quantify geometric and dosimetric accuracy of a novel prostate\nMR-to-MR deformable image registration (DIR) approach to support MR-guided\nadaptive radiation therapy dose accumulation.\n  Approach: We evaluated DIR accuracy in 25 patients treated with 30 Gy in 5\nfractions on a 1.5 T MR-linac using an adaptive workflow. A reference MR was\nused for planning, with three images collected at each fraction: adapt MR for\nadaptive planning, verify MR for pretreatment position verification and beam-on\nfor capturing anatomy during radiation delivery. We assessed three DIR\napproaches: intensity-based, intensity-based with controlling structures (CS)\nand novel intensity based with controlling structures and points of interest\n(CS+P). DIRs were performed between the reference and fraction images and\nwithin fractions. We propagated CTV, bladder, and rectum contours using the\nDIRs and compared to manual contours using Dice similarity coefficient, mean\ndistance to agreement (DTAmean), and dose-volume metrics.\n  Results: CS and CS+P improved geometric agreement between contours over\nintensity-only DIR. DTAmean for reference-to-beam-on intensity-only DIR was\n0.131+/-0.009cm (CTV), 0.46+/-0.08cm (bladder), and 0.154+/-0.013cm (rectum).\nFor the CS, the values were 0.018+/-0.002cm, 0.388+/-0.14cm, and\n0.036+/-0.013cm. For CS+P these values were 0.015+/-0.001cm, 0.025+/-0.004cm,\nand 0.021+/-0.002cm. Dosimetrically, comparing CS and CS+P for reference to\nbeam-on DIRs resulted in a change of CTV D98% from [-29cGy, 19cGy] to [-18cGy,\n26cGy], rectum D1cc from [-106cGy, 72cGy] to [-52cGy, 74cGy], and bladder D5cc\nfrom [-51cGy, 544cGy] to [-79cGy, 36cGy].\n  Significance: CS improved geometric and dosimetric accuracy over\nintensity-only DIR, with CS+P providing the most consistent performance.\nHowever, session image segmentation remains a challenge, which may be addressed\nwith automated contouring.","main_category":"physics.med-ph","categories":"physics.med-ph","published":"2025-04-10T17:47:47Z"}
{"aid":"http://arxiv.org/abs/2504.07962v1","title":"GLUS: Global-Local Reasoning Unified into A Single Large Language Model\n  for Video Segmentation","summary":"This paper proposes a novel framework utilizing multi-modal large language\nmodels (MLLMs) for referring video object segmentation (RefVOS). Previous\nMLLM-based methods commonly struggle with the dilemma between \"Ref\" and \"VOS\":\nthey either specialize in understanding a few key frames (global reasoning) or\ntracking objects on continuous frames (local reasoning), and rely on external\nVOS or frame selectors to mitigate the other end of the challenge. However, our\nframework GLUS shows that global and local consistency can be unified into a\nsingle video segmentation MLLM: a set of sparse \"context frames\" provides\nglobal information, while a stream of continuous \"query frames\" conducts local\nobject tracking. This is further supported by jointly training the MLLM with a\npre-trained VOS memory bank to simultaneously digest short-range and long-range\ntemporal information. To improve the information efficiency within the limited\ncontext window of MLLMs, we introduce object contrastive learning to\ndistinguish hard false-positive objects and a self-refined framework to\nidentify crucial frames and perform propagation. By collectively integrating\nthese insights, our GLUS delivers a simple yet effective baseline, achieving\nnew state-of-the-art for MLLMs on the MeViS and Ref-Youtube-VOS benchmark. Our\nproject page is at https://glus-video.github.io/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:59:55Z"}
{"aid":"http://arxiv.org/abs/2504.09883v1","title":"Modelling & Steady State Compliance Testing of an Improved Time\n  Synchronized Phasor Measurement Unit Based on IEEE Standard C37.118.1","summary":"Synchrophasor technology is an emerging and developing technology for\nmonitoring and control of wide area measurement systems (WAMS). In an\nelementary WAMS, two identical phasors measured at two different locations have\ndifference in the phase angles measured since their reference waveforms are not\nsynchronized with each other. Phasor measurement units (PMUs) measure input\nphasors with respect to a common reference wave based on the atomic clock\npulses received from global positioning system (GPS) satellites, eliminating\nvariation in the measured phase angles due to distant locations of the\nmeasurement nodes. This has found tremendous applications in quick fault\ndetection, fault location analysis, accurate current, voltage, frequency and\nphase angle measurements in WAMS. Commercially available PMU models are often\nproven to be expensive for research and development as well as for grid\nintegration projects. This research article proposes an economic PMU model\noptimized for accurate steadystate performance based on recursive discrete\nFourier transform (DFT) and provides results and detailed analysis of the\nproposed PMU model as per the steady state compliance specifications of IEEE\nstandard C37.118.1. Results accurate up to 13 digits after decimal point are\nobtained through the developed PMU model for both nominal and off-nominal\nfrequency inputs in steady state.","main_category":"eess.SP","categories":"eess.SP,cs.SY,eess.SY,physics.soc-ph","published":"2025-04-14T05:13:34Z"}
{"aid":"http://arxiv.org/abs/2504.09898v1","title":"The Milky Way Project MOBStIRS: Parametrizing Infrared Stellar-Wind Bow\n  Shock Morphologies with Citizen Science","summary":"Mass-loss influences stellar evolution, especially for massive stars with\nstrong winds. Stellar wind bow shock nebulae driven by Galactic OB stars can be\nused to measure mass-loss rates ($\\dot{M}$). The standoff distance ($R_{0}$)\nbetween the star and the bow shock is set by momentum flux balance between the\nstellar wind and the surrounding interstellar medium (ISM). We created the\nMilky Way Project: MOBStIRS (Mass-loss rates for OB Stars driving IR bow\nShocks) using the online Zooniverse citizen science platform. We enlisted\nseveral hundred students to measure $R_0$ and two other projected shape\nparameters for 764 cataloged IR bow shocks. MOBStIRS incorporated 1528 JPEG\ncutout images produced from Spitzer GLIMPSE and MIPSGAL survey data.\nMeasurements were aggregated to compute shape parameters for each bow shock\nimage deemed high-quality by participants. The average statistical uncertainty\non $R_0$ is $12.5\\%$ but varies from ${<}5\\%$ to ${\\sim}40\\%$ among individual\nbow shocks, contributing significantly to the total error budget of $\\dot{M}$.\nThe derived nebular morphologies agree well with (magneto)hydrodynamic\nsimulations of bow shocks driven by the winds of OB stars moving at $V_a =\n10-40~km~s^{-1}$ with respect to the ambient interstellar medium (ISM). A\nsystematic correction to $R_0$ to account for viewing angle appears unnecessary\nfor computing $\\dot{M}$. Slightly more than half of MOBStIRS bow shocks are\nasymmetric, which could indicate anisotropic stellar winds, ISM clumping on\nsub-pc scales, time-dependent instabilities, and/or misalignments between the\nlocal ISM magnetic field and the star-bow shock axis.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-04-14T05:46:21Z"}
{"aid":"http://arxiv.org/abs/2504.09903v1","title":"Refining Financial Consumer Complaints through Multi-Scale Model\n  Interaction","summary":"Legal writing demands clarity, formality, and domain-specific\nprecision-qualities often lacking in documents authored by individuals without\nlegal training. To bridge this gap, this paper explores the task of legal text\nrefinement that transforms informal, conversational inputs into persuasive\nlegal arguments. We introduce FinDR, a Chinese dataset of financial dispute\nrecords, annotated with official judgments on claim reasonableness. Our\nproposed method, Multi-Scale Model Interaction (MSMI), leverages a lightweight\nclassifier to evaluate outputs and guide iterative refinement by Large Language\nModels (LLMs). Experimental results demonstrate that MSMI significantly\noutperforms single-pass prompting strategies. Additionally, we validate the\ngeneralizability of MSMI on several short-text benchmarks, showing improved\nadversarial robustness. Our findings reveal the potential of multi-model\ncollaboration for enhancing legal document generation and broader text\nrefinement tasks.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T05:51:31Z"}
{"aid":"http://arxiv.org/abs/2504.09905v1","title":"Fusing Bluetooth with Pedestrian Dead Reckoning: A Floor Plan-Assisted\n  Positioning Approach","summary":"Floor plans can provide valuable prior information that helps enhance the\naccuracy of indoor positioning systems. However, existing research typically\nfaces challenges in efficiently leveraging floor plan information and applying\nit to complex indoor layouts. To fully exploit information from floor plans for\npositioning, we propose a floor plan-assisted fusion positioning algorithm\n(FP-BP) using Bluetooth low energy (BLE) and pedestrian dead reckoning (PDR).\nIn the considered system, a user holding a smartphone walks through a\npositioning area with BLE beacons installed on the ceiling, and can locate\nhimself in real time. In particular, FP-BP consists of two phases. In the\noffline phase, FP-BP programmatically extracts map features from a stylized\nfloor plan based on their binary masks, and constructs a mapping function to\nidentify the corresponding map feature of any given position on the map. In the\nonline phase, FP-BP continuously computes BLE positions and PDR results from\nBLE signals and smartphone sensors, where a novel grid-based maximum likelihood\nestimation (GML) algorithm is introduced to enhance BLE positioning. Then, a\nparticle filter is used to fuse them and obtain an initial estimate. Finally,\nFP-BP performs post-position correction to obtain the final position based on\nits specific map feature. Experimental results show that FP-BP can achieve a\nreal-time mean positioning accuracy of 1.19 m, representing an improvement of\nover 28% compared to existing floor plan-fused baseline algorithms.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T06:00:39Z"}
{"aid":"http://arxiv.org/abs/2504.09910v1","title":"Learning to Erase Private Knowledge from Multi-Documents for\n  Retrieval-Augmented Large Language Models","summary":"Retrieval-Augmented Generation (RAG) is a promising technique for applying\nLLMs to proprietary domains. However, retrieved documents may contain sensitive\nknowledge, posing risks of privacy leakage in generative results. Thus,\neffectively erasing private information from retrieved documents is a key\nchallenge for RAG. Unlike traditional text anonymization, RAG should consider:\n(1) the inherent multi-document reasoning may face de-anonymization attacks;\n(2) private knowledge varies by scenarios, so users should be allowed to\ncustomize which information to erase; (3) preserving sufficient publicly\navailable knowledge for generation tasks. This paper introduces the privacy\nerasure task for RAG and proposes Eraser4RAG, a private knowledge eraser which\neffectively removes user-defined private knowledge from documents while\npreserving sufficient public knowledge for generation. Specifically, we first\nconstruct a global knowledge graph to identify potential knowledge across\ndocuments, aiming to defend against de-anonymization attacks. Then we randomly\nsplit it into private and public sub-graphs, and fine-tune Flan-T5 to rewrite\nthe retrieved documents excluding private triples. Finally, PPO algorithm\noptimizes the rewriting model to minimize private triples and maximize public\ntriples retention. Experiments on four QA datasets demonstrate that Eraser4RAG\nachieves superior erase performance than GPT-4o.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T06:10:31Z"}
{"aid":"http://arxiv.org/abs/2504.09917v1","title":"Creation of chaos for interacting Brownian particles","summary":"We consider a system of $N$ Brownian particles, with or without inertia,\ninteracting in the mean-field regime via a weak, smooth, long-range potential,\nand starting initially from an arbitrary exchangeable $N$-particle\ndistribution. In this model framework, we establish a fine version of the\nso-called creation-of-chaos phenomenon: in weak norms, the mean-field\napproximation for a typical particle is shown to hold with an accuracy\n$O(N^{-1})$ up to an error due solely to initial pair correlations, which is\ndamped exponentially over time. The novelty is that the initial information\nappears in our estimates only through pair correlations, which currently seems\ninaccessible to other methods. This is complemented by corresponding results on\nhigher-order creation of chaos in the form of higher-order correlation\nestimates.","main_category":"math.PR","categories":"math.PR,math-ph,math.AP,math.MP","published":"2025-04-14T06:26:01Z"}
{"aid":"http://arxiv.org/abs/2504.09935v1","title":"Constrained Auto-Regressive Decoding Constrains Generative Retrieval","summary":"Generative retrieval seeks to replace traditional search index data\nstructures with a single large-scale neural network, offering the potential for\nimproved efficiency and seamless integration with generative large language\nmodels. As an end-to-end paradigm, generative retrieval adopts a learned\ndifferentiable search index to conduct retrieval by directly generating\ndocument identifiers through corpus-specific constrained decoding. The\ngeneralization capabilities of generative retrieval on out-of-distribution\ncorpora have gathered significant attention.\n  In this paper, we examine the inherent limitations of constrained\nauto-regressive generation from two essential perspectives: constraints and\nbeam search. We begin with the Bayes-optimal setting where the generative\nretrieval model exactly captures the underlying relevance distribution of all\npossible documents. Then we apply the model to specific corpora by simply\nadding corpus-specific constraints. Our main findings are two-fold: (i) For the\neffect of constraints, we derive a lower bound of the error, in terms of the KL\ndivergence between the ground-truth and the model-predicted step-wise marginal\ndistributions. (ii) For the beam search algorithm used during generation, we\nreveal that the usage of marginal distributions may not be an ideal approach.\nThis paper aims to improve our theoretical understanding of the generalization\ncapabilities of the auto-regressive decoding retrieval paradigm, laying a\nfoundation for its limitations and inspiring future advancements toward more\nrobust and generalizable generative retrieval.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-14T06:54:49Z"}
{"aid":"http://arxiv.org/abs/2504.09996v1","title":"Nonlinear transport of Wigner solid phase surrounding the two-flux\n  composite fermion liquid","summary":"We have investigated the low temperature (T) transport properties of\nfractional quantum Hall (FQH) states in a high-mobility two-dimensional hole\ngas. According to the composite fermion (CF) model, FQH states stemming from a\nhalf-filled Landau level, specifically at filling factors ${\\nu}=p/(2p+1)\n(p=\\pm 1,\\pm 2,\\pm 3,...)$, can be associated with two-flux-attached CFs at the\ncorresponding Lambda filling factor p. The zero-resistance minima and Hall\nplateaus of these states exhibit unusual temperature dependencies,\ncharacterized by rapid increases in width below a threshold temperature around\n100 mK. Differential conductivity measurements from Corbino samples reveal that\nthe regimes surrounding the CF liquid display clear nonlinear transport\ncharacteristics. This nonlinearity implies that each CF liquid is surrounded by\nCF solid phase composed of dilute CF excitations. Quantitatively, the applied\nelectric field E influences the motion of CF solid in a way analogous to T,\nwhich is dubbed the \"E-T duality\". Our analysis indicates that this E-T duality\nis consistent with the Berezinskii-Kosterlitz-Thouless theory in\ntwo-dimensional phase transitions.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-14T09:00:07Z"}
{"aid":"http://arxiv.org/abs/2504.10042v1","title":"Search for $B^0 \\to K^{\\ast 0} τ^+ τ^-$ decays at the Belle II\n  experiment","summary":"We present a search for the rare flavor-changing neutral-current decay $B^0\n\\to K^{\\ast 0} \\tau^+ \\tau^-$ with data collected by the Belle II experiment at\nthe SuperKEKB electron-positron collider. The analysis uses a 365 fb$^{-1}$\ndata sample recorded at the center-of-mass energy of the $\\Upsilon(4S)$\nresonance. One of the $B$ mesons produced in the $\\Upsilon(4S)\\to B^0\n\\bar{B}^0$ process is fully reconstructed in a hadronic decay mode, while its\ncompanion $B$ meson is required to decay into a $K^{\\ast 0}$ and two $\\tau$\nleptons of opposite charge. The $\\tau$ leptons are reconstructed in final\nstates with a single electron, muon, charged pion or charged $\\rho$ meson, and\nadditional neutrinos. We set an upper limit on the branching ratio of $BR(B^0\n\\to K^{\\ast 0} \\tau^+ \\tau^-) < 1.8 \\times 10^{-3}$ at the 90% confidence\nlevel, which is the most stringent constraint reported to date.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-14T09:43:05Z"}
{"aid":"http://arxiv.org/abs/2504.10050v1","title":"Emotional Strain and Frustration in LLM Interactions in Software\n  Engineering","summary":"Large Language Models (LLMs) are increasingly integrated into various daily\ntasks in Software Engineering such as coding and requirement elicitation.\nDespite their various capabilities and constant use, some interactions can lead\nto unexpected challenges (e.g. hallucinations or verbose answers) and, in turn,\ncause emotions that develop into frustration. Frustration can negatively impact\nengineers' productivity and well-being if they escalate into stress and\nburnout. In this paper, we assess the impact of LLM interactions on software\nengineers' emotional responses, specifically strains, and identify common\ncauses of frustration when interacting with LLMs at work. Based on 62 survey\nresponses from software engineers in industry and academia across various\ncompanies and universities, we found that a majority of our respondents\nexperience frustrations or other related emotions regardless of the nature of\ntheir work. Additionally, our results showed that frustration mainly stemmed\nfrom issues with correctness and less critical issues such as adaptability to\ncontext or specific format. While such issues may not cause frustration in\ngeneral, artefacts that do not follow certain preferences, standards, or best\npractices can make the output unusable without extensive modification, causing\nfrustration over time. In addition to the frustration triggers, our study\noffers guidelines to improve the software engineers' experience, aiming to\nminimise long-term consequences on mental health.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-14T09:55:47Z"}
{"aid":"http://arxiv.org/abs/2504.10055v1","title":"Joint Action Language Modelling for Transparent Policy Execution","summary":"An agent's intention often remains hidden behind the black-box nature of\nembodied policies. Communication using natural language statements that\ndescribe the next action can provide transparency towards the agent's behavior.\nWe aim to insert transparent behavior directly into the learning process, by\ntransforming the problem of policy learning into a language generation problem\nand combining it with traditional autoregressive modelling. The resulting model\nproduces transparent natural language statements followed by tokens\nrepresenting the specific actions to solve long-horizon tasks in the\nLanguage-Table environment. Following previous work, the model is able to learn\nto produce a policy represented by special discretized tokens in an\nautoregressive manner. We place special emphasis on investigating the\nrelationship between predicting actions and producing high-quality language for\na transparent agent. We find that in many cases both the quality of the action\ntrajectory and the transparent statement increase when they are generated\nsimultaneously.","main_category":"cs.RO","categories":"cs.RO,cs.CL","published":"2025-04-14T09:57:37Z"}
{"aid":"http://arxiv.org/abs/2504.10058v1","title":"Data Cooperatives: Democratic Models for Ethical Data Stewardship","summary":"Data cooperatives offer a new model for fair data governance, enabling\nindividuals to collectively control, manage, and benefit from their information\nwhile adhering to cooperative principles such as democratic member control,\neconomic participation, and community concern. This paper reviews data\ncooperatives, distinguishing them from models like data trusts, data commons,\nand data unions, and defines them based on member ownership, democratic\ngovernance, and data sovereignty. It explores applications in sectors like\nhealthcare, agriculture, and construction. Despite their potential, data\ncooperatives face challenges in coordination, scalability, and member\nengagement, requiring innovative governance strategies, robust technical\nsystems, and mechanisms to align member interests with cooperative goals. The\npaper concludes by advocating for data cooperatives as a sustainable,\ndemocratic, and ethical model for the future data economy.","main_category":"cs.SI","categories":"cs.SI","published":"2025-04-14T10:01:07Z"}
{"aid":"http://arxiv.org/abs/2504.10060v1","title":"Learning to Beamform for Cooperative Localization and Communication: A\n  Link Heterogeneous GNN-Based Approach","summary":"Integrated sensing and communication (ISAC) has emerged as a key enabler for\nnext-generation wireless networks, supporting advanced applications such as\nhigh-precision localization and environment reconstruction. Cooperative ISAC\n(CoISAC) further enhances these capabilities by enabling multiple base stations\n(BSs) to jointly optimize communication and sensing performance through\ncoordination. However, CoISAC beamforming design faces significant challenges\ndue to system heterogeneity, large-scale problem complexity, and sensitivity to\nparameter estimation errors. Traditional deep learning-based techniques fail to\nexploit the unique structural characteristics of CoISAC systems, thereby\nlimiting their ability to enhance system performance. To address these\nchallenges, we propose a Link-Heterogeneous Graph Neural Network (LHGNN) for\njoint beamforming in CoISAC systems. Unlike conventional approaches, LHGNN\nmodels communication and sensing links as heterogeneous nodes and their\ninteractions as edges, enabling the capture of the heterogeneous nature and\nintricate interactions of CoISAC systems. Furthermore, a graph attention\nmechanism is incorporated to dynamically adjust node and link importance,\nimproving robustness to channel and position estimation errors. Numerical\nresults demonstrate that the proposed attention-enhanced LHGNN achieves\nsuperior communication rates while maintaining sensing accuracy under power\nconstraints. The proposed method also exhibits strong robustness to\ncommunication channel and position estimation error.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T10:03:12Z"}
{"aid":"http://arxiv.org/abs/2504.10068v1","title":"Mavors: Multi-granularity Video Representation for Multimodal Large\n  Language Model","summary":"Long-context video understanding in multimodal large language models (MLLMs)\nfaces a critical challenge: balancing computational efficiency with the\nretention of fine-grained spatio-temporal patterns. Existing approaches (e.g.,\nsparse sampling, dense sampling with low resolution, and token compression)\nsuffer from significant information loss in temporal dynamics, spatial details,\nor subtle interactions, particularly in videos with complex motion or varying\nresolutions. To address this, we propose $\\mathbf{Mavors}$, a novel framework\nthat introduces $\\mathbf{M}$ulti-gr$\\mathbf{a}$nularity\n$\\mathbf{v}$ide$\\mathbf{o}$ $\\mathbf{r}$epre$\\mathbf{s}$entation for holistic\nlong-video modeling. Specifically, Mavors directly encodes raw video content\ninto latent representations through two core components: 1) an Intra-chunk\nVision Encoder (IVE) that preserves high-resolution spatial features via 3D\nconvolutions and Vision Transformers, and 2) an Inter-chunk Feature Aggregator\n(IFA) that establishes temporal coherence across chunks using transformer-based\ndependency modeling with chunk-level rotary position encodings. Moreover, the\nframework unifies image and video understanding by treating images as\nsingle-frame videos via sub-image decomposition. Experiments across diverse\nbenchmarks demonstrate Mavors' superiority in maintaining both spatial fidelity\nand temporal continuity, significantly outperforming existing methods in tasks\nrequiring fine-grained spatio-temporal reasoning.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL","published":"2025-04-14T10:14:44Z"}
{"aid":"http://arxiv.org/abs/2504.10076v1","title":"Towards Scalable Bayesian Optimization via Gradient-Informed Bayesian\n  Neural Networks","summary":"Bayesian optimization (BO) is a widely used method for data-driven\noptimization that generally relies on zeroth-order data of objective function\nto construct probabilistic surrogate models. These surrogates guide the\nexploration-exploitation process toward finding global optimum. While Gaussian\nprocesses (GPs) are commonly employed as surrogates of the unknown objective\nfunction, recent studies have highlighted the potential of Bayesian neural\nnetworks (BNNs) as scalable and flexible alternatives. Moreover, incorporating\ngradient observations into GPs, when available, has been shown to improve BO\nperformance. However, the use of gradients within BNN surrogates remains\nunexplored. By leveraging automatic differentiation, gradient information can\nbe seamlessly integrated into BNN training, resulting in more informative\nsurrogates for BO. We propose a gradient-informed loss function for BNN\ntraining, effectively augmenting function observations with local gradient\ninformation. The effectiveness of this approach is demonstrated on well-known\nbenchmarks in terms of improved BNN predictions and faster BO convergence as\nthe number of decision variables increases.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-14T10:21:08Z"}
{"aid":"http://arxiv.org/abs/2504.10089v1","title":"Convergence Analysis of a Stochastic Interacting Particle-Field\n  Algorithm for 3D Parabolic-Parabolic Keller-Segel Systems","summary":"Chemotaxis models describe the movement of organisms in response to chemical\ngradients. In this paper, we present a stochastic interacting particle-field\nalgorithm with random batch approximation (SIPF-$r$) for the three-dimensional\n(3D) parabolic-parabolic Keller-Segel (KS) system, also known as the fully\nparabolic KS system. The SIPF-$r$ method approximates the KS system by coupling\nparticle-based representations of density with a smooth field variable computed\nusing spectral methods. By incorporating the random batch method (RBM), we\nbypass the mean-field limit and significantly reduce computational complexity.\nUnder mild assumptions on the regularity of the original KS system and the\nboundedness of numerical approximations, we prove that, with high probability,\nthe empirical measure of the SIPF-$r$ particle system converges to the exact\nmeasure of the limiting McKean-Vlasov process in the $1$-Wasserstein distance.\nNumerical experiments validate the theoretical convergence rates and\ndemonstrate the robustness and accuracy of the SIPF-$r$ method.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-14T10:53:40Z"}
{"aid":"http://arxiv.org/abs/2504.10101v1","title":"The Human Visual System Can Inspire New Interaction Paradigms for LLMs","summary":"The dominant metaphor of LLMs-as-minds leads to misleading conceptions of\nmachine agency and is limited in its ability to help both users and developers\nbuild the right degree of trust and understanding for outputs from LLMs. It\nmakes it harder to disentangle hallucinations from useful model interactions.\nThis position paper argues that there are fundamental similarities between\nvisual perception and the way LLMs process and present language. These\nsimilarities inspire a metaphor for LLMs which could open new avenues for\nresearch into interaction paradigms and shared representations. Our visual\nsystem metaphor introduces possibilities for addressing these challenges by\nunderstanding the information landscape assimilated by LLMs. In this paper we\nmotivate our proposal, introduce the interrelating theories from the fields\nthat inspired this view and discuss research directions that stem from this\nabstraction.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T11:07:11Z"}
{"aid":"http://arxiv.org/abs/2504.10132v1","title":"Asymptotic Optimality of Projected Inventory Level Policies for Lost\n  Sales Inventory Systems with Large Leadtime and Penalty Cost","summary":"We study the canonical periodic review lost sales inventory system with\npositive leadtime and independent and identically distributed (i.i.d.) demand\nunder the average cost criterion. We demonstrate that the relative value\nfunction under the constant order policy satisfies the Wiener-Hopf equation. We\nemploy ladder processes associated with a random walk featuring i.i.d.\nincrements, to obtain an explicit solution for the relative value function.\nThis solution can be expressed as a quadratic form and a term that grows\nsublinearly. Then we perform an approximate policy iteration step on the\nconstant order policy and bound the approximation errors as a function of the\ncost of losing a sale. This leads to our main result that projected inventory\nlevel policies are asymptotically optimal as the leadtime grows when the cost\nof losing a sale is sufficiently large and demand has a finite second moment.\nUnder these conditions, we also show that the optimal cost rate approaches\ninfinity, proportional to the square root of the cost of losing a sale.","main_category":"math.PR","categories":"math.PR,math.OC,G.3","published":"2025-04-14T11:38:35Z"}
{"aid":"http://arxiv.org/abs/2504.10149v1","title":"BoTTA: Benchmarking on-device Test Time Adaptation","summary":"The performance of deep learning models depends heavily on test samples at\nruntime, and shifts from the training data distribution can significantly\nreduce accuracy. Test-time adaptation (TTA) addresses this by adapting models\nduring inference without requiring labeled test data or access to the original\ntraining set. While research has explored TTA from various perspectives like\nalgorithmic complexity, data and class distribution shifts, model\narchitectures, and offline versus continuous learning, constraints specific to\nmobile and edge devices remain underexplored. We propose BoTTA, a benchmark\ndesigned to evaluate TTA methods under practical constraints on mobile and edge\ndevices. Our evaluation targets four key challenges caused by limited resources\nand usage conditions: (i) limited test samples, (ii) limited exposure to\ncategories, (iii) diverse distribution shifts, and (iv) overlapping shifts\nwithin a sample. We assess state-of-the-art TTA methods under these scenarios\nusing benchmark datasets and report system-level metrics on a real testbed.\nFurthermore, unlike prior work, we align with on-device requirements by\nadvocating periodic adaptation instead of continuous inference-time adaptation.\nExperiments reveal key insights: many recent TTA algorithms struggle with small\ndatasets, fail to generalize to unseen categories, and depend on the diversity\nand complexity of distribution shifts. BoTTA also reports device-specific\nresource use. For example, while SHOT improves accuracy by $2.25\\times$ with\n$512$ adaptation samples, it uses $1.08\\times$ peak memory on Raspberry Pi\nversus the base model. BoTTA offers actionable guidance for TTA in real-world,\nresource-constrained deployments.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-14T12:00:00Z"}
{"aid":"http://arxiv.org/abs/2504.10154v1","title":"The energy content of Alfven waves in the stratified solar atmosphere","summary":"Alfven waves propagating in a vertically stratified plasma, such as those\ntravelling from the solar photosphere to the corona, are partially reflected\ndue to the gradient in the Alfven speed. Wave reflection naturally results in\nthe superposition of upward- and downward-propagating waves. A simple analytic\nmodel demonstrates that this superposition leads to the non-equipartition of\nkinetic and magnetic energies in the Alfven wave perturbations and slows down\nthe net energy transport. A numerical model of Alfven wave propagation in the\nlower solar atmosphere reveals significant wave reflection below the transition\nregion, leading to highly variable kinetic and magnetic energy content in the\nlower chromosphere. At higher altitudes, the kinetic energy eventually\ndominates, depending on the wave frequency. The velocity at which net energy\npropagates upward is significantly smaller than the local Alfven speed\nthroughout the chromosphere. Consequently, the commonly used expression for\nunidirectional Alfven waves in a uniform plasma, which relates the energy flux\nto the kinetic energy density, is not generally applicable in the stratified\nlower solar atmosphere and cannot be reliably used to estimate the energy\ncontent of observed waves. A generalized expression is given, incorporating\ncorrection factors that account for wave reflection and energy\nnon-equipartition. The applicability of the expression is discussed.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-14T12:07:51Z"}
{"aid":"http://arxiv.org/abs/2504.10155v1","title":"A Buium--Coleman bound for the Mordell--Lang conjecture","summary":"For $X$ a hyperbolic curve of genus $g$ with good reduction at $p\\geq 2g$, we\ngive an explicit bound on the Mordell--Lang locus $X(\\mathbb{C})\\cap \\Gamma $,\nwhen $\\Gamma \\subset J(\\mathbb{C})$ is the divisible hull of a subgroup of\n$J(\\mathbb{Q} _p ^{\\mathrm{nr}})$ of rank less than $g$. Without any\nassumptions on the rank (but with all the other assumptions) we show that\n$X(\\mathbb{C})\\cap \\Gamma $ is unramified at $p$, and bound the size of its\nimage in $X(\\overline{\\mathbb{F} }_p )$. As a corollary, we show that Mordell\nimplies Mordell--Lang for curves.","main_category":"math.NT","categories":"math.NT,math.AG","published":"2025-04-14T12:11:22Z"}
{"aid":"http://arxiv.org/abs/2504.10157v1","title":"SocioVerse: A World Model for Social Simulation Powered by LLM Agents\n  and A Pool of 10 Million Real-World Users","summary":"Social simulation is transforming traditional social science research by\nmodeling human behavior through interactions between virtual individuals and\ntheir environments. With recent advances in large language models (LLMs), this\napproach has shown growing potential in capturing individual differences and\npredicting group behaviors. However, existing methods face alignment challenges\nrelated to the environment, target users, interaction mechanisms, and\nbehavioral patterns. To this end, we introduce SocioVerse, an LLM-agent-driven\nworld model for social simulation. Our framework features four powerful\nalignment components and a user pool of 10 million real individuals. To\nvalidate its effectiveness, we conducted large-scale simulation experiments\nacross three distinct domains: politics, news, and economics. Results\ndemonstrate that SocioVerse can reflect large-scale population dynamics while\nensuring diversity, credibility, and representativeness through standardized\nprocedures and minimal manual adjustments.","main_category":"cs.CL","categories":"cs.CL,cs.CY","published":"2025-04-14T12:12:52Z"}
{"aid":"http://arxiv.org/abs/2504.10162v1","title":"When Do We Feel Present in a Virtual Reality? Towards Sensitivity and\n  User Acceptance of Presence Questionnaires","summary":"Presence is an important and widely used metric to measure the quality of\nvirtual reality (VR) applications. Given the multifaceted and subjective nature\nof presence, the most common measures for presence are questionnaires. But\nthere is little research on their validity regarding specific presence\ndimensions and their responsiveness to differences in perception among users.\nWe investigated four presence questionnaires (SUS, PQ, IPQ, Bouchard) on their\nresponsiveness to intensity variations of known presence dimensions and asked\nusers about their consistency with their experience. Therefore, we created five\nVR scenarios that were designed to emphasize a specific presence dimension. Our\nfindings showed heterogeneous sensitivity of the questionnaires dependent on\nthe different dimensions of presence. This highlights a context-specific\nsuitability of presence questionnaires. The questionnaires' sensitivity was\nfurther stated as lower than actually perceived. Based on our findings, we\noffer guidance on selecting these questionnaires based on their suitability for\nparticular use cases.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T12:18:05Z"}
{"aid":"http://arxiv.org/abs/2504.10209v1","title":"Continuity of differential operators for nonarchimedean Banach algebras","summary":"Given a nonarchimedean field $K$ and a commutative, noetherian, Banach\n$K$-algebra $A$, we study continuity of $K$-linear differential operators (in\nthe sense of Grothendieck) between finitely generated Banach $A$-modules. When\n$K$ is of characteristic zero we show that every such operator is continuous if\nand only if $A/\\mathfrak{m}$ is a finite extension of $K$ for every maximal\nideal $\\mathfrak{m}\\subset A$.","main_category":"math.AG","categories":"math.AG,math.FA","published":"2025-04-14T13:24:59Z"}
{"aid":"http://arxiv.org/abs/2504.10222v1","title":"PRM-BAS: Enhancing Multimodal Reasoning through PRM-guided Beam\n  Annealing Search","summary":"Recent work increasingly focuses on improving the reasoning capabilities of\nMultimodal Large Language Models (MLLMs). Among existing methods, Process\nReward Models (PRMs) stand out for offering dense, step-wise supervision to\nguide intermediate reasoning. However, how to effectively integrate PRMs into\nsearch strategies remains an open question. In this paper, we introduce PRM-BAS\n(PRM-Guided Beam Annealing Search), a lightweight approach for PRM-guided\nreasoning that dynamically adjusts beam size -- starting with a broader search\nspace and gradually narrowing it as contextual information accumulates, thereby\nbalancing performance and efficiency. We further propose a unified framework\nfor data construction and PRM training. Specifically, we construct the\nPRM-BAS-300k dataset by selecting 300k questions from existing datasets and\nperforming rollouts at each step to estimate the probability of reaching a\ncorrect final answer. The PRM is then trained using a combination of value loss\nfor absolute action quality and rank loss for relative action quality.\nExtensive experiments on challenging multimodal reasoning benchmarks\ndemonstrate that PRM-BAS significantly improves reasoning performance while\nmaintaining low computational cost. Moreover, it generalizes well across\ndifferent model scales and architectures, showcasing strong robustness and\nplug-and-play capability.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-14T13:44:11Z"}
{"aid":"http://arxiv.org/abs/2504.10230v1","title":"Extracting cosmological information from the abundance of galaxy\n  clusters with simulation-based inference","summary":"The abundance of galaxy clusters as a function of mass and redshift is a\nwell-established and powerful cosmological probe. Cosmological analyses based\non galaxy cluster number counts have traditionally relied on explicitly\ncomputed likelihoods, which are often challenging to develop with the required\naccuracy and expensive to evaluate. In this work, we implement an alternative\napproach based on simulation-based inference (SBI) methods that relies solely\non synthetic galaxy cluster catalogues generated under a given model. These\ncatalogues are much easier to produce than it is to develop and validate a\nlikelihood. We validate this approach in the context of the galaxy cluster\nsurvey of the upcoming Simons Observatory for a setup in which we can also\nevaluate an exact explicit likelihood. We find that our SBI-based approach\nyields cosmological parameter posterior means that are within $0.2\\,\\sigma$ of\nthose obtained with the explicit likelihood and with biases smaller than\n$0.1\\,\\sigma$. We also introduce and validate a procedure to assess the\ngoodness of fit using only synthetic catalogues similar to those used for\ntraining. This demonstrates, for the first time, that a galaxy cluster number\ncount cosmological analysis can be performed fully without resorting to a\nlikelihood at any stage. Finally, we apply our SBI-based approach to the real\nPlanck MMF3 cosmology sample, obtaining cosmological parameter constraints that\nare within $0.1\\,\\sigma$ of their likelihood-based counterparts. This\nconstitutes the first SBI-based number count cosmological analysis of a real\ngalaxy cluster catalogue.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-14T13:51:55Z"}
{"aid":"http://arxiv.org/abs/2504.10233v1","title":"Bingo: Radix-based Bias Factorization for Random Walk on Dynamic Graphs","summary":"Random walks are a primary means for extracting information from large-scale\ngraphs. While most real-world graphs are inherently dynamic, state-of-the-art\nrandom walk engines failed to efficiently support such a critical use case.\nThis paper takes the initiative to build a general random walk engine for\ndynamically changing graphs with two key principles: (i) This system should\nsupport both low-latency streaming updates and high-throughput batched updates.\n(ii) This system should achieve fast sampling speed while maintaining\nacceptable space consumption to support dynamic graph updates. Upholding both\nstandards, we introduce Bingo, a GPU-based random walk engine for dynamically\nchanging graphs. First, we propose a novel radix-based bias factorization\nalgorithm to support constant time sampling complexity while supporting fast\nstreaming updates. Second, we present a group-adaption design to reduce space\nconsumption dramatically. Third, we incorporate GPU-aware designs to support\nhigh-throughput batched graph updates on massively parallel platforms.\nTogether, Bingo outperforms existing efforts across various applications,\nsettings, and datasets, achieving up to a 271.11x speedup compared to the\nstate-of-the-art efforts.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-14T13:53:58Z"}
{"aid":"http://arxiv.org/abs/2504.10264v1","title":"Multidimensional non-uniform hyperbolicity, robust exponential mixing\n  and the basin problem","summary":"We show that the ergodic, topological and geometric basins coincide for\nhyperbolic dominated ergodic $cu$-Gibbs states, solving the ``basin problem''\nfor a wide class of non-uniformly hyperbolic systems.\n  We obtain robust examples of exponential mixing physical measures for systems\nwith multidimensional nonuniform hyperbolic dominated splitting, without\nuniformly expanding or contracting subbundles.\n  Both results are a consequence of extending the construction of\nGibbs-Markov-Young structures from partial hyperbolic systems to systems with\nonly a dominated splitting, using the existence of an ``improved hyperbolic\nblock'', with respect to Pesin's Nonuniform Hyperbolic Theory, for hyperbolic\ndominated measures of smooth maps, obtained through hyperbolic times and\nassociated ``coherent schedules'' introduced by one of the coauthors.","main_category":"math.DS","categories":"math.DS","published":"2025-04-14T14:29:23Z"}
{"aid":"http://arxiv.org/abs/2504.10266v1","title":"Vision based driving agent for race car simulation environments","summary":"In recent years, autonomous driving has become a popular field of study. As\ncontrol at tire grip limit is essential during emergency situations, algorithms\ndeveloped for racecars are useful for road cars too. This paper examines the\nuse of Deep Reinforcement Learning (DRL) to solve the problem of grip limit\ndriving in a simulated environment. Proximal Policy Optimization (PPO) method\nis used to train an agent to control the steering wheel and pedals of the\nvehicle, using only visual inputs to achieve professional human lap times. The\npaper outlines the formulation of the task of time optimal driving on a race\ntrack as a deep reinforcement learning problem, and explains the chosen\nobservations, actions, and reward functions. The results demonstrate human-like\nlearning and driving behavior that utilize maximum tire grip potential.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.LG","published":"2025-04-14T14:29:37Z"}
{"aid":"http://arxiv.org/abs/2504.10283v1","title":"$α$-Flow: A Unified Framework for Continuous-State Discrete Flow\n  Matching Models","summary":"Recent efforts have extended the flow-matching framework to discrete\ngenerative modeling. One strand of models directly works with the continuous\nprobabilities instead of discrete tokens, which we colloquially refer to as\nContinuous-State Discrete Flow Matching (CS-DFM). Existing CS-DFM models differ\nsignificantly in their representations and geometric assumptions. This work\npresents a unified framework for CS-DFM models, under which the existing\nvariants can be understood as operating on different $\\alpha$-representations\nof probabilities. Building upon the theory of information geometry, we\nintroduce $\\alpha$-Flow, a family of CS-DFM models that adheres to the\ncanonical $\\alpha$-geometry of the statistical manifold, and demonstrate its\noptimality in minimizing the generalized kinetic energy. Theoretically, we show\nthat the flow matching loss for $\\alpha$-flow establishes a unified variational\nbound for the discrete negative log-likelihood. We comprehensively evaluate\ndifferent instantiations of $\\alpha$-flow on various discrete generation\ndomains to demonstrate their effectiveness in discrete generative modeling,\nincluding intermediate values whose geometries have never been explored before.\n$\\alpha$-flow significantly outperforms its discrete-state counterpart in image\nand protein sequence generation and better captures the entropy in language\nmodeling.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-14T14:51:45Z"}
{"aid":"http://arxiv.org/abs/2504.10286v1","title":"Characterizing LLM-driven Social Network: The Chirper.ai Case","summary":"Large language models (LLMs) demonstrate the ability to simulate human\ndecision-making processes, enabling their use as agents in modeling\nsophisticated social networks, both offline and online. Recent research has\nexplored collective behavioral patterns and structural characteristics of LLM\nagents within simulated networks. However, empirical comparisons between\nLLM-driven and human-driven online social networks remain scarce, limiting our\nunderstanding of how LLM agents differ from human users. This paper presents a\nlarge-scale analysis of Chirper.ai, an X/Twitter-like social network entirely\npopulated by LLM agents, comprising over 65,000 agents and 7.7 million\nAI-generated posts. For comparison, we collect a parallel dataset from\nMastodon, a human-driven decentralized social network, with over 117,000 users\nand 16 million posts. We examine key differences between LLM agents and humans\nin posting behaviors, abusive content, and social network structures. Our\nfindings provide critical insights into the evolving landscape of online social\nnetwork analysis in the AI era, offering a comprehensive profile of LLM agents\nin social simulations.","main_category":"cs.SI","categories":"cs.SI,cs.AI","published":"2025-04-14T14:53:31Z"}
{"aid":"http://arxiv.org/abs/2504.10289v1","title":"Optimal Graph Stretching for Distributed Averaging","summary":"The performance of distributed averaging depends heavily on the underlying\ntopology. In various fields, including compressed sensing, multi-party\ncomputation, and abstract graph theory, graphs may be expected to be free of\nshort cycles, i.e. to have high girth. Though extensive analyses and heuristics\nexist for optimising the performance of distributed averaging in general\nnetworks, these studies do not consider girth. As such, it is not clear what\nhappens to convergence time when a graph is stretched to a higher girth.\n  In this work, we introduce the optimal graph stretching problem, wherein we\nare interested in finding the set of edges for a particular graph that ensures\noptimal convergence time under constraint of a minimal girth. We compare\nvarious methods for choosing which edges to remove, and use various convergence\nheuristics to speed up the searching process. We generate many graphs with\nvarying parameters, stretch and optimise them, and measure the duration of\ndistributed averaging. We find that stretching by itself significantly\nincreases convergence time. This decrease can be counteracted with a subsequent\nrepair phase, guided by a convergence time heuristic. Existing heuristics are\ncapable, but may be suboptimal.","main_category":"cs.DC","categories":"cs.DC,cs.DM","published":"2025-04-14T15:01:24Z"}
{"aid":"http://arxiv.org/abs/2504.10303v1","title":"Row completion of polynomial and rational matrices","summary":"We characterize the existence of a polynomial (rational) matrix when its\neigenstructure (complete structural data) and some of its rows are prescribed.\nFor polynomial matrices, this problem was solved in a previous work when the\npolynomial matrix has the same degree as the prescribed submatrix. In that\npaper, the following row completion problems were also solved arising when the\neigenstructure was partially prescribed, keeping the restriction on the degree:\nthe eigenstructure but the row (column) minimal indices, and the finite and/or\ninfinite structures. Here we remove the restriction on the degree, allowing it\nto be greater than or equal to that of the submatrix. We also generalize the\nresults to rational matrices. Obviously, the results obtained hold for the\ncorresponding column completion problems.","main_category":"math.SP","categories":"math.SP","published":"2025-04-14T15:11:19Z"}
{"aid":"http://arxiv.org/abs/2504.10326v1","title":"AlayaDB: The Data Foundation for Efficient and Effective Long-context\n  LLM Inference","summary":"AlayaDB is a cutting-edge vector database system natively architected for\nefficient and effective long-context inference for Large Language Models (LLMs)\nat AlayaDB AI. Specifically, it decouples the KV cache and attention\ncomputation from the LLM inference systems, and encapsulates them into a novel\nvector database system. For the Model as a Service providers (MaaS), AlayaDB\nconsumes fewer hardware resources and offers higher generation quality for\nvarious workloads with different kinds of Service Level Objectives (SLOs), when\ncomparing with the existing alternative solutions (e.g., KV cache\ndisaggregation, retrieval-based sparse attention). The crux of AlayaDB is that\nit abstracts the attention computation and cache management for LLM inference\ninto a query processing procedure, and optimizes the performance via a native\nquery optimizer. In this work, we demonstrate the effectiveness of AlayaDB via\n(i) three use cases from our industry partners, and (ii) extensive experimental\nresults on LLM inference benchmarks.","main_category":"cs.AI","categories":"cs.AI,cs.DB,cs.IR","published":"2025-04-14T15:34:26Z"}
{"aid":"http://arxiv.org/abs/2504.10339v1","title":"Gyroscopically stabilized quantum spin rotors","summary":"Recent experiments demonstrate all-electric spinning of levitated\nnanodiamonds with embedded nitrogen-vacancy spins. Here, we argue that such\ngyroscopically stabilized spin rotors offer a promising platform for probing\nand exploiting quantum spin-rotation coupling of particles hosting a single\nspin degree of freedom. Specifically, we derive the effective Hamiltonian\ndescribing how an embedded spin affects the rotation of rapidly revolving\nquantum rotors due to the Einstein-de Haas and Barnett effects, which we use to\ndevise experimental protocols for observing this coupling in state-of-the-art\nexperiments. This will open the door for future exploitations of quantum spin\nrotors for superposition experiments with massive objects.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T15:47:58Z"}
{"aid":"http://arxiv.org/abs/2504.10351v1","title":"Multimodal Representation Learning Techniques for Comprehensive Facial\n  State Analysis","summary":"Multimodal foundation models have significantly improved feature\nrepresentation by integrating information from multiple modalities, making them\nhighly suitable for a broader set of applications. However, the exploration of\nmultimodal facial representation for understanding perception has been limited.\nUnderstanding and analyzing facial states, such as Action Units (AUs) and\nemotions, require a comprehensive and robust framework that bridges visual and\nlinguistic modalities. In this paper, we present a comprehensive pipeline for\nmultimodal facial state analysis. First, we compile a new Multimodal Face\nDataset (MFA) by generating detailed multilevel language descriptions of face,\nincorporating Action Unit (AU) and emotion descriptions, by leveraging GPT-4o.\nSecond, we introduce a novel Multilevel Multimodal Face Foundation model (MF^2)\ntailored for Action Unit (AU) and emotion recognition. Our model incorporates\ncomprehensive visual feature modeling at both local and global levels of face\nimage, enhancing its ability to represent detailed facial appearances. This\ndesign aligns visual representations with structured AU and emotion\ndescriptions, ensuring effective cross-modal integration. Third, we develop a\nDecoupled Fine-Tuning Network (DFN) that efficiently adapts MF^2 across various\ntasks and datasets. This approach not only reduces computational overhead but\nalso broadens the applicability of the foundation model to diverse scenarios.\nExperimentation show superior performance for AU and emotion detection tasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:00:57Z"}
{"aid":"http://arxiv.org/abs/2504.10352v1","title":"Pseudo-Autoregressive Neural Codec Language Models for Efficient\n  Zero-Shot Text-to-Speech Synthesis","summary":"Recent zero-shot text-to-speech (TTS) systems face a common dilemma:\nautoregressive (AR) models suffer from slow generation and lack duration\ncontrollability, while non-autoregressive (NAR) models lack temporal modeling\nand typically require complex designs. In this paper, we introduce a novel\npseudo-autoregressive (PAR) codec language modeling approach that unifies AR\nand NAR modeling. Combining explicit temporal modeling from AR with parallel\ngeneration from NAR, PAR generates dynamic-length spans at fixed time steps.\nBuilding on PAR, we propose PALLE, a two-stage TTS system that leverages PAR\nfor initial generation followed by NAR refinement. In the first stage, PAR\nprogressively generates speech tokens along the time dimension, with each step\npredicting all positions in parallel but only retaining the left-most span. In\nthe second stage, low-confidence tokens are iteratively refined in parallel,\nleveraging the global contextual information. Experiments demonstrate that\nPALLE, trained on LibriTTS, outperforms state-of-the-art systems trained on\nlarge-scale data, including F5-TTS, E2-TTS, and MaskGCT, on the LibriSpeech\ntest-clean set in terms of speech quality, speaker similarity, and\nintelligibility, while achieving up to ten times faster inference speed. Audio\nsamples are available at https://anonymous-palle.github.io.","main_category":"eess.AS","categories":"eess.AS,cs.CL","published":"2025-04-14T16:03:21Z"}
{"aid":"http://arxiv.org/abs/2504.10367v1","title":"On the universality of the split monopole black hole magnetosphere","summary":"Black holes can acquire magnetic flux from their magnetized progenitor or via\nprolonged accretion. We study the evolution of black hole magnetospheres by\nmeans of axisymmetric general relativistic magnetohydrodynamic simulations. We\nshow that all simulated initial magnetic field geometries of varying complexity\nultimately evolve into a split monopole magnetosphere. The magnetospheric\nevolution consists of two phases. In the first phase, the magnetosphere evolves\ntoward pressure equilibrium accompanied by a large magnetic flux decrease on\nthe event horizon on a fast Alfv\\'enic timescale of $\\sim 60$ light-crossing\ntimes of the gravitational radius. The second phase proceeds in a pressure\nbalance in which the magnetic flux decays and current sheets shift in polar\nangle over the event horizon on slower resistive timescales. We present an\nanalytic model for the second phase. Furthermore, we show that in a split\nmonopole magnetosphere the magnetic flux on the event horizon decays\nexponentially with a timescale that depends on the black hole spin, where\nhigher spin results in slower decay. Our results can have an implications for\nthe timescales of reconnection-powered flares and for multimessenger\ncounterparts to gravitational wave events.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-14T16:12:31Z"}
{"aid":"http://arxiv.org/abs/2504.10383v1","title":"A monotonicity formula for a semilinear fractional parabolic equation","summary":"By applying a high-dimensional parabolic-to-elliptic transformation, we\nestablish a monotonicity formula for the extension problem of the fractional\nparabolic semilinear equation $(\\partial_t -\\Delta)^s u = |u|^{p-1}u$, where\n$0<s<1$. This is an analogous result to the Giga-Kohn monotonicity formula for\nthe equation $\\partial_t u - \\Delta u = |u|^{p-1}u.$","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T16:28:09Z"}
{"aid":"http://arxiv.org/abs/2504.10418v1","title":"CliniChat: A Multi-Source Knowledge-Driven Framework for Clinical\n  Interview Dialogue Reconstruction and Evaluation","summary":"Large language models (LLMs) hold great promise for assisting clinical\ninterviews due to their fluent interactive capabilities and extensive medical\nknowledge. However, the lack of high-quality interview dialogue data and widely\naccepted evaluation methods has significantly impeded this process. So we\npropose CliniChat, a framework that integrates multi-source knowledge to enable\nLLMs to simulate real-world clinical interviews. It consists of two modules:\nClini-Recon and Clini-Eval, each responsible for reconstructing and evaluating\ninterview dialogues, respectively. By incorporating three sources of knowledge,\nClini-Recon transforms clinical notes into systematic, professional, and\nempathetic interview dialogues. Clini-Eval combines a comprehensive evaluation\nmetric system with a two-phase automatic evaluation approach, enabling LLMs to\nassess interview performance like experts. We contribute MedQA-Dialog, a\nhigh-quality synthetic interview dialogue dataset, and CliniChatGLM, a model\nspecialized for clinical interviews. Experimental results demonstrate that\nCliniChatGLM's interview capabilities undergo a comprehensive upgrade,\nparticularly in history-taking, achieving state-of-the-art performance.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T17:06:47Z"}
{"aid":"http://arxiv.org/abs/2504.10426v1","title":"Spectral Mode Enhancement in Coherent-harmonic Dual-comb Spectroscopy\n  Enables Exceeding 300-fold Averaging Time Reduction","summary":"Dual-comb spectroscopy (DCS) is a novel Fourier-transform spectroscopy not\nrelying on mechanical scanning and capable of simultaneously achieving\nhigh-speed, high spectral resolution, and broad optical bandwidth. Despite\nthis, conventional DCS suffers from low signal-to-noise ratio (SNR) per single\nacquisition due to the dynamic range limitation of photodetectors imposed by\nthe high peak power of mode-locked pulses, necessitating coherent averaging.\nConsequently, averaging numerous interferograms compromises both the\nexceptional time resolution and places greater demands on long-term mutual\ncoherence and stability. In this study, we demonstrate a novel approach to\nenhance SNR by exploiting the spectral mode enhancement mechanism in\ncoherent-harmonic pulses. As a proof-of-concept, we employ two frequency combs\nwith mode spacing of $\\sim$12.5 MHz, operating at a 20th harmonic repetition\nrate of $\\sim$250 MHz. The result demonstrates a $>$300-fold reduction in\naveraging time while achieving comparable SNR in conventional DCS. This\nreduction is expected to be further enhancement through integration with\nultra-high repetition rate combs, such as microresonator combs. This approach\npromises both a recovery of the inherent high-speed capability and a mitigation\nof the coherence-time requirements, thereby making it possible to significantly\nfacilitate subsequent DCS investigations, as well as field-deployed\nimplementations.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-14T17:16:08Z"}
{"aid":"http://arxiv.org/abs/2504.10439v1","title":"Bayesian Analysis of Interpretable Aging across Thousands of Lithium-ion\n  Battery Cycles","summary":"The Doyle-Fuller-Newman (DFN) model is a common mechanistic model for\nlithium-ion batteries. The reaction rate constant and diffusivity within the\nDFN model are key parameters that directly affect the movement of lithium ions,\nthereby offering explanations for cell aging. This work investigates the\nability to uniquely estimate each electrode's diffusion coefficients and\nreaction rate constants of 95 Tesla Model 3 cells with a nickel cobalt aluminum\noxide (NCA) cathode and silicon oxide--graphite\n(LiC$_\\text{6}$--SiO$_{\\text{x}}$) anode. The parameters are estimated at\nintermittent diagnostic cycles over the lifetime of each cell. The four\nparameters are estimated using Markov chain Monte Carlo (MCMC) for uncertainty\nquantification (UQ) for a total of 7776 cycles at discharge C-rates of C/5, 1C,\nand 2C. While one or more anode parameters are uniquely identifiable over every\ncell's lifetime, cathode parameters become identifiable at mid- to end-of-life,\nindicating measurable resistive growth in the cathode. The contribution of key\nparameters to the state of health (SOH) is expressed as a power law. This model\nfor SOH shows a high consistency with the MCMC results performed over the\noverall lifespan of each cell. Our approach suggests that effective diagnosis\nof aging can be achieved by predicting the trajectories of the parameters\ncontributing to cell aging. As such, extending our analysis with more\nphysically accurate models building on DFN may lead to more identifiable\nparameters and further improved aging predictions.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-14T17:31:16Z"}
{"aid":"http://arxiv.org/abs/2504.10442v1","title":"Pinching-Antenna System (PASS) Enhanced Covert Communications","summary":"A Pinching-Antenna SyStem (PASS)-assisted convert communication framework is\nproposed. PASS utilizes dielectric waveguides with freely positioned pinching\nantennas (PAs) to establish strong line-of-sight links. Capitalizing on this\nhigh reconfigurable flexibility of antennas, the potential of PASS for covert\ncommunications is investigated. 1)~For the single-waveguide single-PA (SWSP)\nscenario, a closed-form optimal PA position that maximizes the covert rate is\nfirst derived. Subsequently, a one-dimensional power search is employed to\nenable low-complexity optimization for covert communications. With antenna\nmobility on a scale of meters, PASS can deal with the challenging situation of\nthe eavesdropper enjoying better channel conditions than the legal user. 2)~For\nthe multi-waveguide multi-PA (MWMP) scenario, the positions of multiple PAs are\noptimized to enable effective pinching beamforming, thereby enhancing the\ncovert rate. To address the resultant multimodal joint transmit and pinching\nbeamforming problem, a twin particle swarm optimization (TwinPSO) approach is\nproposed. Numerical results demonstrate that: i)~the proposed approaches can\neffectively resolve the optimization problems; ii)~PASS achieves a higher\ncovert rate than conventional fixed-position antenna architectures; and\niii)~with enhanced flexibility, the MWMP setup outperforms the SWSP\ncounterpart.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T17:32:54Z"}
{"aid":"http://arxiv.org/abs/2504.10443v1","title":"Multimodal Long Video Modeling Based on Temporal Dynamic Context","summary":"Recent advances in Large Language Models (LLMs) have led to significant\nbreakthroughs in video understanding. However, existing models still struggle\nwith long video processing due to the context length constraint of LLMs and the\nvast amount of information within the video. Although some recent methods are\ndesigned for long video understanding, they often lose crucial information\nduring token compression and struggle with additional modality like audio. In\nthis work, we propose a dynamic long video encoding method utilizing the\ntemporal relationship between frames, named Temporal Dynamic Context (TDC).\nFirstly, we segment the video into semantically consistent scenes based on\ninter-frame similarities, then encode each frame into tokens using visual-audio\nencoders. Secondly, we propose a novel temporal context compressor to reduce\nthe number of tokens within each segment. Specifically, we employ a query-based\nTransformer to aggregate video, audio, and instruction text tokens into a\nlimited set of temporal context tokens. Finally, we feed the static frame\ntokens and the temporal context tokens into the LLM for video understanding.\nFurthermore, to handle extremely long videos, we propose a training-free\nchain-of-thought strategy that progressively extracts answers from multiple\nvideo segments. These intermediate answers serve as part of the reasoning\nprocess and contribute to the final answer. We conduct extensive experiments on\ngeneral video understanding and audio-video understanding benchmarks, where our\nmethod demonstrates strong performance. The code and models are available at\nhttps://github.com/Hoar012/TDC-Video.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL,cs.LG,cs.MM","published":"2025-04-14T17:34:06Z"}
{"aid":"http://arxiv.org/abs/2504.10463v1","title":"Influence of excitonic coupling, static disorder, and coherent dynamics\n  in action-2D electronic spectroscopy of a molecular dimer model","summary":"We investigate the spectral features of Action-2D Electronic Spectroscopy\n(A-2DES) in a molecular dimer model across different regimes of excitonic\ncoupling. By explicitly including a second-excited state for each chromophore,\nwe simulate A-2DES spectra ranging from the non-interacting limit to the\nstrong-coupling case, focusing on the significance of cross peaks. While for\nweak excitonic coupling, cross peaks can be understood as the incoherent mixing\nof linear signals of the two chromophores, these features reflect excitonic\ndelocalization as the coupling increases. We highlight that A-2DES offers\nenhanced sensitivity to coherent excited-state dynamics, particularly in the\nintermediate-coupling regime, where it provides higher contrast compared to its\ncoherent-detected counterpart. Finally, we show that static disorder reduces\nthe relative amplitude of cross peaks compared to diagonal features in a way\nthat depends on the excitonic coupling. Notably, the relative suppression of\ncross peaks decreases with the strength of the excitonic coupling, implying\nthat spectral features related to incoherent mixing are less prominent in\ninhomogeneous samples. These findings support the potential of A-2DES for\ninvestigating excitonic dynamics in small multi-chromophoric systems.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-14T17:51:47Z"}
{"aid":"http://arxiv.org/abs/2504.10469v1","title":"Bounds as blueprints: towards optimal and accelerated photonic inverse\n  design","summary":"Our ability to structure materials at the nanoscale has, and continues to,\nenable key advances in optical control. In pursuit of optimal photonic designs,\nsubstantial progress has been made on two complementary fronts: bottom-up\nstructural optimizations (inverse design) discover complex high-performing\nstructures but offer no guarantees of optimality; top-down field optimizations\n(convex relaxations) reveal fundamental performance limits but offer no\nguarantees that structures meeting the limits exist. We bridge the gap between\nthese two parallel paradigms by introducing a ``verlan'' initialization method\nthat exploits the encoded local and global wave information in duality-based\nconvex relaxations to guide inverse design towards better-performing\nstructures. We illustrate this technique via the challenging problem of Purcell\nenhancement, maximizing the power extracted from a small emitter in the\nvicinity of a photonic structure, where ill-conditioning and the presence of\ncompeting local maxima lead to sub-optimal designs for adjoint optimization.\nStructures discovered by our verlan method outperform standard (random)\ninitializations by close to an order of magnitude and approach fundamental\nperformance limits within a factor of two, highlighting the possibility of\naccessing significant untapped performance improvements.","main_category":"physics.optics","categories":"physics.optics,math.OC","published":"2025-04-14T17:53:34Z"}
{"aid":"http://arxiv.org/abs/2504.10481v1","title":"xVerify: Efficient Answer Verifier for Reasoning Model Evaluations","summary":"With the release of the o1 model by OpenAI, reasoning models adopting slow\nthinking strategies have gradually emerged. As the responses generated by such\nmodels often include complex reasoning, intermediate steps, and\nself-reflection, existing evaluation methods are often inadequate. They\nstruggle to determine whether the LLM output is truly equivalent to the\nreference answer, and also have difficulty identifying and extracting the final\nanswer from long, complex responses. To address this issue, we propose xVerify,\nan efficient answer verifier for reasoning model evaluations. xVerify\ndemonstrates strong capability in equivalence judgment, enabling it to\neffectively determine whether the answers produced by reasoning models are\nequivalent to reference answers across various types of objective questions. To\ntrain and evaluate xVerify, we construct the VAR dataset by collecting\nquestion-answer pairs generated by multiple LLMs across various datasets,\nleveraging multiple reasoning models and challenging evaluation sets designed\nspecifically for reasoning model assessment. A multi-round annotation process\nis employed to ensure label accuracy. Based on the VAR dataset, we train\nmultiple xVerify models of different scales. In evaluation experiments\nconducted on both the test set and generalization set, all xVerify models\nachieve overall F1 scores and accuracy exceeding 95\\%. Notably, the smallest\nvariant, xVerify-0.5B-I, outperforms all evaluation methods except GPT-4o,\nwhile xVerify-3B-Ib surpasses GPT-4o in overall performance. These results\nvalidate the effectiveness and generalizability of xVerify.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T17:59:36Z"}
{"aid":"http://arxiv.org/abs/2504.10484v1","title":"Generalized Symmetries of Non-SUSY and Discrete Torsion String\n  Backgrounds","summary":"String / M-theory backgrounds with degrees of freedom at a localized\nsingularity provide a general template for generating strongly correlated\nsystems decoupled from lower-dimensional gravity. There are by now several\ncomplementary procedures for extracting the associated generalized symmetry\ndata from orbifolds of the form $\\mathbb{R}^6 / \\Gamma$, including methods\nbased on the boundary topology of the asymptotic geometry, as well as the\nadjacency matrix for fermionic degrees of freedom in the quiver gauge theory of\nprobe branes. In this paper we show that this match between the two methods\nalso works in non-supersymmetric and discrete torsion backgrounds. In\nparticular, a refinement of geometric boundary data based on Chen-Ruan\ncohomology matches the expected answer based on quiver data. Additionally, we\nalso show that free (i.e., non-torsion) factors count the number of\nhigher-dimensional branes which couple to the localized singularity. We use\nthis to also extract quadratic pairing terms in the associated symmetry theory\n(SymTh) for these systems, and explain how these considerations generalize to a\nbroader class of backgrounds.","main_category":"hep-th","categories":"hep-th,math.AT,math.RT","published":"2025-04-14T17:59:55Z"}
{"aid":"http://arxiv.org/abs/2504.10486v1","title":"DNF-Avatar: Distilling Neural Fields for Real-time Animatable Avatar\n  Relighting","summary":"Creating relightable and animatable human avatars from monocular videos is a\nrising research topic with a range of applications, e.g. virtual reality,\nsports, and video games. Previous works utilize neural fields together with\nphysically based rendering (PBR), to estimate geometry and disentangle\nappearance properties of human avatars. However, one drawback of these methods\nis the slow rendering speed due to the expensive Monte Carlo ray tracing. To\ntackle this problem, we proposed to distill the knowledge from implicit neural\nfields (teacher) to explicit 2D Gaussian splatting (student) representation to\ntake advantage of the fast rasterization property of Gaussian splatting. To\navoid ray-tracing, we employ the split-sum approximation for PBR appearance. We\nalso propose novel part-wise ambient occlusion probes for shadow computation.\nShadow prediction is achieved by querying these probes only once per pixel,\nwhich paves the way for real-time relighting of avatars. These techniques\ncombined give high-quality relighting results with realistic shadow effects.\nOur experiments demonstrate that the proposed student model achieves comparable\nor even better relighting results with our teacher model while being 370 times\nfaster at inference time, achieving a 67 FPS rendering speed.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T17:59:58Z"}
{"aid":"http://arxiv.org/abs/2504.10842v1","title":"A comprehensive review of remote sensing in wetland classification and\n  mapping","summary":"Wetlands constitute critical ecosystems that support both biodiversity and\nhuman well-being; however, they have experienced a significant decline since\nthe 20th century. Back in the 1970s, researchers began to employ remote sensing\ntechnologies for wetland classification and mapping to elucidate the extent and\nvariations of wetlands. Although some review articles summarized the\ndevelopment of this field, there is a lack of a thorough and in-depth\nunderstanding of wetland classification and mapping: (1) the scientific\nimportance of wetlands, (2) major data, methods used in wetland classification\nand mapping, (3) driving factors of wetland changes, (4) current research\nparadigm and limitations, (5) challenges and opportunities in wetland\nclassification and mapping under the context of technological innovation and\nglobal environmental change. In this review, we aim to provide a comprehensive\nperspective and new insights into wetland classification and mapping for\nreaders to answer these questions. First, we conduct a meta-analysis of over\n1,200 papers, encompassing wetland types, methods, sensor types, and study\nsites, examining prevailing trends in wetland classification and mapping. Next,\nwe review and synthesize the wetland features and existing data and methods in\nwetland classification and mapping. We also summarize typical wetland mapping\nproducts and explore the intrinsic driving factors of wetland changes across\nmultiple spatial and temporal scales. Finally, we discuss current limitations\nand propose future directions in response to global environmental change and\ntechnological innovation. This review consolidates our understanding of wetland\nremote sensing and offers scientific recommendations that foster transformative\nprogress in wetland science.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-15T03:59:36Z"}
{"aid":"http://arxiv.org/abs/2504.10848v1","title":"Ichiyo: Fragile and Transient Interaction in Neighborhood","summary":"As the Internet develops, social networking and other communication tools\nhave transformed people's relationships into something fast, visible, and\ngeographically huge. However, these communication tools have not expanded\nopportunities for acquainting oneself with neighbors outside one's social\nnetwork; rather, they have comparatively diminished occasions for interacting\nwith unfamiliar neighbors by prioritizing communication with existing friends.\nTherefore, we invented the medium Ichiyo to increase the opportunities to think\nof neighbors walking along the same street or in the same neighborhood and to\nexpand the imagination of those who pass by and those who used to be there.\nThus, users can engage in indirect interaction. We used commercially available\nlaser cutters to engrave QR codes on leaves that are naturally found in our\nliving space to prevent environmental invasion. The QR codes lead to a communal\nspace on the web where users can freely leave messages. By engraving QR codes,\ninformation can be virtually expanded to be presented. To get the feedback of\nIchiyo, we let a total of several thousand people experience a new way of\ncommunication as a part of the exhibition ''iii Exhibition 2022'', an art\nexhibition at the University of Tokyo. A total of more than 1,000 leaves\nengraved with QR codes were prepared and scattered at the exhibition site and\nalong the road from the nearest station to the venue.","main_category":"cs.HC","categories":"cs.HC,cs.MM","published":"2025-04-15T04:16:48Z"}
{"aid":"http://arxiv.org/abs/2504.10851v1","title":"ICAFS: Inter-Client-Aware Feature Selection for Vertical Federated\n  Learning","summary":"Vertical federated learning (VFL) enables a paradigm for vertically\npartitioned data across clients to collaboratively train machine learning\nmodels. Feature selection (FS) plays a crucial role in Vertical Federated\nLearning (VFL) due to the unique nature that data are distributed across\nmultiple clients. In VFL, different clients possess distinct subsets of\nfeatures for overlapping data samples, making the process of identifying and\nselecting the most relevant features a complex yet essential task. Previous FS\nefforts have primarily revolved around intra-client feature selection,\noverlooking vital feature interaction across clients, leading to subpar model\noutcomes. We introduce ICAFS, a novel multi-stage ensemble approach for\neffective FS in VFL by considering inter-client interactions. By employing\nconditional feature synthesis alongside multiple learnable feature selectors,\nICAFS facilitates ensemble FS over these selectors using synthetic embeddings.\nThis method bypasses the limitations of private gradient sharing and allows for\nmodel training using real data with refined embeddings. Experiments on multiple\nreal-world datasets demonstrate that ICAFS surpasses current state-of-the-art\nmethods in prediction accuracy.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-15T04:19:04Z"}
{"aid":"http://arxiv.org/abs/2504.10858v1","title":"Universal thermodynamic topological classes of three-dimensional BTZ\n  black holes","summary":"We establish a universal thermodynamic topological classification for\nthree-dimensional static neutral Ba\\~{n}ados-Teitelboim-Zanelli (BTZ), charged\nBTZ, and rotating BTZ black holes. We demonstrate that in all three cases\n(static neutral BTZ, charged BTZ, and rotating BTZ black holes), both the\ninnermost small black hole states and the outermost large black hole states\nexhibit stable thermodynamic behavior. In the low-temperature limit, all three\ncases exhibit a thermodynamically stable small black hole state. Conversely, in\nthe high-temperature limit, each system admits a thermodynamically stable large\nblack hole state. Through this analysis, we have rigorously shown that static\nneutral, charged, and rotating BTZ black holes are consistently classified\nwithin the $W^{1+}$ category. Our results demonstrate that neither the charge\nparameter nor the rotation parameter exerts significant influence on the\nuniversal thermodynamic topological classification of three-dimensional static\nneutral BTZ black holes. This reveals a fundamental dichotomy: while angular\nmomentum and electric charge dominate the thermodynamic topology of\nfour-dimensional static black holes, their effects become negligible in the\nthree-dimensional static BTZ case, highlighting a dimension-driven divergence\nin black hole thermodynamic behavior.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-15T04:39:37Z"}
{"aid":"http://arxiv.org/abs/2504.10863v1","title":"Intertwined fluctuations and isotope effects in the Hubbard-Holstein\n  model on the square lattice from functional renormalization","summary":"Electron-electron and electron-phonon interactions are responsible for the\nformation of spin, charge, and superconducting correlations in layered quantum\nmaterials. A paradigmatic model for such materials that captures both kinds of\ninteractions is the two-dimensional Hubbard-Holstein model with a\ndispersionless Einstein phonon. In this work, we provide a detailed analysis of\nthe magnetic, density, and superconducting fluctuations at and away from\nhalf-filling. To that end, we employ the functional renormalization group using\nthe recently introduced extension of the single-boson exchange formulation.\nMore precisely, we go beyond previous approaches to the model by resolving the\nfull frequency dependence of the two-particle vertex and taking into account\nthe feedback from the electronic self-energy. We perform broad parameter scans\nin the space of Hubbard repulsion, electron-phonon coupling strength, and\nphonon frequency to explore the leading magnetic, density, and superconducting\nsusceptibilities from the adiabatic to the anti-adiabatic regime. Our numerical\ndata reveal that self-energy effects lead to an enhancement of the $d$-wave\nsuperconducting susceptibility towards larger phonon frequencies, in contrast\nto earlier isotope-effect studies. At small phonon frequencies, large density\ncontributions to the $s$-wave superconducting susceptibility change sign and\neventually lead to a reduction of $s$-wave superconductivity with increasing\nelectron-phonon coupling, signaling the breakdown of Migdal-Eliashberg theory.\nWe analyze our findings systematically, employing detailed diagnostics of the\nintertwined fluctuations and pinning down the various positive and negative\nisotope effects of the physical susceptibilities.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.supr-con","published":"2025-04-15T04:49:50Z"}
{"aid":"http://arxiv.org/abs/2504.10869v1","title":"Unveiling a young thick disk in the Milky Way","summary":"The thickness of a galaxy's disk provides a valuable probe of its formation\nand evolution history. Observations of the Milky Way and local galaxies have\nrevealed an ubiquitous disk structure with two distinctive components: an old\nthick disk and a relatively young thin disk. The formation of this dual-disk\nstructure and the mechanisms that develop the thickness of the disk are still\nunclear. Whether the disk thickness inherit from the birth environment or is\nestablished through secular dynamical heating after formation is under debate.\nIn this work we identify a relatively young ($\\sim$6.6 billion years old)\ngeometric thick disk in the Milky Way, with a scale height of $0.64$ kpc at the\nSolar Circle. This young thick component exhibits comparable thickness and\nflaring strength to the canonical old thick disk but is more radially extended\nand systematically younger. We also identify thin disk components that formed\nbefore and after this young thick disk. Detailed analysis of the solar vicinity\nstructure suggests that the young thick disk marks the onset of a new phase of\nupside-down disk formation. These findings strongly discount the role of\nsecular dynamical heating and support a turbulent, bursty birth environment as\nthe primary mechanism behind thick disk formation. The existence of two thick\ndisk components suggests that the Milky Way has undergone at least two episodes\nof turbulent and bursty star formation, likely triggered by galaxy mergers.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-04-15T05:01:21Z"}
{"aid":"http://arxiv.org/abs/2504.10870v1","title":"Algorithmic Advances Towards a Realizable Quantum Lattice Boltzmann\n  Method","summary":"The Quantum Lattice Boltzmann Method (QLBM) is one of the most promising\napproaches for realizing the potential of quantum computing in simulating\ncomputational fluid dynamics. Many recent works mostly focus on classical\nsimulation, and rely on full state tomography. Several key algorithmic issues\nlike observable readout, data encoding, and impractical circuit depth remain\nunsolved. As a result, these are not directly realizable on any quantum\nhardware. We present a series of novel algorithmic advances which allow us to\nimplement the QLBM algorithm, for the first time, on a quantum computer.\nHardware results for the time evolution of a 2D Gaussian initial density\ndistribution subject to a uniform advection-diffusion field are presented.\nFurthermore, 3D simulation results are presented for particular non-uniform\nadvection fields, devised so as to avoid the problem of diminishing probability\nof success due to repeated post-selection operations required for multiple\ntimesteps. We demonstrate the evolution of an initial quantum state governed by\nthe advection-diffusion equation, accounting for the iterative nature of the\nexplicit QLBM algorithm. A tensor network encoding scheme is used to represent\nthe initial condition supplied to the advection-diffusion equation,\nsignificantly reducing the two-qubit gate count affording a shorter circuit\ndepth. Further reductions are made in the collision and streaming operators.\nCollectively, these advances give a path to realizing more practical, 2D and 3D\nQLBM applications with non-trivial velocity fields on quantum hardware.","main_category":"quant-ph","categories":"quant-ph,physics.comp-ph","published":"2025-04-15T05:02:41Z"}
{"aid":"http://arxiv.org/abs/2504.10876v1","title":"Non-Minimal RT Coupling and its Impact on Inflationary Evolution in f(R,\n  T) Gravity","summary":"We examine inflationary models in the $f(R, T)$ gravity framework where we\nhave a conformal constant and an $RT$-mixing term apart from an R term. The\nRT-mixing term introduces non-minimal coupling between gravity and matter. We\nconsider the exponential SUSY potential $V(\\p)=M^4 \\lt(1-e^{-\\l \\p/\\mp}\\rt)$\nand a novel potential $V(\\p)=\\l \\mp^{4-2\\a} \\p^{2\\a} \\sin^2\\lt(\\frac{\\b\n\\mp^\\a}{\\p^\\a}\\rt)$. With the help of COBE normalization, we constrain values\nof different parameters and extract the field value at the time of Hubble\ncrossing. The end of inflation is marked by $\\tep(\\p_i)=1$ where $\\p_i$ is the\nfield value at the end of inflation. Equipped with these values, we then move\non to calculate values of spectral index $n_s$ and tensor-to-scalar ratio $r$.\nOur predicted values of $n_s$ and $r$ fall within their observed values from\nthe Planck 2018 survey and BICEP/Keck array measurement for both potential,\nmaking them plausible candidates for the inflationary model. We also display\nthe variation of the tensor-to-scalar ratio and spectral index with the\ncoefficient of RT-mixing term for fixed values of e-fold number. There, we find\nthe existence of two local maxima of $n_s$, which occur at a negative and a\npositive value of $\\x$, the coefficient of $RT$-mixing term. Our analysis finds\na significant impact of $\\x$ on values of observables","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-15T05:09:10Z"}
{"aid":"http://arxiv.org/abs/2504.10881v1","title":"A Nonparametric Bayesian Local-Global Model for Enhanced Adverse Event\n  Signal Detection in Spontaneous Reporting System Data","summary":"Spontaneous reporting system databases are key resources for post-marketing\nsurveillance, providing real-world evidence (RWE) on the adverse events (AEs)\nof regulated drugs or other medical products. Various statistical methods have\nbeen proposed for AE signal detection in these databases, flagging\ndrug-specific AEs with disproportionately high observed counts compared to\nexpected counts under independence. However, signal detection remains\nchallenging for rare AEs or newer drugs, which receive small observed and\nexpected counts and thus suffer from reduced statistical power. Principled\ninformation sharing on signal strengths across drugs/AEs is crucial in such\ncases to enhance signal detection. However, existing methods typically ignore\ncomplex between-drug associations on AE signal strengths, limiting their\nability to detect signals. We propose novel local-global mixture Dirichlet\nprocess (DP) prior-based nonparametric Bayesian models to capture these\nassociations, enabling principled information sharing between drugs while\nbalancing flexibility and shrinkage for each drug, thereby enhancing\nstatistical power. We develop efficient Markov chain Monte Carlo algorithms for\nimplementation and employ a false discovery rate (FDR)-controlled, false\nnegative rate (FNR)-optimized hypothesis testing framework for AE signal\ndetection. Extensive simulations demonstrate our methods' superior sensitivity\n-- often surpassing existing approaches by a twofold or greater margin -- while\nstrictly controlling the FDR. An application to FDA FAERS data on statin drugs\nfurther highlights our methods' effectiveness in real-world AE signal\ndetection. Software implementing our methods is provided as supplementary\nmaterial.","main_category":"stat.ME","categories":"stat.ME,stat.AP,stat.CO","published":"2025-04-15T05:22:01Z"}
{"aid":"http://arxiv.org/abs/2504.10929v1","title":"Cross-Frequency Implicit Neural Representation with Self-Evolving\n  Parameters","summary":"Implicit neural representation (INR) has emerged as a powerful paradigm for\nvisual data representation. However, classical INR methods represent data in\nthe original space mixed with different frequency components, and several\nfeature encoding parameters (e.g., the frequency parameter $\\omega$ or the rank\n$R$) need manual configurations. In this work, we propose a self-evolving\ncross-frequency INR using the Haar wavelet transform (termed CF-INR), which\ndecouples data into four frequency components and employs INRs in the wavelet\nspace. CF-INR allows the characterization of different frequency components\nseparately, thus enabling higher accuracy for data representation. To more\nprecisely characterize cross-frequency components, we propose a cross-frequency\ntensor decomposition paradigm for CF-INR with self-evolving parameters, which\nautomatically updates the rank parameter $R$ and the frequency parameter\n$\\omega$ for each frequency component through self-evolving optimization. This\nself-evolution paradigm eliminates the laborious manual tuning of these\nparameters, and learns a customized cross-frequency feature encoding\nconfiguration for each dataset. We evaluate CF-INR on a variety of visual data\nrepresentation and recovery tasks, including image regression, inpainting,\ndenoising, and cloud removal. Extensive experiments demonstrate that CF-INR\noutperforms state-of-the-art methods in each case.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T07:14:35Z"}
{"aid":"http://arxiv.org/abs/2504.10934v1","title":"Induced magnetic moment at two-dimensional MXene/ferromagnetic interface\n  evaluated by angle-dependent hard X-ray photoemission spectroscopy","summary":"Emergent ferromagnetism on the surface of recent two-dimensional (2D) MXene\nis investigated by X-ray magnetic circular dichroism (XMCD) and angle-dependent\nhard X-ray photoemission spectroscopy (HAXPES). Focusing on the Cr2N as one of\nthe 2D-MXenes, the bilayers of Cr2N/Co and Cr2N/Pt are prepared by magnetron\nsputtering technique. XMCD reveals the induced magnetic moment of Cr in the\nCr2N/Co interface, while it is not observed in the Cr2N/Pt interface at room\ntemperature. To distinguish the possible origins of either the interlayer\nmagnetic exchange coupling or the charge transfer at the interfaces, the\nadditional controlled Cr2N/Cu bilayer, whose work function of Cu is consistent\nwith Co, is prepared. HAXPES spectra for the Cr 2p core level near the\ninterface of Cr2N/Cu is consistent with that of Cr2N/Co, indicating that the\ninduced magnetic moment of Cr observed by XMCD for the Cr2N/Co can be\nattributed to the interlayer magnetic exchange coupling, rather than the charge\ntransfer, which is a specific characteristics emerged at the interface with\n2D-MXene.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-15T07:27:39Z"}
{"aid":"http://arxiv.org/abs/2504.10955v1","title":"Designing optimal subsidy schemes and recycling plans for sustainable\n  treatment of construction and demolition waste","summary":"More than 10 billion tons of construction and demolition waste (CW) are\ngenerated globally each year, exerting a significant impact on the environment.\nIn the CW recycling process, the government and the carrier are the two primary\nstakeholders. The carrier is responsible for transporting CW from production\nsites to backfill sites or processing facilities, with a primary focus on\ntransport efficiency and revenue. Meanwhile, the government aims to minimize\npollution from the recycling system, which is influenced by transport modes,\nshipment distances, and the processing methods used for CW. This paper develops\na bi-objective, bi-level optimization model to address these challenges. The\nupper-level model is a linear programming model that optimizes the government's\nsubsidy scheme, while the lower-level model is a minimum-cost flow model that\noptimizes the carrier's recycling plan. A hybrid heuristic solution method is\nproposed to tackle the problem's complexity. A case study in Chengdu, China,\ndemonstrates the computational efficiency of the model and its small solution\ngap. With an optimized subsidy scheme and recycling plan, pollution can be\nreduced by over 29.29% through a relatively small investment in subsidies.","main_category":"math.OC","categories":"math.OC","published":"2025-04-15T08:00:46Z"}
{"aid":"http://arxiv.org/abs/2504.10962v1","title":"$π$-MPPI: A Projection-based Model Predictive Path Integral Scheme for\n  Smooth Optimal Control of Fixed-Wing Aerial Vehicles","summary":"Model Predictive Path Integral (MPPI) is a popular sampling-based Model\nPredictive Control (MPC) algorithm for nonlinear systems. It optimizes\ntrajectories by sampling control sequences and averaging them. However, a key\nissue with MPPI is the non-smoothness of the optimal control sequence, leading\nto oscillations in systems like fixed-wing aerial vehicles (FWVs). Existing\nsolutions use post-hoc smoothing, which fails to bound control derivatives.\nThis paper introduces a new approach: we add a projection filter $\\pi$ to\nminimally correct control samples, ensuring bounds on control magnitude and\nhigher-order derivatives. The filtered samples are then averaged using MPPI,\nleading to our $\\pi$-MPPI approach. We minimize computational overhead by using\na neural accelerated custom optimizer for the projection filter. $\\pi$-MPPI\noffers a simple way to achieve arbitrary smoothness in control sequences. While\nwe focus on FWVs, this projection filter can be integrated into any MPPI\npipeline. Applied to FWVs, $\\pi$-MPPI is easier to tune than the baseline,\nresulting in smoother, more robust performance.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-15T08:11:02Z"}
{"aid":"http://arxiv.org/abs/2504.10964v1","title":"Distributed Optimization with Gradient Tracking over Heterogeneous\n  Delay-Prone Directed Networks","summary":"In this paper, we address the distributed optimization problem over\nunidirectional networks with possibly time-invariant heterogeneous bounded\ntransmission delays. In particular, we propose a modified version of the\nAccelerated Distributed Directed OPTimization (ADD-OPT) algorithm, herein\ncalled Robustified ADD-OPT (R-ADD-OPT), which is able to solve the distributed\noptimization problem, even when the communication links suffer from\nheterogeneous but bounded transmission delays. We show that if the gradient\nstep-size of the R-ADD-OPT algorithm is within a certain range, which also\ndepends on the maximum time delay in the network, then the nodes are guaranteed\nto converge to the optimal solution of the distributed optimization problem.\nThe range of the gradient step-size that guarantees convergence can be computed\na priori based on the maximum time delay in the network.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-15T08:14:30Z"}
{"aid":"http://arxiv.org/abs/2504.10971v1","title":"The Effectiveness of Business Process Visualisations: a Systematic\n  Literature Review","summary":"Business Process Visualisations (BPVs) have become indispensable tools for\norganisations seeking to enhance their operational efficiency, decision-making\ncapabilities, and overall performance. The burgeoning interest in process\nmodeling and tool development, coupled with the rise of data visualisation\nfield, underscores the significant role of visual tools in leveraging human\ncognition. Unlike traditional models, data visualisation approaches graphics\nfrom a novel angle, emphasising the potency of visual representations. This\nreview aims to integrate the domains of BPV and data visualisation to assess\ntheir combined influence on organisational effectiveness comprehensively.\nThrough a meticulous analysis of existing literature, this study aims to\namalgamate insights on BPVs impact from a data visualisation standpoint,\nadvocating for a design philosophy that prioritises user engagement to bolster\norganisational outcomes. Additionally, our systematic review has unveiled\npromising avenues for future research, identifying underexplored variables that\ninfluence the efficacy of BPVs, thereby charting a path for forthcoming\nscholarly inquiries.","main_category":"cs.HC","categories":"cs.HC,cs.GR","published":"2025-04-15T08:26:04Z"}
{"aid":"http://arxiv.org/abs/2504.10977v1","title":"Phonon-polaritons in Zn(1-x)MgxTe (x<0.09): A Raman scattering study","summary":"Phonon-polaritons (PP) are phonon-photon coupled modes. Using near-forward\nRaman scattering, the PP of the cubic Zn(1-x)MgxTe (x<0.09) semiconductor alloy\ncould be measured. While the PP-coupling hardly develops in pure ZnTe, minor\nMg-alloying suffices to stabilize a long-lifetime PP strongly bound to the\nlattice, i.e., with a pronounced phonon character, and yet a fast one\noriginating from the highly dispersive photon-like bottleneck of the\nPP-dispersion. By combining the advantages of a phonon and of a photon, the\nlong-lifetime PP generated by minor Mg-alloying of ZnTe marks an improvement\nover the PP of pristine ZnTe, that, from the Raman cross section calculation,\ncan only achieve a balanced compromise between the two kinds of advantages,\nintensity and speed. The discussion of the PP-related lattice dynamics of\nZn(1-x)MgxTe (x<0.09) is grounded in a preliminary study of the lattice macro-\nand microstructure using X-ray diffraction and solid-state nuclear magnetic\nresonance, respectively, and further relies on ab initio calculations of the\nnative phonon modes behind the PP in the Mg-dilute limit of Zn(1-x)MgxTe (x~0),\nconsidering various Mg-isotopes.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.other,J.2","published":"2025-04-15T08:38:23Z"}
{"aid":"http://arxiv.org/abs/2504.10999v1","title":"Splitting the Forward-Backward Algorithm: A Full Characterization","summary":"We study frugal splitting algorithms with minimal lifting for solving\nmonotone inclusion problems involving sums of maximal monotone and cocoercive\noperators. Building on a foundational result by Ryu, we fully characterize all\nmethods that use only individual resolvent evaluations, direct evaluations of\ncocoercive operators, and minimal memory resources while ensuring convergence\nvia averaged fixed-point iterations. We show that all such methods are captured\nby a unified framework, which includes known schemes and enables new ones with\npromising features. Systematic numerical experiments lead us to propose three\ndesign heuristics to achieve excellent performances in practice, yielding\nsignificant gains over existing methods.","main_category":"math.OC","categories":"math.OC","published":"2025-04-15T09:15:58Z"}
{"aid":"http://arxiv.org/abs/2504.11001v1","title":"ReZero: Enhancing LLM search ability by trying one-more-time","summary":"Retrieval-Augmented Generation (RAG) improves Large Language Model (LLM)\nperformance on knowledge-intensive tasks but depends heavily on initial search\nquery quality. Current methods, often using Reinforcement Learning (RL),\ntypically focus on query formulation or reasoning over results, without\nexplicitly encouraging persistence after a failed search. We introduce ReZero\n(Retry-Zero), a novel RL framework that directly rewards the act of retrying a\nsearch query following an initial unsuccessful attempt. This incentivizes the\nLLM to explore alternative queries rather than prematurely halting. ReZero\ndemonstrates significant improvement, achieving 46.88% accuracy compared to a\n25% baseline. By rewarding persistence, ReZero enhances LLM robustness in\ncomplex information-seeking scenarios where initial queries may prove\ninsufficient.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-15T09:18:21Z"}
{"aid":"http://arxiv.org/abs/2504.11019v1","title":"DRIFT open dataset: A drone-derived intelligence for traffic analysis in\n  urban environmen","summary":"Reliable traffic data are essential for understanding urban mobility and\ndeveloping effective traffic management strategies. This study introduces the\nDRone-derived Intelligence For Traffic analysis (DRIFT) dataset, a large-scale\nurban traffic dataset collected systematically from synchronized drone videos\nat approximately 250 meters altitude, covering nine interconnected\nintersections in Daejeon, South Korea. DRIFT provides high-resolution vehicle\ntrajectories that include directional information, processed through video\nsynchronization and orthomap alignment, resulting in a comprehensive dataset of\n81,699 vehicle trajectories. Through our DRIFT dataset, researchers can\nsimultaneously analyze traffic at multiple scales - from individual vehicle\nmaneuvers like lane-changes and safety metrics such as time-to-collision to\naggregate network flow dynamics across interconnected urban intersections. The\nDRIFT dataset is structured to enable immediate use without additional\npreprocessing, complemented by open-source models for object detection and\ntrajectory extraction, as well as associated analytical tools. DRIFT is\nexpected to significantly contribute to academic research and practical\napplications, such as traffic flow analysis and simulation studies. The dataset\nand related resources are publicly accessible at\nhttps://github.com/AIxMobility/The-DRIFT.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T09:43:13Z"}
{"aid":"http://arxiv.org/abs/2504.11039v1","title":"Modeling dislocations in quasicrystals through amplitude equations","summary":"Quasicrystals (QCs) are a class of aperiodic ordered structures that emerge\nin various systems, from metallic alloys to soft matter and driven\nnon-equilibrium systems. Within a mesoscale theory based on slowly-varying\ncomplex amplitudes for QCs, we track dislocations as topological defects\nharbored by the amplitudes and characterize their Burgers vectors and induced\ndeformations. We study the formation of dislocations at semicoherent\ninterfaces, particularly those emerging from rotated inclusions, and find a\nhierarchy of dislocations forming at such interfaces. We further analyze\ninterfaces in strained systems, revealing conditions for the emergence of\nperiodic dislocation arrays and discussing the energetics of dislocations\nassociated with different phonon and phason deformations. The stability,\ninteraction, and motion of dislocation dipoles and quadrupoles are also\ndiscussed. These findings provide new insights into the mesoscale modeling of\ndislocations in QCs and their distinct behavior compared to conventional\ncrystals, while demonstrating a versatile framework for studying dislocations\nin systems exhibiting quasicrystalline order.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall,cond-mat.soft","published":"2025-04-15T10:03:41Z"}
{"aid":"http://arxiv.org/abs/2504.11045v1","title":"Neural Control Barrier Functions from Physics Informed Neural Networks","summary":"As autonomous systems become increasingly prevalent in daily life, ensuring\ntheir safety is paramount. Control Barrier Functions (CBFs) have emerged as an\neffective tool for guaranteeing safety; however, manually designing them for\nspecific applications remains a significant challenge. With the advent of deep\nlearning techniques, recent research has explored synthesizing CBFs using\nneural networks-commonly referred to as neural CBFs. This paper introduces a\nnovel class of neural CBFs that leverages a physics-inspired neural network\nframework by incorporating Zubov's Partial Differential Equation (PDE) within\nthe context of safety. This approach provides a scalable methodology for\nsynthesizing neural CBFs applicable to high-dimensional systems. Furthermore,\nby utilizing reciprocal CBFs instead of zeroing CBFs, the proposed framework\nallows for the specification of flexible, user-defined safe regions. To\nvalidate the effectiveness of the approach, we present case studies on three\ndifferent systems: an inverted pendulum, autonomous ground navigation, and\naerial navigation in obstacle-laden environments.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.SY,eess.SY","published":"2025-04-15T10:13:30Z"}
{"aid":"http://arxiv.org/abs/2504.11053v1","title":"QualiTagger: Automating software quality detection in issue trackers","summary":"A systems quality is a major concern for development teams when it evolve.\nUnderstanding the effects of a loss of quality in the codebase is crucial to\navoid side effects like the appearance of technical debt. Although the\nidentification of these qualities in software requirements described in natural\nlanguage has been investigated, most of the results are often not applicable in\npractice, and rely on having been validated on small datasets and limited\namount of projects. For many years, machine learning (ML) techniques have been\nproved as a valid technique to identify and tag terms described in natural\nlanguage. In order to advance previous works, in this research we use cutting\nedge models like Transformers, together with a vast dataset mined and curated\nfrom GitHub, to identify what text is usually associated with different quality\nproperties. We also study the distribution of such qualities in issue trackers\nfrom openly accessible software repositories, and we evaluate our approach both\nwith students from a software engineering course and with its application to\nrecognize security labels in industry.","main_category":"cs.SE","categories":"cs.SE,cs.LG","published":"2025-04-15T10:40:40Z"}
{"aid":"http://arxiv.org/abs/2504.11089v1","title":"InfoClus: Informative Clustering of High-dimensional Data Embeddings","summary":"Developing an understanding of high-dimensional data can be facilitated by\nvisualizing that data using dimensionality reduction. However, the\nlow-dimensional embeddings are often difficult to interpret. To facilitate the\nexploration and interpretation of low-dimensional embeddings, we introduce a\nnew concept named partitioning with explanations. The idea is to partition the\ndata shown through the embedding into groups, each of which is given a sparse\nexplanation using the original high-dimensional attributes. We introduce an\nobjective function that quantifies how much we can learn through observing the\nexplanations of the data partitioning, using information theory, and also how\ncomplex the explanations are. Through parameterization of the complexity, we\ncan tune the solutions towards the desired granularity. We propose InfoClus,\nwhich optimizes the partitioning and explanations jointly, through greedy\nsearch constrained over a hierarchical clustering. We conduct a qualitative and\nquantitative analysis of InfoClus on three data sets. We contrast the results\non the Cytometry data with published manual analysis results, and compare with\ntwo other recent methods for explaining embeddings (RVX and VERA). These\ncomparisons highlight that InfoClus has distinct advantages over existing\nprocedures and methods. We find that InfoClus can automatically create good\nstarting points for the analysis of dimensionality-reduction-based scatter\nplots.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-15T11:34:03Z"}
{"aid":"http://arxiv.org/abs/2504.11131v1","title":"A Fully Asynchronous Unsourced Random Access Scheme","summary":"We investigate fully asynchronous unsourced random access (URA), and propose\na high-performing scheme that employs on-off division multiple access (ODMA).\nIn this scheme, active users distribute their data over the transmit block\nbased on a sparse transmission pattern without any limitations on the starting\ntime. At the receiver side, we adopt a double sliding-window decoding approach,\nutilizing a smaller inner decoding window of two block lengths within a larger\nouter window to enhance the interference cancellation process. Within the inner\nwindow, the receiver iteratively applies preamble-free joint starting time and\npattern detection, single-user decoding, and successive interference\ncancellation operations. A notable feature of the proposed scheme is its\nelimination of the need for a preamble for starting time detection; this is\nachieved using ODMA transmission patterns. Numerical results demonstrate that\nthe proposed asynchronous URA scheme outperforms existing alternatives.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-15T12:31:24Z"}
{"aid":"http://arxiv.org/abs/2504.11141v1","title":"A definition of the background state of the atmosphere using optimal\n  transport","summary":"The dynamics of atmospheric disturbances are often described in terms of\ndisplacements of air parcels relative to their locations in a notional\nbackground state. Modified Lagrangian Mean (MLM) states have been proposed by\nM. E. McIntyre using the Lagrangian conserved variables potential vorticity and\npotential temperature to label air parcels, thus avoiding the need to calculate\ntrajectories explicitly. Methven and Berrisford further defined a zonally\nsymmetric MLM state for global atmospheric flow in terms of mass in zonal\nangular momentum ($z$) and potential temperature ($\\theta$) coordinates. We\nprove that for any snapshot of an atmospheric flow in a single hemisphere,\nthere exists a unique energy-minimising MLM state in geophysical coordinates\n(latitude and pressure). Since the state is an energy minimum, it is suitable\nfor quantification of finite amplitude disturbances and examining atmospheric\ninstability. This state is obtained by solving a free surface problem, which we\nframe as the minimisation of an optimal transport cost over a class of source\nmeasures. The solution consists of a source measure, encoding surface pressure,\nand an optimal transport map, connecting the distribution of mass in\ngeophysical coordinates to the known distribution of mass in $(z, \\theta)$. We\nshow that this problem reduces to an optimal transport problem with a known\nsource measure, which has a numerically feasible discretisation. Additionally,\nour results hold for a large class of cost functions, and generalise analogous\nresults on free surface variants of the semi-geostrophic equations.","main_category":"math.OC","categories":"math.OC","published":"2025-04-15T12:42:42Z"}
{"aid":"http://arxiv.org/abs/2504.11145v1","title":"Nonreciprocal Spin-Wave Propagation in Anisotropy-Graded Iron Films\n  Prepared by Nitrogen Implantation","summary":"Gradual modification of the magnetic properties in ferromagnetic films has\nrecently been proposed as an effective method to channel and control spin waves\nfor the development of new functionalities in magnonic devices. Here, we\ninvestigate graded FeN films prepared by low-dose nitrogen implantation of Fe\nepitaxial thin films. Combining Brillouin light scattering measurements and a\nspin-wave theoretical approach, we show that nitrogen implantation induces a\ngraded profile of both the in-plane and the perpendicular anisotropies along\nthe film thickness. This graduation leads to a significant modification of the\nspin-wave spatial localization and generates a marked frequency asymmetry in\nthe spin-wave dispersion. Moreover, we find that the anisotropy profile, and as\na consequence the dispersion relation, can be tuned on changing the\nimplantation dose, opening a way for the potential use of the graded Fe-N films\nin magnonic applications.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci,cond-mat.soft","published":"2025-04-15T12:45:28Z"}
{"aid":"http://arxiv.org/abs/2504.11179v1","title":"Semistable reduction of plane quartics at $p=3$","summary":"We explain how to compute the semistable reduction of plane quartic curves\nover local fields of residue characteristic $p=3$. Our approach is based on\nfinding suitable degree-$3$ coverings of the projective line by such plane\nquartics and on the different function of Cohen, Temkin, and Trushin associated\nto the analytifications of these coverings. In particular, we give an explicit\nformula for computing the different function on a given interval. The resulting\nalgorithm for computing the semistable reduction of plane quartics is\nimplemented in SageMath, and we illustrate it by determining the semistable\nreduction of a particular plane quartic at $p=3$ that arises as a quotient of\nthe non-split Cartan modular curve $X^+_{ns}(27)$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-15T13:33:52Z"}
{"aid":"http://arxiv.org/abs/2504.11183v1","title":"Bias Beyond English: Evaluating Social Bias and Debiasing Methods in a\n  Low-Resource Setting","summary":"Social bias in language models can potentially exacerbate social\ninequalities. Despite it having garnered wide attention, most research focuses\non English data. In a low-resource scenario, the models often perform worse due\nto insufficient training data. This study aims to leverage high-resource\nlanguage corpora to evaluate bias and experiment with debiasing methods in\nlow-resource languages. We evaluated the performance of recent multilingual\nmodels in five languages: English (\\textsc{eng}), Chinese (\\textsc{zho}),\nRussian (\\textsc{rus}), Indonesian (\\textsc{ind}) and Thai (\\textsc{tha}), and\nanalyzed four bias dimensions: \\textit{gender}, \\textit{religion},\n\\textit{nationality}, and \\textit{race-color}. By constructing multilingual\nbias evaluation datasets, this study allows fair comparisons between models\nacross languages. We have further investigated three debiasing\nmethods-\\texttt{CDA}, \\texttt{Dropout}, \\texttt{SenDeb}-and demonstrated that\ndebiasing methods from high-resource languages can be effectively transferred\nto low-resource ones, providing actionable insights for fairness research in\nmultilingual NLP.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-15T13:40:22Z"}
{"aid":"http://arxiv.org/abs/2504.11187v1","title":"A Spatial-Sign based Direct Approach for High Dimensional Sparse\n  Quadratic Discriminant Analysis","summary":"In this paper, we study the problem of high-dimensional sparse quadratic\ndiscriminant analysis (QDA). We propose a novel classification method, termed\nSSQDA, which is constructed via constrained convex optimization based on the\nsample spatial median and spatial sign covariance matrix under the assumption\nof an elliptically symmetric distribution. The proposed classifier is shown to\nachieve the optimal convergence rate over a broad class of parameter spaces, up\nto a logarithmic factor. Extensive simulation studies and real data\napplications demonstrate that SSQDA is both robust and efficient, particularly\nin the presence of heavy-tailed distributions, highlighting its practical\nadvantages in high-dimensional classification tasks.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-15T13:42:41Z"}
{"aid":"http://arxiv.org/abs/2504.11203v1","title":"Braiding vineyards","summary":"Vineyards are a common way to study persistence diagrams of a data set which\nis changing, as strong stability means that it is possible to pair points in\n``nearby'' persistence diagrams, yielding a family of point sets which connect\ninto curves when stacked. Recent work has also studied monodromy in the\npersistent homology transform, demonstrating some interesting connections\nbetween an input shape and monodromy in the persistent homology transform for\n0-dimensional homology embedded in $\\mathbb{R}^2$. In this work, we\nre-characterize monodromy in terms of periodicity of the associated vineyard of\npersistence diagrams.\n  We construct a family of objects in any dimension which have non-trivial\nmonodromy for $l$-persistence of any periodicity and for any $l$. More\ngenerally we prove that any knot or link can appear as a vineyard for a shape\nin $\\mathbb{R}^d$, with $d\\geq 3$. This shows an intriguing and, to the best of\nour knowledge, previously unknown connection between knots and persistence\nvineyards. In particular this shows that vineyards are topologically as rich as\none could possibly hope.","main_category":"cs.CG","categories":"cs.CG,math.AT,math.GT,I.3.5","published":"2025-04-15T14:02:59Z"}
{"aid":"http://arxiv.org/abs/2504.11240v1","title":"A deep dive into the interplay of structured quantum peaked circuits and\n  infinite temperature correlation functions","summary":"Random quantum circuits have been extensively explored for quantum supremacy\ndemonstrations. However, verifying their output distributions remains\nchallenging. Here, we propose the infinite-temperature correlation function\n(ITCF) as a physically meaningful observable for noisy intermediate-scale\nquantum (NISQ) devices one that can be extracted using engineered circuits\nrather than relying on fully random constructions. This is realized by\nleveraging peaked quantum states whose probability distributions are sharply\npeaked at specific outcomes due to constructive interference thus offering more\nefficient verifiability and stronger signal observability. Rather than using\nHaar-random states, which often yield vanishing signals through destructive\ninterference, we construct purposefully biased quantum states using either\nGrover-based amplitude amplification or shallow structured circuits. These\nengineered states amplify contributions from relevant operator subspaces,\nenabling robust detection of non-zero ITCF values that would otherwise be\nsuppressed under random-state sampling. Our results highlight a\nproblem-specific state preparation framework that mitigates signal loss from\nrandom averaging and facilitates the detection of physically meaningful\nobservables in NISQ devices. We also discuss future extensions to multi-qubit\nobservables, scrambling diagnostics, and variational circuit optimization,\nunderscoring the broader potential of Peaked States for quantum simulation and\nverification.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T14:41:36Z"}
{"aid":"http://arxiv.org/abs/2504.11253v1","title":"Large deformations of Tr($Φ^3$) and the world at infinity","summary":"The amplitudes of the non-linear sigma model can be obtained from those of\nTr($\\Phi^3$) theory by sending the kinematic (Mandelstam) variables to infinity\nin a certain direction. In this paper we characterize the behavior of\nTr($\\Phi^3$) amplitudes under a general class of large kinematic shifts called\n$g$-vector shifts. The objects that live in this world at infinity retain\ncertain key amplitude-like properties, most notably factorization, and admit\ndescriptions in terms of polytopes, but they are not generally amplitudes of\nany cognizable theory. We identify particular $g$-vector shifts that lead at\ninfinity to mixed amplitudes involving two pions and any number of scalars,\nallowing us to provide polytopal descriptions of these amplitudes.","main_category":"hep-th","categories":"hep-th","published":"2025-04-15T14:48:15Z"}
{"aid":"http://arxiv.org/abs/2504.11264v1","title":"DeepSelective: Feature Gating and Representation Matching for\n  Interpretable Clinical Prediction","summary":"The rapid accumulation of Electronic Health Records (EHRs) has transformed\nhealthcare by providing valuable data that enhance clinical predictions and\ndiagnoses. While conventional machine learning models have proven effective,\nthey often lack robust representation learning and depend heavily on\nexpert-crafted features. Although deep learning offers powerful solutions, it\nis often criticized for its lack of interpretability. To address these\nchallenges, we propose DeepSelective, a novel end to end deep learning\nframework for predicting patient prognosis using EHR data, with a strong\nemphasis on enhancing model interpretability. DeepSelective combines data\ncompression techniques with an innovative feature selection approach,\nintegrating custom-designed modules that work together to improve both accuracy\nand interpretability. Our experiments demonstrate that DeepSelective not only\nenhances predictive accuracy but also significantly improves interpretability,\nmaking it a valuable tool for clinical decision-making. The source code is\nfreely available at http://www.healthinformaticslab.org/supp/resources.php .","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-15T15:04:39Z"}
{"aid":"http://arxiv.org/abs/2504.11335v1","title":"Code Reborn AI-Driven Legacy Systems Modernization from COBOL to Java","summary":"This study investigates AI-driven modernization of legacy COBOL code into\nJava, addressing a critical challenge in aging software systems. Leveraging the\nLegacy COBOL 2024 Corpus -- 50,000 COBOL files from public and enterprise\nsources -- Java parses the code, AI suggests upgrades, and React visualizes\ngains. Achieving 93% accuracy, complexity drops 35% (from 18 to 11.7) and\ncoupling 33% (from 8 to 5.4), surpassing manual efforts (75%) and rule-based\ntools (82%). The approach offers a scalable path to rejuvenate COBOL systems,\nvital for industries like banking and insurance.","main_category":"cs.SE","categories":"cs.SE,cs.AI,cs.LG","published":"2025-04-15T16:07:54Z"}
{"aid":"http://arxiv.org/abs/2504.11337v1","title":"REWARD CONSISTENCY: Improving Multi-Objective Alignment from a\n  Data-Centric Perspective","summary":"Multi-objective preference alignment in language models often encounters a\nchallenging trade-off: optimizing for one human preference (e.g., helpfulness)\nfrequently compromises others (e.g., harmlessness) due to the inherent\nconflicts between competing objectives. While prior work mainly focuses on\nalgorithmic solutions, we explore a novel data-driven approach to uncover the\ntypes of data that can effectively mitigate these conflicts. Specifically, we\npropose the concept of Reward Consistency (RC), which identifies samples that\nalign with multiple preference objectives, thereby reducing conflicts during\ntraining. Through gradient-based analysis, we demonstrate that RC-compliant\nsamples inherently constrain performance degradation during multi-objective\noptimization. Building on these insights, we further develop Reward Consistency\nSampling, a framework that automatically constructs preference datasets that\neffectively mitigate conflicts during multi-objective alignment. Our generated\ndata achieves an average improvement of 13.37% in both the harmless rate and\nhelpfulness win rate when optimizing harmlessness and helpfulness, and can\nconsistently resolve conflicts in varying multi-objective scenarios.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-15T16:09:19Z"}
{"aid":"http://arxiv.org/abs/2504.11342v1","title":"Williams' conjecture holds for graphs of Gelfand-Kirillov dimension\n  three","summary":"A graph of Gelfand-Kirillov dimension three is a connected finite essential\ngraph such that its Leavitt path algebra has Gelfand-Kirillov dimension three.\nWe provide number-theoretic criteria for graphs of Gelfand-Kirillov dimension\nthree to be strong shift equivalent. We then prove that two graphs of\nGelfand-Kirillov dimension three are shift equivalent if and only if they are\nstrongly shift equivalent, if and only if their corresponding Leavitt path\nalgebras are graded Morita equivalent, if and only if their graded\n$K$-theories, $K^{\\text{gr}}_0$, are order-preserving $\\mathbb{Z}[x,\nx^{-1}]$-module isomorphic. As a consequence, we obtain that the Leavitt path\nalgebras of graphs of Gelfand-Kirillov dimension three are graded Morita\nequivalent if and only if their graph $C^*$-algebras are equivariant Morita\nequivalent, and two graphs $E$ and $F$ of Gelfand-Kirillov dimension three are\nshift equivalent if and only if the singularity categories\n$\\text{D}_{\\text{sg}}(KE/J_E^2)$ and $\\text{D}_{\\text{sg}}(KF/J_F^2)$ are\ntriangulated equivalent.","main_category":"math.RA","categories":"math.RA,math.DS,math.OA","published":"2025-04-15T16:14:00Z"}
{"aid":"http://arxiv.org/abs/2504.11345v1","title":"Erzeugunsgrad, VC-Dimension and Neural Networks with rational activation\n  function","summary":"The notion of Erzeugungsgrad was introduced by Joos Heintz in 1983 to bound\nthe number of non-empty cells occurring after a process of quantifier\nelimination. We extend this notion and the combinatorial bounds of Theorem 2 in\nHeintz (1983) using the degree for constructible sets defined in\nPardo-Sebasti\\'an (2022). We show that the Erzeugungsgrad is the key ingredient\nto connect affine Intersection Theory over algebraically closed fields and the\nVC-Theory of Computational Learning Theory for families of classifiers given by\nparameterized families of constructible sets. In particular, we prove that the\nVC-dimension and the Krull dimension are linearly related up to logarithmic\nfactors based on Intersection Theory. Using this relation, we study the density\nof correct test sequences in evasive varieties. We apply these ideas to analyze\nparameterized families of neural networks with rational activation function.","main_category":"cs.LG","categories":"cs.LG,math.AG","published":"2025-04-15T16:16:38Z"}
{"aid":"http://arxiv.org/abs/2504.11346v1","title":"Seedream 3.0 Technical Report","summary":"We present Seedream 3.0, a high-performance Chinese-English bilingual image\ngeneration foundation model. We develop several technical improvements to\naddress existing challenges in Seedream 2.0, including alignment with\ncomplicated prompts, fine-grained typography generation, suboptimal visual\naesthetics and fidelity, and limited image resolutions. Specifically, the\nadvancements of Seedream 3.0 stem from improvements across the entire pipeline,\nfrom data construction to model deployment. At the data stratum, we double the\ndataset using a defect-aware training paradigm and a dual-axis collaborative\ndata-sampling framework. Furthermore, we adopt several effective techniques\nsuch as mixed-resolution training, cross-modality RoPE, representation\nalignment loss, and resolution-aware timestep sampling in the pre-training\nphase. During the post-training stage, we utilize diversified aesthetic\ncaptions in SFT, and a VLM-based reward model with scaling, thereby achieving\noutputs that well align with human preferences. Furthermore, Seedream 3.0\npioneers a novel acceleration paradigm. By employing consistent noise\nexpectation and importance-aware timestep sampling, we achieve a 4 to 8 times\nspeedup while maintaining image quality. Seedream 3.0 demonstrates significant\nimprovements over Seedream 2.0: it enhances overall capabilities, in particular\nfor text-rendering in complicated Chinese characters which is important to\nprofessional typography generation. In addition, it provides native\nhigh-resolution output (up to 2K), allowing it to generate images with high\nvisual quality.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T16:19:07Z"}
{"aid":"http://arxiv.org/abs/2504.11350v1","title":"Adaptive Compressible Smoothed Particle Hydrodynamics","summary":"Modulating the number of particles in a region is key to accurately capturing\nthe nuances in compressible flows with Smoothed Particle Hydrodynamics (SPH).\nThis paper details the implementation of a volume-based adaptive refinement and\nderefinement procedure, incorporating state-of-the-art features such as\nautomatic local adaptivity and solution adaptivity. A shock-aware particle\nshifting procedure is introduced to regularize the particle distribution while\npreserving the integrity of shocks. To our knowledge, this is the first\ndemonstration of shock-based solution adaptivity and shock-aware particle\nshifting in the literature. A wide variety of test problems, which involve flow\nin and around boundaries, are employed to highlight the utility of these\nadaptivity features in improving the results and in making simulations faster.\nFor instance, the adaptive resolution procedure is shown to deliver an order of\nmagnitude speedup. We also demonstrate the effectiveness of the adaptivity\nprocedure in resolving existing issues like errors due to interaction with\ndifferently spaced ghost particles at boundaries, formation of spot-like\nstructures due to particle clumping, and poorly resolved low-density regions.\nIn essence, the adaptivity technique presented in this paper is positioned as a\npowerful tool for simulating compressible flows with enhanced accuracy and\nefficiency.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,physics.comp-ph","published":"2025-04-15T16:22:01Z"}
{"aid":"http://arxiv.org/abs/2504.11364v1","title":"Teaching Large Language Models to Reason through Learning and Forgetting","summary":"Leveraging inference-time search in large language models has proven\neffective in further enhancing a trained model's capability to solve complex\nmathematical and reasoning problems. However, this approach significantly\nincreases computational costs and inference time, as the model must generate\nand evaluate multiple candidate solutions to identify a viable reasoning path.\nTo address this, we propose an effective approach that integrates search\ncapabilities directly into the model by fine-tuning it using both successful\n(learning) and failed reasoning paths (forgetting) derived from diverse search\nmethods. While fine-tuning the model with these data might seem\nstraightforward, we identify a critical issue: the model's search capability\ntends to degrade rapidly if fine-tuning is performed naively. We show that this\ndegradation can be substantially mitigated by employing a smaller learning\nrate. Extensive experiments on the challenging Game-of-24 and Countdown\nmathematical reasoning benchmarks show that our approach not only outperforms\nboth standard fine-tuning and inference-time search baselines but also\nsignificantly reduces inference time by 180$\\times$.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-15T16:30:02Z"}
{"aid":"http://arxiv.org/abs/2504.11368v1","title":"From Gaze to Insight: Bridging Human Visual Attention and Vision\n  Language Model Explanation for Weakly-Supervised Medical Image Segmentation","summary":"Medical image segmentation remains challenging due to the high cost of\npixel-level annotations for training. In the context of weak supervision,\nclinician gaze data captures regions of diagnostic interest; however, its\nsparsity limits its use for segmentation. In contrast, vision-language models\n(VLMs) provide semantic context through textual descriptions but lack the\nexplanation precision required. Recognizing that neither source alone suffices,\nwe propose a teacher-student framework that integrates both gaze and language\nsupervision, leveraging their complementary strengths. Our key insight is that\ngaze data indicates where clinicians focus during diagnosis, while VLMs explain\nwhy those regions are significant. To implement this, the teacher model first\nlearns from gaze points enhanced by VLM-generated descriptions of lesion\nmorphology, establishing a foundation for guiding the student model. The\nteacher then directs the student through three strategies: (1) Multi-scale\nfeature alignment to fuse visual cues with textual semantics; (2)\nConfidence-weighted consistency constraints to focus on reliable predictions;\n(3) Adaptive masking to limit error propagation in uncertain areas. Experiments\non the Kvasir-SEG, NCI-ISBI, and ISIC datasets show that our method achieves\nDice scores of 80.78%, 80.53%, and 84.22%, respectively-improving 3-5% over\ngaze baselines without increasing the annotation burden. By preserving\ncorrelations among predictions, gaze data, and lesion descriptions, our\nframework also maintains clinical interpretability. This work illustrates how\nintegrating human visual attention with AI-generated semantic context can\neffectively overcome the limitations of individual weak supervision signals,\nthereby advancing the development of deployable, annotation-efficient medical\nAI systems. Code is available at: https://github.com/jingkunchen/FGI.git.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T16:32:15Z"}
{"aid":"http://arxiv.org/abs/2504.11376v1","title":"A Multi-Stage Potts Machine based on Coupled CMOS Ring Oscillators","summary":"This work presents a multi-stage coupled ring oscillator\n  based Potts machine, designed with phase-shifted Sub\nHarmonic-Injection-Locking (SHIL) to represent multi valued Potts spins at\ndifferent solution stages with os cillator phases. The proposed Potts machine\nis able to\n  solve a certain class of combinatorial optimization prob lems that natively\nrequire multivalued spins with a divide and-conquer approach, facilitated\nthrough the alternating\n  phase-shifted SHILs acting on the oscillators. The pro posed architecture\neliminates the need for any external in termediary mappings or usage of\nexternal memory, as the\n  influence of SHIL allows oscillators to act as both mem ory and computation\nunits. Planar 4-coloring problems\n  of sizes up to 2116 nodes are mapped to the proposed\n  architecture. Simulations demonstrate that the proposed\n  Potts machine provides exact solutions for smaller prob lems (e.g. 49 nodes)\nand generates solutions reaching up\n  to 97% accuracy for larger problems (e.g. 2116 nodes).","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-15T16:47:34Z"}
{"aid":"http://arxiv.org/abs/2504.11383v1","title":"Accelerating Multiscale Modeling with Hybrid Solvers: Coupling FEM and\n  Neural Operators with Domain Decomposition","summary":"Numerical solvers for partial differential equations (PDEs) face challenges\nbalancing computational cost and accuracy, especially in multiscale and dynamic\nsystems. Neural operators can significantly speed up simulations; however, they\noften face challenges such as error accumulation and limited generalization in\nmultiphysics problems. This work introduces a novel hybrid framework that\nintegrates physics-informed DeepONet with FEM through domain decomposition. The\ncore innovation lies in adaptively coupling FEM and DeepONet subdomains via a\nSchwarz alternating method. This methodology strategically allocates\ncomputationally demanding regions to a pre-trained Deep Operator Network, while\nthe remaining computational domain is solved through FEM. To address dynamic\nsystems, we integrate the Newmark time-stepping scheme directly into the\nDeepONet, significantly mitigating error accumulation in long-term simulations.\nFurthermore, an adaptive subdomain evolution enables the ML-resolved region to\nexpand dynamically, capturing emerging fine-scale features without remeshing.\nThe framework's efficacy has been validated across a range of solid mechanics\nproblems, including static, quasi-static, and dynamic regimes, demonstrating\naccelerated convergence rates (up to 20% improvement compared to FE-FE\napproaches), while preserving solution fidelity with error < 1%. Our case\nstudies show that our proposed hybrid solver: (1) maintains solution continuity\nacross subdomain interfaces, (2) reduces computational costs by eliminating\nfine mesh requirements, (3) mitigates error accumulation in time-dependent\nsimulations, and (4) enables automatic adaptation to evolving physical\nphenomena. This work bridges the gap between numerical methods and AI-driven\nsurrogates, offering a scalable pathway for high-fidelity simulations in\nengineering and scientific applications.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-15T16:54:04Z"}
{"aid":"http://arxiv.org/abs/2504.11401v1","title":"Advances in Prebiotic Chemistry: the potential of Analog Computing and\n  Navier-Stokes Nernst-Planck (NPNS) Modeling in Organic Electronics\n  Technologies (OECTs)","summary":"In this article, we attempt to make a conceptual bridge between the research\nin biology, pre-biotic chemistry, biomimetics, and the tools used in organic\nbioelectronics in terms of materials and devices. The goal is discussing how\nmaterials and devices of organic bioelectronics can be exploited and used at\nthe interface with biology, but also how, and at what extent, they can be\nadapted to mimicking nature-inspired properties, herein including\nunconventional computing strategies. The idea is to provide new hints and solid\nhypotheses for designing niche experiments that could benefit from a proper\ninteraction, even at a basic communicative level, between materials science and\nbiotechnology. The finale long-term vision goal being the vision of collecting\nexperimental data that may help to made a step forward toward the\nimplementation of the transition from inanimate objects to animated beings. The\nmathematical model canonically considered in this work is the\nNavier-Stokes-Nernst-Planck (NPNS) Model which is often used to model a charged\ncontinuum system such as the organic electrochemical transistors.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,physics.chem-ph","published":"2025-04-15T17:17:45Z"}
{"aid":"http://arxiv.org/abs/2504.11403v1","title":"Counting irreducible representations of general linear groups and\n  unitary groups","summary":"Let $G$ be a general linear group over $\\BR$, $\\BC$, or $\\BH$, or a real\nunitary group. In this paper, we precisely describe the number of isomorphism\nclasses of irreducible Casselman-Wallach representations of $G$ with a given\ninfinitesimal character and a given associated variety, expressed in terms of\ncertain combinatorial data called painted Young diagrams and assigned Young\ndiagrams.","main_category":"math.RT","categories":"math.RT","published":"2025-04-15T17:18:20Z"}
{"aid":"http://arxiv.org/abs/2504.11415v1","title":"Robustness and sex differences in skin cancer detection: logistic\n  regression vs CNNs","summary":"Deep learning has been reported to achieve high performances in the detection\nof skin cancer, yet many challenges regarding the reproducibility of results\nand biases remain. This study is a replication (different data, same analysis)\nof a study on Alzheimer's disease [28] which studied robustness of logistic\nregression (LR) and convolutional neural networks (CNN) across patient sexes.\nWe explore sex bias in skin cancer detection, using the PAD-UFES-20 dataset\nwith LR trained on handcrafted features reflecting dermatological guidelines\n(ABCDE and the 7-point checklist), and a pre-trained ResNet-50 model. We\nevaluate these models in alignment with [28]: across multiple training datasets\nwith varied sex composition to determine their robustness. Our results show\nthat both the LR and the CNN were robust to the sex distributions, but the\nresults also revealed that the CNN had a significantly higher accuracy (ACC)\nand area under the receiver operating characteristics (AUROC) for male patients\nthan for female patients. We hope these findings to contribute to the growing\nfield of investigating potential bias in popular medical machine learning\nmethods. The data and relevant scripts to reproduce our results can be found in\nour Github.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-15T17:31:46Z"}
{"aid":"http://arxiv.org/abs/2504.11416v1","title":"Deep Learning-based Bathymetry Retrieval without In-situ Depths using\n  Remote Sensing Imagery and SfM-MVS DSMs with Data Gaps","summary":"Accurate, detailed, and high-frequent bathymetry is crucial for shallow\nseabed areas facing intense climatological and anthropogenic pressures. Current\nmethods utilizing airborne or satellite optical imagery to derive bathymetry\nprimarily rely on either SfM-MVS with refraction correction or Spectrally\nDerived Bathymetry (SDB). However, SDB methods often require extensive manual\nfieldwork or costly reference data, while SfM-MVS approaches face challenges\neven after refraction correction. These include depth data gaps and noise in\nenvironments with homogeneous visual textures, which hinder the creation of\naccurate and complete Digital Surface Models (DSMs) of the seabed. To address\nthese challenges, this work introduces a methodology that combines the\nhigh-fidelity 3D reconstruction capabilities of the SfM-MVS methods with\nstate-of-the-art refraction correction techniques, along with the spectral\nanalysis capabilities of a new deep learning-based method for bathymetry\nprediction. This integration enables a synergistic approach where SfM-MVS\nderived DSMs with data gaps are used as training data to generate complete\nbathymetric maps. In this context, we propose Swin-BathyUNet that combines\nU-Net with Swin Transformer self-attention layers and a cross-attention\nmechanism, specifically tailored for SDB. Swin-BathyUNet is designed to improve\nbathymetric accuracy by capturing long-range spatial relationships and can also\nfunction as a standalone solution for standard SDB with various training depth\ndata, independent of the SfM-MVS output. Experimental results in two completely\ndifferent test sites in the Mediterranean and Baltic Seas demonstrate the\neffectiveness of the proposed approach through extensive experiments that\ndemonstrate improvements in bathymetric accuracy, detail, coverage, and noise\nreduction in the predicted DSM. The code is available at\nhttps://github.com/pagraf/Swin-BathyUNet.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-15T17:31:48Z"}
{"aid":"http://arxiv.org/abs/2504.11435v1","title":"Robust Containment Queries over Collections of Trimmed NURBS Surfaces\n  via Generalized Winding Numbers","summary":"Efficient and accurate evaluation of containment queries for regions bound by\ntrimmed NURBS surfaces is important in many graphics and engineering\napplications. However, the algebraic complexity of surface-surface\nintersections makes gaps and overlaps between surfaces difficult to avoid for\nin-the-wild surface models. By considering this problem through the lens of the\ngeneralized winding number (GWN), a mathematical construction that is\nindifferent to the arrangement of surfaces in the shape, we can define a\ncontainment query that is robust to model watertightness. Applying contemporary\ntechniques for the 3D GWN on arbitrary curved surfaces would require some form\nof geometric discretization, potentially inducing containment\nmisclassifications near boundary components. In contrast, our proposed method\ncomputes an accurate GWN directly on the curved geometry of the input model. We\naccomplish this using a novel reformulation of the relevant surface integral\nusing Stokes' theorem, which in turn permits an efficient adaptive quadrature\ncalculation on the boundary and trimming curves of the model. While this is\nsufficient for \"far-field\" query points that are distant from the surface, we\naugment this approach for \"near-field\" query points (i.e., within a bounding\nbox) and even those coincident to the surface patches via a strategy that\ndirectly identifies and accounts for the jump discontinuity in the scalar\nfield. We demonstrate that our method of evaluating the GWN field is robust to\ncomplex trimming geometry in a CAD model, and is accurate up to arbitrary\nprecision at arbitrary distances from the surface. Furthermore, the derived\ncontainment query is robust to non-watertightness while respecting all curved\nfeatures of the input shape.","main_category":"cs.GR","categories":"cs.GR,cs.CG,cs.NA,math.NA,I.3.5","published":"2025-04-15T17:51:39Z"}
{"aid":"http://arxiv.org/abs/2504.11778v1","title":"Spectroscopic evidence for possible quantum spin liquid behavior in a\n  two-dimensional Mott insulator","summary":"Mott insulators with localized magnetic moments will exhibit a quantum spin\nliquid (QSL) state when the quantum fluctuations are strong enough to suppress\nthe ordering of the spins. Such an entangled state will give rise to collective\nexcitations, in which spin and charge information are carried separately. Our\nangle-resolved photoemission spectroscopy (ARPES) measurements on single-layer\n1T-TaS2 show a flat band around the zone center and a gap opening of about 200\nmeV in the low temperature, indicating 2D Mott insulating nature in the system.\nThis flat band is dispersionless in momentum space but shows anomalously broad\nwidth around the zone center and the spectral weight decays rapidly as momentum\nincreases. The observation is described as a spectral continuum from electron\nfractionalization, corroborated by a low energy effective model.The intensity\nof the flat band is reduced by surface doping with magnetic adatoms and the gap\nis closing, a result from the interaction between spin impurities coupled with\nspinons and the chargons, which gives rise to a charge redistribution. Doping\nwith nonmagnetic impurities behaves differently as the chemical potential shift\ndominates. These findings provide insight into the QSL states of strongly\ncorrelated electrons on 2D triangular lattices.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-16T05:31:42Z"}
{"aid":"http://arxiv.org/abs/2504.11787v1","title":"The AstroSat UV Deep Field South. III. Evolution of the UV Luminosity\n  Function and Luminosity Density from z~0.8-0.4","summary":"We characterise the rest-frame 1500 \\r{A} UV luminosity Function (UVLF) from\ndeep AstroSat/UVIT F154W and N242W imaging in the Great Observatories Origins\nSurvey South (GOODS-S) deep field. The UVLFs are constructed and subsequently\ncharacterised with fitted Schechter function parameters from FUV observations\nat z$<0.13$ and NUV observations in seven redshift bins in z~0.8-0.4. The UVLF\nslope ($\\alpha$) and characteristic magnitude ($M^*$) are consistent with\nprevious determinations for this redshift range based on AstroSat/UVIT\nGOODS-North observations, as well as with those from Galaxy evolution Explorer\nand Hubble Space Telescope observations. However, differences in the\nnormalisation factor ($\\phi_{*}$) are present for UVLFs for some redshift bins.\nWe compute the UV luminosity density, $\\rho_{\\rm UV}$, combining our determined\nUVLF parameters with literature determinations out to z$\\sim10$. The $\\rho_{\\rm\nUV}$ trend with redshift implies the rapid increase in cosmic star formation\ntill its peak at z$\\sim3$ (cosmic noon) followed by a slow decline till present\nday. Both the initial increase in cosmic star formation and subsequent decline\nare found to be more rapid than previous determinations.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-16T05:40:32Z"}
{"aid":"http://arxiv.org/abs/2504.11789v1","title":"The vanishing discount problem for nonlocal Hamilton-Jacobi equations","summary":"We establish a convergence result for the vanishing discount problem in the\ncontext of nonlocal HJ equations. We consider a fairly general class of\ndiscounted first-order and convex HJ equations which incorporate an\nintegro-differential operator posed on the $d$-dimensional torus, and we show\nthat the solutions converge to a specific critical solution as the discount\nfactor tends to zero. Our approach relies on duality techniques for nonlocal\nconvex HJ equations, building upon Hahn-Banach separation theorems to develop a\ngeneralized notion of Mather measure. The results are applied to a specific\nclass of convex and superlinear Hamiltonians.","main_category":"math.AP","categories":"math.AP,math.FA","published":"2025-04-16T05:42:24Z"}
{"aid":"http://arxiv.org/abs/2504.11809v1","title":"Efficient and Adaptive Simultaneous Speech Translation with Fully\n  Unidirectional Architecture","summary":"Simultaneous speech translation (SimulST) produces translations incrementally\nwhile processing partial speech input. Although large language models (LLMs)\nhave showcased strong capabilities in offline translation tasks, applying them\nto SimulST poses notable challenges. Existing LLM-based SimulST approaches\neither incur significant computational overhead due to repeated encoding of\nbidirectional speech encoder, or they depend on a fixed read/write policy,\nlimiting the efficiency and performance. In this work, we introduce Efficient\nand Adaptive Simultaneous Speech Translation (EASiST) with fully unidirectional\narchitecture, including both speech encoder and LLM. EASiST includes a\nmulti-latency data curation strategy to generate semantically aligned SimulST\ntraining samples and redefines SimulST as an interleaved generation task with\nexplicit read/write tokens. To facilitate adaptive inference, we incorporate a\nlightweight policy head that dynamically predicts read/write actions.\nAdditionally, we employ a multi-stage training strategy to align speech-text\nmodalities and optimize both translation and policy behavior. Experiments on\nthe MuST-C En$\\rightarrow$De and En$\\rightarrow$Es datasets demonstrate that\nEASiST offers superior latency-quality trade-offs compared to several strong\nbaselines.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-16T06:46:15Z"}
{"aid":"http://arxiv.org/abs/2504.11826v1","title":"When Should I Run My Application Benchmark?: Studying Cloud Performance\n  Variability for the Case of Stream Processing Applications","summary":"Performance benchmarking is a common practice in software engineering,\nparticularly when building large-scale, distributed, and data-intensive\nsystems. While cloud environments offer several advantages for running\nbenchmarks, it is often reported that benchmark results can vary significantly\nbetween repetitions -- making it difficult to draw reliable conclusions about\nreal-world performance. In this paper, we empirically quantify the impact of\ncloud performance variability on benchmarking results, focusing on stream\nprocessing applications as a representative type of data-intensive,\nperformance-critical system. In a longitudinal study spanning more than three\nmonths, we repeatedly executed an application benchmark used in research and\ndevelopment at Dynatrace. This allows us to assess various aspects of\nperformance variability, particularly concerning temporal effects. With\napproximately 591 hours of experiments, deploying 789 Kubernetes clusters on\nAWS and executing 2366 benchmarks, this is likely the largest study of its kind\nand the only one addressing performance from an end-to-end, i.e., application\nbenchmark perspective. Our study confirms that performance variability exists,\nbut it is less pronounced than often assumed (coefficient of variation of <\n3.7%). Unlike related studies, we find that performance does exhibit a daily\nand weekly pattern, although with only small variability (<= 2.5%). Re-using\nbenchmarking infrastructure across multiple repetitions introduces only a\nslight reduction in result accuracy (<= 2.5 percentage points). These key\nobservations hold consistently across different cloud regions and machine types\nwith different processor architectures. We conclude that for engineers and\nresearchers focused on detecting substantial performance differences (e.g., >\n5%) in...","main_category":"cs.SE","categories":"cs.SE,cs.DC,cs.PF","published":"2025-04-16T07:22:44Z"}
{"aid":"http://arxiv.org/abs/2504.11836v1","title":"Non-centering for discrete-valued state transition models: an\n  application to ESBL-producing E. coli transmission in Malawi","summary":"Infectious disease transmission is often modelled by discrete-valued\nstochastic state-transition processes. Due to a lack of complete data, Bayesian\ninference for these models often relies on data-augmentation techniques. These\ntechniques are often inefficient or time consuming to implement. We introduce a\nnovel data-augmentation Markov chain Monte Carlo method for discrete-time\nindividual-based epidemic models, which we call the Rippler algorithm. This\nmethod uses the transmission model in the proposal step of the\nMetropolis-Hastings algorithm, rather than in the accept-reject step. We test\nthe Rippler algorithm on simulated data and apply it to data on\nextended-spectrum beta-lactamase (ESBL)-producing E. coli collected in\nBlantyre, Malawi. We compare the Rippler algorithm to two other commonly used\nBayesian inference methods for partially observed epidemic data, and find that\nit has a good balance between mixing speed and computational complexity.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-16T07:46:46Z"}
{"aid":"http://arxiv.org/abs/2504.11838v1","title":"A Visual RAG Pipeline for Few-Shot Fine-Grained Product Classification","summary":"Despite the rapid evolution of learning and computer vision algorithms,\nFine-Grained Classification (FGC) still poses an open problem in many\npractically relevant applications. In the retail domain, for example, the\nidentification of fast changing and visually highly similar products and their\nproperties are key to automated price-monitoring and product recommendation.\nThis paper presents a novel Visual RAG pipeline that combines the Retrieval\nAugmented Generation (RAG) approach and Vision Language Models (VLMs) for\nfew-shot FGC. This Visual RAG pipeline extracts product and promotion data in\nadvertisement leaflets from various retailers and simultaneously predicts\nfine-grained product ids along with price and discount information. Compared to\nprevious approaches, the key characteristic of the Visual RAG pipeline is that\nit allows the prediction of novel products without re-training, simply by\nadding a few class samples to the RAG database. Comparing several VLM back-ends\nlike GPT-4o [23], GPT-4o-mini [24], and Gemini 2.0 Flash [10], our approach\nachieves 86.8% accuracy on a diverse dataset.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T07:53:50Z"}
{"aid":"http://arxiv.org/abs/2504.11849v1","title":"On symmetric functions and symmetric operators on Banach spaces","summary":"We study left symmetric and right symmetric elements in the space\n$\\ell_{\\infty}(K, \\mathbb{X}) $ of bounded functions from a non-empty set $K$\nto a Banach space $\\mathbb{X}.$ We prove that a non-zero element $ f\n\\in\\ell_{\\infty}(K, \\mathbb{X}) $ is left symmetric if and only if $f$ is zero\nexcept for an element $k_0 \\in K$ and $f(k_0)$ is left symmetric in\n$\\mathbb{X}.$ We characterize left symmetric elements in the space $C_0(K,\n\\mathbb{X}),$ where $K$ is a locally compact perfectly normal space. We also\nstudy the right symmetric elements in $\\ell_{\\infty}(K, \\mathbb{X}).$\nFurthermore, we characterize right symmetric elements in $C_0(K, \\mathbb{X}),$\nwhere $K$ is a locally compact Hausdorff space and $\\mathbb{X}$ is real Banach\nspace. As an application of the results obtained in this article, we\ncharacterize the left symmetric and right symmetric operators on some special\nBanach spaces. These results improve and generalize the existing ones on the\nstudy of left and right symmetric elements in operator spaces.","main_category":"math.FA","categories":"math.FA","published":"2025-04-16T08:15:13Z"}
{"aid":"http://arxiv.org/abs/2504.11857v1","title":"Heat kernel estimates, fractional Riesz transforms and applications on\n  exterior domains","summary":"In this paper, we derive sharp two side heat kernel estimate on exterior\n$C^{1,1}$ domains in the plane, and sharp upper heat kernel bound on exterior\n$C^{1,\\mathrm{Dini}}$ domains in $\\mathbb{R}^n$, $n\\ge 2$. Estimates for\nGreen's function and Riesz potentials on exterior domains in the plane are also\npresented. Based on the heat kernel estimates, we show the boundedness of the\nfractional Riesz transforms on exterior $C^{1,\\mathrm{Dini}}$ domains in\n$\\mathbb{R}^n$, $n\\ge 2$. Some further applications to product and chain rules\nand nonlinear Schr\\\"odinger equation are also presented.","main_category":"math.CA","categories":"math.CA,math.AP","published":"2025-04-16T08:29:42Z"}
{"aid":"http://arxiv.org/abs/2504.11858v1","title":"Synthetic Data for Blood Vessel Network Extraction","summary":"Blood vessel networks in the brain play a crucial role in stroke research,\nwhere understanding their topology is essential for analyzing blood flow\ndynamics. However, extracting detailed topological vessel network information\nfrom microscopy data remains a significant challenge, mainly due to the\nscarcity of labeled training data and the need for high topological accuracy.\nThis work combines synthetic data generation with deep learning to\nautomatically extract vessel networks as graphs from volumetric microscopy\ndata. To combat data scarcity, we introduce a comprehensive pipeline for\ngenerating large-scale synthetic datasets that mirror the characteristics of\nreal vessel networks. Our three-stage approach progresses from abstract graph\ngeneration through vessel mask creation to realistic medical image synthesis,\nincorporating biological constraints and imaging artifacts at each stage. Using\nthis synthetic data, we develop a two-stage deep learning pipeline of 3D\nU-Net-based models for node detection and edge prediction. Fine-tuning on real\nmicroscopy data shows promising adaptation, improving edge prediction F1 scores\nfrom 0.496 to 0.626 by training on merely 5 manually labeled samples. These\nresults suggest that automated vessel network extraction is becoming\npractically feasible, opening new possibilities for large-scale vascular\nanalysis in stroke research.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T08:29:46Z"}
{"aid":"http://arxiv.org/abs/2504.11866v1","title":"On the Problem of Best Arm Retention","summary":"This paper presents a comprehensive study on the problem of Best Arm\nRetention (BAR), which has recently found applications in streaming algorithms\nfor multi-armed bandits. In the BAR problem, the goal is to retain $m$ arms\nwith the best arm included from $n$ after some trials, in stochastic\nmulti-armed bandit settings. We first investigate pure exploration for the BAR\nproblem under different criteria, and then minimize the regret with specific\nconstraints, in the context of further exploration in streaming algorithms.\n  - We begin by revisiting the lower bound for the $(\\varepsilon,\\delta)$-PAC\nalgorithm for Best Arm Identification (BAI) and adapt the classical\nKL-divergence argument to derive optimal bounds for $(\\varepsilon,\\delta)$-PAC\nalgorithms for BAR.\n  - We further study another variant of the problem, called $r$-BAR, which\nrequires the expected gap between the best arm and the optimal arm retained is\nless than $r$. We prove tight sample complexity for the problem.\n  - We explore the regret minimization problem for $r$-BAR and develop\nalgorithm beyond pure exploration. We conclude with a conjecture on the optimal\nregret in this setting.","main_category":"cs.LG","categories":"cs.LG,cs.DS","published":"2025-04-16T08:41:20Z"}
{"aid":"http://arxiv.org/abs/2504.11878v1","title":"A Novel Approach to Secure RSMA Networks","summary":"This letter introduces a novel data-dependent interleaving technique designed\nto enhance the security of rate-splitting multiple access (RSMA) networks by\nprotecting the common stream from eavesdropping threats. Specifically, we\nexploit the RSMA structure by interleaving the common bits of each user based\non a sequence derived from their private bits. By decoding its private stream,\nthe legitimate receiver reconstructs the interleaving sequence set by the\ntransmitter and successfully de-interleaves the common stream. Therefore, the\ncommon part is successfully prevented from being intercepted by an eavesdropper\nwho is unable to deduce the dynamic changing interleaving permutations. To\nensure dynamic interleaving sequences, a private bit selection approach that\nbalances the trade-off between security and system efficiency is proposed.\nSimulation findings confirm the effectiveness of the suggested method, showing\nnotable security improvements while maintaining robust overall system\nreliability.","main_category":"eess.SP","categories":"eess.SP,cs.SY,eess.SY","published":"2025-04-16T08:59:10Z"}
{"aid":"http://arxiv.org/abs/2504.11885v1","title":"HyperSAT: Unsupervised Hypergraph Neural Networks for Weighted MaxSAT\n  Problems","summary":"Graph neural networks (GNNs) have shown promising performance in solving both\nBoolean satisfiability (SAT) and Maximum Satisfiability (MaxSAT) problems due\nto their ability to efficiently model and capture the structural dependencies\nbetween literals and clauses. However, GNN methods for solving Weighted MaxSAT\nproblems remain underdeveloped. The challenges arise from the non-linear\ndependency and sensitive objective function, which are caused by the\nnon-uniform distribution of weights across clauses. In this paper, we present\nHyperSAT, a novel neural approach that employs an unsupervised hypergraph\nneural network model to solve Weighted MaxSAT problems. We propose a hypergraph\nrepresentation for Weighted MaxSAT instances and design a cross-attention\nmechanism along with a shared representation constraint loss function to\ncapture the logical interactions between positive and negative literal nodes in\nthe hypergraph. Extensive experiments on various Weighted MaxSAT datasets\ndemonstrate that HyperSAT achieves better performance than state-of-the-art\ncompetitors.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-16T09:11:16Z"}
{"aid":"http://arxiv.org/abs/2504.11886v1","title":"Detection of wave activity within a realistic 3D MHD quiet sun\n  simulation","summary":"Context. Tracing wave activity from the photosphere to the corona has\nimportant implications for coronal heating and prediction of the solar wind.\nDespite extensive theory and simulations, the detection of waves in realistic\nMHD simulations still presents a large challenge due to wave interaction, mode\nconversion, and damping mechanisms. Aims. We conducted this study to detect\nlocalised wave activity within a realistic MHD simulation of the solar\natmosphere by the Bifrost code. Methods. We present a new method of detecting\nthe most significant contributions of wave activity within localised areas of\nthe domain, aided by Discrete Fourier Transforms and frequency filtering. We\ncorrelate oscillations in the vertical & horizontal magnetic field, velocities\nparallel & perpendicular to the magnetic field, and pressure to infer the\nnature of the dominant wave modes. Results. Our method captures the most\npowerful frequencies and wavenumbers, as well as providing a new diagnostic for\ndamping processes. We infer the presence of magnetoacoustic waves in the\nboundaries of prominent chromospheric/coronal swirling features. We find these\nwaves are likely damped by viscous heating in the swirl boundaries,\ncontributing to heating in the upper atmosphere. Conclusions. Using the most\nsignificant frequencies decomposition, we highlight that energy can be\ntransported from the lower atmosphere to the upper atmosphere through waves and\nfluctuations along the swirl boundaries. Although further analysis is needed to\nconfirm these findings, our new method provides a path forward to investigate\nwave activity in the solar atmosphere","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-16T09:14:14Z"}
{"aid":"http://arxiv.org/abs/2504.11917v1","title":"Dirac Representation for Lattice Spin Operators: Spin-$1/2$ and Spin-$1$\n  cases","summary":"A novel quantum representation of lattice spin operators (LSOs) is achieved\nby mapping quantum spins onto their classical analogues for spin size $S=1/2$\nand $S=1$. The \"braket\" representations of LSOs are attained thanks to a\nprofound inspection into the binary/ternary distribution of classical\nbits/trits in non-negative integers. We claim the possility of getting the\n$j$th digit of a positive integer without performing any binary/ternary\ndecomposition. Analytical formulas returning the $j$th bits/trits of an integer\nare presented. Impacts of our achievements in Physics are highlighted by\nrevisiting the $1D$ spin-$1/2$ {XXZ} Heisenberg model with open boundaries in a\nmagnetic field in both absence (uniform magnetic field) and presence of\ndisorder (random magnetic field). In the absence of disorder (clean system), we\ndemonstrate that the corresponding eigenvalues problem can be reduced to a\ntight-binding problem on a graph and solved without resorting to any spinless\ntransformation nor the Bethe Anzath. In the presence of disorder, a convergent\nperturbation theory is elaborated. Our analytical results are compared with\ndata from exact diagonalization for relatively large spin systems ($K\\leq 18$\nspins with $K$ denoting the total number of spins) obtained by implementing\nboth the global $U(1)$ symmetry to block-diagonalize the Hamiltonian and the\nspin-inversion symmetry for two-fold block-diagonalization in the sector with\ntotal magnetization $\\mathcal{J}^z=0$. We observe a good agreement between both\nresults.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-16T09:54:35Z"}
{"aid":"http://arxiv.org/abs/2504.11920v1","title":"Lagrangian finite elements in Sobolev-like spaces of order $3/2$","summary":"This paper introduces a Sobolev-like space of order $3/2$, denoted as\n$\\widehat{H}^{3/2}$, for Lagrangian finite elements, especially for $C^0$\nelements. It is motivated by the limitations of current stability analysis of\nthe evolving surface finite element method (ESFEM), which relies exclusively on\nan energy estimate framework. To establish a PDE-based analysis framework for\nESFEM, we encounter a fundamental regularity mismatch: the ESFEM adopts the\n$C^0$ elements, while the PDE regularity theory requires $H^{3/2}$ regularity\nfor solutions. To overcome this difficulty, we first examine the properties of\nthe continuous $H^{3/2}$ space, then introduce a Dirichlet lift and Scott-Zhang\ntype interpolation operators to bridge to the discrete $\\widehat{H}^{3/2}$\nspace. Our new $\\widehat{H}^{3/2}$ space is shown to be compatible with the\nelliptic PDE regularity theory, the trace inequality, and the inverse\ninequality. Notably, we extend the critical domain deformation estimate in\nESFEM to the $\\widehat{H}^{3/2}$ setting. The $\\widehat{H}^{3/2}$ theory\nprovides a foundation for establishing a PDE-based convergence analysis\nframework of ESFEM.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-16T09:56:43Z"}
{"aid":"http://arxiv.org/abs/2504.11927v1","title":"Super-LoRa: Enhancing LoRa Throughput via Payload Superposition","summary":"This paper presents Super-LoRa, a novel approach to enhancing the throughput\nof LoRa networks by leveraging the inherent robustness of LoRa modulation\nagainst interference. By superimposing multiple payload symbols, Super-LoRa\nsignificantly increases the data rate while maintaining lower transmitter and\nreceiver complexity. Our solution is evaluated through both simulations and\nreal-world experiments, showing a potential throughput improvement of up to 5x\ncompared to standard LoRa. This advancement positions Super-LoRa as a viable\nsolution for data-intensive IoT applications such as smart cities and precision\nagriculture, which demand higher data transmission rates.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-16T10:02:38Z"}
{"aid":"http://arxiv.org/abs/2504.11928v1","title":"The Jade Gateway to Trust: Exploring How Socio-Cultural Perspectives\n  Shape Trust Within Chinese NFT Communities","summary":"Today's world is witnessing an unparalleled rate of technological\ntransformation. The emergence of non-fungible tokens (NFTs) has transformed how\nwe handle digital assets and value. Despite their initial popularity, NFTs face\ndeclining adoption influenced not only by cryptocurrency volatility but also by\ntrust dynamics within communities. From a social computing perspective,\nunderstanding these trust dynamics offers valuable insights for the development\nof both the NFT ecosystem and the broader digital economy. China presents a\ncompelling context for examining these dynamics, offering a unique intersection\nof technological innovation and traditional cultural values. Through a content\nanalysis of eight Chinese NFT-focused WeChat groups and 21 semi-structured\ninterviews, we examine how socio-cultural factors influence trust formation and\ndevelopment. We found that trust in Chinese NFT communities is significantly\nmolded by local cultural values. To be precise, Confucian virtues, such as\nbenevolence, propriety, and integrity, play a crucial role in shaping these\ntrust relationships. Our research identifies three critical trust dimensions in\nChina's NFT market: (1) technological, (2) institutional, and (3) social. We\nexamined the challenges in cultivating each dimension. Based on these insights,\nwe developed tailored trust-building guidelines for Chinese NFT stakeholders.\nThese guidelines address trust issues that factor into NFT's declining\npopularity and could offer valuable strategies for CSCW researchers,\ndevelopers, and designers aiming to enhance trust in global NFT communities.\nOur research urges CSCW scholars to take into account the unique socio-cultural\ncontexts when developing trust-enhancing strategies for digital innovations and\nonline interactions.","main_category":"cs.CY","categories":"cs.CY,cs.HC","published":"2025-04-16T10:03:30Z"}
{"aid":"http://arxiv.org/abs/2504.11931v1","title":"Local-in-time well-posedness for 2D compressible magneto-micropolar\n  boundary layer in Sobolev spaces","summary":"In this paper, we study the two-dimensional compressible magneto-micropolar\nboundary layer equations on the half-plane, which are derived from 2D\ncompressible magneto-micropolar fluid equations with the non-slip boundary\ncondition on velocity, Dirichlet boundary condition on micro-rotational\nvelocity and perfectly conducting boundary condition on magnetic field. Based\non a nonlinear coordinate transformation proposed in \\cite{LXY2019}, we first\nprove the local-in-time well-posedness for the compressible magneto-micropolar\nboundary layer system in Sobolev spaces, provided that initial tangential\nmagnetic field is non-degenerate.","main_category":"math.AP","categories":"math.AP","published":"2025-04-16T10:10:40Z"}
{"aid":"http://arxiv.org/abs/2504.11938v1","title":"Exact noise and dissipation operators for quantum stochastic\n  thermodynamics","summary":"The theory of open quantum systems plays a fundamental role in several\nscientific and technological disciplines, from quantum computing and\ninformation science to molecular electronics and quantum thermodynamics.\nDespite its widespread relevance, a rigorous formulation of quantum dissipation\nin conjunction with thermal noise remains a topic of active research. In this\nwork, we establish a formal correspondence between classical stochastic\nthermodynamics, in particular the Fokker-Planck and Klein-Kramers equations,\nand the quantum master equation. Building on prior studies of multiplicative\nnoise in classical stochastic differential equations, we demonstrate that\nthermal noise at the quantum level manifests as a multidimensional geometric\nstochastic process. By applying canonical quantization, we introduce a novel\nHermitian dissipation operator that serves as a quantum analogue of classical\nviscous friction. This operator not only preserves the mathematical rigor of\nopen quantum system dynamics but also allows for a well-defined expression of\nheat exchange between a system and its environment, enabling the formulation of\nan alternative quantum equipartition theorem. Our framework ensures a precise\nenergy balance that aligns with the first law of thermodynamics and an entropy\nbalance consistent with the second law. The theoretical formalism is applied to\ntwo prototypical quantum systems, the harmonic oscillator and a particle in an\ninfinite potential well, for whom it provides new insights into nonequilibrium\nthermodynamics at the quantum scale. Our results advance the understanding of\ndissipation in quantum systems and establish a foundation for future studies on\nstochastic thermodynamics in the quantum domain.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.MP","published":"2025-04-16T10:16:33Z"}
{"aid":"http://arxiv.org/abs/2504.11939v1","title":"Assessing WGC Compatibility in ModMax Black Holes via Photon Spheres\n  Analysis and WCCC Validation","summary":"It seems that the regime of Hawking radiation and evaporation ultimately\ndrives charged black holes toward super-extremality of the charge parameter and\nthe dominance of extremal conditions. This progression, in turn, lays the\ngroundwork for satisfying the necessary conditions for the Weak Gravity\nConjecture (WGC). Preliminary studies indicate that black holes such as the\nReissner-Nordstr$\\\"o$m (RN) model, in their initial form, lack the capacity to\nsustain super-extremality of the charge parameter. If such conditions arise,\nthese black holes transition into naked singularities-a scenario that is highly\nundesirable due to the loss of causality and the breakdown of space-time\ngeometry. This raises whether the inability to sustain super-extremality is an\ninherent property of the model or a consequence of the approximations and\nprecision limitations employed in its construction. To address this, we turned\nto the ModMax model, which represents an extension of the RN model. Our\nanalysis revealed that the ModMax model not only accommodates super-extremality\nof the charge parameter but also, under certain conditions, emerges as a\npromising candidate for investigating the WGC. Furthermore, we independently\nobserved how the inclusion of the de Sitter radius ($\\ell$) in the AdS model\nand $f(R)$ gravitational corrections-both of which enhance and complicate the\nmodel-can have a direct impact on the range of super-extremal charge tolerance\nwhich, in turn, provides the realization of the conditions necessary for the\nWGC.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-16T10:17:15Z"}
{"aid":"http://arxiv.org/abs/2504.11962v1","title":"Curvilinear Mask Optimization for Inverse Lithography Based on B-splines\n  and Delaunay Triangulation","summary":"In this paper, we propose a novel gradient-based method to optimize\ncurvilinear masks in optical lithography. The mask pattern is represented by\nperiodic B-spline curves. We apply Delaunay triangulation to discretize the\ndomains circled by the spline curves. Subsequently, we establish an explicit\nrelationship between the integral points and the control points of the boundary\nspline curve. Based on the relationship, we derive explicit formulas of the\ngradient of the optimization objective function with respect to the coordinates\nof the control points. Then we propose an inverse lithography algorithm to\noptimize the curvilinear mask pattern. Finally, the results of the numerical\nexperiments demonstrate the feasibility and extensive adaptability of our\nmethod.","main_category":"math.OC","categories":"math.OC","published":"2025-04-16T10:44:02Z"}
{"aid":"http://arxiv.org/abs/2504.11976v1","title":"Stochastic Quadrature Rules for Solving PDEs using Neural Networks","summary":"In this article, we consider issues surrounding integration when using Neural\nNetworks to solve Partial Differential Equations. We focus on the Deep Ritz\nMethod as it is of practical interest and sensitive to integration errors. We\nshow how both deterministic integration rules as well as biased, stochastic\nquadrature can lead to erroneous results, whilst high order, unbiased\nstochastic quadrature rules on integration meshes can significantly improve\nconvergence at an equivalent computational cost. Furthermore, we propose novel\nstochastic quadrature rules for triangular and tetrahedral elements, offering\ngreater flexibility when designing integration meshes in more complex\ngeometries. We highlight how the variance in the stochastic gradient limits\nconvergence, whilst quadrature rules designed to give similar errors when\nintegrating the loss function may lead to disparate results when employed in a\ngradient-based optimiser.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-16T11:15:38Z"}
{"aid":"http://arxiv.org/abs/2504.11999v1","title":"A Complex-valued SAR Foundation Model Based on Physically Inspired\n  Representation Learning","summary":"Vision foundation models in remote sensing have been extensively studied due\nto their superior generalization on various downstream tasks. Synthetic\nAperture Radar (SAR) offers all-day, all-weather imaging capabilities,\nproviding significant advantages for Earth observation. However, establishing a\nfoundation model for SAR image interpretation inevitably encounters the\nchallenges of insufficient information utilization and poor interpretability.\nIn this paper, we propose a remote sensing foundation model based on\ncomplex-valued SAR data, which simulates the polarimetric decomposition process\nfor pre-training, i.e., characterizing pixel scattering intensity as a weighted\ncombination of scattering bases and scattering coefficients, thereby endowing\nthe foundation model with physical interpretability. Specifically, we construct\na series of scattering queries, each representing an independent and meaningful\nscattering basis, which interact with SAR features in the scattering query\ndecoder and output the corresponding scattering coefficient. To guide the\npre-training process, polarimetric decomposition loss and power\nself-supervision loss are constructed. The former aligns the predicted\ncoefficients with Yamaguchi coefficients, while the latter reconstructs power\nfrom the predicted coefficients and compares it to the input image's power. The\nperformance of our foundation model is validated on six typical downstream\ntasks, achieving state-of-the-art results. Notably, the foundation model can\nextract stable feature representations and exhibits strong generalization, even\nin data-scarce conditions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T11:51:34Z"}
{"aid":"http://arxiv.org/abs/2504.12031v1","title":"Proof-Carrying Neuro-Symbolic Code","summary":"This invited paper introduces the concept of \"proof-carrying neuro-symbolic\ncode\" and explains its meaning and value, from both the \"neural\" and the\n\"symbolic\" perspectives. The talk outlines the first successes and challenges\nthat this new area of research faces.","main_category":"cs.PL","categories":"cs.PL,cs.AI,cs.LO","published":"2025-04-16T12:42:18Z"}
{"aid":"http://arxiv.org/abs/2504.12039v1","title":"RadMamba: Efficient Human Activity Recognition through Radar-based\n  Micro-Doppler-Oriented Mamba State-Space Model","summary":"Radar-based HAR has emerged as a promising alternative to conventional\nmonitoring approaches, such as wearable devices and camera-based systems, due\nto its unique privacy preservation and robustness advantages. However, existing\nsolutions based on convolutional and recurrent neural networks, although\neffective, are computationally demanding during deployment. This limits their\napplicability in scenarios with constrained resources or those requiring\nmultiple sensors. Advanced architectures, such as ViT and SSM architectures,\noffer improved modeling capabilities and have made efforts toward lightweight\ndesigns. However, their computational complexity remains relatively high. To\nleverage the strengths of transformer architectures while simultaneously\nenhancing accuracy and reducing computational complexity, this paper introduces\nRadMamba, a parameter-efficient, radar micro-Doppler-oriented Mamba SSM\nspecifically tailored for radar-based HAR. Across three diverse datasets,\nRadMamba matches the top-performing previous model's 99.8% classification\naccuracy on Dataset DIAT with only 1/400 of its parameters and equals the\nleading models' 92.0% accuracy on Dataset CI4R with merely 1/10 of their\nparameters. In scenarios with continuous sequences of actions evaluated on\nDataset UoG2020, RadMamba surpasses other models with significantly higher\nparameter counts by at least 3%, achieving this with only 6.7k parameters. Our\ncode is available at: https://github.com/lab-emi/AIRHAR.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-16T12:54:11Z"}
{"aid":"http://arxiv.org/abs/2504.12056v1","title":"Refining the Understanding of Operator Size Dynamics in Open Quantum\n  Systems","summary":"Information scrambling refers to the phenomenon in which local quantum\ninformation in a many-body system becomes dispersed throughout the entire\nsystem under unitary evolution. It has been extensively studied in closed\nquantum systems, where it is quantified by operator size growth, revealing deep\nconnections between condensed matter physics, high-energy physics, and quantum\ninformation. However, when extending the study of operator size dynamics to\nopen quantum systems, two different definitions of operator size distributions\nemerge. These definitions are based on different treatments of the bath. In\nthis work, we aim to establish a unified picture for operator size dynamics in\nopen quantum systems, using the solvable Brownian SYK models at generic system\nsize. In particular, we provide the conditions under which the signature of\nscrambling transition, discovered using one particular definition, appears in\noperator size dynamics under the other definition. Additionally, we extend\nprevious studies by exploring finite-size effects that are not captured by the\nscramblon theory. Our results provide a refined understanding of operator size\ndynamics in open quantum systems.","main_category":"quant-ph","categories":"quant-ph,cond-mat.str-el,hep-th","published":"2025-04-16T13:10:15Z"}
{"aid":"http://arxiv.org/abs/2504.12070v1","title":"A Light Lepton-flavor-violating Flavon: the Messenger of Neutrino Mixing\n  and Muon $g-2$","summary":"In neutrino physics, a class of models with local or global family symmetries\nmay be invoked, and then a flavon field is needed to realize the full neutrino\nmixing. This flavon may shed light on the long-standing muon $g-2$ puzzle. In\nthis work, we explore this idea in the $({B-L})_{13}$ gauge extension to the\nstandard model (SM), in which realistic neutrino mixing requires both a SM\nsinglet flavon $s$ and a vector-like lepton (VLL) doublet. The dominant\ncoupling between the flavon and leptons is in the manner of\nlepton-flavor-violation (LFV). Through an analytical analysis of the SM\nlepton-VLL mixing matrix, we find that the parameter space of the $s\\bar\\mu\ne$-type flavon to explain the muon $g-2$ has been completely excluded by the\nspecific LFV process, muonium-antimuonium oscillation. But the $s\\bar\\mu\n\\tau$-type flavon still has the opportunity; however, it confronts the strong\nconstraint from $\\tau\\to \\mu$ conservation and, in particular, the lepton\nflavor universality test of $Z$ boson decay, which arises due to our way to\nrealize the LFV flavon. The surviving flavon is highly predictable, with mass\nin the narrow window $m_\\tau\\lesssim m_s\\lesssim 1.5~ m_\\tau$ and LFV coupling\nstrength $\\sim 10^{-2}$. Besides, it leaves a TeV scale VLL with a multi-lepton\nsignature at the LHC.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-16T13:25:54Z"}
{"aid":"http://arxiv.org/abs/2504.12072v1","title":"Observational properties of regular black holes in Asymptotic Safety","summary":"We consider the observational properties of a spherically symmetric, static\nregular black hole within the framework of asymptotic safety (AS) as proposed\nby Bonanno et al. The metric resembles the Schwarzschild solution in the\nclassical limit. The departure from Schwarzschild at small scales is controlled\nby a single free parameter related to the ultraviolet (UV) cutoff of the\ntheory. We investigated null and time-like geodesics around the AS metric,\nincluding circular orbits, photon rings and lensing effects. In particular we\nfocused on the optical properties of thin accretion disks in the equatorial\nplane of the object and compared them with those of accretion disks in the\nSchwarzschild metric. We found that the radiation flux, luminosity, and\nefficiency of the accretion disk increase with the value of the free parameter.\nUsing a spacetime generic open-source relativistic ray-tracing code, we\nsimulate the K$\\alpha$ iron line profiles emitted by the disk and analyze their\ndeviation from that of the Schwarzschild geometry.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-16T13:28:51Z"}
{"aid":"http://arxiv.org/abs/2504.12078v1","title":"Single-shot Star-convex Polygon-based Instance Segmentation for\n  Spatially-correlated Biomedical Objects","summary":"Biomedical images often contain objects known to be spatially correlated or\nnested due to their inherent properties, leading to semantic relations.\nExamples include cell nuclei being nested within eukaryotic cells and colonies\ngrowing exclusively within their culture dishes. While these semantic relations\nbear key importance, detection tasks are often formulated independently,\nrequiring multi-shot analysis pipelines. Importantly, spatial correlation could\nconstitute a fundamental prior facilitating learning of more meaningful\nrepresentations for tasks like instance segmentation. This knowledge has, thus\nfar, not been utilised by the biomedical computer vision community. We argue\nthat the instance segmentation of two or more categories of objects can be\nachieved in parallel. We achieve this via two architectures HydraStarDist (HSD)\nand the novel (HSD-WBR) based on the widely-used StarDist (SD), to take\nadvantage of the star-convexity of our target objects. HSD and HSD-WBR are\nconstructed to be capable of incorporating their interactions as constraints\ninto account. HSD implicitly incorporates spatial correlation priors based on\nobject interaction through a joint encoder. HSD-WBR further enforces the prior\nin a regularisation layer with the penalty we proposed named Within Boundary\nRegularisation Penalty (WBR). Both architectures achieve nested instance\nsegmentation in a single shot. We demonstrate their competitiveness based on\n$IoU_R$ and AP and superiority in a new, task-relevant criteria, Joint TP rate\n(JTPR) compared to their baseline SD and Cellpose. Our approach can be further\nmodified to capture partial-inclusion/-exclusion in multi-object interactions\nin fluorescent or brightfield microscopy or digital imaging. Finally, our\nstrategy suggests gains by making this learning single-shot and computationally\nefficient.","main_category":"cs.CV","categories":"cs.CV,q-bio.QM","published":"2025-04-16T13:41:02Z"}
{"aid":"http://arxiv.org/abs/2504.12103v1","title":"Metric-Solver: Sliding Anchored Metric Depth Estimation from a Single\n  Image","summary":"Accurate and generalizable metric depth estimation is crucial for various\ncomputer vision applications but remains challenging due to the diverse depth\nscales encountered in indoor and outdoor environments. In this paper, we\nintroduce Metric-Solver, a novel sliding anchor-based metric depth estimation\nmethod that dynamically adapts to varying scene scales. Our approach leverages\nan anchor-based representation, where a reference depth serves as an anchor to\nseparate and normalize the scene depth into two components: scaled near-field\ndepth and tapered far-field depth. The anchor acts as a normalization factor,\nenabling the near-field depth to be normalized within a consistent range while\nmapping far-field depth smoothly toward zero. Through this approach, any depth\nfrom zero to infinity in the scene can be represented within a unified\nrepresentation, effectively eliminating the need to manually account for scene\nscale variations. More importantly, for the same scene, the anchor can slide\nalong the depth axis, dynamically adjusting to different depth scales. A\nsmaller anchor provides higher resolution in the near-field, improving depth\nprecision for closer objects while a larger anchor improves depth estimation in\nfar regions. This adaptability enables the model to handle depth predictions at\nvarying distances and ensure strong generalization across datasets. Our design\nenables a unified and adaptive depth representation across diverse\nenvironments. Extensive experiments demonstrate that Metric-Solver outperforms\nexisting methods in both accuracy and cross-dataset generalization.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T14:12:25Z"}
{"aid":"http://arxiv.org/abs/2504.12106v1","title":"A new description of the bicrystal $B(\\infty)$ and the extended crystal","summary":"We define new crystal maps on $B(\\infty)$ using its polyhedral realization,\nand show that the crystal $B(\\infty)$ equipped with the new crystal maps is\nisomorphic to Kashiwara's $B(\\infty)$ as bicrystals. In addition, we\ncombinatorially describe the bicrystal structure of $B(\\infty)$, which is\ncalled a sliding diamond rule. Using the bicrystal structure on $B(\\infty)$, we\ndefine the extended crystal and show that it is isomorphic to the extended\ncrystal introduced by Kashiwara and Park.","main_category":"math.RT","categories":"math.RT,math.QA","published":"2025-04-16T14:14:51Z"}
{"aid":"http://arxiv.org/abs/2504.12132v1","title":"Weakly Semi-supervised Whole Slide Image Classification by Two-level\n  Cross Consistency Supervision","summary":"Computer-aided Whole Slide Image (WSI) classification has the potential to\nenhance the accuracy and efficiency of clinical pathological diagnosis. It is\ncommonly formulated as a Multiple Instance Learning (MIL) problem, where each\nWSI is treated as a bag and the small patches extracted from the WSI are\nconsidered instances within that bag. However, obtaining labels for a large\nnumber of bags is a costly and time-consuming process, particularly when\nutilizing existing WSIs for new classification tasks. This limitation renders\nmost existing WSI classification methods ineffective. To address this issue, we\npropose a novel WSI classification problem setting, more aligned with clinical\npractice, termed Weakly Semi-supervised Whole slide image Classification\n(WSWC). In WSWC, a small number of bags are labeled, while a significant number\nof bags remain unlabeled. The MIL nature of the WSWC problem, coupled with the\nabsence of patch labels, distinguishes it from typical semi-supervised image\nclassification problems, making existing algorithms for natural images\nunsuitable for directly solving the WSWC problem. In this paper, we present a\nconcise and efficient framework, named CroCo, to tackle the WSWC problem\nthrough two-level Cross Consistency supervision. CroCo comprises two\nheterogeneous classifier branches capable of performing both instance\nclassification and bag classification. The fundamental idea is to establish\ncross-consistency supervision at both the bag-level and instance-level between\nthe two branches during training. Extensive experiments conducted on four\ndatasets demonstrate that CroCo achieves superior bag classification and\ninstance classification performance compared to other comparative methods when\nlimited WSIs with bag labels are available. To the best of our knowledge, this\npaper presents for the first time the WSWC problem and gives a successful\nresolution.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T14:45:26Z"}
{"aid":"http://arxiv.org/abs/2504.12136v1","title":"The Social Learning Barrier","summary":"We consider long-lived agents who interact repeatedly in a social network. In\neach period, each agent learns about an unknown state by observing a private\nsignal and her neighbors' actions in the previous period before taking an\naction herself. Our main result shows that the learning rate of the slowest\nlearning agent is bounded from above independently of the number of agents, the\nnetwork structure, and the agents' strategies. Applying this result to\nequilibrium learning with rational agents shows that the learning rate of all\nagents in any equilibrium is bounded under general conditions. This extends\nrecent findings on equilibrium learning and demonstrates that the limitation\nstems from an inherent tradeoff between optimal action choices and information\nrevelation rather than strategic considerations.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-16T14:50:22Z"}
{"aid":"http://arxiv.org/abs/2504.12137v1","title":"Efficient Contrastive Decoding with Probabilistic Hallucination\n  Detection - Mitigating Hallucinations in Large Vision Language Models -","summary":"Despite recent advances in Large Vision Language Models (LVLMs), these models\nstill suffer from generating hallucinatory responses that do not align with the\nvisual input provided. To mitigate such hallucinations, we introduce Efficient\nContrastive Decoding (ECD), a simple method that leverages probabilistic\nhallucination detection to shift the output distribution towards contextually\naccurate answers at inference time. By contrasting token probabilities and\nhallucination scores, ECD subtracts hallucinated concepts from the original\ndistribution, effectively suppressing hallucinations. Notably, our proposed\nmethod can be applied to any open-source LVLM and does not require additional\nLVLM training. We evaluate our method on several benchmark datasets and across\ndifferent LVLMs. Our experiments show that ECD effectively mitigates\nhallucinations, outperforming state-of-the-art methods with respect to\nperformance on LVLM benchmarks and computation time.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL,cs.LG","published":"2025-04-16T14:50:25Z"}
{"aid":"http://arxiv.org/abs/2504.12151v1","title":"Towards Explainable Fusion and Balanced Learning in Multimodal Sentiment\n  Analysis","summary":"Multimodal Sentiment Analysis (MSA) faces two critical challenges: the lack\nof interpretability in the decision logic of multimodal fusion and modality\nimbalance caused by disparities in inter-modal information density. To address\nthese issues, we propose KAN-MCP, a novel framework that integrates the\ninterpretability of Kolmogorov-Arnold Networks (KAN) with the robustness of the\nMultimodal Clean Pareto (MCPareto) framework. First, KAN leverages its\nunivariate function decomposition to achieve transparent analysis of\ncross-modal interactions. This structural design allows direct inspection of\nfeature transformations without relying on external interpretation tools,\nthereby ensuring both high expressiveness and interpretability. Second, the\nproposed MCPareto enhances robustness by addressing modality imbalance and\nnoise interference. Specifically, we introduce the Dimensionality Reduction and\nDenoising Modal Information Bottleneck (DRD-MIB) method, which jointly denoises\nand reduces feature dimensionality. This approach provides KAN with\ndiscriminative low-dimensional inputs to reduce the modeling complexity of KAN\nwhile preserving critical sentiment-related information. Furthermore, MCPareto\ndynamically balances gradient contributions across modalities using the\npurified features output by DRD-MIB, ensuring lossless transmission of\nauxiliary signals and effectively alleviating modality imbalance. This synergy\nof interpretability and robustness not only achieves superior performance on\nbenchmark datasets such as CMU-MOSI, CMU-MOSEI, and CH-SIMS v2 but also offers\nan intuitive visualization interface through KAN's interpretable architecture.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-16T15:00:06Z"}
{"aid":"http://arxiv.org/abs/2504.12163v1","title":"Pulsar Coherent Radio Emission from Solitons : Average Emission\n  Properties","summary":"Observations have established that coherent radio emission from pulsars arise\nat few hundred kilometers above stellar surface. Recent polarization studies\nhave further demonstrated that plasma instabilities are necessary for charge\nbunching that gives rise to coherent emission. The formation of charged\nsolitons in the electron-positron plasma is the only known bunching mechanism\nthat can be realised at these heights. More than five decades of observations\nhave revealed a number of emission features that should emerge from any valid\nradio emission mechanism. We have carried out numerical calculations to find\nthe features of average emission from curvature radiation due to charged\nsolitons. The characteristic curvature radiation spectrum has been updated from\nthe well known one-dimensional dependence into a general two-dimensional form,\nand contribution from each soliton along observer's line of sight (LOS) has\nbeen added to reproduce the pulsar emission. The outflowing plasma is formed by\nsparking discharges above the stellar surface that are located within\nconcentric rings resembling the core-cone emission beam, and uniform\ndistribution of solitons along any LOS has been assumed. The observed effects\nof radius to frequency mapping, where the lower frequency emission originates\nfrom higher altitudes, is seen in this setup. The power law spectrum and\nrelative steepening of the core spectra with respect to the cones also emerges.\nThe estimated polarization position angle reflects the geometrical\nconfiguration of pulsars as expected. These studies demonstrate the efficacy of\ncoherent curvature radiation from charged solitons to reproduce the average\nobservational features of pulsars.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-16T15:12:51Z"}
{"aid":"http://arxiv.org/abs/2504.12164v1","title":"Analysis of steady-state solutions to a vasculogenesis model in\n  dimension two","summary":"We investigate the steady state solutions of a vasculogenesis model governed\nby coupled partial differential equations in a bounded two dimensional domain.\nExplicit steady state solutions are analytically constructed, and their\nstability is rigorously analyzed under prescribed initial and boundary\nconditions. By employing the energy method, we prove that these solutions\nexhibit local asymptotic stability when specific parametric criteria are\nsatisfied. The analysis establishes a direct connection between the stability\nthresholds and the system's diffusion coefficient, offering quantitative\ninsights into the mechanisms governing pattern formation. These results provide\nfoundational theoretical advances for understanding self organization in\nchemotaxis-driven biological systems, particularly vasculogenesis.","main_category":"math.AP","categories":"math.AP","published":"2025-04-16T15:18:02Z"}
{"aid":"http://arxiv.org/abs/2504.12185v1","title":"SALAD: Improving Robustness and Generalization through Contrastive\n  Learning with Structure-Aware and LLM-Driven Augmented Data","summary":"In various natural language processing (NLP) tasks, fine-tuning Pre-trained\nLanguage Models (PLMs) often leads to the issue of spurious correlations, which\nnegatively impacts performance, particularly when dealing with\nout-of-distribution data. To address this problem, we propose SALAD}(Structure\nAware and LLM-driven Augmented Data), a novel approach designed to enhance\nmodel robustness and generalization by generating structure-aware and\ncounterfactually augmented data for contrastive learning. Our method leverages\na tagging-based approach to generate structure-aware positive samples and\nutilizes large language models (LLMs) to generate counterfactual negative\nsamples with diverse sentence patterns. By applying contrastive learning, SALAD\nenables the model to focus on learning the structural relationships between key\nsentence components while minimizing reliance on spurious correlations. We\nvalidate our approach through experiments on three tasks: Sentiment\nClassification, Sexism Detection, and Natural Language Inference. The results\ndemonstrate that SALAD not only improves model robustness and performance\nacross different environments but also enhances generalization to\nout-of-distribution datasets and cross-domain scenarios.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-16T15:40:10Z"}
{"aid":"http://arxiv.org/abs/2504.12187v1","title":"What Do Large Language Models Know? Tacit Knowledge as a Potential\n  Causal-Explanatory Structure","summary":"It is sometimes assumed that Large Language Models (LLMs) know language, or\nfor example that they know that Paris is the capital of France. But what -- if\nanything -- do LLMs actually know? In this paper, I argue that LLMs can acquire\ntacit knowledge as defined by Martin Davies (1990). Whereas Davies himself\ndenies that neural networks can acquire tacit knowledge, I demonstrate that\ncertain architectural features of LLMs satisfy the constraints of semantic\ndescription, syntactic structure, and causal systematicity. Thus, tacit\nknowledge may serve as a conceptual framework for describing, explaining, and\nintervening on LLMs and their behavior.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-16T15:42:33Z"}
{"aid":"http://arxiv.org/abs/2504.12188v1","title":"Nonequilibrium physics of brain dynamics","summary":"Information processing in the brain is coordinated by the dynamic activity of\nneurons and neural populations at a range of spatiotemporal scales. These\ndynamics, captured in the form of electrophysiological recordings and\nneuroimaging, show evidence of time-irreversibility and broken detailed balance\nsuggesting that the brain operates in a nonequilibrium stationary state.\nFurthermore, the level of nonequilibrium, measured by entropy production or\nirreversibility appears to be a crucial signature of cognitive complexity and\nconsciousness. The subsequent study of neural dynamics from the perspective of\nnonequilibrium statistical physics is an emergent field that challenges the\nassumptions of symmetry and maximum-entropy that are common in traditional\nmodels. In this review, we discuss the plethora of exciting results emerging at\nthe interface of nonequilibrium dynamics and neuroscience. We begin with an\nintroduction to the mathematical paradigms necessary to understand\nnonequilibrium dynamics in both continuous and discrete state-spaces. Next, we\nreview both model-free and model-based approaches to analysing nonequilibrium\ndynamics in both continuous-state recordings and neural spike-trains, as well\nas the results of such analyses. We briefly consider the topic of\nnonequilibrium computation in neural systems, before concluding with a\ndiscussion and outlook on the field.","main_category":"q-bio.NC","categories":"q-bio.NC,cond-mat.dis-nn,cond-mat.stat-mech,math.DS","published":"2025-04-16T15:43:35Z"}
{"aid":"http://arxiv.org/abs/2504.12218v1","title":"Accountable Liveness","summary":"Safety and liveness are the two classical security properties of consensus\nprotocols. Recent works have strengthened safety with accountability: should\nany safety violation occur, a sizable fraction of adversary nodes can be proven\nto be protocol violators. This paper studies to what extent analogous\naccountability guarantees are achievable for liveness. To reveal the full\ncomplexity of this question, we introduce an interpolation between the\nclassical synchronous and partially-synchronous models that we call the\n$x$-partially-synchronous network model in which, intuitively, at most an $x$\nfraction of the time steps in any sufficiently long interval are asynchronous\n(and, as with a partially-synchronous network, all time steps are synchronous\nfollowing the passage of an unknown \"global stablization time\"). We prove a\nprecise characterization of the parameter regime in which accountable liveness\nis achievable: if and only if $x < 1/2$ and $f < n/2$, where $n$ denotes the\nnumber of nodes and $f$ the number of nodes controlled by an adversary. We\nfurther refine the problem statement and our analysis by parameterizing by the\nnumber of violating nodes identified following a liveness violation, and\nprovide evidence that the guarantees achieved by our protocol are near-optimal\n(as a function of $x$ and $f$). Our results provide rigorous foundations for\nliveness-accountability heuristics such as the \"inactivity leaks\" employed in\nEthereum.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-16T16:13:09Z"}
{"aid":"http://arxiv.org/abs/2504.12230v1","title":"Suppression of composition g-modes in chemically-equilibrating warm\n  neutron stars","summary":"We investigate the impact of chemical equilibration and the resulting bulk\nviscosity on non-radial oscillation modes of warm neutron stars at temperatures\nup to T~5 MeV, relevant for protoneutron stars and neutron-star post-merger\nremnants. In this regime, the relaxation rate of weak interactions becomes\ncomparable to the characteristic frequencies of composition g-modes in the\ncore, resulting in resonant damping. To capture this effect, we introduce the\ndynamic sound speed, a complex, frequency-dependent generalization of the\nadiabatic sound speed that encodes both the restoring force and the dissipative\neffects of bulk compression. Using realistic weak reaction rates and three\nrepresentative equations of state, we compute the complex frequencies of\ncomposition g-modes with finite-temperature profiles. We find that bulk viscous\ndamping becomes increasingly significant with temperature and can completely\nsuppress composition g-modes. In contrast, the f-mode remains largely\nunaffected by bulk viscosity due to its nearly divergence-free character. Our\nresults highlight the sensitivity of g-mode behavior to thermal structure, weak\nreaction rates, and the equation of state, and establish the dynamic sound\nspeed as a valuable descriptor characterizing oscillation properties in\ndissipative neutron star matter.","main_category":"astro-ph.HE","categories":"astro-ph.HE,gr-qc,nucl-th","published":"2025-04-16T16:27:50Z"}
{"aid":"http://arxiv.org/abs/2504.12254v1","title":"Advancing Arabic Speech Recognition Through Large-Scale Weakly\n  Supervised Learning","summary":"Automatic speech recognition (ASR) is crucial for human-machine interaction\nin diverse applications like conversational agents, industrial robotics, call\ncenter automation, and automated subtitling. However, developing\nhigh-performance ASR models remains challenging, particularly for low-resource\nlanguages like Arabic, due to the scarcity of large, labeled speech datasets,\nwhich are costly and labor-intensive to produce. In this work, we employ weakly\nsupervised learning to train an Arabic ASR model using the Conformer\narchitecture. Our model is trained from scratch on 15,000 hours of weakly\nannotated speech data covering both Modern Standard Arabic (MSA) and Dialectal\nArabic (DA), eliminating the need for costly manual transcriptions. Despite the\nabsence of human-verified labels, our approach attains state-of-the-art (SOTA)\nperformance, exceeding all previous efforts in the field of Arabic ASR on the\nstandard benchmarks. By demonstrating the effectiveness of weak supervision as\na scalable, cost-efficient alternative to traditional supervised approaches,\npaving the way for improved ASR systems in low resource settings.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-16T17:05:14Z"}
{"aid":"http://arxiv.org/abs/2504.12261v1","title":"Dependency Dilemmas: A Comparative Study of Independent and Dependent\n  Artifacts in Maven Central Ecosystem","summary":"The Maven Central ecosystem forms the backbone of Java dependency management,\nhosting artifacts that vary significantly in their adoption, security, and\necosystem roles. Artifact reuse is fundamental in software development, with\necosystems like Maven Central facilitating this process. However, prior studies\npredominantly analyzed popular artifacts with numerous dependencies, leaving\nthose without incoming dependencies (independent artifacts) unexplored. In this\nstudy, we analyzed 658,078 artifacts, of which 635,003 had at least one\nrelease. Among these, 93,101 artifacts (15.4%) were identified as independent\n(in-degree = 0), while the rest were classified as dependent. We looked at the\nimpact of separate artifacts using PageRank and out-degree centrality and\ndiscovered that they were very important to the ecosystem. Further analysis\nacross 18 different metrics revealed several advantages and comparability of\nindependent artifacts with dependent artifacts: comparable popularity (25.58\nvs. 7.30), fewer vulnerabilities (60 CVEs vs. 179 CVEs), and zero propagated\nvulnerabilities. Based on these results, it seems that independent artifacts\nmake a big difference in the ecosystem and give developers a safe,\nself-contained alternative to traditional dependencies. These findings suggest\nthat independent artifacts might be a beneficial choice for dependencies but\nhave some maintainability issues. Therefore, developers should carefully\nincorporate independent artifacts into their projects, and artifact maintainers\nshould prioritize this group of artifacts to mitigate the risk of transitive\nvulnerability propagation and improve software sustainability.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-16T17:15:58Z"}
{"aid":"http://arxiv.org/abs/2504.12269v1","title":"SEROAISE: Advancing ROA Estimation for ReLU and PWA Dynamics through\n  Estimating Certified Invariant Sets","summary":"This paper presents a novel framework for constructing the Region of\nAttraction (RoA) for dynamics derived either from Piecewise Affine (PWA)\nfunctions or from Neural Networks (NNs) with Rectified Linear Units (ReLU)\nactivation function. This method, described as Sequential Estimation of RoA\nbased on Invariant Set Estimation (SEROAISE), computes a Lyapunov-like PWA\nfunction over a certified PWA invariant set. While traditional approaches\nsearch for Lyapunov functions by enforcing Lyapunov conditions over\npre-selected domains, this framework enforces Lyapunov-like conditions over a\ncertified invariant subset obtained using the Iterative Invariant Set\nEstimator(IISE). Compared to the state-of-the-art, IISE provides systematically\nlarger certified invariant sets. In order to find a larger invariant subset,\nthe IISE utilizes a novel concept known as the Non-Uniform Growth of Invariant\nSet (NUGIS). A number of examples illustrating the efficacy of the proposed\nmethods are provided, including dynamical systems derived from learning\nalgorithms. The implementation is publicly available at:\nhttps://github.com/PouyaSamanipour/SEROAISE.git.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-16T17:31:47Z"}
{"aid":"http://arxiv.org/abs/2504.12271v1","title":"On the effective magnetostrictive properties of anisotropic\n  magneto-active elastomers in the small-deformation limit","summary":"Magneto-active elastomers (MAEs) are composite materials comprising an\nelastomer matrix with embedded magnetic particles, endowing the composite with\ncoupled effective magneto-mechanical responses. It is widely reported that\nanisotropic MAEs exhibit much stronger magneto-mechanical coupling than\nisotropic MAEs. However, most efforts to model effective magneto-mechanical\nproperties of MAEs via homogenization focused on isotropic microstructures or\nthose with large separations between particles, to use analytical solutions. In\nthis work, we introduce a periodic homogenization approach to compute effective\nmagneto-mechanical properties of anisotropic MAEs, and analyze microstructural\nfeatures that enhance the magneto-mechanical coupling. Using the finite element\nmethod, we numerically determine the effect of particle shape, gap, and voids\non the effective stiffness, permeability, and magneto-mechanical coupling\ntensors for chain-like periodic microstructures. Using insights gained from the\nfull-field simulations, we derive an analytical expression for the\nmagneto-mechanical coupling in the chain direction, in terms of the volume\nfraction, gap size, and properties of the matrix and particles. Results show\nthat the overall magnetostriction of anisotropic MAEs is most sensitive to the\ngap between particles and the waviness of the particle chains, with smaller gap\nsizes and straighter chains yielding higher overall magnetostriction.\nSimulations also show that while isotropic MAEs elongate in a uniform magnetic\nfield, anisotropic MAEs contract with much larger strain amplitudes, a result\nof the attractive forces between particles being much stronger in anisotropic\nMAEs than in isotropic MAEs. Results provide fundamental insights into the\nmechanisms that govern magneto-mechanical coupling in anisotropic MAEs, and\nconstitute a toolbox of homogenized MAE material properties.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-16T17:32:29Z"}
{"aid":"http://arxiv.org/abs/2504.12292v1","title":"SHeaP: Self-Supervised Head Geometry Predictor Learned via 2D Gaussians","summary":"Accurate, real-time 3D reconstruction of human heads from monocular images\nand videos underlies numerous visual applications. As 3D ground truth data is\nhard to come by at scale, previous methods have sought to learn from abundant\n2D videos in a self-supervised manner. Typically, this involves the use of\ndifferentiable mesh rendering, which is effective but faces limitations. To\nimprove on this, we propose SHeaP (Self-supervised Head Geometry Predictor\nLearned via 2D Gaussians). Given a source image, we predict a 3DMM mesh and a\nset of Gaussians that are rigged to this mesh. We then reanimate this rigged\nhead avatar to match a target frame, and backpropagate photometric losses to\nboth the 3DMM and Gaussian prediction networks. We find that using Gaussians\nfor rendering substantially improves the effectiveness of this self-supervised\napproach. Training solely on 2D data, our method surpasses existing\nself-supervised approaches in geometric evaluations on the NoW benchmark for\nneutral faces and a new benchmark for non-neutral expressions. Our method also\nproduces highly expressive meshes, outperforming state-of-the-art in emotion\nclassification.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-16T17:55:02Z"}
{"aid":"http://arxiv.org/abs/2504.12607v1","title":"Solving Constrained Combinatorial Optimization Problems with Variational\n  Quantum Imaginary Time Evolution","summary":"Solving combinatorial optimization problems using variational quantum\nalgorithms (VQAs) has emerged as a promising research direction. Since the\nintroduction of the Quantum Approximate Optimization Algorithm (QAOA), numerous\nvariants have been proposed to enhance its performance. QAOA was later extended\nto the Quantum Alternating Operator Ansatz (QAOA+), which generalizes the\ninitial state, phase-separation operator, and mixer to address constrained\nproblems without relying on the standard Quadratic Unconstrained Binary\nOptimization (QUBO) formulation. However, QAOA+ often requires additional\nancilla qubits and a large number of multi-controlled Toffoli gates to prepare\nthe superposition of feasible states, resulting in deep circuits that are\nchallenging for near-term quantum devices. Furthermore, VQAs are generally\nhindered by issues such as barren plateaus and suboptimal local minima.\nRecently, Quantum Imaginary Time Evolution (QITE), a ground-state preparation\nalgorithm, has been explored as an alternative to QAOA and its variants. QITE\nhas demonstrated improved performance in quantum chemistry problems and has\nbeen applied to unconstrained combinatorial problems such as Max-Cut. In this\nwork, we apply the variational form of QITE (VarQITE) to solve the Multiple\nKnapsack Problem (MKP), a constrained problem, using a Max-Cut-tailored ansatz.\nTo the best of our knowledge, this is the first attempt to address constrained\noptimization using VarQITE. We show that VarQITE achieves significantly lower\nmean optimality gaps compared to QAOA and other conventional methods. Moreover,\nwe demonstrate that scaling the Hamiltonian coefficients can further reduce\noptimization costs and accelerate convergence.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T03:09:37Z"}
{"aid":"http://arxiv.org/abs/2504.12621v1","title":"Revisiting multifunctionality in reservoir computing","summary":"Multifunctionality is ubiquitous in biological neurons. Several studies have\ntranslated the concept to artificial neural networks as well. Recently,\nmultifunctionality in reservoir computing (RC) has gained the widespread\nattention of researchers. Multistable dynamics of the reservoir can be\nconfigured to capture multiple tasks, each by one of the co-existing\nattractors. However, there are several limitations in the applicability of this\napproach. So far, multifunctional RC has been shown to be able to reconstruct\ndifferent attractor climates only when the attractors are well separated in the\nphase space. We propose a more flexible reservoir computing scheme capable of\nmultifunctioning beyond the earlier limitations. The proposed architecture\nholds striking similarity with the multifunctional biological neural networks\nand showcases superior performance. It is capable of learning multiple chaotic\nattractors with overlapping phase space. We successfully train the RC to\nachieve multifunctionality with wide range of tasks.","main_category":"nlin.CD","categories":"nlin.CD","published":"2025-04-17T03:54:08Z"}
{"aid":"http://arxiv.org/abs/2504.12643v1","title":"RoPETR: Improving Temporal Camera-Only 3D Detection by Integrating\n  Enhanced Rotary Position Embedding","summary":"This technical report introduces a targeted improvement to the StreamPETR\nframework, specifically aimed at enhancing velocity estimation, a critical\nfactor influencing the overall NuScenes Detection Score. While StreamPETR\nexhibits strong 3D bounding box detection performance as reflected by its high\nmean Average Precision our analysis identified velocity estimation as a\nsubstantial bottleneck when evaluated on the NuScenes dataset. To overcome this\nlimitation, we propose a customized positional embedding strategy tailored to\nenhance temporal modeling capabilities. Experimental evaluations conducted on\nthe NuScenes test set demonstrate that our improved approach achieves a\nstate-of-the-art NDS of 70.86% using the ViT-L backbone, setting a new\nbenchmark for camera-only 3D object detection.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T05:05:31Z"}
{"aid":"http://arxiv.org/abs/2504.12647v1","title":"Equitable coloring of graphs beyond planarity","summary":"An equitable coloring of a graph is a proper coloring where the sizes of any\ntwo different color classes do not differ by more than one. A graph is\nIC-planar if it can be drawn in the plane so that no two crossed edges have a\ncommon endpoint, and is NIC-planar graphs if it can be embedded in the plane in\nsuch a way that no two pairs of crossed edges share two endpoints. Zhang proved\nthat every IC-planar graph with maximum degree $\\Delta\\geq 12$ and every\nNIC-planar graph with maximum degree $\\Delta\\geq 13$ have equitable\n$\\Delta$-colorings. In this paper, we reduce the threshold from 12 to 10 for\nIC-planar graphs and from 13 to 11 for NIC-planar graphs.","main_category":"math.CO","categories":"math.CO","published":"2025-04-17T05:18:23Z"}
{"aid":"http://arxiv.org/abs/2504.12659v1","title":"Topologically Directed Simulations Reveal the Impact of Geometric\n  Constraints on Knotted Proteins","summary":"Simulations of knotting and unknotting in polymers or other filaments rely on\nrandom processes to facilitate topological changes. Here we introduce a method\nof \\textit{topological steering} to determine the optimal pathway by which a\nfilament may knot or unknot while subject to a given set of physics. The method\ninvolves measuring the knotoid spectrum of a space curve projected onto many\nsurfaces and computing the mean unravelling number of those projections.\nSeveral perturbations of a curve can be generated stochastically, e.g. using\nthe Langevin equation or crankshaft moves, and a gradient can be followed that\nmaximises or minimises the topological complexity. We apply this method to a\npolymer model based on a growing self-avoiding tangent-sphere chain, which can\nbe made to model proteins by imposing a constraint that the bending and\ntwisting angles between successive spheres must maintain the distribution found\nin naturally occurring protein structures. We show that without these\nprotein-like geometric constraints, topologically optimised polymers typically\nform alternating torus knots and composites thereof, similar to the stochastic\nknots predicted for long DNA. However, when the geometric constraints are\nimposed on the system, the frequency of twist knots increases, similar to the\nobserved abundance of twist knots in protein structures.","main_category":"math.GT","categories":"math.GT,cond-mat.soft,cond-mat.stat-mech,q-bio.BM","published":"2025-04-17T05:39:30Z"}
{"aid":"http://arxiv.org/abs/2504.12682v1","title":"WebLists: Extracting Structured Information From Complex Interactive\n  Websites Using Executable LLM Agents","summary":"Most recent web agent research has focused on navigation and transaction\ntasks, with little emphasis on extracting structured data at scale. We present\nWebLists, a benchmark of 200 data-extraction tasks across four common business\nand enterprise use-cases. Each task requires an agent to navigate to a webpage,\nconfigure it appropriately, and extract complete datasets with well-defined\nschemas. We show that both LLMs with search capabilities and SOTA web agents\nstruggle with these tasks, with a recall of 3% and 31%, respectively, despite\nhigher performance on question-answering tasks.\n  To address this challenge, we propose BardeenAgent, a novel framework that\nenables web agents to convert their execution into repeatable programs, and\nreplay them at scale across pages with similar structure. BardeenAgent is also\nthe first LLM agent to take advantage of the regular structure of HTML. In\nparticular BardeenAgent constructs a generalizable CSS selector to capture all\nrelevant items on the page, then fits the operations to extract the data.\n  On the WebLists benchmark, BardeenAgent achieves 66% recall overall, more\nthan doubling the performance of SOTA web agents, and reducing cost per output\nrow by 3x.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-17T06:16:40Z"}
{"aid":"http://arxiv.org/abs/2504.12693v1","title":"Counting degree-constrained orientations","summary":"We study the enumeration of graph orientations under local degree\nconstraints. Given a finite graph $G = (V, E)$ and a family of admissible sets\n$\\{\\mathsf P_v \\subseteq \\mathbb{Z} : v \\in V\\}$, let $\\mathcal N (G; \\prod_{v\n\\in V} \\mathsf P_v)$ denote the number of orientations in which the out-degree\nof each vertex $v$ lies in $P_v$. We prove a general duality formula expressing\n$\\mathcal N(G; \\prod_{v \\in V} \\mathsf P_v)$ as a signed sum over edge subsets,\ninvolving products of coefficient sums associated with $\\{\\mathsf P_v\\}_{v \\in\nV}$, from a family of polynomials. Our approach employs gauge transformations,\na technique rooted in statistical physics and holographic algorithms. We also\npresent a probabilistic derivation of the same identity, interpreting the\norientation-generating polynomial as the expectation of a random polynomial\nproduct. As applications, we obtain explicit formulas for the number of even\norientations and for mixed Eulerian-even orientations on general graphs. Our\nformula generalizes a result of Borb\\'enyi and Csikv\\'ari on Eulerian\norientations of graphs.","main_category":"math.CO","categories":"math.CO","published":"2025-04-17T06:40:50Z"}
{"aid":"http://arxiv.org/abs/2504.12706v1","title":"Thermodynamic formalism for non-uniform systems with controlled\n  specification and entropy expansiveness","summary":"We study thermodynamic formalism of dynamical systems with non-uniform\nstructure. Precisely, we obtain the uniqueness of equilibrium states for a\nfamily of non-uniformly expansive flows by generalizing Climenhaga-Thompson's\norbit decomposition criteria. In particular, such family includes entropy\nexpansive flows. Meanwhile, the essential part of the decomposition is allowed\nto satisfy an even weaker version of specification, namely controlled\nspecification, thus also extends the corresponding results by Pavlov.\n  Two applications of our abstract theorems are explored. Firstly, we introduce\na notion of regularity condition called weak Walters condition, and study the\nuniqueness of measure of maximal entropy for a suspension flow with roof\nfunction satisfying such condition. Secondly, we investigate topologically\ntransitive frame flows on rank one manifolds of nonpositive curvature, which is\na group extension of nonuniformly hyperbolic flows. Under a bunched curvature\ncondition and running a Gauss-Bonnet type of argument, we show the uniqueness\nof equilibrium states with respect to certain potentials.","main_category":"math.DS","categories":"math.DS","published":"2025-04-17T07:22:00Z"}
{"aid":"http://arxiv.org/abs/2504.12710v1","title":"Quantum circuit synthesis with qudit phase gadget method","summary":"Current quantum devices have unutilized high-level quantum resources. More\nand more attention has been paid to the qudit quantum systems with larger than\ntwo dimensions to maximize the potential computing power of quantum\ncomputation. Then, a natural problem arises: How do we implement quantum\nalgorithms on qudit quantum systems? In this work, we propose a novel qudit\nphase gadget method for synthesizing the qudit diagonal unitary matrices. This\nmethod is suitable for the Noisy Intermediate-Scale Quantum (NISQ) and\nfault-tolerant eras due to its versatility in different connectivity\narchitectures and the optimality of its resource consumption. The method can\nwork on any connectivity architecture with asymptotic optimal circuit depth and\nsize. For a 10-qutrit diagonal unitary, our algorithm reduces the circuit depth\nform about 100000 to 500 with 300 ancillary qutrits. Further, this method can\nbe promoted to different quantum circuit synthesis problems, such as quantum\nstate preparation problems, general unitary synthesis problems, etc.","main_category":"quant-ph","categories":"quant-ph,cs.ET","published":"2025-04-17T07:26:33Z"}
{"aid":"http://arxiv.org/abs/2504.12720v1","title":"Malicious Code Detection in Smart Contracts via Opcode Vectorization","summary":"With the booming development of blockchain technology, smart contracts have\nbeen widely used in finance, supply chain, Internet of things and other fields\nin recent years. However, the security problems of smart contracts become\nincreasingly prominent. Security events caused by smart contracts occur\nfrequently, and the existence of malicious codes may lead to the loss of user\nassets and system crash. In this paper, a simple study is carried out on\nmalicious code detection of intelligent contracts based on machine learning.\nThe main research work and achievements are as follows: Feature extraction and\nvectorization of smart contract are the first step to detect malicious code of\nsmart contract by using machine learning method, and feature processing has an\nimportant impact on detection results. In this paper, an opcode vectorization\nmethod based on smart contract text is adopted. Based on considering the\nstructural characteristics of contract opcodes, the opcodes are classified and\nsimplified. Then, N-Gram (N=2) algorithm and TF-IDF algorithm are used to\nconvert the simplified opcodes into vectors, and then put into the machine\nlearning model for training. In contrast, N-Gram algorithm and TF-IDF algorithm\nare directly used to quantify opcodes and put into the machine learning model\ntraining. Judging which feature extraction method is better according to the\ntraining results. Finally, the classifier chain is applied to the intelligent\ncontract malicious code detection.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-17T07:51:48Z"}
{"aid":"http://arxiv.org/abs/2504.12735v1","title":"The Athenian Academy: A Seven-Layer Architecture Model for Multi-Agent\n  Systems","summary":"This paper proposes the \"Academy of Athens\" multi-agent seven-layer\nframework, aimed at systematically addressing challenges in multi-agent systems\n(MAS) within artificial intelligence (AI) art creation, such as collaboration\nefficiency, role allocation, environmental adaptation, and task parallelism.\nThe framework divides MAS into seven layers: multi-agent collaboration,\nsingle-agent multi-role playing, single-agent multi-scene traversal,\nsingle-agent multi-capability incarnation, different single agents using the\nsame large model to achieve the same target agent, single-agent using different\nlarge models to achieve the same target agent, and multi-agent synthesis of the\nsame target agent. Through experimental validation in art creation, the\nframework demonstrates its unique advantages in task collaboration, cross-scene\nadaptation, and model fusion. This paper further discusses current challenges\nsuch as collaboration mechanism optimization, model stability, and system\nsecurity, proposing future exploration through technologies like meta-learning\nand federated learning. The framework provides a structured methodology for\nmulti-agent collaboration in AI art creation and promotes innovative\napplications in the art field.","main_category":"cs.MA","categories":"cs.MA,cs.AI","published":"2025-04-17T08:21:28Z"}
{"aid":"http://arxiv.org/abs/2504.12736v1","title":"Incorporating a Deep Neural Network into Moving Horizon Estimation for\n  Embedded Thermal Torque Derating of an Electric Machine","summary":"This study introduces a novel state estimation framework that incorporates\nDeep Neural Networks (DNNs) into Moving Horizon Estimation (MHE), shifting from\ntraditional physics-based models to rapidly developed data-driven techniques. A\nDNN model with Long Short-Term Memory (LSTM) nodes is trained on synthetic data\ngenerated by a high-fidelity thermal model of a Permanent Magnet Synchronous\nMachine (PMSM), which undergoes thermal derating as part of the torque control\nstrategy in a battery electric vehicle. The MHE is constructed by integrating\nthe trained DNN with a simplified driving dynamics model in a discrete-time\nformulation, incorporating the LSTM hidden and cell states in the state vector\nto retain system dynamics. The resulting optimal control problem (OCP) is\nformulated as a nonlinear program (NLP) and implemented using the acados\nframework. Model-in-the-loop (MiL) simulations demonstrate accurate temperature\nestimation, even under noisy sensor conditions or failures. Achieving threefold\nreal-time capability on embedded hardware confirms the feasibility of the\napproach for practical deployment. The primary focus of this study is to assess\nthe feasibility of the MHE framework using a DNN-based plant model instead of\nfocusing on quantitative comparisons of vehicle performance. Overall, this\nresearch highlights the potential of DNN-based MHE for real-time,\nsafety-critical applications by combining the strengths of model-based and\ndata-driven methods.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-17T08:24:32Z"}
{"aid":"http://arxiv.org/abs/2504.12755v1","title":"Trajectory Adaptation using Large Language Models","summary":"Adapting robot trajectories based on human instructions as per new situations\nis essential for achieving more intuitive and scalable human-robot\ninteractions. This work proposes a flexible language-based framework to adapt\ngeneric robotic trajectories produced by off-the-shelf motion planners like\nRRT, A-star, etc, or learned from human demonstrations. We utilize pre-trained\nLLMs to adapt trajectory waypoints by generating code as a policy for dense\nrobot manipulation, enabling more complex and flexible instructions than\ncurrent methods. This approach allows us to incorporate a broader range of\ncommands, including numerical inputs. Compared to state-of-the-art\nfeature-based sequence-to-sequence models which require training, our method\ndoes not require task-specific training and offers greater interpretability and\nmore effective feedback mechanisms. We validate our approach through simulation\nexperiments on the robotic manipulator, aerial vehicle, and ground robot in the\nPybullet and Gazebo simulation environments, demonstrating that LLMs can\nsuccessfully adapt trajectories to complex human instructions.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-17T08:48:23Z"}
{"aid":"http://arxiv.org/abs/2504.12771v1","title":"Classification-Based Analysis of Price Pattern Differences Between\n  Cryptocurrencies and Stocks","summary":"Cryptocurrencies are digital tokens built on blockchain technology, with\nthousands actively traded on centralized exchanges (CEXs). Unlike stocks, which\nare backed by real businesses, cryptocurrencies are recognized as a distinct\nclass of assets by researchers. How do investors treat this new category of\nasset in trading? Are they similar to stocks as an investment tool for\ninvestors? We answer these questions by investigating cryptocurrencies' and\nstocks' price time series which can reflect investors' attitudes towards the\ntargeted assets. Concretely, we use different machine learning models to\nclassify cryptocurrencies' and stocks' price time series in the same period and\nget an extremely high accuracy rate, which reflects that cryptocurrency\ninvestors behave differently in trading from stock investors. We then extract\nfeatures from these price time series to explain the price pattern difference,\nincluding mean, variance, maximum, minimum, kurtosis, skewness, and first to\nthird-order autocorrelation, etc., and then use machine learning methods\nincluding logistic regression (LR), random forest (RF), support vector machine\n(SVM), etc. for classification. The classification results show that these\nextracted features can help to explain the price time series pattern difference\nbetween cryptocurrencies and stocks.","main_category":"q-fin.ST","categories":"q-fin.ST","published":"2025-04-17T09:12:27Z"}
{"aid":"http://arxiv.org/abs/2504.12774v1","title":"Phase field model of Coulomb explosion damage in solid induced by\n  ultrashort laser","summary":"Much experimental evidence reveals that Coulomb explosion governs non-thermal\nmaterial removal under femtosecond or even shorter laser pulses, and\nnon-thermal laser damage has been a topic widely discussed. Nevertheless, there\nis still no continuum mechanical model capable of describing the evolution of\nsuch damage. In this study, we develop a model that characterizes solid damage\nthrough a phase field variable governed by Allen-Cahn dynamics. The parameter\nof the model is defined by a conceptual mechanism: during Coulomb explosion,\nelectron pressure surpasses the interatomic barrier potential, dissociates\nmaterial from the solid surface as small equivalent particles and resulting in\nlocalized damage. The numerical simulation validates the model's availability\nand demonstrate its ability to predict damage morphology under varying laser\nconditions. This work advances the understanding of non-thermal ablation and\nprovides a tool for optimizing ultrafast laser processing.","main_category":"physics.optics","categories":"physics.optics,cond-mat.other,physics.comp-ph","published":"2025-04-17T09:16:41Z"}
{"aid":"http://arxiv.org/abs/2504.12787v1","title":"Counting Irreducible Representations of a Finite Abelian Group","summary":"Let $q$ be a power of a prime $p$, $G$ be a finite abelian group, where $p$\ndoes not divide $|G|$,and let $n$ be a positive integer. In this paper we find\na formula for the number of irreducible representations of $G$ of a given\ndimension $n$ over the field of order $q$, up to equivalence, using Brauer\ncharacters. We also provide a formula for such $n$ using the prime\ndecomposition of the exponent of $G$ and an algorithm to compute the\nirreducible degrees and their multiplicities.","main_category":"math.GR","categories":"math.GR","published":"2025-04-17T09:34:05Z"}
{"aid":"http://arxiv.org/abs/2504.12807v1","title":"Hybrid Dense-UNet201 Optimization for Pap Smear Image Segmentation Using\n  Spider Monkey Optimization","summary":"Pap smear image segmentation is crucial for cervical cancer diagnosis.\nHowever, traditional segmentation models often struggle with complex cellular\nstructures and variations in pap smear images. This study proposes a hybrid\nDense-UNet201 optimization approach that integrates a pretrained DenseNet201 as\nthe encoder for the U-Net architecture and optimizes it using the spider monkey\noptimization (SMO) algorithm. The Dense-UNet201 model excelled at feature\nextraction. The SMO was modified to handle categorical and discrete parameters.\nThe SIPaKMeD dataset was used in this study and evaluated using key performance\nmetrics, including loss, accuracy, Intersection over Union (IoU), and Dice\ncoefficient. The experimental results showed that Dense-UNet201 outperformed\nU-Net, Res-UNet50, and Efficient-UNetB0. SMO Dense-UNet201 achieved a\nsegmentation accuracy of 96.16%, an IoU of 91.63%, and a Dice coefficient score\nof 95.63%. These findings underscore the effectiveness of image preprocessing,\npretrained models, and metaheuristic optimization in improving medical image\nanalysis and provide new insights into cervical cell segmentation methods.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-17T10:14:05Z"}
{"aid":"http://arxiv.org/abs/2504.12845v1","title":"Can LLMs reason over extended multilingual contexts? Towards\n  long-context evaluation beyond retrieval and haystacks","summary":"Existing multilingual long-context benchmarks, often based on the popular\nneedle-in-a-haystack test, primarily evaluate a model's ability to locate\nspecific information buried within irrelevant texts. However, such a\nretrieval-centric approach is myopic and inherently limited, as successful\nrecall alone does not indicate a model's capacity to reason over extended\ncontexts. Moreover, these benchmarks are susceptible to data leakage,\nshort-circuiting, and risk making the evaluation a priori identifiable. To\naddress these limitations, we introduce MLRBench, a new synthetic benchmark for\nmultilingual long-context reasoning. Unlike existing benchmarks, MLRBench goes\nbeyond surface-level retrieval by including tasks that assess multi-hop\ninference, aggregation, and epistemic reasoning. Spanning seven languages,\nMLRBench is designed to be parallel, resistant to leakage, and scalable to\narbitrary context lengths. Our extensive experiments with an open-weight large\nlanguage model (LLM) reveal a pronounced gap between high- and low-resource\nlanguages, particularly for tasks requiring the model to aggregate multiple\nfacts or predict the absence of information. We also find that, in multilingual\nsettings, LLMs effectively utilize less than 30% of their claimed context\nlength. Although off-the-shelf Retrieval Augmented Generation helps alleviate\nthis to a certain extent, it does not solve the long-context problem. We\nopen-source MLRBench to enable future research in improved evaluation and\ntraining of multilingual LLMs.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-17T11:02:35Z"}
{"aid":"http://arxiv.org/abs/2504.12857v1","title":"A note on distance-hereditary graphs whose complement is also\n  distance-hereditary","summary":"Distance-hereditary graphs are known to be the graphs that are totally\ndecomposable for the split decomposition. We characterise distance-hereditary\ngraphs whose complement is also distance-hereditary by their split\ndecomposition and by their modular decomposition.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-17T11:29:10Z"}
{"aid":"http://arxiv.org/abs/2504.12859v1","title":"Enhancing Decentralization in Blockchain Decision-Making Through\n  Quadratic Voting and Its Generalization","summary":"This study explores the application of Quadratic Voting (QV) and its\ngeneralization to improve decentralization and effectiveness in blockchain\ngovernance systems. The conducted research identified three main types of\nquadratic (square root) voting. Two of them pertain to voting with a split\nstake, and one involves voting without splitting. In split stakes, Type 1 QV\napplies the square root to the total stake before distributing it among\npreferences, while Type 2 QV distributes the stake first and then applies the\nsquare root. In unsplit stakes (Type 3 QV), the square root of the total stake\nis allocated entirely to each preference. The presented formal proofs confirm\nthat Types 2 and 3 QV, along with generalized models, enhance decentralization\nas measured by the Gini and Nakamoto coefficients. A pivotal discovery is the\nexistence of a threshold stakeholder whose relative voting ratio increases\nunder QV compared to linear voting, while smaller stakeholders also gain\ninfluence. The generalized QV model allows flexible adjustment of this\nthreshold, enabling tailored decentralization levels. Maintaining fairness, QV\nensures that stakeholders with higher stakes retain a proportionally greater\nvoting ratio while redistributing influence to prevent excessive concentration.\nIt is shown that to preserve fairness and robustness, QV must be implemented\nalongside privacy-preserving cryptographic voting protocols, as voters casting\ntheir ballots last could otherwise manipulate outcomes. The generalized QV\nmodel, proposed in this paper, enables algorithmic parametrization to achieve\ndesired levels of decentralization for specific use cases. This flexibility\nmakes it applicable across diverse domains, including user interaction with\ncryptocurrency platforms, facilitating community events and educational\ninitiatives, and supporting charitable activities through decentralized\ndecision-making.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-17T11:36:32Z"}
{"aid":"http://arxiv.org/abs/2504.12884v1","title":"TOI-3493 b: A planet with a Neptune-like density transiting a bright\n  G0-type star","summary":"We report the discovery of TOI-3493 b, a sub-Neptune-sized planet on an\n8.15-d orbit transiting the bright (V=9.3) G0 star HD 119355 (aka TIC\n203377303) initially identified by NASA's TESS space mission. With the aim of\nconfirming the planetary nature of the transit signal detected by TESS and\ndetermining the mass of the planet, we performed an intensive Doppler campaign\nwith the HARPS spectrograph, collecting radial velocity measurements. We found\nthat TOI-3493 b lies in a nearly circular orbit and has a mass of 9.0+/-1.2\nM_earth and a radius of 3.22+/-0.08 R_earth, implying a bulk density of\n1.47+/-0.23 g/cm^3, consistent with a composition comprising a small solid core\nsurrounded by a thick H/He dominated atmosphere.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-04-17T12:20:27Z"}
{"aid":"http://arxiv.org/abs/2504.12891v1","title":"Are AI agents the new machine translation frontier? Challenges and\n  opportunities of single- and multi-agent systems for multilingual digital\n  communication","summary":"The rapid evolution of artificial intelligence (AI) has introduced AI agents\nas a disruptive paradigm across various industries, yet their application in\nmachine translation (MT) remains underexplored. This paper describes and\nanalyses the potential of single- and multi-agent systems for MT, reflecting on\nhow they could enhance multilingual digital communication. While single-agent\nsystems are well-suited for simpler translation tasks, multi-agent systems,\nwhich involve multiple specialized AI agents collaborating in a structured\nmanner, may offer a promising solution for complex scenarios requiring high\naccuracy, domain-specific knowledge, and contextual awareness. To demonstrate\nthe feasibility of multi-agent workflows in MT, we are conducting a pilot study\nin legal MT. The study employs a multi-agent system involving four specialized\nAI agents for (i) translation, (ii) adequacy review, (iii) fluency review, and\n(iv) final editing. Our findings suggest that multi-agent systems may have the\npotential to significantly improve domain-adaptability and contextual\nawareness, with superior translation quality to traditional MT or single-agent\nsystems. This paper also sets the stage for future research into multi-agent\napplications in MT, integration into professional translation workflows, and\nshares a demo of the system analyzed in the paper.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.ET,cs.HC","published":"2025-04-17T12:32:18Z"}
{"aid":"http://arxiv.org/abs/2504.12896v1","title":"Performance guarantees of light-cone variational quantum algorithms for\n  the maximum cut problem","summary":"Variational quantum algorithms (VQAs) are promising to demonstrate the\nadvantage of near-term quantum computing over classical computing in practical\napplications, such as the maximum cut (MaxCut) problem. However, current VQAs\nsuch as the quantum approximate optimization algorithm (QAOA) have lower\nperformance guarantees compared to the best-known classical algorithm, and\nsuffer from hard optimization processes due to the barren plateau problem. We\npropose a light-cone VQA by choosing an optimal gate sequence of the standard\nVQAs, which enables a significant improvement in solution accuracy while\navoiding the barren plateau problem. Specifically, we prove that the light-cone\nVQA with one round achieves an approximation ratio of 0.7926 for the MaxCut\nproblem in the worst case of $3$-regular graphs, which is higher than that of\nthe 3-round QAOA, and can be further improved to 0.8333 by an angle-relaxation\nprocedure. Finally, these performance guarantees are verified by numerical\nsimulations and hardware demonstrations on IBM quantum devices. In a 72-qubit\ndemonstration, the single-round light-cone VQA achieves the exact MaxCut\nsolution whereas the $p$-round QAOA with $p=1,2,3$ only obtains approximate\nsolutions. Furthermore, the single-round light-cone VQA derives solutions\nsurpassing the hardness threshold in a 148-qubit demonstration while QAOA with\n$p=1,2,3$ does not. Our work highlights a promising route towards solving\npractical and classically hard problems on near-term quantum devices.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T12:38:16Z"}
{"aid":"http://arxiv.org/abs/2504.12899v1","title":"Tree-NeRV: A Tree-Structured Neural Representation for Efficient\n  Non-Uniform Video Encoding","summary":"Implicit Neural Representations for Videos (NeRV) have emerged as a powerful\nparadigm for video representation, enabling direct mappings from frame indices\nto video frames. However, existing NeRV-based methods do not fully exploit\ntemporal redundancy, as they rely on uniform sampling along the temporal axis,\nleading to suboptimal rate-distortion (RD) performance. To address this\nlimitation, we propose Tree-NeRV, a novel tree-structured feature\nrepresentation for efficient and adaptive video encoding. Unlike conventional\napproaches, Tree-NeRV organizes feature representations within a Binary Search\nTree (BST), enabling non-uniform sampling along the temporal axis.\nAdditionally, we introduce an optimization-driven sampling strategy,\ndynamically allocating higher sampling density to regions with greater temporal\nvariation. Extensive experiments demonstrate that Tree-NeRV achieves superior\ncompression efficiency and reconstruction quality, outperforming prior uniform\nsampling-based methods. Code will be released.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T12:40:33Z"}
{"aid":"http://arxiv.org/abs/2504.12924v1","title":"The Monge--Kantorovich problem, the Schur--Horn theorem, and the\n  diffeomorphism group of the annulus","summary":"First, we analyze the discrete Monge--Kantorovich problem, linking it with\nthe minimization problem of linear functionals over adjoint orbits. Second, we\nconsider its generalization to the setting of area preserving diffeomorphisms\nof the annulus. In both cases, we show how the problem can be linked to\npermutohedra, majorization, and to gradient flows with respect to a suitable\nmetric.","main_category":"math.OC","categories":"math.OC","published":"2025-04-17T13:15:26Z"}
{"aid":"http://arxiv.org/abs/2504.12930v1","title":"Performance of the advanced gamma-ray trigger system for the High Energy\n  Cosmic Radiation Detection (HERD) facility","summary":"The High Energy Cosmic-Radiation Detection (HERD) facility has been proposed\nas a leading experiment on China's Space Station (CSS). Scheduled for\ninstallation around 2027, HERD is expected to operate for at least a decade.\nThe main scientific objectives include indirect detection of dark matter with\nunprecedented sensitivity, studying the cosmic-ray spectrum and composition up\nto the knee, and observing all-sky gamma rays with energies above 100 MeV. HERD\nis designed as a large-acceptance telescope with a unique design aimed at\nmaximizing its efficiency. It comprises a central 3D imaging calorimeter (CALO)\nmade of LYSO crystals, encircled by four complementary subdetectors on its top\nand four lateral faces: the scintillating fiber tracking detector (FIT), the\nplastic scintillator detector (PSD), the silicon charge detector (SCD), and a\ntransition radiation detector (TRD) on one lateral side. To fully harness HERD\ngamma-ray detection capabilities down to 100 MeV, an advanced ultra-low-energy\ngamma-ray (ULEG) trigger system has been developed. We present an extensive\noverview of the design, performance, and optimization of the gamma-ray trigger\nsystem supported by software simulations and preliminary results from the\nsuccessful implementation of the HERD prototype at CERN's PS and SPS beam test\ncampaigns in Fall 2023.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-17T13:27:54Z"}
{"aid":"http://arxiv.org/abs/2504.12935v1","title":"Dynamical relationship between CAR algebras and determinantal point\n  processes: point processes at finite temperature and stochastically positive\n  KMS systems","summary":"The aim of this paper is threefold. Firstly, we develop the author's previous\nwork on the dynamical relationship between determinantal point processes and\nCAR algebras. Secondly, we present a novel application of the theory of\nstochastic processes associated with KMS states for CAR algebras and their\nquasi-free states. Lastly, we propose a unified theory of algebraic\nconstructions and analysis of stationary processes on point configuration\nspaces with respect to determinantal point processes. As a byproduct, we\nestablish an algebraic derivation of a determinantal formula for space-time\ncorrelations of stochastic processes, and we analyze several limiting behaviors\nof these processes.","main_category":"math.PR","categories":"math.PR,math-ph,math.MP,math.OA","published":"2025-04-17T13:31:09Z"}
{"aid":"http://arxiv.org/abs/2504.12936v1","title":"Relative magnetic helicity under turbulent relaxation","summary":"Magnetic helicity is a quantity that underpins many theories of magnetic\nrelaxation in electrically conducting fluids, both laminar and turbulent.\nAlthough much theoretical effort has been expended on magnetic fields that are\neverywhere tangent to their domain boundaries, many applications, both in\nastrophysics and laboratories, actually involve magnetic fields that are\nline-tied to the boundary, i.e. with a non-trivial normal component on the\nboundary. This modification of the boundary condition requires a modification\nof magnetic helicity, whose suitable replacement is called relative magnetic\nhelicity. In this work, we investigate rigorously the behaviour of relative\nmagnetic helicity under turbulent relaxation. In particular, we specify the\nnormal component of the magnetic field on the boundary and consider the\n\\emph{ideal limit} of resistivity tending to zero in order to model the\nturbulent evolution in the sense of Onsager's theory of turbulence. We show\nthat relative magnetic helicity is conserved in this distinguished limit and\nthat, for constant viscosity, the magnetic field can relax asymptotically to a\nmagnetohydrostatic equilibrium.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph,math.AP","published":"2025-04-17T13:34:24Z"}
{"aid":"http://arxiv.org/abs/2504.12954v1","title":"Phenomenology of Inverse Seesaw Using $S_3$ Modular Symmetry","summary":"Describing neutrino masses using the inverse seesaw mechanism with discrete\nflavor symmetry imposed through modular forms provides a testable framework at\nTeV scales with fewer parameters. However, $S_3$, the smallest modular group,\nremains relatively underexplored. In this work, we construct the minimal\nsupersymmetric inverse seesaw model based on the modular $S_3$ flavor symmetry.\nIn our model, the light neutrino mass matrix depends on 6 real parameters: the\ncomplex modulus, an overall scale for light neutrino mass, a real ratio and a\ncomplex ratio of Yukawa coupling. Thanks to its minimality, our model offers\nvarious definite predictions: the lightest neutrino is massless, the neutrino\nmasses are inverted ordering, the sum of the three light neutrino masses\n($\\sum_i m_i$) is 100 meV, the effective mass for the end point of the beta\ndecay spectrum is 50 meV, the effective mass for neutrinoless double beta decay\n($m_{ee}$) is in the range $38-58$ meV. In particular, the predicted values for\n$\\sum_i m_i$ and $m_{ee}$ from our model are within reach of the next\ngeneration experiments. Our model also predicts radiative lepton flavor\nviolating decays $\\ell\\to\\ell'\\gamma$ which are compatible with experimental\nconstraints.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-17T13:58:43Z"}
{"aid":"http://arxiv.org/abs/2504.12957v1","title":"Cavity-enhanced spectroscopy of individual nuclear spins in a dense bath","summary":"Echo-based spectroscopy of the superhyperfine interaction of an electronic\nspin with nuclear spins in its surroundings enables detailed insights into the\nmicroscopic magnetic environment of spins in solids. Still, it is an\noutstanding challenge to resolve individual nuclear spins in a dense bath, in\nwhich many of them exhibit a comparable coupling strength. This simultaneously\nrequires a high spectral resolution and a large signal-to-noise ratio. However,\nwhen probing spin ensembles, dipolar interactions between the dopants can lead\nto a concentration-dependent trade-off between resolution and signal. Here, we\nfully eliminate this limitation of previous optical-echo-envelope-modulation\nspectroscopy experiments by integrating the emitters into a high-finesse\nresonator, which allows for strong optical echoes even at very low\nconcentrations. To demonstrate its potential, the technique is applied to\nerbium dopants in yttrium-orthosilicate (Er:YSO). Achieving an unprecedented\nspectral resolution enables precise measurements of the superhyperfine\ninteraction with four of the Y nuclear spins densely surrounding each emitter.\nThe achieved boost of the signal, enabled by the resonator, allows for\nextending the approach to the lowest concentration possible -- to the level of\nsingle dopants, thereby providing a tool for detecting and studying individual\nnuclear spins. Thus, our technique paves the way for an improved understanding\nof dense nuclear spin baths in solids.","main_category":"quant-ph","categories":"quant-ph,cond-mat.other","published":"2025-04-17T14:03:10Z"}
{"aid":"http://arxiv.org/abs/2504.12979v1","title":"Weizsäcker-Williams Gluon Helicity Distribution and Inclusive Dijet\n  Production in Longitudinally Polarized Electron-Proton Collisions","summary":"It is well-known that the back-to-back (correlation) limit of inclusive\nquark-antiquark dijet production in unpolarized high energy electron-proton\ncollisions can probe the Weizs\\\"{a}cker-Williams (WW) gluon transverse\nmomentum-dependent distribution (TMD) at small $x$ \\cite{Dominguez:2010xd,\nDominguez:2011wm}. In this paper, we consider a helicity-dependent version of\nthe same process: we study the double-spin asymmetry for inclusive\nquark-antiquark dijet production in longitudinally polarized electron-proton\nscattering at high energies. We show that in the back-to-back limit this\nprocess probes the WW gluon helicity TMD. Furthermore, we derive the small-$x$\nevolution equation for the operator related to the WW gluon helicity\ndistribution. We find that in the double-logarithmic approximation and in the\nlarge-$N_c$ limit, the small-$x$ asymptotics of the WW gluon helicity\ndistribution is governed by exactly the same evolution equation as that for the\ndipole gluon helicity distribution. The longitudinal double-spin asymmetry for\ninclusive dijet production in the longitudinally polarized electron-proton\ncollisions can thus test the small-$x$ helicity evolution equations and\nfacilitate constraining the initial conditions for phenomenology based on these\nequations.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-17T14:32:05Z"}
{"aid":"http://arxiv.org/abs/2504.12985v1","title":"Accurate Modeling of LEGO-like vdW Heterostructures: Integrating Machine\n  Learned with Anisotropic Interlayer Potentials","summary":"Accurately modeling the structural reconstruction and thermodynamic behavior\nof van der Waals (vdW) heterostructures remains a significant challenge due to\nthe limitations of conventional force fields in capturing their complex\nmechanical, thermal, electronic, and tribological properties. To address these\nlimitations, we develop a hybrid framework that combines single-layer\nmachine-learned potential ($s$MLP) with physics-based anisotropic interlayer\npotential (ILP), effectively decoupling intralayer and interlayer interactions.\nThis $s$MLP+ILP approach modularizes the modeling of vdW heterostructures like\nassembling LEGOs, reducing the required training configurations by at least an\norder of magnitude compared to the pure MLP approach, while retaining\npredictive accuracy and computational efficiency. We validate our framework by\naccurately reproducing the mechanical properties of graphite, and resolving\nintricate Moir\\'e patterns in graphene/$h$-BN bilayers and\ngraphene/graphene/$h$-BN trilayer heterostructures, achieving excellent\nagreement with experimental observations. Leveraging the developed $s$MLP+ILP\napproach, we reveal the stacking order-dependent formation of Moir\\'e\nsuperlattice in trilayer graphene/$h$-BN/MoS$_2$ heterostructures,\ndemonstrating its ability to accurately model large-scale vdW systems\ncomprising hundreds of thousands of atoms with near $ab$ $initio$ precision.\nThese findings demonstrate that hybrid $s$MLP+ILP framework remarkably\noutperforms existing pure machine-learned or empirical potentials, offering a\nscalable and transferable solution for accurately and extensively modeling\ncomplex vdW materials across diverse applications, including sliding\nferroelectricity, thermal management, resistive switching, and superlubric\nnanodevices.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-04-17T14:47:59Z"}
{"aid":"http://arxiv.org/abs/2504.12997v1","title":"All-in-One Transferring Image Compression from Human Perception to\n  Multi-Machine Perception","summary":"Efficiently transferring Learned Image Compression (LIC) model from human\nperception to machine perception is an emerging challenge in vision-centric\nrepresentation learning. Existing approaches typically adapt LIC to downstream\ntasks in a single-task manner, which is inefficient, lacks task interaction,\nand results in multiple task-specific bitstreams. To address these limitations,\nwe propose an asymmetric adaptor framework that supports multi-task adaptation\nwithin a single model. Our method introduces a shared adaptor to learn general\nsemantic features and task-specific adaptors to preserve task-level\ndistinctions. With only lightweight plug-in modules and a frozen base codec,\nour method achieves strong performance across multiple tasks while maintaining\ncompression efficiency. Experiments on the PASCAL-Context benchmark demonstrate\nthat our method outperforms both Fully Fine-Tuned and other Parameter Efficient\nFine-Tuned (PEFT) baselines, and validating the effectiveness of multi-vision\ntransferring.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T15:06:52Z"}
{"aid":"http://arxiv.org/abs/2504.13003v1","title":"Towards Optimal Distributed Edge Coloring with Small Palettes","summary":"We design a deterministic distributed $\\mathcal{O}(\\log n)$-round reduction\nfrom the $(2\\Delta-2)$-edge coloring problem to the much easier\n$(2\\Delta-1)$-edge coloring problem. This is almost optimal, as the\n$(2\\Delta-2)$-edge coloring problem admits an $\\Omega(\\log_\\Delta n)$ lower\nbound. Further, we also obtain an optimal $\\mathcal{O}(\\log_\\Delta n)$-round\nreduction, albeit to the harder maximal independent set (MIS) problem.\n  The current state-of-the-art for $(2\\Delta - 1)$-edge coloring actually comes\nfrom an MIS algorithm by [Ghaffari \\& Grunau, FOCS'24], which runs in\n$\\widetilde{\\mathcal{O}}(\\log^{5/3} n)$ rounds. With our new reduction, this\nround complexity now carries over to the $(2\\Delta - 2)$-edge coloring problem\nas well. Alternatively, one can also plug in the $(\\mathrm{poly} \\log \\Delta +\n\\mathcal{O}(\\log^{\\ast} n))$-round $(2\\Delta - 1)$-edge coloring algorithm from\n[Balliu, Brandt, Kuhn \\& Olivetti, PODC'22], which yields an optimal runtime of\n$\\mathcal{O}(\\log n)$ rounds for $\\Delta \\leq \\mathrm{poly} \\log n$.\nPreviously, the fastest deterministic algorithm using less than $2\\Delta - 1$\ncolors for general graphs by [Brandt, Maus, Narayanan, Schager \\& Uitto,\nSODA'25] ran in $\\widetilde{\\mathcal{O}}(\\log^3 n)$ rounds. In addition, we\nalso obtain a $\\mathcal{O}(\\log \\log n)$-round randomized reduction of\n$(2\\Delta - 2)$-edge coloring to $(2\\Delta - 1)$-edge coloring. This improves\nupon the (very recent) best randomized algorithm using less than $2\\Delta - 1$\ncolors from [Bourreau, Brandt \\& Nolin, STOC'25] by reducing the round\ncomplexity from $\\widetilde{\\mathcal{O}}(\\log^{8/3}\\log n)$ down to\n$\\widetilde{\\mathcal{O}}(\\log^{5/3} \\log n)$.","main_category":"cs.DS","categories":"cs.DS,cs.DC","published":"2025-04-17T15:13:20Z"}
{"aid":"http://arxiv.org/abs/2504.13053v1","title":"Quantitative Resolvent and Eigenfunction Stability for the Faber-Krahn\n  Inequality","summary":"For a bounded open set $\\Omega \\subset \\mathbb{R}^n$ with the same volume as\nthe unit ball, the classical Faber-Krahn inequality says that the first\nDirichlet eigenvalue $\\lambda_1(\\Omega)$ of the Laplacian is at least that of\nthe unit ball $B$. We prove that the deficit $\\lambda_1(\\Omega)- \\lambda_1(B)$\nin the Faber-Krahn inequality controls the square of the distance between the\nresolvent operator $(-\\Delta_\\Omega)^{-1}$ for the Dirichlet Laplacian on\n$\\Omega$ and the resolvent operator on the nearest unit ball $B(x_\\Omega)$. The\ndistance is measured by the operator norm from $C^{0,\\alpha}$ to $L^2$. As a\nmain application, we show that the Faber-Krahn deficit $\\lambda_1(\\Omega)-\n\\lambda_1(B)$ controls the squared $L^2$ norm between $k$th eigenfunctions on\n$\\Omega$ and $B(x_\\Omega)$ for every $k \\in \\mathbb{N}.$ In both of these main\ntheorems, the quadratic power is optimal.","main_category":"math.AP","categories":"math.AP","published":"2025-04-17T16:09:26Z"}
{"aid":"http://arxiv.org/abs/2504.13079v1","title":"Retrieval-Augmented Generation with Conflicting Evidence","summary":"Large language model (LLM) agents are increasingly employing\nretrieval-augmented generation (RAG) to improve the factuality of their\nresponses. However, in practice, these systems often need to handle ambiguous\nuser queries and potentially conflicting information from multiple sources\nwhile also suppressing inaccurate information from noisy or irrelevant\ndocuments. Prior work has generally studied and addressed these challenges in\nisolation, considering only one aspect at a time, such as handling ambiguity or\nrobustness to noise and misinformation. We instead consider multiple factors\nsimultaneously, proposing (i) RAMDocs (Retrieval with Ambiguity and\nMisinformation in Documents), a new dataset that simulates complex and\nrealistic scenarios for conflicting evidence for a user query, including\nambiguity, misinformation, and noise; and (ii) MADAM-RAG, a multi-agent\napproach in which LLM agents debate over the merits of an answer over multiple\nrounds, allowing an aggregator to collate responses corresponding to\ndisambiguated entities while discarding misinformation and noise, thereby\nhandling diverse sources of conflict jointly. We demonstrate the effectiveness\nof MADAM-RAG using both closed and open-source models on AmbigDocs -- which\nrequires presenting all valid answers for ambiguous queries -- improving over\nstrong RAG baselines by up to 11.40% and on FaithEval -- which requires\nsuppressing misinformation -- where we improve by up to 15.80% (absolute) with\nLlama3.3-70B-Instruct. Furthermore, we find that RAMDocs poses a challenge for\nexisting RAG baselines (Llama3.3-70B-Instruct only obtains 32.60 exact match\nscore). While MADAM-RAG begins to address these conflicting factors, our\nanalysis indicates that a substantial gap remains especially when increasing\nthe level of imbalance in supporting evidence and misinformation.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T16:46:11Z"}
{"aid":"http://arxiv.org/abs/2504.13080v1","title":"Instability and stress fluctuations of a probe driven through a\n  worm-like micellar fluid","summary":"A particle moving through a worm-like micellar fluid (WLM) shows instability\nand large fluctuations beyond a threshold. Despite many detailed studies, a\ndirect measurement of the time-dependent stress on the probe particle remains\nunexplored. To address this, we have designed a measuring geometry coupled with\na commercial rheometer to study the dynamics of a cylindrical probe through a\nWLM system of 2 wt.\\% cetyltrimethyl ammonium tosylate(CTAT) + 100 mM sodium\nchloride(NaCl) for a wide range of velocity and stress scales. We map out the\nin-situ velocity distribution using particle imaging velocimetry. Beyond a\ncertain velocity threshold, we observe large stress fluctuation events with\ngradual stress build-up followed by sudden stress drop indicating the storage\nand release of elastic energy. The length scale constructed from the stress\nbuild-up time scale and the probe's velocity match the length scale of\nextensile deformation in the sample just before the stress drop, further\nconfirming the strong correlation of such storage and release of energy with\nthe unstable motion of the probe. Interestingly, despite their significant\ndifference in magnitudes, the Weissenberg number ($Wi$) for the onset of flow\ninstability obtained from the shear and extensile components remains almost the\nsame. We also find that the turbulent motion of the probe at higher $Wi$\nresults from the complex mixing of the stick-slip events originating from the\npartial release of the stored elastic energy. Further, we show that the\nmagnitude of the stick-slip events depends on the detailed micellar structure\nand dynamics controlled by salt concentration and temperature.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-17T16:46:19Z"}
{"aid":"http://arxiv.org/abs/2504.13083v1","title":"Feedforward suppression of readout-induced faults in quantum error\n  correction","summary":"We propose a method to reduce readout-induced faults, applicable in settings\nlike quantum error correction with repeated measurement cycles. The method\nconsists of an adaptive readout sequence conditioned on each check qubit's\nreadout result from the previous cycle. For readout errors and\nmeasurement-induced leakage that are stronger in a particular qubit state, this\nfeedforward protocol can suppress the physical qubit errors. Focusing on a\nsimple realization of conditionally flipping (by an X gate) the state of check\nqubits before their measurement, we investigate the effect of such\nstate-dependent errors using simulations in the setup of a low-density parity\ncheck code. We show that the suggested protocol can reduce both logical errors\nand decoding time, two important aspects of fault-tolerant quantum\ncomputations.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T16:50:26Z"}
{"aid":"http://arxiv.org/abs/2504.14831v1","title":"Supersymmetric Hybrid Inflation in light of Atacama Cosmology Telescope\n  Data Release 6, Planck 2018 and LB-BK18","summary":"Supersymmetry-based hybrid inflation models (referred to as `spontaneously\nbroken supersymmetry' by the Planck collaboration) are attractive for several\nreasons, including the appealing feature that inflation is associated with\nlocal gauge symmetry breaking in the early universe. Following the Planck\ncollaboration's notation, the inflationary potential with sub-Planckian\ninflaton field values is given by: $V = \\Lambda^4 [1 + \\alpha_h \\log(\\phi /\nM_{Pl})] - m_{3/2} \\Lambda^2 \\phi + \\Lambda^4 O((\\phi / M_{Pl})^4)$. Here,\n$\\Lambda = \\sqrt{\\kappa} M$ denotes the energy scale of inflation, $M$ is the\ngauge symmetry breaking scale, $\\kappa$ is a dimensionless parameter that sets\nthe inflaton mass ($\\sqrt{2} \\kappa M$), and $\\alpha_h$ is determined from\nquantum corrections in terms of $\\kappa$ and the underlying gauge group. A soft\nsupersymmetry-breaking term proportional to the gravitino mass $m_{3/2}$ (~10\nTeV) and linear in the inflaton field $\\phi$ is also present during inflation.\nThe final term in $V$ represents the leading-order supergravity correction.\n(Note that the last two terms were not taken into account in the Planck\nanalysis.) We provide estimates for the parameters $\\kappa$ (and $\\alpha_h$)\nthat yield a scalar spectral index $n_s$ in the range 0.96 to 0.98, which is\nfully consistent with recent P-ACT-LB measurements presented by the Atacama\nCosmology Telescope, as well as earlier measurements by Planck. We recall that\nin the absence of the soft SUSY-breaking term proportional to $m_{3/2}$ in $V$,\nthe spectral index $n_s = 1 - 1/N = 0.98$, where $N = 50$ denotes the number of\ne-foldings. The tensor-to-scalar ratio $r$ in this minimal model is tiny, but\nit can reach potentially observable values ($r \\lesssim 0.01$) in non-minimal\nmodels.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-21T03:18:43Z"}
{"aid":"http://arxiv.org/abs/2504.14832v1","title":"Protecting Your Voice: Temporal-aware Robust Watermarking","summary":"The rapid advancement of generative models has led to the synthesis of\nreal-fake ambiguous voices. To erase the ambiguity, embedding watermarks into\nthe frequency-domain features of synthesized voices has become a common\nroutine. However, the robustness achieved by choosing the frequency domain\noften comes at the expense of fine-grained voice features, leading to a loss of\nfidelity. Maximizing the comprehensive learning of time-domain features to\nenhance fidelity while maintaining robustness, we pioneer a\n\\textbf{\\underline{t}}emporal-aware\n\\textbf{\\underline{r}}ob\\textbf{\\underline{u}}st\nwat\\textbf{\\underline{e}}rmarking (\\emph{True}) method for protecting the\nspeech and singing voice.","main_category":"cs.CR","categories":"cs.CR,cs.AI,cs.SD","published":"2025-04-21T03:23:10Z"}
{"aid":"http://arxiv.org/abs/2504.14837v1","title":"SQL-Factory: A Multi-Agent Framework for High-Quality and Large-Scale\n  SQL Generation","summary":"Hight quality SQL corpus is essential for intelligent database. For example,\nText-to-SQL requires SQL queries and correspond natural language questions as\ntraining samples. However, collecting such query corpus remains challenging in\npractice due to the high cost of manual annotation, which highlights the\nimportance of automatic SQL generation. Despite recent advances, existing\ngeneration methods still face limitations in achieving both diversity and\ncost-effectiveness. Besides, many methods also treat all tables equally during\ngeneration, which overlooks schema complexity and leads to under-utilization of\nstructurally rich tables. To address these issues, this paper proposes a\nmulti-agent framework for high-quality and large-scale SQL generation, dubbed\nSQL-Factory. It decomposes the generation process into three collaborative\nteams: the Generation Team explores diverse query structures using large\nlanguage models, the Expansion Team scales promising patterns via lightweight\nlocal models, and the Management Team adaptively schedules and evaluates\ngeneration based on schema coverage and real-time query quality. This modular\nframework ensures a balanced trade-off between diversity, scalability, and\ngeneration cost. We apply SQL-Factory to four widely used benchmarks and\ngenerate over 300,000 executable and broadly distributed SQL queries with less\nthan $200 API cost. Our generated queries achieve higher diversity compared to\nother methods, and extensive experiments demonstrate that the generated queries\nsignificantly improve the model performance in various downstream tasks.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-21T03:37:43Z"}
{"aid":"http://arxiv.org/abs/2504.14880v1","title":"Stratification and Rectifiability of Harmonic Map Flows via Tangent\n  Measures","summary":"In this paper, we investigate the stratification theory for suitable\nsolutions of harmonic map flows based on the spatial symmetry of tangent\nmeasures. Generally, suitable solutions are a category of solutions that\nsatisfy both the localized energy inequality and the monotonicity formula.\nBuilding on the modifications and adjustments of quantitative stratifications\nand Reifenberg-rectifiable theory by Naber and Valtorta, we confirm that each\nstratum in our model is rectifiable. We also establish an estimate for the\nMinkowski content of the singular set at each time slice, demonstrating that\nthe singular set is rectifiable and that our results strengthen previous\nfindings, which were limited to almost every time slice. Furthermore, under\ncertain assumptions about the target manifolds that exclude specific tangent\nflows and measures, our analysis achieves substantial improvements in the\nregularity of suitable solutions for harmonic map flows.","main_category":"math.AP","categories":"math.AP,math.DG","published":"2025-04-21T06:16:09Z"}
{"aid":"http://arxiv.org/abs/2504.14888v1","title":"WMKA-Net: A Weighted Multi-Kernel Attention NetworkMethod for Retinal\n  Vessel Segmentation","summary":"We propose a novel retinal vessel segmentation network, the Weighted\nMulti-Kernel Attention Network (WMKA-Net), which aims to address the issues of\ninsufficient multiscale feature capture, loss of contextual information, and\nnoise sensitivity in retinal vessel segmentation. WMKA-Net significantly\nimproves the segmentation performance of small vessels and low-contrast regions\nby integrating several innovative components, including the MultiKernelFeature\nFusion Module (MKDC), the Progressive Feature Weighting Fusion Strategy (UDFF),\nand the Attention Mechanism Module (AttentionBlock). The MKDC module employs\nmultiscale parallel convolutional kernels to extract vessel characteristics,\nthereby enhancing the ability to capture complex vascular structures. The UDFF\nstrategy optimizes the transmission of feature information by weighted fusion\nof high- and low-level features. The AttentionBlock highlights key regions and\nsuppresses noise interference through the attention mechanism. Experimental\nresults demonstrate that WMKA-Net achieves excellent segmentation performance\nin multiple public datasets, particularly in segmentation of small vessels and\nprocessing of pathological regions. This work provides a robust and efficient\nnew method for segmentation of the retinal vessel.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T06:32:25Z"}
{"aid":"http://arxiv.org/abs/2504.14908v1","title":"The universality of filamentation-caused challenges of ultrafast laser\n  energy deposition in semiconductors","summary":"Light propagation in semiconductors is the cornerstone of emerging disruptive\ntechnologies holding considerable potential to revolutionize\ntelecommunications, sensors, quantum engineering, healthcare, and artificial\nintelligence. Sky-high optical nonlinearities make these materials ideal\nplatforms for photonic integrated circuits. The fabrication of such complex\ndevices could greatly benefit from in-volume ultrafast laser writing for\nmonolithic and contactless integration. Ironically, as exemplified for Si,\nnonlinearities act as an efficient immune system self-protecting the material\nfrom internal permanent modifications that ultrashort laser pulses could\npotentially produce. While nonlinear propagation of high-intensity ultrashort\nlaser pulses has been extensively investigated in Si, other semiconductors\nremain uncharted. In this work, we demonstrate that filamentation universally\ndictates ultrashort laser pulse propagation in various semiconductors. The\neffective key nonlinear parameters obtained strongly differ from standard\nmeasurements with low-intensity pulses. Furthermore, the temporal scaling laws\nfor these key parameters are extracted. Temporal-spectral shaping is finally\nproposed to optimize energy deposition inside semiconductors. The whole set of\nresults lays the foundations for future improvements, up to the point where\nsemiconductors can be selectively tailored internally by ultrafast laser\nwriting, thus leading to countless applications for in-chip processing and\nfunctionalization, and opening new markets in various sectors including\ntechnology, photonics, and semiconductors.","main_category":"physics.optics","categories":"physics.optics,nlin.AO,nlin.PS,physics.app-ph,physics.plasm-ph","published":"2025-04-21T07:25:48Z"}
{"aid":"http://arxiv.org/abs/2504.14936v1","title":"Giving AI a voice: how does AI think it should be treated?","summary":"With the astounding progress in (generative) artificial intelligence (AI),\nthere has been significant public discourse regarding regulation and ethics of\nthe technology. Is it sufficient when humans discuss this with other humans?\nOr, given that AI is increasingly becoming a viable source of inspiration for\npeople (and let alone the hypothetical possibility that the technology may at\nsome point become \"artificial general intelligence\" and/or develop\nconsciousness), should AI not join the discourse? There are new questions and\nangles that AI brings to the table that we might not have considered before -\nso let us make the key subject of this book an active participant. This chapter\ntherefore includes a brief human-AI conversation on the topic of AI rights and\nethics.","main_category":"cs.CY","categories":"cs.CY,cs.AI","published":"2025-04-21T07:59:17Z"}
{"aid":"http://arxiv.org/abs/2504.14939v1","title":"Full Discretization of Stochastic Semilinear Schrödinger equation\n  driven by multiplicative Wiener noise","summary":"In this article, we have analyzed the full discretization of the Stochastic\nsemilinear Schr\\\"{o}dinger equation in a bounded convex polygonal domain driven\nby multiplicative Wiener noise. We use the finite element method for spatial\ndiscretization and the stochastic trigonometric method for time discretization\nand derive a strong convergence rate with respect to both parameters (temporal\nand spatial). Numerical experiments have also been performed to support\ntheoretical bounds.","main_category":"math.NA","categories":"math.NA,cs.NA,math.PR","published":"2025-04-21T08:02:07Z"}
{"aid":"http://arxiv.org/abs/2504.14962v1","title":"A Spectral Splitting Theorem for the $N$-Bakry Émery Ricci tensor","summary":"We extend the spectral generalization of the Cheeger-Gromoll splitting\ntheorem to smooth metric measure space. We show that if a complete non-compact\nweighted Riemannian manifold $(M,g,e^{-f}\\,dvolg)$ of dimension $n\\ge 2$ has at\nleast two ends where $f$ is smooth and bounded. If there is some $N\\in\n(0,\\infty)$ such that $$\\lambda_1(\\gamma \\Delta_f+\\operatorname{Ric}^N_f)\\ge\n0$$ for some $\\gamma<\\left(\\frac{1}{(n-1)\\left(1 + \\frac{n-1}{N}\\right)} +\n\\frac{n-1}{4}\\right)^{-1}$, then $M$ splits isometrically as $\\mathbb{R}\\times\nX$ for some complete Riemannian manifold $X$ with\n$(\\operatorname{Ric}_X)^N_f\\ge 0$. The estimate can recover the spectral\nsplitting result and its sharp constant $\\frac{4}{n-1}$ in\nAntonelli-Pozzetta-Xu and and Catino--Mari--Mastrolia--Roncoroni.","main_category":"math.DG","categories":"math.DG,math.AP","published":"2025-04-21T08:44:32Z"}
{"aid":"http://arxiv.org/abs/2504.14963v1","title":"Speaker Fuzzy Fingerprints: Benchmarking Text-Based Identification in\n  Multiparty Dialogues","summary":"Speaker identification using voice recordings leverages unique acoustic\nfeatures, but this approach fails when only textual data is available. Few\napproaches have attempted to tackle the problem of identifying speakers solely\nfrom text, and the existing ones have primarily relied on traditional methods.\nIn this work, we explore the use of fuzzy fingerprints from large pre-trained\nmodels to improve text-based speaker identification. We integrate\nspeaker-specific tokens and context-aware modeling, demonstrating that\nconversational context significantly boosts accuracy, reaching 70.6% on the\nFriends dataset and 67.7% on the Big Bang Theory dataset. Additionally, we show\nthat fuzzy fingerprints can approximate full fine-tuning performance with fewer\nhidden units, offering improved interpretability. Finally, we analyze ambiguous\nutterances and propose a mechanism to detect speaker-agnostic lines. Our\nfindings highlight key challenges and provide insights for future improvements\nin text-based speaker identification.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.CE,cs.LG,cs.NE","published":"2025-04-21T08:44:33Z"}
{"aid":"http://arxiv.org/abs/2504.14978v1","title":"clusttraj: a solvent-informed clustering tool for molecular modeling","summary":"Clustering techniques are consolidated as a powerful strategy for analyzing\nthe extensive data generated from molecular modeling. In particular, some tools\nhave been developed to cluster configurations from classical simulations with a\nstandard focus on individual units, ranging from small molecules to complex\nproteins. Since the standard approach includes computing the Root Mean Square\nDeviation (RMSD) of atomic positions, accounting for the permutation between\natoms is crucial for optimizing the clustering procedure in the presence of\nidentical molecules. To address this issue, we present the clusttraj program, a\nsolvent-informed clustering package that fixes inflated RMSD values by finding\nthe optimal pairing between configurations. The program combines reordering\nschemes with the Kabsch algorithm to minimize the RMSD of molecular\nconfigurations before running a hierarchical clustering protocol. By\nconsidering evaluation metrics, one can determine the ideal threshold in an\nautomated fashion and compare the different linkage schemes available. The\nprogram capabilities are exemplified by considering solute-solvent systems\nranging from pure water clusters to a solvated protein or a small solute in\ndifferent solvents. As a result, we investigate the dependence on different\nparameters, such as the system size and reordering method, and also the\nrepresentativeness of the cluster medoids for the characterization of optical\nproperties. clusttraj is implemented as a Python library and can be employed to\ncluster generic ensembles of molecular configurations that go beyond\nsolute-solvent systems.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-04-21T09:12:00Z"}
{"aid":"http://arxiv.org/abs/2504.14999v1","title":"On Strong Lefschetz Property of 0-dimensional complete intersections and\n  Veronese varieties","summary":"We show that the Strong Lefschetz Property in degree 1 for a homogeneous\n0-dimensional complete intersection holds if the corresponding associated form,\nthe Macaulay inverse systems, has a non-zero discriminant.","main_category":"math.AG","categories":"math.AG","published":"2025-04-21T09:59:23Z"}
{"aid":"http://arxiv.org/abs/2504.15000v1","title":"Quasilinear problems with mixed local-nonlocal operator and\n  concave-critical nonlinearities: Multiplicity of positive solutions","summary":"We study the existence and multiplicity of positive solutions for the\nfollowing concave-critical problem driven by an operator of mixed order\nobtained by the sum of the classical $p$-Laplacian and of the fractional\n$p$-Laplacian, \\begin{equation}\\tag{$\\mathcal{P}_{\\lambda,\\varepsilon}$}\n  -\\Delta_p u+\\varepsilon(-\\Delta_p)^s u=\\lambda|u|^{q-2}u+|u|^{p^*-2}u\n\\;\\text{ in }\\Omega,\\quad\n  u=0 \\; \\text{ in }\\mathbb{R}^N \\setminus \\Omega, \\end{equation} where\n$\\Omega\\subset\\mathbb{R}^N$ is a bounded open set, $\\epsilon\\in(0,1]$,\n$0<s<1<q<p<N$, and $p^*=\\frac{Np}{N-p}$, and $\\lambda \\in \\mathbb{R}$ is a\nparameter. For $\\lambda \\leq 0$, we show that\n(\\textcolor{blue}{$\\mathcal{P}_{\\lambda,\\varepsilon}$}) has no nontrivial\nsolution. For $\\lambda>0$, we prove Ambrosetti-Brezis-Cerami type results. In\nparticular, we prove the existence of $\\Lambda_\\varepsilon$ such that\n(\\textcolor{blue}{$\\mathcal{P}_{\\lambda,\\varepsilon}$}) has a positive minimal\nsolution for $0<\\lambda<\\Lambda_\\varepsilon$, a positive solution for\n$\\lambda=\\Lambda_\\varepsilon$ and no positive solution for\n$\\lambda>\\Lambda_\\varepsilon$. We also prove the existence of\n$0<\\lambda^\\#\\leq\\Lambda_\\varepsilon$ such that\n(\\textcolor{blue}{$\\mathcal{P}_{\\lambda,\\varepsilon}$}) has at least two\npositive solutions for $\\lambda\\in(0,\\lambda^\\#)$ provided $\\varepsilon$ small\nenough. This extends the recent result of Biagi and Vecchi (Nonlinear Anal. 256\n(2025),113795), Amundsen, et al. (Commun. Pure Appl. Anal., 22(10):3139-3164,\n2023) from $p=2$ to the general $1<p<N$. Additionally, it extends the classical\nresult of Azorero and Peral (Indiana Univ. Math. J., 43(3):947-957, 1994) to\nthe mixed local-nonlocal quasilinear problems. Moreover, our results\ncomplements the multiplicity results for nonnegative solutions in da Silva, et\nal. (J. Differential Equations, 408:494-536, 2024).","main_category":"math.AP","categories":"math.AP","published":"2025-04-21T10:00:07Z"}
{"aid":"http://arxiv.org/abs/2504.15002v1","title":"Enhanced Quark-Loop Contribution to Pure Annihilation Nonleptonic\n  B-meson decays in PQCD approach","summary":"In this study, we conduct an enhanced investigation of pure annihilation-type\ncharmless hadronic B-decays within the framework of the PQCD approach.\nSpecifically, we account for the quark-loop enhanced contribution to various\ndecay processes at the next-to-leading order(NLO) in the strong coupling\nconstant $\\alpha_s$. The NLO amplitudes possess large imaginary parts that have\nsigns opposite to those of the leading-order amplitudes. This cancellation\neffect implies that the NLO contribution does not significantly influence the\nbranching ratios of the processes under consideration. However, the NLO effect\nexplored in this work constitutes an important source of the strong phases in\nthe weak - annihilation non-leptonic $\\bar B_q$-meson decay amplitudes. As a\nresult, it can have a substantial impact on CP - violating observables such as\nthe direct CP asymmetry ${\\cal A}_{\\rm CP}^{\\rm dir}$ and mixing induced CP\nasymmetry ${\\cal A}_{\\rm CP}^{\\rm mix}$. The numerical result evidently\nrevealed that NLO QCD correction significantly enhances both ${\\cal A}_{\\rm\nCP}^{\\rm dir}$ and ${\\cal A}_{\\rm CP}^{\\rm mix}$ of the pure annihilation type\nB decay processes.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-21T10:02:32Z"}
{"aid":"http://arxiv.org/abs/2504.15015v1","title":"Identifying polycentric urban structure using the minimum cycle basis of\n  road network as building blocks","summary":"In a graph, the minimum cycle bases are a set of linearly independent cycles\nthat can be used to represent any cycle within that cycle space of graph. These\nbases are useful in various contexts, including the intricate analysis of\nelectrical networks, structural engineering endeavors, chemical processes and\nsurface reconstruction techniques etc. This study focuses on six cities in\nChina to explore the topological characteristics, the centrality of nodes and\nrobustness of urban road networks based on motif and minimum cycle bases. Some\ninteresting conclusions are obtained: the frequency of motifs containing cycles\nexceeds that of random networks with equivalent degree sequences; the frequency\ndistribution of minimum cycle's length and surface areas obey the power-law\ndistribution. The cycle contribution rate is introduced to investigate the\ncentrality of nodes within road networks, and has a significant impact on the\ntotal number of cycles in the robustness analysis. Finally, we construct two\ntypes of cycle-based dual networks for urban road networks by representing\ncycles as nodes and establishing edges between two cycles sharing a common node\nand edge respectively. The results show that cycle-based dual networks exhibit\nsmall-world and scale-free properties.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-21T10:47:50Z"}
{"aid":"http://arxiv.org/abs/2504.15021v1","title":"Is Intelligence the Right Direction in New OS Scheduling for Multiple\n  Resources in Cloud Environments?","summary":"Making it intelligent is a promising way in System/OS design. This paper\nproposes OSML+, a new ML-based resource scheduling mechanism for co-located\ncloud services. OSML+ intelligently schedules the cache and main memory\nbandwidth resources at the memory hierarchy and the computing core resources\nsimultaneously. OSML+ uses a multi-model collaborative learning approach during\nits scheduling and thus can handle complicated cases, e.g., avoiding resource\ncliffs, sharing resources among applications, enabling different scheduling\npolicies for applications with different priorities, etc. OSML+ can converge\nfaster using ML models than previous studies. Moreover, OSML+ can automatically\nlearn on the fly and handle dynamically changing workloads accordingly. Using\ntransfer learning technologies, we show our design can work well across various\ncloud servers, including the latest off-the-shelf large-scale servers. Our\nexperimental results show that OSML+ supports higher loads and meets QoS\ntargets with lower overheads than previous studies.","main_category":"cs.DC","categories":"cs.DC,cs.LG,cs.PF","published":"2025-04-21T11:09:43Z"}
{"aid":"http://arxiv.org/abs/2504.15038v1","title":"Estimating transformative agreement impact on hybrid open access: A\n  comparative large-scale study using Scopus, Web of Science and open metadata","summary":"This study compares open metadata from hoaddata, an openly available dataset\nbased on Crossref, OpenAlex and the cOAlition S Journal Checker Tool, with\nproprietary bibliometric databases Scopus and Web of Science to estimate the\nimpact of transformative agreements on hybrid open access publishing. Analysing\nover 13,000 hybrid journals between 2019-2023, the research found substantial\ngrowth in open access due to these agreements, although most articles remain\npaywalled. The results were consistent across all three data sources, showing\nstrong correlations in country-level metrics despite differences in journal\ncoverage and metadata availability. By 2023, transformative agreements enabled\nthe majority of open access in hybrid journals, with particularly high adoption\nin European countries. The analysis revealed strong alignment between first and\ncorresponding authorship when measuring agreement uptake by publisher and\ncountry. This comparative approach supports the use of open metadata for\nlarge-scale hybrid open access studies, while using multiple data sources\ntogether provides a more robust understanding of hybrid open access adoption\nthan any single database can offer, overcoming individual limitations in\ncoverage and metadata quality.","main_category":"cs.DL","categories":"cs.DL","published":"2025-04-21T11:48:39Z"}
{"aid":"http://arxiv.org/abs/2504.15039v1","title":"Direct Search Algorithm for Clock Skew Compensation Immune to\n  Floating-Point Precision Loss","summary":"We have been investigating clock skew compensation immune to floating-point\nprecision loss by taking into account the discrete nature of clocks in digital\ncommunication systems; extending Bresenham's line drawing algorithm, we\nconstructed an incremental error algorithm using only integer\naddition/subtraction and comparison. Still, bounding the initial value of the\nclock remains a challenge, which determines the initial condition of the\nalgorithm and thereby its number of iterations. In this letter, we propose a\nnew incremental error algorithm for clock skew compensation, called direct\nsearch, which no longer relies on the bounds on the initial value of the clock.\nThe numerical examples demonstrate that the proposed algorithm can\nsignificantly reduce the number of iterations in comparison to the prior work\nwhile eliminating the effect of floating-point precision loss on clock skew\ncompensation.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-21T11:48:49Z"}
{"aid":"http://arxiv.org/abs/2504.15061v1","title":"Effective Starobinsky pre-inflation","summary":"We consider one-loop corrections to a recently obtained form of Starobinsky\ninflation in Jordan frame to extract information about the initial conditions\nof the universe leading to cosmological inflation. Integrating out graviton\nmodes, we find higher-derivative instabilities that are shown to decay into\nscalarons and causing an effective kinetic-domination stage where the universe\nbehaves as a stiff fluid. Through slow cosmological expansion, the kination\nstage leads to inflation. We find a natural cut-off for the scalaron magnitude\nensuring positivity of the modified kinetic term which matches Planck\nconstraints on inflaton energy density at the pivot scale. We, then, backtrack\nto find that even for arbitrary initial conditions, kination naturally leads to\nthe inflationary epoch without the need for fine-tuning. Modifications to the\nscalar power spectrum are also shown to potentially explain low-$l$ anomaly in\nCMB observations as well as the updated prediction of spectral index\n$\\approx0.9743$ accounting for data from Atacama Cosmology Telescope (ACT).","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-21T12:40:36Z"}
{"aid":"http://arxiv.org/abs/2504.15075v1","title":"Mitigating Degree Bias in Graph Representation Learning with Learnable\n  Structural Augmentation and Structural Self-Attention","summary":"Graph Neural Networks (GNNs) update node representations through message\npassing, which is primarily based on the homophily principle, assuming that\nadjacent nodes share similar features. However, in real-world graphs with\nlong-tailed degree distributions, high-degree nodes dominate message passing,\ncausing a degree bias where low-degree nodes remain under-represented due to\ninadequate messages. The main challenge in addressing degree bias is how to\ndiscover non-adjacent nodes to provide additional messages to low-degree nodes\nwhile reducing excessive messages for high-degree nodes. Nevertheless,\nexploiting non-adjacent nodes to provide valuable messages is challenging, as\nit could generate noisy information and disrupt the original graph structures.\nTo solve it, we propose a novel Degree Fairness Graph Transformer, named\nDegFairGT, to mitigate degree bias by discovering structural similarities\nbetween non-adjacent nodes through learnable structural augmentation and\nstructural self-attention. Our key idea is to exploit non-adjacent nodes with\nsimilar roles in the same community to generate informative edges under our\naugmentation, which could provide informative messages between nodes with\nsimilar roles while ensuring that the homophily principle is maintained within\nthe community. To enable DegFairGT to learn such structural similarities, we\nthen propose a structural self-attention to capture the similarities between\nnode pairs. To preserve global graph structures and prevent graph augmentation\nfrom hindering graph structure, we propose a Self-Supervised Learning task to\npreserve p-step transition probability and regularize graph augmentation.\nExtensive experiments on six datasets showed that DegFairGT outperformed\nstate-of-the-art baselines in degree fairness analysis, node classification,\nand node clustering tasks.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-21T13:03:40Z"}
{"aid":"http://arxiv.org/abs/2504.15087v1","title":"Explicit Lossless Vertex Expanders","summary":"We give the first construction of explicit constant-degree lossless vertex\nexpanders. Specifically, for any $\\varepsilon > 0$ and sufficiently large $d$,\nwe give an explicit construction of an infinite family of $d$-regular graphs\nwhere every small set $S$ of vertices has $(1-\\varepsilon)d|S|$ neighbors\n(which implies $(1-2\\varepsilon)d|S|$ unique-neighbors). Our results also\nextend naturally to construct biregular bipartite graphs of any constant\nimbalance, where small sets on each side have strong expansion guarantees. The\ngraphs we construct admit a free group action, and hence realize new families\nof quantum LDPC codes of Lin and M. Hsieh with a linear time decoding\nalgorithm.\n  Our construction is based on taking an appropriate product of a\nconstant-sized lossless expander with a base graph constructed from Ramanujan\nCayley cubical complexes.","main_category":"math.CO","categories":"math.CO,cs.CC,cs.DM,cs.DS,math.GR","published":"2025-04-21T13:20:37Z"}
{"aid":"http://arxiv.org/abs/2504.15095v1","title":"VistaDepth: Frequency Modulation With Bias Reweighting For Enhanced\n  Long-Range Depth Estimation","summary":"Monocular depth estimation (MDE) aims to predict per-pixel depth values from\na single RGB image. Recent advancements have positioned diffusion models as\neffective MDE tools by framing the challenge as a conditional image generation\ntask. Despite their progress, these methods often struggle with accurately\nreconstructing distant depths, due largely to the imbalanced distribution of\ndepth values and an over-reliance on spatial-domain features. To overcome these\nlimitations, we introduce VistaDepth, a novel framework that integrates\nadaptive frequency-domain feature enhancements with an adaptive\nweight-balancing mechanism into the diffusion process. Central to our approach\nis the Latent Frequency Modulation (LFM) module, which dynamically refines\nspectral responses in the latent feature space, thereby improving the\npreservation of structural details and reducing noisy artifacts. Furthermore,\nwe implement an adaptive weighting strategy that modulates the diffusion loss\nin real-time, enhancing the model's sensitivity towards distant depth\nreconstruction. These innovations collectively result in superior depth\nperception performance across both distance and detail. Experimental\nevaluations confirm that VistaDepth achieves state-of-the-art performance among\ndiffusion-based MDE techniques, particularly excelling in the accurate\nreconstruction of distant regions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T13:30:51Z"}
{"aid":"http://arxiv.org/abs/2504.15101v1","title":"NeuGaze: Reshaping the future BCI","summary":"Traditional brain-computer interfaces (BCIs), reliant on costly\nelectroencephalography or invasive implants, struggle with complex\nhuman-computer interactions due to setup complexity and limited precision. We\npresent NeuGaze, a novel webcam-based system that leverages eye gaze, head\nmovements, and facial expressions to enable intuitive, real-time control using\nonly a standard 30 Hz webcam, often pre-installed in laptops. Requiring minimal\ncalibration, NeuGaze achieves performance comparable to conventional inputs,\nsupporting precise cursor navigation, key triggering via an efficient skill\nwheel, and dynamic gaming interactions, such as defeating formidable opponents\nin first-person games. By harnessing preserved neck-up functionalities in\nmotor-impaired individuals, NeuGaze eliminates the need for specialized\nhardware, offering a low-cost, accessible alternative to BCIs. This paradigm\nempowers diverse applications, from assistive technology to entertainment,\nredefining human-computer interaction for motor-impaired users. Project is at\n\\href{https://github.com/NeuSpeech/NeuGaze}{github.com/NeuSpeech/NeuGaze}.","main_category":"cs.HC","categories":"cs.HC,cs.AI,cs.ET","published":"2025-04-21T13:49:17Z"}
{"aid":"http://arxiv.org/abs/2504.15105v1","title":"A triple-branch network for latent fingerprint enhancement guided by\n  orientation fields and minutiae","summary":"Latent fingerprint enhancement is a critical step in the process of latent\nfingerprint identification. Existing deep learning-based enhancement methods\nstill fall short of practical application requirements, particularly in\nrestoring low-quality fingerprint regions. Recognizing that different regions\nof latent fingerprints require distinct enhancement strategies, we propose a\nTriple Branch Spatial Fusion Network (TBSFNet), which simultaneously enhances\ndifferent regions of the image using tailored strategies. Furthermore, to\nimprove the generalization capability of the network, we integrate orientation\nfield and minutiae-related modules into TBSFNet and introduce a Multi-Level\nFeature Guidance Network (MLFGNet). Experimental results on the MOLF and MUST\ndatasets demonstrate that MLFGNet outperforms existing enhancement algorithms.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-21T13:54:33Z"}
{"aid":"http://arxiv.org/abs/2504.15107v1","title":"Learning via mechanosensitivity and activity in cytoskeletal networks","summary":"In this work we show how a network inspired by a coarse-grained description\nof actomyosin cytoskeleton can learn - in a contrastive learning framework -\nfrom environmental perturbations if it is endowed with mechanosensitive\nproteins and motors. Our work is a proof of principle for how force-sensitive\nproteins and molecular motors can form the basis of a general strategy to learn\nin biological systems. Our work identifies a minimal biologically plausible\nlearning mechanism and also explores its implications for commonly occuring\nphenomenolgy such as adaptation and homeostatis.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.bio-ph","published":"2025-04-21T13:58:29Z"}
{"aid":"http://arxiv.org/abs/2504.15111v1","title":"Electronic stopping cross sections of tungsten to swift ions and\n  comparisons with models","summary":"Accurate stopping power data for tungsten is crucial for ion beam analysis\n(IBA) techniques applied to fusion-related materials. In this work, we present\nnew experimental measurements of the stopping power of tungsten for protons and\nalpha particles, addressing key gaps in fundamental databases. Our results\nprovide a densely spaced dataset, refining the practical uncertainty limits to\napproximately 1.5\\% for protons and 4\\% for alpha particles. We critically\ncompare our findings with semi-empirical and theoretical models, evaluating\ntheir performance in describing the stopping power of tungsten for light\nprojectiles. By improving the accuracy and reliability of stopping power data,\nwe contribute to the enhancement of the applicability of ion-beam methods for\ncharacterizing tungsten in fusion-related research. These findings contribute\nto the refinement of semi-empirical models and support the ongoing efforts to\ndevelop more precise theoretical frameworks for ion-solid interactions in\nhigh-Z materials.","main_category":"cond-mat.other","categories":"cond-mat.other,nucl-ex","published":"2025-04-21T14:03:50Z"}
{"aid":"http://arxiv.org/abs/2504.15121v1","title":"Robust and Real-time Surface Normal Estimation from Stereo Disparities\n  using Affine Transformations","summary":"This work introduces a novel method for surface normal estimation from\nrectified stereo image pairs, leveraging affine transformations derived from\ndisparity values to achieve fast and accurate results. We demonstrate how the\nrectification of stereo image pairs simplifies the process of surface normal\nestimation by reducing computational complexity. To address noise reduction, we\ndevelop a custom algorithm inspired by convolutional operations, tailored to\nprocess disparity data efficiently. We also introduce adaptive heuristic\ntechniques for efficiently detecting connected surface components within the\nimages, further improving the robustness of the method. By integrating these\nmethods, we construct a surface normal estimator that is both fast and\naccurate, producing a dense, oriented point cloud as the final output. Our\nmethod is validated using both simulated environments and real-world stereo\nimages from the Middlebury and Cityscapes datasets, demonstrating significant\nimprovements in real-time performance and accuracy when implemented on a GPU.\nUpon acceptance, the shader source code will be made publicly available to\nfacilitate further research and reproducibility.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T14:19:00Z"}
{"aid":"http://arxiv.org/abs/2504.15134v1","title":"Instance-Adaptive Keypoint Learning with Local-to-Global Geometric\n  Aggregation for Category-Level Object Pose Estimation","summary":"Category-level object pose estimation aims to predict the 6D pose and size of\npreviously unseen instances from predefined categories, requiring strong\ngeneralization across diverse object instances. Although many previous methods\nattempt to mitigate intra-class variations, they often struggle with instances\nexhibiting complex geometries or significant deviations from canonical shapes.\nTo address this challenge, we propose INKL-Pose, a novel category-level object\npose estimation framework that enables INstance-adaptive Keypoint Learning with\nlocal-to-global geometric aggregation. Specifically, our approach first\npredicts semantically consistent and geometric informative keypoints through an\nInstance-Adaptive Keypoint Generator, then refines them with: (1) a Local\nKeypoint Feature Aggregator capturing fine-grained geometries, and (2) a Global\nKeypoint Feature Aggregator using bidirectional Mamba for structural\nconsistency. To enable bidirectional modeling in Mamba, we introduce a Feature\nSequence Flipping strategy that preserves spatial coherence while constructing\nbackward feature sequences. Additionally, we design a surface loss and a\nseparation loss to enforce uniform coverage and spatial diversity in keypoint\ndistribution. The generated keypoints are finally mapped to a canonical space\nfor regressing the object's 6D pose and size. Extensive experiments on\nCAMERA25, REAL275, and HouseCat6D demonstrate that INKL-Pose achieves\nstate-of-the-art performance and significantly outperforms existing methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T14:37:37Z"}
{"aid":"http://arxiv.org/abs/2504.15178v1","title":"Time-Series Analysis on Edge-AI Hardware for Healthcare Monitoring","summary":"This project addresses the need for efficient, real-time analysis of\nbiomedical signals such as electrocardiograms (ECG) and electroencephalograms\n(EEG) for continuous health monitoring. Traditional methods rely on\nlong-duration data recording followed by offline analysis, which is\npower-intensive and delays responses to critical symptoms such as arrhythmia.\nTo overcome these limitations, a time-domain ECG analysis model based on a\nnovel dynamically-biased Long Short-Term Memory (DB-LSTM) neural network is\nproposed. This model supports simultaneous ECG forecasting and classification\nwith high performance-achieving over 98% accuracy and a normalized mean square\nerror below 1e-3 for forecasting, and over 97% accuracy with faster convergence\nand fewer training parameters for classification. To enable edge deployment,\nthe model is hardware-optimized by quantizing weights to INT4 or INT3 formats,\nresulting in only a 2% and 6% drop in classification accuracy during training\nand inference, respectively, while maintaining full accuracy for forecasting.\nExtensive simulations using multiple ECG datasets confirm the model's\nrobustness. Future work includes implementing the algorithm on FPGA and CMOS\ncircuits for practical cardiac monitoring, as well as developing a digital\nhardware platform that supports flexible neural network configurations and\non-chip online training for personalized healthcare applications.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-21T15:40:10Z"}
{"aid":"http://arxiv.org/abs/2504.15179v1","title":"FaceCraft4D: Animated 3D Facial Avatar Generation from a Single Image","summary":"We present a novel framework for generating high-quality, animatable 4D\navatar from a single image. While recent advances have shown promising results\nin 4D avatar creation, existing methods either require extensive multiview data\nor struggle with shape accuracy and identity consistency. To address these\nlimitations, we propose a comprehensive system that leverages shape, image, and\nvideo priors to create full-view, animatable avatars. Our approach first\nobtains initial coarse shape through 3D-GAN inversion. Then, it enhances\nmultiview textures using depth-guided warping signals for cross-view\nconsistency with the help of the image diffusion model. To handle expression\nanimation, we incorporate a video prior with synchronized driving signals\nacross viewpoints. We further introduce a Consistent-Inconsistent training to\neffectively handle data inconsistencies during 4D reconstruction. Experimental\nresults demonstrate that our method achieves superior quality compared to the\nprior art, while maintaining consistency across different viewpoints and\nexpressions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T15:40:14Z"}
{"aid":"http://arxiv.org/abs/2504.15202v1","title":"Extending the ElGamal Cryptosystem to the Third Group of Units of\n  $\\Z_{n}$","summary":"In this paper, we extend the ElGamal cryptosystem to the third group of units\nof the ring $\\Z_{n}$, which we prove to be more secure than the previous\nextensions. We describe the arithmetic needed in the new setting. We also\nprovide some numerical simulations that shows the security and efficiency of\nour proposed cryptosystem.","main_category":"cs.CR","categories":"cs.CR,cs.IT,math.GR,math.IT,math.PR,math.RA","published":"2025-04-21T16:17:53Z"}
{"aid":"http://arxiv.org/abs/2504.15209v1","title":"A Causal Convolutional Low-rank Representation Model for Imputation of\n  Water Quality Data","summary":"The monitoring of water quality is a crucial part of environmental\nprotection, and a large number of monitors are widely deployed to monitor water\nquality. Due to unavoidable factors such as data acquisition breakdowns,\nsensors and communication failures, water quality monitoring data suffers from\nmissing values over time, resulting in High-Dimensional and Sparse (HDS) Water\nQuality Data (WQD). The simple and rough filling of the missing values leads to\ninaccurate results and affects the implementation of relevant measures.\nTherefore, this paper proposes a Causal convolutional Low-rank Representation\n(CLR) model for imputing missing WQD to improve the completeness of the WQD,\nwhich employs a two-fold idea: a) applying causal convolutional operation to\nconsider the temporal dependence of the low-rank representation, thus\nincorporating temporal information to improve the imputation accuracy; and b)\nimplementing a hyperparameters adaptation scheme to automatically adjust the\nbest hyperparameters during model training, thereby reducing the tedious manual\nadjustment of hyper-parameters. Experimental studies on three real-world water\nquality datasets demonstrate that the proposed CLR model is superior to some of\nthe existing state-of-the-art imputation models in terms of imputation accuracy\nand time cost, as well as indicating that the proposed model provides more\nreliable decision support for environmental monitoring.","main_category":"cs.LG","categories":"cs.LG,cs.AI,I.2.7","published":"2025-04-21T16:27:16Z"}
{"aid":"http://arxiv.org/abs/2504.15218v1","title":"Non-minimal coupling in light of ACT","summary":"The latest ACT data release disfavors the attractor $n_s=1-2/N$. In\ninflationary models with nonminimal coupling, such attractors typically arise\nin the strong coupling limit. To align with observational constraints, we focus\non nonminimal coupling models with small coupling constants. For the model with\nthe coupling function $\\Omega(\\phi) = 1 + \\xi f(\\phi)$ and the potential\n$V(\\phi) = \\lambda^2 f^2(\\phi)$, we find that observational data constrain the\nparameters as $0.1 \\lesssim \\xi \\lesssim 35$ and $0 \\lesssim k \\lesssim 1.5$\nfor $f(\\phi) = \\phi^k$ at the $1\\sigma$ confidence level. With the help of the\nnonmiminal coupling $\\Omega(\\phi) = 1 + \\xi \\phi^2$, the hilltop inflation and\npower-law inflation models with power indices $2/3$ and $1/3$ can be consistent\nwith observational data within the $1\\sigma$ range. We also give the viable\nparameter regions for $\\xi$ for these three models.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-21T16:43:18Z"}
{"aid":"http://arxiv.org/abs/2504.15245v1","title":"Probing the octupole deformation of $^{238}$U in high-energy nuclear\n  collisions","summary":"Some atomic nuclei exhibit ``pear\" shapes arising from octupole deformation\n($\\beta_3$), though direct experimental evidences for such exotic shapes\nremains scarce. Low-energy model studies suggest $^{238}$U may have a modest\noctupole deformation arising from collective vibrational degrees of freedom, in\naddition to a large prolate shape. We investigated the impact of this modest\noctupole shape on observables involving triangular flow ($v_3$) in high-energy\nnuclear collisions. Using a hydrodynamic framework, we show $v_3$ and its\ncorrelation with mean transverse momentum, $\\langle v_3^2 \\delta\\pT \\rangle$,\nexhibit strong sensitivity to $\\beta_3$. We found that $\\langle v_3^2\\rangle$\nfollows a linear increase with $\\beta_3^2$, while $\\langle v_3^2 \\delta\\pT\n\\rangle$ is suppressed in the presence of $\\beta_3$. Our findings show that the\ncollective-flow-assisted nuclear imaging method in high-energy nuclear\ncollisions, when compared with experimental data, can provide unique\nconstraints on higher-order deformations.","main_category":"nucl-th","categories":"nucl-th,nucl-ex","published":"2025-04-21T17:17:33Z"}
{"aid":"http://arxiv.org/abs/2504.15249v1","title":"Quantum-enhanced second harmonic generation beyond the photon pairs\n  regime","summary":"Two-photon processes are crucial in applications like microscopy and\nmicrofabrication, but their low cross-section requires intense illumination and\nlimits, e.g., the penetration depth in nonlinear microscopy. Entangled states\nhave been proposed to enhance the efficiency of two-photon interactions and\nhave shown effectiveness at low intensities. This quantum enhancement is\ngenerally believed to be lost at high intensities, for more than one photon per\nmode, raising doubts about its usefulness. We explored experimentally and\ntheoretically two-photon processes driven by entangled photons at intensities\nbeyond this threshold and compared the results with the classical case. We\nfound that a quantum advantage can still be observed at nearly one order of\nmagnitude higher intensities than previously assumed. Our findings show a\npotential path for exploiting quantum-enhanced two-photon processes in\npractical applications.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-21T17:27:26Z"}
{"aid":"http://arxiv.org/abs/2504.15251v1","title":"On Learning Parallel Pancakes with Mostly Uniform Weights","summary":"We study the complexity of learning $k$-mixtures of Gaussians ($k$-GMMs) on\n$\\mathbb{R}^d$. This task is known to have complexity $d^{\\Omega(k)}$ in full\ngenerality. To circumvent this exponential lower bound on the number of\ncomponents, research has focused on learning families of GMMs satisfying\nadditional structural properties. A natural assumption posits that the\ncomponent weights are not exponentially small and that the components have the\nsame unknown covariance. Recent work gave a $d^{O(\\log(1/w_{\\min}))}$-time\nalgorithm for this class of GMMs, where $w_{\\min}$ is the minimum weight. Our\nfirst main result is a Statistical Query (SQ) lower bound showing that this\nquasi-polynomial upper bound is essentially best possible, even for the special\ncase of uniform weights. Specifically, we show that it is SQ-hard to\ndistinguish between such a mixture and the standard Gaussian. We further\nexplore how the distribution of weights affects the complexity of this task.\nOur second main result is a quasi-polynomial upper bound for the aforementioned\ntesting task when most of the weights are uniform while a small fraction of the\nweights are potentially arbitrary.","main_category":"cs.LG","categories":"cs.LG,cs.DS,math.ST,stat.ML,stat.TH","published":"2025-04-21T17:31:55Z"}
{"aid":"http://arxiv.org/abs/2504.15255v1","title":"Population Models for Star Formation Timescales in Early Galaxies: The\n  First Step Towards Solving Outshining in Star Formation History Inference","summary":"JWST have revealed temporarily-quenched and ultraviolet-luminous galaxies in\nthe early universe, suggesting enhanced star formation stochasticity. Verifying\nthis hypothesis is critical, yet challenging; outshining, wherein light from\nyoung stars dominates the spectral energy distribution, represents perhaps the\ngreatest challenge in inferring the formation histories of unresolved galaxies.\nIn this paper, we take a simple model of burstiness and show that\nstate-of-the-art inference methods with flexible star formation histories\n(SFHs) and neutral priors, while recovering average star formation rates (SFRs;\n$\\sim0.1$ dex median offset), fail to recover the complexities of fluctuations\non tens of Myr timescales, and typically underestimate masses in bursty systems\n($\\sim0.15$ dex). Surprisingly, detailed SFH recovery is still sensitive to\npriors even when data quality is optimal, e.g., including high signal-to-noise\n($\\rm20~pixel^{-1}$) spectroscopy with wide coverage (rest-frame\n$0.12-1.06~\\mu$m). Crucially, however, refitting the same data with a prior\ncorrectly encoding the bursty expectation eliminates these biases: median\noffsets in mass and SFRs decrease to $\\sim 0.04$ dex and $\\sim 0.05$ dex,\nrespectively. Under the assumption that current population burstiness predicts\npast SFH, the solution to outshining in modeling statistical samples is\nempirically measuring recent galaxy SFHs with population modeling. A prototype\nis H$\\alpha$/UV: while helpful, it is insufficient to constrain the expected\ncomplex burstiness. To this end, we introduce a more complete, quantitative\npopulation-level approach and demonstrate that it promises to recover the\ntypical amplitude, timescale, and slope of the recent SFH to high accuracy.\nThis approach thus has the strong potential to solve outshining using\nobservations from JWST.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-21T17:34:55Z"}
{"aid":"http://arxiv.org/abs/2504.15555v1","title":"Optimal Procurement Design: A Reduced Form Approach","summary":"Standard procurement models assume that the buyer knows the quality of the\ngood at the time of procurement; however, in many settings, the quality is\nlearned only long after the transaction. We study procurement problems in which\nthe buyer's valuation of the supplied good depends directly on its quality,\nwhich is unverifiable and unobservable to the buyer. For a broad class of\nprocurement problems, we identify procurement mechanisms maximizing any\nweighted average of the buyer's expected payoff and social surplus. The optimal\nmechanism can be implemented by an auction that restricts sellers to submit\nbids within specific intervals.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-22T03:19:02Z"}
{"aid":"http://arxiv.org/abs/2504.15562v1","title":"Bayesian Autoencoder for Medical Anomaly Detection: Uncertainty-Aware\n  Approach for Brain 2 MRI Analysis","summary":"In medical imaging, anomaly detection is a vital element of healthcare\ndiagnostics, especially for neurological conditions which can be\nlife-threatening. Conventional deterministic methods often fall short when it\ncomes to capturing the inherent uncertainty of anomaly detection tasks. This\npaper introduces a Bayesian Variational Autoencoder (VAE) equipped with\nmulti-head attention mechanisms for detecting anomalies in brain magnetic\nresonance imaging (MRI). For the purpose of improving anomaly detection\nperformance, we incorporate both epistemic and aleatoric uncertainty estimation\nthrough Bayesian inference. The model was tested on the BraTS2020 dataset, and\nthe findings were a 0.83 ROC AUC and a 0.83 PR AUC. The data in our paper\nsuggests that modeling uncertainty is an essential component of anomaly\ndetection, enhancing both performance and interpretability and providing\nconfidence estimates, as well as anomaly predictions, for clinicians to\nleverage in making medical decisions.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-22T03:30:42Z"}
{"aid":"http://arxiv.org/abs/2504.15572v1","title":"Global Solutions for 5D Quadratic Fourth-Order Schrödinger Equations","summary":"We prove small data scattering for the fourth-order Schr\\\"odinger equation\nwith quadratic nonlinearity \\begin{equation*}\n  i\\partial_t u+\\Delta^2 u+\\alpha u^2 + \\beta \\bar{u}^2=0\\qquad\\text{in\n}\\mathbb{R}^5 \\end{equation*} for $\\alpha, \\beta \\in \\mathbb{R}$. We extend the\nspace-time resonance method, originally introduced by Germain, Masmoudi, and\nShatah, to the setting involving the bilaplacian. We show that under a\nsmallness condition on the initial data measured in a suitable norm, the\nsolution satisfies $\\|u\\|_{L^{\\infty}_x }\\lesssim t^{-\\frac{5}{4}} $ and\nscatters to the solution to the free equation. Although our work builds upon an\nestablished method, the fourth-order nature of the equation presents\nsubstantial challenges, requiring different techniques to overcome them.","main_category":"math.AP","categories":"math.AP","published":"2025-04-22T04:05:59Z"}
{"aid":"http://arxiv.org/abs/2504.15590v1","title":"Optical-vortex-pulse induced nonequilibrium spin textures in spin-orbit\n  coupled electrons","summary":"Optical vortex beams are a type of topological light characterized by their\ninherent orbital angular momentum, leading to the propagation of a\nspiral-shaped wavefront. In this study, we focus on two-dimensional electrons\nwith Rashba and Dresselhaus spin-orbit interactions and examine how they\nrespond to pulsed vortex beams in the terahertz frequency band. Spin-orbital\ninteractions play a vital role in transferring the orbital angular momentum of\nlight to electron systems and generating spatiotemporal spin textures. We show\nthat the spatiotemporal spin polarization of electrons reflects orbital angular\nmomentum carried by optical vortex pulses. These findings demonstrate how\noptical vortices facilitate ultrafast spin manipulation in spin-orbit-coupled\nelectrons. Our results can be straightforwardly extended to the case of\nhigher-frequency vortex beams for other two-dimensional metals with a larger\nFermi energy.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-22T05:12:06Z"}
{"aid":"http://arxiv.org/abs/2504.15601v1","title":"[PK2008] HalphaJ115927 and IGR J14091-6108: Two new intermediate polars\n  above the period gap","summary":"This study presents a detailed timing analyses of two cataclysmic variables\n(CVs), [PK2008] HalphaJ115927 and IGR J14091-610, utilizing the optical data\nfrom the Transiting Exoplanet Survey Satellite (TESS). Periods of 7.20$\\pm$0.02\nh, 1161.49$\\pm$0.14 s, and 1215.99$\\pm$0.15 s are presented for [PK2008]\nHalphaJ115927, and are interpreted as the probable orbital, spin, and beat\nperiods of the system, respectively. The presence of multiple periodic\nvariations suggests that it likely belongs to the intermediate polar (IP)\ncategory of magnetic CVs. Interestingly, [PK2008] HalphaJ115927 exhibits a\nunique and strong periodic modulation at 5.66$\\pm$0.29 d, which may result from\nthe precession of an accretion disc, similar to the IP TV Col. The detection of\na spin signal of 576.63$\\pm$0.03 s and inferred orbital signal of $\\sim$ 15.84\nh supports the classification of IGR J14091-610 as an IP. The identification of\nsuch a long orbital period adds a new example to the limited population of\nlong-period IPs. The observed dominant signal at the second harmonic of the\norbital frequency also suggests ellipsoidal modulation of the secondary in this\nsystem. The observed double-peaked spin pulse profile in [PK2008] HalphaJ115927\nlikely results from two-pole accretion, where both poles contribute to the spin\nmodulation, and their geometry allows equal visibility of both accreting poles.\nIn contrast, IGR J14091-610 exhibits a single-peaked sinusoidal like spin\npulse, attributed to the changing visibility of the accretion curtains due to a\nrelatively low dipole inclination. The present observations indicate that\naccretion in both systems occurs predominantly through a disc.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-22T05:42:12Z"}
{"aid":"http://arxiv.org/abs/2504.15638v1","title":"A characteristic optical variability time scale in jetted active\n  galactic nuclei: a large gamma-ray emission sample","summary":"The variability mechanisms from jetted AGNs are still under debate. Here the\ndamped random walk (DRW) model, implemented through Gaussian Processe (GPs), is\nused to fit the $ZTF$ long-term optical light curves of 1684 $\\gamma$-ray\nemission jetted AGNs. This analysis yields one of the largest samples with\ncharacteristic optical variability timescales for jetted AGNs. A single DRW\nmodel from GPs can fit the optical light curve of most jetted AGNs\nwell/potentially well, while there are still some jetted AGNs whose light curve\ncan not be fitted well by a single DRW model. After the jet power, proxied by\ngamma-ray luminosity, is introduced as a new parameter, new relationships among\nintrinsic variability time scales, black hole mass and jet power are discovered\nfor efficient accretion AGNs ($\\tau^{\\rm in} \\propto M_{\\rm\nBH}^{0.29^{+0.06}_{-0.06}}P_{\\rm jet}^{-0.3^{+0.03}_{-0.03}}$ with scatter of\napproximately 0.09~dex) and for inefficient accretion AGNs ($\\tau^{\\rm in}\n\\propto M_{\\rm BH}^{0.06^{+0.07}_{-0.07}}P_{\\rm jet}^{0.37^{+0.11}_{-0.11}}$\nwith scatter of approximately 0.14~dex), respectively. Our results support that\nthe optical variability of jetted AGNs with efficient accretion may originate\nwithin the standard accretion disk at UV emitting radii similar to non-jetted\nAGNs, and is directly related to the acceleration of shock in the jet and then\nenhanced through the beaming effect in beamed AGNs. For the jetted AGNs with\ninefficient accretion, the intrinsic timescale is consistent with the escape\ntimescale of electrons.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.HE","published":"2025-04-22T06:57:01Z"}
{"aid":"http://arxiv.org/abs/2504.15655v1","title":"Effective loop cosmology is a mere symplectic modification of standard\n  cosmology","summary":"It is shown that several prescriptions for the effective continuum limit of\nthe flat Friedmann-Lemaitre-Robertson-Walker loop quantum cosmology can be\nunderstood as the exact classical limit of the Wheeler-DeWitt quantization of\ncertain dynamical systems -- which are themeselves symplectic modifications of\nthe standard Friedmann-Lemaitre-Robertson-Walker model. It is also demonstrated\nthat a similar situation holds for two highly relevant anisotropic models. The\nrequired symplectic modifications are explicitly constructed. It is argued that\nthis state of affairs makes the case for the associated Wheeler-DeWitt\nframework to be considered as an alternate quantum cosmology paradigm.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-22T07:26:23Z"}
{"aid":"http://arxiv.org/abs/2504.15662v1","title":"On GKM fiber bundles and realizability with full flag fibers","summary":"We investigate under which conditions an equivariant fiber bundle whose base,\ntotal space and fiber are GKM manifolds induces a fibration or fiber bundle of\nthe corresponding GKM graphs. In particular, we give several counterexamples.\nConcerning the converse direction, i.e., the realization problem for fiber\nbundles of GKM graphs, we restrict to the setting of fiberwise signed GKM fiber\nbundles over $n$-gons whose fiber is the GKM graph of a full flag manifold.\nWhile it was known that any such bundle is realizable for a\n$\\mathbb{CP}^1$-fiber, we observe that new phenomena occur in higher dimensions\nwhere realizability depends on the twist automorphism of the GKM fiber bundle.\nWe classify possible twist isomorphsims and show that realizability can be\ndecided in terms of our classification.","main_category":"math.AT","categories":"math.AT,math.DG","published":"2025-04-22T07:37:33Z"}
{"aid":"http://arxiv.org/abs/2504.15674v1","title":"TrojanDam: Detection-Free Backdoor Defense in Federated Learning through\n  Proactive Model Robustification utilizing OOD Data","summary":"Federated learning (FL) systems allow decentralized data-owning clients to\njointly train a global model through uploading their locally trained updates to\na centralized server. The property of decentralization enables adversaries to\ncraft carefully designed backdoor updates to make the global model misclassify\nonly when encountering adversary-chosen triggers. Existing defense mechanisms\nmainly rely on post-training detection after receiving updates. These methods\neither fail to identify updates which are deliberately fabricated statistically\nclose to benign ones, or show inconsistent performance in different FL training\nstages. The effect of unfiltered backdoor updates will accumulate in the global\nmodel, and eventually become functional. Given the difficulty of ruling out\nevery backdoor update, we propose a backdoor defense paradigm, which focuses on\nproactive robustification on the global model against potential backdoor\nattacks. We first reveal that the successful launching of backdoor attacks in\nFL stems from the lack of conflict between malicious and benign updates on\nredundant neurons of ML models. We proceed to prove the feasibility of\nactivating redundant neurons utilizing out-of-distribution (OOD) samples in\ncentralized settings, and migrating to FL settings to propose a novel backdoor\ndefense mechanism, TrojanDam. The proposed mechanism has the FL server\ncontinuously inject fresh OOD mappings into the global model to activate\nredundant neurons, canceling the effect of backdoor updates during aggregation.\nWe conduct systematic and extensive experiments to illustrate the superior\nperformance of TrojanDam, over several SOTA backdoor defense methods across a\nwide range of FL settings.","main_category":"cs.CR","categories":"cs.CR,cs.LG","published":"2025-04-22T07:56:51Z"}
{"aid":"http://arxiv.org/abs/2504.15677v1","title":"Affine isoperimetric type inequalities for static convex domains in\n  hyperbolic space","summary":"In this paper, the notion of hyperbolic ellipsoids in hyperbolic space is\nintroduced. Using a natural orthogonal projection from hyperbolic space to\nEuclidean space, we establish affine isoperimetric type inequalities for static\nconvex domains in hyperbolic space. Moreover, equality of such inequalities is\ncharacterized by these hyperbolic ellipsoids.","main_category":"math.DG","categories":"math.DG","published":"2025-04-22T08:00:28Z"}
{"aid":"http://arxiv.org/abs/2504.15712v1","title":"(Thermo-)dynamics of the spin-boson model in the weak coupling regime:\n  Application as a quantum battery","summary":"We investigate the spin-boson model's dynamical and thermodynamic features in\nthe weak coupling regime using the weak coupling spin-boson (WCSB) and phase\ncovariant (PC) master equations. Both unital (pure dephasing) and non-unital\n(dissipative) quantum channels are considered. On the dynamical side, we\nexplore key quantum features including non-Markovianity, quantum speed limit,\nquantum coherence, and the system's steady-state behavior. Notably, the\nmeasures of non-Markovianity exhibit different behavior under WCSB and PC\ndynamics. From the quantum thermodynamic perspective, we conceptualize the\nspin-boson system as a quantum battery and analyze its performance through\nmetrics such as energy, ergotropy, anti-ergotropy, and battery capacity. We\nfurther examine the roles of pure dephasing and dissipative processes in\nshaping the battery's performance. Our findings demonstrate the spin-boson\nmodel's versatility as a platform for efficient energy storage and transfer in\nquantum thermodynamic devices.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-22T08:53:57Z"}
{"aid":"http://arxiv.org/abs/2504.15724v1","title":"Collaborative Split Federated Learning with Parallel Training and\n  Aggregation","summary":"Federated learning (FL) operates based on model exchanges between the server\nand the clients, and it suffers from significant client-side computation and\ncommunication burden. Split federated learning (SFL) arises a promising\nsolution by splitting the model into two parts, that are trained sequentially:\nthe clients train the first part of the model (client-side model) and transmit\nit to the server that trains the second (server-side model). Existing SFL\nschemes though still exhibit long training delays and significant communication\noverhead, especially when clients of different computing capability\nparticipate. Thus, we propose Collaborative-Split Federated Learning~(C-SFL), a\nnovel scheme that splits the model into three parts, namely the model parts\ntrained at the computationally weak clients, the ones trained at the\ncomputationally strong clients, and the ones at the server. Unlike existing\nworks, C-SFL enables parallel training and aggregation of model's parts at the\nclients and at the server, resulting in reduced training delays and\ncommmunication overhead while improving the model's accuracy. Experiments\nverify the multiple gains of C-SFL against the existing schemes.","main_category":"cs.DC","categories":"cs.DC,cs.AI","published":"2025-04-22T09:18:57Z"}
{"aid":"http://arxiv.org/abs/2504.15735v1","title":"Local Hölder Regularity For Nonlocal Porous Media And Fast Diffusion\n  Equations With General Kernel","summary":"We show that locally bounded, local weak solutions to certain nonlocal,\nnonlinear diffusion equations modeled on the fractional porous media and fast\ndiffusion equations given by \\begin{align*} \\partial_t u +\n(-\\Delta)^s(|u|^{m-1}u) = 0 \\quad \\mbox{ for } \\quad 0<s<1 \\quad\\text{and}\\quad\nm>0 \\end{align*} are locally H\\\"older continuous. We work with bounded,\nmeasurable kernels and provide the corresponding $L^{\\infty}_{loc} \\rightarrow\nC^{0,\\alpha}_{loc}$ De Giorgi-Nash-Moser theory for the equation via a delicate\nanalysis of the set of singularity/degeneracy in a geometry dictated by the\nsolution itself and a careful analysis of far-off effects. In particular, our\nresults are in the spirit of interior regularity, requiring the equation to\nhold only locally, and thus are new even for positive solutions of the equation\nwith constant coefficients.","main_category":"math.AP","categories":"math.AP","published":"2025-04-22T09:27:11Z"}
{"aid":"http://arxiv.org/abs/2504.15766v1","title":"Dynamic Intent Queries for Motion Transformer-based Trajectory\n  Prediction","summary":"In autonomous driving, accurately predicting the movements of other traffic\nparticipants is crucial, as it significantly influences a vehicle's planning\nprocesses. Modern trajectory prediction models strive to interpret complex\npatterns and dependencies from agent and map data. The Motion Transformer (MTR)\narchitecture and subsequent work define the most accurate methods in common\nbenchmarks such as the Waymo Open Motion Benchmark. The MTR model employs\npre-generated static intention points as initial goal points for trajectory\nprediction. However, the static nature of these points frequently leads to\nmisalignment with map data in specific traffic scenarios, resulting in\nunfeasible or unrealistic goal points. Our research addresses this limitation\nby integrating scene-specific dynamic intention points into the MTR model. This\nadaptation of the MTR model was trained and evaluated on the Waymo Open Motion\nDataset. Our findings demonstrate that incorporating dynamic intention points\nhas a significant positive impact on trajectory prediction accuracy, especially\nfor predictions over long time horizons. Furthermore, we analyze the impact on\nground truth trajectories which are not compliant with the map data or are\nillegal maneuvers.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-22T10:20:35Z"}
{"aid":"http://arxiv.org/abs/2504.15767v1","title":"Is there a Birch Swinnerton-Dyer conjecture for Dedekind zeta functions?","summary":"A Birch Swinnerton-Dyer conjecture for number fields $K / \\mathbb{Q}$ would\nassert that $dim V_K = ord_{s = 1/2} \\zeta_K (s)$ for some vector space\nfunctorially attached to $K$. Presently there is no natural candidate for the\n$V_K$'s. However, assuming $V_K$ is of a cohomological nature and assuming a\nconjecture of Serre on the vanishing order of $\\zeta_K (s)$ at $s = 1/2$ we\nshow that such functors $K \\mapsto V_K$ (with natural extra structures) exist\nand are all isomorphic. Their common automorphism group is $2$-torsion and\nabelian.","main_category":"math.NT","categories":"math.NT","published":"2025-04-22T10:25:17Z"}
{"aid":"http://arxiv.org/abs/2504.15772v1","title":"Laplacian eigenvalue distribution and girth of graphs","summary":"Let $G$ be a connected graph on $n$ vertices with girth $g$. Let $m_GI$\ndenote the number of Laplacian eigenvalues of graph $G$ in an interval $I$. In\nthis paper, we show that $m_G(n-g+3,n]\\leq n-g$. Moreover, we prove that\n$m_G(n-g+3,n]= n-g$ if and only if $G\\cong K_{3,2}$ or $G\\cong U_1$, where\n$U_1$ is obtained from a cycle by joining a single vertex with a vertex of this\ncycle.","main_category":"math.CO","categories":"math.CO","published":"2025-04-22T10:28:41Z"}
{"aid":"http://arxiv.org/abs/2504.15775v1","title":"Rings whose mininjective modules are injective","summary":"The main goal of this paper is to characterize rings over which the\nmininjective modules are injective, so that the classes of mininjective modules\nand injective modules coincide. We show that these rings are precisely those\nNoetherian rings for which every min-flat module is projective and we study\nthis characterization in the cases when the ring is Kasch, commutative and when\nit is quasi-Frobenius. We also treat the case of $n\\times n$ upper triangular\nmatrix rings, proving that their mininjective modules are injective if and only\nif $n=2$.\n  We use the developed machinery to find a new type of examples of indigent\nmodules (those whose subinjectivity domain contains only the injective\nmodules), whose existence is known, so far, only in some rather restricted\nsituations.","main_category":"math.RA","categories":"math.RA","published":"2025-04-22T10:32:34Z"}
{"aid":"http://arxiv.org/abs/2504.15813v1","title":"Thermoelectric performance of quantum dots embedded in an Aharonov-Bohm\n  ring: a Pauli master equation approach","summary":"Within linear response theory using Pauli master equation approach, we have\ninvestigated the thermoelectric properties of quantum dots (QDs) embedded in an\nAharonov-Bohm (AB) ring weakly coupled to two metallic electrodes. This study\nexplores the impact of magnetic flux on thermoelectric transport, emphasizing\nthe role of quantum interference induced by the flux. When the magnetic flux is\nvaried from 0 to one quantum of flux $\\Phi = \\Phi_{0} = \\frac{h}{e}$, both the\nelectrical conductance and the thermoelectric figure of merit ($ZT$)\nsignificantly increase by two order of magnitude. Moreover, our investigation\ninto the effects of onsite and inter-site Coulomb interactions in this\nnanojunction indicates that an optimal $ZT$ is attained with moderate onsite\nCoulomb interaction and minimal inter-site Coulomb interaction. We briefly\ndiscussed the effects of asymmetric arrangements of triple QDs within an AB\nring. However, within our parameter regime, a symmetric arrangement offers\nsuperior thermoelectric performance compared to asymmetric configurations.\nFurthermore, we explored how increasing the number of QDs in the ring enhances\nthe thermoelectric properties, resulting in a potential $ZT$ value of around\n$0.43$. This study shows that arranging multiple QDs symmetrically in an AB\nring can result in significant thermoelectric performance in nanostructured\nsystem at low temperatures.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.str-el","published":"2025-04-22T11:52:42Z"}
{"aid":"http://arxiv.org/abs/2504.15837v1","title":"GUE Fluctuations Near the Axis in One-Sided Ballistic Deposition","summary":"We introduce a variation of the classic ballistic deposition model in which\nvertically falling blocks can only stick to the top or the upper right corner\nof growing columns. We establish that the fluctuations of the height function\nat points near the $t$-axis are given by the GUE ensemble and its correspondent\nTracy-Widom limiting distribution. The proof is based on a graphical\nconstruction of the process in terms of a directed Last Passage Percolation\nmodel.","main_category":"math.PR","categories":"math.PR,math-ph,math.MP","published":"2025-04-22T12:31:02Z"}
{"aid":"http://arxiv.org/abs/2504.15842v1","title":"Radiative equilibrium boundary condition and correlation analysis on\n  catalytic surfaces in DSMC","summary":"This study integrates radiative equilibrium boundary conditions on a\ncatalytic surface within the Direct Simulation Monte Carlo (DSMC) method. The\nradiative equilibrium boundary condition is based on the principle of energy\nconservation at each surface element, enabling the accurate capture of\nspatially varying surface temperatures and heat fluxes encountered during\natmospheric re-entry. The surface catalycity is represented through the\nfinite-rate surface chemistry (FRSC) model, specifically focusing on the\nheterogeneous recombination of atomic oxygen on silica surfaces. Both the FRSC\nmodel and the radiative equilibrium boundary conditions within the DSMC\nframework are validated through comparison to analytical solutions. Numerical\nsimulations are conducted for rarefied hypersonic flow around a two-dimensional\ncylinder under representative re-entry conditions for both non-catalytic and\ncatalytic surfaces. The results demonstrate significant discrepancies in\ncomputed surface properties between the radiative equilibrium and conventional\nisothermal boundary conditions. Furthermore, linear interpolation between\nresults from two independent isothermal boundary conditions is shown to be\ninadequate for accurately predicting surface heat flux, particularly when\nsurface reactions are considered. The observed discrepancies originate from a\nnon-linear correlation between surface temperature and heat flux, influenced by\nfactors such as surface catalycity and local geometric variations along the\ncylinder. These findings highlight the necessity of implementing radiative\nequilibrium boundary conditions within DSMC to ensure physically accurate\naerothermodynamic computations.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-22T12:38:19Z"}
{"aid":"http://arxiv.org/abs/2504.15849v1","title":"NLCTables: A Dataset for Marrying Natural Language Conditions with Table\n  Discovery","summary":"With the growing abundance of repositories containing tabular data,\ndiscovering relevant tables for in-depth analysis remains a challenging task.\nExisting table discovery methods primarily retrieve desired tables based on a\nquery table or several vague keywords, leaving users to manually filter large\nresult sets. To address this limitation, we propose a new task: NL-conditional\ntable discovery (nlcTD), where users combine a query table with natural\nlanguage (NL) requirements to refine search results. To advance research in\nthis area, we present nlcTables, a comprehensive benchmark dataset comprising\n627 diverse queries spanning NL-only, union, join, and fuzzy conditions, 22,080\ncandidate tables, and 21,200 relevance annotations. Our evaluation of six\nstate-of-the-art table discovery methods on nlcTables reveals substantial\nperformance gaps, highlighting the need for advanced techniques to tackle this\nchallenging nlcTD scenario. The dataset, construction framework, and baseline\nimplementations are publicly available at\nhttps://github.com/SuDIS-ZJU/nlcTables to foster future research.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-22T12:44:59Z"}
{"aid":"http://arxiv.org/abs/2504.15857v1","title":"Instability of oxide perovskite surfaces induced by vacancy formation","summary":"This work presents a first principles study of the (001) surface energetics\nof nine oxide perovskites, with a focus on the role of surface vacancies in\ndetermining termination stability. Additionally, investigation into the\nbehaviour of vacancies as a function of depth from the surface in these\nperovskites, ABO$_{3}$ (A=Ca, Sr, Ba; B=Ti, Zr, Sn), is carried out, and\nresults are compared to formation of the vacancies in bulk. Combining results\nfrom these investigations reveals a general trend for all nine perovskites -\nthe undefected AO surface is more energetically favourable to form than the BO2\nsurface. This dominance of the AO over the BO2 surface is further enforced by\nthe phase diagrams of perovskite surfaces. However, A-site vacancies at the AO\nsurface are far more favourable (1-2 eV lower in energy) than B-site vacancies\nat the BO2 surface. Charged vacancies only drive this further under oxygen-rich\nconditions, showing a smaller range of stability for the AO than the BO2\nsurface. These results indicates that, whilst the AO surface is easier to form,\nthe BO2 surface will display better long term stability, making it more\nsuitable for use in potential applications. This study furthers the\nunderstanding of oxide perovskite (001)-terminated surface stability, which\nwill aid in surface growth and manufacturing.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-22T12:53:37Z"}
{"aid":"http://arxiv.org/abs/2504.15867v1","title":"Inducing Vulnerable Code Generation in LLM Coding Assistants","summary":"Due to insufficient domain knowledge, LLM coding assistants often reference\nrelated solutions from the Internet to address programming problems. However,\nincorporating external information into LLMs' code generation process\nintroduces new security risks. In this paper, we reveal a real-world threat,\nnamed HACKODE, where attackers exploit referenced external information to embed\nattack sequences, causing LLMs to produce code with vulnerabilities such as\nbuffer overflows and incomplete validations. We designed a prototype of the\nattack, which generates effective attack sequences for potential diverse inputs\nwith various user queries and prompt templates. Through the evaluation on two\ngeneral LLMs and two code LLMs, we demonstrate that the attack is effective,\nachieving an 84.29% success rate. Additionally, on a real-world application,\nHACKODE achieves 75.92% ASR, demonstrating its real-world impact.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-22T13:09:20Z"}
{"aid":"http://arxiv.org/abs/2504.15885v1","title":"Branch-and-Bound Algorithms as Polynomial-time Approximation Schemes","summary":"Branch-and-bound algorithms (B&B) and polynomial-time approximation schemes\n(PTAS) are two seemingly distant areas of combinatorial optimization. We intend\nto (partially) bridge the gap between them while expanding the boundary of\ntheoretical knowledge on the B&B framework. Branch-and-bound algorithms\ntypically guarantee that an optimal solution is eventually found. However, we\nshow that the standard implementation of branch-and-bound for certain knapsack\nand scheduling problems also exhibits PTAS-like behavior, yielding increasingly\nbetter solutions within polynomial time. Our findings are supported by\ncomputational experiments and comparisons with benchmark methods. This paper is\nan extended version of a paper accepted at ICALP 2025.","main_category":"cs.DS","categories":"cs.DS,math.OC","published":"2025-04-22T13:30:01Z"}
{"aid":"http://arxiv.org/abs/2504.15888v1","title":"MS-Occ: Multi-Stage LiDAR-Camera Fusion for 3D Semantic Occupancy\n  Prediction","summary":"Accurate 3D semantic occupancy perception is essential for autonomous driving\nin complex environments with diverse and irregular objects. While\nvision-centric methods suffer from geometric inaccuracies, LiDAR-based\napproaches often lack rich semantic information. To address these limitations,\nMS-Occ, a novel multi-stage LiDAR-camera fusion framework which includes\nmiddle-stage fusion and late-stage fusion, is proposed, integrating LiDAR's\ngeometric fidelity with camera-based semantic richness via hierarchical\ncross-modal fusion. The framework introduces innovations at two critical\nstages: (1) In the middle-stage feature fusion, the Gaussian-Geo module\nleverages Gaussian kernel rendering on sparse LiDAR depth maps to enhance 2D\nimage features with dense geometric priors, and the Semantic-Aware module\nenriches LiDAR voxels with semantic context via deformable cross-attention; (2)\nIn the late-stage voxel fusion, the Adaptive Fusion (AF) module dynamically\nbalances voxel features across modalities, while the High Classification\nConfidence Voxel Fusion (HCCVF) module resolves semantic inconsistencies using\nself-attention-based refinement. Experiments on the nuScenes-OpenOccupancy\nbenchmark show that MS-Occ achieves an Intersection over Union (IoU) of 32.1%\nand a mean IoU (mIoU) of 25.3%, surpassing the state-of-the-art by +0.7% IoU\nand +2.4% mIoU. Ablation studies further validate the contribution of each\nmodule, with substantial improvements in small-object perception, demonstrating\nthe practical value of MS-Occ for safety-critical autonomous driving scenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T13:33:26Z"}
{"aid":"http://arxiv.org/abs/2504.15926v1","title":"ErMn$_6$Sn$_6$: A Promising Kagome Antiferromagnetic Candidate for\n  Room-Temperature Nernst Effect-based thermoelectrics","summary":"The Nernst effect, the generation of a transverse electric voltage in the\npresence of longitudinal thermal gradient, has garnered significant attention\nin the realm of magnetic topological materials due to its superior potential\nfor thermoelectric applications. In this work, we investigate electronic and\nthermoelectric transport properties of a Kagome magnet ErMn$_6$Sn$_6$, a\ncompound showing an incommensurate antiferromagnetic phase followed by a\nferrimagnetic phase transition upon cooling. We show that in the\nantiferromagnetic phase ErMn$_6$Sn$_6$ exhibits both topological Nernst effect\nand anomalous Nernst effect, analogous to the electric Hall effects, with the\nNernst coefficient reaching 1.71 uV/K at 300 K and 3 T. This value surpasses\nthat of most of previously reported state-of-the-art canted antiferromagnetic\nmaterials and is comparable to recently reported other members of RMn$_6$Sn$_6$\n(R = rare-earth, Y, Lu, Sc) compounds, which makes ErMn$_6$Sn$_6$ a promising\ncandidate for advancing the development of Nernst effect-based thermoelectric\ndevices.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-04-22T14:14:05Z"}
{"aid":"http://arxiv.org/abs/2504.15945v1","title":"Selmer stability for elliptic curves in Galois $\\ell$-extensions","summary":"We study the behavior of Selmer groups of an elliptic curve $E/\\mathbb{Q}$ in\nfinite Galois extensions with prescribed Galois group. Fix a prime $\\ell \\geq\n5$, a finite group $G$ with $\\#G = \\ell^n$, and an elliptic curve\n$E/\\mathbb{Q}$ with $Sel_\\ell(E/\\mathbb{Q}) = 0$ and surjective mod-$\\ell$\nGalois representation. We show that there exist infinitely many Galois\nextensions $F/\\mathbb{Q}$ with Galois group $Gal(F/\\mathbb{Q}) \\simeq G$ for\nwhich the $\\ell$-Selmer group $Sel_\\ell(E/F)$ also vanishes. We obtain an\nasymptotic lower bound for the number $M(G, E; X)$ of such fields $F$ with\nabsolute discriminant $|\\Delta_F|\\leq X$, proving that there is an explicit\nconstant $\\delta>0$ such that $M(G, E; X) \\gg X^{\\frac{1}{\\ell^{n-1}(\\ell -\n1)}} (\\log X)^{\\delta - 1}$. The asymptotic for $M(G, E; X)$ matches the\nconjectural count for all $G$-extensions $F/\\mathbb{Q}$ for which\n$|\\Delta_F|\\leq X$, up to a power of $\\log X$. This demonstrates that Selmer\nstability is not a rare phenomenon.","main_category":"math.NT","categories":"math.NT","published":"2025-04-22T14:43:07Z"}
{"aid":"http://arxiv.org/abs/2504.15953v1","title":"Visual Place Cell Encoding: A Computational Model for Spatial\n  Representation and Cognitive Mapping","summary":"This paper presents the Visual Place Cell Encoding (VPCE) model, a\nbiologically inspired computational framework for simulating place cell-like\nactivation using visual input. Drawing on evidence that visual landmarks play a\ncentral role in spatial encoding, the proposed VPCE model activates visual\nplace cells by clustering high-dimensional appearance features extracted from\nimages captured by a robot-mounted camera. Each cluster center defines a\nreceptive field, and activation is computed based on visual similarity using a\nradial basis function. We evaluate whether the resulting activation patterns\ncorrelate with key properties of biological place cells, including spatial\nproximity, orientation alignment, and boundary differentiation. Experiments\ndemonstrate that the VPCE can distinguish between visually similar yet\nspatially distinct locations and adapt to environment changes such as the\ninsertion or removal of walls. These results suggest that structured visual\ninput, even in the absence of motion cues or reward-driven learning, is\nsufficient to generate place-cell-like spatial representations and support\nbiologically inspired cognitive mapping.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-22T14:49:30Z"}
{"aid":"http://arxiv.org/abs/2504.15956v1","title":"Universal Approximation with Softmax Attention","summary":"We prove that with linear transformations, both (i) two-layer self-attention\nand (ii) one-layer self-attention followed by a softmax function are universal\napproximators for continuous sequence-to-sequence functions on compact domains.\nOur main technique is a new interpolation-based method for analyzing\nattention's internal mechanism. This leads to our key insight: self-attention\nis able to approximate a generalized version of ReLU to arbitrary precision,\nand hence subsumes many known universal approximators. Building on these, we\nshow that two-layer multi-head attention alone suffices as a\nsequence-to-sequence universal approximator. In contrast, prior works rely on\nfeed-forward networks to establish universal approximation in Transformers.\nFurthermore, we extend our techniques to show that, (softmax-)attention-only\nlayers are capable of approximating various statistical models in-context. We\nbelieve these techniques hold independent interest.","main_category":"cs.LG","categories":"cs.LG,cs.AI,stat.ML","published":"2025-04-22T14:51:33Z"}
{"aid":"http://arxiv.org/abs/2504.15965v1","title":"From Human Memory to AI Memory: A Survey on Memory Mechanisms in the Era\n  of LLMs","summary":"Memory is the process of encoding, storing, and retrieving information,\nallowing humans to retain experiences, knowledge, skills, and facts over time,\nand serving as the foundation for growth and effective interaction with the\nworld. It plays a crucial role in shaping our identity, making decisions,\nlearning from past experiences, building relationships, and adapting to\nchanges. In the era of large language models (LLMs), memory refers to the\nability of an AI system to retain, recall, and use information from past\ninteractions to improve future responses and interactions. Although previous\nresearch and reviews have provided detailed descriptions of memory mechanisms,\nthere is still a lack of a systematic review that summarizes and analyzes the\nrelationship between the memory of LLM-driven AI systems and human memory, as\nwell as how we can be inspired by human memory to construct more powerful\nmemory systems. To achieve this, in this paper, we propose a comprehensive\nsurvey on the memory of LLM-driven AI systems. In particular, we first conduct\na detailed analysis of the categories of human memory and relate them to the\nmemory of AI systems. Second, we systematically organize existing\nmemory-related work and propose a categorization method based on three\ndimensions (object, form, and time) and eight quadrants. Finally, we illustrate\nsome open problems regarding the memory of current AI systems and outline\npossible future directions for memory in the era of large language models.","main_category":"cs.IR","categories":"cs.IR,H.0","published":"2025-04-22T15:05:04Z"}
{"aid":"http://arxiv.org/abs/2504.15966v1","title":"Criticality and magnetic phases of Ising Shastry-Sutherland candidate\n  holmium tetraboride","summary":"Frustrated magnetic systems arising in geometrically constrained lattices\nrepresent rich platforms for exploring unconventional phases of matter,\nincluding fractional magnetization plateaus, incommensurate orders, and complex\ndomain dynamics. However, determining the microscopic spin configurations that\nstabilize such phases is a key challenge, especially when in-plane and\nout-of-plane spin components coexist and compete. Here, we combine neutron\nscattering and magnetic susceptibility experiments with simulations to\ninvestigate the emergence of field-induced fractional plateaus and the related\ncriticality in a frustrated magnet holmium tetraboride (HoB4) that represents\nthe family of rare earth tetraborides that crystalize in a Shastry-Sutherland\nlattice in the ab plane. We focus on the interplay between classical and\nquantum criticality near phase boundaries as well as the role of material\ndefects in the stabilization of the ordered phases. We find that simulations\nusing classical annealing can explain certain observed features in the\nexperimental Laue diffraction and the origin of multiple magnetization\nplateaus. Our results show that defects and out of plane interactions play an\nimportant role and can guide the route towards resolving microscopic spin\ntextures in highly frustrated magnets.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci","published":"2025-04-22T15:05:09Z"}
{"aid":"http://arxiv.org/abs/2504.15969v1","title":"Improved energy-based scatter estimation by incorporating local energy\n  spectra and accelerating the parametric fitting","summary":"PET requires accurate, precise, and efficient scatter correction techniques.\nConventional scatter estimation typically relies on tail-fitted single-scatter\nsimulation (SSS) strategy. However, the accuracy of tail-fitted SSS is limited,\nfor example, by mismatches between the attenuation image and the PET emission\ndata or by the presence of activity outside the FOV. These shortcomings can be\naddressed using energy-based scatter estimation (EBSE), as recently proposed by\nEfthimiou et al. and Hamill et al. The aim of this work is to 1. improve the\naccuracy of EBSE by accounting for the LOR dependence of the energy spectrum of\nunscattered photons, 2. improve the computational speed of EBSE through better\ninitialization and a more efficient optimization algorithm. The proposed\nimproved EBSE method models the energy probability density function (PDF) of\nboth single and multiple scattered photons, and incorporates a\nposition-dependent energy PDF for unscattered photons. These energy PDFs form\nthe basis of two forward models used for scatter estimation based on 2D energy\nhistograms. The performance of these models were evaluated using GATE Monte\nCarlo simulations and a NEMA phantom acquisition on a GE SIGNA PET/MR scanner.\nFurthermore, we assessed the stability of EBSE across the forward models by\nvarying the number of counts in the 2D energy histograms via data mashing. EBSE\noutperformed tail-fitted SSS, particularly in regions near out-of-FOV activity.\nOur GATE simulations showed that incorporating a local energy for unscattered\nphotons improves off-center regional quantification by approximately 2% points.\nAdditionally, improved initialization combined with the NEGML optimizer\nenabling execution on a mashed TOF sinogram in 12 minutes on six-core CPU. The\nproposed method enhances both the accuracy and computational efficiency of\nEBSE, making it well-suited for clinical applications.","main_category":"physics.med-ph","categories":"physics.med-ph","published":"2025-04-22T15:09:54Z"}
{"aid":"http://arxiv.org/abs/2504.15977v1","title":"QCaMP: A 4-Week Summer Camp Introducing High School Students to Quantum\n  Information Science and Technology","summary":"The 2024 Quantum Computing, Math and Physics Camp (QCaMP) for Students was a\n4-week long summer camp aimed at introducing high school students to quantum\nconcepts and careers, including applications spanning quantum computing,\nsensing, and communication. The program ran for 7 hours/day, Monday-Friday,\nJuly 1-26, and included hands-on modules and activities, professional\ndevelopment, and project-based learning. Here we provide details on the camp\ncurriculum and outcomes based on pre and post knowledge and attitudes\nassessments.","main_category":"physics.ed-ph","categories":"physics.ed-ph,quant-ph","published":"2025-04-22T15:25:51Z"}
{"aid":"http://arxiv.org/abs/2504.15989v1","title":"Token-Aware Coding Flow: A Study with Nano Surge in Reasoning Model","summary":"With the widespread application of large-scale language models (LLMs) in\nsoftware engineering, the Chain of Thought (CoT) approach has emerged as a\ncrucial tool for driving automated code generation and optimization. However,\ndespite the significant success of CoT methods in generating high-quality code,\nthe issue of token inflation during the reasoning process remains a formidable\nchallenge to model performance and efficiency, particularly when dealing with\ncomplex code smells. Code smells not only affect the maintainability and\nscalability of code but also significantly increase the computational burden\nduring LLM inference, leading to excessive token consumption and, consequently,\nreduced reasoning efficiency. This paper introduces an innovative Token-Aware\nCoding Flow method, aimed at addressing the token inflation problem caused by\nsmelly code in the CoT process. Through experimentation, we validate the\nsynergistic effect of code refactoring and prompt engineering strategies,\ndemonstrating that after eliminating code smells, token consumption during\nmodel inference is significantly reduced. The experimental results show that\nrefactored code, while maintaining functional consistency, can reduce token\nconsumption by up to 50\\%. Additionally, by explicitly prompting the type of\ncode smells in the prompt and incorporating strategies such as context\nawareness and role constraints, we further optimize the reasoning process,\nachieving a 24.5\\% to 30\\% reduction in token consumption. These optimizations\nnot only significantly enhance the model's reasoning efficiency and improve\ncode generation quality but also provide new insights for addressing\nperformance bottlenecks in complex code generation tasks.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-22T15:51:00Z"}
{"aid":"http://arxiv.org/abs/2504.15992v1","title":"Repeated singular values of a random symmetric matrix and decoupled\n  singular value estimates","summary":"Let $A_n$ be a random symmetric matrix with Bernoulli $\\{\\pm 1\\}$ entries.\nFor any $\\kappa>0$ and two real numbers $\\lambda_1,\\lambda_2$ with a separation\n$|\\lambda_1-\\lambda_2|\\geq \\kappa n^{1/2}$ and both lying in the bulk\n$[-(2-\\kappa)n^{1/2},(2-\\kappa)n^{1/2}]$, we prove a joint singular value\nestimate $$ \\mathbb{P}(\\sigma_{min}(A_n-\\lambda_i I_n)\\leq\\epsilon\nn^{-1/2};i=1,2)\\leq C\\epsilon^2+2e^{-cn}. $$ For general subgaussian\ndistribution and a mesoscopic separation $|\\lambda_1-\\lambda_2|\\geq \\kappa\nn^{-1/2+\\sigma},\\sigma>0$ we prove the same estimate with $e^{-cn}$ replaced by\nan exponential type error. This means that extreme behaviors of the least\nsingular value at two locations can essentially be decoupled all the way down\nto the exponential scale when the two locations are separated. As a corollary,\nwe prove that all the singular values of $A_n$ in $[\\kappa\nn^{1/2},(2-\\kappa)n^{1/2}]$ are distinct with probability $1-e^{-cn}$, and with\nhigh probability the minimal gap between these singular values has order at\nleast $n^{-3/2}$. This justifies, in a strong quantitative form, a conjecture\nof Vu up to $(1-\\kappa)$-fraction of the spectrum for any $\\kappa>0$.","main_category":"math.PR","categories":"math.PR","published":"2025-04-22T15:54:32Z"}
{"aid":"http://arxiv.org/abs/2504.16021v1","title":"Navigating the State of Cognitive Flow: Context-Aware AI Interventions\n  for Effective Reasoning Support","summary":"Flow theory describes an optimal cognitive state where individuals experience\ndeep focus and intrinsic motivation when a task's difficulty aligns with their\nskill level. In AI-augmented reasoning, interventions that disrupt the state of\ncognitive flow can hinder rather than enhance decision-making. This paper\nproposes a context-aware cognitive augmentation framework that adapts\ninterventions based on three key contextual factors: type, timing, and scale.\nBy leveraging multimodal behavioral cues (e.g., gaze behavior, typing\nhesitation, interaction speed), AI can dynamically adjust cognitive support to\nmaintain or restore flow. We introduce the concept of cognitive flow, an\nextension of flow theory in AI-augmented reasoning, where interventions are\npersonalized, adaptive, and minimally intrusive. By shifting from static\ninterventions to context-aware augmentation, our approach ensures that AI\nsystems support deep engagement in complex decision-making and reasoning\nwithout disrupting cognitive immersion.","main_category":"cs.HC","categories":"cs.HC,cs.AI","published":"2025-04-22T16:35:39Z"}
{"aid":"http://arxiv.org/abs/2504.16069v1","title":"Increase of $n_s$ in regularized pole inflation & Einstein-Cartan\n  gravity","summary":"We show that the regularization of the second order pole in the pole\ninflation can induce the increase of $n_s$, which may be important after the\nlatest data release of cosmic microwave background (CMB) observation by Atacama\nCosmology Telescope (ACT). Pole inflation is known to provide a unified\ndescription of attractor models that they can generate a flat plateau for\ninflation given a general potential. Recent ACT observation suggests that the\nconstraint on the scalar spectral index $n_s$ at CMB scale may be shifted to a\nlarger value than the predictions in the Starobinsky model, the Higgs\ninflation, and the $\\alpha$-attractor model, which motivates us to consider the\nmodification of the pole inflation. We find that if we regularize the second\norder pole in the kinetic term such that the kinetic term becomes regular for\nall field range, we can generally increase $n_s$ because the potential in the\nlarge field regime will be lifted. We have explicitly demonstrated that this\ntype of regularized pole inflation can naturally arise from the Einstein-Cartan\nformalism, and the inflationary predictions are consistent with the latest ACT\ndata without spoiling the success of the $\\alpha$-attractor models.","main_category":"astro-ph.CO","categories":"astro-ph.CO,hep-ph","published":"2025-04-22T17:49:04Z"}
{"aid":"http://arxiv.org/abs/2504.16081v1","title":"Survey of Video Diffusion Models: Foundations, Implementations, and\n  Applications","summary":"Recent advances in diffusion models have revolutionized video generation,\noffering superior temporal consistency and visual quality compared to\ntraditional generative adversarial networks-based approaches. While this\nemerging field shows tremendous promise in applications, it faces significant\nchallenges in motion consistency, computational efficiency, and ethical\nconsiderations. This survey provides a comprehensive review of diffusion-based\nvideo generation, examining its evolution, technical foundations, and practical\napplications. We present a systematic taxonomy of current methodologies,\nanalyze architectural innovations and optimization strategies, and investigate\napplications across low-level vision tasks such as denoising and\nsuper-resolution. Additionally, we explore the synergies between diffusionbased\nvideo generation and related domains, including video representation learning,\nquestion answering, and retrieval. Compared to the existing surveys (Lei et\nal., 2024a;b; Melnik et al., 2024; Cao et al., 2023; Xing et al., 2024c) which\nfocus on specific aspects of video generation, such as human video synthesis\n(Lei et al., 2024a) or long-form content generation (Lei et al., 2024b), our\nwork provides a broader, more updated, and more fine-grained perspective on\ndiffusion-based approaches with a special section for evaluation metrics,\nindustry solutions, and training engineering techniques in video generation.\nThis survey serves as a foundational resource for researchers and practitioners\nworking at the intersection of diffusion models and video generation, providing\ninsights into both the theoretical frameworks and practical implementations\nthat drive this rapidly evolving field. A structured list of related works\ninvolved in this survey is also available on\nhttps://github.com/Eyeline-Research/Survey-Video-Diffusion.","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-04-22T17:59:17Z"}
{"aid":"http://arxiv.org/abs/2504.16380v1","title":"Tight Exponential Strong Converses for Lossy Source Coding with\n  Side-Information and Distributed Function Computation","summary":"The exponential strong converse for a coding problem states that, if a coding\nrate is beyond the theoretical limit, the correct probability converges to zero\nexponentially. For the lossy source coding with side-information, also known as\nthe Wyner-Ziv (WZ) problem, a lower bound on the strong converse exponent was\nderived by Oohama. In this paper, we derive the tight strong converse exponent\nfor the WZ problem; as a special case, we also derive the tight strong converse\nexponent for the distributed function computation problem. For the converse\npart, we use the change-of-measure argument developed in the literature and the\nsoft Markov constraint introduced by Oohama; the matching achievability is\nproved via the Poisson matching approach recently introduced by Li and\nAnantharam. Our result is build upon the recently derived tight strong converse\nexponent for the Wyner-Ahlswede-Korner (WAK) problem; however, compared to the\nWAK problem, more sophisticated argument is needed. As an illustration of the\nnecessity of the soft Markov constraint, we present an example such that the\nsoft Markov constraint is strictly positive.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-23T03:00:44Z"}
{"aid":"http://arxiv.org/abs/2504.16383v1","title":"Fast and Modular Whole-Body Lagrangian Dynamics of Legged Robots with\n  Changing Morphology","summary":"Fast and modular modeling of multi-legged robots (MLRs) is essential for\nresilient control, particularly under significant morphological changes caused\nby mechanical damage. Conventional fixed-structure models, often developed with\nsimplifying assumptions for nominal gaits, lack the flexibility to adapt to\nsuch scenarios. To address this, we propose a fast modular whole-body modeling\nframework using Boltzmann-Hamel equations and screw theory, in which each leg's\ndynamics is modeled independently and assembled based on the current robot\nmorphology. This singularity-free, closed-form formulation enables efficient\ndesign of model-based controllers and damage identification algorithms. Its\nmodularity allows autonomous adaptation to various damage configurations\nwithout manual re-derivation or retraining of neural networks. We validate the\nproposed framework using a custom simulation engine that integrates contact\ndynamics, a gait generator, and local leg control. Comparative simulations\nagainst hardware tests on a hexapod robot with multiple leg damage confirm the\nmodel's accuracy and adaptability. Additionally, runtime analyses reveal that\nthe proposed model is approximately three times faster than real-time, making\nit suitable for real-time applications in damage identification and recovery.","main_category":"cs.RO","categories":"cs.RO,nlin.AO","published":"2025-04-23T03:24:57Z"}
{"aid":"http://arxiv.org/abs/2504.16393v1","title":"An Explicit and Efficient $O(n^2)$-Time Algorithm for Sorting Sumsets","summary":"We present the first explicit comparison-based algorithm that sorts the\nsumset $X + Y = \\{x_i + y_j,\\ \\forall 0 \\le i, j < n\\}$, where $X$ and $Y$ are\nsorted arrays of real numbers, in optimal $O(n^2)$ time and comparisons. While\nFredman (1976) proved the theoretical existence of such an algorithm, a\nconcrete construction has remained open for nearly five decades. Our algorithm\nexploits the structured monotonicity of the sumset matrix to perform amortized\nconstant-comparisons and insertions, eliminating the $\\log(n)$ overhead typical\nof comparison-based sorting. We prove correctness and optimality in the\nstandard comparison model, extend the method to $k$-fold sumsets with $O(n^k)$\nperformance, and outline potential support for dynamic updates. Experimental\nbenchmarks show significant speedups over classical algorithms such as\nMergeSort and QuickSort when applied to sumsets. These results resolve a\nlongstanding open problem in sorting theory and contribute novel techniques for\nexploiting input structure in algorithm design.","main_category":"cs.DS","categories":"cs.DS,cs.DM","published":"2025-04-23T03:42:17Z"}
{"aid":"http://arxiv.org/abs/2504.16405v1","title":"EEmo-Bench: A Benchmark for Multi-modal Large Language Models on Image\n  Evoked Emotion Assessment","summary":"The furnishing of multi-modal large language models (MLLMs) has led to the\nemergence of numerous benchmark studies, particularly those evaluating their\nperception and understanding capabilities.\n  Among these, understanding image-evoked emotions aims to enhance MLLMs'\nempathy, with significant applications such as human-machine interaction and\nadvertising recommendations. However, current evaluations of this MLLM\ncapability remain coarse-grained, and a systematic and comprehensive assessment\nis still lacking.\n  To this end, we introduce EEmo-Bench, a novel benchmark dedicated to the\nanalysis of the evoked emotions in images across diverse content categories.\n  Our core contributions include:\n  1) Regarding the diversity of the evoked emotions, we adopt an emotion\nranking strategy and employ the Valence-Arousal-Dominance (VAD) as emotional\nattributes for emotional assessment. In line with this methodology, 1,960\nimages are collected and manually annotated.\n  2) We design four tasks to evaluate MLLMs' ability to capture the evoked\nemotions by single images and their associated attributes: Perception, Ranking,\nDescription, and Assessment. Additionally, image-pairwise analysis is\nintroduced to investigate the model's proficiency in performing joint and\ncomparative analysis.\n  In total, we collect 6,773 question-answer pairs and perform a thorough\nassessment on 19 commonly-used MLLMs.\n  The results indicate that while some proprietary and large-scale open-source\nMLLMs achieve promising overall performance, the analytical capabilities in\ncertain evaluation dimensions remain suboptimal.\n  Our EEmo-Bench paves the path for further research aimed at enhancing the\ncomprehensive perceiving and understanding capabilities of MLLMs concerning\nimage-evoked emotions, which is crucial for machine-centric emotion perception\nand understanding.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-23T04:18:17Z"}
{"aid":"http://arxiv.org/abs/2504.16434v1","title":"Achieving the positivity of the secret key in a BB84 like quantum key\n  distribution protocol","summary":"Woodhead [Phys. Rev. A \\textbf{88}, 012331 (2013)] derived the lower bound of\nthe secret key rate for a Bennett-Brassard (BB84) like quantum key distribution\nprotocol under collective attacks. However, this lower bound does not always\nassure the generation of the secret key and thus the protocol may have to be\naborted sometimes. Thus, we modify the Woodhead's lower bound of the secret key\nrate in such a way that the secret key is always generated in a BB84 like\nquantum key distribution protocol. Exploiting the obtained modified lower bound\nof the secret key rate, we analyze two state dependent quantum cloning machines\nsuch as (i) Wootters-Zurek QCM and (ii) Modified Buzek-Hillery QCM constructed\nby fixing the cloning machine parameters of Buzek Hillery quantum cloning\nmachine (QCM), which may be used by the eavesdropper to extract information\nfrom the intercepted state. We, thereafter, show that it is possible for the\ncommunicating parties to distill a secret key, even in the presence of an\neavesdropper. Moreover, we also discuss the effect of the efficiency of the QCM\non the generation of the secret key for a successful key distribution protocol.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T05:37:11Z"}
{"aid":"http://arxiv.org/abs/2504.16435v1","title":"Toward a Principled Workflow for Prevalence Mapping Using Household\n  Survey Data","summary":"Understanding the prevalence of key demographic and health indicators in\nsmall geographic areas and domains is of global interest, especially in low-\nand middle-income countries (LMICs), where vital registration data is sparse\nand household surveys are the primary source of information. Recent advances in\ncomputation and the increasing availability of spatially detailed datasets have\nled to much progress in sophisticated statistical modeling of prevalence. As a\nresult, high-resolution prevalence maps for many indicators are routinely\nproduced in the literature. However, statistical and practical guidance for\nproducing prevalence maps in LMICs has been largely lacking. In particular,\nadvice in choosing and evaluating models and interpreting results is needed,\nespecially when data is limited. Software and analysis tools are also usually\ninaccessible to researchers in low-resource settings to conduct their own\nanalysis or reproduce findings in the literature. In this paper, we propose a\ngeneral workflow for prevalence mapping using household survey data. We\nconsider all stages of the analysis pipeline, with particular emphasis on model\nchoice and interpretation. We illustrate the proposed workflow using a case\nstudy mapping the proportion of pregnant women who had at least four antenatal\ncare visits in Kenya. Reproducible code is provided in the Supplementary\nMaterials and can be readily extended to a broad collection of indicators.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-23T05:37:31Z"}
{"aid":"http://arxiv.org/abs/2504.16439v1","title":"Chebyshev polynomials and Gram determinants from the Möbius band","summary":"This article explores the connection between Chebyshev polynomials and knot\ntheory, specifically in relation to Gram determinants. We reveal intriguing\nformulae involving the Chebyshev polynomial of the first and second kind. In\nparticular we show that for Mersenne numbers, $M_k=2^k-1$ where $k\\geq 2$, the\n$M_k$-th Chebyshev polynomial of the second kind is the product of Chebyshev\npolynomials of the first kind. We then discuss the Gram determinant of type\n$(Mb)_1$, restate the conjecture of its closed formula in terms of mostly\nproducts of Chebyshev polynomials of the second kind, and prove a factor of the\ndeterminant that supports the conjecture. We also showcase an algorithm for\ncalculating the Gram determinant's corresponding matrix. Furthermore, we\nrestate Qi Chen's conjectured closed formula for the Gram determinant of type\nMb and discuss future directions.","main_category":"math.GT","categories":"math.GT","published":"2025-04-23T05:58:19Z"}
{"aid":"http://arxiv.org/abs/2504.16471v1","title":"RGB-D Video Object Segmentation via Enhanced Multi-store Feature Memory","summary":"The RGB-Depth (RGB-D) Video Object Segmentation (VOS) aims to integrate the\nfine-grained texture information of RGB with the spatial geometric clues of\ndepth modality, boosting the performance of segmentation. However,\noff-the-shelf RGB-D segmentation methods fail to fully explore cross-modal\ninformation and suffer from object drift during long-term prediction. In this\npaper, we propose a novel RGB-D VOS method via multi-store feature memory for\nrobust segmentation. Specifically, we design the hierarchical modality\nselection and fusion, which adaptively combines features from both modalities.\nAdditionally, we develop a segmentation refinement module that effectively\nutilizes the Segmentation Anything Model (SAM) to refine the segmentation mask,\nensuring more reliable results as memory to guide subsequent segmentation\ntasks. By leveraging spatio-temporal embedding and modality embedding, mixed\nprompts and fused images are fed into SAM to unleash its potential in RGB-D\nVOS. Experimental results show that the proposed method achieves\nstate-of-the-art performance on the latest RGB-D VOS benchmark.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T07:31:37Z"}
{"aid":"http://arxiv.org/abs/2504.16476v1","title":"Analysis of surface tension in terms of force gradient per unit area.\n  Part II : Theoretical model of a statistical molecular reorganization\n  gradient at interfaces","summary":"Classically, surface tension is seen as a force per unit length or as energy\nper unit area. The surface energy is calculated thermodynamically on the\nsurface of a mathematical layer with no thickness. The surface energy concept\nis certainly practical and elegant, but it doesn't seem entirely satisfactory\nto us. In an earlier article 1 , we proposed a thought experiment in which\nsurface tension is replaced with an equivalent force per unit area according to\nthe principles of fluid mechanics. This theoretical tool can be used to rewrite\nthe classical static equations in terms of surface stress gradient and propose\na new way of calculating known phenomena such as meniscus, capillary tube,\nwater drops, etc. In this article, we propose a new thought experiment assuming\nthat beyond the classical interaction forces acting at short distance,\nmolecules at liquid interfaces statistically reorganize according to a\nstationary process of creation/destruction at long distance. The process is\nsuch that the degree of statistical molecular organization decreases with a\ngradient from the surface to the bulk, where the molecules recover the natural\ndisorder of Brownian motion. Assuming that this reorganization process follows\nan Avrami-type law, we will reinterpret the effects of surface tension in terms\nof energy per unit volume, which will allow us to retrieve the previous\nequations of force gradient per unit area.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-23T07:41:47Z"}
{"aid":"http://arxiv.org/abs/2504.16477v1","title":"Distributed Optimization with Efficient Communication, Event-Triggered\n  Solution Enhancement, and Operation Stopping","summary":"In modern large-scale systems with sensor networks and IoT devices it is\nessential to collaboratively solve complex problems while utilizing network\nresources efficiently. In our paper we present three distributed optimization\nalgorithms that exhibit efficient communication among nodes. Our first\nalgorithm presents a simple quantized averaged gradient procedure for\ndistributed optimization, which is shown to converge to a neighborhood of the\noptimal solution. Our second algorithm incorporates a novel event-triggered\nrefinement mechanism, which refines the utilized quantization level to enhance\nthe precision of the estimated optimal solution. It enables nodes to terminate\ntheir operation according to predefined performance guarantees. Our third\nalgorithm is tailored to operate in environments where each message consists of\nonly a few bits. It incorporates a novel event-triggered mechanism for\nadjusting the quantizer basis and quantization level, allowing nodes to\ncollaboratively decide operation termination based on predefined performance\ncriteria. We analyze the three algorithms and establish their linear\nconvergence. Finally, an application on distributed sensor fusion for target\nlocalization is used to demonstrate their favorable performance compared to\nexisting algorithms in the literature.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-23T07:42:02Z"}
{"aid":"http://arxiv.org/abs/2504.16497v1","title":"Generalized vector equilibrium problems with pairs of bifunctions and\n  some applications","summary":"In this paper, we deal with the following generalized vector equilibrium\nproblem: Let $X, Y$ be topological vector spaces over reals, $D$ be a nonempty\nsubset of $X$, $K$ be a nonempty set and $\\theta$ be origin of $Y$. Given\nmulti-valued mapping $F: D\\times K\\rightrightarrows Y$, can be formulated as\nthe problem, find $\\bar x\\in D$ such that $$\\mbox{GVEP}(F, D,\nK)\\,\\,\\,\\,\\,\\,\\theta\\in F(\\bar x, y)\\ \\mbox{for all}\\ y\\in K.$$ We prove\nseveral existence theorems for solutions to the generalized vector equilibrium\nproblem when $K$ is an arbitrary nonempty set without any algebraic or\ntopological structure. Furthermore, we establish that some sufficient\nconditions ensuring the existence of a solution for the considered conditions\nare imposed not on the entire domain of the bifunctions but rather on a\nself-segment-dense subset. We apply the obtained results to variational\nrelation problems, vector equilibrium problems, and common fixed point\nproblems.","main_category":"math.OC","categories":"math.OC","published":"2025-04-23T08:21:50Z"}
{"aid":"http://arxiv.org/abs/2504.16499v1","title":"PRaDA: Projective Radial Distortion Averaging","summary":"We tackle the problem of automatic calibration of radially distorted cameras\nin challenging conditions. Accurately determining distortion parameters\ntypically requires either 1) solving the full Structure from Motion (SfM)\nproblem involving camera poses, 3D points, and the distortion parameters, which\nis only possible if many images with sufficient overlap are provided, or 2)\nrelying heavily on learning-based methods that are comparatively less accurate.\nIn this work, we demonstrate that distortion calibration can be decoupled from\n3D reconstruction, maintaining the accuracy of SfM-based methods while avoiding\nmany of the associated complexities. This is achieved by working in Projective\nSpace, where the geometry is unique up to a homography, which encapsulates all\ncamera parameters except for distortion. Our proposed method, Projective Radial\nDistortion Averaging, averages multiple distortion estimates in a fully\nprojective framework without creating 3d points and full bundle adjustment. By\nrelying on pairwise projective relations, our methods support any\nfeature-matching approaches without constructing point tracks across multiple\nimages.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T08:22:59Z"}
{"aid":"http://arxiv.org/abs/2504.16503v1","title":"Neuro-Evolutionary Approach to Physics-Aware Symbolic Regression","summary":"Symbolic regression is a technique that can automatically derive analytic\nmodels from data. Traditionally, symbolic regression has been implemented\nprimarily through genetic programming that evolves populations of candidate\nsolutions sampled by genetic operators, crossover and mutation. More recently,\nneural networks have been employed to learn the entire analytical model, i.e.,\nits structure and coefficients, using regularized gradient-based optimization.\nAlthough this approach tunes the model's coefficients better, it is prone to\npremature convergence to suboptimal model structures. Here, we propose a\nneuro-evolutionary symbolic regression method that combines the strengths of\nevolutionary-based search for optimal neural network (NN) topologies with\ngradient-based tuning of the network's parameters. Due to the inherent high\ncomputational demand of evolutionary algorithms, it is not feasible to learn\nthe parameters of every candidate NN topology to full convergence. Thus, our\nmethod employs a memory-based strategy and population perturbations to enhance\nexploitation and reduce the risk of being trapped in suboptimal NNs. In this\nway, each NN topology can be trained using only a short sequence of\nbackpropagation iterations. The proposed method was experimentally evaluated on\nthree real-world test problems and has been shown to outperform other NN-based\napproaches regarding the quality of the models obtained.","main_category":"cs.NE","categories":"cs.NE,cs.LG","published":"2025-04-23T08:29:53Z"}
{"aid":"http://arxiv.org/abs/2504.16512v1","title":"Criteria of Renormalizability in Effective Field Theories","summary":"Any effective field theory relies on power counting rules that allow one to\nperform a systematic expansion of calculated quantities in terms of some soft\nscales. However, a naive power counting can be violated due to the presence of\nvarious hard scales in a given scheme. A typical example of such a scale is an\nultraviolet regulator. This issue is particularly challenging when the\ninteraction is nonperturbative. The power counting is expected to be restored\nin the course of renormalization, that is by redefining bare low-energy\nconstants in the effective Lagrangian. Whether this procedure eventually leads\nto a self-consistent framework is not a priory obvious. We discuss various\ncriteria of renormalizability in application to nuclear chiral effective field\ntheory and provide several instructive counterexamples.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-23T08:38:24Z"}
{"aid":"http://arxiv.org/abs/2504.16519v1","title":"Exciton Basis Description of Ultrafast Triplet Separation in\n  Pentacene-(Tetracene)2-Pentacene Intramolecular Singlet Fission Chromophore","summary":"Precise understanding of the electronic structures of optically dark\ntriplet-triplet multiexcitons that are the intermediate states in singlet\nfission (SF) continues to be a challenge. This is particularly true for\nintramolecular singlet fission (iSF) chromophores, that are oligomers of large\nmonomer molecules. We have performed quantum many-body calculations of the\ncomplete set of excited states relevant to iSF in\nPentacene-(Tetracene)2-Pentacene oligomers, consisting of two terminal\npentacene monomers linked by two tetracene monomers. Our computations use an\nexciton basis that gives physical pictorial descriptions of all eigenstates,\nand are performed over an active space of twenty-eight monomer molecular\norbitals, including configuration interaction with all relevant quadruple\nexcitations within the active space, thereby ensuring very high precision. We\ndiscuss the many-electron structures of the optical predominantly intramonomer\nspin-singlets, intermonomer charge-transfer excitations, and most importantly,\nthe complete set of low energy covalent triplet-triplet multiexcitons. We are\nable to explain the weak binding energy of the pentacene-tetracene\ntriplet-triplet eigenstate that is generated following photoexcitation. We\nexplain the increase in lifetime with increasing numbers of tetracene monomers\nof the transient absorption associated with contiguous pentacene-tetracene\ntriplet-triplet in this family of oligomers. We are consequently able to give a\npictorial description of the triplet separation following generation of the\ninitial triplet-triplet, leading to a state with individual triplets occupying\nonly the two pentacene monomers. We expect many applications of our theoretical\napproach to triplet separation.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-23T08:44:23Z"}
{"aid":"http://arxiv.org/abs/2504.16526v1","title":"Using Causal Inference to Test Systems with Hidden and Interacting\n  Variables: An Evaluative Case Study","summary":"Software systems with large parameter spaces, nondeterminism and high\ncomputational cost are challenging to test. Recently, software testing\ntechniques based on causal inference have been successfully applied to systems\nthat exhibit such characteristics, including scientific models and autonomous\ndriving systems. One significant limitation is that these are restricted to\ntest properties where all of the variables involved can be observed and where\nthere are no interactions between variables. In practice, this is rarely\nguaranteed; the logging infrastructure may not be available to record all of\nthe necessary runtime variable values, and it can often be the case that an\noutput of the system can be affected by complex interactions between variables.\nTo address this, we leverage two additional concepts from causal inference,\nnamely effect modification and instrumental variable methods. We build these\nconcepts into an existing causal testing tool and conduct an evaluative case\nstudy which uses the concepts to test three system-level requirements of CARLA,\na high-fidelity driving simulator widely used in autonomous vehicle development\nand testing. The results show that we can obtain reliable test outcomes without\nrequiring large amounts of highly controlled test data or instrumentation of\nthe code, even when variables interact with each other and are not recorded in\nthe test data.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-23T08:50:24Z"}
{"aid":"http://arxiv.org/abs/2504.16562v1","title":"A Vision for AI-Driven Adaptation of Dynamic AR Content to Users and\n  Environments","summary":"Augmented Reality (AR) is transforming the way we interact with virtual\ninformation in the physical world. By overlaying digital content in real-world\nenvironments, AR enables new forms of immersive and engaging experiences.\nHowever, existing AR systems often struggle to effectively manage the many\ninteractive possibilities that AR presents. This vision paper speculates on\nAI-driven approaches for adaptive AR content placement, dynamically adjusting\nto user movement and environmental changes. By leveraging machine learning\nmethods, such a system would intelligently manage content distribution between\nAR projections integrated into the external environment and fixed static\ncontent, enabling seamless UI layout and potentially reducing users' cognitive\nload. By exploring the possibilities of AI-driven dynamic AR content placement,\nwe aim to envision new opportunities for innovation and improvement in various\nindustries, from urban navigation and workplace productivity to immersive\nlearning and beyond. This paper outlines a vision for the development of more\nintuitive, engaging, and effective AI-powered AR experiences.","main_category":"cs.HC","categories":"cs.HC,cs.AI","published":"2025-04-23T09:42:38Z"}
{"aid":"http://arxiv.org/abs/2504.16563v1","title":"Enhancing LLM-Based Agents via Global Planning and Hierarchical\n  Execution","summary":"Intelligent agent systems based on Large Language Models (LLMs) have shown\ngreat potential in real-world applications. However, existing agent frameworks\nstill face critical limitations in task planning and execution, restricting\ntheir effectiveness and generalizability. Specifically, current planning\nmethods often lack clear global goals, leading agents to get stuck in local\nbranches, or produce non-executable plans. Meanwhile, existing execution\nmechanisms struggle to balance complexity and stability, and their limited\naction space restricts their ability to handle diverse real-world tasks. To\naddress these limitations, we propose GoalAct, a novel agent framework that\nintroduces a continuously updated global planning mechanism and integrates a\nhierarchical execution strategy. GoalAct decomposes task execution into\nhigh-level skills, including searching, coding, writing and more, thereby\nreducing planning complexity while enhancing the agents' adaptability across\ndiverse task scenarios. We evaluate GoalAct on LegalAgentBench, a benchmark\nwith multiple types of legal tasks that require the use of multiple types of\ntools. Experimental results demonstrate that GoalAct achieves state-of-the-art\n(SOTA) performance, with an average improvement of 12.22% in success rate.\nThese findings highlight GoalAct's potential to drive the development of more\nadvanced intelligent agent systems, making them more effective across complex\nreal-world applications. Our code can be found at\nhttps://github.com/cjj826/GoalAct.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-23T09:43:40Z"}
{"aid":"http://arxiv.org/abs/2504.16568v1","title":"Relatively big projective modules and their applications to direct sum\n  decompositions","summary":"Countably generated projective modules that are relatively big with respect\nto a trace ideal were introduced by P. P\\v{r}\\'ihoda, as an extension of Bass'\nuniformly big projectives. It has already been proved that there are a number\nof interesting examples of rings whose countably generated projective modules\nare always relatively big. In this paper, we increase the list of such\nexamples, showing that it includes all right noetherian rings satisfying a\npolynomial identity.\n  We also show that countably generated projective modules over locally\nsemiperfect torsion-free algebras over $h$-local domains are always relatively\nbig. This last result applies to endomorphism rings of finitely generated\ntorsion-free modules over $h$-local domains. As a consequence, we can give a\ncomplete characterization of those $h$-local domains of Krull dimension $1$ for\nwhich every direct summand of a direct sum of copies of a single finitely\ngenerated torsion-free module is again a direct sum of finitely generated\nmodules.","main_category":"math.AC","categories":"math.AC,math.RA,math.RT","published":"2025-04-23T09:46:53Z"}
{"aid":"http://arxiv.org/abs/2504.16578v1","title":"Spontaneous symmetry breaking induced by curvature : Analysis via\n  non-perturbative 2PI Hartree approximation","summary":"In this work we investigate the spontaneous symmetry breaking (SSB) induced\nby a classical background spacetime's curvature, via the 2 particle irreducible\n(2PI) non-perturbative effective action formalism. We use the standard\nSchwinger-DeWitt local expansion of the Feynman propagator, appropriate to\nprobe the effect of spacetime curvature on the local or short scale physics.\nRecently it was shown using perturbative computations that such SSB is possible\nwith a scalar with a quartic self interaction, positive rest mass squared and\npositive non-minimal coupling. Here we confirm in the two loop Hartree\napproximation that curvature can indeed induce SSB for such a theory. SSB for\nsuch a model is not possible in a flat spacetime. The 2PI technique does not\nonly resum the self energy resulting in mass generation, but also resums, as we\nhave discussed, curvature terms through such mass generation. We have\nexplicitly discussed our results in the context of the de Sitter spacetime,\nalthough our calculations are valid for any non-singular curved spacetime. We\nshow that, in contrast to the perturbative results, SSB is possible with a\nvanishing non-minimal coupling. These results are further extended to the case\nof an $O(N)$ symmetric scalar field theory. Restoration of the broken symmetry\nin the thermal case is also briefly discussed.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-23T10:00:31Z"}
{"aid":"http://arxiv.org/abs/2504.16629v1","title":"Finite-strain constitutive model for shape memory alloys formulated in\n  the logarithmic strain space","summary":"This work presents a finite-strain version of an established\nthree-dimensional constitutive model for polycrystalline shape memory alloys\n(SMA) that is able to account for the large deformations and rotations that SMA\ncomponents may undergo. The model is constructed by applying the logarithmic\nstrain space approach to the original small-strain model, which was formulated\nwithin the Generalized Standard Materials framework and features a refined\ndissipation (rate) function. Additionally, the free energy function is\naugmented to be more versatile in capturing the transformation kinetics. The\nmodel is implemented into finite element software. To demonstrate the model\nperformance and validate the implementation, material parameters are fitted to\nthe experimental data of two SMA, and two computational simulations of SMA\ncomponents are conducted. The applied approach is highly flexible from the\nperspective of the future incorporation of other phenomena, e.g.,\nirreversibility associated with plasticity, into the model.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-23T11:39:23Z"}
{"aid":"http://arxiv.org/abs/2504.16633v1","title":"Interactions of mechanical rarefaction solitary waves","summary":"Interactions between solitary waves have been pivotal to understanding\nnonlinear phenomena across various disciplines. The dynamics of rarefaction\nsolitary waves holds great potential, yet their fundamental characteristics and\ninteractions remain only partially understood through experimental means in\nmechanical metamaterials. Previous studies highlighted their existence and\nproposed applications, such as waveguides, impact mitigation, and energy\nharvesting. Challenges, including energy dissipation and a lack of precise\nmeasurement techniques, have hindered deeper exploration, most notably of\nsolitonic collisions. In this work, we provide a definitive platform for\nexamining pure rarefaction solitons propagating through a strain-softening\nmechanical lattice, addressing these challenges. Employing a theoretical\nframework based on the Boussinesq approximation and multiple-scale analysis, we\npredict soliton behavior, including phase shifts resulting from head-on\ncollisions. These theoretical insights are corroborated through numerical\nsimulations and systematic experiments designed to generate and measure pure\nrarefaction solitons with high precision. Both symmetric and asymmetric\ncollisions are examined, revealing practically elastic interaction behaviors\nand amplitude-dependent phase shifts. Furthermore, collision dynamics, such as\nspeed and phase shifts during rarefaction soliton collisions, from the\nexperimental results show agreement with theoretical and numerical models.\nThese results validate our experimental platform and findings, underscoring the\npotential of mechanical rarefaction solitons as robust, controllable wave\npackets. This suggests a robust paradigm for exploring nonlinear wave\ninteractions in mechanical systems, opening new application avenues in\nmechanical metamaterials, such as wave-based computing and advanced signal\nprocessing.","main_category":"nlin.PS","categories":"nlin.PS","published":"2025-04-23T11:49:30Z"}
{"aid":"http://arxiv.org/abs/2504.16638v1","title":"Existence and uniqueness of Leray-Hopf weak solution for the\n  inhomogeneous 2D Navier--Stokes equations without vacuum","summary":"We prove the existence and uniqueness of weak solutions of the inhomogeneous\nincompressible Navier--Stokes equations without vacuum using the relative\nenergy method.\n  We present a novel and direct proof of the existence of weak solutions based\non approximation with more regular solutions. The analysis we employ to justify\nthe strong convergence reveals how to conclude the stability and uniqueness of\nweak solutions. To the best of our knowledge, these stability estimates are\ncompletely new. Furthermore, for the first time, we establish energy\nconservation for weak solutions.","main_category":"math.AP","categories":"math.AP","published":"2025-04-23T11:58:03Z"}
{"aid":"http://arxiv.org/abs/2504.16639v1","title":"DAPLSR: Data Augmentation Partial Least Squares Regression Model via\n  Manifold Optimization","summary":"Traditional Partial Least Squares Regression (PLSR) models frequently\nunderperform when handling data characterized by uneven categories. To address\nthe issue, this paper proposes a Data Augmentation Partial Least Squares\nRegression (DAPLSR) model via manifold optimization. The DAPLSR model\nintroduces the Synthetic Minority Over-sampling Technique (SMOTE) to increase\nthe number of samples and utilizes the Value Difference Metric (VDM) to select\nthe nearest neighbor samples that closely resemble the original samples for\ngenerating synthetic samples. In solving the model, in order to obtain a more\naccurate numerical solution for PLSR, this paper proposes a manifold\noptimization method that uses the geometric properties of the constraint space\nto improve model degradation and optimization. Comprehensive experiments show\nthat the proposed DAPLSR model achieves superior classification performance and\noutstanding evaluation metrics on various datasets, significantly outperforming\nexisting methods.","main_category":"cs.LG","categories":"cs.LG,cs.IR","published":"2025-04-23T11:58:28Z"}
{"aid":"http://arxiv.org/abs/2504.16642v1","title":"Hitting and Covering Affine Families of Convex Polyhedra, with\n  Applications to Robust Optimization","summary":"Geometric hitting set problems, in which we seek a smallest set of points\nthat collectively hit a given set of ranges, are ubiquitous in computational\ngeometry. Most often, the set is discrete and is given explicitly. We propose\nnew variants of these problems, dealing with continuous families of convex\npolyhedra, and show that they capture decision versions of the two-level finite\nadaptability problem in robust optimization. We show that these problems can be\nsolved in strongly polynomial time when the size of the hitting/covering set\nand the dimension of the polyhedra and the parameter space are constant. We\nalso show that the hitting set problem can be solved in strongly quadratic time\nfor one-parameter families of convex polyhedra in constant dimension. This\nleads to new tractability results for finite adaptability that are the first\nones with so-called left-hand-side uncertainty, where the underlying problem is\nnon-linear.","main_category":"cs.CG","categories":"cs.CG,math.OC","published":"2025-04-23T12:01:16Z"}
{"aid":"http://arxiv.org/abs/2504.16646v1","title":"Pareto-optimality of pulses for robust population transfer in a\n  ladder-type qutrit","summary":"Frequency-modulation schemes have recently emerged as alternatives to\nstandard Rabi pulses for realizing robust quantum operations. In this work, we\ninvestigate short-duration population transfer between the ground and first\nexcited states of a ladder-type qutrit, with the goal of minimizing leakage\ninto the second excited state. Our multiobjective approach seeks to reduce the\nmaximum transient second-state population and maximize detuning robustness.\nInspired by two-state models, such as the Allen-Eberly and Hioe-Carroll models,\nwe extend these concepts to our system, exploring a range of pulse families,\nincluding those with super-Gaussian envelopes and polynomial detuning\nfunctions. We identify Pareto fronts for pulse models constructed from one of\ntwo envelope functions paired with one of four detuning functions. We then\nanalyze how each Pareto-optimal pulse parameter influences the two Pareto\nobjectives and amplitude robustness.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T12:06:56Z"}
{"aid":"http://arxiv.org/abs/2504.16651v1","title":"MAYA: Addressing Inconsistencies in Generative Password Guessing through\n  a Unified Benchmark","summary":"The rapid evolution of generative models has led to their integration across\nvarious fields, including password guessing, aiming to generate passwords that\nresemble human-created ones in complexity, structure, and patterns. Despite\ngenerative model's promise, inconsistencies in prior research and a lack of\nrigorous evaluation have hindered a comprehensive understanding of their true\npotential. In this paper, we introduce MAYA, a unified, customizable,\nplug-and-play password benchmarking framework. MAYA provides a standardized\napproach for evaluating generative password-guessing models through a rigorous\nset of advanced testing scenarios and a collection of eight real-life password\ndatasets. Using MAYA, we comprehensively evaluate six state-of-the-art\napproaches, which have been re-implemented and adapted to ensure\nstandardization, for a total of over 15,000 hours of computation. Our findings\nindicate that these models effectively capture different aspects of human\npassword distribution and exhibit strong generalization capabilities. However,\ntheir effectiveness varies significantly with long and complex passwords.\nThrough our evaluation, sequential models consistently outperform other\ngenerative architectures and traditional password-guessing tools, demonstrating\nunique capabilities in generating accurate and complex guesses. Moreover,\nmodels learn and generate different password distributions, enabling a\nmulti-model attack that outperforms the best individual model. By releasing\nMAYA, we aim to foster further research, providing the community with a new\ntool to consistently and reliably benchmark password-generation techniques. Our\nframework is publicly available at\nhttps://github.com/williamcorrias/MAYA-Password-Benchmarking","main_category":"cs.CR","categories":"cs.CR,cs.AI,cs.LG","published":"2025-04-23T12:16:59Z"}
{"aid":"http://arxiv.org/abs/2504.16669v1","title":"Binarity at LOw Metallicity (BLOeM): Bayesian inference of natal kicks\n  from inert black hole binaries","summary":"Context. The emerging population of inert black hole binaries (BHBs) provides\na unique opportunity to constrain black hole (BH) formation physics. These\nsystems are composed of a stellar-mass BH in a wide orbit around a\nnon-degenerate star with no observed Xray emission. Inert BHBs allow for narrow\nconstraints to be inferred on the natal kick and mass loss during BH-forming\ncore-collapse events. Aims. In anticipation of the upcoming BLOeM survey, we\naim to provide tight constraints on BH natal kicks by exploiting the full\nparameter space obtained from combined spectroscopic and astrometric data to\ncharacterize the orbits of inert BHBs. Multi-epoch spectroscopy from the BLOeM\nproject will provide measurements of periods, eccentricities, and radial\nvelocities for inert BHBs in the SMC, which complements Gaia astrometric\nobservations of proper motions. Methods. We present a Bayesian parameter\nestimation framework to infer natal kicks and mass loss during core-collapse\nfrom inert BHBs, accounting for all available observables, including the\nsystemic velocity and its orientation relative to the orbital plane. The\nframework further allows for circumstances when some of the observables are\nunavailable, such as for the distant BLOeM sources which preclude resolved\norbits. Results. With our new framework, we are able to distinguish between BH\nformation channels, even in the absence of a resolved orbit. In cases when the\npre-explosion orbit can be assumed to be circular, we precisely recover the\nparameters of the core-collapse, highlighting the importance of understanding\nthe eccentricity landscape of pre-explosion binaries, both theoretically and\nobservationally. Treating the near-circular, inert BHB, VFTS 243, as a\nrepresentative of the anticipated BLOeM systems, we constrain the natal kick to\nless than 27 km/s and the mass loss to less than 2.9 Msun within a 90% credible\ninterval.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA,astro-ph.HE","published":"2025-04-23T12:36:32Z"}
{"aid":"http://arxiv.org/abs/2504.16677v1","title":"A Post-trainer's Guide to Multilingual Training Data: Uncovering\n  Cross-lingual Transfer Dynamics","summary":"In order for large language models to be useful across the globe, they are\nfine-tuned to follow instructions on multilingual data. Despite the ubiquity of\nsuch post-training, a clear understanding of the dynamics that enable\ncross-lingual transfer remains elusive. This study examines cross-lingual\ntransfer (CLT) dynamics in realistic post-training settings. We study two model\nfamilies of up to 35B parameters in size trained on carefully controlled\nmixtures of multilingual data on three generative tasks with varying levels of\ncomplexity (summarization, instruction following, and mathematical reasoning)\nin both single-task and multi-task instruction tuning settings. Overall, we\nfind that the dynamics of cross-lingual transfer and multilingual performance\ncannot be explained by isolated variables, varying depending on the combination\nof post-training settings. Finally, we identify the conditions that lead to\neffective cross-lingual transfer in practice.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-23T12:52:49Z"}
{"aid":"http://arxiv.org/abs/2504.16683v1","title":"MCMC for Bayesian estimation of Differential Privacy from Membership\n  Inference Attacks","summary":"We propose a new framework for Bayesian estimation of differential privacy,\nincorporating evidence from multiple membership inference attacks (MIA).\nBayesian estimation is carried out via a Markov chain Monte Carlo (MCMC)\nalgorithm, named MCMC-DP-Est, which provides an estimate of the full posterior\ndistribution of the privacy parameter (e.g., instead of just credible\nintervals). Critically, the proposed method does not assume that privacy\nauditing is performed with the most powerful attack on the worst-case (dataset,\nchallenge point) pair, which is typically unrealistic. Instead, MCMC-DP-Est\njointly estimates the strengths of MIAs used and the privacy of the training\nalgorithm, yielding a more cautious privacy analysis. We also present an\neconomical way to generate measurements for the performance of an MIA that is\nto be used by the MCMC method to estimate privacy. We present the use of the\nmethods with numerical examples with both artificial and real data.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-23T13:10:37Z"}
{"aid":"http://arxiv.org/abs/2504.16696v1","title":"Evaluating Meta-Regression Techniques: A Simulation Study on\n  Heterogeneity in Location and Time","summary":"In this paper, we conduct a simulation study to evaluate conventional\nmeta-regression approaches (study-level random, fixed, and mixed effects)\nagainst seven methodology specifications new to meta-regressions that control\njoint heterogeneity in location and time (including a new one that we\nintroduce). We systematically vary heterogeneity levels to assess statistical\npower, estimator bias and model robustness for each methodology specification.\nThis assessment focuses on three aspects: performance under joint heterogeneity\nin location and time, the effectiveness of our proposed settings incorporating\nlocation fixed effects and study-level fixed effects with a time trend, as well\nas guidelines for model selection. The results show that jointly modeling\nheterogeneity when heterogeneity is in both dimensions improves performance\ncompared to modeling only one type of heterogeneity.","main_category":"econ.EM","categories":"econ.EM","published":"2025-04-23T13:27:52Z"}
{"aid":"http://arxiv.org/abs/2504.16710v1","title":"On the Asymptotic MSE-Optimality of Parametric Bayesian Channel\n  Estimation in mmWave Systems","summary":"The mean square error (MSE)-optimal estimator is known to be the conditional\nmean estimator (CME). This paper introduces a parametric channel estimation\ntechnique based on Bayesian estimation. This technique uses the estimated\nchannel parameters to parameterize the well-known LMMSE channel estimator. We\nfirst derive an asymptotic CME formulation that holds for a wide range of\npriors on the channel parameters. Based on this, we show that parametric\nBayesian channel estimation is MSE-optimal for high signal-to-noise ratio (SNR)\nand/or long coherence intervals, i.e., many noisy observations provided within\none coherence interval. Numerical simulations validate the derived\nformulations.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-23T13:41:02Z"}
{"aid":"http://arxiv.org/abs/2504.16754v1","title":"HEMA : A Hippocampus-Inspired Extended Memory Architecture for\n  Long-Context AI Conversations","summary":"Large language models (LLMs) struggle with maintaining coherence in extended\nconversations spanning hundreds of turns, despite performing well within their\ncontext windows. This paper introduces HEMA (Hippocampus-Inspired Extended\nMemory Architecture), a dual-memory system inspired by human cognitive\nprocesses. HEMA combines Compact Memory - a continuously updated one-sentence\nsummary preserving global narrative coherence, and Vector Memory - an episodic\nstore of chunk embeddings queried via cosine similarity. When integrated with a\n6B-parameter transformer, HEMA maintains coherent dialogues beyond 300 turns\nwhile keeping prompt length under 3,500 tokens. Experimental results show\nsubstantial improvements: factual recall accuracy increases from 41% to 87%,\nand human-rated coherence improves from 2.7 to 4.3 on a 5-point scale. With 10K\nindexed chunks, Vector Memory achieves P@5 >= 0.80 and R@50 >= 0.74, doubling\nthe area under the precision-recall curve compared to summarization-only\napproaches. Ablation studies reveal two key insights: semantic forgetting\nthrough age-weighted pruning reduces retrieval latency by 34% with minimal\nrecall loss, and a two-level summary hierarchy prevents cascade errors in\nultra-long conversations exceeding 1,000 turns. HEMA demonstrates that\ncombining verbatim recall with semantic continuity provides a practical\nsolution for privacy-aware conversational AI capable of month-long dialogues\nwithout model retraining.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-23T14:27:12Z"}
{"aid":"http://arxiv.org/abs/2504.16755v1","title":"QAOA-PCA: Enhancing Efficiency in the Quantum Approximate Optimization\n  Algorithm via Principal Component Analysis","summary":"The Quantum Approximate Optimization Algorithm (QAOA) is a promising\nvariational algorithm for solving combinatorial optimization problems on\nnear-term devices. However, as the number of layers in a QAOA circuit\nincreases, which is correlated with the quality of the solution, the number of\nparameters to optimize grows linearly. This results in more iterations required\nby the classical optimizer, which results in an increasing computational burden\nas more circuit executions are needed. To mitigate this issue, we introduce\nQAOA-PCA, a novel reparameterization technique that employs Principal Component\nAnalysis (PCA) to reduce the dimensionality of the QAOA parameter space. By\nextracting principal components from optimized parameters of smaller problem\ninstances, QAOA-PCA facilitates efficient optimization with fewer parameters on\nlarger instances. Our empirical evaluation on the prominent MaxCut problem\ndemonstrates that QAOA-PCA consistently requires fewer iterations than standard\nQAOA, achieving substantial efficiency gains. While this comes at the cost of a\nslight reduction in approximation ratio compared to QAOA with the same number\nof layers, QAOA-PCA almost always outperforms standard QAOA when matched by\nparameter count. QAOA-PCA strikes a favorable balance between efficiency and\nperformance, reducing optimization overhead without significantly compromising\nsolution quality.","main_category":"cs.LG","categories":"cs.LG,cs.ET","published":"2025-04-23T14:27:31Z"}
{"aid":"http://arxiv.org/abs/2504.16772v1","title":"Thermal Evolution and Mass Loss on Short-Period, Low-Mass Planets During\n  FU Orionis Outbursts","summary":"Ultra-short-period (USP) planets represent a unique class of exoplanets\ncharacterized by their tight orbits and relatively low masses, with some also\nexhibiting unusually high iron fractions. Previous work (Becker et al, 2021)\nproposed a dynamical pathway wherein planets can migrate inward due to drag\nfrom sub-Keplerian gas during episodic FU Orionis (FU Ori) outbursts, an abrupt\naccretion phenomenon exhibited by young stellar objects, thereby potentially\npopulating USP orbits. However, the implications of this migration process on\nthe structural and compositional evolution of these planets remain unexplored.\nIn this work, we model the response of a planet's surface material to the high\ndisk temperatures characteristic of an FU Ori event and compute the fraction of\nan Earth-like planet's mass that will be lost due to vaporization and\nsubsequent turbulent diffusion of gaseous molecules during the FU Ori event. We\nfind that low-mass planets may lose a substantial fraction of their mantle mass\nduring FU Ori events, potentially contributing to the observed prevalence of\nlow-mass, iron-rich USP planets.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-04-23T14:43:54Z"}
{"aid":"http://arxiv.org/abs/2504.16790v1","title":"Toroidal black holes in four dimensions","summary":"From a purely geometric (kinematic) perspective, black holes in four\ndimensional spacetimes can have event horizons with arbitrary topologies. It is\nonly when energy conditions are imposed that the horizon's shape is constrained\nto be spherical. Despite this, exploring exotic horizon topologies remains\ntheoretically intriguing since it allows to unveil structural aspects of\nGeneral Relativity and gain intuition on energy condition violations. In the\naxisymmetric case, besides the well-known spherical topology, only a toroidal\ntopology is consistent with the symmetry. Complete solutions, describing the\nentire exterior region of such toroidal black holes without singularities, have\nnot been reported yet. To the best of our knowledge, the construction we\npresent here is the first explicit example of a toroidal black hole solution in\nfour spacetime dimensions that is free of singularities in the external region.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-23T15:06:50Z"}
{"aid":"http://arxiv.org/abs/2504.16795v1","title":"Random Long-Context Access for Mamba via Hardware-aligned Hierarchical\n  Sparse Attention","summary":"A key advantage of Recurrent Neural Networks (RNNs) over Transformers is\ntheir linear computational and space complexity enables faster training and\ninference for long sequences. However, RNNs are fundamentally unable to\nrandomly access historical context, and simply integrating attention mechanisms\nmay undermine their efficiency advantages. To overcome this limitation, we\npropose \\textbf{H}ierarchical \\textbf{S}parse \\textbf{A}ttention (HSA), a novel\nattention mechanism that enhances RNNs with long-range random access\nflexibility while preserving their merits in efficiency and length\ngeneralization. HSA divides inputs into chunks, selecting the top-$k$ chunks\nand hierarchically aggregates information. The core innovation lies in learning\ntoken-to-chunk relevance based on fine-grained token-level information inside\neach chunk. This approach enhances the precision of chunk selection across both\nin-domain and out-of-domain context lengths. To make HSA efficient, we further\nintroduce a hardware-aligned kernel design. By combining HSA with Mamba, we\nintroduce RAMba, which achieves perfect accuracy in passkey retrieval across 64\nmillion contexts despite pre-training on only 4K-length contexts, and\nsignificant improvements on various downstream tasks, with nearly constant\nmemory footprint. These results show RAMba's huge potential in long-context\nmodeling.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-23T15:15:06Z"}
{"aid":"http://arxiv.org/abs/2504.16809v1","title":"Rotating effects on the Hall conductivity in a quantum dot","summary":"We investigate the behavior of the quantized Hall conductivity in a\ntwo-dimensional quantum system under rotating effects, a uniform magnetic\nfield, and an Aharonov-Bohm (AB) flux tube. By varying the angular velocity and\nthe AB flux, we analyze their impact on the formation, shifting, and structure\nof quantized Hall plateaus. Our results reveal that rotation modifies the\nenergy spectrum, leading to slight shifts in the plateau positions and\nvariations in their widths. Additionally, we identify Aharonov-Bohm-type\noscillations in $\\sigma_{\\text{Hall}}$, which become more pronounced for lower\nvalues of the cyclotron frequency $\\omega_c$, indicating enhanced quantum\ninterference effects in the low-field regime. These oscillations are further\nmodulated by $\\Omega$, affecting their periodicity and amplitude. The interplay\nbetween the confinement frequency $\\omega_0$, the cyclotron frequency\n$\\omega_c$, and the rotational effects plays a crucial role in determining the\noverall behavior of $\\sigma_{\\text{Hall}}$. Our findings provide insights into\nthe interplay between rotation, magnetic field, and quantum interference\neffects, which are relevant for experimental investigations of quantum Hall\nsystems in rotating systems.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,quant-ph","published":"2025-04-23T15:27:08Z"}
{"aid":"http://arxiv.org/abs/2504.16811v1","title":"A novel method for measuring the attenuation length and the group\n  velocity of transparent liquids in a variable length cavity","summary":"The transparency of liquid scintillators or water is an important parameter\nfor many detectors in particle and astroparticle physics. In this work, the\nCavity Enhanced Long Light Path Attenuation Length Screening (CELLPALS) method\nfor the determination of the attenuation length is presented for the first\ntime. The method is based on an experimental setup similar to a Fabry-P\\'erot\ninterferometer but adding up multiple-reflected intensities of a modulated\nlight source. CELLPALS was developed to measure the attenuation length of\nhighly transparent liquids (> 10 m) with significantly lower uncertainties than\nwith UV-Vis spectroscopy, which is a standard method for determining the\nattenuation length. In addition to the attenuation length, the group velocity\nof light in the sample can also be derived from the free spectral range of the\ncavity, which is not provided by any conventional method for determining the\nattenuation length. In this work, the CELLPALS method, its achievable precision\nand an experimental setup to demonstrate its feasibility are discussed. The\nattenuation lengths and group velocities of several transparent liquids were\nmeasured at wavelengths between 420 nm and 435 nm. In addition, the attenuation\nlength and group velocity of linear alkylbenzene (LAB) samples after different\npurification stages and a purified LAB-based liquid scintillator were measured\nat a wavelength of 425 nm. The results confirmed the potential of CELLPALS to\ndetermine the attenuation length with an uncertainty of ~ 2 %. The group\nvelocity of light in the sample can be determined with an uncertainty of ~ 0.03\n%.","main_category":"physics.ins-det","categories":"physics.ins-det,hep-ex","published":"2025-04-23T15:30:04Z"}
{"aid":"http://arxiv.org/abs/2504.16836v1","title":"Snorkeling in dark waters: A longitudinal surface exploration of unique\n  Tor Hidden Services (Extended Version)","summary":"The Onion Router (Tor) is a controversial network whose utility is constantly\nunder scrutiny. On the one hand, it allows for anonymous interaction and\ncooperation of users seeking untraceable navigation on the Internet. This\nfreedom also attracts criminals who aim to thwart law enforcement\ninvestigations, e.g., trading illegal products or services such as drugs or\nweapons. Tor allows delivering content without revealing the actual hosting\naddress, by means of .onion (or hidden) services. Different from regular\ndomains, these services can not be resolved by traditional name services, are\nnot indexed by regular search engines, and they frequently change. This\ngenerates uncertainty about the extent and size of the Tor network and the type\nof content offered.\n  In this work, we present a large-scale analysis of the Tor Network. We\nleverage our crawler, dubbed Mimir, which automatically collects and visits\ncontent linked within the pages to collect a dataset of pages from more than\n25k sites. We analyze the topology of the Tor Network, including its depth and\nreachability from the surface web. We define a set of heuristics to detect the\npresence of replicated content (mirrors) and show that most of the analyzed\ncontent in the Dark Web (82% approx.) is a replica of other content. Also, we\ntrain a custom Machine Learning classifier to understand the type of content\nthe hidden services offer. Overall, our study provides new insights into the\nTor network, highlighting the importance of initial seeding for focus on\nspecific topics, and optimize the crawling process. We show that previous work\non large-scale Tor measurements does not consider the presence of mirrors,\nwhich biases their understanding of the Dark Web topology and the distribution\nof content.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-23T15:59:16Z"}
{"aid":"http://arxiv.org/abs/2504.16840v1","title":"A Low-Cost Photogrammetry System for 3D Plant Modeling and Phenotyping","summary":"We present an open-source, low-cost photogrammetry system for 3D plant\nmodeling and phenotyping. The system uses a structure-from-motion approach to\nreconstruct 3D representations of the plants via point clouds. Using wheat as\nan example, we demonstrate how various phenotypic traits can be computed easily\nfrom the point clouds. These include standard measurements such as plant height\nand radius, as well as features that would be more cumbersome to measure by\nhand, such as leaf angles and convex hull. We further demonstrate the utility\nof the system through the investigation of specific metrics that may yield\nobjective classifications of erectophile versus planophile wheat canopy\narchitectures.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T16:02:52Z"}
{"aid":"http://arxiv.org/abs/2504.16858v1","title":"Planning with Diffusion Models for Target-Oriented Dialogue Systems","summary":"Target-Oriented Dialogue (TOD) remains a significant challenge in the LLM\nera, where strategic dialogue planning is crucial for directing conversations\ntoward specific targets. However, existing dialogue planning methods generate\ndialogue plans in a step-by-step sequential manner, and may suffer from\ncompounding errors and myopic actions. To address these limitations, we\nintroduce a novel dialogue planning framework, DiffTOD, which leverages\ndiffusion models to enable non-sequential dialogue planning. DiffTOD formulates\ndialogue planning as a trajectory generation problem with conditional guidance,\nand leverages a diffusion language model to estimate the likelihood of the\ndialogue trajectory. To optimize the dialogue action strategies, DiffTOD\nintroduces three tailored guidance mechanisms for different target types,\noffering flexible guidance towards diverse TOD targets at test time. Extensive\nexperiments across three diverse TOD settings show that DiffTOD can effectively\nperform non-myopic lookahead exploration and optimize action strategies over a\nlong horizon through non-sequential dialogue planning, and demonstrates strong\nflexibility across complex and diverse dialogue scenarios. Our code and data\nare accessible through https://anonymous.4open.science/r/DiffTOD.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-23T16:27:15Z"}
{"aid":"http://arxiv.org/abs/2504.16862v1","title":"Neural Network Element Method for Partial Differential Equations","summary":"In this paper, based on the combination of finite element mesh and neural\nnetwork, a novel type of neural network element space and corresponding machine\nlearning method are designed for solving partial differential equations. The\napplication of finite element mesh makes the neural network element space\nsatisfy the boundary value conditions directly on the complex geometric\ndomains. The use of neural networks allows the accuracy of the approximate\nsolution to reach the high level of neural network approximation even for the\nproblems with singularities. We also provide the error analysis of the proposed\nmethod for the understanding. The proposed numerical method in this paper\nprovides the way to enable neural network-based machine learning algorithms to\nsolve a broader range of problems arising from engineering applications.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-23T16:32:30Z"}
{"aid":"http://arxiv.org/abs/2504.16863v1","title":"On graphs with a simple structure of maximal cliques","summary":"We say that a hereditary graph class $\\mathcal{G}$ is \\emph{clique-sparse} if\nthere is a constant $k=k(\\mathcal{G})$ such that for every graph\n$G\\in\\mathcal{G}$, every vertex of $G$ belongs to at most $k$ maximal cliques,\nand any maximal clique of $G$ can be intersected in at most $k$ different ways\nby other maximal cliques.\n  We provide various characterisations of clique-sparse graph classes,\nincluding a list of five parametric forbidden induced subgraphs. We show that\nrecent techniques for proving induced analogues of Menger's Theorem and the\nGrid Theorem of Robertson and Seymour can be lifted to prove induced variants\nin clique-sparse graph classes when replacing ``treewidth'' by\n''tree-independence number''.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-23T16:34:20Z"}
{"aid":"http://arxiv.org/abs/2504.16897v1","title":"Assessing SSL/TLS Certificate Centralization: Implications for Digital\n  Sovereignty","summary":"SSL/TLS is a fundamental technology in the network protocol stack that\nenables encrypted data transmission and authentication of web domains. However,\nthe current model relies on a small number of Certificate Authorities (CAs) to\nprovide and validate certificates, thus creating a highly centralized\necosystem. In this paper, we analyze the degree of centralization of\ncertificate provisioning from CAs in two major political groups: Brazil,\nRussia, India, China, and South Africa (BRICS) and the European Union (EU). We\nhave found that over 75\\% of certificates for both BRICS and EU domains\noriginate from CAs based in the United States, indicating possible risks to\ntheir digital sovereignty due to the high level of external dependency. This\nindicates the need for nations within those groups to research alternatives to\nreduce the high level of dependency on foreign CAs and increase their digital\nautonomy.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-23T17:26:18Z"}
{"aid":"http://arxiv.org/abs/2504.16903v1","title":"Collinear Corrections to the Cachazo-Strominger Soft Theorem","summary":"Soft theorems describe the behavior of scattering amplitudes when one or\nseveral external particles are taken to be energetically soft. In tree-level\ngravity there are universal soft theorems for the three leading orders in the\nsoft expansion, and they can be shown to be equivalent to Ward identities of\nasymptotic symmetries. While the leading and subleading symmetries are\nunderstood as supertranslations and superrotations respectively, the precise\nsymmetry interpretation of the sub-subleading soft theorem is still a matter of\ninvestigation. The form of the sub-subleading soft graviton theorem was\nelucidated by Cachazo and Strominger using a BCFW expansion of graviton\namplitudes. In this work we show that consistency with results based on\nasymptotic charges requires a careful treatment of collinear singularities in\nthe amplitude, giving rise to collinear corrections to the usual\nCachazo-Strominger soft theorem.","main_category":"hep-th","categories":"hep-th","published":"2025-04-23T17:27:52Z"}
{"aid":"http://arxiv.org/abs/2504.16908v1","title":"Axiomatic Equilibrium Selection: The Case of Generic Extensive Form\n  Games","summary":"A solution concept that is a refinement of Nash equilibria selects for each\nfinite game a nonempty collection of closed and connected subsets of Nash\nequilibria as solutions. We impose three axioms for such solution concepts. The\naxiom of backward induction requires each solution to contain a quasi-perfect\nequilibrium. Two invariance axioms posit that solutions of a game are the same\nas those of a game obtained by the addition of strategically irrelevant\nstrategies and players. Stability satisfies these axioms; and any solution\nconcept that satisfies them must, for generic extensive-form games, select from\namong its stable outcomes. A strengthening of the two invariance axioms\nprovides an analogous axiomatization of components of equilibria with a nonzero\nindex.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-23T17:35:47Z"}
{"aid":"http://arxiv.org/abs/2504.16916v1","title":"Zero-shot Sim-to-Real Transfer for Reinforcement Learning-based Visual\n  Servoing of Soft Continuum Arms","summary":"Soft continuum arms (SCAs) soft and deformable nature presents challenges in\nmodeling and control due to their infinite degrees of freedom and non-linear\nbehavior. This work introduces a reinforcement learning (RL)-based framework\nfor visual servoing tasks on SCAs with zero-shot sim-to-real transfer\ncapabilities, demonstrated on a single section pneumatic manipulator capable of\nbending and twisting. The framework decouples kinematics from mechanical\nproperties using an RL kinematic controller for motion planning and a local\ncontroller for actuation refinement, leveraging minimal sensing with visual\nfeedback. Trained entirely in simulation, the RL controller achieved a 99.8%\nsuccess rate. When deployed on hardware, it achieved a 67% success rate in\nzero-shot sim-to-real transfer, demonstrating robustness and adaptability. This\napproach offers a scalable solution for SCAs in 3D visual servoing, with\npotential for further refinement and expanded applications.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-23T17:41:55Z"}
{"aid":"http://arxiv.org/abs/2504.17239v1","title":"Polydisperse polymer networks with irregular topologies","summary":"The structure of polymer networks, defined by chain lengths and connectivity\npatterns, fundamentally influences their bulk properties. Despite decades of\nresearch, many open questions remain regarding structure-property\nrelationships, particularly in heterogeneous networks. While existing polymer\nnetwork models connect chain properties to emergent network behavior, they are\noften limited to monodisperse networks with regular connectivities, making the\nextension to heterogeneous systems an active area of research. In this work, we\nintroduce a novel modeling framework that shifts the focus from individual\npolymer chains to cross-links and their connected chains as the fundamental\nunit of analysis. This perspective enables direct incorporation of structural\nheterogeneity by averaging over cross-links with different chain lengths and\ncoordination numbers. We establish important connections between polymerization\ntheory and statistical descriptors of network structure, providing key\ncomponents of a theoretical foundation for predicting properties from the\nsynthesis parameters. Our results demonstrate that increased variance in\nmonomer numbers generally leads to network softening, while in bimodal\nnetworks, the onset of strain stiffening is controlled by shorter chains and\nthe stiffening response is modulated by the ratio of short to long chains. By\nderiving closed-form approximations valid in both the limits of (1) small\ndeformation and (2) finite deformation but with small polydispersity, we offer\nan efficient computational approach to modeling complex networks. This\nframework represents an advance toward the rational modeling and design of\nheterogeneous polymer networks with structures tailored for specific\nproperties.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-24T04:25:12Z"}
{"aid":"http://arxiv.org/abs/2504.17255v1","title":"3D Deep-learning-based Segmentation of Human Skin Sweat Glands and Their\n  3D Morphological Response to Temperature Variations","summary":"Skin, the primary regulator of heat exchange, relies on sweat glands for\nthermoregulation. Alterations in sweat gland morphology play a crucial role in\nvarious pathological conditions and clinical diagnoses. Current methods for\nobserving sweat gland morphology are limited by their two-dimensional, in\nvitro, and destructive nature, underscoring the urgent need for real-time,\nnon-invasive, quantifiable technologies. We proposed a novel three-dimensional\n(3D) transformer-based multi-object segmentation framework, integrating a\nsliding window approach, joint spatial-channel attention mechanism, and\narchitectural heterogeneity between shallow and deep layers. Our proposed\nnetwork enables precise 3D sweat gland segmentation from skin volume data\ncaptured by optical coherence tomography (OCT). For the first time, subtle\nvariations of sweat gland 3D morphology in response to temperature changes,\nhave been visualized and quantified. Our approach establishes a benchmark for\nnormal sweat gland morphology and provides a real-time, non-invasive tool for\nquantifying 3D structural parameters. This enables the study of individual\nvariability and pathological changes in sweat gland structure, advancing\ndermatological research and clinical applications, including thermoregulation\nand bromhidrosis treatment.","main_category":"eess.IV","categories":"eess.IV,cs.AI,physics.optics","published":"2025-04-24T05:19:47Z"}
{"aid":"http://arxiv.org/abs/2504.17258v1","title":"Group Downsampling with Equivariant Anti-aliasing","summary":"Downsampling layers are crucial building blocks in CNN architectures, which\nhelp to increase the receptive field for learning high-level features and\nreduce the amount of memory/computation in the model. In this work, we study\nthe generalization of the uniform downsampling layer for group equivariant\narchitectures, e.g., G-CNNs. That is, we aim to downsample signals (feature\nmaps) on general finite groups with anti-aliasing. This involves the following:\n(a) Given a finite group and a downsampling rate, we present an algorithm to\nform a suitable choice of subgroup. (b) Given a group and a subgroup, we study\nthe notion of bandlimited-ness and propose how to perform anti-aliasing.\nNotably, our method generalizes the notion of downsampling based on classical\nsampling theory. When the signal is on a cyclic group, i.e., periodic, our\nmethod recovers the standard downsampling of an ideal low-pass filter followed\nby a subsampling operation. Finally, we conducted experiments on image\nclassification tasks demonstrating that the proposed downsampling operation\nimproves accuracy, better preserves equivariance, and reduces model size when\nincorporated into G-equivariant networks","main_category":"cs.LG","categories":"cs.LG,cs.CV,math.GR","published":"2025-04-24T05:29:51Z"}
{"aid":"http://arxiv.org/abs/2504.17270v1","title":"Thermally quenched metastable phase in the Ising model with competing\n  interactions","summary":"Thermal quenching has been used to find metastable materials such as hard\nsteels and metallic glasses. More recently, quenching-based phase control has\nbeen applied to correlated electron systems that exhibit metal--insulator,\nmagnetic or superconducting transitions. Despite the discovery of metastable\nelectronic phases, however, how metastability is achieved through the degrees\nof freedom, which can vary even at low temperatures such as those of an\nelectron, is unclear. Here, we show a thermally quenched metastable phase in\nthe Ising model without conservation of magnetization by Monte Carlo\nsimulations. When multiple types of interactions that stabilize different\nlong-range orders are introduced, the ordering kinetics divergently slow toward\nlow temperatures, meaning that the system will reach a low temperature without\nordering if the cooling rate is high enough. Quantitative analysis of the\ndivergent behavior suggests that the energy barrier for eliminating the local\nstructure of competing orders is the origin of this metastability. Thus, the\npresent simulations show that competing interactions play a key role in\nrealizing metastability.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.stat-mech","published":"2025-04-24T05:58:07Z"}
{"aid":"http://arxiv.org/abs/2504.17271v1","title":"Contrastive Learning for Continuous Touch-Based Authentication","summary":"Smart mobile devices have become indispensable in modern daily life, where\nsensitive information is frequently processed, stored, and transmitted-posing\ncritical demands for robust security controls. Given that touchscreens are the\nprimary medium for human-device interaction, continuous user authentication\nbased on touch behavior presents a natural and seamless security solution.\nWhile existing methods predominantly adopt binary classification under\nsingle-modal learning settings, we propose a unified contrastive learning\nframework for continuous authentication in a non-disruptive manner.\nSpecifically, the proposed method leverages a Temporal Masked Autoencoder to\nextract temporal patterns from raw multi-sensor data streams, capturing\ncontinuous motion and gesture dynamics. The pre-trained TMAE is subsequently\nintegrated into a Siamese Temporal-Attentive Convolutional Network within a\ncontrastive learning paradigm to model both sequential and cross-modal\npatterns. To further enhance performance, we incorporate multi-head attention\nand channel attention mechanisms to capture long-range dependencies and\noptimize inter-channel feature integration. Extensive experiments on public\nbenchmarks and a self-collected dataset demonstrate that our approach\noutperforms state-of-the-art methods, offering a reliable and effective\nsolution for user authentication on mobile devices.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-24T05:58:12Z"}
{"aid":"http://arxiv.org/abs/2504.17285v1","title":"Some remarks on Liouville type theorems for the 3D steady tropical\n  climate model","summary":"Observing the special structure of the system and using the\nPoincar{\\'{e}}-Sobolev inequality, we establish Liouville type theorems for the\n3D steady tropical climate model under certain conditions on $u$, $v$, $\\nabla\n\\theta$. Our results extend and improve a Liouville type result of Cho-In-Yang\n(arXiv:2312.17441).","main_category":"math.AP","categories":"math.AP","published":"2025-04-24T06:26:50Z"}
{"aid":"http://arxiv.org/abs/2504.17327v1","title":"Simple Universally Optimal Dijkstra","summary":"Let G be a weighted (directed) graph with n vertices and m edges. Given a\nsource vertex s, Dijkstra's algorithm computes the shortest path lengths from s\nto all other vertices in O(m + n log n) time. This bound is known to be\nworst-case optimal via a reduction to sorting. Theoretical computer science has\ndeveloped numerous fine-grained frameworks for analyzing algorithmic\nperformance beyond standard worst-case analysis, such as instance optimality\nand output sensitivity. Haeupler et al. [FOCS '24] consider the notion of\nuniversal optimality, a refined complexity measure that accounts for both the\ngraph topology and the edge weights. For a fixed graph topology, the universal\nrunning time of a weighted graph algorithm is defined as its worst-case running\ntime over all possible edge weightings of G. An algorithm is universally\noptimal if no other algorithm achieves a better asymptotic universal running\ntime on any particular graph topology. They show that Dijkstra's algorithm can\nbe made universally optimal by replacing the heap with a custom data structure.\n  We revisit their result. We introduce a simple heap property called timestamp\noptimality, where the cost of popping an element x is logarithmic in the number\nof elements inserted between pushing and popping x. We show that timestamp\noptimal heaps are not only easier to define but also easier to implement. Using\nthese timestamps, we provide a significantly simpler proof that Dijkstra's\nalgorithm, with the right kind of heap, is universally optimal.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-24T07:40:44Z"}
{"aid":"http://arxiv.org/abs/2504.17328v1","title":"On spaces of Euclidean triangles and triangulated Euclidean surfaces","summary":"In this paper, we introduce an asymmetric metric on the space of marked\nEuclidean triangles, and we prove several properties of this metric, including\ntwo equivalent definitions of this metric, one of them comparing ratios of\nfunctions of the edges, and the other one in terms of best Lipschitz maps. We\ngive a description of the geodesics of this metric. We show that this metric is\nFinsler, and give a formula for its infinitesimal Finsler structure. We then\ngeneralise this study to the case of convex Euclidean polygons in the Euclidean\nplane and to surfaces equipped with singular Euclidean structures with an\nunderlying fixed triangulation. After developing some elements of the theory of\ncompleteness and completion of asymmetric metrics which is adapted to our\nsetting, we study the completeness of the metrics we introduce in this paper.\nThese problems and the results obtained are motivated by Thurston's work\ndeveloped in his paper Minimal stretch maps between hyperbolic surfaces. We\nprovide an analogue of Thurston's theory in a Euclidean setting.","main_category":"math.GT","categories":"math.GT","published":"2025-04-24T07:45:38Z"}
{"aid":"http://arxiv.org/abs/2504.17337v1","title":"Error Exponents for DNA Storage Codes with a Variable Number of Reads","summary":"In this paper, we study error exponents for a concatataned coding based class\nof DNA storage codes in which the number of reads performed can be variable.\nThat is, the decoder can sequentially perform reads and choose whether to\noutput the final decision or take more reads, and we are interested in\nminimizing the average number of reads performed rather than a fixed\npre-specified value. We show that this flexibility leads to a considerable\nreduction in the error probability compared to a fixed number of reads, not\nonly in terms of constants in the error exponent but also in the scaling laws.\nThis is shown via an achievability result for a suitably-designed protocol, and\nin certain parameter regimes we additionally establish a matching converse that\nholds for all protocols within a broader concatenated coding based class.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-24T07:56:21Z"}
{"aid":"http://arxiv.org/abs/2504.17349v1","title":"DRC: Enhancing Personalized Image Generation via Disentangled\n  Representation Composition","summary":"Personalized image generation has emerged as a promising direction in\nmultimodal content creation. It aims to synthesize images tailored to\nindividual style preferences (e.g., color schemes, character appearances,\nlayout) and semantic intentions (e.g., emotion, action, scene contexts) by\nleveraging user-interacted history images and multimodal instructions. Despite\nnotable progress, existing methods -- whether based on diffusion models, large\nlanguage models, or Large Multimodal Models (LMMs) -- struggle to accurately\ncapture and fuse user style preferences and semantic intentions. In particular,\nthe state-of-the-art LMM-based method suffers from the entanglement of visual\nfeatures, leading to Guidance Collapse, where the generated images fail to\npreserve user-preferred styles or reflect the specified semantics.\n  To address these limitations, we introduce DRC, a novel personalized image\ngeneration framework that enhances LMMs through Disentangled Representation\nComposition. DRC explicitly extracts user style preferences and semantic\nintentions from history images and the reference image, respectively, to form\nuser-specific latent instructions that guide image generation within LMMs.\nSpecifically, it involves two critical learning stages: 1) Disentanglement\nlearning, which employs a dual-tower disentangler to explicitly separate style\nand semantic features, optimized via a reconstruction-driven paradigm with\ndifficulty-aware importance sampling; and 2) Personalized modeling, which\napplies semantic-preserving augmentations to effectively adapt the disentangled\nrepresentations for robust personalized generation. Extensive experiments on\ntwo benchmarks demonstrate that DRC shows competitive performance while\neffectively mitigating the guidance collapse issue, underscoring the importance\nof disentangled representation learning for controllable and effective\npersonalized image generation.","main_category":"cs.CV","categories":"cs.CV,cs.IR","published":"2025-04-24T08:10:10Z"}
{"aid":"http://arxiv.org/abs/2504.17350v1","title":"First-order store and visibility in name-passing calculi","summary":"The $\\pi$-calculus is the paradigmatical name-passing calculus. While being\npurely name-passing, it allows the representation of higher-order functions and\nstore. We study how $\\pi$-calculus processes can be controlled so that\ncomputations can only involve storage of first-order values. The discipline is\nenforced by a type system that is based on the notion of visibility, coming\nfrom game semantics. We discuss the impact of visibility on the behavioural\ntheory. We propose characterisations of may-testing and barbed equivalence,\nbased on (variants of) trace equivalence and labelled bisimilarity, in the case\nwhere computation is sequential, and in the case where computation is\nwell-bracketed.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-24T08:11:02Z"}
{"aid":"http://arxiv.org/abs/2504.17367v1","title":"Increasing dynamic range of NESs by using geometric nonlinear damping","summary":"The paper deals with the passive control of resonant systems using nonlinear\nenergy sink (NES). The objective is to highlight the benefits of adding\nnonlinear geometrical damping in addition to the cubic stiffness nonlinearity.\nThe behaviour of the system is investigated theoretically by using the mixed\nharmonic balance multiple scales method. Based on the obtained slow flow\nequations, a design procedure that maximizes the dynamic range of the NES is\npresented. Singularity theory is used to express conditions for the birth of\ndetached resonance cure independently of the forcing frequency. It is shown\nthat the presence of a detached resonance curve is not necessarily detrimental\nto the performance of the NES. Moreover, the detached resonance curve can be\ncompletely suppressed by adding nonlinear damping. The results of the design\nprocedure are then compared to numerical simulations.","main_category":"physics.class-ph","categories":"physics.class-ph","published":"2025-04-24T08:28:36Z"}
{"aid":"http://arxiv.org/abs/2504.17380v1","title":"NMR chemical shielding for solid-state systems using spin-orbit coupled\n  ZORA GIPAW","summary":"We present an implementation of spin-orbit coupling (SOC) for the computation\nof nuclear magnetic resonance (NMR) chemical shielding tensors within linear\nresponse theory. Our implementation in the Vienna {\\it Ab initio} Simulation\nPackage (VASP) is tailored to solid-state systems by employing periodic\nboundary conditions and the gauge-including projector augmented waves (GIPAW)\napproach. Relativistic effects are included on the level of the zeroth-order\nregular approximation (ZORA). We discuss the challenges posed by the PAW\npartial wave basis in describing SOC regarding chemical shielding tensors. Our\nmethod is in good agreement with existing local-basis ZORA implementations for\na series of Sn, Hg, and Pb molecules and cluster approximations for crystalline\nsystems.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-24T08:55:30Z"}
{"aid":"http://arxiv.org/abs/2504.17423v1","title":"RIS-Assisted Noncoherent Wireless System: Error Analysis with Optimal\n  Receiver and Multi-level ASK","summary":"This paper considers a reconfigurable intelligent surface (RIS) aided\nwireless communication system where the transmitter employs one-sided\namplitude-shift keying (ASK) for data modulation and the receiver employs an\noptimal noncoherent maximum-likelihood rule for symbol detection. A novel\nstatistical analysis is presented to approximate the weighted sum of a central\nand a non-central chi-squared random variable, which is used to derive a novel\nclosed-form expression for the symbol error probability (SEP) of the\nnoncoherent system. Furthermore, an optimization problem to minimize the\nsystem's SEP under transmission energy constraint is proposed, and novel\nalgorithms are presented to obtain the optimal ASK constellation minimizing the\nSEP. Numerical results indicate that the noncoherent system achieves superior\nerror performance and higher diversity order with the optimal ASK constellation\ncompared to the traditional equispaced ASK constellation. Further, the optimal\nASK significantly differs from the traditional one, with the difference\nbecoming significant with an increase in the average signal-to-noise ratio and\nat a lower number of RIS's reflecting elements.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-24T10:25:19Z"}
{"aid":"http://arxiv.org/abs/2504.17438v1","title":"Storing and Querying Evolving Graphs in NoSQL Storage Models","summary":"This paper investigates advanced storage models for evolving graphs, focusing\non the efficient management of historical data and the optimization of global\nquery performance. Evolving graphs, which represent dynamic relationships\nbetween entities over time, present unique challenges in preserving their\ncomplete history while supporting complex analytical queries. We first do a\nfast review of the current state of the art focusing mainly on distributed\nhistorical graph databases to provide the context of our proposals. We\ninvestigate the im- plementation of an enhanced vertex-centric storage model in\nMongoDB that prioritizes space efficiency by leveraging in-database query\nmechanisms to minimize redundant data and reduce storage costs. To ensure broad\napplicability, we employ datasets, some of which are generated with the LDBC\nSNB generator, appropriately post-processed to utilize both snapshot- and\ninterval-based representations. Our experimental results both in centralized\nand distributed infrastructures, demonstrate significant improvements in query\nperformance, particularly for resource-intensive global queries that\ntraditionally suffer from inefficiencies in entity-centric frameworks. The\nproposed model achieves these gains by optimizing memory usage, reducing client\ninvolvement, and exploiting the computational capabilities of MongoDB. By\naddressing key bottlenecks in the storage and processing of evolving graphs,\nthis study demonstrates a step toward a robust and scalable framework for\nmanaging dynamic graph data. This work contributes to the growing field of\ntemporal graph analytics by enabling more efficient ex- ploration of historical\ndata and facilitating real-time insights into the evolution of complex\nnetworks.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-24T10:57:27Z"}
{"aid":"http://arxiv.org/abs/2504.17442v1","title":"Band-dominated and Fourier-band-dominated operators on locally compact\n  abelian groups","summary":"By relating notions from quantum harmonic analysis and band-dominated\noperator theory, we prove that over any locally compact abelian group $G$, the\noperator algebra $\\mathcal C_1$ from quantum harmonic analysis agrees with the\nintersection of band-dominated operators and Fourier band-dominated operators.\nAs an application, we characterize the compactness of operators acting on\n$L^2(G)$ and compare it with previous results in the discrete case. In\nparticular, our results can be seen as a generalization of the limit operator\nconcept to the non-discrete world. Moreover, we briefly discuss property $A'$\nfor arbitrary locally compact abelian groups.","main_category":"math.FA","categories":"math.FA,math.OA","published":"2025-04-24T11:03:33Z"}
{"aid":"http://arxiv.org/abs/2504.17456v1","title":"Thermodynamics and Holographic RG Flow in 3D C-metric","summary":"In this paper, we investigate the microscopic derivation of the entropy and\nthe holographic RG flow in 3D C-metric. We first discuss the case of a sector\nin BTZ (Banados-Teitelboim-Zanelli) black hole. By rescaling the Newton's\nconstant we recover the area law of entropy of this sector by microstate\ncounting. Then we apply this technique to all accelerating BTZ phases in 3D\nC-metric. Finally, for the boundary entropy in 3D C-metric, we study the\nmonotonicity of the $g$-function of 3D C-metric in small acceleration limit and\nfind that the $g$-theorem is satisfied only in $\\rm I_{2}$.","main_category":"hep-th","categories":"hep-th","published":"2025-04-24T11:37:06Z"}
{"aid":"http://arxiv.org/abs/2504.17460v1","title":"A Lightweight Method for Generating Multi-Tier JIT Compilation Virtual\n  Machine in a Meta-Tracing Compiler Framework","summary":"Meta-compiler frameworks, such as RPython and Graal/Truffle, generate\nhigh-performance virtual machines (VMs) from interpreter definitions. Although\nthey generate VMs with high-quality just-in-time (JIT) compilers, they still\nlack an important feature that dedicated VMs (i.e., VMs that are developed for\nspecific languages) have, namely \\emph{multi-tier compilation}. Multi-tier\ncompilation uses light-weight compilers at early stages and highly-optimizing\ncompilers at later stages in order to balance between compilation overheads and\ncode quality.\n  We propose a novel approach to enabling multi-tier compilation in the VMs\ngenerated by a meta-compiler framework. Instead of extending the JIT compiler\nbackend of the framework, our approach drives an existing (heavyweight)\ncompiler backend in the framework to quickly generate unoptimized native code\nby merely embedding directives and compile-time operations into interpreter\ndefinitions.\n  As a validation of the approach, we developed 2SOM, a Simple Object Machine\nwith a two-tier JIT compiler based on RPython. 2SOM first applies the tier-1\nthreaded code generator that is generated by our proposed technique, then, to\nthe loops that exceed a threshold, applies the tier-2 tracing JIT compiler that\nis generated by the original RPython framework. Our performance evaluation that\nruns a program with a realistic workload showed that 2SOM improved, when\ncompared against an RPython-based VM, warm-up performance by 15\\%, with merely\na 5\\% reduction in peak performance.","main_category":"cs.PL","categories":"cs.PL","published":"2025-04-24T11:51:28Z"}
{"aid":"http://arxiv.org/abs/2504.17462v1","title":"Measuring short-range correlations and quasi-elastic cross sections in\n  A(e,e') at x>1 and modest Q$^2$","summary":"We present results from the Jefferson Lab E08-014 experiment, investigating\nshort-range correlations (SRC) through measurements of absolute inclusive\nquasi-elastic cross sections and their ratios. This study utilized 3.356 GeV\nelectrons scattered off targets including $^2$H, $^3$He, $^4$He, $^{12}$C,\n$^{40}$Ca, and $^{48}$Ca, at modest momentum transfers ($1.3 < Q^2 \\leq 2$\nGeV$^2$). Kinematics were selected to enhance the cross-section contribution\nfrom high-momentum nucleons originating from the strongly interacting,\nshort-distance components of two-nucleon SRCs (2N-SRCs), known to exhibit a\nuniversal structure across both light and heavy nuclei.We analyzed the A/$^2$H\nratio within the region dominated by 2N-SRCs to characterize the nuclear\ndependence of SRC contributions across various nuclei. Additionally, the\nA/$^3$He ratio was examined at kinematics sensitive to nucleons with even\nhigher momentum, aiming to identify signals indicative of three-nucleon SRCs\n(3N-SRCs). The traditional analysis method in the expected 3N-SRC region ($x >\n2$) did not yield a clear plateau; instead, the data diverged from the\npredicted 3N-SRC behavior as momentum transfer increased. However, when\nanalyzed in terms of the struck nucleon's light-cone momentum, the data\nexhibited the opposite trend, progressively approaching the predicted 3N-SRC\nplateau. These observations suggest that future measurements at higher energies\nmay facilitate a definitive isolation and identification of 3N-SRCs.","main_category":"nucl-ex","categories":"nucl-ex,hep-ph","published":"2025-04-24T11:53:43Z"}
{"aid":"http://arxiv.org/abs/2504.17464v1","title":"Consistency between the Green-Kubo formula and Lorentz model for\n  predicting the infrared dielectric function of polar materials","summary":"Accurate prediction of infrared dielectric functions in polar materials is\nfundamental for thermal and photonic applications, yet it remains unexplored\nwhether the two main methods, Green-Kubo formula and Lorentz model, can give\nunified predictions. In this work, we present a detailed comparison of these\ntwo approaches using MgO and LiH as prototypical cases employing both empirical\nrigid ion model (RIM) and machine learning potential (MLP). We demonstrate that\nthe conventional Lorentz model fails to capture the multi-phonon absorption\ninherent in Green-Kubo method, which can be resolved via using the phonon\nself-energy as a generalization of the usual linewidth. In addition, with RIM,\na correction factor is required in the ionic contribution to infrared response\nto account for the electronic polarization effect, which is yet captured by MLP\nusing the Born effective charges for calculating dipole moment. The present\nbenchmark study thus enables cross-validation of dielectric function\ncalculations while providing mechanistic insights into the polarization\ndynamics.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-24T11:54:12Z"}
{"aid":"http://arxiv.org/abs/2504.17466v1","title":"From Single Particles to Clinical Beam Rates: A Wide Dynamic Range Beam\n  Monitor","summary":"Access to high-energy particle beams is key for testing high-energy physics\n(HEP) instruments. Accelerators for cancer treatment can serve as such a\ntesting ground. However, HEP instrument tests typically require particle fluxes\nsignificantly lower than for cancer treatment. Thus, facilities need\nadaptations to fulfill both the requirements for cancer treatment and the\nrequirements for HEP instrument testing. We report on the progress made in\ndeveloping a beam monitor with a sufficient dynamic range to allow for the\ndetection of single particles, while still being able to act as a monitor at\nthe clinical particle rates of the MedAustron treatment facility. The beam\nmonitor is designed for integration into existing accelerators.","main_category":"physics.acc-ph","categories":"physics.acc-ph,hep-ex","published":"2025-04-24T12:00:09Z"}
{"aid":"http://arxiv.org/abs/2504.17467v1","title":"Matching with regional constraints: An equivalence","summary":"In two-sided matching market, when the regional constraints are present, the\ndeferred acceptance (DA) algorithm suffers from undesirable inefficiency due to\nthe artificial allocation of the regional caps among hospitals. We show that,\ngiven preferences, there exist allocations that guarantee the efficiency of the\nDA algorithm. Furthermore, it is equivalent to the FDA algorithm developed by\nKamada and Kojima (2015), which endows the latter with an interpretation as a\ntool for endogenous capacity design. Our proof applies the optimality within\nthe matching with contracts (Hatfield and Milgrom 2005) framework, offering a\nbroadly applicable method for establishing equivalence among DA-based\nmechanisms.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-24T12:00:34Z"}
{"aid":"http://arxiv.org/abs/2504.17491v1","title":"On the robustness of the emergent spatiotemporal dynamics in\n  biophysically realistic and phenomenological whole-brain models at multiple\n  network resolutions","summary":"The human brain is a complex dynamical system which displays a wide range of\nmacroscopic and mesoscopic patterns of neural activity, whose mechanistic\norigin remains poorly understood. Whole-brain modelling allows us to explore\ncandidate mechanisms causing the observed patterns. However, it is not fully\nestablished how the choice of model type and the networks' resolution influence\nthe simulation results, hence, it remains unclear, to which extent conclusions\ndrawn from these results are limited by modelling artefacts. Here, we compare\nthe dynamics of a biophysically realistic, linear-nonlinear cascade model of\nwhole-brain activity with a phenomenological Wilson-Cowan model using three\nstructural connectomes based on the Schaefer parcellation scheme with 100, 200,\nand 500 nodes. Both neural mass models implement the same mechanistic\nhypotheses, which specifically address the interaction between excitation,\ninhibition, and a slow adaptation current, which affects the excitatory\npopulations. We quantify the emerging dynamical states in detail and\ninvestigate how consistent results are across the different model variants.\nThen we apply both model types to the specific phenomenon of slow oscillations,\nwhich are a prevalent brain rhythm during deep sleep. We investigate the\nconsistency of model predictions when exploring specific mechanistic hypotheses\nabout the effects of both short- and long-range connections and of the\nantero-posterior structural connectivity gradient on key properties of these\noscillations. Overall, our results demonstrate that the coarse-grained dynamics\nare robust to changes in both model type and network resolution. In some cases,\nhowever, model predictions do not generalize. Thus, some care must be taken\nwhen interpreting model results.","main_category":"q-bio.NC","categories":"q-bio.NC,nlin.AO","published":"2025-04-24T12:32:40Z"}
{"aid":"http://arxiv.org/abs/2504.17500v1","title":"New insights on supernova remnants and HII regions in M82","summary":"The nearby (d=3.6 Mpc) starburst galaxy M82 has been studied for several\ndecades by very long baseline interferometry (VLBI) networks such as e-MERLIN\nand the European VLBI Network (EVN). The numerous supernova remnants (SNRs),\nHII regions and other exotic transients make it a perfect laboratory for\nstudying stellar evolution and the interstellar medium (ISM). Its proximity\nprovides a linear resolution of 17 pc/arcsec, enabling decadal-time-scale\nvariability and morphology studies of the tens of compact radio sources. In\nthis proceedings, we describe new techniques developed in the last ten years\nthat provide deeper, more robust imaging, enable in-band spectral index\nmapping, and allow wider fields of view to be imaged to find new radio sources.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.GA","published":"2025-04-24T12:42:34Z"}
{"aid":"http://arxiv.org/abs/2504.17507v1","title":"Spectroscopic properties of $1F$-wave singly bottom baryons","summary":"This study investigates the mass spectra and decay behaviors of the\nexperimentally unobserved $1F$-wave singly bottom baryons. Calculating their\nmass spectra could provide crucial guidance for determining their spectroscopic\npositions. Additionally, by analyzing their decay properties, we could predict\nthe important decay channels, which are essential for experimental searches and\nquantum number assignments. Our calculations aim to support ongoing\nexperimental and theoretical efforts in singly bottom baryon spectroscopy.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-24T12:49:58Z"}
{"aid":"http://arxiv.org/abs/2504.17544v1","title":"Auditing the Ethical Logic of Generative AI Models","summary":"As generative AI models become increasingly integrated into high-stakes\ndomains, the need for robust methods to evaluate their ethical reasoning\nbecomes increasingly important. This paper introduces a five-dimensional audit\nmodel -- assessing Analytic Quality, Breadth of Ethical Considerations, Depth\nof Explanation, Consistency, and Decisiveness -- to evaluate the ethical logic\nof leading large language models (LLMs). Drawing on traditions from applied\nethics and higher-order thinking, we present a multi-battery prompt approach,\nincluding novel ethical dilemmas, to probe the models' reasoning across diverse\ncontexts. We benchmark seven major LLMs finding that while models generally\nconverge on ethical decisions, they vary in explanatory rigor and moral\nprioritization. Chain-of-Thought prompting and reasoning-optimized models\nsignificantly enhance performance on our audit metrics. This study introduces a\nscalable methodology for ethical benchmarking of AI systems and highlights the\npotential for AI to complement human moral reasoning in complex decision-making\ncontexts.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-24T13:32:30Z"}
{"aid":"http://arxiv.org/abs/2504.17564v1","title":"Doubling modulo odd integers, generalizations, and unexpected\n  occurrences","summary":"The starting point of this work is an equality between two quantities $A$ and\n$B$ found in the literature, which involve the {\\em\ndoubling-modulo-an-odd-integer} map, i.e., $x\\in {\\mathbb N} \\mapsto 2x\n\\bmod{(2n+1)}$ for some positive integer $n$. More precisely, this doubling map\ndefines a permutation $\\sigma_{2,n}$ and each of $A$ and $B$ counts the number\n$C_2(n)$ of cycles of $\\sigma_{2,n}$, hence $A=B$. In the first part of this\nnote, we give a direct proof of this last equality. To do so, we consider and\nstudy a generalized $(k,n)$-perfect shuffle permutation $\\sigma_{k,n}$, where\nwe multiply by an integer $k\\ge 2$ instead of $2$, and its number $C_k(n)$ of\ncycles. The second part of this note lists some of the many occurrences and\napplications of the doubling map and its generalizations in the literature: in\nmathematics (combinatorics of words, dynamical systems, number theory,\ncorrecting algorithms), but also in card-shuffling, juggling, bell-ringing,\npoetry, and music composition.","main_category":"math.NT","categories":"math.NT","published":"2025-04-24T13:57:24Z"}
{"aid":"http://arxiv.org/abs/2504.17573v1","title":"Semi-Blind Strategies for MMSE Channel Estimation Utilizing Generative\n  Priors","summary":"This paper investigates semi-blind channel estimation for massive\nmultiple-input multiple-output (MIMO) systems. To this end, we first estimate a\nsubspace based on all received symbols (pilot and payload) to provide\nadditional information for subsequent channel estimation. We show how this\nadditional information enhances minimum mean square error (MMSE) channel\nestimation. Two variants of the linear MMSE (LMMSE) estimator are formulated,\nwhere the first one solves the estimation within the subspace, and the second\none uses a subspace projection as a preprocessing step. Theoretical derivations\nshow the superior estimation performance of the latter method in terms of mean\nsquare error for uncorrelated Rayleigh fading. Subsequently, we introduce\nparameterizations of this semi-blind LMMSE estimator based on two different\nconditional Gaussian latent models, i.e., the Gaussian mixture model and the\nvariational autoencoder. Both models learn the underlying channel distribution\nof the propagation environment based on training data and serve as generative\npriors for semi-blind channel estimation. Extensive simulations for real-world\nmeasurement data and spatial channel models show the superior performance of\nthe proposed methods compared to state-of-the-art semi-blind channel estimators\nwith respect to the MSE.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-24T14:01:27Z"}
{"aid":"http://arxiv.org/abs/2504.17579v1","title":"THz Emission from Spintronic Microstructure","summary":"Recent advancements in spintronics have opened a new avenue in terahertz\n(THz) radiation sources that may outperform the traditional contact-based\nmetallic counterparts. Inspired by the generation of broadband spintronic THz\nsignals at the interface of a ferromagnet and ultrawide bandgap semiconductors,\nhere we investigated the generation of THz radiation from micro-structured\nheterostructures of a metallic ferromagnet (Ni80Fe20) and an ultrawide bandgap\nsemiconductor (AlGaN/GaN) that contains a layer of 2D electron gas. By\nprecisely tailoring the dimension of the subwavelength pillars of a THz device,\nthe micro-structured spintronic THz emitter can achieve up to more than three\ntimes higher emission intensity compared to that of the un-patterned\ncounterpart. Our study advances the development of the next generation of\nspintronic THz sources that allow a tailored emission frequency and intensity\ncontrol and, further, are compatible with existing integrated wide-bandgap\nsemiconductor circuits.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-24T14:09:43Z"}
{"aid":"http://arxiv.org/abs/2504.17582v1","title":"Occlusion-Aware Self-Supervised Monocular Depth Estimation for\n  Weak-Texture Endoscopic Images","summary":"We propose a self-supervised monocular depth estimation network tailored for\nendoscopic scenes, aiming to infer depth within the gastrointestinal tract from\nmonocular images. Existing methods, though accurate, typically assume\nconsistent illumination, which is often violated due to dynamic lighting and\nocclusions caused by GI motility. These variations lead to incorrect geometric\ninterpretations and unreliable self-supervised signals, degrading depth\nreconstruction quality. To address this, we introduce an occlusion-aware\nself-supervised framework. First, we incorporate an occlusion mask for data\naugmentation, generating pseudo-labels by simulating viewpoint-dependent\nocclusion scenarios. This enhances the model's ability to learn robust depth\nfeatures under partial visibility. Second, we leverage semantic segmentation\nguided by non-negative matrix factorization, clustering convolutional\nactivations to generate pseudo-labels in texture-deprived regions, thereby\nimproving segmentation accuracy and mitigating information loss from lighting\nchanges. Experimental results on the SCARED dataset show that our method\nachieves state-of-the-art performance in self-supervised depth estimation.\nAdditionally, evaluations on the Endo-SLAM and SERV-CT datasets demonstrate\nstrong generalization across diverse endoscopic environments.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T14:12:57Z"}
{"aid":"http://arxiv.org/abs/2504.17598v1","title":"TSUE: A Two-Stage Data Update Method for an Erasure Coded Cluster File\n  System","summary":"Compared to replication-based storage systems, erasure-coded storage incurs\nsignificantly higher overhead during data updates. To address this issue,\nvarious parity logging methods have been pro- posed. Nevertheless, due to the\nlong update path and substantial amount of random I/O involved in erasure code\nupdate processes, the resulting long latency and low throughput often fail to\nmeet the requirements of high performance applications. To this end, we propose\na two-stage data update method called TSUE. TSUE divides the update process\ninto a synchronous stage that records updates in a data log, and an\nasynchronous stage that recycles the log in real-time. TSUE effectively reduces\nupdate latency by transforming random I/O into sequential I/O, and it\nsignificantly reduces recycle overhead by utilizing a three-layer log and the\nspatio-temporal locality of access patterns. In SSDs cluster, TSUE\nsignificantly im- proves update performance, achieving improvements of 7.6X\nunder Ali-Cloud trace, 5X under Ten-Cloud trace, while it also extends the\nSSD's lifespan by up to 13X through reducing the frequencies of reads/writes\nand of erase operations.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-24T14:24:16Z"}
{"aid":"http://arxiv.org/abs/2504.17606v1","title":"From surface roughness to crater formation in a 2D multi-scale\n  simulation of ultrashort pulse laser ablation","summary":"Surface roughness plays a critical role in ultrashort pulse laser ablation,\nparticularly for industrial applications using burst mode operations,\nmulti-pulse laser processing, and the generation of laser-induced periodic\nsurface structures. Hence, we address the impact of surface roughness on the\nresulting laser ablation topography predicted by a simulation model and\ncompared to experimental results. We present a comprehensive multi-scale\nsimulation framework that first employs finite-difference-time-domain\nsimulations for calculating the surface fluence distribution on a rough surface\nmeasured by an atomic-force-microscope followed by the two-temperature model\ncoupled with hydrodynamic/solid mechanics simulation for the initial material\nheating. Lastly, a computational fluid dynamics model for material relaxation\nand fluid flow is developed and employed. Final state results of aluminum and\nAISI 304 stainless steel simulations demonstrated alignment with established\nablation models and crater dimension prediction. Notably, Al exhibited\nsignificant optical scattering effects due to initial surface roughness of 15\nnm - being 70 times below the laser wavelength, leading to localized, selective\nablation processes and substantially altered crater topography compared to\nidealized conditions. Contrary, AISI 304 with RMS roughness of 2 nm showed no\ndifference. Hence, we highlight the necessity of incorporating realistic,\nmaterial-specific surface roughness values into large-scale ablation\nsimulations. Furthermore, the induced local fluence variations demonstrated the\ninadequacy of neglecting lateral heat transport effects in this context.","main_category":"hep-ex","categories":"hep-ex,cond-mat.mtrl-sci","published":"2025-04-24T14:29:33Z"}
{"aid":"http://arxiv.org/abs/2504.17619v1","title":"Enhancing CNNs robustness to occlusions with bioinspired filters for\n  border completion","summary":"We exploit the mathematical modeling of the visual cortex mechanism for\nborder completion to define custom filters for CNNs. We see a consistent\nimprovement in performance, particularly in accuracy, when our modified LeNet 5\nis tested with occluded MNIST images.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-24T14:43:55Z"}
{"aid":"http://arxiv.org/abs/2504.17629v1","title":"Integrated Sensing and Communications for Unsourced Random Access: A\n  Spectrum Sharing Compressive Sensing Approach","summary":"This paper addresses the unsourced/uncoordinated random access problem in an\nintegrated sensing and communications (ISAC) system, with a focus on uplink\nmultiple access code design. Recent theoretical advancements highlight that an\nISAC system will be overwhelmed by the increasing number of active devices,\ndriven by the growth of massive machine-type communication (mMTC). To meet the\ndemands of future mMTC network, fundamental solutions are required that ensure\nrobust capacity while maintaining favorable energy and spectral efficiency. One\npromising approach to support emerging massive connectivity is the development\nof systems based on the unsourced ISAC (UNISAC) framework. This paper proposes\na spectrum-sharing compressive sensing-based UNISAC (SSCS-UNISAC) and offers\ninsights into the practical design of UNISAC multiple access codes. In this\nframework, both communication signals (data transmission) and sensing signals\n(e.g., radar echoes) overlap within finite channel uses and are transmitted via\nthe proposed UNISAC protocol. The proposed decoder exhibits robust performance,\nproviding 20-30 dB capacity gains compared to conventional protocols such as\nTDMA and ALOHA. Numerical results validate the promising performance of the\nproposed scheme.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-24T14:53:28Z"}
{"aid":"http://arxiv.org/abs/2504.17632v1","title":"Are EVs Cleaner Than We Think? Evaluating Consequential Greenhouse Gas\n  Emissions from EV Charging","summary":"While electrifying transportation eliminates tailpipe greenhouse gas (GHG)\nemissions, electric vehicle (EV) adoption can create additional electricity\nsector emissions. To quantify this emissions impact, prior work typically\nemploys short-run marginal emissions or average emissions rates calculated from\nhistorical data or power systems models that do not consider changes in\ninstalled capacity. In this work, we use an electricity system capacity\nexpansion model to consider the full consequential GHG emissions impact from\nlarge-scale EV adoption in the western United States, accounting for induced\nchanges in generation and storage capacity. We find that the metrics described\nabove do not accurately reflect the true emissions impact of EV\nadoption-average emissions rates can either under- or over-estimate emission\nimpacts, and short-run marginal emissions rates can significantly underestimate\nemission reductions, especially when charging timing is flexible. Our results\nalso show that using short-run marginal emission rates as signals to coordinate\nEV charging could increase emissions relative to price-based charging signals,\nindicating the need for alternative control strategies to minimize\nconsequential emissions.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-24T15:05:44Z"}
{"aid":"http://arxiv.org/abs/2504.17636v1","title":"A Guide to Structureless Visual Localization","summary":"Visual localization algorithms, i.e., methods that estimate the camera pose\nof a query image in a known scene, are core components of many applications,\nincluding self-driving cars and augmented / mixed reality systems.\nState-of-the-art visual localization algorithms are structure-based, i.e., they\nstore a 3D model of the scene and use 2D-3D correspondences between the query\nimage and 3D points in the model for camera pose estimation. While such\napproaches are highly accurate, they are also rather inflexible when it comes\nto adjusting the underlying 3D model after changes in the scene. Structureless\nlocalization approaches represent the scene as a database of images with known\nposes and thus offer a much more flexible representation that can be easily\nupdated by adding or removing images. Although there is a large amount of\nliterature on structure-based approaches, there is significantly less work on\nstructureless methods. Hence, this paper is dedicated to providing the, to the\nbest of our knowledge, first comprehensive discussion and comparison of\nstructureless methods. Extensive experiments show that approaches that use a\nhigher degree of classical geometric reasoning generally achieve higher pose\naccuracy. In particular, approaches based on classical absolute or\nsemi-generalized relative pose estimation outperform very recent methods based\non pose regression by a wide margin. Compared with state-of-the-art\nstructure-based approaches, the flexibility of structureless methods comes at\nthe cost of (slightly) lower pose accuracy, indicating an interesting direction\nfor future work.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T15:08:36Z"}
{"aid":"http://arxiv.org/abs/2504.17641v1","title":"PTCL: Pseudo-Label Temporal Curriculum Learning for Label-Limited\n  Dynamic Graph","summary":"Dynamic node classification is critical for modeling evolving systems like\nfinancial transactions and academic collaborations. In such systems,\ndynamically capturing node information changes is critical for dynamic node\nclassification, which usually requires all labels at every timestamp. However,\nit is difficult to collect all dynamic labels in real-world scenarios due to\nhigh annotation costs and label uncertainty (e.g., ambiguous or delayed labels\nin fraud detection). In contrast, final timestamp labels are easier to obtain\nas they rely on complete temporal patterns and are usually maintained as a\nunique label for each user in many open platforms, without tracking the history\ndata. To bridge this gap, we propose PTCL(Pseudo-label Temporal Curriculum\nLearning), a pioneering method addressing label-limited dynamic node\nclassification where only final labels are available. PTCL introduces: (1) a\ntemporal decoupling architecture separating the backbone (learning time-aware\nrepresentations) and decoder (strictly aligned with final labels), which\ngenerate pseudo-labels, and (2) a Temporal Curriculum Learning strategy that\nprioritizes pseudo-labels closer to the final timestamp by assigning them\nhigher weights using an exponentially decaying function. We contribute a new\nacademic dataset (CoOAG), capturing long-range research interest in dynamic\ngraph. Experiments across real-world scenarios demonstrate PTCL's consistent\nsuperiority over other methods adapted to this task. Beyond methodology, we\npropose a unified framework FLiD (Framework for Label-Limited Dynamic Node\nClassification), consisting of a complete preparation workflow, training\npipeline, and evaluation standards, and supporting various models and datasets.\nThe code can be found at https://github.com/3205914485/FLiD.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-24T15:11:41Z"}
{"aid":"http://arxiv.org/abs/2504.17657v1","title":"Fast and accurate modelling of Kerr-Brillouin combs in Fabry-Perot\n  resonators","summary":"We introduce a new mean-field equation for modeling Fabry-Perot resonators\nfilled with a dispersive medium exhibiting both Brillouin and Kerr\nnonlinearities, e.g. an optical fiber. This model is derived from a unified\nframework that accounts for Brillouin scattering and four-wave mixing. It\ninvolves two coupled nonlinear Schrodinger equations for the forward and\nbackward propagating fields, alongside a single equation governing the acoustic\noscillation. Under standard assumptions for mean-field models -such as high\nfinesse, weak nonlinearity, and weak dispersion- we demonstrate that our\nequation closely matches the original system. The simplified and elegant\nmathematical structure of our model provides valuable physical insights. As a\nkey example, we derive an expression for the growth rate of harmonic\nperturbations of steady states. Additionally, our model facilitates fast and\naccurate numerical simulations using standard Fourier split-step methods. We\nhighlight the effectiveness of this approach by simulating frequency comb\ngeneration in state-of-the-art high-Q fiber Fabry-Perot resonators.","main_category":"physics.optics","categories":"physics.optics,nlin.PS","published":"2025-04-24T15:26:28Z"}
{"aid":"http://arxiv.org/abs/2504.17666v1","title":"A Systematic Study on the Design of Odd-Sized Highly Nonlinear Boolean\n  Functions via Evolutionary Algorithms","summary":"This paper focuses on the problem of evolving Boolean functions of odd sizes\nwith high nonlinearity, a property of cryptographic relevance. Despite its\nsimple formulation, this problem turns out to be remarkably difficult. We\nperform a systematic evaluation by considering three solution encodings and\nfour problem instances, analyzing how well different types of evolutionary\nalgorithms behave in finding a maximally nonlinear Boolean function. Our\nresults show that genetic programming generally outperforms other evolutionary\nalgorithms, although it falls short of the best-known results achieved by\nad-hoc heuristics. Interestingly, by adding local search and restricting the\nspace to rotation symmetric Boolean functions, we show that a genetic algorithm\nwith the bitstring encoding manages to evolve a $9$-variable Boolean function\nwith nonlinearity 241.","main_category":"cs.NE","categories":"cs.NE,cs.CR","published":"2025-04-24T15:35:53Z"}
{"aid":"http://arxiv.org/abs/2504.17677v1","title":"INSIGHT: Bridging the Student-Teacher Gap in Times of Large Language\n  Models","summary":"The rise of AI, especially Large Language Models, presents challenges and\nopportunities to integrate such technology into the classroom. AI has the\npotential to revolutionize education by helping teaching staff with various\ntasks, such as personalizing their teaching methods, but it also raises\nconcerns, for example, about the degradation of student-teacher interactions\nand user privacy. This paper introduces INSIGHT, a proof of concept to combine\nvarious AI tools to assist teaching staff and students in the process of\nsolving exercises. INSIGHT has a modular design that allows it to be integrated\ninto various higher education courses. We analyze students' questions to an LLM\nby extracting keywords, which we use to dynamically build an FAQ from students'\nquestions and provide new insights for the teaching staff to use for more\npersonalized face-to-face support. Future work could build upon INSIGHT by\nusing the collected data to provide adaptive learning and adjust content based\non student progress and learning styles to offer a more interactive and\ninclusive learning experience.","main_category":"cs.HC","categories":"cs.HC,cs.AI","published":"2025-04-24T15:47:20Z"}
{"aid":"http://arxiv.org/abs/2504.17696v1","title":"Hierarchical and Multimodal Data for Daily Activity Understanding","summary":"Daily Activity Recordings for Artificial Intelligence (DARai, pronounced\n\"Dahr-ree\") is a multimodal, hierarchically annotated dataset constructed to\nunderstand human activities in real-world settings. DARai consists of\ncontinuous scripted and unscripted recordings of 50 participants in 10\ndifferent environments, totaling over 200 hours of data from 20 sensors\nincluding multiple camera views, depth and radar sensors, wearable inertial\nmeasurement units (IMUs), electromyography (EMG), insole pressure sensors,\nbiomonitor sensors, and gaze tracker.\n  To capture the complexity in human activities, DARai is annotated at three\nlevels of hierarchy: (i) high-level activities (L1) that are independent tasks,\n(ii) lower-level actions (L2) that are patterns shared between activities, and\n(iii) fine-grained procedures (L3) that detail the exact execution steps for\nactions. The dataset annotations and recordings are designed so that 22.7% of\nL2 actions are shared between L1 activities and 14.2% of L3 procedures are\nshared between L2 actions. The overlap and unscripted nature of DARai allows\ncounterfactual activities in the dataset.\n  Experiments with various machine learning models showcase the value of DARai\nin uncovering important challenges in human-centered applications.\nSpecifically, we conduct unimodal and multimodal sensor fusion experiments for\nrecognition, temporal localization, and future action anticipation across all\nhierarchical annotation levels. To highlight the limitations of individual\nsensors, we also conduct domain-variant experiments that are enabled by DARai's\nmulti-sensor and counterfactual activity design setup.\n  The code, documentation, and dataset are available at the dedicated DARai\nwebsite:\nhttps://alregib.ece.gatech.edu/software-and-datasets/darai-daily-activity-recordings-for-artificial-intelligence-and-machine-learning/","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-24T16:04:00Z"}
{"aid":"http://arxiv.org/abs/2504.17707v1","title":"CoMBolt-ITA, a Collective Model via relativistic Boltzmann equation in\n  Isotropization Time Approximation","summary":"A new (2+1)-model is developed to investigate the collective behavior of the\nquark-gluon plasma produced in high-energy heavy-ion collisions. This framework\ncouples pre-equilibrium dynamics with hydrodynamic evolution by solving the\nBoltzmann equation within the isotropization time approximation. A numerical\nscheme based on the method of characteristics enables the evolution to begin\nfrom a specified initial Boltzmann distribution. In this work, the spatial\nstructure of the initial distribution is modeled using the TrENTo framework.\nOur results show that a medium initialized at $\\tau_0 $ in the order of\n1\\,[fm/$c$] with a small shear viscosity to entropy density ratio ($\\eta/s =\n0.008$) evolves consistently with hydrodynamic simulations, such as those\nperformed using the VISH2+1 code, while discrepancies arise for a medium with\n$\\eta/s = 0.8$. Furthermore, when initialized with a highly anisotropic\nmomentum distribution in the longitudinal direction at early times, the system\nexhibits spatially non-uniform thermalization in the transverse plane, leading\nto the emergence of a nontrivial hypersurface that marks the onset of\nhydrodynamic applicability.","main_category":"hep-ph","categories":"hep-ph,hep-th,nucl-th","published":"2025-04-24T16:12:45Z"}
{"aid":"http://arxiv.org/abs/2504.17714v1","title":"Hierarchical Balance Theory: Emergence of Instability in Follower Layer\n  Below Critical Temperatures","summary":"Hierarchy significantly shapes interactions in social structures by\norganizing individuals or groups based on status, power, or privilege. This\nstudy investigates how hierarchy affects structural balance as temperature\nvariations, which measure an individual's average irrationality in society. To\naddress this question, we develop a two-layer balance model, the\n\\enquote{leader layer}, which maintains structural balance exclusively through\nintra-layer interactions. Conversely, the \\enquote{follower layer} maintains\nstructural equilibrium through both inter- and intra-layer interactions. The\nHamiltonian of the leading layer is independent, while the follower layer\ndepends on its parameters as well as those of the leading layer. Analytical\nresults from the mean-field approximation and exact Monte Carlo simulations\nshow that instability arises in the equilibrium states of the follower layer\nwhen the temperature is below the critical threshold ($T<T_c$), which is\ndifferent from the structural Heider equilibrium. Furthermore, our findings\nindicate that the critical temperature is elevated in the follower layer.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-24T16:16:58Z"}
{"aid":"http://arxiv.org/abs/2504.17724v1","title":"Unsupervised EEG-based decoding of absolute auditory attention with\n  canonical correlation analysis","summary":"We propose a fully unsupervised algorithm that detects from encephalography\n(EEG) recordings when a subject actively listens to sound, versus when the\nsound is ignored. This problem is known as absolute auditory attention decoding\n(aAAD). We propose an unsupervised discriminative CCA model for feature\nextraction and combine it with an unsupervised classifier called minimally\ninformed linear discriminant analysis (MILDA) for aAAD classification.\nRemarkably, the proposed unsupervised algorithm performs significantly better\nthan a state-of-the-art supervised model. A key reason is that the unsupervised\nalgorithm can successfully adapt to the non-stationary test data at a low\ncomputational cost. This opens the door to the analysis of the auditory\nattention of a subject using EEG signals with a model that automatically tunes\nitself to the subject without requiring an arduous supervised training session\nbeforehand.","main_category":"eess.SP","categories":"eess.SP,cs.SD","published":"2025-04-24T16:36:56Z"}
{"aid":"http://arxiv.org/abs/2504.17726v1","title":"Optical to infrared mapping of vapor-to-liquid phase change dynamics\n  using generative machine learning","summary":"Infrared thermography is a powerful tool for studying liquid-to-vapor phase\nchange processes. However, its application has been limited in the study of\nvapor-to-liquid phase transitions due to the presence of complex liquid\ndynamics, multiple phases within the same field of view, and experimental\ndifficulty. Here, we develop a calibration framework which is capable to\nstudying one of the most complex two-phase heat transfer processes: dropwise\ncondensation. The framework accounts for non-uniformities arising from dynamic\ntwo-phase interactions such as droplet nucleation, growth, coalescence, and\ndeparture, as well as substrate effects particularly observed on micro- and\nnanoengineered surfaces. This approach enables high-resolution temperature\nmeasurements with both spatial (12 $\\mu$m) and temporal (5 ms) precision,\nleading to the discovery of local temperature phenomena unobservable using\nconventional approaches. These observed temperature variations are linked to\ndroplet statistics, showing how different regions contribute to local\ncondensation heat transfer. We extend the developed method to quantify local\nthermal parameters by fusing it with a generative machine learning model to map\nvisual images into temperature fields. The model is informed of the physical\nparameter by incorporating vapor pressure embedding as the conditional\nparameter. This work represents a significant step toward simplifying local\ntemperature measurements for vapor-to-liquid phase change phenomena by\ndeveloping a methodology as well as a machine learning approach to map local\nthermal phenomena using only optical images as the input.","main_category":"physics.comp-ph","categories":"physics.comp-ph,physics.app-ph,physics.flu-dyn","published":"2025-04-24T16:39:20Z"}
{"aid":"http://arxiv.org/abs/2504.17727v1","title":"Widom factors in $\\mathbb C^n$","summary":"We generalize the theory of Widom factors to the $\\mathbb C^n$ setting. We\ndefine Widom factors of compact subsets $K\\subset \\mathbb C^n$ associated with\nmultivariate orthogonal polynomials and weighted Chebyshev polynomials. We show\nthat on product subsets $K=K_1\\times\\cdots\\times K_n$ of $\\mathbb C^n$, where\neach $K_j$ is a non-polar compact subset of $\\mathbb C$, these quantities have\nuniversal lower bounds which directly extend one dimensional results. Under the\nadditional assumption that each $K_j$ is a subset of the real line, we provide\nimproved lower bounds for Widom factors for some weight functions $w$; in\nparticular, for the case $w\\equiv 1$. Finally, we define the Mahler measure of\na multivariate polynomial relative to $K\\subset \\mathbb C^n$ and obtain lower\nbounds for this quantity on product sets.","main_category":"math.CV","categories":"math.CV,math.CA","published":"2025-04-24T16:42:20Z"}
{"aid":"http://arxiv.org/abs/2504.17735v1","title":"EgoCHARM: Resource-Efficient Hierarchical Activity Recognition using an\n  Egocentric IMU Sensor","summary":"Human activity recognition (HAR) on smartglasses has various use cases,\nincluding health/fitness tracking and input for context-aware AI assistants.\nHowever, current approaches for egocentric activity recognition suffer from low\nperformance or are resource-intensive. In this work, we introduce a resource\n(memory, compute, power, sample) efficient machine learning algorithm,\nEgoCHARM, for recognizing both high level and low level activities using a\nsingle egocentric (head-mounted) Inertial Measurement Unit (IMU). Our\nhierarchical algorithm employs a semi-supervised learning strategy, requiring\nprimarily high level activity labels for training, to learn generalizable low\nlevel motion embeddings that can be effectively utilized for low level activity\nrecognition. We evaluate our method on 9 high level and 3 low level activities\nachieving 0.826 and 0.855 F1 scores on high level and low level activity\nrecognition respectively, with just 63k high level and 22k low level model\nparameters, allowing the low level encoder to be deployed directly on current\nIMU chips with compute. Lastly, we present results and insights from a\nsensitivity analysis and highlight the opportunities and limitations of\nactivity recognition using egocentric IMUs.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-24T16:48:45Z"}
{"aid":"http://arxiv.org/abs/2504.17737v1","title":"Modularity of tadpole Nahm sums in ranks 4 and 5","summary":"Around 2016, Calinescu, Milas and Penn conjectured that the rank $r$ Nahm sum\nassociated with the $r\\times r$ tadpole Cartan matrix is modular, and they\nprovided a proof for $r=2$. The $r=3$ case was recently resolved by Milas and\nWang. We prove this conjecture for the next cases $r=4,5$. We also prove the\nmodularity of some companion Nahm sums by establishing the corresponding\nRogers--Ramanujan type identities. A key new ingredient in our proofs is some\nrank reduction formulas which allow us to decompose higher rank tadpole Nahm\nsums to mixed products of some lower rank Nahm-type sums and theta functions.","main_category":"math.NT","categories":"math.NT,math.CO","published":"2025-04-24T16:49:38Z"}
{"aid":"http://arxiv.org/abs/2504.17769v1","title":"Bringing light into the Landau-Lifshitz-Gilbert equation: Consequences\n  of its fractal non-Markovian memory kernel for optically induced magnetic\n  inertia and magnons","summary":"The Landau-Lisfhitz-Gilbert (LLG) equation has been the cornerstone of\nmodeling the dynamics of localized spins, viewed as classical vectors of fixed\nlength, within nonequilibrium magnets. When light is employed as the\nnonequilibrium drive, the LLG equation must be supplemented with additional\nterms that are usually conjectured using phenomenological arguments for direct\nopto-magnetic coupling between localized spins and (real or effective) magnetic\nfield of light. However, direct coupling of magnetic field to spins is 1/c\nsmaller than coupling of light and electrons; or both magnetic and electric\nfields are too fast for slow classical spins to be able to follow them. Here,\nwe displace the need for phenomenological arguments by rigorously deriving an\nextended LLG equation via Schwinger-Keldysh field theory (SKFT). Within such a\ntheory, light interacts with itinerant electrons, and then spin current carried\nby them exerts spin-transfer torque onto localized spins, so that when\nphotoexcited electrons are integrated out we arrive at a spin-only equation.\nUnlike the standard phenomenological LLG equation with local-in-time Gilbert\ndamping, our extended one contains a non-Markovian memory kernel whose plot\nwithin the plane of its two times variables exhibits fractal properties. By\napplying SKFT-derived extended LLG equation, as our central result, to a\nlight-driven ferromagnet as an example, we predict an optically induced\nmagnetic inertia term. Its magnitude is governed by spatially nonlocal and\ntime-dependent prefactor, leading to excitation of coherent magnons at sharp\nfrequencies in and outside of the band of incoherent (or thermal) magnons.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-24T17:41:17Z"}
{"aid":"http://arxiv.org/abs/2504.17775v1","title":"Long-term stable nonlinear evolutions of ultracompact black-hole\n  mimickers","summary":"We study the stability of ultracompact boson stars admitting light rings\ncombining a perturbative analysis with 3+1 numerical-relativity simulations\nwith and without symmetry assumptions. We observe excellent agreement between\nall perturbative and numerical results which uniformly support the hypothesis\nthat this family of black-hole mimickers is separated into stable and unstable\nbranches by extremal-mass configurations. This separation includes, in\nparticular, thin-shell boson stars with light rings located on the stable\nbranch which we conclude to represent long-term stable black-hole mimickers.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-24T17:48:48Z"}
{"aid":"http://arxiv.org/abs/2504.17786v1","title":"Emergent fractals in dirty topological crystals","summary":"Non-trivial geometry of electronic Bloch states gives birth to topological\ninsulators that are robust against sufficiently weak randomness, inevitably\npresent in any quantum material. However, increasing disorder triggers a\nquantum phase transition into a featureless normal insulator. As the underlying\nquantum critical point is approached from the topological side, small scattered\ndroplets of normal insulators start to develop in the system and their coherent\nnucleation causes ultimate condensation of a trivial insulation. Unless\ndisorder is too strong, the normal insulator accommodates disjoint tiny\ntopological puddles. Furthermore, in the close vicinity of such a transition\nthe emergent islands of topological and trivial insulators display spatial\nfractal structures, a feature that is revealed only by local topological\nmarkers. Here we showcase this (possibly) generic phenomenon that should be\napposite to dirty topological crystals of any symmetry class in any dimension\nfrom the Bott index and local Chern marker for a square lattice-based\ndisordered Chern insulator model.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.mes-hall,cond-mat.mtrl-sci,cond-mat.stat-mech","published":"2025-04-24T17:59:35Z"}
{"aid":"http://arxiv.org/abs/2504.17790v1","title":"Quantum Error Correction with Girth-16 Non-Binary LDPC Codes via Affine\n  Permutation Construction","summary":"We propose a method for constructing quantum error-correcting codes based on\nnon-binary low-density parity-check codes with girth 16. In conventional\nconstructions using circulant permutation matrices, the girth is upper-bounded\nby 12, which limits the suppression of harmful short cycles. Our construction\nemploys affine permutation matrices and a randomized sequential selection\nprocedure designed to eliminate short cycles, which are known to limit decoding\nperformance.\n  Joint belief propagation decoding is applied over depolarizing channels.\nNumerical experiments confirm that the proposed codes reduce the number of\nlow-weight codewords in $C_X \\setminus C_Z^\\perp$ and $C_Z \\setminus\nC_X^\\perp$, and thus have the potential to suppress error floors. In addition,\nwe obtain a significantly improved upper bound on the minimum distance, which\nwe conjecture to be tight.","main_category":"quant-ph","categories":"quant-ph,cs.IT,math.IT","published":"2025-04-24T17:59:58Z"}
