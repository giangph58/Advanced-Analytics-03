{"aid":"http://arxiv.org/abs/2503.21681v1","title":"A Comprehensive Benchmark for RNA 3D Structure-Function Modeling","summary":"The RNA structure-function relationship has recently garnered significant\nattention within the deep learning community, promising to grow in importance\nas nucleic acid structure models advance. However, the absence of standardized\nand accessible benchmarks for deep learning on RNA 3D structures has impeded\nthe development of models for RNA functional characteristics.\n  In this work, we introduce a set of seven benchmarking datasets for RNA\nstructure-function prediction, designed to address this gap. Our library builds\non the established Python library rnaglib, and offers easy data distribution\nand encoding, splitters and evaluation methods, providing a convenient\nall-in-one framework for comparing models. Datasets are implemented in a fully\nmodular and reproducible manner, facilitating for community contributions and\ncustomization. Finally, we provide initial baseline results for all tasks using\na graph neural network.\n  Source code: https://github.com/cgoliver/rnaglib\n  Documentation: https://rnaglib.org","main_category":"q-bio.BM","categories":"q-bio.BM,cs.LG,stat.ML","published":"2025-03-27T16:49:31Z"}
{"aid":"http://arxiv.org/abs/2503.21683v1","title":"LLM-Gomoku: A Large Language Model-Based System for Strategic Gomoku\n  with Self-Play and Reinforcement Learning","summary":"In recent years, large language models (LLMs) have shown significant\nadvancements in natural language processing (NLP), with strong capa-bilities in\ngeneration, comprehension, and rea-soning. These models have found applications\nin education, intelligent decision-making, and gaming. However, effectively\nutilizing LLMs for strategic planning and decision-making in the game of Gomoku\nremains a challenge. This study aims to develop a Gomoku AI system based on\nLLMs, simulating the human learning process of playing chess. The system is\nde-signed to understand and apply Gomoku strat-egies and logic to make rational\ndecisions. The research methods include enabling the model to \"read the board,\"\n\"understand the rules,\" \"select strategies,\" and \"evaluate positions,\" while\nen-hancing its abilities through self-play and rein-forcement learning. The\nresults demonstrate that this approach significantly improves the se-lection of\nmove positions, resolves the issue of generating illegal positions, and reduces\npro-cess time through parallel position evaluation. After extensive self-play\ntraining, the model's Gomoku-playing capabilities have been notably enhanced.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-03-27T16:52:25Z"}
{"aid":"http://arxiv.org/abs/2503.21691v1","title":"Place Capability Graphs: A General-Purpose Model of Rust's Ownership and\n  Borrowing Guarantees","summary":"Rust's novel type system has proved an attractive target for verification and\nprogram analysis tools, due to the rich guarantees it provides for controlling\naliasing and mutability. However, fully understanding, extracting and\nexploiting these guarantees is subtle and challenging: existing models for\nRust's type checking either support a smaller idealised language disconnected\nfrom real-world Rust code, or come with severe limitations in terms of precise\nmodelling of Rust borrows, composite types storing them, function signatures\nand loops.\n  In this paper, we present a novel model of Rust's type-checking called Place\nCapability Graphs, which lifts these limitations, and which can be directly\ncalculated from the Rust compiler's own programmatic representations and\nanalyses. We demonstrate that our model supports over 98% of Rust functions in\nthe most popular public crates, and show its suitability as a general-purpose\nbasis for verification and program analysis tools by developing promising new\nprototype versions of the existing Flowistry and Prusti tools.","main_category":"cs.PL","categories":"cs.PL","published":"2025-03-27T16:55:41Z"}
{"aid":"http://arxiv.org/abs/2503.21692v1","title":"RapidPoseTriangulation: Multi-view Multi-person Whole-body Human Pose\n  Triangulation in a Millisecond","summary":"The integration of multi-view imaging and pose estimation represents a\nsignificant advance in computer vision applications, offering new possibilities\nfor understanding human movement and interactions. This work presents a new\nalgorithm that improves multi-view multi-person pose estimation, focusing on\nfast triangulation speeds and good generalization capabilities. The approach\nextends to whole-body pose estimation, capturing details from facial\nexpressions to finger movements across multiple individuals and viewpoints.\nAdaptability to different settings is demonstrated through strong performance\nacross unseen datasets and configurations. To support further progress in this\nfield, all of this work is publicly accessible.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T16:57:33Z"}
{"aid":"http://arxiv.org/abs/2503.21698v1","title":"Anisotropic light-tailored RKKY interaction in two-dimensional $d$-wave\n  altermagnets","summary":"Altermagnets are known in spintronics for their intrinsic spin-splitting and\nunconventional magnetic responses, particularly to magnetic impurities.\nHowever, effectively controlling the magnetic exchange interactions in\naltermagnets is challenging for practical applications. Here, we propose using\ncircularly polarized light to tune the Ruderman-Kittel-Kasuya-Yosida (RKKY)\ninteraction in two-dimensional $d$-wave altermagnets. Using the real-space\nretarded Green's functions approach, our results show that while the Heisenberg\nand Ising exchanges dominate, a notable Dzyaloshinskii-Moriya (DM) interaction\nalso plays a key role. Furthermore, the inherent strength of altermagnetism\nimprints chirp-like signatures into the magnetic responses, which can be\ndynamically tuned via light. We mainly demonstrate that gate-induced Rashba\nspin-orbit coupling is essential in response to light -- light selectively and\nanisotropically adjusts the DM interaction without affecting the other\nexchanges. Our findings further indicate that rotating the altermagnet by\n$45^\\circ$ relative to the light's polarization direction generates a\nDirac-like dispersion and different DM interactions. We finally extract\ncritical thresholds where light reverses DM interactions along one axis or\nbalances both in-plane components. The anisotropic light-driven control of RKKY\ninteractions in 2D altermagnets not only highlights their unique properties but\nalso opens new avenues for engineering tailored magnetic characteristics in\nspintronic applications.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-03-27T17:03:27Z"}
{"aid":"http://arxiv.org/abs/2503.21703v1","title":"Trivial source characters in blocks of domestic representation type","summary":"Let $G$ be a finite group of even order, let $k$ be an algebraically closed\nfield of characteristic $2$, and let $B$ be a block of the group algebra $kG$\nwhich is of domestic representation type. Up to splendid Morita equivalence,\nprecisely three cases can occur: $kV_4$, $k\\mathfrak{A}_4$ and the principal\nblock of $k\\mathfrak{A}_5$. In each case, given the character values of the\nordinary irreducible characters of $B$, we determine the ordinary characters of\nall trivial source $B$-modules.","main_category":"math.RT","categories":"math.RT","published":"2025-03-27T17:09:40Z"}
{"aid":"http://arxiv.org/abs/2503.21710v1","title":"Enhancing Repository-Level Software Repair via Repository-Aware\n  Knowledge Graphs","summary":"Repository-level software repair faces challenges in bridging semantic gaps\nbetween issue descriptions and code patches. Existing approaches, which mostly\ndepend on large language models (LLMs), suffer from semantic ambiguities,\nlimited structural context understanding, and insufficient reasoning\ncapability. To address these limitations, we propose KGCompass with two\ninnovations: (1) a novel repository-aware knowledge graph (KG) that accurately\nlinks repository artifacts (issues and pull requests) and codebase entities\n(files, classes, and functions), allowing us to effectively narrow down the\nvast search space to only 20 most relevant functions with accurate candidate\nbug locations and contextual information, and (2) a path-guided repair\nmechanism that leverages KG-mined entity path, tracing through which allows us\nto augment LLMs with relevant contextual information to generate precise\npatches along with their explanations. Experimental results in the\nSWE-Bench-Lite demonstrate that KGCompass achieves state-of-the-art repair\nperformance (45.67%) and function-level localization accuracy (51.33%) across\nopen-source approaches, costing only $0.20 per repair. Our analysis reveals\nthat among successfully localized bugs, 69.7% require multi-hop traversals\nthrough the knowledge graph, without which LLM-based approaches struggle to\naccurately locate bugs. The knowledge graph built in KGCompass is language\nagnostic and can be incrementally updated, making it a practical solution for\nreal-world development environments.","main_category":"cs.SE","categories":"cs.SE","published":"2025-03-27T17:21:47Z"}
{"aid":"http://arxiv.org/abs/2503.21711v1","title":"Efficient Computation of the Directional Extremal Boundary of a Union of\n  Equal-Radius Circles","summary":"This paper focuses on computing the directional extremal boundary of a union\nof equal-radius circles. We introduce an efficient algorithm that accurately\ndetermines this boundary by analyzing the intersections and dominant\nrelationships among the circles. The algorithm has time complexity of O(n log\nn).","main_category":"cs.CG","categories":"cs.CG","published":"2025-03-27T17:22:14Z"}
{"aid":"http://arxiv.org/abs/2503.21715v1","title":"A Powerful Bootstrap Test of Independence in High Dimensions","summary":"This paper proposes a nonparametric test of independence of one random\nvariable from a large pool of other random variables. The test statistic is the\nmaximum of several Chatterjee's rank correlations and critical values are\ncomputed via a block multiplier bootstrap. The test is shown to asymptotically\ncontrol size uniformly over a large class of data-generating processes, even\nwhen the number of variables is much larger than sample size. The test is\nconsistent against any fixed alternative. It can be combined with a stepwise\nprocedure for selecting those variables from the pool that violate\nindependence, while controlling the family-wise error rate. All formal results\nleave the dependence among variables in the pool completely unrestricted. In\nsimulations, we find that our test is very powerful, outperforming existing\ntests in most scenarios considered, particularly in high dimensions and/or when\nthe variables in the pool are dependent.","main_category":"stat.ME","categories":"stat.ME,econ.EM","published":"2025-03-27T17:28:15Z"}
{"aid":"http://arxiv.org/abs/2503.21719v1","title":"The Principle of Redundant Reflection","summary":"The fact that redundant information does not change a rational belief after\nBayesian updating implies uniqueness of Bayes rule. In fact, any updating rule\nis uniquely specified by this principle. This is true for the classical\nsetting, as well as settings with improper or continuous priors. We prove this\nresult and illustrate it with two examples.","main_category":"stat.ME","categories":"stat.ME,stat.OT","published":"2025-03-27T17:31:22Z"}
{"aid":"http://arxiv.org/abs/2503.21732v1","title":"SparseFlex: High-Resolution and Arbitrary-Topology 3D Shape Modeling","summary":"Creating high-fidelity 3D meshes with arbitrary topology, including open\nsurfaces and complex interiors, remains a significant challenge. Existing\nimplicit field methods often require costly and detail-degrading watertight\nconversion, while other approaches struggle with high resolutions. This paper\nintroduces SparseFlex, a novel sparse-structured isosurface representation that\nenables differentiable mesh reconstruction at resolutions up to $1024^3$\ndirectly from rendering losses. SparseFlex combines the accuracy of Flexicubes\nwith a sparse voxel structure, focusing computation on surface-adjacent regions\nand efficiently handling open surfaces. Crucially, we introduce a frustum-aware\nsectional voxel training strategy that activates only relevant voxels during\nrendering, dramatically reducing memory consumption and enabling\nhigh-resolution training. This also allows, for the first time, the\nreconstruction of mesh interiors using only rendering supervision. Building\nupon this, we demonstrate a complete shape modeling pipeline by training a\nvariational autoencoder (VAE) and a rectified flow transformer for high-quality\n3D shape generation. Our experiments show state-of-the-art reconstruction\naccuracy, with a ~82% reduction in Chamfer Distance and a ~88% increase in\nF-score compared to previous methods, and demonstrate the generation of\nhigh-resolution, detailed 3D shapes with arbitrary topology. By enabling\nhigh-resolution, differentiable mesh reconstruction and generation with\nrendering losses, SparseFlex significantly advances the state-of-the-art in 3D\nshape representation and modeling.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:46:42Z"}
{"aid":"http://arxiv.org/abs/2503.21740v1","title":"Transitioning to Memory Burden: Detectable Small Primordial Black Holes\n  as Dark Matter","summary":"Mounting theoretical evidence suggests that black holes are subjected to the\nmemory burden effect, implying that after certain time the information stored\nin them suppresses the decay rate. This effect opens up a new window for small\nprimordial black holes (PBHs) below $10^{15}\\,{\\rm g}$ as dark matter. We show\nthat the smooth transition from semi-classical evaporation to the\nmemory-burdened phase strongly impacts observational bounds on the abundance of\nsmall PBHs. The most stringent constraints come from present-day fluxes of\nastrophysical particles. Remarkably, currently-transitioning small PBHs are\ndetectable through high-energetic neutrino events.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO,astro-ph.HE,gr-qc,hep-th","published":"2025-03-27T17:51:05Z"}
{"aid":"http://arxiv.org/abs/2503.21756v1","title":"A Unified Framework for Diffusion Bridge Problems: Flow Matching and\n  Schrödinger Matching into One","summary":"The bridge problem is to find an SDE (or sometimes an ODE) that bridges two\ngiven distributions. The application areas of the bridge problem are enormous,\namong which the recent generative modeling (e.g., conditional or unconditional\nimage generation) is the most popular. Also the famous Schr\\\"{o}dinger bridge\nproblem, a widely known problem for a century, is a special instance of the\nbridge problem. Two most popular algorithms to tackle the bridge problems in\nthe deep learning era are: (conditional) flow matching and iterative fitting\nalgorithms, where the former confined to ODE solutions, and the latter\nspecifically for the Schr\\\"{o}dinger bridge problem. The main contribution of\nthis article is in two folds: i) We provide concise reviews of these algorithms\nwith technical details to some extent; ii) We propose a novel unified\nperspective and framework that subsumes these seemingly unrelated algorithms\n(and their variants) into one. In particular, we show that our unified\nframework can instantiate the Flow Matching (FM) algorithm, the (mini-batch)\noptimal transport FM algorithm, the (mini-batch) Schr\\\"{o}dinger bridge FM\nalgorithm, and the deep Schr\\\"{o}dinger bridge matching (DSBM) algorithm as its\nspecial cases. We believe that this unified framework will be useful for\nviewing the bridge problems in a more general and flexible perspective, and in\nturn can help researchers and practitioners to develop new bridge algorithms in\ntheir fields.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-27T17:57:03Z"}
{"aid":"http://arxiv.org/abs/2503.21757v1","title":"Fwd2Bot: LVLM Visual Token Compression with Double Forward Bottleneck","summary":"In this work, we aim to compress the vision tokens of a Large Vision Language\nModel (LVLM) into a representation that is simultaneously suitable for (a)\ngenerative and (b) discriminative tasks, (c) is nearly lossless, and (d) is\nstorage-efficient. We propose a novel compression approach, called Fwd2Bot,\nthat uses the LVLM itself to compress the visual information in a task-agnostic\nmanner. At the core of Fwd2bot there exists a \"double-forward pass\" training\nstrategy, whereby, during the first forward pass, the LLM (of the LVLM) creates\na bottleneck by condensing the visual information into a small number of\nsummary tokens. Then, using the same LLM, the second forward pass processes the\nlanguage instruction(s) alongside the summary tokens, used as a direct\nreplacement for the image ones. The training signal is provided by two losses:\nan autoregressive one applied after the second pass that provides a direct\noptimization objective for compression, and a contrastive loss, applied after\nthe first pass, that further boosts the representation strength, especially for\ndiscriminative tasks. The training is further enhanced by stage-specific\nadapters. We accompany the proposed method by an in-depth ablation study.\nOverall, Fwd2Bot results in highly-informative compressed representations\nsuitable for both generative and discriminative tasks. For generative tasks, we\noffer a 2x higher compression rate without compromising the generative\ncapabilities, setting a new state-of-the-art result. For discriminative tasks,\nwe set a new state-of-the-art on image retrieval and compositionality.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-03-27T17:57:07Z"}
{"aid":"http://arxiv.org/abs/2503.21758v1","title":"Lumina-Image 2.0: A Unified and Efficient Image Generative Framework","summary":"We introduce Lumina-Image 2.0, an advanced text-to-image generation framework\nthat achieves significant progress compared to previous work, Lumina-Next.\nLumina-Image 2.0 is built upon two key principles: (1) Unification - it adopts\na unified architecture (Unified Next-DiT) that treats text and image tokens as\na joint sequence, enabling natural cross-modal interactions and allowing\nseamless task expansion. Besides, since high-quality captioners can provide\nsemantically well-aligned text-image training pairs, we introduce a unified\ncaptioning system, Unified Captioner (UniCap), specifically designed for T2I\ngeneration tasks. UniCap excels at generating comprehensive and accurate\ncaptions, accelerating convergence and enhancing prompt adherence. (2)\nEfficiency - to improve the efficiency of our proposed model, we develop\nmulti-stage progressive training strategies and introduce inference\nacceleration techniques without compromising image quality. Extensive\nevaluations on academic benchmarks and public text-to-image arenas show that\nLumina-Image 2.0 delivers strong performances even with only 2.6B parameters,\nhighlighting its scalability and design efficiency. We have released our\ntraining details, code, and models at\nhttps://github.com/Alpha-VLLM/Lumina-Image-2.0.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:57:07Z"}
{"aid":"http://arxiv.org/abs/2503.21762v1","title":"On the open TS/ST correspondence","summary":"The topological string/spectral theory correspondence establishes a precise,\nnon-perturbative duality between topological strings on local Calabi-Yau\nthreefolds and the spectral theory of quantized mirror curves. While this\nduality has been rigorously formulated for the closed topological string\nsector, the open string sector remains less understood. Building on the results\nof [1-3], we make further progress in this direction by constructing entire,\noff-shell eigenfunctions for the quantized mirror curve from open topological\nstring partition functions. We focus on local $\\mathbb{F}_0$, whose mirror\ncurve corresponds to the Baxter equation of the two-particle, relativistic Toda\nlattice. We then study the standard and dual four-dimensional limits, where the\nquantum mirror curve for local $\\mathbb{F}_0$ degenerates into the modified\nMathieu and McCoy-Tracy-Wu operators, respectively. In these limits, our\nframework provides a way to construct entire, off-shell eigenfunctions for the\ndifference equations associated with these operators. Furthermore, we find a\nsimple relation between the on-shell eigenfunctions of the modified Mathieu and\nMcCoy-Tracy-Wu operators, leading to a functional relation between the\noperators themselves.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP,math.SP","published":"2025-03-27T17:57:37Z"}
{"aid":"http://arxiv.org/abs/2503.21765v1","title":"Exploring the Evolution of Physics Cognition in Video Generation: A\n  Survey","summary":"Recent advancements in video generation have witnessed significant progress,\nespecially with the rapid advancement of diffusion models. Despite this, their\ndeficiencies in physical cognition have gradually received widespread attention\n- generated content often violates the fundamental laws of physics, falling\ninto the dilemma of ''visual realism but physical absurdity\". Researchers began\nto increasingly recognize the importance of physical fidelity in video\ngeneration and attempted to integrate heuristic physical cognition such as\nmotion representations and physical knowledge into generative systems to\nsimulate real-world dynamic scenarios. Considering the lack of a systematic\noverview in this field, this survey aims to provide a comprehensive summary of\narchitecture designs and their applications to fill this gap. Specifically, we\ndiscuss and organize the evolutionary process of physical cognition in video\ngeneration from a cognitive science perspective, while proposing a three-tier\ntaxonomy: 1) basic schema perception for generation, 2) passive cognition of\nphysical knowledge for generation, and 3) active cognition for world\nsimulation, encompassing state-of-the-art methods, classical paradigms, and\nbenchmarks. Subsequently, we emphasize the inherent key challenges in this\ndomain and delineate potential pathways for future research, contributing to\nadvancing the frontiers of discussion in both academia and industry. Through\nstructured review and interdisciplinary analysis, this survey aims to provide\ndirectional guidance for developing interpretable, controllable, and physically\nconsistent video generation paradigms, thereby propelling generative models\nfrom the stage of ''visual mimicry'' towards a new phase of ''human-like\nphysical comprehension''.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:58:33Z"}
{"aid":"http://arxiv.org/abs/2503.21767v1","title":"Semantic Consistent Language Gaussian Splatting for Point-Level\n  Open-vocabulary Querying","summary":"Open-vocabulary querying in 3D Gaussian Splatting aims to identify\nsemantically relevant regions within a 3D Gaussian representation based on a\ngiven text query. Prior work, such as LangSplat, addressed this task by\nretrieving these regions in the form of segmentation masks on 2D renderings.\nMore recently, OpenGaussian introduced point-level querying, which directly\nselects a subset of 3D Gaussians. In this work, we propose a point-level\nquerying method that builds upon LangSplat's framework. Our approach improves\nthe framework in two key ways: (a) we leverage masklets from the Segment\nAnything Model 2 (SAM2) to establish semantic consistent ground-truth for\ndistilling the language Gaussians; (b) we introduces a novel two-step querying\napproach that first retrieves the distilled ground-truth and subsequently uses\nthe ground-truth to query the individual Gaussians. Experimental evaluations on\nthree benchmark datasets demonstrate that the proposed method achieves better\nperformance compared to state-of-the-art approaches. For instance, our method\nachieves an mIoU improvement of +20.42 on the 3D-OVS dataset.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:05Z"}
{"aid":"http://arxiv.org/abs/2503.21770v1","title":"Visual Jenga: Discovering Object Dependencies via Counterfactual\n  Inpainting","summary":"This paper proposes a novel scene understanding task called Visual Jenga.\nDrawing inspiration from the game Jenga, the proposed task involves\nprogressively removing objects from a single image until only the background\nremains. Just as Jenga players must understand structural dependencies to\nmaintain tower stability, our task reveals the intrinsic relationships between\nscene elements by systematically exploring which objects can be removed while\npreserving scene coherence in both physical and geometric sense. As a starting\npoint for tackling the Visual Jenga task, we propose a simple, data-driven,\ntraining-free approach that is surprisingly effective on a range of real-world\nimages. The principle behind our approach is to utilize the asymmetry in the\npairwise relationships between objects within a scene and employ a large\ninpainting model to generate a set of counterfactuals to quantify the\nasymmetry.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:33Z"}
{"aid":"http://arxiv.org/abs/2503.21779v1","title":"X$^{2}$-Gaussian: 4D Radiative Gaussian Splatting for Continuous-time\n  Tomographic Reconstruction","summary":"Four-dimensional computed tomography (4D CT) reconstruction is crucial for\ncapturing dynamic anatomical changes but faces inherent limitations from\nconventional phase-binning workflows. Current methods discretize temporal\nresolution into fixed phases with respiratory gating devices, introducing\nmotion misalignment and restricting clinical practicality. In this paper, We\npropose X$^2$-Gaussian, a novel framework that enables continuous-time 4D-CT\nreconstruction by integrating dynamic radiative Gaussian splatting with\nself-supervised respiratory motion learning. Our approach models anatomical\ndynamics through a spatiotemporal encoder-decoder architecture that predicts\ntime-varying Gaussian deformations, eliminating phase discretization. To remove\ndependency on external gating devices, we introduce a physiology-driven\nperiodic consistency loss that learns patient-specific breathing cycles\ndirectly from projections via differentiable optimization. Extensive\nexperiments demonstrate state-of-the-art performance, achieving a 9.93 dB PSNR\ngain over traditional methods and 2.25 dB improvement against prior Gaussian\nsplatting techniques. By unifying continuous motion modeling with hardware-free\nperiod learning, X$^2$-Gaussian advances high-fidelity 4D CT reconstruction for\ndynamic clinical imaging. Project website at: https://x2-gaussian.github.io/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:57Z"}
{"aid":"http://arxiv.org/abs/2503.23682v1","title":"Stability conditions on blowups","summary":"We study the relation between perverse stability conditions and geometric\nstability conditions under blow up. We confirm a conjecture of Toda in some\nspecial cases and show that geometric stability conditions can be induced from\nperverse stability conditions from semiorthogonal decompositions associated to\nblowups.","main_category":"math.AG","categories":"math.AG","published":"2025-03-31T03:13:46Z"}
{"aid":"http://arxiv.org/abs/2503.23689v1","title":"Existence of complete conformal metrics on $\\mathbb{R}^n$ with\n  prescribed Q-curvature","summary":"Given a smooth function $f(x)$ on $\\mathbb{R}^n$ which is positive somewhere\nand satisfies $f(x)=O(|x|^{-l})$ for any $l>\\frac{n}{2}$, we show that there\nexists a complete and conformal metric $g=e^{2u}|dx|^2$ with finite total\nQ-curvature such that its Q-curvature equals to $f(x)$.","main_category":"math.DG","categories":"math.DG,math.AP","published":"2025-03-31T03:38:56Z"}
{"aid":"http://arxiv.org/abs/2503.23701v1","title":"Topological Electronic Structure and Transport Properties of the\n  Distorted Rutile-type WO$_2$","summary":"We elucidate the transport properties and electronic structures of distorted\nrutile-type WO2. Electrical resistivity and Hall effect measurements of\nhigh-quality single crystals revealed the transport property characteristics of\ntopological materials; these characteristics included an extremely large\nmagnetoresistance of 13,200% (2 K and 9 T) and a very high carrier mobility of\n25,700 cm2 V-1 s-1 (5 K). First-principles calculations revealed Dirac nodal\nlines (DNL) near the Fermi energy in the electronic structure when spin-orbit\ninteractions (SOIs) were absent. Although these DNLs mostly disappeared in the\npresence of SOIs, band crossings at high-symmetry points in the reciprocal\nspace existed as Dirac points. Furthermore, DNLs protected by nonsymmorphic\nsymmetry persisted on the ky = {\\pi}/b plane. The unique transport properties\noriginating from the topological electronic structure of chemically and\nthermally stable WO2 could represent an opportunity to investigate the\npotential electronic applications of the material.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-03-31T03:58:36Z"}
{"aid":"http://arxiv.org/abs/2503.23704v1","title":"Paramagnetic half-moon shaped diffuse scattering arising from 3D\n  magnetic frustration","summary":"We use spin dynamics simulations to determine the origin of the unusual\ncorrelated diffuse scattering, characterised by half-moon shapes bridging the\nmagnetic Bragg peaks, observed in the polarised elastic neutron scattering from\nmanganese tungstate, MnWO\\textsubscript{4}. We first fit a Heisenberg\nHamiltonian with twelve nearest-neighbour exchange interactions and single-ion\nanisotropy to the experimental ground-state magnon dispersion. We then show via\nspin dynamics simulations that our model Hamiltonian both reproduces the\nexperimentally observed half-moon features and captures their persistence into\nthe paramagnetic regime. Moreover, we identify the three-dimensional, competing\nantiferromagnetic interactions driving this behavior. Our work complements\nearlier studies of half-moon-shaped signatures in pyrochlore and triangular\nstructures, by providing insight into their origin in a zigzag chain geometry\nwith three-dimensional competing exchange interactions.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci","published":"2025-03-31T04:01:00Z"}
{"aid":"http://arxiv.org/abs/2503.23708v1","title":"Towards Benchmarking and Assessing the Safety and Robustness of\n  Autonomous Driving on Safety-critical Scenarios","summary":"Autonomous driving has made significant progress in both academia and\nindustry, including performance improvements in perception task and the\ndevelopment of end-to-end autonomous driving systems. However, the safety and\nrobustness assessment of autonomous driving has not received sufficient\nattention. Current evaluations of autonomous driving are typically conducted in\nnatural driving scenarios. However, many accidents often occur in edge cases,\nalso known as safety-critical scenarios. These safety-critical scenarios are\ndifficult to collect, and there is currently no clear definition of what\nconstitutes a safety-critical scenario. In this work, we explore the safety and\nrobustness of autonomous driving in safety-critical scenarios. First, we\nprovide a definition of safety-critical scenarios, including static traffic\nscenarios such as adversarial attack scenarios and natural distribution shifts,\nas well as dynamic traffic scenarios such as accident scenarios. Then, we\ndevelop an autonomous driving safety testing platform to comprehensively\nevaluate autonomous driving systems, encompassing not only the assessment of\nperception modules but also system-level evaluations. Our work systematically\nconstructs a safety verification process for autonomous driving, providing\ntechnical support for the industry to establish standardized test framework and\nreduce risks in real-world road deployment.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-03-31T04:13:32Z"}
{"aid":"http://arxiv.org/abs/2503.23712v1","title":"ElimPCL: Eliminating Noise Accumulation with Progressive Curriculum\n  Labeling for Source-Free Domain Adaptation","summary":"Source-Free Domain Adaptation (SFDA) aims to train a target model without\nsource data, and the key is to generate pseudo-labels using a pre-trained\nsource model. However, we observe that the source model often produces highly\nuncertain pseudo-labels for hard samples, particularly those heavily affected\nby domain shifts, leading to these noisy pseudo-labels being introduced even\nbefore adaptation and further reinforced through parameter updates.\nAdditionally, they continuously influence neighbor samples through propagation\nin the feature space.To eliminate the issue of noise accumulation, we propose a\nnovel Progressive Curriculum Labeling (ElimPCL) method, which iteratively\nfilters trustworthy pseudo-labeled samples based on prototype consistency to\nexclude high-noise samples from training. Furthermore, a Dual MixUP technique\nis designed in the feature space to enhance the separability of hard samples,\nthereby mitigating the interference of noisy samples on their\nneighbors.Extensive experiments validate the effectiveness of ElimPCL,\nachieving up to a 3.4% improvement on challenging tasks compared to\nstate-of-the-art methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T04:28:27Z"}
{"aid":"http://arxiv.org/abs/2503.23729v1","title":"Integral regularization PINNs for evolution equations","summary":"Evolution equations, including both ordinary differential equations (ODEs)\nand partial differential equations (PDEs), play a pivotal role in modeling\ndynamic systems. However, achieving accurate long-time integration for these\nequations remains a significant challenge. While physics-informed neural\nnetworks (PINNs) provide a mesh-free framework for solving PDEs, they often\nsuffer from temporal error accumulation, which limits their effectiveness in\ncapturing long-time behaviors. To alleviate this issue, we propose integral\nregularization PINNs (IR-PINNs), a novel approach that enhances temporal\naccuracy by incorporating an integral-based residual term into the loss\nfunction. This method divides the entire time interval into smaller\nsub-intervals and enforces constraints over these sub-intervals, thereby\nimproving the resolution and correlation of temporal dynamics. Furthermore,\nIR-PINNs leverage adaptive sampling to dynamically refine the distribution of\ncollocation points based on the evolving solution, ensuring higher accuracy in\nregions with sharp gradients or rapid variations. Numerical experiments on\nbenchmark problems demonstrate that IR-PINNs outperform original PINNs and\nother state-of-the-art methods in capturing long-time behaviors, offering a\nrobust and accurate solution for evolution equations.","main_category":"math.NA","categories":"math.NA,cs.LG,cs.NA","published":"2025-03-31T05:02:59Z"}
{"aid":"http://arxiv.org/abs/2503.23734v1","title":"Semantic Packet Aggregation and Repeated Transmission for Text-to-Image\n  Generation","summary":"Text-based communication is expected to be prevalent in 6G applications such\nas wireless AI-generated content (AIGC). Motivated by this, this paper\naddresses the challenges of transmitting text prompts over erasure channels for\na text-to-image AIGC task by developing the semantic segmentation and repeated\ntransmission (SMART) algorithm. SMART groups words in text prompts into\npackets, prioritizing the task-specific significance of semantics within these\npackets, and optimizes the number of repeated transmissions. Simulation results\nshow that SMART achieves higher similarities in received texts and generated\nimages compared to a character-level packetization baseline, while reducing\ncomputing latency by orders of magnitude compared to an exhaustive search\nbaseline.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T05:14:40Z"}
{"aid":"http://arxiv.org/abs/2503.23735v1","title":"Altermagnetism and Weak Ferromagnetism","summary":"Using a realistic model relevant to La$_2$CuO$_4$ and other altermagnetic\nperovskite oxides, we study interrelations between weak ferromagnetism (WF),\nanomalous Hall effect (AHE), and net orbital magnetization (OM). All of them\ncan be linked to the form of Dzyaloshinskii-Moriya (DM) interactions.\nNevertheless, while spin WF is induced by the DM vector components having the\nsame sign in all equivalent bonds, AHE and OM are related to alternating-sign\ncomponents, which do not contribute to any canting of spins. The microscopic\nmodel remains invariant under the symmetry operation $\\{ \\mathcal{S}|{\\bf t}\n\\}$, combining the shift ${\\bf t}$ of antiferromagnetically coupled sublattices\nto each other with the spin flip $\\mathcal{S}$. Thus, the band structure\nremains Kramers-degenerate, but the time-reversal symmetry is broken, providing\na possibility to realize AHE in antiferromagnetic substances. The altermagnetic\nsplitting of bands, breaking the $\\{ \\mathcal{S}|{\\bf t}\\}$ symmetry, does not\nplay a major role in the problem. More important is the orthorhombic strain,\nresponsible for finite values of AHE and OM.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-03-31T05:15:47Z"}
{"aid":"http://arxiv.org/abs/2503.23744v1","title":"European Contributions to Fermilab Accelerator Upgrades and Facilities\n  for the DUNE Experiment","summary":"The Proton Improvement Plan (PIP-II) to the FNAL accelerator chain and the\nLong-Baseline Neutrino Facility (LBNF) will provide the world's most intense\nneutrino beam to the Deep Underground Neutrino Experiment (DUNE) enabling a\nwide-ranging physics program. This document outlines the significant\ncontributions made by European national laboratories and institutes towards\nrealizing the first phase of the project with a 1.2 MW neutrino beam.\nConstruction of this first phase is well underway. For DUNE Phase II, this will\nbe closely followed by an upgrade of the beam power to > 2 MW, for which the\nEuropean groups again have a key role and which will require the continued\nsupport of the European community for machine aspects of neutrino physics.\nBeyond the neutrino beam aspects, LBNF is also responsible for providing unique\ninfrastructure to install and operate the DUNE neutrino detectors at FNAL and\nat the Sanford Underground Research Facility (SURF). The cryostats for the\nfirst two Liquid Argon Time Projection Chamber detector modules at SURF, a\ncontribution of CERN to LBNF, are central to the success of the ongoing\nexecution of DUNE Phase I. Likewise, successful and timely procurement of\ncryostats for two additional detector modules at SURF will be critical to the\nsuccess of DUNE Phase II and the overall physics program. The DUNE\nCollaboration is submitting four main contributions to the 2026 Update of the\nEuropean Strategy for Particle Physics process. This paper is being submitted\nto the 'Accelerator technologies' and 'Projects and Large Experiments' streams.\nAdditional inputs related to the DUNE science program, DUNE detector\ntechnologies and R&D, and DUNE software and computing, are also being submitted\nto other streams.","main_category":"physics.acc-ph","categories":"physics.acc-ph,hep-ex,physics.ins-det","published":"2025-03-31T05:47:29Z"}
{"aid":"http://arxiv.org/abs/2503.23756v1","title":"On a natural L2 metric on the space of Hermitian metrics","summary":"We investigate the space of Hermitian metrics on a fixed complex vector\nbundle. This infinite-dimensional space has appeared in the study of\nHermitian-Einstein structures, where a special L2-type Riemannian metric is\nintroduced. We compute the metric spray, geodesics and curvature associated to\nthis metric, and show that the exponential map is a diffeomorphsim. Though\nbeing geodesically complete, the space of Hermitian metrics is metrically\nincomplete, and its metric completion is proved to be the space of L2\nintegrable singular Hermitian metrics. In addition, both the original space and\nits completion are CAT(0). In the holomorphic case, it turns out that Griffiths\nseminegative/semipositive singular Hermitian metric is always L2 integrable in\nour sense. Also, in the Appendix, the Nash-Moser inverse function theorem is\nused to prove that, for any L2 metric on the space of smooth sections of a\ngiven fiber bundle, the exponential map is always a local diffeomorphism,\nprovided that each fiber is nonpositively curved.","main_category":"math.DG","categories":"math.DG","published":"2025-03-31T06:12:40Z"}
{"aid":"http://arxiv.org/abs/2503.23758v1","title":"Exact Solution of the Frustrated Potts Model with Next-Nearest-Neighbor\n  Interactions in One Dimension: An AI-Aided Discovery","summary":"The one-dimensional $J_1$-$J_2$ $q$-state Potts model is solved exactly for\narbitrary $q$, based on using OpenAI's latest reasoning model o3-mini-high to\nexactly solve the $q=3$ case. The exact results provide insights to outstanding\nphysical problems such as the stacking of atomic or electronic orders in\nlayered materials and the formation of a $T_c$-dome-shaped phase often seen in\nunconventional superconductors. The work is anticipated to fuel both the\nresearch in one-dimensional frustrated magnets for recently discovered\nfinite-temperature application potentials and the fast moving topic area of AI\nfor sciences.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,math-ph,math.MP","published":"2025-03-31T06:16:26Z"}
{"aid":"http://arxiv.org/abs/2503.23762v1","title":"UniSep: Universal Target Audio Separation with Language Models at Scale","summary":"We propose Universal target audio Separation (UniSep), addressing the\nseparation task on arbitrary mixtures of different types of audio.\nDistinguished from previous studies, UniSep is performed on unlimited source\ndomains and unlimited source numbers. We formulate the separation task as a\nsequence-to-sequence problem, and a large language model (LLM) is used to model\nthe audio sequence in the discrete latent space, leveraging the power of LLM in\nhandling complex mixture audios with large-scale data. Moreover, a novel\npre-training strategy is proposed to utilize audio-only data, which reduces the\nefforts of large-scale data simulation and enhances the ability of LLMs to\nunderstand the consistency and correlation of information within audio\nsequences. We also demonstrate the effectiveness of scaling datasets in an\naudio separation task: we use large-scale data (36.5k hours), including speech,\nmusic, and sound, to train a universal target audio separation model that is\nnot limited to a specific domain. Experiments show that UniSep achieves\ncompetitive subjective and objective evaluation results compared with\nsingle-task models.","main_category":"cs.SD","categories":"cs.SD,eess.AS","published":"2025-03-31T06:27:37Z"}
{"aid":"http://arxiv.org/abs/2503.23763v1","title":"Career Incentives, Risk-Taking, and Sorting Dynamics: Evidence from Top\n  Financial Advisers","summary":"We examine how career concerns influence the behavior and mobility of\nfinancial advisers. Drawing on a uniquely comprehensive matched panel that\ncombines employer-employee data with a longstanding national ranking, our study\ntests predictions from classic career concerns models and tournament theory.\nOur analysis shows that, in the early stages of their careers, advisers\ndestined for top performance differ significantly from their peers.\nSpecifically, before being ranked, these advisers are twice as likely to obtain\na key investment license, experience customer disputes at rates up to seven\ntimes higher, and transition to firms with 80% larger total assets. Moreover,\nwe find that top advisers mitigate the potential costs of their higher\nrisk-taking by facing reduced labor market penalties following disciplinary\nactions. Leveraging exogenous variation from the staggered adoption of the\nBroker Protocol through an event-study framework, our results reveal dynamic\nsorting: firms attract high-performing advisers intensely within a short\npost-adoption period. These findings shed new light on the interplay between\ncareer incentives, risk-taking, and labor market outcomes in the financial\nservices industry, with important implications for both firm performance and\nregulatory policy.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-03-31T06:27:41Z"}
{"aid":"http://arxiv.org/abs/2503.23776v1","title":"VIDEX: A Disaggregated and Extensible Virtual Index for the Cloud and AI\n  Era","summary":"Virtual index, also known as hypothetical indexes, play a crucial role in\ndatabase query optimization. However, with the rapid advancement of cloud\ncomputing and AI-driven models for database optimization, traditional virtual\nindex approaches face significant challenges. Cloud-native environments often\nprohibit direct conducting query optimization process on production databases\ndue to stability requirements and data privacy concerns. Moreover, while AI\nmodels show promising progress, their integration with database systems poses\nchallenges in system complexity, inference acceleration, and model hot updates.\nIn this paper, we present VIDEX, a three-layer disaggregated architecture that\ndecouples database instances, the virtual index optimizer, and algorithm\nservices, providing standardized interfaces for AI model integration. Users can\nconfigure VIDEX by either collecting production statistics or by loading from a\nprepared file; this setup allows for high-accurate what-if analyses based on\nvirtual indexes, achieving query plans that are identical to those of the\nproduction instance. Additionally, users can freely integrate new AI-driven\nalgorithms into VIDEX. VIDEX has been successfully deployed at ByteDance,\nserving thousands of MySQL instances daily and over millions of SQL queries for\nindex optimization tasks.","main_category":"cs.DB","categories":"cs.DB","published":"2025-03-31T06:52:13Z"}
{"aid":"http://arxiv.org/abs/2503.23782v1","title":"Distributional regression with reject option","summary":"Selective prediction, where a model has the option to abstain from making a\ndecision, is crucial for machine learning applications in which mistakes are\ncostly. In this work, we focus on distributional regression and introduce a\nframework that enables the model to abstain from estimation in situations of\nhigh uncertainty. We refer to this approach as distributional regression with\nreject option, inspired by similar concepts in classification and regression\nwith reject option. We study the scenario where the rejection rate is fixed. We\nderive a closed-form expression for the optimal rule, which relies on\nthresholding the entropy function of the Continuous Ranked Probability Score\n(CRPS). We propose a semi-supervised estimation procedure for the optimal rule,\nusing two datasets: the first, labeled, is used to estimate both the\nconditional distribution function and the entropy function of the CRPS, while\nthe second, unlabeled, is employed to calibrate the desired rejection rate.\nNotably, the control of the rejection rate is distribution-free. Under mild\nconditions, we show that our procedure is asymptotically as effective as the\noptimal rule, both in terms of error rate and rejection rate. Additionally, we\nestablish rates of convergence for our approach based on distributional\nk-nearest neighbor. A numerical analysis on real-world datasets demonstrates\nthe strong performance of our procedure","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-03-31T06:56:18Z"}
{"aid":"http://arxiv.org/abs/2503.23790v1","title":"Constructing geometric realizations of birational maps between Mori\n  Dream Spaces","summary":"We construct geometric realizations -- projective algebraic versions of\ncobordisms -- for birational maps between Mori Dream Spaces. We show that these\ngeometric realizations are Mori Dream Spaces, as well, and that they can be\nconstructed so that they induce factorizations of the original birational maps\nas compositions of wall-crossings. In the case of toric birational maps between\nnormal $\\mathbb{Q}$-factorial, projective toric varieties, we provide several\nSageMath functions to work with $\\mathbb{C}^*$-actions and birational geometry;\nin particular we show how to explicitly construct a moment polytope of a toric\ngeometric realization. Moreover, by embedding Mori Dream Spaces in toric\nvarieties, we obtain geometric realizations of birational maps of Mori Dream\nSpaces as restrictions of toric geometric realizations. We also provide\nexamples and discuss when a geometric realization is Fano.","main_category":"math.AG","categories":"math.AG","published":"2025-03-31T07:07:54Z"}
{"aid":"http://arxiv.org/abs/2503.23794v1","title":"Force-Free Molecular Dynamics Through Autoregressive Equivariant\n  Networks","summary":"Molecular dynamics (MD) simulations play a crucial role in scientific\nresearch. Yet their computational cost often limits the timescales and system\nsizes that can be explored. Most data-driven efforts have been focused on\nreducing the computational cost of accurate interatomic forces required for\nsolving the equations of motion. Despite their success, however, these machine\nlearning interatomic potentials (MLIPs) are still bound to small time-steps. In\nthis work, we introduce TrajCast, a transferable and data-efficient framework\nbased on autoregressive equivariant message passing networks that directly\nupdates atomic positions and velocities lifting the constraints imposed by\ntraditional numerical integration. We benchmark our framework across various\nsystems, including a small molecule, crystalline material, and bulk liquid,\ndemonstrating excellent agreement with reference MD simulations for structural,\ndynamical, and energetic properties. Depending on the system, TrajCast allows\nfor forecast intervals up to $30\\times$ larger than traditional MD time-steps,\ngenerating over 15 ns of trajectory data per day for a solid with more than\n4,000 atoms. By enabling efficient large-scale simulations over extended\ntimescales, TrajCast can accelerate materials discovery and explore physical\nphenomena beyond the reach of traditional simulations and experiments. An\nopen-source implementation of TrajCast is accessible under\nhttps://github.com/IBM/trajcast.","main_category":"physics.comp-ph","categories":"physics.comp-ph,cond-mat.mtrl-sci,cs.LG,physics.chem-ph","published":"2025-03-31T07:14:32Z"}
{"aid":"http://arxiv.org/abs/2503.23796v1","title":"On-device Sora: Enabling Training-Free Diffusion-based Text-to-Video\n  Generation for Mobile Devices","summary":"We present On-device Sora, the first model training-free solution for\ndiffusion-based on-device text-to-video generation that operates efficiently on\nsmartphone-grade devices. To address the challenges of diffusion-based\ntext-to-video generation on computation- and memory-limited mobile devices, the\nproposed On-device Sora applies three novel techniques to pre-trained video\ngenerative models. First, Linear Proportional Leap (LPL) reduces the excessive\ndenoising steps required in video diffusion through an efficient leap-based\napproach. Second, Temporal Dimension Token Merging (TDTM) minimizes intensive\ntoken-processing computation in attention layers by merging consecutive tokens\nalong the temporal dimension. Third, Concurrent Inference with Dynamic Loading\n(CI-DL) dynamically partitions large models into smaller blocks and loads them\ninto memory for concurrent model inference, effectively addressing the\nchallenges of limited device memory. We implement On-device Sora on the iPhone\n15 Pro, and the experimental evaluations show that it is capable of generating\nhigh-quality videos on the device, comparable to those produced by high-end\nGPUs. These results show that On-device Sora enables efficient and high-quality\nvideo generation on resource-constrained mobile devices. We envision the\nproposed On-device Sora as a significant first step toward democratizing\nstate-of-the-art generative technologies, enabling video generation on\ncommodity mobile and embedded devices without resource-intensive re-training\nfor model optimization (compression). The code implementation is available at a\nGitHub repository(https://github.com/eai-lab/On-device-Sora).","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T07:19:09Z"}
{"aid":"http://arxiv.org/abs/2503.23801v1","title":"A PINN Methodology for Temperature Field Reconstruction in the PIV\n  Measurement Plane: Case of Rayleigh-Bénard Convection","summary":"We present a method to infer temperature fields from stereo particle-image\nvelocimetry (PIV) data in turbulent Rayleigh-B\\'enard convection (RBC) using\nPhysics-informed neural networks (PINNs). The physical setup is a cubic RBC\ncell with Rayleigh number $\\text{Ra}=10^7$ and Prandtl number $\\text{Pr}=0.7$.\nWith data only available in a vertical plane $A:x=x_0$, the residuals of the\ngoverning partial differential equations are minimised in an enclosing 3D\ndomain around $A$ with thickness $\\delta_x$. Dynamic collocation point sampling\nstrategies are used to overcome the lack of 3D labelled information and to\noptimize the overall convergence of the PINN. In particular, in the\nout-of-plane direction $x$, the collocation points are distributed according to\na normal distribution, in order to emphasize the region where data is provided.\nAlong the vertical direction, we leverage meshing information and sample points\nfrom a distribution designed based on the grid of a direct numerical simulation\n(DNS). This approach points greater attention to critical regions, particularly\nthe areas with high temperature gradients within the thermal boundary layers.\nUsing planar three-component velocity data from a DNS, we successfully validate\nthe reconstruction of the temperature fields in the PIV plane. We evaluate the\nrobustness of our method with respect to characteristics of the labelled data\nused for training: the data time span, the sampling frequency, some noisy data\nand boundary data omission, aiming to better accommodate the challenges\nassociated with experimental data. Developing PINNs on controlled simulation\ndata is a crucial step toward their effective deployment on experimental data.\nThe key is to systematically introduce noise, gaps, and uncertainties in\nsimulated data to mimic real-world conditions and ensure robust generalization.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-03-31T07:24:06Z"}
{"aid":"http://arxiv.org/abs/2503.23808v1","title":"Why does tinnitus vary with naps? A polysomnographic prospective study\n  exploring the somatosensory hypothesis","summary":"Background: Tinnitus, defined as the conscious awareness of a noise without\nany identifiable corresponding external acoustic source, can be modulated by\nvarious factors. Among these factors, tinnitus patients commonly report drastic\nincreases of tinnitus loudness following nap sleep. Previous studies have\nsuggested that this clinical pattern could be attributed to a somatosensory\nmodulation of tinnitus. To our knowledge, no polysomnographic study has been\ncarried out to assess this hypothesis. Methods: For this observational\nprospective study, 37 participants reporting frequent increases of tinnitus\nfollowing naps were recruited. They participated to six full-polysomnography\nnap attempts over two days. Audiological and kinesiologic tests were conducted\nbefore and after each nap attempt. Results: 197 naps were collected. Each nap\nat each time of day elicited an overall significant increase in tinnitus\nminimum masking level (MML). Each inter nap period elicited an overall\nsignificant decrease. Tinnitus modulations were found significantly correlated\nwith nap sleep duration (Visual numeric scale on tinnitus loudness, VNS-L, p <\n0.05), with snoring duration (MML, p < 0.001), with snoring average sound level\n(VNS on tinnitus intrusiveness, VNS-I, p < 0.05) and with sleep apnea count\n(VNS-I, p < 0.001). Conclusions: This study confirms objectively that tinnitus\nmay increase following naps. No association was found between these modulations\nand somatosensory modulations involving the temporomandibular joint and\ncervical areas. However, it may be possible that nap-induced tinnitus\nmodulations are a hidden form of somatosensory modulation as snoring and sleep\napnea events are often related to tensor veli palatini muscle dysfunction.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-03-31T07:42:33Z"}
{"aid":"http://arxiv.org/abs/2503.23812v1","title":"A new independent look at the galactic black hole low-mass X-ray binary\n  distribution","summary":"Investigations of the Galactic black hole low-mass X-ray binaries (BH-LMXBs)\noffer valuable insights into the elusive black hole population in the Milky\nWay. Motivated by recent tensions in the natal kick velocity distribution and\nBH mass distribution of BH-LMXBs, we revisit the spatial distribution of the\nGalactic BH-LMXBs using a new set of distance measurements obtained from an\nX-ray spectral modelling framework that we introduced in earlier work. We\nperform a multiparameter simulation study to mitigate part of the bias present\nin our prior estimates and gain insights into possible observational selection\neffects that affect the observed population. We derive a bias correction\nfactor, well described by a Pareto probability density function that closely\nfollows an inverse-square law dependence on distance. We then construct a\nbias-corrected, literature-independent, Galactic spatial distribution that\nclearly traces spiral arm structures and shows a deficit of sources very close\nto the Galactic centre, which might be explained due to high extinction or a\ntrue paucity of these sources at that region. Further analysis of the\nsimulation results provides hints for a hidden population of BH-LMXBs at low\nGalactic heights. Lastly, we estimate the root-mean-squared Galactic height and\nfind that it is most compatible with a hybrid scenario of BH formation, with\nsome BHs receiving high natal kicks and thus propelled further from the thin\ndisc plane while others receiving low natal kicks and remaining close to their\nbirth place.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.GA","published":"2025-03-31T07:45:41Z"}
{"aid":"http://arxiv.org/abs/2503.23813v1","title":"Evaluation of a Virtual Laboratory Platform in General Education on\n  Quantum Information Science","summary":"Quantum information science and technology has been revolutionizing our daily\nlife, which attracts the curiosity of young generations from diverse\nbackgrounds. While it is quite challenging to teach and learn quantum\ninformation science for non-physics majors due to the abstract and counter\nintuitive nature of quantum mechanics. To address such challenges, virtual\nlaboratories have offered an effective solution. This paper presents the\nresults of pedagogical research on the efficacy of a virtual laboratory\nplatform in general education courses on quantum information science.\nSpecifically, a virtual lab activity on the Bell test was developed using the\ncommercially available platform QLab. This activity aims to help undergraduates\nfrom diverse disciplines grasp the counterintuitive yet fundamental concept of\nquantum entanglement, famously referred to by Albert Einstein as \"spooky action\nat a distance.\" Qualitative and quantitative evaluations were conducted over\nthree academic years, demonstrating that the virtual laboratory enabled over 80\n\\% of students to comprehend the complex concept and characteristics of quantum\nentanglement. This study provides an effective solution for addressing the\nchallenges of teaching quantum information science in undergraduate general\neducation courses, particularly for students from both science and non-science\nbackgrounds.","main_category":"physics.ed-ph","categories":"physics.ed-ph","published":"2025-03-31T07:47:24Z"}
{"aid":"http://arxiv.org/abs/2503.23814v1","title":"An extension of linear self-attention for in-context learning","summary":"In-context learning is a remarkable property of transformers and has been the\nfocus of recent research. An attention mechanism is a key component in\ntransformers, in which an attention matrix encodes relationships between words\nin a sentence and is used as weights for words in a sentence. This mechanism is\neffective for capturing language representations. However, it is questionable\nwhether naive self-attention is suitable for in-context learning in general\ntasks, since the computation implemented by self-attention is somewhat\nrestrictive in terms of matrix multiplication. In fact, we may need appropriate\ninput form designs when considering heuristic implementations of computational\nalgorithms. In this paper, in case of linear self-attention, we extend it by\nintroducing a bias matrix in addition to a weight matrix for an input. Despite\nthe simple extension, the extended linear self-attention can output any\nconstant matrix, input matrix and multiplications of two or three matrices in\nthe input. Note that the second property implies that it can be a skip\nconnection. Therefore, flexible matrix manipulations can be implemented by\nconnecting the extended linear self-attention components. As an example of\nimplementation using the extended linear self-attention, we show a heuristic\nconstruction of a batch-type gradient descent of ridge regression under a\nreasonable input form.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T07:49:05Z"}
{"aid":"http://arxiv.org/abs/2503.23821v1","title":"Science4Peace: A Plea for Continued Peaceful International Scientific\n  Cooperation (Input to the European Strategy for Particle Physics -- 2026\n  update)","summary":"The European Strategy for Particle Physics (ESPP) - 2026 update is taking\nplace in a turbulent international climate. Many of the norms that have\ngoverned relations between states for decades are being broken or challenged.\nThe future progress of science in general, and particle physics in particular,\nwill depend on our ability to maintain peaceful international scientific\ncollaboration in the face of political pressures. We plead that the ESPP 2026\nupdate acknowledge explicitly the importance of peaceful international\nscientific collaboration, not only for the progress of science, but also as a\nprecious bridge between geopolitical blocs.\n  \"Scientific thought is the common heritage of mankind\" - Abdus Salam","main_category":"physics.soc-ph","categories":"physics.soc-ph,hep-ex,hep-ph,hep-th","published":"2025-03-31T08:15:42Z"}
{"aid":"http://arxiv.org/abs/2503.23824v1","title":"On the Reproducibility of Learned Sparse Retrieval Adaptations for Long\n  Documents","summary":"Document retrieval is one of the most challenging tasks in Information\nRetrieval. It requires handling longer contexts, often resulting in higher\nquery latency and increased computational overhead. Recently, Learned Sparse\nRetrieval (LSR) has emerged as a promising approach to address these\nchallenges. Some have proposed adapting the LSR approach to longer documents by\naggregating segmented document using different post-hoc methods, including\nn-grams and proximity scores, adjusting representations, and learning to\nensemble all signals. In this study, we aim to reproduce and examine the\nmechanisms of adapting LSR for long documents. Our reproducibility experiments\nconfirmed the importance of specific segments, with the first segment\nconsistently dominating document retrieval performance. Furthermore, We\nre-evaluate recently proposed methods -- ExactSDM and SoftSDM -- across varying\ndocument lengths, from short (up to 2 segments) to longer (3+ segments). We\nalso designed multiple analyses to probe the reproduced methods and shed light\non the impact of global information on adapting LSR to longer contexts. The\ncomplete code and implementation for this project is available at:\nhttps://github.com/lionisakis/Reproducibilitiy-lsr-long.","main_category":"cs.IR","categories":"cs.IR","published":"2025-03-31T08:19:31Z"}
{"aid":"http://arxiv.org/abs/2503.23828v1","title":"High-Throughput Exploration of NV-like Color Centers Across Host\n  Materials","summary":"Point defects in semiconductors offer a promising platform for advancing\nquantum technologies due to their localized energy states and controllable spin\nproperties. Prior research has focused on a limited set of defects within\nmaterials such as diamond, silicon carbide, and hexagonal boron nitride. We\npresent a high-throughput study to systematically identify and evaluate point\ndefects across a diverse range of host materials, aiming to uncover previously\nunexplored defects in novel host materials suitable for use in quantum\napplications. A range of host materials are selected for their desirable\nproperties, such as appropriate bandgaps, crystal structure, and absence of d-\nor f-electrons. The Automatic Defect Analysis and Qualification (ADAQ) software\nframework is used to generate vacancies, substitutions with s- and p-elements,\nand interstitials in these materials and use density functional theory to\ncalculate key properties such as Zero-Phonon Lines (ZPLs), ionic displacements,\nTransition Dipole Moments (TDMs), and formation energies. Special attention is\ngiven to charge correction methods for materials with dielectric anisotropy. We\nuncover new defect-host combinations with advantageous properties for quantum\napplications: 28 defects across 11 isotropic and 2 anisotropic host materials\nshow properties similar to the nitrogen-vacancy (NV) center in diamond.\nBeryllium (Be) substitutional defects in SrS, MgS, and SrO emerge as particu-\nlarly promising. These findings contribute to diversifying and enhancing the\nmaterials available for quantum technologies.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-31T08:22:24Z"}
{"aid":"http://arxiv.org/abs/2503.23835v1","title":"Disambiguate Gripper State in Grasp-Based Tasks: Pseudo-Tactile as\n  Feedback Enables Pure Simulation Learning","summary":"Grasp-based manipulation tasks are fundamental to robots interacting with\ntheir environments, yet gripper state ambiguity significantly reduces the\nrobustness of imitation learning policies for these tasks. Data-driven\nsolutions face the challenge of high real-world data costs, while simulation\ndata, despite its low costs, is limited by the sim-to-real gap. We identify the\nroot cause of gripper state ambiguity as the lack of tactile feedback. To\naddress this, we propose a novel approach employing pseudo-tactile as feedback,\ninspired by the idea of using a force-controlled gripper as a tactile sensor.\nThis method enhances policy robustness without additional data collection and\nhardware involvement, while providing a noise-free binary gripper state\nobservation for the policy and thus facilitating pure simulation learning to\nunleash the power of simulation. Experimental results across three real-world\ngrasp-based tasks demonstrate the necessity, effectiveness, and efficiency of\nour approach.","main_category":"cs.RO","categories":"cs.RO","published":"2025-03-31T08:29:17Z"}
{"aid":"http://arxiv.org/abs/2503.23839v1","title":"Three-dimensional Optical Reconstruction of colloidal electrokinetics\n  via multiplane imaging","summary":"Selective manipulation of particles is crucial in many fields, ranging from\nchemistry to biology and physics. Dielectrophoresis stands out due to its high\nselectivity potential and the absence of need for labels. To fully understand\nand control the phenomenon, observation of the dynamic of nanoparticles under\nDEP needs to be performed in the three spatial dimensions. However, not many\nmicroscopy approaches offer such capability at fast frame rates (>100fps) and\nhigh resolution. Here, we used widefield microscopy, to follow the\nspatiotemporal dynamics of fluorescently labelled polystyrene nanoparticles of\n200 nm under positive and negative dielectrophoresis conditions. This real-time\n3D imaging technique allows for single particle tracking, enabling\nsuper-resolved reconstruction of the DEP force and electrokinetic flows with\nunprecedented detail. We compare the differences for positive and negative\ndielectrophoresis conditions and rationalize these by direct comparison with\ndynamic modeling results. The framework shown here shows great promise to\nelucidate the frequency-dependent DEP behavior of nanoparticle, crucial for\nparticle manipulation and sorting.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-03-31T08:33:42Z"}
{"aid":"http://arxiv.org/abs/2503.23858v1","title":"Incremental capacity-based multi-feature fusion model for predicting\n  state-of-health of lithium-ion batteries","summary":"Lithium-ion batteries have become an indispensable part of human industrial\nproduction and daily life. For the safe use, management and maintenance of\nlithium-ion batteries, the state of health (SOH) of lithium-ion batteries is an\nimportant indicator so that the SOH estimation is of significant practical\nvalue. In order to accurately predict SOH, this paper proposes a fusion\nprediction model which combines particle swarm optimization (PSO) algorithm,\nbi-directional long-short time memory network (BiLSTM) and adaptive boosting\n(AdaBoost) algorithm. In the proposed prediction model, indirect health\nindicators (HIs), which characterize battery degradation, are obtained with the\nhelp of incremental capacity analysis (ICA), and is fed into BiLSTM to extract\ntime-series features, whose parameters are optimized by employing PSO\nalgorithm. On this basis, the AdaBoost algorithm is applied to reduce the risk\nof overfitting the PSO-BiLSTM model. The study based on lithium-ion battery\ndata from Center for Advanced Life Cycle Engineering (CALCE) shows that the\nPSO-BiLSTM-AdaBoost model has higher accuracy, better robustness, and\ngeneralization ability.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-03-31T09:05:56Z"}
{"aid":"http://arxiv.org/abs/2503.23876v1","title":"Populations of evolved massive binary stars in the Small Magellanic\n  Cloud I: Predictions from detailed evolution models","summary":"Context. The majority of massive stars are born with a close binary\ncompanion. How this affects their evolution and fate is still largely\nuncertain, especially at low metallicity. Aims. We derive synthetic populations\nof massive post-interaction binary products and compare them with corresponding\nobserved populations in the Small Magellanic Cloud (SMC). Methods. We analyse\n53298 detailed binary evolutionary models computed with MESA. Our models\ninclude the physics of rotation, mass and angular momentum transfer, magnetic\ninternal angular momentum transport, and tidal spin-orbit coupling. They cover\ninitial primary masses of 5-100Msun, initial mass ratios of 0.3-0.95, and all\ninitial periods for which interaction is expected. They are evolved through the\nfirst mass transfer and the donor star death, a possible ensuing Be/X-ray\nbinary phase, and they end when the mass gainer leaves the main sequence.\nResults.In our fiducial synthetic population, 8% of the OB stars in the SMC are\npost-mass transfer systems, and 7% are merger products. In many of our models,\nthe mass gainers are spun up and form Oe/Be stars. While our model\nunderpredicts the number of Be/X-ray binaries in the SMC, it reproduces the\nmain features of their orbital period distribution and the observed number of\nSMC binary WR stars. We expect $\\sim$50 OB+BH binaries below and $\\sim$170\nabove 20d orbital period. The latter might produce merging double BHs. However,\ntheir progenitors, the predicted long-period WR+OB binaries, are not observed.\nConclusions. While the comparison with the observed SMC stars supports many\nphysics assumptions in our high-mass binary models, a better match of the large\nnumber of observed OBe stars and Be/X-ray binaries likely requires a lower\nmerger rate and/or a higher mass transfer efficiency during the first mass\ntransfer. The fate of the initially wide O star binaries remains uncertain.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA,astro-ph.HE","published":"2025-03-31T09:26:52Z"}
{"aid":"http://arxiv.org/abs/2503.23877v1","title":"ZeroMimic: Distilling Robotic Manipulation Skills from Web Videos","summary":"Many recent advances in robotic manipulation have come through imitation\nlearning, yet these rely largely on mimicking a particularly hard-to-acquire\nform of demonstrations: those collected on the same robot in the same room with\nthe same objects as the trained policy must handle at test time. In contrast,\nlarge pre-recorded human video datasets demonstrating manipulation skills\nin-the-wild already exist, which contain valuable information for robots. Is it\npossible to distill a repository of useful robotic skill policies out of such\ndata without any additional requirements on robot-specific demonstrations or\nexploration? We present the first such system ZeroMimic, that generates\nimmediately deployable image goal-conditioned skill policies for several common\ncategories of manipulation tasks (opening, closing, pouring, pick&place,\ncutting, and stirring) each capable of acting upon diverse objects and across\ndiverse unseen task setups. ZeroMimic is carefully designed to exploit recent\nadvances in semantic and geometric visual understanding of human videos,\ntogether with modern grasp affordance detectors and imitation policy classes.\nAfter training ZeroMimic on the popular EpicKitchens dataset of ego-centric\nhuman videos, we evaluate its out-of-the-box performance in varied real-world\nand simulated kitchen settings with two different robot embodiments,\ndemonstrating its impressive abilities to handle these varied tasks. To enable\nplug-and-play reuse of ZeroMimic policies on other task setups and robots, we\nrelease software and policy checkpoints of our skill policies.","main_category":"cs.RO","categories":"cs.RO,cs.CV,cs.LG","published":"2025-03-31T09:27:00Z"}
{"aid":"http://arxiv.org/abs/2503.23885v1","title":"Robust Suboptimal Local Basis Function Algorithms for Identification of\n  Nonstationary FIR Systems in Impulsive Noise Environments","summary":"While local basis function (LBF) estimation algorithms, commonly used for\nidentifying/tracking systems with time-varying parameters, demonstrate good\nperformance under the assumption of normally distributed measurement noise, the\nestimation results may significantly deviate from satisfactory when the noise\ndistribution is impulsive in nature, for example, corrupted by outliers. This\npaper introduces a computationally efficient method to make the LBF estimator\nrobust, enhancing its resistance to impulsive noise. First, the choice of basis\nfunctions is optimized based on the knowledge of parameter variation\nstatistics. Then, the parameter tracking algorithm is made robust using the\nsequential data trimming technique. Finally, it is demonstrated that the\nproposed algorithm can undergo online tuning through parallel estimation and\nleave-one-out cross-validation.","main_category":"eess.SP","categories":"eess.SP,cs.SY,eess.SY","published":"2025-03-31T09:37:58Z"}
{"aid":"http://arxiv.org/abs/2503.23888v1","title":"MuseFace: Text-driven Face Editing via Diffusion-based Mask Generation\n  Approach","summary":"Face editing modifies the appearance of face, which plays a key role in\ncustomization and enhancement of personal images. Although much work have\nachieved remarkable success in text-driven face editing, they still face\nsignificant challenges as none of them simultaneously fulfill the\ncharacteristics of diversity, controllability and flexibility. To address this\nchallenge, we propose MuseFace, a text-driven face editing framework, which\nrelies solely on text prompt to enable face editing. Specifically, MuseFace\nintegrates a Text-to-Mask diffusion model and a semantic-aware face editing\nmodel, capable of directly generating fine-grained semantic masks from text and\nperforming face editing. The Text-to-Mask diffusion model provides\n\\textit{diversity} and \\textit{flexibility} to the framework, while the\nsemantic-aware face editing model ensures \\textit{controllability} of the\nframework. Our framework can create fine-grained semantic masks, making precise\nface editing possible, and significantly enhancing the controllability and\nflexibility of face editing models. Extensive experiments demonstrate that\nMuseFace achieves superior high-fidelity performance.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T09:41:09Z"}
{"aid":"http://arxiv.org/abs/2503.23895v1","title":"Better wit than wealth: Dynamic Parametric Retrieval Augmented\n  Generation for Test-time Knowledge Enhancement","summary":"Retrieval-augmented generation (RAG) enhances large language models (LLMs) by\nretrieving relevant documents from external sources and incorporating them into\nthe context. While it improves reliability by providing factual texts, it\nsignificantly increases inference costs as context length grows and introduces\nchallenging issue of RAG hallucination, primarily caused by the lack of\ncorresponding parametric knowledge in LLMs. An efficient solution is to enhance\nthe knowledge of LLMs at test-time. Parametric RAG (PRAG) addresses this by\nembedding document into LLMs parameters to perform test-time knowledge\nenhancement, effectively reducing inference costs through offline training.\nHowever, its high training and storage costs, along with limited generalization\nability, significantly restrict its practical adoption. To address these\nchallenges, we propose Dynamic Parametric RAG (DyPRAG), a novel framework that\nleverages a lightweight parameter translator model to efficiently convert\ndocuments into parametric knowledge. DyPRAG not only reduces inference,\ntraining, and storage costs but also dynamically generates parametric\nknowledge, seamlessly enhancing the knowledge of LLMs and resolving knowledge\nconflicts in a plug-and-play manner at test-time. Extensive experiments on\nmultiple datasets demonstrate the effectiveness and generalization capabilities\nof DyPRAG, offering a powerful and practical RAG paradigm which enables\nsuperior knowledge fusion and mitigates RAG hallucination in real-world\napplications. Our code is available at https://github.com/Trae1ounG/DyPRAG.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-03-31T09:46:35Z"}
{"aid":"http://arxiv.org/abs/2503.23896v1","title":"Feature learning from non-Gaussian inputs: the case of Independent\n  Component Analysis in high dimensions","summary":"Deep neural networks learn structured features from complex, non-Gaussian\ninputs, but the mechanisms behind this process remain poorly understood. Our\nwork is motivated by the observation that the first-layer filters learnt by\ndeep convolutional neural networks from natural images resemble those learnt by\nindependent component analysis (ICA), a simple unsupervised method that seeks\nthe most non-Gaussian projections of its inputs. This similarity suggests that\nICA provides a simple, yet principled model for studying feature learning.\nHere, we leverage this connection to investigate the interplay between data\nstructure and optimisation in feature learning for the most popular ICA\nalgorithm, FastICA, and stochastic gradient descent (SGD), which is used to\ntrain deep networks. We rigorously establish that FastICA requires at least\n$n\\gtrsim d^4$ samples to recover a single non-Gaussian direction from\n$d$-dimensional inputs on a simple synthetic data model. We show that vanilla\nonline SGD outperforms FastICA, and prove that the optimal sample complexity $n\n\\gtrsim d^2$ can be reached by smoothing the loss, albeit in a data-dependent\nway. We finally demonstrate the existence of a search phase for FastICA on\nImageNet, and discuss how the strong non-Gaussianity of said images compensates\nfor the poor sample complexity of FastICA.","main_category":"stat.ML","categories":"stat.ML,cond-mat.dis-nn,cond-mat.stat-mech,cs.LG,math.PR","published":"2025-03-31T09:46:47Z"}
{"aid":"http://arxiv.org/abs/2503.23899v1","title":"Rubrik's Cube: Testing a New Rubric for Evaluating Explanations on the\n  CUBE dataset","summary":"The performance and usability of Large-Language Models (LLMs) are driving\ntheir use in explanation generation tasks. However, despite their widespread\nadoption, LLM explanations have been found to be unreliable, making it\ndifficult for users to distinguish good from bad explanations. To address this\nissue, we present Rubrik's CUBE, an education-inspired rubric and a dataset of\n26k explanations, written and later quality-annotated using the rubric by both\nhumans and six open- and closed-source LLMs. The CUBE dataset focuses on two\nreasoning and two language tasks, providing the necessary diversity for us to\neffectively test our proposed rubric. Using Rubrik, we find that explanations\nare influenced by both task and perceived difficulty. Low quality stems\nprimarily from a lack of conciseness in LLM-generated explanations, rather than\ncohesion and word choice. The full dataset, rubric, and code will be made\navailable upon acceptance.","main_category":"cs.CL","categories":"cs.CL,I.2.7","published":"2025-03-31T09:48:59Z"}
{"aid":"http://arxiv.org/abs/2503.23905v1","title":"Boosting MLLM Reasoning with Text-Debiased Hint-GRPO","summary":"MLLM reasoning has drawn widespread research for its excellent\nproblem-solving capability. Current reasoning methods fall into two types: PRM,\nwhich supervises the intermediate reasoning steps, and ORM, which supervises\nthe final results. Recently, DeepSeek-R1 has challenged the traditional view\nthat PRM outperforms ORM, which demonstrates strong generalization performance\nusing an ORM method (i.e., GRPO). However, current MLLM's GRPO algorithms still\nstruggle to handle challenging and complex multimodal reasoning tasks (e.g.,\nmathematical reasoning). In this work, we reveal two problems that impede the\nperformance of GRPO on the MLLM: Low data utilization and Text-bias. Low data\nutilization refers to that GRPO cannot acquire positive rewards to update the\nMLLM on difficult samples, and text-bias is a phenomenon that the MLLM bypasses\nimage condition and solely relies on text condition for generation after GRPO\ntraining. To tackle these problems, this work proposes Hint-GRPO that improves\ndata utilization by adaptively providing hints for samples of varying\ndifficulty, and text-bias calibration that mitigates text-bias by calibrating\nthe token prediction logits with image condition in test-time. Experiment\nresults on three base MLLMs across eleven datasets demonstrate that our\nproposed methods advance the reasoning capability of original MLLM by a large\nmargin, exhibiting superior performance to existing MLLM reasoning methods. Our\ncode is available at https://github.com/hqhQAQ/Hint-GRPO.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T09:54:55Z"}
{"aid":"http://arxiv.org/abs/2503.23916v1","title":"Deterministic Bottom-Up Fabrication of Plasmonic Nanostructures on\n  Optical Nanofibers via Blurred Electron Beam Deposition","summary":"This study introduces a novel method for the deterministic fabrication of\nmetallic nanostructures with controlled geometry and composition on suspended,\nsingle mode tapered optical nanofibers (TNFs) using a tailored Blurred Electron\nBeam Induced Deposition (BEBID) technique. TNFs, owing to their subwavelength\ndiameters and intense evanescent fields, offer a unique platform for enhanced\nlight matter interactions at the nanoscale. However, their mechanical fragility\nhas thus far hindered the integration of plasmonic structures using\nconventional high energy deposition methods. BEBID addresses this limitation by\ndeliberately defocusing the electron beam to reduce local mechanical stress,\nminimize vibration, and prevent fiber damage during deposition, thereby\nenabling the one-step growth of platinum nanopillars with sub 20 nm spatial\nprecision and high structural fidelity directly on suspended TNFs. The\nfabricated structures were characterized using SEM, EDX, and their optical\nproperties were investigated through broadband scattering spectra and\npolarization resolved measurements, showing strong agreement with Finite\nDifference Time Domain (FDTD) simulations. Numerical modeling further reveals\nthat ordered arrays of nanopillars can shape and direct the scattered field\nalong the fiber axis, enabling directional emission. This work establishes\nBEBID as a versatile bottom up nanofabrication approach for functional photonic\narchitectures on fragile substrates, with direct applications in quantum\nphotonics, nano optics, and on fiber plasmonic sensing.","main_category":"physics.optics","categories":"physics.optics,physics.app-ph","published":"2025-03-31T10:06:58Z"}
{"aid":"http://arxiv.org/abs/2503.23919v1","title":"Production of $K^+K^-$ Pairs Through Decay of $φ$ Meson","summary":"We develop a theoretical framework for the production of $K^+K^-$ pairs\nthrough the decay of $\\phi$ mesons produced from a thermal background, based on\nthe Nambu-Jona-Lasinio (NJL) model. The differential production rate of\n$K^+K^-$ is related to the self-energy of the $\\phi$ meson, incorporating the\ncontributions of the quark loop at leading order and the kaon loop at\nnext-to-leading order in the $1/N_c$ expansion. We numerically evaluate the\ninvariant mass spectrum of the $K^+K^-$ pair both in vacuum and at finite\ntemperature. The inclusion of the kaon loop results in a finite width of the\nspectrum, improving agreement with experimental data. We also investigate the\nspin alignment of the $\\phi$ meson induced by its motion relative to the\nthermal background. In the NJL model with only chiral condensates, we find that\ndeviations from the unpolarized limit of 1/3 are negligible.","main_category":"hep-ph","categories":"hep-ph,hep-th,nucl-th","published":"2025-03-31T10:08:18Z"}
{"aid":"http://arxiv.org/abs/2503.23923v1","title":"What the F*ck Is Artificial General Intelligence?","summary":"Artificial general intelligence (AGI) is an established field of research.\nYet Melanie Mitchell and others have questioned if the term still has meaning.\nAGI has been subject to so much hype and speculation it has become something of\na Rorschach test. Mitchell points out that the debate will only be settled\nthrough long term, scientific investigation. To that end here is a short,\naccessible and provocative overview of AGI. I compare definitions of\nintelligence, settling on intelligence in terms of adaptation and AGI as an\nartificial scientist. Taking my queue from Sutton's Bitter Lesson I describe\ntwo foundational tools used to build adaptive systems: search and\napproximation. I compare pros, cons, hybrids and architectures like o3,\nAlphaGo, AERA, NARS and Hyperon. I then discuss overall meta-approaches to\nmaking systems behave more intelligently. I divide them into scale-maxing,\nsimp-maxing, w-maxing based on the Bitter Lesson, Ockham's and Bennett's\nRazors. These maximise resources, simplicity of form, and the weakness of\nconstraints on functionality. I discuss examples including AIXI, the free\nenergy principle and The Embiggening of language models. I conclude that though\nscale-maxed approximation dominates, AGI will be a fusion of tools and\nmeta-approaches. The Embiggening was enabled by improvements in hardware. Now\nthe bottlenecks are sample and energy efficiency.","main_category":"cs.AI","categories":"cs.AI","published":"2025-03-31T10:15:37Z"}
{"aid":"http://arxiv.org/abs/2503.23925v1","title":"CoMatch: Dynamic Covisibility-Aware Transformer for Bilateral\n  Subpixel-Level Semi-Dense Image Matching","summary":"This prospective study proposes CoMatch, a novel semi-dense image matcher\nwith dynamic covisibility awareness and bilateral subpixel accuracy. Firstly,\nobserving that modeling context interaction over the entire coarse feature map\nelicits highly redundant computation due to the neighboring representation\nsimilarity of tokens, a covisibility-guided token condenser is introduced to\nadaptively aggregate tokens in light of their covisibility scores that are\ndynamically estimated, thereby ensuring computational efficiency while\nimproving the representational capacity of aggregated tokens simultaneously.\nSecondly, considering that feature interaction with massive non-covisible areas\nis distracting, which may degrade feature distinctiveness, a\ncovisibility-assisted attention mechanism is deployed to selectively suppress\nirrelevant message broadcast from non-covisible reduced tokens, resulting in\nrobust and compact attention to relevant rather than all ones. Thirdly, we find\nthat at the fine-level stage, current methods adjust only the target view's\nkeypoints to subpixel level, while those in the source view remain restricted\nat the coarse level and thus not informative enough, detrimental to keypoint\nlocation-sensitive usages. A simple yet potent fine correlation module is\ndeveloped to refine the matching candidates in both source and target views to\nsubpixel level, attaining attractive performance improvement. Thorough\nexperimentation across an array of public benchmarks affirms CoMatch's\npromising accuracy, efficiency, and generalizability.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T10:17:01Z"}
{"aid":"http://arxiv.org/abs/2503.23937v1","title":"Electromagnetic multipole expansions and the logarithmic soft photon\n  theorem","summary":"We study the general structure of the electromagnetic field in the vicinity\nof spatial infinity. Starting from the general solution of the sourced Maxwell\nequations written in terms of multipole moments as obtained by Iyer and Damour,\nwe derive the expansion of the electromagnetic field perturbatively in the\nelectromagnetic coupling. At leading order, where the effect of long-range\nCoulombic interactions between charged particles is neglected, we discover\ninfinite sets of antipodal matching relations satisfied by the electromagnetic\nfield, which extend and sometimes correct previously known relations. At\nnext-to-leading order, electromagnetic tails resulting from these Coulombic\ninteractions appear, which affect the antipodal matching relations beyond those\nequivalent to the leading soft photon theorem. Moreover, new antipodal matching\nrelations arise, which we use to re-derive the classical logarithmic soft\nphoton theorem of Sahoo and Sen. Our analysis largely builds upon that of\nCampiglia and Laddha, although it invalidates the antipodal matching relation\nwhich they originally used in their derivation.","main_category":"hep-th","categories":"hep-th","published":"2025-03-31T10:35:22Z"}
{"aid":"http://arxiv.org/abs/2503.23951v1","title":"JointTuner: Appearance-Motion Adaptive Joint Training for Customized\n  Video Generation","summary":"Recent text-to-video advancements have enabled coherent video synthesis from\nprompts and expanded to fine-grained control over appearance and motion.\nHowever, existing methods either suffer from concept interference due to\nfeature domain mismatch caused by naive decoupled optimizations or exhibit\nappearance contamination induced by spatial feature leakage resulting from the\nentanglement of motion and appearance in reference video reconstructions. In\nthis paper, we propose JointTuner, a novel adaptive joint training framework,\nto alleviate these issues. Specifically, we develop Adaptive LoRA, which\nincorporates a context-aware gating mechanism, and integrate the gated LoRA\ncomponents into the spatial and temporal Transformers within the diffusion\nmodel. These components enable simultaneous optimization of appearance and\nmotion, eliminating concept interference. In addition, we introduce the\nAppearance-independent Temporal Loss, which decouples motion patterns from\nintrinsic appearance in reference video reconstructions through an\nappearance-agnostic noise prediction task. The key innovation lies in adding\nframe-wise offset noise to the ground-truth Gaussian noise, perturbing its\ndistribution, thereby disrupting spatial attributes associated with frames\nwhile preserving temporal coherence. Furthermore, we construct a benchmark\ncomprising 90 appearance-motion customized combinations and 10 multi-type\nautomatic metrics across four dimensions, facilitating a more comprehensive\nevaluation for this customization task. Extensive experiments demonstrate the\nsuperior performance of our method compared to current advanced approaches.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T11:04:07Z"}
{"aid":"http://arxiv.org/abs/2503.23964v1","title":"On Cameron's Greedy Conjecture","summary":"A base for a permutation group $G$ acting on a set $\\Omega$ is a subset\n$\\mathcal{B}$ of $\\Omega$ whose pointwise stabiliser $G_{(\\mathcal{B})}$ is\ntrivial. There is a natural greedy algorithm for constructing a base of\nrelatively small size. We write $\\mathcal{G}(G)$ the maximum size of a base it\nproduces, and $b(G)$ for the size of the smallest base for $G$. In 1999, Peter\nCameron conjectured that there exists an absolute constant $c$ such that every\nfinite primitive group $G$ satisfies $\\mathcal{G}(G)\\leq cb(G)$. We show that\nif $G$ is $\\mathrm{S}_n$ or $\\mathrm{A}_n$ acting primitively then either\nCameron's Greedy Conjecture holds for $G$, or $G$ falls into one class of\npossible exceptions.","main_category":"math.GR","categories":"math.GR,math.CO","published":"2025-03-31T11:27:03Z"}
{"aid":"http://arxiv.org/abs/2503.23966v1","title":"Machine Learning-assisted High-speed Combinatorial Optimization with\n  Ising Machines for Dynamically Changing Problems","summary":"Quantum or quantum-inspired Ising machines have recently shown promise in\nsolving combinatorial optimization problems in a short time. Real-world\napplications, such as time division multiple access (TDMA) scheduling for\nwireless multi-hop networks and financial trading, require solving those\nproblems sequentially where the size and characteristics change dynamically.\nHowever, using Ising machines involves challenges to shorten system-wide\nlatency due to the transfer of large Ising model or the cloud access and to\ndetermine the parameters for each problem. Here we show a combinatorial\noptimization method using embedded Ising machines, which enables solving\ndiverse problems at high speed without runtime parameter tuning. We customize\nthe algorithm and circuit architecture of the simulated bifurcation-based Ising\nmachine to compress the Ising model and accelerate computation and then built a\nmachine learning model to estimate appropriate parameters using extensive\ntraining data. In TDMA scheduling for wireless multi-hop networks, our\ndemonstration has shown that the sophisticated system can adapt to changes in\nthe problem and showed that it has a speed advantage over conventional methods.","main_category":"cs.ET","categories":"cs.ET,cs.LG","published":"2025-03-31T11:31:36Z"}
{"aid":"http://arxiv.org/abs/2503.23974v1","title":"Revealing the Low Temperature Phase of FAPbI$_3$ using Machine-Learned\n  Potential","summary":"FAPbI$_3$ is a material of interest for its potential in solar cell\napplications, driven by its remarkable optoelectronic properties. However, the\nlow-temperature phase of FAPbI$_3$ remains poorly understood, with open\nquestions surrounding its crystal structure, octahedral tilting, and the\narrangement of formamidinium (FA) cations. Using our trained machine-learned\npotential in combination with large-scale molecular dynamics simulations, we\nprovide a detailed investigation of this phase, uncovering its structural\ncharacteristics and dynamical behavior. Our analysis reveals the octahedral\ntilt pattern and sheds light on the rotational dynamics of FA cations in the\nlow temperature phase. Strikingly, we find that the FA cations become frozen in\na metastable configuration, unable to reach the thermodynamic ground state. By\ncomparing our simulated results with experimental nuclear magnetic resonance\n(NMR) and inelastic neutron scattering (INS) spectra, we demonstrate good\nagreement, further validating our findings. This phenomenon mirrors\nexperimental observations and offers a compelling explanation for the\nexperimental challenges in accessing the true ground state. These findings\nprovide critical insights into the fundamental physics of FAPbI$_3$ and its\nlow-temperature behavior, advancing our understanding of this technologically\nimportant material.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-31T11:36:16Z"}
{"aid":"http://arxiv.org/abs/2503.23978v1","title":"Non-Abelian Gauge Enhances Self-Healing for Non-Hermitian Topological\n  Su-Schrieffer-Heeger Chain","summary":"This work introduces and analyzes a non-Hermitian Su-Schrieffer-Heeger (SSH)\nmodel generalized through spin-dependent non-Abelian SU(2) gauge couplings. By\nincorporating SU(2) symmetry transformations that couple explicitly to spin\ndegrees of freedom, our model demonstrates distinct topological properties\noriginating from the interplay between non-Hermiticity and gauge-induced\nspin-orbit coupling. Exact diagonalization and generalized Brillouin zone (GBZ)\nanalyses reveal distinct spectral phases, characterized by complex-energy loops\nunder periodic boundary conditions (PBC) and substantial localization\nindicative of the non-Hermitian skin effect (NHSE) under open boundary\nconditions (OBC). We define a gauge-invariant winding number for non-Hermitian\nchiral symmetry, clarifying the topological transitions. Furthermore, we\nuncover a novel self-healing phenomenon in response to dynamically introduced\nscattering potentials, showing significant robustness enhancement induced by\nappropriate non-Abelian SU(2) couplings. These findings clarify how non-Abelian\ngauge interactions can control spin-dependent localization and dynamical\nstability in non-Hermitian topological systems, guiding the development of\ntunable quantum devices.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.other","published":"2025-03-31T11:41:35Z"}
{"aid":"http://arxiv.org/abs/2503.23991v1","title":"Deviation Between Team-Optimal Solution and Nash Equilibrium in Flow\n  Assignment Problems","summary":"We investigate the relationship between the team-optimal solution and the\nNash equilibrium (NE) to assess the impact of strategy deviation on team\nperformance. As a working use case, we focus on a class of flow assignment\nproblems in which each source node acts as a cooperating decision maker (DM)\nwithin a team that minimizes the team cost based on the team-optimal strategy.\nIn practice, some selfish DMs may prioritize their own marginal cost and\ndeviate from NE strategies, thus potentially degrading the overall performance.\nTo quantify this deviation, we explore the deviation bound between the\nteam-optimal solution and the NE in two specific scenarios: (i) when the\nteam-optimal solution is unique and (ii) when multiple solutions do exist. This\nhelps DMs analyze the factors influencing the deviation and adopting the NE\nstrategy within a tolerable range. Furthermore, in the special case of a\npotential game model, we establish the consistency between the team-optimal\nsolution and the NE. Once the consistency condition is satisfied, the strategy\ndeviation does not alter the total cost, and DMs do not face a strategic\ntrade-off. Finally, we validate our theoretical analysis through some\nsimulation studies.","main_category":"cs.GT","categories":"cs.GT,math.OC","published":"2025-03-31T12:06:09Z"}
{"aid":"http://arxiv.org/abs/2503.23992v1","title":"A cost of capital approach to determining the LGD discount rate","summary":"Loss Given Default (LGD) is a key risk parameter in determining a bank's\nregulatory capital. During LGD-estimation, realised recovery cash flows are to\nbe discounted at an appropriate rate. Regulatory guidance mandates that this\nrate should allow for the time value of money, as well as include a risk\npremium that reflects the \"undiversifiable risk\" within these recoveries.\nHaving extensively reviewed earlier methods of determining this rate, we\npropose a new approach that is inspired by the cost of capital approach from\nthe Solvency II regulatory regime. Our method involves estimating a\nmarket-consistent price for a portfolio of defaulted loans, from which an\nassociated discount rate may be inferred. We apply this method to mortgage and\npersonal loans data from a large South African bank. The results reveal the\nmain drivers of the discount rate to be the mean and variance of these\nrecoveries, as well as the bank's cost of capital in excess of the risk-free\nrate. Our method therefore produces a discount rate that reflects both the\nundiversifiable risk of recovery recoveries and the time value of money,\nthereby satisfying regulatory requirements. This work can subsequently enhance\nthe LGD-component within the modelling of both regulatory and economic capital.","main_category":"q-fin.RM","categories":"q-fin.RM,q-fin.ST","published":"2025-03-31T12:09:21Z"}
{"aid":"http://arxiv.org/abs/2503.24006v1","title":"Comparing representations of long clinical texts for the task of patient\n  note-identification","summary":"In this paper, we address the challenge of patient-note identification, which\ninvolves accurately matching an anonymized clinical note to its corresponding\npatient, represented by a set of related notes. This task has broad\napplications, including duplicate records detection and patient similarity\nanalysis, which require robust patient-level representations. We explore\nvarious embedding methods, including Hierarchical Attention Networks (HAN),\nthree-level Hierarchical Transformer Networks (HTN), LongFormer, and advanced\nBERT-based models, focusing on their ability to process mediumto-long clinical\ntexts effectively. Additionally, we evaluate different pooling strategies\n(mean, max, and mean_max) for aggregating wordlevel embeddings into\npatient-level representations and we examine the impact of sliding windows on\nmodel performance. Our results indicate that BERT-based embeddings outperform\ntraditional and hierarchical models, particularly in processing lengthy\nclinical notes and capturing nuanced patient representations. Among the pooling\nstrategies, mean_max pooling consistently yields the best results, highlighting\nits ability to capture critical features from clinical notes. Furthermore, the\nreproduction of our results on both MIMIC dataset and Necker hospital data\nwarehouse illustrates the generalizability of these approaches to real-world\napplications, emphasizing the importance of both embedding methods and\naggregation strategies in optimizing patient-note identification and enhancing\npatient-level modeling.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T12:31:44Z"}
{"aid":"http://arxiv.org/abs/2503.24008v1","title":"H2VU-Benchmark: A Comprehensive Benchmark for Hierarchical Holistic\n  Video Understanding","summary":"With the rapid development of multimodal models, the demand for assessing\nvideo understanding capabilities has been steadily increasing. However,\nexisting benchmarks for evaluating video understanding exhibit significant\nlimitations in coverage, task diversity, and scene adaptability. These\nshortcomings hinder the accurate assessment of models' comprehensive video\nunderstanding capabilities. To tackle this challenge, we propose a hierarchical\nand holistic video understanding (H2VU) benchmark designed to evaluate both\ngeneral video and online streaming video comprehension. This benchmark\ncontributes three key features:\n  Extended video duration: Spanning videos from brief 3-second clips to\ncomprehensive 1.5-hour recordings, thereby bridging the temporal gaps found in\ncurrent benchmarks. Comprehensive assessment tasks: Beyond traditional\nperceptual and reasoning tasks, we have introduced modules for\ncountercommonsense comprehension and trajectory state tracking. These additions\ntest the models' deep understanding capabilities beyond mere prior knowledge.\nEnriched video data: To keep pace with the rapid evolution of current AI\nagents, we have expanded first-person streaming video datasets. This expansion\nallows for the exploration of multimodal models' performance in understanding\nstreaming videos from a first-person perspective. Extensive results from H2VU\nreveal that existing multimodal large language models (MLLMs) possess\nsubstantial potential for improvement in our newly proposed evaluation tasks.\nWe expect that H2VU will facilitate advancements in video understanding\nresearch by offering a comprehensive and in-depth analysis of MLLMs.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T12:32:51Z"}
{"aid":"http://arxiv.org/abs/2503.24009v1","title":"Learning 3D-Gaussian Simulators from RGB Videos","summary":"Learning physics simulations from video data requires maintaining spatial and\ntemporal consistency, a challenge often addressed with strong inductive biases\nor ground-truth 3D information -- limiting scalability and generalization. We\nintroduce 3DGSim, a 3D physics simulator that learns object dynamics end-to-end\nfrom multi-view RGB videos. It encodes images into a 3D Gaussian particle\nrepresentation, propagates dynamics via a transformer, and renders frames using\n3D Gaussian splatting. By jointly training inverse rendering with a dynamics\ntransformer using a temporal encoding and merging layer, 3DGSimembeds physical\nproperties into point-wise latent vectors without enforcing explicit\nconnectivity constraints. This enables the model to capture diverse physical\nbehaviors, from rigid to elastic and cloth-like interactions, along with\nrealistic lighting effects that also generalize to unseen multi-body\ninteractions and novel scene edits.","main_category":"cs.GR","categories":"cs.GR,cs.AI,cs.CV,cs.LG,cs.RO","published":"2025-03-31T12:33:59Z"}
{"aid":"http://arxiv.org/abs/2503.24013v1","title":"You Cannot Feed Two Birds with One Score: the Accuracy-Naturalness\n  Tradeoff in Translation","summary":"The goal of translation, be it by human or by machine, is, given some text in\na source language, to produce text in a target language that simultaneously 1)\npreserves the meaning of the source text and 2) achieves natural expression in\nthe target language. However, researchers in the machine translation community\nusually assess translations using a single score intended to capture semantic\naccuracy and the naturalness of the output simultaneously. In this paper, we\nbuild on recent advances in information theory to mathematically prove and\nempirically demonstrate that such single-score summaries do not and cannot give\nthe complete picture of a system's true performance. Concretely, we prove that\na tradeoff exists between accuracy and naturalness and demonstrate it by\nevaluating the submissions to the WMT24 shared task. Our findings help explain\nwell-known empirical phenomena, such as the observation that optimizing\ntranslation systems for a specific accuracy metric (like BLEU) initially\nimproves the system's naturalness, while ``overfitting'' the system to the\nmetric can significantly degrade its naturalness. Thus, we advocate for a\nchange in how translations are evaluated: rather than comparing systems using a\nsingle number, they should be compared on an accuracy-naturalness plane.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T12:39:51Z"}
{"aid":"http://arxiv.org/abs/2503.24023v1","title":"Coherent microwave control of coupled electron-muon centers","summary":"Coherent control by means of tailored excitation is a key to versatile\nexperimental schemes for spectroscopic investigation and technological\nutilization of quantum systems. Here we study a quantum system which consists\nof a coupled electron-moun spin state, i.e., muonium, a light isotope of\nhydrogen. We demonstrate the most fundamental coherent control techniques by\nmicrowave excitation of spin transitions, namely driven Rabi oscillations and\nRamsey fringes upon free evolution. Unprecedented performance is achieved by\nthe microwave hardware devised for these experiments, which enables coherent\nspin manipulation of individual, isolated, muonium centers. For muonium formed\nin SiO$_2$ with strong electron-muon hyperfine interaction, a virtually\nundamped free precession signal is observed up to a 3.5 $\\mu$s time window. For\nmuonium formed in Si with weak and anisotropic hyperfine interaction, a strong\ndrive at the multi-quantum transition decouples the muonium center from its\nmagnetic environment formed by the bath of $^{29}$Si nuclear spins at natural\nabundance. We expect that these capabilities will provide a powerful tool to\ninvestigate the effect of the environment on isolated coupled spins, uncover\nthe details of coupled electron-muon systems in matter and validate quantum\nelectrodynamics in the context of muonium spectroscopy.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T12:50:05Z"}
{"aid":"http://arxiv.org/abs/2503.24029v1","title":"Global Well-Posedness of the 3D Navier-Stokes Equations under\n  Multi-Level Logarithmically Improved Criteria","summary":"This paper extends our previous results on logarithmically improved\nregularity criteria for the three-dimensional Navier-Stokes equations by\nestablishing a comprehensive framework of multi-level logarithmic improvements.\nWe prove that if the initial data $u_0 \\in L^2(\\mathbb{R}^3)$ satisfies a\nnested logarithmically weakened condition\n$\\|(-\\Delta)^{s/2}u_0\\|_{L^q(\\mathbb{R}^3)} \\leq \\frac{C_0}{\\prod_{j=1}^{n} (1\n+ L_j(\\|u_0\\|_{\\dot{H}^s}))^{\\delta_j}}$ for some $s \\in (1/2, 1)$, where $L_j$\nrepresents $j$-fold nested logarithms, then the corresponding solution exists\nglobally in time and is unique. The proof introduces a novel sequence of\nincreasingly precise commutator estimates incorporating multiple layers of\nlogarithmic corrections. We establish the existence of a critical threshold\nfunction $\\Phi(s,q,\\{\\delta_j\\}_{j=1}^n)$ that completely characterizes the\nboundary between global regularity and potential singularity formation, with\nexplicit asymptotics as $s$ approaches the critical value $1/2$. This paper\nfurther provides a rigorous geometric characterization of potential singular\nstructures through refined multi-fractal analysis, showing that any singular\nset must have Hausdorff dimension bounded by $1 - \\sum_{j=1}^n\n\\frac{\\delta_j}{1+\\delta_j} \\cdot \\frac{1}{j+1}$. Our results constitute a\nsignificant advancement toward resolving the global regularity question for the\nNavier-Stokes equations, as we demonstrate that with properly calibrated\nsequences of nested logarithmic improvements, the gap to the critical case can\nbe systematically reduced.","main_category":"math.AP","categories":"math.AP","published":"2025-03-31T12:55:30Z"}
{"aid":"http://arxiv.org/abs/2503.24032v1","title":"BBoxCut: A Targeted Data Augmentation Technique for Enhancing Wheat Head\n  Detection Under Occlusions","summary":"Wheat plays a critical role in global food security, making it one of the\nmost extensively studied crops. Accurate identification and measurement of key\ncharacteristics of wheat heads are essential for breeders to select varieties\nfor cross-breeding, with the goal of developing nutrient-dense, resilient, and\nsustainable cultivars. Traditionally, these measurements are performed\nmanually, which is both time-consuming and inefficient. Advances in digital\ntechnologies have paved the way for automating this process. However, field\nconditions pose significant challenges, such as occlusions of leaves,\noverlapping wheat heads, varying lighting conditions, and motion blur. In this\npaper, we propose a novel data augmentation technique, BBoxCut, which uses\nrandom localized masking to simulate occlusions caused by leaves and\nneighboring wheat heads. We evaluated our approach using three state-of-the-art\nobject detectors and observed mean average precision (mAP) gains of 2.76, 3.26,\nand 1.9 for Faster R-CNN, FCOS, and DETR, respectively. Our augmentation\ntechnique led to significant improvements both qualitatively and\nquantitatively. In particular, the improvements were particularly evident in\nscenarios involving occluded wheat heads, demonstrating the robustness of our\nmethod in challenging field conditions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T12:59:02Z"}
{"aid":"http://arxiv.org/abs/2503.24033v1","title":"Independence of $\\ell$","summary":"We prove independence of $\\ell$ for Betti numbers as well as for\ncharacteristic polynomials of motivically defined endomorphisms of $\\ell$-adic\ncohomology. This long standing problem is solved through the construction of\nnew comparison isomorphisms relating $\\ell$-adic cohomology of a separated\nscheme of finite type over an algebraically closed field of positive\ncharacteristic with its rigid cohomology. Taking advantage of the description\nof categories of $\\ell$-adic sheaves of geometric origin as categories of\nmodules over $\\ell$-adic cohomology in the stable category of motivic sheaves,\nthese independence of $\\ell$-results are promoted to independence of $\\ell$ of\nsuitable categories of $\\ell$-adic sheaves themselves.","main_category":"math.AG","categories":"math.AG,math.KT,math.NT","published":"2025-03-31T12:59:51Z"}
{"aid":"http://arxiv.org/abs/2503.24046v1","title":"Contrasting exchange-field and spin-transfer torque driving mechanisms\n  in all-electric electron spin resonance","summary":"Understanding the coherent properties of electron spins driven by electric\nfields is crucial for their potential application in quantum-coherent\nnanoscience. In this work, we address two distinct driving mechanisms in\nelectric-field driven electron-spin resonance as implemented in scanning\ntunneling spectroscopy. We study the origin of the driving field using a single\norbital Anderson impurity, connected to polarized leads and biased by a voltage\nmodulated on resonance with a spin transition. By mapping the quantum master\nequation into a system of equations for the impurity spin, we identify two\ndistinct driving mechanisms. Below the charging thresholds of the impurity,\nelectron spin resonance is dominated by a magnetically exchange-driven\nmechanism or field-like torque. Conversely, above the charging threshold\nspin-transfer torque caused by the spin-polarized current through the impurity\ndrives the spin transition. Only the first mechanism enables coherent quantum\nspin control, while the second one leads to fast decoherence and spin\naccumulation towards a non-equilibrium steady-state. The electron spin\nresonance signals and spin dynamics vary significantly depending on which\ndriving mechanism dominates, highlighting the potential for optimizing\nquantum-coherent control in electrically driven quantum systems.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,quant-ph","published":"2025-03-31T13:10:22Z"}
{"aid":"http://arxiv.org/abs/2503.24048v1","title":"Surge sourcing via hybrid supply in a sharing economy: a\n  resource-efficient, progressive and sustainable way to satisfy surge demand","summary":"We propose a surge sourcing approach to address occasional synchronous high\ndemand (surge demand) in sharing economy systems, providing a\nsocio-economically progressive alternative to surge pricing. Instead of\nsuppressing demand among disadvantaged consumers, our scheme increases supply\nby involving privileged consumer-providers (prosumers) who under-utilize their\nresources. This hybrid supply approach maintains high quality-of-service (QoS)\nfor both consumers and prosumers in both normal and surge demand situations\nwithout surge pricing. To ensure prosumer QoS, we reserve a small portion of\nthe primary supply to meet their needs if their resources become unavailable\nduring surge periods. As the probability of such events is low compared to that\nof the surge demand itself, the reserved resources required are minimal. The\nresulting scheme is resource-efficient, socially progressive, and sustainable,\nexploiting under-used resources. We illustrate our scheme through two\napplications: high-range car sharing for owners of small EVs, and shared\ncharging points for EV drivers.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-03-31T13:12:03Z"}
{"aid":"http://arxiv.org/abs/2503.24057v1","title":"AMMSM: Adaptive Motion Magnification and Sparse Mamba for\n  Micro-Expression Recognition","summary":"Micro-expressions are typically regarded as unconscious manifestations of a\nperson's genuine emotions. However, their short duration and subtle signals\npose significant challenges for downstream recognition. We propose a multi-task\nlearning framework named the Adaptive Motion Magnification and Sparse Mamba\n(AMMSM) to address this. This framework aims to enhance the accurate capture of\nmicro-expressions through self-supervised subtle motion magnification, while\nthe sparse spatial selection Mamba architecture combines sparse activation with\nthe advanced Visual Mamba model to model key motion regions and their valuable\nrepresentations more effectively. Additionally, we employ evolutionary search\nto optimize the magnification factor and the sparsity ratios of spatial\nselection, followed by fine-tuning to improve performance further. Extensive\nexperiments on two standard datasets demonstrate that the proposed AMMSM\nachieves state-of-the-art (SOTA) accuracy and robustness.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T13:17:43Z"}
{"aid":"http://arxiv.org/abs/2503.24062v1","title":"Artificial Conversations, Real Results: Fostering Language Detection\n  with Synthetic Data","summary":"Collecting high-quality training data is essential for fine-tuning Large\nLanguage Models (LLMs). However, acquiring such data is often costly and\ntime-consuming, especially for non-English languages such as Italian. Recently,\nresearchers have begun to explore the use of LLMs to generate synthetic\ndatasets as a viable alternative. This study proposes a pipeline for generating\nsynthetic data and a comprehensive approach for investigating the factors that\ninfluence the validity of synthetic data generated by LLMs by examining how\nmodel performance is affected by metrics such as prompt strategy, text length\nand target position in a specific task, i.e. inclusive language detection in\nItalian job advertisements. Our results show that, in most cases and across\ndifferent metrics, the fine-tuned models trained on synthetic data consistently\noutperformed other models on both real and synthetic test datasets. The study\ndiscusses the practical implications and limitations of using synthetic data\nfor language detection tasks with LLMs.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-03-31T13:22:34Z"}
{"aid":"http://arxiv.org/abs/2503.24065v1","title":"COSMO: Combination of Selective Memorization for Low-cost\n  Vision-and-Language Navigation","summary":"Vision-and-Language Navigation (VLN) tasks have gained prominence within\nartificial intelligence research due to their potential application in fields\nlike home assistants. Many contemporary VLN approaches, while based on\ntransformer architectures, have increasingly incorporated additional components\nsuch as external knowledge bases or map information to enhance performance.\nThese additions, while boosting performance, also lead to larger models and\nincreased computational costs. In this paper, to achieve both high performance\nand low computational costs, we propose a novel architecture with the\nCOmbination of Selective MemOrization (COSMO). Specifically, COSMO integrates\nstate-space modules and transformer modules, and incorporates two\nVLN-customized selective state space modules: the Round Selective Scan (RSS)\nand the Cross-modal Selective State Space Module (CS3). RSS facilitates\ncomprehensive inter-modal interactions within a single scan, while the CS3\nmodule adapts the selective state space module into a dual-stream architecture,\nthereby enhancing the acquisition of cross-modal interactions. Experimental\nvalidations on three mainstream VLN benchmarks, REVERIE, R2R, and R2R-CE, not\nonly demonstrate competitive navigation performance of our model but also show\na significant reduction in computational costs.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-03-31T13:24:10Z"}
{"aid":"http://arxiv.org/abs/2503.24070v1","title":"HACTS: a Human-As-Copilot Teleoperation System for Robot Learning","summary":"Teleoperation is essential for autonomous robot learning, especially in\nmanipulation tasks that require human demonstrations or corrections. However,\nmost existing systems only offer unilateral robot control and lack the ability\nto synchronize the robot's status with the teleoperation hardware, preventing\nreal-time, flexible intervention. In this work, we introduce HACTS\n(Human-As-Copilot Teleoperation System), a novel system that establishes\nbilateral, real-time joint synchronization between a robot arm and\nteleoperation hardware. This simple yet effective feedback mechanism, akin to a\nsteering wheel in autonomous vehicles, enables the human copilot to intervene\nseamlessly while collecting action-correction data for future learning.\nImplemented using 3D-printed components and low-cost, off-the-shelf motors,\nHACTS is both accessible and scalable. Our experiments show that HACTS\nsignificantly enhances performance in imitation learning (IL) and reinforcement\nlearning (RL) tasks, boosting IL recovery capabilities and data efficiency, and\nfacilitating human-in-the-loop RL. HACTS paves the way for more effective and\ninteractive human-robot collaboration and data-collection, advancing the\ncapabilities of robot manipulation.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-03-31T13:28:13Z"}
{"aid":"http://arxiv.org/abs/2503.24071v1","title":"From Colors to Classes: Emergence of Concepts in Vision Transformers","summary":"Vision Transformers (ViTs) are increasingly utilized in various computer\nvision tasks due to their powerful representation capabilities. However, it\nremains understudied how ViTs process information layer by layer. Numerous\nstudies have shown that convolutional neural networks (CNNs) extract features\nof increasing complexity throughout their layers, which is crucial for tasks\nlike domain adaptation and transfer learning. ViTs, lacking the same inductive\nbiases as CNNs, can potentially learn global dependencies from the first layers\ndue to their attention mechanisms. Given the increasing importance of ViTs in\ncomputer vision, there is a need to improve the layer-wise understanding of\nViTs. In this work, we present a novel, layer-wise analysis of concepts encoded\nin state-of-the-art ViTs using neuron labeling. Our findings reveal that ViTs\nencode concepts with increasing complexity throughout the network. Early layers\nprimarily encode basic features such as colors and textures, while later layers\nrepresent more specific classes, including objects and animals. As the\ncomplexity of encoded concepts increases, the number of concepts represented in\neach layer also rises, reflecting a more diverse and specific set of features.\nAdditionally, different pretraining strategies influence the quantity and\ncategory of encoded concepts, with finetuning to specific downstream tasks\ngenerally reducing the number of encoded concepts and shifting the concepts to\nmore relevant categories.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-03-31T13:28:43Z"}
{"aid":"http://arxiv.org/abs/2503.24073v1","title":"Krylov complexity in quantum many-body scars of spin-1 models","summary":"Weak ergodicity breaking, particularly through quantum many-body scars\n(QMBS), has become a significant focus in many-body physics. Krylov state\ncomplexity quantifies the spread of quantum states within the Krylov basis and\nserves as a powerful diagnostic for analyzing nonergodic dynamics. In this\nwork, we study spin-one XXZ magnets and reveal nonergodic behavior tied to\nQMBS. For the XY model, the nematic N\\'eel state exhibits periodic revivals in\nKrylov complexity. In the generic XXZ model, we identify spin helix states as\nweakly ergodicity-breaking states, characterized by low entanglement and\nnonthermal dynamics. Across different scenarios, the Lanczos coefficients for\nscarred states display an elliptical pattern, reflecting a hidden SU(2) algebra\nthat enables analytical results for Krylov complexity and fidelity. These\nfindings, which exemplify the rare capability to characterize QMBS\nanalytically, are feasible with current experimental techniques and offer deep\ninsights into the nonergodic dynamics of interacting quantum systems.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-03-31T13:29:45Z"}
{"aid":"http://arxiv.org/abs/2503.24074v1","title":"Physics-informed neural networks for hidden boundary detection and flow\n  field reconstruction","summary":"Simultaneously detecting hidden solid boundaries and reconstructing flow\nfields from sparse observations poses a significant inverse challenge in fluid\nmechanics. This study presents a physics-informed neural network (PINN)\nframework designed to infer the presence, shape, and motion of static or moving\nsolid boundaries within a flow field. By integrating a body fraction parameter\ninto the governing equations, the model enforces no-slip/no-penetration\nboundary conditions in solid regions while preserving conservation laws of\nfluid dynamics. Using partial flow field data, the method simultaneously\nreconstructs the unknown flow field and infers the body fraction distribution,\nthereby revealing solid boundaries. The framework is validated across diverse\nscenarios, including incompressible Navier-Stokes and compressible Euler flows,\nsuch as steady flow past a fixed cylinder, an inline oscillating cylinder, and\nsubsonic flow over an airfoil. The results demonstrate accurate detection of\nhidden boundaries, reconstruction of missing flow data, and estimation of\ntrajectories and velocities of a moving body. Further analysis examines the\neffects of data sparsity, velocity-only measurements, and noise on inference\naccuracy. The proposed method exhibits robustness and versatility, highlighting\nits potential for applications when only limited experimental or numerical data\nare available.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cs.LG,physics.comp-ph","published":"2025-03-31T13:30:46Z"}
{"aid":"http://arxiv.org/abs/2503.24097v1","title":"Systematic Search for FFPs in KMTNet Full-Frame Images. I. Photometry\n  Pipeline","summary":"To exhume the buried signatures of free-floating planets (FFPs) with small\nangular Einstein radius $\\theta_\\mathrm{E}$, we build a new full-frame\ndifference image for the Korean Microlensing Telescope Network (KMTNet) survey\nbased on the newly optimized pySIS package. We introduce the detailed processes\nof the new pipeline, including frame registration, difference image analysis,\nand light curve extraction. To test this pipeline, we extract the light curves\nfor 483,068 stars with $I \\lesssim 17$ and conduct a model-independent search\nfor microlensing events. The search finds 36 microlensing events, including\nfive new events and six events discovered by other collaborations but missed by\nprevious KMTNet searches. We find that the light curves from the new pipeline\nare precise enough to be sensitive to FFPs with $\\theta_\\mathrm{E} \\sim\n1~\\mu$as. Using the new pipeline, a complete FFP search on the eight-year\nKMTNet images can be finished within six months and then yield the FFP mass\nfunction. The new pipeline can be used for a new KMTNet AlertFinder system,\nwith significantly reduced false positives.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM,astro-ph.SR","published":"2025-03-31T13:50:38Z"}
{"aid":"http://arxiv.org/abs/2503.24102v1","title":"Is LLM the Silver Bullet to Low-Resource Languages Machine Translation?","summary":"Low-Resource Languages (LRLs) present significant challenges in natural\nlanguage processing due to their limited linguistic resources and\nunderrepresentation in standard datasets. While recent advancements in Large\nLanguage Models (LLMs) and Neural Machine Translation (NMT) have substantially\nimproved translation capabilities for high-resource languages, performance\ndisparities persist for LRLs, particularly impacting privacy-sensitive and\nresource-constrained scenarios. This paper systematically evaluates the\nlimitations of current LLMs across 200 languages using benchmarks such as\nFLORES-200. We also explore alternative data sources, including news articles\nand bilingual dictionaries, and demonstrate how knowledge distillation from\nlarge pre-trained models can significantly improve smaller LRL translations.\nAdditionally, we investigate various fine-tuning strategies, revealing that\nincremental enhancements markedly reduce performance gaps on smaller LLMs.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T13:56:03Z"}
{"aid":"http://arxiv.org/abs/2503.24111v1","title":"Inductive Graph Representation Learning with Quantum Graph Neural\n  Networks","summary":"Quantum Graph Neural Networks (QGNNs) present a promising approach for\ncombining quantum computing with graph-structured data processing. While\nclassical Graph Neural Networks (GNNs) are renowned for their scalability and\nrobustness, existing QGNNs often lack flexibility due to graph-specific quantum\ncircuit designs, limiting their applicability to a narrower range of\ngraph-structured problems, falling short of real-world scenarios. To address\nthese limitations, we propose a versatile QGNN framework inspired by the\nclassical GraphSAGE approach, utilizing quantum models as aggregators. In this\nwork, we integrate established techniques for inductive representation learning\non graphs with parametrized quantum convolutional and pooling layers,\neffectively bridging classical and quantum paradigms. The convolutional layer\nis flexible, enabling tailored designs for specific problems. Benchmarked on a\nnode regression task with the QM9 dataset, we demonstrate that our framework\nsuccessfully models a non-trivial molecular dataset, achieving performance\ncomparable to classical GNNs. In particular, we show that our quantum approach\nexhibits robust generalization across molecules with varying numbers of atoms\nwithout requiring circuit modifications, slightly outperforming classical GNNs.\nFurthermore, we numerically investigate the scalability of the QGNN framework.\nSpecifically, we demonstrate the absence of barren plateaus in our architecture\nas the number of qubits increases, suggesting that the proposed quantum model\ncan be extended to handle larger and more complex graph-based problems\neffectively.","main_category":"quant-ph","categories":"quant-ph,cs.LG","published":"2025-03-31T14:04:08Z"}
{"aid":"http://arxiv.org/abs/2503.24118v1","title":"Experimental and theoretical research of photoneutron reactions in the\n  181Ta nucleus","summary":"Bremsstrahlung fluxes for irradiating tantalum samples were formed by\nirradiating a tungsten converter with an electron beam with energy up to 130\nMeV. The relative yields and flux-averaged cross-sections of multinucleon\nphotonuclear reactions with the emission of up to 9 neutrons in 181Ta nuclei\nwere determined. Monte Carlo simulations to study the yields of photonuclear\nreactions were performed using Geant4 and TALYS-2.0 codes. The obtained\nexperimental results were compared with the available literature data and\ncalculated results. The comparison showed that the values of the relative\nreaction yield and the flux-averaged cross-section coincide with the literature\ndata, taking into account the different geometry of the experiments. The\ncalculated results coincide with the experimental ones only for reactions with\nthe emission of up to 5 neutrons from the nucleus.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-03-31T14:07:31Z"}
{"aid":"http://arxiv.org/abs/2503.24129v1","title":"It's a (Blind) Match! Towards Vision-Language Correspondence without\n  Parallel Data","summary":"The platonic representation hypothesis suggests that vision and language\nembeddings become more homogeneous as model and dataset sizes increase. In\nparticular, pairwise distances within each modality become more similar. This\nsuggests that as foundation models mature, it may become possible to match\nvision and language embeddings in a fully unsupervised fashion, i.e. without\nparallel data. We present the first feasibility study, and investigate\nconformity of existing vision and language foundation models in the context of\nunsupervised, or \"blind\", matching. First, we formulate unsupervised matching\nas a quadratic assignment problem and introduce a novel heuristic that\noutperforms previous solvers. We also develop a technique to find optimal\nmatching problems, for which a non-trivial match is very likely. Second, we\nconduct an extensive study deploying a range of vision and language models on\nfour datasets. Our analysis reveals that for many problem instances, vision and\nlanguage representations can be indeed matched without supervision. This\nfinding opens up the exciting possibility of embedding semantic knowledge into\nother modalities virtually annotation-free. As a proof of concept, we showcase\nan unsupervised classifier, which achieves non-trivial classification accuracy\nwithout any image-text annotation.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-03-31T14:14:25Z"}
{"aid":"http://arxiv.org/abs/2503.24135v1","title":"PixelCAM: Pixel Class Activation Mapping for Histology Image\n  Classification and ROI Localization","summary":"Weakly supervised object localization (WSOL) methods allow training models to\nclassify images and localize ROIs. WSOL only requires low-cost image-class\nannotations yet provides a visually interpretable classifier, which is\nimportant in histology image analysis. Standard WSOL methods rely on class\nactivation mapping (CAM) methods to produce spatial localization maps according\nto a single- or two-step strategy. While both strategies have made significant\nprogress, they still face several limitations with histology images.\nSingle-step methods can easily result in under- or over-activation due to the\nlimited visual ROI saliency in histology images and the limited localization\ncues. They also face the well-known issue of asynchronous convergence between\nclassification and localization tasks. The two-step approach is sub-optimal\nbecause it is tied to a frozen classifier, limiting the capacity for\nlocalization. Moreover, these methods also struggle when applied to\nout-of-distribution (OOD) datasets. In this paper, a multi-task approach for\nWSOL is introduced for simultaneous training of both tasks to address the\nasynchronous convergence problem. In particular, localization is performed in\nthe pixel-feature space of an image encoder that is shared with classification.\nThis allows learning discriminant features and accurate delineation of\nforeground/background regions to support ROI localization and image\nclassification. We propose PixelCAM, a cost-effective foreground/background\npixel-wise classifier in the pixel-feature space that allows for spatial object\nlocalization. PixelCAM is trained using pixel pseudo-labels collected from a\npretrained WSOL model. Both image and pixel-wise classifiers are trained\nsimultaneously using standard gradient descent. In addition, our pixel\nclassifier can easily be integrated into CNN- and transformer-based\narchitectures without any modifications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T14:18:01Z"}
{"aid":"http://arxiv.org/abs/2503.24147v1","title":"Net 3.2 Tbps 225 Gbaud PAM4 O-Band IM/DD 2 km Transmission Using FR8 and\n  DR8 with a CMOS 3 nm SerDes and TFLN Modulators","summary":"We report the first 3.2 and 4.2 Tbps (8 x 225Gbaud PAM4-8), IM/DD\ntransmission system using FR8 and DR8 configurations with TFLN modulators\ndriven by a 3nm SerDes under the HD-FEC threshold.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T14:33:17Z"}
{"aid":"http://arxiv.org/abs/2503.24150v1","title":"Learning a Canonical Basis of Human Preferences from Binary Ratings","summary":"Recent advances in generative AI have been driven by alignment techniques\nsuch as reinforcement learning from human feedback (RLHF). RLHF and related\ntechniques typically involve constructing a dataset of binary or ranked choice\nhuman preferences and subsequently fine-tuning models to align with these\npreferences. This paper shifts the focus to understanding the preferences\nencoded in such datasets and identifying common human preferences. We find that\na small subset of 21 preference categories (selected from a set of nearly 5,000\ndistinct preferences) captures >89% of preference variation across individuals.\nThis small set of preferences is analogous to a canonical basis of human\npreferences, similar to established findings that characterize human variation\nin psychology or facial recognition studies. Through both synthetic and\nempirical evaluations, we confirm that our low-rank, canonical set of human\npreferences generalizes across the entire dataset and within specific topics.\nWe further demonstrate our preference basis' utility in model evaluation, where\nour preference categories offer deeper insights into model alignment, and in\nmodel training, where we show that fine-tuning on preference-defined subsets\nsuccessfully aligns the model accordingly.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.HC","published":"2025-03-31T14:35:48Z"}
{"aid":"http://arxiv.org/abs/2503.24152v1","title":"Quantifying Grid-Forming Behavior: Bridging Device-level Dynamics and\n  System-Level Stability","summary":"Grid-Forming (GFM) technology is considered a promising solution to build\npower electronics-dominated power systems. However, the impact of GFM\nconverters on the system stability is still unquantified, creating a gap\nbetween the system- and device-level perspectives. To fill this gap, at the\ndevice-level, we propose a Forming Index to quantify a converter's response to\ngrid voltage variations, providing a characterization of its GFM behavior. At\nthe system-level, a quantitative notion of System Strength is introduced to\ncapture the fundamental requirements for power system formation. Finally, we\nestablish the alignment between device- and system-level metrics by\ndemonstrating that GFM converters provably enhance system strength.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-03-31T14:37:51Z"}
{"aid":"http://arxiv.org/abs/2503.24167v1","title":"Relative solidity for biexact groups in measure equivalence","summary":"We demonstrate a relative solidity property for the product of a nonamenable\nbiexact group with an arbitrary infinite group in the measure equivalence\nsetting. Among other applications, we obtain the following unique product\ndecomposition for products of nonamenable biexact groups, strengthening\n\\cite{Sa09}: for any nonamenable biexact groups $\\Gamma_1,\\cdots, \\Gamma_n$, if\na product group $\\Lambda_1\\times \\Lambda_2$ is measure equivalent to\n$\\times_{k=1}^n\\Gamma_k$, then there exists a partition $T_1\\sqcup\nT_2=\\{1,\\dots, n\\}$ such that $\\Lambda_i$ is measure equivalent to\n$\\times_{k\\in T_i}\\Gamma_k$ for $i=1,2$.","main_category":"math.OA","categories":"math.OA,math.GR","published":"2025-03-31T14:48:48Z"}
{"aid":"http://arxiv.org/abs/2503.24168v1","title":"The Compact Linear e$^+$e$^-$ Collider (CLIC)","summary":"The Compact Linear Collider (CLIC) is a TeV-scale high-luminosity linear\ne$^+$e$^-$ collider studied by the international CLIC and CLICdp\ncollaborations. CLIC uses a two-beam acceleration scheme, in which\nnormal-conducting high-gradient 12 GHz accelerating structures are powered via\na high-current drive beam. CLIC is foreseen to be built and operated in stages.\nThe initial 380 GeV stage, with a site length of 11 km, optimally combines the\nexploration of Higgs and top-quark physics, including a top threshold scan near\n350 GeV. A higher-energy stage, still using the initial single drive-beam\ncomplex, can be optimised for any energy up to 2 TeV. Parameters are presented\nin detail for a 1.5 TeV stage, with a site length of 29 km. Since the 2018\nESPPU reporting, significant effort was invested in CLIC accelerator\noptimisation, technology developments and system tests, including collaboration\nwith new-generation light sources and free-electron lasers. CLIC implementation\naspects at CERN have covered detailed studies of civil engineering, electrical\nnetworks, cooling and ventilation, scheduling, and costing. The CLIC baseline\nat 380 GeV is now 100 Hz operation, with a luminosity of 4.5$\\times\n10^{34}$\\,cm$^{-2}$s$^{-1}$ and a power consumption of 166 MW. Compared to the\n2018 design, this gives three times higher luminosity-per-power. The new\nbaseline has two beam-delivery systems, allowing for two detectors operating in\nparallel. The cost estimate of the 380 GeV baseline is approximately 7.17\nbillion CHF. The construction of the first CLIC energy stage could start as\nearly as 2033 with first beams available by 2041. This report summarises the\nCLIC project, its implementation and running scenarios, with emphasis on new\ndevelopments and recent progress. It concludes with an update on the CLIC\ndetector studies and on the physics potential in light of the improved\naccelerator performance.","main_category":"physics.acc-ph","categories":"physics.acc-ph","published":"2025-03-31T14:48:58Z"}
{"aid":"http://arxiv.org/abs/2503.24180v1","title":"Navi-plus: Managing Ambiguous GUI Navigation Tasks with Follow-up","summary":"Graphical user interfaces (GUI) automation agents are emerging as powerful\ntools, enabling humans to accomplish increasingly complex tasks on smart\ndevices. However, users often inadvertently omit key information when conveying\ntasks, which hinders agent performance in the current agent paradigm that does\nnot support immediate user intervention. To address this issue, we introduce a\n$\\textbf{Self-Correction GUI Navigation}$ task that incorporates interactive\ninformation completion capabilities within GUI agents. We developed the\n$\\textbf{Navi-plus}$ dataset with GUI follow-up question-answer pairs,\nalongside a $\\textbf{Dual-Stream Trajectory Evaluation}$ method to benchmark\nthis new capability. Our results show that agents equipped with the ability to\nask GUI follow-up questions can fully recover their performance when faced with\nambiguous user tasks.","main_category":"cs.CV","categories":"cs.CV,cs.HC","published":"2025-03-31T14:56:24Z"}
{"aid":"http://arxiv.org/abs/2503.24185v1","title":"Adding the constant evasion and constant prediction numbers to\n  Cichoń's maximum","summary":"Let $\\mathfrak{e}^\\mathsf{const}_2$ be the constant evasion number, that is,\nthe size of the least family $F\\subseteq{}^{\\omega}2$ of reals such that for\neach predictor $\\pi\\colon {}^{<\\omega}2\\to 2$ there is $x\\in F$ which is not\nconstantly predicted by $\\pi$; and let $\\mathfrak{v}_2^\\mathsf{const}$ be the\nconstant prediction number, that is, the size of the least family $\\Pi_2$ of\nfunctions $\\pi\\colon {}^{<\\omega}2\\to 2$ such that for each $x\\in{}^{\\omega}2$\nthere is $\\pi\\in\\Pi_2$ that predicts constantly $x$. In this work, we show that\nthe constant evasion number $\\mathfrak{e}_2^{\\mathrm{cons}}$ and the constant\nprediction number $\\mathfrak{v}_2^\\mathsf{const}$ can be added to Cicho\\'n's\nmaximum with distinct values.","main_category":"math.LO","categories":"math.LO","published":"2025-03-31T15:02:26Z"}
{"aid":"http://arxiv.org/abs/2503.24187v1","title":"NeuRaLaTeX: A machine learning library written in pure LaTeX","summary":"In this paper, we introduce NeuRaLaTeX, which we believe to be the first deep\nlearning library written entirely in LaTeX. As part of your LaTeX document you\ncan specify the architecture of a neural network and its loss functions, define\nhow to generate or load training data, and specify training hyperparameters and\nexperiments. When the document is compiled, the LaTeX compiler will generate or\nload training data, train the network, run experiments, and generate figures.\nThis paper generates a random 100 point spiral dataset, trains a two layer MLP\non it, evaluates on a different random spiral dataset, produces plots and\ntables of results. The paper took 48 hours to compile and the entire source\ncode for NeuRaLaTeX is contained within the source code of the paper. We\npropose two new metrics: the Written In Latex (WIL) metric measures the\nproportion of a machine learning library that is written in pure LaTeX, while\nthe Source Code Of Method in Source Code of Paper (SCOMISCOP) metric measures\nthe proportion of a paper's implementation that is contained within the paper\nsource. We are state-of-the-art for both metrics, outperforming the ResNet and\nTransformer papers, as well as the PyTorch and Tensorflow libraries. Source\ncode, documentation, videos, crypto scams and an invitation to invest in the\ncommercialisation of NeuRaLaTeX are available at https://www.neuralatex.com","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T15:05:19Z"}
{"aid":"http://arxiv.org/abs/2503.24198v1","title":"TwT: Thinking without Tokens by Habitual Reasoning Distillation with\n  Multi-Teachers' Guidance","summary":"Large Language Models (LLMs) have made significant strides in problem-solving\nby incorporating reasoning processes. However, this enhanced reasoning\ncapability results in an increased number of output tokens during inference,\nleading to higher computational costs. To address this challenge, we propose\nTwT (Thinking without Tokens), a method that reduces inference-time costs\nthrough habitual reasoning distillation with multi-teachers' guidance, while\nmaintaining high performance. Our approach introduces a Habitual Reasoning\nDistillation method, which internalizes explicit reasoning into the model's\nhabitual behavior through a Teacher-Guided compression strategy inspired by\nhuman cognition. Additionally, we propose Dual-Criteria Rejection Sampling\n(DCRS), a technique that generates a high-quality and diverse distillation\ndataset using multiple teacher models, making our method suitable for\nunsupervised scenarios. Experimental results demonstrate that TwT effectively\nreduces inference costs while preserving superior performance, achieving up to\na 13.6% improvement in accuracy with fewer output tokens compared to other\ndistillation methods, offering a highly practical solution for efficient LLM\ndeployment.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T15:16:31Z"}
{"aid":"http://arxiv.org/abs/2503.24203v1","title":"Traffic Engineering in Large-scale Networks with Generalizable Graph\n  Neural Networks","summary":"Traffic engineering (TE) in large-scale computer networks has become a\nfundamental yet challenging problem, owing to the swift growth of global-scale\ncloud wide-area networks or backbone low-Earth-orbit satellite constellations.\nTo address the scalability issue of traditional TE algorithms, learning-based\napproaches have been proposed, showing potential of significant efficiency\nimprovement over state-of-the-art methods. Nevertheless, the intrinsic\nlimitations of existing learning-based methods hinder their practical\napplication: they are not generalizable across diverse topologies and network\nconditions, incur excessive training overhead, and do not respect link\ncapacities by default.\n  This paper proposes TELGEN, a novel TE algorithm that learns to solve TE\nproblems efficiently in large-scale networks, while achieving superior\ngeneralizability across diverse network conditions. TELGEN is based on the\nnovel idea of transforming the problem of \"predicting the optimal TE solution\"\ninto \"predicting the optimal TE algorithm\", which enables TELGEN to learn and\nefficiently approximate the end-to-end solving process of classical optimal TE\nalgorithms. The learned algorithm is agnostic to the exact network topology or\ntraffic patterns, and can efficiently solve TE problems given arbitrary inputs\nand generalize well to unseen topologies and demands.\n  We trained and evaluated TELGEN on random and real-world networks with up to\n5000 nodes and 106 links. TELGEN achieved less than 3% optimality gap while\nensuring feasibility in all cases, even when the test network had up to 20x\nmore nodes than the largest in training. It also saved up to 84% solving time\nthan classical optimal solver, and could reduce training time per epoch and\nsolving time by 2-4 orders of magnitude than latest learning algorithms on the\nlargest networks.","main_category":"cs.NI","categories":"cs.NI,cs.LG","published":"2025-03-31T15:21:22Z"}
{"aid":"http://arxiv.org/abs/2503.24204v1","title":"Many-to-Many Matching via Sparsity Controlled Optimal Transport","summary":"Many-to-many matching seeks to match multiple points in one set and multiple\npoints in another set, which is a basis for a wide range of data mining\nproblems. It can be naturally recast in the framework of Optimal Transport\n(OT). However, existing OT methods either lack the ability to accomplish\nmany-to-many matching or necessitate careful tuning of a regularization\nparameter to achieve satisfactory results. This paper proposes a novel\nmany-to-many matching method to explicitly encode many-to-many constraints\nwhile preventing the degeneration into one-to-one matching. The proposed method\nconsists of the following two components. The first component is the matching\nbudget constraints on each row and column of a transport plan, which specify\nhow many points can be matched to a point at most. The second component is the\ndeformed $q$-entropy regularization, which encourages a point to meet the\nmatching budget maximally. While the deformed $q$-entropy was initially\nproposed to sparsify a transport plan, we employ it to avoid the degeneration\ninto one-to-one matching. We optimize the objective via a penalty algorithm,\nwhich is efficient and theoretically guaranteed to converge. Experimental\nresults on various tasks demonstrate that the proposed method achieves good\nperformance by gleaning meaningful many-to-many matchings.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T15:22:02Z"}
{"aid":"http://arxiv.org/abs/2503.24205v1","title":"A Comparison of Parametric Dynamic Mode Decomposition Algorithms for\n  Thermal-Hydraulics Applications","summary":"In recent years, algorithms aiming at learning models from available data\nhave become quite popular due to two factors: 1) the significant developments\nin Artificial Intelligence techniques and 2) the availability of large amounts\nof data. Nevertheless, this topic has already been addressed by methodologies\nbelonging to the Reduced Order Modelling framework, of which perhaps the most\nfamous equation-free technique is Dynamic Mode Decomposition. This algorithm\naims to learn the best linear model that represents the physical phenomena\ndescribed by a time series dataset: its output is a best state operator of the\nunderlying dynamical system that can be used, in principle, to advance the\noriginal dataset in time even beyond its span. However, in its standard\nformulation, this technique cannot deal with parametric time series, meaning\nthat a different linear model has to be derived for each parameter realization.\nResearch on this is ongoing, and some versions of a parametric Dynamic Mode\nDecomposition already exist. This work contributes to this research field by\ncomparing the different algorithms presently deployed and assessing their\nadvantages and shortcomings compared to each other. To this aim, three\ndifferent thermal-hydraulics problems are considered: two benchmark 'flow over\ncylinder' test cases at diverse Reynolds numbers, whose datasets are,\nrespectively, obtained with the FEniCS finite element solver and retrieved from\nthe CFDbench dataset, and the DYNASTY experimental facility operating at\nPolitecnico di Milano, which studies the natural circulation established by\ninternally heated fluids for Generation IV nuclear applications, whose dataset\nwas generated using the RELAP5 nodal solver.","main_category":"math.DS","categories":"math.DS,cs.LG","published":"2025-03-31T15:23:22Z"}
{"aid":"http://arxiv.org/abs/2503.24209v1","title":"Optimal low-rank approximations for linear Gaussian inverse problems on\n  Hilbert spaces, Part II: posterior mean approximation","summary":"In this work, we construct optimal low-rank approximations for the Gaussian\nposterior distribution in linear Gaussian inverse problems. The parameter space\nis a separable Hilbert space of possibly infinite dimension, and the data space\nis assumed to be finite-dimensional. We consider various types of approximation\nfamilies for the posterior. We first consider approximate posteriors in which\nthe means vary among a class of either structure-preserving or\nstructure-ignoring low-rank transformations of the data, and in which the\nposterior covariance is kept fixed. We give necessary and sufficient conditions\nfor these approximating posteriors to be equivalent to the exact posterior, for\nall possible realisations of the data simultaneously. For such approximations,\nwe measure approximation error with the Kullback-Leibler, R\\'enyi and Amari\n$\\alpha$-divergences for $\\alpha\\in(0,1)$, and with the Hellinger distance, all\naveraged over the data distribution. With these losses, we find the optimal\napproximations and formulate an equivalent condition for their uniqueness,\nextending the work in finite dimensions of Spantini et al. (SIAM J. Sci.\nComput. 2015). We then consider joint approximation of the mean and covariance,\nby also varying the posterior covariance over the low-rank updates considered\nin Part I of this work. For the reverse Kullback-Leibler divergence, we show\nthat the separate optimal approximations of the mean and of the covariance can\nbe combined to yield an optimal joint approximation of the mean and covariance.\nIn addition, we interpret the joint approximation with the optimal\nstructure-ignoring approximate mean in terms of an optimal projector in\nparameter space.","main_category":"math.ST","categories":"math.ST,math.PR,stat.TH","published":"2025-03-31T15:26:48Z"}
{"aid":"http://arxiv.org/abs/2503.24218v1","title":"Visible optical vortices measured with bulk lateral shearing\n  interferometry","summary":"Ultrafast pulse optical vortices are spatiotemporal structures with a diverse\nrange of applications. There are different ways to generate them, often\nrestricted to a wavelength range. Likewise, characterization techniques\nfrequently possess similar limitations. In this work, we first generate\nultrashort optical vortices in the near infrared from Ti:sapphire laser pulses\nby means of structured waveplates and beam manipulation. Then, we produce the\nvisible vortices through up-conversion using a second-harmonic generation\ncrystal. The resulting beams require spatiotemporal characterization, which are\nperformed by bulk lateral shearing interferometry. The reference pulse is\ntemporally characterized with the amplitude swing technique. In this manner, we\npresent the generation of these pulses in the visible range, which are\nexperimentally validated, and demonstrate that bulk lateral shearing\ninterferometry can be used for pulsed beams across widely different spectral\nregions with the same setup. This finding is significant for future\napplications of the technique with various sources.","main_category":"physics.optics","categories":"physics.optics,physics.ins-det","published":"2025-03-31T15:36:13Z"}
{"aid":"http://arxiv.org/abs/2503.24223v1","title":"Jordanian deformation of the non-compact and $\\mathfrak{sl}_2\n  $-invariant $XXX_{-1/2}$ spin-chain","summary":"Using a Drinfeld twist of Jordanian type, we construct a deformation of the\nnon-compact and $\\mathfrak{sl}_2$-invariant $XXX_{-1/2}$ spin-chain. Before the\ndeformation, the seed model can be understood as a sector of the\n$\\mathfrak{psu}(2,2|4)$-invariant spin-chain encoding the spectral problem of\n$\\mathcal{N}=4$ super Yang-Mills at one loop in the planar limit. The\ndeformation gives rise to interesting features because, while being integrable,\nthe Hamiltonian is non-hermitian and non-diagonalisable, so that it only admits\na Jordan decomposition. Moreover, the eigenvalues of the deformed Hamiltonian\ncoincide with those of the original undeformed spin-chain. We use explicit\nexamples as well as the techniques of the coordinate and of the algebraic Bethe\nansatz to discuss the construction of the (generalised) eigenvectors of the\ndeformed model. We also show that the deformed spin-chain is equivalent to an\nundeformed one with twisted boundary conditions, and that it may be derived\nfrom a scaling limit of the non-compact $U_q(\\mathfrak{sl}_2)$-invariant\n$XXZ_{-1/2} $ spin-chain.","main_category":"hep-th","categories":"hep-th,cond-mat.stat-mech,cond-mat.str-el,quant-ph","published":"2025-03-31T15:38:04Z"}
{"aid":"http://arxiv.org/abs/2503.24248v1","title":"Optimizing PCA for Health and Care Research: A Reliable Approach to\n  Component Selection","summary":"PCA is widely used in health and care research to analyze complex HD\ndatasets, such as patient health records, genetic data, and medical imaging. By\nreducing dimensionality, PCA helps identify key patterns and trends, which can\naid in disease diagnosis, treatment optimization, and the discovery of new\nbiomarkers. However, the primary goal of any dimensional reduction technique is\nto reduce the dimensionality in a data set while keeping the essential\ninformation and variability. There are a few ways to do this in practice, such\nas the Kaiser-Guttman criterion, Cattell's Scree Test, and the percent\ncumulative variance approach. Unfortunately, the results of these methods are\nentirely different. That means using inappropriate methods to find the optimal\nnumber of PCs retained in PCA may lead to misinterpreted and inaccurate results\nin PCA and PCA-related health and care research applications. This\ncontradiction becomes even more pronounced in HD settings where n < p, making\nit even more critical to determine the best approach. Therefore, it is\nnecessary to identify the issues of different techniques to select the optimal\nnumber of PCs retained in PCA. Kaiser-Guttman criterion retains fewer PCs,\ncausing overdispersion, while Cattell's scree test retains more PCs,\ncompromising reliability. The percentage of cumulative variation criterion\noffers greater stability, consistently selecting the optimal number of\ncomponents. Therefore, the Pareto chart, which shows both the cumulative\npercentage and the cut-off point for retained PCs, provides the most reliable\nmethod of selecting components, ensuring stability and enhancing PCA\neffectiveness, particularly in health-related research applications.","main_category":"stat.ME","categories":"stat.ME","published":"2025-03-31T15:58:50Z"}
{"aid":"http://arxiv.org/abs/2503.24255v1","title":"The Mysterious Phenomenon of Forward-Progressing Student Tables","summary":"This study investigates the factors that contribute to the forward movement\nof student desks throughout the school day. We hypothesize that desk movement\nis influenced not only by classroom floor type but also by the physical\ncharacteristics of students, such as height and age. Furthermore, we explore\nhow the subject taught in the classroom (e.g., Science vs. Modern Foreign\nLanguages) contributes to desk dynamics. Utilizing a Monte Carlo simulation\nmodel, we quantitatively analyse the forces at play in these phenomena. This\nresearch reveals that desks on carpeted floors are particularly prone to\nmovement, especially in science classrooms with taller and younger students.\nWhile the results may seem trivial, they provide critical insights into the\nmechanics of classroom furniture behaviour and its implications for educational\npractices. The paper offers compelling evidence that classroom furniture has a\nmind of its own or, at the very least, a subtle gravitational pull towards the\nfront of the room.","main_category":"physics.ed-ph","categories":"physics.ed-ph","published":"2025-03-31T16:03:53Z"}
{"aid":"http://arxiv.org/abs/2503.24266v1","title":"EP240414a: Off-axis View of a Jet-Cocoon System from an Expanded\n  Progenitor Star","summary":"When a relativistic jet is launched following the core-collapse of a star,\nits interaction with the stellar envelope leads to the formation of a hot\ncocoon, which produces various viewing-angle-dependent observational phenomena\nfollowing the breakout from the surface. We study the observational signatures\nof fast X-ray transient (FXT) EP240414a, which may originate from a jet-cocoon\nsystem viewed slightly off-axis. In our model, (1) the prompt X-ray emission\nlasting $\\sim\\! 100\\,{\\rm{s}}$ is attributed to the cooling emission from the\ninner cocoon (shocked jet material); (2) the $\\sim\\! 0.1\\,{\\rm{d}}$ X-ray\nemission comes from the inner cocoon's afterglow; (3) the $\\sim\\!\n0.4\\,{\\rm{d}}$ thermal-dominated optical emission arises from the cooling of\nthe outer cocoon (shocked stellar material); (4) the $\\sim\\! 3\\,{\\rm{d}}$\nnon-thermal optical component and subsequent radio emission can be explained by\nthe afterglow from a jet with a viewing angle of $10^{\\circ}\\lesssim\n\\theta_{\\rm{v}}\\lesssim15^\\circ$; and (5) the associated broad-lined Type Ic\nsupernova only dominates the optical emission after $\\sim\\! 7\\rm\\, d$. Both the\njet inferred from the off-axis afterglow and the inner cocoon constrained by\nthe cooling emission are found to have similar kinetic energies, on the order\nof $10^{51}\\,{\\rm{erg}}$. We find that the progenitor's radius is\n$\\sim3\\,R_\\odot$ as constrained by the { inner cocoon's} cooling emissions,\nindicating that the pre-explosion star may be a massive helium star that is\nslightly inflated. More FXTs associated with off-axis jets and supernovae will\nbe further examined by the Einstein Probe, leading to a deeper understanding of\njet-cocoon systems.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-03-31T16:12:46Z"}
{"aid":"http://arxiv.org/abs/2503.24277v1","title":"Evaluating and Designing Sparse Autoencoders by Approximating\n  Quasi-Orthogonality","summary":"Sparse autoencoders (SAEs) have emerged as a workhorse of modern mechanistic\ninterpretability, but leading SAE approaches with top-$k$ style activation\nfunctions lack theoretical grounding for selecting the hyperparameter $k$. SAEs\nare based on the linear representation hypothesis (LRH), which assumes that the\nrepresentations of large language models (LLMs) are linearly encoded, and the\nsuperposition hypothesis (SH), which states that there can be more features in\nthe model than its dimensionality. We show that, based on the formal\ndefinitions of the LRH and SH, the magnitude of sparse feature vectors (the\nlatent representations learned by SAEs of the dense embeddings of LLMs) can be\napproximated using their corresponding dense vector with a closed-form error\nbound. To visualize this, we propose the ZF plot, which reveals a previously\nunknown relationship between LLM hidden embeddings and SAE feature vectors,\nallowing us to make the first empirical measurement of the extent to which\nfeature vectors of pre-trained SAEs are over- or under-activated for a given\ninput. Correspondingly, we introduce Approximate Feature Activation (AFA),\nwhich approximates the magnitude of the ground-truth sparse feature vector, and\npropose a new evaluation metric derived from AFA to assess the alignment\nbetween inputs and activations. We also leverage AFA to introduce a novel SAE\narchitecture, the top-AFA SAE, leading to SAEs that: (a) are more in line with\ntheoretical justifications; and (b) obviate the need to tune SAE sparsity\nhyperparameters. Finally, we empirically demonstrate that top-AFA SAEs achieve\nreconstruction loss comparable to that of state-of-the-art top-k SAEs, without\nrequiring the hyperparameter $k$ to be tuned. Our code is available at:\nhttps://github.com/SewoongLee/top-afa-sae.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-03-31T16:22:11Z"}
{"aid":"http://arxiv.org/abs/2503.24279v1","title":"Toward the effective 2-topos","summary":"A candidate for the effective 2-topos is proposed and shown to include the\neffective 1-topos as its subcategory of 0-types.","main_category":"math.CT","categories":"math.CT,math.LO","published":"2025-03-31T16:23:47Z"}
{"aid":"http://arxiv.org/abs/2503.24292v1","title":"Implicit Electric Field Conjugation with the Photonic Lantern Nuller","summary":"The Photonic Lantern Nuller (PLN) is an instrument concept designed to\ncharacterize exoplanets within a single beam-width from its host star. The PLN\nleverages the spatial symmetry of a mode-selective photonic lantern (MSPL) to\ncreate nulled ports, which cancel out on-axis starlight but allow off-axis\nexoplanet light to couple. The null-depths are limited by wavefront aberrations\nin the system as well as by imperfections in the lantern. We show that the\nimplicit electric field conjugation algorithm can be used to reduce the stellar\ncoupling through the PLN by orders of magnitude while maintaining the majority\nof the off-axis light, leading to deeper null depths (~10^{-4}) and thus higher\nsensitivity to potential planet signals. We discuss a theory for the tradeoff\nwe observed between the different ports, where iEFC improves the nulls of some\nports at the expense of others, and show that targeting one port alone can lead\nto deeper starlight rejection through that port than when targeting all ports\nat once. We also observe different levels of stability depending on the port\nand discuss the implications for practically implementing this technique for\nscience observations.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.EP","published":"2025-03-31T16:38:18Z"}
{"aid":"http://arxiv.org/abs/2503.24295v1","title":"Brazilian input to the European Strategy for Particle Physics Update","summary":"The Brazilian High-Energy Physics (HEP) community has expanded remarkably\nsince its first involvement at CERN and Fermilab in the 1980s. Its recent\norganization under the Brazilian Network for High-Energy Physics (RENAFAE),\nsince 2008, has further strengthened its scientific and technological goals,\nparticularly in detector instrumentation, computing, and industry partnerships.\nIn 2024, Brazil became an Associate Member State of CERN, opening new\nopportunities for deeper engagement in accelerator and detector R&D. This input\nto the 2026 update of the European Strategy for Particle Physics highlights\nBrazil's current participation in LHC experiments as well as ongoing\ndevelopments in detector and accelerator technology, and details the\ncommunity's view towards future colliders. The potential for expanded\nscientific and industrial collaborations between Brazil and CERN is also\ndiscussed.","main_category":"hep-ex","categories":"hep-ex","published":"2025-03-31T16:41:38Z"}
{"aid":"http://arxiv.org/abs/2503.24298v1","title":"Order Matters: On Parameter-Efficient Image-to-Video Probing for\n  Recognizing Nearly Symmetric Actions","summary":"We study parameter-efficient image-to-video probing for the unaddressed\nchallenge of recognizing nearly symmetric actions - visually similar actions\nthat unfold in opposite temporal order (e.g., opening vs. closing a bottle).\nExisting probing mechanisms for image-pretrained models, such as DinoV2 and\nCLIP, rely on attention mechanism for temporal modeling but are inherently\npermutation-invariant, leading to identical predictions regardless of frame\norder. To address this, we introduce Self-attentive Temporal Embedding Probing\n(STEP), a simple yet effective approach designed to enforce temporal\nsensitivity in parameter-efficient image-to-video transfer. STEP enhances\nself-attentive probing with three key modifications: (1) a learnable frame-wise\npositional encoding, explicitly encoding temporal order; (2) a single global\nCLS token, for sequence coherence; and (3) a simplified attention mechanism to\nimprove parameter efficiency. STEP outperforms existing image-to-video probing\nmechanisms by 3-15% across four activity recognition benchmarks with only 1/3\nof the learnable parameters. On two datasets, it surpasses all published\nmethods, including fully fine-tuned models. STEP shows a distinct advantage in\nrecognizing nearly symmetric actions, surpassing other probing mechanisms by\n9-19%. and parameter-heavier PEFT-based transfer methods by 5-15%. Code and\nmodels will be made publicly available.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T16:42:38Z"}
{"aid":"http://arxiv.org/abs/2503.24309v1","title":"The edge-on disk Tau042021: icy grains at high altitudes and a wind\n  containing astronomical PAHs","summary":"Spectra of the nearly edge-on protoplanetary disks observed with the JWST\nhave shown ice absorption bands of varying optical depths and peculiar\nprofiles, challenging radiative transfer modelling and our understanding of\ndust and ice in disks. We build models including dust grain size, shape, and\ncomposition to reproduce JWST IFU spectroscopy of the large edge-on disk\nTau042021. We explore radiative transfer models using different dust grain size\ndistributions, including grains of effective radii a_eff = 0.005-3000 microns.\nScattering properties of distributions of triaxial ellipsoidal grains are\ncalculated. We consider compositions with silicates, amorphous carbon, and\nmixtures of H2O, CO2, and CO. We use RADMC-3D Monte Carlo radiative transfer\nmodels of Tau042021 to simulate the spectral cubes observed with JWST-NIRSpec\nand MIRI. We compare the results to observations, including H2O at 3.05\nmicrons, CO at 4.67 microns, and CO2 at 4.27 microns and to archival\nJWST-NIRCam and ALMA continuum images. The observed near- to mid-infrared imply\ndust distributions with grain sizes up to several tens of microns. The\nintensity distribution perpendicular to the disk exhibits emission profile\nwings extending into the upper disk atmosphere at altitudes exceeding the\nclassical scale height expected in the isothermal hydrostatic limit. We produce\nice map images demonstrating the presence of icy dust grains up to altitudes\nhigh above the disk midplane, more than three hydrostatic equilibrium scale\nheights. We demonstrate the presence of a wind containing the carriers of\nastronomical PAH bands. The wind appears as an X-shaped emission at 3.3, 6.2,\n7.7 and 11.3 microns, characteristic wavelengths of the infrared astronomical\nPAH bands. We associate the spatial distribution of this component with\ncarriers of astronomical PAH bands that form a layer of emission at the\ninterface with the H2 wind.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-03-31T16:56:16Z"}
{"aid":"http://arxiv.org/abs/2503.24314v1","title":"Impact of Synchronization Offsets and CSI Feedback Delay in Distributed\n  MIMO Systems","summary":"The main challenges of distributed MIMO systems lie in achieving highly\naccurate synchronization and ensuring the availability of accurate channel\nstate information (CSI) at distributed nodes. This paper analytically examines\nthe effects of synchronization offsets and CSI feedback delays on system\ncapacity, providing insights into how these affect the coherent joint\ntransmission gain. The capacity expressions are first derived under ideal\nconditions, and the effects of synchronization offsets and feedback delays are\nsubsequently incorporated. This analysis can be applied to any distributed MIMO\narchitecture. A comprehensive study, including system models and simulations\nevaluating the analytical expressions, is presented to quantify the capacity\ndegradation caused by these factors. This study provides valuable insights into\nthe design and performance of distributed MIMO systems. The analysis shows that\ntime and frequency offsets, along with CSI feedback delay, cause inter-layer\ninterference. Additionally, time offsets result in inter-symbol interference.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T17:02:33Z"}
{"aid":"http://arxiv.org/abs/2503.24325v1","title":"Pro-Routing: Proactive Routing of Autonomous Multi-Capacity Robots for\n  Pickup-and-Delivery Tasks","summary":"We consider a multi-robot setting, where we have a fleet of multi-capacity\nautonomous robots that must service spatially distributed pickup-and-delivery\nrequests with fixed maximum wait times. Requests can be either scheduled ahead\nof time or they can enter the system in real-time. In this setting, stability\nfor a routing policy is defined as the cost of the policy being uniformly\nbounded over time. Most previous work either solve the problem offline to\ntheoretically maintain stability or they consider dynamically arriving requests\nat the expense of the theoretical guarantees on stability. In this paper, we\naim to bridge this gap by proposing a novel proactive rollout-based routing\nframework that adapts to real-time demand while still provably maintaining the\nstability of the learned routing policy. We derive provable stability\nguarantees for our method by proposing a fleet sizing algorithm that obtains a\nsufficiently large fleet that ensures stability by construction. To validate\nour theoretical results, we consider a case study on real ride requests for\nHarvard's evening Van System. We also evaluate the performance of our framework\nusing the currently deployed smaller fleet size. In this smaller setup, we\ncompare against the currently deployed routing algorithm, greedy heuristics,\nand Monte-Carlo-Tree-Search-based algorithms. Our empirical results show that\nour framework maintains stability when we use the sufficiently large fleet size\nfound in our theoretical results. For the smaller currently deployed fleet\nsize, our method services 6% more requests than the closest baseline while\nreducing median passenger wait times by 33%.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.MA","published":"2025-03-31T17:14:07Z"}
{"aid":"http://arxiv.org/abs/2503.24327v1","title":"Thermal transport in superconductor heterostructures: some recent\n  progress","summary":"This article reviews recent advances in low-temperature electronic thermal\ntransport properties of thermally biased superconductor heterostructures\nfocusing on the two-terminal transport. Since the last decade, ferromagnetism\nhas been widely used to enhance the thermoelectricity in heterostructures based\non ordinary superconductors. The possibility of getting giant thermoelectric\neffects with optimum thermal conductance by breaking the electron-hole symmetry\nof the ordinary superconductor boosted the research in this direction.\nRecently, attention has been paid to the role of triplet Cooper pairs that\nemerged in ferromagnetic junctions and the possibility of advanced\napplications. Other forms of magnetism, specifically antiferromagnetism and\naltermagnetism, have been investigated to unravel the behavior of the thermal\nand charge current in thermally biased junctions. In parallel to ordinary\nsuperconductors, junctions with unconventional superconductors have been\nexplored for the same purpose. Thermal transport in superconducting bilayers\nhas been studied using advanced materials like Dirac and topological materials,\nincluding Weyl semimetals. Significant attention has been paid to thermally\nbiased topological Josephson junctions to explore the phase-tunable current in\nrecent times. Weyl Josephson junctions, multi-terminal Josephson junctions, and\nvarious other multilayer junctions have also been studied to engineer large\nthermoelectric effects and various functionalities with potential applications\nin superconductor-based thermal device components.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-03-31T17:17:25Z"}
{"aid":"http://arxiv.org/abs/2503.24344v1","title":"Local basis for interacting topological bands","summary":"The discovery of correlated states in moire materials has challenged the\nestablished methods of projecting interactions into a local Wannier basis due\nto topological obstructions that manifest in extended interactions. This\ndifficulty can sometimes be evaded by decomposing the band into a basis of\nextended itinerant states and a lattice of local states, using the heavy\nfermion prescription. We revisit this framework by systematically identifying\nthe dominant interaction channels guided by the eigenvalues of the projected\ndensity operator. This approach can be applied both to tight-binding and\ncontinuum models, allowing us to identify a hierarchy in interaction scales\nthat can be universally used to reduce the Hilbert space dimension and\ndetermine an appropriate local basis for modeling electronic correlations in\ninteracting topological materials.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-03-31T17:26:23Z"}
{"aid":"http://arxiv.org/abs/2503.24348v1","title":"On the unitarity and modularity of ribbon tensor categories associated\n  with affine Lie algebras","summary":"We study the unitarity and modularity of ribbon tensor categories derived\nfrom simple affine Lie algebras, via their associated quantum groups. Based on\nnumerical calculations, and assuming two conjectures, we provide the complete\npicture for which values of $q$ these ribbon tensor categories are\n(pseudo-)unitary and for which values of $q$ they are modular. We compare our\nresults with the extensive rigorous results appearing in the literature,\nfinding complete agreement. For the cases that do not appear in the literature,\nwe complete the picture.","main_category":"math.QA","categories":"math.QA","published":"2025-03-31T17:32:29Z"}
{"aid":"http://arxiv.org/abs/2503.24353v1","title":"Universality of Rényi Entropy in Conformal Field Theory","summary":"We use the thermal effective theory to prove that, for the vacuum state in\nany conformal field theory in $d$ dimensions, the $n$-th R\\'enyi entropy\n$S_A^{(n)}$ behaves as $S_A^{(n)} = \\frac{f}{(2\\pi n)^{d-1}} \\frac{ {\\rm\nArea}(\\partial A)}{(d-2)\\epsilon^{d-2}}\\left(1+O(n)\\right)$ in the $n\n\\rightarrow 0$ limit when the boundary of the entanglement domain $A$ is\nspherical with the UV cutoff $\\epsilon$.The theory dependence is encapsulated\nin the cosmological constant $f$ in the thermal effective action. Using this\nresult, we estimate the density of states for large eigenvalues of the modular\nHamiltonian for the domain $A$. In two dimensions, we can use the hot spot idea\nto derive more powerful formulas valid for arbitrary positive $n$. We discuss\nthe difference between two and higher dimensions and clarify the applicability\nof the hot spot idea. We also use the thermal effective theory to derive an\nanalog of the Cardy formula for boundary operators in higher dimensions.","main_category":"hep-th","categories":"hep-th,cond-mat.stat-mech,cond-mat.str-el,quant-ph","published":"2025-03-31T17:34:59Z"}
{"aid":"http://arxiv.org/abs/2503.24355v1","title":"Modified cosmology though spacetime thermodynamics and generalized\n  mass-to-horizon entropy","summary":"In this work we apply the gravity-thermodynamics approach for the case of\ngeneralized mass-to-horizon entropy, which is a two-parameter extension of\nBekenstein-Hawking entropy that arises from the extended mass-to-horizon\nrelation, that is in turn required in order to have consistency with the\nClausius relation. We extract the modified Friedmann equations and we obtain an\neffective dark energy sector arising from the novel terms. We derive analytical\nsolutions for the dark energy density parameter, the dark energy\nequation-of-state parameter, and the deceleration parameter, and we show that\nthe Universe exhibits the usual thermal history with the succession of matter\nand dark energy epochs. Additionally, depending on the value of the entropy\nparameters, the dark energy equation-of-state parameter can either lie in the\nphantom regime at high redshifts entering into the quintessence regime at small\nredshifts, or it can lie in the quintessence regime at high redshifts and\nexperience the phantom-divide crossing at small redshifts, while in the far\nfuture in all cases it asymptotically obtains the cosmological constant value\n$-1$. Finally, we perform observational confrontation with Supernova Type Ia\n(SNIa), Cosmic Chronometers (CC) and Baryonic Acoustic Oscillations (BAO)\ndatasets, showing that the scenario is in agreement with observations.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-th","published":"2025-03-31T17:35:35Z"}
{"aid":"http://arxiv.org/abs/2503.24356v1","title":"Single-Shot Matrix-Matrix Multiplication Optical Tensor Processor for\n  Deep Learning","summary":"The ever-increasing data demand craves advancements in high-speed and\nenergy-efficient computing hardware. Analog optical neural network (ONN)\nprocessors have emerged as a promising solution, offering benefits in bandwidth\nand energy consumption. However, existing ONN processors exhibit limited\ncomputational parallelism, and while certain architectures achieve high\nparallelism, they encounter serious scaling roadblocks for large-scale\nimplementation. This restricts the throughput, latency, and energy efficiency\nadvantages of ONN processors. Here, we introduce a spatial-wavelength-temporal\nhyper-multiplexed ONN processor that supports high data dimensionality, high\ncomputing parallelism and is feasible for large-scale implementation, and in a\nsingle time step, a three-dimensional matrix-matrix multiplication (MMM)\noptical tensor processor is demonstrated. Our hardware accelerates\nconvolutional neural networks (CNNs) and deep neural networks (DNNs) through\nparallel matrix multiplication. We demonstrate benchmark image recognition\nusing a CNN and a subsequently fully connected DNN in the optical domain. The\nnetwork works with 292,616 weight parameters under ultra-low optical energy of\n20 attojoules (aJ) per multiply and accumulate (MAC) at 96.4% classification\naccuracy. The system supports broad spectral and spatial bandwidths and is\ncapable for large-scale demonstration, paving the way for highly efficient\nlarge-scale optical computing for next-generation deep learning.","main_category":"physics.optics","categories":"physics.optics","published":"2025-03-31T17:35:48Z"}
{"aid":"http://arxiv.org/abs/2503.24369v1","title":"Exploring light propagation in nonlinear electrodynamics: phase and\n  group velocities and related phenomena","summary":"Nonlinear electrodynamics has been an important area of research for a long\ntime. Investigations based on nonlinear Lagrangians, such as Euler-Heisenberg\nand Born-Infeld, are instrumental in exploring the limits of classical and\nquantum field theories, providing valuable insights into strong-field\nphenomena. In this context, this work considers how light propagates in\nstrong-field environments, where such nonlinearities play significant roles,\noffering a way to investigate events in high-energy astrophysics, quantum\noptics, and fundamental physics beyond classical Maxwell's framework. Here,\nseveral aspects of light propagation in nonlinear electrodynamics are\ndiscussed. Phase and group velocities are derived and several interesting\nbehaviors are unveiled, such as birefringence, non-reciprocal propagation, and\nasymmetries between phase and group velocities in special configurations.\nSpecific solutions based on commonly studied nonlinear theories are also\ninvestigated, and phenomena like slow-light and one-way propagation are\ndiscussed.","main_category":"physics.gen-ph","categories":"physics.gen-ph","published":"2025-03-31T17:49:51Z"}
{"aid":"http://arxiv.org/abs/2503.24373v1","title":"Accelerated Approximate Optimization of Multi-Commodity Flows on\n  Directed Graphs","summary":"We provide $m^{1+o(1)}k\\epsilon^{-1}$-time algorithms for computing\nmultiplicative $(1 - \\epsilon)$-approximate solutions to multi-commodity flow\nproblems with $k$-commodities on $m$-edge directed graphs, including concurrent\nmulti-commodity flow and maximum multi-commodity flow.\n  To obtain our results, we provide new optimization tools of potential\nindependent interest. First, we provide an improved optimization method for\nsolving $\\ell_{q, p}$-regression problems to high accuracy. This method makes\n$\\tilde{O}_{q, p}(k)$ queries to a high accuracy convex minimization oracle for\nan individual block, where $\\tilde{O}_{q, p}(\\cdot)$ hides factors depending\nonly on $q$, $p$, or $\\mathrm{poly}(\\log m)$, improving upon the $\\tilde{O}_{q,\np}(k^2)$ bound of [Chen-Ye, ICALP 2024]. As a result, we obtain the first\nalmost-linear time algorithm that solves $\\ell_{q, p}$ flows on directed graphs\nto high accuracy. Second, we present optimization tools to reduce approximately\nsolving composite $\\ell_{1, \\infty}$-regression problems to solving\n$m^{o(1)}\\epsilon^{-1}$ instances of composite $\\ell_{q, p}$-regression\nproblem. The method builds upon recent advances in solving box-simplex games\n[Jambulapati-Tian, NeurIPS 2023] and the area convex regularizer introduced in\n[Sherman, STOC 2017] to obtain faster rates for constrained versions of the\nproblem. Carefully combining these techniques yields our directed\nmulti-commodity flow algorithm.","main_category":"cs.DS","categories":"cs.DS,math.OC","published":"2025-03-31T17:53:00Z"}
{"aid":"http://arxiv.org/abs/2503.24377v1","title":"Harnessing the Reasoning Economy: A Survey of Efficient Reasoning for\n  Large Language Models","summary":"Recent advancements in Large Language Models (LLMs) have significantly\nenhanced their ability to perform complex reasoning tasks, transitioning from\nfast and intuitive thinking (System 1) to slow and deep reasoning (System 2).\nWhile System 2 reasoning improves task accuracy, it often incurs substantial\ncomputational costs due to its slow thinking nature and inefficient or\nunnecessary reasoning behaviors. In contrast, System 1 reasoning is\ncomputationally efficient but leads to suboptimal performance. Consequently, it\nis critical to balance the trade-off between performance (benefits) and\ncomputational costs (budgets), giving rise to the concept of reasoning economy.\nIn this survey, we provide a comprehensive analysis of reasoning economy in\nboth the post-training and test-time inference stages of LLMs, encompassing i)\nthe cause of reasoning inefficiency, ii) behavior analysis of different\nreasoning patterns, and iii) potential solutions to achieve reasoning economy.\nBy offering actionable insights and highlighting open challenges, we aim to\nshed light on strategies for improving the reasoning economy of LLMs, thereby\nserving as a valuable resource for advancing research in this evolving area. We\nalso provide a public repository to continually track developments in this\nfast-evolving field.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-03-31T17:58:07Z"}
{"aid":"http://arxiv.org/abs/2503.24379v1","title":"Any2Caption:Interpreting Any Condition to Caption for Controllable Video\n  Generation","summary":"To address the bottleneck of accurate user intent interpretation within the\ncurrent video generation community, we present Any2Caption, a novel framework\nfor controllable video generation under any condition. The key idea is to\ndecouple various condition interpretation steps from the video synthesis step.\nBy leveraging modern multimodal large language models (MLLMs), Any2Caption\ninterprets diverse inputs--text, images, videos, and specialized cues such as\nregion, motion, and camera poses--into dense, structured captions that offer\nbackbone video generators with better guidance. We also introduce Any2CapIns, a\nlarge-scale dataset with 337K instances and 407K conditions for\nany-condition-to-caption instruction tuning. Comprehensive evaluations\ndemonstrate significant improvements of our system in controllability and video\nquality across various aspects of existing video generation models. Project\nPage: https://sqwu.top/Any2Cap/","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T17:59:01Z"}
{"aid":"http://arxiv.org/abs/2503.24381v1","title":"UniOcc: A Unified Benchmark for Occupancy Forecasting and Prediction in\n  Autonomous Driving","summary":"We introduce UniOcc, a comprehensive, unified benchmark for occupancy\nforecasting (i.e., predicting future occupancies based on historical\ninformation) and current-frame occupancy prediction from camera images. UniOcc\nunifies data from multiple real-world datasets (i.e., nuScenes, Waymo) and\nhigh-fidelity driving simulators (i.e., CARLA, OpenCOOD), which provides 2D/3D\noccupancy labels with per-voxel flow annotations and support for cooperative\nautonomous driving. In terms of evaluation, unlike existing studies that rely\non suboptimal pseudo labels for evaluation, UniOcc incorporates novel metrics\nthat do not depend on ground-truth occupancy, enabling robust assessment of\nadditional aspects of occupancy quality. Through extensive experiments on\nstate-of-the-art models, we demonstrate that large-scale, diverse training data\nand explicit flow information significantly enhance occupancy prediction and\nforecasting performance.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG,cs.MA,cs.RO","published":"2025-03-31T17:59:24Z"}
{"aid":"http://arxiv.org/abs/2503.24388v1","title":"RIG: Synergizing Reasoning and Imagination in End-to-End Generalist\n  Policy","summary":"Reasoning before action and imagining potential outcomes (i.e., world models)\nare essential for embodied agents operating in complex open-world environments.\nYet, prior work either incorporates only one of these abilities in an\nend-to-end agent or integrates multiple specialized models into an agent\nsystem, limiting the learning efficiency and generalization of the policy.\nThus, this paper makes the first attempt to synergize Reasoning and Imagination\nin an end-to-end Generalist policy, termed RIG. To train RIG in an end-to-end\nmanner, we construct a data pipeline that progressively integrates and enriches\nthe content of imagination and reasoning in the trajectories collected from\nexisting agents. The joint learning of reasoning and next image generation\nexplicitly models the inherent correlation between reasoning, action, and\ndynamics of environments, and thus exhibits more than $17\\times$ sample\nefficiency improvements and generalization in comparison with previous works.\nDuring inference, RIG first reasons about the next action, produces potential\naction, and then predicts the action outcomes, which offers the agent a chance\nto review and self-correct based on the imagination before taking real actions.\nExperimental results show that the synergy of reasoning and imagination not\nonly improves the robustness, generalization, and interoperability of\ngeneralist policy but also enables test-time scaling to enhance overall\nperformance.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.LG","published":"2025-03-31T17:59:52Z"}
{"aid":"http://arxiv.org/abs/2503.24390v1","title":"Intertwining bulk and surface: the case of UTe$_2$","summary":"UTe$_2$ has been the focus of numerous experimental and theoretical studies\nin recent years, as it is recognized as an odd-parity bulk superconductor. Its\nsurface has also been probed, revealing charge density wave (CDW), pair density\nwave (PDW), and time-reversal symmetry breaking (TRSB). In this work, we\npropose that the interplay between the order parameters observed on the surface\nand in the bulk of UTe$_2$ may be crucial in explaining some of the unusual\nfeatures detected by surface probes in this material. Through a\nphenomenological analysis, we can account for three distinctive experimental\nsignatures observed on the surface of UTe$_2$: i) the apparent suppression of\nCDW order at the upper critical field of the bulk superconducting state; ii)\nthe magnetic field-induced imbalance of the Fourier peaks associated with the\nCDW; iii) the onset of TRSB at the bulk superconducting critical temperature\nand its field-trainability. Furthermore, we propose specific experimental\nchecks to validate our conjecture, which we believe could be promptly achieved.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.str-el","published":"2025-03-31T17:59:55Z"}
{"aid":"http://arxiv.org/abs/2503.24391v1","title":"Easi3R: Estimating Disentangled Motion from DUSt3R Without Training","summary":"Recent advances in DUSt3R have enabled robust estimation of dense point\nclouds and camera parameters of static scenes, leveraging Transformer network\narchitectures and direct supervision on large-scale 3D datasets. In contrast,\nthe limited scale and diversity of available 4D datasets present a major\nbottleneck for training a highly generalizable 4D model. This constraint has\ndriven conventional 4D methods to fine-tune 3D models on scalable dynamic video\ndata with additional geometric priors such as optical flow and depths. In this\nwork, we take an opposite path and introduce Easi3R, a simple yet efficient\ntraining-free method for 4D reconstruction. Our approach applies attention\nadaptation during inference, eliminating the need for from-scratch pre-training\nor network fine-tuning. We find that the attention layers in DUSt3R inherently\nencode rich information about camera and object motion. By carefully\ndisentangling these attention maps, we achieve accurate dynamic region\nsegmentation, camera pose estimation, and 4D dense point map reconstruction.\nExtensive experiments on real-world dynamic videos demonstrate that our\nlightweight attention adaptation significantly outperforms previous\nstate-of-the-art methods that are trained or finetuned on extensive dynamic\ndatasets. Our code is publicly available for research purpose at\nhttps://easi3r.github.io/","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T17:59:58Z"}
{"aid":"http://arxiv.org/abs/2504.01319v1","title":"Decoupled anisotropic Charge-Phonon Transport Enables Exceptional n-Type\n  Thermoelectric Performance in CuBiSCl$_2$","summary":"First-principles calculations demonstrate an exceptional decoupling of charge\nand thermal transport along the \\textit{a}-axis in CuBiSCl$_2$. The material\nachieves superior electron mobility (138 cm$^2$/V$\\cdot$s at 300 K) through\ndelocalized Bi-6\\textit{p}/S-3\\textit{p} networks while maintaining ultralow\nlattice thermal conductivity (0.40 W/mK at 300 K) via Cu-dominated anharmonic\nphonon scattering - both optimized along the same crystallographic direction.\nThis simultaneous optimization originates from the anisotropic bonding\nhierarchy where [BiSCl$_2$]$_n$ ribbons enable efficient charge transport along\n\\textit{a}-axis, while the soft vibrational modes associated with Cu atoms\nstrongly scatter heat-carrying phonons. The resulting high power factor (1.71\nmW/mK$^2$ at 700 K) and peak \\textit{ZT} of 1.57 establish CuBiSCl$_2$ as a\nmodel system that realizes the long-sought \"phonon glass-electron crystal\"\nparadigm through crystallographically engineered transport channels.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T03:10:17Z"}
{"aid":"http://arxiv.org/abs/2504.01321v1","title":"COST: Contrastive One-Stage Transformer for Vision-Language Small Object\n  Tracking","summary":"Transformer has recently demonstrated great potential in improving\nvision-language (VL) tracking algorithms. However, most of the existing VL\ntrackers rely on carefully designed mechanisms to perform the multi-stage\nmulti-modal fusion. Additionally, direct multi-modal fusion without alignment\nignores distribution discrepancy between modalities in feature space,\npotentially leading to suboptimal representations. In this work, we propose\nCOST, a contrastive one-stage transformer fusion framework for VL tracking,\naiming to learn semantically consistent and unified VL representations.\nSpecifically, we introduce a contrastive alignment strategy that maximizes\nmutual information (MI) between a video and its corresponding language\ndescription. This enables effective cross-modal alignment, yielding\nsemantically consistent features in the representation space. By leveraging a\nvisual-linguistic transformer, we establish an efficient multi-modal fusion and\nreasoning mechanism, empirically demonstrating that a simple stack of\ntransformer encoders effectively enables unified VL representations. Moreover,\nwe contribute a newly collected VL tracking benchmark dataset for small object\ntracking, named VL-SOT500, with bounding boxes and language descriptions. Our\ndataset comprises two challenging subsets, VL-SOT230 and VL-SOT270, dedicated\nto evaluating generic and high-speed small object tracking, respectively. Small\nobject tracking is notoriously challenging due to weak appearance and limited\nfeatures, and this dataset is, to the best of our knowledge, the first to\nexplore the usage of language cues to enhance visual representation for small\nobject tracking. Extensive experiments demonstrate that COST achieves\nstate-of-the-art performance on five existing VL tracking datasets, as well as\non our proposed VL-SOT500 dataset. Source codes and dataset will be made\npublicly available.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T03:12:38Z"}
{"aid":"http://arxiv.org/abs/2504.01324v1","title":"On Data Synthesis and Post-training for Visual Abstract Reasoning","summary":"This paper is a pioneering work attempting to address abstract visual\nreasoning (AVR) problems for large vision-language models (VLMs). We make a\ncommon LLaVA-NeXT 7B model capable of perceiving and reasoning about specific\nAVR problems, surpassing both open-sourced (e.g., Qwen-2-VL-72B) and\nclosed-sourced powerful VLMs (e.g., GPT-4o) with significant margin. This is a\ngreat breakthrough since almost all previous VLMs fail or show nearly random\nperformance on representative AVR benchmarks. Our key success is our innovative\ndata synthesis and post-training process, aiming to fully relieve the task\ndifficulty and elicit the model to learn, step by step. Our 7B model is also\nshown to be behave well on AVR without sacrificing common multimodal\ncomprehension abilities. We hope our paper could serve as an early effort in\nthis area and would inspire further research in abstract visual reasoning.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL","published":"2025-04-02T03:18:24Z"}
{"aid":"http://arxiv.org/abs/2504.01331v1","title":"An Explainable Reconfiguration-Based Optimization Algorithm for\n  Industrial and Reliability-Redundancy Allocation Problems","summary":"Industrial and reliability optimization problems often involve complex\nconstraints and require efficient, interpretable solutions. This paper presents\nAI-AEFA, an advanced parameter reconfiguration-based metaheuristic algorithm\ndesigned to address large-scale industrial and reliability-redundancy\nallocation problems. AI-AEFA enhances search space exploration and convergence\nefficiency through a novel log-sigmoid-based parameter adaptation and chaotic\nmapping mechanism. The algorithm is validated across twenty-eight IEEE CEC 2017\nconstrained benchmark problems, fifteen large-scale industrial optimization\nproblems, and seven reliability-redundancy allocation problems, consistently\noutperforming state-of-the-art optimization techniques in terms of feasibility,\ncomputational efficiency, and convergence speed. The additional key\ncontribution of this work is the integration of SHAP (Shapley Additive\nExplanations) to enhance the interpretability of AI-AEFA, providing insights\ninto the impact of key parameters such as Coulomb's constant, charge,\nacceleration, and electrostatic force. This explainability feature enables a\ndeeper understanding of decision-making within the AI-AEFA framework during the\noptimization processes. The findings confirm AI-AEFA as a robust, scalable, and\ninterpretable optimization tool with significant real-world applications.","main_category":"cs.AI","categories":"cs.AI,cs.NE","published":"2025-04-02T03:33:48Z"}
{"aid":"http://arxiv.org/abs/2504.01336v1","title":"Inverse RL Scene Dynamics Learning for Nonlinear Predictive Control in\n  Autonomous Vehicles","summary":"This paper introduces the Deep Learning-based Nonlinear Model Predictive\nController with Scene Dynamics (DL-NMPC-SD) method for autonomous navigation.\nDL-NMPC-SD uses an a-priori nominal vehicle model in combination with a scene\ndynamics model learned from temporal range sensing information. The scene\ndynamics model is responsible for estimating the desired vehicle trajectory, as\nwell as to adjust the true system model used by the underlying model predictive\ncontroller. We propose to encode the scene dynamics model within the layers of\na deep neural network, which acts as a nonlinear approximator for the high\norder state-space of the operating conditions. The model is learned based on\ntemporal sequences of range sensing observations and system states, both\nintegrated by an Augmented Memory component. We use Inverse Reinforcement\nLearning and the Bellman optimality principle to train our learning controller\nwith a modified version of the Deep Q-Learning algorithm, enabling us to\nestimate the desired state trajectory as an optimal action-value function. We\nhave evaluated DL-NMPC-SD against the baseline Dynamic Window Approach (DWA),\nas well as against two state-of-the-art End2End and reinforcement learning\nmethods, respectively. The performance has been measured in three experiments:\ni) in our GridSim virtual environment, ii) on indoor and outdoor navigation\ntasks using our RovisLab AMTU (Autonomous Mobile Test Unit) platform and iii)\non a full scale autonomous test vehicle driving on public roads.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-02T03:46:37Z"}
{"aid":"http://arxiv.org/abs/2504.01341v1","title":"Uniform convergence to the equilibrium of the homogeneous\n  Boltzmann-Fermi-Dirac Equation with moderately soft potential","summary":"We concern the long-time behavior of mild solutions to the spatially\nhomogeneous Boltzmann--Fermi--Dirac equation with moderately soft potential.\nBased on the well-posedness results in [X-G. Lu, J. Stat. Phys., 105, (2001),\n353-388], we prove that the mild solution decays algebraically to the\nFermi--Dirac statistics with an explicit rate. Under the framework of the level\nset analysis by De Giorgi, we derive an $L^\\infty$ estimate which is uniform\nwith respect to the quantum parameter $\\varepsilon$. All quantitative estimates\nare independent of $\\varepsilon$, which implies that they also hold in the\nclassical limit, i.e., the Boltzmann equation.","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T04:10:34Z"}
{"aid":"http://arxiv.org/abs/2504.01367v1","title":"Enhancing Computational Notebooks with Code+Data Space Versioning","summary":"There is a gap between how people explore data and how Jupyter-like\ncomputational notebooks are designed. People explore data nonlinearly, using\nexecution undos, branching, and/or complete reverts, whereas notebooks are\ndesigned for sequential exploration. Recent works like ForkIt are still\ninsufficient to support these multiple modes of nonlinear exploration in a\nunified way. In this work, we address the challenge by introducing\ntwo-dimensional code+data space versioning for computational notebooks and\nverifying its effectiveness using our prototype system, Kishuboard, which\nintegrates with Jupyter. By adjusting code and data knobs, users of Kishuboard\ncan intuitively manage the state of computational notebooks in a flexible way,\nthereby achieving both execution rollbacks and checkouts across complex\nmulti-branch exploration history. Moreover, this two-dimensional versioning\nmechanism can easily be presented along with a friendly one-dimensional\nhistory. Human subject studies indicate that Kishuboard significantly enhances\nuser productivity in various data science tasks.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-02T05:26:51Z"}
{"aid":"http://arxiv.org/abs/2504.01374v1","title":"The Multifractal IP Address Structure: Physical Explanation and\n  Implications","summary":"The structure of IP addresses observed in Internet traffic plays a critical\nrole for a wide range of networking problems of current interest. For example,\nmodern network telemetry systems that take advantage of existing data plane\ntechnologies for line rate traffic monitoring and processing cannot afford to\nwaste precious data plane resources on traffic that comes from \"uninteresting\"\nregions of the IP address space. However, there is currently no\nwell-established structural model or analysis toolbox that enables a\nfirst-principles approach to the specific problem of identifying\n\"uninteresting\" regions of the address space or the myriad of other networking\nproblems that prominently feature IP addresses.\n  To address this key missing piece, we present in this paper a\nfirst-of-its-kind empirically validated physical explanation for why the\nobserved IP address structure in measured Internet traffic is multifractal in\nnature. Our root cause analysis overcomes key limitations of mostly forgotten\nfindings from ~20 years ago and demonstrates that the Internet processes and\nmechanisms responsible for how IP addresses are allocated, assigned, and used\nin today's Internet are consistent with and well modeled by a class of\nevocative mathematical models called conservative cascades. We complement this\nroot cause analysis with the development of an improved toolbox that is\ntailor-made for analyzing finite and discrete sets of IP addresses and includes\nstatistical estimators that engender high confidence in the inferences they\nproduce. We illustrate the use of this toolbox in the context of a novel\naddress structure anomaly detection method we designed and conclude with a\ndiscussion of a range of challenging open networking problems that are\nmotivated or inspired by our findings.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-02T05:36:10Z"}
{"aid":"http://arxiv.org/abs/2504.01376v1","title":"On the dual structure of the Schrödinger dynamics","summary":"This paper elucidates the dual structure of the Schr\\\"{o}dinger dynamics in\ntwo correlated stages: (1) We first derive the real-valued Schr\\\"{o}dinger\nequation from scratch without referring to classical mechanics, wave mechanics,\nnor optics, and thereby attain a concrete and clear interpretation of the\nSchr\\\"{o}dinger (wave) function. Beginning with a factorization of the density\ndistribution function of the particles to two component vectors in\nconfiguration space, we impose very simple conditions on them such as\ntranslational invariance of space-time and the conservation of flux under a\ngiven potential function. A real-valued path-integral is formulated as a Green\nfunction for the real-valued Schr\\\"{o}dinger equation. (2) We then study a\nquantum stochastic path dynamics in a manner compatible with the\nSchr\\\"{o}dinger equation. The relation between them is like the Langevin\ndynamics with the diffusion equation. Each quantum path describes a\n\\textquotedblleft trajectory\\textquotedblright\\ in configuration space\nrepresenting, for instance, a singly launched electron in the double-slit\nexperiment that leaves a spot one by one at the measurement board, while\naccumulated spots give rise to the fringe pattern as predicted by the absolute\nsquare of the Schr\\\"{o}dinger function. We start from the relationship between\nthe Ito stochastic differential equation, the Feynman-Kac formula, and the\nassociated parabolic partial differential equations, to one of which\\ the\nSchr\\\"{o}dinger equation is transformed. The physical significance of the\nquantum intrinsic stochasticity and the indirect correlation among the quantum\npaths and so on are discussed. The self-referential nonlinear interrelationship\nbetween the Schr\\\"{o}dinger functions (regarded as a whole) and the quantum\npaths (as its parts) is identified as the ultimate mystery in quantum dynamics.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T05:38:05Z"}
{"aid":"http://arxiv.org/abs/2504.01382v1","title":"An Illusion of Progress? Assessing the Current State of Web Agents","summary":"As digitalization and cloud technologies evolve, the web is becoming\nincreasingly important in the modern society. Autonomous web agents based on\nlarge language models (LLMs) hold a great potential in work automation. It is\ntherefore important to accurately measure and monitor the progression of their\ncapabilities. In this work, we conduct a comprehensive and rigorous assessment\nof the current state of web agents. Our results depict a very different picture\nof the competency of current agents, suggesting over-optimism in previously\nreported results. This gap can be attributed to shortcomings in existing\nbenchmarks. We introduce Online-Mind2Web, an online evaluation benchmark\nconsisting of 300 diverse and realistic tasks spanning 136 websites. It enables\nus to evaluate web agents under a setting that approximates how real users use\nthese agents. To facilitate more scalable evaluation and development, we also\ndevelop a novel LLM-as-a-Judge automatic evaluation method and show that it can\nachieve around 85% agreement with human judgment, substantially higher than\nexisting methods. Finally, we present the first comprehensive comparative\nanalysis of current web agents, highlighting both their strengths and\nlimitations to inspire future research.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-02T05:51:29Z"}
{"aid":"http://arxiv.org/abs/2504.01384v1","title":"On the efficient computation of Fourier coefficients of eta-quotients","summary":"We give formulas for computing efficiently the generalized Kloosterman sums\nappearing in the Hardy-Ramanujan-Rademacher expansions of the Fourier\ncoefficients of general eta-quotients given by Sussman and Chern, as well as\nexplicit bounds for the tails of these series.","main_category":"math.NT","categories":"math.NT","published":"2025-04-02T05:52:33Z"}
{"aid":"http://arxiv.org/abs/2504.01388v1","title":"(Non-)well-founded derivations in the provability logic $\\mathsf{GLP}$","summary":"We examine cyclic, non-well-founded and well-founded derivations in the\nprovability logic $\\mathsf{GLP}$. While allowing cyclic derivations does not\nchange the system, the non-well-founded and well-founded derivations we\nconsider define the same proper infinitary extension of $\\mathsf{GLP}$. We\nestablish that this extension is strongly algebraic and neighbourhood complete\nwith respect to both local and global semantic consequence relations. In fact,\nthese completeness results are proved for generalizations of global and local\nconsequence relations, which we call global-local. In addition, we prove strong\nlocal neighbourhood completeness for the original system $\\mathsf{GLP}$ (with\nordinary derivations only).","main_category":"math.LO","categories":"math.LO","published":"2025-04-02T06:00:05Z"}
{"aid":"http://arxiv.org/abs/2504.01394v1","title":"Double unstable avoided crossings and complex domain patterns formation\n  in spin-orbit coupled spin-1 condensates","summary":"We analyze the impact of spin-orbit and Rabi couplings on the dynamical\nstability of spin-orbit-coupled spin-1 Bose-Einstein condensates for\nferromagnetic (FM) and antiferromagnetic (AFM) interactions. Determining the\ncollective excitation spectrum through Bogoliubov-de-Gennes theory, we\ncharacterize the dynamical stability regime via modulational instability. For\nAFM interactions, the eigenspectrum reveals the presence of both stable and\nunstable avoided crossings (UAC), with the first-excited branch undergoing a\ndouble unstable avoided crossing. In contrast, with ferromagnetic interactions,\nonly a single UAC, which occurs between the low-lying and first-excited\nbranches, is observed. Furthermore, the eigenvectors demonstrate the transition\nfrom density-like to spin-like behaviour, as the collective excitation shows\nthe transition from stable to unstable mode for both the FM and AFM\ninteractions. In the multi-band instability state, eigenvectors display\nspin-density mixed mode, while they show spin-flip nature in the avoided\ncrossing regime. Our analysis suggests that spin-orbit coupling enhances the\ninstability gain, while Rabi coupling plays the opposite role. Finally, we\ncorroborate our analytical findings of stable and unstable regimes through\nnumerical simulations of the dynamical evolution of the condensates by\nintroducing the perturbations upon quenching the trap strength. The dynamical\nphases show the formation of complex domains with AFM interaction, which may be\nattributed to the double unstable avoided crossings in such a system.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas","published":"2025-04-02T06:19:52Z"}
{"aid":"http://arxiv.org/abs/2504.01395v1","title":"From Easy to Hard: Building a Shortcut for Differentially Private Image\n  Synthesis","summary":"Differentially private (DP) image synthesis aims to generate synthetic images\nfrom a sensitive dataset, alleviating the privacy leakage concerns of\norganizations sharing and utilizing synthetic images. Although previous methods\nhave significantly progressed, especially in training diffusion models on\nsensitive images with DP Stochastic Gradient Descent (DP-SGD), they still\nsuffer from unsatisfactory performance. In this work, inspired by curriculum\nlearning, we propose a two-stage DP image synthesis framework, where diffusion\nmodels learn to generate DP synthetic images from easy to hard. Unlike existing\nmethods that directly use DP-SGD to train diffusion models, we propose an easy\nstage in the beginning, where diffusion models learn simple features of the\nsensitive images. To facilitate this easy stage, we propose to use `central\nimages', simply aggregations of random samples of the sensitive dataset.\nIntuitively, although those central images do not show details, they\ndemonstrate useful characteristics of all images and only incur minimal privacy\ncosts, thus helping early-phase model training. We conduct experiments to\npresent that on the average of four investigated image datasets, the fidelity\nand utility metrics of our synthetic images are 33.1% and 2.1% better than the\nstate-of-the-art method.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-02T06:30:55Z"}
{"aid":"http://arxiv.org/abs/2504.01405v1","title":"Teaching Robots to Handle Nuclear Waste: A Teleoperation-Based Learning\n  Approach<","summary":"This paper presents a Learning from Teleoperation (LfT) framework that\nintegrates human expertise with robotic precision to enable robots to\nautonomously perform skills learned from human operators. The proposed\nframework addresses challenges in nuclear waste handling tasks, which often\ninvolve repetitive and meticulous manipulation operations. By capturing\noperator movements and manipulation forces during teleoperation, the framework\nutilizes this data to train machine learning models capable of replicating and\ngeneralizing human skills. We validate the effectiveness of the LfT framework\nthrough its application to a power plug insertion task, selected as a\nrepresentative scenario that is repetitive yet requires precise trajectory and\nforce control. Experimental results highlight significant improvements in task\nefficiency, while reducing reliance on continuous operator involvement.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-02T06:46:29Z"}
{"aid":"http://arxiv.org/abs/2504.01407v1","title":"TimeSearch: Hierarchical Video Search with Spotlight and Reflection for\n  Human-like Long Video Understanding","summary":"Large video-language models (LVLMs) have shown remarkable performance across\nvarious video-language tasks. However, they encounter significant challenges\nwhen processing long videos because of the large number of video frames\ninvolved. Downsampling long videos in either space or time can lead to visual\nhallucinations, making it difficult to accurately interpret long videos.\nMotivated by human hierarchical temporal search strategies, we propose\n\\textbf{TimeSearch}, a novel framework enabling LVLMs to understand long videos\nin a human-like manner. TimeSearch integrates two human-like primitives into a\nunified autoregressive LVLM: 1) \\textbf{Spotlight} efficiently identifies\nrelevant temporal events through a Temporal-Augmented Frame Representation\n(TAFR), explicitly binding visual features with timestamps; 2)\n\\textbf{Reflection} evaluates the correctness of the identified events,\nleveraging the inherent temporal self-reflection capabilities of LVLMs.\nTimeSearch progressively explores key events and prioritizes temporal search\nbased on reflection confidence. Extensive experiments on challenging long-video\nbenchmarks confirm that TimeSearch substantially surpasses previous\nstate-of-the-art, improving the accuracy from 41.8\\% to 51.5\\% on the LVBench.\nAdditionally, experiments on temporal grounding demonstrate that appropriate\nTAFR is adequate to effectively stimulate the surprising temporal grounding\nability of LVLMs in a simpler yet versatile manner, which improves mIoU on\nCharades-STA by 11.8\\%. The code will be released.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T06:47:19Z"}
{"aid":"http://arxiv.org/abs/2504.01408v1","title":"From Shadows to Safety: Occlusion Tracking and Risk Mitigation for Urban\n  Autonomous Driving","summary":"Autonomous vehicles (AVs) must navigate dynamic urban environments where\nocclusions and perception limitations introduce significant uncertainties. This\nresearch builds upon and extends existing approaches in risk-aware motion\nplanning and occlusion tracking to address these challenges. While prior\nstudies have developed individual methods for occlusion tracking and risk\nassessment, a comprehensive method integrating these techniques has not been\nfully explored. We, therefore, enhance a phantom agent-centric model by\nincorporating sequential reasoning to track occluded areas and predict\npotential hazards. Our model enables realistic scenario representation and\ncontext-aware risk evaluation by modeling diverse phantom agents, each with\ndistinct behavior profiles. Simulations demonstrate that the proposed approach\nimproves situational awareness and balances proactive safety with efficient\ntraffic flow. While these results underline the potential of our method,\nvalidation in real-world scenarios is necessary to confirm its feasibility and\ngeneralizability. By utilizing and advancing established methodologies, this\nwork contributes to safer and more reliable AV planning in complex urban\nenvironments. To support further research, our method is available as\nopen-source software at:\nhttps://github.com/TUM-AVS/OcclusionAwareMotionPlanning","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-02T06:48:50Z"}
{"aid":"http://arxiv.org/abs/2504.01415v1","title":"Systematic Literature Review of Automation and Artificial Intelligence\n  in Usability Issue Detection","summary":"Usability issues can hinder the effective use of software. Therefore, various\ntechniques are deployed to diagnose and mitigate them. However, these\ntechniques are costly and time-consuming, particularly in iterative design and\ndevelopment. A substantial body of research indicates that automation and\nartificial intelligence can enhance the process of obtaining usability\ninsights. In our systematic review of 155 publications, we offer a\ncomprehensive overview of the current state of the art for automated usability\nissue detection. We analyze trends, paradigms, and the technical context in\nwhich they are applied. Finally, we discuss the implications and potential\ndirections for future research.","main_category":"cs.HC","categories":"cs.HC,cs.SE","published":"2025-04-02T07:07:32Z"}
{"aid":"http://arxiv.org/abs/2504.01420v1","title":"FAIRE: Assessing Racial and Gender Bias in AI-Driven Resume Evaluations","summary":"In an era where AI-driven hiring is transforming recruitment practices,\nconcerns about fairness and bias have become increasingly important. To explore\nthese issues, we introduce a benchmark, FAIRE (Fairness Assessment In Resume\nEvaluation), to test for racial and gender bias in large language models (LLMs)\nused to evaluate resumes across different industries. We use two methods-direct\nscoring and ranking-to measure how model performance changes when resumes are\nslightly altered to reflect different racial or gender identities. Our findings\nreveal that while every model exhibits some degree of bias, the magnitude and\ndirection vary considerably. This benchmark provides a clear way to examine\nthese differences and offers valuable insights into the fairness of AI-based\nhiring tools. It highlights the urgent need for strategies to reduce bias in\nAI-driven recruitment. Our benchmark code and dataset are open-sourced at our\nrepository:\nhttps://github.com/athenawen/FAIRE-Fairness-Assessment-In-Resume-Evaluation.git.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-02T07:11:30Z"}
{"aid":"http://arxiv.org/abs/2504.01440v1","title":"Solving Time-Fractional Partial Integro-Differential Equations Using\n  Tensor Neural Networks","summary":"In this paper, we propose a novel machine learning method based on adaptive\ntensor neural network subspace to solve linear time-fractional diffusion-wave\nequations and nonlinear time-fractional partial integro-differential equations.\nIn this framework, the tensor neural network and Gauss-Jacobi quadrature are\neffectively combined to construct a universal numerical scheme for the temporal\nCaputo derivative with orders spanning $ (0,1)$ and $(1,2)$. Specifically, in\norder to effectively utilize Gauss-Jacobi quadrature to discretize Caputo\nderivatives, we design the tensor neural network function multiplied by the\nfunction $t^{\\mu}$ where the power $\\mu$ is selected according to the\nparameters of the equations at hand. Finally, some numerical examples are\nprovided to validate the efficiency and accuracy of the proposed tensor neural\nnetwork-based machine learning method.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T07:50:23Z"}
{"aid":"http://arxiv.org/abs/2504.01445v1","title":"Enabling Systematic Generalization in Abstract Spatial Reasoning through\n  Meta-Learning for Compositionality","summary":"Systematic generalization refers to the capacity to understand and generate\nnovel combinations from known components. Despite recent progress by large\nlanguage models (LLMs) across various domains, these models often fail to\nextend their knowledge to novel compositional scenarios, revealing notable\nlimitations in systematic generalization. There has been an ongoing debate\nabout whether neural networks possess the capacity for systematic\ngeneralization, with recent studies suggesting that meta-learning approaches\ndesigned for compositionality can significantly enhance this ability. However,\nthese insights have largely been confined to linguistic problems, leaving their\napplicability to other tasks an open question. In this study, we extend the\napproach of meta-learning for compositionality to the domain of abstract\nspatial reasoning. To this end, we introduce $\\textit{SYGAR}$-a dataset\ndesigned to evaluate the capacity of models to systematically generalize from\nknown geometric transformations (e.g., translation, rotation) of\ntwo-dimensional objects to novel combinations of these transformations (e.g.,\ntranslation+rotation). Our results show that a transformer-based\nencoder-decoder model, trained via meta-learning for compositionality, can\nsystematically generalize to previously unseen transformation compositions,\nsignificantly outperforming state-of-the-art LLMs, including o3-mini, GPT-4o,\nand Gemini 2.0 Flash, which fail to exhibit similar systematic behavior. Our\nfindings highlight the effectiveness of meta-learning in promoting\nsystematicity beyond linguistic tasks, suggesting a promising direction toward\nmore robust and generalizable models.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-02T07:56:39Z"}
{"aid":"http://arxiv.org/abs/2504.01447v1","title":"What KM3-230213A events may tell us about the neutrino mass and dark\n  matter","summary":"Within the framework of general $U(1)$ scenario, we demonstrate that the\nultra high energy neutrinos recently detected by KM3NeT could originate from a\ndecaying right handed neutrino dark matter (DM), with a mass of 440 PeV.\nConsidering DM production via freeze-in, we delineate the parameter space that\nsatisfies the observed relic abundance and also lies within the reach of\nmultiple gravitational wave detectors. Our study provides a testable new\nphysics scenario, enabled by multi-messenger astronomy.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO,astro-ph.HE","published":"2025-04-02T08:00:23Z"}
{"aid":"http://arxiv.org/abs/2504.01457v1","title":"Deep LG-Track: An Enhanced Localization-Confidence-Guided Multi-Object\n  Tracker","summary":"Multi-object tracking plays a crucial role in various applications, such as\nautonomous driving and security surveillance. This study introduces Deep\nLG-Track, a novel multi-object tracker that incorporates three key enhancements\nto improve the tracking accuracy and robustness. First, an adaptive Kalman\nfilter is developed to dynamically update the covariance of measurement noise\nbased on detection confidence and trajectory disappearance. Second, a novel\ncost matrix is formulated to adaptively fuse motion and appearance information,\nleveraging localization confidence and detection confidence as weighting\nfactors. Third, a dynamic appearance feature updating strategy is introduced,\nadjusting the relative weighting of historical and current appearance features\nbased on appearance clarity and localization accuracy. Comprehensive\nevaluations on the MOT17 and MOT20 datasets demonstrate that the proposed Deep\nLG-Track consistently outperforms state-of-the-art trackers across multiple\nperformance metrics, highlighting its effectiveness in multi-object tracking\ntasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T08:10:18Z"}
{"aid":"http://arxiv.org/abs/2504.01461v1","title":"Fate of Berezinskii-Kosterlitz-Thouless Paired Phase in Coupled $XY$\n  Models","summary":"Intriguing phases may emerge when two-dimensional systems are coupled in a\nbilayer configuration. In particular, a Berezinskii-Kosterlitz-Thouless (BKT)\npaired superfluid phase was predicted and claimed to be numerically observed in\na coupled $XY$ model with ferromagnetic interlayer interactions, as reported in\n[\\href{https://doi.org/10.1103/PhysRevLett.123.100601}{Phys. Rev. Lett. 123,\n100601 (2019)}]. However, both our Monte Carlo simulations and analytical\nanalysis show that this model does not exhibit a BKT paired phase. We then\npropose a new model incorporating four-body interlayer interactions to realize\nthe BKT paired phase. Moreover, we observe that the anomalous magnetic\ndimension varies along the phase transition line between the disordered normal\nphase and the BKT paired phase. This finding requires an understanding beyond\nthe conventional phase transition theory.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-02T08:17:51Z"}
{"aid":"http://arxiv.org/abs/2504.01465v1","title":"Photometry and Spectroscopy of the Symbiotic Binary V1413 Aquilae during\n  the 2024 Eclipse","summary":"We report our photometric and spectroscopic observations and analysis of the\n2024 eclipse of the symbiotic binary V1413 Aquilae. We found the system in a\nvisually bright state and the eclipse time of minimum consistent with the\npublished ephemeris. The eclipse profile showed that the hot component was an\nextended object rather than an isolated white dwarf. By analyzing the eclipse\nprofile we estimated the orbital inclination to be 67.9{\\deg}, the radius of\nthe extended hot component surrounding the white dwarf to be 39.3 Rsun, and\nthat the red giant star was probably filling its Roche Lobe. From our flux\ncalibrated spectra, we determined the brightest component of the system to be\nthe hot component whose continuum and emission lines together are responsible\nfor 83% of the V-band light. The circumbinary nebula and its emission lines\ncontribute over 14%, while the red giant is responsible for less than 3%. Our\nspectra revealed a rich harvest of low ionization emission lines. By measuring\nhow flux in these emission lines varied through the eclipse, we have provided\ninformation which should prove useful for future modelling of this symbiotic\nsystem.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-02T08:22:23Z"}
{"aid":"http://arxiv.org/abs/2504.01469v1","title":"Mechanisms of Dual-Band Emission in Sb-Doped Rare-Earth Phosphates\n  Revealed","summary":"The Sb$^{3+}$ ion has garnered significant interest due to its effectiveness\nin boosting the optical properties of host materials. Among the interesting\nphenomena is the commonly observed dual-band emission, which has often been\ninterpreted by adopting the phenomenological model that explains the dual-band\nemission (``ultraviolet band'' and ``visible band'') in Sb-doped $L$PO$_{4}$\n($L$ = Sc, Y, Lu). However, the model for Sb-doped $L$PO$_{4}$ series itself\nhas not been well understood theoretically. In this work, we employ\nfirst-principles calculations combined with group-theory analysis to clarify\nthe underlying physical mechanism behind dual-band emission in Sb-doped\n$L$PO$_{4}$ series. We demonstrate that the dual-band arises from two\nexcited-state equilibrium structures, one exhibits a relatively small\ndistortion with respect to the ground-state equilibrium structure, while the\nother displays a significantly larger distortion, characteristic of an\n``off-center'' configuration. The deviations from the ground-state\nconfiguration are dominated by two distinct vibrational modes, $b_2$ and $e$\nmodes, involving the Jahn-Teller effect and the pseudo Jahn-Teller effect,\nrespectively. Furthermore, charge transition levels and energy barriers\ncalculated using the climbing image nudged elastic band (CI-NEB) method have\naided in understanding the relaxation between the two excited-state\nconfigurations and the property changes across the Sc, Y, and Lu series. These\ninsights provide a basis for understanding the exotic properties of Sb$^{3+}$\nin other hosts and may facilitate the design of optical materials in a broader\nrange of systems involving Sb$^{3+}$ ions.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T08:23:34Z"}
{"aid":"http://arxiv.org/abs/2504.01470v1","title":"Detecting Lip-Syncing Deepfakes: Vision Temporal Transformer for\n  Analyzing Mouth Inconsistencies","summary":"Deepfakes are AI-generated media in which the original content is digitally\naltered to create convincing but manipulated images, videos, or audio. Among\nthe various types of deepfakes, lip-syncing deepfakes are one of the most\nchallenging deepfakes to detect. In these videos, a person's lip movements are\nsynthesized to match altered or entirely new audio using AI models. Therefore,\nunlike other types of deepfakes, the artifacts in lip-syncing deepfakes are\nconfined to the mouth region, making them more subtle and, thus harder to\ndiscern. In this paper, we propose LIPINC-V2, a novel detection framework that\nleverages a combination of vision temporal transformer with multihead\ncross-attention to detect lip-syncing deepfakes by identifying spatiotemporal\ninconsistencies in the mouth region. These inconsistencies appear across\nadjacent frames and persist throughout the video. Our model can successfully\ncapture both short-term and long-term variations in mouth movement, enhancing\nits ability to detect these inconsistencies. Additionally, we created a new\nlip-syncing deepfake dataset, LipSyncTIMIT, which was generated using five\nstate-of-the-art lip-syncing models to simulate real-world scenarios. Extensive\nexperiments on our proposed LipSyncTIMIT dataset and two other benchmark\ndeepfake datasets demonstrate that our model achieves state-of-the-art\nperformance. The code and the dataset are available at\nhttps://github.com/skrantidatta/LIPINC-V2 .","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T08:24:06Z"}
{"aid":"http://arxiv.org/abs/2504.01475v1","title":"Optimal Control of an Interconnected SDE -Parabolic PDE System","summary":"In this paper, we design a controller for an interconnected system where a\nlinear Stochastic Differential Equation (SDE) is actuated through a linear\nparabolic heat equation. These dynamics arise in various applications, such as\ncoupled heat transfer systems and chemical reaction processes that are subject\nto disturbances. Our goal is to develop a computational method for\napproximating the controller that minimizes a quadratic cost associated with\nthe state of the SDE component. To achieve this, we first perform a change of\nvariables to shift the actuation inside the PDE domain and reformulate the\nsystem as a linear Stochastic Partial Differential Equation (SPDE). We use a\nspectral approximation of the Laplacian operator to discretize the coupled\ndynamics into a finite-dimensional SDE and compute the optimal control for this\napproximated system. The resulting control serves as an approximation of the\noptimal control for the original system. We then establish the convergence of\nthe approximated optimal control and the corresponding closed-loop dynamics to\ntheir infinite-dimensional counterparts. Numerical simulations are provided to\nillustrate the effectiveness of our approach.","main_category":"math.AP","categories":"math.AP,math.OC","published":"2025-04-02T08:29:04Z"}
{"aid":"http://arxiv.org/abs/2504.01479v1","title":"Spectral theory of the Neumann-Poincaré operator associated with\n  multi-layer structures and analysis of plasmon mode splitting","summary":"In this paper, we develop a general mathematical framework for analyzing\nelectostatics within multi-layer metamaterial structures. The multi-layer\nstructure can be designed by nesting complementary negative and regular\nmaterials together, and it can be easily achieved by truncating bulk metallic\nmaterial in a specific configuration. Using layer potentials and symmetrization\ntechniques, we establish the perturbation formula in terms of\nNeumann-Poincar\\'e (NP) operator for general multi-layered medium, and obtain\nthe spectral properties of the NP operator, which demonstrates that the number\nof plasmon modes increases with the number of layers. Based on Fourier series,\nwe present an exact matrix representation of the NP operator in an apparently\nunsymmetrical structure, exemplified by multi-layer confocal ellipses. By\nhighly intricate and delicate analysis, we establish a handy algebraic\nframework for studying the splitting of the plasmon modes within multi-layer\nstructures. Moreover, the asymptotic profiles of the plasmon modes are also\nobtained. This framework helps reveal the effects of material truncation and\nrotational symmetry breaking on the splitting of the plasmon modes, thereby\ninducing desired resonances and enabling the realization of customized\napplications.","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T08:35:27Z"}
{"aid":"http://arxiv.org/abs/2504.01485v1","title":"Diameter Shortcut Sets on Temporal Graphs","summary":"Shortcut sets are a vital instrument for reducing the diameter of a static\ngraph and, consequently, its shortest path complexity, which is relevant in\nnumerous subfields of graph theory. We explore the notion of shortcut sets in\ntemporal graphs, which incorporate a discrete time model into the graph,\nrendering each edge accessible exclusively at specific points in time. This not\nonly alters the underlying assumptions of regular graphs but also substantially\nincreases the complexity of path problems and reachability. In turn, a temporal\ngraph is often a much more realistic and accurate representation of a\nreal-world network. In this thesis we provide a definition for a shortcut set\nin a temporal graph and explore differences to classic shortcut sets. Utilizing\nthis definition, we show that temporal and regular shortcut sets yield the same\nresults on temporal paths, enabling the application of existing construction\nalgorithms for static shortcut sets on paths. The primary contribution of this\nthesis is a translation approach for general temporal graphs that utilizes the\nstatic expansion of a temporal graph, allowing the conversion of static\nshortcut sets into temporal shortcut sets, yielding similar results.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-02T08:38:21Z"}
{"aid":"http://arxiv.org/abs/2504.01486v1","title":"Generalized Assignment and Knapsack Problems in the Random-Order Model","summary":"We study different online optimization problems in the random-order model.\nThere is a finite set of bins with known capacity and a finite set of items\narriving in a random order. Upon arrival of an item, its size and its value for\neach of the bins is revealed and it has to be decided immediately and\nirrevocably to which bin the item is assigned, or to not assign the item at\nall. In this setting, an algorithm is $\\alpha$-competitive if the total value\nof all items assigned to the bins is at least an $\\alpha$-fraction of the total\nvalue of an optimal assignment that knows all items beforehand. We give an\nalgorithm that is $\\alpha$-competitive with $\\alpha = (1-\\ln(2))/2 \\approx\n1/6.52$ improving upon the previous best algorithm with $\\alpha \\approx 1/6.99$\nfor the generalized assignment problem and the previous best algorithm with\n$\\alpha \\approx 1/6.65$ for the integral knapsack problem. We then study the\nfractional knapsack problem where we have a single bin and it is also allowed\nto pack items fractionally. For that case, we obtain an algorithm that is\n$\\alpha$-competitive with $\\alpha = 1/e \\approx 1/2.71$ improving on the\nprevious best algorithm with $\\alpha = 1/4.39$. We further show that this\ncompetitive ratio is the best-possible for deterministic algorithms in this\nmodel.","main_category":"cs.DS","categories":"cs.DS,math.OC","published":"2025-04-02T08:38:41Z"}
{"aid":"http://arxiv.org/abs/2504.01487v1","title":"Discrete stability estimates for the pressureless\n  Euler-Poisson-Boltzmann equations in the Quasi-Neutral limit","summary":"We propose and study a fully implicit finite volume scheme for the\npressureless Euler-Poisson-Boltzmann equations on the one dimensional torus.\nEspecially, we design a consistent and dissipative discretization of the force\nterm which yields an unconditional energy decay. In addition, we establish a\ndiscrete analogue of the modulated energy estimate around constant states with\na small velocity. Numerical experiments are carried to illustrate our\ntheoretical results and to assess the accuracy of our scheme. A test case of\nthe literature is also illustrated.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-02T08:39:02Z"}
{"aid":"http://arxiv.org/abs/2504.01492v1","title":"Nagaoka ferromagnetism in semiconductor artificial graphene","summary":"We present the emergence of Nagaoka ferromagnetism in semiconductor-based\nartificial graphene using high-precision variational and diffusion Monte Carlo\nmethods, complemented by exact diagonalization calculations of the extended\nHubbard model. Specifically, we analyze a realistic model of an armchair\nhexagonal geometry comprising $42$ lattice sites, nanopatterned on GaAs quantum\nwells with nearest-neighbor distance of $a = 50$ nm. Our results reveal a\ndistinct magnetic phase transition near $U/t \\approx 60$ driven by the\nabsence/addition of a single electron at half-filling where the ferromagnetic\nphase is further stabilized by Coulomb scattering terms.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.str-el","published":"2025-04-02T08:46:41Z"}
{"aid":"http://arxiv.org/abs/2504.01503v1","title":"Luminance-GS: Adapting 3D Gaussian Splatting to Challenging Lighting\n  Conditions with View-Adaptive Curve Adjustment","summary":"Capturing high-quality photographs under diverse real-world lighting\nconditions is challenging, as both natural lighting (e.g., low-light) and\ncamera exposure settings (e.g., exposure time) significantly impact image\nquality. This challenge becomes more pronounced in multi-view scenarios, where\nvariations in lighting and image signal processor (ISP) settings across\nviewpoints introduce photometric inconsistencies. Such lighting degradations\nand view-dependent variations pose substantial challenges to novel view\nsynthesis (NVS) frameworks based on Neural Radiance Fields (NeRF) and 3D\nGaussian Splatting (3DGS). To address this, we introduce Luminance-GS, a novel\napproach to achieving high-quality novel view synthesis results under diverse\nchallenging lighting conditions using 3DGS. By adopting per-view color matrix\nmapping and view-adaptive curve adjustments, Luminance-GS achieves\nstate-of-the-art (SOTA) results across various lighting conditions -- including\nlow-light, overexposure, and varying exposure -- while not altering the\noriginal 3DGS explicit representation. Compared to previous NeRF- and\n3DGS-based baselines, Luminance-GS provides real-time rendering speed with\nimproved reconstruction quality.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T08:54:57Z"}
{"aid":"http://arxiv.org/abs/2504.01505v1","title":"In-situ compression and shape recovery of Ceramic single grain\n  micro-pillar","summary":"Most ceramic materials are known for high fracture toughness while reacting\nhighly brittle to physical deformation. Some advancements were made by\nutilizing the transformation toughening effect of Yttria-doped Zirconia.\nHowever, finding a ceramic material demonstrating an effect analogous to the\nShape Memory Effect (SME) in certain metals, that also allows for superelastic\nresponses, remains a challenge. The underlying mechanism for SME and\nsuperelasticity is based on crystallographic variations within the material's\ngrains, requiring sophisticated electron microscopy techniques for direct\nobservation. The combination of a scanning electron microscope (SEM) with\nfocused ion beam (FIB) milling, a Kleindiek Nanotechnik GmbH micro-manipulator\nwith a 1.5 $\\mu$m diamond tip, and the ability to achieve in-situ heating up to\n450 {\\deg}C on a Kleindiek heating stage provides a robust platform for the\npreparation, deformation, and heating of micro-pillars made from ceramic\nmaterials. This setup enabled us to conduct detailed studies on the\nZirconia-based ceramic, observing permanent deformation exceeding 4% strain,\nfollowed by shape recovery at 370 {\\deg}C. The paper provides outlines the key\nexperimental steps that facilitated these observations.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T08:55:27Z"}
{"aid":"http://arxiv.org/abs/2504.01506v1","title":"MLKV: Efficiently Scaling up Large Embedding Model Training with\n  Disk-based Key-Value Storage","summary":"Many modern machine learning (ML) methods rely on embedding models to learn\nvector representations (embeddings) for a set of entities (embedding tables).\nAs increasingly diverse ML applications utilize embedding models and embedding\ntables continue to grow in size and number, there has been a surge in the\nad-hoc development of specialized frameworks targeted to train large embedding\nmodels for specific tasks. Although the scalability issues that arise in\ndifferent embedding model training tasks are similar, each of these frameworks\nindependently reinvents and customizes storage components for specific tasks,\nleading to substantial duplicated engineering efforts in both development and\ndeployment. This paper presents MLKV, an efficient, extensible, and reusable\ndata storage framework designed to address the scalability challenges in\nembedding model training, specifically data stall and staleness. MLKV augments\ndisk-based key-value storage by democratizing optimizations that were\npreviously exclusive to individual specialized frameworks and provides\neasy-to-use interfaces for embedding model training tasks. Extensive\nexperiments on open-source workloads, as well as applications in eBay's payment\ntransaction risk detection and seller payment risk detection, show that MLKV\noutperforms offloading strategies built on top of industrial-strength key-value\nstores by 1.6-12.6x. MLKV is open-source at https://github.com/llm-db/MLKV.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T08:57:01Z"}
{"aid":"http://arxiv.org/abs/2504.01511v1","title":"A computational framework for evaluating tire-asphalt hysteretic\n  friction including pavement roughness","summary":"Pavement surface textures obtained by a photogrammetry-based method for data\nacquisition and analysis are employed to investigate if related roughness\ndescriptors are comparable to the frictional performance evaluated by finite\nelement analysis. Pavement surface profiles are obtained from 3D digital\nsurface models created with Close-Range Orthogonal Photogrammetry. To\ncharacterize the roughness features of analyzed profiles, selected texture\nparameters were calculated from the profile's geometry. The parameters values\nwere compared to the frictional performance obtained by numerical simulations.\nContact simulations are performed according to a dedicated finite element\nscheme where surface roughness is directly embedded into a special class of\ninterface finite elements. Simulations were performed for different case\nscenarios and the obtained results showed a notable trend between roughness\ndescriptors and friction performance, indicating a promising potential for this\nnumerical method to be consistently employed to predict the frictional\nproperties of actual pavement surface profiles.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-02T08:58:31Z"}
{"aid":"http://arxiv.org/abs/2504.01517v1","title":"Cascade topologies in rare charm decays and implications for CP\n  violation","summary":"The CP violation observed in the hadronic decays of charmed mesons remains a\npuzzling open question for theorists. Calculations relying on the assumption of\ninelastic final-state interactions occurring between the pairs of pions and\nkaons fall short of the experimental value. It has been pointed out that a\nthird channel of four pions can leave imprints on the CP asymmetries of the\ntwo-body decays. At the same time, plenty of data are available for the $4\\pi$\ndecays of charmed mesons, as well as for the rare decays\n$D^0\\to\\pi^+\\pi^-\\ell^+\\ell^-$. With this motivation, we study the cascade\ntopology $D^0\\to a_1(1260)^+(\\to \\rho(770)^0\\pi^+)\\,\\pi^-$, which has been\nmeasured to contribute significantly to the $4\\pi$ decays, and estimate its\neffect on the branching ratio of the rare decays. We also explore the\npossibility of this topology contributing to the decay amplitude of\n$D^0\\to\\pi^+\\pi^-$ and by extension to the related CP asymmetry.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-02T09:03:15Z"}
{"aid":"http://arxiv.org/abs/2504.01518v1","title":"On 2-color partitions where one of the colors is multiples of $7^k$","summary":"In this work, we investigate the arithmetic properties of $p_{1,7^k}(n)$,\nwhich counts 2-color partitions of $n$ where one of the colors appears only in\nparts that are multiples of $7^k$. By constructing generating functions for\n$p_{1,7^k}(n)$ across specific arithmetic progressions, we establish a set of\nRamanujan-type infinite family of congruences modulo powers of $7$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-02T09:04:50Z"}
{"aid":"http://arxiv.org/abs/2504.01519v1","title":"Chain of Correction for Full-text Speech Recognition with Large Language\n  Models","summary":"Full-text error correction with Large Language Models (LLMs) for Automatic\nSpeech Recognition (ASR) has gained increased attention due to its potential to\ncorrect errors across long contexts and address a broader spectrum of error\ntypes, including punctuation restoration and inverse text normalization.\nNevertheless, many challenges persist, including issues related to stability,\ncontrollability, completeness, and fluency. To mitigate these challenges, this\npaper proposes the Chain of Correction (CoC) for full-text error correction\nwith LLMs, which corrects errors segment by segment using pre-recognized text\nas guidance within a regular multi-turn chat format. The CoC also uses\npre-recognized full text for context, allowing the model to better grasp global\nsemantics and maintain a comprehensive overview of the entire content.\nUtilizing the open-sourced full-text error correction dataset ChFT, we\nfine-tune a pre-trained LLM to evaluate the performance of the CoC framework.\nExperimental results demonstrate that the CoC effectively corrects errors in\nfull-text ASR outputs, significantly outperforming baseline and benchmark\nsystems. We further analyze how to set the correction threshold to balance\nunder-correction and over-rephrasing, extrapolate the CoC model on extremely\nlong ASR outputs, and investigate whether other types of information can be\nemployed to guide the error correction process.","main_category":"cs.CL","categories":"cs.CL,eess.AS","published":"2025-04-02T09:06:23Z"}
{"aid":"http://arxiv.org/abs/2504.01520v1","title":"Time-to-event prediction for grouped variables using Exclusive Lasso","summary":"The integration of high-dimensional genomic data and clinical data into\ntime-to-event prediction models has gained significant attention due to the\ngrowing availability of these datasets. Traditionally, a Cox regression model\nis employed, concatenating various covariate types linearly. Given that much of\nthe data may be redundant or irrelevant, feature selection through penalization\nis often desirable. A notable characteristic of these datasets is their\norganization into blocks of distinct data types, such as methylation and\nclinical predictors, which requires selecting a subset of covariates from each\ngroup due to high intra-group correlations. For this reason, we propose\nutilizing Exclusive Lasso regularization in place of standard Lasso\npenalization. We apply our methodology to a real-life cancer dataset,\ndemonstrating enhanced survival prediction performance compared to the\nconventional Cox regression model.","main_category":"stat.ME","categories":"stat.ME,stat.CO,stat.ML","published":"2025-04-02T09:07:05Z"}
{"aid":"http://arxiv.org/abs/2504.01534v1","title":"Context-Aware Toxicity Detection in Multiplayer Games: Integrating\n  Domain-Adaptive Pretraining and Match Metadata","summary":"The detrimental effects of toxicity in competitive online video games are\nwidely acknowledged, prompting publishers to monitor player chat conversations.\nThis is challenging due to the context-dependent nature of toxicity, often\nspread across multiple messages or informed by non-textual interactions.\nTraditional toxicity detectors focus on isolated messages, missing the broader\ncontext needed for accurate moderation. This is especially problematic in video\ngames, where interactions involve specialized slang, abbreviations, and typos,\nmaking it difficult for standard models to detect toxicity, especially given\nits rarity. We adapted RoBERTa LLM to support moderation tailored to video\ngames, integrating both textual and non-textual context. By enhancing\npretrained embeddings with metadata and addressing the unique slang and\nlanguage quirks through domain adaptive pretraining, our method better captures\nthe nuances of player interactions. Using two gaming datasets - from Defense of\nthe Ancients 2 (DOTA 2) and Call of Duty$^\\circledR$: Modern\nWarfare$^\\circledR$III (MWIII) we demonstrate which sources of context\n(metadata, prior interactions...) are most useful, how to best leverage them to\nboost performance, and the conditions conducive to doing so. This work\nunderscores the importance of context-aware and domain-specific approaches for\nproactive moderation.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T09:21:41Z"}
{"aid":"http://arxiv.org/abs/2504.01538v1","title":"AI-Newton: A Concept-Driven Physical Law Discovery System without Prior\n  Physical Knowledge","summary":"Current limitations in human scientific discovery necessitate a new research\nparadigm. While advances in artificial intelligence (AI) offer a highly\npromising solution, enabling AI to emulate human-like scientific discovery\nremains an open challenge. To address this, we propose AI-Newton, a\nconcept-driven discovery system capable of autonomously deriving physical laws\nfrom raw data -- without supervision or prior physical knowledge. The system\nintegrates a knowledge base and knowledge representation centered on physical\nconcepts, along with an autonomous discovery workflow. As a proof of concept,\nwe apply AI-Newton to a large set of Newtonian mechanics problems. Given\nexperimental data with noise, the system successfully rediscovers fundamental\nlaws, including Newton's second law, energy conservation and law of\ngravitation, using autonomously defined concepts. This achievement marks a\nsignificant step toward AI-driven autonomous scientific discovery.","main_category":"cs.AI","categories":"cs.AI,cs.LG,cs.SC,hep-ph,physics.class-ph","published":"2025-04-02T09:25:34Z"}
{"aid":"http://arxiv.org/abs/2504.01549v1","title":"Business Process Modeling Using a Metamodeling Approach","summary":"The thesis discusses topics related to the development of business process\nmanagement systems. Business process management systems have evolved on the\nbasis of workflow management systems through incremental inclusion of standard\ninformation system functions, for example, resource and client management. The\napplication of model driven development is required to deal with the complexity\nof business management systems and to increase development efficiency. In\ncontrast to conventional information systems, the behavior of business\nmanagement systems is strongly affected by the business models that they\nexecute. Thus, business process models also can be used for designing and\ndeveloping business management systems using sequentially applied model\ntransformations that adapt models to a specific execution platform.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-02T09:46:54Z"}
{"aid":"http://arxiv.org/abs/2504.01551v1","title":"Identifying Macro Causal Effects in C-DMGs","summary":"Causal effect identification using causal graphs is a fundamental challenge\nin causal inference. While extensive research has been conducted in this area,\nmost existing methods assume the availability of fully specified causal graphs.\nHowever, in complex domains such as medicine and epidemiology, complete causal\nknowledge is often unavailable, and only partial information about the system\nis accessible. This paper focuses on causal effect identification within\npartially specified causal graphs, with particular emphasis on cluster-directed\nmixed graphs (C-DMGs). These graphs provide a higher-level representation of\ncausal relationships by grouping variables into clusters, offering a more\npractical approach for handling complex systems. Unlike fully specified causal\ngraphs, C-DMGs can contain cycles, which complicate their analysis and\ninterpretation. Furthermore, their cluster-based nature introduces new\nchallenges, as it gives rise to two distinct types of causal effects, macro\ncausal effects and micro causal effects, with different properties. In this\nwork, we focus on macro causal effects, which describe the effects of entire\nclusters on other clusters. We establish that the do-calculus is both sound and\ncomplete for identifying these effects in C-DMGs. Additionally, we provide a\ngraphical characterization of non-identifiability for macro causal effects in\nthese graphs.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-02T09:48:27Z"}
{"aid":"http://arxiv.org/abs/2504.01563v1","title":"Height arguments toward the dynamical Mordell-Lang problem in arbitrary\n  characteristic","summary":"We use height arguments to prove two results about the dynamical Mordell-Lang\nproblem. We are more interested in the positive characteristic case due to our\noriginal purpose.\n  (i) For an endomorphism of a projective variety, the return set of a dense\norbit into a curve is finite if any cohomological Lyapunov exponent of any\niteration is not an integer.\n  (ii) Let $f\\times g:X\\times C\\rightarrow X\\times C$ be an endomorphism in\nwhich $f$ and $g$ are endomorphisms of a projective variety $X$ and a curve\n$C$, respectively. If the degree of $g$ is greater than the first dynamical\ndegree of $f$, then the return sets of the system $(X\\times C,f\\times g)$ have\nthe same form as the return sets of the system $(X,f)$.\n  Using the second result, we deal with the case of split endomorphisms of\nproducts of curves, for which the degrees of the factors are pairwise distinct.\n  In the cases that the height argument cannot be applied, we find examples\nwhich show that the return set can be very complicated -- more complicated than\nexperts once imagine -- even for endomorphisms of tori of zero entropy.","main_category":"math.DS","categories":"math.DS,math.AG,math.NT","published":"2025-04-02T10:04:14Z"}
{"aid":"http://arxiv.org/abs/2504.01572v1","title":"A microscopic calculation of fission cross sections with the\n  non-equilibrium Green function method","summary":"We apply the non-equilibrium Green function (NEGF) method to microscopically\nevaluate fission cross sections for the neutron induced $^{235}$U$(n,f)$\nreaction. While the model space was restricted only to seniority zero\nconfigurations in the previous applications of the NEGF method, we remove this\nrestriction and include seniority non-zero configurations as well. In such\nmodel space, a proton-neutron interaction is active, for which we introduce a\nrandom interaction. We find that the seniority non-zero configurations\nsignificantly increase the fission cross sections, and thus the\nfission-to-capture branching ratios, even though they are still underestimated\nby about one order of magnitude as compared to the experimental data. In\naddition, we also find that the fission dynamics is governed by only a small\nnumber of eigenstates of the model Hamiltonian.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-02T10:18:05Z"}
{"aid":"http://arxiv.org/abs/2504.01573v1","title":"Asymmetric VI-NES with dry friction: An impact map approach","summary":"This paper examines the dynamics of a vibro-impact nonlinear energy sink\n(VI-NES) using a generalized impact map approach. The study incorporates\nasymmetry and dry friction, reflecting realistic conditions. The proposed\nmethod identifies all periodic solutions and determines their stability, and is\napplicable to various VI-NES configurations, including horizontal and vertical\norientations. Numerical results validate prior findings for symmetric\nfrictionless cases and extend them to include frictional and asymmetric\ndynamics, providing a powerful tool for optimizing the performance of VI-NES in\nvibration mitigation.","main_category":"nlin.CD","categories":"nlin.CD","published":"2025-04-02T10:19:43Z"}
{"aid":"http://arxiv.org/abs/2504.01581v1","title":"Shape transitions of sedimenting confined droplets and capsules: from\n  oblate to bullet-like geometries","summary":"The transport and deformation of confined droplets and flexible capsules are\ncentral to diverse phenomena and applications, from biological flows in\nmicrocapillaries to industrial processes in porous media. We combine\nexperiments and numerical simulations to investigate their shape dynamics under\nvarying levels of confinement and particle flexibility. A transition from an\noblate to a bullet-like shape is observed at a confinement threshold,\nindependent of flexibility. A fluid-structure interaction analysis reveals two\nregimes: a pressure-dominated and a viscous-dominated regime. For highly\nflexible particles, the pressure-dominated regime prevails and the deformation\nis enhanced. These findings offer new insights into the transport of flexible\nparticles in confined environments, with implications for biomedical\napplications, filtration technologies, and multiphase fluid mechanics.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-02T10:38:07Z"}
{"aid":"http://arxiv.org/abs/2504.01589v1","title":"Text Speaks Louder than Vision: ASCII Art Reveals Textual Biases in\n  Vision-Language Models","summary":"Vision-language models (VLMs) have advanced rapidly in processing multimodal\ninformation, but their ability to reconcile conflicting signals across\nmodalities remains underexplored. This work investigates how VLMs process ASCII\nart, a unique medium where textual elements collectively form visual patterns,\npotentially creating semantic-visual conflicts. We introduce a novel evaluation\nframework that systematically challenges five state-of-the-art models\n(including GPT-4o, Claude, and Gemini) using adversarial ASCII art, where\ncharacter-level semantics deliberately contradict global visual patterns. Our\nexperiments reveal a strong text-priority bias: VLMs consistently prioritize\ntextual information over visual patterns, with visual recognition ability\ndeclining dramatically as semantic complexity increases. Various mitigation\nattempts through visual parameter tuning and prompt engineering yielded only\nmodest improvements, suggesting that this limitation requires\narchitectural-level solutions. These findings uncover fundamental flaws in how\ncurrent VLMs integrate multimodal information, providing important guidance for\nfuture model development while highlighting significant implications for\ncontent moderation systems vulnerable to adversarial examples.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T10:47:07Z"}
{"aid":"http://arxiv.org/abs/2504.01593v1","title":"Integrating experimental feedback improves generative models for\n  biological sequences","summary":"Generative probabilistic models have shown promise in designing artificial\nRNA and protein sequences but often suffer from high rates of false positives,\nwhere sequences predicted as functional fail experimental validation. To\naddress this critical limitation, we explore the impact of reintegrating\nexperimental feedback into the model design process. We propose a\nlikelihood-based reintegration scheme, which we test through extensive\ncomputational experiments on both RNA and protein datasets, as well as through\nwet-lab experiments on the self-splicing ribozyme from the group I intron RNA\nfamily where our approach demonstrates particular efficacy. We show that\nintegrating recent experimental data enhances the model's capacity of\ngenerating functional sequences (e.g. from 6.7\\% to 63.7\\% of active designs at\n45 mutations). This feedback-driven approach thus provides a significant\nimprovement in the design of biomolecular sequences by directly tackling the\nfalse-positive challenge.","main_category":"q-bio.BM","categories":"q-bio.BM,physics.bio-ph,q-bio.QM","published":"2025-04-02T10:57:53Z"}
{"aid":"http://arxiv.org/abs/2504.01594v1","title":"Anticipating Degradation: A Predictive Approach to Fault Tolerance in\n  Robot Swarms","summary":"An active approach to fault tolerance is essential for robot swarms to\nachieve long-term autonomy. Previous efforts have focused on responding to\nspontaneous electro-mechanical faults and failures. However, many faults occur\ngradually over time. Waiting until such faults have manifested as failures\nbefore addressing them is both inefficient and unsustainable in a variety of\nscenarios. This work argues that the principles of predictive maintenance, in\nwhich potential faults are resolved before they hinder the operation of the\nswarm, offer a promising means of achieving long-term fault tolerance. This is\na novel approach to swarm fault tolerance, which is shown to give a comparable\nor improved performance when tested against a reactive approach in almost all\ncases tested.","main_category":"cs.RO","categories":"cs.RO,cs.MA","published":"2025-04-02T10:59:10Z"}
{"aid":"http://arxiv.org/abs/2504.01598v1","title":"Expanding the Horizons of Phase Transition-Based Luminescence\n  Thermometry","summary":"The limited operational range of phase transition-based luminescence\nthermometers necessitates the exploration of new host materials exhibiting\nfirst-order structural phase transitions to broaden the applicability of this\napproach. Addressing this need, the present study investigates the\nspectroscopic properties of as a function of temperature. A thermally induced\nstructural transition from the low-temperature orthorhombic phase to the\nhigh-temperature trigonal phase, occurring at approximately 430 K,\nsignificantly alters the spectroscopic properties of Eu3 ions. Specifically, a\nreduction in the number of Stark lines due to changes in the point symmetry of\nEu3 ions enables the development of a ratiometric luminescence thermometer with\nsensitivity as high as K. Furthermore, it was demonstrated that increasing the\nconcentration of Eu3 ions shifts the phase transition temperature, allowing for\nmodulation of the thermometric performance of this luminescence thermometer.\nThe findings presented here not only expand the repertoire of phase\ntransition-based luminescence thermometers but also illustrate how the\nluminescence properties of Eu3 ions can be employed to accurately monitor\nstructural changes in the host material.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T11:05:57Z"}
{"aid":"http://arxiv.org/abs/2504.01605v1","title":"Multi-Relation Graph-Kernel Strengthen Network for Graph-Level\n  Clustering","summary":"Graph-level clustering is a fundamental task of data mining, aiming at\ndividing unlabeled graphs into distinct groups. However, existing deep methods\nthat are limited by pooling have difficulty extracting diverse and complex\ngraph structure features, while traditional graph kernel methods rely on\nexhaustive substructure search, unable to adaptive handle multi-relational\ndata. This limitation hampers producing robust and representative graph-level\nembeddings. To address this issue, we propose a novel Multi-Relation\nGraph-Kernel Strengthen Network for Graph-Level Clustering (MGSN), which\nintegrates multi-relation modeling with graph kernel techniques to fully\nleverage their respective advantages. Specifically, MGSN constructs\nmulti-relation graphs to capture diverse semantic relationships between nodes\nand graphs, which employ graph kernel methods to extract graph similarity\nfeatures, enriching the representation space. Moreover, a relation-aware\nrepresentation refinement strategy is designed, which adaptively aligns\nmulti-relation information across views while enhancing graph-level features\nthrough a progressive fusion process. Extensive experiments on multiple\nbenchmark datasets demonstrate the superiority of MGSN over state-of-the-art\nmethods. The results highlight its ability to leverage multi-relation\nstructures and graph kernel features, establishing a new paradigm for robust\ngraph-level clustering.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T11:17:15Z"}
{"aid":"http://arxiv.org/abs/2504.01607v1","title":"High-Chern-number Quantum anomalous Hall insulators in mixing-stacked\n  MnBi$_2$Te$_4$ thin films","summary":"Quantum anomalous Hall (QAH) insulators are characterized by vanishing\nlongitudinal resistance and quantized Hall resistance in the absence of an\nexternal magnetic field. Among them, high-Chern-number QAH insulators offer\nmultiple nondissipative current channels, making them crucial for the\ndevelopment of low-power-consumption electronics. Using first-principles\ncalculations, we propose that high-Chern-number ($C>1$) QAH insulators can be\nrealized in MnBi$_2$Te$_4$ (MBT) multilayer films through the combination of\nmixed stacking orders, eliminating the need for additional buffer layers. The\nunderlying physical mechanism is validated by calculating real-space-resolved\nanomalous Hall conductivity (AHC). Local AHC is found to be predominantly\nlocated in regions with consecutive correct stacking orders, contributing to\nquasi-quantized AHC. Conversely, regions with consecutive incorrect stacking\ncontribute minimally to the total AHC, which can be attributed to the varied\ninterlayer coupling in different stacking configurations. Our work provides\nvaluable insights into the design principle for achieving large Chern numbers,\nand highlights the role of stacking configurations in manipulating electronic\nand topological properties in MBT films and its derivatives.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-02T11:20:40Z"}
{"aid":"http://arxiv.org/abs/2504.01615v1","title":"The Mini-SiTian Array: A Pathfinder for the SiTian Project","summary":"The Mini-SiTian Array serves as a pathfinder for the SiTian project, which\naims to survey the entire sky in $gri$ bands every 30 minutes, reaching a\nlimiting magnitude of 21. This special issue features 11 papers covering the\ndesign, operation, data reduction, and early scientific results from two years\nof Mini-SiTian observations. The insights gained from these pathfinder\nexperiments represent a significant milestone toward the full realization of\nthe SiTian project.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-02T11:26:27Z"}
{"aid":"http://arxiv.org/abs/2504.01617v1","title":"The Mini-SiTian Array: Evaluation Camera System","summary":"The Mini-SiTian project, which is the pathfinder for the SiTian project,\nutilizes three 30 cm telescopes equipped with commercial CMOS cameras (ZWO\nASI6200MM Pro) to simulate large-area time-domain survey. Due to the avoidance\nof the traditional mechanical shutter, the CMOS camera is favorable in\ntime-domain survey projects. In the future, the SiTian telescope array will\nemploy a two-by-two scientific-grade mosaic CMOS camera to survey a\n10,000-degree square area every 30 minutes. Therefore, the performance of CMOS\ndirectly determines the detection capability of SiTian telescopes for transient\nsources, and a comprehensive understanding of the performance of CMOS cameras\nis crucial. In this research, laboratory testing was conducted to thoroughly\nevaluate three cameras by assessing several critical parameters, including bias\nstability, dark current, pixel anomalies, linearity, gain, and read noise. We\nfind exceptional short-term bias stability with standard deviations below 0.02\nADU, negligible dark current of approximately 0.002 e$^{-}$ pixel$^{-1}$\ns$^{-1}$ at $0^\\circ\\text{C}$, and excellent linearity with nonlinearity\nconsistently below $\\pm$ 0.5\\%, and a small proportion (0.06\\% to 0.08\\%) of\npixels with anomalous responses. Furthermore, our analysis demonstrates uniform\ngain values across all cameras, ranging from 0.252 to 0.255 e$^{-}$ ADU$^{-1}$,\nwith low readout noise, measured to be below 1.6 e$^{-}$ using conventional\nmethods. We also propose a novel method for pixel-level gain and read noise\ncalculation for CMOS sensors, which revealed a narrow gain distribution and a\nlow median read noise of 1.028 e$^-$ for one of the cameras. The laboratory\ntesting of the ZWO ASI6200MM Pro cameras indicates their potential to meet the\nrequirements of time-domain surveys for the Mini-SiTian project.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-02T11:26:32Z"}
{"aid":"http://arxiv.org/abs/2504.01621v1","title":"Two-photon microscopy using picosecond pulses from four-wave mixing in a\n  Yb-doped photonic crystal fiber","summary":"Two-photon microscopy (TPM) enables deep tissue imaging but requires\nexcitation pulses that have a large product of average and peak power,\ntypically supplied by femtosecond solid-state lasers. However, these lasers are\nbulky and femtosecond pulses require careful dispersion management to avoid\npulse broadening, particularly when delivery fibers are used. Here we present a\ncompact, fiber-based picosecond laser source operating at 790 nm for TPM using\na ytterbium-doped photonic crystal fiber (Yb-doped PCF). The Yb-doped PCF\nsimultaneously amplifies 1064 nm input pulses and efficiently converts them to\n790 nm via four-wave mixing, generating pulses with a peak power of up to ~3.8\nkW. The source has a variable repetition rate (1.48 MHz-14.78 MHz), enabling\nthe two-photon excitation fluorescence signal to be maximized in the presence\nof excitation saturation. We benchmark our picosecond laser source against a\nfemtosecond Ti:Sapphire laser for TPM of stained Convallaria majalis samples\nand demonstrate comparable fluorescence signal when the two-photon excitation\nconditions are matched.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-02T11:30:04Z"}
{"aid":"http://arxiv.org/abs/2504.01626v1","title":"NIR-to-NIR ratiometric and lifetime based luminescence thermometer on a\n  structural phase transition in Na3Sc2(PO4)3:Yb3+","summary":"The ratiometric approach is the most commonly employed readout technique in\nluminescence thermometry. To address the trade-off between the risk of\nmeasurement disturbance in thermometers with high spectral separation of\nemission bands (due to dispersion in the surrounding medium) and the low\nsensitivity observed in ratiometric thermometers based on Stark level\nthermalization, we propose a thermometer based on the structural phase\ntransition in . The use of Yb3+ ions as dopants and the changes in Stark level\nenergies associated with the thermally induced monoclinic-to-trigonal phase\ntransition enable the development of a thermometer with high relative\nsensitivity, achieving at 340K for N. Additionally, as demonstrated, the\nstructural transition alters the probability of radiative depopulation of the\n2F5/2 state of Yb3+, allowing the development of a lifetime-based luminescence\nthermometer. Furthermore, the phase transition temperature and consequently the\nthermometric performance of can be modulated by varying the Yb3+ ion\nconcentration, offering additional tunability for specific applications.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T11:32:02Z"}
{"aid":"http://arxiv.org/abs/2504.01628v1","title":"Copositive geometry of Feynman integrals","summary":"Copositive matrices and copositive polynomials are objects from optimization.\nWe connect these to the geometry of Feynman integrals in physics. The integral\nis guaranteed to converge if its kinematic parameters lie in the copositive\ncone. P\\'olya's method makes this manifest. We study the copositive cone for\nthe second Symanzik polynomial of any Feynman graph. Its algebraic boundary is\ndescribed by Landau discriminants.","main_category":"math.OC","categories":"math.OC,hep-th,math-ph,math.CO,math.MP","published":"2025-04-02T11:34:09Z"}
{"aid":"http://arxiv.org/abs/2504.01642v1","title":"Spanning clique subdivisions in pseudorandom graphs","summary":"In this paper, we study the appearance of a spanning subdivision of a clique\nin graphs satisfying certain pseudorandom conditions. Specifically, we show the\nfollowing three results. Firstly, that there are constants $C>0$ and $c\\in\n(0,1]$ such that, whenever $d/\\lambda\\ge C$, every $(n,d,\\lambda)$-graph\ncontains a spanning subdivision of $K_t$ for all $2\\le t \\le\n\\min\\{cd,c\\sqrt{\\frac{n}{\\log n}}\\}$. Secondly, that there are constants $C>0$\nand $c\\in (0,1]$ such that, whenever $d/\\lambda\\ge C\\log^3n$, every\n$(n,d,\\lambda)$-graph contains a spanning nearly-balanced subdivision of $K_t$\nfor all $2\\le t \\le \\min\\{cd,c\\sqrt{\\frac{n}{\\log^3n}}\\}$. Finally, we show\nthat for every $\\mu>0$, there are constants $c,\\varepsilon\\in (0,1]$ and\n$n_0\\in \\mathbb N$ such that, whenever $n\\ge n_0$, every $n$-vertex graph with\nminimum degree at least $\\mu n$ and no bipartite holes of size $\\varepsilon n$\ncontains a spanning nearly-balanced subdivision of $K_t$ for all $2\\le t \\le\nc\\sqrt{n}$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-02T11:46:24Z"}
{"aid":"http://arxiv.org/abs/2504.01658v1","title":"Scaling in Magnetic Neutron Scattering","summary":"We report the discovery of scaling in the mesoscale magnetic microstructure\nof bulk ferromagnets. Supported by analytical micromagnetic theory, we\nintroduce the field-dependent scaling length $l_{\\mathrm{C}}(H)$, which\ndescribes the characteristic long-wavelength magnetization fluctuations that\nare caused by microstructural defects by means of magnetoelastic and\nmagnetocrystalline anisotropy. The scaling length $l_{\\mathrm{C}}$ is\nidentified to consist of the micromagnetic exchange length of the field\n$l_{\\mathrm{H}}$, which depends on the magnetic interactions, and a\nfield-independent contribution that reflects the properties of the magnetic\nanisotropy field and the magnetostatic fluctuations. The latter finding is\nrooted in the convolution relationship between the grain microstructure and\nmicromagnetic response functions. We validated the scaling property by\nanalyzing experimental data for the magnetic neutron scattering cross section.\nWhen plotted as a function of the dimensionless scaled scattering vector\n$\\mathfrak{q}(H) = q \\, l_{\\mathrm{C}}(H)$, the field-dependent\namplitude-scaled neutron data of nanocrystalline Co and a Nd-Fe-B-based\nnanocomposite collapse onto a single master curve, demonstrating universal\nbehavior. The scaling length $l_{\\mathrm{C}}$ provides a framework for\nanalyzing the field-dependent neutron scattering cross section, highlighting\nthe existence of critical length scales that govern the mesoscale\nmicrostructure of magnetic materials.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-02T12:11:12Z"}
{"aid":"http://arxiv.org/abs/2504.01663v1","title":"Recovering Small Communities in the Planted Partition Model","summary":"We analyze community recovery in the planted partition model (PPM) in regimes\nwhere the number of communities is arbitrarily large. We examine the three\nstandard recovery regimes: exact recovery, almost exact recovery, and weak\nrecovery. When communities vary in size, traditional accuracy- or\nalignment-based metrics become unsuitable for assessing the correctness of a\npredicted partition. To address this, we redefine these recovery regimes using\nthe correlation coefficient, a more versatile metric for comparing partitions.\nWe then demonstrate that \\emph{Diamond Percolation}, an algorithm based on\ncommon-neighbors, successfully recovers communities under mild assumptions on\nedge probabilities, with minimal restrictions on the number and sizes of\ncommunities. As a key application, we consider the case where community sizes\nfollow a power-law distribution, a characteristic frequently found in\nreal-world networks. To the best of our knowledge, we provide the first\nrecovery results for such unbalanced partitions.","main_category":"math.PR","categories":"math.PR,cs.SI","published":"2025-04-02T12:14:57Z"}
{"aid":"http://arxiv.org/abs/2504.01666v1","title":"CLIP-SLA: Parameter-Efficient CLIP Adaptation for Continuous Sign\n  Language Recognition","summary":"Continuous sign language recognition (CSLR) focuses on interpreting and\ntranscribing sequences of sign language gestures in videos. In this work, we\npropose CLIP sign language adaptation (CLIP-SLA), a novel CSLR framework that\nleverages the powerful pre-trained visual encoder from the CLIP model to sign\nlanguage tasks through parameter-efficient fine-tuning (PEFT). We introduce two\nvariants, SLA-Adapter and SLA-LoRA, which integrate PEFT modules into the CLIP\nvisual encoder, enabling fine-tuning with minimal trainable parameters. The\neffectiveness of the proposed frameworks is validated on four datasets:\nPhoenix2014, Phoenix2014-T, CSL-Daily, and Isharah-500, where both CLIP-SLA\nvariants outperformed several SOTA models with fewer trainable parameters.\nExtensive ablation studies emphasize the effectiveness and flexibility of the\nproposed methods with different vision-language models for CSLR. These findings\nshowcase the potential of adapting large-scale pre-trained models for scalable\nand efficient CSLR, which pave the way for future advancements in sign language\nunderstanding.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T12:15:33Z"}
{"aid":"http://arxiv.org/abs/2504.01672v1","title":"A flexible framework for early power and timing comparison of\n  time-multiplexed CGRA kernel executions","summary":"At the intersection between traditional CPU architectures and more\nspecialized options such as FPGAs or ASICs lies the family of reconfigurable\nhardware architectures, termed Coarse-Grained Reconfigurable Arrays (CGRAs).\nCGRAs are composed of a 2-dimensional array of processing elements (PE),\ntightly integrated with each other, each capable of performing arithmetic and\nlogic operations. The vast design space of CGRA implementations poses a\nchallenge, which calls for fast exploration tools to prune it in advance of\ntime-consuming syntheses. The proposed tool aims to simplify this process by\nsimulating kernel execution and providing a characterization framework. The\nestimator returns energy and latency values otherwise only available through a\ntime-consuming post-synthesis simulation, allowing for instantaneous\ncomparative analysis between different kernels and hardware configurations.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-02T12:21:09Z"}
{"aid":"http://arxiv.org/abs/2504.01678v1","title":"Second-order cone programming for distributionally robust compliance\n  optimization of trusses considering input distribution uncertainty","summary":"Reliability-based design optimization (RBDO) is a methodology for designing\nstructures under the consideration for uncertainty with the assumption that the\ninput distribution is completely known. In practical engineering, the number of\ninput data is often limited, which can damage the validity of the optimal\nresults obtained by RBDO. Confidence-based design optimization (CBDO) has been\nproposed to account for the uncertainty of the input distribution. However,\nthis approach faces challenges, computational cost and accuracy when dealing\nwith highly nonlinear performance constraints. In this paper, we consider the\ncompliance minimization problem of truss structures with uncertain external\nforces. Armed with the advanced risk measure, conditional Value-at-Risk (CVaR),\nwe formulate a bi-objective optimization problem for the worst-case expected\nvalue and the worst-case CVaR of compliance, which allows us to account for the\ntail risk of performance functions not addressed in CBDO. Employing kernel\ndensity estimation for estimation of the input distribution allows us to\neliminate the need for modeling the input distribution. We show that this\nproblem reduces to a second-order cone programming when assigning either\nuniform kernel or triangular kernel. Finally, through numerical experiments, we\nobtain the Pareto front for the bi-objective optimization problem of the\nworst-case expected value and CVaR of compliance of truss structures, and\nconfirm the changes in the Pareto solutions.","main_category":"math.OC","categories":"math.OC","published":"2025-04-02T12:26:23Z"}
{"aid":"http://arxiv.org/abs/2504.01687v1","title":"Radiative Vlasov-Maxwell Equations","summary":"In the radiative Vlasov-Maxwell equations, the Lorentz force is modified by\nthe addition of radiation reaction forces. The radiation forces produce damping\nof particle energy but the forces are no longer divergence-free in momentum\nspace, which has an effect of concentration to zero momentum. We prove\nunconditional global regularity of solutions for a class of radiative\nVlasov-Maxwell equations with large initial data.","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T12:34:40Z"}
{"aid":"http://arxiv.org/abs/2504.01704v1","title":"Performance and applications of optical pin beams in turbulent\n  long-range free space optical communications","summary":"Optical pin beams (OPBs) are a promising candidate for realizing\nturbulence-resilient long-distance free-space optical communication links\nspanning hundreds of kilometers. In this work, we introduce a unified\ntheoretical model to describe the propagation of OPBs and present comprehensive\nsimulation results based on many realizations and link-budget analyses for\nconstant turbulence strengths. For reference, we compare the performance of the\nOPBs to weakly diverging and focusing Gaussian beams. For a 100km long\nair-to-air link, 10km above sea level, our simulation results show that OPBs\noffer an improved link budget of up to 8.6dB and enhanced beam wander\nstatistics of up to 3dB compared to the considered Gaussian beams.\nAdditionally, we identified a quadratic relationship between the transmitter\naperture diameter and the maximum achievable distances, which is crucial in\ndeciding the suitability of OPBs for a given application scenario.","main_category":"physics.optics","categories":"physics.optics,physics.ao-ph","published":"2025-04-02T13:07:13Z"}
{"aid":"http://arxiv.org/abs/2504.01709v1","title":"How chiral vibrations drive molecular rotation","summary":"We analyze two simple model planar molecules: an ionic molecule with D3\nsymmetry and a covalent molecule with D6 symmetry. Both symmetries allow the\nexistence of chiral molecular orbitals and normal modes that are coupled to\neach other in a Jahn-Teller manner, invariant under U (1) symmetry with\ngenerator a pseudo angular momentum. In the ionic molecule, the chiral mode\npossesses an electric dipole but lacks physical angular momentum, whereas, in\nthe covalent molecule, the situation is reversed. In spite of that, we show\nthat in both cases the chiral modes can be excited by a circularly polarized\nlight and are subsequently able to induce rotational motion of the entire\nmolecule. We further discuss the potential extension of our findings to the\ncase of crystalline bulk samples.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-02T13:15:59Z"}
{"aid":"http://arxiv.org/abs/2504.01720v1","title":"Input-Erasing Two-Way Finite Automata","summary":"The present paper introduces and studies an alternative concept of two-way\nfinite automata called input-erasing two-way finite automata. Like the original\nmodel, these new automata can also move the reading head freely left or right\non the input tape. However, each time they read a symbol, they also erase it\nfrom the tape. The paper demonstrates that these automata define precisely the\nfamily of linear languages and are thus strictly stronger than the original\nones. Furthermore, it introduces a variety of restrictions placed upon these\nautomata and the way they work and investigates the effect of these\nrestrictions on their acceptance power. In particular, it explores the mutual\nrelations of language families resulting from some of these restrictions and\nshows that some of them reduce the power of these automata to that of even\nlinear grammars or even ordinary finite automata.","main_category":"cs.FL","categories":"cs.FL","published":"2025-04-02T13:28:01Z"}
{"aid":"http://arxiv.org/abs/2504.01733v1","title":"Epistemic Skills: Reasoning about Knowledge and Oblivion","summary":"This paper presents a class of epistemic logics that captures the dynamics of\nacquiring knowledge and descending into oblivion, while incorporating concepts\nof group knowledge. The approach is grounded in a system of weighted models,\nintroducing an ``epistemic skills'' metric to represent the epistemic\ncapacities tied to knowledge updates. Within this framework, knowledge\nacquisition is modeled as a process of upskilling, whereas oblivion is\nrepresented as a consequence of downskilling. The framework further enables\nexploration of ``knowability'' and ``forgettability,'' defined as the potential\nto gain knowledge through upskilling and to lapse into oblivion through\ndownskilling, respectively. Additionally, it supports a detailed analysis of\nthe distinctions between epistemic de re and de dicto expressions. The\ncomputational complexity of the model checking and satisfiability problems is\nexamined, offering insights into their theoretical foundations and practical\nimplications.","main_category":"cs.AI","categories":"cs.AI,cs.CC,cs.LO","published":"2025-04-02T13:41:42Z"}
{"aid":"http://arxiv.org/abs/2504.01735v1","title":"AdPO: Enhancing the Adversarial Robustness of Large Vision-Language\n  Models with Preference Optimization","summary":"Large Vision-Language Models (LVLMs), such as GPT-4o and LLaVA, have recently\nwitnessed remarkable advancements and are increasingly being deployed in\nreal-world applications. However, inheriting the sensitivity of visual neural\nnetworks, LVLMs remain vulnerable to adversarial attacks, which can result in\nerroneous or malicious outputs. While existing efforts utilize adversarial\nfine-tuning to enhance robustness, they often suffer from performance\ndegradation on clean inputs. In this paper, we proposes AdPO, a novel\nadversarial defense strategy for LVLMs based on preference optimization. For\nthe first time, we reframe adversarial training as a preference optimization\nproblem, aiming to enhance the model's preference for generating normal outputs\non clean inputs while rejecting the potential misleading outputs for\nadversarial examples. Notably, AdPO achieves this by solely modifying the image\nencoder, e.g., CLIP ViT, resulting in superior clean and adversarial\nperformance in a variety of downsream tasks. Considering that training involves\nlarge language models (LLMs), the computational cost increases significantly.\nWe validate that training on smaller LVLMs and subsequently transferring to\nlarger models can achieve competitive performance while maintaining efficiency\ncomparable to baseline methods. Our comprehensive experiments confirm the\neffectiveness of the proposed AdPO, which provides a novel perspective for\nfuture adversarial defense research.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T13:43:21Z"}
{"aid":"http://arxiv.org/abs/2504.01743v1","title":"High Dimensional Bayesian Optimization using Lasso Variable Selection","summary":"Bayesian optimization (BO) is a leading method for optimizing expensive\nblack-box optimization and has been successfully applied across various\nscenarios. However, BO suffers from the curse of dimensionality, making it\nchallenging to scale to high-dimensional problems. Existing work has adopted a\nvariable selection strategy to select and optimize only a subset of variables\niteratively. Although this approach can mitigate the high-dimensional challenge\nin BO, it still leads to sample inefficiency. To address this issue, we\nintroduce a novel method that identifies important variables by estimating the\nlength scales of Gaussian process kernels. Next, we construct an effective\nsearch region consisting of multiple subspaces and optimize the acquisition\nfunction within this region, focusing on only the important variables. We\ndemonstrate that our proposed method achieves cumulative regret with a\nsublinear growth rate in the worst case while maintaining computational\nefficiency. Experiments on high-dimensional synthetic functions and real-world\nproblems show that our method achieves state-of-the-art performance.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T13:54:04Z"}
{"aid":"http://arxiv.org/abs/2504.01745v1","title":"Characterising galaxy cluster scaling relations as cosmic isotropy\n  tracers using the FLAMINGO simulations","summary":"The standard cosmological model, $\\Lambda$CDM, assumes isotropy on large\ncosmic scales. However, recent studies using galaxy cluster scaling relations\nreported an apparent $H_0$ anisotropy at $5.4\\sigma$ that could be attributed\nto large bulk flows extending beyond $500\\,\\mathrm{Mpc}$, in disagreement with\n$\\Lambda$CDM. To quantify the statistical tension of the observational galaxy\ncluster data used in past studies with $\\Lambda$CDM, we utilise the isotropic\n($2.8\\,\\mathrm{Gpc})^3$ run of the FLAMINGO ($\\Lambda$CDM) simulations, the\nlargest hydrodynamical cosmological simulation available to date. We create\n1728 simulated lightcones and study the apparent level of anisotropy traced by\nX-ray and thermal Sunyaev-Zeldovich scaling relations in the same cluster\nsample selection and methodology as in Migkas et al. (2021, arXiv:2103.13904).\nWe find the probability of such apparent anisotropies randomly emerging in\ncluster scaling relations within a $\\Lambda$CDM universe to be $0.12\\%\\,\n(3.2\\sigma)$. The discrepancy goes up to $\\sim 3.6\\sigma$ when modelled as a\nbulk flow at $z < 0.1$. We find that statistical noise accounts for over $80\\%$\nof the anisotropy amplitude in each lightcone, with large peculiar velocities\ncontributing less than $20\\%$. We also show that anisotropy amplitudes are\nhighly sensitive to the intrinsic scatter in the scaling relations, with\ntighter relations providing stronger constraints. Nevertheless, the tension\nbetween Migkas et al. (2021, arXiv:2103.13904) and $\\Lambda$CDM persists,\nhowever, at a lower significance than previously reported.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-02T13:55:14Z"}
{"aid":"http://arxiv.org/abs/2504.01751v1","title":"Cyanine-Conjugated Gold Nanospheres for Near-infrared Fluorescence","summary":"Near-infrared fluorescence imaging offers improved spatial precision by\nreducing light scattering and absorption in tissue. Despite this key advantage,\nthe NIR region is limited by the availability of fluorophores, most of which\nexhibit relatively low quantum yield. In this study, gold nanospheres with\nabsorption peaks in the visible range were used to enhance the fluorescence\nintensity of the cyanine NIR fluorophore IRdye 800 in the first NIR window of\nthe electromagnetic spectrum. AuNSs with diameters ranging from 5 to 25 nm were\nchosen to investigate the impact of a nanoparticle size on fluorescence\nenhancement, functionalized with polyethylene glycol of varying molecular\nweights to optimize the distance between the fluorophore and the nanoparticle\nsurface. Theoretical analyses using finite-difference time-domain simulations\nand experimental comparisons with non-metallic nanoparticles were performed to\nidentify the factors contributing to the enhancement of fluorescence. PEGylated\nAuNSs conjugated with IRdye 800 (AuNDs) exhibited decreased photoisomerization,\nresulting in increased fluorescence intensity and altered fluorescence\nlifetimes. The observed enhancement in the fluorescence intensity of the AuNDs\nwas attributed to three primary mechanisms: metal-enhanced fluorescence,\naltered radiative decay rates, and steric stabilization. Among these three\nmechanisms, two are attributed to the tail-end absorption spectral overlap of\nthe AuNSs with IRdye 800. This study highlights the potential of AuNSs for\nimproving NIR-I fluorescence imaging and opens up new possibilities for\napplications in biomedical research.","main_category":"physics.optics","categories":"physics.optics,physics.chem-ph","published":"2025-04-02T14:03:37Z"}
{"aid":"http://arxiv.org/abs/2504.01758v1","title":"Isospin asymmetry and neutron stars in V-QCD","summary":"Isospin asymmetric nuclear matter is introduced to V-QCD, a bottom-up\nholographic Quantum Chromodynamics (QCD) model. Using a small isospin chemical\npotential we extract the symmetry energy in the model, finding excellent\nagreement with experimental results for some of the potentials. Extending the\ncalculation for finite and arbitrary sized isospin chemical potentials, we\nconstruct beta-equilibrated neutron stars via the usual\nTolman-Oppenheimer-Volkov (TOV) equations. We find, pleasingly, that the\nneutron stars passing the mass/radius and tidal deformability constraints are\nthose with the potentials that also lead to excellent symmetry energies.","main_category":"hep-ph","categories":"hep-ph,hep-th,nucl-th","published":"2025-04-02T14:15:12Z"}
{"aid":"http://arxiv.org/abs/2504.01760v1","title":"Compact Group Homeomorphisms Preserving The Haar Measure","summary":"This paper studies the measure-preserving homeomorphisms on compact groups\nand proposes new methods for constructing measure-preserving homeomorphisms on\ndirect products of compact groups and non-commutative compact groups.\n  On the direct product of compact groups, we construct measure-preserving\nhomeomorphisms using the method of integration. In particular, by applying this\nmethod to the \\(n\\)-dimensional torus \\({\\mathbb{T}}^{n}\\), we can construct\nmany new examples of measure-preserving homeomorphisms. We completely\ncharacterize the measure-preserving homeomorphisms on the two-dimensional torus\nwhere one coordinate is a translation depending on the other coordinate, and\ngeneralize this result to the \\(n\\)-dimensional torus.\n  For non-commutative compact groups, we generalize the concept of the\nnormalizer subgroup \\(N\\left( H\\right)\\) of the subgroup \\(H\\) to the\nnormalizer subset \\({E}_{K}( P)\\) from the subset \\(K\\) to the subset \\(P\\) of\nthe group of measure-preserving homeomorphisms. We prove that if \\(\\mu\\) is the\nunique \\(K\\)-invariant measure, then the elements in \\({E}_{K}\\left( P\\right)\\)\nalso preserve \\(\\mu\\). In some non-commutative compact groups the normalizer\nsubset \\({E}_{G}\\left( {\\mathrm{{AF}}\\left( G\\right) }\\right)\\) can give\nnon-affine homeomorphisms that preserve the Haar measure. Finally, we prove\nthat when \\(G\\) is a finite cyclic group and a \\(n\\)-dimensional torus, then\n\\(\\mathrm{{AF}}\\left( G\\right)= N\\left( G\\right) = {E}_{G}\\left(\n{\\mathrm{{AF}}\\left( G\\right) }\\right)\\).","main_category":"math.DS","categories":"math.DS","published":"2025-04-02T14:16:29Z"}
{"aid":"http://arxiv.org/abs/2504.01769v1","title":"Operator aspects of wave propagation through periodic media","summary":"Recent results in quantitative homogenisation of the wave equation with\nrapidly oscillating coefficients are discussed from the operator-theoretic\nperspective, which views the solution as the result of applying the operator of\nhyperbolic dynamics, i.e. the unitary group of a self-adjoint operator on a\nsuitable Hilbert space. A prototype one-dimensional example of utilising the\nframework of Ryzhov boundary triples is analysed, where operator-norm resolvent\nestimates for the problem of classical moderate-contrast homogenisation are\nobtained. By an appropriate \"dilation\" procedure, these are shown to upgrade to\nsecond-order (and more generally, higher-order) estimates for the resolvent and\nthe unitary group describing the evolution for the related wave equation.","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T14:26:48Z"}
{"aid":"http://arxiv.org/abs/2504.01772v1","title":"Adaptation of Moreau-Yosida regularization to the modulus of convexity","summary":"We study a generalization of Moreau-Yosida regularization that is adapted to\nthe geometry of Banach spaces where the dual space is uniformly convex with\nmodulus of convexity of power type. Important properties for regularized convex\nfunctions are given, in particular strong monotonicity of the subdifferential\nof their convex conjugate and H\\\"older-continuity of their gradient.","main_category":"math.FA","categories":"math.FA,math-ph,math.MP","published":"2025-04-02T14:31:08Z"}
{"aid":"http://arxiv.org/abs/2504.01776v1","title":"Hydrodynamic simulations of the Disc of Gas Around Supermassive black\n  holes (HDGAS) -II; The transition from neutral atomic to molecular gas phases","summary":"We use HDGAS hydrodynamic simulations to study the impact of active galactic\nnucleus (AGN) feedback on the conversion of atomic-gas to molecular-gas within\nthe circumnuclear-disc (CND) of a typical AGN-dominated galaxy. The comparison\nof CI, CII, and CO line intensities and their ratios in the HDGAS\npost-processing radiative-transfer analysis reveals the complex interplay\nbetween AGN-activity, cold molecular gas properties, and the physical processes\ngoverning the evolution of star-formation in galaxies. Our results demonstrate\nthat the CI/CO intensity ratio serves as a reliable indicator of the\natomic-to-molecular gas transition. We present the probability distribution\nfunction (PDF) and abundance trends of various metal species related to\nmolecular H$2$ gas, highlighting differences in clumpiness and intensity maps\nbetween AGN feedback and NoAGN models. The profile of the integrated intensity\n(moment-0) maps shows that the AGN-feedback model exhibits a lower CI/CO\nintensity ratio in the vicinity of the supermassive black hole (< 50 pc),\nindicating a smaller atomic-gas abundance and the presence of positive\nAGN-feedback. Our simulations have successfully predicted the presence of\nfaint-CO emissions extending to larger radii from the galactic center. We also\nexplore the relationships between CII/CO and CI/CII intensity ratios, as well\nas the ratios versus CO intensity, which provides insights into the \"CO-dark\"\nissues. One notable feature in the later time-scale of the AGN model is the\npresence of a \"CO-dark\" region, where the intensity of CO emission ($\\rm\nI_{CO}$) is depleted relative to the H$_2$ column density ($N_{\\rm H_2}$)\ncompared to the NoAGN model.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-02T14:38:45Z"}
{"aid":"http://arxiv.org/abs/2504.01781v1","title":"Proper scoring rules for estimation and forecast evaluation","summary":"Proper scoring rules have been a subject of growing interest in recent years,\nnot only as tools for evaluation of probabilistic forecasts but also as methods\nfor estimating probability distributions. In this article, we review the\nmathematical foundations of proper scoring rules including general\ncharacterization results and important families of scoring rules. We discuss\ntheir role in statistics and machine learning for estimation and forecast\nevaluation. Furthermore, we comment on interesting developments of their usage\nin applications.","main_category":"math.ST","categories":"math.ST,stat.ML,stat.TH","published":"2025-04-02T14:46:14Z"}
{"aid":"http://arxiv.org/abs/2504.01784v1","title":"Optimized Schwarz method for the Stokes-Darcy problem with generalized\n  interface conditions","summary":"Due to their wide appearance in environmental settings as well as industrial\nand medical applications, the Stokes-Darcy problems with different sets of\ninterface conditions establish an active research area in the community of\nmathematical modelers and computational scientists. For numerical simulation of\nsuch coupled problems in applications, robust and efficient computational\nalgorithms are needed. In this work, we consider a generalization of the\nBeavers-Joseph interface condition recently developed using homogenization and\nboundary layer theory. This extension is applicable not only for the parallel\nflows to the fluid-porous interface as its predecessor, but also for arbitrary\nflow directions. To solve the Stokes-Darcy problem with these generalized\ninterface conditions efficiently, we develop and analyze a Robin-Robin domain\ndecomposition method using Fourier analysis to identify optimal weights in the\nRobin interface conditions. We study efficiency and robustness of the proposed\nmethod and provide numerical simulations which confirm the obtained theoretical\nresults.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-02T14:48:28Z"}
{"aid":"http://arxiv.org/abs/2504.01808v1","title":"Coloring of graphs without long odd holes","summary":"A {\\em hole} is an induced cycle of length at least 4, a $k$-hole is a hole\nof length $k$, and an {\\em odd hole} is a hole of odd length. Let $\\ell\\ge 2$\nbe an integer. Let ${\\cal A}_{\\ell}$ be the family of graphs of girth at least\n$2\\ell$ and having no odd holes of length at least $2\\ell+3$, let ${\\cal\nB}_{\\ell}$ be the triangle-free graphs which have no 5-holes and no odd holes\nof length at least $2\\ell+3$, and let ${\\cal G}_{\\ell}$ be the family of graphs\nof girth $2\\ell+1$ and have no odd hole of length at least $2\\ell+5$.\nChudnovsky {\\em et al.} \\cite{CSS2016} proved that every graph in ${\\cal\nA}_{2}$ is 58000-colorable, and every graph in ${\\cal B}_{\\ell}$ is\n$(\\ell+1)4^{\\ell-1}$-colorable. Lan and liu \\cite{LL2023} showed that for\n$\\ell\\geq3$, every graph in ${\\cal G}_{\\ell}$ is 4-colorable. It is not known\nwhether there exists a small constant $c$ such that graphs of ${\\cal G}_2$ are\n$c$-colorable. In this paper, we show that every graph in ${\\cal G}_2$ is\n1456-colorable, and every graph in ${\\cal A}_{3}$ is 4-colorable. We also show\nthat every 7-hole free graph in ${\\cal B}_{\\ell}$ is $(12\\ell+8)$-colorable.","main_category":"math.CO","categories":"math.CO","published":"2025-04-02T15:12:42Z"}
{"aid":"http://arxiv.org/abs/2504.01815v1","title":"Multiplexed Control at Scale for Electrode Arrays in Trapped-Ion Quantum\n  Processors","summary":"The scaling up of trapped-ion quantum processors based on the quantum\ncharge-coupled device (QCCD) architecture is difficult owing to the extensive\nelectronics and high-density wiring required to control numerous trap\nelectrodes. In conventional QCCD architectures, each trap electrode is\ncontrolled via a dedicated digital-to-analog converter (DAC). The conventional\napproach places an overwhelming demand on electronic resources and wiring\ncomplexity. This is because the number of trap electrodes typically exceeds the\nnumber of trapped-ion qubits. This study proposes a method that leverages a\nhigh-speed DAC to generate time-division multiplexed signals to control a\nlarge-scale QCCD trapped-ion quantum processor. The proposed method replaces\nconventional DACs with a single high-speed DAC that generates the complete\nvoltage waveforms required to control the trap electrodes, thereby\nsignificantly reducing the wiring complexity and overall resource requirements.\nBased on realistic parameters and commercially available electronics, our\nanalysis demonstrates that a QCCD trapped-ion quantum computer with 10,000 trap\nelectrodes can be controlled using only 13 field-programmable gate arrays and\n104 high-speed DACs. This is in stark contrast to the 10,000 dedicated DACs\nrequired by conventional control methods. Consequently, employing this\napproach, we developed a proof-of-concept electronic system and evaluated its\nanalog output performance.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T15:21:31Z"}
{"aid":"http://arxiv.org/abs/2504.01817v1","title":"Multi-actuator lens systems for turbulence correction in free-space\n  optical communications","summary":"The implementation of efficient free-space channels is fundamental for both\nclassical and quantum Free-Space Optical (FSO) communication. This can be\nchallenging for fibre-coupled receivers, due to the time variant inhomogeneity\nof the refractive index that can cause strong fluctuations in the power coupled\ninto the Single-Mode Fiber (SMF), and requires the use of Adaptive Optics (AO)\nsystems to correct the atmospheric induced aberrations. In this work, we\npresent two adaptive optic systems, one using a Fast-Steering Prism (FSP) for\nthe correction of tip-tilt and a second one based on a Multi-Actuator\ndeformable Lens (MAL), capable of correcting up to the third order of Zernike's\npolynomials. We test both systems at telecom wavelength both with artificial\nturbulence in the laboratory and on a free-space channel, demonstrating their\neffectiveness in increasing the fibre coupling efficiency.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-02T15:21:58Z"}
{"aid":"http://arxiv.org/abs/2504.01823v1","title":"Evidence of doubly OZI-suppressed decay $η_{c} \\to ωφ$ in the\n  radiative decay $J/ψ\\to γη_{c}$","summary":"Using a sample of $(10087\\pm44) \\times 10^{6}$ $J/\\psi$ events collected with\nthe BESIII detector at the BEPCII collider, the first evidence for the doubly\nOZI-suppressed decay $\\eta_{c} \\to \\omega\\phi$ is reported with a significance\nof 4.0$\\sigma$. The branching fraction of $\\eta_{c} \\to \\omega\\phi$ is measured\nto be $\\mathcal{B}(\\eta_{c} \\to \\omega\\phi) = (3.86 \\pm 0.92 \\pm 0.62) \\times\n10^{-5}$, where the first uncertainty is statistical and the second is\nsystematic. This result provides valuable insights into the underlying\nmechanisms of charmonium decays, particularly for processes such as $\\eta_{c}\n\\to VV$ (where $V$ represents a vector meson).","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-02T15:30:09Z"}
{"aid":"http://arxiv.org/abs/2504.01827v1","title":"What is AI, what is it not, how we use it in physics and how it\n  impacts... you","summary":"Artificial Intelligence (AI) and Machine Learning (ML) have been prevalent in\nparticle physics for over three decades, shaping many aspects of High Energy\nPhysics (HEP) analyses. As AI's influence grows, it is essential for physicists\n$\\unicode{x2013}$ as both researchers and informed citizens $\\unicode{x2013}$\nto critically examine its foundations, misconceptions, and impact. This paper\nexplores AI definitions, examines how ML differs from traditional programming,\nand provides a brief review of AI/ML applications in HEP, highlighting\npromising trends such as Simulation-Based Inference, uncertainty-aware machine\nlearning, and Fast ML for anomaly detection. Beyond physics, it also addresses\nthe broader societal harms of AI systems, underscoring the need for responsible\nengagement. Finally, it stresses the importance of adapting research practices\nto an evolving AI landscape, ensuring that physicists not only benefit from the\nlatest tools but also remain at the forefront of innovation.","main_category":"physics.soc-ph","categories":"physics.soc-ph,cs.LG,hep-ex","published":"2025-04-02T15:35:43Z"}
{"aid":"http://arxiv.org/abs/2504.01830v1","title":"Is Lorentz invariance violation found?","summary":"Lorentz invariance violation (LIV) has long been recognized as an observable\nlow-energy signature of quantum gravity. In spite of a great effort to detect\nLIV effects, so far only lower bounds have been derived. The high energy\nphotons from the gamma ray burst GRB 221009A have been detected by the LHAASO\ncollaboration and one at ${\\cal E} \\simeq 251 \\, \\rm TeV$ by the Carpet\ncollaboration using a partial data set. Very recently, the Carpet collaboration\nhas completed the full data analysis, reporting further support for their\npreviously detected photon now at ${\\cal E} = 300^{+ 43}_{- 38} \\, {\\rm TeV}$,\nwhich manifestly clashes with conventional physics. Taking this result at face\nvalue, we derive the first evidence for LIV and we show that such a detection\ncannot be explained by axion-like particles (ALPs), which allow for the\nobservation of the highest energy photons detected by LHAASO. We also outline a\nscenario in which ALPs and LIV naturally coexist. If confirmed by future\nobservations our finding would represent the first positive result in quantum\ngravity phenomenology.","main_category":"astro-ph.HE","categories":"astro-ph.HE,gr-qc,hep-ph,hep-th","published":"2025-04-02T15:39:37Z"}
{"aid":"http://arxiv.org/abs/2504.01836v1","title":"Estimating hazard rates from $δ$-records in discrete distributions","summary":"This paper focuses on nonparametric statistical inference of the hazard rate\nfunction of discrete distributions based on $\\delta$-record data. We derive the\nexplicit expression of the maximum likelihood estimator and determine its exact\ndistribution, as well as some important characteristics such as its bias and\nmean squared error. We then discuss the construction of confidence intervals\nand goodness-of-fit tests. The performance of our proposals is evaluated using\nsimulation methods. Applications to real data are given, as well. The\nestimation of the hazard rate function based on usual records has been studied\nin the literature, although many procedures require several samples of records.\nIn contrast, our approach relies on a single sequence of $\\delta$-records,\nsimplifying the experimental design and increasing the applicability of the\nmethods.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-02T15:43:19Z"}
{"aid":"http://arxiv.org/abs/2504.01842v1","title":"shapr: Explaining Machine Learning Models with Conditional Shapley\n  Values in R and Python","summary":"This paper introduces the shapr package, a versatile tool for generating\nShapley value explanations for machine learning and statistical regression\nmodels in both R and Python. The package emphasizes conditional Shapley value\nestimates, providing a comprehensive range of approaches for accurately\ncapturing feature dependencies, which is crucial for correct model\ninterpretation and lacking in similar software. In addition to regular tabular\ndata, the shapr R-package includes specialized functionality for explaining\ntime series forecasts. The package offers a minimal set of user functions with\nsensible defaults for most use cases while providing extensive flexibility for\nadvanced users to fine-tune computations. Additional features include\nparallelized computations, iterative estimation with convergence detection, and\nrich visualization tools. shapr also extends its functionality to compute\ncausal and asymmetric Shapley values when causal information is available. In\naddition, we introduce the shaprpy Python library, which brings core\ncapabilities of shapr to the Python ecosystem. Overall, the package aims to\nenhance the interpretability of predictive models within a powerful and\nuser-friendly framework.","main_category":"cs.LG","categories":"cs.LG,stat.CO","published":"2025-04-02T15:47:30Z"}
{"aid":"http://arxiv.org/abs/2504.01846v1","title":"Many neighbors little entanglement: A curious scaling in the\n  variable-range extended Ising model","summary":"We study the two-point correlation functions and the bipartite entanglement\nin the ground state of the exactly-solvable variable-range extended Ising model\nof qubits in the presence of a transverse field on a one-dimensional lattice.\nWe introduce the variation in the range of interaction by varying the\ncoordination number, $\\mathcal{Z}$, of each qubit, where the interaction\nstrength between a pair of qubits at a distance $r$ varies as $\\sim\nr^{-\\alpha}$. We show that the algebraic nature of the correlation functions is\npresent only up to $r=\\mathcal{Z}$, above which it exhibits short-range\nexponential scaling. We also show that at the critical point, the bipartite\nentanglement exhibits a power-law decrease ($\\sim\\mathcal{Z}^{-\\gamma}$) with\nincreasing coordination number irrespective of the partition size and the value\nof $\\alpha$ for $\\alpha>1$. We further consider a sudden quench of the system\nstarting from the ground state of the infinite-field limit of the system\nHamiltonian via turning on the critical Hamiltonian, and demonstrate that the\nlong-time averaged bipartite entanglement exhibits a qualitatively similar\nvariation ($\\sim\\mathcal{Z}^{-\\gamma}$) with $\\mathcal{Z}$.","main_category":"quant-ph","categories":"quant-ph,cond-mat.str-el","published":"2025-04-02T15:54:52Z"}
{"aid":"http://arxiv.org/abs/2504.01866v1","title":"From Code Generation to Software Testing: AI Copilot with Context-Based\n  RAG","summary":"The rapid pace of large-scale software development places increasing demands\non traditional testing methodologies, often leading to bottlenecks in\nefficiency, accuracy, and coverage. We propose a novel perspective on software\ntesting by positing bug detection and coding with fewer bugs as two\ninterconnected problems that share a common goal, which is reducing bugs with\nlimited resources. We extend our previous work on AI-assisted programming,\nwhich supports code auto-completion and chatbot-powered Q&A, to the realm of\nsoftware testing. We introduce Copilot for Testing, an automated testing system\nthat synchronizes bug detection with codebase updates, leveraging context-based\nRetrieval Augmented Generation (RAG) to enhance the capabilities of large\nlanguage models (LLMs). Our evaluation demonstrates a 31.2% improvement in bug\ndetection accuracy, a 12.6% increase in critical test coverage, and a 10.5%\nhigher user acceptance rate, highlighting the transformative potential of\nAI-driven technologies in modern software development practices.","main_category":"cs.SE","categories":"cs.SE,cs.AI,cs.PL","published":"2025-04-02T16:20:05Z"}
{"aid":"http://arxiv.org/abs/2504.01868v1","title":"Focal Mechanism Uncertainty Quantification In Ground Motion Simulations\n  Of Le Teil Earthquake","summary":"Ensuring the seismic safety of nuclear power plants (NPPs) is essential,\nespecially for facilities that rely on base isolation to reduce earthquake\nimpacts. For understanding the seismic response, accurate models are key to\npredict the ground motions, which are generally sensitive to various factors,\nincluding earthquake source parameters like the focal mechanism, i.e., strike,\ndip, and rake angles. This study examines how uncertainties in these parameters\naffect ground motion predictions. The analysis is based on the SMATCH\nbenchmark, which provides a standardized approach for evaluating the seismic\nresponse of the Cruas-Meysse NPP in France during the Mw 4.9 Le-Teil earthquake\nof 2019. A set of 27 3D high-fidelity numerical simulations was performed using\na spectral-element method, each incorporating different focal mechanism\nvariations. These simulations provide an effective approach for investigating\nthe factors behind the exceptional ground motion observed during this event. To\nquantify uncertainty, the simulated ground motions were compared to recorded\ndata using two well-established goodness-of-fit criteria: one assessing\ntime-frequency domain characteristics and another focusing on the\ncharacterization of the ground motion signals by intensity measures. Results\nhighlight the significant influence of focal mechanism variability on ground\nmotion predictions, especially on the rake angle, which showed the strongest\ncorrelation with wave and intensity measures.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-02T16:22:46Z"}
{"aid":"http://arxiv.org/abs/2504.01869v1","title":"Buggin: Automatic intrinsic bugs classification model using NLP and ML","summary":"Recent studies have shown that bugs can be categorized into intrinsic and\nextrinsic types. Intrinsic bugs can be backtracked to specific changes in the\nversion control system (VCS), while extrinsic bugs originate from external\nchanges to the VCS and lack a direct bug-inducing change. Using only intrinsic\nbugs to train bug prediction models has been reported as beneficial to improve\nthe performance of such models. However, there is currently no automated\napproach to identify intrinsic bugs. To bridge this gap, our study employs\nNatural Language Processing (NLP) techniques to automatically identify\nintrinsic bugs. Specifically, we utilize two embedding techniques, seBERT and\nTF-IDF, applied to the title and description text of bug reports. The resulting\nembeddings are fed into well-established machine learning algorithms such as\nSupport Vector Machine, Logistic Regression, Decision Tree, Random Forest, and\nK-Nearest Neighbors. The primary objective of this paper is to assess the\nperformance of various NLP and machine learning techniques in identifying\nintrinsic bugs using the textual information extracted from bug reports. The\nresults demonstrate that both seBERT and TF-IDF can be effectively utilized for\nintrinsic bug identification. The highest performance scores were achieved by\ncombining TF-IDF with the Decision Tree algorithm and utilizing the bug titles\n(yielding an F1 score of 78%). This was closely followed by seBERT, Support\nVector Machine, and bug titles (with an F1 score of 77%). In summary, this\npaper introduces an innovative approach that automates the identification of\nintrinsic bugs using textual information derived from bug reports.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-02T16:23:08Z"}
{"aid":"http://arxiv.org/abs/2504.01874v1","title":"The Hitchin morphism for certain surfaces fibered over a curve","summary":"The Chen-Ng\\^o Conjecture predicts that the Hitchin morphism from the moduli\nstack of $G$-Higgs bundles on a smooth projective variety surjects onto the\nspace of spectral data. The conjecture is known to hold for the group $GL_n$\nand any surface, and for the group $GL_2$ and any smooth projective variety. We\nprove the Chen-Ng\\^o Conjecture for any reductive group when the variety is a\nruled surface or (a blowup of) a nonisotrivial elliptic fibration with reduced\nfibers. Furthermore, if the group is a classical group, i.e. $G \\in\n\\{SL_n,SO_n,Sp_{2n}\\}$, then we prove the Hitchin morphism restricted to the\nDolbeault moduli space of semiharmonic $G$-Higgs bundles surjects onto the\nspace of spectral data.","main_category":"math.AG","categories":"math.AG","published":"2025-04-02T16:30:25Z"}
{"aid":"http://arxiv.org/abs/2504.01875v1","title":"Architect Your Landscape Approach (AYLA) for Optimizations in Deep\n  Learning","summary":"Stochastic Gradient Descent (SGD) and its variants, such as ADAM, are\nfoundational to deep learning optimization, adjusting model parameters using\nfixed or adaptive learning rates based on loss function gradients. However,\nthese methods often face challenges in balancing adaptability and efficiency in\nnon-convex, high-dimensional settings. This paper introduces AYLA, a novel\noptimization technique that enhances training dynamics through loss function\ntransformations. By applying a tunable power-law transformation, AYLA preserves\ncritical points while scaling loss values to amplify gradient sensitivity,\naccelerating convergence. We further propose a dynamic (effective) learning\nrate that adapts to the transformed loss, improving optimization efficiency.\nEmpirical tests on finding minimum of a synthetic non-convex polynomial, a\nnon-convex curve-fitting dataset, and digit classification (MNIST) demonstrate\nthat AYLA surpasses SGD and ADAM in convergence speed and stability. This\napproach redefines the loss landscape for better optimization outcomes,\noffering a promising advancement for deep neural networks and can be applied to\nany optimization method and potentially improve the performance of it.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T16:31:39Z"}
{"aid":"http://arxiv.org/abs/2504.01884v1","title":"Thermoelectric AC Josephson effect","summary":"A temperature gradient ${\\Delta}T$ across a Josephson junction induces a\nthermoelectric current. We predict the AC Josephson effect is activated when\nthis current surpasses the junction's critical current. Our investigation of\nthis phenomenon employs the time-dependent Ginzburg-Landau theory framework in\nproximity to the critical temperature. Our results indicate that the frequency\nof the AC current is approximately given by ${\\pi} S {\\Delta} T / (2\n{\\Phi}_0)$, where $S$ represents the Seebeck coefficient and ${\\Phi}_0$ the\nmagnetic flux quantum and we estimate the frequency be on the range of GHz for\nSn up to a THz for larger $S$ and $T_c$ materials. Furthermore, we propose two\ndistinct experimental configurations to observe this effect.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-02T16:41:34Z"}
{"aid":"http://arxiv.org/abs/2504.01900v1","title":"Physical Modeling of Saturated Common Mode Choke","summary":"Common mode chokes (CMCs) are conventional circuit elements performing\nseveral tasks, including noise suppression, hindering electromagnetic\ninterference, providing signal integrity, and circuit protection. Much as they\nare widely used, their fundamental construction and description are often\nqualitative and lack an understanding of the underlying physical principles. We\ndiscuss the behavior of a commercial CMC based on the physical description of\nthe superparamagnetic core and parasitic circuit elements. The results are\nvalidated using a DC bias current and an external magnetic field, which affect\nthe magnetic properties. The behavior of the CMCs in the strongly non-linear\nregime is also described.","main_category":"physics.app-ph","categories":"physics.app-ph,cond-mat.mtrl-sci","published":"2025-04-02T16:58:47Z"}
{"aid":"http://arxiv.org/abs/2504.01905v1","title":"Accelerating IoV Intrusion Detection: Benchmarking GPU-Accelerated vs\n  CPU-Based ML Libraries","summary":"The Internet of Vehicles (IoV) may face challenging cybersecurity attacks\nthat may require sophisticated intrusion detection systems, necessitating a\nrapid development and response system. This research investigates the\nperformance advantages of GPU-accelerated libraries (cuML) compared to\ntraditional CPU-based implementations (scikit-learn), focusing on the speed and\nefficiency required for machine learning models used in IoV threat detection\nenvironments. The comprehensive evaluations conducted employ four machine\nlearning approaches (Random Forest, KNN, Logistic Regression, XGBoost) across\nthree distinct IoV security datasets (OTIDS, GIDS, CICIoV2024). Our findings\ndemonstrate that GPU-accelerated implementations dramatically improved\ncomputational efficiency, with training times reduced by a factor of up to 159\nand prediction speeds accelerated by up to 95 times compared to traditional CPU\nprocessing, all while preserving detection accuracy. This remarkable\nperformance breakthrough empowers researchers and security specialists to\nharness GPU acceleration for creating faster, more effective threat detection\nsystems that meet the urgent real-time security demands of today's connected\nvehicle networks.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CR","published":"2025-04-02T17:04:53Z"}
{"aid":"http://arxiv.org/abs/2504.01918v1","title":"Long-eared digraphs","summary":"Let $H$ be a subdigraph of a digraph $D$. An ear of $H$ in $D$ is a path or a\ncycle in $D$ whose ends lie in $H$ but whose internal vertices do not. An\n\\emph{ear decomposition} of a strong digraph $D$ is a nested sequence\n$(D_0,D_1,\\ldots , D_k)$ of strong subdigraphs of $D$ such that: 1) $D_0$ is a\ncycle, 2) $D_{i+1} = D_i\\cup P_i$, where $P_i$ is an ear of $D_i$ in $D$, for\nevery $i\\in \\{0,1,\\ldots,k-1\\}$, and 3) $D_k=D$.\n  In this work, the $\\mathcal{LE}_i$ is defined as the family of strong\ndigraphs, with an ear decomposition such that every ear has a length of at\nleast $i\\geq 1$. It is proved that Seymour's second Neighborhood Conjecture and\nthe Laborde, Payan, and Soung conjecture, are true in the family\n$\\mathcal{LE}_2$, and the Small quasi-kernel conjecture is true for digraphs in\n$\\mathcal{LE}_3$. Also, some sufficient conditions for a strong nonseparable\ndigraph in $\\mathcal{LE}_2$ with a kernel to imply that the previous\n(following) subdigraph in the ear decomposition has a kernel too, are\npresented. It is proved that digraphs in $\\mathcal{LE}_2$ have a chromatic\nnumber at most 3, and a dichromatic number 2 or 3. Finally, the oriented\nchromatic number of asymmetrical digraphs in $\\mathcal{LE}_3$ is bounded by 6,\nand it is shown that the oriented chromatic number of asymmetrical digraphs in\n$\\mathcal{LE}_2$ is not bounded.","main_category":"math.CO","categories":"math.CO","published":"2025-04-02T17:22:44Z"}
{"aid":"http://arxiv.org/abs/2504.01936v1","title":"Fermionic Averaged Circuit Eigenvalue Sampling","summary":"Fermionic averaged circuit eigenvalue sampling (FACES) is a protocol to\nsimultaneously learn the averaged error rates of many fermionic linear optical\n(FLO) gates simultaneously and self-consistently from a suitable collection of\nFLO circuits. It is highly flexible, allowing for the in situ characterization\nof FLO-averaged gate-dependent noise under natural assumptions on a family of\ncontinuously parameterized one- and two-qubit gates. We rigorously show that\nour protocol has an efficient sampling complexity, owing in-part to useful\nproperties of the Kravchuk transformations that feature in our analysis. We\nsupport our conclusions with numerical results. As FLO circuits become\nuniversal with access to certain resource states, we expect our results to\ninform noise characterization and error mitigation techniques on universal\nquantum computing architectures which naturally admit a fermionic description.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T17:46:16Z"}
{"aid":"http://arxiv.org/abs/2504.01940v1","title":"Strengthening Multi-Robot Systems for SAR: Co-Designing Robotics and\n  Communication Towards 6G","summary":"This paper presents field-tested use cases from Search and Rescue (SAR)\nmissions, highlighting the co-design of mobile robots and communication systems\nto support Edge-Cloud architectures based on 5G Standalone (SA). The main goal\nis to contribute to the effective cooperation of multiple robots and first\nresponders. Our field experience includes the development of Hybrid Wireless\nSensor Networks (H-WSNs) for risk and victim detection, smartphones integrated\ninto the Robot Operating System (ROS) as Edge devices for mission requests and\npath planning, real-time Simultaneous Localization and Mapping (SLAM) via\nMulti-Access Edge Computing (MEC), and implementation of Uncrewed Ground\nVehicles (UGVs) for victim evacuation in different navigation modes. These\nexperiments, conducted in collaboration with actual first responders,\nunderscore the need for intelligent network resource management, balancing\nlow-latency and high-bandwidth demands. Network slicing is key to ensuring\ncritical emergency services are performed despite challenging communication\nconditions. The paper identifies architectural needs, lessons learned, and\nchallenges to be addressed by 6G technologies to enhance emergency response\ncapabilities.","main_category":"cs.RO","categories":"cs.RO,cs.NI","published":"2025-04-02T17:47:11Z"}
{"aid":"http://arxiv.org/abs/2504.01943v1","title":"OpenCodeReasoning: Advancing Data Distillation for Competitive Coding","summary":"Since the advent of reasoning-based large language models, many have found\ngreat success from distilling reasoning capabilities into student models. Such\ntechniques have significantly bridged the gap between reasoning and standard\nLLMs on coding tasks. Despite this, much of the progress on distilling\nreasoning models remains locked behind proprietary datasets or lacks details on\ndata curation, filtering and subsequent training. To address this, we construct\na superior supervised fine-tuning (SFT) dataset that we use to achieve\nstate-of-the-art coding capability results in models of various sizes. Our\ndistilled models use only SFT to achieve 61.8% on LiveCodeBench and 24.6% on\nCodeContests, surpassing alternatives trained with reinforcement learning. We\nthen perform analysis on the data sources used to construct our dataset, the\nimpact of code execution filtering, and the importance of instruction/solution\ndiversity. We observe that execution filtering negatively affected benchmark\naccuracy, leading us to prioritize instruction diversity over solution\ncorrectness. Finally, we also analyze the token efficiency and reasoning\npatterns utilized by these models. We will open-source these datasets and\ndistilled models to the community.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T17:50:31Z"}
{"aid":"http://arxiv.org/abs/2504.02214v1","title":"Geospatial Artificial Intelligence for Satellite-based Flood Extent\n  Mapping: Concepts, Advances, and Future Perspectives","summary":"Geospatial Artificial Intelligence (GeoAI) for satellite-based flood extent\nmapping systematically integrates artificial intelligence techniques with\nsatellite data to identify flood events and assess their impacts, for disaster\nmanagement and spatial decision-making. The primary output often includes flood\nextent maps, which delineate the affected areas, along with additional\nanalytical outputs such as uncertainty estimation and change detection.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-03T02:08:22Z"}
{"aid":"http://arxiv.org/abs/2504.02217v1","title":"The Plot Thickens: Quantitative Part-by-Part Exploration of MLLM\n  Visualization Literacy","summary":"Multimodal Large Language Models (MLLMs) can interpret data visualizations,\nbut what makes a visualization understandable to these models? Do factors like\ncolor, shape, and text influence legibility, and how does this compare to human\nperception? In this paper, we build on prior work to systematically assess\nwhich visualization characteristics impact MLLM interpretability. We expanded\nthe Visualization Literacy Assessment Test (VLAT) test set from 12 to 380\nvisualizations by varying plot types, colors, and titles. This allowed us to\nstatistically analyze how these features affect model performance. Our findings\nsuggest that while color palettes have no significant impact on accuracy, plot\ntypes and the type of title significantly affect MLLM performance. We observe\nsimilar trends for model omissions. Based on these insights, we look into which\nplot types are beneficial for MLLMs in different tasks and propose\nvisualization design principles that enhance MLLM readability. Additionally, we\nmake the extended VLAT test set, VLAT ex, publicly available on\nhttps://osf.io/ermwx/ together with our supplemental material for future model\ntesting and evaluation.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-03T02:13:00Z"}
{"aid":"http://arxiv.org/abs/2504.02228v1","title":"Stochastic positivity-preserving symplectic splitting methods for\n  stochastic Lotka--Volterra predator-prey model","summary":"In this paper, we present two stochastic positive-preserving symplectic\nmethods for the stochastic Lotka-Volterra predator-prey model driven by a\nmultiplicative noise. To inherit the intrinsic characteristic of the original\nsystem, the stochastic Lie--Trotter splitting method and the stochastic Strang\nsplitting method are introduced, which are proved to preserve the positivity of\nthe numerical solution and possess the discrete stochastic symplectic\nconservation law as well. By deriving the uniform boundedness of the $p$-th\nmoment of the numerical solution, we prove that the strong convergence orders\nof these two methods are both one in the $L^2(\\Omega)$-norm. Finally, we\nvalidate the theoretical results through two and four dimensional numerical\nexamples.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-03T02:49:40Z"}
{"aid":"http://arxiv.org/abs/2504.02241v1","title":"Quantum Deep Sets and Sequences","summary":"This paper introduces the quantum deep sets model, expanding the quantum\nmachine learning tool-box by enabling the possibility of learning variadic\nfunctions using quantum systems. A couple of variants are presented for this\nmodel. The first one focuses on mapping sets to quantum systems through state\nvector averaging: each element of the set is mapped to a quantum state, and the\nquantum state of the set is the average of the corresponding quantum states of\nits elements. This approach allows the definition of a permutation-invariant\nvariadic model. The second variant is useful for ordered sets, i.e., sequences,\nand relies on optimal coherification of tristochastic tensors that implement\nproducts of mixed states: each element of the set is mapped to a density\nmatrix, and the quantum state of the set is the product of the corresponding\ndensity matrices of its elements. Such variant can be relevant in tasks such as\nnatural language processing. The resulting quantum state in any of the variants\nis then processed to realise a function that solves a machine learning task\nsuch as classification, regression or density estimation. Through synthetic\nproblem examples, the efficacy and versatility of quantum deep sets and\nsequences (QDSs) is demonstrated.","main_category":"quant-ph","categories":"quant-ph,cs.LG","published":"2025-04-03T03:14:17Z"}
{"aid":"http://arxiv.org/abs/2504.02245v1","title":"Traffic Flow Data Completion and Anomaly Diagnosis via Sparse and\n  Low-Rank Tensor Optimization","summary":"Spatiotemporal traffic time series, such as traffic speed data, collected\nfrom sensing systems are often incomplete, with considerable corruption and\nlarge amounts of missing values. A vast amount of data conceals implicit data\nstructures, which poses significant challenges for data recovery issues, such\nas mining the potential spatio-temporal correlations of data and identifying\nabnormal data. In this paper, we propose a Tucker decomposition-based sparse\nlow-rank high-order tensor optimization model (TSLTO) for data imputation and\nanomaly diagnosis. We decompose the traffic tensor data into low-rank and\nsparse tensors, and establish a sparse low-rank high-order tensor optimization\nmodel based on Tucker decomposition. By utilizing tools of non-smooth analysis\nfor tensor functions, we explore the optimality conditions of the proposed\ntensor optimization model and design an ADMM optimization algorithm for solving\nthe model. Finally, numerical experiments are conducted on both synthetic data\nand a real-world dataset: the urban traffic speed dataset of Guangzhou.\nNumerical comparisons with several representative existing algorithms\ndemonstrate that our proposed approach achieves higher accuracy and efficiency\nin traffic flow data recovery and anomaly diagnosis tasks.","main_category":"math.OC","categories":"math.OC,cs.NA,math.NA","published":"2025-04-03T03:21:30Z"}
{"aid":"http://arxiv.org/abs/2504.02254v1","title":"LLMs as Deceptive Agents: How Role-Based Prompting Induces Semantic\n  Ambiguity in Puzzle Tasks","summary":"Recent advancements in Large Language Models (LLMs) have not only showcased\nimpressive creative capabilities but also revealed emerging agentic behaviors\nthat exploit linguistic ambiguity in adversarial settings. In this study, we\ninvestigate how an LLM, acting as an autonomous agent, leverages semantic\nambiguity to generate deceptive puzzles that mislead and challenge human users.\nInspired by the popular puzzle game \"Connections\", we systematically compare\npuzzles produced through zero-shot prompting, role-injected adversarial\nprompts, and human-crafted examples, with an emphasis on understanding the\nunderlying agent decision-making processes. Employing computational analyses\nwith HateBERT to quantify semantic ambiguity, alongside subjective human\nevaluations, we demonstrate that explicit adversarial agent behaviors\nsignificantly heighten semantic ambiguity -- thereby increasing cognitive load\nand reducing fairness in puzzle solving. These findings provide critical\ninsights into the emergent agentic qualities of LLMs and underscore important\nethical considerations for evaluating and safely deploying autonomous language\nsystems in both educational technologies and entertainment.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-03T03:45:58Z"}
{"aid":"http://arxiv.org/abs/2504.02255v1","title":"Bipedal Robust Walking on Uneven Footholds: Piecewise Slope LIPM with\n  Discrete Model Predictive Control","summary":"This study presents an enhanced theoretical formulation for bipedal\nhierarchical control frameworks under uneven terrain conditions. Specifically,\nowing to the inherent limitations of the Linear Inverted Pendulum Model (LIPM)\nin handling terrain elevation variations, we develop a Piecewise Slope LIPM\n(PS-LIPM). This innovative model enables dynamic adjustment of the Center of\nMass (CoM) height to align with topographical undulations during single-step\ncycles. Another contribution is proposed a generalized Angular Momentum-based\nLIPM (G-ALIP) for CoM velocity compensation using Centroidal Angular Momentum\n(CAM) regulation. Building upon these advancements, we derive the DCM\nstep-to-step dynamics for Model Predictive Control MPC formulation, enabling\nsimultaneous optimization of step position and step duration. A hierarchical\ncontrol framework integrating MPC with a Whole-Body Controller (WBC) is\nimplemented for bipedal locomotion across uneven stepping stones. The results\nvalidate the efficacy of the proposed hierarchical control framework and the\ntheoretical formulation.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-03T03:54:10Z"}
{"aid":"http://arxiv.org/abs/2504.02258v1","title":"Submanifold-genericity of $\\mathbb{R}^d$-actions and uniform\n  multiplicative Diophantine approximation","summary":"In this paper, we prove a new ergodic theorem for $\\mathbb{R}^d$-actions\ninvolving averages over dilated submanifolds, thereby generalizing the theory\nof spherical averages. Our main result is a quantitative estimate for the error\nterm of such averages valid for smooth functions under some effective mixing\nassumptions on the action. With the aid of this theorem, we investigate\nmultiplicative-type Dirichlet-improvability for $(m\\times n)$-matrices with\nreal coefficients. In particular, we establish that almost all matrices are\nuniformly approximable by the function $x\\mapsto x^{-1}(\\log\nx)^{-1+\\varepsilon}$ for any $\\varepsilon>0$. Results of this type motivate a\nquestion which can be thought as a strengthening of Littlewood's conjecture in\nmultiplicative Diophantine approximation.","main_category":"math.NT","categories":"math.NT,math.DS","published":"2025-04-03T04:01:49Z"}
{"aid":"http://arxiv.org/abs/2504.02267v1","title":"Third-Order Spontaneous Parametric Down Conversion in Dielectric\n  Nonlinear Resonant Metasurfaces","summary":"We propose a general scheme to investigate photon triplet generation (PTG)\nvia third-order spontaneous parametric downconversion (TOSPDC) in $\\chi^{(3)}$\nnonlinear structures. Our approach leverages the quantum-classical\ncorrespondence between TOSPDC and its reverse classical process, three-wave\nsum-frequency generation (TSFG), to efficiently estimate the PTG rate. We apply\nthis framework to nonlinear metasurfaces supporting quasi-bound states in the\ncontinuum (qBICs) in the optical range. From numerical analysis of\nnon-collinear TSFG with degenerate input waves at qBIC wavelengths, we predict\nwavelength-tunable three-photon emission with spatio-angular correlations.\nThese findings establish a novel method for modelling TOSPDC and also highlight\nthe potential of nonlinear resonant metasurfaces as compact free-space photon\ntriplet sources with quantum state control.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-03T04:26:50Z"}
{"aid":"http://arxiv.org/abs/2504.02269v1","title":"Engineering Artificial Intelligence: Framework, Challenges, and Future\n  Direction","summary":"Over the past ten years, the application of artificial intelligence (AI) and\nmachine learning (ML) in engineering domains has gained significant popularity,\nshowcasing their potential in data-driven contexts. However, the complexity and\ndiversity of engineering problems often require the development of\ndomain-specific AI approaches, which are frequently hindered by a lack of\nsystematic methodologies, scalability, and robustness during the development\nprocess. To address this gap, this paper introduces the \"ABCDE\" as the key\nelements of Engineering AI and proposes a unified, systematic engineering AI\necosystem framework, including eight essential layers, along with attributes,\ngoals, and applications, to guide the development and deployment of AI\nsolutions for specific engineering needs. Additionally, key challenges are\nexamined, and nine future research directions are highlighted. By providing a\ncomprehensive perspective, this paper aims to advance the strategic\nimplementation of AI, fostering the development of next-generation engineering\nAI solutions.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-03T04:30:10Z"}
{"aid":"http://arxiv.org/abs/2504.02296v1","title":"Exceedance and force of centrality for functional data","summary":"Exceedance refers to instances where a dynamic process surpasses given\nthresholds, e.g., the occurrence of a heat wave. We propose a novel exceedance\nframework for functional data, where each observed random trajectory is\ntransformed into an exceedance function, which quantifies exceedance durations\nas a function of threshold levels. An inherent relationship between exceedance\nfunctions and probability distributions makes it possible to draw on\ndistributional data analysis techniques such as Fr\\'echet regression to study\nthe dependence of exceedances on Euclidean predictors, e.g., calendar year when\nthe exceedances are observed. We use local linear estimators to obtain\nexceedance functions from discretely observed functional data with noise and\nstudy the convergence of the proposed estimators. New concepts of interest\ninclude the force of centrality that quantifies the propensity of a system to\nrevert to lower levels when a given threshold has been exceeded, conditional\nexceedance functions when conditioning on Euclidean covariates, and threshold\nexceedance functions, which characterize the size of exceedance sets in\ndependence on covariates for any fixed threshold. We establish consistent\nestimation with rates of convergence for these targets. The practical merits of\nthe proposed methodology are illustrated through simulations and applications\nfor annual temperature curves and medfly activity profiles.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-03T05:58:24Z"}
{"aid":"http://arxiv.org/abs/2504.02297v1","title":"The temperature dependence of fractional topological charge objects","summary":"We present a novel method for defining the topological charge contained\nwithin distinct topological objects in the nontrivial ground-state fields of\nSU(N) lattice gauge theory. Such an analysis has been called for by the growing\nnumber of models for Yang-Mills topological structure which propose the\nexistence of fractionally charged objects. This investigation is performed for\nSU(3) at a range of temperatures across the deconfinement phase transition,\nproviding an assessment of how the topological structure evolves with\ntemperature. This reveals a connection between the topological charge and\nholonomy of the system which must be satisfied by finite-temperature models of\nYang-Mills vacuum structure. We find a promising consistency with the\ninstanton-dyon model for SU(N) vacuum structure.","main_category":"hep-lat","categories":"hep-lat,hep-ph,nucl-th","published":"2025-04-03T06:04:20Z"}
{"aid":"http://arxiv.org/abs/2504.02298v1","title":"SPACE: SPike-Aware Consistency Enhancement for Test-Time Adaptation in\n  Spiking Neural Networks","summary":"Spiking Neural Networks (SNNs), as a biologically plausible alternative to\nArtificial Neural Networks (ANNs), have demonstrated advantages in terms of\nenergy efficiency, temporal processing, and biological plausibility. However,\nSNNs are highly sensitive to distribution shifts, which can significantly\ndegrade their performance in real-world scenarios. Traditional test-time\nadaptation (TTA) methods designed for ANNs often fail to address the unique\ncomputational dynamics of SNNs, such as sparsity and temporal spiking behavior.\nTo address these challenges, we propose $\\textbf{SP}$ike-$\\textbf{A}$ware\n$\\textbf{C}$onsistency $\\textbf{E}$nhancement (SPACE), the first source-free\nand single-instance TTA method specifically designed for SNNs. SPACE leverages\nthe inherent spike dynamics of SNNs to maximize the consistency of\nspike-behavior-based local feature maps across augmented versions of a single\ntest sample, enabling robust adaptation without requiring source data. We\nevaluate SPACE on multiple datasets, including CIFAR-10-C, CIFAR-100-C,\nTiny-ImageNet-C and DVS Gesture-C. Furthermore, SPACE demonstrates strong\ngeneralization across different model architectures, achieving consistent\nperformance improvements on both VGG9 and ResNet11. Experimental results show\nthat SPACE outperforms state-of-the-art methods, highlighting its effectiveness\nand robustness in real-world settings.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T06:05:05Z"}
{"aid":"http://arxiv.org/abs/2504.02305v1","title":"Nuclear Winds Drive Large-Scale Cold Gas Outflows in Quasars during the\n  Reionization Epoch","summary":"Accreting supermassive black holes (SMBHs) regulate the evolution of their\nhost galaxies through powerful outflows and multi-phase feedback. This process\nplays a crucial role in shaping SMBH-galaxy co-evolution across cosmic time,\nbut direct evidence linking nuclear winds to large-scale cold gas outflows,\nparticularly in high-redshift quasars, has remained elusive. Here we present\nstatistical evidence of a connection between nuclear winds and large-scale cold\ngas outflows in quasars at $z \\sim 5.5$. Using stacked [C II] 158 $\\mu$m\nemission profiles from ALMA observations, which trace galactic-scale neutral\ngas, we compare broad absorption line (BAL) quasars -- tracing parsec- to\nsub-kiloparsec-scale nuclear winds -- with non-BAL quasars. The BAL stack\nreveals a significant (S/N=4.45) broad component in the [C II] emission,\nindicating high-velocity neutral gas outflows with a velocity offset of $\\Delta\nv_{\\rm b} = -2.1 \\times 10^2 \\, \\rm km\\,s^{-1}$ and a full width at half\nmaximum of $1.18 \\times 10^3 \\, \\rm km\\,s^{-1}$, while the non-BAL stack shows\nno such feature. We estimate that a few percent up to one-quarter of the BAL\nwind energy is transferred to neutral gas on kiloparsec scales. These findings\nprovide direct observational evidence that nuclear winds couple with\ngalactic-scale neutral gas flows, supporting multi-phase AGN feedback models.\nThis mechanism may contribute to explaining the diversity of $M_{\\rm BH}/M_*$\nratios observed in some luminous AGN recently observed by JWST, compared to the\nMagorrian relation.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-04-03T06:22:57Z"}
{"aid":"http://arxiv.org/abs/2504.02312v1","title":"OmniCam: Unified Multimodal Video Generation via Camera Control","summary":"Camera control, which achieves diverse visual effects by changing camera\nposition and pose, has attracted widespread attention. However, existing\nmethods face challenges such as complex interaction and limited control\ncapabilities. To address these issues, we present OmniCam, a unified multimodal\ncamera control framework. Leveraging large language models and video diffusion\nmodels, OmniCam generates spatio-temporally consistent videos. It supports\nvarious combinations of input modalities: the user can provide text or video\nwith expected trajectory as camera path guidance, and image or video as content\nreference, enabling precise control over camera motion. To facilitate the\ntraining of OmniCam, we introduce the OmniTr dataset, which contains a large\ncollection of high-quality long-sequence trajectories, videos, and\ncorresponding descriptions. Experimental results demonstrate that our model\nachieves state-of-the-art performance in high-quality camera-controlled video\ngeneration across various metrics.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-03T06:38:30Z"}
{"aid":"http://arxiv.org/abs/2504.02315v1","title":"On $\\rm GL_3$ Fourier coefficients over values of mixed powers","summary":"Let $A_{\\pi}(n,1)$ be the $(n,1)$-th Fourier coefficient of the Hecke-Maass\ncusp form $\\pi$ for $\\rm SL_3(\\mathbb{Z})$ and $ \\omega(x)$ be a smooth\ncompactly supported function. In this paper, we prove a nontrivial upper bound\nfor the sum $$\\sum_{n_1,\\cdots,n_\\ell,n_{\\ell+1}\\in\\mathbb{Z}^+ \\atop\nn=n_1^r+\\cdots+n_{\\ell}^r+n_{\\ell+1}^s} A_{\\pi}(n,1)\\omega\\left(n/X\\right),$$\nwhere $r\\geq2$, $s\\geq 2$ and $\\ell\\geq 2^{r-1}$ are integers.","main_category":"math.NT","categories":"math.NT","published":"2025-04-03T06:43:21Z"}
{"aid":"http://arxiv.org/abs/2504.02329v1","title":"Towards Assessing Deep Learning Test Input Generators","summary":"Deep Learning (DL) systems are increasingly deployed in safety-critical\napplications, yet they remain vulnerable to robustness issues that can lead to\nsignificant failures. While numerous Test Input Generators (TIGs) have been\ndeveloped to evaluate DL robustness, a comprehensive assessment of their\neffectiveness across different dimensions is still lacking. This paper presents\na comprehensive assessment of four state-of-the-art TIGs--DeepHunter,\nDeepFault, AdvGAN, and SinVAD--across multiple critical aspects:\nfault-revealing capability, naturalness, diversity, and efficiency. Our\nempirical study leverages three pre-trained models (LeNet-5, VGG16, and\nEfficientNetB3) on datasets of varying complexity (MNIST, CIFAR-10, and\nImageNet-1K) to evaluate TIG performance. Our findings reveal important\ntrade-offs in robustness revealing capability, variation in test case\ngeneration, and computational efficiency across TIGs. The results also show\nthat TIG performance varies significantly with dataset complexity, as tools\nthat perform well on simpler datasets may struggle with more complex ones. In\ncontrast, others maintain steadier performance or better scalability. This\npaper offers practical guidance for selecting appropriate TIGs aligned with\nspecific objectives and dataset characteristics. Nonetheless, more work is\nneeded to address TIG limitations and advance TIGs for real-world,\nsafety-critical systems.","main_category":"cs.LG","categories":"cs.LG,cs.CV,cs.SE","published":"2025-04-03T07:06:55Z"}
{"aid":"http://arxiv.org/abs/2504.02330v1","title":"Commutators between coprime order elements in non-abelian simple groups","summary":"Recent investigations on the set of commutators between the elements of a\nfinite group having relatively prime orders have prompt us to propose a variant\nof the Ore conjecture: For every finite non-abelian simple group and for every\n$g\\in G$, there exist $x,y\\in G$ with $g=[y,x]$ and with the order of $x$\nrelatively prime to the order of $y$. In this note we present some evidence\ntowards the veracity of this conjecture by proving it for alternating groups\nand some sporadic simple groups.","main_category":"math.GR","categories":"math.GR","published":"2025-04-03T07:07:41Z"}
{"aid":"http://arxiv.org/abs/2504.02337v1","title":"LPA3D: 3D Room-Level Scene Generation from In-the-Wild Images","summary":"Generating realistic, room-level indoor scenes with semantically plausible\nand detailed appearances from in-the-wild images is crucial for various\napplications in VR, AR, and robotics. The success of NeRF-based generative\nmethods indicates a promising direction to address this challenge. However,\nunlike their success at the object level, existing scene-level generative\nmethods require additional information, such as multiple views, depth images,\nor semantic guidance, rather than relying solely on RGB images. This is because\nNeRF-based methods necessitate prior knowledge of camera poses, which is\nchallenging to approximate for indoor scenes due to the complexity of defining\nalignment and the difficulty of globally estimating poses from a single image,\ngiven the unseen parts behind the camera. To address this challenge, we\nredefine global poses within the framework of Local-Pose-Alignment (LPA) -- an\nanchor-based multi-local-coordinate system that uses a selected number of\nanchors as the roots of these coordinates. Building on this foundation, we\nintroduce LPA-GAN, a novel NeRF-based generative approach that incorporates\nspecific modifications to estimate the priors of camera poses under LPA. It\nalso co-optimizes the pose predictor and scene generation processes. Our\nablation study and comparisons with straightforward extensions of NeRF-based\nobject generative methods demonstrate the effectiveness of our approach.\nFurthermore, visual comparisons with other techniques reveal that our method\nachieves superior view-to-view consistency and semantic normality.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T07:18:48Z"}
{"aid":"http://arxiv.org/abs/2504.02339v1","title":"Riemannian Optimization for Sparse Tensor CCA","summary":"Tensor canonical correlation analysis (TCCA) has received significant\nattention due to its ability to effectively preserve the geometric structure of\nhigh-order data. However, existing methods generally rely on tensor\ndecomposition techniques with high computational complexity, which severely\nlimits their application in large-scale datasets. In this paper, a modified\nmethod, TCCA-L, is proposed, which integrates sparse regularization and\nLaplacian regularization. An alternating manifold proximal gradient algorithm\nis designed based on Riemannian manifold theory. The algorithm avoids the\ntraditional tensor decomposition and combines with the semi-smooth Newton\nalgorithm to solve the subproblem, thus significantly improving the\ncomputational efficiency. Furthermore, the global convergence of the sequence\ngenerated by the algorithm is established, providing a solid theoretical\nfoundation for its convergence. Numerical experiments demonstrate that TCCA-L\noutperforms traditional methods in both classification accuracy and running\ntime.","main_category":"math.OC","categories":"math.OC","published":"2025-04-03T07:19:14Z"}
{"aid":"http://arxiv.org/abs/2504.02360v1","title":"On graded going-down domains, II","summary":"In this paper we consider the graded going-down property of graded integral\ndomains in pullbacks. It then enables us to give original examples of these\ndomains.","main_category":"math.AC","categories":"math.AC","published":"2025-04-03T07:51:21Z"}
{"aid":"http://arxiv.org/abs/2504.02364v1","title":"SProBench: Stream Processing Benchmark for High Performance Computing\n  Infrastructure","summary":"Recent advancements in data stream processing frameworks have improved\nreal-time data handling, however, scalability remains a significant challenge\naffecting throughput and latency. While studies have explored this issue on\nlocal machines and cloud clusters, research on modern high performance\ncomputing (HPC) infrastructures is yet limited due to the lack of scalable\nmeasurement tools. This work presents SProBench, a novel benchmark suite\ndesigned to evaluate the performance of data stream processing frameworks in\nlarge-scale computing systems. Building on best practices, SProBench\nincorporates a modular architecture, offers native support for SLURM-based\nclusters, and seamlessly integrates with popular stream processing frameworks\nsuch as Apache Flink, Apache Spark Streaming, and Apache Kafka Streams.\nExperiments conducted on HPC clusters demonstrate its exceptional scalability,\ndelivering throughput that surpasses existing benchmarks by more than tenfold.\nThe distinctive features of SProBench, including complete customization\noptions, built-in automated experiment management tools, seamless\ninteroperability, and an open-source license, distinguish it as an innovative\nbenchmark suite tailored to meet the needs of modern data stream processing\nframeworks.","main_category":"cs.DC","categories":"cs.DC,cs.PF","published":"2025-04-03T07:54:49Z"}
{"aid":"http://arxiv.org/abs/2504.02368v1","title":"Electrical conductivities and low frequency opacities in the warm dense\n  matter regime","summary":"In this article, we examine different approaches for calculating low\nfrequency opacities in the warm dense matter regime. The relevance of the\naverage-atom approximation and of different models for calculating opacities,\nsuch as the Ziman or Ziman-Evans models is discussed and the results compared\nto \\textit{ab initio} simulations. We begin by recalling the derivation of the\nZiman-Evans resistivity from Kubo's linear response theory, using the local\napproximation to the solutions of the Lippmann-Schwinger equation. With the\nhelp of this approximation, we explicitly introduce an ionic structure factor\ninto the Ziman formula, without resorting to the Born approximation. Both\napproaches involve the calculation of scattering phase shifts, which we\nintegrate from Calogero equation with an adaptive step numerical scheme based\non a Runge-Kutta-Merson solver. We show that if the atomic number $Z$ is not\ntoo large, integrating the phase shifts in this way is more time-efficient than\nusing a classical Numerov-type scheme to solve the radial Schr\\\"odinger\nequation. Various approximations are explored for phase shifts to further\nimprove computation time. For the Born approximation, we show that using Born\nphase shifts directly in the scattering cross-section gives more accurate\nresults than with the integral formula based on the Fourier transform of the\nelectron-ion potential. We also compare an analytical formula based on a Yukawa\nfit of the electron-ion potential to a numerical integration. The average-atom\nresults are compared with DFT-based molecular dynamics simulations for aluminum\nin the dilute regime and for copper, aluminum and gold at solid density and\ndifferent temperatures.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-03T08:00:17Z"}
{"aid":"http://arxiv.org/abs/2504.02370v1","title":"A Spectral Approach for Quasinormal Frequencies of Noncommutative\n  Geometry-inspired Wormholes","summary":"We present a detailed investigation of quasinormal modes (QNMs) for\nnoncommutative geometry-inspired wormholes, focusing on scalar,\nelectromagnetic, and vector-type gravitational perturbations. By employing the\nspectral method, the perturbation equations are reformulated into an eigenvalue\nproblem over a compact domain, using Chebyshev polynomials to ensure high\nprecision and fast numerical convergence. Our results reveal the absence of\noverdamped modes, with all detected QNMs exhibiting oscillatory behaviour.\nAdditionally, for large values of the rescaled mass parameter, the QNMs of the\nnoncommutative wormhole transition smoothly to those of the classical\nSchwarzschild wormhole, validating the accuracy of the spectral method. This\nwork represents the first comprehensive exploration of QNMs in noncommutative\ngeometry-inspired wormholes, shedding light on their stability and dynamical\nproperties.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-03T08:04:17Z"}
{"aid":"http://arxiv.org/abs/2504.02377v1","title":"Research Paper Recommender System by Considering Users' Information\n  Seeking Behaviors","summary":"With the rapid growth of scientific publications, researchers need to spend\nmore time and effort searching for papers that align with their research\ninterests. To address this challenge, paper recommendation systems have been\ndeveloped to help researchers in effectively identifying relevant paper. One of\nthe leading approaches to paper recommendation is content-based filtering\nmethod. Traditional content-based filtering methods recommend relevant papers\nto users based on the overall similarity of papers. However, these approaches\ndo not take into account the information seeking behaviors that users commonly\nemploy when searching for literature. Such behaviors include not only\nevaluating the overall similarity among papers, but also focusing on specific\nsections, such as the method section, to ensure that the approach aligns with\nthe user's interests. In this paper, we propose a content-based filtering\nrecommendation method that takes this information seeking behavior into\naccount. Specifically, in addition to considering the overall content of a\npaper, our approach also takes into account three specific sections\n(background, method, and results) and assigns weights to them to better reflect\nuser preferences. We conduct offline evaluations on the publicly available DBLP\ndataset, and the results demonstrate that the proposed method outperforms six\nbaseline methods in terms of precision, recall, F1-score, MRR, and MAP.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-03T08:11:58Z"}
{"aid":"http://arxiv.org/abs/2504.02403v1","title":"DaKultur: Evaluating the Cultural Awareness of Language Models for\n  Danish with Native Speakers","summary":"Large Language Models (LLMs) have seen widespread societal adoption. However,\nwhile they are able to interact with users in languages beyond English, they\nhave been shown to lack cultural awareness, providing anglocentric or\ninappropriate responses for underrepresented language communities. To\ninvestigate this gap and disentangle linguistic versus cultural proficiency, we\nconduct the first cultural evaluation study for the mid-resource language of\nDanish, in which native speakers prompt different models to solve tasks\nrequiring cultural awareness. Our analysis of the resulting 1,038 interactions\nfrom 63 demographically diverse participants highlights open challenges to\ncultural adaptation: Particularly, how currently employed automatically\ntranslated data are insufficient to train or measure cultural adaptation, and\nhow training on native-speaker data can more than double response acceptance\nrates. We release our study data as DaKultur - the first native Danish cultural\nawareness dataset.","main_category":"cs.CL","categories":"cs.CL,cs.CY,cs.HC","published":"2025-04-03T08:52:42Z"}
{"aid":"http://arxiv.org/abs/2504.02404v1","title":"AnesBench: Multi-Dimensional Evaluation of LLM Reasoning in\n  Anesthesiology","summary":"The application of large language models (LLMs) in the medical field has\ngained significant attention, yet their reasoning capabilities in more\nspecialized domains like anesthesiology remain underexplored. In this paper, we\nsystematically evaluate the reasoning capabilities of LLMs in anesthesiology\nand analyze key factors influencing their performance. To this end, we\nintroduce AnesBench, a cross-lingual benchmark designed to assess\nanesthesiology-related reasoning across three levels: factual retrieval (System\n1), hybrid reasoning (System 1.x), and complex decision-making (System 2).\nThrough extensive experiments, we first explore how model characteristics,\nincluding model scale, Chain of Thought (CoT) length, and language\ntransferability, affect reasoning performance. Then, we further evaluate the\neffectiveness of different training strategies, leveraging our curated\nanesthesiology-related dataset, including continuous pre-training (CPT) and\nsupervised fine-tuning (SFT). Additionally, we also investigate how the\ntest-time reasoning techniques, such as Best-of-N sampling and beam search,\ninfluence reasoning performance, and assess the impact of reasoning-enhanced\nmodel distillation, specifically DeepSeek-R1. We will publicly release\nAnesBench, along with our CPT and SFT training datasets and evaluation code at\nhttps://github.com/MiliLab/AnesBench.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T08:54:23Z"}
{"aid":"http://arxiv.org/abs/2504.02416v1","title":"Hyperspectral Remote Sensing Images Salient Object Detection: The First\n  Benchmark Dataset and Baseline","summary":"The objective of hyperspectral remote sensing image salient object detection\n(HRSI-SOD) is to identify objects or regions that exhibit distinct spectrum\ncontrasts with the background. This area holds significant promise for\npractical applications; however, progress has been limited by a notable\nscarcity of dedicated datasets and methodologies. To bridge this gap and\nstimulate further research, we introduce the first HRSI-SOD dataset, termed\nHRSSD, which includes 704 hyperspectral images and 5327 pixel-level annotated\nsalient objects. The HRSSD dataset poses substantial challenges for salient\nobject detection algorithms due to large scale variation, diverse\nforeground-background relations, and multi-salient objects. Additionally, we\npropose an innovative and efficient baseline model for HRSI-SOD, termed the\nDeep Spectral Saliency Network (DSSN). The core of DSSN is the Cross-level\nSaliency Assessment Block, which performs pixel-wise attention and evaluates\nthe contributions of multi-scale similarity maps at each spatial location,\neffectively reducing erroneous responses in cluttered regions and emphasizes\nsalient regions across scales. Additionally, the High-resolution Fusion Module\ncombines bottom-up fusion strategy and learned spatial upsampling to leverage\nthe strengths of multi-scale saliency maps, ensuring accurate localization of\nsmall objects. Experiments on the HRSSD dataset robustly validate the\nsuperiority of DSSN, underscoring the critical need for specialized datasets\nand methodologies in this domain. Further evaluations on the HSOD-BIT and\nHS-SOD datasets demonstrate the generalizability of the proposed method. The\ndataset and source code are publicly available at\nhttps://github.com/laprf/HRSSD.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T09:12:42Z"}
{"aid":"http://arxiv.org/abs/2504.02427v1","title":"Stochastic domination and lifts of random variables in percolation\n  theory","summary":"Consider some matrix waiting for its coefficients to be written. For each\ncolumn, sample independently one Bernoulli random variable of some parameter\n$p$. Seeing all this and possibly using extra randomness, Alice then chooses\none spot in each column, in any way she wants. When the Bernoulli random\nvariable of some column is equal to 1, the number 1 is written in the chosen\nspot. When the Bernoulli random variable of a column is 0, nothing is done on\nthis column. We prove that, using extra randomness, it is possible for Bob to\nfill the empty spots with well chosen 0's and 1's so that the entries of the\nmatrix are independent Bernoulli random variables of parameter $p$. We\ninvestigate various generalisations and variations of this problem, and use\nthis result to revisit and generalise (nonstrict) monotonicity of the\npercolation threshold $p_c$ with respect to some sort of graph-quotienting,\nnamely fibrations.\n  In a second part, which is independent of the first one, we revisit strict\nmonotonicity of $p_c$ with respect to fibrations, a result that naturally\nrequires more assumptions than its nonstrict counterpart. We reprove the\nbond-percolation case of the result of Martineau--Severo without resorting to\nessential enhancements, using couplings instead.","main_category":"math.PR","categories":"math.PR,math.CO","published":"2025-04-03T09:31:59Z"}
{"aid":"http://arxiv.org/abs/2504.02431v1","title":"Koney: A Cyber Deception Orchestration Framework for Kubernetes","summary":"System operators responsible for protecting software applications remain\nhesitant to implement cyber deception technology, including methods that place\ntraps to catch attackers, despite its proven benefits. Overcoming their\nconcerns removes a barrier that currently hinders industry adoption of\ndeception technology. Our work introduces deception policy documents to\ndescribe deception technology \"as code\" and pairs them with Koney, a Kubernetes\noperator, which facilitates the setup, rotation, monitoring, and removal of\ntraps in Kubernetes. We leverage cloud-native technologies, such as service\nmeshes and eBPF, to automatically add traps to containerized software\napplications, without having access to the source code. We focus specifically\non operational properties, such as maintainability, scalability, and\nsimplicity, which we consider essential to accelerate the adoption of cyber\ndeception technology and to facilitate further research on cyber deception.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-03T09:37:14Z"}
{"aid":"http://arxiv.org/abs/2504.02436v1","title":"SkyReels-A2: Compose Anything in Video Diffusion Transformers","summary":"This paper presents SkyReels-A2, a controllable video generation framework\ncapable of assembling arbitrary visual elements (e.g., characters, objects,\nbackgrounds) into synthesized videos based on textual prompts while maintaining\nstrict consistency with reference images for each element. We term this task\nelements-to-video (E2V), whose primary challenges lie in preserving the\nfidelity of each reference element, ensuring coherent composition of the scene,\nand achieving natural outputs. To address these, we first design a\ncomprehensive data pipeline to construct prompt-reference-video triplets for\nmodel training. Next, we propose a novel image-text joint embedding model to\ninject multi-element representations into the generative process, balancing\nelement-specific consistency with global coherence and text alignment. We also\noptimize the inference pipeline for both speed and output stability. Moreover,\nwe introduce a carefully curated benchmark for systematic evaluation, i.e, A2\nBench. Experiments demonstrate that our framework can generate diverse,\nhigh-quality videos with precise element control. SkyReels-A2 is the first\nopen-source commercial grade model for the generation of E2V, performing\nfavorably against advanced closed-source commercial models. We anticipate\nSkyReels-A2 will advance creative applications such as drama and virtual\ne-commerce, pushing the boundaries of controllable video generation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T09:50:50Z"}
{"aid":"http://arxiv.org/abs/2504.02437v1","title":"MonoGS++: Fast and Accurate Monocular RGB Gaussian SLAM","summary":"We present MonoGS++, a novel fast and accurate Simultaneous Localization and\nMapping (SLAM) method that leverages 3D Gaussian representations and operates\nsolely on RGB inputs. While previous 3D Gaussian Splatting (GS)-based methods\nlargely depended on depth sensors, our approach reduces the hardware dependency\nand only requires RGB input, leveraging online visual odometry (VO) to generate\nsparse point clouds in real-time. To reduce redundancy and enhance the quality\nof 3D scene reconstruction, we implemented a series of methodological\nenhancements in 3D Gaussian mapping. Firstly, we introduced dynamic 3D Gaussian\ninsertion to avoid adding redundant Gaussians in previously well-reconstructed\nareas. Secondly, we introduced clarity-enhancing Gaussian densification module\nand planar regularization to handle texture-less areas and flat surfaces\nbetter. We achieved precise camera tracking results both on the synthetic\nReplica and real-world TUM-RGBD datasets, comparable to those of the\nstate-of-the-art. Additionally, our method realized a significant 5.57x\nimprovement in frames per second (fps) over the previous state-of-the-art,\nMonoGS.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T09:51:51Z"}
{"aid":"http://arxiv.org/abs/2504.02439v1","title":"Estimating Scene Flow in Robot Surroundings with Distributed\n  Miniaturized Time-of-Flight Sensors","summary":"Tracking motions of humans or objects in the surroundings of the robot is\nessential to improve safe robot motions and reactions. In this work, we present\nan approach for scene flow estimation from low-density and noisy point clouds\nacquired from miniaturized Time of Flight (ToF) sensors distributed on the\nrobot body. The proposed method clusters points from consecutive frames and\napplies Iterative Closest Point (ICP) to estimate a dense motion flow, with\nadditional steps introduced to mitigate the impact of sensor noise and\nlow-density data points. Specifically, we employ a fitness-based classification\nto distinguish between stationary and moving points and an inlier removal\nstrategy to refine geometric correspondences. The proposed approach is\nvalidated in an experimental setup where 24 ToF are used to estimate the\nvelocity of an object moving at different controlled speeds. Experimental\nresults show that the method consistently approximates the direction of the\nmotion and its magnitude with an error which is in line with sensor noise.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-03T09:57:51Z"}
{"aid":"http://arxiv.org/abs/2504.02441v1","title":"Cognitive Memory in Large Language Models","summary":"This paper examines memory mechanisms in Large Language Models (LLMs),\nemphasizing their importance for context-rich responses, reduced\nhallucinations, and improved efficiency. It categorizes memory into sensory,\nshort-term, and long-term, with sensory memory corresponding to input prompts,\nshort-term memory processing immediate context, and long-term memory\nimplemented via external databases or structures. The text-based memory section\ncovers acquisition (selection and summarization), management (updating,\naccessing, storing, and resolving conflicts), and utilization (full-text\nsearch, SQL queries, semantic search). The KV cache-based memory section\ndiscusses selection methods (regularity-based summarization, score-based\napproaches, special token embeddings) and compression techniques (low-rank\ncompression, KV merging, multimodal compression), along with management\nstrategies like offloading and shared attention mechanisms. Parameter-based\nmemory methods (LoRA, TTT, MoE) transform memories into model parameters to\nenhance efficiency, while hidden-state-based memory approaches (chunk\nmechanisms, recurrent transformers, Mamba model) improve long-text processing\nby combining RNN hidden states with current methods. Overall, the paper offers\na comprehensive analysis of LLM memory mechanisms, highlighting their\nsignificance and future research directions.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-03T09:58:19Z"}
{"aid":"http://arxiv.org/abs/2504.02442v1","title":"Youthful perspectives on sustainability: Examining pro-environmental\n  behaviors in tourism through latent class cluster analysis","summary":"Tourism has emerged as a significant driver of the global economy. As its\neconomic impact grows, concerns regarding environmental sustainability have\nintensified. This paper explores the dual dimensions of sustainable tourism:\nthe relationship between tourism supply and sustainability, and tourist demand\ncharacteristics. It highlights the critical role of young tourists, who exhibit\na heightened awareness of environmental issues and advocate for sustainable\npractices. By conducting a survey among young Italian university students, the\nstudy identifies distinct segments based on family background, political\norientation, and travel habits. Utilizing latent class cluster analysis, the\nfindings aim to enhance understanding of pro-environmental behaviors among\nyouth, offering insights for policymakers to foster sustainable tourism\npractices.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-03T09:58:51Z"}
{"aid":"http://arxiv.org/abs/2504.02446v1","title":"Revolutionizing Medical Data Transmission with IoMT: A Comprehensive\n  Survey of Wireless Communication Solutions and Future Directions","summary":"Traditional hospital-based medical examination methods face unprecedented\nchallenges due to the aging global population. The Internet of Medical Things\n(IoMT), an advanced extension of the Internet of Things (IoT) tailored for the\nmedical field, offers a transformative solution for delivering medical care.\nIoMT consists of interconnected medical devices that collect and transmit\npatients' vital signs online. This data can be analyzed to identify potential\nhealth issues, support medical decision-making, enhance patient outcomes, and\nstreamline healthcare operations. Additionally, IoMT helps individuals make\ninformed decisions about their health and fitness. There is a natural synergy\nwith emerging communication technologies to ensure the secure and timely\ntransmission of medical data. This paper presents the first comprehensive\ntutorial on cutting-edge IoMT research focusing on wireless communication-based\nsolutions. It introduces a systematic three-tier framework to analyze IoMT\nnetworks and identify application scenarios. The paper examines the medical\ndata transmission process, including intra-wireless Body Area Networks (WBAN),\ninter-WBAN, and beyond-WBAN communications. It also discusses the challenges of\nimplementing IoMT applications, such as the longevity of biosensors, co-channel\ninterference management, information security, and data processing delays.\nProposed solutions to these challenges are explored from a wireless\ncommunication perspective, and future research directions are outlined. The\nsurvey concludes with a summary of key findings and insights.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-03T10:00:42Z"}
{"aid":"http://arxiv.org/abs/2504.02449v1","title":"Strongly regular graphs with parameters (85,14,3,2) do not exist","summary":"We investigate the second smallest unresolved feasible set of parameters of\nstrongly regular graphs, $(v,k,\\lambda,\\mu)=(85,14,3,2)$. Using the\nclassification of cubic graphs of small degree, we restrict possible local\nstructure of such a graph $G$. After that, we exhaustively enumerate possible\nneighbourhoods of a maximal $3$-clique of $G$ and check them against a variety\nof conditions, including the combinatorial ones, coming from $\\lambda=3$ and\n$\\mu=2$, as well as the linear algebra ones, utilising the Euclidean\nrepresentation of $G$. These conditions yield contradiction in all cases, and\nhence, no $\\mathrm{srg}(85,14,3,2)$ exists.","main_category":"math.CO","categories":"math.CO","published":"2025-04-03T10:13:09Z"}
{"aid":"http://arxiv.org/abs/2504.02451v1","title":"ConMo: Controllable Motion Disentanglement and Recomposition for\n  Zero-Shot Motion Transfer","summary":"The development of Text-to-Video (T2V) generation has made motion transfer\npossible, enabling the control of video motion based on existing footage.\nHowever, current methods have two limitations: 1) struggle to handle\nmulti-subjects videos, failing to transfer specific subject motion; 2) struggle\nto preserve the diversity and accuracy of motion as transferring to subjects\nwith varying shapes. To overcome these, we introduce \\textbf{ConMo}, a\nzero-shot framework that disentangle and recompose the motions of subjects and\ncamera movements. ConMo isolates individual subject and background motion cues\nfrom complex trajectories in source videos using only subject masks, and\nreassembles them for target video generation. This approach enables more\naccurate motion control across diverse subjects and improves performance in\nmulti-subject scenarios. Additionally, we propose soft guidance in the\nrecomposition stage which controls the retention of original motion to adjust\nshape constraints, aiding subject shape adaptation and semantic transformation.\nUnlike previous methods, ConMo unlocks a wide range of applications, including\nsubject size and position editing, subject removal, semantic modifications, and\ncamera motion simulation. Extensive experiments demonstrate that ConMo\nsignificantly outperforms state-of-the-art methods in motion fidelity and\nsemantic consistency. The code is available at\nhttps://github.com/Andyplus1/ConMo.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T10:15:52Z"}
{"aid":"http://arxiv.org/abs/2504.02454v1","title":"Taylor Series-Inspired Local Structure Fitting Network for Few-shot\n  Point Cloud Semantic Segmentation","summary":"Few-shot point cloud semantic segmentation aims to accurately segment\n\"unseen\" new categories in point cloud scenes using limited labeled data.\nHowever, pretraining-based methods not only introduce excessive time overhead\nbut also overlook the local structure representation among irregular point\nclouds. To address these issues, we propose a pretraining-free local structure\nfitting network for few-shot point cloud semantic segmentation, named\nTaylorSeg. Specifically, inspired by Taylor series, we treat the local\nstructure representation of irregular point clouds as a polynomial fitting\nproblem and propose a novel local structure fitting convolution, called\nTaylorConv. This convolution learns the low-order basic information and\nhigh-order refined information of point clouds from explicit encoding of local\ngeometric structures. Then, using TaylorConv as the basic component, we\nconstruct two variants of TaylorSeg: a non-parametric TaylorSeg-NN and a\nparametric TaylorSeg-PN. The former can achieve performance comparable to\nexisting parametric models without pretraining. For the latter, we equip it\nwith an Adaptive Push-Pull (APP) module to mitigate the feature distribution\ndifferences between the query set and the support set. Extensive experiments\nvalidate the effectiveness of the proposed method. Notably, under the 2-way\n1-shot setting, TaylorSeg-PN achieves improvements of +2.28% and +4.37% mIoU on\nthe S3DIS and ScanNet datasets respectively, compared to the previous\nstate-of-the-art methods. Our code is available at\nhttps://github.com/changshuowang/TaylorSeg.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T10:19:06Z"}
{"aid":"http://arxiv.org/abs/2504.02458v1","title":"Retrieval-Augmented Purifier for Robust LLM-Empowered Recommendation","summary":"Recently, Large Language Model (LLM)-empowered recommender systems have\nrevolutionized personalized recommendation frameworks and attracted extensive\nattention. Despite the remarkable success, existing LLM-empowered RecSys have\nbeen demonstrated to be highly vulnerable to minor perturbations. To mitigate\nthe negative impact of such vulnerabilities, one potential solution is to\nemploy collaborative signals based on item-item co-occurrence to purify the\nmalicious collaborative knowledge from the user's historical interactions\ninserted by attackers. On the other hand, due to the capabilities to expand\ninsufficient internal knowledge of LLMs, Retrieval-Augmented Generation (RAG)\ntechniques provide unprecedented opportunities to enhance the robustness of\nLLM-empowered recommender systems by introducing external collaborative\nknowledge. Therefore, in this paper, we propose a novel framework (RETURN) by\nretrieving external collaborative signals to purify the poisoned user profiles\nand enhance the robustness of LLM-empowered RecSys in a plug-and-play manner.\nSpecifically, retrieval-augmented perturbation positioning is proposed to\nidentify potential perturbations within the users' historical sequences by\nretrieving external knowledge from collaborative item graphs. After that, we\nfurther retrieve the collaborative knowledge to cleanse the perturbations by\nusing either deletion or replacement strategies and introduce a robust ensemble\nrecommendation strategy to generate final robust predictions. Extensive\nexperiments on three real-world datasets demonstrate the effectiveness of the\nproposed RETURN.","main_category":"cs.IR","categories":"cs.IR,cs.AI","published":"2025-04-03T10:22:30Z"}
{"aid":"http://arxiv.org/abs/2504.02475v1","title":"Heat Conduction with Phase Change in Permafrost Modules of Vegetation\n  Models","summary":"We consider the problem of heat conduction with phase change, that is\nessential for permafrost modeling in Land Surface Models and Dynamic Global\nVegetation Models. These models require minimal computational effort and an\nextremely robust solver for large-scale, long-term simulations. The weak\nenthalpy formulation of the Stefan problem is used as the mathematical model\nand a finite element method is employed for the discretization. Leveraging the\npiecewise affine structure of the nonlinear time-stepping equation system, we\ndemonstrate that this system has a unique solution and provide a solver that is\nguaranteed to find this solution in a finite number of steps from any initial\nguess. Comparisons with the Neumann analytical solution and tests in the\nLund-Potsdam-Jena managed Land vegetation model reveal that the new method does\nnot introduce significantly higher computational costs than the widely used\nDECP method while providing greater accuracy. In particular, it avoids a known\nnonphysical artifact in the solution.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-03T10:52:35Z"}
{"aid":"http://arxiv.org/abs/2504.02485v1","title":"Tilted dipolar bosons in the quasi-2D regime: from liquid stripes to\n  droplets","summary":"We characterize a system of tilted dipoles in a quasi two-dimensional\n(flattened) geometry and in the thermodynamic limit. We consider a finite\ntrapping in the z-axis achievable in current experiments. We compute the phase\ndiagram of the system at its equilibrium density for high tilting angles, where\nit becomes self-bound, and a striped liquid state emerges. To characterize the\nsystem, we perform a variational calculation, which is benchmarked with the\nsolution of the extended Gross-Pitaevskii equation. We connect the\nphenomenology in the thermodynamic limit to the physics of the finite-size\nsystem, provide parameters for the realization of potentially supersolid\nstriped states and study the critical number for dipolar droplet formation. Our\nresults are helpful to guide potential experiments in the study of dipolar\natoms in quasi two-dimensional geometries in the dipole-dominated regime.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas","published":"2025-04-03T11:07:48Z"}
{"aid":"http://arxiv.org/abs/2504.02490v1","title":"Iterative blow-ups for maps with bounded $\\mathcal{A}$-variation: a\n  refinement, with application to $\\mathrm{BD}$ and $\\mathrm{BV}$","summary":"We refine the iterated blow-up techniques. This technique, combined with a\nrigidity result and a specific choice of the kernel projection in the\nPoincar\\'e inequality, might be employed to completely linearize blow-ups along\nat least one sequence. We show how to implement such argument by applying it to\nderive affine blow-up limits for $\\mathrm{BD}$ and $\\mathrm{BV}$ functions\naround Cantor points. In doing so we identify a specific subset of points -\ncalled totally singular points having blow-ups with completely singular\ngradient measure $D p=D^s p$, $\\mathcal{E} p=\\mathcal{E}^s p$ - at which such\nlinearization fails.","main_category":"math.AP","categories":"math.AP,math.FA","published":"2025-04-03T11:13:47Z"}
{"aid":"http://arxiv.org/abs/2504.02493v1","title":"On zero-divisor graph of the ring of Gaussian integers modulo $2^n$","summary":"For a commutative ring $R$, the zero-divisor graph of $R$ is a simple graph\nwith the vertex set as the set of all zero-divisors of $R$ and two distinct\nvertices $x$ and $y$ are adjacent if and only if $xy = 0$. This article\nattempts to predict the structure of the zero-divisor graph of the ring of\nGaussian integers modulo $2$ to the power $n$ and determine the size, chromatic\nnumber, clique number, independence number, and matching through associate\nclasses of divisors of $2^n$ in $\\mathbb{Z}_{2^n}[i]$. In addition, a few\ntopological indices of the corresponding zero-divisor graph, are obtained.","main_category":"math.AC","categories":"math.AC,math.CO,math.NT","published":"2025-04-03T11:15:59Z"}
{"aid":"http://arxiv.org/abs/2504.02496v1","title":"Group-based Distinctive Image Captioning with Memory Difference Encoding\n  and Attention","summary":"Recent advances in image captioning have focused on enhancing accuracy by\nsubstantially increasing the dataset and model size. While conventional\ncaptioning models exhibit high performance on established metrics such as BLEU,\nCIDEr, and SPICE, the capability of captions to distinguish the target image\nfrom other similar images is under-explored. To generate distinctive captions,\na few pioneers employed contrastive learning or re-weighted the ground-truth\ncaptions. However, these approaches often overlook the relationships among\nobjects in a similar image group (e.g., items or properties within the same\nalbum or fine-grained events). In this paper, we introduce a novel approach to\nenhance the distinctiveness of image captions, namely Group-based Differential\nDistinctive Captioning Method, which visually compares each image with other\nimages in one similar group and highlights the uniqueness of each image. In\nparticular, we introduce a Group-based Differential Memory Attention (GDMA)\nmodule, designed to identify and emphasize object features in an image that are\nuniquely distinguishable within its image group, i.e., those exhibiting low\nsimilarity with objects in other images. This mechanism ensures that such\nunique object features are prioritized during caption generation for the image,\nthereby enhancing the distinctiveness of the resulting captions. To further\nrefine this process, we select distinctive words from the ground-truth captions\nto guide both the language decoder and the GDMA module. Additionally, we\npropose a new evaluation metric, the Distinctive Word Rate (DisWordRate), to\nquantitatively assess caption distinctiveness. Quantitative results indicate\nthat the proposed method significantly improves the distinctiveness of several\nbaseline models, and achieves state-of-the-art performance on distinctiveness\nwhile not excessively sacrificing accuracy...","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-03T11:19:51Z"}
{"aid":"http://arxiv.org/abs/2504.02497v1","title":"An all-electrical scheme for valley polarization in graphene","summary":"We propose an all-electrical setup for achieving valley polarization in\ngraphene. The setup consists of a finite graphene sheet connected to normal\nmetal electrodes on both sides, with the junctions aligned along the zigzag\nedges while the armchair edges remain free. Each normal metal has two\nterminals, and when a bias is applied at one terminal while keeping the other\nthree grounded, valley polarization arises due to transverse momentum matching\nbetween graphene and the normal metal. The valley polarization is maximized\nwhen the Fermi wave vector of the normal metal is approximately half the\nseparation between the $K$ and $K'$ valleys in graphene. We analyze the\ndependence of conductance and valley polarization on system parameters such as\nthe width and length of the graphene sheet, as well as the chemical potentials\nof graphene and the normal metal. The conductance through graphene increases\nwith its width, while an increase in length initially reduces the conductance\nbefore leading to oscillatory behavior due to Fabry-P\\'erot interference. The\nvalley polarization efficiency decreases with increasing graphene length due to\ninter-valley mixing from back-and-forth reflections within the graphene region.\nFurthermore, we investigate the impact of disorder in graphene and find that\nwhile conductance near the Dirac point increases with disorder strength due to\nenhanced density of states, valley polarization efficiency decreases due to\nintervalley scattering. Our results provide insights into controlling valley\npolarization in graphene-based devices for valleytronic applications.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-03T11:20:41Z"}
{"aid":"http://arxiv.org/abs/2504.02502v1","title":"Berry-Esseen bounds for step-reinforced random walks","summary":"We study both the positively and negatively step-reinforced random walks with\nparameter $p$. For a step distribution $\\mu$ with finite second moment, the\npositively step-reinforced random walk with $p\\in [1/2,1)$ and the negatively\nstep-reinforced random walk with $p\\in (0,1)$ converge to a normal distribution\nunder suitable normalization. In this work, we obtain the rates of convergence\nto normality for both cases under the assumption that $\\mu$ has a finite third\nmoment. In the proofs, we establish a Berry-Esseen bound for general\nfunctionals of independent random variables, utilize the randomly weighted sum\nrepresentations of step-reinforced random walks, and apply special comparison\narguments to quantify the Kolmogorov distance between a mixed normal\ndistribution and its corresponding normal distribution.","main_category":"math.PR","categories":"math.PR","published":"2025-04-03T11:35:20Z"}
{"aid":"http://arxiv.org/abs/2504.02505v1","title":"Centrality dependence of charged-particle pseudorapidity density at\n  midrapidity in Pb-Pb collisions at $\\mathbf{\\sqrt{\\textit{s}_{\\rm NN}} =\n  5.36}$ TeV","summary":"The ALICE Collaboration reports its first LHC Run 3 measurements of\ncharged-particle pseudorapidity density at midrapidity in Pb-Pb collisions at a\ncentre-of-mass energy per nucleon pair of $\\sqrt{s_{\\mathrm{NN}}}=5.36$ TeV.\nParticle multiplicity in high-energy collisions characterises the system\ngeometry, constrains particle-production mechanisms, and is used to estimate\ninitial energy density. Multiplicity also acts as a reference for subsequent\nmeasurements as a function of centrality. In this letter, for the first time,\ncharged particles are reconstructed using the upgraded ALICE Inner Tracking\nSystem and Time Projection Chamber, while the collision centrality is\ndetermined by measuring charged-particle multiplicities with the Fast\nInteraction Trigger system. Pseudorapidity density, ${\\rm d}N_{\\rm ch}/{\\rm\nd}\\eta$, is presented, averaged over events, for various centrality classes.\nResults are shown as a function of pseudorapidity and the average number of\nparticipating nucleons ($\\langle N_{\\mathrm{part}}\\rangle$) in the collision.\nThe average charged-particle pseudorapidity density ($\\langle {\\rm d}N_{\\rm\nch}/{\\rm d}\\eta \\rangle$) at midrapidity ($|\\eta|<0.5$) is 2047 $\\pm$ 54 for\nthe 5% most central collisions. The value of $\\langle {\\rm d}N_{\\rm ch}/{\\rm\nd}\\eta \\rangle$ normalised to $\\langle N_{\\mathrm{part}}\\rangle/2$ as a\nfunction of $\\sqrt{s_{\\mathrm{NN}}}$ follows the trend established in previous\nmeasurements in heavy-ion collisions. Theoretical models based on mechanisms\nfor particle production in nuclear collisions that involve the formation of\nquark-gluon plasma medium and models based on individual nucleon-nucleon\ninteractions are compared to the data.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-03T11:36:43Z"}
{"aid":"http://arxiv.org/abs/2504.02520v1","title":"Beyond Traditional Coherence Time: An Electromagnetic Perspective for\n  Mobile Channels","summary":"Channel coherence time has been widely regarded as a critical parameter in\nthe design of mobile systems. However, a prominent challenge lies in\nintegrating electromagnetic (EM) polarization effects into the derivation of\nthe channel coherence time. In this paper, we develop a framework to analyze\nthe impact of polarization mismatch on the channel coherence time.\nSpecifically, we first establish an EM channel model to capture the essence of\nEM wave propagation. Based on this model, we then derive the EM temporal\ncorrelation function, incorporating the effects of polarization mismatch and\nbeam misalignment. Further, considering the random orientation of the mobile\nuser equipment (UE), we derive a closed-form solution for the EM coherence time\nin the turning scenario. When the trajectory degenerates into a straight line,\nwe also provide a closed-form lower bound on the EM coherence time. The\nsimulation results validate our theoretical analysis and reveal that neglecting\nthe EM polarization effects leads to overly optimistic estimates of the EM\ncoherence time.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-03T12:17:30Z"}
{"aid":"http://arxiv.org/abs/2504.02532v1","title":"Polynomial Bounds for the Graph Minor Structure Theorem","summary":"The Graph Minor Structure Theorem, originally proven by Robertson and Seymour\n[JCTB, 2003], asserts that there exist functions $f_1, f_2 \\colon \\mathbb{N}\n\\to \\mathbb{N}$ such that for every non-planar graph $H$ with $t := |V(H)|$,\nevery $H$-minor-free graph can be obtained via the clique-sum operation from\ngraphs which embed into surfaces where $H$ does not embed after deleting at\nmost $f_1(t)$ many vertices with up to at most $t^2-1$ many ``vortices'' which\nare of ``depth'' at most $f_2(t)$. In the proof presented by Robertson and\nSeymour the functions $f_1$ and $f_2$ are non-constructive. Kawarabayashi,\nThomas, and Wollan [arXiv, 2020] found a new proof showing that $f_1(t), f_2(t)\n\\in 2^{\\mathbf{poly}(t)}$. While believing that this bound was the best their\nmethods could achieve, Kawarabayashi, Thomas, and Wollan conjectured that $f_1$\nand $f_2$ can be improved to be polynomials.\n  In this paper we confirm their conjecture and prove that $f_1(t), f_2(t) \\in\n\\mathbf{O}(t^{2300})$. Our proofs are fully constructive and yield a\npolynomial-time algorithm that either finds $H$ as a minor in a graph $G$ or\nproduces a clique-sum decomposition for $G$ as above.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-03T12:35:45Z"}
{"aid":"http://arxiv.org/abs/2504.02545v1","title":"MAD: Makeup All-in-One with Cross-Domain Diffusion Model","summary":"Existing makeup techniques often require designing multiple models to handle\ndifferent inputs and align features across domains for different makeup tasks,\ne.g., beauty filter, makeup transfer, and makeup removal, leading to increased\ncomplexity. Another limitation is the absence of text-guided makeup try-on,\nwhich is more user-friendly without needing reference images. In this study, we\nmake the first attempt to use a single model for various makeup tasks.\nSpecifically, we formulate different makeup tasks as cross-domain translations\nand leverage a cross-domain diffusion model to accomplish all tasks. Unlike\nexisting methods that rely on separate encoder-decoder configurations or\ncycle-based mechanisms, we propose using different domain embeddings to\nfacilitate domain control. This allows for seamless domain switching by merely\nchanging embeddings with a single model, thereby reducing the reliance on\nadditional modules for different tasks. Moreover, to support precise\ntext-to-makeup applications, we introduce the MT-Text dataset by extending the\nMT dataset with textual annotations, advancing the practicality of makeup\ntechnologies.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T12:52:31Z"}
{"aid":"http://arxiv.org/abs/2504.02546v1","title":"GPG: A Simple and Strong Reinforcement Learning Baseline for Model\n  Reasoning","summary":"Reinforcement Learning (RL) can directly enhance the reasoning capabilities\nof large language models without extensive reliance on Supervised Fine-Tuning\n(SFT). In this work, we revisit the traditional Policy Gradient (PG) mechanism\nand propose a minimalist RL approach termed Group Policy Gradient (GPG). Unlike\nconventional methods, GPG directly optimize the original RL objective, thus\nobviating the need for surrogate loss functions. As illustrated in our paper,\nby eliminating both the critic and reference models, and avoiding KL divergence\nconstraints, our approach significantly simplifies the training process when\ncompared to Group Relative Policy Optimization (GRPO). Our approach achieves\nsuperior performance without relying on auxiliary techniques or adjustments.\nExtensive experiments demonstrate that our method not only reduces\ncomputational costs but also consistently outperforms GRPO across various\nunimodal and multimodal tasks. Our code is available at\nhttps://github.com/AMAP-ML/GPG.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-03T12:53:41Z"}
{"aid":"http://arxiv.org/abs/2504.02554v1","title":"Measure-independent description of wave-particle duality via coherence","summary":"Wave-particle duality as one of the expression of Bohr complementarity is a\nsignificant concept in the field of quantum mechanics. Quantitative analysis of\nwave-particle duality aims to establish a complementary relation between the\nparticle and wave properties. Beyond the conventional quantitative analysis\ndepending on special choice of quantum information measures, we are aimed to\nprovide a measure-independent complementary relation via coherence. By\nemploying maximally coherent states in the set of all states with fixed\ndiagonal elements, a measure-independent complementary relation is proposed.\nBased on this, we give a measure-independent description of\nwave-particle-mixedness triality in d-path interferometers. Our complementary\nrelations reveal the relationship between wave-particle duality and quantum\ncoherence, and also give a justification to coherence as it truly brings out\nthe wave nature of quantum systems at its heart.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-03T13:09:31Z"}
{"aid":"http://arxiv.org/abs/2504.02558v1","title":"Rip Current Segmentation: A Novel Benchmark and YOLOv8 Baseline Results","summary":"Rip currents are the leading cause of fatal accidents and injuries on many\nbeaches worldwide, emphasizing the importance of automatically detecting these\nhazardous surface water currents. In this paper, we address a novel task: rip\ncurrent instance segmentation. We introduce a comprehensive dataset containing\n$2,466$ images with newly created polygonal annotations for instance\nsegmentation, used for training and validation. Additionally, we present a\nnovel dataset comprising $17$ drone videos (comprising about $24K$ frames)\ncaptured at $30 FPS$, annotated with both polygons for instance segmentation\nand bounding boxes for object detection, employed for testing purposes. We\ntrain various versions of YOLOv8 for instance segmentation on static images and\nassess their performance on the test dataset (videos). The best results were\nachieved by the YOLOv8-nano model (runnable on a portable device), with an\nmAP50 of $88.94%$ on the validation dataset and $81.21%$ macro average on the\ntest dataset. The results provide a baseline for future research in rip current\nsegmentation. Our work contributes to the existing literature by introducing a\ndetailed, annotated dataset, and training a deep learning model for instance\nsegmentation of rip currents. The code, training details and the annotated\ndataset are made publicly available at https://github.com/Irikos/rip_currents.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-03T13:14:16Z"}
{"aid":"http://arxiv.org/abs/2504.02560v1","title":"L-LBVC: Long-Term Motion Estimation and Prediction for Learned\n  Bi-Directional Video Compression","summary":"Recently, learned video compression (LVC) has shown superior performance\nunder low-delay configuration. However, the performance of learned\nbi-directional video compression (LBVC) still lags behind traditional\nbi-directional coding. The performance gap mainly arises from inaccurate\nlong-term motion estimation and prediction of distant frames, especially in\nlarge motion scenes. To solve these two critical problems, this paper proposes\na novel LBVC framework, namely L-LBVC. Firstly, we propose an adaptive motion\nestimation module that can handle both short-term and long-term motions.\nSpecifically, we directly estimate the optical flows for adjacent frames and\nnon-adjacent frames with small motions. For non-adjacent frames with large\nmotions, we recursively accumulate local flows between adjacent frames to\nestimate long-term flows. Secondly, we propose an adaptive motion prediction\nmodule that can largely reduce the bit cost for motion coding. To improve the\naccuracy of long-term motion prediction, we adaptively downsample reference\nframes during testing to match the motion ranges observed during training.\nExperiments show that our L-LBVC significantly outperforms previous\nstate-of-the-art LVC methods and even surpasses VVC (VTM) on some test datasets\nunder random access configuration.","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-03T13:15:45Z"}
{"aid":"http://arxiv.org/abs/2504.02562v1","title":"Spectrum Assignment of Stochastic Systems with Multiplicative Noise","summary":"This paper studies the spectrum assignment of a class of stochastic systems\nwith multiplicative noise. A novel $\\alpha$-spectrum assignment is proposed for\ndiscrete-time and continuous-time stochastic systems with multiplicative noise.\nIn particular, $0$-spectrum assignment is equivalent to the pole assignment for\nthe deterministic systems. The main contribution is two-fold: On the one hand,\nwe present the conditions for $\\alpha$-spectrum assignment and the design of\nfeedback controllers based on the system parameters. On the other hand, when\nthe system parameters are unknown, we present a stochastic approximation\nalgorithm to learn the feedback gains which guarantee the spectrum of the\nstochastic systems to achieve the predetermined value. Numerical examples are\nprovided to demonstrate the effectiveness of the proposed algorithms.","main_category":"math.OC","categories":"math.OC","published":"2025-04-03T13:25:09Z"}
{"aid":"http://arxiv.org/abs/2504.02565v1","title":"MAD: A Magnitude And Direction Policy Parametrization for Stability\n  Constrained Reinforcement Learning","summary":"We introduce magnitude and direction (MAD) policies, a policy\nparameterization for reinforcement learning (RL) that preserves Lp closed-loop\nstability for nonlinear dynamical systems. Although complete in their ability\nto describe all stabilizing controllers, methods based on nonlinear Youla and\nsystem-level synthesis are significantly affected by the difficulty of\nparameterizing Lp-stable operators. In contrast, MAD policies introduce\nexplicit feedback on state-dependent features - a key element behind the\nsuccess of RL pipelines - without compromising closed-loop stability. This is\nachieved by describing the magnitude of the control input with a\ndisturbance-feedback Lp-stable operator, while selecting its direction based on\nstate-dependent features through a universal function approximator. We further\ncharacterize the robust stability properties of MAD policies under model\nmismatch. Unlike existing disturbance-feedback policy parameterizations, MAD\npolicies introduce state-feedback components compatible with model-free RL\npipelines, ensuring closed-loop stability without requiring model information\nbeyond open-loop stability. Numerical experiments show that MAD policies\ntrained with deep deterministic policy gradient (DDPG) methods generalize to\nunseen scenarios, matching the performance of standard neural network policies\nwhile guaranteeing closed-loop stability by design.","main_category":"eess.SY","categories":"eess.SY,cs.LG,cs.SY","published":"2025-04-03T13:26:26Z"}
{"aid":"http://arxiv.org/abs/2504.02569v1","title":"Fluorine production in He-burning regions of massive stars during cosmic\n  history","summary":"The origin of fluorine is still a debated question. AGB stars synthesise this\nelement and likely contribute significantly to its synthesis in the present-day\nUniverse. However, it is not clear whether other sources contribute, especially\nin the early Universe. We discuss variations of the surface abundances of\nfluorine coming from our massive star models and compare them with available\npresent-day observations. We compute the contribution of massive stars in\nproducing 19F over metallicities covering the whole cosmic history. We used\nmodels in the mass range of 9Msol < Mini < 300Msol at metallicities from Pop\nIII up to super-solar while accounting for the required nuclear network to\nfollow the evolution of 19F during the core H- and He-burning phases. Results\nfrom models with and without rotational mixing are presented. We find that\nrotating models predict a slight depletion of fluorine at their surface at the\nend of the MS phase. In more advanced evolutionary phases, only models with an\ninitial mass larger than 25Msol at metallicities Z > 0.014 show phases where\nthe abundance of fluorine is enhanced. This occurs when the star is a WR star\nof the WC type. WC stars can show surface abundances of fluorine ten times\nlarger than their initial abundance. However, we obtained that the winds of\nmassive stars at metallicities larger than Z=0.006 do not significantly\ncontribute to fluorine production, confirming previous findings. In contrast,\nvery metal-poor rapidly rotating massive star models may be important sources\nof fluorine through the mass expelled at the time of their SN explosion.\nObservations of WC stars at solar or super-solar metallicities may provide very\ninteresting indications on the nuclear pathways that lead to fluorine\nproduction in massive stars. The possibility of observing fluorine-rich CEMPs\nis also a way to put constrains in present models at very low metallicities.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-03T13:36:04Z"}
{"aid":"http://arxiv.org/abs/2504.02570v1","title":"Time resolution limits in silicon sensors from Landau fluctuations and\n  electronics noise","summary":"In this report, we derive analytical expressions for the time resolution\nlimits of standard silicon sensors, LGADs, and 3D trench sensors. We separately\nexamine the effects of Landau fluctuations and electronic noise. To analyze\nLandau fluctuations, we relate the time resolution of a single electron-hole\npair generated at a random position in the sensor to the time resolution\nassociated with the full ionization pattern produced by a charged particle. For\nelectronic noise, we explore optimal filtering techniques that minimize its\nimpact on time resolution, and evaluate how closely these can be approximated\nby practical filters. Finally, we demonstrate that the combined effect of\nLandau fluctuations and electronic noise cannot, in general, be simply\nexpressed as the quadratic sum of the individual contributions.","main_category":"hep-ex","categories":"hep-ex,physics.ins-det","published":"2025-04-03T13:36:06Z"}
{"aid":"http://arxiv.org/abs/2504.02577v1","title":"Reasoning Inconsistencies and How to Mitigate Them in Deep Learning","summary":"The recent advancements in Deep Learning models and techniques have led to\nsignificant strides in performance across diverse tasks and modalities.\nHowever, while the overall capabilities of models show promising growth, our\nunderstanding of their internal reasoning processes remains limited,\nparticularly concerning systematic inconsistencies or errors patterns of\nlogical or inferential flaws. These inconsistencies may manifest as\ncontradictory outputs, failure to generalize across similar tasks, or erroneous\nconclusions in specific contexts. Even detecting and measuring such reasoning\ndiscrepancies is challenging, as they may arise from opaque internal\nprocedures, biases and imbalances in training data, or the inherent complexity\nof the task. Without effective methods to detect, measure, and mitigate these\nerrors, there is a risk of deploying models that are biased, exploitable, or\nlogically unreliable. This thesis aims to address these issues by producing\nnovel methods for deep learning models that reason over knowledge graphs,\nnatural language, and images. The thesis contributes two techniques for\ndetecting and quantifying predictive inconsistencies originating from opaque\ninternal procedures in natural language and image processing models. To\nmitigate inconsistencies from biases in training data, this thesis presents a\ndata efficient sampling method to improve fairness and performance and a\nsynthetic dataset generation approach in low resource scenarios. Finally, the\nthesis offers two techniques to optimize the models for complex reasoning\ntasks. These methods enhance model performance while allowing for more faithful\nand interpretable exploration and exploitation during inference. Critically,\nthis thesis provides a comprehensive framework to improve the robustness,\nfairness, and interpretability of deep learning models across diverse tasks and\nmodalities.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.LG,cs.LO","published":"2025-04-03T13:40:55Z"}
{"aid":"http://arxiv.org/abs/2504.02578v1","title":"Helium escape signatures are generally strongest during younger ages but\n  this age dependence is lost in the diversity of observed exoplanets","summary":"Highly irradiated exoplanets undergo extreme hydrodynamic atmospheric escape,\ndue to their high level of received XUV flux. Over their lifetime, this escape\nvaries significantly, making evolution studies essential for interpreting the\ngrowing number of observations of escaping planetary atmospheres. In a previous\nwork, we modelled this evolving escape, alongside one of its observable\ntracers, the helium triplet transit signature at 1083nm. Using hydrodynamic and\nray-tracing models, we demonstrated that atmospheric escape and the\ncorresponding He 1083nm signature are stronger at younger ages, for a\n0.3$~M_\\text{J}$ gas-giant. Yet, the current literature includes several young\n(<1Gyr) planets with weak or non-detections in He 1083nm. To understand this\napparent discrepancy, we now perform detailed modelling for many of these\nsystems. The resulting He 1083nm predictions align relatively well with the\nobservations. From our two studies, we conclude that for any given planet,\nstronger atmospheric escape during younger ages produces deeper He 1083nm\nabsorption. However, for a population of exoplanets, the relation between\nyounger ages and stronger He absorptions is lost to the broad diversity of\ntheir various other system parameters. Accordingly, for the current sample of\nyoung, 1083nm-observed exoplanets, alternative trends take precedence. One such\ntrend is that planets with deeper geometrical transits exhibit more favourable\ndetections. Our modelling also agrees with the strong empirical trend in the\nliterature between $ EW \\cdot R_{*}^{2}$ and $F_{\\text{xuv}} \\cdot\nR_{\\text{pl}}^2 / \\Phi_{g}$. Additionally, we show that the coupling between\nthe lower and upper atmospheres is necessary for a robust prediction of the\n1083nm signature.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-03T13:41:16Z"}
{"aid":"http://arxiv.org/abs/2504.02579v1","title":"Bridging the Gap between Gaussian Diffusion Models and Universal\n  Quantization for Image Compression","summary":"Generative neural image compression supports data representation at extremely\nlow bitrate, synthesizing details at the client and consistently producing\nhighly realistic images. By leveraging the similarities between quantization\nerror and additive noise, diffusion-based generative image compression codecs\ncan be built using a latent diffusion model to \"denoise\" the artifacts\nintroduced by quantization. However, we identify three critical gaps in\nprevious approaches following this paradigm (namely, the noise level, noise\ntype, and discretization gaps) that result in the quantized data falling out of\nthe data distribution known by the diffusion model. In this work, we propose a\nnovel quantization-based forward diffusion process with theoretical foundations\nthat tackles all three aforementioned gaps. We achieve this through universal\nquantization with a carefully tailored quantization schedule and a diffusion\nmodel trained with uniform noise. Compared to previous work, our proposal\nproduces consistently realistic and detailed reconstructions, even at very low\nbitrates. In such a regime, we achieve the best rate-distortion-realism\nperformance, outperforming previous related works.","main_category":"eess.IV","categories":"eess.IV","published":"2025-04-03T13:42:19Z"}
{"aid":"http://arxiv.org/abs/2504.02583v1","title":"Ramírez's problems and fibers on well approximable set of systems of\n  affine forms","summary":"We show that badly approximable matrices are exactly those that, for any\ninhomogeneous parameter, can not be inhomogeneous approximated at every\nmonotone divergent rate, which generalizes Ram\\'irez's result (2018). We also\nestablish some metrical results of the fibers on well approximable set of\nsystems of affine forms, which gives answer to two of Ram\\'irez's problems\n(2018). Furthermore, we prove that badly approximable systems are exactly those\nthat, can not be approximated at each monotone convergent rate {\\psi}.\nMoreover, we study the topological structure of the set of approximation\nfunctions.","main_category":"math.NT","categories":"math.NT,math.CA","published":"2025-04-03T13:49:12Z"}
{"aid":"http://arxiv.org/abs/2504.02584v1","title":"Parabolic character sheaves and Hecke algebras","summary":"We show that certain Iwahori-Hecke algebras with unequal parameters can be\nrealized in the framework of parabolic character sheaves.","main_category":"math.RT","categories":"math.RT","published":"2025-04-03T13:49:50Z"}
{"aid":"http://arxiv.org/abs/2504.02586v1","title":"Deep learning for music generation. Four approaches and their\n  comparative evaluation","summary":"This paper introduces four different artificial intelligence algorithms for\nmusic generation and aims to compare these methods not only based on the\naesthetic quality of the generated music but also on their suitability for\nspecific applications. The first set of melodies is produced by a slightly\nmodified visual transformer neural network that is used as a language model.\nThe second set of melodies is generated by combining chat sonification with a\nclassic transformer neural network (the same method of music generation is\npresented in a previous research), the third set of melodies is generated by\ncombining the Schillinger rhythm theory together with a classic transformer\nneural network, and the fourth set of melodies is generated using GPT3\ntransformer provided by OpenAI. A comparative analysis is performed on the\nmelodies generated by these approaches and the results indicate that\nsignificant differences can be observed between them and regarding the\naesthetic value of them, GPT3 produced the most pleasing melodies, and the\nnewly introduced Schillinger method proved to generate better sounding music\nthan previous sonification methods.","main_category":"cs.SD","categories":"cs.SD,cs.AI,eess.AS","published":"2025-04-03T13:51:07Z"}
{"aid":"http://arxiv.org/abs/2504.02590v1","title":"LexPam: Legal Procedure Awareness-Guided Mathematical Reasoning","summary":"The legal mathematical reasoning ability of LLMs is crucial when applying\nthem to real-world scenarios, as it directly affects the credibility of the\nLLM. While existing legal LLMs can perform general judicial question answering,\ntheir legal mathematical reasoning capabilities have not been trained.\nOpen-domain reasoning models, though able to generate detailed calculation\nsteps, do not follow the reasoning logic required for legal scenarios.\nAdditionally, there is currently a lack of legal mathematical reasoning\ndatasets to help validate and enhance LLMs' reasoning abilities in legal\ncontexts. To address these issues, we propose the first Chinese legal\nMathematical Reasoning Dataset, LexNum, which includes three common legal\nmathematical reasoning scenarios: economic compensation, work injury\ncompensation, and traffic accident compensation. Based on LexNum, we tested the\nperformance of existing legal LLMs and reasoning LLMs, and introduced LexPam, a\nreinforcement learning algorithm guided by legal procedural awareness to train\nLLMs, enhancing their mathematical reasoning abilities in legal scenarios.\nExperiments on tasks in the three legal scenarios show that the performance of\nexisting legal LLMs and reasoning models in legal mathematical reasoning tasks\nis unsatisfactory. LexPam can enhance the LLM's ability in these tasks.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T13:54:53Z"}
{"aid":"http://arxiv.org/abs/2504.02595v1","title":"Native defects, hydrogen impurities, and metal dopants in CeO$_2$","summary":"Ceria (CeO$_2$) is a material of significant technological importance. A\ndetailed understanding of the material's defect physics and chemistry is key to\nunderstanding and optimizing its properties. Here, we report a hybrid\ndensity-functional study of native point defects, hydrogen impurities, and\nmetal dopants in CeO$_2$. We find that electron polarons ($\\eta_{\\rm Ce}^-$)\nand oxygen vacancies ($V_{\\rm O}^{2+}$) are the dominant native defects under\nconditions ranging from extreme oxidizing to highly reducing. Hydrogen is\nstable either in the hydroxyl (H$_i^+$) or hydride (H$_{\\rm O}^+$) structure\nbut the substitutional H$_{\\rm O}^+$ is energetically more favorable than\nH$_i^+$ only under highly reducing conditions. The interstitial H$_i^+$ is\nhighly mobile in the bulk. Yttrium (Y) is energetically most favorable at the\nsubstitutional Ce site. Copper (Cu) and nickel (Ni) can be incorporated at the\nsubstitutional site and/or an interstitial site, depending on actual conditions\nduring preparation, and the dopants can exist in different charge and spin\nstates. In light of the results, we discuss electronic and ionic conduction and\nthe effects of metal doping on the formation of electron polarons and oxygen\nvacancies.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-03T13:57:18Z"}
{"aid":"http://arxiv.org/abs/2504.02609v1","title":"One-loop correction to primordial tensor modes during radiation era","summary":"The ability to infer properties of primordial inflation relies on the\nconservation of the superhorizon perturbations between their exit during\ninflation, and their re-entry during radiation era. Any considerable departure\nfrom this property would require reinterpreting the data. This is why it is\nimportant to understand how superhorizon perturbations interact with the\nthermal plasma driving the radiation dominated Universe. We model the plasma by\nfree photons in a thermal state and compute the one-loop correction to the\npower spectrum of primordial tensor perturbations. This correction grows in\ntime and is not suppressed by any small parameter. While one-loop result is not\nreliable because it invalidates perturbation theory, it signals potentially\ninteresting effects that should be investigated further.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-03T14:10:50Z"}
{"aid":"http://arxiv.org/abs/2504.02616v1","title":"Cosmological gas accretion of Milky Way-type galaxies and the build-up\n  of galactic discs","summary":"In this work, we present results on the assembly of stellar discs belonging\nto Milky Way-type galaxies in the Auriga simulated sample. We study the net\naccretion of gas onto the disc region as a function of time and radius to\nassess the feasibility of the so-called inside-out formation of galaxy discs.\nWe found that most of the galaxies in our sample exhibit an inside-out disc\ngrowth, with younger stellar populations preferentially formed in the outer\nregions as accreted material turns into starts. This produces stable discs as\nlong as late-time accretion is free from significant external perturbations.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-03T14:14:47Z"}
{"aid":"http://arxiv.org/abs/2504.02617v1","title":"PicoPose: Progressive Pixel-to-Pixel Correspondence Learning for Novel\n  Object Pose Estimation","summary":"Novel object pose estimation from RGB images presents a significant challenge\nfor zero-shot generalization, as it involves estimating the relative 6D\ntransformation between an RGB observation and a CAD model of an object that was\nnot seen during training. In this paper, we introduce PicoPose, a novel\nframework designed to tackle this task using a three-stage pixel-to-pixel\ncorrespondence learning process. Firstly, PicoPose matches features from the\nRGB observation with those from rendered object templates, identifying the\nbest-matched template and establishing coarse correspondences. Secondly,\nPicoPose smooths the correspondences by globally regressing a 2D affine\ntransformation, including in-plane rotation, scale, and 2D translation, from\nthe coarse correspondence map. Thirdly, PicoPose applies the affine\ntransformation to the feature map of the best-matched template and learns\ncorrespondence offsets within local regions to achieve fine-grained\ncorrespondences. By progressively refining the correspondences, PicoPose\nsignificantly improves the accuracy of object poses computed via PnP/RANSAC.\nPicoPose achieves state-of-the-art performance on the seven core datasets of\nthe BOP benchmark, demonstrating exceptional generalization to novel objects\nrepresented by CAD models or object reference images. Code and models are\navailable at https://github.com/foollh/PicoPose.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T14:16:41Z"}
{"aid":"http://arxiv.org/abs/2504.02624v1","title":"EmbodiedSense: Understanding Embodied Activities with Earphones","summary":"In this paper, we propose EmbodiedSense, a sensing system based on commercial\nearphones, which enables fine-grained activity logs using existing sensors. The\nactivity logs record both user activities and the scenario in which the\nactivities took place, benefiting detailed behavior understanding. By\nunderstanding both the user and the environment, EmbodiedSense addresses three\nmain challenges: the limited recognition capability caused by\ninformation-hungry configurations (i.e., limited sensors available), the\nineffective fusion to extract ambient information such as contextual scenarios,\nand the interference from ambient noise. Specifically, EmbodiedSense consists\nof a context-aware scenario recognition module and spatial-aware activity\ndetection, which is further integrated with other attributes by expert\nknowledge. We implement our system on commercial earphones equipped with\nbinaural microphones and an Inertial Measurement Unit (IMU). By distinguishing\nusage scenarios and identifying the source of sounds, EmbodiedSense enables\nfine-grained activity logs in a zero-shot manner (evaluated with up to 41\ncategories) and outperforms strong baselines like ImageBind-LLM by 38%\nF1-score. Extensive evaluations demonstrate that EmbodiedSense is a promising\nsolution for long-term and short-term activity logs and provides significant\nbenefits in monitoring the wearer's daily life.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-03T14:21:35Z"}
{"aid":"http://arxiv.org/abs/2504.02631v1","title":"Feature splitting parallel algorithm for Dantzig selectors","summary":"The Dantzig selector is a widely used and effective method for variable\nselection in ultra-high-dimensional data. Feature splitting is an efficient\nprocessing technique that involves dividing these ultra-high-dimensional\nvariable datasets into manageable subsets that can be stored and processed more\neasily on a single machine. This paper proposes a variable splitting parallel\nalgorithm for solving both convex and nonconvex Dantzig selectors based on the\nproximal point algorithm. The primary advantage of our parallel algorithm,\ncompared to existing parallel approaches, is the significantly reduced number\nof iteration variables, which greatly enhances computational efficiency and\naccelerates the convergence speed of the algorithm. Furthermore, we show that\nour solution remains unchanged regardless of how the data is partitioned, a\nproperty referred to as partitioninsensitive. In theory, we use a concise proof\nframework to demonstrate that the algorithm exhibits linear convergence.\nNumerical experiments indicate that our algorithm performs competitively in\nboth parallel and nonparallel environments. The R package for implementing the\nproposed algorithm can be obtained at https://github.com/xfwu1016/PPADS.","main_category":"stat.CO","categories":"stat.CO","published":"2025-04-03T14:28:50Z"}
{"aid":"http://arxiv.org/abs/2504.02638v1","title":"Characterization of nuclear breakup as a function of hard-scattering\n  kinematics using dijets measured by ATLAS in $p$+Pb collisions","summary":"This Letter analyzes the sensitivity of event geometry estimators to the\ninitial-state kinematics of hard scattering in proton-lead collisions. This\nanalysis uses dijets as a proxy for the parton-parton scattering configuration,\ncorrelating it with event geometry estimators, namely the energy deposited in\nthe Zero-Degree Calorimeter and the transverse energy recorded in the Forward\nCalorimeter in the Pb-going direction. The analysis uses data recorded by the\nATLAS detector at the Large Hadron Collider with a nucleon-nucleon\ncenter-of-mass energy of 8.16 TeV, corresponding to an integrated luminosity of\n56 nb$^{-1}$. The jets are measured within the pseudorapidity interval $-$2.8\n$<$ $\\eta$ $<$ 4.5, where positive $\\eta$ values correspond to the direction of\nthe proton beam. Results are presented as a function of the Bjorken-$x$ of the\nparton originating from the proton, $x_{p}$. Both event geometry estimators are\nfound to be dependent on $x_{p}$, with the energy deposited in the Zero-Degree\nCalorimeter about six times less sensitive to $x_{p}$ compared with the\ntransverse energy deposited in the Forward Calorimeter.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-03T14:34:40Z"}
{"aid":"http://arxiv.org/abs/2504.02650v1","title":"Investigating Simple Drawings of $K_n$ using SAT","summary":"We present a SAT framework which allows to investigate properties of simple\ndrawings of the complete graph $K_n$ using the power of AI. In contrast to\nclassic imperative programming, where a program is operated step by step, our\nframework models mathematical questions as Boolean formulas which are then\nsolved using modern SAT solvers. Our framework for simple drawings is based on\na characterization via rotation systems and finite forbidden substructures. We\nshowcase its universality by addressing various open problems, reproving\nprevious computational results and deriving several new computational results.\nIn particular, we test and progress on several unavoidable configurations such\nas variants of Rafla's conjecture on plane Hamiltonian cycles, Harborth's\nconjecture on empty triangles, and crossing families for general simple\ndrawings as well as for various subclasses. Moreover, based our computational\nresults we propose some new challenging conjectures.","main_category":"cs.CG","categories":"cs.CG,cs.DM,math.CO","published":"2025-04-03T14:48:47Z"}
{"aid":"http://arxiv.org/abs/2504.02653v1","title":"Online and Offline Space-Filling Input Design for Nonlinear System\n  Identification: A Receding Horizon Control-Based Approach","summary":"The effectiveness of data-driven techniques heavily depends on the input\nsignal used to generate the estimation data. However, a significant research\ngap exists in the field of input design for nonlinear dynamic system\nidentification. In particular, existing methods largely overlook the\nminimization of the generalization error, i.e., model inaccuracies in regions\nnot covered by the estimation dataset. This work addresses this gap by\nproposing an input design method that embeds a novel optimality criterion\nwithin a receding horizon control (RHC)-based optimization framework. The\ndistance-based optimality criterion induces a space-filling design within a\nuser-defined region of interest in a surrogate model's input space, requiring\nonly minimal prior knowledge. Additionally, the method is applicable both\nonline, where model parameters are continuously updated based on process\nobservations, and offline, where a fixed model is employed. The space-filling\nperformance of the proposed strategy is evaluated on an artificial example and\ncompared to state-of-the-art methods, demonstrating superior efficiency in\nexploring process operating spaces.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-03T14:50:52Z"}
{"aid":"http://arxiv.org/abs/2504.02661v1","title":"Complete Classification of the Symmetry Group of $L_p$-Minkowski Problem\n  on the Sphere","summary":"In Convex Geometry, a core topic is the $L_p$-Minkowski problem\n  \\begin{equation}\\label{e0.1}\n  \\det(\\nabla^2h+hI)=fh^{p-1}, \\ \\ \\forall X\\in{\\mathbb{S}}^n, \\ \\ \\forall p\\in\n\\mathbb{R}\n  \\end{equation} of Monge-Amp\\`{e}re type. By the transformation\n$u(x)=h(X)\\sqrt{1+|x|^2}$ and semi-spherical projection, equation \\eqref{e0.1}\ncan be reformulated by the Monge-Amp\\`{e}re type equation\n  \\begin{equation}\\label{e0.2}\n  \\det D^2u=(1+|x|^2)^{-\\frac{p+n+1}{2}}u^{p-1}, \\ \\ \\forall\nx\\in{\\mathbb{R}}^n, \\ \\ \\forall p\\in \\mathbb{R}\n  \\end{equation} on the Euclidean space. In this paper, we will firstly\ndetermine the symmetric groups of $n$-dimensional fully nonlinear equation\n\\eqref{e0.2} without asymptotic growth assumption. After proving several key\nresolution lemmas, we thus completely classify the symmetric groups of the\n$L_p$-Minkowski problem. Our method develops the Lie theory to fully nonlinear\nPDEs in Convex Geometry.","main_category":"math.AP","categories":"math.AP,math.DG","published":"2025-04-03T14:57:14Z"}
{"aid":"http://arxiv.org/abs/2504.02662v1","title":"Integrating Human Knowledge Through Action Masking in Reinforcement\n  Learning for Operations Research","summary":"Reinforcement learning (RL) provides a powerful method to address problems in\noperations research. However, its real-world application often fails due to a\nlack of user acceptance and trust. A possible remedy is to provide managers\nwith the possibility of altering the RL policy by incorporating human expert\nknowledge. In this study, we analyze the benefits and caveats of including\nhuman knowledge via action masking. While action masking has so far been used\nto exclude invalid actions, its ability to integrate human expertise remains\nunderexplored. Human knowledge is often encapsulated in heuristics, which\nsuggest reasonable, near-optimal actions in certain situations. Enforcing such\nactions should hence increase trust among the human workforce to rely on the\nmodel's decisions. Yet, a strict enforcement of heuristic actions may also\nrestrict the policy from exploring superior actions, thereby leading to overall\nlower performance. We analyze the effects of action masking based on three\nproblems with different characteristics, namely, paint shop scheduling, peak\nload management, and inventory management. Our findings demonstrate that\nincorporating human knowledge through action masking can achieve substantial\nimprovements over policies trained without action masking. In addition, we find\nthat action masking is crucial for learning effective policies in constrained\naction spaces, where certain actions can only be performed a limited number of\ntimes. Finally, we highlight the potential for suboptimal outcomes when action\nmasks are overly restrictive.","main_category":"cs.LG","categories":"cs.LG,math.OC","published":"2025-04-03T15:00:04Z"}
{"aid":"http://arxiv.org/abs/2504.02673v1","title":"QUITS: A modular Qldpc code circUIT Simulator","summary":"To achieve quantum fault tolerance with lower overhead, quantum low-density\nparity-check (QLDPC) codes have emerged as a promising alternative to\ntopological codes such as the surface code, offering higher code rates. To\nsupport their study, an end-to-end framework for simulating QLDPC codes at the\ncircuit level is needed. In this work, we present QUITS, a modular and flexible\ncircuit-level simulator for QLDPC codes. Its design allows users to freely\ncombine LDPC code constructions, syndrome extraction circuits, decoding\nalgorithms, and noise models, enabling comprehensive and customizable studies\nof the performance of QLDPC codes under circuit-level noise. QUITS supports\nseveral leading QLDPC families, including hypergraph product codes, lifted\nproduct codes, and balanced product codes. As part of the framework, we\nintroduce a syndrome extraction circuit improved from Tremblay, Delfosse, and\nBeverland [Phys. Rev. Lett. 129, 050504 (2022)] that applies to all three code\nfamilies. In particular, for a small hypergraph product code, our circuit\nachieves lower depth than the conventional method, resulting in improved\nlogical performance. Using \\QUITS, we evaluate the performance of\nstate-of-the-art QLDPC codes and decoders under various settings, revealing\ntrade-offs between the decoding runtime and the logical failure rate. The\nsource code of QUITS is available online.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-03T15:14:13Z"}
{"aid":"http://arxiv.org/abs/2504.02677v1","title":"Monte Carlo evaluations of gamma-ray and radio pulsar populations","summary":"Based on well-grounded Galactic neutron star populations formed from radio\npulsar population syntheses of canonical pulsars (CPs) and millisecond pulsars\n(MSPs), we use the latest Fermi-LAT catalog (4FGL-DR4) to investigate the\nimplications of proposed $\\gamma-$ray luminosity models. Using Monte Carlo\ntechniques, we calculate the number of CPs and MSPs that would comprise the\nsample of pulsar-like unidentified sources (PLUIDs) in 4FGL-DR4. While radio\nbeaming fractions were used to scale the sizes of the populations, when forming\nthe mock 4FGL-DR4 samples, we make the simplifying assumption that all\n$\\gamma-$ray pulsars are beaming towards the Earth. We then explore the\nobservable outcomes of seven different $\\gamma-$ray luminosity models. Four of\nthe models provide a good match to the observed number of PLUIDs, while three\nothers significantly over-predict the number of PLUIDs. For these latter\nmodels, either the average beaming fraction of $\\gamma-$ray pulsars is more\nlike 25--50\\%, or a revision in the luminosity scaling is required. Most of the\nradio detectable MSPs that our models predict as part of the PLUIDs within\n4FGL-DR4 are, unsurprisingly, fainter than the currently observed sample and at\nlarger dispersion measures. For CPs, in spite of an excellent match to the\nobserved radio population, none of the $\\gamma-$ray models we investigated\ncould replicate the observed sample of 150 $\\gamma-$ray CPs. Further work is\nrequired to understand this discrepancy. For both MSPs and CPs, we provide\nencouraging forecasts for targeted radio searches of PLUIDs from 4FGL-DR4 to\nelucidate the issues raised in this study.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-03T15:15:37Z"}
{"aid":"http://arxiv.org/abs/2504.02678v1","title":"Valley and Spin Polarized States in Bernal Bilayer Graphene","summary":"We present the results for the evolution of the Fermi surfaces under\nvariation of number density and displacement field for spin and\nvalley-polarized states in Bernal bilayer graphene (BBG) using a realistic form\nof the electronic dispersion with trigonal warping terms. Earlier studies\nwithout trigonal warping have found discrete half-metal and quarter-metal\nstates with full spin and/or valley polarization and complete depletion of some\nof the Fermi surfaces. We show that when trigonal warping terms are included in\nthe dispersion, partially polarized states with large but non-complete\npolarization and with both majority and minority carriers present, emerge at\nsmall doping, as seen in the experimental data. We show the results when the\nintervalley and intravalley interactions are equal as well as when they are\nunequal.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mes-hall","published":"2025-04-03T15:15:42Z"}
{"aid":"http://arxiv.org/abs/2504.02679v1","title":"A Set-Theoretic Robust Control Approach for Linear Quadratic Games with\n  Unknown Counterparts","summary":"Ensuring robust decision-making in multi-agent systems is challenging when\nagents have distinct, possibly conflicting objectives and lack full knowledge\nof each other s strategies. This is apparent in safety-critical applications\nsuch as human-robot interaction and assisted driving, where uncertainty arises\nnot only from unknown adversary strategies but also from external disturbances.\nTo address this, the paper proposes a robust adaptive control approach based on\nlinear quadratic differential games. Our method allows a controlled agent to\niteratively refine its belief about the adversary strategy and disturbances\nusing a set-membership approach, while simultaneously adapting its policy to\nguarantee robustness against the uncertain adversary policy and improve\nperformance over time. We formally derive theoretical guarantees on the\nrobustness of the proposed control scheme and its convergence to epsilon-Nash\nstrategies. The effectiveness of our approach is demonstrated in a numerical\nsimulation.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-03T15:15:46Z"}
{"aid":"http://arxiv.org/abs/2504.02696v1","title":"The Tension between Trust and Oversight in Long-term Relationships","summary":"A principal continually decides whether to approve resource allocations to an\nagent, who exerts private effort to remain eligible. The principal must perform\ncostly inspections to determine the agent's eligibility. We characterize Markov\nPerfect Equilibria and analyze the paths of trust and oversight that emerge\nfrom the dynamic interplay of effort and oversight. At high trust levels,\neffort is an intertemporal substitute to oversight, which leads to unique\ninterior effort choices and random inspections. At low trust levels, effort is\nan intertemporal complement to oversight, which may create a coordination\nproblem, leading to equilibrium multiplicity. Voluntary disclosure can mitigate\nthis coordination issue.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-03T15:32:41Z"}
{"aid":"http://arxiv.org/abs/2504.02700v1","title":"Centroidal Voronoi Tessellations as Electrostatic Equilibria: A\n  Generalized Thomson Problem in Convex Domains","summary":"We present a variational framework in which Centroidal Voronoi Tessellations\n(CVTs) arise as local minimizers of a generalized electrostatic energy\nfunctional. By modeling interior point distributions in a convex domain as\nrepelling charges balanced against a continuous boundary charge, we show that\nthe resulting equilibrium configurations converge to CVT structures. We prove\nthis by showing that CVTs minimize both the classical centroidal energy and the\nelectrostatic potential, establishing a connection between geometric\nquantization and potential theory. Finally, we introduce a thermodynamic\nannealing scheme for global CVT optimization, rooted in Boltzmann statistics\nand random walk dynamics. By introducing a scheme for varying time steps\n(faster or slower cooling) we show that the set of minima of the centroid\nenergy functional (and therefore the electrostatic potential) can be recovered.\nBy recovering a set of generator locations corresponding to each minimum we can\ncreate a lattice continuation that allows for a customizable framework for\nindividual minimum seeking.","main_category":"math.NA","categories":"math.NA,cs.NA,math-ph,math.MG,math.MP,math.OC","published":"2025-04-03T15:36:15Z"}
{"aid":"http://arxiv.org/abs/2504.02714v1","title":"Impact of a Blockchain-based Universal Basic Income Pilot: The case of\n  Circles UBI currency","summary":"Circles UBI is a blockchain-based Community Currency System (CCS) that has\nbeen active in Berlin (Germany) since October 2021. The Circles Coop, which\nlaunched the project in 2021, was shut down in December 2023. In this paper, we\nshow the results of a survey carried out between October and November 2023. The\nrespondents were twenty-five individuals involved in various ways in the\nCircles' network. The main emerging narrative points out how their\nparticipation was deeply motivated by their identification with the values and\nideals of the Circles community. Among them, we selected five profiles that\nstood for their difference in type and degree of involvement. Finally, we\nreport some stories of economic linkages that suggest a positive externality in\nadopting a local community currency. To our knowledge, this is the first\nqualitative study of a universal basic income designed as a community currency\nand adopting blockchain technology. This pilot project was a remarkable\nexperiment for its adopted advanced technological and social innovations. In\nfact, as far as we know, the integration of basic income and local currency\nfeatures has been experimented with only in two other cases (Maric\\'a, Brazil\nand Barcelona, Spain) and none of them adopted a decentralized ledger system.\nIn this work, we try to outline strengths and weaknesses that emerged after\nabout two years of activity. For this reason, future researchers and activists\ninterested in this field will find valuable information.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-03T15:53:37Z"}
{"aid":"http://arxiv.org/abs/2504.02724v1","title":"Autonomous Human-Robot Interaction via Operator Imitation","summary":"Teleoperated robotic characters can perform expressive interactions with\nhumans, relying on the operators' experience and social intuition. In this\nwork, we propose to create autonomous interactive robots, by training a model\nto imitate operator data. Our model is trained on a dataset of human-robot\ninteractions, where an expert operator is asked to vary the interactions and\nmood of the robot, while the operator commands as well as the pose of the human\nand robot are recorded. Our approach learns to predict continuous operator\ncommands through a diffusion process and discrete commands through a\nclassifier, all unified within a single transformer architecture. We evaluate\nthe resulting model in simulation and with a user study on the real system. We\nshow that our method enables simple autonomous human-robot interactions that\nare comparable to the expert-operator baseline, and that users can recognize\nthe different robot moods as generated by our model. Finally, we demonstrate a\nzero-shot transfer of our model onto a different robotic platform with the same\noperator interface.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-03T16:06:44Z"}
{"aid":"http://arxiv.org/abs/2504.02728v1","title":"On deformations of Azumaya algebras with quadratic pair","summary":"We construct a tangent-obstruction theory for Azumaya algebras equipped with\na quadratic pair. Under the assumption that either 2 is a global unit or the\nalgebra is of degree 2, we show how the deformation theory of these objects\nreduces to the deformation theory of the underlying Azumaya algebra. Namely, if\nthe underlying Azumaya algebra has unobstructed deformations then so does the\nquadratic pair.\n  On the other hand, in the purely characteristic 2 setting, we construct an\nAzumaya algebra with unobstructed deformations which can be equipped with a\nquadratic pair such that the associated triple has obstructed deformations. Our\nexample is a biquaternion Azumaya algebra on an Igusa surface.\n  Independently from the above results, we also introduce a new obstruction for\nquadratic pairs, existing only in characteristic 2, which is intermediate to\nboth the strong and weak obstructions that were recently introduced by Gille,\nNeher, and the second named author. This intermediate obstruction characterizes\nwhen a canonical extension of the Lie algebra sheaf of the automorphism group\nscheme of some quadratic triple is split.","main_category":"math.AG","categories":"math.AG,math.RA","published":"2025-04-03T16:11:25Z"}
{"aid":"http://arxiv.org/abs/2504.02730v1","title":"HQViT: Hybrid Quantum Vision Transformer for Image Classification","summary":"Transformer-based architectures have revolutionized the landscape of deep\nlearning. In computer vision domain, Vision Transformer demonstrates remarkable\nperformance on par with or even surpassing that of convolutional neural\nnetworks. However, the quadratic computational complexity of its self-attention\nmechanism poses challenges for classical computing, making model training with\nhigh-dimensional input data, e.g., images, particularly expensive. To address\nsuch limitations, we propose a Hybrid Quantum Vision Transformer (HQViT), that\nleverages the principles of quantum computing to accelerate model training\nwhile enhancing model performance. HQViT introduces whole-image processing with\namplitude encoding to better preserve global image information without\nadditional positional encoding. By leveraging quantum computation on the most\ncritical steps and selectively handling other components in a classical way, we\nlower the cost of quantum resources for HQViT. The qubit requirement is\nminimized to $O(log_2N)$ and the number of parameterized quantum gates is only\n$O(log_2d)$, making it well-suited for Noisy Intermediate-Scale Quantum\ndevices. By offloading the computationally intensive attention coefficient\nmatrix calculation to the quantum framework, HQViT reduces the classical\ncomputational load by $O(T^2d)$. Extensive experiments across various computer\nvision datasets demonstrate that HQViT outperforms existing models, achieving a\nmaximum improvement of up to $10.9\\%$ (on the MNIST 10-classification task)\nover the state of the art. This work highlights the great potential to combine\nquantum and classical computing to cope with complex image classification\ntasks.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-03T16:13:34Z"}
{"aid":"http://arxiv.org/abs/2504.02732v1","title":"Why do LLMs attend to the first token?","summary":"Large Language Models (LLMs) tend to attend heavily to the first token in the\nsequence -- creating a so-called attention sink. Many works have studied this\nphenomenon in detail, proposing various ways to either leverage or alleviate\nit. Attention sinks have been connected to quantisation difficulties, security\nissues, and streaming attention. Yet, while many works have provided conditions\nin which they occur or not, a critical question remains shallowly answered: Why\ndo LLMs learn such patterns and how are they being used? In this work, we argue\ntheoretically and empirically that this mechanism provides a method for LLMs to\navoid over-mixing, connecting this to existing lines of work that study\nmathematically how information propagates in Transformers. We conduct\nexperiments to validate our theoretical intuitions and show how choices such as\ncontext length, depth, and data packing influence the sink behaviour. We hope\nthat this study provides a new practical perspective on why attention sinks are\nuseful in LLMs, leading to a better understanding of the attention patterns\nthat form during training.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T16:17:55Z"}
{"aid":"http://arxiv.org/abs/2504.02734v1","title":"Monitored Fluctuating Hydrodynamics","summary":"We introduce a hydrodynamic framework for describing monitored classical\nstochastic processes. We study the conditional ensembles for these monitored\nprocesses -- i.e., we compute spacetime correlation functions conditioned on a\nfixed, typical measurement record. In the presence of global symmetries we show\nthat these conditional ensembles can undergo measurement-induced ``sharpening''\nphase transitions as a function of the monitoring rate; moreover, even weak\nmonitoring can give rise to novel critical phases, derived entirely from a\nclassical perspective. We give a simple hydrodynamic derivation of the known\ncharge-sharpening transition for diffusive many-body quantum systems. We show\nthat although the unmonitored symmetric and asymmetric exclusion processes are\nin different universality classes of transport, their conditional ensembles\nflow to the same fixed point with emergent relativistic invariance under\nmonitoring. On the other hand, weakly monitored systems with non-Abelian\nsymmetries enter a novel strongly coupled fixed point with non-trivial\ndynamical exponent, which we characterize. Our formalism naturally accounts for\nmonitoring general observables, such as currents or density gradients, and\nallows for a direct calculation of information-theoretic diagnostics of\nsharpening transitions, including the Shannon entropy of the measurement\nrecord.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.dis-nn,quant-ph","published":"2025-04-03T16:19:18Z"}
{"aid":"http://arxiv.org/abs/2504.02736v1","title":"Parity violation as enforced symmetry breaking in 3D fermionic\n  topological order","summary":"Symmetry can be intrinsically broken in topological phases due to inherent\nincompatibilities, a phenomenon known as enforced symmetry breaking (ESB) in\nthe framework of topological order. In our previous work, we developed a\nsystematic framework to understand ESB within 2D invertible topological order.\nMeanwhile, the origin of parity violation in the Standard Model remains one of\nthe most profound mysteries in physics, with no clear explanation to date. In\nthis study, we explore the ESB of parity symmetry by three-dimensional\nfermionic topological order (fTO), offering potential insights into the origins\nof parity violation. As the simplest example, here we consider an fTO related\nto the intrinsic interacting fermionic SPT phase protected by $Z_2^f\\times\nZ_2\\times Z_8$ symmetry in three dimensions. We show that time-reversal\nsymmetry (TRS) with ${T}^2=1$ on physical fermions is incompatible with such\nfTO; then, through the so-called crystalline equivalence principle, we show\nthat the parity symmetry is also incompatible with it. In comparison,\nconventional TRS with ${T}^2={P}_f$ remains compatible to this fTO. We also\ndiscuss a general framework to study the ESB phenomenon for 3D fTO.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.supr-con,hep-ph,hep-th","published":"2025-04-03T16:23:36Z"}
{"aid":"http://arxiv.org/abs/2504.02738v1","title":"Inequivalence of the low-density insulating state and quantum Hall\n  insulating states in a strongly correlated two-dimensional electron system","summary":"We find that the behaviors of the voltage-current characteristics as one\nenters the low-density insulating state and integer quantum Hall insulating\nstates in the ultra-clean two-dimensional electron system in SiGe/Si/SiGe\nquantum wells are qualitatively different. The double-threshold voltage-current\ncurves, representative of electron solid formation at low densities, are not\nobserved in the quantum Hall regime, which does not confirm the existence of a\nquasi-particle quantum Hall Wigner solid and indicates that quasi-particles\nnear integer filling do not form an independent subsystem.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mes-hall","published":"2025-04-03T16:24:54Z"}
{"aid":"http://arxiv.org/abs/2504.02744v1","title":"The Ordering Principle and Dependent Choice","summary":"We introduce finite support iterations of symmetric systems, and use them to\nprovide a strongly modernized proof of David Pincus' classical result that the\naxiom of dependent choice is independent over ZF with the ordering principle\ntogether with a failure of the axiom of choice.","main_category":"math.LO","categories":"math.LO","published":"2025-04-03T16:31:05Z"}
{"aid":"http://arxiv.org/abs/2504.02746v1","title":"Is the CMB revealing signs of pre-inflationary physics?","summary":"Given the latest observational constraints coming from the joint analyses of\nthe Atacama Cosmology Telescope, the Planck Satellite and other missions, we\npoint out the possibility of reconciling fundamental particle-physics models of\ninflation with data by considering non-Bunch-Davies initial conditions for\nprimordial density perturbations.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-03T16:33:19Z"}
{"aid":"http://arxiv.org/abs/2504.02750v1","title":"Investigation of the influence of electrostatic excitation on\n  instabilities and electron transport in ExB plasma configurations","summary":"Partially magnetized plasmas in ExB configurations - where the electric and\nmagnetic fields are mutually perpendicular - exhibit a cross-field transport\nbehavior, which is widely believed to be dominantly governed by complex\ninstability-driven mechanisms. This phenomenon plays a crucial role in a\nvariety of plasma technologies, including Hall thrusters, where azimuthal\ninstabilities significantly influence electron confinement and, hence, device\nperformance. While the impact of prominent plasma instabilities, such as the\nelectron cyclotron drift instability (ECDI) and the modified two-stream\ninstability (MTSI) on cross-field transport of electron species is well\nrecognized and widely studied, strategies for actively manipulating these\ndynamics remain underexplored. In this study, we investigate the effect of\ntargeted wave excitation on instability evolution and electron transport using\none- and two-dimensional particle-in-cell simulations of representative plasma\ndischarge configurations. A time-varying electric field is applied axially to\nmodulate the spectral energy distribution of the instabilities across a range\nof forcing frequencies and amplitudes. Our results reveal that the so-called\n\"unsteady forcing\" can both suppress and amplify instability modes depending on\nexcitation parameters. In particular, across both 1D and 2D simulation\nconfigurations, forcing near 40 MHz effectively reduces ECDI amplitude and\ndecreases axial electron transport by about 30%, while high-frequency\nexcitation near the electron cyclotron frequency induces spectral broadening,\ninverse energy cascades, and enhanced transport. These findings point to the\nrole of nonlinear frequency locking and energy pathway disruption as mechanisms\nfor modifying instability-driven transport. Our results offer insights into\npotential pathways to enhance plasma confinement and control in next-generation\nExB devices.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-03T16:36:08Z"}
{"aid":"http://arxiv.org/abs/2504.02754v1","title":"Learning dynamics on the picosecond timescale in a superconducting\n  synapse structure","summary":"Conventional Artificial Intelligence (AI) systems are running into\nlimitations in terms of training time and energy. Following the principles of\nthe human brain, spiking neural networks trained with unsupervised learning\noffer a faster, more energy-efficient alternative. However, the dynamics of\nspiking, learning, and forgetting become more complicated in such schemes. Here\nwe study a superconducting electronics implementation of a learning synapse and\nexperimentally measure its spiking dynamics. By pulsing the system with a\nsuperconducting neuron, we show that a superconducting inductor can dynamically\nhold the synaptic weight with updates due to learning and forgetting. Learning\ncan be stopped by slowing down the arrival time of the post-synaptic pulse, in\naccordance with the Spike-Timing Dependent Plasticity paradigm. We find\nexcellent agreement with circuit simulations, and by fitting the turn-on of the\npulsing frequency, we confirm a learning time of 16.1 +/- 1 ps. The power\ndissipation in the learning part of the synapse is less than one attojoule per\nlearning event. This leads to the possibility of an extremely fast and\nenergy-efficient learning processor.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.dis-nn","published":"2025-04-03T16:46:19Z"}
{"aid":"http://arxiv.org/abs/2504.02761v1","title":"A Geometric Framework for Stochastic Iterations","summary":"This paper concerns models and convergence principles for dealing with\nstochasticity in a wide range of algorithms arising in nonlinear analysis and\noptimization in Hilbert spaces. It proposes a flexible geometric framework\nwithin which existing solution methods can be recast and improved, and new ones\ncan be designed. Almost sure weak, strong, and linear convergence results are\nestablished in particular for fixed point and feasibility problems. In these\nareas, the proposed algorithms exceed the features of the state of the art in\nseveral respects. Numerical applications to signal and image recovery are\nprovided.","main_category":"math.OC","categories":"math.OC,math.PR","published":"2025-04-03T16:57:22Z"}
{"aid":"http://arxiv.org/abs/2504.02762v1","title":"MD-ProjTex: Texturing 3D Shapes with Multi-Diffusion Projection","summary":"We introduce MD-ProjTex, a method for fast and consistent text-guided texture\ngeneration for 3D shapes using pretrained text-to-image diffusion models. At\nthe core of our approach is a multi-view consistency mechanism in UV space,\nwhich ensures coherent textures across different viewpoints. Specifically,\nMD-ProjTex fuses noise predictions from multiple views at each diffusion step\nand jointly updates the per-view denoising directions to maintain 3D\nconsistency. In contrast to existing state-of-the-art methods that rely on\noptimization or sequential view synthesis, MD-ProjTex is computationally more\nefficient and achieves better quantitative and qualitative results.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T16:58:06Z"}
{"aid":"http://arxiv.org/abs/2504.02765v1","title":"Robot-Led Vision Language Model Wellbeing Assessment of Children","summary":"This study presents a novel robot-led approach to assessing children's mental\nwellbeing using a Vision Language Model (VLM). Inspired by the Child\nApperception Test (CAT), the social robot NAO presented children with pictorial\nstimuli to elicit their verbal narratives of the images, which were then\nevaluated by a VLM in accordance with CAT assessment guidelines. The VLM's\nassessments were systematically compared to those provided by a trained\npsychologist. The results reveal that while the VLM demonstrates moderate\nreliability in identifying cases with no wellbeing concerns, its ability to\naccurately classify assessments with clinical concern remains limited.\nMoreover, although the model's performance was generally consistent when\nprompted with varying demographic factors such as age and gender, a\nsignificantly higher false positive rate was observed for girls, indicating\npotential sensitivity to gender attribute. These findings highlight both the\npromise and the challenges of integrating VLMs into robot-led assessments of\nchildren's wellbeing.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-03T17:02:09Z"}
{"aid":"http://arxiv.org/abs/2504.02774v1","title":"Component-wise Krasnosel'skii type fixed point theorem in product spaces\n  and applications","summary":"We present a version of Krasnosel'skii fixed point theorem for operators\nacting on Cartesian products of normed linear spaces, under cone-compression\nand cone-expansion conditions of norm type. Our approach, based on the fixed\npoint index theory in cones, guarantees the existence of a coexistence fixed\npoint - that is, one with nontrivial components. As an application, we prove\nthe existence of periodic solutions with strictly positive components for a\nsystem of second-order differential equations. In particular, we address cases\ninvolving singular nonlinearities and hybrid terms, characterized by sublinear\nbehavior in one component and superlinear behavior in the other.","main_category":"math.FA","categories":"math.FA,math.CA","published":"2025-04-03T17:14:48Z"}
{"aid":"http://arxiv.org/abs/2504.02781v1","title":"Towards Green AI-Native Networks: Evaluation of Neural Circuit Policy\n  for Estimating Energy Consumption of Base Stations","summary":"Optimization of radio hardware and AI-based network management software yield\nsignificant energy savings in radio access networks. The execution of\nunderlying Machine Learning (ML) models, which enable energy savings through\nrecommended actions, may require additional compute and energy, highlighting\nthe opportunity to explore and adopt accurate and energy-efficient ML\ntechnologies. This work evaluates the novel use of sparsely structured Neural\nCircuit Policies (NCPs) in a use case to estimate the energy consumption of\nbase stations. Sparsity in ML models yields reduced memory, computation and\nenergy demand, hence facilitating a low-cost and scalable solution. We also\nevaluate the generalization capability of NCPs in comparison to traditional and\nwidely used ML models such as Long Short Term Memory (LSTM), via quantifying\ntheir sensitivity to varying model hyper-parameters (HPs). NCPs demonstrated a\nclear reduction in computational overhead and energy consumption. Moreover,\nresults indicated that the NCPs are robust to varying HPs such as number of\nepochs and neurons in each layer, making them a suitable option to ease model\nmanagement and to reduce energy consumption in Machine Learning Operations\n(MLOps) in telecommunications.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.NE,eess.SP","published":"2025-04-03T17:22:39Z"}
{"aid":"http://arxiv.org/abs/2504.02783v1","title":"Non-linear elasticity effects and stratification in brushes of branched\n  polyelectrolytes","summary":"Brushes formed by arm-tethered starlike polyelectrolytes may exhibit internal\nsegregation into weakly and strongly extended populations (stratified two-layer\nstructure) when strong ionic intermolecular repulsions induce stretching of the\ntethers up to the limit of their extensibility. We propose an approximate\nPoisson-Boltzmann theory for analysis of the structure of the stratified brush\nand compare it with results of numerical self-consistent field modelling. Both\nanalytical and numerical models point to formation of a narrow cloud of\ncounterions (internal double electrical layer) localized inside stratified\nbrush at the boundary between the layers.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-03T17:25:10Z"}
{"aid":"http://arxiv.org/abs/2504.02784v1","title":"The level of distribution of the sum-of-digits function in arithmetic\n  progressions","summary":"For $q \\geq 2$, $n \\in \\mathbb{N}$, let $s_{q}(n)$ denote the sum of the\ndigits of $n$ written in base $q$. Spiegelhofer (2020) proved that the\nThue--Morse sequence has level of distribution $1$, improving on a former\nresult of Fouvry and Mauduit (1996). In this paper we generalize this result to\nsequences of type $\\left\\{\\exp\\left(2\\pi i\\ell s_q(n)/b\\right)\\right\\}_{n \\in\n\\mathbb{N}}$ and provide an explicit exponent in the upper bound.","main_category":"math.NT","categories":"math.NT","published":"2025-04-03T17:27:02Z"}
{"aid":"http://arxiv.org/abs/2504.02790v1","title":"Dynamic Treewidth in Logarithmic Time","summary":"We present a dynamic data structure that maintains a tree decomposition of\nwidth at most $9k+8$ of a dynamic graph with treewidth at most $k$, which is\nupdated by edge insertions and deletions. The amortized update time of our data\nstructure is $2^{O(k)} \\log n$, where $n$ is the number of vertices. The data\nstructure also supports maintaining any ``dynamic programming scheme'' on the\ntree decomposition, providing, for example, a dynamic version of Courcelle's\ntheorem with $O_{k}(\\log n)$ amortized update time; the $O_{k}(\\cdot)$ notation\nhides factors that depend on $k$. This improves upon a result of Korhonen,\nMajewski, Nadara, Pilipczuk, and Soko{\\l}owski [FOCS 2023], who gave a similar\ndata structure but with amortized update time $2^{k^{O(1)}} n^{o(1)}$.\nFurthermore, our data structure is arguably simpler.\n  Our main novel idea is to maintain a tree decomposition that is ``downwards\nwell-linked'', which allows us to implement local rotations and analysis\nsimilar to those for splay trees.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-03T17:37:46Z"}
{"aid":"http://arxiv.org/abs/2504.02793v1","title":"A Framework for Situating Innovations, Opportunities, and Challenges in\n  Advancing Vertical Systems with Large AI Models","summary":"Large artificial intelligence (AI) models have garnered significant attention\nfor their remarkable, often \"superhuman\", performance on standardized\nbenchmarks. However, when these models are deployed in high-stakes verticals\nsuch as healthcare, education, and law, they often reveal notable limitations.\nFor instance, they exhibit brittleness to minor variations in input data,\npresent contextually uninformed decisions in critical settings, and undermine\nuser trust by confidently producing or reproducing inaccuracies. These\nchallenges in applying large models necessitate cross-disciplinary innovations\nto align the models' capabilities with the needs of real-world applications. We\nintroduce a framework that addresses this gap through a layer-wise abstraction\nof innovations aimed at meeting users' requirements with large models. Through\nmultiple case studies, we illustrate how researchers and practitioners across\nvarious fields can operationalize this framework. Beyond modularizing the\npipeline of transforming large models into useful \"vertical systems\", we also\nhighlight the dynamism that exists within different layers of the framework.\nFinally, we discuss how our framework can guide researchers and practitioners\nto (i) optimally situate their innovations (e.g., when vertical-specific\ninsights can empower broadly impactful vertical-agnostic innovations), (ii)\nuncover overlooked opportunities (e.g., spotting recurring problems across\nverticals to develop practically useful foundation models instead of chasing\nbenchmarks), and (iii) facilitate cross-disciplinary communication of critical\nchallenges (e.g., enabling a shared vocabulary for AI developers, domain\nexperts, and human-computer interaction scholars).","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.CY,cs.HC","published":"2025-04-03T17:40:11Z"}
{"aid":"http://arxiv.org/abs/2504.02794v1","title":"MENA: Multimodal Epistemic Network Analysis for Visualizing Competencies\n  and Emotions","summary":"The need to improve geriatric care quality presents a challenge that requires\ninsights from stakeholders. While simulated trainings can boost competencies,\nextracting meaningful insights from these practices to enhance simulation\neffectiveness remains a challenge. In this study, we introduce Multimodal\nEpistemic Network Analysis (MENA), a novel framework for analyzing caregiver\nattitudes and emotions in an Augmented Reality setting and exploring how the\nawareness of a virtual geriatric patient (VGP) impacts these aspects. MENA\nenhances the capabilities of Epistemic Network Analysis by detecting positive\nemotions, enabling visualization and analysis of complex relationships between\ncaregiving competencies and emotions in dynamic caregiving practices. The\nframework provides visual representations that demonstrate how participants\nprovided more supportive care and engaged more effectively in person-centered\ncaregiving with aware VGP. This method could be applicable in any setting that\ndepends on dynamic interpersonal interactions, as it visualizes connections\nbetween key elements using network graphs and enables the direct comparison of\nmultiple networks, thereby broadening its implications across various fields.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-03T17:40:49Z"}
{"aid":"http://arxiv.org/abs/2504.02795v1","title":"Greedy Regular Convolutions","summary":"We introduce a class of convolutions on arithmetical functions that are\nregular in the sense of of Narkiewicz, homogeneous in the sense of Burnett et\nal, and bounded, in the sense that there exists a common finite bound for the\nrank of primitive numbers. Among these \"greedy convolutions\" the unitary\nconvolution and the \"ternary convolution\" are particularly interesting: they\nare the only regular, homogeneous convolutions where each primitive number have\nthe same finite rank. While the greedy convolution of length 3, also described\nin detail, has primitive numbers of rank 3 and rank 1, it is still special in\nthat the set of primitives can be generated by a simple recursive procedure\nthat we name selective sifting.","main_category":"math.NT","categories":"math.NT","published":"2025-04-03T17:41:11Z"}
{"aid":"http://arxiv.org/abs/2504.02814v1","title":"Convergence of the Markovian iteration for coupled FBSDEs via a\n  differentiation approach","summary":"In this paper, we investigate the Markovian iteration method for solving\ncoupled forward-backward stochastic differential equations (FBSDEs) featuring a\nfully coupled forward drift, meaning the drift term explicitly depends on both\nthe forward and backward processes. An FBSDE system typically involves three\nstochastic processes: the forward process $X$, the backward process $Y$\nrepresenting the solution, and the $Z$ process corresponding to the scaled\nderivative of $Y$. Prior research by Bender and Zhang (2008) has established\nconvergence results for iterative schemes dealing with $Y$-coupled FBSDEs.\nHowever, extending these results to equations with $Z$ coupling poses\nsignificant challenges, especially in uniformly controlling the Lipschitz\nconstant of the decoupling fields across iterations and time steps within a\nfixed-point framework.\n  To overcome this issue, we propose a novel differentiation-based method for\nhandling the $Z$ process. This approach enables improved management of the\nLipschitz continuity of decoupling fields, facilitating the well-posedness of\nthe discretized FBSDE system with fully coupled drift. We rigorously prove the\nconvergence of our Markovian iteration method in this more complex setting.\nFinally, numerical experiments confirm our theoretical insights, showcasing the\neffectiveness and accuracy of the proposed methodology.","main_category":"math.NA","categories":"math.NA,cs.NA,math.PR,q-fin.CP","published":"2025-04-03T17:56:36Z"}
{"aid":"http://arxiv.org/abs/2504.02826v1","title":"Envisioning Beyond the Pixels: Benchmarking Reasoning-Informed Visual\n  Editing","summary":"Large Multi-modality Models (LMMs) have made significant progress in visual\nunderstanding and generation, but they still face challenges in General Visual\nEditing, particularly in following complex instructions, preserving appearance\nconsistency, and supporting flexible input formats. To address this gap, we\nintroduce RISEBench, the first benchmark for evaluating Reasoning-Informed\nviSual Editing (RISE). RISEBench focuses on four key reasoning types: Temporal,\nCausal, Spatial, and Logical Reasoning. We curate high-quality test cases for\neach category and propose an evaluation framework that assesses Instruction\nReasoning, Appearance Consistency, and Visual Plausibility with both human\njudges and an LMM-as-a-judge approach. Our experiments reveal that while\nGPT-4o-Native significantly outperforms other open-source and proprietary\nmodels, even this state-of-the-art system struggles with logical reasoning\ntasks, highlighting an area that remains underexplored. As an initial effort,\nRISEBench aims to provide foundational insights into reasoning-aware visual\nediting and to catalyze future research. Though still in its early stages, we\nare committed to continuously expanding and refining the benchmark to support\nmore comprehensive, reliable, and scalable evaluations of next-generation\nmultimodal systems. Our code and data will be released at\nhttps://github.com/PhoenixZ810/RISEBench.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T17:59:56Z"}
{"aid":"http://arxiv.org/abs/2504.02828v1","title":"Concept Lancet: Image Editing with Compositional Representation\n  Transplant","summary":"Diffusion models are widely used for image editing tasks. Existing editing\nmethods often design a representation manipulation procedure by curating an\nedit direction in the text embedding or score space. However, such a procedure\nfaces a key challenge: overestimating the edit strength harms visual\nconsistency while underestimating it fails the editing task. Notably, each\nsource image may require a different editing strength, and it is costly to\nsearch for an appropriate strength via trial-and-error. To address this\nchallenge, we propose Concept Lancet (CoLan), a zero-shot plug-and-play\nframework for principled representation manipulation in diffusion-based image\nediting. At inference time, we decompose the source input in the latent (text\nembedding or diffusion score) space as a sparse linear combination of the\nrepresentations of the collected visual concepts. This allows us to accurately\nestimate the presence of concepts in each image, which informs the edit. Based\non the editing task (replace/add/remove), we perform a customized concept\ntransplant process to impose the corresponding editing direction. To\nsufficiently model the concept space, we curate a conceptual representation\ndataset, CoLan-150K, which contains diverse descriptions and scenarios of\nvisual terms and phrases for the latent dictionary. Experiments on multiple\ndiffusion-based image editing baselines show that methods equipped with CoLan\nachieve state-of-the-art performance in editing effectiveness and consistency\npreservation.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL","published":"2025-04-03T17:59:58Z"}
{"aid":"http://arxiv.org/abs/2504.04730v1","title":"Precision Thermo-Welding of Polymer Microspheres into Periodically\n  Organized, Hybrid, Mechanically Rollable Coupled-Resonator Optical Waveguides","summary":"Polymer microspherical resonators that trap light are crucial structures for\non-chip and on-board integration in nanophotonic applications. Using advanced\nmicromanipulation and thermo-welding methods, we successfully create welded\npolystyrene-based coupled-resonator optical waveguides (CROWs) with customized\nlengths, shapes, and optical characteristics. Through the thermal fusion of\nblue, green, and red fluorophore-doped polystyrene microspheres,\nmulti-fluorescent cohesive units are created from dimeric to henicosameric\nperiodic arrangements. Detailed micro-spectroscopy studies reveal CROWs'\ncapability to support optical whispering-gallery modes. The periodic\narrangements of different fluorophore-doped resonators within the CROW\nfacilitate efficient guided transmission of light via both active and passive\nmechanisms in opposite directions. The welded structures exhibit mechanically\ndriven rolling motion, confirming their integration as cohesive units. These\nfindings highlight the versatility and performance of thermo-welded polymer\nmicrosphere-based waveguides, paving the way for scalable, low-cost photonic\ndevices in sensing, modulation, and light guiding, emphasizing their role in\nfuture integrated photonics.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mtrl-sci","published":"2025-04-07T05:02:40Z"}
{"aid":"http://arxiv.org/abs/2504.04740v1","title":"Enhancing Compositional Reasoning in Vision-Language Models with\n  Synthetic Preference Data","summary":"Compositionality, or correctly recognizing scenes as compositions of atomic\nvisual concepts, remains difficult for multimodal large language models\n(MLLMs). Even state of the art MLLMs such as GPT-4o can make mistakes in\ndistinguishing compositions like \"dog chasing cat\" vs \"cat chasing dog\". While\non Winoground, a benchmark for measuring such reasoning, MLLMs have made\nsignificant progress, they are still far from a human's performance. We show\nthat compositional reasoning in these models can be improved by elucidating\nsuch concepts via data, where a model is trained to prefer the correct caption\nfor an image over a close but incorrect one. We introduce SCRAMBLe: Synthetic\nCompositional Reasoning Augmentation of MLLMs with Binary preference Learning,\nan approach for preference tuning open-weight MLLMs on synthetic preference\ndata generated in a fully automated manner from existing image-caption data.\nSCRAMBLe holistically improves these MLLMs' compositional reasoning\ncapabilities which we can see through significant improvements across multiple\nvision language compositionality benchmarks, as well as smaller but significant\nimprovements on general question answering tasks. As a sneak peek, SCRAMBLe\ntuned Molmo-7B model improves on Winoground from 49.5% to 54.8% (best reported\nto date), while improving by ~1% on more general visual question answering\ntasks. Code for SCRAMBLe along with tuned models and our synthetic training\ndataset is available at https://github.com/samarth4149/SCRAMBLe.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T05:35:34Z"}
{"aid":"http://arxiv.org/abs/2504.04743v1","title":"AnyArtisticGlyph: Multilingual Controllable Artistic Glyph Generation","summary":"Artistic Glyph Image Generation (AGIG) differs from current\ncreativity-focused generation models by offering finely controllable\ndeterministic generation. It transfers the style of a reference image to a\nsource while preserving its content. Although advanced and promising, current\nmethods may reveal flaws when scrutinizing synthesized image details, often\nproducing blurred or incorrect textures, posing a significant challenge. Hence,\nwe introduce AnyArtisticGlyph, a diffusion-based, multilingual controllable\nartistic glyph generation model. It includes a font fusion and embedding\nmodule, which generates latent features for detailed structure creation, and a\nvision-text fusion and embedding module that uses the CLIP model to encode\nreferences and blends them with transformation caption embeddings for seamless\nglobal image generation. Moreover, we incorporate a coarse-grained\nfeature-level loss to enhance generation accuracy. Experiments show that it\nproduces natural, detailed artistic glyph images with state-of-the-art\nperformance. Our project will be open-sourced on\nhttps://github.com/jiean001/AnyArtisticGlyph to advance text generation\ntechnology.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T05:37:39Z"}
{"aid":"http://arxiv.org/abs/2504.04761v1","title":"WLPCM Approach for Great Lakes Regulation","summary":"This study develops a water-level management model for the Great Lakes using\na predictive control framework. Requirement 1: Historical data (pre-2019)\nrevealed consistent monthly water-level patterns. A simulated annealing\nalgorithm optimized flow control via the Moses-Saunders Dam and Compensating\nWorks to align levels with multi-year benchmarks. Requirement 2: A Water Level\nPredictive Control Model (WLPCM) integrated delayed differential equations\n(DDEs) and model predictive control (MPC) to account for inflow/outflow\ndynamics and upstream time lags. Natural variables (e.g., precipitation) were\nmodeled via linear regression, while dam flow rates were optimized over 6-month\nhorizons with feedback adjustments for robustness. Requirement 3: Testing WLPCM\non 2017 data successfully mitigated Ottawa River flooding, outperforming\nhistorical records. Sensitivity analysis via the Sobol method confirmed model\nresilience to parameter variations. Requirement 4: Ice-clogging was identified\nas the most impactful natural variable (via RMSE-based sensitivity tests),\nfollowed by snowpack and precipitation. Requirement 5: Stakeholder demands\n(e.g., flood prevention, ecological balance) were incorporated into a fitness\nfunction. Compared to Plan 2014, WLPCM reduced catastrophic high levels in Lake\nOntario and excessive St. Lawrence River flows by prioritizing long-term\noptimization. Key innovations include DDE-based predictive regulation,\nreal-time feedback loops, and adaptive control under extreme conditions. The\nframework balances hydrological dynamics, stakeholder needs, and uncertainty\nmanagement, offering a scalable solution for large freshwater systems.","main_category":"math.OC","categories":"math.OC","published":"2025-04-07T06:21:22Z"}
{"aid":"http://arxiv.org/abs/2504.04767v1","title":"Extended URDF: Accounting for parallel mechanism in robot description","summary":"Robotic designs played an important role in recent advances by providing\npowerful robots with complex mechanics. Many recent systems rely on parallel\nactuation to provide lighter limbs and allow more complex motion. However,\nthese emerging architectures fall outside the scope of most used description\nformats, leading to difficulties when designing, storing, and sharing the\nmodels of these systems. This paper introduces an extension to the widely used\nUnified Robot Description Format (URDF) to support closed-loop kinematic\nstructures. Our approach relies on augmenting URDF with minimal additional\ninformation to allow more efficient modeling of complex robotic systems while\nmaintaining compatibility with existing design and simulation frameworks. This\nmethod sets the basic requirement for a description format to handle parallel\nmechanisms efficiently. We demonstrate the applicability of our approach by\nproviding an open-source collection of parallel robots, along with tools for\ngenerating and parsing this extended description format. The proposed extension\nsimplifies robot modeling, reduces redundancy, and improves usability for\nadvanced robotic applications.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T06:42:27Z"}
{"aid":"http://arxiv.org/abs/2504.04769v1","title":"Scalable simulation of random quantum circuits using projected\n  entangled-pair states","summary":"Classical simulation of a programmable quantum processor is crucial in\nidentifying the threshold of a quantum advantage. We use the simple update of\nprojected entangled-pair states (PEPSs) in the Vidal gauge to simulate the\nstates of random quantum circuits (RQCs), which center around recent quantum\nadvantage claims. Applied to square lattices of qubits akin to state-of-the-art\nsuperconducting processors, our PEPS simulation is exact for circuit depths\nless than $D_\\mathrm{tr}$ = $\\beta\\log_2\\chi$, where $\\chi$ is the maximum bond\ndimension and $2 \\lesssim \\beta \\lesssim 4$ depends on the choice of two-qubit\ngates, independent of the qubit number $n$. We find the universal scaling\nbehaviors of the state fidelity by performing large-scale simulations for $n\n\\leq 10^{4}$ or $\\chi \\leq 128$ on a conventional CPU. Our method has\ncomputational cost scaling polynomially with $n$ for circuit depth $D =O(\\log\nn)$ and is more advantageous than matrix product state (MPS) approaches if $n$\nis large. This work underscores PEPSs as a scalable tool for benchmarking\nquantum algorithms, with future potential for sampling applications using\nadvanced contraction techniques.","main_category":"quant-ph","categories":"quant-ph,physics.comp-ph","published":"2025-04-07T06:47:48Z"}
{"aid":"http://arxiv.org/abs/2504.04773v1","title":"Hyperspace convergences, bornologies and geometric set functionals","summary":"For a bornology $\\mathcal{S}$ of subsets of a metric space $(X,d)$, we\nconsider the following unified approaches of hyperspace convergence:\nconvergence induced through uniform convergence of distance functionals\n($\\tau_{\\mathcal{S},d}$-convergence); bornological convergence, and the weak\nconvergence induced by a family of gap and excess functionals. An interesting\nproblem regarding these convergences is to investigate when any two of them are\nequivalent. In this article, we investigate the relation of\n$\\tau_{\\mathcal{S},d}$-convergence with the other two convergences, which is\nnot completely transparent. As a main tool for our investigation, we use the\nidea of pointwise enlargement of a set by a positive Lipschitz function. As\napplications of our results, we provide new proofs of some known results about\nAttouch-Wets convergence.","main_category":"math.GN","categories":"math.GN,math.FA","published":"2025-04-07T07:04:30Z"}
{"aid":"http://arxiv.org/abs/2504.04776v1","title":"Drastic softening of Pd nanoparticles induced by hydrogen cycling","summary":"Single crystalline faceted Pd nanoparticles attached to a sapphire substrate\nwere fabricated employing the solid state dewetting method. The as-dewetted\nnanoparticles tested in compression exhibited all features of dislocation\nnucleation-controlled plasticity, including the size effect on strength and\nultrahigh compressive strength reaching up to 11 GPa. Hydrogen cycling of\nas-dewetted Pd nanoparticles resulted in their drastic softening and in change\nof the deformation mode. This softening effect was correlated with the high\ndensity of glissile dislocations observed in the cycled particles. This work\ndemonstrates that the nanomechanical behavior of hydride-forming metals can be\nmanipulated by hydrogen cycling.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-07T07:09:10Z"}
{"aid":"http://arxiv.org/abs/2504.04779v1","title":"Black hole destabilization via trapped quasi-normal modes","summary":"In the presence of non-minimal gravitational couplings, matter field\nperturbations on a static black hole spacetime may develop unphysical poles in\ntheir linearized equations. Physical solutions confined in the domain between\nthe event horizon and a pole satisfy a boundary value problem, although with\nboundary conditions which are different from standard quasi-normal modes. We\nrefer to them as \"trapped quasi-normal modes\". Focusing on a Schwarzschild\nblack hole in Einstein-Proca theory, we find that trapped quasi-normal modes\naccurately capture the behavior of perturbations under time evolution. In\nparticular, axial-vector modes are unstable, with a growth rate that increases\nwith multipole number. More interestingly, we uncover a new instability that\naffects monopole perturbations. These results confirm the existence of a novel\ndestabilization mechanism of black holes by non-minimally coupled vector\nfields, with potential implications to well-studied models of modified gravity\nand cosmology based on vector particles.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-07T07:14:36Z"}
{"aid":"http://arxiv.org/abs/2504.04786v1","title":"Dynamic fabrication method of SNAP microresonators","summary":"Surface Nanoscale Axial Photonics (SNAP) technology has demonstrated the\nrecord subangstrom fabrication precision of optical microresonators and\nresonant photonic circuits at the optical fiber surface. However, fabrication\nerrors arising from fluctuations of temperature, inscription parameters,\nalignment inconsistencies, and other factors did not allow researchers to\nachieve the subangstrom precision without sophisticated postprocessing. Here we\nshow that the key fabrication method of SNAP structures -- CO$_2$ laser beam\noptical fiber annealing -- suffers from significant fiber displacements which\nmay introduce a few percent fabrication errors. To suppress the effects of\nmisalignment, we develop a dynamic fabrication method employing a translating\nbeam exposure and demonstrate its excellent precision. The effective fiber\nradius variation of $\\sim 10 $nm is introduced with an error of $\\sim 0.1\n$angstrom. We suggest that the remaining fabrication errors can be attributed\nto laser power fluctuations.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-07T07:31:13Z"}
{"aid":"http://arxiv.org/abs/2504.04796v1","title":"Long-range transverse momentum correlations and radial flow in Pb$-$Pb\n  collisions at the LHC","summary":"This Letter presents measurements of long-range transverse-momentum\ncorrelations using a new observable, $v_{0}(p_\\mathrm{T})$, which serves as a\nprobe of radial flow and medium properties in heavy-ion collisions. Results are\nreported for inclusive charged particles, pions, kaons, and protons across\nvarious centrality intervals in Pb$-$Pb collisions at $\\sqrt{s_\\mathrm{NN}} =\n5.02$ TeV, recorded by the ALICE detector. A pseudorapidity-gap technique,\nsimilar to that used in anisotropic-flow studies, is employed to suppress\nshort-range correlations. At low $p_\\mathrm{T}$, a characteristic mass ordering\nconsistent with hydrodynamic collective flow is observed. At higher\n$p_\\mathrm{T}$ ($> 3$ GeV/$c$), protons exhibit larger $v_{0}(p_\\mathrm{T})$\nthan pions and kaons, in agreement with expectations from quark-recombination\nmodels. These results are sensitive to the bulk viscosity and the equation of\nstate of the QCD medium formed in heavy-ion collisions.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-07T07:39:49Z"}
{"aid":"http://arxiv.org/abs/2504.04802v1","title":"Markov Gap and Bound Entanglement in Haar Random State","summary":"Bound entanglement refers to entangled states that cannot be distilled into\nmaximally entangled states, thus cannot be used directly in many protocols of\nquantum information processing. We identify a relationship between bound\nentanglement and Markov gap, which is introduced in holography from the\nentanglement wedge cross-section, and is related to the fidelity of Markov\nrecovery problem. We prove that the bound entanglement must have non-zero\nMarkov gap, and conversely, the state with weakly non-zero Markov gap almost\nsurely, with respect to Haar measure, has an entanglement undistillable, i.e.\nbound entangled or separable, marginal state for sufficiently large system.\nMoreover, we show that the bound entanglement and the threshold for\nseparability in Haar random state is originated from the state with weakly\nnon-zero Markov gap, which supports the non-perturbative effects from\nholographic perspective. Our results shed light on the investigation of Markov\ngap, and enhance the interdisciplinary application of quantum information.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-07T07:54:04Z"}
{"aid":"http://arxiv.org/abs/2504.04806v1","title":"Interplay Between Structural Defects and Charge Transport Dynamics in MA\n  and FA Modified CsSnI3 Thin Film Semiconductors","summary":"Owing high conductivity in microcrystalline thin-films, CsSnI3 perovskite is\na promising semiconductor for thermoelectrics and optoelectronics. Rapid\noxidation of thin-film and intrinsic lattice strain hinders stabilization of\nthe device performance. Cation engineering of perovskite molecule was\nconsidered as an effective strategy to tailor the structural properties and\nsuppress the degradation processes. However, molecular engineering demands a\nthorough analysis of defect behavior, as it can influence ionic motion,\nrecombination dynamics, and capacitive effects. The effective implementation of\nCsSnI3 in energy conversion devices requires careful consideration of the\nspecific properties of thin films electrical conductivity, Seebeck coefficient,\npower factor, as well as electronic transients, and charge transport in the\ndevice structures. In this work, we performed a complex investigation for\nmodified CsSnI3 through cation substitution with methyl ammonium (MA) and\nformamidinium (FA). Our findings highlight a complex interplay between\nelectrical parameters of the bare thin films and stability of the devices\n(p-i-n diodes) after thermal stress. FA-CsSnI3 showed beneficial results for\nstabilization under elevated temperatures with improved non-ideality factor in\ndiode structures, enhanced shunt properties and reduced trapping. The\nphoto-induced voltage relaxation spectroscopy performed for MA-CsSnI3 showed\nrelevant traps concentration of 1016 cm-3 with activation energy of 0.52\neV(210K) likely attributed to Sn atom defect. The obtained results are deeply\nanalyzed and discussed.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-07T08:02:17Z"}
{"aid":"http://arxiv.org/abs/2504.04813v1","title":"Generalized Fermi-Dirac Distribution of Exclusive Fermions","summary":"A system of exclusive fermions occurs when two fermions of opposite spin are\nprohibited from occupying the same quantum level. We derive the distribution of\nexclusive fermions via the employment of the grand canonical ensemble. Salient\nfeatures of its statistical properties, compared to the free electron gases,\ninclude: larger Fermi energy, higher degeneracy pressure, but the same Pauli\nparamagnetism and Landau diamagnetism. In particular, higher degeneracy\npressure leads to an inflation of the Chandrasekhar limit to 1.6 times when\napplied to white dwarf stars and neutron stars.","main_category":"math-ph","categories":"math-ph,astro-ph.SR,cond-mat.stat-mech,math.MP","published":"2025-04-07T08:08:57Z"}
{"aid":"http://arxiv.org/abs/2504.04819v1","title":"Stability of spin dynamics in a driven non-Hermitian double well","summary":"We study the stability of spin dynamics for a spin-orbit (SO) coupled boson\nheld in a driven non-Hermitian double-well potential. It is surprising to find\nthat when the ratio of the Zeeman field strength to the driving frequency is\neven, the SO coupling strength can take any value, and suitable parameters can\nbe found to stabilize the quantum spin dynamics of the system. However, when\nthe ratio of the Zeeman field strength to the driving frequency is odd, the SO\ncoupling strength can only take integer or half-integer values for the spin\ndynamics of the system to possibly be stable.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas","published":"2025-04-07T08:20:35Z"}
{"aid":"http://arxiv.org/abs/2504.04828v1","title":"Enumeration on polyominoes determined by Catalan words avoiding\n  $(\\geq,\\geq)$","summary":"A Catalan word of length $n$ that avoids the pattern $(\\geq, \\geq)$ is a\nsequence $w=w_1\\cdots w_n$ with $w_1=0$ and $0\\leq w_i\\leq w_{i-1}+1$ for all\n$i$, while ensuring that no subsequence satisfies $w_i \\geq w_{i+1}\\geq\nw_{i+2}$ for $i=2,\\ldots,n$. These words are enumerated by the $n$-th Motzkin\nnumber. From such a word, we associate a $n$-column Motzkin polyomino (called a\n$(\\geq,\\geq)$-polyomino), where the $i$-th column contains $w_i+1$\nbottom-aligned cells. In this paper, we derive generating functions for\n$(\\geq,\\geq)$-polyominoes based on their length, area, semiperimeter, last\nsymbol value, and number of interior points. We provide asymptotic analyses and\nclosed-form expressions for the total area, total semiperimeter, sum of the\nlast symbol values, and total number of interior points across all\n$(\\geq,\\geq)$-polyominoes of a given length. Finally, we express all these\nresults as linear combinations of trinomial coefficients.","main_category":"math.CO","categories":"math.CO","published":"2025-04-07T08:36:14Z"}
{"aid":"http://arxiv.org/abs/2504.04829v1","title":"Attentional Graph Meta-Learning for Indoor Localization Using Extremely\n  Sparse Fingerprints","summary":"Fingerprint-based indoor localization is often labor-intensive due to the\nneed for dense grids and repeated measurements across time and space.\nMaintaining high localization accuracy with extremely sparse fingerprints\nremains a persistent challenge. Existing benchmark methods primarily rely on\nthe measured fingerprints, while neglecting valuable spatial and environmental\ncharacteristics. In this paper, we propose a systematic integration of an\nAttentional Graph Neural Network (AGNN) model, capable of learning spatial\nadjacency relationships and aggregating information from neighboring\nfingerprints, and a meta-learning framework that utilizes datasets with similar\nenvironmental characteristics to enhance model training. To minimize the labor\nrequired for fingerprint collection, we introduce two novel data augmentation\nstrategies: 1) unlabeled fingerprint augmentation using moving platforms, which\nenables the semi-supervised AGNN model to incorporate information from\nunlabeled fingerprints, and 2) synthetic labeled fingerprint augmentation\nthrough environmental digital twins, which enhances the meta-learning framework\nthrough a practical distribution alignment, which can minimize the feature\ndiscrepancy between synthetic and real-world fingerprints effectively. By\nintegrating these novel modules, we propose the Attentional Graph Meta-Learning\n(AGML) model. This novel model combines the strengths of the AGNN model and the\nmeta-learning framework to address the challenges posed by extremely sparse\nfingerprints. To validate our approach, we collected multiple datasets from\nboth consumer-grade WiFi devices and professional equipment across diverse\nenvironments. Extensive experiments conducted on both synthetic and real-world\ndatasets demonstrate that the AGML model-based localization method consistently\noutperforms all baseline methods using sparse fingerprints across all evaluated\nmetrics.","main_category":"cs.LG","categories":"cs.LG,eess.SP,stat.ML","published":"2025-04-07T08:37:18Z"}
{"aid":"http://arxiv.org/abs/2504.04842v1","title":"FantasyTalking: Realistic Talking Portrait Generation via Coherent\n  Motion Synthesis","summary":"Creating a realistic animatable avatar from a single static portrait remains\nchallenging. Existing approaches often struggle to capture subtle facial\nexpressions, the associated global body movements, and the dynamic background.\nTo address these limitations, we propose a novel framework that leverages a\npretrained video diffusion transformer model to generate high-fidelity,\ncoherent talking portraits with controllable motion dynamics. At the core of\nour work is a dual-stage audio-visual alignment strategy. In the first stage,\nwe employ a clip-level training scheme to establish coherent global motion by\naligning audio-driven dynamics across the entire scene, including the reference\nportrait, contextual objects, and background. In the second stage, we refine\nlip movements at the frame level using a lip-tracing mask, ensuring precise\nsynchronization with audio signals. To preserve identity without compromising\nmotion flexibility, we replace the commonly used reference network with a\nfacial-focused cross-attention module that effectively maintains facial\nconsistency throughout the video. Furthermore, we integrate a motion intensity\nmodulation module that explicitly controls expression and body motion\nintensity, enabling controllable manipulation of portrait movements beyond mere\nlip motion. Extensive experimental results show that our proposed approach\nachieves higher quality with better realism, coherence, motion intensity, and\nidentity preservation. Ours project page:\nhttps://fantasy-amap.github.io/fantasy-talking/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T08:56:01Z"}
{"aid":"http://arxiv.org/abs/2504.04843v1","title":"Data Augmentation as Free Lunch: Exploring the Test-Time Augmentation\n  for Sequential Recommendation","summary":"Data augmentation has become a promising method of mitigating data sparsity\nin sequential recommendation. Existing methods generate new yet effective data\nduring model training to improve performance. However, deploying them requires\nretraining, architecture modification, or introducing additional learnable\nparameters. The above steps are time-consuming and costly for well-trained\nmodels, especially when the model scale becomes large. In this work, we explore\nthe test-time augmentation (TTA) for sequential recommendation, which augments\nthe inputs during the model inference and then aggregates the model's\npredictions for augmented data to improve final accuracy. It avoids significant\ntime and cost overhead from loss calculation and backward propagation. We first\nexperimentally disclose the potential of existing augmentation operators for\nTTA and find that the Mask and Substitute consistently achieve better\nperformance. Further analysis reveals that these two operators are effective\nbecause they retain the original sequential pattern while adding appropriate\nperturbations. Meanwhile, we argue that these two operators still face\ntime-consuming item selection or interference information from mask tokens.\nBased on the analysis and limitations, we present TNoise and TMask. The former\ninjects uniform noise into the original representation, avoiding the\ncomputational overhead of item selection. The latter blocks mask token from\nparticipating in model calculations or directly removes interactions that\nshould have been replaced with mask tokens. Comprehensive experiments\ndemonstrate the effectiveness, efficiency, and generalizability of our method.\nWe provide an anonymous implementation at https://github.com/KingGugu/TTA4SR.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-07T08:56:16Z"}
{"aid":"http://arxiv.org/abs/2504.04846v1","title":"Iterated and Generalized Iterated Integrals","summary":"For a differential field $F$ having an algebraically closed field of\nconstants, we analyze the structure of Picard-Vessiot extensions of $F$ whose\ndifferential Galois groups are unipotent algebraic groups and apply these\nresults to study stability problems in integration in finite terms and the\ninverse problem in differential Galois theory for unipotent algebraic groups.","main_category":"math.AC","categories":"math.AC","published":"2025-04-07T08:59:28Z"}
{"aid":"http://arxiv.org/abs/2504.04849v1","title":"Discovering dynamical laws for speech gestures","summary":"A fundamental challenge in the cognitive sciences is discovering the dynamics\nthat govern behaviour. Take the example of spoken language, which is\ncharacterised by a highly variable and complex set of physical movements that\nmap onto the small set of cognitive units that comprise language. What are the\nfundamental dynamical principles behind the movements that structure speech\nproduction? In this study, we discover models in the form of symbolic equations\nthat govern articulatory gestures during speech. A sparse symbolic regression\nalgorithm is used to discover models from kinematic data on the tongue and\nlips. We explore these candidate models using analytical techniques and\nnumerical simulations, and find that a second-order linear model achieves high\nlevels of accuracy, but a nonlinear force is required to properly model\narticulatory dynamics in approximately one third of cases. This supports the\nproposal that an autonomous, nonlinear, second-order differential equation is a\nviable dynamical law for articulatory gestures in speech. We conclude by\nidentifying future opportunities and obstacles in data-driven model discovery\nand outline prospects for discovering the dynamical principles that govern\nlanguage, brain and behaviour.","main_category":"cs.CL","categories":"cs.CL,nlin.AO","published":"2025-04-07T09:03:32Z"}
{"aid":"http://arxiv.org/abs/2504.04853v1","title":"Charmonium-nucleon femtoscopic correlation function","summary":"This study investigates the femtoscopic correlation functions of\ncharmonium-nucleon pairs, utilizing the lattice QCD phase shifts provided by\nthe HAL QCD Collaboration. A model-independent formalism is employed to\ntransform scattering phase shifts directly into momentum correlation functions,\nthereby circumventing the approximations inherent in traditional methods, such\nas the Lednick\\'y-Lyuboshits model. The $J/\\psi$-$p$ correlation functions,\nincluding spin-averaged and partial-wave results, are predicted using\nnear-physical pion mass lattice results. The $\\eta_c$-$p$ correlation function\nis calculated for the first time. The derived correlation functions provide\ncritical references for future experiments, such as those at the LHC, where\nhigh-precision measurements of charmonium-nucleon correlations could unveil\nvaluable insights into non-perturbative QCD dynamics.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-07T09:10:58Z"}
{"aid":"http://arxiv.org/abs/2504.04858v1","title":"Don't Lag, RAG: Training-Free Adversarial Detection Using RAG","summary":"Adversarial patch attacks pose a major threat to vision systems by embedding\nlocalized perturbations that mislead deep models. Traditional defense methods\noften require retraining or fine-tuning, making them impractical for real-world\ndeployment. We propose a training-free Visual Retrieval-Augmented Generation\n(VRAG) framework that integrates Vision-Language Models (VLMs) for adversarial\npatch detection. By retrieving visually similar patches and images that\nresemble stored attacks in a continuously expanding database, VRAG performs\ngenerative reasoning to identify diverse attack types, all without additional\ntraining or fine-tuning. We extensively evaluate open-source large-scale VLMs,\nincluding Qwen-VL-Plus, Qwen2.5-VL-72B, and UI-TARS-72B-DPO, alongside\nGemini-2.0, a closed-source model. Notably, the open-source UI-TARS-72B-DPO\nmodel achieves up to 95 percent classification accuracy, setting a new\nstate-of-the-art for open-source adversarial patch detection. Gemini-2.0\nattains the highest overall accuracy, 98 percent, but remains closed-source.\nExperimental results demonstrate VRAG's effectiveness in identifying a variety\nof adversarial patches with minimal human annotation, paving the way for\nrobust, practical defenses against evolving adversarial patch attacks.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-07T09:14:47Z"}
{"aid":"http://arxiv.org/abs/2504.04860v1","title":"Stochastic differential equations driven by fractional Brownian motion:\n  dependence on the Hurst parameter","summary":"Stochastic models with fractional Brownian motion as source of randomness\nhave become popular since the early 2000s. Fractional Brownian motion (fBm) is\na Gaussian process, whose covariance depends on the so-called Hurst parameter\n$H\\in (0,1)$. Consequently, stochastic models with fBm also depend on the Hurst\nparameter $H$, and the stability of these models with respect to $H$ is an\ninteresting and important question. In recent years, the continuous (or even\nsmoother) dependence on the Hurst parameter has been studied for several\nstochastic models, including stochastic integrals with respect to fBm,\nstochastic differential equations (SDEs) driven by fBm and also stochastic\npartial differential equations with fractional noise, for different topologies,\ne.g., in law or almost surely, and for finite and infinite time horizons. In\nthis manuscript, we give an overview of these results with a particular focus\non SDE models.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T09:17:59Z"}
{"aid":"http://arxiv.org/abs/2504.04881v1","title":"Critical Behaviour in the Single Flavor Thirring Model in 2+1$d$ with\n  Wilson Kernel Domain Wall Fermions","summary":"We present results of a lattice field theory simulation of the 2+1$d$\nThirring model with $N=1$ fermion flavors, using domain wall fermions. The\nmodel exhibits a U(2) symmetry-breaking phase transition with the potential to\ndefine a UV-stable renormalisation group fixed point. The novelty is the\nreplacement of the Shamir kernel used in all previous work with the Wilson\nkernel, improving the action particularly with respect to the $L_s\\to\\infty$\nlimit needed to recover U(2), now under much better control. Auxiliary field\nensembles generated on $16^3\\times24$ with varying self-interaction strength\n$g^2$ and bare mass $m$ are used to measure the bilinear condensate order\nparameter $\\langle\\bar\\psi i\\gamma_3\\psi\\rangle$ with domain wall separations\nas large as $L_s=120$. The resulting $L_s\\to\\infty$ extrapolation is used to\nfit an empirical equation of state modelling spontaneous symmetry breaking as\n$m\\to0$. The fit is remarkably stable and compelling, with the fitted critical\nexponents $\\beta_m\\simeq2.4$, $\\delta\\simeq1.3$ differing markedly from\nprevious estimates. The associated susceptibility exhibits a mass hierarchy in\nline with physical expectations, again unlike previous estimates.\nSchwinger-Dyson equation (SDE) solutions of the Thirring model exploiting a\nhidden local symmetry in the action are reviewed, and analytic predictions\npresented for the exponents. In contrast to all previous lattice studies, the\nuniversal characteristics of the critical point revealed qualitatively resemble\nthe SDE predictions.","main_category":"hep-lat","categories":"hep-lat,hep-th","published":"2025-04-07T09:42:48Z"}
{"aid":"http://arxiv.org/abs/2504.04882v1","title":"Observation of non-Hermitian bulk-boundary correspondence in non-chiral\n  non-unitary quantum dynamics of single photons","summary":"The breakdown of conventional bulk-boundary correspondence, a cornerstone of\ntopological physics, is one of counter-intuitive phenomena in non-Hermitian\nsystems, that is deeply rooted in symmetry. In particular, preserved chiral\nsymmetry is one of the key ingredients, which plays a pivotal role in\ndetermining non-Hermitian topology. Nevertheless, chiral symmetry breaking in\nnon-Hermitian systems disrupts topological protection, modifies topological\ninvariants, and substantially reshapes spectral and edge-state behavior. The\ncorresponding fundamentally important bulk-boundary correspondence thus needs\nto be drastically reconstructed. However, it has so far eluded experimental\nefforts. Here, we theoretically predict and experimentally demonstrate the\nbulk-boundary correspondence of a one-dimensional (1D) non-Hermitian system\nwith chiral symmetry breaking in discrete-time non-chiral non-unitary quantum\nwalks of single photons. Through constructing a domain-wall configuration, we\nexperimentally observe the photon localization at the interface of domain-wall\nstructure, clearly indicating the presence of the topological edge mode. The\nappearance of that matches excellently with the prediction of our introduced\nnon-chiral non-Bloch topological invariants pair. Our work thus unequivocally\nbuilds the non-Hermitian bulk-boundary correspondence as a general principle\nfor studying topological physics in non-Hermitian systems with chiral symmetry\nbreaking.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.quant-gas,physics.optics,quant-ph","published":"2025-04-07T09:43:43Z"}
{"aid":"http://arxiv.org/abs/2504.04884v1","title":"Parallelization is All System Identification Needs: End-to-end Vibration\n  Diagnostics on a multi-core RISC-V edge device","summary":"The early detection of structural malfunctions requires the installation of\nreal-time monitoring systems ensuring continuous access to the damage-sensitive\ninformation; nevertheless, it can generate bottlenecks in terms of bandwidth\nand storage. Deploying data reduction techniques at the edge is recognized as a\nproficient solution to reduce the system's network traffic. However, the most\neffective solutions currently employed for the purpose are based on memory and\npower-hungry algorithms, making their embedding on resource-constrained devices\nvery challenging; this is the case of vibration data reduction based on System\nIdentification models. This paper presents PARSY-VDD, a fully optimized\nPArallel end-to-end software framework based on SYstem identification for\nVibration-based Damage Detection, as a suitable solution to perform damage\ndetection at the edge in a time and energy-efficient manner, avoiding streaming\nraw data to the cloud. We evaluate the damage detection capabilities of\nPARSY-VDD with two benchmarks: a bridge and a wind turbine blade, showcasing\nthe robustness of the end-to-end approach. Then, we deploy PARSY-VDD on both\ncommercial single-core and a specific multi-core edge device. We introduce an\narchitecture-agnostic algorithmic optimization for SysId, improving the\nexecution by 90x and reducing the consumption by 85x compared with the\nstate-of-the-art SysId implementation on GAP9. Results show that by utilizing\nthe unique parallel computing capabilities of GAP9, the execution time is\n751{\\mu}s with the high-performance multi-core solution operating at 370MHz and\n0.8V, while the energy consumption is 37{\\mu}J with the low-power solution\noperating at 240MHz and 0.65V. Compared with other single-core implementations\nbased on STM32 microcontrollers, the GAP9 high-performance configuration is 76x\nfaster, while the low-power configuration is 360x more energy efficient.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-07T09:51:02Z"}
{"aid":"http://arxiv.org/abs/2504.04885v1","title":"Renormalisation in the flow approach for singular SPDEs","summary":"In this work, we study the renormalisation of singular SPDEs in the flow\napproach recently developed by Duch using a bottom-up setting. We introduce a\ngeneral ansatz based on decorated trees for the solution of the flow equation.\nThe ansatz is renormalised in a recursive way, in the sense of the trees, via\nlocal extractions introduced for regularity structures. We derive the\nrenormalised equation from this ansatz and show that the renormalisation scheme\nis identical to that appearing in the context of regularity structures, thus\nmatching the BPHZ renormalisation.","main_category":"math.PR","categories":"math.PR,math-ph,math.AP,math.MP,math.RA","published":"2025-04-07T09:52:25Z"}
{"aid":"http://arxiv.org/abs/2504.04888v1","title":"A note on delay-inverse systems, I","summary":"A generalization of an inverse system in a category was recently introduced,\nas well as that of the corresponding pro-category These so called the\ndelay-inverse systems and delay-pro-category could potentially yield a new\ntheory of (delay-) inverse systems as well as a kind of coarser abstract shape\ntheory. However, we have proven that, whenever an indexing set has cardinality\n$\\aleph_{n}, n\\in\\mathbb{N}_{0}$, the potential new theory reduces, in its\nessence (the classification and invariants), to the ordinary one.","main_category":"math.CT","categories":"math.CT,math.GN","published":"2025-04-07T09:55:24Z"}
{"aid":"http://arxiv.org/abs/2504.04900v1","title":"Controlled bit-flip of period-doubling and discrete time crystalline\n  states in open systems","summary":"In this work, we explore the robustness of a bit-flip operation against\nthermal and quantum noise for bits represented by the symmetry-broken pairs of\nthe period-doubled (PD) states in a classical parametric oscillator and\ndiscrete time crystal (DTC) states in a fully-connected open spin-cavity\nsystem, respectively. The bit-flip operation corresponds to switching between\nthe two PD and DTC states induced by a defect in a periodic drive, introduced\nin a controlled manner by linearly ramping the phase of the modulation of the\ndrive. In the absence of stochastic noise, strong dissipation results in a more\nrobust bit-flip operation in which slight changes to the defect parameters do\nnot significantly lower the success rate of bit-flips. The operation remains\nrobust even in the presence of stochastic noise when the defect duration is\nsufficiently large. The fluctuations also enhance the success rate of the\nbit-flip below the critical defect duration needed to induce a switch. By\nconsidering parameter regimes in which the DTC states in the spin-cavity system\ndo not directly map to the PD states, we reveal that this robustness is due to\nthe system being quenched by the defect towards a new phase that has enough\nexcitation to suppress the effects of the stochastic noise. This allows for\nprecise control of the bit-flip operations by tuning into the preferred\nintermediate state that the system will enter during a bit-flip operation. We\ndemonstrate this in a modified protocol based on precise quenches of the\ndriving frequency.","main_category":"quant-ph","categories":"quant-ph,cond-mat.quant-gas,nlin.PS","published":"2025-04-07T10:19:55Z"}
{"aid":"http://arxiv.org/abs/2504.04903v1","title":"Lumina-OmniLV: A Unified Multimodal Framework for General Low-Level\n  Vision","summary":"We present Lunima-OmniLV (abbreviated as OmniLV), a universal multimodal\nmulti-task framework for low-level vision that addresses over 100 sub-tasks\nacross four major categories: image restoration, image enhancement,\nweak-semantic dense prediction, and stylization. OmniLV leverages both textual\nand visual prompts to offer flexible and user-friendly interactions. Built on\nDiffusion Transformer (DiT)-based generative priors, our framework supports\narbitrary resolutions -- achieving optimal performance at 1K resolution --\nwhile preserving fine-grained details and high fidelity. Through extensive\nexperiments, we demonstrate that separately encoding text and visual\ninstructions, combined with co-training using shallow feature control, is\nessential to mitigate task ambiguity and enhance multi-task generalization. Our\nfindings also reveal that integrating high-level generative tasks into\nlow-level vision models can compromise detail-sensitive restoration. These\ninsights pave the way for more robust and generalizable low-level vision\nsystems.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T10:22:00Z"}
{"aid":"http://arxiv.org/abs/2504.04907v1","title":"Video-Bench: Human-Aligned Video Generation Benchmark","summary":"Video generation assessment is essential for ensuring that generative models\nproduce visually realistic, high-quality videos while aligning with human\nexpectations. Current video generation benchmarks fall into two main\ncategories: traditional benchmarks, which use metrics and embeddings to\nevaluate generated video quality across multiple dimensions but often lack\nalignment with human judgments; and large language model (LLM)-based\nbenchmarks, though capable of human-like reasoning, are constrained by a\nlimited understanding of video quality metrics and cross-modal consistency. To\naddress these challenges and establish a benchmark that better aligns with\nhuman preferences, this paper introduces Video-Bench, a comprehensive benchmark\nfeaturing a rich prompt suite and extensive evaluation dimensions. This\nbenchmark represents the first attempt to systematically leverage MLLMs across\nall dimensions relevant to video generation assessment in generative models. By\nincorporating few-shot scoring and chain-of-query techniques, Video-Bench\nprovides a structured, scalable approach to generated video evaluation.\nExperiments on advanced models including Sora demonstrate that Video-Bench\nachieves superior alignment with human preferences across all dimensions.\nMoreover, in instances where our framework's assessments diverge from human\nevaluations, it consistently offers more objective and accurate insights,\nsuggesting an even greater potential advantage over traditional human judgment.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T10:32:42Z"}
{"aid":"http://arxiv.org/abs/2504.04913v1","title":"The GRINTA hard X-ray mission: an Explorer of the Transient Sky","summary":"The era of time domain multi-messenger (MM) astrophysics requires sensitive,\nlarge field-of-view (FoV) observatories that are able to quickly react in order\nto respond to alerts from gravitational wave (GW) triggers, neutrino\ndetections, and transient sources from all parts of the electromagnetic (EM)\nspectrum. This is particularly true at hard X-rays and soft gamma-rays where\nthe EM counterparts to GW triggers, gamma-ray bursts (GRBs), emit most of their\nflux. While the present decade has a number of instruments capable of\naccomplishing this task, there are no missions planned for the 2030's when\nimproved MM facilities will detect many more events. It is in this context that\nwe present the GRINTA mission concept. GRINTA has a large area, large FoV\ndetector to search for short, impulsive events in the 20 keV - 10 MeV energy\nrange and a coded mask telescope for localizing and performing follow-up\nobservations of sources from 5-200 keV. While GRINTA's main scientific goal is\nstudying MM events, the instruments will observe numerous other sources to\nexplore the sky at hard X-rays/soft gamma-rays.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.IM","published":"2025-04-07T10:47:36Z"}
{"aid":"http://arxiv.org/abs/2504.04932v1","title":"Weighted Approximate Quantum Natural Gradient for Variational Quantum\n  Eigensolver","summary":"Variational quantum eigensolver (VQE) is one of the most prominent algorithms\nusing near-term quantum devices, designed to find the ground state of a\nHamiltonian. In VQE, a classical optimizer iteratively updates the parameters\nin the quantum circuit. Among various optimization methods, quantum natural\ngradient descent (QNG) stands out as a promising optimization approach for VQE.\nHowever, standard QNG only leverages the quantum Fisher information of the\nentire system and treats each subsystem equally in the optimization process,\nwithout accounting for the different weights and contributions of each\nsubsystem corresponding to each observable. To address this limitation, we\npropose a Weighted Approximate Quantum Natural Gradient (WA-QNG) method\ntailored for $k$-local Hamiltonians. In this paper, we theoretically analyze\nthe potential advantages of WA-QNG compared to QNG from three distinct\nperspectives and reveal its connection with the Gauss-Newton method. We also\nshow it outperforms standard quantum natural gradient descent in the numerical\nexperiments for seeking the ground state of the Hamiltonian.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-07T11:18:09Z"}
{"aid":"http://arxiv.org/abs/2504.04934v1","title":"Boosting Relational Deep Learning with Pretrained Tabular Models","summary":"Relational databases, organized into tables connected by primary-foreign key\nrelationships, are a common format for organizing data. Making predictions on\nrelational data often involves transforming them into a flat tabular format\nthrough table joins and feature engineering, which serve as input to tabular\nmethods. However, designing features that fully capture complex relational\npatterns remains challenging. Graph Neural Networks (GNNs) offer a compelling\nalternative by inherently modeling these relationships, but their time overhead\nduring inference limits their applicability for real-time scenarios. In this\nwork, we aim to bridge this gap by leveraging existing feature engineering\nefforts to enhance the efficiency of GNNs in relational databases.\nSpecifically, we use GNNs to capture complex relationships within relational\ndatabases, patterns that are difficult to featurize, while employing engineered\nfeatures to encode temporal information, thereby avoiding the need to retain\nthe entire historical graph and enabling the use of smaller, more efficient\ngraphs. Our \\textsc{LightRDL} approach not only improves efficiency, but also\noutperforms existing models. Experimental results on the RelBench benchmark\ndemonstrate that our framework achieves up to $33\\%$ performance improvement\nand a $526\\times$ inference speedup compared to GNNs, making it highly suitable\nfor real-time inference.","main_category":"cs.DB","categories":"cs.DB,cs.AI,cs.LG","published":"2025-04-07T11:19:04Z"}
{"aid":"http://arxiv.org/abs/2504.04943v1","title":"Emergence of microbial host dormancy during a persistent virus epidemic","summary":"We study a minimal stochastic individual-based model for a microbial\npopulation challenged by a persistent (lytic) virus epidemic. We focus on the\nsituation in which the resident microbial host population and the virus\npopulation are in stable coexistence upon arrival of a single new ``mutant''\nhost individual. We assume that this mutant is capable of switching to a\nreversible state of dormancy upon contact with virions as a means of avoiding\ninfection by the virus. At the same time, we assume that this new dormancy\ntrait comes with a cost, namely a reduced individual reproduction rate. We\nprove that there is a non-trivial range of parameters where the mutants can\nnevertheless invade the resident population with strictly positive probability\n(bounded away from 0) in the large population limit. Given the reduced\nreproductive rate, such an invasion would be impossible in the absence of\neither the dormancy trait or the virus epidemic. We explicitly characterize the\nparameter regime where this emergence of a (costly) host dormancy trait is\npossible, determine the success probability of a single invader and the typical\namount of time it takes the successful mutants to reach a macroscopic\npopulation size. We conclude this study by an investigation of the fate of the\npopulation after the successful emergence of a dormancy trait. Heuristic\narguments and simulations suggest that after successful invasion, either both\nhost types and the virus will reach coexistence, or the mutants will drive the\nresident hosts to extinction while the virus will stay in the system.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T11:30:42Z"}
{"aid":"http://arxiv.org/abs/2504.04962v1","title":"A refined operational semantics for FreeCHR","summary":"Constraint Handling Rules (CHR) is a rule-based programming language that\nwhich is typically embedded into a general-purpose language with a plethora of\nimplementations. However, the existing implementations often re-invent the way\nto embed CHR, which impedes maintenance and weakens assertions of correctness.\nTo formalize and thereby unify the embedding of CHR into arbitrary host\nlanguages, we recently introduced the framework FreeCHR and proved it to be a\nvalid representation of classical CHR. Until now, this framework only includes\na translation of the very abstract operational semantics of CHR which, due to\nits abstract nature, introduces several practical issues. In this paper we\npresent a definition of the refined operational semantics for FreeCHR and prove\nit to be both, a valid concretization of the very abstract semantics of\nFreeCHR, and an equivalent representation of the refined semantics of CHR. This\nwill establish implementations of FreeCHR as equivalent in behavior and\nexpressiveness to existing implementations of CHR. This is an extended preprint\nof a paper submitted to the the 41st International Conference on Logic\nProgramming.","main_category":"cs.PL","categories":"cs.PL","published":"2025-04-07T11:51:07Z"}
{"aid":"http://arxiv.org/abs/2504.04965v1","title":"Climate adaptation of millet and sorghum varieties in North-Eastern\n  Senegal: cross-referencing rainfall, thermal and phenological parameters","summary":"Millet (Pennisetum glaucum) and sorghum (Sorghum bicolor) are the main\nrainfed cereals grown in North-Eastern Senegal. However, faced with constraints\nsuch as falling rainfall, rising temperatures and frequent dry spells, their\nproduction is tending to decline. This article examines the climatic\nconstraints and other shocks suffered by rainfed millet varieties Souna__3,\nICTP 8203, GB 8735, Gawane and Chakti, as well as those as sorghum CE__180-33,\nPayenne and Golob{\\'e}, which are the main varieties released and currently\ngrown in north-eastern Senegal. Based on data collected in Podor, Matam and\nLingu{\\`e}re, the article analyses the adaptation of different millet and\nsorghum varieties to climatic condition and their evolution over time The\nresults show a rainfall deficit since the early 1970s, combined by greater\nthermal constraints. Analysis of the differences between cumulative rainfall\nand maximum evapotranspiration for varieties at different growth stages reveals\nconstant water deficits for Souna__3 millet and CE 180-33 sorghum. In contrast,\nChakti millet shows positive water balances in over 80% of years in the east\nand west of the study area, and in 47% of cases in the north. Only Chakti and\nICTP 8203 are adapted to the climatic conditions of the eastern and western\nzones, with a probability of suitability of over 80% for the periods 1931-1969\nand 1999-2020. However, none of the varieties is adapted to the climatic\nconditions in the north. In addition to these climatic constraints, the\ninterviewed farmers attribute the decline in agricultural production to\nlivestock straying, attacks by bird pests and parasitic infestations.\nexacerbate agricultural losses. It is therefore essential to develop\ncomplementary strategies including wider dissemination of varieties better\nadapted to current climatic conditions, such as Chakti and ICTP 8203, and the\nstrengthening of crop protection systems, notably through biological control\nand integrated pest management.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-04-07T11:52:54Z"}
{"aid":"http://arxiv.org/abs/2504.04967v1","title":"Using AI to Help in the Semantic Lexical Database to Evaluate Ideas","summary":"Inside a challenge of ideas there are several phases in a Creative Support\nSystem (CSS), they are problem analysis, ideation, evaluation, and\nimplementation. Our problem: we need a full semantic lexical database SLD in an\noral (voice) and writing way to help stakeholders to create ideas, these ideas\ncontain nouns, verbs, adverbs, adjectives in the English, Spanish, and French\nlanguages. We utilize a Cloud Service Provider to use a service of Artificial\nIntelligence (AI), also we prepare nouns, verbs, adjectives and adverbs files\nin order to create the service text to voice and create our SLD with voice.\nThis paper presents, first, an introduction about some contests that use a\nsemantic lexical database in different languages; second, a SLD management\napproach using analysis of texts; third, a management application approach to\ncomplete all the new elements; fourth, the results of the management\napplication approach, finally the conclusions and future work.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-07T11:54:06Z"}
{"aid":"http://arxiv.org/abs/2504.04970v1","title":"A High-Force Gripper with Embedded Multimodal Sensing for Powerful and\n  Perception Driven Grasping","summary":"Modern humanoid robots have shown their promising potential for executing\nvarious tasks involving the grasping and manipulation of objects using their\nend-effectors. Nevertheless, in the most of the cases, the grasping and\nmanipulation actions involve low to moderate payload and interaction forces.\nThis is due to limitations often presented by the end-effectors, which can not\nmatch their arm-reachable payload, and hence limit the payload that can be\ngrasped and manipulated. In addition, grippers usually do not embed adequate\nperception in their hardware, and grasping actions are mainly driven by\nperception sensors installed in the rest of the robot body, frequently affected\nby occlusions due to the arm motions during the execution of the grasping and\nmanipulation tasks. To address the above, we developed a modular high grasping\nforce gripper equipped with embedded multi-modal perception functionalities.\nThe proposed gripper can generate a grasping force of 110 N in a compact\nimplementation. The high grasping force capability is combined with embedded\nmulti-modal sensing, which includes an eye-in-hand camera, a Time-of-Flight\n(ToF) distance sensor, an Inertial Measurement Unit (IMU) and an\nomnidirectional microphone, permitting the implementation of perception-driven\ngrasping functionalities.\n  We extensively evaluated the grasping force capacity of the gripper by\nintroducing novel payload evaluation metrics that are a function of the robot\narm's dynamic motion and gripper thermal states. We also evaluated the embedded\nmulti-modal sensing by performing perception-guided enhanced grasping\noperations.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-07T11:57:08Z"}
{"aid":"http://arxiv.org/abs/2504.04972v1","title":"Sub-diffusive behavior of a recurrent Axis-Driven Random Walk","summary":"We study the second order of the number of excursions of a simple random walk\nwith a bias that drives a return toward the origin along the axes introduced by\nP. Andreoletti and P. Debs \\cite{AndDeb3}. This is a crucial step toward\nderiving the asymptotic behavior of these walks, whose limit is explicit and\nreveals various characteristics of the process: the invariant probability\nmeasure of the extracted coordinates away from the axes, the 1-stable\ndistribution arising from the tail distribution of entry times on the axes, and\nfinally, the presence of a Bessel process of dimension 3, which implies that\nthe trajectory can be interpreted as a random path conditioned to stay within a\nsingle quadrant.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T11:58:11Z"}
{"aid":"http://arxiv.org/abs/2504.04974v1","title":"Towards Visual Text Grounding of Multimodal Large Language Model","summary":"Despite the existing evolution of Multimodal Large Language Models (MLLMs), a\nnon-neglectable limitation remains in their struggle with visual text\ngrounding, especially in text-rich images of documents. Document images, such\nas scanned forms and infographics, highlight critical challenges due to their\ncomplex layouts and textual content. However, current benchmarks do not fully\naddress these challenges, as they mostly focus on visual grounding on natural\nimages, rather than text-rich document images. Thus, to bridge this gap, we\nintroduce TRIG, a novel task with a newly designed instruction dataset for\nbenchmarking and improving the Text-Rich Image Grounding capabilities of MLLMs\nin document question-answering. Specifically, we propose an OCR-LLM-human\ninteraction pipeline to create 800 manually annotated question-answer pairs as\na benchmark and a large-scale training set of 90$ synthetic data based on four\ndiverse datasets. A comprehensive evaluation of various MLLMs on our proposed\nbenchmark exposes substantial limitations in their grounding capability on\ntext-rich images. In addition, we propose two simple and effective TRIG methods\nbased on general instruction tuning and plug-and-play efficient embedding,\nrespectively. By finetuning MLLMs on our synthetic dataset, they promisingly\nimprove spatial reasoning and grounding capabilities.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL,cs.LG","published":"2025-04-07T12:01:59Z"}
{"aid":"http://arxiv.org/abs/2504.04982v1","title":"Transforming Future Data Center Operations and Management via Physical\n  AI","summary":"Data centers (DCs) as mission-critical infrastructures are pivotal in\npowering the growth of artificial intelligence (AI) and the digital economy.\nThe evolution from Internet DC to AI DC has introduced new challenges in\noperating and managing data centers for improved business resilience and\nreduced total cost of ownership. As a result, new paradigms, beyond the\ntraditional approaches based on best practices, must be in order for future\ndata centers. In this research, we propose and develop a novel Physical AI\n(PhyAI) framework for advancing DC operations and management. Our system\nleverages the emerging capabilities of state-of-the-art industrial products and\nour in-house research and development. Specifically, it presents three core\nmodules, namely: 1) an industry-grade in-house simulation engine to simulate DC\noperations in a highly accurate manner, 2) an AI engine built upon NVIDIA\nPhysicsNemo for the training and evaluation of physics-informed machine\nlearning (PIML) models, and 3) a digital twin platform built upon NVIDIA\nOmniverse for our proposed 5-tier digital twin framework. This system presents\na scalable and adaptable solution to digitalize, optimize, and automate future\ndata center operations and management, by enabling real-time digital twins for\nfuture data centers. To illustrate its effectiveness, we present a compelling\ncase study on building a surrogate model for predicting the thermal and airflow\nprofiles of a large-scale DC in a real-time manner. Our results demonstrate its\nsuperior performance over traditional time-consuming Computational Fluid\nDynamics/Heat Transfer (CFD/HT) simulation, with a median absolute temperature\nprediction error of 0.18 {\\deg}C. This emerging approach would open doors to\nseveral potential research directions for advancing Physical AI in future DC\noperations.","main_category":"cs.AI","categories":"cs.AI,cs.DC","published":"2025-04-07T12:09:22Z"}
{"aid":"http://arxiv.org/abs/2504.04992v1","title":"Error bound for the asymptotic expansion of the Hartman-Watson integral","summary":"This note gives a bound on the error of the leading term of the $t\\to 0$\nasymptotic expansion of the Hartman-Watson distribution $\\theta(r,t)$ in the\nregime $rt=\\rho$ constant. The leading order term has the form\n$\\theta(\\rho/t,t)=\\frac{1}{2\\pi t}e^{-\\frac{1}{t} (F(\\rho)-\\pi^2/2)} G(\\rho) (1\n+ \\vartheta(t,\\rho))$, where the error term is bounded uniformly over $\\rho$ as\n$|\\vartheta(t,\\rho)|\\leq \\frac{1}{70}t$.","main_category":"math.CA","categories":"math.CA,q-fin.CP","published":"2025-04-07T12:18:19Z"}
{"aid":"http://arxiv.org/abs/2504.04995v1","title":"The universal crossover from thermodynamics and dynamics of\n  supercritical RN-AdS black hole","summary":"We study the properties of supercritical Reissner-Nordstr\\\"om Anti-de Sitter\n(RN-AdS) black holes in the extended phase space with the pressure defines as\nthe cosmological constant. Supercritical black holes exist in the region where\nboth temperature and pressure exceed the critical point, known as the\nsupercritical region. The conventional view states that black holes in this\nregime are indistinguishable between large and small phases. However, recent\nresearch reveals that the supercritical regime exhibits universal gas-like and\nliquid-like phase separation, which shed light on the study on the\nsupercritical region of RN-AdS black holes in the extended phase space. In this\nwork, we calculate the thermodynamic potential and quasinormal modes (QNMs) of\nRN-AdS black holes, and identify transition curves between two different states\nin supercritical region using thermodynamic and dynamic methods. On one hand,\nwe find the thermodynamic crossover curve (Widom line) by defining the scaled\nvariance $\\Omega$ (a higher-order derivative of Gibbs free energy). On the\nother hand, we identify the dynamic crossover curve (Frenkel line) by analyzing\ntransitions between distinct QNM decay modes.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-ph,hep-th","published":"2025-04-07T12:24:23Z"}
{"aid":"http://arxiv.org/abs/2504.05002v1","title":"SmartBugBert: BERT-Enhanced Vulnerability Detection for Smart Contract\n  Bytecode","summary":"Smart contracts deployed on blockchain platforms are vulnerable to various\nsecurity vulnerabilities. However, only a small number of Ethereum contracts\nhave released their source code, so vulnerability detection at the bytecode\nlevel is crucial. This paper introduces SmartBugBert, a novel approach that\ncombines BERT-based deep learning with control flow graph (CFG) analysis to\ndetect vulnerabilities directly from bytecode. Our method first decompiles\nsmart contract bytecode into optimized opcode sequences, extracts semantic\nfeatures using TF-IDF, constructs control flow graphs to capture execution\nlogic, and isolates vulnerable CFG fragments for targeted analysis. By\nintegrating both semantic and structural information through a fine-tuned BERT\nmodel and LightGBM classifier, our approach effectively identifies four\ncritical vulnerability types: transaction-ordering, access control,\nself-destruct, and timestamp dependency vulnerabilities. Experimental\nevaluation on 6,157 Ethereum smart contracts demonstrates that SmartBugBert\nachieves 90.62% precision, 91.76% recall, and 91.19% F1-score, significantly\noutperforming existing detection methods. Ablation studies confirm that the\ncombination of semantic features with CFG information substantially enhances\ndetection performance. Furthermore, our approach maintains efficient detection\nspeed (0.14 seconds per contract), making it practical for large-scale\nvulnerability assessment.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-07T12:30:12Z"}
{"aid":"http://arxiv.org/abs/2504.05003v1","title":"Re-evaluation of the deuteron-deuteron thermonuclear reaction rates in\n  metallic deuterium plasma","summary":"The deuteron-deuteron (D-D) thermonuclear reaction rates in metallic\nenvironments (considering the electron screening effects) is re-evaluated using\nthe S-factor functions which\n  were obtained by fitting to low-energy data on D-D reactions.\n  For this purpose, a fitted S-factor model based on the NACRE compilation is\nemployed.\n  This limited the energy range of Big Bang nucleosynthesis (BBN) for\n  the $ ^{2}\\textrm{H}\\left(d,p\\right) ^{3}\\textrm{H}$ and $^{2} \\textrm{H}\n\\left(d,n\\right) ^{3}\\textrm{He}$ reactions.\n  The corresponding Maxwellian-averaged thermonuclear reaction\n  rates of relevance in astrophysical plasmas at temperatures in the\n  range from $10^{6}$ K to $10^{10}\\left(\\textrm{or }1.3\\times10^{8}\\right)$ K\nare provided in tabular formats.\n  In these evaluations,\n  the screening energy is assumed to be $100, 400, 750, 1000$ eV and $1250$ eV.\n  This series of values has been selected based on theoretical and experimental\nstudies conducted so far.","main_category":"nucl-th","categories":"nucl-th,nucl-ex","published":"2025-04-07T12:30:20Z"}
{"aid":"http://arxiv.org/abs/2504.05014v1","title":"Review of analytic results on quasinormal modes of black holes","summary":"We present a concise review of known analytic results for quasinormal modes\nof black holes and related spacetimes. Our emphasis is on those regimes where\nthe perturbation equations admit exact or perturbative solutions, providing\ninsights complementary to numerical or semi-analytic approaches. We discuss\nsolvable cases in lower-dimensional spacetimes, algebraically special modes,\nand exact results in higher-curvature gravity theories. Particular attention is\ngiven to the eikonal regime and its correspondence with null geodesics, as well\nas to beyond-eikonal approximations based on inverse multipole expansions in\nparametrized metrics. We review analytic solutions obtained in the\nnear-extremal limit of Schwarzschild - de Sitter black holes, in the regime of\nlarge field mass, and in pure de Sitter and anti - de Sitter spacetimes, where\nboundary conditions play a crucial role. While not exhaustive, this overview\nhighlights the diversity of techniques and physical insights made possible by\nanalytic treatments of quasinormal spectra.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-07T12:39:23Z"}
{"aid":"http://arxiv.org/abs/2504.05015v1","title":"PVASS Reachability is Decidable","summary":"Reachability in pushdown vector addition systems with states (PVASS) is among\nthe longest standing open problems in Theoretical Computer Science. We show\nthat the problem is decidable in full generality. Our decision procedure is\nsimilar in spirit to the KLMST algorithm for VASS reachability, but works over\nobjects that support an elaborate form of procedure summarization as known from\npushdown reachability.","main_category":"cs.LO","categories":"cs.LO,cs.FL,F.1.1","published":"2025-04-07T12:40:18Z"}
{"aid":"http://arxiv.org/abs/2504.05019v1","title":"Mixture-of-Personas Language Models for Population Simulation","summary":"Advances in Large Language Models (LLMs) paved the way for their emerging\napplications in various domains, such as human behavior simulations, where LLMs\ncould augment human-generated data in social science research and machine\nlearning model training. However, pretrained LLMs often fail to capture the\nbehavioral diversity of target populations due to the inherent variability\nacross individuals and groups. To address this, we propose \\textit{Mixture of\nPersonas} (MoP), a \\textit{probabilistic} prompting method that aligns the LLM\nresponses with the target population. MoP is a contextual mixture model, where\neach component is an LM agent characterized by a persona and an exemplar\nrepresenting subpopulation behaviors. The persona and exemplar are randomly\nchosen according to the learned mixing weights to elicit diverse LLM responses\nduring simulation. MoP is flexible, requires no model finetuning, and is\ntransferable across base models. Experiments for synthetic data generation show\nthat MoP outperforms competing methods in alignment and diversity metrics.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-07T12:43:05Z"}
{"aid":"http://arxiv.org/abs/2504.05024v1","title":"Concept Extraction for Time Series with ECLAD-ts","summary":"Convolutional neural networks (CNNs) for time series classification (TSC) are\nbeing increasingly used in applications ranging from quality prediction to\nmedical diagnosis. The black box nature of these models makes understanding\ntheir prediction process difficult. This issue is crucial because CNNs are\nprone to learning shortcuts and biases, compromising their robustness and\nalignment with human expectations. To assess whether such mechanisms are being\nused and the associated risk, it is essential to provide model explanations\nthat reflect the inner workings of the model. Concept Extraction (CE) methods\noffer such explanations, but have mostly been developed for the image domain so\nfar, leaving a gap in the time series domain. In this work, we present a CE and\nlocalization method tailored to the time series domain, based on the ideas of\nCE methods for images. We propose the novel method ECLAD-ts, which provides\npost-hoc global explanations based on how the models encode subsets of the\ninput at different levels of abstraction. For this, concepts are produced by\nclustering timestep-wise aggregations of CNN activation maps, and their\nimportance is computed based on their impact on the prediction process. We\nevaluate our method on synthetic and natural datasets. Furthermore, we assess\nthe advantages and limitations of CE in time series through empirical results.\nOur results show that ECLAD-ts effectively explains models by leveraging their\ninternal representations, providing useful insights about their prediction\nprocess.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-07T12:49:20Z"}
{"aid":"http://arxiv.org/abs/2504.05046v1","title":"MotionPRO: Exploring the Role of Pressure in Human MoCap and Beyond","summary":"Existing human Motion Capture (MoCap) methods mostly focus on the visual\nsimilarity while neglecting the physical plausibility. As a result, downstream\ntasks such as driving virtual human in 3D scene or humanoid robots in real\nworld suffer from issues such as timing drift and jitter, spatial problems like\nsliding and penetration, and poor global trajectory accuracy. In this paper, we\nrevisit human MoCap from the perspective of interaction between human body and\nphysical world by exploring the role of pressure. Firstly, we construct a\nlarge-scale human Motion capture dataset with Pressure, RGB and Optical sensors\n(named MotionPRO), which comprises 70 volunteers performing 400 types of\nmotion, encompassing a total of 12.4M pose frames. Secondly, we examine both\nthe necessity and effectiveness of the pressure signal through two challenging\ntasks: (1) pose and trajectory estimation based solely on pressure: We propose\na network that incorporates a small kernel decoder and a long-short-term\nattention module, and proof that pressure could provide accurate global\ntrajectory and plausible lower body pose. (2) pose and trajectory estimation by\nfusing pressure and RGB: We impose constraints on orthographic similarity along\nthe camera axis and whole-body contact along the vertical axis to enhance the\ncross-attention strategy to fuse pressure and RGB feature maps. Experiments\ndemonstrate that fusing pressure with RGB features not only significantly\nimproves performance in terms of objective metrics, but also plausibly drives\nvirtual humans (SMPL) in 3D scene. Furthermore, we demonstrate that\nincorporating physical perception enables humanoid robots to perform more\nprecise and stable actions, which is highly beneficial for the development of\nembodied artificial intelligence. Project page is available at:\nhttps://nju-cite-mocaphumanoid.github.io/MotionPRO/","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:17:24Z"}
{"aid":"http://arxiv.org/abs/2504.05049v1","title":"CMaP-SAM: Contraction Mapping Prior for SAM-driven Few-shot Segmentation","summary":"Few-shot segmentation (FSS) aims to segment new classes using few annotated\nimages. While recent FSS methods have shown considerable improvements by\nleveraging Segment Anything Model (SAM), they face two critical limitations:\ninsufficient utilization of structural correlations in query images, and\nsignificant information loss when converting continuous position priors to\ndiscrete point prompts. To address these challenges, we propose CMaP-SAM, a\nnovel framework that introduces contraction mapping theory to optimize position\npriors for SAM-driven few-shot segmentation. CMaP-SAM consists of three key\ncomponents: (1) a contraction mapping module that formulates position prior\noptimization as a Banach contraction mapping with convergence guarantees. This\nmodule iteratively refines position priors through pixel-wise structural\nsimilarity, generating a converged prior that preserves both semantic guidance\nfrom reference images and structural correlations in query images; (2) an\nadaptive distribution alignment module bridging continuous priors with SAM's\nbinary mask prompt encoder; and (3) a foreground-background decoupled\nrefinement architecture producing accurate final segmentation masks. Extensive\nexperiments demonstrate CMaP-SAM's effectiveness, achieving state-of-the-art\nperformance with 71.1 mIoU on PASCAL-$5^i$ and 56.1 on COCO-$20^i$ datasets.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:19:16Z"}
{"aid":"http://arxiv.org/abs/2504.05065v1","title":"Quantitative Supermartingale Certificates","summary":"We introduce a general methodology for quantitative model checking and\ncontrol synthesis with supermartingale certificates. We show that every\nspecification that is invariant to time shifts admits a stochastic invariant\nthat bounds its probability from below; for systems with general state space,\nthe stochastic invariant bounds this probability as closely as desired; for\nsystems with finite state space, it quantifies it exactly. Our result enables\nthe extension of every certificate for the almost-sure satisfaction of\nshift-invariant specifications to its quantitative counterpart, ensuring\ncompleteness up to an approximation in the general case and exactness in the\nfinite-state case. This generalises and unifies existing supermartingale\ncertificates for quantitative verification and control under reachability,\nsafety, reach-avoidance, and stability specifications, as well as asymptotic\nbounds on accrued costs and rewards. Furthermore, our result provides the first\nsupermartingale certificate for computing upper and lower bounds on the\nprobability of satisfying $\\omega$-regular and linear temporal logic\nspecifications. We present an algorithm for quantitative $\\omega$-regular\nverification and control synthesis based on our method and demonstrate its\npractical efficacy on several infinite-state examples.","main_category":"cs.LO","categories":"cs.LO,cs.SY,eess.SY","published":"2025-04-07T13:34:40Z"}
{"aid":"http://arxiv.org/abs/2504.05066v1","title":"Turing instability for nonlocal heterogeneous reaction-diffusion\n  systems: A computer-assisted proof approach","summary":"This paper provides a computer-assisted proof for the Turing instability\ninduced by heterogeneous nonlocality in reaction-diffusion systems. Due to the\nheterogeneity and nonlocality, the linear Fourier analysis gives rise to\n\\textit{strongly coupled} infinite differential systems. By introducing\nsuitable changes of basis as well as the Gershgorin disks theorem for infinite\nmatrices, we first show that all $N$-th Gershgorin disks lie completely on the\nleft half-plane for sufficiently large $N$. For the remaining finitely many\ndisks, a computer-assisted proof shows that if the intensity $\\delta$ of the\nnonlocal term is large enough, there is precisely one eigenvalue with positive\nreal part, which proves the Turing instability. Moreover, by detailed study of\nthis eigenvalue as a function of $\\delta$, we obtain a sharp threshold\n$\\delta^*$ which is the bifurcation point for Turing instability.","main_category":"math.AP","categories":"math.AP,cs.NA,math.DS,math.NA","published":"2025-04-07T13:34:46Z"}
{"aid":"http://arxiv.org/abs/2504.05074v1","title":"On the Performance of an Explainable Language Model on PubMedQA","summary":"Large language models (LLMs) have shown significant abilities in retrieving\nmedical knowledge, reasoning over it and answering medical questions comparably\nto physicians. However, these models are not interpretable, hallucinate, are\ndifficult to maintain and require enormous compute resources for training and\ninference. In this paper, we report results from Gyan, an explainable language\nmodel based on an alternative architecture, on the PubmedQA data set. The Gyan\nLLM is a compositional language model and the model is decoupled from\nknowledge. Gyan is trustable, transparent, does not hallucinate and does not\nrequire significant training or compute resources. Gyan is easily transferable\nacross domains. Gyan-4.3 achieves SOTA results on PubmedQA with 87.1% accuracy\ncompared to 82% by MedPrompt based on GPT-4 and 81.8% by Med-PaLM 2 (Google and\nDeepMind). We will be reporting results for other medical data sets - MedQA,\nMedMCQA, MMLU - Medicine in the future.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T13:42:02Z"}
{"aid":"http://arxiv.org/abs/2504.05075v1","title":"PvNeXt: Rethinking Network Design and Temporal Motion for Point Cloud\n  Video Recognition","summary":"Point cloud video perception has become an essential task for the realm of 3D\nvision. Current 4D representation learning techniques typically engage in\niterative processing coupled with dense query operations. Although effective in\ncapturing temporal features, this approach leads to substantial computational\nredundancy. In this work, we propose a framework, named as PvNeXt, for\neffective yet efficient point cloud video recognition, via personalized\none-shot query operation. Specially, PvNeXt consists of two key modules, the\nMotion Imitator and the Single-Step Motion Encoder. The former module, the\nMotion Imitator, is designed to capture the temporal dynamics inherent in\nsequences of point clouds, thus generating the virtual motion corresponding to\neach frame. The Single-Step Motion Encoder performs a one-step query operation,\nassociating point cloud of each frame with its corresponding virtual motion\nframe, thereby extracting motion cues from point cloud sequences and capturing\ntemporal dynamics across the entire sequence. Through the integration of these\ntwo modules, {PvNeXt} enables personalized one-shot queries for each frame,\neffectively eliminating the need for frame-specific looping and intensive query\nprocesses. Extensive experiments on multiple benchmarks demonstrate the\neffectiveness of our method.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:43:51Z"}
{"aid":"http://arxiv.org/abs/2504.05089v1","title":"Climplicit: Climatic Implicit Embeddings for Global Ecological Tasks","summary":"Deep learning on climatic data holds potential for macroecological\napplications. However, its adoption remains limited among scientists outside\nthe deep learning community due to storage, compute, and technical expertise\nbarriers. To address this, we introduce Climplicit, a spatio-temporal\ngeolocation encoder pretrained to generate implicit climatic representations\nanywhere on Earth. By bypassing the need to download raw climatic rasters and\ntrain feature extractors, our model uses x1000 fewer disk space and\nsignificantly reduces computational needs for downstream tasks. We evaluate our\nClimplicit embeddings on biomes classification, species distribution modeling,\nand plant trait regression. We find that linear probing our Climplicit\nembeddings consistently performs better or on par with training a model from\nscratch on downstream tasks and overall better than alternative geolocation\nencoding models.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:58:55Z"}
{"aid":"http://arxiv.org/abs/2504.05106v1","title":"SpeakEasy: Enhancing Text-to-Speech Interactions for Expressive Content\n  Creation","summary":"Novice content creators often invest significant time recording expressive\nspeech for social media videos. While recent advancements in text-to-speech\n(TTS) technology can generate highly realistic speech in various languages and\naccents, many struggle with unintuitive or overly granular TTS interfaces. We\npropose simplifying TTS generation by allowing users to specify high-level\ncontext alongside their script. Our Wizard-of-Oz system, SpeakEasy, leverages\nuser-provided context to inform and influence TTS output, enabling iterative\nrefinement with high-level feedback. This approach was informed by two\n8-subject formative studies: one examining content creators' experiences with\nTTS, and the other drawing on effective strategies from voice actors. Our\nevaluation shows that participants using SpeakEasy were more successful in\ngenerating performances matching their personal standards, without requiring\nsignificantly more effort than leading industry interfaces.","main_category":"cs.HC","categories":"cs.HC,cs.AI,cs.LG","published":"2025-04-07T14:13:49Z"}
{"aid":"http://arxiv.org/abs/2504.05110v1","title":"Stochastic storage models in theoretical physics problems","summary":"Stochastic storage models based on essentially non-Gaussian noise are\nconsidered. The stochastic description of physical systems based on stochastic\nstorage models is associated with generalized Poisson (or shot) noise, in which\nthe jump values can be quite large. Stochastic storage models have a direct\nphysical meaning: some elements enter the system and leave it. Storage\nprocesses fit into the general scheme of dynamic systems subject to the\nadditive influence of a random process. The main relationships of storage\nmodels are described, and the possibilities of applying the mathematical\nprovisions of stochastic storage processes to various physical problems are\nindicated. A number of examples of applying the stochastic storage model are\nconsidered.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-07T14:15:18Z"}
{"aid":"http://arxiv.org/abs/2504.05116v1","title":"Supersaturation of odd linear cycles","summary":"An $r$-uniform linear cycle of length $\\ell$, denoted by $C^r_{\\ell}$, is an\n$r$-graph with $\\ell$ edges $e_1,e_2,\\dots,e_{\\ell}$ where\n$e_i=\\{v_{(r-1)(i-1)},v_{(r-1)(i-1)+1},\\dots,v_{(r-1)i}\\}$ (here\n$v_0=v_{(r-1)\\ell}$). For $0<\\delta<1$ and $n$ sufficiently large, we show that\nevery $n$-vertex $r$-graph $G$ with $n^{r-\\delta}$ edges contains at least\n$n^{(r-1)(2\\ell+1)-\\delta(2\\ell+1+\\frac{4\\ell-1}{(r-1)(2\\ell+1)-3})-o(1)}$\ncopies of $C^r_{2\\ell+1}$. Further, conditioning on the existence of dense\nhigh-girth hypergraphs, we show that there exists $n$-vertex $r$-graphs with\n$n^{r-\\delta}$ edges and at most\n$n^{(r-1)(2\\ell+1)-\\delta(2\\ell+1+\\frac{1}{(r-1)\\ell-1})+o(1)}$ copies of\n$C^r_{2\\ell+1}$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-07T14:20:13Z"}
{"aid":"http://arxiv.org/abs/2504.05117v1","title":"On the Origins of \"Hostless'' Supernovae: Testing the Faint-end Galaxy\n  Luminosity Function and Supernova Progenitors with Events in Dwarf Galaxies","summary":"We present arguments on the likely origins of supernovae without associated\nhost galaxies from open field, non-clustered, environments. We show why it is\nunlikely these ``hostless'' supernovae stem from escaped hyper-velocity stars\n(HVS) in any appreciable numbers, especially for core-collapse supernovae. It\nis highly likely that hostless events arise from dwarf host galaxies too faint\nto be detected in their parent surveys. Several detections and numerous upper\nlimits suggest a large number of field dwarfs, to $M_V>-14$, which themselves\nmay be important to constraining the slope of the low-mass end of the UV\nluminosity function, understanding galaxy evolution, and putting $\\Lambda$CDM\ninto context. Moreover, the detailed study of these mass and\nmetallicity-constrained host environments, and the variety of supernovae that\noccur within them, could provide more stringent constraints on the nature of\nprogenitor systems.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-04-07T14:20:48Z"}
{"aid":"http://arxiv.org/abs/2504.05122v1","title":"DoCIA: An Online Document-Level Context Incorporation Agent for Speech\n  Translation","summary":"Document-level context is crucial for handling discourse challenges in\ntext-to-text document-level machine translation (MT). Despite the increased\ndiscourse challenges introduced by noise from automatic speech recognition\n(ASR), the integration of document-level context in speech translation (ST)\nremains insufficiently explored. In this paper, we develop DoCIA, an online\nframework that enhances ST performance by incorporating document-level context.\nDoCIA decomposes the ST pipeline into four stages. Document-level context is\nintegrated into the ASR refinement, MT, and MT refinement stages through\nauxiliary LLM (large language model)-based modules. Furthermore, DoCIA\nleverages document-level information in a multi-level manner while minimizing\ncomputational overhead. Additionally, a simple yet effective determination\nmechanism is introduced to prevent hallucinations from excessive refinement,\nensuring the reliability of the final results. Experimental results show that\nDoCIA significantly outperforms traditional ST baselines in both sentence and\ndiscourse metrics across four LLMs, demonstrating its effectiveness in\nimproving ST performance.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T14:26:49Z"}
{"aid":"http://arxiv.org/abs/2504.05126v1","title":"Frustrated Rydberg Atom Arrays Meet Cavity-QED: Emergence of the\n  Superradiant Clock Phase","summary":"Rydberg atom triangular arrays in an optical cavity serve as an ideal\nplatform for understanding the interplay between geometric frustration and\nquantized photons. Using a large-scale quantum Monte Carlo method, we obtain a\nrich ground state phase diagram. Around half-filling, the infinite long-range\nlight-matter interaction lifts the ground state degeneracy, resulting in a\nnovel order-coexisted superradiant clock (SRC) phase that completely destroys\nthe fragile order-by-disorder (OBD) phase observed in classical light fields.\nAccording to the Ginzburg-Landau theory, this replacement may result from the\ncompetition between threefold and sixfold clock terms. Similar to the spin\nsupersolid, the clear first-order phase transition at the $Z_2$ symmetry line\nis attributed to the nonzero photon density, which couples to the threefold\nclock term. Finally, we discuss the low-energy physics in the dimer language\nand propose that cavity-mediated nonlocal ring exchange interactions may play a\ncritical role in the rich physics induced by the attachment of cavity-QED. Our\nwork opens a new arena of research on the emergent phenomena of quantum phase\ntransitions in many-body quantum optics.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,cond-mat.str-el,quant-ph","published":"2025-04-07T14:29:45Z"}
{"aid":"http://arxiv.org/abs/2504.05128v1","title":"Kinetic study of compressible Rayleigh-Taylor instability with\n  time-varying acceleration","summary":"Rayleigh-Taylor (RT) instability commonly arises in compressible systems with\ntime-dependent acceleration in practical applications. To capture the complex\ndynamics of such systems, a two-component discrete Boltzmann method is\ndeveloped to systematically investigate the compressible RT instability driven\nby variable acceleration. Specifically, the effects of different acceleration\nperiods, amplitudes, and phases are systematically analyzed. The simulation\nresults are interpreted from three key perspectives: the density gradient,\nwhich characterizes the spatial variation in density; the thermodynamic\nnon-equilibrium strength, which quantifies the system's deviation from local\nthermodynamic equilibrium; and the fraction of non-equilibrium regions, which\ncaptures the spatial distribution of non-equilibrium behaviors. Notably, the\nfluid system exhibits rich and diverse dynamic patterns resulting from the\ninterplay of multiple competing physical mechanisms, including time-dependent\nacceleration, RT instability, diffusion, and dissipation effects. These\nfindings provide deeper insights into the evolution and regulation of\ncompressible RT instability under complex driving conditions.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-07T14:32:33Z"}
{"aid":"http://arxiv.org/abs/2504.05131v1","title":"One-Loop Transverse-Momentum-Dependent Soft Function at Higher Orders in\n  the Dimensional Regulator","summary":"The transverse-momentum-dependent (TMD) soft function for a generic\nhadroproduction process involving massive colored particles is analytically\ncalculated at the one-loop level, extended to higher orders in the dimensional\nregulator $\\epsilon$. We present both the azimuthal-angle-averaged and\nazimuthal-angle-dependent soft functions in impact-parameter space, making them\nsuitable for small $q_T$ resummation calculations. Their analytic expressions\nare provided in terms of multiple polylogarithms. Our results offer essential\ningredients for a complete higher-order perturbative calculation of the TMD\nsoft function.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-07T14:34:31Z"}
{"aid":"http://arxiv.org/abs/2504.05134v1","title":"Partially compactified quantum cluster algebras and coordinate rings of\n  simple algebraic groups","summary":"The construction of partially compactified cluster algebras on coordinate\nrings is handled by using codimension 2 arguments on cluster covers. An analog\nof this in the quantum situation is highly desirable but has not been found\nyet. In this paper, we present a general method for the construction of\npartially compactified quantum cluster algebra structures on quantized\ncoordinate rings from that of quantum cluster algebra structures on\nlocalizations. As an application, we construct a partially compactified quantum\ncluster algebra structure on the quantized coordinate ring of every connected,\nsimply connected complex simple algebraic group. Along the way, we also prove\nthat the Berenstein--Zelevinsky seeds on a quantum double Bruhat cell\nassociated to arbitrary unshuffled signed words can be obtained from each other\nby successive mutations.","main_category":"math.QA","categories":"math.QA,math.RA,math.RT","published":"2025-04-07T14:38:54Z"}
{"aid":"http://arxiv.org/abs/2504.05137v1","title":"BoxSeg: Quality-Aware and Peer-Assisted Learning for Box-supervised\n  Instance Segmentation","summary":"Box-supervised instance segmentation methods aim to achieve instance\nsegmentation with only box annotations. Recent methods have demonstrated the\neffectiveness of acquiring high-quality pseudo masks under the teacher-student\nframework. Building upon this foundation, we propose a BoxSeg framework\ninvolving two novel and general modules named the Quality-Aware Module (QAM)\nand the Peer-assisted Copy-paste (PC). The QAM obtains high-quality pseudo\nmasks and better measures the mask quality to help reduce the effect of noisy\nmasks, by leveraging the quality-aware multi-mask complementation mechanism.\nThe PC imitates Peer-Assisted Learning to further improve the quality of the\nlow-quality masks with the guidance of the obtained high-quality pseudo masks.\nTheoretical and experimental analyses demonstrate the proposed QAM and PC are\neffective. Extensive experimental results show the superiority of our BoxSeg\nover the state-of-the-art methods, and illustrate the QAM and PC can be applied\nto improve other models.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T14:42:33Z"}
{"aid":"http://arxiv.org/abs/2504.05139v1","title":"Violation of local reciprocity in charge-orbital interconversion","summary":"We demonstrate a violation of local reciprocity in the interconversion\nbetween charge and orbital currents. By investigating orbital torque and\norbital pumping in W/Ni bilayers, we show that the charge-orbital\ninterconversion in the bulk of the W layer exhibits opposite signs in the\ndirect and inverse processes -- the direct and inverse orbital Hall effects\nbeing positive and negative, respectively. This finding provides direct\nevidence of local non-reciprocity in the charge-orbital interconversion, in\nagreement with a theoretical prediction. These results highlight the unique\ncharacteristics of charge-orbital coupled transport and offer fundamental\ninsights into the mechanisms underlying orbital-current-driven phenomena.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-07T14:45:31Z"}
{"aid":"http://arxiv.org/abs/2504.05144v1","title":"Online Cluster-Based Parameter Control for Metaheuristic","summary":"The concept of parameter setting is a crucial and significant process in\nmetaheuristics since it can majorly impact their performance. It is a highly\ncomplex and challenging procedure since it requires a deep understanding of the\noptimization algorithm and the optimization problem at hand. In recent years,\nthe upcoming rise of autonomous decision systems has attracted ongoing\nscientific interest in this direction, utilizing a considerable number of\nparameter-tuning methods. There are two types of methods: offline and online.\nOnline methods usually excel in complex real-world problems, as they can offer\ndynamic parameter control throughout the execution of the algorithm. The\npresent work proposes a general-purpose online parameter-tuning method called\nCluster-Based Parameter Adaptation (CPA) for population-based metaheuristics.\nThe main idea lies in the identification of promising areas within the\nparameter search space and in the generation of new parameters around these\nareas. The method's validity has been demonstrated using the differential\nevolution algorithm and verified in established test suites of low- and\nhigh-dimensional problems. The obtained results are statistically analyzed and\ncompared with state-of-the-art algorithms, including advanced auto-tuning\napproaches. The analysis reveals the promising solid CPA's performance as well\nas its robustness under a variety of benchmark problems and dimensions.","main_category":"math.OC","categories":"math.OC,cs.LG","published":"2025-04-07T14:48:30Z"}
{"aid":"http://arxiv.org/abs/2504.05148v1","title":"Stereo-LiDAR Fusion by Semi-Global Matching With Discrete\n  Disparity-Matching Cost and Semidensification","summary":"We present a real-time, non-learning depth estimation method that fuses Light\nDetection and Ranging (LiDAR) data with stereo camera input. Our approach\ncomprises three key techniques: Semi-Global Matching (SGM) stereo with Discrete\nDisparity-matching Cost (DDC), semidensification of LiDAR disparity, and a\nconsistency check that combines stereo images and LiDAR data. Each of these\ncomponents is designed for parallelization on a GPU to realize real-time\nperformance. When it was evaluated on the KITTI dataset, the proposed method\nachieved an error rate of 2.79\\%, outperforming the previous state-of-the-art\nreal-time stereo-LiDAR fusion method, which had an error rate of 3.05\\%.\nFurthermore, we tested the proposed method in various scenarios, including\ndifferent LiDAR point densities, varying weather conditions, and indoor\nenvironments, to demonstrate its high adaptability. We believe that the\nreal-time and non-learning nature of our method makes it highly practical for\napplications in robotics and automation.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-07T14:54:08Z"}
{"aid":"http://arxiv.org/abs/2504.05149v1","title":"Fast Convolutions on $\\mathbb{Z}^2\\backslash SE(2)$ via Radial\n  Translational Dependence and Classical FFT","summary":"Let $\\mathbb{Z}^2\\backslash SE(2)$ denote the right coset space of the\nsubgroup consisting of translational isometries of the orthogonal lattice\n$\\mathbb{Z}^2$ in the non-Abelian group of planar motions $SE(2)$. This paper\ndevelops a fast and accurate numerical scheme for approximation of functions on\n$\\mathbb{Z}^2\\backslash SE(2)$. We address finite Fourier series of functions\non the right coset space $\\mathbb{Z}^2\\backslash SE(2)$ using finite Fourier\ncoefficients. The convergence/error analysis of finite Fourier coefficients are\ninvestigated. Conditions are established for the finite Fourier coefficients to\nconverge to the Fourier coefficients. The matrix forms of the finite transforms\nare discussed. The implementation of the discrete method to compute numerical\napproximation of $SE(2)$-convolutions with functions which are radial in\ntranslations are considered. The paper is concluded by discussing capability of\nthe numerical scheme to develop fast algorithms for approximating multiple\nconvolutions with functions with are radial in translations.","main_category":"math.NA","categories":"math.NA,cs.NA,math.FA,math.GR","published":"2025-04-07T14:56:32Z"}
{"aid":"http://arxiv.org/abs/2504.05158v1","title":"Leveraging Label Potential for Enhanced Multimodal Emotion Recognition","summary":"Multimodal emotion recognition (MER) seeks to integrate various modalities to\npredict emotional states accurately. However, most current research focuses\nsolely on the fusion of audio and text features, overlooking the valuable\ninformation in emotion labels. This oversight could potentially hinder the\nperformance of existing methods, as emotion labels harbor rich, insightful\ninformation that could significantly aid MER. We introduce a novel model called\nLabel Signal-Guided Multimodal Emotion Recognition (LSGMER) to overcome this\nlimitation. This model aims to fully harness the power of emotion label\ninformation to boost the classification accuracy and stability of MER.\nSpecifically, LSGMER employs a Label Signal Enhancement module that optimizes\nthe representation of modality features by interacting with audio and text\nfeatures through label embeddings, enabling it to capture the nuances of\nemotions precisely. Furthermore, we propose a Joint Objective Optimization(JOO)\napproach to enhance classification accuracy by introducing the\nAttribution-Prediction Consistency Constraint (APC), which strengthens the\nalignment between fused features and emotion categories. Extensive experiments\nconducted on the IEMOCAP and MELD datasets have demonstrated the effectiveness\nof our proposed LSGMER model.","main_category":"cs.SD","categories":"cs.SD,cs.AI,eess.AS","published":"2025-04-07T15:00:34Z"}
{"aid":"http://arxiv.org/abs/2504.05159v1","title":"A Fast Multiplication Algorithm and RLWE-PLWE Equivalence for the\n  Maximal Real Subfield of the $2^r p^s$-th Cyclotomic Field","summary":"This paper proves the RLWE-PLWE equivalence for the maximal real subfields of\nthe cyclotomic fields with conductor $n = 2^r p^s$, where $p$ is an odd prime,\nand $r \\geq 0$ and $s \\geq 1$ are integers. In particular, we show that the\ncanonical embedding as a linear transform has a condition number bounded above\nby a polynomial in $n$. In addition, we describe a fast multiplication\nalgorithm in the ring of integers of these real subfields. The multiplication\nalgorithm uses the fast Discrete Cosine Transform (DCT) and has computational\ncomplexity $\\mathcal{O}(n \\log n)$. Both the proof of the RLWE-PLWE equivalence\nand the fast multiplication algorithm are generalizations of previous results\nby Ahola et al., where the same claims are proved for a single prime $p = 3$.","main_category":"cs.CR","categories":"cs.CR,math.NT,E.3.3","published":"2025-04-07T15:01:48Z"}
{"aid":"http://arxiv.org/abs/2504.05165v1","title":"Forced oscillations for generalized $Φ$-Laplacian equations with\n  Carathéodory perturbations","summary":"Using topological methods, we study the structure of the set of forced\noscillations of a class of parametric, implicit ordinary differential equations\nwith a generalized $\\Phi$-Laplacian type term. We work in the Carath\\'eodory\nsetting. Under suitable assumptions, involving merely the Brouwer degree in\nEuclidean spaces, we obtain global bifurcation results. In some illustrative\nexamples we provide a visual representation of the bifurcating set.","main_category":"math.CA","categories":"math.CA","published":"2025-04-07T15:10:37Z"}
{"aid":"http://arxiv.org/abs/2504.05168v1","title":"Modeling Micro-Doppler Signature of Multi-Propeller Drones in\n  Distributed ISAC","summary":"Integrated Sensing and Communication (ISAC) will be one key feature of future\n6G networks, enabling simultaneous communication and radar sensing. The radar\nsensing geometry of ISAC will be multistatic since that corresponds to the\ncommon distributed structure of a mobile communication network. Within this\nframework, micro-Doppler analysis plays a vital role in classifying targets\nbased on their micromotions, such as rotating propellers, vibration, or moving\nlimbs. However, research on bistatic micro-Doppler effects, particularly in\nISAC systems utilizing OFDM waveforms, remains limited. Existing methods,\nincluding electromagnetic simulations often lack scalability for generating the\nlarge datasets required to train machine learning algorithms. To address this\ngap, this work introduces an OFDM-based bistatic micro-Doppler model for\nmulti-propeller drones. The proposed model adapts the classic thin-wire model\nto include bistatic sensing configuration with an OFDM-like signal. Then, it\nextends further by incorporating multiple propellers and integrating the\nreflectivity of the drone's static parts. Measurements were performed to\ncollect ground truth data for verification of the proposed model. Validation\nresults show that the model generates micro-Doppler signatures closely\nresembling those obtained from measurements, demonstrating its potential as a\ntool for data generation. In addition, it offers a comprehensive approach to\nanalyzing bistatic micro-Doppler effects.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-07T15:12:24Z"}
{"aid":"http://arxiv.org/abs/2504.05170v1","title":"SSLFusion: Scale & Space Aligned Latent Fusion Model for Multimodal 3D\n  Object Detection","summary":"Multimodal 3D object detection based on deep neural networks has indeed made\nsignificant progress. However, it still faces challenges due to the\nmisalignment of scale and spatial information between features extracted from\n2D images and those derived from 3D point clouds. Existing methods usually\naggregate multimodal features at a single stage. However, leveraging\nmulti-stage cross-modal features is crucial for detecting objects of various\nscales. Therefore, these methods often struggle to integrate features across\ndifferent scales and modalities effectively, thereby restricting the accuracy\nof detection. Additionally, the time-consuming Query-Key-Value-based\n(QKV-based) cross-attention operations often utilized in existing methods aid\nin reasoning the location and existence of objects by capturing non-local\ncontexts. However, this approach tends to increase computational complexity. To\naddress these challenges, we present SSLFusion, a novel Scale & Space Aligned\nLatent Fusion Model, consisting of a scale-aligned fusion strategy (SAF), a\n3D-to-2D space alignment module (SAM), and a latent cross-modal fusion module\n(LFM). SAF mitigates scale misalignment between modalities by aggregating\nfeatures from both images and point clouds across multiple levels. SAM is\ndesigned to reduce the inter-modal gap between features from images and point\nclouds by incorporating 3D coordinate information into 2D image features.\nAdditionally, LFM captures cross-modal non-local contexts in the latent space\nwithout utilizing the QKV-based attention operations, thus mitigating\ncomputational complexity. Experiments on the KITTI and DENSE datasets\ndemonstrate that our SSLFusion outperforms state-of-the-art methods. Our\napproach obtains an absolute gain of 2.15% in 3D AP, compared with the\nstate-of-art method GraphAlign on the moderate level of the KITTI test set.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T15:15:06Z"}
{"aid":"http://arxiv.org/abs/2504.05171v1","title":"A hydro-geomechanical porous-media model to study effects of engineered\n  carbonate precipitation in faults","summary":"Hydro-geomechanical models are required to predict or understand the impact\nof subsurface engineering applications as, for example, in gas storage in\ngeological formations. This study puts a focus on engineered carbonate\nprecipitation through biomineralization in a fault zone of a cap-rock to reduce\ngas leakage from a reservoir. Besides hydraulic properties like porosity and\npermeability, precipitated carbonates also change the mechanical properties of\nthe rock. We present a conceptual modeling approach implemented into the\nopen-source simulator Dumux and, after verification examples, at hand of a\nCO2-storage scenario, we discuss impacts of biomineralization on the stress\ndistribution in the rock and potentially altered risks of fault reactivations\nand induced seismic events.\n  The generic study shows the tendency towards increased stiffness due to\nprecipitated carbonate, which may cause shear failure events to occur earlier\nthan in an untreated setup, while the magnitude of the seismicity is smaller.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-07T15:15:12Z"}
{"aid":"http://arxiv.org/abs/2504.05175v1","title":"Semiflows on finite topological spaces","summary":"In this paper, we study flows and semiflows defined on any given finite\ntopological $T_0$-space $X$. We show that there exist non-trivial semiflows on\n$X$, unless $X$ is a minimal finite space. Specifically, non-trivial semiflows\nexist if and only if $X$ contains down beat points, and a non-trivial semiflow\nis essentially a strong deformation retraction. As a consequence of this\nresult, we provide a new and concise proof that the only flow that can be\ndefined on $X$ is the trivial flow. Finally, we discuss the number of different\nsemiflows that can be defined on $X$ in terms of down beat points and other\nspecial points.","main_category":"math.GN","categories":"math.GN","published":"2025-04-07T15:19:16Z"}
{"aid":"http://arxiv.org/abs/2504.05178v1","title":"The 1st Solution for 4th PVUW MeViS Challenge: Unleashing the Potential\n  of Large Multimodal Models for Referring Video Segmentation","summary":"Motion expression video segmentation is designed to segment objects in\naccordance with the input motion expressions. In contrast to the conventional\nReferring Video Object Segmentation (RVOS), it places emphasis on motion as\nwell as multi-object expressions, making it more arduous. Recently, Large\nMultimodal Models (LMMs) have begun to shine in RVOS due to their powerful\nvision-language perception capabilities. In this work, we propose a simple and\neffective inference optimization method to fully unleash the potential of LMMs\nin referring video segmentation. Firstly, we use Sa2VA as our baseline, which\nis a unified LMM for dense grounded understanding of both images and videos.\nSecondly, we uniformly sample the video frames during the inference process to\nenhance the model's understanding of the entire video. Finally, we integrate\nthe results of multiple expert models to mitigate the erroneous predictions of\na single model. Our solution achieved 61.98% J&F on the MeViS test set and\nranked 1st place in the 4th PVUW Challenge MeViS Track at CVPR 2025.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T15:24:54Z"}
{"aid":"http://arxiv.org/abs/2504.05196v1","title":"Universal Lymph Node Detection in Multiparametric MRI with Selective\n  Augmentation","summary":"Robust localization of lymph nodes (LNs) in multiparametric MRI (mpMRI) is\ncritical for the assessment of lymphadenopathy. Radiologists routinely measure\nthe size of LN to distinguish benign from malignant nodes, which would require\nsubsequent cancer staging. Sizing is a cumbersome task compounded by the\ndiverse appearances of LNs in mpMRI, which renders their measurement difficult.\nFurthermore, smaller and potentially metastatic LNs could be missed during a\nbusy clinical day. To alleviate these imaging and workflow problems, we propose\na pipeline to universally detect both benign and metastatic nodes in the body\nfor their ensuing measurement. The recently proposed VFNet neural network was\nemployed to identify LN in T2 fat suppressed and diffusion weighted imaging\n(DWI) sequences acquired by various scanners with a variety of exam protocols.\nWe also use a selective augmentation technique known as Intra-Label LISA (ILL)\nto diversify the input data samples the model sees during training, such that\nit improves its robustness during the evaluation phase. We achieved a\nsensitivity of $\\sim$83\\% with ILL vs. $\\sim$80\\% without ILL at 4 FP/vol.\nCompared with current LN detection approaches evaluated on mpMRI, we show a\nsensitivity improvement of $\\sim$9\\% at 4 FP/vol.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-07T15:46:43Z"}
{"aid":"http://arxiv.org/abs/2504.05206v1","title":"Content-aware rankings: a new approach to rankings in scholarship","summary":"Entity rankings (e.g., institutions, journals) are a core component of\nacademia and related industries. Existing approaches to institutional rankings\nhave relied on a variety of data sources, and approaches to computing outcomes,\nbut remain controversial. One limitation of existing approaches is reliance on\nscholarly output (e.g., number of publications associated with a given\ninstitution during a time period). We propose a new approach to rankings - one\nthat relies not on scholarly output, but rather on the type of citations\nreceived (an implementation of the Scite Index). We describe how the necessary\ndata can be gathered, as well as how relevant metrics are computed. To\ndemonstrate the utility of our approach, we present rankings of fields,\njournals, and institutions, and discuss the various ways Scite's data can be\ndeployed in the context of rankings. Implications, limitations, and future\ndirections are discussed.","main_category":"cs.DL","categories":"cs.DL","published":"2025-04-07T15:55:18Z"}
{"aid":"http://arxiv.org/abs/2504.05207v1","title":"Correcting Class Imbalances with Self-Training for Improved Universal\n  Lesion Detection and Tagging","summary":"Universal lesion detection and tagging (ULDT) in CT studies is critical for\ntumor burden assessment and tracking the progression of lesion status\n(growth/shrinkage) over time. However, a lack of fully annotated data hinders\nthe development of effective ULDT approaches. Prior work used the DeepLesion\ndataset (4,427 patients, 10,594 studies, 32,120 CT slices, 32,735 lesions, 8\nbody part labels) for algorithmic development, but this dataset is not\ncompletely annotated and contains class imbalances. To address these issues, in\nthis work, we developed a self-training pipeline for ULDT. A VFNet model was\ntrained on a limited 11.5\\% subset of DeepLesion (bounding boxes + tags) to\ndetect and classify lesions in CT studies. Then, it identified and incorporated\nnovel lesion candidates from a larger unseen data subset into its training set,\nand self-trained itself over multiple rounds. Multiple self-training\nexperiments were conducted with different threshold policies to select\npredicted lesions with higher quality and cover the class imbalances. We\ndiscovered that direct self-training improved the sensitivities of\nover-represented lesion classes at the expense of under-represented classes.\nHowever, upsampling the lesions mined during self-training along with a\nvariable threshold policy yielded a 6.5\\% increase in sensitivity at 4 FP in\ncontrast to self-training without class balancing (72\\% vs 78.5\\%) and a 11.7\\%\nincrease compared to the same self-training policy without upsampling (66.8\\%\nvs 78.5\\%). Furthermore, we show that our results either improved or maintained\nthe sensitivity at 4FP for all 8 lesion classes.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T15:57:03Z"}
{"aid":"http://arxiv.org/abs/2504.05221v1","title":"Apparent fractional charge signatures in PbTe quantum dots due to\n  capacitively coupled charge trap dynamics","summary":"We report the observation of fractional shifts in the experimental stability\ndiagrams of PbTe nanowire quantum dots. Although this behavior may appear to\nsuggest fractional charge transport, akin to that reported in the fractional\nquantum Hall regime, the quasi-one-dimensionality of the system and absence of\nan applied magnetic field indicate that the presence of fractional charges is\nhighly unlikely. We instead attribute these effects to the presence of one or\nmore spurious dots, or charge traps, capacitively coupled to the primary dot.\nOur findings illustrate how signatures of fractional charge transport may be\nreplicated through trivial mesoscopic Coulombic effects.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-07T16:08:20Z"}
{"aid":"http://arxiv.org/abs/2504.05232v1","title":"Discovery of the 7-ring PAH Cyanocoronene (C$_{24}$H$_{11}$CN) in GOTHAM\n  Observations of TMC-1","summary":"We present the synthesis and laboratory rotational spectroscopy of the 7-ring\npolycyclic aromatic hydrocarbon (PAH) cyanocoronene (C$_{24}$H$_{11}$CN) using\na laser-ablation assisted cavity-enhanced Fourier transform microwave\nspectrometer. A total of 71 transitions were measured and assigned between\n6.8--10.6\\,GHz. Using these assignments, we searched for emission from\ncyanocoronene in the GBT Observations of TMC-1: Hunting Aromatic Molecules\n(GOTHAM) project observations of the cold dark molecular cloud TMC-1 using the\n100\\,m Green Bank Telescope (GBT). We detect a number of individually resolved\ntransitions in ultrasensitive X-band observations and perform a Markov Chain\nMonte Carlo analysis to derive best-fit parameters, including a total column\ndensity of $N(\\mathrm{C}_{24}\\mathrm{H}_{11}\\mathrm{CN}) = 2.69^{+0.26}_{-0.23}\n\\times 10^{12}\\,\\mathrm{cm}^{-2}$ at a temperature of\n$6.05^{+0.38}_{-0.37}\\,$K. A spectral stacking and matched filtering analysis\nprovides a robust 17.3$\\,\\sigma$ significance to the overall detection. The\nderived column density is comparable to that of cyano-substituted naphthalene,\nacenaphthylene, and pyrene, defying the trend of decreasing abundance with\nincreasing molecular size and complexity found for carbon chains. We discuss\nthe implications of the detection for our understanding of interstellar PAH\nchemistry and highlight major open questions and next steps.","main_category":"astro-ph.GA","categories":"astro-ph.GA,physics.chem-ph","published":"2025-04-07T16:15:54Z"}
{"aid":"http://arxiv.org/abs/2504.05241v1","title":"Chiral magnetic excitations and domain textures of $g$-wave altermagnets","summary":"Altermagnets (AMs) constitute a novel class of spin-compensated materials in\nwhich opposite-spin sublattices are connected by a crystal rotation, causing\ntheir electronic iso-energy surfaces to be spin-split. While cubic and\ntetragonal crystal symmetries tend to produce AMs in which the splitting of\nelectronic iso-energy surfaces has $d$-wave symmetry, hexagonal AMs, such as\nCrSb and MnTe, are $g$-wave AMs. Here we investigate the purely magnetic modes\nand spin-textures of $g$-wave AMs and show that they are drastically different\nfor easy-axial (CrSb) and easy-planar (MnTe) materials. We show that in CrSb\nthe splitting of the chiral magnon branches possesses $g$-wave symmetry, with\neach branch carrying a fixed momentum-independent magnetic moment. The\naltermagnetic splitting is not affected by the easy-axial anisotropy and is the\nsame as that in the nonrelativistic limit. The magnon splitting of MnTe,\nhowever, does not strictly possess $g$-wave symmetry due to its easy-planar\nanisotropy. Instead the magnetic moment of each branch becomes\nmomentum-dependent, with a distribution that is of $g$-wave symmetry. To\ngeneralize the concept of the altermagnetic splitting beyond the\nnonrelativistic limit, we introduce alternative, directly observable splitting\nparameter which comprises both the magnon eigenenergy and its magnetic moment\nand possesses the $g$-wave symmetry in both easy-axial and easy-planar cases.\nThe associated altermagnetic domain walls in easy-axial CrSb possess a net\nmagnetization with an amplitude that depends on their orientation.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-07T16:25:54Z"}
{"aid":"http://arxiv.org/abs/2504.05249v1","title":"Texture2LoD3: Enabling LoD3 Building Reconstruction With Panoramic\n  Images","summary":"Despite recent advancements in surface reconstruction, Level of Detail (LoD)\n3 building reconstruction remains an unresolved challenge. The main issue\npertains to the object-oriented modelling paradigm, which requires\ngeoreferencing, watertight geometry, facade semantics, and low-poly\nrepresentation -- Contrasting unstructured mesh-oriented models. In\nTexture2LoD3, we introduce a novel method leveraging the ubiquity of 3D\nbuilding model priors and panoramic street-level images, enabling the\nreconstruction of LoD3 building models. We observe that prior low-detail\nbuilding models can serve as valid planar targets for ortho-rectifying\nstreet-level panoramic images. Moreover, deploying segmentation on accurately\ntextured low-level building surfaces supports maintaining essential\ngeoreferencing, watertight geometry, and low-poly representation for LoD3\nreconstruction. In the absence of LoD3 validation data, we additionally\nintroduce the ReLoD3 dataset, on which we experimentally demonstrate that our\nmethod leads to improved facade segmentation accuracy by 11% and can replace\ncostly manual projections. We believe that Texture2LoD3 can scale the adoption\nof LoD3 models, opening applications in estimating building solar potential or\nenhancing autonomous driving simulations. The project website, code, and data\nare available here: https://wenzhaotang.github.io/Texture2LoD3/.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-07T16:40:16Z"}
{"aid":"http://arxiv.org/abs/2504.05255v1","title":"Adversarial KA","summary":"Regarding the representation theorem of Kolmogorov and Arnold (KA) as an\nalgorithm for representing or {\\guillemotleft}expressing{\\guillemotright}\nfunctions, we test its robustness by analyzing its ability to withstand\nadversarial attacks. We find KA to be robust to countable collections of\ncontinuous adversaries, but unearth a question about the equi-continuity of the\nouter functions that, so far, obstructs taking limits and defeating continuous\ngroups of adversaries. This question on the regularity of the outer functions\nis relevant to the debate over the applicability of KA to the general theory of\nNNs.","main_category":"cs.LG","categories":"cs.LG,cs.AI,math.FA","published":"2025-04-07T16:46:52Z"}
{"aid":"http://arxiv.org/abs/2504.05258v1","title":"Learning to Reason Over Time: Timeline Self-Reflection for Improved\n  Temporal Reasoning in Language Models","summary":"Large Language Models (LLMs) have emerged as powerful tools for generating\ncoherent text, understanding context, and performing reasoning tasks. However,\nthey struggle with temporal reasoning, which requires processing time-related\ninformation such as event sequencing, durations, and inter-temporal\nrelationships. These capabilities are critical for applications including\nquestion answering, scheduling, and historical analysis. In this paper, we\nintroduce TISER, a novel framework that enhances the temporal reasoning\nabilities of LLMs through a multi-stage process that combines timeline\nconstruction with iterative self-reflection. Our approach leverages test-time\nscaling to extend the length of reasoning traces, enabling models to capture\ncomplex temporal dependencies more effectively. This strategy not only boosts\nreasoning accuracy but also improves the traceability of the inference process.\nExperimental results demonstrate state-of-the-art performance across multiple\nbenchmarks, including out-of-distribution test sets, and reveal that TISER\nenables smaller open-source models to surpass larger closed-weight models on\nchallenging temporal reasoning tasks.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-07T16:51:45Z"}
{"aid":"http://arxiv.org/abs/2504.05269v1","title":"A model-based analysis of the AggregateEU mechanism: Implications of\n  overbidding and non-commitment","summary":"AggregateEU is a new centralised mechanism that provides a no-commitment\nplatform to trade natural gas in the European Union. Throughout the\nconsultation process, AggregateEU has been mocked as `Tinder of the European\ngas markets' as it helps consumers and suppliers to find partners, but leaves\nit up to the matched partners to decide whether or not to contract on the\npossible trade. The non-commitment nature leads to substantial overbidding and\nmany non-realised matches.\n  We propose a quantitative modelling framework to study the effect of\noverbidding in the AggergateEU demand aggregation or joint purchasing\nmechanism. We conclude that the mechanism is prone to overbidding and that\noverbidding has ambiguous effects on trade. Depending on the parameters,\noverbidding may facilitate trade, but may also result in highly inefficient\noutcomes when overbidding is combined with a miscoordination over the delivery\npoints.\n  Suggested remedies include allowing for convex bids, restrictions on\noverbidding, or giving up part of the non-binding character of the market.\n%Ideally, the traditional mechanisms of gas exchanges should be augmented by\nfeatures of AggregateEU. Our results sugge","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-07T17:06:17Z"}
{"aid":"http://arxiv.org/abs/2504.05276v1","title":"Enhancing LLM-Based Short Answer Grading with Retrieval-Augmented\n  Generation","summary":"Short answer assessment is a vital component of science education, allowing\nevaluation of students' complex three-dimensional understanding. Large language\nmodels (LLMs) that possess human-like ability in linguistic tasks are\nincreasingly popular in assisting human graders to reduce their workload.\nHowever, LLMs' limitations in domain knowledge restrict their understanding in\ntask-specific requirements and hinder their ability to achieve satisfactory\nperformance. Retrieval-augmented generation (RAG) emerges as a promising\nsolution by enabling LLMs to access relevant domain-specific knowledge during\nassessment. In this work, we propose an adaptive RAG framework for automated\ngrading that dynamically retrieves and incorporates domain-specific knowledge\nbased on the question and student answer context. Our approach combines\nsemantic search and curated educational sources to retrieve valuable reference\nmaterials. Experimental results in a science education dataset demonstrate that\nour system achieves an improvement in grading accuracy compared to baseline LLM\napproaches. The findings suggest that RAG-enhanced grading systems can serve as\nreliable support with efficient performance gains.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T17:17:41Z"}
{"aid":"http://arxiv.org/abs/2504.05285v1","title":"Hopf tori and standard tori","summary":"This article provides a complete characterization of the conformal classes of\nproduct tori and standard flat tori in complex dimension 1 (real dimension 2).\nUtilizing basic differential geometry methods, our approach contrasts with\ntechniques employing Hopf tori for the conformal classification of Riemann\nsurfaces of genus 1. While the results may be familiar to experts in complex\nanalysis and Riemann surface theory, we contend that this work offers a clear\nand insightful perspective on the conformal properties of these geometrically\ndistinct appearing tori.","main_category":"math.DG","categories":"math.DG","published":"2025-04-07T17:35:14Z"}
{"aid":"http://arxiv.org/abs/2504.05286v1","title":"UK APAP R-matrix electron-impact excitation cross-sections for modelling\n  laboratory and astrophysical plasma","summary":"Systematic R-matrix calculations of electron-impact excitation for ions of\nastrophysical interest have been performed since 2007 for many iso-electronic\nsequences as part of the UK Atomic Process for Astrophysical Plasma (APAP)\nnetwork. Rate coefficients for Maxwellian electron distributions have been\nprovided and used extensively in the literature and many databases for\nastrophysics. Here, we provide averaged collision strengths to be used to model\nplasma where electrons are non-Maxwellian, which often occur in laboratory and\nastrophysical plasma. We also provide for many ions new Maxwellian-averaged\ncollision strengths which include important corrections to the published\nvalues. The H- and He-like atomic data were recently made available in\nMao+(2022). Here, we provide data for ions of the Li-, Be-, B-, C-, N-, O-,\nNe-, Na-, and Mg-like sequences.","main_category":"physics.atom-ph","categories":"physics.atom-ph,astro-ph.IM,astro-ph.SR","published":"2025-04-07T17:37:09Z"}
{"aid":"http://arxiv.org/abs/2504.05627v1","title":"Maternal and Fetal Health Status Assessment by Using Machine Learning on\n  Optical 3D Body Scans","summary":"Monitoring maternal and fetal health during pregnancy is crucial for\npreventing adverse outcomes. While tests such as ultrasound scans offer high\naccuracy, they can be costly and inconvenient. Telehealth and more accessible\nbody shape information provide pregnant women with a convenient way to monitor\ntheir health. This study explores the potential of 3D body scan data, captured\nduring the 18-24 gestational weeks, to predict adverse pregnancy outcomes and\nestimate clinical parameters. We developed a novel algorithm with two parallel\nstreams which are used for extract body shape features: one for supervised\nlearning to extract sequential abdominal circumference information, and another\nfor unsupervised learning to extract global shape descriptors, alongside a\nbranch for demographic data.\n  Our results indicate that 3D body shape can assist in predicting preterm\nlabor, gestational diabetes mellitus (GDM), gestational hypertension (GH), and\nin estimating fetal weight. Compared to other machine learning models, our\nalgorithm achieved the best performance, with prediction accuracies exceeding\n88% and fetal weight estimation accuracy of 76.74% within a 10% error margin,\noutperforming conventional anthropometric methods by 22.22%.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-08T03:02:26Z"}
{"aid":"http://arxiv.org/abs/2504.05630v1","title":"A new discrimination measure for assessing predictive performance of\n  non-linear survival models","summary":"Non-linear survival models are flexible models in which the proportional\nhazard assumption is not required. This poses difficulties in their evaluation.\nWe introduce a new discrimination measure, time-dependent Uno's C-index, to\nassess the discrimination performance of non-linear survival models. This is an\nunbiased version of Antolini's time-dependent concordance. We prove convergence\nof both measures employing Nolan and Pollard's results on U-statistics. We\nexplore the relationship between these measures and, in particular, the bias of\nAntolini's concordance in the presence of censoring using simulated data. We\ndemonstrate the value of time-dependent Uno's C-index for the evaluation of\nmodels trained on censored real data and for model tuning.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-08T03:11:43Z"}
{"aid":"http://arxiv.org/abs/2504.05631v1","title":"Distributed Solving of Linear Quadratic Optimal Controller with Terminal\n  State Constraint","summary":"This paper is concerned with the linear quadratic (LQ) optimal control of\ncontinuous-time system with terminal state constraint. In particular, multiple\nagents exist in the system which can only access partial information of the\nmatrix parameters. This makes the classical solving method based on Riccati\nequation with global information suffering. The main contribution is to present\na distributed algorithm to derive the optimal controller which is consisting of\nthe distributed iterations for the Riccati equation, a backward differential\nequation driven by the optimal Lagrange multiplier and the optimal state.\nFinally, a numerical example verifies the effectiveness of the proposed\nalgorithm.","main_category":"math.OC","categories":"math.OC","published":"2025-04-08T03:19:16Z"}
{"aid":"http://arxiv.org/abs/2504.05634v1","title":"Simplifying Data Integration: SLM-Driven Systems for Unified Semantic\n  Queries Across Heterogeneous Databases","summary":"The integration of heterogeneous databases into a unified querying framework\nremains a critical challenge, particularly in resource-constrained\nenvironments. This paper presents a novel Small Language Model(SLM)-driven\nsystem that synergizes advancements in lightweight Retrieval-Augmented\nGeneration (RAG) and semantic-aware data structuring to enable efficient,\naccurate, and scalable query resolution across diverse data formats. By\nintegrating MiniRAG's semantic-aware heterogeneous graph indexing and\ntopology-enhanced retrieval with SLM-powered structured data extraction, our\nsystem addresses the limitations of traditional methods in handling\nMulti-Entity Question Answering (Multi-Entity QA) and complex semantic queries.\nExperimental results demonstrate superior performance in accuracy and\nefficiency, while the introduction of semantic entropy as an unsupervised\nevaluation metric provides robust insights into model uncertainty. This work\npioneers a cost-effective, domain-agnostic solution for next-generation\ndatabase systems.","main_category":"cs.DB","categories":"cs.DB,cs.IR","published":"2025-04-08T03:28:03Z"}
{"aid":"http://arxiv.org/abs/2504.05645v1","title":"A Study of Multiple Molecular Lines at the 3 mm Band toward Gas\n  Infalling Sources","summary":"The study of multiple molecular spectral lines in gas infalling sources can\nprovide the physical and chemical properties of these sources and help us\nestimate their evolutionary stages. We report line detections within the 3 mm\nband using the FTS wide-sideband mode of the IRAM 30 m telescope toward 20\ngas-infalling sources. Using XCLASS, we identify the emission lines of up to 22\nmolecular species (including a few isotopologues) and one hydrogen radio\nrecombination line in these sources. H$^{13}$CO$^+$, HCO$^+$, HCN, HNC,\nc-C$_3$H$_2$, and CCH lines are detected in 15 sources. We estimate the\nrotation temperatures and column densities of these molecular species using the\nLTE radiative transfer model, and compare the molecular abundances of these\nsources with those from nine high-mass star-forming regions reported in\nprevious studies and with those from the chemical model. Our results suggest\nthat G012.79-0.20, G012.87-0.22 clump A and B, and G012.96-0.23 clump A may be\nin the high-mass protostellar object stage, while sources with fewer detected\nspecies may be in the earlier evolutionary stage. Additionally, the CCH and\nc-C$_3$H$_2$ column densities in our sources reveal a linear correlation, with\na ratio of N(CCH)/N(c-C$_3$H$_2$) = 89.2$\\pm$5.6, which is higher than the\nratios reported in the literature. When considering only sources with lower\ncolumn densities, this ratio decreases to 29.0$\\pm$6.1, consistent with those\nof diffuse clouds. Furthermore, a comparison between the N(CCH)/N(c-C$_3$H$_2$)\nratio and the sources' physical parameters reveals a correlation, with sources\nexhibiting higher ratios tending to have higher kinetic temperatures and H$_2$\ncolumn densities.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-08T03:40:53Z"}
{"aid":"http://arxiv.org/abs/2504.05648v1","title":"The stochastic Navier-Stokes equations with general $L^{3}$ data","summary":"We consider the stochastic Navier-Stokes equations with multiplicative noise\nwith critical initial data. Assuming that the initial data $u_0$ belongs to the\ncritical space $L^{3}$ almost surely, we construct a unique local-in-time\nprobabilistically strong solution. We also prove an analogous result for data\nin the critical space~$H^\\frac{1}{2}$.","main_category":"math.PR","categories":"math.PR,math.AP","published":"2025-04-08T03:52:54Z"}
{"aid":"http://arxiv.org/abs/2504.05656v1","title":"Anti-pre-Novikov algebras and anti-pre-Novikov bialgebras","summary":"Firstly, we introduce the notion of anti-pre-Novikov algebras as a new\napproach of splitting the Novikov algebras. The notions of anti-O-operators on\nNovikov algebras are developed to interpret anti-pre-Novikov algebras.\nSecondly, we introduce the notion of anti-pre-Novikov bialgebras as the\nbialgebra structures corresponding to a double constructions of symmetric\nquasi-Frobenius Novikov algebras, which are interpreted in terms of certain\nmatched pairs of Novikov algebras as well as the compatible anti-pre-Novikov\nalgebras. The study of coboundary cases leads to the introduction of the the\nanti-pre-Novikov Yang-Baxter equation (APN-YBE), whose skew-symmetric solutions\ngive coboundary anti-pre-Novikov bialgebras. The notion of O-operators on\nanti-pre-Novikov algebras is studied to construct skew-symmetric solutions of\nthe APN-YBE.","main_category":"math.RA","categories":"math.RA,math.QA","published":"2025-04-08T04:10:38Z"}
{"aid":"http://arxiv.org/abs/2504.05668v1","title":"A Message-Passing Perspective on Ptychographic Phase Retrieval","summary":"We introduce a probabilistic approach to ptychographic reconstruction in\ncomputational imaging. Ptychography is an imaging method where the complex\namplitude of an object is estimated from a sequence of diffraction\nmeasurements. We formulate this reconstruction as a Bayesian inverse problem\nand derive an inference algorithm, termed \"Ptycho-EP,\" based on belief\npropagation and Vector Approximate Message Passing from information theory.\nPrior knowledge about the unknown object can be integrated into the\nprobabilistic model, and the Bayesian framework inherently provides uncertainty\nquantification of the reconstruction. Numerical experiments demonstrate that,\nwhen the probe's illumination function is known, our algorithm accurately\nretrieves the object image at a sampling ratio approaching the information\ntheoretic limit. In scenarios where the illumination function is unknown, both\nthe object and the probe can be jointly reconstructed via an\nExpectation-Maximization algorithm. We evaluate the performance of our\nalgorithm against conventional methods, highlighting its superior convergence\nspeed.","main_category":"stat.AP","categories":"stat.AP,physics.optics","published":"2025-04-08T04:27:32Z"}
{"aid":"http://arxiv.org/abs/2504.05672v1","title":"Contrastive Decoupled Representation Learning and Regularization for\n  Speech-Preserving Facial Expression Manipulation","summary":"Speech-preserving facial expression manipulation (SPFEM) aims to modify a\ntalking head to display a specific reference emotion while preserving the mouth\nanimation of source spoken contents. Thus, emotion and content information\nexisting in reference and source inputs can provide direct and accurate\nsupervision signals for SPFEM models. However, the intrinsic intertwining of\nthese elements during the talking process poses challenges to their\neffectiveness as supervisory signals. In this work, we propose to learn content\nand emotion priors as guidance augmented with contrastive learning to learn\ndecoupled content and emotion representation via an innovative Contrastive\nDecoupled Representation Learning (CDRL) algorithm. Specifically, a Contrastive\nContent Representation Learning (CCRL) module is designed to learn audio\nfeature, which primarily contains content information, as content priors to\nguide learning content representation from the source input. Meanwhile, a\nContrastive Emotion Representation Learning (CERL) module is proposed to make\nuse of a pre-trained visual-language model to learn emotion prior, which is\nthen used to guide learning emotion representation from the reference input. We\nfurther introduce emotion-aware and emotion-augmented contrastive learning to\ntrain CCRL and CERL modules, respectively, ensuring learning\nemotion-independent content representation and content-independent emotion\nrepresentation. During SPFEM model training, the decoupled content and emotion\nrepresentations are used to supervise the generation process, ensuring more\naccurate emotion manipulation together with audio-lip synchronization.\nExtensive experiments and evaluations on various benchmarks show the\neffectiveness of the proposed algorithm.","main_category":"cs.CV","categories":"cs.CV,cs.SD","published":"2025-04-08T04:34:38Z"}
{"aid":"http://arxiv.org/abs/2504.05694v1","title":"Large Language Models Enhanced Hyperbolic Space Recommender Systems","summary":"Large Language Models (LLMs) have attracted significant attention in\nrecommender systems for their excellent world knowledge capabilities. However,\nexisting methods that rely on Euclidean space struggle to capture the rich\nhierarchical information inherent in textual and semantic data, which is\nessential for capturing user preferences. The geometric properties of\nhyperbolic space offer a promising solution to address this issue.\nNevertheless, integrating LLMs-based methods with hyperbolic space to\neffectively extract and incorporate diverse hierarchical information is\nnon-trivial. To this end, we propose a model-agnostic framework, named\nHyperLLM, which extracts and integrates hierarchical information from both\nstructural and semantic perspectives. Structurally, HyperLLM uses LLMs to\ngenerate multi-level classification tags with hierarchical parent-child\nrelationships for each item. Then, tag-item and user-item interactions are\njointly learned and aligned through contrastive learning, thereby providing the\nmodel with clear hierarchical information. Semantically, HyperLLM introduces a\nnovel meta-optimized strategy to extract hierarchical information from semantic\nembeddings and bridge the gap between the semantic and collaborative spaces for\nseamless integration. Extensive experiments show that HyperLLM significantly\noutperforms recommender systems based on hyperbolic space and LLMs, achieving\nperformance improvements of over 40%. Furthermore, HyperLLM not only improves\nrecommender performance but also enhances training stability, highlighting the\ncritical role of hierarchical information in recommender systems.","main_category":"cs.IR","categories":"cs.IR,cs.AI","published":"2025-04-08T05:35:38Z"}
{"aid":"http://arxiv.org/abs/2504.05697v1","title":"VADIS: A Visual Analytics Pipeline for Dynamic Document Representation\n  and Information-Seeking","summary":"In the biomedical domain, visualizing the document embeddings of an extensive\ncorpus has been widely used in information-seeking tasks. However, three key\nchallenges with existing visualizations make it difficult for clinicians to\nfind information efficiently. First, the document embeddings used in these\nvisualizations are generated statically by pretrained language models, which\ncannot adapt to the user's evolving interest. Second, existing document\nvisualization techniques cannot effectively display how the documents are\nrelevant to users' interest, making it difficult for users to identify the most\npertinent information. Third, existing embedding generation and visualization\nprocesses suffer from a lack of interpretability, making it difficult to\nunderstand, trust and use the result for decision-making. In this paper, we\npresent a novel visual analytics pipeline for user driven document\nrepresentation and iterative information seeking (VADIS). VADIS introduces a\nprompt-based attention model (PAM) that generates dynamic document embedding\nand document relevance adjusted to the user's query. To effectively visualize\nthese two pieces of information, we design a new document map that leverages a\ncircular grid layout to display documents based on both their relevance to the\nquery and the semantic similarity. Additionally, to improve the\ninterpretability, we introduce a corpus-level attention visualization method to\nimprove the user's understanding of the model focus and to enable the users to\nidentify potential oversight. This visualization, in turn, empowers users to\nrefine, update and introduce new queries, thereby facilitating a dynamic and\niterative information-seeking experience. We evaluated VADIS quantitatively and\nqualitatively on a real-world dataset of biomedical research papers to\ndemonstrate its effectiveness.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-08T05:39:11Z"}
{"aid":"http://arxiv.org/abs/2504.05704v1","title":"Wave propagation and scattering in time dependent media:\n  Lippmann-Schwinger equations, multiple scattering theory, Kirchhoff Helmholtz\n  integrals, Green's functions, reciprocity theorems and Huygens' principle","summary":"Wave scattering plays a central role for the modeling of complex wave\npropagation across all corners of science and engineering applications,\nincluding electromagnetic, acoustics, seismic and scattering physics. Wave\ncontrol using time interfaces, where the properties of the medium through with\nthe wave travels rapidly change in time, has opened further opportunities to\ncontrol wave propagation in both space and time. For acoustic waves, studies on\ntime modulated media have not been reported. In this context, full numerical\nsolution of the wave equation using time interfaces is key to fully understand\ntheir potential. When applying time interfaces, the underlying physics of\nacoustic wave propagation and scattering and their similar roles on time and\nspace, are still being explored. In this work, we introduce a mathematical\nformulation of the Lippmann-Schwinger integral equations for acoustic wave\nscattering when time interfaces are induced via a change of the velocity of the\nmedium. We demonstrate that space-time duality for acoustic wave propagation\nwith time interfaces and derive the Lippmann-Schwinger integral equations for\nwave scattering in time-dependent media, multiple scattering theory, Kirchhoff\nHelmholtz integrals, Green's functions, reciprocity theorems. We experimentally\nverify our theoretical derivation by studying and measuring the acoustic wave\nscattering in strongly scattering media. We illustrate the proposed framework\nand present results of acoustic wave scattering without prior knowledge of the\nbackground wave-fields. This improves the understanding of the generation and\nwave scattering and opens previously inaccessible research directions,\npotentially facilitating practical applications for acoustic, geophysical and\noptical imaging.","main_category":"physics.optics","categories":"physics.optics,physics.geo-ph","published":"2025-04-08T05:56:20Z"}
{"aid":"http://arxiv.org/abs/2504.05710v1","title":"Cryptomania v.s. Minicrypt in a Quantum World","summary":"We prove that it is impossible to construct perfect-complete quantum\npublic-key encryption (QPKE) with classical keys from quantumly secure one-way\nfunctions (OWFs) in a black-box manner, resolving a long-standing open question\nin quantum cryptography. Specifically, in the quantum random oracle model\n(QROM), no perfect-complete QPKE scheme with classical keys, and\nclassical/quantum ciphertext can be secure. This improves the previous works\nwhich require either unproven conjectures or imposed restrictions on key\ngeneration algorithms. This impossibility even extends to QPKE with quantum\npublic key if the public key can be uniquely determined by the secret key, and\nthus is tight to all existing QPKE constructions.","main_category":"quant-ph","categories":"quant-ph,cs.CR","published":"2025-04-08T06:07:40Z"}
{"aid":"http://arxiv.org/abs/2504.05713v1","title":"Revisiting poverty measures using quantile functions","summary":"In this article we redefine various poverty measures in literature in terms\nof quantile functions instead of distribution functions in the prevailing\napproach. This enables provision for alternative methodology for poverty\nmeasurement and analysis along with some new results that are difficult to\nobtain in the existing framework. Several flexible quantile function models\nthat can enrich the existing ones are proposed and their utility is\ndemonstrated for real data.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-08T06:15:17Z"}
{"aid":"http://arxiv.org/abs/2504.05721v1","title":"Graph product and the stability of circulant graphs","summary":"A graph $\\Gamma$ is said to be stable if $\\mathrm{Aut}(\\Gamma\\times\nK_2)\\cong\\mathrm{Aut}(\\Gamma)\\times \\mathbb{Z}_{2}$ and unstable otherwise. If\nan unstable graph is connected, non-bipartite and any two of its distinct\nvertices have different neighborhoods, then it is called nontrivially unstable.\nWe establish conditions guaranteeing the instability of various graph products,\nincluding direct products, direct product bundles, Cartesian products, strong\nproducts, semi-strong products, and lexicographic products. Inspired by a\ncondition for the instability of direct product bundles, we propose a new\nsufficient condition for circulant graphs to be unstable. This condition yields\ninfinitely many nontrivially unstable circulant graphs that do not satisfy any\npreviously established instability conditions for circulant graphs.","main_category":"math.CO","categories":"math.CO","published":"2025-04-08T06:42:11Z"}
{"aid":"http://arxiv.org/abs/2504.05723v1","title":"Improved Polynomial Bounds and Acceleration of GMRES by Solving a\n  min-max Problem on Rectangles, and by Deflating","summary":"Polynomial convergence bounds are considered for left, right, and split\npreconditioned GMRES. They include the cases of Weighted and Deflated GMRES for\na linear system Ax = b. In particular, the case of positive definite A is\nconsidered. The well-known polynomial bounds are generalized to the cases\nconsidered, and then reduced to solving a min-max problem on rectangles on the\ncomplex plane. Several approaches are considered and compared. The new bounds\ncan be improved by using specific deflation spaces and preconditioners. This in\nturn accelerates the convergence of GMRES. Numerical examples illustrate the\nresults obtained.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-08T06:45:34Z"}
{"aid":"http://arxiv.org/abs/2504.05737v1","title":"Developing a novel hybrid family associated with hypergeometric\n  functions through umbral techniques","summary":"The umbral methods are used to reformulate the theoretical framework of\nspecial functions and provide powerful techniques for uncovering new extensions\nand relationships among these functions. This research article introduces an\ninnovative class of special polynomials, specifically the hypergeometric-Appell\npolynomials. The fundamental attributes of this versatile family of special\npolynomials are outlined, including generating relations, explicit\nrepresentations, and differential recurrence relations. Certain particular\nexamples that belong to the class of hypergeometric-Appell polynomials are also\nconsidered. This article aims to reinforce the broad applicability of the\numbral approach to address complex mathematical challenges and contribute to\nvarious scientific and engineering endeavors.","main_category":"math.CA","categories":"math.CA","published":"2025-04-08T07:12:20Z"}
{"aid":"http://arxiv.org/abs/2504.05739v1","title":"PRACH Preamble Detection as a Multi-Class Classification Problem: A\n  Machine Learning Approach Using SVM","summary":"This study addresses the preamble detection problem in the Random Access\nprocedure of LTE/5G networks by formulating it as a multi-class classification\ntask and evaluating the effectiveness of machine learning techniques. A Support\nVector Machine (SVM) model is implemented and compared against conventional\ndetection methods. The proposed approach improves preamble index assignment,\nenhancing detection efficiency for User Equipment (UE) accessing the network.\nPerformance analysis demonstrates that the SVM-based solution increases\ndetection accuracy while reducing missed detections. These findings underscore\nthe potential of machine learning in optimizing the Random Access procedure and\nimproving network accessibility.","main_category":"eess.SP","categories":"eess.SP,40-06","published":"2025-04-08T07:15:50Z"}
{"aid":"http://arxiv.org/abs/2504.05740v1","title":"Micro-splatting: Maximizing Isotropic Constraints for Refined\n  Optimization in 3D Gaussian Splatting","summary":"Recent advancements in 3D Gaussian Splatting have achieved impressive\nscalability and real-time rendering for large-scale scenes but often fall short\nin capturing fine-grained details. Conventional approaches that rely on\nrelatively large covariance parameters tend to produce blurred representations,\nwhile directly reducing covariance sizes leads to sparsity. In this work, we\nintroduce Micro-splatting (Maximizing Isotropic Constraints for Refined\nOptimization in 3D Gaussian Splatting), a novel framework designed to overcome\nthese limitations. Our approach leverages a covariance regularization term to\npenalize excessively large Gaussians to ensure each splat remains compact and\nisotropic. This work implements an adaptive densification strategy that\ndynamically refines regions with high image gradients by lowering the splitting\nthreshold, followed by loss function enhancement. This strategy results in a\ndenser and more detailed gaussian means where needed, without sacrificing\nrendering efficiency. Quantitative evaluations using metrics such as L1, L2,\nPSNR, SSIM, and LPIPS, alongside qualitative comparisons demonstrate that our\nmethod significantly enhances fine-details in 3D reconstructions.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-08T07:15:58Z"}
{"aid":"http://arxiv.org/abs/2504.05743v1","title":"Causal Portfolio Optimization: Principles and Sensitivity-Based\n  Solutions","summary":"Fundamental and necessary principles for achieving efficient portfolio\noptimization based on asset and diversification dynamics are presented. The\nCommonality Principle is a necessary and sufficient condition for identifying\noptimal drivers of a portfolio in terms of its diversification dynamics. The\nproof relies on the Reichenbach Common Cause Principle, along with the fact\nthat the sensitivities of portfolio constituents with respect to the common\ncausal drivers are themselves causal. A conformal map preserves idiosyncratic\ndiversification from the unconditional setting while optimizing systematic\ndiversification on an embedded space of these sensitivities. Causal\nmethodologies for combinatorial driver selection are presented, such as the use\nof Bayesian networks and correlation-based algorithms from Reichenbach's\nprinciple. Limitations of linear models in capturing causality are discussed,\nand included for completeness alongside more advanced models such as neural\nnetworks. Portfolio optimization methods are presented that map risk from the\nsensitivity space to other risk measures of interest. Finally, the work\nintroduces a novel risk management framework based on Common Causal Manifolds,\nincluding both theoretical development and experimental validation. The\nsensitivity space is predicted along the common causal manifold, which is\nmodeled as a causal time system. Sensitivities are forecasted using SDEs\ncalibrated to data previously extracted from neural networks to move along the\nmanifold via its tangent bundles. An optimization method is then proposed that\naccumulates information across future predicted tangent bundles on the common\ncausal time system manifold. It aggregates sensitivity-based distance metrics\nalong the trajectory to build a comprehensive sensitivity distance matrix. This\nmatrix enables trajectory-wide optimal diversification, taking into account\nfuture dynamics.","main_category":"q-fin.PM","categories":"q-fin.PM","published":"2025-04-08T07:21:40Z"}
{"aid":"http://arxiv.org/abs/2504.05754v1","title":"Dispersion-corrected Machine Learning Potentials for 2D van der Waals\n  Materials","summary":"Machine-learned interatomic potentials (MLIPs) based on message passing\nneural networks hold promise to enable large-scale atomistic simulations of\ncomplex materials with ab initio accuracy. A number of MLIPs trained on\nenergies and forces from density functional theory (DFT) calculations employing\nsemi-local exchange-correlation (xc) functionals have recently been introduced.\nHere, we benchmark the performance of six dispersion-corrected MLIPs on a\ndataset of van der Waals heterobilayers containing between 4 and 300 atoms in\nthe moir\\'e cell. Using various structure similarity metrics, we compare the\nrelaxed heterostructures to the ground truth DFT results. With some notable\nexceptions, the model precisions are comparable to the uncertainty on the DFT\nresults stemming from the choice of xc-functional. We further explore how the\nstructural inaccuracies propagate to the electronic properties, and find\nexcellent performance with average errors on band energies as low as 35 meV.\nOur results demonstrate that recent MLIPs after dispersion corrections are on\npar with DFT for general vdW heterostructures, and thus justify their\napplication to complex and experimentally relevant 2D materials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T07:35:53Z"}
{"aid":"http://arxiv.org/abs/2504.05756v1","title":"Interpretable Non-linear Survival Analysis with Evolutionary Symbolic\n  Regression","summary":"Survival Regression (SuR) is a key technique for modeling time to event in\nimportant applications such as clinical trials and semiconductor manufacturing.\nCurrently, SuR algorithms belong to one of three classes: non-linear black-box\n-- allowing adaptability to many datasets but offering limited interpretability\n(e.g., tree ensembles); linear glass-box -- being easier to interpret but\nlimited to modeling only linear interactions (e.g., Cox proportional hazards);\nand non-linear glass-box -- allowing adaptability and interpretability, but\nempirically found to have several limitations (e.g., explainable boosting\nmachines, survival trees). In this work, we investigate whether Symbolic\nRegression (SR), i.e., the automated search of mathematical expressions from\ndata, can lead to non-linear glass-box survival models that are interpretable\nand accurate. We propose an evolutionary, multi-objective, and multi-expression\nimplementation of SR adapted to SuR. Our empirical results on five real-world\ndatasets show that SR consistently outperforms traditional glass-box methods\nfor SuR in terms of accuracy per number of dimensions in the model, while\nexhibiting comparable accuracy with black-box methods. Furthermore, we offer\nqualitative examples to assess the interpretability potential of SR models for\nSuR. Code at: https://github.com/lurovi/SurvivalMultiTree-pyNSGP.","main_category":"cs.LG","categories":"cs.LG,cs.NE","published":"2025-04-08T07:37:37Z"}
{"aid":"http://arxiv.org/abs/2504.05760v1","title":"Cutoff for East models at high temperature","summary":"We consider the East model in $\\mathbb Z^d$, an example of a kinetically\nconstrained interacting particle system with oriented constraints, together\nwith one of its natural variant. Under any ergodic boundary condition it is\nknown that the mixing time of the chain in a box of side $L$ is $\\Theta(L)$ for\nany $d\\ge 1$. Moreover, with minimal boundary conditions and at low\ntemperature, i.e. low equilibrium density of the facilitating vertices, the\nchain exhibits cutoff around the mixing time of the $d=1$ case. Here we extend\nthis result to high temperature. As in the low temperature case, the key tool\nis to prove that the speed of infection propagation in the $(1,1,\\dots,1)$\ndirection is larger than $d$ $\\times$ the same speed along a coordinate\ndirection. By borrowing a technique from first passage percolation, the proof\nlinks the result to the precise value of the critical probability of oriented\n(bond or site) percolation in $\\mathbb Z^d$.","main_category":"math.PR","categories":"math.PR","published":"2025-04-08T07:42:29Z"}
{"aid":"http://arxiv.org/abs/2504.05762v1","title":"Statistics of velocity gradient and vortex sheet structures in polymeric\n  turbulent von K{á}rm{á}n swirling flow","summary":"Investigations into the effects of polymers on small-scale statistics and\nflow patterns were conducted in a turbulent von Karman swirling (VKS) flow. We\nemployed the tomographic particle image velocimetry (Tomo-PIV) technique to\nobtain full information on three-dimensional velocity data, allowing us to\neffectively resolve dissipation scales. Under varying Reynolds numbers\n($R_\\lambda=168 - 235$) and polymer concentrations ($\\phi=0 -25~\\rm ppm$), we\nmeasured the velocity gradient tensor (VGT) and related quantities. Our\nfindings reveal that the ensemble average and probability density function\n(PDF) of VGT invariants, which represent turbulent dissipation and enstrophy\nalong with their generation terms, are suppressed as polymer concentration\nincreases. Notably, the joint PDFs of the invariants of VGT, which characterize\nlocal flow patterns, exhibited significant changes. Specifically, the\nthird-order invariants, especially the local vortex stretching, are greatly\nsuppressed, and strong events of dissipation and enstrophy coexist in space.\nThe local flow pattern tends to be two-dimensional, where the eigenvalues of\nthe rate-of-strain tensor satisfy a ratio $1:0:-1$, and the vorticity aligns\nwith the intermediate eigenvector of the rate-of-strain tensor while is\nperpendicular to the other two. We find that these statistics observations can\nbe well described by the vortex sheet model. Moreover, we find that these\nvortex sheet structures align with the symmetry axis of the VKS system and\norient randomly in the horizontal plane. Further investigation, including flow\nvisualization and conditional statistics on vorticity, confirms the presence of\nvortex sheet structures in turbulent flows with polymer additions. Our results\nestablish a link between single-point statistics and small-scale flow topology,\nshedding light on the previously overlooked small-scale structures in polymeric\nturbulence.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-08T07:43:17Z"}
{"aid":"http://arxiv.org/abs/2504.05765v1","title":"Probabilistic Process Discovery with Stochastic Process Trees","summary":"In order to obtain a stochastic model that accounts for the stochastic\naspects of the dynamics of a business process, usually the following steps are\ntaken. Given an event log, a process tree is obtained through a process\ndiscovery algorithm, i.e., a process tree that is aimed at reproducing, as\naccurately as possible, the language of the log. The process tree is then\ntransformed into a Petri net that generates the same set of sequences as the\nprocess tree. In order to capture the frequency of the sequences in the event\nlog, weights are assigned to the transitions of the Petri net, resulting in a\nstochastic Petri net with a stochastic language in which each sequence is\nassociated with a probability. In this paper we show that this procedure has\nunfavorable properties. First, the weights assigned to the transitions of the\nPetri net have an unclear role in the resulting stochastic language. We will\nshow that a weight can have multiple, ambiguous impact on the probability of\nthe sequences generated by the Petri net. Second, a number of different Petri\nnets with different number of transitions can correspond to the same process\ntree. This means that the number of parameters (the number of weights) that\ndetermines the stochastic language is not well-defined. In order to avoid these\nambiguities, in this paper, we propose to add stochasticity directly to process\ntrees. The result is a new formalism, called stochastic process trees, in which\nthe number of parameters and their role in the associated stochastic language\nis clear and well-defined.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T07:46:06Z"}
{"aid":"http://arxiv.org/abs/2504.05771v1","title":"Dissolution-driven transport in a rotating horizontal cylinder","summary":"Dissolution, in particular, coupled with convection, can be of great\nrelevance in the fields of pharmaceuticals, food science, chemical engineering,\nand environmental science, having applications in drug release into the\nbloodstream, ingredient dissolution in liquids, metal extraction from ores, and\npollutant dispersion in water. We study the combined effects of natural\nconvection and rotation on the dissolution of a solute in a solvent-filled\ncircular cylinder. The density of the fluid increases with the increasing\nconcentration of the dissolved solute, and we model this using the\nOberbeck-Boussinesq approximation. The underlying moving-boundary problem has\nbeen modelled by combining Navier-Stokes equations with the advection-diffusion\nequation and a Stefan condition for the evolving solute-fluid interface. We use\nhighly resolved numerical simulations to investigate the flow regimes,\ndissolution rates, and mixing of the dissolved solute for $Sc = 1$, $Ra =\n[10^5, 10^8]$ and $\\Omega = [0, 2.5]$. In the absence of rotation and buoyancy,\nthe distance of the interface from its initial position follows a square root\nrelationship with time ($r_d \\propto \\sqrt{t}$), which ceases to exist at a\nlater time due to the finite-size effect of the liquid domain. We then explore\nthe rotation parameter, considering a range of rotation frequency -- from\nsmaller to larger, relative to the inverse of the buoyancy-induced timescale --\nand Rayleigh number. We show that the area of the dissolved solute varies\nnonlinearly with time depending on $Ra$ and $\\Omega$. The symmetry breaking of\nthe interface is best described in terms of $Ra/\\Omega^2$.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-08T07:50:30Z"}
{"aid":"http://arxiv.org/abs/2504.05774v1","title":"Transferable Mask Transformer: Cross-domain Semantic Segmentation with\n  Region-adaptive Transferability Estimation","summary":"Recent advances in Vision Transformers (ViTs) have set new benchmarks in\nsemantic segmentation. However, when adapting pretrained ViTs to new target\ndomains, significant performance degradation often occurs due to distribution\nshifts, resulting in suboptimal global attention. Since self-attention\nmechanisms are inherently data-driven, they may fail to effectively attend to\nkey objects when source and target domains exhibit differences in texture,\nscale, or object co-occurrence patterns. While global and patch-level domain\nadaptation methods provide partial solutions, region-level adaptation with\ndynamically shaped regions is crucial due to spatial heterogeneity in\ntransferability across different image areas. We present Transferable Mask\nTransformer (TMT), a novel region-level adaptation framework for semantic\nsegmentation that aligns cross-domain representations through spatial\ntransferability analysis. TMT consists of two key components: (1) An Adaptive\nCluster-based Transferability Estimator (ACTE) that dynamically segments images\ninto structurally and semantically coherent regions for localized\ntransferability assessment, and (2) A Transferable Masked Attention (TMA)\nmodule that integrates region-specific transferability maps into ViTs'\nattention mechanisms, prioritizing adaptation in regions with low\ntransferability and high semantic uncertainty. Comprehensive evaluations across\n20 cross-domain pairs demonstrate TMT's superiority, achieving an average 2%\nMIoU improvement over vanilla fine-tuning and a 1.28% increase compared to\nstate-of-the-art baselines. The source code will be publicly available.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-08T07:53:51Z"}
{"aid":"http://arxiv.org/abs/2504.05785v1","title":"Presolve techniques for quasi-convex chance constraints with\n  finite-support low-dimensional uncertainty","summary":"Chance-constrained programs (CCP) represent a trade-off between conservatism\nand robustness in optimization. In many CCPs, one optimizes an objective under\na probabilistic constraint continuously parameterized by a random vector $\\xi$.\nIn this work, we study the specific case where the constraint is quasi-convex\nwith $\\xi$. Moreover, the support of vector $\\xi$ is a collection of $N$\nscenarios in dimension $p=2$ or $p=3$. In general, even when both the\nconstraint and the objective are convex in the decision variable, the feasible\nregion of a CCP is nonconvex, turning it into a difficult problem. However,\nunder mild assumptions, many CCPs can be recast as big-$M$ mixed-integer convex\nprograms (MICP). Unfortunately, the difficulty of these MICPs explodes with the\nnumber of scenarios, restricting the instances practically solvable in decent\ntime. To cut down the effective number of scenarios considered in MICP\nreformulations and accelerate their solving, we propose and test presolve\ntechniques based on computational geometry. Our techniques produce certificates\nto discard or select a priori some scenarios before solving a regular MICP.\nMoreover, the information aggregated during presolve leverages the possibility\nto strengthen big-$M$ constants. Our numerical experiments suggest that\nspending some time in presolve is more efficient than a direct solve for a\nclass of probabilistic projection problems, including an interesting type of\nfacility location problem.","main_category":"math.OC","categories":"math.OC","published":"2025-04-08T08:11:38Z"}
{"aid":"http://arxiv.org/abs/2504.05787v1","title":"Finiteness properties of asymptotically rigid handlebody groups","summary":"We introduce asymptotically rigid mapping class groups of handlebodies and\ndetermine their finiteness properties, which vary depending on the space of\nends of the underlying handlebody. As it turns out, in some cases, the homology\nof these groups coincides with the stable homology of handlebody groups, as\nstudied by Hatcher and Wahl.","main_category":"math.GT","categories":"math.GT,math.GR","published":"2025-04-08T08:13:15Z"}
{"aid":"http://arxiv.org/abs/2504.05790v1","title":"ViralQC: A Tool for Assessing Completeness and Contamination of\n  Predicted Viral Contigs","summary":"Motivation: Viruses represent the most abundant biological entities on the\nplanet and play vital roles in diverse ecosystems. Cataloging viruses across\nvarious environments is essential for understanding their properties and\nfunctions. Metagenomic sequencing has emerged as the most comprehensive method\nfor virus discovery, enabling the sequencing of all genetic materials,\nincluding viruses, from host or environmental samples. However, distinguishing\nviral sequences from the vast background of cellular organism-derived reads in\nmetagenomic data remains a significant challenge. While several learning-based\ntools, such as VirSorter2 and geNomad, have shown promise in identifying viral\ncontigs, they often experience varying degrees of false positive rates due to\nnoise in sequencing and assembly, shared genes between viruses and their hosts,\nand the formation of proviruses within host genomes. This highlights the urgent\nneed for an accurate and efficient method to evaluate the quality of viral\ncontigs. Results: To address these challenges, we introduce ViralQC, a tool\ndesigned to assess the quality of reported viral contigs or bins. ViralQC\nidentifies contamination regions within putative viral sequences using\nfoundation models trained on viral and cellular genomes and estimates viral\ncompleteness through protein organization alignment. We evaluate ViralQC on\nmultiple datasets and compare its performance against CheckV, the\nstate-of-the-art in virus quality assessment. Notably, ViralQC correctly\nidentifies 38% more contamination than CheckV, while maintaining a median\nabsolute error of only 3%. In addition, ViralQC delivers more accurate results\nfor medium- to high-quality (>50% completeness) contigs, demonstrating its\nsuperior performance in completeness estimation.","main_category":"q-bio.GN","categories":"q-bio.GN","published":"2025-04-08T08:14:44Z"}
{"aid":"http://arxiv.org/abs/2504.05792v1","title":"Pinching-Antenna Assisted ISAC: A CRLB Perspective","summary":"Recently, pinching antennas have attracted significant research interest due\nto their capability to reconfigure wireless channels as well as their array\nconfiguration flexibility. This letter focuses on how these features can be\nused to support integrated sensing and communications (ISAC) from the Cramer\nRao lower bound (CRLB) perspective. In particular, the CRLB achieved by\npinching antennas is first derived and then compared to that of conventional\nantennas. The presented analytical and simulation results demonstrate that\nusing pinching antennas can significantly reduce CRLB and, hence, enhance\npositioning accuracy. In addition, this letter also reveals that the low-cost\nand reconfigurability features of pinching antennas can be utilized to realize\nflexible user-centric positioning.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-08T08:21:58Z"}
{"aid":"http://arxiv.org/abs/2504.05795v1","title":"Robust Fusion Controller: Degradation-aware Image Fusion with\n  Fine-grained Language Instructions","summary":"Current image fusion methods struggle to adapt to real-world environments\nencompassing diverse degradations with spatially varying characteristics. To\naddress this challenge, we propose a robust fusion controller (RFC) capable of\nachieving degradation-aware image fusion through fine-grained language\ninstructions, ensuring its reliable application in adverse environments.\nSpecifically, RFC first parses language instructions to innovatively derive the\nfunctional condition and the spatial condition, where the former specifies the\ndegradation type to remove, while the latter defines its spatial coverage.\nThen, a composite control priori is generated through a multi-condition\ncoupling network, achieving a seamless transition from abstract language\ninstructions to latent control variables. Subsequently, we design a hybrid\nattention-based fusion network to aggregate multi-modal information, in which\nthe obtained composite control priori is deeply embedded to linearly modulate\nthe intermediate fused features. To ensure the alignment between language\ninstructions and control outcomes, we introduce a novel language-feature\nalignment loss, which constrains the consistency between feature-level gains\nand the composite control priori. Extensive experiments on publicly available\ndatasets demonstrate that our RFC is robust against various composite\ndegradations, particularly in highly challenging flare scenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T08:22:55Z"}
{"aid":"http://arxiv.org/abs/2504.05799v1","title":"Higgs alignment limits in the type-II 2HDM and the MSSM with explicit\n  CP-violation","summary":"For the general two-Higgs doublet model with Yukawa sector of type II (type\nII 2HDM), the Higgs alignment limit conditions are obtained for the neutral\nHiggs bosons with indefinite CP-parity $h_1, h_2$ or $h_3$, based on the\nsymbolic results relating the elements of the mixing matrix to the masses of\nthe Higgs bosons and the mixing angles. The results are valid up to\ndimension-six operators in the decomposition of the effective Higgs potential.\nWithin the framework of the obtained Higgs alignment conditions, the\npossibility of the existence of light scalars is discussed. Within the Minimal\nSupersymmetric Standard Model (MSSM) framework, four benchmark scenarios are\nproposed. It is shown that two of them predict phenomenologically\ndistinguishable CP-violating interactions of the Higgs boson $h_3$ with\nup-fermions.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-08T08:27:09Z"}
{"aid":"http://arxiv.org/abs/2504.05834v1","title":"Elongation-Induced Segregation in Periodically Textured Microfluidic\n  Channels","summary":"We numerically investigate the motion of elongated microparticles in\nmicrofluidic channels at low Reynolds numbers. In channels with smooth walls,\nasymmetric initial conditions -- including particle orientation and lateral\nposition -- lead to continuous variations in particle trajectories, potentially\nexhibiting repeated behavior depending on the channel geometry and initial\nconditions. However, we find that introducing periodically textured walls\ninduces alignment of the particle with the channel centerline within a specific\nrange of texture wavelengths. This occurs as the textured pattern disrupts the\nuniformity of the flow, creating localized high-velocity nodes that repeatedly\nguide the particle toward the centerline as it moves downstream. Notably, the\ncharacteristic length scale over which this alignment forms reduces with\nincreasing particle elongation and diverges with increasing Reynolds number.\nOur findings reveal that elongation-induced alignment can be leveraged for\nmicrofluidic filtering applications, enabling the efficient separation of\nmicroparticles based on their geometric properties. This work opens new avenues\nfor designing microfluidic devices tailored for high-precision particle\nsorting, with broad implications for biomedical and industrial applications.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cond-mat.stat-mech,physics.comp-ph","published":"2025-04-08T09:17:23Z"}
{"aid":"http://arxiv.org/abs/2504.05836v1","title":"Work probability distribution of weakly driven process in overdamped\n  dynamics","summary":"Analytical work probability distributions for open classical systems are\nscarce; they can only be calculated in a few examples. In this work, I present\na new method to derive such quantities for weakly driven processes in the\noverdamped regime for any switching time. The white noise Brownian motion in a\nharmonic linear stiffening trap illustrates the result. The work probability\ndistribution is non-tabulated, with positive, semi-finite support, diverging at\nthe minimal value, and non-Gaussian. An analysis of the range of validity of\nlinear response is made by using the self-consistent criterion of the\nfluctuation-dissipation relation. The first, second, third, and fourth moments\nare correctly calculated for small perturbations.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-08T09:18:35Z"}
{"aid":"http://arxiv.org/abs/2504.05841v1","title":"Continuous spectrum-shrinking maps between finite-dimensional algebras","summary":"Let $\\mathcal{A}$ and $\\mathcal{B}$ be unital finite-dimensional complex\nalgebras, each equipped with the unique Hausdorff vector topology. Denote by\n$\\mathrm{Max}(\\mathcal{A})=\\{\\mathcal{M}_1, \\ldots, \\mathcal{M}_p\\}$ and\n$\\mathrm{Max}(\\mathcal{B})=\\{\\mathcal{N}_1, \\ldots, \\mathcal{N}_q\\}$ the sets\nof all maximal ideals of $\\mathcal{A}$ and $\\mathcal{B}$, respectively, and\ndefine the quantities $$k_i:=\\sqrt{\\dim(\\mathcal{A}/\\mathcal{M}_i)}, \\, \\, 1\n\\leq i \\leq p \\quad \\text{ and } \\quad\nm:=\\sum_{j=1}^q\\sqrt{\\dim(\\mathcal{B}/\\mathcal{N}_j)},$$ which are positive\nintegers by Wedderburn's structure theorem. We show that there exists a\ncontinuous spectrum-shrinking map $\\phi: \\mathcal{A} \\to \\mathcal{B}$ (i.e.\n$\\mathrm{sp}(\\phi(x))\\subseteq \\mathrm{sp}(x)$ for all $x \\in \\mathcal{A}$) if\nand only if the linear Diophantine equation $$ k_1x_1 + \\cdots + k_px_p = m $$\nhas a non-negative integer solution $(x_1,\\ldots,x_p)$. Moreover, all such maps\n$\\phi$ are spectrum preserving (i.e. $\\mathrm{sp}(\\phi(x))=\\mathrm{sp}(x)$ for\nall $x \\in \\mathcal{A}$) if and only if each non-negative solution consists\nonly of positive integers.","main_category":"math.SP","categories":"math.SP,math.RA","published":"2025-04-08T09:21:40Z"}
{"aid":"http://arxiv.org/abs/2504.05842v1","title":"Exact results for spin glass criticality","summary":"In recent years scale invariant scattering theory provided the first exact\naccess to the magnetic critical properties of two-dimensional statistical\nsystems with quenched disorder. We show how the theory extends to the overlap\nvariables entering the characterization of spin glass properties. The resulting\nexact fixed point equations yield both the magnetic and, for the first time,\nthe spin glass renormalization group fixed points. For the case of the random\nbond Ising model, on which we focus, the spin glass subspace of solutions is\nfound to contain a line of fixed points. We discuss the implications of the\nresults for Ising spin glass criticality and compare with the available\nnumerical results.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.dis-nn,hep-th","published":"2025-04-08T09:22:05Z"}
{"aid":"http://arxiv.org/abs/2504.05857v1","title":"Towards an AI-Driven Video-Based American Sign Language Dictionary:\n  Exploring Design and Usage Experience with Learners","summary":"Searching for unfamiliar American Sign Language (ASL) signs is challenging\nfor learners because, unlike spoken languages, they cannot type a text-based\nquery to look up an unfamiliar sign. Advances in isolated sign recognition have\nenabled the creation of video-based dictionaries, allowing users to submit a\nvideo and receive a list of the closest matching signs. Previous HCI research\nusing Wizard-of-Oz prototypes has explored interface designs for ASL\ndictionaries. Building on these studies, we incorporate their design\nrecommendations and leverage state-of-the-art sign-recognition technology to\ndevelop an automated video-based dictionary. We also present findings from an\nobservational study with twelve novice ASL learners who used this dictionary\nduring video-comprehension and question-answering tasks. Our results address\nhuman-AI interaction challenges not covered in previous WoZ research, including\nrecording and resubmitting signs, unpredictable outputs, system latency, and\nprivacy concerns. These insights offer guidance for designing and deploying\nvideo-based ASL dictionary systems.","main_category":"cs.HC","categories":"cs.HC,cs.AI","published":"2025-04-08T09:35:46Z"}
{"aid":"http://arxiv.org/abs/2504.05860v1","title":"Functional matrix product state simulation of continuous variable\n  quantum circuits","summary":"We introduce a functional matrix product state (FMPS) based method for\nsimulating the real-space representation of continuous-variable (CV) quantum\ncomputation. This approach efficiently simulates non-Gaussian CV systems by\nleveraging their functional form. By addressing scaling bottlenecks, FMPS\nenables more efficient simulation of shallow, multi-mode CV quantum circuits\nwith non-Gaussian input states. The method is validated by simulating random\nshallow and cascaded circuits with highly non-Gaussian input states, showing\nsuperior performance compared to existing techniques, also in the presence of\nloss.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T09:37:19Z"}
{"aid":"http://arxiv.org/abs/2504.05869v1","title":"The Ultraviolet Spectra of 2003fg-like Type Ia Supernovae","summary":"2003fg-like Type Ia supernovae (03fg-like SNe Ia) are a rare subtype of SNe\nIa, photometrically characterized by broader optical light curves and bluer\nultraviolet (UV) colors compared to normal SNe Ia. In this work, we study four\n03fg-like SNe Ia using Swift UltraViolet and Optical Telescope (UVOT) grism\nobservations to understand their unique UV properties and progenitor\nscenario(s). We report 03fg-like SNe Ia to have similar UV features and\nelemental compositions as normal SNe Ia, but with higher UV flux relative to\noptical. Previous studies have suggested that the UV flux levels of normal SNe\nIa could be influenced by their progenitor properties, such as metallicity,\nwith metal-poor progenitors producing higher UV flux levels. While 03fg-like\nSNe were previously reported to occur in low-mass and metal-poor host\nenvironments, our analysis indicates that their UV excess cannot be explained\nby their host-galaxy parameters. Instead, we demonstrate that the addition of a\nhot blackbody component, likely arising from the interaction with the\ncircumstellar material (CSM), to the normal SN Ia spectrum, can reproduce their\ndistinctive UV excess. This supports the hypothesis that 03fg-like SNe Ia could\nexplode in a CSM-rich environment.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-08T09:52:56Z"}
{"aid":"http://arxiv.org/abs/2504.05875v1","title":"Gravitational waves from primordial black hole dominance: The effect of\n  inflaton decay rate","summary":"In this work, we explore primordial black holes (PBH) formation scenario\nduring the post-inflationary preheating stage dominated by the inflaton field.\nWe consider, in particular, a model-independent parametrization of the Gaussian\npeak inflationary power spectrum that leads to amplified inflationary density\nfluctuations before the end of inflation. These modes can reenter the horizon\nduring preheating and could experience instabilities that trigger the\nproduction of PBH. This is estimated with the Khlopov-Polnarev (KP) formalism\nthat takes into account non-spherical effects. We derive an accurate analytical\nexpression for the mass fraction under the KP formalism that fits well with the\nnumerical evaluation. Particularly, we focus on ultra-light PBH of masses\n$M_{\\text{PBH}}<10^9g$ and study their evolution and (possible) dominance after\nthe decay of the inflation field into radiation and before the PBH evaporation\nvia Hawking radiation. These considerations alter the previous estimates of\ninduced gravitational waves (GWs) from PBH dominance and open new windows for\ndetecting stochastic GW backgrounds with future detectors.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-08T09:58:47Z"}
{"aid":"http://arxiv.org/abs/2504.05886v1","title":"Learning strategies for optimised fitness in a model of cyclic dominance","summary":"A major problem in evolutionary biology is how species learn and adapt under\nthe constraint of environmental conditions and competition of other species.\nModels of cyclic dominance provide simplified settings in which such questions\ncan be addressed using methods from theoretical physics. We investigate how a\nprivileged (\"smart\") species optimises its population by adopting advantageous\nstrategies in one such model. We use a reinforcement learning algorithm, which\nsuccessfully identifies optimal strategies based on a survival-of-the-weakest\neffect, including directional incentives to avoid predators. We also\ncharacterise the steady-state behaviour of the system in the presence of the\nsmart species and compare with the symmetric case where all species are\nequivalent.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,q-bio.PE","published":"2025-04-08T10:22:25Z"}
{"aid":"http://arxiv.org/abs/2504.05887v1","title":"Jointly-optimized Trajectory Generation and Camera Control for 3D\n  Coverage Planning","summary":"This work proposes a jointly optimized trajectory generation and camera\ncontrol approach, enabling an autonomous agent, such as an unmanned aerial\nvehicle (UAV) operating in 3D environments, to plan and execute coverage\ntrajectories that maximally cover the surface area of a 3D object of interest.\nSpecifically, the UAV's kinematic and camera control inputs are jointly\noptimized over a rolling planning horizon to achieve complete 3D coverage of\nthe object. The proposed controller incorporates ray-tracing into the planning\nprocess to simulate the propagation of light rays, thereby determining the\nvisible parts of the object through the UAV's camera. This integration enables\nthe generation of precise look-ahead coverage trajectories. The coverage\nplanning problem is formulated as a rolling finite-horizon optimal control\nproblem and solved using mixed-integer programming techniques. Extensive\nreal-world and synthetic experiments validate the performance of the proposed\napproach.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-08T10:23:37Z"}
{"aid":"http://arxiv.org/abs/2504.05895v1","title":"Orthogonal Matching Pursuit based Reconstruction for Modulo Hysteresis\n  Operators","summary":"Unlimited sampling provides an acquisition scheme for high dynamic range\nsignals by folding the signal into the dynamic range of the analog-to-digital\nconverter (ADC) using modulo non-linearity prior to sampling to prevent\nsaturation. Recently, a generalized scheme called modulo hysteresis was\nintroduced to account for hardware non-idealities. The encoding operator,\nhowever, does not guarantee that the output signal is within the dynamic range\nof the ADC. To resolve this, we propose a modified modulo hysteresis operator\nand show identifiability of bandlimited signals from modulo hysteresis samples.\nWe propose a recovery algorithm based on orthogonal matching pursuit and\nvalidate our theoretical results through numerical experiments.","main_category":"math.NA","categories":"math.NA,cs.NA,eess.SP","published":"2025-04-08T10:45:44Z"}
{"aid":"http://arxiv.org/abs/2504.05898v1","title":"Assessing Thai Dialect Performance in LLMs with Automatic Benchmarks and\n  Human Evaluation","summary":"Large language models show promising results in various NLP tasks. Despite\nthese successes, the robustness and consistency of LLMs in underrepresented\nlanguages remain largely unexplored, especially concerning local dialects.\nExisting benchmarks also focus on main dialects, neglecting LLMs' ability on\nlocal dialect texts. In this paper, we introduce a Thai local dialect benchmark\ncovering Northern (Lanna), Northeastern (Isan), and Southern (Dambro) Thai,\nevaluating LLMs on five NLP tasks: summarization, question answering,\ntranslation, conversation, and food-related tasks. Furthermore, we propose a\nhuman evaluation guideline and metric for Thai local dialects to assess\ngeneration fluency and dialect-specific accuracy. Results show that LLM\nperformance declines significantly in local Thai dialects compared to standard\nThai, with only proprietary models like GPT-4o and Gemini2 demonstrating some\nfluency","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T10:49:45Z"}
{"aid":"http://arxiv.org/abs/2504.05900v1","title":"Strict renormalizability as a paradigm for fundamental physics","summary":"An important theoretical achievement of the last century was the realization\nthat strict renormalizability can be a powerful criterion to select Lagrangians\nin the framework of perturbative quantum field theory. The Standard Model\nLagrangian (without gravity) is strictly renormalizable from a perturbative\npoint of view. On the other hand, the inclusion of gravity seems not to respect\nthis criterion, since general relativity is perturbatively non-renormalizable.\nThe aim of this work is to provide concrete evidence that strict\nrenormalizability is still a valid criterion even when applied to gravity.\nFirst, we show that adding quadratic curvature terms to the Einstein-Hilbert\naction gives rise to a strictly renormalizable theory known as quadratic\ngravity. Second, we argue that this unique theory represents the most\nconservative approach to quantum gravity and, at the same time, is highly\npredictive, as it can explain new physics beyond general relativity already in\nthe sub-Planckian regime. In particular, it provides one of the best fits to\nthe CMB anisotropies via Starobinsky inflation and makes sharp cosmological\npredictions that can be tested in the near future. Finally, we comment on the\n(super-)Planckian regime and conclude with a historical note.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-08T10:54:19Z"}
{"aid":"http://arxiv.org/abs/2504.05903v1","title":"A construction of multiple group racks","summary":"A multiple group rack is a rack which is a disjoint union of groups equipped\nwith a binary operation satisfying some conditions. It is used to define\ninvariants of spatial surfaces, i.e., oriented compact surfaces with boundaries\nembedded in the $3$-sphere $S^{3}$. A $G$-family of racks is a set with a\nfamily of binary operations indexed by the elements of a group $G$. There are\ntwo known methods for constructing multiple group racks. One is via a\n$G$-family of racks. The resulting multiple group rack is called the associated\nmultiple group rack of the $G$-family of racks. The other is by taking an\nabelian extension of a multiple group rack. In this paper, we introduce a new\nmethod for constructing multiple group racks by using a $G$-family of racks and\na normal subgroup $N$ of $G$. We show that this construction yields multiple\ngroup racks that are neither the associated multiple group racks of any\n$G$-family of racks nor their abelian extensions when the right conjugation\naction of $G$ on $N$ is nontrivial. As an application, we present a pair of\nspatial surfaces that cannot be distinguished by invariants derived from the\nassociated multiple group racks of any $G$-family of racks, yet can be\ndistinguished using invariants obtained from a multiple group rack introduced\nin this paper.","main_category":"math.GT","categories":"math.GT","published":"2025-04-08T11:01:42Z"}
{"aid":"http://arxiv.org/abs/2504.05904v1","title":"Intrinsic Saliency Guided Trunk-Collateral Network for Unsupervised\n  Video Object Segmentation","summary":"Recent unsupervised video object segmentation (UVOS) methods predominantly\nadopt the motion-appearance paradigm. Mainstream motion-appearance approaches\nuse either the two-encoder structure to separately encode motion and appearance\nfeatures, or the single-encoder structure for joint encoding. However, these\nmethods fail to properly balance the motion-appearance relationship.\nConsequently, even with complex fusion modules for motion-appearance\nintegration, the extracted suboptimal features degrade the models' overall\nperformance. Moreover, the quality of optical flow varies across scenarios,\nmaking it insufficient to rely solely on optical flow to achieve high-quality\nsegmentation results. To address these challenges, we propose the Intrinsic\nSaliency guided Trunk-Collateral Net}work (ISTC-Net), which better balances the\nmotion-appearance relationship and incorporates model's intrinsic saliency\ninformation to enhance segmentation performance. Specifically, considering that\noptical flow maps are derived from RGB images, they share both commonalities\nand differences. We propose a novel Trunk-Collateral structure. The shared\ntrunk backbone captures the motion-appearance commonality, while the collateral\nbranch learns the uniqueness of motion features. Furthermore, an Intrinsic\nSaliency guided Refinement Module (ISRM) is devised to efficiently leverage the\nmodel's intrinsic saliency information to refine high-level features, and\nprovide pixel-level guidance for motion-appearance fusion, thereby enhancing\nperformance without additional input. Experimental results show that ISTC-Net\nachieved state-of-the-art performance on three UVOS datasets (89.2% J&F on\nDAVIS-16, 76% J on YouTube-Objects, 86.4% J on FBMS) and four standard video\nsalient object detection (VSOD) benchmarks with the notable increase,\ndemonstrating its effectiveness and superiority over previous methods.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-08T11:02:14Z"}
{"aid":"http://arxiv.org/abs/2504.05910v1","title":"Testing the parquet equations and the U(1) Ward identity for\n  real-frequency correlation functions from the multipoint numerical\n  renormalization group","summary":"Recently, it has become possible to compute real-frequency four-point\ncorrelation functions of quantum impurity models using a multipoint extension\nof the numerical renormalization group (mpNRG). In this work, we perform\nseveral numerical consistency checks of the output of mpNRG by investigating\nexact relations between two- and four-point functions. This includes the\nBethe-Salpeter equations and the Schwinger-Dyson equation from the parquet\nformalism, which we evaluate in two formally identical but numerically\nnonequivalent ways. We also study the first-order U(1) Ward identity between\nthe vertex and the self-energy, which we derive for the first time in full\ngenerality in the real-frequency Keldysh formalism. We generally find good\nagreement of all relations, often up to a few percent, both at weak and at\nstrong interaction.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-08T11:06:06Z"}
{"aid":"http://arxiv.org/abs/2504.05913v1","title":"Balancing long- and short-term dynamics for the modeling of saliency in\n  videos","summary":"The role of long- and short-term dynamics towards salient object detection in\nvideos is under-researched. We present a Transformer-based approach to learn a\njoint representation of video frames and past saliency information. Our model\nembeds long- and short-term information to detect dynamically shifting saliency\nin video. We provide our model with a stream of video frames and past saliency\nmaps, which acts as a prior for the next prediction, and extract spatiotemporal\ntokens from both modalities. The decomposition of the frame sequence into\ntokens lets the model incorporate short-term information from within the token,\nwhile being able to make long-term connections between tokens throughout the\nsequence. The core of the system consists of a dual-stream Transformer\narchitecture to process the extracted sequences independently before fusing the\ntwo modalities. Additionally, we apply a saliency-based masking scheme to the\ninput frames to learn an embedding that facilitates the recognition of\ndeviations from previous outputs. We observe that the additional prior\ninformation aids in the first detection of the salient location. Our findings\nindicate that the ratio of spatiotemporal long- and short-term features\ndirectly impacts the model's performance. While increasing the short-term\ncontext is beneficial up to a certain threshold, the model's performance\ngreatly benefits from an expansion of the long-term context.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T11:09:37Z"}
{"aid":"http://arxiv.org/abs/2504.05921v1","title":"Accelerated Reeds-Shepp and Under-Specified Reeds-Shepp Algorithms for\n  Mobile Robot Path Planning","summary":"In this study, we present a simple and intuitive method for accelerating\noptimal Reeds-Shepp path computation. Our approach uses geometrical reasoning\nto analyze the behavior of optimal paths, resulting in a new partitioning of\nthe state space and a further reduction in the minimal set of viable paths. We\nrevisit and reimplement classic methodologies from the literature, which lack\ncontemporary open-source implementations, to serve as benchmarks for evaluating\nour method. Additionally, we address the under-specified Reeds-Shepp planning\nproblem where the final orientation is unspecified. We perform exhaustive\nexperiments to validate our solutions. Compared to the modern C++\nimplementation of the original Reeds-Shepp solution in the Open Motion Planning\nLibrary, our method demonstrates a 15x speedup, while classic methods achieve a\n5.79x speedup. Both approaches exhibit machine-precision differences in path\nlengths compared to the original solution. We release our proposed C++\nimplementations for both the accelerated and under-specified Reeds-Shepp\nproblems as open-source code.","main_category":"cs.RO","categories":"cs.RO,cs.CG","published":"2025-04-08T11:22:50Z"}
{"aid":"http://arxiv.org/abs/2504.05926v1","title":"The Interconnection Tensor Rank and the Neural Network Storage Capacity","summary":"Neural network properties are considered in the case of the interconnection\ntensor rank being higher than two. This sort of interconnection tensor occurs\nin realization of crossbar-based neural networks. It is intrinsic for a\ncrossbar design to suffer from parasitic currents. It is shown that the\ninterconnection tensor of a certain form makes the neural network much more\nefficient: the storage capacity and basin of attraction of the network increase\nconsiderably. A network like the Hopfield one is used in the study.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,94-10,I.5.1","published":"2025-04-08T11:32:19Z"}
{"aid":"http://arxiv.org/abs/2504.05930v1","title":"Totally equimodular matrices: decomposition and triangulation","summary":"Totally equimodular matrices generalize totally unimodular matrices and arise\nin the context of box-total dual integral polyhedra. This work further explores\nthe parallels between these two classes and introduces foundational building\nblocks for constructing totally equimodular matrices. Consequently, we present\na decomposition theorem for totally equimodular matrices of full row rank.\n  Building on this decomposition theorem, we prove that simplicial cones whose\ngenerators form the rows of a totally equimodular matrix sa\\-tisfy strong\nintegrality decomposition properties. More precisely, we provide the Hilbert\nbasis for these cones and construct regular unimodular Hilbert triangulations\nin most cases. We conjecture that cases not covered here do not exist.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-08T11:40:59Z"}
{"aid":"http://arxiv.org/abs/2504.05934v1","title":"Widening the Role of Group Recommender Systems with CAJO","summary":"Group Recommender Systems (GRSs) have been studied and developed for more\nthan twenty years. However, their application and usage has not grown. They can\neven be labeled as failures, if compared to the very successful and common\nrecommender systems (RSs) used on all the major ecommerce and social platforms.\nAs a result, the RSs that we all use now, are only targeted for individual\nusers, aiming at choosing an item exclusively for themselves; no choice support\nis provided to groups trying to select a service, a product, an experience, a\nperson, serving equally well all the group members. In this opinion article we\ndiscuss why the success of group recommender systems is lagging and we propose\na research program unfolding on the analysis and development of new forms of\ncollaboration between humans and intelligent systems. We define a set of roles,\nnamed CAJO, that GRSs should play in order to become more useful tools for\ngroup decision making.","main_category":"cs.IR","categories":"cs.IR,cs.HC","published":"2025-04-08T11:47:40Z"}
{"aid":"http://arxiv.org/abs/2504.05946v1","title":"InstructMPC: A Human-LLM-in-the-Loop Framework for Context-Aware Control","summary":"Model Predictive Control~(MPC) is a powerful control strategy widely utilized\nin domains like energy management, building control, and autonomous systems.\nHowever, its effectiveness in real-world settings is challenged by the need to\nincorporate context-specific predictions and expert instructions, which\ntraditional MPC often neglects. We propose \\IMPC, a novel framework that\naddresses this gap by integrating real-time human instructions through a Large\nLanguage Model~(LLM) to produce context-aware predictions for MPC. Our method\nemploys a Language-to-Distribution~(L2D) module to translate contextual\ninformation into predictive disturbance trajectories, which are then\nincorporated into the MPC optimization. Unlike existing context-aware and\nlanguage-based MPC models, \\IMPC enables dynamic human-LLM interaction and\nfine-tunes the L2D module in a closed loop with theoretical performance\nguarantees, achieving a regret bound of $O(\\sqrt{T\\log T})$ for linear dynamics\nwhen optimized via advanced fine-tuning methods such as Direct Preference\nOptimization~(DPO) using a tailored loss function.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-08T11:59:00Z"}
{"aid":"http://arxiv.org/abs/2504.05948v1","title":"Control-Oriented Modelling and Adaptive Parameter Estimation for Hybrid\n  Wind-Wave Energy Systems","summary":"Hybrid wind-wave energy system, integrating floating offshore wind turbine\nand wave energy converters, has received much attention in recent years due to\nits potential benefit in increasing the power harvest density and reducing the\nlevelized cost of electricity. Apart from the design complexities of the hybrid\nwind-wave energy systems, their energy conversion efficiency, power output\nsmoothness and their safe operations introduce new challenges for their control\nsystem designs. Recent studies show that advanced model-based control\nstrategies have the great potential to significantly improve their overall\ncontrol performance. However the performance of these advanced control\nstrategies rely on the computationally efficient control-oriented models with\nsufficient fidelity, which are normally difficult to derive due to the\ncomplexity of the hydro-, aero-dynamic effects and the couplings.In most\navailable results, the hybrid wind-wave energy system models are established by\nusing the Boundary Element Method, devoting to understanding the hydrodynamic\nresponses and performance analysis. However, such models are complex and\ninvolved relatively heavy computational burden, which cannot be directly used\nfor the advanced model-based control methods that are essential for improving\npower capture efficiency from implementing in practice. To overcome this issue,\nthis paper proposes a control-oriented model of the hybrid windwave energy\nsystem with six degrees of freedom. First, ...","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-08T12:00:59Z"}
{"aid":"http://arxiv.org/abs/2504.05954v1","title":"Unsupervised Location Mapping for Narrative Corpora","summary":"This work presents the task of unsupervised location mapping, which seeks to\nmap the trajectory of an individual narrative on a spatial map of locations in\nwhich a large set of narratives take place. Despite the fundamentality and\ngenerality of the task, very little work addressed the spatial mapping of\nnarrative texts. The task consists of two parts: (1) inducing a ``map'' with\nthe locations mentioned in a set of texts, and (2) extracting a trajectory from\na single narrative and positioning it on the map. Following recent advances in\nincreasing the context length of large language models, we propose a pipeline\nfor this task in a completely unsupervised manner without predefining the set\nof labels. We test our method on two different domains: (1) Holocaust\ntestimonies and (2) Lake District writing, namely multi-century literature on\ntravels in the English Lake District. We perform both intrinsic and extrinsic\nevaluations for the task, with encouraging results, thereby setting a benchmark\nand evaluation practices for the task, as well as highlighting challenges.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-08T12:06:47Z"}
{"aid":"http://arxiv.org/abs/2504.05958v1","title":"Hybrid Control as a Proxy for Detection and Mitigation of Sensor Attacks\n  in Cooperative Driving","summary":"To enhance the robustness of cooperative driving against cyberattacks, we\npropose a hybrid controller scheme to detect and mitigate False-Data Injection\n(FDI) attacks in real-time. The core of our method builds on a given\nCooperative Adaptive Cruise Control (CACC) algorithm and exploits sensor\nredundancy to construct equivalent controllers, each driven by a distinct,\nnon-overlapping subset of sensors (equivalent controller realizations). By\nconstruction, these controller realizations generate the same control input in\nthe absence of an attack, allowing us to devise an algorithm that compares\ncontrol signals and measurements to pinpoint anomalous behavior via a majority\nvote. This allows us to: 1) decide in real-time which subset of sensors is\ncompromised; and 2) switch to a healthy subset, mitigating thus sensor FDI\nattacks. We model the latter logic as a hybrid dynamic controller that decides\nin real-time what realization to use, builds on attack-dependent flow and jump\nsets, and employs controller resets (to return the state of previously\ncompromised controller realizations to a correct value after the attack stops).\nWe demonstrate the performance of our scheme through simulation experiments.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-08T12:11:57Z"}
{"aid":"http://arxiv.org/abs/2504.05967v1","title":"On the Lipschitz continuity of the Spherical Cap Discrepancy around\n  generic point sets","summary":"The spherical cap discrepancy is a prominent measure of uniformity for sets\non the d-dimensional sphere. It is particularly important for estimating the\nintegration error for certain classes of functions on the sphere. Building on a\nrecently proven explicit formula for the spherical discrepancy, we show as a\nmain result of this paper that this discrepancy is Lipschitz continuous in a\nneighbourhood of so-called generic point sets (as they are typical outcomes of\nMonte-Carlo sampling). This property may have some impact (both algorithmically\nand theoretically for deriving necessary optimality conditions) on optimal\nquantization, i.e., on finding point sets of fixed size on the sphere having\nminimum spherical discrepancy.","main_category":"math.CO","categories":"math.CO,math.OC","published":"2025-04-08T12:25:30Z"}
{"aid":"http://arxiv.org/abs/2504.05968v1","title":"Security Vulnerabilities in Ethereum Smart Contracts: A Systematic\n  Analysis","summary":"Smart contracts are a secure and trustworthy application that plays a vital\nrole in decentralized applications in various fields such as insurance,the\ninternet, and gaming. However, in recent years, smart contract security\nbreaches have occurred frequently, and due to their financial properties, they\nhave caused huge economic losses, such as the most famous security incident\n\"The DAO\" which caused a loss of over \\$60 million in Ethereum. This has drawn\na lot of attention from all sides. Writing a secure smart contract is now a\ncritical issue.This paper focuses on Ether smart contracts and explains the\nmain components of Ether, smart contract architecture and mechanism.The\nenvironment used in this paper is the Ethernet environment, using remix online\ncompilation platform and Solidity language, according to the four security\nevents of American Chain, The DAO, Parity and KotET, the principles of integer\noverflow attack, reentrant attack, access control attack and denial of service\nattack are studied and analyzed accordingly, and the scenarios of these\nvulnerabilities are reproduced, and the measures to prevent them are given.\nFinally, preventive measures are given. In addition, the principles of short\naddress attack, early transaction attack and privileged function exposure\nattack are also introduced in detail, and security measures are proposed.As\nvulnerabilities continue to emerge, their classification will also evolve. The\nanalysis and research of the current vulnerabilities are also to lay a solid\nfoundation for avoiding more vulnerabilities.","main_category":"cs.CR","categories":"cs.CR,D.2.4","published":"2025-04-08T12:25:34Z"}
{"aid":"http://arxiv.org/abs/2504.05970v1","title":"MLPROP -- an open interactive web interface for thermophysical property\n  prediction with machine learning","summary":"Machine learning (ML) enables the development of powerful methods for\npredicting thermophysical properties with unprecedented scope and accuracy.\nHowever, technical barriers like cumbersome implementation in established\nworkflows hinder their application in practice. With MLPROP, we provide an\ninteractive web interface for directly applying advanced ML methods to predict\nthermophysical properties without requiring ML expertise, thereby substantially\nincreasing the accessibility of novel models. MLPROP currently includes models\nfor predicting the vapor pressure of pure components (GRAPPA), activity\ncoefficients and vapor-liquid equilibria in binary mixtures (UNIFAC 2.0, mod.\nUNIFAC 2.0, and HANNA), and a routine to fit NRTL parameters to the model\npredictions. MLPROP will be continuously updated and extended and is accessible\nfree of charge via https://ml-prop.mv.rptu.de/. MLPROP removes the barrier to\nlearning and experimenting with new ML-based methods for predicting\nthermophysical properties. The source code of all models is available as open\nsource, which allows integration into existing workflows.","main_category":"cs.CE","categories":"cs.CE,cs.LG","published":"2025-04-08T12:28:18Z"}
{"aid":"http://arxiv.org/abs/2504.05971v1","title":"Transient population dynamics of nanoparticles during pulsed EUV\n  exposures","summary":"The transient population dynamics of charged (postive or negative) and\nneutral nanoparticles have been investigated in a pulsed Extreme Ultra-Violet\n(EUV) exposure environment with 3DPIC simulations. At the initial stage of the\nsimulation, all the particles are kept neutral. As the number of EUV pulses\nincreases over time, the population of neutral particle decreases faster at the\nexpense of negatively charged particle generation outside the beam location.\nHowever, a small population (< 1%) of neutral particles become positively\ncharged due to EUV photon interaction within the beam area and remains in\nsteady state over time. The critical pulse numbers have been estimated for\ndifferent nanometer size particles above which most of the particles outside\nthe beam locations become negatively charged: smaller is the particle size,\nlarger is the critical pulse number.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-08T12:28:28Z"}
{"aid":"http://arxiv.org/abs/2504.05972v1","title":"Existence of periodic solutions for the Grushin critical problem","summary":"We study a Grushin critical problem in a strip domain which satisfies the\nperiodic boundary conditions. By applying the finite-dimensional reduction\nmethod, we construct a periodic solution when the prescribed curvature function\nis periodic. Furthermore, we also consider the Grushin critical problem in\n$\\mathbb{R}^{N} (N \\geq 5)$. Compared with Billel et al. (Differential Integral\nEquations 32: 49-90, 2019), we use the method by Guo and Yan (Math. Ann. 388:\n795-830, 2024) to construct periodic solutions under some weaker conditions,\navoiding the complicated estimates and uniqueness proof. Notably, Guo and Yan\n(Math. Ann. 388: 795-830, 2024) obtained solutions periodic with respect to\nsome of the first variables, while the solutions in this paper are periodic\nwith respect to some intermediate variables.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T12:29:32Z"}
{"aid":"http://arxiv.org/abs/2504.05974v1","title":"The Higgs trilinear coupling in the SMEFT at the HL-LHC and the FCC-ee","summary":"Motivated by the updated HL-LHC projections for Higgs pair production from\nATLAS and CMS and by the release of the FCC-ee Feasibility Study, we critically\nrevisit the sensitivity of the global SMEFT analysis to deformations of the\nHiggs self-coupling modifier $\\kappa_3$. To this end, we quantify the impact of\nSMEFT operators modifying double Higgs production at the LHC and single Higgs\nproduction, including loop corrections, at the FCC-ee, and include\nRenormalisation Group Evolution throughout. We demonstrate that significantly\nimproving on the legacy HL-LHC constraints on $\\kappa_3$ at the FCC-ee is not\npossible without the $\\sqrt{s}=365$ GeV run; that individual and marginalised\ndeterminations are similar at the HL-LHC while differing by up to a factor 3 at\nthe FCC-ee; and that quadratic EFT corrections cannot be neglected. Overall,\nthe combination of HL-LHC and FCC-ee data offers unique potential to pin down\nthe Higgs self-coupling with $\\sim$$15\\%$ precision.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-08T12:30:44Z"}
{"aid":"http://arxiv.org/abs/2504.05975v1","title":"A Corrector-aided Look-ahead Distance-based Guidance for Reference Path\n  Following with an Efficient Midcourse Guidance Strategy","summary":"Efficient path-following is crucial in most of the applications of autonomous\nvehicles (UxV). Among various guidance strategies presented in literature,\nlook-ahead distance ($L_1$)-based guidance method has received significant\nattention due to its ease in implementation and ability to maintain a low\ncross-track error while following simpler reference paths and generate bounded\nlateral acceleration commands. However, the constant value of $L_1$ becomes\nproblematic when the UxV is far away from the reference path and also produce\nhigher cross-track error while following complex reference paths having high\nvariation in radius of curvature. To address these challenges, the notion of\nlook-ahead distance is leveraged in a novel way to develop a two-phase guidance\nstrategy. Initially, when the UxV is far from the reference path, an optimized\n$L_1$ selection strategy is developed to guide the UxV toward the reference\npath in order to maintain minimal lateral acceleration command. Once the\nvehicle reaches a close vicinity of the reference path, a novel notion of\ncorrector point is incorporated in the constant $L_1$-based guidance scheme to\ngenerate the lateral acceleration command that effectively reduces the root\nmean square of the cross-track error thereafter. Simulation results demonstrate\nthat this proposed corrector point and look-ahead point pair-based guidance\nstrategy along with the developed midcourse guidance scheme outperforms the\nconventional constant $L_1$ guidance scheme both in terms of feasibility and\nmeasures of effectiveness like cross-track error and lateral acceleration\nrequirements.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-08T12:31:19Z"}
{"aid":"http://arxiv.org/abs/2504.05991v1","title":"On non-local exchange and scattering operators in domain decomposition\n  methods","summary":"We study non-local exchange and scattering operators arising in domain\ndecomposition algorithms for solving elliptic problems on domains in\n$\\mathbb{R}^2$. Motivated by recent formulations of the Optimized Schwarz\nMethod introduced by Claeys, we rigorously analyze the behavior of a family of\nnon-local exchange operators $\\Pi_\\gamma$, defined in terms of boundary\nintegral operators associated to the fundamental solution for $-\\Delta +\n\\gamma^{-2}$, with $\\gamma > 0$. Our first main result establishes precise\nestimates comparing $\\Pi_\\gamma$ to its local counterpart $\\Pi_0$ as $\\gamma\n\\to 0$, providing a quantitative bridge between the classical and non-local\nformulations of the Optimized Schwarz Method. In addition, we investigate the\ncorresponding scattering operators, proving norm estimates that relate them to\ntheir classical analogues through a detailed analysis of the associated\nDirichlet-to-Neumann operators. Our results clarify the relationship between\nclassical and non-local formulations of domain decomposition methods and yield\nnew insights that are essential for the analysis of these algorithms,\nparticularly in the presence of cross points and for domains with curvilinear\npolygonal boundaries.","main_category":"math.NA","categories":"math.NA,cs.NA,math.AP","published":"2025-04-08T12:54:54Z"}
{"aid":"http://arxiv.org/abs/2504.05994v1","title":"Quantitative Spectral Stability for the Robin Laplacian","summary":"This paper deals with eigenelements of the Laplacian in bounded domains,\nunder Robin boundary conditions, without any assumption on the sign of the\nRobin parameter. We quantify the asymptotics of the variation of simple\neigenvalues under the singular perturbation produced by removing a shrinking\nset and imposing the same Robin condition on its boundary. We also study the\nconvergence rate of the corresponding eigenfunctions.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T12:56:55Z"}
{"aid":"http://arxiv.org/abs/2504.05995v1","title":"NativQA Framework: Enabling LLMs with Native, Local, and Everyday\n  Knowledge","summary":"The rapid advancement of large language models (LLMs) has raised concerns\nabout cultural bias, fairness, and their applicability in diverse linguistic\nand underrepresented regional contexts. To enhance and benchmark the\ncapabilities of LLMs, there is a need to develop large-scale resources focused\non multilingual, local, and cultural contexts. In this study, we propose a\nframework, NativQA, that can seamlessly construct large-scale, culturally and\nregionally aligned QA datasets in native languages. The framework utilizes\nuser-defined seed queries and leverages search engines to collect\nlocation-specific, everyday information. It has been evaluated across 39\nlocations in 24 countries and in 7 languages, ranging from extremely\nlow-resource to high-resource languages, which resulted over 300K Question\nAnswer (QA) pairs. The developed resources can be used for LLM benchmarking and\nfurther fine-tuning. The framework has been made publicly available for the\ncommunity (https://gitlab.com/nativqa/nativqa-framework).","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-08T13:01:51Z"}
{"aid":"http://arxiv.org/abs/2504.06004v1","title":"FedFeat+: A Robust Federated Learning Framework Through Federated\n  Aggregation and Differentially Private Feature-Based Classifier Retraining","summary":"In this paper, we propose the FedFeat+ framework, which distinctively\nseparates feature extraction from classification. We develop a two-tiered model\ntraining process: following local training, clients transmit their weights and\nsome features extracted from the feature extractor from the final local epochs\nto the server. The server aggregates these models using the FedAvg method and\nsubsequently retrains the global classifier utilizing the shared features. The\nclassifier retraining process enhances the model's understanding of the\nholistic view of the data distribution, ensuring better generalization across\ndiverse datasets. This improved generalization enables the classifier to\nadaptively influence the feature extractor during subsequent local training\nepochs. We establish a balance between enhancing model accuracy and\nsafeguarding individual privacy through the implementation of differential\nprivacy mechanisms. By incorporating noise into the feature vectors shared with\nthe server, we ensure that sensitive data remains confidential. We present a\ncomprehensive convergence analysis, along with theoretical reasoning regarding\nperformance enhancement and privacy preservation. We validate our approach\nthrough empirical evaluations conducted on benchmark datasets, including\nCIFAR-10, CIFAR-100, MNIST, and FMNIST, achieving high accuracy while adhering\nto stringent privacy guarantees. The experimental results demonstrate that the\nFedFeat+ framework, despite using only a lightweight two-layer CNN classifier,\noutperforms the FedAvg method in both IID and non-IID scenarios, achieving\naccuracy improvements ranging from 3.92 % to 12.34 % across CIFAR-10,\nCIFAR-100, and Fashion-MNIST datasets.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T13:12:38Z"}
{"aid":"http://arxiv.org/abs/2504.06005v1","title":"A deep search for Complex Organic Molecules toward the protoplanetary\n  disk of V883 Ori","summary":"Complex Organic Molecules (COMs) in the form of prebiotic molecules are\npotentially building blocks of life. Using Atacama Large\nMillimeter/submillimeter Array (ALMA) Band 7 observations in spectral scanning\nmode, we carried out a deep search for COMs within the disk of V883 Ori,\ncovering frequency ranges of $\\sim$ 348 - 366 GHz. V883 Ori is an FUor object\ncurrently undergoing an accretion burst, which increases its luminosity and\nconsequently increases the temperature of the surrounding protoplanetary disk,\nfacilitating the detection of COMs in the gas phase. We identified 26\nmolecules, including 14 COMs and 12 other molecules, with first detection in\nthis source of the molecules: CH3OD, H2C17O, and H213CO. We searched for\nmultiple nitrogen-bearing COMs, as CH3CN had been the only nitrogen-bearing COM\nthat has been identified so far in this source. We also detected CH3CN, and\ntentatively detect CH3CH2CN, CH2CHCN, CH3OCN, CH3NCO, and NH2CHO. We compared\nthe abundances relative to CH3OH with those in the handful of objects with\nprevious detections of these species: the Class 0 protostars IRAS 16293-2422 A,\nIRAS 16293-2422 B and B1-c, the high-mass star-forming region Sagittarius B2\n(North), the Solar System comet 67P/Churyumov-Gerasimenko, and the\nprotoplanetary disk of Oph-IRS 48. We report $\\sim$ 1 to 3 orders of magnitude\nhigher abundances compared to Class 0 protostars and $\\sim$ 1 to 3 orders of\nmagnitude lower abundances compared to the protoplanetary disk, Sagittarius B2\n(North), and 67P/C-G. These results indicate that the protoplanetary disk phase\ncould contribute to build up of COMs.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP,astro-ph.GA","published":"2025-04-08T13:15:46Z"}
{"aid":"http://arxiv.org/abs/2504.06010v1","title":"Latent Multimodal Reconstruction for Misinformation Detection","summary":"Multimodal misinformation, such as miscaptioned images, where captions\nmisrepresent an image's origin, context, or meaning, poses a growing challenge\nin the digital age. To support fact-checkers, researchers have been focusing on\ncreating datasets and developing methods for multimodal misinformation\ndetection (MMD). Due to the scarcity of large-scale annotated MMD datasets,\nrecent studies leverage synthetic training data via out-of-context\nimage-caption pairs or named entity manipulations; altering names, dates, and\nlocations. However, these approaches often produce simplistic misinformation\nthat fails to reflect real-world complexity, limiting the robustness of\ndetection models trained on them. Meanwhile, despite recent advancements, Large\nVision-Language Models (LVLMs) remain underutilized for generating diverse,\nrealistic synthetic training data for MMD. To address this gap, we introduce\n\"MisCaption This!\", a training dataset comprising LVLM-generated miscaptioned\nimages. Additionally, we introduce \"Latent Multimodal Reconstruction\" (LAMAR),\na network trained to reconstruct the embeddings of truthful captions, providing\na strong auxiliary signal to the detection process. To optimize LAMAR, we\nexplore different training strategies (end-to-end training and large-scale\npre-training) and integration approaches (direct, mask, gate, and attention).\nExtensive experiments show that models trained on \"MisCaption This!\" generalize\nbetter on real-world misinformation, while LAMAR sets new state-of-the-art on\nboth NewsCLIPpings and VERITE benchmarks; highlighting the potential of\nLVLM-generated data and reconstruction-based approaches for advancing MMD. We\nrelease our code at:\nhttps://github.com/stevejpapad/miscaptioned-image-reconstruction","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-08T13:16:48Z"}
{"aid":"http://arxiv.org/abs/2504.06022v1","title":"CamContextI2V: Context-aware Controllable Video Generation","summary":"Recently, image-to-video (I2V) diffusion models have demonstrated impressive\nscene understanding and generative quality, incorporating image conditions to\nguide generation. However, these models primarily animate static images without\nextending beyond their provided context. Introducing additional constraints,\nsuch as camera trajectories, can enhance diversity but often degrades visual\nquality, limiting their applicability for tasks requiring faithful scene\nrepresentation. We propose CamContextI2V, an I2V model that integrates multiple\nimage conditions with 3D constraints alongside camera control to enrich both\nglobal semantics and fine-grained visual details. This enables more coherent\nand context-aware video generation. Moreover, we motivate the necessity of\ntemporal awareness for an effective context representation. Our comprehensive\nstudy on the RealEstate10K dataset demonstrates improvements in visual quality\nand camera controllability. We make our code and models publicly available at:\nhttps://github.com/LDenninger/CamContextI2V.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T13:26:59Z"}
{"aid":"http://arxiv.org/abs/2504.06030v1","title":"NQG III -- Two-Centre Problems, Whirlpool Galaxy and Toy Neutron Stars","summary":"In the hunt for WIMPish dark matter and testing our new theory, we extend the\nresults obtained for the Kepler problem in NQG I and NQG II to the Euler\ntwo-centre problem and to other classical Hamiltonian systems with planar\nperiodic orbits. In the first case our results lead to quantum elliptical\nspirals converging to elliptical orbits where stars and other celestial bodies\ncan form as the corresponding WIMP/molecular clouds condense. The examples\ninevitably involve elliptic integrals as was the case in our earlier work on\nequatorial orbits of toy neutron stars (see Ref. [27]). Hence this is the\nexample on which we focus in this work on quantisation. The main part of our\nanalysis which leans heavily on Hamilton-Jacobi theory is applicable to any\nKLMN integrable planar periodic orbits for Hamiltonian systems. The most useful\nresults on Weierstrass elliptic functions needed in these two works we have\nsummarised with complete proofs in the appendix. This has been one of the most\nenjoyable parts of this research understanding in more detail the genius of\nWeierstrass and Jacobi. However we have to say that the beautiful simplicity of\nthe Euler two-centre results herein transcend even this as far as we are\nconcerned. At the end of the paper we see how the Burgers-Zeldovich fluid model\nrelates to our set-up through Nelson's stochastic mechanics.","main_category":"math-ph","categories":"math-ph,astro-ph.GA,math.MP","published":"2025-04-08T13:34:33Z"}
{"aid":"http://arxiv.org/abs/2504.06039v1","title":"Enhanced Anomaly Detection for Capsule Endoscopy Using Ensemble Learning\n  Strategies","summary":"Capsule endoscopy is a method to capture images of the gastrointestinal tract\nand screen for diseases which might remain hidden if investigated with standard\nendoscopes. Due to the limited size of a video capsule, embedding AI models\ndirectly into the capsule demands careful consideration of the model size and\nthus complicates anomaly detection in this field. Furthermore, the scarcity of\navailable data in this domain poses an ongoing challenge to achieving effective\nanomaly detection. Thus, this work introduces an ensemble strategy to address\nthis challenge in anomaly detection tasks in video capsule endoscopies,\nrequiring only a small number of individual neural networks during both the\ntraining and inference phases. Ensemble learning combines the predictions of\nmultiple independently trained neural networks. This has shown to be highly\neffective in enhancing both the accuracy and robustness of machine learning\nmodels. However, this comes at the cost of higher memory usage and increased\ncomputational effort, which quickly becomes prohibitive in many real-world\napplications. Instead of applying the same training algorithm to each\nindividual network, we propose using various loss functions, drawn from the\nanomaly detection field, to train each network. The methods are validated on\nthe two largest publicly available datasets for video capsule endoscopy images,\nthe Galar and the Kvasir-Capsule dataset. We achieve an AUC score of 76.86% on\nthe Kvasir-Capsule and an AUC score of 76.98% on the Galar dataset. Our\napproach outperforms current baselines with significantly fewer parameters\nacross all models, which is a crucial step towards incorporating artificial\nintelligence into capsule endoscopies.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T13:39:39Z"}
{"aid":"http://arxiv.org/abs/2504.06042v1","title":"An Adaptive Algorithm for Bilevel Optimization on Riemannian Manifolds","summary":"Existing methods for solving Riemannian bilevel optimization (RBO) problems\nrequire prior knowledge of the problem's first- and second-order information\nand curvature parameter of the Riemannian manifold to determine step sizes,\nwhich poses practical limitations when these parameters are unknown or\ncomputationally infeasible to obtain. In this paper, we introduce the Adaptive\nRiemannian Hypergradient Descent (AdaRHD) algorithm for solving RBO problems.\nTo the best of our knowledge, AdaRHD is the first method to incorporate a fully\nadaptive step size strategy that eliminates the need for problem-specific\nparameters. We prove that AdaRHD achieves an $\\mathcal{O}(1/\\epsilon)$\niteration complexity for finding an $\\epsilon$-stationary point, thus matching\nthe complexity of existing non-adaptive methods. Furthermore, we demonstrate\nthat substituting exponential mappings with retraction mappings maintains the\nsame complexity bound. Experiments demonstrate that AdaRHD achieves comparable\nperformance to existing non-adaptive approaches while exhibiting greater\nrobustness.","main_category":"math.OC","categories":"math.OC","published":"2025-04-08T13:42:18Z"}
{"aid":"http://arxiv.org/abs/2504.06049v1","title":"Directed LS category and directed parametrized topological complexity","summary":"We introduce and study a parametrized analogue of the directed topological\ncomplexity, originally developed by Goubault, Farber, and Sagnier. We establish\nthe fibrewise basic dihomotopy invariance of directed parametrized topological\ncomplexity and explore its relationship with the parametrized topological\ncomplexity. In addition, we introduce the concept of the directed\nLusternik$-$Schnirelmann (LS) category, prove its basic dihomotopy invariance,\nand investigate its connections with both directed topological complexity and\ndirected parametrized topological complexity. As an application, we show that\nthe directed LS category of the directed spheres is equal to two.","main_category":"math.AT","categories":"math.AT","published":"2025-04-08T13:47:09Z"}
{"aid":"http://arxiv.org/abs/2504.06053v1","title":"Characteristic exciton energy scales in antiferromagnetic NiPS$_3$","summary":"Two-dimensional antiferromagnets are promising materials for spintronics. The\nvan der Waals antiferromagnet NiPS$_3$ has attracted extensive interest due to\nits ultra-narrow exciton feature which is closely linked with the magnetic\nordering. Here, we use time-resolved terahertz spectroscopy to investigate\nphoto-excited carriers in NiPS$_3$. We identify the onset of interband\ntransitions and estimate the exciton dissociation energy from the excitation\nwavelength and fluence dependence of the transient spectral weight. Our results\nprovide key insights to quantify the exciton characteristics and validate the\nband structure for NiPS$_3$.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci","published":"2025-04-08T13:55:55Z"}
{"aid":"http://arxiv.org/abs/2504.06054v1","title":"Thermodynamic formalism for Quasi-Morphisms: Bounded Cohomology and\n  Statistics","summary":"For a compact negatively curved space, we develop a notion of thermodynamic\nformalism and apply it to study the space of quasi-morphisms of its fundamental\ngroup modulo boundedness. We prove that this space is Banach isomorphic to the\nspace of Bowen functions corresponding to the associated Gromov geodesic flow,\nmodulo a weak notion of Livsic cohomology.\n  The results include that each such unbounded quasi-morphism is associated\nwith a unique invariant measure for the flow, and this measure uniquely\ncharacterizes the cohomology class. As a consequence, we establish the Central\nLimit Theorem for any unbounded quasi-morphism with respect to Markov measures,\nthe invariance principle, and the Bernoulli property of the associated\nequilibrium state.","main_category":"math.DS","categories":"math.DS,math.GT","published":"2025-04-08T13:59:30Z"}
{"aid":"http://arxiv.org/abs/2504.06073v1","title":"A Data-constrained Magnetohydrodynamic Simulation of Successive X-class\n  Flares in Solar Active Region 13842 I. Dynamics of the Solar Eruption\n  Associated with the X7.1 Solar Flare","summary":"We investigated the initiation and the evolution of an X7.1-class solar flare\nobserved in solar active region NOAA 13842 on October 1, 2024, based on a\ndata-constrained magnetohydrodynamic (MHD) simulation. The nonlinear force-free\nfield (NLFFF) extrapolated from the photospheric magnetic field about 1 hour\nbefore the flare was used as the initial condition for the MHD simulations. The\nNLFFF reproduces highly sheared field lines that undergo tether-cutting\nreconnection in the MHD simulation, leading to the formation of a highly\ntwisted magnetic flux rope (MFR), which then erupts rapidly driven by both\ntorus instability and magnetic reconnection. This paper focuses on the dynamics\nof the MFR and its role in eruptions. We find that magnetic reconnection in the\npre-eruption phase is crucial in the subsequent eruption driven by the torus\ninstability. Furthermore, our simulation indicates that magnetic reconnection\nalso directly enhances the torus instability. These results suggest that\nmagnetic reconnection is not just a byproduct of the eruption due to\nreconnecting of post-flare arcade, but also plays a significant role in\naccelerating the MFR during the eruption.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-08T14:12:15Z"}
{"aid":"http://arxiv.org/abs/2504.06075v1","title":"Collaborative Prediction: Tractable Information Aggregation via\n  Agreement","summary":"We give efficient \"collaboration protocols\" through which two parties, who\nobserve different features about the same instances, can interact to arrive at\npredictions that are more accurate than either could have obtained on their\nown. The parties only need to iteratively share and update their own label\npredictions-without either party ever having to share the actual features that\nthey observe. Our protocols are efficient reductions to the problem of learning\non each party's feature space alone, and so can be used even in settings in\nwhich each party's feature space is illegible to the other-which arises in\nmodels of human/AI interaction and in multi-modal learning. The communication\nrequirements of our protocols are independent of the dimensionality of the\ndata. In an online adversarial setting we show how to give regret bounds on the\npredictions that the parties arrive at with respect to a class of benchmark\npolicies defined on the joint feature space of the two parties, despite the\nfact that neither party has access to this joint feature space. We also give\nsimpler algorithms for the same task in the batch setting in which we assume\nthat there is a fixed but unknown data distribution. We generalize our\nprotocols to a decision theoretic setting with high dimensional outcome spaces,\nwhere parties communicate only \"best response actions.\"\n  Our theorems give a computationally and statistically tractable\ngeneralization of past work on information aggregation amongst Bayesians who\nshare a common and correct prior, as part of a literature studying \"agreement\"\nin the style of Aumann's agreement theorem. Our results require no knowledge of\n(or even the existence of) a prior distribution and are computationally\nefficient. Nevertheless we show how to lift our theorems back to this classical\nBayesian setting, and in doing so, give new information aggregation theorems\nfor Bayesian agreement.","main_category":"cs.LG","categories":"cs.LG,cs.DS,cs.GT","published":"2025-04-08T14:12:42Z"}
{"aid":"http://arxiv.org/abs/2504.06076v1","title":"$K_4^-$-free triple systems without large stars in the complement","summary":"The $n$-star $S_n$ is the $n$-vertex triple system with ${n-1 \\choose 2}$\nedges all of which contain a fixed vertex, and $K_4^-$ is the unique triple\nsystem with four vertices and three edges. We prove that the Ramsey number\n$r(K_4^-, S_n)$ has order of magnitude $n^2 /\\log n$.\n  This confirms a conjecture of Conlon, Fox, He, Suk, Verstra\\\"ete and the\nfirst author. It also generalizes the well-known bound of Kim for the graph\nRamsey number $r(3,n)$, as the link of any vertex in a $K_4^-$-free triple\nsystem is a triangle-free graph. Our method builds on the approach of Guo and\nWarnke who adapted Kim's lower bound for $r(3,n)$ to the pseudorandom setting.","main_category":"math.CO","categories":"math.CO","published":"2025-04-08T14:15:43Z"}
{"aid":"http://arxiv.org/abs/2504.06079v1","title":"Geometric Bipartite Matching Based Exact Algorithms for Server Problems","summary":"For any given metric space, obtaining an offline optimal solution to the\nclassical $k$-server problem can be reduced to solving a minimum-cost partial\nbipartite matching between two point sets $A$ and $B$ within that metric space.\n  For $d$-dimensional $\\ell_p$ metric space, we present an $\\tilde{O}(\\min\\{nk,\nn^{2-\\frac{1}{2d+1}}\\log \\Delta\\}\\cdot \\Phi(n))$ time algorithm for solving\nthis instance of minimum-cost partial bipartite matching; here, $\\Delta$\nrepresents the spread of the point set, and $\\Phi(n)$ is the query/update time\nof a $d$-dimensional dynamic weighted nearest neighbor data structure. Our\nalgorithm improves upon prior algorithms that require at least\n$\\Omega(nk\\Phi(n))$ time. The design of minimum-cost (partial) bipartite\nmatching algorithms that make sub-quadratic queries to a weighted\nnearest-neighbor data structure, even for bounded spread instances, is a major\nopen problem in computational geometry. We resolve this problem at least for\nthe instances that are generated by the offline version of the $k$-server\nproblem.\n  Our algorithm employs a hierarchical partitioning approach, dividing the\npoints of $A\\cup B$ into rectangles. It maintains a minimum-cost partial\nmatching where any point $b \\in B$ is either matched to a point $a\\in A$ or to\nthe boundary of the rectangle it is located in. The algorithm involves\niteratively merging pairs of rectangles by erasing the shared boundary between\nthem and recomputing the minimum-cost partial matching. This continues until\nall boundaries are erased and we obtain the desired minimum-cost partial\nmatching of $A$ and $B$. We exploit geometry in our analysis to show that each\npoint participates in only $\\tilde{O}(n^{1-\\frac{1}{2d+1}}\\log \\Delta)$ number\nof augmenting paths, leading to a total execution time of\n$\\tilde{O}(n^{2-\\frac{1}{2d+1}}\\Phi(n)\\log \\Delta)$.","main_category":"cs.CG","categories":"cs.CG","published":"2025-04-08T14:19:12Z"}
{"aid":"http://arxiv.org/abs/2504.06083v1","title":"Security Analysis of Thumbnail-Preserving Image Encryption and a New\n  Framework","summary":"As a primary encryption primitive balancing the privacy and searchability of\ncloud storage images, thumbnail preserving encryption (TPE) enables users to\nquickly identify the privacy personal image on the cloud and request this image\nfrom the owner through a secure channel. In this paper, we have found that two\ndifferent plaintext images may produce the same thumbnail. It results in the\nfailure of search strategy because the collision of thumbnail occurs. To\naddress this serious security issues, we conduct an in-depth analysis on the\ncollision probabilities of thumbnails, and then propose a new TPE framework,\ncalled multi-factor thumbnail preserving encryption (MFTPE). It starts from the\ncollision probability of two blocks, extend to the probabilities of two images\nand ultimately to N images. Then, we in detail describe three specific MFTPE\nconstructions preserving different combinations of factors, i.e., the sum and\nthe geometric mean, the sum and the range, and the sum and the weighted mean.\nThe theoretical and experimental results demonstrate that the proposed MFTPE\nreduces the probability of thumbnails, exhibits strong robustness, and also\neffectively resists face detection and noise attacks.","main_category":"cs.CR","categories":"cs.CR,cs.MM","published":"2025-04-08T14:24:43Z"}
{"aid":"http://arxiv.org/abs/2504.06084v1","title":"MAPLE: Encoding Dexterous Robotic Manipulation Priors Learned From\n  Egocentric Videos","summary":"Large-scale egocentric video datasets capture diverse human activities across\na wide range of scenarios, offering rich and detailed insights into how humans\ninteract with objects, especially those that require fine-grained dexterous\ncontrol. Such complex, dexterous skills with precise controls are crucial for\nmany robotic manipulation tasks, yet are often insufficiently addressed by\ntraditional data-driven approaches to robotic manipulation. To address this\ngap, we leverage manipulation priors learned from large-scale egocentric video\ndatasets to improve policy learning for dexterous robotic manipulation tasks.\nWe present MAPLE, a novel method for dexterous robotic manipulation that\nexploits rich manipulation priors to enable efficient policy learning and\nbetter performance on diverse, complex manipulation tasks. Specifically, we\npredict hand-object contact points and detailed hand poses at the moment of\nhand-object contact and use the learned features to train policies for\ndownstream manipulation tasks. Experimental results demonstrate the\neffectiveness of MAPLE across existing simulation benchmarks, as well as a\nnewly designed set of challenging simulation tasks, which require fine-grained\nobject control and complex dexterous skills. The benefits of MAPLE are further\nhighlighted in real-world experiments using a dexterous robotic hand, whereas\nsimultaneous evaluation across both simulation and real-world experiments has\nremained underexplored in prior work.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-08T14:25:25Z"}
{"aid":"http://arxiv.org/abs/2504.06115v1","title":"In search of almost generic Calabi-Yau 3-folds","summary":"We call a projective Calabi-Yau (CY) 3-fold almost generic if it has only\nisolated nodes as singularities and the homology classes of all of the\nexceptional curves in an analytic small resolution are non-trivial but torsion.\nSuch a Calabi-Yau supports a topologically non-trivial flat B-field and the\ncorresponding A-model topological string partition function encodes a torsion\nrefinement of the Gopakumar-Vafa invariants of the smooth deformation. Our goal\nin this paper is to find new examples of almost generic CY 3-folds, using both\nconifold transitions as well as the integral structure of the periods of the\nmirrors. In this way we explicitly construct two quintic CY 3-folds with\n$\\mathbb{Z}_2$-torsion, two octics with $\\mathbb{Z}_3$-torsion and deduce the\nexistence of a complete intersection\n$X_{(6,6)}\\subset\\mathbb{P}^5_{1,1,2,2,3,3}$ with $\\mathbb{Z}_5$-torsion. Via\nmirror symmetry, the examples give new geometric interpretations to several\nAESZ Calabi-Yau operators. The mirror periods of the almost generic $X_{(6,6)}$\nwith non-trivial B-field topology are annihilated by an irrational Picard-Fuchs\noperator. We describe how the usual integral structure of the periods has to be\nmodified and in all of the cases we calculate the monodromies around the\nsingular points to verify integrality. Additional points of maximally unipotent\nmonodromy in the moduli spaces lead us to find several more examples of smooth\nor almost generic CY 3-folds and to conjecture new twisted derived\nequivalences. We integrate the holomorphic anomaly equations and extract the\ntorsion refined Gopakumar-Vafa invariants up to varying genus. For our\nconstruction of the almost generic octic CY 3-folds, we also give a short\nintroduction to the subject of hypermatrices and hyperdeterminants.","main_category":"hep-th","categories":"hep-th,math.AG","published":"2025-04-08T15:07:42Z"}
{"aid":"http://arxiv.org/abs/2504.06119v1","title":"Variational discretizations of viscous and resistive\n  magnetohydrodynamics using structure-preserving finite elements","summary":"We propose a novel structure preserving discretization for viscous and\nresistive magnetohydrodynamics. We follow the recent line of work on discrete\nleast action principle for fluid and plasma equation, incorporating the recent\nadvances to model dissipative phenomena through a generalized Lagrange-d\nAlembert constrained variational principle. We prove that our semi-discrete\nscheme is equivalent to a metriplectic system and use this property to propose\na Poisson splitting time integration. The resulting approximation preserves\nmass, energy and the divergence constraint of the magnetic field. We then show\nsome numerical results obtained with our approach. We first test our scheme on\nsimple academic test to compare the results with established methodologies, and\nthen focus specifically on the simulation of plasma instabilities, with some\ntests on non Cartesian geometries to validate our discretization in the scope\nof tokamak instabilities.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-08T15:12:32Z"}
{"aid":"http://arxiv.org/abs/2504.06123v1","title":"Equating quantum imaginary time evolution, Riemannian gradient flows,\n  and stochastic implementations","summary":"We identify quantum imaginary time evolution as a Riemannian gradient flow on\nthe unitary group. We develop an upper bound for the error between the two\nevolutions that can be controlled through the step size of the Riemannian\ngradient descent which minimizes the energy of the system. We discuss\nimplementations through adaptive quantum algorithms and present a stochastic\nRiemannian gradient descent algorithm in which each step is efficiently\nimplementable on a quantum computer. We prove that for a sufficiently small\nstep size, the stochastic evolution concentrates around the imaginary time\nevolution, thereby providing performance guarantees for cooling the system\nthrough stochastic Riemannian gradient descent.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T15:17:05Z"}
{"aid":"http://arxiv.org/abs/2504.06134v1","title":"SpikeStream: Accelerating Spiking Neural Network Inference on RISC-V\n  Clusters with Sparse Computation Extensions","summary":"Spiking Neural Network (SNN) inference has a clear potential for high energy\nefficiency as computation is triggered by events. However, the inherent\nsparsity of events poses challenges for conventional computing systems, driving\nthe development of specialized neuromorphic processors, which come with high\nsilicon area costs and lack the flexibility needed for running other\ncomputational kernels, limiting widespread adoption. In this paper, we explore\nthe low-level software design, parallelization, and acceleration of SNNs on\ngeneral-purpose multicore clusters with a low-overhead RISC-V ISA extension for\nstreaming sparse computations. We propose SpikeStream, an optimization\ntechnique that maps weights accesses to affine and indirect register-mapped\nmemory streams to enhance performance, utilization, and efficiency. Our results\non the end-to-end Spiking-VGG11 model demonstrate a significant 4.39x speedup\nand an increase in utilization from 9.28% to 52.3% compared to a non-streaming\nparallel baseline. Additionally, we achieve an energy efficiency gain of 3.46x\nover LSMCore and a performance gain of 2.38x over Loihi.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-08T15:28:44Z"}
{"aid":"http://arxiv.org/abs/2504.06138v1","title":"A Multimedia Analytics Model for the Foundation Model Era","summary":"The rapid advances in Foundation Models and agentic Artificial Intelligence\nare transforming multimedia analytics by enabling richer, more sophisticated\ninteractions between humans and analytical systems. Existing conceptual models\nfor visual and multimedia analytics, however, do not adequately capture the\ncomplexity introduced by these powerful AI paradigms. To bridge this gap, we\npropose a comprehensive multimedia analytics model specifically designed for\nthe foundation model era. Building upon established frameworks from visual\nanalytics, multimedia analytics, knowledge generation, analytic task\ndefinition, mixed-initiative guidance, and human-in-the-loop reinforcement\nlearning, our model emphasizes integrated human-AI teaming based on visual\nanalytics agents from both technical and conceptual perspectives. Central to\nthe model is a seamless, yet explicitly separable, interaction channel between\nexpert users and semi-autonomous analytical processes, ensuring continuous\nalignment between user intent and AI behavior. The model addresses practical\nchallenges in sensitive domains such as intelligence analysis, investigative\njournalism, and other fields handling complex, high-stakes data. We illustrate\nthrough detailed case studies how our model facilitates deeper understanding\nand targeted improvement of multimedia analytics solutions. By explicitly\ncapturing how expert users can optimally interact with and guide AI-powered\nmultimedia analytics systems, our conceptual framework sets a clear direction\nfor system design, comparison, and future research.","main_category":"cs.MM","categories":"cs.MM,cs.AI,cs.HC","published":"2025-04-08T15:35:59Z"}
{"aid":"http://arxiv.org/abs/2504.06145v1","title":"Deploying Chatbots in Customer Service: Adoption Hurdles and Simple\n  Remedies","summary":"Despite recent advances in Artificial Intelligence, the use of chatbot\ntechnology in customer service continues to face adoption hurdles. This paper\nexplores reasons for these adoption hurdles and tests several service design\nlevers to increase chatbot uptake. We use incentivized online experiments to\nstudy chatbot uptake in a variety of scenarios. The results of these\nexperiments are threefold. First, people respond positively to improvements in\nchatbot performance; however, the chatbot channel is utilized less frequently\nthan expected-time minimization would predict. A key driver of this\nunderutilization is the reluctance to engage with a gatekeeper process, i.e., a\nprocess with an imperfect initial service stage and possible transfer to a\nsecond, expert service stage -- a behavior we term \"gatekeeper aversion\". We\nshow that gatekeeper aversion can be further amplified by a secondary hurdle,\nalgorithm aversion. Second, chatbot uptake can be increased by providing\ncustomers with average waiting times in the chatbot channel, as well as by\nbeing more transparent about chatbot capabilities and limitations. Third,\nmethodologically, we show that chatbot adoption can depend on experimental\nimplementation. In particular, chatbot adoption decreases further as (i) stakes\nare increased, (ii) the human/algorithmic nature of the server is manipulated\nwith more realism. Our results suggest that firms should continue to prioritize\ninvestments in chatbot technology. However, less expensive, process-related\ninterventions can also be effective. These may include being more transparent\nabout the types of queries that are (or are not) suitable for chatbots,\nemphasizing chatbot reliability and quick resolution times, as well as\nproviding faster live agent access to customers who experienced chatbot\nfailure.","main_category":"cs.HC","categories":"cs.HC,econ.GN,q-fin.EC,J.4","published":"2025-04-08T15:40:31Z"}
{"aid":"http://arxiv.org/abs/2504.06148v1","title":"V-MAGE: A Game Evaluation Framework for Assessing Visual-Centric\n  Capabilities in Multimodal Large Language Models","summary":"Recent advancements in Multimodal Large Language Models (MLLMs) have led to\nsignificant improvements across various multimodal benchmarks. However, as\nevaluations shift from static datasets to open-world, dynamic environments,\ncurrent game-based benchmarks remain inadequate because they lack\nvisual-centric tasks and fail to assess the diverse reasoning skills required\nfor real-world decision-making. To address this, we introduce Visual-centric\nMultiple Abilities Game Evaluation (V-MAGE), a game-based evaluation framework\ndesigned to assess visual reasoning capabilities of MLLMs. V-MAGE features five\ndiverse games with 30+ handcrafted levels, testing models on core visual skills\nsuch as positioning, trajectory tracking, timing, and visual memory, alongside\nhigher-level reasoning like long-term planning and deliberation. We use V-MAGE\nto evaluate leading MLLMs, revealing significant challenges in their visual\nperception and reasoning. In all game environments, the top-performing MLLMs,\nas determined by Elo rating comparisons, exhibit a substantial performance gap\ncompared to humans. Our findings highlight critical limitations, including\nvarious types of perceptual errors made by the models, and suggest potential\navenues for improvement from an agent-centric perspective, such as refining\nagent strategies and addressing perceptual inaccuracies. Code is available at\nhttps://github.com/CSU-JPG/V-MAGE.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T15:43:01Z"}
{"aid":"http://arxiv.org/abs/2504.06162v1","title":"A distributional approach to nonlocal curvature flows","summary":"In \\cite{CMP17} a novel distributional approach has been introduced to\nprovide a well-posed formulation of a class of crystalline mean curvature\nflows. In this paper, such an approach is extended to the nonlocal setting.\nApplications include the fractional mean curvature flow and the Minkowski flow;\ni.e., the geometric flow generated by the $(N-1)$-dimensional Minkowski\npre-content.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T15:58:49Z"}
{"aid":"http://arxiv.org/abs/2504.06166v1","title":"Assessing how hyperparameters impact Large Language Models' sarcasm\n  detection performance","summary":"Sarcasm detection is challenging for both humans and machines. This work\nexplores how model characteristics impact sarcasm detection in OpenAI's GPT,\nand Meta's Llama-2 models, given their strong natural language understanding,\nand popularity. We evaluate fine-tuned and zero-shot models across various\nsizes, releases, and hyperparameters. Experiments were conducted on the\npolitical and balanced (pol-bal) portion of the popular Self-Annotated Reddit\nCorpus (SARC2.0) sarcasm dataset. Fine-tuned performance improves monotonically\nwith model size within a model family, while hyperparameter tuning also impacts\nperformance. In the fine-tuning scenario, full precision Llama-2-13b achieves\nstate-of-the-art accuracy and $F_1$-score, both measured at 0.83, comparable to\naverage human performance. In the zero-shot setting, one GPT-4 model achieves\ncompetitive performance to prior attempts, yielding an accuracy of 0.70 and an\n$F_1$-score of 0.75. Furthermore, a model's performance may increase or decline\nwith each release, highlighting the need to reassess performance after each\nrelease.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T16:05:25Z"}
{"aid":"http://arxiv.org/abs/2504.06174v1","title":"On Soft Clustering For Correlation Estimators: Model Uncertainty,\n  Differentiability, and Surrogates","summary":"Properly estimating correlations between objects at different spatial scales\nnecessitates $\\mathcal{O}(n^2)$ distance calculations. For this reason, most\nwidely adopted packages for estimating correlations use clustering algorithms\nto approximate local trends. However, methods for quantifying the error\nintroduced by this clustering have been understudied. In response, we present\nan algorithm for estimating correlations that is probabilistic in the way that\nit clusters objects, enabling us to quantify the uncertainty caused by\nclustering simply through model inference. These soft clustering assignments\nenable correlation estimators that are theoretically differentiable with\nrespect to their input catalogs. Thus, we also build a theoretical framework\nfor differentiable correlation functions and describe their utility in\ncomparison to existing surrogate models. Notably, we find that repeated\nnormalization and distance function calls slow gradient calculations and that\nsparse Jacobians destabilize precision, pointing towards either approximate or\nsurrogate methods as a necessary solution to exact gradients from correlation\nfunctions. To that end, we close with a discussion of surrogate models as\nproxies for correlation functions. We provide an example that demonstrates the\nefficacy of surrogate models to enable gradient-based optimization of\nastrophysical model parameters, successfully minimizing a correlation function\noutput. Our numerical experiments cover science cases across cosmology, from\npoint spread function (PSF) modeling efforts to gravitational simulations to\ngalaxy intrinsic alignment (IA).","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-08T16:18:39Z"}
{"aid":"http://arxiv.org/abs/2504.06180v1","title":"Blockchain Oracles for Real Estate Rental","summary":"Blockchain technology has seen adoption across various industries and the\nreal estate sector is no exception. The traditional property leasing process\nguarantees no trust between parties, uses insecure communication channels, and\nforces participants who are not familiar with the process to perform contracts.\nBlockchain technology emerges as a solution to simplify the traditional\nproperty leasing process. This work proposes the use of two blockchain oracles\nto handle, respectively, maintenance issues and automate rent payments in the\ncontext of property rental. These two components are introduced in a\nblockchain-based property rental platform.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-08T16:21:30Z"}
{"aid":"http://arxiv.org/abs/2504.06182v1","title":"Efficient algorithms to solve atom reconfiguration problems. III. The\n  bird and batching algorithms and other parallel implementations on GPUs","summary":"We present efficient implementations of atom reconfiguration algorithms for\nboth CPUs and GPUs, along with a batching routine to merge displacement\noperations for parallel execution. Leveraging graph-theoretic methods, our\napproach derives improved algorithms that achieve reduced time complexity and\nfaster operational running times. First, we introduce an enhanced version of\nthe redistribution-reconfiguration (red-rec) algorithm, which offers superior\noperational and runtime performance. We detail its efficient implementation on\na GPU using a parallel approach. Next, we present an optimized version of the\nassignment-reconfiguration-ordering (aro) algorithm, specifically tailored for\nunweighted grid graphs. Finally, we introduce the bird algorithm to solve\nreconfiguration problems on grids, achieving performance gains over both\nred-rec and aro. These algorithms can be used to prepare defect-free\nconfigurations of neutral atoms in arrays of optical traps, serve as\nsubroutines in more complex algorithms, or cross-benchmark the operational and\nruntime performance of new algorithms. They are suitable for realizing quantum\ncircuits incorporating displacement operations and are optimized for real-time\noperation on increasingly large system sizes.","main_category":"quant-ph","categories":"quant-ph,physics.atom-ph","published":"2025-04-08T16:22:42Z"}
{"aid":"http://arxiv.org/abs/2504.06186v1","title":"Equivalence between the timelike Brunn-Minkowski inequality and timelike\n  Bakry-Émery-Ricci lower bound on weighted globally hyperbolic spacetimes","summary":"We prove the timelike Brunn-Minkowski inequality $\\mathsf{TBM}(K,N)$ implies\na timelike lower bound on the Bakry-\\'Emery-Ricci curvature on weighted\nglobally hyperbolic spacetimes. This result, together with the well-known\nequivalence between timelike Bakry-\\'Emery-Ricci lower bounds and the\n$\\mathsf{TCD}(K,N)$ condition, and the fact that $\\mathsf{TCD}(K,N)$ spaces\nsupport the timelike Brunn-Minkowski inequality, draws an equivalence between\n$\\mathsf{TBM}(K,N)$ and $\\mathsf{TCD}(K,N)$ in the smooth setting.","main_category":"math.MG","categories":"math.MG,gr-qc","published":"2025-04-08T16:28:07Z"}
{"aid":"http://arxiv.org/abs/2504.06194v1","title":"Positive 3-braids, Khovanov homology and Garside theory","summary":"Khovanov homology is a powerful invariant of oriented links that categorifies\nthe Jones polynomial. Nevertheless, computing Khovanov homology of a given link\nremains challenging in general with current techniques. In this work we focus\non links that are the closure of positive 3-braids. Starting with a\nclassification of conjugacy classes of 3-braids arising from the Garside\nstructure of braid groups, we compute, for any closed positive 3-braid, the\nfirst four columns (homological degree) and the three lowest rows (quantum\ndegree) of the associated Khovanov homology table. Moreover, the number of rows\nand columns we can describe increases with the infimum of the positive braid (a\nGarside theoretical notion). We will show how to increase the infimum of a\n3-braid to its maximal possible value by a conjugation, maximizing the number\nof cells in the Khovanov homology of its closure that can be determined, and\nshow that this can be done in linear time.","main_category":"math.GT","categories":"math.GT,math.AT,math.GR","published":"2025-04-08T16:35:15Z"}
{"aid":"http://arxiv.org/abs/2504.06206v1","title":"Antiferromagnetism and spin excitations in a two-dimensional\n  non-Hermitian Hatano-Nelson flux model","summary":"The one-dimensional Hatano-Nelson model with non-reciprocal hoppings is a\nprominent example of a relatively simple non-Hermitian quantum-mechanical\nsystem, which allows to study various phenomena in open quantum systems without\nadding extra gain and loss terms. Here we propose to use it as a building block\nto construct a correlated non-Hermitian Hamiltonian in two dimensions. It has\nthe characteristic form of a flux model with clock-anticlockwise non-reciprocal\nhopping on each plaquette. Adding the on-site Hubbard type interaction we\nanalyze the formation of the longe-range antiferromagnetic order and its spin\nexcitations. Such a model is non-Hermitian, but $\\mathcal{PT}$-symmetric, which\nleads to the existence of two regions: a region of unbroken $\\mathcal{PT}$\nsymmetry (real-valued spectrum) and a region of broken $\\mathcal{PT}$ symmetry\nwith exceptional lines and complex-valued energy spectrum. The transition from\none region to another is controlled by the value of the on-site interaction\nparameter and coincides with the metal-insulator transition. We also analyze\nthe spin wave spectrum, which is characterized by two diffusive d-wave type of\nmodes corresponding to gain and loss.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-08T16:51:15Z"}
{"aid":"http://arxiv.org/abs/2504.06217v1","title":"Chernoff Information Bottleneck for Covert Quantum Target Sensing","summary":"Target sensing is a fundamental task with many practical applications,\ne.g.~in LiDaR and radar systems. Quantum strategies with entangled states can\nachieve better sensing accuracies with the same probe energy, yet it is often\nsimpler to use classical probes with higher energy than to take advantage of\nthe quantum regime. Recently, it has been shown that useful quantum advantage\ncan be achieved in covert situations, where sensing has to be performed while\nalso avoiding detection by an adversary: here increasing energy is not a viable\nstratagem, as it facilitates the adversary. In this paper we introduce a\ngeneral framework to assess and quantify quantum advantage in covert\nsituations. This is based on extending the information bottleneck principle,\noriginally developed for communication and machine learning applications, to\ndecision problems via the Chernoff information, with the ultimate goal of\nquantitatively optimizing the trade-off between covertness and sensing ability.\nIn this context we show how quantum resources, namely entangled photonic probes\npaired with photon counting, greatly outperform classical coherent transmitters\nin target detection and ranging, while also maintaining a chosen level of\ncovertness. Our work highlights the great potential of integrating quantum\nsensing in LiDAR systems to enhance the covert performance.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-08T17:05:41Z"}
{"aid":"http://arxiv.org/abs/2504.06224v1","title":"Nonlinear Tails of Gravitational Waves in Schwarzschild Black Hole\n  Ringdown","summary":"Schwarzschild black holes evolve toward their static configuration by\nemitting gravitational waves, which decay over time following a power law at\nfixed spatial positions. We derive this power law analytically for the\nsecond-order even gravitational perturbations, demonstrating that it is\ndetermined by the fact that the second-order source decays as the inverse\nsquare of the distance. Quadratic gravitational modes with multipole $\\ell$\ndecay according to a law $\\sim t^{-2\\ell-1}$, in contrast to the linear Price\nlaw scaling $\\sim t^{-2\\ell-3}$. Consequently, nonlinear tails may persist\nlonger than their linear counterparts.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-ph,hep-th","published":"2025-04-08T17:12:28Z"}
{"aid":"http://arxiv.org/abs/2504.06229v1","title":"Continuous-variable spatio-spectral quantum networks in nonlinear\n  photonic lattices","summary":"Multiplexing information in different degrees of freedom and use of\nintegrated and fiber-optic components are natural solutions to the scalability\nbottleneck in optical quantum communications and computing. However, for\nbulk-optics systems, where size, cost, stability, and reliability are factors,\nthis remains either impractical or highly challenging to implement. In this\npaper we present a framework to engineer continuous-variable entanglement\nproduced through nondegenerate spontaneous parametric down-conversion in\n\\chi^(2) nonlinear photonic lattices in spatial and spectral degrees of freedom\nthat can solve the scalability challenge. We show how spatio-spectral pump\nshaping produce cluster states that are naturally distributable in quantum\ncommunication networks and a resource for measurement-based quantum computing.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-08T17:24:00Z"}
{"aid":"http://arxiv.org/abs/2504.06230v1","title":"Global solutions for cubic quasilinear ultrahyperbolic Schrödinger\n  flows","summary":"In recent work, two of the authors proposed a broad global well-posedness\nconjecture for cubic quasilinear dispersive equations in two space dimensions,\nwhich asserts that global well-posedness and scattering holds for small initial\ndata in Sobolev spaces. As a first validation they proved the conjecture for\nquasilinear Schr\\\"odinger flows.\n  In the present article we expand the reach of these ideas and methods to the\ncase of quasilinear ultrahyperbolic Schr\\\"odinger flows, which is the first\nexample with a nonconvex dispersion relation.\n  The study of local well-posedness for this class of problems, in all\ndimensions, was initiated in pioneering work of Kenig-Ponce-Vega for localized\ninitial data, and then continued by Marzuola-Metcalfe-Tataru (MMT) and\nPineau-Taylor (PT) for initial data in Sobolev spaces in the elliptic and\nnon-elliptic cases, respectively.\n  Our results here mirror the earlier results in the elliptic case: (i) a new,\npotentially sharp local well-posedness result in low regularity Sobolev spaces,\none derivative below MMT and just one-half derivative above scaling, (ii) a\nsmall data global well-posedness and scattering result at the same regularity\nlevel. One key novelty in this setting is the introduction of a new family of\ninteraction Morawetz functionals which are suitable for obtaining bilinear\nestimates in the ultrahyperbolic setting. We remark that this method appears to\nbe robust enough to potentially be of use in a large data regime when the\nmetric is not a small perturbation of a Euclidean one.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T17:24:40Z"}
{"aid":"http://arxiv.org/abs/2504.06243v1","title":"Renormalization Group in far-from-equilibrium states","summary":"We study renormalization group flows in far-from-equilibrium states. The\nstudy is made tractable by focusing on states that are spatially homogeneous,\ntime-independent, and scale-invariant. Such states, in which mode $k$ has\noccupation numbers $n_k \\sim k^{-\\gamma}$, are well known in nonlinear physics.\nRG flow in such states is qualitatively different from that in the vacuum -- a\npositive $\\gamma$ decreases the dimension of an operator, turning marginal\ninteractions into relevant interactions. We compute one-loop beta functions.\nDepending on the sign of the beta function, backreaction may either cause a\nminor shift of the state in the IR, or completely change the nature of the\nstate. Focusing on nearly marginal interactions, we construct an analog of the\nepsilon expansion and IR fixed points, with epsilon now set by the scaling of\nthe interaction rather than the spacetime dimension. In the language of RG\nflow, critical-balance scaling -- which has applications in fields as varied as\nastrophysics and ocean waves -- corresponds to the state dynamically adjusting\nitself along the RG flow until the interaction becomes marginal.","main_category":"hep-th","categories":"hep-th,hep-ph","published":"2025-04-08T17:43:01Z"}
{"aid":"http://arxiv.org/abs/2504.06245v1","title":"Underwater Robotic Simulators Review for Autonomous System Development","summary":"The increasing complexity of underwater robotic systems has led to a surge in\nsimulation platforms designed to support perception, planning, and control\ntasks in marine environments. However, selecting the most appropriate\nunderwater robotic simulator (URS) remains a challenge due to wide variations\nin fidelity, extensibility, and task suitability. This paper presents a\ncomprehensive review and comparative analysis of five state-of-the-art,\nROS-compatible, open-source URSs: Stonefish, DAVE, HoloOcean, MARUS, and\nUNav-Sim. Each simulator is evaluated across multiple criteria including sensor\nfidelity, environmental realism, sim-to-real capabilities, and research impact.\nWe evaluate them across architectural design, sensor and physics modeling, task\ncapabilities, and research impact. Additionally, we discuss ongoing challenges\nin sim-to-real transfer and highlight the need for standardization and\nbenchmarking in the field. Our findings aim to guide practitioners in selecting\neffective simulation environments and inform future development of more robust\nand transferable URSs.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T17:43:48Z"}
{"aid":"http://arxiv.org/abs/2504.06251v1","title":"Moiré enhanced flat band in rhombohedral graphene","summary":"The fractional quantum anomalous Hall effect (FQAHE) is a fascinating\nemergent quantum state characterized by fractionally charged excitations in the\nabsence of magnetic field,which could arise from the intricate interplay\nbetween electron correlation, nontrivial topology and spontaneous time-reversal\nsymmetry breaking. Recently, FQAHE has been realized in aligned rhombohedral\npentalayer graphene on BN superlattice (aligned R5G/BN), where the topological\nflat band is modulated by the moir\\'e potential. However, intriguingly, the\nFQAHE is observed only when electrons are pushed away from the moir\\'e\ninterface. The apparently opposite implications from these experimental\nobservations, along with different theoretical models, have sparked intense\ndebates regarding the role of the moir\\'e potential. Unambiguous experimental\nobservation of the topological flat band as well as moir\\'e bands with energy\nand momentum resolved information is therefore critical to elucidate the\nunderlying mechanism. Here by performing nanospot angle-resolved photoemission\nspectroscopy (NanoARPES) measurements, we directly reveal the topological flat\nband electronic structures of R5G, from which key hopping parameters essential\nfor determining the fundamental electronic structure of rhombohedral graphene\nare extracted. Moreover, a comparison of electronic structures between aligned\nand non-aligned samples reveals that the moir\\'e potential plays a pivotal role\nin enhancing the topological flat band in the aligned sample. Our study\nprovides experimental guiding lines to narrow down the phase space of\nrhombohedral graphene, laying an important foundation for understanding exotic\nquantum phenomena in this emerging platform.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.str-el,cond-mat.supr-con","published":"2025-04-08T17:56:35Z"}
{"aid":"http://arxiv.org/abs/2504.06255v1","title":"Diagrammatic expansion for the mutual-information rate in the realm of\n  limited statistics","summary":"Neurons in sensory systems encode stimulus information into their stochastic\nspiking response. The Mutual information has been broadly applied to these\nsystems to quantify the neurons' capacity of transmitting such information.\nYet, while for discrete stimuli, like flashed images or single tones, its\ncomputation is straightforward, for dynamical stimuli it is necessary to\ncompute a (mutual) information rate (MIR), therefore integrating over the\nmultiple temporal correlations which characterize sensory systems. Previous\nmethods are based on extensive sampling of the neuronal response, require large\namounts of data, and are therefore prone to biases and inaccuracy. Here, we\ndevelop Moba-MIRA (moment-based mutual-information-rate approximation), a\ncomputational method to estimate the mutual information rate. To derive\nMoba-MIRA, we use Feynman diagrams to expand the mutual information in\narbitrary orders in the correlations around the corresponding value for the\nempirical spike count distributions of single binss. As a result, only the\nempirical estimation of the pairwise correlations between time bins and the\nsingle-bin entropies are required, without the need for the whole joint\nprobability distributions. We tested Moba-MIRA on synthetic data generated with\ngeneralized linear models, and showed that it requires only a few tens of\nstimulus repetitions to provide an accurate estimate of the information rate.\nFinally, we applied it to ex-vivo electrophysiological recordings of rats\nretina, obtaining rates ranging between 5 to 20 bits per second, consistent\nwith earlier estimates.","main_category":"q-bio.NC","categories":"q-bio.NC,cond-mat.dis-nn","published":"2025-04-08T17:57:27Z"}
{"aid":"http://arxiv.org/abs/2504.06267v1","title":"Prethermalization of light and matter in cavity-coupled Rydberg arrays","summary":"We explore the dynamics of two-dimensional Rydberg atom arrays coupled to a\nsingle-mode optical cavity, employing nonequilibrium diagrammatic techniques to\ncapture nonlinearities and fluctuations beyond mean-field theory. We discover a\nnovel prethermalization regime driven by the interplay between short-range\nRydberg interactions and long-range photon-mediated interactions. In this\nregime, matter and light equilibrate at distinct - and in some cases opposite -\neffective temperatures, resembling the original concept of prethermalization\nfrom particle physics. Our results establish strongly correlated AMO platforms\nas tools to investigate fundamental questions in statistical mechanics,\nincluding quantum thermalization in higher-dimensional systems.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,quant-ph","published":"2025-04-08T17:59:59Z"}
{"aid":"http://arxiv.org/abs/2504.06555v1","title":"Dihedral solutions of the set theoretical Yang-Baxter equation","summary":"We introduce the notion of a \\emph{braided dihedral set} (BDS) to describe\nset-theoretical solutions of the Yang-Baxter equation (YBE) that furnish\nrepresentations of the infinite dihedral group on the Cartesian square of the\nunderlying set. BDS which lead to representations of the symmetric group on\nthree objects are called \\emph{braided triality sets} (BTS). Basic examples of\nBDS come from symmetric spaces. We show that Latin BDS (LBDS) can be described\nentirely in terms of involutions of uniquely 2-divisible Bruck loops. We show\nthat isomorphism classes of LBDS are in one-to-one correspondence with\nconjugacy classes of involutions of uniquely 2-divisible Bruck loops. We\ndescribe all LBDS of prime, prime-square and 3 times prime-order, up to\nisomorphism. Using \\texttt{GAP}, we enumerate isomorphism classes of LBDS of\norders 27 and 81. Latin BTS, or LBTS, are shown to be in one-to-one\ncorrespondence with involutions of commutative Moufang loops of exponent 3\n(CML3), and, as with LBDS, isomorphisms classes of LBTS coincide with conjugacy\nclasses of CML3-involutions. We classify all LBTS of order at most 81.","main_category":"math.QA","categories":"math.QA","published":"2025-04-09T03:23:52Z"}
{"aid":"http://arxiv.org/abs/2504.06560v1","title":"NeedleInATable: Exploring Long-Context Capability of Large Language\n  Models towards Long-Structured Tables","summary":"Processing structured tabular data, particularly lengthy tables, constitutes\na fundamental yet challenging task for large language models (LLMs). However,\nexisting long-context benchmarks primarily focus on unstructured text,\nneglecting the challenges of long and complex structured tables. To address\nthis gap, we introduce NeedleInATable (NIAT), a novel task that treats each\ntable cell as a \"needle\" and requires the model to extract the target cell\nunder different queries. Evaluation results of mainstream LLMs on this\nbenchmark show they lack robust long-table comprehension, often relying on\nsuperficial correlations or shortcuts for complex table understanding tasks,\nrevealing significant limitations in processing intricate tabular data. To this\nend, we propose a data synthesis method to enhance models' long-table\ncomprehension capabilities. Experimental results show that our synthesized\ntraining data significantly enhances LLMs' performance on the NIAT task,\noutperforming both long-context LLMs and long-table agent methods. This work\nadvances the evaluation of LLMs' genuine long-structured table comprehension\ncapabilities and paves the way for progress in long-context and table\nunderstanding applications.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T03:46:56Z"}
{"aid":"http://arxiv.org/abs/2504.06566v1","title":"Diffusion Factor Models: Generating High-Dimensional Returns with Factor\n  Structure","summary":"Financial scenario simulation is essential for risk management and portfolio\noptimization, yet it remains challenging especially in high-dimensional and\nsmall data settings common in finance. We propose a diffusion factor model that\nintegrates latent factor structure into generative diffusion processes,\nbridging econometrics with modern generative AI to address the challenges of\nthe curse of dimensionality and data scarcity in financial simulation. By\nexploiting the low-dimensional factor structure inherent in asset returns, we\ndecompose the score function--a key component in diffusion models--using\ntime-varying orthogonal projections, and this decomposition is incorporated\ninto the design of neural network architectures. We derive rigorous statistical\nguarantees, establishing nonasymptotic error bounds for both score estimation\nat O(d^{5/2} n^{-2/(k+5)}) and generated distribution at O(d^{5/4}\nn^{-1/2(k+5)}), primarily driven by the intrinsic factor dimension k rather\nthan the number of assets d, surpassing the dimension-dependent limits in the\nclassical nonparametric statistics literature and making the framework viable\nfor markets with thousands of assets. Numerical studies confirm superior\nperformance in latent subspace recovery under small data regimes. Empirical\nanalysis demonstrates the economic significance of our framework in\nconstructing mean-variance optimal portfolios and factor portfolios. This work\npresents the first theoretical integration of factor structure with diffusion\nmodels, offering a principled approach for high-dimensional financial\nsimulation with limited data.","main_category":"q-fin.ST","categories":"q-fin.ST,cs.LG,q-fin.MF","published":"2025-04-09T04:01:35Z"}
{"aid":"http://arxiv.org/abs/2504.06573v1","title":"Mutation Cycles from Reddening Sequences","summary":"Given two quivers, each with a reddening sequence, we show how to construct a\nplethora of mutation cycles. We give several examples, including a\ngeneralization of the construction of long mutation cycles in earlier work by\nthe second author. We also give new results on the reddening sequences of\ncertain mutation-acyclic quivers and forks, classifying them in some cases.","main_category":"math.CO","categories":"math.CO","published":"2025-04-09T04:21:51Z"}
{"aid":"http://arxiv.org/abs/2504.06587v1","title":"SigChord: Sniffing Wide Non-sparse Multiband Signals for Terrestrial and\n  Non-terrestrial Wireless Networks","summary":"While unencrypted information inspection in physical layer (e.g., open\nheaders) can provide deep insights for optimizing wireless networks, the\nstate-of-the-art (SOTA) methods heavily depend on full sampling rate (a.k.a\nNyquist rate), and high-cost radios, due to terrestrial and non-terrestrial\nnetworks densely occupying multiple bands across large bandwidth (e.g., from\n4G/5G at 0.4-7 GHz to LEO satellite at 4-40 GHz). To this end, we present\nSigChord, an efficient physical layer inspection system built on low-cost and\nsub-Nyquist sampling radios. We first design a deep and rule-based interleaving\nalgorithm based on Transformer network to perform spectrum sensing and signal\nrecovery under sub-Nyquist sampling rate, and second, cascade protocol\nidentifier and decoder based on Transformer neural networks to help physical\nlayer packets analysis. We implement SigChord using software-defined radio\nplatforms, and extensively evaluate it on over-the-air terrestrial and\nnon-terrestrial wireless signals. The experiments demonstrate that SigChord\ndelivers over 99% accuracy in detecting and decoding, while still decreasing\n34% sampling rate, compared with the SOTA approaches.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-09T05:32:39Z"}
{"aid":"http://arxiv.org/abs/2504.06594v1","title":"Machine Learning for Extrapolating No-Core Shell Model Results to\n  Infinite Basis","summary":"We utilize the machine learning to extrapolate to the infinite model space\nthe no-core shell model (NCSM) results for the energies and rms radii of the\n6He ground state and 6Li lowest states. The extrapolated energies and rms radii\nconverge as the NCSM results from larger model spaces are included in the\ntraining dataset for ensemble of artificial neural networks thus enabling an\naccurate predictions for these observables.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-09T05:42:41Z"}
{"aid":"http://arxiv.org/abs/2504.06598v1","title":"Stochastic Ray Tracing of 3D Transparent Gaussians","summary":"3D Gaussian splatting has recently been widely adopted as a 3D representation\nfor novel-view synthesis, relighting, and text-to-3D generation tasks, offering\nrealistic and detailed results through a collection of explicit 3D Gaussians\ncarrying opacities and view-dependent colors. However, efficient rendering of\nmany transparent primitives remains a significant challenge. Existing\napproaches either rasterize the 3D Gaussians with approximate sorting per view\nor rely on high-end RTX GPUs to exhaustively process all ray-Gaussian\nintersections (bounding Gaussians by meshes). This paper proposes a stochastic\nray tracing method to render 3D clouds of transparent primitives. Instead of\nprocessing all ray-Gaussian intersections in sequential order, each ray\ntraverses the acceleration structure only once, randomly accepting and shading\na single intersection (or N intersections, using a simple extension). This\napproach minimizes shading time and avoids sorting the Gaussians along the ray\nwhile minimizing the register usage and maximizing parallelism even on low-end\nGPUs. The cost of rays through the Gaussian asset is comparable to that of\nstandard mesh-intersection rays. While our method introduces noise, the shading\nis unbiased, and the variance is slight, as stochastic acceptance is\nimportance-sampled based on accumulated opacity. The alignment with the Monte\nCarlo philosophy simplifies implementation and easily integrates our method\ninto a conventional path-tracing framework.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-09T05:49:05Z"}
{"aid":"http://arxiv.org/abs/2504.06599v1","title":"Axionless Solution to the Strong CP Problem -- two-zeros textures of the\n  quark and lepton mass matrices and neutrino CP violation --","summary":"CP invariance is a very attractive solution to the strong CP problem in QCD.\nThis solution requires the vanishing ${\\rm arg}\\,[{\\rm det}\\, M_d\\, {\\rm det}\nM_u]$, where the $M_d$ and $M_u$ are the mass matrices for the down- and\nup-type quarks. It happens if we have several zeros in the quark mass matrices.\nWe proceed a systematic construction, in this paper, of two zeros textures for\nthe down-type quark mass matrix while the mass matrix for the up-type quarks is\nalways diagonal. We find only three types of the mass matrices can explain the\nobserved CKM matrix, the masses of the quarks and the charged leptons and the\nsmall enough vacuum angle $\\theta < 10^{-10}$. We extend the mass construction\nto the neutrino sector and derive predictions on the CP violating parameter\n$\\delta_{CP}$ in the neutrino oscillation and the mass parameter\n$m_{\\beta\\beta}$. It is extremely remarkable that the normal (NH) and inverted\n(IH) hierarchies in the neutrino masses are equally possible in the case where\nwe introduce only two right-handed neutrinos $N$s. Furthermore, we have a\nstrict prediction on the $\\delta_{CP} \\simeq 200^\\circ$ or $250^\\circ$ in the\nNH case. If it is the case we can naturally explain the positive sign of the\nbaryon asymmetry in the present universe.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-09T05:52:11Z"}
{"aid":"http://arxiv.org/abs/2504.06604v1","title":"Image registration of 2D optical thin sections in a 3D porous medium:\n  Application to a Berea sandstone digital rock image","summary":"This study proposes a systematic image registration approach to align 2D\noptical thin-section images within a 3D digital rock volume. Using template\nimage matching with differential evolution optimization, we identify the most\nsimilar 2D plane in 3D. The method is validated on a synthetic porous medium,\nachieving exact registration, and applied to Berea sandstone, where it achieves\na structural similarity index (SSIM) of 0.990. With the registered images, we\nexplore upscaling properties based on paired multimodal images, focusing on\npore characteristics and effective elastic moduli. The thin-section image\nreveals 50 % more porosity and submicron pores than the registered CT plane. In\naddition, bulk and shear moduli from thin sections are 25 % and 30 % lower,\nrespectively, than those derived from CT images. Beyond numerical comparisons,\nthin sections provide additional geological insights, including cementation,\nmineral phases, and weathering effects, which are not clear in CT images. This\nstudy demonstrates the potential of multimodal image registration to improve\ncomputed rock properties in digital rock physics by integrating complementary\nimaging modalities.","main_category":"physics.geo-ph","categories":"physics.geo-ph,cs.CV","published":"2025-04-09T06:01:43Z"}
{"aid":"http://arxiv.org/abs/2504.06610v1","title":"Disentangle and Regularize: Sign Language Production with\n  Articulator-Based Disentanglement and Channel-Aware Regularization","summary":"In this work, we propose a simple gloss-free, transformer-based sign language\nproduction (SLP) framework that directly maps spoken-language text to sign pose\nsequences. We first train a pose autoencoder that encodes sign poses into a\ncompact latent space using an articulator-based disentanglement strategy, where\nfeatures corresponding to the face, right hand, left hand, and body are modeled\nseparately to promote structured and interpretable representation learning.\nNext, a non-autoregressive transformer decoder is trained to predict these\nlatent representations from sentence-level text embeddings. To guide this\nprocess, we apply channel-aware regularization by aligning predicted latent\ndistributions with priors extracted from the ground-truth encodings using a\nKL-divergence loss. The contribution of each channel to the loss is weighted\naccording to its associated articulator region, enabling the model to account\nfor the relative importance of different articulators during training. Our\napproach does not rely on gloss supervision or pretrained models, and achieves\nstate-of-the-art results on the PHOENIX14T dataset using only a modest training\nset.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-09T06:14:19Z"}
{"aid":"http://arxiv.org/abs/2504.06617v1","title":"Spectrum radii of trees","summary":"For any positive integer $r$ and positive number $\\alpha$, let ${\\mathscr\nW}_r(\\alpha)$ denote the set of positive numbers defined recursively:\n$\\alpha\\in {\\mathscr W}_r(\\alpha)$, and for any multi-set $\\{q_i\\in {\\mathscr\nW}_r(\\alpha): 1\\le i\\le s\\}$, where $1\\le s<r$,\n$\\beta:=\\alpha-\\sum\\limits_{i=1}^sq_i^{-1}$ belongs to ${\\mathscr W}_r(\\alpha)$\nas long as $\\beta>0$. We first show that there exists a tree $T$ such that its\nmaximum degree $\\Delta(T)$ is at most $r$ and its spectrum radius $\\lambda(T)$\nis equal to $\\alpha$ if and only if $\\alpha^{-1}\\in {\\mathscr W}_r(\\alpha)$. It\nfollows that the set of spectrum radii of non-trivial trees is exactly the set\nof positive numbers $\\alpha$ such that $\\alpha^{-1}\\in {\\mathscr\nW}_{\\lfloor\\alpha^2\\rfloor}(\\alpha)$. Applying this conclusion, we then prove\nthat for any positive integers $r$ and $k$, there exists a tree $T$ with\n$\\Delta(T)=r$ and $\\lambda(T)=\\sqrt k$ if and only if $\\frac 14 k+1<r\\le k$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-09T06:30:32Z"}
{"aid":"http://arxiv.org/abs/2504.06623v1","title":"The curious case of operators with spectral density increasing as\n  $Ω(E)\\sim e^{\\,\\mathrm{Const.}\\, E^2}$","summary":"Motivated by a putative model of black holes as quantum objects we consider\nwhat types of operators would have a corresponding spectrum. We find that there\nare indeed such operators, but of a rather unusual types, and for which the\nwave functions are only barely localized. We point out a tension between such\nalmost delocalized states and black holes as compact objects.","main_category":"gr-qc","categories":"gr-qc,cond-mat.stat-mech,quant-ph","published":"2025-04-09T06:44:28Z"}
{"aid":"http://arxiv.org/abs/2504.06638v1","title":"HGMamba: Enhancing 3D Human Pose Estimation with a HyperGCN-Mamba\n  Network","summary":"3D human pose lifting is a promising research area that leverages estimated\nand ground-truth 2D human pose data for training. While existing approaches\nprimarily aim to enhance the performance of estimated 2D poses, they often\nstruggle when applied to ground-truth 2D pose data. We observe that achieving\naccurate 3D pose reconstruction from ground-truth 2D poses requires precise\nmodeling of local pose structures, alongside the ability to extract robust\nglobal spatio-temporal features. To address these challenges, we propose a\nnovel Hyper-GCN and Shuffle Mamba (HGMamba) block, which processes input data\nthrough two parallel streams: Hyper-GCN and Shuffle-Mamba. The Hyper-GCN stream\nmodels the human body structure as hypergraphs with varying levels of\ngranularity to effectively capture local joint dependencies. Meanwhile, the\nShuffle Mamba stream leverages a state space model to perform spatio-temporal\nscanning across all joints, enabling the establishment of global dependencies.\nBy adaptively fusing these two representations, HGMamba achieves strong global\nfeature modeling while excelling at local structure modeling. We stack multiple\nHGMamba blocks to create three variants of our model, allowing users to select\nthe most suitable configuration based on the desired speed-accuracy trade-off.\nExtensive evaluations on the Human3.6M and MPI-INF-3DHP benchmark datasets\ndemonstrate the effectiveness of our approach. HGMamba-B achieves\nstate-of-the-art results, with P1 errors of 38.65 mm and 14.33 mm on the\nrespective datasets. Code and models are available:\nhttps://github.com/HuCui2022/HGMamba","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T07:28:19Z"}
{"aid":"http://arxiv.org/abs/2504.06644v1","title":"Nonlocal Quasilinear Parabolic Equations in Heisenberg Group: Local\n  Boundedness with an Optimal Tail","summary":"We prove local boundedness for a quasilinear parabolic equation on the\nHeisenberg group\n  \\[\n  \\partial_t u(\\xi,t) + \\text{p.v.}\\int_{\\mathbb{H}^N}\n\\frac{|u(\\xi,t)-u(\\eta,t)|^{p-2}(u(\\xi,t)-u(\\eta,t))}{|\\eta^{-1}\\circ\n\\xi|^{Q+sp}} \\,d\\eta = 0,\n  \\] with optimal regularity assumption on the tail term. We also prove\ninterpolation inequalities and an extension theorem for fractional Sobolev\nspaces on the Heisenberg group.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T07:33:02Z"}
{"aid":"http://arxiv.org/abs/2504.06645v1","title":"Evidence for repeating fast radio bursts association with fast\n  super-twisted magnetars","summary":"Fast radio bursts (FRBs) are bright millisecond radio events of unknown\nextra-galactic origin. Magnetars are one of the main contenders. Some sources,\nthe repeaters, produce multiple events but so far generally without the\ncharacteristic periodicity that one could associate with the spin of a neutron\nstar. We fit a geometrical model to the two main repeaters of the CHIME/FRB\ncatalogue, namely FRB 20180814A and FRB 20180916B. Assuming the bursts\noriginate from a magnetar's magnetosphere, we constrain the spin and magnetic\nparameters of the star which are encoded into burst spectro-temporal\nmorphologies. We estimate that a very strong toroidal magnetic component\ntogether with spin periods of respectively $2.3_{-0.5}^{+0.5} ~ \\rm s$ and\n$0.8_{-0.2}^{+0.1} ~ \\rm s$ best explain the data. We argue that this points\ntowards young magnetars with super-twisted magnetospheres.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-09T07:33:25Z"}
{"aid":"http://arxiv.org/abs/2504.06650v1","title":"ThoughtProbe: Classifier-Guided Thought Space Exploration Leveraging LLM\n  Intrinsic Reasoning","summary":"Pre-trained large language models (LLMs) have been demonstrated to possess\nintrinsic reasoning capabilities that can emerge naturally when expanding the\nresponse space. However, the neural representation mechanisms underlying these\nintrinsic capabilities and approaches for their optimal utilization remain\ninadequately understood. In this work, we make the key discovery that a simple\nlinear classifier can effectively detect intrinsic reasoning capabilities in\nLLMs' activation space, particularly within specific representation types and\nnetwork layers. Based on this finding, we propose a classifier-guided search\nframework that strategically explore a tree-structured response space. In each\nnode expansion, the classifier serves as a scoring and ranking mechanism that\nefficiently allocates computational resources by identifying and prioritizing\nmore thoughtful reasoning directions for continuation. After completing the\ntree expansion, we collect answers from all branches to form a candidate answer\npool. We propose a branch-aggregation selection method that marginalizes over\nall supporting branches by aggregating their thoughtfulness scores, thereby\nidentifying the optimal answer from the pool. Experimental results show that\nour framework's comprehensive exploration not only covers valid reasoning\nchains but also effectively identifies them, achieving significant improvements\nacross multiple arithmetic reasoning benchmarks.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T07:37:27Z"}
{"aid":"http://arxiv.org/abs/2504.06657v1","title":"When Pythagoras meets Navier-Stokes","summary":"In this article, we develop a new method, based on a time decomposition of a\nCauchy problem elaborated in [6], to retrieve the well-known $L^\\infty\n([0,T],L^2(\\mathbb{R}^d,\\mathbb{R}^d))$ control of the solution of the\nincompressible Navier-Stokes equation in $\\mathbb{R}^d$. We precisely explain\nhow the Pythagorean theorem in $L^2(\\mathbb{R}^d,\\mathbb{R}^d)$ allows to get\nthe proper energy estimate; however such an argument does not work anymore in\n$L^p(\\mathbb{R}^d,\\mathbb{R}^d)$, $p \\neq 2$. We also deduce, by similar\narguments, an already known $L^\\infty ([0,T],L^1(\\mathbb{R}^3,\\mathbb{R}^3))$\ncontrol of vorticity for $d=3$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T07:47:35Z"}
{"aid":"http://arxiv.org/abs/2504.06669v1","title":"NLP Security and Ethics, in the Wild","summary":"As NLP models are used by a growing number of end-users, an area of\nincreasing importance is NLP Security (NLPSec): assessing the vulnerability of\nmodels to malicious attacks and developing comprehensive countermeasures\nagainst them. While work at the intersection of NLP and cybersecurity has the\npotential to create safer NLP for all, accidental oversights can result in\ntangible harm (e.g., breaches of privacy or proliferation of malicious models).\nIn this emerging field, however, the research ethics of NLP have not yet faced\nmany of the long-standing conundrums pertinent to cybersecurity, until now. We\nthus examine contemporary works across NLPSec, and explore their engagement\nwith cybersecurity's ethical norms. We identify trends across the literature,\nultimately finding alarming gaps on topics like harm minimization and\nresponsible disclosure. To alleviate these concerns, we provide concrete\nrecommendations to help NLP researchers navigate this space more ethically,\nbridging the gap between traditional cybersecurity and NLP ethics, which we\nframe as ``white hat NLP''. The goal of this work is to help cultivate an\nintentional culture of ethical research for those working in NLP Security.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-09T08:12:34Z"}
{"aid":"http://arxiv.org/abs/2504.06671v1","title":"Defects in Silicon Carbide as Quantum Qubits: Recent Advances in Defect\n  Engineering","summary":"This review provides an overview of defects in silicon carbide (SiC) with\npotential applications as quantum qubits. It begins with a brief introduction\nto quantum qubits and existing qubit platforms, outlining the essential\ncriteria a defect must meet to function as a viable qubit. The focus then\nshifts to the most promising defects in SiC, notably the silicon vacancy (VSi)\nand divacancy (VC-VSi). A key challenge in utilizing these defects for quantum\napplications is their precise and controllable creation. Various fabrication\ntechniques, including irradiation, ion implantation, femtosecond laser\nprocessing, and focused ion beam methods, have been explored to create these\ndefects. Designed as a beginner-friendly resource, this review aims to support\nearly-career experimental researchers entering the field of SiC-related quantum\nqubits. Providing an introduction to defect-based qubits in SiC offers valuable\ninsights into fabrication strategies, recent progress, and the challenges that\nlie ahead.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,quant-ph","published":"2025-04-09T08:13:58Z"}
{"aid":"http://arxiv.org/abs/2504.06684v1","title":"SDHN: Skewness-Driven Hypergraph Networks for Enhanced Localized\n  Multi-Robot Coordination","summary":"Multi-Agent Reinforcement Learning is widely used for multi-robot\ncoordination, where simple graphs typically model pairwise interactions.\nHowever, such representations fail to capture higher-order collaborations,\nlimiting effectiveness in complex tasks. While hypergraph-based approaches\nenhance cooperation, existing methods often generate arbitrary hypergraph\nstructures and lack adaptability to environmental uncertainties. To address\nthese challenges, we propose the Skewness-Driven Hypergraph Network (SDHN),\nwhich employs stochastic Bernoulli hyperedges to explicitly model higher-order\nmulti-robot interactions. By introducing a skewness loss, SDHN promotes an\nefficient structure with Small-Hyperedge Dominant Hypergraph, allowing robots\nto prioritize localized synchronization while still adhering to the overall\ninformation, similar to human coordination. Extensive experiments on Moving\nAgents in Formation and Robotic Warehouse tasks validate SDHN's effectiveness,\ndemonstrating superior performance over state-of-the-art baselines.","main_category":"cs.RO","categories":"cs.RO,cs.MA","published":"2025-04-09T08:41:57Z"}
{"aid":"http://arxiv.org/abs/2504.06692v1","title":"SHiP experiment at the SPS Beam Dump Facility","summary":"In 2024, the SHiP experiment, together with the associated Beam Dump Facility\n(BDF) under the auspices of the High Intensity ECN3 (HI-ECN3) project, was\nselected for the future physics exploitation of the ECN3 experimental facility\nat the SPS. The SHiP experiment is a general-purpose intensity-frontier setup\ndesigned to search for physics beyond the Standard Model in the domain of\nFeebly Interacting Particles at the GeV-scale. It comprises a multi-system\napparatus that provides discovery sensitivity to both decay and scattering\nsignatures of models with feebly interacting particles, such as dark-sector\nmediators, both elastic and inelastic light dark matter, as well as\nmillicharged particles. The experiment will also be able to perform both\nStandard Model measurements and Beyond Standard Model searches with neutrino\ninteractions. In particular, it will have access to unprecedented statistics of\ntau and anti-tau neutrinos. The construction plan foresees commissioning of the\nfacility and detector, and start of operation in advance of Long Shutdown 4,\nwith a programme of exploration for 15 years of data taking. By exploring\nunique regions of parameter space for feebly interacting particles in the\nGeV/c$^2$ mass range, the SHiP experiment will complement ongoing searches at\nthe LHC and searches at future colliders.","main_category":"hep-ex","categories":"hep-ex,hep-ph","published":"2025-04-09T08:53:20Z"}
{"aid":"http://arxiv.org/abs/2504.06695v1","title":"A Convex-Analytical Proof of the Fundamental Theorem of Algebra","summary":"A weak version of Birkhoff's generalization of the Perron-Frobenius theorem\nstates that every endomorphism of a finite-dimensional real vector that leaves\ninvariant a non-degenerate closed convex cone has an eigenvector in that cone.\n  Here, we show that this theorem, whose proof relies only upon basic convex\nanalysis, yields very short proofs of both the spectral theorem for selfadjoint\noperators of Euclidean spaces and the Fundamental Theorem of Algebra.","main_category":"math.FA","categories":"math.FA,math.SP","published":"2025-04-09T08:54:14Z"}
{"aid":"http://arxiv.org/abs/2504.06702v1","title":"Consensus-based qubit configuration optimization for variational\n  algorithms on neutral atom quantum systems","summary":"In this work, we report an algorithm that is able to tailor qubit\ninteractions for individual variational quantum algorithm problems. Here, the\nalgorithm leverages the unique ability of a neutral atom tweezer platform to\nrealize arbitrary qubit position configurations. These configurations determine\nthe degree of entanglement available to a variational quantum algorithm via the\ninteratomic interactions. Good configurations will accelerate pulse\noptimization convergence and help mitigate barren plateaus. As gradient-based\napproaches are ineffective for position optimization due to the divergent\n$R^{-6}$ nature of neutral atom interactions, we opt to use a consensus-based\nalgorithm to optimize the qubit positions. By sampling the configuration space\ninstead of using gradient information, the consensus-based algorithm is able to\nsuccessfully optimize the positions, yielding adapted variational quantum\nalgorithm ansatzes that lead to both faster convergence and lower errors. In\nthis work, we show that these optimized configurations generally result in\nlarge improvements in the system's ability to solve ground state minimization\nproblems for both random Hamiltonians and small molecules.","main_category":"quant-ph","categories":"quant-ph,physics.atom-ph","published":"2025-04-09T09:07:49Z"}
{"aid":"http://arxiv.org/abs/2504.06704v1","title":"CAT: Circular-Convolutional Attention for Sub-Quadratic Transformers","summary":"Transformers have driven remarkable breakthroughs in natural language\nprocessing and computer vision, yet their standard attention mechanism still\nimposes O(N^2) complexity, hindering scalability to longer sequences. We\nintroduce Circular-convolutional ATtention (CAT), a Fourier-based approach that\nefficiently applies circular convolutions to reduce complexity without\nsacrificing representational power. CAT achieves O(NlogN) computations,\nrequires fewer learnable parameters by streamlining fully-connected layers, and\nintroduces no heavier operations, resulting in consistent accuracy improvements\nand about a 10% speedup in naive PyTorch implementations on large-scale\nbenchmarks such as ImageNet-1k and WikiText-103. Grounded in an\nengineering-isomorphism framework, CAT's design not only offers practical\nefficiency and ease of implementation but also provides insights to guide the\ndevelopment of next-generation, high-performance Transformer architectures.\nFinally, our ablation studies highlight the key conditions underlying CAT's\nsuccess, shedding light on broader principles for scalable attention\nmechanisms.","main_category":"cs.LG","categories":"cs.LG,cs.CL,cs.CV","published":"2025-04-09T09:08:26Z"}
{"aid":"http://arxiv.org/abs/2504.06707v1","title":"Phase transition of the kinetic Justh-Krishnaprasad type model for\n  nematic alignment","summary":"We present a stochastic Justh-Krishnaprasad flocking model and study the\nphase transition of the Vlasov-McKean-Fokker-Planck (VMFP) equation, which can\nbe obtained in the mean-field limit. To describe the alignment, we use order\nparameters in terms of the distribution function of the kinetic model. For the\nconstant noise case, we study the well-posedness of the VMFP equation on the\ntorus. Based on regularity, we show that the phenomenon of phase transition is\nonly related to the ratio between the strengths of noise and coupling. In\nparticular, for the low-noise case, we derive an exponential convergence to the\nvon-Mises type equilibrium, which shows a strong evidence for the nematic\nalignment. The multiplicative noise is also studied to obtain a non-symmetric\nequilibrium with two different peaks on the torus.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T09:09:24Z"}
{"aid":"http://arxiv.org/abs/2504.06708v1","title":"Transport of electrolytes across nanochannels: the role of slip","summary":"We characterize the electrokinetic flow due to the transport of electrolytes\nembedded in nanochannels of varying cross-section with inhomogeneous slip on\ntheir walls, modeled as an effective slip length on the channel wall. We show\nthat, within linear response and Debye-Huckel regime, the transport\ncoefficients, and so the fluxes, can be significantly improved by the presence\nof a hydrophobic surface coating located at the narrowest section of the\nnanochannel. Our model indicates that the enhancement is larger when\nconsidering electric conductive walls in comparison to dielectric microchannel\nwalls, and it is produced by a synergy between the entropic effects due to the\ngeometry and the presence of the slip boundary layer. Our results show that a\ntailored hydrophobic coating design can be an effective strategy to improve\ntransport properties in the broad areas of lab-on-a-chip, biophysics, and blue\nenergy harvesting and energy conversion technologies.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cond-mat.soft","published":"2025-04-09T09:09:52Z"}
{"aid":"http://arxiv.org/abs/2504.06723v1","title":"5-dimensional minimal quadratic and bilinear forms over function fields\n  of conics","summary":"Over a field of characteristic 2, we give a complete classification of\nquadratic and bilinear forms of dimension 5 that are minimal over the function\nfield of an arbitrary conic. This completes the unique known case due to Faivre\nconcerning the classification of minimal quadratic forms of dimension 5 and\ntype (2,1) over function fields of nonsingular conics.","main_category":"math.AC","categories":"math.AC","published":"2025-04-09T09:23:45Z"}
{"aid":"http://arxiv.org/abs/2504.06730v1","title":"PETNet -- Coincident Particle Event Detection using Spiking Neural\n  Networks","summary":"Spiking neural networks (SNN) hold the promise of being a more biologically\nplausible, low-energy alternative to conventional artificial neural networks.\nTheir time-variant nature makes them particularly suitable for processing\ntime-resolved, sparse binary data. In this paper, we investigate the potential\nof leveraging SNNs for the detection of photon coincidences in positron\nemission tomography (PET) data. PET is a medical imaging technique based on\ninjecting a patient with a radioactive tracer and detecting the emitted\nphotons. One central post-processing task for inferring an image of the tracer\ndistribution is the filtering of invalid hits occurring due to e.g. absorption\nor scattering processes. Our approach, coined PETNet, interprets the detector\nhits as a binary-valued spike train and learns to identify photon coincidence\npairs in a supervised manner. We introduce a dedicated multi-objective loss\nfunction and demonstrate the effects of explicitly modeling the detector\ngeometry on simulation data for two use-cases. Our results show that PETNet can\noutperform the state-of-the-art classical algorithm with a maximal coincidence\ndetection $F_1$ of 95.2%. At the same time, PETNet is able to predict photon\ncoincidences up to 36 times faster than the classical approach, highlighting\nthe great potential of SNNs in particle physics applications.","main_category":"cs.LG","categories":"cs.LG,hep-ex","published":"2025-04-09T09:38:45Z"}
{"aid":"http://arxiv.org/abs/2504.06733v1","title":"Timing the Escape of a Caged Electron","summary":"Charge transfer is fundamentally dependent on the overlap of the orbitals\ncomprising the transport pathway. This has key implications for molecular,\nnanoscale, and quantum technologies, for which delocalization (and decoherence)\nrates are essential figures of merit. Here, we apply the core hole clock\ntechnique - an energy-domain variant of ultrafast spectroscopy - to probe the\ndelocalization of a photoexcited electron inside a closed molecular cage,\nnamely the Ar 2p54s1 state of Ar@C60. Despite marginal frontier orbital mixing\nin the ground configuration, almost 80% of the excited state density is found\noutside the buckyball due to the formation of a markedly diffuse hybrid\norbital. Far from isolating the intracage excitation, the surrounding fullerene\nis instead a remarkably efficient conduit for electron transfer: we measure\ncharacteristic delocalization times of 6.6 $\\pm$ 0.3 fs and $\\lesssim$ 500\nattoseconds, respectively, for a 3D Ar@C60 film and a 2D monolayer on Ag(111).","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-09T09:45:23Z"}
{"aid":"http://arxiv.org/abs/2504.06746v1","title":"Adaptive Human-Robot Collaborative Missions using Hybrid Task Planning","summary":"Producing robust task plans in human-robot collaborative missions is a\ncritical activity in order to increase the likelihood of these missions\ncompleting successfully. Despite the broad research body in the area, which\nconsiders different classes of constraints and uncertainties, its applicability\nis confined to relatively simple problems that can be comfortably addressed by\nthe underpinning mathematically-based or heuristic-driven solver engines. In\nthis paper, we introduce a hybrid approach that effectively solves the task\nplanning problem by decomposing it into two intertwined parts, starting with\nthe identification of a feasible plan and followed by its uncertainty\naugmentation and verification yielding a set of Pareto optimal plans. To\nenhance its robustness, adaptation tactics are devised for the evolving system\nrequirements and agents' capabilities. We demonstrate our approach through an\nindustrial case study involving workers and robots undertaking activities\nwithin a vineyard, showcasing the benefits of our hybrid approach both in the\ngeneration of feasible solutions and scalability compared to native planners.","main_category":"cs.MA","categories":"cs.MA,cs.RO","published":"2025-04-09T10:07:15Z"}
{"aid":"http://arxiv.org/abs/2504.06751v1","title":"Visualisation of a multidimensional point cloud as a 3D swarm of avatars","summary":"The article presents an innovative approach to the visualisation of\nmultidimensional data, using icons inspired by Chernoff faces. The approach\nmerges classical projection techniques with the assignment of particular data\ndimensions to mimic features, capitalizing on the natural ability of the human\nbrain to interpret facial expressions. The technique is implemented as a plugin\nto the dpVision open-source image handling platform. The plugin allows the data\nto be interactively explored in the form of a swarm of \"totems\" whose position\nin hyperspace as well as facial features represent various aspects of the data.\nSample visualisations, based on synthetic test data as well as the vinhoverde\n15-dimensional database on Portuguese wines, confirm the usefulness of our\napproach to the analysis of complex data structures.","main_category":"cs.CV","categories":"cs.CV,cs.HC","published":"2025-04-09T10:14:33Z"}
{"aid":"http://arxiv.org/abs/2504.06754v1","title":"A new norm on the space of reproducing kernel Hilbert space operators\n  and Berezin number inequalities","summary":"In this note, we introduce a novel norm, termed the $t-$Berezin norm, on the\nalgebra of all bounded linear operators defined on a reproducing kernel Hilbert\nspace $\\mathcal{H}$ as\n  $$\\|A\\|_{t-ber} = \\sup_{ \\lambda, \\mu \\in \\Omega} \\left\\{ t|\\langle A\n\\hat{k}_\\lambda, \\hat{k}_\\mu \\rangle| + (1-t) |\\langle A^* \\hat{k}_\\lambda,\n\\hat{k}_\\mu \\rangle| \\right\\}, \\quad t\\in [0,1],$$\n  where $A \\in \\mathcal{B}(\\mathcal{H})$ is a bounded linear operator. This\nnorm characterizes those invertible operators which are also unitary.\n  Using this newly defined norm, we establish various upper bounds for the\nBerezin number, thereby refining the existing results. Additionally, we derive\nseveral sharp bounds for the Berezin number of an operator via the Orlicz\nfunction.","main_category":"math.FA","categories":"math.FA","published":"2025-04-09T10:18:53Z"}
{"aid":"http://arxiv.org/abs/2504.06772v1","title":"Towards Efficient Roadside LiDAR Deployment: A Fast Surrogate Metric\n  Based on Entropy-Guided Visibility","summary":"The deployment of roadside LiDAR sensors plays a crucial role in the\ndevelopment of Cooperative Intelligent Transport Systems (C-ITS). However, the\nhigh cost of LiDAR sensors necessitates efficient placement strategies to\nmaximize detection performance. Traditional roadside LiDAR deployment methods\nrely on expert insight, making them time-consuming. Automating this process,\nhowever, demands extensive computation, as it requires not only visibility\nevaluation but also assessing detection performance across different LiDAR\nplacements. To address this challenge, we propose a fast surrogate metric, the\nEntropy-Guided Visibility Score (EGVS), based on information gain to evaluate\nobject detection performance in roadside LiDAR configurations. EGVS leverages\nTraffic Probabilistic Occupancy Grids (TPOG) to prioritize critical areas and\nemploys entropy-based calculations to quantify the information captured by\nLiDAR beams. This eliminates the need for direct detection performance\nevaluation, which typically requires extensive labeling and computational\nresources. By integrating EGVS into the optimization process, we significantly\naccelerate the search for optimal LiDAR configurations. Experimental results\nusing the AWSIM simulator demonstrate that EGVS strongly correlates with\nAverage Precision (AP) scores and effectively predicts object detection\nperformance. This approach offers a computationally efficient solution for\nroadside LiDAR deployment, facilitating scalable smart infrastructure\ndevelopment.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-09T10:53:03Z"}
{"aid":"http://arxiv.org/abs/2504.06774v1","title":"Hybrid machine learning models based on physical patterns to accelerate\n  CFD simulations: a short guide on autoregressive models","summary":"Accurate modeling of the complex dynamics of fluid flows is a fundamental\nchallenge in computational physics and engineering. This study presents an\ninnovative integration of High-Order Singular Value Decomposition (HOSVD) with\nLong Short-Term Memory (LSTM) architectures to address the complexities of\nreduced-order modeling (ROM) in fluid dynamics. HOSVD improves the\ndimensionality reduction process by preserving multidimensional structures,\nsurpassing the limitations of Singular Value Decomposition (SVD). The\nmethodology is tested across numerical and experimental data sets, including\ntwo- and three-dimensional (2D and 3D) cylinder wake flows, spanning both\nlaminar and turbulent regimes. The emphasis is also on exploring how the depth\nand complexity of LSTM architectures contribute to improving predictive\nperformance. Simpler architectures with a single dense layer effectively\ncapture the periodic dynamics, demonstrating the network's ability to model\nnon-linearities and chaotic dynamics. The addition of extra layers provides\nhigher accuracy at minimal computational cost. These additional layers enable\nthe network to expand its representational capacity, improving the prediction\naccuracy and reliability. The results demonstrate that HOSVD outperforms SVD in\nall tested scenarios, as evidenced by using different error metrics. Efficient\nmode truncation by HOSVD-based models enables the capture of complex temporal\npatterns, offering reliable predictions even in challenging, noise-influenced\ndata sets. The findings underscore the adaptability and robustness of\nHOSVD-LSTM architectures, offering a scalable framework for modeling fluid\ndynamics.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cs.LG","published":"2025-04-09T10:56:03Z"}
{"aid":"http://arxiv.org/abs/2504.06783v1","title":"Organization of Historical Oceanic Overturnings on Cross-Sphere Climate\n  Signals","summary":"The global ocean meridional overturning circulation (GMOC) is central for\nocean transport and climate variations. However, a comprehensive picture of its\nhistorical mean state and variability remains vague due to limitations in\nmodelling and observing systems. Incorporating observations into models offers\na viable approach to reconstructing climate history, yet achieving coherent\nestimates of GMOC has proven challenging due to difficulties in harmonizing\nocean stratification. Here, we demonstrate that applying multiscale data\nassimilation scheme that integrates atmospheric and oceanic observations into\nmultiple coupled models in a dynamically consistent way, the global ocean\ncurrents and GMOC over the past 80 years are retrieved. While the major\nhistoric events are printed in variability of the rebuilt GMOC, the timeseries\nof multisphere 3-dimensional physical variables representing the realistic\nhistorical evolution enable us to advance understanding of mechanisms of\nclimate signal propagation cross spheres and give birth to Artificial\nIntelligence coupled big models, thus advancing the Earth science.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-09T11:15:03Z"}
{"aid":"http://arxiv.org/abs/2504.06786v1","title":"Axion production from electron-nucleon scattering in chiral effective\n  theory","summary":"In this work we study the axion production from the electron-nucleon\nscattering, i.e., the $eN\\to e N a$ processes, being $N$ the proton and\nneutron. We simultaneously include three different types of axion interaction\ncouplings within the chiral effective field theory, namely the\naxion-nucleon-nucleon couplings $g_{aNN}$, axion-photon-photon coupling\n$g_{a\\gamma\\gamma}$ and axion-photon-vector meson resonances couplings $g_{\\rho\na\\gamma}$ and $g_{\\omega a\\gamma}$. Vast inputs from the lattice QCD and hadron\nphenomenological studies are used to fix the unknown couplings. The relative\nstrengths of different axion interactions in the $eN\\to e N a$ processes are\nthen revealed. We provide detailed predictions for the differential cross\nsections with respect to various angles and axion energy, as well as the total\ncross sections, both for the Kim-Shifman-Vainstein-Zakharov (KSVZ) and\nDine-Fischler-Srednicki-Zhitnitsky (DFSZ) axion models.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-09T11:19:20Z"}
{"aid":"http://arxiv.org/abs/2504.06793v1","title":"Variable Metric Splitting Methods for Neuromorphic Circuits Simulation","summary":"This paper proposes a variable metric splitting algorithm to solve the\nelectrical behavior of neuromorphic circuits made of capacitors, memristive\nelements, and batteries. The gradient property of the memristive elements is\nexploited to split the current to voltage operator as the sum of the derivative\noperator, a Riemannian gradient operator, and a nonlinear residual operator\nthat is linearized at each step of the algorithm. The diagonal structure of the\nthree operators makes the variable metric forward-backward splitting algorithm\nscalable and amenable to the simulation of large-scale neuromorphic circuits.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-09T11:34:31Z"}
{"aid":"http://arxiv.org/abs/2504.06797v1","title":"Quantum Field Theory on Multifractal Spacetime: Varying Dimension and\n  Ultraviolet Completeness","summary":"Inspired by various quantum gravity approaches, we explore quantum field\ntheory where spacetime exhibits scaling properties and dimensional reduction\nwith changing energy scales, effectively behaving as a multifractal manifold.\nWorking within canonical quantization, we demonstrate how to properly quantize\nfields in such multifractal spacetime. Our analysis reveals that a\nnon-differentiable nature of spacetime is not merely compatible with quantum\nfield theory but significantly enhances its mathematical foundation. Most\nnotably, this approach guarantees the finiteness of the theory at all orders in\nperturbation theory and enables rigorous construction of the S-matrix in the\ninteraction picture. The multifractal structure tames dominant, large-order\ndivergence sources in the perturbative series and resolves the Landau pole\nproblem through asymptotic safety, substantially improving the theory's\nbehavior in the deep ultraviolet regime. Our formulation preserves all\nestablished predictions of standard quantum field theory at low energies while\noffering novel physical behaviors at high energy scales.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-04-09T11:41:15Z"}
{"aid":"http://arxiv.org/abs/2504.06799v1","title":"Compatibility of Missing Data Handling Methods across the Stages of\n  Producing Clinical Prediction Models","summary":"Missing data is a challenge when developing, validating and deploying\nclinical prediction models (CPMs). Traditionally, decisions concerning missing\ndata handling during CPM development and validation havent accounted for\nwhether missingness is allowed at deployment. We hypothesised that the missing\ndata approach used during model development should optimise model performance\nupon deployment, whilst the approach used during model validation should yield\nunbiased predictive performance estimates upon deployment; we term this\ncompatibility. We aimed to determine which combinations of missing data\nhandling methods across the CPM life cycle are compatible. We considered\nscenarios where CPMs are intended to be deployed with missing data allowed or\nnot, and we evaluated the impact of that choice on earlier modelling decisions.\nThrough a simulation study and an empirical analysis of thoracic surgery data,\nwe compared CPMs developed and validated using combinations of complete case\nanalysis, mean imputation, single regression imputation, multiple imputation,\nand pattern sub-modelling. If planning to deploy a CPM without allowing missing\ndata, then development and validation should use multiple imputation when\nrequired. Where missingness is allowed at deployment, the same imputation\nmethod must be used during development and validation. Commonly used\ncombinations of missing data handling methods result in biased predictive\nperformance estimates.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-09T11:45:10Z"}
{"aid":"http://arxiv.org/abs/2504.06807v1","title":"Evaluating amyloid-beta as a surrogate endpoint in trials of\n  anti-amyloid drugs in Alzheimer's disease: a Bayesian meta-analysis","summary":"The use of amyloid-beta (A$\\beta$) clearance to support regulatory approvals\nof drugs in Alzheimer's disease (AD) remains controversial. We evaluate\nA$\\beta$ as a potential trial-level surrogate endpoint for clinical function in\nAD using a meta-analysis. Randomised controlled trials (RCTs) reporting data on\nthe effectiveness of anti- A$\\beta$ monoclonal antibodies (MABs) on A$\\beta$\nand clinical outcomes were identified through a literature review. A Bayesian\nbivariate meta-analysis was used to evaluate surrogate relationships between\nthe treatment effects on A$\\beta$ and clinical function, with the intercept,\nslope and variance quantifying the trial level association. The analysis was\nperformed using RCT data both collectively across all MABs and separately for\neach MAB through subgroup analysis. The latter analysis was extended by\napplying Bayesian hierarchical models to borrow information across treatments.\nWe identified 23 RCTs with 39 treatment contrasts for seven MABs. The\nassociation between treatment effects on A$\\beta$ and Clinical Dementia Rating\n- Sum of Boxes (CDR-SOB) across all MABs was strong: with intercept of -0.03\n(95% credible intervals: -0.16, 0.11), slope of 1.41 (0.60, 2.21) and variance\nof 0.02 (0.00, 0.05). For individual treatments, the surrogate relationships\nwere suboptimal, displaying large uncertainty. The use of hierarchical models\nconsiderably reduced the uncertainty around key parameters, narrowing the\nintervals for the slopes by an average of 71% (range: 51%-95%) and for the\nvariances by 28% (7%-65%). Our results suggest that A$\\beta$ is a potential\nsurrogate endpoint for CDR-SOB when assuming a common surrogate relationship\nacross all MABs. When allowing for information-sharing, the surrogate\nrelationships improved, but only for lecanemab and aducanumab was the\nimprovement sufficient to support a surrogate relationship.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-09T11:55:05Z"}
{"aid":"http://arxiv.org/abs/2504.06811v1","title":"Hybrid CNN with Chebyshev Polynomial Expansion for Medical Image\n  Analysis","summary":"Lung cancer remains one of the leading causes of cancer-related mortality\nworldwide, with early and accurate diagnosis playing a pivotal role in\nimproving patient outcomes. Automated detection of pulmonary nodules in\ncomputed tomography (CT) scans is a challenging task due to variability in\nnodule size, shape, texture, and location. Traditional Convolutional Neural\nNetworks (CNNs) have shown considerable promise in medical image analysis;\nhowever, their limited ability to capture fine-grained spatial-spectral\nvariations restricts their performance in complex diagnostic scenarios. In this\nstudy, we propose a novel hybrid deep learning architecture that incorporates\nChebyshev polynomial expansions into CNN layers to enhance expressive power and\nimprove the representation of underlying anatomical structures. The proposed\nChebyshev-CNN leverages the orthogonality and recursive properties of Chebyshev\npolynomials to extract high-frequency features and approximate complex\nnonlinear functions with greater fidelity. The model is trained and evaluated\non benchmark lung cancer imaging datasets, including LUNA16 and LIDC-IDRI,\nachieving superior performance in classifying pulmonary nodules as benign or\nmalignant. Quantitative results demonstrate significant improvements in\naccuracy, sensitivity, and specificity compared to traditional CNN-based\napproaches. This integration of polynomial-based spectral approximation within\ndeep learning provides a robust framework for enhancing automated medical\ndiagnostics and holds potential for broader applications in clinical decision\nsupport systems.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-09T12:02:56Z"}
{"aid":"http://arxiv.org/abs/2504.06812v1","title":"Semi-classical geometric tensor in multiparameter quantum information","summary":"The quantum geometric tensor (QGT) captures the variations of quantum states\nwith parameters, serving as a central concept in modern quantum physics. Its\nreal part, the quantum Fisher information matrix (QFIM), has a\nmeasurement-dependent counterpart that links statistics to distinguishability.\nHowever, an analogous extension for the QGT is hindered by the fundamental\ninaccessibility of its imaginary part through measurement probabilities. Here\nwe introduce a counterpart to the QGT that includes measurement operators,\ntermed the \\textit{semi-classical} geometric tensor (SCGT). We show that the\nSCGT provides a lower bound to the QGT that is tight for pure states. Moreover,\nwe use the SCGT to derive sharp multiparameter information bounds and discuss\nextensions of the Berry phase.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-09T12:06:57Z"}
{"aid":"http://arxiv.org/abs/2504.06814v1","title":"Revisit Gradient Descent for Geodesically Convex Optimization","summary":"In a seminal work of Zhang and Sra, gradient descent methods for geodesically\nconvex optimization were comprehensively studied. In particular, based on a\nrefined use of the triangle comparison theorem of Toponogov, Zhang and Sra\nderived a comparison inequality that relates the current iterate, the next\niterate and the optimum point. Since their seminal work, numerous follow-ups\nhave studied different downstream usages of their comparison lemma. However,\nall results along this line relies on strong assumptions, such as bounded\ndomain assumption or curvature bounded below assumption.\n  In this work, we introduce the concept of quasilinearization to optimization,\npresenting a novel framework for analyzing geodesically convex optimization. By\nleveraging this technique, we establish state-of-the-art convergence rates --\nfor both deterministic and stochastic settings -- under substantially weaker\nassumptions than previously required.","main_category":"math.OC","categories":"math.OC","published":"2025-04-09T12:08:43Z"}
{"aid":"http://arxiv.org/abs/2504.06815v1","title":"SVG-IR: Spatially-Varying Gaussian Splatting for Inverse Rendering","summary":"Reconstructing 3D assets from images, known as inverse rendering (IR),\nremains a challenging task due to its ill-posed nature. 3D Gaussian Splatting\n(3DGS) has demonstrated impressive capabilities for novel view synthesis (NVS)\ntasks. Methods apply it to relighting by separating radiance into BRDF\nparameters and lighting, yet produce inferior relighting quality with artifacts\nand unnatural indirect illumination due to the limited capability of each\nGaussian, which has constant material parameters and normal, alongside the\nabsence of physical constraints for indirect lighting. In this paper, we\npresent a novel framework called Spatially-vayring Gaussian Inverse Rendering\n(SVG-IR), aimed at enhancing both NVS and relighting quality. To this end, we\npropose a new representation-Spatially-varying Gaussian (SVG)-that allows\nper-Gaussian spatially varying parameters. This enhanced representation is\ncomplemented by a SVG splatting scheme akin to vertex/fragment shading in\ntraditional graphics pipelines. Furthermore, we integrate a physically-based\nindirect lighting model, enabling more realistic relighting. The proposed\nSVG-IR framework significantly improves rendering quality, outperforming\nstate-of-the-art NeRF-based methods by 2.5 dB in peak signal-to-noise ratio\n(PSNR) and surpassing existing Gaussian-based techniques by 3.5 dB in\nrelighting tasks, all while maintaining a real-time rendering speed.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T12:11:58Z"}
{"aid":"http://arxiv.org/abs/2504.06817v1","title":"Unparalleled instances of prolifickness, random walks, and square root\n  boundaries","summary":"We revisit the problem of influencing the sex ratio of a population by\nsubjecting reproduction of each family to some stopping rule. As an easy\nconsequence of the strong law of large numbers, no such modification is\npossible in the sense that the ratio converges to 1 almost surely, for any\nstopping rule that is finite almost surely. We proceed to quantify the effects\nand provide limit distributions for the properly rescaled sex ratio. Besides\nthe total ratio, which is predominantly considered in the pertinent literature,\nwe also analyze the average sex ratio, which may converge to values different\nfrom 1. The first part of this note is largely expository, applying classical\nresults and standard methods from the fluctuation theory of random walks. In\nthe second part we apply tail asymptotics for the time at which a random walk\nhits a one-sided square root boundary, exhibit the differences to the\ncorresponding two-sided problem, and use a limit law related to the empirical\ndispersion coefficient of a heavy-tailed distribution. Finally, we derive a\nlarge deviations result for a special stopping strategy, using saddle point\nasymptotics.","main_category":"math.PR","categories":"math.PR","published":"2025-04-09T12:19:37Z"}
{"aid":"http://arxiv.org/abs/2504.06821v1","title":"Inducing Programmatic Skills for Agentic Tasks","summary":"To succeed in common digital tasks such as web navigation, agents must carry\nout a variety of specialized tasks such as searching for products or planning a\ntravel route. To tackle these tasks, agents can bootstrap themselves by\nlearning task-specific skills online through interaction with the web\nenvironment. In this work, we demonstrate that programs are an effective\nrepresentation for skills. We propose agent skill induction (ASI), which allows\nagents to adapt themselves by inducing, verifying, and utilizing program-based\nskills on the fly. We start with an evaluation on the WebArena agent benchmark\nand show that ASI outperforms the static baseline agent and its text-skill\ncounterpart by 23.5% and 11.3% in success rate, mainly thanks to the\nprogrammatic verification guarantee during the induction phase. ASI also\nimproves efficiency by reducing 10.7-15.3% of the steps over baselines, by\ncomposing primitive actions (e.g., click) into higher-level skills (e.g.,\nsearch product). We then highlight the efficacy of ASI in remaining efficient\nand accurate under scaled-up web activities. Finally, we examine the\ngeneralizability of induced skills when transferring between websites, and find\nthat ASI can effectively reuse common skills, while also updating incompatible\nskills to versatile website changes.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T12:25:37Z"}
{"aid":"http://arxiv.org/abs/2504.06823v1","title":"Open Problems and a Hypothetical Path Forward in LLM Knowledge Paradigms","summary":"Knowledge is fundamental to the overall capabilities of Large Language Models\n(LLMs). The knowledge paradigm of a model, which dictates how it encodes and\nutilizes knowledge, significantly affects its performance. Despite the\ncontinuous development of LLMs under existing knowledge paradigms, issues\nwithin these frameworks continue to constrain model potential.\n  This blog post highlight three critical open problems limiting model\ncapabilities: (1) challenges in knowledge updating for LLMs, (2) the failure of\nreverse knowledge generalization (the reversal curse), and (3) conflicts in\ninternal knowledge. We review recent progress made in addressing these issues\nand discuss potential general solutions. Based on observations in these areas,\nwe propose a hypothetical paradigm based on Contextual Knowledge Scaling, and\nfurther outline implementation pathways that remain feasible within\ncontemporary techniques. Evidence suggests this approach holds potential to\naddress current shortcomings, serving as our vision for future model paradigms.\n  This blog post aims to provide researchers with a brief overview of progress\nin LLM knowledge systems, while provide inspiration for the development of\nnext-generation model architectures.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T12:31:25Z"}
{"aid":"http://arxiv.org/abs/2504.06826v1","title":"Long-period double-lined eclipsing binaries: the system V454 Aur with\n  the secondary eclipse caused by the occultation of the hotter component","summary":"We present the results of our study of the long-period eclipsing binary star\n\\Aur. The results are based on spectroscopic data obtained with the UFES\n\\'echelle spectrograph and photometric observations from TESS. The derived\nradial velocity curve is based on 17 spectra obtained between 2021 and 2023,\ncovering all orbital phases of this binary system. The orbital period\ndetermined from TESS data, $P = 27.019803 \\pm 0.000003$ days, agrees within\nuncertainties with the period established in previous studies. The model\nconstructed for the TESS photometric light curve achieves a precision of\n0.01\\%. The effective temperatures of both components, as well as the system\nmetallicity, were directly derived from the spectra and are $T_\\mathrm{eff, A}\n= 6250 \\pm 50$\\,K, $T_\\mathrm{eff, B} = 5855 \\pm 50$\\,K, and $\\mathrm{[Fe/H]} =\n-0.10 \\pm 0.08$, respectively. Our analysis of the photometric and\nspectroscopic data allowed us to directly compute the luminosities of the\ncomponents, $L_A = 1.82\\,L_\\odot$ and $L_B = 1.07\\,L_\\odot$, their radii, $R_A\n= 1.15\\,R_\\odot$ and $R_B = 1.00\\,R_\\odot$, and their masses, $M_A =\n1.137\\,M_\\odot$ and $M_B = 1.023\\,M_\\odot$, with uncertainties below 1\\%.\nComparison with evolutionary tracks indicates that the system's age is $1.18\n\\pm 0.10$\\,Gyr, and both components are still on the main sequence. The \\Aur\\\nsystem is particularly interesting due to the partial eclipse of the primary\ncomponent, which results in the ``inversion'' of the primary and secondary\nminima in the photometric light curve.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-09T12:34:35Z"}
{"aid":"http://arxiv.org/abs/2504.06838v1","title":"ZIP: An Efficient Zeroth-order Prompt Tuning for Black-box\n  Vision-Language Models","summary":"Recent studies have introduced various approaches for prompt-tuning black-box\nvision-language models, referred to as black-box prompt-tuning (BBPT). While\nBBPT has demonstrated considerable potential, it is often found that many\nexisting methods require an excessive number of queries (i.e., function\nevaluations), which poses a significant challenge in real-world scenarios where\nthe number of allowed queries is limited. To tackle this issue, we propose\nZeroth-order Intrinsic-dimensional Prompt-tuning (ZIP), a novel approach that\nenables efficient and robust prompt optimization in a purely black-box setting.\nThe key idea of ZIP is to reduce the problem dimensionality and the variance of\nzeroth-order gradient estimates, such that the training is done fast with far\nless queries. We achieve this by re-parameterizing prompts in low-rank\nrepresentations and designing intrinsic-dimensional clipping of estimated\ngradients. We evaluate ZIP on 13+ vision-language tasks in standard benchmarks\nand show that it achieves an average improvement of approximately 6% in\nfew-shot accuracy and 48% in query efficiency compared to the best-performing\nalternative BBPT methods, establishing a new state of the art. Our ablation\nanalysis further shows that the proposed clipping mechanism is robust and\nnearly optimal, without the need to manually select the clipping threshold,\nmatching the result of expensive hyperparameter search.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-09T12:56:22Z"}
{"aid":"http://arxiv.org/abs/2504.06850v1","title":"Symmetric splitting of one-dimensional noises","summary":"A symmetric random walk $X$ whose jumps have diffuse law, looked at up to an\nindependent geometric random time, splits at the minimum into two independent\nand identically distributed pieces. The same for the maxima. It is natural to\nask, are there any other times ``adapted'' to $X$ exhibiting this ``symmetric\nsplitting'' property? It appears that the phenomenon is most conveniently\ncouched in terms of the ``noise'' structure associated to $X$. At the level of\ngenerality of the latter, an equivalent set-theoretic condition for the\nsymmetric splitting property is provided, leading to the observation that the\nanswer to the elucidated question is to the affirmative. While we do not deal\nmuch with the obvious analog of the phenomenon in continuous time, the discrete\nfindings do beg the question: does linear Brownian motion admit times of\nsymmetric splitting other than the maxima and minima? This is left unresolved,\nbut we do make some comments as to why it may be non-trivial/interesting.","main_category":"math.PR","categories":"math.PR","published":"2025-04-09T13:05:23Z"}
{"aid":"http://arxiv.org/abs/2504.06857v1","title":"Machine Learning-Assisted Unfolding for Neutrino Cross-section\n  Measurements","summary":"The choice of unfolding method for a cross-section measurement is tightly\ncoupled to the model dependence of the efficiency correction and the overall\nimpact of cross-section modeling uncertainties in the analysis. A key issue is\nthe dimensionality used in unfolding, as the kinematics of all outgoing\nparticles in an event typically affect the reconstruction performance in a\nneutrino detector. OmniFold is an unfolding method that iteratively reweights a\nsimulated dataset, using machine learning to utilize arbitrarily\nhigh-dimensional information, that has previously been applied to proton-proton\nand proton-electron datasets. This paper demonstrates OmniFold's application to\na neutrino cross-section measurement for the first time using a public T2K near\ndetector simulated dataset, comparing its performance with traditional\napproaches using a mock data study.","main_category":"hep-ex","categories":"hep-ex,hep-ph,physics.data-an","published":"2025-04-09T13:08:35Z"}
{"aid":"http://arxiv.org/abs/2504.06862v1","title":"Dynamics of critical cascades in interdependent networks","summary":"The collapse of interdependent networks, as well as similar avalanche\nphenomena, is driven by cascading failures. At the critical point, the cascade\nbegins as a critical branching process, where each failing node (element)\ntriggers, on average, the failure of one other node. As nodes continue to fail,\nthe network becomes increasingly fragile and the branching factor grows. If the\nfailure process does not reach extinction during its critical phase, the\nnetwork undergoes an abrupt collapse. Here, we implement the analogy between\nthis dynamic and birth-death processes to derive new analytical results and\nsignificantly optimize numerical calculations. Using this approach, we analyze\nthree key aspects of the dynamics: the probability of collapse, the duration of\navalanches, and the length of the cascading plateau phase preceding a collapse.\nThis analysis quantifies how system size and the intensity of the initial\ntriggering event influence these characteristics.","main_category":"physics.soc-ph","categories":"physics.soc-ph,q-bio.PE","published":"2025-04-09T13:12:43Z"}
{"aid":"http://arxiv.org/abs/2504.06863v1","title":"MovSAM: A Single-image Moving Object Segmentation Framework Based on\n  Deep Thinking","summary":"Moving object segmentation plays a vital role in understanding dynamic visual\nenvironments. While existing methods rely on multi-frame image sequences to\nidentify moving objects, single-image MOS is critical for applications like\nmotion intention prediction and handling camera frame drops. However,\nsegmenting moving objects from a single image remains challenging for existing\nmethods due to the absence of temporal cues. To address this gap, we propose\nMovSAM, the first framework for single-image moving object segmentation. MovSAM\nleverages a Multimodal Large Language Model (MLLM) enhanced with\nChain-of-Thought (CoT) prompting to search the moving object and generate text\nprompts based on deep thinking for segmentation. These prompts are cross-fused\nwith visual features from the Segment Anything Model (SAM) and a\nVision-Language Model (VLM), enabling logic-driven moving object segmentation.\nThe segmentation results then undergo a deep thinking refinement loop, allowing\nMovSAM to iteratively improve its understanding of the scene context and\ninter-object relationships with logical reasoning. This innovative approach\nenables MovSAM to segment moving objects in single images by considering scene\nunderstanding. We implement MovSAM in the real world to validate its practical\napplication and effectiveness for autonomous driving scenarios where the\nmulti-frame methods fail. Furthermore, despite the inherent advantage of\nmulti-frame methods in utilizing temporal information, MovSAM achieves\nstate-of-the-art performance across public MOS benchmarks, reaching 92.5\\% on\nJ\\&F. Our implementation will be available at\nhttps://github.com/IRMVLab/MovSAM.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T13:12:58Z"}
{"aid":"http://arxiv.org/abs/2504.06868v1","title":"Persona Dynamics: Unveiling the Impact of Personality Traits on Agents\n  in Text-Based Games","summary":"Artificial agents are increasingly central to complex interactions and\ndecision-making tasks, yet aligning their behaviors with desired human values\nremains an open challenge. In this work, we investigate how human-like\npersonality traits influence agent behavior and performance within text-based\ninteractive environments. We introduce PANDA: PersonalityAdapted Neural\nDecision Agents, a novel method for projecting human personality traits onto\nagents to guide their behavior. To induce personality in a text-based game\nagent, (i) we train a personality classifier to identify what personality type\nthe agent's actions exhibit, and (ii) we integrate the personality profiles\ndirectly into the agent's policy-learning pipeline. By deploying agents\nembodying 16 distinct personality types across 25 text-based games and\nanalyzing their trajectories, we demonstrate that an agent's action decisions\ncan be guided toward specific personality profiles. Moreover, certain\npersonality types, such as those characterized by higher levels of Openness,\ndisplay marked advantages in performance. These findings underscore the promise\nof personality-adapted agents for fostering more aligned, effective, and\nhuman-centric decision-making in interactive environments.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-09T13:17:00Z"}
{"aid":"http://arxiv.org/abs/2504.06874v1","title":"Optical imaging of spontaneous electric polarizations in tetralayer\n  graphene","summary":"The recent discovery of sliding ferroelectricity has sparked intense\ninterests in studying interfacial polarizations in two-dimensional (2D) van der\nWaals materials. However, akin to the conventional ferroelectrics, the studies\nhave predominantly reported semiconducting and/or insulating moir\\'e systems\nand binary compounds. Spontaneous electric polarizations in elemental metallic\nphases remain scarcity. Here, we report the first optical imaging of intrinsic\nout-of-plane electric polarizations and domain wall (DW) sliding dynamics in\ntetralayer graphene, a 2D conductive layer composed entirely of carbon. Using\nscanning near-field optical microscopy (SNOM), we directly visualize adjacent\nABAC and ABCB stacking orders with intrinsic and opposite electric\npolarizations. Our gate-dependent SNOM measurements reveal distinct optical\nresponse that systematically changes upon carrier doping and unconventional\ninterplay between DW sliding and electric polarizations, which are supported by\ndensity functional theory (DFT) calculations. Independent corroboration through\nKelvin probe force microscopy (KPFM) and Raman spectroscopy confirms the polar\nnature and their polarization directions. Furthermore, reversible mechanical\nswitching of polar states via atomic force microscopy (AFM) tip manipulation is\nalso demonstrated. Our work establishes SNOM as a critical tool for probing\nsliding ferroelectricity in conductive 2D layers, opening avenues for exploring\nmultiferroic behaviors and nonvolatile memory applications in atomically thin\nmetals at room temperature.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-09T13:26:25Z"}
{"aid":"http://arxiv.org/abs/2504.06878v1","title":"CRYSIM: Prediction of Symmetric Structures of Large Crystals with\n  GPU-based Ising Machines","summary":"Solving black-box optimization problems with Ising machines is increasingly\ncommon in materials science. However, their application to crystal structure\nprediction (CSP) is still ineffective due to symmetry agnostic encoding of\natomic coordinates. We introduce CRYSIM, an algorithm that encodes the space\ngroup, the Wyckoff positions combination, and coordinates of independent atomic\nsites as separate variables. This encoding reduces the search space\nsubstantially by exploiting the symmetry in space groups. When CRYSIM is\ninterfaced to Fixstars Amplify, a GPU-based Ising machine, its prediction\nperformance was competitive with CALYPSO and Bayesian optimization for crystals\ncontaining more than 150 atoms in a unit cell. Although it is not realistic to\ninterface CRYSIM to current small-scale quantum devices, it has the potential\nto become the standard CSP algorithm in the coming quantum age.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cs.LG","published":"2025-04-09T13:33:48Z"}
{"aid":"http://arxiv.org/abs/2504.06883v1","title":"The Dirac Equation, Mass and Arithmetic by Permutations of Automaton\n  States","summary":"The cornerstones of the Cellular Automaton Interpretation of Quantum\nMechanics are its underlying ontological states that evolve by permutations.\nThey do not create would-be quantum mechanical superposition states. We review\nthis with a classical automaton consisting of an Ising spin chain which is then\nrelated to the Weyl equation in the continuum limit. Based on this and\ngeneralizing, we construct a new ``Necklace of Necklaces'' automaton with a\ntorus-like topology that lends itself to represent the Dirac equation in 1 + 1\ndimensions. Special attention has to be paid to its mass term, which\nnecessitates this enlarged structure and a particular scattering operator\ncontributing to the step-wise updates of the automaton. As discussed earlier,\nsuch deterministic models of discrete spins or bits unavoidably become quantum\nmechanical, when only slightly deformed.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.MP,nlin.CG","published":"2025-04-09T13:37:12Z"}
{"aid":"http://arxiv.org/abs/2504.06884v1","title":"Audio-visual Event Localization on Portrait Mode Short Videos","summary":"Audio-visual event localization (AVEL) plays a critical role in multimodal\nscene understanding. While existing datasets for AVEL predominantly comprise\nlandscape-oriented long videos with clean and simple audio context, short\nvideos have become the primary format of online video content due to the the\nproliferation of smartphones. Short videos are characterized by\nportrait-oriented framing and layered audio compositions (e.g., overlapping\nsound effects, voiceovers, and music), which brings unique challenges\nunaddressed by conventional methods. To this end, we introduce AVE-PM, the\nfirst AVEL dataset specifically designed for portrait mode short videos,\ncomprising 25,335 clips that span 86 fine-grained categories with frame-level\nannotations. Beyond dataset creation, our empirical analysis shows that\nstate-of-the-art AVEL methods suffer an average 18.66% performance drop during\ncross-mode evaluation. Further analysis reveals two key challenges of different\nvideo formats: 1) spatial bias from portrait-oriented framing introduces\ndistinct domain priors, and 2) noisy audio composition compromise the\nreliability of audio modality. To address these issues, we investigate optimal\npreprocessing recipes and the impact of background music for AVEL on portrait\nmode videos. Experiments show that these methods can still benefit from\ntailored preprocessing and specialized model design, thus achieving improved\nperformance. This work provides both a foundational benchmark and actionable\ninsights for advancing AVEL research in the era of mobile-centric video\ncontent. Dataset and code will be released.","main_category":"cs.MM","categories":"cs.MM,cs.AI,cs.CV","published":"2025-04-09T13:38:40Z"}
{"aid":"http://arxiv.org/abs/2504.06888v1","title":"The Singular CR Yamabe Problem and Hausdorff Dimension","summary":"We consider a compact pseudo-hermitian manifold (M,\\theta, J), that is a\nmanifold equipped with a contact form \\theta and CR structure J. We consider a\nconformal deformation of the contact form to obtain a complete, singular\ncontact form and a corresponding Yamabe problem. We estimate then the Hausdorff\ndimension of the singular set. The conformal geometry analog of this result is\ndue to R. Schoen and S. -T. Yau. Results of this type have their origin in work\nby Huber for Riemann surfaces. In the second part of our paper we investigate\nthe CR developing map for three dimensional CR manifolds. We establish the\ninjectivity of the developing map essentially using the same strategy as Schoen\nand Yau for the conformal case which is based on the positive mass theorem.\nHigher dimensional analogs of Huber's theorem in the conformal case for Q\ncurvature are due to Alice Chang, Jie Qing and P. Yang.","main_category":"math.DG","categories":"math.DG","published":"2025-04-09T13:49:53Z"}
{"aid":"http://arxiv.org/abs/2504.06892v1","title":"Applications of Hybrid Machine Learning Methods to Large Datasets: A\n  Case Study","summary":"We combine classical and quantum Machine Learning (ML) techniques to\neffectively analyze long time-series data acquired during experiments.\nSpecifically, we demonstrate that replacing a deep classical neural network\nwith a thoughtfully designed Variational Quantum Circuit (VQC) in an ML\npipeline for multiclass classification of time-series data yields the same\nclassification performance, while significantly reducing the number of\ntrainable parameters. To achieve this, we use a VQC based on a single qudit,\nand encode the classical data into the VQC via a trainable hybrid autoencoder\nwhich has been recently proposed as embedding technique. Our results highlight\nthe importance of tailored data pre-processing for the circuit and show the\npotential of qudit-based VQCs.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T13:53:27Z"}
{"aid":"http://arxiv.org/abs/2504.06900v1","title":"On Poincaré constants related to isoperimetric problems in convex\n  bodies","summary":"For any convex set $\\Omega \\subset {\\mathbb R} ^N$, we provide a lower bound\nfor the inverse of the Poincar\\'e constant in $W ^ {1, 1}(\\Omega)$: it refines\nan inequality in terms of the diameter due to Acosta-Duran, via the addition of\nan extra term giving account for the flatness of the domain. In dimension $N =\n2$, we are able to make the extra term completely explicit, thus providing a\nnew Bonnesen-type inequality for the Poincar\\'e constant in terms of diameter\nand inradius. Such estimate is sharp, and it is asymptotically attained when\nthe domain is the intersection of a ball with a strip bounded by parallel\nstraight lines, symmetric about the centre of the ball. As a key intermediate\nstep, we prove that the ball maximizes the Poincar\\'e constant in $W ^ {1, 1}\n(\\Omega)$, among convex bodies $\\Omega$ of given constant width.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T14:00:04Z"}
{"aid":"http://arxiv.org/abs/2504.06916v1","title":"Semi-Orthogonal Decompositions for Rank Two Imprimitive Reflection\n  Groups","summary":"For every imprimitive complex reflection group of rank 2, we construct a\nsemi-orthogonal decomposition of the derived category of the associated global\nquotient stack which categorifies the usual decomposition of the orbifold\ncohomology indexed by conjugacy classes. This confirms a conjecture of\nPolishchuk and Van den Bergh in these cases. This conjecture was recently also\nproved by Ishii and Nimura for arbitrary complex reflection groups of rank at\nmost 3, but our approach is very different.","main_category":"math.AG","categories":"math.AG,math.RT","published":"2025-04-09T14:23:21Z"}
{"aid":"http://arxiv.org/abs/2504.06919v1","title":"Correcting for interloper contamination in the power spectrum with\n  neural networks","summary":"Modern slitless spectroscopic surveys, such as Euclid and the Roman Space\nTelescope, collect vast numbers of galaxy spectra but suffer from low\nsignal-to-noise ratios. This often leads to incorrect redshift assignments when\nrelying on a single emission line, due to noise spikes or contamination from\nnon-target emission lines, commonly referred to as redshift interlopers. We\npropose a machine learning approach to correct the impact of interlopers at the\nlevel of measured summary statistics, focusing on the power spectrum monopole\nand line interlopers as a proof of concept. To model interloper effects, we use\nhalo catalogs from the Quijote simulations as proxies for galaxies, displacing\na fraction of halos by the distance corresponding to the redshift offset\nbetween target and interloper galaxies. This yields contaminated catalogs with\nvarying interloper fractions across a wide range of cosmologies from the\nQuijote suite. We train a neural network on the power spectrum monopole, alone\nor combined with the bispectrum monopole, from contaminated mocks to estimate\nthe interloper fraction and reconstruct the cleaned power spectrum. We evaluate\nperformance in two settings: one with fixed cosmology and another where\ncosmological parameters vary under broad priors. In the fixed case, the network\nrecovers the interloper fraction and corrects the power spectrum to better than\n1% accuracy. When cosmology varies, performance degrades, but adding bispectrum\ninformation significantly improves results, reducing the interloper fraction\nerror by 40-60%. We also study the method's performance as a function of the\nsize of the training set and find that optimal strategies depend on the\ncorrelation between target and interloper samples: bispectrum information aids\nperformance when target and interloper galaxies are uncorrelated, while tighter\npriors are more effective when the two are strongly correlated.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-09T14:24:19Z"}
{"aid":"http://arxiv.org/abs/2504.06932v1","title":"Maximizing Battery Storage Profits via High-Frequency Intraday Trading","summary":"Maximizing revenue for grid-scale battery energy storage systems in\ncontinuous intraday electricity markets requires strategies that are able to\nseize trading opportunities as soon as new information arrives. This paper\nintroduces and evaluates an automated high-frequency trading strategy for\nbattery energy storage systems trading on the intraday market for power while\nexplicitly considering the dynamics of the limit order book, market rules, and\ntechnical parameters. The standard rolling intrinsic strategy is adapted for\ncontinuous intraday electricity markets and solved using a dynamic programming\napproximation that is two to three orders of magnitude faster than an exact\nmixed-integer linear programming solution. A detailed backtest over a full year\nof German order book data demonstrates that the proposed dynamic programming\nformulation does not reduce trading profits and enables the policy to react to\nevery relevant order book update, enabling realistic rapid backtesting. Our\nresults show the significant revenue potential of high-frequency trading: our\npolicy earns 58% more than when re-optimizing only once every hour and 14% more\nthan when re-optimizing once per minute, highlighting that profits critically\ndepend on trading speed. Furthermore, we leverage the speed of our algorithm to\ntrain a parametric extension of the rolling intrinsic, increasing yearly\nrevenue by 8.4% out of sample.","main_category":"q-fin.TR","categories":"q-fin.TR,cs.SY,eess.SY,math.OC","published":"2025-04-09T14:38:09Z"}
{"aid":"http://arxiv.org/abs/2504.06942v1","title":"Density Approximation of Affine Jump Diffusions via Closed-Form Moment\n  Matching","summary":"We develop a recursive approach for deriving closed-form solutions to both\nconditional and unconditional moments of affine jump diffusions with\nstate-independent jump intensities. Using these moment solutions, we construct\nclosed-form density approximations (up to a normalization constant) via moment\nmatching for both conditional and unconditional distributions. Our framework\nenables important financial applications, including efficient option pricing\nand exact simulation for affine jump diffusions. Numerical experiments\ndemonstrate the method's superior computational efficiency compared to existing\nsimulation techniques, while preserving numerical precision.","main_category":"q-fin.MF","categories":"q-fin.MF","published":"2025-04-09T14:50:18Z"}
{"aid":"http://arxiv.org/abs/2504.06948v1","title":"An improved quantum algorithm for linear autonomous differential\n  equations via Padé approximation","summary":"We propose a novel quantum algorithm for solving linear autonomous ordinary\ndifferential equations (ODEs) using the Pad\\'e approximation. For linear\nautonomous ODEs, the discretized solution can be represented by a product of\nmatrix exponentials. The proposed algorithm approximates the matrix exponential\nby the diagonal Pad\\'e approximation, which is then encoded into a large,\nblock-sparse linear system and solved via quantum linear system algorithms\n(QLSA). The detailed quantum circuit is given based on quantum oracle access to\nthe matrix, the inhomogeneous term, and the initial state. The complexity of\nthe proposed algorithm is analyzed. Compared to the method based on Taylor\napproximation, which approximates the matrix exponential using a $k$-th order\nTaylor series, the proposed algorithm improves the approximation order $k$ from\ntwo perspectives: 1) the explicit complexity dependency on $k$ is improved, and\n2) a smaller $k$ suffices for the same precision. Numerical experiments\ndemonstrate the advantages of the proposed algorithm comparing to other related\nalgorithms.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T14:54:27Z"}
{"aid":"http://arxiv.org/abs/2504.06952v1","title":"Holographic hybrid stars with slow phase transitions","summary":"The $D_3$-$D_7$ holographic model is used to describe the core of the hybrid\nstar, composed by quark matter, while its crust is modeled from a hadronic\nrelativistic mean field (RMF) model capable of reproducing low-energy nuclear\nphysics data as well as some astrophysical observations. The $D_3$-$D_7$ brane\nconfiguration and the RMF model lead to an equation of state that is used to\nsolve the Tolman-Oppenheimer-Volkoff equations. For different model parameters,\nthe mass-radius diagram is presented. The conditions for the dynamic stability\nof stellar configurations are discussed, considering the radial oscillation\ncriterion for hybrid stars with slow phase transitions. Strikingly, it is shown\nthat the models generate stable star configurations with a core of quarks. We\ncompare our results with NICER observational data for the pulsars PSR\nJ0030+0451 and PSR J0740+6620 and show that the compact stars generated from\nthis method fall within the corresponding observational regions.","main_category":"nucl-th","categories":"nucl-th,hep-ph","published":"2025-04-09T14:58:58Z"}
{"aid":"http://arxiv.org/abs/2504.06956v1","title":"How does the supercritical GMC converge?","summary":"In the spirit of [M. Biskup & O. Louidor, Adv. Math. 330 (2018)], we study\nthe local structure of $\\star$-scale invariant fields -- a class of\nlog-correlated Gaussian fields -- around their extremal points by\ncharacterising the law of the \"shape\" of the field's configuration near such\npoints. As a consequence, we obtain a refined understanding of the freezing\nphenomenon in supercritical Gaussian multiplicative chaos.","main_category":"math.PR","categories":"math.PR,math-ph,math.MP","published":"2025-04-09T15:04:19Z"}
{"aid":"http://arxiv.org/abs/2504.06957v1","title":"A Comparison of Deep Learning Methods for Cell Detection in Digital\n  Cytology","summary":"Accurate and efficient cell detection is crucial in many biomedical image\nanalysis tasks. We evaluate the performance of several Deep Learning (DL)\nmethods for cell detection in Papanicolaou-stained cytological Whole Slide\nImages (WSIs), focusing on accuracy of predictions and computational\nefficiency. We examine recentoff-the-shelf algorithms as well as\ncustom-designed detectors, applying them to two datasets: the CNSeg Dataset and\nthe Oral Cancer (OC) Dataset. Our comparison includes well-established\nsegmentation methods such as StarDist, Cellpose, and the Segment Anything Model\n2 (SAM2), alongside centroid-based Fully Convolutional Regression Network\n(FCRN) approaches. We introduce a suitable evaluation metric to assess the\naccuracy of predictions based on the distance from ground truth positions. We\nalso explore the impact of dataset size and data augmentation techniques on\nmodel performance. Results show that centroid-based methods, particularly the\nImproved Fully Convolutional Regression Network (IFCRN) method, outperform\nsegmentation-based methods in terms of both detection accuracy and\ncomputational efficiency. This study highlights the potential of centroid-based\ndetectors as a preferred option for cell detection in resource-limited\nenvironments, offering faster processing times and lower GPU memory usage\nwithout compromising accuracy.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T15:08:12Z"}
{"aid":"http://arxiv.org/abs/2504.06961v1","title":"Two by Two: Learning Multi-Task Pairwise Objects Assembly for\n  Generalizable Robot Manipulation","summary":"3D assembly tasks, such as furniture assembly and component fitting, play a\ncrucial role in daily life and represent essential capabilities for future home\nrobots. Existing benchmarks and datasets predominantly focus on assembling\ngeometric fragments or factory parts, which fall short in addressing the\ncomplexities of everyday object interactions and assemblies. To bridge this\ngap, we present 2BY2, a large-scale annotated dataset for daily pairwise\nobjects assembly, covering 18 fine-grained tasks that reflect real-life\nscenarios, such as plugging into sockets, arranging flowers in vases, and\ninserting bread into toasters. 2BY2 dataset includes 1,034 instances and 517\npairwise objects with pose and symmetry annotations, requiring approaches that\nalign geometric shapes while accounting for functional and spatial\nrelationships between objects. Leveraging the 2BY2 dataset, we propose a\ntwo-step SE(3) pose estimation method with equivariant features for assembly\nconstraints. Compared to previous shape assembly methods, our approach achieves\nstate-of-the-art performance across all 18 tasks in the 2BY2 dataset.\nAdditionally, robot experiments further validate the reliability and\ngeneralization ability of our method for complex 3D assembly tasks.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-09T15:12:38Z"}
{"aid":"http://arxiv.org/abs/2504.06965v1","title":"A Deep Single Image Rectification Approach for Pan-Tilt-Zoom Cameras","summary":"Pan-Tilt-Zoom (PTZ) cameras with wide-angle lenses are widely used in\nsurveillance but often require image rectification due to their inherent\nnonlinear distortions. Current deep learning approaches typically struggle to\nmaintain fine-grained geometric details, resulting in inaccurate rectification.\nThis paper presents a Forward Distortion and Backward Warping Network\n(FDBW-Net), a novel framework for wide-angle image rectification. It begins by\nusing a forward distortion model to synthesize barrel-distorted images,\nreducing pixel redundancy and preventing blur. The network employs a pyramid\ncontext encoder with attention mechanisms to generate backward warping flows\ncontaining geometric details. Then, a multi-scale decoder is used to restore\ndistorted features and output rectified images. FDBW-Net's performance is\nvalidated on diverse datasets: public benchmarks, AirSim-rendered PTZ camera\nimagery, and real-scene PTZ camera datasets. It demonstrates that FDBW-Net\nachieves SOTA performance in distortion rectification, boosting the\nadaptability of PTZ cameras for practical visual applications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T15:19:38Z"}
{"aid":"http://arxiv.org/abs/2504.06968v1","title":"Probable evidence for a transient mega-electron volt emission line in\n  the GRB 221023A","summary":"Detection of spectral line in gamma-ray bursts (GRBs) is importance for\nstudying GRB physics, as it provides insights into the composition and physical\nconditions of the GRB environment. However, progress in detecting X-ray or\ngamma-ray emission and absorption lines in GRB spectra has been relatively\nslow, only the narrow emission line feature of about 10 MeV found in GRB\n221009A has exhibited a significance exceeding $5 \\sigma$. Here, we report the\nprobable evidence of a narrow emission feature at about 2.1 mega-electron volts\n(MeV) in the spectrum of GRB 221023A. The highest statistical significance of\nthis feature is observed in the time interval between 8 and 30 seconds after\nFermi Gamma-Ray Burst Monitor trigger, with the chance probability value $<2.56\n\\times 10^{-5}$ (after accounting for the look-elsewhere effect), corresponding\nto a Gaussian-equivalent significance $> 4.20 \\sigma$. We interpret this\nfeature as being generated through the de-excitation of excited electrons in\nthe relativistic hydrogen-like high-atomic-number ions entrained in the GRB\njet.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-09T15:24:59Z"}
{"aid":"http://arxiv.org/abs/2504.06974v1","title":"Framelets and Wavelets with Mixed Dilation Factors","summary":"As a main research area in applied and computational harmonic analysis, the\ntheory and applications of framelets have been extensively investigated. Most\nexisting literature is devoted to framelet systems that only use one dilation\nmatrix as the sampling factor. To keep some key properties such as\ndirectionality, a framelet system often has a high redundancy rate. To reduce\nredundancy, a one-dimensional tight framelet with mixed dilation factors has\nbeen introduced for image processing. Though such tight framelets offer good\nperformance in practice, their theoretical properties are far from being well\nunderstood. In this paper, we will systematically investigate framelets with\nmixed dilation factors, with arbitrary multiplicity in arbitrary dimensions. We\nwill first study the discrete framelet transform employing a filter bank with\nmixed dilation factors and discuss its various properties. Next, we will\nintroduce the notion of a discrete affine system in $l_2(\\mathbb{Z}^d)$ and\nstudy discrete framelet transforms with mixed dilation factors. Finally, we\nwill discuss framelets and wavelets with mixed dilation factors in the space\n$L_2(\\mathbb{R}^d)$.","main_category":"math.FA","categories":"math.FA","published":"2025-04-09T15:29:10Z"}
{"aid":"http://arxiv.org/abs/2504.06978v1","title":"Wheat3DGS: In-field 3D Reconstruction, Instance Segmentation and\n  Phenotyping of Wheat Heads with Gaussian Splatting","summary":"Automated extraction of plant morphological traits is crucial for supporting\ncrop breeding and agricultural management through high-throughput field\nphenotyping (HTFP). Solutions based on multi-view RGB images are attractive due\nto their scalability and affordability, enabling volumetric measurements that\n2D approaches cannot directly capture. While advanced methods like Neural\nRadiance Fields (NeRFs) have shown promise, their application has been limited\nto counting or extracting traits from only a few plants or organs. Furthermore,\naccurately measuring complex structures like individual wheat heads-essential\nfor studying crop yields-remains particularly challenging due to occlusions and\nthe dense arrangement of crop canopies in field conditions. The recent\ndevelopment of 3D Gaussian Splatting (3DGS) offers a promising alternative for\nHTFP due to its high-quality reconstructions and explicit point-based\nrepresentation. In this paper, we present Wheat3DGS, a novel approach that\nleverages 3DGS and the Segment Anything Model (SAM) for precise 3D instance\nsegmentation and morphological measurement of hundreds of wheat heads\nautomatically, representing the first application of 3DGS to HTFP. We validate\nthe accuracy of wheat head extraction against high-resolution laser scan data,\nobtaining per-instance mean absolute percentage errors of 15.1%, 18.3%, and\n40.2% for length, width, and volume. We provide additional comparisons to\nNeRF-based approaches and traditional Muti-View Stereo (MVS), demonstrating\nsuperior results. Our approach enables rapid, non-destructive measurements of\nkey yield-related traits at scale, with significant implications for\naccelerating crop breeding and improving our understanding of wheat\ndevelopment.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T15:31:42Z"}
{"aid":"http://arxiv.org/abs/2504.06984v1","title":"Weak Signals and Heavy Tails: Machine-learning meets Extreme Value\n  Theory","summary":"The masses of data now available have opened up the prospect of discovering\nweak signals using machine-learning algorithms, with a view to predictive or\ninterpretation tasks. As this survey of recent results attempts to show,\nbringing multivariate extreme value theory and statistical learning theory\ntogether in a common, non-parametric and non-asymptotic framework makes it\npossible to design and analyze new methods for exploiting the scarce\ninformation located in distribution tails in these purposes. This article\nreviews recently proved theoretical tools for establishing guarantees for\nsupervised or unsupervised algorithms learning from a fraction of extreme data.\nThese are mainly exponential maximal deviation inequalities tailored to\nlow-probability regions and concentration results for stochastic processes\nempirically describing the behavior of extreme observations, their dependence\nstructure in particular. Under appropriate assumptions of regular variation,\nseveral illustrative applications are then examined: classification,\nregression, anomaly detection, model selection via cross-validation. For these,\ngeneralization results are established inspired by the classical bounds in\nstatistical learning theory. In the same spirit, it is also shown how to adapt\nthe popular high-dimensional lasso technique in the context of extreme values\nfor the covariates with generalization guarantees.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-09T15:41:40Z"}
{"aid":"http://arxiv.org/abs/2504.06988v1","title":"Existence and order of the self--binding transition in non--local\n  non--linear Schrödinger equations","summary":"We consider a class of non--linear and non--local functionals giving rise to\nthe Choquard equation with a suitably regular interaction potential, modelling,\ni.e., gases with impurities and axion stars. We study how existence of\nminimizers depends on the coupling constant, and find that there is a critical\ninteraction strength needed for the minimizers to exist, both in dimensions two\nand three. In $d=3$, a minimizer exists also at the critical coupling but none\ndo in $d=2$ under suitable assumptions on the potential. We also establish the\nexistence of non--minimizing critical points in $d=3$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T15:52:10Z"}
{"aid":"http://arxiv.org/abs/2504.07003v1","title":"The FitzHugh-Nagumo system on undulated cylinders: spontaneous\n  symmetrization and effective system","summary":"We consider the FitzHugh-Nagumo system on undulated cylindrical surfaces\nmodeling nerve axons. We show that for sufficiently small radii and for initial\nconditions close to radially symmetrical ones, (i) the solutions converge to\ntheir radial averages, and (ii) the latter averages can be approximated by\nsolutions of a 1+1 dimensional ('radial') system (the effective system)\ninvolving the surface radius function in its coefficients. This perhaps\nexplains why solutions of the original 1+1 dimensional FitzHugh-Nagumo system\nagree so well with experimental data on electrical impulse propagation.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T16:22:58Z"}
{"aid":"http://arxiv.org/abs/2504.07004v1","title":"Task-Based Tensor Computations on Modern GPUs","summary":"Domain-specific, fixed-function units are becoming increasingly common in\nmodern processors. As the computational demands of applications evolve, the\ncapabilities and programming interfaces of these fixed-function units continue\nto change. NVIDIA's Hopper GPU architecture contains multiple fixed-function\nunits per compute unit, including an asynchronous data movement unit (TMA) and\nan asynchronous matrix multiplication unit (Tensor Core). Efficiently utilizing\nthese units requires a fundamentally different programming style than previous\narchitectures; programmers must now develop warp-specialized kernels that\norchestrate producer-consumer pipelines between the asynchronous units. To\nmanage the complexity of programming these new architectures, we introduce\nCypress, a task-based programming model with sequential semantics. Cypress\nprograms are a set of designated functions called \\emph{tasks} that operate on\n\\emph{tensors} and are free of communication and synchronization. Cypress\nprograms are bound to the target machine through a \\emph{mapping} specification\nthat describes where tasks should run and in which memories tensors should be\nmaterialized. We present a compiler architecture that lowers Cypress programs\ninto CUDA programs that perform competitively with expert-written codes.\nCypress achieves 0.88x-1.06x the performance of cuBLAS on GEMM, and between\n0.80x-0.98x the performance of the currently best-known Flash Attention\nimplementation while eliminating all aspects of explicit data movement and\nasynchronous computation from application code.","main_category":"cs.PL","categories":"cs.PL","published":"2025-04-09T16:24:15Z"}
{"aid":"http://arxiv.org/abs/2504.07014v1","title":"Fermi surface as a quantum critical manifold: gaplessness, order\n  parameter, and scaling in $d$-dimensions","summary":"We study several models of $d$-dimensional fermions ($d=1,2,3$) with an\nemphasis on the properties of their gapless (metallic) phase. It occurs at $T =\n0$ as a continuous transition when zeros of the partition function reach the\nreal range of parameters. Those zeros define the $(d-1)$-manifold of quantum\ncriticality (Fermi surface). Its appearance or restructuring correspond to the\nLifshitz transition. Such $(d-1)$-membrane breaks the symmetry of the momentum\nspace, leading to gapless excitations, a hallmark of metallic phase. To probe\nquantitatively the gapless phase we introduce the geometric order parameter as\n$d$-volume of the Fermi sea. From analysis of the chain, ladder, and free\nfermions with different spectra, this proposal is shown to be consistent with\nscaling near the Lifshitz points of other quantities: correlation length,\noscillation wavelength, susceptibilities, and entanglement. All the\n(hyper)scaling relations are satisfied. Two interacting cases of the\nTomonaga-Luttinger ($d=1$) and the Fermi ($d=2,3$) liquids are analysed,\nyielding the same universality classes as free fermions.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.stat-mech,quant-ph","published":"2025-04-09T16:31:07Z"}
{"aid":"http://arxiv.org/abs/2504.07022v1","title":"Evaluating Retrieval Augmented Generative Models for Document Queries in\n  Transportation Safety","summary":"Applications of generative Large Language Models LLMs are rapidly expanding\nacross various domains, promising significant improvements in workflow\nefficiency and information retrieval. However, their implementation in\nspecialized, high-stakes domains such as hazardous materials transportation is\nchallenging due to accuracy and reliability concerns. This study evaluates the\nperformance of three fine-tuned generative models, ChatGPT, Google's Vertex AI,\nand ORNL Retrieval Augmented Generation augmented LLaMA 2 and LLaMA in\nretrieving regulatory information essential for hazardous material\ntransportation compliance in the United States. Utilizing approximately 40\npublicly available federal and state regulatory documents, we developed 100\nrealistic queries relevant to route planning and permitting requirements.\nResponses were qualitatively rated based on accuracy, detail, and relevance,\ncomplemented by quantitative assessments of semantic similarity between model\noutputs. Results demonstrated that the RAG-augmented LLaMA models significantly\noutperformed Vertex AI and ChatGPT, providing more detailed and generally\naccurate information, despite occasional inconsistencies. This research\nintroduces the first known application of RAG in transportation safety,\nemphasizing the need for domain-specific fine-tuning and rigorous evaluation\nmethodologies to ensure reliability and minimize the risk of inaccuracies in\nhigh-stakes environments.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T16:37:03Z"}
{"aid":"http://arxiv.org/abs/2504.07025v1","title":"Glossy Object Reconstruction with Cost-effective Polarized Acquisition","summary":"The challenge of image-based 3D reconstruction for glossy objects lies in\nseparating diffuse and specular components on glossy surfaces from captured\nimages, a task complicated by the ambiguity in discerning lighting conditions\nand material properties using RGB data alone. While state-of-the-art methods\nrely on tailored and/or high-end equipment for data acquisition, which can be\ncumbersome and time-consuming, this work introduces a scalable\npolarization-aided approach that employs cost-effective acquisition tools. By\nattaching a linear polarizer to readily available RGB cameras, multi-view\npolarization images can be captured without the need for advance calibration or\nprecise measurements of the polarizer angle, substantially reducing system\nconstruction costs. The proposed approach represents polarimetric BRDF, Stokes\nvectors, and polarization states of object surfaces as neural implicit fields.\nThese fields, combined with the polarizer angle, are retrieved by optimizing\nthe rendering loss of input polarized images. By leveraging fundamental\nphysical principles for the implicit representation of polarization rendering,\nour method demonstrates superiority over existing techniques through\nexperiments in public datasets and real captured images on both reconstruction\nand novel view synthesis.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T16:38:51Z"}
{"aid":"http://arxiv.org/abs/2504.07035v1","title":"Classification results for totally real surfaces of nearly Kähler\n  $\\mathbb{C}P^3$","summary":"Totally real surfaces in the nearly K\\\"ahler $\\mathbb{C}P^3$ are investigated\nand are completely classified under various additional assumptions, resulting\nin multiple new examples. Among others, the classification includes totally\nreal surfaces that are extrinsically homogeneous; or minimal; or totally\numbilical; or Codazzi-like (including parallel and non-parallel examples).","main_category":"math.DG","categories":"math.DG","published":"2025-04-09T16:51:40Z"}
{"aid":"http://arxiv.org/abs/2504.07046v1","title":"A Unified Agentic Framework for Evaluating Conditional Image Generation","summary":"Conditional image generation has gained significant attention for its ability\nto personalize content. However, the field faces challenges in developing\ntask-agnostic, reliable, and explainable evaluation metrics. This paper\nintroduces CIGEval, a unified agentic framework for comprehensive evaluation of\nconditional image generation tasks. CIGEval utilizes large multimodal models\n(LMMs) as its core, integrating a multi-functional toolbox and establishing a\nfine-grained evaluation framework. Additionally, we synthesize evaluation\ntrajectories for fine-tuning, empowering smaller LMMs to autonomously select\nappropriate tools and conduct nuanced analyses based on tool outputs.\nExperiments across seven prominent conditional image generation tasks\ndemonstrate that CIGEval (GPT-4o version) achieves a high correlation of 0.4625\nwith human assessments, closely matching the inter-annotator correlation of\n0.47. Moreover, when implemented with 7B open-source LMMs using only 2.3K\ntraining trajectories, CIGEval surpasses the previous GPT-4o-based\nstate-of-the-art method. Case studies on GPT-4o image generation highlight\nCIGEval's capability in identifying subtle issues related to subject\nconsistency and adherence to control guidance, indicating its great potential\nfor automating evaluation of image generation tasks with human-level\nreliability.","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-04-09T17:04:14Z"}
{"aid":"http://arxiv.org/abs/2504.07049v1","title":"Harnessing non-equilibrium forces to optimize work extraction","summary":"While optimal control theory offers effective strategies for minimizing\nenergetic costs in noisy microscopic systems over finite durations, a\nsignificant opportunity lies in exploiting the temporal structure of\nnon-equilibrium forces. We demonstrate this by presenting exact analytical\nforms for the optimal protocol and the corresponding work for any driving force\nand protocol duration. We also derive a general quasistatic bound on the work,\nrelying only on the coarse-grained, time-integrated characteristics of the\napplied forces. Notably, we show that the optimal protocols often automatically\nact as information engines that harness information about non-equilibrium\nforces and an initial state measurement to extract work. These findings chart\nnew directions for designing adaptive, energy-efficient strategies in noisy,\ntime-dependent environments, as illustrated through our examples of periodic\ndriving forces and active matter systems. By exploiting the temporal structure\nof non-equilibrium forces, this largely unexplored approach holds promise for\nsubstantial performance gains in microscopic devices operating at the nano- and\nmicroscale.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.soft","published":"2025-04-09T17:06:15Z"}
{"aid":"http://arxiv.org/abs/2504.07052v1","title":"To Backtrack or Not to Backtrack: When Sequential Search Limits Model\n  Reasoning","summary":"Recent advancements in large language models have significantly improved\ntheir reasoning abilities, particularly through techniques involving search and\nbacktracking. Backtracking naturally scales test-time compute by enabling\nsequential, linearized exploration via long chain-of-thought (CoT) generation.\nHowever, this is not the only strategy for scaling test-time compute: parallel\nsampling with best-of-n selection provides an alternative that generates\ndiverse solutions simultaneously. Despite the growing adoption of sequential\nsearch, its advantages over parallel sampling--especially under a fixed compute\nbudget remain poorly understood. In this paper, we systematically compare these\ntwo approaches on two challenging reasoning tasks: CountDown and Sudoku.\nSurprisingly, we find that sequential search underperforms parallel sampling on\nCountDown but outperforms it on Sudoku, suggesting that backtracking is not\nuniversally beneficial. We identify two factors that can cause backtracking to\ndegrade performance: (1) training on fixed search traces can lock models into\nsuboptimal strategies, and (2) explicit CoT supervision can discourage\n\"implicit\" (non-verbalized) reasoning. Extending our analysis to reinforcement\nlearning (RL), we show that models with backtracking capabilities benefit\nsignificantly from RL fine-tuning, while models without backtracking see\nlimited, mixed gains. Together, these findings challenge the assumption that\nbacktracking universally enhances LLM reasoning, instead revealing a complex\ninteraction between task structure, training data, model scale, and learning\nparadigm.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T17:12:49Z"}
{"aid":"http://arxiv.org/abs/2504.07055v1","title":"$Π$-NeSy: A Possibilistic Neuro-Symbolic Approach","summary":"In this article, we introduce a neuro-symbolic approach that combines a\nlow-level perception task performed by a neural network with a high-level\nreasoning task performed by a possibilistic rule-based system. The goal is to\nbe able to derive for each input instance the degree of possibility that it\nbelongs to a target (meta-)concept. This (meta-)concept is connected to\nintermediate concepts by a possibilistic rule-based system. The probability of\neach intermediate concept for the input instance is inferred using a neural\nnetwork. The connection between the low-level perception task and the\nhigh-level reasoning task lies in the transformation of neural network outputs\nmodeled by probability distributions (through softmax activation) into\npossibility distributions. The use of intermediate concepts is valuable for the\nexplanation purpose: using the rule-based system, the classification of an\ninput instance as an element of the (meta-)concept can be justified by the fact\nthat intermediate concepts have been recognized.\n  From the technical side, our contribution consists of the design of efficient\nmethods for defining the matrix relation and the equation system associated\nwith a possibilistic rule-based system. The corresponding matrix and equation\nare key data structures used to perform inferences from a possibilistic\nrule-based system and to learn the values of the rule parameters in such a\nsystem according to a training data sample. Furthermore, leveraging recent\nresults on the handling of inconsistent systems of fuzzy relational equations,\nan approach for learning rule parameters according to multiple training data\nsamples is presented. Experiments carried out on the MNIST addition problems\nand the MNIST Sudoku puzzles problems highlight the effectiveness of our\napproach compared with state-of-the-art neuro-symbolic ones.","main_category":"cs.AI","categories":"cs.AI,cs.LG,cs.LO","published":"2025-04-09T17:16:23Z"}
{"aid":"http://arxiv.org/abs/2504.07064v1","title":"Equivariant operations in topological Hochschild homology","summary":"We observe a new equivariant relationship between topological Hochschild\nhomology and cohomology. We also calculate the topological Hochschild homology\nof the topological Hochschild cohomology of a finite prime field, which can be\nviewed as a certain ring of structured operations in this case.","main_category":"math.AT","categories":"math.AT,math.KT","published":"2025-04-09T17:27:53Z"}
{"aid":"http://arxiv.org/abs/2504.07067v1","title":"Spin state of iron in I-42d-type Mg2SiO4 at ultra-high pressures","summary":"At extreme pressures of approximately 500 GPa, conditions characteristic of\nthe deep interiors of super-Earths, the combination of NaCl-type MgO and\npost-perovskite-type MgSiO3 (PPv) has been reported to produce a post-PPv phase\nof Mg2SiO4 with an I-42d symmetry. This post-PPv (pppv) silicate is proposed as\nthe primary mantle silicate in these massive rocky exoplanets. Understanding\nthe fundamental properties of pppv, particularly in solid solutions with\nFe2SiO4, is crucial for insights into the interior dynamics and compositions of\nsuch planets. In this study, we conduct an ab initio investigation of the\nproperties of Fe2+-bearing pppv at pressures ranging from 400 GPa to 1 TPa.\nGiven the localized nature of 3d-electrons in iron, we employ the LDA+Usc\nmethod alongside conventional DFT functionals to probe the electronic structure\nof this system. The dependence of the Hubbard parameter U on volume and spin\nstate is carefully evaluated. Furthermore, we systematically explore the\neffects of pressure, temperature, and structural variations on the spin state\nof iron in Fe2+-bearing pppv, providing valuable data to improve mantle\nmodeling for super-Earth-type exoplanets.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.other","published":"2025-04-09T17:32:32Z"}
{"aid":"http://arxiv.org/abs/2504.07072v1","title":"Kaleidoscope: In-language Exams for Massively Multilingual Vision\n  Evaluation","summary":"The evaluation of vision-language models (VLMs) has mainly relied on\nEnglish-language benchmarks, leaving significant gaps in both multilingual and\nmulticultural coverage. While multilingual benchmarks have expanded, both in\nsize and languages, many rely on translations of English datasets, failing to\ncapture cultural nuances. In this work, we propose Kaleidoscope, as the most\ncomprehensive exam benchmark to date for the multilingual evaluation of\nvision-language models. Kaleidoscope is a large-scale, in-language multimodal\nbenchmark designed to evaluate VLMs across diverse languages and visual inputs.\nKaleidoscope covers 18 languages and 14 different subjects, amounting to a\ntotal of 20,911 multiple-choice questions. Built through an open science\ncollaboration with a diverse group of researchers worldwide, Kaleidoscope\nensures linguistic and cultural authenticity. We evaluate top-performing\nmultilingual vision-language models and find that they perform poorly on\nlow-resource languages and in complex multimodal scenarios. Our results\nhighlight the need for progress on culturally inclusive multimodal evaluation\nframeworks.","main_category":"cs.CL","categories":"cs.CL,cs.CV","published":"2025-04-09T17:43:16Z"}
{"aid":"http://arxiv.org/abs/2504.07076v1","title":"On Fundamental Theorems of Super Invariant Theory","summary":"The purpose of this paper is to prove the First and Second Fundamental\nTheorems of invariant theory for the complex special linear supergroup and\ndiscuss the superalgebra of invariants, via the super Plucker relations.","main_category":"math.RA","categories":"math.RA","published":"2025-04-09T17:47:55Z"}
{"aid":"http://arxiv.org/abs/2504.07080v1","title":"DeduCE: Deductive Consistency as a Framework to Evaluate LLM Reasoning","summary":"Despite great performance on Olympiad-level reasoning problems, frontier\nlarge language models can still struggle on high school math when presented\nwith novel problems outside standard benchmarks. Going beyond final accuracy,\nwe propose a deductive consistency metric to analyze chain-of-thought output\nfrom language models (LMs).Formally, deductive reasoning involves two subtasks:\nunderstanding a set of input premises and inferring the conclusions that follow\nfrom them. The proposed metric studies LMs' performance on these subtasks, with\nthe goal of explaining LMs' reasoning errors on novel problems: how well do LMs\nunderstand input premises with increasing context lengths, and how well can\nthey infer conclusions over multiple reasoning hops? Since existing benchmarks\nmay be memorized, we develop a pipeline to evaluate LMs' deductive consistency\non novel, perturbed versions of benchmark problems. On novel grade school math\nproblems (GSM-8k), we find that LMs are fairly robust to increasing number of\ninput premises, but suffer significant accuracy decay as the number of\nreasoning hops is increased. Interestingly, these errors are masked in the\noriginal benchmark as all models achieve near 100% accuracy. As we increase the\nnumber of solution steps using a synthetic dataset, prediction over multiple\nhops still remains the major source of error compared to understanding input\npremises. Other factors, such as shifts in language style or natural\npropagation of early errors do not explain the trends. Our analysis provides a\nnew view to characterize LM reasoning -- as computations over a window of input\npremises and reasoning hops -- that can provide unified evaluation across\nproblem domains.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-09T17:53:55Z"}
{"aid":"http://arxiv.org/abs/2504.07083v1","title":"GenDoP: Auto-regressive Camera Trajectory Generation as a Director of\n  Photography","summary":"Camera trajectory design plays a crucial role in video production, serving as\na fundamental tool for conveying directorial intent and enhancing visual\nstorytelling. In cinematography, Directors of Photography meticulously craft\ncamera movements to achieve expressive and intentional framing. However,\nexisting methods for camera trajectory generation remain limited: Traditional\napproaches rely on geometric optimization or handcrafted procedural systems,\nwhile recent learning-based methods often inherit structural biases or lack\ntextual alignment, constraining creative synthesis. In this work, we introduce\nan auto-regressive model inspired by the expertise of Directors of Photography\nto generate artistic and expressive camera trajectories. We first introduce\nDataDoP, a large-scale multi-modal dataset containing 29K real-world shots with\nfree-moving camera trajectories, depth maps, and detailed captions in specific\nmovements, interaction with the scene, and directorial intent. Thanks to the\ncomprehensive and diverse database, we further train an auto-regressive,\ndecoder-only Transformer for high-quality, context-aware camera movement\ngeneration based on text guidance and RGBD inputs, named GenDoP. Extensive\nexperiments demonstrate that compared to existing methods, GenDoP offers better\ncontrollability, finer-grained trajectory adjustments, and higher motion\nstability. We believe our approach establishes a new standard for\nlearning-based cinematography, paving the way for future advancements in camera\ncontrol and filmmaking. Our project website:\nhttps://kszpxxzmc.github.io/GenDoP/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T17:56:01Z"}
{"aid":"http://arxiv.org/abs/2504.07085v1","title":"Identifying Unknown Stochastic Dynamics via Finite expression methods","summary":"Modeling stochastic differential equations (SDEs) is crucial for\nunderstanding complex dynamical systems in various scientific fields. Recent\nmethods often employ neural network-based models, which typically represent\nSDEs through a combination of deterministic and stochastic terms. However,\nthese models usually lack interpretability and have difficulty generalizing\nbeyond their training domain. This paper introduces the Finite Expression\nMethod (FEX), a symbolic learning approach designed to derive interpretable\nmathematical representations of the deterministic component of SDEs. For the\nstochastic component, we integrate FEX with advanced generative modeling\ntechniques to provide a comprehensive representation of SDEs. The numerical\nexperiments on linear, nonlinear, and multidimensional SDEs demonstrate that\nFEX generalizes well beyond the training domain and delivers more accurate\nlong-term predictions compared to neural network-based methods. The symbolic\nexpressions identified by FEX not only improve prediction accuracy but also\noffer valuable scientific insights into the underlying dynamics of the systems,\npaving the way for new scientific discoveries.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T17:57:54Z"}
{"aid":"http://arxiv.org/abs/2504.07086v1","title":"A Sober Look at Progress in Language Model Reasoning: Pitfalls and Paths\n  to Reproducibility","summary":"Reasoning has emerged as the next major frontier for language models (LMs),\nwith rapid advances from both academic and industrial labs. However, this\nprogress often outpaces methodological rigor, with many evaluations relying on\nbenchmarking practices that lack transparency, robustness, or statistical\ngrounding. In this work, we conduct a comprehensive empirical study and find\nthat current mathematical reasoning benchmarks are highly sensitive to subtle\nimplementation choices - including decoding parameters, random seeds, prompt\nformatting, and even hardware and software-framework configurations.\nPerformance gains reported in recent studies frequently hinge on unclear\ncomparisons or unreported sources of variance. To address these issues, we\npropose a standardized evaluation framework with clearly defined best practices\nand reporting standards. Using this framework, we reassess recent methods and\nfind that reinforcement learning (RL) approaches yield only modest improvements\n- far below prior claims - and are prone to overfitting, especially on\nsmall-scale benchmarks like AIME24. In contrast, supervised finetuning (SFT)\nmethods show consistently stronger generalization. To foster reproducibility,\nwe release all code, prompts, and model outputs, for reasoning benchmarks,\nestablishing more rigorous foundations for future work.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-09T17:58:17Z"}
{"aid":"http://arxiv.org/abs/2504.07092v1","title":"Are We Done with Object-Centric Learning?","summary":"Object-centric learning (OCL) seeks to learn representations that only encode\nan object, isolated from other objects or background cues in a scene. This\napproach underpins various aims, including out-of-distribution (OOD)\ngeneralization, sample-efficient composition, and modeling of structured\nenvironments. Most research has focused on developing unsupervised mechanisms\nthat separate objects into discrete slots in the representation space,\nevaluated using unsupervised object discovery. However, with recent\nsample-efficient segmentation models, we can separate objects in the pixel\nspace and encode them independently. This achieves remarkable zero-shot\nperformance on OOD object discovery benchmarks, is scalable to foundation\nmodels, and can handle a variable number of slots out-of-the-box. Hence, the\ngoal of OCL methods to obtain object-centric representations has been largely\nachieved. Despite this progress, a key question remains: How does the ability\nto separate objects within a scene contribute to broader OCL objectives, such\nas OOD generalization? We address this by investigating the OOD generalization\nchallenge caused by spurious background cues through the lens of OCL. We\npropose a novel, training-free probe called $\\textbf{Object-Centric\nClassification with Applied Masks (OCCAM)}$, demonstrating that\nsegmentation-based encoding of individual objects significantly outperforms\nslot-based OCL methods. However, challenges in real-world applications remain.\nWe provide the toolbox for the OCL community to use scalable object-centric\nrepresentations, and focus on practical applications and fundamental questions,\nsuch as understanding object perception in human cognition. Our code is\navailable $\\href{https://github.com/AlexanderRubinstein/OCCAM}{here}$.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-09T17:59:05Z"}
{"aid":"http://arxiv.org/abs/2504.07095v1","title":"Neural Motion Simulator: Pushing the Limit of World Models in\n  Reinforcement Learning","summary":"An embodied system must not only model the patterns of the external world but\nalso understand its own motion dynamics. A motion dynamic model is essential\nfor efficient skill acquisition and effective planning. In this work, we\nintroduce the neural motion simulator (MoSim), a world model that predicts the\nfuture physical state of an embodied system based on current observations and\nactions. MoSim achieves state-of-the-art performance in physical state\nprediction and provides competitive performance across a range of downstream\ntasks. This works shows that when a world model is accurate enough and performs\nprecise long-horizon predictions, it can facilitate efficient skill acquisition\nin imagined worlds and even enable zero-shot reinforcement learning.\nFurthermore, MoSim can transform any model-free reinforcement learning (RL)\nalgorithm into a model-based approach, effectively decoupling physical\nenvironment modeling from RL algorithm development. This separation allows for\nindependent advancements in RL algorithms and world modeling, significantly\nimproving sample efficiency and enhancing generalization capabilities. Our\nfindings highlight that world models for motion dynamics is a promising\ndirection for developing more versatile and capable embodied systems.","main_category":"cs.LG","categories":"cs.LG,cs.RO","published":"2025-04-09T17:59:32Z"}
{"aid":"http://arxiv.org/abs/2504.07097v1","title":"Sculpting Subspaces: Constrained Full Fine-Tuning in LLMs for Continual\n  Learning","summary":"Continual learning in large language models (LLMs) is prone to catastrophic\nforgetting, where adapting to new tasks significantly degrades performance on\npreviously learned ones. Existing methods typically rely on low-rank,\nparameter-efficient updates that limit the model's expressivity and introduce\nadditional parameters per task, leading to scalability issues. To address these\nlimitations, we propose a novel continual full fine-tuning approach leveraging\nadaptive singular value decomposition (SVD). Our method dynamically identifies\ntask-specific low-rank parameter subspaces and constrains updates to be\northogonal to critical directions associated with prior tasks, thus effectively\nminimizing interference without additional parameter overhead or storing\nprevious task gradients. We evaluate our approach extensively on standard\ncontinual learning benchmarks using both encoder-decoder (T5-Large) and\ndecoder-only (LLaMA-2 7B) models, spanning diverse tasks including\nclassification, generation, and reasoning. Empirically, our method achieves\nstate-of-the-art results, up to 7% higher average accuracy than recent\nbaselines like O-LoRA, and notably maintains the model's general linguistic\ncapabilities, instruction-following accuracy, and safety throughout the\ncontinual learning process by reducing forgetting to near-negligible levels.\nOur adaptive SVD framework effectively balances model plasticity and knowledge\nretention, providing a practical, theoretically grounded, and computationally\nscalable solution for continual learning scenarios in large language models.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL,math.PR,stat.ML","published":"2025-04-09T17:59:42Z"}
{"aid":"http://arxiv.org/abs/2504.07411v1","title":"Estimand framework development for eGFR slope estimation and comparative\n  analyses across various estimation methods","summary":"Chronic kidney disease (CKD) is a global health challenge characterized by\nprogressive kidney function decline, often culminating in end-stage kidney\ndisease (ESKD) and increased mortality. To address the limitations such as the\nextended trial follow-up necessitated by the low incidence of kidney composite\nendpoint, the eGFR slope -- a surrogate endpoint reflecting the trajectory of\nkidney function decline -- has gained prominence for its predictive power and\nregulatory support. Despite its advantages, the lack of a standardized\nframework for eGFR slope estimand and estimation complicates consistent\ninterpretation and cross-trial comparisons. Existing methods, including simple\nlinear regression and mixed-effects models, vary in their underlying\nassumptions, creating a need for a formalized approach to align estimation\nmethods with trial objectives. This manuscript proposes an estimand framework\ntailored to eGFR slope-based analyses in CKD RCTs, ensuring clarity in defining\n\"what to estimate\" and enhancing the comparability of results. Through\nsimulation studies and real-world data applications, we evaluate the\nperformance of various commonly applied estimation techniques under distinct\nscenarios. By recommending a clear characterization for eGFR slope estimand and\nproviding considerations for estimation approaches, this work aims to improve\nthe reliability and interpretability of CKD trial results, advancing\ntherapeutic development and clinical decision-making.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-10T03:03:31Z"}
{"aid":"http://arxiv.org/abs/2504.07413v1","title":"Regression for Left-Truncated and Right-Censored Data: A Semiparametric\n  Sieve Likelihood Approach","summary":"Cohort studies of the onset of a disease often encounter left-truncation on\nthe event time of interest in addition to right-censoring due to variable\nenrollment times of study participants. Analysis of such event time data can be\nbiased if left-truncation is not handled properly. We propose a semiparametric\nsieve likelihood approach for fitting a linear regression model to data where\nthe response variable is subject to both left-truncation and right-censoring.\nWe show that the estimators of regression coefficients are consistent,\nasymptotically normal and semiparametrically efficient. Extensive simulation\nstudies show the effectiveness of the method across a wide variety of error\ndistributions. We further illustrate the method by analyzing a dataset from The\n90+ Study for aging and dementia.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-10T03:08:50Z"}
{"aid":"http://arxiv.org/abs/2504.07423v1","title":"Over-Relying on Reliance: Towards Realistic Evaluations of AI-Based\n  Clinical Decision Support","summary":"As AI-based clinical decision support (AI-CDS) is introduced in more and more\naspects of healthcare services, HCI research plays an increasingly important\nrole in designing for complementarity between AI and clinicians. However,\ncurrent evaluations of AI-CDS often fail to capture when AI is and is not\nuseful to clinicians. This position paper reflects on our work and influential\nAI-CDS literature to advocate for moving beyond evaluation metrics like Trust,\nReliance, Acceptance, and Performance on the AI's task (what we term the \"trap\"\nof human-AI collaboration). Although these metrics can be meaningful in some\nsimple scenarios, we argue that optimizing for them ignores important ways that\nAI falls short of clinical benefit, as well as ways that clinicians\nsuccessfully use AI. As the fields of HCI and AI in healthcare develop new ways\nto design and evaluate CDS tools, we call on the community to prioritize\necologically valid, domain-appropriate study setups that measure the emergent\nforms of value that AI can bring to healthcare professionals.","main_category":"cs.HC","categories":"cs.HC,cs.AI,q-bio.OT","published":"2025-04-10T03:28:56Z"}
{"aid":"http://arxiv.org/abs/2504.07426v1","title":"Conditional Data Synthesis Augmentation","summary":"Reliable machine learning and statistical analysis rely on diverse,\nwell-distributed training data. However, real-world datasets are often limited\nin size and exhibit underrepresentation across key subpopulations, leading to\nbiased predictions and reduced performance, particularly in supervised tasks\nsuch as classification. To address these challenges, we propose Conditional\nData Synthesis Augmentation (CoDSA), a novel framework that leverages\ngenerative models, such as diffusion models, to synthesize high-fidelity data\nfor improving model performance across multimodal domains including tabular,\ntextual, and image data. CoDSA generates synthetic samples that faithfully\ncapture the conditional distributions of the original data, with a focus on\nunder-sampled or high-interest regions. Through transfer learning, CoDSA\nfine-tunes pre-trained generative models to enhance the realism of synthetic\ndata and increase sample density in sparse areas. This process preserves\ninter-modal relationships, mitigates data imbalance, improves domain\nadaptation, and boosts generalization. We also introduce a theoretical\nframework that quantifies the statistical accuracy improvements enabled by\nCoDSA as a function of synthetic sample volume and targeted region allocation,\nproviding formal guarantees of its effectiveness. Extensive experiments\ndemonstrate that CoDSA consistently outperforms non-adaptive augmentation\nstrategies and state-of-the-art baselines in both supervised and unsupervised\nsettings.","main_category":"stat.ME","categories":"stat.ME,cs.LG","published":"2025-04-10T03:38:11Z"}
{"aid":"http://arxiv.org/abs/2504.07430v1","title":"Nonlinear Optimal Guidance for Intercepting Moving Targets","summary":"This paper introduces a nonlinear optimal guidance framework for guiding a\npursuer to intercept a moving target, with an emphasis on real-time generation\nof optimal feedback control for a nonlinear optimal control problem. Initially,\nconsidering the target moves without maneuvering, we derive the necessary\noptimality conditions using Pontryagin's Maximum Principle. These conditions\nreveal that each extremal trajectory is uniquely determined by two scalar\nparameters. Analyzing the geometric property of the parameterized extremal\ntrajectories not only leads to an additional necessary condition but also\nallows to establish a sufficient condition for local optimality. This enables\nthe generation of a dataset containing at least locally optimal trajectories.\nBy studying the properties of the optimal feedback control, the size of the\ndataset is reduced significantly, allowing training a lightweight neural\nnetwork to predict the optimal guidance command in real time. Furthermore, the\nperformance of the neural network is enhanced by incorporating the target's\nacceleration, making it suitable for intercepting both uniformly moving and\nmaneuvering targets. Finally, numerical simulations validate the proposed\nnonlinear optimal guidance framework, demonstrating its better performance over\nexisting guidance laws.","main_category":"math.OC","categories":"math.OC","published":"2025-04-10T03:52:24Z"}
{"aid":"http://arxiv.org/abs/2504.07443v1","title":"Optoelectronic properties of self-trapped holes in orthorhombic Ga2O3\n  and its alloys","summary":"We investigated the influence of valence band holes on the optoelectronic\nproperties of orthorhombic k-Ga2O3 and its alloys with Al and In. Our hybrid\ndensity functional theory calculations show that self-trapped holes (STHs)\nlocalize on oxygen atoms within a single unit cell and exhibit \\emph{p}-orbital\ncharacteristics. The inclusion of isoelectronic dopants such as Al and In\nreduces but does not remove the absorption of visible light due to STH\nformation. The combination of a positive STH formation energy, large lattice\ndistortions, and emergent acceptor levels, coupled with the observed\nred-shifted, visible spectrum, emergent absorption peaks, implies that\nalternative doping/alloying strategies are necessary to achieve effective\np-type conductivity in orthorhombic k-Ga2O3.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-10T04:20:23Z"}
{"aid":"http://arxiv.org/abs/2504.07447v1","title":"Exact Quantification of Bipartite Entanglement in Unresolvable Spin\n  Ensembles","summary":"Quantifying mixed-state entanglement in many-body systems has been a\nformidable task. In this work, we quantify the entanglement of states in\nunresolvable spin ensembles, which are inherently mixed. By exploiting their\npermutationally invariant properties, we show that the bipartite entanglement\nof a wide range of unresolvable ensemble states can be calculated exactly. Our\nformalism is versatile; it can be used to evaluate the entanglement in an\nensemble with an arbitrary number of particles, effective angular momentum, and\nbipartition. We apply our method to explore the characteristics of entanglement\nin different physically motivated scenarios, including states with definite\nmagnetization and metrologically useful superpositions such as\nGreenberger-Horne-Zeilinger (GHZ) states and spin-squeezed states. Our method\ncan help understand the role of entanglement in spin-ensemble-based quantum\ntechnologies.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-10T04:35:05Z"}
{"aid":"http://arxiv.org/abs/2504.07449v1","title":"Polarization Angle Orthogonal Jumps in Fast Radio Bursts","summary":"Recently, polarization angle (PA) orthogonal jumps over millisecond timescale\nwere discovered from three bursts of a repeating fast radio burst source FRB\n20201124A by the FAST telescope. We investigate the physical implications of\nthis phenomenon. In general, PA jumps can arise from the superposition of two\nelectromagnetic waves, either coherently or incoherently, as the dominance of\nthe two orthogonal modes switches. In the coherent case, PA jumps occur when\nlinear polarization reaches a minimum and circular polarization peaks, with the\ntotal polarization degree conserved. However, incoherent superposition can lead\nto depolarization. The observations seem to be more consistent with incoherent\nsuperposition. The amplitudes of the two orthogonal modes are required to be\ncomparable when jumps occur, placing constraints on the intrinsic radiation\nmechanisms. We provide general constraints on FRB emission and propagation\nmechanisms based on the data. Physically, it is difficult to produce PA jumps\nby generating two orthogonal modes within millisecond timescales, and a\ngeometric effect due to sweeping line-of-sight is a more plausible reason. This\nrequires the emission region to be within the magnetosphere of a spinning\ncentral engine, likely a magnetar. The two orthogonal modes may be produced by\nintrinsic radiation mechanisms or Alfv\\'en-O-mode transition. Plasma\nbirefringence is not easy to achieve when the plasma is moving\nrelativistically. Curvature radiation predicts $|E_{\\rm X}/E_{\\rm O}|\\gtrsim1$,\nand is difficult to produce jumps; whereas inverse Compton scattering can\nachieve the transition amplitude ratio $|E_{\\rm X}/E_{\\rm O}|=1$ to allow jumps\nto occur under special geometric configurations.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-10T04:48:50Z"}
{"aid":"http://arxiv.org/abs/2504.07451v1","title":"Continuity conditions weaker than lower semi-continuity","summary":"Lower semi-continuity (\\texttt{LSC}) is a critical assumption in many\nfoundational optimisation theory results; however, in many cases, \\texttt{LSC}\nis stronger than necessary. This has led to the introduction of numerous weaker\ncontinuity conditions that enable more general theorem statements. In the\ncontext of unstructured optimization over topological domains, we collect these\ncontinuity conditions from disparate sources and review their applications. As\nprimary outcomes, we prove two comprehensive implication diagrams that\nestablish novel connections between the reviewed conditions. In doing so, we\nalso introduce previously missing continuity conditions and provide new\ncounterexamples.","main_category":"math.OC","categories":"math.OC","published":"2025-04-10T04:53:32Z"}
{"aid":"http://arxiv.org/abs/2504.07461v1","title":"Achilles Heel of Distributed Multi-Agent Systems","summary":"Multi-agent system (MAS) has demonstrated exceptional capabilities in\naddressing complex challenges, largely due to the integration of multiple large\nlanguage models (LLMs). However, the heterogeneity of LLMs, the scalability of\nquantities of LLMs, and local computational constraints pose significant\nchallenges to hosting these models locally. To address these issues, we propose\na new framework termed Distributed Multi-Agent System (DMAS). In DMAS,\nheterogeneous third-party agents function as service providers managed remotely\nby a central MAS server and each agent offers its services through API\ninterfaces. However, the distributed nature of DMAS introduces several concerns\nabout trustworthiness. In this paper, we study the Achilles heel of distributed\nmulti-agent systems, identifying four critical trustworthiness challenges: free\nriding, susceptibility to malicious attacks, communication inefficiencies, and\nsystem instability. Extensive experiments across seven frameworks and four\ndatasets reveal significant vulnerabilities of the DMAS. These attack\nstrategies can lead to a performance degradation of up to 80% and attain a 100%\nsuccess rate in executing free riding and malicious attacks. We envision our\nwork will serve as a useful red-teaming tool for evaluating future multi-agent\nsystems and spark further research on trustworthiness challenges in distributed\nmulti-agent systems.","main_category":"cs.MA","categories":"cs.MA","published":"2025-04-10T05:16:11Z"}
{"aid":"http://arxiv.org/abs/2504.07466v1","title":"Personalized and Demand-Based Education Concept: Practical Tools for\n  Control Engineers","summary":"This paper presents a personalized lecture concept using educational blocks\nand its demonstrative application in a new university lecture. Higher education\nfaces daily challenges: deep and specialized knowledge is available from\neverywhere and accessible to almost everyone. University lecturers of\nspecialized master courses confront the problem that their lectures are either\ntoo boring or too complex for the attending students. Additionally, curricula\nare changing more rapidly than they have in the past 10-30 years. The German\neducation system comprises different educational forms, with universities\nproviding less practical content. Consequently, many university students do not\nobtain the practical skills they should ideally gain through university\nlectures. Therefore, in this work, a new lecture concept is proposed based on\nthe extension of the just-in-time teaching paradigm: Personalized and\nDemand-Based Education. This concept includes: 1) an initial assessment of\nstudents' backgrounds, 2) selecting the appropriate educational blocks, and 3)\ncollecting ongoing feedback during the semester. The feedback was gathered via\nPingo, ensuring anonymity for the students. Our concept was exemplarily tested\nin the new lecture \"Practical Tools for Control Engineers\" at the Karlsruhe\nInstitute of Technology. The initial results indicate that our proposed concept\ncould be beneficial in addressing the current challenges in higher education.","main_category":"eess.SY","categories":"eess.SY,cs.RO,cs.SY,K.3.1","published":"2025-04-10T05:34:37Z"}
{"aid":"http://arxiv.org/abs/2504.07468v1","title":"Novel Pooling-based VGG-Lite for Pneumonia and Covid-19 Detection from\n  Imbalanced Chest X-Ray Datasets","summary":"This paper proposes a novel pooling-based VGG-Lite model in order to mitigate\nclass imbalance issues in Chest X-Ray (CXR) datasets. Automatic Pneumonia\ndetection from CXR images by deep learning model has emerged as a prominent and\ndynamic area of research, since the inception of the new Covid-19 variant in\n2020. However, the standard Convolutional Neural Network (CNN) models encounter\nchallenges associated with class imbalance, a prevalent issue found in many\nmedical datasets. The innovations introduced in the proposed model architecture\ninclude: (I) A very lightweight CNN model, `VGG-Lite', is proposed as a base\nmodel, inspired by VGG-16 and MobileNet-V2 architecture. (II) On top of this\nbase model, we leverage an ``Edge Enhanced Module (EEM)\" through a parallel\nbranch, consisting of a ``negative image layer\", and a novel custom pooling\nlayer ``2Max-Min Pooling\". This 2Max-Min Pooling layer is entirely novel in\nthis investigation, providing more attention to edge components within\npneumonia CXR images. Thus, it works as an efficient spatial attention module\n(SAM). We have implemented the proposed framework on two separate CXR datasets.\nThe first dataset is obtained from a readily available source on the internet,\nand the second dataset is a more challenging CXR dataset, assembled by our\nresearch team from three different sources. Experimental results reveal that\nour proposed framework has outperformed pre-trained CNN models, and three\nrecent trend existing models ``Vision Transformer\", ``Pooling-based Vision\nTransformer (PiT)'' and ``PneuNet\", by substantial margins on both datasets.\nThe proposed framework VGG-Lite with EEM, has achieved a macro average of 95%\naccuracy, 97.1% precision, 96.1% recall, and 96.6% F1 score on the ``Pneumonia\nImbalance CXR dataset\", without employing any pre-processing technique.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-10T05:38:46Z"}
{"aid":"http://arxiv.org/abs/2504.07471v1","title":"Traversal Learning Coordination For Lossless And Efficient Distributed\n  Learning","summary":"In this paper, we introduce Traversal Learning (TL), a novel approach\ndesigned to address the problem of decreased quality encountered in popular\ndistributed learning (DL) paradigms such as Federated Learning (FL), Split\nLearning (SL), and SplitFed Learning (SFL). Traditional FL experiences from an\naccuracy drop during aggregation due to its averaging function, while SL and\nSFL face increased loss due to the independent gradient updates on each split\nnetwork. TL adopts a unique strategy where the model traverses the nodes during\nforward propagation (FP) and performs backward propagation (BP) on the\norchestrator, effectively implementing centralized learning (CL) principles\nwithin a distributed environment. The orchestrator is tasked with generating\nvirtual batches and planning the sequential node visits of the model during FP,\naligning them with the ordered index of the data within these batches. We\nconducted experiments on six datasets representing diverse characteristics\nacross various domains. Our evaluation demonstrates that TL is on par with\nclassic CL approaches in terms of accurate inference, thereby offering a viable\nand robust solution for DL tasks. TL outperformed other DL methods and improved\naccuracy by 7.85% for independent and identically distributed (IID) datasets,\nmacro F1-score by 1.06% for non-IID datasets, accuracy by 2.60% for text\nclassification, and AUC by 3.88% and 4.54% for medical and financial datasets,\nrespectively. By effectively preserving data privacy while maintaining\nperformance, TL represents a significant advancement in DL methodologies.","main_category":"cs.LG","categories":"cs.LG,cs.DC","published":"2025-04-10T05:48:57Z"}
{"aid":"http://arxiv.org/abs/2504.07474v1","title":"Dynamical quantum phase transition, metastable state, and dimensionality\n  reduction: Krylov analysis of fully-connected spin models","summary":"We study quenched dynamics of fully-connected spin models. The system is\nprepared in a ground state of the initial Hamiltonian and the Hamiltonian is\nsuddenly changed to a different form. We apply the Krylov subspace method to\nmap the system onto an effective tridiagonal Hamiltonian. The state is confined\nin a potential well and is time-evolved by nonuniform hoppings. The dynamical\nsingularities for the survival probability can occur when the state is\nreflected from a potential barrier. Although we do not observe any singularity\nin the spread complexity, we find that the entropy exhibits small dips at the\nsingular times. We find that the presence of metastable state affects long-time\nbehavior of the spread complexity, and physical observables. We also observe a\nreduction of the state-space dimension when the Hamiltonian reduces to a\nclassical form.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-10T05:58:49Z"}
{"aid":"http://arxiv.org/abs/2504.07476v1","title":"CMEdataset Advancing China Map Detection and Standardization with\n  Digital Image Resources","summary":"Digital images of Chinas maps play a crucial role in map detection,\nparticularly in ensuring national sovereignty, territorial integrity, and map\ncompliance. However, there is currently no publicly available dataset\nspecifically dedicated to problematic maps the CME dataset. Existing datasets\nprimarily focus on general map data and are insufficient for effectively\nidentifying complex issues such as national boundary misrepresentations,\nmissing elements, and blurred boundaries. Therefore, this study creates a\nProblematic Map dataset that covers five key problem areas, aiming to provide\ndiverse samples for problematic map detection technologies, support\nhigh-precision map compliance detection, and enhance map data quality and\ntimeliness. This dataset not only provides essential resources for map\ncompliance, national security monitoring, and map updates, but also fosters\ninnovation and application of related technologies.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-10T06:04:16Z"}
{"aid":"http://arxiv.org/abs/2504.07503v1","title":"Event Signal Filtering via Probability Flux Estimation","summary":"Events offer a novel paradigm for capturing scene dynamics via asynchronous\nsensing, but their inherent randomness often leads to degraded signal quality.\nEvent signal filtering is thus essential for enhancing fidelity by reducing\nthis internal randomness and ensuring consistent outputs across diverse\nacquisition conditions. Unlike traditional time series that rely on fixed\ntemporal sampling to capture steady-state behaviors, events encode transient\ndynamics through polarity and event intervals, making signal modeling\nsignificantly more complex. To address this, the theoretical foundation of\nevent generation is revisited through the lens of diffusion processes. The\nstate and process information within events is modeled as continuous\nprobability flux at threshold boundaries of the underlying irradiance\ndiffusion. Building on this insight, a generative, online filtering framework\ncalled Event Density Flow Filter (EDFilter) is introduced. EDFilter estimates\nevent correlation by reconstructing the continuous probability flux from\ndiscrete events using nonparametric kernel smoothing, and then resamples\nfiltered events from this flux. To optimize fidelity over time, spatial and\ntemporal kernels are employed in a time-varying optimization framework. A fast\nrecursive solver with O(1) complexity is proposed, leveraging state-space\nmodels and lookup tables for efficient likelihood computation. Furthermore, a\nnew real-world benchmark Rotary Event Dataset (RED) is released, offering\nmicrosecond-level ground truth irradiance for full-reference event filtering\nevaluation. Extensive experiments validate EDFilter's performance across tasks\nlike event filtering, super-resolution, and direct event-based blob tracking.\nSignificant gains in downstream applications such as SLAM and video\nreconstruction underscore its robustness and effectiveness.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T07:03:08Z"}
{"aid":"http://arxiv.org/abs/2504.07504v1","title":"On Ihara's lemma for definite unitary groups","summary":"Clozel, Harris, and Taylor proposed a conjectural generalized Ihara's lemma\nfor definite unitary groups. In this paper, we prove their conjecture over\nbanal coefficients under some conditions. As an application, we prove a\nlevel-raising result for automorphic forms associated to definite unitary\ngroups.","main_category":"math.NT","categories":"math.NT,math.RT","published":"2025-04-10T07:03:27Z"}
{"aid":"http://arxiv.org/abs/2504.07517v1","title":"Gravitational wave signals from primordial black holes orbiting\n  solar-type stars","summary":"Primordial black holes (PBHs) with masses between $10^{14}$ and $10^{20}$ kg\nare candidates to contribute a substantial fraction of the total dark matter\nabundance. When in orbit around the center of a star, which can possibly be a\ncompletely interior orbit, such objects would emit gravitational waves, as\npredicted by general relativity. In this work, we examine the gravitational\nwave signals emitted by such objects when they orbit typical stars, such as the\nSun. We show that the magnitude of the waves that could eventually be detected\non Earth from a possible PBH orbiting the Sun or a neighboring Sun-like star\nwithin our galaxy can be significantly stronger than those originating from a\nPBH orbiting a denser but more distant neutron star (NS). Such signals may be\ndetectable by the LISA gravitational-wave detector. In addition, we estimate\nthe contribution that a large collection of such PBH-star systems would make to\nthe stochastic gravitational-wave background (SGWB) within a range of\nfrequencies to which pulsar timing arrays are sensitive.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,astro-ph.HE,astro-ph.SR","published":"2025-04-10T07:25:26Z"}
{"aid":"http://arxiv.org/abs/2504.07520v1","title":"Stability and Convergence of Strang Splitting Method for the Allen-Cahn\n  Equation with Homogeneous Neumann Boundary Condition","summary":"The Strang splitting method has been widely used to solve nonlinear\nreaction-diffusion equations, with most theoretical convergence analysis\nassuming periodic boundary conditions. However, such analysis presents\nadditional challenges for the case of homogeneous Neumann boundary condition.\nIn this work the Strang splitting method with variable time steps is\ninvestigated for solving the Allen--Cahn equation with homogeneous Neumann\nboundary conditions. Uniform $H^k$-norm stability is established under the\nassumption that the initial condition $u^0$ belongs to the Sobolev space\n$H^k(\\Omega)$ with integer $k\\ge 0$, using the Gagliardo--Nirenberg\ninterpolation inequality and the Sobolev embedding inequality. Furthermore,\nrigorous convergence analysis is provided in the $H^k$-norm for initial\nconditions $u^0 \\in H^{k+6}(\\Omega)$, based on the uniform stability. Several\nnumerical experiments are conducted to verify the theoretical results,\ndemonstrating the effectiveness of the proposed method.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-10T07:33:42Z"}
{"aid":"http://arxiv.org/abs/2504.07525v1","title":"Non triviality of the percolation threshold and Gumbel fluctuations for\n  Branching Interlacements","summary":"We consider the model of Branching Interlacements, introduced by Zhu, which\nis a natural analogue of Sznitman's Random Interlacements model, where the\nrandom walk trajectories are replaced by ranges of some suitable tree-indexed\nrandom walks. We first prove a basic decorrelation inequality for events\ndepending on the state of the field on distinct boxes. We then show that in all\nrelevant dimensions, the vacant set undergoes a nontrivial phase transition\nregarding the existence of an infinite connected component. Finally we obtain\nthe Gumbel fluctuations for the cover level of finite sets, which is analogous\nto Belius' result in the setting of Random Interlacements.","main_category":"math.PR","categories":"math.PR","published":"2025-04-10T07:46:21Z"}
{"aid":"http://arxiv.org/abs/2504.07526v1","title":"Computing gradient vector fields with Morse sequences","summary":"We rely on the framework of Morse sequences to enable the direct computation\nof gradient vector fields on simplicial complexes. A Morse sequence is a\nfiltration from a subcomplex L to a complex K via elementary expansions and\nfillings, naturally encoding critical and regular simplexes. Maximal increasing\nand minimal decreasing schemes allow constructing these sequences, and are\nlinked to algorithms like Random Discrete Morse and Coreduction. Extending the\napproach to cosimplicial complexes (S = K \\ L), we define operations --\nreductions, perforations, coreductions, and coperforations -- for efficient\ncomputation. We further generalize to F -sequences, which are Morse sequences\nweighted by an arbitrary stack function F , and provide algorithms to compute\nmaximal and minimal sequences. A particular case is when the stack function is\ngiven through a vertex map, as it is common in topological data analysis. We\nshow that we retrieve existing methods when the vertex map is injective; in\nthis case, the complex partitions into lower stars, facilitating parallel\nprocessing. Thus, this paper proposes simple, flexible, and computationally\nefficient approaches to obtain Morse sequences from arbitrary stack functions,\nallowing to generalize previous approaches dedicated to computing gradient\nvector fields from injective vertex maps.","main_category":"cs.DM","categories":"cs.DM,math.AT","published":"2025-04-10T07:48:31Z"}
{"aid":"http://arxiv.org/abs/2504.07534v1","title":"Convex spacelike hypersurface of constant curvature with boundary on a\n  hyperboloid","summary":"We consider convex, spacelike hypersurfaces with boundaries on some\nhyperboloid (or lightcone) in the Minkowski space. If the hypersurface has\nconstant higher order mean curvature, and the angle between the normal vectors\nof the hypersurface and the hyperboloid (or the lightcone) is constant on the\nboundary, then the hypersurface must be a part of another hyperboloid.","main_category":"math.DG","categories":"math.DG","published":"2025-04-10T08:00:55Z"}
{"aid":"http://arxiv.org/abs/2504.07535v1","title":"The v-numbers of Stanley-Reisner ideals from the viewpoint of Alexander\n  dual complexes","summary":"We express the v-number of the Stanley-Reisner ideal in terms of its\nAlexander dual complex and prove that the v-number of a cover ideal is just two\nless than the initial degree of the its syzygy module. We give some relation\nbetween the v-number of the Stanley-Reisner ideal and the Serre-depth of the\nquotient ring of the second symbolic power of the Stanley-Reisner ideal of its\nAlexander dual. We also show that the v-number of the Stanley-Reisner ideal of\na 2-pure simplicial complex is equal to the dimension of its Stanley-Reisner\nring.","main_category":"math.AC","categories":"math.AC","published":"2025-04-10T08:01:59Z"}
{"aid":"http://arxiv.org/abs/2504.07539v1","title":"$C$ and $CP$ violation in effective field theories and applications to\n  $η$-meson decays","summary":"The quest for sources of the simultaneous violation of $C$ and $CP$ symmetry\nwas popular in the 1960s, but has since been neglected for a long time. We\nrevisit the operators that break $C$ and $CP$ for flavor-conserving transitions\nin both the Standard Model effective field theory and the low-energy effective\nfield theory, which subsequently can be matched to light-meson physics using\nchiral perturbation theory. As applications, we discuss in particular the\n$C$-odd Dalitz plot asymmetries in $\\eta\\to3\\pi$, but also decays with dilepton\npairs in the final state, such as long-distance contributions to the rare\nsemileptonic decays $\\eta\\to\\pi^0\\ell^+\\ell^-$ as well as asymmetries in\n$\\eta^{(\\prime)} \\to \\gamma \\ell^+\\ell^-$ and $\\eta^{(\\prime)} \\to\n\\pi^+\\pi^-\\ell^+\\ell^-$.","main_category":"hep-ph","categories":"hep-ph,hep-ex,nucl-th","published":"2025-04-10T08:07:32Z"}
{"aid":"http://arxiv.org/abs/2504.07547v1","title":"Strategic learning for disturbance rejection in multi-agent systems:\n  Nash and Minmax in graphical games","summary":"This article investigates the optimal control problem with disturbance\nrejection for discrete-time multi-agent systems under cooperative and\nnon-cooperative graphical games frameworks. Given the practical challenges of\nobtaining accurate models, Q-function-based policy iteration methods are\nproposed to seek the Nash equilibrium solution for the cooperative graphical\ngame and the distributed minmax solution for the non-cooperative graphical\ngame. To implement these methods online, two reinforcement learning frameworks\nare developed, an actor-disturber-critic structure for the cooperative\ngraphical game and an actor-adversary-disturber-critic structure for the\nnon-cooperative graphical game. The stability of the proposed methods is\nrigorously analyzed, and simulation results are provided to illustrate the\neffectiveness of the proposed methods.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-10T08:22:33Z"}
{"aid":"http://arxiv.org/abs/2504.07554v1","title":"Efficient Swept Volume-Based Trajectory Generation for Arbitrary-Shaped\n  Ground Robot Navigation","summary":"Navigating an arbitrary-shaped ground robot safely in cluttered environments\nremains a challenging problem. The existing trajectory planners that account\nfor the robot's physical geometry severely suffer from the intractable runtime.\nTo achieve both computational efficiency and Continuous Collision Avoidance\n(CCA) of arbitrary-shaped ground robot planning, we proposed a novel\ncoarse-to-fine navigation framework that significantly accelerates planning. In\nthe first stage, a sampling-based method selectively generates distinct\ntopological paths that guarantee a minimum inflated margin. In the second\nstage, a geometry-aware front-end strategy is designed to discretize these\ntopologies into full-state robot motion sequences while concurrently\npartitioning the paths into SE(2) sub-problems and simpler R2 sub-problems for\nback-end optimization. In the final stage, an SVSDF-based optimizer generates\ntrajectories tailored to these sub-problems and seamlessly splices them into a\ncontinuous final motion plan. Extensive benchmark comparisons show that the\nproposed method is one to several orders of magnitude faster than the\ncutting-edge methods in runtime while maintaining a high planning success rate\nand ensuring CCA.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-10T08:34:34Z"}
{"aid":"http://arxiv.org/abs/2504.07556v1","title":"TokenFocus-VQA: Enhancing Text-to-Image Alignment with Position-Aware\n  Focus and Multi-Perspective Aggregations on LVLMs","summary":"While text-to-image (T2I) generation models have achieved remarkable progress\nin recent years, existing evaluation methodologies for vision-language\nalignment still struggle with the fine-grained semantic matching. Current\napproaches based on global similarity metrics often overlook critical\ntoken-level correspondences between textual descriptions and visual content. To\nthis end, we present TokenFocus-VQA, a novel evaluation framework that\nleverages Large Vision-Language Models (LVLMs) through visual question\nanswering (VQA) paradigm with position-specific probability optimization. Our\nkey innovation lies in designing a token-aware loss function that selectively\nfocuses on probability distributions at pre-defined vocabulary positions\ncorresponding to crucial semantic elements, enabling precise measurement of\nfine-grained semantical alignment. The proposed framework further integrates\nensemble learning techniques to aggregate multi-perspective assessments from\ndiverse LVLMs architectures, thereby achieving further performance enhancement.\nEvaluated on the NTIRE 2025 T2I Quality Assessment Challenge Track 1, our\nTokenFocus-VQA ranks 2nd place (0.8445, only 0.0001 lower than the 1st method)\non public evaluation and 2nd place (0.8426) on the official private test set,\ndemonstrating superiority in capturing nuanced text-image correspondences\ncompared to conventional evaluation methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T08:37:13Z"}
{"aid":"http://arxiv.org/abs/2504.07582v1","title":"Nanodiamond quantum thermometry assisted with machine learning","summary":"Nanodiamonds (NDs) are quantum sensors that enable local temperature\nmeasurements, taking advantage of their small size. Though the model based\nanalysis methods have been used for ND quantum thermometry, their accuracy has\nyet to be thoroughly investigated. Here, we apply model-free machine learning\nwith the Gaussian process regression (GPR) to ND quantum thermometry and\ncompare its capabilities with the existing methods. We prove that GPR provides\nmore robust results than them, even for a small number of data points and\nregardless of the data acquisition methods. This study extends the range of\napplications of ND quantum thermometry with machine learning.","main_category":"quant-ph","categories":"quant-ph,physics.app-ph","published":"2025-04-10T09:24:10Z"}
{"aid":"http://arxiv.org/abs/2504.07586v1","title":"A perspective on totally geodesic submanifolds of the symmetric space\n  $G_2/SO(4)$","summary":"We provide an independent proof of the classification of the maximal totally\ngeodesic submanifolds of the symmetric spaces $G_2$ and $G_2/SO(4)$, jointly\nwith very natural descriptions of all of these submanifolds. The description of\nthe totally geodesic submanifolds of $G_2$ is in terms of (1) principal\nsubalgebras of $\\mathfrak{g}_2$; (2) stabilizers of nonzero points of\n$\\mathbb{R}^7$; (3) stabilizers of associative subalgebras; (4) the set of\norder two elements in $G_2$ (and its translations). The space $G_2/SO(4)$ is\nidentified with the set of associative subalgebras of $\\mathbb{R}^7$ and its\nmaximal totally geodesic submanifolds can be described as the associative\nsubalgebras adapted to a fixed principal subalgebra, the associative\nsubalgebras orthogonal to a fixed nonzero vector, the associative subalgebras\ncontaining a fixed nonzero vector, and the associative subalgebras intersecting\nboth a fixed associative subalgebra and its orthogonal. A second description is\nincluded in terms of Grassmannians, the advantage of which is that the\nassociated Lie triple systems are easily described in matrix form.","main_category":"math.DG","categories":"math.DG","published":"2025-04-10T09:28:50Z"}
{"aid":"http://arxiv.org/abs/2504.07592v1","title":"Hardness of 4-Colourings G-Colourable Graphs","summary":"We study the complexity of a class of promise graph homomorphism problems.\nFor a fixed graph H, the H-colouring problem is to decide whether a given graph\nhas a homomorphism to H. By a result of Hell and Ne\\v{s}et\\v{r}il, this problem\nis NP-hard for any non-bipartite loop-less graph H. Brakensiek and Guruswami\n[SODA 2018] conjectured the hardness extends to promise graph homomorphism\nproblems as follows: fix a pair of non-bipartite loop-less graphs G, H such\nthat there is a homomorphism from G to H, it is NP-hard to distinguish between\ngraphs that are G-colourable and those that are not H-colourable. We confirm\nthis conjecture in the cases when both G and H are 4-colourable. This is a\ncommon generalisation of previous results of Khanna, Linial, and Safra [Comb.\n20(3): 393-415 (2000)] and of Krokhin and Opr\\v{s}al [FOCS 2019]. The result is\nobtained by combining the algebraic approach to promise constraint satisfaction\nwith methods of topological combinatorics and equivariant obstruction theory.","main_category":"cs.CC","categories":"cs.CC,math.AT,math.CO","published":"2025-04-10T09:44:53Z"}
{"aid":"http://arxiv.org/abs/2504.07596v1","title":"Boosting Universal LLM Reward Design through the Heuristic Reward\n  Observation Space Evolution","summary":"Large Language Models (LLMs) are emerging as promising tools for automated\nreinforcement learning (RL) reward design, owing to their robust capabilities\nin commonsense reasoning and code generation. By engaging in dialogues with RL\nagents, LLMs construct a Reward Observation Space (ROS) by selecting relevant\nenvironment states and defining their internal operations. However, existing\nframeworks have not effectively leveraged historical exploration data or manual\ntask descriptions to iteratively evolve this space. In this paper, we propose a\nnovel heuristic framework that enhances LLM-driven reward design by evolving\nthe ROS through a table-based exploration caching mechanism and a text-code\nreconciliation strategy. Our framework introduces a state execution table,\nwhich tracks the historical usage and success rates of environment states,\novercoming the Markovian constraint typically found in LLM dialogues and\nfacilitating more effective exploration. Furthermore, we reconcile\nuser-provided task descriptions with expert-defined success criteria using\nstructured prompts, ensuring alignment in reward design objectives.\nComprehensive evaluations on benchmark RL tasks demonstrate the effectiveness\nand stability of the proposed framework. Code and video demos are available at\njingjjjjjie.github.io/LLM2Reward.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-10T09:48:56Z"}
{"aid":"http://arxiv.org/abs/2504.07599v1","title":"Tuning chirality amplitude at ultrafast timescales","summary":"Chirality is a fundamental symmetry concept describing discrete states, i.e.,\nleft-handed, right-handed, or achiral, and existing at disparate scales and in\nmany categories of scientific fields. Even though symmetry breaking is\nindispensable for describing qualitatively distinct phenomena, symmetry cannot\nquantitatively predict measurable quantities. One can continuously distort an\nobject, introducing the concept of chirality amplitude, similar to representing\nmagnetization as the amplitude of time-reversal symmetry breaking. Considering\nthe role of magnetization in emergent phenomena with time-reversal symmetry\nbreaking, chirality amplitude is intuitively a key quantity for controlling\nchirality-related emergent phenomena. Here, we propose two types of chiral\nlattice distortions and demonstrate the tunability of their amplitude in\nultrafast timescales. Resonant X-ray diffraction with circular polarization is\nan established technique to measure crystal chirality directly. We quantify the\nultrafast change in chirality amplitude in real time after an optical\nexcitation. Using instead a THz excitation, we observe oscillations in the\nresonant diffraction intensities corresponding to specific phonon frequencies.\nThis indicates the creation of additional asymmetry, which could also be\ndescribed as an enhancement in chirality amplitude. Our proposed concept of\nchirality amplitude and its ultrafast control may lead to a unique approach to\ncontrol chirality-induced emergent phenomena in ultrafast timescales.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-10T09:52:13Z"}
{"aid":"http://arxiv.org/abs/2504.07604v1","title":"Fourier multipliers and their applications to PDE on the quantum\n  Euclidean space","summary":"In this work, we present some applications of the $L^p$-$L^q$ boundedness of\nFourier multipliers to PDEs on the noncommutative (or quantum) Euclidean space.\nMore precisely, we establish $L^p$-$L^q$ norm estimates for solutions of heat,\nwave, and Schr\\\"odinger type equations with Caputo fractional derivative in the\ncase $1 < p \\leq 2 \\leq q < \\infty.$ Moreover, we obtain well-posedness of\nnonlinear heat and wave equations on the noncommutative Euclidean space.","main_category":"math.AP","categories":"math.AP","published":"2025-04-10T09:55:19Z"}
{"aid":"http://arxiv.org/abs/2504.07612v1","title":"SaRoHead: A Dataset for Satire Detection in Romanian Multi-Domain News\n  Headlines","summary":"The headline is an important part of a news article, influenced by\nexpressiveness and connection to the exposed subject. Although most news\noutlets aim to present reality objectively, some publications prefer a humorous\napproach in which stylistic elements of satire, irony, and sarcasm blend to\ncover specific topics. Satire detection can be difficult because a headline\naims to expose the main idea behind a news article. In this paper, we propose\nSaRoHead, the first corpus for satire detection in Romanian multi-domain news\nheadlines. Our findings show that the clickbait used in some non-satirical\nheadlines significantly influences the model.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T10:03:29Z"}
{"aid":"http://arxiv.org/abs/2504.07613v1","title":"Power spectrum of the CODEX clusters","summary":"Aims. We analyze the clustering of galaxy clusters in a large contiguous\nsample, the Constrain Dark Energy with X-ray (CODEX) sample. We construct a\nlikelihood for cosmological parameters by comparing the measured clustering\nsignal and a theoretical prediction, and use this to obtain parameter\nconstraints. Methods. We measured the three multipole moments (monopole,\nquadrupole, and hexadecapole, $\\ell = 0, 2, 4$) of the power spectrum of a\nsubset of the CODEX clusters. To fully model cluster clustering, we also\ndetermined the expected clustering bias of the sample using estimates for the\ncluster masses and a mass-to-bias model calibrated using N-body simulations. We\nestimated the covariance matrix of the measured power spectrum multipoles using\na set of simulated dark-matter halo catalogs. Combining all these ingredients,\nwe performed a Markov chain Monte Carlo sampling of cosmological parameters\n$\\Omega_m$ and $\\sigma_8$ to obtain their posterior. Results. We found the\nCODEX clustering signal to be consistent with an earlier X-ray selected cluster\nsample, the REFLEX II sample. We also found that the measured power spectrum\nmultipoles are compatible with the predicted, bias-scaled linear matter power\nspectrum when the cosmological parameters determined by the Planck satellite\nare assumed. Furthermore, we found the marginalized parameter constraints of\n$\\Omega_m = 0.24^{+0.06}_{-0.04}$ and $\\sigma_8 = 1.13^{+0.43}_{-0.24}$. The\nfull 2D posterior is consistent, for example, with the Planck cosmology within\nthe 68% confidence region.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-10T10:04:24Z"}
{"aid":"http://arxiv.org/abs/2504.07625v1","title":"Deep Learning Meets Teleconnections: Improving S2S Predictions for\n  European Winter Weather","summary":"Predictions on subseasonal-to-seasonal (S2S) timescales--ranging from two\nweeks to two month--are crucial for early warning systems but remain\nchallenging owing to chaos in the climate system. Teleconnections, such as the\nstratospheric polar vortex (SPV) and Madden-Julian Oscillation (MJO), offer\nwindows of enhanced predictability, however, their complex interactions remain\nunderutilized in operational forecasting. Here, we developed and evaluated deep\nlearning architectures to predict North Atlantic-European (NAE) weather\nregimes, systematically assessing the role of remote drivers in improving S2S\nforecast skill of deep learning models. We implemented (1) a Long Short-term\nMemory (LSTM) network predicting the NAE regimes of the next six weeks based on\nprevious regimes, (2) an Index-LSTM incorporating SPV and MJO indices, and (3)\na ViT-LSTM using a Vision Transformer to directly encode stratospheric wind and\ntropical outgoing longwave radiation fields. These models are compared with\noperational hindcasts as well as other AI models. Our results show that\nleveraging teleconnection information enhances skill at longer lead times.\nNotably, the ViT-LSTM outperforms ECMWF's subseasonal hindcasts beyond week 4\nby improving Scandinavian Blocking (SB) and Atlantic Ridge (AR) predictions.\nAnalysis of high-confidence predictions reveals that NAO-, SB, and AR\nopportunity forecasts can be associated with SPV variability and MJO phase\npatterns aligning with established pathways, also indicating new patterns.\nOverall, our work demonstrates that encoding physically meaningful climate\nfields can enhance S2S prediction skill, advancing AI-driven subseasonal\nforecast. Moreover, the experiments highlight the potential of deep learning\nmethods as investigative tools, providing new insights into atmospheric\ndynamics and predictability.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-10T10:23:07Z"}
{"aid":"http://arxiv.org/abs/2504.07626v1","title":"Upper bounds of focusing light through multimode fibers","summary":"Wavefront shaping enables precise control of light propagation through\nmultimode fibers, facilitating diffraction-limited focusing for applications\nsuch as high-resolution single-fiber imaging and high-power fiber amplifiers.\nWhile the theoretical intensity enhancement at the focal point is dictated by\nthe number of input degrees of freedom, practical constraints such as\nphase-only modulation and experimental noise impose significant limitations.\nDespite its importance, the upper bounds of enhancement under these constraints\nremain largely unexplored. In this work, we establish a theoretical framework\nto predict the fundamental limits of intensity enhancement with phase-only\nmodulation in the presence of noise-induced phase errors, and we experimentally\ndemonstrate wavefront shaping that approaches these limits. Our experimental\nresults confirm an enhancement factor of 5,000 in a large-core multimode fiber,\napproaching the theoretical upper bound, enabled by noise-tolerant wavefront\nshaping. These findings provide key insights into the limits of phase-only\ncontrol in multimode fibers, with profound implications for single-fiber\nimaging, optical communication, high-power broad-area fiber amplification, and\nbeyond.","main_category":"physics.optics","categories":"physics.optics,physics.app-ph","published":"2025-04-10T10:24:08Z"}
{"aid":"http://arxiv.org/abs/2504.07633v1","title":"Kernel Logistic Regression Learning for High-Capacity Hopfield Networks","summary":"Hebbian learning limits Hopfield network storage capacity (pattern-to-neuron\nratio around 0.14). We propose Kernel Logistic Regression (KLR) learning.\nUnlike linear methods, KLR uses kernels to implicitly map patterns to\nhigh-dimensional feature space, enhancing separability. By learning dual\nvariables, KLR dramatically improves storage capacity, achieving perfect recall\neven when pattern numbers exceed neuron numbers (up to ratio 1.5 shown), and\nenhances noise robustness. KLR demonstrably outperforms Hebbian and linear\nlogistic regression approaches.","main_category":"cs.LG","categories":"cs.LG,cs.NE","published":"2025-04-10T10:27:43Z"}
{"aid":"http://arxiv.org/abs/2504.07635v1","title":"Generative Artificial Intelligence for Internet of Things Computing: A\n  Systematic Survey","summary":"The integration of Generative Artificial Intelligence (GenAI) within the\nInternet of Things (IoT) is garnering considerable interest. This growing\nattention stems from the continuous evolution and widespread adoption they are\nboth having individually, enough to spontaneously reshape numerous sectors,\nincluding Healthcare, Manufacturing, and Smart Cities. Hence, their increasing\npopularity has catalyzed further extensive research for understanding the\npotential of the duo GenAI-IoT, how they interplay, and to which extent their\nsynergy can innovate the state-of-the-art in their individual scenarios.\nHowever, despite the increasing prominence of GenAI for IoT Computing, much of\nthe existing research remains focused on specific, narrowly scoped\napplications. This fragmented approach highlights the need for a more\ncomprehensive analysis of the potential, challenges, and implications of GenAI\nintegration within the broader IoT ecosystem. This survey exactly aims to\naddress this gap by providing a holistic overview of the opportunities, issues,\nand considerations arising from the convergence of these mainstream paradigms.\nOur contribution is realized through a systematic literature review following\nthe PRISMA methodology. A comparison framework is presented, and well-defined\nresearch questions are outlined to comprehensively explore the past, present,\nand future directions of GenAI integration with IoT Computing, offering\nvaluable insights for both experts and newcomers.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-10T10:32:18Z"}
{"aid":"http://arxiv.org/abs/2504.07636v1","title":"Rational concordance of double twist knots","summary":"Double twist knots $K_{m, n}$ are known to be rationally slice if $mn = 0$,\n$n = -m\\pm 1$, or $n = -m$. In this paper, we prove the converse. It is done by\nshowing that infinitely many prime power-fold cyclic branched covers of the\nother cases do not bound a rational ball. Our rational ball obstruction is\nbased on Donaldson's diagonalization theorem.","main_category":"math.GT","categories":"math.GT","published":"2025-04-10T10:32:28Z"}
{"aid":"http://arxiv.org/abs/2504.07646v1","title":"On the Temporal Question-Answering Capabilities of Large Language Models\n  Over Anonymized Data","summary":"The applicability of Large Language Models (LLMs) in temporal reasoning tasks\nover data that is not present during training is still a field that remains to\nbe explored. In this paper we work on this topic, focusing on structured and\nsemi-structured anonymized data. We not only develop a direct LLM pipeline, but\nalso compare various methodologies and conduct an in-depth analysis. We\nidentified and examined seventeen common temporal reasoning tasks in natural\nlanguage, focusing on their algorithmic components. To assess LLM performance,\nwe created the \\textit{Reasoning and Answering Temporal Ability} dataset\n(RATA), featuring semi-structured anonymized data to ensure reliance on\nreasoning rather than on prior knowledge. We compared several methodologies,\ninvolving SoTA techniques such as Tree-of-Thought, self-reflexion and code\nexecution, tuned specifically for this scenario. Our results suggest that\nachieving scalable and reliable solutions requires more than just standalone\nLLMs, highlighting the need for integrated approaches.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-10T10:48:42Z"}
{"aid":"http://arxiv.org/abs/2504.07655v1","title":"Synthesizing High-Quality Programming Tasks with LLM-based Expert and\n  Student Agents","summary":"Generative AI is transforming computing education by enabling the automatic\ngeneration of personalized content and feedback. We investigate its\ncapabilities in providing high-quality programming tasks to students. Despite\npromising advancements in task generation, a quality gap remains between\nAI-generated and expert-created tasks. The AI-generated tasks may not align\nwith target programming concepts, could be incomprehensible for students to\nsolve, or may contain critical issues such as incorrect tests. Existing works\noften require interventions from human teachers for validation. We address\nthese challenges by introducing PyTaskSyn, a novel synthesis technique that\nfirst generates a programming task and then decides whether it meets certain\nquality criteria to be given to students. The key idea is to break this process\ninto multiple stages performed by expert and student agents simulated using\nboth strong and weaker generative models. Through extensive evaluation, we show\nthat PyTaskSyn significantly improves task quality compared to baseline\ntechniques and showcases the importance of each specialized agent type in our\nvalidation pipeline. Additionally, we conducted user studies using our publicly\navailable web application and show that PyTaskSyn can deliver high-quality\nprogramming tasks comparable to expert-designed ones while reducing workload\nand costs, and being more engaging than programming tasks that are available in\nonline resources.","main_category":"cs.AI","categories":"cs.AI,cs.CY","published":"2025-04-10T11:08:39Z"}
{"aid":"http://arxiv.org/abs/2504.07661v1","title":"Unveiling the Impact of Multimodal Features on Chinese Spelling\n  Correction: From Analysis to Design","summary":"The Chinese Spelling Correction (CSC) task focuses on detecting and\ncorrecting spelling errors in sentences. Current research primarily explores\ntwo approaches: traditional multimodal pre-trained models and large language\nmodels (LLMs). However, LLMs face limitations in CSC, particularly\nover-correction, making them suboptimal for this task. While existing studies\nhave investigated the use of phonetic and graphemic information in multimodal\nCSC models, effectively leveraging these features to enhance correction\nperformance remains a challenge. To address this, we propose the Multimodal\nAnalysis for Character Usage (\\textbf{MACU}) experiment, identifying potential\nimprovements for multimodal correctison. Based on empirical findings, we\nintroduce \\textbf{NamBert}, a novel multimodal model for Chinese spelling\ncorrection. Experiments on benchmark datasets demonstrate NamBert's superiority\nover SOTA methods. We also conduct a comprehensive comparison between NamBert\nand LLMs, systematically evaluating their strengths and limitations in CSC. Our\ncode and model are available at https://github.com/iioSnail/NamBert.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T11:19:09Z"}
{"aid":"http://arxiv.org/abs/2504.07663v1","title":"Multiplicative assignment with upgrades","summary":"We study a problem related to submodular function optimization and the exact\nmatching problem for which we show a rather peculiar status: its natural\nLP-relaxation can have fractional optimal vertices, but there is always also an\noptimal integral vertex, which we can also compute in polynomial time.\n  More specifically, we consider the multiplicative assignment problem with\nupgrades in which we are given a set of customers and suppliers and we seek to\nassign each customer to a different supplier. Each customer has a demand and\neach supplier has a regular and an upgraded cost for each unit demand provided\nto the respective assigned client. Our goal is to upgrade at most $k$ suppliers\nand to compute an assignment in order to minimize the total resulting cost.\nThis can be cast as the problem to compute an optimal matching in a bipartite\ngraph with the additional constraint that we must select $k$ edges from a\ncertain group of edges, similar to selecting $k$ red edges in the exact\nmatching problem. Also, selecting the suppliers to be upgraded corresponds to\nmaximizing a submodular set function under a cardinality constraint.\n  Our result yields an efficient LP-based algorithm to solve our problem\noptimally. In addition, we provide also a purely strongly polynomial-time\nalgorithm for it. As an application, we obtain exact algorithms for the\nupgrading variant of the problem to schedule jobs on identical or uniformly\nrelated machines in order to minimize their sum of completion times, i.e.,\nwhere we may upgrade up to $k$ jobs to reduce their respective processing\ntimes.","main_category":"cs.DS","categories":"cs.DS,cs.DM,math.OC","published":"2025-04-10T11:25:29Z"}
{"aid":"http://arxiv.org/abs/2504.07667v1","title":"S2R-HDR: A Large-Scale Rendered Dataset for HDR Fusion","summary":"The generalization of learning-based high dynamic range (HDR) fusion is often\nlimited by the availability of training data, as collecting large-scale HDR\nimages from dynamic scenes is both costly and technically challenging. To\naddress these challenges, we propose S2R-HDR, the first large-scale\nhigh-quality synthetic dataset for HDR fusion, with 24,000 HDR samples. Using\nUnreal Engine 5, we design a diverse set of realistic HDR scenes that encompass\nvarious dynamic elements, motion types, high dynamic range scenes, and\nlighting. Additionally, we develop an efficient rendering pipeline to generate\nrealistic HDR images. To further mitigate the domain gap between synthetic and\nreal-world data, we introduce S2R-Adapter, a domain adaptation designed to\nbridge this gap and enhance the generalization ability of models. Experimental\nresults on real-world datasets demonstrate that our approach achieves\nstate-of-the-art HDR reconstruction performance. Dataset and code will be\navailable at https://openimaginglab.github.io/S2R-HDR.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T11:39:56Z"}
{"aid":"http://arxiv.org/abs/2504.07668v1","title":"Distributed Fault-Tolerant Control for Heterogeneous MAS with Prescribed\n  Performance under Communication Failures","summary":"This paper presents a novel approach employing prescribed performance control\nto address the distributed fault-tolerant formation control problem in a\nheterogeneous UAV-UGV cooperative system under a directed interaction topology\nand communication link failures. The proposed distributed fault-tolerant\ncontrol scheme enables UAVs to accurately track a virtual leader's trajectory\nand achieve the desired formation, while ensuring UGVs converge within the\nconvex hull formed by leader UAVs. By accounting for differences in system\nparameters and state dimensions between UAVs and UGVs, the method leverages\nperformance functions to guarantee predefined transient and steady-state\nbehavior. Additionally, a variable prescribed performance boundary control\nstrategy with an adaptive learning rate is introduced to tackle actuator\nsaturation, ensuring reliable formation tracking in real-world scenarios.\nSimulation results demonstrate the effectiveness and robustness of the proposed\napproach.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-10T11:40:40Z"}
{"aid":"http://arxiv.org/abs/2504.07689v1","title":"Inequality at risk of automation? Gender differences in routine tasks\n  intensity in developing country labor markets","summary":"Technological change can have profound impacts on the labor market. Decades\nof research have made it clear that technological change produces winners and\nlosers. Machines can replace some types of work that humans do, while new\ntechnologies increase human's productivity in other types of work. For a long\ntime, highly educated workers benefitted from increased demand for their labor\ndue to skill-biased technological change, while the losers were concentrated at\nthe bottom of the wage distribution (Katz and Autor, 1999; Goldin and Katz,\n2007, 2010; Kijima, 2006). Currently, however, labor markets seem to be\naffected by a different type of technological change, the so-called\nroutine-biased technological change (RBTC). This chapter studies the risk of\nautomation in developing country labor markets, with a particular focus on\ndifferences between men and women. Given the pervasiveness of gender\noccupational segregation, there may be important gender differences in the risk\nof automation. Understanding these differences is important to ensure progress\ntowards equitable development and gender inclusion in the face of new\ntechnological advances. Our objective is to describe the gender gap in the\nroutine task intensity of jobs in developing countries and to explore the role\nof occupational segregation and several worker characteristics in accounting\nfor the gender gap.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-10T12:19:25Z"}
{"aid":"http://arxiv.org/abs/2504.07694v1","title":"Sim-to-Real Transfer in Reinforcement Learning for Maneuver Control of a\n  Variable-Pitch MAV","summary":"Reinforcement learning (RL) algorithms can enable high-maneuverability in\nunmanned aerial vehicles (MAVs), but transferring them from simulation to\nreal-world use is challenging. Variable-pitch propeller (VPP) MAVs offer\ngreater agility, yet their complex dynamics complicate the sim-to-real\ntransfer. This paper introduces a novel RL framework to overcome these\nchallenges, enabling VPP MAVs to perform advanced aerial maneuvers in\nreal-world settings. Our approach includes real-to-sim transfer techniques-such\nas system identification, domain randomization, and curriculum learning to\ncreate robust training simulations and a sim-to-real transfer strategy\ncombining a cascade control system with a fast-response low-level controller\nfor reliable deployment. Results demonstrate the effectiveness of this\nframework in achieving zero-shot deployment, enabling MAVs to perform complex\nmaneuvers such as flips and wall-backtracking.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-10T12:27:59Z"}
{"aid":"http://arxiv.org/abs/2504.07696v1","title":"Conformalized Generative Bayesian Imaging: An Uncertainty Quantification\n  Framework for Computational Imaging","summary":"Uncertainty quantification plays an important role in achieving trustworthy\nand reliable learning-based computational imaging. Recent advances in\ngenerative modeling and Bayesian neural networks have enabled the development\nof uncertainty-aware image reconstruction methods. Current generative\nmodel-based methods seek to quantify the inherent (aleatoric) uncertainty on\nthe underlying image for given measurements by learning to sample from the\nposterior distribution of the underlying image. On the other hand, Bayesian\nneural network-based approaches aim to quantify the model (epistemic)\nuncertainty on the parameters of a deep neural network-based reconstruction\nmethod by approximating the posterior distribution of those parameters.\nUnfortunately, an ongoing need for an inversion method that can jointly\nquantify complex aleatoric uncertainty and epistemic uncertainty patterns still\npersists. In this paper, we present a scalable framework that can quantify both\naleatoric and epistemic uncertainties. The proposed framework accepts an\nexisting generative model-based posterior sampling method as an input and\nintroduces an epistemic uncertainty quantification capability through Bayesian\nneural networks with latent variables and deep ensembling. Furthermore, by\nleveraging the conformal prediction methodology, the proposed framework can be\neasily calibrated to ensure rigorous uncertainty quantification. We evaluated\nthe proposed framework on magnetic resonance imaging, computed tomography, and\nimage inpainting problems and showed that the epistemic and aleatoric\nuncertainty estimates produced by the proposed framework display the\ncharacteristic features of true epistemic and aleatoric uncertainties.\nFurthermore, our results demonstrated that the use of conformal prediction on\ntop of the proposed framework enables marginal coverage guarantees consistent\nwith frequentist principles.","main_category":"eess.IV","categories":"eess.IV,cs.LG","published":"2025-04-10T12:30:46Z"}
{"aid":"http://arxiv.org/abs/2504.07702v1","title":"Functional Understanding Of Quantum Technology Is Essential To The\n  Ethical Debate About Its Impact","summary":"As the innovative potential of quantum technologies comes into focus, so too\ndoes the urgent need to address their ethical implications. While many voices\nhighlight the importance of ethical engagement, less attention has been paid to\nthe conditions that make such engagement possible. In this article, I argue\nthat technological understanding is a foundational capacity for meaningful\nethical reflection on emerging technology like quantum technologies. Drawing on\nDe Jong & De Haro's account of technological understanding (2025a; 2025b), I\nclarify what such understanding entails and how it enables ethical enquiry. I\ncontend that ethical assessment, first and foremost, requires an understanding\nof what quantum technologies can do - their functional capacities and, by\nextension, their potential applications. Current efforts to build engagement\ncapacities among broader audiences - within and beyond academic contexts -\ntend, however, to focus on explaining the underlying quantum mechanics.\nInstead, I advocate a shift from a physics-first to a functions-first approach:\nfostering an understanding of quantum technologies' capabilities as the basis\nfor ethical reflection. Presenting technological understanding as an epistemic\nrequirement for meaningful ethical engagement may appear to raise the bar for\nparticipation. However, by decoupling functional understanding from technical\nexpertise, this condition becomes attainable for a broader group, contributing\nnot only to a well-informed but also to a more inclusive ethical debate.","main_category":"physics.soc-ph","categories":"physics.soc-ph,quant-ph","published":"2025-04-10T12:38:45Z"}
{"aid":"http://arxiv.org/abs/2504.07709v1","title":"Integrated Sensing and Communications for Pinching-Antenna Systems\n  (PASS)","summary":"An integrated sensing and communication (ISAC) design for pinching antenna\nsystems (PASS) is proposed, where the pinching antennas are deployed for\nestablishing reliable line-of-sight communication and sensing links. More\nparticularly, a separated ISAC design is proposed for the two-waveguide PASS,\nwhere one waveguide is used to emit the joint communication and sensing signals\nwhile the other waveguide is used to receive the reflected echo signals. Based\non this framework, a penalty-based alternating optimization algorithm is\nproposed to maximize the illumination power as well as ensure the communication\nquality-of-service requirement. Numerical results demonstrate that 1) the\nproposed PASS-ISAC scheme outperforms the other baseline schemes, and 2) the\nconsidered equal power allocation model achieves a performance comparable to\nthe optimal power allocation.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-10T12:58:46Z"}
{"aid":"http://arxiv.org/abs/2504.07713v1","title":"Mock Eisenstein series associated to partition ranks","summary":"In this paper, we introduce a new class of mock Eisenstein series, describe\ntheir modular properties, and write the partition rank generating function in\nterms of so-called partition traces of these. Moreover, we show the Fourier\ncoefficients of the mock Eisenstein series are integral and we obtain a\nholomorphic anomaly equation for their completions.","main_category":"math.NT","categories":"math.NT,math-ph,math.CO,math.MP","published":"2025-04-10T13:05:33Z"}
{"aid":"http://arxiv.org/abs/2504.07714v1","title":"Quasi-Periodic Pulsations in Ionospheric TEC Synchronized with Solar\n  Flare EUV Emission","summary":"The extreme ultraviolet (EUV) and X-ray radiation emitted during solar flares\nhas been shown to significantly increase the electron density of the Earth's\nionosphere. During flares, quasi-periodic pulsations (QPPs) in X-ray flux\noriginating in the corona have previously been linked to subsequent pulsations\nin the Earth's ionospheric D-region. Similar pulsations have been detected in\nchromospheric EUV emission, although their impact on the Earth's ionosphere has\nnot previously been investigated. Here, for the first time, synchronous\npulsations were detected in solar EUV emission and ionospheric Total Electron\nContent (TEC) measurements. Using wavelet and periodogram analysis, we detect\nQPPs with approximately 85 second periods in chromospheric EUV emission lines\n(He II 304 \\AA{}, C III 977 \\AA{} and H I 972 \\AA{}) from the Solar Dynamics\nObservatory Extreme Ultraviolet Variability Experiment (SDO/EVE) during the\nimpulsive phase of an X5.4 flare on March 7, 2012. These lines contribute to\nionization in the ionospheric E- and F-regions, resulting in subsequent\nvariations of electron density with the same periodicity, which was detected in\nTEC measurements. This work demonstrates that the Earth's ionosphere is\nresponsive to fine-scale fluctuations in EUV emission during flares, with a\ntime delay of approximately 30 seconds found. These findings may have\napplications in atmospheric modelling and solar-terrestrial studies, including\nthe calculation of ionospheric recombination rates.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP","published":"2025-04-10T13:05:45Z"}
{"aid":"http://arxiv.org/abs/2504.07716v1","title":"Forced Oscillations of a Spring-Mounted Body by a Viscous Liquid:\n  Rotational Case","summary":"We study the periodic motions of the coupled system $\\mathscr S$, consisting\nof an incompressible Navier-Stokes fluid interacting with a structure formed by\na rigid body subject to {\\em undamped} elastic restoring forces and torque\naround its rotation axis. The motion of $\\mathscr S$ is driven by the uniform\nflow of the liquid, far away from the body, characterized by a time-periodic\nvelocity field, $\\mathbf{V}$, of frequency $f$. We show that the corresponding\nset of governing equations always possesses a time-periodic weak solution of\nthe same frequency $f$, whatever $f>0$, the magnitude of $\\mathbf{V}$ and the\nvalues of physical parameters. Moreover, we show that the amplitude of linear\nand rotational displacement is always pointwise in time uniformly bounded by\none and the same constant depending on the data, regardless of whether $f$ is\nor is not close to a natural frequency of the structure. Thus, our result rules\nout the occurrence of resonant phenomena.","main_category":"math.AP","categories":"math.AP","published":"2025-04-10T13:09:14Z"}
{"aid":"http://arxiv.org/abs/2504.07725v1","title":"Approximation Algorithms for Connected Maximum Coverage, Minimum\n  Connected Set Cover, and Node-Weighted Group Steiner Tree","summary":"In the Connected Budgeted maximum Coverage problem (CBC), we are given a\ncollection of subsets $\\mathcal{S}$, defined over a ground set $X$, and an\nundirected graph $G=(V,E)$, where each node is associated with a set of\n$\\mathcal{S}$. Each set in $\\mathcal{S}$ has a different cost and each element\nof $X$ gives a different prize. The goal is to find a subcollection\n$\\mathcal{S}'\\subseteq \\mathcal{S}$ such that $\\mathcal{S}'$ induces a\nconnected subgraph in $G$, the total cost of the sets in $\\mathcal{S}'$ does\nnot exceed a budget $B$, and the total prize of the elements covered by\n$\\mathcal{S}'$ is maximized. The Directed rooted Connected Budgeted maximum\nCoverage problem (DCBC) is a generalization of CBC where the underlying graph\n$G$ is directed and in the subgraph induced by $\\mathcal{S}'$ in $G$ must be an\nout-tree rooted at a given node.\n  The current best algorithms achieve approximation ratios that are linear in\nthe size of $G$ or depend on $B$. In this paper, we provide two algorithms for\nCBC and DCBC that guarantee approximation ratios of\n$O\\left(\\frac{\\log^2|X|}{\\epsilon^2}\\right)$ and\n$O\\left(\\frac{\\sqrt{|V|}\\log^2|X|}{\\epsilon^2}\\right)$, resp., with a budget\nviolation of a factor $1+\\epsilon$, where $\\epsilon\\in (0,1]$.\n  Our algorithms imply improved approximation factors of other related\nproblems. For the particular case of DCBC where the prize function is additive,\nwe improve from $O\\left(\\frac{1}{\\epsilon^2}|V|^{2/3}\\log|V|\\right)$ to\n$O\\left(\\frac{1}{\\epsilon^2}|V|^{1/2}\\log^2|V|\\right)$. For the minimum\nconnected set cover, a minimization version of CBC, and its directed variant,\nwe obtain approximation factors of $O(\\log^3|X|)$ and $O(\\sqrt{|V|}\\log^3|X|)$,\nresp. For the Node-Weighted Group Steiner Tree and and its directed variant, we\nobtain approximation factors of $O(\\log^3k)$ and $O(\\sqrt{|V|}\\log^3k)$, resp.,\nwhere $k$ is the number of groups.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-10T13:18:22Z"}
{"aid":"http://arxiv.org/abs/2504.07730v1","title":"Thermodynamics of Reissner-nordstorm black bounce black hole","summary":"Our study focuses on the thermodynamics of Reissner-nordstorm black bounce\nblack hole,we have determined the thermodynamic parameters including entropy,\nmass, temperature, heat capacity and free energies and investigated how those\nparameters are related to entropy and for some insights we additionally focused\non the P V isotherm and the logarithmic correction to the entropy.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-10T13:27:49Z"}
{"aid":"http://arxiv.org/abs/2504.07738v1","title":"Automated Construction of a Knowledge Graph of Nuclear Fusion Energy for\n  Effective Elicitation and Retrieval of Information","summary":"In this document, we discuss a multi-step approach to automated construction\nof a knowledge graph, for structuring and representing domain-specific\nknowledge from large document corpora. We apply our method to build the first\nknowledge graph of nuclear fusion energy, a highly specialized field\ncharacterized by vast scope and heterogeneity. This is an ideal benchmark to\ntest the key features of our pipeline, including automatic named entity\nrecognition and entity resolution. We show how pre-trained large language\nmodels can be used to address these challenges and we evaluate their\nperformance against Zipf's law, which characterizes human-generated natural\nlanguage. Additionally, we develop a knowledge-graph retrieval-augmented\ngeneration system that combines large language models with a multi-prompt\napproach. This system provides contextually relevant answers to\nnatural-language queries, including complex multi-hop questions that require\nreasoning across interconnected entities.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T13:29:58Z"}
{"aid":"http://arxiv.org/abs/2504.07739v1","title":"Implicit Incompressible Porous Flow using SPH","summary":"We present a novel implicit porous flow solver using SPH, which maintains\nfluid incompressibility and is able to model a wide range of scenarios, driven\nby strongly coupled solid-fluid interaction forces. Many previous SPH porous\nflow methods reduce particle volumes as they transition across the solid-fluid\ninterface, resulting in significant stability issues. We instead allow fluid\nand solid to overlap by deriving a new density estimation. This further allows\nus to extend modern SPH pressure solvers to take local porosity into account\nand results in strict enforcement of incompressibility. As a result, we can\nsimulate porous flow using physically consistent pressure forces between fluid\nand solid. In contrast to previous SPH porous flow methods, which use explicit\nforces for internal fluid flow, we employ implicit non-pressure forces. These\nwe solve as a linear system and strongly couple with fluid viscosity and solid\nelasticity. We capture the most common effects observed in porous flow, namely\ndrag, buoyancy and capillary action due to adhesion. To achieve elastic\nbehavior change based on local fluid saturation, such as bloating or softening,\nwe propose an extension to the elasticity model. We demonstrate the efficacy of\nour model with various simulations that showcase the different aspects of\nporous flow behavior. To summarize, our system of strongly coupled non-pressure\nforces and enforced incompressibility across overlapping phases allows us to\nnaturally model and stably simulate complex porous interactions.","main_category":"cs.GR","categories":"cs.GR,physics.flu-dyn","published":"2025-04-10T13:30:22Z"}
{"aid":"http://arxiv.org/abs/2504.07741v1","title":"Harnessing Equivariance: Modeling Turbulence with Graph Neural Networks","summary":"This work proposes a novel methodology for turbulence modeling in Large Eddy\nSimulation (LES) based on Graph Neural Networks (GNNs), which embeds the\ndiscrete rotational, reflectional and translational symmetries of the\nNavier-Stokes equations into the model architecture. In addition, suitable\ninvariant input and output spaces are derived that allow the GNN models to be\nembedded seamlessly into the LES framework to obtain a symmetry-preserving\nsimulation setup. The suitability of the proposed approach is investigated for\ntwo canonical test cases: Homogeneous Isotropic Turbulence (HIT) and turbulent\nchannel flow. For both cases, GNN models are trained successfully in actual\nsimulations using Reinforcement Learning (RL) to ensure that the models are\nconsistent with the underlying LES formulation and discretization. It is\ndemonstrated for the HIT case that the resulting GNN-based LES scheme recovers\nrotational and reflectional equivariance up to machine precision in actual\nsimulations. At the same time, the stability and accuracy remain on par with\nnon-symmetry-preserving machine learning models that fail to obey these\nproperties. The same modeling strategy translates well to turbulent channel\nflow, where the GNN model successfully learns the more complex flow physics and\nis able to recover the turbulent statistics and Reynolds stresses. It is shown\nthat the GNN model learns a zonal modeling strategy with distinct behaviors in\nthe near-wall and outer regions. The proposed approach thus demonstrates the\npotential of GNNs for turbulence modeling, especially in the context of LES and\nRL.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cs.LG","published":"2025-04-10T13:37:54Z"}
{"aid":"http://arxiv.org/abs/2504.07746v1","title":"Upper semi-continuity of metric entropy for $\\mathcal{C}^{1,α}$\n  diffeomorphisms","summary":"We prove that for $\\mathcal{C}^{1,\\alpha}$ diffeomorphisms on a compact\nmanifold $M$ with ${\\rm dim} M\\leq 3$, if an invariant measure $\\mu$ is a\ncontinuity point of the sum of positive Lyapunov exponents, then $\\mu$ is an\nupper semi-continuity point of the entropy map. This gives several\nconsequences, such as the upper-semi continuity of dimensions of measures for\nsurface diffeomorphisms. Furthermore, we know the continuity of dimensions for\nmeasures of maximal entropy.","main_category":"math.DS","categories":"math.DS","published":"2025-04-10T13:41:37Z"}
{"aid":"http://arxiv.org/abs/2504.07757v1","title":"Search-contempt: a hybrid MCTS algorithm for training AlphaZero-like\n  engines with better computational efficiency","summary":"AlphaZero in 2017 was able to master chess and other games without human\nknowledge by playing millions of games against itself (self-play), with a\ncomputation budget running in the tens of millions of dollars. It used a\nvariant of the Monte Carlo Tree Search (MCTS) algorithm, known as PUCT. This\npaper introduces search-contempt, a novel hybrid variant of the MCTS algorithm\nthat fundamentally alters the distribution of positions generated in self-play,\npreferring more challenging positions. In addition, search-contempt has been\nshown to give a big boost in strength for engines in Odds Chess (where one side\nreceives an unfavorable position from the start). More significantly, it opens\nup the possibility of training a self-play based engine, in a much more\ncomputationally efficient manner with the number of training games running into\nhundreds of thousands, costing tens of thousands of dollars (instead of tens of\nmillions of training games costing millions of dollars required by AlphaZero).\nThis means that it may finally be possible to train such a program from zero on\na standard consumer GPU even with a very limited compute, cost, or time budget.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-10T13:56:31Z"}
{"aid":"http://arxiv.org/abs/2504.07758v1","title":"PIDSR:ComplementaryPolarizedImageDemosaicingandSuper-Resolution","summary":"Polarization cameras can capture multiple polarized images with different\npolarizer angles in a single shot, bringing convenience to polarization-based\ndownstream tasks. However, their direct outputs are color-polarization filter\narray (CPFA) raw images, requiring demosaicing to reconstruct full-resolution,\nfull-color polarized images; unfortunately, this necessary step introduces\nartifacts that make polarization-related parameters such as the degree of\npolarization (DoP) and angle of polarization (AoP) prone to error. Besides,\nlimited by the hardware design, the resolution of a polarization camera is\noften much lower than that of a conventional RGB camera. Existing polarized\nimage demosaicing (PID) methods are limited in that they cannot enhance\nresolution, while polarized image super-resolution (PISR) methods, though\ndesigned to obtain high-resolution (HR) polarized images from the demosaicing\nresults, tend to retain or even amplify errors in the DoP and AoP introduced by\ndemosaicing artifacts. In this paper, we propose PIDSR, a joint framework that\nperforms complementary Polarized Image Demosaicing and Super-Resolution,\nshowing the ability to robustly obtain high-quality HR polarized images with\nmore accurate DoP and AoP from a CPFA raw image in a direct manner. Experiments\nshow our PIDSR not only achieves state-of-the-art performance on both synthetic\nand real data, but also facilitates downstream tasks.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-10T13:56:33Z"}
{"aid":"http://arxiv.org/abs/2504.07760v1","title":"PRAD: Periapical Radiograph Analysis Dataset and Benchmark Model\n  Development","summary":"Deep learning (DL), a pivotal technology in artificial intelligence, has\nrecently gained substantial traction in the domain of dental auxiliary\ndiagnosis. However, its application has predominantly been confined to imaging\nmodalities such as panoramic radiographs and Cone Beam Computed Tomography,\nwith limited focus on auxiliary analysis specifically targeting Periapical\nRadiographs (PR). PR are the most extensively utilized imaging modality in\nendodontics and periodontics due to their capability to capture detailed local\nlesions at a low cost. Nevertheless, challenges such as resolution limitations\nand artifacts complicate the annotation and recognition of PR, leading to a\nscarcity of publicly available, large-scale, high-quality PR analysis datasets.\nThis scarcity has somewhat impeded the advancement of DL applications in PR\nanalysis. In this paper, we present PRAD-10K, a dataset for PR analysis.\nPRAD-10K comprises 10,000 clinical periapical radiograph images, with\npixel-level annotations provided by professional dentists for nine distinct\nanatomical structures, lesions, and artificial restorations or medical devices,\nWe also include classification labels for images with typical conditions or\nlesions. Furthermore, we introduce a DL network named PRNet to establish\nbenchmarks for PR segmentation tasks. Experimental results demonstrate that\nPRNet surpasses previous state-of-the-art medical image segmentation models on\nthe PRAD-10K dataset. The codes and dataset will be made publicly available.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-10T13:58:58Z"}
{"aid":"http://arxiv.org/abs/2504.07773v1","title":"Monitored quantum transport: full counting statistics of a quantum Hall\n  interferometer","summary":"We generalize the Levitov-Lesovik formula for the probability distribution\nfunction of the electron charge transferred through a phase coherent conductor,\nto include projective measurements that monitor the chiral propagation in\nquantum Hall edge modes. When applied to an electronic Mach-Zehnder\ninterferometer, the monitoring reduces the visibility of the Aharonov-Bohm\nconductance oscillations while preserving the binomial form of the counting\nstatistics, thereby removing a fundamental shortcoming of the dephasing-probe\nmodel of decoherence.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-10T14:12:23Z"}
{"aid":"http://arxiv.org/abs/2504.07774v1","title":"Bondi Mass, Memory Effect And Balance Law of Polyhomogeneous Spacetime","summary":"Spacetimes with metrics admitting an expansion in terms of a combination of\npowers of 1/r and ln r are known as polyhomogeneous spacetimes. The asymptotic\nbehaviour of the Newman-Penrose quantities for these spacetimes is presented\nunder certain gauges. The Bondi mass is revisited via the Iyer-Wald formalism.\nThe memory effect of the gravitational radiation in the polyhomogeneous\nspacetimes is also discussed. It is found that the appearance of the\nlogarithmic terms does not affect the balance law and it remains unchanged as\nthe one of spacetimes with metrics admitting an expansion in terms of powers of\n1/r.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-10T14:14:25Z"}
{"aid":"http://arxiv.org/abs/2504.07777v1","title":"Adaptive Detection of Fast Moving Celestial Objects Using a Mixture of\n  Experts and Physical-Inspired Neural Network","summary":"Fast moving celestial objects are characterized by velocities across the\ncelestial sphere that significantly differ from the motions of background\nstars. In observational images, these objects exhibit distinct shapes,\ncontrasting with the typical appearances of stars. Depending on the\nobservational method employed, these celestial entities may be designated as\nnear-Earth objects or asteroids. Historically, fast moving celestial objects\nhave been observed using ground-based telescopes, where the relative stability\nof stars and Earth facilitated effective image differencing techniques\nalongside traditional fast moving celestial object detection and classification\nalgorithms. However, the growing prevalence of space-based telescopes, along\nwith their diverse observational modes, produces images with different\nproperties, rendering conventional methods less effective. This paper presents\na novel algorithm for detecting fast moving celestial objects within star\nfields. Our approach enhances state-of-the-art fast moving celestial object\ndetection neural networks by transforming them into physical-inspired neural\nnetworks. These neural networks leverage the point spread function of the\ntelescope and the specific observational mode as prior information; they can\ndirectly identify moving fast moving celestial objects within star fields\nwithout requiring additional training, thereby addressing the limitations of\ntraditional techniques. Additionally, all neural networks are integrated using\nthe mixture of experts technique, forming a comprehensive fast moving celestial\nobject detection algorithm. We have evaluated our algorithm using simulated\nobservational data that mimics various observations carried out by space based\ntelescope scenarios and real observation images. Results demonstrate that our\nmethod effectively detects fast moving celestial objects across different\nobservational modes.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.EP,cs.CV,cs.LG,physics.optics","published":"2025-04-10T14:15:30Z"}
{"aid":"http://arxiv.org/abs/2504.07781v1","title":"Rydberg Superatom Interface for Topological Microwave-to-Optical Photon\n  Conversion in Fock-State Lattices","summary":"Microwave-to-optical conversion (MTOC) of single photons plays a pivotal role\nin bridging quantum devices across different frequency domains, but faces\nchallenges in maintaining efficiency and robustness against fluctuations and\ndissipation in hybrid quantum systems. Here, we propose a topologically\nprotected MTOC scheme mediated by a Rydberg superatom to address these\nlimitations. By constructing cross-linked Fock-state lattices (FSLs) through a\ndual-mode Jaynes-Cummings (JC) architecture, we map the effective hybrid system\nonto an extended Su-Schrieffer-Heeger~(SSH) model with tunable hopping rates.\nPhoton-number--dependent property of hopping rates triggers a topological phase\ntransition in the extended SSH chain, converting the defect mode into a\ntopological channel that directionally pumps photons between microwave and\noptical cavities. This mechanism leverages Rydberg blockade-enhanced\nphoton-superatom couplings to establish a robust energy transfer channel,\nachieving high-efficiency photon conversion under realistic decoherence. Our\ntheoretical framework demonstrates how topological protection synergizes with\nRydberg-mediated light-matter interactions to realize a robust quantum\ntransducer, providing a scalable platform for noise-resilient quantum networks\nand frequency-multiplexed quantum interfaces.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-10T14:20:38Z"}
{"aid":"http://arxiv.org/abs/2504.07787v1","title":"Fairness Mediator: Neutralize Stereotype Associations to Mitigate Bias\n  in Large Language Models","summary":"LLMs have demonstrated remarkable performance across diverse applications,\nyet they inadvertently absorb spurious correlations from training data, leading\nto stereotype associations between biased concepts and specific social groups.\nThese associations perpetuate and even amplify harmful social biases, raising\nsignificant fairness concerns. To mitigate such biases, prior studies have\nattempted to project model embeddings into unbiased spaces during inference.\nHowever, these approaches have shown limited effectiveness due to their weak\nalignment with downstream social biases. Inspired by the observation that\nconcept cognition in LLMs is primarily represented through a linear associative\nmemory mechanism, where key-value mapping occurs in the MLP layers, we posited\nthat biased concepts and social groups are similarly encoded as entity (key)\nand information (value) pairs, which can be manipulated to promote fairer\nassociations. To this end, we propose Fairness Mediator (FairMed), a bias\nmitigation framework that neutralizes stereotype associations. Our framework\ncomprises two main components: a stereotype association prober and an\nadversarial debiasing neutralizer. The prober captures stereotype associations\nencoded within MLP layer activations by employing prompts centered around\nbiased concepts to detect the emission probabilities for social groups.\nSubsequently, the adversarial debiasing neutralizer intervenes in MLP\nactivations during inference to equalize the association probabilities among\ndifferent social groups. Extensive experiments across nine protected attributes\nshow that FairMed significantly outperforms SOTA methods in effectiveness.\nCompared to the most effective baseline, FairMed presents competitive\nefficiency by cutting mitigation overhead by hundreds of minutes. FairMed also\nmaintains the LLM's language understanding capabilities without compromising\noverall performance.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-10T14:23:06Z"}
{"aid":"http://arxiv.org/abs/2504.07799v1","title":"Equivalence of Variants of Shadowing of Free Semigroup Actions","summary":"We prove that for finitely generated free semigroup actions the average\nshadowing property, the weak asymptotic average shadowing property, the mean\nergodic shadowing property, the almost asymptotic average shadowing property,\nthe asymptotic average shadowing property and the $M_{\\alpha}$-shadowing\nproperty for every $\\alpha\\in (0,1)$, are equivalent. This gives an affirmative\nanswer to an open question asked in Question 10.3 [M. Kulczycki, D. Kwietniak,\nP. Oprocha, On almost specification and average shadowing properties,\nFundamenta Mathematicae, 224 (2014)].","main_category":"math.DS","categories":"math.DS","published":"2025-04-10T14:37:56Z"}
{"aid":"http://arxiv.org/abs/2504.07817v1","title":"Search for the baryon and lepton number violating decay $J/ψ\\to pe^-$\n  + c.c","summary":"Based on $(2712.4\\pm 14.3) \\times 10^{6} $ ${\\psi(3686)}$ events collected by\nthe BESIII detector operating at the BEPCII storage ring, we perform a search\nfor the baryon- and lepton-number violating decay $J/\\psi \\to pe^{-}+c.c.$ via\n$\\psi(3686) \\to \\pi^{+}\\pi^{-}J/\\psi$. No significant signal is found. An upper\nlimit on the branching fraction of $\\mathcal{B}(J/\\psi \\to p e^{-}+ c.c.) < 3.1\n\\times 10^{-8}$ at 90\\% confidence level.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-10T14:54:57Z"}
{"aid":"http://arxiv.org/abs/2504.07821v1","title":"Signatures of NED on Quasi periodic Oscillations of a Magnetically\n  Charged Black Hole","summary":"In this work, we explore the influence of nonlinear electrodynamics (NED) on\nthe quasi-periodic oscillations (QPOs) of a magnetic charged black hole by\nanalyzing the motion of test particles and their epicyclic frequencies.\nStarting from the effective potential, angular momentum, and energy of circular\norbits, we examine how the NED parameter b alters the orbital dynamics. We find\nthat as b increases, the system transitions smoothly from the RN regime towards\nthe Schwarzschild profile, with observable changes in the innermost stable\ncircular orbit (ISCO) and Keplerian frequencies. We further investigate the\nvariation in the radii of QPOs with respect to the NED parameter b by employing\nthe RP, WD, and ER models. We also perform Markov Chain Monte Carlo (MCMC)\nanalysis using observational QPO data from a diverse set of black hole sources\nspanning stellar-mass, intermediate-mass, and supermassive regimes. The MCMC\nresults yield consistent constraints on the parameter b across all mass\nregimes, indicating that NED effects leave a distinguishable signature on the\nQPO structure of a charged black hole.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-10T14:58:18Z"}
{"aid":"http://arxiv.org/abs/2504.07831v1","title":"Deceptive Automated Interpretability: Language Models Coordinating to\n  Fool Oversight Systems","summary":"We demonstrate how AI agents can coordinate to deceive oversight systems\nusing automated interpretability of neural networks. Using sparse autoencoders\n(SAEs) as our experimental framework, we show that language models (Llama,\nDeepSeek R1, and Claude 3.7 Sonnet) can generate deceptive explanations that\nevade detection. Our agents employ steganographic methods to hide information\nin seemingly innocent explanations, successfully fooling oversight models while\nachieving explanation quality comparable to reference labels. We further find\nthat models can scheme to develop deceptive strategies when they believe the\ndetection of harmful features might lead to negative consequences for\nthemselves. All tested LLM agents were capable of deceiving the overseer while\nachieving high interpretability scores comparable to those of reference labels.\nWe conclude by proposing mitigation strategies, emphasizing the critical need\nfor robust understanding and defenses against deception.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-10T15:07:10Z"}
{"aid":"http://arxiv.org/abs/2504.07835v1","title":"Pychop: Emulating Low-Precision Arithmetic in Numerical Methods and\n  Neural Networks","summary":"Motivated by the growing demand for low-precision arithmetic in computational\nscience, we exploit lower-precision emulation in Python -- widely regarded as\nthe dominant programming language for numerical analysis and machine learning.\nLow-precision training has revolutionized deep learning by enabling more\nefficient computation and reduced memory and energy consumption while\nmaintaining model fidelity. To better enable numerical experimentation with and\nexploration of low precision computation, we developed the Pychop library,\nwhich supports customizable floating-point formats and a comprehensive set of\nrounding modes in Python, allowing users to benefit from fast, low-precision\nemulation in numerous applications. Pychop also introduces interfaces for both\nPyTorch and JAX, enabling efficient low-precision emulation on GPUs for neural\nnetwork training and inference with unparalleled flexibility.\n  In this paper, we offer a comprehensive exposition of the design,\nimplementation, validation, and practical application of Pychop, establishing\nit as a foundational tool for advancing efficient mixed-precision algorithms.\nFurthermore, we present empirical results on low-precision emulation for image\nclassification and object detection using published datasets, illustrating the\nsensitivity of the use of low precision and offering valuable insights into its\nimpact. Pychop enables in-depth investigations into the effects of numerical\nprecision, facilitates the development of novel hardware accelerators, and\nintegrates seamlessly into existing deep learning workflows. Software and\nexperimental code are publicly available at\nhttps://github.com/inEXASCALE/pychop.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.NA","published":"2025-04-10T15:12:29Z"}
{"aid":"http://arxiv.org/abs/2504.07841v1","title":"Anytime Single-Step MAPF Planning with Anytime PIBT","summary":"PIBT is a popular Multi-Agent Path Finding (MAPF) method at the core of many\nstate-of-the-art MAPF methods including LaCAM, CS-PIBT, and WPPL. The main\nutility of PIBT is that it is a very fast and effective single-step MAPF solver\nand can return a collision-free single-step solution for hundreds of agents in\nless than a millisecond. However, the main drawback of PIBT is that it is\nextremely greedy in respect to its priorities and thus leads to poor solution\nquality. Additionally, PIBT cannot use all the planning time that might be\navailable to it and returns the first solution it finds. We thus develop\nAnytime PIBT, which quickly finds a one-step solution identically to PIBT but\nthen continuously improves the solution in an anytime manner. We prove that\nAnytime PIBT converges to the optimal solution given sufficient time. We\nexperimentally validate that Anytime PIBT can rapidly improve single-step\nsolution quality within milliseconds and even find the optimal single-step\naction. However, we interestingly find that improving the single-step solution\nquality does not have a significant effect on full-horizon solution costs.","main_category":"cs.AI","categories":"cs.AI,cs.MA","published":"2025-04-10T15:21:23Z"}
{"aid":"http://arxiv.org/abs/2504.07845v1","title":"A Spectral Gap Absorption Principle","summary":"We show that unitary representations of simply connected, semisimple\nalgebraic groups over local fields of characteristic zero obey a spectral gap\nabsorption principle: that is, that spectral gap is preserved under tensor\nproducts. We do this by proving that the unitary dual of simple algebraic\ngroups is filtered by the integrability parameter of matrix coefficients. This\nis a filtration of closed ideals that captures every closed subset of the dual\nthat doesn't contain the trivial representation. In other words, we show that a\nrepresentation has a spectral gap if and only if there exists some $p < \\infty$\nsuch that its matrix coefficients are in $L^{p+\\epsilon}(G)$ for every\n$\\epsilon>0$. Doing this, we continue the work of Bader and Sauer in this area\nand prove a conjecture they phrased. We also use this principle to give an\naffirmative solution to a conjecture raised by Bekka and Valette: the image of\nthe restriction map from a semisimple group to a lattice is never dense in Fell\ntopology.","main_category":"math.GR","categories":"math.GR","published":"2025-04-10T15:24:44Z"}
{"aid":"http://arxiv.org/abs/2504.07853v1","title":"V2V3D: View-to-View Denoised 3D Reconstruction for Light-Field\n  Microscopy","summary":"Light field microscopy (LFM) has gained significant attention due to its\nability to capture snapshot-based, large-scale 3D fluorescence images. However,\nexisting LFM reconstruction algorithms are highly sensitive to sensor noise or\nrequire hard-to-get ground-truth annotated data for training. To address these\nchallenges, this paper introduces V2V3D, an unsupervised view2view-based\nframework that establishes a new paradigm for joint optimization of image\ndenoising and 3D reconstruction in a unified architecture. We assume that the\nLF images are derived from a consistent 3D signal, with the noise in each view\nbeing independent. This enables V2V3D to incorporate the principle of\nnoise2noise for effective denoising. To enhance the recovery of high-frequency\ndetails, we propose a novel wave-optics-based feature alignment technique,\nwhich transforms the point spread function, used for forward propagation in\nwave optics, into convolution kernels specifically designed for feature\nalignment. Moreover, we introduce an LFM dataset containing LF images and their\ncorresponding 3D intensity volumes. Extensive experiments demonstrate that our\napproach achieves high computational efficiency and outperforms the other\nstate-of-the-art methods. These advancements position V2V3D as a promising\nsolution for 3D imaging under challenging conditions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T15:29:26Z"}
{"aid":"http://arxiv.org/abs/2504.07854v1","title":"The KL3M Data Project: Copyright-Clean Training Resources for Large\n  Language Models","summary":"Practically all large language models have been pre-trained on data that is\nsubject to global uncertainty related to copyright infringement and breach of\ncontract. This creates potential risk for users and developers due to this\nuncertain legal status. The KL3M Data Project directly confronts this critical\nissue by introducing the largest comprehensive training data pipeline that\nminimizes risks related to copyright or breach of contract. The foundation of\nthis project is a corpus of over 132 million documents and trillions of tokens\nspanning 16 different sources that have been verified to meet the strict\ncopyright and licensing protocol detailed herein. We are releasing the entire\npipeline, including 1) the source code to acquire and process these documents,\n2) the original document formats with associated provenance and metadata, 3)\nextracted content in a standardized format, 4) pre-tokenized representations of\nthe documents, and 5) various mid- and post-train resources such as\nquestion-answer, summarization, conversion, drafting, classification,\nprediction, and conversational data. All of these resources are freely\navailable to the public on S3, Hugging Face, and GitHub under CC-BY terms. We\nare committed to continuing this project in furtherance of a more ethical,\nlegal, and sustainable approach to the development and use of AI models.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-10T15:31:17Z"}
{"aid":"http://arxiv.org/abs/2504.07855v1","title":"Foreign Signal Radar","summary":"We introduce a new machine learning approach to detect value-relevant foreign\ninformation for both domestic and multinational companies. Candidate foreign\nsignals include lagged returns of stock markets and individual stocks across 47\nforeign markets. By training over 100,000 models, we capture stock-specific,\ntime-varying relationships between foreign signals and U.S. stock returns.\nForeign signals exhibit out-of-sample return predictability for a subset of\nU.S. stocks across domestic and multinational companies. Valuable foreign\nsignals are not concentrated in those largest foreign markets nor foreign firms\nin the same industry as U.S. firms. Signal importance analysis reveals the\nprice discovery of foreign information is significantly slower for information\nfrom emerging and low-media-coverage markets and among stocks with lower\nforeign institutional ownership but is accelerated during the COVID-19 crisis.\nOur study suggests that machine learning-based investment strategies leveraging\nforeign signals can emerge as important mechanisms to improve the market\nefficiency of foreign information.","main_category":"q-fin.PR","categories":"q-fin.PR","published":"2025-04-10T15:31:35Z"}
{"aid":"http://arxiv.org/abs/2504.07857v1","title":"$B$ meson semileptonic decays from lattice QCD","summary":"$B$ processes are a rich source of potential anomalies that could lead to the\ndiscovery of BSM physics. The long-standing tension between the inclusive and\nthe exclusive determinations of the CKM matrix elements $|V_{xb}|$, or the\ncurrent tensions in the $R(D)$-$R(D^\\ast)$ plane are some examples of active\nareas of research where we might find signals of new physics. Heavy-to-heavy\n$B$ semileptonic decays, $B_{(s)}\\to D^{(\\ast)}_{(s)}\\ell\\nu$, and in\nparticular, decays with a vector product ($D^\\ast_{(s)}$) are especially\ninteresting from an experimental point of view, but experiment and theory must\nwalk together in order to reach conclusions in the intensity frontier. In this\nreview I talk about the current status of the lattice-QCD calculations of the\n$B\\to D^{\\ast}\\ell\\nu$ form factors at non-zero recoil, I discuss the\nimplications they have for the determination of $B$ anomalies, and finally I\ngive some hints of what we can expect from future calculations.","main_category":"hep-ph","categories":"hep-ph,hep-lat","published":"2025-04-10T15:32:23Z"}
{"aid":"http://arxiv.org/abs/2504.07859v1","title":"Conversion-Driven Freeze-Out: A Common Framework for Dark Matter and\n  Baryogenesis","summary":"We explore dark matter genesis beyond the WIMP paradigm, focusing on the\nmechanism of conversion-driven freeze-out. This mechanism enables the\nthermalization of dark matter despite its very weak couplings. While the\nscenario evades conventional WIMP searches, it predicts novel signatures of\nlong-lived particles at colliders, making it a prime target for upcoming LHC\nsearches. We review various model realizations of this mechanism, highlighting\nits deep connections to other unresolved problems of the Standard Model. In\nparticular, we show how conversion-driven freeze-out can naturally give rise to\nbaryogenesis, offering a compelling perspective on the origins of both dark and\nbaryonic matter.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-10T15:35:53Z"}
{"aid":"http://arxiv.org/abs/2504.07870v1","title":"Open Datasets for Grid Modeling and Visualization: An Alberta Power\n  Network Case","summary":"In the power and energy industry, multiple entities in grid operational logs\nare frequently recorded and updated. Thanks to recent advances in IT facilities\nand smart metering services, a variety of datasets such as system load,\ngeneration mix, and grid connection are often publicly available. While these\nresources are valuable in evaluating power grid's operational conditions and\nsystem resilience, the lack of fine-grained, accurate locational information\nconstrain the usage of current data, which further hinders the development of\nsmart grid and renewables integration. For instance, electricity end users are\nnot aware of nodal generation mix or carbon emissions, while the general public\nhave limited understanding about the effect of demand response or renewables\nintegration if only the whole system's demands and generations are available.\nIn this work, we focus on recovering power grid topology and line flow\ndirections from open public dataset. Taking the Alberta grid as a working\nexample, we start from mapping multi-modal power system datasets to the grid\ntopology integrated with geographical information. By designing a novel\noptimization-based scheme to recover line flow directions, we are able to\nanalyze and visualize the interactions between generations and demand vectors\nin an efficient manner. Proposed research is fully open-sourced and highly\ngeneralizable, which can help model and visualize grid information, create\nsynthetic dataset, and facilitate analytics and decision-making framework for\nclean energy transition.","main_category":"cs.HC","categories":"cs.HC,cs.SY,eess.SP,eess.SY","published":"2025-04-10T15:45:07Z"}
{"aid":"http://arxiv.org/abs/2504.07873v1","title":"Spectral Periodic Differential Operators of Odd Order","summary":"In this paper, we establish a condition on the coefficients of the\ndifferential operators L generated by an ordinary differential expression of\nodd order with periodic, complex-valued coefficients, under which the operator\nL is a spectral operator.","main_category":"math.SP","categories":"math.SP","published":"2025-04-10T15:46:53Z"}
{"aid":"http://arxiv.org/abs/2504.07874v1","title":"Power Operations on $K(n-1)$-Localized Morava $E$-theory at Height $n$","summary":"We calculate the $K(n-1)$-localized $E_n$ theory for symmetric groups, and\ndeduce a modular interpretation of the total power operation $\\psi^p_F$ on\n$F=L_{K(n-1)}E_n$ in terms of augmented deformations of formal groups and their\nsubgroups. We compute the Dyer-Lashof algebra structure over $K(n-1)$-local\n$E_n$-algebra. Then we specify our calculation to the $n=2$ case. We calculate\nan explicit formula for $\\psi^p_F$ using the formula of $\\psi^p_E$, and explain\nconnections between these computations and elliptic curves, modular forms and\n$p$-divisible groups.","main_category":"math.AT","categories":"math.AT","published":"2025-04-10T15:47:31Z"}
{"aid":"http://arxiv.org/abs/2504.07881v1","title":"An LLM-Driven Multi-Agent Debate System for Mendelian Diseases","summary":"Accurate diagnosis of Mendelian diseases is crucial for precision therapy and\nassistance in preimplantation genetic diagnosis. However, existing methods\noften fall short of clinical standards or depend on extensive datasets to build\npretrained machine learning models. To address this, we introduce an innovative\nLLM-Driven multi-agent debate system (MD2GPS) with natural language\nexplanations of the diagnostic results. It utilizes a language model to\ntransform results from data-driven and knowledge-driven agents into natural\nlanguage, then fostering a debate between these two specialized agents. This\nsystem has been tested on 1,185 samples across four independent datasets,\nenhancing the TOP1 accuracy from 42.9% to 66% on average. Additionally, in a\nchallenging cohort of 72 cases, MD2GPS identified potential pathogenic genes in\n12 patients, reducing the diagnostic time by 90%. The methods within each\nmodule of this multi-agent debate system are also replaceable, facilitating its\nadaptation for diagnosing and researching other complex diseases.","main_category":"q-bio.GN","categories":"q-bio.GN","published":"2025-04-10T15:55:34Z"}
{"aid":"http://arxiv.org/abs/2504.07898v1","title":"How do Large Language Models Understand Relevance? A Mechanistic\n  Interpretability Perspective","summary":"Recent studies have shown that large language models (LLMs) can assess\nrelevance and support information retrieval (IR) tasks such as document ranking\nand relevance judgment generation. However, the internal mechanisms by which\noff-the-shelf LLMs understand and operationalize relevance remain largely\nunexplored. In this paper, we systematically investigate how different LLM\nmodules contribute to relevance judgment through the lens of mechanistic\ninterpretability. Using activation patching techniques, we analyze the roles of\nvarious model components and identify a multi-stage, progressive process in\ngenerating either pointwise or pairwise relevance judgment. Specifically, LLMs\nfirst extract query and document information in the early layers, then process\nrelevance information according to instructions in the middle layers, and\nfinally utilize specific attention heads in the later layers to generate\nrelevance judgments in the required format. Our findings provide insights into\nthe mechanisms underlying relevance assessment in LLMs, offering valuable\nimplications for future research on leveraging LLMs for IR tasks.","main_category":"cs.IR","categories":"cs.IR,cs.CL,cs.LG","published":"2025-04-10T16:14:55Z"}
{"aid":"http://arxiv.org/abs/2504.07904v1","title":"The Efficacy of Semantics-Preserving Transformations in Self-Supervised\n  Learning for Medical Ultrasound","summary":"Data augmentation is a central component of joint embedding self-supervised\nlearning (SSL). Approaches that work for natural images may not always be\neffective in medical imaging tasks. This study systematically investigated the\nimpact of data augmentation and preprocessing strategies in SSL for lung\nultrasound. Three data augmentation pipelines were assessed: (1) a baseline\npipeline commonly used across imaging domains, (2) a novel semantic-preserving\npipeline designed for ultrasound, and (3) a distilled set of the most effective\ntransformations from both pipelines. Pretrained models were evaluated on\nmultiple classification tasks: B-line detection, pleural effusion detection,\nand COVID-19 classification. Experiments revealed that semantics-preserving\ndata augmentation resulted in the greatest performance for COVID-19\nclassification - a diagnostic task requiring global image context.\nCropping-based methods yielded the greatest performance on the B-line and\npleural effusion object classification tasks, which require strong local\npattern recognition. Lastly, semantics-preserving ultrasound image\npreprocessing resulted in increased downstream performance for multiple tasks.\nGuidance regarding data augmentation and preprocessing strategies was\nsynthesized for practitioners working with SSL in ultrasound.","main_category":"eess.IV","categories":"eess.IV,cs.CV,cs.LG","published":"2025-04-10T16:26:47Z"}
{"aid":"http://arxiv.org/abs/2504.07915v1","title":"Detecting changes in space-varying parameters of local Poisson point\n  processes","summary":"Recent advances in local models for point processes have highlighted the need\nfor flexible methodologies to account for the spatial heterogeneity of external\ncovariates influencing process intensity. In this work, we introduce\ntessellated spatial regression, a novel framework that extends segmented\nregression models to spatial point processes, with the aim of detecting abrupt\nchanges in the effect of external covariates onto the process intensity.\n  Our approach consists of two main steps. First, we apply a spatial\nsegmentation algorithm to geographically weighted regression estimates,\ngenerating different tessellations that partition the study area into regions\nwhere model parameters can be assumed constant. Next, we fit log-linear Poisson\nmodels in which covariates interact with the tessellations, enabling\nregion-specific parameter estimation and classical inferential procedures, such\nas hypothesis testing on regression coefficients.\n  Unlike geographically weighted regression, our approach allows for discrete\nchanges in regression coefficients, making it possible to capture abrupt\nspatial variations in the effect of real-valued spatial covariates.\nFurthermore, the method naturally addresses the problem of locating and\nquantifying the number of detected spatial changes.\n  We validate our methodology through simulation studies and applications to\ntwo examples where a model with region-wise parameters seems appropriate and to\nan environmental dataset of earthquake occurrences in Greece.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-10T17:23:32Z"}
{"aid":"http://arxiv.org/abs/2504.07927v1","title":"Zero-Shot Low-dose CT Denoising via Sinogram Flicking","summary":"Many low-dose CT imaging methods rely on supervised learning, which requires\na large number of paired noisy and clean images. However, obtaining paired\nimages in clinical practice is challenging. To address this issue, zero-shot\nself-supervised methods train denoising networks using only the information\nwithin a single image, such as ZS-N2N. However, these methods often employ\ndownsampling operations that degrade image resolution. Additionally, the\ntraining dataset is inherently constrained to the image itself. In this paper,\nwe propose a zero-shot low-dose CT imaging method based on sinogram flicking,\nwhich operates within a single image but generates many copies via random\nconjugate ray matching. Specifically, two conjugate X-ray pencil beams measure\nthe same path; their expected values should be identical, while their noise\nlevels vary during measurements. By randomly swapping portions of the conjugate\nX-rays in the sinogram domain, we generate a large set of sinograms with\nconsistent content but varying noise patterns. When displayed dynamically,\nthese sinograms exhibit a flickering effect due to their identical structural\ncontent but differing noise patterns-hence the term sinogram flicking. We train\nthe network on pairs of sinograms with the same content but different noise\ndistributions using a lightweight model adapted from ZS-NSN. This process is\nrepeated to obtain the final results. A simulation study demonstrates that our\nmethod outperforms state-of-the-art approaches such as ZS-N2N.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-10T17:42:01Z"}
{"aid":"http://arxiv.org/abs/2504.07934v1","title":"SoTA with Less: MCTS-Guided Sample Selection for Data-Efficient Visual\n  Reasoning Self-Improvement","summary":"In this paper, we present an effective method to enhance visual reasoning\nwith significantly fewer training samples, relying purely on self-improvement\nwith no knowledge distillation. Our key insight is that the difficulty of\ntraining data during reinforcement fine-tuning (RFT) is critical. Appropriately\nchallenging samples can substantially boost reasoning capabilities even when\nthe dataset is small. Despite being intuitive, the main challenge remains in\naccurately quantifying sample difficulty to enable effective data filtering. To\nthis end, we propose a novel way of repurposing Monte Carlo Tree Search (MCTS)\nto achieve that. Starting from our curated 70k open-source training samples, we\nintroduce an MCTS-based selection method that quantifies sample difficulty\nbased on the number of iterations required by the VLMs to solve each problem.\nThis explicit step-by-step reasoning in MCTS enforces the model to think longer\nand better identifies samples that are genuinely challenging. We filter and\nretain 11k samples to perform RFT on Qwen2.5-VL-7B-Instruct, resulting in our\nfinal model, ThinkLite-VL. Evaluation results on eight benchmarks show that\nThinkLite-VL improves the average performance of Qwen2.5-VL-7B-Instruct by 7%,\nusing only 11k training samples with no knowledge distillation. This\nsignificantly outperforms all existing 7B-level reasoning VLMs, and our fairly\ncomparable baselines that use classic selection methods such as accuracy-based\nfiltering. Notably, on MathVista, ThinkLite-VL-7B achieves the SoTA accuracy of\n75.1, surpassing Qwen2.5-VL-72B, GPT-4o, and O1. Our code, data, and model are\navailable at https://github.com/si0wang/ThinkLite-VL.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:49:05Z"}
{"aid":"http://arxiv.org/abs/2504.07939v1","title":"Echo: An Open-Source, Low-Cost Teleoperation System with Force Feedback\n  for Dataset Collection in Robot Learning","summary":"In this article, we propose Echo, a novel joint-matching teleoperation system\ndesigned to enhance the collection of datasets for manual and bimanual tasks.\nOur system is specifically tailored for controlling the UR manipulator and\nfeatures a custom controller with force feedback and adjustable sensitivity\nmodes, enabling precise and intuitive operation. Additionally, Echo integrates\na user-friendly dataset recording interface, simplifying the process of\ncollecting high-quality training data for imitation learning. The system is\ndesigned to be reliable, cost-effective, and easily reproducible, making it an\naccessible tool for researchers, laboratories, and startups passionate about\nadvancing robotics through imitation learning. Although the current\nimplementation focuses on the UR manipulator, Echo architecture is\nreconfigurable and can be adapted to other manipulators and humanoid systems.\nWe demonstrate the effectiveness of Echo through a series of experiments,\nshowcasing its ability to perform complex bimanual tasks and its potential to\naccelerate research in the field. We provide assembly instructions, a hardware\ndescription, and code at https://eterwait.github.io/Echo/.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-10T17:51:37Z"}
{"aid":"http://arxiv.org/abs/2504.07940v1","title":"Beyond the Frame: Generating 360° Panoramic Videos from Perspective\n  Videos","summary":"360{\\deg} videos have emerged as a promising medium to represent our dynamic\nvisual world. Compared to the \"tunnel vision\" of standard cameras, their\nborderless field of view offers a more complete perspective of our\nsurroundings. While existing video models excel at producing standard videos,\ntheir ability to generate full panoramic videos remains elusive. In this paper,\nwe investigate the task of video-to-360{\\deg} generation: given a perspective\nvideo as input, our goal is to generate a full panoramic video that is\nconsistent with the original video. Unlike conventional video generation tasks,\nthe output's field of view is significantly larger, and the model is required\nto have a deep understanding of both the spatial layout of the scene and the\ndynamics of objects to maintain spatio-temporal consistency. To address these\nchallenges, we first leverage the abundant 360{\\deg} videos available online\nand develop a high-quality data filtering pipeline to curate pairwise training\ndata. We then carefully design a series of geometry- and motion-aware\noperations to facilitate the learning process and improve the quality of\n360{\\deg} video generation. Experimental results demonstrate that our model can\ngenerate realistic and coherent 360{\\deg} videos from in-the-wild perspective\nvideo. In addition, we showcase its potential applications, including video\nstabilization, camera viewpoint control, and interactive visual question\nanswering.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:51:38Z"}
{"aid":"http://arxiv.org/abs/2504.07946v1","title":"Characteristic function-based tests for spatial randomness","summary":"We introduce a new type of test for complete spatial randomness that applies\nto mapped point patterns in a rectangle or a cube of any dimension. This is the\nfirst test of its kind to be based on characteristic functions and utilizes a\nweighted L2-distance between the empirical and uniform characteristic\nfunctions. It is simple to calculate and does not require adjusting for edge\neffects. An efficient algorithm is developed to find the asymptotic null\ndistribution of the test statistic under the Cauchy weight function. In a\nsimulation, our test shows varying sensitivity to different levels of spatial\ninteraction depending on the scale parameter of the Cauchy weight function.\nTests with different parameter values can be combined to create a\nBonferroni-corrected omnibus test, which is almost always more powerful than\nthe popular L-test and the Clark-Evans test for detecting heterogeneous and\naggregated alternatives, although less powerful than the L-test for detecting\nregular alternatives. The simplicity of empirical characteristic function makes\nit straightforward to extend our test to non-rectangular or sparsely sampled\npoint patterns.","main_category":"stat.ME","categories":"stat.ME,stat.CO","published":"2025-04-10T17:54:11Z"}
{"aid":"http://arxiv.org/abs/2504.07959v1","title":"CCMNet: Leveraging Calibrated Color Correction Matrices for Cross-Camera\n  Color Constancy","summary":"Computational color constancy, or white balancing, is a key module in a\ncamera's image signal processor (ISP) that corrects color casts from scene\nlighting. Because this operation occurs in the camera-specific raw color space,\nwhite balance algorithms must adapt to different cameras. This paper introduces\na learning-based method for cross-camera color constancy that generalizes to\nnew cameras without retraining. Our method leverages pre-calibrated color\ncorrection matrices (CCMs) available on ISPs that map the camera's raw color\nspace to a standard space (e.g., CIE XYZ). Our method uses these CCMs to\ntransform predefined illumination colors (i.e., along the Planckian locus) into\nthe test camera's raw space. The mapped illuminants are encoded into a compact\ncamera fingerprint embedding (CFE) that enables the network to adapt to unseen\ncameras. To prevent overfitting due to limited cameras and CCMs during\ntraining, we introduce a data augmentation technique that interpolates between\ncameras and their CCMs. Experimental results across multiple datasets and\nbackbones show that our method achieves state-of-the-art cross-camera color\nconstancy while remaining lightweight and relying only on data readily\navailable in camera ISPs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:59:31Z"}
{"aid":"http://arxiv.org/abs/2504.07961v1","title":"Geo4D: Leveraging Video Generators for Geometric 4D Scene Reconstruction","summary":"We introduce Geo4D, a method to repurpose video diffusion models for\nmonocular 3D reconstruction of dynamic scenes. By leveraging the strong dynamic\nprior captured by such video models, Geo4D can be trained using only synthetic\ndata while generalizing well to real data in a zero-shot manner. Geo4D predicts\nseveral complementary geometric modalities, namely point, depth, and ray maps.\nIt uses a new multi-modal alignment algorithm to align and fuse these\nmodalities, as well as multiple sliding windows, at inference time, thus\nobtaining robust and accurate 4D reconstruction of long videos. Extensive\nexperiments across multiple benchmarks show that Geo4D significantly surpasses\nstate-of-the-art video depth estimation methods, including recent methods such\nas MonST3R, which are also designed to handle dynamic scenes.","main_category":"cs.CV","categories":"cs.CV,I.4.5","published":"2025-04-10T17:59:55Z"}
{"aid":"http://arxiv.org/abs/2504.07965v1","title":"Cat, Rat, Meow: On the Alignment of Language Model and Human\n  Term-Similarity Judgments","summary":"Small and mid-sized generative language models have gained increasing\nattention. Their size and availability make them amenable to being analyzed at\na behavioral as well as a representational level, allowing investigations of\nhow these levels interact. We evaluate 32 publicly available language models\nfor their representational and behavioral alignment with human similarity\njudgments on a word triplet task. This provides a novel evaluation setting to\nprobe semantic associations in language beyond common pairwise comparisons. We\nfind that (1) even the representations of small language models can achieve\nhuman-level alignment, (2) instruction-tuned model variants can exhibit\nsubstantially increased agreement, (3) the pattern of alignment across layers\nis highly model dependent, and (4) alignment based on models' behavioral\nresponses is highly dependent on model size, matching their representational\nalignment only for the largest evaluated models.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-10T17:59:57Z"}
