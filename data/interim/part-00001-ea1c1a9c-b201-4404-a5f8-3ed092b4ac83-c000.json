{"aid":"http://arxiv.org/abs/2503.21662v1","title":"Electronic structure dimensionality of the quantum-critical ferromagnet\n  YbNi$_4$P$_2$","summary":"YbNi$_4$P$_2$ is the first known ferromagnetic metal showing a second-order\nquantum phase transition. Current theoretical understanding rules out second\norder ferromagnetic quantum criticality in centrosymmetric 2D and 3D metals.\nThus, studying the electronic structure of YbNi$_4$P$_2$ is of prime\nfundamental importance. Using angle-resolved photoemission spectroscopy, we\nexperimentally prove the existence of 1D Fermi surface contours. In addition,\nour results demonstrate that part of the electronic structure of YbNi$_4$P$_2$\nis made of states of higher dimensionality, thereby bringing into question the\nfact that ferromagnetic quantum criticality in centrosymmetric crystals, is\nexclusively found in 1D systems. Our experimental data show that the electronic\nstructure of YbNi$_4$P$_2$ is a playground of mixed dimensionality, electron\ncorrelations, strong hybridization and spin-orbit coupling, all of them\nproviding new insights in understanding the origin of ferromagnetic quantum\ncriticality.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci,quant-ph","published":"2025-03-27T16:27:42Z"}
{"aid":"http://arxiv.org/abs/2503.21672v1","title":"The Avoider-Enforcer game on hypergraphs of rank 3","summary":"In the Avoider-Enforcer convention of positional games, two players, Avoider\nand Enforcer, take turns selecting vertices from a hypergraph H. Enforcer wins\nif, by the time all vertices of H have been selected, Avoider has completely\nfilled an edge of H with her vertices; otherwise, Avoider wins. In this paper,\nwe first give some general results, in particular regarding the outcome of the\ngame and disjoint unions of hypergraphs. We then determine which player has a\nwinning strategy for all hypergraphs of rank 2, and for linear hypergraphs of\nrank 3 when Avoider plays the last move. The structural characterisations we\nobtain yield polynomial-time algorithms.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-03-27T16:40:37Z"}
{"aid":"http://arxiv.org/abs/2503.21673v1","title":"A friendly introduction to triangular transport","summary":"Decision making under uncertainty is a cross-cutting challenge in science and\nengineering. Most approaches to this challenge employ probabilistic\nrepresentations of uncertainty. In complicated systems accessible only via data\nor black-box models, however, these representations are rarely known. We\ndiscuss how to characterize and manipulate such representations using\ntriangular transport maps, which approximate any complex probability\ndistribution as a transformation of a simple, well-understood distribution. The\nparticular structure of triangular transport guarantees many desirable\nmathematical and computational properties that translate well into solving\npractical problems. Triangular maps are actively used for density estimation,\n(conditional) generative modelling, Bayesian inference, data assimilation,\noptimal experimental design, and related tasks. While there is ample literature\non the development and theory of triangular transport methods, this manuscript\nprovides a detailed introduction for scientists interested in employing measure\ntransport without assuming a formal mathematical background. We build intuition\nfor the key foundations of triangular transport, discuss many aspects of its\npractical implementation, and outline the frontiers of this field.","main_category":"stat.CO","categories":"stat.CO,physics.ao-ph,stat.ME,stat.ML","published":"2025-03-27T16:41:14Z"}
{"aid":"http://arxiv.org/abs/2503.21674v1","title":"Intelligent IoT Attack Detection Design via ODLLM with Feature\n  Ranking-based Knowledge Base","summary":"The widespread adoption of Internet of Things (IoT) devices has introduced\nsignificant cybersecurity challenges, particularly with the increasing\nfrequency and sophistication of Distributed Denial of Service (DDoS) attacks.\nTraditional machine learning (ML) techniques often fall short in detecting such\nattacks due to the complexity of blended and evolving patterns. To address\nthis, we propose a novel framework leveraging On-Device Large Language Models\n(ODLLMs) augmented with fine-tuning and knowledge base (KB) integration for\nintelligent IoT network attack detection. By implementing feature ranking\ntechniques and constructing both long and short KBs tailored to model\ncapacities, the proposed framework ensures efficient and accurate detection of\nDDoS attacks while overcoming computational and privacy limitations. Simulation\nresults demonstrate that the optimized framework achieves superior accuracy\nacross diverse attack types, especially when using compact models in edge\ncomputing environments. This work provides a scalable and secure solution for\nreal-time IoT security, advancing the applicability of edge intelligence in\ncybersecurity.","main_category":"cs.CR","categories":"cs.CR,cs.AI,cs.NI","published":"2025-03-27T16:41:57Z"}
{"aid":"http://arxiv.org/abs/2503.21684v1","title":"Decorated phases in triblock copolymers: zeroth- and first-order\n  analysis","summary":"We study a two-dimensional inhibitory ternary system characterized by a free\nenergy functional which combines an interface short-range interaction energy\npromoting micro-domain growth with a Coulomb-type long-range interaction energy\nwhich prevents micro-domains from unlimited spreading. Here we consider a\nscenario in which two species are dominant and one species is vanishingly\nsmall. In this scenario two energy levels are distinguished: the zeroth-order\nenergy encodes information on the optimal arrangement of the dominant\nconstituents, while the first-order energy gives the shape of the vanishing\nconstituent. This first-order energy also shows that, for any optimal\nconfiguration, the vanishing phase must lie on the boundary between the two\ndominant constituents and form lens clusters also known as vesica piscis.","main_category":"math.AP","categories":"math.AP","published":"2025-03-27T16:52:27Z"}
{"aid":"http://arxiv.org/abs/2503.21694v1","title":"Progressive Rendering Distillation: Adapting Stable Diffusion for\n  Instant Text-to-Mesh Generation without 3D Data","summary":"It is highly desirable to obtain a model that can generate high-quality 3D\nmeshes from text prompts in just seconds. While recent attempts have adapted\npre-trained text-to-image diffusion models, such as Stable Diffusion (SD), into\ngenerators of 3D representations (e.g., Triplane), they often suffer from poor\nquality due to the lack of sufficient high-quality 3D training data. Aiming at\novercoming the data shortage, we propose a novel training scheme, termed as\nProgressive Rendering Distillation (PRD), eliminating the need for 3D\nground-truths by distilling multi-view diffusion models and adapting SD into a\nnative 3D generator. In each iteration of training, PRD uses the U-Net to\nprogressively denoise the latent from random noise for a few steps, and in each\nstep it decodes the denoised latent into 3D output. Multi-view diffusion\nmodels, including MVDream and RichDreamer, are used in joint with SD to distill\ntext-consistent textures and geometries into the 3D outputs through score\ndistillation. Since PRD supports training without 3D ground-truths, we can\neasily scale up the training data and improve generation quality for\nchallenging text prompts with creative concepts. Meanwhile, PRD can accelerate\nthe inference speed of the generation model in just a few steps. With PRD, we\ntrain a Triplane generator, namely TriplaneTurbo, which adds only $2.5\\%$\ntrainable parameters to adapt SD for Triplane generation. TriplaneTurbo\noutperforms previous text-to-3D generators in both efficiency and quality.\nSpecifically, it can produce high-quality 3D meshes in 1.2 seconds and\ngeneralize well for challenging text input. The code is available at\nhttps://github.com/theEricMa/TriplaneTurbo.","main_category":"cs.GR","categories":"cs.GR,cs.AI,cs.CV","published":"2025-03-27T16:59:15Z"}
{"aid":"http://arxiv.org/abs/2503.21727v1","title":"Enhancing Underwater Navigation through Cross-Correlation-Aware Deep\n  INS/DVL Fusion","summary":"The accurate navigation of autonomous underwater vehicles critically depends\non the precision of Doppler velocity log (DVL) velocity measurements. Recent\nadvancements in deep learning have demonstrated significant potential in\nimproving DVL outputs by leveraging spatiotemporal dependencies across multiple\nsensor modalities. However, integrating these estimates into model-based\nfilters, such as the extended Kalman filter, introduces statistical\ninconsistencies, most notably, cross-correlations between process and\nmeasurement noise. This paper addresses this challenge by proposing a\ncross-correlation-aware deep INS/DVL fusion framework. Building upon BeamsNet,\na convolutional neural network designed to estimate AUV velocity using DVL and\ninertial data, we integrate its output into a navigation filter that explicitly\naccounts for the cross-correlation induced between the noise sources. This\napproach improves filter consistency and better reflects the underlying sensor\nerror structure. Evaluated on two real-world underwater trajectories, the\nproposed method outperforms both least squares and cross-correlation-neglecting\napproaches in terms of state uncertainty. Notably, improvements exceed 10% in\nvelocity and misalignment angle confidence metrics. Beyond demonstrating\nempirical performance, this framework provides a theoretically principled\nmechanism for embedding deep learning outputs within stochastic filters.","main_category":"cs.RO","categories":"cs.RO","published":"2025-03-27T17:38:43Z"}
{"aid":"http://arxiv.org/abs/2503.21736v1","title":"Local Primordial non-Gaussian Bias from Time Evolution","summary":"Primordial non-Gaussianity (PNG) is a signature of fundamental physics in the\nearly universe that is probed by cosmological observations. It is well known\nthat the local type of PNG generates a strong signal in the two-point function\nof large-scale structure tracers, such as galaxies. This signal, often termed\n``scale-dependent bias'' is a generic feature of modulation of gravitational\nstructure formation by a large-scale mode. It is less well-appreciated that the\ncoefficient controlling this signal, $b_{\\phi}$, is closely connected to the\ntime evolution of the tracer number density. This correspondence between time\nevolution and local PNG can be simply explained for a universal tracer whose\nmass function only depends on peak height, and more generally for non-universal\ntracers in the separate universe picture, which we validate in simulations. We\nalso describe how to recover the bias of tracers subject to a survey selection\nfunction, and perform a simple demonstration on simulated galaxies. Since the\nlocal PNG amplitude in $n-$point statistics ($f_{\\rm NL}$) is largely\ndegenerate with the coefficient $b_{\\phi}$, this proof of concept study\ndemonstrates that galaxy survey data can allow for more optimal and robust\nextraction of local PNG information from upcoming surveys.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-03-27T17:49:31Z"}
{"aid":"http://arxiv.org/abs/2503.21746v1","title":"Effects of dissipation on phase diagram and bosonic excitations in the\n  quark-meson model","summary":"In this work we study the quark-meson model within a real-time formulation of\nthe functional renormalization group (FRG) on the Schwinger-Keldysh contour.\nFirst, we discuss in detail the symmetry of thermal equilibrium for the\nfermionic sector of the Keldysh action. We take into account dissipation for\nthe bosonic degrees of freedom in the spirit of the Caldeira-Leggett model by\ncoupling the system to an $O(4)$ invariant external heat bath. We study the\neffect of dissipation on static equilibrium properties, most prominently on the\nFRG flow of the effective potential and thus on the resulting phase diagram. We\nfind that, unlike in classical systems, through the contributions from non-zero\nMatsubara modes the dissipative dynamics can in general have an effect on\nstatic observables. We investigate these effects within two phenomenological\nmodels for the temperature dependence of the pion damping to verify that they\nare quantitatively small. To estimate their largest possible influence, we\nconsider limits where the damping constants approach infinity.","main_category":"hep-ph","categories":"hep-ph","published":"2025-03-27T17:53:22Z"}
{"aid":"http://arxiv.org/abs/2503.21749v1","title":"LeX-Art: Rethinking Text Generation via Scalable High-Quality Data\n  Synthesis","summary":"We introduce LeX-Art, a comprehensive suite for high-quality text-image\nsynthesis that systematically bridges the gap between prompt expressiveness and\ntext rendering fidelity. Our approach follows a data-centric paradigm,\nconstructing a high-quality data synthesis pipeline based on Deepseek-R1 to\ncurate LeX-10K, a dataset of 10K high-resolution, aesthetically refined\n1024$\\times$1024 images. Beyond dataset construction, we develop LeX-Enhancer,\na robust prompt enrichment model, and train two text-to-image models, LeX-FLUX\nand LeX-Lumina, achieving state-of-the-art text rendering performance. To\nsystematically evaluate visual text generation, we introduce LeX-Bench, a\nbenchmark that assesses fidelity, aesthetics, and alignment, complemented by\nPairwise Normalized Edit Distance (PNED), a novel metric for robust text\naccuracy evaluation. Experiments demonstrate significant improvements, with\nLeX-Lumina achieving a 79.81% PNED gain on CreateBench, and LeX-FLUX\noutperforming baselines in color (+3.18%), positional (+4.45%), and font\naccuracy (+3.81%). Our codes, models, datasets, and demo are publicly\navailable.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:56:15Z"}
{"aid":"http://arxiv.org/abs/2503.21752v1","title":"Hypergraphic zonotopes and acyclohedra","summary":"We introduce a higher-uniformity analogue of graphic zonotopes and\npermutohedra. Specifically, given a $(d+1)$-uniform hypergraph $H$, we define\nits hypergraphic zonotope $\\mathcal{Z}_H$, and when $H$ is the complete\n$(d+1)$-uniform hypergraph $K^{(d+1)}_n$, we call its hypergraphic zonotope the\nacyclohedron $\\mathcal{A}_{n,d}$.\n  We express the volume of $\\mathcal{Z}_H$ as a homologically weighted count of\nthe spanning $d$-dimensional hypertrees of $H$, which is closely related to\nKalai's generalization of Cayley's theorem in the case when $H=K^{(d+1)}_n$\n(but which, curiously, is not the same). We also relate the vertices of\nhypergraphic zonotopes to a notion of acyclic orientations previously studied\nby Linial and Morganstern for complete hypergraphs.","main_category":"math.CO","categories":"math.CO","published":"2025-03-27T17:56:42Z"}
{"aid":"http://arxiv.org/abs/2503.23700v1","title":"Dual-band Unified Exploration of Three CMZ Clouds (DUET). Cloud-wide\n  census of continuum sources showing low spectral indices","summary":"The Milky Way's Central Molecular Zone (CMZ) is measured to form stars 10\ntimes less efficiently than in the Galactic disk, based on emission from\nhigh-mass stars. However, the CMZ's low-mass protostellar population, which\naccounts for most of the initial stellar mass budget and star formation rate\n(SFR), is poorly constrained observationally due to limited sensitivity and\nresolution. We present the Dual-band Unified Exploration of Three CMZ Clouds\n(DUET) survey, targeting the 20 km/s Cloud, Sgr C, and Dust Ridge cloud e using\nthe Atacama Large Millimeter/submillimeter Array (ALMA) at 1.3 and 3 mm. The\nmosaicked observations achieve a comparable resolution of 0.2-0.3\" (~1600-2500\nau) and a sky coverage of 8.3-10.4 square arcmin, respectively. We report 563\ncontinuum sources at 1.3 mm and 330 at 3 mm, respectively, and a dual-band\ncatalog with 450 continuum sources. These sources are marginally resolved at\nthe 2,000 au resolution. We find a cloud-wide deviation (>70%) from\ncommonly-used dust modified blackbody (MBB) models, characterized by either low\nspectral indices or low brightness temperatures. Three possible explanations\nfor the deviation are discussed. (1) Optically thick Class 0/I Young stellar\nobjects (YSOs) with very small beam filling factors can lead to lower\nbrightness temperatures than what MBB models predict. (2) Large (mm/cm-sized)\ndust grains have more significant self-scattering, and therefore\nfrequency-dependent albedo could cause lower spectral indices. (3) Free-free\nemission over 30 uJy can severely contaminate dust emission and cause low\nspectral indices for mJy sources in our sample, although the needed number of\nmassive protostars (embedded UCHII regions) is infeasibly high for the normal\nstellar initial mass function. A reliable measurement of the SFR at low\nprotostellar masses will require future work to distinguish between these\npossible explanations.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-03-31T03:56:43Z"}
{"aid":"http://arxiv.org/abs/2503.23723v1","title":"Undecidable problems associated with variational quantum algorithms","summary":"Variational Quantum Algorithms (VQAs), such as the Variational Quantum\nEigensolver (VQE) and the Quantum Approximate Optimization Algorithm (QAOA),\nare widely studied as candidates for near-term quantum advantage. Recent work\nhas shown that training VQAs is NP-hard in general. In this paper, we present a\nconditional result suggesting that the training of VQAs is undecidable, even in\nidealized, noiseless settings. We reduce the decision version of the digitized\nVQA training problem-where circuit parameters are drawn from a discrete set-to\nthe question of whether a universal Diophantine equation (UDE) has a root. This\nreduction relies on encoding the UDE into the structure of a variational\nquantum circuit via the matrix exponentials. The central step involves\nestablishing a correspondence between the objective function of the VQA and a\nknown UDE of 58 variables and degree 4. Our main result is conditional on a\nnatural conjecture: that a certain system of structured complex polynomial\nequations-arising from the inner product of a VQA circuit output and a fixed\nobservable-has at least one solution. We argue this conjecture is plausible\nbased on dimension-counting arguments (degrees of freedom in the Hamiltonians,\nstate vector, and observable), and the generic solvability of such systems in\nalgebraic geometry over the complex numbers. Under this assumption, we suggest\nthat deciding whether a digitized VQA achieves a given energy threshold is\nundecidable. This links the limitations of variational quantum algorithms to\nfoundational questions in mathematics and logic, extending the known landscape\nof quantum computational hardness to include uncomputability. Additionally, we\nestablish an unconditional undecidability result for VQA convergence in open\nquantum systems.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T04:52:43Z"}
{"aid":"http://arxiv.org/abs/2503.23748v1","title":"THEMIS: Towards Practical Intellectual Property Protection for\n  Post-Deployment On-Device Deep Learning Models","summary":"On-device deep learning (DL) has rapidly gained adoption in mobile apps,\noffering the benefits of offline model inference and user privacy preservation\nover cloud-based approaches. However, it inevitably stores models on user\ndevices, introducing new vulnerabilities, particularly model-stealing attacks\nand intellectual property infringement. While system-level protections like\nTrusted Execution Environments (TEEs) provide a robust solution, practical\nchallenges remain in achieving scalable on-device DL model protection,\nincluding complexities in supporting third-party models and limited adoption in\ncurrent mobile solutions. Advancements in TEE-enabled hardware, such as\nNVIDIA's GPU-based TEEs, may address these obstacles in the future. Currently,\nwatermarking serves as a common defense against model theft but also faces\nchallenges here as many mobile app developers lack corresponding machine\nlearning expertise and the inherent read-only and inference-only nature of\non-device DL models prevents third parties like app stores from implementing\nexisting watermarking techniques in post-deployment models.\n  To protect the intellectual property of on-device DL models, in this paper,\nwe propose THEMIS, an automatic tool that lifts the read-only restriction of\non-device DL models by reconstructing their writable counterparts and leverages\nthe untrainable nature of on-device DL models to solve watermark parameters and\nprotect the model owner's intellectual property. Extensive experimental results\nacross various datasets and model structures show the superiority of THEMIS in\nterms of different metrics. Further, an empirical investigation of 403\nreal-world DL mobile apps from Google Play is performed with a success rate of\n81.14%, showing the practicality of THEMIS.","main_category":"cs.CR","categories":"cs.CR,cs.LG,cs.SE","published":"2025-03-31T05:58:57Z"}
{"aid":"http://arxiv.org/abs/2503.23749v1","title":"Lower semicontinuity of bounded property in the branching problem and\n  sphericity of flag variety","summary":"Vinberg--Kimel'fel'd [Funct. Anal. Appl., 1978] established that a\nquasi-projective normal $G$-variety $X$ is spherical if and only if $G$-modules\non the spaces $\\Gamma(X, \\mathcal{L})$ of global sections of $G$-equivariant\nline bundles are multiplicity-free. This result was generalized by\nKobayashi--Oshima [Adv. Math., 2013] and several researchers to (degenerate)\nprincipal series representations of reductive Lie groups. The purpose of this\nshort article is to show that the boundedness of the multiplicities in the\nrestrictions of cohomologically induced modules implies the sphericity of some\npartial flag variety.\n  In our previous paper, we reduce the boundedness of the multiplicities to the\nfiniteness of a ring-theoretic invariant $\\mathrm{PIdeg}$. To show the main\nresult, we discuss the lower semicontinuity of $\\mathrm{PIdeg}$ on the space\n$\\mathrm{Prim}(\\mathcal{U}(\\mathfrak{g}))$ of primitive ideals. We also treat\nthe finiteness of the lengths of the restrictions of cohomologically induced\nmodules.","main_category":"math.RT","categories":"math.RT","published":"2025-03-31T06:01:51Z"}
{"aid":"http://arxiv.org/abs/2503.23755v1","title":"Large-scale quantum-dot-lithium-niobate hybrid integrated photonic\n  circuits enabling on-chip quantum networking","summary":"Hybrid integrated quantum photonics combines solid-state artificial atoms\nwith reconfigurable photonic circuits, enabling scalable chip-based quantum\nnetworks. Self-assembled quantum dots (QDs) are ideal for this goal due to\ntheir ability to generate highly indistinguishable single photons with\nexceptional brightness. Integrating QDs into low-loss photonic circuits can\nfacilitate complex quantum networks by enabling entanglement transfer via\ntwo-photon interference. However, challenges such as limited scalability,\nspectral inhomogeneity, and quantum interference between independent sources\nremain. We present a hybrid photonic architecture that integrates QD-containing\nwaveguides with low-loss lithium niobate (LN) circuits, incorporating 20\ndeterministic single-photon sources (SPSs). Using the piezoelectric properties\nof thin-film lithium niobate (TFLN), we achieve on-chip local spectral tuning\nof QD emissions by up to 7.7 meV,three orders of magnitude greater than the\ntransform-limited linewidth. This approach enables on-chip quantum interference\nwith a visibility of 0.73 between two spatially separated QD SPSs connected by\n0.48 mm long waveguides, establishing a functional quantum network.The\nlarge-scale integration of spectrally tunable QD-based SPSs into low-loss LN\ncircuits, combined with fast electro-optical switching, paves the way for\ncompact, lightweight, and scalable photonic quantum networks.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T06:10:44Z"}
{"aid":"http://arxiv.org/abs/2503.23781v1","title":"DebFlow: Automating Agent Creation via Agent Debate","summary":"Large language models (LLMs) have demonstrated strong potential and\nimpressive performance in automating the generation and optimization of\nworkflows. However, existing approaches are marked by limited reasoning\ncapabilities, high computational demands, and significant resource\nrequirements. To address these issues, we propose DebFlow, a framework that\nemploys a debate mechanism to optimize workflows and integrates reflexion to\nimprove based on previous experiences. We evaluated our method across six\nbenchmark datasets, including HotpotQA, MATH, and ALFWorld. Our approach\nachieved a 3\\% average performance improvement over the latest baselines,\ndemonstrating its effectiveness in diverse problem domains. In particular,\nduring training, our framework reduces resource consumption by 37\\% compared to\nthe state-of-the-art baselines. Additionally, we performed ablation studies.\nRemoving the Debate component resulted in a 4\\% performance drop across two\nbenchmark datasets, significantly greater than the 2\\% drop observed when the\nReflection component was removed. These findings strongly demonstrate the\ncritical role of Debate in enhancing framework performance, while also\nhighlighting the auxiliary contribution of reflexion to overall optimization.","main_category":"cs.AI","categories":"cs.AI","published":"2025-03-31T06:56:13Z"}
{"aid":"http://arxiv.org/abs/2503.23784v1","title":"Sample-based subsampling strategies to identify microplastics in the\n  presence of a high number of particles using quantum-cascade laser-based\n  infrared imaging","summary":"Microplastics (MPs) are ubiquitous in all ecosystems, affecting wildlife and,\nultimately, human health. The complexity of natural samples plus the\nunspecificity of their treatments to isolate polymers renders the\ncharacterization of thousands of particles impractical for environmental\nmonitoring using conventional spectroscopic techniques. Two primary solutions\nare to analyze a small fraction of the sample or to measure only a subset of\nparticles present over a holder, known as subsampling. A strategy to subsample\nreflective Kevley slides and gold-coated filters using quantum-cascade\nlaser-based infrared imaging is proposed here, as this technology is a\npromising tool for MPs monitoring. In contrast to most previous approaches that\nstruggle to propose general subsampling schemes, we introduce the concept of\nsample-based subsampling. This can be applied ex-ante always and it highlights\nthe best subsampling areas for a sample after a preliminary assay to count the\ntotal number of particles on a holder. The error at this stage acts as a proxy\nto minimize errors when evaluating the number of particles and MPs,\nsignificantly enhancing the feasibility of large-scale MPs monitoring. The\npredictive ability of the approach was tested for fibres and fragments, for\ntotal amounts of particles and MPs. Further, the evaluations were disaggregated\nby size and polymer type. In most situations the reference values were\ncontained in the confidence intervals of the predicted values (often within the\n68 % ones) and relative errors were lower than 25 %. Exceptions occurred when\nvery scarce (one or two) items of a given size or polymer were present on the\noverall holder. The approach was compared to other systematic ad-hoc\nstrategies.","main_category":"physics.ins-det","categories":"physics.ins-det","published":"2025-03-31T07:02:04Z"}
{"aid":"http://arxiv.org/abs/2503.23795v1","title":"Trajectory Planning for Automated Driving using Target Funnels","summary":"Self-driving vehicles rely on sensory input to monitor their surroundings and\ncontinuously adapt to the most likely future road course. Predictive trajectory\nplanning is based on snapshots of the (uncertain) road course as a key input.\nUnder noisy perception data, estimates of the road course can vary\nsignificantly, leading to indecisive and erratic steering behavior. To overcome\nthis issue, this paper introduces a predictive trajectory planning algorithm\nwith a novel objective function: instead of targeting a single reference\ntrajectory based on the most likely road course, tracking a series of target\nreference sets, called a target funnel, is considered. The proposed planning\nalgorithm integrates probabilistic information about the road course, and thus\nimplicitly considers regular updates to road perception. Our solution is\nassessed in a case study using real driving data collected from a prototype\nvehicle. The results demonstrate that the algorithm maintains tracking accuracy\nand substantially reduces undesirable steering commands in the presence of\nnoisy road perception, achieving a 56% reduction in input costs compared to a\ncertainty equivalent formulation.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-03-31T07:15:55Z"}
{"aid":"http://arxiv.org/abs/2503.23820v1","title":"When Counterfactual Reasoning Fails: Chaos and Real-World Complexity","summary":"Counterfactual reasoning, a cornerstone of human cognition and\ndecision-making, is often seen as the 'holy grail' of causal learning, with\napplications ranging from interpreting machine learning models to promoting\nalgorithmic fairness. While counterfactual reasoning has been extensively\nstudied in contexts where the underlying causal model is well-defined,\nreal-world causal modeling is often hindered by model and parameter\nuncertainty, observational noise, and chaotic behavior. The reliability of\ncounterfactual analysis in such settings remains largely unexplored. In this\nwork, we investigate the limitations of counterfactual reasoning within the\nframework of Structural Causal Models. Specifically, we empirically investigate\n\\emph{counterfactual sequence estimation} and highlight cases where it becomes\nincreasingly unreliable. We find that realistic assumptions, such as low\ndegrees of model uncertainty or chaotic dynamics, can result in\ncounterintuitive outcomes, including dramatic deviations between predicted and\ntrue counterfactual trajectories. This work urges caution when applying\ncounterfactual reasoning in settings characterized by chaos and uncertainty.\nFurthermore, it raises the question of whether certain systems may pose\nfundamental limitations on the ability to answer counterfactual questions about\ntheir behavior.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-03-31T08:14:51Z"}
{"aid":"http://arxiv.org/abs/2503.23836v1","title":"Gradient catastrophe and Peregrine soliton in nonlinear flexible\n  mechanical metamaterials","summary":"We explore the generation of extreme wave events in mechanical metamaterials\nusing the regularization of the gradient catastrophe theory developed by A.\nTovbis and M. Bertola for the nonlinear Schr\\\"odinger equation. According to\nthis theory, Peregrine solitons can locally emerge in the semiclassical limit\nof the nonlinear Schr\\\"odinger equation. Our objective is to determine whether\nthe phenomenon of gradient catastrophe can occur in a class of architected\nstructures designated as flexible mechanical metamaterials, both with and\nwithout losses. We demonstrate theoretically and numerically that this\nphenomenon can occur in a canonical example of such flexible mechanical\nmetamaterial, a chain of rotating units, studied earlier for its ability to\nsupport robust nonlinear waves such as elastic vector solitons. We find that in\nthe presence of weak losses, the gradient catastrophe persists although the\namplitude of extreme generated events is smaller and their onset is delayed\ncompared to the lossless configuration.","main_category":"nlin.PS","categories":"nlin.PS,physics.class-ph","published":"2025-03-31T08:31:15Z"}
{"aid":"http://arxiv.org/abs/2503.23860v1","title":"The Kossakowski Matrix and Strict Positivity of Markovian Quantum\n  Dynamics","summary":"We investigate the relationship between strict positivity of the Kossakowski\nmatrix, irreducibility and positivity improvement properties of Markovian\nQuantum Dynamics. We show that for a Gaussian quantum dynamical semigroup\nstrict positivity of the Kossakowski matrix implies irreducibility and, with an\nadditional technical assumption, that the support of any initial state is the\nwhole space for any positive time.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T09:07:26Z"}
{"aid":"http://arxiv.org/abs/2503.23863v1","title":"GRACEFUL: A Learned Cost Estimator For UDFs","summary":"User-Defined-Functions (UDFs) are a pivotal feature in modern DBMS, enabling\nthe extension of native DBMS functionality with custom logic. However, the\nintegration of UDFs into query optimization processes poses significant\nchallenges, primarily due to the difficulty of estimating UDF execution costs.\nConsequently, existing cost models in DBMS optimizers largely ignore UDFs or\nrely on static assumptions, resulting in suboptimal performance for queries\ninvolving UDFs. In this paper, we introduce GRACEFUL, a novel learned cost\nmodel to make accurate cost predictions of query plans with UDFs enabling\noptimization decisions for UDFs in DBMS. For example, as we show in our\nevaluation, using our cost model, we can achieve 50x speedups through informed\npull-up/push-down filter decisions of the UDF compared to the standard case\nwhere always a filter push-down is applied. Additionally, we release a\nsynthetic dataset of over 90,000 UDF queries to promote further research in\nthis area.","main_category":"cs.DB","categories":"cs.DB","published":"2025-03-31T09:09:12Z"}
{"aid":"http://arxiv.org/abs/2503.23872v1","title":"European Strategy for Particle Physics 2026: the NA60+/DiCE experiment\n  at the SPS","summary":"The exploration of the phase diagram of Quantum ChromoDynamics (QCD) is\ncarried out by studying ultrarelativistic heavy-ion collisions. The energy\nrange covered by the CERN SPS ($\\sqrt{s_{\\rm {NN}}} \\sim 6-17$ GeV) is ideal\nfor the investigation of the region corresponding to finite baryochemical\npotential ($\\mu_{\\rm B}$), and was little explored up to now. We propose in\nthis document a new experiment, NA60+/DiCE (Dilepton and Charm Experiment),\nthat will address several observables which are fundamental for the\nunderstanding of the phase transition from hadronic matter towards a\nQuark-Gluon Plasma (QGP) at finite $\\mu_B$. In particular, we propose to study,\nin Pb-Pb collisions, as a function of the collision energy, the production of\nthermal dimuons, from which one can obtain a caloric curve of the QCD phase\ndiagram that may be sensitive to the order of the phase transition. In\naddition, the measurement of a $\\rho-{\\rm a}_1$ mixing contribution will\nprovide conclusive insights into the restoration of the chiral symmetry of QCD.\nStudies of open charm and charmonium production will also be carried out,\naddressing the measurement of transport properties of the QGP and the\ninvestigation of the onset of the deconfinement transition. Reference\nmeasurements with proton-nucleus collisions are an essential part of this\nprogram. The experimental set-up couples a vertex telescope based on monolithic\nactive pixel sensors (MAPS) to a muon spectrometer with MWPC detectors. Two\nexisting CERN dipole magnets, MEP48 and MNP33, will be used for the vertex and\nmuon spectrometers, respectively. The continuing availability of Pb ion beams\nin the CERN SPS is a crucial requirement for the experimental program. After\nthe submission of a LoI, the experiment proposal is currently in preparation\nand is due by mid 2025. The start of the data taking is foreseen by 2029/2030,\nand should last about 7 years.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-03-31T09:23:01Z"}
{"aid":"http://arxiv.org/abs/2503.23887v1","title":"An End-to-End Comprehensive Gear Fault Diagnosis Method Based on\n  Multi-Scale Feature-Level Fusion Strategy","summary":"To satisfy the requirements of the end-to-end fault diagnosis of gears, an\nintegrated intelligent method of fault diagnosis for gears using acceleration\nsignals was proposed, which was based on Gabor-based Adaptive Short-Time\nFourier Transform (Gabor-ASTFT) and Dual-Tree Complex Wavelet Transform(DTCWT)\nalgorithms, Dilated Residual structure and feature fusion layer, is proposed in\nthis paper. Initially, the raw one-dimensional acceleration signals collected\nfrom the gearbox base using vibration sensors undergo pre-segmentation\nprocessing. The Gabor-ASTFT and DTCWT are then applied to convert the original\none-dimensional time-domain signals into two-dimensional time-frequency\nrepresentations, facilitating the preliminary extraction of fault features and\nobtaining weak feature maps.Subsequently, a dual-channel structure is\nestablished using deconvolution and dilated convolution to perform upsampling\nand downsampling on the feature maps, adjusting their sizes accordingly. A\nfeature fusion layer is then constructed to integrate the dual-channel\nfeatures, enabling multi-scale analysis of the extracted fault\nfeatures.Finally, a convolutional neural network (CNN) model incorporating a\nresidual structure is developed to conduct deep feature extraction from the\nfused feature maps. The extracted features are subsequently fed into a Global\nAverage Pooling(GAP) and a classification function for fault classification.\nConducting comparative experiments on different datasets, the proposed method\nis demonstrated to effectively meet the requirements of end-to-end fault\ndiagnosis for gears.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T09:40:06Z"}
{"aid":"http://arxiv.org/abs/2503.23920v1","title":"Semileptonic baryon decays $Ξ_b\\rightarrow Ξ_c \\ell^- \\barν_\\ell\n  $ in perturbative QCD","summary":"We perform a detailed analysis of the semileptonic $\\Xi_b\\rightarrow \\Xi_c\n\\ell^- \\bar{\\nu}_\\ell$ decays within the perturbative QCD (PQCD) framework. In\nour study, the $\\Xi_b\\rightarrow \\Xi_c$ transition form factors are calculated\nusing several popular models for baryonic light-cone distribution amplitudes\n(LCDAs). These form factors are then employed to analyze a range of observable\nquantities for the semileptonic processes via the helicity formalism. Our work\npresents predictions for the branching fractions of these decays for both the\n$\\tau$ and $e$ channels. Notably, the obtained lepton flavor universality\nratio, $\\mathcal{R}_{\\Xi_c}\\approx 0.3$, may offer new insights into the\n$\\mathcal{R}^{(*)}$ puzzle. Furthermore, we investigate various angular\nobservables, such as forward-backward asymmetries, lepton-side convexity\nparameters, and polarization asymmetries, which provide complementary\ninformation regarding potential new physics in $b$-baryonic semileptonic\ntransitions. The numerical results for these angular observables are presented\nas both functions of $q^2$ and as averaged values. We observe that the lepton\nmass plays a significant role in shaping the angular distributions, affecting\nmost of the observables under consideration. These results are expected to be\nvaluable for both current and future experimental investigations of\nsemileptonic heavy-to-heavy baryon decays.","main_category":"hep-ph","categories":"hep-ph","published":"2025-03-31T10:10:31Z"}
{"aid":"http://arxiv.org/abs/2503.23954v1","title":"Exclusion of a diquark-antidiquark structure for the lightest\n  positive-parity charmed mesons","summary":"The nature of low-lying scalar and axial-vector charmed mesons has been\ndebated for decades, with hadronic molecular and compact tetraquark models\nbeing prominent candidates. These two models predict quite different features\nfor the accessible SU(3) multiplets in the scalar and axial-vector sectors,\nwhich can be tested through lattice calculations at SU(3) symmetric points. In\nthis work, we perform lattice calculations for both scalar and axial-vector\ncharmed mesons with an SU(3) symmetric pion mass about 613 MeV for the SU(3)\n$[6]$ and $[\\overline{15}]$ multiplets. We find that the $[6]$ multiplet\nexhibits attractive interactions in both scalar and axial-vector sectors, while\nthe $[\\overline{15}]$ multiplet shows repulsive interactions in both sectors.\nThe energy shifts in the scalar and axial-vector sectors are compatible with\neach other within uncertainties. These results are fully consistent with the\nhadronic molecular picture, while challenging the compact tetraquark model,\nwhich predicts the existence of low-lying $[\\overline{15}]$ states in the\naxial-vector sector but not in the scalar sector.","main_category":"hep-lat","categories":"hep-lat,hep-ph","published":"2025-03-31T11:12:29Z"}
{"aid":"http://arxiv.org/abs/2503.23968v1","title":"Total Cartier index of a bounded family","summary":"We prove that the total Cartier index of a bounded family of projective\nvarieties of klt type is bounded.","main_category":"math.AG","categories":"math.AG","published":"2025-03-31T11:33:38Z"}
{"aid":"http://arxiv.org/abs/2503.23981v1","title":"Federated Structured Sparse PCA for Anomaly Detection in IoT Networks","summary":"Although federated learning has gained prominence as a privacy-preserving\nframework tailored for distributed Internet of Things (IoT) environments,\ncurrent federated principal component analysis (PCA) methods lack integration\nof sparsity, a critical feature for robust anomaly detection. To address this\nlimitation, we propose a novel federated structured sparse PCA (FedSSP)\napproach for anomaly detection in IoT networks. The proposed model uniquely\nintegrates double sparsity regularization: (1) row-wise sparsity governed by\n$\\ell_{2,p}$-norm with $p\\in[0,1)$ to eliminate redundant feature dimensions,\nand (2) element-wise sparsity via $\\ell_{q}$-norm with $q\\in[0,1)$ to suppress\nnoise-sensitive components. To efficiently solve this non-convex optimization\nproblem in a distributed setting, we devise a proximal alternating minimization\n(PAM) algorithm with rigorous theoretical proofs establishing its convergence\nguarantees. Experiments on real datasets validate that incorporating structured\nsparsity enhances both model interpretability and detection accuracy.","main_category":"cs.LG","categories":"cs.LG,math.OC","published":"2025-03-31T11:50:21Z"}
{"aid":"http://arxiv.org/abs/2503.23982v1","title":"Deep Nets as Hamiltonians","summary":"Neural networks are complex functions of both their inputs and parameters.\nMuch prior work in deep learning theory analyzes the distribution of network\noutputs at a fixed a set of inputs (e.g. a training dataset) over random\ninitializations of the network parameters. The purpose of this article is to\nconsider the opposite situation: we view a randomly initialized Multi-Layer\nPerceptron (MLP) as a Hamiltonian over its inputs. For typical realizations of\nthe network parameters, we study the properties of the energy landscape induced\nby this Hamiltonian, focusing on the structure of near-global minimum in the\nlimit of infinite width. Specifically, we use the replica trick to perform an\nexact analytic calculation giving the entropy (log volume of space) at a given\nenergy. We further derive saddle point equations that describe the overlaps\nbetween inputs sampled iid from the Gibbs distribution induced by the random\nMLP. For linear activations we solve these saddle point equations exactly. But\nwe also solve them numerically for a variety of depths and activation\nfunctions, including $\\tanh, \\sin, \\text{ReLU}$, and shaped non-linearities. We\nfind even at infinite width a rich range of behaviors. For some\nnon-linearities, such as $\\sin$, for instance, we find that the landscapes of\nrandom MLPs exhibit full replica symmetry breaking, while shallow $\\tanh$ and\nReLU networks or deep shaped MLPs are instead replica symmetric.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.stat-mech,cs.AI,cs.LG,math.PR","published":"2025-03-31T11:51:10Z"}
{"aid":"http://arxiv.org/abs/2503.23986v1","title":"A Practical Rollup Escape Hatch Design","summary":"A rollup network is a type of popular \"Layer 2\" scaling solution for general\npurpose \"Layer 1\" blockchains like Ethereum. Rollups networks separate\nexecution of transactions from other aspects like consensus, processing\ntransactions off of the Layer 1, and posting the data onto the underlying layer\nfor security. While rollups offer significant scalability advantages, they\noften rely on centralized operators for transaction ordering and inclusion,\nwhich also introduces potential risks. If the operator fails to build rollup\nblocks or propose new state roots to the underlying Layer 1, users may lose\naccess to digital assets on the rollup. An escape hatch allows users to bypass\nthe failing operator and withdraw assets directly on the Layer 1. We propose\nusing a time-based trigger, Merkle proofs, and new resolver contracts to\nimplement a practical escape hatch for these networks. The use of novel\nresolver contracts allow user owned assets to be located in the Layer 2 state\nroot, including those owned by smart contracts, in order to allow users to\nescape them. This design ensures safe and verifiable escape of assets,\nincluding ETH, ERC-20 and ERC-721 tokens, and more, from the Layer 2.","main_category":"cs.DC","categories":"cs.DC,cs.CR","published":"2025-03-31T11:55:10Z"}
{"aid":"http://arxiv.org/abs/2503.23990v1","title":"BeMERC: Behavior-Aware MLLM-based Framework for Multimodal Emotion\n  Recognition in Conversation","summary":"Multimodal emotion recognition in conversation (MERC), the task of\nidentifying the emotion label for each utterance in a conversation, is vital\nfor developing empathetic machines. Current MLLM-based MERC studies focus\nmainly on capturing the speaker's textual or vocal characteristics, but ignore\nthe significance of video-derived behavior information. Different from text and\naudio inputs, learning videos with rich facial expression, body language and\nposture, provides emotion trigger signals to the models for more accurate\nemotion predictions. In this paper, we propose a novel behavior-aware\nMLLM-based framework (BeMERC) to incorporate speaker's behaviors, including\nsubtle facial micro-expression, body language and posture, into a vanilla\nMLLM-based MERC model, thereby facilitating the modeling of emotional dynamics\nduring a conversation. Furthermore, BeMERC adopts a two-stage instruction\ntuning strategy to extend the model to the conversations scenario for\nend-to-end training of a MERC predictor. Experiments demonstrate that BeMERC\nachieves superior performance than the state-of-the-art methods on two\nbenchmark datasets, and also provides a detailed discussion on the significance\nof video-derived behavior information in MERC.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T12:04:53Z"}
{"aid":"http://arxiv.org/abs/2503.24001v1","title":"Convergence of a finite volume scheme for a model for ants","summary":"We develop and analyse a finite volume scheme for a nonlocal active matter\nsystem known to exhibit a rich array of complex behaviours. The model under\ninvestigation was derived from a stochastic system of interacting particles\ndescribing a foraging ant colony coupled to pheromone dynamics. In this work,\nwe prove that the unique numerical solution converges to the unique weak\nsolution as the mesh size and the time step go to zero. We also show discrete\nlong-time estimates, which prove that certain norms are preserved for all\ntimes, uniformly in the mesh size and time step. In particular, we prove higher\nregularity estimates which provide an analogue of continuum parabolic higher\nregularity estimates. Finally, we numerically study the rate of convergence of\nthe scheme, and we provide examples of the existence of multiple metastable\nsteady states.","main_category":"math.NA","categories":"math.NA,cs.NA,math.AP","published":"2025-03-31T12:23:49Z"}
{"aid":"http://arxiv.org/abs/2503.24028v1","title":"Pay More Attention to the Robustness of Prompt for Instruction Data\n  Mining","summary":"Instruction tuning has emerged as a paramount method for tailoring the\nbehaviors of LLMs. Recent work has unveiled the potential for LLMs to achieve\nhigh performance through fine-tuning with a limited quantity of high-quality\ninstruction data. Building upon this approach, we further explore the impact of\nprompt's robustness on the selection of high-quality instruction data. This\npaper proposes a pioneering framework of high-quality online instruction data\nmining for instruction tuning, focusing on the impact of prompt's robustness on\nthe data mining process. Our notable innovation, is to generate the adversarial\ninstruction data by conducting the attack for the prompt of online instruction\ndata. Then, we introduce an Adversarial Instruction-Following Difficulty metric\nto measure how much help the adversarial instruction data can provide to the\ngeneration of the corresponding response. Apart from it, we propose a novel\nAdversarial Instruction Output Embedding Consistency approach to select\nhigh-quality online instruction data. We conduct extensive experiments on two\nbenchmark datasets to assess the performance. The experimental results serve to\nunderscore the effectiveness of our proposed two methods. Moreover, the results\nunderscore the critical practical significance of considering prompt's\nrobustness.","main_category":"cs.AI","categories":"cs.AI","published":"2025-03-31T12:53:08Z"}
{"aid":"http://arxiv.org/abs/2503.24034v1","title":"Creation of a black hole bomb instability in an electromagnetic system","summary":"The amplification and generation of electromagnetic radiation by a rotating\nmetallic or lossy cylinder, first theorized by Zeldovich in the 1970s, is\ntightly connected to the concepts of quantum friction, energy extraction from\nrotating black holes and runaway mechanisms such as black hole bombs. Despite\nrecent advances including acoustic analogues of the Zeldovich effect and the\nobservation of a negative resistance in a low-frequency electromagnetic model,\nactual positive signal amplitude gain, the spontaneous generation of\nelectromagnetic waves and runaway amplifi- cation effects have never been\nexperimentally verified. Here, we demonstrate experimentally that a\nmechanically rotating metallic cylinder not only definitively acts as an\namplifier of a rotating elec- tromagnetic field mode but also, when paired with\na low-loss resonator, becomes unstable and acts as a generator, seeded only by\nnoise. The system exhibits an exponential runaway amplification of\nspontaneously generated electromagnetic modes thus demonstrating the\nelectromagnetic analogue of Press and Teukolskys black hole bomb. The\nexponential amplification from noise supports theoretical investigations into\nblack hole instabilities and is promising for the development of future\nexperiments to observe quantum friction in the form of the Zeldovich effect\nseeded by the quantum vacuum.","main_category":"quant-ph","categories":"quant-ph,physics.app-ph,physics.ins-det","published":"2025-03-31T13:00:10Z"}
{"aid":"http://arxiv.org/abs/2503.24051v1","title":"Practical Quantum Advantage for Boosting Citations","summary":"Realizing practical quantum advantage with meaningful economic impact is the\nholy grail of the quantum information field. Recent quantum technology advances\nhave driven exponential growth in quantum information research, with resultant\npublications achieving significantly elevated impact. Within academia, citation\ncounts serve as a key metric for evaluating research impact, often directly\ninfluencing career advancement and compensation structures. Motivated by these\nobservations, we propose a potential protocol for practical quantum advantage\nin boosting citations.","main_category":"physics.pop-ph","categories":"physics.pop-ph,quant-ph","published":"2025-03-31T13:13:48Z"}
{"aid":"http://arxiv.org/abs/2503.24058v1","title":"Mechanical Squeezed Kerr Oscillator based on Tapered Ion Trap","summary":"We propose the realization of a mechanically squeezed Kerr oscillator with a\nsingle ion in a tapered trap. We show that the motion coupling between the\naxial and radial modes caused by the trap geometry leads to Kerr nonlinearity\nof the radial mode with magnitude controlled by the trap frequencies. This\nallows the realization of non-Gaussian quantum gates, which play a significant\nrole in the universal set of continuous variable quantum gates. Furthermore, we\nshow that, because of the nonlinearity of the ion trap, applying an\noff-resonant time-varying electric field along the trap axis causes a motion\nsqueezing of the radial mode. Finally, we discuss the motion mode frequency\nspectrum of an ion crystal in a tapered trap. We show that the frequency gap\nbetween the motion modes increases with trap nonlinearity, which benefits the\nrealization of faster quantum gates.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T13:19:09Z"}
{"aid":"http://arxiv.org/abs/2503.24068v1","title":"A Quantum Energy Inequality for a Non-commutative QFT","summary":"We establish a quantum energy inequality (QEI) for a quantum field theory\nformulated in a non-commutative spacetime. This inequality provides a\nfundamental bound on the expectation values of the energy density, ensuring the\nstability and physical consistency of the theory.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-03-31T13:27:12Z"}
{"aid":"http://arxiv.org/abs/2503.24072v1","title":"Estimation of thermal properties and boundary heat transfer coefficient\n  of the ground with a Bayesian technique","summary":"Urbanization is the key contributor for climate change. Increasing\nurbanization rate causes an urban heat island (UHI) effect, which strongly\ndepends on the short- and long-wave radiation balance heat flux between the\nsurfaces. In order to calculate accurately this heat flux, it is required to\nassess the surface temperature which depends on the knowledge of the thermal\nproperties and the surface heat transfer coefficients in the heat transfer\nproblem. The aim of this paper is to estimate the thermal properties of the\nground and the time varying surface heat transfer coefficient by solving an\ninverse problem. The Dufort--Frankel scheme is applied for solving the unsteady\nheat transfer problem. For the inverse problem, a Markov chain Monte Carlo\nmethod is used to estimate the posterior probability density function of\nunknown parameters within the Bayesian framework of statistics, by applying the\nMetropolis-Hastings algorithm for random sample generation. Actual temperature\nmeasurements available at different ground depths were used for the solution of\nthe inverse problem. Different time discretizations were examined for the\ntransient heat transfer coefficient at the ground surface, which then involved\ndifferent prior distributions. Results of different case studies show that the\nestimated values of the unknown parameters were in accordance with literature\nvalues. Moreover, with the present solution of the inverse problem the\ntemperature residuals were smaller than those obtained by using literature\nvalues for the unknowns.","main_category":"cs.CE","categories":"cs.CE,math-ph,math.MP,G.3","published":"2025-03-31T13:29:25Z"}
{"aid":"http://arxiv.org/abs/2503.24083v1","title":"Controlled Latent Diffusion Models for 3D Porous Media Reconstruction","summary":"Three-dimensional digital reconstruction of porous media presents a\nfundamental challenge in geoscience, requiring simultaneous resolution of\nfine-scale pore structures while capturing representative elementary volumes.\nWe introduce a computational framework that addresses this challenge through\nlatent diffusion models operating within the EDM framework. Our approach\nreduces dimensionality via a custom variational autoencoder trained in binary\ngeological volumes, improving efficiency and also enabling the generation of\nlarger volumes than previously possible with diffusion models. A key innovation\nis our controlled unconditional sampling methodology, which enhances\ndistribution coverage by first sampling target statistics from their empirical\ndistributions, then generating samples conditioned on these values. Extensive\ntesting on four distinct rock types demonstrates that conditioning on porosity\n- a readily computable statistic - is sufficient to ensure a consistent\nrepresentation of multiple complex properties, including permeability,\ntwo-point correlation functions, and pore size distributions. The framework\nachieves better generation quality than pixel-space diffusion while enabling\nsignificantly larger volume reconstruction (256-cube voxels) with substantially\nreduced computational requirements, establishing a new state-of-the-art for\ndigital rock physics applications.","main_category":"physics.geo-ph","categories":"physics.geo-ph,cs.LG","published":"2025-03-31T13:36:55Z"}
{"aid":"http://arxiv.org/abs/2503.24095v1","title":"Threats and Opportunities in AI-generated Images for Armed Forces","summary":"Images of war are almost as old as war itself. From cave paintings to\nphotographs of mobile devices on social media, humans always had the urge to\ncapture particularly important events during a war. Images provide visual\nevidence. For armed forces, they may serve as the output of a sensor (e.g. in\naerial reconnaissance) or as an effector on cognition (e.g. in form of\nphotographic propaganda). They can inform, influence, or even manipulate a\ntarget audience. The recent advancements in the field of generative Artificial\nIntelligence (AI) to synthesize photorealistic images give rise to several new\nchallenges for armed forces. The objective of this report is to investigate the\nrole of AI-generated images for armed forces and provide an overview on\nopportunities and threats. When compared with traditional image generation\n(e.g. photography), generative AI brings distinct conceptual advantages to\nimplement new tactical tenets and concepts which so far have not been feasible:\nmasses of AI-generated images can be used for deceptive purposes, to influence\nthe pace of combat in the information environment, to cause surprise, sow\nconfusion and shock. AI-generated images are a tool favoured for offensive\nmanoeuvres in the information environment. To prepare for future challenges\ninvolving AI-generated images and improve their resilience, recommendations are\ngiven at the end of the report for all branches of the armed forces, who are\nactive in cyber defense and/or exposed to the information environment.","main_category":"cs.CY","categories":"cs.CY","published":"2025-03-31T13:46:02Z"}
{"aid":"http://arxiv.org/abs/2503.24104v1","title":"Application of Battery Storage to Switching Predictive Control of Power\n  Distribution Systems Including Road Heating","summary":"A road heating system is an electrical device which promotes snow melting by\nburying a heating cable as a thermal source underground. When integrating road\nheating into the power distribution system, we need to optimize the flow of\nelectric power by appropriately integrating distributed power sources and\nconventional power distribution equipment. In this paper, we extend the power\ndistribution system considered in the authors' previous study to the case where\nbattery storage is installed. As a main result, we propose a predictive\nswitching control that achieves the reduction of distribution loss, attenuation\nof voltage fluctuation, and efficient snow melting, simultaneously. We verify\nthe effectiveness of the application of battery storage through numerical\nsimulation.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-03-31T13:57:04Z"}
{"aid":"http://arxiv.org/abs/2503.24113v1","title":"From Local to Remote: VisIVO Visual Analytics in the Era of the Square\n  Kilometre Array","summary":"The field of astrophysics is continuously advancing, with an ever-growing\ninflux of data requiring robust and efficient analysis tools. As the Square\nKilometre Array (SKA) radio telescopes come fully operational, we anticipate\nthe generation of hundreds of petabytes of data annually, characterized by\nunprecedented resolution and detail. In this context, scientific visualization\nbecomes a critical component, enabling researchers to interpret complex\ndatasets and extract meaningful insights. The immense volume of data demands\nnot only suitable tools but also substantial infrastructure and computational\ncapacity to analyze it effectively. In this work, we will discuss how we are\naddressing these challenges with the development of our interactive\nvisualization tool named VisIVO Visual Analytics. The tool is transitioning\nfrom a local visualizer to a remote visualizer, utilizing a client-server\narchitecture. This evolution will allow the software to run parallel\nvisualization pipelines on high-performance computing (HPC) clusters, thereby\nenhancing its capacity to handle extensive datasets efficiently.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-03-31T14:04:53Z"}
{"aid":"http://arxiv.org/abs/2503.24114v1","title":"Generic linearized curvature singularity at the perturbed Kerr Cauchy\n  horizon","summary":"We prove the precise asymptotics of the spin $-2$ Teukolsky field in the\ninterior and along the Cauchy horizon of a subextremal Kerr black hole.\nTogether with the oscillatory blow-up asymptotics of the spin $+2$ Teukolsky\nfield proven in our previous work arXiv:2409.02670, our result suggests that\ngeneric perturbations of a Kerr black hole build up to form a\ncoordinate-independent curvature singularity at the Cauchy horizon. This\nsupports the Strong Cosmic Censorship conjecture in Kerr spacetimes. Unlike in\nthe spin $+2$ case, the spin $-2$ Teukolsky field is regular on the Cauchy\nhorizon and the first term in its asymptotic development vanishes. As a result,\nthe derivation of a precise lower bound for the spin $-2$ field is more\ndelicate than in the spin $+2$ case, and relies on a novel ODE method based on\na decomposition of the Teukolsky operator between radial and time derivatives.","main_category":"gr-qc","categories":"gr-qc,math.AP","published":"2025-03-31T14:05:27Z"}
{"aid":"http://arxiv.org/abs/2503.24136v1","title":"Numerical simulation of Generalized Hermite Processes","summary":"Hermite processes are paradigmatic examples of stochastic processes which can\nbelong to any Wiener chaos of an arbitrary order; the wellknown fractional\nBrownian motion belonging to the Gaussian first order Wiener chaos and the\nRosenblatt process belonging to the non-Gaussian second order Wiener chaos are\ntwo particular cases of them. Except these two particular cases no simulation\nmethod for sample paths of Hermite processes is available so far. The goal of\nour article is to introduce a new method which potentially allows to simulate\nsample paths of any Hermite process and even those of any generalized Hermite\nprocess. Our starting point is the representation for the latter process as\nrandom wavelet-typeseries, obtained in our very recent paper [3]. We construct\nfrom it a \"concrete\" sequence of piecewise linear continuous random functions\nwhich almost surely approximate sample paths of this process for the uniform\nnorm on any compact interval, and we provide an almost sure estimate of the\napproximation error. Then, for the Rosenblatt process and more importantly for\nthe third order Hermite process, we propose algorithms allowing to implement\nthis sequence and we illustrate them by several simulations. Python routines\nimplementing these synthesis procedures are available upon request.","main_category":"math.PR","categories":"math.PR","published":"2025-03-31T14:18:42Z"}
{"aid":"http://arxiv.org/abs/2503.24151v1","title":"Robust Feedback Optimization with Model Uncertainty: A Regularization\n  Approach","summary":"Feedback optimization optimizes the steady state of a dynamical system by\nimplementing optimization iterations in closed loop with the plant. It relies\non online measurements and limited model information, namely, the input-output\nsensitivity. In practice, various issues including inaccurate modeling, lack of\nobservation, or changing conditions can lead to sensitivity mismatches, causing\nclosed-loop sub-optimality or even instability. To handle such uncertainties,\nwe pursue robust feedback optimization, where we optimize the closed-loop\nperformance against all possible sensitivities lying in specific uncertainty\nsets. We provide tractable reformulations for the corresponding min-max\nproblems via regularizations and characterize the online closed-loop\nperformance through the tracking error in case of time-varying optimal\nsolutions. Simulations on a distribution grid illustrate the effectiveness of\nour robust feedback optimization controller in addressing sensitivity\nmismatches in a non-stationary environment.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-03-31T14:36:25Z"}
{"aid":"http://arxiv.org/abs/2503.24172v1","title":"Pseudo-Random UAV Test Generation Using Low-Fidelity Path Simulator","summary":"Simulation-based testing provides a safe and cost-effective environment for\nverifying the safety of Uncrewed Aerial Vehicles (UAVs). However, simulation\ncan be resource-consuming, especially when High-Fidelity Simulators (HFS) are\nused. To optimise simulation resources, we propose a pseudo-random test\ngenerator that uses a Low-Fidelity Simulator (LFS) to estimate UAV flight\npaths. This work simplifies the PX4 autopilot HFS to develop a LFS, which\noperates one order of magnitude faster than the HFS.Test cases predicted to\ncause safety violations in the LFS are subsequently validated using the HFS.","main_category":"cs.RO","categories":"cs.RO","published":"2025-03-31T14:50:46Z"}
{"aid":"http://arxiv.org/abs/2503.24207v1","title":"Definability of mad families of vector spaces and two local Ramsey\n  theories","summary":"Let $E$ be a vector space over a countable field of dimension $\\aleph_0$. Two\ninfinite-dimensional subspaces $V,W \\subseteq E$ are almost disjoint if $V \\cap\nW$ is finite-dimensional. This paper provides some improvements on results\nabout the definability of maximal almost disjoint families (mad families) of\nsubspaces in [17]. We show that a full mad family of block subspaces exists\nassuming either $\\frak{p} = \\max\\{\\frak{b},\\frak{s}\\}$ or a positive answer to\na problem in [17], improving Smythe's construction assuming $\\frak{p} =\n\\frak{c}$. We also discuss the abstract Mathias forcing introduced by Di\nPrisco-Mijares-Nieto in [11], and apply it to show that in the Solovay's model\nobtained by the collapse of a Mahlo cardinal, there are no full mad families of\nblock subspaces over $\\mathbb{F}_2$.","main_category":"math.LO","categories":"math.LO","published":"2025-03-31T15:24:19Z"}
{"aid":"http://arxiv.org/abs/2503.24212v1","title":"Characterization of $\\PSL(2,q)$ by the number of singular elements","summary":"Given a finite group $G$, let $\\pi(G)$ denote the set of all primes that\ndivide the order of $G$. For a prime $r \\in \\pi(G)$, we define $r$-singular\nelements as those elements of $G$ whose order is divisible by $r$. Denote by\n$S_r(G)$ the number of $r$-singluar elements of $G$. We denote the proportion\n$S_r(G)/|G|$ of $r$-singular elements in $G$ by ${\\mu_r}(G)$. Let $\\mu(G) :=\n{\\{\\mu_r}(G) | r\\in \\pi(G)\\}$ be the set of all proportions of $r$-singular\nelements for each prime $r$ in $\\pi(G)$. In this paper, we prove that if a\nfinite group $G$ has the same set $\\mu(G)$ as the simple group $\\PSL(2,q)$,\nthen $G$ is isomorphic to $\\PSL(2,q)$.","main_category":"math.GR","categories":"math.GR","published":"2025-03-31T15:30:34Z"}
{"aid":"http://arxiv.org/abs/2503.24227v1","title":"Ambient and high pressure studies of structural, electronic and magnetic\n  properties of EuZn$_2$P$_2$ single crystal","summary":"A thorough study of EuZn$_2$P$_2$ single crystals, which were grown from Sn\nflux, was performed using both bulk (heat capacity, ac susceptibility, dc\nmagnetization, electrical resistivitivity, magnetoresistance) and microscopic\n(M\\\"ossbauer spectroscopy) techniques. Electrical resistance and magnetic\nsusceptibility were measured also under high pressure conditions (up to 19 GPa\nand 9.5 GPa, respectively). Further insight into electronic properties and\nphonons is provided by ab initio calculations. The results indicate that\nEuZn$_2$P$_2$ is an antiferromagnet with strong Eu-Eu exchange coupling of\nferromagnetic type within the basal plane and weaker antiferromagnetic\ninteraction along the c axis. The Eu magnetic moments are tilted from the basal\nplane. Hydrostatic pressure strongly affects both magnetic (increase of the\nN\\'eel temperature) and electronic (suppression of the band gap and semi\nmetallic behavior) properties, indicating a strong interplay of structure with\nmagnetic and electronic degrees of freedom.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-03-31T15:40:30Z"}
{"aid":"http://arxiv.org/abs/2503.24238v1","title":"PhD Thesis: Shifted Contact Structures on Differentiable Stacks","summary":"This thesis focuses on developing \"stacky\" versions of contact structures,\nextending the classical notion of contact structures on manifolds. A fruitful\napproach is to study contact structures using line bundle-valued $1$-forms.\nSpecifically, we introduce the notions of $0$ and $+1$-shifted contact\nstructures on Lie groupoids. To define the kernel of a line bundle-valued\n$1$-form $\\theta$ on a Lie groupoid, we draw inspiration from the concept of\nthe homotopy kernel in Homological Algebra. That kernel is essentially given by\na representation up to homotopy (RUTH). Similarly, the curvature is described\nby a specific RUTH morphism. Both the definitions are motivated by the\nSymplectic-to-Contact Dictionary, which establishes a relationship between\nSymplectic and Contact Geometry. Examples of $0$-shifted contact structures can\nbe found in contact structures on orbifolds, while examples of $+1$-shifted\ncontact structures include the prequantization of $+1$-shifted symplectic\nstructures and the integration of Dirac-Jacobi structures.","main_category":"math.DG","categories":"math.DG,math-ph,math.MP,math.SG","published":"2025-03-31T15:52:35Z"}
{"aid":"http://arxiv.org/abs/2503.24245v1","title":"Enhancing Large Language Models (LLMs) for Telecommunications using\n  Knowledge Graphs and Retrieval-Augmented Generation","summary":"Large language models (LLMs) have made significant progress in\ngeneral-purpose natural language processing tasks. However, LLMs are still\nfacing challenges when applied to domain-specific areas like\ntelecommunications, which demands specialized expertise and adaptability to\nevolving standards. This paper presents a novel framework that combines\nknowledge graph (KG) and retrieval-augmented generation (RAG) techniques to\nenhance LLM performance in the telecom domain. The framework leverages a KG to\ncapture structured, domain-specific information about network protocols,\nstandards, and other telecom-related entities, comprehensively representing\ntheir relationships. By integrating KG with RAG, LLMs can dynamically access\nand utilize the most relevant and up-to-date knowledge during response\ngeneration. This hybrid approach bridges the gap between structured knowledge\nrepresentation and the generative capabilities of LLMs, significantly enhancing\naccuracy, adaptability, and domain-specific comprehension. Our results\ndemonstrate the effectiveness of the KG-RAG framework in addressing complex\ntechnical queries with precision. The proposed KG-RAG model attained an\naccuracy of 88% for question answering tasks on a frequently used\ntelecom-specific dataset, compared to 82% for the RAG-only and 48% for the\nLLM-only approaches.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T15:58:08Z"}
{"aid":"http://arxiv.org/abs/2503.24257v1","title":"Mathematical foundations of information economics","summary":"The state of economic theory and accumulated facts from the different\nbranches of the economic science require to analyze the concept of the\ndescription of economy systems. The economic reality generates the problems the\nsolution of that is only possible by a new paradigm of the description of\neconomy system. The classical mathematical economics is based on a notion of\nthe rational consumer choice generated by a certain preference relation on some\nset of goods a consumer wanted and the concept of maximization of the firm\nprofit. The sense of the notion of the ratio- nal consumer choice is that it is\ndetermined by a certain utility function, defining the choice of a consumer by\nmaximization of it on a certain budget set of goods. More- over, choices of\nconsumers are independent. In the reality choices of consumers are not\nindependent because they depend on the firms supply. Except the firms supply,\nthe consumer choice is also determined by information about the state of the\neconomy system that the consumer has and respectively eval- uates at the moment\nof the choice. In turn, the firms supply is made on the basis of needs of the\nconsumers and their buying power. By information about the state of the economy\nsystem we understand a certain information about the equilibrium price vector\nand productive processes realized in the economy system under the equilibrium\nprice vector.","main_category":"q-fin.MF","categories":"q-fin.MF","published":"2025-03-31T16:05:39Z"}
{"aid":"http://arxiv.org/abs/2503.24259v1","title":"Advances in Continual Graph Learning for Anti-Money Laundering Systems:\n  A Comprehensive Review","summary":"Financial institutions are required by regulation to report suspicious\nfinancial transactions related to money laundering. Therefore, they need to\nconstantly monitor vast amounts of incoming and outgoing transactions. A\nparticular challenge in detecting money laundering is that money launderers\ncontinuously adapt their tactics to evade detection. Hence, detection methods\nneed constant fine-tuning. Traditional machine learning models suffer from\ncatastrophic forgetting when fine-tuning the model on new data, thereby\nlimiting their effectiveness in dynamic environments. Continual learning\nmethods may address this issue and enhance current anti-money laundering (AML)\npractices, by allowing models to incorporate new information while retaining\nprior knowledge. Research on continual graph learning for AML, however, is\nstill scarce. In this review, we critically evaluate state-of-the-art continual\ngraph learning approaches for AML applications. We categorise methods into\nreplay-based, regularization-based, and architecture-based strategies within\nthe graph neural network (GNN) framework, and we provide in-depth experimental\nevaluations on both synthetic and real-world AML data sets that showcase the\neffect of the different hyperparameters. Our analysis demonstrates that\ncontinual learning improves model adaptability and robustness in the face of\nextreme class imbalances and evolving fraud patterns. Finally, we outline key\nchallenges and propose directions for future research.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T16:06:47Z"}
{"aid":"http://arxiv.org/abs/2503.24275v1","title":"Davenport-Heilbronn Function Ratio Properties and Non-Trivial Zeros\n  Study","summary":"This paper systematically investigates the analytic properties of the ratio\n$f(s)/f(1-s) = X(s)$ based on the Davenport-Heilbronn functional equation $f(s)\n= X(s)f(1-s)$. We propose a novel method to analyze the distribution of\nnon-trivial zeros through the monotonicity of the ratio $|f(s)/f(1-s)|$.\nRigorously proving that non-trivial zeros can only lie on the critical line\n$\\sigma=1/2$, we highlight two groundbreaking findings: 1. Contradiction of\nOff-Critical Zeros: Numerical \"exceptional zeros\" (e.g., Spira, 1994) violate\nthe theoretical threshold $\\kappa=1.21164$ and conflict with the monotonicity\nconstraint of $|X(s)|=1$. 2. Essential Difference Between Approximate and\nStrict Zeros: Points satisfying $f(s) \\to 0$ do not constitute strict zeros\nunless verified by analyticity. This work provides a new perspective for\nstudying zero distributions of $L$-functions related to the Riemann Hypothesis.","main_category":"math.NT","categories":"math.NT,math.AP","published":"2025-03-31T16:21:38Z"}
{"aid":"http://arxiv.org/abs/2503.24307v1","title":"A Systematic Evaluation of LLM Strategies for Mental Health Text\n  Analysis: Fine-tuning vs. Prompt Engineering vs. RAG","summary":"This study presents a systematic comparison of three approaches for the\nanalysis of mental health text using large language models (LLMs): prompt\nengineering, retrieval augmented generation (RAG), and fine-tuning. Using LLaMA\n3, we evaluate these approaches on emotion classification and mental health\ncondition detection tasks across two datasets. Fine-tuning achieves the highest\naccuracy (91% for emotion classification, 80% for mental health conditions) but\nrequires substantial computational resources and large training sets, while\nprompt engineering and RAG offer more flexible deployment with moderate\nperformance (40-68% accuracy). Our findings provide practical insights for\nimplementing LLM-based solutions in mental health applications, highlighting\nthe trade-offs between accuracy, computational requirements, and deployment\nflexibility.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.IR,cs.LG","published":"2025-03-31T16:54:04Z"}
{"aid":"http://arxiv.org/abs/2503.24317v1","title":"Thermodynamic Features of a Heat Engine Coupled with Exponentially\n  Decreasing Temperature Across the Reaction Coordinate, as well as\n  Perspectives on Nonequilibrium Thermodynamics","summary":"In this study, we advance the understanding of non-equilibrium systems by\nderiving thermodynamic relations for a heat engine operating under an\nexponentially decreasing temperature profile. Such thermal configurations\nclosely mimic spatially localized heating such as laser-induced thermal\ngradients. Using exact analytical solutions, we show that this arrangement\nresults in significantly higher velocity, entropy production, and extraction\nrates than piecewise thermal profiles, while exhibiting reduced irreversibility\nand complexity relative to linear or quadratic gradients. We further examine\nthe thermodynamic behavior of the Brownian particles in the networks. Our study\nreveals that the velocity and entropy production rates remain independent of\nnetwork size; on the contrary, extensive quantities such as total entropy\ndepend on the number of microstates. Additionally, we show that a Brownian\nparticle in a ratchet potential with spatially varying temperature achieves\ndirected motion, even without external forces driven by solely thermal\nasymmetry. These findings highlight the critical role of temperature asymmetry\nin controlling the transport processes and optimizing the particle dynamics.\nThis in turn will have promising applications in microfluidic devices and\nnanoscale sensors. Finally, we explore the influence of the system parameters\non the efficiency and performance of the heat engine. The exponential\ntemperature profiles enable faster velocities while simultaneously exhibiting\nhigher efficiency compared with other thermal arrangements. Moreover, by\naddressing key questions on entropy production, we provide insights into the\ntransition between nonequilibrium and equilibrium systems and contribute tools\nfor optimizing energy-efficient systems in both natural and engineered\nsettings.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-03-31T17:07:01Z"}
{"aid":"http://arxiv.org/abs/2503.24341v1","title":"Chemically Tuning Room Temperature Pulsed Optically Detected Magnetic\n  Resonance","summary":"Optical detection of magnetic resonance enables spin-based quantum sensing\nwith high spatial resolution and sensitivity-even at room temperature-as\nexemplified by solid-state defects. Molecular systems provide a complementary,\nchemically tunable, platform for room-temperature optically detected magnetic\nresonance (ODMR)-based quantum sensing. A critical parameter governing sensing\nsensitivity is the optical contrast-i.e., the difference in emission between\ntwo spin states. In state-of-the-art solid-state defects such as the\nnitrogen-vacancy center in diamond, this contrast is approximately 30%. Here,\ncapitalizing on chemical tunability, we show that room-temperature ODMR\ncontrasts of 40% can be achieved in molecules. Using a nitrogen-substituted\nanalogue of pentacene (6,13-diazapentacene), we enhance contrast compared to\npentacene and, by determining the triplet kinetics through time-dependent\npulsed ODMR, show how this arises from accelerated anisotropic intersystem\ncrossing. Furthermore, we translate high-contrast room-temperature pulsed ODMR\nto self-assembled nanocrystals. Overall, our findings highlight the synthetic\nhandles available to optically readable molecular spins and the opportunities\nto capitalize on chemical tunability for room-temperature quantum sensing.","main_category":"quant-ph","categories":"quant-ph,physics.chem-ph","published":"2025-03-31T17:25:46Z"}
{"aid":"http://arxiv.org/abs/2503.24346v1","title":"Projections for Key Measurements in Heavy Flavour Physics","summary":"Precision studies of flavour-changing processes involving quarks and leptons\nprovide a number of ways to improve knowledge of the Standard Model and search\nfor physics beyond it. There are excellent short- and mid-term prospects for\nsignificantly improved measurements in heavy flavour physics (involving b and c\nhadrons and $\\tau$ leptons), with upgrades in progress or planned for the\nATLAS, CMS and LHCb experiments exploiting proton-proton collisions at CERN's\nLarge Hadron Collider, and for the Belle II experiment operating with\nelectron-positron collisions from the SuperKEKB accelerator in KEK. The\nexpected sensitivities that can be achieved from these experiments for a number\nof key observables are presented, highlighting the complementarity of the\ndifferent experiments and showing how the precision will improve with time.\nThis international programme in heavy flavour physics will result in\nunprecedented capability to probe this sector of the Standard Model and,\npotentially, observe imprints of physics at higher energy scales than can be\naccessed directly.","main_category":"hep-ex","categories":"hep-ex","published":"2025-03-31T17:32:03Z"}
{"aid":"http://arxiv.org/abs/2503.24359v1","title":"Unveiling the Fast Acceleration of AGN-Driven Winds at Kiloparsec Scales","summary":"Supermassive black holes at the centre of galaxies gain mass through\naccretion disks. Models predict that quasi-spherical winds, expelled by the\nblack hole during active accretion phases, have a key role in shaping galaxy\nevolution by regulating star formation, the distribution of metals over\nkiloparsec scales, and by sweeping ambient gas to the outskirts and beyond of\ngalaxies. Nonetheless, the mechanism driving these outflows and the amount of\nenergy exchanged between the wind and the galaxy's interstellar medium remain\nunclear. Here, we present a detailed analysis of the kinematical properties of\nwinds in a sample of nearby active galaxies using the novel kinematic tool\nMOKA3D, which takes into account the clumpy nature of the ISM. We find\nremarkable similarities among the properties of the outflows in all the\ngalaxies examined. In particular, we provide the first evidence that outflows\nexhibit a regular trend in radial velocity, initially constant or slightly\ndecreasing, followed by rapid acceleration starting at approximately 1 kpc from\nthe nucleus, despite the seemingly complex kinematics observed. The observed\nbehavior aligns with our current theoretical understanding of Active Galactic\nNuclei outflows, where a momentum-driven phase transitions to an\nenergy-conserving phase just beyond approximately 1 kpc. The constant velocity\nof the momentum-driven wind is then rapidly accelerated following the\ninefficient Compton cooling of post-shock material and the transition to energy\nconservation. The measured radial terminal velocities of the outflows are\nalways larger than the escape velocities from the host galaxies, confirming the\nkey role of outflows in shaping the galaxy properties and evolution, as a\nmanifestation of AGN feedback. Our results, only made possible by our novel\nkinematic analysis tool, are crucial to understand the origin and the powering\nmechanism of these winds.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-03-31T17:37:44Z"}
{"aid":"http://arxiv.org/abs/2504.01339v1","title":"Computing Time-varying Network Reliability using Binary Decision\n  Diagrams","summary":"Computing the reliability of a time-varying network, taking into account its\ndynamic nature, is crucial for networks that change over time, such as space\nnetworks, vehicular ad-hoc networks, and drone networks. These networks are\nmodeled using temporal graphs, in which each edge is labeled with a time\nindicating its existence at a specific point in time. The time-varying network\nreliability is defined as the probability that a data packet from the source\nvertex can reach the terminal vertex, following links with increasing time\nlabels (i.e., a journey), while taking into account the possibility of network\nlink failures. Currently, the existing method for calculating this reliability\ninvolves explicitly enumerating all possible journeys between the source and\nterminal vertices and then calculating the reliability using the sum of\ndisjoint products method. However, this method has high computational\ncomplexity. In contrast, there is an efficient algorithm that uses binary\ndecision diagrams (BDDs) to evaluate the reliability of a network whose\ntopology does not change over time. This paper presents an efficient exact\nalgorithm that utilizes BDDs for computing the time-varying network\nreliability. Experimental results show that the proposed method runs faster\nthan the existing method up to four orders of magnitude.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-02T03:58:50Z"}
{"aid":"http://arxiv.org/abs/2504.01346v1","title":"GTR: Graph-Table-RAG for Cross-Table Question Answering","summary":"Beyond pure text, a substantial amount of knowledge is stored in tables. In\nreal-world scenarios, user questions often require retrieving answers that are\ndistributed across multiple tables. GraphRAG has recently attracted much\nattention for enhancing LLMs' reasoning capabilities by organizing external\nknowledge to address ad-hoc and complex questions, exemplifying a promising\ndirection for cross-table question answering. In this paper, to address the\ncurrent gap in available data, we first introduce a multi-table benchmark,\nMutliTableQA, comprising 60k tables and 25k user queries collected from\nreal-world sources. Then, we propose the first Graph-Table-RAG framework,\nnamely GTR, which reorganizes table corpora into a heterogeneous graph, employs\na hierarchical coarse-to-fine retrieval process to extract the most relevant\ntables, and integrates graph-aware prompting for downstream LLMs' tabular\nreasoning. Extensive experiments show that GTR exhibits superior cross-table\nquestion-answering performance while maintaining high deployment efficiency,\ndemonstrating its real-world practical applicability.","main_category":"cs.CL","categories":"cs.CL,cs.IR,cs.LG","published":"2025-04-02T04:24:41Z"}
{"aid":"http://arxiv.org/abs/2504.01347v1","title":"MEEK: Re-thinking Heterogeneous Parallel Error Detection Architecture\n  for Real-World OoO Superscalar Processors","summary":"Heterogeneous parallel error detection is an approach to achieving\nfault-tolerant processors, leveraging multiple power-efficient cores to\nre-execute software originally run on a high-performance core. Yet, its complex\ncomponents, gathering data cross-chip from many parts of the core, raise\nquestions of how to build it into commodity cores without heavy design invasion\nand extensive re-engineering.\n  We build the first full-RTL design, MEEK, into an open-source SoC, from\nmicroarchitecture and ISA to the OS and programming model. We identify and\nsolve bottlenecks and bugs overlooked in previous work, and demonstrate that\nMEEK offers microsecond-level detection capacity with affordable overheads. By\ntrading off architectural functionalities across codesigned hardware-software\nlayers, MEEK features only light changes to a mature out-of-order superscalar\ncore, simple coordinating software layers, and a few lines of operating-system\ncode. The Repo. of MEEK's source code:\nhttps://github.com/SEU-ACAL/reproduce-MEEK-DAC-25.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-02T04:32:49Z"}
{"aid":"http://arxiv.org/abs/2504.01362v1","title":"Connection Matrices in Macaulay2","summary":"In this article, we describe the theoretical foundations of the Macaulay2\npackage ConnectionMatrices and explain how to use it. For a left ideal in the\nWeyl algebra that is of finite holonomic rank, we implement the computation of\nthe encoded system of linear PDEs in connection form with respect to an\nelimination term order that depends on a chosen positive weight vector. We also\nimplement the gauge transformation for carrying out a change of basis over the\nfield of rational functions. We demonstrate all implemented algorithms with\nexamples.","main_category":"math.AG","categories":"math.AG,cs.SC","published":"2025-04-02T05:08:45Z"}
{"aid":"http://arxiv.org/abs/2504.01432v1","title":"Adaptive adequacy testing of high-dimensional factor-augmented\n  regression model","summary":"In this paper, we investigate the adequacy testing problem of\nhigh-dimensional factor-augmented regression model. Existing test procedures\nperform not well under dense alternatives. To address this critical issue, we\nintroduce a novel quadratic-type test statistic which can efficiently detect\ndense alternative hypotheses. We further propose an adaptive test procedure to\nremain powerful under both sparse and dense alternative hypotheses.\nTheoretically, under the null hypothesis, we establish the asymptotic normality\nof the proposed quadratic-type test statistic and asymptotic independence of\nthe newly introduced quadratic-type test statistic and a maximum-type test\nstatistic. We also prove that our adaptive test procedure is powerful to detect\nsignals under either sparse or dense alternative hypotheses. Simulation studies\nand an application to an FRED-MD macroeconomics dataset are carried out to\nillustrate the merits of our introduced procedures.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-02T07:34:23Z"}
{"aid":"http://arxiv.org/abs/2504.01435v1","title":"Relativistic quantum Otto heat engine using a three-level Unruh-DeWitt\n  detector","summary":"In this study, we explore a relativistic quantum Otto heat engine with a\nqutrit as the working substance interacting with a quantum scalar field in\ncurved spacetime. Unlike qubits, which extract work by simply expanding or\nshrinking a single energy gap, qutrits allow multiple energy gaps to be\nadjusted independently, enabling more versatile work extraction in the quantum\nOtto cycle. We derive a general positive work condition in terms of the\neffective temperature that each pair of energy levels perceives. Moreover, we\ndiscuss additional subtleties that are absent when using a qubit, such as the\ngeneration of coherence terms in the density matrix due to interactions.","main_category":"quant-ph","categories":"quant-ph,gr-qc","published":"2025-04-02T07:38:58Z"}
{"aid":"http://arxiv.org/abs/2504.01439v1","title":"On $\\overline{\\partial }_{b}$-harmonic maps from pseudo-Hermitian\n  manifolds to Kähler manifolds","summary":"In this paper, we consider maps from pseudo-Hermitian manifolds to K\\\"{a}hler\nmanifolds and introduce partial energy functionals for these maps.\n  First, we obtain a foliated Lichnerowicz type result on general\n  pseudo-Hermitian manifolds, which generalizes a related result on Sasakian\n  manifolds in \\cite{SSZ2013holomorphic}. Next, we investigate critical maps of\nthe partial\n  energy functionals, which are referred to as $\\overline{\\partial\n}_{b}$-harmonic maps and $\\partial _{b}$-harmonic maps. We give a foliated\nresult\n  for both $\\overline{\\partial }_{b}$- and $\\partial _{b}$-harmonic maps,\n  generalizing a foliated result of Petit \\cite{Pet2002harmonic} for harmonic\nmaps. Then we\n  are able to generalize Siu's holomorphicity result for harmonic maps\n\\cite{Siu1980rigid}\n  to the case for $\\overline{\\partial }_{b}$- and $\\partial _{b}$-harmonic\n  maps.","main_category":"math.DG","categories":"math.DG","published":"2025-04-02T07:49:49Z"}
{"aid":"http://arxiv.org/abs/2504.01480v1","title":"A microscopic traffic flow model on network with destination-aware V2V\n  communications and rational decision-making","summary":"In this paper we carry out a computational study of a novel microscopic\nfollow-the-leader model for traffic flow on road networks. We assume that each\ndriver has its own origin and destination, and wants to complete its journey in\nminimal time. We also assume that each driver is able to take rational\ndecisions at junctions and can change route while moving depending on the\ntraffic conditions. The main novelty of the model is that vehicles can\nautomatically and anonymously share information about their position,\ndestination, and planned path when they are close to each other within a\ncertain distance. The pieces of information acquired during the journey are\nused to optimize the route itself. In the limit case of a infinite\ncommunication range, we recover the classical Reactive User Equilibrium and\nDynamic User Equilibrium.","main_category":"math.OC","categories":"math.OC","published":"2025-04-02T08:35:37Z"}
{"aid":"http://arxiv.org/abs/2504.01481v1","title":"Identifying Obfuscated Code through Graph-Based Semantic Analysis of\n  Binary Code","summary":"Protecting sensitive program content is a critical issue in various\nsituations, ranging from legitimate use cases to unethical contexts.\nObfuscation is one of the most used techniques to ensure such protection.\nConsequently, attackers must first detect and characterize obfuscation before\nlaunching any attack against it. This paper investigates the problem of\nfunction-level obfuscation detection using graph-based approaches, comparing\nalgorithms, from elementary baselines to promising techniques like GNN (Graph\nNeural Networks), on different feature choices. We consider various obfuscation\ntypes and obfuscators, resulting in two complex datasets. Our findings\ndemonstrate that GNNs need meaningful features that capture aspects of function\nsemantics to outperform baselines. Our approach shows satisfactory results,\nespecially in a challenging 11-class classification task and in a practical\nmalware analysis example.","main_category":"cs.CR","categories":"cs.CR,cs.LG,stat.ML","published":"2025-04-02T08:36:27Z"}
{"aid":"http://arxiv.org/abs/2504.01495v1","title":"Are Autonomous Web Agents Good Testers?","summary":"Despite advances in automated testing, manual testing remains prevalent due\nto the high maintenance demands associated with test script fragility-scripts\noften break with minor changes in application structure. Recent developments in\nLarge Language Models (LLMs) offer a potential alternative by powering\nAutonomous Web Agents (AWAs) that can autonomously interact with applications.\nThese agents may serve as Autonomous Test Agents (ATAs), potentially reducing\nthe need for maintenance-heavy automated scripts by utilising natural language\ninstructions similar to those used by human testers. This paper investigates\nthe feasibility of adapting AWAs for natural language test case execution and\nhow to evaluate them. We contribute with (1) a benchmark of three offline web\napplications, and a suite of 113 manual test cases, split between passing and\nfailing cases, to evaluate and compare ATAs performance, (2) SeeAct-ATA and\npinATA, two open-source ATA implementations capable of executing test steps,\nverifying assertions and giving verdicts, and (3) comparative experiments using\nour benchmark that quantifies our ATAs effectiveness. Finally we also proceed\nto a qualitative evaluation to identify the limitations of PinATA, our best\nperforming implementation. Our findings reveal that our simple implementation,\nSeeAct-ATA, does not perform well compared to our more advanced PinATA\nimplementation when executing test cases (50% performance improvement).\nHowever, while PinATA obtains around 60% of correct verdict and up to a\npromising 94% specificity, we identify several limitations that need to be\naddressed to develop more resilient and reliable ATAs, paving the way for\nrobust, low maintenance test automation. CCS Concepts: $\\bullet$ Software and\nits engineering $\\rightarrow$ Software testing and debugging.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-02T08:48:01Z"}
{"aid":"http://arxiv.org/abs/2504.01504v1","title":"Approximate Agreement Algorithms for Byzantine Collaborative Learning","summary":"In Byzantine collaborative learning, $n$ clients in a peer-to-peer network\ncollectively learn a model without sharing their data by exchanging and\naggregating stochastic gradient estimates. Byzantine clients can prevent others\nfrom collecting identical sets of gradient estimates. The aggregation step thus\nneeds to be combined with an efficient (approximate) agreement subroutine to\nensure convergence of the training process.\n  In this work, we study the geometric median aggregation rule for Byzantine\ncollaborative learning. We show that known approaches do not provide\ntheoretical guarantees on convergence or gradient quality in the agreement\nsubroutine. To satisfy these theoretical guarantees, we present a hyperbox\nalgorithm for geometric median aggregation.\n  We practically evaluate our algorithm in both centralized and decentralized\nsettings under Byzantine attacks on non-i.i.d. data. We show that our geometric\nmedian-based approaches can tolerate sign-flip attacks better than known\nmean-based approaches from the literature.","main_category":"cs.LG","categories":"cs.LG,cs.DC","published":"2025-04-02T08:55:24Z"}
{"aid":"http://arxiv.org/abs/2504.01531v1","title":"DRAN: A Distribution and Relation Adaptive Network for Spatio-temporal\n  Forecasting","summary":"Accurate predictions of spatio-temporal systems' states are crucial for tasks\nsuch as system management, control, and crisis prevention. However, the\ninherent time variance of spatio-temporal systems poses challenges to achieving\naccurate predictions whenever stationarity is not granted. To address\nnon-stationarity frameworks, we propose a Distribution and Relation Adaptive\nNetwork (DRAN) capable of dynamically adapting to relation and distribution\nchanges over time. While temporal normalization and de-normalization are\nfrequently used techniques to adapt to distribution shifts, this operation is\nnot suitable for the spatio-temporal context as temporal normalization scales\nthe time series of nodes and possibly disrupts the spatial relations among\nnodes. In order to address this problem, we develop a Spatial Factor Learner\n(SFL) module that enables the normalization and de-normalization process in\nspatio-temporal systems. To adapt to dynamic changes in spatial relationships\namong sensors, we propose a Dynamic-Static Fusion Learner (DSFL) module that\neffectively integrates features learned from both dynamic and static relations\nthrough an adaptive fusion ratio mechanism. Furthermore, we introduce a\nStochastic Learner to capture the noisy components of spatio-temporal\nrepresentations. Our approach outperforms state of the art methods in weather\nprediction and traffic flows forecasting tasks. Experimental results show that\nour SFL efficiently preserves spatial relationships across various temporal\nnormalization operations. Visualizations of the learned dynamic and static\nrelations demonstrate that DSFL can capture both local and distant\nrelationships between nodes. Moreover, ablation studies confirm the\neffectiveness of each component.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T09:18:43Z"}
{"aid":"http://arxiv.org/abs/2504.01544v1","title":"Periodic solutions of a class of second-order non-autonomous\n  differential equations","summary":"This paper investigates the dynamical behavior of periodic solutions for a\nclass of second-order non-autonomous differential equations. First, based on\nthe Lyapunov-Schmidt reduction method for finite-dimensional functions, the\ncorresponding bifurcation function is constructed, and it is proven that the\nsystem possesses at least one T-periodic solution. Second, a two-timing method\nis employed to perform perturbation analysis on the original equation. By\nseparating the fast and slow time scales, an explicit expression for the\napproximate T-periodic solution is derived. Furthermore, for the stability of\nthe system under parametric excitation, the bifurcation characteristics near\nthe first instability tongue are revealed through perturbation expansion and\neigenvalue analysis. Additionally, the Ince-Strutt stability diagram is plotted\nto illustrate the stability boundaries.","main_category":"math.CA","categories":"math.CA","published":"2025-04-02T09:33:03Z"}
{"aid":"http://arxiv.org/abs/2504.01547v1","title":"Semi-Supervised Biomedical Image Segmentation via Diffusion Models and\n  Teacher-Student Co-Training","summary":"Supervised deep learning for semantic segmentation has achieved excellent\nresults in accurately identifying anatomical and pathological structures in\nmedical images. However, it often requires large annotated training datasets,\nwhich limits its scalability in clinical settings. To address this challenge,\nsemi-supervised learning is a well-established approach that leverages both\nlabeled and unlabeled data. In this paper, we introduce a novel semi-supervised\nteacher-student framework for biomedical image segmentation, inspired by the\nrecent success of generative models. Our approach leverages denoising diffusion\nprobabilistic models (DDPMs) to generate segmentation masks by progressively\nrefining noisy inputs conditioned on the corresponding images. The teacher\nmodel is first trained in an unsupervised manner using a cycle-consistency\nconstraint based on noise-corrupted image reconstruction, enabling it to\ngenerate informative semantic masks. Subsequently, the teacher is integrated\ninto a co-training process with a twin-student network. The student learns from\nground-truth labels when available and from teacher-generated pseudo-labels\notherwise, while the teacher continuously improves its pseudo-labeling\ncapabilities. Finally, to further enhance performance, we introduce a\nmulti-round pseudo-label generation strategy that iteratively improves the\npseudo-labeling process. We evaluate our approach on multiple biomedical\nimaging benchmarks, spanning multiple imaging modalities and segmentation\ntasks. Experimental results show that our method consistently outperforms\nstate-of-the-art semi-supervised techniques, highlighting its effectiveness in\nscenarios with limited annotated data. The code to replicate our experiments\ncan be found at\nhttps://github.com/ciampluca/diffusion_semi_supervised_biomedical_image_segmentation","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T09:41:43Z"}
{"aid":"http://arxiv.org/abs/2504.01564v1","title":"Numerical techniques for geodesic approximation in Riemaniann shape\n  optimization","summary":"Shape optimization is commonly applied in engineering to optimize shapes with\nrespect to an objective functional relying on PDE solutions. In this paper, we\nview shape optimization as optimization on Riemannian shape manifolds. We\nconsider so-called outer metrics on the diffeomorphism group to solve\nPDE-constrained shape optimization problems efficiently. Commonly, the\nnumerical solution of such problems relies on the Riemannian version of the\nsteepest descent method. One key difference between this version and the\nstandard method is that iterates are updated via geodesics or retractions. Due\nto the lack of explicit expressions for geodesics, for most of the previously\nproposed metrics, very limited progress has been made in this direction.\nLeveraging the existence of explicit expressions for the geodesic equations\nassociated to the outer metrics on the diffeomorphism group, we aim to study\nthe viability of using such equations in the context of PDE-constrained shape\noptimization. However, solving geodesic equations is computationally\nchallenging and often restrictive. Therefore, this paper discusses potential\nnumerical approaches to simplify the numerical burden of using geodesics,\nmaking the proposed method computationally competitive with previously\nestablished methods.","main_category":"math.OC","categories":"math.OC","published":"2025-04-02T10:07:20Z"}
{"aid":"http://arxiv.org/abs/2504.01574v1","title":"Cutwidth Bounds via Vertex Partitions","summary":"We study the cutwidth measure on graphs and ways to bound the cutwidth of a\ngraph by partitioning its vertices. We consider bounds expressed as a function\nof two quantities: on the one hand, the maximal cutwidth x of the subgraphs\ninduced by the classes of the partition, and on the other hand, the cutwidth y\nof the quotient multigraph obtained by merging each class to a single vertex.\nWe consider in particular decomposition of directed graphs into strongly\nconnected components (SCCs): in this case, x is the maximal cutwidth of an SCC,\nand y is the cutwidth of the directed acyclic condensation multigraph.\n  We show that the cutwidth of a graph is always in O(x + y), specifically it\ncan be upper bounded by 1.5x + y. We also show a lower bound justifying that\nthe constant 1.5 cannot be improved in general","main_category":"cs.DS","categories":"cs.DS,cs.DM","published":"2025-04-02T10:23:58Z"}
{"aid":"http://arxiv.org/abs/2504.01575v1","title":"Fully ergodic simulations using radial updates","summary":"A sensible application of the Hybrid Monte Carlo (HMC) method is often\nhindered by the presence of large - or even infinite - potential barriers.\nThese potential barriers separate the configuration space into distinct sectors\nand can lead to ergodicity violations that bias measurements. In this work, we\naddress this problem by augmenting HMC with a multiplicative\nMetropolis-Hastings update in a so-called ''radial direction'' of the fields\nwhich enables crossing the potential barriers and ensures ergodicity of the\nsampling algorithm at comparably low computational cost. We demonstrate the\nalgorithm on a simple toy model and show how it can be applied to the fermionic\nHubbard model describing physics ranging from an exactly-solvable two-site\nsystem to the $C_{20}H_{12}$ perylene molecule. Our numerical results show that\nthe radial updates successfully remove ergodicity violations, while\nsimultaneously reducing autocorrelation times.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,hep-lat","published":"2025-04-02T10:28:49Z"}
{"aid":"http://arxiv.org/abs/2504.01624v1","title":"Glycemic Variability Before And After Hypoglycemia Across Different\n  Timeframes In Type 1 Diabetes With And Without Automated Insulin Delivery","summary":"Managing Type 1 diabetes (T1D) aims to optimize glucose levels within the\ntarget range while minimizing hyperglycemia and hypoglycemia. Exercise presents\nadditional challenges due to complex effects on glucose dynamics. Despite\nadvancements in diabetes technology, significant gaps remain in understanding\nthe relationship between exercise, glycemic variability (GV), and hypoglycemia\nin both automated insulin delivery (AID) and non-AID users. Additionally,\nlimited research explores the temporal progression of GV before and after\nhypoglycemia and the impact of long-duration episodes on glucose recovery. This\nstudy analyses the Type 1 Diabetes and Exercise Initiative (T1DEXI) dataset,\nassessing GV, hypoglycemia, gender, and exercise interactions in AID (n=222)\nand non-AID (n=276) users. The study examined patterns of glycemic variability\nmetrics like time below range (TBR) surrounding hypoglycemia events, focusing\non the 48 hours before and after these events. We further assess the impact of\ndifferent hypoglycemia levels (41-50 mg/dL, 51-60 mg/dL, and 61-70 mg/dL) on\npost-event glucose stability. GV increased before and after hypoglycemia up to\n48 hours in both AID and non-AID users, with statistically significant\ndifferences. TBR elevation persisted across all groups, peaking around\nhypoglycemic episodes. Notably, females using AID achieved significantly\nimproved glucose stability compared to non-AID females - a larger within-group\ndifference than that observed in males. Individual-level AID analyses showed\nthat long hypoglycemia episodes (>40 minutes) led to prolonged TBR elevation,\nsuggesting slower recovery despite AID intervention. GV trends may aid in\npredicting hypoglycemia over extended periods. Integrating GV patterns into AID\nsystems could enhance glucose stability and mitigate hypoglycemia cycles.","main_category":"q-bio.QM","categories":"q-bio.QM","published":"2025-04-02T11:30:34Z"}
{"aid":"http://arxiv.org/abs/2504.01654v1","title":"Bubble Clustering Decoder for Quantum Topological Codes","summary":"Quantum computers are highly vulnerable to noise, necessitating the use of\nerror-correcting codes to protect stored data. Errors must be continuously\ncorrected over time to counteract decoherence using appropriate decoders.\nTherefore, fast decoding strategies capable of handling real-time syndrome\nextraction are crucial for achieving fault-tolerant quantum computing. In this\npaper, we introduce the bubble clustering (BC) decoder for quantum surface\ncodes, which serves as a low-latency replacement for MWPM, achieving\nsignificantly faster execution at the cost of a slight performance degradation.\nThis speed boost is obtained leveraging an efficient cluster generation based\non bubbles centered on defects, and avoiding the computational overhead\nassociated with cluster growth and merging phases, commonly adopted in\ntraditional decoders. Our complexity analysis reveals that the proposed decoder\noperates with a complexity on the order of the square of the number of defects.\nFor moderate physical error rates, this is equivalent to linear complexity in\nthe number of data qubits.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T12:02:34Z"}
{"aid":"http://arxiv.org/abs/2504.01656v1","title":"Probabilistic plugging of airways by sliding mucus films","summary":"When do mucus films plug lung airways? Using reduced-order simulations of a\nlarge ensemble of randomly perturbed films, we show that the answer is not\ndetermined by just the film's volume. While very thin films always stay open\nand very thick films always plug, we find a range of intermediate films for\nwhich plugging is uncertain. The fastest-growing linear mode of the\nRayleigh-Plateau instability ensures that the film's volume is divided among\nmultiple humps. However, the nonlinear growth of these humps can occur\nunevenly, due to spontaneous axial sliding -- a lucky hump can sweep up a\ndisproportionate share of the film's volume and so form a plug. This\nsliding-induced plugging is robust and prevails with or without gravitational\nand ciliary transport.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,nlin.PS","published":"2025-04-02T12:04:44Z"}
{"aid":"http://arxiv.org/abs/2504.01668v1","title":"Overlap-Aware Feature Learning for Robust Unsupervised Domain Adaptation\n  for 3D Semantic Segmentation","summary":"3D point cloud semantic segmentation (PCSS) is a cornerstone for\nenvironmental perception in robotic systems and autonomous driving, enabling\nprecise scene understanding through point-wise classification. While\nunsupervised domain adaptation (UDA) mitigates label scarcity in PCSS, existing\nmethods critically overlook the inherent vulnerability to real-world\nperturbations (e.g., snow, fog, rain) and adversarial distortions. This work\nfirst identifies two intrinsic limitations that undermine current PCSS-UDA\nrobustness: (a) unsupervised features overlap from unaligned boundaries in\nshared-class regions and (b) feature structure erosion caused by\ndomain-invariant learning that suppresses target-specific patterns. To address\nthe proposed problems, we propose a tripartite framework consisting of: 1) a\nrobustness evaluation model quantifying resilience against adversarial\nattack/corruption types through robustness metrics; 2) an invertible attention\nalignment module (IAAM) enabling bidirectional domain mapping while preserving\ndiscriminative structure via attention-guided overlap suppression; and 3) a\ncontrastive memory bank with quality-aware contrastive learning that\nprogressively refines pseudo-labels with feature quality for more\ndiscriminative representations. Extensive experiments on\nSynLiDAR-to-SemanticPOSS adaptation demonstrate a maximum mIoU improvement of\n14.3\\% under adversarial attack.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-02T12:16:23Z"}
{"aid":"http://arxiv.org/abs/2504.01675v1","title":"Einstein's elevator and the principle of equivalence","summary":"We outlines here the design, execution, and educational outcomes of an\nintervention inspired by Einstein's elevator thought experiment, intended to\nintroduce secondary school students to the principle of equivalence, which is\nat the basis of the theory of General Relativity. We build an experimental\nversion of Einstein's elevator, which simulated the effects of free-fall in an\naccelerated reference frame: a detailed description of the experimental\napparatus and its construction is provided, highlighting the challenges and\ninnovations in creating a simple yet functional setup using everyday materials.","main_category":"physics.ed-ph","categories":"physics.ed-ph","published":"2025-04-02T12:25:08Z"}
{"aid":"http://arxiv.org/abs/2504.01708v1","title":"TransforMerger: Transformer-based Voice-Gesture Fusion for Robust\n  Human-Robot Communication","summary":"As human-robot collaboration advances, natural and flexible communication\nmethods are essential for effective robot control. Traditional methods relying\non a single modality or rigid rules struggle with noisy or misaligned data as\nwell as with object descriptions that do not perfectly fit the predefined\nobject names (e.g. 'Pick that red object'). We introduce TransforMerger, a\ntransformer-based reasoning model that infers a structured action command for\nrobotic manipulation based on fused voice and gesture inputs. Our approach\nmerges multimodal data into a single unified sentence, which is then processed\nby the language model. We employ probabilistic embeddings to handle uncertainty\nand we integrate contextual scene understanding to resolve ambiguous references\n(e.g., gestures pointing to multiple objects or vague verbal cues like \"this\").\nWe evaluate TransforMerger in simulated and real-world experiments,\ndemonstrating its robustness to noise, misalignment, and missing information.\nOur results show that TransforMerger outperforms deterministic baselines,\nespecially in scenarios requiring more contextual knowledge, enabling more\nrobust and flexible human-robot communication. Code and datasets are available\nat: http://imitrob.ciirc.cvut.cz/publications/transformerger.","main_category":"cs.RO","categories":"cs.RO,cs.HC,cs.LG","published":"2025-04-02T13:15:59Z"}
{"aid":"http://arxiv.org/abs/2504.01719v1","title":"Beyond Non-Expert Demonstrations: Outcome-Driven Action Constraint for\n  Offline Reinforcement Learning","summary":"We address the challenge of offline reinforcement learning using realistic\ndata, specifically non-expert data collected through sub-optimal behavior\npolicies. Under such circumstance, the learned policy must be safe enough to\nmanage \\textit{distribution shift} while maintaining sufficient flexibility to\ndeal with non-expert (bad) demonstrations from offline data.To tackle this\nissue, we introduce a novel method called Outcome-Driven Action Flexibility\n(ODAF), which seeks to reduce reliance on the empirical action distribution of\nthe behavior policy, hence reducing the negative impact of those bad\ndemonstrations.To be specific, a new conservative reward mechanism is developed\nto deal with {\\it distribution shift} by evaluating actions according to\nwhether their outcomes meet safety requirements - remaining within the state\nsupport area, rather than solely depending on the actions' likelihood based on\noffline data.Besides theoretical justification, we provide empirical evidence\non widely used MuJoCo and various maze benchmarks, demonstrating that our ODAF\nmethod, implemented using uncertainty quantification techniques, effectively\ntolerates unseen transitions for improved \"trajectory stitching,\" while\nenhancing the agent's ability to learn from realistic non-expert data.","main_category":"cs.LG","categories":"cs.LG,cs.RO","published":"2025-04-02T13:27:44Z"}
{"aid":"http://arxiv.org/abs/2504.01737v1","title":"Enlightenment Period Improving DNN Performance","summary":"In the early stage of deep neural network training, the loss decreases\nrapidly before gradually leveling off. Extensive research has shown that during\nthis stage, the model parameters undergo significant changes and their\ndistribution is largely established. Existing studies suggest that the\nintroduction of noise during early training can degrade model performance. We\nidentify a critical \"enlightenment period\" encompassing up to the first 4% of\nthe training cycle (1--20 epochs for 500-epoch training schedules), a phase\ncharacterized by intense parameter fluctuations and heightened noise\nsensitivity. Our findings reveal that strategically reducing noise during this\nbrief phase--by disabling data augmentation techniques such as Mixup or\nremoving high-loss samples--leads to statistically significant improvements in\nmodel performance. This work opens new avenues for exploring the relationship\nbetween the enlightenment period and network training dynamics across diverse\nmodel architectures and tasks.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T13:49:31Z"}
{"aid":"http://arxiv.org/abs/2504.01747v1","title":"The untangling number of 3-periodic tangles","summary":"The entanglement of curves within a 3-periodic box provides a model for\ncomplicated space-filling entangled structures occurring in biological\nmaterials and structural chemistry. Quantifying the complexity of the\nentanglement within these models enhances the characterisation of these\nstructures. In this paper, we introduce a new measure of entanglement\ncomplexity through the untangling number, reminiscent of the unknotting number\nin knot theory. The untangling number quantifies the minimum distance between a\ngiven 3-periodic structure and its least tangled version, called ground state,\nthrough a sequence of operations in a diagrammatic representation of the\nstructure. For entanglements that consist of only infinite open curves, we show\nthat the generic ground states of these structures are crystallographic rod\npackings, well-known in structural chemistry.","main_category":"math.GT","categories":"math.GT","published":"2025-04-02T14:00:14Z"}
{"aid":"http://arxiv.org/abs/2504.01773v1","title":"Budget-Feasible Contracts","summary":"The problem of computing near-optimal contracts in combinatorial settings has\nrecently attracted significant interest in the computer science community.\nPrevious work has provided a rich body of structural and algorithmic insights\ninto this problem. However, most of these results rely on the assumption that\nthe principal has an unlimited budget for incentivizing agents, an assumption\nthat is often unrealistic in practice. This motivates the study of the optimal\ncontract problem under budget constraints. We study multi-agent contracts with\nbudget constraints under both binary and combinatorial actions. For binary\nactions, our contribution is threefold. First, we generalize all previously\nknown approximation guarantees on the principal's revenue to budgeted settings.\nSecond, through the lens of budget constraints, we uncover insightful\nconnections between the standard objective of the principal's revenue and other\nobjectives. We identify a broad class of objectives, which we term BEST\nobjectives, including reward, social welfare, and revenue, and show that they\nare all equivalent (up to a constant factor), leading to approximation\nguarantees for all BEST objectives. Third, we introduce the price of frugality,\nwhich quantifies the loss due to budget constraints, and establish near-tight\nbounds on this measure, providing deeper insights into the tradeoffs between\nbudgets and incentives. For combinatorial actions, we establish a strong\nnegative result. Specifically, we show that in a budgeted setting with\nsubmodular rewards, no finite approximation is possible to any BEST objective.\nThis stands in contrast to the unbudgeted setting with submodular rewards,\nwhere a polynomial-time constant-factor approximation is known for revenue. On\nthe positive side, for gross substitutes rewards, we recover our binary-actions\nresults, obtaining a constant-factor approximation for all BEST objectives.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-02T14:32:39Z"}
{"aid":"http://arxiv.org/abs/2504.01785v1","title":"Time-optimal single-scalar control on a qubit of unitary dynamics","summary":"Optimal control theory is applied to analyze the time-optimal solution with a\nsingle scalar control knob in a two-level quantum system without quantum\ndecoherence. Emphasis is \\change{placed} on the dependence on the maximum\ncontrol strength $u_\\text{max}$. General constraints on the optimal protocol\nare derived and used to rigorously parameterize the time-optimal solution. Two\nconcrete problems are investigated. For generic state preparation problems,\nboth multiple bang-bang and bang-singular-bang are legitimate and should be\nconsidered. Generally, the optimal is bang-bang for small $u_\\text{max}$, and\nthere exists a state-dependent critical amplitude above which singular control\nemerges. For the X-gate operation of a qubit, the optimal protocol \\change{is\nexclusively} multiple bang-bang. The minimum gate time is about 80\\% of that\nbased on the resonant Rabi $\\pi$-pulse over a wide range of control strength;\nin the $u_\\text{max} \\rightarrow 0$ limit this ratio is derived to be $\\pi/4$.\nTo develop practically feasible protocols, we present methods to smooth the\nabrupt changes in the bang-bang control while preserving perfect gate fidelity.\n\\change{The presence of bang-bang segments in the time-optimal protocol}\nindicates that the high-frequency components and a full calculation (instead of\nthe commonly adopted Rotating Wave Approximation) are essential for the\nultimate quantum speed limit.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T14:48:50Z"}
{"aid":"http://arxiv.org/abs/2504.01803v1","title":"DISINFOX: an open-source threat exchange platform serving intelligence\n  on disinformation and influence operations","summary":"This paper introduces DISINFOX, an open-source threat intelligence exchange\nplatform for the structured collection, management, and dissemination of\ndisinformation incidents and influence operations. Analysts can upload and\ncorrelate information manipulation and interference incidents, while clients\ncan access and analyze the data through an interactive web interface or\nprogrammatically via a public API. This facilitates integration with other\nvendors, providing a unified view of cybersecurity and disinformation events.\n  The solution is fully containerized using Docker, comprising a web-based\nfrontend for user interaction, a backend REST API for managing core\nfunctionalities, and a public API for structured data retrieval, enabling\nseamless integration with existing Cyber Threat Intelligence (CTI) workflows.\nIn particular, DISINFOX models the incidents through DISARM Tactics,\nTechniques, and Procedures (TTPs), a MITRE ATT&CK-like framework for\ndisinformation, with a custom data model based on the Structured Threat\nInformation eXpression (STIX2) standard.\n  As an open-source solution, DISINFOX provides a reproducible and extensible\nhub for researchers, analysts, and policymakers seeking to enhance the\ndetection, investigation, and mitigation of disinformation threats. The\nintelligence generated from a custom dataset has been tested and utilized by a\nlocal instance of OpenCTI, a mature CTI platform, via a custom-built connector,\nvalidating the platform with the exchange of more than 100 disinformation\nincidents.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-02T15:11:43Z"}
{"aid":"http://arxiv.org/abs/2504.01805v1","title":"Spatial-R1: Enhancing MLLMs in Video Spatial Reasoning","summary":"Enhancing the spatial reasoning capabilities of Multi-modal Large Language\nModels (MLLMs) for video understanding is crucial yet challenging. We present\nSpatial-R1, a targeted approach involving two key contributions: the curation\nof SR, a new video spatial reasoning dataset from ScanNet with automatically\ngenerated QA pairs across seven task types, and the application of\nTask-Specific Group Relative Policy Optimization (GRPO) for fine-tuning. By\ntraining the Qwen2.5-VL-7B-Instruct model on SR using GRPO, Spatial-R1\nsignificantly advances performance on the VSI-Bench benchmark, achieving a\n7.4\\% gain over the baseline and outperforming strong contemporary models. This\nwork validates the effectiveness of specialized data curation and optimization\ntechniques for improving complex spatial reasoning in video MLLMs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T15:12:17Z"}
{"aid":"http://arxiv.org/abs/2504.01850v1","title":"Code Red! On the Harmfulness of Applying Off-the-shelf Large Language\n  Models to Programming Tasks","summary":"Nowadays, developers increasingly rely on solutions powered by Large Language\nModels (LLM) to assist them with their coding tasks. This makes it crucial to\nalign these tools with human values to prevent malicious misuse. In this paper,\nwe propose a comprehensive framework for assessing the potential harmfulness of\nLLMs within the software engineering domain. We begin by developing a taxonomy\nof potentially harmful software engineering scenarios and subsequently, create\na dataset of prompts based on this taxonomy. To systematically assess the\nresponses, we design and validate an automatic evaluator that classifies the\noutputs of a variety of LLMs both open-source and closed-source models, as well\nas general-purpose and code-specific LLMs. Furthermore, we investigate the\nimpact of models size, architecture family, and alignment strategies on their\ntendency to generate harmful content. The results show significant disparities\nin the alignment of various LLMs for harmlessness. We find that some models and\nmodel families, such as Openhermes, are more harmful than others and that\ncode-specific models do not perform better than their general-purpose\ncounterparts. Notably, some fine-tuned models perform significantly worse than\ntheir base-models due to their design choices. On the other side, we find that\nlarger models tend to be more helpful and are less likely to respond with\nharmful information. These results highlight the importance of targeted\nalignment strategies tailored to the unique challenges of software engineering\ntasks and provide a foundation for future work in this critical area.","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-02T16:00:14Z"}
{"aid":"http://arxiv.org/abs/2504.01935v1","title":"Critical Thinking: Which Kinds of Complexity Govern Optimal Reasoning\n  Length?","summary":"Large language models (LLMs) often benefit from verbalized reasoning at\ninference time, but it remains unclear which aspects of task difficulty these\nextra reasoning tokens address. To investigate this question, we formalize a\nframework using deterministic finite automata (DFAs). DFAs offer a formalism\nthrough which we can characterize task complexity through measurable properties\nsuch as run length (number of reasoning steps required) and state-space size\n(decision complexity). We first show that across different tasks and models of\ndifferent sizes and training paradigms, there exists an optimal amount of\nreasoning tokens such that the probability of producing a correct solution is\nmaximized. We then investigate which properties of complexity govern this\ncritical length: we find that task instances with longer corresponding\nunderlying DFA runs (i.e. demand greater latent state-tracking requirements)\ncorrelate with longer reasoning lengths, but, surprisingly, that DFA size (i.e.\nstate-space complexity) does not. We then demonstrate an implication of these\nfindings: being able to predict the optimal number of reasoning tokens for new\nproblems and filtering out non-optimal length answers results in consistent\naccuracy improvements.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-02T17:45:58Z"}
{"aid":"http://arxiv.org/abs/2504.01955v1","title":"Scene-Centric Unsupervised Panoptic Segmentation","summary":"Unsupervised panoptic segmentation aims to partition an image into\nsemantically meaningful regions and distinct object instances without training\non manually annotated data. In contrast to prior work on unsupervised panoptic\nscene understanding, we eliminate the need for object-centric training data,\nenabling the unsupervised understanding of complex scenes. To that end, we\npresent the first unsupervised panoptic method that directly trains on\nscene-centric imagery. In particular, we propose an approach to obtain\nhigh-resolution panoptic pseudo labels on complex scene-centric data, combining\nvisual representations, depth, and motion cues. Utilizing both pseudo-label\ntraining and a panoptic self-training strategy yields a novel approach that\naccurately predicts panoptic segmentation of complex scenes without requiring\nany human annotations. Our approach significantly improves panoptic quality,\ne.g., surpassing the recent state of the art in unsupervised panoptic\nsegmentation on Cityscapes by 9.4% points in PQ.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T17:58:46Z"}
{"aid":"http://arxiv.org/abs/2504.02211v1","title":"FT-Transformer: Resilient and Reliable Transformer with End-to-End Fault\n  Tolerant Attention","summary":"Transformer models leverage self-attention mechanisms to capture complex\ndependencies, demonstrating exceptional performance in various applications.\nHowever, the long-duration high-load computations required for model inference\nimpose stringent reliability demands on the computing platform, as soft errors\nthat occur during execution can significantly degrade model performance.\nExisting fault tolerance methods protect each operation separately using\ndecoupled kernels, incurring substantial computational and memory overhead. In\nthis paper, we propose a novel error-resilient framework for Transformer\nmodels, integrating end-to-end fault tolerant attention (EFTA) to improve\ninference reliability against soft errors. Our approach enables error detection\nand correction within a fully fused attention kernel, reducing redundant data\naccess and thereby mitigating memory faults. To further enhance error coverage\nand reduce overhead, we design a hybrid fault tolerance scheme tailored for the\nEFTA, introducing for the first time: 1) architecture-aware algorithm-based\nfault tolerance (ABFT) using tensor checksum, which minimizes inter-thread\ncommunication overhead on tensor cores during error detection; 2) selective\nneuron value restriction, which selectively applies adaptive fault tolerance\nconstraints to neuron values, balancing error coverage and overhead; 3) unified\nverification, reusing checksums to streamline multiple computation steps into a\nsingle verification process. Experimental results show that EFTA achieves up to\n7.56x speedup over traditional methods with an average fault tolerance overhead\nof 13.9%.","main_category":"cs.DC","categories":"cs.DC,cs.AI,cs.LG","published":"2025-04-03T02:05:08Z"}
{"aid":"http://arxiv.org/abs/2504.02230v1","title":"An exact five dimensional Weyl-Geometry Gauss-Bonnet Black Hole","summary":"We present a new exact black hole solution of a 5-dimensional Weyl-geometry\nGauss-Bonnet theory of gravity. The Euclidean sector defines a fully regular\nmetric coupled to the Weyl vector field. The Euclidean action and entropy are\ncomputed, with the latter following the simple $A/4$ form plus a term linear in\nthe horizon radius, characteristic of Gauss-Bonnet couplings.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-03T02:50:31Z"}
{"aid":"http://arxiv.org/abs/2504.02244v1","title":"SocialGesture: Delving into Multi-person Gesture Understanding","summary":"Previous research in human gesture recognition has largely overlooked\nmulti-person interactions, which are crucial for understanding the social\ncontext of naturally occurring gestures. This limitation in existing datasets\npresents a significant challenge in aligning human gestures with other\nmodalities like language and speech. To address this issue, we introduce\nSocialGesture, the first large-scale dataset specifically designed for\nmulti-person gesture analysis. SocialGesture features a diverse range of\nnatural scenarios and supports multiple gesture analysis tasks, including\nvideo-based recognition and temporal localization, providing a valuable\nresource for advancing the study of gesture during complex social interactions.\nFurthermore, we propose a novel visual question answering (VQA) task to\nbenchmark vision language models'(VLMs) performance on social gesture\nunderstanding. Our findings highlight several limitations of current gesture\nrecognition models, offering insights into future directions for improvement in\nthis field. SocialGesture is available at\nhuggingface.co/datasets/IrohXu/SocialGesture.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T03:21:06Z"}
{"aid":"http://arxiv.org/abs/2504.02256v1","title":"A direct algebraic proof for the non-positivity of Liouvillian\n  eigenvalues in Markovian quantum dynamics","summary":"Markovian open quantum systems are described by the Lindblad master equation\n$\\partial_t\\rho =\\mathcal{L}(\\rho)$, where $\\rho$ denotes the system's density\noperator and $\\mathcal{L}$ the Liouville super-operator, which is also known as\nthe Liouvillian. For systems with a finite-dimensional Hilbert space, it is a\nfundamental property of the Liouvillian, that the real-parts of all its\neigenvalues are non-positive which, in physical terms, corresponds to the\nstability of the system. The usual argument for this property is indirect,\nusing that $\\mathcal{L}$ generates a quantum channel and that quantum channels\nare contractive. We provide a direct algebraic proof based on the Lindblad form\nof Liouvillians.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-03T03:54:25Z"}
{"aid":"http://arxiv.org/abs/2504.02262v1","title":"Predictive modeling of altitude resolved greenline airglow emission\n  (557.7 nm) in the MLT region","summary":"Atomic oxygen is a critical and highly reactive chemical species responsible\nfor key physical and chemical processes in the mesosphere and lower\nthermosphere.","main_category":"physics.space-ph","categories":"physics.space-ph","published":"2025-04-03T04:15:56Z"}
{"aid":"http://arxiv.org/abs/2504.02268v1","title":"Advancing Semantic Caching for LLMs with Domain-Specific Embeddings and\n  Synthetic Data","summary":"This report investigates enhancing semantic caching effectiveness by\nemploying specialized, fine-tuned embedding models. Semantic caching relies on\nembedding similarity rather than exact key matching, presenting unique\nchallenges in balancing precision, query latency, and computational efficiency.\nWe propose leveraging smaller, domain-specific embedding models, fine-tuned\nwith targeted real-world and synthetically generated datasets. Our empirical\nevaluations demonstrate that compact embedding models fine-tuned for just one\nepoch on specialized datasets significantly surpass both state-of-the-art\nopen-source and proprietary alternatives in precision and recall. Moreover, we\nintroduce a novel synthetic data generation pipeline for the semantic cache\nthat mitigates the challenge of limited domain-specific annotated data, further\nboosting embedding performance. Our approach effectively balances computational\noverhead and accuracy, establishing a viable and efficient strategy for\npractical semantic caching implementations.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-03T04:27:02Z"}
{"aid":"http://arxiv.org/abs/2504.02272v1","title":"Generative Classifier for Domain Generalization","summary":"Domain generalization (DG) aims to improve the generalizability of computer\nvision models toward distribution shifts. The mainstream DG methods focus on\nlearning domain invariance, however, such methods overlook the potential\ninherent in domain-specific information. While the prevailing practice of\ndiscriminative linear classifier has been tailored to domain-invariant\nfeatures, it struggles when confronted with diverse domain-specific\ninformation, e.g., intra-class shifts, that exhibits multi-modality. To address\nthese issues, we explore the theoretical implications of relying on domain\ninvariance, revealing the crucial role of domain-specific information in\nmitigating the target risk for DG. Drawing from these insights, we propose\nGenerative Classifier-driven Domain Generalization (GCDG), introducing a\ngenerative paradigm for the DG classifier based on Gaussian Mixture Models\n(GMMs) for each class across domains. GCDG consists of three key modules:\nHeterogeneity Learning Classifier~(HLC), Spurious Correlation Blocking~(SCB),\nand Diverse Component Balancing~(DCB). Concretely, HLC attempts to model the\nfeature distributions and thereby capture valuable domain-specific information\nvia GMMs. SCB identifies the neural units containing spurious correlations and\nperturbs them, mitigating the risk of HLC learning spurious patterns.\nMeanwhile, DCB ensures a balanced contribution of components in HLC, preventing\nthe underestimation or neglect of critical components. In this way, GCDG excels\nin capturing the nuances of domain-specific information characterized by\ndiverse distributions. GCDG demonstrates the potential to reduce the target\nrisk and encourage flat minima, improving the generalizability. Extensive\nexperiments show GCDG's comparable performance on five DG benchmarks and one\nface anti-spoofing dataset, seamlessly integrating into existing DG methods\nwith consistent improvements.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T04:38:33Z"}
{"aid":"http://arxiv.org/abs/2504.02279v1","title":"MultiTSF: Transformer-based Sensor Fusion for Human-Centric Multi-view\n  and Multi-modal Action Recognition","summary":"Action recognition from multi-modal and multi-view observations holds\nsignificant potential for applications in surveillance, robotics, and smart\nenvironments. However, existing methods often fall short of addressing\nreal-world challenges such as diverse environmental conditions, strict sensor\nsynchronization, and the need for fine-grained annotations. In this study, we\npropose the Multi-modal Multi-view Transformer-based Sensor Fusion (MultiTSF).\nThe proposed method leverages a Transformer-based to dynamically model\ninter-view relationships and capture temporal dependencies across multiple\nviews. Additionally, we introduce a Human Detection Module to generate\npseudo-ground-truth labels, enabling the model to prioritize frames containing\nhuman activity and enhance spatial feature learning. Comprehensive experiments\nconducted on our in-house MultiSensor-Home dataset and the existing MM-Office\ndataset demonstrate that MultiTSF outperforms state-of-the-art methods in both\nvideo sequence-level and frame-level action recognition settings.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T05:04:05Z"}
{"aid":"http://arxiv.org/abs/2504.02280v1","title":"LLM-Guided Evolution: An Autonomous Model Optimization for Object\n  Detection","summary":"In machine learning, Neural Architecture Search (NAS) requires domain\nknowledge of model design and a large amount of trial-and-error to achieve\npromising performance. Meanwhile, evolutionary algorithms have traditionally\nrelied on fixed rules and pre-defined building blocks. The Large Language Model\n(LLM)-Guided Evolution (GE) framework transformed this approach by\nincorporating LLMs to directly modify model source code for image\nclassification algorithms on CIFAR data and intelligently guide mutations and\ncrossovers. A key element of LLM-GE is the \"Evolution of Thought\" (EoT)\ntechnique, which establishes feedback loops, allowing LLMs to refine their\ndecisions iteratively based on how previous operations performed. In this\nstudy, we perform NAS for object detection by improving LLM-GE to modify the\narchitecture of You Only Look Once (YOLO) models to enhance performance on the\nKITTI dataset. Our approach intelligently adjusts the design and settings of\nYOLO to find the optimal algorithms against objective such as detection\naccuracy and speed. We show that LLM-GE produced variants with significant\nperformance improvements, such as an increase in Mean Average Precision from\n92.5% to 94.5%. This result highlights the flexibility and effectiveness of\nLLM-GE on real-world challenges, offering a novel paradigm for automated\nmachine learning that combines LLM-driven reasoning with evolutionary\nstrategies.","main_category":"cs.NE","categories":"cs.NE,cs.CV","published":"2025-04-03T05:06:06Z"}
{"aid":"http://arxiv.org/abs/2504.02285v1","title":"Tree-based Models for Vertical Federated Learning: A Survey","summary":"Tree-based models have achieved great success in a wide range of real-world\napplications due to their effectiveness, robustness, and interpretability,\nwhich inspired people to apply them in vertical federated learning (VFL)\nscenarios in recent years. In this paper, we conduct a comprehensive study to\ngive an overall picture of applying tree-based models in VFL, from the\nperspective of their communication and computation protocols. We categorize\ntree-based models in VFL into two types, i.e., feature-gathering models and\nlabel-scattering models, and provide a detailed discussion regarding their\ncharacteristics, advantages, privacy protection mechanisms, and applications.\nThis study also focuses on the implementation of tree-based models in VFL,\nsummarizing several design principles for better satisfying various\nrequirements from both academic research and industrial deployment. We conduct\na series of experiments to provide empirical observations on the differences\nand advances of different types of tree-based models.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-03T05:16:09Z"}
{"aid":"http://arxiv.org/abs/2504.02294v1","title":"Search for Fast Radio Bursts and radio pulsars from pulsing\n  Ultraluminous X-ray Sources","summary":"We conducted targeted fast radio burst (FRB) and pulsar searches on eight\npulsing ultraluminous X-ray sources (PULXs) using the Five-hundred-meter\nAperture Spherical Radio Telescope (FAST) and the Parkes 64-meter Radio\nTelescope (Murriyang) to investigate whether PULXs could be progenitors of\nFRBs. FAST carried out 12 observations of four PULXs, totaling 8 hours, while\nParkes conducted 12 observations of the remaining four PULXs, totaling 11\nhours. No significant signals were detected through single-pulse and periodic\nsearches, covering a dispersion measure (DM) range of 0-5000 pc cm$^{-3}$,\nplacing stringent upper limits on the radio flux density from these sources.\nThe results imply that accretion processes and dense stellar winds in PULXs\nlikely suppress or attenuate potential coherent emission in radio band.\nAdditionally, the beaming factor and luminosity of FRBs associated with PULXs,\nas well as the highly relativistic and magnetized nature of their outflows, may\nlimit detectability. Non-detection yielded from the observations covering the\nfull orbital phases of PULXs can also constrain the theoretical models that\nlink FRB emission to highly magnetized neutron stars in binary systems.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-03T05:49:34Z"}
{"aid":"http://arxiv.org/abs/2504.02323v1","title":"CoTAL: Human-in-the-Loop Prompt Engineering, Chain-of-Thought Reasoning,\n  and Active Learning for Generalizable Formative Assessment Scoring","summary":"Large language models (LLMs) have created new opportunities to assist\nteachers and support student learning. Methods such as chain-of-thought (CoT)\nprompting enable LLMs to grade formative assessments in science, providing\nscores and relevant feedback to students. However, the extent to which these\nmethods generalize across curricula in multiple domains (such as science,\ncomputing, and engineering) remains largely untested. In this paper, we\nintroduce Chain-of-Thought Prompting + Active Learning (CoTAL), an LLM-based\napproach to formative assessment scoring that (1) leverages Evidence-Centered\nDesign (ECD) principles to develop curriculum-aligned formative assessments and\nrubrics, (2) applies human-in-the-loop prompt engineering to automate response\nscoring, and (3) incorporates teacher and student feedback to iteratively\nrefine assessment questions, grading rubrics, and LLM prompts for automated\ngrading. Our findings demonstrate that CoTAL improves GPT-4's scoring\nperformance, achieving gains of up to 24.5% over a non-prompt-engineered\nbaseline. Both teachers and students view CoTAL as effective in scoring and\nexplaining student responses, each providing valuable refinements to enhance\ngrading accuracy and explanation quality.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T06:53:34Z"}
{"aid":"http://arxiv.org/abs/2504.02363v1","title":"Double groupoids of composites: applications to uniformity","summary":"In this paper we present a geometrical framework to study the uniformity of a\ncomposite material by means of double groupoid theory. The notions of vertical\nand horizontal uniformity are introduced, as well as other weaker ones that\nallows us to study other possible notions of more general uniformity.","main_category":"math-ph","categories":"math-ph,math.MP","published":"2025-04-03T07:53:36Z"}
{"aid":"http://arxiv.org/abs/2504.02380v1","title":"Beyond Asymptotics: Targeted exploration with finite-sample guarantees","summary":"In this paper, we introduce a targeted exploration strategy for the\nnon-asymptotic, finite-time case. The proposed strategy is applicable to\nuncertain linear time-invariant systems subject to sub-Gaussian disturbances.\nAs the main result, the proposed approach provides a priori guarantees,\nensuring that the optimized exploration inputs achieve a desired accuracy of\nthe model parameters. The technical derivation of the strategy (i) leverages\nexisting non-asymptotic identification bounds with self-normalized martingales,\n(ii) utilizes spectral lines to predict the effect of sinusoidal excitation,\nand (iii) effectively accounts for spectral transient error and parametric\nuncertainty. A numerical example illustrates how the finite exploration time\ninfluence the required exploration energy.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-03T08:17:17Z"}
{"aid":"http://arxiv.org/abs/2504.02384v1","title":"Resistive switching characteristics of Cu/MgO/MoS2/Cu structure","summary":"During the study of resistive switching devices, researchers have found that\nthe influence of the insertion layer cannot be ignored. Many reports have\nconfirmed that the appropriate insertion layer can significantly improve the\nperformance of the resistive switching devices. Therefore, in this work, we use\nmagnetron sputtering to fabricate three devices: Cu/MgO/Cu, Cu/MgO/MoS2/Cu and\nCu/MoS2/MgO/Cu. Through the characterization test of each device and the\nmeasurement of the I-V curve, it is found that the resistive switching\ncharacteristics of the Cu/MgO/Cu device will change greatly after adding an\nMoS2 insertion layer. The analysis results show that the inserted MoS2 layer\ndoes not change the main transmission mechanism (space charge limited\nconduction) of the device, but affects the regulating function of interfacial\npotential barrier, the effect also is related to the location of MoS2 inserted\ninto the layer. Among the Cu/MgO/Cu, Cu/MgO/MoS2/Cu and Cu/MoS2/MgO/Cu devices,\nthe Cu/MgO/MoS2/Cu device exhibits a larger switching ratio (about 103) and a\nlower reset voltage (about 0.21 V), which can be attributed to the regulation\nof the interface barrier between MgO and MoS2. In addition, when the MoS2 layer\nis inserted between the bottom electrodes Cu and MgO, the leakage current of\nthe device is significantly reduced. Therefore, Cu/MoS2/MgO/Cu device has the\nhighest commercial value from the point of view of practical applications.\nFinally, according to the XPS results and XRD results, we establish the\nconductive filament models for the three devices, and analyze the reasons for\nthe different resistive switching characteristics of the three devices.","main_category":"physics.app-ph","categories":"physics.app-ph,cond-mat.mtrl-sci","published":"2025-04-03T08:22:36Z"}
{"aid":"http://arxiv.org/abs/2504.02420v1","title":"On learning racing policies with reinforcement learning","summary":"Fully autonomous vehicles promise enhanced safety and efficiency. However,\nensuring reliable operation in challenging corner cases requires control\nalgorithms capable of performing at the vehicle limits. We address this\nrequirement by considering the task of autonomous racing and propose solving it\nby learning a racing policy using Reinforcement Learning (RL). Our approach\nleverages domain randomization, actuator dynamics modeling, and policy\narchitecture design to enable reliable and safe zero-shot deployment on a real\nplatform. Evaluated on the F1TENTH race car, our RL policy not only surpasses a\nstate-of-the-art Model Predictive Control (MPC), but, to the best of our\nknowledge, also represents the first instance of an RL policy outperforming\nexpert human drivers in RC racing. This work identifies the key factors driving\nthis performance improvement, providing critical insights for the design of\nrobust RL-based control strategies for autonomous vehicles.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-03T09:21:48Z"}
{"aid":"http://arxiv.org/abs/2504.02424v1","title":"Designing optimal elastic filaments for viscous propulsion","summary":"The propulsion of many eukaryotic cells is generated by flagella, flexible\nslender filaments that are actively oscillating in space and time. The dynamics\nof these biological appendages have inspired the design of many types of\nartificial microswimmers. The magnitude of the filament's viscous propulsion\ndepends on the time-varying shape of the filament, and that shape depends in\nturn on the spatial distribution of the bending rigidity of the filament. In\nthis work, we rigorously determine the relationship between the mechanical\n(bending) properties of the filament and the viscous thrust it produces using\nmathematical optimisation. Specifically, by considering a model system (a\nslender elastic filament with an oscillating slope at its base), we derive the\noptimal bending rigidity function along the filament that maximises the\ntime-averaged thrust produced by the actuated filament. Instead of prescribing\na specific functional form, we use functional optimisation and adjoint-based\nvariational calculus to formally establish the link between the distribution of\nbending rigidity and propulsion. The optimal rigidities are found to be stiff\nnear the base, and soft near the distal end, with a spatial distribution that\ndepends critically on the constraints used in the optimisation procedure. These\nfindings may guide the optimal design of future artificial swimmers.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.bio-ph","published":"2025-04-03T09:28:32Z"}
{"aid":"http://arxiv.org/abs/2504.02428v1","title":"Semigroup Congruences and Subsemigroups of the Direct Square","summary":"We investigate semigroups $S$ which have the property that every subsemigroup\nof $S\\times S$ which contains the diagonal $\\{ (s,s)\\colon s\\in S\\}$ is\nnecessarily a congruence on $S$. We call such $S$ a DSC semigroup. It is well\nknown that all finite groups are DSC, and easy to see that every DSC semigroup\nmust be simple. Building on this, we show that for broad classes of semigroups\n-- including periodic, stable, inverse and several well-known types of simple\nsemigroups -- the only DSC members are groups. However, it turns out that there\nexist non-group DSC semigroups, which we obtain utilising a construction\nintroduced by Byleen for the purpose of constructing interesting\ncongruence-free semigroups. Such examples can additionally be regular or\nbisimple.","main_category":"math.RA","categories":"math.RA,math.GR","published":"2025-04-03T09:33:50Z"}
{"aid":"http://arxiv.org/abs/2504.02462v1","title":"Gravitational Wave with Domain Wall Dominance","summary":"Domain walls (DWs) can be produced when a discrete symmetry is spontaneously\nbroken, and long-lived DWs can dominate the energy density of the universe. In\nthis work, we explore the possibility that a \"domain wall dominant (DWD)\" phase\nexisted in the early universe and ended with DW decay. During the DWD phase,\nthe universe undergoes a power-law accelerated expansion of the scale factor\nand exhibits temporal superhorizon evolution of the relevant frequency modes.\nWe show that this can lead to distinct features imprinted on the stochastic\ngravitational wave (GW) background. Our findings provide a comprehensive\nframework for evaluating GW emission associated with DWD, leading to\ndistinguishable long-lived DW-induced GWs from other cosmological sources, with\nsignificant implications for future GW observatories.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph,hep-th","published":"2025-04-03T10:28:48Z"}
{"aid":"http://arxiv.org/abs/2504.02522v1","title":"Charm: The Missing Piece in ViT fine-tuning for Image Aesthetic\n  Assessment","summary":"The capacity of Vision transformers (ViTs) to handle variable-sized inputs is\noften constrained by computational complexity and batch processing limitations.\nConsequently, ViTs are typically trained on small, fixed-size images obtained\nthrough downscaling or cropping. While reducing computational burden, these\nmethods result in significant information loss, negatively affecting tasks like\nimage aesthetic assessment. We introduce Charm, a novel tokenization approach\nthat preserves Composition, High-resolution, Aspect Ratio, and Multi-scale\ninformation simultaneously. Charm prioritizes high-resolution details in\nspecific regions while downscaling others, enabling shorter fixed-size input\nsequences for ViTs while incorporating essential information. Charm is designed\nto be compatible with pre-trained ViTs and their learned positional embeddings.\nBy providing multiscale input and introducing variety to input tokens, Charm\nimproves ViT performance and generalizability for image aesthetic assessment.\nWe avoid cropping or changing the aspect ratio to further preserve information.\nExtensive experiments demonstrate significant performance improvements on\nvarious image aesthetic and quality assessment datasets (up to 8.1 %) using a\nlightweight ViT backbone. Code and pre-trained models are available at\nhttps://github.com/FBehrad/Charm.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T12:19:04Z"}
{"aid":"http://arxiv.org/abs/2504.02534v1","title":"Delineate Anything: Resolution-Agnostic Field Boundary Delineation on\n  Satellite Imagery","summary":"The accurate delineation of agricultural field boundaries from satellite\nimagery is vital for land management and crop monitoring. However, current\nmethods face challenges due to limited dataset sizes, resolution discrepancies,\nand diverse environmental conditions. We address this by reformulating the task\nas instance segmentation and introducing the Field Boundary Instance\nSegmentation - 22M dataset (FBIS-22M), a large-scale, multi-resolution dataset\ncomprising 672,909 high-resolution satellite image patches (ranging from 0.25 m\nto 10 m) and 22,926,427 instance masks of individual fields, significantly\nnarrowing the gap between agricultural datasets and those in other computer\nvision domains. We further propose Delineate Anything, an instance segmentation\nmodel trained on our new FBIS-22M dataset. Our proposed model sets a new\nstate-of-the-art, achieving a substantial improvement of 88.5% in mAP@0.5 and\n103% in mAP@0.5:0.95 over existing methods, while also demonstrating\nsignificantly faster inference and strong zero-shot generalization across\ndiverse image resolutions and unseen geographic regions. Code, pre-trained\nmodels, and the FBIS-22M dataset are available at\nhttps://lavreniuk.github.io/Delineate-Anything.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T12:37:04Z"}
{"aid":"http://arxiv.org/abs/2504.02552v1","title":"Variational convergences under moving anisotropies","summary":"We study the asymptotic behaviour of sequences of integral functionals\ndepending on moving anisotropies. We introduce and describe the relevant\nfunctional setting, establishing uniform Meyers-Serrin type approximations,\nPoincar\\'e inequalities and compactness properties. We prove several\n$\\Gamma$-convergence results, and apply the latter to the study of\n$H$-convergence of anisotropic linear differential operators.","main_category":"math.AP","categories":"math.AP","published":"2025-04-03T13:06:41Z"}
{"aid":"http://arxiv.org/abs/2504.02553v1","title":"Exploring Individual Factors in the Adoption of LLMs for Specific\n  Software Engineering Tasks","summary":"The advent of Large Language Models (LLMs) is transforming software\ndevelopment, significantly enhancing software engineering processes. Research\nhas explored their role within development teams, focusing on specific tasks\nsuch as artifact generation, decision-making support, and information\nretrieval. Despite the growing body of work on LLMs in software engineering,\nmost studies have centered on broad adoption trends, neglecting the nuanced\nrelationship between individual cognitive and behavioral factors and their\nimpact on task-specific adoption. While factors such as perceived effort and\nperformance expectancy have been explored at a general level, their influence\non distinct software engineering tasks remains underexamined. This gap hinders\nthe development of tailored LLM-based systems (e.g., Generative AI Agents) that\nalign with engineers' specific needs and limits the ability of team leaders to\ndevise effective strategies for fostering LLM adoption in targeted workflows.\nThis study bridges this gap by surveying N=188 software engineers to test the\nrelationship between individual attributes related to technology adoption and\nLLM adoption across five key tasks, using structural equation modeling (SEM).\nThe Unified Theory of Acceptance and Use of Technology (UTAUT2) was applied to\ncharacterize individual adoption behaviors. The findings reveal that\ntask-specific adoption is influenced by distinct factors, some of which\nnegatively impact adoption when considered in isolation, underscoring the\ncomplexity of LLM integration in software engineering. To support effective\nadoption, this article provides actionable recommendations, such as seamlessly\nintegrating LLMs into existing development environments and encouraging\npeer-driven knowledge sharing to enhance information retrieval.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-03T13:07:04Z"}
{"aid":"http://arxiv.org/abs/2504.02575v1","title":"Assessing Geographical and Seasonal Influences on Energy Efficiency of\n  Electric Drayage Trucks","summary":"The electrification of heavy-duty vehicles is a critical pathway towards\nimproved energy efficiency of the freight sector. The current battery electric\ntruck technology poses several challenges to the operations of commercial\nvehicles, such as limited driving range, sensitivity to climate conditions, and\nlong recharging times. Estimating the energy consumption of heavy-duty electric\ntrucks is crucial to assess the feasibility of the fleet electrification and\nits impact on the electric grid. This paper focuses on developing a model-based\nsimulation approach to predict and analyze the energy consumption of drayage\ntrucks used in ports logistic operations, considering seasonal climate\nvariations and geographical characteristics. The paper includes results for\nthree major container ports within the United States, providing region-specific\ninsights into driving range, payload capacity, and charging infrastructure\nrequirements, which will inform decision-makers in integrating electric trucks\ninto the existing drayage operations and plan investments for electric grid\ndevelopment.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-03T13:39:21Z"}
{"aid":"http://arxiv.org/abs/2504.02599v1","title":"Technical Overview of Recent Developments in Small Modular Reactors in\n  the United States","summary":"Small modular reactors (SMRs) are a class of advanced nuclear fission\nreactors characterized by their compact core size (typically <300 MWe) and\npassive safety systems. Their modular design enables on-site assembly, making\nthem suitable for deployment in locations inaccessible to conventional\nlarge-scale reactors. With rising global energy demand, particularly driven by\nthe growth of AI, SMRs have recently gained attention as a potential solution\nfor powering data centers. This technical review aims to provide the public and\nrelevant stakeholders with a foundational understanding of SMR technology. It\nbegins with an overview of SMR concepts, historical context, and their current\nrole in the U.S. energy mix. Detailed technical summaries of nine selected SMR\ndesigns are then presented, covering core design, fuel systems, reactivity\ncontrol, and safety features. The report also outlines key regulatory\nframeworks, including 10 CFR Part 50, Part 52, and the technology-inclusive,\nrisk-informed, and performance-based framework currently under development.\nFinally, major U.S. programs and legislative efforts supporting SMR deployment\nover the past decade are summarized.","main_category":"physics.soc-ph","categories":"physics.soc-ph,physics.ins-det","published":"2025-04-03T14:01:32Z"}
{"aid":"http://arxiv.org/abs/2504.02634v1","title":"The FCC integrated programme: a physics manifesto","summary":"The FCC integrated programme comprises an $\\rm e^+e^-$ high-luminosity\ncircular collider that will produce very large samples of data in an energy\nrange $88 \\le \\sqrt{s} \\le 365$ GeV, followed by a high-energy $\\rm pp$ machine\nthat, with the current baseline plan, will operate at a collision energy of\naround 85 TeV and deliver datasets an order of magnitude larger than those of\nthe HL-LHC. This visionary project will allow for transformative measurements\nacross a very broad range of topics, which in almost all cases will exceed in\nsensitivity the projections of any other proposed facility, and simultaneously\nprovide the best possible opportunity for discovering physics beyond the\nStandard Model. The highlights of the physics programme are presented, together\nwith discussion on the key attributes of the integrated project that enable the\nphysics reach. It is noted that the baseline programme of FCC-ee, in\nparticular, is both flexible and extendable, and also that the synergy and\ncomplementarity of the electron and proton machines, and the sharing of a\ncommon infrastructure, provides a remarkably efficient, timely and\ncost-effective approach to addressing the most pressing open questions in\nelementary particle physics.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-03T14:31:24Z"}
{"aid":"http://arxiv.org/abs/2504.02667v1","title":"Compositionality Unlocks Deep Interpretable Models","summary":"We propose $\\chi$-net, an intrinsically interpretable architecture combining\nthe compositional multilinear structure of tensor networks with the\nexpressivity and efficiency of deep neural networks. $\\chi$-nets retain equal\naccuracy compared to their baseline counterparts. Our novel, efficient\ndiagonalisation algorithm, ODT, reveals linear low-rank structure in a\nmultilayer SVHN model. We leverage this toward formal weight-based\ninterpretability and model compression.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T15:07:54Z"}
{"aid":"http://arxiv.org/abs/2504.02694v1","title":"Semiparametric Counterfactual Regression","summary":"We study counterfactual regression, which aims to map input features to\noutcomes under hypothetical scenarios that differ from those observed in the\ndata. This is particularly useful for decision-making when adapting to sudden\nshifts in treatment patterns is essential. We propose a doubly robust-style\nestimator for counterfactual regression within a generalizable framework that\naccommodates a broad class of risk functions and flexible constraints, drawing\non tools from semiparametric theory and stochastic optimization. Our approach\nuses incremental interventions to enhance adaptability while maintaining\nconsistency with standard methods. We formulate the target estimand as the\noptimal solution to a stochastic optimization problem and develop an efficient\nestimation strategy, where we can leverage rapid development of modern\noptimization algorithms. We go on to analyze the rates of convergence and\ncharacterize the asymptotic distributions. Our analysis shows that the proposed\nestimators can achieve $\\sqrt{n}$-consistency and asymptotic normality for a\nbroad class of problems. Numerical illustrations highlight their effectiveness\nin adapting to unseen counterfactual scenarios while maintaining parametric\nconvergence rates.","main_category":"stat.ME","categories":"stat.ME,cs.LG,stat.ML","published":"2025-04-03T15:32:26Z"}
{"aid":"http://arxiv.org/abs/2504.02699v1","title":"An extension of smooth numbers: multiple dense divisibility","summary":"The $i$-tuply $y$-densely divisible numbers were introduced by a Polymath\nproject, as a weaker condition on the moduli than $y$-smoothness, in\ndistribution estimates for primes in arithmetic progressions. We obtain the\norder of magnitude of the count of these integers up to $x$, uniformly in $x$\nand $y$, for every fixed natural number $i$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-03T15:34:43Z"}
{"aid":"http://arxiv.org/abs/2504.02718v1","title":"A simple description of blow-up solutions through dynamics at infinity\n  in nonautonomous ODEs","summary":"A simple criterion of the existence of (type-I) blow-up solutions for\nnonautonomous ODEs is provided. In a previous study [Matsue, SIADS, 24(2025),\n415-456], geometric criteria for characterizing blow-up solutions for\nnonautonomous ODEs are provided by means of dynamics at infinity. The basic\nidea towards the present aim is to correspond such criteria to leading-term\nequations associated with blow-up ansatz characterizing multiple-order\nasymptotic expansions, which originated from the corresponding study developed\nin the framework of autonomous ODEs. Restricting our attention to constant\ncoefficients of leading terms of blow-ups, results involving the simple\ncriterion of blow-up characterizations in autonomous ODEs can be mimicked to\nnonautonomous ODEs.","main_category":"math.DS","categories":"math.DS,math.CA","published":"2025-04-03T16:02:39Z"}
{"aid":"http://arxiv.org/abs/2504.02743v1","title":"Sequential Binary Hypothesis Testing with Competing Agents under\n  Information Asymmetry","summary":"This paper concerns sequential hypothesis testing in competitive multi-agent\nsystems where agents exchange potentially manipulated information.\nSpecifically, a two-agent scenario is studied where each agent aims to\ncorrectly infer the true state of nature while optimizing decision speed and\naccuracy. At each iteration, agents collect private observations, update their\nbeliefs, and share (possibly corrupted) belief signals with their counterparts\nbefore deciding whether to stop and declare a state, or continue gathering more\ninformation. The analysis yields three main results: (1)~when agents share\ninformation strategically, the optimal signaling policy involves\nequal-probability randomization between truthful and inverted beliefs;\n(2)~agents maximize performance by relying solely on their own observations for\nbelief updating while using received information only to anticipate their\ncounterpart's stopping decision; and (3)~the agent reaching their confidence\nthreshold first cause the other agent to achieve a higher conditional\nprobability of error. Numerical simulations further demonstrate that agents\nwith higher KL divergence in their conditional distributions gain competitive\nadvantage. Furthermore, our results establish that information sharing --\ndespite strategic manipulation -- reduces overall system stopping time compared\nto non-interactive scenarios, which highlights the inherent value of\ncommunication even in this competitive setup.","main_category":"eess.SY","categories":"eess.SY,cs.MA,cs.SY,math.OC","published":"2025-04-03T16:30:40Z"}
{"aid":"http://arxiv.org/abs/2504.02776v1","title":"Bifurcations of the Hénon map with additive bounded noise","summary":"We numerically study bifurcations of attractors of the H\\'enon map with\nadditive bounded noise with spherical reach. The bifurcations are analysed\nusing a finite-dimensional boundary map. We distinguish between two types of\nbifurcations: topological bifurcations and boundary bifurcations. Topological\nbifurcations describe discontinuous changes of attractors and boundary\nbifurcations occur when singularities of an attractor's boundary are created or\ndestroyed. We identify correspondences between topological and boundary\nbifurcations of attractors and local and global bifurcations of the boundary\nmap.","main_category":"math.DS","categories":"math.DS","published":"2025-04-03T17:17:11Z"}
{"aid":"http://arxiv.org/abs/2504.02786v1","title":"Quantum maximally symmetric space-times","summary":"We show that 4-dimensional maximally symmetric spacetimes can be obtained\nfrom a coherent state quantisation of gravity, always resulting in geometries\nthat approach the Minkowski vacuum exponentially away from the radius of\ncurvature. A possible connection with the central charge in the AdS/CFT\ncorrespondence is also noted.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-03T17:30:31Z"}
{"aid":"http://arxiv.org/abs/2504.02792v1","title":"Unified World Models: Coupling Video and Action Diffusion for\n  Pretraining on Large Robotic Datasets","summary":"Imitation learning has emerged as a promising approach towards building\ngeneralist robots. However, scaling imitation learning for large robot\nfoundation models remains challenging due to its reliance on high-quality\nexpert demonstrations. Meanwhile, large amounts of video data depicting a wide\nrange of environments and diverse behaviors are readily available. This data\nprovides a rich source of information about real-world dynamics and\nagent-environment interactions. Leveraging this data directly for imitation\nlearning, however, has proven difficult due to the lack of action annotation\nrequired for most contemporary methods. In this work, we present Unified World\nModels (UWM), a framework that allows for leveraging both video and action data\nfor policy learning. Specifically, a UWM integrates an action diffusion process\nand a video diffusion process within a unified transformer architecture, where\nindependent diffusion timesteps govern each modality. We show that by simply\ncontrolling each diffusion timestep, UWM can flexibly represent a policy, a\nforward dynamics, an inverse dynamics, and a video generator. Through simulated\nand real-world experiments, we show that: (1) UWM enables effective pretraining\non large-scale multitask robot datasets with both dynamics and action\npredictions, resulting in more generalizable and robust policies than imitation\nlearning, (2) UWM naturally facilitates learning from action-free video data\nthrough independent control of modality-specific diffusion timesteps, further\nimproving the performance of finetuned policies. Our results suggest that UWM\noffers a promising step toward harnessing large, heterogeneous datasets for\nscalable robot learning, and provides a simple unification between the often\ndisparate paradigms of imitation learning and world modeling. Videos and code\nare available at https://weirdlabuw.github.io/uwm/.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.LG","published":"2025-04-03T17:38:59Z"}
{"aid":"http://arxiv.org/abs/2504.02809v1","title":"Fractional attractors in light of the latest ACT observations","summary":"In light of the latest results from ACT observations we review a class of\npotentials labeled as fractional attractors, that can originate from Palatini\ngravity. We show in a model independent way that this class of potentials\npredicts both a spectral index $n_s$ and a tensor-to-scalar ratio $r$ which fit\nthe $1\\sigma$ region of the combination ACT+Planck data for a wide choice of\nthe parameters. We also provide a numerical fit for the parameter space of this\nmodels in the case of a simple quadratic and quartic fractional potential.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-ph","published":"2025-04-03T17:53:22Z"}
{"aid":"http://arxiv.org/abs/2504.02817v1","title":"Efficient Autoregressive Shape Generation via Octree-Based Adaptive\n  Tokenization","summary":"Many 3D generative models rely on variational autoencoders (VAEs) to learn\ncompact shape representations. However, existing methods encode all shapes into\na fixed-size token, disregarding the inherent variations in scale and\ncomplexity across 3D data. This leads to inefficient latent representations\nthat can compromise downstream generation. We address this challenge by\nintroducing Octree-based Adaptive Tokenization, a novel framework that adjusts\nthe dimension of latent representations according to shape complexity. Our\napproach constructs an adaptive octree structure guided by a\nquadric-error-based subdivision criterion and allocates a shape latent vector\nto each octree cell using a query-based transformer. Building upon this\ntokenization, we develop an octree-based autoregressive generative model that\neffectively leverages these variable-sized representations in shape generation.\nExtensive experiments demonstrate that our approach reduces token counts by 50%\ncompared to fixed-size methods while maintaining comparable visual quality.\nWhen using a similar token length, our method produces significantly\nhigher-quality shapes. When incorporated with our downstream generative model,\nour method creates more detailed and diverse 3D content than existing\napproaches.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T17:57:52Z"}
{"aid":"http://arxiv.org/abs/2504.04728v1","title":"Exploring Kernel Transformations for Implicit Neural Representations","summary":"Implicit neural representations (INRs), which leverage neural networks to\nrepresent signals by mapping coordinates to their corresponding attributes,\nhave garnered significant attention. They are extensively utilized for image\nrepresentation, with pixel coordinates as input and pixel values as output. In\ncontrast to prior works focusing on investigating the effect of the model's\ninside components (activation function, for instance), this work pioneers the\nexploration of the effect of kernel transformation of input/output while\nkeeping the model itself unchanged. A byproduct of our findings is a simple yet\neffective method that combines scale and shift to significantly boost INR with\nnegligible computation overhead. Moreover, we present two perspectives, depth\nand normalization, to interpret the performance benefits caused by scale and\nshift transformation. Overall, our work provides a new avenue for future works\nto understand and improve INR through the lens of kernel transformation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T04:43:50Z"}
{"aid":"http://arxiv.org/abs/2504.04733v1","title":"Robustifying Approximate Bayesian Computation","summary":"Approximate Bayesian computation (ABC) is one of the most popular\n\"likelihood-free\" methods. These methods have been applied in a wide range of\nfields by providing solutions to intractable likelihood problems in which exact\nBayesian approaches are either infeasible or computationally costly. However,\nthe performance of ABC can be unreliable when dealing with model\nmisspecification. To circumvent the poor behavior of ABC in these settings, we\npropose a novel ABC approach that is robust to model misspecification. This new\nmethod can deliver more accurate statistical inference under model\nmisspecification than alternatives and also enables the detection of summary\nstatistics that are incompatible with the assumed data-generating process. We\ndemonstrate the effectiveness of our approach through several simulated\nexamples, where it delivers more accurate point estimates and uncertainty\nquantification over standard ABC approaches when the model is misspecified.\nAdditionally, we apply our approach to an empirical example, further showcasing\nits advantages over alternative methods.","main_category":"stat.ME","categories":"stat.ME,stat.CO","published":"2025-04-07T05:11:02Z"}
{"aid":"http://arxiv.org/abs/2504.04735v1","title":"Fermi Operator Expansion for the Hartree-Fock-Bogoliubov Theory","summary":"A variety of phases in the inner crust of neutron stars are crucial for\nunderstanding the pulsar phenomena. However, the three-dimensional\ncoordinate-space calculation of the phases is computationally demanding. We aim\nto generalize the Fermi Operator Expansion (FOE) method that is effective for\nfinite-temperature coordinate-space simulation, from the Hartree-Fock theory to\nHartree-Fock-Bogoliubov (HFB) theory including the pairing effects.\nFurthermore, the periodic structure with free neutrons in the inner crust\nrequires us to treat the system with the band theory. We give a concise proof\nthat the generalized density matrix in the HFB theory can be obtained with the\nFOE. The Chebyshev polynomial expansion is used for calculations of the HFB\nband theory. Using a model for a slab phase of the inner crust, the FOE method\nproduces results in good agreement with those based on the diagonalization of\nthe HFB Hamiltonian. The FOE method for the HFB band theory is a powerful tool\nfor studying the non-trivial exotic structures in neutron stars. The FOE method\nis suitable for parallelization and further acceleration is possible with\nnearsightedness.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-07T05:13:18Z"}
{"aid":"http://arxiv.org/abs/2504.04748v1","title":"Sharp threshold for network recovery from voter model dynamics","summary":"We investigate the problem of recovering a latent directed Erd\\H{o}s-R\\'enyi\ngraph $G^*\\sim \\mathcal G(n,p)$ from observations of discrete voter model\ntrajectories on $G^*$, where $np$ grows polynomially in $n$. Given access to\n$M$ independent voter model trajectories evolving up to time $T$, we establish\nthat $G^*$ can be recovered \\emph{exactly} with probability at least $0.9$ by\nan \\emph{efficient} algorithm, provided that \\[ M \\cdot \\min\\{T, n\\} \\geq C n^2\np^2 \\log n \\] holds for a sufficiently large constant $C$. Here, $M\\cdot\n\\min\\{T,n\\}$ can be interpreted as the approximate number of effective update\nrounds being observed, since the voter model on $G^*$ typically reaches\nconsensus after $\\Theta(n)$ rounds, and no further information can be gained\nafter this point. Furthermore, we prove an \\emph{information-theoretic} lower\nbound showing that the above condition is tight up to a constant factor. Our\nresults indicate that the recovery problem does not exhibit a\nstatistical-computational gap.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T05:47:52Z"}
{"aid":"http://arxiv.org/abs/2504.04758v1","title":"Feature Importance-Aware Deep Joint Source-Channel Coding for\n  Computationally Efficient and Adjustable Image Transmission","summary":"Recent advancements in deep learning-based joint source-channel coding\n(deepJSCC) have significantly improved communication performance, but their\nhigh computational demands restrict practical deployment. Furthermore, some\napplications require the adaptive adjustment of computational complexity. To\naddress these challenges, we propose a computationally efficient and adjustable\ndeepJSCC model for image transmission, which we call feature importance-aware\ndeepJSCC (FAJSCC). Unlike existing deepJSCC models that equally process all\nneural features of images, FAJSCC first classifies features into important and\nless important features and then processes them differently. Specifically,\ncomputationally-intensive self-attention is applied to the important features\nand computationally-efficient spatial attention to the less important ones. The\nfeature classification is based on the available computational budget and\nimportance scores predicted by an importance predictor, which estimates each\nfeature's contribution to performance. It also allows independent adjustment of\nencoder and decoder complexity within a single trained model. With these\nproperties, our FAJSCC is the first deepJSCC that is computationally efficient\nand adjustable while maintaining high performance. Experiments demonstrate that\nour FAJSCC achieves higher image transmission performance across various\nchannel conditions while using less computational complexity than the recent\nstate-of-the-art models. Adding to this, by separately varying the\ncomputational resources of the encoder and decoder, it is concluded that the\ndecoder's error correction function requires the largest computational\ncomplexity in FAJSCC, which is the first observation in deepJSCC literature.\nThe FAJSCC code is publicly available at\nhttps://github.com/hansung-choi/FAJSCC.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-07T06:11:39Z"}
{"aid":"http://arxiv.org/abs/2504.04771v1","title":"Improving Multilingual Retrieval-Augmented Language Models through\n  Dialectic Reasoning Argumentations","summary":"Retrieval-augmented generation (RAG) is key to enhancing large language\nmodels (LLMs) to systematically access richer factual knowledge. Yet, using RAG\nbrings intrinsic challenges, as LLMs must deal with potentially conflicting\nknowledge, especially in multilingual retrieval, where the heterogeneity of\nknowledge retrieved may deliver different outlooks. To make RAG more\nanalytical, critical and grounded, we introduce Dialectic-RAG (DRAG), a modular\napproach guided by Argumentative Explanations, i.e., structured reasoning\nprocess that systematically evaluates retrieved\n  information by comparing, contrasting, and resolving conflicting\nperspectives. Given a query and a set of multilingual related documents, DRAG\nselects and exemplifies relevant knowledge for delivering dialectic\nexplanations that, by critically weighing opposing arguments and filtering\nextraneous content, clearly determine the final response. Through a series of\nin-depth experiments, we show the impact of our framework both as an in-context\nlearning strategy and for constructing demonstrations to instruct smaller\nmodels. The final results demonstrate that DRAG significantly improves RAG\napproaches, requiring low-impact computational effort and providing robustness\nto knowledge perturbations.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T06:55:15Z"}
{"aid":"http://arxiv.org/abs/2504.04784v1","title":"Disentangling Instruction Influence in Diffusion Transformers for\n  Parallel Multi-Instruction-Guided Image Editing","summary":"Instruction-guided image editing enables users to specify modifications using\nnatural language, offering more flexibility and control. Among existing\nframeworks, Diffusion Transformers (DiTs) outperform U-Net-based diffusion\nmodels in scalability and performance. However, while real-world scenarios\noften require concurrent execution of multiple instructions, step-by-step\nediting suffers from accumulated errors and degraded quality, and integrating\nmultiple instructions with a single prompt usually results in incomplete edits\ndue to instruction conflicts. We propose Instruction Influence Disentanglement\n(IID), a novel framework enabling parallel execution of multiple instructions\nin a single denoising process, designed for DiT-based models. By analyzing\nself-attention mechanisms in DiTs, we identify distinctive attention patterns\nin multi-instruction settings and derive instruction-specific attention masks\nto disentangle each instruction's influence. These masks guide the editing\nprocess to ensure localized modifications while preserving consistency in\nnon-edited regions. Extensive experiments on open-source and custom datasets\ndemonstrate that IID reduces diffusion steps while improving fidelity and\ninstruction completion compared to existing baselines. The codes will be\npublicly released upon the acceptance of the paper.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T07:26:25Z"}
{"aid":"http://arxiv.org/abs/2504.04797v1","title":"Addressing the Curse of Scenario and Task Generalization in AI-6G: A\n  Multi-Modal Paradigm","summary":"Existing works on machine learning (ML)-empowered wireless communication\nprimarily focus on monolithic scenarios and single tasks. However, with the\nblooming growth of communication task classes coupled with various task\nrequirements in future 6G systems, this working pattern is obviously\nunsustainable. Therefore, identifying a groundbreaking paradigm that enables a\nuniversal model to solve multiple tasks in the physical layer within diverse\nscenarios is crucial for future system evolution. This paper aims to\nfundamentally address the curse of ML model generalization across diverse\nscenarios and tasks by unleashing multi-modal feature integration capabilities\nin future systems. Given the universality of electromagnetic propagation\ntheory, the communication process is determined by the scattering environment,\nwhich can be more comprehensively characterized by cross-modal perception, thus\nproviding sufficient information for all communication tasks across varied\nenvironments. This fact motivates us to propose a transformative two-stage\nmulti-modal pre-training and downstream task adaptation paradigm...","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-07T07:43:03Z"}
{"aid":"http://arxiv.org/abs/2504.04805v1","title":"Measurement of substructure-dependent suppression of large-radius jets\n  with charged particles in Pb+Pb collisions with ATLAS","summary":"Measurements of jet substructure in Pb+Pb collisions provide key insights\ninto the mechanism of jet quenching in the hot and dense QCD medium created in\nthese collisions. This Letter presents a measurement of the suppression of\nlarge-radius jets with a radius parameter of $R = 1.0$ and its dependence on\nthe jet substructure. The measurement uses 1.72 nb$^{-1}$ of Pb+Pb data and 255\npb$^{-1}$ of $pp$ data, both at $\\sqrt{s_{_\\mathrm{NN}}} = 5.02$ TeV, recorded\nwith the ATLAS detector at the Large Hadron Collider. Large-radius jets are\nreconstructed by reclustering $R = 0.2$ calorimetric jets and are measured for\ntransverse momentum above $200$ GeV. Jet substructure is evaluated using\ncharged-particle tracks, and the overall level of jet suppression is quantified\nusing the jet nuclear modification factor ($R_\\mathrm{AA}$). The jet\n$R_\\mathrm{AA}$ is measured as a function of jet $p_{\\mathrm{T}}$, the charged\n$k_t$ splitting scale ($\\sqrt{d_{12}}$), and the angular separation ($dR_{12}$)\nof two leading sub-jets. The jet $R_\\mathrm{AA}$ gradually decreases with\nincreasing $\\sqrt{d_{12}}$, implying significantly stronger suppression of\nlarge-radius jets with larger $k_t$ splitting scale. The jet $R_\\mathrm{AA}$\ngradually decreases for $dR_{12}$ in the range $0.01{-}0.2$ and then remains\nconsistent with a constant for $dR_{12} \\gtrsim 0.2$. The observed significant\ndependence of jet suppression on the jet substructure will provide new insights\ninto its role in the quenching process.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-07T08:01:08Z"}
{"aid":"http://arxiv.org/abs/2504.04837v1","title":"Uni4D: A Unified Self-Supervised Learning Framework for Point Cloud\n  Videos","summary":"Point cloud video representation learning is primarily built upon the masking\nstrategy in a self-supervised manner. However, the progress is slow due to\nseveral significant challenges: (1) existing methods learn the motion\nparticularly with hand-crafted designs, leading to unsatisfactory motion\npatterns during pre-training which are non-transferable on fine-tuning\nscenarios. (2) previous Masked AutoEncoder (MAE) frameworks are limited in\nresolving the huge representation gap inherent in 4D data. In this study, we\nintroduce the first self-disentangled MAE for learning discriminative 4D\nrepresentations in the pre-training stage. To address the first challenge, we\npropose to model the motion representation in a latent space. The second issue\nis resolved by introducing the latent tokens along with the typical geometry\ntokens to disentangle high-level and low-level features during decoding.\nExtensive experiments on MSR-Action3D, NTU-RGBD, HOI4D, NvGesture, and SHREC'17\nverify this self-disentangled learning framework. We demonstrate that it can\nboost the fine-tuning performance on all 4D tasks, which we term Uni4D. Our\npre-trained model presents discriminative and meaningful 4D representations,\nparticularly benefits processing long videos, as Uni4D gets $+3.8\\%$\nsegmentation accuracy on HOI4D, significantly outperforming either\nself-supervised or fully-supervised methods after end-to-end fine-tuning.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T08:47:36Z"}
{"aid":"http://arxiv.org/abs/2504.04845v1","title":"Open problems UP24","summary":"The conference Unexpected Phenomena in Energy Minimization and Polarization,\nheld in Sofia, Bulgaria in 2024, provided a platform for researchers to discuss\nand propose challenging open questions across various fields, such as potential\ntheory, approximation, special functions, point configurations, lattices, and\nnumerical analysis. The open problems sessions were productive, fruitful and\nled to a range of interesting questions. In this document, we present these\nopen problems.","main_category":"math.CA","categories":"math.CA,math-ph,math.MP","published":"2025-04-07T08:56:48Z"}
{"aid":"http://arxiv.org/abs/2504.04857v1","title":"3D Gaussian Particle Approximation of VDB Datasets: A Study for\n  Scientific Visualization","summary":"The complexity and scale of Volumetric and Simulation datasets for Scientific\nVisualization(SciVis) continue to grow. And the approaches and advantages of\nmemory-efficient data formats and storage techniques for such datasets vary.\nOpenVDB library and its VDB data format excels in memory efficiency through its\nhierarchical and dynamic tree structure, with active and inactive sub-trees for\ndata storage. It is heavily used in current production renderers for both\nanimation and rendering stages in VFX pipelines and photorealistic rendering of\nvolumes and fluids. However, it still remains to be fully leveraged in SciVis\nwhere domains dealing with sparse scalar fields like porous media, time varying\nvolumes such as tornado and weather simulation or high resolution simulation of\nComputational Fluid Dynamics present ample number of large challenging data\nsets.Goal of this paper is not only to explore the use of OpenVDB in SciVis but\nalso to explore a level of detail(LOD) technique using 3D Gaussian particles\napproximating voxel regions. For rendering, we utilize NVIDIA OptiX library for\nray marching through the Gaussians particles. Data modeling using 3D Gaussians\nhas been very popular lately due to success in stereoscopic image to 3D scene\nconversion using Gaussian Splatting and Gaussian approximation and mixture\nmodels aren't entirely new in SciVis as well. Our work explores the integration\nwith rendering software libraries like OpenVDB and OptiX to take advantage of\ntheir built-in memory compaction and hardware acceleration features, while also\nleveraging the performance capabilities of modern GPUs. Thus, we present a\nSciVis rendering approach that uses 3D Gaussians at varying LOD in a lossy\nscheme derived from VDB datasets, rather than focusing on photorealistic volume\nrendering.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-07T09:14:15Z"}
{"aid":"http://arxiv.org/abs/2504.04896v1","title":"Understanding and Design of Interstitial Oxygen Conductors","summary":"Highly efficient oxygen active materials that react with, absorb, and\ntransport oxygen is essential for fuel cells, electrolyzers and related\napplications. While vacancy mediated oxygen ion conductors have long been the\nfocus of research, they are limited by high migration barriers at intermediate\ntemperatures, which hinder their practical applications. In contrast,\ninterstitial oxygen conductors exhibit significantly lower migration barriers\nenabling faster ionic conductivity at lower temperatures. This review\nsystematically examines both well established and recently identified families\nof interstitial oxygen ion conductors, focusing on how their unique structural\nmotifs such as corner sharing polyhedral frameworks, isolated polyhedral, and\ncage like architectures, facilitate low migration barriers through interstitial\nand interstitialcy diffusion mechanisms. A central discussion of this review\nfocuses on the evolution of design strategies, from targeted donor doping,\nelement screening, and physical intuition descriptor material discovery, which\nleverage computational tools to explore vast chemical spaces in search of new\ninterstitial conductors. The success of these strategies demonstrates that a\nsignificant, largely unexplored space remains for discovering high performing\ninterstitial oxygen conductors. Crucial features enabling high performance\ninterstitial oxygen diffusion include the availability of electrons for oxygen\nreduction and sufficient structural flexibility with accessible volume for\ninterstitial accommodation. This review concludes with a forward looking\nperspective, proposing a knowledge driven methodology that integrates current\nunderstanding with data centric approaches to identify promising interstitial\noxygen conductors outside traditional search paradigms.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-07T10:08:31Z"}
{"aid":"http://arxiv.org/abs/2504.04897v1","title":"The Minimum Eternal Vertex Cover Problem on a Subclass of\n  Series-Parallel Graphs","summary":"Eternal vertex cover is the following two-player game between a defender and\nan attacker on a graph. Initially, the defender positions k guards on k\nvertices of the graph; the game then proceeds in turns between the defender and\nthe attacker, with the attacker selecting an edge and the defender responding\nto the attack by moving some of the guards along the edges, including the\nattacked one. The defender wins a game on a graph G with k guards if they have\na strategy such that, in every round of the game, the vertices occupied by the\nguards form a vertex cover of G, and the attacker wins otherwise. The eternal\nvertex cover number of a graph G is the smallest number k of guards allowing\nthe defender to win and Eternal Vertex Cover is the problem of computing the\neternal vertex cover number of the given graph.\n  We study this problem when restricted to the well-known class of\nseries-parallel graphs. In particular, we prove that Eternal Vertex Cover can\nbe solved in linear time when restricted to melon graphs, a proper subclass of\nseries-parallel graphs. Moreover, we also conjecture that this problem is\nNP-hard on series-parallel graphs.","main_category":"math.CO","categories":"math.CO,cs.CC,cs.DM,cs.DS,G.2.2","published":"2025-04-07T10:12:09Z"}
{"aid":"http://arxiv.org/abs/2504.04939v1","title":"A Taxonomy of Self-Handover","summary":"Self-handover, transferring an object between one's own hands, is a common\nbut understudied bimanual action. While it facilitates seamless transitions in\ncomplex tasks, the strategies underlying its execution remain largely\nunexplored. Here, we introduce the first systematic taxonomy of self-handover,\nderived from manual annotation of over 12 hours of cooking activity performed\nby 21 participants. Our analysis reveals that self-handover is not merely a\npassive transition, but a highly coordinated action involving anticipatory\nadjustments by both hands. As a step toward automated analysis of human\nmanipulation, we further demonstrate the feasibility of classifying\nself-handover types using a state-of-the-art vision-language model. These\nfindings offer fresh insights into bimanual coordination, underscoring the role\nof self-handover in enabling smooth task transitions-an ability essential for\nadaptive dual-arm robotics.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.CV","published":"2025-04-07T11:21:42Z"}
{"aid":"http://arxiv.org/abs/2504.04949v1","title":"One Quantizer is Enough: Toward a Lightweight Audio Codec","summary":"Neural audio codecs have recently gained traction for their ability to\ncompress high-fidelity audio and generate discrete tokens that can be utilized\nin downstream generative modeling tasks. However, leading approaches often rely\non resource-intensive models and multi-quantizer architectures, resulting in\nconsiderable computational overhead and constrained real-world applicability.\nIn this paper, we present SQCodec, a lightweight neural audio codec that\nleverages a single quantizer to address these limitations. SQCodec explores\nstreamlined convolutional networks and local Transformer modules, alongside\nTConv, a novel mechanism designed to capture acoustic variations across\nmultiple temporal scales, thereby enhancing reconstruction fidelity while\nreducing model complexity. Extensive experiments across diverse datasets show\nthat SQCodec achieves audio quality comparable to multi-quantizer baselines,\nwhile its single-quantizer design offers enhanced adaptability and its\nlightweight architecture reduces resource consumption by an order of magnitude.\nThe source code is publicly available at https://github.com/zhai-lw/SQCodec.","main_category":"cs.SD","categories":"cs.SD,cs.AI,I.2.m","published":"2025-04-07T11:34:39Z"}
{"aid":"http://arxiv.org/abs/2504.04985v1","title":"Quasi-periodic sub-structure of RRAT J1913+1330","summary":"Recent findings suggest a universal relationship between the quasi-periodic\nsub-structures and rotational periods across various types of radio-emitting\nneutron stars. In this study, we report the detection of 12 quasi-periodic\nsub-structures in a rotating radio transient (RRAT) J1913+1330 using the\nFive-hundred-meter Aperture Spherical Radio Telescope (FAST). This is the\nsecond known RRAT exhibiting quasi-periodic sub-structures. Our result\nreinforces the observed relationship between quasi-periodicity and rotational\nperiod. The polarization analysis reveals that 11 of the 12 pulses exhibit high\nlinear polarization consistent with the quasi-periodic behaviour of the total\nintensity, while circular polarization with detectable quasi-periodic\nsub-structures is observed in only three pulses. No correlation is found\nbetween the sub-structure periods and their widths, peak fluxes, or fluences,\neven under the extremely variable single-pulse energy and morphology observed\nin J1913+1330.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-07T12:11:49Z"}
{"aid":"http://arxiv.org/abs/2504.04986v1","title":"Quantum control of a random transverse Ising spin system","summary":"We consider subspace transfer within the time-dependent one-dimensional\nquantum transverse Ising model, with random nearest-neighbor interactions and a\ntransverse field. We run numerical simulations using a variational approach and\nthe numerical GRAPE (gradient-ascent pulse engineering) and dCRAB (dressed\nchopped random basis) quantum control algorithms.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-07T12:12:09Z"}
{"aid":"http://arxiv.org/abs/2504.04990v1","title":"Quantum walk with coherent multiple translations induces fast quantum\n  gate operations","summary":"Quantum walks with one-dimensional translational symmetry are important for\nquantum algorithms, where the speed-up of the diffusion speed can be reached if\nlong-range couplings are added. Our work studies a scheme of a ring under the\nstrong resonant modulation that can support discrete-time quantum walk\nincluding coherent multiple long-range translations in a natural way along\nsynthetic frequency dimension. These multiple translation paths are added in a\ncoherent way, which makes the walker evolve under the topological band.\nTherein, not only the fast diffusion speed is expected, but more importantly,\nwe find that single quantum gate operations can be performed in the\nquasi-momentum space. In particular, we show the arbitrary single-qubit state\npreparation and an example of CNOT two-qubit gate with only one time step,\ndramarically increasing quantum algorithms. Our study uses a single ring to\nprovide fast quantum gate operations based on coherent multiple path quantum\nwalk, which may provide unique designs for efficient quantum operations on\nphotonic chips.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-07T12:14:19Z"}
{"aid":"http://arxiv.org/abs/2504.05000v1","title":"Energy Gap Modulation in Proximitized Superconducting Puddles of\n  Graphene","summary":"We investigated proximity-induced superconductivity in a graphene-insulating\nInO bilayer system through gate-controlled transport measurements. Distinct\noscillations in the differential conductance are observed across both the\nelectron and hole doping regimes, with oscillation amplitudes increasing as the\nchemical potential moves away from the Dirac point. These findings are\nexplained using a theoretical model of a normal-superconductor-normal (NSN)\njunction, which addresses reflection and transmission probabilities at normal\nincidence. From this model, we extract key parameters for the proximitized\ngraphene, including the superconducting energy gap Delta and the effective\nlength scale Ls of the superconducting regions. Near the Dirac point, we\nobserve a minimal Ls and a maximal Delta, aligning with the theory that the gap\nin strongly disordered superconductors increases as the coherence length of\nlocalized pairs decreases. This suggests that spatial confinement in a\nlow-density superconductor leads to an effective increase in the\nsuperconducting gap.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.dis-nn,cond-mat.mes-hall","published":"2025-04-07T12:27:11Z"}
{"aid":"http://arxiv.org/abs/2504.05005v1","title":"Can audio recordings be used to detect leaks and coughs during\n  mechanical insufflation exsufflation (MI-E) treatment?","summary":"This report relates to a study group hosted by the EPSRC funded network,\nIntegrating data-driven BIOphysical models into REspiratory MEdicine (BIOREME),\nand supported by SofTMech and Innovate UK, Business Connect. The BIOREME\nnetwork hosts events, including this study group, to bring together\nmulti-disciplinary researchers, clinicians, companies and charities to catalyse\nresearch in the applications of mathematical modelling for respiratory\nmedicine. The goal of this study group was to provide an interface between\ncompanies, clinicians, and mathematicians to develop mathematical tools to the\nproblems presented. The study group was held at The University of Glasgow on\nthe 17 - 21 June 2024 and was attended by 16 participants from 8 different\ninstitutions. Below details the technical report of one of the challenges and\nthe methods developed by the team of researchers who worked on this challenge.","main_category":"physics.med-ph","categories":"physics.med-ph","published":"2025-04-07T12:32:01Z"}
{"aid":"http://arxiv.org/abs/2504.05023v1","title":"Topological transition between gapless phases in quantum walks","summary":"Topological gapless phases of matter have been a recent interest among\ntheoretical and experimental condensed matter physicists. Fermionic chains with\nextended nearest neighbor couplings have been observed to show unique\ntopological transition at the multicritical points between distinct gapless\nphases. In this work, we show that such topological gapless phases and the\ntransition between them can be simulated in a quantum walk. We consider a\nthree-step discrete-time quantum walk and identify various critical or gapless\nphases and multicriticalities from the topological phase diagram along with\ntheir distinguished energy dispersions. We reconstruct the scaling theory based\non the curvature function to study transition between gapless phases in the\nquantum walk. We show the interesting features observed in fermionic chains,\nsuch as diverging, sign flipping and swapping properties of curvature function,\ncan be simulated in the quantum walk. Moreover, the renormalization group flow\nand Wannier state correlation functions also identify transition at the\nmulticritical points between gapless phases. We observe the scaling law and\noverlapping of critical and fixed point properties at the multicritical points\nof the fermionic chains can also be observed in the quantum walk. Furthermore,\nwe categorize the topological transitions at various multicritical points using\nthe group velocity of the energy eigenstates. Finally, the topological\ncharacters of various gapless phases are captured using winding number which\nallows one to distinguish various gapless phases and also show the transitions\nat the multicritical points.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall,cond-mat.other,cond-mat.stat-mech","published":"2025-04-07T12:48:12Z"}
{"aid":"http://arxiv.org/abs/2504.05033v1","title":"CloSE: A Compact Shape- and Orientation-Agnostic Cloth State\n  Representation","summary":"Cloth manipulation is a difficult problem mainly because of the non-rigid\nnature of cloth, which makes a good representation of deformation essential. We\npresent a new representation for the deformation-state of clothes. First, we\npropose the dGLI disk representation, based on topological indices computed for\nsegments on the edges of the cloth mesh border that are arranged on a circular\ngrid. The heat-map of the dGLI disk uncovers patterns that correspond to\nfeatures of the cloth state that are consistent for different shapes, sizes of\npositions of the cloth, like the corners and the fold locations. We then\nabstract these important features from the dGLI disk onto a circle, calling it\nthe Cloth StatE representation (CloSE). This representation is compact,\ncontinuous, and general for different shapes. Finally, we show the strengths of\nthis representation in two relevant applications: semantic labeling and high-\nand low-level planning. The code, the dataset and the video can be accessed\nfrom : https://jaykamat99.github.io/close-representation","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-07T12:54:58Z"}
{"aid":"http://arxiv.org/abs/2504.05050v1","title":"Revealing the Intrinsic Ethical Vulnerability of Aligned Large Language\n  Models","summary":"Large language models (LLMs) are foundational explorations to artificial\ngeneral intelligence, yet their alignment with human values via instruction\ntuning and preference learning achieves only superficial compliance. Here, we\ndemonstrate that harmful knowledge embedded during pretraining persists as\nindelible \"dark patterns\" in LLMs' parametric memory, evading alignment\nsafeguards and resurfacing under adversarial inducement at distributional\nshifts. In this study, we first theoretically analyze the intrinsic ethical\nvulnerability of aligned LLMs by proving that current alignment methods yield\nonly local \"safety regions\" in the knowledge manifold. In contrast, pretrained\nknowledge remains globally connected to harmful concepts via high-likelihood\nadversarial trajectories. Building on this theoretical insight, we empirically\nvalidate our findings by employing semantic coherence inducement under\ndistributional shifts--a method that systematically bypasses alignment\nconstraints through optimized adversarial prompts. This combined theoretical\nand empirical approach achieves a 100% attack success rate across 19 out of 23\nstate-of-the-art aligned LLMs, including DeepSeek-R1 and LLaMA-3, revealing\ntheir universal vulnerabilities.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-07T13:20:17Z"}
{"aid":"http://arxiv.org/abs/2504.05062v1","title":"LDGNet: A Lightweight Difference Guiding Network for Remote Sensing\n  Change Detection","summary":"With the rapid advancement of deep learning, the field of change detection\n(CD) in remote sensing imagery has achieved remarkable progress. Existing\nchange detection methods primarily focus on achieving higher accuracy with\nincreased computational costs and parameter sizes, leaving development of\nlightweight methods for rapid real-world processing an underexplored challenge.\nTo address this challenge, we propose a Lightweight Difference Guiding Network\n(LDGNet), leveraging absolute difference image to guide optical remote sensing\nchange detection. First, to enhance the feature representation capability of\nthe lightweight backbone network, we propose the Difference Guiding Module\n(DGM), which leverages multi-scale features extracted from the absolute\ndifference image to progressively influence the original image encoder at each\nlayer, thereby reinforcing feature extraction. Second, we propose the\nDifference-Aware Dynamic Fusion (DADF) module with Visual State Space Model\n(VSSM) for lightweight long-range dependency modeling. The module first uses\nfeature absolute differences to guide VSSM's global contextual modeling of\nchange regions, then employs difference attention to dynamically fuse these\nlong-range features with feature differences, enhancing change semantics while\nsuppressing noise and background. Extensive experiments on multiple datasets\ndemonstrate that our method achieves comparable or superior performance to\ncurrent state-of-the-art (SOTA) methods requiring several times more\ncomputation, while maintaining only 3.43M parameters and 1.12G FLOPs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:33:54Z"}
{"aid":"http://arxiv.org/abs/2504.05109v1","title":"Inverse Mixed Integer Optimization: An Interior Point Perspective","summary":"We propose a novel solution framework for inverse mixed-integer optimization\nbased on analytic center concepts from interior point methods. We characterize\nthe optimality gap of a given solution, provide structural results, and propose\nmodels that can efficiently solve large problems. First, we exploit the\nproperty that mixed-integer solutions are primarily interior points that can be\nmodeled as weighted analytic centers with unique weights. We then demonstrate\nthat the optimality of a given solution can be measured relative to an\nidentifiable optimal solution to the linear programming relaxation. We quantify\nthe absolute optimality gap and pose the inverse mixed-integer optimization\nproblem as a bi-level program where the upper-level objective minimizes the\nnorm to a given reference cost, while the lower-level objective minimizes the\nabsolute optimality gap to an optimal linear programming solution. We provide\ntwo models that address the discrepancies between the upper and lower-level\nproblems, establish links with noisy and data-driven optimization, and conduct\nextensive numerical testing. We find that the proposed framework successfully\nidentifies high-quality solutions in rapid computational times. Compared to the\nstate-of-the-art trust region cutting plane method, it achieves optimal cost\nvectors for 95% and 68% of the instances within optimality gaps of e-2 and e-5,\nrespectively, without sacrificing the relative proximity to the nominal cost\nvector. To ensure the optimality of the given solution, the proposed approach\nis complemented by a classical cutting plane method. It is shown to solve\ninstances that the trust region cutting plane method could not successfully\nsolve as well as being in very close proximity to the nominal cost vector.","main_category":"math.OC","categories":"math.OC","published":"2025-04-07T14:15:17Z"}
{"aid":"http://arxiv.org/abs/2504.05169v1","title":"Machine learning interatomic potential can infer electrical response","summary":"Modeling the response of material and chemical systems to electric fields\nremains a longstanding challenge. Machine learning interatomic potentials\n(MLIPs) offer an efficient and scalable alternative to quantum mechanical\nmethods but do not by themselves incorporate electrical response. Here, we show\nthat polarization and Born effective charge (BEC) tensors can be directly\nextracted from long-range MLIPs within the Latent Ewald Summation (LES)\nframework, solely by learning from energy and force data. Using this approach,\nwe predict the infrared spectra of bulk water under zero or finite external\nelectric fields, ionic conductivities of high-pressure superionic ice, and the\nphase transition and hysteresis in ferroelectric PbTiO$_3$ perovskite. This\nwork thus extends the capability of MLIPs to predict electrical\nresponse--without training on charges or polarization or BECs--and enables\naccurate modeling of electric-field-driven processes in diverse systems at\nscale.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cs.LG,physics.chem-ph,physics.comp-ph","published":"2025-04-07T15:14:07Z"}
{"aid":"http://arxiv.org/abs/2504.05214v1","title":"Post-Training Language Models for Continual Relation Extraction","summary":"Real-world data, such as news articles, social media posts, and chatbot\nconversations, is inherently dynamic and non-stationary, presenting significant\nchallenges for constructing real-time structured representations through\nknowledge graphs (KGs). Relation Extraction (RE), a fundamental component of KG\ncreation, often struggles to adapt to evolving data when traditional models\nrely on static, outdated datasets. Continual Relation Extraction (CRE) methods\ntackle this issue by incrementally learning new relations while preserving\npreviously acquired knowledge. This study investigates the application of\npre-trained language models (PLMs), specifically large language models (LLMs),\nto CRE, with a focus on leveraging memory replay to address catastrophic\nforgetting. We evaluate decoder-only models (eg, Mistral-7B and Llama2-7B) and\nencoder-decoder models (eg, Flan-T5 Base) on the TACRED and FewRel datasets.\nTask-incremental fine-tuning of LLMs demonstrates superior performance over\nearlier approaches using encoder-only models like BERT on TACRED, excelling in\nseen-task accuracy and overall performance (measured by whole and average\naccuracy), particularly with the Mistral and Flan-T5 models. Results on FewRel\nare similarly promising, achieving second place in whole and average accuracy\nmetrics. This work underscores critical factors in knowledge transfer, language\nmodel architecture, and KG completeness, advancing CRE with LLMs and memory\nreplay for dynamic, real-time relation extraction.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T16:01:22Z"}
{"aid":"http://arxiv.org/abs/2504.05287v1","title":"RobustDexGrasp: Robust Dexterous Grasping of General Objects from\n  Single-view Perception","summary":"Robust grasping of various objects from single-view perception is fundamental\nfor dexterous robots. Previous works often rely on fully observable objects,\nexpert demonstrations, or static grasping poses, which restrict their\ngeneralization ability and adaptability to external disturbances. In this\npaper, we present a reinforcement-learning-based framework that enables\nzero-shot dynamic dexterous grasping of a wide range of unseen objects from\nsingle-view perception, while performing adaptive motions to external\ndisturbances. We utilize a hand-centric object representation for shape feature\nextraction that emphasizes interaction-relevant local shapes, enhancing\nrobustness to shape variance and uncertainty. To enable effective hand\nadaptation to disturbances with limited observations, we propose a mixed\ncurriculum learning strategy, which first utilizes imitation learning to\ndistill a policy trained with privileged real-time visual-tactile feedback, and\ngradually transfers to reinforcement learning to learn adaptive motions under\ndisturbances caused by observation noises and dynamic randomization. Our\nexperiments demonstrate strong generalization in grasping unseen objects with\nrandom poses, achieving success rates of 97.0% across 247,786 simulated objects\nand 94.6% across 512 real objects. We also demonstrate the robustness of our\nmethod to various disturbances, including unobserved object movement and\nexternal forces, through both quantitative and qualitative evaluations. Project\nPage: https://zdchan.github.io/Robust_DexGrasp/","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T17:38:19Z"}
{"aid":"http://arxiv.org/abs/2504.05304v1","title":"Gaussian Mixture Flow Matching Models","summary":"Diffusion models approximate the denoising distribution as a Gaussian and\npredict its mean, whereas flow matching models reparameterize the Gaussian mean\nas flow velocity. However, they underperform in few-step sampling due to\ndiscretization error and tend to produce over-saturated colors under\nclassifier-free guidance (CFG). To address these limitations, we propose a\nnovel Gaussian mixture flow matching (GMFlow) model: instead of predicting the\nmean, GMFlow predicts dynamic Gaussian mixture (GM) parameters to capture a\nmulti-modal flow velocity distribution, which can be learned with a KL\ndivergence loss. We demonstrate that GMFlow generalizes previous diffusion and\nflow matching models where a single Gaussian is learned with an $L_2$ denoising\nloss. For inference, we derive GM-SDE/ODE solvers that leverage analytic\ndenoising distributions and velocity fields for precise few-step sampling.\nFurthermore, we introduce a novel probabilistic guidance scheme that mitigates\nthe over-saturation issues of CFG and improves image generation quality.\nExtensive experiments demonstrate that GMFlow consistently outperforms flow\nmatching baselines in generation quality, achieving a Precision of 0.942 with\nonly 6 sampling steps on ImageNet 256$\\times$256.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-07T17:59:42Z"}
{"aid":"http://arxiv.org/abs/2504.05306v1","title":"CREA: A Collaborative Multi-Agent Framework for Creative Content\n  Generation with Diffusion Models","summary":"Creativity in AI imagery remains a fundamental challenge, requiring not only\nthe generation of visually compelling content but also the capacity to add\nnovel, expressive, and artistically rich transformations to images. Unlike\nconventional editing tasks that rely on direct prompt-based modifications,\ncreative image editing demands an autonomous, iterative approach that balances\noriginality, coherence, and artistic intent. To address this, we introduce\nCREA, a novel multi-agent collaborative framework that mimics the human\ncreative process. Our framework leverages a team of specialized AI agents who\ndynamically collaborate to conceptualize, generate, critique, and enhance\nimages. Through extensive qualitative and quantitative evaluations, we\ndemonstrate that CREA significantly outperforms state-of-the-art methods in\ndiversity, semantic alignment, and creative transformation. By structuring\ncreativity as a dynamic, agentic process, CREA redefines the intersection of AI\nand art, paving the way for autonomous AI-driven artistic exploration,\ngenerative design, and human-AI co-creation. To the best of our knowledge, this\nis the first work to introduce the task of creative editing.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T17:59:51Z"}
{"aid":"http://arxiv.org/abs/2504.05635v1","title":"The $L^p$-boundedness of wave operators for nonhomogeneous fourth-order\n  Schrödinger operators in high dimensions","summary":"This paper investigates the $L^p$-boundedness of wave operators associated\nwith the nonhomogeneous fourth-order Sch\\\"odinger operator $H = \\Delta^2 -\n\\Delta + V(x)$ on $\\mathbb{R}^n$. Assuming the real-valued potential $ V $\nexhibits sufficient decay and regularity, we prove that for all dimensions $ n\n\\geq 5 $, the wave operators $ W_{\\pm}(H, H_0)$ are bounded on\n$L^{p}(\\mathbb{R}^{n}) $ for all $ 1 \\leq p \\leq \\infty $, provided that zero\nis a regular threshold of $H $.\n  As applications, we derive the sharp $L^p$-$L^{p'}$ dispersive estimates for\nSchr\\\"odinger group $e^{-itH}$, as well as for the solutions operators $\\cos(t\n\\sqrt{H})$ and $\\frac{\\sin (t \\sqrt{H})}{ \\sqrt{H}}$ associated with the\nfollowing beam equations with potentials: $$\n  \\partial_t^2 u + \\left(\\Delta^2 -\\Delta+ V(x) \\right) u = 0, \\ \\\n  u(0, x) = f(x), \\quad \\partial_t u(0, x) = g(x),\\ \\ (t, x) \\in \\mathbb{R}\n\\times \\mathbb{R}^n,\\ n\\geq5, $$\n  where $p'$ denotes the H\\\"older conjugate of $p$, with $1 \\leq p \\leq 2$.\nMoreover, we remark that the same results hold for the operator $ \\epsilon\n\\Delta^2 - \\Delta + V$ with a parameter $\\epsilon>0,$ providing greater\nflexibility for the analysis of related equations.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T03:28:06Z"}
{"aid":"http://arxiv.org/abs/2504.05640v1","title":"CTI-Unet: Cascaded Threshold Integration for Improved U-Net Segmentation\n  of Pathology Images","summary":"Chronic kidney disease (CKD) is a growing global health concern,\nnecessitating precise and efficient image analysis to aid diagnosis and\ntreatment planning. Automated segmentation of kidney pathology images plays a\ncentral role in facilitating clinical workflows, yet conventional segmentation\nmodels often require delicate threshold tuning. This paper proposes a novel\n\\textit{Cascaded Threshold-Integrated U-Net (CTI-Unet)} to overcome the\nlimitations of single-threshold segmentation. By sequentially integrating\nmultiple thresholded outputs, our approach can reconcile noise suppression with\nthe preservation of finer structural details. Experiments on the challenging\nKPIs2024 dataset demonstrate that CTI-Unet outperforms state-of-the-art\narchitectures such as nnU-Net, Swin-Unet, and CE-Net, offering a robust and\nflexible framework for kidney pathology image segmentation.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-08T03:35:09Z"}
{"aid":"http://arxiv.org/abs/2504.05646v1","title":"Lattice: Learning to Efficiently Compress the Memory","summary":"Attention mechanisms have revolutionized sequence learning but suffer from\nquadratic computational complexity. This paper introduces Lattice, a novel\nrecurrent neural network (RNN) mechanism that leverages the inherent low-rank\nstructure of K-V matrices to efficiently compress the cache into a fixed number\nof memory slots, achieving sub-quadratic complexity. We formulate this\ncompression as an online optimization problem and derive a dynamic memory\nupdate rule based on a single gradient descent step. The resulting recurrence\nfeatures a state- and input-dependent gating mechanism, offering an\ninterpretable memory update process. The core innovation is the orthogonal\nupdate: each memory slot is updated exclusively with information orthogonal to\nits current state hence incorporation of only novel, non-redundant data, which\nminimizes the interference with previously stored information. The experimental\nresults show that Lattice achieves the best perplexity compared to all\nbaselines across diverse context lengths, with performance improvement becoming\nmore pronounced as the context length increases.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-08T03:48:43Z"}
{"aid":"http://arxiv.org/abs/2504.05650v1","title":"Exploring exclusive decay $B^+\\to ω\\ell^+ν$ within LCSR","summary":"In this paper, we calculate the Cabibbo-Kobayashi-Maskawa matrix element\n$|V_{ub}|$ by the semileptonic decay $B^+\\to \\omega\\ell^+\\nu$. For the\ntransition form factors (TFFs) $A_1(q^2)$, $A_2(q^2)$ and $V(q^2)$ of $B^+\\to\n\\omega$, we employ the QCD light-cone sum rules method for calculation, and by\nconstructing the correlation function using left-handed chiral current, we make\nthe $\\delta^1$-order twist-2 LCDA $\\phi^\\| _{2;\\omega}(x,\\mu)$ dominate the\ncontribution. In which the twist-2 LCDA $\\phi^\\| _{2;\\omega}(x,\\mu)$ is\nconstructed by light-cone harmonic oscillator model. Then, we obtain\n$A_1(0)=0.209^{+0.049}_{-0.042}$, $A_2(0)=0.206^{+0.051}_{-0.042}$ and\n$V(0)=0.258^{+0.058}_{-0.048}$ at large recoil region. Two important ratios of\nTFFs are $r_V=1.234_{-0.322}^{+0.425}$ and $r_2=0.985_{-0.274}^{+0.347}$. After\nextrapolating TFFs to the whole physical $q^2$-region by simplified\n$z(q^2,t)$-series expansion, we obtain the differential decay width and\nbranching fraction $\\mathcal{B}(B^+\\to\n\\omega\\ell^+\\nu)=(1.35^{+1.24}_{-0.69})\\times 10^{-4}$, which show good\nagreement with BaBar and Belle Collaborations. Finally, we extract the\n$|V_{ub}|$ by using the $\\mathcal{B}(B^+\\to \\omega\\ell^+\\nu)$ result from BaBar\nCollaboration, which leads to $|V_{ub}|=(3.66^{+1.38}_{-1.12})\\times 10^{-3}$.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-08T03:54:28Z"}
{"aid":"http://arxiv.org/abs/2504.05653v1","title":"How communities shape epidemic spreading: A hierarchically structured\n  metapopulation perspective","summary":"Recent outbreaks of COVID-19, Zika, Ebola, and influenza have renewed\ninterest in advancing epidemic models to better reflect the complexities of\ndisease spreading. Modern approaches incorporate social norms, mobility\npatterns, and heterogeneous community structures to capture the interplay\nbetween social and biological dynamics. This study examines epidemic\npropagation in hierarchically structured metapopulation networks, where\nindividuals interact within localized communities -- such as schools,\nworkplaces, and theaters -- and diffuse across them. Using mean-field\naveraging, we derive a scaling law linking contagion rates to the mean\nconnectivity degree, while stability analysis identifies thresholds for\ninfection surges. In networks with heterogeneous mean degrees, spectral\nperturbation theory reveals how structural variability accelerates and\namplifies disease spreading. We find that nodes with above-average degrees are\nnot only infected earlier but also act as key outbreak drivers. Framing\nepidemic dynamics as a continuous phase transition, we apply pattern formation\ntheory to show that the critical eigenvectors governing system stability are\nshaped by the network's degree distribution. Crucially, by analyzing Laplacian\neigenvector localization, we uncover a one-to-one correspondence between\ncommunity infection densities and the entries of the critical eigenvector --\nrevealing how internal community structure directly shapes global infection\npatterns. This work provides a systematic framework for understanding and\npredicting epidemic dynamics in structured populations, while highlighting the\nfundamental role of community organization.","main_category":"physics.soc-ph","categories":"physics.soc-ph,nlin.AO","published":"2025-04-08T04:02:06Z"}
{"aid":"http://arxiv.org/abs/2504.05669v1","title":"xMTF: A Formula-Free Model for Reinforcement-Learning-Based Multi-Task\n  Fusion in Recommender Systems","summary":"Recommender systems need to optimize various types of user feedback, e.g.,\nclicks, likes, and shares. A typical recommender system handling multiple types\nof feedback has two components: a multi-task learning (MTL) module, predicting\nfeedback such as click-through rate and like rate; and a multi-task fusion\n(MTF) module, integrating these predictions into a single score for item\nranking. MTF is essential for ensuring user satisfaction, as it directly\ninfluences recommendation outcomes. Recently, reinforcement learning (RL) has\nbeen applied to MTF tasks to improve long-term user satisfaction. However,\nexisting RL-based MTF methods are formula-based methods, which only adjust\nlimited coefficients within pre-defined formulas. The pre-defined formulas\nrestrict the RL search space and become a bottleneck for MTF. To overcome this,\nwe propose a formula-free MTF framework. We demonstrate that any suitable\nfusion function can be expressed as a composition of single-variable monotonic\nfunctions, as per the Sprecher Representation Theorem. Leveraging this, we\nintroduce a novel learnable monotonic fusion cell (MFC) to replace pre-defined\nformulas. We call this new MFC-based model eXtreme MTF (xMTF). Furthermore, we\nemploy a two-stage hybrid (TSH) learning strategy to train xMTF effectively. By\nexpanding the MTF search space, xMTF outperforms existing methods in extensive\noffline and online experiments.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-08T04:28:22Z"}
{"aid":"http://arxiv.org/abs/2504.05676v1","title":"Interfacial Heat Transport via Evanescent Radiation by Hot Electrons","summary":"We predict an additional thermal transport pathway across metal/non-metal\ninterfaces with large electron-phonon non-equilibrium via evanescent radiative\nheat transfer. In such systems, electron scattering processes vary drastically\nand can be leveraged to guide heat across interfaces via radiative heat\ntransport without engaging the lattice directly. We employ the formalism of\nfluctuational electrodynamics to simulate the spectral radiative heat flux\nacross the interface of a metal film and a non-metal substrate. We find that\nthe radiative conductance can exceed 300 MW m$^{-2}$ K$^{-1}$ at an electron\ntemperature of 5000 K for an emitting tungsten film on a hexagonal boron\nnitride substrate, becoming comparable to its conductive counterpart. This\nallows for a more holistic approach to the heat flow across interfaces,\naccounting for electron-phonon non-equilibrium and ultrafast near-field\nphonon-polariton coupling.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,physics.comp-ph","published":"2025-04-08T04:36:29Z"}
{"aid":"http://arxiv.org/abs/2504.05703v1","title":"Natural Theories","summary":"We consider the class of physical theories whose dynamics are given by\nnatural equations, which are partial differential equations determined by a\nfunctor from the category of n-manifolds, for some n, to the category of fiber\nbundles, satisfying certain further conditions. We show how the theory of\nnatural equations clarifies several important foundational issues, including\nthe status and meaning of minimal coupling, symmetries of theories, and\nbackground structure. We also state and prove a fundamental result about the\ninitial value problem for natural equations.","main_category":"physics.hist-ph","categories":"physics.hist-ph,gr-qc,math-ph,math.MP","published":"2025-04-08T05:56:17Z"}
{"aid":"http://arxiv.org/abs/2504.05726v1","title":"Signal and Backward Raman Pump Power Optimization in Multi-Band Systems\n  Using Fast Power Profile Estimation","summary":"This paper presents an efficient numerical method for calculating spatial\npower profiles of both signal and pump with significant Interchannel Stimulated\nRaman Scattering (ISRS) and backward Raman amplification in multiband systems.\nThis method was evaluated in the optimization of a C+L+S/C+L+S+E 1000km link,\nemploying three backward Raman pumps, by means of a closed-form EGN model\n(CFM6). The results show a 100x computational speed increase, enabling deep\noptimization which made it possible to obtain very good overall system\nperformance and flat GSNR.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-08T06:54:56Z"}
{"aid":"http://arxiv.org/abs/2504.05749v1","title":"Limitations of the $g$-tensor formalism of semiconductor spin qubits","summary":"The $g$-tensor formalism is a powerful method for describing the electrical\ndriving of semiconductor spin qubits. However, up to now, this technique has\nonly been applied to the simplest qubit dynamics, resonant monochromatic\ndriving by a single gate. Here we study the description of (i) monochromatic\ndriving using two driving gates and bichromatic driving via (ii) one or (iii)\ntwo gates. Assuming a general Hamiltonian with qubit states well separated from\nexcited orbital states, we find that when (i) two driving gates are used for\nmonochromatic driving or (ii) a single one for bichromatic, the $g$-tensor\nformalism successfully captures the leading-order dynamics. We express the Rabi\nfrequency and the Bloch-Siegert shift using the $g$-tensor and its first and\nsecond derivatives with respect to the gate voltage. However, when (iii)\nbichromatic driving is realized using two distinct driving gates, we see a\nbreakdown of $g$-tensor formalism: the Rabi frequency cannot be expressed using\nthe $g$-tensor and its derivatives. We find that beyond the $g$-tensor and its\nderivatives, three additional parameters are needed to capture the dynamics. We\ndemonstrate our general results by assuming an electron (hole) confined in a\ncircular quantum dot, subjected to Rashba spin-orbit interaction.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,quant-ph","published":"2025-04-08T07:25:13Z"}
{"aid":"http://arxiv.org/abs/2504.05752v1","title":"Complete and robust population transfer between the two ground states of\n  a three-state loop quantum system by amplitude composite pulse control","summary":"This work presents a method for achieving complete, robust, and efficient\npopulation transfer between the two ground states in a three-level loop quantum\nsystem. The approach utilizes composite pulse sequences by effectively mapping\nthe three-state system onto an equivalent two-level system. This transformation\nallows the use of broadband composite pulses designed initially for\nconventional two-state quantum systems. Unlike traditional implementations, the\ncomposite pulses in the three-level system are not controlled through phase\nadjustments; instead, they are realized via the amplitude ratio of the Rabi\nfrequencies.","main_category":"quant-ph","categories":"quant-ph,physics.atom-ph","published":"2025-04-08T07:32:00Z"}
{"aid":"http://arxiv.org/abs/2504.05791v1","title":"Illusion Spaces in VR: The Interplay Between Size and Taper Angle\n  Perception in Grasping","summary":"Leveraging the integration of visual and proprioceptive cues, research has\nuncovered various perception thresholds in VR that can be exploited to support\nhaptic feedback for grasping. While previous studies have explored individual\ndimensions, such as size, the combined effect of multiple geometric properties\non perceptual illusions remains poorly understood. We present a two-alternative\nforced choice study investigating the perceptual interplay between object size\nand taper angle. We introduce an illusion space model, providing detailed\ninsights into how physical and virtual object configurations affect human\nperception. Our insights reveal how, for example, as virtual sizes increase,\nusers perceive that taper angles increase, and as virtual angles decrease,\nusers overestimate sizes. We provide a mathematical model of the illusion\nspace, and an associated tool, which can be used as a guide for the design of\nfuture VR haptic devices and for proxy object selections.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-08T08:19:56Z"}
{"aid":"http://arxiv.org/abs/2504.05813v1","title":"A new approach for simulating PBH formation from generic curvature\n  fluctuations with the Misner-Sharp formalism","summary":"Primordial Black Holes (PBHs) may have formed in the early Universe due to\nthe collapse of super-horizon curvature fluctuations. Simulations of PBH\nformation have been essential for inferring the initial conditions that lead to\nblack hole formation and for studying their properties and impact on our\nUniverse. The Misner-Sharp formalism is commonly used as a standard approach\nfor these simulations. Recently, type-II fluctuations, characterized by a\nnon-monotonic areal radius, have gained interest. In the standard Misner-Sharp\napproach for simulating PBH formation with these fluctuations, the evolution\nequations suffer from divergent terms (0/0), which complicate and prevent the\nsimulations. We formulate a new approach to overcome this issue in a simple\nmanner by using the trace of the extrinsic curvature as an auxiliary variable,\nallowing simulations of type-II fluctuations within the Misner-Sharp formalism.\nUsing a set of standard exponential-shaped curvature profiles, we apply our new\napproach and numerical code based on pseudospectral methods to study the time\nevolution of the gravitational collapse, threshold values of type A/B PBHs and\nPBH mass. Interestingly, we identify cases of type-II fluctuations that do not\nnecessarily result in PBH formation.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-08T08:53:38Z"}
{"aid":"http://arxiv.org/abs/2504.05814v1","title":"The threshold for PBH formation in the type-II region and its analytical\n  estimation","summary":"We numerically simulate the formation of Primordial Black Holes (PBHs) in a\nradiation-dominated Universe under the assumption of spherical symmetry, driven\nby the collapse of adiabatic fluctuations, for different curvature profiles\n$\\zeta$. Our results show that the threshold for PBH formation, defined as the\npeak value of the critical compaction function $\\mathcal{C}_{c}(r_m)$ (where\n$r_m$ is the scale at which the peak occurs), does not asymptotically saturate\nto its maximum possible value in the type-I region for sufficiently sharp\nprofiles. Instead, the threshold is found in the type-II region with\n$\\mathcal{C}_{c}(r_m)$ being a minimum. We find, for the cases tested, that\nthis is a general trend associated with profiles that exhibit extremely large\ncurvatures in the linear component of the compaction function\n$\\mathcal{C}_{l}(r) \\equiv -4r \\zeta'(r)/3$ shape around its peak $r_m$ (spiky\nshapes). To measure this curvature at $r_m$, we define a dimensionless\nparameter: $\\kappa \\equiv -r^{2}_m \\mathcal{C}_l''(r_m)$, and we find that the\nthresholds observed in the type-II region occur for $\\kappa \\gtrsim 30$ for the\nprofiles we have used. By defining the threshold in terms of\n$\\mathcal{C}_{l,c}(r_m)$, we extend previous analytical estimations to the\ntype-II region, which is shown to be accurate within a few percent when\ncompared to the numerical simulations for the tested profiles. Our results\nsuggest that current PBH abundance calculations for models where the threshold\nlies in the type-II region may have been overestimated due to the general\nassumption that it should saturate at the boundary between the type-I and\ntype-II regions.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-08T08:53:42Z"}
{"aid":"http://arxiv.org/abs/2504.05816v1","title":"Solitons of the constrained Schrödinger equations","summary":"We consider the linear vector Schr\\\"odinger equation subjected to quadratic\nconstraints. We demonstrate that the resulting nonlinear system is closely\nrelated to the Ablowitz-Ladik hierarchy and use this fact to derive the\nN-soliton solutions for the discussed model.","main_category":"nlin.SI","categories":"nlin.SI,math-ph,math.MP","published":"2025-04-08T08:54:55Z"}
{"aid":"http://arxiv.org/abs/2504.05823v1","title":"New cosystolic high-dimensional expanders from KMS groups","summary":"Cosystolic expansion is a high-dimensional generalization of the Cheeger\nconstant for simplicial complexes. Originally, this notion was motivated by the\nfact that it implies the topological overlapping property, but more recently it\nwas shown to be connected to problems in theoretical computer science such as\nlist agreement expansion and agreement expansion in the low soundness regime.\n  There are only a few constructions of high-dimensional cosystolic expanders\nand, in dimension larger than $2$, the only known constructions prior to our\nwork were (co-dimension 1)-skeletons of quotients of affine buildings. In this\npaper, we give the first coset complex construction of cosystolic expanders for\nan arbitrary dimension. Our construction is more symmetric and arguably more\nelementary than the previous constructions relying on quotients of affine\nbuildings.\n  The coset complexes we consider arise from finite quotients of\nKac--Moody--Steinberg (KMS) groups and are known as KMS complexes. KMS\ncomplexes were introduced in recent work by Grave de Peralta and\nValentiner-Branth where it was shown that they are local-spectral expanders.\nOur result is that KMS complexes, satisfying some minor condition, give rise to\ninfinite families of bounded degree cosystolic expanders of arbitrary dimension\nand for any finitely generated Abelian coefficient group.\n  This result is achieved by observing that proper links of KMS complexes are\njoins of opposition complexes in spherical buildings. In order to show that\nthese opposition complexes are coboundary expanders, we develop a new method\nfor constructing cone functions by iteratively adding sets of vertices. Hence\nwe show that the links of KMS complexes are coboundary expanders. Using the\nprior local-to-global results, we obtain cosystolic expansion for the\n(co-dimension 1)-skeletons of the KMS complexes.","main_category":"math.CO","categories":"math.CO,math.GR","published":"2025-04-08T09:05:46Z"}
{"aid":"http://arxiv.org/abs/2504.05824v1","title":"End-to-End Dialog Neural Coreference Resolution: Balancing Efficiency\n  and Accuracy in Large-Scale Systems","summary":"Large-scale coreference resolution presents a significant challenge in\nnatural language processing, necessitating a balance between efficiency and\naccuracy. In response to this challenge, we introduce an End-to-End Neural\nCoreference Resolution system tailored for large-scale applications. Our system\nefficiently identifies and resolves coreference links in text, ensuring minimal\ncomputational overhead without compromising on performance. By utilizing\nadvanced neural network architectures, we incorporate various contextual\nembeddings and attention mechanisms, which enhance the quality of predictions\nfor coreference pairs. Furthermore, we apply optimization strategies to\naccelerate processing speeds, making the system suitable for real-world\ndeployment. Extensive evaluations conducted on benchmark datasets demonstrate\nthat our model achieves improved accuracy compared to existing approaches,\nwhile effectively maintaining rapid inference times. Rigorous testing confirms\nthe ability of our system to deliver precise coreference resolutions\nefficiently, thereby establishing a benchmark for future advancements in this\nfield.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T09:06:52Z"}
{"aid":"http://arxiv.org/abs/2504.05825v1","title":"Spin Dynamics in Rotating Quantum Plasmas: Coupled EPI Dispersion and\n  Solitary wave analysis","summary":"The propagation of an electrostatic wave in a three-component e-p-I\nastrophysical quantum plasma in a rotating frame has been studied, taking into\naccount the particle spin, Fermi pressure, and quantum Bohm potential. Spin\npolarization plays a key role in explaining the dynamics of quantum plasmas,\nespecially in astrophysical contexts due to the high external magnetic field\nprevalent in such environments. Effects specific to this particular\nenvironment, like rotation as well as gravity, have also been included. Coupled\ndispersion of electron, positron, and ion modes has been obtained. Further, the\ninvestigation of solitary waves by the Korteweg de Vries method has been\ncarried out, and a soliton solution has been obtained. Quantum effects increase\nwave dispersion and soliton stability in quantum plasma, thereby affecting the\nelectrostatic potential.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-08T09:07:55Z"}
{"aid":"http://arxiv.org/abs/2504.05840v1","title":"Momentum Boosted Episodic Memory for Improving Learning in Long-Tailed\n  RL Environments","summary":"Traditional Reinforcement Learning (RL) algorithms assume the distribution of\nthe data to be uniform or mostly uniform. However, this is not the case with\nmost real-world applications like autonomous driving or in nature where animals\nroam. Some experiences are encountered frequently, and most of the remaining\nexperiences occur rarely; the resulting distribution is called Zipfian. Taking\ninspiration from the theory of complementary learning systems, an architecture\nfor learning from Zipfian distributions is proposed where important long tail\ntrajectories are discovered in an unsupervised manner. The proposal comprises\nan episodic memory buffer containing a prioritised memory module to ensure\nimportant rare trajectories are kept longer to address the Zipfian problem,\nwhich needs credit assignment to happen in a sample efficient manner. The\nexperiences are then reinstated from episodic memory and given weighted\nimportance forming the trajectory to be executed. Notably, the proposed\narchitecture is modular, can be incorporated in any RL architecture and yields\nimproved performance in multiple Zipfian tasks over traditional architectures.\nOur method outperforms IMPALA by a significant margin on all three tasks and\nall three evaluation metrics (Zipfian, Uniform, and Rare Accuracy) and also\ngives improvements on most Atari environments that are considered challenging","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-08T09:21:39Z"}
{"aid":"http://arxiv.org/abs/2504.05849v1","title":"On the Importance of Conditioning for Privacy-Preserving Data\n  Augmentation","summary":"Latent diffusion models can be used as a powerful augmentation method to\nartificially extend datasets for enhanced training. To the human eye, these\naugmented images look very different to the originals. Previous work has\nsuggested to use this data augmentation technique for data anonymization.\nHowever, we show that latent diffusion models that are conditioned on features\nlike depth maps or edges to guide the diffusion process are not suitable as a\nprivacy preserving method. We use a contrastive learning approach to train a\nmodel that can correctly identify people out of a pool of candidates. Moreover,\nwe demonstrate that anonymization using conditioned diffusion models is\nsusceptible to black box attacks. We attribute the success of the described\nmethods to the conditioning of the latent diffusion model in the anonymization\nprocess. The diffusion model is instructed to produce similar edges for the\nanonymized images. Hence, a model can learn to recognize these patterns for\nidentification.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T09:27:51Z"}
{"aid":"http://arxiv.org/abs/2504.05876v1","title":"Topological ignition of the stealth coronal mass ejections","summary":"One of hot topics in the solar physics are the so-called 'stealth' coronal\nmass ejections (CME), which are not associated with any appreciable energy\nrelease events in the lower corona, such as the solar flares. It is sometimes\nassumed that these phenomena might be produced by some specific physical\nmechanism, but no particular suggestions were put forward. It is the aim of the\npresent paper to show that a promising explanation of the stealth CMEs can be\nbased on the so-called 'topological' ignition of the magnetic reconnection. As\na theoretical basis, we employ the Gorbachev-Kel'ner-Somov-Shvarts (GKSS) model\nof formation of the magnetic null point, which is produced by a specific\nsuperposition of the remote sources (sunspots) rather than by the local current\nsystems. As follows from our numerical simulations, the topological model\nexplains very well all basic features of the stealth CMEs: (i) the plasma\neruption develops without an appreciable heat release from the spot of\nreconnection, i.e., without the solar flare; (ii) the spot of reconnection\n(magnetic null point) can be formed far away from the location of the magnetic\nfield sources; (iii) the trajectories of eruption are strongly curved, which\ncan explain observability of CMEs generated behind the solar limb. Therefore,\nthe topological ignition of magnetic reconnection should be interesting both by\nitself, as a novel physical phenomenon, and as a prognostic tool for\nforecasting the stealth CMEs and the resulting unexpected geomagnetic storms.","main_category":"astro-ph.SR","categories":"astro-ph.SR,physics.space-ph","published":"2025-04-08T10:04:57Z"}
{"aid":"http://arxiv.org/abs/2504.05882v1","title":"Turin3D: Evaluating Adaptation Strategies under Label Scarcity in Urban\n  LiDAR Segmentation with Semi-Supervised Techniques","summary":"3D semantic segmentation plays a critical role in urban modelling, enabling\ndetailed understanding and mapping of city environments. In this paper, we\nintroduce Turin3D: a new aerial LiDAR dataset for point cloud semantic\nsegmentation covering an area of around 1.43 km2 in the city centre of Turin\nwith almost 70M points. We describe the data collection process and compare\nTurin3D with others previously proposed in the literature. We did not fully\nannotate the dataset due to the complexity and time-consuming nature of the\nprocess; however, a manual annotation process was performed on the validation\nand test sets, to enable a reliable evaluation of the proposed techniques. We\nfirst benchmark the performances of several point cloud semantic segmentation\nmodels, trained on the existing datasets, when tested on Turin3D, and then\nimprove their performances by applying a semi-supervised learning technique\nleveraging the unlabelled training set. The dataset will be publicly available\nto support research in outdoor point cloud segmentation, with particular\nrelevance for self-supervised and semi-supervised learning approaches given the\nabsence of ground truth annotations for the training set.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-08T10:17:14Z"}
{"aid":"http://arxiv.org/abs/2504.05905v1","title":"Rethinking Review Citations: Impact on Scientific Integrity","summary":"The proliferation of surveys and review articles in academic journals has\nimpacted citation metrics like impact factor and h-index, skewing evaluations\nof journal and researcher quality. This work investigates the implications of\nthis trend, focusing on the field of Computer Science, where a notable increase\nin review publications has led to inflated citation counts and rankings. While\nreviews serve as valuable literature overviews, they should not overshadow the\nprimary goal of research -to advance scientific knowledge through original\ncontributions. We advocate for prioritizing citations of primary research in\njournal articles to uphold citation integrity and ensure fair recognition of\nsubstantive contributions. This approach preserves the reliability of\ncitation-based metrics and supports genuine scientific advancement.","main_category":"cs.DL","categories":"cs.DL,cs.CY","published":"2025-04-08T11:02:31Z"}
{"aid":"http://arxiv.org/abs/2504.05959v1","title":"Old and New Results on Alphabetic Codes","summary":"This comprehensive survey examines the field of alphabetic codes, tracing\ntheir development from the 1960s to the present day. We explore classical\nalphabetic codes and their variants, analyzing their properties and the\nunderlying mathematical and algorithmic principles. The paper covers the\nfundamental relationship between alphabetic codes and comparison-based search\nprocedures and their applications in data compression, routing, and testing. We\nreview optimal alphabetic code construction algorithms, necessary and\nsufficient conditions for their existence, and upper bounds on the average code\nlength of optimal alphabetic codes. The survey also discusses variations and\ngeneralizations of the classical problem of constructing minimum average length\nalphabetic codes. By elucidating both classical results and recent findings,\nthis paper aims to serve as a valuable resource for researchers and students,\nconcluding with promising future research directions in this still-active\nfield.","main_category":"cs.IT","categories":"cs.IT,cs.DS,math.IT","published":"2025-04-08T12:15:53Z"}
{"aid":"http://arxiv.org/abs/2504.05988v1","title":"Consistency Relation for Fixed Point Dynamics","summary":"We gain insight on the fixed point dynamics of $d$ dimensional quantum field\ntheories by exploiting the critical behavior of the $d-\\epsilon$ sister\ntheories. To this end we first derive a self-consistent relation between the\n$d-\\epsilon$ scaling exponents and the associated $d$ dimensional beta\nfunctions. We then demonstrate that to account for an interacting fixed point\nin the original theory the related $d-\\epsilon$ scaling exponent must be\nmulti-valued in $\\epsilon$. We elucidate our findings by discussing several\nexamples such as the QCD Banks-Zaks infrared fixed point, QCD at large number\nof flavors, as well as the O(N) model in four dimensions. For the latter, we\nshow that although the $1/N$ corrections prevent the reconstruction of the\nrenormalization group flow, this is possible when adding the $1/N^2$\ncontributions.","main_category":"hep-ph","categories":"hep-ph,hep-th","published":"2025-04-08T12:50:27Z"}
{"aid":"http://arxiv.org/abs/2504.06006v1","title":"Optuna vs Code Llama: Are LLMs a New Paradigm for Hyperparameter Tuning?","summary":"Optimal hyperparameter selection is critical for maximizing neural network\nperformance, especially as models grow in complexity. This work investigates\nthe viability of using large language models (LLMs) for hyperparameter\noptimization by employing a fine-tuned version of Code Llama. Through\nparameter-efficient fine-tuning using LoRA, we adapt the LLM to generate\naccurate and efficient hyperparameter recommendations tailored to diverse\nneural network architectures. Unlike traditional methods such as Optuna, which\nrely on exhaustive trials, the proposed approach achieves competitive or\nsuperior results in terms of Root Mean Square Error (RMSE) while significantly\nreducing computational overhead. Our approach highlights that LLM-based\noptimization not only matches state-of-the-art methods like Tree-structured\nParzen Estimators but also accelerates the tuning process. This positions LLMs\nas a promising alternative to conventional optimization techniques,\nparticularly for rapid experimentation. Furthermore, the ability to generate\nhyperparameters in a single inference step makes this method particularly\nwell-suited for resource-constrained environments such as edge devices and\nmobile applications, where computational efficiency is paramount. The results\nconfirm that LLMs, beyond their efficiency, offer substantial time savings and\ncomparable stability, underscoring their value in advancing machine learning\nworkflows. All generated hyperparameters are included in the LEMUR Neural\nNetwork (NN) Dataset, which is publicly available and serves as an open-source\nbenchmark for hyperparameter optimization research.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.NE","published":"2025-04-08T13:15:47Z"}
{"aid":"http://arxiv.org/abs/2504.06032v1","title":"3D evolution of protein networks and lipid globules in heat-treated egg\n  yolk","summary":"Upon heating, egg yolk transforms from a liquid to a gel due to protein\ndenaturation. This process can serve as a useful model to better understand\nprotein denaturation in general. Using x-ray holographic tomography, we\ninvestigated the structural changes in egg yolk during boiling without the need\nfor complex sample fixation or drying. Our results reveal a developing\nseparation between proteins and lipids, with fatty components rapidly\naggregating into large globules that subsequently evolve into bubbles.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-08T13:35:25Z"}
{"aid":"http://arxiv.org/abs/2504.06033v1","title":"Parallel Small Vertex Connectivity in Near-Linear Work and\n  Polylogarithmic Depth","summary":"We present a randomized parallel algorithm in the {\\sf PRAM} model for\n$k$-vertex connectivity. Given an undirected simple graph, our algorithm either\nfinds a set of fewer than $k$ vertices whose removal disconnects the graph or\nreports that no such set exists. The algorithm runs in $O(m \\cdot\n\\text{poly}(k, \\log n))$ work and $O(\\text{poly}(k, \\log n))$ depth, which is\nnearly optimal for any $k = \\text{poly}(\\log n)$. Prior to our work, algorithms\nwith near-linear work and polylogarithmic depth were known only for $k=3$\n[Miller, Ramachandran, STOC'87]; for $k=4$, sequential algorithms achieving\nnear-linear time were known [Forster, Nanongkai, Yang, Saranurak,\nYingchareonthawornchai, SODA'20], but no algorithm with near-linear work could\nachieve even sublinear (on $n$) depth.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-08T13:35:38Z"}
{"aid":"http://arxiv.org/abs/2504.06059v1","title":"New designs of linear optical interferometers with minimal depth and\n  component count","summary":"We adapt an algorithm for CNOT circuits synthesis based on the Bruhat\ndecomposition to the design of linear optical circuits with Mach-Zehnder\ninterferometers (MZI). The synthesis algorithm reduces to designing sorting\nnetworks with nearest neighbor swapping operations as elementary gates. We\nrecover previous designs from the literature but with additional theoretical\nproperties regarding the compiler that implements unitaries on the\ninterferometer. Notably the compiler can always decide whether a unitary can be\nimplemented on a given interferometer and, if so, returns the shallowest\npossible implementation. We also show natural extensions of our framework for\nboson sampling experiments and for the coupling of multiple integrated\ninterferometers to design larger linear optical systems. In both cases, the\ndesigns are optimal in terms of number of optical components. Finally, we\npropose a greedy design which exploits the arbritrary-but-fixed coupling of\nseparate integrated interferometers to perform shallow boson sampling. We\ndiscuss the optimal interferometer dimensions to maximize the transmission.\nBeyond boson sampling, our developed framework allows a resource-favourable\nimplemention of any non-adaptive linear optical quantum algorithm, by providing\nthe shallowest possible interferometer for implementing this algorithm.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T14:03:04Z"}
{"aid":"http://arxiv.org/abs/2504.06069v1","title":"Physics-Constrained Neural Network for Metasurface Optical Response\n  Prediction","summary":"A physics-constrained neural network is presented for predicting the optical\nresponse of metasurfaces. Our approach incorporates physical laws directly into\nthe neural network architecture and loss function, addressing critical\nchallenges in the modeling of metasurfaces. Unlike methods that require\nspecialized weighting strategies or separate architectural branches to handle\ndifferent data regimes and phase wrapping discontinuities, this unified\napproach effectively addresses phase discontinuities, energy conservation\nconstraints, and complex gap-dependent behavior. We implement sine-cosine phase\nrepresentation with Euclidean normalization as a non-trainable layer within the\nnetwork, enabling the model to account for the periodic nature of phase while\nenforcing the mathematical constraint $\\sin^2 \\phi + \\cos^2 \\phi = 1$. A\nEuclidean distance-based loss function in the sine-cosine space ensures a\nphysically meaningful error metric while preventing discontinuity issues. The\nmodel achieves good, consistent performance with small, imbalanced datasets of\n580 and 1075 data points, compared to several thousand typically required by\nalternative approaches. This physics-informed approach preserves physical\ninterpretability while reducing reliance on large datasets and could be\nextended to other photonic structures by incorporating additional physical\nconstraints tailored to specific applications.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-08T14:10:28Z"}
{"aid":"http://arxiv.org/abs/2504.06094v1","title":"On the structure of DHR bimodules of abstract spin chains","summary":"Abstract spin chains axiomatize the structure of local observables on the 1D\nlattice which are invariant under a global symmetry, and arise at the physical\nboundary of 2+1D topologically ordered spin systems. In this paper, we study\ntensor categorical properties of DHR bimodules over abstract spin chains.\nAssuming that the charge transporters generate the algebra of observables, we\nprove that the associated category has a structure of modular tensor category\nwith respect to the natural braiding. Under an additional assumption of\nalgebraic Haag duality, this category becomes the Drinfeld center of the\nhalf-line fusion category.","main_category":"math.QA","categories":"math.QA,math-ph,math.MP,math.OA","published":"2025-04-08T14:35:19Z"}
{"aid":"http://arxiv.org/abs/2504.06121v1","title":"A Robust Real-Time Lane Detection Method with Fog-Enhanced Feature\n  Fusion for Foggy Conditions","summary":"Lane detection is a critical component of Advanced Driver Assistance Systems\n(ADAS). Existing lane detection algorithms generally perform well under\nfavorable weather conditions. However, their performance degrades significantly\nin adverse conditions, such as fog, which increases the risk of traffic\naccidents. This challenge is compounded by the lack of specialized datasets and\nmethods designed for foggy environments. To address this, we introduce the\nFoggyLane dataset, captured in real-world foggy scenarios, and synthesize two\nadditional datasets, FoggyCULane and FoggyTusimple, from existing popular lane\ndetection datasets. Furthermore, we propose a robust Fog-Enhanced Network for\nlane detection, incorporating a Global Feature Fusion Module (GFFM) to capture\nglobal relationships in foggy images, a Kernel Feature Fusion Module (KFFM) to\nmodel the structural and positional relationships of lane instances, and a\nLow-level Edge Enhanced Module (LEEM) to address missing edge details in foggy\nconditions. Comprehensive experiments demonstrate that our method achieves\nstate-of-the-art performance, with F1-scores of 95.04 on FoggyLane, 79.85 on\nFoggyCULane, and 96.95 on FoggyTusimple. Additionally, with TensorRT\nacceleration, the method reaches a processing speed of 38.4 FPS on the NVIDIA\nJetson AGX Orin, confirming its real-time capabilities and robustness in foggy\nenvironments.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T15:13:01Z"}
{"aid":"http://arxiv.org/abs/2504.06124v1","title":"Safe Interaction via Monte Carlo Linear-Quadratic Games","summary":"Safety is critical during human-robot interaction. But -- because people are\ninherently unpredictable -- it is often difficult for robots to plan safe\nbehaviors. Instead of relying on our ability to anticipate humans, here we\nidentify robot policies that are robust to unexpected human decisions. We\nachieve this by formulating human-robot interaction as a zero-sum game, where\n(in the worst case) the human's actions directly conflict with the robot's\nobjective. Solving for the Nash Equilibrium of this game provides robot\npolicies that maximize safety and performance across a wide range of human\nactions. Existing approaches attempt to find these optimal policies by\nleveraging Hamilton-Jacobi analysis (which is intractable) or linear-quadratic\napproximations (which are inexact). By contrast, in this work we propose a\ncomputationally efficient and theoretically justified method that converges\ntowards the Nash Equilibrium policy. Our approach (which we call MCLQ)\nleverages linear-quadratic games to obtain an initial guess at safe robot\nbehavior, and then iteratively refines that guess with a Monte Carlo search.\nNot only does MCLQ provide real-time safety adjustments, but it also enables\nthe designer to tune how conservative the robot is -- preventing the system\nfrom focusing on unrealistic human behaviors. Our simulations and user study\nsuggest that this approach advances safety in terms of both computation time\nand expected performance. See videos of our experiments here:\nhttps://youtu.be/KJuHeiWVuWY.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T15:18:38Z"}
{"aid":"http://arxiv.org/abs/2504.06144v1","title":"A Training-Free Style-aligned Image Generation with Scale-wise\n  Autoregressive Model","summary":"We present a training-free style-aligned image generation method that\nleverages a scale-wise autoregressive model. While large-scale text-to-image\n(T2I) models, particularly diffusion-based methods, have demonstrated\nimpressive generation quality, they often suffer from style misalignment across\ngenerated image sets and slow inference speeds, limiting their practical\nusability. To address these issues, we propose three key components: initial\nfeature replacement to ensure consistent background appearance, pivotal feature\ninterpolation to align object placement, and dynamic style injection, which\nreinforces style consistency using a schedule function. Unlike previous methods\nrequiring fine-tuning or additional training, our approach maintains fast\ninference while preserving individual content details. Extensive experiments\nshow that our method achieves generation quality comparable to competing\napproaches, significantly improves style alignment, and delivers inference\nspeeds over six times faster than the fastest model.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T15:39:25Z"}
{"aid":"http://arxiv.org/abs/2504.06161v1","title":"A Hom formula for Soergel modules","summary":"We study Soergel modules for arbitrary Coxeter groups. For infinite Coxeter\ngroups, we show that the homomorphisms between Soergel modules are in general\nmore than those coming from morphisms of Soergel bimodules. This result\nprovides a negative answer to a question posed by Soergel.\n  We further show that the dimensions of the morphism spaces agree with the\npairing in the Hecke algebra when Soergel modules are instead regarded as\nmodules over the structure algebra. Moreover, we use this module structure to\ndefine a distinguished submodule of indecomposable Soergel bimodules that\nmimics the cohomology submodule of the intersection cohomology. Combined with\nthe Hodge theory of Soergel bimodules, this can be used to extend results\nregarding the shape of Bruhat intervals, such as top-heaviness, to arbitrary\nCoxeter groups.","main_category":"math.RT","categories":"math.RT","published":"2025-04-08T15:58:42Z"}
{"aid":"http://arxiv.org/abs/2504.06169v1","title":"Linear Regulator-Based Synchronization of Positive Multi-Agent Systems","summary":"This paper addresses the positive synchronization of interconnected systems\non undirected graphs. For homogeneous positive systems, a static feedback\nprotocol design is proposed, based on the Linear Regulator problem. The\nsolution to the algebraic equation associated to the stabilizing policy can be\nfound using a linear program. Necessary and sufficient conditions on the\npositivity of each agent's trajectory for all nonnegative initial conditions\nare also provided. Simulations on large regular graphs with different nodal\ndegree illustrate the proposed results.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-08T16:08:07Z"}
{"aid":"http://arxiv.org/abs/2504.06172v1","title":"Monotonicity of functionals associated to product measures via their\n  Fourier transform and applications","summary":"Let $\\mu$ be a probability measure on $\\mathbb{R}$. We give conditions on the\nFourier transform of its density for functionals of the form\n$H(a)=\\int_{\\mathbb{R}^n}h(\\langle a,x\\rangle)\\mu^n(dx)$ to be Schur monotone.\nAs applications, we put certain known and new results under the same umbrella,\ngiven by a condition on the Fourier transform of the density. These results\ninclude certain moment comparisons for independent and identically distributed\nrandom vectors, when the norm is given by intersection bodies, and the\ncorresponding vector Khinchin inequalities. We also extend the discussion to\nhigher dimensions.","main_category":"math.PR","categories":"math.PR,math.FA","published":"2025-04-08T16:16:55Z"}
{"aid":"http://arxiv.org/abs/2504.06190v1","title":"No-scale supergravity","summary":"To connect supergravity with the real world, a highly non-trivial requirement\nis complete spontaneous supersymmetry breaking in an approximately flat\nfour-dimensional space-time. In no-scale supergravity models, this naturally\nhappens at the classical level: the gravitino mass, setting the scale of\nsupersymmetry breaking, slides along a flat direction of the potential with\nvanishing energy. This contribution briefly describes, with a personal\nselection of simple illustrative examples, some qualitative features of\nno-scale models that relate them to a possible dynamical generation of the\nhierarchies between the vacuum energy scale, the weak scale and the Planck\nscale. It includes comments on their versions with extended supersymmetry, on\ntheir higher-dimensional origin and on how their still unsolved problems of\nquantum stability can already be addressed, with some results, at the level of\nsupergravity compactifications, although their solution (if any) will\neventually require a better understanding of superstring theories.","main_category":"hep-th","categories":"hep-th","published":"2025-04-08T16:34:09Z"}
{"aid":"http://arxiv.org/abs/2504.06213v1","title":"Guidelines for designs for ultrastable laser with $\\mathbf{10^{-17}}$\n  fractional frequency instability","summary":"Lasers with long coherence time and narrow linewidth are an essential tool\nfor quantum sensors and clocks. Ultrastable cavities and laser systems are now\ncommercially available with fractional frequency instabilities in the mid\n$10^{-16}$ range. This document aims to provide technical guidance for\nresearchers starting in the field of ultrastable lasers and to give an outlook\ntoward the next generation of improved ultrastable lasers. These guidelines\nhave arisen from the scope of the EMPIR project ``Next generation ultrastable\nlasers'' ( https://www.ptb.de/empir2021/nextlasers ) with contributions from\nthe European project partners.","main_category":"physics.optics","categories":"physics.optics,physics.ins-det","published":"2025-04-08T16:58:14Z"}
{"aid":"http://arxiv.org/abs/2504.06248v1","title":"Kuramoto meets Koopman: Constants of motion, symmetries, and network\n  motifs","summary":"The partial integrability of the Kuramoto model is often thought to be\nrestricted to identically connected oscillators or groups thereof. Yet, the\nexact connectivity prerequisites for having constants of motion on more general\ngraphs have remained elusive. Using spectral properties of the Koopman\ngenerator, we derive necessary and sufficient conditions for the existence of\ndistinct constants of motion in the Kuramoto model with heterogeneous phase\nlags on any weighted, directed, signed graph. This reveals a broad class of\nnetwork motifs that support conserved quantities. Furthermore, we identify Lie\nsymmetries that generate new constants of motion. Our results provide a\nrigorous theoretical application of Koopman's framework to nonlinear dynamics\non complex networks.","main_category":"nlin.AO","categories":"nlin.AO,math-ph,math.MP,nlin.SI","published":"2025-04-08T17:53:08Z"}
{"aid":"http://arxiv.org/abs/2504.06250v1","title":"Fractal and Regular Geometry of Deep Neural Networks","summary":"We study the geometric properties of random neural networks by investigating\nthe boundary volumes of their excursion sets for different activation\nfunctions, as the depth increases. More specifically, we show that, for\nactivations which are not very regular (e.g., the Heaviside step function), the\nboundary volumes exhibit fractal behavior, with their Hausdorff dimension\nmonotonically increasing with the depth. On the other hand, for activations\nwhich are more regular (e.g., ReLU, logistic and $\\tanh$), as the depth\nincreases, the expected boundary volumes can either converge to zero, remain\nconstant or diverge exponentially, depending on a single spectral parameter\nwhich can be easily computed. Our theoretical results are confirmed in some\nnumerical experiments based on Monte Carlo simulations.","main_category":"math.PR","categories":"math.PR,cs.LG,stat.ML","published":"2025-04-08T17:56:05Z"}
{"aid":"http://arxiv.org/abs/2504.06258v1","title":"Two-Dimensional Ferroelectric Altermagnets: From Model to Material\n  Realization","summary":"Multiferroic altermagnets offer new opportunities for magnetoelectric\ncoupling and electrically tunable spintronics. However, due to intrinsic\nsymmetry conflicts between altermagnetism and ferroelectricity, achieving their\ncoexistence, known as ferroelectric altermagnets (FEAM), remains an outstanding\nchallenge, especially in two-dimensional (2D) systems. Here, we propose a\nuniversal, symmetry-based design principle for 2D FEAM, supported by\ntight-binding models and first-principles calculations. We show that\nferroelectric lattice distortions can break spin equivalence and introduce the\nnecessary rotational symmetry, enabling altermagnetism with electrically\nreversible spin splitting. Guided by this framework, we identify a family of 2D\nvanadium oxyhalides and sulfide halides as promising FEAM candidates. In these\ncompounds, pseudo Jahn-Teller distortions and Peierls-like dimerization\ncooperatively establish the required symmetry conditions. We further propose\nthe magneto-optical Kerr effect as an experimental probe to confirm FEAM and\nits electric spin reversal. Our findings provide a practical framework for 2D\nFEAM and advancing electrically controlled spintronic devices.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T17:58:59Z"}
{"aid":"http://arxiv.org/abs/2504.06259v1","title":"Realization and Calibration of Continuously Parameterized Two-Qubit\n  Gates on a Trapped-Ion Quantum Processor","summary":"Continuously parameterized two-qubit gates are a key feature of\nstate-of-the-art trapped-ion quantum processors as they have favorable error\nscalings and show distinct improvements in circuit performance over more\nrestricted maximally entangling gatesets. In this work, we provide a\ncomprehensive and pedagogical discussion on how to practically implement these\ncontinuously parameterized M{\\o}lmer-S{\\o}rensen gates on the Quantum\nScientific Computing Open User Testbed (QSCOUT), a low-level trapped-ion\nprocessor. To generate the arbitrary entangling angles, $\\theta$, we simply\nscale the amplitude of light used to generate the entanglement. However, doing\nso requires careful consideration of amplifier saturation as well as the\nvariable light shifts that result. As such, we describe a method to calibrate\nand cancel the dominant fourth-order effects, followed by a dynamic virtual\nphase advance during the gate to cancel any residual light shifts, and find a\nlinear scaling between $\\theta$ and the residual light shift. Once, we have\nconsidered and calibrated these effects, we demonstrate performance improvement\nwith decreasing $\\theta$. Finally, we describe nuances of hardware control to\ntransform the XX-type interaction of the arbitrary-angle M{\\o}lmer-S{\\o}rensen\ngate into a phase-agnostic and crosstalk-mitigating ZZ interaction.","main_category":"quant-ph","categories":"quant-ph,physics.atom-ph","published":"2025-04-08T17:59:10Z"}
{"aid":"http://arxiv.org/abs/2504.06265v1","title":"GOLLuM: Gaussian Process Optimized LLMs -- Reframing LLM Finetuning\n  through Bayesian Optimization","summary":"Large Language Models (LLMs) can encode complex relationships in their latent\nspaces, yet harnessing them for optimization under uncertainty remains\nchallenging. We address this gap with a novel architecture that reframes LLM\nfinetuning as Gaussian process (GP) marginal likelihood optimization via deep\nkernel methods. We introduce LLM-based deep kernels, jointly optimized with GPs\nto preserve the benefits of both - LLMs to provide a rich and flexible input\nspace for Bayesian optimization and - GPs to model this space with predictive\nuncertainty for more efficient sampling. Applied to Buchwald-Hartwig reaction\noptimization, our method nearly doubles the discovery rate of high-performing\nreactions compared to static LLM embeddings (from 24% to 43% coverage of the\ntop 5% reactions in just 50 optimization iterations). We also observe a 14%\nimprovement over domain-specific representations without requiring specialized\nfeatures. Extensive empirical evaluation across 19 benchmarks - ranging from\ngeneral chemistry to reaction and molecular property optimization -\ndemonstrates our method's robustness, generality, and consistent improvements\nacross: (1) tasks, (2) LLM architectures (encoder, decoder, encoder-decoder),\n(3) pretraining domains (chemistry-related or general-purpose) and (4)\nhyperparameter settings (tuned once on a single dataset). Finally, we explain\nthese improvements: joint LLM-GP optimization through marginal likelihood\nimplicitly performs contrastive learning, aligning representations to produce\n(1) better-structured embedding spaces, (2) improved uncertainty calibration,\nand (3) more efficient sampling - without requiring any external loss. This\nwork provides both practical advances in sample-efficient optimization and\ninsights into what makes effective Bayesian optimization.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-08T17:59:57Z"}
{"aid":"http://arxiv.org/abs/2504.06545v1","title":"Radio emission across the entire rotation phases of pulsars","summary":"Super-sensitive observations of bright pulsars by the Five-hundred-meter\nAperture Spherical radio Telescope (FAST) have revealed weak radio emission\ncontinuously emerged in the rotation phases between the main pulse and\ninterpulse of an rotating neutron star. We develop a model for the polarized\nradio emission radiated from different heights in the pulsar magnetosphere and\nexamine emission intensity distribution over the whole rotation phases of\npulsars seen from all directions by the line of sight. We find that for pulsars\nwith small periods and the magnetosphere filled with much more relativistic\nparticles, the polarized radio emission can be generated in all rotation phases\nfor both the aligned and perpendicular rotating neutron stars. When the line of\nsight cuts the pulsar emission beam between the rotation and magnetic axes, the\npolarization angles have the same sense of variation gradient for the ``main''\npulse and ``interpulse''. If the line of sight cuts the beams between the\ninclined magnetic axis and the equator, the opposite senses can be found for\nthe main pulse and interpulse. In addition to the pulsed emission, we find\npersistent radio emission generated in the pulsar magnetosphere. The model can\nnaturally explain the emission across the entire rotation phases.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-09T03:00:39Z"}
{"aid":"http://arxiv.org/abs/2504.06550v1","title":"Blameocracy: Causal Attribution in Political Communication","summary":"We propose a supervised method to detect causal attribution in political\ntexts, distinguishing between expressions of merit and blame. Analyzing four\nmillion tweets shared by U.S. Congress members from 2012 to 2023, we document a\npronounced shift toward causal attribution following the 2016 presidential\nelection. The shift reflects changes in rhetorical strategy rather than\ncompositional variation in the actors or topics of the political debate. Within\ncausal communication, a trade-off emerges between positive and negative tone,\nwith power status as the key determinant: government emphasizes merit, while\nopposition casts blame. This pattern distinguishes causal from purely affective\ncommunication. Additionally, we find that blame is associated with lower trust\nin politicians, perceived government effectiveness, and spreads more virally\nthan merit.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-09T03:12:16Z"}
{"aid":"http://arxiv.org/abs/2504.06551v1","title":"Bridging Queries and Tables through Entities in Table Retrieval","summary":"Table retrieval is essential for accessing information stored in structured\ntabular formats; however, it remains less explored than text retrieval. The\ncontent of the table primarily consists of phrases and words, which include a\nlarge number of entities, such as time, locations, persons, and organizations.\nEntities are well-studied in the context of text retrieval, but there is a\nnoticeable lack of research on their applications in table retrieval. In this\nwork, we explore how to leverage entities in tables to improve retrieval\nperformance. First, we investigate the important role of entities in table\nretrieval from a statistical perspective and propose an entity-enhanced\ntraining framework. Subsequently, we use the type of entities to highlight\nentities instead of introducing an external knowledge base. Moreover, we design\nan interaction paradigm based on entity representations. Our proposed framework\nis plug-and-play and flexible, making it easy to integrate into existing table\nretriever training processes. Empirical results on two table retrieval\nbenchmarks, NQ-TABLES and OTT-QA, show that our proposed framework is both\nsimple and effective in enhancing existing retrievers. We also conduct\nextensive analyses to confirm the efficacy of different components. Overall,\nour work provides a promising direction for elevating table retrieval,\nenlightening future research in this area.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-09T03:16:33Z"}
{"aid":"http://arxiv.org/abs/2504.06556v1","title":"Improved Bounds for Codes over Trees","summary":"Codes over trees were introduced recently to bridge graph theory and coding\ntheory with diverse applications in computer science and beyond. A central\nchallenge lies in determining the maximum number of labelled trees over $n$\nnodes with pairwise distance at least $d$, denoted by $A(n,d)$, where the\ndistance between any two labelled trees is the minimum number of edit edge\noperations in order to transform one tree to another. By various tools from\ngraph theory and algebra, we show that when $n$ is large,\n$A(n,d)=O((Cn)^{n-d})$ for any $d\\leq n-2$, and $A(n,d)=\\Omega((cn)^{n-d})$ for\nany $d$ linear with $n$, where constants $c\\in(0,1)$ and $C\\in [1/2,1)$\ndepending on $d$. Previously, only $A(n,d)=O(n^{n-d-1})$ for fixed $d$ and\n$A(n,d)=\\Omega(n^{n-2d})$ for $d\\leq n/2$ were known, while the upper bound is\nimproved for any $d$ and the lower bound is improved for $d\\geq 2\\sqrt{n}$.\nFurther, for any fixed integer $k$, we prove the existence of codes of size\n$\\Omega(n^k)$ when $n-d=o(n)$, and give explicit constructions of codes which\nshow $A(n,n-4)=\\Omega(n^2)$ and $A(n,n-13)=\\Omega(n^3)$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-09T03:35:21Z"}
{"aid":"http://arxiv.org/abs/2504.06564v1","title":"Do Reasoning Models Show Better Verbalized Calibration?","summary":"Large reasoning models (LRMs) have recently shown impressive capabilities in\ncomplex reasoning by leveraging increased test-time computation and exhibiting\nbehaviors akin to human-like deliberation. Despite these advances, it remains\nan open question whether LRMs are better calibrated - particularly in their\nverbalized confidence - compared to instruction-tuned counterparts. In this\npaper, we investigate the calibration properties of LRMs trained via supervised\nfine-tuning distillation on long reasoning traces (henceforth SFT reasoning\nmodels) and outcome-based reinforcement learning for reasoning (henceforth RL\nreasoning models) across diverse domains. Our findings reveal that LRMs\nsignificantly outperform instruction-tuned models on complex reasoning tasks in\nboth accuracy and confidence calibration. In contrast, we find surprising\ntrends in the domain of factuality in particular. On factuality tasks, while\nDeepseek-R1 shows strong calibration behavior, smaller QwQ-32B shows no\nimprovement over instruct models; moreover, SFT reasoning models display worse\ncalibration (greater overconfidence) compared to instruct models. Our results\nprovide evidence for a potentially critical role of reasoning-oriented RL\ntraining in improving LLMs' capacity for generating trustworthy, self-aware\noutputs.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T03:58:19Z"}
{"aid":"http://arxiv.org/abs/2504.06578v1","title":"Attributes-aware Visual Emotion Representation Learning","summary":"Visual emotion analysis or recognition has gained considerable attention due\nto the growing interest in understanding how images can convey rich semantics\nand evoke emotions in human perception. However, visual emotion analysis poses\ndistinctive challenges compared to traditional vision tasks, especially due to\nthe intricate relationship between general visual features and the different\naffective states they evoke, known as the affective gap. Researchers have used\ndeep representation learning methods to address this challenge of extracting\ngeneralized features from entire images. However, most existing methods\noverlook the importance of specific emotional attributes such as brightness,\ncolorfulness, scene understanding, and facial expressions. Through this paper,\nwe introduce A4Net, a deep representation network to bridge the affective gap\nby leveraging four key attributes: brightness (Attribute 1), colorfulness\n(Attribute 2), scene context (Attribute 3), and facial expressions (Attribute\n4). By fusing and jointly training all aspects of attribute recognition and\nvisual emotion analysis, A4Net aims to provide a better insight into emotional\ncontent in images. Experimental results show the effectiveness of A4Net,\nshowcasing competitive performance compared to state-of-the-art methods across\ndiverse visual emotion datasets. Furthermore, visualizations of activation maps\ngenerated by A4Net offer insights into its ability to generalize across\ndifferent visual emotion datasets.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.MM","published":"2025-04-09T05:00:43Z"}
{"aid":"http://arxiv.org/abs/2504.06579v1","title":"Coherence-decoherence interplay in quantum systems due to projective\n  stochastic pulses: The case of Rabi oscillations","summary":"The interplay of coherence and decoherence is played out in a three-level\nquantum system, in which the third level is incoherently coupled to the second\none which itself is in coherent interaction with the first level. The study is\nbased on a stochastic scenario in which the coherent, unitary evolution of the\nsystem is randomly interrupted by a Poisson-driven pulse sequence. In the\nabsence of an external pulse, the system undergoes coherent, unitary evolution\nrestricted to the subspace spanned by the first level (level $1$) and the\nsecond level (level $2$). The application of a pulse induces transitions\nbetween the second and the third level (level $3$), thereby introducing\nnon-unitary effects that perturb the otherwise isolated two-level dynamics. The\npulses are assumed to have infinitesimal duration, with strengths modeled as\nrandom variables that are uncorrelated across different pulses. A\nrepresentative model for the stochastically-averaged transition (super)operator\nmimicking the dynamics induced by the application of pulses allows for an\nanalytical derivation of the matrix elements of the averaged density operator.\nWhen the system is initially in level $1$, we obtain in particular the temporal\nbehavior of the stay-put probability, that is, the probability $P_1(t)$ that\nthe system is still in level $1$ at time $t$. As a function of time, the\nquantity $P_1(t)$ exhibits a coherence-to-decoherence crossover behavior. At\nshort times $t \\ll 1/\\lambda$, where $\\lambda$ is the average frequency at\nwhich pulses are applied to the system, coherent dynamics dominate.\nConsequently, $P_1(t)$ displays pronounced Rabi-like oscillations. At long\ntimes $t \\gg 1/\\lambda$, decoherence effects prevail, leading to an exponential\ndecay of the form $P_1(t) \\sim \\exp(-\\lambda t)$.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-09T05:02:08Z"}
{"aid":"http://arxiv.org/abs/2504.06581v1","title":"Right Prediction, Wrong Reasoning: Uncovering LLM Misalignment in RA\n  Disease Diagnosis","summary":"Large language models (LLMs) offer a promising pre-screening tool, improving\nearly disease detection and providing enhanced healthcare access for\nunderprivileged communities. The early diagnosis of various diseases continues\nto be a significant challenge in healthcare, primarily due to the nonspecific\nnature of early symptoms, the shortage of expert medical practitioners, and the\nneed for prolonged clinical evaluations, all of which can delay treatment and\nadversely affect patient outcomes. With impressive accuracy in prediction\nacross a range of diseases, LLMs have the potential to revolutionize clinical\npre-screening and decision-making for various medical conditions. In this work,\nwe study the diagnostic capability of LLMs for Rheumatoid Arthritis (RA) with\nreal world patients data. Patient data was collected alongside diagnoses from\nmedical experts, and the performance of LLMs was evaluated in comparison to\nexpert diagnoses for RA disease prediction. We notice an interesting pattern in\ndisease diagnosis and find an unexpected \\textit{misalignment between\nprediction and explanation}. We conduct a series of multi-round analyses using\ndifferent LLM agents. The best-performing model accurately predicts rheumatoid\narthritis (RA) diseases approximately 95\\% of the time. However, when medical\nexperts evaluated the reasoning generated by the model, they found that nearly\n68\\% of the reasoning was incorrect. This study highlights a clear misalignment\nbetween LLMs high prediction accuracy and its flawed reasoning, raising\nimportant questions about relying on LLM explanations in clinical settings.\n\\textbf{LLMs provide incorrect reasoning to arrive at the correct answer for RA\ndisease diagnosis.}","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-09T05:04:01Z"}
{"aid":"http://arxiv.org/abs/2504.06636v1","title":"BBQRec: Behavior-Bind Quantization for Multi-Modal Sequential\n  Recommendation","summary":"Multi-modal sequential recommendation systems leverage auxiliary signals\n(e.g., text, images) to alleviate data sparsity in user-item interactions.\nWhile recent methods exploit large language models to encode modalities into\ndiscrete semantic IDs for autoregressive prediction, we identify two critical\nlimitations: (1) Existing approaches adopt fragmented quantization, where\nmodalities are independently mapped to semantic spaces misaligned with\nbehavioral objectives, and (2) Over-reliance on semantic IDs disrupts\ninter-modal semantic coherence, thereby weakening the expressive power of\nmulti-modal representations for modeling diverse user preferences.\n  To address these challenges, we propose a Behavior-Bind multi-modal\nQuantization for Sequential Recommendation (BBQRec for short) featuring\ndual-aligned quantization and semantics-aware sequence modeling. First, our\nbehavior-semantic alignment module disentangles modality-agnostic behavioral\npatterns from noisy modality-specific features through contrastive codebook\nlearning, ensuring semantic IDs are inherently tied to recommendation tasks.\nSecond, we design a discretized similarity reweighting mechanism that\ndynamically adjusts self-attention scores using quantized semantic\nrelationships, preserving multi-modal synergies while avoiding invasive\nmodifications to the sequence modeling architecture. Extensive evaluations\nacross four real-world benchmarks demonstrate BBQRec's superiority over the\nstate-of-the-art baselines.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-09T07:19:48Z"}
{"aid":"http://arxiv.org/abs/2504.06640v1","title":"Design and use of devices to assist movement of the upper limb: review\n  of the literature","summary":"This article explores assistive devices for upper limb movement in people\nwith disabilities through a systematic review based on the PRISMA methodology.\nThe studied devices encompass technologies ranging from orthoses to advanced\nrobotics, aiming to compensate for or supplement motor impairments. The results\nhighlight the diversity of applications (rehabilitation, daily living\nactivities), targeted body segments (distal, proximal, or global), as well as\ncontrol mechanisms and interfaces used. However, despite the variety of\npromising prototypes, few devices are commercially available, limiting their\nreal impact on end users. Existing technologies, while effective in improving\nfunctional autonomy and quality of life, still face challenges in terms of\nergonomics, cost, and portability. In conclusion, this article emphasizes the\nimportance of a user-centered approach and proposes avenues for the development\nof innovative, modular, and accessible assistive devices.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-09T07:32:02Z"}
{"aid":"http://arxiv.org/abs/2504.06643v1","title":"AMAD: AutoMasked Attention for Unsupervised Multivariate Time Series\n  Anomaly Detection","summary":"Unsupervised multivariate time series anomaly detection (UMTSAD) plays a\ncritical role in various domains, including finance, networks, and sensor\nsystems. In recent years, due to the outstanding performance of deep learning\nin general sequential tasks, many models have been specialized for deep UMTSAD\ntasks and have achieved impressive results, particularly those based on the\nTransformer and self-attention mechanisms. However, the sequence anomaly\nassociation assumptions underlying these models are often limited to specific\npredefined patterns and scenarios, such as concentrated or peak anomaly\npatterns. These limitations hinder their ability to generalize to diverse\nanomaly situations, especially where the lack of labels poses significant\nchallenges. To address these issues, we propose AMAD, which integrates\n\\textbf{A}uto\\textbf{M}asked Attention for UMTS\\textbf{AD} scenarios. AMAD\nintroduces a novel structure based on the AutoMask mechanism and an attention\nmixup module, forming a simple yet generalized anomaly association\nrepresentation framework. This framework is further enhanced by a Max-Min\ntraining strategy and a Local-Global contrastive learning approach. By\ncombining multi-scale feature extraction with automatic relative association\nmodeling, AMAD provides a robust and adaptable solution to UMTSAD challenges.\nExtensive experimental results demonstrate that the proposed model achieving\ncompetitive performance results compared to SOTA benchmarks across a variety of\ndatasets.","main_category":"cs.LG","categories":"cs.LG,cs.AI,I.5.1","published":"2025-04-09T07:32:59Z"}
{"aid":"http://arxiv.org/abs/2504.06647v1","title":"Uni-PrevPredMap: Extending PrevPredMap to a Unified Framework of\n  Prior-Informed Modeling for Online Vectorized HD Map Construction","summary":"Safety constitutes a foundational imperative for autonomous driving systems,\nnecessitating the maximal incorporation of accessible external prior\ninformation. This study establishes that temporal perception buffers and\ncost-efficient maps inherently form complementary prior sources for online\nvectorized high-definition (HD) map construction. We present Uni-PrevPredMap, a\nunified prior-informed framework that systematically integrates two synergistic\ninformation sources: previous predictions and simulated outdated HD maps. The\nframework introduces two core innovations: a tile-indexed 3D vectorized global\nmap processor enabling efficient refreshment, storage, and retrieval of 3D\nvectorized priors; a tri-mode operational optimization paradigm ensuring\nconsistency across prior-free, map-absent, and map-prior scenarios while\nmitigating reliance on idealized map fidelity assumptions. Uni-PrevPredMap\nachieves state-of-the-art performance in map-free scenarios across established\nonline vectorized HD map construction benchmarks. When provided with simulated\noutdated HD maps, the framework exhibits robust capabilities in error-resilient\nprior fusion, empirically confirming the synergistic complementarity between\nprevious predictions and simulated outdated HD maps. Code will be available at\nhttps://github.com/pnnnnnnn/Uni-PrevPredMap.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T07:36:17Z"}
{"aid":"http://arxiv.org/abs/2504.06672v1","title":"RAGME: Retrieval Augmented Video Generation for Enhanced Motion Realism","summary":"Video generation is experiencing rapid growth, driven by advances in\ndiffusion models and the development of better and larger datasets. However,\nproducing high-quality videos remains challenging due to the high-dimensional\ndata and the complexity of the task. Recent efforts have primarily focused on\nenhancing visual quality and addressing temporal inconsistencies, such as\nflickering. Despite progress in these areas, the generated videos often fall\nshort in terms of motion complexity and physical plausibility, with many\noutputs either appearing static or exhibiting unrealistic motion. In this work,\nwe propose a framework to improve the realism of motion in generated videos,\nexploring a complementary direction to much of the existing literature.\nSpecifically, we advocate for the incorporation of a retrieval mechanism during\nthe generation phase. The retrieved videos act as grounding signals, providing\nthe model with demonstrations of how the objects move. Our pipeline is designed\nto apply to any text-to-video diffusion model, conditioning a pretrained model\non the retrieved samples with minimal fine-tuning. We demonstrate the\nsuperiority of our approach through established metrics, recently proposed\nbenchmarks, and qualitative results, and we highlight additional applications\nof the framework.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T08:14:05Z"}
{"aid":"http://arxiv.org/abs/2504.06698v1","title":"Emergent Metric from Wavelet-transformed Quantum Field Theory","summary":"We introduce a method of reverse holography by which a bulk metric is shown\nto arise from locally computable multiscale correlations of a boundary quantum\nfield theory (QFT). The metric is obtained from the Petz-R\\'enyi mutual\ninformation using as input the correlations computed from the continuous\nwavelet transform. We show for free massless fermionic and bosonic QFTs that\nthe emerging metric is asymptotically anti-de Sitter space (AdS), and that the\nparameters fixing the geometry are tunable by changing the chosen wavelet\nbasis. The method is applicable to a variety of boundary QFTs that need not be\nconformal field theories.","main_category":"hep-th","categories":"hep-th,quant-ph","published":"2025-04-09T09:04:54Z"}
{"aid":"http://arxiv.org/abs/2504.06765v1","title":"Characterization of infinitesimal boundedness of Schrödinger\n  operator","summary":"In this paper, we characterize the weighted infinitesimal boundedness: for\n$0<\\alpha<n$ and $1<p<\\infty$,\n  $$\\|V\\phi\\|_{L^{p}(w)}^{p}\\leq\\epsilon\\|(-\\Delta)^{\\frac{\\alpha}{2}}\\phi\\|_{L^{p}(w)}^{p}+C(\\epsilon)\\|\\phi\\|_{L^{p}(w)}^{p}.$$\n  In particular, we extend the classical result due to Maz'ya and Verbitsky by\nusing Carleson condition, localization estimates and capacity theory.","main_category":"math.CA","categories":"math.CA","published":"2025-04-09T10:41:02Z"}
{"aid":"http://arxiv.org/abs/2504.06766v1","title":"FamilyTool: A Multi-hop Personalized Tool Use Benchmark","summary":"The integration of tool learning with Large Language Models (LLMs) has\nexpanded their capabilities in handling complex tasks by leveraging external\ntools. However, existing benchmarks for tool learning inadequately address\ncritical real-world personalized scenarios, particularly those requiring\nmulti-hop reasoning and inductive knowledge adaptation in dynamic environments.\nTo bridge this gap, we introduce FamilyTool, a novel benchmark grounded in a\nfamily-based knowledge graph (KG) that simulates personalized, multi-hop tool\nuse scenarios. FamilyTool challenges LLMs with queries spanning 1 to 3\nrelational hops (e.g., inferring familial connections and preferences) and\nincorporates an inductive KG setting where models must adapt to unseen user\npreferences and relationships without re-training, a common limitation in prior\napproaches that compromises generalization. We further propose KGETool: a\nsimple KG-augmented evaluation pipeline to systematically assess LLMs' tool use\nability in these settings. Experiments reveal significant performance gaps in\nstate-of-the-art LLMs, with accuracy dropping sharply as hop complexity\nincreases and inductive scenarios exposing severe generalization deficits.\nThese findings underscore the limitations of current LLMs in handling\npersonalized, evolving real-world contexts and highlight the urgent need for\nadvancements in tool-learning frameworks. FamilyTool serves as a critical\nresource for evaluating and advancing LLM agents' reasoning, adaptability, and\nscalability in complex, dynamic environments. Code and dataset are available at\nGithub.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-09T10:42:36Z"}
{"aid":"http://arxiv.org/abs/2504.06789v1","title":"When is the partial map classifier a Sierpiński cone?","summary":"We study the relationship between partial map classifiers, Sierpi\\'nski\ncones, and axioms for synthetic higher categories and domains within univalent\nfoundations. In particular, we show that synthetic $\\infty$-categories are\nclosed under partial map classifiers assuming Phoa's principle, and we isolate\na new reflective subuniverse of types within which the Sierpi\\'nski cone (a lax\ncolimit) can be computed as a partial map classifier by strengthening the Segal\ncondition.","main_category":"cs.LO","categories":"cs.LO,cs.PL,math.CT","published":"2025-04-09T11:27:54Z"}
{"aid":"http://arxiv.org/abs/2504.06792v1","title":"Domain-Specific Pruning of Large Mixture-of-Experts Models with Few-shot\n  Demonstrations","summary":"Mixture-of-Experts (MoE) models achieve a favorable trade-off between\nperformance and inference efficiency by activating only a subset of experts.\nHowever, the memory overhead of storing all experts remains a major limitation,\nespecially in large-scale MoE models such as DeepSeek-R1 (671B). In this study,\nwe investigate domain specialization and expert redundancy in large-scale MoE\nmodels and uncover a consistent behavior we term few-shot expert localization,\nwith only a few demonstrations, the model consistently activates a sparse and\nstable subset of experts. Building on this observation, we propose a simple yet\neffective pruning framework, EASY-EP, that leverages a few domain-specific\ndemonstrations to identify and retain only the most relevant experts. EASY-EP\ncomprises two key components: output-aware expert importance assessment and\nexpert-level token contribution estimation. The former evaluates the importance\nof each expert for the current token by considering the gating scores and\nmagnitudes of the outputs of activated experts, while the latter assesses the\ncontribution of tokens based on representation similarities after and before\nrouted experts. Experiments show that our method can achieve comparable\nperformances and $2.99\\times$ throughput under the same memory budget with full\nDeepSeek-R1 with only half the experts. Our code is available at\nhttps://github.com/RUCAIBox/EASYEP.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-09T11:34:06Z"}
{"aid":"http://arxiv.org/abs/2504.06795v1","title":"Winning and nullity of inhomogeneous bad","summary":"We prove the hyperplane absolute winning property of weighted inhomogeneous\nbadly approximable vectors in $\\mathbb{R}^d$. This answers a question by\nBeresnevich--Nesharim--Yang and extends the main result of [Geometric and\nFunctional Analysis, 31 (1), 1-33, 2021] to the inhomogeneous set-up.\n  We also show for any nondegenerate curve and nondegenerate analytic manifold\nthat almost every point is not weighted inhomogeneous badly approximable for\nany weight. This is achieved by duality and the quantitative nondivergence\nestimates from homogeneous dynamics motivated by [Acta Math. 231 (2023), 1-30],\ntogether with the methods from [arXiv:2307.10109].","main_category":"math.NT","categories":"math.NT,math.DS","published":"2025-04-09T11:38:28Z"}
{"aid":"http://arxiv.org/abs/2504.06824v1","title":"A Roadmap for Improving Data Reliability and Sharing in Crosslinking\n  Mass Spectrometry","summary":"Crosslinking Mass Spectrometry (MS) can uncover protein-protein interactions\nand provide structural information on proteins in their native cellular\nenvironments. Despite its promise, the field remains hampered by inconsistent\ndata formats, variable approaches to error control, and insufficient\ninteroperability with global data repositories. Recent advances, especially in\nfalse discovery rate (FDR) models and pipeline benchmarking, show that\nCrosslinking MS data can reach a reliability that matches the demand of\nintegrative structural biology. To drive meaningful progress, however, the\ncommunity must agree on error estimation, open data formats, and streamlined\nrepository submissions. This perspective highlights these challenges, clarifies\nremaining barriers, and frames practical next steps. Successful field\nharmonisation will enhance the acceptance of Crosslinking MS in the broader\nbiological community and is critical for the dependability of the data, no\nmatter where it is produced.","main_category":"q-bio.OT","categories":"q-bio.OT","published":"2025-04-09T12:32:39Z"}
{"aid":"http://arxiv.org/abs/2504.06833v1","title":"Symbolic Parallel Composition for Multi-language Protocol Verification","summary":"The implementation of security protocols often combines different languages.\nThis practice, however, poses a challenge to traditional verification\ntechniques, which typically assume a single-language environment and,\ntherefore, are insufficient to handle challenges presented by the interplay of\ndifferent languages. To address this issue, we establish principles for\ncombining multiple programming languages operating on different atomic types\nusing a symbolic execution semantics. This facilitates the (parallel)\ncomposition of labeled transition systems, improving the analysis of complex\nsystems by streamlining communication between diverse programming languages. By\ntreating the Dolev-Yao (DY) model as a symbolic abstraction, our approach\neliminates the need for translation between different base types, such as\nbitstrings and DY terms. Our technique provides a foundation for securing\ninteractions in multi-language environments, enhancing program verification and\nsystem analysis in complex, interconnected systems.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-09T12:50:03Z"}
{"aid":"http://arxiv.org/abs/2504.06865v1","title":"On manifolds with almost non-negative Ricci curvature and\n  integrally-positive $k^{th}$-scalar curvature","summary":"We consider manifolds with almost non-negative Ricci curvature and strictly\npositive integral lower bounds on the sum of the lowest $k$ eigenvalues of the\nRicci tensor.\n  If $(M^n,g)$ is a Riemannian manifold satisfying such curvature bounds for\n$k=2$, then we show that $M$ is contained in a neighbourhood of controlled\nwidth of an isometrically embedded $1$-dimensional sub-manifold. From this, we\ndeduce several metric and topological consequences: $M$ has at most linear\nvolume growth and at most two ends, the first Betti number of $M$ is bounded\nabove by $1$, and there is precise information on elements of infinite order in\n$\\pi_1(M)$.\n  If $(M^n,g)$ is a Riemannian manifold satisfying such bounds for $k\\geq 2$\nand additionally the Ricci curvature is asymptotically non-negative, then we\nshow that $M$ has at most $(k-1)$-dimensional behavior at large scales. If\n$k=n={\\rm dim}(M)$, so that the integral lower bound is on the scalar\ncurvature, assuming in addition that the $n-2$-Ricci curvature is\nasymptotically non-negative, then we prove that the dimension drop at large\nscales improves to $n-2$. From the above results, we deduce topological\nrestrictions, such as upper bounds on the first Betti number.","main_category":"math.DG","categories":"math.DG,math.MG","published":"2025-04-09T13:13:24Z"}
{"aid":"http://arxiv.org/abs/2504.06867v1","title":"xApp Conflict Mitigation with Scheduler","summary":"Open RAN (O-RAN) fosters multi-vendor interoperability and data-driven\ncontrol but simultaneously introduces the challenge of managing pre-trained\nxApps that can produce conflicting actions. Although O-RAN specifications\nmandate offline training and validation to prevent untrained models,\noperational conflicts remain likely under dynamic, context-dependent\nconditions. This work proposes a scheduler-based conflict mitigation framework\nto address these challenges without requiring training xApps together or\nfurther xApp re-training. By examining an indirect conflict involving power and\nresource block allocation xApps and employing an Advantage Actor-Critic (A2C)\napproach to train both xApps and the scheduler, we illustrate that a\nstraightforward A2C-based scheduler improves performance relative to\nindependently deployed xApps and conflicting cases. Notably, augmenting the\nsystem with baseline xApps and allowing the scheduler to select from a broader\npool yields the best results, underscoring the importance of adaptive\nscheduling mechanisms. These findings highlight the context-dependent nature of\nconflicts in automated network management, as two xApps may conflict under\ncertain conditions but coexist under others. Consequently, the ability to\ndynamically update and adapt the scheduler to accommodate diverse operational\nintents is vital for future network deployments. By offering dynamic scheduling\nwithout re-training xApps, this framework advances practical conflict\nresolution solutions while supporting real-world scalability.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-09T13:16:48Z"}
{"aid":"http://arxiv.org/abs/2504.06870v1","title":"Bayesian Component Separation for DESI LAE Automated Spectroscopic\n  Redshifts and Photometric Targeting","summary":"Lyman Alpha Emitters (LAEs) are valuable high-redshift cosmological probes\ntraditionally identified using specialized narrow-band photometric surveys. In\nground-based spectroscopy, it can be difficult to distinguish the sharp LAE\npeak from residual sky emission lines using automated methods, leading to\nmisclassified redshifts. We present a Bayesian spectral component separation\ntechnique to automatically determine spectroscopic redshifts for LAEs while\nmarginalizing over sky residuals. We use visually inspected spectra of LAEs\nobtained using the Dark Energy Spectroscopic Instrument (DESI) to create a\ndata-driven prior and can determine redshift by jointly inferring sky residual,\nLAE, and residual components for each individual spectrum. We demonstrate this\nmethod on 910 spectroscopically observed $z = 2-4$ DESI LAE candidate spectra\nand determine their redshifts with $>$90% accuracy when validated against\nvisually inspected redshifts. Using the $\\Delta \\chi^2$ value from our pipeline\nas a proxy for detection confidence, we then explore potential survey design\nchoices and implications for targeting LAEs with medium-band photometry. This\nmethod allows for scalability and accuracy in determining redshifts from DESI\nspectra, and the results provide recommendations for LAE targeting in\nanticipation of future high-redshift spectroscopic surveys.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.CO,stat.AP","published":"2025-04-09T13:21:20Z"}
{"aid":"http://arxiv.org/abs/2504.06902v1","title":"A Measurement Device Independent Quantum Key Distribution protocol in\n  the service of three users","summary":"Quantum Key Distribution (QKD) is the only theoretically proven method for\nsecure key distribution between two users. In this work, we propose and analyze\na Measurement Device Independent (MDI) protocol designed to distribute keys\namong three users in a pairwise manner. Each user randomly selects a basis,\nencodes bit values in the phase of coherent states, and sends the resulting\npulses to a central measurement unit (MU) composed of three beam splitters and\nthree photon detectors. When the three pulses arrive simultaneously at the MU\nand under the condition of successful detection of photons, a key bit is\ndistributed to at least one pair of users. This protocol extends the\nfoundational phase-encoding MDI protocol introduced by [K. Tamaki, et al.,\nPhys. Rev. A 85, 042307 (2012)] to three users, but this comes at the cost of\nintroducing a systematic error in the implementation of the honest protocol.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T14:01:49Z"}
{"aid":"http://arxiv.org/abs/2504.06927v1","title":"RO-FIGS: Efficient and Expressive Tree-Based Ensembles for Tabular Data","summary":"Tree-based models are often robust to uninformative features and can\naccurately capture non-smooth, complex decision boundaries. Consequently, they\noften outperform neural network-based models on tabular datasets at a\nsignificantly lower computational cost. Nevertheless, the capability of\ntraditional tree-based ensembles to express complex relationships efficiently\nis limited by using a single feature to make splits. To improve the efficiency\nand expressiveness of tree-based methods, we propose Random Oblique Fast\nInterpretable Greedy-Tree Sums (RO-FIGS). RO-FIGS builds on Fast Interpretable\nGreedy-Tree Sums, and extends it by learning trees with oblique or multivariate\nsplits, where each split consists of a linear combination learnt from random\nsubsets of features. This helps uncover interactions between features and\nimproves performance. The proposed method is suitable for tabular datasets with\nboth numerical and categorical features. We evaluate RO-FIGS on 22 real-world\ntabular datasets, demonstrating superior performance and much smaller models\nover other tree- and neural network-based methods. Additionally, we analyse\ntheir splits to reveal valuable insights into feature interactions, enriching\nthe information learnt from SHAP summary plots, and thereby demonstrating the\nenhanced interpretability of RO-FIGS models. The proposed method is well-suited\nfor applications, where balance between accuracy and interpretability is\nessential.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T14:35:24Z"}
{"aid":"http://arxiv.org/abs/2504.06950v1","title":"PathSegDiff: Pathology Segmentation using Diffusion model\n  representations","summary":"Image segmentation is crucial in many computational pathology pipelines,\nincluding accurate disease diagnosis, subtyping, outcome, and survivability\nprediction. The common approach for training a segmentation model relies on a\npre-trained feature extractor and a dataset of paired image and mask\nannotations. These are used to train a lightweight prediction model that\ntranslates features into per-pixel classes. The choice of the feature extractor\nis central to the performance of the final segmentation model, and recent\nliterature has focused on finding tasks to pre-train the feature extractor. In\nthis paper, we propose PathSegDiff, a novel approach for histopathology image\nsegmentation that leverages Latent Diffusion Models (LDMs) as pre-trained\nfeatured extractors. Our method utilizes a pathology-specific LDM, guided by a\nself-supervised encoder, to extract rich semantic information from H\\&E stained\nhistopathology images. We employ a simple, fully convolutional network to\nprocess the features extracted from the LDM and generate segmentation masks.\nOur experiments demonstrate significant improvements over traditional methods\non the BCSS and GlaS datasets, highlighting the effectiveness of\ndomain-specific diffusion pre-training in capturing intricate tissue structures\nand enhancing segmentation accuracy in histopathology images.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T14:58:21Z"}
{"aid":"http://arxiv.org/abs/2504.06999v1","title":"Extremal Planar Matchings of Inhomogenous Random Bipartite Graphs","summary":"In this paper we study maximum size and minimum weight planar matchings of\ninhomogenous random bipartite graphs. Our motivation for this study comes from\nefficient usage of cross edges in relay networks for overall improvement in\nnetwork performance. We first consider Bernoulli planar matchings with a\nconstraint on the edge length and obtain deviation estimates for the maximum\nsize of a planar matching. We then equip each edge of the complete bipartite\ngraph with a positive random weight and obtain bounds on the minimum weight of\na planar matching containing a given number of edges. We also use segmentation\nand martingale methods to obtain~\\(L^2-\\)convergence of the minimum weight,\nappropriately scaled and centred.","main_category":"math.PR","categories":"math.PR","published":"2025-04-09T16:09:54Z"}
{"aid":"http://arxiv.org/abs/2504.07011v1","title":"FAME: Introducing Fuzzy Additive Models for Explainable AI","summary":"In this study, we introduce the Fuzzy Additive Model (FAM) and FAM with\nExplainability (FAME) as a solution for Explainable Artificial Intelligence\n(XAI). The family consists of three layers: (1) a Projection Layer that\ncompresses the input space, (2) a Fuzzy Layer built upon Single Input-Single\nOutput Fuzzy Logic Systems (SFLS), where SFLS functions as subnetworks within\nan additive index model, and (3) an Aggregation Layer. This architecture\nintegrates the interpretability of SFLS, which uses human-understandable\nif-then rules, with the explainability of input-output relationships,\nleveraging the additive model structure. Furthermore, using SFLS inherently\naddresses issues such as the curse of dimensionality and rule explosion. To\nfurther improve interpretability, we propose a method for sculpting antecedent\nspace within FAM, transforming it into FAME. We show that FAME captures the\ninput-output relationships with fewer active rules, thus improving clarity. To\nlearn the FAM family, we present a deep learning framework. Through the\npresented comparative results, we demonstrate the promising potential of FAME\nin reducing model complexity while retaining interpretability, positioning it\nas a valuable tool for XAI.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T16:29:55Z"}
{"aid":"http://arxiv.org/abs/2504.07015v1","title":"LLM-IFT: LLM-Powered Information Flow Tracking for Secure Hardware","summary":"As modern hardware designs grow in complexity and size, ensuring security\nacross the confidentiality, integrity, and availability (CIA) triad becomes\nincreasingly challenging. Information flow tracking (IFT) is a widely-used\napproach to tracing data propagation, identifying unauthorized activities that\nmay compromise confidentiality or/and integrity in hardware. However,\ntraditional IFT methods struggle with scalability and adaptability,\nparticularly in high-density and interconnected architectures, leading to\ntracing bottlenecks that limit applicability in large-scale hardware. To\naddress these limitations and show the potential of transformer-based models in\nintegrated circuit (IC) design, this paper introduces LLM-IFT that integrates\nlarge language models (LLM) for the realization of the IFT process in hardware.\nLLM-IFT exploits LLM-driven structured reasoning to perform hierarchical\ndependency analysis, systematically breaking down even the most complex\ndesigns. Through a multi-step LLM invocation, the framework analyzes both\nintra-module and inter-module dependencies, enabling comprehensive IFT\nassessment. By focusing on a set of Trust-Hub vulnerability test cases at both\nthe IP level and the SoC level, our experiments demonstrate a 100\\% success\nrate in accurate IFT analysis for confidentiality and integrity checks in\nhardware.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-09T16:32:13Z"}
{"aid":"http://arxiv.org/abs/2504.07028v1","title":"UAV Position Estimation using a LiDAR-based 3D Object Detection Method","summary":"This paper explores the use of applying a deep learning approach for 3D\nobject detection to compute the relative position of an Unmanned Aerial Vehicle\n(UAV) from an Unmanned Ground Vehicle (UGV) equipped with a LiDAR sensor in a\nGPS-denied environment. This was achieved by evaluating the LiDAR sensor's data\nthrough a 3D detection algorithm (PointPillars). The PointPillars algorithm\nincorporates a column voxel point-cloud representation and a 2D Convolutional\nNeural Network (CNN) to generate distinctive point-cloud features representing\nthe object to be identified, in this case, the UAV. The current localization\nmethod utilizes point-cloud segmentation, Euclidean clustering, and predefined\nheuristics to obtain the relative position of the UAV. Results from the two\nmethods were then compared to a reference truth solution.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-09T16:43:59Z"}
{"aid":"http://arxiv.org/abs/2504.07041v1","title":"Efficient Storage Integrity in Adversarial Settings","summary":"Storage integrity is essential to systems and applications that use untrusted\nstorage (e.g., public clouds, end-user devices). However, known methods for\nachieving storage integrity either suffer from high (and often prohibitive)\noverheads or provide weak integrity guarantees. In this work, we demonstrate a\nhybrid approach to storage integrity that simultaneously reduces overhead while\nproviding strong integrity guarantees. Our system, partially asynchronous\nintegrity checking (PAC), allows disk write commitments to be deferred while\nstill providing guarantees around read integrity. PAC delivers a 5.5X\nthroughput and latency improvement over the state of the art, and 85% of the\nthroughput achieved by non-integrity-assuring approaches. In this way, we show\nthat untrusted storage can be used for integrity-critical workloads without\nmeaningfully sacrificing performance.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-09T16:58:22Z"}
{"aid":"http://arxiv.org/abs/2504.07063v1","title":"Non-Gaussianity of Tensor Induced Density Perturbations","summary":"We investigate the non-Gaussianity of second-order matter density\nperturbations induced by primordial gravitational waves (GWs). These\ntensor-induced scalar modes arise from local fluctuations in the GWs energy\ndensity, which is quadratic in tensor perturbations. The resulting second-order\ndensity contrast follows a chi-squared distribution, naturally exhibiting\nsignificant non-Gaussianity. We compute the bispectrum of these tensor-induced\nscalar modes and analyze its dependence on various primordial GWs power\nspectra, including scale-invariant, blue-tilted, Gaussian-bump, and\nmonochromatic sources. We find that the bispectrum shape is inherently\nsensitive to the underlying GWs spectrum by construction. In particular,\nGaussian-bump and monochromatic sources produce a strong signal peaking in the\nequilateral configuration, similar to the effect of scalar-induced tensor\nmodes. Our findings reveal a new way to probe primordial GWs via galaxy surveys\nand highlight a unique feature of tensor-induced density perturbations,\notherwise mimicking linear ones on sub-horizon scales.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-09T17:26:41Z"}
{"aid":"http://arxiv.org/abs/2504.07074v1","title":"The Lyman-alpha and Continuum Origins Survey II: the uneventful journey\n  of escaping Ly$α$ and ionizing radiation through the neutral ISM and CGM\n  of galaxies","summary":"One of the current challenges in galaxy evolution studies is to establish the\nmechanisms that govern the escape of ionizing radiation from galaxies. In this\nwork, we investigate the connection between Lyman Continuum (LyC) escape and\nthe conditions of the Circumgalactic Medium (CGM), as probed by Ly$\\alpha$\nhalos (LAHs) in emission. We use Ly$\\alpha$ and UV continuum imaging data from\nthe Lyman alpha and Continuum Origins Survey (LaCOS), targeting 42 nearby ($z\n\\simeq 0.3$), star-forming galaxies with LyC observations (escape fractions of\n$f_{\\rm esc}^{\\rm LyC} \\simeq 0.01-0.49$). LaCOS galaxies show extended\nLy$\\alpha$ emission ubiquitously, with LyC emitters (LCEs) having more compact\nLy$\\alpha$ morphologies relative to the UV size than non-LCEs, and Ly$\\alpha$\nspatial offsets that do not exceed the extent of the UV continuum. We model the\ndiffuse LAHs using a combined Sersic plus exponential 2D profile, and find that\nthe characteristic scale length of the Ly$\\alpha$ is ten times the scale length\nof the UV, on average. We unveil a tight anti-correlation between $f_{\\rm\nesc}^{\\rm LyC}$ and the Ly$\\alpha$ Halo Fraction (HF, or contribution of the\nhalo to the total Ly$\\alpha$ luminosity), that we propose as a new LyC\nindicator. Our observations also show that the HF scales positively with the\nneutral gas in the ISM, revealing a picture in which Ly$\\alpha$ and LyC photons\nin LCEs emerge through clear sight-lines directly from the central starbursts\nand, in the case of Ly$\\alpha$, minimizing the number of scattering\ninteractions in the CGM. The properties of LAHs in LaCOS resemble those of LAHs\nat $z \\geq 3$, suggesting a lack of evolution in the $f_{\\rm esc}^{\\rm LyC}$\npredictors that rely on the spatial properties of Ly$\\alpha$, and ensuring the\napplicability of these indicators to observations of high-redshift galaxies.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-09T17:46:13Z"}
{"aid":"http://arxiv.org/abs/2504.07091v1","title":"AssistanceZero: Scalably Solving Assistance Games","summary":"Assistance games are a promising alternative to reinforcement learning from\nhuman feedback (RLHF) for training AI assistants. Assistance games resolve key\ndrawbacks of RLHF, such as incentives for deceptive behavior, by explicitly\nmodeling the interaction between assistant and user as a two-player game where\nthe assistant cannot observe their shared goal. Despite their potential,\nassistance games have only been explored in simple settings. Scaling them to\nmore complex environments is difficult because it requires both solving\nintractable decision-making problems under uncertainty and accurately modeling\nhuman users' behavior. We present the first scalable approach to solving\nassistance games and apply it to a new, challenging Minecraft-based assistance\ngame with over $10^{400}$ possible goals. Our approach, AssistanceZero, extends\nAlphaZero with a neural network that predicts human actions and rewards,\nenabling it to plan under uncertainty. We show that AssistanceZero outperforms\nmodel-free RL algorithms and imitation learning in the Minecraft-based\nassistance game. In a human study, our AssistanceZero-trained assistant\nsignificantly reduces the number of actions participants take to complete\nbuilding tasks in Minecraft. Our results suggest that assistance games are a\ntractable framework for training effective AI assistants in complex\nenvironments. Our code and models are available at\nhttps://github.com/cassidylaidlaw/minecraft-building-assistance-game.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-09T17:59:03Z"}
{"aid":"http://arxiv.org/abs/2504.07418v1","title":"ThermoStereoRT: Thermal Stereo Matching in Real Time via Knowledge\n  Distillation and Attention-based Refinement","summary":"We introduce ThermoStereoRT, a real-time thermal stereo matching method\ndesigned for all-weather conditions that recovers disparity from two rectified\nthermal stereo images, envisioning applications such as night-time drone\nsurveillance or under-bed cleaning robots. Leveraging a lightweight yet\npowerful backbone, ThermoStereoRT constructs a 3D cost volume from thermal\nimages and employs multi-scale attention mechanisms to produce an initial\ndisparity map. To refine this map, we design a novel channel and spatial\nattention module. Addressing the challenge of sparse ground truth data in\nthermal imagery, we utilize knowledge distillation to boost performance without\nincreasing computational demands. Comprehensive evaluations on multiple\ndatasets demonstrate that ThermoStereoRT delivers both real-time capacity and\nrobust accuracy, making it a promising solution for real-world deployment in\nvarious challenging environments. Our code will be released on\nhttps://github.com/SJTU-ViSYS-team/ThermoStereoRT","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T03:24:21Z"}
{"aid":"http://arxiv.org/abs/2504.07424v1","title":"Routing to the Right Expertise: A Trustworthy Judge for\n  Instruction-based Image Editing","summary":"Instruction-based Image Editing (IIE) models have made significantly\nimprovement due to the progress of multimodal large language models (MLLMs) and\ndiffusion models, which can understand and reason about complex editing\ninstructions. In addition to advancing current IIE models, accurately\nevaluating their output has become increasingly critical and challenging.\nCurrent IIE evaluation methods and their evaluation procedures often fall short\nof aligning with human judgment and often lack explainability. To address these\nlimitations, we propose JUdgement through Routing of Expertise (JURE). Each\nexpert in JURE is a pre-selected model assumed to be equipped with an atomic\nexpertise that can provide useful feedback to judge output, and the router\ndynamically routes the evaluation task of a given instruction and its output to\nappropriate experts, aggregating their feedback into a final judge. JURE is\ntrustworthy in two aspects. First, it can effortlessly provide explanations\nabout its judge by examining the routed experts and their feedback. Second,\nexperimental results demonstrate that JURE is reliable by achieving superior\nalignment with human judgments, setting a new standard for automated IIE\nevaluation. Moreover, JURE's flexible design is future-proof - modular experts\ncan be seamlessly replaced or expanded to accommodate advancements in IIE,\nmaintaining consistently high evaluation quality. Our evaluation data and\nresults are available at https://github.com/Cyyyyyrus/JURE.git.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-10T03:30:15Z"}
{"aid":"http://arxiv.org/abs/2504.07440v1","title":"Revisiting LLM Evaluation through Mechanism Interpretability: a New\n  Metric and Model Utility Law","summary":"Large Language Models (LLMs) have become indispensable across academia,\nindustry, and daily applications, yet current evaluation methods struggle to\nkeep pace with their rapid development. In this paper, we analyze the core\nlimitations of traditional evaluation pipelines and propose a novel metric, the\nModel Utilization Index (MUI), which introduces mechanism interpretability\ntechniques to complement traditional performance metrics. MUI quantifies the\nextent to which a model leverages its capabilities to complete tasks. The core\nidea is that to assess an LLM's overall ability, we must evaluate not only its\ntask performance but also the effort expended to achieve the outcome. Our\nextensive experiments reveal an inverse relationship between MUI and\nperformance, from which we deduce a common trend observed in popular LLMs,\nwhich we term the Utility Law. Based on this, we derive four corollaries that\naddress key challenges, including training judgement, the issue of data\ncontamination, fairness in model comparison, and data diversity. We hope that\nour survey, novel metric, and utility law will foster mutual advancement in\nboth evaluation and mechanism interpretability. Our code can be found at\nhttps://github.com/ALEX-nlp/MUI-Eva.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T04:09:47Z"}
{"aid":"http://arxiv.org/abs/2504.07456v1","title":"Sums with Stern-Brocot sequences and Minkowski question mark function","summary":"We give an affirmative answer to a question asked by N. Moshchevitin\n\\cite{m1} in his lecture at International Congress of Basic Science, Beijing,\n2024 (see also \\cite{m}, Section 6.3). The question is that whether the\nremainder $$\nR_n=\\sum_{j=1}^{2^n}\\left(\\xi_{j,n}-\\frac{j}{2^n}\\right)^2-2^n\\int_0^1(?(x)-x))^2\\text{d}x\n$$ tends to $0$ when $n$ tends to infinity, where $\\xi_{j,n}$ are elements of\nthe Stern-Brocot sequence and $?(x)$ denotes Minkowski Question-Mark Function.\nWe present some extended results and give a correct proof of a theorem on the\nFourier-Stieltjes coefficient of the inverse function of $?(x)$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-10T05:03:35Z"}
{"aid":"http://arxiv.org/abs/2504.07467v1","title":"Defense against Prompt Injection Attacks via Mixture of Encodings","summary":"Large Language Models (LLMs) have emerged as a dominant approach for a wide\nrange of NLP tasks, with their access to external information further enhancing\ntheir capabilities. However, this introduces new vulnerabilities, known as\nprompt injection attacks, where external content embeds malicious instructions\nthat manipulate the LLM's output. Recently, the Base64 defense has been\nrecognized as one of the most effective methods for reducing success rate of\nprompt injection attacks. Despite its efficacy, this method can degrade LLM\nperformance on certain NLP tasks. To address this challenge, we propose a novel\ndefense mechanism: mixture of encodings, which utilizes multiple character\nencodings, including Base64. Extensive experimental results show that our\nmethod achieves one of the lowest attack success rates under prompt injection\nattacks, while maintaining high performance across all NLP tasks, outperforming\nexisting character encoding-based defense methods. This underscores the\neffectiveness of our mixture of encodings strategy for both safety and task\nperformance metrics.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T05:35:21Z"}
{"aid":"http://arxiv.org/abs/2504.07470v1","title":"Transformer-Based Temporal Information Extraction and Application: A\n  Review","summary":"Temporal information extraction (IE) aims to extract structured temporal\ninformation from unstructured text, thereby uncovering the implicit timelines\nwithin. This technique is applied across domains such as healthcare, newswire,\nand intelligence analysis, aiding models in these areas to perform temporal\nreasoning and enabling human users to grasp the temporal structure of text.\nTransformer-based pre-trained language models have produced revolutionary\nadvancements in natural language processing, demonstrating exceptional\nperformance across a multitude of tasks. Despite the achievements garnered by\nTransformer-based approaches in temporal IE, there is a lack of comprehensive\nreviews on these endeavors. In this paper, we aim to bridge this gap by\nsystematically summarizing and analyzing the body of work on temporal IE using\nTransformers while highlighting potential future research directions.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T05:48:24Z"}
{"aid":"http://arxiv.org/abs/2504.07492v1","title":"Homogeneous nucleation rate of carbon dioxide hydrate formation under\n  experimental condition from Seeding simulations","summary":"We investigate the nucleation of carbon dioxide (CO$_2$) hydrates from carbon\ndioxide aqueous solutions by means of molecular dynamics simulations using the\nTIP4P/Ice and the TraPPE models for water and CO$_2$ respectively. We work at\n400 bar and different temperatures and CO$_2$ concentrations. We use brute\nforce molecular dynamics when the supersaturation or the supercooling are so\nhigh so that nucleation occurs spontaneously and Seeding otherwise. We used\nboth methods for a particular state and we get a rate of\n10$^{25}\\,\\text{m}^{-3}\\text{s}^{-1}$ for nucleation in a CO$_2$ saturated\nsolution at 255 K (35 K of supercooling). By comparison with our previous work\non methane hydrates, we conclude that nucleation of CO$_2$ hydrates is several\norders of magnitude faster due to a lower interfacial free energy between the\ncrystal and the solution. By combining our nucleation studies with a recent\ncalculation of the hydrate-solution interfacial free energy at coexistence, we\nobtain a prediction of the nucleation rate temperature dependence for\nCO$_{2}$-saturated solutions (the experimentally relevant concentration). On\nthe one hand, we open the window for comparison with experiments for\nsupercooling larger than 25 K. On the other hand, we conclude that homogeneous\nnucleation is impossible for supercooling lower than 20 K. Therefore,\nnucleation must be heterogeneous in typical experiments where hydrate formation\nis observed at low supercooling. To assess the hypothesis that nucleation\noccurs at the solution-CO$_2$ interface we run spontaneous nucleation\nsimulations in two-phase systems and find, by comparison with single-phase\nsimulations, that the interface does not affect hydrate nucleation, at least at\nthe deep supercooling at which this study was carried out (40 and 45 K).\nOverall, our work sheds light on molecular and thermodynamic aspects of hydrate\nnucleation.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-10T06:49:16Z"}
{"aid":"http://arxiv.org/abs/2504.07510v1","title":"Wigner distribution, Wigner entropy, and Anomalous Transport of a\n  Generalized Aubry-André model","summary":"In this paper, we study a generalized Aubry-Andr\\'{e} model with tunable\nquasidisordered potentials. The model has an invariable mobility edge that\nseparates the extended states from the localized states. At the mobility edge,\nthe wave function presents critical characteristics, which can be verified by\nfinite-size scaling analysis. Our numerical investigations demonstrate that the\nextended, critical, and localized states can be effectively distinguished via\ntheir phase space representation, specially the Wigner distribution. Based on\nthe Wigner distribution function, we can further obtain the corresponding\nWigner entropy and employ the feature that the critical state has the maximum\nWigner entropy to locate the invariable mobility edge. Finally, we reveal that\nthere are anomalous transport phenomena between the transition from ballistic\ntransport to the absence of diffusion.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn","published":"2025-04-10T07:12:17Z"}
{"aid":"http://arxiv.org/abs/2504.07537v1","title":"Formalizing Representation Theorems for a Logical Framework with\n  Rewriting","summary":"Representation theorems for formal systems often take the form of an\ninductive translation that satisfies certain invariants, which are proved\ninductively. Theory morphisms and logical relations are common patterns of such\ninductive constructions. They allow representing the translation and the proofs\nof the invariants as a set of translation rules, corresponding to the cases of\nthe inductions. Importantly, establishing the invariants is reduced to checking\na finite set of, typically decidable, statements. Therefore, in a framework\nsupporting theory morphisms and logical relations, translations that fit one of\nthese patterns become much easier to formalize and to verify. The\n$\\lambda\\Pi$-calculus modulo rewriting is a logical framework designed for\nrepresenting and translating between formal systems that has previously not\nsystematically supported such patterns. In this paper, we extend it with theory\nmorphisms and logical relations. We apply these to define and verify invariants\nfor a number of translations between formal systems. In doing so, we identify\nsome best practices that enable us to obtain elegant novel formalizations of\nsome challenging translations, in particular type erasure translations from\ntyped to untyped languages.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-10T08:02:40Z"}
{"aid":"http://arxiv.org/abs/2504.07558v1","title":"Atomic structure analysis of PL5 in silicon carbide with single-spin\n  spectroscopy","summary":"Divacancy (VV) spin defects in 4H polytype of silicon carbide (4H-SiC) are\nemerging candidates for quantum information processing and quantum sensing.\nAmong these defects, PL5 and PL6 stand out due to their superior charge\nstability and optically detected magnetic resonance (ODMR) properties at room\ntemperature. However, their atomic structures remain unresolved, with ongoing\ncontroversy regarding their potential association with stacking faults.\nPrevious measurements relying on spin ensemble detection are insufficient to\ndraw definitive conclusions. In this study, we conduct correlative imaging of\nstacking faults and PL5-6 at single-defect level, conclusively demonstrating\nthat PL5-6 are not associated with stacking faults. Further investigation of\nPL5 through single-spin ODMR spectroscopy allows us to determine its six\nspatial orientations, as well as to measure the orientation of its transverse\nanisotropy spin splitting (E) and the statistical distribution of hyperfine\nsplitting. These results and ab initio calculations suggest that PL5 should be\nVsiVc(hk) divacancy coupled with a nearby antisite atom (VVA). The structure\nresolution of PL5 starts the first step toward its controllable fabrication,\npaving the way for various applications.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall,physics.comp-ph,quant-ph","published":"2025-04-10T08:39:40Z"}
{"aid":"http://arxiv.org/abs/2504.07560v1","title":"PhaseGen: A Diffusion-Based Approach for Complex-Valued MRI Data\n  Generation","summary":"Magnetic resonance imaging (MRI) raw data, or k-Space data, is\ncomplex-valued, containing both magnitude and phase information. However,\nclinical and existing Artificial Intelligence (AI)-based methods focus only on\nmagnitude images, discarding the phase data despite its potential for\ndownstream tasks, such as tumor segmentation and classification. In this work,\nwe introduce $\\textit{PhaseGen}$, a novel complex-valued diffusion model for\ngenerating synthetic MRI raw data conditioned on magnitude images, commonly\nused in clinical practice. This enables the creation of artificial\ncomplex-valued raw data, allowing pretraining for models that require k-Space\ninformation. We evaluate PhaseGen on two tasks: skull-stripping directly in\nk-Space and MRI reconstruction using the publicly available FastMRI dataset.\nOur results show that training with synthetic phase data significantly improves\ngeneralization for skull-stripping on real-world data, with an increased\nsegmentation accuracy from $41.1\\%$ to $80.1\\%$, and enhances MRI\nreconstruction when combined with limited real-world data. This work presents a\nstep forward in utilizing generative AI to bridge the gap between\nmagnitude-based datasets and the complex-valued nature of MRI raw data. This\napproach allows researchers to leverage the vast amount of avaliable image\ndomain data in combination with the information-rich k-Space data for more\naccurate and efficient diagnostic tasks. We make our code publicly\n$\\href{https://github.com/TIO-IKIM/PhaseGen}{\\text{available here}}$.","main_category":"eess.IV","categories":"eess.IV,cs.CV,cs.LG","published":"2025-04-10T08:44:19Z"}
{"aid":"http://arxiv.org/abs/2504.07583v1","title":"Do LLMs Understand Your Translations? Evaluating Paragraph-level MT with\n  Question Answering","summary":"Despite the steady progress in machine translation evaluation, existing\nautomatic metrics struggle to capture how well meaning is preserved beyond\nsentence boundaries. We posit that reliance on a single intrinsic quality\nscore, trained to mimic human judgments, might be insufficient for evaluating\ntranslations of long, complex passages, and a more ``pragmatic'' approach that\nassesses how accurately key information is conveyed by a translation in context\nis needed. We introduce TREQA (Translation Evaluation via Question-Answering),\na framework that extrinsically evaluates translation quality by assessing how\naccurately candidate translations answer reading comprehension questions that\ntarget key information in the original source or reference texts. In\nchallenging domains that require long-range understanding, such as literary\ntexts, we show that TREQA is competitive with and, in some cases, outperforms\nstate-of-the-art neural and LLM-based metrics in ranking alternative\nparagraph-level translations, despite never being explicitly optimized to\ncorrelate with human judgments. Furthermore, the generated questions and\nanswers offer interpretability: empirical analysis shows that they effectively\ntarget translation errors identified by experts in evaluated datasets. Our code\nis available at https://github.com/deep-spin/treqa","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-10T09:24:54Z"}
{"aid":"http://arxiv.org/abs/2504.07624v1","title":"ConceptFormer: Towards Efficient Use of Knowledge-Graph Embeddings in\n  Large Language Models","summary":"Retrieval Augmented Generation (RAG) has enjoyed increased attention in the\nrecent past and recent advancements in Large Language Models (LLMs) have\nhighlighted the importance of integrating world knowledge into these systems.\nCurrent RAG methodologies often modify the internal architecture of pre-trained\nlanguage models (PLMs) or rely on textifying knowledge graphs (KGs), which is\ninefficient in terms of token usage. This paper introduces ConceptFormer, a new\napproach to augment LLMs with structured knowledge from KGs, such as Wikidata,\nwithout altering their internal structure or relying on textual input of KGs.\nConceptFormer operates in the LLM embedding vector space, creating and\ninjecting \\emph{concept vectors} that encapsulate the information of the KG\nnodes directly. Trained in conjunction with a frozen LLM, ConceptFormer\ngenerates a comprehensive lookup table that maps KG nodes to their respective\nconcept vectors. The approach aims to enhance the factual recall capabilities\nof LLMs by enabling them to process these concept vectors natively, thus\nenriching them with structured world knowledge in an efficient and scalable\nmanner. Our experiments demonstrate that the addition of concept vectors to\nGPT-2 0.1B substantially increases its factual recall ability (Hit@10) by up to\n272\\% when tested on sentences from Wikipedia and up to 348\\% on synthetically\ngenerated sentences. Even injecting only a single concept vector into the\nprompt increases factual recall ability (Hit@10) by up to 213\\% on Wikipedia\nsentences, significantly outperforming RAG with graph textification while\nconsuming 130x fewer input tokens.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.IR","published":"2025-04-10T10:17:08Z"}
{"aid":"http://arxiv.org/abs/2504.07671v1","title":"Cross-Laplacians Based Topological Signal Processing over Cell\n  MultiComplexes","summary":"The study of the interactions among different types of interconnected systems\nin complex networks has attracted significant interest across many research\nfields. However, effective signal processing over layered networks requires\ntopological descriptors of the intra- and cross-layers relationships that are\nable to disentangle the homologies of different domains, at different scales,\naccording to the specific learning task. In this paper, we present Cell\nMultiComplex (CMC) spaces, which are novel topological domains for representing\nmultiple higher-order relationships among interconnected complexes. We\nintroduce cross-Laplacians matrices, which are algebraic descriptors of CMCs\nenabling the extraction of topological invariants at different scales, whether\nglobal or local, inter-layer or intra-layer. Using the eigenvectors of these\ncross-Laplacians as signal bases, we develop topological signal processing\ntools for CMC spaces. In this first study, we focus on the representation and\nfiltering of noisy flows observed over cross-edges between different layers of\nCMCs to identify cross-layer hubs, i.e., key nodes on one layer controlling the\nothers.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-10T11:42:58Z"}
{"aid":"http://arxiv.org/abs/2504.07683v1","title":"Effects of Berry Curvature and Orbital Magnetic Moment in the\n  Magnetothermoelectric Transport of Bloch Electron Systems","summary":"Thermoelectric transport coefficients up to linear order in the applied\nmagnetic field are microscopically studied using Kubo-Luttinger linear response\ntheory and thermal Green's functions. We derive exact formulas for the\nthermoelectric conductivity and thermal conductivity in the limit of small\nrelaxation rates for Bloch electrons in terms of Bloch wave functions, which\nshow that the Sommerfeld-Bethe relationship holds. Our final formula contains\nthe Berry curvature contributions as well as the orbital magnetic moment\ncontributions, that arise naturally from the microscopic theory. We show that\ngeneralized $f$-sum rules containing the Berry curvature and orbital magnetic\nmoment play essential roles in taking into account the interband effects of the\nmagnetic field. As an application, we study a model of a gapped Dirac electron\nsystem with broken time-reversal symmetry and show the presence of a linear\nmagnetothermopower in such systems.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-10T12:13:35Z"}
{"aid":"http://arxiv.org/abs/2504.07684v1","title":"Improving Photometric Redshift Estimation for CSST Mock Catalog Using\n  SED Templates Calibrated with Perturbation Algorithm","summary":"Photometric redshifts of galaxies obtained by multi-wavelength data are\nwidely used in photometric surveys because of its high efficiency. Although\nvarious methods have been developed, template fitting is still adopted as one\nof the most popular approaches. Its accuracy strongly depends on the quality of\nthe Spectral Energy Distribution (SED) templates, which can be calibrated using\nbroadband photometric data from galaxies with known spectroscopic redshifts.\nSuch calibration is expected to improve photometric redshift accuracy, as the\ncalibrated templates will align with observed photometric data more closely.\nThe upcoming China Space Station Survey Telescope (CSST) is one of the Stage IV\nsurveys, which aiming for high precision cosmological studies. To improve the\naccuracy of photometric redshift estimation for CSST, we calibrated the CWW+KIN\ntemplates using a perturbation algorithm with broadband photometric data from\nthe CSST mock catalog. This calibration used a training set consisting of\napproximately 4,500 galaxies, which is 10% of the total galaxy sample. The\noutlier fraction and scatter of the photometric redshifts derived from the\ncalibrated templates are 2.55% and 0.036, respectively. Compared to the CWW+KIN\ntemplates, these values are reduced by 34% and 23%, respectively. This\ndemonstrates that SED templates calibrated with a small training set can\neffectively optimize photometric redshift accuracy for future large-scale\nsurveys like CSST, especially with limited spectral training data.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-10T12:13:55Z"}
{"aid":"http://arxiv.org/abs/2504.07692v1","title":"Singularity resolution and inflation from an infinite tower of\n  regularized curvature corrections","summary":"We explore four-dimensional scalar-tensor theories obtained from well-defined\ndimensional regularizations of Lovelock invariants. When an infinite tower of\ncorrections is considered, these theories allow for cosmological models in\nwhich the Big Bang singularity is replaced by an inflationary phase in the\nearly-universe, and they also admit a specific class of regular black hole\nsolutions.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-th","published":"2025-04-10T12:26:03Z"}
{"aid":"http://arxiv.org/abs/2504.07704v1","title":"Measures of non-simplifyingness for conditional copulas and vines","summary":"In copula modeling, the simplifying assumption has recently been the object\nof much interest. Although it is very useful to reduce the computational\nburden, it remains far from obvious whether it is actually satisfied in\npractice. We propose a theoretical framework which aims at giving a precise\nmeaning to the following question: how non-simplified or close to be simplified\nis a given conditional copula? For this, we propose a theoretical framework\ncentered at the notion of measure of non-constantness. Then we discuss\ngeneralizations of the simplifying assumption to the case where the conditional\nmarginal distributions may not be continuous, and corresponding measures of\nnon-simplifyingness in this case. The simplifying assumption is of particular\nimportance for vine copula models, and we therefore propose a notion of measure\nof non-simplifyingness of a given copula for a particular vine structure, as\nwell as different scores measuring how non-simplified such a vine\ndecompositions would be for a general vine. Finally, we propose estimators for\nthese measures of non-simplifyingness given an observed dataset.","main_category":"math.ST","categories":"math.ST,stat.OT,stat.TH","published":"2025-04-10T12:46:39Z"}
{"aid":"http://arxiv.org/abs/2504.07706v1","title":"Strong laws of large numbers for sequences of blockwise $m$-dependent\n  and orthogonal random variables under sublinear expectations","summary":"In this paper, we establish some strong laws of large numbers (SLLN) for\nnon-independent variables under the framework of sublinear expectations. One of\nour main results is for blockwise m-dependent random variables and another is\nfor orthogonal random variables, both of which are the generalization of SLLN\nfor independent random variables in sublinear expectation spaces.","main_category":"math.PR","categories":"math.PR","published":"2025-04-10T12:47:27Z"}
{"aid":"http://arxiv.org/abs/2504.07727v1","title":"Exploratory calculation of the rare hyperon decay $Σ^+ \\to p \\ell^+\n  \\ell^-$ from lattice QCD","summary":"The rare hyperon decay $\\Sigma^+ \\to p \\ell^+ \\ell^-$ is a flavour-changing\nneutral current process mediated by an $s \\to d$ transition that occurs only at\nloop level within the Standard Model. Consequently, this decay is highly\nsuppressed, making it a promising avenue for probing potential new physics.\nWhile phenomenological calculations have made important progress in predicting\nthe decay amplitude, there remains a four-fold ambiguity in the relevant\ntransition form factors that prevents a unique prediction for the branching\nfraction and angular observables. Fully resolving this ambiguity requires a\nfirst-principles Standard-Model calculation, and the recent observation of this\nprocess using LHCb Run 2 data reinforces the timeliness of such a calculation.\nIn this work, we present the first lattice-QCD calculation of this decay,\nperformed using a 2+1-flavour domain-wall fermion ensemble with a pion mass of\n340 MeV. At a small baryon source-sink separation, we observe the emergence of\na signal in the relevant baryonic four-point functions. This allows us to\ndetermine the positive-parity form factors for the rare hyperon decays from\nfirst-principles, albeit with large statistical and systematic uncertainties.","main_category":"hep-lat","categories":"hep-lat,hep-ph","published":"2025-04-10T13:20:40Z"}
{"aid":"http://arxiv.org/abs/2504.07771v1","title":"Penalized Linear Models for Highly Correlated High-Dimensional\n  Immunophenotyping Data","summary":"Accurate prediction and identification of variables associated with outcomes\nor disease states are critical for advancing diagnosis, prognosis, and\nprecision medicine in biomedical research. Regularized regression techniques,\nsuch as lasso, are widely employed to enhance interpretability by reducing\nmodel complexity and identifying significant variables. However, when applying\nto biomedical datasets, e.g., immunophenotyping dataset, there are two major\nchallenges that may lead to unsatisfactory results using these methods: 1) high\ncorrelation between predictors, which leads to the exclusion of important\nvariables with included predictors in variable selection, and 2) the presence\nof skewness, which violates key statistical assumptions of these methods.\nCurrent approaches that fail to address these issues simultaneously may lead to\nbiased interpretations and unreliable coefficient estimates. To overcome these\nlimitations, we propose a novel two-step approach, the Bootstrap-Enhanced\nRegularization Method (BERM). BERM outperforms existing two-step approaches and\ndemonstrates consistent performance in terms of variable selection and\nestimation accuracy across simulated sparsity scenarios. We further demonstrate\nthe effectiveness of BERM by applying it to a human immunophenotyping dataset\nidentifying important immune parameters associated the autoimmune disease, type\n1 diabetes.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-10T14:10:42Z"}
{"aid":"http://arxiv.org/abs/2504.07783v1","title":"On approximation of convex functionals with a convexity constraint and\n  general Lagrangians","summary":"In this note, we prove that minimizers of convex functionals with a convexity\nconstraint and a general class of Lagrangians can be approximated by solutions\nto fourth-order equations of Abreu type. Our result generalizes that of Le\n(Twisted Harnack inequality and approximation of variational problems with a\nconvexity constraint by singular Abreu equations. Adv. Math. 434 (2023)) where\nthe case of quadratically growing Lagrangians was treated.","main_category":"math.AP","categories":"math.AP","published":"2025-04-10T14:22:04Z"}
{"aid":"http://arxiv.org/abs/2504.07788v1","title":"Generalized Passivity Sensitivity Methodology for Small-Signal Stability\n  Analysis","summary":"This paper proposes a generalized passivity sensitivity analysis for power\nsystem stability studies. The method uncovers the most effective instability\nmitigation actions for both device-level and system-level investigations. The\nparticular structure of the admittance and nodal models is exploited in the\ndetailed derivation of the passivity sensitivity expressions. These proposed\nsensitivities are validated for different parameters at device-level and at\nsystem-level. Compared to previous stability and sensitivity methods, it does\nnot require detailed system information, such as exact system eigenvalues,\nwhile it provides valuable information for a less conservative stable system\ndesign. In addition, we demonstrate how to utilize the proposed method through\ncase studies with different converter controls and system-wide insights showing\nits general applicability.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-10T14:23:23Z"}
{"aid":"http://arxiv.org/abs/2504.07796v1","title":"Numerical solution by shape optimization method to an inverse shape\n  problem in multi-dimensional advection-diffusion problem with space dependent\n  coefficients","summary":"This work focuses on numerically solving a shape identification problem\nrelated to advection-diffusion processes with space-dependent coefficients\nusing shape optimization techniques. Two boundary-type cost functionals are\nconsidered, and their corresponding variations with respect to shapes are\nderived using the adjoint method, employing the chain rule approach. This\ninvolves firstly utilizing the material derivative of the state system and\nsecondly using its shape derivative. Subsequently, an alternating direction\nmethod of multipliers (ADMM) combined with the Sobolev-gradient-descent\nalgorithm is applied to stably solve the shape reconstruction problem.\nNumerical experiments in two and three dimensions are conducted to demonstrate\nthe feasibility of the methods.","main_category":"math.OC","categories":"math.OC,cs.NA,math.NA","published":"2025-04-10T14:36:56Z"}
{"aid":"http://arxiv.org/abs/2504.07822v1","title":"DG-STMTL: A Novel Graph Convolutional Network for Multi-Task\n  Spatio-Temporal Traffic Forecasting","summary":"Spatio-temporal traffic prediction is crucial in intelligent transportation\nsystems. The key challenge of accurate prediction is how to model the complex\nspatio-temporal dependencies and adapt to the inherent dynamics in data.\nTraditional Graph Convolutional Networks (GCNs) often struggle with static\nadjacency matrices that introduce domain bias or learnable matrices that may be\noverfitting to specific patterns. This challenge becomes more complex when\nconsidering Multi-Task Learning (MTL). While MTL has the potential to enhance\nprediction accuracy through task synergies, it can also face significant\nhurdles due to task interference. To overcome these challenges, this study\nintroduces a novel MTL framework, Dynamic Group-wise Spatio-Temporal Multi-Task\nLearning (DG-STMTL). DG-STMTL proposes a hybrid adjacency matrix generation\nmodule that combines static matrices with dynamic ones through a task-specific\ngating mechanism. We also introduce a group-wise GCN module to enhance the\nmodelling capability of spatio-temporal dependencies. We conduct extensive\nexperiments on two real-world datasets to evaluate our method. Results show\nthat our method outperforms other state-of-the-arts, indicating its\neffectiveness and robustness.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-10T15:00:20Z"}
{"aid":"http://arxiv.org/abs/2504.07851v1","title":"Independence Is Not an Issue in Neurosymbolic AI","summary":"A popular approach to neurosymbolic AI is to take the output of the last\nlayer of a neural network, e.g. a softmax activation, and pass it through a\nsparse computation graph encoding certain logical constraints one wishes to\nenforce. This induces a probability distribution over a set of random\nvariables, which happen to be conditionally independent of each other in many\ncommonly used neurosymbolic AI models. Such conditionally independent random\nvariables have been deemed harmful as their presence has been observed to\nco-occur with a phenomenon dubbed deterministic bias, where systems learn to\ndeterministically prefer one of the valid solutions from the solution space\nover the others. We provide evidence contesting this conclusion and show that\nthe phenomenon of deterministic bias is an artifact of improperly applying\nneurosymbolic AI.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-10T15:28:36Z"}
{"aid":"http://arxiv.org/abs/2504.07872v1","title":"Dual Engines of Thoughts: A Depth-Breadth Integration Framework for\n  Open-Ended Analysis","summary":"We propose the Dual Engines of Thoughts (DEoT), an analytical framework for\ncomprehensive open-ended reasoning. While traditional reasoning frameworks\nprimarily focus on finding \"the best answer\" or \"the correct answer\" for\nsingle-answer problems, DEoT is specifically designed for \"open-ended\nquestions,\" enabling both broader and deeper analytical exploration. The\nframework centers on three key components: a Base Prompter for refining user\nqueries, a Solver Agent that orchestrates task decomposition, execution, and\nvalidation, and a Dual-Engine System consisting of a Breadth Engine (to explore\ndiverse impact factors) and a Depth Engine (to perform deep investigations).\nThis integrated design allows DEoT to balance wide-ranging coverage with\nin-depth analysis, and it is highly customizable, enabling users to adjust\nanalytical parameters and tool configurations based on specific requirements.\nExperimental results show that DEoT excels in addressing complex, multi-faceted\nquestions, achieving a total win rate of 77-86% compared to existing reasoning\nmodels, thus highlighting its effectiveness in real-world applications.","main_category":"cs.AI","categories":"cs.AI,cs.CE,cs.CL,cs.MA","published":"2025-04-10T15:46:03Z"}
{"aid":"http://arxiv.org/abs/2504.07882v1","title":"Large black-hole scalar charges induced by cosmology in Horndeski\n  theories","summary":"The regularity of black hole solutions, embedded in an expanding Universe, is\nstudied in a subclass of Horndeski theories, namely the sum of the simplest\nquadratic, cubic and quintic actions. We find that in presence of a time\nderivative of the scalar field, driven by the cosmological expansion, this\nregularity generically imposes large scalar charges for black holes, even when\nassuming strictly no direct coupling of matter to the scalar field. Such\ncharges cause a significant accretion of the scalar field by the black holes,\ndriving its local time derivative to a small value. This phenomenon, together\nwith the Vainshtein screening typical of these theories, strongly suppresses\nobservable scalar effects. We show that this full class of models is consistent\nwith LIGO/Virgo detections of gravitational waves, but that the LISA mission\nshould be able to constrain the coefficient of the quintic term at the\n$10^{-30}$ level in a self-acceleration scenario, an improvement by 16 orders\nof magnitude with respect to what is imposed by the speed of gravitational\nwaves.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-10T15:55:38Z"}
{"aid":"http://arxiv.org/abs/2504.07889v1","title":"A Steklov eigenvalue estimate for affine connections and its application\n  to substatic triples","summary":"Choi-Wang obtained a lower bound of the first eigenvalue of the Laplacian on\nclosed minimal hypersurfaces. On minimal hypersurfaces with boundary, Fraser-Li\nestablished an inequality giving a lower bound of the first Steklov eigenvalue\nas a counterpart of the Choi-Wang type inequality. These inequalities were\nshown under lower bounds of the Ricci curvature. In this paper, under\nnon-negative Ricci curvature associated with an affine connection introduced by\nWylie-Yeroshkin, we give a generalization of Fraser-Li type inequality. Our\nresults hold not only for weighted manifolds under non-negative $1$-weighted\nRicci curvature but also for substatic triples.","main_category":"math.DG","categories":"math.DG","published":"2025-04-10T16:02:32Z"}
{"aid":"http://arxiv.org/abs/2504.07906v1","title":"Deflection angle in the strong deflection limit of axisymmetric\n  spacetimes: local curvature, matter fields, and quasinormal modes","summary":"We investigate the deflection of photons in the strong deflection limit\nwithin static, axisymmetric spacetimes possessing reflection symmetry. As the\nimpact parameter approaches its critical value, the deflection angle exhibits a\nlogarithmic divergence. This divergence is characterized by a logarithmic rate\nand a constant offset, which we express in terms of coordinate-invariant\ncurvature evaluated at the unstable photon circular orbit. The curvature\ncontribution is encoded in the electric part of the Weyl tensor, reflecting\ntidal effects, and the matter contribution is encoded in the Einstein tensor,\ncapturing the influence of local energy and pressure. We also express these\ncoefficients using Newman--Penrose scalars. By exploiting the relationship\nbetween the strong deflection limit and quasinormal modes, we derive a new\nexpression for the quasinormal mode frequency in the eikonal limit in terms of\nthe curvature scalars. Our results provide a unified and coordinate-invariant\nframework that connects observable lensing features and quasinormal modes to\nthe local geometry and matter distribution near compact objects.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE,hep-th","published":"2025-04-10T16:28:45Z"}
{"aid":"http://arxiv.org/abs/2504.09918v1","title":"Berry curvature-induced intrinsic spin Hall effect in\n  light-element-based CrN system for magnetization switching","summary":"The current-induced spin-orbit torque-based devices for magnetization\nswitching are commonly relied on the 4d and 5d heavy metals owing to their\nstrong spin-orbit coupling (SOC) to produce large spin current via spin Hall\neffect (SHE). Here we present the sizable SHE in CrN, a light element-based\nsystem and demonstrate the current-induced magnetization switching in the\nadjacent ferromagnetic layer [Co(0.35nm)/Pt(0.3nm)]3, which exhibits\nperpendicular magnetic anisotropy. We found the switching current density of\n2.6 MA/cm2. The first principles calculation gives the spin Hall conductivity\n(SHC) to be 120 (hcross/e) S/cm due to intrinsic Berry curvature arising from\nSOC induced band splitting near Fermi-energy. The theoretically calculated\nintrinsic SHC is close to the experimental SHC extracted from second harmonic\nHall measurement. We estimated spin Hall angle to be 0.09, demonstrating\nefficient charge-to-spin conversion in CrN system.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-14T06:26:39Z"}
{"aid":"http://arxiv.org/abs/2504.09958v1","title":"C-MTCSD: A Chinese Multi-Turn Conversational Stance Detection Dataset","summary":"Stance detection has become an essential tool for analyzing public\ndiscussions on social media. Current methods face significant challenges,\nparticularly in Chinese language processing and multi-turn conversational\nanalysis. To address these limitations, we introduce C-MTCSD, the largest\nChinese multi-turn conversational stance detection dataset, comprising 24,264\ncarefully annotated instances from Sina Weibo, which is 4.2 times larger than\nthe only prior Chinese conversational stance detection dataset. Our\ncomprehensive evaluation using both traditional approaches and large language\nmodels reveals the complexity of C-MTCSD: even state-of-the-art models achieve\nonly 64.07% F1 score in the challenging zero-shot setting, while performance\nconsistently degrades with increasing conversation depth. Traditional models\nparticularly struggle with implicit stance detection, achieving below 50% F1\nscore. This work establishes a challenging new benchmark for Chinese stance\ndetection research, highlighting significant opportunities for future\nimprovements.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T07:55:47Z"}
{"aid":"http://arxiv.org/abs/2504.09974v1","title":"Towards Resilient Tracking in Autonomous Vehicles: A Distributionally\n  Robust Input and State Estimation Approach","summary":"This paper proposes a novel framework for the distributionally robust input\nand state estimation (DRISE) for autonomous vehicles operating under model\nuncertainties and measurement outliers. The proposed framework improves the\ninput and state estimation (ISE) approach by integrating distributional\nrobustness, enhancing the estimator's resilience and robustness to adversarial\ninputs and unmodeled dynamics. Moment-based ambiguity sets capture\nprobabilistic uncertainties in both system dynamics and measurement noise,\noffering analytical tractability and efficiently handling uncertainties in mean\nand covariance. In particular, the proposed framework minimizes the worst-case\nestimation error, ensuring robustness against deviations from nominal\ndistributions. The effectiveness of the proposed approach is validated through\nsimulations conducted in the CARLA autonomous driving simulator, demonstrating\nimproved performance in state estimation accuracy and robustness in dynamic and\nuncertain environments.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-14T08:26:06Z"}
{"aid":"http://arxiv.org/abs/2504.09978v1","title":"New exponential law for real networks","summary":"In this article we have shown that the distributions of ksi satisfy an\nexponential law for real networks while the distributions of ksi for random\nnetworks are bell-shaped and closer to the normal distribution. The ksi\ndistributions for Barabasi-Albert and Watts-Strogatz networks are similar to\nthe ksi distributions for random networks (bell-shaped) for most parameters,\nbut when these parameters become small enough, the Barabasi-Albert and\nWatts-Strogatz networks become more realistic with respect to the ksi\ndistributions.","main_category":"cs.SI","categories":"cs.SI,physics.soc-ph","published":"2025-04-14T08:39:25Z"}
{"aid":"http://arxiv.org/abs/2504.09990v1","title":"Correlative and Discriminative Label Grouping for Multi-Label Visual\n  Prompt Tuning","summary":"Modeling label correlations has always played a pivotal role in multi-label\nimage classification (MLC), attracting significant attention from researchers.\nHowever, recent studies have overemphasized co-occurrence relationships among\nlabels, which can lead to overfitting risk on this overemphasis, resulting in\nsuboptimal models. To tackle this problem, we advocate for balancing\ncorrelative and discriminative relationships among labels to mitigate the risk\nof overfitting and enhance model performance. To this end, we propose the\nMulti-Label Visual Prompt Tuning framework, a novel and parameter-efficient\nmethod that groups classes into multiple class subsets according to label\nco-occurrence and mutual exclusivity relationships, and then models them\nrespectively to balance the two relationships. In this work, since each group\ncontains multiple classes, multiple prompt tokens are adopted within Vision\nTransformer (ViT) to capture the correlation or discriminative label\nrelationship within each group, and effectively learn correlation or\ndiscriminative representations for class subsets. On the other hand, each group\ncontains multiple group-aware visual representations that may correspond to\nmultiple classes, and the mixture of experts (MoE) model can cleverly assign\nthem from the group-aware to the label-aware, adaptively obtaining label-aware\nrepresentation, which is more conducive to classification. Experiments on\nmultiple benchmark datasets show that our proposed approach achieves\ncompetitive results and outperforms SOTA methods on multiple pre-trained\nmodels.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T08:52:50Z"}
{"aid":"http://arxiv.org/abs/2504.10019v1","title":"Sagbi bases, defining ideals and algebra of minors","summary":"This paper extends the article of the Bruns and Conca on SAGBI bases and\ntheir computation (J. Symb. Comput. 120 (2024)) in two directions. (i) We\ndescribe the extension of the Singular library sagbiNormaliz.sing to the\ncomputation of defining ideals of subalgebras of polynomial rings. (ii) We give\na complete classification of the algebras of minors for which the generating\nset is a SAGBI basis with respect to a suitable monomial order and we identify\nuniversal SAGBI basis in three cases. The investigation is illustrated by\nseveral examples.","main_category":"math.AC","categories":"math.AC","published":"2025-04-14T09:25:29Z"}
{"aid":"http://arxiv.org/abs/2504.10021v1","title":"Masked Autoencoder Self Pre-Training for Defect Detection in\n  Microelectronics","summary":"Whereas in general computer vision, transformer-based architectures have\nquickly become the gold standard, microelectronics defect detection still\nheavily relies on convolutional neural networks (CNNs). We hypothesize that\nthis is due to the fact that a) transformers have an increased need for data\nand b) labelled image generation procedures for microelectronics are costly,\nand labelled data is therefore sparse. Whereas in other domains, pre-training\non large natural image datasets can mitigate this problem, in microelectronics\ntransfer learning is hindered due to the dissimilarity of domain data and\nnatural images. Therefore, we evaluate self pre-training, where models are\npre-trained on the target dataset, rather than another dataset. We propose a\nvision transformer (ViT) pre-training framework for defect detection in\nmicroelectronics based on masked autoencoders (MAE). In MAE, a large share of\nimage patches is masked and reconstructed by the model during pre-training. We\nperform pre-training and defect detection using a dataset of less than 10.000\nscanning acoustic microscopy (SAM) images labelled using transient thermal\nanalysis (TTA). Our experimental results show that our approach leads to\nsubstantial performance gains compared to a) supervised ViT, b) ViT pre-trained\non natural image datasets, and c) state-of-the-art CNN-based defect detection\nmodels used in the literature. Additionally, interpretability analysis reveals\nthat our self pre-trained models, in comparison to ViT baselines, correctly\nfocus on defect-relevant features such as cracks in the solder material. This\ndemonstrates that our approach yields fault-specific feature representations,\nmaking our self pre-trained models viable for real-world defect detection in\nmicroelectronics.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T09:25:50Z"}
{"aid":"http://arxiv.org/abs/2504.10030v1","title":"EmbodiedAgent: A Scalable Hierarchical Approach to Overcome Practical\n  Challenge in Multi-Robot Control","summary":"This paper introduces EmbodiedAgent, a hierarchical framework for\nheterogeneous multi-robot control. EmbodiedAgent addresses critical limitations\nof hallucination in impractical tasks. Our approach integrates a next-action\nprediction paradigm with a structured memory system to decompose tasks into\nexecutable robot skills while dynamically validating actions against\nenvironmental constraints. We present MultiPlan+, a dataset of more than 18,000\nannotated planning instances spanning 100 scenarios, including a subset of\nimpractical cases to mitigate hallucination. To evaluate performance, we\npropose the Robot Planning Assessment Schema (RPAS), combining automated\nmetrics with LLM-aided expert grading. Experiments demonstrate EmbodiedAgent's\nsuperiority over state-of-the-art models, achieving 71.85% RPAS score.\nReal-world validation in an office service task highlights its ability to\ncoordinate heterogeneous robots for long-horizon objectives.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-14T09:33:42Z"}
{"aid":"http://arxiv.org/abs/2504.10056v1","title":"CMOS-compatible vanadium dioxide via Pulsed Laser and Atomic Layer\n  deposition: towards ultra-thin film phase-change layers","summary":"Vanadium dioxide, a well-known Mott insulator, is a highly studied electronic\nmaterial with promising applications in information processing and storage.\nWhile fully crystalline layers exhibit exceptional properties, such as a sharp\nand abrupt conductivity change at the metal-insulator transition, fabricating\npoly-crystalline films on silicon substrates often involves trade-offs in\ntransport characteristics and switching performance, especially for ultra-thin\nlayers required in advanced gate applications. In this study, we explore the\ngrowth of vanadium dioxide films on standard wet-oxidized silicon wafers using\ntwo established deposition techniques with pulsed laser deposition and atomic\nlayer deposition. Thin films, ranging in thickness from 200 to 10 nano meters,\nwere systematically characterized through structural and electrical analyses to\noptimize key growth parameters. Temperature and pressure were identified as the\nprimary factors affecting film quality, and the optimal growth conditions\nacross the entire thickness range are discussed in detail. We demonstrate that\nboth pulsed laser deposition and atomic layer deposition methods can\nsuccessfully produce ultra-thin vanadium dioxide layers down to 8 nano meters\nwith functional properties suitable for practical applications. This work\nunderscores the potential of vanadium dioxide for fully industry compatible\nphase-change switching devices and provides valuable insights into optimizing\ngrowth processes for poly-crystalline films.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-14T09:59:24Z"}
{"aid":"http://arxiv.org/abs/2504.10092v1","title":"Bayesian optimal experimental design with Wasserstein information\n  criteria","summary":"Bayesian optimal experimental design (OED) provides a principled framework\nfor selecting the most informative observational settings in experiments. With\nrapid advances in computational power, Bayesian OED has become increasingly\nfeasible for inference problems involving large-scale simulations, attracting\ngrowing interest in fields such as inverse problems. In this paper, we\nintroduce a novel design criterion based on the expected Wasserstein-$p$\ndistance between the prior and posterior distributions. Especially, for $p=2$,\nthis criterion shares key parallels with the widely used expected information\ngain (EIG), which relies on the Kullback--Leibler divergence instead. First,\nthe Wasserstein-2 criterion admits a closed-form solution for Gaussian\nregression, a property which can be also leveraged for approximative schemes.\nSecond, it can be interpreted as maximizing the information gain measured by\nthe transport cost incurred when updating the prior to the posterior. Our main\ncontribution is a stability analysis of the Wasserstein-1 criterion, where we\nprovide a rigorous error analysis under perturbations of the prior or\nlikelihood. We partially extend this study also to the Wasserstein-2 criterion.\nIn particular, these results yield error rates when empirical approximations of\npriors are used. Finally, we demonstrate the computability of the Wasserstein-2\ncriterion and demonstrate our approximation rates through simulations.","main_category":"stat.ME","categories":"stat.ME,cs.NA,math.NA,stat.CO","published":"2025-04-14T10:56:42Z"}
{"aid":"http://arxiv.org/abs/2504.10119v1","title":"Non-intrusive Auto-detecting and Adaptive Hybrid Scheme for Multiscale\n  Heat Transfer: Thermal Runaway in a Battery Pack","summary":"Accurately capturing and simulating multiscale systems is a formidable\nchallenge, as both spatial and temporal scales can span many orders of\nmagnitude. Rigorous upscaling methods not only ensure efficient computation,\nbut also maintains errors within a priori prescribed limits. This provides a\nbalance between computational costs and accuracy. However, the most significant\ndifficulties arise when the conditions under which upscaled models can be\napplied cease to hold. To address this, we develop an automatic-detecting and\nadaptive, nonintrusive two-sided hybrid method for multiscale heat transfer and\napply it to thermal runaway in a battery pack. To allow adaptive hybrid\nsimulations, two kernels are developed to dynamically map the values between\nthe fine-scale and the upscaled subdomains in a single simulation. The accuracy\nof the developed hybrid method is demonstrated through conducting a series of\nthermal runaway test cases in a battery pack. Our results show that the maximum\nspatial errors consistently remain below the threshold bounded by upscaling\nerrors.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-04-14T11:28:27Z"}
{"aid":"http://arxiv.org/abs/2504.10122v1","title":"Design Optimization of Flip FET Standard Cells with Dual-sided Pins for\n  Ultimate Scaling","summary":"Recently, we proposed a novel transistor architecture for 3D stacked FETs\ncalled Flip FET (FFET), featuring N/P transistors back-to-back stacked and\ndual-sided interconnects. With dual-sided power rails and signal tracks, FFET\ncan achieve an aggressive 2.5T cell height. As a tradeoff, the complex\nstructure and limited numbers of M0 tracks could limit the standard cell\ndesign. As a solution, multiple innovations were introduced and examined in\nthis work. Based on an advanced node design rule, several unique building\nblocks in FFET such as drain merge (DM), gate merge (GM), field drain merge\n(FDM) and buried signal track (BST) were investigated. Other key design\nconcepts of multi-row, split gate and dummy gate insertion (DG) were also\ncarefully studied, delivering around 35.6% area reduction compared with 3T\nCFET. Furthermore, the symmetric design of FFET has unique superiority over\nCFET thanks to the separate N/P logic on two sides of the wafer and their\nconnections using DM and GM. New routing scheme with dual-sided output pins on\nboth wafer frontside (FS) and backside (BS) was proposed for the first time.\nFinally, we conducted a comprehensive evaluation on complex cell design, taking\nAOI22 as an example. New strategies were proposed and examined. The FDM design\nis identified as the best, outperforming the BST and dummy gate design by 1.93%\nand 5.13% for the transition delay.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-14T11:31:44Z"}
{"aid":"http://arxiv.org/abs/2504.10128v1","title":"Probing Binary Lens Caustics with Gravitational Waves: A Uniform\n  Approximation Approach","summary":"We present a new framework for modeling gravitational wave diffraction near\nfold caustics using the Uniform Approximation (UA), focusing on binary mass\nlenses-axially asymmetric systems with complex caustic structures. Full-wave\nmethods based on the Kirchhoff integral become impractical in this regime due\nto highly oscillatory integrands. The UA provides a robust and accurate\ndescription of the wave field near folds, resolving the breakdown of\nGeometrical Optics at caustics and improving upon Transitional\nAsymptotics-based on Airy function approximations-which lack global validity.\nCentral to our approach is the concept of the caustic width, $d_c$, a\ncharacteristic length scale defining the region where diffraction significantly\nalters wave propagation. We find that $d_c$ scales universally with the\ngravitational wavelength as ~ $ \\lambda^{2/3}$ and inversely with the\nredshifted lens mass as ~ $ M_{Lz}^{-2/3}$. The wave amplification near the\nfold grows as ~ $ d_c^{-1/4}$, substantially enhancing the signal and\npotentially playing a key role in the detection of gravitational waves lensed\nnear caustics. Notably, for lens masses below the galactic scale, the caustic\nwidth for gravitational waves is not negligible compared to the Einstein\nradius-as it is in electromagnetic lensing-making the UA essential for\naccurately capturing wave effects.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-14T11:36:36Z"}
{"aid":"http://arxiv.org/abs/2504.10179v1","title":"The Future of MLLM Prompting is Adaptive: A Comprehensive Experimental\n  Evaluation of Prompt Engineering Methods for Robust Multimodal Performance","summary":"Multimodal Large Language Models (MLLMs) are set to transform how machines\nprocess and generate human-like responses by integrating diverse modalities\nsuch as text, images, and code. Yet, effectively harnessing their capabilities\nhinges on optimal prompt engineering. We present a comprehensive experimental\nevaluation of seven prompt engineering methods applied to 13 open-source MLLMs\nover 24 tasks spanning Reasoning and Compositionality, Multimodal Understanding\nand Alignment, Complex Code Generation and Execution, and Knowledge Retrieval\nand Integration. Our approach stratifies models by parameter count into Small\n(<4B), Medium (4B-10B), and Large (>10B) categories and compares prompting\ntechniques including Zero-Shot, One-Shot, Few-Shot, Chain-of-Thought,\nAnalogical, Generated Knowledge, and Tree-of-Thought. While Large MLLMs excel\nin structured tasks such as code generation, achieving accuracies up to 96.88%\nunder Few-Shot prompting, all models struggle with complex reasoning and\nabstract understanding, often yielding accuracies below 60% and high\nhallucination rates. Structured reasoning prompts frequently increased\nhallucination up to 75% in small models and led to longer response times (over\n20 seconds in Large MLLMs), while simpler prompting methods provided more\nconcise and efficient outputs. No single prompting method uniformly optimises\nall task types. Instead, adaptive strategies combining example-based guidance\nwith selective structured reasoning are essential to enhance robustness,\nefficiency, and factual accuracy. Our findings offer practical recommendations\nfor prompt engineering and support more reliable deployment of MLLMs across\napplications including AI-assisted coding, knowledge retrieval, and multimodal\ncontent understanding.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.ET","published":"2025-04-14T12:31:39Z"}
{"aid":"http://arxiv.org/abs/2504.10206v1","title":"Approximation by Neural Network Sampling Operators in Mixed Lebesgue\n  Spaces","summary":"In this paper, we prove the rate of approximation for the Neural Network\nSampling Operators activated by sigmoidal functions with mixed Lebesgue norm in\nterms of averaged modulus of smoothness for a bounded measurable functions on\nbounded domain. In order to achieve the above result, we first establish that\nthe averaged modulus of smoothness is finite for certain suitable subspaces of\n$L^{p,q}(\\mathbb{R}\\times\\mathbb{R}).$ Using the properties of averaged modulus\nof smoothness, we estimate the rate of approximation of certain linear\noperators in mixed Lebesgue norm. Then, as an application of these linear\noperators, we obtain the Jackson type approximation theorem, in order to give a\ncharacterization for the rate of approximation of neural network operators\nin-terms of averaged modulus of smoothness in mixed norm. Lastly, we discuss\nsome examples of sigmoidal functions and using these sigmoidal functions, we\nshow the implementation of continuous and discontinuous functions by neural\nnetwork operators.","main_category":"math.FA","categories":"math.FA","published":"2025-04-14T13:16:17Z"}
{"aid":"http://arxiv.org/abs/2504.10228v1","title":"Magneto-Hydrodynamic Simulations of Eccentric Binary Neutron Star\n  Mergers","summary":"Highly eccentric binary neutron star mergers exhibit unique dynamical and\nobservational signatures compared to quasi-circular ones in terms of their\ngravitational wave signal and the ejection of matter, leading to different\nelectromagnetic counterparts. In this article, we present general relativistic\nmagneto-hydrodynamic simulations of binary neutron star systems on highly\neccentric orbits. While in quasi-circular binaries, the influence of the\nmagnetic field is too weak to affect the general pre-merger dynamics, the close\nencounters in eccentric systems could potentially trigger magneto-hydrodynamic\ninstabilities. Therefore, we investigate possible effects before, during, and\nafter the merger for a total of three different systems with varying initial\neccentricity.\n  We study the f-mode oscillations excited by tidal interaction in close\nencounters and find good agreement with predicted f-mode frequency estimates.\nHowever, our simulations reveal no significant differences compared to results\nneglecting the magnetic field. Although we observe a rearrangement of the\npoloidal structure of the magnetic field inside the stars, there is no relevant\nincrease in the magnetic energy during the encounters. Also, during the merger,\nthe amplification of the magnetic field seems to be largely independent of the\neccentricity in our systems. Consistent with studies of merging non-magnetized\nbinary neutron stars, we find a correlation between eccentricity and mass\nejection, with a higher impact parameter leading to a larger amount of unbound\nmaterial.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE","published":"2025-04-14T13:48:10Z"}
{"aid":"http://arxiv.org/abs/2504.10240v1","title":"GNN-ACLP: Graph Neural Networks based Analog Circuit Link Prediction","summary":"Circuit link prediction identifying missing component connections from\nincomplete netlists is crucial in automating analog circuit design. However,\nexisting methods face three main challenges: 1) Insufficient use of topological\npatterns in circuit graphs reduces prediction accuracy; 2) Data scarcity due to\nthe complexity of annotations hinders model generalization; 3) Limited\nadaptability to various netlist formats. We propose GNN-ACLP, a Graph Neural\nNetworks (GNNs) based framework featuring three innovations to tackle these\nchallenges. First, we introduce the SEAL (Subgraphs, Embeddings, and Attributes\nfor Link Prediction) framework and achieve port-level accuracy in circuit link\nprediction. Second, we propose Netlist Babel Fish, a netlist format conversion\ntool leveraging retrieval-augmented generation (RAG) with large language model\n(LLM) to enhance the compatibility of netlist formats. Finally, we construct\nSpiceNetlist, a comprehensive dataset that contains 775 annotated circuits\nacross 10 different classes of components. The experimental results demonstrate\nan improvement of 15.05% on the SpiceNetlist dataset and 12.01% on the\nImage2Net dataset over the existing approach.","main_category":"cs.AR","categories":"cs.AR,cs.LG","published":"2025-04-14T14:02:09Z"}
{"aid":"http://arxiv.org/abs/2504.10246v1","title":"Simplified and Verified: A Second Look at a Proof-Producing Union-Find\n  Algorithm","summary":"Using Isabelle/HOL, we verify a union-find data structure with an explain\noperation due to Nieuwenhuis and Oliveras. We devise a simpler, more naive\nversion of the explain operation whose soundness and completeness is easy to\nverify. Then, we prove the original formulation of the explain operation to be\nequal to our version. Finally, we refine this data structure to Imperative HOL,\nenabling us to export efficient imperative code. The formalisation provides a\nstepping stone towards the verification of proof-producing congruence closure\nalgorithms which are a core ingredient of Satisfiability Modulo Theories (SMT)\nsolvers.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-14T14:09:09Z"}
{"aid":"http://arxiv.org/abs/2504.10250v1","title":"MURR: Model Updating with Regularized Replay for Searching a Document\n  Stream","summary":"The Internet produces a continuous stream of new documents and user-generated\nqueries. These naturally change over time based on events in the world and the\nevolution of language. Neural retrieval models that were trained once on a\nfixed set of query-document pairs will quickly start misrepresenting\nnewly-created content and queries, leading to less effective retrieval.\nTraditional statistical sparse retrieval can update collection statistics to\nreflect these changes in the use of language in documents and queries. In\ncontrast, continued fine-tuning of the language model underlying neural\nretrieval approaches such as DPR and ColBERT creates incompatibility with\npreviously-encoded documents. Re-encoding and re-indexing all\npreviously-processed documents can be costly. In this work, we explore updating\na neural dual encoder retrieval model without reprocessing past documents in\nthe stream. We propose MURR, a model updating strategy with regularized replay,\nto ensure the model can still faithfully search existing documents without\nreprocessing, while continuing to update the model for the latest topics. In\nour simulated streaming environments, we show that fine-tuning models using\nMURR leads to more effective and more consistent retrieval results than other\nstrategies as the stream of documents and queries progresses.","main_category":"cs.IR","categories":"cs.IR,cs.CL","published":"2025-04-14T14:13:03Z"}
{"aid":"http://arxiv.org/abs/2504.10259v1","title":"Dual-grid parameter choice method with application to image deblurring","summary":"Variational regularization of ill-posed inverse problems is based on\nminimizing the sum of a data fidelity term and a regularization term. The\nbalance between them is tuned using a positive regularization parameter, whose\nautomatic choice remains an open question in general. A novel approach for\nparameter choice is introduced, based on the use of two slightly different\ncomputational models for the same inverse problem. Small parameter values\nshould give two very different reconstructions due to amplification of noise.\nLarge parameter values lead to two identical but trivial reconstructions.\nOptimal parameter is chosen between the extremes by matching image similarity\nof the two reconstructions with a pre-defined value. Efficacy of the new method\nis demonstrated with image deblurring using measured data and two different\nregularizers.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-14T14:19:58Z"}
{"aid":"http://arxiv.org/abs/2504.10261v1","title":"Universality, Robustness, and Limits of the Eigenstate Thermalization\n  Hypothesis in Open Quantum Systems","summary":"The eigenstate thermalization hypothesis (ETH) underpins much of our modern\nunderstanding of the thermalization of closed quantum many-body systems. Here,\nwe investigate the statistical properties of observables in the eigenbasis of\nthe Lindbladian operator of a Markovian open quantum system. We demonstrate the\nvalidity of a Lindbladian ETH ansatz through extensive numerical simulations of\nseveral physical models. To highlight the robustness of Lindbladian ETH, we\nconsider what we dub the dilute-click regime of the model, in which one\npostselects only quantum trajectories with a finite fraction of quantum jumps.\nThe average dynamics are generated by a non-trace-preserving Liouvillian, and\nwe show that the Lindbladian ETH ansatz still holds in this case. On the other\nhand, the no-click limit is a singular point at which the Lindbladian reduces\nto a doubled non-Hermitian Hamiltonian and Lindbladian ETH breaks down.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.dis-nn,nlin.CD,quant-ph","published":"2025-04-14T14:25:11Z"}
{"aid":"http://arxiv.org/abs/2504.10270v1","title":"Affine and cyclotomic $q$-Schur categories via webs","summary":"We formulate two new $\\mathbb Z[q,q^{-1}]$-linear diagrammatic monoidal\ncategories, the affine $q$-web category and the affine $q$-Schur category, as\nwell as their respective cyclotomic quotient categories. Diagrammatic integral\nbases for the Hom-spaces of all these categories are established. In addition,\nwe establish the following isomorphisms, providing diagrammatic presentations\nof these $q$-Schur algebras for the first time: (i)~ the path algebras of the\naffine $q$-web category to R.~Green's affine $q$-Schur algebras, (ii)~ the path\nalgebras of the affine $q$-Schur category to Maksimau-Stroppel's higher level\naffine $q$-Schur algebras, and most significantly, (iii)~ the path algebras of\nthe cyclotomic $q$-Schur categories to Dipper-James-Mathas' cyclotomic\n$q$-Schur algebras.","main_category":"math.RT","categories":"math.RT,math.QA","published":"2025-04-14T14:34:52Z"}
{"aid":"http://arxiv.org/abs/2504.10284v1","title":"Can LLMs Generate Tabular Summaries of Science Papers? Rethinking the\n  Evaluation Protocol","summary":"Literature review tables are essential for summarizing and comparing\ncollections of scientific papers. We explore the task of generating tables that\nbest fulfill a user's informational needs given a collection of scientific\npapers. Building on recent work (Newman et al., 2024), we extend prior\napproaches to address real-world complexities through a combination of\nLLM-based methods and human annotations. Our contributions focus on three key\nchallenges encountered in real-world use: (i) User prompts are often\nunder-specified; (ii) Retrieved candidate papers frequently contain irrelevant\ncontent; and (iii) Task evaluation should move beyond shallow text similarity\ntechniques and instead assess the utility of inferred tables for\ninformation-seeking tasks (e.g., comparing papers). To support reproducible\nevaluation, we introduce ARXIV2TABLE, a more realistic and challenging\nbenchmark for this task, along with a novel approach to improve literature\nreview table generation in real-world scenarios. Our extensive experiments on\nthis benchmark show that both open-weight and proprietary LLMs struggle with\nthe task, highlighting its difficulty and the need for further advancements.\nOur dataset and code are available at https://github.com/JHU-CLSP/arXiv2Table.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T14:52:28Z"}
{"aid":"http://arxiv.org/abs/2504.10290v1","title":"Maximizing subgraph density in graphs of bounded degree and clique\n  number","summary":"We asymptotically determine the maximum density of subgraphs isomorphic to\n$H$, where $H$ is any graph containing a dominating vertex, in graphs $G$ on\n$n$ vertices with bounded maximum degree and bounded clique number. That is, we\nasymptotically determine the constant $c=c(H,\\Delta,\\omega)$ such that\nex$(n,H,\\{K_{1,\\Delta+1},K_{\\omega+1}\\})=(1-o_n(1))cn$. More generally, if $H$\nhas at least $u$ dominating vertices, then we find the maximum density of\nsubgraphs isomorphic to $H$ in graphs $G$ that have $p$ cliques of size $u$,\nhave bounded clique number, and are $K_u\\vee I_{\\Delta+1}$-free. For example,\nwe asymptotically determine the constant $d=d(H,\\Delta,\\omega)$ such that\nmex$(m,H,\\{K_{1,1,\\Delta+1},K_{\\omega+1}\\})=(1-o_m(1))dm$. Then we localize\nthese results, proving a tight inequality involving the sizes of the locally\nlargest cliques and complete split graphs.","main_category":"math.CO","categories":"math.CO","published":"2025-04-14T15:02:24Z"}
{"aid":"http://arxiv.org/abs/2504.10306v1","title":"Global existence of measure-valued solutions to the multicomponent\n  Smoluchowski coagulation equation","summary":"Global solutions to the multicomponent Smoluchowski coagulation equation are\nconstructed for measure-valued initial data with minimal assumptions on the\nmoments. The framework is based on an abstract formulation of the\nArzel\\`a-Ascoli theorem for uniform spaces. The result holds for a large class\nof coagulation rate kernels, satisfying a power-law upper bound with possibly\ndifferent singularities at small-small, small-large and large-large coalescence\npairs. This includes in particular both mass-conserving and gelling kernels, as\nwell as interpolation kernels used in applications. We also provide short\nproofs of mass-conservation and gelation results for any weak solution, which\nextends previous results for one-component systems.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP","published":"2025-04-14T15:14:22Z"}
{"aid":"http://arxiv.org/abs/2504.10337v1","title":"Heimdall: test-time scaling on the generative verification","summary":"An AI system can create and maintain knowledge only to the extent that it can\nverify that knowledge itself. Recent work on long Chain-of-Thought reasoning\nhas demonstrated great potential of LLMs on solving competitive problems, but\ntheir verification ability remains to be weak and not sufficiently\ninvestigated. In this paper, we propose Heimdall, the long CoT verification LLM\nthat can accurately judge the correctness of solutions. With pure reinforcement\nlearning, we boost the verification accuracy from 62.5% to 94.5% on competitive\nmath problems. By scaling with repeated sampling, the accuracy further\nincreases to 97.5%. Through human evaluation, Heimdall demonstrates impressive\ngeneralization capabilities, successfully detecting most issues in challenging\nmath proofs, the type of which is not included during training. Furthermore, we\npropose Pessimistic Verification to extend the functionality of Heimdall to\nscaling up the problem solving. It calls Heimdall to judge the solutions from a\nsolver model and based on the pessimistic principle, selects the most likely\ncorrect solution with the least uncertainty. Taking\nDeepSeek-R1-Distill-Qwen-32B as the solver model, Pessimistic Verification\nimproves the solution accuracy on AIME2025 from 54.2% to 70.0% with 16x compute\nbudget and to 83.3% with more compute budget. With the stronger solver Gemini\n2.5 Pro, the score reaches 93.0%. Finally, we prototype an automatic knowledge\ndiscovery system, a ternary system where one poses questions, another provides\nsolutions, and the third verifies the solutions. Using the data synthesis work\nNuminaMath for the first two components, Heimdall effectively identifies\nproblematic records within the dataset and reveals that nearly half of the data\nis flawed, which interestingly aligns with the recent ablation studies from\nNuminaMath.","main_category":"cs.AI","categories":"cs.AI,I.2.7","published":"2025-04-14T15:46:33Z"}
{"aid":"http://arxiv.org/abs/2504.10344v1","title":"ALMTokenizer: A Low-bitrate and Semantic-rich Audio Codec Tokenizer for\n  Audio Language Modeling","summary":"Recent advancements in audio language models have underscored the pivotal\nrole of audio tokenization, which converts audio signals into discrete tokens,\nthereby facilitating the application of language model architectures to the\naudio domain. In this study, we introduce ALMTokenizer, a novel low-bitrate and\nsemantically rich audio codec tokenizer for audio language models. Prior\nmethods, such as Encodec, typically encode individual audio frames into\ndiscrete tokens without considering the use of context information across\nframes. Unlike these methods, we introduce a novel query-based compression\nstrategy to capture holistic information with a set of learnable query tokens\nby explicitly modeling the context information across frames. This design not\nonly enables the codec model to capture more semantic information but also\nencodes the audio signal with fewer token sequences. Additionally, to enhance\nthe semantic information in audio codec models, we introduce the following: (1)\nA masked autoencoder (MAE) loss, (2) Vector quantization based on semantic\npriors, and (3) An autoregressive (AR) prediction loss. As a result,\nALMTokenizer achieves competitive reconstruction performance relative to\nstate-of-the-art approaches while operating at a lower bitrate. Within the same\naudio language model framework, ALMTokenizer outperforms previous tokenizers in\naudio understanding and generation tasks.","main_category":"cs.SD","categories":"cs.SD","published":"2025-04-14T15:51:56Z"}
{"aid":"http://arxiv.org/abs/2504.10353v1","title":"Patch and Shuffle: A Preprocessing Technique for Texture Classification\n  in Autonomous Cementitious Fabrication","summary":"Autonomous fabrication systems are transforming construction and\nmanufacturing, yet they remain vulnerable to print errors. Texture\nclassification is a key component of computer vision systems that enable\nreal-time monitoring and adjustment during cementitious fabrication.\nTraditional classification methods often rely on global image features, which\ncan bias the model toward semantic content rather than low-level textures. In\nthis paper, we introduce a novel preprocessing technique called \"patch and\nshuffle,\" which segments input images into smaller patches, shuffles them, and\nreconstructs a jumbled image before classification. This transformation removes\nsemantic context, forcing the classifier to rely on local texture features.\n  We evaluate this approach on a dataset of extruded cement images, using a\nResNet-18-based architecture. Our experiments compare the patch and shuffle\nmethod to a standard pipeline, holding all other factors constant. Results show\na significant improvement in accuracy: the patch and shuffle model achieved\n90.64% test accuracy versus 72.46% for the baseline. These findings suggest\nthat disrupting global structure enhances performance in texture-based\nclassification tasks.\n  This method has implications for broader vision tasks where low-level\nfeatures matter more than high-level semantics. The technique may improve\nclassification in applications ranging from fabrication monitoring to medical\nimaging.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:03:21Z"}
{"aid":"http://arxiv.org/abs/2504.10355v1","title":"A geometric analysis of the Bazykin-Berezovskaya predator-prey model\n  with Allee effect in an economic framework","summary":"We study a fast-slow version of the Bazykin-Berezovskaya predator-prey model\nwith Allee effect evolving on two timescales, through the lenses of Geometric\nSingular Perturbation Theory (GSPT). The system we consider is in non-standard\nform. We completely characterize its dynamics, providing explicit threshold\nquantities to distinguish between a rich variety of possible asymptotic\nbehaviors. Moreover, we propose numerical results to illustrate our findings.\nLastly, we comment on the real-world interpretation of these results, in an\neconomic framework and in the context of predator-prey models.","main_category":"math.DS","categories":"math.DS,q-bio.PE","published":"2025-04-14T16:04:03Z"}
{"aid":"http://arxiv.org/abs/2504.10369v1","title":"SymRTLO: Enhancing RTL Code Optimization with LLMs and Neuron-Inspired\n  Symbolic Reasoning","summary":"Optimizing Register Transfer Level (RTL) code is crucial for improving the\npower, performance, and area (PPA) of digital circuits in the early stages of\nsynthesis. Manual rewriting, guided by synthesis feedback, can yield\nhigh-quality results but is time-consuming and error-prone. Most existing\ncompiler-based approaches have difficulty handling complex design constraints.\nLarge Language Model (LLM)-based methods have emerged as a promising\nalternative to address these challenges. However, LLM-based approaches often\nface difficulties in ensuring alignment between the generated code and the\nprovided prompts. This paper presents SymRTLO, a novel neuron-symbolic RTL\noptimization framework that seamlessly integrates LLM-based code rewriting with\nsymbolic reasoning techniques. Our method incorporates a retrieval-augmented\ngeneration (RAG) system of optimization rules and Abstract Syntax Tree\n(AST)-based templates, enabling LLM-based rewriting that maintains syntactic\ncorrectness while minimizing undesired circuit behaviors. A symbolic module is\nproposed for analyzing and optimizing finite state machine (FSM) logic,\nallowing fine-grained state merging and partial specification handling beyond\nthe scope of pattern-based compilers. Furthermore, a fast verification\npipeline, combining formal equivalence checks with test-driven validation,\nfurther reduces the complexity of verification. Experiments on the RTL-Rewriter\nbenchmark with Synopsys Design Compiler and Yosys show that SymRTLO improves\npower, performance, and area (PPA) by up to 43.9%, 62.5%, and 51.1%,\nrespectively, compared to the state-of-the-art methods.","main_category":"cs.AR","categories":"cs.AR,cs.AI,cs.LG,cs.PL","published":"2025-04-14T16:15:55Z"}
{"aid":"http://arxiv.org/abs/2504.10372v1","title":"Simple physical systems as a reference for multivariate information\n  dynamics","summary":"Understanding a complex system entails capturing the non-trivial collective\nphenomena that arise from interactions between its different parts. Information\ntheory is a flexible and robust framework to study such behaviours, with\nseveral measures designed to quantify and characterise the interdependencies\namong the system's components. However, since these estimators rely on the\nstatistical distributions of observed quantities, it is crucial to examine the\nrelationships between information-theoretic measures and the system's\nunderlying mechanistic structure. To this end, here we present an\ninformation-theoretic analytical investigation of an elementary system of\ninteractive random walkers subject to Gaussian noise. Focusing on partial\ninformation decomposition, causal emergence, and integrated information, our\nresults help us develop some intuitions on their relationship with the physical\nparameters of the system. For instance, we observe that uncoupled systems can\nexhibit emergent properties, in a way that we suggest may be better described\nas ''statistically autonomous''. Overall, we observe that in this simple\nscenario information measures align more reliably with the system's mechanistic\nproperties when calculated at the level of microscopic components, rather than\ntheir coarse-grained counterparts, and over timescales comparable with the\nsystem's intrinsic dynamics. Moreover, we show that approaches that separate\nthe contributions of the system's dynamics and steady-state distribution (e.g.\nvia causal perturbations) may help strengthen the interpretation of\ninformation-theoretic analyses.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-14T16:20:48Z"}
{"aid":"http://arxiv.org/abs/2504.10381v1","title":"Abstract simplicial complexes in {\\tt Macaulay2}","summary":"{\\tt AbstractSimplicialComplexes.m2} is a computer algebra package written\nfor the computer algebra system {\\tt Macaulay2} \\cite{M2}. It provides new\ninfrastructure to work with abstract simplicial complexes and related\nhomological constructions. Its key novel feature is to implement each given\nabstract simplicial complex as a certain graded list in the form of a hash\ntable with integer keys. Among other features, this allows for a direct\nimplementation of the associated reduced and non-reduced simplicial chain\ncomplexes. Further, it facilitates construction of random simplicial complexes.\nThe approach that we employ here builds on the {\\tt Macaulay2} package {\\tt\nComplexes.m2} \\cite{Stillman:Smith:Complexes.m2}. It complements and is\nentirely different from the existing {\\tt Macaulay2} simplicial complexes\nframework that is made possible by the package {\\tt SimplicialComplexes.m2}\n\\cite{Smith:et:al:SimplicialComplexes.m2:jsag}.","main_category":"math.AG","categories":"math.AG,math.AC,math.AT,math.CO,math.KT","published":"2025-04-14T16:25:50Z"}
{"aid":"http://arxiv.org/abs/2504.10452v1","title":"Integrating Vision and Location with Transformers: A Multimodal Deep\n  Learning Framework for Medical Wound Analysis","summary":"Effective recognition of acute and difficult-to-heal wounds is a necessary\nstep in wound diagnosis. An efficient classification model can help wound\nspecialists classify wound types with less financial and time costs and also\nhelp in deciding on the optimal treatment method. Traditional machine learning\nmodels suffer from feature selection and are usually cumbersome models for\naccurate recognition. Recently, deep learning (DL) has emerged as a powerful\ntool in wound diagnosis. Although DL seems promising for wound type\nrecognition, there is still a large scope for improving the efficiency and\naccuracy of the model. In this study, a DL-based multimodal classifier was\ndeveloped using wound images and their corresponding locations to classify them\ninto multiple classes, including diabetic, pressure, surgical, and venous\nulcers. A body map was also created to provide location data, which can help\nwound specialists label wound locations more effectively. The model uses a\nVision Transformer to extract hierarchical features from input images, a\nDiscrete Wavelet Transform (DWT) layer to capture low and high frequency\ncomponents, and a Transformer to extract spatial features. The number of\nneurons and weight vector optimization were performed using three swarm-based\noptimization techniques (Monster Gorilla Toner (MGTO), Improved Gray Wolf\nOptimization (IGWO), and Fox Optimization Algorithm). The evaluation results\nshow that weight vector optimization using optimization algorithms can increase\ndiagnostic accuracy and make it a very effective approach for wound detection.\nIn the classification using the original body map, the proposed model was able\nto achieve an accuracy of 0.8123 using image data and an accuracy of 0.8007\nusing a combination of image data and wound location. Also, the accuracy of the\nmodel in combination with the optimization models varied from 0.7801 to 0.8342.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T17:39:18Z"}
{"aid":"http://arxiv.org/abs/2504.10465v1","title":"Pixel-SAIL: Single Transformer For Pixel-Grounded Understanding","summary":"Multimodal Large Language Models (MLLMs) achieve remarkable performance for\nfine-grained pixel-level understanding tasks. However, all the works rely\nheavily on extra components, such as vision encoder (CLIP), segmentation\nexperts, leading to high system complexity and limiting model scaling. In this\nwork, our goal is to explore a highly simplified MLLM without introducing extra\ncomponents. Our work is motivated by the recent works on Single trAnsformer as\na unified vIsion-Language Model (SAIL) design, where these works jointly learn\nvision tokens and text tokens in transformers. We present Pixel-SAIL, a single\ntransformer for pixel-wise MLLM tasks. In particular, we present three\ntechnical improvements on the plain baseline. First, we design a learnable\nupsampling module to refine visual token features. Secondly, we propose a novel\nvisual prompt injection strategy to enable the single transformer to understand\nvisual prompt inputs and benefit from the early fusion of visual prompt\nembeddings and vision tokens. Thirdly, we introduce a vision expert\ndistillation strategy to efficiently enhance the single transformer's\nfine-grained feature extraction capability. In addition, we have collected a\ncomprehensive pixel understanding benchmark (PerBench), using a manual check.\nIt includes three tasks: detailed object description, visual prompt-based\nquestion answering, and visual-text referring segmentation. Extensive\nexperiments on four referring segmentation benchmarks, one visual prompt\nbenchmark, and our PerBench show that our Pixel-SAIL achieves comparable or\neven better results with a much simpler pipeline. Code and model will be\nreleased at https://github.com/magic-research/Sa2VA.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T17:52:22Z"}
{"aid":"http://arxiv.org/abs/2504.10840v1","title":"XRD study of the magnetization plateau above 40 T in the frustrated\n  helimagnet CuGaCr$_{4}$S$_{8}$","summary":"CuGaCr$_{4}$S$_{8}$, which contains a chromium breathing pyrochlore network,\nexhibits diverse magnetic phases, including an incommensurate helical state\nbelow 31 K and a 1/2-magnetization plateau above 40 T, owing to the interplay\nbetween magnetic frustration and spin-lattice coupling. Here, we perform a\nsingle-shot powder x-ray diffraction experiment on CuGaCr$_{4}$S$_{8}$ in a\npulsed high magnetic field of 55 T, revealing an orthorhombic-to-cubic (or\npseudocubic) structural transition upon entering the 1/2-magnetization plateau\nphase at low temperatures. This observation suggests the emergence of a\ncommensurate ferrimagnetic order, where a 3-up-1-down spin configuration is\nrealized in each small tetrahedron, and the all-up or all-down in each large\ntetrahedron. We propose two types of 16-sublattice magnetic structures, which\nare degenerate within exchange interactions between the first, second, and\nthird nearest neighbors.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-04-15T03:55:12Z"}
{"aid":"http://arxiv.org/abs/2504.10852v1","title":"Enhancing Features in Long-tailed Data Using Large Vision Mode","summary":"Language-based foundation models, such as large language models (LLMs) or\nlarge vision-language models (LVLMs), have been widely studied in long-tailed\nrecognition. However, the need for linguistic data is not applicable to all\npractical tasks. In this study, we aim to explore using large vision models\n(LVMs) or visual foundation models (VFMs) to enhance long-tailed data features\nwithout any language information. Specifically, we extract features from the\nLVM and fuse them with features in the baseline network's map and latent space\nto obtain the augmented features. Moreover, we design several prototype-based\nlosses in the latent space to further exploit the potential of the augmented\nfeatures. In the experimental section, we validate our approach on two\nbenchmark datasets: ImageNet-LT and iNaturalist2018.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T04:21:50Z"}
{"aid":"http://arxiv.org/abs/2504.10866v1","title":"Gaussian Approximation for High-Dimensional $U$-statistics with\n  Size-Dependent Kernels","summary":"Motivated by small bandwidth asymptotics for kernel-based semiparametric\nestimators in econometrics, this paper establishes Gaussian approximation\nresults for high-dimensional fixed-order $U$-statistics whose kernels depend on\nthe sample size. Our results allow for a situation where the dominant component\nof the Hoeffding decomposition is absent or unknown, including cases with known\ndegrees of degeneracy as special forms. The obtained error bounds for Gaussian\napproximations are sharp enough to almost recover the weakest bandwidth\ncondition of small bandwidth asymptotics in the fixed-dimensional setting when\napplied to a canonical semiparametric estimation problem. We also present an\napplication to an adaptive goodness-of-fit testing, along with discussions\nabout several potential applications.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-15T04:58:58Z"}
{"aid":"http://arxiv.org/abs/2504.10872v1","title":"Design and Fabrication of a lightweight three-lens corrector system for\n  the 2.34-m Vainu Bappu Telescope","summary":"The Vainu Bappu Telescope (VBT) is a 2.34-m reflector, primarily supported\non-axis field of view, offering high-resolution and low-to-medium resolution\nspectroscopic observations in its prime and Cassegrain configurations. This\nstudy presents the design and fabrication of a compact, lightweight,\nthree-element wide-field corrector (WFC) utilizing three spherical lenses to\ncover a polychromatic wavelength range over a 30$'$ FoV at prime focus. The WFC\ndesign was optimized using ZEMAX, ensuring precision in aberrations,\ntolerances, and atmospheric dispersion. The fabricated lenses met stringent\ntolerances, with a $\\pm$1 mm deviation in radius of curvature and 2 mm\ndeviation in center thickness. A mechanical mount was developed to integrate\nall the WFC lenses, and wavefront error testing for the WFC system was\nperformed using ZYGO interferometry, yielding a Wavefront Error of 0.05\n$\\lambda$. Laboratory performance tests were designed and conducted using a\ndedicated setup with achromatic lenses and 100 $\\mu m$ fiber-coupled\npolychromatic light source showed a deviation of 0.1 pixel on-axis and 0.5\npixel at the extreme off-axis field compared to the ZEMAX design, demonstrating\nthat the optical performance of WFC is with minimal aberrations across the\nentire FoV. The successful integration of the WFC at the VBT prime focus will\nincrease the FoV, enabling the multi-fiber, multi-spectrograph setup in 30\narcmin field that will facilitate both OMR and Echelle spectrograph to be used\non the same night along with the addition of new multi-object spectrograph and\nan integral field unit instrument. This will mark a significant upgrade for the\nVBT, broadening its research potential, and expanding its observational\nversatility.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-15T05:03:00Z"}
{"aid":"http://arxiv.org/abs/2504.10887v1","title":"Fisher information approximation of random orthogonal matrices by\n  Gaussian matrices","summary":"Let ${\\Gamma}_n$ be an $n\\times n$ Haar-invariant orthogonal matrix. Let ${\nZ}_n$ be the $p\\times q$ upper-left submatrix of ${\\Gamma}_n$ and ${G}_n$ be a\n$p\\times q$ matrix whose $pq$ entries are independent standard normals, where\n$p$ and $q$ are two positive integers. Let $\\mathcal{L}(\\sqrt{n} {Z}_n)$ and\n$\\mathcal{L}({G}_n)$ be their joint distribution, respectively. Consider the\nFisher information $I(\\mathcal{L}(\\sqrt{n} { Z}_n)|\\mathcal{L}(G_n))$ between\nthe distributions of $\\sqrt{n} {Z}_n$ and ${ G}_n.$ In this paper, we conclude\nthat $$I(\\mathcal{L}(\\sqrt{n} {Z}_n)|\\mathcal{L}(G_n))\\longrightarrow 0 $$ as\n$n\\to\\infty$ if $pq=o(n)$ and it does not tend to zero if\n$c=\\lim\\limits_{n\\to\\infty}\\frac{pq}{n}\\in(0, +\\infty).$ Precisely, we obtain\nthat $$I(\\mathcal{L}(\\sqrt{n}\n{Z}_n)|\\mathcal{L}(G_n))=\\frac{p^2q(q+1)}{4n^2}(1+o(1))$$ when $p=o(n).$","main_category":"math.PR","categories":"math.PR","published":"2025-04-15T05:38:13Z"}
{"aid":"http://arxiv.org/abs/2504.10894v1","title":"Infinite temperature spin dynamics in the asymmetric Hatsugai-Kohmoto\n  model","summary":"We focus on the infinite temperature dynamical spin structure factor of the\nasymmetric Hatsugai-Kohmoto model, the relative of the asymmetric Hubbard\nmodel. It is characterized by distinct single particle energies for the two\nspin species, which interact with each other through a contact interaction in\nmomentum space. We evaluate its spin structure factor exactly and follow the\nevolution of its excitation spectrum for all fillings and interactions,\nidentify signatures of the Mott transition and fingerprints of the asymmetric\nhoppings. The longitudinal spin structure factor exhibits sound like and\ninteraction induced gapped excitations, whose number gets doubled in the\npresence of hopping asymmetry. The transverse response displays the competition\nof interaction and asymmetry induced gaps and results in a quadratic excitation\nbranch at their transition. The complete asymmetric case features\nmomentum-independent dynamical structure factor, characteristic to transitions\ninvolving a flat band.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.stat-mech","published":"2025-04-15T06:10:02Z"}
{"aid":"http://arxiv.org/abs/2504.10939v1","title":"Formation of Ba stars : impact of wind Roche lobe overflow and\n  circumbinary disk in shaping the orbital parameters","summary":"After more than three decades of investigation, the distribution of Ba stars\nin the e-log P diagram still defies our understanding. Recent smooth particle\nhydrodynamic simulations involving an asymptotic giant branch (AGB) primary\nhave shown that a circumbinary disk (CB) can form around the binary and that\nthe presence of dust in the wind of evolved low- and intermediate-mass stars\ncan significantly affect the systemic angular momentum loss and mass accretion\nonto the companion through the wind Roche lobe overflow (WRLOF) phase. We used\nthe binary evolution code BINSTAR, where we updated the modeling of the\nprogenitors of Ba stars including a CB disk, the WRLOF, tidally enhanced wind\nmass loss, and non-conservative RLOF with their effects on the orbital\nevolution. In our approach, we considered that a CB disk forms when WRLOF is\nactivated. The coupling between the CB disk and the binary follows the standard\nresonant interaction theory. We constructed grids of 2.0 + 1.0 $M_\\odot{}$ and\n1.2 + 0.8 $M_\\odot{}$ binaries for initial orbital parameters that result in\nWRLOF, and evolved these systems until the end of the primary's AGB phase.\nWRLOF resulted in a significant shrinkage of the orbital separation during the\nAGB phase, leading to binaries with initial periods on the order of $\\lesssim\n12000$ d undergoing Roche lobe overflow (RLOF). The combination of WRLOF,\neccentricity pumping from the CB disk, and/or tidally enhanced wind mass loss\ncan lead to RLOF on eccentric orbits down to periods of $P_\\mathrm{orb} \\sim\n3000$d. Non-conservative RLOF enabled a reduction of the period before\ncircularization down to $\\sim 2000$d, provided at least 50 percent of the\ntransferred mass left the system. Our models still cannot account for the\neccentricity distribution of Ba stars with periods shorter than $P_\\mathrm{orb}\n\\lesssim 2000$d, where a common envelope evolution appears unavoidable.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-15T07:39:51Z"}
{"aid":"http://arxiv.org/abs/2504.10954v1","title":"Offset-free Nonlinear MPC with Koopman-based Surrogate Models","summary":"In this paper, we design offset-free nonlinear Model Predictive Control (MPC)\nfor surrogate models based on Extended Dynamic Mode Decomposition (EDMD). The\nmodel used for prediction in MPC is augmented with a disturbance term, that is\nestimated by an observer. If the full information about the equilibrium of the\nreal system is not available, a reference calculator is introduced in the\nalgorithm to compute the MPC state and input references. The control algorithm\nguarantees offset-free tracking of the controlled output under the assumption\nthat the modeling errors are asymptotically constant. The effectiveness of the\nproposed approach is showcased with numerical simulations for two popular\nbenchmark systems: the van-der-Pol oscillator and the four-tanks process.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-15T08:00:15Z"}
{"aid":"http://arxiv.org/abs/2504.10967v1","title":"An Efficient and Mixed Heterogeneous Model for Image Restoration","summary":"Image restoration~(IR), as a fundamental multimedia data processing task, has\na significant impact on downstream visual applications. In recent years,\nresearchers have focused on developing general-purpose IR models capable of\nhandling diverse degradation types, thereby reducing the cost and complexity of\nmodel development. Current mainstream approaches are based on three\narchitectural paradigms: CNNs, Transformers, and Mambas. CNNs excel in\nefficient inference, whereas Transformers and Mamba excel at capturing\nlong-range dependencies and modeling global contexts. While each architecture\nhas demonstrated success in specialized, single-task settings, limited efforts\nhave been made to effectively integrate heterogeneous architectures to jointly\naddress diverse IR challenges. To bridge this gap, we propose RestorMixer, an\nefficient and general-purpose IR model based on mixed-architecture fusion.\nRestorMixer adopts a three-stage encoder-decoder structure, where each stage is\ntailored to the resolution and feature characteristics of the input. In the\ninitial high-resolution stage, CNN-based blocks are employed to rapidly extract\nshallow local features. In the subsequent stages, we integrate a refined\nmulti-directional scanning Mamba module with a multi-scale window-based\nself-attention mechanism. This hierarchical and adaptive design enables the\nmodel to leverage the strengths of CNNs in local feature extraction, Mamba in\nglobal context modeling, and attention mechanisms in dynamic feature\nrefinement. Extensive experimental results demonstrate that RestorMixer\nachieves leading performance across multiple IR tasks while maintaining high\ninference efficiency. The official code can be accessed at\nhttps://github.com/ClimBin/RestorMixer.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T08:19:12Z"}
{"aid":"http://arxiv.org/abs/2504.10982v1","title":"Exploring the Role of KG-Based RAG in Japanese Medical Question\n  Answering with Small-Scale LLMs","summary":"Large language models (LLMs) perform well in medical QA, but their\neffectiveness in Japanese contexts is limited due to privacy constraints that\nprevent the use of commercial models like GPT-4 in clinical settings. As a\nresult, recent efforts focus on instruction-tuning open-source LLMs, though the\npotential of combining them with retrieval-augmented generation (RAG) remains\nunderexplored. To bridge this gap, we are the first to explore a knowledge\ngraph-based (KG) RAG framework for Japanese medical QA small-scale open-source\nLLMs. Experimental results show that KG-based RAG has only a limited impact on\nJapanese medical QA using small-scale open-source LLMs. Further case studies\nreveal that the effectiveness of the RAG is sensitive to the quality and\nrelevance of the external retrieved content. These findings offer valuable\ninsights into the challenges and potential of applying RAG in Japanese medical\nQA, while also serving as a reference for other low-resource languages.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-15T08:46:39Z"}
{"aid":"http://arxiv.org/abs/2504.11015v1","title":"AnimeDL-2M: Million-Scale AI-Generated Anime Image Detection and\n  Localization in Diffusion Era","summary":"Recent advances in image generation, particularly diffusion models, have\nsignificantly lowered the barrier for creating sophisticated forgeries, making\nimage manipulation detection and localization (IMDL) increasingly challenging.\nWhile prior work in IMDL has focused largely on natural images, the anime\ndomain remains underexplored-despite its growing vulnerability to AI-generated\nforgeries. Misrepresentations of AI-generated images as hand-drawn artwork,\ncopyright violations, and inappropriate content modifications pose serious\nthreats to the anime community and industry. To address this gap, we propose\nAnimeDL-2M, the first large-scale benchmark for anime IMDL with comprehensive\nannotations. It comprises over two million images including real, partially\nmanipulated, and fully AI-generated samples. Experiments indicate that models\ntrained on existing IMDL datasets of natural images perform poorly when applied\nto anime images, highlighting a clear domain gap between anime and natural\nimages. To better handle IMDL tasks in anime domain, we further propose\nAniXplore, a novel model tailored to the visual characteristics of anime\nimagery. Extensive evaluations demonstrate that AniXplore achieves superior\nperformance compared to existing methods. Dataset and code can be found in\nhttps://flytweety.github.io/AnimeDL2M/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T09:41:08Z"}
{"aid":"http://arxiv.org/abs/2504.11018v1","title":"Cavity cooling using ultrafast electrons","summary":"We propose a method to cool a thermal photonic state in a cavity by passing\nelectrons through it. Electrons are coherently split into two paths, with one\npath traversing the cavity, becoming entangled with its photonic state. A\nsequence of such entanglement interactions can achieve cooling of the cavity:\ne.g., a twofold reduction in thermal photon number with a 25% post-selection\nprobability. This ``which-path''-based approach extends to other qubit\noscillator systems, such as phonons in crystals or optomechanical resonators,\noffering a general framework for quantum oscillator cooling.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T09:41:43Z"}
{"aid":"http://arxiv.org/abs/2504.11031v1","title":"Acquisition of high-quality images for camera calibration in robotics\n  applications via speech prompts","summary":"Accurate intrinsic and extrinsic camera calibration can be an important\nprerequisite for robotic applications that rely on vision as input. While there\nis ongoing research on enabling camera calibration using natural images, many\nsystems in practice still rely on using designated calibration targets with\ne.g. checkerboard patterns or April tag grids. Once calibration images from\ndifferent perspectives have been acquired and feature descriptors detected,\nthose are typically used in an optimization process to minimize the geometric\nreprojection error. For this optimization to converge, input images need to be\nof sufficient quality and particularly sharpness; they should neither contain\nmotion blur nor rolling-shutter artifacts that can arise when the calibration\nboard was not static during image capture. In this work, we present a novel\ncalibration image acquisition technique controlled via voice commands recorded\nwith a clip-on microphone, that can be more robust and user-friendly than e.g.\ntriggering capture with a remote control, or filtering out blurry frames from a\nvideo sequence in postprocessing. To achieve this, we use a state-of-the-art\nspeech-to-text transcription model with accurate per-word timestamping to\ncapture trigger words with precise temporal alignment. Our experiments show\nthat the proposed method improves user experience by being fast and efficient,\nallowing us to successfully calibrate complex multi-camera setups.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-15T09:54:43Z"}
{"aid":"http://arxiv.org/abs/2504.11049v1","title":"A quantum algorithm for estimating the determinant","summary":"We present a quantum algorithm for estimating the matrix determinant based on\nquantum spectral sampling. The algorithm estimates the logarithm of the\ndeterminant of an $n \\times n$ positive sparse matrix to an accuracy $\\epsilon$\nin time ${\\cal O}(\\log n/\\epsilon^3)$, exponentially faster than previously\nexisting classical or quantum algorithms that scale linearly in $n$. The\nquantum spectral sampling algorithm generalizes to estimating any quantity\n$\\sum_j f(\\lambda_j)$, where $\\lambda_j$ are the matrix eigenvalues. For\nexample, the algorithm allows the efficient estimation of the partition\nfunction $Z(\\beta) =\\sum_j e^{-\\beta E_j}$ of a Hamiltonian system with energy\neigenvalues $E_j$, and of the entropy $ S =-\\sum_j p_j \\log p_j$ of a density\nmatrix with eigenvalues $p_j$.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T10:32:36Z"}
{"aid":"http://arxiv.org/abs/2504.11054v1","title":"Zero-Shot Whole-Body Humanoid Control via Behavioral Foundation Models","summary":"Unsupervised reinforcement learning (RL) aims at pre-training agents that can\nsolve a wide range of downstream tasks in complex environments. Despite recent\nadvancements, existing approaches suffer from several limitations: they may\nrequire running an RL process on each downstream task to achieve a satisfactory\nperformance, they may need access to datasets with good coverage or\nwell-curated task-specific samples, or they may pre-train policies with\nunsupervised losses that are poorly correlated with the downstream tasks of\ninterest. In this paper, we introduce a novel algorithm regularizing\nunsupervised RL towards imitating trajectories from unlabeled behavior\ndatasets. The key technical novelty of our method, called Forward-Backward\nRepresentations with Conditional-Policy Regularization, is to train\nforward-backward representations to embed the unlabeled trajectories to the\nsame latent space used to represent states, rewards, and policies, and use a\nlatent-conditional discriminator to encourage policies to ``cover'' the states\nin the unlabeled behavior dataset. As a result, we can learn policies that are\nwell aligned with the behaviors in the dataset, while retaining zero-shot\ngeneralization capabilities for reward-based and imitation tasks. We\ndemonstrate the effectiveness of this new approach in a challenging humanoid\ncontrol problem: leveraging observation-only motion capture datasets, we train\nMeta Motivo, the first humanoid behavioral foundation model that can be\nprompted to solve a variety of whole-body tasks, including motion tracking,\ngoal reaching, and reward optimization. The resulting model is capable of\nexpressing human-like behaviors and it achieves competitive performance with\ntask-specific methods while outperforming state-of-the-art unsupervised RL and\nmodel-based baselines.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-15T10:41:11Z"}
{"aid":"http://arxiv.org/abs/2504.11074v1","title":"Dynamical errors in machine learning forecasts","summary":"In machine learning forecasting, standard error metrics such as mean absolute\nerror (MAE) and mean squared error (MSE) quantify discrepancies between\npredictions and target values. However, these metrics do not directly evaluate\nthe physical and/or dynamical consistency of forecasts, an increasingly\ncritical concern in scientific and engineering applications.\n  Indeed, a fundamental yet often overlooked question is whether machine\nlearning forecasts preserve the dynamical behavior of the underlying system.\nAddressing this issue is essential for assessing the fidelity of machine\nlearning models and identifying potential failure modes, particularly in\napplications where maintaining correct dynamical behavior is crucial.\n  In this work, we investigate the relationship between standard forecasting\nerror metrics, such as MAE and MSE, and the dynamical properties of the\nunderlying system. To achieve this goal, we use two recently developed\ndynamical indices: the instantaneous dimension ($d$), and the inverse\npersistence ($\\theta$). Our results indicate that larger forecast errors --\ne.g., higher MSE -- tend to occur in states with higher $d$ (higher complexity)\nand higher $\\theta$ (lower persistence). To further assess dynamical\nconsistency, we propose error metrics based on the dynamical indices that\nmeasure the discrepancy of the forecasted $d$ and $\\theta$ versus their correct\nvalues. Leveraging these dynamical indices-based metrics, we analyze direct and\nrecursive forecasting strategies for three canonical datasets -- Lorenz,\nKuramoto-Sivashinsky equation, and Kolmogorov flow -- as well as a real-world\nweather forecasting task. Our findings reveal substantial distortions in\ndynamical properties in ML forecasts, especially for long forecast lead times\nor long recursive simulations, providing complementary information on ML\nforecast fidelity that can be used to improve ML models.","main_category":"cs.LG","categories":"cs.LG,cs.AI,physics.comp-ph","published":"2025-04-15T11:16:13Z"}
{"aid":"http://arxiv.org/abs/2504.11093v1","title":"Interstellar scintillation of sources B0821+394 and B1812+412 as\n  observed by the LPA LPI radio telescope","summary":"The search for long-term variability of compact components of radio sources\nB0821+394 and B1812+412 over an interval of 10 years was carried out. The LPA\nLPI radio telescope with an operating frequency of 111 MHz was used for\nobservations. According to our estimates, the characteristic time of\nvariability for both sources is 1.5-2.5 years. It is shown that the observed\nvariability is not related to intrinsic variations in the radiation flux, but\nis due to refractive scintillation on inhomogeneities of the interstellar\nmedium. From the obtained upper estimates of the apparent angular dimensions of\nthe sources, it follows that the main contribution to the scattering of radio\nemission is made by turbulent plasma concentrated in sufficiently thin screens,\nthe distance to which does not exceed 300-400 pc.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-15T11:39:44Z"}
{"aid":"http://arxiv.org/abs/2504.11097v1","title":"Steering Feedback in Dynamic Driving Simulators: Road-Induced and\n  Non-Road-Induced Harshness","summary":"Steering feedback plays a substantial role in the validity of driving\nsimulators for the virtual development of modern vehicles. Established\nobjective steering characteristics typically assess the feedback behavior in\nthe frequency range of up to 30 Hz while factors such as steering wheel and\nvehicle body vibrations at higher frequencies are mainly approached as comfort\nissues. This work investigates the influence of steering wheel and vehicle body\nexcitations in the frequency range between 30 and 100 Hz on the subjective\nevaluation of steering feedback in a dynamic driving simulator. A controlled\nsubject study with 42 participants was performed to compare a reference vehicle\nwith an electrical power steering system to four variants of its virtual\nrepresentation on a dynamic driving simulator. The effects of road-induced\nexcitations were investigated by comparing a semi-empirical and a physics-based\ntire model, while the influence of non-road-induced excitations was\ninvestigated by implementing engine and wheel orders. The simulator variants\nwere evaluated in comparison to the reference vehicle during closed-loop\ndriving on a country road in a single-blind within-subjects design. The\nsubjective evaluation focused on the perception of road feedback compared to\nthe reference vehicle. The statistical analysis of subjective results shows\nthat there is a strong effect of non-road-induced steering and vehicle body\nexcitations, while the effect of road-induced excitations is considerably less\npronounced.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-15T11:42:55Z"}
{"aid":"http://arxiv.org/abs/2504.11100v1","title":"Uncertainty modeling method for wind and solar power output in building\n  integrated energy systems under continuous anomalous weather","summary":"The increasing occurrence of continuous anomalous weather events has\nintensified the uncertainty in wind and photovoltaic power generation, posing\nsignificant challenges to the operation and optimization of building integrated\nenergy systems. Existing studies often neglect the interdependence between\nsuccessive anomalous weather events and their collective impact on wind and\nsolar power output. Additionally, conventional modeling approaches struggle to\naccurately capture the nonlinear fluctuations induced by these weather\nconditions. To address this gap, this study proposes an uncertainty modeling\nmethod based on stochastic optimization and scenario generation. The Weibull\nand Beta distributions characterize the probabilistic properties of wind speed\nand solar irradiance, respectively, while the Copula function captures the\ndependence between wind speed and precipitation, enabling the construction of a\nwind-solar power uncertainty model that incorporates the joint distribution of\nconsecutive anomalous weather events. A Monte Carlo-based scenario generation\napproach is employed to construct a dataset representing anomalous weather\ncharacteristics, followed by a probabilistic distance-based scenario reduction\ntechnique to enhance modeling efficiency. Furthermore, the unscented\ntransformation method is introduced to mitigate nonlinear propagation errors in\nwind and solar power state estimation. Case studies demonstrate that the\nproposed method effectively characterizes the fluctuation patterns of wind and\nsolar power under continuous anomalous weather conditions while preserving the\nstatistical properties of the original data. These findings provide a reliable\nbasis for improving the operational resilience of building integrated energy\nsystems under extreme weather scenarios.","main_category":"math.OC","categories":"math.OC","published":"2025-04-15T11:48:55Z"}
{"aid":"http://arxiv.org/abs/2504.11129v1","title":"$R$-matrix type parametrization of the Jost function for extracting the\n  resonance parameters from scattering data","summary":"A new method is proposed for fitting non-relativistic binary-scattering data\nand for extracting the parameters of possible quantum resonances in the\ncompound system that is formed during the collision. The method combines the\nwell-known $R$-matrix approach with the analysis based on the semi-analytic\nrepresentation of the Jost functions. It is shown that such a combination has\nthe advantages of both these approaches, namely, the number of the fitting\nparameters remains relatively small (as for the $R$-matrix approach) and the\nproper analytic structure of the $S$-matrix is preserved (as for the Jost\nfunction method). It is also shown that the new formalism, although closely\nrelated to the $R$-matrix method, has the benefit of no dependence on an\narbitrary channel radius. The efficiency and accuracy of the proposed method\nare tested using a model single-channel potential. Artificial ``experimental''\ndata generated with this potential are fitted, and its known resonances are\nsuccessfully recovered as zeros of the Jost function on the appropriate sheet\nof the Riemann surface of the energy.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T12:29:57Z"}
{"aid":"http://arxiv.org/abs/2504.11136v1","title":"Structure of some mapping spaces","summary":"We prove that the path space of a differentiable manifold is diffeomorphic to\na Fr\\'echet space, endowing the path space with a linear structure.\nFurthermore, the base point preserving mapping space consisting of maps from a\ncube to a differentiable manifold is also diffeomorphic to a Fr\\'echet space.\nAs a corollary of a more general theorem, we prove that the path fibration\nbecomes a fibre bundle for manifolds M. Additionally, we discuss the mapping\nspace from a compact topological space to a differentiable manifold,\ndemonstrating that this space admits the structure of a smooth Banach manifold.","main_category":"math.DG","categories":"math.DG","published":"2025-04-15T12:39:17Z"}
{"aid":"http://arxiv.org/abs/2504.11148v1","title":"Super time-resolved tomography","summary":"Understanding 3D fundamental processes is crucial for academic and industrial\napplications. Nowadays, X-ray time-resolved tomography, or tomoscopy, is a\nleading technique for in-situ and operando 4D (3D+time) characterization.\nDespite its ability to achieve 1000 tomograms per second at large-scale X-ray\nfacilities, its applicability is limited by the centrifugal forces exerted on\nsamples and the challenges of developing suitable environments for such\nhigh-speed studies. Here, we introduce STRT, an approach that has the potential\nto enhance the temporal resolution of tomoscopy by at least an order of\nmagnitude while preserving spatial resolution. STRT exploits a 4D DL\nreconstruction algorithm to produce high-fidelity 3D reconstructions at each\ntime point, retrieved from a significantly reduced angular range of a few\ndegrees compared to the 0-180 degrees of traditional tomoscopy. Thus, STRT\nenhances the temporal resolution compared to tomoscopy by a factor equal to the\nratio between 180 degrees and the angular ranges used by STRT. In this work, we\nvalidate the 4D capabilities of STRT through simulations and experiments on\ndroplet collision simulations and additive manufacturing processes. We\nanticipate that STRT will significantly expand the capabilities of 4D X-ray\nimaging, enabling previously unattainable studies in both academic and\nindustrial contexts, such as materials formation and mechanical testing.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-15T12:49:19Z"}
{"aid":"http://arxiv.org/abs/2504.11151v1","title":"Magnetic uniform resolvent estimates","summary":"We establish uniform $L^{p}-L^{q}$ resolvent estimates for magnetic\nSchr\\\"odinger operators $H=(i\\partial+A(x))^2+V(x)$ in dimension $n \\geq 3$.\nUnder suitable decay conditions on the electromagnetic potentials, we prove\nthat for all $z \\in \\mathbb{C}\\setminus[0,+\\infty)$ with $|\\Im z| \\leq 1$, the\nresolvent satisfies \\begin{equation*}\n\\|(H-z)^{-1}\\phi\\|_{L^{q}}\\lesssim|z|^{\\theta(p,q)} (1+|z|^{\\frac 12\n\\frac{n-1}{n+1}}) \\|\\phi\\|_{L^{p}} \\end{equation*} where\n$\\theta(p,q)=\\frac{n}{2}(\\frac{1}{p}-\\frac{1}{q})-1$. This extends previous\nresults by providing estimates valid for all frequencies with explicit\ndependence on $z$, covering the same optimal range of indices as the free\nLaplacian case, and including weak endpoint estimates. We also derive a variant\nwith less stringent decay assumptions when restricted to a smaller parameter\nrange. As an application, we establish the first $L^p-L^{p'}$ bounds for the\nspectral measure of magnetic Schr\\\"odinger operators.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP","published":"2025-04-15T12:53:09Z"}
{"aid":"http://arxiv.org/abs/2504.11166v1","title":"Adjustable Molecular Cross-Linkage of MXene Layers for Tunable Charge\n  Transport and VOC Sensing","summary":"MXenes, two-dimensional transition metal carbides, nitrides or carbonitrides,\nare emerging as highly promising materials due to their remarkable charge\ntransport characteristics and their versatile surface chemistry. Herein, we\ndemonstrate the tunability of interfaces and the inter-layer spacing between\nTi$_3$C$_2$T$_X$ MXene flakes through molecular cross-linking via ligand\nexchange with homologous diamines. Oleylamine was initially introduced as a\nligand, to facilitate the delamination and stable dispersion of pristine\nTi$_3$C$_2$T$_X$ flakes in chloroform. Subsequently, controlled cross-linkage\nof the flakes was achieved using diamine ligands with varying aliphatic chain\nlengths, enabling the precise tuning of the inter-layer spacing. Grazing\nincidence X-ray scattering (GIXRD / GIWAXS) confirmed the correlation between\nligand chain length and inter-layer spacing, which was further supported by\nDensity Functional Theory (DFT) calculations. Furthermore, we investigated the\ncharge transport properties of thin films consisting of these diamine\ncross-linked MXenes and observed a strong dependence of the conductivity on the\ninterlayer spacing. Finally, we probed chemiresistive vapor sensing properties\nof the MXene composites and observed a pronounced sensitivity and selectivity\ntowards water vapor, highlighting their potential for use in humidity sensors.\nProviding significant insights into molecular cross-linking of MXenes to form\nhybrid inorganic/organic composites and its consequences for charge transport,\nthis study opens avenues for the development of next-generation MXene-based\nelectronic devices.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-15T13:14:32Z"}
{"aid":"http://arxiv.org/abs/2504.11211v1","title":"Instability of the Standing Pulse in Skew-Gradient Systems and Its\n  Application to FitzHugh-Nagumo Type Systems","summary":"In this paper, we use the Maslov index to obtain a lower bound on the number\nof unstable eigenvalues associated with standing pulse solutions in\nskew-gradient systems. Based on this, we establish an instability criterion for\nthe standing pulse. As an application, the results are applied to\nFitzHugh-Nagumo type systems, in which the activator and inhibitor reaction\nterms exhibit inherent nonlinear structures.","main_category":"math.AP","categories":"math.AP,math.DS","published":"2025-04-15T14:13:21Z"}
{"aid":"http://arxiv.org/abs/2504.11244v1","title":"Multireference covariant density functional theory for shape coexistence\n  and isomerism in $^{43}$S","summary":"We extend the multireference covariant density functional theory (MR-CDFT) to\ndescribe the low-lying states of the odd-mass nucleus $^{43}$S near the neutron\nmagic number $N=28$ with shape coexistence. The wave functions of the low-lying\nstates are constructed as superpositions of configurations with different\nintrinsic shapes and $K$ quantum numbers, projected onto good particle numbers\nand angular momenta. The MR-CDFT successfully reproduces the main features of\nthe low-energy structure in $^{43}$S. Our results indicate that the ground\nstate, $3/2^-_1$, is predominantly composed of the intruder prolate\none-quasiparticle (1qp) configuration $\\nu1/2^-[321]$. In contrast, the\n$7/2^-_1$ state is identified as a high-$K$ isomer, primarily built on the\nprolate 1qp configuration $\\nu7/2^-[303]$. Additionally, the $3/2^-_2$ state is\nfound to be an admixture dominated by an oblate configuration with $K^\\pi =\n1/2^-$, along with a small contribution from a prolate configuration with\n$K^\\pi = 3/2^-$. These results demonstrate the capability of MR-CDFT to capture\nthe intricate interplay among shape coexistence, $K$-mixing, and isomerism in\nthe low-energy structure of odd-mass nuclei around $N = 28$.","main_category":"nucl-th","categories":"nucl-th,nucl-ex","published":"2025-04-15T14:43:48Z"}
{"aid":"http://arxiv.org/abs/2504.11251v1","title":"Easy repair via codes with simplex locality","summary":"In the context of distributed storage systems, locally repairable codes have\nbecome important. In this paper we focus on codes that allow for multi-erasure\npattern decoding with low computational effort. Different optimality\nrequirements, measured by the code's rate, minimum distance, locality,\navailability as well as field size, influence each other and can not all be\nmaximized at the same time. We focus on the notion of easy repair, more\nspecifically on the construction of codes that can repair correctable erasure\npatterns with minimal computational effort. In particular, we introduce the\neasy repair property and then present codes of different rates that possess\nthis property. The presented codes are all in some way related to simplex codes\nand comprise block codes as well as unit-memory convolutional codes. We also\nformulate conditions under which the easy repairs can be performed in parallel,\nthus improving access speed of the distributed storage system.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-15T14:47:22Z"}
{"aid":"http://arxiv.org/abs/2504.11256v1","title":"Covering Approximate Shortest Paths with DAGs","summary":"We define and study analogs of probabilistic tree embedding and tree cover\nfor directed graphs. We define the notion of a DAG cover of a general directed\ngraph $G$: a small collection $D_1,\\dots D_g$ of DAGs so that for all pairs of\nvertices $s,t$, some DAG $D_i$ provides low distortion for $dist(s,t)$; i.e. $\ndist_G(s, t) \\le \\min_{i \\in [g]} dist_{D_i}(s, t) \\leq \\alpha \\cdot dist_G(s,\nt)$, where $\\alpha$ is the distortion.\n  As a trivial upper bound, there is a DAG cover with $n$ DAGs and $\\alpha=1$\nby taking the shortest-paths tree from each vertex. When each DAG is restricted\nto be a subgraph of $G$, there is a matching lower bound (via a directed cycle)\nthat $n$ DAGs are necessary, even to preserve reachability. Thus, we allow the\nDAGs to include a limited number of additional edges not in the original graph.\n  When $n^2$ additional edges are allowed, there is a simple upper bound of two\nDAGs and $\\alpha=1$. Our first result is an almost-matching lower bound that\neven for $n^{2-o(1)}$ additional edges, at least $n^{1-o(1)}$ DAGs are needed,\neven to preserve reachability. However, the story is different when the number\nof additional edges is $\\tilde{O}(m)$, a natural setting where the sparsity of\nthe DAG collection nearly matches the original graph. Our main upper bound is\nthat there is a near-linear time algorithm to construct a DAG cover with\n$\\tilde{O}(m)$ additional edges, polylogarithmic distortion, and only $O(\\log\nn)$ DAGs. This is similar to known results for undirected graphs: the\nwell-known FRT probabilistic tree embedding implies a tree cover where both the\nnumber of trees and the distortion are logarithmic. Our algorithm also extends\nto a certain probabilistic embedding guarantee. Lastly, we complement our upper\nbound with a lower bound showing that achieving a DAG cover with no distortion\nand $\\tilde{O}(m)$ additional edges requires a polynomial number of DAGs.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-15T14:55:26Z"}
{"aid":"http://arxiv.org/abs/2504.11273v1","title":"Hybrid Compton-PET Imaging for ion-range verification:A Preclinical\n  Study for Proton-, Helium-, and Carbon-Therapy at HIT","summary":"Enhanced-accuracy ion-range verification in real time shall enable a\nsignificant step forward in the use of therapeutic ion beams. Positron-emission\ntomography (PET) and prompt-gamma imaging (PGI) are two of the most promising\nand researched methodologies, both of them with their own advantages and\nchallenges. Thus far, both of them have been explored for ion-range\nverification in an independent way. However, the simultaneous combination of\nPET and PGI within the same imaging framework may open-up the possibility to\nexploit more efficiently all radiative emissions excited in the tissue by the\nion beam. Here we report on the first pre-clinical implementation of an hybrid\nPET-PGI imaging system, hereby exploring its performance over several ion-beam\nspecies (H, He and C), energies (55 MeV to 275 MeV) and intensities\n(10$^7$-10$^9$ ions/spot), which are representative of clinical conditions. The\nmeasurements were carried out using the pencil-beam scanning technique at the\nsynchrotron accelerator of the Heavy Ion Therapy centre in Heidelberg utilizing\nan array of four Compton cameras in a twofold front-to-front configuration. The\nresults demonstrate that the hybrid PET-PGI technique can be well suited for\nrelatively low energies (55-155 MeV) and beams of protons. On the other hand,\nfor heavier beams of helium and carbon ions at higher energies (155-275 MeV),\nrange monitoring becomes more challenging owing to large backgrounds from\nadditional nuclear processes. The experimental results are well understood on\nthe basis of realistic Monte Carlo (MC) calculations, which show a satisfactory\nagreement with the measured data. This work can guide further upgrades of the\nhybrid PET-PGI system towards a clinical implementation of this innovative\ntechnique.","main_category":"physics.med-ph","categories":"physics.med-ph,physics.ins-det","published":"2025-04-15T15:14:28Z"}
{"aid":"http://arxiv.org/abs/2504.11278v1","title":"Towards dimensions and granularity in a unified workflow and data\n  provenance framework","summary":"Provenance information are essential for the traceability of scientific\nstudies or experiments and thus crucial for ensuring the credibility and\nreproducibility of research findings. This paper discusses a comprehensive\nprovenance framework combining the two types 1. workflow provenance, and 2.\ndata provenance as well as their dimensions and granularity, which enables the\nanswering of W7+1 provenance questions. We demonstrate the applicability by\nemploying a biomedical research use case, that can be easily transferred into\nother scientific fields. An integration of these concepts into a unified\nframework enables credibility and reproducibility of the research findings.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-15T15:18:22Z"}
{"aid":"http://arxiv.org/abs/2504.11280v1","title":"PGU-SGP: A Pheno-Geno Unified Surrogate Genetic Programming For\n  Real-life Container Terminal Truck Scheduling","summary":"Data-driven genetic programming (GP) has proven highly effective in solving\ncombinatorial optimization problems under dynamic and uncertain environments. A\ncentral challenge lies in fast fitness evaluations on large training datasets,\nespecially for complex real-world problems involving time-consuming\nsimulations. Surrogate models, like phenotypic characterization (PC)-based\nK-nearest neighbors (KNN), have been applied to reduce computational cost.\nHowever, the PC-based similarity measure is confined to behavioral\ncharacteristics, overlooking genotypic differences, which can limit surrogate\nquality and impair performance. To address these issues, this paper proposes a\npheno-geno unified surrogate GP algorithm, PGU-SGP, integrating phenotypic and\ngenotypic characterization (GC) to enhance surrogate sample selection and\nfitness prediction. A novel unified similarity metric combining PC and GC\ndistances is proposed, along with an effective and efficient GC representation.\nExperimental results of a real-life vehicle scheduling problem demonstrate that\nPGU-SGP reduces training time by approximately 76% while achieving comparable\nperformance to traditional GP. With the same training time, PGU-SGP\nsignificantly outperforms traditional GP and the state-of-the-art algorithm on\nmost datasets. Additionally, PGU-SGP shows faster convergence and improved\nsurrogate quality by maintaining accurate fitness rankings and appropriate\nselection pressure, further validating its effectiveness.","main_category":"cs.NE","categories":"cs.NE","published":"2025-04-15T15:19:42Z"}
{"aid":"http://arxiv.org/abs/2504.11289v1","title":"UniAnimate-DiT: Human Image Animation with Large-Scale Video Diffusion\n  Transformer","summary":"This report presents UniAnimate-DiT, an advanced project that leverages the\ncutting-edge and powerful capabilities of the open-source Wan2.1 model for\nconsistent human image animation. Specifically, to preserve the robust\ngenerative capabilities of the original Wan2.1 model, we implement Low-Rank\nAdaptation (LoRA) technique to fine-tune a minimal set of parameters,\nsignificantly reducing training memory overhead. A lightweight pose encoder\nconsisting of multiple stacked 3D convolutional layers is designed to encode\nmotion information of driving poses. Furthermore, we adopt a simple\nconcatenation operation to integrate the reference appearance into the model\nand incorporate the pose information of the reference image for enhanced pose\nalignment. Experimental results show that our approach achieves visually\nappearing and temporally consistent high-fidelity animations. Trained on 480p\n(832x480) videos, UniAnimate-DiT demonstrates strong generalization\ncapabilities to seamlessly upscale to 720P (1280x720) during inference. The\ntraining and inference code is publicly available at\nhttps://github.com/ali-vilab/UniAnimate-DiT.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T15:29:11Z"}
{"aid":"http://arxiv.org/abs/2504.11295v1","title":"Autoregressive Distillation of Diffusion Transformers","summary":"Diffusion models with transformer architectures have demonstrated promising\ncapabilities in generating high-fidelity images and scalability for high\nresolution. However, iterative sampling process required for synthesis is very\nresource-intensive. A line of work has focused on distilling solutions to\nprobability flow ODEs into few-step student models. Nevertheless, existing\nmethods have been limited by their reliance on the most recent denoised samples\nas input, rendering them susceptible to exposure bias. To address this\nlimitation, we propose AutoRegressive Distillation (ARD), a novel approach that\nleverages the historical trajectory of the ODE to predict future steps. ARD\noffers two key benefits: 1) it mitigates exposure bias by utilizing a predicted\nhistorical trajectory that is less susceptible to accumulated errors, and 2) it\nleverages the previous history of the ODE trajectory as a more effective source\nof coarse-grained information. ARD modifies the teacher transformer\narchitecture by adding token-wise time embedding to mark each input from the\ntrajectory history and employs a block-wise causal attention mask for training.\nFurthermore, incorporating historical inputs only in lower transformer layers\nenhances performance and efficiency. We validate the effectiveness of ARD in a\nclass-conditioned generation on ImageNet and T2I synthesis. Our model achieves\na $5\\times$ reduction in FID degradation compared to the baseline methods while\nrequiring only 1.1\\% extra FLOPs on ImageNet-256. Moreover, ARD reaches FID of\n1.84 on ImageNet-256 in merely 4 steps and outperforms the publicly available\n1024p text-to-image distilled models in prompt adherence score with a minimal\ndrop in FID compared to the teacher. Project page:\nhttps://github.com/alsdudrla10/ARD.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T15:33:49Z"}
{"aid":"http://arxiv.org/abs/2504.11305v1","title":"CFIS-YOLO: A Lightweight Multi-Scale Fusion Network for Edge-Deployable\n  Wood Defect Detection","summary":"Wood defect detection is critical for ensuring quality control in the wood\nprocessing industry. However, current industrial applications face two major\nchallenges: traditional methods are costly, subjective, and labor-intensive,\nwhile mainstream deep learning models often struggle to balance detection\naccuracy and computational efficiency for edge deployment. To address these\nissues, this study proposes CFIS-YOLO, a lightweight object detection model\noptimized for edge devices. The model introduces an enhanced C2f structure, a\ndynamic feature recombination module, and a novel loss function that\nincorporates auxiliary bounding boxes and angular constraints. These\ninnovations improve multi-scale feature fusion and small object localization\nwhile significantly reducing computational overhead. Evaluated on a public wood\ndefect dataset, CFIS-YOLO achieves a mean Average Precision (mAP@0.5) of\n77.5\\%, outperforming the baseline YOLOv10s by 4 percentage points. On SOPHON\nBM1684X edge devices, CFIS-YOLO delivers 135 FPS, reduces power consumption to\n17.3\\% of the original implementation, and incurs only a 0.5 percentage point\ndrop in mAP. These results demonstrate that CFIS-YOLO is a practical and\neffective solution for real-world wood defect detection in resource-constrained\nenvironments.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T15:45:59Z"}
{"aid":"http://arxiv.org/abs/2504.11306v1","title":"Context-Aware Palmprint Recognition via a Relative Similarity Metric","summary":"We propose a new approach to matching mechanism for palmprint recognition by\nintroducing a Relative Similarity Metric (RSM) that enhances the robustness and\ndiscriminability of existing matching frameworks. While conventional systems\nrely on direct pairwise similarity measures, such as cosine or Euclidean\ndistances, these metrics fail to capture how a pairwise similarity compares\nwithin the context of the entire dataset. Our method addresses this by\nevaluating the relative consistency of similarity scores across up to all\nidentities, allowing for better suppression of false positives and negatives.\nApplied atop the CCNet architecture, our method achieves a new state-of-the-art\n0.000036% Equal Error Rate (EER) on the Tongji dataset, outperforming previous\nmethods and demonstrating the efficacy of incorporating relational structure\ninto the palmprint matching process.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T15:46:17Z"}
{"aid":"http://arxiv.org/abs/2504.11308v1","title":"Constraints on Generalized Gravity-Thermodynamic Cosmology from DESI DR2","summary":"We explore the cosmological implications of generalized entropic models\nwithin the framework of Gravity-Thermodynamics (GT) approaches. These models,\ncharacterized by three or four additional free parameters, are designed to\ncapture deviations from the standard Bekenstein-Hawking entropy and can\nreproduce well-known entropic formulations, including Tsallis, R\\'enyi,\nSharma-Mittal, Barrow, Kaniadakis, and Loop Quantum Gravity entropies in\nvarious analytical limits. We implement the corresponding cosmological models\nusing a fully numerical GT approach to constrain the model parameters and to\nstudy the evolution of the dark energy equation of state as a function of the\nscale factor. Our Bayesian analysis, which incorporates the Pantheon+ and DESy5\nsupernovae data alongside the recently released DESI-DR2/DR1 Baryon Acoustic\nOscillation (BAO) measurements, shows that the data favor the standard\nBekenstein-Hawking entropy, leading to a $\\Lambda$CDM-like late-time behavior.\nIn this context, the three-parameter ($\\mathcal{S}_3$) entropic model appears\nto be sufficient to capture the observed dark energy phenomenology.\nFurthermore, a direct comparison of the Bayesian evidence indicates that the\nthree-parameter model is preferred over the four-parameter ($\\mathcal{S}_4$)\nvariant by a factor of $\\Delta\\log\\mathcal{B} \\sim -6$, while the GT approach\nas a whole is significantly disfavored relative to the $\\Lambda$CDM model with\nat least $\\Delta\\log\\mathcal{B} \\sim -8$ ($\\mathcal{S}_3$) to\n$\\Delta\\log\\mathcal{B} \\sim -13$ ($\\mathcal{S}_4$), when using the DESy5 and\nDESI-DR2 datasets.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph","published":"2025-04-15T15:49:10Z"}
{"aid":"http://arxiv.org/abs/2504.11321v1","title":"Subset-Contrastive Multi-Omics Network Embedding","summary":"Motivation: Network-based analyses of omics data are widely used, and while\nmany of these methods have been adapted to single-cell scenarios, they often\nremain memory- and space-intensive. As a result, they are better suited to\nbatch data or smaller datasets. Furthermore, the application of network-based\nmethods in multi-omics often relies on similarity-based networks, which lack\nstructurally-discrete topologies. This limitation may reduce the effectiveness\nof graph-based methods that were initially designed for topologies with better\ndefined structures. Results: We propose Subset-Contrastive multi-Omics Network\nEmbedding (SCONE), a method that employs contrastive learning techniques on\nlarge datasets through a scalable subgraph contrastive approach. By exploiting\nthe pairwise similarity basis of many network-based omics methods, we\ntransformed this characteristic into a strength, developing an approach that\naims to achieve scalable and effective analysis. Our method demonstrates\nsynergistic omics integration for cell type clustering in single-cell data.\nAdditionally, we evaluate its performance in a bulk multi-omics integration\nscenario, where SCONE performs comparable to the state-of-the-art despite\nutilising limited views of the original data. We anticipate that our findings\nwill motivate further research into the use of subset contrastive methods for\nomics data.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-15T16:01:39Z"}
{"aid":"http://arxiv.org/abs/2504.11333v1","title":"Implicit dual time-stepping positivity-preserving entropy-stable schemes\n  for the compressible Navier-Stokes equations","summary":"We generalize the explicit high-order positivity-preserving entropy-stable\nspectral collocation schemes developed in [30, 34] for the three-dimensional\n(3D) compressible Navier Stokes equations to a time implicit formulation. The\ntime derivative terms are discretized by using the first- and second-order\nimplicit backward difference formulas (BDF1 and BDF2) that are well suited for\nsolving steady-state and time-dependent viscous flows at high Reynolds numbers,\nrespectively. The nonlinear system of discrete equations at each physical\ntimestep is solved by using a dual time-stepping technique. The proposed scheme\nis provably entropy-stable and positivity-preserving and provides unconditional\nstability properties in the physical time. Numerical results demonstrating\naccuracy and positivity-preserving properties of the new dual time-stepping\nscheme are presented for supersonic viscous flows with strong shock waves and\ncontact discontinuities.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-15T16:07:05Z"}
{"aid":"http://arxiv.org/abs/2504.11347v1","title":"DeepWheel: Generating a 3D Synthetic Wheel Dataset for Design and\n  Performance Evaluation","summary":"Data-driven design is emerging as a powerful strategy to accelerate\nengineering innovation. However, its application to vehicle wheel design\nremains limited due to the lack of large-scale, high-quality datasets that\ninclude 3D geometry and physical performance metrics. To address this gap, this\nstudy proposes a synthetic design-performance dataset generation framework\nusing generative AI. The proposed framework first generates 2D rendered images\nusing Stable Diffusion, and then reconstructs the 3D geometry through 2.5D\ndepth estimation. Structural simulations are subsequently performed to extract\nengineering performance data. To further expand the design and performance\nspace, topology optimization is applied, enabling the generation of a more\ndiverse set of wheel designs. The final dataset, named DeepWheel, consists of\nover 6,000 photo-realistic images and 900 structurally analyzed 3D models. This\nmulti-modal dataset serves as a valuable resource for surrogate model training,\ndata-driven inverse design, and design space exploration. The proposed\nmethodology is also applicable to other complex design domains. The dataset is\nreleased under the Creative Commons Attribution-NonCommercial 4.0\nInternational(CC BY-NC 4.0) and is available on the\nhttps://www.smartdesignlab.org/datasets","main_category":"cs.CV","categories":"cs.CV,physics.app-ph","published":"2025-04-15T16:20:00Z"}
{"aid":"http://arxiv.org/abs/2504.11349v1","title":"Explicit and Implicit Representations in AI-based 3D Reconstruction for\n  Radiology: A systematic literature review","summary":"The demand for high-quality medical imaging in clinical practice and assisted\ndiagnosis has made 3D reconstruction in radiological imaging a key research\nfocus. Artificial intelligence (AI) has emerged as a promising approach to\nenhancing reconstruction accuracy while reducing acquisition and processing\ntime, thereby minimizing patient radiation exposure and discomfort and\nultimately benefiting clinical diagnosis. This review explores state-of-the-art\nAI-based 3D reconstruction algorithms in radiological imaging, categorizing\nthem into explicit and implicit approaches based on their underlying\nprinciples. Explicit methods include point-based, volume-based, and Gaussian\nrepresentations, while implicit methods encompass implicit prior embedding and\nneural radiance fields. Additionally, we examine commonly used evaluation\nmetrics and benchmark datasets. Finally, we discuss the current state of\ndevelopment, key challenges, and future research directions in this evolving\nfield. Our project available on: https://github.com/Bean-Young/AI4Med.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.GR,I.4.5","published":"2025-04-15T16:21:47Z"}
{"aid":"http://arxiv.org/abs/2504.11352v1","title":"Diagnostic Uncertainty Limits the Potential of Early Warning Signals to\n  Identify Epidemic Emergence","summary":"Methods to detect the emergence of infectious diseases, and approach to the\n\"critical transition\" RE = 1, have to potential to avert substantial disease\nburden by facilitating preemptive actions like vaccination campaigns. Early\nwarning signals (EWS), summary statistics of infection case time series, show\npromise in providing such advanced warnings. As EWS are computed on test\npositive case data, the accuracy of this underlying data is integral to their\npredictive ability, but will vary with changes in the diagnostic test accuracy\nand the incidence of the target disease relative to clinically-compatible\nbackground noise. We simulated emergent and null time series as the sum of an\nSEIR-generated measles time series, and background noise generated by either\nindependent draws from a Poisson distribution, or an SEIR simulation with\nrubella-like parameters. We demonstrate that proactive outbreak detection with\nEWS metrics is resilient to decreasing diagnostic accuracy, so long as\nbackground infections remain proportionally low. Under situations with large,\nepisodic, noise, imperfect diagnostic tests cannot appropriately discriminate\nbetween emergent and null periods. Not all EWS metrics performed equally: we\nfind that the mean was the least affected by changes to the noise structure and\nmagnitude, given a moderately accurate diagnostic test (>= to 95% sensitive and\nspecific), and the autocovariance and variance were the most predictive when\nthe noise incidence did not exhibit large temporal variations. In these\nsituations, diagnostic test accuracy should not be a precursor to the\nimplementation of an EWS metric-based alert system.","main_category":"q-bio.OT","categories":"q-bio.OT","published":"2025-04-15T16:22:58Z"}
{"aid":"http://arxiv.org/abs/2504.11353v1","title":"An Adaptive Dropout Approach for High-Dimensional Bayesian Optimization","summary":"Bayesian optimization (BO) is a widely used algorithm for solving expensive\nblack-box optimization problems. However, its performance decreases\nsignificantly on high-dimensional problems due to the inherent\nhigh-dimensionality of the acquisition function. In the proposed algorithm, we\nadaptively dropout the variables of the acquisition function along the\niterations. By gradually reducing the dimension of the acquisition function,\nthe proposed approach has less and less difficulty to optimize the acquisition\nfunction. Numerical experiments demonstrate that AdaDropout effectively tackle\nhigh-dimensional challenges and improve solution quality where standard\nBayesian optimization methods often struggle. Moreover, it achieves superior\nresults when compared with state-of-the-art high-dimensional Bayesian\noptimization approaches. This work provides a simple yet efficient solution for\nhigh-dimensional expensive optimization.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-15T16:23:25Z"}
{"aid":"http://arxiv.org/abs/2504.11372v1","title":"A Review of Traffic Wave Suppression Strategies: Variable Speed Limit\n  vs. Jam-Absorption Driving","summary":"The main form of freeway traffic congestion is the familiar stop-and-go wave,\ncharacterized by wide moving jams that propagate indefinitely upstream provided\nenough traffic demand. They cause severe, long-lasting adverse effects, such as\nreduced traffic efficiency, increased driving risks, and higher vehicle\nemissions. This underscores the crucial importance of artificial intervention\nin the propagation of stop-and-go waves. Over the past two decades, two\nprominent strategies for stop-and-go wave suppression have emerged: variable\nspeed limit (VSL) and jam-absorption driving (JAD). Although they share similar\nresearch motivations, objectives, and theoretical foundations, the development\nof these strategies has remained relatively disconnected. To synthesize\nfragmented advances and drive the field forward, this paper first provides a\ncomprehensive review of the achievements in the stop-and-go wave\nsuppression-oriented VSL and JAD, respectively. It then focuses on bridging the\ntwo areas and identifying research opportunities from the following\nperspectives: fundamental diagrams, traffic dynamics modeling, traffic state\nestimation and prediction, stochasticity, scenarios for strategy validation,\nand field tests and practical deployment. We expect that through this review,\none area can effectively address its limitations by identifying and leveraging\nthe strengths of the other, thus promoting the overall research goal of freeway\nstop-and-go wave suppression.","main_category":"physics.soc-ph","categories":"physics.soc-ph,cs.SY,eess.SY,stat.AP","published":"2025-04-15T16:37:23Z"}
{"aid":"http://arxiv.org/abs/2504.11392v1","title":"Probing General Relativity-Induced Decoherence Using an on-chip Sagnac\n  Interferometer","summary":"The intersection of quantum mechanics and general relativity remains an open\nfrontier in fundamental physics, with few experimentally accessible phenomena\nconnecting the two. Recent theoretical proposals suggest that relativistic\nproper time can act as a source of decoherence in quantum systems, providing a\ntestable overlap between the two theories. Here, we propose a chip-integrated\nSagnac interferometer where rotation induces a proper time difference between\nclockwise and counterclockwise single-photon paths. When this time delay\nexceeds the photon's coherence time, interference visibility is predicted to\ndecrease, offering a direct signature of relativistic time dilation-induced\ndecoherence. We theoretically derive the proper time difference arising from\nthe Sagnac effect and estimate that for a loop radius of 18.9 cm and a rotation\nspeed of 1000 rad/s, decoherence should occur for single-photon wavepackets\nwith a coherence time of 10 femtoseconds. We also present a practical chip\ndesign that accommodates the required high-speed mechanical rotation and\nincludes an all-optical readout scheme to eliminate wiring constraints. This\napproach enables a stable, on-chip implementation using realistic parameters,\nwith rotation speed serving as a continuously tunable knob to control\ndecoherence. Our platform opens a new route for experimentally probing the\ninterplay between quantum coherence and relativistic proper time in a scalable\nand compact form.","main_category":"physics.optics","categories":"physics.optics,quant-ph","published":"2025-04-15T17:01:16Z"}
{"aid":"http://arxiv.org/abs/2504.11394v1","title":"Overrings of half-factorial orders","summary":"The behavior of factorization properties in various ring extensions is a\ncentral theme in commutative algebra. Classically, the UFDs are (completely)\nintegrally closed and tend to behave well in standard ring extensions, with the\nnotable exception of power series extension. The half-factorial property is not\nas robust; HFDs need not be integrally closed and the half-factorial property\nis not necessarily preserved in integral extensions or even localizations. Here\nwe exhibit classes of HFDs that behave well in (almost) integral extensions,\nresolve an open question on the behavior of the boundary map, and give a\nsqueeze theorem for elasticity in certain domains.","main_category":"math.AC","categories":"math.AC","published":"2025-04-15T17:05:28Z"}
{"aid":"http://arxiv.org/abs/2504.11400v1","title":"FlowUnits: Extending Dataflow for the Edge-to-Cloud Computing Continuum","summary":"This paper introduces FlowUnits, a novel programming and deployment model\nthat extends the traditional dataflow paradigm to address the unique challenges\nof edge-to-cloud computing environments. While conventional dataflow systems\noffer significant advantages for large-scale data processing in homogeneous\ncloud settings, they fall short when deployed across distributed, heterogeneous\ninfrastructures. FlowUnits addresses three critical limitations of current\napproaches: lack of locality awareness, insufficient resource adaptation, and\nabsence of dynamic update mechanisms. FlowUnits organize processing operators\ninto cohesive, independently manageable components that can be transparently\nreplicated across different regions, efficiently allocated on nodes with\nappropriate hardware capabilities, and dynamically updated without disrupting\nongoing computations. We implement and evaluate the FlowUnits model within\nRenoir, an existing dataflow system, demonstrating significant improvements in\ndeployment flexibility and resource utilization across the computing continuum.\nOur approach maintains the simplicity of dataflow while enabling seamless\nintegration of edge and cloud resources into unified data processing pipelines.","main_category":"cs.DC","categories":"cs.DC,cs.SE","published":"2025-04-15T17:14:08Z"}
{"aid":"http://arxiv.org/abs/2504.11402v1","title":"Complex multiannual cycles of Mycoplasma pneumoniae: persistence and the\n  role of stochasticity","summary":"The epidemiological dynamics of Mycoplasma pneumoniae are characterized by\ncomplex and poorly understood multiannual cycles, posing challenges for\nforecasting. Using Bayesian methods to fit a seasonally forced transmission\nmodel to long-term surveillance data from Denmark (1958-1995, 2010-2025), we\ninvestigate the mechanisms driving recurrent outbreaks of M. pneumoniae. The\nperiod of the multiannual cycles (predominantly approx. 5 years in Denmark) are\nexplained as a consequence of the interaction of two time-scales in the system,\none intrinsic and one extrinsic (seasonal). While it provides an excellent fit\nto shorter time series (a few decades), we find that the deterministic model\neventually settles into an annual cycle, failing to reproduce the observed\n4-5-year periodicity long-term. Upon further analysis, the system is found to\nexhibit transient chaos and thus high sensitivity to stochasticity. We show\nthat environmental (but not purely demographic) stochasticity can sustain the\nmulti-year cycles via stochastic resonance. The disruptive effects of COVID-19\nnon-pharmaceutical interventions (NPIs) on M. pneumoniae circulation constitute\na natural experiment on the effects of large perturbations. Consequently, the\neffects of NPIs are included in the model and medium-term predictions are\nexplored. Our findings highlight the intrinsic sensitivity of M. pneumoniae\ndynamics to perturbations and interventions, underscoring the limitations of\ndeterministic epidemic models for long-term prediction. More generally, our\nresults emphasize the potential role of stochasticity as a driver of complex\ncycles across endemic and recurring pathogens.","main_category":"q-bio.PE","categories":"q-bio.PE,nlin.CD","published":"2025-04-15T17:18:10Z"}
{"aid":"http://arxiv.org/abs/2504.11410v1","title":"Randomized block proximal method with locally Lipschitz continuous\n  gradient","summary":"Block-coordinate algorithms are recognized to furnish efficient iterative\nschemes for addressing large-scale problems, especially when the computation of\nfull derivatives entails substantial memory requirements and computational\nefforts. In this paper, we investigate a randomized block proximal gradient\nalgorithm for minimizing the sum of a differentiable function and a separable\nproper lower-semicontinuous function, both possibly nonconvex. In contrast to\nprevious works, we only assume that the partial gradients of the differentiable\nfunction are locally Lipschitz continuous. At each iteration, the method\nadaptively selects a proximal stepsize to satisfy a sufficient decrease\ncondition without prior knowledge of the local Lipschitz moduli of the partial\ngradients of the differentiable function. In addition, we incorporate the\npossibility of conducting an additional linesearch to enhance the performance\nof the algorithm. Our main result establishes subsequential convergence to a\nstationary point of the problem almost surely. Finally, we provide numerical\nvalidation of the method in an experiment in image compression using a\nnonnegative matrix factorization model.","main_category":"math.OC","categories":"math.OC","published":"2025-04-15T17:26:40Z"}
{"aid":"http://arxiv.org/abs/2504.11430v1","title":"The 2D Lorentz-violating fermionic Casimir effect under thermal\n  conditions","summary":"In the present work, we explore the dimensional projection method applied to\na fermionic Lorentz invariance violation (LIV) theory with the CPT-even\ndimension-six extension. Due to the dimensional reduction of a fermionic system\nfrom $4D$ to $2D$, it is possible to study the influence of LIV on the Casimir\neffect under the MIT bag boundary condition model in a low-dimensional setting,\nwhere results are obtained without any approximations for a null-temperature\nsystem. Moreover, the Matsubara formalism is applied to derive closed\nexpressions for the influence of temperature on the physical observables:\nCasimir energy, Casimir force, and entropy associated with the system in a LIV\ncontext. For each thermal observable, the influence of the LIV correction term\nis considered in the analysis of both low- and high-temperature regimes.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-15T17:41:33Z"}
{"aid":"http://arxiv.org/abs/2504.11445v1","title":"Pixel-level modelling of group-scale strong lens CASSOWARY 19","summary":"We present the first high-precision model for the group-scale strong lensing\nsystem CASSOWARY 19 (CSWA19), utilising images from the Hubble Space Telescope\n(HST). Sixteen member galaxies identified via the red-sequence method, and the\nmain halo, all modelled as the dual Pseudo Isothermal Elliptical profile\n(dPIE), are incorporated into a parametric lens model alongside an external\nshear field. To model the system, we adopt the PyAutoLens software package,\nemploying a progressive search chain strategy for realizing the transition of\nsource model from multiple S\\'ersic profiles to a brightness-adaptive\npixelization, which uses 1000 pixels in the source plane to reconstruct the\nbackground source corresponding to 177,144 image pixels in the image plane. Our\nresults indicate that the total mass within the Einstein radius is\n$M_{\\theta_\\mathrm{E}}$ $\\approx 1.41\\times10^{13}$M$_{\\odot}$ and the average\nslope of the total mass density $\\rho (r)\\propto r^{-\\gamma}$ is\n$\\tilde{\\gamma}=1.33$ within the effective radius. This slope is shallower than\nthose measured in galaxies and groups but is closer to those of galaxy\nclusters. In addition, our approach successfully resolves the two merging\ngalaxies in the background source and yields a total magnification of\n$\\mu=103.18^{+0.23}_{-0.19}$, which is significantly higher than the outcomes\nfrom previous studies of CSWA19. In summary, our research demonstrates the\neffectiveness of the brightness-adaptive pixelization source reconstruction\ntechnique for modelling group-scale strong lensing systems. It can serve as a\ntechnical reference for future investigations into pixel-level modelling of the\ngroup- and cluster-scale strong lensing systems.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-15T17:56:11Z"}
{"aid":"http://arxiv.org/abs/2504.11799v1","title":"Gaussian states in quantum field theory: Exact representations of\n  relative phase in superpositions of Gaussian states","summary":"Gaussian quantum mechanics is a powerful tool regularly used in quantum\noptics to model linear and quadratic Hamiltonians efficiently. Recent interest\nin qubit-CV hybrid models has revealed a simple, yet important gap in our\nknowledge, namely, how to fully manipulate superpositions of Gaussian states.\nIn this paper, we show how to faithfully represent a quadratic Gaussian state\nin the Fock basis. Specifically, we evaluate the phase necessary to equate the\nunitary representation of a zero-mean Gaussian state with its Fock\nrepresentation. This allows for the coherent manipulation of superpositions of\nGaussian states, especially the evaluation of expectation values from these\nsuperposed states. We then use this method to model a simple quantum field\ntheory communication protocol using quadratic detectors in a regime that has\npreviously been impossible to solve. The result presented in this paper is\nexpected to become increasingly relevant with hybrid-CV systems, especially in\nthe strong-coupling regime.","main_category":"quant-ph","categories":"quant-ph,gr-qc,hep-th","published":"2025-04-16T06:13:36Z"}
{"aid":"http://arxiv.org/abs/2504.11816v1","title":"Cost-Efficient LLM Serving in the Cloud: VM Selection with KV Cache\n  Offloading","summary":"LLM inference is essential for applications like text summarization,\ntranslation, and data analysis, but the high cost of GPU instances from Cloud\nService Providers (CSPs) like AWS is a major burden. This paper proposes\nInferSave, a cost-efficient VM selection framework for cloud based LLM\ninference. InferSave optimizes KV cache offloading based on Service Level\nObjectives (SLOs) and workload charac teristics, estimating GPU memory needs,\nand recommending cost-effective VM instances. Additionally, the Compute Time\nCalibration Function (CTCF) improves instance selection accuracy by adjusting\nfor discrepancies between theoretical and actual GPU performance. Experiments\non AWS GPU instances show that selecting lower-cost instances without KV cache\noffloading improves cost efficiency by up to 73.7% for online workloads, while\nKV cache offloading saves up to 20.19% for offline workloads.","main_category":"cs.LG","categories":"cs.LG,cs.DC","published":"2025-04-16T07:02:38Z"}
{"aid":"http://arxiv.org/abs/2504.11831v1","title":"Support is All You Need for Certified VAE Training","summary":"Variational Autoencoders (VAEs) have become increasingly popular and deployed\nin safety-critical applications. In such applications, we want to give\ncertified probabilistic guarantees on performance under adversarial attacks. We\npropose a novel method, CIVET, for certified training of VAEs. CIVET depends on\nthe key insight that we can bound worst-case VAE error by bounding the error on\ncarefully chosen support sets at the latent layer. We show this point\nmathematically and present a novel training algorithm utilizing this insight.\nWe show in an extensive evaluation across different datasets (in both the\nwireless and vision application areas), architectures, and perturbation\nmagnitudes that our method outperforms SOTA methods achieving good standard\nperformance with strong robustness guarantees.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-16T07:41:40Z"}
{"aid":"http://arxiv.org/abs/2504.11839v1","title":"\"Good\" and \"Bad\" Failures in Industrial CI/CD -- Balancing Cost and\n  Quality Assurance","summary":"Continuous Integration and Continuous Deployment (CI/CD) pipeline automates\nsoftware development to speed up and enhance the efficiency of engineering\nsoftware. These workflows consist of various jobs, such as code validation and\ntesting, which developers must wait to complete before receiving feedback. The\njobs can fail, which leads to unnecessary delays in build times, decreasing\nproductivity for developers, and increasing costs for companies. To explore how\ncompanies adopt CI/CD workflows and balance cost with quality assurance during\noptimization, we studied 4 companies, reporting industry experiences with CI/CD\npractices. Our findings reveal that organizations can confuse the distinction\nbetween CI and CD, whereas code merge and product release serve as more\neffective milestones for process optimization and risk control. While numerous\ntools and research efforts target the post-merge phase to enhance productivity,\nlimited attention has been given to the pre-merge phase, where early failure\nprevention brings more impacts and less risks.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-16T07:56:36Z"}
{"aid":"http://arxiv.org/abs/2504.11853v1","title":"Stability of Highly Hydrogenated Monolayer Graphene in Ultra-High Vacuum\n  and in Air","summary":"The stability of hydrogenated monolayer graphene was investigated via X-ray\nphotoemission spectroscopy (XPS) for two different environmental conditions:\nultra-high vacuum (UHV) and ambient pressure. The study is carried out by\nmeasuring the C 1s line shape evolution for two hydrogenated samples one kept\nin the UHV chamber and the other progressively exposed to air. In particular,\nthe $sp^3$ relative intensity in the C 1s core-level spectrum, represented by\nthe area ratio $\\frac{sp^3}{sp^2+sp^3}$, was used as a marker for the\nhydrogenation-level and it resulted to vary by (4 $\\pm$ 2)$\\%$ in UHV after\nfour months. Thus, a long-term stability of hydrogenated monolayer graphene was\nfound, that indicates this material as a good candidate for hydrogen (or\ntritium) storage as long as it is kept in vacuum. On the other hand, the C 1s\nspectrum of the sample exposed to air shows a significant oxidation. A rapid\ngrowth up to saturation of the carbon oxides was observed with a time constant\n$\\tau$ = 1.8 $\\pm$ 0.2 hours. Finally, the re-exposure of the oxidised sample\nto atomic hydrogen was found to be an effective method for the recovery of\nhydrogenated graphene. This process was studied by carrying out both XPS and\nelectron energy loss spectroscopy, the latter exploited to observe the CH\nstretching mode as a direct footprint of re-hydrogenation.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-16T08:21:13Z"}
{"aid":"http://arxiv.org/abs/2504.11894v1","title":"Trajectory Dispersion Control for Precision Landing Guidance of Reusable\n  Rockets","summary":"This article is an engineering note, and formal abstract is omitted in\naccordance with the requirements of the journal. The main idea of this note is\nas follows. In endoatmospheric landing of reusable rockets, there exist various\nkinds of disturbances that can induce the trajectory dispersion. The trajectory\ndispersion propagates with flight time and ultimately determines landing\naccuracy. Therefore, to achieve high-precision landing, this note proposes a\nnovel online trajectory dispersion control method. Based on a Parameterized\nOptimal Feedback Guidance Law (POFGL), two key components of the proposed\nmethod are designed: online trajectory dispersion prediction and real-time\nguidance parameter tuning for trajectory dispersion optimization. First, by\nformalizing a parameterized probabilistic disturbance model, the closed-loop\ntrajectory dispersion under the POFGL is predicted online. Compared with the\ncovariance control guidance method, a more accurate trajectory dispersion\nprediction is achieved by using generalized Polynomial Chaos (gPC) expansion\nand pseudospectral collocation methods. Second, to ensure computational\nefficiency, a gradient descent based real-time guidance parameter tuning law is\ndesigned to simultaneously optimize the performance index and meet the landing\nerror dispersion constraint, which significantly reduces the conservativeness\nof guidance design compared with the robust trajectory optimization method.\nNumerical simulations indicate that the trajectory dispersion prediction method\ncan achieve the same accuracy as the Monte Carlo method with smaller\ncomputational resource; the guidance parameter tuning law can improve the\noptimal performance index and meet the desired accuracy requirements through\ndirectly shaping the trajectory dispersion.","main_category":"physics.space-ph","categories":"physics.space-ph","published":"2025-04-16T09:20:16Z"}
{"aid":"http://arxiv.org/abs/2504.11900v1","title":"Finding Flawed Fictions: Evaluating Complex Reasoning in Language Models\n  via Plot Hole Detection","summary":"Stories are a fundamental aspect of human experience. Engaging deeply with\nstories and spotting plot holes -- inconsistencies in a storyline that break\nthe internal logic or rules of a story's world -- requires nuanced reasoning\nskills, including tracking entities and events and their interplay, abstract\nthinking, pragmatic narrative understanding, commonsense and social reasoning,\nand theory of mind. As Large Language Models (LLMs) increasingly generate,\ninterpret, and modify text, rigorously assessing their narrative consistency\nand deeper language understanding becomes critical. However, existing\nbenchmarks focus mainly on surface-level comprehension. In this work, we\npropose plot hole detection in stories as a proxy to evaluate language\nunderstanding and reasoning in LLMs. We introduce FlawedFictionsMaker, a novel\nalgorithm to controllably and carefully synthesize plot holes in human-written\nstories. Using this algorithm, we construct a benchmark to evaluate LLMs' plot\nhole detection abilities in stories -- FlawedFictions -- , which is robust to\ncontamination, with human filtering ensuring high quality. We find that\nstate-of-the-art LLMs struggle in accurately solving FlawedFictions regardless\nof the reasoning effort allowed, with performance significantly degrading as\nstory length increases. Finally, we show that LLM-based story summarization and\nstory generation are prone to introducing plot holes, with more than 50% and\n100% increases in plot hole detection rates with respect to human-written\noriginals.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-16T09:25:54Z"}
{"aid":"http://arxiv.org/abs/2504.11907v1","title":"A Graph-Based Reinforcement Learning Approach with Frontier Potential\n  Based Reward for Safe Cluttered Environment Exploration","summary":"Autonomous exploration of cluttered environments requires efficient\nexploration strategies that guarantee safety against potential collisions with\nunknown random obstacles. This paper presents a novel approach combining a\ngraph neural network-based exploration greedy policy with a safety shield to\nensure safe navigation goal selection. The network is trained using\nreinforcement learning and the proximal policy optimization algorithm to\nmaximize exploration efficiency while reducing the safety shield interventions.\nHowever, if the policy selects an infeasible action, the safety shield\nintervenes to choose the best feasible alternative, ensuring system\nconsistency. Moreover, this paper proposes a reward function that includes a\npotential field based on the agent's proximity to unexplored regions and the\nexpected information gain from reaching them. Overall, the approach\ninvestigated in this paper merges the benefits of the adaptability of\nreinforcement learning-driven exploration policies and the guarantee ensured by\nexplicit safety mechanisms. Extensive evaluations in simulated environments\ndemonstrate that the approach enables efficient and safe exploration in\ncluttered environments.","main_category":"cs.RO","categories":"cs.RO,I.2.9","published":"2025-04-16T09:31:14Z"}
{"aid":"http://arxiv.org/abs/2504.11918v1","title":"Deep learning to improve the discovery of near-Earth asteroids in the\n  Zwicky Transient Facility","summary":"We present a novel pipeline that uses a convolutional neural network (CNN) to\nimprove the detection capability of near-Earth asteroids (NEAs) in the context\nof planetary defense. Our work aims to minimize the dependency on human\nintervention of the current approach adopted by the Zwicky Transient Facility\n(ZTF). The target NEAs have a high proper motion of up to tens of degrees per\nday and thus appear as streaks of light in the images. We trained our CNNs to\ndetect these streaks using three datasets: a set with real asteroid streaks, a\nset with synthetic (i.e., simulated) streaks and a mixed set, and tested the\nresultant models on real survey images. The results achieved were almost\nidentical across the three models: $0.843\\pm0.005$ in completeness and\n$0.820\\pm0.025$ in precision. The bias on streak measurements reported by the\nCNNs was $1.84\\pm0.03$ pixels in streak position, $0.817\\pm0.026$ degrees in\nstreak angle and $-0.048\\pm0.003$ in fractional bias in streak length (computed\nas the absolute length bias over the streak length, with the negative sign\nindicating an underestimation). We compared the performance of our CNN trained\nwith a mix of synthetic and real streaks to that of the ZTF human scanners by\nanalyzing a set of 317 streaks flagged as valid by the scanners. Our pipeline\ndetected $80~\\%$ of the streaks found by the scanners and 697 additional\nstreaks that were subsequently verified by the scanners to be valid streaks.\nThese results suggest that our automated pipeline can complement the work of\nthe human scanners at no cost for the precision and find more objects than the\ncurrent approach. They also prove that the synthetic streaks were realistic\nenough to be used for augmenting training sets when insufficient real streaks\nare available or exploring the simulation of streaks with unusual\ncharacteristics that have not yet been detected.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-16T09:55:26Z"}
{"aid":"http://arxiv.org/abs/2504.11923v1","title":"SemDiff: Generating Natural Unrestricted Adversarial Examples via\n  Semantic Attributes Optimization in Diffusion Models","summary":"Unrestricted adversarial examples (UAEs), allow the attacker to create\nnon-constrained adversarial examples without given clean samples, posing a\nsevere threat to the safety of deep learning models. Recent works utilize\ndiffusion models to generate UAEs. However, these UAEs often lack naturalness\nand imperceptibility due to simply optimizing in intermediate latent noises. In\nlight of this, we propose SemDiff, a novel unrestricted adversarial attack that\nexplores the semantic latent space of diffusion models for meaningful\nattributes, and devises a multi-attributes optimization approach to ensure\nattack success while maintaining the naturalness and imperceptibility of\ngenerated UAEs. We perform extensive experiments on four tasks on three\nhigh-resolution datasets, including CelebA-HQ, AFHQ and ImageNet. The results\ndemonstrate that SemDiff outperforms state-of-the-art methods in terms of\nattack success rate and imperceptibility. The generated UAEs are natural and\nexhibit semantically meaningful changes, in accord with the attributes'\nweights. In addition, SemDiff is found capable of evading different defenses,\nwhich further validates its effectiveness and threatening.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-16T09:58:04Z"}
{"aid":"http://arxiv.org/abs/2504.11925v1","title":"Reducing Calls to the Simulator in Simulation Based Inference (SBI)","summary":"Simulation-Based Inference (SBI) deals with statistical inference in problems\nwhere the data are generated from a system that is described by a complex\nstochastic simulator. The challenge for inference in these problems is that the\nlikelihood is intractable; SBI proceeds by using the simulator to sample from\nthe likelihood. In many real world applications, simulator calls are expensive,\nlimiting the associated sample size. Our goal in this work is to extend SBI to\nexploit two proposals for reducing simulator calls: to draw likelihood samples\nfrom a Neural Density Estimator (NDE) surrogate rather than from the stochastic\nsimulator; and use of Support Points rather than simple random sampling to\ngenerate evaluation sites. We embed these methods in the Sequential Neural\nPosterior Estimator (SNPE) algorithm. Across a suite of test cases, we find\nthat the NDE surrogate improves the quality of the inference; support points\nworked well in some examples, but not in others.","main_category":"stat.CO","categories":"stat.CO,62-08","published":"2025-04-16T09:59:31Z"}
{"aid":"http://arxiv.org/abs/2504.11929v1","title":"Separate universe in multifield inflation: a phase-space approach","summary":"In this article we extend a study of the validity conditions of the\nseparate-universe approach of cosmological perturbations to models of inflation\nwith multiple fields. The separate-universe approach consists in describing the\nuniverse as a collection of homogeneous and isotropic patches, giving us an\neffective description of perturbation theory at large scales through\nphase-space reduction. This approximation is a necessary step in stochastic\ninflation, an effective theory of coarse-grained, super-Hubble, scalar fields\nfluctuations. One needs a stochastic inflation description in the context of\nprimordial black hole productions since it needs enhancements of the curvature\npower spectrum. It easily achievable in multifield inflation models but\nnecessarily comes with strong diffusive effects. We study and compare\ncosmological perturbation theory and the separate-universe approach in said\nnon-linear sigma models as a typical framework of multifield inflation and\nemploying the Hamiltonian formalism to keep track of the complete phase space\n(or the reduced isotropic phase space in the separate-universe approach). We\nfind that the separate-universe approach adequately describes the cosmological\nperturbation theory provided the wavelength of the modes considered is greater\nthat several lower bounds that depend on the cosmological horizon and the\ninverse of the effective Hamiltonian masses of the fields; the latter being\nfixed by the coupling potential and the field-space geometry. We also compare\ngauge-invariant variables and several gauge fixing procedures in both\napproaches. For instance, we showed that the uniform-expansion gauge is nicely\ndescribed by the separate-universe picture, hence qualifying its use in\nstochastic inflation as commonly done.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-16T10:08:43Z"}
{"aid":"http://arxiv.org/abs/2504.11934v1","title":"An LLM-as-a-judge Approach for Scalable Gender-Neutral Translation\n  Evaluation","summary":"Gender-neutral translation (GNT) aims to avoid expressing the gender of human\nreferents when the source text lacks explicit cues about the gender of those\nreferents. Evaluating GNT automatically is particularly challenging, with\ncurrent solutions being limited to monolingual classifiers. Such solutions are\nnot ideal because they do not factor in the source sentence and require\ndedicated data and fine-tuning to scale to new languages. In this work, we\naddress such limitations by investigating the use of large language models\n(LLMs) as evaluators of GNT. Specifically, we explore two prompting approaches:\none in which LLMs generate sentence-level assessments only, and another, akin\nto a chain-of-thought approach, where they first produce detailed phrase-level\nannotations before a sentence-level judgment. Through extensive experiments on\nmultiple languages with five models, both open and proprietary, we show that\nLLMs can serve as evaluators of GNT. Moreover, we find that prompting for\nphrase-level annotations before sentence-level assessments consistently\nimproves the accuracy of all models, providing a better and more scalable\nalternative to current solutions.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-16T10:14:27Z"}
{"aid":"http://arxiv.org/abs/2504.11947v1","title":"Dissecting coupled orders in a terahertz-driven electron-doped cuprate","summary":"The interplay between superconductivity and charge density wave has often\nbeen studied from an equilibrium point of view. For example, using static\ntuning knobs such as doping, magnetic field and pressure, superconductivity can\nbe enhanced or suppressed. The resulting effect on the co-existing charge\ndensity wave order, if any, is judged by variations in its ground state\nproperties such as the ordering temperature or the spatial correlation. Such an\napproach can be understood as coordinated static displacements of two coupled\norder parameters within a Ginzburg-Landau description, evincing their interplay\nas either co-operative or competing but does not provide further microscopic\ninformation about the interaction. In order to assess such information, we\ndynamically perturb both orders from equilibrium and observe their coupling\ndirectly in the time-domain. We show that high-field multicycle terahertz\npulses drive both the Higgs amplitude fluctuations of the superconducting order\nas well as collective fluctuations of the charge order in an electron-doped\ncuprate, resulting in characteristic third harmonic generation. A notable time\ndelay is manifested between their respective driven dynamics. We propose that\nthis may signify the important energy scale describing their coupling or imply\na terahertz field-depinned charge density wave that destroys macroscopic\nsuperconductivity. Our work demonstrates a holistic approach for investigating\ncoupled superconducting and charge density wave orders, which may shed novel\nlight on their intertwined presence and widespread fluctuations in many classes\nof unconventional superconductors.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-16T10:24:08Z"}
{"aid":"http://arxiv.org/abs/2504.11966v1","title":"Exploring Video-Based Driver Activity Recognition under Noisy Labels","summary":"As an open research topic in the field of deep learning, learning with noisy\nlabels has attracted much attention and grown rapidly over the past ten years.\nLearning with label noise is crucial for driver distraction behavior\nrecognition, as real-world video data often contains mislabeled samples,\nimpacting model reliability and performance. However, label noise learning is\nbarely explored in the driver activity recognition field. In this paper, we\npropose the first label noise learning approach for the driver activity\nrecognition task. Based on the cluster assumption, we initially enable the\nmodel to learn clustering-friendly low-dimensional representations from given\nvideos and assign the resultant embeddings into clusters. We subsequently\nperform co-refinement within each cluster to smooth the classifier outputs.\nFurthermore, we propose a flexible sample selection strategy that combines two\nselection criteria without relying on any hyperparameters to filter clean\nsamples from the training dataset. We also incorporate a self-adaptive\nparameter into the sample selection process to enforce balancing across\nclasses. A comprehensive variety of experiments on the public Drive&Act dataset\nfor all granularity levels demonstrates the superior performance of our method\nin comparison with other label-denoising methods derived from the image\nclassification field. The source code is available at\nhttps://github.com/ilonafan/DAR-noisy-labels.","main_category":"cs.CV","categories":"cs.CV,cs.LG,cs.RO,eess.IV","published":"2025-04-16T10:55:13Z"}
{"aid":"http://arxiv.org/abs/2504.11971v1","title":"Spinorial quasilocal mass for spacetimes with negative cosmological\n  constant","summary":"A new notion of quasilocal mass is defined for generic, compact, two\ndimensional, spacelike surfaces in four dimensional spacetimes with negative\ncosmological constant. The definition is spinorial and based on work for\nvanishing cosmological constant by Penrose and Dougan & Mason. Furthermore,\nthis mass is non-negative, equal to the Misner-Sharp mass in spherical\nsymmetry, equal to zero for every generic surface in AdS, has an appropriate\nform for gravity linearised about AdS and has an appropriate limit for large\nspheres in asymptotically AdS spacetimes.","main_category":"gr-qc","categories":"gr-qc,hep-th,math.DG","published":"2025-04-16T11:07:23Z"}
{"aid":"http://arxiv.org/abs/2504.11972v1","title":"LLM-as-a-Judge: Reassessing the Performance of LLMs in Extractive QA","summary":"Extractive reading comprehension question answering (QA) datasets are\ntypically evaluated using Exact Match (EM) and F1-score, but these metrics\noften fail to fully capture model performance. With the success of large\nlanguage models (LLMs), they have been employed in various tasks, including\nserving as judges (LLM-as-a-judge). In this paper, we reassess the performance\nof QA models using LLM-as-a-judge across four reading comprehension QA\ndatasets. We examine different families of LLMs and various answer types to\nevaluate the effectiveness of LLM-as-a-judge in these tasks. Our results show\nthat LLM-as-a-judge is highly correlated with human judgments and can replace\ntraditional EM/F1 metrics. By using LLM-as-a-judge, the correlation with human\njudgments improves significantly, from 0.17 (EM) and 0.36 (F1-score) to 0.85.\nThese findings confirm that EM and F1 metrics underestimate the true\nperformance of the QA models. While LLM-as-a-judge is not perfect for more\ndifficult answer types (e.g., job), it still outperforms EM/F1, and we observe\nno bias issues, such as self-preference, when the same model is used for both\nthe QA and judgment tasks.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-16T11:08:46Z"}
{"aid":"http://arxiv.org/abs/2504.11986v1","title":"Language Models as Quasi-Crystalline Thought: Structure, Constraint, and\n  Emergence in Generative Systems","summary":"This essay proposes an analogy between large language models (LLMs) and\nquasicrystals: systems that exhibit global coherence without periodic\nrepetition and that are generated through local constraints. While LLMs are\noften evaluated in terms of predictive accuracy, factuality, or alignment, this\nstructural perspective suggests that their most characteristic behavior is the\nproduction of internally resonant linguistic patterns. Just as quasicrystals\nforced a redefinition of order in physical systems, viewing LLMs as generators\nof quasi-structured language opens new paths for evaluation and design:\nprivileging propagation of constraint over token-level accuracy, and coherence\nof form over fixed meaning. LLM outputs should be read not only for what they\nsay, but for the patterns of constraint and coherence that organize them. This\nshift reframes generative language as a space of emergent patterning: LLMs are\nneither fully random nor strictly rule-based, but defined by a logic of\nconstraint, resonance, and structural depth.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-16T11:27:47Z"}
{"aid":"http://arxiv.org/abs/2504.12015v1","title":"Power Line Communication vs. Talkative Power Conversion: A Benchmarking\n  Study","summary":"The convergence of energy transmission and data communication has become a\nkey feature of decentralized energy systems across a broad spectrum of\nvoltage/power ranges, including smart grid applications and cyber-physical\npower systems. This paper compares two distinct approaches: Power Line\nCommunications (PLC) and Talkative Power Conversion (TPC). While PLC leverages\nexisting power infrastructure for data transmission by using external data\ntransmitters and receivers, TPC integrates communication capabilities directly\ninto power electronic converters. We present their technical foundations and\napplications, benchmark their strengths and bottlenecks, and outline future\nresearch directions regarding TPC that could bridge the gap between power and\ncommunication technologies.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-16T12:15:42Z"}
{"aid":"http://arxiv.org/abs/2504.12045v1","title":"pix2pockets: Shot Suggestions in 8-Ball Pool from a Single Image in the\n  Wild","summary":"Computer vision models have seen increased usage in sports, and reinforcement\nlearning (RL) is famous for beating humans in strategic games such as Chess and\nGo. In this paper, we are interested in building upon these advances and\nexamining the game of classic 8-ball pool. We introduce pix2pockets, a\nfoundation for an RL-assisted pool coach. Given a single image of a pool table,\nwe first aim to detect the table and the balls and then propose the optimal\nshot suggestion. For the first task, we build a dataset with 195 diverse images\nwhere we manually annotate all balls and table dots, leading to 5748 object\nsegmentation masks. For the second task, we build a standardized RL environment\nthat allows easy development and benchmarking of any RL algorithm. Our object\ndetection model yields an AP50 of 91.2 while our ball location pipeline obtains\nan error of only 0.4 cm. Furthermore, we compare standard RL algorithms to set\na baseline for the shot suggestion task and we show that all of them fail to\npocket all balls without making a foul move. We also present a simple baseline\nthat achieves a per-shot success rate of 94.7% and clears a full game in a\nsingle turn 30% of the time.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-16T13:01:44Z"}
{"aid":"http://arxiv.org/abs/2504.12094v1","title":"Relaxation of perturbed circles in flat spaces for the Mullins-Sekerka\n  evolution in two dimensions","summary":"We analyze the convergence of a perturbed circular interface for the\ntwo-phase Mullins-Sekerka evolution in flat two-dimensional space. Our method\nis based on the gradient flow structure of the evolution and captures two\ndistinct regimes of the dynamics, an initial - and novel - phase of\nalgebraic-in-time decay and a later - and previously explored - phase of\nexponential-in-time decay. By quantifying the initial phase of relaxation, our\nmethod allows for the investigation of systems with large initial dissipation\nas long as the isoperimetric deficit is small enough. We include quantitative\nestimates of the solution in terms of its initial data, including the\n$C^{1}$-distance to the center manifold of circles and the displacement of the\nbarycenter.","main_category":"math.AP","categories":"math.AP","published":"2025-04-16T13:59:28Z"}
{"aid":"http://arxiv.org/abs/2504.12143v1","title":"ARCeR: an Agentic RAG for the Automated Definition of Cyber Ranges","summary":"The growing and evolving landscape of cybersecurity threats necessitates the\ndevelopment of supporting tools and platforms that allow for the creation of\nrealistic IT environments operating within virtual, controlled settings as\nCyber Ranges (CRs). CRs can be exploited for analyzing vulnerabilities and\nexperimenting with the effectiveness of devised countermeasures, as well as\nserving as training environments for building cyber security skills and\nabilities for IT operators. This paper proposes ARCeR as an innovative solution\nfor the automatic generation and deployment of CRs, starting from user-provided\ndescriptions in a natural language. ARCeR relies on the Agentic RAG paradigm,\nwhich allows it to fully exploit state-of-art AI technologies. Experimental\nresults show that ARCeR is able to successfully process prompts even in cases\nthat LLMs or basic RAG systems are not able to cope with. Furthermore, ARCeR is\nable to target any CR framework provided that specific knowledge is made\navailable to it.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-16T14:53:28Z"}
{"aid":"http://arxiv.org/abs/2504.12153v1","title":"Central-Upwind Scheme for the Phase-Transition Traffic Flow Model","summary":"Phase-transition models are an important family of non-equilibrium continuum\ntraffic flow models, offering properties like replicating complex traffic\nphenomena, maintaining anisotropy, and promising potentials for accommodating\nautomated vehicles. However, their complex mathematical characteristics such as\ndiscontinuous solution domains, pose numerical challenges and limit their\nexploration in traffic flow theory. This paper focuses on developing a robust\nand accurate numerical method for phase-transition traffic flow models: We\npropose a second-order semi-discrete central-upwind scheme specifically\ndesigned for discontinuous phase-transition models. This novel scheme\nincorporates the projection onto appropriate flow domains, ensuring enhanced\nhandling of discontinuities and maintaining physical consistency and accuracy.\nWe demonstrate the efficacy of the proposed scheme through extensive and\nchallenging numerical tests, showcasing their potential to facilitate further\nresearch and application in phase-transition traffic flow modeling. The ability\nof phase-transition models to embed the ``time-gap'' -- a crucial element in\nautomated traffic control -- as a conserved variable aligns seamlessly with the\ncontrol logic of automated vehicles, presenting significant potential for\nfuture applications, and the proposed numerical scheme now substantially\nfacilitates exploring such potentials.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-16T15:02:14Z"}
{"aid":"http://arxiv.org/abs/2504.12154v1","title":"Deep Generative Models for Bayesian Inference on High-Rate Sensor Data:\n  Applications in Automotive Radar and Medical Imaging","summary":"Deep generative models have been studied and developed primarily in the\ncontext of natural images and computer vision. This has spurred the development\nof (Bayesian) methods that use these generative models for inverse problems in\nimage restoration, such as denoising, inpainting, and super-resolution. In\nrecent years, generative modeling for Bayesian inference on sensory data has\nalso gained traction. Nevertheless, the direct application of generative\nmodeling techniques initially designed for natural images on raw sensory data\nis not straightforward, requiring solutions that deal with high dynamic range\nsignals acquired from multiple sensors or arrays of sensors that interfere with\neach other, and that typically acquire data at a very high rate. Moreover, the\nexact physical data-generating process is often complex or unknown. As a\nconsequence, approximate models are used, resulting in discrepancies between\nmodel predictions and the observations that are non-Gaussian, in turn\ncomplicating the Bayesian inverse problem. Finally, sensor data is often used\nin real-time processing or decision-making systems, imposing stringent\nrequirements on, e.g., latency and throughput. In this paper, we will discuss\nsome of these challenges and offer approaches to address them, all in the\ncontext of high-rate real-time sensing applications in automotive radar and\nmedical imaging.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-16T15:03:01Z"}
{"aid":"http://arxiv.org/abs/2504.12167v1","title":"RADLER: Radar Object Detection Leveraging Semantic 3D City Models and\n  Self-Supervised Radar-Image Learning","summary":"Semantic 3D city models are worldwide easy-accessible, providing accurate,\nobject-oriented, and semantic-rich 3D priors. To date, their potential to\nmitigate the noise impact on radar object detection remains under-explored. In\nthis paper, we first introduce a unique dataset, RadarCity, comprising 54K\nsynchronized radar-image pairs and semantic 3D city models. Moreover, we\npropose a novel neural network, RADLER, leveraging the effectiveness of\ncontrastive self-supervised learning (SSL) and semantic 3D city models to\nenhance radar object detection of pedestrians, cyclists, and cars.\nSpecifically, we first obtain the robust radar features via a SSL network in\nthe radar-image pretext task. We then use a simple yet effective feature fusion\nstrategy to incorporate semantic-depth features from semantic 3D city models.\nHaving prior 3D information as guidance, RADLER obtains more fine-grained\ndetails to enhance radar object detection. We extensively evaluate RADLER on\nthe collected RadarCity dataset and demonstrate average improvements of 5.46%\nin mean avarage precision (mAP) and 3.51% in mean avarage recall (mAR) over\nprevious radar object detection methods. We believe this work will foster\nfurther research on semantic-guided and map-supported radar object detection.\nOur project page is publicly available\nathttps://gpp-communication.github.io/RADLER .","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-16T15:18:56Z"}
{"aid":"http://arxiv.org/abs/2504.12172v1","title":"Poem Meter Classification of Recited Arabic Poetry: Integrating\n  High-Resource Systems for a Low-Resource Task","summary":"Arabic poetry is an essential and integral part of Arabic language and\nculture. It has been used by the Arabs to spot lights on their major events\nsuch as depicting brutal battles and conflicts. They also used it, as in many\nother languages, for various purposes such as romance, pride, lamentation, etc.\nArabic poetry has received major attention from linguistics over the decades.\nOne of the main characteristics of Arabic poetry is its special rhythmic\nstructure as opposed to prose. This structure is referred to as a meter.\nMeters, along with other poetic characteristics, are intensively studied in an\nArabic linguistic field called \"\\textit{Aroud}\". Identifying these meters for a\nverse is a lengthy and complicated process. It also requires technical\nknowledge in \\textit{Aruod}. For recited poetry, it adds an extra layer of\nprocessing. Developing systems for automatic identification of poem meters for\nrecited poems need large amounts of labelled data. In this study, we propose a\nstate-of-the-art framework to identify the poem meters of recited Arabic\npoetry, where we integrate two separate high-resource systems to perform the\nlow-resource task. To ensure generalization of our proposed architecture, we\npublish a benchmark for this task for future research.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-16T15:25:45Z"}
{"aid":"http://arxiv.org/abs/2504.12181v1","title":"Battery-aware Cyclic Scheduling in Energy-harvesting Federated Learning","summary":"Federated Learning (FL) has emerged as a promising framework for distributed\nlearning, but its growing complexity has led to significant energy consumption,\nparticularly from computations on the client side. This challenge is especially\ncritical in energy-harvesting FL (EHFL) systems, where device availability\nfluctuates due to limited and time-varying energy resources. We propose\nFedBacys, a battery-aware FL framework that introduces cyclic client\nparticipation based on users' battery levels to cope with these issues.\nFedBacys enables clients to save energy and strategically perform local\ntraining just before their designated transmission time by clustering clients\nand scheduling their involvement sequentially. This design minimizes redundant\ncomputation, reduces system-wide energy usage, and improves learning stability.\nOur experiments demonstrate that FedBacys outperforms existing approaches in\nterms of energy efficiency and performance consistency, exhibiting robustness\neven under non-i.i.d. training data distributions and with very infrequent\nbattery charging. This work presents the first comprehensive evaluation of\ncyclic client participation in EHFL, incorporating both communication and\ncomputation costs into a unified, resource-aware scheduling strategy.","main_category":"cs.LG","categories":"cs.LG,cs.IT,math.IT","published":"2025-04-16T15:38:38Z"}
{"aid":"http://arxiv.org/abs/2504.12195v1","title":"Validating and monitoring bibliographic and citation data in\n  OpenCitations collections","summary":"Purpose. The increasing emphasis on data quantity in research infrastructures\nhas highlighted the need for equally robust mechanisms ensuring data quality,\nparticularly in bibliographic and citation datasets. This paper addresses the\nchallenge of maintaining high-quality open research information within\nOpenCitations, a community-guided Open Science Infrastructure, by introducing\ntools for validating and monitoring bibliographic metadata and citation data.\n  Methods. We developed a custom validation tool tailored to the OpenCitations\nData Model (OCDM), designed to detect and explain ingestion errors from\nheterogeneous sources, whether due to upstream data inconsistencies or internal\nsoftware bugs. Additionally, a quality monitoring tool was created to track\nknown data issues post-publication. These tools were applied in two scenarios:\n(1) validating metadata and citations from Matilda, a potential future source,\nand (2) monitoring data quality in the existing OpenCitations Meta dataset.\n  Results. The validation tool successfully identified a variety of structural\nand semantic issues in the Matilda dataset, demonstrating its precision. The\nmonitoring tool enabled the detection of recurring problems in the\nOpenCitations Meta collection, as well as their quantification. Together, these\ntools proved effective in enhancing the reliability of OpenCitations' published\ndata.\n  Conclusion. The presented validation and monitoring tools represent a step\ntoward ensuring high-quality bibliographic data in open research\ninfrastructures, though they are limited to the data model adopted by\nOpenCitations. Future developments are aimed at expanding to additional data\nsources, with particular regard to crowdsourced data.","main_category":"cs.DL","categories":"cs.DL,H.3.7","published":"2025-04-16T15:47:44Z"}
{"aid":"http://arxiv.org/abs/2504.12197v1","title":"Beyond Patches: Mining Interpretable Part-Prototypes for Explainable AI","summary":"Deep learning has provided considerable advancements for multimedia systems,\nyet the interpretability of deep models remains a challenge. State-of-the-art\npost-hoc explainability methods, such as GradCAM, provide visual interpretation\nbased on heatmaps but lack conceptual clarity. Prototype-based approaches, like\nProtoPNet and PIPNet, offer a more structured explanation but rely on fixed\npatches, limiting their robustness and semantic consistency.\n  To address these limitations, a part-prototypical concept mining network\n(PCMNet) is proposed that dynamically learns interpretable prototypes from\nmeaningful regions. PCMNet clusters prototypes into concept groups, creating\nsemantically grounded explanations without requiring additional annotations.\nThrough a joint process of unsupervised part discovery and concept activation\nvector extraction, PCMNet effectively captures discriminative concepts and\nmakes interpretable classification decisions.\n  Our extensive experiments comparing PCMNet against state-of-the-art methods\non multiple datasets show that it can provide a high level of interpretability,\nstability, and robustness under clean and occluded scenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T15:48:21Z"}
{"aid":"http://arxiv.org/abs/2504.12217v1","title":"zkVC: Fast Zero-Knowledge Proof for Private and Verifiable Computing","summary":"In the context of cloud computing, services are held on cloud servers, where\nthe clients send their data to the server and obtain the results returned by\nserver. However, the computation, data and results are prone to tampering due\nto the vulnerabilities on the server side. Thus, verifying the integrity of\ncomputation is important in the client-server setting. The cryptographic method\nknown as Zero-Knowledge Proof (ZKP) is renowned for facilitating private and\nverifiable computing. ZKP allows the client to validate that the results from\nthe server are computed correctly without violating the privacy of the server's\nintellectual property. Zero-Knowledge Succinct Non-Interactive Argument of\nKnowledge (zkSNARKs), in particular, has been widely applied in various\napplications like blockchain and verifiable machine learning. Despite their\npopularity, existing zkSNARKs approaches remain highly computationally\nintensive. For instance, even basic operations like matrix multiplication\nrequire an extensive number of constraints, resulting in significant overhead.\nIn addressing this challenge, we introduce \\textit{zkVC}, which optimizes the\nZKP computation for matrix multiplication, enabling rapid proof generation on\nthe server side and efficient verification on the client side. zkVC integrates\noptimized ZKP modules, such as Constraint-reduced Polynomial Circuit (CRPC) and\nPrefix-Sum Query (PSQ), collectively yielding a more than 12-fold increase in\nproof speed over prior methods. The code is available at\nhttps://github.com/UCF-Lou-Lab-PET/zkformer","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-16T16:11:11Z"}
{"aid":"http://arxiv.org/abs/2504.12231v1","title":"Finite time blowup for Keller-Segel equation with logistic damping in\n  three dimensions","summary":"The Keller-Segel equation, a classical chemotaxis model, and many of its\nvariants have been extensively studied for decades. In this work, we focus on\n3D Keller-Segel equation with a quadratic logistic damping term $-\\mu \\rho^2$\n(modeling density-dependent mortality rate) and show the existence of\nfinite-time blowup solutions with nonnegative density and finite mass for any\n$\\mu \\in \\big[0,\\frac{1}{3}\\big)$. This range of $\\mu$ is sharp; for $\\mu \\ge\n\\frac{1}{3}$, the logistic damping effect suppresses the blowup as shown in\n[Kang-Stevens, 2016] and [Tello-Winkler, 2007]. A key ingredient is to\nconstruct a self-similar blowup solution to a related aggregation equation as\nan approximate solution, with subcritical scaling relative to the original\nmodel. Based on this construction, we employ a robust weighted $L^2$ method to\nprove the stability of this approximate solution, where modulation ODEs are\nintroduced to enforce local vanishing conditions for the perturbation lying in\na singular-weighted $L^2$ space. As a byproduct, we exhibit a new family of\ntype I blowup mechanisms for the classical 3D Keller-Segel equation.","main_category":"math.AP","categories":"math.AP","published":"2025-04-16T16:30:13Z"}
{"aid":"http://arxiv.org/abs/2504.12238v1","title":"Exceptional deficiency of non-Hermitian systems: high-dimensional\n  coalescence and dynamics","summary":"Exceptional points (EPs) are non-Hermitian singularities associated with the\ncoalescence of individual eigenvectors accompanied by the degeneracy of their\ncomplex energies. Here, we report the discovery of a generalization to the\nconcept of EP called exceptional deficiency (ED), which features the complete\ncoalescence of two eigenspaces with identical but arbitrarily large dimensions\nand the coincidence of entire spectral continua. The characteristics of the ED\nare studied using one-way coupled Hermitian and non-Hermitian lattices. The ED\ncan induce an anomalous absence and presence of non-Hermitian skin effect\n(NHSE) that transcends the topological bulk-edge correspondence of NHSE,\nresulting in unexpected synergistic skin-propagative dynamics. The conditions\nof the ED are also explored for unprecedented control of localization and\npropagation in non-Hermitian systems. These effects are experimentally observed\nusing active mechanical lattices. The discovery of ED opens multiple new\nfrontiers in non-Hermitian physics and can potentially resolve long-standing\nchallenges in related applications.","main_category":"quant-ph","categories":"quant-ph,physics.class-ph","published":"2025-04-16T16:43:42Z"}
{"aid":"http://arxiv.org/abs/2504.12277v1","title":"On D-spaces and Covering Properties","summary":"In this thesis, we introduce the subject of D-spaces and some of its most\nimportant open problems which are related to well known covering properties. We\nthen introduce a new approach for studying D-spaces and covering properties in\ngeneral. We start by defining a topology on the family of all principal\nultrafilters of a set $X$ called the principal ultrafilter topology. We show\nthat each open neighborhood assignment could be transformed uniquely to a\nspecial continuous map using the principal ultrafilter topology. We study some\nstructures related to this special continuous map in the category Top, then we\nobtain a characterization of D-spaces via this map. Finally, we prove some\nresults on Lindel\\\"of, paracompact, and metacompact spaces that are related to\nthe property D.","main_category":"math.GN","categories":"math.GN","published":"2025-04-16T17:35:51Z"}
{"aid":"http://arxiv.org/abs/2504.12298v1","title":"Projectively implemented altermagnetism in an exactly solvable quantum\n  spin liquid","summary":"Altermagnets are a new class of symmetry-compensated magnets with large spin\nsplittings. Here, we show that the notion of altermagnetism extends beyond the\nrealm of Landau-type order: we study exactly solvable $\\mathbb{Z}_2$ quantum\nspin(-orbital) liquids (QSL), which simultaneously support magnetic long-range\norder as well as fractionalization and $\\mathbb{Z}_2$ topological order. Our\nsymmetry analysis reveals that in this model three distinct types of\n``fractionalized altermagnets (AM$^*$)'' may emerge, which can be distinguished\nby their residual symmetries. Importantly, the fractionalized excitations of\nthese states carry an emergent $\\mathbb{Z}_2$ gauge charge, which implies that\nthey transform \\emph{projectively} under symmetry operations. Consequently, we\nshow that ``altermagnetic spin splittings'' are now encoded in a\nmomentum-dependent particle-hole asymmetry of the fermionic parton bands. We\ndiscuss consequences for experimental observables such as dynamical spin\nstructure factors and (nonlinear) thermal and spin transport.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci","published":"2025-04-16T17:59:01Z"}
{"aid":"http://arxiv.org/abs/2504.12616v1","title":"Graph-based Path Planning with Dynamic Obstacle Avoidance for Autonomous\n  Parking","summary":"Safe and efficient path planning in parking scenarios presents a significant\nchallenge due to the presence of cluttered environments filled with static and\ndynamic obstacles. To address this, we propose a novel and computationally\nefficient planning strategy that seamlessly integrates the predictions of\ndynamic obstacles into the planning process, ensuring the generation of\ncollision-free paths. Our approach builds upon the conventional Hybrid A star\nalgorithm by introducing a time-indexed variant that explicitly accounts for\nthe predictions of dynamic obstacles during node exploration in the graph, thus\nenabling dynamic obstacle avoidance. We integrate the time-indexed Hybrid A\nstar algorithm within an online planning framework to compute local paths at\neach planning step, guided by an adaptively chosen intermediate goal. The\nproposed method is validated in diverse parking scenarios, including\nperpendicular, angled, and parallel parking. Through simulations, we showcase\nour approach's potential in greatly improving the efficiency and safety when\ncompared to the state of the art spline-based planning method for parking\nsituations.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-17T03:43:20Z"}
{"aid":"http://arxiv.org/abs/2504.12657v1","title":"Photon Calibration Performance of KAGRA during the 4th Joint Observing\n  Run (O4)","summary":"KAGRA is a kilometer-scale cryogenic gravitational-wave (GW) detector in\nJapan. It joined the 4th joint observing run (O4) in May 2023 in collaboration\nwith the Laser Interferometer GW Observatory (LIGO) in the USA, and Virgo in\nItaly. After one month of observations, KAGRA entered a break period to enhance\nits sensitivity to GWs, and it is planned to rejoin O4 before its scheduled end\nin October 2025. To accurately recover the information encoded in the GW\nsignals, it is essential to properly calibrate the observed signals. We employ\na photon calibration (Pcal) system as a reference signal injector to calibrate\nthe output signals obtained from the telescope. In ideal future conditions, the\nuncertainty in Pcal could dominate the uncertainty in the observed data. In\nthis paper, we present the methods used to estimate the uncertainty in the Pcal\nsystems employed during KAGRA O4 and report an estimated system uncertainty of\n0.79%, which is three times lower than the uncertainty achieved in the previous\n3rd joint observing run (O3) in 2020. Additionally, we investigate the\nuncertainty in the Pcal laser power sensors, which had the highest impact on\nthe Pcal uncertainty, and estimate the beam positions on the KAGRA main mirror,\nwhich had the second highest impact. The Pcal systems in KAGRA are the first\nfully functional calibration systems for a cryogenic GW telescope. To avoid\ninterference with the KAGRA cryogenic systems, the Pcal systems incorporate\nunique features regarding their placement and the use of telephoto cameras,\nwhich can capture images of the mirror surface at almost normal incidence. As\nfuture GW telescopes, such as the Einstein Telescope, are expected to adopt\ncryogenic techniques, the performance of the KAGRA Pcal systems can serve as a\nvaluable reference.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-17T05:36:31Z"}
{"aid":"http://arxiv.org/abs/2504.12669v1","title":"A novel fast sweeping method for computing the attenuation operator\n  $t^*$ in absorbing media","summary":"$t^*$ represents the total path attenuation and characterizes the amplitude\ndecay of a propagating seismic wave. Calculating the attenuation operator $t^*$\nis typically required in seismic attenuation tomography. Traditional methods\nfor calculating $t^*$ require determining the ray path explicitly. However, ray\ntracing can be computationally intensive when processing large datasets, and\nconventional ray tracing techniques may fail even in mildly heterogeneous\nmedia. In this study, we propose a modified fast sweeping method (MFSM) to\nsolve the governing equation for $t^*$ without explicitly calculating the ray\npath. The approach consists of two main steps. First, the traveltime field is\ncalculated by numerically solving the eikonal equation using the fast sweeping\nmethod. Second, $t^*$ is computed by solving its governing equation with the\nMFSM, based on the discretization of the gradient of $t^*$ using an upwinding\nscheme derived from the traveltime gradient. The MFSM is rigorously validated\nthrough comparisons with analytical solutions and by examining $t^*$ errors\nunder grid refinement in both simple and complex models. Key performance\nmetrics, including convergence, number of iterations, and computation time, are\nevaluated. Two versions of the MFSM are developed for both Cartesian and\nspherical coordinate systems. We demonstrate the practical applicability of the\ndeveloped MFSM in calculating $t^*$ in North Island, and discuss the method's\nefficiency in estimating earthquake response spectra.","main_category":"physics.geo-ph","categories":"physics.geo-ph,physics.comp-ph","published":"2025-04-17T05:54:55Z"}
{"aid":"http://arxiv.org/abs/2504.12679v1","title":"TongUI: Building Generalized GUI Agents by Learning from Multimodal Web\n  Tutorials","summary":"Building Graphical User Interface (GUI) agents is a promising research\ndirection, which simulates human interaction with computers or mobile phones to\nperform diverse GUI tasks. However, a major challenge in developing generalized\nGUI agents is the lack of sufficient trajectory data across various operating\nsystems and applications, mainly due to the high cost of manual annotations. In\nthis paper, we propose the TongUI framework that builds generalized GUI agents\nby learning from rich multimodal web tutorials. Concretely, we crawl and\nprocess online GUI tutorials (such as videos and articles) into GUI agent\ntrajectory data, through which we produce the GUI-Net dataset containing 143K\ntrajectory data across five operating systems and more than 200 applications.\nWe develop the TongUI agent by fine-tuning Qwen2.5-VL-3B/7B models on GUI-Net,\nwhich show remarkable performance improvements on commonly used grounding and\nnavigation benchmarks, outperforming baseline agents about 10\\% on multiple\nbenchmarks, showing the effectiveness of the GUI-Net dataset and underscoring\nthe significance of our TongUI framework. We will fully open-source the code,\nthe GUI-Net dataset, and the trained models soon.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T06:15:56Z"}
{"aid":"http://arxiv.org/abs/2504.12686v1","title":"Rheology of dilute granular gases with hard-core and inverse power-law\n  potentials","summary":"The kinetic theory of dilute granular gases with hard-core and inverse\npower-law potentials is developed. The scattering process is studied\ntheoretically, which yields the relative speed and the impact parameter\ndependence of the scattering angle. The viscosity is derived from the Boltzmann\nequation and its temperature dependence is plotted. We also perform the direct\nsimulation Monte Carlo to check the validity of the theory.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech","published":"2025-04-17T06:26:46Z"}
{"aid":"http://arxiv.org/abs/2504.12700v1","title":"A Two-Phase Perspective on Deep Learning Dynamics","summary":"We propose that learning in deep neural networks proceeds in two phases: a\nrapid curve fitting phase followed by a slower compression or coarse graining\nphase. This view is supported by the shared temporal structure of three\nphenomena: grokking, double descent and the information bottleneck, all of\nwhich exhibit a delayed onset of generalization well after training error\nreaches zero. We empirically show that the associated timescales align in two\nrather different settings. Mutual information between hidden layers and input\ndata emerges as a natural progress measure, complementing circuit-based metrics\nsuch as local complexity and the linear mapping number. We argue that the\nsecond phase is not actively optimized by standard training algorithms and may\nbe unnecessarily prolonged. Drawing on an analogy with the renormalization\ngroup, we suggest that this compression phase reflects a principled form of\nforgetting, critical for generalization.","main_category":"hep-th","categories":"hep-th,cond-mat.dis-nn,cs.LG","published":"2025-04-17T06:57:37Z"}
{"aid":"http://arxiv.org/abs/2504.12725v1","title":"The $S$-resolvent estimates for the Dirac operator on hyperbolic and\n  spherical spaces","summary":"This seminal paper marks the beginning of our investigation into on the\nspectral theory based on $S$-spectrum applied to the Dirac operator on\nmanifolds. Specifically, we examine in detail the cases of the Dirac operator\n$\\mathcal{D}_H$ on hyperbolic space and the Dirac operator $\\mathcal{D}_S$ on\nthe spherical space, where these operators, and their squares $\\mathcal{D}_H^2$\nand $\\mathcal{D}_S^2$, can be written in a very explicit form. This fact is\nvery important for the application of the spectral theory on the $S$-spectrum.\nIn fact, let $T$ denote a (right) linear Clifford operator, the $S$-spectrum is\nassociated with a second-order polynomial in the operator $T$, specifically the\noperator defined as $ Q_s(T) := T^2 - 2s_0T + |s|^2. $ This allows us to\nassociate to the Dirac operator boundary conditions that can be of Dirichlet\ntype but also of Robin-like type. Moreover, our theory is not limited to\nHilbert modules; it is applicable to Banach modules as well. The spectral\ntheory based on the $S$-spectrum has gained increasing attention in recent\nyears, particularly as it aims to provide quaternionic quantum mechanics with a\nsolid mathematical foundation from the perspective of spectral theory. This\ntheory was extended to Clifford operators, and more recently, the spectral\ntheorem has been adapted to this broader context. The $S$-spectrum is crucial\nfor defining the so-called $S$-functional calculus for quaternionic and\nClifford operators in various forms. This includes bounded as well as unbounded\noperators, where suitable estimates of sectorial and bi-sectorial type for the\n$S$-resolvent operator are essential for the convergence of the Dunford\nintegrals in this setting.","main_category":"math.FA","categories":"math.FA","published":"2025-04-17T08:06:18Z"}
{"aid":"http://arxiv.org/abs/2504.12727v1","title":"Efficient Major Transition Exchange under Distributional and Dual\n  Priority-respecting Constraints","summary":"Many real matching markets encounter distributional and fairness constraints.\nMotivated by the Chinese Major Transition Program (CMT), this paper studies the\ndesign of exchange mechanisms within a fresh framework of both distributional\nand dual priority-respecting constraints. Specifically, each student has an\ninitial assigned major and applies to transfer to a more desirable one. A\nstudent can successfully transfer majors only if they obtain eligibility from\nboth their initial major and the applied major. Each major has a dual priority:\na strict priority over current students who wish to transfer out and a strict\npriority over students from other majors who wish to transfer in. Additionally,\neach major faces a ceiling constraint and a floor constraint to regulate\nstudent distribution. We show that the existing mechanisms of CMT result in\navoidable inefficiencies, and propose two mechanisms that can match students to\nmajors in an efficient way as well as respecting each major's distributional\nand dual priority. The efficient mechanisms are based on a proposed solution\nconcept: eligibility maximization (EM), and two processes for identifying\nimprovement cycles--specifically, transfer-in exchangeable cycles and\ntransfer-out exchangeable cycles.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-17T08:09:05Z"}
{"aid":"http://arxiv.org/abs/2504.12728v1","title":"Seierstad Sufficient Conditions for Stochastic Optimal Control Problems\n  with Infinite Horizon","summary":"In this note we consider a problem of stochastic optimal control with the\ninfinite-time horizon. We present analogues of the Seierstad sufficient\nconditions of overtaking optimality based on the dual variables stochastic\ndescribed by BSDEs appeared in the Bismut-Pontryagin maximum principle.","main_category":"math.OC","categories":"math.OC","published":"2025-04-17T08:09:23Z"}
{"aid":"http://arxiv.org/abs/2504.12731v1","title":"Nonlinear spin dynamics across Néel phase transition in\n  ferromagnetic/antiferromagnetic multilayers","summary":"We observe strongly nonlinear spin dynamics in ferro-/antiferro-magnetic\nmultilayers, controlled by the number of bilayers in the system, layer\nthicknesses, as well as temperature, peaking in magnitude near the N\\'eel point\nof the antiferromagnetic layers just above room temperature. Well above the\nN\\'eel transition, the individual ferromagnetic layers are exchange decoupled\nand resonate independently. As the temperature is lowered toward the N\\'eel\npoint, the ferromagnetic proximity effect through the thin antiferromagnetic\nspacers transforms the system into a weakly coupled macrospin chain along the\nfilm normal, which exhibits pronounced standing spin-wave resonance modes,\ncomparable in intensity to the uniform resonance in the ferromagnetic layers.\nThese findings are supported by our micromagnetic simulations showing clear\nspin-wave profiles with precessional phase lag along the macrospin chain. Well\nbelow the N\\'eel transition, the FeMn layers order strongly\nantiferromagnetically and exchange-pin the ferromagnetic layers to effectively\nmake the multilayer one macrospin. The appearance and intensity of the\nhigh-frequency spin-wave modes can thus be conveniently controlled by thermal\ngating the multilayer. The nonlinearity in the microwave response of the\ndemonstrated material can approach 100\\%, large compared to nonlinear materials\nused in e.g. optics, with second-harmonic generation often at the single\npercentage level.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-17T08:14:01Z"}
{"aid":"http://arxiv.org/abs/2504.12741v1","title":"Chaos indicators for non-linear dynamics in circular particle\n  accelerators","summary":"The understanding of non-linear effects in circular storage rings and\ncolliders based on superconducting magnets is a key issue for the luminosity\nthe beam lifetime optimisation. A detailed analysis of the multidimensional\nphase space requires a large computing effort when many variants of the\nmagnetic lattice, representing the realisation of magnetic errors or\nconfigurations for performance optimisation, have to be considered. Dynamic\nindicators for chaos detection have proven to be very effective in finding and\ndistinguishing the weakly-chaotic regions of phase space where diffusion takes\nplace and regions that remain stable over time scales in the order of multiple\nhours of continuous operation. This paper explores the use of advanced chaos\nindicators, including the Fast Lyapunov Indicator with Birkhoff weights and the\nReverse Error Method, in realistic lattice models for the CERN Large Hadron\nCollider (LHC). Their convergence, predictive power, and potential to define a\nmagnetic lattice quality factor linked to long-term dynamic aperture are\nassessed. The results demonstrate the efficiency of these indicators in\nidentifying chaotic dynamics, offering valuable insights of these chaos\nindicators for optimising accelerator lattices with reduced computational cost\ncompared to the classical approach based on CPU-demanding long-term tracking\ncampaigns.","main_category":"physics.acc-ph","categories":"physics.acc-ph,nlin.CD","published":"2025-04-17T08:30:15Z"}
{"aid":"http://arxiv.org/abs/2504.12749v1","title":"LAD-Reasoner: Tiny Multimodal Models are Good Reasoners for Logical\n  Anomaly Detection","summary":"Recent advances in industrial anomaly detection have highlighted the need for\ndeeper logical anomaly analysis, where unexpected relationships among objects,\ncounts, and spatial configurations must be identified and explained. Existing\napproaches often rely on large-scale external reasoning modules or elaborate\npipeline designs, hindering practical deployment and interpretability. To\naddress these limitations, we introduce a new task, Reasoning Logical Anomaly\nDetection (RLAD), which extends traditional anomaly detection by incorporating\nlogical reasoning. We propose a new framework, LAD-Reasoner, a customized tiny\nmultimodal language model built on Qwen2.5-VL 3B. Our approach leverages a\ntwo-stage training paradigm that first employs Supervised Fine-Tuning (SFT) for\nfine-grained visual understanding, followed by Group Relative Policy\nOptimization (GRPO) to refine logical anomaly detection and enforce coherent,\nhuman-readable reasoning. Crucially, reward signals are derived from both the\ndetection accuracy and the structural quality of the outputs, obviating the\nneed for building chain of thought (CoT) reasoning data. Experiments on the\nMVTec LOCO AD dataset show that LAD-Reasoner, though significantly smaller,\nmatches the performance of Qwen2.5-VL-72B in accuracy and F1 score, and further\nexcels in producing concise and interpretable rationales. This unified design\nreduces reliance on large models and complex pipelines, while offering\ntransparent and interpretable insights into logical anomaly detection. Code and\ndata will be released.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T08:41:23Z"}
{"aid":"http://arxiv.org/abs/2504.12750v1","title":"Spatial Functional Deep Neural Network Model: A New Prediction Algorithm","summary":"Accurate prediction of spatially dependent functional data is critical for\nvarious engineering and scientific applications. In this study, a spatial\nfunctional deep neural network model was developed with a novel non-linear\nmodeling framework that seamlessly integrates spatial dependencies and\nfunctional predictors using deep learning techniques. The proposed model\nextends classical scalar-on-function regression by incorporating a spatial\nautoregressive component while leveraging functional deep neural networks to\ncapture complex non-linear relationships. To ensure a robust estimation, the\nmethodology employs an adaptive estimation approach, where the spatial\ndependence parameter was first inferred via maximum likelihood estimation,\nfollowed by non-linear functional regression using deep learning. The\neffectiveness of the proposed model was evaluated through extensive Monte Carlo\nsimulations and an application to Brazilian COVID-19 data, where the goal was\nto predict the average daily number of deaths. Comparative analysis with\nmaximum likelihood-based spatial functional linear regression and functional\ndeep neural network models demonstrates that the proposed algorithm\nsignificantly improves predictive performance. The results for the Brazilian\nCOVID-19 data showed that while all models achieved similar mean squared error\nvalues over the training modeling phase, the proposed model achieved the lowest\nmean squared prediction error in the testing phase, indicating superior\ngeneralization ability.","main_category":"stat.ME","categories":"stat.ME,stat.AP","published":"2025-04-17T08:44:29Z"}
{"aid":"http://arxiv.org/abs/2504.12760v1","title":"Analyzing multi-center randomized trials with covariate adjustment while\n  accounting for clustering","summary":"Augmented inverse probability weighting (AIPW) and G-computation with\ncanonical generalized linear models have become increasingly popular for\nestimating the average treatment effect in randomized experiments. These\nestimators leverage outcome prediction models to adjust for imbalances in\nbaseline covariates across treatment arms, improving statistical power compared\nto unadjusted analyses, while maintaining control over Type I error rates, even\nwhen the models are misspecified. Practical application of such estimators\noften overlooks the clustering present in multi-center clinical trials. Even\nwhen prediction models account for center effects, this neglect can degrade the\ncoverage of confidence intervals, reduce the efficiency of the estimators, and\ncomplicate the interpretation of the corresponding estimands. These issues are\nparticularly pronounced for estimators of counterfactual means, though less\nsevere for those of the average treatment effect, as demonstrated through Monte\nCarlo simulations and supported by theoretical insights. To address these\nchallenges, we develop efficient estimators of counterfactual means and the\naverage treatment effect in a random center. These extract information from\nbaseline covariates by relying on outcome prediction models, but remain\nunbiased in large samples when these models are misspecified. We also introduce\nan accompanying inference framework inspired by random-effects meta-analysis\nand relevant for settings where data from many small centers are being\nanalyzed. Adjusting for center effects yields substantial gains in efficiency,\nespecially when treatment effect heterogeneity across centers is large. Monte\nCarlo simulations and application to the WASH Benefits Bangladesh study\ndemonstrate adequate performance of the proposed methods.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-17T08:56:01Z"}
{"aid":"http://arxiv.org/abs/2504.12818v1","title":"An etude on a renormalization","summary":"In this paper, we study renormalization, that is, the procedure for\neliminating singularities, for a special model using both combinatorial\ntechniques in the framework of working with formal series, and using a limit\ntransition in a standard multidimensional integral, taking into account the\nremoval of the singular components. Special attention is paid to the\ncomparative analysis of the two views on the problem. It is remarkably that the\ndivergences, which have the same form in one approach, acquire a different\nnature in another approach and lead to interesting consequences. A special\ndeformation of the spectrum is used as regularization.","main_category":"math-ph","categories":"math-ph,hep-th,math.CA,math.MP","published":"2025-04-17T10:22:01Z"}
{"aid":"http://arxiv.org/abs/2504.12825v1","title":"TwoSquared: 4D Generation from 2D Image Pairs","summary":"Despite the astonishing progress in generative AI, 4D dynamic object\ngeneration remains an open challenge. With limited high-quality training data\nand heavy computing requirements, the combination of hallucinating unseen\ngeometry together with unseen movement poses great challenges to generative\nmodels. In this work, we propose TwoSquared as a method to obtain a 4D\nphysically plausible sequence starting from only two 2D RGB images\ncorresponding to the beginning and end of the action. Instead of directly\nsolving the 4D generation problem, TwoSquared decomposes the problem into two\nsteps: 1) an image-to-3D module generation based on the existing generative\nmodel trained on high-quality 3D assets, and 2) a physically inspired\ndeformation module to predict intermediate movements. To this end, our method\ndoes not require templates or object-class-specific prior knowledge and can\ntake in-the-wild images as input. In our experiments, we demonstrate that\nTwoSquared is capable of producing texture-consistent and geometry-consistent\n4D sequences only given 2D images.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T10:39:52Z"}
{"aid":"http://arxiv.org/abs/2504.12830v1","title":"Questions: A Taxonomy for Critical Reflection in Machine-Supported\n  Decision-Making","summary":"Decision-makers run the risk of relying too much on machine recommendations.\nExplainable AI, a common strategy for calibrating reliance, has mixed and even\nnegative effects, such as increasing overreliance. To cognitively engage the\ndecision-maker and to facilitate a deliberate decision-making process, we\npropose a potential `reflection machine' that supports critical reflection\nabout the pending decision, including the machine recommendation. Reflection\nhas been shown to improve critical thinking and reasoning, and thus\ndecision-making. One way to stimulate reflection is to ask relevant questions.\nTo systematically create questions, we present a question taxonomy inspired by\nSocratic questions and human-centred explainable AI. This taxonomy can\ncontribute to the design of such a `reflection machine' that asks\ndecision-makers questions. Our work is part of the growing research on\nhuman-machine collaborations that goes beyond the paradigm of machine\nrecommendations and explanations, and aims to enable greater human oversight as\nrequired by the European AI Act.","main_category":"cs.HC","categories":"cs.HC,cs.CY","published":"2025-04-17T10:44:08Z"}
{"aid":"http://arxiv.org/abs/2504.12855v1","title":"Amplitudes and partial wave unitarity bounds","summary":"We develop a formalism, based on spinor-helicity techniques, to generalize\nthe formulation of partial wave unitarity bounds. We discuss unitarity bounds\nfor $N \\to M$ (with $N,M \\geq 2$) scattering processes -- relevant for\nhigh-energy future colliders -- and spin-2 or higher-spin theories -- relevant\nfor effective field theories of gravity -- that are not approachable by\nstandard methods. Moreover, we emphasize the power and complementarity of\npositivity and partial wave unitarity bounds to constrain the parameter space\nof effective field theories.","main_category":"hep-ph","categories":"hep-ph,hep-th","published":"2025-04-17T11:22:34Z"}
{"aid":"http://arxiv.org/abs/2504.12864v1","title":"Unbiased Quantum Error Mitigation Without Reliance on an Accurate Error\n  Model","summary":"Probabilistic error cancellation is a quantum error mitigation technique\ncapable of producing unbiased computation results but requires an accurate\nerror model. Constructing this model involves estimating a set of parameters,\nwhich, in the worst case, may scale exponentially with the number of qubits. In\nthis paper, we introduce a method called spacetime noise inversion, revealing\nthat unbiased quantum error mitigation can be achieved with just a single\naccurately measured error parameter and a sampler of Pauli errors. The error\nsampler can be efficiently implemented in conjunction with quantum error\ncorrection. We provide rigorous analyses of bias and cost, showing that the\ncost of measuring the parameter and sampling errors is low -- comparable to the\ncost of the computation itself. Moreover, our method is robust to the\nfluctuation of error parameters, a limitation of unbiased quantum error\nmitigation in practice. These findings highlight the potential of integrating\nquantum error mitigation with error correction as a promising approach to\nsuppress computational errors in the early fault-tolerant era.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T11:42:34Z"}
{"aid":"http://arxiv.org/abs/2504.12901v1","title":"Control of blow-up profiles for the mass-critical focusing nonlinear\n  Schrödinger equation on bounded domains","summary":"In this paper, we consider the mass-critical focusing nonlinear Schr\\\"odinger\non bounded two-dimensional domains with Dirichlet boundary conditions. In the\nabsence of control, it is well-known that free solutions starting from initial\ndata sufficiently large can blow-up. More precisely, given a finite number of\npoints, there exists particular profiles blowing up exactly at these points at\nthe blow-up time. For pertubations of these profiles, we show that, with the\nhelp of an appropriate nonlinear feedback law located in an open set containing\nthe blow-up points, the blow-up can be prevented from happening. More\nspecifically, we construct a small-time control acting just before the blow-up\ntime. The solution may then be extended globally in time. This is the first\nresult of control for blow-up profiles for nonlinear Schr\\\"odinger type\nequations. Assuming further a geometrical control condition on the support of\nthe control, we are able to prove a null-controllability result for such\nblow-up profiles. Finally, we discuss possible extensions to three-dimensional\ndomains.","main_category":"math.AP","categories":"math.AP,math.OC","published":"2025-04-17T12:46:00Z"}
{"aid":"http://arxiv.org/abs/2504.12959v1","title":"Rethinking Temporal Fusion with a Unified Gradient Descent View for 3D\n  Semantic Occupancy Prediction","summary":"We present GDFusion, a temporal fusion method for vision-based 3D semantic\noccupancy prediction (VisionOcc). GDFusion opens up the underexplored aspects\nof temporal fusion within the VisionOcc framework, focusing on both temporal\ncues and fusion strategies. It systematically examines the entire VisionOcc\npipeline, identifying three fundamental yet previously overlooked temporal\ncues: scene-level consistency, motion calibration, and geometric\ncomplementation. These cues capture diverse facets of temporal evolution and\nmake distinct contributions across various modules in the VisionOcc framework.\nTo effectively fuse temporal signals across heterogeneous representations, we\npropose a novel fusion strategy by reinterpreting the formulation of vanilla\nRNNs. This reinterpretation leverages gradient descent on features to unify the\nintegration of diverse temporal information, seamlessly embedding the proposed\ntemporal cues into the network. Extensive experiments on nuScenes demonstrate\nthat GDFusion significantly outperforms established baselines. Notably, on\nOcc3D benchmark, it achieves 1.4\\%-4.8\\% mIoU improvements and reduces memory\nconsumption by 27\\%-72\\%.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T14:05:33Z"}
{"aid":"http://arxiv.org/abs/2504.12969v1","title":"Lessons from commissioning of the cryogenic system for the\n  Short-Baseline Neutrino Detector at Fermilab","summary":"Results from commissioning and first year of operations of the cryogenic\nsystem of the Short-Baseline Neutrino Detector (SBND) and its membrane cryostat\ninstalled at the Fermi National Accelerator Laboratory are described. The SBND\ndetector is installed in a 200 m$^3$ membrane cryostat filled with liquid\nargon, which serves both as target and as active media. For the correct\noperation of the detector, the liquid argon must be kept in very stable thermal\nconditions while the contamination of electronegative impurities must be\nconsistently kept at the level of small fractions of parts per billion. The\ndetector is operated in Booster Neutrino Beams (BNB) at Fermilab for the search\nof sterile neutrinos and measurements of neutrino-argon cross sections. The\ncryostat and the cryogenic systems also serve as prototypes for the much larger\nequipment to be used for the LBNF/DUNE experiment. Since its installation in\n2018-2023 and cooldown in spring of 2024, the cryostat and the cryogenic system\nhave been commissioned to support the detector operations. The lessons learned\nthrough installation, testing, commissioning, cooldown, and initial operations\nare described.","main_category":"physics.ins-det","categories":"physics.ins-det,physics.acc-ph","published":"2025-04-17T14:19:34Z"}
{"aid":"http://arxiv.org/abs/2504.12984v1","title":"A Virtual Machine for Arbitrary Low-Precision GPGPU Computation in LLM\n  Serving","summary":"Serving Large Language Models (LLMs) is critical for AI-powered applications\nbut demands substantial computational resources, particularly in memory\nbandwidth and computational throughput. Low-precision computation has emerged\nas a key technique to improve efficiency while reducing resource consumption.\nExisting approaches for generating low-precision kernels are limited to weight\nbit widths that are powers of two and suffer from suboptimal performance due to\nhigh-level GPU programming abstractions. These abstractions restrict critical\noptimizations, such as fine-grained register management and optimized memory\naccess patterns, which are essential for efficient low-precision computations.\nIn this paper, we introduce a virtual machine (VM) designed for General-Purpose\nGPU (GPGPU) computing, enabling support for low-precision data types with\narbitrary bit widths while maintaining GPU programmability. The proposed VM\nfeatures a thread-block-level programming model, a hierarchical memory space, a\nnovel algebraic layout system, and extensive support for diverse low-precision\ndata types. VM programs are compiled into highly efficient GPU programs with\nautomatic vectorization and instruction selection. Extensive experiments\ndemonstrate that our VM efficiently supports a full spectrum of low-precision\ndata types, and outperforms state-of-the-art low-precision kernels on their\nsupported types. Compared to existing compilers like Triton and Ladder, as well\nas hand-optimized kernels such as QuantLLM and Marlin, our VM achieves\nperformance improvements of 1.75x, 2.61x, 1.29x and 1.03x, respectively.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.PL","published":"2025-04-17T14:45:03Z"}
{"aid":"http://arxiv.org/abs/2504.12999v1","title":"GSAC: Leveraging Gaussian Splatting for Photorealistic Avatar Creation\n  with Unity Integration","summary":"Photorealistic avatars have become essential for immersive applications in\nvirtual reality (VR) and augmented reality (AR), enabling lifelike interactions\nin areas such as training simulations, telemedicine, and virtual collaboration.\nThese avatars bridge the gap between the physical and digital worlds, improving\nthe user experience through realistic human representation. However, existing\navatar creation techniques face significant challenges, including high costs,\nlong creation times, and limited utility in virtual applications. Manual\nmethods, such as MetaHuman, require extensive time and expertise, while\nautomatic approaches, such as NeRF-based pipelines often lack efficiency,\ndetailed facial expression fidelity, and are unable to be rendered at a speed\nsufficent for real-time applications. By involving several cutting-edge modern\ntechniques, we introduce an end-to-end 3D Gaussian Splatting (3DGS) avatar\ncreation pipeline that leverages monocular video input to create a scalable and\nefficient photorealistic avatar directly compatible with the Unity game engine.\nOur pipeline incorporates a novel Gaussian splatting technique with customized\npreprocessing that enables the user of \"in the wild\" monocular video capture,\ndetailed facial expression reconstruction and embedding within a fully rigged\navatar model. Additionally, we present a Unity-integrated Gaussian Splatting\nAvatar Editor, offering a user-friendly environment for VR/AR application\ndevelopment. Experimental results validate the effectiveness of our\npreprocessing pipeline in standardizing custom data for 3DGS training and\ndemonstrate the versatility of Gaussian avatars in Unity, highlighting the\nscalability and practicality of our approach.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-17T15:10:14Z"}
{"aid":"http://arxiv.org/abs/2504.13007v1","title":"Detecting light dark matter with prompt-delayed events in neutrino\n  experiments","summary":"We demonstrate the prompt-delayed signals induced by knockout neutrons from\nthe quasi-elastic scattering in neutrino experiments provides a new avenue for\ndetecting light dark matter. As an illustration, we consider the detection of\natmospheric dark matter in the liquid scintillator detectors. The results show\nthat the constraint on the DM-nucleon interaction from KamLAND is approximately\none order of magnitude more stringent than those obtained from the elastic\nnuclear recoil signals in dark matter direct detection experiments.\nFurthermore, a larger volume neutrino experiment, such as JUNO, is expected to\nsignificantly enhance the light dark matter detection sensitivity through the\nquasi-elastic scattering.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO","published":"2025-04-17T15:16:06Z"}
{"aid":"http://arxiv.org/abs/2504.13013v1","title":"Minkowski chirality: a measure of reflectional asymmetry of convex\n  bodies","summary":"Using an optimal containment approach, we quantify the asymmetry of convex\nbodies in $\\mathbb{R}^n$ with respect to reflections across affine subspaces of\na given dimension. We prove general inequalities relating these ''Minkowski\nchirality'' measures to Banach--Mazur distances and to each other, and prove\ntheir continuity with respect to the Hausdorff distance. In the planar case, we\ndetermine the reflection axes at which the Minkowski chirality of triangles and\nparallelograms is attained, and show that $\\sqrt{2}$ is a tight upper bound on\nthe chirality in both cases.","main_category":"math.MG","categories":"math.MG","published":"2025-04-17T15:19:06Z"}
{"aid":"http://arxiv.org/abs/2504.13023v1","title":"ChatEXAONEPath: An Expert-level Multimodal Large Language Model for\n  Histopathology Using Whole Slide Images","summary":"Recent studies have made significant progress in developing large language\nmodels (LLMs) in the medical domain, which can answer expert-level questions\nand demonstrate the potential to assist clinicians in real-world clinical\nscenarios. Studies have also witnessed the importance of integrating various\nmodalities with the existing LLMs for a better understanding of complex\nclinical contexts, which are innately multi-faceted by nature. Although studies\nhave demonstrated the ability of multimodal LLMs in histopathology to answer\nquestions from given images, they lack in understanding of thorough clinical\ncontext due to the patch-level data with limited information from public\ndatasets. Thus, developing WSI-level MLLMs is significant in terms of the\nscalability and applicability of MLLMs in histopathology. In this study, we\nintroduce an expert-level MLLM for histopathology using WSIs, dubbed as\nChatEXAONEPath. We present a retrieval-based data generation pipeline using\n10,094 pairs of WSIs and histopathology reports from The Cancer Genome Atlas\n(TCGA). We also showcase an AI-based evaluation protocol for a comprehensive\nunderstanding of the medical context from given multimodal information and\nevaluate generated answers compared to the original histopathology reports. We\ndemonstrate the ability of diagnosing the given histopathology images using\nChatEXAONEPath with the acceptance rate of 62.9% from 1,134 pairs of WSIs and\nreports. Our proposed model can understand pan-cancer WSIs and clinical context\nfrom various cancer types. We argue that our proposed model has the potential\nto assist clinicians by comprehensively understanding complex morphology of\nWSIs for cancer diagnosis through the integration of multiple modalities.","main_category":"cs.CL","categories":"cs.CL,cs.CV","published":"2025-04-17T15:33:17Z"}
{"aid":"http://arxiv.org/abs/2504.13024v1","title":"Riemannian Patch Assignment Gradient Flows","summary":"This paper introduces patch assignment flows for metric data labeling on\ngraphs. Labelings are determined by regularizing initial local labelings\nthrough the dynamic interaction of both labels and label assignments across the\ngraph, entirely encoded by a dictionary of competing labeled patches and\nmediated by patch assignment variables. Maximal consistency of patch\nassignments is achieved by geometric numerical integration of a Riemannian\nascent flow, as critical point of a Lagrangian action functional. Experiments\nillustrate properties of the approach, including uncertainty quantification of\nlabel assignments.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T15:34:58Z"}
{"aid":"http://arxiv.org/abs/2504.13025v1","title":"Magnetism-Enhanced Strong Electron-Phonon Coupling in Infinite-Layer\n  Nickelate","summary":"Intriguing analogies between the nickelates and the cuprates provide a\npromising avenue for unraveling the microscopic mechanisms underlying\nhigh-$T_c$ superconductivity. While electron correlation effects in the\nnickelates have been extensively studied, the role of electron-phonon coupling\n(EPC) remains highly controversial. Here, by taking pristine LaNiO$_2$ as an\nexemplar nickelate, we present an in-depth study of EPC for both the\nnon-magnetic (NM) and the $C$-type antiferromagnetic ($C$-AFM) phase using\nadvanced density functional theory methods without invoking $U$ or other free\nparameters. The weak EPC strength $\\lambda$ in the NM phase is found to be\ngreatly enhanced ($\\sim$4$\\times$) due to the presence of magnetism in the\n$C$-AFM phase. This enhancement arises from strong interactions between the\nflat bands associated with the Ni-3$d_{z^2}$ orbitals and the low-frequency\nphonon modes driven by the vibrations of Ni and La atoms. The resulting phonon\nsoftening is shown to yield a distinctive kink in the electronic structure\naround 15 meV, which would provide an experimentally testable signature of our\npredictions. Our study highlights the critical role of local magnetic moments\nand interply EPC in the nickelate.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.supr-con","published":"2025-04-17T15:35:10Z"}
{"aid":"http://arxiv.org/abs/2504.13031v1","title":"Degrees of Freedom of Holographic MIMO -- Fundamental Theory and\n  Analytical Methods","summary":"Holographic multiple-input multiple-output (MIMO) is envisioned as one of the\nmost promising technology enablers for future sixth-generation (6G) networks.\nThe use of electrically large holographic surface (HoloS) antennas has the\npotential to significantly boost the spatial multiplexing gain by increasing\nthe number of degrees of freedom (DoF), even in line-of-sight (LoS) channels.\nIn this context, the research community has shown a growing interest in\ncharacterizing the fundamental limits of this technology. In this paper, we\ncompare the two analytical methods commonly utilized in the literature for this\npurpose: the cut-set integral and the self-adjoint operator. We provide a\ndetailed description of both methods and discuss their advantages and\nlimitations.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-17T15:41:28Z"}
{"aid":"http://arxiv.org/abs/2504.13037v1","title":"Towards Cardiac MRI Foundation Models: Comprehensive Visual-Tabular\n  Representations for Whole-Heart Assessment and Beyond","summary":"Cardiac magnetic resonance imaging is the gold standard for non-invasive\ncardiac assessment, offering rich spatio-temporal views of the cardiac anatomy\nand physiology. Patient-level health factors, such as demographics, metabolic,\nand lifestyle, are known to substantially influence cardiovascular health and\ndisease risk, yet remain uncaptured by CMR alone. To holistically understand\ncardiac health and to enable the best possible interpretation of an\nindividual's disease risk, CMR and patient-level factors must be jointly\nexploited within an integrated framework. Recent multi-modal approaches have\nbegun to bridge this gap, yet they often rely on limited spatio-temporal data\nand focus on isolated clinical tasks, thereby hindering the development of a\ncomprehensive representation for cardiac health evaluation. To overcome these\nlimitations, we introduce ViTa, a step toward foundation models that delivers a\ncomprehensive representation of the heart and a precise interpretation of\nindividual disease risk. Leveraging data from 42,000 UK Biobank participants,\nViTa integrates 3D+T cine stacks from short-axis and long-axis views, enabling\na complete capture of the cardiac cycle. These imaging data are then fused with\ndetailed tabular patient-level factors, enabling context-aware insights. This\nmulti-modal paradigm supports a wide spectrum of downstream tasks, including\ncardiac phenotype and physiological feature prediction, segmentation, and\nclassification of cardiac and metabolic diseases within a single unified\nframework. By learning a shared latent representation that bridges rich imaging\nfeatures and patient context, ViTa moves beyond traditional, task-specific\nmodels toward a universal, patient-specific understanding of cardiac health,\nhighlighting its potential to advance clinical utility and scalability in\ncardiac analysis.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-17T15:46:19Z"}
{"aid":"http://arxiv.org/abs/2504.13044v1","title":"The Dissipation Theory of Aging: A Quantitative Analysis Using a\n  Cellular Aging Map","summary":"We propose a new theory for aging based on dynamical systems and provide a\ndata-driven computational method to quantify the changes at the cellular level.\nWe use ergodic theory to decompose the dynamics of changes during aging and\nshow that aging is fundamentally a dissipative process within biological\nsystems, akin to dynamical systems where dissipation occurs due to\nnon-conservative forces. To quantify the dissipation dynamics, we employ a\ntransformer-based machine learning algorithm to analyze gene expression data,\nincorporating age as a token to assess how age-related dissipation is reflected\nin the embedding space. By evaluating the dynamics of gene and age embeddings,\nwe provide a cellular aging map (CAM) and identify patterns indicative of\ndivergence in gene embedding space, nonlinear transitions, and entropy\nvariations during aging for various tissues and cell types. Our results provide\na novel perspective on aging as a dissipative process and introduce a\ncomputational framework that enables measuring age-related changes with\nmolecular resolution.","main_category":"q-bio.QM","categories":"q-bio.QM,cs.LG,physics.bio-ph","published":"2025-04-17T15:59:15Z"}
{"aid":"http://arxiv.org/abs/2504.13046v1","title":"Variance-Reduced Fast Operator Splitting Methods for Stochastic\n  Generalized Equations","summary":"We develop two classes of variance-reduced fast operator splitting methods to\napproximate solutions of both finite-sum and stochastic generalized equations.\nOur approach integrates recent advances in accelerated fixed-point methods,\nco-hypomonotonicity, and variance reduction. First, we introduce a class of\nvariance-reduced estimators and establish their variance-reduction bounds. This\nclass covers both unbiased and biased instances and comprises common estimators\nas special cases, including SVRG, SAGA, SARAH, and Hybrid-SGD. Next, we design\na novel accelerated variance-reduced forward-backward splitting (FBS) algorithm\nusing these estimators to solve finite-sum and stochastic generalized\nequations. Our method achieves both $\\mathcal{O}(1/k^2)$ and $o(1/k^2)$\nconvergence rates on the expected squared norm $\\mathbb{E}[ \\|\nG_{\\lambda}x^k\\|^2]$ of the FBS residual $G_{\\lambda}$, where $k$ is the\niteration counter. Additionally, we establish, for the first time, almost sure\nconvergence rates and almost sure convergence of iterates to a solution in\nstochastic accelerated methods. Unlike existing stochastic fixed-point\nalgorithms, our methods accommodate co-hypomonotone operators, which\npotentially include nonmonotone problems arising from recent applications. We\nfurther specify our method to derive an appropriate variant for each stochastic\nestimator -- SVRG, SAGA, SARAH, and Hybrid-SGD -- demonstrating that they\nachieve the best-known complexity for each without relying on enhancement\ntechniques. Alternatively, we propose an accelerated variance-reduced\nbackward-forward splitting (BFS) method, which attains similar convergence\nrates and oracle complexity as our FBS method. Finally, we validate our results\nthrough several numerical experiments and compare their performance.","main_category":"math.OC","categories":"math.OC,stat.ML","published":"2025-04-17T16:02:20Z"}
{"aid":"http://arxiv.org/abs/2504.13085v1","title":"Tackling Social Bias against the Poor: A Dataset and Taxonomy on\n  Aporophobia","summary":"Eradicating poverty is the first goal in the United Nations Sustainable\nDevelopment Goals. However, aporophobia -- the societal bias against people\nliving in poverty -- constitutes a major obstacle to designing, approving and\nimplementing poverty-mitigation policies. This work presents an initial step\ntowards operationalizing the concept of aporophobia to identify and track\nharmful beliefs and discriminative actions against poor people on social media.\nIn close collaboration with non-profits and governmental organizations, we\nconduct data collection and exploration. Then we manually annotate a corpus of\nEnglish tweets from five world regions for the presence of (1) direct\nexpressions of aporophobia, and (2) statements referring to or criticizing\naporophobic views or actions of others, to comprehensively characterize the\nsocial media discourse related to bias and discrimination against the poor.\nBased on the annotated data, we devise a taxonomy of categories of aporophobic\nattitudes and actions expressed through speech on social media. Finally, we\ntrain several classifiers and identify the main challenges for automatic\ndetection of aporophobia in social networks. This work paves the way towards\nidentifying, tracking, and mitigating aporophobic views on social media at\nscale.","main_category":"cs.CY","categories":"cs.CY,cs.CL","published":"2025-04-17T16:53:14Z"}
{"aid":"http://arxiv.org/abs/2504.13087v1","title":"The $h$-vectors of toric ideals of odd cycle compositions revisited","summary":"Let $G$ be a graph consisting of $s$ odd cycles that all share a common\nvertex. Bhaskara, Higashitani, and Shibu Deepthi recently computed the\n$h$-polynomial for the quotient ring $R/I_G$, where $I_G$ is the toric ideal of\n$G$, in terms of the number and sizes of odd cycles in the graph. The purpose\nof this note is to prove the stronger result that these toric ideals are\ngeometrically vertex decomposable, which allows us to deduce the result of\nBhaskara, Higashitani, and Shibu Deepthi about the $h$-polyhomial as a\ncorollary.","main_category":"math.AC","categories":"math.AC,math.CO","published":"2025-04-17T16:55:17Z"}
{"aid":"http://arxiv.org/abs/2504.13095v1","title":"Should We Tailor the Talk? Understanding the Impact of Conversational\n  Styles on Preference Elicitation in Conversational Recommender Systems","summary":"Conversational recommender systems (CRSs) provide users with an interactive\nmeans to express preferences and receive real-time personalized\nrecommendations. The success of these systems is heavily influenced by the\npreference elicitation process. While existing research mainly focuses on what\nquestions to ask during preference elicitation, there is a notable gap in\nunderstanding what role broader interaction patterns including tone, pacing,\nand level of proactiveness play in supporting users in completing a given task.\nThis study investigates the impact of different conversational styles on\npreference elicitation, task performance, and user satisfaction with CRSs. We\nconducted a controlled experiment in the context of scientific literature\nrecommendation, contrasting two distinct conversational styles, high\ninvolvement (fast paced, direct, and proactive with frequent prompts) and high\nconsiderateness (polite and accommodating, prioritizing clarity and user\ncomfort) alongside a flexible experimental condition where users could switch\nbetween the two. Our results indicate that adapting conversational strategies\nbased on user expertise and allowing flexibility between styles can enhance\nboth user satisfaction and the effectiveness of recommendations in CRSs.\nOverall, our findings hold important implications for the design of future\nCRSs.","main_category":"cs.HC","categories":"cs.HC,cs.IR","published":"2025-04-17T17:01:17Z"}
{"aid":"http://arxiv.org/abs/2504.13112v1","title":"Hadamard product in deep learning: Introduction, Advances and Challenges","summary":"While convolution and self-attention mechanisms have dominated architectural\ndesign in deep learning, this survey examines a fundamental yet understudied\nprimitive: the Hadamard product. Despite its widespread implementation across\nvarious applications, the Hadamard product has not been systematically analyzed\nas a core architectural primitive. We present the first comprehensive taxonomy\nof its applications in deep learning, identifying four principal domains:\nhigher-order correlation, multimodal data fusion, dynamic representation\nmodulation, and efficient pairwise operations. The Hadamard product's ability\nto model nonlinear interactions with linear computational complexity makes it\nparticularly valuable for resource-constrained deployments and edge computing\nscenarios. We demonstrate its natural applicability in multimodal fusion tasks,\nsuch as visual question answering, and its effectiveness in representation\nmasking for applications including image inpainting and pruning. This\nsystematic review not only consolidates existing knowledge about the Hadamard\nproduct's role in deep learning architectures but also establishes a foundation\nfor future architectural innovations. Our analysis reveals the Hadamard product\nas a versatile primitive that offers compelling trade-offs between\ncomputational efficiency and representational power, positioning it as a\ncrucial component in the deep learning toolkit.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T17:26:29Z"}
{"aid":"http://arxiv.org/abs/2504.13144v1","title":"Bayesian model-data comparison incorporating theoretical uncertainties","summary":"Accurate comparisons between theoretical models and experimental data are\ncritical for scientific progress. However, inferred model parameters can vary\nsignificantly with the chosen physics model, highlighting the importance of\nproperly accounting for theoretical uncertainties. In this article, we\nexplicitly incorporate these uncertainties using Gaussian processes that model\nthe domain of validity of theoretical models, integrating prior knowledge about\nwhere a theory applies and where it does not. We demonstrate the effectiveness\nof this approach using two systems: a simple ball drop experiment and\nmulti-stage heavy-ion simulations. In both cases incorporating model\ndiscrepancy leads to improved parameter estimates, with systematic improvements\nobserved as additional experimental observables are integrated.","main_category":"hep-ph","categories":"hep-ph,nucl-th,physics.data-an","published":"2025-04-17T17:53:39Z"}
{"aid":"http://arxiv.org/abs/2504.13152v1","title":"St4RTrack: Simultaneous 4D Reconstruction and Tracking in the World","summary":"Dynamic 3D reconstruction and point tracking in videos are typically treated\nas separate tasks, despite their deep connection. We propose St4RTrack, a\nfeed-forward framework that simultaneously reconstructs and tracks dynamic\nvideo content in a world coordinate frame from RGB inputs. This is achieved by\npredicting two appropriately defined pointmaps for a pair of frames captured at\ndifferent moments. Specifically, we predict both pointmaps at the same moment,\nin the same world, capturing both static and dynamic scene geometry while\nmaintaining 3D correspondences. Chaining these predictions through the video\nsequence with respect to a reference frame naturally computes long-range\ncorrespondences, effectively combining 3D reconstruction with 3D tracking.\nUnlike prior methods that rely heavily on 4D ground truth supervision, we\nemploy a novel adaptation scheme based on a reprojection loss. We establish a\nnew extensive benchmark for world-frame reconstruction and tracking,\ndemonstrating the effectiveness and efficiency of our unified, data-driven\nframework. Our code, model, and benchmark will be released.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T17:55:58Z"}
{"aid":"http://arxiv.org/abs/2504.14862v1","title":"FERMI: Flexible Radio Mapping with a Hybrid Propagation Model and\n  Scalable Autonomous Data Collection","summary":"Communication is fundamental for multi-robot collaboration, with accurate\nradio mapping playing a crucial role in predicting signal strength between\nrobots. However, modeling radio signal propagation in large and occluded\nenvironments is challenging due to complex interactions between signals and\nobstacles. Existing methods face two key limitations: they struggle to predict\nsignal strength for transmitter-receiver pairs not present in the training set,\nwhile also requiring extensive manual data collection for modeling, making them\nimpractical for large, obstacle-rich scenarios. To overcome these limitations,\nwe propose FERMI, a flexible radio mapping framework. FERMI combines\nphysics-based modeling of direct signal paths with a neural network to capture\nenvironmental interactions with radio signals. This hybrid model learns radio\nsignal propagation more efficiently, requiring only sparse training data.\nAdditionally, FERMI introduces a scalable planning method for autonomous data\ncollection using a multi-robot team. By increasing parallelism in data\ncollection and minimizing robot travel costs between regions, overall data\ncollection efficiency is significantly improved. Experiments in both simulation\nand real-world scenarios demonstrate that FERMI enables accurate signal\nprediction and generalizes well to unseen positions in complex environments. It\nalso supports fully autonomous data collection and scales to different team\nsizes, offering a flexible solution for creating radio maps. Our code is\nopen-sourced at https://github.com/ymLuo1214/Flexible-Radio-Mapping.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-21T05:03:19Z"}
{"aid":"http://arxiv.org/abs/2504.14868v1","title":"Twin Co-Adaptive Dialogue for Progressive Image Generation","summary":"Modern text-to-image generation systems have enabled the creation of\nremarkably realistic and high-quality visuals, yet they often falter when\nhandling the inherent ambiguities in user prompts. In this work, we present\nTwin-Co, a framework that leverages synchronized, co-adaptive dialogue to\nprogressively refine image generation. Instead of a static generation process,\nTwin-Co employs a dynamic, iterative workflow where an intelligent dialogue\nagent continuously interacts with the user. Initially, a base image is\ngenerated from the user's prompt. Then, through a series of synchronized\ndialogue exchanges, the system adapts and optimizes the image according to\nevolving user feedback. The co-adaptive process allows the system to\nprogressively narrow down ambiguities and better align with user intent.\nExperiments demonstrate that Twin-Co not only enhances user experience by\nreducing trial-and-error iterations but also improves the quality of the\ngenerated images, streamlining the creative process across various\napplications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T05:37:07Z"}
{"aid":"http://arxiv.org/abs/2504.14876v1","title":"Initiation Route of Coronal Mass Ejections: II. The Role of Filament\n  Mass","summary":"The thorough understanding on the initiation of coronal mass ejections\n(CMEs), which is manifested as a slow rise of pre-eruptive structures before\nthe impulsive ejection in kinematics, is the key for forecasting the solar\neruptions. In our previous work, we showed that the slow rise of a hot flux\nrope with coronal mass density is caused by the moderate magnetic reconnection\noccurring in the hyperbolic flux tube (HFT) combined with the torus\ninstability. However, it remains unclear how the initiation process varies when\na filament is present in the pre-eruptive flux rope. In this work, we reveal\nthe complete initiation route of a CME containing filament mass with a\nstate-of-the-art full-magnetohydrodynamics simulation. The comprehensive\nanalyses show that the filament mass has an important impact on the CME\ninitiation through triggering and driving the slow rise of flux rope with its\ndrainage, besides the contributions of HFT reconnection and torus instability.\nFinally, in combination with our previous work, we propose that the enhanced\ndrainage of filament mass and various features related to the HFT reconnection,\nsuch as, the split of pre-eruptive structure and the pre-flare loops and X-ray\nemissions, can serve as the precursors of CME initiation in observations.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-21T06:06:24Z"}
{"aid":"http://arxiv.org/abs/2504.14887v1","title":"Quantitative Analysis of Cell Membrane Tension in Time-Series Imaging\n  and A Minimal Lattice Model of Single Cell Motion","summary":"Cell membrane tension directly influences various cellular functions. In this\nstudy, we developed a method to estimate surface tension from time-series data.\nWe obtained the curvature-velocity relationship from time-series of binarized\ncell shape images, and the effective surface tension term was calculated from\nlinear regression.\n  During the process, we observed an S-shaped pattern in the curvature-velocity\nrelationship. To understand the dynamics, we constructed a minimal lattice\nmodel describing single-cell motion. The model consists of surface tension and\nprotrusion formation, and the characteristic parameters are obtained from\nexperimental observations. We found that similar patterns emerged in the\ncurvature-velocity relationship.","main_category":"q-bio.CB","categories":"q-bio.CB","published":"2025-04-21T06:30:29Z"}
{"aid":"http://arxiv.org/abs/2504.14894v1","title":"Never too Cocky to Cooperate: An FIM and RL-based USV-AUV Collaborative\n  System for Underwater Tasks in Extreme Sea Conditions","summary":"This paper develops a novel unmanned surface vehicle (USV)-autonomous\nunderwater vehicle (AUV) collaborative system designed to enhance underwater\ntask performance in extreme sea conditions. The system integrates a dual\nstrategy: (1) high-precision multi-AUV localization enabled by Fisher\ninformation matrix-optimized USV path planning, and (2) reinforcement\nlearning-based cooperative planning and control method for multi-AUV task\nexecution. Extensive experimental evaluations in the underwater data collection\ntask demonstrate the system's operational feasibility, with quantitative\nresults showing significant performance improvements over baseline methods. The\nproposed system exhibits robust coordination capabilities between USV and AUVs\nwhile maintaining stability in extreme sea conditions. To facilitate\nreproducibility and community advancement, we provide an open-source simulation\ntoolkit available at: https://github.com/360ZMEM/USV-AUV-colab .","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-21T06:47:46Z"}
{"aid":"http://arxiv.org/abs/2504.14917v1","title":"POLYRAG: Integrating Polyviews into Retrieval-Augmented Generation for\n  Medical Applications","summary":"Large language models (LLMs) have become a disruptive force in the industry,\nintroducing unprecedented capabilities in natural language processing, logical\nreasoning and so on. However, the challenges of knowledge updates and\nhallucination issues have limited the application of LLMs in medical scenarios,\nwhere retrieval-augmented generation (RAG) can offer significant assistance.\nNevertheless, existing retrieve-then-read approaches generally digest the\nretrieved documents, without considering the timeliness, authoritativeness and\ncommonality of retrieval. We argue that these approaches can be suboptimal,\nespecially in real-world applications where information from different sources\nmight conflict with each other and even information from the same source in\ndifferent time scale might be different, and totally relying on this would\ndeteriorate the performance of RAG approaches. We propose PolyRAG that\ncarefully incorporate judges from different perspectives and finally integrate\nthe polyviews for retrieval augmented generation in medical applications. Due\nto the scarcity of real-world benchmarks for evaluation, to bridge the gap we\npropose PolyEVAL, a benchmark consists of queries and documents collected from\nreal-world medical scenarios (including medical policy, hospital & doctor\ninquiry and healthcare) with multiple tagging (e.g., timeliness,\nauthoritativeness) on them. Extensive experiments and analysis on PolyEVAL have\ndemonstrated the superiority of PolyRAG.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-21T07:35:24Z"}
{"aid":"http://arxiv.org/abs/2504.14970v1","title":"Gapless behavior in a two-leg spin ladder with bond randomness","summary":"We successfully synthesized\n[Cu$_2$(AcO)$_4$($p$-Py-V-$p$-F)$_2$]$\\cdot$4CHCl$_3$, a verdazyl-based complex\nwith a paddlewheel structure comprising two Cu atoms, which induces strong\nantiferromagnetic (AF) exchange interactions between Cu spins, generating a\nnonmagnetic singlet state at low temperatures. Two primary exchange\ninteractions between radical spins generate a spin-1/2 AF two-leg ladder. In\naddition, two possible positional configurations of the F atom in the complex\ncreate four different overlap patterns of molecular orbitals, introducing bond\nrandomness in the spin ladder. The observed experimental behaviors, such as the\nCurie tail in the magnetic susceptibility and the gapless gradual increase in\nthe magnetization curve, are attributed to a broad distribution of excitation\nenergies and a few orphan spins in the random-singlet (RS) state that are\nstabilized by bond randomness. The low-temperature specific heat exhibits a\ntemperature dependence with $\\propto 1/|{\\rm{ln}}T|^3$, demonstrating the\nformation of the RS state in unfrustrated systems. We also consider the effect\nof restricted patterns of exchange interactions and one-dimensional nature of\nthe system on the RS state.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci","published":"2025-04-21T08:57:57Z"}
{"aid":"http://arxiv.org/abs/2504.15023v1","title":"Dust-obscured Galaxies with Broken Power-law Spectral Energy\n  Distributions Discovered by UNIONS","summary":"We report on the spectral energy distributions (SEDs) of infrared-bright\ndust-obscured galaxies (DOGs) with $(i - [22])_{\\rm AB} \\geq 7.0$. Using\nphotometry from the deep and wide Ultraviolet Near-Infrared Optical Northern\nSurvey, combined with near-IR and mid-IR data from the UKIRT Infrared Deep Sky\nSurvey and the Wide-field Infrared Survey Explorer, we successfully identified\n382 DOGs in $\\sim$ 170 deg$^2$. Among them, the vast majority (376 DOGs) were\nclassified into two subclasses: bump DOGs (132/376) and power-law (PL) DOGs\n(244/376), which are dominated by star formation and active galactic nucleus\n(AGN), respectively. Through the SED analysis, we found that roughly half\n(120/244) of the PL DOGs show ``broken'' power-law SEDs. The significant red\nslope from optical to near-IR in the SEDs of these ``broken power-law DOGs''\n(BPL DOGs) probably reflects their large amount of dust extinction. In other\nwords, BPL DOGs are more heavily obscured AGNs, compared to PL DOGs with\nnon-broken power-law SEDs.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-21T11:11:41Z"}
{"aid":"http://arxiv.org/abs/2504.15024v1","title":"Extending Collinear Density Functionals to Noncollinear Cases under\n  Periodic Boundary Condition","summary":"Accurate modeling of spin-orbit coupling and noncollinear magnetism in\nmaterials requires noncollinear density functionals within the two-component\ngeneralized Kohn-Sham (GKS) framework, yet constructing and implementing\nnoncollinear functionals remains challenging. Recently, a methodology was\nproposed to extend collinear functionals into noncollinear ones, successfully\ndefining noncollinear functionals and their derivatives. However, the initial\nimplementation involved a systematic approach to differentiate energy over\ndensity matrix elements rather than the derivatives of the energy functional\nwith respect to density, presenting challenges for integration with periodic\nboundary condition-density functional theory (PBC-DFT) software. We have\nderived a novel set of working equations based on the original methodology,\nwhich provides noncollinear energy functionals and their derivatives. These\nworking equations have been implemented in our noncollinear functional ensemble\nnamed NCXC, ensuring numerical stability and transferability without the need\nfor incorporating derivatives of basis functions. This implementation is\nexpected to facilitate compatibility with most DFT software packages. We\ndemonstrate some preliminary applications in periodic systems, including\nnoncollinear magnetism in spin spirals, band structures in topological\ninsulators, and band gaps in semiconducting inorganic materials, using NCXC.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-21T11:11:59Z"}
{"aid":"http://arxiv.org/abs/2504.15053v1","title":"One pathogen does not an epidemic make: A review of interacting\n  contagions, diseases, beliefs, and stories","summary":"From pathogens and computer viruses to genes and memes, contagion models have\nfound widespread utility across the natural and social sciences. Despite their\nsuccess and breadth of adoption, the approach and structure of these models\nremain surprisingly siloed by field. Given the siloed nature of their\ndevelopment and widespread use, one persistent assumption is that a given\ncontagion can be studied in isolation, independently from what else might be\nspreading in the population. In reality, countless contagions of biological and\nsocial nature interact within hosts (interacting with existing beliefs, or the\nimmune system) and across hosts (interacting in the environment, or affecting\ntransmission mechanisms). Additionally, from a modeling perspective, we know\nthat relaxing these assumptions has profound effects on the physics and\ntranslational implications of the models. Here, we review mechanisms for\ninteractions in social and biological contagions, as well as the models and\nframeworks developed to include these interactions in the study of the\ncontagions. We highlight existing problems related to the inference of\ninteractions and to the scalability of mathematical models and identify\npromising avenues of future inquiries. In doing so, we highlight the need for\ninterdisciplinary efforts under a unified science of contagions and for\nremoving a common dichotomy between social and biological contagions.","main_category":"physics.soc-ph","categories":"physics.soc-ph,q-bio.PE","published":"2025-04-21T12:26:27Z"}
{"aid":"http://arxiv.org/abs/2504.15056v1","title":"Semileptonic and nonleptonic $\\bar{B}_{s}\\to D_{sJ}$ decays in covariant\n  light-front approach","summary":"In this work, we investigate the $\\bar{B}_{s}\\to D_{sJ}$ transitions in\ncovariant light-front approach, where $D_{sJ}$ denotes an s-wave or p-wave\n$c\\bar{s}$ meson state. We first obtain the transition form factors within the\nframework of the quark model, and then apply the obtained form factors to\nobtain the branching fractions of semileptonic and nonleptonic decays. We also\ncompare our results with experimental data and other theoretical predictions.\nWe find that some branching fractions are sizable and might be accessible at\nthe LHC and future $e^{+}$-$e^{-}$ colliders. Our work is expected to be of\ngreat value for establishing corresponding decay channels, and also be helpful\nin understanding the non-perturbative QCD dynamics.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-21T12:32:18Z"}
{"aid":"http://arxiv.org/abs/2504.15093v1","title":"Rethinking the Potential of Multimodality in Collaborative Problem\n  Solving Diagnosis with Large Language Models","summary":"Detecting collaborative and problem-solving behaviours from digital traces to\ninterpret students' collaborative problem solving (CPS) competency is a\nlong-term goal in the Artificial Intelligence in Education (AIEd) field.\nAlthough multimodal data and advanced models are argued to have the potential\nto detect complex CPS behaviours, empirical evidence on their value remains\nlimited with some contrasting evidence. In this study, we investigated the\npotential of multimodal data to improve model performance in diagnosing 78\nsecondary school students' CPS subskills and indicators in authentic\neducational settings. In particular, text embeddings from verbal data and\nacoustic embeddings from audio data were used in a multimodal classification\nmodel for CPS diagnosis. Both unimodal and multimodal transformer-based models\noutperformed traditional models in detecting CPS classes. Although the\ninclusion of multimodality did not improve the performance of traditional\nunimodal models, its integration into transformer-based models demonstrated\nimproved performance for diagnosing social-cognitive CPS classes compared to\nunimodal transformer-based models. Based on the results, the paper argues that\nmultimodality and the selection of a particular modelling technique should not\nbe taken for granted to achieve the best performance in the automated detection\nof every CPS subskill and indicator. Rather, their value is limited to certain\ntypes of CPS indicators, affected by the complexity of the labels, and\ndependent on the composition of indicators in the dataset. We conclude the\npaper by discussing the required nuance when considering the value of LLMs and\nmultimodality in automated CPS diagnosis, highlighting the need for human-AI\ncomplementarity, and proposing the exploration of relevant model architectures\nand techniques to improve CPS diagnosis in authentic educational contexts.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-21T13:25:55Z"}
{"aid":"http://arxiv.org/abs/2504.15119v1","title":"FRB cosmology with the RM-PRS Luminosity Correlation","summary":"Fast Radio Bursts (FRBs) have emerged as a powerful tool for cosmological\nstudies, particularly through the dispersion measure-redshift ($\\mathrm{DM}-z$)\nrelation. This work proposes a novel calibration method for FRBs using the\nYang-Li-Zhang (YLZ) empirical relation, which links the rotation measure (RM)\nof FRBs to the luminosity of their associated persistent radio sources (PRS).\nWe demonstrate that this approach provides independent constraints on\ncosmological parameters, bypassing limitations inherent to traditional\n$\\mathrm{DM}-z$ method. Utilizing the current sample of four YLZ-calibrated\nFRBs, we derive a Hubble constant measurement of $H_0 =\n86.18_{-14.99}^{+18.03}\\ \\mathrm{km\\ s^{-1}\\ Mpc^{-1}}$ (68\\% CL). Monte Carlo\nsimulations indicate that a future catalog of 400 FRB-PSR systems could reduce\nthe relative uncertainty of $H_0$ to 4.5\\%. Combining YLZ-calibrated FRBs with\n$\\mathrm{DM}-z$ sample reveals critical synergies: joint analysis of equalized\nsamples ($N=100$ for both methods) reduces the relative uncertainty of $H_0$ to\n2.9\\%, mainly because the incorporation of PRS observations substantially\nmitigates the degeneracy between the parameters such as IGM baryon mass\nfraction ($f_{\\rm IGM}$) and other cosmological parameters inherent to the\n$\\mathrm{DM}-z$ relation.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph","published":"2025-04-21T14:17:03Z"}
{"aid":"http://arxiv.org/abs/2504.15120v1","title":"Kuwain 1.5B: An Arabic SLM via Language Injection","summary":"Enhancing existing models with new knowledge is a crucial aspect of AI\ndevelopment. This paper introduces a novel method for integrating a new\nlanguage into a large language model (LLM). Our approach successfully\nincorporates a previously unseen target language into an existing LLM without\ncompromising its prior knowledge. We trained a tiny model with 1.5 billion\nparameters named Kuwain by injecting the Arabic language into a small\nopen-source model mainly trained in English. Our method demonstrates\nsignificant improvements in Arabic language performance, with an average 8%\nimprovement across various benchmarks, while retaining the model's existing\nknowledge with a minimum amount of the original model's data. This offers a\ncost-effective alternative to training a comprehensive model in both English\nand Arabic. The results highlight the potential for efficient, targeted\nlanguage model expansion without extensive retraining or resource-intensive\nprocesses.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-21T14:17:25Z"}
{"aid":"http://arxiv.org/abs/2504.15135v1","title":"KGMEL: Knowledge Graph-Enhanced Multimodal Entity Linking","summary":"Entity linking (EL) aligns textual mentions with their corresponding entities\nin a knowledge base, facilitating various applications such as semantic search\nand question answering. Recent advances in multimodal entity linking (MEL) have\nshown that combining text and images can reduce ambiguity and improve alignment\naccuracy. However, most existing MEL methods overlook the rich structural\ninformation available in the form of knowledge-graph (KG) triples. In this\npaper, we propose KGMEL, a novel framework that leverages KG triples to enhance\nMEL. Specifically, it operates in three stages: (1) Generation: Produces\nhigh-quality triples for each mention by employing vision-language models based\non its text and images. (2) Retrieval: Learns joint mention-entity\nrepresentations, via contrastive learning, that integrate text, images, and\n(generated or KG) triples to retrieve candidate entities for each mention. (3)\nReranking: Refines the KG triples of the candidate entities and employs large\nlanguage models to identify the best-matching entity for the mention. Extensive\nexperiments on benchmark datasets demonstrate that KGMEL outperforms existing\nmethods. Our code and datasets are available at:\nhttps://github.com/juyeonnn/KGMEL.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.CL","published":"2025-04-21T14:38:44Z"}
{"aid":"http://arxiv.org/abs/2504.15149v1","title":"Cosmological Constraints with Void Lensing I: the Simulation-Based\n  Inference Framework","summary":"We present a Simulation-Based Inference (SBI) framework for cosmological\nparameter estimation via void lensing analysis. Despite the absence of an\nanalytical model of void lensing, SBI can effectively learn posterior\ndistributions through forward modeling of mock data. We develop a forward\nmodeling pipeline that accounts for both cosmology and the galaxy-halo\nconnection. By training a neural density estimator on simulated data, we infer\nthe posteriors of two cosmological parameters, $\\Omega_m$ and $S_8$. Validation\ntests are conducted on posteriors derived from different cosmological\nparameters and a fiducial sample. The results demonstrate that SBI provides\nunbiased estimates of mean values and accurate uncertainties. These findings\nhighlight the potential to apply void lensing analysis to observational data\neven without an analytical void lensing model.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-21T14:52:56Z"}
{"aid":"http://arxiv.org/abs/2504.15208v1","title":"Compute-Optimal LLMs Provably Generalize Better With Scale","summary":"Why do larger language models generalize better? To investigate this\nquestion, we develop generalization bounds on the pretraining objective of\nlarge language models (LLMs) in the compute-optimal regime, as described by the\nChinchilla scaling laws. We introduce a novel, fully empirical Freedman-type\nmartingale concentration inequality that tightens existing bounds by accounting\nfor the variance of the loss function. This generalization bound can be\ndecomposed into three interpretable components: the number of parameters per\ntoken, the loss variance, and the quantization error at a fixed bitrate. As\ncompute-optimal language models are scaled up, the number of parameters per\ndata point remains constant; however, both the loss variance and the\nquantization error decrease, implying that larger models should have smaller\ngeneralization gaps. We examine why larger models tend to be more quantizable\nfrom an information theoretic perspective, showing that the rate at which they\ncan integrate new information grows more slowly than their capacity on the\ncompute-optimal frontier. From these findings we produce a scaling law for the\ngeneralization gap, with bounds that become predictably stronger with scale.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-21T16:26:56Z"}
{"aid":"http://arxiv.org/abs/2504.15217v1","title":"DRAGON: Distributional Rewards Optimize Diffusion Generative Models","summary":"We present Distributional RewArds for Generative OptimizatioN (DRAGON), a\nversatile framework for fine-tuning media generation models towards a desired\noutcome. Compared with traditional reinforcement learning with human feedback\n(RLHF) or pairwise preference approaches such as direct preference optimization\n(DPO), DRAGON is more flexible. It can optimize reward functions that evaluate\neither individual examples or distributions of them, making it compatible with\na broad spectrum of instance-wise, instance-to-distribution, and\ndistribution-to-distribution rewards. Leveraging this versatility, we construct\nnovel reward functions by selecting an encoder and a set of reference examples\nto create an exemplar distribution. When cross-modality encoders such as CLAP\nare used, the reference examples may be of a different modality (e.g., text\nversus audio). Then, DRAGON gathers online and on-policy generations, scores\nthem to construct a positive demonstration set and a negative set, and\nleverages the contrast between the two sets to maximize the reward. For\nevaluation, we fine-tune an audio-domain text-to-music diffusion model with 20\ndifferent reward functions, including a custom music aesthetics model, CLAP\nscore, Vendi diversity, and Frechet audio distance (FAD). We further compare\ninstance-wise (per-song) and full-dataset FAD settings while ablating multiple\nFAD encoders and reference sets. Over all 20 target rewards, DRAGON achieves an\n81.45% average win rate. Moreover, reward functions based on exemplar sets\nindeed enhance generations and are comparable to model-based rewards. With an\nappropriate exemplar set, DRAGON achieves a 60.95% human-voted music quality\nwin rate without training on human preference annotations. As such, DRAGON\nexhibits a new approach to designing and optimizing reward functions for\nimproving human-perceived quality. Sound examples at\nhttps://ml-dragon.github.io/web.","main_category":"cs.SD","categories":"cs.SD,cs.LG","published":"2025-04-21T16:41:40Z"}
{"aid":"http://arxiv.org/abs/2504.15219v1","title":"EvalAgent: Discovering Implicit Evaluation Criteria from the Web","summary":"Evaluation of language model outputs on structured writing tasks is typically\nconducted with a number of desirable criteria presented to human evaluators or\nlarge language models (LLMs). For instance, on a prompt like \"Help me draft an\nacademic talk on coffee intake vs research productivity\", a model response may\nbe evaluated for criteria like accuracy and coherence. However, high-quality\nresponses should do more than just satisfy basic task requirements. An\neffective response to this query should include quintessential features of an\nacademic talk, such as a compelling opening, clear research questions, and a\ntakeaway. To help identify these implicit criteria, we introduce EvalAgent, a\nnovel framework designed to automatically uncover nuanced and task-specific\ncriteria. EvalAgent first mines expert-authored online guidance. It then uses\nthis evidence to propose diverse, long-tail evaluation criteria that are\ngrounded in reliable external sources. Our experiments demonstrate that the\ngrounded criteria produced by EvalAgent are often implicit (not directly stated\nin the user's prompt), yet specific (high degree of lexical precision).\nFurther, EvalAgent criteria are often not satisfied by initial responses but\nthey are actionable, such that responses can be refined to satisfy them.\nFinally, we show that combining LLM-generated and EvalAgent criteria uncovers\nmore human-valued criteria than using LLMs alone.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-21T16:43:50Z"}
{"aid":"http://arxiv.org/abs/2504.15225v1","title":"M$^2$AD: Multi-Sensor Multi-System Anomaly Detection through Global\n  Scoring and Calibrated Thresholding","summary":"With the widespread availability of sensor data across industrial and\noperational systems, we frequently encounter heterogeneous time series from\nmultiple systems. Anomaly detection is crucial for such systems to facilitate\npredictive maintenance. However, most existing anomaly detection methods are\ndesigned for either univariate or single-system multivariate data, making them\ninsufficient for these complex scenarios. To address this, we introduce\nM$^2$AD, a framework for unsupervised anomaly detection in multivariate time\nseries data from multiple systems. M$^2$AD employs deep models to capture\nexpected behavior under normal conditions, using the residuals as indicators of\npotential anomalies. These residuals are then aggregated into a global anomaly\nscore through a Gaussian Mixture Model and Gamma calibration. We theoretically\ndemonstrate that this framework can effectively address heterogeneity and\ndependencies across sensors and systems. Empirically, M$^2$AD outperforms\nexisting methods in extensive evaluations by 21% on average, and its\neffectiveness is demonstrated on a large-scale real-world case study on 130\nassets in Amazon Fulfillment Centers. Our code and results are available at\nhttps://github.com/sarahmish/M2AD.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-21T16:57:46Z"}
{"aid":"http://arxiv.org/abs/2504.15235v1","title":"Cascade IPG Observer for Underwater Robot State Estimation","summary":"This paper presents a novel cascade nonlinear observer framework for inertial\nstate estimation. It tackles the problem of intermediate state estimation when\nexternal localization is unavailable or in the event of a sensor outage. The\nproposed observer comprises two nonlinear observers based on a recently\ndeveloped iteratively preconditioned gradient descent (IPG) algorithm. It takes\nthe inputs via an IMU preintegration model where the first observer is a\nquaternion-based IPG. The output for the first observer is the input for the\nsecond observer, estimating the velocity and, consequently, the position. The\nproposed observer is validated on a public underwater dataset and a real-world\nexperiment using our robot platform. The estimation is compared with an\nextended Kalman filter (EKF) and an invariant extended Kalman filter (InEKF).\nResults demonstrate that our method outperforms these methods regarding better\npositional accuracy and lower variance.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-21T17:10:10Z"}
{"aid":"http://arxiv.org/abs/2504.15252v1","title":"SuoiAI: Building a Dataset for Aquatic Invertebrates in Vietnam","summary":"Understanding and monitoring aquatic biodiversity is critical for ecological\nhealth and conservation efforts. This paper proposes SuoiAI, an end-to-end\npipeline for building a dataset of aquatic invertebrates in Vietnam and\nemploying machine learning (ML) techniques for species classification. We\noutline the methods for data collection, annotation, and model training,\nfocusing on reducing annotation effort through semi-supervised learning and\nleveraging state-of-the-art object detection and classification models. Our\napproach aims to overcome challenges such as data scarcity, fine-grained\nclassification, and deployment in diverse environmental conditions.","main_category":"cs.AI","categories":"cs.AI,cs.CV,cs.LG","published":"2025-04-21T17:33:02Z"}
{"aid":"http://arxiv.org/abs/2504.15273v1","title":"Efficient Testing Using Surrogate Information","summary":"In modern clinical trials, there is immense pressure to use surrogate markers\nin place of an expensive or long-term primary outcome to make more timely\ndecisions about treatment effectiveness. However, using a surrogate marker to\ntest for a treatment effect can be difficult and controversial. Existing\nmethods tend to either rely on fully parametric methods where strict\nassumptions are made about the relationship between the surrogate and the\noutcome, or assume the surrogate marker is valid for the entire study\npopulation. In this paper, we develop a fully nonparametric method for\nefficient testing using surrogate information (ETSI). Our approach is\nspecifically designed for settings where there is heterogeneity in the utility\nof the surrogate marker, i.e., the surrogate is valid for certain patient\nsubgroups and not others. ETSI enables treatment effect estimation and\nhypothesis testing via kernel-based estimation for a setting where the\nsurrogate is used in place of the primary outcome for individuals for whom the\nsurrogate is valid, and the primary outcome is purposefully only measured in\nthe remaining patients. In addition, we provide a framework for future study\ndesign with power and sample size estimates based on our proposed testing\nprocedure. We demonstrate the performance of our methods via a simulation study\nand application to two distinct HIV clinical trials.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-21T17:57:53Z"}
{"aid":"http://arxiv.org/abs/2504.15277v1","title":"A Short History of (Orbital) Decay: Roman's Prospects for Detecting\n  Dying Planets","summary":"The Roman Space Telescope Galactic Bulge Time Domain Survey (GBTDS) is\nexpected to detect ~10^5 transiting planets. Many of these planets will have\nshort orbital periods and are thus susceptible to tidal decay. We use a catalog\nof simulated transiting planet detections to predict the yield of orbital decay\ndetections in the Roman GBTDS. Assuming a constant stellar tidal dissipation\nfactor, Q^{'}_{*}, of 10^6, we predict ~ 5 - 10 detections. We additionally\nconsider an empirical period-dependent parameterization of Q^{'}_{*} \\propto\nP^{-3} and find a substantially suppressed yield. We conclude that Roman will\nprovide constraints on the rate of planet engulfment in the Galaxy and probe\nthe physics of tidal dissipation in stars.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.GA,astro-ph.IM,astro-ph.SR","published":"2025-04-21T17:59:12Z"}
{"aid":"http://arxiv.org/abs/2504.15283v1","title":"Simultaneously Modelling Dusty Star Forming Galaxies and Massive\n  Quiescents: A Calibration Framework for Galaxy Formation Models","summary":"Galaxy formation models, particularly semi-analytic models (SAMs), rely on\ndifferential equations with free parameters to describe the physical mechanisms\ngoverning galaxy formation and evolution. Traditionally, most SAMs calibrate\nthese parameters manually to match observational data. However, this approach\nfails to fully explore the multidimensional parameter space, resulting in\nlimited robustness and inconsistency with some observations. In contrast, the\nL-Galaxies SAM features a unique Markov Chain Monte Carlo (MCMC) mode, enabling\nrobust model calibration. Using this functionality, we address a long-standing\ntension in galaxy formation models: simultaneously reproducing the number\ndensities of dusty star-forming galaxies (DSFGs) and high-redshift massive\nquiescent galaxies (MQs). We test nine combinations of observational\nconstraints - including stellar mass functions, quiescent fractions, neutral\nhydrogen mass functions, and DSFG number densities - across different\nredshifts. We then analyze the resulting galaxy property predictions and\ndiscuss the underlying physical mechanisms. Our results identify a model that\nreasonably matches the number density of DSFGs while remaining consistent with\nobservationally-derived lower limits on the number density of high-redshift\nMQs. This model requires high star formation efficiencies in mergers and a null\ndependency of supermassive black hole (SMBH) cold gas accretion on halo mass,\nfacilitating rapid stellar mass and SMBH growth. Additionally, our findings\nhighlight the importance of robust calibration procedures to address the\nsignificant degeneracies inherent to multidimensional galaxy formation models.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-21T17:59:59Z"}
{"aid":"http://arxiv.org/abs/2504.15549v1","title":"Do It For Me vs. Do It With Me: Investigating User Perceptions of\n  Different Paradigms of Automation in Copilots for Feature-Rich Software","summary":"Large Language Model (LLM)-based in-application assistants, or copilots, can\nautomate software tasks, but users often prefer learning by doing, raising\nquestions about the optimal level of automation for an effective user\nexperience. We investigated two automation paradigms by designing and\nimplementing a fully automated copilot (AutoCopilot) and a semi-automated\ncopilot (GuidedCopilot) that automates trivial steps while offering\nstep-by-step visual guidance. In a user study (N=20) across data analysis and\nvisual design tasks, GuidedCopilot outperformed AutoCopilot in user control,\nsoftware utility, and learnability, especially for exploratory and creative\ntasks, while AutoCopilot saved time for simpler visual tasks. A follow-up\ndesign exploration (N=10) enhanced GuidedCopilot with task-and state-aware\nfeatures, including in-context preview clips and adaptive instructions. Our\nfindings highlight the critical role of user control and tailored guidance in\ndesigning the next generation of copilots that enhance productivity, support\ndiverse skill levels, and foster deeper software engagement.","main_category":"cs.HC","categories":"cs.HC,cs.AI,cs.LG","published":"2025-04-22T03:11:10Z"}
{"aid":"http://arxiv.org/abs/2504.15561v1","title":"SPECI: Skill Prompts based Hierarchical Continual Imitation Learning for\n  Robot Manipulation","summary":"Real-world robot manipulation in dynamic unstructured environments requires\nlifelong adaptability to evolving objects, scenes and tasks. Traditional\nimitation learning relies on static training paradigms, which are ill-suited\nfor lifelong adaptation. Although Continual Imitation Learnin (CIL) enables\nincremental task adaptation while preserving learned knowledge, current CIL\nmethods primarily overlook the intrinsic skill characteristics of robot\nmanipulation or depend on manually defined and rigid skills, leading to\nsuboptimal cross-task knowledge transfer. To address these issues, we propose\nSkill Prompts-based HiErarchical Continual Imitation Learning (SPECI), a novel\nend-to-end hierarchical CIL policy architecture for robot manipulation. The\nSPECI framework consists of a multimodal perception and fusion module for\nheterogeneous sensory information encoding, a high-level skill inference module\nfor dynamic skill extraction and selection, and a low-level action execution\nmodule for precise action generation. To enable efficient knowledge transfer on\nboth skill and task levels, SPECI performs continual implicit skill acquisition\nand reuse via an expandable skill codebook and an attention-driven skill\nselection mechanism. Furthermore, we introduce mode approximation to augment\nthe last two modules with task-specific and task-sharing parameters, thereby\nenhancing task-level knowledge transfer. Extensive experiments on diverse\nmanipulation task suites demonstrate that SPECI consistently outperforms\nstate-of-the-art CIL methods across all evaluated metrics, revealing\nexceptional bidirectional knowledge transfer and superior overall performance.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-22T03:30:38Z"}
{"aid":"http://arxiv.org/abs/2504.15611v1","title":"An ACO-MPC Framework for Energy-Efficient and Collision-Free Path\n  Planning in Autonomous Maritime Navigation","summary":"Automated driving on ramps presents significant challenges due to the need to\nbalance both safety and efficiency during lane changes. This paper proposes an\nintegrated planner for automated vehicles (AVs) on ramps, utilizing an\nunsatisfactory level metric for efficiency and arrow-cluster-based sampling for\nsafety. The planner identifies optimal times for the AV to change lanes, taking\ninto account the vehicle's velocity as a key factor in efficiency.\nAdditionally, the integrated planner employs arrow-cluster-based sampling to\nevaluate collision risks and select an optimal lane-changing curve. Extensive\nsimulations were conducted in a ramp scenario to verify the planner's efficient\nand safe performance. The results demonstrate that the proposed planner can\neffectively select an appropriate lane-changing time point and a safe\nlane-changing curve for AVs, without incurring any collisions during the\nmaneuver.","main_category":"eess.SY","categories":"eess.SY,cs.RO,cs.SY","published":"2025-04-22T06:09:54Z"}
{"aid":"http://arxiv.org/abs/2504.15615v1","title":"Dimension-Free Decision Calibration for Nonlinear Loss Functions","summary":"When model predictions inform downstream decision making, a natural question\nis under what conditions can the decision-makers simply respond to the\npredictions as if they were the true outcomes. Calibration suffices to\nguarantee that simple best-response to predictions is optimal. However,\ncalibration for high-dimensional prediction outcome spaces requires exponential\ncomputational and statistical complexity. The recent relaxation known as\ndecision calibration ensures the optimality of the simple best-response rule\nwhile requiring only polynomial sample complexity in the dimension of outcomes.\nHowever, known results on calibration and decision calibration crucially rely\non linear loss functions for establishing best-response optimality. A natural\napproach to handle nonlinear losses is to map outcomes $y$ into a feature space\n$\\phi(y)$ of dimension $m$, then approximate losses with linear functions of\n$\\phi(y)$. Unfortunately, even simple classes of nonlinear functions can demand\nexponentially large or infinite feature dimensions $m$. A key open problem is\nwhether it is possible to achieve decision calibration with sample complexity\nindependent of~$m$. We begin with a negative result: even verifying decision\ncalibration under standard deterministic best response inherently requires\nsample complexity polynomial in~$m$. Motivated by this lower bound, we\ninvestigate a smooth version of decision calibration in which decision-makers\nfollow a smooth best-response. This smooth relaxation enables dimension-free\ndecision calibration algorithms. We introduce algorithms that, given\n$\\mathrm{poly}(|A|,1/\\epsilon)$ samples and any initial predictor~$p$, can\nefficiently post-process it to satisfy decision calibration without worsening\naccuracy. Our algorithms apply broadly to function classes that can be\nwell-approximated by bounded-norm functions in (possibly infinite-dimensional)\nseparable RKHS.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-22T06:14:23Z"}
{"aid":"http://arxiv.org/abs/2504.15648v1","title":"A diagrammatic approach to correlation functions in superfluids","summary":"Renaud Parentani has given a vast contribution to the development of\ngravitational analogue models as tools to explore various important aspects of\ngeneral relativity and of quantum field theory in curved space-time. In these\nsystems, two-point correlation functions are of the utmost importance for the\ncharacterization of processes taking place close to the acoustic horizon. In\nthe present paper, dedicated to him, we present a study of path integral\nmethods that allow to determine two-point correlation functions by a\nperturbative expansion, in a way that -- beyond its generality -- is especially\nsuited to analyze these processes. Our results apply to non-relativistic\nsuperfluids, realizable in terrestrial experiments, as well as to relativistic\nsuperfluids, relevant for compact stellar objects.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,hep-ph","published":"2025-04-22T07:14:59Z"}
{"aid":"http://arxiv.org/abs/2504.15683v1","title":"FinTextSim: Enhancing Financial Text Analysis with BERTopic","summary":"Recent advancements in information availability and computational\ncapabilities have transformed the analysis of annual reports, integrating\ntraditional financial metrics with insights from textual data. To extract\nvaluable insights from this wealth of textual data, automated review processes,\nsuch as topic modeling, are crucial. This study examines the effectiveness of\nBERTopic, a state-of-the-art topic model relying on contextual embeddings, for\nanalyzing Item 7 and Item 7A of 10-K filings from S&P 500 companies\n(2016-2022). Moreover, we introduce FinTextSim, a finetuned\nsentence-transformer model optimized for clustering and semantic search in\nfinancial contexts. Compared to all-MiniLM-L6-v2, the most widely used\nsentence-transformer, FinTextSim increases intratopic similarity by 81% and\nreduces intertopic similarity by 100%, significantly enhancing organizational\nclarity. We assess BERTopic's performance using embeddings from both FinTextSim\nand all-MiniLM-L6-v2. Our findings reveal that BERTopic only forms clear and\ndistinct economic topic clusters when paired with FinTextSim's embeddings.\nWithout FinTextSim, BERTopic struggles with misclassification and overlapping\ntopics. Thus, FinTextSim is pivotal for advancing financial text analysis.\nFinTextSim's enhanced contextual embeddings, tailored for the financial domain,\nelevate the quality of future research and financial information. This improved\nquality of financial information will enable stakeholders to gain a competitive\nadvantage, streamlining resource allocation and decision-making processes.\nMoreover, the improved insights have the potential to leverage business\nvaluation and stock price prediction models.","main_category":"cs.CL","categories":"cs.CL,cs.LG,econ.GN,q-fin.EC,q-fin.GN","published":"2025-04-22T08:06:37Z"}
{"aid":"http://arxiv.org/abs/2504.15685v1","title":"Monte Carlo simulation of GRB data to test Lorentz-invariance violation","summary":"Lorentz-invariance violation (LV) at energy scales approaching the Planck\nregime serves as a critical probe for understanding quantum gravity\nphenomenology. Astrophysical observations of gamma-ray bursts (GRBs) present a\npromising avenue for testing LV-induced spectral lag phenomena; however,\ninterpretations are complicated by degeneracies between LV effects and\nintrinsic emission delays. This study systematically investigates three\ncompeting time delay models: Model A (LV delay combined with a constant\nintrinsic delay), Model B (energy-dependent intrinsic delay without LV), and\nModel C (LV delay combined with energy-dependent intrinsic delay). We utilize\nmock GRB datasets generated under distinct delay mechanisms and employ Bayesian\nparameter estimation on simulated observations of 10 GRBs. Our findings\ndemonstrate that Model C consistently recovers input parameters across all\ndatasets. In contrast, Models A and B struggle to reconcile data generated\nunder alternative mechanisms, particularly when confronted with high-energy TeV\nphotons from GRB 190114C and GRB 221009A. Our analysis confirms that the\nincorporation of energy-dependent intrinsic delays in Model C is essential for\nestablishing robust LV constraints, effectively resolving prior ambiguities in\nthe interpretation of multi-GeV and TeV photon emissions. The results validate\nModel C as a generalized framework for future LV searches, yielding a\nsubluminal LV scale of \\(E_{\\rm LV} \\simeq 3 \\times 10^{17}\\) GeV based on\nrealistic datasets. These findings are consistent with earlier constraints\nderived from Fermi-LAT datasets. This work underscores the necessity for joint\nmodeling of LV and astrophysical emission processes in next-generation LV\nstudies utilizing observatories such as LHAASO and CTA.","main_category":"hep-ph","categories":"hep-ph,astro-ph.HE,gr-qc","published":"2025-04-22T08:09:20Z"}
{"aid":"http://arxiv.org/abs/2504.15694v1","title":"You Sense Only Once Beneath: Ultra-Light Real-Time Underwater Object\n  Detection","summary":"Despite the remarkable achievements in object detection, the model's accuracy\nand efficiency still require further improvement under challenging underwater\nconditions, such as low image quality and limited computational resources. To\naddress this, we propose an Ultra-Light Real-Time Underwater Object Detection\nframework, You Sense Only Once Beneath (YSOOB). Specifically, we utilize a\nMulti-Spectrum Wavelet Encoder (MSWE) to perform frequency-domain encoding on\nthe input image, minimizing the semantic loss caused by underwater optical\ncolor distortion. Furthermore, we revisit the unique characteristics of\neven-sized and transposed convolutions, allowing the model to dynamically\nselect and enhance key information during the resampling process, thereby\nimproving its generalization ability. Finally, we eliminate model redundancy\nthrough a simple yet effective channel compression and reconstructed large\nkernel convolution (RLKC) to achieve model lightweight. As a result, forms a\nhigh-performance underwater object detector YSOOB with only 1.2 million\nparameters. Extensive experimental results demonstrate that, with the fewest\nparameters, YSOOB achieves mAP50 of 83.1% and 82.9% on the URPC2020 and DUO\ndatasets, respectively, comparable to the current SOTA detectors. The inference\nspeed reaches 781.3 FPS and 57.8 FPS on the T4 GPU (TensorRT FP16) and the edge\ncomputing device Jetson Xavier NX (TensorRT FP16), surpassing YOLOv12-N by\n28.1% and 22.5%, respectively.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T08:26:35Z"}
{"aid":"http://arxiv.org/abs/2504.15706v1","title":"Distributed Compression for Computation and Bounds on the Optimal Rate","summary":"We address the problem of distributed computation of arbitrary functions of\ntwo correlated sources $X_1$ and $X_2$, residing in two distributed source\nnodes, respectively. We exploit the structure of a computation task by coding\nsource characteristic graphs (and multiple instances using the $n$-fold OR\nproduct of this graph with itself). For regular graphs and general graphs, we\nestablish bounds on the optimal rate -- characterized by the chromatic entropy\nfor the $n$-fold graph products -- that allows a receiver for asymptotically\nlossless computation of arbitrary functions over finite fields. For the special\nclass of cycle graphs (i.e., $2$-regular graphs), we establish an exact\ncharacterization of chromatic numbers and derive bounds on the required rates.\nNext, focusing on the more general class of $d$-regular graphs, we establish\nconnections between $d$-regular graphs and expansion rates for $n$-fold graph\npowers using graph spectra. Finally, for general graphs, we leverage the\nGershgorin Circle Theorem (GCT) to provide a characterization of the spectra,\nwhich allows us to build new bounds on the optimal rate. Our codes leverage the\nspectra of the computation and provide a graph expansion-based characterization\nto efficiently/succinctly capture the computation structure, providing new\ninsights into the problem of distributed computation of arbitrary functions.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-22T08:47:40Z"}
{"aid":"http://arxiv.org/abs/2504.15719v1","title":"Implementing Rational Choice Functions with LLMs and Measuring their\n  Alignment with User Preferences","summary":"As large language models (LLMs) become integral to intelligent user\ninterfaces (IUIs), their role as decision-making agents raises critical\nconcerns about alignment. Although extensive research has addressed issues such\nas factuality, bias, and toxicity, comparatively little attention has been paid\nto measuring alignment to preferences, i.e., the relative desirability of\ndifferent alternatives, a concept used in decision making, economics, and\nsocial choice theory. However, a reliable decision-making agent makes choices\nthat align well with user preferences.\n  In this paper, we generalize existing methods that exploit LLMs for ranking\nalternative outcomes by addressing alignment with the broader and more flexible\nconcept of user preferences, which includes both strict preferences and\nindifference among alternatives. To this end, we put forward design principles\nfor using LLMs to implement rational choice functions, and provide the\nnecessary tools to measure preference satisfaction. We demonstrate the\napplicability of our approach through an empirical study in a practical\napplication of an IUI in the automotive domain.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-22T09:08:21Z"}
{"aid":"http://arxiv.org/abs/2504.15745v1","title":"Search for lepton-flavor-violating $τ^- \\to \\ell^- K_s^0$ decays at\n  Belle and Belle II","summary":"We present the results of a search for charged-lepton-flavor violating decays\n$\\tau^{-} \\rightarrow \\ell^{-}K_{S}^{0}$, where $\\ell^{-}$ is either an\nelectron or a muon. We combine $e^+e^-$ data samples recorded by the Belle II\nexperiment at the SuperKEKB collider (428 fb$^{-1}$) with samples recorded by\nthe Belle experiment at the KEKB collider (980 fb$^{-1}$) to obtain a sample of\n1.3 billion $e^+e^-\\to\\tau^+\\tau^-$ events. We observe 0 and 1 events and set\n$90\\%$ confidence level upper limits of $0.8 \\times 10^{-8}$ and $1.2 \\times\n10^{-8}$ on the branching fractions of the decay modes $\\tau^{-} \\rightarrow\ne^{-}K_{S}^{0}$ and $\\tau^{-} \\rightarrow \\mu^{-}K_{S}^{0}$, respectively.\nThese are the most stringent upper limits to date.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-22T09:46:45Z"}
{"aid":"http://arxiv.org/abs/2504.15759v1","title":"An equivalence theorem for algebraic and functorial QFT","summary":"This paper develops a novel approach to functorial quantum field theories\n(FQFTs) in the context of Lorentzian geometry. The key challenge is that\nglobally hyperbolic Lorentzian bordisms between two Cauchy surfaces cannot\nchange the topology of the Cauchy surface. This is addressed and solved by\nintroducing a more flexible concept of bordisms which provide morphisms from\ntuples of causally disjoint partial Cauchy surfaces to a later-in-time full\nCauchy surface. They assemble into a globally hyperbolic Lorentzian bordism\npseudo-operad, generalizing the geometric bordism pseudo-categories of Stolz\nand Teichner. The associated FQFTs are defined as pseudo-multifunctors into a\nsymmetric monoidal category of unital associative algebras. The main result of\nthis paper is an equivalence theorem between such globally hyperbolic\nLorentzian FQFTs and algebraic quantum field theories (AQFTs), both subject to\nthe time-slice axiom and a mild descent condition called additivity.","main_category":"math-ph","categories":"math-ph,hep-th,math.DG,math.MP,math.QA","published":"2025-04-22T10:11:48Z"}
{"aid":"http://arxiv.org/abs/2504.15763v1","title":"Modulus of continuity of Monge--Ampère potentials in big cohomology\n  classes","summary":"In this paper, we prove a uniform estimate for the modulus of continuity of\nsolutions to degenerate complex Monge--Amp\\`ere equation in big cohomology\nclasses. This improves the previous results of Di Nezza--Lu and of the first\nauthor.","main_category":"math.CV","categories":"math.CV","published":"2025-04-22T10:17:09Z"}
{"aid":"http://arxiv.org/abs/2504.15776v1","title":"Pose Optimization for Autonomous Driving Datasets using Neural Rendering\n  Models","summary":"Autonomous driving systems rely on accurate perception and localization of\nthe ego car to ensure safety and reliability in challenging real-world driving\nscenarios. Public datasets play a vital role in benchmarking and guiding\nadvancement in research by providing standardized resources for model\ndevelopment and evaluation. However, potential inaccuracies in sensor\ncalibration and vehicle poses within these datasets can lead to erroneous\nevaluations of downstream tasks, adversely impacting the reliability and\nperformance of the autonomous systems. To address this challenge, we propose a\nrobust optimization method based on Neural Radiance Fields (NeRF) to refine\nsensor poses and calibration parameters, enhancing the integrity of dataset\nbenchmarks. To validate improvement in accuracy of our optimized poses without\nground truth, we present a thorough evaluation process, relying on reprojection\nmetrics, Novel View Synthesis rendering quality, and geometric alignment. We\ndemonstrate that our method achieves significant improvements in sensor pose\naccuracy. By optimizing these critical parameters, our approach not only\nimproves the utility of existing datasets but also paves the way for more\nreliable autonomous driving models. To foster continued progress in this field,\nwe make the optimized sensor poses publicly available, providing a valuable\nresource for the research community.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-22T10:33:01Z"}
{"aid":"http://arxiv.org/abs/2504.15790v1","title":"Microstructure and Manipulation: Quantifying Pump-and-Dump Dynamics in\n  Cryptocurrency Markets","summary":"Building on our prior threshold-based analysis of six months of Poloniex\ntrading data, we have extended both the temporal span and granularity of our\nstudy by incorporating minute-level OHLCV records for 1021 tokens around each\nconfirmed pump-and-dump event. First, we algorithmically identify the\naccumulation phase, marking the initial and final insider volume spikes, and\nobserve that 70% of pre-event volume transacts within one hour of the pump\nannouncement. Second, we compute conservative lower bounds on insider profits\nunder both a single-point liquidation at 70% of peak and a tranche-based\nstrategy (selling 20% at 50%, 30% at 60%, and 50% at 80% of peak), yielding\nmedian returns above 100% and upper-quartile returns exceeding 2000%. Third, by\nunfolding the full pump structure and integrating social-media verification\n(e.g., Telegram announcements), we confirm numerous additional events that\neluded our initial model. We also categorize schemes into \"pre-accumulation\"\nversus \"on-the-spot\" archetypes-insights that sharpen detection algorithms,\ninform risk assessments, and underpin actionable strategies for real-time\nmarket-integrity enforcement.","main_category":"q-fin.TR","categories":"q-fin.TR","published":"2025-04-22T11:05:31Z"}
{"aid":"http://arxiv.org/abs/2504.15810v1","title":"Multilevel lattice-based kernel approximation for elliptic PDEs with\n  random coefficients","summary":"This paper introduces a multilevel kernel-based approximation method to\nestimate efficiently solutions to elliptic partial differential equations\n(PDEs) with periodic random coefficients. Building upon the work of Kaarnioja,\nKazashi, Kuo, Nobile, Sloan (Numer. Math., 2022) on kernel interpolation with\nquasi-Monte Carlo (QMC) lattice point sets, we leverage multilevel techniques\nto enhance computational efficiency while maintaining a given level of\naccuracy. In the function space setting with product-type weight parameters,\nthe single-level approximation can achieve an accuracy of $\\varepsilon>0$ with\ncost $\\mathcal{O}(\\varepsilon^{-\\eta-\\nu-\\theta})$ for positive constants\n$\\eta, \\nu, \\theta $ depending on the rates of convergence associated with\ndimension truncation, kernel approximation, and finite element approximation,\nrespectively. Our multilevel approximation can achieve the same $\\varepsilon$\naccuracy at a reduced cost $\\mathcal{O}(\\varepsilon^{-\\eta-\\max(\\nu,\\theta)})$.\nFull regularity theory and error analysis are provided, followed by numerical\nexperiments that validate the efficacy of the proposed multilevel approximation\nin comparison to the single-level approach.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-22T11:49:51Z"}
{"aid":"http://arxiv.org/abs/2504.15835v1","title":"Text-based Animatable 3D Avatars with Morphable Model Alignment","summary":"The generation of high-quality, animatable 3D head avatars from text has\nenormous potential in content creation applications such as games, movies, and\nembodied virtual assistants. Current text-to-3D generation methods typically\ncombine parametric head models with 2D diffusion models using score\ndistillation sampling to produce 3D-consistent results. However, they struggle\nto synthesize realistic details and suffer from misalignments between the\nappearance and the driving parametric model, resulting in unnatural animation\nresults. We discovered that these limitations stem from ambiguities in the 2D\ndiffusion predictions during 3D avatar distillation, specifically: i) the\navatar's appearance and geometry is underconstrained by the text input, and ii)\nthe semantic alignment between the predictions and the parametric head model is\ninsufficient because the diffusion model alone cannot incorporate information\nfrom the parametric model. In this work, we propose a novel framework,\nAnimPortrait3D, for text-based realistic animatable 3DGS avatar generation with\nmorphable model alignment, and introduce two key strategies to address these\nchallenges. First, we tackle appearance and geometry ambiguities by utilizing\nprior information from a pretrained text-to-3D model to initialize a 3D avatar\nwith robust appearance, geometry, and rigging relationships to the morphable\nmodel. Second, we refine the initial 3D avatar for dynamic expressions using a\nControlNet that is conditioned on semantic and normal maps of the morphable\nmodel to ensure accurate alignment. As a result, our method outperforms\nexisting approaches in terms of synthesis quality, alignment, and animation\nfidelity. Our experiments show that the proposed method advances the state of\nthe art in text-based, animatable 3D head avatar generation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T12:29:14Z"}
{"aid":"http://arxiv.org/abs/2504.15854v1","title":"Consistent Causal Inference of Group Effects in Non-Targeted Trials with\n  Finitely Many Effect Levels","summary":"A treatment may be appropriate for some group (the ``sick\" group) on whom it\nhas a positive effect, but it can also have a detrimental effect on subjects\nfrom another group (the ``healthy\" group). In a non-targeted trial both sick\nand healthy subjects may be treated, producing heterogeneous effects within the\ntreated group. Inferring the correct treatment effect on the sick population is\nthen difficult, because the effects on the different groups get tangled. We\npropose an efficient nonparametric approach to estimating the group effects,\ncalled {\\bf PCM} (pre-cluster and merge). We prove its asymptotic consistency\nin a general setting and show, on synthetic data, more than a 10x improvement\nin accuracy over existing state-of-the-art. Our approach applies more generally\nto consistent estimation of functions with a finite range.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-22T12:51:07Z"}
{"aid":"http://arxiv.org/abs/2504.15879v1","title":"Multivariate Poisson intensity estimation via low-rank tensor\n  decomposition","summary":"In this work, we introduce new matrix- and tensor-based methodologies for\nestimating multivariate intensity functions of spatial point processes. By\nmodeling intensity functions as infinite-rank tensors within function spaces,\nwe develop new algorithms to reveal optimal bias-variance trade-off for\ninfinite-rank tensor estimation. Our methods dramatically enhance estimation\naccuracy while simultaneously reducing computational complexity. To our\nknowledge, this work marks the first application of matrix and tensor\ntechinques to spatial point processes. Extensive numerical experiments further\ndemonstrate that our techniques consistently outperform current\nstate-of-the-art methods.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-22T13:25:17Z"}
{"aid":"http://arxiv.org/abs/2504.15895v1","title":"Dynamic Early Exit in Reasoning Models","summary":"Recent advances in large reasoning language models (LRLMs) rely on test-time\nscaling, which extends long chain-of-thought (CoT) generation to solve complex\ntasks. However, overthinking in long CoT not only slows down the efficiency of\nproblem solving, but also risks accuracy loss due to the extremely detailed or\nredundant reasoning steps. We propose a simple yet effective method that allows\nLLMs to self-truncate CoT sequences by early exit during generation. Instead of\nrelying on fixed heuristics, the proposed method monitors model behavior at\npotential reasoning transition points (e.g.,\"Wait\" tokens) and dynamically\nterminates the next reasoning chain's generation when the model exhibits high\nconfidence in a trial answer. Our method requires no additional training and\ncan be seamlessly integrated into existing o1-like reasoning LLMs. Experiments\non multiple reasoning benchmarks MATH-500, AMC 2023, GPQA Diamond and AIME 2024\nshow that the proposed method is consistently effective on deepseek-series\nreasoning LLMs, reducing the length of CoT sequences by an average of 31% to\n43% while improving accuracy by 1.7% to 5.7%.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-22T13:36:53Z"}
{"aid":"http://arxiv.org/abs/2504.15907v1","title":"On meromorphic solutions of Fermat type delay-differential equations\n  with two exponential terms","summary":"The existence of the meromorphic solutions to Fermat type delay-differential\nequation\n  \\begin{equation}\n  f^n(z)+a(f^{(l)}(z+c))^m=p_1(z)e^{a_1z^k}+p_2(z)e^{a_2z^k}, \\nonumber\n  \\end{equation}\n  is derived by using Nevanlinna theory under certain conditions, where\n$k\\ge1$, $m,$ $n$ and $l\\ge0$ are integers, $p_i$ are nonzero entire functions\nof order less than $k$, $c$, $a$ and $a_i$ are constants, $i=1,2$. These\nresults not only improve the previous results from Zhu et al. [J. Contemp.\nMath. Anal. 59(2024), 209-219], Qi et al. [Mediterr. J. Math. 21(2024), article\nno. 122], but also completely solve two conjectures posed by Gao et al.\n[Mediterr. J. Math. 20(2023), article no. 167].Some examples are given to\nillustrate our results.","main_category":"math.CV","categories":"math.CV","published":"2025-04-22T13:52:39Z"}
{"aid":"http://arxiv.org/abs/2504.15911v1","title":"Direct and inverse problem for bi-wave equation with time-dependent\n  coefficients from partial data","summary":"In this article, we study a direct and an inverse problem for the bi-wave\noperator $(\\Box^2)$ along with second and lower order time-dependent\nperturbations. In the direct problem, we prove that the operator is well-posed,\ngiven initial and boundary data in suitable function spaces. In the inverse\nproblem, we prove uniqueness of the lower order time-dependent perturbations\nfrom the partial input-output operator. The restriction in the measurements are\nconsidered by restricting some of the Neumann data over a portion of the\nlateral boundary.","main_category":"math.AP","categories":"math.AP","published":"2025-04-22T13:56:50Z"}
{"aid":"http://arxiv.org/abs/2504.15958v1","title":"FreeGraftor: Training-Free Cross-Image Feature Grafting for\n  Subject-Driven Text-to-Image Generation","summary":"Subject-driven image generation aims to synthesize novel scenes that\nfaithfully preserve subject identity from reference images while adhering to\ntextual guidance, yet existing methods struggle with a critical trade-off\nbetween fidelity and efficiency. Tuning-based approaches rely on time-consuming\nand resource-intensive subject-specific optimization, while zero-shot methods\nfail to maintain adequate subject consistency. In this work, we propose\nFreeGraftor, a training-free framework that addresses these limitations through\ncross-image feature grafting. Specifically, FreeGraftor employs semantic\nmatching and position-constrained attention fusion to transfer visual details\nfrom reference subjects to the generated image. Additionally, our framework\nincorporates a novel noise initialization strategy to preserve geometry priors\nof reference subjects for robust feature matching. Extensive qualitative and\nquantitative experiments demonstrate that our method enables precise subject\nidentity transfer while maintaining text-aligned scene synthesis. Without\nrequiring model fine-tuning or additional training, FreeGraftor significantly\noutperforms existing zero-shot and training-free approaches in both subject\nfidelity and text alignment. Furthermore, our framework can seamlessly extend\nto multi-subject generation, making it practical for real-world deployment. Our\ncode is available at https://github.com/Nihukat/FreeGraftor.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T14:55:23Z"}
{"aid":"http://arxiv.org/abs/2504.15979v1","title":"Efficient Discovery of Motif Transition Process for Large-Scale Temporal\n  Graphs","summary":"Understanding the dynamic transition of motifs in temporal graphs is\nessential for revealing how graph structures evolve over time, identifying\ncritical patterns, and predicting future behaviors, yet existing methods often\nfocus on predefined motifs, limiting their ability to comprehensively capture\ntransitions and interrelationships. We propose a parallel motif transition\nprocess discovery algorithm, PTMT, a novel parallel method for discovering\nmotif transition processes in large-scale temporal graphs. PTMT integrates a\ntree-based framework with the temporal zone partitioning (TZP) strategy, which\npartitions temporal graphs by time and structure while preserving lossless\nmotif transitions and enabling massive parallelism. PTMT comprises three\nphases: growth zone parallel expansion, overlap-aware result aggregation, and\ndeterministic encoding of motif transitions, ensuring accurate tracking of\ndynamic transitions and interactions. Results on 10 real-world datasets\ndemonstrate that PTMT achieves speedups ranging from 12.0$\\times$ to\n50.3$\\times$ compared to the SOTA method.","main_category":"cs.DB","categories":"cs.DB,cs.LG","published":"2025-04-22T15:30:04Z"}
{"aid":"http://arxiv.org/abs/2504.16007v1","title":"Methods for Recognizing Nested Terms","summary":"In this paper, we describe our participation in the RuTermEval competition\ndevoted to extracting nested terms. We apply the Binder model, which was\npreviously successfully applied to the recognition of nested named entities, to\nextract nested terms. We obtained the best results of term recognition in all\nthree tracks of the RuTermEval competition. In addition, we study the new task\nof recognition of nested terms from flat training data annotated with terms\nwithout nestedness. We can conclude that several approaches we proposed in this\nwork are viable enough to retrieve nested terms effectively without nested\nlabeling of them.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-22T16:15:37Z"}
{"aid":"http://arxiv.org/abs/2504.16034v1","title":"LHCspin: a Polarized Gas Target for LHC","summary":"The goal of the LHCspin project is to develop innovative solutions for\nmeasuring the 3D structure of nucleons in high-energy polarized fixed-target\ncollisions at LHC, exploring new processes and exploiting new probes in a\nunique, previously unexplored, kinematic regime. A precise multi-dimensional\ndescription of the hadron structure has, in fact, the potential to deepen our\nunderstanding of the strong interactions and to provide a much more precise\nframework for measuring both Standard Model and Beyond Standard Model\nobservables. This ambitious task poses its basis on the recent experience with\nthe successful installation and operation of the SMOG2 unpolarized gas target\nin front of the LHCb spectrometer. Besides allowing for interesting physics\nstudies ranging from astrophysics to heavy-ion physics, SMOG2 provides an ideal\nbenchmark for studying beam-target dynamics at the LHC and demonstrates the\nfeasibility of simultaneous operation with beam-beam collisions. With the\ninstallation of the proposed polarized target system, LHCb will become the\nfirst experiment to simultaneously collect data from unpolarized beam-beam\ncollisions at $\\sqrt{s}$=14 TeV and polarized and unpolarized beam-target\ncollisions at $\\sqrt{s_{NN}}\\sim$100 GeV. LHCspin has the potential to open new\nfrontiers in physics by exploiting the capabilities of the world's most\npowerful collider and one of the most advanced spectrometers. This document\nalso highlights the need to perform an R\\&D campaign and the commissioning of\nthe apparatus at the LHC Interaction Region 4 during the Run 4, before its\nfinal installation in LHCb. This opportunity could also allow to undertake\npreliminary physics measurements with unprecedented conditions.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-22T16:58:08Z"}
{"aid":"http://arxiv.org/abs/2504.16049v1","title":"Effect of Coriolis Force on the Shear Viscosity of Rotating Nuclear\n  Medium","summary":"Following the recent observation of non-zero spin polarization and spin\nalignment of a few hadrons, the rotational aspect of quark-gluon plasma formed\nin heavy ion collisions has attracted considerable interest. The present work\nexplores the effect of the Coriolis force, arising due to this rotation, on the\nshear viscosity of the medium. Using the relaxation time approximation within\nthe kinetic theory framework, we analyze the parallel (\\(\\eta_{||}/s\\)),\nperpendicular (\\(\\eta_\\perp/s\\)) and Hall (\\(\\eta_\\times/s\\)) components of\nshear viscosity to entropy density ratio under rotation. The estimation of\nanisotropic shear viscosity components is carried out using hadron resonance\ngas degrees of freedom below the critical (transition) temperature and massless\npartonic degrees of freedom above this temperature. Our results show that\nrotation suppresses the shear viscosity of the medium, with the degree of\nsuppression depending on the ratio between the relaxation time and the\nrotational period. In the context of realistic heavy-ion collision experiments,\nthe temperature and angular velocity both decrease with time, and one can\nestablish a connection between them through the standard approximate cooling\nlaw. For a temperature-dependent angular velocity \\(\\Omega(T)\\), we obtain a\ntraditional valley-like pattern for all components \\(\\eta_{||}/s\\),\n\\(\\eta_\\perp/s\\) and \\(\\eta_\\times/s\\) with reduced magnitudes compared to the\nvalley-like isotropic $\\eta/s$ one encounters in the absence of rotation.","main_category":"nucl-th","categories":"nucl-th,hep-th","published":"2025-04-22T17:27:10Z"}
{"aid":"http://arxiv.org/abs/2504.16059v1","title":"Sub-Horizon Amplification of Curvature Perturbations: A New Route to\n  Primordial Black Holes and Gravitational Waves","summary":"The enhanced primordial scalar power spectrum is a widely studied mechanism\nfor generating primordial gravitational waves (PGWs), also referred to as\nscalar-induced gravitational waves (SIGWs). This process also plays a pivotal\nrole in facilitating the formation of primordial black holes (PBHs).\nTraditionally, the ultra slow-roll (USR) mechanism has been the predominant\napproach used in the early universe. In this framework, the second slow-roll\nparameter $\\epsilon_2$, is typically set to $-6$ or lower for a brief period --\nmarking a significant departure from the standard slow-roll condition where\n$\\epsilon_2 \\simeq 0$. Such conditions often emerge in models with inflection\npoints or localized features, such as bumps in the potential. In this paper, we\nchallenge the conventional assumption that $\\epsilon_2 \\lesssim -6$ is a\nprerequisite for substantial amplification of the scalar power spectrum. We\ndemonstrate that any negative value of the second slow-roll parameter can\nindeed enhance the scalar power spectrum through sub-horizon growth,\nestablishing this as a necessary and sufficient condition for amplification.\nConsequently, this mechanism facilitates the generation of both PGWs and PBHs.\nTo illustrate this, we examine a standard scenario where a brief USR phase is\nembedded between two slow-roll (SR) phases. By systematically varying\n$\\epsilon_{2}$ values from $-1$ to $-10$ in the USR region, we investigate the\namplification of the power spectrum and its implications for PGWs and PBHs\nproduction, particularly in the context of ongoing and future cosmological\nmissions.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph,hep-th","published":"2025-04-22T17:36:01Z"}
{"aid":"http://arxiv.org/abs/2504.16082v1","title":"MR. Video: \"MapReduce\" is the Principle for Long Video Understanding","summary":"We propose MR. Video, an agentic long video understanding framework that\ndemonstrates the simple yet effective MapReduce principle for processing long\nvideos: (1) Map: independently and densely perceiving short video clips, and\n(2) Reduce: jointly aggregating information from all clips. Compared with\nsequence-to-sequence vision-language models (VLMs), MR. Video performs detailed\nshort video perception without being limited by context length. Compared with\nexisting video agents that typically rely on sequential key segment selection,\nthe Map operation enables simpler and more scalable sequence parallel\nperception of short video segments. Its Reduce step allows for more\ncomprehensive context aggregation and reasoning, surpassing explicit key\nsegment retrieval. This MapReduce principle is applicable to both VLMs and\nvideo agents, and we use LLM agents to validate its effectiveness.\n  In practice, MR. Video employs two MapReduce stages: (A) Captioning:\ngenerating captions for short video clips (map), then standardizing repeated\ncharacters and objects into shared names (reduce); (B) Analysis: for each user\nquestion, analyzing relevant information from individual short videos (map),\nand integrating them into a final answer (reduce). MR. Video achieves over 10%\naccuracy improvement on the challenging LVBench compared to state-of-the-art\nVLMs and video agents.\n  Code is available at: https://github.com/ziqipang/MR-Video","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T17:59:41Z"}
{"aid":"http://arxiv.org/abs/2504.16388v1","title":"Measurement of the Temperature Dependence of the Refractive Index of\n  CdZnTe","summary":"We have been developing a CdZnTe immersion grating for a compact\nhigh-dispersion mid-infrared spectrometer (wavelength range 10--18 $\\mu$m,\nspectral resolution $R = \\lambda/\\Delta \\lambda > 25,000$, operating\ntemperature $T < 20$ K). Using an immersion grating, the spectrometer size can\nbe reduced to $1/n$ ($n$: refractive index) compared to conventional\ndiffraction gratings. CdZnTe is promising as a material for immersion gratings\nfor the wavelength range. However, the refractive index $n$ of CdZnTe has not\nbeen measured at $T < 20$ K.\n  We have been developing a system to precisely measure $n$ at cryogenic\ntemperatures ($T \\sim 10$ K) in the mid-infrared wavelength range. As the first\nresult, this paper reports the temperature dependence of $n$ of CdZnTe at the\nwavelength of 10.68 $\\mu$m. This system employs the minimum deviation method.\nThe refractive index $n$ of CdZnTe is measured at temperatures of \\( T = 12.57,\n22.47, 50.59, 70.57, \\text{ and } 298 \\, \\text{K} \\). We find that $n$ of\nCdZnTe at $\\lambda =$ 10.68 $\\mu$m is $2.6371 \\pm 0.0022$ at $12.57 \\pm 0.14$\nK, and the average temperature dependence of $n$ between 12.57 $\\pm$ 0.14 K and\n70.57 $\\pm$ 0.23 K is $\\Delta n/\\Delta T = (5.8 \\pm 0.3) \\times 10^{-5}$\nK$^{-1}$.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-23T03:30:54Z"}
{"aid":"http://arxiv.org/abs/2504.16391v1","title":"Evolution of QPO during Rising Phase of Discovery Outburst of Swift\n  J1727.8-1613: Estimation of Mass from Spectro-Temporal Study","summary":"The rising phase of the 2023-24 outburst of the recently discovered bright\ntransient black hole candidate Swift J1727.8-1613 was monitored by\n\\textit{Insight}-HXMT. We study the evolution of hard ($4$-$150$ keV) and soft\n($2$-$4$ keV) band photon count rates, the hardness ratio (HR), and QPO\nfrequencies using daily observations from the HXMT/LE, ME, and HE instruments\nbetween August 25 and October 5, 2023. The QPO frequency is found to be\nstrongly correlated with the soft-band X-ray count rates, and spectral photon\nindices. In contrast, a strong anti-correlation is observed between HR and QPO\nfrequency, as well as between HR and photon index. Based on the evolution of\nthe QPO frequency, the rising phase of the outburst is subdivided into six\nparts, with parts 1-5 fitted using the propagating oscillatory shock (POS)\nsolution to understand the nature of the evolution from a physical perspective.\nThe best-fitted POS model is obtained with a black hole mass of\n$13.34\\pm0.02~M_\\odot$. An inward-propagating shock with weakening strength\n(except in part 4) is observed during the period of our study. The POS\nmodel-fitted mass of the source is further confirmed using the QPO frequency\n($\\nu$)-photon index ($\\Gamma$) scaling method. From this method, the estimated\nprobable mass of Swift J1727.8-1613 is obtained to be $13.54\\pm1.87~M_\\odot$.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-23T03:37:58Z"}
{"aid":"http://arxiv.org/abs/2504.16406v1","title":"Long Exposure Localization in Darkness Using Consumer Cameras","summary":"In this paper we evaluate performance of the SeqSLAM algorithm for passive\nvision-based localization in very dark environments with low-cost cameras that\nresult in massively blurred images. We evaluate the effect of motion blur from\nexposure times up to 10,000 ms from a moving car, and the performance of\nlocalization in day time from routes learned at night in two different\nenvironments. Finally we perform a statistical analysis that compares the\nbaseline performance of matching unprocessed grayscale images to using patch\nnormalization and local neighborhood normalization - the two key SeqSLAM\ncomponents. Our results and analysis show for the first time why the SeqSLAM\nalgorithm is effective, and demonstrate the potential for cheap camera-based\nlocalization systems that function despite extreme appearance change.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-23T04:18:57Z"}
{"aid":"http://arxiv.org/abs/2504.16417v1","title":"Anytime Safe Reinforcement Learning","summary":"This paper considers the problem of solving constrained\n  reinforcement learning problems with anytime guarantees, meaning\n  that the algorithmic solution returns a safe policy regardless of\n  when it is terminated. Drawing inspiration from anytime constrained\n  optimization, we introduce Reinforcement Learning-based Safe\n  Gradient Flow (RL-SGF), an on-policy algorithm which employs\n  estimates of the value functions and their respective gradients\n  associated with the objective and safety constraints for the current\n  policy, and updates the policy parameters by solving a convex\n  quadratically constrained quadratic program. We show that if the\n  estimates are computed with a sufficiently large number of episodes\n  (for which we provide an explicit bound), safe policies are updated\n  to safe policies with a probability higher than a prescribed\n  tolerance. We also show that iterates asymptotically converge to a\n  neighborhood of a KKT point, whose size can be arbitrarily reduced\n  by refining the estimates of the value function and their gradients.\n  We illustrate the performance of RL-SGF in a navigation example.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-23T04:51:31Z"}
{"aid":"http://arxiv.org/abs/2504.16419v1","title":"PixelWeb: The First Web GUI Dataset with Pixel-Wise Labels","summary":"Graphical User Interface (GUI) datasets are crucial for various downstream\ntasks. However, GUI datasets often generate annotation information through\nautomatic labeling, which commonly results in inaccurate GUI element BBox\nannotations, including missing, duplicate, or meaningless BBoxes. These issues\ncan degrade the performance of models trained on these datasets, limiting their\neffectiveness in real-world applications. Additionally, existing GUI datasets\nonly provide BBox annotations visually, which restricts the development of\nvisually related GUI downstream tasks. To address these issues, we introduce\nPixelWeb, a large-scale GUI dataset containing over 100,000 annotated web\npages. PixelWeb is constructed using a novel automatic annotation approach that\nintegrates visual feature extraction and Document Object Model (DOM) structure\nanalysis through two core modules: channel derivation and layer analysis.\nChannel derivation ensures accurate localization of GUI elements in cases of\nocclusion and overlapping elements by extracting BGRA four-channel bitmap\nannotations. Layer analysis uses the DOM to determine the visibility and\nstacking order of elements, providing precise BBox annotations. Additionally,\nPixelWeb includes comprehensive metadata such as element images, contours, and\nmask annotations. Manual verification by three independent annotators confirms\nthe high quality and accuracy of PixelWeb annotations. Experimental results on\nGUI element detection tasks show that PixelWeb achieves performance on the\nmAP95 metric that is 3-7 times better than existing datasets. We believe that\nPixelWeb has great potential for performance improvement in downstream tasks\nsuch as GUI generation and automated user interaction.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.HC","published":"2025-04-23T05:01:25Z"}
{"aid":"http://arxiv.org/abs/2504.16429v1","title":"Give LLMs a Security Course: Securing Retrieval-Augmented Code\n  Generation via Knowledge Injection","summary":"Retrieval-Augmented Code Generation (RACG) leverages external knowledge to\nenhance Large Language Models (LLMs) in code synthesis, improving the\nfunctional correctness of the generated code. However, existing RACG systems\nlargely overlook security, leading to substantial risks. Especially, the\npoisoning of malicious code into knowledge bases can mislead LLMs, resulting in\nthe generation of insecure outputs, which poses a critical threat in modern\nsoftware development. To address this, we propose a security-hardening\nframework for RACG systems, CodeGuarder, that shifts the paradigm from\nretrieving only functional code examples to incorporating both functional code\nand security knowledge. Our framework constructs a security knowledge base from\nreal-world vulnerability databases, including secure code samples and root\ncause annotations. For each code generation query, a retriever decomposes the\nquery into fine-grained sub-tasks and fetches relevant security knowledge. To\nprioritize critical security guidance, we introduce a re-ranking and filtering\nmechanism by leveraging the LLMs' susceptibility to different vulnerability\ntypes. This filtered security knowledge is seamlessly integrated into the\ngeneration prompt. Our evaluation shows CodeGuarder significantly improves code\nsecurity rates across various LLMs, achieving average improvements of 20.12\\%\nin standard RACG, and 31.53\\% and 21.91\\% under two distinct poisoning\nscenarios without compromising functional correctness. Furthermore, CodeGuarder\ndemonstrates strong generalization, enhancing security even when the targeted\nlanguage's security knowledge is lacking. This work presents CodeGuarder as a\npivotal advancement towards building secure and trustworthy RACG systems.","main_category":"cs.CR","categories":"cs.CR,cs.SE","published":"2025-04-23T05:27:27Z"}
{"aid":"http://arxiv.org/abs/2504.16469v1","title":"Closed-form analysis of Multi-RIS Reflected Signals in RIS-Aided\n  Networks Using Stochastic Geometry","summary":"Reconfigurable intelligent surfaces (RISs) enhance wireless communication by\ncreating engineered signal reflection paths in addition to direct links. This\nwork presents a stochastic geometry framework using point processes (PPs) to\nmodel multiple randomly deployed RISs conditioned on their associated base\nstation (BS) locations. By characterizing aggregated reflections from multiple\nRISs using the Laplace transform, we analytically assess the performance impact\nof RIS-reflected signals by integrating this characterization into\nwell-established stochastic geometry frameworks. Specifically, we derive\nclosed-form expressions for the Laplace transform of the reflected signal power\nin several deployment scenarios. These analytical results facilitate\nperformance evaluation of RIS-enabled enhancements. Numerical simulations\nvalidate that optimal RIS placement favors proximity to BSs or user equipment\n(UEs), and further quantify the impact of reflected interference, various\nfading assumptions, and diverse spatial deployment strategies. Importantly, our\nanalytical approach shows superior computational efficiency compared to Monte\nCarlo simulations.","main_category":"cs.PF","categories":"cs.PF,cs.IT,math.IT","published":"2025-04-23T07:29:32Z"}
{"aid":"http://arxiv.org/abs/2504.16482v1","title":"Next Generation Multi-element monolithic Germanium detectors for\n  Spectroscopy: First integration at ESRF facility","summary":"The XAFS-DET work package of the European LEAPS-INNOV project is developing a\nhigh-purity Germanium detectors for synchrotron applications requiring\nspectroscopic-grade response. The detectors integrate three key features: (1)\nnewly designed monolithic Germanium sensors optimised to mitigate\ncharge-sharing events, (2) an improved cooling and mechanical design structure\nsupported by thermal simulations, and (3) complete electronic chain featuring a\nlow-noise CMOS technology-based preamplifier. enabling high X-ray count rate\ncapability over a broad energy range (5-100 keV). This paper discusses the\nfirst integration and characterization of one of the two multi-element Ge\ndetectors at the European Synchrotron Radiation Facility (ESRF). The\nintegration phase included validating high-throughput front-End electronics,\nintegrating them with the Ge sensor, and operating them at liquid nitrogen\ntemperature, in addition to the experimental characterization, which consists\nof electronics noise study and spectroscopic performance evaluation.","main_category":"physics.ins-det","categories":"physics.ins-det","published":"2025-04-23T07:51:37Z"}
{"aid":"http://arxiv.org/abs/2504.16483v1","title":"Exploring turnover, retention and growth in an OSS Ecosystem","summary":"The Gentoo ecosystem has evolved significantly over 23 years, highlighting\nthe critical impact of developer sentiment on workforce dynamics such as\nturnover, retention, and growth. While prior research has explored sentiment at\nthe project level, sentiment-driven dynamics at the component level remain\nunderexplored, particularly in their implications for software stability.\n  This study investigates the interplay between developer sentiment and\nworkforce dynamics in Gentoo. The primary objectives are to (1) compare\nworkforce metrics (turnover, retention, and growth rates) between\nsentiment-positive (SP) and sentiment-negative (SN) components, (2) examine\ntemporal trends across three time phases, and (3) analyze the impact of these\ndynamics on software stability.\n  A mixed-method approach was employed, integrating sentiment analysis of\nmailing lists and commit histories using the SentiStrength-SE tool. Workforce\nmetrics were statistically analyzed using Pearson Correlation Matrix and\nMann-Whitney U tests. The analysis focused on the most SP and SN components in\nthe ecosystem.\n  SN components exhibited higher retention rates but slower growth and turnover\ncompared to SP components, which showed dynamic contributor behavior but\nreduced long-term stability. Temporal analysis revealed significant variations\nin workforce dynamics over three phases, with developer retention correlating\npositively with modifications in both sentiment groups.\n  Tailored strategies are necessary for managing sentiment-driven dynamics in\nOSS projects. Improving \\textit{adaptability} in SN components, and\n\\textit{continuity} in SP components, could improve project sustainability and\ninnovation. This study contributes to a nuanced understanding of sentiment's\nrole in workforce behavior and software stability within OSS ecosystems.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-23T07:52:12Z"}
{"aid":"http://arxiv.org/abs/2504.16484v1","title":"Experimentally Certifying Kochen-Specker Set with the Maximally Mixed\n  State","summary":"Certifying Kochen-Specker (KS) set is a task of certifying a set of\nuncharacterized projectors as desired KS set. This work demonstrates an\nimproved scheme that enables this certification using only a maximally mixed\nstate, rather than traversing over all states, making it experimental feasible.\nIn this scheme, outcomes obtained from sequential measurements are used for the\nevaluation of the worst result and its certification threshold, based on the\ncharacteristics of maximally mixed state and a semi-definite program.\nExperimentally, a group of projectors closely approximating the KS set Peres-24\nis certified in an optical system, highlighting the feasibility of this scheme\nin certifying KS set. Furthermore, a quantitative analysis is presented by\nmanually adding errors to the optical system, demonstrating a strict level of\nexperimental imperfection in achieving successful certification. These results\noffer a new perspective on characterizing measurements from quantum devices.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T07:52:19Z"}
{"aid":"http://arxiv.org/abs/2504.16487v1","title":"Rethinking Generalizable Infrared Small Target Detection: A Real-scene\n  Benchmark and Cross-view Representation Learning","summary":"Infrared small target detection (ISTD) is highly sensitive to sensor type,\nobservation conditions, and the intrinsic properties of the target. These\nfactors can introduce substantial variations in the distribution of acquired\ninfrared image data, a phenomenon known as domain shift. Such distribution\ndiscrepancies significantly hinder the generalization capability of ISTD models\nacross diverse scenarios. To tackle this challenge, this paper introduces an\nISTD framework enhanced by domain adaptation. To alleviate distribution shift\nbetween datasets and achieve cross-sample alignment, we introduce Cross-view\nChannel Alignment (CCA). Additionally, we propose the Cross-view Top-K Fusion\nstrategy, which integrates target information with diverse background features,\nenhancing the model' s ability to extract critical data characteristics. To\nfurther mitigate the impact of noise on ISTD, we develop a Noise-guided\nRepresentation learning strategy. This approach enables the model to learn more\nnoise-resistant feature representations, to improve its generalization\ncapability across diverse noisy domains. Finally, we develop a dedicated\ninfrared small target dataset, RealScene-ISTD. Compared to state-of-the-art\nmethods, our approach demonstrates superior performance in terms of detection\nprobability (Pd), false alarm rate (Fa), and intersection over union (IoU). The\ncode is available at: https://github.com/luy0222/RealScene-ISTD.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T07:58:15Z"}
{"aid":"http://arxiv.org/abs/2504.16502v1","title":"Helping Blind People Grasp: Enhancing a Tactile Bracelet with an\n  Automated Hand Navigation System","summary":"Grasping constitutes a critical challenge for visually impaired people. To\naddress this problem, we developed a tactile bracelet that assists in grasping\nby guiding the user's hand to a target object using vibration commands. Here we\ndemonstrate the fully automated system around the bracelet, which can\nconfidently detect and track target and distractor objects and reliably guide\nthe user's hand. We validate our approach in three tasks that resemble complex,\neveryday use cases. In a grasping task, the participants grasp varying target\nobjects on a table, guided via the automated hand navigation system. In the\nmultiple objects task, participants grasp objects from the same class,\ndemonstrating our system's ability to track one specific object without\ntargeting surrounding distractor objects. Finally, the participants grasp one\nspecific target object by avoiding an obstacle along the way in the depth\nnavigation task, showcasing the potential to utilize our system's depth\nestimations to navigate even complex scenarios. Additionally, we demonstrate\nthat the system can aid users in the real world by testing it in a less\nstructured environment with a blind participant. Overall, our results\ndemonstrate that the system, by translating the AI-processed visual inputs into\na reduced data rate of actionable signals, enables autonomous behavior in\neveryday environments, thus potentially increasing the quality of life of\nvisually impaired people.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-23T08:24:24Z"}
{"aid":"http://arxiv.org/abs/2504.16511v1","title":"QuaDMix: Quality-Diversity Balanced Data Selection for Efficient LLM\n  Pretraining","summary":"Quality and diversity are two critical metrics for the training data of large\nlanguage models (LLMs), positively impacting performance. Existing studies\noften optimize these metrics separately, typically by first applying quality\nfiltering and then adjusting data proportions. However, these approaches\noverlook the inherent trade-off between quality and diversity, necessitating\ntheir joint consideration. Given a fixed training quota, it is essential to\nevaluate both the quality of each data point and its complementary effect on\nthe overall dataset. In this paper, we introduce a unified data selection\nframework called QuaDMix, which automatically optimizes the data distribution\nfor LLM pretraining while balancing both quality and diversity. Specifically,\nwe first propose multiple criteria to measure data quality and employ domain\nclassification to distinguish data points, thereby measuring overall diversity.\nQuaDMix then employs a unified parameterized data sampling function that\ndetermines the sampling probability of each data point based on these quality\nand diversity related labels. To accelerate the search for the optimal\nparameters involved in the QuaDMix framework, we conduct simulated experiments\non smaller models and use LightGBM for parameters searching, inspired by the\nRegMix method. Our experiments across diverse models and datasets demonstrate\nthat QuaDMix achieves an average performance improvement of 7.2% across\nmultiple benchmarks. These results outperform the independent strategies for\nquality and diversity, highlighting the necessity and ability to balance data\nquality and diversity.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-23T08:36:50Z"}
{"aid":"http://arxiv.org/abs/2504.16515v1","title":"Federated Learning of Low-Rank One-Shot Image Detection Models in Edge\n  Devices with Scalable Accuracy and Compute Complexity","summary":"This paper introduces a novel federated learning framework termed LoRa-FL\ndesigned for training low-rank one-shot image detection models deployed on edge\ndevices. By incorporating low-rank adaptation techniques into one-shot\ndetection architectures, our method significantly reduces both computational\nand communication overhead while maintaining scalable accuracy. The proposed\nframework leverages federated learning to collaboratively train lightweight\nimage recognition models, enabling rapid adaptation and efficient deployment\nacross heterogeneous, resource-constrained devices. Experimental evaluations on\nthe MNIST and CIFAR10 benchmark datasets, both in an\nindependent-and-identically-distributed (IID) and non-IID setting, demonstrate\nthat our approach achieves competitive detection performance while\nsignificantly reducing communication bandwidth and compute complexity. This\nmakes it a promising solution for adaptively reducing the communication and\ncompute power overheads, while not sacrificing model accuracy.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-23T08:40:44Z"}
{"aid":"http://arxiv.org/abs/2504.16525v1","title":"Gravitational Positivity Bounds on Higgs-Portal Dark Matter","summary":"We consider gravitational positivity bounds on the Higgs-portal scalar dark\nmatter model. Applying gravitational positivity bounds with dark matter forward\nscattering process $\\phi \\phi \\to \\phi \\phi$ to this DM model, we find that the\nnew physics, besides the Higgs-portal dark matter physics, arises at an energy\nscale lower than $10^{10}$ GeV without the dark matter self-coupling. With the\nexistence of the dark matter self-coupling, the hierarchical order of magnitude\nbetween the self-coupling $\\lambda_{\\phi}$ and the Higgs-portal coupling\n$\\lambda_{h\\phi}$ changes the game. With $\\lambda_{\\phi}/\\lambda_{h\\phi} =\n10^{12}$, the GUT scale cutoff can realize. In this case, the dark freezeout\nscenario is possible for realizing the relic density of dark matter in the\nUniverse. We find that $\\lambda_{\\phi} \\sim O(1)$, $\\lambda_{h\\phi} \\sim\n10^{-12}$, and sub-GeV dark matter is implicated for the GUT scale cutoff\npossibility with the Higgs-portal dark matter model.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-23T08:49:36Z"}
{"aid":"http://arxiv.org/abs/2504.16549v1","title":"Exponential mixing of random interval diffeomorphisms","summary":"We consider a finite number of orientation preserving $C^2$ interval\ndiffeomorphisms and apply them randomly in such a way that the expected\nLyapunov exponents at the boundary points are positive. We prove the\nexponential mixing, with respect to the unique stationary measure supported on\nthe interior of the interval. The key step is to show the exponential\nsynchronization in average.","main_category":"math.DS","categories":"math.DS","published":"2025-04-23T09:25:49Z"}
{"aid":"http://arxiv.org/abs/2504.16582v1","title":"Nanomechanics and Pore Structure of Sodium and Potassium Geopolymer\n  Gels: Experiments, Molecular Dynamics and Coarse-Grained Simulations","summary":"The link between composition, microstructure and mechanics of NASH and KASH\ngels is elusive, even in pure metakaolin-based geopolymes. This article\nexploits molecular mechanics, coarse-grained nanomechanics and micromechanics,\nto interpret new experimental results from microscopy, porosimetry and\nnanoindentation. KASH displays a finer nanogranular structure than NASH (3 vs\n30 nm particle diameters, 5 vs 50 nm average pore diameters), higher skeletal\ndensity (2.3 vs 2.02 g/cm$^3$), nanoindentation moduli (9.21 vs 7.5 GPa) and\nhardness (0.56 vs 0.37 GPa) despite a higher total porosity (0.48-0.53 vs\n0.38). This suggests a stiffer and stronger solid skeleton for KASH, confirmed\nthrough predictive molecular dynamics simulations on recent and new models of\nNASH and KASH. The atomistic simulations inform mechanical interactions for\nnew, coarse-grained, particle-based models of NASH and KASH. The resulting\nsimulations predict the nanoindentation result that KASH is stiffer than\nequally porous NASH and the impact of formation eigenstresses on elastic\nmoduli.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-23T10:04:09Z"}
{"aid":"http://arxiv.org/abs/2504.16601v1","title":"Comparing Large Language Models and Traditional Machine Translation\n  Tools for Translating Medical Consultation Summaries: A Pilot Study","summary":"This study evaluates how well large language models (LLMs) and traditional\nmachine translation (MT) tools translate medical consultation summaries from\nEnglish into Arabic, Chinese, and Vietnamese. It assesses both patient,\nfriendly and clinician, focused texts using standard automated metrics. Results\nshowed that traditional MT tools generally performed better, especially for\ncomplex texts, while LLMs showed promise, particularly in Vietnamese and\nChinese, when translating simpler summaries. Arabic translations improved with\ncomplexity due to the language's morphology. Overall, while LLMs offer\ncontextual flexibility, they remain inconsistent, and current evaluation\nmetrics fail to capture clinical relevance. The study highlights the need for\ndomain-specific training, improved evaluation methods, and human oversight in\nmedical translation.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-23T10:31:33Z"}
{"aid":"http://arxiv.org/abs/2504.16608v1","title":"A hybrid high-order method for the biharmonic problem","summary":"This paper proposes a new hybrid high-order discretization for the biharmonic\nproblem and the corresponding eigenvalue problem. The discrete ansatz space\nincludes degrees of freedom in $n-2$ dimensional submanifolds (e.g., nodal\nvalues in 2D and edge values in 3D), in addition to the typical degrees of\nfreedom in the mesh and on the hyperfaces in the HHO literature. This approach\nenables the characteristic commuting property of the hybrid high-order\nmethodology in any space dimension and allows for lower eigenvalue bounds of\nhigher order for the eigenvalue problem. The main results are quasi-best\napproximation estimates as well as reliable and efficient error control. The\nlatter motivates an adaptive mesh-refining algorithm that empirically recovers\noptimal convergence rates for singular solutions.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-23T10:46:21Z"}
{"aid":"http://arxiv.org/abs/2504.16645v1","title":"Preliminary design of a Cavity Tuner for Superconducting Radio-Frequency\n  Cavity","summary":"This paper introduces a newly designed cavity tuner for superconducting\nradio-frequency (SRF) cavity. Aiming to overcome the drawbacks of traditional\ntuning systems, like the limited tuning range of piezoelectric tuner and the\nlow-speed tuning of stepper-motor-based tuner, this novel tuner is crafted to\nimprove SRF cavity performance and stability via efficient and accurate\nfrequency tuning. The design encompasses several key elements. The cavity\nstructure includes a commonly used 1.3 GHz single-cell superconducting cavity\nand a room-temperature coaxial tuner cavity. The coupling mechanism between the\ntwo cavities, along with the coupling window design, ensures effective energy\ntransfer while minimizing losses. The mechanical tuning system, driven by\nelectromagnetic coils, enables precise adjustments, and the cooling mechanisms\nfor both cavities guarantee stable operation. Functioning by coupling an\nexternal resonant cavity to the superconducting one, this tuner can adjust\nfrequencies through mechanical or electromagnetic methods. It realizes rapid\ntuning, with a speed much faster than traditional mechanical tuner,\nhigh-precision tuning down to the sub-mHz level, and a wide tuning range\ncovering a broader frequency spectrum. Theoretical analysis and simulations\nverify that the tuner can remarkably enhance tuning speed, precision, and\nrange. It also has distinct advantages such as a simplified structure, which\nreduces manufacturing and maintenance complexity, and enhanced reliability due\nto its non-contact tuning operation. In particle accelerators, this cavity\ntuner holds great potential. It represents a significant step forward in\nsuperconducting accelerator technology, offering a novel way to optimize the\nperformance and stability of SRF cavity.","main_category":"physics.acc-ph","categories":"physics.acc-ph","published":"2025-04-23T12:05:34Z"}
{"aid":"http://arxiv.org/abs/2504.16652v1","title":"Non-linearity Effect Analysis of Gaussian Pulse Propagation In Optical\n  Fiber","summary":"In this research, numerical analysis of nonlinear pulse propagation is\ncarried out. This is done mainly by solving the nonlinear Schrodinger equation\nusing the split step algorithm. In a nonlinear media, dispersive effects exist\nsimultaneously with nonlinear effects. Refractive index dependence on intensity\nresults in optical Kerr effect which causes narrowing of transmitted pulses by\ninducing self-phase modulation while second order group velocity dispersion\ncauses the pulses to spread. In this project, group velocity dispersion is\ndiscussed followed by self-phase modulation. These individually detrimental\neffects are shown to combine beneficially for propagation of pulses here.\nGaussian pulse is studied and propagated by using them as input in to the\nnonlinear Schrodinger equation. The split step algorithm is described in depth.\nExplanation of each step is included along with the relevant equations defining\nthese steps.","main_category":"physics.optics","categories":"physics.optics,eess.SP","published":"2025-04-23T12:17:43Z"}
{"aid":"http://arxiv.org/abs/2504.16665v1","title":"A Diff-Attention Aware State Space Fusion Model for Remote Sensing\n  Classification","summary":"Multispectral (MS) and panchromatic (PAN) images describe the same land\nsurface, so these images not only have their own advantages, but also have a\nlot of similar information. In order to separate these similar information and\ntheir respective advantages, reduce the feature redundancy in the fusion stage.\nThis paper introduces a diff-attention aware state space fusion model\n(DAS2F-Model) for multimodal remote sensing image classification. Based on the\nselective state space model, a cross-modal diff-attention module (CMDA-Module)\nis designed to extract and separate the common features and their respective\ndominant features of MS and PAN images. Among this, space preserving visual\nmamba (SPVM) retains image spatial features and captures local features by\noptimizing visual mamba's input reasonably. Considering that features in the\nfusion stage will have large semantic differences after feature separation and\nsimple fusion operations struggle to effectively integrate these significantly\ndifferent features, an attention-aware linear fusion module (AALF-Module) is\nproposed. It performs pixel-wise linear fusion by calculating influence\ncoefficients. This mechanism can fuse features with large semantic differences\nwhile keeping the feature size unchanged. Empirical evaluations indicate that\nthe presented method achieves better results than alternative approaches. The\nrelevant code can be found at:https://github.com/AVKSKVL/DAS-F-Model","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T12:34:32Z"}
{"aid":"http://arxiv.org/abs/2504.16681v1","title":"On the origin of long-term modulation in the Sun's magnetic activity\n  cycle","summary":"One of the most striking manifestations of orderly behavior emerging out of\ncomplex interactions in any astrophysical system is the 11-year cycle of\nsunspots. However, direct sunspot observations and reconstructions of long-term\nsolar activity clearly exhibit amplitude fluctuations beyond the decadal\ntimescale -- which may be termed as supradecadal modulation. Whether this\nlong-term modulation in the Sun's magnetic activity results from nonlinear\nmechanisms or stochastic perturbations remains controversial and a matter of\nactive debate. Utilizing multi-millennial scale kinematic dynamo simulations\nbased on the Babcock-Leighton paradigm -- in the likely (near-critical) regime\nof operation of the solar dynamo -- we demonstrate that this supradecadal\nmodulation in solar activity cannot be explained by nonlinear mechanisms alone;\nstochastic forcing is essential for the manifestation of observed long-term\nfluctuations in the near-critical dynamo regime. Our findings substantiate some\nindependent observational and theoretical investigations, and provide\nadditional insights into temporal dynamics associated with a plethora of\nnatural phenomena in astronomy and planetary systems arising from weakly\nnonlinear, non-deterministic processes.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-23T13:01:12Z"}
{"aid":"http://arxiv.org/abs/2504.16685v1","title":"Outer regions of galaxy clusters as a new probe to test modifications to\n  gravity","summary":"We apply the caustic technique to samples of galaxy clusters stacked in\nredshift space to estimate the gravitational potential in the cluster's outer\nregion and test modifications to the standard theory of gravity. We separate\n122 galaxy clusters from the HeCS-SZ, HeCS-redMapper, and HeCS samples into\nfour samples with increasing mass; we estimate four robust, highly constraining\ncaustic profiles for these samples. The caustic masses of the four stacked\nclusters agree within $ 10\\%$ with the corresponding median values of each\ncluster sample. By adopting the NFW density profile to model the gravitational\npotential, we recover the caustic profile $\\mathcal{A}(r)$ up to radius $r_{\\rm\np} \\sim 4.0\\, {\\rm Mpc}$. This comparison is a first-order validation of the\nmass-concentration relation for galaxy clusters expected in the $\\Lambda$CDM\nmodel. We thus impose this correlation as a prior in our analysis. Based on our\nstacked clusters, we estimate the value of the filling factor, which enters the\ncaustic technique, $\\mathcal{F}_{\\beta} = 0.59\\pm 0.05$; we derive this value\nusing real data alone and find it consistent with the value usually adopted in\nthe literature. We then use the caustic profiles $\\mathcal{A}(r)$ of the\nstacked clusters to constrain the chameleon gravity model. We find that the\ncaustic profiles provide a stringent upper limit of $|f_{\\rm R0}| \\lesssim 4\n\\times 10^{-6}$ at $95\\%$ C.L. limits in the $f(\\mathcal{R})$ scenario. The\nformalism developed here shall be further refined to test modifications to\ngravity in the extended outer weak gravitational regions of galaxy clusters.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-23T13:14:47Z"}
{"aid":"http://arxiv.org/abs/2504.16706v1","title":"Sorting as Gradient Flow on the Permutohedron","summary":"We investigate how sorting algorithms efficiently overcome the exponential\nsize of the permutation space. Our main contribution is a new continuous-time\nformulation of sorting as a gradient flow on the permutohedron, yielding an\nindependent proof of the classical $\\Omega(n \\log n)$ lower bound for\ncomparison-based sorting. This formulation reveals how exponential contraction\nof disorder occurs under simple geometric dynamics. In support of this\nanalysis, we present algebraic, combinatorial, and geometric perspectives,\nincluding decision-tree arguments and linear constraints on the permutohedron.\nThe idea that efficient sorting arises from structure-guided logarithmic\nreduction offers a unifying lens for how comparisons tame exponential spaces.\nThese observations connect to broader questions in theoretical computer\nscience, such as whether the existence of structure can explain why certain\ncomputational problems permit efficient solutions.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-23T13:38:00Z"}
{"aid":"http://arxiv.org/abs/2504.16712v1","title":"Detecting Cosmological Phase Transitions with Taiji: Sensitivity\n  Analysis and Parameter Estimation","summary":"We investigate the capability of the Taiji space-based gravitational wave\nobservatory to detect stochastic gravitational wave backgrounds produced by\nfirst-order phase transitions in the early universe. Using a comprehensive\nsimulation framework that incorporates realistic instrumental noise, galactic\ndouble white dwarf confusion noise, and extragalactic compact binary\nbackgrounds, we systematically analyze Taiji's sensitivity across a range of\nsignal parameters. Our Bayesian analysis demonstrates that Taiji can robustly\ndetect and characterize phase transition signals with energy densities\nexceeding $\\Omega_{\\text{PT}} \\gtrsim 1.4 \\times 10^{-11}$ across most of its\nfrequency band, with particularly strong sensitivity around $10^{-3}$ to\n$10^{-2}$ Hz. For signals with amplitudes above $\\Omega_{\\text{PT}} \\gtrsim 1.1\n\\times 10^{-10}$, Taiji can determine the peak frequency with relative\nprecision better than $10\\%$. These detection capabilities would enable Taiji\nto probe electroweak-scale phase transitions in various beyond-Standard-Model\nscenarios, potentially revealing new physics connected to baryogenesis and dark\nmatter production. We quantify detection confidence using both Bayes factors\nand the Deviance Information Criterion, finding consistent results that\nvalidate our statistical methodology.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,astro-ph.IM","published":"2025-04-23T13:41:54Z"}
{"aid":"http://arxiv.org/abs/2504.16718v1","title":"Simulating Quantum Circuits with Tree Tensor Networks using\n  Density-Matrix Renormalization Group Algorithm","summary":"Quantum computing offers the potential for computational abilities that can\ngo beyond classical machines. However, they are still limited by several\nchallenges such as noise, decoherence, and gate errors. As a result, efficient\nclassical simulation of quantum circuits is vital not only for validating and\nbenchmarking quantum hardware but also for gaining deeper insights into the\nbehavior of quantum algorithms. A promising framework for classical simulation\nis provided by tensor networks. Recently, the Density-Matrix Renormalization\nGroup (DMRG) algorithm was developed for simulating quantum circuits using\nmatrix product states (MPS). Although MPS is efficient for representing quantum\nstates with one-dimensional correlation structures, the fixed linear geometry\nrestricts the expressive power of the MPS. In this work, we extend the DMRG\nalgorithm for simulating quantum circuits to tree tensor networks (TTNs). To\nbenchmark the method, we simulate random and QAOA circuits with various\ntwo-qubit gate connectivities. For the random circuits, we devise tree-like\ngate layouts that are suitable for TTN and show that TTN requires less memory\nthan MPS for the simulations. For the QAOA circuits, a TTN construction that\nexploits graph structure significantly improves the simulation fidelities. Our\nfindings show that TTNs provide a promising framework for simulating quantum\ncircuits, particularly when gate connectivities exhibit clustering or a\nhierarchical structure.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T13:48:03Z"}
{"aid":"http://arxiv.org/abs/2504.16719v1","title":"Higher-order photon rings of an ultracompact object and their\n  interferometric pattern","summary":"A horizonless ultracompact object can have a stable antiphoton sphere, which\ncauses the strong deflection of photons inside the unstable photon sphere,\nleading to the formation of distinctive inner photon rings. In this work, we\npresent analytical descriptions for the shape, thickness and interference\npattern of higher-order inner photon rings. By taking the static spherically\nsymmetric Schwarzschild star with a photon sphere as an example, we find that\nits inner photon rings can be more non-circular and thicker than the outer\nones, and show that the inclusion of the inner photon rings can give rise to\nnew features in the interferometric pattern. Our formulae can also be applied\nto other ultracompact objects, providing a convenient way to study the\nobservational properties of their higher-order photon rings.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-23T13:49:44Z"}
{"aid":"http://arxiv.org/abs/2504.16760v1","title":"Lightweight Latent Verifiers for Efficient Meta-Generation Strategies","summary":"Verifiers are auxiliary models that assess the correctness of outputs\ngenerated by base large language models (LLMs). They play a crucial role in\nmany strategies for solving reasoning-intensive problems with LLMs. Typically,\nverifiers are LLMs themselves, often as large (or larger) than the base model\nthey support, making them computationally expensive. In this work, we introduce\na novel lightweight verification approach, LiLaVe, which reliably extracts\ncorrectness signals from the hidden states of the base LLM. A key advantage of\nLiLaVe is its ability to operate with only a small fraction of the\ncomputational budget required by traditional LLM-based verifiers. To\ndemonstrate its practicality, we couple LiLaVe with popular meta-generation\nstrategies, like best-of-n or self-consistency. Moreover, we design novel\nLiLaVe-based approaches, like conditional self-correction or conditional\nmajority voting, that significantly improve both accuracy and efficiency in\ngeneration tasks with smaller LLMs. Our work demonstrates the fruitfulness of\nextracting latent information from the hidden states of LLMs, and opens the\ndoor to scalable and resource-efficient solutions for reasoning-intensive\napplications.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-23T14:33:20Z"}
{"aid":"http://arxiv.org/abs/2504.16774v1","title":"Advanced Chest X-Ray Analysis via Transformer-Based Image Descriptors\n  and Cross-Model Attention Mechanism","summary":"The examination of chest X-ray images is a crucial component in detecting\nvarious thoracic illnesses. This study introduces a new image description\ngeneration model that integrates a Vision Transformer (ViT) encoder with\ncross-modal attention and a GPT-4-based transformer decoder. The ViT captures\nhigh-quality visual features from chest X-rays, which are fused with text data\nthrough cross-modal attention to improve the accuracy, context, and richness of\nimage descriptions. The GPT-4 decoder transforms these fused features into\naccurate and relevant captions. The model was tested on the National Institutes\nof Health (NIH) and Indiana University (IU) Chest X-ray datasets. On the IU\ndataset, it achieved scores of 0.854 (B-1), 0.883 (CIDEr), 0.759 (METEOR), and\n0.712 (ROUGE-L). On the NIH dataset, it achieved the best performance on all\nmetrics: BLEU 1--4 (0.825, 0.788, 0.765, 0.752), CIDEr (0.857), METEOR (0.726),\nand ROUGE-L (0.705). This framework has the potential to enhance chest X-ray\nevaluation, assisting radiologists in more precise and efficient diagnosis.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-23T14:46:10Z"}
{"aid":"http://arxiv.org/abs/2504.16779v1","title":"Evaluating the Impact of a Yoga-Based Intervention on Software\n  Engineers' Well-Being","summary":"Software engineering tasks are high-stress and cognitively demanding.\nAdditionally, there is a latent risk of software engineers presenting burnout,\ndepression and anxiety. Established interventions in other fields centred\naround attention awareness have shown positive results in mental well-being.\n  We aim to test how effective a yoga intervention is in improving general\nwell-being in the workplace. For that, we designed, implemented and evaluated\nan eight-week yoga programme in a software development company. We used a\nmixed-methods data collection, using a survey of six psychometric scales, pre\nand post-intervention, and a weekly well-being scale during the programme. For\nmethod triangulation, we conducted a focus group with the organisers to obtain\nqualitative data. The quantitative results did not show any statistically\nsignificant improvement after the intervention. Meanwhile, the qualitative\nresults illustrated that participants felt better and liked the intervention.\n  We conclude that yoga has a positive impact, which, however, can easily get\noverlaid by contextual factors, especially with only a once-per-week\nintervention.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-23T14:54:09Z"}
{"aid":"http://arxiv.org/abs/2504.16803v1","title":"Graph modification of bounded size to minor-closed classes as fast as\n  vertex deletion","summary":"A replacement action is a function $\\mathcal{L}$ that maps each graph $H$ to\na collection of graphs of size at most $|V(H)|$. Given a graph class\n$\\mathcal{H}$, we consider a general family of graph modification problems,\ncalled $\\mathcal{L}$-Replacement to $\\mathcal{H}$, where the input is a graph\n$G$ and the question is whether it is possible to replace some induced subgraph\n$H_1$ of $G$ on at most $k$ vertices by a graph $H_2$ in $\\mathcal{L}(H_1)$ so\nthat the resulting graph belongs to $\\mathcal{H}$. $\\mathcal{L}$-Replacement to\n$\\mathcal{H}$ can simulate many graph modification problems including vertex\ndeletion, edge deletion/addition/edition/contraction, vertex identification,\nsubgraph complementation, independent set deletion, (induced) matching\ndeletion/contraction, etc. We present two algorithms. The first one solves\n$\\mathcal{L}$-Replacement to $\\mathcal{H}$ in time $2^{{\\rm poly}(k)}\\cdot\n|V(G)|^2$ for every minor-closed graph class $\\mathcal{H}$, where {\\rm poly} is\na polynomial whose degree depends on $\\mathcal{H}$, under a mild technical\ncondition on $\\mathcal{L}$. This generalizes the results of Morelle, Sau,\nStamoulis, and Thilikos [ICALP 2020, ICALP 2023] for the particular case of\nVertex Deletion to $\\mathcal{H}$ within the same running time. Our second\nalgorithm is an improvement of the first one when $\\mathcal{H}$ is the class of\ngraphs embeddable in a surface of Euler genus at most $g$ and runs in time\n$2^{\\mathcal{O}(k^{9})}\\cdot |V(G)|^2$, where the $\\mathcal{O}(\\cdot)$ notation\ndepends on $g$. To the best of our knowledge, these are the first parameterized\nalgorithms with a reasonable parametric dependence for such a general family of\ngraph modification problems to minor-closed classes.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-23T15:21:55Z"}
{"aid":"http://arxiv.org/abs/2504.16835v1","title":"Robust Accelerated Dynamics for Subnetwork Bilinear Zero-Sum Games with\n  Distributed Restarting","summary":"In this paper, we investigate distributed Nash equilibrium seeking for a\nclass of two-subnetwork zero-sum games characterized by bilinear coupling. We\npresent a distributed primal-dual accelerated mirror-descent algorithm that\nguarantees convergence. However, we demonstrate that this time-varying\nalgorithm is not robust, as it fails to converge under even the slightest\ndisturbances. To address this limitation, we introduce a distributed\naccelerated algorithm that employs a coordinated restarting mechanism. We model\nthis new algorithm as a hybrid dynamical system and establish that it possesses\nstructural robustness.","main_category":"math.OC","categories":"math.OC","published":"2025-04-23T15:56:39Z"}
{"aid":"http://arxiv.org/abs/2504.16913v1","title":"Tracing Thought: Using Chain-of-Thought Reasoning to Identify the LLM\n  Behind AI-Generated Text","summary":"In recent years, the detection of AI-generated text has become a critical\narea of research due to concerns about academic integrity, misinformation, and\nethical AI deployment. This paper presents COT Fine-tuned, a novel framework\nfor detecting AI-generated text and identifying the specific language model.\nresponsible for generating the text. We propose a dual-task approach, where\nTask A involves classifying text as AI-generated or human-written, and Task B\nidentifies the specific LLM behind the text. The key innovation of our method\nlies in the use of Chain-of-Thought reasoning, which enables the model to\ngenerate explanations for its predictions, enhancing transparency and\ninterpretability. Our experiments demonstrate that COT Fine-tuned achieves high\naccuracy in both tasks, with strong performance in LLM identification and\nhuman-AI classification. We also show that the CoT reasoning process\ncontributes significantly to the models effectiveness and interpretability.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-23T17:39:49Z"}
{"aid":"http://arxiv.org/abs/2504.16920v1","title":"Summary statistics of learning link changing neural representations to\n  behavior","summary":"How can we make sense of large-scale recordings of neural activity across\nlearning? Theories of neural network learning with their origins in statistical\nphysics offer a potential answer: for a given task, there are often a small set\nof summary statistics that are sufficient to predict performance as the network\nlearns. Here, we review recent advances in how summary statistics can be used\nto build theoretical understanding of neural network learning. We then argue\nfor how this perspective can inform the analysis of neural data, enabling\nbetter understanding of learning in biological and artificial neural networks.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-04-23T17:45:42Z"}
{"aid":"http://arxiv.org/abs/2504.16923v1","title":"Meta-Learning Online Dynamics Model Adaptation in Off-Road Autonomous\n  Driving","summary":"High-speed off-road autonomous driving presents unique challenges due to\ncomplex, evolving terrain characteristics and the difficulty of accurately\nmodeling terrain-vehicle interactions. While dynamics models used in\nmodel-based control can be learned from real-world data, they often struggle to\ngeneralize to unseen terrain, making real-time adaptation essential. We propose\na novel framework that combines a Kalman filter-based online adaptation scheme\nwith meta-learned parameters to address these challenges. Offline meta-learning\noptimizes the basis functions along which adaptation occurs, as well as the\nadaptation parameters, while online adaptation dynamically adjusts the onboard\ndynamics model in real time for model-based control. We validate our approach\nthrough extensive experiments, including real-world testing on a full-scale\nautonomous off-road vehicle, demonstrating that our method outperforms baseline\napproaches in prediction accuracy, performance, and safety metrics,\nparticularly in safety-critical scenarios. Our results underscore the\neffectiveness of meta-learned dynamics model adaptation, advancing the\ndevelopment of reliable autonomous systems capable of navigating diverse and\nunseen environments. Video is available at: https://youtu.be/cCKHHrDRQEA","main_category":"cs.RO","categories":"cs.RO,cs.LG,cs.SY,eess.SY","published":"2025-04-23T17:51:36Z"}
{"aid":"http://arxiv.org/abs/2504.17287v1","title":"Combining Static and Dynamic Approaches for Mining and Testing\n  Constraints for RESTful API Testing","summary":"In API testing, deriving logical constraints on API response bodies is\ncrucial in generating the test cases to cover various aspects of RESTful APIs.\nHowever, existing approaches are limited to dynamic analysis in which\nconstraints are extracted from the execution of APIs as part of the system\nunder test. The key limitation of such a dynamic approach is its\nunder-estimation in which inputs in API executions are not sufficiently diverse\nto uncover actual constraints on API response bodies. In this paper, we propose\nto combine a novel static analysis approach (in which the constraints for API\nresponse bodies are mined from API specifications), with the dynamic approach\n(which relies on API execution data). We leverage large language models (LLMs)\nto comprehend the API specifications, mine constraints for response bodies, and\ngenerate test cases. To reduce LLMs' hallucination, we apply an\nObservation-Confirmation (OC) scheme which uses initial prompts to\ncontextualize constraints. %, allowing subsequent prompts to more accurately\nconfirm their presence. Our empirical results show that~LLMs with OC prompting\nachieve high precision in constraint mining with the average of 91.2%. When\ncombining static and dynamic analysis, our tool, RBCTest , achieves a precision\nof 78.5%. RBCTest detects 107 constraints that the dynamic approach misses and\n46 more precise constraints. We also use its generated test cases to detect 21\nmismatches between the API specification and actual response data for 8\nreal-world APIs. Four of the mismatches were, in fact, reported in developers'\nforums.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-24T06:28:18Z"}
{"aid":"http://arxiv.org/abs/2504.17288v1","title":"A Search for Planet Nine with IRAS and AKARI Data","summary":"The outer solar system is theoretically predicted to harbour an undiscovered\nplanet, often referred to as P9. Simulations suggest that its gravitational\ninfluence could explain the unusual clustering of minor bodies in the Kuiper\nBelt. However, no observational evidence for P9 has been found so far, as its\npredicted orbit lies far beyond Neptune, where it reflects only a faint amount\nof Sunlight. This work aims to find P9 candidates by taking advantage of two\nfar-infrared all-sky surveys, which are IRAS and AKARI. The epochs of these two\nsurveys were separated by 23 years, which is large enough to detect the\n~3'/year orbital motion of P9. We use a dedicated AKARI Far-Infrared point\nsource list for our P9 search - AKARI Monthly Unconfirmed Source List, which\nincludes sources detected repeatedly only in hours timescale, but not after\nmonths. We search for objects that moved slowly between IRAS and AKARI\ndetections given in the catalogues. First, we estimated the expected flux and\norbital motion of P9 by assuming its mass, distance, and effective temperature\nto ensure it can be detected by IRAS and AKARI, then applied the positional and\nflux selection criteria to narrow down the number of sources from the\ncatalogues. Next, we produced all possible candidate pairs whose angular\nseparations were limited between 42' and 69.6', corresponding to the\nheliocentric distance range of 500 - 700 AU and the mass range of 7 - 17 Earth\nmasses. There are 13 pairs obtained after the selection criteria. After image\ninspection, we found one good candidate, of which the IRAS source is absent\nfrom the same coordinate in the AKARI image after 23 years and vice versa.\nHowever, AKARI and IRAS detections are not enough to determine the full orbit\nof this candidate. This issue leads to the need for follow-up observations,\nwhich will determine the Keplerian motion of our candidate.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM,astro-ph.SR","published":"2025-04-24T06:28:28Z"}
{"aid":"http://arxiv.org/abs/2504.17291v1","title":"Top on a smooth plane","summary":"We investigate the dynamics of a sliding top that is a rigid body with an\nideal sharp tip moving in a perfectly smooth horizontal plane, so no friction\nforces act on the body. We prove that this system is integrable only in two\ncases analogous to the Euler and Lagrange cases of the classical top problem.\nThe cases with the constant gravity field with acceleration $g\\neq0$ and\nwithout external field $g=0$ are considered. The non-integrability proof for\n$g\\neq0$ based on the fact that the equations of motion for the sliding top are\na perturbation of the classical top equations of motion. We show that the\nintegrability of the classical top is a necessary condition for the\nintegrability of the sliding top. Among four integrable classical top cases the\ncorresponding two cases for the sliding top are also integrable, and for the\ntwo remaining cases, we prove their non-integrability by analyzing the\ndifferential Galois group of variational equations along a certain particular\nsolution. In the absence of constant gravitational field $g=0$ the\nintegrability is much more difficult. At first, we proved that if the sliding\ntop problem is integrable, then the body is symmetric. In the proof, we applied\none of the Ziglin theorem concerning the splitting of separatrices phenomenon.\nThen we prove the non-integrability of the symmetric sliding top using\ndifferential Galois group of variational equations except two the same as for\n$g\\neq0$ cases. The integrability of these cases is also preserved when we add\nto equations of motion a gyrostatic term.","main_category":"nlin.CD","categories":"nlin.CD,nlin.SI","published":"2025-04-24T06:36:16Z"}
{"aid":"http://arxiv.org/abs/2504.17301v1","title":"The Fields of Values of the Isaacs' Head Characters","summary":"We determine the fields of values of the Isaacs' head characters of a finite\nsolvable group.","main_category":"math.GR","categories":"math.GR,math.RT","published":"2025-04-24T06:53:48Z"}
{"aid":"http://arxiv.org/abs/2504.17351v1","title":"A hypercomplex method for solving piecewise continuous biharmonic\n  problem in domains with corner points","summary":"A piecewise continuous biharmonic problem in domains with corner points and a\ncorresponding Schwarz type boundary value problem for monogenic functions in a\ncommutative biharmonic algebra are considered. A method for reducing the\nproblems to a system of integral equations is developed.","main_category":"math.CV","categories":"math.CV","published":"2025-04-24T08:13:17Z"}
{"aid":"http://arxiv.org/abs/2504.17391v1","title":"Mach-Zehnder atom interferometry with non-interacting trapped Bose\n  Einstein condensates","summary":"The coherent manipulation of a quantum wave is at the core of quantum\nsensing. For instance, atom interferometers require linear splitting and\nrecombination processes to map the accumulated phase shift into a measurable\npopulation signal. Although Bose Einstein condensates (BECs) are the archetype\nof coherent matter waves, their manipulation between trapped spatial modes has\nbeen limited by the strong interparticle collisions. Here, we overcome this\nproblem by using BECs with tunable interaction trapped in an innovative array\nof double-well potentials and exploiting quantum tunneling to realize linear\nbeam splitting. We operate several Mach-Zehnder interferometers in parallel,\ncanceling common-mode potential instabilities by a differential analysis, thus\ndemonstrating a trapped-atom gradiometer. Furthermore, by applying a spin-echo\nprotocol, we suppress additional decoherence sources and approach unprecedented\ncoherence times of one second. Our interferometer will find applications in\nprecision measurements of forces with a high spatial resolution and in linear\nmanipulation of quantum entangled states for sensing with sub shot-noise\nsensitivity.","main_category":"quant-ph","categories":"quant-ph,cond-mat.quant-gas,physics.atom-ph","published":"2025-04-24T09:18:01Z"}
{"aid":"http://arxiv.org/abs/2504.17410v1","title":"Bias-Eliminated PnP for Stereo Visual Odometry: Provably Consistent and\n  Large-Scale Localization","summary":"In this paper, we first present a bias-eliminated weighted (Bias-Eli-W)\nperspective-n-point (PnP) estimator for stereo visual odometry (VO) with\nprovable consistency. Specifically, leveraging statistical theory, we develop\nan asymptotically unbiased and $\\sqrt {n}$-consistent PnP estimator that\naccounts for varying 3D triangulation uncertainties, ensuring that the relative\npose estimate converges to the ground truth as the number of features\nincreases. Next, on the stereo VO pipeline side, we propose a framework that\ncontinuously triangulates contemporary features for tracking new frames,\neffectively decoupling temporal dependencies between pose and 3D point errors.\nWe integrate the Bias-Eli-W PnP estimator into the proposed stereo VO pipeline,\ncreating a synergistic effect that enhances the suppression of pose estimation\nerrors. We validate the performance of our method on the KITTI and Oxford\nRobotCar datasets. Experimental results demonstrate that our method: 1)\nachieves significant improvements in both relative pose error and absolute\ntrajectory error in large-scale environments; 2) provides reliable localization\nunder erratic and unpredictable robot motions. The successful implementation of\nthe Bias-Eli-W PnP in stereo VO indicates the importance of information\nscreening in robotic estimation tasks with high-uncertainty measurements,\nshedding light on diverse applications where PnP is a key ingredient.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-24T10:03:47Z"}
{"aid":"http://arxiv.org/abs/2504.17413v1","title":"Boundary observation and control for fractional heat and wave equations","summary":"We establish boundary observability and control for the fractional heat\nequation over arbitrary time horizons $T > 0$, within the optimal range of\nfractional exponents $s \\in (1/2, 1)$. Our approach introduces a novel\nsynthesis of techniques from fractional partial differential equations and\ncontrol theory, combining several key ingredients in an original and effective\nmanner:\n  1. Boundary observability for low-frequency solutions of the fractional wave\nequation. We begin by analyzing the associated fractional wave equation. Using\na fractional analogue of Pohozaev's identity, we establish a partial boundary\nobservability result for the low-frequency solutions. The corresponding\nobservability time horizon increases with the eigenmode frequency, reflecting\nthe inherently slower propagation speed of the fractional waves.\n  2. Transmutation to the parabolic setting. Using transmutation techniques, we\ntransfer the observability results from the wave setting to the parabolic one.\nThis yields a frequency-dependent observability inequality for the fractional\nheat equation, which - via duality - enables control of its low-frequency\ncomponents.\n  3. Frequency-wise iteration. Leveraging the dissipative nature of the\nfractional heat equation, we develop an iterative procedure to successively\ncontrol the entire frequency spectrum of solutions. The condition $s \\in (1/2,\n1)$ is crucial in this analysis, as it guarantees sufficient decay of\nhigh-frequency components, enabling the convergence of the iteration.\n  4. Duality. By a duality argument, we derive boundary observability from the\nboundary controllability of the fractional heat equation. Remarkably, this type\nof boundary observability result is entirely new in the multi-dimensional\nsetting and appears to be out of reach for existing methods. \\end{itemize}","main_category":"math.AP","categories":"math.AP","published":"2025-04-24T10:11:56Z"}
{"aid":"http://arxiv.org/abs/2504.17419v1","title":"How Do Communities of ML-Enabled Systems Smell? A Cross-Sectional Study\n  on the Prevalence of Community Smells","summary":"Effective software development relies on managing both collaboration and\ntechnology, but sociotechnical challenges can harm team dynamics and increase\ntechnical debt. Although teams working on ML enabled systems are\ninterdisciplinary, research has largely focused on technical issues, leaving\ntheir socio-technical dynamics underexplored. This study aims to address this\ngap by examining the prevalence, evolution, and interrelations of community\nsmells, in open-source ML projects. We conducted an empirical study on 188\nrepositories from the NICHE dataset using the CADOCS tool to identify and\nanalyze community smells. Our analysis focused on their prevalence,\ninterrelations, and temporal variations. We found that certain smells, such as\nPrima Donna Effects and Sharing Villainy, are more prevalent and fluctuate over\ntime compared to others like Radio Silence or Organizational Skirmish. These\ninsights might provide valuable support for ML project managers in addressing\nsocio-technical issues and improving team coordination.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-24T10:23:37Z"}
{"aid":"http://arxiv.org/abs/2504.17429v1","title":"Wide-angle Scanning Heterogeneous Element-Based Phased Array Using Novel\n  Scanning Envelope Synthesis Method","summary":"Two novel methods, including the scanning envelope synthesis (SES) method and\nthe active reflection self-cancellation (ARC) method, are proposed to design\nwide-angle scanning heterogeneous element phased arrays. Heterogeneous strategy\nis efficient to extend scanning range but quantitatively characterization of\nthe effect is critically needed to guide design for achieving desired\nperformance. The proposed SES method derives theoretically the relationship\nbetween scanning range and the 3dB-beamwidth of the pattern envelope of one\nphased array, which is linear superposition of active radiation pattern (AEP)\nmagnitude of each element. Therefore, the contribution of each kind of\nheterogeneity can be quantitatively analyzed for further enhancing the scanning\nrange. As we see, a high active reflection coefficient of the phased array can\ndirectly reduce the realized gain. In this way, one ARC method is proposed to\nreduce the active reflection coefficient by counteracting the reflection\ncomponent of active reflection coefficient with its transmission component,\nthereby keeping the realized gain efficiently even when the array scans at\nlarge angels. For verification, one 24.5-29.5GHz 4x4 phased array scanning in\nE-plane is designed and fabricated. Benefiting from the proposed SES method,\nthe scanning range of the prototype is extended up to $\\pm74\\deg$, around\n10{\\deg} improvement over one traditional heterogeneous array. Meanwhile, the\nactive reflection coefficient is reduced from -4dB to lower than -7.5dB by\napplying the ARC method.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-24T10:43:33Z"}
{"aid":"http://arxiv.org/abs/2504.17473v1","title":"Wolves in the Repository: A Software Engineering Analysis of the XZ\n  Utils Supply Chain Attack","summary":"The digital economy runs on Open Source Software (OSS), with an estimated\n90\\% of modern applications containing open-source components. While this\nwidespread adoption has revolutionized software development, it has also\ncreated critical security vulnerabilities, particularly in essential but\nunder-resourced projects. This paper examines a sophisticated attack on the XZ\nUtils project (CVE-2024-3094), where attackers exploited not just code, but the\nentire open-source development process to inject a backdoor into a fundamental\nLinux compression library. Our analysis reveals a new breed of supply chain\nattack that manipulates software engineering practices themselves -- from\ncommunity management to CI/CD configurations -- to establish legitimacy and\nmaintain long-term control. Through a comprehensive examination of GitHub\nevents and development artifacts, we reconstruct the attack timeline, analyze\nthe evolution of attacker tactics. Our findings demonstrate how attackers\nleveraged seemingly beneficial contributions to project infrastructure and\nmaintenance to bypass traditional security measures. This work extends beyond\ntraditional security analysis by examining how software engineering practices\nthemselves can be weaponized, offering insights for protecting the open-source\necosystem.","main_category":"cs.SE","categories":"cs.SE,cs.CR","published":"2025-04-24T12:06:11Z"}
{"aid":"http://arxiv.org/abs/2504.17503v1","title":"Tailored minimal reservoir computing: on the bidirectional connection\n  between nonlinearities in the reservoir and in data","summary":"We study how the degree of nonlinearity in the input data affects the optimal\ndesign of reservoir computers, focusing on how closely the model's nonlinearity\nshould align with that of the data. By reducing minimal RCs to a single tunable\nnonlinearity parameter, we explore how the predictive performance varies with\nthe degree of nonlinearity in the reservoir. To provide controlled testbeds, we\ngeneralize to the fractional Halvorsen system, a novel chaotic system with\nfractional exponents. Our experiments reveal that the prediction performance is\nmaximized when the reservoir's nonlinearity matches the nonlinearity present in\nthe data. In cases where multiple nonlinearities are present in the data, we\nfind that the correlation dimension of the predicted signal is reconstructed\ncorrectly when the smallest nonlinearity is matched. We use this observation to\npropose a method for estimating the minimal nonlinearity in unknown time series\nby sweeping the reservoir exponent and identifying the transition to a\nsuccessful reconstruction. Applying this method to both synthetic and\nreal-world datasets, including financial time series, we demonstrate its\npractical viability. Finally, we transfer these insights to classical RC by\naugmenting traditional architectures with fractional, generalized reservoir\nstates. This yields performance gains, particularly in resource-constrained\nscenarios such as physical reservoirs, where increasing reservoir size is\nimpractical or economically unviable. Our work provides a principled route\ntoward tailoring RCs to the intrinsic complexity of the systems they aim to\nmodel.","main_category":"cs.LG","categories":"cs.LG,nlin.CD","published":"2025-04-24T12:47:21Z"}
{"aid":"http://arxiv.org/abs/2504.17537v1","title":"Long-time asymptotics of the Sawada-Kotera equation on the line","summary":"The Sawada-Kotera (SK) equation is an integrable system characterized by a\nthird-order Lax operator and is related to the modified Sawada-Kotera (mSK)\nequation through a Miura transformation. This work formulates the\nRiemann-Hilbert problem associated with the SK and mSK equations by using\ndirect and inverse scattering transforms. The long-time asymptotic behaviors of\nthe solutions to these equations are then analyzed via the Deift-Zhou steepest\ndescent method for Riemann-Hilbert problems. It is shown that the asymptotic\nsolutions of the SK and mSK equations are categorized into four distinct\nregions: the decay region, the dispersive wave region, the Painlev\\'{e} region,\nand the rapid decay region. Notably, the Painlev\\'{e} region is governed by the\nF-XVIII equation in the Painlev\\'{e} classification of fourth-order ordinary\ndifferential equations, a fourth-order analogue of the Painlev\\'{e}\ntranscendents. This connection is established through the Riemann-Hilbert\nformulation in this work. Similar to the KdV equation, the SK equation exhibits\na transition region between the dispersive wave and Painlev\\'{e} regions,\narising from the special values of the reflection coefficients at the origin.\nFinally, numerical comparisons demonstrate that the asymptotic solutions agree\nexcellently with results from direct numerical simulations.","main_category":"nlin.SI","categories":"nlin.SI,math.AP","published":"2025-04-24T13:26:20Z"}
{"aid":"http://arxiv.org/abs/2504.17549v1","title":"Premature supermassive black hole mergers in cosmological simulations of\n  structure formation","summary":"The co-evolution of massive black holes (BHs) and their host galaxies is\nwell-established within the hierarchical galaxy formation paradigm. Large-scale\ncosmological simulations are an ideal tool to study the repeated BH mergers,\naccretion and feedback that conspire to regulate this process. While such\nsimulations are of fundamental importance for understanding the complex and\nintertwined relationship between BHs and their hosts, they are plagued with\nnumerical inaccuracies at the scale of individual BH orbits. To quantify this\nissue, taking advantage of the $(100 \\, h^{-1}\\,\\text{cMpc})^3$ FABLE\nsimulation box, we track all individual BH mergers and the corresponding host\ngalaxy mergers as a function of cosmic time. We demonstrate that BH mergers\nfrequently occur prematurely, well before the corresponding merger of the host\ngalaxies is complete, and that BHs are sometimes erroneously displaced from\ntheir hosts during close galaxy encounters. Correcting for these artefacts\nresults in substantial macrophysical delays, spanning over several Gyrs, which\nare additional to any microphysical delays arising from unresolved BH binary\nhardening processes. We find that once the macrophysical delays are accounted\nfor, high-mass BH merger events are suppressed, affecting the predictions for\nthe BH population that may be observable with LISA and pulsar timing arrays.\nFurthermore, including these macrophysical delays leads to an increase in the\nnumber of observable dual active galactic nuclei, especially at lower\nredshifts, with respect to FABLE. Our results highlight the pressing need for\nmore accurate modelling of BH dynamics in cosmological simulations of galaxy\nformation as we prepare for the multi-messenger era.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-24T13:40:06Z"}
{"aid":"http://arxiv.org/abs/2504.17576v1","title":"Convex order and increasing convex order for McKean-Vlasov processes\n  with common noise","summary":"We establish results on the conditional and standard convex order, as well as\nthe increasing convex order, for two processes $ X = (X_t)_{t \\in [0, T]} $ and\n$ Y = (Y_t)_{t \\in [0, T]}$, defined by the following McKean-Vlasov equations\nwith common Brownian noise $B^0 = (B_t^0)_{t \\in [0, T]}$: \\begin{align} dX_t\n&= b(t, X_t, \\mathcal{L}^1(X_t))dt + \\sigma(t, X_t, \\mathcal{L}^1(X_t))dB_t +\n\\sigma^0(t, \\mathcal{L}^1(X_t))dB^0_t, \\\\ dY_t &= \\beta(t, Y_t,\n\\mathcal{L}^1(Y_t))dt + \\theta(t, Y_t, \\mathcal{L}^1(Y_t))dB_t + \\theta^0(t,\n\\mathcal{L}^1(Y_t))dB^0_t, \\end{align} where $\\mathcal{L}^1(X_t)$ (respectively\n$\\mathcal{L}^1(Y_t)$) denotes a version of the conditional distribution of\n$X_t$ (resp. $Y_t$) given $B^0$. These results extend those established for\nstandard McKean-Vlasov equations in [Liu and Pag\\`es, Ann. App. Prob. 2023] and\n[Liu and Pag\\`es, Bernoulli 2022]. Under suitable conditions, for a\n(non-decreasing) convex functional $F$ on the path space with polynomial\ngrowth, we show $\\mathbb{E}[F(X) \\mid B^0] \\leq \\mathbb{E}[F(Y) \\mid B^0]$\nalmost surely. Moreover, for a (non-decreasing) convex functional $G$ defined\non the product space of paths and their marginal distributions, we establish \\[\n\\mathbb{E} \\Big[\\,G\\big(X, (\\mathcal{L}^1(X_t))_{t\\in[0, T]}\\big)\\,\\Big| \\,\nB^0\\,\\Big]\\leq \\mathbb{E} \\Big[\\,G\\big(Y, (\\mathcal{L}^1(Y_t))_{t\\in[0,\nT]}\\big)\\,\\Big| \\, B^0\\,\\Big] \\quad \\text{almost surely}. \\] Similar convex\norder results are also established for the corresponding particle system. We\nexplore applications of these results to stochastic control problem - deducing\nin particular an associated comparison principle for Hamilton-Jacobi-Bellman\nequations with different coefficients - and to the interbank systemic risk\nmodel introduced by in [Carmona, Fouque and Sun, Comm. in Math. Sci. 2015].","main_category":"math.PR","categories":"math.PR","published":"2025-04-24T14:08:41Z"}
{"aid":"http://arxiv.org/abs/2504.17577v1","title":"TileLang: A Composable Tiled Programming Model for AI Systems","summary":"Modern AI workloads rely heavily on optimized computing kernels for both\ntraining and inference. These AI kernels follow well-defined data-flow\npatterns, such as moving tiles between DRAM and SRAM and performing a sequence\nof computations on those tiles. However, writing high-performance kernels\nremains complex despite the clarity of these patterns. Achieving peak\nperformance requires careful, hardware-centric optimizations to fully leverage\nmodern accelerators. While domain-specific compilers attempt to reduce the\nburden of writing high-performance kernels, they often struggle with usability\nand expressiveness gaps. In this paper, we present TileLang, a generalized\ntiled programming model for more efficient AI Kernel programming. TileLang\ndecouples scheduling space (thread binding, layout, tensorize and pipeline)\nfrom dataflow, and encapsulated them as a set of customization annotations and\nprimitives. This approach allows users to focus on the kernel's data-flow\nitself, while leaving most other optimizations to compilers. We conduct\ncomprehensive experiments on commonly-used devices, across numerous\nexperiments, our evaluation shows that TileLang can achieve state-of-the-art\nperformance in key kernels, demonstrating that its unified block-and-thread\nparadigm and transparent scheduling capabilities deliver both the power and\nflexibility demanded by modern AI system development.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-24T14:08:49Z"}
{"aid":"http://arxiv.org/abs/2504.17614v1","title":"Bolt: Clothing Virtual Characters at Scale","summary":"Clothing virtual characters is a time-consuming and often manual process.\nOutfits can be composed of multiple garments, and each garment must be fitted\nto the unique shape of a character. Since characters can vary widely in size\nand shape, fitting outfits to many characters is a combinatorially large\nproblem. We present Bolt, a system designed to take outfits originally authored\non a source body and fit them to new body shapes via a three stage transfer,\ndrape, and rig process. First, our new garment transfer method transforms each\ngarment's 3D mesh positions to the new character, then optimizes the garment's\n2D sewing pattern while maintaining key features of the original seams and\nboundaries. Second, our system simulates the transferred garments to\nprogressively drape and untangle each garment in the outfit. Finally, the\ngarments are rigged to the new character. This entire process is automatic,\nmaking it feasible to clothe characters at scale with no human intervention.\nClothed characters are then ready for immediate use in applications such as\ngaming, animation, synthetic generation, and more.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-24T14:38:09Z"}
{"aid":"http://arxiv.org/abs/2504.17622v1","title":"Likelihood-Free Variational Autoencoders","summary":"Variational Autoencoders (VAEs) typically rely on a probabilistic decoder\nwith a predefined likelihood, most commonly an isotropic Gaussian, to model the\ndata conditional on latent variables. While convenient for optimization, this\nchoice often leads to likelihood misspecification, resulting in blurry\nreconstructions and poor data fidelity, especially for high-dimensional data\nsuch as images. In this work, we propose \\textit{EnVAE}, a novel\nlikelihood-free generative framework that has a deterministic decoder and\nemploys the energy score -- a proper scoring rule -- to build the\nreconstruction loss. This enables likelihood-free inference without requiring\nexplicit parametric density functions. To address the computational\ninefficiency of the energy score, we introduce a fast variant, \\textit{FEnVAE},\nbased on the local smoothness of the decoder and the sharpness of the posterior\ndistribution of latent variables. This yields an efficient single-sample\ntraining objective that integrates seamlessly into existing VAE pipelines with\nminimal overhead. Empirical results on standard benchmarks demonstrate that\n\\textit{EnVAE} achieves superior reconstruction and generation quality compared\nto likelihood-based baselines. Our framework offers a general, scalable, and\nstatistically principled alternative for flexible and nonparametric\ndistribution learning in generative modeling.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-24T14:44:46Z"}
{"aid":"http://arxiv.org/abs/2504.17625v1","title":"Non-quadratic solutions to the Monge-Ampère equation","summary":"We construct ample smooth strictly plurisubharmonic non-quadratic solutions\nto the Monge-Amp\\`ere equation on either cylindrical type domains or the whole\ncomplex Euclidean space $\\mathbb C^2$. Among these, the entire solutions\ndefined on $\\mathbb C^2$ induce flat Kahler metrics, as expected by a question\nof Calabi. In contrast, those on cylindrical domains produce a family of\nnowhere flat Kahler metrics. Beyond these smooth solutions, we also classify\nsolutions that are radially symmetric in one variable, which exhibit various\ntypes of singularities. Finally, we explore analogous solutions to Donaldson's\nequation motivated by a result of He.","main_category":"math.CV","categories":"math.CV","published":"2025-04-24T14:48:28Z"}
{"aid":"http://arxiv.org/abs/2504.17626v1","title":"Improving Open-World Object Localization by Discovering Background","summary":"Our work addresses the problem of learning to localize objects in an\nopen-world setting, i.e., given the bounding box information of a limited\nnumber of object classes during training, the goal is to localize all objects,\nbelonging to both the training and unseen classes in an image, during\ninference. Towards this end, recent work in this area has focused on improving\nthe characterization of objects either explicitly by proposing new objective\nfunctions (localization quality) or implicitly using object-centric\nauxiliary-information, such as depth information, pixel/region affinity map\netc. In this work, we address this problem by incorporating background\ninformation to guide the learning of the notion of objectness. Specifically, we\npropose a novel framework to discover background regions in an image and train\nan object proposal network to not detect any objects in these regions. We\nformulate the background discovery task as that of identifying image regions\nthat are not discriminative, i.e., those that are redundant and constitute low\ninformation content. We conduct experiments on standard benchmarks to showcase\nthe effectiveness of our proposed approach and observe significant improvements\nover the previous state-of-the-art approaches for this task.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T14:48:46Z"}
{"aid":"http://arxiv.org/abs/2504.17637v1","title":"On the negative band number","summary":"We study the negative band number of braids, knots, and links using Birman,\nKo, and Lee's left-canonical form of a braid. As applications, we characterize\nup to conjugacy strongly quasipositive braids and almost strongly quasipositive\nbraids.","main_category":"math.GT","categories":"math.GT","published":"2025-04-24T15:08:44Z"}
{"aid":"http://arxiv.org/abs/2504.17645v1","title":"A common first integral from three-body secular theory and Kepler\n  billiards","summary":"We observe that a particular first integral of the partially-averaged system\nin the secular theory of the three-body problem appears also as an important\nconserved quantity of integrable Kepler billiards. In this note we illustrate\ntheir common roots with the projective dynamics of the two-center problem. We\nthen combine these two aspects to define a class of integrable billiard systems\non surfaces of constant curvature.","main_category":"math.DS","categories":"math.DS","published":"2025-04-24T15:14:21Z"}
{"aid":"http://arxiv.org/abs/2504.17649v1","title":"On Josephy-Halley method for generalized equations","summary":"We extend the classical third-order Halley iteration to the setting of\ngeneralized equations of the form \\[ 0 \\in f(x) + F(x), \\] where \\(f\\colon\nX\\longrightarrow Y\\) is twice continuously Fr\\'echet-differentiable on Banach\nspaces and \\(F\\colon X\\tto Y\\) is a set-valued mapping with closed graph.\nBuilding on predictor-corrector framework, our scheme first solves a partially\nlinearized inclusion to produce a predictor \\(u_{k+1}\\), then incorporates\nsecond-order information in a Halley-type corrector step to obtain \\(x_{k+1}\\).\nUnder metric regularity of the linearization at a reference solution and\nH\\\"older continuity of \\(f''\\), we prove that the iterates converge locally\nwith order \\(2+p\\) (cubically when \\(p=1\\)). Moreover, by constructing a\nsuitable scalar majorant function we derive semilocal Kantorovich-type\nconditions guaranteeing well-definedness and R-cubic convergence from an\nexplicit neighbourhood of the initial guess. Numerical experiments-including\none- and two-dimensional test problems confirm the theoretical convergence\nrates and illustrate the efficiency of the Josephy-Halley method compared to\nits Josephy-Newton counterpart.","main_category":"math.NA","categories":"math.NA,cs.NA,math.OC","published":"2025-04-24T15:18:59Z"}
{"aid":"http://arxiv.org/abs/2504.17653v1","title":"Towards a comprehensive taxonomy of online abusive language informed by\n  machine leaning","summary":"The proliferation of abusive language in online communications has posed\nsignificant risks to the health and wellbeing of individuals and communities.\nThe growing concern regarding online abuse and its consequences necessitates\nmethods for identifying and mitigating harmful content and facilitating\ncontinuous monitoring, moderation, and early intervention. This paper presents\na taxonomy for distinguishing key characteristics of abusive language within\nonline text. Our approach uses a systematic method for taxonomy development,\nintegrating classification systems of 18 existing multi-label datasets to\ncapture key characteristics relevant to online abusive language classification.\nThe resulting taxonomy is hierarchical and faceted, comprising 5 categories and\n17 dimensions. It classifies various facets of online abuse, including context,\ntarget, intensity, directness, and theme of abuse. This shared understanding\ncan lead to more cohesive efforts, facilitate knowledge exchange, and\naccelerate progress in the field of online abuse detection and mitigation among\nresearchers, policy makers, online platform owners, and other stakeholders.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-24T15:23:47Z"}
{"aid":"http://arxiv.org/abs/2504.17663v1","title":"The Malicious Technical Ecosystem: Exposing Limitations in Technical\n  Governance of AI-Generated Non-Consensual Intimate Images of Adults","summary":"In this paper, we adopt a survivor-centered approach to locate and dissect\nthe role of sociotechnical AI governance in preventing AI-Generated\nNon-Consensual Intimate Images (AIG-NCII) of adults, colloquially known as\n\"deep fake pornography.\" We identify a \"malicious technical ecosystem\" or\n\"MTE,\" comprising of open-source face-swapping models and nearly 200\n\"nudifying\" software programs that allow non-technical users to create AIG-NCII\nwithin minutes. Then, using the National Institute of Standards and Technology\n(NIST) AI 100-4 report as a reflection of current synthetic content governance\nmethods, we show how the current landscape of practices fails to effectively\nregulate the MTE for adult AIG-NCII, as well as flawed assumptions explaining\nthese gaps.","main_category":"cs.HC","categories":"cs.HC,cs.AI,cs.CY,cs.LG","published":"2025-04-24T15:31:46Z"}
{"aid":"http://arxiv.org/abs/2504.17688v1","title":"The Hubble Image Similarity Project","summary":"We have created a large database of similarity information between\nsub-regions of Hubble Space Telescope images. These data can be used to assess\nthe accuracy of image search algorithms based on computer vision methods. The\nimages were compared by humans in a citizen science project, where they were\nasked to select similar images from a comparison sample. We utilized the Amazon\nMechanical Turk system to pay our reviewers a fair wage for their work. Nearly\n850,000 comparison measurements have been analyzed to construct a similarity\ndistance matrix between all the pairs of images. We describe the algorithm used\nto extract a robust distance matrix from the (sometimes noisy) user reviews.\nThe results are very impressive: the data capture similarity between images\nbased on morphology, texture, and other details that are sometimes difficult\neven to describe in words (e.g., dusty absorption bands with sharp edges). The\ncollective visual wisdom of our citizen scientists matches the accuracy of the\ntrained eye, with even subtle differences among images faithfully reflected in\nthe distances.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-24T15:58:00Z"}
{"aid":"http://arxiv.org/abs/2504.17708v1","title":"Pushing the frontiers of subexponential FPT time for Feedback Vertex Set","summary":"The paper deals with the Feedback Vertex Set problem parameterized by the\nsolution size. Given a graph $G$ and a parameter $k$, one has to decide if\nthere is a set $S$ of at most $k$ vertices such that $G-S$ is acyclic. Assuming\nthe Exponential Time Hypothesis, it is known that FVS cannot be solved in time\n$2^{o(k)}n^{\\mathcal{O}(1)}$ in general graphs. To overcome this, many recent\nresults considered FVS restricted to particular intersection graph classes and\nprovided such $2^{o(k)}n^{\\mathcal{O}(1)}$ algorithms.\n  In this paper we provide generic conditions on a graph class for the\nexistence of an algorithm solving FVS in subexponential FPT time, i.e. time\n$2^{k^\\varepsilon} \\mathop{\\rm poly}(n)$, for some $\\varepsilon<1$, where $n$\ndenotes the number of vertices of the instance and $k$ the parameter. On the\none hand this result unifies algorithms that have been proposed over the years\nfor several graph classes such as planar graphs, map graphs, unit-disk graphs,\npseudo-disk graphs, and string graphs of bounded edge-degree. On the other hand\nit extends the tractability horizon of FVS to new classes that are not amenable\nto previously used techniques, in particular intersection graphs of ``thin''\nobjects like segment graphs or more generally $s$-string graphs.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-24T16:12:52Z"}
{"aid":"http://arxiv.org/abs/2504.17719v1","title":"Evaluating Uncertainty in Deep Gaussian Processes","summary":"Reliable uncertainty estimates are crucial in modern machine learning. Deep\nGaussian Processes (DGPs) and Deep Sigma Point Processes (DSPPs) extend GPs\nhierarchically, offering promising methods for uncertainty quantification\ngrounded in Bayesian principles. However, their empirical calibration and\nrobustness under distribution shift relative to baselines like Deep Ensembles\nremain understudied. This work evaluates these models on regression (CASP\ndataset) and classification (ESR dataset) tasks, assessing predictive\nperformance (MAE, Accu- racy), calibration using Negative Log-Likelihood (NLL)\nand Expected Calibration Error (ECE), alongside robustness under various\nsynthetic feature-level distribution shifts. Results indicate DSPPs provide\nstrong in-distribution calibration leveraging their sigma point approximations.\nHowever, compared to Deep Ensembles, which demonstrated superior robustness in\nboth per- formance and calibration under the tested shifts, the GP-based\nmethods showed vulnerabilities, exhibiting particular sensitivity in the\nobserved metrics. Our findings underscore ensembles as a robust baseline,\nsuggesting that while deep GP methods offer good in-distribution calibration,\ntheir practical robustness under distribution shift requires careful\nevaluation. To facilitate reproducibility, we make our code available at\nhttps://github.com/matthjs/xai-gp.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-24T16:31:55Z"}
{"aid":"http://arxiv.org/abs/2504.17725v1","title":"STGen: A Novel Lightweight IoT Testbed for Generating Sensor Traffic for\n  the Experimentation of IoT Protocol and its Application in Hybrid Network","summary":"A Wireless Sensor Network (WSN) is a network that does not rely on a fixed\ninfrastructure and consists of numerous sensors, such as temperature, humidity,\nGPS, and cameras, equipped with onboard processors that manage and monitor the\nenvironment in a specific area. As a result, building a real sensor network\ntestbed for verifying, validating, or experimenting with a newly designed\nprotocol presents considerable challenges in adapting a laboratory scenario due\nto the significant financial and logistical barriers, such as the need for\nspecialized hardware and large-scale deployments. Additionally, WSN suffers\nfrom severe constraints such as restricted power supply, short communication\nrange, limited bandwidth availability, and restricted memory storage.\nAddressing these challenges, this work presents a flexible testbed solution\nnamed STGen that enables researchers to experiment with IoT protocols in a\nhybrid environment that emulates WSN implementations with the physical Internet\nthrough a dedicated physical server named STGen core, which receives sensor\ntraffic and processes it for further actions. The STGen testbed is lightweight\nin memory usage and easy to deploy. Most importantly, STGen supports\nlarge-scale distributed systems, facilitates experimentation with IoT\nprotocols, and enables integration with back-end services for big data\nanalytics and statistical insights. The key feature of STGen is the integration\nof real-world IoT protocols and their applications with WSN. Its modular and\nlightweight design makes STGen efficient and enables it to outperform other\npopular testbeds, such as Gotham and GothX, reducing memory usage by 89\\%.\nWhile GothX takes approximately 26 minutes to establish a large topology with\nfour VM nodes and 498 Docker nodes, STGen requires only 1.645 seconds to\ninitialize the platform with 500 sensor nodes.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-24T16:38:37Z"}
{"aid":"http://arxiv.org/abs/2504.17739v1","title":"Interpretable Early Detection of Parkinson's Disease through Speech\n  Analysis","summary":"Parkinson's disease is a progressive neurodegenerative disorder affecting\nmotor and non-motor functions, with speech impairments among its earliest\nsymptoms. Speech impairments offer a valuable diagnostic opportunity, with\nmachine learning advances providing promising tools for timely detection. In\nthis research, we propose a deep learning approach for early Parkinson's\ndisease detection from speech recordings, which also highlights the vocal\nsegments driving predictions to enhance interpretability. This approach seeks\nto associate predictive speech patterns with articulatory features, providing a\nbasis for interpreting underlying neuromuscular impairments. We evaluated our\napproach using the Italian Parkinson's Voice and Speech Database, containing\n831 audio recordings from 65 participants, including both healthy individuals\nand patients. Our approach showed competitive classification performance\ncompared to state-of-the-art methods, while providing enhanced interpretability\nby identifying key speech features influencing predictions.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-24T16:50:52Z"}
{"aid":"http://arxiv.org/abs/2504.17785v1","title":"Silenzio: Secure Non-Interactive Outsourced MLP Training","summary":"Outsourcing the ML training to cloud providers presents a compelling\nopportunity for resource constrained clients, while it simultaneously bears\ninherent privacy risks, especially for highly sensitive training data. We\nintroduce Silenzio, the first fully non-interactive outsourcing scheme for the\ntraining of multi-layer perceptrons that achieves 128 bit security using FHE.\nUnlike traditional MPC based protocols that necessitate interactive\ncommunication between the client and server(s) or non-collusion assumptions\namong multiple servers, Silenzio enables the fire-and-forget paradigm without\nsuch assumptions. In this approach, the client encrypts the training data once,\nand the cloud server performs the training without any further interaction.\n  Silenzio operates over low bitwidth integers - never exceeding 8 bit - to\nmitigate the computational overhead of FHE. Our approach features a novel\nlow-bitwidth matrix multiplication that leverages input-dependent residue\nnumber systems and a Karatsuba-inspired multiplication routine, ensuring that\nno intermediate FHE-processed value overflows 8 bit. Starting from an\nRNS-to-MRNS conversion process, we propose an efficient block-scaling\nmechanism, which approximately shifts encrypted tensor values to the\nuser-specified most significant bits. To instantiate the backpropagation of the\nerror, Silenzio introduces a low-bitwidth and TFHE friendly gradient\ncomputation for the cross entropy loss.\n  Implemented using the state-of-the-art Concrete library, we evaluate Silenzio\non standard MLP training tasks regarding runtime as well as model performance\nand achieve similar classification accuracy as MLPs trained using standard\nPyTorch with 32 bit floating-point computations. Our open-source implementation\nrepresents a significant advancement in privacy-preserving ML, providing a new\nbaseline for secure and non-interactive outsourced MLP training.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-24T17:59:22Z"}
{"aid":"http://arxiv.org/abs/2504.19531v1","title":"Precision Determination of Scintillation Screen Parameters from Annual\n  Modulation Measurement of Pulsar Scintillation Arc Curvature with the FAST\n  Telescope","summary":"Pulsar scintillation observations have revealed ubiquitous discrete\nscintillation screens in the interstellar medium. A major obstacle in\nidentifying the nature of these screens is the uncertainty in their distances,\nwhich prevents precise correlation with known structures in the Milky Way. We\nused the Five-hundred-meter Aperture Spherical radio Telescope (FAST) to\nobserve PSR B1237+25, PSR 1842+14, and PSR 2021+51. We detected 10\nscintillation arcs in PSR B1237+25, 1 in PSR 1842+14, and at least 6 in PSR\n2021+51. By modeling the annual modulation of these scintillation arcs, we\nconstrained the distances of the scintillation screens, as well as the\nanisotropic scattering directions and the projected velocities in those\ndirections. The scintillation screens are distributed throughout the entire\npaths between Earth and the pulsars. Among these, the distance to the main\nscintillation screen toward PSR B1237+25 is $267^{+32}_{-28}$ pc, the\nscintillation screen toward PSR B1842+14 is at a distance of\n$240^{+210}_{-120}$ pc, and the main scintillation screen toward PSR B2021+51\nis located at $887^{+167}_{-132}$ pc. Several screens in our sample appear at\ndistances coinciding with the Local Bubble boundary, particularly the brightest\nscintillation arc toward PSR B1237+25. We provide a substantial sample of\nscintillation screen measurements, revealing the rich plasma density\nfluctuation structures present in the Milky Way.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.HE","published":"2025-04-28T07:14:56Z"}
{"aid":"http://arxiv.org/abs/2504.19544v1","title":"On Weight Enumeration and Structure Characterization of Polar Codes via\n  Group Actions","summary":"In this article, we provide a complete characterization of codewords in polar\ncodes with weights less than twice the minimum distance, using the group action\nof the lower triangular affine (LTA) group. We derive a closed-form formula for\nthe enumeration of such codewords. Furthermore, we introduce an enhanced\npartial order based on weight contributions, offering refined tools for code\ndesign. Our results extend previous work on Type II codewords to a full\ndescription of Type I codewords and offer new insights into the algebraic\nstructure underlying decreasing monomial codes, including polar and Reed-Muller\ncodes.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-28T07:48:17Z"}
{"aid":"http://arxiv.org/abs/2504.19551v1","title":"BinCoFer: Three-Stage Purification for Effective C/C++ Binary\n  Third-Party Library Detection","summary":"Third-party libraries (TPL) are becoming increasingly popular to achieve\nefficient and concise software development. However, unregulated use of TPL\nwill introduce legal and security issues in software development. Consequently,\nsome studies have attempted to detect the reuse of TPLs in target programs by\nconstructing a feature repository. Most of the works require access to the\nsource code of TPLs, while the others suffer from redundancy in the repository,\nlow detection efficiency, and difficulties in detecting partially referenced\nthird-party libraries. Therefore, we introduce BinCoFer, a tool designed for\ndetecting TPLs reused in binary programs. We leverage the work of binary code\nsimilarity detection(BCSD) to extract binary-format TPL features, making it\nsuitable for scenarios where the source code of TPLs is inaccessible. BinCoFer\nemploys a novel three-stage purification strategy to mitigate feature\nrepository redundancy by highlighting core functions and extracting\nfunction-level features, making it applicable to scenarios of partial reuse of\nTPLs. We have observed that directly using similarity threshold to determine\nthe reuse between two binary functions is inaccurate, a problem that previous\nwork has not addressed. Thus we design a method that uses weight to aggregate\nthe similarity between functions in the target binary and core functions to\nultimately judge the reuse situation with high frequency. To examine the\nability of BinCoFer, we compiled a dataset on ArchLinux and conduct comparative\nexperiments on it with other four most related works (i.e., ModX, B2SFinder,\nLibAM and BinaryAI)...","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-28T07:57:42Z"}
{"aid":"http://arxiv.org/abs/2504.19552v1","title":"Scattering for the positive density Hartree equation","summary":"We study the asymptotic stability for large times of homogeneous stationary\nstates for the nonlinear Hartree equation for density matrices in Rd for\nd\\geq3. We can reach both the optimal Sobolev and Schatten exponents for the\ninitial data, with a wide class of interaction potentials w (under the sole\nassumption that w is bounded, including in particular delta potentials). Our\nmethod relies on fractional Leibniz rules for density matrices to deal with the\nfractional critical Sobolev regularity s = d/2 -1 for odd d, as well as\nChrist-Kiselev lemmas in Schatten spaces.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP","published":"2025-04-28T07:58:26Z"}
{"aid":"http://arxiv.org/abs/2504.19565v1","title":"m-KAILIN: Knowledge-Driven Agentic Scientific Corpus Distillation\n  Framework for Biomedical Large Language Models Training","summary":"The rapid progress of large language models (LLMs) in biomedical research has\nunderscored the limitations of existing open-source annotated scientific\ncorpora, which are often insufficient in quantity and quality. Addressing the\nchallenge posed by the complex hierarchy of biomedical knowledge, we propose a\nknowledge-driven, multi-agent framework for scientific corpus distillation\ntailored for LLM training in the biomedical domain. Central to our approach is\na collaborative multi-agent architecture, where specialized agents, each guided\nby the Medical Subject Headings (MeSH) hierarchy, work in concert to\nautonomously extract, synthesize, and self-evaluate high-quality textual data\nfrom vast scientific literature. These agents collectively generate and refine\ndomain-specific question-answer pairs, ensuring comprehensive coverage and\nconsistency with biomedical ontologies while minimizing manual involvement.\nExtensive experimental results show that language models trained on our\nmulti-agent distilled datasets achieve notable improvements in biomedical\nquestion-answering tasks, outperforming both strong life sciences LLM baselines\nand advanced proprietary models. Notably, our AI-Ready dataset enables\nLlama3-70B to surpass GPT-4 with MedPrompt and Med-PaLM-2, despite their larger\nscale. Detailed ablation studies and case analyses further validate the\neffectiveness and synergy of each agent within the framework, highlighting the\npotential of multi-agent collaboration in biomedical LLM training.","main_category":"cs.CL","categories":"cs.CL,cs.AI,q-bio.QM","published":"2025-04-28T08:18:24Z"}
{"aid":"http://arxiv.org/abs/2504.19576v1","title":"Infinitely many solutions for a class of elliptic boundary value\n  problems with $(p,q)$-Kirchhoff type","summary":"In this paper, we investigate the existence of infinitely many solutions for\nthe following elliptic boundary value problem with $(p,q)$-Kirchhoff type\n  \\begin{eqnarray*} \\begin{cases}\n  -\\Big[M_1\\left(\\int_\\Omega|\\nabla u_1|^p dx\\right)\\Big]^{p-1}\\Delta_p\nu_1+\\Big[M_3\\left(\\int_\\Omega a_1(x)|u_1|^p\ndx\\right)\\Big]^{p-1}a_1(x)|u_1|^{p-2}u_1=G_{u_1}(x,u_1,u_2)\\ \\ \\mbox{in\n}\\Omega,\n  -\\Big[M_2\\left(\\int_\\Omega|\\nabla u_2|^q dx\\right)\\Big]^{q-1}\\Delta_q\nu_2+\\Big[M_4\\left(\\int_\\Omega a_2(x)|u_2|^q\ndx\\right)\\Big]^{q-1}a_2(x)|u_2|^{q-2}u_2=G_{u_2}(x,u_1,u_2)\\ \\ \\mbox{in\n}\\Omega,\n  u_1=u_2=0\\ \\ \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\ \\mbox{ on\n}\\partial\\Omega.\n  \\end{cases} \\end{eqnarray*}\n  By using a critical point theorem due to Ding in [Y. H. Ding, Existence and\nmultiplicity results for homoclinic solutions to a class of Hamiltonian\nsystems. Nonlinear Anal, 25(11)(1995)1095-1113], we obtain that system has\ninfinitely many solutions under the sub-$(p,q)$ conditions.","main_category":"math.AP","categories":"math.AP","published":"2025-04-28T08:33:29Z"}
{"aid":"http://arxiv.org/abs/2504.19580v1","title":"ARTEMIS: Autoregressive End-to-End Trajectory Planning with Mixture of\n  Experts for Autonomous Driving","summary":"This paper presents ARTEMIS, an end-to-end autonomous driving framework that\ncombines autoregressive trajectory planning with Mixture-of-Experts (MoE).\nTraditional modular methods suffer from error propagation, while existing\nend-to-end models typically employ static one-shot inference paradigms that\ninadequately capture the dynamic changes of the environment. ARTEMIS takes a\ndifferent method by generating trajectory waypoints sequentially, preserves\ncritical temporal dependencies while dynamically routing scene-specific queries\nto specialized expert networks. It effectively relieves trajectory quality\ndegradation issues encountered when guidance information is ambiguous, and\novercomes the inherent representational limitations of singular network\narchitectures when processing diverse driving scenarios. Additionally, we use a\nlightweight batch reallocation strategy that significantly improves the\ntraining speed of the Mixture-of-Experts model. Through experiments on the\nNAVSIM dataset, ARTEMIS exhibits superior competitive performance, achieving\n87.0 PDMS and 83.1 EPDMS with ResNet-34 backbone, demonstrates state-of-the-art\nperformance on multiple metrics.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-28T08:41:08Z"}
{"aid":"http://arxiv.org/abs/2504.19594v1","title":"Mapping the Italian Telegram Ecosystem","summary":"Telegram has become a major space for political discourse and alternative\nmedia. However, its lack of moderation allows misinformation, extremism, and\ntoxicity to spread. While prior research focused on these particular phenomena\nor topics, these have mostly been examined separately, and a broader\nunderstanding of the Telegram ecosystem is still missing. In this work, we fill\nthis gap by conducting a large-scale analysis of the Italian Telegram sphere,\nleveraging a dataset of 186 million messages from 13,151 chats collected in\n2023. Using network analysis, Large Language Models, and toxicity detection\ntools, we examine how different thematic communities form, align ideologically,\nand engage in harmful discourse within the Italian cultural context. Results\nshow strong thematic and ideological homophily. We also identify mixed\nideological communities where far-left and far-right rhetoric coexist on\nparticular geopolitical issues. Beyond political analysis, we find that\ntoxicity, rather than being isolated in a few extreme chats, appears widely\nnormalized within highly toxic communities. Moreover, we find that Italian\ndiscourse primarily targets Black people, Jews, and gay individuals\nindependently of the topic. Finally, we uncover common trend of intra-national\nhostility, where Italians often attack other Italians, reflecting regional and\nintra-regional cultural conflicts that can be traced back to old historical\ndivisions. This study provides the first large-scale mapping of the Italian\nTelegram ecosystem, offering insights into ideological interactions, toxicity,\nand identity-targets of hate and contributing to research on online toxicity\nacross different cultural and linguistic contexts on Telegram.","main_category":"cs.SI","categories":"cs.SI,cs.AI","published":"2025-04-28T08:58:18Z"}
{"aid":"http://arxiv.org/abs/2504.19598v1","title":"Lightweight Adapter Learning for More Generalized Remote Sensing Change\n  Detection","summary":"Deep learning methods have shown promising performances in remote sensing\nimage change detection (CD). However, existing methods usually train a\ndataset-specific deep network for each dataset. Due to the significant\ndifferences in the data distribution and labeling between various datasets, the\ntrained dataset-specific deep network has poor generalization performances on\nother datasets. To solve this problem, this paper proposes a change adapter\nnetwork (CANet) for a more universal and generalized CD. CANet contains\ndataset-shared and dataset-specific learning modules. The former explores the\ndiscriminative features of images, and the latter designs a lightweight adapter\nmodel, to deal with the characteristics of different datasets in data\ndistribution and labeling. The lightweight adapter can quickly generalize the\ndeep network for new CD tasks with a small computation cost. Specifically, this\npaper proposes an interesting change region mask (ICM) in the adapter, which\ncan adaptively focus on interested change objects and decrease the influence of\nlabeling differences in various datasets. Moreover, CANet adopts a unique batch\nnormalization layer for each dataset to deal with data distribution\ndifferences. Compared with existing deep learning methods, CANet can achieve\nsatisfactory CD performances on various datasets simultaneously. Experimental\nresults on several public datasets have verified the effectiveness and\nadvantages of the proposed CANet on CD. CANet has a stronger generalization\nability, smaller training costs (merely updating 4.1%-7.7% parameters), and\nbetter performances under limited training datasets than other deep learning\nmethods, which also can be flexibly inserted with existing deep models.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-28T09:01:56Z"}
{"aid":"http://arxiv.org/abs/2504.19628v1","title":"Molecular Dynamics Investigation of Static and Dynamic Interfacial\n  Properties in Ice-Polymer Premelting Layers","summary":"Premelting at the ice-polymer interfaces, in which a quasi-liquid layer (QLL)\nforms below the melting point, is strongly influenced by polymer surface\nchemistry; however, the molecular-scale mechanisms underlying these effects\nremain poorly understood. This study employs large-scale molecular dynamics\nsimulations combined with machine learning-assisted analysis to elucidate how\npolymer type (hydrophilic vs hydrophobic) modulates interfacial premelting. Our\nsimulations reveal that hydrophilic and hydrophobic polymer surfaces have\ndistinct effects on the QLL thickness, interfacial water structure, and\ndiffusivity. Specifically, a hydrophilic polymer interface promotes a thicker\nQLL with more ordered interfacial water and lower diffusivity, whereas a\nhydrophobic interface induces a thinner QLL with a less ordered interfacial\nwater structure and higher diffusivity. These results advance the understanding\nof polymer-mediated interfacial melting phenomena and offer guidance for\ndesigning anti-icing and low-friction materials.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-28T09:39:44Z"}
{"aid":"http://arxiv.org/abs/2504.19629v1","title":"IPAS: An Adaptive Sample Size Method for Weighted Finite Sum Problems\n  with Linear Equality Constraints","summary":"Optimization problems with the objective function in the form of weighted sum\nand linear equality constraints are considered. Given that the number of local\ncost functions can be large as well as the number of constraints, a stochastic\noptimization method is proposed. The method belongs to the class of variable\nsample size first order methods, where the sample size is adaptive and governed\nby the additional sampling technique earlier proposed in unconstrained\noptimization framework. The resulting algorithm may be a mini-batch method,\nincreasing sample size method, or even deterministic in a sense that it\neventually reaches the full sample size, depending on the problem and\nsimilarity of the local cost functions. Regarding the constraints, the method\nuses controlled, but inexact projections on the feasible set, yielding possibly\ninfeasible iterates. Almost sure convergence is proved under some standard\nassumptions for the stochastic framework, without imposing the convexity.\nNumerical results on relevant problems from CUTEst collection and real-world\ndata sets for logistic regression show the stability and the efficiency of the\nproposed method when compared to the state-of-the-art methods.","main_category":"math.OC","categories":"math.OC,G.1.6","published":"2025-04-28T09:41:13Z"}
{"aid":"http://arxiv.org/abs/2504.19671v1","title":"Varieties of mutual-visibility and general position on Sierpiński\n  graphs","summary":"The variety of mutual-visibility problems contains four members, as does the\nvariety of general position problems. The basic problem is to determine the\ncardinality of the largest such sets. In this paper, these eight invariants are\ninvestigated on Sierpi\\'nski graphs $S_p^n$. They are determined for the\nSierpi\\'nski graphs $S_p^2$, $p\\ge 3$. All, but the outer mutual-visibility\nnumber and the outer general position number, are also determined for $S_3^n$,\n$n\\ge 3$. In many of the cases the corresponding extremal sets are enumerated.","main_category":"math.CO","categories":"math.CO","published":"2025-04-28T10:56:51Z"}
{"aid":"http://arxiv.org/abs/2504.19702v1","title":"Security of a secret sharing protocol on the Qline","summary":"Secret sharing is a fundamental primitive in cryptography, and it can be\nachieved even with perfect security. However, the distribution of shares\nrequires computational assumptions, which can compromise the overall security\nof the protocol. While traditional Quantum Key Distribution (QKD) can maintain\nsecurity, its widespread deployment in general networks would incur prohibitive\ncosts. In this work, we present a quantum protocol for distributing additive\nsecret sharing of 0, which we prove to be composably secure within the Abstract\nCryptography framework. Moreover, our protocol targets the Qline, a recently\nproposed quantum network architecture designed to simplify and reduce the cost\nof quantum communication. Once the shares are distributed, they can be used to\nsecurely perform a wide range of cryptographic tasks, including standard\nadditive secret sharing, anonymous veto, and symmetric key establishment.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-28T11:56:45Z"}
{"aid":"http://arxiv.org/abs/2504.19754v1","title":"Reconstructing Context: Evaluating Advanced Chunking Strategies for\n  Retrieval-Augmented Generation","summary":"Retrieval-augmented generation (RAG) has become a transformative approach for\nenhancing large language models (LLMs) by grounding their outputs in external\nknowledge sources. Yet, a critical question persists: how can vast volumes of\nexternal knowledge be managed effectively within the input constraints of LLMs?\nTraditional methods address this by chunking external documents into smaller,\nfixed-size segments. While this approach alleviates input limitations, it often\nfragments context, resulting in incomplete retrieval and diminished coherence\nin generation. To overcome these shortcomings, two advanced techniques, late\nchunking and contextual retrieval, have been introduced, both aiming to\npreserve global context. Despite their potential, their comparative strengths\nand limitations remain unclear. This study presents a rigorous analysis of late\nchunking and contextual retrieval, evaluating their effectiveness and\nefficiency in optimizing RAG systems. Our results indicate that contextual\nretrieval preserves semantic coherence more effectively but requires greater\ncomputational resources. In contrast, late chunking offers higher efficiency\nbut tends to sacrifice relevance and completeness.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.CL","published":"2025-04-28T12:52:05Z"}
{"aid":"http://arxiv.org/abs/2504.19768v1","title":"Modulation transfer spectroscopy of $^7$Li D1 line","summary":"We present the first implementation of modulation transfer spectroscopy (MTS)\non the D$1$ line of $^7$Li, carried out in a compact heat-pipe vapor cell with\ncold windows. By varying the pump and probe intensities and polarization\nconfigurations, we systematically map the MTS error-signal amplitude, effective\nlinewidth, and slope for the ground-state crossover resonance\n$F=1\\times2\\rightarrow F'=2$. We observe Rabi-induced power broadening and\nidentify optimal conditions for laser frequency stabilization via tightly\nfocused beams with total power below 1 mW. The lin$\\perp$lin polarization\nconfiguration yields a sharp, symmetric, high-contrast error signal with a\nmaximal slope. Our findings establish the MTS spectrum of the $^7$Li D1 line\ntransitions as a reliable frequency reference for quantum technology and\nultracold atom experiments, particularly in scenarios where frequency\nstabilization must be achieved with low laser optical power.","main_category":"physics.atom-ph","categories":"physics.atom-ph","published":"2025-04-28T13:09:14Z"}
{"aid":"http://arxiv.org/abs/2504.19787v1","title":"Interpretable machine learning-guided design of Fe-based soft magnetic\n  alloys","summary":"We present a machine-learning guided approach to predict saturation\nmagnetization (MS) and coercivity (HC) in Fe-rich soft magnetic alloys,\nparticularly Fe-Si-B systems. ML models trained on experimental data reveals\nthat increasing Si and B content reduces MS from 1.81T (DFT~2.04 T) to ~1.54 T\n(DFT~1.56T) in Fe-Si-B, which is attributed to decreased magnetic density and\nstructural modifications. Experimental validation of ML predicted magnetic\nsaturation on Fe-1Si-1B (2.09T), Fe-5Si-5B (2.01T) and Fe-10Si-10B (1.54T)\nalloy compositions further support our findings. These trends are consistent\nwith density functional theory (DFT) predictions, which link increased\nelectronic disorder and band broadening to lower MS values. Experimental\nvalidation on selected alloys confirms the predictive accuracy of the ML model,\nwith good agreement across compositions. Beyond predictive accuracy, detailed\nuncertainty quantification and model interpretability including through feature\nimportance and partial dependence analysis reveals that MS is governed by a\nnonlinear interplay between Fe content, early transition metal ratios, and\nannealing temperature, while HC is more sensitive to processing conditions such\nas ribbon thickness and thermal treatment windows. The ML framework was further\napplied to Fe-Si-B/Cr/Cu/Zr/Nb alloys in a pseudo-quaternary compositional\nspace, which shows comparable magnetic properties to NANOMET\n(Fe84.8Si0.5B9.4Cu0.8 P3.5C1), FINEMET (Fe73.5Si13.5B9 Cu1Nb3), NANOPERM\n(Fe88Zr7B4Cu1), and HITPERM (Fe44Co44Zr7B4Cu1. Our fundings demonstrate the\npotential of ML framework for accelerated search of high-performance, Co- and\nNi-free, soft magnetic materials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.other,cs.LG","published":"2025-04-28T13:30:28Z"}
{"aid":"http://arxiv.org/abs/2504.19790v1","title":"TDP-43 multidomains and RNA modulate interactions and viscoelasticity in\n  biomolecular condensates","summary":"RNA-binding proteins form biomolecular condensates with RNA through phase\nseparation, playing crucial roles in various cellular processes. While\nintrinsically disordered regions (IDRs) are key drivers of phase separation,\nadditional factors such as folded domains and RNA also influence condensate\nformation and physical properties. However, the molecular mechanisms underlying\nthis regulation remain elusive. Here, using molecular dynamics simulations, we\ninvestigate how the multidomain structure of TDP-43, which consists of its IDR,\nRNA recognition motifs (RRMs), and N-terminal domain (NTD), interacts with RNA\nand affects the characteristics of phase separation. Our analysis reveals that\ninteraction sites within the IDR undergo dynamic rearrangement, driven by key\nresidues that depend on the specific combination of folded domains. Upon RNA\nbinding, several intermolecular interactions of TDP-43 are replaced by\nTDP-43-polyA interactions, altering viscoelastic properties of the condensate.\nSpecifically, RRMs enhance viscosity, whereas the NTD reduces it. The presence\nof polyA increases elasticity, making viscosity and elasticity comparable in\nmagnitude. These findings suggest that the multidomain structure of TDP-43 and\nits RNA interactions orchestrate condensate organization, modulating their\nviscoelastic properties.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.comp-ph,q-bio.BM","published":"2025-04-28T13:34:20Z"}
{"aid":"http://arxiv.org/abs/2504.19812v1","title":"Hyper-differential sensitivity analysis with respect to model\n  discrepancy: Prior Distributions","summary":"Hyper-differential sensitivity analysis with respect to model discrepancy was\nrecently developed to enable uncertainty quantification for optimization\nproblems. The approach consists of two primary steps: (i) Bayesian calibration\nof the discrepancy between high- and low-fidelity models, and (ii) propagating\nthe model discrepancy uncertainty through the optimization problem. When\nhigh-fidelity model evaluations are limited, as is common in practice, the\nprior discrepancy distribution plays a crucial role in the uncertainty\nanalysis. However, specification of this prior is challenging due to its\nmathematical complexity and many hyper-parameters. This article presents a\nnovel approach to specify the prior distribution. Our approach consists of two\nparts: (1) an algorithmic initialization of the prior hyper-parameters that\nuses existing data to initialize a hyper-parameter estimate, and (2) a\nvisualization framework to systematically explore properties of the prior and\nguide tuning of the hyper-parameters to ensure that the prior captures the\nappropriate range of uncertainty. We provide detailed mathematical analysis and\na collection of numerical examples that elucidate properties of the prior that\nare crucial to ensure uncertainty quantification.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-28T14:09:37Z"}
{"aid":"http://arxiv.org/abs/2504.19836v1","title":"Independence Polynomials of 2-step Nilpotent Lie Algebras","summary":"Motivated by the Dani-Mainkar construction, we extend the notion of\nindependence polynomial of graphs to arbitrary 2-step nilpotent Lie algebras.\nAfter establishing efficiently computable upper and lower bounds for the\nindependence number, we discuss a metric-dependent generalization motivated by\na quantum mechanical interpretation of our construction. As an application, we\nderive elementary bounds for the dimension of abelian subalgebras of 2-step\nnilpotent Lie algebras.","main_category":"math.RA","categories":"math.RA","published":"2025-04-28T14:37:46Z"}
{"aid":"http://arxiv.org/abs/2504.19840v1","title":"Optimizing the Charging of Open Quantum Batteries using Long Short-Term\n  Memory-Driven Reinforcement Learning","summary":"Controlling the charging process of a quantum battery involves strategies to\nefficiently transfer, store, and retain energy, while mitigating decoherence,\nenergy dissipation, and inefficiencies caused by surrounding interactions. We\ndevelop a model to study the charging process of a quantum battery in an open\nquantum setting, where the battery interacts with a charger and a structured\nreservoir. To overcome the limitations of static charging protocols, a\nreinforcement learning (RL) charging strategy is proposed, which utilizes the\ndeep deterministic policy gradient algorithm alongside long short-term memory\n(LSTM) networks. The LSTM networks enable the RL model to capture temporal\ncorrelations driven by non-Markovian dynamics, facilitating a continuous,\nadaptive charging strategy. The RL protocols consistently outperform\nconventional fixed heuristic strategies by real-time controlling the driving\nfield amplitude and coupling parameters. By penalizing battery-to-charger\nbackflow in the reward function, the RL-optimized charging strategy promotes\nefficient unidirectional energy transfer from charger to battery, achieving\nhigher and more stable extractable work. The proposed RL controller would\nprovide a framework for designing efficient charging schemes in broader\nconfigurations and multi-cell quantum batteries.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-28T14:40:11Z"}
{"aid":"http://arxiv.org/abs/2504.19863v1","title":"Towards Ball Spin and Trajectory Analysis in Table Tennis Broadcast\n  Videos via Physically Grounded Synthetic-to-Real Transfer","summary":"Analyzing a player's technique in table tennis requires knowledge of the\nball's 3D trajectory and spin. While, the spin is not directly observable in\nstandard broadcasting videos, we show that it can be inferred from the ball's\ntrajectory in the video. We present a novel method to infer the initial spin\nand 3D trajectory from the corresponding 2D trajectory in a video. Without\nground truth labels for broadcast videos, we train a neural network solely on\nsynthetic data. Due to the choice of our input data representation, physically\ncorrect synthetic training data, and using targeted augmentations, the network\nnaturally generalizes to real data. Notably, these simple techniques are\nsufficient to achieve generalization. No real data at all is required for\ntraining. To the best of our knowledge, we are the first to present a method\nfor spin and trajectory prediction in simple monocular broadcast videos,\nachieving an accuracy of 92.0% in spin classification and a 2D reprojection\nerror of 0.19% of the image diagonal.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-28T14:55:12Z"}
{"aid":"http://arxiv.org/abs/2504.19894v1","title":"CineVerse: Consistent Keyframe Synthesis for Cinematic Scene Composition","summary":"We present CineVerse, a novel framework for the task of cinematic scene\ncomposition. Similar to traditional multi-shot generation, our task emphasizes\nthe need for consistency and continuity across frames. However, our task also\nfocuses on addressing challenges inherent to filmmaking, such as multiple\ncharacters, complex interactions, and visual cinematic effects. In order to\nlearn to generate such content, we first create the CineVerse dataset. We use\nthis dataset to train our proposed two-stage approach. First, we prompt a large\nlanguage model (LLM) with task-specific instructions to take in a high-level\nscene description and generate a detailed plan for the overall setting and\ncharacters, as well as the individual shots. Then, we fine-tune a text-to-image\ngeneration model to synthesize high-quality visual keyframes. Experimental\nresults demonstrate that CineVerse yields promising improvements in generating\nvisually coherent and contextually rich movie scenes, paving the way for\nfurther exploration in cinematic video synthesis.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-28T15:28:14Z"}
{"aid":"http://arxiv.org/abs/2504.19905v1","title":"Fractional Sturm-Liouville problem on metric graphs","summary":"In the present paper, we investigate the fractional analog of the\nSturm-Liouville problem on a metric graph using a combination of left\nRiemann-Liouville and right Caputo fractional derivatives. This combination\ncreates a symmetric and positive analog of the Sturm-Liouville operator. We\ndemonstrated that the operator has a countable number of eigenvalues converging\nto infinity and analyzed the convergence of the series of the reciprocal\neigenvalues, providing estimates for the eigenfunctions.","main_category":"math.AP","categories":"math.AP","published":"2025-04-28T15:39:03Z"}
{"aid":"http://arxiv.org/abs/2504.19908v1","title":"Finitness of measured homoclinic classes with large Lyapunov exponents\n  for $\\mathcal{C}^2$ surface diffeomorphisms","summary":"We show the finiteness of homoclinic classes carrying measures with large\nLyapunov exponents for $\\mathcal{C}^2$ surface diffeomorphisms. As a\nconsequence, we derive the finiteness of the set of ergodic measures of maximal\nentropy, in the case where the entropy of the system is large.","main_category":"math.DS","categories":"math.DS","published":"2025-04-28T15:40:14Z"}
{"aid":"http://arxiv.org/abs/2504.19912v1","title":"Can AI Agents Design and Implement Drug Discovery Pipelines?","summary":"The rapid advancement of artificial intelligence, particularly autonomous\nagentic systems based on Large Language Models (LLMs), presents new\nopportunities to accelerate drug discovery by improving in-silico modeling and\nreducing dependence on costly experimental trials. Current AI agent-based\nsystems demonstrate proficiency in solving programming challenges and\nconducting research, indicating an emerging potential to develop software\ncapable of addressing complex problems such as pharmaceutical design and drug\ndiscovery. This paper introduces DO Challenge, a benchmark designed to evaluate\nthe decision-making abilities of AI agents in a single, complex problem\nresembling virtual screening scenarios. The benchmark challenges systems to\nindependently develop, implement, and execute efficient strategies for\nidentifying promising molecular structures from extensive datasets, while\nnavigating chemical space, selecting models, and managing limited resources in\na multi-objective context. We also discuss insights from the DO Challenge 2025,\na competition based on the proposed benchmark, which showcased diverse\nstrategies explored by human participants. Furthermore, we present the Deep\nThought multi-agent system, which demonstrated strong performance on the\nbenchmark, outperforming most human teams. Among the language models tested,\nClaude 3.7 Sonnet, Gemini 2.5 Pro and o3 performed best in primary agent roles,\nand GPT-4o, Gemini 2.0 Flash were effective in auxiliary roles. While\npromising, the system's performance still fell short of expert-designed\nsolutions and showed high instability, highlighting both the potential and\ncurrent limitations of AI-driven methodologies in transforming drug discovery\nand broader scientific research.","main_category":"cs.AI","categories":"cs.AI,cs.MA","published":"2025-04-28T15:41:28Z"}
{"aid":"http://arxiv.org/abs/2504.19918v1","title":"Enhancing Surgical Documentation through Multimodal Visual-Temporal\n  Transformers and Generative AI","summary":"The automatic summarization of surgical videos is essential for enhancing\nprocedural documentation, supporting surgical training, and facilitating\npost-operative analysis. This paper presents a novel method at the intersection\nof artificial intelligence and medicine, aiming to develop machine learning\nmodels with direct real-world applications in surgical contexts. We propose a\nmulti-modal framework that leverages recent advancements in computer vision and\nlarge language models to generate comprehensive video summaries. % The approach\nis structured in three key stages. First, surgical videos are divided into\nclips, and visual features are extracted at the frame level using visual\ntransformers. This step focuses on detecting tools, tissues, organs, and\nsurgical actions. Second, the extracted features are transformed into\nframe-level captions via large language models. These are then combined with\ntemporal features, captured using a ViViT-based encoder, to produce clip-level\nsummaries that reflect the broader context of each video segment. Finally, the\nclip-level descriptions are aggregated into a full surgical report using a\ndedicated LLM tailored for the summarization task. % We evaluate our method on\nthe CholecT50 dataset, using instrument and action annotations from 50\nlaparoscopic videos. The results show strong performance, achieving 96\\%\nprecision in tool detection and a BERT score of 0.74 for temporal context\nsummarization. This work contributes to the advancement of AI-assisted tools\nfor surgical reporting, offering a step toward more intelligent and reliable\nclinical documentation.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-28T15:46:02Z"}
{"aid":"http://arxiv.org/abs/2504.19949v1","title":"Capturing Aerodynamic Characteristics of ATTAS Aircraft with Evolving\n  Intelligent System","summary":"Accurate modeling of aerodynamic coefficients is crucial for understanding\nand optimizing the performance of modern aircraft systems. This paper presents\nthe novel deployment of an Evolving Type-2 Quantum Fuzzy Neural Network\n(eT2QFNN) for modeling the aerodynamic coefficients of the ATTAS aircraft to\nexpress the aerodynamic characteristics. eT2QFNN can represent the nonlinear\naircraft model by creating multiple linear submodels with its rule-based\nstructure through an incremental learning strategy rather than a traditional\nbatch learning approach. Moreover, it enhances robustness to uncertainties and\ndata noise through its quantum membership functions, as well as its automatic\nrule-learning and parameter-tuning capabilities. During the estimation of the\naerodynamic coefficients via the flight data of the ATTAS, two different\nstudies are conducted in the training phase: one with a large amount of data\nand the other with a limited amount of data. The results show that the modeling\nperformance of the eT2QFNN is superior in comparison to baseline counterparts.\nFurthermore, eT2QFNN estimated the aerodynamic model with fewer rules compared\nto Type-1 fuzzy counterparts. In addition, by applying the Delta method to the\nproposed approach, the stability and control derivatives of the aircraft are\nanalyzed. The results prove the superiority of the proposed eT2QFNN in\nrepresenting aerodynamic coefficients.","main_category":"eess.SY","categories":"eess.SY,cs.AI,cs.SY","published":"2025-04-28T16:21:20Z"}
{"aid":"http://arxiv.org/abs/2504.19976v1","title":"Formation of trapped surfaces for the Einstein--Maxwell--charged scalar\n  field system","summary":"In this paper, we prove a scale-critical trapped surface formation result for\nthe Einstein--Maxwell--charged scalar field (EMCSF) system, without any\nsymmetry assumptions. Specifically, we establish a scale-critical semi-global\nexistence theorem from past null infinity and show that the focusing of\ngravitational waves, the concentration of electromagnetic fields, or the\ncondensation of complex scalar fields, each individually, can lead to the\nformation of a trapped surface. In addition, we capture a nontrivial charging\nprocess along past null infinity, which introduces new difficulties due to the\nabnormal behavior of the matter fields. Nevertheless, the semi-global existence\nresult and the formation of a trapped surface remain valid.","main_category":"math.AP","categories":"math.AP,gr-qc,math.DG","published":"2025-04-28T16:49:11Z"}
{"aid":"http://arxiv.org/abs/2504.19977v1","title":"$^{208}$Pb nuclear charge radius revisited: closing the\n  fine-structure-anomaly gap","summary":"A comprehensive reevaluation of the root-mean-square nuclear charge radius is\npresented for the doubly magic $^{208}$Pb extracted from muonic spectroscopy\nmeasurements. By integrating rigorous theoretical quantum electrodynamics\ncalculations, state-of-the-art numerical methods, and a systematic reanalysis\nof the uncertainties, we reduced the long-standing muonic fine-structure\nanomaly and improved the goodness of fit by a factor of twenty. The resulting\nvalue of 5.5062(5) fm is fairly consistent with the previously reported muonic\nspectroscopy value, and three standard deviations larger than the commonly used\ncompilation data, which indicates that the current value and its uncertainty\ncould be significantly underestimated. Our study paves a new path for\nsystematic reevaluation of all rms radii based on muonic spectroscopy.","main_category":"physics.atom-ph","categories":"physics.atom-ph,nucl-th","published":"2025-04-28T16:49:59Z"}
{"aid":"http://arxiv.org/abs/2504.20001v1","title":"Engineering Minimal k-Perfect Hash Functions","summary":"Given a set S of n keys, a k-perfect hash function (kPHF) is a data structure\nthat maps the keys to the first m integers, where each output integer can be\nhit by at most k input keys. When m=n/k, the resulting function is called a\nminimal k-perfect hash function (MkPHF). Applications of kPHFs can be found in\nexternal memory data structures or to create efficient 1-perfect hash\nfunctions, which in turn have a wide range of applications from databases to\nbioinformatics. Several papers from the 1980s look at external memory data\nstructures with small internal memory indexes. However, actual k-perfect hash\nfunctions are surprisingly rare, and the area has not seen a lot of research\nrecently. At the same time, recent research in 1-perfect hashing shows that\nthere is a lack of efficient kPHFs. In this paper, we revive the area of\nk-perfect hashing, presenting four new constructions. Our implementations\nsimultaneously dominate older approaches in space consumption, construction\ntime, and query time. We see this paper as a possible starting point of an\nactive line of research, similar to the area of 1-perfect hashing.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-28T17:22:40Z"}
{"aid":"http://arxiv.org/abs/2504.20391v1","title":"The Mean of Multi-Object Trajectories","summary":"This paper introduces the concept of a mean for trajectories and multi-object\ntrajectories--sets or multi-sets of trajectories--along with algorithms for\ncomputing them. Specifically, we use the Fr\\'{e}chet mean, and metrics based on\nthe optimal sub-pattern assignment (OSPA) construct, to extend the notion of\naverage from vectors to trajectories and multi-object trajectories. Further, we\ndevelop efficient algorithms to compute these means using greedy search and\nGibbs sampling. Using distributed multi-object tracking as an application, we\ndemonstrate that the Fr\\'{e}chet mean approach to multi-object trajectory\nconsensus significantly outperforms state-of-the-art distributed multi-object\ntracking methods.","main_category":"eess.SP","categories":"eess.SP,cs.RO","published":"2025-04-29T03:25:39Z"}
{"aid":"http://arxiv.org/abs/2504.20401v1","title":"Nonlinear Computation with Linear Optics via Source-Position Encoding","summary":"Optical computing systems provide an alternate hardware model which appears\nto be aligned with the demands of neural network workloads. However, the\nchallenge of implementing energy efficient nonlinearities in optics -- a key\nrequirement for realizing neural networks -- is a conspicuous missing link. In\nthis work we introduce a novel method to achieve nonlinear computation in fully\nlinear media. Our method can operate at low power and requires only the ability\nto drive the optical system at a data-dependent spatial position. Leveraging\nthis positional encoding, we formulate a fully automated,\ntopology-optimization-based hardware design framework for extremely specialized\noptical neural networks, drawing on modern advancements in optimization and\nmachine learning. We evaluate our optical designs on machine learning\nclassification tasks: demonstrating significant improvements over linear\nmethods, and competitive performance when compared to standard artificial\nneural networks.","main_category":"physics.optics","categories":"physics.optics,cs.AR,cs.LG","published":"2025-04-29T03:55:05Z"}
{"aid":"http://arxiv.org/abs/2504.20404v1","title":"Beyond Robertson-Schrödinger: A General Uncertainty Relation Unveiling\n  Hidden Noncommutative Trade-offs","summary":"We report a universal strengthening of the Robertson-Schr\\''odinger\nuncertainty relation, revealing a previously overlooked trade-off of genuinely\nquantum origin, particularly as the state becomes more mixed. Remarkably, this\ngeneralized bound supplements the standard commutator term and the covariance\nterm with an additional positive contribution that depends on the commutator of\nobservables. The relation also rigorously proves and extends a conjectured\nuncertainty relation previously proposed in [Phys. Rev. A 110, 062215 (2024)].\nFor two-level quantum systems, the inequality becomes an exact equality for any\nstate and any pair of observables, establishing that the bound is tight in the\nstrongest possible sense.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech,hep-th,math-ph,math.MP,physics.ed-ph","published":"2025-04-29T04:00:02Z"}
{"aid":"http://arxiv.org/abs/2504.20428v1","title":"Escaping Helium and a Highly Muted Spectrum Suggest a Metal-Enriched\n  Atmosphere on Sub-Neptune GJ3090b from JWST Transit Spectroscopy","summary":"Sub-Neptunes, the most common planet type, remain poorly understood. Their\natmospheres are expected to be diverse, but their compositions are challenging\nto determine, even with JWST. Here, we present the first JWST spectroscopic\nstudy of the warm sub-Neptune GJ3090b (2.13R$_\\oplus$, Teq~700 K) which orbits\nan M2V star, making it a favourable target for atmosphere characterization. We\nobserved four transits of GJ3090b; two each using JWST NIRISS/SOSS and\nNIRSpec/G395H, yielding wavelength coverage from 0.6-5.2 $\\mu$m. We detect the\nsignature of the 10833 \\r{A} metastable Helium triplet at a statistical\nsignificance of 5.5$\\sigma$ with an amplitude of 434$\\pm$79 ppm, marking the\nfirst such detection in a sub-Neptune with JWST. This amplitude is\nsignificantly smaller than predicted by solar-metallicity forward models,\nsuggesting a metal-enriched atmosphere which decreases the mass-loss rate and\nattenuates the Helium feature amplitude. Moreover, we find that stellar\ncontamination, in the form of the transit light source effect, dominates the\nNIRISS transmission spectra, with unocculted spot and faculae properties\nvarying across the two visits separated in time by approximately six months.\nFree retrieval analyses on the NIRSpec/G395H spectrum find tentative evidence\nfor highly muted features and a lack of CH4. These findings are best explained\nby a high metallicity atmosphere (>100x solar at 3$\\sigma$ confidence, for\nclouds at $\\sim \\mu$bar pressures) using chemically-consistent retrievals and\nself-consistent model grids. Further observations of GJ3090b are needed for\ntighter constraints on the atmospheric abundances, and to gain a deeper\nunderstanding of the processes that led to its potential metal enrichment.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-29T04:48:16Z"}
{"aid":"http://arxiv.org/abs/2504.20429v1","title":"Estimating the housing production function with unobserved land\n  heterogeneity","summary":"This paper develops a novel method for estimating the housing production\nfunction that addresses transmission bias caused by unobserved heterogeneity in\nland productivity. The approach builds on the nonparametric identification\nstrategy of Gandhi et al. (2020) and exploits the zero-profit condition to\nallow consistent estimation even when either capital input or housing value is\nunobserved, under the assumption that land productivity follows a Markov\nprocess. Monte Carlo simulations demonstrate that the estimator performs well\nacross a variety of production technologies.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-29T04:51:35Z"}
{"aid":"http://arxiv.org/abs/2504.20469v1","title":"Fane at SemEval-2025 Task 10: Zero-Shot Entity Framing with Large\n  Language Models","summary":"Understanding how news narratives frame entities is crucial for studying\nmedia's impact on societal perceptions of events. In this paper, we evaluate\nthe zero-shot capabilities of large language models (LLMs) in classifying\nframing roles. Through systematic experimentation, we assess the effects of\ninput context, prompting strategies, and task decomposition. Our findings show\nthat a hierarchical approach of first identifying broad roles and then\nfine-grained roles, outperforms single-step classification. We also demonstrate\nthat optimal input contexts and prompts vary across task levels, highlighting\nthe need for subtask-specific strategies. We achieve a Main Role Accuracy of\n89.4% and an Exact Match Ratio of 34.5%, demonstrating the effectiveness of our\napproach. Our findings emphasize the importance of tailored prompt design and\ninput context optimization for improving LLM performance in entity framing.","main_category":"cs.CL","categories":"cs.CL,cs.CY,I.2.7","published":"2025-04-29T07:10:53Z"}
{"aid":"http://arxiv.org/abs/2504.20486v1","title":"Criticality of charged AdS black holes with string clouds in boundary\n  conformal field theory","summary":"The aim of this letter is to study the universal thermodynamics and\ncriticality of charged AdS black holes with string clouds in the bulk and in\nthe boundary conformal field theory (CFT). For this system, we determined the\ncritical quantities and noticed that the free energy in the bulk exhibits\nswallow tail behavior. In the boundary CFT, the presence of second order phase\ntransition is observed. At constant charge, the heat capacity is finite in the\nbulk but diverges at critical points in the boundary CFT. Furthermore, we tried\nto determine the nature of interactions between black hole molecules in the\nboundary CFT and in the bulk, which is novel for charged AdS black holes with\nstring clouds.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-29T07:24:37Z"}
{"aid":"http://arxiv.org/abs/2504.20490v1","title":"Hetu v2: A General and Scalable Deep Learning System with Hierarchical\n  and Heterogeneous Single Program Multiple Data Annotations","summary":"The Single Program Multiple Data (SPMD) paradigm provides a unified\nabstraction to annotate various parallel dimensions in distributed deep\nlearning (DL) training. With SPMD, users can write training programs from the\nviewpoint of a single device, and the system will automatically deduce the\ntensor sharding and communication patterns. However, with the recent\ndevelopment in large-scale DL models, distributed training exhibits spatial and\ntemporal workload heterogeneity, arising from both device disparities (e.g.,\nmixed hardware, failures) and data variations (e.g., uneven sequence lengths).\nSuch heterogeneity violates SPMD's assumption of uniform workload partitioning,\nwhich restricts its ability to express and optimize heterogeneous parallel\nstrategies effectively.\n  To address this, we propose HSPMD within the Hetu v2 system to achieve\ngeneral and scalable DL training. HSPMD extends SPMD's annotations to support\nasymmetric sharding and composes standard communication primitives for\nhierarchical communication, all while retaining the simplicity of a\nsingle-device declarative programming model. Leveraging HSPMD, Hetu handles\nspatial heterogeneity through progressive graph specialization, enabling\ndevice-specific execution logic, and addresses temporal heterogeneity via\ndynamic graph switching. Evaluations on heterogeneous clusters, elastic\ntraining, and mixed-length data scenarios show that HSPMD matches or\noutperforms specialized systems, providing a flexible and efficient solution\nfor modern large-scale model training.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-29T07:27:54Z"}
{"aid":"http://arxiv.org/abs/2504.20491v1","title":"Separation and Definability in Fragments of Two-Variable First-Order\n  Logic with Counting","summary":"For fragments L of first-order logic (FO) with counting quantifiers, we\nconsider the definability problem, which asks whether a given L-formula can be\nequivalently expressed by a formula in some fragment of L without counting, and\nthe more general separation problem asking whether two mutually exclusive\nL-formulas can be separated in some counting-free fragment of L. We show that\nseparation is undecidable for the two-variable fragment of FO extended with\ncounting quantifiers and for the graded modal logic with inverse, nominals and\nuniversal modality. On the other hand, if inverse or nominals are dropped,\nseparation becomes coNExpTime- or 2ExpTime-complete, depending on whether the\nuniversal modality is present. In contrast, definability can often be reduced\nin polynomial time to validity in L. We also consider uniform separation and\nshow that it often behaves similarly to definability.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-29T07:30:57Z"}
{"aid":"http://arxiv.org/abs/2504.20492v1","title":"Triadic Closure-Heterogeneity-Harmony GCN for Link Prediction","summary":"Link prediction aims to estimate the likelihood of connections between pairs\nof nodes in complex networks, which is beneficial to many applications from\nfriend recommendation to metabolic network reconstruction. Traditional\nheuristic-based methodologies in the field of complex networks typically depend\non predefined assumptions about node connectivity, limiting their\ngeneralizability across diverse networks. While recent graph neural network\n(GNN) approaches capture global structural features effectively, they often\nneglect node attributes and intrinsic structural relationships between node\npairs. To address this, we propose TriHetGCN, an extension of traditional Graph\nConvolutional Networks (GCNs) that incorporates explicit topological indicators\n-- triadic closure and degree heterogeneity. TriHetGCN consists of three\nmodules: topology feature construction, graph structural representation, and\nconnection probability prediction. The topology feature module constructs node\nfeatures using shortest path distances to anchor nodes, enhancing global\nstructure perception. The graph structural module integrates topological\nindicators into the GCN framework to model triadic closure and heterogeneity.\nThe connection probability module uses deep learning to predict links.\nEvaluated on nine real-world datasets, from traditional networks without node\nattributes to large-scale networks with rich features, TriHetGCN achieves\nstate-of-the-art performance, outperforming mainstream methods. This highlights\nits strong generalization across diverse network types, offering a promising\nframework that bridges statistical physics and graph deep learning.","main_category":"cs.SI","categories":"cs.SI,physics.data-an,physics.soc-ph","published":"2025-04-29T07:32:55Z"}
{"aid":"http://arxiv.org/abs/2504.20516v1","title":"Spatial-enhanced Reflective Coded Aperture Snapshot Spectral Imaging","summary":"Coded aperture snapshot hyperspectral imaging (CASSI) system which captures\n2-D spatial information and 1-D spectral information in just one or two shots\nhas become a promising technology to capture hyperspectral image (HSI).\nHowever, previous CASSI have shortcomings such as poor spatial resolution and\nlow light efficiency that hinder their further applications. In this paper, we\npropose a spatial-enhanced reflective coded aperture snapshot spectral imaging\nsystem (SE-RCASSI). The system achieves superior spatial results and high light\nefficiency because of its specially designed structure. Then, we propose\nSpatial-enhanced Network (SEnet) which takes full use of the prior information\nof grayscale image to boost the reconstruction quality and can serve as an\nimage fusion framework to deploy different algorithms. Furthermore, we propose\nhybrid prior strategy (HPS) to effectively exploit the broad-scope prior of\ntraining set and narrow-scope prior of measurements, resulting in improved\ngeneralization and performance of the network. Finally, we fabricate the\nprototype of SE-RCASSI and conduct experiments in different environments. Both\nexperimental results and numerical simulations show the outstanding performance\nof our method.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-29T07:58:06Z"}
{"aid":"http://arxiv.org/abs/2504.20547v1","title":"Revisiting the MIMIC-IV Benchmark: Experiments Using Language Models for\n  Electronic Health Records","summary":"The lack of standardized evaluation benchmarks in the medical domain for text\ninputs can be a barrier to widely adopting and leveraging the potential of\nnatural language models for health-related downstream tasks. This paper\nrevisited an openly available MIMIC-IV benchmark for electronic health records\n(EHRs) to address this issue. First, we integrate the MIMIC-IV data within the\nHugging Face datasets library to allow an easy share and use of this\ncollection. Second, we investigate the application of templates to convert EHR\ntabular data to text. Experiments using fine-tuned and zero-shot LLMs on the\nmortality of patients task show that fine-tuned text-based models are\ncompetitive against robust tabular classifiers. In contrast, zero-shot LLMs\nstruggle to leverage EHR representations. This study underlines the potential\nof text-based approaches in the medical field and highlights areas for further\nimprovement.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-29T08:49:38Z"}
{"aid":"http://arxiv.org/abs/2504.20569v1","title":"VIMU: Effective Physics-based Realtime Detection and Recovery against\n  Stealthy Attacks on UAVs","summary":"Sensor attacks on robotic vehicles have become pervasive and manipulative.\nTheir latest advancements exploit sensor and detector characteristics to bypass\ndetection. Recent security efforts have leveraged the physics-based model to\ndetect or mitigate sensor attacks. However, these approaches are only resilient\nto a few sensor attacks and still need improvement in detection effectiveness.\nWe present VIMU, an efficient sensor attack detection and resilience system for\nunmanned aerial vehicles. We propose a detection algorithm, CS-EMA, that\nleverages low-pass filtering to identify stealthy gyroscope attacks while\nachieving an overall effective sensor attack detection. We develop a\nfine-grained nonlinear physical model with precise aerodynamic and propulsion\nwrench modeling. We also augment the state estimation with a FIFO buffer\nsafeguard to mitigate the impact of high-rate IMU attacks. The proposed\nphysical model and buffer safeguard provide an effective system state recovery\ntoward maintaining flight stability. We implement VIMU on PX4 autopilot. The\nevaluation results demonstrate the effectiveness of VIMU in detecting and\nmitigating various realistic sensor attacks, especially stealthy attacks.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-29T09:20:41Z"}
{"aid":"http://arxiv.org/abs/2504.20572v1","title":"A foundry-fabricated spin qubit unit cell with in-situ dispersive\n  readout","summary":"Spin qubits based on semiconductor quantum dots are a promising prospect for\nquantum computation because of their high coherence times and gate fidelities.\nHowever, scaling up those structures to the numbers required by fault-tolerant\nquantum computing is currently hampered by a number of issues. One of the main\nissues is the need for single-shot low-footprint qubit readout. Here, we\ndemonstrate the single-shot in situ measurement of a compact qubit unit-cell.\nThe unit cell is composed of two electron spins with a controllable exchange\ninteraction. We report initialization, single-shot readout and two-electron\nentangling gate. The unit cell was successfully operated at up to 1 K, with\nstate-of-the-art charge noise levels extracted using free induction decay. With\nits integrated readout and high stability, this foundry fabricated qubit unit\ncell demonstrates strong potential for scalable quantum computing\narchitectures.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-29T09:26:00Z"}
{"aid":"http://arxiv.org/abs/2504.20618v1","title":"Statistical Channel Based Low-Complexity Rotation and Position\n  Optimization for 6D Movable Antennas Enabled Wireless Communication","summary":"Six-dimensional movable antenna (6DMA) is a promising technology to fully\nexploit spatial variation in wireless channels by allowing flexible adjustment\nof three-dimensional (3D) positions and rotations of antennas at the\ntransceiver. In this paper, we investigate the practical low-complexity design\nof 6DMA-enabled communication systems, including transmission protocol,\nstatistical channel information (SCI) acquisition, and joint position and\nrotation optimization of 6DMA surfaces based on the SCI of users. Specifically,\nan orthogonal matching pursuit (OMP)-based algorithm is proposed for the\nestimation of SCI of users at all possible position-rotation pairs of 6DMA\nsurfaces based on the channel measurements at a small subset of\nposition-rotation pairs. Then, the average sum logarithmic rate of all users is\nmaximized by jointly designing the positions and rotations of 6DMA surfaces\nbased on their SCI acquired. Different from prior works on 6DMA which adopt\nalternating optimization to design 6DMA positions/rotations with iterations, we\npropose a new sequential optimization approach that first determines 6DMA\nrotations and then finds their feasible positions to realize the optimized\nrotations subject to practical antenna placement constraints. Simulation\nresults show that the proposed sequential optimization significantly reduces\nthe computational complexity of conventional alternating optimization, while\nachieving comparable communication performance. It is also shown that the\nproposed SCI-based 6DMA design can effectively enhance the communication\nthroughput of wireless networks over existing fixed (position and rotation)\nantenna arrays, yet with a practically appealing low-complexity implementation.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-29T10:37:34Z"}
{"aid":"http://arxiv.org/abs/2504.20622v1","title":"The Graded Dual of a Combinatorial Hopf Algebra on Partition Diagrams","summary":"John M. Campbell constructed a combinatorial Hopf algebra (CHA) \\text{ParSym}\non partition diagrams by lifting the CHA structure of \\text{NSym} (the Hopf\nalgebra of noncommutative symmetric functions) through an analogous approach.\nIn this article, we define \\text{ParQSym}, which is the graded dual of\n\\text{ParSym}. Its CHA structure is defined in an explicit, combinatorial way,\nby analogy with that of the CHA \\text{QSym} of quasisymmetric functions. And we\ngive some subcoalgebra and Hopf subalgebras of \\text{ParQSym}, some gradings\nand filtrations of \\text{ParSym} and \\text{ParQSym}, and some bases of\n\\text{ParSym} and \\text{ParQSym} by analogy with some distinguished bases of\n\\text{NSym} and \\text{QSym}.","main_category":"math.RA","categories":"math.RA","published":"2025-04-29T10:45:30Z"}
{"aid":"http://arxiv.org/abs/2504.20624v1","title":"PaRT: Enhancing Proactive Social Chatbots with Personalized Real-Time\n  Retrieval","summary":"Social chatbots have become essential intelligent companions in daily\nscenarios ranging from emotional support to personal interaction. However,\nconventional chatbots with passive response mechanisms usually rely on users to\ninitiate or sustain dialogues by bringing up new topics, resulting in\ndiminished engagement and shortened dialogue duration. In this paper, we\npresent PaRT, a novel framework enabling context-aware proactive dialogues for\nsocial chatbots through personalized real-time retrieval and generation.\nSpecifically, PaRT first integrates user profiles and dialogue context into a\nlarge language model (LLM), which is initially prompted to refine user queries\nand recognize their underlying intents for the upcoming conversation. Guided by\nrefined intents, the LLM generates personalized dialogue topics, which then\nserve as targeted queries to retrieve relevant passages from RedNote. Finally,\nwe prompt LLMs with summarized passages to generate knowledge-grounded and\nengagement-optimized responses. Our approach has been running stably in a\nreal-world production environment for more than 30 days, achieving a 21.77\\%\nimprovement in the average duration of dialogues.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-29T10:51:58Z"}
{"aid":"http://arxiv.org/abs/2504.20653v1","title":"ComplexVCoder: An LLM-Driven Framework for Systematic Generation of\n  Complex Verilog Code","summary":"Recent advances have demonstrated the promising capabilities of large\nlanguage models (LLMs) in generating register-transfer level (RTL) code, such\nas Verilog. However, existing LLM-based frameworks still face significant\nchallenges in accurately handling the complexity of real-world RTL designs,\nparticularly those that are large-scale and involve multi-level module\ninstantiations. To address this issue, we present ComplexVCoder, an open-source\nLLM-driven framework that enhances both the generation quality and efficiency\nof complex Verilog code. Specifically, we introduce a two-stage generation\nmechanism, which leverages an intermediate representation to enable a more\naccurate and structured transition from natural language descriptions to\nintricate Verilog designs. In addition, we introduce a rule-based alignment\nmethod and a domain-specific retrieval-augmented generation (RAG) to further\nimprove the correctness of the synthesized code by incorporating relevant\ndesign knowledge during generation. To evaluate our approach, we construct a\ncomprehensive dataset comprising 55 complex Verilog designs derived from\nreal-world implementations. We also release an open-source benchmark suite for\nsystematically assessing the quality of auto-generated RTL code together with\nthe ComplexVCoder framework. Experimental results show that ComplexVCoder\noutperforms SOTA frameworks such as CodeV and RTLCoder by 14.6% and 22.2%,\nrespectively, in terms of function correctness on complex Verilog benchmarks.\nFurthermore, ComplexVcoder achieves comparable generation performances in terms\nof functionality correctness using a lightweight 32B model (Qwen2.5), rivaling\nlarger-scale models such as GPT-3.5 and DeepSeek-V3.","main_category":"cs.SE","categories":"cs.SE,cs.SY,eess.SY","published":"2025-04-29T11:22:06Z"}
{"aid":"http://arxiv.org/abs/2504.20657v1","title":"Image deidentification in the XNAT ecosystem: use cases and solutions","summary":"XNAT is a server-based data management platform widely used in academia for\ncurating large databases of DICOM images for research projects. We describe in\ndetail a deidentification workflow for DICOM data using facilities in XNAT,\ntogether with independent tools in the XNAT \"ecosystem\". We list different\ncontexts in which deidentification might be needed, based on our prior\nexperience. The starting point for participation in the Medical Image\nDe-Identification Benchmark (MIDI-B) challenge was a set of pre-existing local\nmethodologies, which were adapted during the validation phase of the challenge.\nOur result in the test phase was 97.91\\%, considerably lower than our peers,\ndue largely to an arcane technical incompatibility of our methodology with the\nchallenge's Synapse platform, which prevented us receiving feedback during the\nvalidation phase. Post-submission, additional discrepancy reports from the\norganisers and via the MIDI-B Continuous Benchmarking facility, enabled us to\nimprove this score significantly to 99.61\\%. An entirely rule-based approach\nwas shown to be capable of removing all name-related information in the test\ncorpus, but exhibited failures in dealing fully with address data. Initial\nexperiments using published machine-learning models to remove addresses were\npartially successful but showed the models to be \"over-aggressive\" on other\ntypes of free-text data, leading to a slight overall degradation in performance\nto 99.54\\%. Future development will therefore focus on improving\naddress-recognition capabilities, but also on better removal of identifiable\ndata burned into the image pixels. Several technical aspects relating to the\n\"answer key\" are still under discussion with the challenge organisers, but we\nestimate that our percentage of genuine deidentification failures on the MIDI-B\ntest corpus currently stands at 0.19\\%. (Abridged from original for arXiv\nsubmission)","main_category":"cs.CV","categories":"cs.CV,J.3","published":"2025-04-29T11:33:51Z"}
{"aid":"http://arxiv.org/abs/2504.20686v1","title":"Inference of high-dimensional weak instrumental variable regression\n  models without ridge-regularization","summary":"Inference of instrumental variable regression models with many weak\ninstruments attracts many attentions recently. To extend the classical\nAnderson-Rubin test to high-dimensional setting, many procedures adopt\nridge-regularization. However, we show that it is not necessary to consider\nridge-regularization. Actually we propose a new quadratic-type test statistic\nwhich does not involve tuning parameters. Our quadratic-type test exhibits high\npower against dense alternatives. While for sparse alternatives, we derive the\nasymptotic distribution of an existing maximum-type test, enabling the use of\nless conservative critical values. To achieve strong performance across a wide\nrange of scenarios, we further introduce a combined test procedure that\nintegrates the strengths of both approaches. This combined procedure is\npowerful without requiring prior knowledge of the underlying sparsity of the\nfirst-stage model. Compared to existing methods, our proposed tests are easy to\nimplement, free of tuning parameters, and robust to arbitrarily weak\ninstruments as well as heteroskedastic errors. Simulation studies and empirical\napplications demonstrate the advantages of our methods over existing\napproaches.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-29T12:10:26Z"}
{"aid":"http://arxiv.org/abs/2504.20702v1","title":"Wavefront Shaping of Scattering Forces Enhances Optical Trapping of\n  Levitated Nanoparticles","summary":"Optically-levitated nanoparticles in vacuum offer a pristine platform for\nhigh-quality mechanical oscillators, enabling a wide range of precision\nmeasurements and quantum technologies. A key performance metric in such systems\nis the stiffness of the optical trap, which is typically enhanced by increasing\nlaser power-at the cost of unwanted heating, reduced coherence, and enhanced\nquantum backaction. Here, we demonstrate a fundamentally new route to\nincreasing trap stiffness: wavefront shaping of the optical field. By tailoring\nthe spatial phase profile of the trapping beam, we significantly boost the\nmechanical confinement of subwavelength particles without raising the optical\nintensity. Remarkably, this enhancement arises from a selective reduction of\nnon-conservative optical forces, while preserving the conservative restoring\nforces that define trap stiffness. As a result, mechanical nonlinearities are\nalso reduced, improving stability at low pressures. Our findings challenge the\nlong-standing assumption that diffraction-limited focusing is optimal for\ndipolar Rayleigh particles, and establish wavefront shaping as a powerful,\nreadily applicable tool to control optomechanical forces in levitation\nexperiments. This opens new avenues for minimizing backaction, reducing thermal\ndecoherence, and expanding the range of materials that can be stably levitated.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-29T12:33:29Z"}
{"aid":"http://arxiv.org/abs/2504.20714v1","title":"Frequency dependence of temporal spin stiffness and short-range magnetic\n  order in the doped two-dimensional Hubbard model","summary":"We study doping and temperature dependencies of temporal and spatial spin\nstiffnesses of the Hubbard model within the mean field approach for\nincommensurate magnetic order. We show that the frequency dependence of\ntemporal spin stiffness is crucial to obtain small values of correlation\nlength, comparable to those observed in cuprates. Using the obtained spin\nstiffnesses, we obtain the temperature and doping dependence of correlation\nlength within the large-$N$ limit of the respective nonlinear sigma model. In\nagreement with the experimental data on La$_{2-x}$Sr$_x$CuO$_4$ we obtain short\nrange magnetic order with relatively small correlation length at $0.1 \\lesssim\nx\\lesssim 0.2$, and magnetically ordered ground state in the narrow doping\nregion $0.05\\lesssim x \\lesssim 0.1$. The latter state may correspond to the\nspin-frosen state, observed in the experimental data on\nLa$_{2-x}$Sr$_x$CuO$_4$.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.supr-con","published":"2025-04-29T12:45:46Z"}
{"aid":"http://arxiv.org/abs/2504.20755v1","title":"Low dose gamma irradiation study of ATLAS ITk MD8 diodes","summary":"Silicon strip detectors developed for the Inner Tracker (ITk) of the ATLAS\nexperiment will operate in a harsh radiation environment of the HL-LHC\naccelerator. The ITk is thus designed to endure a total fluence of 1.6E15 1MeV\nn_eq/cm2 and a total ionizing dose (TID) of 66 Mrad in the strip detector\nregion. A radiation-hard n^+-in-p technology is implemented in the ITk strip\nsensors. To achieve the required radiation hardness, extensive irradiation\nstudies were conducted during sensor development, primarily performed up to the\nmaximal expected total fluence and TID to ensure a full functionality of the\ndetector at its end-of-life. These studies included irradiations of sensors\nwith various particle types and energies, including the Co60 gamma-rays. Our\nprevious results obtained for gamma-irradiated diodes and strip sensors\nindicate a linear increase of bulk current with TID, while the surface current\nsaturates at the lowest TID levels checked (66 Mrad), preventing a\ndetermination of the exact TID for which the observed saturation occurs. This\nwork presents the results coming from irradiations by Co60 gamma-rays to\nmultiple low TIDs, ranging from 0.5 to 100 krad. The detailed study of total,\nbulk, and surface currents of diodes explores an unknown dependence of surface\ncurrent on the TID, annealing, and temperature. Additionally, the effect of the\np-stop implant between the bias and the guard ring of measured samples is\nshown. The observations are relevant for the initial operations of the new\nATLAS tracker.","main_category":"physics.ins-det","categories":"physics.ins-det","published":"2025-04-29T13:34:38Z"}
{"aid":"http://arxiv.org/abs/2504.20768v1","title":"LakeVilla: Multi-Table Transactions for Lakehouses","summary":"Data lakehouses (LHs) are at the core of current cloud analytics stacks by\nproviding elastic, relational compute on data in cloud data lakes across\nvendors. For relational semantics, they rely on open table formats (OTFs).\nUnfortunately, they have many missing features inherent to their metadata\ndesigns, like no support for multi-table transactions and recovery in case of\nan abort in concurrent, multi-query workloads. This, in turn, can lead to\nnon-repeatable reads, stale data, and high costs in productive cloud systems.\nIn this work, we introduce LakeVilla, a complementary solution that introduces\nrecovery, multi-query/table transactions, and transaction isolation to\nstate-of-the-art OTFs like Apache Iceberg and Delta Lake tables. We investigate\nits transactional guarantees and show it has minimal impact on performance (2%\nYCSB writes, 2.5% TPC-DS reads) and provides concurrency control for multiple\nreaders and writers for arbitrary long transactions in OTFs in a non-invasive\nway.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-29T13:47:53Z"}
{"aid":"http://arxiv.org/abs/2504.20793v1","title":"Differential symmetry breaking operators for the pair\n  $(\\operatorname{GL}_{n+1}(\\mathbb{R}),\\operatorname{GL}_n(\\mathbb{R}))$","summary":"In this article we study differential symmetry breaking operators between\nprincipal series representations induced from minimal parabolic subgroups for\nthe pair\n$(\\operatorname{GL}_{n+1}(\\mathbb{R}),\\operatorname{GL}_n(\\mathbb{R}))$. Using\nthe source operator philosophy we construct such operators for generic\ninduction parameters of the representations and establish that this approach\nyields all possible operators in this setting. We show that these differential\noperators occur as residues of a family of symmetry breaking operators that\ndepends meromorphically on the parameters. Finally, in the $n=2$ case we\nclassify and construct all differential symmetry breaking operators for any\nparameters, including the non-generic ones.","main_category":"math.RT","categories":"math.RT,math.CA","published":"2025-04-29T14:10:04Z"}
{"aid":"http://arxiv.org/abs/2504.20804v1","title":"Region of Synchronization Estimation for Complex Networks via SOS\n  Programming","summary":"In this article, we explore the problem of the region of synchronization\n(ROS) for complex networks with nonlinear dynamics. Given a pair of state- and\ntarget- sets, our goal is to estimate the ROS such that the trajectories\noriginating within it reach the target set (i.e., synchronization manifold),\nwithout leaving the state set before the first hitting time. In order to do so,\nan exponential guidance-barrier function is proposed to construct the ROS along\nthe synchronization manifold, and the corresponding sufficient conditions for\nestimating the ROS are developed. The resulting conditions lead to a\nsum-of-squares programming problem, thereby affording a polynomial-time\nsolvability. Furthermore, when the synchronization manifold reduces to an\nequilibrium point, our method not only estimates a larger ROS compared to\nexisting results but also allows the ROS to take more general shapes. Finally,\nwe present two numerical examples to demonstrate the effectiveness of the\ntheoretical results.","main_category":"math.OC","categories":"math.OC","published":"2025-04-29T14:16:49Z"}
{"aid":"http://arxiv.org/abs/2504.20917v1","title":"Clifford algebra analogue of Cartan's theorem for symmetric pairs","summary":"We extend Kostant's results about $\\mathfrak{g}$-invariants in the Clifford\nalgebra $Cl(\\mathfrak{g})$ of a complex semisimple Lie algebra $\\mathfrak{g}$\nto the relative case of $\\mathfrak{k}$-invariants in the Clifford algebra\n$Cl(\\mathfrak{p})$, where $(\\mathfrak{g},\\mathfrak{k})$ is a classical\nsymmetric pair and $\\mathfrak{p}$ is the $(-1)$-eigenspace of the corresponding\ninvolution. In this setup we prove the Cartan theorem for Clifford algebras, a\nrelative transgression theorem, the Harish--Chandra isomorphism for\n$Cl(\\mathfrak{p})$, and a relative version of Kostant's Clifford algebra\nconjecture.","main_category":"math.RT","categories":"math.RT,math.DG","published":"2025-04-29T16:35:08Z"}
{"aid":"http://arxiv.org/abs/2504.20921v1","title":"Leveraging Generative AI Through Prompt Engineering and Rigorous\n  Validation to Create Comprehensive Synthetic Datasets for AI Training in\n  Healthcare","summary":"Access to high-quality medical data is often restricted due to privacy\nconcerns, posing significant challenges for training artificial intelligence\n(AI) algorithms within Electronic Health Record (EHR) applications. In this\nstudy, prompt engineering with the GPT-4 API was employed to generate\nhigh-quality synthetic datasets aimed at overcoming this limitation. The\ngenerated data encompassed a comprehensive array of patient admission\ninformation, including healthcare provider details, hospital departments,\nwards, bed assignments, patient demographics, emergency contacts, vital signs,\nimmunizations, allergies, medical histories, appointments, hospital visits,\nlaboratory tests, diagnoses, treatment plans, medications, clinical notes,\nvisit logs, discharge summaries, and referrals. To ensure data quality and\nintegrity, advanced validation techniques were implemented utilizing models\nsuch as BERT's Next Sentence Prediction for sentence coherence, GPT-2 for\noverall plausibility, RoBERTa for logical consistency, autoencoders for anomaly\ndetection, and conducted diversity analysis. Synthetic data that met all\nvalidation criteria were integrated into a comprehensive PostgreSQL database,\nserving as the data management system for the EHR application. This approach\ndemonstrates that leveraging generative AI models with rigorous validation can\neffectively produce high-quality synthetic medical data, facilitating the\ntraining of AI algorithms while addressing privacy concerns associated with\nreal patient data.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-29T16:37:34Z"}
{"aid":"http://arxiv.org/abs/2504.20938v1","title":"Towards Understanding the Nature of Attention with Low-Rank Sparse\n  Decomposition","summary":"We propose Low-Rank Sparse Attention (Lorsa), a sparse replacement model of\nTransformer attention layers to disentangle original Multi Head Self Attention\n(MHSA) into individually comprehensible components. Lorsa is designed to\naddress the challenge of attention superposition to understand\nattention-mediated interaction between features in different token positions.\nWe show that Lorsa heads find cleaner and finer-grained versions of previously\ndiscovered MHSA behaviors like induction heads, successor heads and attention\nsink behavior (i.e., heavily attending to the first token). Lorsa and Sparse\nAutoencoder (SAE) are both sparse dictionary learning methods applied to\ndifferent Transformer components, and lead to consistent findings in many ways.\nFor instance, we discover a comprehensive family of arithmetic-specific Lorsa\nheads, each corresponding to an atomic operation in Llama-3.1-8B. Automated\ninterpretability analysis indicates that Lorsa achieves parity with SAE in\ninterpretability while Lorsa exhibits superior circuit discovery properties,\nespecially for features computed collectively by multiple MHSA heads. We also\nconduct extensive experiments on architectural design ablation, Lorsa scaling\nlaw and error analysis.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-29T17:03:03Z"}
{"aid":"http://arxiv.org/abs/2504.20942v1","title":"Scenario-based Compositional Verification of Autonomous Systems with\n  Neural Perception","summary":"Recent advances in deep learning have enabled the development of autonomous\nsystems that use deep neural networks for perception. Formal verification of\nthese systems is challenging due to the size and complexity of the perception\nDNNs as well as hard-to-quantify, changing environment conditions. To address\nthese challenges, we propose a probabilistic verification framework for\nautonomous systems based on the following key concepts: (1) Scenario-based\nModeling: We decompose the task (e.g., car navigation) into a composition of\nscenarios, each representing a different environment condition. (2)\nProbabilistic Abstractions: For each scenario, we build a compact abstraction\nof perception based on the DNN's performance on an offline dataset that\nrepresents the scenario's environment condition. (3) Symbolic Reasoning and\nAcceleration: The abstractions enable efficient compositional verification of\nthe autonomous system via symbolic reasoning and a novel acceleration proof\nrule that bounds the error probability of the system under arbitrary variations\nof environment conditions. We illustrate our approach on two case studies: an\nexperimental autonomous system that guides airplanes on taxiways using\nhigh-dimensional perception DNNs and a simulation model of an F1Tenth\nautonomous car using LiDAR observations.","main_category":"cs.LG","categories":"cs.LG,cs.RO","published":"2025-04-29T17:06:22Z"}
{"aid":"http://arxiv.org/abs/2504.20958v1","title":"Soft-X-ray momentum microscopy of nonlinear magnon interactions below\n  100-nm wavelength","summary":"Magnons represent quantised collective motions of long-range ordered spins.\nFor wavelength below 100 nm, exchange interactions dominate their physics,\nwhich gives rise to a so far unexplored regime of nonlinearities and couplings\nbetween magnons and other quasiparticles. Besides their selective excitation,\nalso the detection of such short-wavelength spin waves remains a challenge of\ncurrent research and technology. Here, we probe the amplitude and wave vector\nof magnons by means of quasi-elastic resonant soft-X-ray scattering. This\nMagnon Momentum Microscopy (MMM) can access magnons directly in momentum space\nwith remarkable sensitivity and high photon efficiency up to THz frequencies\nand down to few-nanometre wavelengths. The two-dimensional information obtained\nby this light-scattering-based technique is especially valuable for studying\nthe nonlinear interactions of exchange-dominated magnons within technologically\nrelevant thin-film samples. In doing so, we uncover a rich variety of deeply\nnonlinear magnon interactions, highlighting their potential for applications in\nnovel computing schemes. With its intrinsic element-selectivity and ability to\nprobe also buried layers, soft-X-ray MMM has the potential to establish itself\nas an advanced tool for ultrabroadband studies of short-wavelength magnonics.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-29T17:31:15Z"}
{"aid":"http://arxiv.org/abs/2504.20972v1","title":"SetKE: Knowledge Editing for Knowledge Elements Overlap","summary":"Large Language Models (LLMs) excel in tasks such as retrieval and question\nanswering but require updates to incorporate new knowledge and reduce\ninaccuracies and hallucinations. Traditional updating methods, like fine-tuning\nand incremental learning, face challenges such as overfitting and high\ncomputational costs. Knowledge Editing (KE) provides a promising alternative\nbut often overlooks the Knowledge Element Overlap (KEO) phenomenon, where\nmultiple triplets share common elements, leading to editing conflicts. We\nidentify the prevalence of KEO in existing KE datasets and show its significant\nimpact on current KE methods, causing performance degradation in handling such\ntriplets. To address this, we propose a new formulation, Knowledge Set Editing\n(KSE), and introduce SetKE, a method that edits sets of triplets\nsimultaneously. Experimental results demonstrate that SetKE outperforms\nexisting methods in KEO scenarios on mainstream LLMs. Additionally, we\nintroduce EditSet, a dataset containing KEO triplets, providing a comprehensive\nbenchmark.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-29T17:40:29Z"}
{"aid":"http://arxiv.org/abs/2504.20976v1","title":"Real-Time Wayfinding Assistant for Blind and Low-Vision Users","summary":"Navigating unfamiliar places continues to be one of the most persistent and\nessential everyday obstacles for those who are blind or have limited vision\n(BLV). Existing assistive technologies, such as GPS-based navigation systems,\nAI-powered smart glasses, and sonar-equipped canes, often face limitations in\nreal-time obstacle avoidance, precise localization, and adaptability to dynamic\nsurroundings. To investigate potential solutions, we introduced PathFinder, a\nnovel map-less navigation system that explores different models for\nunderstanding 2D images, including Vision Language Models (VLMs), Large\nLanguage Models (LLMs), and employs monocular depth estimation for free-path\ndetection. Our approach integrates a Depth-First Search (DFS) algorithm on\ndepth images to determine the longest obstacle-free path, ensuring optimal\nroute selection while maintaining computational efficiency. We conducted\ncomparative evaluations against existing AI-powered navigation methods and\nperformed a usability study with BLV participants. The results demonstrate that\nPathFinder achieves a favorable balance between accuracy, computational\nefficiency, and real-time responsiveness. Notably, it reduces mean absolute\nerror (MAE) and improves decision-making speed in outdoor navigation compared\nto AI-based alternatives. Participant feedback emphasizes the system's\nusability and effectiveness in outside situations, but also identifies issues\nin complicated indoor locations and low-light conditions. Usability testing\nrevealed that 73% of participants understood how to use the app in about a\nminute, and 80% praised its balance of accuracy, quick response, and overall\nconvenience.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-29T17:45:04Z"}
{"aid":"http://arxiv.org/abs/2504.20986v1","title":"Planets Across Space and Time (PAST). VI. Age Dependence of the\n  Occurrence and Architecture of Ultra-Short-Period Planet Systems","summary":"Ultra-short-period (USP) planets, with orbital periods shorter than one day,\nrepresent a unique class of exoplanets whose origin remains puzzling.\nDetermining their age distribution and temporal evolution is vital for\nuncovering their formation and evolutionary pathways. Using a sample of over\n1,000 short-period planets around Sun-like stars, we find that the host stars\nof USP planets are relatively older and have a higher prevalence in the\nGalactic thick disk compared to stars hosting other short-period planets.\nFurthermore, we find that the occurrence of USP planets increases with stellar\nage and uncover evidence indicating that USP planetary system architectures\nevolve on Gyr timescales. This includes a distinct dip-pileup in period\ndistributions around ~1 day and an expansion of orbital spacings with time. In\naddition, younger USP planet systems are observed to have fewer multiple\ntransiting planets, implying fewer nearby companions and/or larger mutual\norbital inclinations. Our findings suggest that USP planets continuously form\nthrough inward migration driven by tidal dissipation over Gyr timescales, and\nthat younger and older USP planets may have originated via different specific\ntidal migration pathways.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-29T17:56:03Z"}
{"aid":"http://arxiv.org/abs/2504.20998v1","title":"YoChameleon: Personalized Vision and Language Generation","summary":"Large Multimodal Models (e.g., GPT-4, Gemini, Chameleon) have evolved into\npowerful tools with millions of users. However, they remain generic models and\nlack personalized knowledge of specific user concepts. Previous work has\nexplored personalization for text generation, yet it remains unclear how these\nmethods can be adapted to new modalities, such as image generation. In this\npaper, we introduce Yo'Chameleon, the first attempt to study personalization\nfor large multimodal models. Given 3-5 images of a particular concept,\nYo'Chameleon leverages soft-prompt tuning to embed subject-specific information\nto (i) answer questions about the subject and (ii) recreate pixel-level details\nto produce images of the subject in new contexts. Yo'Chameleon is trained with\n(i) a self-prompting optimization mechanism to balance performance across\nmultiple modalities, and (ii) a ``soft-positive\" image generation approach to\nenhance image quality in a few-shot setting.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-29T17:59:57Z"}
{"aid":"http://arxiv.org/abs/2504.21278v1","title":"Robust Multi-agent Communication Based on Decentralization-Oriented\n  Adversarial Training","summary":"In typical multi-agent reinforcement learning (MARL) problems, communication\nis important for agents to share information and make the right decisions.\nHowever, due to the complexity of training multi-agent communication, existing\nmethods often fall into the dilemma of local optimization, which leads to the\nconcentration of communication in a limited number of channels and presents an\nunbalanced structure. Such unbalanced communication policy are vulnerable to\nabnormal conditions, where the damage of critical communication channels can\ntrigger the crash of the entire system. Inspired by decentralization theory in\nsociology, we propose DMAC, which enhances the robustness of multi-agent\ncommunication policies by retraining them into decentralized patterns.\nSpecifically, we train an adversary DMAC\\_Adv which can dynamically identify\nand mask the critical communication channels, and then apply the adversarial\nsamples generated by DMAC\\_Adv to the adversarial learning of the communication\npolicy to force the policy in exploring other potential communication schemes\nand transition to a decentralized structure. As a training method to improve\nrobustness, DMAC can be fused with any learnable communication policy\nalgorithm. The experimental results in two communication policies and four\nmulti-agent tasks demonstrate that DMAC achieves higher improvement on\nrobustness and performance of communication policy compared with two\nstate-of-the-art and commonly-used baselines. Also, the results demonstrate\nthat DMAC can achieve decentralized communication structure with acceptable\ncommunication cost.","main_category":"cs.MA","categories":"cs.MA","published":"2025-04-30T03:14:50Z"}
{"aid":"http://arxiv.org/abs/2504.21279v1","title":"Linear perturbations of dyonic black holes in the lowest-order $U(1)$\n  gauge-invariant scalar-vector-tensor theories","summary":"We study linear perturbations on top of the static and spherically symmetric\nbackground of dyonic black hole solutions endowed with electric and magnetic\ncharges, as well as a scalar hair, in the lowest-order $U(1)$ gauge-invariant\nscalar-vector-tensor theories. The presence of magnetic charges in the\nbackground solutions gives rise to a mixing between the odd-parity and\neven-parity sectors of perturbations, which makes it impossible to analyze each\nsector separately. Thus, we expand the action up to second order in both\nodd-parity and even-parity perturbations and derive the general conditions for\nthe absence of ghosts and Laplacian instabilities. We apply these general\nconditions to extended Einstein-Maxwell theories, which encompass a wide\nvariety of concrete models from the literature known to have dyonic black hole\nsolutions with the scalar hair, and examine their stabilities. Our general\nframework for studying stability conditions and dynamics of perturbations can\nbe applied to a wide variety of theories, including nonlinear electrodynamics\ncoupled to a scalar field, as well as to calculations of black hole quasinormal\nmodes.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-30T03:20:03Z"}
{"aid":"http://arxiv.org/abs/2504.21307v1","title":"The Dual Power of Interpretable Token Embeddings: Jailbreaking Attacks\n  and Defenses for Diffusion Model Unlearning","summary":"Despite the remarkable generalization capabilities of diffusion models,\nrecent studies have shown that these models can memorize and generate harmful\ncontent when prompted with specific text instructions. Although fine-tuning\napproaches have been developed to mitigate this issue by unlearning harmful\nconcepts, these methods can be easily circumvented through jailbreaking\nattacks. This indicates that the harmful concept has not been fully erased from\nthe model. However, existing attack methods, while effective, lack\ninterpretability regarding why unlearned models still retain the concept,\nthereby hindering the development of defense strategies. In this work, we\naddress these limitations by proposing an attack method that learns an\northogonal set of interpretable attack token embeddings. The attack token\nembeddings can be decomposed into human-interpretable textual elements,\nrevealing that unlearned models still retain the target concept through\nimplicit textual components. Furthermore, these attack token embeddings are\nrobust and transferable across text prompts, initial noises, and unlearned\nmodels. Finally, leveraging this diverse set of embeddings, we design a defense\nmethod applicable to both our proposed attack and existing attack methods.\nExperimental results demonstrate the effectiveness of both our attack and\ndefense strategies.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T04:33:43Z"}
{"aid":"http://arxiv.org/abs/2504.21377v1","title":"Physics-informed Gaussian Processes for Model Predictive Control of\n  Nonlinear Systems","summary":"Recently, a novel linear model predictive control algorithm based on a\nphysics-informed Gaussian Process has been introduced, whose realizations\nstrictly follow a system of underlying linear ordinary differential equations\nwith constant coefficients. The control task is formulated as an inference\nproblem by conditioning the Gaussian process prior on the setpoints and\nincorporating pointwise soft-constraints as further virtual setpoints. We apply\nthis method to systems of nonlinear differential equations, obtaining a local\napproximation through the linearization around an equilibrium point. In the\ncase of an asymptotically stable equilibrium point convergence is given through\nthe Bayesian inference schema of the Gaussian Process. Results for this are\ndemonstrated in a numerical example.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-30T07:25:14Z"}
{"aid":"http://arxiv.org/abs/2504.21406v1","title":"Mapping the Human Brain from the Prenatal Period to Infancy Using 3D\n  Magnetic Resonance Imaging","summary":"Human brain development is a complex and dynamic process that begins during\nthe first weeks of pregnancy and lasts until early adulthood. This chapter\nfocuses on the developmental window from prenatal period to infancy, probably\nthe most dynamic period across the entire lifespan. The availability of\nnon-invasive three-dimensional Magnetic Resonance Imaging (MRI) methodologies\nhas changed the paradigm and allows investigations of the living human brain\nstructure - e.g. micro- and macrostructural features of cortical and\nsubcortical regions and their connections, including cortical\nsulcation/gyrification, area, and thickness, as well as white matter\nmicrostructure and connectivity - beginning in utero. Because of its relative\nsafety, MRI is well-adapted to study individuals at multiple time points and to\nlongitudinally follow the changes in brain structure and function that underlie\nthe early stages of cognitive development.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-04-30T08:05:02Z"}
{"aid":"http://arxiv.org/abs/2504.21430v1","title":"Existence and non-existence of the CLT for a family of SDEs driven by\n  stable process","summary":"Stochastic differential equations (SDEs) without global Lipschitz drift often\ndemonstrate unusual phenomena. In this paper, we consider the following SDE on\n$\\mathbb R^d$:\n  \\begin{align*}\n  \\mathrm{d} \\mathbf{X}_t=\\mathbf{b}(\\mathbf{X}_t) \\mathrm{d} t+\n\\mathrm{d}\\mathbf{Z}_t, \\quad \\mathbf{X}_0=\\mathbf{x} \\in \\mathbb{R}^d,\n\\end{align*} where $\\mathbf{Z}_t$ is the rotationally symmetric $\\alpha$-stable\nprocess with $\\alpha \\in(1,2)$ and $\\mathbf{b}:\\mathbb{R}^d \\rightarrow\n\\mathbb{R}^d$ is a differentiable function satisfying the following condition:\nthere exist some $\\theta \\ge 0$, and $K_1 , K_2 , L>0$, so that $$\\langle\n\\mathbf{b}(\\mathbf{x})-\\mathbf{b}(\\mathbf{y}), \\mathbf{x}-\\mathbf{y}\\rangle\n\\leqslant K_1 |\\mathbf{x}-\\mathbf{y}|^2, \\ \\ \\forall \\ \\\n|\\mathbf{x}-\\mathbf{y}| \\leqslant L, $$ $$\\langle\n\\mathbf{b}(\\mathbf{x})-\\mathbf{b}(\\mathbf{y}), \\mathbf{x}-\\mathbf{y}\\rangle\n\\leqslant -K_2 |\\mathbf{x}-\\mathbf{y}|^{2+\\theta}, \\ \\ \\forall \\ \\\n|\\mathbf{x}-\\mathbf{y}| > L.$$ Under this assumption, the SDE admits a unique\ninvariant measure $\\mu$.\n  We investigate the normal central limit theorem (CLT) of the empirical\nmeasures $$ \\mathcal{E}_t^\\mathbf{x}(\\cdot)=\\frac{1}{t} \\int_0^t\n\\delta_{\\mathbf{X}_s }(\\cdot) \\mathrm{d} s, \\ \\ \\ \\ \\mathbf{X}_0=\\mathbf{x} \\in\n\\mathbb{R}^d, \\ \\ t>0, $$ where $\\delta_{\\mathbf{x}}(\\cdot)$ is the Dirac delta\nmeasure.\n  Our results reveal that, for the bounded measurable function $h$, $$\\sqrt t\n\\left(\\mathcal{E}_t^\\mathbf{x}(h)-\\mu(h)\\right)=\\frac{1}{\\sqrt t} \\int_0^t\n\\left(h\\left(\\mathbf{X}_s^\\mathbf{x}\\right)-\\mu(h)\\right) \\mathrm{d} s$$ admits\na normal CLT for $\\theta \\geqslant 0$. For the Lipschitz continuous function\n$h$, the normal CLT does not necessarily hold when $\\theta=0$, but it is\nsatisfied for $\\theta>1-\\frac{\\alpha}{2}$.","main_category":"math.PR","categories":"math.PR","published":"2025-04-30T08:39:04Z"}
{"aid":"http://arxiv.org/abs/2504.21457v1","title":"xEEGNet: Towards Explainable AI in EEG Dementia Classification","summary":"This work presents xEEGNet, a novel, compact, and explainable neural network\nfor EEG data analysis. It is fully interpretable and reduces overfitting\nthrough major parameter reduction. As an applicative use case, we focused on\nclassifying common dementia conditions, Alzheimer's and frontotemporal\ndementia, versus controls. xEEGNet is broadly applicable to other neurological\nconditions involving spectral alterations. We initially used ShallowNet, a\nsimple and popular model from the EEGNet-family. Its structure was analyzed and\ngradually modified to move from a \"black box\" to a more transparent model,\nwithout compromising performance. The learned kernels and weights were examined\nfrom a clinical standpoint to assess medical relevance. Model variants,\nincluding ShallowNet and the final xEEGNet, were evaluated using robust\nNested-Leave-N-Subjects-Out cross-validation for unbiased performance\nestimates. Variability across data splits was explained using embedded EEG\nrepresentations, grouped by class and set, with pairwise separability to\nquantify group distinction. Overfitting was assessed through\ntraining-validation loss correlation and training speed. xEEGNet uses only 168\nparameters, 200 times fewer than ShallowNet, yet retains interpretability,\nresists overfitting, achieves comparable median performance (-1.5%), and\nreduces variability across splits. This variability is explained by embedded\nEEG representations: higher accuracy correlates with greater separation between\ntest set controls and Alzheimer's cases, without significant influence from\ntraining data. xEEGNet's ability to filter specific EEG bands, learn\nband-specific topographies, and use relevant spectral features demonstrates its\ninterpretability. While large deep learning models are often prioritized for\nperformance, this study shows smaller architectures like xEEGNet can be equally\neffective in EEG pathology classification.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-30T09:24:50Z"}
{"aid":"http://arxiv.org/abs/2504.21472v1","title":"Robust Orthogonal NMF with Label Propagation for Image Clustering","summary":"Non-negative matrix factorization (NMF) is a popular unsupervised learning\napproach widely used in image clustering. However, in real-world clustering\nscenarios, most existing NMF methods are highly sensitive to noise corruption\nand are unable to effectively leverage limited supervised information. To\novercome these drawbacks, we propose a unified non-convex framework with label\npropagation called robust orthogonal nonnegative matrix factorization (RONMF).\nThis method not only considers the graph Laplacian and label propagation as\nregularization terms but also introduces a more effective non-convex structure\nto measure the reconstruction error and imposes orthogonal constraints on the\nbasis matrix to reduce the noise corruption, thereby achieving higher\nrobustness. To solve RONMF, we develop an alternating direction method of\nmultipliers (ADMM)-based optimization algorithm. In particular, all subproblems\nhave closed-form solutions, which ensures its efficiency. Experimental\nevaluations on eight public image datasets demonstrate that the proposed RONMF\noutperforms state-of-the-art NMF methods across various standard metrics and\nshows excellent robustness. The code will be available at\nhttps://github.com/slinda-liu.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T09:49:55Z"}
{"aid":"http://arxiv.org/abs/2504.21476v1","title":"GarmentDiffusion: 3D Garment Sewing Pattern Generation with Multimodal\n  Diffusion Transformers","summary":"Garment sewing patterns are fundamental design elements that bridge the gap\nbetween design concepts and practical manufacturing. The generative modeling of\nsewing patterns is crucial for creating diversified garments. However, existing\napproaches are limited either by reliance on a single input modality or by\nsuboptimal generation efficiency. In this work, we present\n\\textbf{\\textit{GarmentDiffusion}}, a new generative model capable of producing\ncentimeter-precise, vectorized 3D sewing patterns from multimodal inputs (text,\nimage, and incomplete sewing pattern). Our method efficiently encodes 3D sewing\npattern parameters into compact edge token representations, achieving a\nsequence length that is $\\textbf{10}\\times$ shorter than that of the\nautoregressive SewingGPT in DressCode. By employing a diffusion transformer, we\nsimultaneously denoise all edge tokens along the temporal axis, while\nmaintaining a constant number of denoising steps regardless of dataset-specific\nedge and panel statistics. With all combination of designs of our model, the\nsewing pattern generation speed is accelerated by $\\textbf{100}\\times$ compared\nto SewingGPT. We achieve new state-of-the-art results on DressCodeData, as well\nas on the largest sewing pattern dataset, namely GarmentCodeData. The project\nwebsite is available at https://shenfu-research.github.io/Garment-Diffusion/.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-30T09:56:59Z"}
{"aid":"http://arxiv.org/abs/2504.21494v1","title":"Towards a $\\cos(2\\varphi)$ Josephson element using aluminum junctions\n  with well-transmitted channels","summary":"We introduce a novel method for fabricating all-aluminum Josephson junctions\nwith highly transmitted conduction channels. Such properties are typically\nassociated with structures requiring intricate fabrication processes, such as\natomic contacts or hybrid junctions based on semiconducting nanowires and 2D\nmaterials. In contrast, our approach relies solely on standard nanofabrication\ntechniques. The resulting devices exhibit a key signature of high-transmission\njunctions - Multiple Andreev Reflections (MAR) - in their current-voltage\ncharacteristics. Furthermore, we propose a straightforward superconducting\ncircuit design based on these junctions, enabling the implementation of a\nparity-protected qubit.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,quant-ph","published":"2025-04-30T10:24:51Z"}
{"aid":"http://arxiv.org/abs/2504.21501v1","title":"Deep Learning Optimization Using Self-Adaptive Weighted Auxiliary\n  Variables","summary":"In this paper, we develop a new optimization framework for the least squares\nlearning problem via fully connected neural networks or physics-informed neural\nnetworks. The gradient descent sometimes behaves inefficiently in deep learning\nbecause of the high non-convexity of loss functions and the vanishing gradient\nissue. Our idea is to introduce auxiliary variables to separate the layers of\nthe deep neural networks and reformulate the loss functions for ease of\noptimization. We design the self-adaptive weights to preserve the consistency\nbetween the reformulated loss and the original mean squared loss, which\nguarantees that optimizing the new loss helps optimize the original problem.\nNumerical experiments are presented to verify the consistency and show the\neffectiveness and robustness of our models over gradient descent.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-30T10:43:13Z"}
{"aid":"http://arxiv.org/abs/2504.21512v1","title":"Area rule of velocity circulation in two-dimensional instability-driven\n  turbulence beyond the inertial range","summary":"Since Kolmogorov's theory, scaling properties in the inertial range have been\na key topic in turbulence research. However, the velocity statistics show\nnon-universality in three- and two-dimensional turbulence. Migdal (1995) proved\nthe velocity circulation area rule which states the probability density\nfunction (PDF) of circulation is only a function of the minimal surface area\nenclosed by the loop but not the shape of the loop, and later a bifractal\nuniversal behavior is found for circulation in three- and two-dimensional\nturbulence and quantum turbulence (Iyer et al. 2019; M\\\"uller et al. 2021; Zhu\net al. 2023). This paper finds that the velocity circulation area rule can be\ngeneralized in two-dimensional instability-driven turbulence to all scales that\nare not limited to the inertial range. However, similar to the\nthree-dimensional case, the variance of circulation is size-dependent, and\ncompared with the circulation PDFs, the variance-normalized PDFs have a\nsignificantly weaker dependence on the shape of the loop. We also discussed the\narea rule for 8-loops and double loops. We found that the normalized PDF\ndepends only on the scalar area of the 8-loop. However, the area rule for other\ncomplex loops, such as double loops, remains an open question.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-30T11:01:45Z"}
{"aid":"http://arxiv.org/abs/2504.21568v1","title":"A Study on Group Decision Making Problem Based on Fuzzy Reasoning and\n  Bayesian Networks","summary":"Aiming at the group decision - making problem with multi - objective\nattributes, this study proposes a group decision - making system that\nintegrates fuzzy inference and Bayesian network. A fuzzy rule base is\nconstructed by combining threshold values, membership functions, expert\nexperience, and domain knowledge to address quantitative challenges such as\nscale differences and expert linguistic variables. A hierarchical Bayesian\nnetwork is designed, featuring a directed acyclic graph with nodes selected by\nexperts, and maximum likelihood estimation is used to dynamically optimize the\nconditional probability table, modeling the nonlinear correlations among\nmultidimensional indices for posterior probability aggregation. In a\ncomprehensive student evaluation case, this method is compared with the\ntraditional weighted scoring approach. The results indicate that the proposed\nmethod demonstrates effectiveness in both rule criterion construction and\nranking consistency, with a classification accuracy of 86.0% and an F1 value\nimprovement of 53.4% over the traditional method. Additionally, computational\nexperiments on real - world datasets across various group decision scenarios\nassess the method's performance and robustness, providing evidence of its\nreliability in diverse contexts.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-30T12:14:48Z"}
{"aid":"http://arxiv.org/abs/2504.21591v1","title":"Time periodic problem of compressible Euler equations with damping on\n  the whole space","summary":"In this article, time periodic problem of the compressible Euler equations\nwith damping on the whole space is studied. It is well known that in the Euler\nsystem, long-time behavior of solutions is a more delicate problem due to lack\nof the viscosity. By virtue of a damping effect, time global solutions barely\nexist. Under such circumstances, existence of a time periodic solution is\nobtained for sufficiently small time periodic external force when the space\ndimension is greater than or equal to $3$. In addition, its stability is also\nobtained. The solution is asymptotically stable under sufficiently small\ninitial perturbations and the $L^\\infty$ norm of the perturbation decays as\ntime goes to infinity. The potential theoretical estimates work well on a low\nfrequency part of solutions, while a new energy estimate with weights is\nestablished to avoid derivative loss.","main_category":"math.AP","categories":"math.AP","published":"2025-04-30T12:49:03Z"}
{"aid":"http://arxiv.org/abs/2504.21609v1","title":"Applying Machine Learning for characterizing social networks Agent-based\n  models","summary":"Nowadays, social media networks are increasingly significant to our lives,\nthe imperative to study social media networks becomes more and more essential.\nWith billions of users across platforms and constant updates, the complexity of\nmodeling social networks is immense. Agent-based modeling (ABM) is widely\nemployed to study social networks community, allowing us to define individual\nbehaviors and simulate system-level evolution. It can be a powerful tool to\ntest how the algorithms affect users behavior. To fully leverage agent-based\nmodels,superior data processing and storage capabilities are essential. High\nPerformance Computing (HPC) presents an optimal solution, adept at managing\ncomplex computations and analysis, particularly for voluminous or\niteration-intensive tasks. We utilize Machine Learning (ML) methods to analyze\nsocial media users due to their ability to efficiently process vast amounts of\ndata and derive insights that aid in understanding user behaviors, preferences,\nand trends. Therefore, our proposal involves ML to characterize user attributes\nand to develop a general user model for ABM simulation of in social networks on\nHPC systems.","main_category":"cs.SI","categories":"cs.SI,I.6.3","published":"2025-04-30T13:08:53Z"}
{"aid":"http://arxiv.org/abs/2504.21612v1","title":"Selective Variable Convolution Meets Dynamic Content Guided Attention\n  for Infrared Small Target Detection","summary":"Infrared Small Target Detection (IRSTD) system aims to identify small targets\nin complex backgrounds. Due to the convolution operation in Convolutional\nNeural Networks (CNNs), applying traditional CNNs to IRSTD presents challenges,\nsince the feature extraction of small targets is often insufficient, resulting\nin the loss of critical features. To address these issues, we propose a dynamic\ncontent guided attention multiscale feature aggregation network (DCGANet),\nwhich adheres to the attention principle of 'coarse-to-fine' and achieves high\ndetection accuracy. First, we propose a selective variable convolution (SVC)\nmodule that integrates the benefits of standard convolution, irregular\ndeformable convolution, and multi-rate dilated convolution. This module is\ndesigned to expand the receptive field and enhance non-local features, thereby\neffectively improving the discrimination of targets from backgrounds. Second,\nthe core component of DCGANet is a two-stage content guided attention module.\nThis module employs two-stage attention mechanism to initially direct the\nnetwork's focus to salient regions within the feature maps and subsequently\ndetermine whether these regions correspond to targets or background\ninterference. By retaining the most significant responses, this mechanism\neffectively suppresses false alarms. Additionally, we propose adaptive dynamic\nfeature fusion (ADFF) module to substitute for static feature cascading. This\ndynamic feature fusion strategy enables DCGANet to adaptively integrate\ncontextual features, thereby enhancing its ability to discriminate true targets\nfrom false alarms. DCGANet has achieved new benchmarks across multiple\ndatasets.","main_category":"eess.IV","categories":"eess.IV","published":"2025-04-30T13:09:20Z"}
{"aid":"http://arxiv.org/abs/2504.21619v1","title":"LRBO2: Improved 3D Vision Based Hand-Eye Calibration for Collaborative\n  Robot Arm","summary":"Hand-eye calibration is a common problem in the field of collaborative\nrobotics, involving the determination of the transformation matrix between the\nvisual sensor and the robot flange to enable vision-based robotic tasks.\nHowever, this process typically requires multiple movements of the robot arm\nand an external calibration object, making it both time-consuming and\ninconvenient, especially in scenarios where frequent recalibration is\nnecessary. In this work, we extend our previous method, Look at Robot Base Once\n(LRBO), which eliminates the need for external calibration objects such as a\nchessboard. We propose a generic dataset generation approach for point cloud\nregistration, focusing on aligning the robot base point cloud with the scanned\ndata. Furthermore, a more detailed simulation study is conducted involving\nseveral different collaborative robot arms, followed by real-world experiments\nin an industrial setting. Our improved method is simulated and evaluated using\na total of 14 robotic arms from 9 different brands, including KUKA, Universal\nRobots, UFACTORY, and Franka Emika, all of which are widely used in the field\nof collaborative robotics. Physical experiments demonstrate that our extended\napproach achieves performance comparable to existing commercial hand-eye\ncalibration solutions, while completing the entire calibration procedure in\njust a few seconds. In addition, we provide a user-friendly hand-eye\ncalibration solution, with the code publicly available at\ngithub.com/leihui6/LRBO2.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-30T13:20:57Z"}
{"aid":"http://arxiv.org/abs/2504.21626v1","title":"Reply to comment on: Observation of the quantum equivalence principle\n  for matter-waves","summary":"We show that in contrast to a recent claim, the Quantum Galileo\nInterferometer is sensitive to a uniform gravitational field in the presence\nand even in the absence of the levitation condition.","main_category":"quant-ph","categories":"quant-ph,cond-mat.quant-gas,gr-qc,physics.atom-ph","published":"2025-04-30T13:29:18Z"}
{"aid":"http://arxiv.org/abs/2504.21629v1","title":"The Quantitative Faber-Krahn Inequality for the Combinatorial Laplacian\n  in $\\mathbb{Z}^{d}$","summary":"While the classical Faber-Krahn inequality shows that the ball uniquely\nminimizes the first Dirichlet eigenvalue of the Laplacian in the continuum,\nthis rigidity may fail in the discrete setting. We establish quantitative\nfluctuation estimates for the first Dirichlet eigenvalue of the combinatorial\nLaplacian on subsets of $\\mathbb{Z}^{d}$ when their cardinality diverges. Our\napproach is based on a controlled discrete-to-continuum extension of the\nassociated variational problem and the quantitative Faber-Krahn inequality.","main_category":"math.FA","categories":"math.FA","published":"2025-04-30T13:32:00Z"}
{"aid":"http://arxiv.org/abs/2504.21633v1","title":"Convergence rate for Nearest Neighbour matching: geometry of the domain\n  and higher-order regularity","summary":"Estimating some mathematical expectations from partially observed data and in\nparticular missing outcomes is a central problem encountered in numerous fields\nsuch as transfer learning, counterfactual analysis or causal inference.\nMatching estimators, estimators based on k-nearest neighbours, are widely used\nin this context. It is known that the variance of such estimators can converge\nto zero at a parametric rate, but their bias can have a slower rate when the\ndimension of the covariates is larger than 2. This makes analysis of this bias\nparticularly important. In this paper, we provide higher order properties of\nthe bias. In contrast to the existing literature related to this problem, we do\nnot assume that the support of the target distribution of the covariates is\nstrictly included in that of the source, and we analyse two geometric\nconditions on the support that avoid such boundary bias problems. We show that\nthese conditions are much more general than the usual convex support\nassumption, leading to an improvement of existing results. Furthermore, we show\nthat the matching estimator studied by Abadie and Imbens (2006) for the average\ntreatment effect can be asymptotically efficient when the dimension of the\ncovariates is less than 4, a result only known in dimension 1.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-30T13:34:14Z"}
{"aid":"http://arxiv.org/abs/2504.21681v1","title":"Investigating the Effect of Parallel Data in the Cross-Lingual Transfer\n  for Vision-Language Encoders","summary":"Most pre-trained Vision-Language (VL) models and training data for the\ndownstream tasks are only available in English. Therefore, multilingual VL\ntasks are solved using cross-lingual transfer: fine-tune a multilingual\npre-trained model or transfer the text encoder using parallel data. We study\nthe alternative approach: transferring an already trained encoder using\nparallel data. We investigate the effect of parallel data: domain and the\nnumber of languages, which were out of focus in previous work. Our results show\nthat even machine-translated task data are the best on average, caption-like\nauthentic parallel data outperformed it in some languages. Further, we show\nthat most languages benefit from multilingual training.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-30T14:19:15Z"}
{"aid":"http://arxiv.org/abs/2504.21695v1","title":"Self-Supervised Monocular Visual Drone Model Identification through\n  Improved Occlusion Handling","summary":"Ego-motion estimation is vital for drones when flying in GPS-denied\nenvironments. Vision-based methods struggle when flight speed increases and\nclose-by objects lead to difficult visual conditions with considerable motion\nblur and large occlusions. To tackle this, vision is typically complemented by\nstate estimation filters that combine a drone model with inertial measurements.\nHowever, these drone models are currently learned in a supervised manner with\nground-truth data from external motion capture systems, limiting scalability to\ndifferent environments and drones. In this work, we propose a self-supervised\nlearning scheme to train a neural-network-based drone model using only onboard\nmonocular video and flight controller data (IMU and motor feedback). We achieve\nthis by first training a self-supervised relative pose estimation model, which\nthen serves as a teacher for the drone model. To allow this to work at high\nspeed close to obstacles, we propose an improved occlusion handling method for\ntraining self-supervised pose estimation models. Due to this method, the root\nmean squared error of resulting odometry estimates is reduced by an average of\n15%. Moreover, the student neural drone model can be successfully obtained from\nthe onboard data. It even becomes more accurate at higher speeds compared to\nits teacher, the self-supervised vision-based model. We demonstrate the value\nof the neural drone model by integrating it into a traditional filter-based VIO\nsystem (ROVIO), resulting in superior odometry accuracy on aggressive 3D racing\ntrajectories near obstacles. Self-supervised learning of ego-motion estimation\nrepresents a significant step toward bridging the gap between flying in\ncontrolled, expensive lab environments and real-world drone applications. The\nfusion of vision and drone models will enable higher-speed flight and improve\nstate estimation, on any drone in any environment.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-30T14:38:01Z"}
{"aid":"http://arxiv.org/abs/2504.21708v1","title":"Computing Polynomial Representation in Subrings of Multivariate\n  Polynomial Rings","summary":"Let $\\mathcal{R} = \\mathbb{K}[x_1, \\dots, x_n]$ be a multivariate polynomial\nring over a field $\\mathbb{K}$ of characteristic 0. Consider $n$ algebraically\nindependent elements $g_1, \\dots, g_n$ in $\\mathcal{R}$. Let $\\mathcal{S}$\ndenote the subring of $\\mathcal{R}$ generated by $g_1, \\dots, g_n$, and let $h$\nbe an element of $\\mathcal{S}$. Then, there exists a unique element ${f} \\in\n\\mathbb{K}[u_1, \\dots, u_n]$ such that $h = f(g_1, \\dots, g_n)$.\n  In this paper, we provide an algorithm for computing ${f}$, given $h$ and\n$g_1, \\dots, g_n$. The complexity of our algorithm is linear in the size of the\ninput, $h$ and $g_1, \\dots, g_n$, and polynomial in $n$ when the degree of $f$\nis fixed. Previous works are mostly known when $f$ is a symmetric polynomial\nand $g_1, \\dots, g_n$ are elementary symmetric, homogeneous symmetric, or power\nsymmetric polynomials.","main_category":"cs.SC","categories":"cs.SC,cs.CC,math.AG","published":"2025-04-30T14:52:31Z"}
{"aid":"http://arxiv.org/abs/2504.21712v1","title":"Presentations, embeddings and automorphisms of homogeneous spaces for\n  SL(2,C)","summary":"For an algebraically closed field $k$ of characteristic zero and a linear\nalgebraic $k$-group $G$, it is well known that every affine $G$-variety admits\na $G$-equivariant closed embedding into a finite-dimensional $G$-module. Such\nan embedding is a presentation of the $G$-variety, and a minimal presentation\nis one for which the dimension the $G$-module is minimal. The problem of\nfinding a minimal presentation generalizes the problem of determining whether a\ngroup action on affine space is linearizable. We give a minimal presentation\nfor each homogeneous space for $SL_2(k)$. This constitutes the paper's main\nwork. Of particular interest are the surfaces $Y=SL_2(k)/T$ and $X=SL_2(k)/N$\nwhere $T$ is the one-dimensional torus and $N$ is its normalizer. We show that\nthe minimal presentation of $X$ has dimension 5, the embedding dimension of $X$\nis 4, and there does not exist a closed $SL_2$-equivariant embedding of $X$ in\n$A_k^4$. Thus, the $SL_2$-action on $X$ is absolutely nonextendable to $A_k^4$.\nWe give two other examples of surfaces with absolutely nonextendable group\nactions. In addition, $X$ is noncancelative, that is, there exists a surface\n$Z$ such that $X\\times A_k^1\\cong_k Z\\times A_k^1$ and $X\\not\\cong_kZ$.\nFinally, we settle the long-standing open question of whether there exist\ninequivalent closed embeddings of $Y$ in $A_k^3$ by constructing inequivalent\nembeddings.","main_category":"math.AG","categories":"math.AG","published":"2025-04-30T14:55:13Z"}
{"aid":"http://arxiv.org/abs/2504.21750v1","title":"Online Knapsack Problems with Estimates","summary":"Imagine you are a computer scientist who enjoys attending conferences or\nworkshops within the year. Sadly, your travel budget is limited, so you must\nselect a subset of events you can travel to.\n  When you are aware of all possible events and their costs at the beginning of\nthe year, you can select the subset of the possible events that maximizes your\nhappiness and is within your budget.\n  On the other hand, if you are blind about the options, you will likely have a\nhard time when trying to decide if you want to register somewhere or not, and\nwill likely regret decisions you made in the future.\n  These scenarios can be modeled by knapsack variants, either by an offline or\nan online problem. However, both scenarios are somewhat unrealistic:\n  Usually, you will not know the exact costs of each workshop at the beginning\nof the year. The online version, however, is too pessimistic, as you might\nalready know which options there are and how much they cost roughly. At some\npoint, you have to decide whether to register for some workshop, but then you\nare aware of the conference fee and the flight and hotel prices.\n  We model this problem within the setting of online knapsack problems with\nestimates: in the beginning, you receive a list of potential items with their\nestimated size as well as the accuracy of the estimates. Then, the items are\nrevealed one by one in an online fashion with their actual size, and you need\nto decide whether to take one or not. In this article, we show a best-possible\nalgorithm for each estimate accuracy $\\delta$ (i.e., when each actual item size\ncan deviate by $\\pm \\delta$ from the announced size) for both the simple\nknapsack and the simple knapsack with removability.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-30T15:42:43Z"}
{"aid":"http://arxiv.org/abs/2504.21762v1","title":"Spectra of Lorentzian quasi-Fuchsian manifolds","summary":"A three-dimensional quasi-Fuchsian Lorentzian manifold $M$ is a globally\nhyperbolic spacetime diffeomorphic to $\\Sigma\\times (-1,1)$ for a closed\norientable surface $\\Sigma$ of genus $\\geq 2$. It is the quotient\n$M=\\Gamma\\backslash \\Omega_\\Gamma$ of an open set $\\Omega_\\Gamma\\subset {\\rm\nAdS}_3$ by a discrete group $\\Gamma$ of isometries of ${\\rm AdS}_3$ which is a\nparticular example of an Anosov representation of $\\pi_1(\\Sigma)$. We first\nshow that the spacelike geodesic flow of $M$ is Axiom A, has a discrete Ruelle\nresonance spectrum with associated (co-)resonant states, and that the\nPoincar\\'e series for $\\Gamma$ extend meromorphically to $\\mathbb{C}$. This is\nthen used to prove that there is a natural notion of resolvent of the\npseudo-Riemannian Laplacian $\\Box$ of $M$, which is meromorphic on $\\mathbb{C}$\nwith poles of finite rank, defining a notion of quantum resonances and quantum\nresonant states related to the Ruelle resonances and (co-)resonant states by a\nquantum-classical correspondence. This initiates the spectral study of convex\nco-compact pseudo-Riemannian locally symmetric spaces.","main_category":"math.DG","categories":"math.DG,math.DS,math.SP","published":"2025-04-30T16:02:16Z"}
{"aid":"http://arxiv.org/abs/2504.21781v1","title":"Message Optimality and Message-Time Trade-offs for APSP and Beyond","summary":"Round complexity is an extensively studied metric of distributed algorithms.\nIn contrast, our knowledge of the \\emph{message complexity} of distributed\ncomputing problems and its relationship (if any) with round complexity is still\nquite limited. To illustrate, for many fundamental distributed graph\noptimization problems such as (exact) diameter computation, All-Pairs Shortest\nPaths (APSP), Maximum Matching etc., while (near) round-optimal algorithms are\nknown, message-optimal algorithms are hitherto unknown. More importantly, the\nexisting round-optimal algorithms are not message-optimal. This raises two\nimportant questions: (1) Can we design message-optimal algorithms for these\nproblems? (2) Can we give message-time tradeoffs for these problems in case the\nmessage-optimal algorithms are not round-optimal?\n  In this work, we focus on a fundamental graph optimization problem, \\emph{All\nPairs Shortest Path (APSP)}, whose message complexity is still unresolved. We\npresent two main results in the CONGEST model: (1) We give a message-optimal\n(up to logarithmic factors) algorithm that solves weighted APSP, using\n$\\tilde{O}(n^2)$ messages. This algorithm takes $\\tilde{O}(n^2)$ rounds. (2)\nFor any $0 \\leq \\varepsilon \\le 1$, we show how to solve unweighted APSP in\n$\\tilde{O}(n^{2-\\varepsilon })$ rounds and $\\tilde{O}(n^{2+\\varepsilon })$\nmessages. At one end of this smooth trade-off, we obtain a (nearly)\nmessage-optimal algorithm using $\\tilde{O}(n^2)$ messages (for $\\varepsilon =\n0$), whereas at the other end we get a (nearly) round-optimal algorithm using\n$\\tilde{O}(n)$ rounds (for $\\varepsilon = 1$). This is the first such\nmessage-time trade-off result known.","main_category":"cs.DC","categories":"cs.DC,cs.DS","published":"2025-04-30T16:34:53Z"}
{"aid":"http://arxiv.org/abs/2504.21786v1","title":"Improved Lanczos Algorithm using Matrix Product States","summary":"We improve the Lanczos algorithm using the matrix product state\nrepresentation proposed in Phys. Rev. B 85, 205119 (2012). As an alternative to\nthe density matrix renormalization group (DMRG), the Lanczos algorithm avoids\nlocal minima and can directly find multiple low-lying eigenstates. However, its\nperformance and accuracy are affected by the truncation required to maintain\nthe efficiency of the tensor network representation. In this work, we enhance\nits convergence by restarting with multiple states. We benchmark our method on\none-dimensional instances of the Fermi-Hubbard model with 8 sites and the\nHeisenberg model with 16 sites in an external field, using numerical\nexperiments targeting the first five lowest eigenstates. Across these tests,\nour approach obtains accuracy improvements of three to seven orders of\nmagnitude. Finally, we extend the Heisenberg model simulation to a lattice with\n30 sites to highlight its scalability.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,physics.comp-ph,quant-ph","published":"2025-04-30T16:45:25Z"}
{"aid":"http://arxiv.org/abs/2504.21790v1","title":"Discrete series for the graded Hecke algebra of type $H_{4}$","summary":"This article confirms the prediction that the set of discrete series central\ncharacter for the graded (affine) Hecke algebra of type $H_4$ coincides with\nthe set of the Heckman-Opdam central characters. Combining with previous cases\nof Kazhdan-Lusztig, Kriloff, Kriloff-Ram, Opdam-Solleveld, Ciubotaru-Opdam,\nthis completes the classification of discrete series for all the graded Hecke\nalgebras of positive parameters. Main tools include construction of calibrated\nmodules and construction of certain minimally induced modules for discrete\nseries. We also study the anti-sphericiity and Ext-branching laws for some\ndiscrete series.","main_category":"math.RT","categories":"math.RT,math.NT","published":"2025-04-30T16:50:01Z"}
{"aid":"http://arxiv.org/abs/2504.21801v1","title":"DeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via\n  Reinforcement Learning for Subgoal Decomposition","summary":"We introduce DeepSeek-Prover-V2, an open-source large language model designed\nfor formal theorem proving in Lean 4, with initialization data collected\nthrough a recursive theorem proving pipeline powered by DeepSeek-V3. The\ncold-start training procedure begins by prompting DeepSeek-V3 to decompose\ncomplex problems into a series of subgoals. The proofs of resolved subgoals are\nsynthesized into a chain-of-thought process, combined with DeepSeek-V3's\nstep-by-step reasoning, to create an initial cold start for reinforcement\nlearning. This process enables us to integrate both informal and formal\nmathematical reasoning into a unified model. The resulting model,\nDeepSeek-Prover-V2-671B, achieves state-of-the-art performance in neural\ntheorem proving, reaching 88.9% pass ratio on the MiniF2F-test and solving 49\nout of 658 problems from PutnamBench. In addition to standard benchmarks, we\nintroduce ProverBench, a collection of 325 formalized problems, to enrich our\nevaluation, including 15 selected problems from the recent AIME competitions\n(years 24-25). Further evaluation on these 15 AIME problems shows that the\nmodel successfully solves 6 of them. In comparison, DeepSeek-V3 solves 8 of\nthese problems using majority voting, highlighting that the gap between formal\nand informal mathematical reasoning in large language models is substantially\nnarrowing.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-30T16:57:48Z"}
{"aid":"http://arxiv.org/abs/2504.21804v1","title":"Indian participation in the construction of the Facility for Antiproton\n  and Ion Research (FAIR) at Darmstadt, Germany","summary":"India is a founder-member country to participate in the construction of the\ninternational multipurpose accelerator facility called the Facility for\nAntiproton and Ion Research (FAIR) at Darmstadt, Germany. Bose Institute,\nKolkata, has been designated as the Indian shareholder of the FAIR GmbH and the\nnodal Indian Institution for co-ordinating Indian participation in the FAIR\nprogramme.\n  Indian participation in FAIR is twofold. Firstly, the advancement of\nknowledge in nuclear astrophysics and reaction, high-energy nuclear physics,\natomic \\& plasma physics and application through the participation of Indian\nresearchers, engineers and students in various experiments planned at FAIR. In\naddition to this, India is also contributing high-tech accelerator equipment as\nin-kind contribution to FAIR.\n  Our active involvement include the designing, manufacturing and supply of\nin-kind accelerator items e.g. power converters, vacuum chamber, beam catchers,\nIT diagnostic cables among them and coordinating the participation of Indian\nscientists in the FAIR experiments including detector development, physics\nsimulation, experimental data analysis.\n  Indian researchers have been participating in the two major experiments at\nFAIR, i.e. Nuclear Structure, Astrophysics and Reactions (NUSTAR) and\nCompressed Baryonic Matter (CBM) and in particular Bose Institute is involved\nin the CBM experiment, to study and characterize the matter created in the\nrelativistic nucleus-nucleus collisions at high net baryon density and\nrelatively moderate temperature.\n  In this article a brief overview on the FAIR facility, the experiments at\nFAIR and Indian participation are presented.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-30T17:03:11Z"}
{"aid":"http://arxiv.org/abs/2504.21826v1","title":"An Underwater, Fault-Tolerant, Laser-Aided Robotic Multi-Modal Dense\n  SLAM System for Continuous Underwater In-Situ Observation","summary":"Existing underwater SLAM systems are difficult to work effectively in\ntexture-sparse and geometrically degraded underwater environments, resulting in\nintermittent tracking and sparse mapping. Therefore, we present Water-DSLAM, a\nnovel laser-aided multi-sensor fusion system that can achieve uninterrupted,\nfault-tolerant dense SLAM capable of continuous in-situ observation in diverse\ncomplex underwater scenarios through three key innovations: Firstly, we develop\nWater-Scanner, a multi-sensor fusion robotic platform featuring a self-designed\nUnderwater Binocular Structured Light (UBSL) module that enables high-precision\n3D perception. Secondly, we propose a fault-tolerant triple-subsystem\narchitecture combining: 1) DP-INS (DVL- and Pressure-aided Inertial Navigation\nSystem): fusing inertial measurement unit, doppler velocity log, and pressure\nsensor based Error-State Kalman Filter (ESKF) to provide high-frequency\nabsolute odometry 2) Water-UBSL: a novel Iterated ESKF (IESKF)-based tight\ncoupling between UBSL and DP-INS to mitigate UBSL's degeneration issues 3)\nWater-Stereo: a fusion of DP-INS and stereo camera for accurate initialization\nand tracking. Thirdly, we introduce a multi-modal factor graph back-end that\ndynamically fuses heterogeneous sensor data. The proposed multi-sensor factor\ngraph maintenance strategy efficiently addresses issues caused by asynchronous\nsensor frequencies and partial data loss. Experimental results demonstrate\nWater-DSLAM achieves superior robustness (0.039 m trajectory RMSE and 100\\%\ncontinuity ratio during partial sensor dropout) and dense mapping (6922.4\npoints/m^3 in 750 m^3 water volume, approximately 10 times denser than existing\nmethods) in various challenging environments, including pools, dark underwater\nscenes, 16-meter-deep sinkholes, and field rivers. Our project is available at\nhttps://water-scanner.github.io/.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-30T17:30:13Z"}
{"aid":"http://arxiv.org/abs/2505.00266v1","title":"Tripartite hybrid quantum systems: Skyrmion-mediated quantum\n  interactions between single NV centers and superconducting qubits","summary":"Nitrogen-vacancy (NV) centers in diamond and superconducting qubits are two\npromising solid-state quantum systems for quantum science and technology, but\nthe realization of controlled interfaces between individual solid-state spins\nand superconducting qubits remains fundamentally challenging. Here, we propose\nand analyze a hybrid quantum system consisting of a magnetic skyrmion, an NV\ncenter, and a superconducting qubit, where the solid-state qubits are both\npositioned in proximity to the skyrmion structure in a thin magnetic disk. We\nshow that it is experimentally feasible to achieve strong magnetic (coherent or\ndissipative) coupling between the NV center and the superconducting qubit by\nusing the \\textit{quantized gyration mode of the skyrmion} as an intermediary.\nThis allows coherent information transfer and nonreciprocal responses between\nthe NV center and the superconducting qubit at the single quantum level with\nhigh controllability. The proposed platform provides a scalable pathway for\nimplementing quantum protocols that synergistically exploit the complementary\nadvantages of spin-based quantum memories, microwave-frequency superconducting\ncircuits, and topologically protected magnetic excitations.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall","published":"2025-05-01T03:24:42Z"}
{"aid":"http://arxiv.org/abs/2505.00302v1","title":"Temporal Attention Evolutional Graph Convolutional Network for\n  Multivariate Time Series Forecasting","summary":"Multivariate time series forecasting enables the prediction of future states\nby leveraging historical data, thereby facilitating decision-making processes.\nEach data node in a multivariate time series encompasses a sequence of multiple\ndimensions. These nodes exhibit interdependent relationships, forming a graph\nstructure. While existing prediction methods often assume a fixed graph\nstructure, many real-world scenarios involve dynamic graph structures.\nMoreover, interactions among time series observed at different time scales vary\nsignificantly. To enhance prediction accuracy by capturing precise temporal and\nspatial features, this paper introduces the Temporal Attention Evolutional\nGraph Convolutional Network (TAEGCN). This novel method not only integrates\ncausal temporal convolution and a multi-head self-attention mechanism to learn\ntemporal features of nodes, but also construct the dynamic graph structure\nbased on these temporal features to keep the consistency of the changing in\nspatial feature with temporal series. TAEGCN adeptly captures temporal causal\nrelationships and hidden spatial dependencies within the data. Furthermore,\nTAEGCN incorporates a unified neural network that seamlessly integrates these\ncomponents to generate final predictions. Experimental results conducted on two\npublic transportation network datasets, METR-LA and PEMS-BAY, demonstrate the\nsuperior performance of the proposed model.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-01T04:50:00Z"}
{"aid":"http://arxiv.org/abs/2505.00306v1","title":"J-PARSE: Jacobian-based Projection Algorithm for Resolving Singularities\n  Effectively in Inverse Kinematic Control of Serial Manipulators","summary":"J-PARSE is a method for smooth first-order inverse kinematic control of a\nserial manipulator near kinematic singularities. The commanded end-effector\nvelocity is interpreted component-wise, according to the available mobility in\neach dimension of the task space. First, a substitute \"Safety\" Jacobian matrix\nis created, keeping the aspect ratio of the manipulability ellipsoid above a\nthreshold value. The desired motion is then projected onto non-singular and\nsingular directions, and the latter projection scaled down by a factor informed\nby the threshold value. A right-inverse of the non-singular Safety Jacobian is\napplied to the modified command. In the absence of joint limits and collisions,\nthis ensures smooth transition into and out of low-rank poses, guaranteeing\nasymptotic stability for target poses within the workspace, and stability for\nthose outside. Velocity control with J-PARSE is benchmarked against the\nLeast-Squares and Damped Least-Squares inversions of the Jacobian, and shows\nhigh accuracy in reaching and leaving singular target poses. By expanding the\navailable workspace of manipulators, the method finds applications in servoing,\nteleoperation, and learning.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-01T04:58:50Z"}
{"aid":"http://arxiv.org/abs/2505.00308v1","title":"AI-Assisted Decision-Making for Clinical Assessment of Auto-Segmented\n  Contour Quality","summary":"Purpose: This study presents a Deep Learning (DL)-based quality assessment\n(QA) approach for evaluating auto-generated contours (auto-contours) in\nradiotherapy, with emphasis on Online Adaptive Radiotherapy (OART). Leveraging\nBayesian Ordinal Classification (BOC) and calibrated uncertainty thresholds,\nthe method enables confident QA predictions without relying on ground truth\ncontours or extensive manual labeling. Methods: We developed a BOC model to\nclassify auto-contour quality and quantify prediction uncertainty. A\ncalibration step was used to optimize uncertainty thresholds that meet clinical\naccuracy needs. The method was validated under three data scenarios: no manual\nlabels, limited labels, and extensive labels. For rectum contours in prostate\ncancer, we applied geometric surrogate labels when manual labels were absent,\ntransfer learning when limited, and direct supervision when ample labels were\navailable. Results: The BOC model delivered robust performance across all\nscenarios. Fine-tuning with just 30 manual labels and calibrating with 34\nsubjects yielded over 90% accuracy on test data. Using the calibrated\nthreshold, over 93% of the auto-contours' qualities were accurately predicted\nin over 98% of cases, reducing unnecessary manual reviews and highlighting\ncases needing correction. Conclusion: The proposed QA model enhances contouring\nefficiency in OART by reducing manual workload and enabling fast, informed\nclinical decisions. Through uncertainty quantification, it ensures safer, more\nreliable radiotherapy workflows.","main_category":"cs.CV","categories":"cs.CV,cs.AI,stat.AP","published":"2025-05-01T05:05:35Z"}
{"aid":"http://arxiv.org/abs/2505.00327v1","title":"Aganagic's invariant is Khovanov homology","summary":"On the Coulomb branch of a quiver gauge theory, there is a family of\nfunctions parameterized by choices of points in the punctured plane. Aganagic\nhas predicted that Khovanov homology can be recovered from the braid group\naction on Fukaya-Seidel categories arising from monodromy in said space of\npotentials. These categories have since been rigorously studied, and shown to\ncontain a certain (combinatorially defined) category on which Webster had\npreviously constructed a (combinatorially defined) braid group action from\nwhich the Khovanov homology can be recovered.\n  Here we show, by a direct calculation, that the aforementioned containment\nintertwines said combinatorially defined braid group action with the braid\ngroup action arising naturally from monodromy. This provides a mathematical\nverification that Aganagic's proposal gives a symplectic construction of\nKhovanov homology -- with both gradings, and over the integers.","main_category":"math.SG","categories":"math.SG,hep-th,math.GT","published":"2025-05-01T05:55:28Z"}
{"aid":"http://arxiv.org/abs/2505.00342v1","title":"LLMPrism: Black-box Performance Diagnosis for Production LLM Training\n  Platforms","summary":"Large Language Models (LLMs) have brought about revolutionary changes in\ndiverse fields, rendering LLM training of utmost importance for modern\nenterprises. To meet this demand, multi-tenant large-scale LLM training\nplatforms have been built to offer LLM training services. Nevertheless, due to\nthe complexity and synchronous nature of LLM training process, performance\nissues occur frequently and can result in substantial resource wastage. The\nlimited visibility from the perspective of platform providers impedes existing\nprofiling methods and poses challenges to the monitoring and diagnosis of the\nperformance of LLM training jobs. For the first time, this paper proposes the\nutilization of underlying network flow data to reconstruct the training\ntimelines of jobs based on the distinct characteristics in the LLM training\nprocedure. We design LLMPrism, the first black-box performance diagnosis system\nfor LLM training platforms. By progressively recognizing LLM training jobs,\nidentifying their parallelism strategies, and reconstructing the training\ntimelines, LLMPrism achieves non-intrusive, lightweight, and continuous\nmonitoring of LLM training systems. Leveraging this monitoring capability, it\nfurther effectively diagnoses potential performance issues. Since Oct. 2024,\nLLMPrism has been deployed on our large-scale production Platform-X, in which\nthe evaluations and deployment experiences demonstrate that LLMPrism can\nachieve accurate timeline reconstruction with an error within 0.3% and\neffectively diagnose various performance issues.","main_category":"cs.SE","categories":"cs.SE","published":"2025-05-01T06:38:52Z"}
{"aid":"http://arxiv.org/abs/2505.00346v1","title":"Hilbert's Theorem 90, periodicity, and roots of Artin-Schreier\n  polynomials","summary":"Let $E/F$ be a cyclic field extension of degree $n$, and let $\\sigma$\ngenerate the group Gal$(E/F)$. If Tr${}^E_F(y)=\\sum_{i=0}^{n-1}\\sigma^i y=0$,\nthen the additive form of Hilbert's Theorem 90 asserts that $y=\\sigma x-x$ for\nsome $x\\in E$. Suppose that $E$ has characteristic $p$. We prove that $x$ gives\nrise to a periodic sequence $x_0,x_1,\\dots$ which has period $pn_p$, where\n$n_p$ is the largest $p$-power that divides $n$. As an application, we find\nclosed-form expressions for the roots of Artin-Schreier polynomials $t^p-t-y$.\nLet $y$ lie in the finite field $F_{p^n}$ of order $p^n$. The Artin-Schreier\npolynomial $t^p-t-y\\in F_{p^n}[t]$ is reducible precisely when\n$\\sum_{i=0}^{n-1}y^{p^i}=0$. In this case, $t^p-t-y=\\prod_{k=0}^{p-1}(t-x-k)$\nwhere $x=\\sum_{i=0}^{n-1}\\sum_{j=0}^{i-1}z^{p^j}y^{p^i}$ for some $z\\in\nF_{p^e}$ and $e=n_p$. The sequence\n$\\left(\\sum_{j=0}^{i-1}z^{p^j}\\right)_{i\\ge0}$ is periodic with period $pe$,\nand if $e$ is small, then we give explicit $z$.","main_category":"math.NT","categories":"math.NT,math.AC,math.GR","published":"2025-05-01T06:47:38Z"}
{"aid":"http://arxiv.org/abs/2505.00360v1","title":"Interior curvature estimate for curvature quotient equations on convex\n  hypersurfaces","summary":"We study interior curvature estimates for convex graphs which satisfy the\nquotient equation $\\frac{\\sigma_{n}}{\\sigma_{n-2}}(\\lambda)=f(X)>0$ in this\npaper.","main_category":"math.DG","categories":"math.DG,math.AP","published":"2025-05-01T07:19:50Z"}
{"aid":"http://arxiv.org/abs/2505.00396v1","title":"Temporal coupled mode theory for high-$Q$ resonances in dielectric\n  metasurfaces","summary":"In this work, we propose a coupled mode theory for resonant response from\nquasi-guided modes in periodic dielectric metasurfaces. First, we derived a\ngeneric set of constraints imposed onto the parameters of the temporal coupled\nmode theory by energy conservation and time-reversal symmetry in an invariant\nform that allows for asymmetry between the coupling and decoupling\ncoefficients. The proposed approach is applied to the problem of Fano\nresonances induced by isolated quasi-guided modes in the regime of specular\nreflection. Our central result is a generic formula for the line-shape of the\nFano resonance in transmittance for the lossless metasurfaces in the framework\nof 2D electrodynamics. We consider all possible symmetries of the metasurface\nelementary cell and uncover the effects that the symmetry incurs on the profile\nof the Fano resonance induced by an isolated high-$Q$ mode. It is shown that\nthe proposed approach correctly describes the presence of robust reflection and\ntransmission zeros in the spectra as well as the spectral signatures of bound\nstates in the continuum. The approach is applied to uniderictionally guided\nresonant modes in metasurfaces with an asymmetric elementary cell. It is found\nthat the existence of such modes and the transmittance in their spectral\nvicinity are consistent with the theoretical predictions. Furthermore, the\ntheory predicts that a uniderictionally guided resonant mode is dual to a\ncounter-propagating mode of a peculiar type which is coupled with the outgoing\nwave on both sides of the metasurface but, nonetheless, exhibits only a\nsingle-sided coupling with incident waves.","main_category":"physics.optics","categories":"physics.optics","published":"2025-05-01T08:32:07Z"}
{"aid":"http://arxiv.org/abs/2505.00408v1","title":"Multi-dimensional optical imaging on a chip","summary":"Light inherently consists of multiple dimensions beyond intensity, including\nspectrum, polarization, etc. The coupling among these high-dimensional optical\nfeatures provides a compressive characterization of intrinsic material\nproperties. Because multiple optical dimensions are intrinsically coupled\nrather than independent, analyzing their inter-relationships and achieving\ntheir simultaneous acquisition is essential. Despite the existing optical\ntechniques to obtain different-dimensional data with cumbersome systems, joint\nacquisition of multi-dimensional optical information on a chip is still a\nserious challenge, limited by intensity-only photoelectric detection,\nsingle-dimensional optical elements, and finite bandwidth. In this work, we\nreport a multi-dimensional on-chip optical imaging (MOCI) architecture, which\nis functionally composed of three layers, including a multi-dimensional\nencoding layer to simultaneously encode different dimensions of incident light,\nan image acquisition layer to collect coupled intensity data, and a\ncomputational reconstruction layer to recover multi-dimensional images from a\nsingle frame of coupled measurement. Following the MOCI architecture, we for\nthe first time fabricated a real-time (74 FPS) on-chip\npolarization-hyperspectral imaging (PHI) sensor, with 2048$\\times$2448 pixels\nat 61 spectral channels covering the VIS-NIR range and 4 polarization states.\nWe applied the PHI sensor for simultaneously resolving hyperspectral and\npolarization information of complex scenes, and for the first time demonstrated\nnew applications including hyperspectral 3D modeling with normal and height\nmaps, and hyperspectral sensing against strong reflection and glare...","main_category":"physics.optics","categories":"physics.optics","published":"2025-05-01T08:59:18Z"}
{"aid":"http://arxiv.org/abs/2505.00423v1","title":"Thermal evolution model from cometary nuclei to asteroids considering\n  contraction associated with ice sublimation","summary":"Comet--asteroid transition (CAT) objects are small solar system bodies in the\nprocess of evolving from cometary nuclei into asteroids, as they gradually lose\nvolatile substances due to solar heating. The volatile material is mainly water\nice, and the time required for its complete depletion is called the desiccation\ntime. Estimating the desiccation time is important for examining the formation\nand evolution of small solar system bodies. Here, we propose a new theoretical\nmodel for evaluating the desiccation time as a function of orbital elements,\nconsidering the contraction of the entire cometary nucleus due to ice\nsublimation. First, we performed numerical calculations of the thermal\nevolution of a cometary nucleus in an eccentric orbit, considering the seasonal\nvariation in the solar heating rate. Next, we derived the desiccation time\nanalytically as a function of orbital elements based on a steady-state model\nconsidering the solar heating rate averaged over the seasons. We compared the\nnumerical solutions for the desiccation time with the analytical solutions and\nclarified the conditions under which the analytical model can be applied.\nAdditionally, based on the analytical model, we derived formulae for estimating\nthe emission rates of water vapor and dust on the surface of the cometary\nnucleus, the maximum size of the emitted dust, and the dust emission velocity,\nby assuming the amount of ice remaining inside the nucleus. Using these\nanalytical solutions, we considered the internal structure and evolution\nprocess of typical CAT objects. Our analytical model was generally consistent\nwith that of the results of earlier observations of these objects. Our model\nprovides a theoretical guideline for discussing the evolution of cometary\nnuclei and the possibility of retaining internal ice in asteroids.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-05-01T09:45:32Z"}
{"aid":"http://arxiv.org/abs/2505.00426v1","title":"Leveraging Pretrained Diffusion Models for Zero-Shot Part Assembly","summary":"3D part assembly aims to understand part relationships and predict their\n6-DoF poses to construct realistic 3D shapes, addressing the growing demand for\nautonomous assembly, which is crucial for robots. Existing methods mainly\nestimate the transformation of each part by training neural networks under\nsupervision, which requires a substantial quantity of manually labeled data.\nHowever, the high cost of data collection and the immense variability of\nreal-world shapes and parts make traditional methods impractical for\nlarge-scale applications. In this paper, we propose first a zero-shot part\nassembly method that utilizes pre-trained point cloud diffusion models as\ndiscriminators in the assembly process, guiding the manipulation of parts to\nform realistic shapes. Specifically, we theoretically demonstrate that\nutilizing a diffusion model for zero-shot part assembly can be transformed into\nan Iterative Closest Point (ICP) process. Then, we propose a novel pushing-away\nstrategy to address the overlap parts, thereby further enhancing the robustness\nof the method. To verify our work, we conduct extensive experiments and\nquantitative comparisons to several strong baseline methods, demonstrating the\neffectiveness of the proposed approach, which even surpasses the supervised\nlearning method. The code has been released on\nhttps://github.com/Ruiyuan-Zhang/Zero-Shot-Assembly.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-01T09:54:12Z"}
{"aid":"http://arxiv.org/abs/2505.00431v1","title":"Global multiplicity results in a Moore-Nehari type problem with a\n  spectral parameter","summary":"This paper analyzes the structure of the set of positive solutions of a\nMoore-Nehari type problem, where $a\\equiv a_h$ is a piece-wise constant\nfunction defined for some $h\\in (0,1)$. In our analysis, $\\lambda$ is regarded\nas a bifurcation parameter, whereas $h$ is viewed as a deformation parameter\nbetween the autonomous case when $a=1$ and the linear case when $a=0$. In this\npaper, besides establishing some of the multiplicity results suggested by\nprevious numerical experiments (see Cubillos, L\\'opez-G\\'omez and Tellini,\n2024), we have analyzed the asymptotic behavior of the positive solutions of\nthe problem as $h\\uparrow 1$, when the shadow system of the problem is the\nlinear equation $-u''=\\pi^2 u$. This is the first paper where such a problem\nhas been addressed. Numerics is of no help in analyzing this singular\nperturbation problem because the positive solutions blow-up point-wise in\n$(0,1)$ as $h\\uparrow 1$ if $\\lambda<\\pi^2$.","main_category":"math.CA","categories":"math.CA","published":"2025-05-01T10:01:14Z"}
{"aid":"http://arxiv.org/abs/2505.00442v1","title":"Decentralised, Self-Organising Drone Swarms using Coupled Oscillators","summary":"The problem of robotic synchronisation and coordination is a long-standing\none. Combining autonomous, computerised systems with unpredictable real-world\nconditions can have consequences ranging from poor performance to collisions\nand damage. This paper proposes using coupled oscillators to create a drone\nswarm that is decentralised and self organising. This allows for greater\nflexibility and adaptiveness than a hard-coded swarm, with more resilience and\nscalability than a centralised system. Our method allows for a variable number\nof drones to spontaneously form a swarm and react to changing swarm conditions.\nAdditionally, this method includes provisions to prevent communication\ninterference between drones, and signal processing techniques to ensure a\nsmooth and cohesive swarm.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY,nlin.AO","published":"2025-05-01T10:35:08Z"}
{"aid":"http://arxiv.org/abs/2505.00454v1","title":"Approximate calculation of functional integrals arising from the\n  operator approach","summary":"We apply the operator approach to a stochastic system belonging to a class of\ndeath-birth processes, which we introduce utilizing the master equation\napproach. By employing Doi- Peliti formalism we recast the master equation in\nthe form of a Schr\\\"odinger-like equation. Therein appearing pseudo-Hamiltonian\nis conveniently expressed in a suitable Fock space, constructed using\nbosonic-like creation and annihilation operators. The kernel of the associated\ntime evolution operator is rewritten using a functional integral, for which we\npropose an approximate method that allows its analytical treatment. The method\nis based on the expansion in eigenfunctions of the Hamiltonian generating given\nfunctional integral. In this manner, we obtain approximate values for the\nprobabilities of the system being in the first and second states for the case\nof the pure birth process.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-05-01T11:08:31Z"}
{"aid":"http://arxiv.org/abs/2505.00461v1","title":"Field-theoretic Analysis of Dynamic Isotropic Percolation: Three-loop\n  Approximation","summary":"The general epidemic process is a paradigmatic model in non-equilibrium\nstatistical physics displaying a continuous phase transition between active and\nabsorbing states.The dynamic isotropic percolation universality class captures\nits universal properties, which we aim to quantitatively study by means of the\nfield-theoretic formulation of the model augmented with a perturbative\nrenormalization group analysis. The main purpose of this work consists in\ndetermining the critical dynamic exponent $z$ to the three-loop approximation.\nThis allows us to finalize the quantitative description of the dynamic\nisotropic percolation class to this order of perturbation theory. The\ncalculations are performed within the dimensional regularization with the\nminimal subtraction scheme and actual perturbative expansions are carried out\nin a formally small parameter $\\epsilon$, where $\\epsilon = 6 - d$ is a\ndeviation from the upper critical dimension $d_c = 6$.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-05-01T11:28:53Z"}
{"aid":"http://arxiv.org/abs/2505.00462v1","title":"CORSTITCH - A free, open source software for stitching and\n  georeferencing underwater coral reef videos","summary":"CorStitch is an open-source software developed to automate the creation of\naccurate georeferenced reef mosaics from video transects obtained through\nAutomated Rapid Reef Assessment System surveys. We utilized a Fourier-based\nimage correlation algorithm to stitch sequential video frames, aligning them\nwith synchronized GNSS timestamps. The resulting compressed Keyhole Markup\nLanguage files, compatible with geographic information systems such as Google\nEarth, enable detailed spatial analysis. Validation through comparative\nanalysis of mosaics from two temporally distinct surveys of the same reef\ndemonstrated the software's consistent and reliable performance.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-05-01T11:29:45Z"}
{"aid":"http://arxiv.org/abs/2505.00478v1","title":"Probing ALP-portal Fermionic Dark Matter at the $e^+e^-$ Colliders","summary":"Axion-like particles (ALPs) are promising candidates for mediating\ninteractions between a dark sector and the Standard Model (SM). In this work,\nconsidering the effective interactions of ALPs with the SM gauge bosons and a\nfermion dark matter (DM), we explore the DM relic satisfied parameter space and\nassess its testability through indirect searches. The potential of probing such\nALP-portal fermionic DM at electron-positron colliders is investigated with the\nmono-photon + missing energy final states. We show that a spectacular\ndistinction between the signal and SM background is possible via missing energy\nvariable, the seed of which lies in the ALP-photon interaction, which also\ngoverns the relic density of DM. We further discuss the sensitivity of\nALP-photon coupling using the $\\chi^2$ analysis at the future electron-positron\ncollider specifications.","main_category":"hep-ph","categories":"hep-ph","published":"2025-05-01T12:11:03Z"}
{"aid":"http://arxiv.org/abs/2505.00479v1","title":"Computational Identification of Regulatory Statements in EU Legislation","summary":"Identifying regulatory statements in legislation is useful for developing\nmetrics to measure the regulatory density and strictness of legislation. A\ncomputational method is valuable for scaling the identification of such\nstatements from a growing body of EU legislation, constituting approximately\n180,000 published legal acts between 1952 and 2023. Past work on extraction of\nthese statements varies in the permissiveness of their definitions for what\nconstitutes a regulatory statement. In this work, we provide a specific\ndefinition for our purposes based on the institutional grammar tool. We develop\nand compare two contrasting approaches for automatically identifying such\nstatements in EU legislation, one based on dependency parsing, and the other on\na transformer-based machine learning model. We found both approaches performed\nsimilarly well with accuracies of 80% and 84% respectively and a K alpha of\n0.58. The high accuracies and not exceedingly high agreement suggests potential\nfor combining strengths of both approaches.","main_category":"cs.CL","categories":"cs.CL,I.2.7","published":"2025-05-01T12:11:32Z"}
{"aid":"http://arxiv.org/abs/2505.00510v1","title":"Ireland Topsoil Contamination Analysis: A Clustering Approach","summary":"This study investigates topsoil contamination in Ireland using geochemical\ndata from the Tellus Programme, analyzing 4,278 soil samples across 17,983\nsquare kilometer. The research employs CPF clustering with spatial constraints\nto classify samples into seven different groups, revealing distinct\ncontamination patterns.","main_category":"stat.AP","categories":"stat.AP","published":"2025-05-01T13:27:26Z"}
{"aid":"http://arxiv.org/abs/2505.00524v1","title":"Recursive inseparability of classical theories of a binary predicate and\n  non-classical logics of a unary predicate","summary":"The paper considers algorithmic properties of classical and non-classical\nfirst-order logics and theories in bounded languages. The main idea is to prove\nthe undecidability of various fragments of classical and non-classical\nfirst-order logics and theories indirectly, by extracting it as a consequence\nof the recursive inseparability of special problems associated with them.\nFirst, we propose a domino problem, which makes it possible to catch the\nrecursive inseparability of two sets. Second, using this problem, we prove that\nthe classical first-order logic of a binary predicate and the theory of its\nfinite models where the predicate is symmetric and irreflexive are recursively\ninseparable in a language with a single binary predicate letter and three\nvariables (without constants and equality). Third, we prove, for an infinite\nclass of logics, that the monadic fragment of a modal predicate logic and the\nlogic of the class of its finite Kripke frames are recursively inseparable in\nlanguages with a single unary predicate letter and two individual variables;\nthe same result is obtained if we replace the condition of finiteness of frames\nwith the condition of finiteness of domains allowed in frames. Forth, we expand\nthe results to a wide class of superintuitionistic predicate logics. In\nparticular, it is proved that the positive fragments of the intuitionistic\npredicate logic and the logic of the class of finite intuitionistic Kripke\nframes are recursively inseparable in the language with a single unary\npredicate letter and two individual variables. The technique used and the\nresults obtained allow us to answer some additional questions about the\ndecidability of special monadic fragments of some modal and superintuitionistic\npredicate logics.","main_category":"math.LO","categories":"math.LO","published":"2025-05-01T13:46:45Z"}
{"aid":"http://arxiv.org/abs/2505.00558v1","title":"Exponentially Consistent Low Complexity Tests for Outlier Hypothesis\n  Testing with Distribution Uncertainty","summary":"We revisit the outlier hypothesis testing (OHT) problem of Li et al. (TIT\n2024) and propose exponentially consistent tests when there is distribution\nuncertainty for both nominal samples and outliers. In original OHT, one is\ngiven a list of sequences, most of which are generated i.i.d. from a\ndistribution called the nominal distribution while the rest are generated\ni.i.d. from another distribution named the anomalous distribution. The task of\nOHT is to identify outliers when both the nominal and anomalous distributions\nare unknown. Motivated by the study for classification with distribution\nuncertainty by Hsu and Wang (ISIT 2020), we consider OHT with distribution\nuncertainty, where each nominal sample is generated from a distribution\ncentered around the unknown nominal distribution and each outlier is generated\nfrom a distribution centered around the unknown anomalous distribution. With a\nfurther step towards practical applications, in the spirit of Bu et al. (TSP\n2019), we propose low-complexity tests when the number of outliers is known and\nunknown, and show that our proposed tests are exponentially consistent.\nFurthermore, we demonstrate that there is a penalty for not knowing the number\nof outliers in the error exponent when outliers exist. Our results strengthen\nBu et al. in three aspects: i) our tests allow distribution uncertainty and\nreveal the impact of distribution uncertainty on the performance of\nlow-complexity tests; ii) when the number of outliers is known and there is no\ndistribution uncertainty, our test achieves the same asymptotic performance\nwith lower complexity; and iii) when the number of outliers is unknown, we\ncharacterize the tradeoff among the three error probabilities, while two of\nthese error probabilities were not analyzed by Bu et al. even when there is no\ndistribution uncertainty. Finally, we illustrate our theoretical results using\nnumerical examples.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-05-01T14:33:56Z"}
{"aid":"http://arxiv.org/abs/2505.00586v1","title":"ParkDiffusion: Heterogeneous Multi-Agent Multi-Modal Trajectory\n  Prediction for Automated Parking using Diffusion Models","summary":"Automated parking is a critical feature of Advanced Driver Assistance Systems\n(ADAS), where accurate trajectory prediction is essential to bridge perception\nand planning modules. Despite its significance, research in this domain remains\nrelatively limited, with most existing studies concentrating on single-modal\ntrajectory prediction of vehicles. In this work, we propose ParkDiffusion, a\nnovel approach that predicts the trajectories of both vehicles and pedestrians\nin automated parking scenarios. ParkDiffusion employs diffusion models to\ncapture the inherent uncertainty and multi-modality of future trajectories,\nincorporating several key innovations. First, we propose a dual map encoder\nthat processes soft semantic cues and hard geometric constraints using a\ntwo-step cross-attention mechanism. Second, we introduce an adaptive agent type\nembedding module, which dynamically conditions the prediction process on the\ndistinct characteristics of vehicles and pedestrians. Third, to ensure\nkinematic feasibility, our model outputs control signals that are subsequently\nused within a kinematic framework to generate physically feasible trajectories.\nWe evaluate ParkDiffusion on the Dragon Lake Parking (DLP) dataset and the\nIntersections Drone (inD) dataset. Our work establishes a new baseline for\nheterogeneous trajectory prediction in parking scenarios, outperforming\nexisting methods by a considerable margin.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-05-01T15:16:59Z"}
{"aid":"http://arxiv.org/abs/2505.00608v1","title":"Turning dispersion into signal: density-split analyses of pairwise\n  velocities","summary":"Pairwise velocities of the large-scale structure encode valuable information\nabout the growth of structure. They can be observed indirectly through\nredshift-space distortions and the kinetic Sunyaev-Zeldovich effect. Whether it\nis Gaussian or non-Gaussian, pairwise velocity has a broad distribution, but\nthe cosmologically useful information lies primarily in the mean - the\nstreaming velocities; the dispersion around the mean is often treated as a\nnuisance and marginalized over. This conventional approach reduces the\nconstraining power of our observations. Here, we show that this does not have\nto be the case, provided the physics behind the dispersion is understood. We\ndemonstrate that by splitting the halo/galaxy samples according to their\ndensity environments and measuring the streaming velocities separately, the\ntotal signal-to-noise is several times greater than in conventional global\nmeasurements of the pairwise velocity distribution (PVD). This improvement\narises because the global PVD is a composite of a series of near-Gaussian\ndistributions with different means and dispersions, each determined by its\nlocal density environment. Around underdense and overdense regions, the mean\nstreaming velocities are positive and negative, respectively. By splitting the\ndata, we avoid cancellation between these opposing velocities, effectively\nturning what would be considered dispersion in the global PVD into a signal.\nOur findings indicate substantial potential for improving the analysis of PVD\nobservations using the kinetic Sunyaev-Zeldovich effect and redshift-space\ndistortions.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-05-01T15:37:28Z"}
{"aid":"http://arxiv.org/abs/2505.00618v1","title":"RevealNet: Distributed Traffic Correlation for Attack Attribution on\n  Programmable Networks","summary":"Network attackers have increasingly resorted to proxy chains, VPNs, and\nanonymity networks to conceal their activities. To tackle this issue, past\nresearch has explored the applicability of traffic correlation techniques to\nperform attack attribution, i.e., to identify an attacker's true network\nlocation. However, current traffic correlation approaches rely on\nwell-provisioned and centralized systems that ingest flows from multiple\nnetwork probes to compute correlation scores. Unfortunately, this makes\ncorrelation efforts scale poorly for large high-speed networks.\n  In this paper, we propose RevealNet, a decentralized framework for attack\nattribution that orchestrates a fleet of P4-programmable switches to perform\ntraffic correlation. RevealNet builds on a set of correlation primitives\ninspired by prior work on computing and comparing flow sketches -- compact\nsummaries of flows' key characteristics -- to enable efficient, distributed,\nin-network traffic correlation. Our evaluation suggests that RevealNet achieves\ncomparable accuracy to centralized attack attribution systems while\nsignificantly reducing both the computational complexity and bandwidth\noverheads imposed by correlation tasks.","main_category":"cs.CR","categories":"cs.CR,cs.NI","published":"2025-05-01T15:48:35Z"}
{"aid":"http://arxiv.org/abs/2505.00659v1","title":"It's All ${\\tt Ok}$: Curvature in Light of BAO from DESI DR2","summary":"Recent measurements of baryon acoustic oscillations (BAO) from the Dark\nEnergy Spectroscopic Instrument (DESI) show hints of tension with data from the\ncosmic microwave background (CMB) when interpreted within the standard model of\ncosmology. In this short note we discuss the consequences of one solution to\nthis tension, a small but negative spatial curvature with $R_k = 21 H_0^{-1}$,\nwhich DESI measures at $2\\sigma$. We describe the physical role of curvature in\ncosmological distance measures tied to recombination, i.e. the CMB and BAO, and\nthe relation to neutrino mass constraints which are relaxed to $\\sum m_\\nu <\n0.10$ eV when curvature is allowed to deviate from zero. A robust detection of\nnegative curvature would have significant implications for inflationary models:\nimproved BAO measurements, particularly from future high-redshift spectroscopic\nsurveys, will be able to distinguish curvature from other solutions to the\nDESI-CMB tension like phantom dark energy at high significance.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-05-01T17:01:10Z"}
{"aid":"http://arxiv.org/abs/2505.00667v1","title":"A Practical Framework for Simulating Time-Resolved Spectroscopy Based on\n  a Real-time Dyson Expansion","summary":"Time-resolved spectroscopy is a powerful tool for probing electron dynamics\nin molecules and solids, revealing transient phenomena on sub-femtosecond\ntimescales. The interpretation of experimental results is often enhanced by\nparallel numerical studies, which can provide insight and validation for\nexperimental hypotheses. However, developing a theoretical framework for\nsimulating time-resolved spectra remains a significant challenge. The most\nsuitable approach involves the many-body non-equilibrium Green's function\nformalism, which accounts for crucial dynamical many-body correlations during\ntime evolution. While these dynamical correlations are essential for observing\nemergent behavior in time-resolved spectra, they also render the formalism\nprohibitively expensive for large-scale simulations. Substantial effort has\nbeen devoted to reducing this computational cost -- through approximations and\nnumerical techniques -- while preserving the key dynamical correlations. The\nultimate goal is to enable first-principles simulations of time-dependent\nsystems ranging from small molecules to large, periodic, multidimensional\nsolids. In this perspective, we outline key challenges in developing practical\nsimulations for time-resolved spectroscopy, with a particular focus on Green's\nfunction methodologies. We highlight a recent advancement toward a scalable\nframework: the real-time Dyson expansion (RT-DE). We introduce the theoretical\nfoundation of RT-DE and discuss strategies for improving scalability, which\nhave already enabled simulations of system sizes beyond the reach of previous\nfully dynamical approaches. We conclude with an outlook on future directions\nfor extending RT-DE to first-principles studies of dynamically correlated,\nnon-equilibrium systems.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-05-01T17:17:56Z"}
{"aid":"http://arxiv.org/abs/2505.00673v1","title":"Strange correlator and string order parameter for non-invertible\n  symmetry protected topological phases in 1+1d","summary":"In this paper, we construct strange correlators and string order parameters\nfor non-invertible symmetry protected topological phases (NISPTs) in 1+1d\nquantum lattice spin models. The strange correlator exhibits long-range order\nwhen evaluated between two distinct NISPTs and decays exponentially otherwise.\nWe show that strange charged operators inserted into the strange correlator are\nlinked to the interface algebra (boundary tube algebra) and are non-trivial\nwhen all its irreducible representations have dimensions greater than one. We\ndiscuss the generalization to higher dimensions. The string order parameter is\nobtained by contracting the truncated symmetry operator with charge decoration\noperators, which are determined by the NISPT action tensors. We illustrate the\nabove construction using the three NISPTs of $\\text{Rep}(D_8)$ and demonstrate\nthe extraction of categorical data via tensor networks, particularly through\nthe ZX calculus. Finally, we show that the entanglement spectrum degeneracy is\ndetermined by the irreducible representations of the interface algebra when\nassuming non-invertible symmetry on-site condition.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,hep-th,quant-ph","published":"2025-05-01T17:26:43Z"}
{"aid":"http://arxiv.org/abs/2505.00678v1","title":"Photonic Crystal Microring Resonators on a Hybrid Silicon\n  Nitride-on-Lithium Niobate Platform","summary":"Photonic-crystal resonators (PhCRs) have been widely used in nonlinear\nintegrated photonics for frequency engineering applications. A\nmicrowave-assisted frequency converter based on PhCRs highlights its precise\ncontrol of frequency (enabled by creation of a pair of supermodes by a\ncorrugated PhCR) and bidirectional frequency conversion. In this paper, we\ndemonstrate a high-quality PhCR on a hybrid silicon nitride-on-lithium\nniobate-on-insulator (SiN-on-LNOI) platform for the first time for\nvoltage-driven flexible frequency conversion using the electro-optic effect\n(0.85 pm/V). The fabricated PhCR has a large supermode splitting bandwidth =\n14.6 GHz and an intrinsic quality factor (Q) = 147,000. Using different\nperiodic corrugation amplitudes in the fabricated PhCRs enables the precise\ncontrol of mode splitting with a ratio of 93.5 MHz/nm between the mode\nsplitting bandwidth and the corrugation amplitude.","main_category":"physics.optics","categories":"physics.optics,physics.app-ph","published":"2025-05-01T17:36:41Z"}
{"aid":"http://arxiv.org/abs/2505.00683v1","title":"Quantum Circuit Overhead","summary":"We introduce a measure for evaluating the efficiency of finite universal\nquantum gate sets $\\mathcal{S}$, called the Quantum Circuit Overhead (QCO), and\nthe related notion of $T$-Quantum Circuit Overhead ($T$-QCO). The overhead is\nbased on the comparison between the efficiency of $\\mathcal{S}$ versus the\noptimal efficiency among all gate sets with the same number of gates. We\ndemonstrate the usefulness of the ($T$-)QCO by extensive numerical calculations\nof its upper bounds, providing insight into the efficiency of various choices\nof single-qubit $\\mathcal{S}$, including Haar-random gate sets and the gate\nsets derived from finite subgroups, such as Clifford and Hurwitz groups. In\nparticular, our results suggest that, in terms of the upper bounds on the\n$T$-QCO, the famous T gate is a highly non-optimal choice for the completion of\nthe Clifford gate set, even among the gates of order 8. We identify the optimal\nchoices of such completions for both finite subgroups.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.MP","published":"2025-05-01T17:43:33Z"}
{"aid":"http://arxiv.org/abs/2505.00692v1","title":"Multi-wavelength JWST observations of (3200) Phaethon show a dehydrated\n  object with an aqueously altered origin","summary":"We present JWST observations of the near-Earth asteroid (3200) Phaethon using\nthe Near-Infrared Camera (NIRCam), Near-Infrared Spectrograph (NIRSpec), and\nMid-Infrared Instrument (MIRI) to further investigate the composition of\nPhaethon's surface. Our NIRSpec data confirms that Phaethon's surface is\ndehydrated, showing no evidence of hydrated minerals in the 3-$\\mu$m region. We\nestimate an upper limit on the hydrogen content in phyllosilicates of 0.06 wt%.\nComparisons with laboratory spectra of carbonaceous chondrites suggest that\nPhaethon's surface composition is best matched by thermally metamorphosed\nsamples of the CM chondrite Murchison (heated to 1000$^{\\circ}$C), rather than\nCY meteorites as previous work suggested. We find no evidence of ongoing\nsurface evolution due to recent perihelion passages. A comparison of the\nmid-infrared spectra of Phaethon and Bennu shows distinct spectral differences\nthat are consistent with their different thermal histories. Our findings\nfurther refine our understanding of Phaethon's current surface composition and\nevolution and provide additional insights for the upcoming DESTINY+ mission.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-05-01T17:54:35Z"}
{"aid":"http://arxiv.org/abs/2505.03162v1","title":"Efficient and tunable frequency conversion using periodically poled\n  thin-film lithium tantalate nanowaveguides","summary":"Thin-film lithium tantalate (TFLT) has recently emerged as a promising\nphotonic platform for chip-scale nonlinear optics due to its weaker\nphotorefraction, higher optical damage threshold, broader transparency window,\nand lower birefringence compared to that of thin-film lithium niobate. Here we\ndevelop an ultralow-loss lithium tantalate integrated photonic platform and\nreport the first functional second harmonic generator based on high-fidelity\npoling of z-cut TFLT. As a result, quasi-phase matching (QPM) is performed\nbetween telecom (1550 nm) and near-visible (775 nm) wavelengths in a straight\nwaveguide and prompts strong second-harmonic generation with a normalized\nefficiency of 229 %/W/$cm^2$. An absolute conversion efficiency of 5.5 % is\nachieved with a pump power of 700 mW. Such a second-harmonic generator exhibits\nstable temperature tunability (-0.44 nm/$^\\circ C$) which is important for\napplications that require precise frequency alignment such as atomic clocks and\nquantum frequency conversion.","main_category":"physics.optics","categories":"physics.optics","published":"2025-05-06T04:14:26Z"}
{"aid":"http://arxiv.org/abs/2505.03183v1","title":"The Physical Nature of the Off-centered Extended Emission Associated\n  with the Little Red Dots","summary":"A significant fraction of little red dots (LRDs) exhibit nearby extended\nemission of unknown origin. If physically associated with the LRD, this\ncomponent may trace stellar emission from an off-centered host galaxy,\nneighboring companions, or nebular gas illuminated by the active nucleus. We\ninvestigate the detailed spectral energy distribution of the extended emission\nnear four LRDs in the JWST UNCOVER and MegaScience surveys. We accurately\ndecompose the extended emission from the dominant point source by\nsimultaneously fitting the images in eight broad-band and nine medium-band\nfilters. After considering both the results from photometric redshift fitting\nand the probability of galaxies at different redshift overlapping, we confirm\nthat the off-centered blobs in three sources are physically associated with the\nLRDs, with two of them showing strong [\\ion{O}{3}] $\\lambda\\lambda 4959,\\,5007$\nemission captured by the medium-band filters. While the spectral energy\ndistributions of all three blobs can be modeled assuming star-forming galaxies\nwith stellar mass $\\sim 10^8\\,M_{\\odot}$, the exceptionally strong [\\ion{O}{3}]\nemission of two sources is best interpreted as pure nebular emission from\nlow-density ($n<10\\, {\\rm cm}^{-3}$), low-metallicity ($Z\\approx\n0.05\\,Z_{\\odot}$) gas photoionized by the ultraviolet radiation from the nearby\nLRD. Adopting LRD halo masses constrained by clustering measurements and\ntheoretical considerations, we estimate a typical baryonic halo mass accretion\nrate of $\\sim 2-9\\, M_{\\odot}\\,{\\rm yr}^{-1}$. If the halo accretion rate is\nsustained to $z=4$ and stars form with an efficiency of 10\\%, the accreted gas\nwould form a galaxy with stellar mass $\\sim 10^9\\,M_{\\odot}$, potentially\nrendering them spatially resolved at lower redshift.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-05-06T04:59:23Z"}
{"aid":"http://arxiv.org/abs/2505.03195v1","title":"QiMeng-CPU-v2: Automated Superscalar Processor Design by Learning Data\n  Dependencies","summary":"Automated processor design, which can significantly reduce human efforts and\naccelerate design cycles, has received considerable attention. While recent\nadvancements have automatically designed single-cycle processors that execute\none instruction per cycle, their performance cannot compete with modern\nsuperscalar processors that execute multiple instructions per cycle. Previous\nmethods fail on superscalar processor design because they cannot address\ninter-instruction data dependencies, leading to inefficient sequential\ninstruction execution.\n  This paper proposes a novel approach to automatically designing superscalar\nprocessors using a hardware-friendly model called the Stateful Binary\nSpeculation Diagram (State-BSD). We observe that processor parallelism can be\nenhanced through on-the-fly inter-instruction dependent data predictors,\nreusing the processor's internal states to learn the data dependency. To meet\nthe challenge of both hardware-resource limitation and design functional\ncorrectness, State-BSD consists of two components: 1) a lightweight\nstate-selector trained by the simulated annealing method to detect the most\nreusable processor states and store them in a small buffer; and 2) a highly\nprecise state-speculator trained by the BSD expansion method to predict the\ninter-instruction dependent data using the selected states. It is the first\nwork to achieve the automated superscalar processor design, i.e. QiMeng-CPU-v2,\nwhich improves the performance by about $380\\times$ than the state-of-the-art\nautomated design and is comparable to human-designed superscalar processors\nsuch as ARM Cortex A53.","main_category":"cs.AR","categories":"cs.AR","published":"2025-05-06T05:32:34Z"}
{"aid":"http://arxiv.org/abs/2505.03196v1","title":"A Trustworthy Multi-LLM Network: Challenges,Solutions, and A Use Case","summary":"Large Language Models (LLMs) demonstrate strong potential across a variety of\ntasks in communications and networking due to their advanced reasoning\ncapabilities. However, because different LLMs have different model structures\nand are trained using distinct corpora and methods, they may offer varying\noptimization strategies for the same network issues. Moreover, the limitations\nof an individual LLM's training data, aggravated by the potential maliciousness\nof its hosting device, can result in responses with low confidence or even\nbias. To address these challenges, we propose a blockchain-enabled\ncollaborative framework that connects multiple LLMs into a Trustworthy\nMulti-LLM Network (MultiLLMN). This architecture enables the cooperative\nevaluation and selection of the most reliable and high-quality responses to\ncomplex network optimization problems. Specifically, we begin by reviewing\nrelated work and highlighting the limitations of existing LLMs in collaboration\nand trust, emphasizing the need for trustworthiness in LLM-based systems. We\nthen introduce the workflow and design of the proposed Trustworthy MultiLLMN\nframework. Given the severity of False Base Station (FBS) attacks in B5G and 6G\ncommunication systems and the difficulty of addressing such threats through\ntraditional modeling techniques, we present FBS defense as a case study to\nempirically validate the effectiveness of our approach. Finally, we outline\npromising future research directions in this emerging area.","main_category":"cs.NI","categories":"cs.NI,cs.AI","published":"2025-05-06T05:32:46Z"}
{"aid":"http://arxiv.org/abs/2505.03245v1","title":"On the Hessian Hardy-Sobolev Inequality and Related Variational Problems","summary":"In this paper, we first prove the Hardy-Sobolev inequality for the Hessian\nintegral by means of a descent gradient flow of certain Hessian functionals. As\nan application, we study the existence and regularity results of solutions to\nrelated variational problems. Our results extend the variational theory of the\nHessian equation in \\cite{CW01variational}.","main_category":"math.AP","categories":"math.AP","published":"2025-05-06T07:15:30Z"}
{"aid":"http://arxiv.org/abs/2505.03272v1","title":"Tailoring ultra-high-order optical skyrmions","summary":"Skyrmions, as quasiparticles with topological spin textures, has recently\ngarnered great attention for both condensed matter and structured wave\ncommunities, promising next-generation large-density robust information\ntechnologies. However, a big challenge to this end is that the generation of\nhigh-order skyrmions is elusive in any physical systems. Here, we propose the\nmethod to create and control ultra-high-order skyrmions (skyrmion number up to\n$400^{th}$) in a structured light system. We also experimentally control the\ntopological state transition between bimeron and skyrmion, arbitrarily tailor\nthe transverse size of an arbitrary-order skyrmionic beam independent of\ntopological number, and ensure the topological stability upon propagation. Our\nwork offers solutions for topologically resilient communication and memory with\nmuch enhanced information capacity.","main_category":"physics.optics","categories":"physics.optics","published":"2025-05-06T08:03:29Z"}
{"aid":"http://arxiv.org/abs/2505.03307v1","title":"Qimax: Efficient quantum simulation via GPU-accelerated extended\n  stabilizer formalism","summary":"Simulating Clifford and near-Clifford circuits using the extended stabilizer\nformalism has become increasingly popular, particularly in quantum error\ncorrection. Compared to the state-vector approach, the extended stabilizer\nformalism can solve the same problems with fewer computational resources, as it\noperates on stabilizers rather than full state vectors. Most existing studies\non near-Clifford circuits focus on balancing the trade-off between the number\nof ancilla qubits and simulation accuracy, often overlooking performance\nconsiderations. Furthermore, in the presence of high-rank stabilizers,\nperformance is limited by the sequential property of the stabilizer formalism.\nIn this work, we introduce a parallelized version of the extended stabilizer\nformalism, enabling efficient execution on multi-core devices such as GPU.\nExperimental results demonstrate that, in certain scenarios, our Python-based\nimplementation outperforms state-of-the-art simulators such as Qiskit and\nPennylane.","main_category":"quant-ph","categories":"quant-ph,cs.SE","published":"2025-05-06T08:41:28Z"}
{"aid":"http://arxiv.org/abs/2505.03326v1","title":"Decoding the cosmological baryonic fluctuations using localized fast\n  radio bursts","summary":"Aims: The enigma of the missing baryons poses a prominent and unresolved\nproblem in astronomy. Dispersion measures (DM) serve as a distinctive\nobservable of fast radio bursts (FRBs). They quantify the electron column\ndensity along each line of sight and reveal the missing baryons that are\ndescribed in the Macquart (DM-z) relation. The scatter of this relation is\nanticipated to be caused by the variation in the cosmic structure. This is not\nyet statistically confirmed, however. We present statistical evidence that the\ncosmological baryons fluctuate. Methods: We measured the foreground galaxy\nnumber densities around 14 and 13 localized FRBs with the WISE-PS1-STRM and\nWISE x SCOS photometric redshift galaxy catalog, respectively. The foreground\ngalaxy number densities were determined through a comparison with measured\nrandom apertures with a radius of 1 Mpc. Results: We found a positive\ncorrelation between the excess of DM that is contributed by the medium outside\ngalaxies (DM_cosmic) and the foreground galaxy number density. The correlation\nis strong and statistically significant, with median Pearson coefficients of\n0.6 and 0.6 and median p-values of 0.012 and 0.032 for the galaxy catalogs,\nrespectively, as calculated with Monte Carlo simulations. Conclusions: Our\nfindings indicate that the baryonic matter density outside galaxies exceeds its\ncosmic average along the line of sight to regions with an excess galaxy\ndensity, but there are fewer baryons along the line of sight to low-density\nregions. This is statistical evidence that the ionized baryons fluctuate\ncosmologically on a characteristic scale of $\\lesssim$6 Mpc.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.GA,astro-ph.HE","published":"2025-05-06T08:54:19Z"}
{"aid":"http://arxiv.org/abs/2505.03328v1","title":"Learning by exporting with a dose-response function","summary":"This paper investigates the causal effect of export intensity on productivity\nand other firm-level outcomes with a dose-response function. After positing\nthat export intensity acts as a continuous treatment, we investigate\ncounterfactual productivity levels in a quasi-experimental setting. For our\npurpose, we exploit a control group of non-temporary exporters that have\nalready sustained the fixed costs of reaching foreign markets, thus controlling\nfor self-selection into exporting. Our findings reveal a non-linear\nrelationship between export intensity and productivity, with small albeit\nstatistically significant benefits ranging from 0.1% to 0.6% per year only\nafter exports reach 60% of total revenues. After we look at sales, variable\ncosts, capital intensity, and the propensity to filing patents, we show that,\nbefore the 60% threshold, economies of scale and capital adjustment offset each\nother and induce, on average, a minimal albeit statistically significant loss\nin productivity of about 0.01% per year. Crucially, we find that heterogeneous\nexport intensity is associated with the firm's position on the technological\nfrontier, as the propensity to file a patent increases when export intensity\nranges in 8%-60% with a peak at 40%. The latest finding further highlights that\nlearning-by-exporting is linked to the building of absorptive capacity.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-05-06T08:56:09Z"}
{"aid":"http://arxiv.org/abs/2505.03350v1","title":"A Vision-Language Model for Focal Liver Lesion Classification","summary":"Accurate classification of focal liver lesions is crucial for diagnosis and\ntreatment in hepatology. However, traditional supervised deep learning models\ndepend on large-scale annotated datasets, which are often limited in medical\nimaging. Recently, Vision-Language models (VLMs) such as Contrastive\nLanguage-Image Pre-training model (CLIP) has been applied to image\nclassifications. Compared to the conventional convolutional neural network\n(CNN), which classifiers image based on visual information only, VLM leverages\nmultimodal learning with text and images, allowing it to learn effectively even\nwith a limited amount of labeled data. Inspired by CLIP, we pro-pose a\nLiver-VLM, a model specifically designed for focal liver lesions (FLLs)\nclassification. First, Liver-VLM incorporates class information into the text\nencoder without introducing additional inference overhead. Second, by\ncalculating the pairwise cosine similarities between image and text embeddings\nand optimizing the model with a cross-entropy loss, Liver-VLM ef-fectively\naligns image features with class-level text features. Experimental results on\nMPCT-FLLs dataset demonstrate that the Liver-VLM model out-performs both the\nstandard CLIP and MedCLIP models in terms of accuracy and Area Under the Curve\n(AUC). Further analysis shows that using a lightweight ResNet18 backbone\nenhances classification performance, particularly under data-constrained\nconditions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-06T09:19:12Z"}
{"aid":"http://arxiv.org/abs/2505.03366v1","title":"Relativistic dissipative hydrodynamics for particles of arbitrary mass","summary":"Employing a kinetic framework, we calculate all transport coefficients for\nrelativistic dissipative (second-order) hydrodynamics for arbitrary particle\nmasses in the 14-moment approximation. Taking the non-relativistic limit, it is\nshown that the relativistic theory reduces to the Grad equations computed in\nthe 'order-of-magnitude' approach.","main_category":"nucl-th","categories":"nucl-th","published":"2025-05-06T09:38:51Z"}
{"aid":"http://arxiv.org/abs/2505.03375v1","title":"Efficient Wi-Fi Sensing for IoT Forensics with Lossy Compression of CSI\n  Data","summary":"Wi-Fi sensing is an emerging technology that uses channel state information\n(CSI) from ambient Wi-Fi signals to monitor human activity without the need for\ndedicated sensors. Wi-Fi sensing does not only represent a pivotal technology\nin intelligent Internet of Things (IoT) systems, but it can also provide\nvaluable insights in forensic investigations. However, the high dimensionality\nof CSI data presents major challenges for storage, transmission, and processing\nin resource-constrained IoT environments. In this paper, we investigate the\nimpact of lossy compression on the accuracy of Wi-Fi sensing, evaluating both\ntraditional techniques and a deep learning-based approach. Our results reveal\nthat simple, interpretable techniques based on principal component analysis can\nsignificantly reduce the CSI data volume while preserving classification\nperformance, making them highly suitable for lightweight IoT forensic\nscenarios. On the other hand, deep learning models exhibit higher potential in\ncomplex applications like activity recognition (achieving compression ratios up\nto 16000:1 with minimal impact on sensing performance) but require careful\ntuning and greater computational resources. By considering two different\nsensing applications, this work demonstrates the feasibility of integrating\nlossy compression schemes into Wi-Fi sensing pipelines to make intelligent IoT\nsystems more efficient and improve the storage requirements in forensic\napplications.","main_category":"cs.NI","categories":"cs.NI","published":"2025-05-06T09:51:48Z"}
{"aid":"http://arxiv.org/abs/2505.03392v1","title":"Automatic Calibration for Membership Inference Attack on Large Language\n  Models","summary":"Membership Inference Attacks (MIAs) have recently been employed to determine\nwhether a specific text was part of the pre-training data of Large Language\nModels (LLMs). However, existing methods often misinfer non-members as members,\nleading to a high false positive rate, or depend on additional reference models\nfor probability calibration, which limits their practicality. To overcome these\nchallenges, we introduce a novel framework called Automatic Calibration\nMembership Inference Attack (ACMIA), which utilizes a tunable temperature to\ncalibrate output probabilities effectively. This approach is inspired by our\ntheoretical insights into maximum likelihood estimation during the pre-training\nof LLMs. We introduce ACMIA in three configurations designed to accommodate\ndifferent levels of model access and increase the probability gap between\nmembers and non-members, improving the reliability and robustness of membership\ninference. Extensive experiments on various open-source LLMs demonstrate that\nour proposed attack is highly effective, robust, and generalizable, surpassing\nstate-of-the-art baselines across three widely used benchmarks. Our code is\navailable at:\n\\href{https://github.com/Salehzz/ACMIA}{\\textcolor{blue}{Github}}.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-05-06T10:15:05Z"}
{"aid":"http://arxiv.org/abs/2505.03410v1","title":"Lie conformal superalgebras of rank (2 + 1)","summary":"In this paper, Lie conformal superalgebras of rank (2 + 1) are completely\nclassified (up to isomorphism) and their automorphism groups are determined.\nFurthermore, we give the classification of the finite irreducible conformal\nmodules over them and the actions are explicitly described.","main_category":"math.RA","categories":"math.RA","published":"2025-05-06T10:36:11Z"}
{"aid":"http://arxiv.org/abs/2505.03476v1","title":"$L^p$- Partially null controllability of abstract fractional\n  differential inclusion with nonlocal condition","summary":"In this work, we investigate the $L^p$- partial null controllability of the\nabstract semilinear fractional-order differential inclusion with nonlocal\nconditions. The set of admissible controls is characterized by $u\\in L^p(I,U)$,\n$1<p<\\infty$, $I=[0,\\nu]$, where $U$ is a uniformly convex Banach space.\nAssuming partial null controllability for the fractional-order linear system\nwith a source term, we employ an approximate solvability method to simplify the\nproblem to reduce it to finite-dimensional subspaces. Consequently, the\nsolutions of the original problem are obtained as limiting functions within\nthese subspaces. The paper tackles a challenge stemming from the assumption\nthat $U$ is a uniformly convex Banach space, which introduces convexity issues\nin constructing the required control. These complications do not occur if $U$\nis a separable Hilbert space. This study introduces a novel approach by\nresolving the convexity issue, thereby enabling $L^p(I, U)$ partially null\ncontrollability of the semilinear fractional-order differential control system,\nwith $U$ being a uniformly convex Banach space.","main_category":"math.OC","categories":"math.OC,math.CA","published":"2025-05-06T12:29:17Z"}
{"aid":"http://arxiv.org/abs/2505.03510v1","title":"From Neurons to Computation: Biological Reservoir Computing for Pattern\n  Recognition","summary":"In this paper, we introduce a novel paradigm for reservoir computing (RC)\nthat leverages a pool of cultured biological neurons as the reservoir\nsubstrate, creating a biological reservoir computing (BRC). This system\noperates similarly to an echo state network (ESN), with the key distinction\nthat the neural activity is generated by a network of cultured neurons, rather\nthan being modeled by traditional artificial computational units. The neuronal\nactivity is recorded using a multi-electrode array (MEA), which enables\nhigh-throughput recording of neural signals. In our approach, inputs are\nintroduced into the network through a subset of the MEA electrodes, while the\nremaining electrodes capture the resulting neural activity. This generates a\nnonlinear mapping of the input data to a high-dimensional biological feature\nspace, where distinguishing between data becomes more efficient and\nstraightforward, allowing a simple linear classifier to perform pattern\nrecognition tasks effectively. To evaluate the performance of our proposed\nsystem, we present an experimental study that includes various input patterns,\nsuch as positional codes, bars with different orientations, and a digit\nrecognition task. The results demonstrate the feasibility of using biological\nneural networks to perform tasks traditionally handled by artificial neural\nnetworks, paving the way for further exploration of biologically-inspired\ncomputing systems, with potential applications in neuromorphic engineering and\nbio-hybrid computing.","main_category":"cs.NE","categories":"cs.NE,cs.AI,cs.CV","published":"2025-05-06T13:20:04Z"}
{"aid":"http://arxiv.org/abs/2505.03538v1","title":"RAIL: Region-Aware Instructive Learning for Semi-Supervised Tooth\n  Segmentation in CBCT","summary":"Semi-supervised learning has become a compelling approach for 3D tooth\nsegmentation from CBCT scans, where labeled data is minimal. However, existing\nmethods still face two persistent challenges: limited corrective supervision in\nstructurally ambiguous or mislabeled regions during supervised training and\nperformance degradation caused by unreliable pseudo-labels on unlabeled data.\nTo address these problems, we propose Region-Aware Instructive Learning (RAIL),\na dual-group dual-student, semi-supervised framework. Each group contains two\nstudent models guided by a shared teacher network. By alternating training\nbetween the two groups, RAIL promotes intergroup knowledge transfer and\ncollaborative region-aware instruction while reducing overfitting to the\ncharacteristics of any single model. Specifically, RAIL introduces two\ninstructive mechanisms. Disagreement-Focused Supervision (DFS) Controller\nimproves supervised learning by instructing predictions only within areas where\nstudent outputs diverge from both ground truth and the best student, thereby\nconcentrating supervision on structurally ambiguous or mislabeled areas. In the\nunsupervised phase, Confidence-Aware Learning (CAL) Modulator reinforces\nagreement in regions with high model certainty while reducing the effect of\nlow-confidence predictions during training. This helps prevent our model from\nlearning unstable patterns and improves the overall reliability of\npseudo-labels. Extensive experiments on four CBCT tooth segmentation datasets\nshow that RAIL surpasses state-of-the-art methods under limited annotation. Our\ncode will be available at https://github.com/Tournesol-Saturday/RAIL.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-06T13:50:57Z"}
{"aid":"http://arxiv.org/abs/2505.03541v1","title":"Defect analysis of the $β$- to $γ$-Ga$_{2}$O$_{3}$ phase\n  transition","summary":"In this study, we investigate the ion-irradiation-induced phase transition in\ngallium oxide (Ga2O3) from the $\\beta$ to the $\\gamma$ phase, the role of\ndefects during the transformation, and the quality of the resulting crystal\nstructure. Using a multi-method analysis approach including X-ray diffraction\n(XRD), transmission electron microscopy (TEM), Rutherford backscattering\nspectrometry in channeling mode (RBS/c), Doppler broadening variable energy\npositron annihilation spectroscopy (DB-VEPAS) and variable energy positron\nannihilation lifetime spectroscopy (VEPALS) supported by density functional\ntheory (DFT) calculations, we have characterized defects at all the relevant\nstages before, during, and after the phase transition. Reduction in\nbackscattering yield was observed in RBS/c spectra after the transition to the\n$\\gamma$ phase. This is corroborated by a significant decrease in the positron\ntrapping center density due to generation of embedded vacancies intrinsic for\nthe $\\gamma$-Ga2O3 but too shallow in order to trap positrons. A comparison of\nthe observed positron lifetime of $\\gamma$-Ga2O3 with different theoretical\nmodels shows good agreement with the three-site $\\gamma$ phase approach. A\ncharacteristic increase in the effective positron diffusion length and the\npositron lifetime at the transition point from $\\beta$-Ga2O3 to $\\gamma$-Ga2O3\nenables visualization of the phase transition with positrons for the first\ntime. Moreover, a subsequent reduction of these quantities with increasing\nirradiation fluence was observed, which we attribute to further evolution of\nthe $\\gamma$-Ga2O3 and changes in the gallium vacancy density as well as\nrelative occupation in the crystal lattice.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-05-06T13:52:17Z"}
{"aid":"http://arxiv.org/abs/2505.03554v1","title":"Read My Ears! Horse Ear Movement Detection for Equine Affective State\n  Assessment","summary":"The Equine Facial Action Coding System (EquiFACS) enables the systematic\nannotation of facial movements through distinct Action Units (AUs). It serves\nas a crucial tool for assessing affective states in horses by identifying\nsubtle facial expressions associated with discomfort. However, the field of\nhorse affective state assessment is constrained by the scarcity of annotated\ndata, as manually labelling facial AUs is both time-consuming and costly. To\naddress this challenge, automated annotation systems are essential for\nleveraging existing datasets and improving affective states detection tools. In\nthis work, we study different methods for specific ear AU detection and\nlocalization from horse videos. We leverage past works on deep learning-based\nvideo feature extraction combined with recurrent neural networks for the video\nclassification task, as well as a classic optical flow based approach. We\nachieve 87.5% classification accuracy of ear movement presence on a public\nhorse video dataset, demonstrating the potential of our approach. We discuss\nfuture directions to develop these systems, with the aim of bridging the gap\nbetween automated AU detection and practical applications in equine welfare and\nveterinary diagnostics. Our code will be made publicly available at\nhttps://github.com/jmalves5/read-my-ears.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-06T14:05:49Z"}
{"aid":"http://arxiv.org/abs/2505.03570v1","title":"OSUniverse: Benchmark for Multimodal GUI-navigation AI Agents","summary":"In this paper, we introduce OSUniverse: a benchmark of complex, multimodal\ndesktop-oriented tasks for advanced GUI-navigation AI agents that focuses on\nease of use, extensibility, comprehensive coverage of test cases, and automated\nvalidation. We divide the tasks in increasing levels of complexity, from basic\nprecision clicking to multistep, multiapplication tests requiring dexterity,\nprecision, and clear thinking from the agent. In version one of the benchmark,\npresented here, we have calibrated the complexity of the benchmark test cases\nto ensure that the SOTA (State of the Art) agents (at the time of publication)\ndo not achieve results higher than 50%, while the average white collar worker\ncan perform all these tasks with perfect accuracy. The benchmark can be scored\nmanually, but we also introduce an automated validation mechanism that has an\naverage error rate less than 2%. Therefore, this benchmark presents solid\nground for fully automated measuring of progress, capabilities and the\neffectiveness of GUI-navigation AI agents over the short and medium-term\nhorizon. The source code of the benchmark is available at\nhttps://github.com/agentsea/osuniverse.","main_category":"cs.AI","categories":"cs.AI","published":"2025-05-06T14:29:47Z"}
{"aid":"http://arxiv.org/abs/2505.03617v1","title":"Understand the Effect of Importance Weighting in Deep Learning on\n  Dataset Shift","summary":"We evaluate the effectiveness of importance weighting in deep neural networks\nunder label shift and covariate shift. On synthetic 2D data (linearly separable\nand moon-shaped) using logistic regression and MLPs, we observe that weighting\nstrongly affects decision boundaries early in training but fades with prolonged\noptimization. On CIFAR-10 with various class imbalances, only L2 regularization\n(not dropout) helps preserve weighting effects. In a covariate-shift\nexperiment, importance weighting yields no significant performance gain,\nhighlighting challenges on complex data. Our results call into question the\npractical utility of importance weighting for real-world distribution shifts.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-06T15:16:38Z"}
{"aid":"http://arxiv.org/abs/2505.03618v1","title":"Scalable Class-Centric Visual Interactive Labeling","summary":"Large unlabeled datasets demand efficient and scalable data labeling\nsolutions, in particular when the number of instances and classes is large.\nThis leads to significant visual scalability challenges and imposes a high\ncognitive load on the users. Traditional instance-centric labeling methods,\nwhere (single) instances are labeled in each iteration struggle to scale\neffectively in these scenarios. To address these challenges, we introduce cVIL,\na Class-Centric Visual Interactive Labeling methodology designed for\ninteractive visual data labeling. By shifting the paradigm from\nassigning-classes-to-instances to assigning-instances-to-classes, cVIL reduces\nlabeling effort and enhances efficiency for annotators working with large,\ncomplex and class-rich datasets. We propose a novel visual analytics labeling\ninterface built on top of the conceptual cVIL workflow, enabling improved\nscalability over traditional visual labeling. In a user study, we demonstrate\nthat cVIL can improve labeling efficiency and user satisfaction over\ninstance-centric interfaces. The effectiveness of cVIL is further demonstrated\nthrough a usage scenario, showcasing its potential to alleviate cognitive load\nand support experts in managing extensive labeling tasks efficiently.","main_category":"cs.HC","categories":"cs.HC","published":"2025-05-06T15:16:46Z"}
{"aid":"http://arxiv.org/abs/2505.03644v1","title":"Consequences of non-minimal coupling for mass mixing in spontaneous\n  baryogenesis","summary":"We investigate the impact of a non-minimal Yukawa-like coupling between\ncurvature and inflaton field within the \\emph{spontaneous baryogenesis}\nbackground. We demonstrate that this coupling leads to a significant\nenhancement in particle production, even for small values of the coupling\nconstant $\\xi$. Assuming a perfectly homogeneous and isotropic universe during\nthe reheating phase, we study the inflaton decay into fermion-antifermion pairs\nby means of a semiclassical approach, treating fermions as quantized fields and\nconsidering the inflaton and the Ricci scalar as classical quantities. We adopt\nthe simplest approach in which the inflaton is minimally coupled to baryons,\nand non-minimally with gravity. In particular, we solve the equations of motion\nfor the inflaton to first order in perturbation theory, with $\\xi$ serving as\nperturbative parameter. Afterwards, we compute the difference in the number\ndensities of baryons and antibaryons produced through the inflaton decay into\nfermion-antifermion pairs. We show that the non-minimal coupling term \\emph{de\nfacto} increases inflaton mass, letting fermion-antifermion decays be more\nprobable, and thus enhancing the overall baryogenesis process. As a further\noutcome, we find that the non-minimal Yukawa coupling also leads to a\nrenormalization of the inflaton mass and weakly influences the bounds over the\ngravitational constant. Finally, since the fermionic fields appear not to be\nmass eigenstates, we specialize the mass-mixing between them only. To this end,\nwe thus include the effects of mass-mixing and cosmic expansion into our\ncalculations. Physical consequences of baryon production are therefore\nexplored.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-th","published":"2025-05-06T15:51:13Z"}
{"aid":"http://arxiv.org/abs/2505.03659v1","title":"Meta-Learning the Optimal Mixture of Strategies for Online Portfolio\n  Selection","summary":"This paper presents an innovative online portfolio selection model, situated\nwithin a meta-learning framework, that leverages a mixture policies strategy.\nThe core idea is to simulate a fund that employs multiple fund managers, each\nskilled in handling different market environments, and dynamically allocate our\nfunding to these fund managers for investment. To address the non-stationary\nnature of financial markets, we divide the long-term process into multiple\nshort-term processes to adapt to changing environments. We use a clustering\nmethod to identify a set of historically high-performing policies,\ncharacterized by low similarity, as candidate policies. Additionally, we employ\na meta-learning method to search for initial parameters that can quickly adapt\nto upcoming target investment tasks, effectively providing a set of well-suited\ninitial strategies. Subsequently, we update the initial parameters using the\ntarget tasks and determine the optimal mixture weights for these candidate\npolicies. Empirical tests show that our algorithm excels in terms of training\ntime and data requirements, making it particularly suitable for high-frequency\nalgorithmic trading. To validate the effectiveness of our method, we conduct\nnumerical tests on cross-training datasets, demonstrating its excellent\ntransferability and robustness.","main_category":"math.OC","categories":"math.OC","published":"2025-05-06T16:05:03Z"}
{"aid":"http://arxiv.org/abs/2505.03713v1","title":"Large Topological Magnetic Optical Effects and Imaging of\n  Antiferromagnetic Octupole Domains of an Altermagnet-like Weyl Semimetal","summary":"Pyrochlore iridates have attracted significant interest due to their complex\nphase behavior arising from the interplay among electron correlations, quantum\nmetric in flat bands, geometrically frustrated lattices, and topology induced\nby strong spin-orbit coupling. In this study, we focus on Eu$_2$Ir$_2$O$_7$\nthin films oriented along the (111) crystallographic direction. This quantum\nmaterial, identified as an antiferromagnetic Weyl semimetal, exhibits a large\nanomalous Hall effect in transport experiments. Here we employ optical circular\ndichroism microscopy, to directly image ferroic octupole order and resolve\nall-in--all-out and all-out--all-in antiferromagnetic domains below the N\\'eel\ntemperature. Remarkably, despite the absence of a detectable net magnetic\nmoment at zero applied magnetic field, we detected a large magnetic circular\ndichroism signal ($\\sim 10^{-4}$) and Kerr effect ($\\sim 10^{-4}$ radians) in\nzero magnetic field attributable to Berry curvature effects from Weyl nodes.\nEu$_2$Ir$_2$O$_7$ is a non-collinear magnet with vanishing net moment and\nmagnetic octupole order, similar to the recently proposed collinear d-wave\naltermagnets, allowing for magneto-optical responses and anomalous Hall effect.\nThis finding likely represents the first demonstration of magnetic circular\ndichroism and Kerr effect in a topologically non-trivial quantum\nantiferromagnet with a vanishing net magnetization. Our work opens up the\npossibility of ultrafast domain switching in the terahertz frequency and the\ndomain wall dynamics in the magnetic Weyl systems, which establishes the\nfoundation for topological antiferromagnetic spintronics.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-05-06T17:36:17Z"}
{"aid":"http://arxiv.org/abs/2505.03717v1","title":"Nonnegative Low-rank Matrix Recovery Can Have Spurious Local Minima","summary":"The classical low-rank matrix recovery problem is well-known to exhibit\n\\emph{benign nonconvexity} under the restricted isometry property (RIP): local\noptimization is guaranteed to converge to the global optimum, where the ground\ntruth is recovered. We investigate whether benign nonconvexity continues to\nhold when the factor matrices are constrained to be elementwise nonnegative --\na common practical requirement. In the simple setting of a rank-1 nonnegative\nground truth, we confirm that benign nonconvexity holds in the fully-observed\ncase with RIP constant $\\delta=0$. Surprisingly, however, this property fails\nto extend to the partially-observed case with any arbitrarily small RIP\nconstant $\\delta\\to0^{+}$, irrespective of rank overparameterization. This\nfinding exposes a critical theoretical gap: the continuity argument widely used\nto explain the empirical robustness of low-rank matrix recovery fundamentally\nbreaks down once nonnegative constraints are imposed.","main_category":"math.OC","categories":"math.OC,cs.LG,stat.ML","published":"2025-05-06T17:43:35Z"}
{"aid":"http://arxiv.org/abs/2505.03728v1","title":"PyRoki: A Modular Toolkit for Robot Kinematic Optimization","summary":"Robot motion can have many goals. Depending on the task, we might optimize\nfor pose error, speed, collision, or similarity to a human demonstration.\nMotivated by this, we present PyRoki: a modular, extensible, and cross-platform\ntoolkit for solving kinematic optimization problems. PyRoki couples an\ninterface for specifying kinematic variables and costs with an efficient\nnonlinear least squares optimizer. Unlike existing tools, it is also\ncross-platform: optimization runs natively on CPU, GPU, and TPU. In this paper,\nwe present (i) the design and implementation of PyRoki, (ii) motion retargeting\nand planning case studies that highlight the advantages of PyRoki's modularity,\nand (iii) optimization benchmarking, where PyRoki can be 1.4-1.7x faster and\nconverges to lower errors than cuRobo, an existing GPU-accelerated inverse\nkinematics library.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-06T17:56:40Z"}
{"aid":"http://arxiv.org/abs/2505.03733v1","title":"WebGen-Bench: Evaluating LLMs on Generating Interactive and Functional\n  Websites from Scratch","summary":"LLM-based agents have demonstrated great potential in generating and managing\ncode within complex codebases. In this paper, we introduce WebGen-Bench, a\nnovel benchmark designed to measure an LLM-based agent's ability to create\nmulti-file website codebases from scratch. It contains diverse instructions for\nwebsite generation, created through the combined efforts of human annotators\nand GPT-4o. These instructions span three major categories and thirteen minor\ncategories, encompassing nearly all important types of web applications. To\nassess the quality of the generated websites, we use GPT-4o to generate test\ncases targeting each functionality described in the instructions, and then\nmanually filter, adjust, and organize them to ensure accuracy, resulting in 647\ntest cases. Each test case specifies an operation to be performed on the\nwebsite and the expected result after the operation. To automate testing and\nimprove reproducibility, we employ a powerful web-navigation agent to execute\ntests on the generated websites and determine whether the observed responses\nalign with the expected results. We evaluate three high-performance code-agent\nframeworks, Bolt.diy, OpenHands, and Aider, using multiple proprietary and\nopen-source LLMs as engines. The best-performing combination, Bolt.diy powered\nby DeepSeek-R1, achieves only 27.8\\% accuracy on the test cases, highlighting\nthe challenging nature of our benchmark. Additionally, we construct\nWebGen-Instruct, a training set consisting of 6,667 website-generation\ninstructions. Training Qwen2.5-Coder-32B-Instruct on Bolt.diy trajectories\ngenerated from a subset of this training set achieves an accuracy of 38.2\\%,\nsurpassing the performance of the best proprietary model.","main_category":"cs.CL","categories":"cs.CL","published":"2025-05-06T17:59:15Z"}
{"aid":"http://arxiv.org/abs/2505.03735v1","title":"Multi-Agent System for Comprehensive Soccer Understanding","summary":"Recent advancements in AI-driven soccer understanding have demonstrated rapid\nprogress, yet existing research predominantly focuses on isolated or narrow\ntasks. To bridge this gap, we propose a comprehensive framework for holistic\nsoccer understanding. Specifically, we make the following contributions in this\npaper: (i) we construct SoccerWiki, the first large-scale multimodal soccer\nknowledge base, integrating rich domain knowledge about players, teams,\nreferees, and venues to enable knowledge-driven reasoning; (ii) we present\nSoccerBench, the largest and most comprehensive soccer-specific benchmark,\nfeaturing around 10K standardized multimodal (text, image, video) multi-choice\nQA pairs across 13 distinct understanding tasks, curated through automated\npipelines and manual verification; (iii) we introduce SoccerAgent, a novel\nmulti-agent system that decomposes complex soccer questions via collaborative\nreasoning, leveraging domain expertise from SoccerWiki and achieving robust\nperformance; (iv) extensive evaluations and ablations that benchmark\nstate-of-the-art MLLMs on SoccerBench, highlighting the superiority of our\nproposed agentic system. All data and code are publicly available at:\nhttps://jyrao.github.io/SoccerAgent/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-06T17:59:31Z"}
{"aid":"http://arxiv.org/abs/2505.04093v1","title":"Neutrino-jet correlations in charged-current SIDIS","summary":"Charged-current deep inelastic scattering plays a significant role in\ndetermining parton distribution functions with flavour separation. In this\nwork, we present a systematic calculation of the charged-current semi-inclusive\ndeep inelastic scattering (SIDIS) in the $eN$ collinear frame up to twist-3\nlevel at leading order. Semi-inclusive refers to the process in which a jet is\ndetected in addition to the scattered neutrino. We focus on neutrino-jet\ncorrelations in our calculation. We first present the differential cross\nsection in terms of structure functions, followed by the differential cross\nsection expressed in term of transverse momentum dependent parton distribution\nfunctions. We derive the complete set of azimuthal asymmetries and intrinsic\nasymmetries. We also introduce an observable $A^C$, defined as the ratio of the\ndifference to the sum of differential cross sections for electron and positron\nsemi-inclusive deep inelastic scattering. We notice that $A^C$ not only\nprovides a sensitive probe for valence quark distribution functions but also\ncan reveal the violation of strange-antistrange symmetry.","main_category":"hep-ph","categories":"hep-ph","published":"2025-05-07T03:15:28Z"}
{"aid":"http://arxiv.org/abs/2505.04123v1","title":"A Framework to Prevent Biometric Data Leakage in the Immersive\n  Technologies Domain","summary":"Doubtlessly, the immersive technologies have potential to ease people's life\nand uplift economy, however the obvious data privacy risks cannot be ignored.\nFor example, a participant wears a 3D headset device which detects\nparticipant's head motion to track the pose of participant's head to match the\norientation of camera with participant's eyes positions in the real-world. In a\npreliminary study, researchers have proved that the voice command features on\nsuch headsets could lead to major privacy leakages. By analyzing the facial\ndynamics captured with the motion sensors, the headsets suffer security\nvulnerabilities revealing a user's sensitive speech without user's consent. The\npsychography data (such as voice command features, facial dynamics, etc.) is\nsensitive data and it should not be leaked out of the device without users\nconsent else it is a privacy breach. To the best of our literature review, the\nwork done in this particular research problem is very limited. Motivated from\nthis, we develop a simple technical framework to mitigate sensitive data (or\nbiometric data) privacy leaks in immersive technology domain. The performance\nevaluation is conducted in a robust way using six data sets, to show that the\nproposed solution is effective and feasible to prevent this issue.","main_category":"cs.CR","categories":"cs.CR","published":"2025-05-07T04:35:32Z"}
{"aid":"http://arxiv.org/abs/2505.04190v1","title":"The stability of generalized phase retrieval problem over compact groups","summary":"The generalized phase retrieval problem over compact groups aims to recover a\nset of matrices, representing an unknown signal, from their associated Gram\nmatrices, leveraging prior structural knowledge about the signal. This\nframework generalizes the classical phase retrieval problem, which reconstructs\na signal from the magnitudes of its Fourier transform, to a richer setting\ninvolving non-abelian compact groups. In this broader context, the unknown\nphases in Fourier space are replaced by unknown orthogonal matrices that arise\nfrom the action of a compact group on a finite-dimensional vector space. This\nproblem is primarily motivated by advances in electron microscopy to\ndetermining the 3D structure of biological macromolecules from highly noisy\nobservations. To capture realistic assumptions from machine learning and signal\nprocessing, we model the signal as belonging to one of several broad structural\nfamilies: a generic linear subspace, a sparse representation in a generic\nbasis, the output of a generic ReLU neural network, or a generic\nlow-dimensional manifold. Our main result shows that, under mild conditions,\nthe generalized phase retrieval problem not only admits a unique solution (up\nto inherent group symmetries), but also satisfies a bi-Lipschitz property. This\nimplies robustness to both noise and model mismatch, an essential requirement\nfor practical use, especially when measurements are severely corrupted by\nnoise. These findings provide theoretical support for a wide class of\nscientific problems under modern structural assumptions, and they offer strong\nfoundations for developing robust algorithms in high-noise regimes.","main_category":"eess.SP","categories":"eess.SP,cs.IT,math.IT","published":"2025-05-07T07:39:46Z"}
{"aid":"http://arxiv.org/abs/2505.04191v1","title":"Heisenberg Uncertainty Inequality and Breaking of Isospin Symmetry in\n  Atomic Nuclei","summary":"The Heisenberg uncertainty inequality is used to derive a rigorous lower\nbound to the amount of isospin impurities, caused by the violation of isospin\nsymmetry in $N=Z$ atomic nuclei, in terms of the difference between the neutron\nand proton radii and the sum of the charge exchange monopole strengths. We show\nthat the inequality reduces to an identity if one employs a simplified mean\nfield expression for the isovector component of the Coulomb force in first\norder perturbation theory. The uncertainty inequality is also employed to\nderive an upper bound to the isovector dipole moment in terms of the amount of\nisospin impurities, thereby providing an insightful connection between the\nviolation of parity and isospin symmetries.","main_category":"nucl-th","categories":"nucl-th,hep-ex,hep-th,nucl-ex","published":"2025-05-07T07:40:43Z"}
{"aid":"http://arxiv.org/abs/2505.04195v1","title":"AutoPatch: Multi-Agent Framework for Patching Real-World CVE\n  Vulnerabilities","summary":"Large Language Models (LLMs) have emerged as promising tools in software\ndevelopment, enabling automated code generation and analysis. However, their\nknowledge is limited to a fixed cutoff date, making them prone to generating\ncode vulnerable to newly disclosed CVEs. Frequent fine-tuning with new CVE sets\nis costly, and existing LLM-based approaches focus on oversimplified CWE\nexamples and require providing explicit bug locations to LLMs, limiting their\nability to patch complex real-world vulnerabilities. To address these\nlimitations, we propose AutoPatch, a multi-agent framework designed to patch\nvulnerable LLM-generated code, particularly those introduced after the LLMs'\nknowledge cutoff. AutoPatch integrates Retrieval-Augmented Generation (RAG)\nwith a structured database of recently disclosed vulnerabilities, comprising\n525 code snippets derived from 75 high-severity CVEs across real-world systems\nsuch as the Linux kernel and Chrome. AutoPatch combines semantic and taint\nanalysis to identify the most relevant CVE and leverages enhanced\nChain-of-Thought (CoT) reasoning to construct enriched prompts for verification\nand patching. Our unified similarity model, which selects the most relevant\nvulnerabilities, achieves 90.4 percent accuracy in CVE matching. AutoPatch\nattains 89.5 percent F1-score for vulnerability verification and 95.0 percent\naccuracy in patching, while being over 50x more cost-efficient than traditional\nfine-tuning approaches.","main_category":"cs.CR","categories":"cs.CR","published":"2025-05-07T07:49:05Z"}
{"aid":"http://arxiv.org/abs/2505.04200v1","title":"Estimating Causal Effects in Networks with Cluster-Based Bandits","summary":"The gold standard for estimating causal effects is randomized controlled\ntrial (RCT) or A/B testing where a random group of individuals from a\npopulation of interest are given treatment and the outcome is compared to a\nrandom group of individuals from the same population. However, A/B testing is\nchallenging in the presence of interference, commonly occurring in social\nnetworks, where individuals can impact each others outcome. Moreover, A/B\ntesting can incur a high performance loss when one of the treatment arms has a\npoor performance and the test continues to treat individuals with it.\nTherefore, it is important to design a strategy that can adapt over time and\nefficiently learn the total treatment effect in the network. We introduce two\ncluster-based multi-armed bandit (MAB) algorithms to gradually estimate the\ntotal treatment effect in a network while maximizing the expected reward by\nmaking a tradeoff between exploration and exploitation. We compare the\nperformance of our MAB algorithms with a vanilla MAB algorithm that ignores\nclusters and the corresponding RCT methods on semi-synthetic data with\nsimulated interference. The vanilla MAB algorithm shows higher reward-action\nratio at the cost of higher treatment effect error due to undesired spillover.\nThe cluster-based MAB algorithms show higher reward-action ratio compared to\ntheir corresponding RCT methods without sacrificing much accuracy in treatment\neffect estimation.","main_category":"cs.LG","categories":"cs.LG,cs.SI","published":"2025-05-07T07:54:33Z"}
{"aid":"http://arxiv.org/abs/2505.04238v1","title":"Exotic magnetic phase diagram and extremely robust antiferromagnetism in\n  Ce$_2$RhIn$_8$","summary":"The antiferromagnetic heavy-fermion compound Ce$_2$RhIn$_8$ belongs to the\nsame family and bears similarities with the well-studied prototypical material\nCeRhIn$_5$, which demonstrates a unique behavior under applied magnetic field.\nHere, we report specific-heat measurements on a high-quality single crystal of\nCe$_2$RhIn$_8$ in magnetic fields up to 35 T applied along both principal\ncrystallographic directions. When the magnetic field is applied along the $a$\naxis of the tetragonal crystal structure, two additional field-induced\nantiferromagnetic phases are observed, in agreement with previous reports. One\nof them is confined in a small area of the field-temperature phase diagram. The\nother one, which develops above $\\sim$2.5 T, is very robust against the field.\nIts transition temperature increases with field, reaches a maximum at $\\sim$12\nT, and then starts to decrease. However, it tends to saturate towards the\nhighest field of our measurements. For a field applied along the $c$ axis, the\nN\\'{e}el temperature, $T_N$, initially decreases with field, as expected for a\ntypical antiferromagnet. Surprisingly, an additional phase emerges above\n$\\sim$10 T. It is most likely to be of the same origin as its counterpart\nobserved above 2.5 T for the other field orientation. This phase is also\nunusually robust: Its transition temperature increases all the way up to 35 T,\nwhere it exceeds the zero field $T_N =$~2.85 K. Finally, for both field\ndirections, the phase diagrams contain rarely observed tricritical points of\nsecond-order phase transitions.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-05-07T08:41:21Z"}
{"aid":"http://arxiv.org/abs/2505.04247v1","title":"A block preconditioner for thermo-poromechanics with frictional\n  deformation of fractures","summary":"The numerical modeling of fracture contact thermo-poromechanics is crucial\nfor advancing subsurface engineering applications, including CO2 sequestration,\nproduction of geo-energy resources, energy storage and wastewater disposal\noperations. Accurately modeling this problem presents substantial challenges\ndue to the complex physics involved in strongly coupled thermo-poromechanical\nprocesses and the frictional contact mechanics of fractures. To resolve process\ncouplings in the resulting mathematical model, it is common to apply fully\nimplicit time stepping. This necessitates the use of an iterative linear solver\nto run the model. The solver's efficiency primarily depends on a robust\npreconditioner, which is particularly challenging to develop because it must\nhandle the mutual couplings between linearized contact mechanics and energy,\nmomentum, and mass balance. In this work, we introduce a preconditioner for the\nproblem based on the nested approximations of Schur complements. To decouple\nthe momentum balance, we utilize the fixed-stress approximation, extended to\naccount for both the porous media and fracture subdomains. The singularity of\nthe contact mechanics submatrix is resolved by a linear transformation. Two\nvariations of the algorithm are proposed to address the coupled mass and energy\nbalance submatrix: either the Constrained Pressure Residual or the System-AMG\napproach. The preconditioner is evaluated through numerical experiments of\nfluid injection into fractured porous media, which causes thermal contraction\nand subsequent sliding and opening of fractures. The experiments show that the\npreconditioner performs robustly for a wide range of simulation regimes\ngoverned by various fracture states, friction coefficients and Peclet number.\nThe grid refinement experiments demonstrate that the preconditioner scales well\nin terms of GMRES iterations, in both two and three dimensions.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-05-07T08:49:49Z"}
{"aid":"http://arxiv.org/abs/2505.04260v1","title":"Steerable Chatbots: Personalizing LLMs with Preference-Based Activation\n  Steering","summary":"As large language models (LLMs) improve in their capacity to serve as\npersonal AI assistants, their ability to output uniquely tailored, personalized\nresponses that align with the soft preferences of their users is essential for\nenhancing user satisfaction and retention. However, untrained lay users have\npoor prompt specification abilities and often struggle with conveying their\nlatent preferences to AI assistants. To address this, we leverage activation\nsteering to guide LLMs to align with interpretable preference dimensions during\ninference. In contrast to memory-based personalization methods that require\nlonger user history, steering is extremely lightweight and can be easily\ncontrolled by the user via an linear strength factor. We embed steering into\nthree different interactive chatbot interfaces and conduct a within-subjects\nuser study (n=14) to investigate how end users prefer to personalize their\nconversations. The results demonstrate the effectiveness of preference-based\nsteering for aligning real-world conversations with hidden user preferences,\nand highlight further insights on how diverse values around control, usability,\nand transparency lead users to prefer different interfaces.","main_category":"cs.HC","categories":"cs.HC,cs.AI","published":"2025-05-07T09:10:51Z"}
{"aid":"http://arxiv.org/abs/2505.04289v1","title":"Micro-macro population dynamics models of benthic algae with long-memory\n  decay and generic growth","summary":"Benthic algae, as a primary producer in riverine ecosystems, develop biofilms\non the riverbed. Their population dynamics involve growth and decay processes,\nthe former owing to the balance between biological proliferation and mortality,\nwhile the latter results from mechanical abrasion because of the transport of\nsediment particles, such as sand and gravel. The decay has experimentally been\nidentified to exhibit long memory behavior, where the population decreases at\nan algebraic rate. However, the origin and mathematical theory of this\nphenomenon remain unresolved. This study introduces a novel mathematical model\nemploying spin processes to describe microscopic biofilm dynamics. The\ncontinuum limit of these spin processes captures the long-memory decay and\ngenerates generic growth curves. A spin process is defined as a continuous-time\nstochastic process transitioning between states 0 and 1. The proposed framework\nleverages heterogeneous spin rates, achieved by superposing spin processes with\ndistinct rates, to reproduce the long-memory decay. Computational simulations\ndemonstrate the behavior of the model, particularly emphasizing rate-induced\ntipping phenomena. This mathematical model provides a computationally tractable\ninterpretation of benthic algae dynamics, relevant to applications in\nmathematical modelling.","main_category":"math.PR","categories":"math.PR","published":"2025-05-07T09:48:22Z"}
{"aid":"http://arxiv.org/abs/2505.04314v1","title":"Monotonic normalized heat diffusion for distance-regular graphs with\n  classical parameters of diameter $3$","summary":"We prove the monotonic normalized heat diffusion property on distance-regular\ngraphs with classical parameters of diameter $3$. Regev and Shinkar found a\nCayley graph for which this property fails. On the other hand, this property\nhas been proved on abelian Cayley graphs, graphs with $3$ distinct eigenvalues\nand regular bipartite graphs with $4$ distinct eigenvalues by Price, Nica and\nKubo-Namba, respectively. A distance regular graph with classical parameters of\ndiameter $3$ has $4$ distinct eigenvalues and is not necessarily bipartite or\nvertex transitive.","main_category":"math.CO","categories":"math.CO,math.SP","published":"2025-05-07T10:59:06Z"}
{"aid":"http://arxiv.org/abs/2505.04335v1","title":"Hyperbolic Fuzzy $C$-Means with Adaptive Weight-based Filtering for\n  Clustering in Non-Euclidean Spaces","summary":"Clustering algorithms play a pivotal role in unsupervised learning by\nidentifying and grouping similar objects based on shared characteristics. While\ntraditional clustering techniques, such as hard and fuzzy center-based\nclustering, have been widely used, they struggle with complex,\nhigh-dimensional, and non-Euclidean datasets. In particular, the Fuzzy\n$C$-Means (FCM) algorithm, despite its efficiency and popularity, exhibits\nnotable limitations in non-Euclidean spaces. Euclidean spaces assume linear\nseparability and uniform distance scaling, limiting their effectiveness in\ncapturing complex, hierarchical, or non-Euclidean structures in fuzzy\nclustering. To overcome these challenges, we introduce Filtration-based\nHyperbolic Fuzzy $C$-Means (HypeFCM), a novel clustering algorithm tailored for\nbetter representation of data relationships in non-Euclidean spaces. HypeFCM\nintegrates the principles of fuzzy clustering with hyperbolic geometry and\nemploys a weight-based filtering mechanism to improve performance. The\nalgorithm initializes weights using a Dirichlet distribution and iteratively\nrefines cluster centroids and membership assignments based on a hyperbolic\nmetric in the Poincar\\'e Disc model. Extensive experimental evaluations\ndemonstrate that HypeFCM significantly outperforms conventional fuzzy\nclustering methods in non-Euclidean settings, underscoring its robustness and\neffectiveness.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-07T11:32:53Z"}
{"aid":"http://arxiv.org/abs/2505.04343v1","title":"Atmospheric loss during giant impacts: mechanisms and scaling of near-\n  and far-field loss","summary":"The primary epoch of planetary accretion concludes with giant impacts -\nhighly energetic collisions between proto-planets that can play a key role in\nshaping a planet's inventory of volatile elements. Previous work has shown that\nsingle giant impacts have the potential to eject a significant amount of a\nplanet's atmosphere but that the efficiency of atmospheric loss depends\nstrongly on the impact parameters and atmospheric properties. Fully quantifying\nthe role of giant impacts in planetary volatile evolution requires a more\ncomplete understanding of the mechanisms driving loss during impacts. Here, we\nuse a suite of 3D smoothed particle hydrodynamics simulations to show that loss\nin giant impacts is controlled primarily by ejecta plumes near the impact site\nand breakout of the impact shock in the far field, with the efficiency of the\nlatter well approximated by 1D ground-kick calculations. The relative\ncontributions of each mechanism to loss changes drastically with varying impact\nparameters. By considering the near and far field separately, we present a\nscaling law that precisely approximates (to within an average of $\\sim$3%) loss\nfrom 0.35 to 5.0 Earth mass planets with 5% mass fraction H$_2$-He atmospheres\nfor any combination of impactor mass, impact velocity, and angle. Finally, we\napply our scaling law to the results of $N$-body simulations for different\nsolar system formation scenarios. We find that while individual impacts rarely\ncause significant loss ($>$10%) from roughly Earth-mass planets with such\nmassive primary atmospheres, the cumulative effect of multiple impacts can be\nsubstantial (40-70% loss).","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-05-07T11:43:20Z"}
{"aid":"http://arxiv.org/abs/2505.04357v1","title":"Next-to-leading-order QCD corrections to double prompt $J/ψ$\n  hadroproduction","summary":"Within the framework of nonrelativistic-QCD (NRQCD) factorization, we perform\na comprehensive investigation of the color singlet (CS) contribution to prompt\n$J/\\psi$ pair production at the CERN Large Hadron Collider at next-to-leading\norder (NLO) in $\\alpha_s$. Specifically, we compare our NLO predictions with\nmeasurements from the LHCb, CMS, and ATLAS Collaborations. We find that the CS\ncontribution itself can well describe the LHCb data in most of the experimental\nbins, except in the regions where the fixed-order calculation is spoiled by the\nemission of soft or hard-collinear gluons. In the CMS and ATLAS cases, however,\nthe CS predictions greatly undershoot both the measured total and differential\ncross sections, despite sizable $K$ factors, of 2--3, for the total cross\nsections.","main_category":"hep-ph","categories":"hep-ph","published":"2025-05-07T12:10:37Z"}
{"aid":"http://arxiv.org/abs/2505.04364v1","title":"Benchmarking LLMs' Swarm intelligence","summary":"Large Language Models (LLMs) show potential for complex reasoning, yet their\ncapacity for emergent coordination in Multi-Agent Systems (MAS) when operating\nunder strict constraints-such as limited local perception and communication,\ncharacteristic of natural swarms-remains largely unexplored, particularly\nconcerning the nuances of swarm intelligence. Existing benchmarks often do not\nfully capture the unique challenges of decentralized coordination that arise\nwhen agents operate with incomplete spatio-temporal information. To bridge this\ngap, we introduce SwarmBench, a novel benchmark designed to systematically\nevaluate the swarm intelligence capabilities of LLMs acting as decentralized\nagents. SwarmBench features five foundational MAS coordination tasks within a\nconfigurable 2D grid environment, forcing agents to rely primarily on local\nsensory input (k x k view) and local communication. We propose metrics for\ncoordination effectiveness and analyze emergent group dynamics. Evaluating\nseveral leading LLMs in a zero-shot setting, we find significant performance\nvariations across tasks, highlighting the difficulties posed by local\ninformation constraints. While some coordination emerges, results indicate\nlimitations in robust planning and strategy formation under uncertainty in\nthese decentralized scenarios. Assessing LLMs under swarm-like conditions is\ncrucial for realizing their potential in future decentralized systems. We\nrelease SwarmBench as an open, extensible toolkit-built upon a customizable and\nscalable physical system with defined mechanical properties. It provides\nenvironments, prompts, evaluation scripts, and the comprehensive experimental\ndatasets generated, aiming to foster reproducible research into LLM-based MAS\ncoordination and the theoretical underpinnings of Embodied MAS. Our code\nrepository is available at https://github.com/x66ccff/swarmbench.","main_category":"cs.MA","categories":"cs.MA,cs.CL","published":"2025-05-07T12:32:01Z"}
{"aid":"http://arxiv.org/abs/2505.04368v1","title":"Pipelining Split Learning in Multi-hop Edge Networks","summary":"To support large-scale model training, split learning (SL) enables multiple\nedge devices/servers to share the intensive training workload. However, most\nexisting works on SL focus solely on two-tier model splitting. Moreover, while\nsome recent works have investigated the model splitting and placement problems\nfor multi-hop SL, these solutions fail to overcome the resource idleness issue,\nresulting in significant network idle time. In this work, we propose a\npipelined SL scheme by addressing the joint optimization problem of model\nsplitting and placement (MSP) in multi-hop edge networks. By applying pipeline\nparallelism to SL, we identify that the MSP problem can be mapped to a problem\nof minimizing the weighted sum of a bottleneck cost function (min-max) and a\nlinear cost function (min-sum). Based on graph theory, we devise a\nbottleneck-aware shortest-path algorithm to obtain the optimal solution.\nBesides, given the MSP outcomes, we also derive the closed-form solution to the\nmicro-batch size in the pipeline. Finally, we develop an alternating\noptimization algorithm of MSP and micro-batch size to solve the joint\noptimization problem to minimize the end-to-end training latency. Extensive\nsimulations have demonstrated the significant advantages of our algorithm\ncompared to existing benchmarks without pipeline parallelism.","main_category":"cs.NI","categories":"cs.NI","published":"2025-05-07T12:36:24Z"}
{"aid":"http://arxiv.org/abs/2505.04387v1","title":"Geometry-Aware Texture Generation for 3D Head Modeling with\n  Artist-driven Control","summary":"Creating realistic 3D head assets for virtual characters that match a precise\nartistic vision remains labor-intensive. We present a novel framework that\nstreamlines this process by providing artists with intuitive control over\ngenerated 3D heads. Our approach uses a geometry-aware texture synthesis\npipeline that learns correlations between head geometry and skin texture maps\nacross different demographics. The framework offers three levels of artistic\ncontrol: manipulation of overall head geometry, adjustment of skin tone while\npreserving facial characteristics, and fine-grained editing of details such as\nwrinkles or facial hair. Our pipeline allows artists to make edits to a single\ntexture map using familiar tools, with our system automatically propagating\nthese changes coherently across the remaining texture maps needed for realistic\nrendering. Experiments demonstrate that our method produces diverse results\nwith clean geometries. We showcase practical applications focusing on intuitive\ncontrol for artists, including skin tone adjustments and simplified editing\nworkflows for adding age-related details or removing unwanted features from\nscanned models. This integrated approach aims to streamline the artistic\nworkflow in virtual character creation.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-05-07T13:11:35Z"}
{"aid":"http://arxiv.org/abs/2505.04405v1","title":"High-speed multiwavelength photonic temporal integration using silicon\n  photonics","summary":"Optical systems have been pivotal for energy-efficient computing, performing\nhigh-speed, parallel operations in low-loss carriers. While these predominantly\nanalog optical accelerators bypass digitization to perform parallel\nfloating-point computations, scaling optical hardware to map large-vector sizes\nfor AI tasks remains challenging. Here, we overcome this limitation by\nunfolding scalar operations in time and introducing a\nphotonic-heater-in-lightpath (PHIL) unit for all-optical temporal integration.\nCounterintuitively, we exploit a slow heat dissipation process to integrate\noptical signals modulated at 50 GHz bridging the speed gap between the widely\napplied thermo-optic effects and ultrafast photonics. This architecture\nsupports optical end-to-end signal processing, eliminates inefficient\nelectro-optical conversions, and enables both linear and nonlinear operations\nwithin a unified framework. Our results demonstrate a scalable path towards\nhigh-speed photonic computing through thermally driven integration.","main_category":"physics.optics","categories":"physics.optics,cs.AI,physics.app-ph","published":"2025-05-07T13:39:18Z"}
{"aid":"http://arxiv.org/abs/2505.04406v1","title":"YABLoCo: Yet Another Benchmark for Long Context Code Generation","summary":"Large Language Models demonstrate the ability to solve various programming\ntasks, including code generation. Typically, the performance of LLMs is\nmeasured on benchmarks with small or medium-sized context windows of thousands\nof lines of code. At the same time, in real-world software projects,\nrepositories can span up to millions of LoC. This paper closes this gap by\ncontributing to the long context code generation benchmark (YABLoCo). The\nbenchmark featured a test set of 215 functions selected from four large\nrepositories with thousands of functions. The dataset contained metadata of\nfunctions, contexts of the functions with different levels of dependencies,\ndocstrings, functions bodies, and call graphs for each repository. This paper\npresents three key aspects of the contribution. First, the benchmark aims at\nfunction body generation in large repositories in C and C++, two languages not\ncovered by previous benchmarks. Second, the benchmark contains large\nrepositories from 200K to 2,000K LoC. Third, we contribute a scalable\nevaluation pipeline for efficient computing of the target metrics and a tool\nfor visual analysis of generated code. Overall, these three aspects allow for\nevaluating code generation in large repositories in C and C++.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.SE","published":"2025-05-07T13:42:23Z"}
{"aid":"http://arxiv.org/abs/2505.04420v1","title":"The effect of friction on the dynamics of targeted energy transfer by\n  symmetric vibro-impact dampers","summary":"This study investigates the nonlinear dynamics of a symmetric vibro-impact\nnonlinear energy sink (VI-NES) subjected to dry friction, a crucial factor that\nremains insufficiently explored in previous research. The combined effect of\nimpact and friction leads to intricate behaviors that require further\ninvestigation. To address this, the multiple scales method is extended to\nincorporate frictional effects and is complemented with a generalized impact\nmap approach. This allows for a systematic exploration of periodic solutions,\nstability, and bifurcations, revealing critical transitions between\nimpact-dominated and sliding-dominated regimes. The activation thresholds and\namplitude levels for different response regimes, including stick-slip dynamics,\nare identified, offering new insights into friction-induced nonlinearities. The\nresults bridge the gap between theoretical modeling and practical\nimplementation, offering a more accurate predictive framework for VINES\nbehavior. This improves design strategies for enhanced energy dissipation and\nrobustness in real-world applications.","main_category":"nlin.CD","categories":"nlin.CD","published":"2025-05-07T13:53:54Z"}
{"aid":"http://arxiv.org/abs/2505.04421v1","title":"LONGER: Scaling Up Long Sequence Modeling in Industrial Recommenders","summary":"Modeling ultra-long user behavior sequences is critical for capturing both\nlong- and short-term preferences in industrial recommender systems. Existing\nsolutions typically rely on two-stage retrieval or indirect modeling paradigms,\nincuring upstream-downstream inconsistency and computational inefficiency. In\nthis paper, we present LONGER, a Long-sequence Optimized traNsformer for\nGPU-Efficient Recommenders. LONGER incorporates (i) a global token mechanism\nfor stabilizing attention over long contexts, (ii) a token merge module with\nlightweight InnerTransformers and hybrid attention strategy to reduce quadratic\ncomplexity, and (iii) a series of engineering optimizations, including training\nwith mixed-precision and activation recomputation, KV cache serving, and the\nfully synchronous model training and serving framework for unified GPU-based\ndense and sparse parameter updates. LONGER consistently outperforms strong\nbaselines in both offline metrics and online A/B testing in both advertising\nand e-commerce services at ByteDance, validating its consistent effectiveness\nand industrial-level scaling laws. Currently, LONGER has been fully deployed at\nmore than 10 influential scenarios at ByteDance, serving billion users.","main_category":"cs.IR","categories":"cs.IR","published":"2025-05-07T13:54:26Z"}
{"aid":"http://arxiv.org/abs/2505.04422v1","title":"Pool Formation in Oceanic Games: Shapley Value and Proportional Sharing","summary":"We study a game-theoretic model for pool formation in Proof of Stake\nblockchain protocols. In such systems, stakeholders can form pools as a means\nof obtaining regular rewards from participation in ledger maintenance, with the\npower of each pool being dependent on its collective stake. The question we are\ninterested in is the design of mechanisms that suitably split rewards among\npool members and achieve favorable properties in the resulting pool\nconfiguration. With this in mind, we initiate a non-cooperative game-theoretic\nanalysis of the well known Shapley value scheme from cooperative game theory\ninto the context of blockchains. In particular, we focus on the oceanic model\nof games, proposed by Milnor and Shapley (1978), which is suitable for\npopulations where a small set of large players coexists with a big mass of\nrather small, negligible players. This provides an appropriate level of\nabstraction for pool formation processes among the stakeholders. We provide\ncomparisons between the Shapley mechanism and the more standard proportional\nscheme, in terms of attained decentralization, via a Price of Stability\nanalysis and in terms of susceptibility to Sybil attacks, i.e., the strategic\nsplitting of a players' stake with the intention of participating in multiple\npools for increased profit. Interestingly, while the widely deployed\nproportional scheme appears to have certain advantages, the Shapley value\nscheme, which rewards higher the most pivotal players, emerges as a competitive\nalternative, by being able to bypass some of the downsides of proportional\nsharing, while also not being far from optimal guarantees w.r.t.\ndecentralization. Finally, we complement our study with some variations of\nproportional sharing, where the profit is split in proportion to a\nsuperadditive or a subadditive function of the stake, showing that the Shapley\nvalue scheme still maintains the same advantages.","main_category":"cs.GT","categories":"cs.GT","published":"2025-05-07T13:55:46Z"}
{"aid":"http://arxiv.org/abs/2505.04426v1","title":"Polynomial deformations of $sl(2)$ and unified algebraic framework for\n  solutions of a class of spin models","summary":"We introduce novel polynomial deformations of the Lie algebra $sl(2)$. We\nconstruct their finite-dimensional irreducible representations and the\ncorresponding differential operator realizations. We apply our results to a\nclass of spin models with hidden polynomial algebra symmetry and obtain the\nclosed-form expressions for their energies and wave functions by means of the\nBethe ansatz method. The general framework enables us to give an unified\nalgebraic and analytic treatment for three interesting spin models with hidden\ncubic algebra symmetry: the Lipkin-Meshkov-Glick (LMG) model, the molecular\nasymmetric rigid rotor, and the two-axis countertwisting squeezing model. We\nprovide analytic and numerical insights into the structures of the roots of the\nBethe ansatz equations (i.e. the so-called Bethe roots) of these models. We\ngive descriptions of the roots on the spheres using the inverse stereographic\nprojection. The changes in nature and pattern of the Bethe roots on the spheres\nindicate the existence of different phases of the models. We also present the\nfidelity and derivatives of the ground-state energies (with respect to model\nparameters) of the models. The results indicate the presence of critical points\nand phase transitions of the models. In the appendix, we show that, unlike the\nso-called Bender-Dunne polynomials, the set of polynomials in the energy $E$,\n$P_\\ell(E)$, corresponding to each of the three spin models has two critical\npolynomials whose zeros give the quasi-exact energy eigenvalues of the model.\nSuch types of polynomials seem new.","main_category":"math-ph","categories":"math-ph,math.MP","published":"2025-05-07T13:58:15Z"}
{"aid":"http://arxiv.org/abs/2505.04438v1","title":"Do We Still Need to Work on Odometry for Autonomous Driving?","summary":"Over the past decades, a tremendous amount of work has addressed the topic of\nego-motion estimation of moving platforms based on various proprioceptive and\nexteroceptive sensors. At the cost of ever-increasing computational load and\nsensor complexity, odometry algorithms have reached impressive levels of\naccuracy with minimal drift in various conditions. In this paper, we question\nthe need for more research on odometry for autonomous driving by assessing the\naccuracy of one of the simplest algorithms: the direct integration of wheel\nencoder data and yaw rate measurements from a gyroscope. We denote this\nalgorithm as Odometer-Gyroscope (OG) odometry. This work shows that OG odometry\ncan outperform current state-of-the-art radar-inertial SE(2) odometry for a\nfraction of the computational cost in most scenarios. For example, the OG\nodometry is on top of the Boreas leaderboard with a relative translation error\nof 0.20%, while the second-best method displays an error of 0.26%.\nLidar-inertial approaches can provide more accurate estimates, but the\ncomputational load is three orders of magnitude higher than the OG odometry. To\nfurther the analysis, we have pushed the limits of the OG odometry by purposely\nviolating its fundamental no-slip assumption using data collected during a\nheavy snowstorm with different driving behaviours. Our conclusion shows that a\nsignificant amount of slippage is required to result in non-satisfactory pose\nestimates from the OG odometry.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-07T14:07:01Z"}
{"aid":"http://arxiv.org/abs/2505.04442v1","title":"Consistent Field Theory Across the Mott-Insulator to Superfluid\n  Transition","summary":"We employ a field-theoretical approach to analyze the Bose-Hubbard model on a\nlattice, with a focus on the low-energy properties across the Mott insulator\n(MI) to superfluid (SF) transition. Prior approaches approximated the partition\nfunction using cumulant expansions around the MI ground state, which, while\naccurate in the MI phase, lead to inaccuracies in the SF phase where the MI\nstate is a false ground state. By expanding around the correct mean-field\nvacuum, we derive the effective field theory (EFT) governing the MI to SF\ntransition. Through this, we reveal the underlying structure of the EFT\ngoverning the nucleation of low-energy excitations, particularly the massless\nand lowest massive modes, offering new insights into their emergence.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,cond-mat.other","published":"2025-05-07T14:14:14Z"}
{"aid":"http://arxiv.org/abs/2505.04455v1","title":"Reconfigurable Room Temperature Exchange Bias through Néel Order\n  Switching in van der Waals Heterostructures","summary":"Exchange bias effect plays a crucial role in modern magnetic memory\ntechnology. Recently, van der Waals magnetic materials have emerged and shown\npotential in spintronic devices at atomic scale. Owing to their tunable\nphysical properties and the flexibility in fabrication, the van der Waals\nheterostructures offer more possibilities for investigating potential\nmechanisms of the exchange bias effect. However, due to low magnetic ordering\ntemperatures for most van der Waals magnets, to establish exchange bias in van\nder Waals antiferromagnet/ferromagnet heterostructures at room temperature is\nchallenging. In this study, we fabricate\n(Fe$_{0.56}$Co$_{0.44}$)$_{5}$GeTe$_{2}$(FCGT)/Fe$_{3}$GaTe$_{2}$(FGaT)\nheterostructures with magnetic ordering temperatures of each component well\nabove room temperature to achieve a room temperature exchange bias effect. It\nis found that the sign and magnitude of the exchange bias field can be\nefficiently controlled by manipulating the N\\'eel order of FCGT with magnetic\nfield. The manipulation of N\\'eel order shows significant magnetic field\ndependence. A strong pre-set field induces a switch in the N\\'eel order of\nFCGT, which aligns the interfacial magnetization at the FCGT/FGaT interface,\nleading to robust exchange bias, as revealed by both transport measurements and\nmacro-spin model calculations. Our findings demonstrate the intrinsic\nmanipulation and switchable of room-temperature exchange bias in all-van der\nWaals heterostructures and further promote the development of novel\ntwo-dimensional spintronic devices.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-05-07T14:26:50Z"}
{"aid":"http://arxiv.org/abs/2505.04463v1","title":"Adaptive folding and noise filtering for robust quantum error mitigation","summary":"Coping with noise in quantum computation poses significant challenges due to\nits unpredictable nature and the complexities of accurate modeling. This paper\npresents noise-adaptive folding, a technique that enhances zero-noise\nextrapolation (ZNE) through the use of adaptive scaling factors based on\ncircuit error measurements. Furthermore, we introduce two filtering methods:\none relies on measuring error strength, while the other utilizes statistical\nfiltering to improve the extrapolation process. Comparing our approach with\nstandard ZNE reveals that adaptive scaling factors can be optimized using\neither a noise model or direct error strength measurements from inverted\ncircuits. The integration of adaptive scaling with filtering techniques leads\nto notable improvements in expectation-value extrapolation over standard ZNE.\nOur findings demonstrate that these adaptive methods effectively strengthen\nerror mitigation against noise fluctuations, thereby enhancing the precision\nand reliability of quantum computations.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-07T14:35:01Z"}
{"aid":"http://arxiv.org/abs/2505.04467v1","title":"Image Steganography For Securing Intellicise Wireless Networks:\n  \"Invisible Encryption\" Against Eavesdroppers","summary":"As one of the most promising technologies for intellicise (intelligent and\nconsice) wireless networks, Semantic Communication (SemCom) significantly\nimproves communication efficiency by extracting, transmitting, and recovering\nsemantic information, while reducing transmission delay. However, an\nintegration of communication and artificial intelligence (AI) also exposes\nSemCom to security and privacy threats posed by intelligent eavesdroppers. To\naddress this challenge, image steganography in SemCom embeds secret semantic\nfeatures within cover semantic features, allowing intelligent eavesdroppers to\ndecode only the cover image. This technique offers a form of \"invisible\nencryption\" for SemCom. Motivated by these advancements, this paper conducts a\ncomprehensive exploration of integrating image steganography into SemCom.\nFirstly, we review existing encryption techniques in SemCom and assess the\npotential of image steganography in enhancing its security. Secondly, we delve\ninto various image steganographic paradigms designed to secure SemCom,\nencompassing three categories of joint source-channel coding (JSCC) models\ntailored for image steganography SemCom, along with multiple training\nstrategies. Thirdly, we present a case study to illustrate the effectiveness of\ncoverless steganography SemCom. Finally, we propose future research directions\nfor image steganography SemCom.","main_category":"eess.SP","categories":"eess.SP","published":"2025-05-07T14:38:15Z"}
{"aid":"http://arxiv.org/abs/2505.04499v1","title":"Phase sensitivity via photon-subtraction operations inside Mach-Zehnder\n  interferometer","summary":"Based on the conventional Mach-Zehnder interferometer, we propose a\nmetrological scheme to improve phase sensitivity. In this scheme, we use a\ncoherent state and a squeezed vacuum state as input states, employ\nmulti-photon-subtraction operations and make intensity-detection or\nhomodyne-detection. We study phase sensitivity, quantum Fisher information and\nquantum Cram\\'er-Rao bound under both ideal and lossy conditions. The results\nindicate that choosing an appropriate detection method and photon subtraction\nscheme can significantly enhance the phase sensitivity and robustness against\nphoton losses. Even under lossy conditions, the multi-photon subtraction\nschemes can surpass the standard quantum limit. Notably, the homodyne detection\nmethod can even break through the Heisenberg limit. Moreover, increasing the\nnumber of photon-subtracted can enhance both phase sensitivity and quantum\nFisher information. This research highlights the significant value of this\nscheme in quantum precision measurement.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-07T15:20:55Z"}
{"aid":"http://arxiv.org/abs/2505.04523v1","title":"Magnetic precession as a model for QPOs in PULXs: flat-top noise ULXs\n  are different","summary":"Context. Several instances of low frequency Quasi-Periodic Oscillations\n(QPOs) have been reported in ultraluminous X-ray sources (ULXs), including\nthree in pulsating ones (PULXs) to date. The nature of many ULXs is still\nunclear, as are the detailed properties of accretion in PULXs. Aims. We seek an\nanswer to questions such as: Is there a QPO model that fits the data? Can mHz\nQPOs be used to constrain the magnetic field and accretion rate of the neutron\nstars in PULXs? Are all the low frequency QPOs in ULXs a manifestation of the\nsame phenomenon? Methods. We apply Dong Lai's precession model to the PULX\ndata, with the magnetic threading of the accretion disk constrained by recent\nsimulations. Results. Based on the magnetic precession model, and on recent\nprogress in understanding the inner structure of accretion disks, we predict an\ninverse scaling of QPO frequency with the neutron star period in PULXs. The\ntheoretical curve is largely independent of the stellar magnetic field or mass\naccretion rate and agrees with the data for the known QPOs in PULXs. The\nflat-top QPOs detected in ULXs have observational properties that seem to be\nvery different from the QPOs detected in PULXs, indicating they might have a\ndifferent origin.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-05-07T15:56:39Z"}
{"aid":"http://arxiv.org/abs/2505.04526v1","title":"DFVO: Learning Darkness-free Visible and Infrared Image Disentanglement\n  and Fusion All at Once","summary":"Visible and infrared image fusion is one of the most crucial tasks in the\nfield of image fusion, aiming to generate fused images with clear structural\ninformation and high-quality texture features for high-level vision tasks.\nHowever, when faced with severe illumination degradation in visible images, the\nfusion results of existing image fusion methods often exhibit blurry and dim\nvisual effects, posing major challenges for autonomous driving. To this end, a\nDarkness-Free network is proposed to handle Visible and infrared image\ndisentanglement and fusion all at Once (DFVO), which employs a cascaded\nmulti-task approach to replace the traditional two-stage cascaded training\n(enhancement and fusion), addressing the issue of information entropy loss\ncaused by hierarchical data transmission. Specifically, we construct a\nlatent-common feature extractor (LCFE) to obtain latent features for the\ncascaded tasks strategy. Firstly, a details-extraction module (DEM) is devised\nto acquire high-frequency semantic information. Secondly, we design a hyper\ncross-attention module (HCAM) to extract low-frequency information and preserve\ntexture features from source images. Finally, a relevant loss function is\ndesigned to guide the holistic network learning, thereby achieving better image\nfusion. Extensive experiments demonstrate that our proposed approach\noutperforms state-of-the-art alternatives in terms of qualitative and\nquantitative evaluations. Particularly, DFVO can generate clearer, more\ninformative, and more evenly illuminated fusion results in the dark\nenvironments, achieving best performance on the LLVIP dataset with 63.258 dB\nPSNR and 0.724 CC, providing more effective information for high-level vision\ntasks. Our code is publicly accessible at https://github.com/DaVin-Qi530/DFVO.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-05-07T15:59:45Z"}
{"aid":"http://arxiv.org/abs/2505.04535v1","title":"Communication-Efficient Federated Fine-Tuning of Language Models via\n  Dynamic Update Schedules","summary":"Federated learning (FL) makes it possible to train models on data that would\notherwise remain untapped and inaccessible. Simultaneously, pre-trained\nlanguage models (LMs) have emerged as indispensable tools in modern workflows.\nThese models exhibit extraordinary capabilities and are easily adapted to\ndownstream tasks. This opens one of the most exciting frontiers in FL:\nfine-tuning LMs. However, a persistent challenge in FL is the frequent, rigid\ncommunication of parameters, a problem which is magnified by the sheer size of\nthese modern models. Currently, the FedOpt family of algorithms is the\nprevailing approach in FL, though it relies on fixed, heuristic intervals for\nmodel synchronization. Recently, the FDA algorithm introduced a dynamic\nalternative by monitoring training progress, but it came with its own\ndrawbacks; namely, a hard-to-tune threshold parameter and a rigid\nsynchronization scheme. In this work, we introduce the FDA-Opt family of\nalgorithms -- a unified generalization that extends the principles behind both\nFDA and FedOpt, while resolving their core limitations. We evaluate our\napproach on fine-tuning LMs across a range of downstream NLP tasks, and\ndemonstrate that it consistently outperforms FedOpt -- even when FDA-Opt\noperates under hyper-parameter settings originally optimized for its\ncompetitors. In other words, we show that FDA-Opt is a practical, drop-in\nreplacement for FedOpt in modern FL libraries and systems: it requires no\nadditional configuration and delivers superior performance out of the box.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-07T16:13:21Z"}
{"aid":"http://arxiv.org/abs/2505.04536v1","title":"Light Spanners with Small Hop-Diameter","summary":"Lightness, sparsity, and hop-diameter are the fundamental parameters of\ngeometric spanners. Arya et al. [STOC'95] showed in their seminal work that\nthere exists a construction of Euclidean $(1+\\varepsilon)$-spanners with\nhop-diameter $O(\\log n)$ and lightness $O(\\log n)$. They also gave a general\ntradeoff of hop-diameter $k$ and sparsity $O(\\alpha_k(n))$, where $\\alpha_k$ is\na very slowly growing inverse of an Ackermann-style function. The former\ncombination of logarithmic hop-diameter and lightness is optimal due to the\nlower bound by Dinitz et al. [FOCS'08]. Later, Elkin and Solomon [STOC'13]\ngeneralized the light spanner construction to doubling metrics and extended the\ntradeoff for more values of hop-diameter $k$. In a recent line of work\n[SoCG'22, SoCG'23], Le et al. proved that the aforementioned tradeoff between\nthe hop-diameter and sparsity is tight for every choice of hop-diameter $k$. A\nfundamental question remains: What is the optimal tradeoff between the\nhop-diameter and lightness for every value of $k$?\n  In this paper, we present a general framework for constructing light spanners\nwith small hop-diameter. Our framework is based on tree covers. In particular,\nwe show that if a metric admits a tree cover with $\\gamma$ trees, stretch $t$,\nand lightness $L$, then it also admits a $t$-spanner with hop-diameter $k$ and\nlightness $O(kn^{2/k}\\cdot \\gamma L)$. Further, we note that the tradeoff for\ntrees is tight due to a construction in uniform line metric, which is perhaps\nthe simplest tree metric. As a direct consequence of this framework, we obtain\na tight tradeoff between lightness and hop-diameter for doubling metrics in the\nentire regime of $k$.","main_category":"cs.DS","categories":"cs.DS,cs.CG","published":"2025-05-07T16:13:54Z"}
{"aid":"http://arxiv.org/abs/2505.04541v1","title":"On the sensitivity of different ensemble filters to the type of\n  assimilated observation networks","summary":"Recent advances in data assimilation (DA) have focused on developing more\nflexible approaches that can better accommodate nonlinearities in models and\nobservations. However, it remains unclear how the performance of these advanced\nmethods depends on the observation network characteristics. In this study, we\npresent initial experiments with the surface quasi-geostrophic model, in which\nwe compare a recently developed AI-based ensemble filter with the standard\nLocal Ensemble Transform Kalman Filter (LETKF). Our results show that the\nanalysis solutions respond differently to the number, spatial distribution, and\nnonlinear fraction of assimilated observations. We also find notable changes in\nthe multiscale characteristics of the analysis errors. Given that standard DA\ntechniques will be eventually replaced by more advanced methods, we hope this\nstudy sets the ground for future efforts to reassess the value of Earth\nobservation systems in the context of newly emerging algorithms.","main_category":"physics.ao-ph","categories":"physics.ao-ph,nlin.CD,stat.ME","published":"2025-05-07T16:23:22Z"}
{"aid":"http://arxiv.org/abs/2505.04564v1","title":"Optimal Deterministic Rendezvous in Labeled Lines","summary":"In a rendezvous task, a set of mobile agents dispersed in a network have to\ngather at an arbitrary common site. We consider the rendezvous problem on the\ninfinite labeled line, with $2$ initially asleep agents, without communication,\nand a synchronous notion of time. Nodes are labeled with unique positive\nintegers. The initial distance between the two agents is denoted by $D$. Time\nis divided into rounds. We count time from when an agent first wakes up, and\ndenote by $\\tau$ the delay between the agents' wake up times. If awake in a\ngiven round $T$, an agent has three options: stay at its current node $v$, take\nport $0$, or take port $1$. If it decides to stay, the agent is still at node\n$v$ in round $T+1$. Otherwise, it is at one of the two neighbors of $v$ on the\nline, based on the port it chose. The agents achieve rendezvous in $T$ rounds\nif they are at the same node in round $T$. We aim for a deterministic algorithm\nfor this task.\n  The problem was recently considered by Miller and Pelc [DISC 2023]. With\n$\\ell_{\\max}$ the largest label of the two starting nodes, they showed that no\nalgorithm can guarantee rendezvous in $o(D \\log^* \\ell_{\\max})$ rounds. The\nlower bound follows from a connection with the LOCAL model of distributed\ncomputing, and holds even if the agents are guaranteed simultaneous wake-up\n($\\tau = 0$) and are given $D$ as advice. Miller and Pelc also gave an\nalgorithm of optimal matching complexity $O(D \\log^* \\ell_{\\max})$ when $D$ is\nknown to the agents, but only obtained the higher bound of $O(D^2 (\\log^*\n\\ell_{\\max})^3)$ when $D$ is unknown.\n  We improve this second complexity to a tight $O(D \\log^* \\ell_{\\max})$. In\nfact, our algorithm achieves rendezvous in $O(D \\log^* \\ell_{\\min})$ rounds,\nwhere $\\ell_{\\min}$ is the smallest label within distance $O(D)$ of the two\nstarting positions.","main_category":"cs.DC","categories":"cs.DC,cs.DS","published":"2025-05-07T16:56:52Z"}
{"aid":"http://arxiv.org/abs/2505.04568v1","title":"Conformal Survival Bands for Risk Screening under Right-Censoring","summary":"We propose a method to quantify uncertainty around individual survival\ndistribution estimates using right-censored data, compatible with any survival\nmodel. Unlike classical confidence intervals, the survival bands produced by\nthis method offer predictive rather than population-level inference, making\nthem useful for personalized risk screening. For example, in a low-risk\nscreening scenario, they can be applied to flag patients whose survival band at\n12 months lies entirely above 50\\%, while ensuring that at least half of\nflagged individuals will survive past that time on average. Our approach builds\non recent advances in conformal inference and integrates ideas from inverse\nprobability of censoring weighting and multiple testing with false discovery\nrate control. We provide asymptotic guarantees and show promising performance\nin finite samples with both simulated and real data.","main_category":"stat.ME","categories":"stat.ME","published":"2025-05-07T17:03:22Z"}
{"aid":"http://arxiv.org/abs/2505.04597v1","title":"Engineering topological exciton structures in two-dimensional\n  semiconductors by a periodic electrostatic potential","summary":"We propose to engineer topological exciton structures in layered transition\nmetal dichalcogenides through hybridizing different Rydberg states, which can\nbe induced by a periodic electrostatic potential remotely imprinted from charge\ndistributions in adjacent layers. Topological phase diagrams are obtained for\npotentials with various strengths and wavelengths. We find the lowest band of\nthe interlayer exciton can become topologically nontrivial, which exhibits a\nsmall bandwidth as well as quantum geometries well suited for realizing the\nbosonic fractional Chern insulator. For monolayer excitons, topological bands\nand in-gap helical edge states can emerge near the energy of 2p states.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-05-07T17:38:58Z"}
{"aid":"http://arxiv.org/abs/2505.04922v1","title":"Canny2Palm: Realistic and Controllable Palmprint Generation for\n  Large-scale Pre-training","summary":"Palmprint recognition is a secure and privacy-friendly method of biometric\nidentification. One of the major challenges to improve palmprint recognition\naccuracy is the scarcity of palmprint data. Recently, a popular line of\nresearch revolves around the synthesis of virtual palmprints for large-scale\npre-training purposes. In this paper, we propose a novel synthesis method named\nCanny2Palm that extracts palm textures with Canny edge detector and uses them\nto condition a Pix2Pix network for realistic palmprint generation. By\nre-assembling palmprint textures from different identities, we are able to\ncreate new identities by seeding the generator with new assemblies. Canny2Palm\nnot only synthesizes realistic data following the distribution of real\npalmprints but also enables controllable diversity to generate large-scale new\nidentities. On open-set palmprint recognition benchmarks, models pre-trained\nwith Canny2Palm synthetic data outperform the state-of-the-art with up to 7.2%\nhigher identification accuracy. Moreover, the performance of models pre-trained\nwith Canny2Palm continues to improve given 10,000 synthetic IDs while those\nwith existing methods already saturate, demonstrating the potential of our\nmethod for large-scale pre-training.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-08T03:37:07Z"}
{"aid":"http://arxiv.org/abs/2505.04928v1","title":"Lyapunov exponents for products of truncated orthogonal matrices","summary":"This article gives a non-asymptotic analysis of the largest Lyapunov exponent\nof truncated orthogonal matrix products. We prove that as long as N, the number\nof terms in product, is sufficiently large, the largest Lyapunov exponent is\nasympototically Gaussian. Futhermore, the sum of finite Lyapunov exponent is\nasympototically Gaussian, where we use Weingarten Calculus.","main_category":"math.PR","categories":"math.PR","published":"2025-05-08T03:53:31Z"}
{"aid":"http://arxiv.org/abs/2505.04930v1","title":"Accurate and Fast Channel Estimation for Fluid Antenna Systems with\n  Diffusion Models","summary":"Fluid antenna systems (FAS) offer enhanced spatial diversity for\nnext-generation wireless systems. However, acquiring accurate channel state\ninformation (CSI) remains challenging due to the large number of reconfigurable\nports and the limited availability of radio-frequency (RF) chains --\nparticularly in high-dimensional FAS scenarios. To address this challenge, we\npropose an efficient posterior sampling-based channel estimator that leverages\na diffusion model (DM) with a simplified U-Net architecture to capture the\nspatial correlation structure of two-dimensional FAS channels. The DM is\ninitially trained offline in an unsupervised way and then applied online as a\nlearned implicit prior to reconstruct CSI from partial observations via\nposterior sampling through a denoising diffusion restoration model (DDRM). To\naccelerate the online inference, we introduce a skipped sampling strategy that\nupdates only a subset of latent variables during the sampling process, thereby\nreducing the computational cost with minimal accuracy degradation. Simulation\nresults demonstrate that the proposed approach achieves significantly higher\nestimation accuracy and over 20x speedup compared to state-of-the-art\ncompressed sensing-based methods, highlighting its potential for practical\ndeployment in high-dimensional FAS.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-05-08T04:09:31Z"}
{"aid":"http://arxiv.org/abs/2505.04963v1","title":"ViCTr: Vital Consistency Transfer for Pathology Aware Image Synthesis","summary":"Synthesizing medical images remains challenging due to limited annotated\npathological data, modality domain gaps, and the complexity of representing\ndiffuse pathologies such as liver cirrhosis. Existing methods often struggle to\nmaintain anatomical fidelity while accurately modeling pathological features,\nfrequently relying on priors derived from natural images or inefficient\nmulti-step sampling. In this work, we introduce ViCTr (Vital Consistency\nTransfer), a novel two-stage framework that combines a rectified flow\ntrajectory with a Tweedie-corrected diffusion process to achieve high-fidelity,\npathology-aware image synthesis. First, we pretrain ViCTr on the ATLAS-8k\ndataset using Elastic Weight Consolidation (EWC) to preserve critical\nanatomical structures. We then fine-tune the model adversarially with Low-Rank\nAdaptation (LoRA) modules for precise control over pathology severity. By\nreformulating Tweedie's formula within a linear trajectory framework, ViCTr\nsupports one-step sampling, reducing inference from 50 steps to just 4, without\nsacrificing anatomical realism. We evaluate ViCTr on BTCV (CT), AMOS (MRI), and\nCirrMRI600+ (cirrhosis) datasets. Results demonstrate state-of-the-art\nperformance, achieving a Medical Frechet Inception Distance (MFID) of 17.01 for\ncirrhosis synthesis 28% lower than existing approaches and improving nnUNet\nsegmentation by +3.8% mDSC when used for data augmentation. Radiologist reviews\nindicate that ViCTr-generated liver cirrhosis MRIs are clinically\nindistinguishable from real scans. To our knowledge, ViCTr is the first method\nto provide fine-grained, pathology-aware MRI synthesis with graded severity\ncontrol, closing a critical gap in AI-driven medical imaging research.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-08T05:44:16Z"}
{"aid":"http://arxiv.org/abs/2505.04987v1","title":"Intrinsic characterization of projective special complex manifolds","summary":"We define the notion of an $S^1$-bundle of projective special complex base\ntype and construct a conical special complex manifold from it. Consequently the\nbase space of such an $S^{1}$-bundle can be realized as\n$\\mathbb{C}^{\\ast}$-quotient of a conical special complex manifold. As a\ncorollary, we give an intrinsic characterization of a projective special\ncomplex manifold generalizing Mantegazza's characterization of a projective\nspecial K\\\"ahler manifold. Our characterization is in the language of\nc-projective structures. As an application, a non-trivial $S^1$-family of\nObata-Ricci-flat hypercomplex structures (given by a generalization of the\nrigid c-map) on the tangent bundle of the total space of a\n$\\mathbb{C}^*$-bundle over a complex manifold with certain kind of c-projective\nstructure is constructed. Finally, we show that the quaternionic structure\nunderlying any of these hypercomplex structures is in general not flat and that\nits flatness implies the vanishing of the c-projective Weyl tensor of the base\nof the $\\mathbb{C}^*$-bundle. Conversely, any c-projectively flat complex\nmanifold satisfying a cohomological integrality condition gives rise to a flat\nquaternionic structure.","main_category":"math.DG","categories":"math.DG","published":"2025-05-08T06:44:58Z"}
{"aid":"http://arxiv.org/abs/2505.04991v1","title":"Discrete time crystal for periodic-field sensing with quantum-enhanced\n  precision","summary":"Sensing periodic-fields using quantum sensors has been an active field of\nresearch. In many of these scenarios, the quantum state of the probe is flipped\nregularly by the application of ${\\pi}$-pulses to accumulate information about\nthe target periodic-field. The emergence of a discrete time crystalline phase,\nas a nonequilibrium phase of matter, naturally provides oscillations in a\nmany-body system with an inherent controllable frequency. They benefit from\nlong coherence time and robustness against imperfections, which makes them\nexcellent potential quantum sensors. In this paper, through theoretical and\nnumerical analysis, we show that a disorder-free discrete time crystal probe\ncan reach the ultimate achievable precision for sensing a periodic-field. As\nthe amplitude of the periodic-field increases, the discrete time crystalline\norder diminishes, and the performance of the probe decreases remarkably.\nNevertheless, the obtained quantum enhancement in the discrete time crystal\nphase shows robustness against different imperfections in the protocol.\nFinally, we propose the implementation of our protocol in ultra-cold atoms in\noptical lattices.","main_category":"quant-ph","categories":"quant-ph,cond-mat.str-el","published":"2025-05-08T06:53:39Z"}
{"aid":"http://arxiv.org/abs/2505.05008v1","title":"Adaptive Contextual Embedding for Robust Far-View Borehole Detection","summary":"In controlled blasting operations, accurately detecting densely distributed\ntiny boreholes from far-view imagery is critical for operational safety and\nefficiency. However, existing detection methods often struggle due to small\nobject scales, highly dense arrangements, and limited distinctive visual\nfeatures of boreholes. To address these challenges, we propose an adaptive\ndetection approach that builds upon existing architectures (e.g., YOLO) by\nexplicitly leveraging consistent embedding representations derived through\nexponential moving average (EMA)-based statistical updates.\n  Our method introduces three synergistic components: (1) adaptive augmentation\nutilizing dynamically updated image statistics to robustly handle illumination\nand texture variations; (2) embedding stabilization to ensure consistent and\nreliable feature extraction; and (3) contextual refinement leveraging spatial\ncontext for improved detection accuracy. The pervasive use of EMA in our method\nis particularly advantageous given the limited visual complexity and small\nscale of boreholes, allowing stable and robust representation learning even\nunder challenging visual conditions. Experiments on a challenging proprietary\nquarry-site dataset demonstrate substantial improvements over baseline\nYOLO-based architectures, highlighting our method's effectiveness in realistic\nand complex industrial scenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-08T07:25:42Z"}
{"aid":"http://arxiv.org/abs/2505.05009v1","title":"Learning Partitions with Optimal Query and Round Complexities","summary":"We consider the basic problem of learning an unknown partition of $n$\nelements into at most $k$ sets using simple queries that reveal information\nabout a small subset of elements. Our starting point is the well-studied\npairwise same-set queries which ask if a pair of elements belong to the same\nclass. It is known that non-adaptive algorithms require $\\Theta(n^2)$ queries,\nwhile adaptive algorithms require $\\Theta(nk)$ queries, and the best known\nalgorithm uses $k-1$ rounds. This problem has been studied extensively over the\nlast two decades in multiple communities due to its fundamental nature and\nrelevance to clustering, active learning, and crowd sourcing. In many\napplications, it is of high interest to reduce adaptivity while minimizing\nquery complexity. We give a complete characterization of the deterministic\nquery complexity of this problem as a function of the number of rounds, $r$,\ninterpolating between the non-adaptive and adaptive settings: for any constant\n$r$, the query complexity is\n$\\Theta(n^{1+\\frac{1}{2^r-1}}k^{1-\\frac{1}{2^r-1}})$. Our algorithm only needs\n$O(\\log \\log n)$ rounds to attain the optimal $O(nk)$ query complexity.\n  Next, we consider two generalizations of pairwise queries to subsets $S$ of\nsize at most $s$: (1) weak subset queries which return the number of classes\nintersected by $S$, and (2) strong subset queries which return the entire\npartition restricted on $S$. Once again in crowd sourcing applications, queries\non large sets may be prohibitive. For non-adaptive algorithms, we show\n$\\Omega(n^2/s^2)$ strong queries are needed. Perhaps surprisingly, we show that\nthere is a non-adaptive algorithm using weak queries that matches this bound up\nto log-factors for all $s \\leq \\sqrt{n}$. More generally, we obtain nearly\nmatching upper and lower bounds for algorithms using subset queries in terms of\nboth the number of rounds, $r$, and the query size bound, $s$.","main_category":"cs.DS","categories":"cs.DS","published":"2025-05-08T07:27:29Z"}
{"aid":"http://arxiv.org/abs/2505.05080v1","title":"Expectations of some ratio-type estimators under the gamma distribution","summary":"We study the expectations of some ratio-type estimators under the gamma\ndistribution. Expectations of ratio-type estimators are often difficult to\ncompute due to the nature that they are constructed by combining two separate\nestimators. With the aid of Lukacs' Theorem and the gamma-beta\n(gamma-Dirichlet) relationship, we provide alternative proofs for the expected\nvalues of some common ratio-type estimators, including the sample Gini index,\nthe sample Theil index, and the sample Atkinson index, under the gamma\ndistribution. Our proofs using the distributional properties of the gamma\ndistribution are much simpler than the existing ones. In addition, we also\nderive the expected value of the sample variance-to-mean ratio under the gamma\ndistribution.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-05-08T09:23:28Z"}
{"aid":"http://arxiv.org/abs/2505.05107v1","title":"Duplex Self-Aligning Resonant Beam Communications and Power Transfer\n  with Coupled Spatially Distributed Laser Resonator","summary":"Sustainable energy supply and high-speed communications are two significant\nneeds for mobile electronic devices. This paper introduces a self-aligning\nresonant beam system for simultaneous light information and power transfer\n(SLIPT), employing a novel coupled spatially distributed resonator (CSDR). The\nsystem utilizes a resonant beam for efficient power delivery and a\nsecond-harmonic beam for concurrent data transmission, inherently minimizing\necho interference and enabling bidirectional communication. Through\ncomprehensive analyses, we investigate the CSDR's stable region, beam\nevolution, and power characteristics in relation to working distance and device\nparameters. Numerical simulations validate the CSDR-SLIPT system's feasibility\nby identifying a stable beam waist location for achieving accurate mode-match\ncoupling between two spatially distributed resonant cavities and demonstrating\nits operational range and efficient power delivery across varying distances.\nThe research reveals the system's benefits in terms of both safety and energy\ntransmission efficiency. We also demonstrate the trade-off among the\nreflectivities of the cavity mirrors in the CSDR. These findings offer valuable\ndesign insights for resonant beam systems, advancing SLIPT with significant\npotential for remote device connectivity.","main_category":"eess.SP","categories":"eess.SP","published":"2025-05-08T10:11:36Z"}
{"aid":"http://arxiv.org/abs/2505.05117v1","title":"Spin-glass quantum phase transition in amorphous arrays of Rydberg atoms","summary":"The experiments performed with neutral atoms trapped in optical tweezers and\ncoherently coupled to the Rydberg state allow quantum simulations of\nparadigmatic Hamiltonians for quantum magnetism. Previous studies have focused\nmainly on periodic arrangements of the optical tweezers, which host various\nspatially ordered magnetic phases. Here, we perform unbiased quantum Monte\nCarlo simulations of the ground state of quantum Ising models for amorphous\narrays of Rydberg atoms. These models are designed to feature well-controlled\nlocal structural properties in the absence of long-range order. Notably, by\ndetermining the Edwards-Anderson order parameter, we find evidence of a quantum\nphase transition from a paramagnetic to a spin-glass phase. The magnetic\nstructure factor indicates short-range isotropic antiferromagnetic\ncorrelations. For the feasible sizes, the spin-overlap distribution features a\nnontrivial structure with two broad peaks and a sizable weight at zero overlap.\nThe comparison against results for the clean kagome lattice, which features\nlocal structural properties similar to those of our amorphous arrays,\nhighlights the important role of the absence of long-range structural order of\nthe underlying array. Our findings indicate a route to experimentally implement\nthe details of a Hamiltonian which hosts a quantum spin-glass phase.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.quant-gas,cond-mat.stat-mech,physics.comp-ph","published":"2025-05-08T10:41:44Z"}
{"aid":"http://arxiv.org/abs/2505.05125v1","title":"Unraveling New Physics Effects in $b \\rightarrow s \\ell_1 \\ell_2$\n  Transitions with a Model-Independent Perspective","summary":"Motivated by recent anomalies in observables associated with flavor-changing\nneutral current (FCNC) transitions, specifically $b \\rightarrow s \\ell^+\n\\ell^-$ processes, we present a comprehensive analysis of lepton\nflavor-violating (LFV) decay modes mediated by $b \\rightarrow s \\ell_1 \\ell_2$\ntransitions with $\\ell_1 \\neq \\ell_2$. While such LFV processes are forbidden\nwithin the Standard Model (SM), they naturally arise in several of its\nextensions, including models featuring additional vector-like fermions and\nextra $Z'$ bosons. Employing the most general effective Hamiltonian for $b\n\\rightarrow s \\ell_1 \\ell_2$ transitions, we derive the angular distributions\nof the relevant decay modes. Adopting a model-independent framework, we\nsystematically study the LFV decays $B \\rightarrow K^* \\ell_1 \\ell_2$, $B_s\n\\rightarrow \\phi \\ell_1 \\ell_2$, $B \\rightarrow K_2^* \\ell_1 \\ell_2$, and\n$\\Lambda_b \\rightarrow \\Lambda \\ell_1 \\ell_2$. Although LFV mesonic decays have\nbeen widely explored, the corresponding baryonic decays remain comparatively\nunder-investigated. We provide bounds on branching ratio ($\\mathcal{B}$),\nforward-backward asymmetry ($\\mathcal{A}_{FB}$), and longitudinal lepton\npolarization fraction ($\\mathcal{F}_L$). Furthermore, considering the projected\nsensitivities of the LHCb upgrade and Belle II experiments, we estimate upper\nlimits for these observables, offering promising avenues for probing new\nphysics in these LFV channels.","main_category":"hep-ph","categories":"hep-ph","published":"2025-05-08T10:57:06Z"}
{"aid":"http://arxiv.org/abs/2505.05142v1","title":"Non-invertible symmetry as an axion-less solution to the strong CP\n  problem","summary":"We use a non-invertible symmetry to construct a three-zero texture for the\ndown-type quark mass matrix, which can resolve the strong CP problem without\ninvoking the axion, in four-dimensional spacetime with three quark families in\nQCD. We assume CP invariance at the fundamental high-energy scale.","main_category":"hep-ph","categories":"hep-ph","published":"2025-05-08T11:26:35Z"}
{"aid":"http://arxiv.org/abs/2505.05144v1","title":"Output correction factors in a 1.5 T magnetic field determined at the\n  central axis and at the lateral dose maximum for five detectors using alanine","summary":"In recent literature, the output correction factor in a 1.5T magnetic field,\nkB,Q,Clin, were determined only for the central axis (CAX), including our last\nwork. At an MR-linac, the determination of the CAX position relies on e.g.\nMV-imaging and is at small field sizes located at the penumbra, whereas the\nmaximum of the lateral profile (MAX) position is directly measurable. This\nstudy determined kB,Q,Ratio - the influence of the magnetic field on the output\ncorrection factor without a magnetic field, kQ,Clin - and kB,Q,Clin for both\nCAX and MAX fully experimentally for two MR-optimized ionization chambers,\ntheir conventional counterparts, and a solid-state detector. Additionally, the\nuncertainty due to intra-type variation for tabulated kB,Q,Clin was estimated.\nMeasurements were conducted using an experimental setup consisting of a mobile\nelectromagnet positioned in front of a standard clinical linac (6MV, 1.5T).\nIntra-type variation for the solid-state detector was assessed using four\ndetectors. The change of absorbed dose to water was determined with alanine.\nWithin the uncertainty, no difference in kB,Q,Ratio was observed between the\nMR-optimized chambers and their conventional counterparts. For the solid-state\ndetector, no difference between CAX and MAX was observed. For all detectors,\nkB,Q,Clin remained constant down to a field size of 3x3cm2. At smaller field\nsizes, for MAX and for all detectors, kB,Q,Ratio decreased linearly. The\nmaximum intra-type variation standard uncertainty was 0.009 for the smallest\nfield size, with and without a magnetic field. In summary, kB,Q,Ratio and\nkB,Q,Clin, including its uncertainty, was successfully determined for five\ndetectors at both CAX and MAX. For ionization chambers, kB,Q,Clin is lower at\nMAX, whereas for the solid-state detector, it remains the same. For the\ntabulated correction factors uncertainty, intra-type variation must be\nconsidered.","main_category":"physics.med-ph","categories":"physics.med-ph,physics.ins-det","published":"2025-05-08T11:28:49Z"}
{"aid":"http://arxiv.org/abs/2505.05147v1","title":"Contact Lens with Moiré patterns for High-Precision Eye Tracking","summary":"Eye tracking is a key technology for human-computer interaction, particularly\ncrucial in augmented reality (AR) and virtual reality (VR) systems. We propose\na novel eye-tracking approach based on incorporating passive eye-tracking\nmodules into contact lenses. These modules comprise two superimposed gratings\nseparated by a narrow gap. The overlapped gratings produce moir\\'e pattern,\nwhile the spatial separation between them results in parallax effect, namely,\npattern transformation upon variations in viewing angle, which enables accurate\nangular measurements. This method is insensitive to ambient lighting conditions\nand requires neither scale and color bars nor perspective corrections. Using\nthis approach, we have experimentally measured lens orientation with angular\nresolution exceeding 0.3{\\deg}, which is satisfactory for gaze detection in\nmost AR/VR applications. Furthermore, the proposed technological platform holds\na potential for many-fold enhancement in measurement precision.","main_category":"physics.optics","categories":"physics.optics","published":"2025-05-08T11:37:24Z"}
{"aid":"http://arxiv.org/abs/2505.05153v1","title":"Day-Ahead Bidding Strategies for Wind Farm Operators under a One-Price\n  Balancing Scheme","summary":"We study day-ahead bidding strategies for wind farm operators under a\none-price balancing scheme, prevalent in European electricity markets. In this\nsetting, the profit-maximising strategy becomes an all-or-nothing strategy,\naiming to take advantage of open positions in the balancing market. However,\nbalancing prices are difficult, if not impossible, to forecast in the day-ahead\nstage and large open positions can affect the balancing price by changing the\ndirection of the system imbalance. This paper addresses day-ahead bidding as a\ndecision-making problem under uncertainty, with the objective of maximising the\nexpected profit while reducing the imbalance risk related to the strategy. To\nthis end, we develop a stochastic optimisation problem with explicit\nconstraints on the positions in the balancing market, providing risk\ncertificates, and derive an analytical solution to this problem. Moreover, we\nshow how the price-impact of the trading strategy on the balancing market can\nbe included in the ex-post evaluation. Using real data from the Belgian\nelectricity market and an offshore wind farm in the North Sea, we demonstrate\nthat the all-or-nothing strategy negatively impacts the balancing price,\nresulting in long-term losses for the wind farm. Our risk-constrained strategy,\nhowever, can still significantly enhance operational profit compared to\ntraditional point-forecast bidding.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-05-08T11:50:19Z"}
{"aid":"http://arxiv.org/abs/2505.05164v1","title":"Report on Neural-like Criticality in Ag-based Nanoparticle Networks","summary":"Emulating the neural-like information processing dynamics of the brain\nprovides a time and energy efficient approach for solving complex problems.\nWhile the majority of neuromorphic hardware currently developed rely on large\narrays of highly organized building units, such as in rigid crossbar\narchitectures, in biological neuron assemblies make use of dynamic transitions\nwithin highly parallel, reconfigurable connection schemes. Neuroscience\nsuggests that efficiency of information processing in the brain rely on dynamic\ninteractions and signal propagations which are self-tuned and non-rigid.\nBrain-like dynamic and avalanche criticality have already been found in a\nvariety of self-organized networks of nanoobjects, such as nanoparticles (NP)\nor nanowires. Here we report on the dynamics of the electrical spiking signals\nfrom Ag-based self-organized nanoparticle networks (NPNs) at the example of\nmonometallic Ag NPNs, bimetallic AgAu alloy NPNs and composite Ag/ZrN NPNs,\nwhich combine two distinct NP species. We present time series recordings of the\nresistive switching responses in each network and showcase the determination of\nswitching events as well as the evaluation of avalanche criticality. In each\ncase, for Ag NPN, AgAu NPN and Ag/ZrN NPN, the agreement of three independently\nderived estimates of the characteristic exponent provides evidence for\navalanche criticality. The study shows that Ag-based NPNs offer a broad range\nof versatility for integration purposes into physical computing systems without\ndestroying their critical dynamics, as the composition of these NPNs can be\nmodified to suit specific requirements for integration.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-05-08T11:58:22Z"}
{"aid":"http://arxiv.org/abs/2505.05207v1","title":"A Fourier-based inference method for learning interaction kernels in\n  particle systems","summary":"We consider the problem of inferring the interaction kernel of stochastic\ninteracting particle systems from observations of a single particle. We adopt a\nsemi-parametric approach and represent the interaction kernel in terms of a\ngeneralized Fourier series. The basis functions in this expansion are tailored\nto the problem at hand and are chosen to be orthogonal polynomials with respect\nto the invariant measure of the mean-field dynamics. The generalized Fourier\ncoefficients are obtained as the solution of an appropriate linear system whose\ncoefficients depend on the moments of the invariant measure, and which are\napproximated from the particle trajectory that we observe. We quantify the\napproximation error in the Lebesgue space weighted by the invariant measure and\nstudy the asymptotic properties of the estimator in the joint limit as the\nobservation interval and the number of particles tend to infinity, i.e. the\njoint large time-mean field limit. We also explore the regime where an\nincreasing number of generalized Fourier coefficients is needed to represent\nthe interaction kernel. Our theoretical results are supported by extensive\nnumerical simulations.","main_category":"math.ST","categories":"math.ST,cs.NA,math.NA,stat.TH","published":"2025-05-08T13:02:39Z"}
{"aid":"http://arxiv.org/abs/2505.05239v1","title":"Bounds on $k$-hash distances and rates of linear codes","summary":"In this paper, we bound the rate of linear codes in $\\mathbb{F}_q^n$ with the\nproperty that any $k \\leq q$ codewords are all simultaneously distinct in at\nleast $d_k$ coordinates. For the particular case $d_k=1$, this leads to bounds\non the rate of linear $q$-ary $k$-hash codes which generalize, with a simpler\nproof, results recently obtained for the case $q=k=3$ by Pohoata and Zakharov\nand by Bishnoi D'haeseleeer and Gijswijt. We finally discuss some related open\nproblems on the list-decoding zero-error capacity of discrete memoryless\nchannels.","main_category":"cs.IT","categories":"cs.IT,math.CO,math.IT","published":"2025-05-08T13:34:02Z"}
{"aid":"http://arxiv.org/abs/2505.05242v1","title":"Enhancing Treatment Effect Estimation via Active Learning: A\n  Counterfactual Covering Perspective","summary":"Although numerous complex algorithms for treatment effect estimation have\nbeen developed in recent years, their effectiveness remains limited when\nhandling insufficiently labeled training sets due to the high cost of labeling\nthe effect after treatment, e.g., expensive tumor imaging or biopsy procedures\nneeded to evaluate treatment effects. Therefore, it becomes essential to\nactively incorporate more high-quality labeled data, all while adhering to a\nconstrained labeling budget. To enable data-efficient treatment effect\nestimation, we formalize the problem through rigorous theoretical analysis\nwithin the active learning context, where the derived key measures --\n\\textit{factual} and \\textit{counterfactual covering radius} determine the risk\nupper bound. To reduce the bound, we propose a greedy radius reduction\nalgorithm, which excels under an idealized, balanced data distribution. To\ngeneralize to more realistic data distributions, we further propose FCCM, which\ntransforms the optimization objective into the \\textit{Factual} and\n\\textit{Counterfactual Coverage Maximization} to ensure effective radius\nreduction during data acquisition. Furthermore, benchmarking FCCM against other\nbaselines demonstrates its superiority across both fully synthetic and\nsemi-synthetic datasets.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-08T13:42:00Z"}
{"aid":"http://arxiv.org/abs/2505.05253v1","title":"Gap-preserving reductions and RE-completeness of independent set games","summary":"In complexity theory, gap-preserving reductions play a crucial role in\nstudying hardness of approximation and in analyzing the relative complexity of\nmultiprover interactive proof systems. In the quantum setting, multiprover\ninteractive proof systems with entangled provers correspond to gapped promise\nproblems for nonlocal games, and the recent result MIP$^*$=RE (Ji et al.,\narXiv:2001.04383) shows that these are in general undecidable. However, the\nrelative complexity of problems within MIP$^*$ is still not well-understood, as\nestablishing gap-preserving reductions in the quantum setting presents new\nchallenges. In this paper, we introduce a framework to study such reductions\nand use it to establish MIP$^*$-completeness of the gapped promise problem for\nthe natural class of independent set games. In such a game, the goal is to\ndetermine whether a given graph contains an independent set of a specified\nsize. We construct families of independent set games with constant question\nsize for which the gapped promise problem is undecidable. In contrast, the same\nproblem is decidable in polynomial time in the classical setting. To carry out\nour reduction, we establish a new stability theorem, which could be of\nindependent interest, allowing us to perturb families of almost PVMs to genuine\nPVMs.","main_category":"quant-ph","categories":"quant-ph,cs.CC,math.OA","published":"2025-05-08T13:58:52Z"}
{"aid":"http://arxiv.org/abs/2505.05267v1","title":"Exploring unconventional superconductivity in PdTe via Point Contact\n  Spectroscopy","summary":"Palladium Telluride (PdTe), a non-layered intermetallic crystalline compound,\nhas captured attention for its unique superconducting properties and strong\nspin-orbit coupling. In this work, we investigate the superconducting state of\nPdTe using point-contact Andreev reflection (PCAR) spectroscopy. The\nexperimental data are analyzed using the Blonder-Tinkham-Klapwijk (BTK) model\nfor s, p and d wave symmetries. Our results reveal clear evidence of\nunconventional superconductivity. The superconducting gap showing features\nconsistent with either p-wave or d-wave pairing symmetries but cannot be fitted\nwith s-wave symmetry. The observed anisotropic gap structure and deviations\nfrom conventional BCS behaviour highlight the complex nature of the pairing\ninteractions in PdTe. These findings provide strong evidence of unconventional\npairing symmetry in this material.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.mtrl-sci","published":"2025-05-08T14:14:00Z"}
{"aid":"http://arxiv.org/abs/2505.05277v1","title":"An isoperimetric inequality for twisted eigenvalues with one\n  orthogonality constraint","summary":"We consider twisted eigenvalues $\\lambda_{1}^{g}(\\Omega)$, defined as the\nminimum of the Rayleigh quotient of functions in $H^1_{0}(\\Omega)$ that are\northogonal to a given function $g\\in L^2_\\text{loc}(\\mathbb R^d)$. We prove an\nisoperimetric inequality for $\\lambda_1^g(\\Omega)$, which provides a uniform\nbound on twisted eigenvalues -- not only with respect to the domain $\\Omega$\n(an open bounded set of $\\mathbb R^d$) -- but also in relation to the\northogonality function $g$. Remarkably, the lower bound is uniquely attained\nwhen $\\Omega$ is the union of two disjoint balls of specific radii, and when\nthe function $g$ in the orthogonality constraint is of bang-bang type, i.e.,\nconstant on each ball. As a consequence, we obtain a continuous 1-parameter\nfamily of optimal sets -- each being the union of two disjoint balls -- that\ninterpolates between the optimal shapes of the first two Dirichlet eigenvalues\nof the Laplacian.\n  This new isoperimetric inequality offers fresh perspectives on well\nestablished results, such as the Hong-Krahn-Szeg\\H{o} and the Freitas-Henrot\ninequalities. Notably, in these particular cases our proof avoids reliance on\nBessel functions, suggesting potential extensions to nonlinear settings.","main_category":"math.AP","categories":"math.AP,math.SP","published":"2025-05-08T14:24:49Z"}
{"aid":"http://arxiv.org/abs/2505.05297v1","title":"Repair Crew Routing for Infrastructure Network Restoration under\n  Incomplete Information","summary":"This paper considers a disrupted infrastructure network where the repair crew\nknows the locations of service outages but not the locations of actual faults.\nOur goal is to determine a route for a single crew to visit and repair the\ndisruptions to restore service with minimum negative impact. We call this\nproblem the Traveling Repairman Network Restoration Problem (TRNRP). This\nproblem presents strong computational challenges due to the combinatorial\nnature of the decisions, inter-dependencies within the underlying\ninfrastructure network, and incomplete information. Considering the dynamic\nnature of the decisions as a result of dynamic information revelation on the\nstatus of the nodes, we model this problem as a finite-horizon Markov decision\nprocess. Our solution approach uses value approximation based on reinforcement\nlearning, which is strengthened by structural results that identify a set of\nsuboptimal moves. In addition, we propose state aggregation methods to reduce\nthe size of the state space. We perform extensive computational studies to\ncharacterize the performance of our solution methods under different parameter\nsettings and to compare them with benchmark solution approaches.","main_category":"math.OC","categories":"math.OC","published":"2025-05-08T14:39:45Z"}
{"aid":"http://arxiv.org/abs/2505.05325v1","title":"Advanced Stock Market Prediction Using Long Short-Term Memory Networks:\n  A Comprehensive Deep Learning Framework","summary":"Predicting stock market movements remains a persistent challenge due to the\ninherently volatile, non-linear, and stochastic nature of financial time series\ndata. This paper introduces a deep learning-based framework employing Long\nShort-Term Memory (LSTM) networks to forecast the closing stock prices of major\ntechnology firms: Apple, Google, Microsoft, and Amazon, listed on NASDAQ.\nHistorical data was sourced from Yahoo Finance and processed using\nnormalization and feature engineering techniques. The proposed model achieves a\nMean Absolute Percentage Error (MAPE) of 2.72 on unseen test data,\nsignificantly outperforming traditional models like ARIMA. To further enhance\npredictive accuracy, sentiment scores were integrated using real-time news\narticles and social media data, analyzed through the VADER sentiment analysis\ntool. A web application was also developed to provide real-time visualizations\nof stock price forecasts, offering practical utility for both individual and\ninstitutional investors. This research demonstrates the strength of LSTM\nnetworks in modeling complex financial sequences and presents a novel hybrid\napproach combining time series modeling with sentiment analysis.","main_category":"cs.CE","categories":"cs.CE","published":"2025-05-08T15:10:49Z"}
{"aid":"http://arxiv.org/abs/2505.05330v1","title":"There is no polynomial formula for the catenary and the tame degree of\n  finitely generated monoids","summary":"In the last two decades there has been a wealth of results determining the\nprecise value of the catenary degree and the tame degree. Mostly, however, only\nfor very special classes of monoids and domains. In the present work we now\nshow that there is no polynomial formula, neither for the catenary nor for the\ntame degree, which is valid for a sufficiently large class of finitely\ngenerated monoids.","main_category":"math.AC","categories":"math.AC","published":"2025-05-08T15:21:30Z"}
{"aid":"http://arxiv.org/abs/2505.05341v1","title":"Robust Online Learning with Private Information","summary":"This paper investigates the robustness of online learning algorithms when\nlearners possess private information. No-external-regret algorithms, prevalent\nin machine learning, are vulnerable to strategic manipulation, allowing an\nadaptive opponent to extract full surplus. Even standard\nno-weak-external-regret algorithms, designed for optimal learning in stationary\nenvironments, exhibit similar vulnerabilities. This raises a fundamental\nquestion: can a learner simultaneously prevent full surplus extraction by\nadaptive opponents while maintaining optimal performance in well-behaved\nenvironments? To address this, we model the problem as a two-player repeated\ngame, where the learner with private information plays against the environment,\nfacing ambiguity about the environment's types: stationary or adaptive. We\nintroduce \\emph{partial safety} as a key design criterion for online learning\nalgorithms to prevent full surplus extraction. We then propose the\n\\emph{Explore-Exploit-Punish} (\\textsf{EEP}) algorithm and prove that it\nsatisfies partial safety while achieving optimal learning in stationary\nenvironments, and has a variant that delivers improved welfare performance. Our\nfindings highlight the risks of applying standard online learning algorithms in\nstrategic settings with adverse selection. We advocate for a shift toward\nonline learning algorithms that explicitly incorporate safeguards against\nstrategic manipulation while ensuring strong learning performance.","main_category":"econ.TH","categories":"econ.TH,cs.GT","published":"2025-05-08T15:29:06Z"}
{"aid":"http://arxiv.org/abs/2505.05360v1","title":"DSDrive: Distilling Large Language Model for Lightweight End-to-End\n  Autonomous Driving with Unified Reasoning and Planning","summary":"We present DSDrive, a streamlined end-to-end paradigm tailored for\nintegrating the reasoning and planning of autonomous vehicles into a unified\nframework. DSDrive leverages a compact LLM that employs a distillation method\nto preserve the enhanced reasoning capabilities of a larger-sized vision\nlanguage model (VLM). To effectively align the reasoning and planning tasks, a\nwaypoint-driven dual-head coordination module is further developed, which\nsynchronizes dataset structures, optimization objectives, and the learning\nprocess. By integrating these tasks into a unified framework, DSDrive anchors\non the planning results while incorporating detailed reasoning insights,\nthereby enhancing the interpretability and reliability of the end-to-end\npipeline. DSDrive has been thoroughly tested in closed-loop simulations, where\nit performs on par with benchmark models and even outperforms in many key\nmetrics, all while being more compact in size. Additionally, the computational\nefficiency of DSDrive (as reflected in its time and memory requirements during\ninference) has been significantly enhanced. Evidently thus, this work brings\npromising aspects and underscores the potential of lightweight systems in\ndelivering interpretable and efficient solutions for AD.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-08T15:53:34Z"}
{"aid":"http://arxiv.org/abs/2505.05375v1","title":"Threshold Modulation for Online Test-Time Adaptation of Spiking Neural\n  Networks","summary":"Recently, spiking neural networks (SNNs), deployed on neuromorphic chips,\nprovide highly efficient solutions on edge devices in different scenarios.\nHowever, their ability to adapt to distribution shifts after deployment has\nbecome a crucial challenge. Online test-time adaptation (OTTA) offers a\npromising solution by enabling models to dynamically adjust to new data\ndistributions without requiring source data or labeled target samples.\nNevertheless, existing OTTA methods are largely designed for traditional\nartificial neural networks and are not well-suited for SNNs. To address this\ngap, we propose a low-power, neuromorphic chip-friendly online test-time\nadaptation framework, aiming to enhance model generalization under distribution\nshifts. The proposed approach is called Threshold Modulation (TM), which\ndynamically adjusts the firing threshold through neuronal dynamics-inspired\nnormalization, being more compatible with neuromorphic hardware. Experimental\nresults on benchmark datasets demonstrate the effectiveness of this method in\nimproving the robustness of SNNs against distribution shifts while maintaining\nlow computational cost. The proposed method offers a practical solution for\nonline test-time adaptation of SNNs, providing inspiration for the design of\nfuture neuromorphic chips. The demo code is available at\ngithub.com/NneurotransmitterR/TM-OTTA-SNN.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG,cs.NE","published":"2025-05-08T16:09:40Z"}
{"aid":"http://arxiv.org/abs/2505.05383v1","title":"Diffuse Interface Models for Two-Phase Flows with Phase Transition:\n  Modeling and Existence of Weak Solutions","summary":"The flow of two macroscopically immiscible, viscous, incompressible fluids\nwith unmatched densities is studied, where a transfer of mass between the\nconstituents by phase transition is taken into account. To this end, two\nquasi-incompressible diffuse interface models with singular free energies are\nanalyzed, differing primarily in their velocity averaging. Firstly, to\ngeneralize a model by Abels, Garcke, and Gr\\\"un, a thermodynamically consistent\nsystem of Navier--Stokes/Cahn--Hilliard type with source terms is derived in a\nframework of continuum fluid dynamics, followed by a proof of existence of weak\nsolutions to the latter. Secondly, the quasi-stationary version of a model by\nAki, Dreyer, Giesselmann, and Kraus is investigated analytically, with\nexistence of weak solutions being established for the resulting\nquasi-stationary Stokes system coupled to a Cahn--Hilliard equation with a\nsource term.","main_category":"math.AP","categories":"math.AP","published":"2025-05-08T16:15:31Z"}
{"aid":"http://arxiv.org/abs/2505.05408v1","title":"Crosslingual Reasoning through Test-Time Scaling","summary":"Reasoning capabilities of large language models are primarily studied for\nEnglish, even when pretrained models are multilingual. In this work, we\ninvestigate to what extent English reasoning finetuning with long\nchain-of-thoughts (CoTs) can generalize across languages. First, we find that\nscaling up inference compute for English-centric reasoning language models\n(RLMs) improves multilingual mathematical reasoning across many languages\nincluding low-resource languages, to an extent where they outperform models\ntwice their size. Second, we reveal that while English-centric RLM's CoTs are\nnaturally predominantly English, they consistently follow a quote-and-think\npattern to reason about quoted non-English inputs. Third, we discover an\neffective strategy to control the language of long CoT reasoning, and we\nobserve that models reason better and more efficiently in high-resource\nlanguages. Finally, we observe poor out-of-domain reasoning generalization, in\nparticular from STEM to cultural commonsense knowledge, even for English.\nOverall, we demonstrate the potentials, study the mechanisms and outline the\nlimitations of crosslingual generalization of English reasoning test-time\nscaling. We conclude that practitioners should let English-centric RLMs reason\nin high-resource languages, while further work is needed to improve reasoning\nin low-resource languages and out-of-domain contexts.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-05-08T16:50:06Z"}
{"aid":"http://arxiv.org/abs/2505.05412v1","title":"Dynamic injection of a compressible gas into a confined porous layer","summary":"Subsurface gas storage is a critical technology in global efforts to mitigate\nclimate change. In particular, underground hydrogen storage offers a promising\nsolution for integrating large-scale renewable energy into the power grid. When\ninjected into the subsurface, hydrogen's low viscosity compared to the resident\nbrine causes it to spread rapidly, forming a thin gas layer above the brine,\ncomplicating recovery. In long aquifers, the large viscous pressure drop\nbetween the source and the outlet induces significant pressure variations,\nwhich may lead to substantial density changes in the injected gas. To examine\nthe role of gas compressibility in the spreading dynamics, we use long-wave\ntheory to derive coupled nonlinear evolution equations for the gas pressure and\nliquid/gas interface height, focusing on the limit of long domains, weak gas\ncompressibility and low liquid/gas mobility ratio. Simulations using these\nequations are supplemented with a comprehensive asymptotic analysis of\nparameter regimes. Unlike the near-incompressible limit, in which gas spreading\nrates are dictated by the source strength and mobility ratio, and any\ncompressive effects are transient, we show how, in general, compression of the\nmain gas bubble can generate dynamic pressure changes that are coupled to those\nin the thin gas layer that spreads over the liquid, with compressive effects\nhaving a sustained influence along the layer. This allows compressibility to\nreduce spreading rates and lower gas pressures. We characterise this behaviour\nvia a set of low-order models that reveal dominant scalings, highlighting the\nrole of compressibility in mediating the evolution of the gas layer.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-05-08T16:52:26Z"}
{"aid":"http://arxiv.org/abs/2505.05416v1","title":"Variable Selection for Fixed and Random Effects in Multilevel Functional\n  Mixed Effects Models","summary":"We develop a new method for simultaneously selecting fixed and random effects\nin a multilevel functional regression model. The proposed method is motivated\nby accelerometer-derived physical activity data from the 2011-12 cohort of the\nNational Health and Nutrition Examination Survey (NHANES), where we are\ninterested in identifying age and race-specific heterogeneity in covariate\neffects on the diurnal patterns of physical activity across the lifespan.\nExisting methods for variable selection in function-on-scalar regression have\nprimarily been designed for fixed effect selection and for single-level\nfunctional data. In high-dimensional multilevel functional regression, the\npresence of cluster-specific heterogeneity in covariate effects could be\ndetected through sparsity in fixed and random effects, and for this purpose, we\npropose a multilevel functional mixed effects selection (MuFuMES) method. The\nfixed and random functional effects are modelled using splines, with\nspike-and-slab group lasso (SSGL) priors on the unknown parameters of interest\nand a computationally efficient MAP estimation approach is employed for mixed\neffect selection through an Expectation Conditional Maximization (ECM)\nalgorithm. Numerical analysis using simulation study illustrates the\nsatisfactory selection accuracy of the variable selection method in having a\nnegligible false-positive and false-negative rate. The proposed method is\napplied to the accelerometer data from the NHANES 2011-12 cohort, where it\neffectively identifies age and race-specific heterogeneity in covariate effects\non the diurnal patterns of physical activity, recovering biologically\nmeaningful insights.","main_category":"stat.ME","categories":"stat.ME","published":"2025-05-08T16:57:06Z"}
{"aid":"http://arxiv.org/abs/2505.05430v1","title":"Two-dimensional water waves with constant vorticity and general bottom\n  topography","summary":"In this paper we consider two-dimensional water waves with constant\nvorticity, under the action of gravity and surface tension, in a fluid domain\nwith finite depth and general bottom topography. We present a formulation which\ngeneralizes the one by Zakharov-Craig-Sulem for irrotational water waves, and\nthe one by Constantin-Ivanov-Prodanov for water waves with constant vorticity\nand flat bottom topography. We study in detail an operator which appears in\nsuch formulation, extending well-known results for the classical\nDirichlet-Neumann operator, such as an analiticity result, the Taylor expansion\nin homogeneous powers of the wave profile, and a paralinearization formula. As\nan application, we prove a local well-posedness result.","main_category":"math.AP","categories":"math.AP","published":"2025-05-08T17:20:33Z"}
{"aid":"http://arxiv.org/abs/2505.05443v1","title":"Dualité étale à la Poitou-Tate pour les tores sur des variétés\n  définies sur un corps fini","summary":"Let $k$ be a global field of characteristic $p>0$. Denote $\\Omega_k$ the set\nof places of $k$ and let $S$ be a non-empty subset of $\\Omega_k$. We consider a\nscheme $\\mathscr{X} \\rightarrow Spec(\\mathcal{O}_S)$ smooth, separated, of\nfinite type and $\\mathscr{T}$ a tori defined over $\\mathscr{X}$. We study the\nTate-Shafarevich group given by the elements of $H^1(\\mathscr{X}, \\mathscr{T})$\nwhich vanish in the group $H^1(\\mathscr{X} \\otimes_{\\mathcal{O}_S} k_v,\n\\mathscr{T})$ for all $v \\in S$. We establish a Poitou-Tate duality for\n$\\mathscr{T}$ which generalise the classical Poitou-Tate duality for tori for\nvarieties defined over a finite field of arbitrary dimension.\n  Soit $k$ un corps global de caract\\'eristique $p>0$. Notons $\\Omega_k$\nl'ensemble des places de $k$ et soit $S$ un sous-ensemble non vide de\n$\\Omega_k$. On consid\\`ere un sch\\'ema $\\mathscr{X} \\rightarrow\nSpec(\\mathcal{O}_S)$ lisse, s\\'epar\\'e, de type fini et $\\mathscr{T}$ un tore\nd\\'efini sur $\\mathscr{X}$. On \\'etudie le groupe de Tate-Shafarevich donn\\'e\npar les \\'el\\'ements de $H^1(\\mathscr{X}, \\mathscr{T})$ qui s'annulent dans les\ngroupes $H^1(\\mathscr{X} \\otimes_{\\mathcal{O}_S} k_v, \\mathscr{T})$ pour tout\n$v \\in S$. On \\'etablit une dualit\\'e pour $\\mathscr{T}$ qui g\\'en\\'eralise la\ndualit\\'e de Poitou-Tate classique pour les tores \\`a des vari\\'et\\'es\nd\\'efinies sur un corps fini de dimension arbitraire.","main_category":"math.NT","categories":"math.NT,math.AG","published":"2025-05-08T17:32:09Z"}
{"aid":"http://arxiv.org/abs/2505.05464v1","title":"Bring Reason to Vision: Understanding Perception and Reasoning through\n  Model Merging","summary":"Vision-Language Models (VLMs) combine visual perception with the general\ncapabilities, such as reasoning, of Large Language Models (LLMs). However, the\nmechanisms by which these two abilities can be combined and contribute remain\npoorly understood. In this work, we explore to compose perception and reasoning\nthrough model merging that connects parameters of different models. Unlike\nprevious works that often focus on merging models of the same kind, we propose\nmerging models across modalities, enabling the incorporation of the reasoning\ncapabilities of LLMs into VLMs. Through extensive experiments, we demonstrate\nthat model merging offers a successful pathway to transfer reasoning abilities\nfrom LLMs to VLMs in a training-free manner. Moreover, we utilize the merged\nmodels to understand the internal mechanism of perception and reasoning and how\nmerging affects it. We find that perception capabilities are predominantly\nencoded in the early layers of the model, whereas reasoning is largely\nfacilitated by the middle-to-late layers. After merging, we observe that all\nlayers begin to contribute to reasoning, whereas the distribution of perception\nabilities across layers remains largely unchanged. These observations shed\nlight on the potential of model merging as a tool for multimodal integration\nand interpretation.","main_category":"cs.CL","categories":"cs.CL","published":"2025-05-08T17:56:23Z"}
{"aid":"http://arxiv.org/abs/2505.05472v1","title":"Mogao: An Omni Foundation Model for Interleaved Multi-Modal Generation","summary":"Recent progress in unified models for image understanding and generation has\nbeen impressive, yet most approaches remain limited to single-modal generation\nconditioned on multiple modalities. In this paper, we present Mogao, a unified\nframework that advances this paradigm by enabling interleaved multi-modal\ngeneration through a causal approach. Mogao integrates a set of key technical\nimprovements in architecture design, including a deep-fusion design, dual\nvision encoders, interleaved rotary position embeddings, and multi-modal\nclassifier-free guidance, which allow it to harness the strengths of both\nautoregressive models for text generation and diffusion models for high-quality\nimage synthesis. These practical improvements also make Mogao particularly\neffective to process interleaved sequences of text and images arbitrarily. To\nfurther unlock the potential of unified models, we introduce an efficient\ntraining strategy on a large-scale, in-house dataset specifically curated for\njoint text and image generation. Extensive experiments show that Mogao not only\nachieves state-of-the-art performance in multi-modal understanding and\ntext-to-image generation, but also excels in producing high-quality, coherent\ninterleaved outputs. Its emergent capabilities in zero-shot image editing and\ncompositional generation highlight Mogao as a practical omni-modal foundation\nmodel, paving the way for future development and scaling the unified\nmulti-modal systems.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-08T17:58:57Z"}
