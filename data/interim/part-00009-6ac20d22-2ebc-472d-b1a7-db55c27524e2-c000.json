{"aid":"http://arxiv.org/abs/2503.21683v1","title":"LLM-Gomoku: A Large Language Model-Based System for Strategic Gomoku\n  with Self-Play and Reinforcement Learning","summary":"In recent years, large language models (LLMs) have shown significant\nadvancements in natural language processing (NLP), with strong capa-bilities in\ngeneration, comprehension, and rea-soning. These models have found applications\nin education, intelligent decision-making, and gaming. However, effectively\nutilizing LLMs for strategic planning and decision-making in the game of Gomoku\nremains a challenge. This study aims to develop a Gomoku AI system based on\nLLMs, simulating the human learning process of playing chess. The system is\nde-signed to understand and apply Gomoku strat-egies and logic to make rational\ndecisions. The research methods include enabling the model to \"read the board,\"\n\"understand the rules,\" \"select strategies,\" and \"evaluate positions,\" while\nen-hancing its abilities through self-play and rein-forcement learning. The\nresults demonstrate that this approach significantly improves the se-lection of\nmove positions, resolves the issue of generating illegal positions, and reduces\npro-cess time through parallel position evaluation. After extensive self-play\ntraining, the model's Gomoku-playing capabilities have been notably enhanced.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-03-27T16:52:25Z"}
{"aid":"http://arxiv.org/abs/2503.21692v1","title":"RapidPoseTriangulation: Multi-view Multi-person Whole-body Human Pose\n  Triangulation in a Millisecond","summary":"The integration of multi-view imaging and pose estimation represents a\nsignificant advance in computer vision applications, offering new possibilities\nfor understanding human movement and interactions. This work presents a new\nalgorithm that improves multi-view multi-person pose estimation, focusing on\nfast triangulation speeds and good generalization capabilities. The approach\nextends to whole-body pose estimation, capturing details from facial\nexpressions to finger movements across multiple individuals and viewpoints.\nAdaptability to different settings is demonstrated through strong performance\nacross unseen datasets and configurations. To support further progress in this\nfield, all of this work is publicly accessible.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T16:57:33Z"}
{"aid":"http://arxiv.org/abs/2503.21703v1","title":"Trivial source characters in blocks of domestic representation type","summary":"Let $G$ be a finite group of even order, let $k$ be an algebraically closed\nfield of characteristic $2$, and let $B$ be a block of the group algebra $kG$\nwhich is of domestic representation type. Up to splendid Morita equivalence,\nprecisely three cases can occur: $kV_4$, $k\\mathfrak{A}_4$ and the principal\nblock of $k\\mathfrak{A}_5$. In each case, given the character values of the\nordinary irreducible characters of $B$, we determine the ordinary characters of\nall trivial source $B$-modules.","main_category":"math.RT","categories":"math.RT","published":"2025-03-27T17:09:40Z"}
{"aid":"http://arxiv.org/abs/2503.21710v1","title":"Enhancing Repository-Level Software Repair via Repository-Aware\n  Knowledge Graphs","summary":"Repository-level software repair faces challenges in bridging semantic gaps\nbetween issue descriptions and code patches. Existing approaches, which mostly\ndepend on large language models (LLMs), suffer from semantic ambiguities,\nlimited structural context understanding, and insufficient reasoning\ncapability. To address these limitations, we propose KGCompass with two\ninnovations: (1) a novel repository-aware knowledge graph (KG) that accurately\nlinks repository artifacts (issues and pull requests) and codebase entities\n(files, classes, and functions), allowing us to effectively narrow down the\nvast search space to only 20 most relevant functions with accurate candidate\nbug locations and contextual information, and (2) a path-guided repair\nmechanism that leverages KG-mined entity path, tracing through which allows us\nto augment LLMs with relevant contextual information to generate precise\npatches along with their explanations. Experimental results in the\nSWE-Bench-Lite demonstrate that KGCompass achieves state-of-the-art repair\nperformance (45.67%) and function-level localization accuracy (51.33%) across\nopen-source approaches, costing only $0.20 per repair. Our analysis reveals\nthat among successfully localized bugs, 69.7% require multi-hop traversals\nthrough the knowledge graph, without which LLM-based approaches struggle to\naccurately locate bugs. The knowledge graph built in KGCompass is language\nagnostic and can be incrementally updated, making it a practical solution for\nreal-world development environments.","main_category":"cs.SE","categories":"cs.SE","published":"2025-03-27T17:21:47Z"}
{"aid":"http://arxiv.org/abs/2503.21719v1","title":"The Principle of Redundant Reflection","summary":"The fact that redundant information does not change a rational belief after\nBayesian updating implies uniqueness of Bayes rule. In fact, any updating rule\nis uniquely specified by this principle. This is true for the classical\nsetting, as well as settings with improper or continuous priors. We prove this\nresult and illustrate it with two examples.","main_category":"stat.ME","categories":"stat.ME,stat.OT","published":"2025-03-27T17:31:22Z"}
{"aid":"http://arxiv.org/abs/2503.21740v1","title":"Transitioning to Memory Burden: Detectable Small Primordial Black Holes\n  as Dark Matter","summary":"Mounting theoretical evidence suggests that black holes are subjected to the\nmemory burden effect, implying that after certain time the information stored\nin them suppresses the decay rate. This effect opens up a new window for small\nprimordial black holes (PBHs) below $10^{15}\\,{\\rm g}$ as dark matter. We show\nthat the smooth transition from semi-classical evaporation to the\nmemory-burdened phase strongly impacts observational bounds on the abundance of\nsmall PBHs. The most stringent constraints come from present-day fluxes of\nastrophysical particles. Remarkably, currently-transitioning small PBHs are\ndetectable through high-energetic neutrino events.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO,astro-ph.HE,gr-qc,hep-th","published":"2025-03-27T17:51:05Z"}
{"aid":"http://arxiv.org/abs/2503.21756v1","title":"A Unified Framework for Diffusion Bridge Problems: Flow Matching and\n  SchrÃ¶dinger Matching into One","summary":"The bridge problem is to find an SDE (or sometimes an ODE) that bridges two\ngiven distributions. The application areas of the bridge problem are enormous,\namong which the recent generative modeling (e.g., conditional or unconditional\nimage generation) is the most popular. Also the famous Schr\\\"{o}dinger bridge\nproblem, a widely known problem for a century, is a special instance of the\nbridge problem. Two most popular algorithms to tackle the bridge problems in\nthe deep learning era are: (conditional) flow matching and iterative fitting\nalgorithms, where the former confined to ODE solutions, and the latter\nspecifically for the Schr\\\"{o}dinger bridge problem. The main contribution of\nthis article is in two folds: i) We provide concise reviews of these algorithms\nwith technical details to some extent; ii) We propose a novel unified\nperspective and framework that subsumes these seemingly unrelated algorithms\n(and their variants) into one. In particular, we show that our unified\nframework can instantiate the Flow Matching (FM) algorithm, the (mini-batch)\noptimal transport FM algorithm, the (mini-batch) Schr\\\"{o}dinger bridge FM\nalgorithm, and the deep Schr\\\"{o}dinger bridge matching (DSBM) algorithm as its\nspecial cases. We believe that this unified framework will be useful for\nviewing the bridge problems in a more general and flexible perspective, and in\nturn can help researchers and practitioners to develop new bridge algorithms in\ntheir fields.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-27T17:57:03Z"}
{"aid":"http://arxiv.org/abs/2503.21762v1","title":"On the open TS/ST correspondence","summary":"The topological string/spectral theory correspondence establishes a precise,\nnon-perturbative duality between topological strings on local Calabi-Yau\nthreefolds and the spectral theory of quantized mirror curves. While this\nduality has been rigorously formulated for the closed topological string\nsector, the open string sector remains less understood. Building on the results\nof [1-3], we make further progress in this direction by constructing entire,\noff-shell eigenfunctions for the quantized mirror curve from open topological\nstring partition functions. We focus on local $\\mathbb{F}_0$, whose mirror\ncurve corresponds to the Baxter equation of the two-particle, relativistic Toda\nlattice. We then study the standard and dual four-dimensional limits, where the\nquantum mirror curve for local $\\mathbb{F}_0$ degenerates into the modified\nMathieu and McCoy-Tracy-Wu operators, respectively. In these limits, our\nframework provides a way to construct entire, off-shell eigenfunctions for the\ndifference equations associated with these operators. Furthermore, we find a\nsimple relation between the on-shell eigenfunctions of the modified Mathieu and\nMcCoy-Tracy-Wu operators, leading to a functional relation between the\noperators themselves.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP,math.SP","published":"2025-03-27T17:57:37Z"}
{"aid":"http://arxiv.org/abs/2503.21765v1","title":"Exploring the Evolution of Physics Cognition in Video Generation: A\n  Survey","summary":"Recent advancements in video generation have witnessed significant progress,\nespecially with the rapid advancement of diffusion models. Despite this, their\ndeficiencies in physical cognition have gradually received widespread attention\n- generated content often violates the fundamental laws of physics, falling\ninto the dilemma of ''visual realism but physical absurdity\". Researchers began\nto increasingly recognize the importance of physical fidelity in video\ngeneration and attempted to integrate heuristic physical cognition such as\nmotion representations and physical knowledge into generative systems to\nsimulate real-world dynamic scenarios. Considering the lack of a systematic\noverview in this field, this survey aims to provide a comprehensive summary of\narchitecture designs and their applications to fill this gap. Specifically, we\ndiscuss and organize the evolutionary process of physical cognition in video\ngeneration from a cognitive science perspective, while proposing a three-tier\ntaxonomy: 1) basic schema perception for generation, 2) passive cognition of\nphysical knowledge for generation, and 3) active cognition for world\nsimulation, encompassing state-of-the-art methods, classical paradigms, and\nbenchmarks. Subsequently, we emphasize the inherent key challenges in this\ndomain and delineate potential pathways for future research, contributing to\nadvancing the frontiers of discussion in both academia and industry. Through\nstructured review and interdisciplinary analysis, this survey aims to provide\ndirectional guidance for developing interpretable, controllable, and physically\nconsistent video generation paradigms, thereby propelling generative models\nfrom the stage of ''visual mimicry'' towards a new phase of ''human-like\nphysical comprehension''.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:58:33Z"}
{"aid":"http://arxiv.org/abs/2503.21767v1","title":"Semantic Consistent Language Gaussian Splatting for Point-Level\n  Open-vocabulary Querying","summary":"Open-vocabulary querying in 3D Gaussian Splatting aims to identify\nsemantically relevant regions within a 3D Gaussian representation based on a\ngiven text query. Prior work, such as LangSplat, addressed this task by\nretrieving these regions in the form of segmentation masks on 2D renderings.\nMore recently, OpenGaussian introduced point-level querying, which directly\nselects a subset of 3D Gaussians. In this work, we propose a point-level\nquerying method that builds upon LangSplat's framework. Our approach improves\nthe framework in two key ways: (a) we leverage masklets from the Segment\nAnything Model 2 (SAM2) to establish semantic consistent ground-truth for\ndistilling the language Gaussians; (b) we introduces a novel two-step querying\napproach that first retrieves the distilled ground-truth and subsequently uses\nthe ground-truth to query the individual Gaussians. Experimental evaluations on\nthree benchmark datasets demonstrate that the proposed method achieves better\nperformance compared to state-of-the-art approaches. For instance, our method\nachieves an mIoU improvement of +20.42 on the 3D-OVS dataset.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:05Z"}
{"aid":"http://arxiv.org/abs/2503.21770v1","title":"Visual Jenga: Discovering Object Dependencies via Counterfactual\n  Inpainting","summary":"This paper proposes a novel scene understanding task called Visual Jenga.\nDrawing inspiration from the game Jenga, the proposed task involves\nprogressively removing objects from a single image until only the background\nremains. Just as Jenga players must understand structural dependencies to\nmaintain tower stability, our task reveals the intrinsic relationships between\nscene elements by systematically exploring which objects can be removed while\npreserving scene coherence in both physical and geometric sense. As a starting\npoint for tackling the Visual Jenga task, we propose a simple, data-driven,\ntraining-free approach that is surprisingly effective on a range of real-world\nimages. The principle behind our approach is to utilize the asymmetry in the\npairwise relationships between objects within a scene and employ a large\ninpainting model to generate a set of counterfactuals to quantify the\nasymmetry.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:33Z"}
{"aid":"http://arxiv.org/abs/2503.23701v1","title":"Topological Electronic Structure and Transport Properties of the\n  Distorted Rutile-type WO$_2$","summary":"We elucidate the transport properties and electronic structures of distorted\nrutile-type WO2. Electrical resistivity and Hall effect measurements of\nhigh-quality single crystals revealed the transport property characteristics of\ntopological materials; these characteristics included an extremely large\nmagnetoresistance of 13,200% (2 K and 9 T) and a very high carrier mobility of\n25,700 cm2 V-1 s-1 (5 K). First-principles calculations revealed Dirac nodal\nlines (DNL) near the Fermi energy in the electronic structure when spin-orbit\ninteractions (SOIs) were absent. Although these DNLs mostly disappeared in the\npresence of SOIs, band crossings at high-symmetry points in the reciprocal\nspace existed as Dirac points. Furthermore, DNLs protected by nonsymmorphic\nsymmetry persisted on the ky = {\\pi}/b plane. The unique transport properties\noriginating from the topological electronic structure of chemically and\nthermally stable WO2 could represent an opportunity to investigate the\npotential electronic applications of the material.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-03-31T03:58:36Z"}
{"aid":"http://arxiv.org/abs/2503.23735v1","title":"Altermagnetism and Weak Ferromagnetism","summary":"Using a realistic model relevant to La$_2$CuO$_4$ and other altermagnetic\nperovskite oxides, we study interrelations between weak ferromagnetism (WF),\nanomalous Hall effect (AHE), and net orbital magnetization (OM). All of them\ncan be linked to the form of Dzyaloshinskii-Moriya (DM) interactions.\nNevertheless, while spin WF is induced by the DM vector components having the\nsame sign in all equivalent bonds, AHE and OM are related to alternating-sign\ncomponents, which do not contribute to any canting of spins. The microscopic\nmodel remains invariant under the symmetry operation $\\{ \\mathcal{S}|{\\bf t}\n\\}$, combining the shift ${\\bf t}$ of antiferromagnetically coupled sublattices\nto each other with the spin flip $\\mathcal{S}$. Thus, the band structure\nremains Kramers-degenerate, but the time-reversal symmetry is broken, providing\na possibility to realize AHE in antiferromagnetic substances. The altermagnetic\nsplitting of bands, breaking the $\\{ \\mathcal{S}|{\\bf t}\\}$ symmetry, does not\nplay a major role in the problem. More important is the orthorhombic strain,\nresponsible for finite values of AHE and OM.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-03-31T05:15:47Z"}
{"aid":"http://arxiv.org/abs/2503.23744v1","title":"European Contributions to Fermilab Accelerator Upgrades and Facilities\n  for the DUNE Experiment","summary":"The Proton Improvement Plan (PIP-II) to the FNAL accelerator chain and the\nLong-Baseline Neutrino Facility (LBNF) will provide the world's most intense\nneutrino beam to the Deep Underground Neutrino Experiment (DUNE) enabling a\nwide-ranging physics program. This document outlines the significant\ncontributions made by European national laboratories and institutes towards\nrealizing the first phase of the project with a 1.2 MW neutrino beam.\nConstruction of this first phase is well underway. For DUNE Phase II, this will\nbe closely followed by an upgrade of the beam power to > 2 MW, for which the\nEuropean groups again have a key role and which will require the continued\nsupport of the European community for machine aspects of neutrino physics.\nBeyond the neutrino beam aspects, LBNF is also responsible for providing unique\ninfrastructure to install and operate the DUNE neutrino detectors at FNAL and\nat the Sanford Underground Research Facility (SURF). The cryostats for the\nfirst two Liquid Argon Time Projection Chamber detector modules at SURF, a\ncontribution of CERN to LBNF, are central to the success of the ongoing\nexecution of DUNE Phase I. Likewise, successful and timely procurement of\ncryostats for two additional detector modules at SURF will be critical to the\nsuccess of DUNE Phase II and the overall physics program. The DUNE\nCollaboration is submitting four main contributions to the 2026 Update of the\nEuropean Strategy for Particle Physics process. This paper is being submitted\nto the 'Accelerator technologies' and 'Projects and Large Experiments' streams.\nAdditional inputs related to the DUNE science program, DUNE detector\ntechnologies and R&D, and DUNE software and computing, are also being submitted\nto other streams.","main_category":"physics.acc-ph","categories":"physics.acc-ph,hep-ex,physics.ins-det","published":"2025-03-31T05:47:29Z"}
{"aid":"http://arxiv.org/abs/2503.23756v1","title":"On a natural L2 metric on the space of Hermitian metrics","summary":"We investigate the space of Hermitian metrics on a fixed complex vector\nbundle. This infinite-dimensional space has appeared in the study of\nHermitian-Einstein structures, where a special L2-type Riemannian metric is\nintroduced. We compute the metric spray, geodesics and curvature associated to\nthis metric, and show that the exponential map is a diffeomorphsim. Though\nbeing geodesically complete, the space of Hermitian metrics is metrically\nincomplete, and its metric completion is proved to be the space of L2\nintegrable singular Hermitian metrics. In addition, both the original space and\nits completion are CAT(0). In the holomorphic case, it turns out that Griffiths\nseminegative/semipositive singular Hermitian metric is always L2 integrable in\nour sense. Also, in the Appendix, the Nash-Moser inverse function theorem is\nused to prove that, for any L2 metric on the space of smooth sections of a\ngiven fiber bundle, the exponential map is always a local diffeomorphism,\nprovided that each fiber is nonpositively curved.","main_category":"math.DG","categories":"math.DG","published":"2025-03-31T06:12:40Z"}
{"aid":"http://arxiv.org/abs/2503.23762v1","title":"UniSep: Universal Target Audio Separation with Language Models at Scale","summary":"We propose Universal target audio Separation (UniSep), addressing the\nseparation task on arbitrary mixtures of different types of audio.\nDistinguished from previous studies, UniSep is performed on unlimited source\ndomains and unlimited source numbers. We formulate the separation task as a\nsequence-to-sequence problem, and a large language model (LLM) is used to model\nthe audio sequence in the discrete latent space, leveraging the power of LLM in\nhandling complex mixture audios with large-scale data. Moreover, a novel\npre-training strategy is proposed to utilize audio-only data, which reduces the\nefforts of large-scale data simulation and enhances the ability of LLMs to\nunderstand the consistency and correlation of information within audio\nsequences. We also demonstrate the effectiveness of scaling datasets in an\naudio separation task: we use large-scale data (36.5k hours), including speech,\nmusic, and sound, to train a universal target audio separation model that is\nnot limited to a specific domain. Experiments show that UniSep achieves\ncompetitive subjective and objective evaluation results compared with\nsingle-task models.","main_category":"cs.SD","categories":"cs.SD,eess.AS","published":"2025-03-31T06:27:37Z"}
{"aid":"http://arxiv.org/abs/2503.23776v1","title":"VIDEX: A Disaggregated and Extensible Virtual Index for the Cloud and AI\n  Era","summary":"Virtual index, also known as hypothetical indexes, play a crucial role in\ndatabase query optimization. However, with the rapid advancement of cloud\ncomputing and AI-driven models for database optimization, traditional virtual\nindex approaches face significant challenges. Cloud-native environments often\nprohibit direct conducting query optimization process on production databases\ndue to stability requirements and data privacy concerns. Moreover, while AI\nmodels show promising progress, their integration with database systems poses\nchallenges in system complexity, inference acceleration, and model hot updates.\nIn this paper, we present VIDEX, a three-layer disaggregated architecture that\ndecouples database instances, the virtual index optimizer, and algorithm\nservices, providing standardized interfaces for AI model integration. Users can\nconfigure VIDEX by either collecting production statistics or by loading from a\nprepared file; this setup allows for high-accurate what-if analyses based on\nvirtual indexes, achieving query plans that are identical to those of the\nproduction instance. Additionally, users can freely integrate new AI-driven\nalgorithms into VIDEX. VIDEX has been successfully deployed at ByteDance,\nserving thousands of MySQL instances daily and over millions of SQL queries for\nindex optimization tasks.","main_category":"cs.DB","categories":"cs.DB","published":"2025-03-31T06:52:13Z"}
{"aid":"http://arxiv.org/abs/2503.23794v1","title":"Force-Free Molecular Dynamics Through Autoregressive Equivariant\n  Networks","summary":"Molecular dynamics (MD) simulations play a crucial role in scientific\nresearch. Yet their computational cost often limits the timescales and system\nsizes that can be explored. Most data-driven efforts have been focused on\nreducing the computational cost of accurate interatomic forces required for\nsolving the equations of motion. Despite their success, however, these machine\nlearning interatomic potentials (MLIPs) are still bound to small time-steps. In\nthis work, we introduce TrajCast, a transferable and data-efficient framework\nbased on autoregressive equivariant message passing networks that directly\nupdates atomic positions and velocities lifting the constraints imposed by\ntraditional numerical integration. We benchmark our framework across various\nsystems, including a small molecule, crystalline material, and bulk liquid,\ndemonstrating excellent agreement with reference MD simulations for structural,\ndynamical, and energetic properties. Depending on the system, TrajCast allows\nfor forecast intervals up to $30\\times$ larger than traditional MD time-steps,\ngenerating over 15 ns of trajectory data per day for a solid with more than\n4,000 atoms. By enabling efficient large-scale simulations over extended\ntimescales, TrajCast can accelerate materials discovery and explore physical\nphenomena beyond the reach of traditional simulations and experiments. An\nopen-source implementation of TrajCast is accessible under\nhttps://github.com/IBM/trajcast.","main_category":"physics.comp-ph","categories":"physics.comp-ph,cond-mat.mtrl-sci,cs.LG,physics.chem-ph","published":"2025-03-31T07:14:32Z"}
{"aid":"http://arxiv.org/abs/2503.23796v1","title":"On-device Sora: Enabling Training-Free Diffusion-based Text-to-Video\n  Generation for Mobile Devices","summary":"We present On-device Sora, the first model training-free solution for\ndiffusion-based on-device text-to-video generation that operates efficiently on\nsmartphone-grade devices. To address the challenges of diffusion-based\ntext-to-video generation on computation- and memory-limited mobile devices, the\nproposed On-device Sora applies three novel techniques to pre-trained video\ngenerative models. First, Linear Proportional Leap (LPL) reduces the excessive\ndenoising steps required in video diffusion through an efficient leap-based\napproach. Second, Temporal Dimension Token Merging (TDTM) minimizes intensive\ntoken-processing computation in attention layers by merging consecutive tokens\nalong the temporal dimension. Third, Concurrent Inference with Dynamic Loading\n(CI-DL) dynamically partitions large models into smaller blocks and loads them\ninto memory for concurrent model inference, effectively addressing the\nchallenges of limited device memory. We implement On-device Sora on the iPhone\n15 Pro, and the experimental evaluations show that it is capable of generating\nhigh-quality videos on the device, comparable to those produced by high-end\nGPUs. These results show that On-device Sora enables efficient and high-quality\nvideo generation on resource-constrained mobile devices. We envision the\nproposed On-device Sora as a significant first step toward democratizing\nstate-of-the-art generative technologies, enabling video generation on\ncommodity mobile and embedded devices without resource-intensive re-training\nfor model optimization (compression). The code implementation is available at a\nGitHub repository(https://github.com/eai-lab/On-device-Sora).","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T07:19:09Z"}
{"aid":"http://arxiv.org/abs/2503.23813v1","title":"Evaluation of a Virtual Laboratory Platform in General Education on\n  Quantum Information Science","summary":"Quantum information science and technology has been revolutionizing our daily\nlife, which attracts the curiosity of young generations from diverse\nbackgrounds. While it is quite challenging to teach and learn quantum\ninformation science for non-physics majors due to the abstract and counter\nintuitive nature of quantum mechanics. To address such challenges, virtual\nlaboratories have offered an effective solution. This paper presents the\nresults of pedagogical research on the efficacy of a virtual laboratory\nplatform in general education courses on quantum information science.\nSpecifically, a virtual lab activity on the Bell test was developed using the\ncommercially available platform QLab. This activity aims to help undergraduates\nfrom diverse disciplines grasp the counterintuitive yet fundamental concept of\nquantum entanglement, famously referred to by Albert Einstein as \"spooky action\nat a distance.\" Qualitative and quantitative evaluations were conducted over\nthree academic years, demonstrating that the virtual laboratory enabled over 80\n\\% of students to comprehend the complex concept and characteristics of quantum\nentanglement. This study provides an effective solution for addressing the\nchallenges of teaching quantum information science in undergraduate general\neducation courses, particularly for students from both science and non-science\nbackgrounds.","main_category":"physics.ed-ph","categories":"physics.ed-ph","published":"2025-03-31T07:47:24Z"}
{"aid":"http://arxiv.org/abs/2503.23814v1","title":"An extension of linear self-attention for in-context learning","summary":"In-context learning is a remarkable property of transformers and has been the\nfocus of recent research. An attention mechanism is a key component in\ntransformers, in which an attention matrix encodes relationships between words\nin a sentence and is used as weights for words in a sentence. This mechanism is\neffective for capturing language representations. However, it is questionable\nwhether naive self-attention is suitable for in-context learning in general\ntasks, since the computation implemented by self-attention is somewhat\nrestrictive in terms of matrix multiplication. In fact, we may need appropriate\ninput form designs when considering heuristic implementations of computational\nalgorithms. In this paper, in case of linear self-attention, we extend it by\nintroducing a bias matrix in addition to a weight matrix for an input. Despite\nthe simple extension, the extended linear self-attention can output any\nconstant matrix, input matrix and multiplications of two or three matrices in\nthe input. Note that the second property implies that it can be a skip\nconnection. Therefore, flexible matrix manipulations can be implemented by\nconnecting the extended linear self-attention components. As an example of\nimplementation using the extended linear self-attention, we show a heuristic\nconstruction of a batch-type gradient descent of ridge regression under a\nreasonable input form.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T07:49:05Z"}
{"aid":"http://arxiv.org/abs/2503.23821v1","title":"Science4Peace: A Plea for Continued Peaceful International Scientific\n  Cooperation (Input to the European Strategy for Particle Physics -- 2026\n  update)","summary":"The European Strategy for Particle Physics (ESPP) - 2026 update is taking\nplace in a turbulent international climate. Many of the norms that have\ngoverned relations between states for decades are being broken or challenged.\nThe future progress of science in general, and particle physics in particular,\nwill depend on our ability to maintain peaceful international scientific\ncollaboration in the face of political pressures. We plead that the ESPP 2026\nupdate acknowledge explicitly the importance of peaceful international\nscientific collaboration, not only for the progress of science, but also as a\nprecious bridge between geopolitical blocs.\n  \"Scientific thought is the common heritage of mankind\" - Abdus Salam","main_category":"physics.soc-ph","categories":"physics.soc-ph,hep-ex,hep-ph,hep-th","published":"2025-03-31T08:15:42Z"}
{"aid":"http://arxiv.org/abs/2503.23824v1","title":"On the Reproducibility of Learned Sparse Retrieval Adaptations for Long\n  Documents","summary":"Document retrieval is one of the most challenging tasks in Information\nRetrieval. It requires handling longer contexts, often resulting in higher\nquery latency and increased computational overhead. Recently, Learned Sparse\nRetrieval (LSR) has emerged as a promising approach to address these\nchallenges. Some have proposed adapting the LSR approach to longer documents by\naggregating segmented document using different post-hoc methods, including\nn-grams and proximity scores, adjusting representations, and learning to\nensemble all signals. In this study, we aim to reproduce and examine the\nmechanisms of adapting LSR for long documents. Our reproducibility experiments\nconfirmed the importance of specific segments, with the first segment\nconsistently dominating document retrieval performance. Furthermore, We\nre-evaluate recently proposed methods -- ExactSDM and SoftSDM -- across varying\ndocument lengths, from short (up to 2 segments) to longer (3+ segments). We\nalso designed multiple analyses to probe the reproduced methods and shed light\non the impact of global information on adapting LSR to longer contexts. The\ncomplete code and implementation for this project is available at:\nhttps://github.com/lionisakis/Reproducibilitiy-lsr-long.","main_category":"cs.IR","categories":"cs.IR","published":"2025-03-31T08:19:31Z"}
{"aid":"http://arxiv.org/abs/2503.23828v1","title":"High-Throughput Exploration of NV-like Color Centers Across Host\n  Materials","summary":"Point defects in semiconductors offer a promising platform for advancing\nquantum technologies due to their localized energy states and controllable spin\nproperties. Prior research has focused on a limited set of defects within\nmaterials such as diamond, silicon carbide, and hexagonal boron nitride. We\npresent a high-throughput study to systematically identify and evaluate point\ndefects across a diverse range of host materials, aiming to uncover previously\nunexplored defects in novel host materials suitable for use in quantum\napplications. A range of host materials are selected for their desirable\nproperties, such as appropriate bandgaps, crystal structure, and absence of d-\nor f-electrons. The Automatic Defect Analysis and Qualification (ADAQ) software\nframework is used to generate vacancies, substitutions with s- and p-elements,\nand interstitials in these materials and use density functional theory to\ncalculate key properties such as Zero-Phonon Lines (ZPLs), ionic displacements,\nTransition Dipole Moments (TDMs), and formation energies. Special attention is\ngiven to charge correction methods for materials with dielectric anisotropy. We\nuncover new defect-host combinations with advantageous properties for quantum\napplications: 28 defects across 11 isotropic and 2 anisotropic host materials\nshow properties similar to the nitrogen-vacancy (NV) center in diamond.\nBeryllium (Be) substitutional defects in SrS, MgS, and SrO emerge as particu-\nlarly promising. These findings contribute to diversifying and enhancing the\nmaterials available for quantum technologies.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-31T08:22:24Z"}
{"aid":"http://arxiv.org/abs/2503.23839v1","title":"Three-dimensional Optical Reconstruction of colloidal electrokinetics\n  via multiplane imaging","summary":"Selective manipulation of particles is crucial in many fields, ranging from\nchemistry to biology and physics. Dielectrophoresis stands out due to its high\nselectivity potential and the absence of need for labels. To fully understand\nand control the phenomenon, observation of the dynamic of nanoparticles under\nDEP needs to be performed in the three spatial dimensions. However, not many\nmicroscopy approaches offer such capability at fast frame rates (>100fps) and\nhigh resolution. Here, we used widefield microscopy, to follow the\nspatiotemporal dynamics of fluorescently labelled polystyrene nanoparticles of\n200 nm under positive and negative dielectrophoresis conditions. This real-time\n3D imaging technique allows for single particle tracking, enabling\nsuper-resolved reconstruction of the DEP force and electrokinetic flows with\nunprecedented detail. We compare the differences for positive and negative\ndielectrophoresis conditions and rationalize these by direct comparison with\ndynamic modeling results. The framework shown here shows great promise to\nelucidate the frequency-dependent DEP behavior of nanoparticle, crucial for\nparticle manipulation and sorting.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-03-31T08:33:42Z"}
{"aid":"http://arxiv.org/abs/2503.23876v1","title":"Populations of evolved massive binary stars in the Small Magellanic\n  Cloud I: Predictions from detailed evolution models","summary":"Context. The majority of massive stars are born with a close binary\ncompanion. How this affects their evolution and fate is still largely\nuncertain, especially at low metallicity. Aims. We derive synthetic populations\nof massive post-interaction binary products and compare them with corresponding\nobserved populations in the Small Magellanic Cloud (SMC). Methods. We analyse\n53298 detailed binary evolutionary models computed with MESA. Our models\ninclude the physics of rotation, mass and angular momentum transfer, magnetic\ninternal angular momentum transport, and tidal spin-orbit coupling. They cover\ninitial primary masses of 5-100Msun, initial mass ratios of 0.3-0.95, and all\ninitial periods for which interaction is expected. They are evolved through the\nfirst mass transfer and the donor star death, a possible ensuing Be/X-ray\nbinary phase, and they end when the mass gainer leaves the main sequence.\nResults.In our fiducial synthetic population, 8% of the OB stars in the SMC are\npost-mass transfer systems, and 7% are merger products. In many of our models,\nthe mass gainers are spun up and form Oe/Be stars. While our model\nunderpredicts the number of Be/X-ray binaries in the SMC, it reproduces the\nmain features of their orbital period distribution and the observed number of\nSMC binary WR stars. We expect $\\sim$50 OB+BH binaries below and $\\sim$170\nabove 20d orbital period. The latter might produce merging double BHs. However,\ntheir progenitors, the predicted long-period WR+OB binaries, are not observed.\nConclusions. While the comparison with the observed SMC stars supports many\nphysics assumptions in our high-mass binary models, a better match of the large\nnumber of observed OBe stars and Be/X-ray binaries likely requires a lower\nmerger rate and/or a higher mass transfer efficiency during the first mass\ntransfer. The fate of the initially wide O star binaries remains uncertain.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA,astro-ph.HE","published":"2025-03-31T09:26:52Z"}
{"aid":"http://arxiv.org/abs/2503.23896v1","title":"Feature learning from non-Gaussian inputs: the case of Independent\n  Component Analysis in high dimensions","summary":"Deep neural networks learn structured features from complex, non-Gaussian\ninputs, but the mechanisms behind this process remain poorly understood. Our\nwork is motivated by the observation that the first-layer filters learnt by\ndeep convolutional neural networks from natural images resemble those learnt by\nindependent component analysis (ICA), a simple unsupervised method that seeks\nthe most non-Gaussian projections of its inputs. This similarity suggests that\nICA provides a simple, yet principled model for studying feature learning.\nHere, we leverage this connection to investigate the interplay between data\nstructure and optimisation in feature learning for the most popular ICA\nalgorithm, FastICA, and stochastic gradient descent (SGD), which is used to\ntrain deep networks. We rigorously establish that FastICA requires at least\n$n\\gtrsim d^4$ samples to recover a single non-Gaussian direction from\n$d$-dimensional inputs on a simple synthetic data model. We show that vanilla\nonline SGD outperforms FastICA, and prove that the optimal sample complexity $n\n\\gtrsim d^2$ can be reached by smoothing the loss, albeit in a data-dependent\nway. We finally demonstrate the existence of a search phase for FastICA on\nImageNet, and discuss how the strong non-Gaussianity of said images compensates\nfor the poor sample complexity of FastICA.","main_category":"stat.ML","categories":"stat.ML,cond-mat.dis-nn,cond-mat.stat-mech,cs.LG,math.PR","published":"2025-03-31T09:46:47Z"}
{"aid":"http://arxiv.org/abs/2503.23899v1","title":"Rubrik's Cube: Testing a New Rubric for Evaluating Explanations on the\n  CUBE dataset","summary":"The performance and usability of Large-Language Models (LLMs) are driving\ntheir use in explanation generation tasks. However, despite their widespread\nadoption, LLM explanations have been found to be unreliable, making it\ndifficult for users to distinguish good from bad explanations. To address this\nissue, we present Rubrik's CUBE, an education-inspired rubric and a dataset of\n26k explanations, written and later quality-annotated using the rubric by both\nhumans and six open- and closed-source LLMs. The CUBE dataset focuses on two\nreasoning and two language tasks, providing the necessary diversity for us to\neffectively test our proposed rubric. Using Rubrik, we find that explanations\nare influenced by both task and perceived difficulty. Low quality stems\nprimarily from a lack of conciseness in LLM-generated explanations, rather than\ncohesion and word choice. The full dataset, rubric, and code will be made\navailable upon acceptance.","main_category":"cs.CL","categories":"cs.CL,I.2.7","published":"2025-03-31T09:48:59Z"}
{"aid":"http://arxiv.org/abs/2503.23923v1","title":"What the F*ck Is Artificial General Intelligence?","summary":"Artificial general intelligence (AGI) is an established field of research.\nYet Melanie Mitchell and others have questioned if the term still has meaning.\nAGI has been subject to so much hype and speculation it has become something of\na Rorschach test. Mitchell points out that the debate will only be settled\nthrough long term, scientific investigation. To that end here is a short,\naccessible and provocative overview of AGI. I compare definitions of\nintelligence, settling on intelligence in terms of adaptation and AGI as an\nartificial scientist. Taking my queue from Sutton's Bitter Lesson I describe\ntwo foundational tools used to build adaptive systems: search and\napproximation. I compare pros, cons, hybrids and architectures like o3,\nAlphaGo, AERA, NARS and Hyperon. I then discuss overall meta-approaches to\nmaking systems behave more intelligently. I divide them into scale-maxing,\nsimp-maxing, w-maxing based on the Bitter Lesson, Ockham's and Bennett's\nRazors. These maximise resources, simplicity of form, and the weakness of\nconstraints on functionality. I discuss examples including AIXI, the free\nenergy principle and The Embiggening of language models. I conclude that though\nscale-maxed approximation dominates, AGI will be a fusion of tools and\nmeta-approaches. The Embiggening was enabled by improvements in hardware. Now\nthe bottlenecks are sample and energy efficiency.","main_category":"cs.AI","categories":"cs.AI","published":"2025-03-31T10:15:37Z"}
{"aid":"http://arxiv.org/abs/2503.23937v1","title":"Electromagnetic multipole expansions and the logarithmic soft photon\n  theorem","summary":"We study the general structure of the electromagnetic field in the vicinity\nof spatial infinity. Starting from the general solution of the sourced Maxwell\nequations written in terms of multipole moments as obtained by Iyer and Damour,\nwe derive the expansion of the electromagnetic field perturbatively in the\nelectromagnetic coupling. At leading order, where the effect of long-range\nCoulombic interactions between charged particles is neglected, we discover\ninfinite sets of antipodal matching relations satisfied by the electromagnetic\nfield, which extend and sometimes correct previously known relations. At\nnext-to-leading order, electromagnetic tails resulting from these Coulombic\ninteractions appear, which affect the antipodal matching relations beyond those\nequivalent to the leading soft photon theorem. Moreover, new antipodal matching\nrelations arise, which we use to re-derive the classical logarithmic soft\nphoton theorem of Sahoo and Sen. Our analysis largely builds upon that of\nCampiglia and Laddha, although it invalidates the antipodal matching relation\nwhich they originally used in their derivation.","main_category":"hep-th","categories":"hep-th","published":"2025-03-31T10:35:22Z"}
{"aid":"http://arxiv.org/abs/2503.23951v1","title":"JointTuner: Appearance-Motion Adaptive Joint Training for Customized\n  Video Generation","summary":"Recent text-to-video advancements have enabled coherent video synthesis from\nprompts and expanded to fine-grained control over appearance and motion.\nHowever, existing methods either suffer from concept interference due to\nfeature domain mismatch caused by naive decoupled optimizations or exhibit\nappearance contamination induced by spatial feature leakage resulting from the\nentanglement of motion and appearance in reference video reconstructions. In\nthis paper, we propose JointTuner, a novel adaptive joint training framework,\nto alleviate these issues. Specifically, we develop Adaptive LoRA, which\nincorporates a context-aware gating mechanism, and integrate the gated LoRA\ncomponents into the spatial and temporal Transformers within the diffusion\nmodel. These components enable simultaneous optimization of appearance and\nmotion, eliminating concept interference. In addition, we introduce the\nAppearance-independent Temporal Loss, which decouples motion patterns from\nintrinsic appearance in reference video reconstructions through an\nappearance-agnostic noise prediction task. The key innovation lies in adding\nframe-wise offset noise to the ground-truth Gaussian noise, perturbing its\ndistribution, thereby disrupting spatial attributes associated with frames\nwhile preserving temporal coherence. Furthermore, we construct a benchmark\ncomprising 90 appearance-motion customized combinations and 10 multi-type\nautomatic metrics across four dimensions, facilitating a more comprehensive\nevaluation for this customization task. Extensive experiments demonstrate the\nsuperior performance of our method compared to current advanced approaches.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T11:04:07Z"}
{"aid":"http://arxiv.org/abs/2503.23992v1","title":"A cost of capital approach to determining the LGD discount rate","summary":"Loss Given Default (LGD) is a key risk parameter in determining a bank's\nregulatory capital. During LGD-estimation, realised recovery cash flows are to\nbe discounted at an appropriate rate. Regulatory guidance mandates that this\nrate should allow for the time value of money, as well as include a risk\npremium that reflects the \"undiversifiable risk\" within these recoveries.\nHaving extensively reviewed earlier methods of determining this rate, we\npropose a new approach that is inspired by the cost of capital approach from\nthe Solvency II regulatory regime. Our method involves estimating a\nmarket-consistent price for a portfolio of defaulted loans, from which an\nassociated discount rate may be inferred. We apply this method to mortgage and\npersonal loans data from a large South African bank. The results reveal the\nmain drivers of the discount rate to be the mean and variance of these\nrecoveries, as well as the bank's cost of capital in excess of the risk-free\nrate. Our method therefore produces a discount rate that reflects both the\nundiversifiable risk of recovery recoveries and the time value of money,\nthereby satisfying regulatory requirements. This work can subsequently enhance\nthe LGD-component within the modelling of both regulatory and economic capital.","main_category":"q-fin.RM","categories":"q-fin.RM,q-fin.ST","published":"2025-03-31T12:09:21Z"}
{"aid":"http://arxiv.org/abs/2503.24008v1","title":"H2VU-Benchmark: A Comprehensive Benchmark for Hierarchical Holistic\n  Video Understanding","summary":"With the rapid development of multimodal models, the demand for assessing\nvideo understanding capabilities has been steadily increasing. However,\nexisting benchmarks for evaluating video understanding exhibit significant\nlimitations in coverage, task diversity, and scene adaptability. These\nshortcomings hinder the accurate assessment of models' comprehensive video\nunderstanding capabilities. To tackle this challenge, we propose a hierarchical\nand holistic video understanding (H2VU) benchmark designed to evaluate both\ngeneral video and online streaming video comprehension. This benchmark\ncontributes three key features:\n  Extended video duration: Spanning videos from brief 3-second clips to\ncomprehensive 1.5-hour recordings, thereby bridging the temporal gaps found in\ncurrent benchmarks. Comprehensive assessment tasks: Beyond traditional\nperceptual and reasoning tasks, we have introduced modules for\ncountercommonsense comprehension and trajectory state tracking. These additions\ntest the models' deep understanding capabilities beyond mere prior knowledge.\nEnriched video data: To keep pace with the rapid evolution of current AI\nagents, we have expanded first-person streaming video datasets. This expansion\nallows for the exploration of multimodal models' performance in understanding\nstreaming videos from a first-person perspective. Extensive results from H2VU\nreveal that existing multimodal large language models (MLLMs) possess\nsubstantial potential for improvement in our newly proposed evaluation tasks.\nWe expect that H2VU will facilitate advancements in video understanding\nresearch by offering a comprehensive and in-depth analysis of MLLMs.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T12:32:51Z"}
{"aid":"http://arxiv.org/abs/2503.24013v1","title":"You Cannot Feed Two Birds with One Score: the Accuracy-Naturalness\n  Tradeoff in Translation","summary":"The goal of translation, be it by human or by machine, is, given some text in\na source language, to produce text in a target language that simultaneously 1)\npreserves the meaning of the source text and 2) achieves natural expression in\nthe target language. However, researchers in the machine translation community\nusually assess translations using a single score intended to capture semantic\naccuracy and the naturalness of the output simultaneously. In this paper, we\nbuild on recent advances in information theory to mathematically prove and\nempirically demonstrate that such single-score summaries do not and cannot give\nthe complete picture of a system's true performance. Concretely, we prove that\na tradeoff exists between accuracy and naturalness and demonstrate it by\nevaluating the submissions to the WMT24 shared task. Our findings help explain\nwell-known empirical phenomena, such as the observation that optimizing\ntranslation systems for a specific accuracy metric (like BLEU) initially\nimproves the system's naturalness, while ``overfitting'' the system to the\nmetric can significantly degrade its naturalness. Thus, we advocate for a\nchange in how translations are evaluated: rather than comparing systems using a\nsingle number, they should be compared on an accuracy-naturalness plane.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T12:39:51Z"}
{"aid":"http://arxiv.org/abs/2503.24023v1","title":"Coherent microwave control of coupled electron-muon centers","summary":"Coherent control by means of tailored excitation is a key to versatile\nexperimental schemes for spectroscopic investigation and technological\nutilization of quantum systems. Here we study a quantum system which consists\nof a coupled electron-moun spin state, i.e., muonium, a light isotope of\nhydrogen. We demonstrate the most fundamental coherent control techniques by\nmicrowave excitation of spin transitions, namely driven Rabi oscillations and\nRamsey fringes upon free evolution. Unprecedented performance is achieved by\nthe microwave hardware devised for these experiments, which enables coherent\nspin manipulation of individual, isolated, muonium centers. For muonium formed\nin SiO$_2$ with strong electron-muon hyperfine interaction, a virtually\nundamped free precession signal is observed up to a 3.5 $\\mu$s time window. For\nmuonium formed in Si with weak and anisotropic hyperfine interaction, a strong\ndrive at the multi-quantum transition decouples the muonium center from its\nmagnetic environment formed by the bath of $^{29}$Si nuclear spins at natural\nabundance. We expect that these capabilities will provide a powerful tool to\ninvestigate the effect of the environment on isolated coupled spins, uncover\nthe details of coupled electron-muon systems in matter and validate quantum\nelectrodynamics in the context of muonium spectroscopy.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T12:50:05Z"}
{"aid":"http://arxiv.org/abs/2503.24032v1","title":"BBoxCut: A Targeted Data Augmentation Technique for Enhancing Wheat Head\n  Detection Under Occlusions","summary":"Wheat plays a critical role in global food security, making it one of the\nmost extensively studied crops. Accurate identification and measurement of key\ncharacteristics of wheat heads are essential for breeders to select varieties\nfor cross-breeding, with the goal of developing nutrient-dense, resilient, and\nsustainable cultivars. Traditionally, these measurements are performed\nmanually, which is both time-consuming and inefficient. Advances in digital\ntechnologies have paved the way for automating this process. However, field\nconditions pose significant challenges, such as occlusions of leaves,\noverlapping wheat heads, varying lighting conditions, and motion blur. In this\npaper, we propose a novel data augmentation technique, BBoxCut, which uses\nrandom localized masking to simulate occlusions caused by leaves and\nneighboring wheat heads. We evaluated our approach using three state-of-the-art\nobject detectors and observed mean average precision (mAP) gains of 2.76, 3.26,\nand 1.9 for Faster R-CNN, FCOS, and DETR, respectively. Our augmentation\ntechnique led to significant improvements both qualitatively and\nquantitatively. In particular, the improvements were particularly evident in\nscenarios involving occluded wheat heads, demonstrating the robustness of our\nmethod in challenging field conditions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T12:59:02Z"}
{"aid":"http://arxiv.org/abs/2503.24033v1","title":"Independence of $\\ell$","summary":"We prove independence of $\\ell$ for Betti numbers as well as for\ncharacteristic polynomials of motivically defined endomorphisms of $\\ell$-adic\ncohomology. This long standing problem is solved through the construction of\nnew comparison isomorphisms relating $\\ell$-adic cohomology of a separated\nscheme of finite type over an algebraically closed field of positive\ncharacteristic with its rigid cohomology. Taking advantage of the description\nof categories of $\\ell$-adic sheaves of geometric origin as categories of\nmodules over $\\ell$-adic cohomology in the stable category of motivic sheaves,\nthese independence of $\\ell$-results are promoted to independence of $\\ell$ of\nsuitable categories of $\\ell$-adic sheaves themselves.","main_category":"math.AG","categories":"math.AG,math.KT,math.NT","published":"2025-03-31T12:59:51Z"}
{"aid":"http://arxiv.org/abs/2503.24046v1","title":"Contrasting exchange-field and spin-transfer torque driving mechanisms\n  in all-electric electron spin resonance","summary":"Understanding the coherent properties of electron spins driven by electric\nfields is crucial for their potential application in quantum-coherent\nnanoscience. In this work, we address two distinct driving mechanisms in\nelectric-field driven electron-spin resonance as implemented in scanning\ntunneling spectroscopy. We study the origin of the driving field using a single\norbital Anderson impurity, connected to polarized leads and biased by a voltage\nmodulated on resonance with a spin transition. By mapping the quantum master\nequation into a system of equations for the impurity spin, we identify two\ndistinct driving mechanisms. Below the charging thresholds of the impurity,\nelectron spin resonance is dominated by a magnetically exchange-driven\nmechanism or field-like torque. Conversely, above the charging threshold\nspin-transfer torque caused by the spin-polarized current through the impurity\ndrives the spin transition. Only the first mechanism enables coherent quantum\nspin control, while the second one leads to fast decoherence and spin\naccumulation towards a non-equilibrium steady-state. The electron spin\nresonance signals and spin dynamics vary significantly depending on which\ndriving mechanism dominates, highlighting the potential for optimizing\nquantum-coherent control in electrically driven quantum systems.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,quant-ph","published":"2025-03-31T13:10:22Z"}
{"aid":"http://arxiv.org/abs/2503.24062v1","title":"Artificial Conversations, Real Results: Fostering Language Detection\n  with Synthetic Data","summary":"Collecting high-quality training data is essential for fine-tuning Large\nLanguage Models (LLMs). However, acquiring such data is often costly and\ntime-consuming, especially for non-English languages such as Italian. Recently,\nresearchers have begun to explore the use of LLMs to generate synthetic\ndatasets as a viable alternative. This study proposes a pipeline for generating\nsynthetic data and a comprehensive approach for investigating the factors that\ninfluence the validity of synthetic data generated by LLMs by examining how\nmodel performance is affected by metrics such as prompt strategy, text length\nand target position in a specific task, i.e. inclusive language detection in\nItalian job advertisements. Our results show that, in most cases and across\ndifferent metrics, the fine-tuned models trained on synthetic data consistently\noutperformed other models on both real and synthetic test datasets. The study\ndiscusses the practical implications and limitations of using synthetic data\nfor language detection tasks with LLMs.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-03-31T13:22:34Z"}
{"aid":"http://arxiv.org/abs/2503.24070v1","title":"HACTS: a Human-As-Copilot Teleoperation System for Robot Learning","summary":"Teleoperation is essential for autonomous robot learning, especially in\nmanipulation tasks that require human demonstrations or corrections. However,\nmost existing systems only offer unilateral robot control and lack the ability\nto synchronize the robot's status with the teleoperation hardware, preventing\nreal-time, flexible intervention. In this work, we introduce HACTS\n(Human-As-Copilot Teleoperation System), a novel system that establishes\nbilateral, real-time joint synchronization between a robot arm and\nteleoperation hardware. This simple yet effective feedback mechanism, akin to a\nsteering wheel in autonomous vehicles, enables the human copilot to intervene\nseamlessly while collecting action-correction data for future learning.\nImplemented using 3D-printed components and low-cost, off-the-shelf motors,\nHACTS is both accessible and scalable. Our experiments show that HACTS\nsignificantly enhances performance in imitation learning (IL) and reinforcement\nlearning (RL) tasks, boosting IL recovery capabilities and data efficiency, and\nfacilitating human-in-the-loop RL. HACTS paves the way for more effective and\ninteractive human-robot collaboration and data-collection, advancing the\ncapabilities of robot manipulation.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-03-31T13:28:13Z"}
{"aid":"http://arxiv.org/abs/2503.24071v1","title":"From Colors to Classes: Emergence of Concepts in Vision Transformers","summary":"Vision Transformers (ViTs) are increasingly utilized in various computer\nvision tasks due to their powerful representation capabilities. However, it\nremains understudied how ViTs process information layer by layer. Numerous\nstudies have shown that convolutional neural networks (CNNs) extract features\nof increasing complexity throughout their layers, which is crucial for tasks\nlike domain adaptation and transfer learning. ViTs, lacking the same inductive\nbiases as CNNs, can potentially learn global dependencies from the first layers\ndue to their attention mechanisms. Given the increasing importance of ViTs in\ncomputer vision, there is a need to improve the layer-wise understanding of\nViTs. In this work, we present a novel, layer-wise analysis of concepts encoded\nin state-of-the-art ViTs using neuron labeling. Our findings reveal that ViTs\nencode concepts with increasing complexity throughout the network. Early layers\nprimarily encode basic features such as colors and textures, while later layers\nrepresent more specific classes, including objects and animals. As the\ncomplexity of encoded concepts increases, the number of concepts represented in\neach layer also rises, reflecting a more diverse and specific set of features.\nAdditionally, different pretraining strategies influence the quantity and\ncategory of encoded concepts, with finetuning to specific downstream tasks\ngenerally reducing the number of encoded concepts and shifting the concepts to\nmore relevant categories.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-03-31T13:28:43Z"}
{"aid":"http://arxiv.org/abs/2503.24073v1","title":"Krylov complexity in quantum many-body scars of spin-1 models","summary":"Weak ergodicity breaking, particularly through quantum many-body scars\n(QMBS), has become a significant focus in many-body physics. Krylov state\ncomplexity quantifies the spread of quantum states within the Krylov basis and\nserves as a powerful diagnostic for analyzing nonergodic dynamics. In this\nwork, we study spin-one XXZ magnets and reveal nonergodic behavior tied to\nQMBS. For the XY model, the nematic N\\'eel state exhibits periodic revivals in\nKrylov complexity. In the generic XXZ model, we identify spin helix states as\nweakly ergodicity-breaking states, characterized by low entanglement and\nnonthermal dynamics. Across different scenarios, the Lanczos coefficients for\nscarred states display an elliptical pattern, reflecting a hidden SU(2) algebra\nthat enables analytical results for Krylov complexity and fidelity. These\nfindings, which exemplify the rare capability to characterize QMBS\nanalytically, are feasible with current experimental techniques and offer deep\ninsights into the nonergodic dynamics of interacting quantum systems.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-03-31T13:29:45Z"}
{"aid":"http://arxiv.org/abs/2503.24129v1","title":"It's a (Blind) Match! Towards Vision-Language Correspondence without\n  Parallel Data","summary":"The platonic representation hypothesis suggests that vision and language\nembeddings become more homogeneous as model and dataset sizes increase. In\nparticular, pairwise distances within each modality become more similar. This\nsuggests that as foundation models mature, it may become possible to match\nvision and language embeddings in a fully unsupervised fashion, i.e. without\nparallel data. We present the first feasibility study, and investigate\nconformity of existing vision and language foundation models in the context of\nunsupervised, or \"blind\", matching. First, we formulate unsupervised matching\nas a quadratic assignment problem and introduce a novel heuristic that\noutperforms previous solvers. We also develop a technique to find optimal\nmatching problems, for which a non-trivial match is very likely. Second, we\nconduct an extensive study deploying a range of vision and language models on\nfour datasets. Our analysis reveals that for many problem instances, vision and\nlanguage representations can be indeed matched without supervision. This\nfinding opens up the exciting possibility of embedding semantic knowledge into\nother modalities virtually annotation-free. As a proof of concept, we showcase\nan unsupervised classifier, which achieves non-trivial classification accuracy\nwithout any image-text annotation.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-03-31T14:14:25Z"}
{"aid":"http://arxiv.org/abs/2503.24150v1","title":"Learning a Canonical Basis of Human Preferences from Binary Ratings","summary":"Recent advances in generative AI have been driven by alignment techniques\nsuch as reinforcement learning from human feedback (RLHF). RLHF and related\ntechniques typically involve constructing a dataset of binary or ranked choice\nhuman preferences and subsequently fine-tuning models to align with these\npreferences. This paper shifts the focus to understanding the preferences\nencoded in such datasets and identifying common human preferences. We find that\na small subset of 21 preference categories (selected from a set of nearly 5,000\ndistinct preferences) captures >89% of preference variation across individuals.\nThis small set of preferences is analogous to a canonical basis of human\npreferences, similar to established findings that characterize human variation\nin psychology or facial recognition studies. Through both synthetic and\nempirical evaluations, we confirm that our low-rank, canonical set of human\npreferences generalizes across the entire dataset and within specific topics.\nWe further demonstrate our preference basis' utility in model evaluation, where\nour preference categories offer deeper insights into model alignment, and in\nmodel training, where we show that fine-tuning on preference-defined subsets\nsuccessfully aligns the model accordingly.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.HC","published":"2025-03-31T14:35:48Z"}
{"aid":"http://arxiv.org/abs/2503.24167v1","title":"Relative solidity for biexact groups in measure equivalence","summary":"We demonstrate a relative solidity property for the product of a nonamenable\nbiexact group with an arbitrary infinite group in the measure equivalence\nsetting. Among other applications, we obtain the following unique product\ndecomposition for products of nonamenable biexact groups, strengthening\n\\cite{Sa09}: for any nonamenable biexact groups $\\Gamma_1,\\cdots, \\Gamma_n$, if\na product group $\\Lambda_1\\times \\Lambda_2$ is measure equivalent to\n$\\times_{k=1}^n\\Gamma_k$, then there exists a partition $T_1\\sqcup\nT_2=\\{1,\\dots, n\\}$ such that $\\Lambda_i$ is measure equivalent to\n$\\times_{k\\in T_i}\\Gamma_k$ for $i=1,2$.","main_category":"math.OA","categories":"math.OA,math.GR","published":"2025-03-31T14:48:48Z"}
{"aid":"http://arxiv.org/abs/2503.24168v1","title":"The Compact Linear e$^+$e$^-$ Collider (CLIC)","summary":"The Compact Linear Collider (CLIC) is a TeV-scale high-luminosity linear\ne$^+$e$^-$ collider studied by the international CLIC and CLICdp\ncollaborations. CLIC uses a two-beam acceleration scheme, in which\nnormal-conducting high-gradient 12 GHz accelerating structures are powered via\na high-current drive beam. CLIC is foreseen to be built and operated in stages.\nThe initial 380 GeV stage, with a site length of 11 km, optimally combines the\nexploration of Higgs and top-quark physics, including a top threshold scan near\n350 GeV. A higher-energy stage, still using the initial single drive-beam\ncomplex, can be optimised for any energy up to 2 TeV. Parameters are presented\nin detail for a 1.5 TeV stage, with a site length of 29 km. Since the 2018\nESPPU reporting, significant effort was invested in CLIC accelerator\noptimisation, technology developments and system tests, including collaboration\nwith new-generation light sources and free-electron lasers. CLIC implementation\naspects at CERN have covered detailed studies of civil engineering, electrical\nnetworks, cooling and ventilation, scheduling, and costing. The CLIC baseline\nat 380 GeV is now 100 Hz operation, with a luminosity of 4.5$\\times\n10^{34}$\\,cm$^{-2}$s$^{-1}$ and a power consumption of 166 MW. Compared to the\n2018 design, this gives three times higher luminosity-per-power. The new\nbaseline has two beam-delivery systems, allowing for two detectors operating in\nparallel. The cost estimate of the 380 GeV baseline is approximately 7.17\nbillion CHF. The construction of the first CLIC energy stage could start as\nearly as 2033 with first beams available by 2041. This report summarises the\nCLIC project, its implementation and running scenarios, with emphasis on new\ndevelopments and recent progress. It concludes with an update on the CLIC\ndetector studies and on the physics potential in light of the improved\naccelerator performance.","main_category":"physics.acc-ph","categories":"physics.acc-ph","published":"2025-03-31T14:48:58Z"}
{"aid":"http://arxiv.org/abs/2503.24180v1","title":"Navi-plus: Managing Ambiguous GUI Navigation Tasks with Follow-up","summary":"Graphical user interfaces (GUI) automation agents are emerging as powerful\ntools, enabling humans to accomplish increasingly complex tasks on smart\ndevices. However, users often inadvertently omit key information when conveying\ntasks, which hinders agent performance in the current agent paradigm that does\nnot support immediate user intervention. To address this issue, we introduce a\n$\\textbf{Self-Correction GUI Navigation}$ task that incorporates interactive\ninformation completion capabilities within GUI agents. We developed the\n$\\textbf{Navi-plus}$ dataset with GUI follow-up question-answer pairs,\nalongside a $\\textbf{Dual-Stream Trajectory Evaluation}$ method to benchmark\nthis new capability. Our results show that agents equipped with the ability to\nask GUI follow-up questions can fully recover their performance when faced with\nambiguous user tasks.","main_category":"cs.CV","categories":"cs.CV,cs.HC","published":"2025-03-31T14:56:24Z"}
{"aid":"http://arxiv.org/abs/2503.24203v1","title":"Traffic Engineering in Large-scale Networks with Generalizable Graph\n  Neural Networks","summary":"Traffic engineering (TE) in large-scale computer networks has become a\nfundamental yet challenging problem, owing to the swift growth of global-scale\ncloud wide-area networks or backbone low-Earth-orbit satellite constellations.\nTo address the scalability issue of traditional TE algorithms, learning-based\napproaches have been proposed, showing potential of significant efficiency\nimprovement over state-of-the-art methods. Nevertheless, the intrinsic\nlimitations of existing learning-based methods hinder their practical\napplication: they are not generalizable across diverse topologies and network\nconditions, incur excessive training overhead, and do not respect link\ncapacities by default.\n  This paper proposes TELGEN, a novel TE algorithm that learns to solve TE\nproblems efficiently in large-scale networks, while achieving superior\ngeneralizability across diverse network conditions. TELGEN is based on the\nnovel idea of transforming the problem of \"predicting the optimal TE solution\"\ninto \"predicting the optimal TE algorithm\", which enables TELGEN to learn and\nefficiently approximate the end-to-end solving process of classical optimal TE\nalgorithms. The learned algorithm is agnostic to the exact network topology or\ntraffic patterns, and can efficiently solve TE problems given arbitrary inputs\nand generalize well to unseen topologies and demands.\n  We trained and evaluated TELGEN on random and real-world networks with up to\n5000 nodes and 106 links. TELGEN achieved less than 3% optimality gap while\nensuring feasibility in all cases, even when the test network had up to 20x\nmore nodes than the largest in training. It also saved up to 84% solving time\nthan classical optimal solver, and could reduce training time per epoch and\nsolving time by 2-4 orders of magnitude than latest learning algorithms on the\nlargest networks.","main_category":"cs.NI","categories":"cs.NI,cs.LG","published":"2025-03-31T15:21:22Z"}
{"aid":"http://arxiv.org/abs/2503.24205v1","title":"A Comparison of Parametric Dynamic Mode Decomposition Algorithms for\n  Thermal-Hydraulics Applications","summary":"In recent years, algorithms aiming at learning models from available data\nhave become quite popular due to two factors: 1) the significant developments\nin Artificial Intelligence techniques and 2) the availability of large amounts\nof data. Nevertheless, this topic has already been addressed by methodologies\nbelonging to the Reduced Order Modelling framework, of which perhaps the most\nfamous equation-free technique is Dynamic Mode Decomposition. This algorithm\naims to learn the best linear model that represents the physical phenomena\ndescribed by a time series dataset: its output is a best state operator of the\nunderlying dynamical system that can be used, in principle, to advance the\noriginal dataset in time even beyond its span. However, in its standard\nformulation, this technique cannot deal with parametric time series, meaning\nthat a different linear model has to be derived for each parameter realization.\nResearch on this is ongoing, and some versions of a parametric Dynamic Mode\nDecomposition already exist. This work contributes to this research field by\ncomparing the different algorithms presently deployed and assessing their\nadvantages and shortcomings compared to each other. To this aim, three\ndifferent thermal-hydraulics problems are considered: two benchmark 'flow over\ncylinder' test cases at diverse Reynolds numbers, whose datasets are,\nrespectively, obtained with the FEniCS finite element solver and retrieved from\nthe CFDbench dataset, and the DYNASTY experimental facility operating at\nPolitecnico di Milano, which studies the natural circulation established by\ninternally heated fluids for Generation IV nuclear applications, whose dataset\nwas generated using the RELAP5 nodal solver.","main_category":"math.DS","categories":"math.DS,cs.LG","published":"2025-03-31T15:23:22Z"}
{"aid":"http://arxiv.org/abs/2503.24223v1","title":"Jordanian deformation of the non-compact and $\\mathfrak{sl}_2\n  $-invariant $XXX_{-1/2}$ spin-chain","summary":"Using a Drinfeld twist of Jordanian type, we construct a deformation of the\nnon-compact and $\\mathfrak{sl}_2$-invariant $XXX_{-1/2}$ spin-chain. Before the\ndeformation, the seed model can be understood as a sector of the\n$\\mathfrak{psu}(2,2|4)$-invariant spin-chain encoding the spectral problem of\n$\\mathcal{N}=4$ super Yang-Mills at one loop in the planar limit. The\ndeformation gives rise to interesting features because, while being integrable,\nthe Hamiltonian is non-hermitian and non-diagonalisable, so that it only admits\na Jordan decomposition. Moreover, the eigenvalues of the deformed Hamiltonian\ncoincide with those of the original undeformed spin-chain. We use explicit\nexamples as well as the techniques of the coordinate and of the algebraic Bethe\nansatz to discuss the construction of the (generalised) eigenvectors of the\ndeformed model. We also show that the deformed spin-chain is equivalent to an\nundeformed one with twisted boundary conditions, and that it may be derived\nfrom a scaling limit of the non-compact $U_q(\\mathfrak{sl}_2)$-invariant\n$XXZ_{-1/2} $ spin-chain.","main_category":"hep-th","categories":"hep-th,cond-mat.stat-mech,cond-mat.str-el,quant-ph","published":"2025-03-31T15:38:04Z"}
{"aid":"http://arxiv.org/abs/2503.24248v1","title":"Optimizing PCA for Health and Care Research: A Reliable Approach to\n  Component Selection","summary":"PCA is widely used in health and care research to analyze complex HD\ndatasets, such as patient health records, genetic data, and medical imaging. By\nreducing dimensionality, PCA helps identify key patterns and trends, which can\naid in disease diagnosis, treatment optimization, and the discovery of new\nbiomarkers. However, the primary goal of any dimensional reduction technique is\nto reduce the dimensionality in a data set while keeping the essential\ninformation and variability. There are a few ways to do this in practice, such\nas the Kaiser-Guttman criterion, Cattell's Scree Test, and the percent\ncumulative variance approach. Unfortunately, the results of these methods are\nentirely different. That means using inappropriate methods to find the optimal\nnumber of PCs retained in PCA may lead to misinterpreted and inaccurate results\nin PCA and PCA-related health and care research applications. This\ncontradiction becomes even more pronounced in HD settings where n < p, making\nit even more critical to determine the best approach. Therefore, it is\nnecessary to identify the issues of different techniques to select the optimal\nnumber of PCs retained in PCA. Kaiser-Guttman criterion retains fewer PCs,\ncausing overdispersion, while Cattell's scree test retains more PCs,\ncompromising reliability. The percentage of cumulative variation criterion\noffers greater stability, consistently selecting the optimal number of\ncomponents. Therefore, the Pareto chart, which shows both the cumulative\npercentage and the cut-off point for retained PCs, provides the most reliable\nmethod of selecting components, ensuring stability and enhancing PCA\neffectiveness, particularly in health-related research applications.","main_category":"stat.ME","categories":"stat.ME","published":"2025-03-31T15:58:50Z"}
{"aid":"http://arxiv.org/abs/2503.24255v1","title":"The Mysterious Phenomenon of Forward-Progressing Student Tables","summary":"This study investigates the factors that contribute to the forward movement\nof student desks throughout the school day. We hypothesize that desk movement\nis influenced not only by classroom floor type but also by the physical\ncharacteristics of students, such as height and age. Furthermore, we explore\nhow the subject taught in the classroom (e.g., Science vs. Modern Foreign\nLanguages) contributes to desk dynamics. Utilizing a Monte Carlo simulation\nmodel, we quantitatively analyse the forces at play in these phenomena. This\nresearch reveals that desks on carpeted floors are particularly prone to\nmovement, especially in science classrooms with taller and younger students.\nWhile the results may seem trivial, they provide critical insights into the\nmechanics of classroom furniture behaviour and its implications for educational\npractices. The paper offers compelling evidence that classroom furniture has a\nmind of its own or, at the very least, a subtle gravitational pull towards the\nfront of the room.","main_category":"physics.ed-ph","categories":"physics.ed-ph","published":"2025-03-31T16:03:53Z"}
{"aid":"http://arxiv.org/abs/2503.24277v1","title":"Evaluating and Designing Sparse Autoencoders by Approximating\n  Quasi-Orthogonality","summary":"Sparse autoencoders (SAEs) have emerged as a workhorse of modern mechanistic\ninterpretability, but leading SAE approaches with top-$k$ style activation\nfunctions lack theoretical grounding for selecting the hyperparameter $k$. SAEs\nare based on the linear representation hypothesis (LRH), which assumes that the\nrepresentations of large language models (LLMs) are linearly encoded, and the\nsuperposition hypothesis (SH), which states that there can be more features in\nthe model than its dimensionality. We show that, based on the formal\ndefinitions of the LRH and SH, the magnitude of sparse feature vectors (the\nlatent representations learned by SAEs of the dense embeddings of LLMs) can be\napproximated using their corresponding dense vector with a closed-form error\nbound. To visualize this, we propose the ZF plot, which reveals a previously\nunknown relationship between LLM hidden embeddings and SAE feature vectors,\nallowing us to make the first empirical measurement of the extent to which\nfeature vectors of pre-trained SAEs are over- or under-activated for a given\ninput. Correspondingly, we introduce Approximate Feature Activation (AFA),\nwhich approximates the magnitude of the ground-truth sparse feature vector, and\npropose a new evaluation metric derived from AFA to assess the alignment\nbetween inputs and activations. We also leverage AFA to introduce a novel SAE\narchitecture, the top-AFA SAE, leading to SAEs that: (a) are more in line with\ntheoretical justifications; and (b) obviate the need to tune SAE sparsity\nhyperparameters. Finally, we empirically demonstrate that top-AFA SAEs achieve\nreconstruction loss comparable to that of state-of-the-art top-k SAEs, without\nrequiring the hyperparameter $k$ to be tuned. Our code is available at:\nhttps://github.com/SewoongLee/top-afa-sae.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-03-31T16:22:11Z"}
{"aid":"http://arxiv.org/abs/2503.24295v1","title":"Brazilian input to the European Strategy for Particle Physics Update","summary":"The Brazilian High-Energy Physics (HEP) community has expanded remarkably\nsince its first involvement at CERN and Fermilab in the 1980s. Its recent\norganization under the Brazilian Network for High-Energy Physics (RENAFAE),\nsince 2008, has further strengthened its scientific and technological goals,\nparticularly in detector instrumentation, computing, and industry partnerships.\nIn 2024, Brazil became an Associate Member State of CERN, opening new\nopportunities for deeper engagement in accelerator and detector R&D. This input\nto the 2026 update of the European Strategy for Particle Physics highlights\nBrazil's current participation in LHC experiments as well as ongoing\ndevelopments in detector and accelerator technology, and details the\ncommunity's view towards future colliders. The potential for expanded\nscientific and industrial collaborations between Brazil and CERN is also\ndiscussed.","main_category":"hep-ex","categories":"hep-ex","published":"2025-03-31T16:41:38Z"}
{"aid":"http://arxiv.org/abs/2503.24327v1","title":"Thermal transport in superconductor heterostructures: some recent\n  progress","summary":"This article reviews recent advances in low-temperature electronic thermal\ntransport properties of thermally biased superconductor heterostructures\nfocusing on the two-terminal transport. Since the last decade, ferromagnetism\nhas been widely used to enhance the thermoelectricity in heterostructures based\non ordinary superconductors. The possibility of getting giant thermoelectric\neffects with optimum thermal conductance by breaking the electron-hole symmetry\nof the ordinary superconductor boosted the research in this direction.\nRecently, attention has been paid to the role of triplet Cooper pairs that\nemerged in ferromagnetic junctions and the possibility of advanced\napplications. Other forms of magnetism, specifically antiferromagnetism and\naltermagnetism, have been investigated to unravel the behavior of the thermal\nand charge current in thermally biased junctions. In parallel to ordinary\nsuperconductors, junctions with unconventional superconductors have been\nexplored for the same purpose. Thermal transport in superconducting bilayers\nhas been studied using advanced materials like Dirac and topological materials,\nincluding Weyl semimetals. Significant attention has been paid to thermally\nbiased topological Josephson junctions to explore the phase-tunable current in\nrecent times. Weyl Josephson junctions, multi-terminal Josephson junctions, and\nvarious other multilayer junctions have also been studied to engineer large\nthermoelectric effects and various functionalities with potential applications\nin superconductor-based thermal device components.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-03-31T17:17:25Z"}
{"aid":"http://arxiv.org/abs/2503.24373v1","title":"Accelerated Approximate Optimization of Multi-Commodity Flows on\n  Directed Graphs","summary":"We provide $m^{1+o(1)}k\\epsilon^{-1}$-time algorithms for computing\nmultiplicative $(1 - \\epsilon)$-approximate solutions to multi-commodity flow\nproblems with $k$-commodities on $m$-edge directed graphs, including concurrent\nmulti-commodity flow and maximum multi-commodity flow.\n  To obtain our results, we provide new optimization tools of potential\nindependent interest. First, we provide an improved optimization method for\nsolving $\\ell_{q, p}$-regression problems to high accuracy. This method makes\n$\\tilde{O}_{q, p}(k)$ queries to a high accuracy convex minimization oracle for\nan individual block, where $\\tilde{O}_{q, p}(\\cdot)$ hides factors depending\nonly on $q$, $p$, or $\\mathrm{poly}(\\log m)$, improving upon the $\\tilde{O}_{q,\np}(k^2)$ bound of [Chen-Ye, ICALP 2024]. As a result, we obtain the first\nalmost-linear time algorithm that solves $\\ell_{q, p}$ flows on directed graphs\nto high accuracy. Second, we present optimization tools to reduce approximately\nsolving composite $\\ell_{1, \\infty}$-regression problems to solving\n$m^{o(1)}\\epsilon^{-1}$ instances of composite $\\ell_{q, p}$-regression\nproblem. The method builds upon recent advances in solving box-simplex games\n[Jambulapati-Tian, NeurIPS 2023] and the area convex regularizer introduced in\n[Sherman, STOC 2017] to obtain faster rates for constrained versions of the\nproblem. Carefully combining these techniques yields our directed\nmulti-commodity flow algorithm.","main_category":"cs.DS","categories":"cs.DS,math.OC","published":"2025-03-31T17:53:00Z"}
{"aid":"http://arxiv.org/abs/2503.24377v1","title":"Harnessing the Reasoning Economy: A Survey of Efficient Reasoning for\n  Large Language Models","summary":"Recent advancements in Large Language Models (LLMs) have significantly\nenhanced their ability to perform complex reasoning tasks, transitioning from\nfast and intuitive thinking (System 1) to slow and deep reasoning (System 2).\nWhile System 2 reasoning improves task accuracy, it often incurs substantial\ncomputational costs due to its slow thinking nature and inefficient or\nunnecessary reasoning behaviors. In contrast, System 1 reasoning is\ncomputationally efficient but leads to suboptimal performance. Consequently, it\nis critical to balance the trade-off between performance (benefits) and\ncomputational costs (budgets), giving rise to the concept of reasoning economy.\nIn this survey, we provide a comprehensive analysis of reasoning economy in\nboth the post-training and test-time inference stages of LLMs, encompassing i)\nthe cause of reasoning inefficiency, ii) behavior analysis of different\nreasoning patterns, and iii) potential solutions to achieve reasoning economy.\nBy offering actionable insights and highlighting open challenges, we aim to\nshed light on strategies for improving the reasoning economy of LLMs, thereby\nserving as a valuable resource for advancing research in this evolving area. We\nalso provide a public repository to continually track developments in this\nfast-evolving field.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-03-31T17:58:07Z"}
{"aid":"http://arxiv.org/abs/2503.24379v1","title":"Any2Caption:Interpreting Any Condition to Caption for Controllable Video\n  Generation","summary":"To address the bottleneck of accurate user intent interpretation within the\ncurrent video generation community, we present Any2Caption, a novel framework\nfor controllable video generation under any condition. The key idea is to\ndecouple various condition interpretation steps from the video synthesis step.\nBy leveraging modern multimodal large language models (MLLMs), Any2Caption\ninterprets diverse inputs--text, images, videos, and specialized cues such as\nregion, motion, and camera poses--into dense, structured captions that offer\nbackbone video generators with better guidance. We also introduce Any2CapIns, a\nlarge-scale dataset with 337K instances and 407K conditions for\nany-condition-to-caption instruction tuning. Comprehensive evaluations\ndemonstrate significant improvements of our system in controllability and video\nquality across various aspects of existing video generation models. Project\nPage: https://sqwu.top/Any2Cap/","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T17:59:01Z"}
{"aid":"http://arxiv.org/abs/2503.24381v1","title":"UniOcc: A Unified Benchmark for Occupancy Forecasting and Prediction in\n  Autonomous Driving","summary":"We introduce UniOcc, a comprehensive, unified benchmark for occupancy\nforecasting (i.e., predicting future occupancies based on historical\ninformation) and current-frame occupancy prediction from camera images. UniOcc\nunifies data from multiple real-world datasets (i.e., nuScenes, Waymo) and\nhigh-fidelity driving simulators (i.e., CARLA, OpenCOOD), which provides 2D/3D\noccupancy labels with per-voxel flow annotations and support for cooperative\nautonomous driving. In terms of evaluation, unlike existing studies that rely\non suboptimal pseudo labels for evaluation, UniOcc incorporates novel metrics\nthat do not depend on ground-truth occupancy, enabling robust assessment of\nadditional aspects of occupancy quality. Through extensive experiments on\nstate-of-the-art models, we demonstrate that large-scale, diverse training data\nand explicit flow information significantly enhance occupancy prediction and\nforecasting performance.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG,cs.MA,cs.RO","published":"2025-03-31T17:59:24Z"}
{"aid":"http://arxiv.org/abs/2504.01319v1","title":"Decoupled anisotropic Charge-Phonon Transport Enables Exceptional n-Type\n  Thermoelectric Performance in CuBiSCl$_2$","summary":"First-principles calculations demonstrate an exceptional decoupling of charge\nand thermal transport along the \\textit{a}-axis in CuBiSCl$_2$. The material\nachieves superior electron mobility (138 cm$^2$/V$\\cdot$s at 300 K) through\ndelocalized Bi-6\\textit{p}/S-3\\textit{p} networks while maintaining ultralow\nlattice thermal conductivity (0.40 W/mK at 300 K) via Cu-dominated anharmonic\nphonon scattering - both optimized along the same crystallographic direction.\nThis simultaneous optimization originates from the anisotropic bonding\nhierarchy where [BiSCl$_2$]$_n$ ribbons enable efficient charge transport along\n\\textit{a}-axis, while the soft vibrational modes associated with Cu atoms\nstrongly scatter heat-carrying phonons. The resulting high power factor (1.71\nmW/mK$^2$ at 700 K) and peak \\textit{ZT} of 1.57 establish CuBiSCl$_2$ as a\nmodel system that realizes the long-sought \"phonon glass-electron crystal\"\nparadigm through crystallographically engineered transport channels.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T03:10:17Z"}
{"aid":"http://arxiv.org/abs/2504.01336v1","title":"Inverse RL Scene Dynamics Learning for Nonlinear Predictive Control in\n  Autonomous Vehicles","summary":"This paper introduces the Deep Learning-based Nonlinear Model Predictive\nController with Scene Dynamics (DL-NMPC-SD) method for autonomous navigation.\nDL-NMPC-SD uses an a-priori nominal vehicle model in combination with a scene\ndynamics model learned from temporal range sensing information. The scene\ndynamics model is responsible for estimating the desired vehicle trajectory, as\nwell as to adjust the true system model used by the underlying model predictive\ncontroller. We propose to encode the scene dynamics model within the layers of\na deep neural network, which acts as a nonlinear approximator for the high\norder state-space of the operating conditions. The model is learned based on\ntemporal sequences of range sensing observations and system states, both\nintegrated by an Augmented Memory component. We use Inverse Reinforcement\nLearning and the Bellman optimality principle to train our learning controller\nwith a modified version of the Deep Q-Learning algorithm, enabling us to\nestimate the desired state trajectory as an optimal action-value function. We\nhave evaluated DL-NMPC-SD against the baseline Dynamic Window Approach (DWA),\nas well as against two state-of-the-art End2End and reinforcement learning\nmethods, respectively. The performance has been measured in three experiments:\ni) in our GridSim virtual environment, ii) on indoor and outdoor navigation\ntasks using our RovisLab AMTU (Autonomous Mobile Test Unit) platform and iii)\non a full scale autonomous test vehicle driving on public roads.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-02T03:46:37Z"}
{"aid":"http://arxiv.org/abs/2504.01341v1","title":"Uniform convergence to the equilibrium of the homogeneous\n  Boltzmann-Fermi-Dirac Equation with moderately soft potential","summary":"We concern the long-time behavior of mild solutions to the spatially\nhomogeneous Boltzmann--Fermi--Dirac equation with moderately soft potential.\nBased on the well-posedness results in [X-G. Lu, J. Stat. Phys., 105, (2001),\n353-388], we prove that the mild solution decays algebraically to the\nFermi--Dirac statistics with an explicit rate. Under the framework of the level\nset analysis by De Giorgi, we derive an $L^\\infty$ estimate which is uniform\nwith respect to the quantum parameter $\\varepsilon$. All quantitative estimates\nare independent of $\\varepsilon$, which implies that they also hold in the\nclassical limit, i.e., the Boltzmann equation.","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T04:10:34Z"}
{"aid":"http://arxiv.org/abs/2504.01395v1","title":"From Easy to Hard: Building a Shortcut for Differentially Private Image\n  Synthesis","summary":"Differentially private (DP) image synthesis aims to generate synthetic images\nfrom a sensitive dataset, alleviating the privacy leakage concerns of\norganizations sharing and utilizing synthetic images. Although previous methods\nhave significantly progressed, especially in training diffusion models on\nsensitive images with DP Stochastic Gradient Descent (DP-SGD), they still\nsuffer from unsatisfactory performance. In this work, inspired by curriculum\nlearning, we propose a two-stage DP image synthesis framework, where diffusion\nmodels learn to generate DP synthetic images from easy to hard. Unlike existing\nmethods that directly use DP-SGD to train diffusion models, we propose an easy\nstage in the beginning, where diffusion models learn simple features of the\nsensitive images. To facilitate this easy stage, we propose to use `central\nimages', simply aggregations of random samples of the sensitive dataset.\nIntuitively, although those central images do not show details, they\ndemonstrate useful characteristics of all images and only incur minimal privacy\ncosts, thus helping early-phase model training. We conduct experiments to\npresent that on the average of four investigated image datasets, the fidelity\nand utility metrics of our synthetic images are 33.1% and 2.1% better than the\nstate-of-the-art method.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-02T06:30:55Z"}
{"aid":"http://arxiv.org/abs/2504.01405v1","title":"Teaching Robots to Handle Nuclear Waste: A Teleoperation-Based Learning\n  Approach<","summary":"This paper presents a Learning from Teleoperation (LfT) framework that\nintegrates human expertise with robotic precision to enable robots to\nautonomously perform skills learned from human operators. The proposed\nframework addresses challenges in nuclear waste handling tasks, which often\ninvolve repetitive and meticulous manipulation operations. By capturing\noperator movements and manipulation forces during teleoperation, the framework\nutilizes this data to train machine learning models capable of replicating and\ngeneralizing human skills. We validate the effectiveness of the LfT framework\nthrough its application to a power plug insertion task, selected as a\nrepresentative scenario that is repetitive yet requires precise trajectory and\nforce control. Experimental results highlight significant improvements in task\nefficiency, while reducing reliance on continuous operator involvement.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-02T06:46:29Z"}
{"aid":"http://arxiv.org/abs/2504.01408v1","title":"From Shadows to Safety: Occlusion Tracking and Risk Mitigation for Urban\n  Autonomous Driving","summary":"Autonomous vehicles (AVs) must navigate dynamic urban environments where\nocclusions and perception limitations introduce significant uncertainties. This\nresearch builds upon and extends existing approaches in risk-aware motion\nplanning and occlusion tracking to address these challenges. While prior\nstudies have developed individual methods for occlusion tracking and risk\nassessment, a comprehensive method integrating these techniques has not been\nfully explored. We, therefore, enhance a phantom agent-centric model by\nincorporating sequential reasoning to track occluded areas and predict\npotential hazards. Our model enables realistic scenario representation and\ncontext-aware risk evaluation by modeling diverse phantom agents, each with\ndistinct behavior profiles. Simulations demonstrate that the proposed approach\nimproves situational awareness and balances proactive safety with efficient\ntraffic flow. While these results underline the potential of our method,\nvalidation in real-world scenarios is necessary to confirm its feasibility and\ngeneralizability. By utilizing and advancing established methodologies, this\nwork contributes to safer and more reliable AV planning in complex urban\nenvironments. To support further research, our method is available as\nopen-source software at:\nhttps://github.com/TUM-AVS/OcclusionAwareMotionPlanning","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-02T06:48:50Z"}
{"aid":"http://arxiv.org/abs/2504.01415v1","title":"Systematic Literature Review of Automation and Artificial Intelligence\n  in Usability Issue Detection","summary":"Usability issues can hinder the effective use of software. Therefore, various\ntechniques are deployed to diagnose and mitigate them. However, these\ntechniques are costly and time-consuming, particularly in iterative design and\ndevelopment. A substantial body of research indicates that automation and\nartificial intelligence can enhance the process of obtaining usability\ninsights. In our systematic review of 155 publications, we offer a\ncomprehensive overview of the current state of the art for automated usability\nissue detection. We analyze trends, paradigms, and the technical context in\nwhich they are applied. Finally, we discuss the implications and potential\ndirections for future research.","main_category":"cs.HC","categories":"cs.HC,cs.SE","published":"2025-04-02T07:07:32Z"}
{"aid":"http://arxiv.org/abs/2504.01445v1","title":"Enabling Systematic Generalization in Abstract Spatial Reasoning through\n  Meta-Learning for Compositionality","summary":"Systematic generalization refers to the capacity to understand and generate\nnovel combinations from known components. Despite recent progress by large\nlanguage models (LLMs) across various domains, these models often fail to\nextend their knowledge to novel compositional scenarios, revealing notable\nlimitations in systematic generalization. There has been an ongoing debate\nabout whether neural networks possess the capacity for systematic\ngeneralization, with recent studies suggesting that meta-learning approaches\ndesigned for compositionality can significantly enhance this ability. However,\nthese insights have largely been confined to linguistic problems, leaving their\napplicability to other tasks an open question. In this study, we extend the\napproach of meta-learning for compositionality to the domain of abstract\nspatial reasoning. To this end, we introduce $\\textit{SYGAR}$-a dataset\ndesigned to evaluate the capacity of models to systematically generalize from\nknown geometric transformations (e.g., translation, rotation) of\ntwo-dimensional objects to novel combinations of these transformations (e.g.,\ntranslation+rotation). Our results show that a transformer-based\nencoder-decoder model, trained via meta-learning for compositionality, can\nsystematically generalize to previously unseen transformation compositions,\nsignificantly outperforming state-of-the-art LLMs, including o3-mini, GPT-4o,\nand Gemini 2.0 Flash, which fail to exhibit similar systematic behavior. Our\nfindings highlight the effectiveness of meta-learning in promoting\nsystematicity beyond linguistic tasks, suggesting a promising direction toward\nmore robust and generalizable models.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-02T07:56:39Z"}
{"aid":"http://arxiv.org/abs/2504.01447v1","title":"What KM3-230213A events may tell us about the neutrino mass and dark\n  matter","summary":"Within the framework of general $U(1)$ scenario, we demonstrate that the\nultra high energy neutrinos recently detected by KM3NeT could originate from a\ndecaying right handed neutrino dark matter (DM), with a mass of 440 PeV.\nConsidering DM production via freeze-in, we delineate the parameter space that\nsatisfies the observed relic abundance and also lies within the reach of\nmultiple gravitational wave detectors. Our study provides a testable new\nphysics scenario, enabled by multi-messenger astronomy.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO,astro-ph.HE","published":"2025-04-02T08:00:23Z"}
{"aid":"http://arxiv.org/abs/2504.01457v1","title":"Deep LG-Track: An Enhanced Localization-Confidence-Guided Multi-Object\n  Tracker","summary":"Multi-object tracking plays a crucial role in various applications, such as\nautonomous driving and security surveillance. This study introduces Deep\nLG-Track, a novel multi-object tracker that incorporates three key enhancements\nto improve the tracking accuracy and robustness. First, an adaptive Kalman\nfilter is developed to dynamically update the covariance of measurement noise\nbased on detection confidence and trajectory disappearance. Second, a novel\ncost matrix is formulated to adaptively fuse motion and appearance information,\nleveraging localization confidence and detection confidence as weighting\nfactors. Third, a dynamic appearance feature updating strategy is introduced,\nadjusting the relative weighting of historical and current appearance features\nbased on appearance clarity and localization accuracy. Comprehensive\nevaluations on the MOT17 and MOT20 datasets demonstrate that the proposed Deep\nLG-Track consistently outperforms state-of-the-art trackers across multiple\nperformance metrics, highlighting its effectiveness in multi-object tracking\ntasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T08:10:18Z"}
{"aid":"http://arxiv.org/abs/2504.01475v1","title":"Optimal Control of an Interconnected SDE -Parabolic PDE System","summary":"In this paper, we design a controller for an interconnected system where a\nlinear Stochastic Differential Equation (SDE) is actuated through a linear\nparabolic heat equation. These dynamics arise in various applications, such as\ncoupled heat transfer systems and chemical reaction processes that are subject\nto disturbances. Our goal is to develop a computational method for\napproximating the controller that minimizes a quadratic cost associated with\nthe state of the SDE component. To achieve this, we first perform a change of\nvariables to shift the actuation inside the PDE domain and reformulate the\nsystem as a linear Stochastic Partial Differential Equation (SPDE). We use a\nspectral approximation of the Laplacian operator to discretize the coupled\ndynamics into a finite-dimensional SDE and compute the optimal control for this\napproximated system. The resulting control serves as an approximation of the\noptimal control for the original system. We then establish the convergence of\nthe approximated optimal control and the corresponding closed-loop dynamics to\ntheir infinite-dimensional counterparts. Numerical simulations are provided to\nillustrate the effectiveness of our approach.","main_category":"math.AP","categories":"math.AP,math.OC","published":"2025-04-02T08:29:04Z"}
{"aid":"http://arxiv.org/abs/2504.01487v1","title":"Discrete stability estimates for the pressureless\n  Euler-Poisson-Boltzmann equations in the Quasi-Neutral limit","summary":"We propose and study a fully implicit finite volume scheme for the\npressureless Euler-Poisson-Boltzmann equations on the one dimensional torus.\nEspecially, we design a consistent and dissipative discretization of the force\nterm which yields an unconditional energy decay. In addition, we establish a\ndiscrete analogue of the modulated energy estimate around constant states with\na small velocity. Numerical experiments are carried to illustrate our\ntheoretical results and to assess the accuracy of our scheme. A test case of\nthe literature is also illustrated.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-02T08:39:02Z"}
{"aid":"http://arxiv.org/abs/2504.01505v1","title":"In-situ compression and shape recovery of Ceramic single grain\n  micro-pillar","summary":"Most ceramic materials are known for high fracture toughness while reacting\nhighly brittle to physical deformation. Some advancements were made by\nutilizing the transformation toughening effect of Yttria-doped Zirconia.\nHowever, finding a ceramic material demonstrating an effect analogous to the\nShape Memory Effect (SME) in certain metals, that also allows for superelastic\nresponses, remains a challenge. The underlying mechanism for SME and\nsuperelasticity is based on crystallographic variations within the material's\ngrains, requiring sophisticated electron microscopy techniques for direct\nobservation. The combination of a scanning electron microscope (SEM) with\nfocused ion beam (FIB) milling, a Kleindiek Nanotechnik GmbH micro-manipulator\nwith a 1.5 $\\mu$m diamond tip, and the ability to achieve in-situ heating up to\n450 {\\deg}C on a Kleindiek heating stage provides a robust platform for the\npreparation, deformation, and heating of micro-pillars made from ceramic\nmaterials. This setup enabled us to conduct detailed studies on the\nZirconia-based ceramic, observing permanent deformation exceeding 4% strain,\nfollowed by shape recovery at 370 {\\deg}C. The paper provides outlines the key\nexperimental steps that facilitated these observations.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T08:55:27Z"}
{"aid":"http://arxiv.org/abs/2504.01511v1","title":"A computational framework for evaluating tire-asphalt hysteretic\n  friction including pavement roughness","summary":"Pavement surface textures obtained by a photogrammetry-based method for data\nacquisition and analysis are employed to investigate if related roughness\ndescriptors are comparable to the frictional performance evaluated by finite\nelement analysis. Pavement surface profiles are obtained from 3D digital\nsurface models created with Close-Range Orthogonal Photogrammetry. To\ncharacterize the roughness features of analyzed profiles, selected texture\nparameters were calculated from the profile's geometry. The parameters values\nwere compared to the frictional performance obtained by numerical simulations.\nContact simulations are performed according to a dedicated finite element\nscheme where surface roughness is directly embedded into a special class of\ninterface finite elements. Simulations were performed for different case\nscenarios and the obtained results showed a notable trend between roughness\ndescriptors and friction performance, indicating a promising potential for this\nnumerical method to be consistently employed to predict the frictional\nproperties of actual pavement surface profiles.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-02T08:58:31Z"}
{"aid":"http://arxiv.org/abs/2504.01517v1","title":"Cascade topologies in rare charm decays and implications for CP\n  violation","summary":"The CP violation observed in the hadronic decays of charmed mesons remains a\npuzzling open question for theorists. Calculations relying on the assumption of\ninelastic final-state interactions occurring between the pairs of pions and\nkaons fall short of the experimental value. It has been pointed out that a\nthird channel of four pions can leave imprints on the CP asymmetries of the\ntwo-body decays. At the same time, plenty of data are available for the $4\\pi$\ndecays of charmed mesons, as well as for the rare decays\n$D^0\\to\\pi^+\\pi^-\\ell^+\\ell^-$. With this motivation, we study the cascade\ntopology $D^0\\to a_1(1260)^+(\\to \\rho(770)^0\\pi^+)\\,\\pi^-$, which has been\nmeasured to contribute significantly to the $4\\pi$ decays, and estimate its\neffect on the branching ratio of the rare decays. We also explore the\npossibility of this topology contributing to the decay amplitude of\n$D^0\\to\\pi^+\\pi^-$ and by extension to the related CP asymmetry.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-02T09:03:15Z"}
{"aid":"http://arxiv.org/abs/2504.01534v1","title":"Context-Aware Toxicity Detection in Multiplayer Games: Integrating\n  Domain-Adaptive Pretraining and Match Metadata","summary":"The detrimental effects of toxicity in competitive online video games are\nwidely acknowledged, prompting publishers to monitor player chat conversations.\nThis is challenging due to the context-dependent nature of toxicity, often\nspread across multiple messages or informed by non-textual interactions.\nTraditional toxicity detectors focus on isolated messages, missing the broader\ncontext needed for accurate moderation. This is especially problematic in video\ngames, where interactions involve specialized slang, abbreviations, and typos,\nmaking it difficult for standard models to detect toxicity, especially given\nits rarity. We adapted RoBERTa LLM to support moderation tailored to video\ngames, integrating both textual and non-textual context. By enhancing\npretrained embeddings with metadata and addressing the unique slang and\nlanguage quirks through domain adaptive pretraining, our method better captures\nthe nuances of player interactions. Using two gaming datasets - from Defense of\nthe Ancients 2 (DOTA 2) and Call of Duty$^\\circledR$: Modern\nWarfare$^\\circledR$III (MWIII) we demonstrate which sources of context\n(metadata, prior interactions...) are most useful, how to best leverage them to\nboost performance, and the conditions conducive to doing so. This work\nunderscores the importance of context-aware and domain-specific approaches for\nproactive moderation.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T09:21:41Z"}
{"aid":"http://arxiv.org/abs/2504.01538v1","title":"AI-Newton: A Concept-Driven Physical Law Discovery System without Prior\n  Physical Knowledge","summary":"Current limitations in human scientific discovery necessitate a new research\nparadigm. While advances in artificial intelligence (AI) offer a highly\npromising solution, enabling AI to emulate human-like scientific discovery\nremains an open challenge. To address this, we propose AI-Newton, a\nconcept-driven discovery system capable of autonomously deriving physical laws\nfrom raw data -- without supervision or prior physical knowledge. The system\nintegrates a knowledge base and knowledge representation centered on physical\nconcepts, along with an autonomous discovery workflow. As a proof of concept,\nwe apply AI-Newton to a large set of Newtonian mechanics problems. Given\nexperimental data with noise, the system successfully rediscovers fundamental\nlaws, including Newton's second law, energy conservation and law of\ngravitation, using autonomously defined concepts. This achievement marks a\nsignificant step toward AI-driven autonomous scientific discovery.","main_category":"cs.AI","categories":"cs.AI,cs.LG,cs.SC,hep-ph,physics.class-ph","published":"2025-04-02T09:25:34Z"}
{"aid":"http://arxiv.org/abs/2504.01551v1","title":"Identifying Macro Causal Effects in C-DMGs","summary":"Causal effect identification using causal graphs is a fundamental challenge\nin causal inference. While extensive research has been conducted in this area,\nmost existing methods assume the availability of fully specified causal graphs.\nHowever, in complex domains such as medicine and epidemiology, complete causal\nknowledge is often unavailable, and only partial information about the system\nis accessible. This paper focuses on causal effect identification within\npartially specified causal graphs, with particular emphasis on cluster-directed\nmixed graphs (C-DMGs). These graphs provide a higher-level representation of\ncausal relationships by grouping variables into clusters, offering a more\npractical approach for handling complex systems. Unlike fully specified causal\ngraphs, C-DMGs can contain cycles, which complicate their analysis and\ninterpretation. Furthermore, their cluster-based nature introduces new\nchallenges, as it gives rise to two distinct types of causal effects, macro\ncausal effects and micro causal effects, with different properties. In this\nwork, we focus on macro causal effects, which describe the effects of entire\nclusters on other clusters. We establish that the do-calculus is both sound and\ncomplete for identifying these effects in C-DMGs. Additionally, we provide a\ngraphical characterization of non-identifiability for macro causal effects in\nthese graphs.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-02T09:48:27Z"}
{"aid":"http://arxiv.org/abs/2504.01563v1","title":"Height arguments toward the dynamical Mordell-Lang problem in arbitrary\n  characteristic","summary":"We use height arguments to prove two results about the dynamical Mordell-Lang\nproblem. We are more interested in the positive characteristic case due to our\noriginal purpose.\n  (i) For an endomorphism of a projective variety, the return set of a dense\norbit into a curve is finite if any cohomological Lyapunov exponent of any\niteration is not an integer.\n  (ii) Let $f\\times g:X\\times C\\rightarrow X\\times C$ be an endomorphism in\nwhich $f$ and $g$ are endomorphisms of a projective variety $X$ and a curve\n$C$, respectively. If the degree of $g$ is greater than the first dynamical\ndegree of $f$, then the return sets of the system $(X\\times C,f\\times g)$ have\nthe same form as the return sets of the system $(X,f)$.\n  Using the second result, we deal with the case of split endomorphisms of\nproducts of curves, for which the degrees of the factors are pairwise distinct.\n  In the cases that the height argument cannot be applied, we find examples\nwhich show that the return set can be very complicated -- more complicated than\nexperts once imagine -- even for endomorphisms of tori of zero entropy.","main_category":"math.DS","categories":"math.DS,math.AG,math.NT","published":"2025-04-02T10:04:14Z"}
{"aid":"http://arxiv.org/abs/2504.01581v1","title":"Shape transitions of sedimenting confined droplets and capsules: from\n  oblate to bullet-like geometries","summary":"The transport and deformation of confined droplets and flexible capsules are\ncentral to diverse phenomena and applications, from biological flows in\nmicrocapillaries to industrial processes in porous media. We combine\nexperiments and numerical simulations to investigate their shape dynamics under\nvarying levels of confinement and particle flexibility. A transition from an\noblate to a bullet-like shape is observed at a confinement threshold,\nindependent of flexibility. A fluid-structure interaction analysis reveals two\nregimes: a pressure-dominated and a viscous-dominated regime. For highly\nflexible particles, the pressure-dominated regime prevails and the deformation\nis enhanced. These findings offer new insights into the transport of flexible\nparticles in confined environments, with implications for biomedical\napplications, filtration technologies, and multiphase fluid mechanics.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-02T10:38:07Z"}
{"aid":"http://arxiv.org/abs/2504.01589v1","title":"Text Speaks Louder than Vision: ASCII Art Reveals Textual Biases in\n  Vision-Language Models","summary":"Vision-language models (VLMs) have advanced rapidly in processing multimodal\ninformation, but their ability to reconcile conflicting signals across\nmodalities remains underexplored. This work investigates how VLMs process ASCII\nart, a unique medium where textual elements collectively form visual patterns,\npotentially creating semantic-visual conflicts. We introduce a novel evaluation\nframework that systematically challenges five state-of-the-art models\n(including GPT-4o, Claude, and Gemini) using adversarial ASCII art, where\ncharacter-level semantics deliberately contradict global visual patterns. Our\nexperiments reveal a strong text-priority bias: VLMs consistently prioritize\ntextual information over visual patterns, with visual recognition ability\ndeclining dramatically as semantic complexity increases. Various mitigation\nattempts through visual parameter tuning and prompt engineering yielded only\nmodest improvements, suggesting that this limitation requires\narchitectural-level solutions. These findings uncover fundamental flaws in how\ncurrent VLMs integrate multimodal information, providing important guidance for\nfuture model development while highlighting significant implications for\ncontent moderation systems vulnerable to adversarial examples.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T10:47:07Z"}
{"aid":"http://arxiv.org/abs/2504.01594v1","title":"Anticipating Degradation: A Predictive Approach to Fault Tolerance in\n  Robot Swarms","summary":"An active approach to fault tolerance is essential for robot swarms to\nachieve long-term autonomy. Previous efforts have focused on responding to\nspontaneous electro-mechanical faults and failures. However, many faults occur\ngradually over time. Waiting until such faults have manifested as failures\nbefore addressing them is both inefficient and unsustainable in a variety of\nscenarios. This work argues that the principles of predictive maintenance, in\nwhich potential faults are resolved before they hinder the operation of the\nswarm, offer a promising means of achieving long-term fault tolerance. This is\na novel approach to swarm fault tolerance, which is shown to give a comparable\nor improved performance when tested against a reactive approach in almost all\ncases tested.","main_category":"cs.RO","categories":"cs.RO,cs.MA","published":"2025-04-02T10:59:10Z"}
{"aid":"http://arxiv.org/abs/2504.01605v1","title":"Multi-Relation Graph-Kernel Strengthen Network for Graph-Level\n  Clustering","summary":"Graph-level clustering is a fundamental task of data mining, aiming at\ndividing unlabeled graphs into distinct groups. However, existing deep methods\nthat are limited by pooling have difficulty extracting diverse and complex\ngraph structure features, while traditional graph kernel methods rely on\nexhaustive substructure search, unable to adaptive handle multi-relational\ndata. This limitation hampers producing robust and representative graph-level\nembeddings. To address this issue, we propose a novel Multi-Relation\nGraph-Kernel Strengthen Network for Graph-Level Clustering (MGSN), which\nintegrates multi-relation modeling with graph kernel techniques to fully\nleverage their respective advantages. Specifically, MGSN constructs\nmulti-relation graphs to capture diverse semantic relationships between nodes\nand graphs, which employ graph kernel methods to extract graph similarity\nfeatures, enriching the representation space. Moreover, a relation-aware\nrepresentation refinement strategy is designed, which adaptively aligns\nmulti-relation information across views while enhancing graph-level features\nthrough a progressive fusion process. Extensive experiments on multiple\nbenchmark datasets demonstrate the superiority of MGSN over state-of-the-art\nmethods. The results highlight its ability to leverage multi-relation\nstructures and graph kernel features, establishing a new paradigm for robust\ngraph-level clustering.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T11:17:15Z"}
{"aid":"http://arxiv.org/abs/2504.01607v1","title":"High-Chern-number Quantum anomalous Hall insulators in mixing-stacked\n  MnBi$_2$Te$_4$ thin films","summary":"Quantum anomalous Hall (QAH) insulators are characterized by vanishing\nlongitudinal resistance and quantized Hall resistance in the absence of an\nexternal magnetic field. Among them, high-Chern-number QAH insulators offer\nmultiple nondissipative current channels, making them crucial for the\ndevelopment of low-power-consumption electronics. Using first-principles\ncalculations, we propose that high-Chern-number ($C>1$) QAH insulators can be\nrealized in MnBi$_2$Te$_4$ (MBT) multilayer films through the combination of\nmixed stacking orders, eliminating the need for additional buffer layers. The\nunderlying physical mechanism is validated by calculating real-space-resolved\nanomalous Hall conductivity (AHC). Local AHC is found to be predominantly\nlocated in regions with consecutive correct stacking orders, contributing to\nquasi-quantized AHC. Conversely, regions with consecutive incorrect stacking\ncontribute minimally to the total AHC, which can be attributed to the varied\ninterlayer coupling in different stacking configurations. Our work provides\nvaluable insights into the design principle for achieving large Chern numbers,\nand highlights the role of stacking configurations in manipulating electronic\nand topological properties in MBT films and its derivatives.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-02T11:20:40Z"}
{"aid":"http://arxiv.org/abs/2504.01663v1","title":"Recovering Small Communities in the Planted Partition Model","summary":"We analyze community recovery in the planted partition model (PPM) in regimes\nwhere the number of communities is arbitrarily large. We examine the three\nstandard recovery regimes: exact recovery, almost exact recovery, and weak\nrecovery. When communities vary in size, traditional accuracy- or\nalignment-based metrics become unsuitable for assessing the correctness of a\npredicted partition. To address this, we redefine these recovery regimes using\nthe correlation coefficient, a more versatile metric for comparing partitions.\nWe then demonstrate that \\emph{Diamond Percolation}, an algorithm based on\ncommon-neighbors, successfully recovers communities under mild assumptions on\nedge probabilities, with minimal restrictions on the number and sizes of\ncommunities. As a key application, we consider the case where community sizes\nfollow a power-law distribution, a characteristic frequently found in\nreal-world networks. To the best of our knowledge, we provide the first\nrecovery results for such unbalanced partitions.","main_category":"math.PR","categories":"math.PR,cs.SI","published":"2025-04-02T12:14:57Z"}
{"aid":"http://arxiv.org/abs/2504.01672v1","title":"A flexible framework for early power and timing comparison of\n  time-multiplexed CGRA kernel executions","summary":"At the intersection between traditional CPU architectures and more\nspecialized options such as FPGAs or ASICs lies the family of reconfigurable\nhardware architectures, termed Coarse-Grained Reconfigurable Arrays (CGRAs).\nCGRAs are composed of a 2-dimensional array of processing elements (PE),\ntightly integrated with each other, each capable of performing arithmetic and\nlogic operations. The vast design space of CGRA implementations poses a\nchallenge, which calls for fast exploration tools to prune it in advance of\ntime-consuming syntheses. The proposed tool aims to simplify this process by\nsimulating kernel execution and providing a characterization framework. The\nestimator returns energy and latency values otherwise only available through a\ntime-consuming post-synthesis simulation, allowing for instantaneous\ncomparative analysis between different kernels and hardware configurations.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-02T12:21:09Z"}
{"aid":"http://arxiv.org/abs/2504.01709v1","title":"How chiral vibrations drive molecular rotation","summary":"We analyze two simple model planar molecules: an ionic molecule with D3\nsymmetry and a covalent molecule with D6 symmetry. Both symmetries allow the\nexistence of chiral molecular orbitals and normal modes that are coupled to\neach other in a Jahn-Teller manner, invariant under U (1) symmetry with\ngenerator a pseudo angular momentum. In the ionic molecule, the chiral mode\npossesses an electric dipole but lacks physical angular momentum, whereas, in\nthe covalent molecule, the situation is reversed. In spite of that, we show\nthat in both cases the chiral modes can be excited by a circularly polarized\nlight and are subsequently able to induce rotational motion of the entire\nmolecule. We further discuss the potential extension of our findings to the\ncase of crystalline bulk samples.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-02T13:15:59Z"}
{"aid":"http://arxiv.org/abs/2504.01735v1","title":"AdPO: Enhancing the Adversarial Robustness of Large Vision-Language\n  Models with Preference Optimization","summary":"Large Vision-Language Models (LVLMs), such as GPT-4o and LLaVA, have recently\nwitnessed remarkable advancements and are increasingly being deployed in\nreal-world applications. However, inheriting the sensitivity of visual neural\nnetworks, LVLMs remain vulnerable to adversarial attacks, which can result in\nerroneous or malicious outputs. While existing efforts utilize adversarial\nfine-tuning to enhance robustness, they often suffer from performance\ndegradation on clean inputs. In this paper, we proposes AdPO, a novel\nadversarial defense strategy for LVLMs based on preference optimization. For\nthe first time, we reframe adversarial training as a preference optimization\nproblem, aiming to enhance the model's preference for generating normal outputs\non clean inputs while rejecting the potential misleading outputs for\nadversarial examples. Notably, AdPO achieves this by solely modifying the image\nencoder, e.g., CLIP ViT, resulting in superior clean and adversarial\nperformance in a variety of downsream tasks. Considering that training involves\nlarge language models (LLMs), the computational cost increases significantly.\nWe validate that training on smaller LVLMs and subsequently transferring to\nlarger models can achieve competitive performance while maintaining efficiency\ncomparable to baseline methods. Our comprehensive experiments confirm the\neffectiveness of the proposed AdPO, which provides a novel perspective for\nfuture adversarial defense research.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T13:43:21Z"}
{"aid":"http://arxiv.org/abs/2504.01760v1","title":"Compact Group Homeomorphisms Preserving The Haar Measure","summary":"This paper studies the measure-preserving homeomorphisms on compact groups\nand proposes new methods for constructing measure-preserving homeomorphisms on\ndirect products of compact groups and non-commutative compact groups.\n  On the direct product of compact groups, we construct measure-preserving\nhomeomorphisms using the method of integration. In particular, by applying this\nmethod to the \\(n\\)-dimensional torus \\({\\mathbb{T}}^{n}\\), we can construct\nmany new examples of measure-preserving homeomorphisms. We completely\ncharacterize the measure-preserving homeomorphisms on the two-dimensional torus\nwhere one coordinate is a translation depending on the other coordinate, and\ngeneralize this result to the \\(n\\)-dimensional torus.\n  For non-commutative compact groups, we generalize the concept of the\nnormalizer subgroup \\(N\\left( H\\right)\\) of the subgroup \\(H\\) to the\nnormalizer subset \\({E}_{K}( P)\\) from the subset \\(K\\) to the subset \\(P\\) of\nthe group of measure-preserving homeomorphisms. We prove that if \\(\\mu\\) is the\nunique \\(K\\)-invariant measure, then the elements in \\({E}_{K}\\left( P\\right)\\)\nalso preserve \\(\\mu\\). In some non-commutative compact groups the normalizer\nsubset \\({E}_{G}\\left( {\\mathrm{{AF}}\\left( G\\right) }\\right)\\) can give\nnon-affine homeomorphisms that preserve the Haar measure. Finally, we prove\nthat when \\(G\\) is a finite cyclic group and a \\(n\\)-dimensional torus, then\n\\(\\mathrm{{AF}}\\left( G\\right)= N\\left( G\\right) = {E}_{G}\\left(\n{\\mathrm{{AF}}\\left( G\\right) }\\right)\\).","main_category":"math.DS","categories":"math.DS","published":"2025-04-02T14:16:29Z"}
{"aid":"http://arxiv.org/abs/2504.01772v1","title":"Adaptation of Moreau-Yosida regularization to the modulus of convexity","summary":"We study a generalization of Moreau-Yosida regularization that is adapted to\nthe geometry of Banach spaces where the dual space is uniformly convex with\nmodulus of convexity of power type. Important properties for regularized convex\nfunctions are given, in particular strong monotonicity of the subdifferential\nof their convex conjugate and H\\\"older-continuity of their gradient.","main_category":"math.FA","categories":"math.FA,math-ph,math.MP","published":"2025-04-02T14:31:08Z"}
{"aid":"http://arxiv.org/abs/2504.01781v1","title":"Proper scoring rules for estimation and forecast evaluation","summary":"Proper scoring rules have been a subject of growing interest in recent years,\nnot only as tools for evaluation of probabilistic forecasts but also as methods\nfor estimating probability distributions. In this article, we review the\nmathematical foundations of proper scoring rules including general\ncharacterization results and important families of scoring rules. We discuss\ntheir role in statistics and machine learning for estimation and forecast\nevaluation. Furthermore, we comment on interesting developments of their usage\nin applications.","main_category":"math.ST","categories":"math.ST,stat.ML,stat.TH","published":"2025-04-02T14:46:14Z"}
{"aid":"http://arxiv.org/abs/2504.01815v1","title":"Multiplexed Control at Scale for Electrode Arrays in Trapped-Ion Quantum\n  Processors","summary":"The scaling up of trapped-ion quantum processors based on the quantum\ncharge-coupled device (QCCD) architecture is difficult owing to the extensive\nelectronics and high-density wiring required to control numerous trap\nelectrodes. In conventional QCCD architectures, each trap electrode is\ncontrolled via a dedicated digital-to-analog converter (DAC). The conventional\napproach places an overwhelming demand on electronic resources and wiring\ncomplexity. This is because the number of trap electrodes typically exceeds the\nnumber of trapped-ion qubits. This study proposes a method that leverages a\nhigh-speed DAC to generate time-division multiplexed signals to control a\nlarge-scale QCCD trapped-ion quantum processor. The proposed method replaces\nconventional DACs with a single high-speed DAC that generates the complete\nvoltage waveforms required to control the trap electrodes, thereby\nsignificantly reducing the wiring complexity and overall resource requirements.\nBased on realistic parameters and commercially available electronics, our\nanalysis demonstrates that a QCCD trapped-ion quantum computer with 10,000 trap\nelectrodes can be controlled using only 13 field-programmable gate arrays and\n104 high-speed DACs. This is in stark contrast to the 10,000 dedicated DACs\nrequired by conventional control methods. Consequently, employing this\napproach, we developed a proof-of-concept electronic system and evaluated its\nanalog output performance.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T15:21:31Z"}
{"aid":"http://arxiv.org/abs/2504.01830v1","title":"Is Lorentz invariance violation found?","summary":"Lorentz invariance violation (LIV) has long been recognized as an observable\nlow-energy signature of quantum gravity. In spite of a great effort to detect\nLIV effects, so far only lower bounds have been derived. The high energy\nphotons from the gamma ray burst GRB 221009A have been detected by the LHAASO\ncollaboration and one at ${\\cal E} \\simeq 251 \\, \\rm TeV$ by the Carpet\ncollaboration using a partial data set. Very recently, the Carpet collaboration\nhas completed the full data analysis, reporting further support for their\npreviously detected photon now at ${\\cal E} = 300^{+ 43}_{- 38} \\, {\\rm TeV}$,\nwhich manifestly clashes with conventional physics. Taking this result at face\nvalue, we derive the first evidence for LIV and we show that such a detection\ncannot be explained by axion-like particles (ALPs), which allow for the\nobservation of the highest energy photons detected by LHAASO. We also outline a\nscenario in which ALPs and LIV naturally coexist. If confirmed by future\nobservations our finding would represent the first positive result in quantum\ngravity phenomenology.","main_category":"astro-ph.HE","categories":"astro-ph.HE,gr-qc,hep-ph,hep-th","published":"2025-04-02T15:39:37Z"}
{"aid":"http://arxiv.org/abs/2504.01836v1","title":"Estimating hazard rates from $Î´$-records in discrete distributions","summary":"This paper focuses on nonparametric statistical inference of the hazard rate\nfunction of discrete distributions based on $\\delta$-record data. We derive the\nexplicit expression of the maximum likelihood estimator and determine its exact\ndistribution, as well as some important characteristics such as its bias and\nmean squared error. We then discuss the construction of confidence intervals\nand goodness-of-fit tests. The performance of our proposals is evaluated using\nsimulation methods. Applications to real data are given, as well. The\nestimation of the hazard rate function based on usual records has been studied\nin the literature, although many procedures require several samples of records.\nIn contrast, our approach relies on a single sequence of $\\delta$-records,\nsimplifying the experimental design and increasing the applicability of the\nmethods.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-02T15:43:19Z"}
{"aid":"http://arxiv.org/abs/2504.01866v1","title":"From Code Generation to Software Testing: AI Copilot with Context-Based\n  RAG","summary":"The rapid pace of large-scale software development places increasing demands\non traditional testing methodologies, often leading to bottlenecks in\nefficiency, accuracy, and coverage. We propose a novel perspective on software\ntesting by positing bug detection and coding with fewer bugs as two\ninterconnected problems that share a common goal, which is reducing bugs with\nlimited resources. We extend our previous work on AI-assisted programming,\nwhich supports code auto-completion and chatbot-powered Q&A, to the realm of\nsoftware testing. We introduce Copilot for Testing, an automated testing system\nthat synchronizes bug detection with codebase updates, leveraging context-based\nRetrieval Augmented Generation (RAG) to enhance the capabilities of large\nlanguage models (LLMs). Our evaluation demonstrates a 31.2% improvement in bug\ndetection accuracy, a 12.6% increase in critical test coverage, and a 10.5%\nhigher user acceptance rate, highlighting the transformative potential of\nAI-driven technologies in modern software development practices.","main_category":"cs.SE","categories":"cs.SE,cs.AI,cs.PL","published":"2025-04-02T16:20:05Z"}
{"aid":"http://arxiv.org/abs/2504.01869v1","title":"Buggin: Automatic intrinsic bugs classification model using NLP and ML","summary":"Recent studies have shown that bugs can be categorized into intrinsic and\nextrinsic types. Intrinsic bugs can be backtracked to specific changes in the\nversion control system (VCS), while extrinsic bugs originate from external\nchanges to the VCS and lack a direct bug-inducing change. Using only intrinsic\nbugs to train bug prediction models has been reported as beneficial to improve\nthe performance of such models. However, there is currently no automated\napproach to identify intrinsic bugs. To bridge this gap, our study employs\nNatural Language Processing (NLP) techniques to automatically identify\nintrinsic bugs. Specifically, we utilize two embedding techniques, seBERT and\nTF-IDF, applied to the title and description text of bug reports. The resulting\nembeddings are fed into well-established machine learning algorithms such as\nSupport Vector Machine, Logistic Regression, Decision Tree, Random Forest, and\nK-Nearest Neighbors. The primary objective of this paper is to assess the\nperformance of various NLP and machine learning techniques in identifying\nintrinsic bugs using the textual information extracted from bug reports. The\nresults demonstrate that both seBERT and TF-IDF can be effectively utilized for\nintrinsic bug identification. The highest performance scores were achieved by\ncombining TF-IDF with the Decision Tree algorithm and utilizing the bug titles\n(yielding an F1 score of 78%). This was closely followed by seBERT, Support\nVector Machine, and bug titles (with an F1 score of 77%). In summary, this\npaper introduces an innovative approach that automates the identification of\nintrinsic bugs using textual information derived from bug reports.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-02T16:23:08Z"}
{"aid":"http://arxiv.org/abs/2504.01884v1","title":"Thermoelectric AC Josephson effect","summary":"A temperature gradient ${\\Delta}T$ across a Josephson junction induces a\nthermoelectric current. We predict the AC Josephson effect is activated when\nthis current surpasses the junction's critical current. Our investigation of\nthis phenomenon employs the time-dependent Ginzburg-Landau theory framework in\nproximity to the critical temperature. Our results indicate that the frequency\nof the AC current is approximately given by ${\\pi} S {\\Delta} T / (2\n{\\Phi}_0)$, where $S$ represents the Seebeck coefficient and ${\\Phi}_0$ the\nmagnetic flux quantum and we estimate the frequency be on the range of GHz for\nSn up to a THz for larger $S$ and $T_c$ materials. Furthermore, we propose two\ndistinct experimental configurations to observe this effect.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-02T16:41:34Z"}
{"aid":"http://arxiv.org/abs/2504.01900v1","title":"Physical Modeling of Saturated Common Mode Choke","summary":"Common mode chokes (CMCs) are conventional circuit elements performing\nseveral tasks, including noise suppression, hindering electromagnetic\ninterference, providing signal integrity, and circuit protection. Much as they\nare widely used, their fundamental construction and description are often\nqualitative and lack an understanding of the underlying physical principles. We\ndiscuss the behavior of a commercial CMC based on the physical description of\nthe superparamagnetic core and parasitic circuit elements. The results are\nvalidated using a DC bias current and an external magnetic field, which affect\nthe magnetic properties. The behavior of the CMCs in the strongly non-linear\nregime is also described.","main_category":"physics.app-ph","categories":"physics.app-ph,cond-mat.mtrl-sci","published":"2025-04-02T16:58:47Z"}
{"aid":"http://arxiv.org/abs/2504.01905v1","title":"Accelerating IoV Intrusion Detection: Benchmarking GPU-Accelerated vs\n  CPU-Based ML Libraries","summary":"The Internet of Vehicles (IoV) may face challenging cybersecurity attacks\nthat may require sophisticated intrusion detection systems, necessitating a\nrapid development and response system. This research investigates the\nperformance advantages of GPU-accelerated libraries (cuML) compared to\ntraditional CPU-based implementations (scikit-learn), focusing on the speed and\nefficiency required for machine learning models used in IoV threat detection\nenvironments. The comprehensive evaluations conducted employ four machine\nlearning approaches (Random Forest, KNN, Logistic Regression, XGBoost) across\nthree distinct IoV security datasets (OTIDS, GIDS, CICIoV2024). Our findings\ndemonstrate that GPU-accelerated implementations dramatically improved\ncomputational efficiency, with training times reduced by a factor of up to 159\nand prediction speeds accelerated by up to 95 times compared to traditional CPU\nprocessing, all while preserving detection accuracy. This remarkable\nperformance breakthrough empowers researchers and security specialists to\nharness GPU acceleration for creating faster, more effective threat detection\nsystems that meet the urgent real-time security demands of today's connected\nvehicle networks.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CR","published":"2025-04-02T17:04:53Z"}
{"aid":"http://arxiv.org/abs/2504.01936v1","title":"Fermionic Averaged Circuit Eigenvalue Sampling","summary":"Fermionic averaged circuit eigenvalue sampling (FACES) is a protocol to\nsimultaneously learn the averaged error rates of many fermionic linear optical\n(FLO) gates simultaneously and self-consistently from a suitable collection of\nFLO circuits. It is highly flexible, allowing for the in situ characterization\nof FLO-averaged gate-dependent noise under natural assumptions on a family of\ncontinuously parameterized one- and two-qubit gates. We rigorously show that\nour protocol has an efficient sampling complexity, owing in-part to useful\nproperties of the Kravchuk transformations that feature in our analysis. We\nsupport our conclusions with numerical results. As FLO circuits become\nuniversal with access to certain resource states, we expect our results to\ninform noise characterization and error mitigation techniques on universal\nquantum computing architectures which naturally admit a fermionic description.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T17:46:16Z"}
{"aid":"http://arxiv.org/abs/2504.02214v1","title":"Geospatial Artificial Intelligence for Satellite-based Flood Extent\n  Mapping: Concepts, Advances, and Future Perspectives","summary":"Geospatial Artificial Intelligence (GeoAI) for satellite-based flood extent\nmapping systematically integrates artificial intelligence techniques with\nsatellite data to identify flood events and assess their impacts, for disaster\nmanagement and spatial decision-making. The primary output often includes flood\nextent maps, which delineate the affected areas, along with additional\nanalytical outputs such as uncertainty estimation and change detection.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-03T02:08:22Z"}
{"aid":"http://arxiv.org/abs/2504.02267v1","title":"Third-Order Spontaneous Parametric Down Conversion in Dielectric\n  Nonlinear Resonant Metasurfaces","summary":"We propose a general scheme to investigate photon triplet generation (PTG)\nvia third-order spontaneous parametric downconversion (TOSPDC) in $\\chi^{(3)}$\nnonlinear structures. Our approach leverages the quantum-classical\ncorrespondence between TOSPDC and its reverse classical process, three-wave\nsum-frequency generation (TSFG), to efficiently estimate the PTG rate. We apply\nthis framework to nonlinear metasurfaces supporting quasi-bound states in the\ncontinuum (qBICs) in the optical range. From numerical analysis of\nnon-collinear TSFG with degenerate input waves at qBIC wavelengths, we predict\nwavelength-tunable three-photon emission with spatio-angular correlations.\nThese findings establish a novel method for modelling TOSPDC and also highlight\nthe potential of nonlinear resonant metasurfaces as compact free-space photon\ntriplet sources with quantum state control.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-03T04:26:50Z"}
{"aid":"http://arxiv.org/abs/2504.02312v1","title":"OmniCam: Unified Multimodal Video Generation via Camera Control","summary":"Camera control, which achieves diverse visual effects by changing camera\nposition and pose, has attracted widespread attention. However, existing\nmethods face challenges such as complex interaction and limited control\ncapabilities. To address these issues, we present OmniCam, a unified multimodal\ncamera control framework. Leveraging large language models and video diffusion\nmodels, OmniCam generates spatio-temporally consistent videos. It supports\nvarious combinations of input modalities: the user can provide text or video\nwith expected trajectory as camera path guidance, and image or video as content\nreference, enabling precise control over camera motion. To facilitate the\ntraining of OmniCam, we introduce the OmniTr dataset, which contains a large\ncollection of high-quality long-sequence trajectories, videos, and\ncorresponding descriptions. Experimental results demonstrate that our model\nachieves state-of-the-art performance in high-quality camera-controlled video\ngeneration across various metrics.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-03T06:38:30Z"}
{"aid":"http://arxiv.org/abs/2504.02315v1","title":"On $\\rm GL_3$ Fourier coefficients over values of mixed powers","summary":"Let $A_{\\pi}(n,1)$ be the $(n,1)$-th Fourier coefficient of the Hecke-Maass\ncusp form $\\pi$ for $\\rm SL_3(\\mathbb{Z})$ and $ \\omega(x)$ be a smooth\ncompactly supported function. In this paper, we prove a nontrivial upper bound\nfor the sum $$\\sum_{n_1,\\cdots,n_\\ell,n_{\\ell+1}\\in\\mathbb{Z}^+ \\atop\nn=n_1^r+\\cdots+n_{\\ell}^r+n_{\\ell+1}^s} A_{\\pi}(n,1)\\omega\\left(n/X\\right),$$\nwhere $r\\geq2$, $s\\geq 2$ and $\\ell\\geq 2^{r-1}$ are integers.","main_category":"math.NT","categories":"math.NT","published":"2025-04-03T06:43:21Z"}
{"aid":"http://arxiv.org/abs/2504.02339v1","title":"Riemannian Optimization for Sparse Tensor CCA","summary":"Tensor canonical correlation analysis (TCCA) has received significant\nattention due to its ability to effectively preserve the geometric structure of\nhigh-order data. However, existing methods generally rely on tensor\ndecomposition techniques with high computational complexity, which severely\nlimits their application in large-scale datasets. In this paper, a modified\nmethod, TCCA-L, is proposed, which integrates sparse regularization and\nLaplacian regularization. An alternating manifold proximal gradient algorithm\nis designed based on Riemannian manifold theory. The algorithm avoids the\ntraditional tensor decomposition and combines with the semi-smooth Newton\nalgorithm to solve the subproblem, thus significantly improving the\ncomputational efficiency. Furthermore, the global convergence of the sequence\ngenerated by the algorithm is established, providing a solid theoretical\nfoundation for its convergence. Numerical experiments demonstrate that TCCA-L\noutperforms traditional methods in both classification accuracy and running\ntime.","main_category":"math.OC","categories":"math.OC","published":"2025-04-03T07:19:14Z"}
{"aid":"http://arxiv.org/abs/2504.02360v1","title":"On graded going-down domains, II","summary":"In this paper we consider the graded going-down property of graded integral\ndomains in pullbacks. It then enables us to give original examples of these\ndomains.","main_category":"math.AC","categories":"math.AC","published":"2025-04-03T07:51:21Z"}
{"aid":"http://arxiv.org/abs/2504.02368v1","title":"Electrical conductivities and low frequency opacities in the warm dense\n  matter regime","summary":"In this article, we examine different approaches for calculating low\nfrequency opacities in the warm dense matter regime. The relevance of the\naverage-atom approximation and of different models for calculating opacities,\nsuch as the Ziman or Ziman-Evans models is discussed and the results compared\nto \\textit{ab initio} simulations. We begin by recalling the derivation of the\nZiman-Evans resistivity from Kubo's linear response theory, using the local\napproximation to the solutions of the Lippmann-Schwinger equation. With the\nhelp of this approximation, we explicitly introduce an ionic structure factor\ninto the Ziman formula, without resorting to the Born approximation. Both\napproaches involve the calculation of scattering phase shifts, which we\nintegrate from Calogero equation with an adaptive step numerical scheme based\non a Runge-Kutta-Merson solver. We show that if the atomic number $Z$ is not\ntoo large, integrating the phase shifts in this way is more time-efficient than\nusing a classical Numerov-type scheme to solve the radial Schr\\\"odinger\nequation. Various approximations are explored for phase shifts to further\nimprove computation time. For the Born approximation, we show that using Born\nphase shifts directly in the scattering cross-section gives more accurate\nresults than with the integral formula based on the Fourier transform of the\nelectron-ion potential. We also compare an analytical formula based on a Yukawa\nfit of the electron-ion potential to a numerical integration. The average-atom\nresults are compared with DFT-based molecular dynamics simulations for aluminum\nin the dilute regime and for copper, aluminum and gold at solid density and\ndifferent temperatures.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-03T08:00:17Z"}
{"aid":"http://arxiv.org/abs/2504.02403v1","title":"DaKultur: Evaluating the Cultural Awareness of Language Models for\n  Danish with Native Speakers","summary":"Large Language Models (LLMs) have seen widespread societal adoption. However,\nwhile they are able to interact with users in languages beyond English, they\nhave been shown to lack cultural awareness, providing anglocentric or\ninappropriate responses for underrepresented language communities. To\ninvestigate this gap and disentangle linguistic versus cultural proficiency, we\nconduct the first cultural evaluation study for the mid-resource language of\nDanish, in which native speakers prompt different models to solve tasks\nrequiring cultural awareness. Our analysis of the resulting 1,038 interactions\nfrom 63 demographically diverse participants highlights open challenges to\ncultural adaptation: Particularly, how currently employed automatically\ntranslated data are insufficient to train or measure cultural adaptation, and\nhow training on native-speaker data can more than double response acceptance\nrates. We release our study data as DaKultur - the first native Danish cultural\nawareness dataset.","main_category":"cs.CL","categories":"cs.CL,cs.CY,cs.HC","published":"2025-04-03T08:52:42Z"}
{"aid":"http://arxiv.org/abs/2504.02404v1","title":"AnesBench: Multi-Dimensional Evaluation of LLM Reasoning in\n  Anesthesiology","summary":"The application of large language models (LLMs) in the medical field has\ngained significant attention, yet their reasoning capabilities in more\nspecialized domains like anesthesiology remain underexplored. In this paper, we\nsystematically evaluate the reasoning capabilities of LLMs in anesthesiology\nand analyze key factors influencing their performance. To this end, we\nintroduce AnesBench, a cross-lingual benchmark designed to assess\nanesthesiology-related reasoning across three levels: factual retrieval (System\n1), hybrid reasoning (System 1.x), and complex decision-making (System 2).\nThrough extensive experiments, we first explore how model characteristics,\nincluding model scale, Chain of Thought (CoT) length, and language\ntransferability, affect reasoning performance. Then, we further evaluate the\neffectiveness of different training strategies, leveraging our curated\nanesthesiology-related dataset, including continuous pre-training (CPT) and\nsupervised fine-tuning (SFT). Additionally, we also investigate how the\ntest-time reasoning techniques, such as Best-of-N sampling and beam search,\ninfluence reasoning performance, and assess the impact of reasoning-enhanced\nmodel distillation, specifically DeepSeek-R1. We will publicly release\nAnesBench, along with our CPT and SFT training datasets and evaluation code at\nhttps://github.com/MiliLab/AnesBench.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T08:54:23Z"}
{"aid":"http://arxiv.org/abs/2504.02416v1","title":"Hyperspectral Remote Sensing Images Salient Object Detection: The First\n  Benchmark Dataset and Baseline","summary":"The objective of hyperspectral remote sensing image salient object detection\n(HRSI-SOD) is to identify objects or regions that exhibit distinct spectrum\ncontrasts with the background. This area holds significant promise for\npractical applications; however, progress has been limited by a notable\nscarcity of dedicated datasets and methodologies. To bridge this gap and\nstimulate further research, we introduce the first HRSI-SOD dataset, termed\nHRSSD, which includes 704 hyperspectral images and 5327 pixel-level annotated\nsalient objects. The HRSSD dataset poses substantial challenges for salient\nobject detection algorithms due to large scale variation, diverse\nforeground-background relations, and multi-salient objects. Additionally, we\npropose an innovative and efficient baseline model for HRSI-SOD, termed the\nDeep Spectral Saliency Network (DSSN). The core of DSSN is the Cross-level\nSaliency Assessment Block, which performs pixel-wise attention and evaluates\nthe contributions of multi-scale similarity maps at each spatial location,\neffectively reducing erroneous responses in cluttered regions and emphasizes\nsalient regions across scales. Additionally, the High-resolution Fusion Module\ncombines bottom-up fusion strategy and learned spatial upsampling to leverage\nthe strengths of multi-scale saliency maps, ensuring accurate localization of\nsmall objects. Experiments on the HRSSD dataset robustly validate the\nsuperiority of DSSN, underscoring the critical need for specialized datasets\nand methodologies in this domain. Further evaluations on the HSOD-BIT and\nHS-SOD datasets demonstrate the generalizability of the proposed method. The\ndataset and source code are publicly available at\nhttps://github.com/laprf/HRSSD.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T09:12:42Z"}
{"aid":"http://arxiv.org/abs/2504.02427v1","title":"Stochastic domination and lifts of random variables in percolation\n  theory","summary":"Consider some matrix waiting for its coefficients to be written. For each\ncolumn, sample independently one Bernoulli random variable of some parameter\n$p$. Seeing all this and possibly using extra randomness, Alice then chooses\none spot in each column, in any way she wants. When the Bernoulli random\nvariable of some column is equal to 1, the number 1 is written in the chosen\nspot. When the Bernoulli random variable of a column is 0, nothing is done on\nthis column. We prove that, using extra randomness, it is possible for Bob to\nfill the empty spots with well chosen 0's and 1's so that the entries of the\nmatrix are independent Bernoulli random variables of parameter $p$. We\ninvestigate various generalisations and variations of this problem, and use\nthis result to revisit and generalise (nonstrict) monotonicity of the\npercolation threshold $p_c$ with respect to some sort of graph-quotienting,\nnamely fibrations.\n  In a second part, which is independent of the first one, we revisit strict\nmonotonicity of $p_c$ with respect to fibrations, a result that naturally\nrequires more assumptions than its nonstrict counterpart. We reprove the\nbond-percolation case of the result of Martineau--Severo without resorting to\nessential enhancements, using couplings instead.","main_category":"math.PR","categories":"math.PR,math.CO","published":"2025-04-03T09:31:59Z"}
{"aid":"http://arxiv.org/abs/2504.02431v1","title":"Koney: A Cyber Deception Orchestration Framework for Kubernetes","summary":"System operators responsible for protecting software applications remain\nhesitant to implement cyber deception technology, including methods that place\ntraps to catch attackers, despite its proven benefits. Overcoming their\nconcerns removes a barrier that currently hinders industry adoption of\ndeception technology. Our work introduces deception policy documents to\ndescribe deception technology \"as code\" and pairs them with Koney, a Kubernetes\noperator, which facilitates the setup, rotation, monitoring, and removal of\ntraps in Kubernetes. We leverage cloud-native technologies, such as service\nmeshes and eBPF, to automatically add traps to containerized software\napplications, without having access to the source code. We focus specifically\non operational properties, such as maintainability, scalability, and\nsimplicity, which we consider essential to accelerate the adoption of cyber\ndeception technology and to facilitate further research on cyber deception.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-03T09:37:14Z"}
{"aid":"http://arxiv.org/abs/2504.02451v1","title":"ConMo: Controllable Motion Disentanglement and Recomposition for\n  Zero-Shot Motion Transfer","summary":"The development of Text-to-Video (T2V) generation has made motion transfer\npossible, enabling the control of video motion based on existing footage.\nHowever, current methods have two limitations: 1) struggle to handle\nmulti-subjects videos, failing to transfer specific subject motion; 2) struggle\nto preserve the diversity and accuracy of motion as transferring to subjects\nwith varying shapes. To overcome these, we introduce \\textbf{ConMo}, a\nzero-shot framework that disentangle and recompose the motions of subjects and\ncamera movements. ConMo isolates individual subject and background motion cues\nfrom complex trajectories in source videos using only subject masks, and\nreassembles them for target video generation. This approach enables more\naccurate motion control across diverse subjects and improves performance in\nmulti-subject scenarios. Additionally, we propose soft guidance in the\nrecomposition stage which controls the retention of original motion to adjust\nshape constraints, aiding subject shape adaptation and semantic transformation.\nUnlike previous methods, ConMo unlocks a wide range of applications, including\nsubject size and position editing, subject removal, semantic modifications, and\ncamera motion simulation. Extensive experiments demonstrate that ConMo\nsignificantly outperforms state-of-the-art methods in motion fidelity and\nsemantic consistency. The code is available at\nhttps://github.com/Andyplus1/ConMo.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T10:15:52Z"}
{"aid":"http://arxiv.org/abs/2504.02454v1","title":"Taylor Series-Inspired Local Structure Fitting Network for Few-shot\n  Point Cloud Semantic Segmentation","summary":"Few-shot point cloud semantic segmentation aims to accurately segment\n\"unseen\" new categories in point cloud scenes using limited labeled data.\nHowever, pretraining-based methods not only introduce excessive time overhead\nbut also overlook the local structure representation among irregular point\nclouds. To address these issues, we propose a pretraining-free local structure\nfitting network for few-shot point cloud semantic segmentation, named\nTaylorSeg. Specifically, inspired by Taylor series, we treat the local\nstructure representation of irregular point clouds as a polynomial fitting\nproblem and propose a novel local structure fitting convolution, called\nTaylorConv. This convolution learns the low-order basic information and\nhigh-order refined information of point clouds from explicit encoding of local\ngeometric structures. Then, using TaylorConv as the basic component, we\nconstruct two variants of TaylorSeg: a non-parametric TaylorSeg-NN and a\nparametric TaylorSeg-PN. The former can achieve performance comparable to\nexisting parametric models without pretraining. For the latter, we equip it\nwith an Adaptive Push-Pull (APP) module to mitigate the feature distribution\ndifferences between the query set and the support set. Extensive experiments\nvalidate the effectiveness of the proposed method. Notably, under the 2-way\n1-shot setting, TaylorSeg-PN achieves improvements of +2.28% and +4.37% mIoU on\nthe S3DIS and ScanNet datasets respectively, compared to the previous\nstate-of-the-art methods. Our code is available at\nhttps://github.com/changshuowang/TaylorSeg.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T10:19:06Z"}
{"aid":"http://arxiv.org/abs/2504.02496v1","title":"Group-based Distinctive Image Captioning with Memory Difference Encoding\n  and Attention","summary":"Recent advances in image captioning have focused on enhancing accuracy by\nsubstantially increasing the dataset and model size. While conventional\ncaptioning models exhibit high performance on established metrics such as BLEU,\nCIDEr, and SPICE, the capability of captions to distinguish the target image\nfrom other similar images is under-explored. To generate distinctive captions,\na few pioneers employed contrastive learning or re-weighted the ground-truth\ncaptions. However, these approaches often overlook the relationships among\nobjects in a similar image group (e.g., items or properties within the same\nalbum or fine-grained events). In this paper, we introduce a novel approach to\nenhance the distinctiveness of image captions, namely Group-based Differential\nDistinctive Captioning Method, which visually compares each image with other\nimages in one similar group and highlights the uniqueness of each image. In\nparticular, we introduce a Group-based Differential Memory Attention (GDMA)\nmodule, designed to identify and emphasize object features in an image that are\nuniquely distinguishable within its image group, i.e., those exhibiting low\nsimilarity with objects in other images. This mechanism ensures that such\nunique object features are prioritized during caption generation for the image,\nthereby enhancing the distinctiveness of the resulting captions. To further\nrefine this process, we select distinctive words from the ground-truth captions\nto guide both the language decoder and the GDMA module. Additionally, we\npropose a new evaluation metric, the Distinctive Word Rate (DisWordRate), to\nquantitatively assess caption distinctiveness. Quantitative results indicate\nthat the proposed method significantly improves the distinctiveness of several\nbaseline models, and achieves state-of-the-art performance on distinctiveness\nwhile not excessively sacrificing accuracy...","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-03T11:19:51Z"}
{"aid":"http://arxiv.org/abs/2504.02502v1","title":"Berry-Esseen bounds for step-reinforced random walks","summary":"We study both the positively and negatively step-reinforced random walks with\nparameter $p$. For a step distribution $\\mu$ with finite second moment, the\npositively step-reinforced random walk with $p\\in [1/2,1)$ and the negatively\nstep-reinforced random walk with $p\\in (0,1)$ converge to a normal distribution\nunder suitable normalization. In this work, we obtain the rates of convergence\nto normality for both cases under the assumption that $\\mu$ has a finite third\nmoment. In the proofs, we establish a Berry-Esseen bound for general\nfunctionals of independent random variables, utilize the randomly weighted sum\nrepresentations of step-reinforced random walks, and apply special comparison\narguments to quantify the Kolmogorov distance between a mixed normal\ndistribution and its corresponding normal distribution.","main_category":"math.PR","categories":"math.PR","published":"2025-04-03T11:35:20Z"}
{"aid":"http://arxiv.org/abs/2504.02505v1","title":"Centrality dependence of charged-particle pseudorapidity density at\n  midrapidity in Pb-Pb collisions at $\\mathbf{\\sqrt{\\textit{s}_{\\rm NN}} =\n  5.36}$ TeV","summary":"The ALICE Collaboration reports its first LHC Run 3 measurements of\ncharged-particle pseudorapidity density at midrapidity in Pb-Pb collisions at a\ncentre-of-mass energy per nucleon pair of $\\sqrt{s_{\\mathrm{NN}}}=5.36$ TeV.\nParticle multiplicity in high-energy collisions characterises the system\ngeometry, constrains particle-production mechanisms, and is used to estimate\ninitial energy density. Multiplicity also acts as a reference for subsequent\nmeasurements as a function of centrality. In this letter, for the first time,\ncharged particles are reconstructed using the upgraded ALICE Inner Tracking\nSystem and Time Projection Chamber, while the collision centrality is\ndetermined by measuring charged-particle multiplicities with the Fast\nInteraction Trigger system. Pseudorapidity density, ${\\rm d}N_{\\rm ch}/{\\rm\nd}\\eta$, is presented, averaged over events, for various centrality classes.\nResults are shown as a function of pseudorapidity and the average number of\nparticipating nucleons ($\\langle N_{\\mathrm{part}}\\rangle$) in the collision.\nThe average charged-particle pseudorapidity density ($\\langle {\\rm d}N_{\\rm\nch}/{\\rm d}\\eta \\rangle$) at midrapidity ($|\\eta|<0.5$) is 2047 $\\pm$ 54 for\nthe 5% most central collisions. The value of $\\langle {\\rm d}N_{\\rm ch}/{\\rm\nd}\\eta \\rangle$ normalised to $\\langle N_{\\mathrm{part}}\\rangle/2$ as a\nfunction of $\\sqrt{s_{\\mathrm{NN}}}$ follows the trend established in previous\nmeasurements in heavy-ion collisions. Theoretical models based on mechanisms\nfor particle production in nuclear collisions that involve the formation of\nquark-gluon plasma medium and models based on individual nucleon-nucleon\ninteractions are compared to the data.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-03T11:36:43Z"}
{"aid":"http://arxiv.org/abs/2504.02562v1","title":"Spectrum Assignment of Stochastic Systems with Multiplicative Noise","summary":"This paper studies the spectrum assignment of a class of stochastic systems\nwith multiplicative noise. A novel $\\alpha$-spectrum assignment is proposed for\ndiscrete-time and continuous-time stochastic systems with multiplicative noise.\nIn particular, $0$-spectrum assignment is equivalent to the pole assignment for\nthe deterministic systems. The main contribution is two-fold: On the one hand,\nwe present the conditions for $\\alpha$-spectrum assignment and the design of\nfeedback controllers based on the system parameters. On the other hand, when\nthe system parameters are unknown, we present a stochastic approximation\nalgorithm to learn the feedback gains which guarantee the spectrum of the\nstochastic systems to achieve the predetermined value. Numerical examples are\nprovided to demonstrate the effectiveness of the proposed algorithms.","main_category":"math.OC","categories":"math.OC","published":"2025-04-03T13:25:09Z"}
{"aid":"http://arxiv.org/abs/2504.02565v1","title":"MAD: A Magnitude And Direction Policy Parametrization for Stability\n  Constrained Reinforcement Learning","summary":"We introduce magnitude and direction (MAD) policies, a policy\nparameterization for reinforcement learning (RL) that preserves Lp closed-loop\nstability for nonlinear dynamical systems. Although complete in their ability\nto describe all stabilizing controllers, methods based on nonlinear Youla and\nsystem-level synthesis are significantly affected by the difficulty of\nparameterizing Lp-stable operators. In contrast, MAD policies introduce\nexplicit feedback on state-dependent features - a key element behind the\nsuccess of RL pipelines - without compromising closed-loop stability. This is\nachieved by describing the magnitude of the control input with a\ndisturbance-feedback Lp-stable operator, while selecting its direction based on\nstate-dependent features through a universal function approximator. We further\ncharacterize the robust stability properties of MAD policies under model\nmismatch. Unlike existing disturbance-feedback policy parameterizations, MAD\npolicies introduce state-feedback components compatible with model-free RL\npipelines, ensuring closed-loop stability without requiring model information\nbeyond open-loop stability. Numerical experiments show that MAD policies\ntrained with deep deterministic policy gradient (DDPG) methods generalize to\nunseen scenarios, matching the performance of standard neural network policies\nwhile guaranteeing closed-loop stability by design.","main_category":"eess.SY","categories":"eess.SY,cs.LG,cs.SY","published":"2025-04-03T13:26:26Z"}
{"aid":"http://arxiv.org/abs/2504.02569v1","title":"Fluorine production in He-burning regions of massive stars during cosmic\n  history","summary":"The origin of fluorine is still a debated question. AGB stars synthesise this\nelement and likely contribute significantly to its synthesis in the present-day\nUniverse. However, it is not clear whether other sources contribute, especially\nin the early Universe. We discuss variations of the surface abundances of\nfluorine coming from our massive star models and compare them with available\npresent-day observations. We compute the contribution of massive stars in\nproducing 19F over metallicities covering the whole cosmic history. We used\nmodels in the mass range of 9Msol < Mini < 300Msol at metallicities from Pop\nIII up to super-solar while accounting for the required nuclear network to\nfollow the evolution of 19F during the core H- and He-burning phases. Results\nfrom models with and without rotational mixing are presented. We find that\nrotating models predict a slight depletion of fluorine at their surface at the\nend of the MS phase. In more advanced evolutionary phases, only models with an\ninitial mass larger than 25Msol at metallicities Z > 0.014 show phases where\nthe abundance of fluorine is enhanced. This occurs when the star is a WR star\nof the WC type. WC stars can show surface abundances of fluorine ten times\nlarger than their initial abundance. However, we obtained that the winds of\nmassive stars at metallicities larger than Z=0.006 do not significantly\ncontribute to fluorine production, confirming previous findings. In contrast,\nvery metal-poor rapidly rotating massive star models may be important sources\nof fluorine through the mass expelled at the time of their SN explosion.\nObservations of WC stars at solar or super-solar metallicities may provide very\ninteresting indications on the nuclear pathways that lead to fluorine\nproduction in massive stars. The possibility of observing fluorine-rich CEMPs\nis also a way to put constrains in present models at very low metallicities.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-03T13:36:04Z"}
{"aid":"http://arxiv.org/abs/2504.02570v1","title":"Time resolution limits in silicon sensors from Landau fluctuations and\n  electronics noise","summary":"In this report, we derive analytical expressions for the time resolution\nlimits of standard silicon sensors, LGADs, and 3D trench sensors. We separately\nexamine the effects of Landau fluctuations and electronic noise. To analyze\nLandau fluctuations, we relate the time resolution of a single electron-hole\npair generated at a random position in the sensor to the time resolution\nassociated with the full ionization pattern produced by a charged particle. For\nelectronic noise, we explore optimal filtering techniques that minimize its\nimpact on time resolution, and evaluate how closely these can be approximated\nby practical filters. Finally, we demonstrate that the combined effect of\nLandau fluctuations and electronic noise cannot, in general, be simply\nexpressed as the quadratic sum of the individual contributions.","main_category":"hep-ex","categories":"hep-ex,physics.ins-det","published":"2025-04-03T13:36:06Z"}
{"aid":"http://arxiv.org/abs/2504.02579v1","title":"Bridging the Gap between Gaussian Diffusion Models and Universal\n  Quantization for Image Compression","summary":"Generative neural image compression supports data representation at extremely\nlow bitrate, synthesizing details at the client and consistently producing\nhighly realistic images. By leveraging the similarities between quantization\nerror and additive noise, diffusion-based generative image compression codecs\ncan be built using a latent diffusion model to \"denoise\" the artifacts\nintroduced by quantization. However, we identify three critical gaps in\nprevious approaches following this paradigm (namely, the noise level, noise\ntype, and discretization gaps) that result in the quantized data falling out of\nthe data distribution known by the diffusion model. In this work, we propose a\nnovel quantization-based forward diffusion process with theoretical foundations\nthat tackles all three aforementioned gaps. We achieve this through universal\nquantization with a carefully tailored quantization schedule and a diffusion\nmodel trained with uniform noise. Compared to previous work, our proposal\nproduces consistently realistic and detailed reconstructions, even at very low\nbitrates. In such a regime, we achieve the best rate-distortion-realism\nperformance, outperforming previous related works.","main_category":"eess.IV","categories":"eess.IV","published":"2025-04-03T13:42:19Z"}
{"aid":"http://arxiv.org/abs/2504.02583v1","title":"RamÃ­rez's problems and fibers on well approximable set of systems of\n  affine forms","summary":"We show that badly approximable matrices are exactly those that, for any\ninhomogeneous parameter, can not be inhomogeneous approximated at every\nmonotone divergent rate, which generalizes Ram\\'irez's result (2018). We also\nestablish some metrical results of the fibers on well approximable set of\nsystems of affine forms, which gives answer to two of Ram\\'irez's problems\n(2018). Furthermore, we prove that badly approximable systems are exactly those\nthat, can not be approximated at each monotone convergent rate {\\psi}.\nMoreover, we study the topological structure of the set of approximation\nfunctions.","main_category":"math.NT","categories":"math.NT,math.CA","published":"2025-04-03T13:49:12Z"}
{"aid":"http://arxiv.org/abs/2504.02590v1","title":"LexPam: Legal Procedure Awareness-Guided Mathematical Reasoning","summary":"The legal mathematical reasoning ability of LLMs is crucial when applying\nthem to real-world scenarios, as it directly affects the credibility of the\nLLM. While existing legal LLMs can perform general judicial question answering,\ntheir legal mathematical reasoning capabilities have not been trained.\nOpen-domain reasoning models, though able to generate detailed calculation\nsteps, do not follow the reasoning logic required for legal scenarios.\nAdditionally, there is currently a lack of legal mathematical reasoning\ndatasets to help validate and enhance LLMs' reasoning abilities in legal\ncontexts. To address these issues, we propose the first Chinese legal\nMathematical Reasoning Dataset, LexNum, which includes three common legal\nmathematical reasoning scenarios: economic compensation, work injury\ncompensation, and traffic accident compensation. Based on LexNum, we tested the\nperformance of existing legal LLMs and reasoning LLMs, and introduced LexPam, a\nreinforcement learning algorithm guided by legal procedural awareness to train\nLLMs, enhancing their mathematical reasoning abilities in legal scenarios.\nExperiments on tasks in the three legal scenarios show that the performance of\nexisting legal LLMs and reasoning models in legal mathematical reasoning tasks\nis unsatisfactory. LexPam can enhance the LLM's ability in these tasks.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T13:54:53Z"}
{"aid":"http://arxiv.org/abs/2504.02609v1","title":"One-loop correction to primordial tensor modes during radiation era","summary":"The ability to infer properties of primordial inflation relies on the\nconservation of the superhorizon perturbations between their exit during\ninflation, and their re-entry during radiation era. Any considerable departure\nfrom this property would require reinterpreting the data. This is why it is\nimportant to understand how superhorizon perturbations interact with the\nthermal plasma driving the radiation dominated Universe. We model the plasma by\nfree photons in a thermal state and compute the one-loop correction to the\npower spectrum of primordial tensor perturbations. This correction grows in\ntime and is not suppressed by any small parameter. While one-loop result is not\nreliable because it invalidates perturbation theory, it signals potentially\ninteresting effects that should be investigated further.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-03T14:10:50Z"}
{"aid":"http://arxiv.org/abs/2504.02616v1","title":"Cosmological gas accretion of Milky Way-type galaxies and the build-up\n  of galactic discs","summary":"In this work, we present results on the assembly of stellar discs belonging\nto Milky Way-type galaxies in the Auriga simulated sample. We study the net\naccretion of gas onto the disc region as a function of time and radius to\nassess the feasibility of the so-called inside-out formation of galaxy discs.\nWe found that most of the galaxies in our sample exhibit an inside-out disc\ngrowth, with younger stellar populations preferentially formed in the outer\nregions as accreted material turns into starts. This produces stable discs as\nlong as late-time accretion is free from significant external perturbations.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-03T14:14:47Z"}
{"aid":"http://arxiv.org/abs/2504.02650v1","title":"Investigating Simple Drawings of $K_n$ using SAT","summary":"We present a SAT framework which allows to investigate properties of simple\ndrawings of the complete graph $K_n$ using the power of AI. In contrast to\nclassic imperative programming, where a program is operated step by step, our\nframework models mathematical questions as Boolean formulas which are then\nsolved using modern SAT solvers. Our framework for simple drawings is based on\na characterization via rotation systems and finite forbidden substructures. We\nshowcase its universality by addressing various open problems, reproving\nprevious computational results and deriving several new computational results.\nIn particular, we test and progress on several unavoidable configurations such\nas variants of Rafla's conjecture on plane Hamiltonian cycles, Harborth's\nconjecture on empty triangles, and crossing families for general simple\ndrawings as well as for various subclasses. Moreover, based our computational\nresults we propose some new challenging conjectures.","main_category":"cs.CG","categories":"cs.CG,cs.DM,math.CO","published":"2025-04-03T14:48:47Z"}
{"aid":"http://arxiv.org/abs/2504.02653v1","title":"Online and Offline Space-Filling Input Design for Nonlinear System\n  Identification: A Receding Horizon Control-Based Approach","summary":"The effectiveness of data-driven techniques heavily depends on the input\nsignal used to generate the estimation data. However, a significant research\ngap exists in the field of input design for nonlinear dynamic system\nidentification. In particular, existing methods largely overlook the\nminimization of the generalization error, i.e., model inaccuracies in regions\nnot covered by the estimation dataset. This work addresses this gap by\nproposing an input design method that embeds a novel optimality criterion\nwithin a receding horizon control (RHC)-based optimization framework. The\ndistance-based optimality criterion induces a space-filling design within a\nuser-defined region of interest in a surrogate model's input space, requiring\nonly minimal prior knowledge. Additionally, the method is applicable both\nonline, where model parameters are continuously updated based on process\nobservations, and offline, where a fixed model is employed. The space-filling\nperformance of the proposed strategy is evaluated on an artificial example and\ncompared to state-of-the-art methods, demonstrating superior efficiency in\nexploring process operating spaces.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-03T14:50:52Z"}
{"aid":"http://arxiv.org/abs/2504.02661v1","title":"Complete Classification of the Symmetry Group of $L_p$-Minkowski Problem\n  on the Sphere","summary":"In Convex Geometry, a core topic is the $L_p$-Minkowski problem\n  \\begin{equation}\\label{e0.1}\n  \\det(\\nabla^2h+hI)=fh^{p-1}, \\ \\ \\forall X\\in{\\mathbb{S}}^n, \\ \\ \\forall p\\in\n\\mathbb{R}\n  \\end{equation} of Monge-Amp\\`{e}re type. By the transformation\n$u(x)=h(X)\\sqrt{1+|x|^2}$ and semi-spherical projection, equation \\eqref{e0.1}\ncan be reformulated by the Monge-Amp\\`{e}re type equation\n  \\begin{equation}\\label{e0.2}\n  \\det D^2u=(1+|x|^2)^{-\\frac{p+n+1}{2}}u^{p-1}, \\ \\ \\forall\nx\\in{\\mathbb{R}}^n, \\ \\ \\forall p\\in \\mathbb{R}\n  \\end{equation} on the Euclidean space. In this paper, we will firstly\ndetermine the symmetric groups of $n$-dimensional fully nonlinear equation\n\\eqref{e0.2} without asymptotic growth assumption. After proving several key\nresolution lemmas, we thus completely classify the symmetric groups of the\n$L_p$-Minkowski problem. Our method develops the Lie theory to fully nonlinear\nPDEs in Convex Geometry.","main_category":"math.AP","categories":"math.AP,math.DG","published":"2025-04-03T14:57:14Z"}
{"aid":"http://arxiv.org/abs/2504.02677v1","title":"Monte Carlo evaluations of gamma-ray and radio pulsar populations","summary":"Based on well-grounded Galactic neutron star populations formed from radio\npulsar population syntheses of canonical pulsars (CPs) and millisecond pulsars\n(MSPs), we use the latest Fermi-LAT catalog (4FGL-DR4) to investigate the\nimplications of proposed $\\gamma-$ray luminosity models. Using Monte Carlo\ntechniques, we calculate the number of CPs and MSPs that would comprise the\nsample of pulsar-like unidentified sources (PLUIDs) in 4FGL-DR4. While radio\nbeaming fractions were used to scale the sizes of the populations, when forming\nthe mock 4FGL-DR4 samples, we make the simplifying assumption that all\n$\\gamma-$ray pulsars are beaming towards the Earth. We then explore the\nobservable outcomes of seven different $\\gamma-$ray luminosity models. Four of\nthe models provide a good match to the observed number of PLUIDs, while three\nothers significantly over-predict the number of PLUIDs. For these latter\nmodels, either the average beaming fraction of $\\gamma-$ray pulsars is more\nlike 25--50\\%, or a revision in the luminosity scaling is required. Most of the\nradio detectable MSPs that our models predict as part of the PLUIDs within\n4FGL-DR4 are, unsurprisingly, fainter than the currently observed sample and at\nlarger dispersion measures. For CPs, in spite of an excellent match to the\nobserved radio population, none of the $\\gamma-$ray models we investigated\ncould replicate the observed sample of 150 $\\gamma-$ray CPs. Further work is\nrequired to understand this discrepancy. For both MSPs and CPs, we provide\nencouraging forecasts for targeted radio searches of PLUIDs from 4FGL-DR4 to\nelucidate the issues raised in this study.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-03T15:15:37Z"}
{"aid":"http://arxiv.org/abs/2504.02696v1","title":"The Tension between Trust and Oversight in Long-term Relationships","summary":"A principal continually decides whether to approve resource allocations to an\nagent, who exerts private effort to remain eligible. The principal must perform\ncostly inspections to determine the agent's eligibility. We characterize Markov\nPerfect Equilibria and analyze the paths of trust and oversight that emerge\nfrom the dynamic interplay of effort and oversight. At high trust levels,\neffort is an intertemporal substitute to oversight, which leads to unique\ninterior effort choices and random inspections. At low trust levels, effort is\nan intertemporal complement to oversight, which may create a coordination\nproblem, leading to equilibrium multiplicity. Voluntary disclosure can mitigate\nthis coordination issue.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-03T15:32:41Z"}
{"aid":"http://arxiv.org/abs/2504.02724v1","title":"Autonomous Human-Robot Interaction via Operator Imitation","summary":"Teleoperated robotic characters can perform expressive interactions with\nhumans, relying on the operators' experience and social intuition. In this\nwork, we propose to create autonomous interactive robots, by training a model\nto imitate operator data. Our model is trained on a dataset of human-robot\ninteractions, where an expert operator is asked to vary the interactions and\nmood of the robot, while the operator commands as well as the pose of the human\nand robot are recorded. Our approach learns to predict continuous operator\ncommands through a diffusion process and discrete commands through a\nclassifier, all unified within a single transformer architecture. We evaluate\nthe resulting model in simulation and with a user study on the real system. We\nshow that our method enables simple autonomous human-robot interactions that\nare comparable to the expert-operator baseline, and that users can recognize\nthe different robot moods as generated by our model. Finally, we demonstrate a\nzero-shot transfer of our model onto a different robotic platform with the same\noperator interface.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-03T16:06:44Z"}
{"aid":"http://arxiv.org/abs/2504.02730v1","title":"HQViT: Hybrid Quantum Vision Transformer for Image Classification","summary":"Transformer-based architectures have revolutionized the landscape of deep\nlearning. In computer vision domain, Vision Transformer demonstrates remarkable\nperformance on par with or even surpassing that of convolutional neural\nnetworks. However, the quadratic computational complexity of its self-attention\nmechanism poses challenges for classical computing, making model training with\nhigh-dimensional input data, e.g., images, particularly expensive. To address\nsuch limitations, we propose a Hybrid Quantum Vision Transformer (HQViT), that\nleverages the principles of quantum computing to accelerate model training\nwhile enhancing model performance. HQViT introduces whole-image processing with\namplitude encoding to better preserve global image information without\nadditional positional encoding. By leveraging quantum computation on the most\ncritical steps and selectively handling other components in a classical way, we\nlower the cost of quantum resources for HQViT. The qubit requirement is\nminimized to $O(log_2N)$ and the number of parameterized quantum gates is only\n$O(log_2d)$, making it well-suited for Noisy Intermediate-Scale Quantum\ndevices. By offloading the computationally intensive attention coefficient\nmatrix calculation to the quantum framework, HQViT reduces the classical\ncomputational load by $O(T^2d)$. Extensive experiments across various computer\nvision datasets demonstrate that HQViT outperforms existing models, achieving a\nmaximum improvement of up to $10.9\\%$ (on the MNIST 10-classification task)\nover the state of the art. This work highlights the great potential to combine\nquantum and classical computing to cope with complex image classification\ntasks.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-03T16:13:34Z"}
{"aid":"http://arxiv.org/abs/2504.02732v1","title":"Why do LLMs attend to the first token?","summary":"Large Language Models (LLMs) tend to attend heavily to the first token in the\nsequence -- creating a so-called attention sink. Many works have studied this\nphenomenon in detail, proposing various ways to either leverage or alleviate\nit. Attention sinks have been connected to quantisation difficulties, security\nissues, and streaming attention. Yet, while many works have provided conditions\nin which they occur or not, a critical question remains shallowly answered: Why\ndo LLMs learn such patterns and how are they being used? In this work, we argue\ntheoretically and empirically that this mechanism provides a method for LLMs to\navoid over-mixing, connecting this to existing lines of work that study\nmathematically how information propagates in Transformers. We conduct\nexperiments to validate our theoretical intuitions and show how choices such as\ncontext length, depth, and data packing influence the sink behaviour. We hope\nthat this study provides a new practical perspective on why attention sinks are\nuseful in LLMs, leading to a better understanding of the attention patterns\nthat form during training.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T16:17:55Z"}
{"aid":"http://arxiv.org/abs/2504.02738v1","title":"Inequivalence of the low-density insulating state and quantum Hall\n  insulating states in a strongly correlated two-dimensional electron system","summary":"We find that the behaviors of the voltage-current characteristics as one\nenters the low-density insulating state and integer quantum Hall insulating\nstates in the ultra-clean two-dimensional electron system in SiGe/Si/SiGe\nquantum wells are qualitatively different. The double-threshold voltage-current\ncurves, representative of electron solid formation at low densities, are not\nobserved in the quantum Hall regime, which does not confirm the existence of a\nquasi-particle quantum Hall Wigner solid and indicates that quasi-particles\nnear integer filling do not form an independent subsystem.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mes-hall","published":"2025-04-03T16:24:54Z"}
{"aid":"http://arxiv.org/abs/2504.02774v1","title":"Component-wise Krasnosel'skii type fixed point theorem in product spaces\n  and applications","summary":"We present a version of Krasnosel'skii fixed point theorem for operators\nacting on Cartesian products of normed linear spaces, under cone-compression\nand cone-expansion conditions of norm type. Our approach, based on the fixed\npoint index theory in cones, guarantees the existence of a coexistence fixed\npoint - that is, one with nontrivial components. As an application, we prove\nthe existence of periodic solutions with strictly positive components for a\nsystem of second-order differential equations. In particular, we address cases\ninvolving singular nonlinearities and hybrid terms, characterized by sublinear\nbehavior in one component and superlinear behavior in the other.","main_category":"math.FA","categories":"math.FA,math.CA","published":"2025-04-03T17:14:48Z"}
{"aid":"http://arxiv.org/abs/2504.02784v1","title":"The level of distribution of the sum-of-digits function in arithmetic\n  progressions","summary":"For $q \\geq 2$, $n \\in \\mathbb{N}$, let $s_{q}(n)$ denote the sum of the\ndigits of $n$ written in base $q$. Spiegelhofer (2020) proved that the\nThue--Morse sequence has level of distribution $1$, improving on a former\nresult of Fouvry and Mauduit (1996). In this paper we generalize this result to\nsequences of type $\\left\\{\\exp\\left(2\\pi i\\ell s_q(n)/b\\right)\\right\\}_{n \\in\n\\mathbb{N}}$ and provide an explicit exponent in the upper bound.","main_category":"math.NT","categories":"math.NT","published":"2025-04-03T17:27:02Z"}
{"aid":"http://arxiv.org/abs/2504.02795v1","title":"Greedy Regular Convolutions","summary":"We introduce a class of convolutions on arithmetical functions that are\nregular in the sense of of Narkiewicz, homogeneous in the sense of Burnett et\nal, and bounded, in the sense that there exists a common finite bound for the\nrank of primitive numbers. Among these \"greedy convolutions\" the unitary\nconvolution and the \"ternary convolution\" are particularly interesting: they\nare the only regular, homogeneous convolutions where each primitive number have\nthe same finite rank. While the greedy convolution of length 3, also described\nin detail, has primitive numbers of rank 3 and rank 1, it is still special in\nthat the set of primitives can be generated by a simple recursive procedure\nthat we name selective sifting.","main_category":"math.NT","categories":"math.NT","published":"2025-04-03T17:41:11Z"}
{"aid":"http://arxiv.org/abs/2504.04740v1","title":"Enhancing Compositional Reasoning in Vision-Language Models with\n  Synthetic Preference Data","summary":"Compositionality, or correctly recognizing scenes as compositions of atomic\nvisual concepts, remains difficult for multimodal large language models\n(MLLMs). Even state of the art MLLMs such as GPT-4o can make mistakes in\ndistinguishing compositions like \"dog chasing cat\" vs \"cat chasing dog\". While\non Winoground, a benchmark for measuring such reasoning, MLLMs have made\nsignificant progress, they are still far from a human's performance. We show\nthat compositional reasoning in these models can be improved by elucidating\nsuch concepts via data, where a model is trained to prefer the correct caption\nfor an image over a close but incorrect one. We introduce SCRAMBLe: Synthetic\nCompositional Reasoning Augmentation of MLLMs with Binary preference Learning,\nan approach for preference tuning open-weight MLLMs on synthetic preference\ndata generated in a fully automated manner from existing image-caption data.\nSCRAMBLe holistically improves these MLLMs' compositional reasoning\ncapabilities which we can see through significant improvements across multiple\nvision language compositionality benchmarks, as well as smaller but significant\nimprovements on general question answering tasks. As a sneak peek, SCRAMBLe\ntuned Molmo-7B model improves on Winoground from 49.5% to 54.8% (best reported\nto date), while improving by ~1% on more general visual question answering\ntasks. Code for SCRAMBLe along with tuned models and our synthetic training\ndataset is available at https://github.com/samarth4149/SCRAMBLe.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T05:35:34Z"}
{"aid":"http://arxiv.org/abs/2504.04761v1","title":"WLPCM Approach for Great Lakes Regulation","summary":"This study develops a water-level management model for the Great Lakes using\na predictive control framework. Requirement 1: Historical data (pre-2019)\nrevealed consistent monthly water-level patterns. A simulated annealing\nalgorithm optimized flow control via the Moses-Saunders Dam and Compensating\nWorks to align levels with multi-year benchmarks. Requirement 2: A Water Level\nPredictive Control Model (WLPCM) integrated delayed differential equations\n(DDEs) and model predictive control (MPC) to account for inflow/outflow\ndynamics and upstream time lags. Natural variables (e.g., precipitation) were\nmodeled via linear regression, while dam flow rates were optimized over 6-month\nhorizons with feedback adjustments for robustness. Requirement 3: Testing WLPCM\non 2017 data successfully mitigated Ottawa River flooding, outperforming\nhistorical records. Sensitivity analysis via the Sobol method confirmed model\nresilience to parameter variations. Requirement 4: Ice-clogging was identified\nas the most impactful natural variable (via RMSE-based sensitivity tests),\nfollowed by snowpack and precipitation. Requirement 5: Stakeholder demands\n(e.g., flood prevention, ecological balance) were incorporated into a fitness\nfunction. Compared to Plan 2014, WLPCM reduced catastrophic high levels in Lake\nOntario and excessive St. Lawrence River flows by prioritizing long-term\noptimization. Key innovations include DDE-based predictive regulation,\nreal-time feedback loops, and adaptive control under extreme conditions. The\nframework balances hydrological dynamics, stakeholder needs, and uncertainty\nmanagement, offering a scalable solution for large freshwater systems.","main_category":"math.OC","categories":"math.OC","published":"2025-04-07T06:21:22Z"}
{"aid":"http://arxiv.org/abs/2504.04767v1","title":"Extended URDF: Accounting for parallel mechanism in robot description","summary":"Robotic designs played an important role in recent advances by providing\npowerful robots with complex mechanics. Many recent systems rely on parallel\nactuation to provide lighter limbs and allow more complex motion. However,\nthese emerging architectures fall outside the scope of most used description\nformats, leading to difficulties when designing, storing, and sharing the\nmodels of these systems. This paper introduces an extension to the widely used\nUnified Robot Description Format (URDF) to support closed-loop kinematic\nstructures. Our approach relies on augmenting URDF with minimal additional\ninformation to allow more efficient modeling of complex robotic systems while\nmaintaining compatibility with existing design and simulation frameworks. This\nmethod sets the basic requirement for a description format to handle parallel\nmechanisms efficiently. We demonstrate the applicability of our approach by\nproviding an open-source collection of parallel robots, along with tools for\ngenerating and parsing this extended description format. The proposed extension\nsimplifies robot modeling, reduces redundancy, and improves usability for\nadvanced robotic applications.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T06:42:27Z"}
{"aid":"http://arxiv.org/abs/2504.04776v1","title":"Drastic softening of Pd nanoparticles induced by hydrogen cycling","summary":"Single crystalline faceted Pd nanoparticles attached to a sapphire substrate\nwere fabricated employing the solid state dewetting method. The as-dewetted\nnanoparticles tested in compression exhibited all features of dislocation\nnucleation-controlled plasticity, including the size effect on strength and\nultrahigh compressive strength reaching up to 11 GPa. Hydrogen cycling of\nas-dewetted Pd nanoparticles resulted in their drastic softening and in change\nof the deformation mode. This softening effect was correlated with the high\ndensity of glissile dislocations observed in the cycled particles. This work\ndemonstrates that the nanomechanical behavior of hydride-forming metals can be\nmanipulated by hydrogen cycling.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-07T07:09:10Z"}
{"aid":"http://arxiv.org/abs/2504.04786v1","title":"Dynamic fabrication method of SNAP microresonators","summary":"Surface Nanoscale Axial Photonics (SNAP) technology has demonstrated the\nrecord subangstrom fabrication precision of optical microresonators and\nresonant photonic circuits at the optical fiber surface. However, fabrication\nerrors arising from fluctuations of temperature, inscription parameters,\nalignment inconsistencies, and other factors did not allow researchers to\nachieve the subangstrom precision without sophisticated postprocessing. Here we\nshow that the key fabrication method of SNAP structures -- CO$_2$ laser beam\noptical fiber annealing -- suffers from significant fiber displacements which\nmay introduce a few percent fabrication errors. To suppress the effects of\nmisalignment, we develop a dynamic fabrication method employing a translating\nbeam exposure and demonstrate its excellent precision. The effective fiber\nradius variation of $\\sim 10 $nm is introduced with an error of $\\sim 0.1\n$angstrom. We suggest that the remaining fabrication errors can be attributed\nto laser power fluctuations.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-07T07:31:13Z"}
{"aid":"http://arxiv.org/abs/2504.04806v1","title":"Interplay Between Structural Defects and Charge Transport Dynamics in MA\n  and FA Modified CsSnI3 Thin Film Semiconductors","summary":"Owing high conductivity in microcrystalline thin-films, CsSnI3 perovskite is\na promising semiconductor for thermoelectrics and optoelectronics. Rapid\noxidation of thin-film and intrinsic lattice strain hinders stabilization of\nthe device performance. Cation engineering of perovskite molecule was\nconsidered as an effective strategy to tailor the structural properties and\nsuppress the degradation processes. However, molecular engineering demands a\nthorough analysis of defect behavior, as it can influence ionic motion,\nrecombination dynamics, and capacitive effects. The effective implementation of\nCsSnI3 in energy conversion devices requires careful consideration of the\nspecific properties of thin films electrical conductivity, Seebeck coefficient,\npower factor, as well as electronic transients, and charge transport in the\ndevice structures. In this work, we performed a complex investigation for\nmodified CsSnI3 through cation substitution with methyl ammonium (MA) and\nformamidinium (FA). Our findings highlight a complex interplay between\nelectrical parameters of the bare thin films and stability of the devices\n(p-i-n diodes) after thermal stress. FA-CsSnI3 showed beneficial results for\nstabilization under elevated temperatures with improved non-ideality factor in\ndiode structures, enhanced shunt properties and reduced trapping. The\nphoto-induced voltage relaxation spectroscopy performed for MA-CsSnI3 showed\nrelevant traps concentration of 1016 cm-3 with activation energy of 0.52\neV(210K) likely attributed to Sn atom defect. The obtained results are deeply\nanalyzed and discussed.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-07T08:02:17Z"}
{"aid":"http://arxiv.org/abs/2504.04843v1","title":"Data Augmentation as Free Lunch: Exploring the Test-Time Augmentation\n  for Sequential Recommendation","summary":"Data augmentation has become a promising method of mitigating data sparsity\nin sequential recommendation. Existing methods generate new yet effective data\nduring model training to improve performance. However, deploying them requires\nretraining, architecture modification, or introducing additional learnable\nparameters. The above steps are time-consuming and costly for well-trained\nmodels, especially when the model scale becomes large. In this work, we explore\nthe test-time augmentation (TTA) for sequential recommendation, which augments\nthe inputs during the model inference and then aggregates the model's\npredictions for augmented data to improve final accuracy. It avoids significant\ntime and cost overhead from loss calculation and backward propagation. We first\nexperimentally disclose the potential of existing augmentation operators for\nTTA and find that the Mask and Substitute consistently achieve better\nperformance. Further analysis reveals that these two operators are effective\nbecause they retain the original sequential pattern while adding appropriate\nperturbations. Meanwhile, we argue that these two operators still face\ntime-consuming item selection or interference information from mask tokens.\nBased on the analysis and limitations, we present TNoise and TMask. The former\ninjects uniform noise into the original representation, avoiding the\ncomputational overhead of item selection. The latter blocks mask token from\nparticipating in model calculations or directly removes interactions that\nshould have been replaced with mask tokens. Comprehensive experiments\ndemonstrate the effectiveness, efficiency, and generalizability of our method.\nWe provide an anonymous implementation at https://github.com/KingGugu/TTA4SR.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-07T08:56:16Z"}
{"aid":"http://arxiv.org/abs/2504.04849v1","title":"Discovering dynamical laws for speech gestures","summary":"A fundamental challenge in the cognitive sciences is discovering the dynamics\nthat govern behaviour. Take the example of spoken language, which is\ncharacterised by a highly variable and complex set of physical movements that\nmap onto the small set of cognitive units that comprise language. What are the\nfundamental dynamical principles behind the movements that structure speech\nproduction? In this study, we discover models in the form of symbolic equations\nthat govern articulatory gestures during speech. A sparse symbolic regression\nalgorithm is used to discover models from kinematic data on the tongue and\nlips. We explore these candidate models using analytical techniques and\nnumerical simulations, and find that a second-order linear model achieves high\nlevels of accuracy, but a nonlinear force is required to properly model\narticulatory dynamics in approximately one third of cases. This supports the\nproposal that an autonomous, nonlinear, second-order differential equation is a\nviable dynamical law for articulatory gestures in speech. We conclude by\nidentifying future opportunities and obstacles in data-driven model discovery\nand outline prospects for discovering the dynamical principles that govern\nlanguage, brain and behaviour.","main_category":"cs.CL","categories":"cs.CL,nlin.AO","published":"2025-04-07T09:03:32Z"}
{"aid":"http://arxiv.org/abs/2504.04860v1","title":"Stochastic differential equations driven by fractional Brownian motion:\n  dependence on the Hurst parameter","summary":"Stochastic models with fractional Brownian motion as source of randomness\nhave become popular since the early 2000s. Fractional Brownian motion (fBm) is\na Gaussian process, whose covariance depends on the so-called Hurst parameter\n$H\\in (0,1)$. Consequently, stochastic models with fBm also depend on the Hurst\nparameter $H$, and the stability of these models with respect to $H$ is an\ninteresting and important question. In recent years, the continuous (or even\nsmoother) dependence on the Hurst parameter has been studied for several\nstochastic models, including stochastic integrals with respect to fBm,\nstochastic differential equations (SDEs) driven by fBm and also stochastic\npartial differential equations with fractional noise, for different topologies,\ne.g., in law or almost surely, and for finite and infinite time horizons. In\nthis manuscript, we give an overview of these results with a particular focus\non SDE models.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T09:17:59Z"}
{"aid":"http://arxiv.org/abs/2504.04884v1","title":"Parallelization is All System Identification Needs: End-to-end Vibration\n  Diagnostics on a multi-core RISC-V edge device","summary":"The early detection of structural malfunctions requires the installation of\nreal-time monitoring systems ensuring continuous access to the damage-sensitive\ninformation; nevertheless, it can generate bottlenecks in terms of bandwidth\nand storage. Deploying data reduction techniques at the edge is recognized as a\nproficient solution to reduce the system's network traffic. However, the most\neffective solutions currently employed for the purpose are based on memory and\npower-hungry algorithms, making their embedding on resource-constrained devices\nvery challenging; this is the case of vibration data reduction based on System\nIdentification models. This paper presents PARSY-VDD, a fully optimized\nPArallel end-to-end software framework based on SYstem identification for\nVibration-based Damage Detection, as a suitable solution to perform damage\ndetection at the edge in a time and energy-efficient manner, avoiding streaming\nraw data to the cloud. We evaluate the damage detection capabilities of\nPARSY-VDD with two benchmarks: a bridge and a wind turbine blade, showcasing\nthe robustness of the end-to-end approach. Then, we deploy PARSY-VDD on both\ncommercial single-core and a specific multi-core edge device. We introduce an\narchitecture-agnostic algorithmic optimization for SysId, improving the\nexecution by 90x and reducing the consumption by 85x compared with the\nstate-of-the-art SysId implementation on GAP9. Results show that by utilizing\nthe unique parallel computing capabilities of GAP9, the execution time is\n751{\\mu}s with the high-performance multi-core solution operating at 370MHz and\n0.8V, while the energy consumption is 37{\\mu}J with the low-power solution\noperating at 240MHz and 0.65V. Compared with other single-core implementations\nbased on STM32 microcontrollers, the GAP9 high-performance configuration is 76x\nfaster, while the low-power configuration is 360x more energy efficient.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-07T09:51:02Z"}
{"aid":"http://arxiv.org/abs/2504.04962v1","title":"A refined operational semantics for FreeCHR","summary":"Constraint Handling Rules (CHR) is a rule-based programming language that\nwhich is typically embedded into a general-purpose language with a plethora of\nimplementations. However, the existing implementations often re-invent the way\nto embed CHR, which impedes maintenance and weakens assertions of correctness.\nTo formalize and thereby unify the embedding of CHR into arbitrary host\nlanguages, we recently introduced the framework FreeCHR and proved it to be a\nvalid representation of classical CHR. Until now, this framework only includes\na translation of the very abstract operational semantics of CHR which, due to\nits abstract nature, introduces several practical issues. In this paper we\npresent a definition of the refined operational semantics for FreeCHR and prove\nit to be both, a valid concretization of the very abstract semantics of\nFreeCHR, and an equivalent representation of the refined semantics of CHR. This\nwill establish implementations of FreeCHR as equivalent in behavior and\nexpressiveness to existing implementations of CHR. This is an extended preprint\nof a paper submitted to the the 41st International Conference on Logic\nProgramming.","main_category":"cs.PL","categories":"cs.PL","published":"2025-04-07T11:51:07Z"}
{"aid":"http://arxiv.org/abs/2504.04967v1","title":"Using AI to Help in the Semantic Lexical Database to Evaluate Ideas","summary":"Inside a challenge of ideas there are several phases in a Creative Support\nSystem (CSS), they are problem analysis, ideation, evaluation, and\nimplementation. Our problem: we need a full semantic lexical database SLD in an\noral (voice) and writing way to help stakeholders to create ideas, these ideas\ncontain nouns, verbs, adverbs, adjectives in the English, Spanish, and French\nlanguages. We utilize a Cloud Service Provider to use a service of Artificial\nIntelligence (AI), also we prepare nouns, verbs, adjectives and adverbs files\nin order to create the service text to voice and create our SLD with voice.\nThis paper presents, first, an introduction about some contests that use a\nsemantic lexical database in different languages; second, a SLD management\napproach using analysis of texts; third, a management application approach to\ncomplete all the new elements; fourth, the results of the management\napplication approach, finally the conclusions and future work.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-07T11:54:06Z"}
{"aid":"http://arxiv.org/abs/2504.04972v1","title":"Sub-diffusive behavior of a recurrent Axis-Driven Random Walk","summary":"We study the second order of the number of excursions of a simple random walk\nwith a bias that drives a return toward the origin along the axes introduced by\nP. Andreoletti and P. Debs \\cite{AndDeb3}. This is a crucial step toward\nderiving the asymptotic behavior of these walks, whose limit is explicit and\nreveals various characteristics of the process: the invariant probability\nmeasure of the extracted coordinates away from the axes, the 1-stable\ndistribution arising from the tail distribution of entry times on the axes, and\nfinally, the presence of a Bessel process of dimension 3, which implies that\nthe trajectory can be interpreted as a random path conditioned to stay within a\nsingle quadrant.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T11:58:11Z"}
{"aid":"http://arxiv.org/abs/2504.04982v1","title":"Transforming Future Data Center Operations and Management via Physical\n  AI","summary":"Data centers (DCs) as mission-critical infrastructures are pivotal in\npowering the growth of artificial intelligence (AI) and the digital economy.\nThe evolution from Internet DC to AI DC has introduced new challenges in\noperating and managing data centers for improved business resilience and\nreduced total cost of ownership. As a result, new paradigms, beyond the\ntraditional approaches based on best practices, must be in order for future\ndata centers. In this research, we propose and develop a novel Physical AI\n(PhyAI) framework for advancing DC operations and management. Our system\nleverages the emerging capabilities of state-of-the-art industrial products and\nour in-house research and development. Specifically, it presents three core\nmodules, namely: 1) an industry-grade in-house simulation engine to simulate DC\noperations in a highly accurate manner, 2) an AI engine built upon NVIDIA\nPhysicsNemo for the training and evaluation of physics-informed machine\nlearning (PIML) models, and 3) a digital twin platform built upon NVIDIA\nOmniverse for our proposed 5-tier digital twin framework. This system presents\na scalable and adaptable solution to digitalize, optimize, and automate future\ndata center operations and management, by enabling real-time digital twins for\nfuture data centers. To illustrate its effectiveness, we present a compelling\ncase study on building a surrogate model for predicting the thermal and airflow\nprofiles of a large-scale DC in a real-time manner. Our results demonstrate its\nsuperior performance over traditional time-consuming Computational Fluid\nDynamics/Heat Transfer (CFD/HT) simulation, with a median absolute temperature\nprediction error of 0.18 {\\deg}C. This emerging approach would open doors to\nseveral potential research directions for advancing Physical AI in future DC\noperations.","main_category":"cs.AI","categories":"cs.AI,cs.DC","published":"2025-04-07T12:09:22Z"}
{"aid":"http://arxiv.org/abs/2504.04995v1","title":"The universal crossover from thermodynamics and dynamics of\n  supercritical RN-AdS black hole","summary":"We study the properties of supercritical Reissner-Nordstr\\\"om Anti-de Sitter\n(RN-AdS) black holes in the extended phase space with the pressure defines as\nthe cosmological constant. Supercritical black holes exist in the region where\nboth temperature and pressure exceed the critical point, known as the\nsupercritical region. The conventional view states that black holes in this\nregime are indistinguishable between large and small phases. However, recent\nresearch reveals that the supercritical regime exhibits universal gas-like and\nliquid-like phase separation, which shed light on the study on the\nsupercritical region of RN-AdS black holes in the extended phase space. In this\nwork, we calculate the thermodynamic potential and quasinormal modes (QNMs) of\nRN-AdS black holes, and identify transition curves between two different states\nin supercritical region using thermodynamic and dynamic methods. On one hand,\nwe find the thermodynamic crossover curve (Widom line) by defining the scaled\nvariance $\\Omega$ (a higher-order derivative of Gibbs free energy). On the\nother hand, we identify the dynamic crossover curve (Frenkel line) by analyzing\ntransitions between distinct QNM decay modes.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-ph,hep-th","published":"2025-04-07T12:24:23Z"}
{"aid":"http://arxiv.org/abs/2504.05003v1","title":"Re-evaluation of the deuteron-deuteron thermonuclear reaction rates in\n  metallic deuterium plasma","summary":"The deuteron-deuteron (D-D) thermonuclear reaction rates in metallic\nenvironments (considering the electron screening effects) is re-evaluated using\nthe S-factor functions which\n  were obtained by fitting to low-energy data on D-D reactions.\n  For this purpose, a fitted S-factor model based on the NACRE compilation is\nemployed.\n  This limited the energy range of Big Bang nucleosynthesis (BBN) for\n  the $ ^{2}\\textrm{H}\\left(d,p\\right) ^{3}\\textrm{H}$ and $^{2} \\textrm{H}\n\\left(d,n\\right) ^{3}\\textrm{He}$ reactions.\n  The corresponding Maxwellian-averaged thermonuclear reaction\n  rates of relevance in astrophysical plasmas at temperatures in the\n  range from $10^{6}$ K to $10^{10}\\left(\\textrm{or }1.3\\times10^{8}\\right)$ K\nare provided in tabular formats.\n  In these evaluations,\n  the screening energy is assumed to be $100, 400, 750, 1000$ eV and $1250$ eV.\n  This series of values has been selected based on theoretical and experimental\nstudies conducted so far.","main_category":"nucl-th","categories":"nucl-th,nucl-ex","published":"2025-04-07T12:30:20Z"}
{"aid":"http://arxiv.org/abs/2504.05015v1","title":"PVASS Reachability is Decidable","summary":"Reachability in pushdown vector addition systems with states (PVASS) is among\nthe longest standing open problems in Theoretical Computer Science. We show\nthat the problem is decidable in full generality. Our decision procedure is\nsimilar in spirit to the KLMST algorithm for VASS reachability, but works over\nobjects that support an elaborate form of procedure summarization as known from\npushdown reachability.","main_category":"cs.LO","categories":"cs.LO,cs.FL,F.1.1","published":"2025-04-07T12:40:18Z"}
{"aid":"http://arxiv.org/abs/2504.05046v1","title":"MotionPRO: Exploring the Role of Pressure in Human MoCap and Beyond","summary":"Existing human Motion Capture (MoCap) methods mostly focus on the visual\nsimilarity while neglecting the physical plausibility. As a result, downstream\ntasks such as driving virtual human in 3D scene or humanoid robots in real\nworld suffer from issues such as timing drift and jitter, spatial problems like\nsliding and penetration, and poor global trajectory accuracy. In this paper, we\nrevisit human MoCap from the perspective of interaction between human body and\nphysical world by exploring the role of pressure. Firstly, we construct a\nlarge-scale human Motion capture dataset with Pressure, RGB and Optical sensors\n(named MotionPRO), which comprises 70 volunteers performing 400 types of\nmotion, encompassing a total of 12.4M pose frames. Secondly, we examine both\nthe necessity and effectiveness of the pressure signal through two challenging\ntasks: (1) pose and trajectory estimation based solely on pressure: We propose\na network that incorporates a small kernel decoder and a long-short-term\nattention module, and proof that pressure could provide accurate global\ntrajectory and plausible lower body pose. (2) pose and trajectory estimation by\nfusing pressure and RGB: We impose constraints on orthographic similarity along\nthe camera axis and whole-body contact along the vertical axis to enhance the\ncross-attention strategy to fuse pressure and RGB feature maps. Experiments\ndemonstrate that fusing pressure with RGB features not only significantly\nimproves performance in terms of objective metrics, but also plausibly drives\nvirtual humans (SMPL) in 3D scene. Furthermore, we demonstrate that\nincorporating physical perception enables humanoid robots to perform more\nprecise and stable actions, which is highly beneficial for the development of\nembodied artificial intelligence. Project page is available at:\nhttps://nju-cite-mocaphumanoid.github.io/MotionPRO/","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:17:24Z"}
{"aid":"http://arxiv.org/abs/2504.05049v1","title":"CMaP-SAM: Contraction Mapping Prior for SAM-driven Few-shot Segmentation","summary":"Few-shot segmentation (FSS) aims to segment new classes using few annotated\nimages. While recent FSS methods have shown considerable improvements by\nleveraging Segment Anything Model (SAM), they face two critical limitations:\ninsufficient utilization of structural correlations in query images, and\nsignificant information loss when converting continuous position priors to\ndiscrete point prompts. To address these challenges, we propose CMaP-SAM, a\nnovel framework that introduces contraction mapping theory to optimize position\npriors for SAM-driven few-shot segmentation. CMaP-SAM consists of three key\ncomponents: (1) a contraction mapping module that formulates position prior\noptimization as a Banach contraction mapping with convergence guarantees. This\nmodule iteratively refines position priors through pixel-wise structural\nsimilarity, generating a converged prior that preserves both semantic guidance\nfrom reference images and structural correlations in query images; (2) an\nadaptive distribution alignment module bridging continuous priors with SAM's\nbinary mask prompt encoder; and (3) a foreground-background decoupled\nrefinement architecture producing accurate final segmentation masks. Extensive\nexperiments demonstrate CMaP-SAM's effectiveness, achieving state-of-the-art\nperformance with 71.1 mIoU on PASCAL-$5^i$ and 56.1 on COCO-$20^i$ datasets.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:19:16Z"}
{"aid":"http://arxiv.org/abs/2504.05065v1","title":"Quantitative Supermartingale Certificates","summary":"We introduce a general methodology for quantitative model checking and\ncontrol synthesis with supermartingale certificates. We show that every\nspecification that is invariant to time shifts admits a stochastic invariant\nthat bounds its probability from below; for systems with general state space,\nthe stochastic invariant bounds this probability as closely as desired; for\nsystems with finite state space, it quantifies it exactly. Our result enables\nthe extension of every certificate for the almost-sure satisfaction of\nshift-invariant specifications to its quantitative counterpart, ensuring\ncompleteness up to an approximation in the general case and exactness in the\nfinite-state case. This generalises and unifies existing supermartingale\ncertificates for quantitative verification and control under reachability,\nsafety, reach-avoidance, and stability specifications, as well as asymptotic\nbounds on accrued costs and rewards. Furthermore, our result provides the first\nsupermartingale certificate for computing upper and lower bounds on the\nprobability of satisfying $\\omega$-regular and linear temporal logic\nspecifications. We present an algorithm for quantitative $\\omega$-regular\nverification and control synthesis based on our method and demonstrate its\npractical efficacy on several infinite-state examples.","main_category":"cs.LO","categories":"cs.LO,cs.SY,eess.SY","published":"2025-04-07T13:34:40Z"}
{"aid":"http://arxiv.org/abs/2504.05075v1","title":"PvNeXt: Rethinking Network Design and Temporal Motion for Point Cloud\n  Video Recognition","summary":"Point cloud video perception has become an essential task for the realm of 3D\nvision. Current 4D representation learning techniques typically engage in\niterative processing coupled with dense query operations. Although effective in\ncapturing temporal features, this approach leads to substantial computational\nredundancy. In this work, we propose a framework, named as PvNeXt, for\neffective yet efficient point cloud video recognition, via personalized\none-shot query operation. Specially, PvNeXt consists of two key modules, the\nMotion Imitator and the Single-Step Motion Encoder. The former module, the\nMotion Imitator, is designed to capture the temporal dynamics inherent in\nsequences of point clouds, thus generating the virtual motion corresponding to\neach frame. The Single-Step Motion Encoder performs a one-step query operation,\nassociating point cloud of each frame with its corresponding virtual motion\nframe, thereby extracting motion cues from point cloud sequences and capturing\ntemporal dynamics across the entire sequence. Through the integration of these\ntwo modules, {PvNeXt} enables personalized one-shot queries for each frame,\neffectively eliminating the need for frame-specific looping and intensive query\nprocesses. Extensive experiments on multiple benchmarks demonstrate the\neffectiveness of our method.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:43:51Z"}
{"aid":"http://arxiv.org/abs/2504.05110v1","title":"Stochastic storage models in theoretical physics problems","summary":"Stochastic storage models based on essentially non-Gaussian noise are\nconsidered. The stochastic description of physical systems based on stochastic\nstorage models is associated with generalized Poisson (or shot) noise, in which\nthe jump values can be quite large. Stochastic storage models have a direct\nphysical meaning: some elements enter the system and leave it. Storage\nprocesses fit into the general scheme of dynamic systems subject to the\nadditive influence of a random process. The main relationships of storage\nmodels are described, and the possibilities of applying the mathematical\nprovisions of stochastic storage processes to various physical problems are\nindicated. A number of examples of applying the stochastic storage model are\nconsidered.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-07T14:15:18Z"}
{"aid":"http://arxiv.org/abs/2504.05117v1","title":"On the Origins of \"Hostless'' Supernovae: Testing the Faint-end Galaxy\n  Luminosity Function and Supernova Progenitors with Events in Dwarf Galaxies","summary":"We present arguments on the likely origins of supernovae without associated\nhost galaxies from open field, non-clustered, environments. We show why it is\nunlikely these ``hostless'' supernovae stem from escaped hyper-velocity stars\n(HVS) in any appreciable numbers, especially for core-collapse supernovae. It\nis highly likely that hostless events arise from dwarf host galaxies too faint\nto be detected in their parent surveys. Several detections and numerous upper\nlimits suggest a large number of field dwarfs, to $M_V>-14$, which themselves\nmay be important to constraining the slope of the low-mass end of the UV\nluminosity function, understanding galaxy evolution, and putting $\\Lambda$CDM\ninto context. Moreover, the detailed study of these mass and\nmetallicity-constrained host environments, and the variety of supernovae that\noccur within them, could provide more stringent constraints on the nature of\nprogenitor systems.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-04-07T14:20:48Z"}
{"aid":"http://arxiv.org/abs/2504.05122v1","title":"DoCIA: An Online Document-Level Context Incorporation Agent for Speech\n  Translation","summary":"Document-level context is crucial for handling discourse challenges in\ntext-to-text document-level machine translation (MT). Despite the increased\ndiscourse challenges introduced by noise from automatic speech recognition\n(ASR), the integration of document-level context in speech translation (ST)\nremains insufficiently explored. In this paper, we develop DoCIA, an online\nframework that enhances ST performance by incorporating document-level context.\nDoCIA decomposes the ST pipeline into four stages. Document-level context is\nintegrated into the ASR refinement, MT, and MT refinement stages through\nauxiliary LLM (large language model)-based modules. Furthermore, DoCIA\nleverages document-level information in a multi-level manner while minimizing\ncomputational overhead. Additionally, a simple yet effective determination\nmechanism is introduced to prevent hallucinations from excessive refinement,\nensuring the reliability of the final results. Experimental results show that\nDoCIA significantly outperforms traditional ST baselines in both sentence and\ndiscourse metrics across four LLMs, demonstrating its effectiveness in\nimproving ST performance.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T14:26:49Z"}
{"aid":"http://arxiv.org/abs/2504.05128v1","title":"Kinetic study of compressible Rayleigh-Taylor instability with\n  time-varying acceleration","summary":"Rayleigh-Taylor (RT) instability commonly arises in compressible systems with\ntime-dependent acceleration in practical applications. To capture the complex\ndynamics of such systems, a two-component discrete Boltzmann method is\ndeveloped to systematically investigate the compressible RT instability driven\nby variable acceleration. Specifically, the effects of different acceleration\nperiods, amplitudes, and phases are systematically analyzed. The simulation\nresults are interpreted from three key perspectives: the density gradient,\nwhich characterizes the spatial variation in density; the thermodynamic\nnon-equilibrium strength, which quantifies the system's deviation from local\nthermodynamic equilibrium; and the fraction of non-equilibrium regions, which\ncaptures the spatial distribution of non-equilibrium behaviors. Notably, the\nfluid system exhibits rich and diverse dynamic patterns resulting from the\ninterplay of multiple competing physical mechanisms, including time-dependent\nacceleration, RT instability, diffusion, and dissipation effects. These\nfindings provide deeper insights into the evolution and regulation of\ncompressible RT instability under complex driving conditions.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-07T14:32:33Z"}
{"aid":"http://arxiv.org/abs/2504.05131v1","title":"One-Loop Transverse-Momentum-Dependent Soft Function at Higher Orders in\n  the Dimensional Regulator","summary":"The transverse-momentum-dependent (TMD) soft function for a generic\nhadroproduction process involving massive colored particles is analytically\ncalculated at the one-loop level, extended to higher orders in the dimensional\nregulator $\\epsilon$. We present both the azimuthal-angle-averaged and\nazimuthal-angle-dependent soft functions in impact-parameter space, making them\nsuitable for small $q_T$ resummation calculations. Their analytic expressions\nare provided in terms of multiple polylogarithms. Our results offer essential\ningredients for a complete higher-order perturbative calculation of the TMD\nsoft function.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-07T14:34:31Z"}
{"aid":"http://arxiv.org/abs/2504.05171v1","title":"A hydro-geomechanical porous-media model to study effects of engineered\n  carbonate precipitation in faults","summary":"Hydro-geomechanical models are required to predict or understand the impact\nof subsurface engineering applications as, for example, in gas storage in\ngeological formations. This study puts a focus on engineered carbonate\nprecipitation through biomineralization in a fault zone of a cap-rock to reduce\ngas leakage from a reservoir. Besides hydraulic properties like porosity and\npermeability, precipitated carbonates also change the mechanical properties of\nthe rock. We present a conceptual modeling approach implemented into the\nopen-source simulator Dumux and, after verification examples, at hand of a\nCO2-storage scenario, we discuss impacts of biomineralization on the stress\ndistribution in the rock and potentially altered risks of fault reactivations\nand induced seismic events.\n  The generic study shows the tendency towards increased stiffness due to\nprecipitated carbonate, which may cause shear failure events to occur earlier\nthan in an untreated setup, while the magnitude of the seismicity is smaller.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-07T15:15:12Z"}
{"aid":"http://arxiv.org/abs/2504.05196v1","title":"Universal Lymph Node Detection in Multiparametric MRI with Selective\n  Augmentation","summary":"Robust localization of lymph nodes (LNs) in multiparametric MRI (mpMRI) is\ncritical for the assessment of lymphadenopathy. Radiologists routinely measure\nthe size of LN to distinguish benign from malignant nodes, which would require\nsubsequent cancer staging. Sizing is a cumbersome task compounded by the\ndiverse appearances of LNs in mpMRI, which renders their measurement difficult.\nFurthermore, smaller and potentially metastatic LNs could be missed during a\nbusy clinical day. To alleviate these imaging and workflow problems, we propose\na pipeline to universally detect both benign and metastatic nodes in the body\nfor their ensuing measurement. The recently proposed VFNet neural network was\nemployed to identify LN in T2 fat suppressed and diffusion weighted imaging\n(DWI) sequences acquired by various scanners with a variety of exam protocols.\nWe also use a selective augmentation technique known as Intra-Label LISA (ILL)\nto diversify the input data samples the model sees during training, such that\nit improves its robustness during the evaluation phase. We achieved a\nsensitivity of $\\sim$83\\% with ILL vs. $\\sim$80\\% without ILL at 4 FP/vol.\nCompared with current LN detection approaches evaluated on mpMRI, we show a\nsensitivity improvement of $\\sim$9\\% at 4 FP/vol.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-07T15:46:43Z"}
{"aid":"http://arxiv.org/abs/2504.05206v1","title":"Content-aware rankings: a new approach to rankings in scholarship","summary":"Entity rankings (e.g., institutions, journals) are a core component of\nacademia and related industries. Existing approaches to institutional rankings\nhave relied on a variety of data sources, and approaches to computing outcomes,\nbut remain controversial. One limitation of existing approaches is reliance on\nscholarly output (e.g., number of publications associated with a given\ninstitution during a time period). We propose a new approach to rankings - one\nthat relies not on scholarly output, but rather on the type of citations\nreceived (an implementation of the Scite Index). We describe how the necessary\ndata can be gathered, as well as how relevant metrics are computed. To\ndemonstrate the utility of our approach, we present rankings of fields,\njournals, and institutions, and discuss the various ways Scite's data can be\ndeployed in the context of rankings. Implications, limitations, and future\ndirections are discussed.","main_category":"cs.DL","categories":"cs.DL","published":"2025-04-07T15:55:18Z"}
{"aid":"http://arxiv.org/abs/2504.05207v1","title":"Correcting Class Imbalances with Self-Training for Improved Universal\n  Lesion Detection and Tagging","summary":"Universal lesion detection and tagging (ULDT) in CT studies is critical for\ntumor burden assessment and tracking the progression of lesion status\n(growth/shrinkage) over time. However, a lack of fully annotated data hinders\nthe development of effective ULDT approaches. Prior work used the DeepLesion\ndataset (4,427 patients, 10,594 studies, 32,120 CT slices, 32,735 lesions, 8\nbody part labels) for algorithmic development, but this dataset is not\ncompletely annotated and contains class imbalances. To address these issues, in\nthis work, we developed a self-training pipeline for ULDT. A VFNet model was\ntrained on a limited 11.5\\% subset of DeepLesion (bounding boxes + tags) to\ndetect and classify lesions in CT studies. Then, it identified and incorporated\nnovel lesion candidates from a larger unseen data subset into its training set,\nand self-trained itself over multiple rounds. Multiple self-training\nexperiments were conducted with different threshold policies to select\npredicted lesions with higher quality and cover the class imbalances. We\ndiscovered that direct self-training improved the sensitivities of\nover-represented lesion classes at the expense of under-represented classes.\nHowever, upsampling the lesions mined during self-training along with a\nvariable threshold policy yielded a 6.5\\% increase in sensitivity at 4 FP in\ncontrast to self-training without class balancing (72\\% vs 78.5\\%) and a 11.7\\%\nincrease compared to the same self-training policy without upsampling (66.8\\%\nvs 78.5\\%). Furthermore, we show that our results either improved or maintained\nthe sensitivity at 4FP for all 8 lesion classes.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T15:57:03Z"}
{"aid":"http://arxiv.org/abs/2504.05232v1","title":"Discovery of the 7-ring PAH Cyanocoronene (C$_{24}$H$_{11}$CN) in GOTHAM\n  Observations of TMC-1","summary":"We present the synthesis and laboratory rotational spectroscopy of the 7-ring\npolycyclic aromatic hydrocarbon (PAH) cyanocoronene (C$_{24}$H$_{11}$CN) using\na laser-ablation assisted cavity-enhanced Fourier transform microwave\nspectrometer. A total of 71 transitions were measured and assigned between\n6.8--10.6\\,GHz. Using these assignments, we searched for emission from\ncyanocoronene in the GBT Observations of TMC-1: Hunting Aromatic Molecules\n(GOTHAM) project observations of the cold dark molecular cloud TMC-1 using the\n100\\,m Green Bank Telescope (GBT). We detect a number of individually resolved\ntransitions in ultrasensitive X-band observations and perform a Markov Chain\nMonte Carlo analysis to derive best-fit parameters, including a total column\ndensity of $N(\\mathrm{C}_{24}\\mathrm{H}_{11}\\mathrm{CN}) = 2.69^{+0.26}_{-0.23}\n\\times 10^{12}\\,\\mathrm{cm}^{-2}$ at a temperature of\n$6.05^{+0.38}_{-0.37}\\,$K. A spectral stacking and matched filtering analysis\nprovides a robust 17.3$\\,\\sigma$ significance to the overall detection. The\nderived column density is comparable to that of cyano-substituted naphthalene,\nacenaphthylene, and pyrene, defying the trend of decreasing abundance with\nincreasing molecular size and complexity found for carbon chains. We discuss\nthe implications of the detection for our understanding of interstellar PAH\nchemistry and highlight major open questions and next steps.","main_category":"astro-ph.GA","categories":"astro-ph.GA,physics.chem-ph","published":"2025-04-07T16:15:54Z"}
{"aid":"http://arxiv.org/abs/2504.05249v1","title":"Texture2LoD3: Enabling LoD3 Building Reconstruction With Panoramic\n  Images","summary":"Despite recent advancements in surface reconstruction, Level of Detail (LoD)\n3 building reconstruction remains an unresolved challenge. The main issue\npertains to the object-oriented modelling paradigm, which requires\ngeoreferencing, watertight geometry, facade semantics, and low-poly\nrepresentation -- Contrasting unstructured mesh-oriented models. In\nTexture2LoD3, we introduce a novel method leveraging the ubiquity of 3D\nbuilding model priors and panoramic street-level images, enabling the\nreconstruction of LoD3 building models. We observe that prior low-detail\nbuilding models can serve as valid planar targets for ortho-rectifying\nstreet-level panoramic images. Moreover, deploying segmentation on accurately\ntextured low-level building surfaces supports maintaining essential\ngeoreferencing, watertight geometry, and low-poly representation for LoD3\nreconstruction. In the absence of LoD3 validation data, we additionally\nintroduce the ReLoD3 dataset, on which we experimentally demonstrate that our\nmethod leads to improved facade segmentation accuracy by 11% and can replace\ncostly manual projections. We believe that Texture2LoD3 can scale the adoption\nof LoD3 models, opening applications in estimating building solar potential or\nenhancing autonomous driving simulations. The project website, code, and data\nare available here: https://wenzhaotang.github.io/Texture2LoD3/.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-07T16:40:16Z"}
{"aid":"http://arxiv.org/abs/2504.05286v1","title":"UK APAP R-matrix electron-impact excitation cross-sections for modelling\n  laboratory and astrophysical plasma","summary":"Systematic R-matrix calculations of electron-impact excitation for ions of\nastrophysical interest have been performed since 2007 for many iso-electronic\nsequences as part of the UK Atomic Process for Astrophysical Plasma (APAP)\nnetwork. Rate coefficients for Maxwellian electron distributions have been\nprovided and used extensively in the literature and many databases for\nastrophysics. Here, we provide averaged collision strengths to be used to model\nplasma where electrons are non-Maxwellian, which often occur in laboratory and\nastrophysical plasma. We also provide for many ions new Maxwellian-averaged\ncollision strengths which include important corrections to the published\nvalues. The H- and He-like atomic data were recently made available in\nMao+(2022). Here, we provide data for ions of the Li-, Be-, B-, C-, N-, O-,\nNe-, Na-, and Mg-like sequences.","main_category":"physics.atom-ph","categories":"physics.atom-ph,astro-ph.IM,astro-ph.SR","published":"2025-04-07T17:37:09Z"}
{"aid":"http://arxiv.org/abs/2504.05627v1","title":"Maternal and Fetal Health Status Assessment by Using Machine Learning on\n  Optical 3D Body Scans","summary":"Monitoring maternal and fetal health during pregnancy is crucial for\npreventing adverse outcomes. While tests such as ultrasound scans offer high\naccuracy, they can be costly and inconvenient. Telehealth and more accessible\nbody shape information provide pregnant women with a convenient way to monitor\ntheir health. This study explores the potential of 3D body scan data, captured\nduring the 18-24 gestational weeks, to predict adverse pregnancy outcomes and\nestimate clinical parameters. We developed a novel algorithm with two parallel\nstreams which are used for extract body shape features: one for supervised\nlearning to extract sequential abdominal circumference information, and another\nfor unsupervised learning to extract global shape descriptors, alongside a\nbranch for demographic data.\n  Our results indicate that 3D body shape can assist in predicting preterm\nlabor, gestational diabetes mellitus (GDM), gestational hypertension (GH), and\nin estimating fetal weight. Compared to other machine learning models, our\nalgorithm achieved the best performance, with prediction accuracies exceeding\n88% and fetal weight estimation accuracy of 76.74% within a 10% error margin,\noutperforming conventional anthropometric methods by 22.22%.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-08T03:02:26Z"}
{"aid":"http://arxiv.org/abs/2504.05648v1","title":"The stochastic Navier-Stokes equations with general $L^{3}$ data","summary":"We consider the stochastic Navier-Stokes equations with multiplicative noise\nwith critical initial data. Assuming that the initial data $u_0$ belongs to the\ncritical space $L^{3}$ almost surely, we construct a unique local-in-time\nprobabilistically strong solution. We also prove an analogous result for data\nin the critical space~$H^\\frac{1}{2}$.","main_category":"math.PR","categories":"math.PR,math.AP","published":"2025-04-08T03:52:54Z"}
{"aid":"http://arxiv.org/abs/2504.05697v1","title":"VADIS: A Visual Analytics Pipeline for Dynamic Document Representation\n  and Information-Seeking","summary":"In the biomedical domain, visualizing the document embeddings of an extensive\ncorpus has been widely used in information-seeking tasks. However, three key\nchallenges with existing visualizations make it difficult for clinicians to\nfind information efficiently. First, the document embeddings used in these\nvisualizations are generated statically by pretrained language models, which\ncannot adapt to the user's evolving interest. Second, existing document\nvisualization techniques cannot effectively display how the documents are\nrelevant to users' interest, making it difficult for users to identify the most\npertinent information. Third, existing embedding generation and visualization\nprocesses suffer from a lack of interpretability, making it difficult to\nunderstand, trust and use the result for decision-making. In this paper, we\npresent a novel visual analytics pipeline for user driven document\nrepresentation and iterative information seeking (VADIS). VADIS introduces a\nprompt-based attention model (PAM) that generates dynamic document embedding\nand document relevance adjusted to the user's query. To effectively visualize\nthese two pieces of information, we design a new document map that leverages a\ncircular grid layout to display documents based on both their relevance to the\nquery and the semantic similarity. Additionally, to improve the\ninterpretability, we introduce a corpus-level attention visualization method to\nimprove the user's understanding of the model focus and to enable the users to\nidentify potential oversight. This visualization, in turn, empowers users to\nrefine, update and introduce new queries, thereby facilitating a dynamic and\niterative information-seeking experience. We evaluated VADIS quantitatively and\nqualitatively on a real-world dataset of biomedical research papers to\ndemonstrate its effectiveness.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-08T05:39:11Z"}
{"aid":"http://arxiv.org/abs/2504.05704v1","title":"Wave propagation and scattering in time dependent media:\n  Lippmann-Schwinger equations, multiple scattering theory, Kirchhoff Helmholtz\n  integrals, Green's functions, reciprocity theorems and Huygens' principle","summary":"Wave scattering plays a central role for the modeling of complex wave\npropagation across all corners of science and engineering applications,\nincluding electromagnetic, acoustics, seismic and scattering physics. Wave\ncontrol using time interfaces, where the properties of the medium through with\nthe wave travels rapidly change in time, has opened further opportunities to\ncontrol wave propagation in both space and time. For acoustic waves, studies on\ntime modulated media have not been reported. In this context, full numerical\nsolution of the wave equation using time interfaces is key to fully understand\ntheir potential. When applying time interfaces, the underlying physics of\nacoustic wave propagation and scattering and their similar roles on time and\nspace, are still being explored. In this work, we introduce a mathematical\nformulation of the Lippmann-Schwinger integral equations for acoustic wave\nscattering when time interfaces are induced via a change of the velocity of the\nmedium. We demonstrate that space-time duality for acoustic wave propagation\nwith time interfaces and derive the Lippmann-Schwinger integral equations for\nwave scattering in time-dependent media, multiple scattering theory, Kirchhoff\nHelmholtz integrals, Green's functions, reciprocity theorems. We experimentally\nverify our theoretical derivation by studying and measuring the acoustic wave\nscattering in strongly scattering media. We illustrate the proposed framework\nand present results of acoustic wave scattering without prior knowledge of the\nbackground wave-fields. This improves the understanding of the generation and\nwave scattering and opens previously inaccessible research directions,\npotentially facilitating practical applications for acoustic, geophysical and\noptical imaging.","main_category":"physics.optics","categories":"physics.optics,physics.geo-ph","published":"2025-04-08T05:56:20Z"}
{"aid":"http://arxiv.org/abs/2504.05713v1","title":"Revisiting poverty measures using quantile functions","summary":"In this article we redefine various poverty measures in literature in terms\nof quantile functions instead of distribution functions in the prevailing\napproach. This enables provision for alternative methodology for poverty\nmeasurement and analysis along with some new results that are difficult to\nobtain in the existing framework. Several flexible quantile function models\nthat can enrich the existing ones are proposed and their utility is\ndemonstrated for real data.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-08T06:15:17Z"}
{"aid":"http://arxiv.org/abs/2504.05737v1","title":"Developing a novel hybrid family associated with hypergeometric\n  functions through umbral techniques","summary":"The umbral methods are used to reformulate the theoretical framework of\nspecial functions and provide powerful techniques for uncovering new extensions\nand relationships among these functions. This research article introduces an\ninnovative class of special polynomials, specifically the hypergeometric-Appell\npolynomials. The fundamental attributes of this versatile family of special\npolynomials are outlined, including generating relations, explicit\nrepresentations, and differential recurrence relations. Certain particular\nexamples that belong to the class of hypergeometric-Appell polynomials are also\nconsidered. This article aims to reinforce the broad applicability of the\numbral approach to address complex mathematical challenges and contribute to\nvarious scientific and engineering endeavors.","main_category":"math.CA","categories":"math.CA","published":"2025-04-08T07:12:20Z"}
{"aid":"http://arxiv.org/abs/2504.05743v1","title":"Causal Portfolio Optimization: Principles and Sensitivity-Based\n  Solutions","summary":"Fundamental and necessary principles for achieving efficient portfolio\noptimization based on asset and diversification dynamics are presented. The\nCommonality Principle is a necessary and sufficient condition for identifying\noptimal drivers of a portfolio in terms of its diversification dynamics. The\nproof relies on the Reichenbach Common Cause Principle, along with the fact\nthat the sensitivities of portfolio constituents with respect to the common\ncausal drivers are themselves causal. A conformal map preserves idiosyncratic\ndiversification from the unconditional setting while optimizing systematic\ndiversification on an embedded space of these sensitivities. Causal\nmethodologies for combinatorial driver selection are presented, such as the use\nof Bayesian networks and correlation-based algorithms from Reichenbach's\nprinciple. Limitations of linear models in capturing causality are discussed,\nand included for completeness alongside more advanced models such as neural\nnetworks. Portfolio optimization methods are presented that map risk from the\nsensitivity space to other risk measures of interest. Finally, the work\nintroduces a novel risk management framework based on Common Causal Manifolds,\nincluding both theoretical development and experimental validation. The\nsensitivity space is predicted along the common causal manifold, which is\nmodeled as a causal time system. Sensitivities are forecasted using SDEs\ncalibrated to data previously extracted from neural networks to move along the\nmanifold via its tangent bundles. An optimization method is then proposed that\naccumulates information across future predicted tangent bundles on the common\ncausal time system manifold. It aggregates sensitivity-based distance metrics\nalong the trajectory to build a comprehensive sensitivity distance matrix. This\nmatrix enables trajectory-wide optimal diversification, taking into account\nfuture dynamics.","main_category":"q-fin.PM","categories":"q-fin.PM","published":"2025-04-08T07:21:40Z"}
{"aid":"http://arxiv.org/abs/2504.05754v1","title":"Dispersion-corrected Machine Learning Potentials for 2D van der Waals\n  Materials","summary":"Machine-learned interatomic potentials (MLIPs) based on message passing\nneural networks hold promise to enable large-scale atomistic simulations of\ncomplex materials with ab initio accuracy. A number of MLIPs trained on\nenergies and forces from density functional theory (DFT) calculations employing\nsemi-local exchange-correlation (xc) functionals have recently been introduced.\nHere, we benchmark the performance of six dispersion-corrected MLIPs on a\ndataset of van der Waals heterobilayers containing between 4 and 300 atoms in\nthe moir\\'e cell. Using various structure similarity metrics, we compare the\nrelaxed heterostructures to the ground truth DFT results. With some notable\nexceptions, the model precisions are comparable to the uncertainty on the DFT\nresults stemming from the choice of xc-functional. We further explore how the\nstructural inaccuracies propagate to the electronic properties, and find\nexcellent performance with average errors on band energies as low as 35 meV.\nOur results demonstrate that recent MLIPs after dispersion corrections are on\npar with DFT for general vdW heterostructures, and thus justify their\napplication to complex and experimentally relevant 2D materials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T07:35:53Z"}
{"aid":"http://arxiv.org/abs/2504.05760v1","title":"Cutoff for East models at high temperature","summary":"We consider the East model in $\\mathbb Z^d$, an example of a kinetically\nconstrained interacting particle system with oriented constraints, together\nwith one of its natural variant. Under any ergodic boundary condition it is\nknown that the mixing time of the chain in a box of side $L$ is $\\Theta(L)$ for\nany $d\\ge 1$. Moreover, with minimal boundary conditions and at low\ntemperature, i.e. low equilibrium density of the facilitating vertices, the\nchain exhibits cutoff around the mixing time of the $d=1$ case. Here we extend\nthis result to high temperature. As in the low temperature case, the key tool\nis to prove that the speed of infection propagation in the $(1,1,\\dots,1)$\ndirection is larger than $d$ $\\times$ the same speed along a coordinate\ndirection. By borrowing a technique from first passage percolation, the proof\nlinks the result to the precise value of the critical probability of oriented\n(bond or site) percolation in $\\mathbb Z^d$.","main_category":"math.PR","categories":"math.PR","published":"2025-04-08T07:42:29Z"}
{"aid":"http://arxiv.org/abs/2504.05762v1","title":"Statistics of velocity gradient and vortex sheet structures in polymeric\n  turbulent von K{Ã¡}rm{Ã¡}n swirling flow","summary":"Investigations into the effects of polymers on small-scale statistics and\nflow patterns were conducted in a turbulent von Karman swirling (VKS) flow. We\nemployed the tomographic particle image velocimetry (Tomo-PIV) technique to\nobtain full information on three-dimensional velocity data, allowing us to\neffectively resolve dissipation scales. Under varying Reynolds numbers\n($R_\\lambda=168 - 235$) and polymer concentrations ($\\phi=0 -25~\\rm ppm$), we\nmeasured the velocity gradient tensor (VGT) and related quantities. Our\nfindings reveal that the ensemble average and probability density function\n(PDF) of VGT invariants, which represent turbulent dissipation and enstrophy\nalong with their generation terms, are suppressed as polymer concentration\nincreases. Notably, the joint PDFs of the invariants of VGT, which characterize\nlocal flow patterns, exhibited significant changes. Specifically, the\nthird-order invariants, especially the local vortex stretching, are greatly\nsuppressed, and strong events of dissipation and enstrophy coexist in space.\nThe local flow pattern tends to be two-dimensional, where the eigenvalues of\nthe rate-of-strain tensor satisfy a ratio $1:0:-1$, and the vorticity aligns\nwith the intermediate eigenvector of the rate-of-strain tensor while is\nperpendicular to the other two. We find that these statistics observations can\nbe well described by the vortex sheet model. Moreover, we find that these\nvortex sheet structures align with the symmetry axis of the VKS system and\norient randomly in the horizontal plane. Further investigation, including flow\nvisualization and conditional statistics on vorticity, confirms the presence of\nvortex sheet structures in turbulent flows with polymer additions. Our results\nestablish a link between single-point statistics and small-scale flow topology,\nshedding light on the previously overlooked small-scale structures in polymeric\nturbulence.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-08T07:43:17Z"}
{"aid":"http://arxiv.org/abs/2504.05774v1","title":"Transferable Mask Transformer: Cross-domain Semantic Segmentation with\n  Region-adaptive Transferability Estimation","summary":"Recent advances in Vision Transformers (ViTs) have set new benchmarks in\nsemantic segmentation. However, when adapting pretrained ViTs to new target\ndomains, significant performance degradation often occurs due to distribution\nshifts, resulting in suboptimal global attention. Since self-attention\nmechanisms are inherently data-driven, they may fail to effectively attend to\nkey objects when source and target domains exhibit differences in texture,\nscale, or object co-occurrence patterns. While global and patch-level domain\nadaptation methods provide partial solutions, region-level adaptation with\ndynamically shaped regions is crucial due to spatial heterogeneity in\ntransferability across different image areas. We present Transferable Mask\nTransformer (TMT), a novel region-level adaptation framework for semantic\nsegmentation that aligns cross-domain representations through spatial\ntransferability analysis. TMT consists of two key components: (1) An Adaptive\nCluster-based Transferability Estimator (ACTE) that dynamically segments images\ninto structurally and semantically coherent regions for localized\ntransferability assessment, and (2) A Transferable Masked Attention (TMA)\nmodule that integrates region-specific transferability maps into ViTs'\nattention mechanisms, prioritizing adaptation in regions with low\ntransferability and high semantic uncertainty. Comprehensive evaluations across\n20 cross-domain pairs demonstrate TMT's superiority, achieving an average 2%\nMIoU improvement over vanilla fine-tuning and a 1.28% increase compared to\nstate-of-the-art baselines. The source code will be publicly available.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-08T07:53:51Z"}
{"aid":"http://arxiv.org/abs/2504.05795v1","title":"Robust Fusion Controller: Degradation-aware Image Fusion with\n  Fine-grained Language Instructions","summary":"Current image fusion methods struggle to adapt to real-world environments\nencompassing diverse degradations with spatially varying characteristics. To\naddress this challenge, we propose a robust fusion controller (RFC) capable of\nachieving degradation-aware image fusion through fine-grained language\ninstructions, ensuring its reliable application in adverse environments.\nSpecifically, RFC first parses language instructions to innovatively derive the\nfunctional condition and the spatial condition, where the former specifies the\ndegradation type to remove, while the latter defines its spatial coverage.\nThen, a composite control priori is generated through a multi-condition\ncoupling network, achieving a seamless transition from abstract language\ninstructions to latent control variables. Subsequently, we design a hybrid\nattention-based fusion network to aggregate multi-modal information, in which\nthe obtained composite control priori is deeply embedded to linearly modulate\nthe intermediate fused features. To ensure the alignment between language\ninstructions and control outcomes, we introduce a novel language-feature\nalignment loss, which constrains the consistency between feature-level gains\nand the composite control priori. Extensive experiments on publicly available\ndatasets demonstrate that our RFC is robust against various composite\ndegradations, particularly in highly challenging flare scenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T08:22:55Z"}
{"aid":"http://arxiv.org/abs/2504.05834v1","title":"Elongation-Induced Segregation in Periodically Textured Microfluidic\n  Channels","summary":"We numerically investigate the motion of elongated microparticles in\nmicrofluidic channels at low Reynolds numbers. In channels with smooth walls,\nasymmetric initial conditions -- including particle orientation and lateral\nposition -- lead to continuous variations in particle trajectories, potentially\nexhibiting repeated behavior depending on the channel geometry and initial\nconditions. However, we find that introducing periodically textured walls\ninduces alignment of the particle with the channel centerline within a specific\nrange of texture wavelengths. This occurs as the textured pattern disrupts the\nuniformity of the flow, creating localized high-velocity nodes that repeatedly\nguide the particle toward the centerline as it moves downstream. Notably, the\ncharacteristic length scale over which this alignment forms reduces with\nincreasing particle elongation and diverges with increasing Reynolds number.\nOur findings reveal that elongation-induced alignment can be leveraged for\nmicrofluidic filtering applications, enabling the efficient separation of\nmicroparticles based on their geometric properties. This work opens new avenues\nfor designing microfluidic devices tailored for high-precision particle\nsorting, with broad implications for biomedical and industrial applications.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cond-mat.stat-mech,physics.comp-ph","published":"2025-04-08T09:17:23Z"}
{"aid":"http://arxiv.org/abs/2504.05836v1","title":"Work probability distribution of weakly driven process in overdamped\n  dynamics","summary":"Analytical work probability distributions for open classical systems are\nscarce; they can only be calculated in a few examples. In this work, I present\na new method to derive such quantities for weakly driven processes in the\noverdamped regime for any switching time. The white noise Brownian motion in a\nharmonic linear stiffening trap illustrates the result. The work probability\ndistribution is non-tabulated, with positive, semi-finite support, diverging at\nthe minimal value, and non-Gaussian. An analysis of the range of validity of\nlinear response is made by using the self-consistent criterion of the\nfluctuation-dissipation relation. The first, second, third, and fourth moments\nare correctly calculated for small perturbations.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-08T09:18:35Z"}
{"aid":"http://arxiv.org/abs/2504.05841v1","title":"Continuous spectrum-shrinking maps between finite-dimensional algebras","summary":"Let $\\mathcal{A}$ and $\\mathcal{B}$ be unital finite-dimensional complex\nalgebras, each equipped with the unique Hausdorff vector topology. Denote by\n$\\mathrm{Max}(\\mathcal{A})=\\{\\mathcal{M}_1, \\ldots, \\mathcal{M}_p\\}$ and\n$\\mathrm{Max}(\\mathcal{B})=\\{\\mathcal{N}_1, \\ldots, \\mathcal{N}_q\\}$ the sets\nof all maximal ideals of $\\mathcal{A}$ and $\\mathcal{B}$, respectively, and\ndefine the quantities $$k_i:=\\sqrt{\\dim(\\mathcal{A}/\\mathcal{M}_i)}, \\, \\, 1\n\\leq i \\leq p \\quad \\text{ and } \\quad\nm:=\\sum_{j=1}^q\\sqrt{\\dim(\\mathcal{B}/\\mathcal{N}_j)},$$ which are positive\nintegers by Wedderburn's structure theorem. We show that there exists a\ncontinuous spectrum-shrinking map $\\phi: \\mathcal{A} \\to \\mathcal{B}$ (i.e.\n$\\mathrm{sp}(\\phi(x))\\subseteq \\mathrm{sp}(x)$ for all $x \\in \\mathcal{A}$) if\nand only if the linear Diophantine equation $$ k_1x_1 + \\cdots + k_px_p = m $$\nhas a non-negative integer solution $(x_1,\\ldots,x_p)$. Moreover, all such maps\n$\\phi$ are spectrum preserving (i.e. $\\mathrm{sp}(\\phi(x))=\\mathrm{sp}(x)$ for\nall $x \\in \\mathcal{A}$) if and only if each non-negative solution consists\nonly of positive integers.","main_category":"math.SP","categories":"math.SP,math.RA","published":"2025-04-08T09:21:40Z"}
{"aid":"http://arxiv.org/abs/2504.05857v1","title":"Towards an AI-Driven Video-Based American Sign Language Dictionary:\n  Exploring Design and Usage Experience with Learners","summary":"Searching for unfamiliar American Sign Language (ASL) signs is challenging\nfor learners because, unlike spoken languages, they cannot type a text-based\nquery to look up an unfamiliar sign. Advances in isolated sign recognition have\nenabled the creation of video-based dictionaries, allowing users to submit a\nvideo and receive a list of the closest matching signs. Previous HCI research\nusing Wizard-of-Oz prototypes has explored interface designs for ASL\ndictionaries. Building on these studies, we incorporate their design\nrecommendations and leverage state-of-the-art sign-recognition technology to\ndevelop an automated video-based dictionary. We also present findings from an\nobservational study with twelve novice ASL learners who used this dictionary\nduring video-comprehension and question-answering tasks. Our results address\nhuman-AI interaction challenges not covered in previous WoZ research, including\nrecording and resubmitting signs, unpredictable outputs, system latency, and\nprivacy concerns. These insights offer guidance for designing and deploying\nvideo-based ASL dictionary systems.","main_category":"cs.HC","categories":"cs.HC,cs.AI","published":"2025-04-08T09:35:46Z"}
{"aid":"http://arxiv.org/abs/2504.05860v1","title":"Functional matrix product state simulation of continuous variable\n  quantum circuits","summary":"We introduce a functional matrix product state (FMPS) based method for\nsimulating the real-space representation of continuous-variable (CV) quantum\ncomputation. This approach efficiently simulates non-Gaussian CV systems by\nleveraging their functional form. By addressing scaling bottlenecks, FMPS\nenables more efficient simulation of shallow, multi-mode CV quantum circuits\nwith non-Gaussian input states. The method is validated by simulating random\nshallow and cascaded circuits with highly non-Gaussian input states, showing\nsuperior performance compared to existing techniques, also in the presence of\nloss.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T09:37:19Z"}
{"aid":"http://arxiv.org/abs/2504.05869v1","title":"The Ultraviolet Spectra of 2003fg-like Type Ia Supernovae","summary":"2003fg-like Type Ia supernovae (03fg-like SNe Ia) are a rare subtype of SNe\nIa, photometrically characterized by broader optical light curves and bluer\nultraviolet (UV) colors compared to normal SNe Ia. In this work, we study four\n03fg-like SNe Ia using Swift UltraViolet and Optical Telescope (UVOT) grism\nobservations to understand their unique UV properties and progenitor\nscenario(s). We report 03fg-like SNe Ia to have similar UV features and\nelemental compositions as normal SNe Ia, but with higher UV flux relative to\noptical. Previous studies have suggested that the UV flux levels of normal SNe\nIa could be influenced by their progenitor properties, such as metallicity,\nwith metal-poor progenitors producing higher UV flux levels. While 03fg-like\nSNe were previously reported to occur in low-mass and metal-poor host\nenvironments, our analysis indicates that their UV excess cannot be explained\nby their host-galaxy parameters. Instead, we demonstrate that the addition of a\nhot blackbody component, likely arising from the interaction with the\ncircumstellar material (CSM), to the normal SN Ia spectrum, can reproduce their\ndistinctive UV excess. This supports the hypothesis that 03fg-like SNe Ia could\nexplode in a CSM-rich environment.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-08T09:52:56Z"}
{"aid":"http://arxiv.org/abs/2504.05886v1","title":"Learning strategies for optimised fitness in a model of cyclic dominance","summary":"A major problem in evolutionary biology is how species learn and adapt under\nthe constraint of environmental conditions and competition of other species.\nModels of cyclic dominance provide simplified settings in which such questions\ncan be addressed using methods from theoretical physics. We investigate how a\nprivileged (\"smart\") species optimises its population by adopting advantageous\nstrategies in one such model. We use a reinforcement learning algorithm, which\nsuccessfully identifies optimal strategies based on a survival-of-the-weakest\neffect, including directional incentives to avoid predators. We also\ncharacterise the steady-state behaviour of the system in the presence of the\nsmart species and compare with the symmetric case where all species are\nequivalent.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,q-bio.PE","published":"2025-04-08T10:22:25Z"}
{"aid":"http://arxiv.org/abs/2504.05903v1","title":"A construction of multiple group racks","summary":"A multiple group rack is a rack which is a disjoint union of groups equipped\nwith a binary operation satisfying some conditions. It is used to define\ninvariants of spatial surfaces, i.e., oriented compact surfaces with boundaries\nembedded in the $3$-sphere $S^{3}$. A $G$-family of racks is a set with a\nfamily of binary operations indexed by the elements of a group $G$. There are\ntwo known methods for constructing multiple group racks. One is via a\n$G$-family of racks. The resulting multiple group rack is called the associated\nmultiple group rack of the $G$-family of racks. The other is by taking an\nabelian extension of a multiple group rack. In this paper, we introduce a new\nmethod for constructing multiple group racks by using a $G$-family of racks and\na normal subgroup $N$ of $G$. We show that this construction yields multiple\ngroup racks that are neither the associated multiple group racks of any\n$G$-family of racks nor their abelian extensions when the right conjugation\naction of $G$ on $N$ is nontrivial. As an application, we present a pair of\nspatial surfaces that cannot be distinguished by invariants derived from the\nassociated multiple group racks of any $G$-family of racks, yet can be\ndistinguished using invariants obtained from a multiple group rack introduced\nin this paper.","main_category":"math.GT","categories":"math.GT","published":"2025-04-08T11:01:42Z"}
{"aid":"http://arxiv.org/abs/2504.05904v1","title":"Intrinsic Saliency Guided Trunk-Collateral Network for Unsupervised\n  Video Object Segmentation","summary":"Recent unsupervised video object segmentation (UVOS) methods predominantly\nadopt the motion-appearance paradigm. Mainstream motion-appearance approaches\nuse either the two-encoder structure to separately encode motion and appearance\nfeatures, or the single-encoder structure for joint encoding. However, these\nmethods fail to properly balance the motion-appearance relationship.\nConsequently, even with complex fusion modules for motion-appearance\nintegration, the extracted suboptimal features degrade the models' overall\nperformance. Moreover, the quality of optical flow varies across scenarios,\nmaking it insufficient to rely solely on optical flow to achieve high-quality\nsegmentation results. To address these challenges, we propose the Intrinsic\nSaliency guided Trunk-Collateral Net}work (ISTC-Net), which better balances the\nmotion-appearance relationship and incorporates model's intrinsic saliency\ninformation to enhance segmentation performance. Specifically, considering that\noptical flow maps are derived from RGB images, they share both commonalities\nand differences. We propose a novel Trunk-Collateral structure. The shared\ntrunk backbone captures the motion-appearance commonality, while the collateral\nbranch learns the uniqueness of motion features. Furthermore, an Intrinsic\nSaliency guided Refinement Module (ISRM) is devised to efficiently leverage the\nmodel's intrinsic saliency information to refine high-level features, and\nprovide pixel-level guidance for motion-appearance fusion, thereby enhancing\nperformance without additional input. Experimental results show that ISTC-Net\nachieved state-of-the-art performance on three UVOS datasets (89.2% J&F on\nDAVIS-16, 76% J on YouTube-Objects, 86.4% J on FBMS) and four standard video\nsalient object detection (VSOD) benchmarks with the notable increase,\ndemonstrating its effectiveness and superiority over previous methods.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-08T11:02:14Z"}
{"aid":"http://arxiv.org/abs/2504.05910v1","title":"Testing the parquet equations and the U(1) Ward identity for\n  real-frequency correlation functions from the multipoint numerical\n  renormalization group","summary":"Recently, it has become possible to compute real-frequency four-point\ncorrelation functions of quantum impurity models using a multipoint extension\nof the numerical renormalization group (mpNRG). In this work, we perform\nseveral numerical consistency checks of the output of mpNRG by investigating\nexact relations between two- and four-point functions. This includes the\nBethe-Salpeter equations and the Schwinger-Dyson equation from the parquet\nformalism, which we evaluate in two formally identical but numerically\nnonequivalent ways. We also study the first-order U(1) Ward identity between\nthe vertex and the self-energy, which we derive for the first time in full\ngenerality in the real-frequency Keldysh formalism. We generally find good\nagreement of all relations, often up to a few percent, both at weak and at\nstrong interaction.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-08T11:06:06Z"}
{"aid":"http://arxiv.org/abs/2504.05921v1","title":"Accelerated Reeds-Shepp and Under-Specified Reeds-Shepp Algorithms for\n  Mobile Robot Path Planning","summary":"In this study, we present a simple and intuitive method for accelerating\noptimal Reeds-Shepp path computation. Our approach uses geometrical reasoning\nto analyze the behavior of optimal paths, resulting in a new partitioning of\nthe state space and a further reduction in the minimal set of viable paths. We\nrevisit and reimplement classic methodologies from the literature, which lack\ncontemporary open-source implementations, to serve as benchmarks for evaluating\nour method. Additionally, we address the under-specified Reeds-Shepp planning\nproblem where the final orientation is unspecified. We perform exhaustive\nexperiments to validate our solutions. Compared to the modern C++\nimplementation of the original Reeds-Shepp solution in the Open Motion Planning\nLibrary, our method demonstrates a 15x speedup, while classic methods achieve a\n5.79x speedup. Both approaches exhibit machine-precision differences in path\nlengths compared to the original solution. We release our proposed C++\nimplementations for both the accelerated and under-specified Reeds-Shepp\nproblems as open-source code.","main_category":"cs.RO","categories":"cs.RO,cs.CG","published":"2025-04-08T11:22:50Z"}
{"aid":"http://arxiv.org/abs/2504.05946v1","title":"InstructMPC: A Human-LLM-in-the-Loop Framework for Context-Aware Control","summary":"Model Predictive Control~(MPC) is a powerful control strategy widely utilized\nin domains like energy management, building control, and autonomous systems.\nHowever, its effectiveness in real-world settings is challenged by the need to\nincorporate context-specific predictions and expert instructions, which\ntraditional MPC often neglects. We propose \\IMPC, a novel framework that\naddresses this gap by integrating real-time human instructions through a Large\nLanguage Model~(LLM) to produce context-aware predictions for MPC. Our method\nemploys a Language-to-Distribution~(L2D) module to translate contextual\ninformation into predictive disturbance trajectories, which are then\nincorporated into the MPC optimization. Unlike existing context-aware and\nlanguage-based MPC models, \\IMPC enables dynamic human-LLM interaction and\nfine-tunes the L2D module in a closed loop with theoretical performance\nguarantees, achieving a regret bound of $O(\\sqrt{T\\log T})$ for linear dynamics\nwhen optimized via advanced fine-tuning methods such as Direct Preference\nOptimization~(DPO) using a tailored loss function.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-08T11:59:00Z"}
{"aid":"http://arxiv.org/abs/2504.05948v1","title":"Control-Oriented Modelling and Adaptive Parameter Estimation for Hybrid\n  Wind-Wave Energy Systems","summary":"Hybrid wind-wave energy system, integrating floating offshore wind turbine\nand wave energy converters, has received much attention in recent years due to\nits potential benefit in increasing the power harvest density and reducing the\nlevelized cost of electricity. Apart from the design complexities of the hybrid\nwind-wave energy systems, their energy conversion efficiency, power output\nsmoothness and their safe operations introduce new challenges for their control\nsystem designs. Recent studies show that advanced model-based control\nstrategies have the great potential to significantly improve their overall\ncontrol performance. However the performance of these advanced control\nstrategies rely on the computationally efficient control-oriented models with\nsufficient fidelity, which are normally difficult to derive due to the\ncomplexity of the hydro-, aero-dynamic effects and the couplings.In most\navailable results, the hybrid wind-wave energy system models are established by\nusing the Boundary Element Method, devoting to understanding the hydrodynamic\nresponses and performance analysis. However, such models are complex and\ninvolved relatively heavy computational burden, which cannot be directly used\nfor the advanced model-based control methods that are essential for improving\npower capture efficiency from implementing in practice. To overcome this issue,\nthis paper proposes a control-oriented model of the hybrid windwave energy\nsystem with six degrees of freedom. First, ...","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-08T12:00:59Z"}
{"aid":"http://arxiv.org/abs/2504.05954v1","title":"Unsupervised Location Mapping for Narrative Corpora","summary":"This work presents the task of unsupervised location mapping, which seeks to\nmap the trajectory of an individual narrative on a spatial map of locations in\nwhich a large set of narratives take place. Despite the fundamentality and\ngenerality of the task, very little work addressed the spatial mapping of\nnarrative texts. The task consists of two parts: (1) inducing a ``map'' with\nthe locations mentioned in a set of texts, and (2) extracting a trajectory from\na single narrative and positioning it on the map. Following recent advances in\nincreasing the context length of large language models, we propose a pipeline\nfor this task in a completely unsupervised manner without predefining the set\nof labels. We test our method on two different domains: (1) Holocaust\ntestimonies and (2) Lake District writing, namely multi-century literature on\ntravels in the English Lake District. We perform both intrinsic and extrinsic\nevaluations for the task, with encouraging results, thereby setting a benchmark\nand evaluation practices for the task, as well as highlighting challenges.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-08T12:06:47Z"}
{"aid":"http://arxiv.org/abs/2504.05958v1","title":"Hybrid Control as a Proxy for Detection and Mitigation of Sensor Attacks\n  in Cooperative Driving","summary":"To enhance the robustness of cooperative driving against cyberattacks, we\npropose a hybrid controller scheme to detect and mitigate False-Data Injection\n(FDI) attacks in real-time. The core of our method builds on a given\nCooperative Adaptive Cruise Control (CACC) algorithm and exploits sensor\nredundancy to construct equivalent controllers, each driven by a distinct,\nnon-overlapping subset of sensors (equivalent controller realizations). By\nconstruction, these controller realizations generate the same control input in\nthe absence of an attack, allowing us to devise an algorithm that compares\ncontrol signals and measurements to pinpoint anomalous behavior via a majority\nvote. This allows us to: 1) decide in real-time which subset of sensors is\ncompromised; and 2) switch to a healthy subset, mitigating thus sensor FDI\nattacks. We model the latter logic as a hybrid dynamic controller that decides\nin real-time what realization to use, builds on attack-dependent flow and jump\nsets, and employs controller resets (to return the state of previously\ncompromised controller realizations to a correct value after the attack stops).\nWe demonstrate the performance of our scheme through simulation experiments.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-08T12:11:57Z"}
{"aid":"http://arxiv.org/abs/2504.05968v1","title":"Security Vulnerabilities in Ethereum Smart Contracts: A Systematic\n  Analysis","summary":"Smart contracts are a secure and trustworthy application that plays a vital\nrole in decentralized applications in various fields such as insurance,the\ninternet, and gaming. However, in recent years, smart contract security\nbreaches have occurred frequently, and due to their financial properties, they\nhave caused huge economic losses, such as the most famous security incident\n\"The DAO\" which caused a loss of over \\$60 million in Ethereum. This has drawn\na lot of attention from all sides. Writing a secure smart contract is now a\ncritical issue.This paper focuses on Ether smart contracts and explains the\nmain components of Ether, smart contract architecture and mechanism.The\nenvironment used in this paper is the Ethernet environment, using remix online\ncompilation platform and Solidity language, according to the four security\nevents of American Chain, The DAO, Parity and KotET, the principles of integer\noverflow attack, reentrant attack, access control attack and denial of service\nattack are studied and analyzed accordingly, and the scenarios of these\nvulnerabilities are reproduced, and the measures to prevent them are given.\nFinally, preventive measures are given. In addition, the principles of short\naddress attack, early transaction attack and privileged function exposure\nattack are also introduced in detail, and security measures are proposed.As\nvulnerabilities continue to emerge, their classification will also evolve. The\nanalysis and research of the current vulnerabilities are also to lay a solid\nfoundation for avoiding more vulnerabilities.","main_category":"cs.CR","categories":"cs.CR,D.2.4","published":"2025-04-08T12:25:34Z"}
{"aid":"http://arxiv.org/abs/2504.05970v1","title":"MLPROP -- an open interactive web interface for thermophysical property\n  prediction with machine learning","summary":"Machine learning (ML) enables the development of powerful methods for\npredicting thermophysical properties with unprecedented scope and accuracy.\nHowever, technical barriers like cumbersome implementation in established\nworkflows hinder their application in practice. With MLPROP, we provide an\ninteractive web interface for directly applying advanced ML methods to predict\nthermophysical properties without requiring ML expertise, thereby substantially\nincreasing the accessibility of novel models. MLPROP currently includes models\nfor predicting the vapor pressure of pure components (GRAPPA), activity\ncoefficients and vapor-liquid equilibria in binary mixtures (UNIFAC 2.0, mod.\nUNIFAC 2.0, and HANNA), and a routine to fit NRTL parameters to the model\npredictions. MLPROP will be continuously updated and extended and is accessible\nfree of charge via https://ml-prop.mv.rptu.de/. MLPROP removes the barrier to\nlearning and experimenting with new ML-based methods for predicting\nthermophysical properties. The source code of all models is available as open\nsource, which allows integration into existing workflows.","main_category":"cs.CE","categories":"cs.CE,cs.LG","published":"2025-04-08T12:28:18Z"}
{"aid":"http://arxiv.org/abs/2504.05972v1","title":"Existence of periodic solutions for the Grushin critical problem","summary":"We study a Grushin critical problem in a strip domain which satisfies the\nperiodic boundary conditions. By applying the finite-dimensional reduction\nmethod, we construct a periodic solution when the prescribed curvature function\nis periodic. Furthermore, we also consider the Grushin critical problem in\n$\\mathbb{R}^{N} (N \\geq 5)$. Compared with Billel et al. (Differential Integral\nEquations 32: 49-90, 2019), we use the method by Guo and Yan (Math. Ann. 388:\n795-830, 2024) to construct periodic solutions under some weaker conditions,\navoiding the complicated estimates and uniqueness proof. Notably, Guo and Yan\n(Math. Ann. 388: 795-830, 2024) obtained solutions periodic with respect to\nsome of the first variables, while the solutions in this paper are periodic\nwith respect to some intermediate variables.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T12:29:32Z"}
{"aid":"http://arxiv.org/abs/2504.05974v1","title":"The Higgs trilinear coupling in the SMEFT at the HL-LHC and the FCC-ee","summary":"Motivated by the updated HL-LHC projections for Higgs pair production from\nATLAS and CMS and by the release of the FCC-ee Feasibility Study, we critically\nrevisit the sensitivity of the global SMEFT analysis to deformations of the\nHiggs self-coupling modifier $\\kappa_3$. To this end, we quantify the impact of\nSMEFT operators modifying double Higgs production at the LHC and single Higgs\nproduction, including loop corrections, at the FCC-ee, and include\nRenormalisation Group Evolution throughout. We demonstrate that significantly\nimproving on the legacy HL-LHC constraints on $\\kappa_3$ at the FCC-ee is not\npossible without the $\\sqrt{s}=365$ GeV run; that individual and marginalised\ndeterminations are similar at the HL-LHC while differing by up to a factor 3 at\nthe FCC-ee; and that quadratic EFT corrections cannot be neglected. Overall,\nthe combination of HL-LHC and FCC-ee data offers unique potential to pin down\nthe Higgs self-coupling with $\\sim$$15\\%$ precision.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-08T12:30:44Z"}
{"aid":"http://arxiv.org/abs/2504.05991v1","title":"On non-local exchange and scattering operators in domain decomposition\n  methods","summary":"We study non-local exchange and scattering operators arising in domain\ndecomposition algorithms for solving elliptic problems on domains in\n$\\mathbb{R}^2$. Motivated by recent formulations of the Optimized Schwarz\nMethod introduced by Claeys, we rigorously analyze the behavior of a family of\nnon-local exchange operators $\\Pi_\\gamma$, defined in terms of boundary\nintegral operators associated to the fundamental solution for $-\\Delta +\n\\gamma^{-2}$, with $\\gamma > 0$. Our first main result establishes precise\nestimates comparing $\\Pi_\\gamma$ to its local counterpart $\\Pi_0$ as $\\gamma\n\\to 0$, providing a quantitative bridge between the classical and non-local\nformulations of the Optimized Schwarz Method. In addition, we investigate the\ncorresponding scattering operators, proving norm estimates that relate them to\ntheir classical analogues through a detailed analysis of the associated\nDirichlet-to-Neumann operators. Our results clarify the relationship between\nclassical and non-local formulations of domain decomposition methods and yield\nnew insights that are essential for the analysis of these algorithms,\nparticularly in the presence of cross points and for domains with curvilinear\npolygonal boundaries.","main_category":"math.NA","categories":"math.NA,cs.NA,math.AP","published":"2025-04-08T12:54:54Z"}
{"aid":"http://arxiv.org/abs/2504.06004v1","title":"FedFeat+: A Robust Federated Learning Framework Through Federated\n  Aggregation and Differentially Private Feature-Based Classifier Retraining","summary":"In this paper, we propose the FedFeat+ framework, which distinctively\nseparates feature extraction from classification. We develop a two-tiered model\ntraining process: following local training, clients transmit their weights and\nsome features extracted from the feature extractor from the final local epochs\nto the server. The server aggregates these models using the FedAvg method and\nsubsequently retrains the global classifier utilizing the shared features. The\nclassifier retraining process enhances the model's understanding of the\nholistic view of the data distribution, ensuring better generalization across\ndiverse datasets. This improved generalization enables the classifier to\nadaptively influence the feature extractor during subsequent local training\nepochs. We establish a balance between enhancing model accuracy and\nsafeguarding individual privacy through the implementation of differential\nprivacy mechanisms. By incorporating noise into the feature vectors shared with\nthe server, we ensure that sensitive data remains confidential. We present a\ncomprehensive convergence analysis, along with theoretical reasoning regarding\nperformance enhancement and privacy preservation. We validate our approach\nthrough empirical evaluations conducted on benchmark datasets, including\nCIFAR-10, CIFAR-100, MNIST, and FMNIST, achieving high accuracy while adhering\nto stringent privacy guarantees. The experimental results demonstrate that the\nFedFeat+ framework, despite using only a lightweight two-layer CNN classifier,\noutperforms the FedAvg method in both IID and non-IID scenarios, achieving\naccuracy improvements ranging from 3.92 % to 12.34 % across CIFAR-10,\nCIFAR-100, and Fashion-MNIST datasets.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T13:12:38Z"}
{"aid":"http://arxiv.org/abs/2504.06005v1","title":"A deep search for Complex Organic Molecules toward the protoplanetary\n  disk of V883 Ori","summary":"Complex Organic Molecules (COMs) in the form of prebiotic molecules are\npotentially building blocks of life. Using Atacama Large\nMillimeter/submillimeter Array (ALMA) Band 7 observations in spectral scanning\nmode, we carried out a deep search for COMs within the disk of V883 Ori,\ncovering frequency ranges of $\\sim$ 348 - 366 GHz. V883 Ori is an FUor object\ncurrently undergoing an accretion burst, which increases its luminosity and\nconsequently increases the temperature of the surrounding protoplanetary disk,\nfacilitating the detection of COMs in the gas phase. We identified 26\nmolecules, including 14 COMs and 12 other molecules, with first detection in\nthis source of the molecules: CH3OD, H2C17O, and H213CO. We searched for\nmultiple nitrogen-bearing COMs, as CH3CN had been the only nitrogen-bearing COM\nthat has been identified so far in this source. We also detected CH3CN, and\ntentatively detect CH3CH2CN, CH2CHCN, CH3OCN, CH3NCO, and NH2CHO. We compared\nthe abundances relative to CH3OH with those in the handful of objects with\nprevious detections of these species: the Class 0 protostars IRAS 16293-2422 A,\nIRAS 16293-2422 B and B1-c, the high-mass star-forming region Sagittarius B2\n(North), the Solar System comet 67P/Churyumov-Gerasimenko, and the\nprotoplanetary disk of Oph-IRS 48. We report $\\sim$ 1 to 3 orders of magnitude\nhigher abundances compared to Class 0 protostars and $\\sim$ 1 to 3 orders of\nmagnitude lower abundances compared to the protoplanetary disk, Sagittarius B2\n(North), and 67P/C-G. These results indicate that the protoplanetary disk phase\ncould contribute to build up of COMs.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP,astro-ph.GA","published":"2025-04-08T13:15:46Z"}
{"aid":"http://arxiv.org/abs/2504.06010v1","title":"Latent Multimodal Reconstruction for Misinformation Detection","summary":"Multimodal misinformation, such as miscaptioned images, where captions\nmisrepresent an image's origin, context, or meaning, poses a growing challenge\nin the digital age. To support fact-checkers, researchers have been focusing on\ncreating datasets and developing methods for multimodal misinformation\ndetection (MMD). Due to the scarcity of large-scale annotated MMD datasets,\nrecent studies leverage synthetic training data via out-of-context\nimage-caption pairs or named entity manipulations; altering names, dates, and\nlocations. However, these approaches often produce simplistic misinformation\nthat fails to reflect real-world complexity, limiting the robustness of\ndetection models trained on them. Meanwhile, despite recent advancements, Large\nVision-Language Models (LVLMs) remain underutilized for generating diverse,\nrealistic synthetic training data for MMD. To address this gap, we introduce\n\"MisCaption This!\", a training dataset comprising LVLM-generated miscaptioned\nimages. Additionally, we introduce \"Latent Multimodal Reconstruction\" (LAMAR),\na network trained to reconstruct the embeddings of truthful captions, providing\na strong auxiliary signal to the detection process. To optimize LAMAR, we\nexplore different training strategies (end-to-end training and large-scale\npre-training) and integration approaches (direct, mask, gate, and attention).\nExtensive experiments show that models trained on \"MisCaption This!\" generalize\nbetter on real-world misinformation, while LAMAR sets new state-of-the-art on\nboth NewsCLIPpings and VERITE benchmarks; highlighting the potential of\nLVLM-generated data and reconstruction-based approaches for advancing MMD. We\nrelease our code at:\nhttps://github.com/stevejpapad/miscaptioned-image-reconstruction","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-08T13:16:48Z"}
{"aid":"http://arxiv.org/abs/2504.06022v1","title":"CamContextI2V: Context-aware Controllable Video Generation","summary":"Recently, image-to-video (I2V) diffusion models have demonstrated impressive\nscene understanding and generative quality, incorporating image conditions to\nguide generation. However, these models primarily animate static images without\nextending beyond their provided context. Introducing additional constraints,\nsuch as camera trajectories, can enhance diversity but often degrades visual\nquality, limiting their applicability for tasks requiring faithful scene\nrepresentation. We propose CamContextI2V, an I2V model that integrates multiple\nimage conditions with 3D constraints alongside camera control to enrich both\nglobal semantics and fine-grained visual details. This enables more coherent\nand context-aware video generation. Moreover, we motivate the necessity of\ntemporal awareness for an effective context representation. Our comprehensive\nstudy on the RealEstate10K dataset demonstrates improvements in visual quality\nand camera controllability. We make our code and models publicly available at:\nhttps://github.com/LDenninger/CamContextI2V.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T13:26:59Z"}
{"aid":"http://arxiv.org/abs/2504.06030v1","title":"NQG III -- Two-Centre Problems, Whirlpool Galaxy and Toy Neutron Stars","summary":"In the hunt for WIMPish dark matter and testing our new theory, we extend the\nresults obtained for the Kepler problem in NQG I and NQG II to the Euler\ntwo-centre problem and to other classical Hamiltonian systems with planar\nperiodic orbits. In the first case our results lead to quantum elliptical\nspirals converging to elliptical orbits where stars and other celestial bodies\ncan form as the corresponding WIMP/molecular clouds condense. The examples\ninevitably involve elliptic integrals as was the case in our earlier work on\nequatorial orbits of toy neutron stars (see Ref. [27]). Hence this is the\nexample on which we focus in this work on quantisation. The main part of our\nanalysis which leans heavily on Hamilton-Jacobi theory is applicable to any\nKLMN integrable planar periodic orbits for Hamiltonian systems. The most useful\nresults on Weierstrass elliptic functions needed in these two works we have\nsummarised with complete proofs in the appendix. This has been one of the most\nenjoyable parts of this research understanding in more detail the genius of\nWeierstrass and Jacobi. However we have to say that the beautiful simplicity of\nthe Euler two-centre results herein transcend even this as far as we are\nconcerned. At the end of the paper we see how the Burgers-Zeldovich fluid model\nrelates to our set-up through Nelson's stochastic mechanics.","main_category":"math-ph","categories":"math-ph,astro-ph.GA,math.MP","published":"2025-04-08T13:34:33Z"}
{"aid":"http://arxiv.org/abs/2504.06039v1","title":"Enhanced Anomaly Detection for Capsule Endoscopy Using Ensemble Learning\n  Strategies","summary":"Capsule endoscopy is a method to capture images of the gastrointestinal tract\nand screen for diseases which might remain hidden if investigated with standard\nendoscopes. Due to the limited size of a video capsule, embedding AI models\ndirectly into the capsule demands careful consideration of the model size and\nthus complicates anomaly detection in this field. Furthermore, the scarcity of\navailable data in this domain poses an ongoing challenge to achieving effective\nanomaly detection. Thus, this work introduces an ensemble strategy to address\nthis challenge in anomaly detection tasks in video capsule endoscopies,\nrequiring only a small number of individual neural networks during both the\ntraining and inference phases. Ensemble learning combines the predictions of\nmultiple independently trained neural networks. This has shown to be highly\neffective in enhancing both the accuracy and robustness of machine learning\nmodels. However, this comes at the cost of higher memory usage and increased\ncomputational effort, which quickly becomes prohibitive in many real-world\napplications. Instead of applying the same training algorithm to each\nindividual network, we propose using various loss functions, drawn from the\nanomaly detection field, to train each network. The methods are validated on\nthe two largest publicly available datasets for video capsule endoscopy images,\nthe Galar and the Kvasir-Capsule dataset. We achieve an AUC score of 76.86% on\nthe Kvasir-Capsule and an AUC score of 76.98% on the Galar dataset. Our\napproach outperforms current baselines with significantly fewer parameters\nacross all models, which is a crucial step towards incorporating artificial\nintelligence into capsule endoscopies.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T13:39:39Z"}
{"aid":"http://arxiv.org/abs/2504.06042v1","title":"An Adaptive Algorithm for Bilevel Optimization on Riemannian Manifolds","summary":"Existing methods for solving Riemannian bilevel optimization (RBO) problems\nrequire prior knowledge of the problem's first- and second-order information\nand curvature parameter of the Riemannian manifold to determine step sizes,\nwhich poses practical limitations when these parameters are unknown or\ncomputationally infeasible to obtain. In this paper, we introduce the Adaptive\nRiemannian Hypergradient Descent (AdaRHD) algorithm for solving RBO problems.\nTo the best of our knowledge, AdaRHD is the first method to incorporate a fully\nadaptive step size strategy that eliminates the need for problem-specific\nparameters. We prove that AdaRHD achieves an $\\mathcal{O}(1/\\epsilon)$\niteration complexity for finding an $\\epsilon$-stationary point, thus matching\nthe complexity of existing non-adaptive methods. Furthermore, we demonstrate\nthat substituting exponential mappings with retraction mappings maintains the\nsame complexity bound. Experiments demonstrate that AdaRHD achieves comparable\nperformance to existing non-adaptive approaches while exhibiting greater\nrobustness.","main_category":"math.OC","categories":"math.OC","published":"2025-04-08T13:42:18Z"}
{"aid":"http://arxiv.org/abs/2504.06053v1","title":"Characteristic exciton energy scales in antiferromagnetic NiPS$_3$","summary":"Two-dimensional antiferromagnets are promising materials for spintronics. The\nvan der Waals antiferromagnet NiPS$_3$ has attracted extensive interest due to\nits ultra-narrow exciton feature which is closely linked with the magnetic\nordering. Here, we use time-resolved terahertz spectroscopy to investigate\nphoto-excited carriers in NiPS$_3$. We identify the onset of interband\ntransitions and estimate the exciton dissociation energy from the excitation\nwavelength and fluence dependence of the transient spectral weight. Our results\nprovide key insights to quantify the exciton characteristics and validate the\nband structure for NiPS$_3$.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci","published":"2025-04-08T13:55:55Z"}
{"aid":"http://arxiv.org/abs/2504.06075v1","title":"Collaborative Prediction: Tractable Information Aggregation via\n  Agreement","summary":"We give efficient \"collaboration protocols\" through which two parties, who\nobserve different features about the same instances, can interact to arrive at\npredictions that are more accurate than either could have obtained on their\nown. The parties only need to iteratively share and update their own label\npredictions-without either party ever having to share the actual features that\nthey observe. Our protocols are efficient reductions to the problem of learning\non each party's feature space alone, and so can be used even in settings in\nwhich each party's feature space is illegible to the other-which arises in\nmodels of human/AI interaction and in multi-modal learning. The communication\nrequirements of our protocols are independent of the dimensionality of the\ndata. In an online adversarial setting we show how to give regret bounds on the\npredictions that the parties arrive at with respect to a class of benchmark\npolicies defined on the joint feature space of the two parties, despite the\nfact that neither party has access to this joint feature space. We also give\nsimpler algorithms for the same task in the batch setting in which we assume\nthat there is a fixed but unknown data distribution. We generalize our\nprotocols to a decision theoretic setting with high dimensional outcome spaces,\nwhere parties communicate only \"best response actions.\"\n  Our theorems give a computationally and statistically tractable\ngeneralization of past work on information aggregation amongst Bayesians who\nshare a common and correct prior, as part of a literature studying \"agreement\"\nin the style of Aumann's agreement theorem. Our results require no knowledge of\n(or even the existence of) a prior distribution and are computationally\nefficient. Nevertheless we show how to lift our theorems back to this classical\nBayesian setting, and in doing so, give new information aggregation theorems\nfor Bayesian agreement.","main_category":"cs.LG","categories":"cs.LG,cs.DS,cs.GT","published":"2025-04-08T14:12:42Z"}
{"aid":"http://arxiv.org/abs/2504.06084v1","title":"MAPLE: Encoding Dexterous Robotic Manipulation Priors Learned From\n  Egocentric Videos","summary":"Large-scale egocentric video datasets capture diverse human activities across\na wide range of scenarios, offering rich and detailed insights into how humans\ninteract with objects, especially those that require fine-grained dexterous\ncontrol. Such complex, dexterous skills with precise controls are crucial for\nmany robotic manipulation tasks, yet are often insufficiently addressed by\ntraditional data-driven approaches to robotic manipulation. To address this\ngap, we leverage manipulation priors learned from large-scale egocentric video\ndatasets to improve policy learning for dexterous robotic manipulation tasks.\nWe present MAPLE, a novel method for dexterous robotic manipulation that\nexploits rich manipulation priors to enable efficient policy learning and\nbetter performance on diverse, complex manipulation tasks. Specifically, we\npredict hand-object contact points and detailed hand poses at the moment of\nhand-object contact and use the learned features to train policies for\ndownstream manipulation tasks. Experimental results demonstrate the\neffectiveness of MAPLE across existing simulation benchmarks, as well as a\nnewly designed set of challenging simulation tasks, which require fine-grained\nobject control and complex dexterous skills. The benefits of MAPLE are further\nhighlighted in real-world experiments using a dexterous robotic hand, whereas\nsimultaneous evaluation across both simulation and real-world experiments has\nremained underexplored in prior work.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-08T14:25:25Z"}
{"aid":"http://arxiv.org/abs/2504.06148v1","title":"V-MAGE: A Game Evaluation Framework for Assessing Visual-Centric\n  Capabilities in Multimodal Large Language Models","summary":"Recent advancements in Multimodal Large Language Models (MLLMs) have led to\nsignificant improvements across various multimodal benchmarks. However, as\nevaluations shift from static datasets to open-world, dynamic environments,\ncurrent game-based benchmarks remain inadequate because they lack\nvisual-centric tasks and fail to assess the diverse reasoning skills required\nfor real-world decision-making. To address this, we introduce Visual-centric\nMultiple Abilities Game Evaluation (V-MAGE), a game-based evaluation framework\ndesigned to assess visual reasoning capabilities of MLLMs. V-MAGE features five\ndiverse games with 30+ handcrafted levels, testing models on core visual skills\nsuch as positioning, trajectory tracking, timing, and visual memory, alongside\nhigher-level reasoning like long-term planning and deliberation. We use V-MAGE\nto evaluate leading MLLMs, revealing significant challenges in their visual\nperception and reasoning. In all game environments, the top-performing MLLMs,\nas determined by Elo rating comparisons, exhibit a substantial performance gap\ncompared to humans. Our findings highlight critical limitations, including\nvarious types of perceptual errors made by the models, and suggest potential\navenues for improvement from an agent-centric perspective, such as refining\nagent strategies and addressing perceptual inaccuracies. Code is available at\nhttps://github.com/CSU-JPG/V-MAGE.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T15:43:01Z"}
{"aid":"http://arxiv.org/abs/2504.06174v1","title":"On Soft Clustering For Correlation Estimators: Model Uncertainty,\n  Differentiability, and Surrogates","summary":"Properly estimating correlations between objects at different spatial scales\nnecessitates $\\mathcal{O}(n^2)$ distance calculations. For this reason, most\nwidely adopted packages for estimating correlations use clustering algorithms\nto approximate local trends. However, methods for quantifying the error\nintroduced by this clustering have been understudied. In response, we present\nan algorithm for estimating correlations that is probabilistic in the way that\nit clusters objects, enabling us to quantify the uncertainty caused by\nclustering simply through model inference. These soft clustering assignments\nenable correlation estimators that are theoretically differentiable with\nrespect to their input catalogs. Thus, we also build a theoretical framework\nfor differentiable correlation functions and describe their utility in\ncomparison to existing surrogate models. Notably, we find that repeated\nnormalization and distance function calls slow gradient calculations and that\nsparse Jacobians destabilize precision, pointing towards either approximate or\nsurrogate methods as a necessary solution to exact gradients from correlation\nfunctions. To that end, we close with a discussion of surrogate models as\nproxies for correlation functions. We provide an example that demonstrates the\nefficacy of surrogate models to enable gradient-based optimization of\nastrophysical model parameters, successfully minimizing a correlation function\noutput. Our numerical experiments cover science cases across cosmology, from\npoint spread function (PSF) modeling efforts to gravitational simulations to\ngalaxy intrinsic alignment (IA).","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-08T16:18:39Z"}
{"aid":"http://arxiv.org/abs/2504.06194v1","title":"Positive 3-braids, Khovanov homology and Garside theory","summary":"Khovanov homology is a powerful invariant of oriented links that categorifies\nthe Jones polynomial. Nevertheless, computing Khovanov homology of a given link\nremains challenging in general with current techniques. In this work we focus\non links that are the closure of positive 3-braids. Starting with a\nclassification of conjugacy classes of 3-braids arising from the Garside\nstructure of braid groups, we compute, for any closed positive 3-braid, the\nfirst four columns (homological degree) and the three lowest rows (quantum\ndegree) of the associated Khovanov homology table. Moreover, the number of rows\nand columns we can describe increases with the infimum of the positive braid (a\nGarside theoretical notion). We will show how to increase the infimum of a\n3-braid to its maximal possible value by a conjugation, maximizing the number\nof cells in the Khovanov homology of its closure that can be determined, and\nshow that this can be done in linear time.","main_category":"math.GT","categories":"math.GT,math.AT,math.GR","published":"2025-04-08T16:35:15Z"}
{"aid":"http://arxiv.org/abs/2504.06217v1","title":"Chernoff Information Bottleneck for Covert Quantum Target Sensing","summary":"Target sensing is a fundamental task with many practical applications,\ne.g.~in LiDaR and radar systems. Quantum strategies with entangled states can\nachieve better sensing accuracies with the same probe energy, yet it is often\nsimpler to use classical probes with higher energy than to take advantage of\nthe quantum regime. Recently, it has been shown that useful quantum advantage\ncan be achieved in covert situations, where sensing has to be performed while\nalso avoiding detection by an adversary: here increasing energy is not a viable\nstratagem, as it facilitates the adversary. In this paper we introduce a\ngeneral framework to assess and quantify quantum advantage in covert\nsituations. This is based on extending the information bottleneck principle,\noriginally developed for communication and machine learning applications, to\ndecision problems via the Chernoff information, with the ultimate goal of\nquantitatively optimizing the trade-off between covertness and sensing ability.\nIn this context we show how quantum resources, namely entangled photonic probes\npaired with photon counting, greatly outperform classical coherent transmitters\nin target detection and ranging, while also maintaining a chosen level of\ncovertness. Our work highlights the great potential of integrating quantum\nsensing in LiDAR systems to enhance the covert performance.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-08T17:05:41Z"}
{"aid":"http://arxiv.org/abs/2504.06224v1","title":"Nonlinear Tails of Gravitational Waves in Schwarzschild Black Hole\n  Ringdown","summary":"Schwarzschild black holes evolve toward their static configuration by\nemitting gravitational waves, which decay over time following a power law at\nfixed spatial positions. We derive this power law analytically for the\nsecond-order even gravitational perturbations, demonstrating that it is\ndetermined by the fact that the second-order source decays as the inverse\nsquare of the distance. Quadratic gravitational modes with multipole $\\ell$\ndecay according to a law $\\sim t^{-2\\ell-1}$, in contrast to the linear Price\nlaw scaling $\\sim t^{-2\\ell-3}$. Consequently, nonlinear tails may persist\nlonger than their linear counterparts.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-ph,hep-th","published":"2025-04-08T17:12:28Z"}
{"aid":"http://arxiv.org/abs/2504.06229v1","title":"Continuous-variable spatio-spectral quantum networks in nonlinear\n  photonic lattices","summary":"Multiplexing information in different degrees of freedom and use of\nintegrated and fiber-optic components are natural solutions to the scalability\nbottleneck in optical quantum communications and computing. However, for\nbulk-optics systems, where size, cost, stability, and reliability are factors,\nthis remains either impractical or highly challenging to implement. In this\npaper we present a framework to engineer continuous-variable entanglement\nproduced through nondegenerate spontaneous parametric down-conversion in\n\\chi^(2) nonlinear photonic lattices in spatial and spectral degrees of freedom\nthat can solve the scalability challenge. We show how spatio-spectral pump\nshaping produce cluster states that are naturally distributable in quantum\ncommunication networks and a resource for measurement-based quantum computing.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-08T17:24:00Z"}
{"aid":"http://arxiv.org/abs/2504.06230v1","title":"Global solutions for cubic quasilinear ultrahyperbolic SchrÃ¶dinger\n  flows","summary":"In recent work, two of the authors proposed a broad global well-posedness\nconjecture for cubic quasilinear dispersive equations in two space dimensions,\nwhich asserts that global well-posedness and scattering holds for small initial\ndata in Sobolev spaces. As a first validation they proved the conjecture for\nquasilinear Schr\\\"odinger flows.\n  In the present article we expand the reach of these ideas and methods to the\ncase of quasilinear ultrahyperbolic Schr\\\"odinger flows, which is the first\nexample with a nonconvex dispersion relation.\n  The study of local well-posedness for this class of problems, in all\ndimensions, was initiated in pioneering work of Kenig-Ponce-Vega for localized\ninitial data, and then continued by Marzuola-Metcalfe-Tataru (MMT) and\nPineau-Taylor (PT) for initial data in Sobolev spaces in the elliptic and\nnon-elliptic cases, respectively.\n  Our results here mirror the earlier results in the elliptic case: (i) a new,\npotentially sharp local well-posedness result in low regularity Sobolev spaces,\none derivative below MMT and just one-half derivative above scaling, (ii) a\nsmall data global well-posedness and scattering result at the same regularity\nlevel. One key novelty in this setting is the introduction of a new family of\ninteraction Morawetz functionals which are suitable for obtaining bilinear\nestimates in the ultrahyperbolic setting. We remark that this method appears to\nbe robust enough to potentially be of use in a large data regime when the\nmetric is not a small perturbation of a Euclidean one.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T17:24:40Z"}
{"aid":"http://arxiv.org/abs/2504.06243v1","title":"Renormalization Group in far-from-equilibrium states","summary":"We study renormalization group flows in far-from-equilibrium states. The\nstudy is made tractable by focusing on states that are spatially homogeneous,\ntime-independent, and scale-invariant. Such states, in which mode $k$ has\noccupation numbers $n_k \\sim k^{-\\gamma}$, are well known in nonlinear physics.\nRG flow in such states is qualitatively different from that in the vacuum -- a\npositive $\\gamma$ decreases the dimension of an operator, turning marginal\ninteractions into relevant interactions. We compute one-loop beta functions.\nDepending on the sign of the beta function, backreaction may either cause a\nminor shift of the state in the IR, or completely change the nature of the\nstate. Focusing on nearly marginal interactions, we construct an analog of the\nepsilon expansion and IR fixed points, with epsilon now set by the scaling of\nthe interaction rather than the spacetime dimension. In the language of RG\nflow, critical-balance scaling -- which has applications in fields as varied as\nastrophysics and ocean waves -- corresponds to the state dynamically adjusting\nitself along the RG flow until the interaction becomes marginal.","main_category":"hep-th","categories":"hep-th,hep-ph","published":"2025-04-08T17:43:01Z"}
{"aid":"http://arxiv.org/abs/2504.06245v1","title":"Underwater Robotic Simulators Review for Autonomous System Development","summary":"The increasing complexity of underwater robotic systems has led to a surge in\nsimulation platforms designed to support perception, planning, and control\ntasks in marine environments. However, selecting the most appropriate\nunderwater robotic simulator (URS) remains a challenge due to wide variations\nin fidelity, extensibility, and task suitability. This paper presents a\ncomprehensive review and comparative analysis of five state-of-the-art,\nROS-compatible, open-source URSs: Stonefish, DAVE, HoloOcean, MARUS, and\nUNav-Sim. Each simulator is evaluated across multiple criteria including sensor\nfidelity, environmental realism, sim-to-real capabilities, and research impact.\nWe evaluate them across architectural design, sensor and physics modeling, task\ncapabilities, and research impact. Additionally, we discuss ongoing challenges\nin sim-to-real transfer and highlight the need for standardization and\nbenchmarking in the field. Our findings aim to guide practitioners in selecting\neffective simulation environments and inform future development of more robust\nand transferable URSs.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T17:43:48Z"}
{"aid":"http://arxiv.org/abs/2504.06267v1","title":"Prethermalization of light and matter in cavity-coupled Rydberg arrays","summary":"We explore the dynamics of two-dimensional Rydberg atom arrays coupled to a\nsingle-mode optical cavity, employing nonequilibrium diagrammatic techniques to\ncapture nonlinearities and fluctuations beyond mean-field theory. We discover a\nnovel prethermalization regime driven by the interplay between short-range\nRydberg interactions and long-range photon-mediated interactions. In this\nregime, matter and light equilibrate at distinct - and in some cases opposite -\neffective temperatures, resembling the original concept of prethermalization\nfrom particle physics. Our results establish strongly correlated AMO platforms\nas tools to investigate fundamental questions in statistical mechanics,\nincluding quantum thermalization in higher-dimensional systems.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,quant-ph","published":"2025-04-08T17:59:59Z"}
{"aid":"http://arxiv.org/abs/2504.06573v1","title":"Mutation Cycles from Reddening Sequences","summary":"Given two quivers, each with a reddening sequence, we show how to construct a\nplethora of mutation cycles. We give several examples, including a\ngeneralization of the construction of long mutation cycles in earlier work by\nthe second author. We also give new results on the reddening sequences of\ncertain mutation-acyclic quivers and forks, classifying them in some cases.","main_category":"math.CO","categories":"math.CO","published":"2025-04-09T04:21:51Z"}
{"aid":"http://arxiv.org/abs/2504.06604v1","title":"Image registration of 2D optical thin sections in a 3D porous medium:\n  Application to a Berea sandstone digital rock image","summary":"This study proposes a systematic image registration approach to align 2D\noptical thin-section images within a 3D digital rock volume. Using template\nimage matching with differential evolution optimization, we identify the most\nsimilar 2D plane in 3D. The method is validated on a synthetic porous medium,\nachieving exact registration, and applied to Berea sandstone, where it achieves\na structural similarity index (SSIM) of 0.990. With the registered images, we\nexplore upscaling properties based on paired multimodal images, focusing on\npore characteristics and effective elastic moduli. The thin-section image\nreveals 50 % more porosity and submicron pores than the registered CT plane. In\naddition, bulk and shear moduli from thin sections are 25 % and 30 % lower,\nrespectively, than those derived from CT images. Beyond numerical comparisons,\nthin sections provide additional geological insights, including cementation,\nmineral phases, and weathering effects, which are not clear in CT images. This\nstudy demonstrates the potential of multimodal image registration to improve\ncomputed rock properties in digital rock physics by integrating complementary\nimaging modalities.","main_category":"physics.geo-ph","categories":"physics.geo-ph,cs.CV","published":"2025-04-09T06:01:43Z"}
{"aid":"http://arxiv.org/abs/2504.06645v1","title":"Evidence for repeating fast radio bursts association with fast\n  super-twisted magnetars","summary":"Fast radio bursts (FRBs) are bright millisecond radio events of unknown\nextra-galactic origin. Magnetars are one of the main contenders. Some sources,\nthe repeaters, produce multiple events but so far generally without the\ncharacteristic periodicity that one could associate with the spin of a neutron\nstar. We fit a geometrical model to the two main repeaters of the CHIME/FRB\ncatalogue, namely FRB 20180814A and FRB 20180916B. Assuming the bursts\noriginate from a magnetar's magnetosphere, we constrain the spin and magnetic\nparameters of the star which are encoded into burst spectro-temporal\nmorphologies. We estimate that a very strong toroidal magnetic component\ntogether with spin periods of respectively $2.3_{-0.5}^{+0.5} ~ \\rm s$ and\n$0.8_{-0.2}^{+0.1} ~ \\rm s$ best explain the data. We argue that this points\ntowards young magnetars with super-twisted magnetospheres.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-09T07:33:25Z"}
{"aid":"http://arxiv.org/abs/2504.06657v1","title":"When Pythagoras meets Navier-Stokes","summary":"In this article, we develop a new method, based on a time decomposition of a\nCauchy problem elaborated in [6], to retrieve the well-known $L^\\infty\n([0,T],L^2(\\mathbb{R}^d,\\mathbb{R}^d))$ control of the solution of the\nincompressible Navier-Stokes equation in $\\mathbb{R}^d$. We precisely explain\nhow the Pythagorean theorem in $L^2(\\mathbb{R}^d,\\mathbb{R}^d)$ allows to get\nthe proper energy estimate; however such an argument does not work anymore in\n$L^p(\\mathbb{R}^d,\\mathbb{R}^d)$, $p \\neq 2$. We also deduce, by similar\narguments, an already known $L^\\infty ([0,T],L^1(\\mathbb{R}^3,\\mathbb{R}^3))$\ncontrol of vorticity for $d=3$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T07:47:35Z"}
{"aid":"http://arxiv.org/abs/2504.06671v1","title":"Defects in Silicon Carbide as Quantum Qubits: Recent Advances in Defect\n  Engineering","summary":"This review provides an overview of defects in silicon carbide (SiC) with\npotential applications as quantum qubits. It begins with a brief introduction\nto quantum qubits and existing qubit platforms, outlining the essential\ncriteria a defect must meet to function as a viable qubit. The focus then\nshifts to the most promising defects in SiC, notably the silicon vacancy (VSi)\nand divacancy (VC-VSi). A key challenge in utilizing these defects for quantum\napplications is their precise and controllable creation. Various fabrication\ntechniques, including irradiation, ion implantation, femtosecond laser\nprocessing, and focused ion beam methods, have been explored to create these\ndefects. Designed as a beginner-friendly resource, this review aims to support\nearly-career experimental researchers entering the field of SiC-related quantum\nqubits. Providing an introduction to defect-based qubits in SiC offers valuable\ninsights into fabrication strategies, recent progress, and the challenges that\nlie ahead.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,quant-ph","published":"2025-04-09T08:13:58Z"}
{"aid":"http://arxiv.org/abs/2504.06695v1","title":"A Convex-Analytical Proof of the Fundamental Theorem of Algebra","summary":"A weak version of Birkhoff's generalization of the Perron-Frobenius theorem\nstates that every endomorphism of a finite-dimensional real vector that leaves\ninvariant a non-degenerate closed convex cone has an eigenvector in that cone.\n  Here, we show that this theorem, whose proof relies only upon basic convex\nanalysis, yields very short proofs of both the spectral theorem for selfadjoint\noperators of Euclidean spaces and the Fundamental Theorem of Algebra.","main_category":"math.FA","categories":"math.FA,math.SP","published":"2025-04-09T08:54:14Z"}
{"aid":"http://arxiv.org/abs/2504.06702v1","title":"Consensus-based qubit configuration optimization for variational\n  algorithms on neutral atom quantum systems","summary":"In this work, we report an algorithm that is able to tailor qubit\ninteractions for individual variational quantum algorithm problems. Here, the\nalgorithm leverages the unique ability of a neutral atom tweezer platform to\nrealize arbitrary qubit position configurations. These configurations determine\nthe degree of entanglement available to a variational quantum algorithm via the\ninteratomic interactions. Good configurations will accelerate pulse\noptimization convergence and help mitigate barren plateaus. As gradient-based\napproaches are ineffective for position optimization due to the divergent\n$R^{-6}$ nature of neutral atom interactions, we opt to use a consensus-based\nalgorithm to optimize the qubit positions. By sampling the configuration space\ninstead of using gradient information, the consensus-based algorithm is able to\nsuccessfully optimize the positions, yielding adapted variational quantum\nalgorithm ansatzes that lead to both faster convergence and lower errors. In\nthis work, we show that these optimized configurations generally result in\nlarge improvements in the system's ability to solve ground state minimization\nproblems for both random Hamiltonians and small molecules.","main_category":"quant-ph","categories":"quant-ph,physics.atom-ph","published":"2025-04-09T09:07:49Z"}
{"aid":"http://arxiv.org/abs/2504.06707v1","title":"Phase transition of the kinetic Justh-Krishnaprasad type model for\n  nematic alignment","summary":"We present a stochastic Justh-Krishnaprasad flocking model and study the\nphase transition of the Vlasov-McKean-Fokker-Planck (VMFP) equation, which can\nbe obtained in the mean-field limit. To describe the alignment, we use order\nparameters in terms of the distribution function of the kinetic model. For the\nconstant noise case, we study the well-posedness of the VMFP equation on the\ntorus. Based on regularity, we show that the phenomenon of phase transition is\nonly related to the ratio between the strengths of noise and coupling. In\nparticular, for the low-noise case, we derive an exponential convergence to the\nvon-Mises type equilibrium, which shows a strong evidence for the nematic\nalignment. The multiplicative noise is also studied to obtain a non-symmetric\nequilibrium with two different peaks on the torus.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T09:09:24Z"}
{"aid":"http://arxiv.org/abs/2504.06708v1","title":"Transport of electrolytes across nanochannels: the role of slip","summary":"We characterize the electrokinetic flow due to the transport of electrolytes\nembedded in nanochannels of varying cross-section with inhomogeneous slip on\ntheir walls, modeled as an effective slip length on the channel wall. We show\nthat, within linear response and Debye-Huckel regime, the transport\ncoefficients, and so the fluxes, can be significantly improved by the presence\nof a hydrophobic surface coating located at the narrowest section of the\nnanochannel. Our model indicates that the enhancement is larger when\nconsidering electric conductive walls in comparison to dielectric microchannel\nwalls, and it is produced by a synergy between the entropic effects due to the\ngeometry and the presence of the slip boundary layer. Our results show that a\ntailored hydrophobic coating design can be an effective strategy to improve\ntransport properties in the broad areas of lab-on-a-chip, biophysics, and blue\nenergy harvesting and energy conversion technologies.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cond-mat.soft","published":"2025-04-09T09:09:52Z"}
{"aid":"http://arxiv.org/abs/2504.06730v1","title":"PETNet -- Coincident Particle Event Detection using Spiking Neural\n  Networks","summary":"Spiking neural networks (SNN) hold the promise of being a more biologically\nplausible, low-energy alternative to conventional artificial neural networks.\nTheir time-variant nature makes them particularly suitable for processing\ntime-resolved, sparse binary data. In this paper, we investigate the potential\nof leveraging SNNs for the detection of photon coincidences in positron\nemission tomography (PET) data. PET is a medical imaging technique based on\ninjecting a patient with a radioactive tracer and detecting the emitted\nphotons. One central post-processing task for inferring an image of the tracer\ndistribution is the filtering of invalid hits occurring due to e.g. absorption\nor scattering processes. Our approach, coined PETNet, interprets the detector\nhits as a binary-valued spike train and learns to identify photon coincidence\npairs in a supervised manner. We introduce a dedicated multi-objective loss\nfunction and demonstrate the effects of explicitly modeling the detector\ngeometry on simulation data for two use-cases. Our results show that PETNet can\noutperform the state-of-the-art classical algorithm with a maximal coincidence\ndetection $F_1$ of 95.2%. At the same time, PETNet is able to predict photon\ncoincidences up to 36 times faster than the classical approach, highlighting\nthe great potential of SNNs in particle physics applications.","main_category":"cs.LG","categories":"cs.LG,hep-ex","published":"2025-04-09T09:38:45Z"}
{"aid":"http://arxiv.org/abs/2504.06733v1","title":"Timing the Escape of a Caged Electron","summary":"Charge transfer is fundamentally dependent on the overlap of the orbitals\ncomprising the transport pathway. This has key implications for molecular,\nnanoscale, and quantum technologies, for which delocalization (and decoherence)\nrates are essential figures of merit. Here, we apply the core hole clock\ntechnique - an energy-domain variant of ultrafast spectroscopy - to probe the\ndelocalization of a photoexcited electron inside a closed molecular cage,\nnamely the Ar 2p54s1 state of Ar@C60. Despite marginal frontier orbital mixing\nin the ground configuration, almost 80% of the excited state density is found\noutside the buckyball due to the formation of a markedly diffuse hybrid\norbital. Far from isolating the intracage excitation, the surrounding fullerene\nis instead a remarkably efficient conduit for electron transfer: we measure\ncharacteristic delocalization times of 6.6 $\\pm$ 0.3 fs and $\\lesssim$ 500\nattoseconds, respectively, for a 3D Ar@C60 film and a 2D monolayer on Ag(111).","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-09T09:45:23Z"}
{"aid":"http://arxiv.org/abs/2504.06754v1","title":"A new norm on the space of reproducing kernel Hilbert space operators\n  and Berezin number inequalities","summary":"In this note, we introduce a novel norm, termed the $t-$Berezin norm, on the\nalgebra of all bounded linear operators defined on a reproducing kernel Hilbert\nspace $\\mathcal{H}$ as\n  $$\\|A\\|_{t-ber} = \\sup_{ \\lambda, \\mu \\in \\Omega} \\left\\{ t|\\langle A\n\\hat{k}_\\lambda, \\hat{k}_\\mu \\rangle| + (1-t) |\\langle A^* \\hat{k}_\\lambda,\n\\hat{k}_\\mu \\rangle| \\right\\}, \\quad t\\in [0,1],$$\n  where $A \\in \\mathcal{B}(\\mathcal{H})$ is a bounded linear operator. This\nnorm characterizes those invertible operators which are also unitary.\n  Using this newly defined norm, we establish various upper bounds for the\nBerezin number, thereby refining the existing results. Additionally, we derive\nseveral sharp bounds for the Berezin number of an operator via the Orlicz\nfunction.","main_category":"math.FA","categories":"math.FA","published":"2025-04-09T10:18:53Z"}
{"aid":"http://arxiv.org/abs/2504.06774v1","title":"Hybrid machine learning models based on physical patterns to accelerate\n  CFD simulations: a short guide on autoregressive models","summary":"Accurate modeling of the complex dynamics of fluid flows is a fundamental\nchallenge in computational physics and engineering. This study presents an\ninnovative integration of High-Order Singular Value Decomposition (HOSVD) with\nLong Short-Term Memory (LSTM) architectures to address the complexities of\nreduced-order modeling (ROM) in fluid dynamics. HOSVD improves the\ndimensionality reduction process by preserving multidimensional structures,\nsurpassing the limitations of Singular Value Decomposition (SVD). The\nmethodology is tested across numerical and experimental data sets, including\ntwo- and three-dimensional (2D and 3D) cylinder wake flows, spanning both\nlaminar and turbulent regimes. The emphasis is also on exploring how the depth\nand complexity of LSTM architectures contribute to improving predictive\nperformance. Simpler architectures with a single dense layer effectively\ncapture the periodic dynamics, demonstrating the network's ability to model\nnon-linearities and chaotic dynamics. The addition of extra layers provides\nhigher accuracy at minimal computational cost. These additional layers enable\nthe network to expand its representational capacity, improving the prediction\naccuracy and reliability. The results demonstrate that HOSVD outperforms SVD in\nall tested scenarios, as evidenced by using different error metrics. Efficient\nmode truncation by HOSVD-based models enables the capture of complex temporal\npatterns, offering reliable predictions even in challenging, noise-influenced\ndata sets. The findings underscore the adaptability and robustness of\nHOSVD-LSTM architectures, offering a scalable framework for modeling fluid\ndynamics.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cs.LG","published":"2025-04-09T10:56:03Z"}
{"aid":"http://arxiv.org/abs/2504.06793v1","title":"Variable Metric Splitting Methods for Neuromorphic Circuits Simulation","summary":"This paper proposes a variable metric splitting algorithm to solve the\nelectrical behavior of neuromorphic circuits made of capacitors, memristive\nelements, and batteries. The gradient property of the memristive elements is\nexploited to split the current to voltage operator as the sum of the derivative\noperator, a Riemannian gradient operator, and a nonlinear residual operator\nthat is linearized at each step of the algorithm. The diagonal structure of the\nthree operators makes the variable metric forward-backward splitting algorithm\nscalable and amenable to the simulation of large-scale neuromorphic circuits.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-09T11:34:31Z"}
{"aid":"http://arxiv.org/abs/2504.06797v1","title":"Quantum Field Theory on Multifractal Spacetime: Varying Dimension and\n  Ultraviolet Completeness","summary":"Inspired by various quantum gravity approaches, we explore quantum field\ntheory where spacetime exhibits scaling properties and dimensional reduction\nwith changing energy scales, effectively behaving as a multifractal manifold.\nWorking within canonical quantization, we demonstrate how to properly quantize\nfields in such multifractal spacetime. Our analysis reveals that a\nnon-differentiable nature of spacetime is not merely compatible with quantum\nfield theory but significantly enhances its mathematical foundation. Most\nnotably, this approach guarantees the finiteness of the theory at all orders in\nperturbation theory and enables rigorous construction of the S-matrix in the\ninteraction picture. The multifractal structure tames dominant, large-order\ndivergence sources in the perturbative series and resolves the Landau pole\nproblem through asymptotic safety, substantially improving the theory's\nbehavior in the deep ultraviolet regime. Our formulation preserves all\nestablished predictions of standard quantum field theory at low energies while\noffering novel physical behaviors at high energy scales.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-04-09T11:41:15Z"}
{"aid":"http://arxiv.org/abs/2504.06817v1","title":"Unparalleled instances of prolifickness, random walks, and square root\n  boundaries","summary":"We revisit the problem of influencing the sex ratio of a population by\nsubjecting reproduction of each family to some stopping rule. As an easy\nconsequence of the strong law of large numbers, no such modification is\npossible in the sense that the ratio converges to 1 almost surely, for any\nstopping rule that is finite almost surely. We proceed to quantify the effects\nand provide limit distributions for the properly rescaled sex ratio. Besides\nthe total ratio, which is predominantly considered in the pertinent literature,\nwe also analyze the average sex ratio, which may converge to values different\nfrom 1. The first part of this note is largely expository, applying classical\nresults and standard methods from the fluctuation theory of random walks. In\nthe second part we apply tail asymptotics for the time at which a random walk\nhits a one-sided square root boundary, exhibit the differences to the\ncorresponding two-sided problem, and use a limit law related to the empirical\ndispersion coefficient of a heavy-tailed distribution. Finally, we derive a\nlarge deviations result for a special stopping strategy, using saddle point\nasymptotics.","main_category":"math.PR","categories":"math.PR","published":"2025-04-09T12:19:37Z"}
{"aid":"http://arxiv.org/abs/2504.06823v1","title":"Open Problems and a Hypothetical Path Forward in LLM Knowledge Paradigms","summary":"Knowledge is fundamental to the overall capabilities of Large Language Models\n(LLMs). The knowledge paradigm of a model, which dictates how it encodes and\nutilizes knowledge, significantly affects its performance. Despite the\ncontinuous development of LLMs under existing knowledge paradigms, issues\nwithin these frameworks continue to constrain model potential.\n  This blog post highlight three critical open problems limiting model\ncapabilities: (1) challenges in knowledge updating for LLMs, (2) the failure of\nreverse knowledge generalization (the reversal curse), and (3) conflicts in\ninternal knowledge. We review recent progress made in addressing these issues\nand discuss potential general solutions. Based on observations in these areas,\nwe propose a hypothetical paradigm based on Contextual Knowledge Scaling, and\nfurther outline implementation pathways that remain feasible within\ncontemporary techniques. Evidence suggests this approach holds potential to\naddress current shortcomings, serving as our vision for future model paradigms.\n  This blog post aims to provide researchers with a brief overview of progress\nin LLM knowledge systems, while provide inspiration for the development of\nnext-generation model architectures.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T12:31:25Z"}
{"aid":"http://arxiv.org/abs/2504.06826v1","title":"Long-period double-lined eclipsing binaries: the system V454 Aur with\n  the secondary eclipse caused by the occultation of the hotter component","summary":"We present the results of our study of the long-period eclipsing binary star\n\\Aur. The results are based on spectroscopic data obtained with the UFES\n\\'echelle spectrograph and photometric observations from TESS. The derived\nradial velocity curve is based on 17 spectra obtained between 2021 and 2023,\ncovering all orbital phases of this binary system. The orbital period\ndetermined from TESS data, $P = 27.019803 \\pm 0.000003$ days, agrees within\nuncertainties with the period established in previous studies. The model\nconstructed for the TESS photometric light curve achieves a precision of\n0.01\\%. The effective temperatures of both components, as well as the system\nmetallicity, were directly derived from the spectra and are $T_\\mathrm{eff, A}\n= 6250 \\pm 50$\\,K, $T_\\mathrm{eff, B} = 5855 \\pm 50$\\,K, and $\\mathrm{[Fe/H]} =\n-0.10 \\pm 0.08$, respectively. Our analysis of the photometric and\nspectroscopic data allowed us to directly compute the luminosities of the\ncomponents, $L_A = 1.82\\,L_\\odot$ and $L_B = 1.07\\,L_\\odot$, their radii, $R_A\n= 1.15\\,R_\\odot$ and $R_B = 1.00\\,R_\\odot$, and their masses, $M_A =\n1.137\\,M_\\odot$ and $M_B = 1.023\\,M_\\odot$, with uncertainties below 1\\%.\nComparison with evolutionary tracks indicates that the system's age is $1.18\n\\pm 0.10$\\,Gyr, and both components are still on the main sequence. The \\Aur\\\nsystem is particularly interesting due to the partial eclipse of the primary\ncomponent, which results in the ``inversion'' of the primary and secondary\nminima in the photometric light curve.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-09T12:34:35Z"}
{"aid":"http://arxiv.org/abs/2504.06838v1","title":"ZIP: An Efficient Zeroth-order Prompt Tuning for Black-box\n  Vision-Language Models","summary":"Recent studies have introduced various approaches for prompt-tuning black-box\nvision-language models, referred to as black-box prompt-tuning (BBPT). While\nBBPT has demonstrated considerable potential, it is often found that many\nexisting methods require an excessive number of queries (i.e., function\nevaluations), which poses a significant challenge in real-world scenarios where\nthe number of allowed queries is limited. To tackle this issue, we propose\nZeroth-order Intrinsic-dimensional Prompt-tuning (ZIP), a novel approach that\nenables efficient and robust prompt optimization in a purely black-box setting.\nThe key idea of ZIP is to reduce the problem dimensionality and the variance of\nzeroth-order gradient estimates, such that the training is done fast with far\nless queries. We achieve this by re-parameterizing prompts in low-rank\nrepresentations and designing intrinsic-dimensional clipping of estimated\ngradients. We evaluate ZIP on 13+ vision-language tasks in standard benchmarks\nand show that it achieves an average improvement of approximately 6% in\nfew-shot accuracy and 48% in query efficiency compared to the best-performing\nalternative BBPT methods, establishing a new state of the art. Our ablation\nanalysis further shows that the proposed clipping mechanism is robust and\nnearly optimal, without the need to manually select the clipping threshold,\nmatching the result of expensive hyperparameter search.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-09T12:56:22Z"}
{"aid":"http://arxiv.org/abs/2504.06862v1","title":"Dynamics of critical cascades in interdependent networks","summary":"The collapse of interdependent networks, as well as similar avalanche\nphenomena, is driven by cascading failures. At the critical point, the cascade\nbegins as a critical branching process, where each failing node (element)\ntriggers, on average, the failure of one other node. As nodes continue to fail,\nthe network becomes increasingly fragile and the branching factor grows. If the\nfailure process does not reach extinction during its critical phase, the\nnetwork undergoes an abrupt collapse. Here, we implement the analogy between\nthis dynamic and birth-death processes to derive new analytical results and\nsignificantly optimize numerical calculations. Using this approach, we analyze\nthree key aspects of the dynamics: the probability of collapse, the duration of\navalanches, and the length of the cascading plateau phase preceding a collapse.\nThis analysis quantifies how system size and the intensity of the initial\ntriggering event influence these characteristics.","main_category":"physics.soc-ph","categories":"physics.soc-ph,q-bio.PE","published":"2025-04-09T13:12:43Z"}
{"aid":"http://arxiv.org/abs/2504.06868v1","title":"Persona Dynamics: Unveiling the Impact of Personality Traits on Agents\n  in Text-Based Games","summary":"Artificial agents are increasingly central to complex interactions and\ndecision-making tasks, yet aligning their behaviors with desired human values\nremains an open challenge. In this work, we investigate how human-like\npersonality traits influence agent behavior and performance within text-based\ninteractive environments. We introduce PANDA: PersonalityAdapted Neural\nDecision Agents, a novel method for projecting human personality traits onto\nagents to guide their behavior. To induce personality in a text-based game\nagent, (i) we train a personality classifier to identify what personality type\nthe agent's actions exhibit, and (ii) we integrate the personality profiles\ndirectly into the agent's policy-learning pipeline. By deploying agents\nembodying 16 distinct personality types across 25 text-based games and\nanalyzing their trajectories, we demonstrate that an agent's action decisions\ncan be guided toward specific personality profiles. Moreover, certain\npersonality types, such as those characterized by higher levels of Openness,\ndisplay marked advantages in performance. These findings underscore the promise\nof personality-adapted agents for fostering more aligned, effective, and\nhuman-centric decision-making in interactive environments.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-09T13:17:00Z"}
{"aid":"http://arxiv.org/abs/2504.06878v1","title":"CRYSIM: Prediction of Symmetric Structures of Large Crystals with\n  GPU-based Ising Machines","summary":"Solving black-box optimization problems with Ising machines is increasingly\ncommon in materials science. However, their application to crystal structure\nprediction (CSP) is still ineffective due to symmetry agnostic encoding of\natomic coordinates. We introduce CRYSIM, an algorithm that encodes the space\ngroup, the Wyckoff positions combination, and coordinates of independent atomic\nsites as separate variables. This encoding reduces the search space\nsubstantially by exploiting the symmetry in space groups. When CRYSIM is\ninterfaced to Fixstars Amplify, a GPU-based Ising machine, its prediction\nperformance was competitive with CALYPSO and Bayesian optimization for crystals\ncontaining more than 150 atoms in a unit cell. Although it is not realistic to\ninterface CRYSIM to current small-scale quantum devices, it has the potential\nto become the standard CSP algorithm in the coming quantum age.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cs.LG","published":"2025-04-09T13:33:48Z"}
{"aid":"http://arxiv.org/abs/2504.06883v1","title":"The Dirac Equation, Mass and Arithmetic by Permutations of Automaton\n  States","summary":"The cornerstones of the Cellular Automaton Interpretation of Quantum\nMechanics are its underlying ontological states that evolve by permutations.\nThey do not create would-be quantum mechanical superposition states. We review\nthis with a classical automaton consisting of an Ising spin chain which is then\nrelated to the Weyl equation in the continuum limit. Based on this and\ngeneralizing, we construct a new ``Necklace of Necklaces'' automaton with a\ntorus-like topology that lends itself to represent the Dirac equation in 1 + 1\ndimensions. Special attention has to be paid to its mass term, which\nnecessitates this enlarged structure and a particular scattering operator\ncontributing to the step-wise updates of the automaton. As discussed earlier,\nsuch deterministic models of discrete spins or bits unavoidably become quantum\nmechanical, when only slightly deformed.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.MP,nlin.CG","published":"2025-04-09T13:37:12Z"}
{"aid":"http://arxiv.org/abs/2504.06892v1","title":"Applications of Hybrid Machine Learning Methods to Large Datasets: A\n  Case Study","summary":"We combine classical and quantum Machine Learning (ML) techniques to\neffectively analyze long time-series data acquired during experiments.\nSpecifically, we demonstrate that replacing a deep classical neural network\nwith a thoughtfully designed Variational Quantum Circuit (VQC) in an ML\npipeline for multiclass classification of time-series data yields the same\nclassification performance, while significantly reducing the number of\ntrainable parameters. To achieve this, we use a VQC based on a single qudit,\nand encode the classical data into the VQC via a trainable hybrid autoencoder\nwhich has been recently proposed as embedding technique. Our results highlight\nthe importance of tailored data pre-processing for the circuit and show the\npotential of qudit-based VQCs.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T13:53:27Z"}
{"aid":"http://arxiv.org/abs/2504.06900v1","title":"On PoincarÃ© constants related to isoperimetric problems in convex\n  bodies","summary":"For any convex set $\\Omega \\subset {\\mathbb R} ^N$, we provide a lower bound\nfor the inverse of the Poincar\\'e constant in $W ^ {1, 1}(\\Omega)$: it refines\nan inequality in terms of the diameter due to Acosta-Duran, via the addition of\nan extra term giving account for the flatness of the domain. In dimension $N =\n2$, we are able to make the extra term completely explicit, thus providing a\nnew Bonnesen-type inequality for the Poincar\\'e constant in terms of diameter\nand inradius. Such estimate is sharp, and it is asymptotically attained when\nthe domain is the intersection of a ball with a strip bounded by parallel\nstraight lines, symmetric about the centre of the ball. As a key intermediate\nstep, we prove that the ball maximizes the Poincar\\'e constant in $W ^ {1, 1}\n(\\Omega)$, among convex bodies $\\Omega$ of given constant width.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T14:00:04Z"}
{"aid":"http://arxiv.org/abs/2504.06916v1","title":"Semi-Orthogonal Decompositions for Rank Two Imprimitive Reflection\n  Groups","summary":"For every imprimitive complex reflection group of rank 2, we construct a\nsemi-orthogonal decomposition of the derived category of the associated global\nquotient stack which categorifies the usual decomposition of the orbifold\ncohomology indexed by conjugacy classes. This confirms a conjecture of\nPolishchuk and Van den Bergh in these cases. This conjecture was recently also\nproved by Ishii and Nimura for arbitrary complex reflection groups of rank at\nmost 3, but our approach is very different.","main_category":"math.AG","categories":"math.AG,math.RT","published":"2025-04-09T14:23:21Z"}
{"aid":"http://arxiv.org/abs/2504.06932v1","title":"Maximizing Battery Storage Profits via High-Frequency Intraday Trading","summary":"Maximizing revenue for grid-scale battery energy storage systems in\ncontinuous intraday electricity markets requires strategies that are able to\nseize trading opportunities as soon as new information arrives. This paper\nintroduces and evaluates an automated high-frequency trading strategy for\nbattery energy storage systems trading on the intraday market for power while\nexplicitly considering the dynamics of the limit order book, market rules, and\ntechnical parameters. The standard rolling intrinsic strategy is adapted for\ncontinuous intraday electricity markets and solved using a dynamic programming\napproximation that is two to three orders of magnitude faster than an exact\nmixed-integer linear programming solution. A detailed backtest over a full year\nof German order book data demonstrates that the proposed dynamic programming\nformulation does not reduce trading profits and enables the policy to react to\nevery relevant order book update, enabling realistic rapid backtesting. Our\nresults show the significant revenue potential of high-frequency trading: our\npolicy earns 58% more than when re-optimizing only once every hour and 14% more\nthan when re-optimizing once per minute, highlighting that profits critically\ndepend on trading speed. Furthermore, we leverage the speed of our algorithm to\ntrain a parametric extension of the rolling intrinsic, increasing yearly\nrevenue by 8.4% out of sample.","main_category":"q-fin.TR","categories":"q-fin.TR,cs.SY,eess.SY,math.OC","published":"2025-04-09T14:38:09Z"}
{"aid":"http://arxiv.org/abs/2504.06957v1","title":"A Comparison of Deep Learning Methods for Cell Detection in Digital\n  Cytology","summary":"Accurate and efficient cell detection is crucial in many biomedical image\nanalysis tasks. We evaluate the performance of several Deep Learning (DL)\nmethods for cell detection in Papanicolaou-stained cytological Whole Slide\nImages (WSIs), focusing on accuracy of predictions and computational\nefficiency. We examine recentoff-the-shelf algorithms as well as\ncustom-designed detectors, applying them to two datasets: the CNSeg Dataset and\nthe Oral Cancer (OC) Dataset. Our comparison includes well-established\nsegmentation methods such as StarDist, Cellpose, and the Segment Anything Model\n2 (SAM2), alongside centroid-based Fully Convolutional Regression Network\n(FCRN) approaches. We introduce a suitable evaluation metric to assess the\naccuracy of predictions based on the distance from ground truth positions. We\nalso explore the impact of dataset size and data augmentation techniques on\nmodel performance. Results show that centroid-based methods, particularly the\nImproved Fully Convolutional Regression Network (IFCRN) method, outperform\nsegmentation-based methods in terms of both detection accuracy and\ncomputational efficiency. This study highlights the potential of centroid-based\ndetectors as a preferred option for cell detection in resource-limited\nenvironments, offering faster processing times and lower GPU memory usage\nwithout compromising accuracy.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T15:08:12Z"}
{"aid":"http://arxiv.org/abs/2504.06965v1","title":"A Deep Single Image Rectification Approach for Pan-Tilt-Zoom Cameras","summary":"Pan-Tilt-Zoom (PTZ) cameras with wide-angle lenses are widely used in\nsurveillance but often require image rectification due to their inherent\nnonlinear distortions. Current deep learning approaches typically struggle to\nmaintain fine-grained geometric details, resulting in inaccurate rectification.\nThis paper presents a Forward Distortion and Backward Warping Network\n(FDBW-Net), a novel framework for wide-angle image rectification. It begins by\nusing a forward distortion model to synthesize barrel-distorted images,\nreducing pixel redundancy and preventing blur. The network employs a pyramid\ncontext encoder with attention mechanisms to generate backward warping flows\ncontaining geometric details. Then, a multi-scale decoder is used to restore\ndistorted features and output rectified images. FDBW-Net's performance is\nvalidated on diverse datasets: public benchmarks, AirSim-rendered PTZ camera\nimagery, and real-scene PTZ camera datasets. It demonstrates that FDBW-Net\nachieves SOTA performance in distortion rectification, boosting the\nadaptability of PTZ cameras for practical visual applications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T15:19:38Z"}
{"aid":"http://arxiv.org/abs/2504.07003v1","title":"The FitzHugh-Nagumo system on undulated cylinders: spontaneous\n  symmetrization and effective system","summary":"We consider the FitzHugh-Nagumo system on undulated cylindrical surfaces\nmodeling nerve axons. We show that for sufficiently small radii and for initial\nconditions close to radially symmetrical ones, (i) the solutions converge to\ntheir radial averages, and (ii) the latter averages can be approximated by\nsolutions of a 1+1 dimensional ('radial') system (the effective system)\ninvolving the surface radius function in its coefficients. This perhaps\nexplains why solutions of the original 1+1 dimensional FitzHugh-Nagumo system\nagree so well with experimental data on electrical impulse propagation.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T16:22:58Z"}
{"aid":"http://arxiv.org/abs/2504.07014v1","title":"Fermi surface as a quantum critical manifold: gaplessness, order\n  parameter, and scaling in $d$-dimensions","summary":"We study several models of $d$-dimensional fermions ($d=1,2,3$) with an\nemphasis on the properties of their gapless (metallic) phase. It occurs at $T =\n0$ as a continuous transition when zeros of the partition function reach the\nreal range of parameters. Those zeros define the $(d-1)$-manifold of quantum\ncriticality (Fermi surface). Its appearance or restructuring correspond to the\nLifshitz transition. Such $(d-1)$-membrane breaks the symmetry of the momentum\nspace, leading to gapless excitations, a hallmark of metallic phase. To probe\nquantitatively the gapless phase we introduce the geometric order parameter as\n$d$-volume of the Fermi sea. From analysis of the chain, ladder, and free\nfermions with different spectra, this proposal is shown to be consistent with\nscaling near the Lifshitz points of other quantities: correlation length,\noscillation wavelength, susceptibilities, and entanglement. All the\n(hyper)scaling relations are satisfied. Two interacting cases of the\nTomonaga-Luttinger ($d=1$) and the Fermi ($d=2,3$) liquids are analysed,\nyielding the same universality classes as free fermions.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.stat-mech,quant-ph","published":"2025-04-09T16:31:07Z"}
{"aid":"http://arxiv.org/abs/2504.07022v1","title":"Evaluating Retrieval Augmented Generative Models for Document Queries in\n  Transportation Safety","summary":"Applications of generative Large Language Models LLMs are rapidly expanding\nacross various domains, promising significant improvements in workflow\nefficiency and information retrieval. However, their implementation in\nspecialized, high-stakes domains such as hazardous materials transportation is\nchallenging due to accuracy and reliability concerns. This study evaluates the\nperformance of three fine-tuned generative models, ChatGPT, Google's Vertex AI,\nand ORNL Retrieval Augmented Generation augmented LLaMA 2 and LLaMA in\nretrieving regulatory information essential for hazardous material\ntransportation compliance in the United States. Utilizing approximately 40\npublicly available federal and state regulatory documents, we developed 100\nrealistic queries relevant to route planning and permitting requirements.\nResponses were qualitatively rated based on accuracy, detail, and relevance,\ncomplemented by quantitative assessments of semantic similarity between model\noutputs. Results demonstrated that the RAG-augmented LLaMA models significantly\noutperformed Vertex AI and ChatGPT, providing more detailed and generally\naccurate information, despite occasional inconsistencies. This research\nintroduces the first known application of RAG in transportation safety,\nemphasizing the need for domain-specific fine-tuning and rigorous evaluation\nmethodologies to ensure reliability and minimize the risk of inaccuracies in\nhigh-stakes environments.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T16:37:03Z"}
{"aid":"http://arxiv.org/abs/2504.07049v1","title":"Harnessing non-equilibrium forces to optimize work extraction","summary":"While optimal control theory offers effective strategies for minimizing\nenergetic costs in noisy microscopic systems over finite durations, a\nsignificant opportunity lies in exploiting the temporal structure of\nnon-equilibrium forces. We demonstrate this by presenting exact analytical\nforms for the optimal protocol and the corresponding work for any driving force\nand protocol duration. We also derive a general quasistatic bound on the work,\nrelying only on the coarse-grained, time-integrated characteristics of the\napplied forces. Notably, we show that the optimal protocols often automatically\nact as information engines that harness information about non-equilibrium\nforces and an initial state measurement to extract work. These findings chart\nnew directions for designing adaptive, energy-efficient strategies in noisy,\ntime-dependent environments, as illustrated through our examples of periodic\ndriving forces and active matter systems. By exploiting the temporal structure\nof non-equilibrium forces, this largely unexplored approach holds promise for\nsubstantial performance gains in microscopic devices operating at the nano- and\nmicroscale.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.soft","published":"2025-04-09T17:06:15Z"}
{"aid":"http://arxiv.org/abs/2504.07055v1","title":"$Î $-NeSy: A Possibilistic Neuro-Symbolic Approach","summary":"In this article, we introduce a neuro-symbolic approach that combines a\nlow-level perception task performed by a neural network with a high-level\nreasoning task performed by a possibilistic rule-based system. The goal is to\nbe able to derive for each input instance the degree of possibility that it\nbelongs to a target (meta-)concept. This (meta-)concept is connected to\nintermediate concepts by a possibilistic rule-based system. The probability of\neach intermediate concept for the input instance is inferred using a neural\nnetwork. The connection between the low-level perception task and the\nhigh-level reasoning task lies in the transformation of neural network outputs\nmodeled by probability distributions (through softmax activation) into\npossibility distributions. The use of intermediate concepts is valuable for the\nexplanation purpose: using the rule-based system, the classification of an\ninput instance as an element of the (meta-)concept can be justified by the fact\nthat intermediate concepts have been recognized.\n  From the technical side, our contribution consists of the design of efficient\nmethods for defining the matrix relation and the equation system associated\nwith a possibilistic rule-based system. The corresponding matrix and equation\nare key data structures used to perform inferences from a possibilistic\nrule-based system and to learn the values of the rule parameters in such a\nsystem according to a training data sample. Furthermore, leveraging recent\nresults on the handling of inconsistent systems of fuzzy relational equations,\nan approach for learning rule parameters according to multiple training data\nsamples is presented. Experiments carried out on the MNIST addition problems\nand the MNIST Sudoku puzzles problems highlight the effectiveness of our\napproach compared with state-of-the-art neuro-symbolic ones.","main_category":"cs.AI","categories":"cs.AI,cs.LG,cs.LO","published":"2025-04-09T17:16:23Z"}
{"aid":"http://arxiv.org/abs/2504.07072v1","title":"Kaleidoscope: In-language Exams for Massively Multilingual Vision\n  Evaluation","summary":"The evaluation of vision-language models (VLMs) has mainly relied on\nEnglish-language benchmarks, leaving significant gaps in both multilingual and\nmulticultural coverage. While multilingual benchmarks have expanded, both in\nsize and languages, many rely on translations of English datasets, failing to\ncapture cultural nuances. In this work, we propose Kaleidoscope, as the most\ncomprehensive exam benchmark to date for the multilingual evaluation of\nvision-language models. Kaleidoscope is a large-scale, in-language multimodal\nbenchmark designed to evaluate VLMs across diverse languages and visual inputs.\nKaleidoscope covers 18 languages and 14 different subjects, amounting to a\ntotal of 20,911 multiple-choice questions. Built through an open science\ncollaboration with a diverse group of researchers worldwide, Kaleidoscope\nensures linguistic and cultural authenticity. We evaluate top-performing\nmultilingual vision-language models and find that they perform poorly on\nlow-resource languages and in complex multimodal scenarios. Our results\nhighlight the need for progress on culturally inclusive multimodal evaluation\nframeworks.","main_category":"cs.CL","categories":"cs.CL,cs.CV","published":"2025-04-09T17:43:16Z"}
{"aid":"http://arxiv.org/abs/2504.07076v1","title":"On Fundamental Theorems of Super Invariant Theory","summary":"The purpose of this paper is to prove the First and Second Fundamental\nTheorems of invariant theory for the complex special linear supergroup and\ndiscuss the superalgebra of invariants, via the super Plucker relations.","main_category":"math.RA","categories":"math.RA","published":"2025-04-09T17:47:55Z"}
{"aid":"http://arxiv.org/abs/2504.07086v1","title":"A Sober Look at Progress in Language Model Reasoning: Pitfalls and Paths\n  to Reproducibility","summary":"Reasoning has emerged as the next major frontier for language models (LMs),\nwith rapid advances from both academic and industrial labs. However, this\nprogress often outpaces methodological rigor, with many evaluations relying on\nbenchmarking practices that lack transparency, robustness, or statistical\ngrounding. In this work, we conduct a comprehensive empirical study and find\nthat current mathematical reasoning benchmarks are highly sensitive to subtle\nimplementation choices - including decoding parameters, random seeds, prompt\nformatting, and even hardware and software-framework configurations.\nPerformance gains reported in recent studies frequently hinge on unclear\ncomparisons or unreported sources of variance. To address these issues, we\npropose a standardized evaluation framework with clearly defined best practices\nand reporting standards. Using this framework, we reassess recent methods and\nfind that reinforcement learning (RL) approaches yield only modest improvements\n- far below prior claims - and are prone to overfitting, especially on\nsmall-scale benchmarks like AIME24. In contrast, supervised finetuning (SFT)\nmethods show consistently stronger generalization. To foster reproducibility,\nwe release all code, prompts, and model outputs, for reasoning benchmarks,\nestablishing more rigorous foundations for future work.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-09T17:58:17Z"}
{"aid":"http://arxiv.org/abs/2504.07092v1","title":"Are We Done with Object-Centric Learning?","summary":"Object-centric learning (OCL) seeks to learn representations that only encode\nan object, isolated from other objects or background cues in a scene. This\napproach underpins various aims, including out-of-distribution (OOD)\ngeneralization, sample-efficient composition, and modeling of structured\nenvironments. Most research has focused on developing unsupervised mechanisms\nthat separate objects into discrete slots in the representation space,\nevaluated using unsupervised object discovery. However, with recent\nsample-efficient segmentation models, we can separate objects in the pixel\nspace and encode them independently. This achieves remarkable zero-shot\nperformance on OOD object discovery benchmarks, is scalable to foundation\nmodels, and can handle a variable number of slots out-of-the-box. Hence, the\ngoal of OCL methods to obtain object-centric representations has been largely\nachieved. Despite this progress, a key question remains: How does the ability\nto separate objects within a scene contribute to broader OCL objectives, such\nas OOD generalization? We address this by investigating the OOD generalization\nchallenge caused by spurious background cues through the lens of OCL. We\npropose a novel, training-free probe called $\\textbf{Object-Centric\nClassification with Applied Masks (OCCAM)}$, demonstrating that\nsegmentation-based encoding of individual objects significantly outperforms\nslot-based OCL methods. However, challenges in real-world applications remain.\nWe provide the toolbox for the OCL community to use scalable object-centric\nrepresentations, and focus on practical applications and fundamental questions,\nsuch as understanding object perception in human cognition. Our code is\navailable $\\href{https://github.com/AlexanderRubinstein/OCCAM}{here}$.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-09T17:59:05Z"}
{"aid":"http://arxiv.org/abs/2504.07097v1","title":"Sculpting Subspaces: Constrained Full Fine-Tuning in LLMs for Continual\n  Learning","summary":"Continual learning in large language models (LLMs) is prone to catastrophic\nforgetting, where adapting to new tasks significantly degrades performance on\npreviously learned ones. Existing methods typically rely on low-rank,\nparameter-efficient updates that limit the model's expressivity and introduce\nadditional parameters per task, leading to scalability issues. To address these\nlimitations, we propose a novel continual full fine-tuning approach leveraging\nadaptive singular value decomposition (SVD). Our method dynamically identifies\ntask-specific low-rank parameter subspaces and constrains updates to be\northogonal to critical directions associated with prior tasks, thus effectively\nminimizing interference without additional parameter overhead or storing\nprevious task gradients. We evaluate our approach extensively on standard\ncontinual learning benchmarks using both encoder-decoder (T5-Large) and\ndecoder-only (LLaMA-2 7B) models, spanning diverse tasks including\nclassification, generation, and reasoning. Empirically, our method achieves\nstate-of-the-art results, up to 7% higher average accuracy than recent\nbaselines like O-LoRA, and notably maintains the model's general linguistic\ncapabilities, instruction-following accuracy, and safety throughout the\ncontinual learning process by reducing forgetting to near-negligible levels.\nOur adaptive SVD framework effectively balances model plasticity and knowledge\nretention, providing a practical, theoretically grounded, and computationally\nscalable solution for continual learning scenarios in large language models.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL,math.PR,stat.ML","published":"2025-04-09T17:59:42Z"}
{"aid":"http://arxiv.org/abs/2504.07411v1","title":"Estimand framework development for eGFR slope estimation and comparative\n  analyses across various estimation methods","summary":"Chronic kidney disease (CKD) is a global health challenge characterized by\nprogressive kidney function decline, often culminating in end-stage kidney\ndisease (ESKD) and increased mortality. To address the limitations such as the\nextended trial follow-up necessitated by the low incidence of kidney composite\nendpoint, the eGFR slope -- a surrogate endpoint reflecting the trajectory of\nkidney function decline -- has gained prominence for its predictive power and\nregulatory support. Despite its advantages, the lack of a standardized\nframework for eGFR slope estimand and estimation complicates consistent\ninterpretation and cross-trial comparisons. Existing methods, including simple\nlinear regression and mixed-effects models, vary in their underlying\nassumptions, creating a need for a formalized approach to align estimation\nmethods with trial objectives. This manuscript proposes an estimand framework\ntailored to eGFR slope-based analyses in CKD RCTs, ensuring clarity in defining\n\"what to estimate\" and enhancing the comparability of results. Through\nsimulation studies and real-world data applications, we evaluate the\nperformance of various commonly applied estimation techniques under distinct\nscenarios. By recommending a clear characterization for eGFR slope estimand and\nproviding considerations for estimation approaches, this work aims to improve\nthe reliability and interpretability of CKD trial results, advancing\ntherapeutic development and clinical decision-making.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-10T03:03:31Z"}
{"aid":"http://arxiv.org/abs/2504.07461v1","title":"Achilles Heel of Distributed Multi-Agent Systems","summary":"Multi-agent system (MAS) has demonstrated exceptional capabilities in\naddressing complex challenges, largely due to the integration of multiple large\nlanguage models (LLMs). However, the heterogeneity of LLMs, the scalability of\nquantities of LLMs, and local computational constraints pose significant\nchallenges to hosting these models locally. To address these issues, we propose\na new framework termed Distributed Multi-Agent System (DMAS). In DMAS,\nheterogeneous third-party agents function as service providers managed remotely\nby a central MAS server and each agent offers its services through API\ninterfaces. However, the distributed nature of DMAS introduces several concerns\nabout trustworthiness. In this paper, we study the Achilles heel of distributed\nmulti-agent systems, identifying four critical trustworthiness challenges: free\nriding, susceptibility to malicious attacks, communication inefficiencies, and\nsystem instability. Extensive experiments across seven frameworks and four\ndatasets reveal significant vulnerabilities of the DMAS. These attack\nstrategies can lead to a performance degradation of up to 80% and attain a 100%\nsuccess rate in executing free riding and malicious attacks. We envision our\nwork will serve as a useful red-teaming tool for evaluating future multi-agent\nsystems and spark further research on trustworthiness challenges in distributed\nmulti-agent systems.","main_category":"cs.MA","categories":"cs.MA","published":"2025-04-10T05:16:11Z"}
{"aid":"http://arxiv.org/abs/2504.07474v1","title":"Dynamical quantum phase transition, metastable state, and dimensionality\n  reduction: Krylov analysis of fully-connected spin models","summary":"We study quenched dynamics of fully-connected spin models. The system is\nprepared in a ground state of the initial Hamiltonian and the Hamiltonian is\nsuddenly changed to a different form. We apply the Krylov subspace method to\nmap the system onto an effective tridiagonal Hamiltonian. The state is confined\nin a potential well and is time-evolved by nonuniform hoppings. The dynamical\nsingularities for the survival probability can occur when the state is\nreflected from a potential barrier. Although we do not observe any singularity\nin the spread complexity, we find that the entropy exhibits small dips at the\nsingular times. We find that the presence of metastable state affects long-time\nbehavior of the spread complexity, and physical observables. We also observe a\nreduction of the state-space dimension when the Hamiltonian reduces to a\nclassical form.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-10T05:58:49Z"}
{"aid":"http://arxiv.org/abs/2504.07503v1","title":"Event Signal Filtering via Probability Flux Estimation","summary":"Events offer a novel paradigm for capturing scene dynamics via asynchronous\nsensing, but their inherent randomness often leads to degraded signal quality.\nEvent signal filtering is thus essential for enhancing fidelity by reducing\nthis internal randomness and ensuring consistent outputs across diverse\nacquisition conditions. Unlike traditional time series that rely on fixed\ntemporal sampling to capture steady-state behaviors, events encode transient\ndynamics through polarity and event intervals, making signal modeling\nsignificantly more complex. To address this, the theoretical foundation of\nevent generation is revisited through the lens of diffusion processes. The\nstate and process information within events is modeled as continuous\nprobability flux at threshold boundaries of the underlying irradiance\ndiffusion. Building on this insight, a generative, online filtering framework\ncalled Event Density Flow Filter (EDFilter) is introduced. EDFilter estimates\nevent correlation by reconstructing the continuous probability flux from\ndiscrete events using nonparametric kernel smoothing, and then resamples\nfiltered events from this flux. To optimize fidelity over time, spatial and\ntemporal kernels are employed in a time-varying optimization framework. A fast\nrecursive solver with O(1) complexity is proposed, leveraging state-space\nmodels and lookup tables for efficient likelihood computation. Furthermore, a\nnew real-world benchmark Rotary Event Dataset (RED) is released, offering\nmicrosecond-level ground truth irradiance for full-reference event filtering\nevaluation. Extensive experiments validate EDFilter's performance across tasks\nlike event filtering, super-resolution, and direct event-based blob tracking.\nSignificant gains in downstream applications such as SLAM and video\nreconstruction underscore its robustness and effectiveness.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T07:03:08Z"}
{"aid":"http://arxiv.org/abs/2504.07504v1","title":"On Ihara's lemma for definite unitary groups","summary":"Clozel, Harris, and Taylor proposed a conjectural generalized Ihara's lemma\nfor definite unitary groups. In this paper, we prove their conjecture over\nbanal coefficients under some conditions. As an application, we prove a\nlevel-raising result for automorphic forms associated to definite unitary\ngroups.","main_category":"math.NT","categories":"math.NT,math.RT","published":"2025-04-10T07:03:27Z"}
{"aid":"http://arxiv.org/abs/2504.07520v1","title":"Stability and Convergence of Strang Splitting Method for the Allen-Cahn\n  Equation with Homogeneous Neumann Boundary Condition","summary":"The Strang splitting method has been widely used to solve nonlinear\nreaction-diffusion equations, with most theoretical convergence analysis\nassuming periodic boundary conditions. However, such analysis presents\nadditional challenges for the case of homogeneous Neumann boundary condition.\nIn this work the Strang splitting method with variable time steps is\ninvestigated for solving the Allen--Cahn equation with homogeneous Neumann\nboundary conditions. Uniform $H^k$-norm stability is established under the\nassumption that the initial condition $u^0$ belongs to the Sobolev space\n$H^k(\\Omega)$ with integer $k\\ge 0$, using the Gagliardo--Nirenberg\ninterpolation inequality and the Sobolev embedding inequality. Furthermore,\nrigorous convergence analysis is provided in the $H^k$-norm for initial\nconditions $u^0 \\in H^{k+6}(\\Omega)$, based on the uniform stability. Several\nnumerical experiments are conducted to verify the theoretical results,\ndemonstrating the effectiveness of the proposed method.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-10T07:33:42Z"}
{"aid":"http://arxiv.org/abs/2504.07526v1","title":"Computing gradient vector fields with Morse sequences","summary":"We rely on the framework of Morse sequences to enable the direct computation\nof gradient vector fields on simplicial complexes. A Morse sequence is a\nfiltration from a subcomplex L to a complex K via elementary expansions and\nfillings, naturally encoding critical and regular simplexes. Maximal increasing\nand minimal decreasing schemes allow constructing these sequences, and are\nlinked to algorithms like Random Discrete Morse and Coreduction. Extending the\napproach to cosimplicial complexes (S = K \\ L), we define operations --\nreductions, perforations, coreductions, and coperforations -- for efficient\ncomputation. We further generalize to F -sequences, which are Morse sequences\nweighted by an arbitrary stack function F , and provide algorithms to compute\nmaximal and minimal sequences. A particular case is when the stack function is\ngiven through a vertex map, as it is common in topological data analysis. We\nshow that we retrieve existing methods when the vertex map is injective; in\nthis case, the complex partitions into lower stars, facilitating parallel\nprocessing. Thus, this paper proposes simple, flexible, and computationally\nefficient approaches to obtain Morse sequences from arbitrary stack functions,\nallowing to generalize previous approaches dedicated to computing gradient\nvector fields from injective vertex maps.","main_category":"cs.DM","categories":"cs.DM,math.AT","published":"2025-04-10T07:48:31Z"}
{"aid":"http://arxiv.org/abs/2504.07534v1","title":"Convex spacelike hypersurface of constant curvature with boundary on a\n  hyperboloid","summary":"We consider convex, spacelike hypersurfaces with boundaries on some\nhyperboloid (or lightcone) in the Minkowski space. If the hypersurface has\nconstant higher order mean curvature, and the angle between the normal vectors\nof the hypersurface and the hyperboloid (or the lightcone) is constant on the\nboundary, then the hypersurface must be a part of another hyperboloid.","main_category":"math.DG","categories":"math.DG","published":"2025-04-10T08:00:55Z"}
{"aid":"http://arxiv.org/abs/2504.07535v1","title":"The v-numbers of Stanley-Reisner ideals from the viewpoint of Alexander\n  dual complexes","summary":"We express the v-number of the Stanley-Reisner ideal in terms of its\nAlexander dual complex and prove that the v-number of a cover ideal is just two\nless than the initial degree of the its syzygy module. We give some relation\nbetween the v-number of the Stanley-Reisner ideal and the Serre-depth of the\nquotient ring of the second symbolic power of the Stanley-Reisner ideal of its\nAlexander dual. We also show that the v-number of the Stanley-Reisner ideal of\na 2-pure simplicial complex is equal to the dimension of its Stanley-Reisner\nring.","main_category":"math.AC","categories":"math.AC","published":"2025-04-10T08:01:59Z"}
{"aid":"http://arxiv.org/abs/2504.07539v1","title":"$C$ and $CP$ violation in effective field theories and applications to\n  $Î·$-meson decays","summary":"The quest for sources of the simultaneous violation of $C$ and $CP$ symmetry\nwas popular in the 1960s, but has since been neglected for a long time. We\nrevisit the operators that break $C$ and $CP$ for flavor-conserving transitions\nin both the Standard Model effective field theory and the low-energy effective\nfield theory, which subsequently can be matched to light-meson physics using\nchiral perturbation theory. As applications, we discuss in particular the\n$C$-odd Dalitz plot asymmetries in $\\eta\\to3\\pi$, but also decays with dilepton\npairs in the final state, such as long-distance contributions to the rare\nsemileptonic decays $\\eta\\to\\pi^0\\ell^+\\ell^-$ as well as asymmetries in\n$\\eta^{(\\prime)} \\to \\gamma \\ell^+\\ell^-$ and $\\eta^{(\\prime)} \\to\n\\pi^+\\pi^-\\ell^+\\ell^-$.","main_category":"hep-ph","categories":"hep-ph,hep-ex,nucl-th","published":"2025-04-10T08:07:32Z"}
{"aid":"http://arxiv.org/abs/2504.07554v1","title":"Efficient Swept Volume-Based Trajectory Generation for Arbitrary-Shaped\n  Ground Robot Navigation","summary":"Navigating an arbitrary-shaped ground robot safely in cluttered environments\nremains a challenging problem. The existing trajectory planners that account\nfor the robot's physical geometry severely suffer from the intractable runtime.\nTo achieve both computational efficiency and Continuous Collision Avoidance\n(CCA) of arbitrary-shaped ground robot planning, we proposed a novel\ncoarse-to-fine navigation framework that significantly accelerates planning. In\nthe first stage, a sampling-based method selectively generates distinct\ntopological paths that guarantee a minimum inflated margin. In the second\nstage, a geometry-aware front-end strategy is designed to discretize these\ntopologies into full-state robot motion sequences while concurrently\npartitioning the paths into SE(2) sub-problems and simpler R2 sub-problems for\nback-end optimization. In the final stage, an SVSDF-based optimizer generates\ntrajectories tailored to these sub-problems and seamlessly splices them into a\ncontinuous final motion plan. Extensive benchmark comparisons show that the\nproposed method is one to several orders of magnitude faster than the\ncutting-edge methods in runtime while maintaining a high planning success rate\nand ensuring CCA.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-10T08:34:34Z"}
{"aid":"http://arxiv.org/abs/2504.07596v1","title":"Boosting Universal LLM Reward Design through the Heuristic Reward\n  Observation Space Evolution","summary":"Large Language Models (LLMs) are emerging as promising tools for automated\nreinforcement learning (RL) reward design, owing to their robust capabilities\nin commonsense reasoning and code generation. By engaging in dialogues with RL\nagents, LLMs construct a Reward Observation Space (ROS) by selecting relevant\nenvironment states and defining their internal operations. However, existing\nframeworks have not effectively leveraged historical exploration data or manual\ntask descriptions to iteratively evolve this space. In this paper, we propose a\nnovel heuristic framework that enhances LLM-driven reward design by evolving\nthe ROS through a table-based exploration caching mechanism and a text-code\nreconciliation strategy. Our framework introduces a state execution table,\nwhich tracks the historical usage and success rates of environment states,\novercoming the Markovian constraint typically found in LLM dialogues and\nfacilitating more effective exploration. Furthermore, we reconcile\nuser-provided task descriptions with expert-defined success criteria using\nstructured prompts, ensuring alignment in reward design objectives.\nComprehensive evaluations on benchmark RL tasks demonstrate the effectiveness\nand stability of the proposed framework. Code and video demos are available at\njingjjjjjie.github.io/LLM2Reward.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-10T09:48:56Z"}
{"aid":"http://arxiv.org/abs/2504.07599v1","title":"Tuning chirality amplitude at ultrafast timescales","summary":"Chirality is a fundamental symmetry concept describing discrete states, i.e.,\nleft-handed, right-handed, or achiral, and existing at disparate scales and in\nmany categories of scientific fields. Even though symmetry breaking is\nindispensable for describing qualitatively distinct phenomena, symmetry cannot\nquantitatively predict measurable quantities. One can continuously distort an\nobject, introducing the concept of chirality amplitude, similar to representing\nmagnetization as the amplitude of time-reversal symmetry breaking. Considering\nthe role of magnetization in emergent phenomena with time-reversal symmetry\nbreaking, chirality amplitude is intuitively a key quantity for controlling\nchirality-related emergent phenomena. Here, we propose two types of chiral\nlattice distortions and demonstrate the tunability of their amplitude in\nultrafast timescales. Resonant X-ray diffraction with circular polarization is\nan established technique to measure crystal chirality directly. We quantify the\nultrafast change in chirality amplitude in real time after an optical\nexcitation. Using instead a THz excitation, we observe oscillations in the\nresonant diffraction intensities corresponding to specific phonon frequencies.\nThis indicates the creation of additional asymmetry, which could also be\ndescribed as an enhancement in chirality amplitude. Our proposed concept of\nchirality amplitude and its ultrafast control may lead to a unique approach to\ncontrol chirality-induced emergent phenomena in ultrafast timescales.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-10T09:52:13Z"}
{"aid":"http://arxiv.org/abs/2504.07613v1","title":"Power spectrum of the CODEX clusters","summary":"Aims. We analyze the clustering of galaxy clusters in a large contiguous\nsample, the Constrain Dark Energy with X-ray (CODEX) sample. We construct a\nlikelihood for cosmological parameters by comparing the measured clustering\nsignal and a theoretical prediction, and use this to obtain parameter\nconstraints. Methods. We measured the three multipole moments (monopole,\nquadrupole, and hexadecapole, $\\ell = 0, 2, 4$) of the power spectrum of a\nsubset of the CODEX clusters. To fully model cluster clustering, we also\ndetermined the expected clustering bias of the sample using estimates for the\ncluster masses and a mass-to-bias model calibrated using N-body simulations. We\nestimated the covariance matrix of the measured power spectrum multipoles using\na set of simulated dark-matter halo catalogs. Combining all these ingredients,\nwe performed a Markov chain Monte Carlo sampling of cosmological parameters\n$\\Omega_m$ and $\\sigma_8$ to obtain their posterior. Results. We found the\nCODEX clustering signal to be consistent with an earlier X-ray selected cluster\nsample, the REFLEX II sample. We also found that the measured power spectrum\nmultipoles are compatible with the predicted, bias-scaled linear matter power\nspectrum when the cosmological parameters determined by the Planck satellite\nare assumed. Furthermore, we found the marginalized parameter constraints of\n$\\Omega_m = 0.24^{+0.06}_{-0.04}$ and $\\sigma_8 = 1.13^{+0.43}_{-0.24}$. The\nfull 2D posterior is consistent, for example, with the Planck cosmology within\nthe 68% confidence region.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-10T10:04:24Z"}
{"aid":"http://arxiv.org/abs/2504.07636v1","title":"Rational concordance of double twist knots","summary":"Double twist knots $K_{m, n}$ are known to be rationally slice if $mn = 0$,\n$n = -m\\pm 1$, or $n = -m$. In this paper, we prove the converse. It is done by\nshowing that infinitely many prime power-fold cyclic branched covers of the\nother cases do not bound a rational ball. Our rational ball obstruction is\nbased on Donaldson's diagonalization theorem.","main_category":"math.GT","categories":"math.GT","published":"2025-04-10T10:32:28Z"}
{"aid":"http://arxiv.org/abs/2504.07709v1","title":"Integrated Sensing and Communications for Pinching-Antenna Systems\n  (PASS)","summary":"An integrated sensing and communication (ISAC) design for pinching antenna\nsystems (PASS) is proposed, where the pinching antennas are deployed for\nestablishing reliable line-of-sight communication and sensing links. More\nparticularly, a separated ISAC design is proposed for the two-waveguide PASS,\nwhere one waveguide is used to emit the joint communication and sensing signals\nwhile the other waveguide is used to receive the reflected echo signals. Based\non this framework, a penalty-based alternating optimization algorithm is\nproposed to maximize the illumination power as well as ensure the communication\nquality-of-service requirement. Numerical results demonstrate that 1) the\nproposed PASS-ISAC scheme outperforms the other baseline schemes, and 2) the\nconsidered equal power allocation model achieves a performance comparable to\nthe optimal power allocation.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-10T12:58:46Z"}
{"aid":"http://arxiv.org/abs/2504.07741v1","title":"Harnessing Equivariance: Modeling Turbulence with Graph Neural Networks","summary":"This work proposes a novel methodology for turbulence modeling in Large Eddy\nSimulation (LES) based on Graph Neural Networks (GNNs), which embeds the\ndiscrete rotational, reflectional and translational symmetries of the\nNavier-Stokes equations into the model architecture. In addition, suitable\ninvariant input and output spaces are derived that allow the GNN models to be\nembedded seamlessly into the LES framework to obtain a symmetry-preserving\nsimulation setup. The suitability of the proposed approach is investigated for\ntwo canonical test cases: Homogeneous Isotropic Turbulence (HIT) and turbulent\nchannel flow. For both cases, GNN models are trained successfully in actual\nsimulations using Reinforcement Learning (RL) to ensure that the models are\nconsistent with the underlying LES formulation and discretization. It is\ndemonstrated for the HIT case that the resulting GNN-based LES scheme recovers\nrotational and reflectional equivariance up to machine precision in actual\nsimulations. At the same time, the stability and accuracy remain on par with\nnon-symmetry-preserving machine learning models that fail to obey these\nproperties. The same modeling strategy translates well to turbulent channel\nflow, where the GNN model successfully learns the more complex flow physics and\nis able to recover the turbulent statistics and Reynolds stresses. It is shown\nthat the GNN model learns a zonal modeling strategy with distinct behaviors in\nthe near-wall and outer regions. The proposed approach thus demonstrates the\npotential of GNNs for turbulence modeling, especially in the context of LES and\nRL.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cs.LG","published":"2025-04-10T13:37:54Z"}
{"aid":"http://arxiv.org/abs/2504.07757v1","title":"Search-contempt: a hybrid MCTS algorithm for training AlphaZero-like\n  engines with better computational efficiency","summary":"AlphaZero in 2017 was able to master chess and other games without human\nknowledge by playing millions of games against itself (self-play), with a\ncomputation budget running in the tens of millions of dollars. It used a\nvariant of the Monte Carlo Tree Search (MCTS) algorithm, known as PUCT. This\npaper introduces search-contempt, a novel hybrid variant of the MCTS algorithm\nthat fundamentally alters the distribution of positions generated in self-play,\npreferring more challenging positions. In addition, search-contempt has been\nshown to give a big boost in strength for engines in Odds Chess (where one side\nreceives an unfavorable position from the start). More significantly, it opens\nup the possibility of training a self-play based engine, in a much more\ncomputationally efficient manner with the number of training games running into\nhundreds of thousands, costing tens of thousands of dollars (instead of tens of\nmillions of training games costing millions of dollars required by AlphaZero).\nThis means that it may finally be possible to train such a program from zero on\na standard consumer GPU even with a very limited compute, cost, or time budget.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-10T13:56:31Z"}
{"aid":"http://arxiv.org/abs/2504.07758v1","title":"PIDSR:ComplementaryPolarizedImageDemosaicingandSuper-Resolution","summary":"Polarization cameras can capture multiple polarized images with different\npolarizer angles in a single shot, bringing convenience to polarization-based\ndownstream tasks. However, their direct outputs are color-polarization filter\narray (CPFA) raw images, requiring demosaicing to reconstruct full-resolution,\nfull-color polarized images; unfortunately, this necessary step introduces\nartifacts that make polarization-related parameters such as the degree of\npolarization (DoP) and angle of polarization (AoP) prone to error. Besides,\nlimited by the hardware design, the resolution of a polarization camera is\noften much lower than that of a conventional RGB camera. Existing polarized\nimage demosaicing (PID) methods are limited in that they cannot enhance\nresolution, while polarized image super-resolution (PISR) methods, though\ndesigned to obtain high-resolution (HR) polarized images from the demosaicing\nresults, tend to retain or even amplify errors in the DoP and AoP introduced by\ndemosaicing artifacts. In this paper, we propose PIDSR, a joint framework that\nperforms complementary Polarized Image Demosaicing and Super-Resolution,\nshowing the ability to robustly obtain high-quality HR polarized images with\nmore accurate DoP and AoP from a CPFA raw image in a direct manner. Experiments\nshow our PIDSR not only achieves state-of-the-art performance on both synthetic\nand real data, but also facilitates downstream tasks.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-10T13:56:33Z"}
{"aid":"http://arxiv.org/abs/2504.07773v1","title":"Monitored quantum transport: full counting statistics of a quantum Hall\n  interferometer","summary":"We generalize the Levitov-Lesovik formula for the probability distribution\nfunction of the electron charge transferred through a phase coherent conductor,\nto include projective measurements that monitor the chiral propagation in\nquantum Hall edge modes. When applied to an electronic Mach-Zehnder\ninterferometer, the monitoring reduces the visibility of the Aharonov-Bohm\nconductance oscillations while preserving the binomial form of the counting\nstatistics, thereby removing a fundamental shortcoming of the dephasing-probe\nmodel of decoherence.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-10T14:12:23Z"}
{"aid":"http://arxiv.org/abs/2504.07777v1","title":"Adaptive Detection of Fast Moving Celestial Objects Using a Mixture of\n  Experts and Physical-Inspired Neural Network","summary":"Fast moving celestial objects are characterized by velocities across the\ncelestial sphere that significantly differ from the motions of background\nstars. In observational images, these objects exhibit distinct shapes,\ncontrasting with the typical appearances of stars. Depending on the\nobservational method employed, these celestial entities may be designated as\nnear-Earth objects or asteroids. Historically, fast moving celestial objects\nhave been observed using ground-based telescopes, where the relative stability\nof stars and Earth facilitated effective image differencing techniques\nalongside traditional fast moving celestial object detection and classification\nalgorithms. However, the growing prevalence of space-based telescopes, along\nwith their diverse observational modes, produces images with different\nproperties, rendering conventional methods less effective. This paper presents\na novel algorithm for detecting fast moving celestial objects within star\nfields. Our approach enhances state-of-the-art fast moving celestial object\ndetection neural networks by transforming them into physical-inspired neural\nnetworks. These neural networks leverage the point spread function of the\ntelescope and the specific observational mode as prior information; they can\ndirectly identify moving fast moving celestial objects within star fields\nwithout requiring additional training, thereby addressing the limitations of\ntraditional techniques. Additionally, all neural networks are integrated using\nthe mixture of experts technique, forming a comprehensive fast moving celestial\nobject detection algorithm. We have evaluated our algorithm using simulated\nobservational data that mimics various observations carried out by space based\ntelescope scenarios and real observation images. Results demonstrate that our\nmethod effectively detects fast moving celestial objects across different\nobservational modes.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.EP,cs.CV,cs.LG,physics.optics","published":"2025-04-10T14:15:30Z"}
{"aid":"http://arxiv.org/abs/2504.07835v1","title":"Pychop: Emulating Low-Precision Arithmetic in Numerical Methods and\n  Neural Networks","summary":"Motivated by the growing demand for low-precision arithmetic in computational\nscience, we exploit lower-precision emulation in Python -- widely regarded as\nthe dominant programming language for numerical analysis and machine learning.\nLow-precision training has revolutionized deep learning by enabling more\nefficient computation and reduced memory and energy consumption while\nmaintaining model fidelity. To better enable numerical experimentation with and\nexploration of low precision computation, we developed the Pychop library,\nwhich supports customizable floating-point formats and a comprehensive set of\nrounding modes in Python, allowing users to benefit from fast, low-precision\nemulation in numerous applications. Pychop also introduces interfaces for both\nPyTorch and JAX, enabling efficient low-precision emulation on GPUs for neural\nnetwork training and inference with unparalleled flexibility.\n  In this paper, we offer a comprehensive exposition of the design,\nimplementation, validation, and practical application of Pychop, establishing\nit as a foundational tool for advancing efficient mixed-precision algorithms.\nFurthermore, we present empirical results on low-precision emulation for image\nclassification and object detection using published datasets, illustrating the\nsensitivity of the use of low precision and offering valuable insights into its\nimpact. Pychop enables in-depth investigations into the effects of numerical\nprecision, facilitates the development of novel hardware accelerators, and\nintegrates seamlessly into existing deep learning workflows. Software and\nexperimental code are publicly available at\nhttps://github.com/inEXASCALE/pychop.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.NA","published":"2025-04-10T15:12:29Z"}
{"aid":"http://arxiv.org/abs/2504.07841v1","title":"Anytime Single-Step MAPF Planning with Anytime PIBT","summary":"PIBT is a popular Multi-Agent Path Finding (MAPF) method at the core of many\nstate-of-the-art MAPF methods including LaCAM, CS-PIBT, and WPPL. The main\nutility of PIBT is that it is a very fast and effective single-step MAPF solver\nand can return a collision-free single-step solution for hundreds of agents in\nless than a millisecond. However, the main drawback of PIBT is that it is\nextremely greedy in respect to its priorities and thus leads to poor solution\nquality. Additionally, PIBT cannot use all the planning time that might be\navailable to it and returns the first solution it finds. We thus develop\nAnytime PIBT, which quickly finds a one-step solution identically to PIBT but\nthen continuously improves the solution in an anytime manner. We prove that\nAnytime PIBT converges to the optimal solution given sufficient time. We\nexperimentally validate that Anytime PIBT can rapidly improve single-step\nsolution quality within milliseconds and even find the optimal single-step\naction. However, we interestingly find that improving the single-step solution\nquality does not have a significant effect on full-horizon solution costs.","main_category":"cs.AI","categories":"cs.AI,cs.MA","published":"2025-04-10T15:21:23Z"}
{"aid":"http://arxiv.org/abs/2504.07857v1","title":"$B$ meson semileptonic decays from lattice QCD","summary":"$B$ processes are a rich source of potential anomalies that could lead to the\ndiscovery of BSM physics. The long-standing tension between the inclusive and\nthe exclusive determinations of the CKM matrix elements $|V_{xb}|$, or the\ncurrent tensions in the $R(D)$-$R(D^\\ast)$ plane are some examples of active\nareas of research where we might find signals of new physics. Heavy-to-heavy\n$B$ semileptonic decays, $B_{(s)}\\to D^{(\\ast)}_{(s)}\\ell\\nu$, and in\nparticular, decays with a vector product ($D^\\ast_{(s)}$) are especially\ninteresting from an experimental point of view, but experiment and theory must\nwalk together in order to reach conclusions in the intensity frontier. In this\nreview I talk about the current status of the lattice-QCD calculations of the\n$B\\to D^{\\ast}\\ell\\nu$ form factors at non-zero recoil, I discuss the\nimplications they have for the determination of $B$ anomalies, and finally I\ngive some hints of what we can expect from future calculations.","main_category":"hep-ph","categories":"hep-ph,hep-lat","published":"2025-04-10T15:32:23Z"}
{"aid":"http://arxiv.org/abs/2504.07870v1","title":"Open Datasets for Grid Modeling and Visualization: An Alberta Power\n  Network Case","summary":"In the power and energy industry, multiple entities in grid operational logs\nare frequently recorded and updated. Thanks to recent advances in IT facilities\nand smart metering services, a variety of datasets such as system load,\ngeneration mix, and grid connection are often publicly available. While these\nresources are valuable in evaluating power grid's operational conditions and\nsystem resilience, the lack of fine-grained, accurate locational information\nconstrain the usage of current data, which further hinders the development of\nsmart grid and renewables integration. For instance, electricity end users are\nnot aware of nodal generation mix or carbon emissions, while the general public\nhave limited understanding about the effect of demand response or renewables\nintegration if only the whole system's demands and generations are available.\nIn this work, we focus on recovering power grid topology and line flow\ndirections from open public dataset. Taking the Alberta grid as a working\nexample, we start from mapping multi-modal power system datasets to the grid\ntopology integrated with geographical information. By designing a novel\noptimization-based scheme to recover line flow directions, we are able to\nanalyze and visualize the interactions between generations and demand vectors\nin an efficient manner. Proposed research is fully open-sourced and highly\ngeneralizable, which can help model and visualize grid information, create\nsynthetic dataset, and facilitate analytics and decision-making framework for\nclean energy transition.","main_category":"cs.HC","categories":"cs.HC,cs.SY,eess.SP,eess.SY","published":"2025-04-10T15:45:07Z"}
{"aid":"http://arxiv.org/abs/2504.07898v1","title":"How do Large Language Models Understand Relevance? A Mechanistic\n  Interpretability Perspective","summary":"Recent studies have shown that large language models (LLMs) can assess\nrelevance and support information retrieval (IR) tasks such as document ranking\nand relevance judgment generation. However, the internal mechanisms by which\noff-the-shelf LLMs understand and operationalize relevance remain largely\nunexplored. In this paper, we systematically investigate how different LLM\nmodules contribute to relevance judgment through the lens of mechanistic\ninterpretability. Using activation patching techniques, we analyze the roles of\nvarious model components and identify a multi-stage, progressive process in\ngenerating either pointwise or pairwise relevance judgment. Specifically, LLMs\nfirst extract query and document information in the early layers, then process\nrelevance information according to instructions in the middle layers, and\nfinally utilize specific attention heads in the later layers to generate\nrelevance judgments in the required format. Our findings provide insights into\nthe mechanisms underlying relevance assessment in LLMs, offering valuable\nimplications for future research on leveraging LLMs for IR tasks.","main_category":"cs.IR","categories":"cs.IR,cs.CL,cs.LG","published":"2025-04-10T16:14:55Z"}
{"aid":"http://arxiv.org/abs/2504.07904v1","title":"The Efficacy of Semantics-Preserving Transformations in Self-Supervised\n  Learning for Medical Ultrasound","summary":"Data augmentation is a central component of joint embedding self-supervised\nlearning (SSL). Approaches that work for natural images may not always be\neffective in medical imaging tasks. This study systematically investigated the\nimpact of data augmentation and preprocessing strategies in SSL for lung\nultrasound. Three data augmentation pipelines were assessed: (1) a baseline\npipeline commonly used across imaging domains, (2) a novel semantic-preserving\npipeline designed for ultrasound, and (3) a distilled set of the most effective\ntransformations from both pipelines. Pretrained models were evaluated on\nmultiple classification tasks: B-line detection, pleural effusion detection,\nand COVID-19 classification. Experiments revealed that semantics-preserving\ndata augmentation resulted in the greatest performance for COVID-19\nclassification - a diagnostic task requiring global image context.\nCropping-based methods yielded the greatest performance on the B-line and\npleural effusion object classification tasks, which require strong local\npattern recognition. Lastly, semantics-preserving ultrasound image\npreprocessing resulted in increased downstream performance for multiple tasks.\nGuidance regarding data augmentation and preprocessing strategies was\nsynthesized for practitioners working with SSL in ultrasound.","main_category":"eess.IV","categories":"eess.IV,cs.CV,cs.LG","published":"2025-04-10T16:26:47Z"}
{"aid":"http://arxiv.org/abs/2504.07915v1","title":"Detecting changes in space-varying parameters of local Poisson point\n  processes","summary":"Recent advances in local models for point processes have highlighted the need\nfor flexible methodologies to account for the spatial heterogeneity of external\ncovariates influencing process intensity. In this work, we introduce\ntessellated spatial regression, a novel framework that extends segmented\nregression models to spatial point processes, with the aim of detecting abrupt\nchanges in the effect of external covariates onto the process intensity.\n  Our approach consists of two main steps. First, we apply a spatial\nsegmentation algorithm to geographically weighted regression estimates,\ngenerating different tessellations that partition the study area into regions\nwhere model parameters can be assumed constant. Next, we fit log-linear Poisson\nmodels in which covariates interact with the tessellations, enabling\nregion-specific parameter estimation and classical inferential procedures, such\nas hypothesis testing on regression coefficients.\n  Unlike geographically weighted regression, our approach allows for discrete\nchanges in regression coefficients, making it possible to capture abrupt\nspatial variations in the effect of real-valued spatial covariates.\nFurthermore, the method naturally addresses the problem of locating and\nquantifying the number of detected spatial changes.\n  We validate our methodology through simulation studies and applications to\ntwo examples where a model with region-wise parameters seems appropriate and to\nan environmental dataset of earthquake occurrences in Greece.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-10T17:23:32Z"}
{"aid":"http://arxiv.org/abs/2504.07934v1","title":"SoTA with Less: MCTS-Guided Sample Selection for Data-Efficient Visual\n  Reasoning Self-Improvement","summary":"In this paper, we present an effective method to enhance visual reasoning\nwith significantly fewer training samples, relying purely on self-improvement\nwith no knowledge distillation. Our key insight is that the difficulty of\ntraining data during reinforcement fine-tuning (RFT) is critical. Appropriately\nchallenging samples can substantially boost reasoning capabilities even when\nthe dataset is small. Despite being intuitive, the main challenge remains in\naccurately quantifying sample difficulty to enable effective data filtering. To\nthis end, we propose a novel way of repurposing Monte Carlo Tree Search (MCTS)\nto achieve that. Starting from our curated 70k open-source training samples, we\nintroduce an MCTS-based selection method that quantifies sample difficulty\nbased on the number of iterations required by the VLMs to solve each problem.\nThis explicit step-by-step reasoning in MCTS enforces the model to think longer\nand better identifies samples that are genuinely challenging. We filter and\nretain 11k samples to perform RFT on Qwen2.5-VL-7B-Instruct, resulting in our\nfinal model, ThinkLite-VL. Evaluation results on eight benchmarks show that\nThinkLite-VL improves the average performance of Qwen2.5-VL-7B-Instruct by 7%,\nusing only 11k training samples with no knowledge distillation. This\nsignificantly outperforms all existing 7B-level reasoning VLMs, and our fairly\ncomparable baselines that use classic selection methods such as accuracy-based\nfiltering. Notably, on MathVista, ThinkLite-VL-7B achieves the SoTA accuracy of\n75.1, surpassing Qwen2.5-VL-72B, GPT-4o, and O1. Our code, data, and model are\navailable at https://github.com/si0wang/ThinkLite-VL.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:49:05Z"}
{"aid":"http://arxiv.org/abs/2504.07946v1","title":"Characteristic function-based tests for spatial randomness","summary":"We introduce a new type of test for complete spatial randomness that applies\nto mapped point patterns in a rectangle or a cube of any dimension. This is the\nfirst test of its kind to be based on characteristic functions and utilizes a\nweighted L2-distance between the empirical and uniform characteristic\nfunctions. It is simple to calculate and does not require adjusting for edge\neffects. An efficient algorithm is developed to find the asymptotic null\ndistribution of the test statistic under the Cauchy weight function. In a\nsimulation, our test shows varying sensitivity to different levels of spatial\ninteraction depending on the scale parameter of the Cauchy weight function.\nTests with different parameter values can be combined to create a\nBonferroni-corrected omnibus test, which is almost always more powerful than\nthe popular L-test and the Clark-Evans test for detecting heterogeneous and\naggregated alternatives, although less powerful than the L-test for detecting\nregular alternatives. The simplicity of empirical characteristic function makes\nit straightforward to extend our test to non-rectangular or sparsely sampled\npoint patterns.","main_category":"stat.ME","categories":"stat.ME,stat.CO","published":"2025-04-10T17:54:11Z"}
{"aid":"http://arxiv.org/abs/2504.07961v1","title":"Geo4D: Leveraging Video Generators for Geometric 4D Scene Reconstruction","summary":"We introduce Geo4D, a method to repurpose video diffusion models for\nmonocular 3D reconstruction of dynamic scenes. By leveraging the strong dynamic\nprior captured by such video models, Geo4D can be trained using only synthetic\ndata while generalizing well to real data in a zero-shot manner. Geo4D predicts\nseveral complementary geometric modalities, namely point, depth, and ray maps.\nIt uses a new multi-modal alignment algorithm to align and fuse these\nmodalities, as well as multiple sliding windows, at inference time, thus\nobtaining robust and accurate 4D reconstruction of long videos. Extensive\nexperiments across multiple benchmarks show that Geo4D significantly surpasses\nstate-of-the-art video depth estimation methods, including recent methods such\nas MonST3R, which are also designed to handle dynamic scenes.","main_category":"cs.CV","categories":"cs.CV,I.4.5","published":"2025-04-10T17:59:55Z"}
{"aid":"http://arxiv.org/abs/2504.07965v1","title":"Cat, Rat, Meow: On the Alignment of Language Model and Human\n  Term-Similarity Judgments","summary":"Small and mid-sized generative language models have gained increasing\nattention. Their size and availability make them amenable to being analyzed at\na behavioral as well as a representational level, allowing investigations of\nhow these levels interact. We evaluate 32 publicly available language models\nfor their representational and behavioral alignment with human similarity\njudgments on a word triplet task. This provides a novel evaluation setting to\nprobe semantic associations in language beyond common pairwise comparisons. We\nfind that (1) even the representations of small language models can achieve\nhuman-level alignment, (2) instruction-tuned model variants can exhibit\nsubstantially increased agreement, (3) the pattern of alignment across layers\nis highly model dependent, and (4) alignment based on models' behavioral\nresponses is highly dependent on model size, matching their representational\nalignment only for the largest evaluated models.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-10T17:59:57Z"}
{"aid":"http://arxiv.org/abs/2504.09888v1","title":"Scalable fluxonium qubit architecture with tunable interactions between\n  non-computational levels","summary":"The fluxonium qubit has emerged as a promising candidate for superconducting\nquantum computing due to its long coherence times and high-fidelity gates.\nNonetheless, further scaling up and improving performance remain critical\nchallenges for establishing fluxoniums as a viable alternative to transmons. A\nkey obstacle lies in developing scalable coupling architectures. In this work,\nwe introduce a scalable fluxonium architecture that enables decoupling of qubit\nstates while maintaining tunable couplings between non-computational states.\nBeyond the well-studied ZZ crosstalk, we identify that an always-on interaction\ninvolving non-computational levels can significantly degrade the fidelities of\ninitialization, control, and readout in large systems, thereby impeding\nscalability. We demonstrate that this issue can be mitigated by implementing\ntunable couplings for fluxonium's plasmon transitions, meanwhile enabling fast,\nhigh-fidelity gates with passive ZZ suppression. Furthermore, since fluxonium\ntransitions span multiple frequency octaves, we emphasize the importance of\ncarefully designing coupling mechanisms and parameters to suppress residual\ninteractions.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T05:31:47Z"}
{"aid":"http://arxiv.org/abs/2504.09943v1","title":"The Tropical Atmosphere of Jupiter - Shallow Weather, Deep Plumes, and\n  Vortices","summary":"Towering storms, swirling clouds, and vortices are the cloud tops\nmanifestation of complex weather systems shaping the atmosphere of Jupiter. We\nuse observations from Juno's MicroWave Radiometer (MWR), the Very Large Array\n(VLA) and the Hubble Space Telescope (HST) to probe for the first time the\ndepth and impact of weather on Jupiter. We use ammonia, the main source of\nopacity at radio wavelengths on Jupiter, as the tracer for the weather by\nfitting ammonia anomalies to the MWR brightness temperature variations. We show\nthat the majority of the weather on Jupiter is confined to regions where the\nclouds are forming. Both the South Equatorial Belt and the Equatorial Zone have\nsurprisingly shallow weather systems (P < 2 bar), and even in the North\nEquatorial Belt most of the ammonia variations is above the water condensation\nlevel (P ~ 6 bar). This confirms that the water condensation layer plays a\ncrucial role in controlling the dynamics and the weather on Jupiter. However,\nthe shallow nature of the weather cannot explain the deep-seated depletion down\nto 30 bar that the Juno mission has revealed. We do find three features,\nhowever, that extend below the water condensation layer: a vortex in the\nnorthern hemisphere reaching down to 30 bar, an ammonia plume down to 20-30\nbars, and the signature of precipitation down to 20 bar. This work highlights\nthe interplay of large-scale processes (vortices, plumes) and small-scale\nprocesses (storms) are responsible for shaping the atmospheric makeup of\nJupiter.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-14T07:09:39Z"}
{"aid":"http://arxiv.org/abs/2504.09970v1","title":"IsoSEL: Isometric Structural Entropy Learning for Deep Graph Clustering\n  in Hyperbolic Space","summary":"Graph clustering is a longstanding topic in machine learning. In recent\nyears, deep learning methods have achieved encouraging results, but they still\nrequire predefined cluster numbers K, and typically struggle with imbalanced\ngraphs, especially in identifying minority clusters. The limitations motivate\nus to study a challenging yet practical problem: deep graph clustering without\nK considering the imbalance in reality. We approach this problem from a fresh\nperspective of information theory (i.e., structural information). In the\nliterature, structural information has rarely been touched in deep clustering,\nand the classic definition falls short in its discrete formulation, neglecting\nnode attributes and exhibiting prohibitive complexity. In this paper, we first\nestablish a new Differentiable Structural Information, generalizing the\ndiscrete formalism to continuous realm, so that the optimal partitioning tree,\nrevealing the cluster structure, can be created by the gradient\nbackpropagation. Theoretically, we demonstrate its capability in clustering\nwithout requiring K and identifying the minority clusters in imbalanced graphs,\nwhile reducing the time complexity to O(N) w.r.t. the number of nodes.\nSubsequently, we present a novel IsoSEL framework for deep graph clustering,\nwhere we design a hyperbolic neural network to learn the partitioning tree in\nthe Lorentz model of hyperbolic space, and further conduct Lorentz Tree\nContrastive Learning with isometric augmentation. As a result, the partitioning\ntree incorporates node attributes via mutual information maximization, while\nthe cluster assignment is refined by the proposed tree contrastive learning.\nExtensive experiments on five benchmark datasets show the IsoSEL outperforms 14\nrecent baselines by an average of +1.3% in NMI.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T08:21:41Z"}
{"aid":"http://arxiv.org/abs/2504.09977v1","title":"EthCluster: An Unsupervised Static Analysis Method for Ethereum Smart\n  Contract","summary":"Poorly designed smart contracts are particularly vulnerable, as they may\nallow attackers to exploit weaknesses and steal the virtual currency they\nmanage. In this study, we train a model using unsupervised learning to identify\nvulnerabilities in the Solidity source code of Ethereum smart contracts. To\naddress the challenges associated with real-world smart contracts, our training\ndata is derived from actual vulnerability samples obtained from datasets such\nas SmartBugs Curated and the SolidiFI Benchmark. These datasets enable us to\ndevelop a robust unsupervised static analysis method for detecting five\nspecific vulnerabilities: Reentrancy, Access Control, Timestamp Dependency,\ntx.origin, and Unchecked Low-Level Calls. We employ clustering algorithms to\nidentify outliers, which are subsequently classified as vulnerable smart\ncontracts.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-14T08:36:21Z"}
{"aid":"http://arxiv.org/abs/2504.09984v1","title":"On Precomputation and Caching in Information Retrieval Experiments with\n  Pipeline Architectures","summary":"Modern information retrieval systems often rely on multiple components\nexecuted in a pipeline. In a research setting, this can lead to substantial\nredundant computations (e.g., retrieving the same query multiple times for\nevaluating different downstream rerankers). To overcome this, researchers take\ncached \"result\" files as inputs, which represent the output of another\npipeline. However, these result files can be brittle and can cause a disconnect\nbetween the conceptual design of the pipeline and its logical implementation.\nTo overcome both the redundancy problem (when executing complete pipelines) and\nthe disconnect problem (when relying on intermediate result files), we describe\nour recent efforts to improve the caching capabilities in the open-source\nPyTerrier IR platform. We focus on two main directions: (1) automatic implicit\ncaching of common pipeline prefixes when comparing systems and (2) explicit\ncaching of operations through a new extension package, pyterrier-caching. These\napproaches allow for the best of both worlds: pipelines can be fully expressed\nend-to-end, while also avoiding redundant computations between pipelines.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-14T08:51:35Z"}
{"aid":"http://arxiv.org/abs/2504.09986v1","title":"Diversity Analysis for Indoor Terahertz Communication Systems under\n  Small-Scale Fading","summary":"Harnessing diversity is fundamental to wireless communication systems,\nparticularly in the terahertz (THz) band, where severe path loss and\nsmall-scale fading pose significant challenges to system reliability and\nperformance. In this paper, we present a comprehensive diversity analysis for\nindoor THz communication systems, accounting for the combined effects of path\nloss and small-scale fading, with the latter modeled as an $\\alpha-\\mu$\ndistribution to reflect THz indoor channel conditions. We derive closed-form\nexpressions for the bit error rate (BER) as a function of the reciprocal of the\nsignal-to-noise ratio (SNR) and propose an asymptotic expression. Furthermore,\nwe validate these expressions through extensive simulations, which show strong\nagreement with the theoretical analysis, confirming the accuracy and robustness\nof the proposed methods. Our results show that the diversity order in THz\nsystems is primarily determined by the combined effects of the number of\nindependent paths, the severity of fading, and the degree of channel frequency\nselectivity, providing clear insights into how diversity gains can be optimized\nin high-frequency wireless networks.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T08:51:52Z"}
{"aid":"http://arxiv.org/abs/2504.09987v1","title":"Gravitational metamaterials from optical properties of spacetime media","summary":"Gravitational optical properties are here investigated under the hypothesis\nof spherically-symmetric spacetimes behaving as media. To do so, we first\nconsider two different definitions of the refractive index, $n_O$, of a\nspacetime medium and show how to pass from one definition to another by means\nof a coordinate transformation. Accordingly, the corresponding physical role of\n$n_O$ is discussed by virtue of the Misner-Sharp mass and the redshift\ndefinition. Afterwards, we discuss the inclusion of the electromagnetic fields\nand the equivalence with nonlinear effects induced by geometry. Accordingly,\nthe infrared and ultraviolet gravity regimes are thus discussed, obtaining\nbounds from the Solar System, neutron stars and white dwarfs, respectively. To\ndo so, we also investigate the Snell's law and propose how to possibly\ndistinguish regular solutions from black holes. As a consequence of our recipe,\nwe speculate on the existence of \\emph{gravitational metamaterials}, whose\nrefractive index may be negative and explore the corresponding physical\nimplications, remarking that $n_O<0$ may lead to invisible optical properties,\nas light is bent in the opposite direction compared to what occurs in ordinary\ncases. Further, we conjecture that gravitational metamaterials exhibit a\nparticle-like behavior, contributing to dark matter and propose three toy\nmodels, highlighting possible advantages and limitations of their use. Finally,\nwe suggest that such particle-like configurations can be ``dressed\" by\ninteraction, giving rise to \\emph{geometric quasiparticles}. We thus construct\nmodifications of the quantum propagator as due to nonminimal couplings between\ncurvature and external matter-like fields, finding the corresponding effective\nmass through a boson mixing mechanism.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-14T08:51:56Z"}
{"aid":"http://arxiv.org/abs/2504.10000v1","title":"Do We Really Need Curated Malicious Data for Safety Alignment in\n  Multi-modal Large Language Models?","summary":"Multi-modal large language models (MLLMs) have made significant progress, yet\ntheir safety alignment remains limited. Typically, current open-source MLLMs\nrely on the alignment inherited from their language module to avoid harmful\ngenerations. However, the lack of safety measures specifically designed for\nmulti-modal inputs creates an alignment gap, leaving MLLMs vulnerable to\nvision-domain attacks such as typographic manipulation. Current methods utilize\na carefully designed safety dataset to enhance model defense capability, while\nthe specific knowledge or patterns acquired from the high-quality dataset\nremain unclear. Through comparison experiments, we find that the alignment gap\nprimarily arises from data distribution biases, while image content, response\nquality, or the contrastive behavior of the dataset makes little contribution\nto boosting multi-modal safety. To further investigate this and identify the\nkey factors in improving MLLM safety, we propose finetuning MLLMs on a small\nset of benign instruct-following data with responses replaced by simple, clear\nrejection sentences. Experiments show that, without the need for\nlabor-intensive collection of high-quality malicious data, model safety can\nstill be significantly improved, as long as a specific fraction of rejection\ndata exists in the finetuning set, indicating the security alignment is not\nlost but rather obscured during multi-modal pretraining or instruction\nfinetuning. Simply correcting the underlying data bias could narrow the safety\ngap in the vision domain.","main_category":"cs.CR","categories":"cs.CR,cs.AI,cs.CL,cs.CV,cs.LG","published":"2025-04-14T09:03:51Z"}
{"aid":"http://arxiv.org/abs/2504.10003v1","title":"NaviDiffusor: Cost-Guided Diffusion Model for Visual Navigation","summary":"Visual navigation, a fundamental challenge in mobile robotics, demands\nversatile policies to handle diverse environments. Classical methods leverage\ngeometric solutions to minimize specific costs, offering adaptability to new\nscenarios but are prone to system errors due to their multi-modular design and\nreliance on hand-crafted rules. Learning-based methods, while achieving high\nplanning success rates, face difficulties in generalizing to unseen\nenvironments beyond the training data and often require extensive training. To\naddress these limitations, we propose a hybrid approach that combines the\nstrengths of learning-based methods and classical approaches for RGB-only\nvisual navigation. Our method first trains a conditional diffusion model on\ndiverse path-RGB observation pairs. During inference, it integrates the\ngradients of differentiable scene-specific and task-level costs, guiding the\ndiffusion model to generate valid paths that meet the constraints. This\napproach alleviates the need for retraining, offering a plug-and-play solution.\nExtensive experiments in both indoor and outdoor settings, across simulated and\nreal-world scenarios, demonstrate zero-shot transfer capability of our\napproach, achieving higher success rates and fewer collisions compared to\nbaseline methods. Code will be released at\nhttps://github.com/SYSU-RoboticsLab/NaviD.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-14T09:06:02Z"}
{"aid":"http://arxiv.org/abs/2504.10012v1","title":"EBAD-Gaussian: Event-driven Bundle Adjusted Deblur Gaussian Splatting","summary":"While 3D Gaussian Splatting (3D-GS) achieves photorealistic novel view\nsynthesis, its performance degrades with motion blur. In scenarios with rapid\nmotion or low-light conditions, existing RGB-based deblurring methods struggle\nto model camera pose and radiance changes during exposure, reducing\nreconstruction accuracy. Event cameras, capturing continuous brightness changes\nduring exposure, can effectively assist in modeling motion blur and improving\nreconstruction quality. Therefore, we propose Event-driven Bundle Adjusted\nDeblur Gaussian Splatting (EBAD-Gaussian), which reconstructs sharp 3D\nGaussians from event streams and severely blurred images. This method jointly\nlearns the parameters of these Gaussians while recovering camera motion\ntrajectories during exposure time. Specifically, we first construct a blur loss\nfunction by synthesizing multiple latent sharp images during the exposure time,\nminimizing the difference between real and synthesized blurred images. Then we\nuse event stream to supervise the light intensity changes between latent sharp\nimages at any time within the exposure period, supplementing the light\nintensity dynamic changes lost in RGB images. Furthermore, we optimize the\nlatent sharp images at intermediate exposure times based on the event-based\ndouble integral (EDI) prior, applying consistency constraints to enhance the\ndetails and texture information of the reconstructed images. Extensive\nexperiments on synthetic and real-world datasets show that EBAD-Gaussian can\nachieve high-quality 3D scene reconstruction under the condition of blurred\nimages and event stream inputs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T09:17:00Z"}
{"aid":"http://arxiv.org/abs/2504.10014v1","title":"Air Quality Prediction with A Meteorology-Guided Modality-Decoupled\n  Spatio-Temporal Network","summary":"Air quality prediction plays a crucial role in public health and\nenvironmental protection. Accurate air quality prediction is a complex\nmultivariate spatiotemporal problem, that involves interactions across temporal\npatterns, pollutant correlations, spatial station dependencies, and\nparticularly meteorological influences that govern pollutant dispersion and\nchemical transformations. Existing works underestimate the critical role of\natmospheric conditions in air quality prediction and neglect comprehensive\nmeteorological data utilization, thereby impairing the modeling of dynamic\ninterdependencies between air quality and meteorological data. To overcome\nthis, we propose MDSTNet, an encoder-decoder framework that explicitly models\nair quality observations and atmospheric conditions as distinct modalities,\nintegrating multi-pressure-level meteorological data and weather forecasts to\ncapture atmosphere-pollution dependencies for prediction. Meantime, we\nconstruct ChinaAirNet, the first nationwide dataset combining air quality\nrecords with multi-pressure-level meteorological observations. Experimental\nresults on ChinaAirNet demonstrate MDSTNet's superiority, substantially\nreducing 48-hour prediction errors by 17.54\\% compared to the state-of-the-art\nmodel. The source code and dataset will be available on github.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV","published":"2025-04-14T09:18:11Z"}
{"aid":"http://arxiv.org/abs/2504.10015v1","title":"Many-Body Colloidal Dynamics under Stochastic Resetting: Competing\n  Effects of Particle Interactions on the Steady State Distribution","summary":"The random arrest of the diffusion of a single particle and its return to its\norigin has served as the paradigmatic example of a large variety of processes\nundergoing stochastic resetting. While the implications and applications of\nstochastic resetting for a single particle are well understood, less is known\nabout resetting of many interacting particles. In this study, we experimentally\nand numerically investigate a system of six colloidal particles undergoing two\ntypes of stochastic resetting protocols: global resetting, where all particles\nare returned to their origin simultaneously, and local resetting, where\nparticles are reset one at a time. Our particles interact mainly through\nhard-core repulsion and hydrodynamic flows. We find that the most substantial\neffect of interparticle interactions is observed for local resetting,\nspecifically when particles are physically dragged to the origin. In this case,\nhard-core repulsion broadens the steady-state distribution, while hydrodynamic\ninteractions significantly narrow the distribution. The combination results in\na steady-state distribution that is wider compared to that of a single particle\nsystem both for global and local resetting protocols.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech","published":"2025-04-14T09:18:37Z"}
{"aid":"http://arxiv.org/abs/2504.10016v1","title":"Quantifying Privacy Leakage in Split Inference via Fisher-Approximated\n  Shannon Information Analysis","summary":"Split inference (SI) partitions deep neural networks into distributed\nsub-models, enabling privacy-preserving collaborative learning. Nevertheless,\nit remains vulnerable to Data Reconstruction Attacks (DRAs), wherein\nadversaries exploit exposed smashed data to reconstruct raw inputs. Despite\nextensive research on adversarial attack-defense games, a shortfall remains in\nthe fundamental analysis of privacy risks. This paper establishes a theoretical\nframework for privacy leakage quantification using information theory, defining\nit as the adversary's certainty and deriving both average-case and worst-case\nerror bounds. We introduce Fisher-approximated Shannon information (FSInfo), a\nnovel privacy metric utilizing Fisher Information (FI) for operational privacy\nleakage computation. We empirically show that our privacy metric correlates\nwell with empirical attacks and investigate some of the factors that affect\nprivacy leakage, namely the data distribution, model size, and overfitting.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-14T09:19:06Z"}
{"aid":"http://arxiv.org/abs/2504.10094v1","title":"Local-in-time well-posedness for the regular solution to the 2D full\n  compressible Navier-Stokes equations with degenerate viscosities and heat\n  conductivity","summary":"This paper considers the two-dimensional Cauchy problem of the full\ncompressible Navier-Stokes equations with far-field vacuum in $\\mathbb{R}^2$,\nwhere the viscosity and heat-conductivity coefficients depend on the absolute\ntemperature $\\theta$ in the form of $\\theta^\\nu$ with $\\nu>0$. Due to the\nappearance of the vacuum, the momentum equation are both degenerate in the time\nevolution and spatial dissipation, which makes the study on the well-posedness\nchallenged. By establishing some new singular-weighted (negative powers of the\ndensity $\\rho$) estimates of the solution, we establish the local-in-time\nwell-posedness of the regular solution with far-field vacuum in terms of\n$\\rho$, the velocity $u$ and the entropy $S$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T10:58:53Z"}
{"aid":"http://arxiv.org/abs/2504.10110v1","title":"Eigengap Sparsity for Covariance Parsimony","summary":"Covariance estimation is a central problem in statistics. An important issue\nis that there are rarely enough samples $n$ to accurately estimate the $p (p+1)\n/ 2$ coefficients in dimension $p$. Parsimonious covariance models are\ntherefore preferred, but the discrete nature of model selection makes inference\ncomputationally challenging. In this paper, we propose a relaxation of\ncovariance parsimony termed \"eigengap sparsity\" and motivated by the good\naccuracy-parsimony tradeoff of eigenvalue-equalization in covariance matrices.\nThis new penalty can be included in a penalized-likelihood framework that we\npropose to solve with a projected gradient descent on a monotone cone. The\nalgorithm turns out to resemble an isotonic regression of mutually-attracted\nsample eigenvalues, drawing an interesting link between covariance parsimony\nand shrinkage.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-14T11:18:02Z"}
{"aid":"http://arxiv.org/abs/2504.10117v1","title":"AGO: Adaptive Grounding for Open World 3D Occupancy Prediction","summary":"Open-world 3D semantic occupancy prediction aims to generate a voxelized 3D\nrepresentation from sensor inputs while recognizing both known and unknown\nobjects. Transferring open-vocabulary knowledge from vision-language models\n(VLMs) offers a promising direction but remains challenging. However, methods\nbased on VLM-derived 2D pseudo-labels with traditional supervision are limited\nby a predefined label space and lack general prediction capabilities. Direct\nalignment with pretrained image embeddings, on the other hand, fails to achieve\nreliable performance due to often inconsistent image and text representations\nin VLMs. To address these challenges, we propose AGO, a novel 3D occupancy\nprediction framework with adaptive grounding to handle diverse open-world\nscenarios. AGO first encodes surrounding images and class prompts into 3D and\ntext embeddings, respectively, leveraging similarity-based grounding training\nwith 3D pseudo-labels. Additionally, a modality adapter maps 3D embeddings into\na space aligned with VLM-derived image embeddings, reducing modality gaps.\nExperiments on Occ3D-nuScenes show that AGO improves unknown object prediction\nin zero-shot and few-shot transfer while achieving state-of-the-art\nclosed-world self-supervised performance, surpassing prior methods by 4.09\nmIoU.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T11:26:20Z"}
{"aid":"http://arxiv.org/abs/2504.10178v1","title":"MSCoT: Structured Chain-of-Thought Generation for Multiple Programming\n  Languages","summary":"With the rapid development of code intelligence, the application of multiple\nprogramming languages is becoming increasingly widespread. However, most\nexisting code generation models mainly focus on a single or a few programming\nlanguages, resulting in unsatisfactory performance in a multilingual\nenvironment. Chain-of-Thought (CoT) reasoning can significantly improve the\nperformance of the model without the need for retraining or fine-tuning the\ncode generation model by reasonably decomposing complex code generation tasks\ninto multiple subtasks and gradually deriving solutions for each subtask.\nNevertheless, the existing CoT generation methods mainly concentrate on Python\ncode, and the performance on other programming languages remains unclear. To\nfill this gap, we first constructed a CoT generation dataset for 12 programming\nlanguages through multi-agent technology. On this basis, we proposed a CoT\ngeneration method MSCoT applicable to multiple programming languages. By\nintroducing CoT into the code generation large model, the performance of the\ncode generation large model in a multilingual environment can be improved.\nThrough large-scale empirical research, we compared the generalization\nabilities of MSCoT and the existing CoT generation methods on multiple\nprogramming languages and proved the effectiveness of MSCoT for multiple\nprogramming languages. In addition, we also designed a human study to prove the\nquality of the CoT generated by MSCoT. Finally, we opensourced the model and\ndataset of MSCoT to promote the research on CoT generation for multiple\nprogramming languages.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-14T12:30:47Z"}
{"aid":"http://arxiv.org/abs/2504.10189v1","title":"Topological exciton bands and many-body exciton phases in transition\n  metal dichalcogenide trilayer heterostructures","summary":"Twisted multilayer transition metal dichalcogenides (TMDs) are a promising\nplatform for realizing topological exciton phases. Here we propose that twisted\nTMD heterotrilayers WX$_2$/MX$_2$/WX$_2$ with layer symmetry represents a\nrealistic system for realizing topological exciton bands and interesting\nmany-body excitonic phases, simply by tuning the twist angle. These symmetric\nheterotrilayers form a type-II band alignment, where the electrons are confined\nin the middle layer and holes are distributed among the outer two layers, for\nthe lowest energy excitons. The outer two layers are then rotated at different\ncenters by opposite angles, forming a helical structure. Interlayer excitons\nwith opposite dipoles are hybridized by the coupling between outer two layers,\nresulting in topological moir\\'e exciton bands. Furthermore, by constructing a\nthree-orbital tight-binding model, we map the many-body phase diagram of\ninteracting dipolar and quadrupolar excitons at different twist angles and\nexciton densities and reveal the existence of sublattice-dependent staggered\nsuperfluid and Mott insulator phases. The recent experimental observation of\nquadrupolar excitons in symmetric heterotrilayers brings the intriguing phases\npredicted in this study within immediate experimental reach.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-14T12:46:52Z"}
{"aid":"http://arxiv.org/abs/2504.10204v1","title":"Cohomological obstructions to equivariant unirationality","summary":"We study cohomological obstructions to equivariant unirationality, with\nspecial regard to actions of finite groups on del Pezzo surfaces and Fano\nthreefolds.","main_category":"math.AG","categories":"math.AG","published":"2025-04-14T13:12:54Z"}
{"aid":"http://arxiv.org/abs/2504.10235v1","title":"Eccentric mergers of binary Proca stars","summary":"We present a numerical relativity study of eccentric mergers of equal-mass\nrotating $\\bar m=1$ Proca stars, focusing on their gravitational-wave (GW)\nemission. By systematically varying key binary parameters, such as the initial\norbital boost, which determines the orbital angular momentum, and the relative\nphase between the stars, we examine how the internal phase structure of the\nProca field influences the merger dynamics and the properties of the emitted\nGWs. Our simulations demonstrate that the relative phase has paramount impact\non the post-merger evolution, resulting in prompt black hole formation\naccompanied by a transient Proca remnant, the formation of a hypermassive $\\bar\nm=1$ Proca star or even the emergence of a dynamically-unstable spinning $\\bar\nm=2$ Proca star. Under certain conditions, the GW signal exhibits significant\nodd-modes (e.g., the $\\ell=m=3$ mode) that are absent in conventional black\nhole mergers, potentially serving as unique signatures of these exotic objects.\nOur findings offer new insights into the phenomenology of bosonic star mergers\nand the potential astrophysical role of ultralight bosonic fields.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-14T13:59:33Z"}
{"aid":"http://arxiv.org/abs/2504.10260v1","title":"Periodic approximation of topological Lyapunov exponents and the joint\n  spectral radius for cocycles of mapping classes of surfaces","summary":"We study cocycles taking values in the mapping class group of closed surfaces\nand investigate their leading topological Lyapunov exponent. Under a natural\nclosing property, we show that the top topological Lyapunov exponent can be\napproximated by periodic orbits. We also extend the notion of the joint\nspectral radius to this setting, interpreting it via the exponential growth of\ncurves under iterated mapping classes. Our approach connects ideas from ergodic\ntheory, Teichm\\\"uller geometry, and spectral theory, and suggests a broader\nframework for similar results.","main_category":"math.DS","categories":"math.DS,math.GR,math.GT","published":"2025-04-14T14:22:46Z"}
{"aid":"http://arxiv.org/abs/2504.10277v1","title":"RealHarm: A Collection of Real-World Language Model Application Failures","summary":"Language model deployments in consumer-facing applications introduce numerous\nrisks. While existing research on harms and hazards of such applications\nfollows top-down approaches derived from regulatory frameworks and theoretical\nanalyses, empirical evidence of real-world failure modes remains underexplored.\nIn this work, we introduce RealHarm, a dataset of annotated problematic\ninteractions with AI agents built from a systematic review of publicly reported\nincidents. Analyzing harms, causes, and hazards specifically from the\ndeployer's perspective, we find that reputational damage constitutes the\npredominant organizational harm, while misinformation emerges as the most\ncommon hazard category. We empirically evaluate state-of-the-art guardrails and\ncontent moderation systems to probe whether such systems would have prevented\nthe incidents, revealing a significant gap in the protection of AI\napplications.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.CL,cs.CR","published":"2025-04-14T14:44:41Z"}
{"aid":"http://arxiv.org/abs/2504.10279v1","title":"Elastic Planetoids","summary":"Modeling the internal structure of self-gravitating solid and liquid bodies\npresents a challenge, as existing approaches are often limited to either overly\nsimplistic constant-density approximations or more complex numerical equations\nof state. We present a detailed analysis of a tractable and physically\nmotivated model for perfectly elastic, spherically symmetric self-gravitating\nbodies in hydrostatic equilibrium. The model employs a logarithmic equation of\nstate (logotropic EOS) with a non-zero initial density and constant bulk\nmodulus. Importantly, scaling properties of the model allow all solutions to be\nderived from a single, universal solution of an ordinary differential equation,\nresembling the Lane-Emden and Chandrasekhar models. The model provides new\ninsights into stability issues and reveals oscillatory asymptotic behavior in\nthe mass-radius relation, including the existence of both a maximum mass and a\nmaximum radius. We derive useful, simple analytical approximations for key\nproperties, such as central overdensity, moment of inertia, binding energy, and\ngravitational potential, applicable to small, metallic bodies like asteroids\nand moons. These new approximations could aid future research, including space\nmining and the scientific characterization of small Solar System bodies.","main_category":"astro-ph.EP","categories":"astro-ph.EP,cond-mat.mtrl-sci,physics.space-ph","published":"2025-04-14T14:45:38Z"}
{"aid":"http://arxiv.org/abs/2504.10296v1","title":"Siamese Network with Dual Attention for EEG-Driven Social Learning:\n  Bridging the Human-Robot Gap in Long-Tail Autonomous Driving","summary":"Robots with wheeled, quadrupedal, or humanoid forms are increasingly\nintegrated into built environments. However, unlike human social learning, they\nlack a critical pathway for intrinsic cognitive development, namely, learning\nfrom human feedback during interaction. To understand human ubiquitous\nobservation, supervision, and shared control in dynamic and uncertain\nenvironments, this study presents a brain-computer interface (BCI) framework\nthat enables classification of Electroencephalogram (EEG) signals to detect\ncognitively demanding and safety-critical events. As a timely and motivating\nco-robotic engineering application, we simulate a human-in-the-loop scenario to\nflag risky events in semi-autonomous robotic driving-representative of\nlong-tail cases that pose persistent bottlenecks to the safety performance of\nsmart mobility systems and robotic vehicles. Drawing on recent advances in\nfew-shot learning, we propose a dual-attention Siamese convolutional network\npaired with Dynamic Time Warping Barycenter Averaging approach to generate\nrobust EEG-encoded signal representations. Inverse source localization reveals\nactivation in Broadman areas 4 and 9, indicating perception-action coupling\nduring task-relevant mental imagery. The model achieves 80% classification\naccuracy under data-scarce conditions and exhibits a nearly 100% increase in\nthe utility of salient features compared to state-of-the-art methods, as\nmeasured through integrated gradient attribution. Beyond performance, this\nstudy contributes to our understanding of the cognitive architecture required\nfor BCI agents-particularly the role of attention and memory mechanisms-in\ncategorizing diverse mental states and supporting both inter- and intra-subject\nadaptation. Overall, this research advances the development of cognitive\nrobotics and socially guided learning for service robots in complex built\nenvironments.","main_category":"cs.RO","categories":"cs.RO,cs.HC,cs.LG","published":"2025-04-14T15:06:17Z"}
{"aid":"http://arxiv.org/abs/2504.10325v1","title":"Cumulative-Time Signal Temporal Logic","summary":"Signal Temporal Logic (STL) is a widely adopted specification language in\ncyber-physical systems for expressing critical temporal requirements, such as\nsafety conditions and response time. However, STL's expressivity is not\nsufficient to capture the cumulative duration during which a property holds\nwithin an interval of time. To overcome this limitation, we introduce\nCumulative-Time Signal Temporal Logic (CT-STL) that operates over discrete-time\nsignals and extends STL with a new cumulative-time operator. This operator\ncompares the sum of all time steps for which its nested formula is true with a\nthreshold. We present both a qualitative and a quantitative (robustness)\nsemantics for CT-STL and prove both their soundness and completeness\nproperties. We provide an efficient online monitoring algorithm for both\nsemantics. Finally, we show the applicability of CT-STL in two case studies:\nspecifying and monitoring cumulative temporal requirements for a microgrid and\nan artificial pancreas.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-14T15:34:13Z"}
{"aid":"http://arxiv.org/abs/2504.10340v1","title":"Forecasting from Clinical Textual Time Series: Adaptations of the\n  Encoder and Decoder Language Model Families","summary":"Clinical case reports encode rich, temporal patient trajectories that are\noften underexploited by traditional machine learning methods relying on\nstructured data. In this work, we introduce the forecasting problem from\ntextual time series, where timestamped clinical findings--extracted via an\nLLM-assisted annotation pipeline--serve as the primary input for prediction. We\nsystematically evaluate a diverse suite of models, including fine-tuned\ndecoder-based large language models and encoder-based transformers, on tasks of\nevent occurrence prediction, temporal ordering, and survival analysis. Our\nexperiments reveal that encoder-based models consistently achieve higher F1\nscores and superior temporal concordance for short- and long-horizon event\nforecasting, while fine-tuned masking approaches enhance ranking performance.\nIn contrast, instruction-tuned decoder models demonstrate a relative advantage\nin survival analysis, especially in early prognosis settings. Our sensitivity\nanalyses further demonstrate the importance of time ordering, which requires\nclinical time series construction, as compared to text ordering, the format of\nthe text inputs that LLMs are classically trained on. This highlights the\nadditional benefit that can be ascertained from time-ordered corpora, with\nimplications for temporal tasks in the era of widespread LLM use.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T15:48:56Z"}
{"aid":"http://arxiv.org/abs/2504.10350v1","title":"Benchmarking 3D Human Pose Estimation Models Under Occlusions","summary":"This paper addresses critical challenges in 3D Human Pose Estimation (HPE) by\nanalyzing the robustness and sensitivity of existing models to occlusions,\ncamera position, and action variability. Using a novel synthetic dataset,\nBlendMimic3D, which includes diverse scenarios with multi-camera setups and\nseveral occlusion types, we conduct specific tests on several state-of-the-art\nmodels. Our study focuses on the discrepancy in keypoint formats between common\ndatasets such as Human3.6M, and 2D datasets such as COCO, commonly used for 2D\ndetection models and frequently input of 3D HPE models. Our work explores the\nimpact of occlusions on model performance and the generality of models trained\nexclusively under standard conditions. The findings suggest significant\nsensitivity to occlusions and camera settings, revealing a need for models that\nbetter adapt to real-world variability and occlusion scenarios. This research\ncontributed to ongoing efforts to improve the fidelity and applicability of 3D\nHPE systems in complex environments.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:00:25Z"}
{"aid":"http://arxiv.org/abs/2504.10370v1","title":"Further Comments on Yablo's Construction","summary":"We continue our analysis of Yablo's coding of the liar paradox by infinite\nacyclic graphs. The present notes are based on and continue the author's\nprevious results on the problem. In particular, our approach is often more\nsystematic than before.","main_category":"math.CO","categories":"math.CO,cs.LO","published":"2025-04-14T16:16:54Z"}
{"aid":"http://arxiv.org/abs/2504.10375v1","title":"PG-DPIR: An efficient plug-and-play method for high-count\n  Poisson-Gaussian inverse problems","summary":"Poisson-Gaussian noise describes the noise of various imaging systems thus\nthe need of efficient algorithms for Poisson-Gaussian image restoration. Deep\nlearning methods offer state-of-the-art performance but often require\nsensor-specific training when used in a supervised setting. A promising\nalternative is given by plug-and-play (PnP) methods, which consist in learning\nonly a regularization through a denoiser, allowing to restore images from\nseveral sources with the same network. This paper introduces PG-DPIR, an\nefficient PnP method for high-count Poisson-Gaussian inverse problems, adapted\nfrom DPIR. While DPIR is designed for white Gaussian noise, a naive adaptation\nto Poisson-Gaussian noise leads to prohibitively slow algorithms due to the\nabsence of a closed-form proximal operator. To address this, we adapt DPIR for\nthe specificities of Poisson-Gaussian noise and propose in particular an\nefficient initialization of the gradient descent required for the proximal step\nthat accelerates convergence by several orders of magnitude. Experiments are\nconducted on satellite image restoration and super-resolution problems.\nHigh-resolution realistic Pleiades images are simulated for the experiments,\nwhich demonstrate that PG-DPIR achieves state-of-the-art performance with\nimproved efficiency, which seems promising for on-ground satellite processing\nchains.","main_category":"cs.CV","categories":"cs.CV,cs.LG,eess.IV","published":"2025-04-14T16:23:15Z"}
{"aid":"http://arxiv.org/abs/2504.10378v1","title":"Cosmogenic Neutrino Point Source and KM3-230213A","summary":"Cosmogenic neutrinos (CNs) are produced by ultra-high energy cosmic rays\n(UHECRs) interacting with cosmic background radiation. We investigated the\nproperties of CN point/extended sources, i.e, the neutrino spectrum, and\nangular profile as functions of time, by assuming that UHECR sources are\ntransient events, such as gamma-ray bursts. The properties depend much on the\nintergalactic magnetic field (IGMF), but the angular extent is in general\nsub-degree, within which the CN flux can overshoot the diffuse CN flux in early\ntime. The nearby CN point sources could be detected for the low IGMF case by\nfuture neutrino telescopes. The recent KM3-230213A event is possible to account\nfor by a nearby transient CN source, rather than diffuse CN emission.\nObservations of CN point sources will provide a chance to search for UHECR\nsources.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-14T16:24:52Z"}
{"aid":"http://arxiv.org/abs/2504.10394v1","title":"Digits of pi: limits to the seeming randomness II","summary":"According to a popular belief, the decimal digits of mathematical constants\nsuch as {\\pi} behave like statistically independent random variables, each\ntaking the values 0, 1, 2, 3, 4, 5, 6, 7, 8, and 9 with equal probability of\n1/10. If this is the case, then, in particular, the decimal representations of\nthese constants should tend to satisfy the central limit theorem (CLT) and the\nlaw of the iterated logarithm (LIL). The paper presents the results of a direct\nstatistical analysis of the decimal representations of 12 mathematical\nconstants with respect to the central limit theorem (CLT) and the law of the\niterated logarithm (LIL). The first billion digits of each constant were\nanalyzed, with ten billion digits examined in the case of {\\pi}. Within these\nlimits, no evidence was found to suggest that the digits of these constants\nsatisfy CLT or LIL.","main_category":"math.NT","categories":"math.NT","published":"2025-04-14T16:42:47Z"}
{"aid":"http://arxiv.org/abs/2504.10395v1","title":"Better Coherence, Better Height: Fusing Physical Models and Deep\n  Learning for Forest Height Estimation from Interferometric SAR Data","summary":"Estimating forest height from Synthetic Aperture Radar (SAR) images often\nrelies on traditional physical models, which, while interpretable and\ndata-efficient, can struggle with generalization. In contrast, Deep Learning\n(DL) approaches lack physical insight. To address this, we propose CoHNet - an\nend-to-end framework that combines the best of both worlds: DL optimized with\nphysics-informed constraints. We leverage a pre-trained neural surrogate model\nto enforce physical plausibility through a unique training loss. Our\nexperiments show that this approach not only improves forest height estimation\naccuracy but also produces meaningful features that enhance the reliability of\npredictions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:44:08Z"}
{"aid":"http://arxiv.org/abs/2504.10404v1","title":"Framing Perception: Exploring Camera Induced Objectification in Cinema","summary":"This study investigates how cinematographic techniques influence viewer\nperception and contribute to the objectification of women, utilizing\neye-tracking data from 91 participants. They watched a sexualized music video\n(SV) known for objectifying portrayals and a non-sexualized music video (TV).\nUsing dynamic Areas of Interests (AOIs) (head, torso, and lower body), gaze\nmetrics such as fixation duration, visit count, and scan paths were recorded to\nassess visual attention patterns. Participants were grouped according to their\naverage fixations on sexualized AOIs. Statistical analyses revealed significant\ndifferences in gaze behavior between the videos and among the groups, with\nincreased attention to sexualized AOIs in SV. Additionally, data-driven group\ndifferences in fixations identified specific segments with heightened\nobjectification that are further analyzed using scan path visualization\ntechniques. These findings provide strong empirical evidence of camera-driven\ngaze objectification, demonstrating how cinematic framing implicitly shapes\nobjectifying gaze patterns, highlighting the critical need for mindful media\nrepresentation.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T16:53:16Z"}
{"aid":"http://arxiv.org/abs/2504.10429v1","title":"Out of the box approach to Black hole Information paradox","summary":"Suppose a black hole forms from a pure quantum state $\\ket{\\psi}$. The black\nhole information loss paradox arises from semiclassical arguments suggesting\nthat, even in a closed system, the process of black hole formation and\nevaporation evolves a pure state into a mixed state. Resolution to the paradox\ntypically demands violation of quantum mechanics or relativity in domains where\nthey should hold. Instead, I propose that in a complete theory of quantum\ngravity, any region $\\mathcal{U}$ that could collapse into a black hole should\nalready be described by a mixed state, thus bypassing the paradox entirely. To\nthat end, I present a model in which the universe is in a quantum\nerror-corrected state, such that any local black hole appears mixed and encodes\nno information locally.","main_category":"gr-qc","categories":"gr-qc,hep-th,quant-ph","published":"2025-04-14T17:19:57Z"}
{"aid":"http://arxiv.org/abs/2504.10432v1","title":"Invariance Matters: Empowering Social Recommendation via Graph Invariant\n  Learning","summary":"Graph-based social recommendation systems have shown significant promise in\nenhancing recommendation performance, particularly in addressing the issue of\ndata sparsity in user behaviors. Typically, these systems leverage Graph Neural\nNetworks (GNNs) to capture user preferences by incorporating high-order social\ninfluences from observed social networks. However, existing graph-based social\nrecommendations often overlook the fact that social networks are inherently\nnoisy, containing task-irrelevant relationships that can hinder accurate user\npreference learning. The removal of these redundant social relations is\ncrucial, yet it remains challenging due to the lack of ground truth. In this\npaper, we approach the social denoising problem from the perspective of graph\ninvariant learning and propose a novel method, Social Graph Invariant\nLearning(SGIL). Specifically,SGIL aims to uncover stable user preferences\nwithin the input social graph, thereby enhancing the robustness of graph-based\nsocial recommendation systems. To achieve this goal, SGIL first simulates\nmultiple noisy social environments through graph generators. It then seeks to\nlearn environment-invariant user preferences by minimizing invariant risk\nacross these environments. To further promote diversity in the generated social\nenvironments, we employ an adversarial training strategy to simulate more\npotential social noisy distributions. Extensive experimental results\ndemonstrate the effectiveness of the proposed SGIL. The code is available at\nhttps://github.com/yimutianyang/SIGIR2025-SGIL.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-14T17:20:48Z"}
{"aid":"http://arxiv.org/abs/2504.10433v1","title":"MonoDiff9D: Monocular Category-Level 9D Object Pose Estimation via\n  Diffusion Model","summary":"Object pose estimation is a core means for robots to understand and interact\nwith their environment. For this task, monocular category-level methods are\nattractive as they require only a single RGB camera. However, current methods\nrely on shape priors or CAD models of the intra-class known objects. We propose\na diffusion-based monocular category-level 9D object pose generation method,\nMonoDiff9D. Our motivation is to leverage the probabilistic nature of diffusion\nmodels to alleviate the need for shape priors, CAD models, or depth sensors for\nintra-class unknown object pose estimation. We first estimate coarse depth via\nDINOv2 from the monocular image in a zero-shot manner and convert it into a\npoint cloud. We then fuse the global features of the point cloud with the input\nimage and use the fused features along with the encoded time step to condition\nMonoDiff9D. Finally, we design a transformer-based denoiser to recover the\nobject pose from Gaussian noise. Extensive experiments on two popular benchmark\ndatasets show that MonoDiff9D achieves state-of-the-art monocular\ncategory-level 9D object pose estimation accuracy without the need for shape\npriors or CAD models at any stage. Our code will be made public at\nhttps://github.com/CNJianLiu/MonoDiff9D.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-14T17:21:10Z"}
{"aid":"http://arxiv.org/abs/2504.10457v1","title":"Holographic Entanglement Entropy in the FLRW Universe","summary":"We compute a holographic entanglement entropy via Ryu--Takayanagi\nprescription in the three-dimensional Friedmann--Lema\\^itre--Robertson--Walker\nuniverse. We consider two types of holographic scenarios analogous to the\nstatic patch holography and the half de Sitter holography, in which the\nholographic boundary is timelike and placed in the bulk. We find in general\nthat the strong subadditivity can be satisfied only in the former type and in\naddition the holographic boundary has to fit inside the apparent horizon. Also,\nfor the universe filled with an ideal fluid of constant equation of state\n$w<-1$, the condition is sharpened as that the holographic boundary has to fit\ninside the event horizon instead. These conditions provide a necessary\ncondition for the dual quantum field theory to be standard and compatible with\nthe strong subadditivity.","main_category":"hep-th","categories":"hep-th,astro-ph.CO,gr-qc","published":"2025-04-14T17:44:34Z"}
{"aid":"http://arxiv.org/abs/2504.10461v1","title":"Layered Multirate Control of Constrained Linear Systems","summary":"Layered control architectures have been a standard paradigm for efficiently\nmanaging complex constrained systems. A typical architecture consists of: i) a\nhigher layer, where a low-frequency planner controls a simple model of the\nsystem, and ii) a lower layer, where a high-frequency tracking controller\nguides a detailed model of the system toward the output of the higher-layer\nmodel. A fundamental problem in this layered architecture is the design of\nplanners and tracking controllers that guarantee both higher- and lower-layer\nsystem constraints are satisfied. Toward addressing this problem, we introduce\na principled approach for layered multirate control of linear systems subject\nto output and input constraints. Inspired by discrete-time simulation\nfunctions, we propose a streamlined control design that guarantees the\nlower-layer system tracks the output of the higher-layer system with computable\nprecision. Using this design, we derive conditions and present a method for\npropagating the constraints of the lower-layer system to the higher-layer\nsystem. The propagated constraints are integrated into the design of an\narbitrary planner that can handle higher-layer system constraints. Our\nframework ensures that the output constraints of the lower-layer system are\nsatisfied at all high-level time steps, while respecting its input constraints\nat all low-level time steps. We apply our approach in a scenario of motion\nplanning, highlighting its critical role in ensuring collision avoidance.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-14T17:48:34Z"}
{"aid":"http://arxiv.org/abs/2504.10847v1","title":"Cosmic-Ray Constraints on the Flux of Ultra-High-Energy Neutrino Event\n  KM3-230213A","summary":"The detection of a $\\simeq220$~PeV muon neutrino by the KM3NeT neutrino\ntelescope offers an unprecedented opportunity to probe the Universe at extreme\nenergies. We analyze the origin of this event under three scenarios, viz., a\ntransient point source, a diffuse astrophysical emission, and line-of-sight\ninteraction of ultrahigh-energy cosmic rays (UHECR; $E \\gtrsim 0.1$~EeV). Our\nanalysis includes the flux from both a KM3NeT-only fit and a joint fit,\nincorporating data from KM3NeT, IceCube, and Pierre Auger Observatory. If the\nneutrino event originates from transients, it requires a new population of\ntransient that is energetic, gamma-ray dark, and more abundant than known ones.\nIn the framework of diffuse astrophysical emission, we compare the required\nlocal UHECR energy injection rate at $\\gtrsim4$ EeV, assuming a proton primary,\nwith the rate derived from the flux measurements by Auger. This disfavors the\nKM3NeT-only fit at all redshifts, while the joint fit remains viable for\n$z\\gtrsim 1$, based on redshift evolution models of known source populations.\nFor cosmogenic origin from point sources, our results suggest that the\nluminosity obtained at redshifts $z \\lesssim 1$ from the joint fit is\ncompatible with the Eddington luminosity of supermassive black holes in active\ngalactic nuclei.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-15T04:07:13Z"}
{"aid":"http://arxiv.org/abs/2504.10854v1","title":"LVLM_CSP: Accelerating Large Vision Language Models via Clustering,\n  Scattering, and Pruning for Reasoning Segmentation","summary":"Large Vision Language Models (LVLMs) have been widely adopted to guide vision\nfoundation models in performing reasoning segmentation tasks, achieving\nimpressive performance. However, the substantial computational overhead\nassociated with LVLMs presents a new challenge. The primary source of this\ncomputational cost arises from processing hundreds of image tokens. Therefore,\nan effective strategy to mitigate such overhead is to reduce the number of\nimage tokens, a process known as image token pruning. Previous studies on image\ntoken pruning for LVLMs have primarily focused on high level visual\nunderstanding tasks, such as visual question answering and image captioning. In\ncontrast, guiding vision foundation models to generate accurate visual masks\nbased on textual queries demands precise semantic and spatial reasoning\ncapabilities. Consequently, pruning methods must carefully control individual\nimage tokens throughout the LVLM reasoning process. Our empirical analysis\nreveals that existing methods struggle to adequately balance reductions in\ncomputational overhead with the necessity to maintain high segmentation\naccuracy. In this work, we propose LVLM_CSP, a novel training free visual token\npruning method specifically designed for LVLM based reasoning segmentation\ntasks. LVLM_CSP consists of three stages: clustering, scattering, and pruning.\nInitially, the LVLM performs coarse-grained visual reasoning using a subset of\nselected image tokens. Next, fine grained reasoning is conducted, and finally,\nmost visual tokens are pruned in the last stage. Extensive experiments\ndemonstrate that LVLM_CSP achieves a 65% reduction in image token inference\nFLOPs with virtually no accuracy degradation, and a 70% reduction with only a\nminor 1% drop in accuracy on the 7B LVLM.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T04:27:15Z"}
{"aid":"http://arxiv.org/abs/2504.10859v1","title":"A Sublinear Algorithm for Path Feasibility Among Rectangular Obstacles","summary":"The problem of finding a path between two points while avoiding obstacles is\ncritical in robotic path planning. We focus on the feasibility problem:\ndetermining whether such a path exists. We model the robot as a query-specific\nrectangular object capable of moving parallel to its sides. The obstacles are\naxis-aligned, rectangular, and may overlap. Most previous works only consider\nnondisjoint rectangular objects and point-sized or statically sized robots. Our\napproach introduces a novel technique leveraging generalized Gabriel graphs and\nconstructs a data structure to facilitate online queries regarding path\nfeasibility with varying robot sizes in sublinear time. To efficiently handle\nfeasibility queries, we propose an online algorithm utilizing sweep line to\nconstruct a generalized Gabriel graph under the $L_\\infty$ norm, capturing key\ngap constraints between obstacles. We utilize a persistent disjoint-set union\ndata structure to efficiently determine feasibility queries in\n$\\mathcal{O}(\\log n)$ time and $\\mathcal{O}(n)$ total space.","main_category":"cs.CG","categories":"cs.CG,cs.RO","published":"2025-04-15T04:40:25Z"}
{"aid":"http://arxiv.org/abs/2504.10879v1","title":"Strain effect on optical properties and quantum weight of 2D magnetic\n  topological insulators MnBi$_2$X$_4$ (X = Te, Se, S)","summary":"Manipulating the optical and quantum properties of two-dimensional (2D)\nmaterials through strain engineering is not only fundamentally interesting but\nalso provides significant benefits across various applications. In this work,\nwe employ first-principles calculations to investigate the effects of strain on\nthe magnetic and optical properties of 2D topological insulators MnBi$_2$X$_4$\n(X = Te, Se, S). Our results indicate that biaxial strain enhances the Mn\nmagnetic moment, while uniaxial strains reduce it. Significantly, the\nstrain-dependent behavior, quantified through the quantum weight, can be\nleveraged to control the system's quantum geometry and topological features.\nParticularly, uniaxial strains reduce the quantum weight and introduce\nanisotropy, thus providing an additional degree of freedom to tailor device\nfunctionalities. Finally, by analyzing chemical bonds under various strain\ndirections, we elucidate how the intrinsic ductile or brittle fracture behavior\nof MnBi$_2$X$_4$ could impact fabrication protocols and structural stability.\nThese insights pave the way for strain-based approaches to optimize the quantum\nproperties in 2D magnetic topological insulators in practical device contexts.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,quant-ph","published":"2025-04-15T05:18:21Z"}
{"aid":"http://arxiv.org/abs/2504.10886v1","title":"Exploring Persona-dependent LLM Alignment for the Moral Machine\n  Experiment","summary":"Deploying large language models (LLMs) with agency in real-world applications\nraises critical questions about how these models will behave. In particular,\nhow will their decisions align with humans when faced with moral dilemmas? This\nstudy examines the alignment between LLM-driven decisions and human judgment in\nvarious contexts of the moral machine experiment, including personas reflecting\ndifferent sociodemographics. We find that the moral decisions of LLMs vary\nsubstantially by persona, showing greater shifts in moral decisions for\ncritical tasks than humans. Our data also indicate an interesting partisan\nsorting phenomenon, where political persona predominates the direction and\ndegree of LLM decisions. We discuss the ethical implications and risks\nassociated with deploying these models in applications that involve moral\ndecisions.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.CL","published":"2025-04-15T05:29:51Z"}
{"aid":"http://arxiv.org/abs/2504.10895v1","title":"Weighted norm inequalities of higher-order Riesz transforms associated\n  with Laguerre expansions","summary":"Let $\\nu=(\\nu_1,\\ldots,\\nu_n)\\in (-1,\\vc)^n$, $n\\ge 1$, and let\n$\\mathcal{L}_\\nu$ be a self-adjoint extension of the differential operator \\[\nL_\\nu := \\sum_{i=1}^n \\left[-\\frac{\\partial^2}{\\partial x_i^2} + x_i^2 +\n\\frac{1}{x_i^2}(\\nu_i^2 - \\frac{1}{4})\\right] \\] on\n$C_c^\\infty(\\mathbb{R}_+^n)$ as the natural domain. The $j$-th partial\nderivative associated with $L_{\\nu}$ is given by \\[ \\delta_{\\nu_j} =\n\\frac{\\partial}{\\partial x_j} + x_j-\\frac{1}{x_j}\\Big(\\nu_j + \\f{1}{2}\\Big), \\\n\\ \\ \\ j=1,\\ldots, n. \\] In this paper, we investigate the weighted estimates of\nthe higher-order Riesz transforms $\\delta_\\nu^k\\mathcal L^{-|k|/2}_\\nu, k\\in\n\\mathbb N^n$, where $\\delta_\\nu^k=\\delta_{\\nu_n}^{k_n}\\ldots\n\\delta_{\\nu_1}^{k_1}$. This completes the description of the boundedness of the\nhigher-order Riesz transforms with the full range $\\nu \\in (-1,\\vc)^n$.","main_category":"math.CA","categories":"math.CA","published":"2025-04-15T06:12:59Z"}
{"aid":"http://arxiv.org/abs/2504.10911v1","title":"Low-Overhead Channel Estimation Framework for Beyond Diagonal\n  Reconfigurable Intelligent Surface Assisted Multi-User MIMO Communication","summary":"Beyond diagonal reconfigurable intelligent surface (BD-RIS) refers to a\nfamily of RIS architectures characterized by scattering matrices not limited to\nbeing diagonal and enables higher wave manipulation flexibility and large\nperformance gains over conventional (diagonal) RIS. To achieve those promising\ngains, accurate channel state information (CSI) needs to be acquired in BD-RIS\nassisted communication systems. However, the number of coefficients in the\ncascaded channels to be estimated in BD-RIS assisted systems is significantly\nlarger than that in conventional RIS assisted systems, because the channels\nassociated with the off-diagonal elements of the scattering matrix have to be\nestimated as well. Surprisingly, for the first time in the literature, this\npaper rigorously shows that the uplink channel estimation overhead in BD-RIS\nassisted systems is actually of the same order as that in the conventional RIS\nassisted systems. This amazing result stems from a key observation: for each\nuser antenna, its cascaded channel matrix associated with one reference BD-RIS\nelement is a scaled version of that associated with any other BD-RIS element\ndue to the common RIS-base station (BS) channel. In other words, the number of\nindependent unknown variables is far less than it would seem at first glance.\nBuilding upon this property, this paper manages to characterize the minimum\noverhead to perfectly estimate all the channels in the ideal case without noise\nat the BS, and propose a twophase estimation framework for the practical case\nwith noise at the BS. Numerical results demonstrate outstanding channel\nestimation overhead reduction over existing schemes in BD-RIS assisted systems.","main_category":"eess.SP","categories":"eess.SP,cs.IT,math.IT","published":"2025-04-15T06:48:08Z"}
{"aid":"http://arxiv.org/abs/2504.10917v1","title":"Towards A Universal Graph Structural Encoder","summary":"Recent advancements in large-scale pre-training have shown the potential to\nlearn generalizable representations for downstream tasks. In the graph domain,\nhowever, capturing and transferring structural information across different\ngraph domains remains challenging, primarily due to the inherent differences in\ntopological patterns across various contexts. Additionally, most existing\nmodels struggle to capture the complexity of rich graph structures, leading to\ninadequate exploration of the embedding space. To address these challenges, we\npropose GFSE, a universal graph structural encoder designed to capture\ntransferable structural patterns across diverse domains such as molecular\ngraphs, social networks, and citation networks. GFSE is the first cross-domain\ngraph structural encoder pre-trained with multiple self-supervised learning\nobjectives. Built on a Graph Transformer, GFSE incorporates attention\nmechanisms informed by graph inductive bias, enabling it to encode intricate\nmulti-level and fine-grained topological features. The pre-trained GFSE\nproduces generic and theoretically expressive positional and structural\nencoding for graphs, which can be seamlessly integrated with various downstream\ngraph feature encoders, including graph neural networks for vectorized features\nand Large Language Models for text-attributed graphs. Comprehensive experiments\non synthetic and real-world datasets demonstrate GFSE's capability to\nsignificantly enhance the model's performance while requiring substantially\nless task-specific fine-tuning. Notably, GFSE achieves state-of-the-art\nperformance in 81.6% evaluated cases, spanning diverse graph models and\ndatasets, highlighting its potential as a powerful and versatile encoder for\ngraph-structured data.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-15T06:57:26Z"}
{"aid":"http://arxiv.org/abs/2504.10943v1","title":"Drivers and barriers of adopting shared micromobility: a latent class\n  clustering model on the attitudes towards shared micromobility as part of\n  public transport trips in the Netherlands","summary":"Shared micromobility (SMM) is often cited as a solution to the first/last\nmile problem of public transport (train) travel, yet when implemented, they\noften do not get adopted by a broader travelling public. A large part of\nbehavioural adoption is related to peoples' attitudes and perceptions. In this\npaper, we develop an adjusted behavioural framework, based on the UTAUT2\ntechnology acceptance framework. We carry out an exploratory factor analysis\n(EFA) to obtain attitudinal factors which we then use to perform a latent class\ncluster analysis (LCCA), with the goal of studying the potential adoption of\nSMM and to assess the various drivers and barriers as perceived by different\nuser groups. Our findings suggest there are six distinct user groups with\nvarying intention to use shared micromobility: Progressives, Conservatives,\nHesitant participants, Bold innovators, Anxious observers and Skilled sceptics.\nBold innovators and Progressives tend to be the most open to adopting SMM and\nare also able to do so. Hesitant participants would like to, but find it\ndifficult or dangerous to use, while Skilled sceptics are capable and\nconfident, but have limited intention of using it. Conservatives and Anxious\nobservers are most negative about SMM, finding it difficult to use and\ndangerous. In general, factors relating to technological savviness,\nease-of-use, physical safety and societal perception seem to be the biggest\nbarriers to wider adoption. Younger, highly educated males are the group most\nlikely and open to using shared micromobility, while older individuals with\nlower incomes and a lower level of education tend to be the least likely.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-15T07:46:19Z"}
{"aid":"http://arxiv.org/abs/2504.10949v1","title":"A Primer on Orthogonal Delay-Doppler Division Multiplexing (ODDM)","summary":"As a new type of multicarrier (MC) scheme built upon the recently discovered\ndelay-Doppler domain orthogonal pulse (DDOP), orthogonal delay-Doppler division\nmultiplexing (ODDM) aims to address the challenges of waveform design in linear\ntime-varying channels. In this paper, we explore the design principles of ODDM\nand clarify the key ideas underlying the DDOP. We then derive an alternative\nrepresentation of the DDOP and highlight the fundamental differences between\nODDM and conventional MC schemes. Finally, we discuss and compare two\nimplementation methods for ODDM.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-15T07:56:44Z"}
{"aid":"http://arxiv.org/abs/2504.10957v1","title":"When is Task Vector Provably Effective for Model Editing? A\n  Generalization Analysis of Nonlinear Transformers","summary":"Task arithmetic refers to editing the pre-trained model by adding a weighted\nsum of task vectors, each of which is the weight update from the pre-trained\nmodel to fine-tuned models for certain tasks. This approach recently gained\nattention as a computationally efficient inference method for model editing,\ne.g., multi-task learning, forgetting, and out-of-domain generalization\ncapabilities. However, the theoretical understanding of why task vectors can\nexecute various conceptual operations remains limited, due to the highly\nnon-convexity of training Transformer-based models. To the best of our\nknowledge, this paper provides the first theoretical characterization of the\ngeneralization guarantees of task vector methods on nonlinear Transformers. We\nconsider a conceptual learning setting, where each task is a binary\nclassification problem based on a discriminative pattern. We theoretically\nprove the effectiveness of task addition in simultaneously learning a set of\nirrelevant or aligned tasks, as well as the success of task negation in\nunlearning one task from irrelevant or contradictory tasks. Moreover, we prove\nthe proper selection of linear coefficients for task arithmetic to achieve\nguaranteed generalization to out-of-domain tasks. All of our theoretical\nresults hold for both dense-weight parameters and their low-rank\napproximations. Although established in a conceptual setting, our theoretical\nfindings were validated on a practical machine unlearning task using the large\nlanguage model Phi-1.5 (1.3B).","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-15T08:04:39Z"}
{"aid":"http://arxiv.org/abs/2504.10963v1","title":"Modeling liquid-mediated interactions for close-to-substrate magnetic\n  microparticle transport in dynamic magnetic field landscapes","summary":"Understanding the on-chip motion of magnetic particles in a microfluidic\nenvironment is key to realizing magnetic particle-based Lab-on-a-chip systems\nfor medical diagnostics. In this work, a simulation model is established to\nquantify the trajectory of a single particle moving close to a polymer surface\nin a quiescent liquid. The simulations include hydrodynamic, magnetostatic, and\nDerjaguin-Landau-Verwey-Overbeek (DLVO) interactions. They are applied to\nparticle motion driven by a dynamically changing magnetic field landscape\ncreated by engineered parallel-stripe magnetic domains superposed by a\nhomogeneous, time-varying external magnetic field. The simulation model is\nadapted to experiments in terms of fluid-particle interactions with the\nmagnetic field landscape approximated by analytic equations under the\nassumption of surface charges. Varying simulation parameters, we especially\nclarify the impact of liquid-mediated DLVO interactions, which are essential\nfor diagnostic applications, on the 3D trajectory of the particle. A comparison\nto experimental results validates our simulation approach.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,physics.app-ph,physics.comp-ph","published":"2025-04-15T08:14:16Z"}
{"aid":"http://arxiv.org/abs/2504.10980v1","title":"Planar Hall effect in ultrathin topological insulator films","summary":"The planar Hall effect (PHE), previously observed in Weyl and Dirac\nsemimetals due to the chiral anomaly, emerges with a different origin in\ntopological insulators (TIs), where in-plane magnetic fields induce resistivity\nanisotropy. In strictly two-dimensional TIs, PHE is generally suppressed due to\nthe inability of the out-of-plane Berry curvature to couple to the in-plane\nband velocity of the charge carriers. Here, we demonstrate that in ultrathin TI\nfilms, a quasi-two-dimensional system, intersurface tunneling coupling with\nin-plane magnetization induces electronic anisotropy, enabling a finite PHE. In\naddition, we reveal that strong in-plane magnetization can stabilize the\nthickness-dependent quantum anomalous Hall effect, typically associated with\nout-of-plane magnetization. These insights advance the understanding of\nmagnetic topological phases, paving the way for next-generation spintronic\ndevices and magnetic sensing technologies.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-15T08:45:02Z"}
{"aid":"http://arxiv.org/abs/2504.10990v1","title":"Mathematical Analysis of the PDE Model for the Consensus-based\n  Optimization","summary":"In this paper, we develop an analytical framework for the partial\ndifferential equation underlying the consensus-based optimization model. The\nmain challenge arises from the nonlinear, nonlocal nature of the consensus\npoint, coupled with a diffusion term that is both singular and degenerate. By\nemploying a regularization procedure in combination with a compactness\nargument, we establish the global existence and uniqueness of weak solutions in\n$L^\\infty(0,T;L^1\\cap L^\\infty(\\mathbb{R}^d))$. Furthermore, we show that the\nweak solutions exhibit improved $H^2$-regularity when the initial data is\nregular.","main_category":"math.AP","categories":"math.AP,math.OC","published":"2025-04-15T09:02:36Z"}
{"aid":"http://arxiv.org/abs/2504.10995v1","title":"TMCIR: Token Merge Benefits Composed Image Retrieval","summary":"Composed Image Retrieval (CIR) retrieves target images using a multi-modal\nquery that combines a reference image with text describing desired\nmodifications. The primary challenge is effectively fusing this visual and\ntextual information. Current cross-modal feature fusion approaches for CIR\nexhibit an inherent bias in intention interpretation. These methods tend to\ndisproportionately emphasize either the reference image features\n(visual-dominant fusion) or the textual modification intent (text-dominant\nfusion through image-to-text conversion). Such an imbalanced representation\noften fails to accurately capture and reflect the actual search intent of the\nuser in the retrieval results. To address this challenge, we propose TMCIR, a\nnovel framework that advances composed image retrieval through two key\ninnovations: 1) Intent-Aware Cross-Modal Alignment. We first fine-tune CLIP\nencoders contrastively using intent-reflecting pseudo-target images,\nsynthesized from reference images and textual descriptions via a diffusion\nmodel. This step enhances the encoder ability of text to capture nuanced\nintents in textual descriptions. 2) Adaptive Token Fusion. We further fine-tune\nall encoders contrastively by comparing adaptive token-fusion features with the\ntarget image. This mechanism dynamically balances visual and textual\nrepresentations within the contrastive learning pipeline, optimizing the\ncomposed feature for retrieval. Extensive experiments on Fashion-IQ and CIRR\ndatasets demonstrate that TMCIR significantly outperforms state-of-the-art\nmethods, particularly in capturing nuanced user intent.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T09:14:04Z"}
{"aid":"http://arxiv.org/abs/2504.11013v1","title":"Effective Theory of Ultrafast Skyrmion Nucleation","summary":"Laser-induced ultrafast skyrmion nucleation has been experimentally\ndemonstrated in several materials. So far, atomistic models have been used to\ncorroborate experimental results. However, such simulations do not provide a\nsimple intuitive understanding of the underlying physics. Here, we propose a\ncoarse-grained effective theory where skyrmions can be nucleated or annihilated\nby thermal activation over energy barriers. Evaluating these two processes\nduring a heat pulse shows good agreement with atomistic spin dynamics\nsimulations and experiments while drastically reducing computational\ncomplexity. Furthermore, the effective theory provides a direct guide for\nexperimentally optimizing the number of nucleated skyrmions. Interestingly, the\nmodel also predicts a novel pathway for ultrafast annihilation of skyrmions.\nOur results pave the way for a deeper understanding of ultrafast nanomagnetism\nand the role of non-equilibrium physics.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-15T09:34:15Z"}
{"aid":"http://arxiv.org/abs/2504.11052v1","title":"Weyl-mediated Ruderman-Kittel-Kasuya-Yosida interaction revisited:\n  imaginary-time formalism and finite temperature effects","summary":"Noncentrosymmetric magnetic Weyl semimetals provide a platform for\ninvestigating the interplay among magnetism, inversion symmetry breaking, and\ntopologically nontrivial Weyl fermions. The Weyl-mediated\nRuderman-Kittel-Kasuya-Yosida (RKKY) interaction may be related to the magnetic\norders observed in rare-earth magnetic Weyl semimetals. Previous studies of\nRKKY interaction between magnetic impurities in Weyl semimetals found\nHeisenberg, Ising-like, and Dzyaloshinskii-Moriya (DM) types of interactions.\nHowever, different range functions are obtained in the literature. In this\nwork, we calculate the Weyl-mediated RKKY interaction by using the\ndivergence-free imaginary-time formalism and obtain exact analytical results at\nfinite temperature. The discrepancies among zero temperature range functions in\nthe literature are resolved. At nonzero temperature, the interaction strength\ndecays exponentially in the long distance limit. But in the short distance\nlimit, the DM interaction shows a thermal enhancement, an effect persists up to\nhigher temperature for shorter distance. This provides a mechanism stabilizing\nthe helical order observed in rare-earth magnetic Weyl semimetals.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-15T10:39:59Z"}
{"aid":"http://arxiv.org/abs/2504.11060v1","title":"Goos-HÃ¤nchen Shift and Photonic Spin Hall Effect in Semi-Dirac\n  Material Heterostructures","summary":"We investigate the photonic spin Hall effect (PSHE) and the Goos-H\\\"anchen\nshift (GH shift) in semi-Dirac\n  materials. Through theoretical modeling, we demonstrate that the anisotropic\ndielectric function in semi-Dirac\n  materials play a critical role in determining the magnitude and polarity of\nthese optical displacements. Further more, by utilizing the unidirectional\ndrift of massless Dirac electrons in Semi-Dirac materials, we systematically\n  reveal how the drift velocity and direction modulate the behavior of optical\ndisplacements. The results indicate\n  that semi-Dirac materials provide a versatile platform for controlling\nspin-dependent photonic phenomena with\n  their material anisotropy and carrier transport. This work opens a new avenue\nfor designing advanced photonic\n  devices with tunable optical responses, particularly with significant\napplication potential in quantum information\n  processing and topological photonics.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-15T10:48:19Z"}
{"aid":"http://arxiv.org/abs/2504.11061v1","title":"Synthesis and characterization of gold-coated nanodiamonds through green\n  chemistry as potential radiosensitizers for proton therapy","summary":"In this work the synthesis and characterization of novel gold-nanodiamond\nnanoparticles was performed. The synthesis was based on the reduction of gold\nonto the different types of nanodiamond (annealed or annealed and oxidized, 50\nor 230 nm) using root extracts of Nympheaea alba as a reducing agent. These\ngold-coated nanodiamonds were characterized by UV-Vis, PXRD, DLS,\nzeta-potential, PIXE, Raman, SEM, and TEM, assessing particle size, stability,\nand gold coating effectiveness. Cellular studies in the A549 and Panc1 cancer\ncell lines assessed uptake, cytotoxicity, and colony formation to evaluate\nNDAu's biological activity. NDAu demonstrated strong cellular uptake and\ncytotoxic effects in A549 and Panc1 cell lines, reducing cell survival in\nclonogenic assay. Futher research in the capabilites of these nanoparticles for\nproton therapy will be performed.","main_category":"hep-ex","categories":"hep-ex,cond-mat.mtrl-sci","published":"2025-04-15T10:49:51Z"}
{"aid":"http://arxiv.org/abs/2504.11092v1","title":"Vivid4D: Improving 4D Reconstruction from Monocular Video by Video\n  Inpainting","summary":"Reconstructing 4D dynamic scenes from casually captured monocular videos is\nvaluable but highly challenging, as each timestamp is observed from a single\nviewpoint. We introduce Vivid4D, a novel approach that enhances 4D monocular\nvideo synthesis by augmenting observation views - synthesizing multi-view\nvideos from a monocular input. Unlike existing methods that either solely\nleverage geometric priors for supervision or use generative priors while\noverlooking geometry, we integrate both. This reformulates view augmentation as\na video inpainting task, where observed views are warped into new viewpoints\nbased on monocular depth priors. To achieve this, we train a video inpainting\nmodel on unposed web videos with synthetically generated masks that mimic\nwarping occlusions, ensuring spatially and temporally consistent completion of\nmissing regions. To further mitigate inaccuracies in monocular depth priors, we\nintroduce an iterative view augmentation strategy and a robust reconstruction\nloss. Experiments demonstrate that our method effectively improves monocular 4D\nscene reconstruction and completion.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T11:38:14Z"}
{"aid":"http://arxiv.org/abs/2504.11095v1","title":"Magnetotransport and activation energy of the surface states in Cd3As2\n  thin films","summary":"Recent experiments performed the magnetotransport measurements in\n(001)-oriented Cd$_3$As$_2$ thin films and attributed the magnetotransport\nproperties to the surface states. In this paper, by using an effective model to\ndescribe the surface states, we analyze the Landau bands and then calculate the\nmagnetoconductivities and magnetoresistivities. From these results, the\nfeatures of two-dimensional quantum Hall effect of the surface states can be\ncaptured. More importantly, we reveal that the activation energy is determined\nby the Hall plateau width, which can explain the experimental observations that\nthe activation energies at odd plateaus are larger than those at even plateaus.\nWe also analyze the roles played by the structural inversion symmetry breaking\nand impurity scatterings in the magnetotransport, and suggest that their\ncombined effects would lead to the absence of some Hall plateaus.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-15T11:40:31Z"}
{"aid":"http://arxiv.org/abs/2504.11111v1","title":"S$^2$Teacher: Step-by-step Teacher for Sparsely Annotated Oriented\n  Object Detection","summary":"Although fully-supervised oriented object detection has made significant\nprogress in multimodal remote sensing image understanding, it comes at the cost\nof labor-intensive annotation. Recent studies have explored weakly and\nsemi-supervised learning to alleviate this burden. However, these methods\noverlook the difficulties posed by dense annotations in complex remote sensing\nscenes. In this paper, we introduce a novel setting called sparsely annotated\noriented object detection (SAOOD), which only labels partial instances, and\npropose a solution to address its challenges. Specifically, we focus on two key\nissues in the setting: (1) sparse labeling leading to overfitting on limited\nforeground representations, and (2) unlabeled objects (false negatives)\nconfusing feature learning. To this end, we propose the S$^2$Teacher, a novel\nmethod that progressively mines pseudo-labels for unlabeled objects, from easy\nto hard, to enhance foreground representations. Additionally, it reweights the\nloss of unlabeled objects to mitigate their impact during training. Extensive\nexperiments demonstrate that S$^2$Teacher not only significantly improves\ndetector performance across different sparse annotation levels but also\nachieves near-fully-supervised performance on the DOTA dataset with only 10%\nannotation instances, effectively balancing detection accuracy with annotation\nefficiency. The code will be public.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T11:57:00Z"}
{"aid":"http://arxiv.org/abs/2504.11118v1","title":"Revealing Covert Attention by Analyzing Human and Reinforcement Learning\n  Agent Gameplay","summary":"This study introduces a novel method for revealing human covert attention\npatterns using gameplay data alone, utilizing offline attention techniques from\nreinforcement learning (RL). We propose the contextualized, task-relevant (CTR)\nattention network, which generates attention maps from both human and RL agent\ngameplay in Atari environments. These maps are sparse yet retain the necessary\ninformation for the current player's decision making. We compare the\nCTR-derived attention maps with a temporally integrated overt attention (TIOA)\nmodel based on eye-tracking data, serving as a point of comparison and\ndiscussion. Visual inspection reveals distinct attention patterns: human CTR\nmaps focus on the player and rather nearby opponents, occasionally shifting\nbetween stronger focus and broader views - sometimes even attending to empty\nspace ahead. In contrast, agent maps maintain a consistent broad focus on most\nobjects, including distant ones and the player. Quantitative analysis further\ndemonstrates that human CTR maps align more closely with TIOA than agent maps\ndo. Our findings indicate that the CTR attention network can effectively reveal\nhuman covert attention patterns from gameplay alone, without the need for\nadditional data like brain activity recordings. This work contributes to\nunderstanding human-agent attention differences and enables the development of\nRL agents augmented with human covert attention.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-15T12:07:14Z"}
{"aid":"http://arxiv.org/abs/2504.11135v1","title":"The baryonic Tully-Fisher relation and Fundamental Plane in the light of\n  $f(R)$ gravity","summary":"Here we use the samples of spiral and elliptical galaxies, in order to\ninvestigate theoretically some of their properties and to test the empirical\nrelations, in the light of modified gravities. We show that the baryonic\nTully-Fisher relation can be described in the light of $f(R)$ gravity, without\nintroducing the dark matter. Also, it is possible to explain the features of\nfundamental plane of elliptical galaxies without the dark matter hypothesis.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-15T12:38:55Z"}
{"aid":"http://arxiv.org/abs/2504.11156v1","title":"A preliminary cosmological analysis of stellar population synthesis of\n  galaxies released by LAMOST LRS DR11","summary":"The evolution of the universe together with the galaxies is one of the\nfundamental issues that we humans are most interested in. Both the observations\nof tidal streams from SDSS and the theory of $\\Lambda$CDM support the\nhierarchical merging theory. The study of high redshift celestial bodies\ncontributes to a more in-depth study of cosmology. The LAMOST low resolution\nsearch catalog DR11 v1.0 has released 11,939,296 spectra, including 11,581,542\nstars, 275,302 galaxies, and 82,452 quasars, and so on. The data of 28,780\nstellar population synthesis of galaxies and some high redshift quasars are\nused to do a preliminary statistical research. We selected the data with small\nerrors for analysis and obtained some basic statistical conclusions. Older\ngalaxies have relatively larger stellar velocity dispersions. The larger the\nmetallicity, the greater the stellar velocity dispersion. These statistical\nresults are reasonable and consistent with previous work. Because the stellar\nvelocity dispersion is driven by the total mass of a galaxy at the first order\nand more massive galaxies have older ages and greater metallicities. The\nspectra of high redshift quasars show clear Gunn-Peterson trough and\nLyman-$\\alpha$ forest. The identified emission lines and high redshift\ncelestial spectra released by LAMOST can be used for cosmological research.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-15T13:01:48Z"}
{"aid":"http://arxiv.org/abs/2504.11162v1","title":"Scalable Transceiver Design for Multi-User Communication in FDD Massive\n  MIMO Systems via Deep Learning","summary":"This paper addresses the joint transceiver design, including pilot\ntransmission, channel feature extraction and feedback, as well as precoding,\nfor low-overhead downlink massive multiple-input multiple-output (MIMO)\ncommunication in frequency-division duplex (FDD) systems. Although deep\nlearning (DL) has shown great potential in tackling this problem, existing\nmethods often suffer from poor scalability in practical systems, as the\nsolution obtained in the training phase merely works for a fixed feedback\ncapacity and a fixed number of users in the deployment phase. To address this\nlimitation, we propose a novel DL-based framework comprised of choreographed\nneural networks, which can utilize one training phase to generate all the\ntransceiver solutions used in the deployment phase with varying sizes of\nfeedback codebooks and numbers of users. The proposed framework includes a\nresidual vector-quantized variational autoencoder (RVQ-VAE) for efficient\nchannel feedback and an edge graph attention network (EGAT) for robust\nmultiuser precoding. It can adapt to different feedback capacities by flexibly\nadjusting the RVQ codebook sizes using the hierarchical codebook structure, and\nscale with the number of users through a feedback module sharing scheme and the\ninherent scalability of EGAT. Moreover, a progressive training strategy is\nproposed to further enhance data transmission performance and generalization\ncapability. Numerical results on a real-world dataset demonstrate the superior\nscalability and performance of our approach over existing methods.","main_category":"eess.SP","categories":"eess.SP,cs.IT,math.IT","published":"2025-04-15T13:11:26Z"}
{"aid":"http://arxiv.org/abs/2504.11195v1","title":"R-TPT: Improving Adversarial Robustness of Vision-Language Models\n  through Test-Time Prompt Tuning","summary":"Vision-language models (VLMs), such as CLIP, have gained significant\npopularity as foundation models, with numerous fine-tuning methods developed to\nenhance performance on downstream tasks. However, due to their inherent\nvulnerability and the common practice of selecting from a limited set of\nopen-source models, VLMs suffer from a higher risk of adversarial attacks than\ntraditional vision models. Existing defense techniques typically rely on\nadversarial fine-tuning during training, which requires labeled data and lacks\nof flexibility for downstream tasks. To address these limitations, we propose\nrobust test-time prompt tuning (R-TPT), which mitigates the impact of\nadversarial attacks during the inference stage. We first reformulate the\nclassic marginal entropy objective by eliminating the term that introduces\nconflicts under adversarial conditions, retaining only the pointwise entropy\nminimization. Furthermore, we introduce a plug-and-play reliability-based\nweighted ensembling strategy, which aggregates useful information from reliable\naugmented views to strengthen the defense. R-TPT enhances defense against\nadversarial attacks without requiring labeled training data while offering high\nflexibility for inference tasks. Extensive experiments on widely used\nbenchmarks with various attacks demonstrate the effectiveness of R-TPT. The\ncode is available in https://github.com/TomSheng21/R-TPT.","main_category":"cs.LG","categories":"cs.LG,cs.CR,cs.CV","published":"2025-04-15T13:49:31Z"}
{"aid":"http://arxiv.org/abs/2504.11212v1","title":"SDFs from Unoriented Point Clouds using Neural Variational Heat\n  Distances","summary":"We propose a novel variational approach for computing neural Signed Distance\nFields (SDF) from unoriented point clouds. To this end, we replace the commonly\nused eikonal equation with the heat method, carrying over to the neural domain\nwhat has long been standard practice for computing distances on discrete\nsurfaces. This yields two convex optimization problems for whose solution we\nemploy neural networks: We first compute a neural approximation of the\ngradients of the unsigned distance field through a small time step of heat flow\nwith weighted point cloud densities as initial data. Then we use it to compute\na neural approximation of the SDF. We prove that the underlying variational\nproblems are well-posed. Through numerical experiments, we demonstrate that our\nmethod provides state-of-the-art surface reconstruction and consistent SDF\ngradients. Furthermore, we show in a proof-of-concept that it is accurate\nenough for solving a PDE on the zero-level set.","main_category":"math.NA","categories":"math.NA,cs.LG,cs.NA","published":"2025-04-15T14:13:54Z"}
{"aid":"http://arxiv.org/abs/2504.11226v1","title":"Ab initio Maxwell-Bloch Approach for X-Ray Excitations in\n  Two-Dimensional Materials","summary":"The combination of Maxwell and X-ray Bloch equations forms an appropriate\nframework to describe ultrafast time-resolved X-ray experiments on attosecond\ntime scale in crystalline solids. However, broadband experiments such as X-ray\nabsorption near edge spectroscopy or resonant inelastic X-ray scattering\nrequire a detailed knowledge of the electronic structure and transition matrix\nelements. Here, we show how to fill this gap by combining the Maxwell-X-ray\nBloch formalism with first-principles calculations treating explicitly the core\nstates. The resulting X-ray absorption spectrum recovers key spectral\nsignatures which were missing in our previous work relying on a semi-empirical\ntight-binding approach.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-15T14:28:30Z"}
{"aid":"http://arxiv.org/abs/2504.11235v1","title":"Guided Wave-Based Structural Awareness Under Varying Operating States\n  via Manifold Representations","summary":"Guided wave-based structural health monitoring (SHM) remains a powerful\nstrategy for identifying early-stage defects and safeguarding vital aerospace\nstructures. Yet, its practical use is often hindered by the enormous,\nhigh-dimensional data streams produced by sensor arrays operating at megahertz\nsampling rates, coupled with the added complexity of shifts in environmental\nand operational conditions (EOCs). Studies have explored various\ndata-compression approaches that retain critical diagnostic details in a\nlower-dimensional latent space. While conventional techniques can streamline\ndimensionality to some extent, they do not always capture the nonlinear\ninteractions typical of guided waves. Manifold learning, as illustrated by\nDiffusion Maps, tackles these nonlinearities by deriving low-dimensional\nembeddings directly from wave signals, minimizing the need for manual feature\nextraction. In parallel, developments in deep learning -- particularly\nautoencoders -- provide an encoder-decoder model for both data compression and\nreconstruction. Convolutional autoencoders (CAEs) and variational autoencoders\n(VAEs) have been particularly effective for guided wave applications. However,\ncurrent methods can still struggle to maintain accurate state estimation under\nchanging EOCs, and they are often limited to a single task. In response, the\nproposed framework adopts a two-fold strategy: it compresses high-dimensional\nsignals into lower-dimensional representations and then leverages those\nrepresentations to both estimate structural states and reconstruct the original\ndata, even as conditions vary. Applied to two real-world SHM use-cases, this\nintegrated method has proven its ability to preserve and retrieve key damage\nsignatures under noise, shifting operational parameters, and other complicating\nfactors.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-15T14:38:30Z"}
{"aid":"http://arxiv.org/abs/2504.11249v1","title":"Cryo-em images are intrinsically low dimensional","summary":"Simulation-based inference provides a powerful framework for cryo-electron\nmicroscopy, employing neural networks in methods like CryoSBI to infer\nbiomolecular conformations via learned latent representations. This latent\nspace represents a rich opportunity, encoding valuable information about the\nphysical system and the inference process. Harnessing this potential hinges on\nunderstanding the underlying geometric structure of these representations. We\ninvestigate this structure by applying manifold learning techniques to CryoSBI\nrepresentations of hemagglutinin (simulated and experimental). We reveal that\nthese high-dimensional data inherently populate low-dimensional, smooth\nmanifolds, with simulated data effectively covering the experimental\ncounterpart. By characterizing the manifold's geometry using Diffusion Maps and\nidentifying its principal axes of variation via coordinate interpretation\nmethods, we establish a direct link between the latent structure and key\nphysical parameters. Discovering this intrinsic low-dimensionality and\ninterpretable geometric organization not only validates the CryoSBI approach\nbut enables us to learn more from the data structure and provides opportunities\nfor improving future inference strategies by exploiting this revealed manifold\ngeometry.","main_category":"q-bio.QM","categories":"q-bio.QM,cs.CV,cs.LG,q-bio.BM,stat.ML","published":"2025-04-15T14:46:25Z"}
{"aid":"http://arxiv.org/abs/2504.11254v1","title":"Model Consistency of Iterative Regularization for Low-Complexity\n  Regularization","summary":"Regularization is a core component of modern inverse problems as it allows to\nestablish well-posedness to the solution of interests. Popular regularization\napproaches include variational regularization and iterative regularization. The\nformer one can be tackled by solving a variational optimization problem, which\nis the sum of a regularization term and a data-fidelity term balanced by a\nproper weight, while the latter one chooses a proper stopping time to avoid\noverfitting to the noise. In the study of regularization, an important topic is\nthe relation between the solution obtained by regularization and the original\nground truth. When the ground truth has low-complexity structure which is\nencoded as the \"model\", a sensitivity property shows that the solution obtained\nfrom proper regularization that promotes the same structure is robust to small\nperturbations, this is called \"model consistency\". For variational\nregularization, model consistency of linear inverse problem is studied in [1].\nWhile, for iterative regularization, the existence of model consistency is an\nopen problem. In this paper, based on a recent development of partial\nsmoothness which is also considered in [1], we show that if the noise level is\nsufficiently small and a proper stopping time is chosen, the solution by\niterative regularization also achieves model consistency and more exhibit local\nlinear convergence behavior. Numerical simulations are provided to verify our\ntheoretical findings.","main_category":"math.OC","categories":"math.OC","published":"2025-04-15T14:51:11Z"}
{"aid":"http://arxiv.org/abs/2504.11260v1","title":"$QQ$-systems and tropical geometry","summary":"We investigate the system of polynomial equations, known as $QQ$-systems,\nwhich are closely related to the so-called Bethe ansatz equations of the XXZ\nspin chain, using the methods of tropical geometry.","main_category":"math.AG","categories":"math.AG,hep-th,math-ph,math.MP,math.QA,math.RT","published":"2025-04-15T14:59:26Z"}
{"aid":"http://arxiv.org/abs/2504.11269v1","title":"Minimax asymptotics","summary":"In this paper, we consider asymptotics of the optimal value and the optimal\nsolutions of parametric minimax estimation problems. Specifically, we consider\nestimators of the optimal value and the optimal solutions in a sample minimax\nproblem that approximates the true population problem and study the limiting\ndistributions of these estimators as the sample size tends to infinity. The\nmain technical tool we employ in our analysis is the theory of sensitivity\nanalysis of parameterized mathematical optimization problems. Our results go\nwell beyond the existing literature and show that these limiting distributions\nare highly non-Gaussian in general and normal in simple specific cases. These\nresults open up the way for the development of statistical inference methods in\nparametric minimax problems.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-15T15:10:59Z"}
{"aid":"http://arxiv.org/abs/2504.11276v1","title":"Invention, Innovation, and Commercialisation in British Biophysics","summary":"British biophysics has a rich tradition of scientific invention and\ninnovation, on several occasions resulting in new technologies which have\ntransformed biological insight, such as rapid DNA sequencing, high-precision\nsuper-resolution and label-free microscopy hardware, new approaches for\nhigh-throughput and single-molecule bio-sensing, and the development of a range\nof de novo bio-inspired synthetic materials. Some of these advances have been\nestablished through democratised, open-source platforms and many have\nbiomedical success, a key example involving the SARS-CoV-2 spike protein during\nthe COVID-19 pandemic. Here, three UK labs made crucial contributions in\nrevealing how the spike protein targets human cells, and how therapies such as\nvaccines and neutralizing nanobodies likely work, enabled in large part through\nthe biophysical technological innovations of cryo-electron microscopy. In this\nreview, we discuss leading-edge technological and methodological innovations\nwhich resulted from initial outcomes of discovery-led 'Physics of Life' (PoL)\nresearch (capturing biophysics, biological physics and multiple blends of\nphysical-life sciences interdisciplinary research in the UK) and which have\nmatured into wider-reaching sustainable commercial ventures enabling\nsignificant translational impact. We describe the fundamental biophysical\nscience which led to a diverse range of academic spinouts, presenting the\nscientific questions that were first asked and addressed through innovating new\ntechniques and approaches, and highlighting the key publications which\nultimately led to commercialisation. We consider these example companies\nthrough the lens of opportunities and challenges for academic biophysics\nresearch in partnership with British industry. Finally, we propose\nrecommendations concerning future resourcing and structuring of UK biophysics\nresearch and the training and support of...","main_category":"physics.bio-ph","categories":"physics.bio-ph","published":"2025-04-15T15:16:42Z"}
{"aid":"http://arxiv.org/abs/2504.11287v1","title":"On kinetic energy localization in fluid flow","summary":"This works focuses on participation number -- a parameter that allows to\nquantitatively asses the level of kinetic energy localization. The author\npresents a clear way of deriving participation number in a continuous case\nwithout making any assumptions about the system, fluid or flow regime.\nMoreover, a method of computing participation number in discretized cases is\ndiscussed and verified against well known analytical solutions using three\nmethods, in which one was used previously in research on fluid flow through\nporous media. A robust formula, that works for both uniform and nonuniform\ndiscretization grids is presented.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,physics.comp-ph","published":"2025-04-15T15:26:47Z"}
{"aid":"http://arxiv.org/abs/2504.11298v1","title":"Giant Magnetocaloric Effect in Spin Supersolid Candidate\n  Na$_2$BaCo(PO$_4$)$_2$","summary":"Supersolid, an exotic quantum state of matter that consists of particles\nforming an incompressible solid structure while simultaneously showing\nsuperfluidity of zero viscosity [1], is one of the long-standing pursuits in\nfundamental research [2, 3]. Although the initial report of $^4$He supersolid\nturned out to be an artifact [4], this intriguing quantum matter has inspired\nenthusiastic investigations into ultracold quantum gases [5-8]. Nevertheless,\nthe realization of supersolidity in condensed matter remains elusive. Here we\nfind evidence for a quantum magnetic analogue of supersolid -- the spin\nsupersolid -- in the recently synthesized triangular-lattice antiferromagnet\nNa$_2$BaCo(PO$_4$)$_2$ [9]. Notably, a giant magnetocaloric effect related to\nthe spin supersolidity is observed in the demagnetization cooling process,\nmanifesting itself as two prominent valley-like regimes, with the lowest\ntemperature attaining below 100 mK. Not only is there an experimentally\ndetermined series of critical fields but the demagnetization cooling profile\nalso shows excellent agreement with the theoretical simulations with an\neasy-axis Heisenberg model. Neutron diffractions also successfully locate the\nproposed spin supersolid phases by revealing the coexistence of\nthree-sublattice spin solid order and interlayer incommensurability indicative\nof the spin superfluidity. Thus, our results indicate a strong entropic effect\nof the spin supersolid phase in a frustrated quantum magnet and open up a\nviable and promising avenue for applications in sub-Kelvin refrigeration,\nespecially in the context of persistent concerns about helium shortages [10,\n11].","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-15T15:37:03Z"}
{"aid":"http://arxiv.org/abs/2504.11348v1","title":"Circuit metaconstruction in logspace for Rice-like complexity lower\n  bounds in ANs and SGRs","summary":"A new proof technique combining finite model theory and dynamical systems has\nrecently been introduced to obtain general complexity lower bounds on any\nquestion one may formulate on the dynamics (seen as a graph) of a given\nautomata network (AN). ANs are abstract finite dynamical systems of interacting\nentities whose evolution rules are encoded as circuits, hence the study also\napplies to succinct graph representations (SGRs). In this article, we detail\nthe construction of circuits to obtain general complexity lower bounds\n(metareduction) and show that the reduction is feasible in logarithmic space.","main_category":"cs.CC","categories":"cs.CC","published":"2025-04-15T16:20:22Z"}
{"aid":"http://arxiv.org/abs/2504.11355v1","title":"Neural Networks for on-chip Model Predictive Control: a Method to Build\n  Optimized Training Datasets and its application to Type-1 Diabetes","summary":"Training Neural Networks (NNs) to behave as Model Predictive Control (MPC)\nalgorithms is an effective way to implement them in constrained embedded\ndevices. By collecting large amounts of input-output data, where inputs\nrepresent system states and outputs are MPC-generated control actions, NNs can\nbe trained to replicate MPC behavior at a fraction of the computational cost.\nHowever, although the composition of the training data critically influences\nthe final NN accuracy, methods for systematically optimizing it remain\nunderexplored. In this paper, we introduce the concept of Optimally-Sampled\nDatasets (OSDs) as ideal training sets and present an efficient algorithm for\ngenerating them. An OSD is a parametrized subset of all the available data that\n(i) preserves existing MPC information up to a certain numerical resolution,\n(ii) avoids duplicate or near-duplicate states, and (iii) becomes saturated or\ncomplete. We demonstrate the effectiveness of OSDs by training NNs to replicate\nthe University of Virginia's MPC algorithm for automated insulin delivery in\nType-1 Diabetes, achieving a four-fold improvement in final accuracy. Notably,\ntwo OSD-trained NNs received regulatory clearance for clinical testing as the\nfirst NN-based control algorithm for direct human insulin dosing. This\nmethodology opens new pathways for implementing advanced optimizations on\nresource-constrained embedded platforms, potentially revolutionizing how\ncomplex algorithms are deployed.","main_category":"eess.SY","categories":"eess.SY,cs.AI,cs.SY","published":"2025-04-15T16:25:06Z"}
{"aid":"http://arxiv.org/abs/2504.11381v1","title":"RankAlign: A Ranking View of the Generator-Validator Gap in Large\n  Language Models","summary":"Although large language models (LLMs) have become generally more capable and\naccurate across many tasks, some fundamental sources of unreliability remain in\ntheir behavior. One key limitation is their inconsistency at reporting the the\nsame information when prompts are changed. In this paper, we consider the\ndiscrepancy between a model's generated answer and their own verification of\nthat answer, the generator-validator gap. We define this gap in a more\nstringent way than prior work: we expect correlation of scores from a generator\nand a validator over the entire set of candidate answers. We show that\naccording to this measure, a large gap exists in various settings, including\nquestion answering, lexical semantics tasks, and next-word prediction. We then\npropose RankAlign, a ranking-based training method, and show that it\nsignificantly closes the gap by 31.8% on average, surpassing all baseline\nmethods. Moreover, this approach generalizes well to out-of-domain tasks and\nlexical items.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-15T16:53:31Z"}
{"aid":"http://arxiv.org/abs/2504.11407v1","title":"The Higman-M\\lowercase{c}Laughlin Theorem for the flag-transitive\n  $2$-designs with $Î»$ prime","summary":"A famous result of Higman and McLaughlin \\cite{HM} in 1961 asserts that any\nflag-transitive automorphism group $G$ of a $2$-design $\\mathcal{D}$ with\n$\\lambda=1$ acts point-primitively on $\\mathcal{D}$. In this paper, we show\nthat the Higman and McLaughlin theorem is still true when $\\lambda$ is a prime\nand $\\mathcal{D}$ is not isomorphic to one of the two $2$-$(16,6,2)$ designs as\nin [42, Section 1.2], or the $2$-$(45,12,3)$ design as in [44, Construction\n4.2], or, when $2^{2^{j}}+1$ is a Fermat prime, a possible\n$2$-$(2^{2^{j+1}}(2^{2^{j}}+2),2^{2^{j}}(2^{2^{j}}+1),2^{2^{j}}+1)$ design\nhaving very specific features.","main_category":"math.CO","categories":"math.CO,math.GR","published":"2025-04-15T17:23:58Z"}
{"aid":"http://arxiv.org/abs/2504.11425v1","title":"MINDS: The very low-mass star and brown dwarf sample -- Hidden water in\n  carbon-dominated protoplanetary disks","summary":"Infrared observations of the inner disks around very low-mass stars (VLMS,\n$<$0.3$\\,M_{\\odot}$) have revealed a carbon-rich gas composition in the\nterrestrial planet-forming regions. Contrary to the typically water-rich T\nTauri disk spectra, only two disks around VLMS have been observed to be\nwater-rich among more than ten VLMS disks observed so far with JWST/MIRI. In\nthis letter, we systematically search for the presence of water and other\noxygen-bearing molecules in the JWST/MIRI spectra of ten VLMS disks from the\nMIRI mid-INfrared Disk Survey (MINDS). In addition to the two previously\nreported detections of water emission in this VLMS sample, we detect water\nemission in the spectra of three other sources and tentatively in one source,\nand we provide strong evidence for water emission in the remaining disks in the\nMINDS sample, most of which have bright emission from carbon-bearing molecules.\nWe show that the $\\rm C_2H_2$ emission is much stronger than that of water for\nsources with low luminosities, and the hydrocarbons outshine the water emission\nin such conditions. We propose that the appearance of water-rich vs.\nhydrocarbon-rich spectra is related to the location of the water reservoir in\nthe disk relative to the main hydrocarbon reservoir. Our findings indicate that\nthe terrestrial planet forming regions in VLMS disks have high carbon-to-oxygen\nratios (C/O$>$1), but can still harbor ample water similar to those in the T\nTauri disks.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-04-15T17:38:14Z"}
{"aid":"http://arxiv.org/abs/2504.11426v1","title":"A Dual-Space Framework for General Knowledge Distillation of Large\n  Language Models","summary":"Knowledge distillation (KD) is a promising solution to compress large\nlanguage models (LLMs) by transferring their knowledge to smaller models.\nDuring this process, white-box KD methods usually minimize the distance between\nthe output distributions of the teacher model and the student model to transfer\nmore information. However, we reveal that the current white-box KD framework\nexhibits two limitations: a) bridging probability distributions from different\noutput spaces will limit the similarity between the teacher model and the\nstudent model; b) this framework cannot be applied to LLMs with different\nvocabularies. One of the root causes for these limitations is that the\ndistributions from the teacher and the student for KD are output by different\nprediction heads, which yield distributions in different output spaces and\ndimensions. Therefore, in this paper, we propose a dual-space knowledge\ndistillation (DSKD) framework that unifies the prediction heads of the teacher\nand the student models for KD. Specifically, we first introduce two projectors\nwith ideal initialization to project the teacher/student hidden states into the\nstudent/teacher representation spaces. After this, the hidden states from\ndifferent models can share the same head and unify the output spaces of the\ndistributions. Furthermore, we develop an exact token alignment (ETA) algorithm\nto align the same tokens in two differently-tokenized sequences. Based on the\nabove, our DSKD framework is a general KD framework that supports both\noff-policy and on-policy KD, and KD between any two LLMs regardless of their\nvocabularies. Extensive experiments on instruction-following, mathematical\nreasoning, and code generation benchmarks show that DSKD significantly\noutperforms existing methods based on the current white-box KD framework and\nsurpasses other cross-tokenizer KD methods for LLMs with different\nvocabularies.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-15T17:38:47Z"}
{"aid":"http://arxiv.org/abs/2504.11438v1","title":"Mamba-Based Ensemble learning for White Blood Cell Classification","summary":"White blood cell (WBC) classification assists in assessing immune health and\ndiagnosing various diseases, yet manual classification is labor-intensive and\nprone to inconsistencies. Recent advancements in deep learning have shown\npromise over traditional methods; however, challenges such as data imbalance\nand the computational demands of modern technologies, such as Transformer-based\nmodels which do not scale well with input size, limit their practical\napplication. This paper introduces a novel framework that leverages Mamba\nmodels integrated with ensemble learning to improve WBC classification. Mamba\nmodels, known for their linear complexity, provide a scalable alternative to\nTransformer-based approaches, making them suitable for deployment in\nresource-constrained environments. Additionally, we introduce a new WBC\ndataset, Chula-WBC-8, for benchmarking. Our approach not only validates the\neffectiveness of Mamba models in this domain but also demonstrates their\npotential to significantly enhance classification efficiency without\ncompromising accuracy. The source code can be found at\nhttps://github.com/LewisClifton/Mamba-WBC-Classification.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-15T17:53:18Z"}
{"aid":"http://arxiv.org/abs/2504.11446v1","title":"eXplainable AI for data driven control: an inverse optimal control\n  approach","summary":"Understanding the behavior of black-box data-driven controllers is a key\nchallenge in modern control design. In this work, we propose an eXplainable AI\n(XAI) methodology based on Inverse Optimal Control (IOC) to obtain local\nexplanations for the behavior of a controller operating around a given region.\nSpecifically, we extract the weights assigned to tracking errors and control\neffort in the implicit cost function that a black-box controller is optimizing,\noffering a more transparent and interpretable representation of the\ncontroller's underlying objectives. This approach presents connections with\nwell-established XAI techniques, such as Local Interpretable Model-agnostic\nExplanations (LIME) since it is still based on a local approximation of the\ncontrol policy. However, rather being limited to a standard sensitivity\nanalysis, the explanation provided by our method relies on the solution of an\ninverse Linear Quadratic (LQ) problem, offering a structured and more\ncontrol-relevant perspective. Numerical examples demonstrate that the inferred\ncost function consistently provides a deeper understanding of the controller's\ndecision-making process, shedding light on otherwise counterintuitive or\nunexpected phenomena.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-15T17:56:24Z"}
{"aid":"http://arxiv.org/abs/2504.11749v1","title":"SkeletonX: Data-Efficient Skeleton-based Action Recognition via\n  Cross-sample Feature Aggregation","summary":"While current skeleton action recognition models demonstrate impressive\nperformance on large-scale datasets, their adaptation to new application\nscenarios remains challenging. These challenges are particularly pronounced\nwhen facing new action categories, diverse performers, and varied skeleton\nlayouts, leading to significant performance degeneration. Additionally, the\nhigh cost and difficulty of collecting skeleton data make large-scale data\ncollection impractical. This paper studies one-shot and limited-scale learning\nsettings to enable efficient adaptation with minimal data. Existing approaches\noften overlook the rich mutual information between labeled samples, resulting\nin sub-optimal performance in low-data scenarios. To boost the utility of\nlabeled data, we identify the variability among performers and the commonality\nwithin each action as two key attributes. We present SkeletonX, a lightweight\ntraining pipeline that integrates seamlessly with existing GCN-based skeleton\naction recognizers, promoting effective training under limited labeled data.\nFirst, we propose a tailored sample pair construction strategy on two key\nattributes to form and aggregate sample pairs. Next, we develop a concise and\neffective feature aggregation module to process these pairs. Extensive\nexperiments are conducted on NTU RGB+D, NTU RGB+D 120, and PKU-MMD with various\nGCN backbones, demonstrating that the pipeline effectively improves performance\nwhen trained from scratch with limited data. Moreover, it surpasses previous\nstate-of-the-art methods in the one-shot setting, with only 1/10 of the\nparameters and much fewer FLOPs. The code and data are available at:\nhttps://github.com/zzysteve/SkeletonX","main_category":"cs.CV","categories":"cs.CV,I.4.9","published":"2025-04-16T04:01:42Z"}
{"aid":"http://arxiv.org/abs/2504.11750v1","title":"Characterizing and Optimizing LLM Inference Workloads on CPU-GPU Coupled\n  Architectures","summary":"Large language model (LLM)-based inference workloads increasingly dominate\ndata center costs and resource utilization. Therefore, understanding the\ninference workload characteristics on evolving CPU-GPU coupled architectures is\ncrucial for optimization. This paper presents an in-depth analysis of LLM\ninference behavior on loosely-coupled (PCIe A100/H100) and closely-coupled\n(GH200) systems. We analyze performance dynamics using fine-grained\noperator-to-kernel trace analysis, facilitated by our novel profiler SKIP and\nmetrics like Total Kernel Launch and Queuing Time (TKLQT). Results show that\nclosely-coupled (CC) GH200 significantly outperforms loosely-coupled (LC)\nsystems at large batch sizes, achieving 1.9x-2.7x faster prefill latency for\nLlama 3.2-1B. However, our analysis also reveals that GH200 remains CPU-bound\nup to 4x larger batch sizes than LC systems. In this extended CPU-bound region,\nwe identify the performance characteristics of the Grace CPU as a key factor\ncontributing to higher inference latency at low batch sizes on GH200. We\ndemonstrate that TKLQT accurately identifies this CPU/GPU-bound transition\npoint. Based on this analysis, we further show that kernel fusion offers\nsignificant potential to mitigate GH200's low-batch latency bottleneck by\nreducing kernel launch overhead. This detailed kernel-level characterization\nprovides critical insights for optimizing diverse CPU-GPU coupling strategies.\nThis work is an initial effort, and we plan to explore other major AI/DL\nworkloads that demand different degrees of CPU-GPU heterogeneous architectures.","main_category":"cs.DC","categories":"cs.DC,cs.AI,cs.AR,cs.PF","published":"2025-04-16T04:02:39Z"}
{"aid":"http://arxiv.org/abs/2504.11759v1","title":"Bringing closure to FDR control: beating the e-Benjamini-Hochberg\n  procedure","summary":"False discovery rate (FDR) has been a key metric for error control in\nmultiple hypothesis testing, and many methods have developed for FDR control\nacross a diverse cross-section of settings and applications. We develop a\nclosure principle for all FDR controlling procedures, i.e., we provide a\ncharacterization based on e-values for all admissible FDR controlling\nprocedures. We leverage this idea to formulate the closed eBH procedure, a\n(usually strict) improvement over the eBH procedure for FDR control when\nprovided with e-values. We demonstrate the practical performance of closed eBH\nin simulations.","main_category":"stat.ME","categories":"stat.ME,math.ST,stat.TH","published":"2025-04-16T04:36:12Z"}
{"aid":"http://arxiv.org/abs/2504.11779v1","title":"Multimodal Spatio-temporal Graph Learning for Alignment-free RGBT Video\n  Object Detection","summary":"RGB-Thermal Video Object Detection (RGBT VOD) can address the limitation of\ntraditional RGB-based VOD in challenging lighting conditions, making it more\npractical and effective in many applications.\n  However, similar to most RGBT fusion tasks, it still mainly relies on\nmanually aligned multimodal image pairs.\n  In this paper, we propose a novel Multimodal Spatio-temporal Graph learning\nNetwork (MSGNet) for alignment-free RGBT VOD problem by leveraging the robust\ngraph representation learning model.\n  Specifically, we first design an Adaptive Partitioning Layer (APL) to\nestimate the corresponding regions of the Thermal image within the RGB image\n(high-resolution), achieving a preliminary inexact alignment.\n  Then, we introduce the Spatial Sparse Graph Learning Module (S-SGLM) which\nemploys a sparse information passing mechanism on the estimated inexact\nalignment to achieve reliable information interaction between different\nmodalities.\n  Moreover, to fully exploit the temporal cues for RGBT VOD problem, we\nintroduce Hybrid Structured Temporal Modeling (HSTM), which involves a Temporal\nSparse Graph Learning Module (T-SGLM) and Temporal Star Block (TSB). T-SGLM\naims to filter out some redundant information between adjacent frames by\nemploying the sparse aggregation mechanism on the temporal graph. Meanwhile,\nTSB is dedicated to achieving the complementary learning of local spatial\nrelationships.\n  Extensive comparative experiments conducted on both the aligned dataset\nVT-VOD50 and the unaligned dataset UVT-VOD2024 demonstrate the effectiveness\nand superiority of our proposed method. Our project will be made available on\nour website for free public access.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T05:32:59Z"}
{"aid":"http://arxiv.org/abs/2504.11788v1","title":"Enhancing Web Agents with Explicit Rollback Mechanisms","summary":"With recent advancements in large language models, web agents have been\ngreatly improved. However, dealing with complex and dynamic web environments\nrequires more advanced planning and search abilities. Previous studies usually\nadopt a greedy one-way search strategy, which may struggle to recover from\nerroneous states. In this work, we enhance web agents with an explicit rollback\nmechanism, enabling the agent to revert back to a previous state in its\nnavigation trajectory. This mechanism gives the model the flexibility to\ndirectly control the search process, leading to an effective and efficient web\nnavigation method. We conduct experiments on two live web navigation benchmarks\nwith zero-shot and fine-tuning settings. The results demonstrate the\neffectiveness of our proposed approach.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-16T05:41:20Z"}
{"aid":"http://arxiv.org/abs/2504.11793v1","title":"Selective Attention Federated Learning: Improving Privacy and Efficiency\n  for Clinical Text Classification","summary":"Federated Learning (FL) faces major challenges regarding communication\noverhead and model privacy when training large language models (LLMs),\nespecially in healthcare applications. To address these, we introduce Selective\nAttention Federated Learning (SAFL), a novel approach that dynamically\nfine-tunes only those transformer layers identified as attention-critical. By\nemploying attention patterns to determine layer importance, SAFL significantly\nreduces communication bandwidth and enhances differential privacy resilience.\nEvaluations on clinical NLP benchmarks (i2b2 Clinical Concept Extraction and\nMIMIC-III discharge summaries) demonstrate that SAFL achieves competitive\nperformance with centralized models while substantially improving communication\nefficiency and privacy preservation.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-16T05:59:29Z"}
{"aid":"http://arxiv.org/abs/2504.11813v1","title":"Threshold, subthreshold and global unbounded solutions of superlinear\n  heat equations","summary":"We consider the semilinear heat equation with a superlinear nonlinearity and\nwe study the properties of threshold or subthreshold solutions, lying on or\nbelow the boundary between blow-up and global existence, respectively. For the\nCauchy-Dirichlet problem, we prove the boundedness of any subthreshold\nsolution. This implies, in particular, that all global unbounded solutions --\nif they exist -- are threshold solutions. For the Cauchy problem, these\nproperties fail in general but we show that they become true for a suitably\nmodified notion of threshold. Our results strongly improve known results even\nin the model case of power nonlinearities, especially in the Sobolev critical\nand supercritical cases.","main_category":"math.AP","categories":"math.AP","published":"2025-04-16T06:50:49Z"}
{"aid":"http://arxiv.org/abs/2504.11814v1","title":"ARWI: Arabic Write and Improve","summary":"Although Arabic is spoken by over 400 million people, advanced Arabic writing\nassistance tools remain limited. To address this gap, we present ARWI, a new\nwriting assistant that helps learners improve essay writing in Modern Standard\nArabic. ARWI is the first publicly available Arabic writing assistant to\ninclude a prompt database for different proficiency levels, an Arabic text\neditor, state-of-the-art grammatical error detection and correction, and\nautomated essay scoring aligned with the Common European Framework of Reference\nstandards for language attainment. Moreover, ARWI can be used to gather a\ngrowing auto-annotated corpus, facilitating further research on Arabic grammar\ncorrection and essay scoring, as well as profiling patterns of errors made by\nnative speakers and non-native learners. A preliminary user study shows that\nARWI provides actionable feedback, helping learners identify grammatical gaps,\nassess language proficiency, and guide improvement.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-16T07:00:47Z"}
{"aid":"http://arxiv.org/abs/2504.11828v1","title":"Semiclassical causal geodesics: Minkowski spacetime case","summary":"We use an integral quantization model based on the Heisenberg-Weyl group to\ndescribe the motion of a spinless particle in the Minkowski background\nspacetime. This work is a sequel to a previous paper, devoted to mathematical\naspects of our model: construction of the space of coherent states and\nproperties of elementary observables. We compute transition amplitudes\ncorresponding to a free motion of a particle between two coherent states. These\namplitudes are then used to model quantum random walks of free relativistic\nparticles. Our quantization scheme allows us to recover interference patterns\noccurring in a standard double-slit experiment, known from the classical\napproach. This result is obtained by modeling the slits in terms of eigenstates\nof the position operator and computing transition amplitudes between position\nand coherent states. We design our model in a way which allows for a future\ngeneralization to a semi-classical quantization of the geodesic motion in\ncurved spacetimes.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-16T07:27:28Z"}
{"aid":"http://arxiv.org/abs/2504.11874v1","title":"Factor-MCLS: Multi-agent learning system with reward factor matrix and\n  multi-critic framework for dynamic portfolio optimization","summary":"Typical deep reinforcement learning (DRL) agents for dynamic portfolio\noptimization learn the factors influencing portfolio return and risk by\nanalyzing the output values of the reward function while adjusting portfolio\nweights within the training environment. However, it faces a major limitation\nwhere it is difficult for investors to intervene in the training based on\ndifferent levels of risk aversion towards each portfolio asset. This difficulty\narises from another limitation: existing DRL agents may not develop a thorough\nunderstanding of the factors responsible for the portfolio return and risk by\nonly learning from the output of the reward function. As a result, the strategy\nfor determining the target portfolio weights is entirely dependent on the DRL\nagents themselves. To address these limitations, we propose a reward factor\nmatrix for elucidating the return and risk of each asset in the portfolio.\nAdditionally, we propose a novel learning system named Factor-MCLS using a\nmulti-critic framework that facilitates learning of the reward factor matrix.\nIn this way, our DRL-based learning system can effectively learn the factors\ninfluencing portfolio return and risk. Moreover, based on the critic networks\nwithin the multi-critic framework, we develop a risk constraint term in the\ntraining objective function of the policy function. This risk constraint term\nallows investors to intervene in the training of the DRL agent according to\ntheir individual levels of risk aversion towards the portfolio assets.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-16T08:51:09Z"}
{"aid":"http://arxiv.org/abs/2504.11880v1","title":"Nonequilibrium Casimir pressure for two graphene-coated plates: Quantum\n  field theoretical approach","summary":"We consider the nonequilibrium Casimir pressure in the system of two parallel\ngraphene-coated plates one of which is either warmer or cooler than the\nenvironment. The electromagnetic response of graphene coating characterized by\nthe nonzero energy gap and chemical potential is described in the framework of\nthe Dirac model by means of the polarization tensor. It is shown that the\nmagnitude of the nonequilibrium Casimir pressure on a warmer plate than the\nenvironment is larger and on a cooler plate is smaller than the magnitude of\nthe standard Casimir pressure in the state of thermal equilibrium. According to\nour results, the spatially local theory underestimates the role of the effects\nof nonequilibrium. This underestimation increases for asmaller chemical\npotential of the graphene coating and at lower temperatures of the cooled\nplate. Possible applications of the obtained results are discussed.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-16T09:04:09Z"}
{"aid":"http://arxiv.org/abs/2504.11891v1","title":"Towards a Refined Understanding of Non-holomorphic Soft SUSY-Breaking\n  Effects on the Higgs Boson Mass Spectra","summary":"We study the impact of the non-holomorphic (NH) soft supersymmetry-breaking\nterms $ T_{33}^{\\prime D} $ and $ \\mu^\\prime $, which introduce additional\nSUSY-breaking effects beyond the holomorphic structure of the superpotential,\non the Higgs boson mass spectrum in the NH Minimal Supersymmetric Standard\nModel (NHSSM). The term $ T_{33}^{\\prime D} $ modifies the scalar bottom-quark\nmass matrix and Higgs couplings, while $ \\mu^\\prime $ affects the mass matrices\nof charginos and neutralinos. In our analysis, we incorporate constraints from\ncharge- and color-breaking (CCB) minima where we find that a portion of the\nparameter space is excluded by these constraints. Focusing on the allowed\nparameter space, the NH contributions to the light $\\cal CP$-even Higgs boson\nmass, $ M_h $, from $ \\mu^\\prime $ and $ T_{33}^{\\prime D} $ can reach up to $\n1.4 \\,\\, \\mathrm{GeV} $ and $ 90 \\,\\, \\mathrm{MeV} $, respectively. For the\nheavy $\\cal CP$-even Higgs boson mass, $ M_H $, and the charged Higgs boson\nmass, $ M_{H^{\\pm}} $, these contributions can be substantially larger in\ncertain regions of the parameter space, reaching up to $ 44 \\,\\, \\mathrm{GeV} $\nfor $ M_H $ and $ 42 \\,\\, \\mathrm{GeV} $ for $ M_{H^{\\pm}} $ due to $\n\\mu^\\prime $, and up to $ 60 \\,\\, \\mathrm{GeV} $ due to $ T_{33}^{\\prime D} $\nfor both $ M_H $ and $ M_{H^{\\pm}} $. These corrections are significantly\nlarger than the expected future experimental precision for Higgs boson masses\nand should therefore be considered in precision analyses for future\nexperiments.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-16T09:19:04Z"}
{"aid":"http://arxiv.org/abs/2504.11945v1","title":"Jets from a stellar-mass black hole are as relativistic as those from\n  supermassive black holes","summary":"Relativistic jets from supermassive black holes in active galactic nuclei are\namongst the most powerful phenomena in the universe, acting to regulate the\ngrowth of massive galaxies. Similar jets from stellar-mass black holes offer a\nchance to study the same phenomena on accessible observation time scales.\nHowever, such comparative studies across black hole masses and time scales\nremain hampered by the long-standing perception that stellar-mass black hole\njets are in a less relativistic regime. We used radio interferometry\nobservations to monitor the Galactic black hole X-ray binary 4U 1543-47 and\ndiscovered two distinct, relativistic ejections launched during a single\noutburst. Our measurements reveal a likely Lorentz factor of $\\sim$ 8 and a\nminimum of 4.6 at launch with 95% confidence, demonstrating that stellar-mass\nblack holes in X-ray binaries can launch jets as relativistic as those seen in\nactive galactic nuclei.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-16T10:23:56Z"}
{"aid":"http://arxiv.org/abs/2504.11948v1","title":"On finitely generated Hausdorff spectra of groups acting on rooted trees","summary":"We answer two longstanding questions of Klopsch (1999) and Shalev (2000) by\nproving that the finitely generated Hausdorff spectrum of the closure of a\nfinitely generated regular branch group with respect to the level-stabilizer\nfiltration is the full interval [0,1]. Previous work related to the above\nquestions include the celebrated result of Ab\\'ert and Vir\\'ag on the\ncompleteness of the finitely generated Hausdorff spectrum of the group of\n$p$-adic automorphisms $W_p$. We extend their result to any level-transitive\niterated wreath product acting on a regular rooted tree, and more importantly,\nprovide the first explicit examples of finitely generated subgroups with\nprescribed Hausdorff dimension. In fact, in $W_p$ such subgroups can be taken\nto be 2-generated, giving further evidence to a conjecture of Ab\\'ert and\nVir\\'ag. Furthermore, we extend a well-known result of Klopsch (1999) for\nbranch groups to closed level-transitive groups with fully dimensional rigid\nstabilizers: these have full Hausdorff spectrum with respect to the\nlevel-stabilizer filtration. In turn, we determine, for the first time, the\nHausdorff spectum of many well-studied families of weakly branch groups. As an\nadditional new contribution, we define {\\it nice filtrations} (which include\nthe level-stabilizer filtration). In fact, the first and the last result can be\nproven more generally with respect to these filtrations (under possibly some\nfurther assumptions). Finally, we also consider two standard filtrations,\nnamely the $2$-central lower series, and the dimension subgroup or\nJenning-Zassenhaus series in the closure of the first Grigorchuck group, and\nshow that its finitely generated Hausdorff spectra with respect to these\nfiltrations is the full interval [0,1], answering a recent question of de las\nHeras and Thillaisundaram (2022). This is obtained via a reduction to\nproperties concerning to nice filtrations.","main_category":"math.GR","categories":"math.GR","published":"2025-04-16T10:24:26Z"}
{"aid":"http://arxiv.org/abs/2504.11953v1","title":"Novel-view X-ray Projection Synthesis through Geometry-Integrated Deep\n  Learning","summary":"X-ray imaging plays a crucial role in the medical field, providing essential\ninsights into the internal anatomy of patients for diagnostics, image-guided\nprocedures, and clinical decision-making. Traditional techniques often require\nmultiple X-ray projections from various angles to obtain a comprehensive view,\nleading to increased radiation exposure and more complex clinical processes.\nThis paper explores an innovative approach using the DL-GIPS model, which\nsynthesizes X-ray projections from new viewpoints by leveraging a single\nexisting projection. The model strategically manipulates geometry and texture\nfeatures extracted from an initial projection to match new viewing angles. It\nthen synthesizes the final projection by merging these modified geometry\nfeatures with consistent texture information through an advanced image\ngeneration process. We demonstrate the effectiveness and broad applicability of\nthe DL-GIPS framework through lung imaging examples, highlighting its potential\nto revolutionize stereoscopic and volumetric imaging by minimizing the need for\nextensive data acquisition.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-16T10:30:08Z"}
{"aid":"http://arxiv.org/abs/2504.11956v1","title":"The Conserved Effective Stress Tensor of Gravitational Wave","summary":"We present a detailed study of the effective stress tensor of gravitational\nwave (GW) as the source for the background Einstein equation and examine three\ncandidates in literature. The second order perturbed Einstein tensor\n$G^{(2)}_{\\mu\\nu}$, up to a coefficient, proposed by Brill, Hartle, and\nIsaacson, has long been known to be covariantly nonconserved with respect to\nthe background spacetime. We observe that $G^{(2)}_{\\mu\\nu}$ is not a true\ntensor on the background spacetime. More importantly, we find that, by\nexpressing $G^{(2)}_{\\mu\\nu}$ in terms of the perturbed Hilbert-Einstein\nactions,\n  the nonconserved part of $G^{(2)}_{\\mu\\nu}$ is actually canceled out by the\nperturbed fluid stress tensors in the back-reaction equation, or is vanishing\nin absence of fluid. The remaining part of $G^{(2)}_{\\mu\\nu}$ is just the\nconserved effective stress tensor $\\tau_{\\mu\\nu}$ proposed by Ford and Parker.\nAs the main result, we derive $\\tau_{\\mu\\nu}$ for a general curved spacetime by\nvarying the GW action and show its conservation using the equation of GW. The\nstress tensor $T_{\\text{MT}}^{\\mu\\nu}$ proposed by MacCallum and Taub was based\non an action $J_2$. We derive $T_{\\text{MT}}^{\\mu\\nu}$ and find that it is\nnonconserved, and that $J_2$ does not give the correct GW equation in presence\nof matter. The difficulty with $J_2$ is due to a background Ricci tensor term,\nwhich should be also canceled out by the fluid term or vanishing in absence of\nfluid. We also demonstrate these three candidates in a flat Robertson-Walker\nspacetime. The conserved $\\tau_{\\mu\\nu}$ has a positive energy density\nspectrum, and is adequate for the back-reaction in a perturbation scheme, while\nthe two nonconserved stress tensors have a negative spectrum at long\nwavelengths and are unphysical.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-16T10:38:43Z"}
{"aid":"http://arxiv.org/abs/2504.11963v1","title":"Advantages of off-line analysis of digitally recorded pulses in case of\n  neutron-gamma discrimination in scintillators","summary":"Many modern digital analyzers offer the ability to record raw pulses from\nionizing radiation detectors. We use this opportunity to investigate the\neffectiveness of Charge Comparison Method in Pulse Shape Discrimination of\nneutron and gamma radiation measured with organic glass scintillator and\ntrans-stilbene. The idea of software for automated off-line analysis of\ndigitally recorded data is briefly described. We discuss the difference between\nLeading Edge and Constant Fraction Discrimination triggering methods and we\npropose triggering on pulse maximum as an alternative. We observe that the\nstarting point of charge integration gates has major impact on Figure of Merit\nvalues, therefore it is important to choose it carefully and report it with\nother Charge Comparison Method parameters to keep comparison between\nscintillators reliable. Figure of Merit has a limited usage, so Relative Height\nof Minimum is proposed as an additional indicator of neutron-gamma\ndiscrimination effectiveness in practical applications.","main_category":"physics.ins-det","categories":"physics.ins-det","published":"2025-04-16T10:53:42Z"}
{"aid":"http://arxiv.org/abs/2504.11967v1","title":"Securing the Skies: A Comprehensive Survey on Anti-UAV Methods,\n  Benchmarking, and Future Directions","summary":"Unmanned Aerial Vehicles (UAVs) are indispensable for infrastructure\ninspection, surveillance, and related tasks, yet they also introduce critical\nsecurity challenges. This survey provides a wide-ranging examination of the\nanti-UAV domain, centering on three core objectives-classification, detection,\nand tracking-while detailing emerging methodologies such as diffusion-based\ndata synthesis, multi-modal fusion, vision-language modeling, self-supervised\nlearning, and reinforcement learning. We systematically evaluate\nstate-of-the-art solutions across both single-modality and multi-sensor\npipelines (spanning RGB, infrared, audio, radar, and RF) and discuss\nlarge-scale as well as adversarially oriented benchmarks. Our analysis reveals\npersistent gaps in real-time performance, stealth detection, and swarm-based\nscenarios, underscoring pressing needs for robust, adaptive anti-UAV systems.\nBy highlighting open research directions, we aim to foster innovation and guide\nthe development of next-generation defense strategies in an era marked by the\nextensive use of UAVs.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.RO","published":"2025-04-16T10:58:33Z"}
{"aid":"http://arxiv.org/abs/2504.12042v1","title":"Diverse regular spacetimes using a parametrised density profile","summary":"We explore the construction of diverse regular spacetimes (black holes and\ndefects) in General Relativity (GR) using a generic parametrised density\nprofile (the Dekel-Zhao profile), which includes, for specific parameter\nchoices, various well-known examples usually studied in the context of dark\nmatter halos. Our solutions, in the Schwarzschild gauge, include new regular\nblack holes as well as non-singular solutions representing spacetime defects.\nFor a sub-class of metrics, a TOV equation approach with a chosen equation of\nstate works. The status of the energy conditions and the issue of geodesic\ncompleteness are explored in detail. We also provide possible Lagrangian\ndensity constructions for the matter energy-momentum tensors. Further, we study\nthe shadow radius of the new regular black holes, and compare our findings with\navailable observational results from the EHT collaboration. Finally, for the\ndefect solution, we present a model for a stable star (a gravastar) by explicit\nuse of the junction conditions and obtain relevant consequences highlighting\nits characteristic features.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-16T12:56:31Z"}
{"aid":"http://arxiv.org/abs/2504.12059v1","title":"Sustainable cooperation on the hybrid pollution-control game with\n  heterogeneous players","summary":"This paper considers a hybrid pollution-control differential game with two\nfarsighted players and one myopic player. Both the seasonal regime shifts in\nthe state dynamics and the players' heterogeneous preferences are introduced\ninto the model. The strategies under cooperative, noncooperative and partially\ncooperative scenarios are obtained by utilizing the Pontryagin's Maximum\nPrinciple. Under all feasible coalition structures, the convergence of the\nstate variable is proved. A new sustainably--cooperative optimality principle\nis proposed according to the coalition structures, which belongs to the\nimputation set. The prerequisite for the existence of time-consistency in the\nsustainably-cooperative optimality principle is explicitly obtained. The\nseasonal imputation distribution procedure (IDP) is designed to maintain the\ntime-consistentcy (dynamic stability) of cooperation over time.","main_category":"math.OC","categories":"math.OC","published":"2025-04-16T13:11:21Z"}
{"aid":"http://arxiv.org/abs/2504.12081v1","title":"QCD$_2$ 't Hooft model: 2-flavour mesons spectrum","summary":"We continue analytical study of the meson mass spectrum in the large-$N_c$\ntwo-dimensional QCD, known as the 't Hooft model, by addressing the most\ngeneral case of quarks with unequal masses. Based on our previous work, we\ndevelop non-perturbative methods to compute spectral sums and systematically\nderive large-$n$ WKB expansion of the spectrum. Furthermore, we examine the\nbehavior of these results in various asymptotic regimes, including the chiral,\nheavy quark, and heavy-light limits, and establish a precise coincidence with\nknown analytical and numerical results obtained through alternative approaches.","main_category":"hep-th","categories":"hep-th,hep-ph,math-ph,math.MP","published":"2025-04-16T13:42:10Z"}
{"aid":"http://arxiv.org/abs/2504.12086v1","title":"Neural Contextual Bandits Under Delayed Feedback Constraints","summary":"This paper presents a new algorithm for neural contextual bandits (CBs) that\naddresses the challenge of delayed reward feedback, where the reward for a\nchosen action is revealed after a random, unknown delay. This scenario is\ncommon in applications such as online recommendation systems and clinical\ntrials, where reward feedback is delayed because the outcomes or results of a\nuser's actions (such as recommendations or treatment responses) take time to\nmanifest and be measured. The proposed algorithm, called Delayed NeuralUCB,\nuses an upper confidence bound (UCB)-based exploration strategy. Under the\nassumption of independent and identically distributed sub-exponential reward\ndelays, we derive an upper bound on the cumulative regret over a T-length\nhorizon. We further consider a variant of the algorithm, called Delayed\nNeuralTS, that uses Thompson Sampling-based exploration. Numerical experiments\non real-world datasets, such as MNIST and Mushroom, along with comparisons to\nbenchmark approaches, demonstrate that the proposed algorithms effectively\nmanage varying delays and are well-suited for complex real-world scenarios.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-16T13:47:25Z"}
{"aid":"http://arxiv.org/abs/2504.12093v1","title":"The Tripod High-Speed Quantum Memory As a Beam Splitter with Arbitrary\n  Splitting Ratios","summary":"The utilisation of a quantum memory cell as a beam splitter with arbitrary\ncoefficients is demonstrated theoretically. For such a beam splitter, an\ninput-output matrix is derived. We investigate the high-speed quantum memory\nbased on the tripod-type atomic levels and transitions.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-16T13:57:35Z"}
{"aid":"http://arxiv.org/abs/2504.12110v1","title":"Towards LLM Agents for Earth Observation","summary":"Earth Observation (EO) provides critical planetary data for environmental\nmonitoring, disaster management, climate science, and other scientific domains.\nHere we ask: Are AI systems ready for reliable Earth Observation? We introduce\n\\datasetnamenospace, a benchmark of 140 yes/no questions from NASA Earth\nObservatory articles across 13 topics and 17 satellite sensors. Using Google\nEarth Engine API as a tool, LLM agents can only achieve an accuracy of 33%\nbecause the code fails to run over 58% of the time. We improve the failure rate\nfor open models by fine-tuning synthetic data, allowing much smaller models\n(Llama-3.1-8B) to achieve comparable accuracy to much larger ones (e.g.,\nDeepSeek-R1). Taken together, our findings identify significant challenges to\nbe solved before AI agents can automate earth observation, and suggest paths\nforward. The project page is available at\nhttps://iandrover.github.io/UnivEarth.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-16T14:19:25Z"}
{"aid":"http://arxiv.org/abs/2504.12111v1","title":"Optimizing the quantum interference between single photons and local\n  oscillator with photon correlations","summary":"The quantum interference between a coherent state and a single photon is an\nimportant tool in continuous variable optical quantum technologies to\ncharacterize and engineer non-Gaussian quantum states. Semiconductor quantum\ndots, which have recently emerged as a key platform for efficient single-photon\ngeneration, could become interesting assets in this context. An essential\nparameter for interfering single photons and classical fields is the mean\nwavepacket overlap between both fields. Here, we report on two homodyne\nphoton-correlation techniques enabling the precise measurement of the overlap\nbetween a single photon generated by a quantum dot-cavity device and pulsed\nlaser light. The different statistics of interfering fields lead to specific\nsignatures of the quantum interference on the photon correlations at the output\nof the interfering beam splitter. We compare the behavior of maximized overlap,\nmeasuring either the Hong-Ou-Mandel visibility between both outputs or the\nphoton bunching at a single output. Through careful tailoring of the laser\nlight in various degrees of freedom, we maximize the overlap to $76\\,\\%$, with\nlimitations primarily due to mismatched spectral and temporal profiles and\nlow-frequency charge noise in the single-photon source.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-16T14:19:51Z"}
{"aid":"http://arxiv.org/abs/2504.12168v1","title":"A simple algorithm for the simple bilevel programming (SBP) problem","summary":"In this article we intend to develop a simple and implementable algorithm for\nminimizing a convex function over the solution set of another convex\noptimization problem. Such a problem is often referred to as a simple bilevel\nprogramming (SBP) problem. One of the key features of our algorithm is that we\nmake no assumption on the diferentiability of the upper level objective, though\nwe will assume that the lower level objective is smooth. Another key feature of\nthe algorithm is that it does not assume that the lower level objective has a\nLipschitz gradient, which is a standard assumption in most of the well-known\nalgorithms for this class of problems. We present the convergence analysis and\nalso some numerical experiments demonstrating the efectiveness of the\nalgorithm.","main_category":"math.OC","categories":"math.OC","published":"2025-04-16T15:19:08Z"}
{"aid":"http://arxiv.org/abs/2504.12192v1","title":"From Requirements to Architecture: Semi-Automatically Generating\n  Software Architectures","summary":"To support junior and senior architects, I propose developing a new\narchitecture creation method that leverages LLMs' evolving capabilities to\nsupport the architect. This method involves the architect's close collaboration\nwith LLM-fueled tooling over the whole process. The architect is guided through\nDomain Model creation, Use Case specification, architectural decisions, and\narchitecture evaluation. While the architect can take complete control of the\nprocess and the results, and use the tooling as a building set, they can follow\nthe intended process for maximum tooling support. The preliminary results\nsuggest the feasibility of this process and indicate major time savings for the\narchitect.","main_category":"cs.SE","categories":"cs.SE,cs.AI,D.2.2","published":"2025-04-16T15:46:56Z"}
{"aid":"http://arxiv.org/abs/2504.12193v1","title":"Discrete-Time Modeling of Interturn Short Circuits in Interior PMSMs","summary":"This article describes the discrete-time modeling approach for interturn\nshort circuits in interior permanent magnet synchronous motors with\nconcentrated windings that facilitate model-based fault diagnostics and\nmitigation. A continuous-time model incorporating universal series-parallel\nstator winding connection and radial permanent magnet fluxes is developed in\nthe stator variables and transformed into the rotor reference frame, including\nalso the electromagnetic torque. The transformed model undergoes discretization\nusing the matrix exponential-based technique, wherein the electrical angular\nvelocity and angle are considered time-varying parameters. The resulting model\nis subsequently expanded to consider the motor connection resistance via\nperturbation techniques. In the laboratory experiments, we validate the\ndynamical properties of the derived model by comparing its outputs with the\nexperimental data and waveforms generated by the forward Euler-based\ndiscrete-time approximation.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-16T15:47:31Z"}
{"aid":"http://arxiv.org/abs/2504.12203v1","title":"Modality-Independent Explainable Detection of Inaccurate Organ\n  Segmentations Using Denoising Autoencoders","summary":"In radiation therapy planning, inaccurate segmentations of organs at risk can\nresult in suboptimal treatment delivery, if left undetected by the clinician.\nTo address this challenge, we developed a denoising autoencoder-based method to\ndetect inaccurate organ segmentations. We applied noise to ground truth organ\nsegmentations, and the autoencoders were tasked to denoise them. Through the\napplication of our method to organ segmentations generated on both MR and CT\nscans, we demonstrated that the method is independent of imaging modality. By\nproviding reconstructions, our method offers visual information about\ninaccurate regions of the organ segmentations, leading to more explainable\ndetection of suboptimal segmentations. We compared our method to existing\napproaches in the literature and demonstrated that it achieved superior\nperformance for the majority of organs.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-16T15:53:40Z"}
{"aid":"http://arxiv.org/abs/2504.12215v1","title":"Uncertainty-Guided Coarse-to-Fine Tumor Segmentation with Anatomy-Aware\n  Post-Processing","summary":"Reliable tumor segmentation in thoracic computed tomography (CT) remains\nchallenging due to boundary ambiguity, class imbalance, and anatomical\nvariability. We propose an uncertainty-guided, coarse-to-fine segmentation\nframework that combines full-volume tumor localization with refined\nregion-of-interest (ROI) segmentation, enhanced by anatomically aware\npost-processing. The first-stage model generates a coarse prediction, followed\nby anatomically informed filtering based on lung overlap, proximity to lung\nsurfaces, and component size. The resulting ROIs are segmented by a\nsecond-stage model trained with uncertainty-aware loss functions to improve\naccuracy and boundary calibration in ambiguous regions. Experiments on private\nand public datasets demonstrate improvements in Dice and Hausdorff scores, with\nfewer false positives and enhanced spatial interpretability. These results\nhighlight the value of combining uncertainty modeling and anatomical priors in\ncascaded segmentation pipelines for robust and clinically meaningful tumor\ndelineation. On the Orlando dataset, our framework improved Swin UNETR Dice\nfrom 0.4690 to 0.6447. Reduction in spurious components was strongly correlated\nwith segmentation gains, underscoring the value of anatomically informed\npost-processing.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-16T16:08:38Z"}
{"aid":"http://arxiv.org/abs/2504.12237v1","title":"Stereoscopic Cylindrical Screen (SCS) Projection","summary":"We present a technique for Stereoscopic Cylindrical Screen (SCS) Projection\nof a world scene to a 360-degree canvas for viewing with 3D glasses. To\noptimize the rendering pipeline, we render the scene to four cubemaps, before\nsampling relevant cubemaps onto the canvas. For an interactive user experience,\nwe perform stereoscopic view rendering and off-axis projection to anchor the\nimage to the viewer. This technique is being used to project virtual worlds at\nCMU ETC, and is a step in creating immersive viewing experiences.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-16T16:42:13Z"}
{"aid":"http://arxiv.org/abs/2504.12244v1","title":"Mobile Distributed MIMO (MD-MIMO) for NextG: Mobility Meets Cooperation\n  in Distributed Arrays","summary":"Distributed multiple-input multiple-output (D\\mbox{-}MIMO) is a promising\ntechnology to realize the promise of massive MIMO gains by fiber-connecting the\ndistributed antenna arrays, thereby overcoming the form factor limitations of\nco-located MIMO. In this paper, we introduce the concept of mobile D-MIMO\n(MD-MIMO) network, a further extension of the D-MIMO technology where\ndistributed antenna arrays are connected to the base station with a wireless\nlink allowing all radio network nodes to be mobile. This approach significantly\nimproves deployment flexibility and reduces operating costs, enabling the\nnetwork to adapt to the highly dynamic nature of next-generation (NextG)\nnetworks. We discuss use cases, system design, network architecture, and the\nkey enabling technologies for MD-MIMO. Furthermore, we investigate a case study\nof MD-MIMO for vehicular networks, presenting detailed performance evaluations\nfor both downlink and uplink. The results show that an MD-MIMO network can\nprovide substantial improvements in network throughput and reliability.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-16T16:48:29Z"}
{"aid":"http://arxiv.org/abs/2504.12278v1","title":"Wormholes with Ends of the World","summary":"We study classical wormhole solutions in 3D gravity with end-of-the-world\n(EOW) branes, conical defects, kinks, and punctures. These solutions compute\nstatistical averages of an ensemble of boundary conformal field theories\n(BCFTs) related to universal asymptotics of OPE data extracted from 2D\nconformal bootstrap. Conical defects connect BCFT bulk operators; branes join\nBCFT boundary intervals with identical boundary conditions; kinks (1D defects\nalong branes) link BCFT boundary operators; and punctures (0D defects) are\nendpoints where conical defects terminate on branes. We provide evidence for a\ncorrespondence between the gravity theory and the ensemble. In particular, the\nagreement of $g$-function dependence results from an underlying topological\naspect of the on-shell EOW brane action, from which a BCFT analogue of the\nSchlenker-Witten theorem also follows.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-16T17:38:27Z"}
{"aid":"http://arxiv.org/abs/2504.12281v1","title":"A Near-Optimal Kernel for a Coloring Problem","summary":"For a fixed integer $q$, the $q$-Coloring problem asks to decide if a given\ngraph has a vertex coloring with $q$ colors such that no two adjacent vertices\nreceive the same color. In a series of papers, it has been shown that for every\n$q \\geq 3$, the $q$-Coloring problem parameterized by the vertex cover number\n$k$ admits a kernel of bit-size $\\widetilde{O}(k^{q-1})$, but admits no kernel\nof bit-size $O(k^{q-1-\\varepsilon})$ for $\\varepsilon >0$ unless $\\mathsf{NP}\n\\subseteq \\mathsf{coNP/poly}$ (Jansen and Kratsch, 2013; Jansen and Pieterse,\n2019). In 2020, Schalken proposed the question of the kernelizability of the\n$q$-Coloring problem parameterized by the number $k$ of vertices whose removal\nresults in a disjoint union of edges and isolated vertices. He proved that for\nevery $q \\geq 3$, the problem admits a kernel of bit-size\n$\\widetilde{O}(k^{2q-2})$, but admits no kernel of bit-size\n$O(k^{2q-3-\\varepsilon})$ for $\\varepsilon >0$ unless $\\mathsf{NP} \\subseteq\n\\mathsf{coNP/poly}$. He further proved that for $q \\in \\{3,4\\}$ the problem\nadmits a near-optimal kernel of bit-size $\\widetilde{O}(k^{2q-3})$ and asked\nwhether such a kernel is achievable for all integers $q \\geq 3$. In this short\npaper, we settle this question in the affirmative.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-16T17:44:33Z"}
{"aid":"http://arxiv.org/abs/2504.12628v1","title":"Enhancing NDAR with Delay-Gate-Induced Amplitude Damping","summary":"The Noise-Directed Adaptive Remapping (NDAR) method utilizes amplitude\ndamping noise to enhance the performance of quantum optimization algorithms.\nNDAR alternates between exploration by sampling solutions from the quantum\ncircuit and exploitation by transforming the cost Hamiltonian by changing the\nsigns of its terms. Both exploration and exploitation are important components\nin classical heuristic algorithm design. In this study, we examine how NDAR\nperformance improves by adjusting the balance between these components. We\ncontrol the degree of exploitation by varying the delay time to 0, 50, and\n$100~\\mu\\text{s}$, and investigate exploration strategies using two quantum\ncircuits, QAOA and a random circuit, on IBM's Heron processor. Our results show\nthat increasing delay time in NDAR improves the best objective value found in\neach iteration. In single-layer QAOA and random circuits applied to unweighted\nMax-Cut problem with low edge density, both exploration strategies yield\nsimilar objective value trajectories and provide competitive solution quality\nto simulated annealing for the 80-node problem. Their similar performance\nindicates that, in most cases, increasing amplitude damping noise via\nadditional delay time results in information loss. On the other hand, QAOA\noutperforms random circuits in specific cases, such as positive-negative\nweighted Max-Cut on a fully connected graph. This suggests potential advantages\nof QAOA in more complex settings. We further develop a classical NDAR to better\nunderstand exploration strategies, demonstrating that controlling the Hamming\nweight distribution of sampled bitstrings yields higher quality solutions. This\nsuggests that identifying suitable quantum circuits for exploration could\nenhance NDAR performance.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T04:09:11Z"}
{"aid":"http://arxiv.org/abs/2504.12646v1","title":"Replication Packages in Software Engineering Secondary Studies: A\n  Systematic Mapping","summary":"Context: Systematic reviews (SRs) summarize state-of-the-art evidence in\nscience, including software engineering (SE). Objective: Our objective is to\nevaluate how SRs report replication packages and to provide a comprehensive\nlist of these packages. Method: We examined 528 secondary studies published\nbetween 2013 and 2023 to analyze the availability and reporting of replication\npackages. Results: Our findings indicate that only 25.4% of the reviewed\nstudies include replication packages. Encouragingly, the situation is gradually\nimproving, as our regression analysis shows significant increase in the\navailability of replication packages over time. However, in 2023, just 50.6% of\nsecondary studies provided a replication package while an even lower\npercentage, 29.1% had used a permanent repository with a digital object\nidentifier (DOI) for storage. Conclusion: To enhance transparency and\nreproducibility in SE research, we advocate for the mandatory publication of\nreplication packages in secondary studies.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-17T05:11:39Z"}
{"aid":"http://arxiv.org/abs/2504.12651v1","title":"Feature selection based on cluster assumption in PU learning","summary":"Feature selection is essential for efficient data mining and sometimes\nencounters the positive-unlabeled (PU) learning scenario, where only a few\npositive labels are available, while most data remains unlabeled. In certain\nreal-world PU learning tasks, data subjected to adequate feature selection\noften form clusters with concentrated positive labels. Conventional feature\nselection methods that treat unlabeled data as negative may fail to capture the\nstatistical characteristics of positive data in such scenarios, leading to\nsuboptimal performance. To address this, we propose a novel feature selection\nmethod based on the cluster assumption in PU learning, called FSCPU. FSCPU\nformulates the feature selection problem as a binary optimization task, with an\nobjective function explicitly designed to incorporate the cluster assumption in\nthe PU learning setting. Experiments on synthetic datasets demonstrate the\neffectiveness of FSCPU across various data conditions. Moreover, comparisons\nwith 10 conventional algorithms on three open datasets show that FSCPU achieves\ncompetitive performance in downstream classification tasks, even when the\ncluster assumption does not strictly hold.","main_category":"cs.LG","categories":"cs.LG,cs.NE","published":"2025-04-17T05:22:17Z"}
{"aid":"http://arxiv.org/abs/2504.12664v1","title":"Autonomous Drone for Dynamic Smoke Plume Tracking","summary":"This paper presents a novel autonomous drone-based smoke plume tracking\nsystem capable of navigating and tracking plumes in highly unsteady atmospheric\nconditions. The system integrates advanced hardware and software and a\ncomprehensive simulation environment to ensure robust performance in controlled\nand real-world settings. The quadrotor, equipped with a high-resolution imaging\nsystem and an advanced onboard computing unit, performs precise maneuvers while\naccurately detecting and tracking dynamic smoke plumes under fluctuating\nconditions. Our software implements a two-phase flight operation, i.e.,\ndescending into the smoke plume upon detection and continuously monitoring the\nsmoke movement during in-plume tracking. Leveraging Proportional\nIntegral-Derivative (PID) control and a Proximal Policy Optimization based Deep\nReinforcement Learning (DRL) controller enables adaptation to plume dynamics.\nUnreal Engine simulation evaluates performance under various smoke-wind\nscenarios, from steady flow to complex, unsteady fluctuations, showing that\nwhile the PID controller performs adequately in simpler scenarios, the\nDRL-based controller excels in more challenging environments. Field tests\ncorroborate these findings. This system opens new possibilities for drone-based\nmonitoring in areas like wildfire management and air quality assessment. The\nsuccessful integration of DRL for real-time decision-making advances autonomous\ndrone control for dynamic environments.","main_category":"cs.RO","categories":"cs.RO,physics.flu-dyn","published":"2025-04-17T05:50:15Z"}
{"aid":"http://arxiv.org/abs/2504.12676v1","title":"Accurate Tracking of Arabidopsis Root Cortex Cell Nuclei in 3D\n  Time-Lapse Microscopy Images Based on Genetic Algorithm","summary":"Arabidopsis is a widely used model plant to gain basic knowledge on plant\nphysiology and development. Live imaging is an important technique to visualize\nand quantify elemental processes in plant development. To uncover novel\ntheories underlying plant growth and cell division, accurate cell tracking on\nlive imaging is of utmost importance. The commonly used cell tracking software,\nTrackMate, adopts tracking-by-detection fashion, which applies Laplacian of\nGaussian (LoG) for blob detection, and Linear Assignment Problem (LAP) tracker\nfor tracking. However, they do not perform sufficiently when cells are densely\narranged. To alleviate the problems mentioned above, we propose an accurate\ntracking method based on Genetic algorithm (GA) using knowledge of Arabidopsis\nroot cellular patterns and spatial relationship among volumes. Our method can\nbe described as a coarse-to-fine method, in which we first conducted relatively\neasy line-level tracking of cell nuclei, then performed complicated nuclear\ntracking based on known linear arrangement of cell files and their spatial\nrelationship between nuclei. Our method has been evaluated on a long-time live\nimaging dataset of Arabidopsis root tips, and with minor manual rectification,\nit accurately tracks nuclei. To the best of our knowledge, this research\nrepresents the first successful attempt to address a long-standing problem in\nthe field of time-lapse microscopy in the root meristem by proposing an\naccurate tracking method for Arabidopsis root nuclei.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T06:07:17Z"}
{"aid":"http://arxiv.org/abs/2504.12698v1","title":"High-Resolution Multipath Angle Estimation Based on Power-Angle-Delay\n  Profile for Directional Scanning Sounding","summary":"Directional scanning sounding (DSS) has become widely adopted for\nhigh-frequency channel measurements because it effectively compensates for\nsevere path loss. However, the resolution of existing multipath component (MPC)\nangle estimation methods is constrained by the DSS angle sampling interval.\nTherefore, this communication proposes a high-resolution MPC angle estimation\nmethod based on power-angle-delay profile (PADP) for DSS. By exploiting the\nmapping relationship between the power difference of adjacent angles in the\nPADP and MPC offset angle, the resolution of MPC angle estimation is refined,\nsignificantly enhancing the accuracy of MPC angle and amplitude estimation\nwithout increasing measurement complexity. Numerical simulation results\ndemonstrate that the proposed method reduces the mean squared estimation errors\nof angle and amplitude by one order of magnitude compared to traditional\nomnidirectional synthesis methods. Furthermore, the estimation errors approach\nthe Cram\\'er-Rao Lower Bounds (CRLBs) derived for wideband DSS, thereby\nvalidating its superior performance in MPC angle and amplitude estimation.\nFinally, experiments conducted in an indoor scenario at 37.5 GHz validate the\nexcellent performance of the proposed method in practical applications.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-17T06:56:34Z"}
{"aid":"http://arxiv.org/abs/2504.12699v1","title":"Unsupervised Cross-Domain 3D Human Pose Estimation via\n  Pseudo-Label-Guided Global Transforms","summary":"Existing 3D human pose estimation methods often suffer in performance, when\napplied to cross-scenario inference, due to domain shifts in characteristics\nsuch as camera viewpoint, position, posture, and body size. Among these\nfactors, camera viewpoints and locations {have been shown} to contribute\nsignificantly to the domain gap by influencing the global positions of human\nposes. To address this, we propose a novel framework that explicitly conducts\nglobal transformations between pose positions in the camera coordinate systems\nof source and target domains. We start with a Pseudo-Label Generation Module\nthat is applied to the 2D poses of the target dataset to generate pseudo-3D\nposes. Then, a Global Transformation Module leverages a human-centered\ncoordinate system as a novel bridging mechanism to seamlessly align the\npositional orientations of poses across disparate domains, ensuring consistent\nspatial referencing. To further enhance generalization, a Pose Augmentor is\nincorporated to address variations in human posture and body size. This process\nis iterative, allowing refined pseudo-labels to progressively improve guidance\nfor domain adaptation. Our method is evaluated on various cross-dataset\nbenchmarks, including Human3.6M, MPI-INF-3DHP, and 3DPW. The proposed method\noutperforms state-of-the-art approaches and even outperforms the target-trained\nmodel.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T06:57:20Z"}
{"aid":"http://arxiv.org/abs/2504.12722v1","title":"SimUSER: Simulating User Behavior with Large Language Models for\n  Recommender System Evaluation","summary":"Recommender systems play a central role in numerous real-life applications,\nyet evaluating their performance remains a significant challenge due to the gap\nbetween offline metrics and online behaviors. Given the scarcity and limits\n(e.g., privacy issues) of real user data, we introduce SimUSER, an agent\nframework that serves as believable and cost-effective human proxies. SimUSER\nfirst identifies self-consistent personas from historical data, enriching user\nprofiles with unique backgrounds and personalities. Then, central to this\nevaluation are users equipped with persona, memory, perception, and brain\nmodules, engaging in interactions with the recommender system. SimUSER exhibits\ncloser alignment with genuine humans than prior work, both at micro and macro\nlevels. Additionally, we conduct insightful experiments to explore the effects\nof thumbnails on click rates, the exposure effect, and the impact of reviews on\nuser engagement. Finally, we refine recommender system parameters based on\noffline A/B test results, resulting in improved user engagement in the real\nworld.","main_category":"cs.IR","categories":"cs.IR,cs.AI","published":"2025-04-17T07:57:23Z"}
{"aid":"http://arxiv.org/abs/2504.12761v1","title":"Temporal Variation of Flare Occurrence Rates via the Spot Evolution on\n  the Sun and Solar-type Stars","summary":"The spot evolution on the Sun and solar-type stars is important for\nunderstanding the nature of consequential flaring activity. This study\nstatistically investigates the variance of flare occurrence rate through the\ntime evolution of spots on the Sun and solar-type stars. We have compiled the\n28-year catalogs of solar flares and their source sunspots obtained from solar\nsurface observations by NOAA and GOES for the Sun. Also, we combined the\ncataloged stellar flares with the time evolution of starspots estimated by\nlight curves obtained by the 4-year Kepler mission for solar-type stars. For\nthe obtained 24124 solar flares and 180 stellar flares, we calculate the flare\noccurrence distribution with respect to $t_\\mathrm{flare}-t_\\mathrm{max}$,\nwhich represents the timing of flare through the spot evolution, where\n$t_\\mathrm{flare}$ is the flare occurrence time, and $t_\\mathrm{max}$ is the\ntime when the source spot takes its maximum area. When normalized by the spot\nlifetime, we found that the flare occurrence distribution for\n$t_\\mathrm{flare}-t_\\mathrm{max}$ shows a similar distribution regardless of\nspot size or flare energy, suggesting that the Sun and the solar-type star\nshare the same physical process in the spot-to-flare activity. On this basis,\nwe propose a formula for the time variation of the flare occurrence rate per\nspot. Also, the correlation between the temporal variation of flare occurrence\nrate and the time evolution of spot area and the lack of difference in flare\noccurrence rate between the emergence and decaying phases provide a milestone\nfor the nature of flare-productive spots.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-17T08:56:43Z"}
{"aid":"http://arxiv.org/abs/2504.12764v1","title":"GraphOmni: A Comprehensive and Extendable Benchmark Framework for Large\n  Language Models on Graph-theoretic Tasks","summary":"In this paper, we presented GraphOmni, a comprehensive benchmark framework\nfor systematically evaluating the graph reasoning capabilities of LLMs. By\nanalyzing critical dimensions, including graph types, serialization formats,\nand prompt schemes, we provided extensive insights into the strengths and\nlimitations of current LLMs. Our empirical findings emphasize that no single\nserialization or prompting strategy consistently outperforms others. Motivated\nby these insights, we propose a reinforcement learning-based approach that\ndynamically selects the best serialization-prompt pairings, resulting in\nsignificant accuracy improvements. GraphOmni's modular and extensible design\nestablishes a robust foundation for future research, facilitating advancements\ntoward general-purpose graph reasoning models.","main_category":"cs.LG","categories":"cs.LG,cs.DM","published":"2025-04-17T09:01:16Z"}
{"aid":"http://arxiv.org/abs/2504.12776v1","title":"StorySets: Ordering Curves and Dimensions for Visualizing Uncertain Sets\n  and Multi-Dimensional Discrete Data","summary":"We propose a method for visualizing uncertain set systems, which differs from\nprevious set visualization approaches that are based on certainty (an element\neither belongs to a set or not). Our method is inspired by storyline\nvisualizations and parallel coordinate plots: (a) each element is represented\nby a vertical glyph, subdivided into bins that represent different levels of\nuncertainty; (b) each set is represented by an x-monotone curve that traverses\nelement glyphs through the bins representing the level of uncertainty of their\nmembership. Our implementation also includes optimizations to reduce visual\ncomplexity captured by the number of turns for the set curves and the number of\ncrossings. Although several of the natural underlying optimization problems are\nNP-hard in theory (e.g., optimal element order, optimal set order), in\npractice, we can compute near-optimal solutions with respect to curve crossings\nwith the help of a new exact algorithm for optimally ordering set curves within\neach element's bins. With these optimizations, the proposed method makes it\neasy to see set containment (the smaller set's curve is strictly below the\nlarger set's curve). A brief design-space exploration using uncertain\nset-membership data, as well as multi-dimensional discrete data, shows the\nflexibility of the proposed approach.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-17T09:18:02Z"}
{"aid":"http://arxiv.org/abs/2504.12784v1","title":"Accessing quasi-flat $\\textit{f}$-bands to harvest large Berry curvature\n  in NdGaSi","summary":"Bands away from the Fermi energy do not influence the electrical conduction.\nIn typical rare-earth lanthanide compounds, the localized\n4$\\textit{f}$-electrons have a weak effect on the electrical conduction,\nlimiting their influence on the Berry curvature and, hence, the intrinsic\nanomalous Hall effect. However, a comprehensive study of the magnetic,\nthermodynamic, and transport properties of single-crystalline NdGaSi, guided by\nfirst-principles calculations, reveals a ferromagnetic ground state that\ninduces a splitting of quasi-flat 4$\\textit{f}$-electronic bands and positions\nthem near the Fermi energy. The observation of an extraordinarily large\nintrinsic anomalous Hall conductivity of 1165 $\\Omega^{-1}$cm$^{-1}$ implies\nthe direct involvement of localized states in the generation of non-trivial\nband crossings around the Fermi energy. These results are remarkable when\ncompared to ferrimagnetic NdAlSi, which differs only in a non-magnetic atom (a\nchange in the principal quantum number $\\textit{n}$ of the outer $\\textit{p}$\norbital) with the same number of valence electrons and does not exhibit any\nmeasurable anomalous Hall conductivity.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-17T09:30:23Z"}
{"aid":"http://arxiv.org/abs/2504.12785v1","title":"New developments in MatCont: delay equation importer and Lyapunov\n  exponents","summary":"MatCont is a powerful toolbox for numerical bifurcation analysis focussing on\nsmooth ODEs. A user can study equilibria, periodic and connecting orbits, and\ntheir stability and bifurcations. Here, we report on additional features in\nversion 7p6. The first is a delay equation importer enabling MatCont users to\nstudy a much larger class of models, namely delay equations with finite delay\n(including delay differential and renewal equations). This importer translates\nthe delay equation into a system of ODEs using a pseudospectral approximation\nwith an order specified by the user. We also implemented Lyapunov exponent\ncomputations, event functions for Poincar\\'e maps, and enhanced homoclinic\ncontinuation. We demonstrate these features with test cases, such as the\nMackey-Glass equation and a renewal equation, and provide additional examples\nin online tutorials.","main_category":"math.DS","categories":"math.DS","published":"2025-04-17T09:33:27Z"}
{"aid":"http://arxiv.org/abs/2504.12786v1","title":"Magnetized black holes in Kaluza-Klein theory and the Kerr/CFT\n  correspondence","summary":"In this work, we examine the Kerr/CFT correspondence for magnetized black\nholes arising from Kaluza--Klein theory, demonstrating that Kerr/CFT holography\npersists beyond the traditional Einstein--Maxwell framework. Notably, unlike in\nthe Einstein--Maxwell case, the massless neutral scalar field equation here is\nfully separable into radial and angular parts. This separability reveals a\nhidden conformal symmetry in the near--horizon, low--frequency regime,\nproviding further support for the robustness of Kerr/CFT dualities in extended\ngravitational theories.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-17T09:33:54Z"}
{"aid":"http://arxiv.org/abs/2504.12832v1","title":"Physics of an AMOC Overshoot in a Box Model","summary":"Recently the global average temperature has temporarily exceeded the\n1.5{\\deg}C goal of the Paris Agreement, and so an overshoot of various climate\ntipping elements becomes increasingly likely. In this study we analyze the\nphysical processes of an overshoot of the Atlantic Meridional Overturning\nCirculation (AMOC), one of the major tipping elements, using a conceptual box\nmodel. Here either the atmospheric temperature above the North Atlantic, or the\nfreshwater forcing into the North Atlantic overshoot their respective critical\nboundaries. In both cases a higher forcing rate can prevent a collapse of the\nAMOC, since a higher rate of forcing causes initially a fresher North Atlantic,\nwhich in turn results in a higher northward transport by the subtropical gyre\nsupplementing the salinity loss in time. For small exceedance amplitudes the\nAMOC is still resilient as the forcing rates can be low and so other state\nvariables outside of the North Atlantic can adjust. Contrarily, for larger\novershoots the trajectories are dynamically similar and we find a lower limit\nin volume and exceedance time for respectively freshwater and temperature\nforcing in order to prevent a collapse. Moreover, for a large overshoot an\nincreased air-sea temperature coupling has a destabilizing effect, while the\nreverse holds for an overshoot close to the tipping point. The understanding of\nthe physics of the AMOC overshoot behavior is important for interpreting\nresults of Earth System Models and for evaluating the effects of mitigation and\nintervention strategies.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-17T10:46:21Z"}
{"aid":"http://arxiv.org/abs/2504.12835v1","title":"Kinetic simulated annealing optimization with entropy-based cooling rate","summary":"We present a modified simulated annealing method with a dynamical choice of\nthe cooling temperature. The latter is determined via a closed-loop control and\nis proven to yield exponential decay of the entropy of the particle system. The\nanalysis is carried out through kinetic equations for interacting particle\nsystems describing the simulated annealing method in an extended phase space.\nDecay estimates are derived under the quasi-invariant scaling of the resulting\nsystem of Boltzmann-type equations to assess the consistency with their\nmean-field limit. Numerical results are provided to illustrate and support the\ntheoretical findings.","main_category":"math.OC","categories":"math.OC,nlin.AO","published":"2025-04-17T10:50:24Z"}
{"aid":"http://arxiv.org/abs/2504.12841v1","title":"ALT: A Python Package for Lightweight Feature Representation in Time\n  Series Classification","summary":"We introduce ALT, an open-source Python package created for efficient and\naccurate time series classification (TSC). The package implements the adaptive\nlaw-based transformation (ALT) algorithm, which transforms raw time series data\ninto a linearly separable feature space using variable-length shifted time\nwindows. This adaptive approach enhances its predecessor, the linear law-based\ntransformation (LLT), by effectively capturing patterns of varying temporal\nscales. The software is implemented for scalability, interpretability, and ease\nof use, achieving state-of-the-art performance with minimal computational\noverhead. Extensive benchmarking on real-world datasets demonstrates the\nutility of ALT for diverse TSC tasks in physics and related domains.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV,cs.MS,stat.ML","published":"2025-04-17T10:57:29Z"}
{"aid":"http://arxiv.org/abs/2504.12843v1","title":"Quadratic subproduct systems, free products, and their C*-algebras","summary":"Motivated by the interplay between quadratic algebras, noncommutative\ngeometry, and operator theory, we introduce the notion of quadratic subproduct\nsystems of Hilbert spaces. Specifically, we study the subproduct systems\ninduced by a finite number of complex quadratic polynomials in noncommuting\nvariables, and describe their Toeplitz and Cuntz--Pimsner algebras. Inspired by\nthe theory of graded associative algebras, we define a free product operation\nin the category of subproduct systems and show that this corresponds to the\nreduced free product of the Toeplitz algebras. Finally, we obtain results about\nthe K-theory of the Toeplitz and Cuntz--Pimsner algebras of a large class of\nquadratic subproduct systems.","main_category":"math.OA","categories":"math.OA","published":"2025-04-17T10:57:58Z"}
{"aid":"http://arxiv.org/abs/2504.12846v1","title":"Timing via Pinwheel Double Categories","summary":"We discuss string diagrams for timed process theories -- represented by\nduoidally-graded symmetric strict monoidal categories -- built upon the string\ndiagrams of pinwheel double categories.","main_category":"math.CT","categories":"math.CT,cs.LO","published":"2025-04-17T11:02:52Z"}
{"aid":"http://arxiv.org/abs/2504.12852v1","title":"Why $w \\ne -1$? Anthropic Selection in a $Î$ + Axion Dark Energy\n  Model","summary":"We study a dark energy model composed of a bare negative cosmological\nconstant and a single ultra-light axion, motivated by the string axiverse.\nAssuming that intelligent observers can exist and observe an accelerating\nuniverse, we derive nontrivial constraints on both the axion mass and the bare\ncosmological constant. The axion mass is bounded from above to avoid\nfine-tuning of the initial misalignment angle near the hilltop, and from below\nbecause extremely light axions would require the bare cosmological constant to\nbe unnaturally close to zero to achieve accelerated expansion. As a result, the\nanthropically allowed axion mass range typically lies around $m =\n\\mathcal{O}(10)\\, H_0$ for a decay constant close to the Planck scale, where\n$H_0$ is the observed value of the Hubble constant. In this framework, the dark\nenergy equation of state parameter $w_0$ generically deviates from $-1$ by\n$\\mathcal{O}(0.1)$, providing a natural explanation for why $w \\ne -1$ may be\nexpected. This outcome is intriguingly consistent with recent DESI hints of\ntime-varying dark energy, and offers a compelling anthropic explanation within\nthe $\\Lambda$ + axion framework.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO","published":"2025-04-17T11:19:58Z"}
{"aid":"http://arxiv.org/abs/2504.12861v1","title":"Hardware Implementation of Tunable Fractional-Order Capacitors by\n  Morphogenesis of Conducting Polymer Dendrites","summary":"Conventional electronics is founded on a paradigm where shaping perfect\nelectrical elements is done at the fabrication plant, so as to make devices and\nsystems identical, \"eternally immutable\". In nature, morphogenic evolutions are\nobserved in most living organisms and exploit topological plasticity as a\nlow-resource mechanism for in operando manufacturing and computation. Often\nfractal, the resulting topologies feature inherent disorder: a property which\nis never exploited in conventional electronics manufacturing, while necessary\nfor data generation and security in software. In this study, we present how\nsuch properties can be exploited to implement long-term and evolvable synaptic\nplasticity in an electronic hardware. The rich topology of conducting polymer\ndendrites (CPDs) is exploited to program the non-ideality of their\nelectrochemical capacitances containing constant-phase-elements. Their\nevolution through structural changes alters the characteristic time constants\nfor them to charge and discharge with the applied voltage stimuli. Under a\ntrain of voltage spikes, the evolvable current relaxation of the\nelectrochemical systems promotes short-term plasticity with timescales ranging\nfrom milliseconds to seconds. This large window depends on the temporality of\nthe voltage pulses used for reading, but also on the structure of a pair of\nCPDs on two electrodes, grown by voltage pulses. This study demonstrates how\nrelevant physically transient and non-ideal electrochemical components can be\nexploited for unconventional electronics, with the aim to mimic a universal\nproperty of living organisms which could barely be replicated in a silicon\nmonocrystal.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-17T11:38:43Z"}
{"aid":"http://arxiv.org/abs/2504.12862v1","title":"A Holomorphic perspective of Strict Deformation Quantization","summary":"We provide and discuss complex analytic methods for overcoming the formal\ncharacter of formal deformation quantization. This is a necessity for returning\nto physically meaningful statements, and accounts for the fact that the formal\nparameter $\\hbar$ carries the interpretation of Planck's constant. As formal\nstar products are given by a formal power series, this naturally leads into the\nrealm of holomorphic functions and analytic continuation, both in finite and\ninfinite dimensions. We propose a general notion of strict deformation\nquantization and investigate how one can use established results from complex\nanalysis to think about the resulting objects. Within the main body of the\ntext, the outlined program is then put into practice for strict deformation\nquantizations of constant Poisson structures on locally convex vector spaces\nand the strict deformation quantization of canonical mechanics on the cotangent\nbundle of a Lie group. Numerous auxiliary results, many of which are well-known\nyet remarkable in their own right, are provided throughout.","main_category":"math.CV","categories":"math.CV,math-ph,math.MP,math.QA","published":"2025-04-17T11:40:43Z"}
{"aid":"http://arxiv.org/abs/2504.12867v1","title":"EmoVoice: LLM-based Emotional Text-To-Speech Model with Freestyle Text\n  Prompting","summary":"Human speech goes beyond the mere transfer of information; it is a profound\nexchange of emotions and a connection between individuals. While Text-to-Speech\n(TTS) models have made huge progress, they still face challenges in controlling\nthe emotional expression in the generated speech. In this work, we propose\nEmoVoice, a novel emotion-controllable TTS model that exploits large language\nmodels (LLMs) to enable fine-grained freestyle natural language emotion\ncontrol, and a phoneme boost variant design that makes the model output phoneme\ntokens and audio tokens in parallel to enhance content consistency, inspired by\nchain-of-thought (CoT) and modality-of-thought (CoM) techniques. Besides, we\nintroduce EmoVoice-DB, a high-quality 40-hour English emotion dataset featuring\nexpressive speech and fine-grained emotion labels with natural language\ndescriptions. EmoVoice achieves state-of-the-art performance on the English\nEmoVoice-DB test set using only synthetic training data, and on the Chinese\nSecap test set using our in-house data. We further investigate the reliability\nof existing emotion evaluation metrics and their alignment with human\nperceptual preferences, and explore using SOTA multimodal LLMs GPT-4o-audio and\nGemini to assess emotional speech. Demo samples are available at\nhttps://anonymous.4open.science/r/EmoVoice-DF55. Dataset, code, and checkpoints\nwill be released.","main_category":"eess.AS","categories":"eess.AS,cs.AI,cs.CL","published":"2025-04-17T11:50:04Z"}
{"aid":"http://arxiv.org/abs/2504.12870v1","title":"CST-former: Multidimensional Attention-based Transformer for Sound Event\n  Localization and Detection in Real Scenes","summary":"Sound event localization and detection (SELD) is a task for the\nclassification of sound events and the identification of direction of arrival\n(DoA) utilizing multichannel acoustic signals. For effective classification and\nlocalization, a channel-spectro-temporal transformer (CST-former) was\nsuggested. CST-former employs multidimensional attention mechanisms across the\nspatial, spectral, and temporal domains to enlarge the model's capacity to\nlearn the domain information essential for event detection and DoA estimation\nover time. In this work, we present an enhanced version of CST-former with\nmultiscale unfolded local embedding (MSULE) developed to capture and aggregate\ndomain information over multiple time-frequency scales. Also, we propose\nfinetuning and post-processing techniques beneficial for conducting the SELD\ntask over limited training datasets. In-depth ablation studies of the proposed\narchitecture and detailed analysis on the proposed modules are carried out to\nvalidate the efficacy of multidimensional attentions on the SELD task.\nEmpirical validation through experimentation on STARSS22 and STARSS23 datasets\ndemonstrates the remarkable performance of CST-former and post-processing\ntechniques without using external data.","main_category":"eess.AS","categories":"eess.AS","published":"2025-04-17T11:56:13Z"}
{"aid":"http://arxiv.org/abs/2504.12880v1","title":"Can Masked Autoencoders Also Listen to Birds?","summary":"Masked Autoencoders (MAEs) pretrained on AudioSet fail to capture the\nfine-grained acoustic characteristics of specialized domains such as\nbioacoustic monitoring. Bird sound classification is critical for assessing\nenvironmental health, yet general-purpose models inadequately address its\nunique acoustic challenges. To address this, we introduce Bird-MAE, a\ndomain-specialized MAE pretrained on the large-scale BirdSet dataset. We\nexplore adjustments to pretraining, fine-tuning and utilizing frozen\nrepresentations. Bird-MAE achieves state-of-the-art results across all BirdSet\ndownstream tasks, substantially improving multi-label classification\nperformance compared to the general-purpose Audio-MAE baseline. Additionally,\nwe propose prototypical probing, a parameter-efficient method for leveraging\nMAEs' frozen representations. Bird-MAE's prototypical probes outperform linear\nprobing by up to 37\\% in MAP and narrow the gap to fine-tuning to approximately\n3\\% on average on BirdSet.","main_category":"cs.LG","categories":"cs.LG,cs.SD,eess.AS","published":"2025-04-17T12:13:25Z"}
{"aid":"http://arxiv.org/abs/2504.12893v1","title":"Hardness of classically sampling quantum chemistry circuits","summary":"Significant advances have been made in the study of quantum advantage both in\ntheory and experiment, although these have mostly been limited to artificial\nsetups. In this work, we extend the scope to address quantum advantage in tasks\nrelevant to chemistry and physics. Specifically, we consider the unitary\ncluster Jastrow (UCJ) ansatz-a variant of the unitary coupled cluster ansatz,\nwhich is widely used to solve the electronic structure problem on quantum\ncomputers-to show that sampling from the output distributions of quantum\ncircuits implementing the UCJ ansatz is likely to be classically hard. More\nspecifically, we show that there exist UCJ circuits for which classical\nsimulation of sampling cannot be performed in polynomial time, under a\nreasonable complexity-theoretical assumption that the polynomial hierarchy does\nnot collapse. Our main contribution is to show that a class of UCJ circuits can\nbe used to perform arbitrary instantaneous quantum polynomial-time (IQP)\ncomputations, which are already known to be classically hard to simulate under\nthe same complexity assumption. As a side result, we also show that UCJ\nequipped with post-selection can generate the class post-BQP. Our\ndemonstration, worst-case nonsimulatability of UCJ, would potentially imply\nquantum advantage in quantum algorithms for chemistry and physics using unitary\ncoupled cluster type ansatzes, such as the variational quantum eigensolver and\nquantum-selected configuration interaction.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T12:34:33Z"}
{"aid":"http://arxiv.org/abs/2504.12913v1","title":"MAIN: Mutual Alignment Is Necessary for instruction tuning","summary":"Instruction tuning has enabled large language models (LLMs) to achieve\nremarkable performance, but its success heavily depends on the availability of\nlarge-scale, high-quality instruction-response pairs. However, current methods\nfor scaling up data generation often overlook a crucial aspect: the alignment\nbetween instructions and responses. We hypothesize that high-quality\ninstruction-response pairs are not defined by the individual quality of each\ncomponent, but by the extent of their alignment with each other. To address\nthis, we propose a Mutual Alignment Framework (MAIN) that ensures coherence\nbetween the instruction and response through mutual constraints. Experiments\ndemonstrate that models such as LLaMA and Mistral, fine-tuned within this\nframework, outperform traditional methods across multiple benchmarks. This\napproach underscores the critical role of instruction-response alignment in\nenabling scalable and high-quality instruction tuning for LLMs.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-17T13:02:44Z"}
{"aid":"http://arxiv.org/abs/2504.12918v1","title":"Sliced-Wasserstein Distance-based Data Selection","summary":"We propose a new unsupervised anomaly detection method based on the\nsliced-Wasserstein distance for training data selection in machine learning\napproaches. Our filtering technique is interesting for decision-making\npipelines deploying machine learning models in critical sectors, e.g., power\nsystems, as it offers a conservative data selection and an optimal transport\ninterpretation. To ensure the scalability of our method, we provide two\nefficient approximations. The first approximation processes reduced-cardinality\nrepresentations of the datasets concurrently. The second makes use of a\ncomputationally light Euclidian distance approximation. Additionally, we open\nthe first dataset showcasing localized critical peak rebate demand response in\na northern climate. We present the filtering patterns of our method on\nsynthetic datasets and numerically benchmark our method for training data\nselection. Finally, we employ our method as part of a first forecasting\nbenchmark for our open-source dataset.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T13:07:26Z"}
{"aid":"http://arxiv.org/abs/2504.12922v1","title":"On the asymptotic behaviour of stochastic processes, with applications\n  to supermartingale convergence, Dvoretzky's approximation theorem, and\n  stochastic quasi-FejÃ©r monotonicity","summary":"We prove a novel and general result on the asymptotic behavior of stochastic\nprocesses which conform to a certain relaxed supermartingale condition. Our\nresult provides quantitative information in the form of an explicit and\neffective construction of a rate of convergence for this process, both in mean\nand almost surely, that is moreover highly uniform in the sense that it only\ndepends on very few data of the surrounding objects involved in the iteration.\nWe then apply this result to derive new quantitative versions of well-known\nconcepts and theorems from stochastic approximation, in particular providing\neffective rates for a variant of the Robbins-Siegmund theorem, Dvoretzky's\nconvergence theorem, as well as the convergence of stochastic quasi-Fej\\'er\nmonotone sequences, the latter of which formulated in a novel and highly\ngeneral metric context. We utilize the classic and widely studied Robbins-Monro\nprocedure as a template to evaluate our quantitative results and their\napplicability in greater detail. We conclude by illustrating the breadth of\npotential further applications with a brief discussion on a variety of other\nwell-known iterative procedures from stochastic approximation, covering a range\nof different applied scenarios to which our methods can be immediately applied.\nThroughout, we isolate and discuss special cases of our results which even\nallow for the construction of fast, and in particular linear, rates.","main_category":"math.OC","categories":"math.OC,cs.LG,math.LO,math.PR","published":"2025-04-17T13:11:26Z"}
{"aid":"http://arxiv.org/abs/2504.12953v1","title":"How to get Rid of SQL, Relational Algebra, the Relational Model, ERM,\n  and ORMs in a Single Paper -- A Thought Experiment","summary":"Without any doubt, the relational paradigm has been a huge success. At the\nsame time, we believe that the time is ripe to rethink how database systems\ncould look like if we designed them from scratch. Would we really end up with\nthe same abstractions and techniques that are prevalent today? This paper\nexplores that space. We discuss the various issues with both the relational\nmodel(RM) and the entity-relationship model (ERM). We provide a unified data\nmodel: the relational map type model (RMTM) which can represent both RM and ERM\nas special cases and overcomes all of their problems. We proceed to identify\nseven rules that an RMTM query language (QL) must fulfill and provide a\nfoundation of a language fulfilling all seven rules. Our QL operates on maps\nwhich may represent tuples, relations, databases or sets of databases. Like\nthat we dramatically expand the existing operational abstractions found in SQL\nand relational algebra (RA) which only operate on relations/tables. In fact, RA\nis just a special case of our much more generic approach. This work has\nfar-reaching consequences: we show a path how to come up with a modern QL that\nsolves (almost if not) all problems of SQL. Our QL is much more expressive than\nSQL and integrates smoothly into existing programming languages (PL). We also\nshow results of an initial experiment showcasing that just by switching to our\ndata model, and without changing the underlying query processing algorithms, we\ncan achieve speed-ups of up to a factor 3. We will conclude that, if we build a\ndatabase system from scratch, we could and should do this without SQL, RA, RM,\nERM, and ORMs.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-17T13:55:41Z"}
{"aid":"http://arxiv.org/abs/2504.12967v1","title":"Krysalis Hand: A Lightweight, High-Payload, 18-DoF Anthropomorphic\n  End-Effector for Robotic Learning and Dexterous Manipulation","summary":"This paper presents the Krysalis Hand, a five-finger robotic end-effector\nthat combines a lightweight design, high payload capacity, and a high number of\ndegrees of freedom (DoF) to enable dexterous manipulation in both industrial\nand research settings. This design integrates the actuators within the hand\nwhile maintaining an anthropomorphic form. Each finger joint features a\nself-locking mechanism that allows the hand to sustain large external forces\nwithout active motor engagement. This approach shifts the payload limitation\nfrom the motor strength to the mechanical strength of the hand, allowing the\nuse of smaller, more cost-effective motors. With 18 DoF and weighing only 790\ngrams, the Krysalis Hand delivers an active squeezing force of 10 N per finger\nand supports a passive payload capacity exceeding 10 lbs. These characteristics\nmake Krysalis Hand one of the lightest, strongest, and most dexterous robotic\nend-effectors of its kind. Experimental evaluations validate its ability to\nperform intricate manipulation tasks and handle heavy payloads, underscoring\nits potential for industrial applications as well as academic research. All\ncode related to the Krysalis Hand, including control and teleoperation, is\navailable on the project GitHub repository:\nhttps://github.com/Soltanilara/Krysalis_Hand","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-17T14:19:26Z"}
{"aid":"http://arxiv.org/abs/2504.12977v1","title":"A Phenomenological Approach to Analyzing User Queries in IT Systems\n  Using Heidegger's Fundamental Ontology","summary":"This paper presents a novel research analytical IT system grounded in Martin\nHeidegger's Fundamental Ontology, distinguishing between beings (das Seiende)\nand Being (das Sein). The system employs two modally distinct, descriptively\ncomplete languages: a categorical language of beings for processing user inputs\nand an existential language of Being for internal analysis. These languages are\nbridged via a phenomenological reduction module, enabling the system to analyze\nuser queries (including questions, answers, and dialogues among IT\nspecialists), identify recursive and self-referential structures, and provide\nactionable insights in categorical terms. Unlike contemporary systems limited\nto categorical analysis, this approach leverages Heidegger's phenomenological\nexistential analysis to uncover deeper ontological patterns in query\nprocessing, aiding in resolving logical traps in complex interactions, such as\nmetaphor usage in IT contexts. The path to full realization involves\nformalizing the language of Being by a research team based on Heidegger's\nFundamental Ontology; given the existing completeness of the language of\nbeings, this reduces the system's computability to completeness, paving the way\nfor a universal query analysis tool. The paper presents the system's\narchitecture, operational principles, technical implementation, use\ncases--including a case based on real IT specialist dialogues--comparative\nevaluation with existing tools, and its advantages and limitations.","main_category":"cs.SE","categories":"cs.SE,cs.AI,cs.CL,cs.HC","published":"2025-04-17T14:29:25Z"}
{"aid":"http://arxiv.org/abs/2504.12994v1","title":"Characterization of the $W_{1+\\infty}$-n-algebra and applications","summary":"In this paper, we construct the $W_{1+\\infty}$-n-algebras in the framework of\nthe generalized quantum algebra. We characterize the\n$\\mathcal{R}(p,q)$-multi-variable $W_{1+\\infty}$-algebra and derive its\n$n$-algebra which is the generalized Lie algebra for $n$ even. Furthermore, we\ninvestigate the $\\mathcal{R}(p,q)$-elliptic hermitian matrix model and\ndetermine a toy model for the generalized quantum $W_{\\infty}$ constraints.\nAlso, we deduce particular cases of our results.","main_category":"math-ph","categories":"math-ph,math.MP","published":"2025-04-17T15:02:43Z"}
{"aid":"http://arxiv.org/abs/2504.12998v1","title":"Automated Generation of Commit Messages in Software Repositories","summary":"Commit messages are crucial for documenting software changes, aiding in\nprogram comprehension and maintenance. However, creating effective commit\nmessages is often overlooked by developers due to time constraints and varying\nlevels of documentation skills. Our research presents an automated approach to\ngenerate commit messages using Machine Learning (ML) and Natural Language\nProcessing (NLP) by developing models that use techniques such as Logistic\nRegression with TF-IDF and Word2Vec, as well as more sophisticated methods like\nLSTM. We used the dataset of code changes and corresponding commit messages\nthat was used by Liu et al., which we used to train and evaluate ML/NLP models\nand was chosen because it is extensively used in previous research, also for\ncomparability in our study. The objective was to explore which ML/NLP\ntechniques generate the most effective, clear, and concise commit messages that\naccurately reflect the code changes. We split the dataset into training,\nvalidation, and testing sets and used these sets to evaluate the performance of\neach model using qualitative and quantitative evaluation methods. Our results\nreveal a spectrum of effectiveness among these models, with the highest BLEU\nscore achieved being 16.82, showcasing the models' capability in automating a\nclear and concise commit message generation. Our paper offers insights into the\ncomparative effectiveness of different machine learning models for automating\ncommit message generation in software development, aiming to enhance the\noverall practice of code documentation. The source code is available at\nhttps://doi.org/10.5281/zenodo.10888106.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-17T15:08:05Z"}
{"aid":"http://arxiv.org/abs/2504.13004v1","title":"Calibrating the SIDM Gravothermal Catastrophe with N-body Simulations","summary":"Self-interacting dark matter (SIDM) theories predict that dark matter halos\nexperience core-collapse in late-stage evolution, a process where the halo's\ninner region rapidly increases in density and decreases in size. This process\ncan be modeled by treating the dark matter as a gravothermal fluid, and solving\nthe fluid equations to predict the density profile evolution. This model is\nincomplete without calibration to N-body simulations, through a constant factor\n$\\beta$ included in the thermal conductivity for the long-mean-free-path limit.\nThe value of $\\beta$ employed in the gravothermal fluid formalism has varied\nbetween studies, with no clear universal value in the literature. In this work,\nwe use the N-body code Arepo to conduct a series of isolated core-collapse\nsimulations across a range of scattering cross-sections, halo concentrations,\nand halo masses to calibrate the heat transfer parameter $\\beta$. We find that\n$\\beta$ is independent of cross-section, halo concentration, and halo mass for\nvelocity independent elastic scattering cross-sections. We present a model for\nan effective $\\beta$ as a function of a dimensionless cross-section, to\ndescribe halo evolution in the long mean free path limit, and show that it\naccurately captures halo evolution as long as the cross section is not too\nlarge. This effective model facilitates comparisons between simulations and the\ngravothermal model, and enables fast predictions of the dark matter density\nprofile at any given time without running N-body simulations.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-17T15:14:35Z"}
{"aid":"http://arxiv.org/abs/2504.13005v1","title":"Knot Floer homology of positive braids","summary":"We compute the next-to-top term of knot Floer homology for positive braid\nlinks. The rank is 1 for any prime positive braid knot. We give some examples\nof fibered positive links that are not positive braids.","main_category":"math.GT","categories":"math.GT","published":"2025-04-17T15:15:06Z"}
{"aid":"http://arxiv.org/abs/2504.13016v1","title":"ORIS allocation to minimize the outage probability in a multi-user VLC\n  scenario","summary":"Visible Light Communication (VLC) is a promising solution to address the\ngrowing demand for wireless data, leveraging the widespread use of\nlight-emitting diodes (LEDs) as transmitters. However, its deployment is\nchallenged by link blockages that cause connectivity outages. Optical\nreconfigurable intelligent surfaces (ORISs) have recently emerged as a solution\nto mitigate these disruptions. This work considers a multi-user VLC system and\ninvestigates the optimal association of ORISs to LEDs and users to minimize the\noutage probability while limiting the number of ORISs used. Numerical results\nfrom our proposed optimization algorithm demonstrate that using ORISs can\nreduce the outage probability by up to 85% compared to a no-ORIS scenario.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-17T15:24:25Z"}
{"aid":"http://arxiv.org/abs/2504.13029v1","title":"Three-dimensional canonical quantum plasmonics for finite media: exact\n  solution in terms of the classical Green tensor","summary":"This article presents a comprehensive three-dimensional canonical\nquantization to treat quantum plasmonics for finite metallic or dielectric\nmedia of arbitrary shape. We use a microscopic model for the dissipative and\ndispersive medium coupled with the electromagnetic field, which is justified by\nthe fact that if one integrates the degrees of freedom of the medium, one\nobtains the macroscopic Maxwell equations. Its quantization features a\nHamiltonian formulation having the form of two infinite harmonic oscillators\ncharacterized by a double continuum. The diagonalized Hamiltonian is quantized\nby the correspondence principle, introducing creation-annihilation operators in\na bosonic Fock space. The diagonal quantum Hamiltonian is the sum of two terms\ncorresponding to the two continua. The physical observables, like, e.g., the\nelectric field, are also the sum of two terms corresponding to the two\ncontinua, one of which had been omitted in the literature geared for an\ninfinite bulk medium. In a second step, we show that the electric field\noperator can by written as linear combinations of the creation-annihilation\noperators with coefficients that satisfy integral equations of Fredholm type.\nWe show that the solution of these equations can be expressed in terms of the\nclassical Green tensor of the medium satisfying the Sommerfeld radiation\ncondition. Finally, we consider the Purcell effect for the spontaneous emission\nof an atom close to the medium. We show that through an exact compensation of\nsome terms, the Purcell factor for the system with the double continuum is\nproportional to the imaginary part of the Green tensor, which defines the local\ndensity of states. This result has the same form as the one obtained in the\nliterature for bulk systems that involve a single continuum and a small\ndissipative background extending to infinity, and can be seen as a\njustification of this approach.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T15:39:29Z"}
{"aid":"http://arxiv.org/abs/2504.13032v1","title":"InstructRAG: Leveraging Retrieval-Augmented Generation on Instruction\n  Graphs for LLM-Based Task Planning","summary":"Recent advancements in large language models (LLMs) have enabled their use as\nagents for planning complex tasks. Existing methods typically rely on a\nthought-action-observation (TAO) process to enhance LLM performance, but these\napproaches are often constrained by the LLMs' limited knowledge of complex\ntasks. Retrieval-augmented generation (RAG) offers new opportunities by\nleveraging external databases to ground generation in retrieved information. In\nthis paper, we identify two key challenges (enlargability and transferability)\nin applying RAG to task planning. We propose InstructRAG, a novel solution\nwithin a multi-agent meta-reinforcement learning framework, to address these\nchallenges. InstructRAG includes a graph to organize past instruction paths\n(sequences of correct actions), an RL-Agent with Reinforcement Learning to\nexpand graph coverage for enlargability, and an ML-Agent with Meta-Learning to\nimprove task generalization for transferability. The two agents are trained\nend-to-end to optimize overall planning performance. Our experiments on four\nwidely used task planning datasets demonstrate that InstructRAG significantly\nenhances performance and adapts efficiently to new tasks, achieving up to a\n19.2% improvement over the best existing approach.","main_category":"cs.AI","categories":"cs.AI,cs.IR","published":"2025-04-17T15:41:39Z"}
{"aid":"http://arxiv.org/abs/2504.13034v1","title":"Inference-friendly Graph Compression for Graph Neural Networks","summary":"Graph Neural Networks (GNNs) have demonstrated promising performance in graph\nanalysis. Nevertheless, the inference process of GNNs remains costly, hindering\ntheir applications for large graphs. This paper proposes inference-friendly\ngraph compression (IFGC), a graph compression scheme to accelerate GNNs\ninference. Given a graph $G$ and a GNN $M$, an IFGC computes a small compressed\ngraph $G_c$, to best preserve the inference results of $M$ over $G$, such that\nthe result can be directly inferred by accessing $G_c$ with no or little\ndecompression cost. (1) We characterize IFGC with a class of inference\nequivalence relation. The relation captures the node pairs in $G$ that are not\ndistinguishable for GNN inference. (2) We introduce three practical\nspecifications of IFGC for representative GNNs: structural preserving\ncompression (SPGC), which computes $G_c$ that can be directly processed by GNN\ninference without decompression; ($\\alpha$, $r$)-compression, that allows for a\nconfigurable trade-off between compression ratio and inference quality, and\nanchored compression that preserves inference results for specific nodes of\ninterest. For each scheme, we introduce compression and inference algorithms\nwith guarantees of efficiency and quality of the inferred results. We conduct\nextensive experiments on diverse sets of large-scale graphs, which verifies the\neffectiveness and efficiency of our graph compression approaches.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T15:42:13Z"}
{"aid":"http://arxiv.org/abs/2504.13043v1","title":"Machine Learning Decoding of Circuit-Level Noise for Bivariate Bicycle\n  Codes","summary":"Fault-tolerant quantum computers will depend crucially on the performance of\nthe classical decoding algorithm which takes in the results of measurements and\noutputs corrections to the errors inferred to have occurred. Machine learning\nmodels have shown great promise as decoders for the surface code; however, this\npromise has not yet been substantiated for the more challenging task of\ndecoding quantum low-density parity-check (QLDPC) codes. In this paper, we\npresent a recurrent, transformer-based neural network designed to decode\ncircuit-level noise on Bivariate Bicycle (BB) codes, introduced recently by\nBravyi et al (Nature 627, 778-782, 2024). For the $[[72,12,6]]$ BB code, at a\nphysical error rate of $p=0.1\\%$, our model achieves a logical error rate\nalmost $5$ times lower than belief propagation with ordered statistics decoding\n(BP-OSD). Moreover, while BP-OSD has a wide distribution of runtimes with\nsignificant outliers, our model has a consistent runtime and is an\norder-of-magnitude faster than the worst-case times from a benchmark BP-OSD\nimplementation. On the $[[144,12,12]]$ BB code, our model obtains worse logical\nerror rates but maintains the speed advantage. These results demonstrate that\nmachine learning decoders can out-perform conventional decoders on QLDPC codes,\nin regimes of current interest.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T15:57:16Z"}
{"aid":"http://arxiv.org/abs/2504.13050v1","title":"Radiative properties of a nonsingular black hole: Hawking radiation and\n  gray-body factor","summary":"We study the radiative properties of a spherical and singularity-free\nblack-hole geometry recently proposed in the literature. Contrary to the\nSchwarzschild spacetime, this geometry is geodesically complete and regular,\nand, instead of the singularity, it presents a minimal surface that connects a\ntrapped (black-hole) with an antitrapped (white-hole) region. The geometry is\ncharacterized by two parameters: the Schwarzschild radius and another parameter\nthat measures the area of the minimal surface. This parameter is related to\ncertain corrections expected in the context of loop quantum gravity to the\nclassical general-relativistic dynamics. We explicitly compute the spectrum of\nthe Hawking radiation and the gray-body factor. Since the gravitational\npotential is shallower than in Schwarzschild, the emission spectrum turns out\nbe colder and purer (less gray). From this, we sketch the evaporation history\nof this geometry and conclude that, instead of completely evaporating, it\nnaturally leads to a remnant, which provides a possible resolution of the\ninformation loss issue.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-17T16:07:11Z"}
{"aid":"http://arxiv.org/abs/2504.13075v1","title":"An All-Atom Generative Model for Designing Protein Complexes","summary":"Proteins typically exist in complexes, interacting with other proteins or\nbiomolecules to perform their specific biological roles. Research on\nsingle-chain protein modeling has been extensively and deeply explored, with\nadvancements seen in models like the series of ESM and AlphaFold. Despite these\ndevelopments, the study and modeling of multi-chain proteins remain largely\nuncharted, though they are vital for understanding biological functions.\nRecognizing the importance of these interactions, we introduce APM (All-Atom\nProtein Generative Model), a model specifically designed for modeling\nmulti-chain proteins. By integrating atom-level information and leveraging data\non multi-chain proteins, APM is capable of precisely modeling inter-chain\ninteractions and designing protein complexes with binding capabilities from\nscratch. It also performs folding and inverse-folding tasks for multi-chain\nproteins. Moreover, APM demonstrates versatility in downstream applications: it\nachieves enhanced performance through supervised fine-tuning (SFT) while also\nsupporting zero-shot sampling in certain tasks, achieving state-of-the-art\nresults. Code will be released at https://github.com/bytedance/apm.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T16:37:41Z"}
{"aid":"http://arxiv.org/abs/2504.13084v1","title":"Proca theory of four-dimensional regularized Gauss-Bonnet gravity and\n  black holes with primary hair","summary":"We introduce a novel, well-defined four-dimensional regularized Gauss-Bonnet\ntheory of gravity by applying a dimensional regularization procedure. The\nresulting theory is a vector-tensor theory within the generalized Proca class.\nWe then consider the static spherically symmetric solutions of this theory and\nfind black hole solutions that acquire primary hair. Notably, one of the\nintegration constants associated with the Proca field is not manifest in the\noriginal metric, but under a disformal transformation of the seed solution, it\nemerges as a second, independent primary hair. This additional hair acts as an\neffective cosmological constant in the disformed geometry, even in the absence\nof a bare cosmological constant term. We further generalize these black hole\nsolutions to include electromagnetic charges and effects related to the\nscalar-tensor counterparts of the regularized Gauss-Bonnet theory. We discuss\nthe implications of our findings to observations.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-17T16:51:57Z"}
{"aid":"http://arxiv.org/abs/2504.13118v1","title":"CEERS: Forging the First Dust Grains in the Universe? A Population of\n  Galaxies with spectroscopically-derived Extremely Low Dust Attenuation\n  (GELDA) at 4.0<z<11.4","summary":"Aims: This paper investigates the coevolution of metals and dust for 173\ngalaxies at $4.0<z<11.4$ observed with JWST/NIRSpec in the CEERS project. We\nfocus on galaxies with extremely low dust attenuation to understand the\nphysical mechanisms at play. Methods: We developed a new version of the\n\\texttt{CIGALE} code that integrates spectroscopic and photometric data. By\nstatistically comparing observations with modeled spectra, we derive physical\nparameters to constrain these mechanisms. Results: Our analysis reveals a\npopulation of 49 extremely low dust attenuation galaxies (GELDAs), consistent\nwith $A_{FUV} = 0.0$ within $2\\sigma$ and $M_{\\star} < 10^9 M_\\odot$. The\nstacked spectrum of GELDAs shows a very blue UV slope $\\beta_{FUV} = -2.451 \\pm\n0.066$ and a Balmer decrement H$\\alpha$/H$\\beta = 2.932 \\pm 0.660$, consistent\nwith no dust and Case B recombination with minimal underlying absorption.\nNotably, GELDAs are more prevalent at $z > 8.8$ (83.3\\%) than at lower\nredshifts (26.3\\%), suggesting they could dominate in the early Universe.\n  Using a far-infrared dust spectrum from the ALPINE sample, we study\n$M_{dust}$ vs. $M_{\\star}$ trends. These exhibit upper and lower sequences\nconnected by transitional galaxies. Our comparison with models indicates a\ncritical transition around $M_{\\star} \\approx 10^{8.5}\\,M_\\odot$, from dust\ndominated by stellar sources (SNe and AGB stars) to dust growth via gas\naccretion. This corresponds to a metallicity of $12 + \\log_{10}(O/H) = 7.60$\n($Z/Z_\\odot \\approx 0.1$), aligning with the point where ISM dust growth\nmatches stellar dust production.\n  The sample has a high gas fraction ($f_{\\mathrm{gas}} \\gtrsim 0.9$), with no\nsignificant gas expulsion, and high surface gas densities. This leads to low\nstar formation efficiencies compared to sub-millimeter galaxies. GELDAs may\nhelp explain the observed excess of bright galaxies at $z \\gtrsim 9$.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-17T17:37:14Z"}
{"aid":"http://arxiv.org/abs/2504.13139v1","title":"Syntactic and Semantic Control of Large Language Models via Sequential\n  Monte Carlo","summary":"A wide range of LM applications require generating text that conforms to\nsyntactic or semantic constraints. Imposing such constraints can be naturally\nframed as probabilistic conditioning, but exact generation from the resulting\ndistribution -- which can differ substantially from the LM's base distribution\n-- is generally intractable. In this work, we develop an architecture for\ncontrolled LM generation based on sequential Monte Carlo (SMC). Our SMC\nframework allows us to flexibly incorporate domain- and problem-specific\nconstraints at inference time, and efficiently reallocate computational\nresources in light of new information during the course of generation. By\ncomparing to a number of alternatives and ablations on four challenging domains\n-- Python code generation for data science, text-to-SQL, goal inference, and\nmolecule synthesis -- we demonstrate that, with little overhead, our approach\nallows small open-source language models to outperform models over 8x larger,\nas well as closed-source, fine-tuned ones. In support of the probabilistic\nperspective, we show that these performance improvements are driven by better\napproximation to the posterior distribution. Our system builds on the framework\nof Lew et al. (2023) and integrates with its language model probabilistic\nprogramming language, giving users a simple, programmable way to apply SMC to a\nbroad variety of controlled generation problems.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-17T17:49:40Z"}
{"aid":"http://arxiv.org/abs/2504.13151v1","title":"MIB: A Mechanistic Interpretability Benchmark","summary":"How can we know whether new mechanistic interpretability methods achieve real\nimprovements? In pursuit of meaningful and lasting evaluation standards, we\npropose MIB, a benchmark with two tracks spanning four tasks and five models.\nMIB favors methods that precisely and concisely recover relevant causal\npathways or specific causal variables in neural language models. The circuit\nlocalization track compares methods that locate the model components - and\nconnections between them - most important for performing a task (e.g.,\nattribution patching or information flow routes). The causal variable\nlocalization track compares methods that featurize a hidden vector, e.g.,\nsparse autoencoders (SAEs) or distributed alignment search (DAS), and locate\nmodel features for a causal variable relevant to the task. Using MIB, we find\nthat attribution and mask optimization methods perform best on circuit\nlocalization. For causal variable localization, we find that the supervised DAS\nmethod performs best, while SAE features are not better than neurons, i.e.,\nstandard dimensions of hidden vectors. These findings illustrate that MIB\nenables meaningful comparisons of methods, and increases our confidence that\nthere has been real progress in the field.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-17T17:55:45Z"}
{"aid":"http://arxiv.org/abs/2504.13161v1","title":"CLIMB: CLustering-based Iterative Data Mixture Bootstrapping for\n  Language Model Pre-training","summary":"Pre-training datasets are typically collected from web content and lack\ninherent domain divisions. For instance, widely used datasets like Common Crawl\ndo not include explicit domain labels, while manually curating labeled datasets\nsuch as The Pile is labor-intensive. Consequently, identifying an optimal\npre-training data mixture remains a challenging problem, despite its\nsignificant benefits for pre-training performance. To address these challenges,\nwe propose CLustering-based Iterative Data Mixture Bootstrapping (CLIMB), an\nautomated framework that discovers, evaluates, and refines data mixtures in a\npre-training setting. Specifically, CLIMB embeds and clusters large-scale\ndatasets in a semantic space and then iteratively searches for optimal mixtures\nusing a smaller proxy model and a predictor. When continuously trained on 400B\ntokens with this mixture, our 1B model exceeds the state-of-the-art\nLlama-3.2-1B by 2.0%. Moreover, we observe that optimizing for a specific\ndomain (e.g., Social Sciences) yields a 5% improvement over random sampling.\nFinally, we introduce ClimbLab, a filtered 1.2-trillion-token corpus with 20\nclusters as a research playground, and ClimbMix, a compact yet powerful\n400-billion-token dataset designed for efficient pre-training that delivers\nsuperior performance under an equal token budget. We analyze the final data\nmixture, elucidating the characteristics of an optimal data mixture. Our data\nis available at: https://research.nvidia.com/labs/lpr/climb/","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-17T17:58:13Z"}
{"aid":"http://arxiv.org/abs/2504.14825v1","title":"ECViT: Efficient Convolutional Vision Transformer with Local-Attention\n  and Multi-scale Stages","summary":"Vision Transformers (ViTs) have revolutionized computer vision by leveraging\nself-attention to model long-range dependencies. However, ViTs face challenges\nsuch as high computational costs due to the quadratic scaling of self-attention\nand the requirement of a large amount of training data. To address these\nlimitations, we propose the Efficient Convolutional Vision Transformer (ECViT),\na hybrid architecture that effectively combines the strengths of CNNs and\nTransformers. ECViT introduces inductive biases such as locality and\ntranslation invariance, inherent to Convolutional Neural Networks (CNNs) into\nthe Transformer framework by extracting patches from low-level features and\nenhancing the encoder with convolutional operations. Additionally, it\nincorporates local-attention and a pyramid structure to enable efficient\nmulti-scale feature extraction and representation. Experimental results\ndemonstrate that ECViT achieves an optimal balance between performance and\nefficiency, outperforming state-of-the-art models on various image\nclassification tasks while maintaining low computational and storage\nrequirements. ECViT offers an ideal solution for applications that prioritize\nhigh efficiency without compromising performance.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-21T03:00:17Z"}
{"aid":"http://arxiv.org/abs/2504.14830v1","title":"Solving All Seismic Tomographic Problems using Deep Learning","summary":"In a variety of geoscientific applications scientists often need to image\nproperties of the Earth's interior in order to understand the heterogeneity and\nprocesses taking place within the Earth. Seismic tomography is one such method\nwhich has been used widely to study properties of the subsurface. In order to\nsolve tomographic problems efficiently, neural network-based methods have been\nintroduced to geophysics. However, these methods can only be applied to certain\ntypes of problems with fixed acquisition geometry at a specific site. In this\nstudy we extend neural network-based methods to problems with various scales\nand acquisition geometries by using graph mixture density networks (MDNs). We\ntrain a graph MDN for 2D tomographic problems using simulated velocity models\nand travel time data, and apply the trained network to both synthetic and real\ndata problems that have various scales and station distributions at different\nsites. The results demonstrate that graph MDNs can provide comparable solutions\nto those obtained using traditional Bayesian methods in seconds, and therefore\nprovide the possibility to use graph MDNs to produce rapid solutions for all\nkinds of seismic tomographic problems over the world.","main_category":"physics.geo-ph","categories":"physics.geo-ph,physics.data-an","published":"2025-04-21T03:14:57Z"}
{"aid":"http://arxiv.org/abs/2504.14843v1","title":"Quantitative Measures for Passive Sonar Texture Analysis","summary":"Passive sonar signals contain complex characteristics often arising from\nenvironmental noise, vessel machinery, and propagation effects. While\nconvolutional neural networks (CNNs) perform well on passive sonar\nclassification tasks, they can struggle with statistical variations that occur\nin the data. To investigate this limitation, synthetic underwater acoustic\ndatasets are generated that centered on amplitude and period variations. Two\nmetrics are proposed to quantify and validate these characteristics in the\ncontext of statistical and structural texture for passive sonar. These measures\nare applied to real-world passive sonar datasets to assess texture information\nin the signals and correlate the performances of the models. Results show that\nCNNs underperform on statistically textured signals, but incorporating explicit\nstatistical texture modeling yields consistent improvements. These findings\nhighlight the importance of quantifying texture information for passive sonar\nclassification.","main_category":"eess.AS","categories":"eess.AS","published":"2025-04-21T03:55:49Z"}
{"aid":"http://arxiv.org/abs/2504.14850v1","title":"Charmonium pair production in ultraperipheral collision","summary":"We study the exclusive double charmonium ($J/\\psi \\mbox{-} J/\\psi$ and\n$\\eta_c \\mbox{-} \\eta_c$) production through photon-photon fusion via\nultraperipheral collision (UPC) at the HL-LHC and FCC with next-to-leading\norder (NLO) QCD predictions in the framework of non-relativistic QCD (NRQCD).\nNumerical results indicate that the NLO corrections for $J/\\psi$ pair are large\nand negative, while positive for $\\eta_c$ pair. The total cross section of\n$J/\\psi \\mbox{-} J/\\psi$ ($\\eta_c \\mbox{-} \\eta_c$) in Pb-Pb UPC is 28.0 (65.1)\nnb at nucleon-nucleon c.m. energy $\\sqrt{s_{NN}} = 5.52$ TeV. Due to the\nbackgrounds from various QCD interactions at UPC are highly suppressed and the\nevent topologies for charmonium pair are easy to tag, the phenomenological\nstudies at the LHC and FCC are feasible. The detailed transverse momentum\n$p_T$, diphoton invariant mass $m_{\\gamma\\gamma}$ and the rapidity difference\n$\\Delta y$ distributions are given. The production for X(6900) is also\ndiscussed.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-21T04:15:46Z"}
{"aid":"http://arxiv.org/abs/2504.14852v1","title":"APIRAT: Integrating Multi-source API Knowledge for Enhanced Code\n  Translation with LLMs","summary":"Code translation is an essential task in software migration, multilingual\ndevelopment, and system refactoring. Recent advancements in large language\nmodels (LLMs) have demonstrated significant potential in this task. However,\nprior studies have highlighted that LLMs often struggle with domain-specific\ncode, particularly in resolving cross-lingual API mappings. To tackle this\nchallenge, we propose APIRAT, a novel code translation method that integrates\nmulti-source API knowledge. APIRAT employs three API knowledge augmentation\ntechniques, including API sequence retrieval, API sequence back-translation,\nand API mapping, to guide LLMs to translating code, ensuring both the correct\nstructure of API sequences and the accurate usage of individual APIs. Extensive\nexperiments on two public datasets, CodeNet and AVATAR, indicate that APIRAT\nsignificantly surpasses existing LLM-based methods, achieving improvements in\ncomputational accuracy ranging from 4% to 15.1%. Additionally, our evaluation\nacross different LLMs showcases the generalizability of APIRAT. An ablation\nstudy further confirms the individual contributions of each API knowledge\ncomponent, underscoring the effectiveness of our approach.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-21T04:24:49Z"}
{"aid":"http://arxiv.org/abs/2504.14860v1","title":"Bridge the Gap: From Weak to Full Supervision for Temporal Action\n  Localization with PseudoFormer","summary":"Weakly-supervised Temporal Action Localization (WTAL) has achieved notable\nsuccess but still suffers from a lack of temporal annotations, leading to a\nperformance and framework gap compared with fully-supervised methods. While\nrecent approaches employ pseudo labels for training, three key challenges:\ngenerating high-quality pseudo labels, making full use of different priors, and\noptimizing training methods with noisy labels remain unresolved. Due to these\nperspectives, we propose PseudoFormer, a novel two-branch framework that\nbridges the gap between weakly and fully-supervised Temporal Action\nLocalization (TAL). We first introduce RickerFusion, which maps all predicted\naction proposals to a global shared space to generate pseudo labels with better\nquality. Subsequently, we leverage both snippet-level and proposal-level labels\nwith different priors from the weak branch to train the regression-based model\nin the full branch. Finally, the uncertainty mask and iterative refinement\nmechanism are applied for training with noisy pseudo labels. PseudoFormer\nachieves state-of-the-art WTAL results on the two commonly used benchmarks,\nTHUMOS14 and ActivityNet1.3. Besides, extensive ablation studies demonstrate\nthe contribution of each component of our method.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-21T05:00:07Z"}
{"aid":"http://arxiv.org/abs/2504.14879v1","title":"Impact of Latent Space Dimension on IoT Botnet Detection Performance:\n  VAE-Encoder Versus ViT-Encoder","summary":"The rapid evolution of Internet of Things (IoT) technology has led to a\nsignificant increase in the number of IoT devices, applications, and services.\nThis surge in IoT devices, along with their widespread presence, has made them\na prime target for various cyber-attacks, particularly through IoT botnets. As\na result, security has become a major concern within the IoT ecosystem. This\nstudy focuses on investigating how the latent dimension impacts the performance\nof different deep learning classifiers when trained on latent vector\nrepresentations of the train dataset. The primary objective is to compare the\noutcomes of these models when encoder components from two cutting-edge\narchitectures: the Vision Transformer (ViT) and the Variational Auto-Encoder\n(VAE) are utilized to project the high dimensional train dataset to the learned\nlow dimensional latent space. The encoder components are employed to project\nhigh-dimensional structured .csv IoT botnet traffic datasets to various latent\nsizes. Evaluated on N-BaIoT and CICIoT2022 datasets, findings reveal that\nVAE-encoder based dimension reduction outperforms ViT-encoder based dimension\nreduction for both datasets in terms of four performance metrics including\naccuracy, precision, recall, and F1-score for all models which can be\nattributed to absence of spatial patterns in the datasets the ViT model\nattempts to learn and extract from image instances.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-21T06:15:07Z"}
{"aid":"http://arxiv.org/abs/2504.14893v1","title":"Hardware-based Heterogeneous Memory Management for Large Language Model\n  Inference","summary":"A large language model (LLM) is one of the most important emerging machine\nlearning applications nowadays. However, due to its huge model size and runtime\nincrease of the memory footprint, LLM inferences suffer from the lack of memory\ncapacity in conventional systems consisting of multiple GPUs with a modest\namount of high bandwidth memory. Moreover, since LLM contains many\nbandwidthintensive kernels, only focusing on the memory capacity without\nconsidering the bandwidth incurs a serious performance degradation. To handle\nsuch conflicting memory capacity and bandwidth demands in a cost-effective way,\nthis study investigates the potential of heterogeneous memory systems,\nproposing H2M2. It uses an asymmetric memory architecture consisting of\ncapacity-centric and bandwidthcentric memory with computation units attached to\neach memory device. With the asymmetric memory, we first analyze the effect of\nkernel-memory mapping for the asymmetric memory. Second, we propose a dynamic\nruntime algorithm that finds a mapping solution considering the characteristics\nof LLM operations and the change of footprint during LLM inference. Third, we\nadvocate the need for memory abstraction for the efficient management of the\nasymmetric memory. H2M2 outperforms the conventional homogeneous memory system\nwith LPDDR by 1.46x, 1.55x, and 2.94x speedup in GPT3-175B, Chinchilla-70B, and\nLlama2-70B, respectively.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-21T06:45:41Z"}
{"aid":"http://arxiv.org/abs/2504.14896v1","title":"Vector pulse magnet","summary":"The underlying symmetry of the crystal, electronic structure, and magnetic\nstructure manifests itself in the anisotropy of materials' properties, which is\na central topic of the present condensed matter research. However, it demands\nsuch a considerable effort to fill the explorable space that only a small part\nhas been conquered. We report a vector pulse magnet (VPM) as an alternative\nexperimental technique to control the direction of applied magnetic fields,\nwhich may complement the conventional methods with its characteristic features.\nThe VPM combines a conventional pulse magnet and a vector magnet. The VPM can\ncreate vector pulsed magnetic fields and swiftly rotating pulsed magnetic\nfields. As a demonstration, the three-dimensional magnetoresistance measurement\nof a highly oriented pyrolytic graphite is carried out using the AC four-probe\nmethod at 4.5 K and 6 T. The two-dimensional electronic structure of graphite\nis visualized in the three-dimensional magnetoresistance data. One can uncover\nthe rotational and time-reversal symmetry of materials using a VPM and a\nvariety of measurement techniques.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-21T07:05:33Z"}
{"aid":"http://arxiv.org/abs/2504.14910v1","title":"Erratic non-Hermitian skin localization","summary":"A novel localization phenomenon, termed erratic non-Hermitian skin\nlocalization, has been identified in disordered globally-reciprocal\nnon-Hermitian lattices. Unlike conventional non-Hermitian skin effect and\nAnderson localization, it features macroscopic eigenstate localization at\nirregular, disorder-dependent positions with sub-exponential decay. Using the\nHatano-Nelson model with disordered imaginary gauge fields as a case study,\nthis effect is linked to stochastic interfaces governed by the universal order\nstatistics of random walks. Finite-size scaling analysis confirms the localized\nnature of the eigenstates. This discovery challenges conventional wave\nlocalization paradigms, offering new avenues for understanding and controlling\nlocalization phenomena in non-Hermitian physics.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,physics.optics,quant-ph","published":"2025-04-21T07:27:59Z"}
{"aid":"http://arxiv.org/abs/2504.14935v1","title":"An elementary definition of opetopic sets","summary":"We propose elementary definitions of opetopes and opetopic sets. We directly\ndefine opetopic sets by a simple structure and several axioms. Opetopes are\nthen opetopic sets satisfying one more axiom. We show that our definition is\nequivalent to the polynomial monad definition given by Kock, Joyal, Batanin,\nand Mascari. We also show that our category of opetopes is equivalent to the\none given by Ho Thanh.","main_category":"math.CT","categories":"math.CT","published":"2025-04-21T07:56:23Z"}
{"aid":"http://arxiv.org/abs/2504.14956v1","title":"Considerations on the Design of Transceivers for Ambient Internet of\n  Things","summary":"The Ambient IoT (A-IoT) will introduce trillions of connections and enable\nlow-cost battery-less devices. The A-IoT nodes can achieve low cost ($\\sim \\$\n0.1$ like RFID tag), sub-1mW average power consumption, $\\leq 10$ kbps data\nrates, maintenance-free working for decades, cm-scale size, cm-scale size, and\nsupporting applications like supply chain and smart agriculture. The\ntransceiver challenges in A-IoT focus on sub-mW receivers and crystal-less\nclock generation. The paper proposes an \"approximate low-IF\" receiver and\n\"carrier-auxiliary IF feedback\" LO synthesizer architecture for Type-B/C A-IoT\ndevices, which tracks the RF carrier frequency and eliminates external\ncrystals. The proposed receiver and LO generator are implemented using 55nm\nCMOS technology. After locking the LO calibration loop, the receiver\nsensitivity is better than -88 dBm. The proposed receiver architecture will\npromote \"zero power\" devices for ubiquitous IoT connectivity, bridging digital\nand physical worlds.","main_category":"eess.SY","categories":"eess.SY,cs.AR,cs.SY","published":"2025-04-21T08:31:41Z"}
{"aid":"http://arxiv.org/abs/2504.14959v1","title":"ScaleGuard: Rational and Scalable Configuration Privacy Protection with\n  Topology Expansion","summary":"As networks grow in size and complexity, safeguarding sensitive data while\nsharing configuration files is critical for network management and research.\nExisting anonymization tools primarily hide fields like IP addresses or AS\nnumbers to mitigate direct data exposure. However, they often lack mechanisms\nto preserve privacy around network scale, an increasingly sensitive aspect that\ncan reveal organizational size or resource distribution. We propose ScaleGuard,\nwhich preserves network functional equivalence while adding fake routers and\nhosts to conceal network scale, and generating complete router configurations\nthat resemble the originals. Our system introduces a graph embedding-based\nexpansion method and k-degree mapping anonymity, reducing unnecessary topology\nmodifications when adversaries only know the original degree sequence. For\nrouting repair, ScaleGuard designs a network repair framework combining SMT and\niterative methods, delivering stable performance under randomized link costs\nand complex cross-protocol routing. Experiment results show that ScaleGuard\nexpands network scale effectively, providing consistent anonymization of\ntopology, scale, and routing, while achieving strong topological rationality,\nconfiguration fidelity, and repairing efficiency.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-21T08:38:52Z"}
{"aid":"http://arxiv.org/abs/2504.14982v1","title":"Understanding the Valence Quark Structure of the Pion through GTMDs","summary":"We investigate the internal structure of the pion using generalized\ntransverse momentum-dependent parton distributions (GTMDs) within the\nlight-cone quark model. By solving the quark-quark correlator, we derive the\ntwist-$2$, $3$, and $4$ quark GTMDs in terms of light-front wave functions\n(LFWFs). Out of the $16$ possible GTMDs, $12$ are found to be nonzero.\nFurthermore, we extract the valence quark transverse momentum-dependent parton\ndistributions (TMDs) and generalized parton distributions (GPDs) from their\ncorresponding GTMDs. Additionally, we compute the valence quark electromagnetic\nform factors (FFs) and parton distribution functions (PDFs) up to twist-$4$.\nThe elastic charge radius of the pion is determined to be $0.558$ fm. Our\nresults exhibit a qualitative agreement with predictions from other theoretical\nmodel like Nambu-Jona-Lasinio model, Light-front holographic model, and\nspectator model at the leading twist. This study provides a comprehensive\ninsight into the internal structure of the pion.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-21T09:19:15Z"}
{"aid":"http://arxiv.org/abs/2504.14984v1","title":"A New Formation Mechanism of Counterstreaming Mass Flows in Filaments\n  and the Doppler Bullseye Pattern in Prominences","summary":"The eruption of solar prominences can eject substantial mass and magnetic\nfield into interplanetary space and cause geomagnetic storms. However, various\nquestions about prominences and their eruption mechanism remain unclear. In\nparticular, what causes the intriguing Doppler bullseye pattern in prominences\nhas not yet been solved, despite some preliminary studies proposing that they\nare probably associated with counterstreaming mass flows. Previous studies are\nmainly based on single-angle and short timescale observations, making it\ndifficult to determine the physical origin of Doppler bullseye patterns in\nprominences. Here, taking advantage of stereoscopic observations taken by the\nSolar Dynamics Observatory and the Solar Terrestrial Relations Observatory and\na three-dimensional numerical simulation, we investigate the origin of\nprominence Doppler bullseye pattern by tracing a long-lived transequatorial\nfilament/prominence from July 23 to August 4, 2012. We find that repeated\ncoronal jets at one end of the prominence can launch the Doppler bullseye\npattern. It is evidenced in our observations and simulation that during the\nforward traveling of jet plasma along the helical magnetic field structure of\nthe prominence, part of the ejecting plasma can not pass through the apex of\nthe prominence due to the insufficient kinetic energy and therefore forms a\nbackward-moving mass flow along the same or neighboring magnetic field lines.\nThis process finally forms counterstreaming mass flows in on-disk filaments.\nWhen the on-disk filament rotates to the solar limb to be a prominence, the\ncounterstreaming mass flows are naturally observed as a Doppler bullseye\npattern.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-21T09:24:50Z"}
{"aid":"http://arxiv.org/abs/2504.15019v1","title":"Feedback Stackelberg-Nash equilibria in difference games with\n  quasi-hierarchical interactions and inequality constraints","summary":"In this paper, we study a class of two-player deterministic finite-horizon\ndifference games with coupled inequality constraints, where each player has two\ntypes of decision variables: one involving sequential interactions and the\nother simultaneous interactions. We refer to these as quasi-hierarchical\ndynamic games and define a solution concept called the feedback\nStackelberg-Nash (FSN) equilibrium. Under a separability assumption on cost\nfunctions, we formulate FSN solutions recursively using a dynamic\nprogramming-like approach. We further show that the FSN solution for these\nconstrained games can be derived from the parametric feedback Stackelberg\nsolution of an associated unconstrained game with only sequential interactions,\ngiven parameter choices that satisfy implicit complementarity conditions. For\nthe linear-quadratic case, we show that the FSN solutions are obtained by\nreformulating these complementarity conditions as a single large-scale linear\ncomplementarity problem. Finally, we illustrate our results with a dynamic\nduopoly game with production constraints.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-21T11:05:03Z"}
{"aid":"http://arxiv.org/abs/2504.15025v1","title":"Quantum pseudoresources imply cryptography","summary":"While one-way functions (OWFs) serve as the minimal assumption for\ncomputational cryptography in the classical setting, in quantum cryptography,\nwe have even weaker cryptographic assumptions such as pseudo-random states, and\nEFI pairs, among others. Moreover, the minimal assumption for computational\nquantum cryptography remains an open question. Recently, it has been shown that\npseudoentanglement is necessary for the existence of quantum cryptography\n(Goul\\~ao and Elkouss 2024), but no cryptographic construction has been built\nfrom it.\n  In this work, we study the cryptographic usefulness of quantum\npseudoresources -- a pair of families of quantum states that exhibit a gap in\ntheir resource content yet remain computationally indistinguishable. We show\nthat quantum pseudoresources imply a variant of EFI pairs, which we call EPFI\npairs, and that these are equivalent to quantum commitments and thus EFI pairs.\nOur results suggest that, just as randomness is fundamental to classical\ncryptography, quantum resources may play a similarly crucial role in the\nquantum setting.\n  Finally, we focus on the specific case of entanglement, analyzing different\ndefinitions of pseudoentanglement and their implications for constructing EPFI\npairs. Moreover, we propose a new cryptographic functionality that is\nintrinsically dependent on entanglement as a resource.","main_category":"quant-ph","categories":"quant-ph,cs.CR","published":"2025-04-21T11:17:30Z"}
{"aid":"http://arxiv.org/abs/2504.15029v1","title":"Story of an architecturally suggestive polyhedron: from medieval trade\n  to Renaissance art and modern design","summary":"We describe a balance weight dated to the Early Islamic Period from the Hecht\nMuseum at the University of Haifa (Israel) Its polyhedral shape was attributed\nto a truncated elongated octagonal bipyramid. To our knowledge, the earliest\nRenaissance book containing the image of this polyhedron is \"La Pratica di\nProspettiva\" published in 1596 by Florentine architect and perspective artist\nLorenzo Sirigatti. We described an outline of Sirigatti life and the importance\nof his book for scientists and artists, Galileo Galilei among them. We depict\nexamples of lamps and lanterns in European cities shaped as the truncated\nelongated octagonal bipyramid, as well as a drawing by Raphael with a lantern\nof a similar form. Finally, we discussed why the artist chose this particular\npolyhedron for his drawing.","main_category":"math.HO","categories":"math.HO","published":"2025-04-21T11:33:41Z"}
{"aid":"http://arxiv.org/abs/2504.15054v1","title":"Structure-guided Diffusion Transformer for Low-Light Image Enhancement","summary":"While the diffusion transformer (DiT) has become a focal point of interest in\nrecent years, its application in low-light image enhancement remains a blank\narea for exploration. Current methods recover the details from low-light images\nwhile inevitably amplifying the noise in images, resulting in poor visual\nquality. In this paper, we firstly introduce DiT into the low-light enhancement\ntask and design a novel Structure-guided Diffusion Transformer based Low-light\nimage enhancement (SDTL) framework. We compress the feature through wavelet\ntransform to improve the inference efficiency of the model and capture the\nmulti-directional frequency band. Then we propose a Structure Enhancement\nModule (SEM) that uses structural prior to enhance the texture and leverages an\nadaptive fusion strategy to achieve more accurate enhancement effect. In\nAddition, we propose a Structure-guided Attention Block (SAB) to pay more\nattention to texture-riched tokens and avoid interference from noisy areas in\nnoise prediction. Extensive qualitative and quantitative experiments\ndemonstrate that our method achieves SOTA performance on several popular\ndatasets, validating the effectiveness of SDTL in improving image quality and\nthe potential of DiT in low-light enhancement tasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T12:30:01Z"}
{"aid":"http://arxiv.org/abs/2504.15058v1","title":"One Dimensional Asymptotic Plateau Problem in $n$-Dimensional\n  Asymptotically Conical Manifolds","summary":"Let $(M,g)$ be an asymptotically conical Riemannian manifold having dimension\n$n\\ge 2$, opening angle $\\alpha \\in (0,\\pi/2) \\setminus \\{\\arcsin\n\\frac{1}{2k+1}\\}_{k \\in \\mathbb{N}}$ and positive asymptotic rate. Under the\nassumption that the exponential map is proper at each point, we give a solution\nto the one dimensional asymptotic Plateau problem on $M$. Precisely, for any\npair of antipodal points in the ideal boundary $\\partial_\\infty M = \\mathbb\nS^{n-1}$, we prove the existence of a geodesic line with asymptotic prescribed\nboundaries and the Morse index $\\le n-1$.","main_category":"math.DG","categories":"math.DG","published":"2025-04-21T12:36:07Z"}
{"aid":"http://arxiv.org/abs/2504.15076v1","title":"Note on Type $III_1$ Algebras in $ c= 1$ String Theory and Bulk Causal\n  Diamonds","summary":"We argue that the Leutheusser-Liu procedure of isolating a von Neumann\nalgebra in the $N = \\infty$ limit of string theories, leads to the algebra of\nrelativistic fermion fields on a half line for the $c = 1$ string theory. This\nis a Type $I$ von Neumann algebra, since it is the algebra of the Rindler wedge\nin the Rindler vacuum state. Subalgebras of finite regions are Type $III_1$.\nThe argument uses the elegant results of Moore and of Alexandrov, Kazakov and\nKostov. This model is well known to be integrable and have no black hole\nexcitations. We have speculated that adding an interaction invisible in\nperturbation theory to a large finite number, $M$, of copies of the model,\nproduces a non-integrable model with meta-stable excitations having all of the\nproperties of linear dilaton black holes. The algebra of fields is the tensor\nproduct of $M$ copies of the $c = 1$ model's algebra, whether or not we add the\nnon-integrable interaction. We argue that the infinite dimensional $c = 1$\nalgebras are analogous to those of the boundary field theory in AdS/CFT, even\nthough they appear to encode bulk causal structure. An IR cutoff on the\nboundary renders them finite and causal structure must be formulated in terms\nof an analog of the Tensor Network Renormalization Group. This is a time\ndependent Hamiltonian flow, embedding smaller Hilbert spaces into larger ones.\nIt is the analog of one sided modular inclusion in quantum field theory.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-21T13:04:09Z"}
{"aid":"http://arxiv.org/abs/2504.15098v1","title":"Optimal Behavior Planning for Implicit Communication using a\n  Probabilistic Vehicle-Pedestrian Interaction Model","summary":"In interactions between automated vehicles (AVs) and crossing pedestrians,\nmodeling implicit vehicle communication is crucial. In this work, we present a\ncombined prediction and planning approach that allows to consider the influence\nof the planned vehicle behavior on a pedestrian and predict a pedestrian's\nreaction. We plan the behavior by solving two consecutive optimal control\nproblems (OCPs) analytically, using variational calculus. We perform a\nvalidation step that assesses whether the planned vehicle behavior is adequate\nto trigger a certain pedestrian reaction, which accounts for the closed-loop\ncharacteristics of prediction and planning influencing each other. In this\nstep, we model the influence of the planned vehicle behavior on the pedestrian\nusing a probabilistic behavior acceptance model that returns an estimate for\nthe crossing probability. The probabilistic modeling of the pedestrian reaction\nfacilitates considering the pedestrian's costs, thereby improving cooperative\nbehavior planning. We demonstrate the performance of the proposed approach in\nsimulated vehicle-pedestrian interactions with varying initial settings and\nhighlight the decision making capabilities of the planning approach.","main_category":"cs.HC","categories":"cs.HC,cs.SY,eess.SY","published":"2025-04-21T13:38:37Z"}
{"aid":"http://arxiv.org/abs/2504.15109v1","title":"New Heintze-Karcher type inequalities in sub-static warped product\n  manifolds","summary":"In this paper, we prove Heintze-Karcher type inequalities involving the\nshifted mean curvature for smooth bounded domains in certain sub-static warped\nproduct manifolds. In particular, we prove a Heintze-Karcher-type inequality\nfor non mean-convex domains in the hyperbolic space. As applications, we obtain\nuniqueness results for hypersurfaces satisfying a class of curvature equations.","main_category":"math.DG","categories":"math.DG","published":"2025-04-21T14:02:09Z"}
{"aid":"http://arxiv.org/abs/2504.15132v1","title":"Investigating Youth's Technical and Ethical Understanding of Generative\n  Language Models When Engaging in Construction and Deconstruction Activities","summary":"The widespread adoption of generative artificial intelligence/machine\nlearning (AI/ML) technologies has increased the need to support youth in\ndeveloping AI/ML literacies. However, most work has centered on preparing young\npeople to use these systems, with less attention to how they can participate in\ndesigning and evaluating them. This study investigates how engaging young\npeople in the design and auditing of generative language models (GLMs) may\nfoster the development of their understanding of how these systems work from\nboth technical and ethical perspectives. The study takes an in-pieces approach\nto investigate novices' conceptions of GLMs. Such an approach supports the\nanalysis of how technical and ethical conceptions evolve and relate to each\nother. I am currently conducting a series of participatory design workshops\nwith sixteen ninth graders (ages 14-15) in which they will (a) build GLMs from\na data-driven perspective that glassboxes how data shapes model performance and\n(b) audit commercial GLMs by repeatedly and systematically querying them to\ndraw inferences about their behaviors. I will analyze participants'\ninteractions to identify ethical and technical conceptions they may exhibit\nwhile designing and auditing GLMs. I will also conduct clinical interviews and\nuse microgenetic knowledge analysis and ordered network analysis to investigate\nhow participants' ethical and technical conceptions of GLMs relate to each\nother and change after the workshop. The study will contribute (a) evidence of\nhow engaging youth in design and auditing activities may support the\ndevelopment of ethical and technical understanding of GLMs and (b) an inventory\nof novice design and auditing practices that may support youth's technical and\nethical understanding of GLMs.","main_category":"cs.HC","categories":"cs.HC,cs.CY","published":"2025-04-21T14:30:16Z"}
{"aid":"http://arxiv.org/abs/2504.15146v1","title":"Behavioral Universe Network (BUN): A Behavioral Information-Based\n  Framework for Complex Systems","summary":"Modern digital ecosystems feature complex, dynamic interactions among\nautonomous entities across diverse domains. Traditional models often separate\nagents and objects, lacking a unified foundation to capture their interactive\nbehaviors. This paper introduces the Behavioral Universe Network (BUN), a\ntheoretical framework grounded in the Agent-Interaction-Behavior (AIB)\nformalism. BUN treats subjects (active agents), objects (resources), and\nbehaviors (operations) as first-class entities, all governed by a shared\nBehavioral Information Base (BIB). We detail the AIB core concepts and\ndemonstrate how BUN leverages information-driven triggers, semantic enrichment,\nand adaptive rules to coordinate multi-agent systems. We highlight key\nbenefits: enhanced behavior analysis, strong adaptability, and cross-domain\ninteroperability. We conclude by positioning BUN as a promising foundation for\nnext-generation digital governance and intelligent applications.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-21T14:50:28Z"}
{"aid":"http://arxiv.org/abs/2504.15152v1","title":"Landmark-Free Preoperative-to-Intraoperative Registration in\n  Laparoscopic Liver Resection","summary":"Liver registration by overlaying preoperative 3D models onto intraoperative\n2D frames can assist surgeons in perceiving the spatial anatomy of the liver\nclearly for a higher surgical success rate. Existing registration methods rely\nheavily on anatomical landmark-based workflows, which encounter two major\nlimitations: 1) ambiguous landmark definitions fail to provide efficient\nmarkers for registration; 2) insufficient integration of intraoperative liver\nvisual information in shape deformation modeling. To address these challenges,\nin this paper, we propose a landmark-free preoperative-to-intraoperative\nregistration framework utilizing effective self-supervised learning, termed\n\\ourmodel. This framework transforms the conventional 3D-2D workflow into a\n3D-3D registration pipeline, which is then decoupled into rigid and non-rigid\nregistration subtasks. \\ourmodel~first introduces a feature-disentangled\ntransformer to learn robust correspondences for recovering rigid\ntransformations. Further, a structure-regularized deformation network is\ndesigned to adjust the preoperative model to align with the intraoperative\nliver surface. This network captures structural correlations through geometry\nsimilarity modeling in a low-rank transformer network. To facilitate the\nvalidation of the registration performance, we also construct an in-vivo\nregistration dataset containing liver resection videos of 21 patients, called\n\\emph{P2I-LReg}, which contains 346 keyframes that provide a global view of the\nliver together with liver mask annotations and calibrated camera intrinsic\nparameters. Extensive experiments and user studies on both synthetic and\nin-vivo datasets demonstrate the superiority and potential clinical\napplicability of our method.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-21T14:55:57Z"}
{"aid":"http://arxiv.org/abs/2504.15157v1","title":"Reconfiguring Proportional Committees","summary":"An important desideratum in approval-based multiwinner voting is\nproportionality. We study the problem of reconfiguring proportional committees:\ngiven two proportional committees, is there a transition path that consists\nonly of proportional committees, where each transition involves replacing one\ncandidate with another candidate? We show that the set of committees satisfying\nthe proportionality axiom of justified representation (JR) is not always\nconnected, and it is PSPACE-complete to decide whether two such committees are\nconnected. On the other hand, we prove that any two JR committees can be\nconnected by committees satisfying a $2$-approximation of JR. We also obtain\nsimilar results for the stronger axiom of extended justified representation\n(EJR). In addition, we demonstrate that the committees produced by several\nwell-known voting rules are connected or at least not isolated, and investigate\nthe reconfiguration problem in restricted preference domains.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-21T15:03:19Z"}
{"aid":"http://arxiv.org/abs/2504.15158v1","title":"Interacting Copies of Random Constraint Satisfaction Problems","summary":"We study a system of $y=2$ coupled copies of a well-known constraint\nsatisfaction problem (random hypergraph bicoloring) to examine how the\nferromagnetic coupling between the copies affects the properties of the\nsolution space. We solve the replicated model by applying the cavity method to\nthe supervariables taking $2^y$ values. Our results show that a coupling of\nstrength $\\gamma$ between the copies decreases the clustering threshold\n$\\alpha_d(\\gamma)$, at which typical solutions shatters into disconnected\ncomponents, therefore preventing numerical methods such as Monte Carlo Markov\nChains from reaching equilibrium in polynomial time. This result needs to be\nreconciled with the observation that, in models with coupled copies, denser\nregions of the solution space should be more accessible. Additionally, we\nobserve a change in the nature of the clustering phase transition, from\ndiscontinuous to continuous, in a wide $\\gamma$ range. We investigate how the\ncoupling affects the behavior of the Belief Propagation (BP) algorithm on\nfinite-size instances and find that BP convergence is significantly impacted by\nthe continuous transition. These results highlight the importance of better\nunderstanding algorithmic performance at the clustering transition, and call\nfor a further exploration into the optimal use of re-weighting strategies\ndesigned to enhance algorithmic performances.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.stat-mech","published":"2025-04-21T15:05:18Z"}
{"aid":"http://arxiv.org/abs/2504.15167v1","title":"Almost-perfect colorful matchings in three-edge-colored bipartite graphs","summary":"We prove that, for positive integers $n,a_1, a_2, a_3$ satisfying\n$a_1+a_2+a_3 = n-1$, it holds that any bipartite graph $G$ which is the union\nof three perfect matchings $M_1$, $M_2$, and $M_3$ on $2n$ vertices contains a\nmatching $M$ such that $|M\\cap M_i| =a_i$ for $i= 1,2,$ and $3$. The bound\n$n-1$ on the sum is best possible in general. Our result verifies the\nmultiplicity extension of the Ryser-Brualdi-Stein Conjecture, proposed recently\nby Anastos, Fabian, M\\\"uyesser, and Szab\\'o, for three colors.","main_category":"math.CO","categories":"math.CO","published":"2025-04-21T15:22:13Z"}
{"aid":"http://arxiv.org/abs/2504.15168v1","title":"On true empty category","summary":"According to Chomsky (1981, 1986), empty categories consist of PRO, pro,\ntrace, and variable. However, some empty object positions seem to be\nincompatible with extant empty categories. Given this, Li (2007a, 2007b, 2014)\nand Li & Wei (2014) raise the true empty category hypothesis, which holds that\ntrue empty category is only an empty position with category and Case features.\nAs a last resort option, it is used mainly to meet the subcatgorization of a\nverb. This assumption is ingenious, and if proved to be true, it will exert a\ngreat impact on the study of UG. In this paper, we evaluate their evidence from\ntopicalization and demonstrate that it can be accounted for without invoking\ntrue empty category.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-21T15:22:21Z"}
{"aid":"http://arxiv.org/abs/2504.15191v1","title":"Aerodynamic Control of Laminar Separation on a Wall-Bounded Airfoil at\n  Transitional Reynolds Numbers","summary":"Experiments were conducted in a low-turbulence wind tunnel to investigate the\nefficacy of localised acoustic forcing upon the dynamics and stability of the\nflow on a cambered, wall-bounded airfoil over a range of Reynolds numbers (Re)\nwhere the flow state can switch between two limits -- a low-lift state (SI)\nwhere separation continues beyond the trailing edge and a high-lift state (SII)\nwhere the separated flow is closed off to form a laminar separation bubble. The\nswitching between SI and SII can occur close to a critical angle of attack\n($\\alpha_{\\textrm{crit}}$) which varies with $\\textrm{Re}$. The most effective\nforcing frequencies are found at a constant value of a rescaled Strouhal\nnumber, $\\textrm{St}^* = \\textrm{St}/\\textrm{Re}^{1/2}= 0.027$, which indicates\nthat though the primary unstable modes of the separated shear layer are of the\ninviscid, Kelvin-Helmholtz type, these modes are seeded by length scales that\noriginate in the laminar (viscous) boundary layer. The most effective chordwise\nforcing location varies with $\\textrm{St}/\\textrm{Re}^{1/2}$ and incidence\nangle, $\\alpha$, and is always upstream of the separation point. Although the\nboundary layer flows are far from two-dimensional, forcing at a fixed chord\nlocation across all spanwise locations is effective in controlling the SI --\nSII transition. Strategies for active and passive feedback control are\nsuggested.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-21T16:01:41Z"}
{"aid":"http://arxiv.org/abs/2504.15195v1","title":"Arc K-semistability is a very general property","summary":"We prove that arc K-semistability is a very general property in flat families\nof polarised varieties, and prove a similar result for uniform arc K-stability.\nThis can be used to produce the only current examples of smooth uniformly arc\nK-stable varieties which are not known to admit a constant scalar curvature\nK\\\"ahler metric. Our technique is to prove a general result stating that\nsemistability of a pair in the sense of Paul is a Zariski open property, and to\nemploy prior work with Reboulet relating arc K-semistability to semistability\nof an associated pair.","main_category":"math.AG","categories":"math.AG,math.DG","published":"2025-04-21T16:07:21Z"}
{"aid":"http://arxiv.org/abs/2504.15213v1","title":"Community detection in hypergraphs through hyperedge percolation","summary":"Complex networks, representing the connections between the constituents of\nlarge complex systems, are often characterised by a community structure, with\ncommunities corresponding to denser sub-graphs in which nodes are closely\nlinked. When modelling systems where interactions extend beyond node pairs to\ninvolve arbitrary numbers of nodes, hypergraphs become necessary, creating a\nneed for specialised community detection methods. Here, we adapt the classical\n$k$-clique percolation method to hypergraphs, building communities from\nhyperedges containing at least $k$ nodes, defining hyperedge adjacency\nsimilarly to clique adjacency in the original algorithm. Although the analogy\nbetween the proposed hyperedge percolation method and the classical clique\npercolation algorithm is evident, we show that communities obtained directly\nfrom the hyperedges can differ from those identified by the clique percolation\nmethod in the pairwise projection of the hypergraph. We also propose an\nalternative way for uniting hyperedges into communities, where instead of\nlimiting the cardinality of the considered hyperedges from below, we restrict\nthe size of the largest hyperedges that can be added to a community. This\nalternative algorithm is better suited to hypergraphs where larger edges\nrealise weaker linkages between the nodes. After comparing the suggested two\napproaches on simple synthetic hypergraphs constructed to highlight their\ndifferences, we test them on hypergraphs generated with a newly proposed\ngeometric process on the hyperbolic plane, as well as on some real-world\nexamples.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-21T16:35:24Z"}
{"aid":"http://arxiv.org/abs/2504.15234v1","title":"Equivariant quasisymmetry and noncrossing partitions","summary":"We introduce a definition of ``equivariant quasisymmetry'' for polynomials in\ntwo sets of variables. Using this definition we define quasisymmetric\ngeneralizations of the theory of double Schur and double Schubert polynomials\nthat we call double fundamental polynomials and double forest polynomials,\nwhere the subset of ``noncrossing partitions'' plays the role of $S_n$. In\nsubsequent work we will show this combinatorics is governed by a new geometric\nconstruction we call the ``quasisymmetric flag variety'' which plays the same\nrole for equivariant quasisymmetry as the usual flag variety plays in the\nclassical story.","main_category":"math.CO","categories":"math.CO,math.AG","published":"2025-04-21T17:09:52Z"}
{"aid":"http://arxiv.org/abs/2504.15242v1","title":"Modified Kantorovich-type Sampling Series in Orlicz Space Frameworks","summary":"This study examines a modified Kantorovich approach applied to generalized\nsampling series. The paper establishes that the approximation order to a\nfunction using these modified operators is atleast as good as that achieved by\nclassical methods by using some graphs. The analysis focuses on these series\nwithin the context of Orlicz space \\( L^{\\eta}(\\mathbb{R}) \\), specifically\nlooking at irregularly spaced samples. This is crucial for real-world\napplications, especially in fields like signal processing and computational\nmathematics, where samples are often not uniformly spaced. The paper also\nestablishes a result on modular convergence for functions \\( g \\in\nL^{\\eta}(\\mathbb{R}) \\), which includes specific cases like convergence in \\(\nL^{p}(\\mathbb{R}) \\)-spaces, \\( L \\log L \\)-spaces, and exponential spaces. The\nstudy then explores practical applications of the modified sampling series,\nnotably for discontinuous functions and provides graphs to illustrate the\nresults.","main_category":"math.FA","categories":"math.FA","published":"2025-04-21T17:15:44Z"}
{"aid":"http://arxiv.org/abs/2504.15243v1","title":"Single-loop Algorithms for Stochastic Non-convex Optimization with\n  Weakly-Convex Constraints","summary":"Constrained optimization with multiple functional inequality constraints has\nsignificant applications in machine learning. This paper examines a crucial\nsubset of such problems where both the objective and constraint functions are\nweakly convex. Existing methods often face limitations, including slow\nconvergence rates or reliance on double-loop algorithmic designs. To overcome\nthese challenges, we introduce a novel single-loop penalty-based stochastic\nalgorithm. Following the classical exact penalty method, our approach employs a\n{\\bf hinge-based penalty}, which permits the use of a constant penalty\nparameter, enabling us to achieve a {\\bf state-of-the-art complexity} for\nfinding an approximate Karush-Kuhn-Tucker (KKT) solution. We further extend our\nalgorithm to address finite-sum coupled compositional objectives, which are\nprevalent in artificial intelligence applications, establishing improved\ncomplexity over existing approaches. Finally, we validate our method through\nexperiments on fair learning with receiver operating characteristic (ROC)\nfairness constraints and continual learning with non-forgetting constraints.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-21T17:15:48Z"}
{"aid":"http://arxiv.org/abs/2504.15264v1","title":"Sunflowers and Ramsey problems for restricted intersections","summary":"Extremal problems on set systems with restricted intersections have been an\nimportant part of combinatorics in the last 70 year. In this paper, we study\nthe following Ramsey version of these problems. Given a set $L\\subseteq\n\\{0,\\dots,k-1\\}$ and a family $\\mathcal{F}$ of $k$-element sets which does not\ncontain a sunflower with $m$ petals whose kernel size is in $L$, how large a\nsubfamily of $\\mathcal{F}$ can we find in which no pair has intersection size\nin $L$? We give matching upper and lower bounds, determining the dependence on\n$m$ for all $k$ and $L$. This problem also finds applications in quantum\ncomputing.\n  As an application of our techniques, we also obtain a variant of F\\\"uredi's\ncelebrated semilattice lemma, which is a key tool in the powerful delta-system\nmethod. We prove that one cannot remove the double-exponential dependency on\nthe uniformity in F\\\"uredi's result, however, we provide an alternative with\nsignificantly better, single-exponential dependency on the parameters, which is\nstill strong enough for most applications of the delta-system method.","main_category":"math.CO","categories":"math.CO,cs.DM,quant-ph","published":"2025-04-21T17:46:21Z"}
{"aid":"http://arxiv.org/abs/2504.15274v1","title":"Is Dynamical Dark Energy Necessary? DESI BAO and Modified Recombination","summary":"Recent measurements of baryon acoustic oscillations (BAO) by the Dark Energy\nSpectroscopic Instrument (DESI) exhibit a mild-to-moderate tension with cosmic\nmicrowave background (CMB) and Type Ia supernova (SN) observations when\ninterpreted within a flat $\\Lambda$CDM framework. This discrepancy has been\ncited as evidence for dynamical dark energy (DDE). Given the profound\nimplications of DDE for fundamental physics, we explore whether the tension can\ninstead be resolved by modifying the physics of recombination. We find that a\nphenomenological model of modified recombination can effectively reconcile the\nBAO and CMB datasets and, unlike DDE, also predicts a higher Hubble constant\n$H_0$, thereby partially alleviating the Hubble tension. A global fit to BAO,\nCMB, and calibrated SN data clearly favors modified recombination over DDE,\nsuggesting that current claims of a DDE detection may be premature.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-21T17:58:14Z"}
{"aid":"http://arxiv.org/abs/2504.15569v1","title":"Centers of perfectoid purity","summary":"We introduce a mixed characteristic analog of log canonical centers in\ncharacteristic $0$ and centers of $F$-purity in positive characteristic, which\nwe call centers of perfectoid purity. We show that their existence detects (the\nfailure of) normality of the ring. We also show the existence of a special\ncenter of perfectoid purity that detects the perfectoid purity of $R$,\nanalogously to the splitting prime of Aberbach and Enescu, and investigate its\nbehavior under \\'etale morphisms.","main_category":"math.AG","categories":"math.AG,math.AC","published":"2025-04-22T03:55:38Z"}
{"aid":"http://arxiv.org/abs/2504.15609v1","title":"SonarT165: A Large-scale Benchmark and STFTrack Framework for Acoustic\n  Object Tracking","summary":"Underwater observation systems typically integrate optical cameras and\nimaging sonar systems. When underwater visibility is insufficient, only sonar\nsystems can provide stable data, which necessitates exploration of the\nunderwater acoustic object tracking (UAOT) task. Previous studies have explored\ntraditional methods and Siamese networks for UAOT. However, the absence of a\nunified evaluation benchmark has significantly constrained the value of these\nmethods. To alleviate this limitation, we propose the first large-scale UAOT\nbenchmark, SonarT165, comprising 165 square sequences, 165 fan sequences, and\n205K high-quality annotations. Experimental results demonstrate that SonarT165\nreveals limitations in current state-of-the-art SOT trackers. To address these\nlimitations, we propose STFTrack, an efficient framework for acoustic object\ntracking. It includes two novel modules, a multi-view template fusion module\n(MTFM) and an optimal trajectory correction module (OTCM). The MTFM module\nintegrates multi-view feature of both the original image and the binary image\nof the dynamic template, and introduces a cross-attention-like layer to fuse\nthe spatio-temporal target representations. The OTCM module introduces the\nacoustic-response-equivalent pixel property and proposes normalized pixel\nbrightness response scores, thereby suppressing suboptimal matches caused by\ninaccurate Kalman filter prediction boxes. To further improve the model\nfeature, STFTrack introduces a acoustic image enhancement method and a\nFrequency Enhancement Module (FEM) into its tracking pipeline. Comprehensive\nexperiments show the proposed STFTrack achieves state-of-the-art performance on\nthe proposed benchmark. The code is available at\nhttps://github.com/LiYunfengLYF/SonarT165.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T06:02:32Z"}
{"aid":"http://arxiv.org/abs/2504.15617v1","title":"Spatiotemporal Assessment of Aircraft Noise Exposure Using Mobile\n  Phone-Derived Population Estimates and High-Resolution Noise Measurements","summary":"Aircraft noise exposure has traditionally been assessed using static\nresidential population data and long-term average noise metrics, often\noverlooking the dynamic nature of human mobility and temporal variations in\noperational conditions. This study proposes a data-driven framework that\nintegrates high-resolution noise measurements from airport monitoring terminals\nwith mobile phone-derived de facto population estimates to evaluate noise\nexposure with fine spatio-temporal resolution. We develop hourly noise exposure\nprofiles and quantify the number of individuals affected across regions and\ntime windows, using both absolute counts and inequality metrics such as Gini\ncoefficients. This enables a nuanced examination of not only who is exposed,\nbut when and where the burden is concentrated. At our case study airport,\noperational runway patterns resulted in recurring spatial shifts in noise\nexposure. By incorporating de facto population data, we demonstrate that\nidentical noise operations can yield unequal impacts depending on the time and\nlocation of population presence, highlighting the importance of accounting for\npopulation dynamics in exposure assessment. Our approach offers a scalable\nbasis for designing population-sensitive noise abatement strategies,\ncontributing to more equitable and transparent aviation noise management.","main_category":"stat.AP","categories":"stat.AP,stat.OT","published":"2025-04-22T06:15:43Z"}
{"aid":"http://arxiv.org/abs/2504.15626v1","title":"Realized Local Volatility Surface","summary":"For quantitative trading risk management purposes, we present a novel idea:\nthe realized local volatility surface. Concisely, it stands for the conditional\nexpected volatility when sudden market behaviors of the underlying occur. One\nis able to explore risk management usages by following the orthotical\nDelta-Gamma dynamic hedging framework. The realized local volatility surface\nis, mathematically, a generalized Wiener measure from historical prices. It is\nreconstructed via employing high-frequency trading market data. A\nStick-Breaking Gaussian Mixture Model is fitted via Hamiltonian Monte Carlo,\nproducing a local volatility surface with 95% credible intervals. A practically\nvalidated Bayesian nonparametric estimation workflow. Empirical results on TSLA\nhigh-frequency data illustrate its ability to capture counterfactual\nvolatility. We also discuss its application in improving volatility-based risk\nmanagement.","main_category":"q-fin.RM","categories":"q-fin.RM,math.OC,q-fin.CP,q-fin.TR","published":"2025-04-22T06:35:34Z"}
{"aid":"http://arxiv.org/abs/2504.15627v1","title":"ZeroSlide: Is Zero-Shot Classification Adequate for Lifelong Learning in\n  Whole-Slide Image Analysis in the Era of Pathology Vision-Language Foundation\n  Models?","summary":"Lifelong learning for whole slide images (WSIs) poses the challenge of\ntraining a unified model to perform multiple WSI-related tasks, such as cancer\nsubtyping and tumor classification, in a distributed, continual fashion. This\nis a practical and applicable problem in clinics and hospitals, as WSIs are\nlarge, require storage, processing, and transfer time. Training new models\nwhenever new tasks are defined is time-consuming. Recent work has applied\nregularization- and rehearsal-based methods to this setting. However, the rise\nof vision-language foundation models that align diagnostic text with pathology\nimages raises the question: are these models alone sufficient for lifelong WSI\nlearning using zero-shot classification, or is further investigation into\ncontinual learning strategies needed to improve performance? To our knowledge,\nthis is the first study to compare conventional continual-learning approaches\nwith vision-language zero-shot classification for WSIs. Our source code and\nexperimental results will be available soon.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T06:38:37Z"}
{"aid":"http://arxiv.org/abs/2504.15633v1","title":"An analytic redshift-independent formulation of baryonic effects on the\n  matter power spectrum","summary":"Baryonic effects created by feedback processes associated with galaxy\nformation are an important, poorly constrained systematic effect for models of\nlarge-scale structure as probed by weak gravitational lensing. Upcoming surveys\nrequire fast methods to predict and marginalize over the potential impact of\nbaryons on the total matter power spectrum. Here we use the FLAMINGO\ncosmological hydrodynamical simulations to test a recent proposal to\napproximate the matter power spectrum as the sum of the linear matter power\nspectrum and a constant multiple, $A_{\\rm mod}$, of the difference between the\nlinear and non-linear gravity-only power spectra. We show that replacing this\nconstant multiple with a one-parameter family of sigmoid functions of the\nwavenumber $k$ allows to us match the predictions of simulations with different\nfeedback strengths for $z \\leq 1, k < 3~h\\cdot{\\rm Mpc}^{-1}$, and the\ndifferent cosmological models in the FLAMINGO suite. The baryonic response\npredicted by FLAMINGO models that use jet-like AGN feedback instead of the\nfiducial thermally-driven AGN feedback can also be reproduced, but at the cost\nof increasing the number of parameters in the sigmoid function from one to\nthree. The assumption that $A_{\\rm mod}$ depends only on $k$ breaks down for\ndecaying dark matter models, highlighting the need for more advanced baryon\nresponse models when studying cosmological models that deviate strongly from\n$\\Lambda$CDM.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-22T06:48:25Z"}
{"aid":"http://arxiv.org/abs/2504.15639v1","title":"A remark for characterizing blowup introduced by Giga and Kohn","summary":"Giga and Kohn studied the blowup solutions for the equation $v_{t} - \\Delta v\n- |v|^{p - 1} v = 0 $ and characterized the asymptotic behavior of $v$ near a\nsingularity. In the proof, they reduced the problem to a Liouville theorem for\nthe equation $\\Delta u - \\frac{1}{2} x \\cdot \\nabla u + |u|^{p - 1} u - \\beta u\n= 0$ where $\\beta = \\frac{1}{p - 1}$ and $|u|$ is bounded. This article is a\nremark for their work and we will show when $u \\geq 0$, the boundedness\ncondition for $|u|$ can be removed.","main_category":"math.AP","categories":"math.AP","published":"2025-04-22T06:57:02Z"}
{"aid":"http://arxiv.org/abs/2504.15660v1","title":"Electroweak form factors of baryons in dense nuclear matter","summary":"There are evidences that the properties of the hadrons are modified in a\nnuclear medium. Information about the medium modifications of the internal\nstructure of the hadrons are fundamental for the study of dense nuclear matter\nand high energy processes including heavy-ion and nucleus-nucleus collisions.\nAt the moment, however, the empirical information about the medium\nmodifications of the hadrons is limited, therefore, theoretical studies are\nessential for the progress in the field. In the present work we review\ntheoretical studies of the electromagnetic and axial form factors of octet\nbaryons in symmetric nuclear matter. The calculations are based on a model that\ntakes into account the degrees of freedom revealed on experimental studies of\nthe low and intermediate square transfer momentum $q^2=-Q^2$: valence quarks\nand meson cloud excitations of the baryon cores. The formalism combines a\ncovariant constituent quark model, developed for the free space (vacuum) with\nthe quark-meson coupling model for the extension to the nuclear medium. We\nconclude that the nuclear medium modifies the baryon properties differently\naccording to the flavor content of the baryons and the medium density. The\neffects of the medium increase with the density, and are stronger (quenched or\nenhanced) for light baryons than for heavy baryons. In particular, the\nin-medium neutrino-nucleon and antineutrino-nucleon cross sections are reduced\ncompared to the values in free space. The proposed formalism can be extended to\ndensities above the normal nuclear density and applied to neutrino-hyperon and\nantineutrino-hyperon scattering in dense nuclear matter.","main_category":"nucl-th","categories":"nucl-th,hep-ex,hep-lat,hep-ph,nucl-ex","published":"2025-04-22T07:35:42Z"}
{"aid":"http://arxiv.org/abs/2504.15665v1","title":"Motion-Enhanced Nonlocal Similarity Implicit Neural Representation for\n  Infrared Dim and Small Target Detection","summary":"Infrared dim and small target detection presents a significant challenge due\nto dynamic multi-frame scenarios and weak target signatures in the infrared\nmodality. Traditional low-rank plus sparse models often fail to capture dynamic\nbackgrounds and global spatial-temporal correlations, which results in\nbackground leakage or target loss. In this paper, we propose a novel\nmotion-enhanced nonlocal similarity implicit neural representation (INR)\nframework to address these challenges. We first integrate motion estimation via\noptical flow to capture subtle target movements, and propose multi-frame fusion\nto enhance motion saliency. Second, we leverage nonlocal similarity to\nconstruct patch tensors with strong low-rank properties, and propose an\ninnovative tensor decomposition-based INR model to represent the nonlocal patch\ntensor, effectively encoding both the nonlocal low-rankness and\nspatial-temporal correlations of background through continuous neural\nrepresentations. An alternating direction method of multipliers is developed\nfor the nonlocal INR model, which enjoys theoretical fixed-point convergence.\nExperimental results show that our approach robustly separates dim targets from\ncomplex infrared backgrounds, outperforming state-of-the-art methods in\ndetection accuracy and robustness.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T07:42:00Z"}
{"aid":"http://arxiv.org/abs/2504.15667v1","title":"Performance Estimation for Supervised Medical Image Segmentation Models\n  on Unlabeled Data Using UniverSeg","summary":"The performance of medical image segmentation models is usually evaluated\nusing metrics like the Dice score and Hausdorff distance, which compare\npredicted masks to ground truth annotations. However, when applying the model\nto unseen data, such as in clinical settings, it is often impractical to\nannotate all the data, making the model's performance uncertain. To address\nthis challenge, we propose the Segmentation Performance Evaluator (SPE), a\nframework for estimating segmentation models' performance on unlabeled data.\nThis framework is adaptable to various evaluation metrics and model\narchitectures. Experiments on six publicly available datasets across six\nevaluation metrics including pixel-based metrics such as Dice score and\ndistance-based metrics like HD95, demonstrated the versatility and\neffectiveness of our approach, achieving a high correlation (0.956$\\pm$0.046)\nand low MAE (0.025$\\pm$0.019) compare with real Dice score on the independent\ntest set. These results highlight its ability to reliably estimate model\nperformance without requiring annotations. The SPE framework integrates\nseamlessly into any model training process without adding training overhead,\nenabling performance estimation and facilitating the real-world application of\nmedical image segmentation algorithms. The source code is publicly available","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-22T07:42:48Z"}
{"aid":"http://arxiv.org/abs/2504.15707v1","title":"RePOPE: Impact of Annotation Errors on the POPE Benchmark","summary":"Since data annotation is costly, benchmark datasets often incorporate labels\nfrom established image datasets. In this work, we assess the impact of label\nerrors in MSCOCO on the frequently used object hallucination benchmark POPE. We\nre-annotate the benchmark images and identify an imbalance in annotation errors\nacross different subsets. Evaluating multiple models on the revised labels,\nwhich we denote as RePOPE, we observe notable shifts in model rankings,\nhighlighting the impact of label quality. Code and data are available at\nhttps://github.com/YanNeu/RePOPE .","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-22T08:47:59Z"}
{"aid":"http://arxiv.org/abs/2504.15715v1","title":"Assessing FAIRness of the Digital Shadow Reference Model","summary":"Models play a critical role in managing the vast amounts of data and\nincreasing complexity found in the IoT, IIoT, and IoP domains. The Digital\nShadow Reference Model, which serves as a foundational metadata schema for\nlinking data and metadata in these environments, is an example of such a model.\nEnsuring FAIRness (adherence to the FAIR Principles) is critical because it\nimproves data findability, accessibility, interoperability, and reusability,\nfacilitating efficient data management and integration across systems.\n  This paper presents an evaluation of the FAIRness of the Digital Shadow\nReference Model using a structured evaluation framework based on the FAIR Data\nPrinciples. Using the concept of FAIR Implementation Profiles (FIPs),\nsupplemented by a mini-questionnaire, we systematically evaluate the model's\nadherence to these principles. Our analysis identifies key strengths, including\nthe model's metadata schema that supports rich descriptions and authentication\ntechniques, and highlights areas for improvement, such as the need for globally\nunique identifiers and consequent support for different Web standards. The\nresults provide actionable insights for improving the FAIRness of the model and\npromoting better data management and reuse. This research contributes to the\nfield by providing a detailed assessment of the Digital Shadow Reference Model\nand recommending next steps to improve its FAIRness and usability.","main_category":"cs.DB","categories":"cs.DB,cs.CY,cs.IR","published":"2025-04-22T08:58:48Z"}
{"aid":"http://arxiv.org/abs/2504.15723v1","title":"Structure-Preserving Zero-Shot Image Editing via Stage-Wise Latent\n  Injection in Diffusion Models","summary":"We propose a diffusion-based framework for zero-shot image editing that\nunifies text-guided and reference-guided approaches without requiring\nfine-tuning. Our method leverages diffusion inversion and timestep-specific\nnull-text embeddings to preserve the structural integrity of the source image.\nBy introducing a stage-wise latent injection strategy-shape injection in early\nsteps and attribute injection in later steps-we enable precise, fine-grained\nmodifications while maintaining global consistency. Cross-attention with\nreference latents facilitates semantic alignment between the source and\nreference. Extensive experiments across expression transfer, texture\ntransformation, and style infusion demonstrate state-of-the-art performance,\nconfirming the method's scalability and adaptability to diverse image editing\nscenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T09:18:16Z"}
{"aid":"http://arxiv.org/abs/2504.15737v1","title":"Energy-Efficient SIM-assisted Communications: How Many Layers Do We\n  Need?","summary":"The stacked intelligent metasurface (SIM), comprising multiple layers of\nreconfigurable transmissive metasurfaces, is becoming an increasingly viable\nsolution for future wireless communication systems. In this paper, we explore\nthe integration of SIM in a multi-antenna base station for application to\ndownlink multi-user communications, and a realistic power consumption model for\nSIM-assisted systems is presented. Specifically, we focus on maximizing the\nenergy efficiency (EE) for hybrid precoding design, i.e., the base station\ndigital precoding and SIM wave-based beamforming. Due to the non-convexity and\nhigh complexity of the formulated problem, we employ the quadratic\ntransformation method to reformulate the optimization problem and propose an\nalternating optimization (AO)-based joint precoding framework. Specifically, a\nsuccessive convex approximation (SCA) algorithm is adopted for the base station\nprecoding design. For the SIM wave-based beamforming, two algorithms are\nemployed: the high-performance semidefinite programming (SDP) method and the\nlow-complexity projected gradient ascent (PGA) algorithm. In particular, the\nresults indicate that while the optimal number of SIM layers for maximizing the\nEE and spectral efficiency differs, a design of 2 to 5 layers can achieve\nsatisfactory performance for both. Finally, numerical results are illustrated\nto evaluate the effectiveness of the proposed hybrid precoding framework and to\nshowcase the performance enhancement achieved by the algorithm in comparison to\nbenchmark schemes.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-22T09:31:55Z"}
{"aid":"http://arxiv.org/abs/2504.15740v1","title":"CaRoSaC: A Reinforcement Learning-Based Kinematic Control of\n  Cable-Driven Parallel Robots by Addressing Cable Sag through Simulation","summary":"This paper introduces the Cable Robot Simulation and Control (CaRoSaC)\nFramework, which integrates a simulation environment with a model-free\nreinforcement learning control methodology for suspended Cable-Driven Parallel\nRobots (CDPRs), accounting for cable sag. Our approach seeks to bridge the\nknowledge gap of the intricacies of CDPRs due to aspects such as cable sag and\nprecision control necessities by establishing a simulation platform that\ncaptures the real-world behaviors of CDPRs, including the impacts of cable sag.\nThe framework offers researchers and developers a tool to further develop\nestimation and control strategies within the simulation for understanding and\npredicting the performance nuances, especially in complex operations where\ncable sag can be significant. Using this simulation framework, we train a\nmodel-free control policy in Reinforcement Learning (RL). This approach is\nchosen for its capability to adaptively learn from the complex dynamics of\nCDPRs. The policy is trained to discern optimal cable control inputs, ensuring\nprecise end-effector positioning. Unlike traditional feedback-based control\nmethods, our RL control policy focuses on kinematic control and addresses the\ncable sag issues without being tethered to predefined mathematical models. We\nalso demonstrate that our RL-based controller, coupled with the flexible cable\nsimulation, significantly outperforms the classical kinematics approach,\nparticularly in dynamic conditions and near the boundary regions of the\nworkspace. The combined strength of the described simulation and control\napproach offers an effective solution in manipulating suspended CDPRs even at\nworkspace boundary conditions where traditional approach fails, as proven from\nour experiments, ensuring that CDPRs function optimally in various applications\nwhile accounting for the often neglected but critical factor of cable sag.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-22T09:45:06Z"}
{"aid":"http://arxiv.org/abs/2504.15742v1","title":"Proving Cypher Query Equivalence","summary":"Graph database systems store graph data as nodes and relationships, and\nutilize graph query languages (e.g., Cypher) for efficiently querying graph\ndata. Proving the equivalence of graph queries is an important foundation for\noptimizing graph query performance, ensuring graph query reliability, etc.\nAlthough researchers have proposed many SQL query equivalence provers for\nrelational database systems, these provers cannot be directly applied to prove\nthe equivalence of graph queries. The difficulty lies in the fact that graph\nquery languages (e.g., Cypher) adopt significantly different data models\n(property graph model vs. relational model) and query patterns (graph pattern\nmatching vs. tabular tuple calculus) from SQL.\n  In this paper, we propose GraphQE, an automated prover to determine whether\ntwo Cypher queries are semantically equivalent. We design a U-semiring based\nCypher algebraic representation to model the semantics of Cypher queries. Our\nCypher algebraic representation is built on the algebraic structure of\nunbounded semirings, and can sufficiently express nodes and relationships in\nproperty graphs and complex Cypher queries. Then, determining the equivalence\nof two Cypher queries is transformed into determining the equivalence of the\ncorresponding Cypher algebraic representations, which can be verified by SMT\nsolvers. To evaluate the effectiveness of GraphQE, we construct a dataset\nconsisting of 148 pairs of equivalent Cypher queries. Among them, we have\nsuccessfully proven 138 pairs of equivalent Cypher queries, demonstrating the\neffectiveness of GraphQE.","main_category":"cs.DB","categories":"cs.DB,cs.SE","published":"2025-04-22T09:45:37Z"}
{"aid":"http://arxiv.org/abs/2504.15753v1","title":"Markov Kernels, Distances and Optimal Control: A Parable of Linear\n  Quadratic Non-Gaussian Distribution Steering","summary":"For a controllable linear time-varying (LTV) pair\n$(\\boldsymbol{A}_t,\\boldsymbol{B}_t)$ and $\\boldsymbol{Q}_{t}$ positive\nsemidefinite, we derive the Markov kernel for the It\\^{o} diffusion\n${\\mathrm{d}}\\boldsymbol{x}_{t}=\\boldsymbol{A}_{t}\\boldsymbol{x}_t {\\mathrm{d}}\nt + \\sqrt{2}\\boldsymbol{B}_{t}{\\mathrm{d}}\\boldsymbol{w}_{t}$ with an\naccompanying killing of probability mass at rate\n$\\frac{1}{2}\\boldsymbol{x}^{\\top}\\boldsymbol{Q}_{t}\\boldsymbol{x}$. This Markov\nkernel is the Green's function for an associated linear\nreaction-advection-diffusion partial differential equation. Our result\ngeneralizes the recently derived kernel for the special case\n$\\left(\\boldsymbol{A}_t,\\boldsymbol{B}_t\\right)=\\left(\\boldsymbol{0},\\boldsymbol{I}\\right)$,\nand depends on the solution of an associated Riccati matrix ODE. A consequence\nof this result is that the linear quadratic non-Gaussian Schr\\\"{o}dinger bridge\nis exactly solvable. This means that the problem of steering a controlled LTV\ndiffusion from a given non-Gaussian distribution to another over a fixed\ndeadline while minimizing an expected quadratic cost can be solved using\ndynamic Sinkhorn recursions performed with the derived kernel. Our derivation\nfor the\n$\\left(\\boldsymbol{A}_t,\\boldsymbol{B}_t,\\boldsymbol{Q}_t\\right)$-parametrized\nkernel pursues a new idea that relies on finding a state-time dependent\ndistance-like functional given by the solution of a deterministic optimal\ncontrol problem. This technique breaks away from existing methods, such as\ngeneralizing Hermite polynomials or Weyl calculus, which have seen limited\nsuccess in the reaction-diffusion context. Our technique uncovers a new\nconnection between Markov kernels, distances, and optimal control. This\nconnection is of interest beyond its immediate application in solving the\nlinear quadratic Schr\\\"{o}dinger bridge problem.","main_category":"math.OC","categories":"math.OC,cs.LG,cs.SY,eess.SY,math.PR,math.ST,stat.TH","published":"2025-04-22T10:07:43Z"}
{"aid":"http://arxiv.org/abs/2504.15778v1","title":"A Stochastic Lattice Model for Convective Self-aggregation Incorporating\n  Longwave Radiative Effect","summary":"Self-aggregation of tropical convection is a universal feature observed in a\ndiverse range of atmospheric environments. Several preceding models\nconceptualized the self-aggregation of convection as a phase transition driven\nby collisions between cold pool gust fronts. However, self-aggregation may also\nbe influenced by various physical processes, such as surface fluxes, radiation,\nand moisture perturbations in the planetary boundary layer, and it remains\nunclear which process plays a dominant role. In this study, we develop a simple\nstochastic lattice model for the pattern formation of deep convection, inspired\nby the two-dimensional Ising model. Here, in addition to the process of cold\npool collisions, which have an effect of triggering new convection, we\nincorporate the process of clear-sky radiative cooling that has an effect of\nsuppressing deep convection as an interaction between clouds. Our results show\nthat by amplifying the intensity of the clear-sky radiative cooling effect, the\ntransition from a quasi-uniform to an inhomogeneous cloud field can be\nreproduced. The model also successfully explains the dependence of\nself-aggregation on several model parameters, such as the experimental domain\nsize and the characteristic size of cold pools. Furthermore, by varying the\ndistance over which the subsidence induced by radiative cooling extends, we\nsucceed in capturing a pattern formation that closely resembles the convective\nclusters observed in the real atmosphere and three-dimensional numerical model\nsimulations.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-22T10:38:33Z"}
{"aid":"http://arxiv.org/abs/2504.15789v1","title":"Doubly-charmed pentaquark states in a mass splitting model","summary":"Concentrating on the mass differences relative to $P_{\\psi}^{N}(4312)^+$, we\nsystematically investigate the spectra of doubly-charmed pentaquark states in\nthe compact $ccqq\\bar{q}$ ($q=u, d, s$) configuration. The assumption that the\nobserved $P_{\\psi}^{N}(4312)^+$ is a compact hidden-charm pentaquark with\n$I(J^P)=\\frac12(\\frac32^-)$ is adopted. We also study the properties of strong\ndecays within a simple rearrangement scheme. The results indicate that the\n$I(J^P)=\\frac12(\\frac12^-)$ $ccnn\\bar{n}$ with $I_{nn}=0$ where $n$ denotes $u$\nor $d$ quark, $I(J^P)=0(\\frac12^-)$ $ccnn\\bar{s}$, and $I(J^P)=0(\\frac12^-)$\n$ccns\\bar{n}$ ground states should be stable.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-22T11:03:34Z"}
{"aid":"http://arxiv.org/abs/2504.15807v1","title":"Evaluating the potential of HIV self-testing to reduce HIV incidence in\n  EHE districts: a modeling study","summary":"Background: High HIV transmission persists in many U.S. jurisdictions despite\nprevention efforts. HIV self-testing offers a means to overcome barriers\nassociated with routine laboratory-based testing but carries a risk of\nincreasing incidence if replacement effects reduce overall test sensitivity.\nMethods: A linearized four-compartment HIV transmission model was applied to 38\nEnding the HIV Epidemic (EHE) priority jurisdictions. A threshold testing level\nwas defined to counterbalance potential negative effects from reduced self-test\nsensitivity. Both the percentage of self-tests and the overall testing rate\nwere varied to quantify 10-year changes in HIV incidence. Results: Substantial\nheterogeneity emerged across districts. Incidence reductions exceeded 5 percent\nin some areas, while others saw only minor effects. Jurisdictions with higher\nbaseline testing displayed an elevated risk of increased incidence from\nsubstitution of laboratory-based testing with self-tests. In contrast, a\nderived Awareness Reproduction Number, capturing transmissions attributable to\nundiagnosed infection, strongly correlated with the magnitude of possible\nincidence declines. Conclusions: Local epidemiological context is pivotal in\ndetermining the risks and benefits of HIV self-testing. Jurisdictions with\nrobust testing systems may face a greater likelihood of inadvertently raising\nincidence, whereas those with a high number of individuals stand to achieve\nnotable transmission reductions. Tailoring self-testing strategies based on\njurisdiction-specific conditions can maximize public health benefits while\nminimizing unintended consequences.","main_category":"math.DS","categories":"math.DS","published":"2025-04-22T11:43:28Z"}
{"aid":"http://arxiv.org/abs/2504.15830v1","title":"Predictive Synthesis of Control Barrier Functions and its Application to\n  Time-Varying Constraints","summary":"This paper presents a systematic method for synthesizing a Control Barrier\nFunction (CBF) that encodes predictive information into a CBF. Unlike other\nmethods, the synthesized CBF can account for changes and time-variations in the\nconstraints even when constructed for time-invariant constraints. This avoids\nrecomputing the CBF when the constraint specifications change. The method\nprovides an explicit characterization of the extended class K function {\\alpha}\nthat determines the dynamic properties of the CBF, and {\\alpha} can even be\nexplicitly chosen as a design parameter in the controller synthesis. The\nresulting CBF further accounts for input constraints, and its values can be\ndetermined at any point without having to compute the CBF over the entire\ndomain. The synthesis method is based on a finite horizon optimal control\nproblem inspired by Hamilton-Jacobi reachability analysis and does not rely on\na nominal control law. The synthesized CBF is time-invariant if the constraints\nare. The method poses mild assumptions on the controllability of the dynamic\nsystem and assumes the knowledge of at least a subset of some control invariant\nset. The paper provides a detailed analysis of the properties of the\nsynthesized CBF, including its application to time-varying constraints. A\nsimulation study applies the proposed approach to various dynamic systems in\nthe presence of time-varying constraints. The paper is accompanied by an online\navailable parallelized implementation of the proposed synthesis method.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-22T12:21:16Z"}
{"aid":"http://arxiv.org/abs/2504.15839v1","title":"On commuting integer matrices","summary":"Given $d, N \\in \\mathbb{N}$, we define $\\mathfrak{C}_d(N)$ to be the number\nof pairs of $d\\times d$ matrices $A,B$ with entries in $[-N,N] \\cap \\mathbb{Z}$\nsuch that $AB = BA$. We prove that $$ N^{10} \\ll \\mathfrak{C}_3(N) \\ll\nN^{10},$$ thus confirming a speculation of Browning-Sawin-Wang. We further\nestablish that $$ \\mathfrak{C}_2(N) = K(2N+1)^5 (1 + o(1)),$$ where $K>0$ is an\nexplicit constant. Our methods are completely elementary and rely on upper\nbounds of the correct order for restricted divisor correlations with high\nuniformity.","main_category":"math.NT","categories":"math.NT,math.CO","published":"2025-04-22T12:34:14Z"}
{"aid":"http://arxiv.org/abs/2504.15840v1","title":"Attractive and repulsive angulons in superfluid environments","summary":"We investigate the in- and out-of-equilibrium phenomena of a rotational\nimpurity -- specifically, a linear molecule -- coupled to a nonconventional\nenvironment, a helium nanodroplet. By employing a Lee-Low-Pines-like\ntransformation combined with a multireference configuration approach, we\nself-consistently account for the molecule's backaction on the superfluid bath\nand accurately capture the complex entanglement between the molecule's\nrotational degrees of freedom and the bath excitations. Our findings reveal\nthat, in the ground state, the impurity induces a density defect in the\nsuperfluid bath, giving rise to two novel types of excited states: (a)\nattractive angulon states, analogous to bound states in photonic crystals and\nYu-Shiba-Rusinov bound states in superconductors, localized within the density\ndefect region; and (b) long-lived repulsive angulon states in dilute\nenvironments. Rotational spectroscopy demonstrates a crossover from repulsive\nto attractive angulon states as the bath density increases. This work paves the\nway for exploring novel nonequilibrium phenomena of quantum impurities in\ninteracting environments.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,physics.atom-ph,physics.chem-ph,quant-ph","published":"2025-04-22T12:34:55Z"}
{"aid":"http://arxiv.org/abs/2504.15844v1","title":"Sound and Complete Invariant-Based Heap Encodings (Technical Report)","summary":"Verification of programs operating on mutable, heap-allocated data structures\nposes significant challenges due to potentially unbounded structures like\nlinked lists and trees. In this paper, we present a novel relational heap\nencoding leveraging uninterpreted predicates and prophecy variables, reducing\nheap verification tasks to satisfiability checks over integers in constrained\nHorn clauses (CHCs). To the best of our knowledge, our approach is the first\ninvariant-based method that achieves both soundness and completeness for\nheap-manipulating programs. We provide formal proofs establishing the\ncorrectness of our encodings. Through an experimental evaluation we demonstrate\nthat our method significantly extends the capability of existing CHC-based\nverification tools, allowing automatic verification of programs with heap\npreviously unreachable by state-of-the-art tools.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-22T12:40:21Z"}
{"aid":"http://arxiv.org/abs/2504.15848v1","title":"Exploring Cognitive and Aesthetic Causality for Multimodal Aspect-Based\n  Sentiment Analysis","summary":"Multimodal aspect-based sentiment classification (MASC) is an emerging task\ndue to an increase in user-generated multimodal content on social platforms,\naimed at predicting sentiment polarity toward specific aspect targets (i.e.,\nentities or attributes explicitly mentioned in text-image pairs). Despite\nextensive efforts and significant achievements in existing MASC, substantial\ngaps remain in understanding fine-grained visual content and the cognitive\nrationales derived from semantic content and impressions (cognitive\ninterpretations of emotions evoked by image content). In this study, we present\nChimera: a cognitive and aesthetic sentiment causality understanding framework\nto derive fine-grained holistic features of aspects and infer the fundamental\ndrivers of sentiment expression from both semantic perspectives and\naffective-cognitive resonance (the synergistic effect between emotional\nresponses and cognitive interpretations). Specifically, this framework first\nincorporates visual patch features for patch-word alignment. Meanwhile, it\nextracts coarse-grained visual features (e.g., overall image representation)\nand fine-grained visual regions (e.g., aspect-related regions) and translates\nthem into corresponding textual descriptions (e.g., facial, aesthetic).\nFinally, we leverage the sentimental causes and impressions generated by a\nlarge language model (LLM) to enhance the model's awareness of sentimental cues\nevoked by semantic content and affective-cognitive resonance. Experimental\nresults on standard MASC datasets demonstrate the effectiveness of the proposed\nmodel, which also exhibits greater flexibility to MASC compared to LLMs such as\nGPT-4o. We have publicly released the complete implementation and dataset at\nhttps://github.com/Xillv/Chimera","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-22T12:43:37Z"}
{"aid":"http://arxiv.org/abs/2504.15858v1","title":"Positive-tone Nanolithography of Antimony Trisulfide with Femtosecond\n  Laser Wet-etching","summary":"Antimony trisulfide ($Sb_{2}S_{3}$), as an emerging material for integrated\nphotonic devices, has attracted significant attention due to its high index,\nlow loss, and phase-changing property in the optical regime. However,\nconventional lithography-based fabrication methods involve complex,\ntime-consuming, multistep processes, rendering the photonic application of\n$Sb_{2}S_{3}$ challenging. Here, we demonstrate that positive-tone fabrication\nof $Sb_{2}S_{3}$ nanostructures using wet-etch femtosecond laser processing, a\nstraightforward technique for the engraving of micro- and nanoscale structures,\ncan address major fabrication challenges. The patterning mechanism and factors\ninfluencing resolution of $Sb_{2}S_{3}$ thin film structures deposited on\nquartz (transmissive) and gold (reflective) substrates are experimentally\ninvestigated and supported by theoretical modelling. Using this approach, the\nsmallest linewidth fabricated is measured at 178 nm. Consequently, multiple\ntest patterns are demonstrated showing versatile functionalities. Functional\nFresnel Zone Plates (FZPs) with varying focal length are fabricated and\ncharacterized. This study provides a significantly simplified approach for\nrealizing $Sb_{2}S_{3}$ based integrated photonic devices.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mtrl-sci,physics.ins-det","published":"2025-04-22T12:53:43Z"}
{"aid":"http://arxiv.org/abs/2504.15925v1","title":"Improving robustness and training efficiency of machine-learned\n  potentials by incorporating short-range empirical potentials","summary":"Machine learning force fields (MLFFs) are powerful tools for materials\nmodeling, but their performance is often limited by training dataset quality,\nparticularly the lack of rare event configurations. This limitation undermines\ntheir accuracy and robustness in long-time and large-scale molecular dynamics\nsimulations. In this work, we present a hybrid MLFF framework that integrates\nan empirical short-range repulsive potential and demonstrates improved\nrobustness and training efficiency. Using solid electrolyte\nLi$_7$La$_3$Zr$_2$O$_{12}$ (LLZO) as a model system, we show that purely\ndata-driven MLFFs fail to prevent unphysical atomistic clustering in extended\nsimulations due to inadequate short-range repulsion. In contrast, the hybrid\nforce field eliminates these artifacts, enabling stable long-time simulations,\nwhich are critical for studying various properties of LLZO. The hybrid\nframework also reduces the need for extensive active learning and performs well\nwith just 25 training configurations. By combining physics-driven constraints\nwith data-driven flexibility, this approach is compatible with most existing\nMLFF architectures and establishes a universal paradigm for developing robust,\ntraining-efficient force fields for complex material systems.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-22T14:12:45Z"}
{"aid":"http://arxiv.org/abs/2504.15927v1","title":"New Recipe for Semi-supervised Community Detection: Clique Annealing\n  under Crystallization Kinetics","summary":"Semi-supervised community detection methods are widely used for identifying\nspecific communities due to the label scarcity. Existing semi-supervised\ncommunity detection methods typically involve two learning stages learning in\nboth initial identification and subsequent adjustment, which often starts from\nan unreasonable community core candidate. Moreover, these methods encounter\nscalability issues because they depend on reinforcement learning and generative\nadversarial networks, leading to higher computational costs and restricting the\nselection of candidates. To address these limitations, we draw a parallel\nbetween crystallization kinetics and community detection to integrate the\nspontaneity of the annealing process into community detection. Specifically, we\nliken community detection to identifying a crystal subgrain (core) that expands\ninto a complete grain (community) through a process similar to annealing. Based\non this finding, we propose CLique ANNealing (CLANN), which applies kinetics\nconcepts to community detection by integrating these principles into the\noptimization process to strengthen the consistency of the community core.\nSubsequently, a learning-free Transitive Annealer was employed to refine the\nfirst-stage candidates by merging neighboring cliques and repositioning the\ncommunity core, enabling a spontaneous growth process that enhances\nscalability. Extensive experiments on \\textbf{43} different network settings\ndemonstrate that CLANN outperforms state-of-the-art methods across multiple\nreal-world datasets, showcasing its exceptional efficacy and efficiency in\ncommunity detection.","main_category":"cs.SI","categories":"cs.SI,cs.AI","published":"2025-04-22T14:17:15Z"}
{"aid":"http://arxiv.org/abs/2504.15933v1","title":"Low-Rank Adaptation of Neural Fields","summary":"Processing visual data often involves small adjustments or sequences of\nchanges, such as in image filtering, surface smoothing, and video storage.\nWhile established graphics techniques like normal mapping and video compression\nexploit redundancy to encode such small changes efficiently, the problem of\nencoding small changes to neural fields (NF) -- neural network\nparameterizations of visual or physical functions -- has received less\nattention.\n  We propose a parameter-efficient strategy for updating neural fields using\nlow-rank adaptations (LoRA). LoRA, a method from the parameter-efficient\nfine-tuning LLM community, encodes small updates to pre-trained models with\nminimal computational overhead. We adapt LoRA to instance-specific neural\nfields, avoiding the need for large pre-trained models yielding a pipeline\nsuitable for low-compute hardware.\n  We validate our approach with experiments in image filtering, video\ncompression, and geometry editing, demonstrating its effectiveness and\nversatility for representing neural field updates.","main_category":"cs.GR","categories":"cs.GR,cs.LG","published":"2025-04-22T14:21:34Z"}
{"aid":"http://arxiv.org/abs/2504.15996v1","title":"Small-scale dynamic phenomena associated with interacting fan-spine\n  topologies: quiet-Sun Ellerman bombs, UV brightenings, and chromospheric\n  inverted-Y-shaped jets","summary":"QSEBs are small-scale magnetic reconnection events in lower solar atmosphere.\nSometimes, they exhibit transition region counterparts, known as UV\nbrightenings. Magnetic field extrapolations suggest that QSEBs can occur at\nvarious locations of a fan-spine topology, with UV brightening occurring at\nnull point through a common reconnection process. We aim to understand how\ncomplex magnetic configurations like interacting fan-spine topologies can cause\nsmall-scale dynamic phenomena in lower atmosphere. QSEBs were detected using\nk-means clustering on Hbeta observations from Swedish 1-m Solar Telescope\n(SST). Further, chromospheric inverted-Y-shaped jets were identified in the\nHbeta blue wing. Magnetic field topologies were determined through potential\nfield extrapolations from photospheric magnetograms using the Fe I 6173 A line.\nUV brightenings were detected in IRIS 1400 A SJI. We identify two distinct\nmagnetic configurations associated with QSEBs, UV brightenings, and\nchromospheric inverted-Y-shaped jets. The first involves a nested fan-spine\nstructure where, due to flux emergence, an inner 3D null forms inside fan\nsurface of an outer 3D null with some overlap. QSEBs occur at two footpoints\nalong the shared fan surface, with UV brightening located near the outer 3D\nnull point. The jet originates close to the two QSEBs and follows the path of\nhigh squashing factor Q. We discuss a comparable scenario using a numerical\nsimulation. In second case, two adjacent fan-spine topologies share fan\nfootpoints at a common positive polarity patch, with the QSEB, along with a\nchromospheric inverted-Y-shaped jet, occurring at the intersection having high\nQ values. This study demonstrates through observational and modelling support\nthat associated QSEBs, UV brightenings, and chromospheric inverted-Y-shaped\njets share a common origin driven by magnetic reconnection between interacting\nfan-spine topologies.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-22T16:01:37Z"}
{"aid":"http://arxiv.org/abs/2504.16027v1","title":"Benchmarking LLM for Code Smells Detection: OpenAI GPT-4.0 vs\n  DeepSeek-V3","summary":"Determining the most effective Large Language Model for code smell detection\npresents a complex challenge. This study introduces a structured methodology\nand evaluation matrix to tackle this issue, leveraging a curated dataset of\ncode samples consistently annotated with known smells. The dataset spans four\nprominent programming languages Java, Python, JavaScript, and C++; allowing for\ncross language comparison. We benchmark two state of the art LLMs, OpenAI GPT\n4.0 and DeepSeek-V3, using precision, recall, and F1 score as evaluation\nmetrics. Our analysis covers three levels of detail: overall performance,\ncategory level performance, and individual code smell type performance.\nAdditionally, we explore cost effectiveness by comparing the token based\ndetection approach of GPT 4.0 with the pattern-matching techniques employed by\nDeepSeek V3. The study also includes a cost analysis relative to traditional\nstatic analysis tools such as SonarQube. The findings offer valuable guidance\nfor practitioners in selecting an efficient, cost effective solution for\nautomated code smell detection","main_category":"cs.SE","categories":"cs.SE,cs.AI,cs.LG,cs.PL","published":"2025-04-22T16:44:39Z"}
{"aid":"http://arxiv.org/abs/2504.16036v1","title":"Rotational ultrasound and photoacoustic tomography of the human body","summary":"Imaging the human body's morphological and angiographic information is\nessential for diagnosing, monitoring, and treating medical conditions.\nUltrasonography performs the morphological assessment of the soft tissue based\non acoustic impedance variations, whereas photoacoustic tomography (PAT) can\nvisualize blood vessels based on intrinsic hemoglobin absorption.\nThree-dimensional (3D) panoramic imaging of the vasculature is generally not\npractical in conventional ultrasonography with limited field-of-view (FOV)\nprobes, and PAT does not provide sufficient scattering-based soft tissue\nmorphological contrast. Complementing each other, fast panoramic rotational\nultrasound tomography (RUST) and PAT are integrated for hybrid rotational\nultrasound and photoacoustic tomography (RUS-PAT), which obtains 3D ultrasound\nstructural and PAT angiographic images of the human body quasi-simultaneously.\nThe RUST functionality is achieved in a cost-effective manner using a\nsingle-element ultrasonic transducer for ultrasound transmission and rotating\narc-shaped arrays for 3D panoramic detection. RUST is superior to conventional\nultrasonography, which either has a limited FOV with a linear array or is\nhigh-cost with a hemispherical array that requires both transmission and\nreceiving. By switching the acoustic source to a light source, the system is\nconveniently converted to PAT mode to acquire angiographic images in the same\nregion. Using RUS-PAT, we have successfully imaged the human head, breast,\nhand, and foot with a 10 cm diameter FOV, submillimeter isotropic resolution,\nand 10 s imaging time for each modality. The 3D RUS-PAT is a powerful tool for\nhigh-speed, 3D, dual-contrast imaging of the human body with potential for\nrapid clinical translation.","main_category":"physics.med-ph","categories":"physics.med-ph,eess.SP,physics.app-ph","published":"2025-04-22T17:02:12Z"}
{"aid":"http://arxiv.org/abs/2504.16044v1","title":"Search for Axionlike Dark Matter Using Liquid-State Nuclear Magnetic\n  Resonance","summary":"We search for dark matter in the form of axionlike particles (ALPs) in the\nmass range $5.576741 \\,\\mathrm{neV/c^2}$ - $5.577733\\,\\mathrm{neV/c^2}$ by\nprobing their possible coupling to fermion spins through the ALP field\ngradient. This is achieved by performing proton nuclear magnetic resonance\nspectroscopy on a sample of methanol as a technical demonstration of the Cosmic\nAxion Spin Precession Experiment Gradient (CASPEr-Gradient) Low-Field\napparatus. Searching for spin-coupled ALP dark matter in this mass range with\nassociated Compton frequencies in a 240 Hz window centered at 1.348570 MHz\nresulted in a sensitivity to the ALP-proton coupling constant of\n$g_{\\mathrm{ap}} \\approx 3 \\times 10^{-2}\\,\\mathrm{GeV}^{-1}$. This\nnarrow-bandwidth search serves as a proof-of-principle and a commissioning\nmeasurement, validating our methodology and demonstrating the experiment's\ncapabilities. It opens the door to probing large swaths of hitherto unexplored\nmass-coupling parameter space in the future by using hyperpolarized samples.","main_category":"hep-ex","categories":"hep-ex,physics.atom-ph","published":"2025-04-22T17:11:01Z"}
{"aid":"http://arxiv.org/abs/2504.16409v1","title":"A Molecular Dynamics Study of Size Effects for Critical Resolved Shear\n  Stress in Nickel Superalloys","summary":"We present in this work a molecular dynamics study of a size effect relating\nto the volume fraction of gamma-prime precipitate of edge dislocation motion in\na simple model of Nickel superalloys. We model the superalloy as periodically\nspaced cubic gamma-prime precipitates inside a uniform gamma matrix. We then\nanalyze the motion of paired edge dislocations in the gamma phase when subject\nto an external shear stress for various volume fractions of the gamma-prime\nprecipitate for a wide range of temperatures, from 300 K to 700 K. While the\nvariation of dislocation velocity is not significant, the critical resolved\nshear stress is found to exhibit a power law dependence on the volume fraction\nof the gamma-prime precipitate with two distinct regimes which have similar\nexponent but markedly different prefactors; we also observe that this\ntwo-regime behavior remains true across a wide range of temperatures. We\npresent a detailed analysis of this behavior and reduce it to a linear\ndependence of the critical resolved shear stress on the length of the\ngamma-prime precipitate along the direction of dislocation motion. We further\nidentify the critical length scale underlying the transition between the two\nobserved regimes as the total core width of the paired dislocations in a pure\ngamma-prime system, which includes in addition to the complex stacking fault\nseparating the partials of the paired dislocations the width of the anti-phase\nboundary that is formed between the super-dislocations. The results presented\nin this work provides new details on the strengthening effect of gamma-prime\nprecipitates in nickel superalloys and also has important implications for\nlarger scale dislocation dynamics studies for nickel superalloys.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-23T04:24:03Z"}
{"aid":"http://arxiv.org/abs/2504.16418v1","title":"Scalable Data-Driven Basis Selection for Linear Machine Learning\n  Interatomic Potentials","summary":"Machine learning interatomic potentials (MLIPs) provide an effective approach\nfor accurately and efficiently modeling atomic interactions, expanding the\ncapabilities of atomistic simulations to complex systems. However, a priori\nfeature selection leads to high complexity, which can be detrimental to both\ncomputational cost and generalization, resulting in a need for hyperparameter\ntuning. We demonstrate the benefits of active set algorithms for automated\ndata-driven feature selection. The proposed methods are implemented within the\nAtomic Cluster Expansion (ACE) framework. Computational tests conducted on a\nvariety of benchmark datasets indicate that sparse ACE models consistently\nenhance computational efficiency, generalization accuracy and interpretability\nover dense ACE models. An added benefit of the proposed algorithms is that they\nproduce entire paths of models with varying cost/accuracy ratio.","main_category":"physics.comp-ph","categories":"physics.comp-ph,math.OC","published":"2025-04-23T04:53:29Z"}
{"aid":"http://arxiv.org/abs/2504.16428v1","title":"Energy Rates Due to Weak Decay Rates of Vanadium Isotopes in Stellar\n  Environment","summary":"The neutrino cooling and gamma heating rates are considered as an important\ninput needed to study the final phases of the evolution of high-mass stars. The\nweak-interaction mediated processes, namely the $\\beta$-decay and electron\ncapture, significantly change the lepton to baryon ratio and accelerate the\ncontraction of the core. The emission of resulting neutrinos/antineutrinos\ntends to cool the stellar core. On the other hand, gamma rays are produced\nbecause of electron capture and $\\beta$-decay to excited states in daughter\nnuclei. These gamma rays heat the core and contribute to an increase of entropy\nwhich may cause convection to occur.\n  In the present work, the weak-interaction heating and cooling rates on a\nchain of twenty-two isotopes of vanadium having mass in the range $43-64$ have\nbeen estimated using the proton-neutron quasiparticle random phase\napproximation theory. The rates have been computed for the temperature ranging\nfrom ($10^{7} - 3 \\times 10^{10}$)\\;K and for the density range\n($10-10^{11}$)\\;g/cm$^{3}$. Our calculated neutrino energy loss rates have also\nbeen compared with the previously reported rates calculated using other\ntheoretical models. At high stellar temperatures, our rates are larger by 1-2\norders of magnitude as compared to previous results.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-23T05:25:42Z"}
{"aid":"http://arxiv.org/abs/2504.16438v1","title":"Private Federated Learning using Preference-Optimized Synthetic Data","summary":"In practical settings, differentially private Federated learning (DP-FL) is\nthe dominant method for training models from private, on-device client data.\nRecent work has suggested that DP-FL may be enhanced or outperformed by methods\nthat use DP synthetic data (Wu et al., 2024; Hou et al., 2024). The primary\nalgorithms for generating DP synthetic data for FL applications require careful\nprompt engineering based on public information and/or iterative private client\nfeedback. Our key insight is that the private client feedback collected by\nprior DP synthetic data methods (Hou et al., 2024; Xie et al., 2024) can be\nviewed as a preference ranking. Our algorithm, Preference Optimization for\nPrivate Client Data (POPri) harnesses client feedback using preference\noptimization algorithms such as Direct Preference Optimization (DPO) to\nfine-tune LLMs to generate high-quality DP synthetic data. To evaluate POPri,\nwe release LargeFedBench, a new federated text benchmark for uncontaminated LLM\nevaluations on federated client data. POPri substantially improves the utility\nof DP synthetic data relative to prior work on LargeFedBench datasets and an\nexisting benchmark from Xie et al. (2024). POPri closes the gap between\nnext-token prediction accuracy in the fully-private and non-private settings by\nup to 68%, compared to 52% for prior synthetic data methods, and 10% for\nstate-of-the-art DP federated learning methods. The code and data are available\nat https://github.com/meiyuw/POPri.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CR,cs.DC","published":"2025-04-23T05:57:20Z"}
{"aid":"http://arxiv.org/abs/2504.16473v1","title":"ERASER: Efficient RTL FAult Simulation Framework with Trimmed Execution\n  Redundancy","summary":"As intelligent computing devices increasingly integrate into human life,\nensuring the functional safety of the corresponding electronic chips becomes\nmore critical. A key metric for functional safety is achieving a sufficient\nfault coverage. To meet this requirement, extensive time-consuming fault\nsimulation of the RTL code is necessary during the chip design phase.The main\noverhead in RTL fault simulation comes from simulating behavioral nodes (always\nblocks). Due to the limited fault propagation capacity, fault simulation\nresults often match the good simulation results for many behavioral nodes. A\nkey strategy for accelerating RTL fault simulation is the identification and\nelimination of redundant simulations. Existing methods detect redundant\nexecutions by examining whether the fault inputs to each RTL node are\nconsistent with the good inputs. However, we observe that this input comparison\nmechanism overlooks a significant amount of implicit redundant execution:\nalthough the fault inputs differ from the good inputs, the node's execution\nresults remain unchanged. Our experiments reveal that this overlooked redundant\nexecution constitutes nearly half of the total execution overhead of behavioral\nnodes, becoming a significant bottleneck in current RTL fault simulation. The\nunderlying reason for this overlooked redundancy is that, in these cases, the\ntrue execution paths within the behavioral nodes are not affected by the\nchanges in input values. In this work, we propose a behavior-level redundancy\ndetection algorithm that focuses on the true execution paths. Building on the\nelimination of redundant executions, we further developed an efficient RTL\nfault simulation framework, Eraser.Experimental results show that compared to\ncommercial tools, under the same fault coverage, our framework achieves a 3.9\n$\\times$ improvement in simulation performance on average.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-23T07:33:44Z"}
{"aid":"http://arxiv.org/abs/2504.16474v1","title":"Seeking Flat Minima over Diverse Surrogates for Improved Adversarial\n  Transferability: A Theoretical Framework and Algorithmic Instantiation","summary":"The transfer-based black-box adversarial attack setting poses the challenge\nof crafting an adversarial example (AE) on known surrogate models that remain\neffective against unseen target models. Due to the practical importance of this\ntask, numerous methods have been proposed to address this challenge. However,\nmost previous methods are heuristically designed and intuitively justified,\nlacking a theoretical foundation. To bridge this gap, we derive a novel\ntransferability bound that offers provable guarantees for adversarial\ntransferability. Our theoretical analysis has the advantages of \\textit{(i)}\ndeepening our understanding of previous methods by building a general attack\nframework and \\textit{(ii)} providing guidance for designing an effective\nattack algorithm. Our theoretical results demonstrate that optimizing AEs\ntoward flat minima over the surrogate model set, while controlling the\nsurrogate-target model shift measured by the adversarial model discrepancy,\nyields a comprehensive guarantee for AE transferability. The results further\nlead to a general transfer-based attack framework, within which we observe that\nprevious methods consider only partial factors contributing to the\ntransferability. Algorithmically, inspired by our theoretical results, we first\nelaborately construct the surrogate model set in which models exhibit diverse\nadversarial vulnerabilities with respect to AEs to narrow an instantiated\nadversarial model discrepancy. Then, a \\textit{model-Diversity-compatible\nReverse Adversarial Perturbation} (DRAP) is generated to effectively promote\nthe flatness of AEs over diverse surrogate models to improve transferability.\nExtensive experiments on NIPS2017 and CIFAR-10 datasets against various target\nmodels demonstrate the effectiveness of our proposed attack.","main_category":"cs.CR","categories":"cs.CR,cs.LG","published":"2025-04-23T07:33:45Z"}
{"aid":"http://arxiv.org/abs/2504.16479v1","title":"The Dance of Atoms-De Novo Protein Design with Diffusion Model","summary":"The de novo design of proteins refers to creating proteins with specific\nstructures and functions that do not naturally exist. In recent years, the\naccumulation of high-quality protein structure and sequence data and\ntechnological advancements have paved the way for the successful application of\ngenerative artificial intelligence (AI) models in protein design. These models\nhave surpassed traditional approaches that rely on fragments and\nbioinformatics. They have significantly enhanced the success rate of de novo\nprotein design, and reduced experimental costs, leading to breakthroughs in the\nfield. Among various generative AI models, diffusion models have yielded the\nmost promising results in protein design. In the past two to three years, more\nthan ten protein design models based on diffusion models have emerged. Among\nthem, the representative model, RFDiffusion, has demonstrated success rates in\n25 protein design tasks that far exceed those of traditional methods, and other\nAI-based approaches like RFjoint and hallucination. This review will\nsystematically examine the application of diffusion models in generating\nprotein backbones and sequences. We will explore the strengths and limitations\nof different models, summarize successful cases of protein design using\ndiffusion models, and discuss future development directions.","main_category":"q-bio.BM","categories":"q-bio.BM,cs.AI","published":"2025-04-23T07:45:00Z"}
{"aid":"http://arxiv.org/abs/2504.16547v1","title":"Generation of Phonons with Angular Momentum During Ultrafast\n  Demagnetization","summary":"A major question in the field of femtosecond laser-induced demagnetization is\nwhereto the angular momentum lost by the electrons is transferred. Recent\nultrafast electron diffraction measurements [Tauchert \\textit{et al.}, Nature\n{\\bf 602}, 73 (2022)] suggest that this angular momentum is transferred to the\nrotational motion of atoms on a sub-picosecond timescale, but a theory\nconfirmation of this proposition has yet to be given. Here we investigate the\ncoupled electron-nuclear dynamics during ultrafast demagnetization of L1$_0$\nFePt, using Ehrenfest nuclear dynamics simulations combined with the\ntime-dependent density functional theory (TDDFT) framework. We demonstrate that\natomic rotations appear, i.e., the generation of phonons carrying finite\nangular momentum following ultrafast demagnetization. We further show that both\nultrafast demagnetization and the generation of phonons with angular momentum\narise from symmetry constraints imposed by the spin-orbit coupling, thus\nproviding insight in spin-phonon interaction at ultrafast timescales.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.atom-ph","published":"2025-04-23T09:23:31Z"}
{"aid":"http://arxiv.org/abs/2504.16561v1","title":"Performance Analysis of MDI-QKD in Thermal-Loss and Phase Noise Channels","summary":"Measurement-device-independent quantum key distribution (MDI-QKD), enhances\nquantum cryptography by mitigating detector-side vulnerabilities. This study\nanalyzes MDI-QKD performance in thermal-loss and phase noise channels, modeled\nas depolarizing and dephasing channels to capture thermal and phase noise\neffects. Based on this channel framework, we derive analytical expressions for\nBell state measurement probabilities, quantum bit error rates (QBER), and\nsecret key rates (SKR) of MDI-QKD. Our simulations reveal that SKR decreases\nexponentially with transmission distance, with performance further degraded by\nincreasing thermal noise and phase noise, particularly under high thermal noise\nconditions. These findings offer insights into enhancing MDI-QKD's noise\nresilience, supporting secure key generation in practical, noisy environments.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T09:39:34Z"}
{"aid":"http://arxiv.org/abs/2504.16566v1","title":"Optically detected and radio wave-controlled spin chemistry in\n  cryptochrome","summary":"Optically addressable spin systems, such as nitrogen-vacancy (NV) centers in\ndiamond, have been widely studied for quantum sensing applications. In this\nwork, we demonstrate that flavin-based cryptochrome proteins, which generate\nradical pairs upon optical excitation, also exhibit optically detected magnetic\nresonance. We further show that this optical spin interface is tunable by the\nprotein structure. These findings establish radical pairs in proteins as a\nnovel platform for optically addressable spin systems and magnetic field\nsensors. Additionally, the ability to control spin transitions introduces a new\nclass of biophysical tools that hold promise for enabling multiplexed\nfluorescence microscopy. Importantly, due to the spin-selective nature of\nradical pair chemistry, the results lay the groundwork for radiofrequency-based\nmanipulation of biological systems.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T09:45:30Z"}
{"aid":"http://arxiv.org/abs/2504.16580v1","title":"Hyper-Transforming Latent Diffusion Models","summary":"We introduce a novel generative framework for functions by integrating\nImplicit Neural Representations (INRs) and Transformer-based hypernetworks into\nlatent variable models. Unlike prior approaches that rely on MLP-based\nhypernetworks with scalability limitations, our method employs a\nTransformer-based decoder to generate INR parameters from latent variables,\naddressing both representation capacity and computational efficiency. Our\nframework extends latent diffusion models (LDMs) to INR generation by replacing\nstandard decoders with a Transformer-based hypernetwork, which can be trained\neither from scratch or via hyper-transforming-a strategy that fine-tunes only\nthe decoder while freezing the pre-trained latent space. This enables efficient\nadaptation of existing generative models to INR-based representations without\nrequiring full retraining.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-23T10:01:18Z"}
{"aid":"http://arxiv.org/abs/2504.16605v1","title":"Phase stabilization of In2Se3 by disordered Ni intercalation and its\n  enhanced thermoelectrical performance","summary":"Van der Waals (vdW) layered materials have gained significant attention owing\nto their distinctive structure and unique properties. The weak interlayer\nbonding in vdW layered materials enables guest atom intercalation, allowing\nprecise tuning of their physical and chemical properties. In this work, a\nternary compound, NixIn2Se3 (x = 0-0.3), with Ni randomly occupying the\ninterlayers of In2Se3, was synthesized via an intercalation route driven by\nelectron injection. The intercalated Ni atoms act as anchor points within the\ninterlayer of In2Se3, which effectively suppresses the phase transition of\nIn2Se3 at elevated temperatures. Furthermore, the disordered Ni intercalation\nsignificantly enhanced the electrical conductivity of In2Se3 through electron\ninjection, while reducing the thermal conductivity due to the interlayer phonon\nscattering, leading to an improved thermoelectric performance. For instance,\nthe thermoelectric figure of merit (ZT) of Ni0.3In2Se3 increased by 86%\n(in-plane) and 222% (out-of-plane) compared to In2Se3 at 500 oC. These findings\nnot only provide an effective strategy to enhance the performance of layered\nthermoelectric materials, but also demonstrate the potential of intercalation\nchemistry for expanding the application scope of van der Waals (vdW) layered\nmaterials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-23T10:34:23Z"}
{"aid":"http://arxiv.org/abs/2504.16617v1","title":"Security Science (SecSci), Basic Concepts and Mathematical Foundations","summary":"This textbook compiles the lecture notes from security courses taught at\nOxford in the 2000s, at Royal Holloway in the 2010s, and currently in Hawaii.\nThe early chapters are suitable for a first course in security. The middle\nchapters have been used in advanced courses. Towards the end there are also\nsome research problems.","main_category":"cs.CR","categories":"cs.CR,cs.CY,cs.IT,cs.SI,math.IT,math.LO","published":"2025-04-23T11:04:17Z"}
{"aid":"http://arxiv.org/abs/2504.16618v1","title":"The quantum spin Brauer category","summary":"We introduce a diagrammatic braided monoidal category, the quantum spin\nBrauer category, together with a full functor to the category of\nfinite-dimensional, type $1$ modules for $U_q(\\mathfrak{so}(N))$ or\n$U_q(\\mathfrak{o}(N))$. This functor becomes essentially surjective after\npassing to the idempotent completion. The quantum spin Brauer category can be\nthought of as a quantum version of the spin Brauer category introduced\npreviously by the authors. Alternatively, it is an enlargement of the Kauffman\ncategory, obtained by adding a generating object corresponding to the quantum\nspin module.","main_category":"math.QA","categories":"math.QA,math.RT","published":"2025-04-23T11:06:25Z"}
{"aid":"http://arxiv.org/abs/2504.16621v1","title":"Ultra-high dose rate 6 MeV electron irradiation generates stable\n  [1-$^{13}$C]alanine radicals suitable for medical imaging with dissolution\n  Dynamic Nuclear Polarisation","summary":"Dissolution Dynamic Nuclear Polarisation (dDNP) is an experimental technique\nthat increases the sensitivity of magnetic resonance experiments by more than a\nfactor of $10^5$, permitting isotopically-labelled molecules to be transiently\nvisible in MRI scans with their biochemical fates spatially resolvable over\ntime following injection into a patient. dDNP requires a source of unpaired\nelectrons to be in contact with the isotope-labelled nuclei, cooled to\ntemperatures close to absolute zero, and spin-pumped into a given state by\nmicrowave irradiation. At present, these electrons are typically provided by\nchemical radicals which require removal by filtration prior to injection into\nhumans. Alternative sources include UV irradiation, requiring storing samples\nin liquid nitrogen, or cobalt-60 gamma irradiation, which requires days and\ngenerates polarisation two to three orders of magnitude lower than chemical\nradicals. In this study, we present ultra-high dose rate electron beam\nirradiation as a novel alternative for generating non-persistent radicals in\nglycerol/alanine mixtures. These radicals are stable for months at room\ntemperature, are present at concentrations dependent on irradiation dose, and\ngenerate comparable nuclear polarisation to the typically used trityl radicals\n(20%) through a novel mechanism. The process of their generation inherently\nsterilises samples, and they enable the imaging of alanine metabolism in vivo\nusing dDNP. This new method of generating radicals for dDNP offers the\npotential to report on relevant biological processes while being translatable\nto the clinic.","main_category":"physics.med-ph","categories":"physics.med-ph,q-bio.BM","published":"2025-04-23T11:23:23Z"}
{"aid":"http://arxiv.org/abs/2504.16628v1","title":"ParetoHqD: Fast Offline Multiobjective Alignment of Large Language\n  Models using Pareto High-quality Data","summary":"Aligning large language models with multiple human expectations and values is\ncrucial for ensuring that they adequately serve a variety of user needs. To\nthis end, offline multiobjective alignment algorithms such as the\nRewards-in-Context algorithm have shown strong performance and efficiency.\nHowever, inappropriate preference representations and training with imbalanced\nreward scores limit the performance of such algorithms. In this work, we\nintroduce ParetoHqD that addresses the above issues by representing human\npreferences as preference directions in the objective space and regarding data\nnear the Pareto front as ''high-quality'' data. For each preference, ParetoHqD\nfollows a two-stage supervised fine-tuning process, where each stage uses an\nindividual Pareto high-quality training set that best matches its preference\ndirection. The experimental results have demonstrated the superiority of\nParetoHqD over five baselines on two multiobjective alignment tasks.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-23T11:35:57Z"}
{"aid":"http://arxiv.org/abs/2504.16661v1","title":"Impact of unidirectional magnetoresistance on spin-orbit torque analysis","summary":"The second-harmonic Hall technique is a widely used, sensitive method for\nstudying the spin-orbit torques generated by charge current. It exploits the\ndependence of the Hall resistance on the magnetization direction, although\nthermal phenomena also contribute. Historically, deviations from the expected\nmagnetic field dependence have usually been neglected. Based on our studies on\npermalloy/platinum bilayers, we show that a unidirectional magnetoresistance -\nknown to appear in the second-harmonic longitudinal resistance - also appears\nin the Hall data, and that describing the results in a wide field range with\nthese contributions is essential to accurately estimate the torques.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-23T12:28:20Z"}
{"aid":"http://arxiv.org/abs/2504.16662v1","title":"MHD Simulations Preliminarily Predict The Habitability and Radio\n  Emission of TRAPPIST-1e","summary":"As the closest Earth-like exoplanet within the habitable zone of the M-dwarf\nstar TRAPPIST-1, TRAPPIST-1e exhibits a magnetic field topology that is\ndependent on space weather conditions. Variations in these conditions influence\nits habitability and contribute to its radio emissions. Our objective is to\nanalyze the response of different terrestrial magnetosphere structures of\nTRAPPIST-1e to various space weather conditions, including events analogous to\ncoronal mass ejections (CMEs). We assess its habitability by computing the\nmagnetopause standoff distance and predict the resulting radio emissions using\nscaling laws. This study provides some priors for future radio observations. We\nperform three-dimensional magnetohydrodynamic (MHD) simulations of the\nTRAPPIST-1e system using the PLUTO code in spherical coordinates. Our analysis\nindicates that the predicted habitability and radio emission of TRAPPIST-1e\nstrongly depend on the planet's magnetic field intensity and magnetic axis\ninclination. Within sub-Alfvenic, super-Alfvenic, and transitional stellar wind\nregimes, the radio emission intensity positively correlates with both planetary\nmagnetic field strength and axial tilt, while planetary habitability,\nquantified by the magnetopause standoff distance, shows a positive correlation\nwith magnetic field strength and a negative correlation with magnetic axis\ntilt...","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.GA","published":"2025-04-23T12:28:26Z"}
{"aid":"http://arxiv.org/abs/2504.16679v1","title":"Transition mechanisms in hypersonic wind-tunnel nozzles: a\n  methodological approach using global linear stability analysis","summary":"Base-flow computations and stability analyses are performed for a hypersonic\nwind tunnel nozzle at a Mach number of 6. Isothermal and adiabatic wall\nboundary conditions are investigated, and moderate stagnation conditions are\nused to provide representative scenarios to study the transition in quiet\nhypersonic wind tunnel facilities. Under these conditions, the studied nozzle\nshows a small flow separation at the convergent inlet. Global stability\nanalysis reveals that this recirculation bubble may trigger a classical\nthree-dimensional stationary unstable global mode. Resolvent analysis reveals\nG\\\"ortler, first and second Mack modes affecting the divergent part of the\nnozzle, along with a Kelvin-Helmholtz instability induced by the bubble. The\npresent study also highlights the key impact of perturbations located in the\nconvergent inlet on the development of instabilities further downstream in the\ndivergent outlet, helping understand the need and efficacy of a suction lip\nupstream of the nozzle throat to mitigate instabilities in the divergent\nnozzle. Detailed knowledge of all these mechanisms is essential for\nunderstanding flows in quiet hypersonic wind tunnel nozzles and, consequently,\nrepresents a key step toward the optimisation of such nozzles.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-23T12:56:20Z"}
{"aid":"http://arxiv.org/abs/2504.16691v1","title":"Rethinking Vision Transformer for Large-Scale Fine-Grained Image\n  Retrieval","summary":"Large-scale fine-grained image retrieval (FGIR) aims to retrieve images\nbelonging to the same subcategory as a given query by capturing subtle\ndifferences in a large-scale setting. Recently, Vision Transformers (ViT) have\nbeen employed in FGIR due to their powerful self-attention mechanism for\nmodeling long-range dependencies. However, most Transformer-based methods focus\nprimarily on leveraging self-attention to distinguish fine-grained details,\nwhile overlooking the high computational complexity and redundant dependencies\ninherent to these models, limiting their scalability and effectiveness in\nlarge-scale FGIR. In this paper, we propose an Efficient and Effective\nViT-based framework, termed \\textbf{EET}, which integrates token pruning module\nwith a discriminative transfer strategy to address these limitations.\nSpecifically, we introduce a content-based token pruning scheme to enhance the\nefficiency of the vanilla ViT, progressively removing background or\nlow-discriminative tokens at different stages by exploiting feature responses\nand self-attention mechanism. To ensure the resulting efficient ViT retains\nstrong discriminative power, we further present a discriminative transfer\nstrategy comprising both \\textit{discriminative knowledge transfer} and\n\\textit{discriminative region guidance}. Using a distillation paradigm, these\ncomponents transfer knowledge from a larger ``teacher'' ViT to a more efficient\n``student'' model, guiding the latter to focus on subtle yet crucial regions in\na cost-free manner. Extensive experiments on two widely-used fine-grained\ndatasets and four large-scale fine-grained datasets demonstrate the\neffectiveness of our method. Specifically, EET reduces the inference latency of\nViT-Small by 42.7\\% and boosts the retrieval performance of 16-bit hash codes\nby 5.15\\% on the challenging NABirds dataset.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-23T13:23:56Z"}
{"aid":"http://arxiv.org/abs/2504.16698v1","title":"Effect of pressure on the transport properties and thermoelectric\n  performance of Dirac semimetal ZrTe5","summary":"In this study, we have investigated and compared the effect of hydrostatic\npressure up to ~20 kbar on the transport properties of ZrTe5 single crystals\ngrown by chemical vapor transport (CVT) and flux methods. With the application\nof pressure, the electrical resistivity Rho(T) and thermopower S(T) of both\ncrystals were found to increase in the whole temperature range unlike the other\nknown thermoelectric materials, such as Bi2Te3, SnSe etc. This observation is\nsupported by the complementary first-principles band structure calculation as\nthe application of pressure widens the direct bandgap at {\\Gamma} point.\nMoreover, the analysis of the pressure dependent magneto-transport and\nShubnikov de-Hass oscillation results revealed an increase in carrier\nconcentration and effective mass along with the reduction of mobility as\npressure rises. Furthermore, with the application of pressure, the flux-grown\nZrTe5 crystals display a transition from unipolar to bipolar charge transport\nas evidenced by the emergence of resistivity peak at T* under high pressure,\nunlike the CVT-grown ZrTe5 crystals where the bipolar charge transport near its\ncharacteristic resistivity peak (Tp) remains unaffected.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-23T13:28:58Z"}
{"aid":"http://arxiv.org/abs/2504.16700v1","title":"The Electric Dipole Moment of the electron in the decoupling limit of\n  the aligned Two-Higgs Doublet Model","summary":"We present a discussion of model-independent contributions to the EDM of the\nelectron. We focus on those contributions that emerge from a heavy scalar\nsector that is linearly realized. In particular, we explore the decoupling\nlimit of the aligned 2HDM. In this model, Barr-Zee diagrams with a fermion loop\nproduce logarithmically-enhanced contributions that are proportional to\npotentially large new sources of CP violation. In the decoupling limit these\ncontributions are generated by effective dimension-6 operators via the mixing\nof four-fermion operators into electroweak dipole operators. These logarithmic\ncontributions are not present in more constrained versions of the 2HDM where a\n$\\mathcal Z_2$ symmetry is imposed, which then controls the basis of effective\noperators needed to describe the new physics contributions to the electron EDM.\nThus, the $\\mathcal Z_2$ symmetry provides a suppression mechanism. We then\nstudy how the experimental bounds on the electron EDM constrain the set of\nparameters of the aligned 2HDM.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-23T13:29:11Z"}
{"aid":"http://arxiv.org/abs/2504.16708v1","title":"Density of rational languages under shift invariant measures","summary":"We study density of rational languages under shift invariant probability\nmeasures on spaces of two-sided infinite words, which generalizes the classical\nnotion of density studied in formal languages and automata theory. The density\nfor a language is defined as the limit in average (if it exists) of the\nprobability that a word of a given length belongs to the language. We establish\nthe existence of densities for all rational languages under all shift invariant\nmeasures. We also give explicit formulas under certain conditions, in\nparticular when the language is aperiodic. Our approach combines tools and\nideas from semigroup theory and ergodic theory.","main_category":"cs.FL","categories":"cs.FL","published":"2025-04-23T13:39:02Z"}
{"aid":"http://arxiv.org/abs/2504.16721v1","title":"Spectrum of cones of non-reduced plane curves with ordinary\n  singularities","summary":"We give a simple proof of the assertion claiming that the spectrum of the\ncone of a non-reduced plane curve can be determined only by its multiplicities\nalong local irreducible components at each singular point as well as those\nalong global ones together with the degrees of the latter (where the relation\nbetween global components and singular points is not needed) if the associated\nreduced plane curve have only ordinary singularities (for instance a line\narrangement). Note that the last condition is strictly weaker than local\nhomogeneity. As a corollary we can also get a simple proof of a formula which\nis equivalent to the one obtained earlier by the second-named author.","main_category":"math.AG","categories":"math.AG","published":"2025-04-23T13:51:18Z"}
{"aid":"http://arxiv.org/abs/2504.16722v1","title":"PMG: Progressive Motion Generation via Sparse Anchor Postures Curriculum\n  Learning","summary":"In computer animation, game design, and human-computer interaction,\nsynthesizing human motion that aligns with user intent remains a significant\nchallenge. Existing methods have notable limitations: textual approaches offer\nhigh-level semantic guidance but struggle to describe complex actions\naccurately; trajectory-based techniques provide intuitive global motion\ndirection yet often fall short in generating precise or customized character\nmovements; and anchor poses-guided methods are typically confined to synthesize\nonly simple motion patterns. To generate more controllable and precise human\nmotions, we propose \\textbf{ProMoGen (Progressive Motion Generation)}, a novel\nframework that integrates trajectory guidance with sparse anchor motion\ncontrol. Global trajectories ensure consistency in spatial direction and\ndisplacement, while sparse anchor motions only deliver precise action guidance\nwithout displacement. This decoupling enables independent refinement of both\naspects, resulting in a more controllable, high-fidelity, and sophisticated\nmotion synthesis. ProMoGen supports both dual and single control paradigms\nwithin a unified training process. Moreover, we recognize that direct learning\nfrom sparse motions is inherently unstable, we introduce \\textbf{SAP-CL (Sparse\nAnchor Posture Curriculum Learning)}, a curriculum learning strategy that\nprogressively adjusts the number of anchors used for guidance, thereby enabling\nmore precise and stable convergence. Extensive experiments demonstrate that\nProMoGen excels in synthesizing vivid and diverse motions guided by predefined\ntrajectory and arbitrary anchor frames. Our approach seamlessly integrates\npersonalized motion with structured guidance, significantly outperforming\nstate-of-the-art methods across multiple control scenarios.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-23T13:51:42Z"}
{"aid":"http://arxiv.org/abs/2504.16737v1","title":"Scaling limints for supercritical nearly unstable Hawkes processes with\n  hheavy tail","summary":"In this paper, we establish the asymptotic behavior of {\\it supercritical}\nnearly unstable Hawkes processes with a power law kernel. We find that, the\nHawkes process in our context admits a similar equation to that in\n\\cite{MR3563196} for {\\it subcritical} case. In particular, the rescaled Hawkes\nprocess $(Z^n_{nt}/n^{2\\alpha})_{t\\in[0,1]}$ converges in law to a kind of\nintegrated fractional Cox Ingersoll Ross process with different coefficients\nfrom that in \\cite{MR3563196}, as $n$ tends to infinity.","main_category":"math.PR","categories":"math.PR","published":"2025-04-23T14:08:53Z"}
{"aid":"http://arxiv.org/abs/2504.16763v1","title":"Noise-Tolerant Coreset-Based Class Incremental Continual Learning","summary":"Many applications of computer vision require the ability to adapt to novel\ndata distributions after deployment. Adaptation requires algorithms capable of\ncontinual learning (CL). Continual learners must be plastic to adapt to novel\ntasks while minimizing forgetting of previous tasks.However, CL opens up\navenues for noise to enter the training pipeline and disrupt the CL. This work\nfocuses on label noise and instance noise in the context of class-incremental\nlearning (CIL), where new classes are added to a classifier over time, and\nthere is no access to external data from past classes. We aim to understand the\nsensitivity of CL methods that work by replaying items from a memory\nconstructed using the idea of Coresets. We derive a new bound for the\nrobustness of such a method to uncorrelated instance noise under a general\nadditive noise threat model, revealing several insights. Putting the theory\ninto practice, we create two continual learning algorithms to construct\nnoise-tolerant replay buffers. We empirically compare the effectiveness of\nprior memory-based continual learners and the proposed algorithms under label\nand uncorrelated instance noise on five diverse datasets. We show that existing\nmemory-based CL are not robust whereas the proposed methods exhibit significant\nimprovements in maximizing classification accuracy and minimizing forgetting in\nthe noisy CIL setting.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV,cs.NE","published":"2025-04-23T14:34:20Z"}
{"aid":"http://arxiv.org/abs/2504.16793v1","title":"A self-avoiding curve associated with sums of digits","summary":"For each $n\\in N ^{\\ast }$, we write $s_{n}=\\left( 1,\\ldots ,1,0\\right) $\nwith $n$ times $1$. For each $a \\in N$, we consider the binary representation\n$\\left( a_{i}\\right) _{i\\in -N }$ of $a$ with $a_{i}=0$ for nearly each $i$; we\ndenote by $\\alpha _{n}(a)$ the number of integers $i$ such that $\\left( a_{i},\n\\ldots ,a_{i+n} \\right) =s_{n}$. We consider the curve $C_{n}=\\left(\nS_{n,k}\\right) _{k\\in N ^{\\ast }}$ which consists of consecutive segments of\nlength $1$ such that, for each $k$, $S_{n,k+1}$ is obtained from $S_{n,k}$ by\nturning right if $k+\\alpha _{n}(k)-\\alpha _{n}(k-1)$ is even and left\notherwise. $C_{1}$ is self-avoiding since it is the curve associated to the\nalternating folding sequence. In [1], M. Mend\\`es France and J. Shallit\nconjectured that the curves $C_{n}$ for $n\\geq 2$ are also self-avoiding. In\nthe present paper, we show that this property is true for $n=2$. We also prove\nthat $C_{2}$ has some properties similar to those which were shown in [2], [3]\nand [4] for folding curves.","main_category":"math.CO","categories":"math.CO","published":"2025-04-23T15:13:11Z"}
{"aid":"http://arxiv.org/abs/2504.16799v1","title":"Coalescence delay mediated by the gas layer during the impact of hot\n  droplets","summary":"Coalescence may not occur immediately when droplets impact a liquid film.\nDespite the prevalence of the high-temperature condition during the impact\nprocess in many applications, the effect of droplet temperature on droplet\ncoalescence is rarely considered. In this study, we experimentally investigate\nthe droplet coalescence during the impact of hot droplets on a liquid film by\nusing color interferometry, high-speed imaging, and infrared imaging. We find\nthat the coalescence of the hot droplet with the liquid film can be delayed\nwhich is mediated by the intervening gas layer between the droplet and the\nfilm. Compared with droplets at room temperature, the residence time of hot\ndroplets can increase by more than two orders of magnitude. We find that the\nthickness of the gas layer increases with the droplet temperature, explaining\nthat the thermal delay of coalescence is due to the thicker gas layer. During\nthe hot droplet impact, the temperature gradient at the bottom of the droplet\ninduces Maranogni flow, which can delay the drainage of the intervening gas\nlayer. The results also show that as the Weber number increases, the residence\ntime of the droplet decreases because of the thinner thickness of the gas\nlayer.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-23T15:20:19Z"}
{"aid":"http://arxiv.org/abs/2504.16818v1","title":"Rediscussion of eclipsing binaries. Paper XXIV. The delta Scuti pulsator\n  V596 Pup (formerly known as VV Pyx)","summary":"V596 Pup is a detached eclipsing binary containing two A1 V stars in a 4.596\nd period orbit with a small eccentricity and apsidal motion, previously\ndesignated as VV Pyxidis. We use new light curves from the Transiting Exoplanet\nSurvey Satellite (TESS) and published radial velocities to determine the\nphysical properties of the component stars. We find masses of 2.098 +/- 0.021\nMsun and 2.091 +/- 0.018 Msun, and radii of 2.179 +/- 0.008 Rsun and 2.139 +/-\n0.007 Rsun. The measured distance to the system is affected by the light from a\nnearby companion star; we obtain 178.4 +/- 2.5 pc. The properties of the system\nare best matched by theoretical predictions for a subsolar metallicity of Z =\n0.010 and an age of 570 Myr. We measure seven significant pulsation frequencies\nfrom the light curve, six of which are consistent with delta Scuti pulsations\nand one of which is likely of slowly-pulsating B-star type.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-23T15:37:29Z"}
{"aid":"http://arxiv.org/abs/2504.16824v1","title":"Nurturing Language Proficiency in Spanish.speaking children Through\n  digital competence","summary":"This article explores into the intricate design and meticulous construction\nof a digital platform aimed at revolutionizing early-age English education,\nparticularly for Spanish-speaking children. The focus of this work used an\ninnovative methodologies, vibrant and engaging visuals, and a comprehensive\napproach to phonics. The principles of usability, accessibility, and\nuser-centered design are intricately woven into every facet of the platform's\narchitecture.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-23T15:41:12Z"}
{"aid":"http://arxiv.org/abs/2504.16826v1","title":"Modeling a Non-Singular Universe with Late-Time Acceleration through a\n  Novel Inhomogeneous Barotropic Equation of State","summary":"In this study, we investigated the effects of incorporating barotropic fluids\non cosmological solutions within the general relativity (GR) framework. We\nproposed a modified version of the barotropic fluid with the EoS, $p=\\zeta _0\n\\rho +\\zeta _1 \\rho \\left(t-t_0\\right){}^{-2 n}$, where $\\zeta_0$, $\\zeta_1$,\n$t_0$ and $n$ are some constants. Our goal is to explore if this type of EoS\nmight help explain the universe's development, concentrating on the scenario\nwhere the universe bounces instead of singularities. Interestingly the generic\nsolutions derived from our model are sufficiently adaptable to illustrate the\nbounce scenario, cosmic inflation and late-time dark-energy behaviour. The\nparameters $\\zeta_0$, $\\zeta_1$, $t_0$, and $n$ define the universe's phase in\nthis non-singular solution. We investigated several elements of cosmic\ndevelopment, including as the energy density, deceleration parameter, and\nenergy conditions, in order to validate our model. Stability analysis showed\nthat the perturbations approach to zero as the time evolves, indicating the\nmodel is stable under scalar perturbation. Additionally, we looked at the\nstatefinder diagnostics and Hubble flow dynamics to get more understanding of\nthe model's dark energy and inflationary behaviour, respectively. Additionally,\nwe conducted a study of the models' relevance to the observational datasets\nfrom BAO, DESI and Pantheon+SH0ES.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-23T15:43:02Z"}
{"aid":"http://arxiv.org/abs/2504.16842v1","title":"Bertrand Menu Competition","summary":"We study a variation of the price competition model a la Bertrand, in which\nfirms must offer menus of contracts that obey monotonicity constraints, e.g.,\nwages that rise with worker productivity to comport with equal pay legislation.\nWhile such constraints limit firms' ability to undercut their competitors, we\nshow that Bertrand's classic result still holds: competition drives firm\nprofits to zero and leads to efficient allocations without rationing. Our\nfindings suggest that Bertrand's logic extends to a broader variety of markets,\nincluding labor and product markets that are subject to real-world constraints\non pricing across workers and products.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-23T16:06:09Z"}
{"aid":"http://arxiv.org/abs/2504.16843v1","title":"Physically Consistent Humanoid Loco-Manipulation using Latent Diffusion\n  Models","summary":"This paper uses the capabilities of latent diffusion models (LDMs) to\ngenerate realistic RGB human-object interaction scenes to guide humanoid\nloco-manipulation planning. To do so, we extract from the generated images both\nthe contact locations and robot configurations that are then used inside a\nwhole-body trajectory optimization (TO) formulation to generate physically\nconsistent trajectories for humanoids. We validate our full pipeline in\nsimulation for different long-horizon loco-manipulation scenarios and perform\nan extensive analysis of the proposed contact and robot configuration\nextraction pipeline. Our results show that using the information extracted from\nLDMs, we can generate physically consistent trajectories that require\nlong-horizon reasoning.","main_category":"cs.RO","categories":"cs.RO,cs.GR","published":"2025-04-23T16:07:02Z"}
{"aid":"http://arxiv.org/abs/2504.16852v1","title":"Fair division of the replacement-units without an appraiser in urban\n  renewal processes","summary":"Rebuild and Divide is an urban renewal process that involves the demolition\nof old buildings and the construction of new ones. Original homeowners are\ncompensated with upgraded apartments, while surplus units are sold for profit,\nso theoretically it is a win-win project for all parties involved. However,\nmany rebuild-and-divide projects withheld or delayed due to disagreements over\nthe assignment of new units, claiming they are not \"fair\". The goal of this\nresearch is to develop algorithms for envy-free allocation of the new units.\nThe main challenge is that, in contrast to previous work on envy-free\nallocation, the envy depends also on the value of the old units, as people with\nmore valuable old units are entitled to more valuable new units. We introduce\nthree models that capture different notions of fairness: (1) the Difference\nModel, where agents evaluate their gains relative to others; (2) the Envy Sum\nModel, which permits some envy as long as the total envy does not exceed that\nof the original allocation; and (3) the Ratio Model, where fairness is assessed\nbased on the proportional value of old apartments. For each model, we establish\nan envy criterion and seek a payment vector and allocation that ensure\nenvy-freeness. These models present both theoretical challenges and intriguing\ninsights. Additionally, within the Envy Sum Model, we present a mechanism that\ncomputes an allocation and payment scheme that minimizes total envy. We also\nanalyze the mechanism's vulnerability to manipulation and identify conditions\nunder which it is obviously manipulable.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-23T16:19:55Z"}
{"aid":"http://arxiv.org/abs/2504.16869v1","title":"Geometry of Cells Sensible to Curvature and Their Receptive Profiles","summary":"We propose a model of the functional architecture of curvature sensible cells\nin the visual cortex that associates curvature with scale. The feature space of\norientation and position is naturally enhanced via its oriented prolongation,\nyielding a 4-dimensional manifold endowed with a canonical Engel structure.\nThis structure encodes position, orientation, signed curvature, and scale. We\nassociate an open submanifold of the prolongation with the quasi-regular\nrepresentation of the similitude group SIM (2), and find left-invariant\ngenerators for the Engel structure. Finally, we use the generators of the Engel\nstructure to characterize curvature-sensitive receptive profiles .","main_category":"q-bio.NC","categories":"q-bio.NC,math.DG","published":"2025-04-23T16:44:25Z"}
{"aid":"http://arxiv.org/abs/2504.16881v1","title":"Fermi-LAT and FAST observation of the gamma-ray binary HESS J0632+057","summary":"Using 15 years of data from the Fermi Large Area Telescope (Fermi-LAT), we\nperformed a comprehensive analysis on the gamma-ray binary HESS J0632+057. Its\nspectrum in 0.1-300 GeV band is well described by a power law model with an\nindex of $2.40\\pm0.16$, leading to an energy flux of (5.5$\\pm$1.6$)\\times$\n10$^{-12}$ erg cm$^{-2}$ s$^{-1}$. The GeV Spectral Energy Distribution (SED)\nof HESS J0632+057 hints for a spectral turn-over between $\\sim$10-100 GeV.\nOrbital analysis reveals a flux enhancement during the phase range of 0.2-0.4,\nconsistent with the X-ray and TeV light curves, indicating an origin of a\ncommon particle population. We carried out six deep radio observations on HESS\nJ0632+057 with the Five-hundred-meter Aperture Spherical Telescope (FAST),\nevenly distributed across its orbit, reaching a detection sensitivity of\n2$\\mu$Jy. However, no radio pulsation was detected within these observations.\nThe absence of radio pulsation may be attributed to the dense stellar wind\nenvironment of HESS J0632+057.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-23T16:57:27Z"}
{"aid":"http://arxiv.org/abs/2504.16893v1","title":"Practical approaches for crystal structure predictions with inpainting\n  generation and universal interatomic potentials","summary":"We present Crystal Host-Guided Generation (CHGGen), a diffusion-based\nframework for crystal structure prediction. Unconditional generation with\ndiffusion models demonstrates limited efficacy in identifying symmetric\ncrystals as the unit cell size increases. CHGGen addresses this limitation\nthrough conditional generation with the inpainting method, which optimizes a\nfraction of atomic positions within a predefined and symmetrized host\nstructure. We demonstrate the method on the ZnS-P$_2$S$_5$ and Li-Si chemical\nsystems, where the inpainting method generates a higher fraction of symmetric\nstructures than unconditional generation. The practical significance of CHGGen\nextends to enabling the structural modification of crystal structures,\nparticularly for systems with partial occupancy, surface absorption and\ndefects. The inpainting method also allows for seamless integration with other\ngenerative models, providing a versatile framework for accelerating materials\ndiscovery.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.comp-ph","published":"2025-04-23T17:21:03Z"}
{"aid":"http://arxiv.org/abs/2504.16904v1","title":"Observation of Double Hysteresis in CoFe$_2$O$_4$/MnFe$_2$O$_4$\n  Core/Shell Nanoparticles and Its Contribution to AC Heat Induction","summary":"Magnetic core/shell nanoparticles are promising candidates for magnetic\nhyperthermia due to its high AC magnetic heat induction (specific loss power\n(SLP)). It's widely accepted that magnetic exchange-coupling between core and\nshell plays the crucial role in enhancing SLP of magnetic core/shell\nnanoparticles. However, the physical contribution of exchange coupling to SLP\nhas not been systematically investigated, and the underlying mechanism remains\nunclear. In this study, magnetic hard/soft CoFe$_2$O$_4$/MnFe$_2$O$_4 and\ninverted soft/hard MnFe$_2$O$_4$/CoFe$_2$O$_4$ core/shell nanoparticles were\nsynthesized, systematically varying the number of shell layers, to investigate\nthe physical contribution of internal bias coupling at the core/shell interface\nto AC heat induction (SLP). Our results show that a unique magnetic property,\ndouble-hysteresis loop, was present and clearly observed, which was never\nreported in previous core/shell research literature. According to the\nexperimentally and theoretically analyzed results, the double-hysteresis\nbehavior in core/shell nanoparticles was caused by the difference in magnetic\nanisotropy between core and shell materials, separated by a non-magnetic\ninterface. The enhanced SLP and maximum temperature rise (TAC,max) of\ncore/shell nanoparticles are attributed to the optimized magnetic anisotropy,\nAC magnetic softness and double hysteresis behavior due to the internal bias\ncoupling. These results demonstrate that the rational design capabilities to\nseparately control the magnetic anisotropy, AC/DC magnetic properties by\nvarying the volume ration between core and shell and by switching hard or soft\nphase materials between core and shell are effective modalities to enhance the\nAC heat induction of core/shell nanoparticles for magnetic nanoparticle\nhyperthermia.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-23T17:28:28Z"}
{"aid":"http://arxiv.org/abs/2504.16925v1","title":"Latent Diffusion Planning for Imitation Learning","summary":"Recent progress in imitation learning has been enabled by policy\narchitectures that scale to complex visuomotor tasks, multimodal distributions,\nand large datasets. However, these methods often rely on learning from large\namount of expert demonstrations. To address these shortcomings, we propose\nLatent Diffusion Planning (LDP), a modular approach consisting of a planner\nwhich can leverage action-free demonstrations, and an inverse dynamics model\nwhich can leverage suboptimal data, that both operate over a learned latent\nspace. First, we learn a compact latent space through a variational\nautoencoder, enabling effective forecasting of future states in image-based\ndomains. Then, we train a planner and an inverse dynamics model with diffusion\nobjectives. By separating planning from action prediction, LDP can benefit from\nthe denser supervision signals of suboptimal and action-free data. On simulated\nvisual robotic manipulation tasks, LDP outperforms state-of-the-art imitation\nlearning approaches, as they cannot leverage such additional data.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-23T17:53:34Z"}
{"aid":"http://arxiv.org/abs/2504.17264v1","title":"JurisCTC: Enhancing Legal Judgment Prediction via Cross-Domain Transfer\n  and Contrastive Learning","summary":"In recent years, Unsupervised Domain Adaptation (UDA) has gained significant\nattention in the field of Natural Language Processing (NLP) owing to its\nability to enhance model generalization across diverse domains. However, its\napplication for knowledge transfer between distinct legal domains remains\nlargely unexplored. To address the challenges posed by lengthy and complex\nlegal texts and the limited availability of large-scale annotated datasets, we\npropose JurisCTC, a novel model designed to improve the accuracy of Legal\nJudgment Prediction (LJP) tasks. Unlike existing approaches, JurisCTC\nfacilitates effective knowledge transfer across various legal domains and\nemploys contrastive learning to distinguish samples from different domains.\nSpecifically, for the LJP task, we enable knowledge transfer between civil and\ncriminal law domains. Compared to other models and specific large language\nmodels (LLMs), JurisCTC demonstrates notable advancements, achieving peak\naccuracies of 76.59% and 78.83%, respectively.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-24T05:48:57Z"}
{"aid":"http://arxiv.org/abs/2504.17266v1","title":"Multipartite continuous-variable quantum nondemolition interaction and\n  entanglement certification and monitoring","summary":"The quantum nondemolition (QND) measurement is one of the most studied\nquantum measurement procedures. Usually, such process involves the coupling of\na single system of interest, called signal, with a single probe system, so that\nthe relevant information in the signal system is indirectly measured by\nobserving the probe system. Here, we extend the concept of quantum\nnondemolition interaction to the cases in which the signal and the probe\nsystems are each one multipartite continuous-variable systems. Specifically, we\npropose a general scheme that performs the multipartite QND interactions,\nrelying on beam-splitter couplings among the signal and probe modes with\nancillary modes prepared off-line in squeezed states. The scheme is also\ncomposed by homodyne detections and feedforward modulations. The ancillary\nmodes are detected in the process, providing photocurrents for post-modulation\nof the output systems, as well as sufficient information to calculate genuine\nmultipartite entanglement conditions of the input systems and to monitor\nsimilar conditions of the output systems.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-24T05:51:53Z"}
{"aid":"http://arxiv.org/abs/2504.17269v1","title":"Towards Generalized and Training-Free Text-Guided Semantic Manipulation","summary":"Text-guided semantic manipulation refers to semantically editing an image\ngenerated from a source prompt to match a target prompt, enabling the desired\nsemantic changes (e.g., addition, removal, and style transfer) while preserving\nirrelevant contents. With the powerful generative capabilities of the diffusion\nmodel, the task has shown the potential to generate high-fidelity visual\ncontent. Nevertheless, existing methods either typically require time-consuming\nfine-tuning (inefficient), fail to accomplish multiple semantic manipulations\n(poorly extensible), and/or lack support for different modality tasks (limited\ngeneralizability). Upon further investigation, we find that the geometric\nproperties of noises in the diffusion model are strongly correlated with the\nsemantic changes. Motivated by this, we propose a novel $\\textit{GTF}$ for\ntext-guided semantic manipulation, which has the following attractive\ncapabilities: 1) $\\textbf{Generalized}$: our $\\textit{GTF}$ supports multiple\nsemantic manipulations (e.g., addition, removal, and style transfer) and can be\nseamlessly integrated into all diffusion-based methods (i.e., Plug-and-play)\nacross different modalities (i.e., modality-agnostic); and 2)\n$\\textbf{Training-free}$: $\\textit{GTF}$ produces high-fidelity results via\nsimply controlling the geometric relationship between noises without tuning or\noptimization. Our extensive experiments demonstrate the efficacy of our\napproach, highlighting its potential to advance the state-of-the-art in\nsemantics manipulation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T05:54:56Z"}
{"aid":"http://arxiv.org/abs/2504.17284v1","title":"Period Function of Maass forms from Ramanujan's Lost Notebook","summary":"The Lost Notebook of Ramanujan contains a number of beautiful formulas, one\nof which can be found on its page 220. It involves an interesting function,\nwhich we denote as $\\mathcal{F}_1(x)$. In this paper, we show that\n$\\mathcal{F}_1(x)$ belongs to the category of period functions as it satisfies\nthe period relations of Maass forms in the sense of Lewis and Zagier \\cite{lz}.\nHence, we refer to $\\mathcal{F}_1(x)$ as the \\emph{Ramanujan period function}.\nMoreover, one of the salient aspects of the Ramanujan period function\n$\\mathcal{F}_1(x)$ that we found out is that it is a Hecke eigenfunction under\nthe action of Hecke operators on the space of periods. We also establish that\nit naturally appears in a Kronecker limit formula of a certain zeta function,\nrevealing its connections to various topics. Finally, we generalize\n$\\mathcal{F}_1(x)$ to include a parameter $s,$ connecting our work to the\nbroader theory of period functions developed by Bettin and Conrey \\cite{bc} and\nLewis and Zagier \\cite{lz}. We emphasize that Ramanujan was the first to study\nthis function, marking the beginning of the study of period functions.","main_category":"math.NT","categories":"math.NT,math.CA","published":"2025-04-24T06:26:22Z"}
{"aid":"http://arxiv.org/abs/2504.17304v1","title":"You Are What You Bought: Generating Customer Personas for E-commerce\n  Applications","summary":"In e-commerce, user representations are essential for various applications.\nExisting methods often use deep learning techniques to convert customer\nbehaviors into implicit embeddings. However, these embeddings are difficult to\nunderstand and integrate with external knowledge, limiting the effectiveness of\napplications such as customer segmentation, search navigation, and product\nrecommendations. To address this, our paper introduces the concept of the\ncustomer persona. Condensed from a customer's numerous purchasing histories, a\ncustomer persona provides a multi-faceted and human-readable characterization\nof specific purchase behaviors and preferences, such as Busy Parents or Bargain\nHunters.\n  This work then focuses on representing each customer by multiple personas\nfrom a predefined set, achieving readable and informative explicit user\nrepresentations. To this end, we propose an effective and efficient solution\nGPLR. To ensure effectiveness, GPLR leverages pre-trained LLMs to infer\npersonas for customers. To reduce overhead, GPLR applies LLM-based labeling to\nonly a fraction of users and utilizes a random walk technique to predict\npersonas for the remaining customers. We further propose RevAff, which provides\nan absolute error $\\epsilon$ guarantee while improving the time complexity of\nthe exact solution by a factor of at least\n$O(\\frac{\\epsilon\\cdot|E|N}{|E|+N\\log N})$, where $N$ represents the number of\ncustomers and products, and $E$ represents the interactions between them. We\nevaluate the performance of our persona-based representation in terms of\naccuracy and robustness for recommendation and customer segmentation tasks\nusing three real-world e-commerce datasets. Most notably, we find that\nintegrating customer persona representations improves the state-of-the-art\ngraph convolution-based recommendation model by up to 12% in terms of NDCG@K\nand F1-Score@K.","main_category":"cs.IR","categories":"cs.IR,cs.AI","published":"2025-04-24T06:59:16Z"}
{"aid":"http://arxiv.org/abs/2504.17314v1","title":"Class-Conditional Distribution Balancing for Group Robust Classification","summary":"Spurious correlations that lead models to correct predictions for the wrong\nreasons pose a critical challenge for robust real-world generalization.\nExisting research attributes this issue to group imbalance and addresses it by\nmaximizing group-balanced or worst-group accuracy, which heavily relies on\nexpensive bias annotations. A compromise approach involves predicting bias\ninformation using extensively pretrained foundation models, which requires\nlarge-scale data and becomes impractical for resource-limited rare domains. To\naddress these challenges, we offer a novel perspective by reframing the\nspurious correlations as imbalances or mismatches in class-conditional\ndistributions, and propose a simple yet effective robust learning method that\neliminates the need for both bias annotations and predictions. With the goal of\nreducing the mutual information between spurious factors and label information,\nour method leverages a sample reweighting strategy to achieve class-conditional\ndistribution balancing, which automatically highlights minority groups and\nclasses, effectively dismantling spurious correlations and producing a debiased\ndata distribution for classification. Extensive experiments and analysis\ndemonstrate that our approach consistently delivers state-of-the-art\nperformance, rivaling methods that rely on bias supervision.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-24T07:15:53Z"}
{"aid":"http://arxiv.org/abs/2504.17321v1","title":"Dargana: fine-tuning EarthPT for dynamic tree canopy mapping from space","summary":"We present Dargana, a fine-tuned variant of the EarthPT time-series\nfoundation model that achieves specialisation using <3% of its pre-training\ndata volume and 5% of its pre-training compute. Dargana is fine-tuned to\ngenerate regularly updated classification of tree canopy cover at 10m\nresolution, distinguishing conifer and broadleaved tree types. Using Cornwall,\nUK, as a test case, the model achieves a pixel-level ROC-AUC of 0.98 and a\nPR-AUC of 0.83 on unseen satellite imagery. Dargana can identify fine\nstructures like hedgerows and coppice below the training sample limit, and can\ntrack temporal changes to canopy cover such as new woodland establishment. Our\nresults demonstrate how pre-trained Large Observation Models like EarthPT can\nbe specialised for granular, dynamic land cover monitoring from space,\nproviding a valuable, scalable tool for natural capital management and\nconservation.","main_category":"physics.geo-ph","categories":"physics.geo-ph,cs.LG","published":"2025-04-24T07:23:27Z"}
{"aid":"http://arxiv.org/abs/2504.17324v1","title":"Conjugate continuous-discrete projection filter via sparse-Grid\n  quadrature","summary":"In this article, we study the continuous-discrete projection filter for the\nexponential-family manifolds with conjugate likehoods. We first derive the\nlocal projection error of the prediction step of the continuous-discrete\nprojection filter. We then derive the exact Bayesian update algorithm for a\nclass of discrete measurement processes with additive Gaussian noise. Lastly,\nwe present a numerical simulation of the stochastic van der Pol filtering\nproblem with a nonlinear measurement process. The proposed projection filter\nshows superior performance compared to several state-of-the-art parametric\ncontinuous-discrete filtering methods.","main_category":"math.OC","categories":"math.OC","published":"2025-04-24T07:30:05Z"}
{"aid":"http://arxiv.org/abs/2504.17329v1","title":"On Runge-Kutta methods of order 10","summary":"A family of explicit 15-stage Runge-Kutta methods of order 10 is derived.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-24T07:45:51Z"}
{"aid":"http://arxiv.org/abs/2504.17330v1","title":"Exploring the giant monopole resonance in superheavy nuclei: A\n  theoretical perspective","summary":"Within the relativistic mean field framework, in an extended Thomas-Fermi\napproximation, we calculate the binding energy and charge distribution radius\nfor the latest superheavy nuclei, synthesised in various laboratories, with\natomic numbers $Z = 110-118$. The binding energy and radii are compared with\nthe results obtained from relativistic Hartree calculations along with the\nexperimental data, wherever available, to check the reliability of the methods.\nThe calculations are extended to estimate the giant monopole resonances to\nunderstand the collective vibration of the nucleons for such superheavy nuclei.\nThe giant monopole resonances obtained from scaling calculations are compared\nwith the constraint computations. Furthermore, the results are compared with\nother known methods, such as the relativistic Random Phase Approximation (RPA)\nand time-dependent mean field calculations, along with some known lighter\nnuclei, specifically Zr isotopes (N = 42-86) and O isotopes (N = 10-36).\nFinally, the nuclear compressibility of the superheavy nuclei is predicted from\nthe energy obtained in the breathing mode.","main_category":"nucl-th","categories":"nucl-th,nucl-ex","published":"2025-04-24T07:46:47Z"}
{"aid":"http://arxiv.org/abs/2504.17342v1","title":"FrÃ©chet Distance in Unweighted Planar Graphs","summary":"The Fr\\'echet distance is a distance measure between trajectories in the\nplane or walks in a graph G. Given constant-time shortest path queries in a\ngraph G, the Discrete Fr\\'echet distance $F_G(P, Q)$ between two walks P and Q\ncan be computed in $O(|P| \\cdot |Q|)$ time using a dynamic program. Driemel,\nvan der Hoog, and Rotenberg [SoCG'22] show that for weighted planar graphs this\napproach is likely tight, as there can be no strongly subquadratic algorithm to\ncompute a $1.01$-approximation of $F_G(P, Q)$ unless the Orthogonal Vector\nHypothesis (OVH) fails.\n  Such quadratic-time conditional lower bounds are common to many Fr\\'echet\ndistance variants. However, they can be circumvented by assuming that the input\ncomes from some well-behaved class: There exist\n$(1+\\varepsilon)$-approximations, both in weighted graphs and in Rd, that take\nnear-linear time for $c$-packed or $\\kappa$-straight walks in the graph. In Rd,\nthere also exists a near-linear time algorithm to compute the Fr\\'echet\ndistance whenever all input edges are long compared to the distance.\n  We consider computing the Fr\\'echet distance in unweighted planar graphs. We\nshow that there exist no 1.25-approximations of the discrete Fr\\'echet distance\nbetween two disjoint simple paths in an unweighted planar graph in strongly\nsubquadratic time, unless OVH fails. This improves the previous lower bound,\nboth in terms of generality and approximation factor. We subsequently show that\nadding graph structure circumvents this lower bound: If the graph is a regular\ntiling with unit-weighted edges, then there exists an $\\tilde{O}( (|P| +\n|Q|)^{1.5})$-time algorithm to compute $D_F(P, Q)$. Our result has natural\nimplications in the plane, as it allows us to define a new class of\nwell-behaved curves that facilitate $(1+\\varepsilon)$-approximations of their\ndiscrete Fr\\'echet distance in subquadratic time.","main_category":"cs.CG","categories":"cs.CG","published":"2025-04-24T07:59:39Z"}
{"aid":"http://arxiv.org/abs/2504.17346v1","title":"Dual-Individual Genetic Algorithm: A Dual-Individual Approach for\n  Efficient Training of Multi-Layer Neural Networks","summary":"This paper introduces an enhanced Genetic Algorithm technique called\nDual-Individual Genetic Algorithm (Dual-Individual GA), which optimizes neural\nnetworks for binary image classification tasks, such as cat vs. non-cat\nclassification. The proposed method employs only two individuals for crossover,\nrepresented by two parameter sets: Leader and Follower. The Leader focuses on\nexploitation, representing the primary optimal solution at even-indexed\npositions (0, 2, 4, ...), while the Follower promotes exploration by preserving\ndiversity and avoiding premature convergence, operating at odd-indexed\npositions (1, 3, 5, ...). Leader and Follower are modeled as two phases or\nroles. The key contributions of this work are threefold: (1) a self-adaptive\nlayer dimension mechanism that eliminates the need for manual tuning of layer\narchitectures; (2) generates two parameter sets, leader and follower parameter\nsets, with 10 layer architecture configurations (5 for each set), ranked by\nPareto dominance and cost. post-optimization; and (3) demonstrated superior\nperformance compared to traditional gradient-based methods. Experimental\nresults show that the Dual-Individual GA achieves 99.04% training accuracy and\n80% testing accuracy (cost = 0.034) on a three-layer network with architecture\n[12288, 17, 4, 1], outperforming a gradient-based approach that achieves 98%\ntraining accuracy and 80% testing accuracy (cost = 0.092) on a four-layer\nnetwork with architecture [12288, 20, 7, 5, 1]. These findings highlight the\nefficiency and effectiveness of the proposed method in optimizing neural\nnetworks.","main_category":"cs.NE","categories":"cs.NE,cs.AI","published":"2025-04-24T08:04:08Z"}
{"aid":"http://arxiv.org/abs/2504.17356v1","title":"Comprehend, Divide, and Conquer: Feature Subspace Exploration via\n  Multi-Agent Hierarchical Reinforcement Learning","summary":"Feature selection aims to preprocess the target dataset, find an optimal and\nmost streamlined feature subset, and enhance the downstream machine learning\ntask. Among filter, wrapper, and embedded-based approaches, the reinforcement\nlearning (RL)-based subspace exploration strategy provides a novel objective\noptimization-directed perspective and promising performance. Nevertheless, even\nwith improved performance, current reinforcement learning approaches face\nchallenges similar to conventional methods when dealing with complex datasets.\nThese challenges stem from the inefficient paradigm of using one agent per\nfeature and the inherent complexities present in the datasets. This observation\nmotivates us to investigate and address the above issue and propose a novel\napproach, namely HRLFS. Our methodology initially employs a Large Language\nModel (LLM)-based hybrid state extractor to capture each feature's mathematical\nand semantic characteristics. Based on this information, features are\nclustered, facilitating the construction of hierarchical agents for each\ncluster and sub-cluster. Extensive experiments demonstrate the efficiency,\nscalability, and robustness of our approach. Compared to contemporary or the\none-feature-one-agent RL-based approaches, HRLFS improves the downstream ML\nperformance with iterative feature subspace exploration while accelerating\ntotal run time by reducing the number of agents involved.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-24T08:16:36Z"}
{"aid":"http://arxiv.org/abs/2504.17359v1","title":"Light-driven lattice metastability for enhanced superconductivity in\n  FeSe/SrTiO3","summary":"Driven quantum materials with on demand properties controlled by external\nstimuli are critical for emergent quantum technology. In optically tunable\nsuperconducting heterostructures, the lattice responses at the buried interface\nmay hold the key to the light susceptibility but is very challenging to detect.\nIn this work, a nondestructive synchrotron-based X-ray scattering\nphase-retrieval technique is implemented in monolayer-FeSe/SrTiO3\nheterostructures to capture the three-dimensional interfacial atomic\ndisplacements in-situ as the interface superconductivity is actively\nmanipulated by light. It is found that the interlayer sliding between FeSe and\nSrTiO3 can drastically alter how the lattice responds to the light. In domains\nwith selected stacking configurations, the interface transforms the very weak\nphotoexcitation in SrTiO3 into significant Fe-atom displacements in FeSe and\ngenerate metastable interfacial structures that can lead to a persistent\nsuperconductivity enhancement. These findings demonstrate an effective strategy\nfor achieving greatly amplified light-lattice coupling for efficient quantum\nphase manipulations at designed interfaces.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-24T08:17:45Z"}
{"aid":"http://arxiv.org/abs/2504.17373v1","title":"The lepton-number-violating pion decay and the type-I seesaw mechanism\n  in chiral perturbation theory","summary":"We investigate the process of lepton-number-violating pion decay, which\ndominates the nuclear neutrinoless double beta decay induced by the short-range\noperator, within the type-\\uppercase\\expandafter{\\romannumeral1} seesaw\nmechanism. The type-\\uppercase\\expandafter{\\romannumeral1} seesaw mechanism\ngives rise to the Dirac and Majorana mass terms of neutrinos by introducing the\ngauge-singlet right-handed neutrinos, which are usually called sterile\nneutrinos. Using chiral perturbation theory, the transition amplitudes in the\ncase of the light and heavy sterile neutrinos are calculated up to\n$\\mathcal{O}(Q^2/\\Lambda^2_\\chi)$ respectively, where $Q$ is the typical\nlow-energy scale in this process and $\\Lambda_\\chi$ the chiral symmetry\nbreaking scale. We then adopt a naive interpolation formula of mass dependence\nto obtain the amplitude in the full mass range and briefly discuss its\nvalidity.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-24T08:47:31Z"}
{"aid":"http://arxiv.org/abs/2504.17389v1","title":"Directed and elliptic flow of light nuclei and hypernuclei in Au+Au\n  collisions at $\\sqrt{s_\\mathrm{NN}}=3$ GeV: Coalescence vs. Statistical\n  Fragmentation","summary":"The harmonic flow coefficients of light nuclei and hypernuclei in Au+Au\ncollisions at $\\sqrt{s_\\mathrm{NN}}=3$ GeV are investigated using the\nUltra-relativistic Quantum Molecular Dynamics transport model. For the\nEquation-of-State we employ a density and momentum dependent potential from the\nChiral-Mean-Field model. Light nuclei and hypernuclei production is described\nat kinetic freeze-out via a coalescence mechanism or with a statistical\nmulti-fragmentation calculation. The directed flow $v_1$ of p, d, t, $^3$He,\n$^4$He as well as the $\\Lambda$, $^3_\\Lambda$H and $^4_\\Lambda$H is shown to\napproximately scale with mass number $A$ of the light cluster in both\ncalculations. This is in agreement with the experimental results for the\ndirected flow measured by STAR. Predictions for the directed and elliptic flow\nof (hyper)nuclei at further RHIC-FXT and FAIR energies show that the scaling\nproperties should improve as the beam energy is increased.","main_category":"nucl-th","categories":"nucl-th,nucl-ex","published":"2025-04-24T09:13:34Z"}
{"aid":"http://arxiv.org/abs/2504.17396v1","title":"Periodic homogenization and harmonic measures","summary":"Since the seminal work of Kenig and Pipher, the Dahlberg-Kenig-Pipher (DKP)\ncondition on oscillations of the coefficient matrix became a standard threshold\nin the study of absolute continuity of the harmonic measure with respect to the\nHausdorff measure on the boundary. It has been proved sufficient for absolute\ncontinuity in the domains with increasingly complex geometry, and known\ncounterexamples show that in a certain sense it is necessary as well. In the\npresent note, we introduce into the subject ideas from homogenization theory to\nexhibit a new class of operators for which the elliptic measure is\nwell-behaved, featuring the coefficients violating the DKP condition, and on\nthe contrary, oscillating so quickly, that the homogenization takes place.","main_category":"math.AP","categories":"math.AP","published":"2025-04-24T09:35:14Z"}
{"aid":"http://arxiv.org/abs/2504.17424v1","title":"Object Pose Estimation by Camera Arm Control Based on the Next Viewpoint\n  Estimation","summary":"We have developed a new method to estimate a Next Viewpoint (NV) which is\neffective for pose estimation of simple-shaped products for product display\nrobots in retail stores. Pose estimation methods using Neural Networks (NN)\nbased on an RGBD camera are highly accurate, but their accuracy significantly\ndecreases when the camera acquires few texture and shape features at a current\nview point. However, it is difficult for previous mathematical model-based\nmethods to estimate effective NV which is because the simple shaped objects\nhave few shape features. Therefore, we focus on the relationship between the\npose estimation and NV estimation. When the pose estimation is more accurate,\nthe NV estimation is more accurate. Therefore, we develop a new pose estimation\nNN that estimates NV simultaneously. Experimental results showed that our NV\nestimation realized a pose estimation success rate 77.3\\%, which was 7.4pt\nhigher than the mathematical model-based NV calculation did. Moreover, we\nverified that the robot using our method displayed 84.2\\% of products.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-24T10:26:14Z"}
{"aid":"http://arxiv.org/abs/2504.17468v1","title":"Optimal design of reinsurance contracts under adverse selection with a\n  continuum of types","summary":"In this paper, we use the principal-agent model to study the optimal contract\ndesign in a monopolistic reinsurance market under adverse selection with a\ncontinuum of types of insurers. Instead of adopting the classical expected\nutility paradigm, we model the risk preference of each insurer (agent) by his\nValue-at-Risk at his own chosen risk tolerance level. Under information\nasymmetry, the reinsurer (principal) aims to maximize her expected profit by\ndesigning an optimal menu of reinsurance contracts for a continuum of insurers\nwith hidden characteristics. The optimization problem is constrained by agents'\nindividual compatibility and rationality constraints. By making use of the\nnotion of indirect utility functions, the problem is completely solved for the\nfollowing three commonly encountered classes of reinsurance indemnities:\nstop-loss, quota-share, and change loss. Some numerical examples are provided\nas illustrations.","main_category":"q-fin.RM","categories":"q-fin.RM","published":"2025-04-24T12:01:35Z"}
{"aid":"http://arxiv.org/abs/2504.17501v1","title":"Surface morphology and thickness variation estimation of zeolites via\n  electron ptychography","summary":"Zeolites, as representative porous materials, possess intricate\nthree-dimensional frameworks that endow them with high surface areas and\nremarkable catalytic properties. There are a few factors that give a huge\ninfluence on the catalytic properties, including the size and connectivity of\nthese three-dimensional channels and atomic level defects. In additional to\nthat, the surface morphology and thickness variation of zeolites particles are\nessential to their catalytic performances as well. However, it is a significant\nchallenge to characterize these macroscopic properties of zeolites using\nconventional techniques due to their sensitivity to electron beams. In this\nstudy, we introduce surface-adaptive electron ptychography, an advanced\napproach based on multi-slice electron ptychography, which enables\nhigh-precision reconstruction of both local atomic configurations and global\nstructural features in zeolite nanoparticles. By adaptively optimizing probe\ndefocus and slice thickness during the reconstruction process, SAEP\nsuccessfully resolves surface morphology, thickness variations and atomic\nstructure simultaneously. This integrated framework facilitates a direct and\nintuitive correlation between zeolite channel structures and particle\nthickness. Our findings open new pathways for large-scale, comprehensive\nstructure property analysis of beam-sensitive porous materials, deepening the\nunderstanding of their catalytic behavior.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-24T12:42:55Z"}
{"aid":"http://arxiv.org/abs/2504.17514v1","title":"Secure Network Function Computation for Linear Functions, Part II:\n  Target-Function Security","summary":"In this Part II of a two-part paper, we put forward secure network function\ncomputation, where in a directed acyclic network, a sink node is required to\ncompute a target function of which the inputs are generated as source messages\nat multiple source nodes, while a wiretapper, who can access any one but not\nmore than one wiretap set in a given collection of wiretap sets, is not allowed\nto obtain any information about a security function of the source messages. In\nPart I of the two-part paper, we have investigated securely computing linear\nfunctions with the wiretapper who can eavesdrop any edge subset up to a certain\nsize r, referred to as the security level, where the security function is the\nidentity function. The notion of this security is called source security. In\nthe current paper, we consider another interesting model which is the same as\nthe above one except that the security function is identical to the target\nfunction, i.e., we need to protect the information on the target function from\nbeing leaked to the wiretapper. The notion of this security is called\ntarget-function security. We first prove a non-trivial upper bound on the\nsecure computing capacity, which is applicable to arbitrary network topologies\nand arbitrary security levels. In particular, when the security level r is\nequal to 0, the upper bound reduces to the computing capacity without security\nconsideration. Further, from an algebraic point of view, we prove two\nequivalent conditions for target-function security and source security for the\nexistence of the corresponding linear function-computing secure network codes.\nWith them, for any linear function over a given finite field, we develop a code\nconstruction of linear secure network codes for target-function security and\nthus obtain a lower bound on the secure computing capacity; and also generalize\nthe code construction developed in Part I for source security.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-24T12:57:20Z"}
{"aid":"http://arxiv.org/abs/2504.17550v1","title":"HalluLens: LLM Hallucination Benchmark","summary":"Large language models (LLMs) often generate responses that deviate from user\ninput or training data, a phenomenon known as \"hallucination.\" These\nhallucinations undermine user trust and hinder the adoption of generative AI\nsystems. Addressing hallucinations is essential for the advancement of LLMs.\nThis paper introduces a comprehensive hallucination benchmark, incorporating\nboth new extrinsic and existing intrinsic evaluation tasks, built upon clear\ntaxonomy of hallucination. A major challenge in benchmarking hallucinations is\nthe lack of a unified framework due to inconsistent definitions and\ncategorizations. We disentangle LLM hallucination from \"factuality,\" proposing\na clear taxonomy that distinguishes between extrinsic and intrinsic\nhallucinations, to promote consistency and facilitate research. Extrinsic\nhallucinations, where the generated content is not consistent with the training\ndata, are increasingly important as LLMs evolve. Our benchmark includes dynamic\ntest set generation to mitigate data leakage and ensure robustness against such\nleakage. We also analyze existing benchmarks, highlighting their limitations\nand saturation. The work aims to: (1) establish a clear taxonomy of\nhallucinations, (2) introduce new extrinsic hallucination tasks, with data that\ncan be dynamically regenerated to prevent saturation by leakage, (3) provide a\ncomprehensive analysis of existing benchmarks, distinguishing them from\nfactuality evaluations.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-24T13:40:27Z"}
{"aid":"http://arxiv.org/abs/2504.17558v1","title":"Quasi-particle residue and charge of the one-dimensional Fermi polaron","summary":"We consider a mobile impurity coupled to an ideal Fermi gas in one spatial\ndimension through an attractive contact interaction. We calculate the\nquasi-particle residue $Z$ exactly, based on Bethe Ansatz and diagrammatic\nMonte Carlo methods, and with varational Ansatz up to one particle-hole\nexcitation of the Fermi sea. We find that the exact quasi-particle residue\nvanishes in the thermodynamic limit as a power law in the number of particles,\nconsistent with the Luttinger-liquid paradigm and the breakdown of Fermi-liquid\ntheory. The variational Ansatz, however, predicts a finite value of $Z$, even\nin the thermodynamic limit. We also study how the presence of the impurity\naffects the density of the spin-up sea by calculating the pair correlation\nfunction. Subtracting the homogeneous background and integrating over all\ndistances gives the charge $Q$. This charge turns out to grow continuously from\n0 at zero coupling to 1 in the strong-coupling limit. The varational Ansatz\npredicts $Q=0$ at all couplings. So, although the variational Ansatz has been\nshown to be remarkably accurate for the energy and the effective mass, it fails\neven qualitatively when predicting $Z$ and the pair correlation function in the\nthermodynamic limit.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,cond-mat.str-el,cond-mat.supr-con","published":"2025-04-24T13:50:46Z"}
{"aid":"http://arxiv.org/abs/2504.17575v1","title":"A Multi-Agent, Laxity-Based Aggregation Strategy for Cost-Effective\n  Electric Vehicle Charging and Local Transformer Overload Prevention","summary":"The rapid electrification of transportation, driven by stringent\ndecarbonization targets and supportive policies, poses significant challenges\nfor distribution system operators (DSOs). When numerous electric vehicles (EVs)\ncharge concurrently, local transformers risk overloading - a problem that\ncurrent tariff-based strategies do not adequately address. This paper\nintroduces an aggregator-based coordination mechanism that shifts EV charging\nfrom congested to underutilized periods using a rule-based scheduling\nalgorithm. Unlike conventional methods that depend on complex real-time pricing\nsignals or optimization-heavy solutions, the aggregator approach uses a simple\nyet effective \"laxity\" measure to prioritize charging flexibility. To assess\ntechnical and economic viability, a multi-agent simulation was developed to\nreplicate residential user behavior and DSO constraints under the use of a 400\nkVA low-voltage transformer. The results indicate that overloads are completely\neliminated with minimal inconvenience to users, whose increased charging costs\nare offset by the aggregator at an annual total of under DKK 6000 -\nsignificantly lower than the cost of infrastructure reinforcement. This study\ncontributes by (i) quantifying the compensation needed to prevent large-scale\noverloads, (ii) presenting a replicable, computationally feasible, rule-based\naggregator model for DSOs, and (iii) comparing aggregator solutions to costly\ntransformer upgrades, underscoring the aggregator's role as a viable tool for\nfuture distribution systems.","main_category":"cs.MA","categories":"cs.MA","published":"2025-04-24T14:04:35Z"}
{"aid":"http://arxiv.org/abs/2504.17578v1","title":"Advancing CMA-ES with Learning-Based Cooperative Coevolution for\n  Scalable Optimization","summary":"Recent research in Cooperative Coevolution~(CC) have achieved promising\nprogress in solving large-scale global optimization problems. However, existing\nCC paradigms have a primary limitation in that they require deep expertise for\nselecting or designing effective variable decomposition strategies. Inspired by\nadvancements in Meta-Black-Box Optimization, this paper introduces LCC, a\npioneering learning-based cooperative coevolution framework that dynamically\nschedules decomposition strategies during optimization processes. The\ndecomposition strategy selector is parameterized through a neural network,\nwhich processes a meticulously crafted set of optimization status features to\ndetermine the optimal strategy for each optimization step. The network is\ntrained via the Proximal Policy Optimization method in a reinforcement learning\nmanner across a collection of representative problems, aiming to maximize the\nexpected optimization performance. Extensive experimental results demonstrate\nthat LCC not only offers certain advantages over state-of-the-art baselines in\nterms of optimization effectiveness and resource consumption, but it also\nexhibits promising transferability towards unseen problems.","main_category":"cs.LG","categories":"cs.LG,cs.NE","published":"2025-04-24T14:09:22Z"}
{"aid":"http://arxiv.org/abs/2504.17585v1","title":"The tidal heating of the exoplanet 55 Cnc e. The role of the orbital\n  eccentricity","summary":"Context. Observations with warm Spitzer and JWST revealed high and variable\nbrightness in the planet 55 Cnc e.\n  Aims. Inventory of the tidal effects on the rotational and orbital evolution\nof the planet 55 Cnc e enhanced by the nonzero orbital eccentricity.\n  Methods. The creep-tide theory is used in simulations and dynamical analyses\nthat explore the difficult trapping of the planet rotation in a 3:2 spin-orbit\nresonance and the most probable synchronization of the rotation.\n  Results. The strong tidal dissipation of energy, enhanced by the non-zero\norbital eccentricity, may explain the observed brightness anomalies. However,\nthe strong dissipation should also circularize the orbit. The observed non-zero\neccentricity, if true, would indicate that an unknown planet in a close orbital\nresonance with 55 Cnc e perturbing the motion of this planet should exist.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-24T14:17:21Z"}
{"aid":"http://arxiv.org/abs/2504.17587v1","title":"Enhancing gravitational-wave detection: a machine learning pipeline\n  combination approach with robust uncertainty quantification","summary":"Gravitational-wave data from advanced-era interferometric detectors consists\nof background Gaussian noise, frequent transient artefacts, and rare\nastrophysical signals. Multiple search algorithms exist to detect the signals\nfrom compact binary coalescences, but their varying performance complicates\ninterpretation. We present a machine learning-driven approach that combines\nresults from individual pipelines and utilises conformal prediction to provide\nrobust, calibrated uncertainty quantification. Using simulations, we\ndemonstrate improved detection efficiency and apply our model to GWTC-3,\nenhancing confidence in multi-pipeline detections, such as the sub-threshold\nbinary neutron star candidate GW200311_103121.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE","published":"2025-04-24T14:18:09Z"}
{"aid":"http://arxiv.org/abs/2504.17655v1","title":"Aerial Image Classification in Scarce and Unconstrained Environments via\n  Conformal Prediction","summary":"This paper presents a comprehensive empirical analysis of conformal\nprediction methods on a challenging aerial image dataset featuring diverse\nevents in unconstrained environments. Conformal prediction is a powerful\npost-hoc technique that takes the output of any classifier and transforms it\ninto a set of likely labels, providing a statistical guarantee on the coverage\nof the true label. Unlike evaluations on standard benchmarks, our study\naddresses the complexities of data-scarce and highly variable real-world\nsettings. We investigate the effectiveness of leveraging pretrained models\n(MobileNet, DenseNet, and ResNet), fine-tuned with limited labeled data, to\ngenerate informative prediction sets. To further evaluate the impact of\ncalibration, we consider two parallel pipelines (with and without temperature\nscaling) and assess performance using two key metrics: empirical coverage and\naverage prediction set size. This setup allows us to systematically examine how\ncalibration choices influence the trade-off between reliability and efficiency.\nOur findings demonstrate that even with relatively small labeled samples and\nsimple nonconformity scores, conformal prediction can yield valuable\nuncertainty estimates for complex tasks. Moreover, our analysis reveals that\nwhile temperature scaling is often employed for calibration, it does not\nconsistently lead to smaller prediction sets, underscoring the importance of\ncareful consideration in its application. Furthermore, our results highlight\nthe significant potential of model compression techniques within the conformal\nprediction pipeline for deployment in resource-constrained environments. Based\non our observations, we advocate for future research to delve into the impact\nof noisy or ambiguous labels on conformal prediction performance and to explore\neffective model reduction strategies.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV,stat.ML","published":"2025-04-24T15:25:37Z"}
{"aid":"http://arxiv.org/abs/2504.17661v1","title":"Sharp Material Interface Limit of the Darcy-Boussinesq System","summary":"We investigate the sharp material interface limit of the Darcy-Boussinesq\nmodel for convection in layered porous media with diffused material interfaces,\nwhich allow a gradual transition of material parameters between different\nlayers. We demonstrate that as the thickness of these transition layers\napproaches zero, the conventional sharp interface model with interfacial\nboundary conditions, commonly adopted by the fluids community, is recovered\nunder the assumption of constant porosity. Our results validate the widely used\nsharp interface model by bridging it with the more physically realistic case of\ndiffused material interfaces. This limiting process is singular and involves a\nboundary layer in the velocity field. Our analysis requires del","main_category":"math.AP","categories":"math.AP","published":"2025-04-24T15:30:18Z"}
{"aid":"http://arxiv.org/abs/2504.17668v1","title":"FRG analysis for relativistic BEC in arbitrary spatial dimensions","summary":"A relativistic Bose-Einstein condensate (BEC) is studied within the complex\nscalar field theory using the functional renormalization group (FRG) under the\nlocal potential approximation. We investigate fluctuation effects on the\nrelativistic BEC through numerical analyses for various spatial dimensions and\nchemical potentials. Our numerical results are consistent with the\nMermin-Wagner theorem, and this consistency is also analytically confirmed from\nthe flow equation. We also discuss a numerical instability of the FRG in lower\nspatial dimensions, which is evadable for certain parameter choices.","main_category":"hep-ph","categories":"hep-ph,cond-mat.quant-gas,hep-th,G.1.8","published":"2025-04-24T15:37:35Z"}
{"aid":"http://arxiv.org/abs/2504.17673v1","title":"DTECM: Digital Twin Enabled Channel Measurement and Modeling in\n  Terahertz Urban Macrocell","summary":"In this work, in the THz UMa, extensive channel measurements are conducted\nand an accurate channel model is developed by combining ray-tracing, computer\nvision (CV), and statistical methods. Specifically, substantial channel\nmeasurement campaigns with distances up to 410~m are conducted at 220~GHz, with\nnanosecond-level absolute time synchronization. Based on the measurement\nresults, the propagation phenomena are analyzed in detail and the channel\ncharacteristics are calculated and statistically modeled. Furthermore, a\ndigital twin enabled channel model (DTECM) is proposed, which generates THz\nchannel responses in a hybrid manner. Specifically, the dominant paths are\ngenerated deterministically by using the ray-tracing technique and CV methods.\nApart from the path gains determined by ray-tracing, the additional foliage\nloss is accurately modeled based on foliage information extracted from\npanoramic pictures. To maintain a low computational complexity for the DTECM,\nnon-dominant paths are then generated statistically. Numeric results reveal\nthat compared to the traditional statistical channel models, the DTECM reduces\nthe path loss modeling error from 14~dB to 4~dB, showing its great superiority.\nFurthermore, a preliminary link performance evaluation using the DTECM\nindicates that THz UMa is feasible, though requiring high antenna gains and\ncoverage extension techniques to achieve high spectral efficiencies and wide\ncoverage.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-24T15:40:57Z"}
{"aid":"http://arxiv.org/abs/2504.17695v1","title":"PICO: Reconstructing 3D People In Contact with Objects","summary":"Recovering 3D Human-Object Interaction (HOI) from single color images is\nchallenging due to depth ambiguities, occlusions, and the huge variation in\nobject shape and appearance. Thus, past work requires controlled settings such\nas known object shapes and contacts, and tackles only limited object classes.\nInstead, we need methods that generalize to natural images and novel object\nclasses. We tackle this in two main ways: (1) We collect PICO-db, a new dataset\nof natural images uniquely paired with dense 3D contact on both body and object\nmeshes. To this end, we use images from the recent DAMON dataset that are\npaired with contacts, but these contacts are only annotated on a canonical 3D\nbody. In contrast, we seek contact labels on both the body and the object. To\ninfer these given an image, we retrieve an appropriate 3D object mesh from a\ndatabase by leveraging vision foundation models. Then, we project DAMON's body\ncontact patches onto the object via a novel method needing only 2 clicks per\npatch. This minimal human input establishes rich contact correspondences\nbetween bodies and objects. (2) We exploit our new dataset of contact\ncorrespondences in a novel render-and-compare fitting method, called PICO-fit,\nto recover 3D body and object meshes in interaction. PICO-fit infers contact\nfor the SMPL-X body, retrieves a likely 3D object mesh and contact from PICO-db\nfor that object, and uses the contact to iteratively fit the 3D body and object\nmeshes to image evidence via optimization. Uniquely, PICO-fit works well for\nmany object categories that no existing method can tackle. This is crucial to\nenable HOI understanding to scale in the wild. Our data and code are available\nat https://pico.is.tue.mpg.de.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T16:03:11Z"}
{"aid":"http://arxiv.org/abs/2504.17697v1","title":"'The Boring and the Tedious': Invisible Labour in India's Gig-Economy","summary":"India's gig-based food delivery platforms, such as Swiggy and Zomato, provide\ncrucial income to marginalised communities but also entrench workers in cycles\nof invisible labour. Through 14 semi-structured interviews, we analyse waiting\ntime and repetitive UI itneractions as key burdens that contribute to 'digital\ndiscomfort' for gig based food delivery agents. We find that workers employ\ncreative strategies to navigate algorithmic management, yet remain constrained\nby platform-side 'gamification' and system opacity. We propose worker-centered\nGUI automation as a potential intervention to reduce friction while preserving\nagency. In conclusion, this position paper argues for rethinking HCI approaches\nin the Global South to prioritise worker autonomy over efficiency-driven design\noptimisations.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-24T16:06:26Z"}
{"aid":"http://arxiv.org/abs/2504.17720v1","title":"Multilingual Performance Biases of Large Language Models in Education","summary":"Large language models (LLMs) are increasingly being adopted in educational\nsettings. These applications expand beyond English, though current LLMs remain\nprimarily English-centric. In this work, we ascertain if their use in education\nsettings in non-English languages is warranted. We evaluated the performance of\npopular LLMs on four educational tasks: identifying student misconceptions,\nproviding targeted feedback, interactive tutoring, and grading translations in\nsix languages (Hindi, Arabic, Farsi, Telugu, Ukrainian, Czech) in addition to\nEnglish. We find that the performance on these tasks somewhat corresponds to\nthe amount of language represented in training data, with lower-resource\nlanguages having poorer task performance. Although the models perform\nreasonably well in most languages, the frequent performance drop from English\nis significant. Thus, we recommend that practitioners first verify that the LLM\nworks well in the target language for their educational task before deployment.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-24T16:32:31Z"}
{"aid":"http://arxiv.org/abs/2504.17734v1","title":"Signed puzzles for Schubert coefficients","summary":"We give a signed puzzle rule to compute Schubert coefficients. The rule is\nbased on a careful analysis of Knutson's recurrence arXiv:math/0306304. We use\nthe rule to prove polynomiality of the sums of Schubert coefficients with\nbounded number of inversions.","main_category":"math.CO","categories":"math.CO","published":"2025-04-24T16:47:38Z"}
{"aid":"http://arxiv.org/abs/2504.17742v1","title":"Novel Heusler Materials for Spintronic Applications: Growth,\n  Characterizations and Applications","summary":"Spintronics is a rapidly evolving technology that utilizes the spin of\nelectrons along with their charge to enable high speed, low power and non\nvolatile electronic devices. The development of novel materials with tailored\nmagnetic and electronic properties is critical to exploit the full potential of\nspintronic applications. Among these, Heusler alloys stand out due to their\ntunable multifunctional properties. This review presents a comprehensive\noverview of various Heusler based materials including half metallic\nferromagnets, spin gapless semiconductors, magnetic semiconductors, spin\nsemimetals, and nearly zero moment materials focusing on their synthesis,\nstructural and magnetic characterizations, and transport behavior. The role of\ncrystal structure, and structural disorder in governing their magnetic and\nelectronic properties is discussed in detail. Emphasis is placed on\nexperimental results and their implications for spintronic devices. By bringing\ntogether recent advancements, the review highlights the critical role of\nHeusler alloys in advancing the next-generation spintronic technologies and\noutlines future directions for their integration in practical applications.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-24T16:57:53Z"}
{"aid":"http://arxiv.org/abs/2504.17747v1","title":"Fourier Acceleration in a Linear Sigma Model with Spontaneous Symmetry\n  Breaking","summary":"Fourier acceleration is a technique used in Hybrid Monte Carlo simulations to\ndecrease the autocorrelation between subsequent field configurations in the\ngenerated ensemble. It has been shown, in the perturbative limit, to eliminate\nthe problem of critical slowing down in a $\\phi^4$ theory (arXiv:1812.05281\n[hep-lat]). As a result, there are several techniques that are being explored\nto generalize Fourier acceleration to work with non-Abelian gauge theories like\nQCD (arXiv:2112.04556 [hep-lat], arXiv:2108.05486 [hep-lat]). It is hoped that\nthese methods will prove effective at overcoming the problem of critical\nslowing down, even in the non-perturbative limit. In our work, we show that\nFourier acceleration can be applied effectively to a linear sigma model in the\nsymmetry broken phase, leading to reduced autocorrelation and faster\nthermalization. We present an algorithm for estimating the optimal Fourier\nacceleration masses dynamically, based on the lattice data. In the future, we\nhope to explore the effectiveness of these techniques in the\nstrongly-interacting case. Since our $\\phi^4$ theory is a linear chiral\neffective theory for QCD, this could be interesting for those who are seeking\nto generalize Fourier acceleration to QCD.","main_category":"hep-lat","categories":"hep-lat","published":"2025-04-24T17:07:44Z"}
{"aid":"http://arxiv.org/abs/2504.17757v1","title":"On canonical differential equations for Calabi-Yau multi-scale Feynman\n  integrals","summary":"We generalise a method recently introduced in the literature, that derives\ncanonical differential equations, to multi-scale Feynman integrals with an\nunderlying Calabi-Yau geometry. We start by recomputing a canonical form for\nthe sunrise integral with all unequal masses. Additionally, we compute for the\nfirst time a canonical form for the three-loop banana integral with two unequal\nmasses and for a four-loop banana integral with two unequal masses. For the\nintegrals we compute, we find an $\\epsilon$-form whose connection has at most\nsimple poles. We motivate our construction by studying the Picard-Fuchs\noperators acting on the integrals considered. In the appendices, we give a\nconstructive explanation for why our generalisation works.","main_category":"hep-th","categories":"hep-th,hep-ph","published":"2025-04-24T17:20:12Z"}
{"aid":"http://arxiv.org/abs/2504.17758v1","title":"First study of neutrino angle reconstruction using quasielastic-like\n  interactions in MicroBooNE","summary":"We investigate the expected precision of the reconstructed neutrino direction\nusing a {\\nu}{\\mu}-argon quasielastic-like event topology with one muon and one\nproton in the final state and the reconstruction capabilities of the MicroBooNE\nliquid argon time projection chamber. This direction is of importance in the\ncontext of DUNE sub-GeV atmospheric oscillation studies. MicroBooNE allows for\na data-driven quantification of this resolution by investigating the deviation\nof the reconstructed muon-proton system orientation with respect to the\nwell-known direction of neutrinos originating from the Booster Neutrino Beam\nwith an exposure of 1.3 x 1021 protons on target. Using simulation studies, we\nderive the expected sub-GeV DUNE atmospheric-neutrino reconstructed simulated\nspectrum by developing a reweighting scheme as a function of the true neutrino\nenergy. We further report flux-integrated single- and double-differential cross\nsection measurements of charged-current {\\nu}{\\mu} quasielastic-like scattering\non argon as a function of the muon-proton system angle using the full\nMicroBooNE data sets. We also demonstrate the sensitivity of these results to\nnuclear effects and final state hadronic reinteraction modeling.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-24T17:20:49Z"}
{"aid":"http://arxiv.org/abs/2504.17779v1","title":"Josephson anomalous vortices","summary":"We show that vortices with circulating current, related with odd-frequency\ntriplet pairing, appear in Josephson junctions where the barrier is a weak\nferromagnet with strong spin-orbit coupling. By both symmetry analysis and\nmicroscopic methods we show that there is an additional term - a rotary\ninvariant - in the superconducting free energy which allows for magnetoelectric\neffects even when the previously considered Lifshitz invariant vanishes. We\nshow that the size, shape, and position of these vortices can be controlled by\nmanipulating Rashba spin-orbit coupling in the weak link, via gates, and we\nsuggest that these vortices could be detected via scanning magnetometry\ntechniques. We also show that the transverse triplet components of the\nsuperconducting correlations can form a texture.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-24T17:56:00Z"}
{"aid":"http://arxiv.org/abs/2504.17782v1","title":"Unleashing the Power of Natural Audio Featuring Multiple Sound Sources","summary":"Universal sound separation aims to extract clean audio tracks corresponding\nto distinct events from mixed audio, which is critical for artificial auditory\nperception. However, current methods heavily rely on artificially mixed audio\nfor training, which limits their ability to generalize to naturally mixed audio\ncollected in real-world environments. To overcome this limitation, we propose\nClearSep, an innovative framework that employs a data engine to decompose\ncomplex naturally mixed audio into multiple independent tracks, thereby\nallowing effective sound separation in real-world scenarios. We introduce two\nremix-based evaluation metrics to quantitatively assess separation quality and\nuse these metrics as thresholds to iteratively apply the data engine alongside\nmodel training, progressively optimizing separation performance. In addition,\nwe propose a series of training strategies tailored to these separated\nindependent tracks to make the best use of them. Extensive experiments\ndemonstrate that ClearSep achieves state-of-the-art performance across multiple\nsound separation tasks, highlighting its potential for advancing sound\nseparation in natural audio scenarios. For more examples and detailed results,\nplease visit our demo page at https://clearsep.github.io.","main_category":"cs.SD","categories":"cs.SD,cs.LG","published":"2025-04-24T17:58:21Z"}
{"aid":"http://arxiv.org/abs/2504.19479v1","title":"Relativistic Two-Electron Contributions within Exact Two-Component\n  Theory","summary":"The development of relativistic exact two-component (X2C) theory is briefly\nreviewed, with an emphasis on cost-effective treatments of relativistic\ntwo-electron contributions by means of model potential (MP) techniques and\nclosely related atomic mean-field (AMF) approaches. The correct MP or AMF\ncontribution to the electronic energy is elucidated. The performance of\none-center approximations to relativistic two-electron contributions is\ncarefully assessed using benchmark calculations of molecular properties.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-28T04:35:04Z"}
{"aid":"http://arxiv.org/abs/2504.19492v1","title":"$K_1$-Stability of symplectic modules over monoid algebras","summary":"Let $R$ be a regular ring of dimension $d$ and $L$ be a $c$-divisible monoid.\nIf ${K}_1{Sp}(R)$ is trivial and $k \\geq d+2,$ then we prove that the\nsymplectic group ${Sp}_{2k}(R[L])$ is generated by elementary symplectic\nmatrices over $R[L]$. When $d \\leq 1$ or $R$ is a geometrically regular ring\ncontaining a field, then improved bounds have been established. We also discuss\nthe linear case, extending the work of Gubeladze.","main_category":"math.AC","categories":"math.AC,math.KT,math.RA","published":"2025-04-28T05:19:25Z"}
{"aid":"http://arxiv.org/abs/2504.19503v1","title":"Signatures of Hund$'s$ metal physics in single-layered 3d transition\n  metal oxide, $\\mathrm{Sr_2CoO_4}$","summary":"With density functional theory plus dynamical mean-field theory, we study the\ninfluence of Hund's coupling on the nature of electronic correlations in\n$\\mathrm{Sr_2CoO_4}$. Our results suggest strong signatures of Hund's metal\nphysics in this compound. The Co 3$d$ states show large orbital differentiation\nin the degree of correlations and mass enhancement. The imaginary-time\ncorrelation functions suggest the presence of spin-orbital separation and large\nlocal charge fluctuations in the system. Breakdown of the Fermi-liquid picture\nis observed at the lowest calculated temperature for various strengths of\nHund's coupling, suggesting the Fermi-liquid coherence scale lower than\n$\\sim$100 K. Interestingly, a sudden emergence of a gapped state is noted for\n$e_g$ orbitals in its spectral density of states at $\\sim$200 K in the vicinity\nof Fermi-level. Among the Co 3$d$ states 3$d_{z^2}$ and 3$d_{x^2-y^2}$ foster\nenlarged correlations. This study conclusively identifies $\\mathrm{Sr_2CoO_4}$\nas the first single-layered 3$d$ transition metal oxide to be classified as\nHund's metal.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-28T05:50:25Z"}
{"aid":"http://arxiv.org/abs/2504.19515v1","title":"Comparative Analysis of Mg$^+$ Properties using Multiconfiguration\n  Dirac-Hartree-Fock and Relativistic Coupled-cluster Methods","summary":"We demonstrate behaviors of correlation effects in the calculations of atomic\nproperties through two commonly employed many-body methods; namely\nmulticonfiguration Dirac-Hartree-Fock (MCDHF) and relativistic coupled-cluster\n(RCC) methods. Particularly, we have bench-marked excitation energies, electric\ndipole (E1) matrix elements, magnetic dipole hyperfine structure constants\n($A_{hf}$), and isotope shift (IS) constants in the singly ionized magnesium\n(Mg$^+$) systematically at different levels of approximation of both methods.\nWe have also estimated the E1 polarizability of the ground state and lifetimes\nof the excited states using the E1 matrix elements from both methods. All these\nresults are compared with the experimental values wherever available. We find\nthat the computed results agree well with each other with a few exceptions;\nparticularly the $A_{hf}$ and IS constants from the RCC method are found to\nagree with the measurements better. This comparison analysis would be useful in\nevaluating the above-discussed properties in other atomic systems using the\nMCDHF and RCC methods more reliably.","main_category":"physics.atom-ph","categories":"physics.atom-ph,physics.comp-ph","published":"2025-04-28T06:25:38Z"}
{"aid":"http://arxiv.org/abs/2504.19523v1","title":"Observational constraints in late time for an axially symmetric\n  transitioning model with bulk viscous fluid","summary":"In this paper, we explore an axially symmetric Bianchi type-I model of the\nuniverse with bulk viscous fluid as a source of gravitational field under the\nframework of Einstein's field equations by assuming barotropic bulk viscous\npressure as $-3\\zeta H^2$.\n  The model parameters have been estimated with the help of four data sets: The\nHubble 46 data set describes Hubble parameter values at various redshifts,\nUnion 2.1 compilation data sets comprise a distance modulus of 580 SNIa\nsupernovae at different redshifts, the Pantheon data set contains Apparent\nmagnitudes of 1048 SNIa supernovae at various redshifts and finally BAO data\nset of volume averaged distances at 5 redshifts.\n  The observational data is analyzed using the traditional Bayesian\nmethodology, and the posterior distributions of the parameters are obtained\nusing the Markov Chain Monte Carlo (MCMC) technique. To get the best-fit values\nfor the model parameters for MCMC analysis, we use the $ emcee $ package. For\nparameter estimation, we have also employed the minimizing $\\chi^{2}$ function.\nWe also tried to achieve these values statistically using combined data sets\nfrom the four described earlier. The OHD+BAO~and~OHD+Pan+BAO+Union combined\ndata sets provide the best fit Hubble parameter value $H_0$ as $66.912\n^{+0.497}_{-0.501})$ Km/s/Mpc and $74.216 ^{+0.150}_{-0.148}$ Km/s/Mpc\nrespectively. We have performed state finder diagnostics to discuss the nature\nof dark energy. Some other geometrical parameters like the Jerk parameter and\nthe Om diagnostic are also being discussed to clarify the nature of the dark\nenergy model. The study reveals that the model behaves like a quintessence in\nlate time and approaches the $\\Lambda$ CDM model.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-28T06:41:32Z"}
{"aid":"http://arxiv.org/abs/2504.19539v1","title":"Monitoring North African regional tourism by web data","summary":"The purpose of this article is to explore the opportunity of recent and\ndetailed unconventional data from the tourism sector collected from\n{\\guillemotleft} Booking.com {\\guillemotright} to make a finer and more\nup-to-date analysis than that established by conventional data, particularly,\nat the territorial level of North Africa. We extracted and geolocalised about\n40 variables of different types covering 1852 accommodations on Booking.com to\nanalyze the characteristics of territorial tourist offer of the six North\nAfrican countries (10 of 12 Moroccan regions, 3 of 13 Mauritanian Wilayas, 26\nof 48 Algerian Wilayas, 13 of 24 Tunisian Governorates, 1 region of Libya, 15\nof 27 Egyptian Mohafazats). Then, we used a random sample of 10% of the most\nrecent appreciations of nearly 606000 tourists of the three most dynamic\ndestinations (Marrakech-Safi, Tunis, Cairo) by analyzing the feelings of their\ncomments with a differentiation according origin of tourists. We concluded that\nthe accommodation offer of the territories of North Africa is very diversified\nand unclassified offers are slightly better appreciated compared to those\nclassified. The coastal regions have higher prices compared to the interior of\nthe countries and quality-price appreciation of North African regions is below\ntheir overall ratings.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-28T07:43:37Z"}
{"aid":"http://arxiv.org/abs/2504.19569v1","title":"Fermionizing the ideal Bose gas via topological pumping","summary":"We investigate the coherence and correlations of many-body states appearing\nin topological pumping in a one-dimensional Bose gas. By analyzing the system\nat zero and infinite interaction strengths, we reveal a rescaling of momentum\ndistributions accompanied by a self-similar behavior in first- and second-order\ncorrelation functions. In excited states of non-interacting bosons, the\nmomentum distribution shows a comb-like structure similar to that of\nnon-interacting fermions but at a higher density. This is mirrored by Friedel\noscillations in the one-body density matrix. At the same time, the\ndensity-density correlations still exhibit the bosonic enhancement. Our work\nillustrates how topological pumping induces a nontrivial mapping between\nbosonic and fermionic correlations.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,quant-ph","published":"2025-04-28T08:28:04Z"}
{"aid":"http://arxiv.org/abs/2504.19595v1","title":"WILD: a new in-the-Wild Image Linkage Dataset for synthetic image\n  attribution","summary":"Synthetic image source attribution is an open challenge, with an increasing\nnumber of image generators being released yearly. The complexity and the sheer\nnumber of available generative techniques, as well as the scarcity of\nhigh-quality open source datasets of diverse nature for this task, make\ntraining and benchmarking synthetic image source attribution models very\nchallenging. WILD is a new in-the-Wild Image Linkage Dataset designed to\nprovide a powerful training and benchmarking tool for synthetic image\nattribution models. The dataset is built out of a closed set of 10 popular\ncommercial generators, which constitutes the training base of attribution\nmodels, and an open set of 10 additional generators, simulating a real-world\nin-the-wild scenario. Each generator is represented by 1,000 images, for a\ntotal of 10,000 images in the closed set and 10,000 images in the open set.\nHalf of the images are post-processed with a wide range of operators. WILD\nallows benchmarking attribution models in a wide range of tasks, including\nclosed and open set identification and verification, and robust attribution\nwith respect to post-processing and adversarial attacks. Models trained on WILD\nare expected to benefit from the challenging scenario represented by the\ndataset itself. Moreover, an assessment of seven baseline methodologies on\nclosed and open set attribution is presented, including robustness tests with\nrespect to post-processing.","main_category":"cs.MM","categories":"cs.MM,cs.AI,cs.CV","published":"2025-04-28T08:58:34Z"}
{"aid":"http://arxiv.org/abs/2504.19597v1","title":"Depth Sensitivity of Hilbert Coefficients","summary":"The purpose of this paper is to explain about the depth sensitivity of the\nHilbert coefficients defined for finitely generated graded modules over graded\nrings. The main result generalize the well known fact that the\nCohen-Macaulayness of graded modules can be characterized using their\nmultiplicities.","main_category":"math.AC","categories":"math.AC","published":"2025-04-28T09:00:27Z"}
{"aid":"http://arxiv.org/abs/2504.19599v1","title":"GVPO: Group Variance Policy Optimization for Large Language Model\n  Post-Training","summary":"Post-training plays a crucial role in refining and aligning large language\nmodels to meet specific tasks and human preferences. While recent advancements\nin post-training techniques, such as Group Relative Policy Optimization (GRPO),\nleverage increased sampling with relative reward scoring to achieve superior\nperformance, these methods often suffer from training instability that limits\ntheir practical adoption. To address this challenge, we present Group Variance\nPolicy Optimization (GVPO). GVPO incorporates the analytical solution to\nKL-constrained reward maximization directly into its gradient weights, ensuring\nalignment with the optimal policy. The method provides intuitive physical\ninterpretations: its gradient mirrors the mean squared error between the\ncentral distance of implicit rewards and that of actual rewards. GVPO offers\ntwo key advantages: (1) it guarantees a unique optimal solution, exactly the\nKL-constrained reward maximization objective, (2) it supports flexible sampling\ndistributions that avoids on-policy and importance sampling limitations. By\nunifying theoretical guarantees with practical adaptability, GVPO establishes a\nnew paradigm for reliable and versatile LLM post-training.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-28T09:02:24Z"}
{"aid":"http://arxiv.org/abs/2504.19614v1","title":"DiVE: Efficient Multi-View Driving Scenes Generation Based on Video\n  Diffusion Transformer","summary":"Collecting multi-view driving scenario videos to enhance the performance of\n3D visual perception tasks presents significant challenges and incurs\nsubstantial costs, making generative models for realistic data an appealing\nalternative. Yet, the videos generated by recent works suffer from poor quality\nand spatiotemporal consistency, undermining their utility in advancing\nperception tasks under driving scenarios. To address this gap, we propose DiVE,\na diffusion transformer-based generative framework meticulously engineered to\nproduce high-fidelity, temporally coherent, and cross-view consistent\nmulti-view videos, aligning seamlessly with bird's-eye view layouts and textual\ndescriptions. DiVE leverages a unified cross-attention and a SketchFormer to\nexert precise control over multimodal data, while incorporating a view-inflated\nattention mechanism that adds no extra parameters, thereby guaranteeing\nconsistency across views. Despite these advancements, synthesizing\nhigh-resolution videos under multimodal constraints introduces dual challenges:\ninvestigating the optimal classifier-free guidance coniguration under intricate\nmulti-condition inputs and mitigating excessive computational latency in\nhigh-resolution rendering--both of which remain underexplored in prior\nresearches. To resolve these limitations, we introduce two innovations:\nMulti-Control Auxiliary Branch Distillation, which streamlines multi-condition\nCFG selection while circumventing high computational overhead, and Resolution\nProgressive Sampling, a training-free acceleration strategy that staggers\nresolution scaling to reduce high latency due to high resolution. These\ninnovations collectively achieve a 2.62x speedup with minimal quality\ndegradation. Evaluated on the nuScenes dataset, DiVE achieves SOTA performance\nin multi-view video generation, yielding photorealistic outputs with\nexceptional temporal and cross-view coherence.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-28T09:20:50Z"}
{"aid":"http://arxiv.org/abs/2504.19619v1","title":"Degenerate quarternionic Monge-AmpÃ¨re equations in weighted energy\n  classes","summary":"In this paper, we consider degenerate quaternionic Monge-Amp\\`ere equations\nin weighted energy class $\\mathcal{E}_{\\chi}(\\Omega)$ where $\\Omega$ is a\nquarternionic domain in $\\mathbb{H}^n$ and $\\chi$ is a weight function which\nsatisfies some natural conditions. Firstly we prove that the quaternionic\nMonge-Amp\\`ere operator is well-defined for functions in\n$\\mathcal{E}_{\\chi}(\\Omega)$, in particular $\\mathcal{E}_p(\\Omega),p>0$.\n  Secondly, we prove that fine property holds in the Cegrell type class\n$\\mathcal{E}(\\Omega)$. As an application, we prove a mass concentration theorem\nfor the quarternionic plurisubharmonic envelope.\n  In the study of complex Monge-Amp\\`ere equation, characterization of finite\nenergy range of complex Monge-Amp\\`ere operator was a central problem which\naroused the interest of experts in the subject. As a quaternionic analogue, we\nprove a theorem which explicitly characterizes the finite energy range of\n\\emph{quaternionic} Monge-Amp\\`ere operator in the end.","main_category":"math.CV","categories":"math.CV,math.AP,math.DG","published":"2025-04-28T09:27:39Z"}
{"aid":"http://arxiv.org/abs/2504.19620v1","title":"From local to collective superconductivity in proximitized graphene","summary":"The superconducting proximity effect induces pairing correlations in metallic\nsystems via Andreev scattering. This effect is particularly intriguing in\ngraphene, as it enables two-dimensional superconductivity that is tunable\nthrough doping. Understanding how superconducting correlations propagate within\nthe metal is crucial to unveiling the key factors behind this tunability. Here,\nwe employ scanning tunneling microscopy to investigate the energy and length\nscales of the proximity effect induced by Pb islands on graphene. Using\ntip-induced manipulation, we assemble S/N/S junctions with tunable N-region\nspacing and explore the evolution of the proximitized state in the confined\nnormal region. We find that different doping levels can lead to either\nlocalized or collective superconducting states. By combining our experimental\nresults with quasiclassical theory, we demonstrate that interface conductance\nplays a key role in determining the strength and coherence length of pairing\ncorrelations and inter-island coupling. Our findings provide new insights into\nthe design of novel superconducting states and the control of their properties.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.supr-con","published":"2025-04-28T09:28:08Z"}
{"aid":"http://arxiv.org/abs/2504.19625v1","title":"Rulebook: bringing co-routines to reinforcement learning environments","summary":"Reinforcement learning (RL) algorithms, due to their reliance on external\nsystems to learn from, require digital environments (e.g., simulators) with\nvery simple interfaces, which in turn constrain significantly the\nimplementation of such environments. In particular, these environments are\nimplemented either as separate processes or as state machines, leading to\nsynchronization and communication overheads in the first case, and to\nunstructured programming in the second.\n  We propose a new domain-specific, co-routine-based, compiled language, called\nRulebook, designed to automatically generate the state machine required to\ninteract with machine learning (ML) algorithms and similar applications, with\nno performance overhead. Rulebook allows users to express programs without\nneeding to be aware of the specific interface required by the ML components. By\ndecoupling the execution model of the program from the syntactical encoding of\nthe program, and thus without the need for manual state management, Rulebook\nallows to create larger and more sophisticated environments at a lower\ndevelopment cost.","main_category":"cs.PL","categories":"cs.PL,cs.LG","published":"2025-04-28T09:34:34Z"}
{"aid":"http://arxiv.org/abs/2504.19648v1","title":"Gaia FGK Benchmark Stars: spectral library, metallicities and abundances\n  of $Î±$ and Fe-peak elements of the third version","summary":"The accurate determination of chemical abundances in stars plays a pivotal\nrole in understanding stellar structure and evolution, nucleosynthesis, and the\nchemical enrichment history of the Milky Way. Benchmark stars with precise and\naccurate atmospheric parameters and abundances are indispensable for\ncalibrating spectroscopic surveys and testing stellar atmosphere models. This\nstudy focuses on the compilation of high-quality spectra and the determination\nof LTE chemical abundances of iron-peak and $\\alpha$ elements for the third\nversion of the Gaia FGK Benchmark Stars (GBSv3). We compiled spectra of the\nGBSv3 from public archives and complemented these with our own observations. We\nuse fundamental atmospheric parameters from Soubiran et al. 2024 to derive the\nchemical abundances and perform a spectroscopic analysis using the public code\niSpec. We compile a homogeneous spectral library of high-resolution (42,000)\nand high signal-to-noise ($>100$) normalised spectra for 202 stars: including\nthe 192 GBSv3, 9 stars with indirect measurement of the angular diameter from\nprevious GBS versions, and the Sun. Using four radiative transfer codes, we\nderive chemical abundances of 13 chemical species (Fe I, Fe II, Mg I, Si I, Ca\nI, Ti I, Ti II, Sc II, V I, Cr I, Mn I, Co I, Ni I). We make an in-depth study\nof several sources of error. The GBSv3 contributes to the legacy samples of\nspectroscopic reference stars with improved statistics and homogeneity. The\ncompiled high-resolution spectral library and the determination of abundances\nfor iron-peak and $\\alpha$ elements, together with an extensive discussion of\nthe linked uncertainties, provides a sample of reference abundances to the\ncommunity.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-28T10:06:02Z"}
{"aid":"http://arxiv.org/abs/2504.19691v1","title":"Unified Non-Singular Cosmology with Late-Time Acceleration through a\n  Novel Parametrization of Bulk Viscosity Coefficient","summary":"This work explores the influence of viscous fluids on cosmological dynamics\nwithin the framework of General Relativity. We introduce a novel time-dependent\nparametrization for the bulk viscosity coefficient, given by \\(\\zeta = \\zeta_0\n(t - t_0)^{-2n} \\rho^{1/2}\\), where \\(\\zeta_0\\), \\(t_0\\), and \\(n\\) are model\nparameters. This formulation is designed to investigate whether bulk viscosity\nof this nature can effectively describe the evolution of the universe,\nparticularly in scenarios that avoid initial singularities through a\ncosmological bounce. Remarkably, the general solutions emerging from our model\nexhibit significant flexibility, accommodating not only a bouncing universe but\nalso an early inflationary phase and a late-time acceleration mimicking dark\nenergy. The roles of \\(\\zeta_0\\), \\(t_0\\), and \\(n\\) are pivotal, as they\ngovern the cosmic evolution and determine the transitions between different\nphases. To validate the robustness of our model, we analyze key cosmological\nquantities such as the energy density, deceleration parameter, and the validity\nof various energy conditions. Furthermore, we employ statefinder diagnostics to\nprobe the dark energy behavior and examine Hubble flow parameters to shed light\non the inflationary aspects of the model. Lastly, we confront our theoretical\npredictions with observational data sets, including the BAO, DESI and\nPantheon+SH0ES datasets, demonstrating the model's consistency with empirical\ncosmological trends.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-28T11:38:10Z"}
{"aid":"http://arxiv.org/abs/2504.19744v1","title":"Lossy Beyond Diagonal Reconfigurable Intelligent Surfaces: Modeling and\n  Optimization","summary":"Beyond diagonal reconfigurable intelligent surface (BD-RIS) has emerged as an\nadvancement and generalization of the conventional diagonal RIS (D-RIS) by\nintroducing tunable interconnections between RIS elements, enabling smarter\nwave manipulation and enlarged coverage. While BD-RIS has demonstrated\nadvantages over D-RIS in various aspects, most existing works rely on the\nassumption of a lossless model, leaving practical considerations unaddressed.\nThis paper thus proposes a lossy BD-RIS model and develops corresponding\noptimization algorithms for various BD-RIS-aided communication systems. First,\nby leveraging admittance parameter analysis, we model each tunable admittance\nbased on a lumped circuit with losses and derive an expression of a circle\ncharacterizing the real and imaginary parts of each tunable admittance. We then\nconsider the received signal power maximization in single-user single-input\nsingle-output (SISO) systems with the proposed lossy BD-RIS model. To solve the\noptimization problem, we design an effective algorithm by carefully exploiting\nthe problem structure. Specifically, an alternating direction method of\nmultipliers (ADMM) framework is custom-designed to deal with the complicated\nconstraints associated with lossy BD-RIS. Furthermore, we extend the proposed\nalgorithmic framework to more general multiuser multiple-input single-output\n(MU-MISO) systems, where the transmit precoder and BD-RIS scattering matrix are\njointly designed to maximize the sum-rate of the system. Finally, simulation\nresults demonstrate that all BD-RIS architectures still outperform D-RIS in the\npresence of losses, but the optimal BD-RIS architectures in the lossless case\nare not necessarily optimal in the lossy case, e.g. group-connected BD-RIS can\noutperform fully- and tree-connected BD-RISs in SISO systems with relatively\nhigh losses, whereas the opposite always holds true in the lossless case.","main_category":"eess.SP","categories":"eess.SP,cs.IT,math.IT","published":"2025-04-28T12:45:33Z"}
{"aid":"http://arxiv.org/abs/2504.19767v1","title":"Crafting a Personal Journaling Practice: Negotiating Ecosystems of\n  Materials, Personal Context, and Community in Analog Journaling","summary":"Analog journaling has grown in popularity, with journaling on paper\nencompassing a range of motivations, styles, and practices including planning,\nhabit-tracking, and reflecting. Journalers develop strong personal preferences\naround the tools they use, the ideas they capture, and the layout in which they\nrepresent their ideas and memories. Understanding how analog journaling\npractices are individually shaped and crafted over time is critical to\nsupporting the varied benefits associated with journaling, including improved\nmental health and positive support for identity development. To understand this\ndevelopment, we qualitatively analyzed publicly-shared journaling content from\nYouTube and Instagram and interviewed 11 journalers. We report on our\nidentification of the journaling ecosystem in which journaling practices are\nshaped by materials, personal context, and communities, sharing how this\necosystem plays a role in the practices and identities of journalers as they\ncustomize their journaling routine to best suit their personal goals. Using\nthese insights, we discuss design opportunities for how future tools can better\nalign with and reflect the rich affordances and practices of journaling on\npaper.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-28T13:07:29Z"}
{"aid":"http://arxiv.org/abs/2504.19804v1","title":"Nonlinear Power Absorption in CCRF Discharges: Transition from Symmetric\n  to Asymmetric Configurations","summary":"This work builds upon previous studies of nonlinear dynamics in low-pressure\ncapacitively coupled radio-frequency discharges, focusing on the electron power\nabsorption mechanism in discharges with various geometric asymmetries. We\npresent a comprehensive investigation using a fully kinetic electrostatic 1d3v\nParticle-in-Cell/Monte Carlo collision simulation in spherical geometry. By\nsystematically varying the inner electrode radius and the electrode gap\ndistance, we analyze the influence of geometric asymmetry on key plasma\nproperties, including electron density, power absorption, electron dynamics,\nand current characteristics. A central focus is placed on the cumulative power\ndensity as a diagnostic for energy deposition. In strongly asymmetric\nconfigurations, the cumulative electron power density exhibits distinct\nstepwise increases during sheath expansion, corresponding to the acceleration\nof successive electron beams. These nonlinear signatures are directly linked to\nthe excitation of plasma series resonance and enhanced beam-driven power\nabsorption. In contrast, more symmetric configurations display smoother, more\nsymmetric cumulative power evolution, indicating balanced energy transfer at\nboth sheaths and reduced nonlinearities. Time- and space-resolved diagnostics\nof cumulative power, current waveforms, and densities of energetic electrons\nreveal the critical role of asymmetry in shaping electron confinement and\nbeam-driven power absorption. These findings demonstrate that the discharge\ngeometry is actually an important design parameter which needs to taken into\naccount during the design and construction phase of a reactor as it directly\ninfluences the plasma behavior with respect to energy deposition.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-28T13:55:43Z"}
{"aid":"http://arxiv.org/abs/2504.19807v1","title":"Multi-Parameter Transitions in Cosmological Calibrators: A Resolution to\n  the Hubble Tension from SH0ES Data Analysis","summary":"The Hubble tension, characterized by discrepant measurements of the Hubble\nconstant from early and late universe probes, remains one of the most\nsignificant challenges in cosmology. Building upon our previous analysis of\nindividual parameter transitions in SH0ES data, we investigate the impact of\nsimultaneous transitions in multiple Cepheid and SNIa calibration parameters at\nspecific cosmic distances. We allow various combinations of transitions in\nCepheid absolute magnitude ($M^W_H$), period-luminosity relation slope ($b_W$),\nmetallicity coefficient ($Z_W$), and SNIa absolute magnitude ($M_B$). Our\ncomprehensive analysis reveals a consistent preferred transition distance of\napproximately 23 Mpc across different parameter combinations. The most\nstatistically favored model allows simultaneous transitions in $b_W$, $Z_W$,\nand $M_B$, yielding $\\Delta \\text{AIC} \\simeq -9.2$ and $\\Delta \\text{BIC}\n\\simeq -3.0$ compared to the baseline SH0ES model. This provides strong\nevidence for inhomogeneities in standard candle calibrations. We demonstrate\nthat the post-transition SNIa absolute magnitude aligns more closely with\nCMB-based constraints, resulting in a reduced Hubble constant value that\nalleviates the tension. Our findings suggest that the Hubble tension might be\nresolved through proper modeling of calibration parameter inhomogeneities\nrather than requiring new physics beyond $\\Lambda$CDM.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-28T14:04:27Z"}
{"aid":"http://arxiv.org/abs/2504.19818v1","title":"PhenoAssistant: A Conversational Multi-Agent AI System for Automated\n  Plant Phenotyping","summary":"Plant phenotyping increasingly relies on (semi-)automated image-based\nanalysis workflows to improve its accuracy and scalability. However, many\nexisting solutions remain overly complex, difficult to reimplement and\nmaintain, and pose high barriers for users without substantial computational\nexpertise. To address these challenges, we introduce PhenoAssistant: a\npioneering AI-driven system that streamlines plant phenotyping via intuitive\nnatural language interaction. PhenoAssistant leverages a large language model\nto orchestrate a curated toolkit supporting tasks including automated phenotype\nextraction, data visualisation and automated model training. We validate\nPhenoAssistant through several representative case studies and a set of\nevaluation tasks. By significantly lowering technical hurdles, PhenoAssistant\nunderscores the promise of AI-driven methodologies to democratising AI adoption\nin plant biology.","main_category":"cs.MA","categories":"cs.MA,cs.AI","published":"2025-04-28T14:20:30Z"}
{"aid":"http://arxiv.org/abs/2504.19846v1","title":"Clustering-based Recurrent Neural Network Controller synthesis under\n  Signal Temporal Logic Specifications","summary":"Autonomous robotic systems require advanced control frameworks to achieve\ncomplex temporal objectives that extend beyond conventional stability and\ntrajectory tracking. Signal Temporal Logic (STL) provides a formal framework\nfor specifying such objectives, with robustness metrics widely employed for\ncontrol synthesis. Existing optimization-based approaches using neural network\n(NN)-based controllers often rely on a single NN for both learning and control.\nHowever, variations in initial states and obstacle configurations can lead to\ndiscontinuous changes in the optimization solution, thereby degrading\ngeneralization and control performance. To address this issue, this study\nproposes a method to enhance recurrent neural network (RNN)-based control by\nclustering solution trajectories that satisfy STL specifications under diverse\ninitial conditions. The proposed approach utilizes trajectory similarity\nmetrics to generate clustering labels, which are subsequently used to train a\nclassification network. This network assigns new initial states and obstacle\nconfigurations to the appropriate cluster, enabling the selection of a\nspecialized controller. By explicitly accounting for variations in solution\ntrajectories, the proposed method improves both estimation accuracy and control\nperformance. Numerical experiments on a dynamic vehicle path planning problem\ndemonstrate the effectiveness of the approach.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-28T14:44:58Z"}
{"aid":"http://arxiv.org/abs/2504.19848v1","title":"Human-Centered AI and Autonomy in Robotics: Insights from a Bibliometric\n  Study","summary":"The development of autonomous robotic systems offers significant potential\nfor performing complex tasks with precision and consistency. Recent advances in\nArtificial Intelligence (AI) have enabled more capable intelligent automation\nsystems, addressing increasingly complex challenges. However, this progress\nraises questions about human roles in such systems. Human-Centered AI (HCAI)\naims to balance human control and automation, ensuring performance enhancement\nwhile maintaining creativity, mastery, and responsibility. For real-world\napplications, autonomous robots must balance task performance with reliability,\nsafety, and trustworthiness. Integrating HCAI principles enhances human-robot\ncollaboration and ensures responsible operation.\n  This paper presents a bibliometric analysis of intelligent autonomous robotic\nsystems, utilizing SciMAT and VOSViewer to examine data from the Scopus\ndatabase. The findings highlight academic trends, emerging topics, and AI's\nrole in self-adaptive robotic behaviour, with an emphasis on HCAI architecture.\nThese insights are then projected onto the IBM MAPE-K architecture, with the\ngoal of identifying how these research results map into actual robotic\nautonomous systems development efforts for real-world scenarios.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-28T14:45:48Z"}
{"aid":"http://arxiv.org/abs/2504.19858v1","title":"Existence of most reliable two-terminal graphs with distance constraints","summary":"A two-terminal graph is a simple graph equipped with two distinguished\nvertices, called terminals. Let $T_{n,m}$ be the class consisting of all\nnonisomorphic two-terminal graphs on $n$ vertices and $m$ edges. Let $G$ be any\ntwo-terminal graph in $T_{n,m}$, and let $d$ be any positive integer. For each\n$\\rho\\in [0,1]$, the \\emph{$d$-constrained two-terminal reliability of $G$ at\n$\\rho$}, denoted $R_G^d(\\rho)$, is the probability that $G$ has some path of\nlength at most $d$ joining its terminals after each of its edges is\nindependently deleted with probability $\\rho$. We say $G$ is a\n\\emph{$d$-uniformly most reliable two-terminal graph} ($d$-UMRTTG) if for each\n$H$ in $T_{n,m}$ and every $\\rho \\in [0,1]$ it holds that $R_{G}^d(\\rho)\\geq\nR_H^d(\\rho)$. Previous works studied the existence of $d$-UMRTTG in $T_{n,m}$\nwhen $d$ is greater than or equal to $n-1$, or equivalently, when the distance\nconstraint is dropped. In this work, a characterization of all $1$-UMRTTGs and\n$2$-UMRTTGs is given. Then, it is proved that there exists a unique $3$-UMRTTG\nin $T_{n,m}$ when $n\\geq 6$ and $5 \\leq m \\leq 2n-3$. Finally, for each $d\\geq\n4$ and each $n\\geq 11$ it is proved that there is no $d$-UMRTTG in $T_{n,m}$\nwhen $20 \\leq m \\leq 3n-9$ or when $3n-5 \\leq m \\leq \\binom{n}{2}-2$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-28T14:49:34Z"}
{"aid":"http://arxiv.org/abs/2504.19859v1","title":"Some PDE results in Heston model with applications","summary":"We present here some results for the PDE related to the logHeston model. We\npresent different regularity results and prove a verification theorem that\nshows that the solution produced via the Feynman-Kac theorem is the unique\nviscosity solution for a wide choice of initial data (even discontinuous) and\nsource data. In addition, our techniques do not use Feller's condition at any\ntime. In the end, we prove a convergence theorem to approximate this solution\nby means of a hybrid (finite differences/tree scheme) approach.","main_category":"math.AP","categories":"math.AP,cs.NA,math.NA,q-fin.CP","published":"2025-04-28T14:50:06Z"}
{"aid":"http://arxiv.org/abs/2504.19867v1","title":"semi-PD: Towards Efficient LLM Serving via Phase-Wise Disaggregated\n  Computation and Unified Storage","summary":"Existing large language model (LLM) serving systems fall into two categories:\n1) a unified system where prefill phase and decode phase are co-located on the\nsame GPU, sharing the unified computational resource and storage, and 2) a\ndisaggregated system where the two phases are disaggregated to different GPUs.\nThe design of the disaggregated system addresses the latency interference and\nsophisticated scheduling issues in the unified system but leads to storage\nchallenges including 1) replicated weights for both phases that prevent\nflexible deployment, 2) KV cache transfer overhead between the two phases, 3)\nstorage imbalance that causes substantial wasted space of the GPU capacity, and\n4) suboptimal resource adjustment arising from the difficulties in migrating KV\ncache. Such storage inefficiency delivers poor serving performance under high\nrequest rates.\n  In this paper, we identify that the advantage of the disaggregated system\nlies in the disaggregated computation, i.e., partitioning the computational\nresource to enable the asynchronous computation of two phases. Thus, we propose\na novel LLM serving system, semi-PD, characterized by disaggregated computation\nand unified storage. In semi-PD, we introduce a computation resource controller\nto achieve disaggregated computation at the streaming multi-processor (SM)\nlevel, and a unified memory manager to manage the asynchronous memory access\nfrom both phases. semi-PD has a low-overhead resource adjustment mechanism\nbetween the two phases, and a service-level objective (SLO) aware dynamic\npartitioning algorithm to optimize the SLO attainment. Compared to\nstate-of-the-art systems, semi-PD maintains lower latency at higher request\nrates, reducing the average end-to-end latency per request by 1.27-2.58x on\nDeepSeek series models, and serves 1.55-1.72x more requests adhering to latency\nconstraints on Llama series models.","main_category":"cs.CL","categories":"cs.CL,cs.DC,cs.LG","published":"2025-04-28T15:00:03Z"}
{"aid":"http://arxiv.org/abs/2504.19871v1","title":"Degree-1 maps and rank inequalities in Heegaard Floer homology","summary":"Ghosh-Sivek-Zentner constructed degree-1 maps from certain rational homology\nsolid tori to the twisted $I$-bundle over the Klein bottle. We show that these\nmaps yield rank inequalities for Heegaard Floer homology. To do so, we use\nHanselman-Rasmussen-Watson's immersed curve interpretation of bordered Floer\nhomology, extending their proof of a similar rank inequality corresponding to\ndegree-1 maps to the solid torus. Our result provides further evidence for\nKronheimer-Mowka's conjectured relationship between Heegaard Floer homology and\ninstanton Floer homology.","main_category":"math.GT","categories":"math.GT","published":"2025-04-28T15:03:39Z"}
{"aid":"http://arxiv.org/abs/2504.19893v1","title":"Separator-based derivations of graphic arrangements","summary":"The class of subarrangements of the well-studied braid arrangement, so-called\ngraphic hyperplane arrangements, is important for analysing new concepts and\nproperties in hyperplane arrangement theory. While there is a nice\ncharacterization of free graphic arrangements, many interesting questions\nbeyond the free case remain open. This paper introduces an explicit set of\ngenerators for the module of logarithmic derivations of a general graphic\narrangement based on graph separators. We obtain new insights in the derivation\ndegree sequence in the non-free case and give bounds on the highest degree in\nthe sequence. Moreover, this can broadly be used for future research in this\narea.","main_category":"math.CO","categories":"math.CO,math.AC","published":"2025-04-28T15:27:07Z"}
{"aid":"http://arxiv.org/abs/2504.19900v1","title":"Breast Cancer Detection from Multi-View Screening Mammograms with Visual\n  Prompt Tuning","summary":"Accurate detection of breast cancer from high-resolution mammograms is\ncrucial for early diagnosis and effective treatment planning. Previous studies\nhave shown the potential of using single-view mammograms for breast cancer\ndetection. However, incorporating multi-view data can provide more\ncomprehensive insights. Multi-view classification, especially in medical\nimaging, presents unique challenges, particularly when dealing with\nlarge-scale, high-resolution data. In this work, we propose a novel Multi-view\nVisual Prompt Tuning Network (MVPT-NET) for analyzing multiple screening\nmammograms. We first pretrain a robust single-view classification model on\nhigh-resolution mammograms and then innovatively adapt multi-view feature\nlearning into a task-specific prompt tuning process. This technique selectively\ntunes a minimal set of trainable parameters (7\\%) while retaining the\nrobustness of the pre-trained single-view model, enabling efficient integration\nof multi-view data without the need for aggressive downsampling. Our approach\noffers an efficient alternative to traditional feature fusion methods,\nproviding a more robust, scalable, and efficient solution for high-resolution\nmammogram analysis. Experimental results on a large multi-institution dataset\ndemonstrate that our method outperforms conventional approaches while\nmaintaining detection efficiency, achieving an AUROC of 0.852 for\ndistinguishing between Benign, DCIS, and Invasive classes. This work highlights\nthe potential of MVPT-NET for medical imaging tasks and provides a scalable\nsolution for integrating multi-view data in breast cancer detection.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-28T15:31:08Z"}
{"aid":"http://arxiv.org/abs/2504.19923v1","title":"Modeling of Parallel Single-Pixel Imaging for 3D Reconstruction: New\n  Insights and Opportunities","summary":"The growing prevalence of intelligent manufacturing and autonomous vehicles\nhas intensified the demand for three-dimensional (3D) reconstruction under\ncomplex reflection and transmission conditions. Traditional structured light\ntechniques rely on inherent point-to-point triangulation, which limits accurate\n3D measurements in these challenging scenarios. Parallel single-pixel imaging\n(PSI) has demonstrated unprecedented superiority under extreme conditions and\nhas emerged as a promising approach of accurate 3D measurements. However, a\ncomplete theoretical model has not been reported in existing work to well\nexplain its underlying mechanisms and quantitatively characterize its\nperformance. In this study, a comprehensive theoretical model for the PSI\nmethod is proposed, including imaging and noise models. The proposed imaging\nmodel describes light transport coefficients under complex illumination,\nelucidating the intrinsic mechanisms of successful 3D imaging using PSI. The\ndeveloped noise model quantitatively analyzes the impact of environmental noise\non measurement accuracy, offering a framework to guide the error analysis of a\nPSI system. Numerical simulations and experimental results validate the\nproposed models, revealing the generality and robustness of PSI. Finally,\npotential research directions are highlighted to guide and inspire future\ninvestigations. The established theoretical models lay a solid foundation of\nPSI and brings new insights and opportunities for future application in more\ndemanding 3D reconstruction tasks.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-28T15:57:44Z"}
{"aid":"http://arxiv.org/abs/2504.19947v1","title":"Nonlinear states of the conservative complex Swift-Hohenberg equation","summary":"We consider the conservative complex Swift-Hohenberg equation, which belongs\nto the family of nonlinear fourth-order dispersive Schr\\\"odinger equations. In\ncontrast to the well-studied one-dimensional dissipative Swift-Hohenberg\nequation, the complex variant introduces a wide array of largely unexplored\nsolutions. Our study provides a fundamental step in understanding the complex\ncharacteristics of this equation, particularly for typical classes of\nsolutions-uniform, periodic, and localized states-and their relationship with\nthe original dissipative model. Our findings reveal significant differences\nbetween the two models. For instance, uniform solutions in the conservative\nmodel are inherently unstable, and periodic solutions are generally unstable\nexcept within a narrow parameter interval that supports multiple localized\nstates. Furthermore, we establish a generalized Vakhitov-Kolokolov criterion to\ndetermine the stability of localized states in the conservative equation and\nrelate it to the stability properties of the dissipative counterpart.","main_category":"nlin.PS","categories":"nlin.PS","published":"2025-04-28T16:19:21Z"}
{"aid":"http://arxiv.org/abs/2504.19950v1","title":"Data-Driven Stabilization of Unknown Linear-Threshold Network Dynamics","summary":"This paper studies the data-driven control of unknown linear-threshold\nnetwork dynamics to stabilize the state to a reference value. We consider two\ntypes of controllers: (i) a state feedback controller with feed-forward\nreference input and (ii) an augmented feedback controller with error\nintegration. The first controller features a simpler structure and is easier to\ndesign, while the second offers improved performance in the presence of system\nparameter changes and disturbances. Our design strategy employs state-input\ndatasets to construct data-based representations of the closed-loop dynamics.\nSince these representations involve linear threshold functions, we rewrite them\nas switched linear systems, and formulate the design problem as that of finding\na common controller for all the resulting modes. This gives rise to a set of\nlinear matrix inequalities (LMIs) whose solutions corresponds to the controller\ngain matrices. We analyze the computational complexity of solving the LMIs and\npropose a simplified, sufficient set of conditions that scales linearly with\nthe system state. Simulations on two case studies involving regulation of\nfiring rate dynamics in rodent brains and of arousal level dynamics in humans\ndemonstrate the effectiveness of the controller designs.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-28T16:21:47Z"}
{"aid":"http://arxiv.org/abs/2504.19953v1","title":"Marginal expected shortfall: Systemic risk measurement under dependence\n  uncertainty","summary":"Measuring the contribution of a bank or an insurance company to the overall\nsystemic risk of the market is an important issue, especially in the aftermath\nof the 2007-2009 financial crisis and the financial downturn of 2020. In this\npaper, we derive the worst-case and best-case bounds for marginal expected\nshortfall (MES) -- a key measure of systemic risk contribution -- under the\nassumption of known marginal distributions for individual companies' risks but\nan unknown dependence structure. We further derive improved bounds for the MES\nrisk measure when partial information on companies' risk exposures -- and hence\ntheir dependence -- is available. To capture this partial information, we\nutilize three commonly used background risk models: the additive,\nminimum-based, and multiplicative factor models. Finally, we present an\nalternative set of improved MES bounds based on a linear regression\nrelationship between individual companies' risks and overall market risk,\nconsistent with the assumptions of the Capital Asset Pricing Model in finance\nand the Weighted Insurance Pricing Model in insurance.","main_category":"q-fin.RM","categories":"q-fin.RM,math.ST,stat.AP,stat.TH","published":"2025-04-28T16:23:53Z"}
{"aid":"http://arxiv.org/abs/2504.19954v1","title":"Type-Based Unsourced Multiple Access over Fading Channels with Cell-Free\n  Massive MIMO","summary":"Type-based unsourced multiple access (TUMA) is a recently proposed framework\nfor type-based estimation in massive uncoordinated access networks. We extend\nthe existing design of TUMA, developed for an additive white Gaussian channel,\nto a more realistic environment with fading and multiple antennas.\nSpecifically, we consider a cell-free massive multiple-input multiple-output\nsystem and exploit spatial diversity to estimate the set of transmitted\nmessages and the number of users transmitting each message. Our solution relies\non a location-based codeword partition and on the use at the receiver of a\nmultisource approximate message passing algorithm in both centralized and\ndistributed implementations. The proposed TUMA framework results in a robust\nand scalable architecture for massive machine-type communications.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-28T16:24:46Z"}
{"aid":"http://arxiv.org/abs/2504.19966v1","title":"Quantum circuit lower bounds in the magic hierarchy","summary":"We introduce the magic hierarchy, a quantum circuit model that alternates\nbetween arbitrary-sized Clifford circuits and constant-depth circuits with\ntwo-qubit gates ($\\textsf{QNC}^0$). This model unifies existing circuit models,\nsuch as $\\textsf{QAC}^0_f$ and models with adaptive intermediate measurements.\nDespite its generality, we are able to prove nontrivial lower bounds.\n  We prove new lower bounds in the first level of the hierarchy, showing that\ncertain explicit quantum states cannot be approximately prepared by circuits\nconsisting of a Clifford circuit followed by $\\textsf{QNC}^0$. These states\ninclude ground states of some topologically ordered Hamiltonians and\nnonstabilizer quantum codes. Our techniques exploit the rigid structure of\nstabilizer codes and introduce an infectiousness property: if even a single\nstate in a high distance code can be approximately prepared by one of these\ncircuits, then the entire subspace must lie close to a perturbed stabilizer\ncode. We also show that proving state preparation lower bounds beyond a certain\nlevel of the hierarchy would imply classical circuit lower bounds beyond the\nreach of current techniques in complexity theory.\n  More broadly, our techniques go beyond lightcone-based methods and highlight\nhow the magic hierarchy provides a natural framework for connecting circuit\ncomplexity, condensed matter, and Hamiltonian complexity.","main_category":"quant-ph","categories":"quant-ph,cs.CC","published":"2025-04-28T16:38:20Z"}
{"aid":"http://arxiv.org/abs/2504.19969v1","title":"Holographic Consequences of Heterotic String Theory beyond its\n  Supergravity Approximation","summary":"In this work, we study the effects of stringy corrections on the low energy\neffective action derived from heterotic string theory beyond its supergravity\napproximation. Compactifying the ten dimensional theory with these stringy\ncorrections produces an effective action for a scalar field whose higher\nderivative term is governed by a single coefficient that depends on the\ninternal volume, average curvature, and flux of the compactification manifold.\nThe higher derivative coupling imported from compactification shifts the\nBreitenlohner Freedman stability bound by an amount set by the relative\nstrengths of internal flux and curvature, relaxing it in flux dominated vacua\nand tightening it in curvature dominated ones. Furthermore, we analyze how the\nstringy corrections shift the scaling dimensions of the dual operators, track\nthe resulting renormalization group flow, and investigate the higher derivative\nterm using a holographic Lee Wick regulator. In holographic superconductors,\nstringy corrections lower the effective bulk mass and raise the critical\ntemperature when flux dominates, but have the opposite effect when curvature\ndominates.","main_category":"hep-th","categories":"hep-th","published":"2025-04-28T16:40:25Z"}
{"aid":"http://arxiv.org/abs/2504.20000v1","title":"Knowledge Distillation of Domain-adapted LLMs for Question-Answering in\n  Telecom","summary":"Knowledge Distillation (KD) is one of the approaches to reduce the size of\nLarge Language Models (LLMs). A LLM with smaller number of model parameters\n(student) is trained to mimic the performance of a LLM of a larger size\n(teacher model) on a specific task. For domain-specific tasks, it is not clear\nif teacher or student model, or both, must be considered for domain adaptation.\nIn this work, we study this problem from perspective of telecom domain\nQuestion-Answering (QA) task. We systematically experiment with Supervised\nFine-tuning (SFT) of teacher only, SFT of student only and SFT of both prior to\nKD. We design experiments to study the impact of vocabulary (same and\ndifferent) and KD algorithms (vanilla KD and Dual Space KD, DSKD) on the\ndistilled model. Multi-faceted evaluation of the distillation using 14\ndifferent metrics (N-gram, embedding and LLM-based metrics) is considered.\nExperimental results show that SFT of teacher improves performance of distilled\nmodel when both models have same vocabulary, irrespective of algorithm and\nmetrics. Overall, SFT of both teacher and student results in better performance\nacross all metrics, although the statistical significance of the same depends\non the vocabulary of the teacher models.","main_category":"cs.CL","categories":"cs.CL,cs.IR,cs.LG,I.2.7","published":"2025-04-28T17:19:25Z"}
{"aid":"http://arxiv.org/abs/2504.20006v1","title":"Chatbot Arena Meets Nuggets: Towards Explanations and Diagnostics in the\n  Evaluation of LLM Responses","summary":"Battles, or side-by-side comparisons in so called arenas that elicit human\npreferences, have emerged as a popular approach to assessing the output quality\nof LLMs. Recently, this idea has been extended to retrieval-augmented\ngeneration (RAG) systems. While undoubtedly representing an advance in\nevaluation, battles have at least two drawbacks, particularly in the context of\ncomplex information-seeking queries: they are neither explanatory nor\ndiagnostic. Recently, the nugget evaluation methodology has emerged as a\npromising approach to evaluate the quality of RAG answers. Nuggets decompose\nlong-form LLM-generated answers into atomic facts, highlighting important\npieces of information necessary in a \"good\" response. In this work, we apply\nour AutoNuggetizer framework to analyze data from roughly 7K Search Arena\nbattles provided by LMArena in a fully automatic manner. Our results show a\nsignificant correlation between nugget scores and human preferences, showcasing\npromise in our approach to explainable and diagnostic system evaluations.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-28T17:24:36Z"}
{"aid":"http://arxiv.org/abs/2504.20043v1","title":"Starlight from JWST: Implications for star formation and dark matter\n  models","summary":"We confront the star formation rate in different dark matter (DM) models with\nUV luminosity data from JWST up to $z\\simeq25$ and legacy data from HST. We\nfind that a transition from a Salpeter population to top-heavy Pop-III stars is\nlikely at $z\\simeq10$ and that beyond $z=10-15$ the feedback from supernovae\nand active galactic nuclei is progressively reduced, so that at $z\\simeq25$ the\nproduction of stars is almost free from any feedback. We compare fuzzy and warm\nDM models that suppress small-scale structures with the CDM paradigm, finding\nthat the fuzzy DM mass $> 4.5 \\times 10^{-22}{\\rm eV}$ and the warm DM mass $>\n1.5\\, {\\rm keV}$ at the 95\\% CL. The fits of the star formation rate\nparametrization do not depend strongly on the DM properties within the allowed\nrange. We find no preference over CDM for enhanced matter perturbations\nassociated with axion miniclusters or primordial black holes. The scale of the\nenhancement of the power spectrum should be $> 27\\,{\\rm Mpc}^{-1}$ at the 95\\%\nCL, excluding axion miniclusters produced for $m_a < 7.5 \\times 10^{-17}\\,{\\rm\neV}$ or heavy primordial black holes that constitute a fraction $f_{\\rm PBH}$\nof DM in the range $10^{-4} (m_{\\rm PBH}/10^4 \\,M_{\\odot})^{-0.09} < f_{\\rm\nPBH} < 8.7\\times 10^{-3} (m_{\\rm PBH}/10^4\\, M_{\\odot})^{-1}$.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.GA,hep-ph","published":"2025-04-28T17:59:58Z"}
{"aid":"http://arxiv.org/abs/2504.20400v1","title":"Evolution of Gaussians in the Hellinger-Kantorovich-Boltzmann gradient\n  flow","summary":"This study leverages the basic insight that the gradient-flow equation\nassociated with the relative Boltzmann entropy, in relation to a Gaussian\nreference measure within the Hellinger-Kantorovich (HK) geometry, preserves the\nclass of Gaussian measures. This invariance serves as the foundation for\nconstructing a reduced gradient structure on the parameter space characterizing\nGaussian densities. We derive explicit ordinary differential equations that\ngovern the evolution of mean, covariance, and mass under the HK-Boltzmann\ngradient flow. The reduced structure retains the additive form of the HK\nmetric, facilitating a comprehensive analysis of the dynamics involved.\n  We explore the geodesic convexity of the reduced system, revealing that\nglobal convexity is confined to the pure transport scenario, while a variant of\nsublevel semi-convexity is observed in the general case. Furthermore, we\ndemonstrate exponential convergence to equilibrium through\nPolyak-Lojasiewicz-type inequalities, applicable both globally and on sublevel\nsets. By monitoring the evolution of covariance eigenvalues, we refine the\ndecay rates associated with convergence. Additionally, we extend our analysis\nto non-Gaussian targets exhibiting strong log-lambda-concavity, corroborating\nour theoretical results with numerical experiments that encompass a\nGaussian-target gradient flow and a Bayesian logistic regression application.","main_category":"math.AP","categories":"math.AP,math.PR,stat.ML","published":"2025-04-29T03:54:56Z"}
{"aid":"http://arxiv.org/abs/2504.20416v1","title":"Large-scale artificial intelligence with 41 million nanophotonic neurons\n  on a metasurface","summary":"Conventional integrated circuits (ICs) struggle to meet the escalating\ndemands of artificial intelligence (AI). This has sparked a renewed interest in\nan unconventional computing paradigm: neuromorphic (brain-inspired) computing.\nHowever, current neuromorphic systems face significant challenges in delivering\na large number of parameters (i.e., weights) required for large-scale AI\nmodels. As a result, most neuromorphic hardware is limited to basic benchmark\ndemonstrations, hindering its application to real-world AI challenges. Here, we\npresent a large-scale optical neural network (ONN) for machine learning\nacceleration, featuring over 41 million photonic neurons. This system not only\nsurpasses digital electronics in speed and energy efficiency but more\nimportantly, closes the performance gap with large-scale AI models. Our ONN\nleverages an innovative optical metasurface device featuring numerous spatial\nmodes. This device integrates over 41 million meta-atoms on a 10 mm$^2$\nmetasurface chip, enabling the processing of tens of millions of weights in a\nsingle operation. For the first time, we demonstrate that an ONN, utilizing a\nsingle-layer metasurface, can match the performance of deep and large-scale\ndeep learning models, such as ResNet and Vision Transformer, across various\nbenchmark tasks. Additionally, we show that our system can deliver\nhigh-performance solutions to real-world AI challenges through its\nunprecedented scale, such as accelerating the analysis of multi-gigapixel whole\nslide images (WSIs) for cancer detection by processing the million-pixel\nsub-image in a single shot. Our system reduces computing time and energy\nconsumption by over 1,000 times compared to state-of-the-art graphic processing\nunits (GPUs). This work presents a large-scale, low-power, and high-performance\nneuromorphic computing system, paving the way for future disruptive AI\ntechnologies.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-29T04:27:35Z"}
{"aid":"http://arxiv.org/abs/2504.20417v1","title":"Protocol-level description and self-contained security proof of\n  decoy-state BB84 QKD protocol","summary":"In this paper, we present a flowchart-based description of the decoy-state\nBB84 quantum key distribution (QKD) protocol and provide a step-by-step,\nself-contained information-theoretic security proof for this protocol within\nthe universal composable security framework. As a result, our proof yields a\nkey rate consistent with previous findings. Importantly, unlike all the prior\nsecurity proofs, our approach offers a fully rigorous and mathematical\njustification for achieving the key rate with the claimed correctness and\nsecrecy parameters, thereby representing a significant step toward the formal\ncertification of QKD systems.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-29T04:28:15Z"}
{"aid":"http://arxiv.org/abs/2504.20430v1","title":"Learning Laplacian Positional Encodings for Heterophilous Graphs","summary":"In this work, we theoretically demonstrate that current graph positional\nencodings (PEs) are not beneficial and could potentially hurt performance in\ntasks involving heterophilous graphs, where nodes that are close tend to have\ndifferent labels. This limitation is critical as many real-world networks\nexhibit heterophily, and even highly homophilous graphs can contain local\nregions of strong heterophily. To address this limitation, we propose Learnable\nLaplacian Positional Encodings (LLPE), a new PE that leverages the full\nspectrum of the graph Laplacian, enabling them to capture graph structure on\nboth homophilous and heterophilous graphs. Theoretically, we prove LLPE's\nability to approximate a general class of graph distances and demonstrate its\ngeneralization properties. Empirically, our evaluation on 12 benchmarks\ndemonstrates that LLPE improves accuracy across a variety of GNNs, including\ngraph transformers, by up to 35% and 14% on synthetic and real-world graphs,\nrespectively. Going forward, our work represents a significant step towards\ndeveloping PEs that effectively capture complex structures in heterophilous\ngraphs.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-29T04:58:13Z"}
{"aid":"http://arxiv.org/abs/2504.20441v1","title":"Task-Oriented Semantic Communication with Importance-Aware Rate Control","summary":"Semantic communication is recognized for its high compression efficiency and\nrobust resistance to noise. However, utilizing a fixed transmission rate in\nenvironments with dynamic signal-to-noise ratios (SNR) often results in\ninefficient use of communication resources. To address this challenge, this\nletter proposes an importance-aware rate control semantic communication (IRCSC)\nscheme, which dynamically adjusts transmission rates in response to both\nchannel conditions and semantic importance. The scheme employs a\ncontribution-based importance analyzer to rank semantic importance.\nAdditionaly, a novel metric, the semantic transmission integrity index (STII),\nis proposed to quantify the amount of correctly transmitted information and to\ncorrelate it with inference performance. Simulations indicate that, with low\ncomputational complexity, IRCSC guarantees a controllable trade-off between\nperformance and rate, delivering higher compression efficiency and improved\ntask performance in high-SNR scenarios.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-29T05:32:18Z"}
{"aid":"http://arxiv.org/abs/2504.20456v1","title":"Reviving Any-Subset Autoregressive Models with Principled Parallel\n  Sampling and Speculative Decoding","summary":"In arbitrary-order language models, it is an open question how to sample\ntokens in parallel from the correct joint distribution. With discrete diffusion\nmodels, the more tokens they generate in parallel, the less their predicted\ndistributions adhere to the originally learned data distribution, as they rely\non a conditional independence assumption that only works with infinitesimally\nsmall timesteps. We find that a different class of models, any-subset\nautoregressive models (AS-ARMs), holds the solution. As implied by the name,\nAS-ARMs can generate tokens in any order, and in parallel. Moreover, AS-ARMs\nsupport parallelized joint probability density estimation, allowing them to\ncorrect their own parallel-generated token distributions, via our Any-Subset\nSpeculative Decoding (ASSD) algorithm. ASSD provably enables generation of\ntokens from the correct joint distribution, with the number of neural network\ncalls upper bounded by the number of tokens predicted. We empirically verify\nthat ASSD speeds up language generation, without sacrificing quality.\nFurthermore, we provide a mathematically justified scheme for training AS-ARMs\nfor generation, and show that AS-ARMs achieve state-of-the-art performance\namong sub-200M parameter models on infilling benchmark tasks, and nearly match\nthe performance of models 50X larger on code generation. Our theoretical and\nempirical results indicate that the once-forgotten AS-ARMs are a promising\ndirection of language modeling.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-29T06:33:13Z"}
{"aid":"http://arxiv.org/abs/2504.20467v1","title":"Switching, Multiple Time-Scales and Geometric Blow-Up in a\n  Low-Dimensional Gene Regulatory Network","summary":"ODE-based models for gene regulatory networks (GRNs) can often be formulated\nas smooth singular perturbation problems with multiple small parameters, some\nof which are related to time-scale separation, whereas others are related to\n'switching' (proximity to a non-smooth singular limit). This motivates the\nstudy of reduced models obtained after (i) quasi-steady state reduction (QSSR),\nwhich utilises the time-scale separation, and (ii) piecewise-smooth\napproximations, which reduce the nonlinearity of the model by viewing highly\nnonlinear sigmoidal terms as singular perturbations of step functions. We\ninvestigate the interplay between the reduction methods (i)-(ii), in the\ncontext of a 4-dimensional GRN which has been used as a low-dimensional\nrepresentative of an important class of (generally high-dimensional) GRN models\nin the literature. We begin by identifying a region in the small parameter\nplane for which this problem can be formulated as a smooth singularly perturbed\nsystem on a blown-up space, uniformly in the switching parameter. This allows\nus to apply Fenichel's coordinate-free theorems and obtain a rigorous reduction\nto a 2-dimensional system, that is a perturbation of the QSSR. Finally, we show\nthat the reduced system features a Hopf bifurcation which does not appear in\nthe QSSR system, due to the influence of higher order terms. Taken together,\nour findings suggest that the relative size of the small parameters is\nimportant for the validity of QSS reductions and the determination of\nqualitative dynamics in GRN models more generally. Although the focus is on the\n4-dimensional GRN, our approach is applicable to higher dimensions.","main_category":"math.DS","categories":"math.DS","published":"2025-04-29T07:05:05Z"}
{"aid":"http://arxiv.org/abs/2504.20479v1","title":"Full-field surrogate modeling of cardiac function encoding geometric\n  variability","summary":"Combining physics-based modeling with data-driven methods is critical to\nenabling the translation of computational methods to clinical use in\ncardiology. The use of rigorous differential equations combined with machine\nlearning tools allows for model personalization with uncertainty quantification\nin time frames compatible with clinical practice. However, accurate and\nefficient surrogate models of cardiac function, built from physics-based\nnumerical simulation, are still mostly geometry-specific and require retraining\nfor different patients and pathological conditions. We propose a novel\ncomputational pipeline to embed cardiac anatomies into full-field surrogate\nmodels. We generate a dataset of electrophysiology simulations using a complex\nmulti-scale mathematical model coupling partial and ordinary differential\nequations. We adopt Branched Latent Neural Maps (BLNMs) as an effective\nscientific machine learning method to encode activation maps extracted from\nphysics-based numerical simulations into a neural network. Leveraging large\ndeformation diffeomorphic metric mappings, we build a biventricular anatomical\natlas and parametrize the anatomical variability of a small and challenging\ncohort of 13 pediatric patients affected by Tetralogy of Fallot. We propose a\nnovel statistical shape modeling based z-score sampling approach to generate a\nnew synthetic cohort of 52 biventricular geometries that are compatible with\nthe original geometrical variability. This synthetic cohort acts as the\ntraining set for BLNMs. Our surrogate model demonstrates robustness and great\ngeneralization across the complex original patient cohort, achieving an average\nadimensional mean squared error of 0.0034. The Python implementation of our\nBLNM model is publicly available under MIT License at\nhttps://github.com/StanfordCBCL/BLNM.","main_category":"eess.IV","categories":"eess.IV,cs.LG","published":"2025-04-29T07:22:06Z"}
{"aid":"http://arxiv.org/abs/2504.20483v1","title":"Merger-Driven Turbulence and Coherent Transport in the Intracluster\n  Medium","summary":"The distribution of metals and temperature in the intracluster medium (ICM)\nprovides key insights into galaxy cluster evolution, revealing information\nabout chemical enrichment and heating and cooling processes, respectively. To\naccess this information, it is crucial to understand the transport processes in\nthe ICM. Here, we systematically study the transport mechanisms in the ICM with\ntracer particle resimulations of the Omega500 cosmological hydrosimulation,\nusing a sample of four galaxy clusters of comparable masses but different mass\nassembly histories. Through the analysis of particle pair dispersion\nstatistics, we find a time-dependent scaling index linked to the cluster's\ndynamical state. It reaches or exceeds Richardson scaling briefly during major\nmergers but remains much lower in relaxed clusters. We identify a coherent\ntransport mode during major mergers that causes directional flow in the ICM.\nAlthough coherent transport can move particles to outer regions, the particles\ntransported to the cluster outskirts compose only a small fraction of the\ndensity there; thus the anisotropy it creates in the overall density\ndistribution is limited. Moreover, strong turbulence generated by mergers\nquickly disperses these particles, further limiting this effect. We also\nprovide useful statistics on the radial evolution of the ICM and the fraction\nof particles that ever reached the inner regions as a function of radius. Our\nresults show that major mergers primarily drive particle transport, linking ICM\ntransport to merger-driven dynamics, and highlighting the interplay between\ncoherent and turbulent transport.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-04-29T07:23:29Z"}
{"aid":"http://arxiv.org/abs/2504.20488v1","title":"Scaling and shape of financial returns distributions modeled as\n  conditionally independent random variables","summary":"We show that assuming that the returns are independent when conditioned on\nthe value of their variance (volatility), which itself varies in time randomly,\nthen the distribution of returns is well described by the statistics of the sum\nof conditionally independent random variables. In particular, we show that the\ndistribution of returns can be cast in a simple scaling form, and that its\nfunctional form is directly related to the distribution of the volatilities.\nThis approach explains the presence of power-law tails in the returns as a\ndirect consequence of the presence of a power law tail in the distribution of\nvolatilities. It also provides the form of the distribution of Bitcoin returns,\nwhich behaves as a stretched exponential, as a consequence of the fact that the\nBitcoin volatilities distribution is also closely described by a stretched\nexponential. We test our predictions with data from the S\\&P 500 index, Apple\nand Paramount stocks; and Bitcoin.","main_category":"q-fin.ST","categories":"q-fin.ST,stat.AP","published":"2025-04-29T07:26:20Z"}
{"aid":"http://arxiv.org/abs/2504.20518v1","title":"Dynamic Attention Analysis for Backdoor Detection in Text-to-Image\n  Diffusion Models","summary":"Recent studies have revealed that text-to-image diffusion models are\nvulnerable to backdoor attacks, where attackers implant stealthy textual\ntriggers to manipulate model outputs. Previous backdoor detection methods\nprimarily focus on the static features of backdoor samples. However, a vital\nproperty of diffusion models is their inherent dynamism. This study introduces\na novel backdoor detection perspective named Dynamic Attention Analysis (DAA),\nshowing that these dynamic characteristics serve as better indicators for\nbackdoor detection. Specifically, by examining the dynamic evolution of\ncross-attention maps, we observe that backdoor samples exhibit distinct feature\nevolution patterns at the $<$EOS$>$ token compared to benign samples. To\nquantify these dynamic anomalies, we first introduce DAA-I, which treats the\ntokens' attention maps as spatially independent and measures dynamic feature\nusing the Frobenius norm. Furthermore, to better capture the interactions\nbetween attention maps and refine the feature, we propose a dynamical\nsystem-based approach, referred to as DAA-S. This model formulates the spatial\ncorrelations among attention maps using a graph-based state equation and we\ntheoretically analyze the global asymptotic stability of this method. Extensive\nexperiments across five representative backdoor attack scenarios demonstrate\nthat our approach significantly surpasses existing detection methods, achieving\nan average F1 Score of 79.49% and an AUC of 87.67%. The code is available at\nhttps://github.com/Robin-WZQ/DAA.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T07:59:35Z"}
{"aid":"http://arxiv.org/abs/2504.20597v1","title":"How to be an orthodox quantum mechanic","summary":"This work sets out to answer a single question: what is the orthodox\ninterpretation of quantum mechanics? However, we adopt a different approach to\nthat normally used. Rather than carefully surveying the precise details of the\nthoughts of Bohr and Heisenberg, we extract an orthodoxy empirically. To do\nthis we review a collection of 33 textbooks on quantum mechanics, encompassing\nthe most popular and prominent works of this nature. We then gauge their\nresponse to 12 propositions to build up a picture of exactly what is believed\nby an orthodox quantum mechanic. We demonstrate that this orthodoxy is largely\nunchanged over the past century, with some interesting emerging deviations, and\nhas many aspects of Copenhagen-like viewpoints. However, it is more nuanced\nthan some reductive characterisations that condense it down to the ontological\nprimacy of the quantum state. The revealed orthodoxy has two main pillars:\nmeasurement inherently disturbs quantum states and these states refer to\nindividual instances, not ensembles. More fully it entails that individual\nparticles exist in wave-like super-positions and present particle behaviours\nonly when forced to by outside influences. The act of measuring such a system\ninherently changes its state in a random fashion, manifesting in a form of\nmeasurement error that corresponds to the uncertainty principle. This implies\nthat measurement does not reveal underlying values of quantum properties.","main_category":"quant-ph","categories":"quant-ph,physics.hist-ph","published":"2025-04-29T09:50:54Z"}
{"aid":"http://arxiv.org/abs/2504.20600v1","title":"A citation index bridging Hirsch's h and Egghe's g","summary":"We propose a citation index $\\nu$ (``nu'') and show that it lies between the\nclassical $h$-index and $g$-index. This idea is then generalized to a monotone\nparametric family $(\\nu_\\alpha)$ ($\\alpha\\ge 0$), whereby $h=\\nu_0$ and\n$\\nu=\\nu_1$, while the limiting value $\\nu_\\infty$ is expressed in terms of the\nmaximum citation.","main_category":"cs.DL","categories":"cs.DL","published":"2025-04-29T10:01:38Z"}
{"aid":"http://arxiv.org/abs/2504.20623v1","title":"Cell-free Fluid Antenna Multiple Access Networks","summary":"Fluid antenna enables position reconfigurability that gives transceiver\naccess to a high-resolution spatial signal and the ability to avoid\ninterference through the ups and downs of fading channels. Previous studies\ninvestigated this fluid antenna multiple access (FAMA) approach in a\nsingle-cell setup only. In this paper, we consider a cell-free network\narchitecture in which users are associated with the nearest base stations (BSs)\nand all users share the same physical channel. Each BS has multiple fixed\nantennas that employ maximum ratio transmission (MRT) to beam to its associated\nusers while each user relies on its fluid antenna system (FAS) on one radio\nfrequency (RF) chain to overcome the inter-user interference. Our aim is to\nanalyze the outage probability performance of such cell-free FAMA network when\nboth large- and small-scale fading effects are considered. To do so, we derive\nthe distribution of the received \\textcolor{black}{magnitude} for a typical\nuser and then the interference distribution under both fast and slow port\nswitching techniques. The outage probability is finally obtained in integral\nform in each case. Numerical results demonstrate that in an\ninterference-limited situation, although fast port switching is typically\nunderstood as the superior method for FAMA, slow port switching emerges as a\nmore effective solution when there is a large antenna array at the BS.\nMoreover, it is revealed that FAS at each user can serve to greatly reduce the\nburden of BS in terms of both antenna costs and CSI estimation overhead,\nthereby enhancing the scalability of cell-free networks.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-29T10:50:10Z"}
{"aid":"http://arxiv.org/abs/2504.20633v1","title":"Collapse of molecular orbital by ultrahigh magnetic fields in\n  V$_6$O$_{13}$","summary":"V$_6$O$_{13}$ exhibits the metal-insulator transition (MIT) with\nvanadium-vanadium (V-V) dimer formation. The magnetostriction of V$_6$O$_{13}$\nalong the crystallographic $b$-axis has been measured in ultrahigh magnetic\nfields up to 186 T at several temperatures in this work. The large negative\nmagnetostriction as large as $\\Delta L / L \\sim10^{-3}$ was observed above 110\nT below the transition temperature. Discussion based on experimental results\nand the physical property of V$_6$O$_{13}$ suggests that the observed large\nnegative magnetostriction corresponds to the collapse of V-V dimer molecular\norbital (MO). This is the first case for direct observation of lattice change\noriginating from the magnetic field-induced collapse of V-V dimer MO in\nvanadium oxides. In addition, the $B$-$T$ phase diagram and the magnitude of\nmagnetostriction indicate that the collapse of V-V dimer MO probably\naccompanies the insulator-to-metal transition. A large hysteresis that is\nlarger than 50 T was observed, which probably arises from the non-equilibrated\ncross-correlation of such degrees of freedom as the charge, spin, and lattice.\nComparison with the VO$_2$ case suggests the magnetic entropy of the remanent\nparamagnetic spins in the insulating phase may play an important role for the\nMIT in V$_6$O$_{13}$.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-29T11:01:35Z"}
{"aid":"http://arxiv.org/abs/2504.20635v1","title":"Bridging the Generalisation Gap: Synthetic Data Generation for\n  Multi-Site Clinical Model Validation","summary":"Ensuring the generalisability of clinical machine learning (ML) models across\ndiverse healthcare settings remains a significant challenge due to variability\nin patient demographics, disease prevalence, and institutional practices.\nExisting model evaluation approaches often rely on real-world datasets, which\nare limited in availability, embed confounding biases, and lack the flexibility\nneeded for systematic experimentation. Furthermore, while generative models aim\nfor statistical realism, they often lack transparency and explicit control over\nfactors driving distributional shifts. In this work, we propose a novel\nstructured synthetic data framework designed for the controlled benchmarking of\nmodel robustness, fairness, and generalisability. Unlike approaches focused\nsolely on mimicking observed data, our framework provides explicit control over\nthe data generating process, including site-specific prevalence variations,\nhierarchical subgroup effects, and structured feature interactions. This\nenables targeted investigation into how models respond to specific\ndistributional shifts and potential biases. Through controlled experiments, we\ndemonstrate the framework's ability to isolate the impact of site variations,\nsupport fairness-aware audits, and reveal generalisation failures, particularly\nhighlighting how model complexity interacts with site-specific effects. This\nwork contributes a reproducible, interpretable, and configurable tool designed\nto advance the reliable deployment of ML in clinical settings.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-29T11:04:28Z"}
{"aid":"http://arxiv.org/abs/2504.20649v1","title":"Short-time quantum Fourier transform processing","summary":"Algorithms for processing data in short-time batches are critical for both\nonline and offline processing of streamed and large data respectively due to\nthe quadratic relation between signal length and computational cost of\nconvolution-based processing schemes. Whilst quantum analogs to some digital\nsignal processing algorithms have been discovered, including the quantum\nFourier transform (QFT), there has been no development of short-time processing\ntechniques in the quantum domain. In this manuscript, we introduce the\nshort-time QFT (STQFT) processing technique to bridge this gap in research. We\ndevelop a novel overlap-add reconstruction technique in the quantum domain\nusing a permutation gate to combine subsequent windows. With this in mind, we\ndiscuss convolution under our novel STQFT processing scheme. We demonstrate\nfiltering in the quantum Fourier domain with a filter stored in a quantum\nregister as well as in a block encoded unitary gate. Throughout the paper, we\nelaborate upon implementation details such as applying DC offsets to input\nsignals, skipping input data frames whenever necessary, the use of overlap-save\nas a reconstruction technique and mitigating time-varying scaling due to\nnormalization of the windowed input data and filters.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-29T11:19:51Z"}
{"aid":"http://arxiv.org/abs/2504.20673v1","title":"CoCo-Bench: A Comprehensive Code Benchmark For Multi-task Large Language\n  Model Evaluation","summary":"Large language models (LLMs) play a crucial role in software engineering,\nexcelling in tasks like code generation and maintenance. However, existing\nbenchmarks are often narrow in scope, focusing on a specific task and lack a\ncomprehensive evaluation framework that reflects real-world applications. To\naddress these gaps, we introduce CoCo-Bench (Comprehensive Code Benchmark),\ndesigned to evaluate LLMs across four critical dimensions: code understanding,\ncode generation, code modification, and code review. These dimensions capture\nessential developer needs, ensuring a more systematic and representative\nevaluation. CoCo-Bench includes multiple programming languages and varying task\ndifficulties, with rigorous manual review to ensure data quality and accuracy.\nEmpirical results show that CoCo-Bench aligns with existing benchmarks while\nuncovering significant variations in model performance, effectively\nhighlighting strengths and weaknesses. By offering a holistic and objective\nevaluation, CoCo-Bench provides valuable insights to guide future research and\ntechnological advancements in code-oriented LLMs, establishing a reliable\nbenchmark for the field.","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-29T11:57:23Z"}
{"aid":"http://arxiv.org/abs/2504.20674v1","title":"DiffLiB: High-fidelity differentiable modeling of lithium-ion batteries\n  and efficient gradient-based parameter identification","summary":"The physics-based Doyle-Fuller-Newman (DFN) model, widely adopted for its\nprecise electrochemical modeling, stands out among various simulation models of\nlithium-ion batteries (LIBs). Although the DFN model is powerful in forward\npredictive analysis, the inverse identification of its model parameters has\nremained a long-standing challenge. The numerous unknown parameters associated\nwith the nonlinear, time-dependent, and multi-scale DFN model are extremely\ndifficult to be determined accurately and efficiently, hindering the practical\nuse of such battery simulation models in industrial applications. To tackle\nthis challenge, we introduce DiffLiB, a high-fidelity finite-element-based LIB\nsimulation framework, equipped with advanced differentiable programming\ntechniques so that efficient gradient-based inverse parameter identification is\nenabled. Customized automatic differentiation rules are defined by identifying\nthe VJP (vector-Jacobian product) structure in the chain rule and implemented\nusing adjoint-based implicit differentiation methods. Four numerical examples,\nincluding both 2D and 3D forward predictions and inverse parameter\nidentification, are presented to validate the accuracy and computational\nefficiency of DiffLiB. Benchmarking against COMSOL demonstrates excellent\nagreement in forward predictions, with terminal voltage discrepancies\nmaintaining a root-mean-square error (RMSE) below 2 mV across all test\nconditions. In parameter identification tasks using experimentally measured\nvoltage data, the proposed gradient-based optimization scheme achieves superior\ncomputational performance, with 96% fewer forward predictions and 72% less\ncomputational time compared with gradient-free approaches. These results\ndemonstrate that DiffLiB is a versatile and powerful computational framework\nfor the development of advanced LIBs.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-29T11:57:51Z"}
{"aid":"http://arxiv.org/abs/2504.20754v1","title":"DDPS: Discrete Diffusion Posterior Sampling for Paths in Layered Graphs","summary":"Diffusion models form an important class of generative models today,\naccounting for much of the state of the art in cutting edge AI research. While\nnumerous extensions beyond image and video generation exist, few of such\napproaches address the issue of explicit constraints in the samples generated.\nIn this paper, we study the problem of generating paths in a layered graph (a\nvariant of a directed acyclic graph) using discrete diffusion models, while\nguaranteeing that our generated samples are indeed paths. Our approach utilizes\na simple yet effective representation for paths which we call the padded\nadjacency-list matrix (PALM). In addition, we show how to effectively perform\nclassifier guidance, which helps steer the sampled paths to specific preferred\nedges without any retraining of the diffusion model. Our preliminary results\nshow that empirically, our method outperforms alternatives which do not\nexplicitly account for path constraints.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-29T13:34:17Z"}
{"aid":"http://arxiv.org/abs/2504.20771v1","title":"Turing Machine Evaluation for Large Language Model","summary":"With the rapid development and widespread application of Large Language\nModels (LLMs), rigorous evaluation has become particularly crucial. This\nresearch adopts a novel perspective, focusing on evaluating the core\ncomputational reasoning ability of LLMs, defined as the capacity of model to\naccurately understand rules, and execute logically computing operations. This\ncapability assesses the reliability of LLMs as precise executors, and is\ncritical to advanced tasks such as complex code generation and multi-step\nproblem-solving. We propose an evaluation framework based on Universal Turing\nMachine (UTM) simulation. This framework requires LLMs to strictly follow\ninstructions and track dynamic states, such as tape content and read/write head\nposition, during multi-step computations. To enable standardized evaluation, we\ndeveloped TMBench, a benchmark for systematically studying the computational\nreasoning capabilities of LLMs. TMBench provides several key advantages,\nincluding knowledge-agnostic evaluation, adjustable difficulty, foundational\ncoverage through Turing machine encoding, and unlimited capacity for instance\ngeneration, ensuring scalability as models continue to evolve. We find that\nmodel performance on TMBench correlates strongly with performance on other\nrecognized reasoning benchmarks (Pearson correlation coefficient is 0.73),\nclearly demonstrating that computational reasoning is a significant dimension\nfor measuring the deep capabilities of LLMs. Code and data are available at\nhttps://github.com/HaitaoWuTJU/Turing-Machine-Bench.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-29T13:52:47Z"}
{"aid":"http://arxiv.org/abs/2504.20792v1","title":"RecGaze: The First Eye Tracking and User Interaction Dataset for\n  Carousel Interfaces","summary":"Carousel interfaces are widely used in e-commerce and streaming services, but\nlittle research has been devoted to them. Previous studies of interfaces for\npresenting search and recommendation results have focused on single ranked\nlists, but it appears their results cannot be extrapolated to carousels due to\nthe added complexity. Eye tracking is a highly informative approach to\nunderstanding how users click, yet there are no eye tracking studies concerning\ncarousels. There are very few interaction datasets on recommenders with\ncarousel interfaces and none that contain gaze data.\n  We introduce the RecGaze dataset: the first comprehensive feedback dataset on\ncarousels that includes eye tracking results, clicks, cursor movements, and\nselection explanations. The dataset comprises of interactions from 3 movie\nselection tasks with 40 different carousel interfaces per user. In total, 87\nusers and 3,477 interactions are logged. In addition to the dataset, its\ndescription and possible use cases, we provide results of a survey on carousel\ndesign and the first analysis of gaze data on carousels, which reveals a golden\ntriangle or F-pattern browsing behavior.\n  Our work seeks to advance the field of carousel interfaces by providing the\nfirst dataset with eye tracking results on carousels. In this manner, we\nprovide and encourage an empirical understanding of interactions with carousel\ninterfaces, for building better recommender systems through gaze information,\nand also encourage the development of gaze-based recommenders.","main_category":"cs.IR","categories":"cs.IR,cs.HC","published":"2025-04-29T14:09:20Z"}
{"aid":"http://arxiv.org/abs/2504.20803v1","title":"Continuation maps for the Morse fundamental group","summary":"We study properties of the continuation map for the Morse fundamental group\n$\\pi_1^\\text{Morse}(f,\\ast)$ associated to a Morse-Smale pair $(f,g)$ on a\nmanifold $M$. We get a morphism between $\\pi_1^\\text{Morse}(f_1,\\ast_1)$ and\n$\\pi_1^\\text{Morse}(f_2,\\ast_2)$ and show that it is functorial. We also define\nthe morphism in the case of Morse data over different manifolds, thanks to the\nuse of grafted trajectories. Finally, given an interpolation function on\n$M\\times\\mathbb{R}$ between two Morse functions (used for example to define the\ncontinuation map), we study the Morse fundamental group associated to that\nfunction and show that it is isomorphic to a relative fundamental group on\n$M\\times\\mathbb{R}$.","main_category":"math.GT","categories":"math.GT,math.DG,math.SG","published":"2025-04-29T14:15:53Z"}
{"aid":"http://arxiv.org/abs/2504.20836v1","title":"Non-Linear Modeling and Analysis of Amplifier-Less Potentiostat\n  Architectures","summary":"In this article, a previously published amplifier-less potentiostat\narchitecture is further examined. Starting with a linearized model, the impact\nof the most important parameters is studied taking in account the\nelectrodes-solution electrochemical interface. A detailed model is obtained and\nthoroughly verified, and recommended operating conditions are given for certain\nlimit load conditions. Then, a more complete non-linear model is developed to\ntake in account the measurement uncertainty introduced by the circuit\nnon-linear components. This non-linear model is compared to a time domain\ndescription of the circuit and it is verified that it can predict the\nnon-linear behavior with a precision better than 20%. This result enables the\ncircuit designers to compensate for these effects and ultimately reduce the\noverall measurement uncertainty.","main_category":"eess.SY","categories":"eess.SY,cs.SY,94-06","published":"2025-04-29T14:59:50Z"}
{"aid":"http://arxiv.org/abs/2504.20840v1","title":"Thermal Resilience of Suspended Thin-Film Lithium Niobate Acoustic\n  Resonators up to 550 Â°C","summary":"This paper reports a suspended thin-film lithium niobate (LN) piezoelectric\nresonator platform surviving high annealing temperatures of 550 {\\deg}C, among\nthe highest temperature at which the thermal resilience of suspended LN\nresonators is studied. Acoustic resonators are built on 600 nm thick\ntransferred stoichiometric LN on silicon wafers with 40 nm thick platinum (Pt)\nelectrodes, selected for high temperature operation. The fabricated resonators\nare first annealed at 250 {\\deg}C, and the anneal temperature is incrementally\nincreased to 550 {\\deg}C after 7 rounds of annealing. The annealing is shown to\nupshift resonant frequencies and can increase the quality factor (Q), within a\ntemperature range, before it gradually damages the device performance. This\nwork presents promising results for using the suspended thin-film LN platform\nfor resonators, sensors, and transducers in harsh thermal environments.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-29T15:05:21Z"}
{"aid":"http://arxiv.org/abs/2504.20842v1","title":"Language Model for Large-Text Transmission in Noisy Quantum\n  Communications","summary":"Quantum communication has the potential to revolutionize information\nprocessing, providing unparalleled security and increased capacity compared to\nits classical counterpart by using the principles of quantum mechanics.\nHowever, the presence of noise remains a major barrier to realizing these\nadvantages. While strategies like quantum error correction and mitigation have\nbeen developed to address this challenge, they often come with substantial\noverhead in physical qubits or sample complexity, limiting their practicality\nfor large-scale information transfer. Here, we present an alternative approach:\napplying machine learning frameworks from natural language processing to\nenhance the performance of noisy quantum communications, focusing on superdense\ncoding. By employing bidirectional encoder representations from transformers\n(BERT), a model known for its capabilities in natural language processing, we\ndemonstrate improvements in information transfer efficiency without resorting\nto conventional error correction or mitigation techniques. These results mark a\nstep toward the practical realization of a scalable and resilient quantum\ninternet.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-29T15:11:35Z"}
{"aid":"http://arxiv.org/abs/2504.20843v1","title":"A nuclear mass model rooted in chiral effective field theory","summary":"We develop a nuclear mass model that is based on chiral effective field\ntheory at next-to-next-to leading order. Nuclear binding energies are computed\nvia the Hartree-Fock method using a Hamiltonian from delta-full chiral\neffective field theory. We employ Hartree-Fock emulators to adjust $11$\nlow-energy constants in the chiral interaction to binding energies of $18$\neven-even nuclei. When applied to $107$ even-even nuclei with mass numbers\n$16\\leq A\\leq 56$ the chiral mass model exhibits an overall root-mean-square\ndeviation of $3.5$ MeV.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-29T15:13:19Z"}
{"aid":"http://arxiv.org/abs/2504.20850v1","title":"Nuclear Dimension for Virtually Abelian Groups","summary":"Let $G$ be a finitely generated virtually abelian group. We show that the\nHirsch length, $h(G)$, is equal to the nuclear dimension of its group\n$C^*$-algebra, $\\dim_{nuc}(C^*(G))$. We then specialize our attention to a\ngeneralization of crystallographic groups dubbed $\\textit{crystal-like}$. We\ndemonstrate that in this scenario a $\\textit{point group}$ is well defined and\nthe order of this point group is preserved by $C^*$-isomorphism. In addition,\nwe provide a counter-example to $C^*$-superrigidity within this crystal-like\nsetting.","main_category":"math.OA","categories":"math.OA,math.GR,math.RT","published":"2025-04-29T15:19:25Z"}
{"aid":"http://arxiv.org/abs/2504.20871v1","title":"Fluctuating magnetism in Zn-doped averievite with well-separated kagome\n  layers","summary":"Kagome lattice decorated with S=1/2 spins is one of the most discussed ways\nto realize a quantum spin liquid. However, all previous material realizations\nof this model have suffered from additional complications, ranging from\nadditional interactions to impurity effects. Recently, a new quantum kagome\nsystem has been identified in the form of averievite Cu(5-x)ZnxV2O10(CsCl),\nfeaturing a unique double-layer spacing between the kagome planes. Using muon\nspin spectroscopy we show that only a complete substitution (i.e. $x=2$) of\ninterplanar copper ions leads to a quantum-disordered ground state. In\ncontrast, the parent compound ($x=0$) exhibits long-range magnetic order, with\na phase transition around 24 K. Experiments performed on the partially\nsubstituted material ($x=1$) show that the transformation proceeds through an\nintermediate disordered, partially frozen ground state, unaffected by pressures\nup to 23 kbar. Our study provides a microscopic view of the magnetism of the\ndecoupling of the kagome layers and establishes the averievite as a new\nmaterial platform for the experimental study of the fully-decoupled kagome\nlayers.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-29T15:43:50Z"}
{"aid":"http://arxiv.org/abs/2504.20882v1","title":"Barotropic Equation of State and Nonlinear Electrodynamics in Dynamical\n  Black Hole Spacetimes","summary":"Models of black holes that differ from idealized vacuum and electrovacuum\nsolutions of Einstein's equations often contain parameters whose physical\ninterpretation is unclear. However, to propose a black hole model for\nexperimental verification, we must clearly understand which parameters describe\nthe black hole and what physical constraints can be imposed on each parameter.\nWhen considering dynamical black holes with a barotropic equation of state, an\nadditional integration constant arises, the nature of which remains unclear\nexcept for a few specific values of the equation of state coefficient.\nNevertheless, when examining solutions such as Husain or Kiselev, we can\nobserve remarkable effects related to black hole evaporation, which are\nassociated with the violation of null energy conditions. However, the main\nissue lies in the fact that while violations of energy conditions may occur in\nnature, the ambiguity in the values of parameters describing black holes makes\nit difficult to determine whether such violations result from natural physical\nprocesses or are purely mathematical artifacts that should be excluded from\nconsideration. Moreover, energy conditions play a crucial role in the evolution\nof a black hole shadow - a characteristic that can potentially be observed\nexperimentally. In this article, we elucidate the parameter arising in Husain's\nand Kiselev's solutions using nonlinear electrodynamics. We demonstrate that\nfor physically relevant equations of state, the additional parameter represents\na combination of electric and magnetic charges.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-29T15:53:44Z"}
{"aid":"http://arxiv.org/abs/2504.20886v1","title":"Mapping a Movement: Exploring a Proposed Police Training Facility in\n  Atlanta and the Stop Cop City Movement through Online Maps","summary":"In 2021, the City of Atlanta and Atlanta Police Foundation launched plans to\nbuild a large police training facility in the South River Forest in\nunincorporated DeKalb County, GA. Residents of Atlanta and DeKalb County,\nenvironmental activists, police and prison abolitionists, and other activists\nand concerned individuals formed the movement in opposition to the facility,\nknown as the Stop Cop City / Defend the Atlanta Forest movement. Social media\nand digital maps became common tools for communicating information about the\nfacility and the movement. Here, we examine online maps about the facility and\nthe opposition movement, originating from grassroots organizations, the City of\nAtlanta, news media outlets, the Atlanta Police Foundation, and individuals. We\ngather and examine 32 publicly available maps collected through the Google\nSearch API, Twitter (now X), Instagram and reddit. Using a framework of\ncritical cartography, we conduct a content analysis of these maps to identify\nthe mapping technologies and techniques (data, cartographic elements, styles)\nused by different stakeholders and roles that maps and mapping technologies can\nplay in social movements. We examine the extent to which these maps provide\ndata to confirm or contradict concerns raised by grassroots organizations and\nlocal residents about the facility. We find that stakeholders and mapmakers use\ngeospatial tools in different ways and likely have varied access to mapping\ntechnologies. We argue that documenting the use of maps to communicate\ninformation about a contentious project can help enumerate community positions\nand perspectives, and we advocate for accessible mapmaking tools. We conclude\nby discussing the implications of accessibility of mapping technology and\nposting maps to social media, and share example map images that extend the\ngeographic information systems (GIS) techniques seen in the retrieved maps.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-29T16:01:51Z"}
{"aid":"http://arxiv.org/abs/2504.20888v1","title":"New Capacity Bounds for PIR on Graph and Multigraph-Based Replicated\n  Storage","summary":"In this paper, we study the problem of private information retrieval (PIR) in\nboth graph-based and multigraph-based replication systems, where each file is\nstored on exactly two servers, and any pair of servers shares at most $r$\nfiles. We derive upper bounds on the PIR capacity for such systems and\nconstruct PIR schemes that approach these bounds. For graph-based systems, we\ndetermine the exact PIR capacity for path graphs and improve upon existing\nresults for complete bipartite graphs and complete graphs. For multigraph-based\nsystems, we propose a PIR scheme that leverages the symmetry of the underlying\ngraph-based construction, yielding a capacity lower bound for such multigraphs.\nFurthermore, we establish several general upper and lower bounds on the PIR\ncapacity of multigraphs, which are tight in certain cases.","main_category":"cs.IT","categories":"cs.IT,cs.CR,math.CO,math.IT,H.3.3","published":"2025-04-29T16:05:42Z"}
{"aid":"http://arxiv.org/abs/2504.20889v1","title":"A Decision Diagram Approach for the Parallel Machine Scheduling Problem\n  with Chance Constraints","summary":"The Chance-Constrained Parallel Machine Scheduling Problem (CC-PMSP) assigns\njobs with uncertain processing times to machines, ensuring that each machine's\navailability constraints are met with a certain probability. We present a\ndecomposition approach where the master problem assigns jobs to machines, and\nthe subproblems schedule the jobs on each machine while verifying the\nsolution's feasibility under the chance constraint. We propose two different\nDecision Diagram (DD) formulations to solve the subproblems and generate cuts.\nThe first formulation employs DDs with a linear cost function, while the second\nuses a non-linear cost function to reduce the diagram's size. We show how to\ngenerate no-good and irreducible infeasible subsystem (IIS) cuts based on our\nDDs. Additionally, we extend the cuts proposed by Lozano & Smith (2018) to\nsolve two-stage stochastic programming models. Our DD-based methodology\noutperforms traditional integer programming (IP) models designed to solve the\nCC-PMSP in several instances. Specifically, our best DD-based approach solves\n55 more instances than the best IP alternative (from a total of 405) and\ntypically achieves smaller gaps (50% vs. 120% gap on average).","main_category":"math.OC","categories":"math.OC","published":"2025-04-29T16:07:01Z"}
{"aid":"http://arxiv.org/abs/2504.20906v1","title":"GiBy: A Giant-Step Baby-Step Classifier For Anomaly Detection In\n  Industrial Control Systems","summary":"The continuous monitoring of the interactions between cyber-physical\ncomponents of any industrial control system (ICS) is required to secure\nautomation of the system controls, and to guarantee plant processes are\nfail-safe and remain in an acceptably safe state. Safety is achieved by\nmanaging actuation (where electric signals are used to trigger physical\nmovement), dependent on corresponding sensor readings; used as ground truth in\ndecision making. Timely detection of anomalies (attacks, faults and\nunascertained states) in ICSs is crucial for the safe running of a plant, the\nsafety of its personnel, and for the safe provision of any services provided.\nWe propose an anomaly detection method that involves accurate linearization of\nthe non-linear forms arising from sensor-actuator(s) relationships, primarily\nbecause solving linear models is easier and well understood. Further, the time\ncomplexity of the anomaly detection scenario/problem at hand is lowered using\ndimensionality reduction of the actuator(s) in relationship with a sensor. We\naccomplish this by using a well-known water treatment testbed as a use case.\nOur experiments show millisecond time response to detect anomalies and provide\nexplainability; that are not simultaneously achieved by other state of the art\nAI/ML models with eXplainable AI (XAI) used for the same purpose. Further, we\npin-point the sensor(s) and its actuation state for which anomaly was detected.","main_category":"cs.CR","categories":"cs.CR,cs.LG","published":"2025-04-29T16:24:11Z"}
{"aid":"http://arxiv.org/abs/2504.20939v1","title":"Flexible Semantic-Aware Resource Allocation: Serving More Users Through\n  Similarity Range Constraints","summary":"Semantic communication (SemCom) aims to enhance the resource efficiency of\nnext-generation networks by transmitting the underlying meaning of messages,\nfocusing on information relevant to the end user. Existing literature on SemCom\nprimarily emphasizes learning the encoder and decoder through end-to-end deep\nlearning frameworks, with the objective of minimizing a task-specific semantic\nloss function. Beyond its influence on the physical and application layer\ndesign, semantic variability across users in multi-user systems enables the\ndesign of resource allocation schemes that incorporate user-specific semantic\nrequirements. To this end, \\emph{a semantic-aware resource allocation} scheme\nis proposed with the objective of maximizing transmission and semantic\nreliability, ultimately increasing the number of users whose semantic\nrequirements are met. The resulting resource allocation problem is a non-convex\nmixed-integer nonlinear program (MINLP), which is known to be NP-hard. To make\nthe problem tractable, it is decomposed into a set of sub-problems, each of\nwhich is efficiently solved via geometric programming techniques. Finally,\nsimulations demonstrate that the proposed method improves user satisfaction by\nup to $17.1\\%$ compared to state of the art methods based on quality of\nexperience-aware SemCom methods.","main_category":"cs.NI","categories":"cs.NI,eess.SP","published":"2025-04-29T17:04:48Z"}
{"aid":"http://arxiv.org/abs/2504.20954v1","title":"21 years of Astronomy at Warwick: celebrating the legacy of Prof. Tom\n  Marsh","summary":"Between the 4th and 6th of September 2024, the Astronomy & Astrophysics group\nat the University of Warwick held a meeting to celebrate 21 years of astronomy\nat Warwick and the scientific legacy of the late Prof. Tom Marsh, the group\nfounder. More than a hundred people attended the meeting, with about half of\nthe attendees being external delegates and coming from as far afield as the USA\nand South Africa. Tom Marsh moved to the University of Warwick from Southampton\nin 2003, after the Department of Physics decided to expand the scope of its\nresearch. From its humble beginnings with only two staff members, Tom himself\nand Boris G\\\"ansicke, one postdoc and a couple of PhD students, the group has\nnow grown to more than 95 members, including 25 staff. Tom pioneered the\ndevelopment of Doppler tomography, led key discoveries in the field of\ndouble-degenerate binary systems and made extensive contributions to\ninstrumentation, primarily to developing the high-speed imaging photometers\nULTRACAM, ULTRASPEC and HiPERCAM. This article provides a summary of Tom's\nlegacy and Warwick's history as presented in the 21 years of Astronomy at\nWarwick meeting.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP,astro-ph.IM","published":"2025-04-29T17:25:07Z"}
{"aid":"http://arxiv.org/abs/2504.20969v1","title":"XPG-RL: Reinforcement Learning with Explainable Priority Guidance for\n  Efficiency-Boosted Mechanical Search","summary":"Mechanical search (MS) in cluttered environments remains a significant\nchallenge for autonomous manipulators, requiring long-horizon planning and\nrobust state estimation under occlusions and partial observability. In this\nwork, we introduce XPG-RL, a reinforcement learning framework that enables\nagents to efficiently perform MS tasks through explainable, priority-guided\ndecision-making based on raw sensory inputs. XPG-RL integrates a task-driven\naction prioritization mechanism with a learned context-aware switching strategy\nthat dynamically selects from a discrete set of action primitives such as\ntarget grasping, occlusion removal, and viewpoint adjustment. Within this\nstrategy, a policy is optimized to output adaptive threshold values that govern\nthe discrete selection among action primitives. The perception module fuses\nRGB-D inputs with semantic and geometric features to produce a structured scene\nrepresentation for downstream decision-making. Extensive experiments in both\nsimulation and real-world settings demonstrate that XPG-RL consistently\noutperforms baseline methods in task success rates and motion efficiency,\nachieving up to 4.5$\\times$ higher efficiency in long-horizon tasks. These\nresults underscore the benefits of integrating domain knowledge with learnable\ndecision-making policies for robust and efficient robotic manipulation.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-29T17:37:45Z"}
{"aid":"http://arxiv.org/abs/2504.20970v1","title":"SVD Based Least Squares for X-Ray Pneumonia Classification Using Deep\n  Features","summary":"Accurate and early diagnosis of pneumonia through X-ray imaging is essential\nfor effective treatment and improved patient outcomes. Recent advancements in\nmachine learning have enabled automated diagnostic tools that assist\nradiologists in making more reliable and efficient decisions. In this work, we\npropose a Singular Value Decomposition-based Least Squares (SVD-LS) framework\nfor multi-class pneumonia classification, leveraging powerful feature\nrepresentations from state-of-the-art self-supervised and transfer learning\nmodels. Rather than relying on computationally expensive gradient based\nfine-tuning, we employ a closed-form, non-iterative classification approach\nthat ensures efficiency without compromising accuracy. Experimental results\ndemonstrate that SVD-LS achieves competitive performance while offering\nsignificantly reduced computational costs, making it a viable alternative for\nreal-time medical imaging applications.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-29T17:39:16Z"}
{"aid":"http://arxiv.org/abs/2504.20995v1","title":"TesserAct: Learning 4D Embodied World Models","summary":"This paper presents an effective approach for learning novel 4D embodied\nworld models, which predict the dynamic evolution of 3D scenes over time in\nresponse to an embodied agent's actions, providing both spatial and temporal\nconsistency. We propose to learn a 4D world model by training on RGB-DN (RGB,\nDepth, and Normal) videos. This not only surpasses traditional 2D models by\nincorporating detailed shape, configuration, and temporal changes into their\npredictions, but also allows us to effectively learn accurate inverse dynamic\nmodels for an embodied agent. Specifically, we first extend existing robotic\nmanipulation video datasets with depth and normal information leveraging\noff-the-shelf models. Next, we fine-tune a video generation model on this\nannotated dataset, which jointly predicts RGB-DN (RGB, Depth, and Normal) for\neach frame. We then present an algorithm to directly convert generated RGB,\nDepth, and Normal videos into a high-quality 4D scene of the world. Our method\nensures temporal and spatial coherence in 4D scene predictions from embodied\nscenarios, enables novel view synthesis for embodied environments, and\nfacilitates policy learning that significantly outperforms those derived from\nprior video-based world models.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-29T17:59:30Z"}
{"aid":"http://arxiv.org/abs/2504.21274v1","title":"Selmer ranks in twists of CM abelian varieties","summary":"We prove the distribution of Selmer ranks in the certain family of $p$-th\ntwists of CM abelian varieties obeys the symplectic distribution $\\sD_p^\\sym$\nor the unitary distribution $\\sD_{p^2}^\\uni$. As an application, for a prime\n$p\\geq 3$, we obtain that the twisted Fermat curve $X^p+Y^p=\\delta$ over a\nnumber field containing a primitive $p$-th root of unity is ``largely\"\nunsolvable as $\\delta$ varies.","main_category":"math.NT","categories":"math.NT","published":"2025-04-30T03:06:56Z"}
{"aid":"http://arxiv.org/abs/2504.21305v1","title":"Virtual Element Method Applied to Two Dimensional Axisymmetric Elastic\n  Problems","summary":"This work presents a Virtual Element Method (VEM) formulation tailored for\ntwo-dimensional axisymmetric problems in linear elasticity. By exploiting the\nrotational symmetry of the geometry and loading conditions, the problem is\nreduced to a meridional cross-section, where all fields depend only on the\nradial and axial coordinates. The method incorporates the radial weight $r$ in\nboth the weak formulation and the interpolation estimates to remain consistent\nwith the physical volume measure of cylindrical coordinates. A projection\noperator onto constant strain fields is constructed via boundary integrals, and\na volumetric correction term is introduced to account for the divergence of the\nstress field arising from axisymmetry. The stabilization term is designed to\nact only on the kernel of the projection and is implemented using a\nboundary-based formulation that guarantees stability without affecting\npolynomial consistency. Furthermore, an a priori interpolation error estimate\nis established in a weighted Sobolev space, showing optimal convergence rates.\nThe implementation is validated through patch tests that demonstrate the\naccuracy, consistency, and robustness of the proposed approach.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-30T04:26:50Z"}
{"aid":"http://arxiv.org/abs/2504.21317v1","title":"Redundancy Analysis and Mitigation for Machine Learning-Based Process\n  Monitoring of Additive Manufacturing","summary":"The deployment of machine learning (ML)-based process monitoring systems has\nsignificantly advanced additive manufacturing (AM) by enabling real-time defect\ndetection, quality assessment, and process optimization. However, redundancy is\na critical yet often overlooked challenge in the deployment and operation of\nML-based AM process monitoring systems. Excessive redundancy leads to increased\nequipment costs, compromised model performance, and high computational\nrequirements, posing barriers to industrial adoption. However, existing\nresearch lacks a unified definition of redundancy and a systematic framework\nfor its evaluation and mitigation. This paper defines redundancy in ML-based AM\nprocess monitoring and categorizes it into sample-level, feature-level, and\nmodel-level redundancy. A comprehensive multi-level redundancy mitigation\n(MLRM) framework is proposed, incorporating advanced methods such as data\nregistration, downscaling, cross-modality knowledge transfer, and model pruning\nto systematically reduce redundancy while improving model performance. The\nframework is validated through an ML-based in-situ defect detection case study\nfor directed energy deposition (DED), demonstrating a 91% reduction in latency,\na 47% decrease in error rate, and a 99.4% reduction in storage requirements.\nAdditionally, the proposed approach lowers sensor costs and energy consumption,\nenabling a lightweight, cost-effective, and scalable monitoring system. By\ndefining redundancy and introducing a structured mitigation framework, this\nstudy establishes redundancy analysis and mitigation as a key enabler of\nefficient ML-based process monitoring in production environments.","main_category":"cs.CE","categories":"cs.CE,cs.LG,eess.SP","published":"2025-04-30T05:04:53Z"}
{"aid":"http://arxiv.org/abs/2504.21329v1","title":"Drawing Reeb Graphs","summary":"Reeb graphs are simple topological descriptors which find applications in\nmany areas like topological data analysis and computational geometry. Despite\ntheir prevalence, visualization of Reeb graphs has received less attention. In\nthis paper, we bridge an essential gap in the literature by exploring the\ncomplexity of drawing Reeb graphs. Specifically, we demonstrate that Reeb graph\ncrossing number minimization is NP-hard, both for straight-line and curve\nrepresentations of edges. On the other hand, we identify specific classes of\nReeb graphs, namely paths and caterpillars, for which crossing-free drawings\nexist. We also give an optimal algorithm for drawing cycle-shaped Reeb graphs\nwith the least number of crossings and provide initial observations on the\ncomplexities of drawing multi-cycle Reeb graphs. We hope that this work\nestablishes the foundation for an understanding of the graph drawing challenges\ninherent in Reeb graph visualization and paves the way for future work in this\narea.","main_category":"cs.CG","categories":"cs.CG","published":"2025-04-30T05:35:04Z"}
{"aid":"http://arxiv.org/abs/2504.21336v1","title":"UniBiomed: A Universal Foundation Model for Grounded Biomedical Image\n  Interpretation","summary":"Multi-modal interpretation of biomedical images opens up novel opportunities\nin biomedical image analysis. Conventional AI approaches typically rely on\ndisjointed training, i.e., Large Language Models (LLMs) for clinical text\ngeneration and segmentation models for target extraction, which results in\ninflexible real-world deployment and a failure to leverage holistic biomedical\ninformation. To this end, we introduce UniBiomed, the first universal\nfoundation model for grounded biomedical image interpretation. UniBiomed is\nbased on a novel integration of Multi-modal Large Language Model (MLLM) and\nSegment Anything Model (SAM), which effectively unifies the generation of\nclinical texts and the segmentation of corresponding biomedical objects for\ngrounded interpretation. In this way, UniBiomed is capable of tackling a wide\nrange of biomedical tasks across ten diverse biomedical imaging modalities. To\ndevelop UniBiomed, we curate a large-scale dataset comprising over 27 million\ntriplets of images, annotations, and text descriptions across ten imaging\nmodalities. Extensive validation on 84 internal and external datasets\ndemonstrated that UniBiomed achieves state-of-the-art performance in\nsegmentation, disease recognition, region-aware diagnosis, visual question\nanswering, and report generation. Moreover, unlike previous models that rely on\nclinical experts to pre-diagnose images and manually craft precise textual or\nvisual prompts, UniBiomed can provide automated and end-to-end grounded\ninterpretation for biomedical image analysis. This represents a novel paradigm\nshift in clinical workflows, which will significantly improve diagnostic\nefficiency. In summary, UniBiomed represents a novel breakthrough in biomedical\nAI, unlocking powerful grounded interpretation capabilities for more accurate\nand efficient biomedical image analysis.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T05:51:48Z"}
{"aid":"http://arxiv.org/abs/2504.21342v1","title":"Low latency FPGA implementation of twisted Edward curve cryptography\n  hardware accelerator over prime field","summary":"The performance of any elliptic curve cryptography hardware accelerator\nsignificantly relies on the efficiency of the underlying point multiplication\n(PM) architecture. This article presents a hardware implementation of\nfield-programmable gate array (FPGA) based modular arithmetic, group operation,\nand point multiplication unit on the twisted Edwards curve (Edwards25519) over\nthe 256-bit prime field. An original hardware architecture of a unified point\noperation module in projective coordinates that executes point addition and\npoint doubling within a single module has been developed, taking only 646 clock\ncycles and ensuring a better security level than conventional approaches. The\nproposed point multiplication module consumes 1.4 ms time, operating at a\nmaximal clock frequency of 117.8 MHz utilising 164,730 clock cycles having\n183.38 kbps throughput on the Xilinx Virtex-5 FPGA platform for 256-bit length\nof key. The comparative assessment of latency and throughput across various\nrelated recent works indicates the effectiveness of our proposed PM\narchitecture. Finally, this high throughput and low latency PM architecture\nwill be a good candidate for rapid data encryption in high-speed wireless\ncommunication networks.","main_category":"cs.CR","categories":"cs.CR,cs.NI","published":"2025-04-30T06:03:36Z"}
{"aid":"http://arxiv.org/abs/2504.21346v1","title":"A microwave-activated high-fidelity three-qubit gate scheme for\n  fixed-frequency superconducting qubits","summary":"Scalable superconducting quantum processors require balancing critical\nconstraints in coherence, control complexity, and spectral crowding.\nFixed-frequency architectures suppress flux noise and simplify control via\nall-microwave operations but remain limited by residual ZZ crosstalk. Here we\npropose a microwave-activated three-qubit gate protocol for fixed-frequency\ntransmon qubits in the large-detuning regime ($|\\Delta| \\gg g$), leveraging the\nthird-order nonlinear interaction to coherently exchange $|001\\rangle\n\\leftrightarrow |110\\rangle$ states. By incorporating a phase-compensated\noptimization protocol, numerical simulations demonstrate a high average gate\nfidelity exceeding $99.9\\%$. Systematic error analysis identifies static\nlong-range ZZ coupling as the dominant error source in multi-qubit systems,\nwhich can be suppressed via operations in the large-detuning regime ($\\sim 1$\nGHz). This approach simultaneously enhances gate fidelity while preserving\nspectral isolation, ensuring compatibility with existing all-microwave\ncontrolled-Z gate frameworks. The protocol exhibits intrinsic robustness to\nfabrication-induced qubit parameter variations. This hardware-efficient\nstrategy advances scalable quantum computing systems by improving coherence\nproperties, reducing spectral congestion, and expanding the experimental\ntoolkit for error-resilient quantum operations in the noisy intermediate-scale\nquantum era.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-30T06:16:16Z"}
{"aid":"http://arxiv.org/abs/2504.21347v1","title":"IRL Dittos: Embodied Multimodal AI Agent Interactions in Open Spaces","summary":"We introduce the In Real Life (IRL) Ditto, an AI-driven embodied agent\ndesigned to represent remote colleagues in shared office spaces, creating\nopportunities for real-time exchanges even in their absence. IRL Ditto offers a\nunique hybrid experience by allowing in-person colleagues to encounter a\ndigital version of their remote teammates, initiating greetings, updates, or\nsmall talk as they might in person. Our research question examines: How can the\nIRL Ditto influence interactions and relationships among colleagues in a shared\noffice space? Through a four-day study, we assessed IRL Ditto's ability to\nstrengthen social ties by simulating presence and enabling meaningful\ninteractions across different levels of social familiarity. We find that\nenhancing social relationships depended deeply on the foundation of the\nrelationship participants had with the source of the IRL Ditto. This study\nprovides insights into the role of embodied agents in enriching workplace\ndynamics for distributed teams.","main_category":"cs.AI","categories":"cs.AI,cs.HC","published":"2025-04-30T06:16:32Z"}
{"aid":"http://arxiv.org/abs/2504.21363v1","title":"The differential structure shared by probability and moment matching\n  priors on non-regular statistical models via the Lie derivative","summary":"In Bayesian statistics, the selection of noninformative priors is a crucial\nissue. There have been various discussions on theoretical justification,\nproblems with the Jeffreys prior, and alternative objective priors. Among them,\nwe focus on two types of matching priors consistent with frequentist theory:\nthe probability matching priors and the moment matching priors. In particular,\nno clear relationship has been established between these two types of priors on\nnon-regular statistical models, even though they share similar objectives.\n  Considering information geometry on a one-sided truncated exponential family,\na typical example of non-regular statistical models, we find that the Lie\nderivative along a particular vector field provides the conditions for both the\nprobability and moment matching priors. Notably, this Lie derivative does not\nappear in regular models. These conditions require the invariance of a\ngeneralized volume element with respect to differentiation along the\nnon-regular parameter. This invariance leads to a suitable decomposition of the\none-sided truncated exponential family into one-dimensional submodels. This\nresult promotes a unified understanding of probability and moment matching\npriors on non-regular models.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-30T06:51:13Z"}
{"aid":"http://arxiv.org/abs/2504.21365v1","title":"Self-sustaining traveling fronts for a model related to bushfires","summary":"This article investigates a mathematical model for bushfire propagation,\nfocusing on the existence and properties of translating solutions. We obtain\nquantitative bounds on the environmental diffusion coefficient and ignition\nkernels, identifying conditions under which fires either propagate across the\nentire region or naturally extinguish.\n  Our analysis also reveals that vertically translating solutions do not exist,\nwhereas traveling wave solutions with a front moving at any prescribed velocity\nalways exist for kernels that are either of mild intensity or short range.\nThese traveling waves exhibit unbounded profiles.\n  Although evolutionary unstable, these traveling waves demonstrate stability\nunder perturbations localized in a small region.","main_category":"math.AP","categories":"math.AP","published":"2025-04-30T06:55:18Z"}
{"aid":"http://arxiv.org/abs/2504.21412v1","title":"On the Encapsulation of Medical Imaging AI Algorithms","summary":"In the context of collaborative AI research and development projects, it\nwould be ideal to have self-contained encapsulated algorithms that can be\neasily shared between different parties, executed and validated on data at\ndifferent sites, or trained in a federated manner. In practice, all of this is\npossible but greatly complicated, because human supervision and expert\nknowledge is needed to set up the execution of algorithms based on their\ndocumentation, possibly implicit assumptions, and knowledge about the execution\nenvironment and data involved.\n  We derive and formulate a range of detailed requirements from the above goal\nand from specific use cases, focusing on medical imaging AI algorithms.\nFurthermore, we refer to a number of existing APIs and implementations and\nreview which aspects each of them addresses, which problems are still open, and\nwhich public standards and ontologies may be relevant. Our contribution is a\ncomprehensive collection of aspects that have not yet been addressed in their\nentirety by any single solution.\n  Working towards the formulated goals should lead to more sustainable\nalgorithm ecosystems and relates to the FAIR principles for research data,\nwhere this paper focuses on interoperability and (re)usability of medical\nimaging AI algorithms.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-30T08:12:09Z"}
{"aid":"http://arxiv.org/abs/2504.21468v1","title":"Quaternion Nuclear Norms Over Frobenius Norms Minimization for Robust\n  Matrix Completion","summary":"Recovering hidden structures from incomplete or noisy data remains a\npervasive challenge across many fields, particularly where multi-dimensional\ndata representation is essential. Quaternion matrices, with their ability to\nnaturally model multi-dimensional data, offer a promising framework for this\nproblem. This paper introduces the quaternion nuclear norm over the Frobenius\nnorm (QNOF) as a novel nonconvex approximation for the rank of quaternion\nmatrices. QNOF is parameter-free and scale-invariant. Utilizing quaternion\nsingular value decomposition, we prove that solving the QNOF can be simplified\nto solving the singular value $L_1/L_2$ problem. Additionally, we extend the\nQNOF to robust quaternion matrix completion, employing the alternating\ndirection multiplier method to derive solutions that guarantee weak convergence\nunder mild conditions. Extensive numerical experiments validate the proposed\nmodel's superiority, consistently outperforming state-of-the-art quaternion\nmethods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T09:44:09Z"}
{"aid":"http://arxiv.org/abs/2504.21495v1","title":"Consistency-aware Fake Videos Detection on Short Video Platforms","summary":"This paper focuses to detect the fake news on the short video platforms.\nWhile significant research efforts have been devoted to this task with notable\nprogress in recent years, current detection accuracy remains suboptimal due to\nthe rapid evolution of content manipulation and generation technologies.\nExisting approaches typically employ a cross-modal fusion strategy that\ndirectly combines raw video data with metadata inputs before applying a\nclassification layer. However, our empirical observations reveal a critical\noversight: manipulated content frequently exhibits inter-modal inconsistencies\nthat could serve as valuable discriminative features, yet remain underutilized\nin contemporary detection frameworks. Motivated by this insight, we propose a\nnovel detection paradigm that explicitly identifies and leverages cross-modal\ncontradictions as discriminative cues. Our approach consists of two core\nmodules: Cross-modal Consistency Learning (CMCL) and Multi-modal Collaborative\nDiagnosis (MMCD). CMCL includes Pseudo-label Generation (PLG) and Cross-modal\nConsistency Diagnosis (CMCD). In PLG, a Multimodal Large Language Model is used\nto generate pseudo-labels for evaluating cross-modal semantic consistency.\nThen, CMCD extracts [CLS] tokens and computes cosine loss to quantify\ncross-modal inconsistencies. MMCD further integrates multimodal features\nthrough Multimodal Feature Fusion (MFF) and Probability Scores Fusion (PSF).\nMFF employs a co-attention mechanism to enhance semantic interactions across\ndifferent modalities, while a Transformer is utilized for comprehensive feature\nfusion. Meanwhile, PSF further integrates the fake news probability scores\nobtained in the previous step. Extensive experiments on established benchmarks\n(FakeSV and FakeTT) demonstrate our model exhibits outstanding performance in\nFake videos detection.","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-30T10:26:04Z"}
{"aid":"http://arxiv.org/abs/2504.21527v1","title":"Low-rank computation of the posterior mean in Multi-Output Gaussian\n  Processes","summary":"Gaussian processes (GP) are a versatile tool in machine learning and\ncomputational science. We here consider the case of multi-output Gaussian\nprocesses (MOGP) and present low-rank approaches for efficiently computing the\nposterior mean of a MOGP. Starting from low-rank spatio-temporal data we\nconsider a structured covariance function, assuming separability across space\nand time. This separability, in turn, gives a decomposition of the covariance\nmatrix into a Kronecker product of individual covariance matrices.\nIncorporating the typical noise term to the model then requires the solution of\na large-scale Stein equation for computing the posterior mean. For this, we\npropose efficient low-rank methods based on a combination of a LRPCG method\nwith the Sylvester equation solver KPIK adjusted for solving Stein equations.\nWe test the developed method on real world street network graphs by using graph\nfilters as covariance matrices. Moreover, we propose a degree-weighted average\ncovariance matrix, which can be employed under specific assumptions to achieve\nmore efficient convergence.","main_category":"math.NA","categories":"math.NA,cs.LG,cs.NA","published":"2025-04-30T11:19:58Z"}
{"aid":"http://arxiv.org/abs/2504.21537v1","title":"The role of dendritic spines in water exchange measurements with\n  diffusion MRI: Double Diffusion Encoding and free-waveform MRI","summary":"Time-dependent diffusion MRI enables the estimation of water exchange rates\nin vivo, yet reported values in grey matter remain inconsistent. While most\nstudies attribute these estimates to membrane permeability, non-permeative\ngeometric exchange has also been proposed. The present study investigates the\ncontribution of geometric exchange between dendritic spines and shafts to\ndiffusion MRI-derived exchange estimates. Monte Carlo simulations were\nperformed in synthetic dendrites with varying spine morphology, density, and\nmembrane permeability. Diffusion-weighted signals were generated using multiple\nprotocols - including single diffusion encoding, double diffusion encoding, and\nfree waveforms - and were analysed using four frameworks: the K\\\"arger model\n(via kurtosis time-dependence), correlation tensor imaging,\nRestriction-Exchange, and Multi-Gaussian Exchange with transient kurtosis\n(tMGE). Dendritic spines were found to impart similar time-dependence\nsignatures on the diffusion-weighted signal as permeative exchange (signal\ndecrease with diffusion time). The effect was modulated by both spine\nmorphology and density. Both the exchange rate and microscopic kurtosis\nincreased with spine density. The tMGE method demonstrated the ability to\ndisentangle geometric from permeative exchange. Non-permeative exchange in\ndendritic spines has a non-negligible impact on exchange estimates obtained\nwith diffusion MRI and should be considered in future studies. Diffusion MRI\nexchange estimates may provide a non-invasive proxy for dendritic spine\ndensity, with potential applications in studies of neurological disorders.","main_category":"physics.med-ph","categories":"physics.med-ph","published":"2025-04-30T11:34:44Z"}
{"aid":"http://arxiv.org/abs/2504.21548v1","title":"Leveraging Systems and Control Theory for Social Robotics: A Model-Based\n  Behavioral Control Approach to Human-Robot Interaction","summary":"Social robots (SRs) should autonomously interact with humans, while\nexhibiting proper social behaviors associated to their role. By contributing to\nhealth-care, education, and companionship, SRs will enhance life quality.\nHowever, personalization and sustaining user engagement remain a challenge for\nSRs, due to their limited understanding of human mental states. Accordingly, we\nleverage a recently introduced mathematical dynamic model of human perception,\ncognition, and decision-making for SRs. Identifying the parameters of this\nmodel and deploying it in behavioral steering system of SRs allows to\neffectively personalize the responses of SRs to evolving mental states of their\nusers, enhancing long-term engagement and personalization. Our approach\nuniquely enables autonomous adaptability of SRs by modeling the dynamics of\ninvisible mental states, significantly contributing to the transparency and\nawareness of SRs. We validated our model-based control system in experiments\nwith 10 participants who interacted with a Nao robot over three chess puzzle\nsessions, 45 - 90 minutes each. The identified model achieved a mean squared\nerror (MSE) of 0.067 (i.e., 1.675% of the maximum possible MSE) in tracking\nbeliefs, goals, and emotions of participants. Compared to a model-free\ncontroller that did not track mental states of participants, our approach\nincreased engagement by 16% on average. Post-interaction feedback of\nparticipants (provided via dedicated questionnaires) further confirmed the\nperceived engagement and awareness of the model-driven robot. These results\nhighlight the unique potential of model-based approaches and control theory in\nadvancing human-SR interactions.","main_category":"eess.SY","categories":"eess.SY,cs.RO,cs.SY","published":"2025-04-30T11:48:26Z"}
{"aid":"http://arxiv.org/abs/2504.21549v1","title":"Online Experimental Design for Network Tomography","summary":"How to efficiently perform network tomography is a fundamental problem in\nnetwork management and monitoring. A network tomography task usually consists\nof applying multiple probing experiments, e.g., across different paths or via\ndifferent casts (including unicast and multicast). We study how to optimize the\nnetwork tomography process through online sequential decision-making. From the\nmethodology perspective, we introduce an online probe allocation algorithm that\ndynamically performs network tomography based on the principles of optimal\nexperimental design and the maximum likelihood estimation. We rigorously\nanalyze the regret of the algorithm under the conditions that i) the optimal\nallocation is Lipschitz continuous in the parameters being estimated and ii)\nthe parameter estimators satisfy a concentration property. From the application\nperspective, we present two case studies: a) the classical lossy\npacket-switched network and b) the quantum bit-flip network. We show that both\ncases fulfill the two theoretical conditions and provide their corresponding\nregrets when deploying our proposed online probe allocation algorithm. Besides\nthese two case studies with theoretical guarantees, we also conduct simulations\nto compare our proposed algorithm with existing methods and demonstrate our\nalgorithm's effectiveness in a broader range of scenarios.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-30T11:48:49Z"}
{"aid":"http://arxiv.org/abs/2504.21557v1","title":"Optimizing carrier balance in CsPbBr3 nanocrystal LEDs: The role of\n  alkyl ligands and polar electron transport layers","summary":"The study of lead halide perovskite nanocrystal based light-emitting diodes\n(LEDs) has advanced significantly, with notable improvements in stability and\noptical properties. However, optimizing charge carrier injection and transport\nremains a challenge. Efficient electroluminescence requires a balanced\ntransport of both holes and electrons within the emitting material. Here, we\ninvestigate cubic CsPbBr\\textsubscript{3} nanocrystals passivated with\noleylamine and oleic acid, comparing them to ligand-exchanged nanocrystals with\ndidodecyldimethylammonium bromide (DDABr). Nuclear magnetic resonance\nspectroscopy and transmission electron microscopy confirm successful ligand\nexchange, revealing reduced ligand coverage in DDABr-treated nanocrystals.\nPhotoelectron spectroscopy, spectroelectrochemistry, and single-carrier devices\nindicate improved hole injection in DDABr-capped nanocrystals. Density\nfunctional theory calculations further reveal the influence of ligand type and\ncoverage on energy levels, with oleic acid introducing localized states in\nnative nanocrystals. Additionally, incorporation of a polar electron transport\nlayer (ETL) enhances LED performance by over an order of magnitude in\nDDABr-capped nanocrystals, driven by improved charge balance arising from the\nspontaneous orientation polarization (SOP) of the ETL. These findings highlight\nthe critical role of ligand selection, passivation degree, and charge transport\ncontrol by the adjacent organic transport layers in optimizing LED efficiency.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-30T11:54:43Z"}
{"aid":"http://arxiv.org/abs/2504.21597v1","title":"Optimizing the ground state energy of the three-dimensional magnetic\n  Dirichlet Laplacian with constant magnetic field","summary":"This paper concerns the shape optimization problem of minimizing the ground\nstate energy of the magnetic Dirichlet Laplacian with constant magnetic field\namong three-dimensional domains of fixed volume. In contrast to the\ntwo-dimensional case, a generalized ''magnetic'' Faber-Krahn inequality does\nnot hold and the minimizers are not expected to be balls when the magnetic\nfield is turned on. An analysis of the problem among cylindrical domains\nreveals geometric constraints for general minimizers. In particular, minimizers\nmust elongate with a certain rate along the direction of the magnetic field as\nthe field strength increases. In addition to the theoretical analysis, we\npresent numerical minimizers which confirm this prediction and give rise to\nfurther conjectures.","main_category":"math-ph","categories":"math-ph,math.AP,math.MP,math.OC,math.SP","published":"2025-04-30T12:55:14Z"}
{"aid":"http://arxiv.org/abs/2504.21608v1","title":"No Evidence of Anomalous Diffusion in Yukawa Crystals","summary":"Diffusion in Yukawa crystals is stochastic due to the thermally activated\nformation of vacancy-interstitial pairs, which have poor statistics in\nsimulations. This makes it difficult to argue if Yukawa crystals exhibit normal\ndiffusion, or if they could be subdiffusive or superdiffusive. To resolve this,\nwe run a long molecular dynamics simulation of an idealized Yukawa crystal for\na billion timesteps. We find no evidence of anomalous diffusion in the pure\ncrystal, but also caution readers against overinterpreting this result as real\ncrystals have complicated structures including grains and defects.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph,astro-ph.SR,cond-mat.mtrl-sci","published":"2025-04-30T13:08:01Z"}
{"aid":"http://arxiv.org/abs/2504.21632v1","title":"Fast Sign Retrieval via Sub-band Convolution: An Elementary Extension of\n  Binary Classification","summary":"To efficiently compress the sign information of images, we address a sign\nretrieval problem for the block-wise discrete cosine transformation~(DCT):\nreconstruction of the signs of DCT coefficients from their amplitudes. To this\nend, we propose a fast sign retrieval method on the basis of binary\nclassification machine learning. We first introduce 3D representations of the\namplitudes and signs, where we pack amplitudes/signs belonging to the same\nfrequency band into a 2D slice, referred to as the sub-band block. We then\nretrieve the signs from the 3D amplitudes via binary classification, where each\nsign is regarded as a binary label. We implement a binary classification\nalgorithm using convolutional neural networks, which are advantageous for\nefficiently extracting features in the 3D amplitudes. Experimental results\ndemonstrate that our method achieves accurate sign retrieval with an\noverwhelmingly low computation cost.","main_category":"cs.IT","categories":"cs.IT,eess.IV,math.IT","published":"2025-04-30T13:34:06Z"}
{"aid":"http://arxiv.org/abs/2504.21642v1","title":"Element-wise description of the $\\mathcal I$-characterized subgroups of\n  the circle","summary":"According to Cartan, given an ideal $\\mathcal I$ of $\\mathbb N$, a sequence\n$(x_n)_{n\\in\\mathbb N}$ in the circle group $\\mathbb T$ is said to {\\em\n$\\mathcal I$-converge} to a point $x\\in \\mathbb T$ if $\\{n\\in \\mathbb N: x_n\n\\not \\in U\\}\\in \\mathcal I$ for every neighborhood $U$ of $x$ in $\\mathbb T$.\nFor a sequence $\\mathbf u=(u_n)_{n\\in\\mathbb N}$ in $\\mathbb Z$, let\n$$t_{\\mathbf u}^\\mathcal I(\\mathbb T) :=\\{x\\in \\mathbb T: u_nx \\\n\\text{$\\mathcal I$-converges to}\\ 0 \\}.$$ This set is a Borel (hence,\nPolishable) subgroup of $\\mathbb T$ with many nice properties, largely studied\nin the case when $\\mathcal I = \\mathcal F in$ is the ideal of all finite\nsubsets of $\\mathbb N$ (so $\\mathcal F in$-convergence coincides with the usual\none) for its remarkable connection to topological algebra, descriptive set\ntheory and harmonic analysis. We give a complete element-wise description of\n$t_{\\mathbf u}^\\mathcal I(\\mathbb T)$ when $u_n\\mid u_{n+1}$ for every\n$n\\in\\mathbb N$ and under suitable hypotheses on $\\mathcal I$. In the special\ncase when $\\mathcal I =\\mathcal F in$, we obtain an alternative proof of a\nsimplified version of a known result.","main_category":"math.GN","categories":"math.GN,math.GR","published":"2025-04-30T13:46:01Z"}
{"aid":"http://arxiv.org/abs/2504.21649v1","title":"Spatio-temporal entanglement of the vacuum","summary":"We demonstrate that the future and left Rindler wedges of Minkowski spacetime\nare entangled, leading to the Unruh effect. Similarly, the past and right\nRindler wedges are also entangled. We propose a protocol to extract this\nentanglement using two two-state detectors located in the past and right\nRindler wedges. By scaling the detector transition frequencies inversely with\nMinkowski time, entanglement from the quantum field is transferred to the\ndetectors, suggesting they may support quantum teleportation via the vacuum.\nOur protocol can be implemented with current quantum systems, such as\nflux-tunable transmon qubits. This research provides new insights into the\nentanglement properties of spacetime and hints at practical applications for\nsecure quantum information transfer using the vacuum state of a quantum field.","main_category":"gr-qc","categories":"gr-qc,quant-ph","published":"2025-04-30T13:54:35Z"}
{"aid":"http://arxiv.org/abs/2504.21690v1","title":"Combinatorial twists in gl_n Yangians","summary":"We introduce the special set-theoretic Yang-Baxter algebra and show that it\nis a Hopf algebra. The associated universal R-matrix is also obtained via an\nadmissible Drinfel'd twist, making the algebra a quasi-triangular Hopf algebra.\nThe fundamental representation of the universal R-matrix yields the familiar\nset-theoretic (combinatorial) solutions of the Yang-Baxter equation. We then\napply the same Drinfel'd twist to the gl_n Yangian after introducing the\naugmented Yangian. We show that the augmented Yangian is also a Hopf algebra\nand we obtain the twisted version of the augmented gl_n Yangian as well as the\ntwisted R-matrix.","main_category":"math.QA","categories":"math.QA,math-ph,math.MP","published":"2025-04-30T14:25:33Z"}
{"aid":"http://arxiv.org/abs/2504.21704v1","title":"Bounds in Sequential Unambiguous Discrimination of Multiple Pure Quantum\n  States","summary":"Sequential methods for quantum hypothesis testing offer significant\nadvantages over fixed-length approaches, which rely on a predefined number of\nstate copies. Despite their potential, these methods remain underexplored for\nunambiguous discrimination. In this work, we derive performance bounds for such\nmethods when applied to the discrimination of a set of pure states. The\nperformance is evaluated based on the expected number of copies required. We\nestablish a lower bound applicable to any sequential method and an upper bound\non the optimal sequential method. The upper bound is derived using a novel and\nsimple non-adaptive method. Importantly, the gap between these bounds is\nminimal, scaling logarithmically with the number of distinct states.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-30T14:46:04Z"}
{"aid":"http://arxiv.org/abs/2504.21733v1","title":"The role of terminal groups in non-chiral rod-like compounds on the\n  formation of polar fluids","summary":"The emergence of ferroelectric mesophases in non-chiral liquid crystal (LCs)\nhas sparked fundamental interest in the molecular mechanisms governing\npolarity. In this study, we investigate how terminal molecular groups influence\nthe formation and stability of polar phases by analyzing six compounds from\nthree homologous series. Specifically, we compare newly synthesized homologs\nwith a nitro group, which predominantly exhibit polar mesophases, to previously\nreported structurally related analogs containing either a cyano group or a\nfluorine atom as terminal fragment. Density Functional Theory (DFT)\ncalculations provide insights into electronic surface potential (ESP)\ndistributions, revealing alternating regions of positive and negative charge\ndensity along the molecular axis, consistent with Madhusudana model of polar\nphase stabilization. We propose the ESP-derived parameter quantifying terminal\nelectrostatic charge, revealing a direct correlation between the negative to\npositive charge ratio at the molecular termini and the formation of\nferroelectric or antiferroelectric mesophases. To validate this hypothesis, we\nanalyze the molecular structure-mesomorphic behavior relationship of other\nknown non-chiral compounds that exhibit polar phases, demonstrating the\ncritical role of terminal groups in determining mesophase polarity. Our\nfindings enhance the understanding of the molecular origins of ferroelectricity\nin non-chiral LCs, paving the way for the rational design of next-generation\nfunctional polar soft materials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-30T15:22:39Z"}
{"aid":"http://arxiv.org/abs/2504.21735v1","title":"TheraQuest: A Gamified, LLM-Powered Simulation for Massage Therapy\n  Training","summary":"Massage therapy training emphasizes hands-on techniques and effective\ntherapist--patient communication. However, many educational programs struggle\nto provide realistic practice scenarios. To address this problem, we propose\nTheraQuest, a gamified, web-based simulation platform that employs large\nlanguage models (LLMs) to generate diverse virtual patients with varying\nsymptoms and cultural backgrounds. Through interactive dialogue, anatomical\ndecision-making, and immediate assessment, trainees develop both diagnostic\nreasoning and empathetic communication skills in a low-risk environment. Unlike\nexclusively VR-based solutions, TheraQuest remains accessible via standard web\nbrowsers, mitigating the cost and discomfort associated with extended headset\nuse. Preliminary testing suggests that integrating LLM-driven virtual patients\nwith real-time skill metrics can enhance trainee engagement and help bridge the\ngap between theoretical knowledge and clinical proficiency.","main_category":"cs.GT","categories":"cs.GT,cs.HC","published":"2025-04-30T15:31:52Z"}
{"aid":"http://arxiv.org/abs/2504.21744v1","title":"Jet Modification and Medium Response -- Theory Overview","summary":"This text contains a summary and personal perspective on the current status\nand challenges of jet quenching physics as portrayed by the presentations\ndelivered at the 12th International Conference on Hard and Electromagnetic\nProbes of High-Energy Nuclear Collisions (Hard Probes 2024) which took place in\nSeptember 2024 in Nagasaki, Japan.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-30T15:39:15Z"}
{"aid":"http://arxiv.org/abs/2504.21752v1","title":"VDDP: Verifiable Distributed Differential Privacy under the\n  Client-Server-Verifier Setup","summary":"Despite differential privacy (DP) often being considered the de facto\nstandard for data privacy, its realization is vulnerable to unfaithful\nexecution of its mechanisms by servers, especially in distributed settings.\nSpecifically, servers may sample noise from incorrect distributions or generate\ncorrelated noise while appearing to follow established protocols. This work\nanalyzes these malicious behaviors in a general differential privacy framework\nwithin a distributed client-server-verifier setup. To address these adversarial\nproblems, we propose a novel definition called Verifiable Distributed\nDifferential Privacy (VDDP) by incorporating additional verification\nmechanisms. We also explore the relationship between zero-knowledge proofs\n(ZKP) and DP, demonstrating that while ZKPs are sufficient for achieving DP\nunder verifiability requirements, they are not necessary. Furthermore, we\ndevelop two novel and efficient mechanisms that satisfy VDDP: (1) the\nVerifiable Distributed Discrete Laplacian Mechanism (VDDLM), which offers up to\na $4 \\times 10^5$x improvement in proof generation efficiency with only\n0.1-0.2x error compared to the previous state-of-the-art verifiable\ndifferentially private mechanism; (2) an improved solution to Verifiable\nRandomized Response (VRR) under local DP, a special case of VDDP, achieving up\na reduction of up to 5000x in communication costs and the verifier's overhead.","main_category":"cs.CR","categories":"cs.CR,cs.DB","published":"2025-04-30T15:46:55Z"}
{"aid":"http://arxiv.org/abs/2504.21794v1","title":"Vortex flow anisotropy in nematic superconductors","summary":"We investigate the vortex flow anisotropy in the mixed state of nematic\nsuperconductors, focusing on the effects of nematic-superconducting coupling on\nvortex dynamics. Using numerical simulations within a time-dependent\nGinzburg-Landau (TDGL) approach, we analyze vortex viscosity in a model\nfeaturing an s-wave superconducting order parameter coupled to an Ising-like\nnematic order parameter, suitable for systems with $C_4$ symmetry. Our results\nindicate that nematicity induces a significant anisotropy in the flux-flow\nresistivity, which depends on both vortex core shape anisotropy and\nnormal-phase conductivity anisotropy. These two effects can either compete or\ncooperate with each other. We discuss the implications of these findings for\nidentifying nematic superconductivity in the superconducting phase. Our work\nprovides new insights into the interplay between nematic and superconducting\norder parameters, leading to new possibilities for experimental and theoretical\nexploration of anisotropic transport properties in unconventional\nsuperconductors.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-30T16:51:09Z"}
{"aid":"http://arxiv.org/abs/2504.21800v1","title":"How Real Are Synthetic Therapy Conversations? Evaluating Fidelity in\n  Prolonged Exposure Dialogues","summary":"The growing adoption of synthetic data in healthcare is driven by privacy\nconcerns, limited access to real-world data, and the high cost of annotation.\nThis work explores the use of synthetic Prolonged Exposure (PE) therapeutic\nconversations for Post-Traumatic Stress Disorder (PTSD) as a scalable\nalternative for training and evaluating clinical models. We systematically\ncompare real and synthetic dialogues using linguistic, structural, and\nprotocol-specific metrics, including turn-taking patterns and treatment\nfidelity. We also introduce and evaluate PE-specific metrics derived from\nlinguistic analysis and semantic modeling, offering a novel framework for\nassessing clinical fidelity beyond surface fluency. Our findings show that\nalthough synthetic data holds promise for mitigating data scarcity and\nprotecting patient privacy, it can struggle to capture the subtle dynamics of\ntherapeutic interactions. In our dataset, synthetic dialogues match structural\nfeatures of real-world dialogues (e.g., speaker switch ratio: 0.98 vs. 0.99),\nhowever, synthetic interactions do not adequately reflect key fidelity markers\n(e.g., distress monitoring). We highlight gaps in existing evaluation\nframeworks and advocate for fidelity-aware metrics that go beyond surface\nfluency to uncover clinically significant failures. Our findings clarify where\nsynthetic data can effectively complement real-world datasets -- and where\ncritical limitations remain.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.CY,cs.HC","published":"2025-04-30T16:56:56Z"}
{"aid":"http://arxiv.org/abs/2504.21811v1","title":"Coarse Baum-Connes and warped cones: failure of surjectivity in odd\n  degree","summary":"We prove a conjecture of Roe by constructing unified warped cones that\nviolate the coarse Baum-Connes conjecture. Interestingly, the reason for this\nis probably not what Roe expected, as the obstruction arises in odd rather than\neven degree.","main_category":"math.KT","categories":"math.KT,math.MG,math.OA","published":"2025-04-30T17:15:20Z"}
{"aid":"http://arxiv.org/abs/2504.21815v1","title":"From Aesthetics to Human Preferences: Comparative Perspectives of\n  Evaluating Text-to-Music Systems","summary":"Evaluating generative models remains a fundamental challenge, particularly\nwhen the goal is to reflect human preferences. In this paper, we use music\ngeneration as a case study to investigate the gap between automatic evaluation\nmetrics and human preferences. We conduct comparative experiments across five\nstate-of-the-art music generation approaches, assessing both perceptual quality\nand distributional similarity to human-composed music. Specifically, we\nevaluate synthesis music from various perceptual dimensions and examine\nreference-based metrics such as Mauve Audio Divergence (MAD) and Kernel Audio\nDistance (KAD). Our findings reveal significant inconsistencies across the\ndifferent metrics, highlighting the limitation of the current evaluation\npractice. To support further research, we release a benchmark dataset\ncomprising samples from multiple models. This study provides a broader\nperspective on the alignment of human preference in generative modeling,\nadvocating for more human-centered evaluation strategies across domains.","main_category":"eess.AS","categories":"eess.AS","published":"2025-04-30T17:21:04Z"}
{"aid":"http://arxiv.org/abs/2504.21824v1","title":"A simple range characterization for spherical mean transform in even\n  dimensions","summary":"The paper presents a new and simple range characterization for the spherical\nmean transform of functions supported in the unit ball in even dimensions. It\ncomplements the previous work of the same authors, where they solved an\nanalogous problem in odd dimensions. The range description in even dimensions\nconsists of symmetry relations, using a special kind of elliptic integrals\ninvolving the coefficients of the spherical harmonics expansion of the function\nin the range of the transform. The article also introduces a pair of original\nidentities involving normalized Bessel functions of the first and the second\nkind. The first result is an integral cross-product identity for Bessel\nfunctions of integer order, complementing a similar relation for Bessel\nfunctions of half-integer order obtained in the aforementioned work of the same\nauthors. The second result is a new Nicholson-type identity. Both of these\nrelations can be considered as important standalone results in the theory of\nspecial functions. Finally, as part of the proof of one of the theorems, the\nauthors derive an interesting equality involving elliptic integrals, which may\nbe of independent interest.","main_category":"math.CA","categories":"math.CA,math-ph,math.FA,math.MP","published":"2025-04-30T17:27:23Z"}
{"aid":"http://arxiv.org/abs/2504.21840v1","title":"Parameter Inference of Black Hole Images using Deep Learning in\n  Visibility Space","summary":"Using very long baseline interferometry, the Event Horizon Telescope (EHT)\ncollaboration has resolved the shadows of two supermassive black holes. Model\ncomparison is traditionally performed in image space, where imaging algorithms\nintroduce uncertainties in the recovered structure. Here, we develop a deep\nlearning framework to perform parameter inference in visibility space, directly\nusing the data measured by the interferometer without introducing potential\nerrors and biases from image reconstruction. First, we train and validate our\nframework on synthetic data derived from general relativistic\nmagnetohydrodynamics (GRMHD) simulations that vary in magnetic field state,\nspin, and $R_\\mathrm{high}$. Applying these models to the real data obtained\nduring the 2017 EHT campaign, and only considering total intensity, we do not\nderive meaningful constraints on either of these parameters. At present, our\nmethod is limited both by theoretical uncertainties in the GRMHD simulations\nand variation between snapshots of the same underlying physical model. However,\nwe demonstrate that spin and $R_\\mathrm{high}$ could be recovered using this\nframework through continuous monitoring of our sources, which mitigates\nvariations due to turbulence. In future work, we anticipate that including\nspectral or polarimetric information will greatly improve the performance of\nthis framework.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-30T17:50:47Z"}
{"aid":"http://arxiv.org/abs/2505.00282v1","title":"A Unifying Framework for Robust and Efficient Inference with\n  Unstructured Data","summary":"This paper presents a general framework for conducting efficient and robust\ninference on parameters derived from unstructured data, which include text,\nimages, audio, and video. Economists have long incorporated data extracted from\ntexts and images into their analyses, a practice that has accelerated with\nadvancements in deep neural networks. However, neural networks do not\ngenerically produce unbiased predictions, potentially propagating bias to\nestimators that use their outputs. To address this challenge, we reframe\ninference with unstructured data as a missing structured data problem, where\nstructured data are imputed from unstructured inputs using deep neural\nnetworks. This perspective allows us to apply classic results from\nsemiparametric inference, yielding valid, efficient, and robust estimators\nbased on unstructured data. We formalize this approach with MARS (Missing At\nRandom Structured Data), a unifying framework that integrates and extends\nexisting methods for debiased inference using machine learning predictions,\nlinking them to a variety of older, familiar problems such as causal inference.\nWe develop robust and efficient estimators for both descriptive and causal\nestimands and address challenges such as inference using aggregated and\ntransformed predictions from unstructured data. Importantly, MARS applies to\ncommon empirical settings that have received limited attention in the existing\nliterature. Finally, we reanalyze prominent studies that use unstructured data,\ndemonstrating the practical value of MARS.","main_category":"econ.EM","categories":"econ.EM,cs.LG","published":"2025-05-01T04:11:25Z"}
{"aid":"http://arxiv.org/abs/2505.00292v1","title":"Conformal changepoint localization","summary":"Changepoint localization is the problem of estimating the index at which a\nchange occurred in the data generating distribution of an ordered list of data,\nor declaring that no change occurred. We present the broadly applicable CONCH\n(CONformal CHangepoint localization) algorithm, which uses a matrix of\nconformal p-values to produce a confidence interval for a (single) changepoint\nunder the mild assumption that the pre-change and post-change distributions are\neach exchangeable. We exemplify the CONCH algorithm on a variety of synthetic\nand real-world datasets, including using black-box pre-trained classifiers to\ndetect changes in sequences of images or text.","main_category":"math.ST","categories":"math.ST,eess.SP,stat.ME,stat.TH","published":"2025-05-01T04:27:52Z"}
{"aid":"http://arxiv.org/abs/2505.00315v1","title":"Mixture of Sparse Attention: Content-Based Learnable Sparse Attention\n  via Expert-Choice Routing","summary":"Recent advances in large language models highlighted the excessive quadratic\ncost of self-attention. Despite the significant research efforts, subquadratic\nattention methods still suffer from inferior performance in practice. We\nhypothesize that dynamic, learned content-based sparsity can lead to more\nefficient attention mechanisms. We present Mixture of Sparse Attention (MoSA),\na novel approach inspired by Mixture of Experts (MoE) with expert choice\nrouting. MoSA dynamically selects tokens for each attention head, allowing\narbitrary sparse attention patterns. By selecting $k$ tokens from a sequence of\nlength $T$, MoSA reduces the computational complexity of each attention head\nfrom $O(T^2)$ to $O(k^2 + T)$. This enables using more heads within the same\ncomputational budget, allowing higher specialization. We show that among the\ntested sparse attention variants, MoSA is the only one that can outperform the\ndense baseline, sometimes with up to 27% better perplexity for an identical\ncompute budget. MoSA can also reduce the resource usage compared to dense\nself-attention. Despite using torch implementation without an optimized kernel,\nperplexity-matched MoSA models are simultaneously faster in wall-clock time,\nrequire less memory for training, and drastically reduce the size of the\nKV-cache compared to the dense transformer baselines.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-05-01T05:22:11Z"}
{"aid":"http://arxiv.org/abs/2505.00321v1","title":"Edge Large AI Models: Revolutionizing 6G Networks","summary":"Large artificial intelligence models (LAMs) possess human-like abilities to\nsolve a wide range of real-world problems, exemplifying the potential of\nexperts in various domains and modalities. By leveraging the communication and\ncomputation capabilities of geographically dispersed edge devices, edge LAM\nemerges as an enabling technology to empower the delivery of various real-time\nintelligent services in 6G. Unlike traditional edge artificial intelligence\n(AI) that primarily supports a single task using small models, edge LAM is\nfeatured by the need of the decomposition and distributed deployment of large\nmodels, and the ability to support highly generalized and diverse tasks.\nHowever, due to limited communication, computation, and storage resources over\nwireless networks, the vast number of trainable neurons and the substantial\ncommunication overhead pose a formidable hurdle to the practical deployment of\nedge LAMs. In this paper, we investigate the opportunities and challenges of\nedge LAMs from the perspectives of model decomposition and resource management.\nSpecifically, we propose collaborative fine-tuning and full-parameter training\nframeworks, alongside a microservice-assisted inference architecture, to\nenhance the deployment of edge LAM over wireless networks. Additionally, we\ninvestigate the application of edge LAM in air-interface designs, focusing on\nchannel prediction and beamforming. These innovative frameworks and\napplications offer valuable insights and solutions for advancing 6G technology.","main_category":"cs.NI","categories":"cs.NI,cs.LG,eess.SP","published":"2025-05-01T05:44:00Z"}
{"aid":"http://arxiv.org/abs/2505.00340v1","title":"Vehicular Communication Security: Multi-Channel and Multi-Factor\n  Authentication","summary":"Secure and reliable communications are crucial for Intelligent Transportation\nSystems (ITSs), where Vehicle-to-Infrastructure (V2I) communication plays a key\nrole in enabling mobility-enhancing and safety-critical services. Current V2I\nauthentication relies on credential-based methods over wireless\nNon-Line-of-Sight (NLOS) channels, leaving them exposed to remote impersonation\nand proximity attacks. To mitigate these risks, we propose a unified\nMulti-Channel, Multi-Factor Authentication (MFA) scheme that combines NLOS\ncryptographic credentials with a Line-of-Sight (LOS) visual channel. Our\napproach leverages a challenge-response security paradigm: the infrastructure\nissues challenges and the vehicle's headlights respond by flashing a structured\nsequence containing encoded security data. Deep learning models on the\ninfrastructure side then decode the embedded information to authenticate the\nvehicle. Real-world experimental evaluations demonstrate high test accuracy,\nreaching an average of 95% and 96.6%, respectively, under various lighting,\nweather, speed, and distance conditions. Additionally, we conducted extensive\nexperiments on three state-of-the-art deep learning models, including detailed\nablation studies for decoding the flashing sequence. Our results indicate that\nthe optimal architecture employs a dual-channel design, enabling simultaneous\ndecoding of the flashing sequence and extraction of vehicle spatial and\nlocational features for robust authentication.","main_category":"cs.CR","categories":"cs.CR","published":"2025-05-01T06:36:24Z"}
{"aid":"http://arxiv.org/abs/2505.00353v1","title":"PYSED: A tool for extracting kinetic-energy-weighted phonon dispersion\n  and lifetime from molecular dynamics simulations","summary":"Machine learning potential-driven molecular dynamics (MD) simulations have\nsignificantly enhanced the predictive accuracy of thermal transport properties\nacross diverse materials. However, extracting phonon-mode-resolved insights\nfrom these simulations remains a critical challenge. Here, we introduce PYSED,\na Python-based package built on the spectral energy density (SED) method,\ndesigned to efficiently compute kinetic-energy-weighted phonon dispersion and\nextract phonon lifetime from large-scale MD simulation trajectories. By\nintegrating high-accuracy machine-learned neuroevolution potential (NEP)\nmodels, we validate and showcase the effectiveness of the implemented SED\nmethod across systems of varying dimensionalities. Specifically, the NEP-driven\nMD-SED accurately reveals how phonon modes are affected by strain in carbon\nnanotubes, as well as by interlayer coupling strength and twist angle in\ntwo-dimensional molybdenum disulfide. For three-dimensional systems, the SED\nmethod effectively establishes the thermal transport regime diagram for\nmetal-organic frameworks, distinguishing between particlelike and wavelike\npropagation regions. Moreover, using bulk silicon as an example, we show that\nphonon SED can efficiently capture quantum dynamics based on path-integral\ntrajectories. The PYSED package bridges MD simulations with detailed\nphonon-mode insights, delivering a robust tool for investigating thermal\ntransport properties with detailed mechanisms across various materials.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-05-01T06:52:18Z"}
{"aid":"http://arxiv.org/abs/2505.00445v1","title":"Effect of Ti$_2$Pd(Ni) on the Transformation Behavior in Sputtered\n  Ti-rich TiNiPd Shape Memory Alloys","summary":"TiNiPd based shape memory alloys (SMAs) share similar microstructural\nfeatures as TiNiCu-based SMAs known for their exceptional resistance to\nfunctional fatigue due to their high crystallographic compatibility, nanometer\nsized grains and coherent precipitates, making them an ideal system to further\nexplore the critical factors influencing cyclic stability. In this study, we\ninvestigate the effect of heat treatments (500 {\\deg}C, 600 {\\deg}C, 700\n{\\deg}C and 800 {\\deg}C) on the cyclic stability and microstructure of\nfree-standing, magnetron-sputtered Ti$_{53.6}$Ni$_{35.2}$Pd$_{11.2}$ films. All\nheat treatments promote the formation of Ti$_2$Pd(Ni) precipitates and result\nin a similar grain size (~1-4 $\\mu$m). Lower heat treatment temperatures\nimprove the cyclic stability of the stress induced transformation while\nreducing transformation temperatures and latent heat. Temperature dependent\nX-ray diffraction reveals a complex microstructure for the martensite phase\nwith Ti$_2$Pd(Ni), Ti$_2$Ni(Pd), TiNiPd(B2), B19/B19$'$ and R-phase. The\nthermal phase transition changes from a distinct 1st order to a 2nd order like\ntransition, accompanied by increasing amount of remanent austenite and R-phase,\nwith nearly no change for the sample heat treated at 500 {\\deg}C. In situ\nstress dependent X-ray diffraction demonstrates a significant difference\nbetween the temperature and stress induced phase transformation for this heat\ntreatment. The observed semi crystalline microstructure, featuring nano domains\nof Ti$_2$Pd(Ni) precipitates in the sample heat-treated at 500 {\\deg}C, leads\nto a mixture of long range martensitic and strain glass transition. This study\nhighlights the impact of heat treatment and microstructure on the phase\ntransformation behavior and functional fatigue in Ti-rich TiNiPd alloys.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-05-01T10:39:49Z"}
{"aid":"http://arxiv.org/abs/2505.00449v1","title":"An approach for modularly verifying the core of Rust's atomic reference\n  counting algorithm against the (X)C20 memory consistency model","summary":"We propose an approach for modular verification of programs that use\nrelaxed-consistency atomic memory access primitives and fences, sufficient for\nverifying the core of Rust's Atomic Reference Counting (ARC) algorithm, and we\nargue its soundness, when combined with a simple static analysis and admitting\nan open sub-problem, with respect to the C20 memory consistency model, as well\nas, even in the absence of any static analysis and without any assumptions,\nwith respect to XC20, a recently proposed minor strengthening of C20 that rules\nout out-of-thin-air behaviors but allows load buffering. In contrast to\nexisting work on verifying ARC, we do not assume acyclicity of the union of the\nprogram-order and reads-from relations. We define an interleaving operational\nsemantics, prove its soundness with respect to (X)C20's axiomatic semantics,\nand then apply any existing program logic for fine-grained interleaving\nconcurrency, such as Iris.","main_category":"cs.PL","categories":"cs.PL","published":"2025-05-01T10:51:20Z"}
{"aid":"http://arxiv.org/abs/2505.00464v1","title":"Stable self-charged perovskite quantum rods for liquid laser with\n  near-zero threshold","summary":"Colloidal quantum dots (QDs) are promising optical gain materials that\nrequire further threshold reduction to realize their full potential. While QD\ncharging theoretically reduces the threshold to zero, its effectiveness has\nbeen limited by strong Auger recombination and unstable charging. Here we\ntheoretically reveal the optimal combination of charging number and Auger\nrecombination to minimize the lasing threshold. Experimentally, we develop\nstable self-charged perovskite quantum rods (QRs) as an alternative to QDs via\nstate engineering and Mn-doping strategy. An unprecedented\ntwo-order-of-magnitude reduction in nonradiative Auger recombination enables\nQRs to support a sufficient charging number of up to 6. The QR liquid lasing is\nthen achieved with a near-zero threshold of 0.098 using quasi-continuous\npumping of nanosecond pulses, which is the lowest threshold among all reported\nQD lasers. These achievements demonstrate the potential of the specially\nengineered QRs as an excellent gain media and pave the way for their\nprospective applications.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,physics.app-ph,physics.optics","published":"2025-05-01T11:31:09Z"}
{"aid":"http://arxiv.org/abs/2505.00483v1","title":"Search for a parity-violating long-range spin-dependent interaction","summary":"High-sensitivity quantum sensors are a promising tool for experimental\nsearches for beyond-Standard-Model interactions. Here, we demonstrate an atomic\ncomagnetometer operating under a resonantly-coupled hybrid spin-resonance (HSR)\nregime to probe P-odd, T-even interactions. The HSR regime enables robust\nnuclear-electron spin coupling, enhancing measurement bandwidth and stability\nwithout compromising the high sensitivity of spin-exchange relaxation-free\nmagnetometers. To minimize vibration noise from velocity-modulated sources, we\nimplement a multistage vibration isolation system, achieving a vibration noise\nreduction exceeding 700-fold. We establish new constraints on\nvector-boson-mediated parity-violating interactions, improving experimental\nsensitivity by three orders of magnitude compared to previous limits. The new\nconstraints complement existing astrophysical and laboratory studies of\npotential extensions to the Standard Model.","main_category":"quant-ph","categories":"quant-ph,physics.atom-ph","published":"2025-05-01T12:29:19Z"}
{"aid":"http://arxiv.org/abs/2505.00489v1","title":"Weighted averages of $\\operatorname{SL}_2(\\mathbb{R})$ automorphic\n  kernel, Part I: non-oscillatory functions","summary":"We prove a theorem that evaluates weighted averages of sums parametrized by\ncongruence subgroups of $\\operatorname{SL}_2(\\mathbb{Z})$. In the proof,\nspectral methods are applied directly to the automorphic kernel instead of\ngoing over sums of Kloosterman sums. For number theoretical applications this\nbetter preserves the specific symmetries throughout the application of spectral\nmethods.","main_category":"math.NT","categories":"math.NT","published":"2025-05-01T12:42:20Z"}
{"aid":"http://arxiv.org/abs/2505.00507v1","title":"HeAL3D: Heuristical-enhanced Active Learning for 3D Object Detection","summary":"Active Learning has proved to be a relevant approach to perform sample\nselection for training models for Autonomous Driving. Particularly, previous\nworks on active learning for 3D object detection have shown that selection of\nsamples in uncontrolled scenarios is challenging. Furthermore, current\napproaches focus exclusively on the theoretical aspects of the sample selection\nproblem but neglect the practical insights that can be obtained from the\nextensive literature and application of 3D detection models. In this paper, we\nintroduce HeAL (Heuristical-enhanced Active Learning for 3D Object Detection)\nwhich integrates those heuristical features together with Localization and\nClassification to deliver the most contributing samples to the model's\ntraining. In contrast to previous works, our approach integrates heuristical\nfeatures such as object distance and point-quantity to estimate the\nuncertainty, which enhance the usefulness of selected samples to train\ndetection models. Our quantitative evaluation on KITTI shows that HeAL presents\ncompetitive mAP with respect to the State-of-the-Art, and achieves the same mAP\nas the full-supervised baseline with only 24% of the samples.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-01T13:24:55Z"}
{"aid":"http://arxiv.org/abs/2505.00517v1","title":"An explicit description of the KÃ¤hler-Einstein metrics of\n  Guenancia-HamenstÃ¤dt","summary":"Fine and Premoselli (FP) constructed the first examples of manifolds that do\nnot admit a locally symmetric metric but do admit a negatively curved Einstein\nmetric. The manifolds here are hyperbolic branched covers like those used by\nGromov and Thurston, and the construction of their model Einstein metric is a\nvariation of the hyperbolic metric written in polar coordinates. Very recently,\nGuenancia and Hamenst\\\"{a}dt (GH) proved the existence of the first examples of\nmanifolds that are not locally symmetric but admit a negatively curved\nK\\\"{a}hler-Einstein metric. The GH metrics are realized on complex hyperbolic\nbranched covers constructed by Stover and Toledo. In this article we generalize\nthe construction of FP to the complex hyperbolic setting and show that this\nyields a negatively curved Einstein metric that asymptotically approaches the\nmetric of GH.","main_category":"math.DG","categories":"math.DG,math-ph,math.GT,math.MG,math.MP","published":"2025-05-01T13:39:20Z"}
{"aid":"http://arxiv.org/abs/2505.00535v1","title":"Moving through Cartesian products, coronas and joins in general position","summary":"The general position problem asks for large sets of vertices such that no\nthree vertices of the set lie on a common shortest path. Recently a dynamic\nversion of this problem was defined, called the \\emph{mobile general position\nproblem}, in which a collection of robots must visit all the vertices of the\ngraph whilst remaining in general position. In this paper we investigate this\nproblem in the context of Cartesian products, corona products and joins, giving\nupper and lower bounds for general graphs and exact values for families\nincluding grids, cylinders, Hamming graphs and prisms of trees.","main_category":"math.CO","categories":"math.CO","published":"2025-05-01T14:00:59Z"}
{"aid":"http://arxiv.org/abs/2505.00550v1","title":"Bridging Cultural and Digital Divides: A Low-Latency JackTrip Framework\n  for Equitable Music Education in the Global South","summary":"The rapid expansion of digital technologies has transformed educational\nlandscapes worldwide, yet significant infrastructural and cultural challenges\npersist in the Global South. This paper introduces a low-latency JackTrip\nframework designed to bridge both the cultural and digital divides in music\neducation. By leveraging an open-source, UDP-based audio streaming protocol\noriginally developed at Stanford's CCRMA, the framework is tailored to address\ntechnical constraints such as intermittent connectivity, limited bandwidth, and\nhigh latency that characterize many rural and underserved regions. The study\nsystematically compares the performance of JackTrip with conventional platforms\nlike Zoom, demonstrating that JackTrip achieves sub-30~ms latency under\nsimulated low-resource conditions while preserving the intricate audio details\nessential for non-Western musical traditions. Spectral analysis confirms that\nJackTrip's superior handling of microtonal scales, complex rhythms, and\nharmonic textures provides a culturally authentic medium for real-time ensemble\nperformance and music education. These findings underscore the transformative\npotential of decentralized, edge-computing solutions in empowering educators\nand musicians across the Global South, promoting both technological equity and\ncultural preservation.","main_category":"cs.SD","categories":"cs.SD,cs.SI","published":"2025-05-01T14:27:47Z"}
{"aid":"http://arxiv.org/abs/2505.00568v1","title":"Multimodal Masked Autoencoder Pre-training for 3D MRI-Based Brain Tumor\n  Analysis with Missing Modalities","summary":"Multimodal magnetic resonance imaging (MRI) constitutes the first line of\ninvestigation for clinicians in the care of brain tumors, providing crucial\ninsights for surgery planning, treatment monitoring, and biomarker\nidentification. Pre-training on large datasets have been shown to help models\nlearn transferable representations and adapt with minimal labeled data. This\nbehavior is especially valuable in medical imaging, where annotations are often\nscarce. However, applying this paradigm to multimodal medical data introduces a\nchallenge: most existing approaches assume that all imaging modalities are\navailable during both pre-training and fine-tuning. In practice, missing\nmodalities often occur due to acquisition issues, specialist unavailability, or\nspecific experimental designs on small in-house datasets. Consequently, a\ncommon approach involves training a separate model for each desired modality\ncombination, making the process both resource-intensive and impractical for\nclinical use. Therefore, we introduce BM-MAE, a masked image modeling\npre-training strategy tailored for multimodal MRI data. The same pre-trained\nmodel seamlessly adapts to any combination of available modalities, extracting\nrich representations that capture both intra- and inter-modal information. This\nallows fine-tuning on any subset of modalities without requiring architectural\nchanges, while still benefiting from a model pre-trained on the full set of\nmodalities. Extensive experiments show that the proposed pre-training strategy\noutperforms or remains competitive with baselines that require separate\npre-training for each modality subset, while substantially surpassing training\nfrom scratch on several downstream tasks. Additionally, it can quickly and\nefficiently reconstruct missing modalities, highlighting its practical value.\nCode and trained models are available at: https://github.com/Lucas-rbnt/bmmae","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-05-01T14:51:30Z"}
{"aid":"http://arxiv.org/abs/2505.00583v1","title":"Gluon Parts of Gravitational Form Factors and Mass Distribution","summary":"The parton structure of the nucleon and pion is investigated in an\nexploratory model that allows one to assess whether the dressing of quarks can,\nby itself, produce realistic gluon contributions to light-cone momentum\nfractions, gravitational form factors, mass/energy distributions and their\nradii. The model is the Dyson-Schwinger Equations in Rainbow-Ladder truncation.\nFor the parton mass/energy distributions as a function of momentum transfer, we\ndirectly calculate matrix elements of the Energy-Momentum Tensor by utilizing\nits similarity to the momentum fraction moment of GPDs associated with deep\ninelastic scattering. A variety of gravitational form factors are obtained\nincluding the D-term.","main_category":"nucl-th","categories":"nucl-th,hep-ph,hep-th","published":"2025-05-01T15:15:29Z"}
{"aid":"http://arxiv.org/abs/2505.00602v1","title":"Irregularity and Topological Indices in Fibonacci Word Trees and\n  Modified Fibonacci Word Index","summary":"This paper introduces the concept of the Fibonacci Word Index\n$\\operatorname{FWI}$, a novel topological index derived from the Albertson\nindex, applied to trees constructed from Fibonacci words. Building upon the\nclassical Fibonacci sequence and its generalizations, we explore the structural\nproperties of Fibonacci word trees and their degree-based irregularity\nmeasures. We define the $\\operatorname{FWI}$ and its variants, including the\ntotal irregularity and modified Fibonacci Word Index where it defined as \\[\n\\operatorname{FWI}^*(T)=\\sum_{n,m\\in E(\\mathscr{T})}[deg F_n^2-deg F_m^2], \\]\nand establish foundational inequalities relating these indices to the maximum\ndegree of the underlying trees. Our results extend known graph invariants to\nthe combinatorial setting of Fibonacci words, providing new insights into their\nalgebraic and topological characteristics.","main_category":"math.CO","categories":"math.CO","published":"2025-05-01T15:34:48Z"}
{"aid":"http://arxiv.org/abs/2505.00611v1","title":"A new pointwise bound for $3$-torsion of class groups","summary":"Ellenberg--Venkatesh proved in 2007 that $h_3(d) \\ll_\\epsilon |d|^{1/3 +\n\\epsilon}$, where $h_3(d)$ denotes the size of the $3$-torsion of the class\ngroup of $\\mathbb{Q}(\\sqrt{d})$. We improve this bound to $h_3(d) \\ll_\\epsilon\n|d|^{\\kappa + \\epsilon}$ with $\\kappa \\approx 0.3193 \\cdots$. We also combine\nour methods with work of Heath-Brown--Pierce to give new bounds for average\n$\\ell$-torsion of real quadratic fields.","main_category":"math.NT","categories":"math.NT","published":"2025-05-01T15:41:30Z"}
{"aid":"http://arxiv.org/abs/2505.00623v1","title":"Planckian scattering and parallel conduction channels in the iron\n  chalcogenide superconductors FeTe$_{1-x}$Se$_x$","summary":"The remarkable linear in temperature resistivity of the cuprate\nsuperconductors, which extends in some samples from $T_c$ to the melting\ntemperature, remains unexplained. Although seemingly simple, this temperature\ndependence is incompatible with the conventional theory of metals that dictates\nthat the scattering rate, $1/\\tau$, should be quadratic in temperature if\nelectron-electron scattering dominates. Understanding the origin of this\ntemperature dependence and its connection to superconductivity may provide the\nkey to pick the lock of high-temperature superconductivity. Using time-domain\nterahertz spectroscopy (TDTS) we elucidate the low temperature conducting\nbehavior of two FeTe$_{1-x}$Se$_x$ (FTS) samples, one with almost equal amounts\nof Se and Te that is believed to be a topological superconductor, and one that\nis more overdoped. Constrained with DC resistivity, we find two conduction\nchannels that add in parallel, a broad one in frequency with weak temperature\ndependence and a sharper one whose scattering rate goes as the Planckian\nlimited rate, $\\sim kT/h$. Through analysis of its spectral weight we show the\nsuperconducting condensate is mainly drawn from the channel that undergoes this\nPlanckian scattering.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.str-el","published":"2025-05-01T16:04:27Z"}
{"aid":"http://arxiv.org/abs/2505.00632v1","title":"Detecting Modeling Bias with Continuous Time Flow Models on Weak Lensing\n  Maps","summary":"Simulation-based inference provides a powerful framework for extracting rich\ninformation from nonlinear scales in current and upcoming cosmological surveys,\nand ensuring its robustness requires stringent validation of forward models. In\nthis work, we recast forward model validation as an out-of-distribution (OoD)\ndetection problem within the framework of machine learning (ML)-based\nsimulation-based inference (SBI). We employ probability density as the metric\nfor OoD detection, and compare various density estimation techniques,\ndemonstrating that field-level probability density estimation via continuous\ntime flow models (CTFM) significantly outperforms feature-level approaches that\ncombine scattering transform (ST) or convolutional neural networks (CNN) with\nnormalizing flows (NFs), as well as NF-based field-level estimators, as\nquantified by the area under the receiver operating characteristic curve\n(AUROC). Our analysis shows that CTFM not only excels in detecting OoD samples\nbut also provides a robust metric for model selection. Additionally, we\nverified CTFM maintains consistent efficacy across different cosmologies while\nmitigating the inductive biases inherent in NF architectures. Although our\nproof-of-concept study employs simplified forward modeling and noise settings,\nour framework establishes a promising pathway for identifying unknown\nsystematics in the cosmology datasets.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.IM","published":"2025-05-01T16:16:47Z"}
{"aid":"http://arxiv.org/abs/2505.00653v1","title":"On the exponents of distribution of primes and smooth numbers","summary":"We show that both primes and smooth numbers are equidistributed in arithmetic\nprogressions to moduli up to $x^{5/8 - o(1)}$, using triply-well-factorable\nweights for the primes (we also get improvements for the well-factorable linear\nsieve weights). This completely eliminates the dependency on Selberg's\neigenvalue conjecture in previous works of Lichtman and the author, which built\nin turn on results of Maynard and Drappeau. We rely on recent large sieve\ninequalities for exceptional Maass forms of the author for\nadditively-structured sequences, and on a related result of Watt for\nmultiplicatively-structured sequences. As applications, we prove refined upper\nbounds for the counts of twin primes and consecutive smooth numbers up to $x$.","main_category":"math.NT","categories":"math.NT","published":"2025-05-01T16:55:08Z"}
{"aid":"http://arxiv.org/abs/2505.00679v1","title":"Steering Large Language Models with Register Analysis for Arbitrary\n  Style Transfer","summary":"Large Language Models (LLMs) have demonstrated strong capabilities in\nrewriting text across various styles. However, effectively leveraging this\nability for example-based arbitrary style transfer, where an input text is\nrewritten to match the style of a given exemplar, remains an open challenge. A\nkey question is how to describe the style of the exemplar to guide LLMs toward\nhigh-quality rewrites. In this work, we propose a prompting method based on\nregister analysis to guide LLMs to perform this task. Empirical evaluations\nacross multiple style transfer tasks show that our prompting approach enhances\nstyle transfer strength while preserving meaning more effectively than existing\nprompting strategies.","main_category":"cs.CL","categories":"cs.CL","published":"2025-05-01T17:39:02Z"}
{"aid":"http://arxiv.org/abs/2505.00690v1","title":"Towards Autonomous Micromobility through Scalable Urban Simulation","summary":"Micromobility, which utilizes lightweight mobile machines moving in urban\npublic spaces, such as delivery robots and mobility scooters, emerges as a\npromising alternative to vehicular mobility. Current micromobility depends\nmostly on human manual operation (in-person or remote control), which raises\nsafety and efficiency concerns when navigating busy urban environments full of\nunpredictable obstacles and pedestrians. Assisting humans with AI agents in\nmaneuvering micromobility devices presents a viable solution for enhancing\nsafety and efficiency. In this work, we present a scalable urban simulation\nsolution to advance autonomous micromobility. First, we build URBAN-SIM - a\nhigh-performance robot learning platform for large-scale training of embodied\nagents in interactive urban scenes. URBAN-SIM contains three critical modules:\nHierarchical Urban Generation pipeline, Interactive Dynamics Generation\nstrategy, and Asynchronous Scene Sampling scheme, to improve the diversity,\nrealism, and efficiency of robot learning in simulation. Then, we propose\nURBAN-BENCH - a suite of essential tasks and benchmarks to gauge various\ncapabilities of the AI agents in achieving autonomous micromobility.\nURBAN-BENCH includes eight tasks based on three core skills of the agents:\nUrban Locomotion, Urban Navigation, and Urban Traverse. We evaluate four robots\nwith heterogeneous embodiments, such as the wheeled and legged robots, across\nthese tasks. Experiments on diverse terrains and urban structures reveal each\nrobot's strengths and limitations.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.RO","published":"2025-05-01T17:52:29Z"}
