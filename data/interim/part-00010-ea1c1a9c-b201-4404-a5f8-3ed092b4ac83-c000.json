{"aid":"http://arxiv.org/abs/2503.21683v1","title":"LLM-Gomoku: A Large Language Model-Based System for Strategic Gomoku\n  with Self-Play and Reinforcement Learning","summary":"In recent years, large language models (LLMs) have shown significant\nadvancements in natural language processing (NLP), with strong capa-bilities in\ngeneration, comprehension, and rea-soning. These models have found applications\nin education, intelligent decision-making, and gaming. However, effectively\nutilizing LLMs for strategic planning and decision-making in the game of Gomoku\nremains a challenge. This study aims to develop a Gomoku AI system based on\nLLMs, simulating the human learning process of playing chess. The system is\nde-signed to understand and apply Gomoku strat-egies and logic to make rational\ndecisions. The research methods include enabling the model to \"read the board,\"\n\"understand the rules,\" \"select strategies,\" and \"evaluate positions,\" while\nen-hancing its abilities through self-play and rein-forcement learning. The\nresults demonstrate that this approach significantly improves the se-lection of\nmove positions, resolves the issue of generating illegal positions, and reduces\npro-cess time through parallel position evaluation. After extensive self-play\ntraining, the model's Gomoku-playing capabilities have been notably enhanced.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-03-27T16:52:25Z"}
{"aid":"http://arxiv.org/abs/2503.21692v1","title":"RapidPoseTriangulation: Multi-view Multi-person Whole-body Human Pose\n  Triangulation in a Millisecond","summary":"The integration of multi-view imaging and pose estimation represents a\nsignificant advance in computer vision applications, offering new possibilities\nfor understanding human movement and interactions. This work presents a new\nalgorithm that improves multi-view multi-person pose estimation, focusing on\nfast triangulation speeds and good generalization capabilities. The approach\nextends to whole-body pose estimation, capturing details from facial\nexpressions to finger movements across multiple individuals and viewpoints.\nAdaptability to different settings is demonstrated through strong performance\nacross unseen datasets and configurations. To support further progress in this\nfield, all of this work is publicly accessible.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T16:57:33Z"}
{"aid":"http://arxiv.org/abs/2503.21703v1","title":"Trivial source characters in blocks of domestic representation type","summary":"Let $G$ be a finite group of even order, let $k$ be an algebraically closed\nfield of characteristic $2$, and let $B$ be a block of the group algebra $kG$\nwhich is of domestic representation type. Up to splendid Morita equivalence,\nprecisely three cases can occur: $kV_4$, $k\\mathfrak{A}_4$ and the principal\nblock of $k\\mathfrak{A}_5$. In each case, given the character values of the\nordinary irreducible characters of $B$, we determine the ordinary characters of\nall trivial source $B$-modules.","main_category":"math.RT","categories":"math.RT","published":"2025-03-27T17:09:40Z"}
{"aid":"http://arxiv.org/abs/2503.21710v1","title":"Enhancing Repository-Level Software Repair via Repository-Aware\n  Knowledge Graphs","summary":"Repository-level software repair faces challenges in bridging semantic gaps\nbetween issue descriptions and code patches. Existing approaches, which mostly\ndepend on large language models (LLMs), suffer from semantic ambiguities,\nlimited structural context understanding, and insufficient reasoning\ncapability. To address these limitations, we propose KGCompass with two\ninnovations: (1) a novel repository-aware knowledge graph (KG) that accurately\nlinks repository artifacts (issues and pull requests) and codebase entities\n(files, classes, and functions), allowing us to effectively narrow down the\nvast search space to only 20 most relevant functions with accurate candidate\nbug locations and contextual information, and (2) a path-guided repair\nmechanism that leverages KG-mined entity path, tracing through which allows us\nto augment LLMs with relevant contextual information to generate precise\npatches along with their explanations. Experimental results in the\nSWE-Bench-Lite demonstrate that KGCompass achieves state-of-the-art repair\nperformance (45.67%) and function-level localization accuracy (51.33%) across\nopen-source approaches, costing only $0.20 per repair. Our analysis reveals\nthat among successfully localized bugs, 69.7% require multi-hop traversals\nthrough the knowledge graph, without which LLM-based approaches struggle to\naccurately locate bugs. The knowledge graph built in KGCompass is language\nagnostic and can be incrementally updated, making it a practical solution for\nreal-world development environments.","main_category":"cs.SE","categories":"cs.SE","published":"2025-03-27T17:21:47Z"}
{"aid":"http://arxiv.org/abs/2503.21719v1","title":"The Principle of Redundant Reflection","summary":"The fact that redundant information does not change a rational belief after\nBayesian updating implies uniqueness of Bayes rule. In fact, any updating rule\nis uniquely specified by this principle. This is true for the classical\nsetting, as well as settings with improper or continuous priors. We prove this\nresult and illustrate it with two examples.","main_category":"stat.ME","categories":"stat.ME,stat.OT","published":"2025-03-27T17:31:22Z"}
{"aid":"http://arxiv.org/abs/2503.21732v1","title":"SparseFlex: High-Resolution and Arbitrary-Topology 3D Shape Modeling","summary":"Creating high-fidelity 3D meshes with arbitrary topology, including open\nsurfaces and complex interiors, remains a significant challenge. Existing\nimplicit field methods often require costly and detail-degrading watertight\nconversion, while other approaches struggle with high resolutions. This paper\nintroduces SparseFlex, a novel sparse-structured isosurface representation that\nenables differentiable mesh reconstruction at resolutions up to $1024^3$\ndirectly from rendering losses. SparseFlex combines the accuracy of Flexicubes\nwith a sparse voxel structure, focusing computation on surface-adjacent regions\nand efficiently handling open surfaces. Crucially, we introduce a frustum-aware\nsectional voxel training strategy that activates only relevant voxels during\nrendering, dramatically reducing memory consumption and enabling\nhigh-resolution training. This also allows, for the first time, the\nreconstruction of mesh interiors using only rendering supervision. Building\nupon this, we demonstrate a complete shape modeling pipeline by training a\nvariational autoencoder (VAE) and a rectified flow transformer for high-quality\n3D shape generation. Our experiments show state-of-the-art reconstruction\naccuracy, with a ~82% reduction in Chamfer Distance and a ~88% increase in\nF-score compared to previous methods, and demonstrate the generation of\nhigh-resolution, detailed 3D shapes with arbitrary topology. By enabling\nhigh-resolution, differentiable mesh reconstruction and generation with\nrendering losses, SparseFlex significantly advances the state-of-the-art in 3D\nshape representation and modeling.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:46:42Z"}
{"aid":"http://arxiv.org/abs/2503.21756v1","title":"A Unified Framework for Diffusion Bridge Problems: Flow Matching and\n  Schr√∂dinger Matching into One","summary":"The bridge problem is to find an SDE (or sometimes an ODE) that bridges two\ngiven distributions. The application areas of the bridge problem are enormous,\namong which the recent generative modeling (e.g., conditional or unconditional\nimage generation) is the most popular. Also the famous Schr\\\"{o}dinger bridge\nproblem, a widely known problem for a century, is a special instance of the\nbridge problem. Two most popular algorithms to tackle the bridge problems in\nthe deep learning era are: (conditional) flow matching and iterative fitting\nalgorithms, where the former confined to ODE solutions, and the latter\nspecifically for the Schr\\\"{o}dinger bridge problem. The main contribution of\nthis article is in two folds: i) We provide concise reviews of these algorithms\nwith technical details to some extent; ii) We propose a novel unified\nperspective and framework that subsumes these seemingly unrelated algorithms\n(and their variants) into one. In particular, we show that our unified\nframework can instantiate the Flow Matching (FM) algorithm, the (mini-batch)\noptimal transport FM algorithm, the (mini-batch) Schr\\\"{o}dinger bridge FM\nalgorithm, and the deep Schr\\\"{o}dinger bridge matching (DSBM) algorithm as its\nspecial cases. We believe that this unified framework will be useful for\nviewing the bridge problems in a more general and flexible perspective, and in\nturn can help researchers and practitioners to develop new bridge algorithms in\ntheir fields.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-27T17:57:03Z"}
{"aid":"http://arxiv.org/abs/2503.21757v1","title":"Fwd2Bot: LVLM Visual Token Compression with Double Forward Bottleneck","summary":"In this work, we aim to compress the vision tokens of a Large Vision Language\nModel (LVLM) into a representation that is simultaneously suitable for (a)\ngenerative and (b) discriminative tasks, (c) is nearly lossless, and (d) is\nstorage-efficient. We propose a novel compression approach, called Fwd2Bot,\nthat uses the LVLM itself to compress the visual information in a task-agnostic\nmanner. At the core of Fwd2bot there exists a \"double-forward pass\" training\nstrategy, whereby, during the first forward pass, the LLM (of the LVLM) creates\na bottleneck by condensing the visual information into a small number of\nsummary tokens. Then, using the same LLM, the second forward pass processes the\nlanguage instruction(s) alongside the summary tokens, used as a direct\nreplacement for the image ones. The training signal is provided by two losses:\nan autoregressive one applied after the second pass that provides a direct\noptimization objective for compression, and a contrastive loss, applied after\nthe first pass, that further boosts the representation strength, especially for\ndiscriminative tasks. The training is further enhanced by stage-specific\nadapters. We accompany the proposed method by an in-depth ablation study.\nOverall, Fwd2Bot results in highly-informative compressed representations\nsuitable for both generative and discriminative tasks. For generative tasks, we\noffer a 2x higher compression rate without compromising the generative\ncapabilities, setting a new state-of-the-art result. For discriminative tasks,\nwe set a new state-of-the-art on image retrieval and compositionality.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-03-27T17:57:07Z"}
{"aid":"http://arxiv.org/abs/2503.21767v1","title":"Semantic Consistent Language Gaussian Splatting for Point-Level\n  Open-vocabulary Querying","summary":"Open-vocabulary querying in 3D Gaussian Splatting aims to identify\nsemantically relevant regions within a 3D Gaussian representation based on a\ngiven text query. Prior work, such as LangSplat, addressed this task by\nretrieving these regions in the form of segmentation masks on 2D renderings.\nMore recently, OpenGaussian introduced point-level querying, which directly\nselects a subset of 3D Gaussians. In this work, we propose a point-level\nquerying method that builds upon LangSplat's framework. Our approach improves\nthe framework in two key ways: (a) we leverage masklets from the Segment\nAnything Model 2 (SAM2) to establish semantic consistent ground-truth for\ndistilling the language Gaussians; (b) we introduces a novel two-step querying\napproach that first retrieves the distilled ground-truth and subsequently uses\nthe ground-truth to query the individual Gaussians. Experimental evaluations on\nthree benchmark datasets demonstrate that the proposed method achieves better\nperformance compared to state-of-the-art approaches. For instance, our method\nachieves an mIoU improvement of +20.42 on the 3D-OVS dataset.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:05Z"}
{"aid":"http://arxiv.org/abs/2503.21770v1","title":"Visual Jenga: Discovering Object Dependencies via Counterfactual\n  Inpainting","summary":"This paper proposes a novel scene understanding task called Visual Jenga.\nDrawing inspiration from the game Jenga, the proposed task involves\nprogressively removing objects from a single image until only the background\nremains. Just as Jenga players must understand structural dependencies to\nmaintain tower stability, our task reveals the intrinsic relationships between\nscene elements by systematically exploring which objects can be removed while\npreserving scene coherence in both physical and geometric sense. As a starting\npoint for tackling the Visual Jenga task, we propose a simple, data-driven,\ntraining-free approach that is surprisingly effective on a range of real-world\nimages. The principle behind our approach is to utilize the asymmetry in the\npairwise relationships between objects within a scene and employ a large\ninpainting model to generate a set of counterfactuals to quantify the\nasymmetry.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:33Z"}
{"aid":"http://arxiv.org/abs/2503.23734v1","title":"Semantic Packet Aggregation and Repeated Transmission for Text-to-Image\n  Generation","summary":"Text-based communication is expected to be prevalent in 6G applications such\nas wireless AI-generated content (AIGC). Motivated by this, this paper\naddresses the challenges of transmitting text prompts over erasure channels for\na text-to-image AIGC task by developing the semantic segmentation and repeated\ntransmission (SMART) algorithm. SMART groups words in text prompts into\npackets, prioritizing the task-specific significance of semantics within these\npackets, and optimizes the number of repeated transmissions. Simulation results\nshow that SMART achieves higher similarities in received texts and generated\nimages compared to a character-level packetization baseline, while reducing\ncomputing latency by orders of magnitude compared to an exhaustive search\nbaseline.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T05:14:40Z"}
{"aid":"http://arxiv.org/abs/2503.23735v1","title":"Altermagnetism and Weak Ferromagnetism","summary":"Using a realistic model relevant to La$_2$CuO$_4$ and other altermagnetic\nperovskite oxides, we study interrelations between weak ferromagnetism (WF),\nanomalous Hall effect (AHE), and net orbital magnetization (OM). All of them\ncan be linked to the form of Dzyaloshinskii-Moriya (DM) interactions.\nNevertheless, while spin WF is induced by the DM vector components having the\nsame sign in all equivalent bonds, AHE and OM are related to alternating-sign\ncomponents, which do not contribute to any canting of spins. The microscopic\nmodel remains invariant under the symmetry operation $\\{ \\mathcal{S}|{\\bf t}\n\\}$, combining the shift ${\\bf t}$ of antiferromagnetically coupled sublattices\nto each other with the spin flip $\\mathcal{S}$. Thus, the band structure\nremains Kramers-degenerate, but the time-reversal symmetry is broken, providing\na possibility to realize AHE in antiferromagnetic substances. The altermagnetic\nsplitting of bands, breaking the $\\{ \\mathcal{S}|{\\bf t}\\}$ symmetry, does not\nplay a major role in the problem. More important is the orthorhombic strain,\nresponsible for finite values of AHE and OM.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-03-31T05:15:47Z"}
{"aid":"http://arxiv.org/abs/2503.23758v1","title":"Exact Solution of the Frustrated Potts Model with Next-Nearest-Neighbor\n  Interactions in One Dimension: An AI-Aided Discovery","summary":"The one-dimensional $J_1$-$J_2$ $q$-state Potts model is solved exactly for\narbitrary $q$, based on using OpenAI's latest reasoning model o3-mini-high to\nexactly solve the $q=3$ case. The exact results provide insights to outstanding\nphysical problems such as the stacking of atomic or electronic orders in\nlayered materials and the formation of a $T_c$-dome-shaped phase often seen in\nunconventional superconductors. The work is anticipated to fuel both the\nresearch in one-dimensional frustrated magnets for recently discovered\nfinite-temperature application potentials and the fast moving topic area of AI\nfor sciences.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,math-ph,math.MP","published":"2025-03-31T06:16:26Z"}
{"aid":"http://arxiv.org/abs/2503.23776v1","title":"VIDEX: A Disaggregated and Extensible Virtual Index for the Cloud and AI\n  Era","summary":"Virtual index, also known as hypothetical indexes, play a crucial role in\ndatabase query optimization. However, with the rapid advancement of cloud\ncomputing and AI-driven models for database optimization, traditional virtual\nindex approaches face significant challenges. Cloud-native environments often\nprohibit direct conducting query optimization process on production databases\ndue to stability requirements and data privacy concerns. Moreover, while AI\nmodels show promising progress, their integration with database systems poses\nchallenges in system complexity, inference acceleration, and model hot updates.\nIn this paper, we present VIDEX, a three-layer disaggregated architecture that\ndecouples database instances, the virtual index optimizer, and algorithm\nservices, providing standardized interfaces for AI model integration. Users can\nconfigure VIDEX by either collecting production statistics or by loading from a\nprepared file; this setup allows for high-accurate what-if analyses based on\nvirtual indexes, achieving query plans that are identical to those of the\nproduction instance. Additionally, users can freely integrate new AI-driven\nalgorithms into VIDEX. VIDEX has been successfully deployed at ByteDance,\nserving thousands of MySQL instances daily and over millions of SQL queries for\nindex optimization tasks.","main_category":"cs.DB","categories":"cs.DB","published":"2025-03-31T06:52:13Z"}
{"aid":"http://arxiv.org/abs/2503.23796v1","title":"On-device Sora: Enabling Training-Free Diffusion-based Text-to-Video\n  Generation for Mobile Devices","summary":"We present On-device Sora, the first model training-free solution for\ndiffusion-based on-device text-to-video generation that operates efficiently on\nsmartphone-grade devices. To address the challenges of diffusion-based\ntext-to-video generation on computation- and memory-limited mobile devices, the\nproposed On-device Sora applies three novel techniques to pre-trained video\ngenerative models. First, Linear Proportional Leap (LPL) reduces the excessive\ndenoising steps required in video diffusion through an efficient leap-based\napproach. Second, Temporal Dimension Token Merging (TDTM) minimizes intensive\ntoken-processing computation in attention layers by merging consecutive tokens\nalong the temporal dimension. Third, Concurrent Inference with Dynamic Loading\n(CI-DL) dynamically partitions large models into smaller blocks and loads them\ninto memory for concurrent model inference, effectively addressing the\nchallenges of limited device memory. We implement On-device Sora on the iPhone\n15 Pro, and the experimental evaluations show that it is capable of generating\nhigh-quality videos on the device, comparable to those produced by high-end\nGPUs. These results show that On-device Sora enables efficient and high-quality\nvideo generation on resource-constrained mobile devices. We envision the\nproposed On-device Sora as a significant first step toward democratizing\nstate-of-the-art generative technologies, enabling video generation on\ncommodity mobile and embedded devices without resource-intensive re-training\nfor model optimization (compression). The code implementation is available at a\nGitHub repository(https://github.com/eai-lab/On-device-Sora).","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T07:19:09Z"}
{"aid":"http://arxiv.org/abs/2503.23808v1","title":"Why does tinnitus vary with naps? A polysomnographic prospective study\n  exploring the somatosensory hypothesis","summary":"Background: Tinnitus, defined as the conscious awareness of a noise without\nany identifiable corresponding external acoustic source, can be modulated by\nvarious factors. Among these factors, tinnitus patients commonly report drastic\nincreases of tinnitus loudness following nap sleep. Previous studies have\nsuggested that this clinical pattern could be attributed to a somatosensory\nmodulation of tinnitus. To our knowledge, no polysomnographic study has been\ncarried out to assess this hypothesis. Methods: For this observational\nprospective study, 37 participants reporting frequent increases of tinnitus\nfollowing naps were recruited. They participated to six full-polysomnography\nnap attempts over two days. Audiological and kinesiologic tests were conducted\nbefore and after each nap attempt. Results: 197 naps were collected. Each nap\nat each time of day elicited an overall significant increase in tinnitus\nminimum masking level (MML). Each inter nap period elicited an overall\nsignificant decrease. Tinnitus modulations were found significantly correlated\nwith nap sleep duration (Visual numeric scale on tinnitus loudness, VNS-L, p <\n0.05), with snoring duration (MML, p < 0.001), with snoring average sound level\n(VNS on tinnitus intrusiveness, VNS-I, p < 0.05) and with sleep apnea count\n(VNS-I, p < 0.001). Conclusions: This study confirms objectively that tinnitus\nmay increase following naps. No association was found between these modulations\nand somatosensory modulations involving the temporomandibular joint and\ncervical areas. However, it may be possible that nap-induced tinnitus\nmodulations are a hidden form of somatosensory modulation as snoring and sleep\napnea events are often related to tensor veli palatini muscle dysfunction.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-03-31T07:42:33Z"}
{"aid":"http://arxiv.org/abs/2503.23835v1","title":"Disambiguate Gripper State in Grasp-Based Tasks: Pseudo-Tactile as\n  Feedback Enables Pure Simulation Learning","summary":"Grasp-based manipulation tasks are fundamental to robots interacting with\ntheir environments, yet gripper state ambiguity significantly reduces the\nrobustness of imitation learning policies for these tasks. Data-driven\nsolutions face the challenge of high real-world data costs, while simulation\ndata, despite its low costs, is limited by the sim-to-real gap. We identify the\nroot cause of gripper state ambiguity as the lack of tactile feedback. To\naddress this, we propose a novel approach employing pseudo-tactile as feedback,\ninspired by the idea of using a force-controlled gripper as a tactile sensor.\nThis method enhances policy robustness without additional data collection and\nhardware involvement, while providing a noise-free binary gripper state\nobservation for the policy and thus facilitating pure simulation learning to\nunleash the power of simulation. Experimental results across three real-world\ngrasp-based tasks demonstrate the necessity, effectiveness, and efficiency of\nour approach.","main_category":"cs.RO","categories":"cs.RO","published":"2025-03-31T08:29:17Z"}
{"aid":"http://arxiv.org/abs/2503.23858v1","title":"Incremental capacity-based multi-feature fusion model for predicting\n  state-of-health of lithium-ion batteries","summary":"Lithium-ion batteries have become an indispensable part of human industrial\nproduction and daily life. For the safe use, management and maintenance of\nlithium-ion batteries, the state of health (SOH) of lithium-ion batteries is an\nimportant indicator so that the SOH estimation is of significant practical\nvalue. In order to accurately predict SOH, this paper proposes a fusion\nprediction model which combines particle swarm optimization (PSO) algorithm,\nbi-directional long-short time memory network (BiLSTM) and adaptive boosting\n(AdaBoost) algorithm. In the proposed prediction model, indirect health\nindicators (HIs), which characterize battery degradation, are obtained with the\nhelp of incremental capacity analysis (ICA), and is fed into BiLSTM to extract\ntime-series features, whose parameters are optimized by employing PSO\nalgorithm. On this basis, the AdaBoost algorithm is applied to reduce the risk\nof overfitting the PSO-BiLSTM model. The study based on lithium-ion battery\ndata from Center for Advanced Life Cycle Engineering (CALCE) shows that the\nPSO-BiLSTM-AdaBoost model has higher accuracy, better robustness, and\ngeneralization ability.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-03-31T09:05:56Z"}
{"aid":"http://arxiv.org/abs/2503.23876v1","title":"Populations of evolved massive binary stars in the Small Magellanic\n  Cloud I: Predictions from detailed evolution models","summary":"Context. The majority of massive stars are born with a close binary\ncompanion. How this affects their evolution and fate is still largely\nuncertain, especially at low metallicity. Aims. We derive synthetic populations\nof massive post-interaction binary products and compare them with corresponding\nobserved populations in the Small Magellanic Cloud (SMC). Methods. We analyse\n53298 detailed binary evolutionary models computed with MESA. Our models\ninclude the physics of rotation, mass and angular momentum transfer, magnetic\ninternal angular momentum transport, and tidal spin-orbit coupling. They cover\ninitial primary masses of 5-100Msun, initial mass ratios of 0.3-0.95, and all\ninitial periods for which interaction is expected. They are evolved through the\nfirst mass transfer and the donor star death, a possible ensuing Be/X-ray\nbinary phase, and they end when the mass gainer leaves the main sequence.\nResults.In our fiducial synthetic population, 8% of the OB stars in the SMC are\npost-mass transfer systems, and 7% are merger products. In many of our models,\nthe mass gainers are spun up and form Oe/Be stars. While our model\nunderpredicts the number of Be/X-ray binaries in the SMC, it reproduces the\nmain features of their orbital period distribution and the observed number of\nSMC binary WR stars. We expect $\\sim$50 OB+BH binaries below and $\\sim$170\nabove 20d orbital period. The latter might produce merging double BHs. However,\ntheir progenitors, the predicted long-period WR+OB binaries, are not observed.\nConclusions. While the comparison with the observed SMC stars supports many\nphysics assumptions in our high-mass binary models, a better match of the large\nnumber of observed OBe stars and Be/X-ray binaries likely requires a lower\nmerger rate and/or a higher mass transfer efficiency during the first mass\ntransfer. The fate of the initially wide O star binaries remains uncertain.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA,astro-ph.HE","published":"2025-03-31T09:26:52Z"}
{"aid":"http://arxiv.org/abs/2503.23896v1","title":"Feature learning from non-Gaussian inputs: the case of Independent\n  Component Analysis in high dimensions","summary":"Deep neural networks learn structured features from complex, non-Gaussian\ninputs, but the mechanisms behind this process remain poorly understood. Our\nwork is motivated by the observation that the first-layer filters learnt by\ndeep convolutional neural networks from natural images resemble those learnt by\nindependent component analysis (ICA), a simple unsupervised method that seeks\nthe most non-Gaussian projections of its inputs. This similarity suggests that\nICA provides a simple, yet principled model for studying feature learning.\nHere, we leverage this connection to investigate the interplay between data\nstructure and optimisation in feature learning for the most popular ICA\nalgorithm, FastICA, and stochastic gradient descent (SGD), which is used to\ntrain deep networks. We rigorously establish that FastICA requires at least\n$n\\gtrsim d^4$ samples to recover a single non-Gaussian direction from\n$d$-dimensional inputs on a simple synthetic data model. We show that vanilla\nonline SGD outperforms FastICA, and prove that the optimal sample complexity $n\n\\gtrsim d^2$ can be reached by smoothing the loss, albeit in a data-dependent\nway. We finally demonstrate the existence of a search phase for FastICA on\nImageNet, and discuss how the strong non-Gaussianity of said images compensates\nfor the poor sample complexity of FastICA.","main_category":"stat.ML","categories":"stat.ML,cond-mat.dis-nn,cond-mat.stat-mech,cs.LG,math.PR","published":"2025-03-31T09:46:47Z"}
{"aid":"http://arxiv.org/abs/2503.23899v1","title":"Rubrik's Cube: Testing a New Rubric for Evaluating Explanations on the\n  CUBE dataset","summary":"The performance and usability of Large-Language Models (LLMs) are driving\ntheir use in explanation generation tasks. However, despite their widespread\nadoption, LLM explanations have been found to be unreliable, making it\ndifficult for users to distinguish good from bad explanations. To address this\nissue, we present Rubrik's CUBE, an education-inspired rubric and a dataset of\n26k explanations, written and later quality-annotated using the rubric by both\nhumans and six open- and closed-source LLMs. The CUBE dataset focuses on two\nreasoning and two language tasks, providing the necessary diversity for us to\neffectively test our proposed rubric. Using Rubrik, we find that explanations\nare influenced by both task and perceived difficulty. Low quality stems\nprimarily from a lack of conciseness in LLM-generated explanations, rather than\ncohesion and word choice. The full dataset, rubric, and code will be made\navailable upon acceptance.","main_category":"cs.CL","categories":"cs.CL,I.2.7","published":"2025-03-31T09:48:59Z"}
{"aid":"http://arxiv.org/abs/2503.23923v1","title":"What the F*ck Is Artificial General Intelligence?","summary":"Artificial general intelligence (AGI) is an established field of research.\nYet Melanie Mitchell and others have questioned if the term still has meaning.\nAGI has been subject to so much hype and speculation it has become something of\na Rorschach test. Mitchell points out that the debate will only be settled\nthrough long term, scientific investigation. To that end here is a short,\naccessible and provocative overview of AGI. I compare definitions of\nintelligence, settling on intelligence in terms of adaptation and AGI as an\nartificial scientist. Taking my queue from Sutton's Bitter Lesson I describe\ntwo foundational tools used to build adaptive systems: search and\napproximation. I compare pros, cons, hybrids and architectures like o3,\nAlphaGo, AERA, NARS and Hyperon. I then discuss overall meta-approaches to\nmaking systems behave more intelligently. I divide them into scale-maxing,\nsimp-maxing, w-maxing based on the Bitter Lesson, Ockham's and Bennett's\nRazors. These maximise resources, simplicity of form, and the weakness of\nconstraints on functionality. I discuss examples including AIXI, the free\nenergy principle and The Embiggening of language models. I conclude that though\nscale-maxed approximation dominates, AGI will be a fusion of tools and\nmeta-approaches. The Embiggening was enabled by improvements in hardware. Now\nthe bottlenecks are sample and energy efficiency.","main_category":"cs.AI","categories":"cs.AI","published":"2025-03-31T10:15:37Z"}
{"aid":"http://arxiv.org/abs/2503.23937v1","title":"Electromagnetic multipole expansions and the logarithmic soft photon\n  theorem","summary":"We study the general structure of the electromagnetic field in the vicinity\nof spatial infinity. Starting from the general solution of the sourced Maxwell\nequations written in terms of multipole moments as obtained by Iyer and Damour,\nwe derive the expansion of the electromagnetic field perturbatively in the\nelectromagnetic coupling. At leading order, where the effect of long-range\nCoulombic interactions between charged particles is neglected, we discover\ninfinite sets of antipodal matching relations satisfied by the electromagnetic\nfield, which extend and sometimes correct previously known relations. At\nnext-to-leading order, electromagnetic tails resulting from these Coulombic\ninteractions appear, which affect the antipodal matching relations beyond those\nequivalent to the leading soft photon theorem. Moreover, new antipodal matching\nrelations arise, which we use to re-derive the classical logarithmic soft\nphoton theorem of Sahoo and Sen. Our analysis largely builds upon that of\nCampiglia and Laddha, although it invalidates the antipodal matching relation\nwhich they originally used in their derivation.","main_category":"hep-th","categories":"hep-th","published":"2025-03-31T10:35:22Z"}
{"aid":"http://arxiv.org/abs/2503.23966v1","title":"Machine Learning-assisted High-speed Combinatorial Optimization with\n  Ising Machines for Dynamically Changing Problems","summary":"Quantum or quantum-inspired Ising machines have recently shown promise in\nsolving combinatorial optimization problems in a short time. Real-world\napplications, such as time division multiple access (TDMA) scheduling for\nwireless multi-hop networks and financial trading, require solving those\nproblems sequentially where the size and characteristics change dynamically.\nHowever, using Ising machines involves challenges to shorten system-wide\nlatency due to the transfer of large Ising model or the cloud access and to\ndetermine the parameters for each problem. Here we show a combinatorial\noptimization method using embedded Ising machines, which enables solving\ndiverse problems at high speed without runtime parameter tuning. We customize\nthe algorithm and circuit architecture of the simulated bifurcation-based Ising\nmachine to compress the Ising model and accelerate computation and then built a\nmachine learning model to estimate appropriate parameters using extensive\ntraining data. In TDMA scheduling for wireless multi-hop networks, our\ndemonstration has shown that the sophisticated system can adapt to changes in\nthe problem and showed that it has a speed advantage over conventional methods.","main_category":"cs.ET","categories":"cs.ET,cs.LG","published":"2025-03-31T11:31:36Z"}
{"aid":"http://arxiv.org/abs/2503.23974v1","title":"Revealing the Low Temperature Phase of FAPbI$_3$ using Machine-Learned\n  Potential","summary":"FAPbI$_3$ is a material of interest for its potential in solar cell\napplications, driven by its remarkable optoelectronic properties. However, the\nlow-temperature phase of FAPbI$_3$ remains poorly understood, with open\nquestions surrounding its crystal structure, octahedral tilting, and the\narrangement of formamidinium (FA) cations. Using our trained machine-learned\npotential in combination with large-scale molecular dynamics simulations, we\nprovide a detailed investigation of this phase, uncovering its structural\ncharacteristics and dynamical behavior. Our analysis reveals the octahedral\ntilt pattern and sheds light on the rotational dynamics of FA cations in the\nlow temperature phase. Strikingly, we find that the FA cations become frozen in\na metastable configuration, unable to reach the thermodynamic ground state. By\ncomparing our simulated results with experimental nuclear magnetic resonance\n(NMR) and inelastic neutron scattering (INS) spectra, we demonstrate good\nagreement, further validating our findings. This phenomenon mirrors\nexperimental observations and offers a compelling explanation for the\nexperimental challenges in accessing the true ground state. These findings\nprovide critical insights into the fundamental physics of FAPbI$_3$ and its\nlow-temperature behavior, advancing our understanding of this technologically\nimportant material.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-31T11:36:16Z"}
{"aid":"http://arxiv.org/abs/2503.24008v1","title":"H2VU-Benchmark: A Comprehensive Benchmark for Hierarchical Holistic\n  Video Understanding","summary":"With the rapid development of multimodal models, the demand for assessing\nvideo understanding capabilities has been steadily increasing. However,\nexisting benchmarks for evaluating video understanding exhibit significant\nlimitations in coverage, task diversity, and scene adaptability. These\nshortcomings hinder the accurate assessment of models' comprehensive video\nunderstanding capabilities. To tackle this challenge, we propose a hierarchical\nand holistic video understanding (H2VU) benchmark designed to evaluate both\ngeneral video and online streaming video comprehension. This benchmark\ncontributes three key features:\n  Extended video duration: Spanning videos from brief 3-second clips to\ncomprehensive 1.5-hour recordings, thereby bridging the temporal gaps found in\ncurrent benchmarks. Comprehensive assessment tasks: Beyond traditional\nperceptual and reasoning tasks, we have introduced modules for\ncountercommonsense comprehension and trajectory state tracking. These additions\ntest the models' deep understanding capabilities beyond mere prior knowledge.\nEnriched video data: To keep pace with the rapid evolution of current AI\nagents, we have expanded first-person streaming video datasets. This expansion\nallows for the exploration of multimodal models' performance in understanding\nstreaming videos from a first-person perspective. Extensive results from H2VU\nreveal that existing multimodal large language models (MLLMs) possess\nsubstantial potential for improvement in our newly proposed evaluation tasks.\nWe expect that H2VU will facilitate advancements in video understanding\nresearch by offering a comprehensive and in-depth analysis of MLLMs.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T12:32:51Z"}
{"aid":"http://arxiv.org/abs/2503.24013v1","title":"You Cannot Feed Two Birds with One Score: the Accuracy-Naturalness\n  Tradeoff in Translation","summary":"The goal of translation, be it by human or by machine, is, given some text in\na source language, to produce text in a target language that simultaneously 1)\npreserves the meaning of the source text and 2) achieves natural expression in\nthe target language. However, researchers in the machine translation community\nusually assess translations using a single score intended to capture semantic\naccuracy and the naturalness of the output simultaneously. In this paper, we\nbuild on recent advances in information theory to mathematically prove and\nempirically demonstrate that such single-score summaries do not and cannot give\nthe complete picture of a system's true performance. Concretely, we prove that\na tradeoff exists between accuracy and naturalness and demonstrate it by\nevaluating the submissions to the WMT24 shared task. Our findings help explain\nwell-known empirical phenomena, such as the observation that optimizing\ntranslation systems for a specific accuracy metric (like BLEU) initially\nimproves the system's naturalness, while ``overfitting'' the system to the\nmetric can significantly degrade its naturalness. Thus, we advocate for a\nchange in how translations are evaluated: rather than comparing systems using a\nsingle number, they should be compared on an accuracy-naturalness plane.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T12:39:51Z"}
{"aid":"http://arxiv.org/abs/2503.24023v1","title":"Coherent microwave control of coupled electron-muon centers","summary":"Coherent control by means of tailored excitation is a key to versatile\nexperimental schemes for spectroscopic investigation and technological\nutilization of quantum systems. Here we study a quantum system which consists\nof a coupled electron-moun spin state, i.e., muonium, a light isotope of\nhydrogen. We demonstrate the most fundamental coherent control techniques by\nmicrowave excitation of spin transitions, namely driven Rabi oscillations and\nRamsey fringes upon free evolution. Unprecedented performance is achieved by\nthe microwave hardware devised for these experiments, which enables coherent\nspin manipulation of individual, isolated, muonium centers. For muonium formed\nin SiO$_2$ with strong electron-muon hyperfine interaction, a virtually\nundamped free precession signal is observed up to a 3.5 $\\mu$s time window. For\nmuonium formed in Si with weak and anisotropic hyperfine interaction, a strong\ndrive at the multi-quantum transition decouples the muonium center from its\nmagnetic environment formed by the bath of $^{29}$Si nuclear spins at natural\nabundance. We expect that these capabilities will provide a powerful tool to\ninvestigate the effect of the environment on isolated coupled spins, uncover\nthe details of coupled electron-muon systems in matter and validate quantum\nelectrodynamics in the context of muonium spectroscopy.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T12:50:05Z"}
{"aid":"http://arxiv.org/abs/2503.24029v1","title":"Global Well-Posedness of the 3D Navier-Stokes Equations under\n  Multi-Level Logarithmically Improved Criteria","summary":"This paper extends our previous results on logarithmically improved\nregularity criteria for the three-dimensional Navier-Stokes equations by\nestablishing a comprehensive framework of multi-level logarithmic improvements.\nWe prove that if the initial data $u_0 \\in L^2(\\mathbb{R}^3)$ satisfies a\nnested logarithmically weakened condition\n$\\|(-\\Delta)^{s/2}u_0\\|_{L^q(\\mathbb{R}^3)} \\leq \\frac{C_0}{\\prod_{j=1}^{n} (1\n+ L_j(\\|u_0\\|_{\\dot{H}^s}))^{\\delta_j}}$ for some $s \\in (1/2, 1)$, where $L_j$\nrepresents $j$-fold nested logarithms, then the corresponding solution exists\nglobally in time and is unique. The proof introduces a novel sequence of\nincreasingly precise commutator estimates incorporating multiple layers of\nlogarithmic corrections. We establish the existence of a critical threshold\nfunction $\\Phi(s,q,\\{\\delta_j\\}_{j=1}^n)$ that completely characterizes the\nboundary between global regularity and potential singularity formation, with\nexplicit asymptotics as $s$ approaches the critical value $1/2$. This paper\nfurther provides a rigorous geometric characterization of potential singular\nstructures through refined multi-fractal analysis, showing that any singular\nset must have Hausdorff dimension bounded by $1 - \\sum_{j=1}^n\n\\frac{\\delta_j}{1+\\delta_j} \\cdot \\frac{1}{j+1}$. Our results constitute a\nsignificant advancement toward resolving the global regularity question for the\nNavier-Stokes equations, as we demonstrate that with properly calibrated\nsequences of nested logarithmic improvements, the gap to the critical case can\nbe systematically reduced.","main_category":"math.AP","categories":"math.AP","published":"2025-03-31T12:55:30Z"}
{"aid":"http://arxiv.org/abs/2503.24033v1","title":"Independence of $\\ell$","summary":"We prove independence of $\\ell$ for Betti numbers as well as for\ncharacteristic polynomials of motivically defined endomorphisms of $\\ell$-adic\ncohomology. This long standing problem is solved through the construction of\nnew comparison isomorphisms relating $\\ell$-adic cohomology of a separated\nscheme of finite type over an algebraically closed field of positive\ncharacteristic with its rigid cohomology. Taking advantage of the description\nof categories of $\\ell$-adic sheaves of geometric origin as categories of\nmodules over $\\ell$-adic cohomology in the stable category of motivic sheaves,\nthese independence of $\\ell$-results are promoted to independence of $\\ell$ of\nsuitable categories of $\\ell$-adic sheaves themselves.","main_category":"math.AG","categories":"math.AG,math.KT,math.NT","published":"2025-03-31T12:59:51Z"}
{"aid":"http://arxiv.org/abs/2503.24046v1","title":"Contrasting exchange-field and spin-transfer torque driving mechanisms\n  in all-electric electron spin resonance","summary":"Understanding the coherent properties of electron spins driven by electric\nfields is crucial for their potential application in quantum-coherent\nnanoscience. In this work, we address two distinct driving mechanisms in\nelectric-field driven electron-spin resonance as implemented in scanning\ntunneling spectroscopy. We study the origin of the driving field using a single\norbital Anderson impurity, connected to polarized leads and biased by a voltage\nmodulated on resonance with a spin transition. By mapping the quantum master\nequation into a system of equations for the impurity spin, we identify two\ndistinct driving mechanisms. Below the charging thresholds of the impurity,\nelectron spin resonance is dominated by a magnetically exchange-driven\nmechanism or field-like torque. Conversely, above the charging threshold\nspin-transfer torque caused by the spin-polarized current through the impurity\ndrives the spin transition. Only the first mechanism enables coherent quantum\nspin control, while the second one leads to fast decoherence and spin\naccumulation towards a non-equilibrium steady-state. The electron spin\nresonance signals and spin dynamics vary significantly depending on which\ndriving mechanism dominates, highlighting the potential for optimizing\nquantum-coherent control in electrically driven quantum systems.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,quant-ph","published":"2025-03-31T13:10:22Z"}
{"aid":"http://arxiv.org/abs/2503.24057v1","title":"AMMSM: Adaptive Motion Magnification and Sparse Mamba for\n  Micro-Expression Recognition","summary":"Micro-expressions are typically regarded as unconscious manifestations of a\nperson's genuine emotions. However, their short duration and subtle signals\npose significant challenges for downstream recognition. We propose a multi-task\nlearning framework named the Adaptive Motion Magnification and Sparse Mamba\n(AMMSM) to address this. This framework aims to enhance the accurate capture of\nmicro-expressions through self-supervised subtle motion magnification, while\nthe sparse spatial selection Mamba architecture combines sparse activation with\nthe advanced Visual Mamba model to model key motion regions and their valuable\nrepresentations more effectively. Additionally, we employ evolutionary search\nto optimize the magnification factor and the sparsity ratios of spatial\nselection, followed by fine-tuning to improve performance further. Extensive\nexperiments on two standard datasets demonstrate that the proposed AMMSM\nachieves state-of-the-art (SOTA) accuracy and robustness.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T13:17:43Z"}
{"aid":"http://arxiv.org/abs/2503.24062v1","title":"Artificial Conversations, Real Results: Fostering Language Detection\n  with Synthetic Data","summary":"Collecting high-quality training data is essential for fine-tuning Large\nLanguage Models (LLMs). However, acquiring such data is often costly and\ntime-consuming, especially for non-English languages such as Italian. Recently,\nresearchers have begun to explore the use of LLMs to generate synthetic\ndatasets as a viable alternative. This study proposes a pipeline for generating\nsynthetic data and a comprehensive approach for investigating the factors that\ninfluence the validity of synthetic data generated by LLMs by examining how\nmodel performance is affected by metrics such as prompt strategy, text length\nand target position in a specific task, i.e. inclusive language detection in\nItalian job advertisements. Our results show that, in most cases and across\ndifferent metrics, the fine-tuned models trained on synthetic data consistently\noutperformed other models on both real and synthetic test datasets. The study\ndiscusses the practical implications and limitations of using synthetic data\nfor language detection tasks with LLMs.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-03-31T13:22:34Z"}
{"aid":"http://arxiv.org/abs/2503.24071v1","title":"From Colors to Classes: Emergence of Concepts in Vision Transformers","summary":"Vision Transformers (ViTs) are increasingly utilized in various computer\nvision tasks due to their powerful representation capabilities. However, it\nremains understudied how ViTs process information layer by layer. Numerous\nstudies have shown that convolutional neural networks (CNNs) extract features\nof increasing complexity throughout their layers, which is crucial for tasks\nlike domain adaptation and transfer learning. ViTs, lacking the same inductive\nbiases as CNNs, can potentially learn global dependencies from the first layers\ndue to their attention mechanisms. Given the increasing importance of ViTs in\ncomputer vision, there is a need to improve the layer-wise understanding of\nViTs. In this work, we present a novel, layer-wise analysis of concepts encoded\nin state-of-the-art ViTs using neuron labeling. Our findings reveal that ViTs\nencode concepts with increasing complexity throughout the network. Early layers\nprimarily encode basic features such as colors and textures, while later layers\nrepresent more specific classes, including objects and animals. As the\ncomplexity of encoded concepts increases, the number of concepts represented in\neach layer also rises, reflecting a more diverse and specific set of features.\nAdditionally, different pretraining strategies influence the quantity and\ncategory of encoded concepts, with finetuning to specific downstream tasks\ngenerally reducing the number of encoded concepts and shifting the concepts to\nmore relevant categories.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-03-31T13:28:43Z"}
{"aid":"http://arxiv.org/abs/2503.24073v1","title":"Krylov complexity in quantum many-body scars of spin-1 models","summary":"Weak ergodicity breaking, particularly through quantum many-body scars\n(QMBS), has become a significant focus in many-body physics. Krylov state\ncomplexity quantifies the spread of quantum states within the Krylov basis and\nserves as a powerful diagnostic for analyzing nonergodic dynamics. In this\nwork, we study spin-one XXZ magnets and reveal nonergodic behavior tied to\nQMBS. For the XY model, the nematic N\\'eel state exhibits periodic revivals in\nKrylov complexity. In the generic XXZ model, we identify spin helix states as\nweakly ergodicity-breaking states, characterized by low entanglement and\nnonthermal dynamics. Across different scenarios, the Lanczos coefficients for\nscarred states display an elliptical pattern, reflecting a hidden SU(2) algebra\nthat enables analytical results for Krylov complexity and fidelity. These\nfindings, which exemplify the rare capability to characterize QMBS\nanalytically, are feasible with current experimental techniques and offer deep\ninsights into the nonergodic dynamics of interacting quantum systems.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-03-31T13:29:45Z"}
{"aid":"http://arxiv.org/abs/2503.24102v1","title":"Is LLM the Silver Bullet to Low-Resource Languages Machine Translation?","summary":"Low-Resource Languages (LRLs) present significant challenges in natural\nlanguage processing due to their limited linguistic resources and\nunderrepresentation in standard datasets. While recent advancements in Large\nLanguage Models (LLMs) and Neural Machine Translation (NMT) have substantially\nimproved translation capabilities for high-resource languages, performance\ndisparities persist for LRLs, particularly impacting privacy-sensitive and\nresource-constrained scenarios. This paper systematically evaluates the\nlimitations of current LLMs across 200 languages using benchmarks such as\nFLORES-200. We also explore alternative data sources, including news articles\nand bilingual dictionaries, and demonstrate how knowledge distillation from\nlarge pre-trained models can significantly improve smaller LRL translations.\nAdditionally, we investigate various fine-tuning strategies, revealing that\nincremental enhancements markedly reduce performance gaps on smaller LLMs.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T13:56:03Z"}
{"aid":"http://arxiv.org/abs/2503.24129v1","title":"It's a (Blind) Match! Towards Vision-Language Correspondence without\n  Parallel Data","summary":"The platonic representation hypothesis suggests that vision and language\nembeddings become more homogeneous as model and dataset sizes increase. In\nparticular, pairwise distances within each modality become more similar. This\nsuggests that as foundation models mature, it may become possible to match\nvision and language embeddings in a fully unsupervised fashion, i.e. without\nparallel data. We present the first feasibility study, and investigate\nconformity of existing vision and language foundation models in the context of\nunsupervised, or \"blind\", matching. First, we formulate unsupervised matching\nas a quadratic assignment problem and introduce a novel heuristic that\noutperforms previous solvers. We also develop a technique to find optimal\nmatching problems, for which a non-trivial match is very likely. Second, we\nconduct an extensive study deploying a range of vision and language models on\nfour datasets. Our analysis reveals that for many problem instances, vision and\nlanguage representations can be indeed matched without supervision. This\nfinding opens up the exciting possibility of embedding semantic knowledge into\nother modalities virtually annotation-free. As a proof of concept, we showcase\nan unsupervised classifier, which achieves non-trivial classification accuracy\nwithout any image-text annotation.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-03-31T14:14:25Z"}
{"aid":"http://arxiv.org/abs/2503.24147v1","title":"Net 3.2 Tbps 225 Gbaud PAM4 O-Band IM/DD 2 km Transmission Using FR8 and\n  DR8 with a CMOS 3 nm SerDes and TFLN Modulators","summary":"We report the first 3.2 and 4.2 Tbps (8 x 225Gbaud PAM4-8), IM/DD\ntransmission system using FR8 and DR8 configurations with TFLN modulators\ndriven by a 3nm SerDes under the HD-FEC threshold.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T14:33:17Z"}
{"aid":"http://arxiv.org/abs/2503.24150v1","title":"Learning a Canonical Basis of Human Preferences from Binary Ratings","summary":"Recent advances in generative AI have been driven by alignment techniques\nsuch as reinforcement learning from human feedback (RLHF). RLHF and related\ntechniques typically involve constructing a dataset of binary or ranked choice\nhuman preferences and subsequently fine-tuning models to align with these\npreferences. This paper shifts the focus to understanding the preferences\nencoded in such datasets and identifying common human preferences. We find that\na small subset of 21 preference categories (selected from a set of nearly 5,000\ndistinct preferences) captures >89% of preference variation across individuals.\nThis small set of preferences is analogous to a canonical basis of human\npreferences, similar to established findings that characterize human variation\nin psychology or facial recognition studies. Through both synthetic and\nempirical evaluations, we confirm that our low-rank, canonical set of human\npreferences generalizes across the entire dataset and within specific topics.\nWe further demonstrate our preference basis' utility in model evaluation, where\nour preference categories offer deeper insights into model alignment, and in\nmodel training, where we show that fine-tuning on preference-defined subsets\nsuccessfully aligns the model accordingly.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.HC","published":"2025-03-31T14:35:48Z"}
{"aid":"http://arxiv.org/abs/2503.24167v1","title":"Relative solidity for biexact groups in measure equivalence","summary":"We demonstrate a relative solidity property for the product of a nonamenable\nbiexact group with an arbitrary infinite group in the measure equivalence\nsetting. Among other applications, we obtain the following unique product\ndecomposition for products of nonamenable biexact groups, strengthening\n\\cite{Sa09}: for any nonamenable biexact groups $\\Gamma_1,\\cdots, \\Gamma_n$, if\na product group $\\Lambda_1\\times \\Lambda_2$ is measure equivalent to\n$\\times_{k=1}^n\\Gamma_k$, then there exists a partition $T_1\\sqcup\nT_2=\\{1,\\dots, n\\}$ such that $\\Lambda_i$ is measure equivalent to\n$\\times_{k\\in T_i}\\Gamma_k$ for $i=1,2$.","main_category":"math.OA","categories":"math.OA,math.GR","published":"2025-03-31T14:48:48Z"}
{"aid":"http://arxiv.org/abs/2503.24203v1","title":"Traffic Engineering in Large-scale Networks with Generalizable Graph\n  Neural Networks","summary":"Traffic engineering (TE) in large-scale computer networks has become a\nfundamental yet challenging problem, owing to the swift growth of global-scale\ncloud wide-area networks or backbone low-Earth-orbit satellite constellations.\nTo address the scalability issue of traditional TE algorithms, learning-based\napproaches have been proposed, showing potential of significant efficiency\nimprovement over state-of-the-art methods. Nevertheless, the intrinsic\nlimitations of existing learning-based methods hinder their practical\napplication: they are not generalizable across diverse topologies and network\nconditions, incur excessive training overhead, and do not respect link\ncapacities by default.\n  This paper proposes TELGEN, a novel TE algorithm that learns to solve TE\nproblems efficiently in large-scale networks, while achieving superior\ngeneralizability across diverse network conditions. TELGEN is based on the\nnovel idea of transforming the problem of \"predicting the optimal TE solution\"\ninto \"predicting the optimal TE algorithm\", which enables TELGEN to learn and\nefficiently approximate the end-to-end solving process of classical optimal TE\nalgorithms. The learned algorithm is agnostic to the exact network topology or\ntraffic patterns, and can efficiently solve TE problems given arbitrary inputs\nand generalize well to unseen topologies and demands.\n  We trained and evaluated TELGEN on random and real-world networks with up to\n5000 nodes and 106 links. TELGEN achieved less than 3% optimality gap while\nensuring feasibility in all cases, even when the test network had up to 20x\nmore nodes than the largest in training. It also saved up to 84% solving time\nthan classical optimal solver, and could reduce training time per epoch and\nsolving time by 2-4 orders of magnitude than latest learning algorithms on the\nlargest networks.","main_category":"cs.NI","categories":"cs.NI,cs.LG","published":"2025-03-31T15:21:22Z"}
{"aid":"http://arxiv.org/abs/2503.24248v1","title":"Optimizing PCA for Health and Care Research: A Reliable Approach to\n  Component Selection","summary":"PCA is widely used in health and care research to analyze complex HD\ndatasets, such as patient health records, genetic data, and medical imaging. By\nreducing dimensionality, PCA helps identify key patterns and trends, which can\naid in disease diagnosis, treatment optimization, and the discovery of new\nbiomarkers. However, the primary goal of any dimensional reduction technique is\nto reduce the dimensionality in a data set while keeping the essential\ninformation and variability. There are a few ways to do this in practice, such\nas the Kaiser-Guttman criterion, Cattell's Scree Test, and the percent\ncumulative variance approach. Unfortunately, the results of these methods are\nentirely different. That means using inappropriate methods to find the optimal\nnumber of PCs retained in PCA may lead to misinterpreted and inaccurate results\nin PCA and PCA-related health and care research applications. This\ncontradiction becomes even more pronounced in HD settings where n < p, making\nit even more critical to determine the best approach. Therefore, it is\nnecessary to identify the issues of different techniques to select the optimal\nnumber of PCs retained in PCA. Kaiser-Guttman criterion retains fewer PCs,\ncausing overdispersion, while Cattell's scree test retains more PCs,\ncompromising reliability. The percentage of cumulative variation criterion\noffers greater stability, consistently selecting the optimal number of\ncomponents. Therefore, the Pareto chart, which shows both the cumulative\npercentage and the cut-off point for retained PCs, provides the most reliable\nmethod of selecting components, ensuring stability and enhancing PCA\neffectiveness, particularly in health-related research applications.","main_category":"stat.ME","categories":"stat.ME","published":"2025-03-31T15:58:50Z"}
{"aid":"http://arxiv.org/abs/2503.24279v1","title":"Toward the effective 2-topos","summary":"A candidate for the effective 2-topos is proposed and shown to include the\neffective 1-topos as its subcategory of 0-types.","main_category":"math.CT","categories":"math.CT,math.LO","published":"2025-03-31T16:23:47Z"}
{"aid":"http://arxiv.org/abs/2503.24295v1","title":"Brazilian input to the European Strategy for Particle Physics Update","summary":"The Brazilian High-Energy Physics (HEP) community has expanded remarkably\nsince its first involvement at CERN and Fermilab in the 1980s. Its recent\norganization under the Brazilian Network for High-Energy Physics (RENAFAE),\nsince 2008, has further strengthened its scientific and technological goals,\nparticularly in detector instrumentation, computing, and industry partnerships.\nIn 2024, Brazil became an Associate Member State of CERN, opening new\nopportunities for deeper engagement in accelerator and detector R&D. This input\nto the 2026 update of the European Strategy for Particle Physics highlights\nBrazil's current participation in LHC experiments as well as ongoing\ndevelopments in detector and accelerator technology, and details the\ncommunity's view towards future colliders. The potential for expanded\nscientific and industrial collaborations between Brazil and CERN is also\ndiscussed.","main_category":"hep-ex","categories":"hep-ex","published":"2025-03-31T16:41:38Z"}
{"aid":"http://arxiv.org/abs/2503.24298v1","title":"Order Matters: On Parameter-Efficient Image-to-Video Probing for\n  Recognizing Nearly Symmetric Actions","summary":"We study parameter-efficient image-to-video probing for the unaddressed\nchallenge of recognizing nearly symmetric actions - visually similar actions\nthat unfold in opposite temporal order (e.g., opening vs. closing a bottle).\nExisting probing mechanisms for image-pretrained models, such as DinoV2 and\nCLIP, rely on attention mechanism for temporal modeling but are inherently\npermutation-invariant, leading to identical predictions regardless of frame\norder. To address this, we introduce Self-attentive Temporal Embedding Probing\n(STEP), a simple yet effective approach designed to enforce temporal\nsensitivity in parameter-efficient image-to-video transfer. STEP enhances\nself-attentive probing with three key modifications: (1) a learnable frame-wise\npositional encoding, explicitly encoding temporal order; (2) a single global\nCLS token, for sequence coherence; and (3) a simplified attention mechanism to\nimprove parameter efficiency. STEP outperforms existing image-to-video probing\nmechanisms by 3-15% across four activity recognition benchmarks with only 1/3\nof the learnable parameters. On two datasets, it surpasses all published\nmethods, including fully fine-tuned models. STEP shows a distinct advantage in\nrecognizing nearly symmetric actions, surpassing other probing mechanisms by\n9-19%. and parameter-heavier PEFT-based transfer methods by 5-15%. Code and\nmodels will be made publicly available.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T16:42:38Z"}
{"aid":"http://arxiv.org/abs/2503.24314v1","title":"Impact of Synchronization Offsets and CSI Feedback Delay in Distributed\n  MIMO Systems","summary":"The main challenges of distributed MIMO systems lie in achieving highly\naccurate synchronization and ensuring the availability of accurate channel\nstate information (CSI) at distributed nodes. This paper analytically examines\nthe effects of synchronization offsets and CSI feedback delays on system\ncapacity, providing insights into how these affect the coherent joint\ntransmission gain. The capacity expressions are first derived under ideal\nconditions, and the effects of synchronization offsets and feedback delays are\nsubsequently incorporated. This analysis can be applied to any distributed MIMO\narchitecture. A comprehensive study, including system models and simulations\nevaluating the analytical expressions, is presented to quantify the capacity\ndegradation caused by these factors. This study provides valuable insights into\nthe design and performance of distributed MIMO systems. The analysis shows that\ntime and frequency offsets, along with CSI feedback delay, cause inter-layer\ninterference. Additionally, time offsets result in inter-symbol interference.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T17:02:33Z"}
{"aid":"http://arxiv.org/abs/2503.24355v1","title":"Modified cosmology though spacetime thermodynamics and generalized\n  mass-to-horizon entropy","summary":"In this work we apply the gravity-thermodynamics approach for the case of\ngeneralized mass-to-horizon entropy, which is a two-parameter extension of\nBekenstein-Hawking entropy that arises from the extended mass-to-horizon\nrelation, that is in turn required in order to have consistency with the\nClausius relation. We extract the modified Friedmann equations and we obtain an\neffective dark energy sector arising from the novel terms. We derive analytical\nsolutions for the dark energy density parameter, the dark energy\nequation-of-state parameter, and the deceleration parameter, and we show that\nthe Universe exhibits the usual thermal history with the succession of matter\nand dark energy epochs. Additionally, depending on the value of the entropy\nparameters, the dark energy equation-of-state parameter can either lie in the\nphantom regime at high redshifts entering into the quintessence regime at small\nredshifts, or it can lie in the quintessence regime at high redshifts and\nexperience the phantom-divide crossing at small redshifts, while in the far\nfuture in all cases it asymptotically obtains the cosmological constant value\n$-1$. Finally, we perform observational confrontation with Supernova Type Ia\n(SNIa), Cosmic Chronometers (CC) and Baryonic Acoustic Oscillations (BAO)\ndatasets, showing that the scenario is in agreement with observations.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-th","published":"2025-03-31T17:35:35Z"}
{"aid":"http://arxiv.org/abs/2503.24373v1","title":"Accelerated Approximate Optimization of Multi-Commodity Flows on\n  Directed Graphs","summary":"We provide $m^{1+o(1)}k\\epsilon^{-1}$-time algorithms for computing\nmultiplicative $(1 - \\epsilon)$-approximate solutions to multi-commodity flow\nproblems with $k$-commodities on $m$-edge directed graphs, including concurrent\nmulti-commodity flow and maximum multi-commodity flow.\n  To obtain our results, we provide new optimization tools of potential\nindependent interest. First, we provide an improved optimization method for\nsolving $\\ell_{q, p}$-regression problems to high accuracy. This method makes\n$\\tilde{O}_{q, p}(k)$ queries to a high accuracy convex minimization oracle for\nan individual block, where $\\tilde{O}_{q, p}(\\cdot)$ hides factors depending\nonly on $q$, $p$, or $\\mathrm{poly}(\\log m)$, improving upon the $\\tilde{O}_{q,\np}(k^2)$ bound of [Chen-Ye, ICALP 2024]. As a result, we obtain the first\nalmost-linear time algorithm that solves $\\ell_{q, p}$ flows on directed graphs\nto high accuracy. Second, we present optimization tools to reduce approximately\nsolving composite $\\ell_{1, \\infty}$-regression problems to solving\n$m^{o(1)}\\epsilon^{-1}$ instances of composite $\\ell_{q, p}$-regression\nproblem. The method builds upon recent advances in solving box-simplex games\n[Jambulapati-Tian, NeurIPS 2023] and the area convex regularizer introduced in\n[Sherman, STOC 2017] to obtain faster rates for constrained versions of the\nproblem. Carefully combining these techniques yields our directed\nmulti-commodity flow algorithm.","main_category":"cs.DS","categories":"cs.DS,math.OC","published":"2025-03-31T17:53:00Z"}
{"aid":"http://arxiv.org/abs/2503.24379v1","title":"Any2Caption:Interpreting Any Condition to Caption for Controllable Video\n  Generation","summary":"To address the bottleneck of accurate user intent interpretation within the\ncurrent video generation community, we present Any2Caption, a novel framework\nfor controllable video generation under any condition. The key idea is to\ndecouple various condition interpretation steps from the video synthesis step.\nBy leveraging modern multimodal large language models (MLLMs), Any2Caption\ninterprets diverse inputs--text, images, videos, and specialized cues such as\nregion, motion, and camera poses--into dense, structured captions that offer\nbackbone video generators with better guidance. We also introduce Any2CapIns, a\nlarge-scale dataset with 337K instances and 407K conditions for\nany-condition-to-caption instruction tuning. Comprehensive evaluations\ndemonstrate significant improvements of our system in controllability and video\nquality across various aspects of existing video generation models. Project\nPage: https://sqwu.top/Any2Cap/","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T17:59:01Z"}
{"aid":"http://arxiv.org/abs/2503.24390v1","title":"Intertwining bulk and surface: the case of UTe$_2$","summary":"UTe$_2$ has been the focus of numerous experimental and theoretical studies\nin recent years, as it is recognized as an odd-parity bulk superconductor. Its\nsurface has also been probed, revealing charge density wave (CDW), pair density\nwave (PDW), and time-reversal symmetry breaking (TRSB). In this work, we\npropose that the interplay between the order parameters observed on the surface\nand in the bulk of UTe$_2$ may be crucial in explaining some of the unusual\nfeatures detected by surface probes in this material. Through a\nphenomenological analysis, we can account for three distinctive experimental\nsignatures observed on the surface of UTe$_2$: i) the apparent suppression of\nCDW order at the upper critical field of the bulk superconducting state; ii)\nthe magnetic field-induced imbalance of the Fourier peaks associated with the\nCDW; iii) the onset of TRSB at the bulk superconducting critical temperature\nand its field-trainability. Furthermore, we propose specific experimental\nchecks to validate our conjecture, which we believe could be promptly achieved.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.str-el","published":"2025-03-31T17:59:55Z"}
{"aid":"http://arxiv.org/abs/2503.24391v1","title":"Easi3R: Estimating Disentangled Motion from DUSt3R Without Training","summary":"Recent advances in DUSt3R have enabled robust estimation of dense point\nclouds and camera parameters of static scenes, leveraging Transformer network\narchitectures and direct supervision on large-scale 3D datasets. In contrast,\nthe limited scale and diversity of available 4D datasets present a major\nbottleneck for training a highly generalizable 4D model. This constraint has\ndriven conventional 4D methods to fine-tune 3D models on scalable dynamic video\ndata with additional geometric priors such as optical flow and depths. In this\nwork, we take an opposite path and introduce Easi3R, a simple yet efficient\ntraining-free method for 4D reconstruction. Our approach applies attention\nadaptation during inference, eliminating the need for from-scratch pre-training\nor network fine-tuning. We find that the attention layers in DUSt3R inherently\nencode rich information about camera and object motion. By carefully\ndisentangling these attention maps, we achieve accurate dynamic region\nsegmentation, camera pose estimation, and 4D dense point map reconstruction.\nExtensive experiments on real-world dynamic videos demonstrate that our\nlightweight attention adaptation significantly outperforms previous\nstate-of-the-art methods that are trained or finetuned on extensive dynamic\ndatasets. Our code is publicly available for research purpose at\nhttps://easi3r.github.io/","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T17:59:58Z"}
{"aid":"http://arxiv.org/abs/2504.01319v1","title":"Decoupled anisotropic Charge-Phonon Transport Enables Exceptional n-Type\n  Thermoelectric Performance in CuBiSCl$_2$","summary":"First-principles calculations demonstrate an exceptional decoupling of charge\nand thermal transport along the \\textit{a}-axis in CuBiSCl$_2$. The material\nachieves superior electron mobility (138 cm$^2$/V$\\cdot$s at 300 K) through\ndelocalized Bi-6\\textit{p}/S-3\\textit{p} networks while maintaining ultralow\nlattice thermal conductivity (0.40 W/mK at 300 K) via Cu-dominated anharmonic\nphonon scattering - both optimized along the same crystallographic direction.\nThis simultaneous optimization originates from the anisotropic bonding\nhierarchy where [BiSCl$_2$]$_n$ ribbons enable efficient charge transport along\n\\textit{a}-axis, while the soft vibrational modes associated with Cu atoms\nstrongly scatter heat-carrying phonons. The resulting high power factor (1.71\nmW/mK$^2$ at 700 K) and peak \\textit{ZT} of 1.57 establish CuBiSCl$_2$ as a\nmodel system that realizes the long-sought \"phonon glass-electron crystal\"\nparadigm through crystallographically engineered transport channels.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T03:10:17Z"}
{"aid":"http://arxiv.org/abs/2504.01321v1","title":"COST: Contrastive One-Stage Transformer for Vision-Language Small Object\n  Tracking","summary":"Transformer has recently demonstrated great potential in improving\nvision-language (VL) tracking algorithms. However, most of the existing VL\ntrackers rely on carefully designed mechanisms to perform the multi-stage\nmulti-modal fusion. Additionally, direct multi-modal fusion without alignment\nignores distribution discrepancy between modalities in feature space,\npotentially leading to suboptimal representations. In this work, we propose\nCOST, a contrastive one-stage transformer fusion framework for VL tracking,\naiming to learn semantically consistent and unified VL representations.\nSpecifically, we introduce a contrastive alignment strategy that maximizes\nmutual information (MI) between a video and its corresponding language\ndescription. This enables effective cross-modal alignment, yielding\nsemantically consistent features in the representation space. By leveraging a\nvisual-linguistic transformer, we establish an efficient multi-modal fusion and\nreasoning mechanism, empirically demonstrating that a simple stack of\ntransformer encoders effectively enables unified VL representations. Moreover,\nwe contribute a newly collected VL tracking benchmark dataset for small object\ntracking, named VL-SOT500, with bounding boxes and language descriptions. Our\ndataset comprises two challenging subsets, VL-SOT230 and VL-SOT270, dedicated\nto evaluating generic and high-speed small object tracking, respectively. Small\nobject tracking is notoriously challenging due to weak appearance and limited\nfeatures, and this dataset is, to the best of our knowledge, the first to\nexplore the usage of language cues to enhance visual representation for small\nobject tracking. Extensive experiments demonstrate that COST achieves\nstate-of-the-art performance on five existing VL tracking datasets, as well as\non our proposed VL-SOT500 dataset. Source codes and dataset will be made\npublicly available.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T03:12:38Z"}
{"aid":"http://arxiv.org/abs/2504.01336v1","title":"Inverse RL Scene Dynamics Learning for Nonlinear Predictive Control in\n  Autonomous Vehicles","summary":"This paper introduces the Deep Learning-based Nonlinear Model Predictive\nController with Scene Dynamics (DL-NMPC-SD) method for autonomous navigation.\nDL-NMPC-SD uses an a-priori nominal vehicle model in combination with a scene\ndynamics model learned from temporal range sensing information. The scene\ndynamics model is responsible for estimating the desired vehicle trajectory, as\nwell as to adjust the true system model used by the underlying model predictive\ncontroller. We propose to encode the scene dynamics model within the layers of\na deep neural network, which acts as a nonlinear approximator for the high\norder state-space of the operating conditions. The model is learned based on\ntemporal sequences of range sensing observations and system states, both\nintegrated by an Augmented Memory component. We use Inverse Reinforcement\nLearning and the Bellman optimality principle to train our learning controller\nwith a modified version of the Deep Q-Learning algorithm, enabling us to\nestimate the desired state trajectory as an optimal action-value function. We\nhave evaluated DL-NMPC-SD against the baseline Dynamic Window Approach (DWA),\nas well as against two state-of-the-art End2End and reinforcement learning\nmethods, respectively. The performance has been measured in three experiments:\ni) in our GridSim virtual environment, ii) on indoor and outdoor navigation\ntasks using our RovisLab AMTU (Autonomous Mobile Test Unit) platform and iii)\non a full scale autonomous test vehicle driving on public roads.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-02T03:46:37Z"}
{"aid":"http://arxiv.org/abs/2504.01376v1","title":"On the dual structure of the Schr√∂dinger dynamics","summary":"This paper elucidates the dual structure of the Schr\\\"{o}dinger dynamics in\ntwo correlated stages: (1) We first derive the real-valued Schr\\\"{o}dinger\nequation from scratch without referring to classical mechanics, wave mechanics,\nnor optics, and thereby attain a concrete and clear interpretation of the\nSchr\\\"{o}dinger (wave) function. Beginning with a factorization of the density\ndistribution function of the particles to two component vectors in\nconfiguration space, we impose very simple conditions on them such as\ntranslational invariance of space-time and the conservation of flux under a\ngiven potential function. A real-valued path-integral is formulated as a Green\nfunction for the real-valued Schr\\\"{o}dinger equation. (2) We then study a\nquantum stochastic path dynamics in a manner compatible with the\nSchr\\\"{o}dinger equation. The relation between them is like the Langevin\ndynamics with the diffusion equation. Each quantum path describes a\n\\textquotedblleft trajectory\\textquotedblright\\ in configuration space\nrepresenting, for instance, a singly launched electron in the double-slit\nexperiment that leaves a spot one by one at the measurement board, while\naccumulated spots give rise to the fringe pattern as predicted by the absolute\nsquare of the Schr\\\"{o}dinger function. We start from the relationship between\nthe Ito stochastic differential equation, the Feynman-Kac formula, and the\nassociated parabolic partial differential equations, to one of which\\ the\nSchr\\\"{o}dinger equation is transformed. The physical significance of the\nquantum intrinsic stochasticity and the indirect correlation among the quantum\npaths and so on are discussed. The self-referential nonlinear interrelationship\nbetween the Schr\\\"{o}dinger functions (regarded as a whole) and the quantum\npaths (as its parts) is identified as the ultimate mystery in quantum dynamics.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T05:38:05Z"}
{"aid":"http://arxiv.org/abs/2504.01408v1","title":"From Shadows to Safety: Occlusion Tracking and Risk Mitigation for Urban\n  Autonomous Driving","summary":"Autonomous vehicles (AVs) must navigate dynamic urban environments where\nocclusions and perception limitations introduce significant uncertainties. This\nresearch builds upon and extends existing approaches in risk-aware motion\nplanning and occlusion tracking to address these challenges. While prior\nstudies have developed individual methods for occlusion tracking and risk\nassessment, a comprehensive method integrating these techniques has not been\nfully explored. We, therefore, enhance a phantom agent-centric model by\nincorporating sequential reasoning to track occluded areas and predict\npotential hazards. Our model enables realistic scenario representation and\ncontext-aware risk evaluation by modeling diverse phantom agents, each with\ndistinct behavior profiles. Simulations demonstrate that the proposed approach\nimproves situational awareness and balances proactive safety with efficient\ntraffic flow. While these results underline the potential of our method,\nvalidation in real-world scenarios is necessary to confirm its feasibility and\ngeneralizability. By utilizing and advancing established methodologies, this\nwork contributes to safer and more reliable AV planning in complex urban\nenvironments. To support further research, our method is available as\nopen-source software at:\nhttps://github.com/TUM-AVS/OcclusionAwareMotionPlanning","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-02T06:48:50Z"}
{"aid":"http://arxiv.org/abs/2504.01415v1","title":"Systematic Literature Review of Automation and Artificial Intelligence\n  in Usability Issue Detection","summary":"Usability issues can hinder the effective use of software. Therefore, various\ntechniques are deployed to diagnose and mitigate them. However, these\ntechniques are costly and time-consuming, particularly in iterative design and\ndevelopment. A substantial body of research indicates that automation and\nartificial intelligence can enhance the process of obtaining usability\ninsights. In our systematic review of 155 publications, we offer a\ncomprehensive overview of the current state of the art for automated usability\nissue detection. We analyze trends, paradigms, and the technical context in\nwhich they are applied. Finally, we discuss the implications and potential\ndirections for future research.","main_category":"cs.HC","categories":"cs.HC,cs.SE","published":"2025-04-02T07:07:32Z"}
{"aid":"http://arxiv.org/abs/2504.01447v1","title":"What KM3-230213A events may tell us about the neutrino mass and dark\n  matter","summary":"Within the framework of general $U(1)$ scenario, we demonstrate that the\nultra high energy neutrinos recently detected by KM3NeT could originate from a\ndecaying right handed neutrino dark matter (DM), with a mass of 440 PeV.\nConsidering DM production via freeze-in, we delineate the parameter space that\nsatisfies the observed relic abundance and also lies within the reach of\nmultiple gravitational wave detectors. Our study provides a testable new\nphysics scenario, enabled by multi-messenger astronomy.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO,astro-ph.HE","published":"2025-04-02T08:00:23Z"}
{"aid":"http://arxiv.org/abs/2504.01470v1","title":"Detecting Lip-Syncing Deepfakes: Vision Temporal Transformer for\n  Analyzing Mouth Inconsistencies","summary":"Deepfakes are AI-generated media in which the original content is digitally\naltered to create convincing but manipulated images, videos, or audio. Among\nthe various types of deepfakes, lip-syncing deepfakes are one of the most\nchallenging deepfakes to detect. In these videos, a person's lip movements are\nsynthesized to match altered or entirely new audio using AI models. Therefore,\nunlike other types of deepfakes, the artifacts in lip-syncing deepfakes are\nconfined to the mouth region, making them more subtle and, thus harder to\ndiscern. In this paper, we propose LIPINC-V2, a novel detection framework that\nleverages a combination of vision temporal transformer with multihead\ncross-attention to detect lip-syncing deepfakes by identifying spatiotemporal\ninconsistencies in the mouth region. These inconsistencies appear across\nadjacent frames and persist throughout the video. Our model can successfully\ncapture both short-term and long-term variations in mouth movement, enhancing\nits ability to detect these inconsistencies. Additionally, we created a new\nlip-syncing deepfake dataset, LipSyncTIMIT, which was generated using five\nstate-of-the-art lip-syncing models to simulate real-world scenarios. Extensive\nexperiments on our proposed LipSyncTIMIT dataset and two other benchmark\ndeepfake datasets demonstrate that our model achieves state-of-the-art\nperformance. The code and the dataset are available at\nhttps://github.com/skrantidatta/LIPINC-V2 .","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T08:24:06Z"}
{"aid":"http://arxiv.org/abs/2504.01475v1","title":"Optimal Control of an Interconnected SDE -Parabolic PDE System","summary":"In this paper, we design a controller for an interconnected system where a\nlinear Stochastic Differential Equation (SDE) is actuated through a linear\nparabolic heat equation. These dynamics arise in various applications, such as\ncoupled heat transfer systems and chemical reaction processes that are subject\nto disturbances. Our goal is to develop a computational method for\napproximating the controller that minimizes a quadratic cost associated with\nthe state of the SDE component. To achieve this, we first perform a change of\nvariables to shift the actuation inside the PDE domain and reformulate the\nsystem as a linear Stochastic Partial Differential Equation (SPDE). We use a\nspectral approximation of the Laplacian operator to discretize the coupled\ndynamics into a finite-dimensional SDE and compute the optimal control for this\napproximated system. The resulting control serves as an approximation of the\noptimal control for the original system. We then establish the convergence of\nthe approximated optimal control and the corresponding closed-loop dynamics to\ntheir infinite-dimensional counterparts. Numerical simulations are provided to\nillustrate the effectiveness of our approach.","main_category":"math.AP","categories":"math.AP,math.OC","published":"2025-04-02T08:29:04Z"}
{"aid":"http://arxiv.org/abs/2504.01485v1","title":"Diameter Shortcut Sets on Temporal Graphs","summary":"Shortcut sets are a vital instrument for reducing the diameter of a static\ngraph and, consequently, its shortest path complexity, which is relevant in\nnumerous subfields of graph theory. We explore the notion of shortcut sets in\ntemporal graphs, which incorporate a discrete time model into the graph,\nrendering each edge accessible exclusively at specific points in time. This not\nonly alters the underlying assumptions of regular graphs but also substantially\nincreases the complexity of path problems and reachability. In turn, a temporal\ngraph is often a much more realistic and accurate representation of a\nreal-world network. In this thesis we provide a definition for a shortcut set\nin a temporal graph and explore differences to classic shortcut sets. Utilizing\nthis definition, we show that temporal and regular shortcut sets yield the same\nresults on temporal paths, enabling the application of existing construction\nalgorithms for static shortcut sets on paths. The primary contribution of this\nthesis is a translation approach for general temporal graphs that utilizes the\nstatic expansion of a temporal graph, allowing the conversion of static\nshortcut sets into temporal shortcut sets, yielding similar results.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-02T08:38:21Z"}
{"aid":"http://arxiv.org/abs/2504.01492v1","title":"Nagaoka ferromagnetism in semiconductor artificial graphene","summary":"We present the emergence of Nagaoka ferromagnetism in semiconductor-based\nartificial graphene using high-precision variational and diffusion Monte Carlo\nmethods, complemented by exact diagonalization calculations of the extended\nHubbard model. Specifically, we analyze a realistic model of an armchair\nhexagonal geometry comprising $42$ lattice sites, nanopatterned on GaAs quantum\nwells with nearest-neighbor distance of $a = 50$ nm. Our results reveal a\ndistinct magnetic phase transition near $U/t \\approx 60$ driven by the\nabsence/addition of a single electron at half-filling where the ferromagnetic\nphase is further stabilized by Coulomb scattering terms.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.str-el","published":"2025-04-02T08:46:41Z"}
{"aid":"http://arxiv.org/abs/2504.01506v1","title":"MLKV: Efficiently Scaling up Large Embedding Model Training with\n  Disk-based Key-Value Storage","summary":"Many modern machine learning (ML) methods rely on embedding models to learn\nvector representations (embeddings) for a set of entities (embedding tables).\nAs increasingly diverse ML applications utilize embedding models and embedding\ntables continue to grow in size and number, there has been a surge in the\nad-hoc development of specialized frameworks targeted to train large embedding\nmodels for specific tasks. Although the scalability issues that arise in\ndifferent embedding model training tasks are similar, each of these frameworks\nindependently reinvents and customizes storage components for specific tasks,\nleading to substantial duplicated engineering efforts in both development and\ndeployment. This paper presents MLKV, an efficient, extensible, and reusable\ndata storage framework designed to address the scalability challenges in\nembedding model training, specifically data stall and staleness. MLKV augments\ndisk-based key-value storage by democratizing optimizations that were\npreviously exclusive to individual specialized frameworks and provides\neasy-to-use interfaces for embedding model training tasks. Extensive\nexperiments on open-source workloads, as well as applications in eBay's payment\ntransaction risk detection and seller payment risk detection, show that MLKV\noutperforms offloading strategies built on top of industrial-strength key-value\nstores by 1.6-12.6x. MLKV is open-source at https://github.com/llm-db/MLKV.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T08:57:01Z"}
{"aid":"http://arxiv.org/abs/2504.01511v1","title":"A computational framework for evaluating tire-asphalt hysteretic\n  friction including pavement roughness","summary":"Pavement surface textures obtained by a photogrammetry-based method for data\nacquisition and analysis are employed to investigate if related roughness\ndescriptors are comparable to the frictional performance evaluated by finite\nelement analysis. Pavement surface profiles are obtained from 3D digital\nsurface models created with Close-Range Orthogonal Photogrammetry. To\ncharacterize the roughness features of analyzed profiles, selected texture\nparameters were calculated from the profile's geometry. The parameters values\nwere compared to the frictional performance obtained by numerical simulations.\nContact simulations are performed according to a dedicated finite element\nscheme where surface roughness is directly embedded into a special class of\ninterface finite elements. Simulations were performed for different case\nscenarios and the obtained results showed a notable trend between roughness\ndescriptors and friction performance, indicating a promising potential for this\nnumerical method to be consistently employed to predict the frictional\nproperties of actual pavement surface profiles.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-02T08:58:31Z"}
{"aid":"http://arxiv.org/abs/2504.01517v1","title":"Cascade topologies in rare charm decays and implications for CP\n  violation","summary":"The CP violation observed in the hadronic decays of charmed mesons remains a\npuzzling open question for theorists. Calculations relying on the assumption of\ninelastic final-state interactions occurring between the pairs of pions and\nkaons fall short of the experimental value. It has been pointed out that a\nthird channel of four pions can leave imprints on the CP asymmetries of the\ntwo-body decays. At the same time, plenty of data are available for the $4\\pi$\ndecays of charmed mesons, as well as for the rare decays\n$D^0\\to\\pi^+\\pi^-\\ell^+\\ell^-$. With this motivation, we study the cascade\ntopology $D^0\\to a_1(1260)^+(\\to \\rho(770)^0\\pi^+)\\,\\pi^-$, which has been\nmeasured to contribute significantly to the $4\\pi$ decays, and estimate its\neffect on the branching ratio of the rare decays. We also explore the\npossibility of this topology contributing to the decay amplitude of\n$D^0\\to\\pi^+\\pi^-$ and by extension to the related CP asymmetry.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-02T09:03:15Z"}
{"aid":"http://arxiv.org/abs/2504.01538v1","title":"AI-Newton: A Concept-Driven Physical Law Discovery System without Prior\n  Physical Knowledge","summary":"Current limitations in human scientific discovery necessitate a new research\nparadigm. While advances in artificial intelligence (AI) offer a highly\npromising solution, enabling AI to emulate human-like scientific discovery\nremains an open challenge. To address this, we propose AI-Newton, a\nconcept-driven discovery system capable of autonomously deriving physical laws\nfrom raw data -- without supervision or prior physical knowledge. The system\nintegrates a knowledge base and knowledge representation centered on physical\nconcepts, along with an autonomous discovery workflow. As a proof of concept,\nwe apply AI-Newton to a large set of Newtonian mechanics problems. Given\nexperimental data with noise, the system successfully rediscovers fundamental\nlaws, including Newton's second law, energy conservation and law of\ngravitation, using autonomously defined concepts. This achievement marks a\nsignificant step toward AI-driven autonomous scientific discovery.","main_category":"cs.AI","categories":"cs.AI,cs.LG,cs.SC,hep-ph,physics.class-ph","published":"2025-04-02T09:25:34Z"}
{"aid":"http://arxiv.org/abs/2504.01551v1","title":"Identifying Macro Causal Effects in C-DMGs","summary":"Causal effect identification using causal graphs is a fundamental challenge\nin causal inference. While extensive research has been conducted in this area,\nmost existing methods assume the availability of fully specified causal graphs.\nHowever, in complex domains such as medicine and epidemiology, complete causal\nknowledge is often unavailable, and only partial information about the system\nis accessible. This paper focuses on causal effect identification within\npartially specified causal graphs, with particular emphasis on cluster-directed\nmixed graphs (C-DMGs). These graphs provide a higher-level representation of\ncausal relationships by grouping variables into clusters, offering a more\npractical approach for handling complex systems. Unlike fully specified causal\ngraphs, C-DMGs can contain cycles, which complicate their analysis and\ninterpretation. Furthermore, their cluster-based nature introduces new\nchallenges, as it gives rise to two distinct types of causal effects, macro\ncausal effects and micro causal effects, with different properties. In this\nwork, we focus on macro causal effects, which describe the effects of entire\nclusters on other clusters. We establish that the do-calculus is both sound and\ncomplete for identifying these effects in C-DMGs. Additionally, we provide a\ngraphical characterization of non-identifiability for macro causal effects in\nthese graphs.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-02T09:48:27Z"}
{"aid":"http://arxiv.org/abs/2504.01589v1","title":"Text Speaks Louder than Vision: ASCII Art Reveals Textual Biases in\n  Vision-Language Models","summary":"Vision-language models (VLMs) have advanced rapidly in processing multimodal\ninformation, but their ability to reconcile conflicting signals across\nmodalities remains underexplored. This work investigates how VLMs process ASCII\nart, a unique medium where textual elements collectively form visual patterns,\npotentially creating semantic-visual conflicts. We introduce a novel evaluation\nframework that systematically challenges five state-of-the-art models\n(including GPT-4o, Claude, and Gemini) using adversarial ASCII art, where\ncharacter-level semantics deliberately contradict global visual patterns. Our\nexperiments reveal a strong text-priority bias: VLMs consistently prioritize\ntextual information over visual patterns, with visual recognition ability\ndeclining dramatically as semantic complexity increases. Various mitigation\nattempts through visual parameter tuning and prompt engineering yielded only\nmodest improvements, suggesting that this limitation requires\narchitectural-level solutions. These findings uncover fundamental flaws in how\ncurrent VLMs integrate multimodal information, providing important guidance for\nfuture model development while highlighting significant implications for\ncontent moderation systems vulnerable to adversarial examples.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T10:47:07Z"}
{"aid":"http://arxiv.org/abs/2504.01593v1","title":"Integrating experimental feedback improves generative models for\n  biological sequences","summary":"Generative probabilistic models have shown promise in designing artificial\nRNA and protein sequences but often suffer from high rates of false positives,\nwhere sequences predicted as functional fail experimental validation. To\naddress this critical limitation, we explore the impact of reintegrating\nexperimental feedback into the model design process. We propose a\nlikelihood-based reintegration scheme, which we test through extensive\ncomputational experiments on both RNA and protein datasets, as well as through\nwet-lab experiments on the self-splicing ribozyme from the group I intron RNA\nfamily where our approach demonstrates particular efficacy. We show that\nintegrating recent experimental data enhances the model's capacity of\ngenerating functional sequences (e.g. from 6.7\\% to 63.7\\% of active designs at\n45 mutations). This feedback-driven approach thus provides a significant\nimprovement in the design of biomolecular sequences by directly tackling the\nfalse-positive challenge.","main_category":"q-bio.BM","categories":"q-bio.BM,physics.bio-ph,q-bio.QM","published":"2025-04-02T10:57:53Z"}
{"aid":"http://arxiv.org/abs/2504.01594v1","title":"Anticipating Degradation: A Predictive Approach to Fault Tolerance in\n  Robot Swarms","summary":"An active approach to fault tolerance is essential for robot swarms to\nachieve long-term autonomy. Previous efforts have focused on responding to\nspontaneous electro-mechanical faults and failures. However, many faults occur\ngradually over time. Waiting until such faults have manifested as failures\nbefore addressing them is both inefficient and unsustainable in a variety of\nscenarios. This work argues that the principles of predictive maintenance, in\nwhich potential faults are resolved before they hinder the operation of the\nswarm, offer a promising means of achieving long-term fault tolerance. This is\na novel approach to swarm fault tolerance, which is shown to give a comparable\nor improved performance when tested against a reactive approach in almost all\ncases tested.","main_category":"cs.RO","categories":"cs.RO,cs.MA","published":"2025-04-02T10:59:10Z"}
{"aid":"http://arxiv.org/abs/2504.01615v1","title":"The Mini-SiTian Array: A Pathfinder for the SiTian Project","summary":"The Mini-SiTian Array serves as a pathfinder for the SiTian project, which\naims to survey the entire sky in $gri$ bands every 30 minutes, reaching a\nlimiting magnitude of 21. This special issue features 11 papers covering the\ndesign, operation, data reduction, and early scientific results from two years\nof Mini-SiTian observations. The insights gained from these pathfinder\nexperiments represent a significant milestone toward the full realization of\nthe SiTian project.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-02T11:26:27Z"}
{"aid":"http://arxiv.org/abs/2504.01621v1","title":"Two-photon microscopy using picosecond pulses from four-wave mixing in a\n  Yb-doped photonic crystal fiber","summary":"Two-photon microscopy (TPM) enables deep tissue imaging but requires\nexcitation pulses that have a large product of average and peak power,\ntypically supplied by femtosecond solid-state lasers. However, these lasers are\nbulky and femtosecond pulses require careful dispersion management to avoid\npulse broadening, particularly when delivery fibers are used. Here we present a\ncompact, fiber-based picosecond laser source operating at 790 nm for TPM using\na ytterbium-doped photonic crystal fiber (Yb-doped PCF). The Yb-doped PCF\nsimultaneously amplifies 1064 nm input pulses and efficiently converts them to\n790 nm via four-wave mixing, generating pulses with a peak power of up to ~3.8\nkW. The source has a variable repetition rate (1.48 MHz-14.78 MHz), enabling\nthe two-photon excitation fluorescence signal to be maximized in the presence\nof excitation saturation. We benchmark our picosecond laser source against a\nfemtosecond Ti:Sapphire laser for TPM of stained Convallaria majalis samples\nand demonstrate comparable fluorescence signal when the two-photon excitation\nconditions are matched.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-02T11:30:04Z"}
{"aid":"http://arxiv.org/abs/2504.01642v1","title":"Spanning clique subdivisions in pseudorandom graphs","summary":"In this paper, we study the appearance of a spanning subdivision of a clique\nin graphs satisfying certain pseudorandom conditions. Specifically, we show the\nfollowing three results. Firstly, that there are constants $C>0$ and $c\\in\n(0,1]$ such that, whenever $d/\\lambda\\ge C$, every $(n,d,\\lambda)$-graph\ncontains a spanning subdivision of $K_t$ for all $2\\le t \\le\n\\min\\{cd,c\\sqrt{\\frac{n}{\\log n}}\\}$. Secondly, that there are constants $C>0$\nand $c\\in (0,1]$ such that, whenever $d/\\lambda\\ge C\\log^3n$, every\n$(n,d,\\lambda)$-graph contains a spanning nearly-balanced subdivision of $K_t$\nfor all $2\\le t \\le \\min\\{cd,c\\sqrt{\\frac{n}{\\log^3n}}\\}$. Finally, we show\nthat for every $\\mu>0$, there are constants $c,\\varepsilon\\in (0,1]$ and\n$n_0\\in \\mathbb N$ such that, whenever $n\\ge n_0$, every $n$-vertex graph with\nminimum degree at least $\\mu n$ and no bipartite holes of size $\\varepsilon n$\ncontains a spanning nearly-balanced subdivision of $K_t$ for all $2\\le t \\le\nc\\sqrt{n}$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-02T11:46:24Z"}
{"aid":"http://arxiv.org/abs/2504.01666v1","title":"CLIP-SLA: Parameter-Efficient CLIP Adaptation for Continuous Sign\n  Language Recognition","summary":"Continuous sign language recognition (CSLR) focuses on interpreting and\ntranscribing sequences of sign language gestures in videos. In this work, we\npropose CLIP sign language adaptation (CLIP-SLA), a novel CSLR framework that\nleverages the powerful pre-trained visual encoder from the CLIP model to sign\nlanguage tasks through parameter-efficient fine-tuning (PEFT). We introduce two\nvariants, SLA-Adapter and SLA-LoRA, which integrate PEFT modules into the CLIP\nvisual encoder, enabling fine-tuning with minimal trainable parameters. The\neffectiveness of the proposed frameworks is validated on four datasets:\nPhoenix2014, Phoenix2014-T, CSL-Daily, and Isharah-500, where both CLIP-SLA\nvariants outperformed several SOTA models with fewer trainable parameters.\nExtensive ablation studies emphasize the effectiveness and flexibility of the\nproposed methods with different vision-language models for CSLR. These findings\nshowcase the potential of adapting large-scale pre-trained models for scalable\nand efficient CSLR, which pave the way for future advancements in sign language\nunderstanding.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T12:15:33Z"}
{"aid":"http://arxiv.org/abs/2504.01672v1","title":"A flexible framework for early power and timing comparison of\n  time-multiplexed CGRA kernel executions","summary":"At the intersection between traditional CPU architectures and more\nspecialized options such as FPGAs or ASICs lies the family of reconfigurable\nhardware architectures, termed Coarse-Grained Reconfigurable Arrays (CGRAs).\nCGRAs are composed of a 2-dimensional array of processing elements (PE),\ntightly integrated with each other, each capable of performing arithmetic and\nlogic operations. The vast design space of CGRA implementations poses a\nchallenge, which calls for fast exploration tools to prune it in advance of\ntime-consuming syntheses. The proposed tool aims to simplify this process by\nsimulating kernel execution and providing a characterization framework. The\nestimator returns energy and latency values otherwise only available through a\ntime-consuming post-synthesis simulation, allowing for instantaneous\ncomparative analysis between different kernels and hardware configurations.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-02T12:21:09Z"}
{"aid":"http://arxiv.org/abs/2504.01678v1","title":"Second-order cone programming for distributionally robust compliance\n  optimization of trusses considering input distribution uncertainty","summary":"Reliability-based design optimization (RBDO) is a methodology for designing\nstructures under the consideration for uncertainty with the assumption that the\ninput distribution is completely known. In practical engineering, the number of\ninput data is often limited, which can damage the validity of the optimal\nresults obtained by RBDO. Confidence-based design optimization (CBDO) has been\nproposed to account for the uncertainty of the input distribution. However,\nthis approach faces challenges, computational cost and accuracy when dealing\nwith highly nonlinear performance constraints. In this paper, we consider the\ncompliance minimization problem of truss structures with uncertain external\nforces. Armed with the advanced risk measure, conditional Value-at-Risk (CVaR),\nwe formulate a bi-objective optimization problem for the worst-case expected\nvalue and the worst-case CVaR of compliance, which allows us to account for the\ntail risk of performance functions not addressed in CBDO. Employing kernel\ndensity estimation for estimation of the input distribution allows us to\neliminate the need for modeling the input distribution. We show that this\nproblem reduces to a second-order cone programming when assigning either\nuniform kernel or triangular kernel. Finally, through numerical experiments, we\nobtain the Pareto front for the bi-objective optimization problem of the\nworst-case expected value and CVaR of compliance of truss structures, and\nconfirm the changes in the Pareto solutions.","main_category":"math.OC","categories":"math.OC","published":"2025-04-02T12:26:23Z"}
{"aid":"http://arxiv.org/abs/2504.01709v1","title":"How chiral vibrations drive molecular rotation","summary":"We analyze two simple model planar molecules: an ionic molecule with D3\nsymmetry and a covalent molecule with D6 symmetry. Both symmetries allow the\nexistence of chiral molecular orbitals and normal modes that are coupled to\neach other in a Jahn-Teller manner, invariant under U (1) symmetry with\ngenerator a pseudo angular momentum. In the ionic molecule, the chiral mode\npossesses an electric dipole but lacks physical angular momentum, whereas, in\nthe covalent molecule, the situation is reversed. In spite of that, we show\nthat in both cases the chiral modes can be excited by a circularly polarized\nlight and are subsequently able to induce rotational motion of the entire\nmolecule. We further discuss the potential extension of our findings to the\ncase of crystalline bulk samples.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-02T13:15:59Z"}
{"aid":"http://arxiv.org/abs/2504.01772v1","title":"Adaptation of Moreau-Yosida regularization to the modulus of convexity","summary":"We study a generalization of Moreau-Yosida regularization that is adapted to\nthe geometry of Banach spaces where the dual space is uniformly convex with\nmodulus of convexity of power type. Important properties for regularized convex\nfunctions are given, in particular strong monotonicity of the subdifferential\nof their convex conjugate and H\\\"older-continuity of their gradient.","main_category":"math.FA","categories":"math.FA,math-ph,math.MP","published":"2025-04-02T14:31:08Z"}
{"aid":"http://arxiv.org/abs/2504.01817v1","title":"Multi-actuator lens systems for turbulence correction in free-space\n  optical communications","summary":"The implementation of efficient free-space channels is fundamental for both\nclassical and quantum Free-Space Optical (FSO) communication. This can be\nchallenging for fibre-coupled receivers, due to the time variant inhomogeneity\nof the refractive index that can cause strong fluctuations in the power coupled\ninto the Single-Mode Fiber (SMF), and requires the use of Adaptive Optics (AO)\nsystems to correct the atmospheric induced aberrations. In this work, we\npresent two adaptive optic systems, one using a Fast-Steering Prism (FSP) for\nthe correction of tip-tilt and a second one based on a Multi-Actuator\ndeformable Lens (MAL), capable of correcting up to the third order of Zernike's\npolynomials. We test both systems at telecom wavelength both with artificial\nturbulence in the laboratory and on a free-space channel, demonstrating their\neffectiveness in increasing the fibre coupling efficiency.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-02T15:21:58Z"}
{"aid":"http://arxiv.org/abs/2504.01827v1","title":"What is AI, what is it not, how we use it in physics and how it\n  impacts... you","summary":"Artificial Intelligence (AI) and Machine Learning (ML) have been prevalent in\nparticle physics for over three decades, shaping many aspects of High Energy\nPhysics (HEP) analyses. As AI's influence grows, it is essential for physicists\n$\\unicode{x2013}$ as both researchers and informed citizens $\\unicode{x2013}$\nto critically examine its foundations, misconceptions, and impact. This paper\nexplores AI definitions, examines how ML differs from traditional programming,\nand provides a brief review of AI/ML applications in HEP, highlighting\npromising trends such as Simulation-Based Inference, uncertainty-aware machine\nlearning, and Fast ML for anomaly detection. Beyond physics, it also addresses\nthe broader societal harms of AI systems, underscoring the need for responsible\nengagement. Finally, it stresses the importance of adapting research practices\nto an evolving AI landscape, ensuring that physicists not only benefit from the\nlatest tools but also remain at the forefront of innovation.","main_category":"physics.soc-ph","categories":"physics.soc-ph,cs.LG,hep-ex","published":"2025-04-02T15:35:43Z"}
{"aid":"http://arxiv.org/abs/2504.01836v1","title":"Estimating hazard rates from $Œ¥$-records in discrete distributions","summary":"This paper focuses on nonparametric statistical inference of the hazard rate\nfunction of discrete distributions based on $\\delta$-record data. We derive the\nexplicit expression of the maximum likelihood estimator and determine its exact\ndistribution, as well as some important characteristics such as its bias and\nmean squared error. We then discuss the construction of confidence intervals\nand goodness-of-fit tests. The performance of our proposals is evaluated using\nsimulation methods. Applications to real data are given, as well. The\nestimation of the hazard rate function based on usual records has been studied\nin the literature, although many procedures require several samples of records.\nIn contrast, our approach relies on a single sequence of $\\delta$-records,\nsimplifying the experimental design and increasing the applicability of the\nmethods.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-02T15:43:19Z"}
{"aid":"http://arxiv.org/abs/2504.01842v1","title":"shapr: Explaining Machine Learning Models with Conditional Shapley\n  Values in R and Python","summary":"This paper introduces the shapr package, a versatile tool for generating\nShapley value explanations for machine learning and statistical regression\nmodels in both R and Python. The package emphasizes conditional Shapley value\nestimates, providing a comprehensive range of approaches for accurately\ncapturing feature dependencies, which is crucial for correct model\ninterpretation and lacking in similar software. In addition to regular tabular\ndata, the shapr R-package includes specialized functionality for explaining\ntime series forecasts. The package offers a minimal set of user functions with\nsensible defaults for most use cases while providing extensive flexibility for\nadvanced users to fine-tune computations. Additional features include\nparallelized computations, iterative estimation with convergence detection, and\nrich visualization tools. shapr also extends its functionality to compute\ncausal and asymmetric Shapley values when causal information is available. In\naddition, we introduce the shaprpy Python library, which brings core\ncapabilities of shapr to the Python ecosystem. Overall, the package aims to\nenhance the interpretability of predictive models within a powerful and\nuser-friendly framework.","main_category":"cs.LG","categories":"cs.LG,stat.CO","published":"2025-04-02T15:47:30Z"}
{"aid":"http://arxiv.org/abs/2504.01846v1","title":"Many neighbors little entanglement: A curious scaling in the\n  variable-range extended Ising model","summary":"We study the two-point correlation functions and the bipartite entanglement\nin the ground state of the exactly-solvable variable-range extended Ising model\nof qubits in the presence of a transverse field on a one-dimensional lattice.\nWe introduce the variation in the range of interaction by varying the\ncoordination number, $\\mathcal{Z}$, of each qubit, where the interaction\nstrength between a pair of qubits at a distance $r$ varies as $\\sim\nr^{-\\alpha}$. We show that the algebraic nature of the correlation functions is\npresent only up to $r=\\mathcal{Z}$, above which it exhibits short-range\nexponential scaling. We also show that at the critical point, the bipartite\nentanglement exhibits a power-law decrease ($\\sim\\mathcal{Z}^{-\\gamma}$) with\nincreasing coordination number irrespective of the partition size and the value\nof $\\alpha$ for $\\alpha>1$. We further consider a sudden quench of the system\nstarting from the ground state of the infinite-field limit of the system\nHamiltonian via turning on the critical Hamiltonian, and demonstrate that the\nlong-time averaged bipartite entanglement exhibits a qualitatively similar\nvariation ($\\sim\\mathcal{Z}^{-\\gamma}$) with $\\mathcal{Z}$.","main_category":"quant-ph","categories":"quant-ph,cond-mat.str-el","published":"2025-04-02T15:54:52Z"}
{"aid":"http://arxiv.org/abs/2504.01866v1","title":"From Code Generation to Software Testing: AI Copilot with Context-Based\n  RAG","summary":"The rapid pace of large-scale software development places increasing demands\non traditional testing methodologies, often leading to bottlenecks in\nefficiency, accuracy, and coverage. We propose a novel perspective on software\ntesting by positing bug detection and coding with fewer bugs as two\ninterconnected problems that share a common goal, which is reducing bugs with\nlimited resources. We extend our previous work on AI-assisted programming,\nwhich supports code auto-completion and chatbot-powered Q&A, to the realm of\nsoftware testing. We introduce Copilot for Testing, an automated testing system\nthat synchronizes bug detection with codebase updates, leveraging context-based\nRetrieval Augmented Generation (RAG) to enhance the capabilities of large\nlanguage models (LLMs). Our evaluation demonstrates a 31.2% improvement in bug\ndetection accuracy, a 12.6% increase in critical test coverage, and a 10.5%\nhigher user acceptance rate, highlighting the transformative potential of\nAI-driven technologies in modern software development practices.","main_category":"cs.SE","categories":"cs.SE,cs.AI,cs.PL","published":"2025-04-02T16:20:05Z"}
{"aid":"http://arxiv.org/abs/2504.01868v1","title":"Focal Mechanism Uncertainty Quantification In Ground Motion Simulations\n  Of Le Teil Earthquake","summary":"Ensuring the seismic safety of nuclear power plants (NPPs) is essential,\nespecially for facilities that rely on base isolation to reduce earthquake\nimpacts. For understanding the seismic response, accurate models are key to\npredict the ground motions, which are generally sensitive to various factors,\nincluding earthquake source parameters like the focal mechanism, i.e., strike,\ndip, and rake angles. This study examines how uncertainties in these parameters\naffect ground motion predictions. The analysis is based on the SMATCH\nbenchmark, which provides a standardized approach for evaluating the seismic\nresponse of the Cruas-Meysse NPP in France during the Mw 4.9 Le-Teil earthquake\nof 2019. A set of 27 3D high-fidelity numerical simulations was performed using\na spectral-element method, each incorporating different focal mechanism\nvariations. These simulations provide an effective approach for investigating\nthe factors behind the exceptional ground motion observed during this event. To\nquantify uncertainty, the simulated ground motions were compared to recorded\ndata using two well-established goodness-of-fit criteria: one assessing\ntime-frequency domain characteristics and another focusing on the\ncharacterization of the ground motion signals by intensity measures. Results\nhighlight the significant influence of focal mechanism variability on ground\nmotion predictions, especially on the rake angle, which showed the strongest\ncorrelation with wave and intensity measures.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-02T16:22:46Z"}
{"aid":"http://arxiv.org/abs/2504.01869v1","title":"Buggin: Automatic intrinsic bugs classification model using NLP and ML","summary":"Recent studies have shown that bugs can be categorized into intrinsic and\nextrinsic types. Intrinsic bugs can be backtracked to specific changes in the\nversion control system (VCS), while extrinsic bugs originate from external\nchanges to the VCS and lack a direct bug-inducing change. Using only intrinsic\nbugs to train bug prediction models has been reported as beneficial to improve\nthe performance of such models. However, there is currently no automated\napproach to identify intrinsic bugs. To bridge this gap, our study employs\nNatural Language Processing (NLP) techniques to automatically identify\nintrinsic bugs. Specifically, we utilize two embedding techniques, seBERT and\nTF-IDF, applied to the title and description text of bug reports. The resulting\nembeddings are fed into well-established machine learning algorithms such as\nSupport Vector Machine, Logistic Regression, Decision Tree, Random Forest, and\nK-Nearest Neighbors. The primary objective of this paper is to assess the\nperformance of various NLP and machine learning techniques in identifying\nintrinsic bugs using the textual information extracted from bug reports. The\nresults demonstrate that both seBERT and TF-IDF can be effectively utilized for\nintrinsic bug identification. The highest performance scores were achieved by\ncombining TF-IDF with the Decision Tree algorithm and utilizing the bug titles\n(yielding an F1 score of 78%). This was closely followed by seBERT, Support\nVector Machine, and bug titles (with an F1 score of 77%). In summary, this\npaper introduces an innovative approach that automates the identification of\nintrinsic bugs using textual information derived from bug reports.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-02T16:23:08Z"}
{"aid":"http://arxiv.org/abs/2504.01884v1","title":"Thermoelectric AC Josephson effect","summary":"A temperature gradient ${\\Delta}T$ across a Josephson junction induces a\nthermoelectric current. We predict the AC Josephson effect is activated when\nthis current surpasses the junction's critical current. Our investigation of\nthis phenomenon employs the time-dependent Ginzburg-Landau theory framework in\nproximity to the critical temperature. Our results indicate that the frequency\nof the AC current is approximately given by ${\\pi} S {\\Delta} T / (2\n{\\Phi}_0)$, where $S$ represents the Seebeck coefficient and ${\\Phi}_0$ the\nmagnetic flux quantum and we estimate the frequency be on the range of GHz for\nSn up to a THz for larger $S$ and $T_c$ materials. Furthermore, we propose two\ndistinct experimental configurations to observe this effect.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-02T16:41:34Z"}
{"aid":"http://arxiv.org/abs/2504.01900v1","title":"Physical Modeling of Saturated Common Mode Choke","summary":"Common mode chokes (CMCs) are conventional circuit elements performing\nseveral tasks, including noise suppression, hindering electromagnetic\ninterference, providing signal integrity, and circuit protection. Much as they\nare widely used, their fundamental construction and description are often\nqualitative and lack an understanding of the underlying physical principles. We\ndiscuss the behavior of a commercial CMC based on the physical description of\nthe superparamagnetic core and parasitic circuit elements. The results are\nvalidated using a DC bias current and an external magnetic field, which affect\nthe magnetic properties. The behavior of the CMCs in the strongly non-linear\nregime is also described.","main_category":"physics.app-ph","categories":"physics.app-ph,cond-mat.mtrl-sci","published":"2025-04-02T16:58:47Z"}
{"aid":"http://arxiv.org/abs/2504.01905v1","title":"Accelerating IoV Intrusion Detection: Benchmarking GPU-Accelerated vs\n  CPU-Based ML Libraries","summary":"The Internet of Vehicles (IoV) may face challenging cybersecurity attacks\nthat may require sophisticated intrusion detection systems, necessitating a\nrapid development and response system. This research investigates the\nperformance advantages of GPU-accelerated libraries (cuML) compared to\ntraditional CPU-based implementations (scikit-learn), focusing on the speed and\nefficiency required for machine learning models used in IoV threat detection\nenvironments. The comprehensive evaluations conducted employ four machine\nlearning approaches (Random Forest, KNN, Logistic Regression, XGBoost) across\nthree distinct IoV security datasets (OTIDS, GIDS, CICIoV2024). Our findings\ndemonstrate that GPU-accelerated implementations dramatically improved\ncomputational efficiency, with training times reduced by a factor of up to 159\nand prediction speeds accelerated by up to 95 times compared to traditional CPU\nprocessing, all while preserving detection accuracy. This remarkable\nperformance breakthrough empowers researchers and security specialists to\nharness GPU acceleration for creating faster, more effective threat detection\nsystems that meet the urgent real-time security demands of today's connected\nvehicle networks.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CR","published":"2025-04-02T17:04:53Z"}
{"aid":"http://arxiv.org/abs/2504.01918v1","title":"Long-eared digraphs","summary":"Let $H$ be a subdigraph of a digraph $D$. An ear of $H$ in $D$ is a path or a\ncycle in $D$ whose ends lie in $H$ but whose internal vertices do not. An\n\\emph{ear decomposition} of a strong digraph $D$ is a nested sequence\n$(D_0,D_1,\\ldots , D_k)$ of strong subdigraphs of $D$ such that: 1) $D_0$ is a\ncycle, 2) $D_{i+1} = D_i\\cup P_i$, where $P_i$ is an ear of $D_i$ in $D$, for\nevery $i\\in \\{0,1,\\ldots,k-1\\}$, and 3) $D_k=D$.\n  In this work, the $\\mathcal{LE}_i$ is defined as the family of strong\ndigraphs, with an ear decomposition such that every ear has a length of at\nleast $i\\geq 1$. It is proved that Seymour's second Neighborhood Conjecture and\nthe Laborde, Payan, and Soung conjecture, are true in the family\n$\\mathcal{LE}_2$, and the Small quasi-kernel conjecture is true for digraphs in\n$\\mathcal{LE}_3$. Also, some sufficient conditions for a strong nonseparable\ndigraph in $\\mathcal{LE}_2$ with a kernel to imply that the previous\n(following) subdigraph in the ear decomposition has a kernel too, are\npresented. It is proved that digraphs in $\\mathcal{LE}_2$ have a chromatic\nnumber at most 3, and a dichromatic number 2 or 3. Finally, the oriented\nchromatic number of asymmetrical digraphs in $\\mathcal{LE}_3$ is bounded by 6,\nand it is shown that the oriented chromatic number of asymmetrical digraphs in\n$\\mathcal{LE}_2$ is not bounded.","main_category":"math.CO","categories":"math.CO","published":"2025-04-02T17:22:44Z"}
{"aid":"http://arxiv.org/abs/2504.01940v1","title":"Strengthening Multi-Robot Systems for SAR: Co-Designing Robotics and\n  Communication Towards 6G","summary":"This paper presents field-tested use cases from Search and Rescue (SAR)\nmissions, highlighting the co-design of mobile robots and communication systems\nto support Edge-Cloud architectures based on 5G Standalone (SA). The main goal\nis to contribute to the effective cooperation of multiple robots and first\nresponders. Our field experience includes the development of Hybrid Wireless\nSensor Networks (H-WSNs) for risk and victim detection, smartphones integrated\ninto the Robot Operating System (ROS) as Edge devices for mission requests and\npath planning, real-time Simultaneous Localization and Mapping (SLAM) via\nMulti-Access Edge Computing (MEC), and implementation of Uncrewed Ground\nVehicles (UGVs) for victim evacuation in different navigation modes. These\nexperiments, conducted in collaboration with actual first responders,\nunderscore the need for intelligent network resource management, balancing\nlow-latency and high-bandwidth demands. Network slicing is key to ensuring\ncritical emergency services are performed despite challenging communication\nconditions. The paper identifies architectural needs, lessons learned, and\nchallenges to be addressed by 6G technologies to enhance emergency response\ncapabilities.","main_category":"cs.RO","categories":"cs.RO,cs.NI","published":"2025-04-02T17:47:11Z"}
{"aid":"http://arxiv.org/abs/2504.01943v1","title":"OpenCodeReasoning: Advancing Data Distillation for Competitive Coding","summary":"Since the advent of reasoning-based large language models, many have found\ngreat success from distilling reasoning capabilities into student models. Such\ntechniques have significantly bridged the gap between reasoning and standard\nLLMs on coding tasks. Despite this, much of the progress on distilling\nreasoning models remains locked behind proprietary datasets or lacks details on\ndata curation, filtering and subsequent training. To address this, we construct\na superior supervised fine-tuning (SFT) dataset that we use to achieve\nstate-of-the-art coding capability results in models of various sizes. Our\ndistilled models use only SFT to achieve 61.8% on LiveCodeBench and 24.6% on\nCodeContests, surpassing alternatives trained with reinforcement learning. We\nthen perform analysis on the data sources used to construct our dataset, the\nimpact of code execution filtering, and the importance of instruction/solution\ndiversity. We observe that execution filtering negatively affected benchmark\naccuracy, leading us to prioritize instruction diversity over solution\ncorrectness. Finally, we also analyze the token efficiency and reasoning\npatterns utilized by these models. We will open-source these datasets and\ndistilled models to the community.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T17:50:31Z"}
{"aid":"http://arxiv.org/abs/2504.02214v1","title":"Geospatial Artificial Intelligence for Satellite-based Flood Extent\n  Mapping: Concepts, Advances, and Future Perspectives","summary":"Geospatial Artificial Intelligence (GeoAI) for satellite-based flood extent\nmapping systematically integrates artificial intelligence techniques with\nsatellite data to identify flood events and assess their impacts, for disaster\nmanagement and spatial decision-making. The primary output often includes flood\nextent maps, which delineate the affected areas, along with additional\nanalytical outputs such as uncertainty estimation and change detection.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-03T02:08:22Z"}
{"aid":"http://arxiv.org/abs/2504.02245v1","title":"Traffic Flow Data Completion and Anomaly Diagnosis via Sparse and\n  Low-Rank Tensor Optimization","summary":"Spatiotemporal traffic time series, such as traffic speed data, collected\nfrom sensing systems are often incomplete, with considerable corruption and\nlarge amounts of missing values. A vast amount of data conceals implicit data\nstructures, which poses significant challenges for data recovery issues, such\nas mining the potential spatio-temporal correlations of data and identifying\nabnormal data. In this paper, we propose a Tucker decomposition-based sparse\nlow-rank high-order tensor optimization model (TSLTO) for data imputation and\nanomaly diagnosis. We decompose the traffic tensor data into low-rank and\nsparse tensors, and establish a sparse low-rank high-order tensor optimization\nmodel based on Tucker decomposition. By utilizing tools of non-smooth analysis\nfor tensor functions, we explore the optimality conditions of the proposed\ntensor optimization model and design an ADMM optimization algorithm for solving\nthe model. Finally, numerical experiments are conducted on both synthetic data\nand a real-world dataset: the urban traffic speed dataset of Guangzhou.\nNumerical comparisons with several representative existing algorithms\ndemonstrate that our proposed approach achieves higher accuracy and efficiency\nin traffic flow data recovery and anomaly diagnosis tasks.","main_category":"math.OC","categories":"math.OC,cs.NA,math.NA","published":"2025-04-03T03:21:30Z"}
{"aid":"http://arxiv.org/abs/2504.02267v1","title":"Third-Order Spontaneous Parametric Down Conversion in Dielectric\n  Nonlinear Resonant Metasurfaces","summary":"We propose a general scheme to investigate photon triplet generation (PTG)\nvia third-order spontaneous parametric downconversion (TOSPDC) in $\\chi^{(3)}$\nnonlinear structures. Our approach leverages the quantum-classical\ncorrespondence between TOSPDC and its reverse classical process, three-wave\nsum-frequency generation (TSFG), to efficiently estimate the PTG rate. We apply\nthis framework to nonlinear metasurfaces supporting quasi-bound states in the\ncontinuum (qBICs) in the optical range. From numerical analysis of\nnon-collinear TSFG with degenerate input waves at qBIC wavelengths, we predict\nwavelength-tunable three-photon emission with spatio-angular correlations.\nThese findings establish a novel method for modelling TOSPDC and also highlight\nthe potential of nonlinear resonant metasurfaces as compact free-space photon\ntriplet sources with quantum state control.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-03T04:26:50Z"}
{"aid":"http://arxiv.org/abs/2504.02312v1","title":"OmniCam: Unified Multimodal Video Generation via Camera Control","summary":"Camera control, which achieves diverse visual effects by changing camera\nposition and pose, has attracted widespread attention. However, existing\nmethods face challenges such as complex interaction and limited control\ncapabilities. To address these issues, we present OmniCam, a unified multimodal\ncamera control framework. Leveraging large language models and video diffusion\nmodels, OmniCam generates spatio-temporally consistent videos. It supports\nvarious combinations of input modalities: the user can provide text or video\nwith expected trajectory as camera path guidance, and image or video as content\nreference, enabling precise control over camera motion. To facilitate the\ntraining of OmniCam, we introduce the OmniTr dataset, which contains a large\ncollection of high-quality long-sequence trajectories, videos, and\ncorresponding descriptions. Experimental results demonstrate that our model\nachieves state-of-the-art performance in high-quality camera-controlled video\ngeneration across various metrics.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-03T06:38:30Z"}
{"aid":"http://arxiv.org/abs/2504.02315v1","title":"On $\\rm GL_3$ Fourier coefficients over values of mixed powers","summary":"Let $A_{\\pi}(n,1)$ be the $(n,1)$-th Fourier coefficient of the Hecke-Maass\ncusp form $\\pi$ for $\\rm SL_3(\\mathbb{Z})$ and $ \\omega(x)$ be a smooth\ncompactly supported function. In this paper, we prove a nontrivial upper bound\nfor the sum $$\\sum_{n_1,\\cdots,n_\\ell,n_{\\ell+1}\\in\\mathbb{Z}^+ \\atop\nn=n_1^r+\\cdots+n_{\\ell}^r+n_{\\ell+1}^s} A_{\\pi}(n,1)\\omega\\left(n/X\\right),$$\nwhere $r\\geq2$, $s\\geq 2$ and $\\ell\\geq 2^{r-1}$ are integers.","main_category":"math.NT","categories":"math.NT","published":"2025-04-03T06:43:21Z"}
{"aid":"http://arxiv.org/abs/2504.02337v1","title":"LPA3D: 3D Room-Level Scene Generation from In-the-Wild Images","summary":"Generating realistic, room-level indoor scenes with semantically plausible\nand detailed appearances from in-the-wild images is crucial for various\napplications in VR, AR, and robotics. The success of NeRF-based generative\nmethods indicates a promising direction to address this challenge. However,\nunlike their success at the object level, existing scene-level generative\nmethods require additional information, such as multiple views, depth images,\nor semantic guidance, rather than relying solely on RGB images. This is because\nNeRF-based methods necessitate prior knowledge of camera poses, which is\nchallenging to approximate for indoor scenes due to the complexity of defining\nalignment and the difficulty of globally estimating poses from a single image,\ngiven the unseen parts behind the camera. To address this challenge, we\nredefine global poses within the framework of Local-Pose-Alignment (LPA) -- an\nanchor-based multi-local-coordinate system that uses a selected number of\nanchors as the roots of these coordinates. Building on this foundation, we\nintroduce LPA-GAN, a novel NeRF-based generative approach that incorporates\nspecific modifications to estimate the priors of camera poses under LPA. It\nalso co-optimizes the pose predictor and scene generation processes. Our\nablation study and comparisons with straightforward extensions of NeRF-based\nobject generative methods demonstrate the effectiveness of our approach.\nFurthermore, visual comparisons with other techniques reveal that our method\nachieves superior view-to-view consistency and semantic normality.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T07:18:48Z"}
{"aid":"http://arxiv.org/abs/2504.02339v1","title":"Riemannian Optimization for Sparse Tensor CCA","summary":"Tensor canonical correlation analysis (TCCA) has received significant\nattention due to its ability to effectively preserve the geometric structure of\nhigh-order data. However, existing methods generally rely on tensor\ndecomposition techniques with high computational complexity, which severely\nlimits their application in large-scale datasets. In this paper, a modified\nmethod, TCCA-L, is proposed, which integrates sparse regularization and\nLaplacian regularization. An alternating manifold proximal gradient algorithm\nis designed based on Riemannian manifold theory. The algorithm avoids the\ntraditional tensor decomposition and combines with the semi-smooth Newton\nalgorithm to solve the subproblem, thus significantly improving the\ncomputational efficiency. Furthermore, the global convergence of the sequence\ngenerated by the algorithm is established, providing a solid theoretical\nfoundation for its convergence. Numerical experiments demonstrate that TCCA-L\noutperforms traditional methods in both classification accuracy and running\ntime.","main_category":"math.OC","categories":"math.OC","published":"2025-04-03T07:19:14Z"}
{"aid":"http://arxiv.org/abs/2504.02360v1","title":"On graded going-down domains, II","summary":"In this paper we consider the graded going-down property of graded integral\ndomains in pullbacks. It then enables us to give original examples of these\ndomains.","main_category":"math.AC","categories":"math.AC","published":"2025-04-03T07:51:21Z"}
{"aid":"http://arxiv.org/abs/2504.02427v1","title":"Stochastic domination and lifts of random variables in percolation\n  theory","summary":"Consider some matrix waiting for its coefficients to be written. For each\ncolumn, sample independently one Bernoulli random variable of some parameter\n$p$. Seeing all this and possibly using extra randomness, Alice then chooses\none spot in each column, in any way she wants. When the Bernoulli random\nvariable of some column is equal to 1, the number 1 is written in the chosen\nspot. When the Bernoulli random variable of a column is 0, nothing is done on\nthis column. We prove that, using extra randomness, it is possible for Bob to\nfill the empty spots with well chosen 0's and 1's so that the entries of the\nmatrix are independent Bernoulli random variables of parameter $p$. We\ninvestigate various generalisations and variations of this problem, and use\nthis result to revisit and generalise (nonstrict) monotonicity of the\npercolation threshold $p_c$ with respect to some sort of graph-quotienting,\nnamely fibrations.\n  In a second part, which is independent of the first one, we revisit strict\nmonotonicity of $p_c$ with respect to fibrations, a result that naturally\nrequires more assumptions than its nonstrict counterpart. We reprove the\nbond-percolation case of the result of Martineau--Severo without resorting to\nessential enhancements, using couplings instead.","main_category":"math.PR","categories":"math.PR,math.CO","published":"2025-04-03T09:31:59Z"}
{"aid":"http://arxiv.org/abs/2504.02436v1","title":"SkyReels-A2: Compose Anything in Video Diffusion Transformers","summary":"This paper presents SkyReels-A2, a controllable video generation framework\ncapable of assembling arbitrary visual elements (e.g., characters, objects,\nbackgrounds) into synthesized videos based on textual prompts while maintaining\nstrict consistency with reference images for each element. We term this task\nelements-to-video (E2V), whose primary challenges lie in preserving the\nfidelity of each reference element, ensuring coherent composition of the scene,\nand achieving natural outputs. To address these, we first design a\ncomprehensive data pipeline to construct prompt-reference-video triplets for\nmodel training. Next, we propose a novel image-text joint embedding model to\ninject multi-element representations into the generative process, balancing\nelement-specific consistency with global coherence and text alignment. We also\noptimize the inference pipeline for both speed and output stability. Moreover,\nwe introduce a carefully curated benchmark for systematic evaluation, i.e, A2\nBench. Experiments demonstrate that our framework can generate diverse,\nhigh-quality videos with precise element control. SkyReels-A2 is the first\nopen-source commercial grade model for the generation of E2V, performing\nfavorably against advanced closed-source commercial models. We anticipate\nSkyReels-A2 will advance creative applications such as drama and virtual\ne-commerce, pushing the boundaries of controllable video generation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T09:50:50Z"}
{"aid":"http://arxiv.org/abs/2504.02439v1","title":"Estimating Scene Flow in Robot Surroundings with Distributed\n  Miniaturized Time-of-Flight Sensors","summary":"Tracking motions of humans or objects in the surroundings of the robot is\nessential to improve safe robot motions and reactions. In this work, we present\nan approach for scene flow estimation from low-density and noisy point clouds\nacquired from miniaturized Time of Flight (ToF) sensors distributed on the\nrobot body. The proposed method clusters points from consecutive frames and\napplies Iterative Closest Point (ICP) to estimate a dense motion flow, with\nadditional steps introduced to mitigate the impact of sensor noise and\nlow-density data points. Specifically, we employ a fitness-based classification\nto distinguish between stationary and moving points and an inlier removal\nstrategy to refine geometric correspondences. The proposed approach is\nvalidated in an experimental setup where 24 ToF are used to estimate the\nvelocity of an object moving at different controlled speeds. Experimental\nresults show that the method consistently approximates the direction of the\nmotion and its magnitude with an error which is in line with sensor noise.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-03T09:57:51Z"}
{"aid":"http://arxiv.org/abs/2504.02441v1","title":"Cognitive Memory in Large Language Models","summary":"This paper examines memory mechanisms in Large Language Models (LLMs),\nemphasizing their importance for context-rich responses, reduced\nhallucinations, and improved efficiency. It categorizes memory into sensory,\nshort-term, and long-term, with sensory memory corresponding to input prompts,\nshort-term memory processing immediate context, and long-term memory\nimplemented via external databases or structures. The text-based memory section\ncovers acquisition (selection and summarization), management (updating,\naccessing, storing, and resolving conflicts), and utilization (full-text\nsearch, SQL queries, semantic search). The KV cache-based memory section\ndiscusses selection methods (regularity-based summarization, score-based\napproaches, special token embeddings) and compression techniques (low-rank\ncompression, KV merging, multimodal compression), along with management\nstrategies like offloading and shared attention mechanisms. Parameter-based\nmemory methods (LoRA, TTT, MoE) transform memories into model parameters to\nenhance efficiency, while hidden-state-based memory approaches (chunk\nmechanisms, recurrent transformers, Mamba model) improve long-text processing\nby combining RNN hidden states with current methods. Overall, the paper offers\na comprehensive analysis of LLM memory mechanisms, highlighting their\nsignificance and future research directions.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-03T09:58:19Z"}
{"aid":"http://arxiv.org/abs/2504.02449v1","title":"Strongly regular graphs with parameters (85,14,3,2) do not exist","summary":"We investigate the second smallest unresolved feasible set of parameters of\nstrongly regular graphs, $(v,k,\\lambda,\\mu)=(85,14,3,2)$. Using the\nclassification of cubic graphs of small degree, we restrict possible local\nstructure of such a graph $G$. After that, we exhaustively enumerate possible\nneighbourhoods of a maximal $3$-clique of $G$ and check them against a variety\nof conditions, including the combinatorial ones, coming from $\\lambda=3$ and\n$\\mu=2$, as well as the linear algebra ones, utilising the Euclidean\nrepresentation of $G$. These conditions yield contradiction in all cases, and\nhence, no $\\mathrm{srg}(85,14,3,2)$ exists.","main_category":"math.CO","categories":"math.CO","published":"2025-04-03T10:13:09Z"}
{"aid":"http://arxiv.org/abs/2504.02451v1","title":"ConMo: Controllable Motion Disentanglement and Recomposition for\n  Zero-Shot Motion Transfer","summary":"The development of Text-to-Video (T2V) generation has made motion transfer\npossible, enabling the control of video motion based on existing footage.\nHowever, current methods have two limitations: 1) struggle to handle\nmulti-subjects videos, failing to transfer specific subject motion; 2) struggle\nto preserve the diversity and accuracy of motion as transferring to subjects\nwith varying shapes. To overcome these, we introduce \\textbf{ConMo}, a\nzero-shot framework that disentangle and recompose the motions of subjects and\ncamera movements. ConMo isolates individual subject and background motion cues\nfrom complex trajectories in source videos using only subject masks, and\nreassembles them for target video generation. This approach enables more\naccurate motion control across diverse subjects and improves performance in\nmulti-subject scenarios. Additionally, we propose soft guidance in the\nrecomposition stage which controls the retention of original motion to adjust\nshape constraints, aiding subject shape adaptation and semantic transformation.\nUnlike previous methods, ConMo unlocks a wide range of applications, including\nsubject size and position editing, subject removal, semantic modifications, and\ncamera motion simulation. Extensive experiments demonstrate that ConMo\nsignificantly outperforms state-of-the-art methods in motion fidelity and\nsemantic consistency. The code is available at\nhttps://github.com/Andyplus1/ConMo.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T10:15:52Z"}
{"aid":"http://arxiv.org/abs/2504.02493v1","title":"On zero-divisor graph of the ring of Gaussian integers modulo $2^n$","summary":"For a commutative ring $R$, the zero-divisor graph of $R$ is a simple graph\nwith the vertex set as the set of all zero-divisors of $R$ and two distinct\nvertices $x$ and $y$ are adjacent if and only if $xy = 0$. This article\nattempts to predict the structure of the zero-divisor graph of the ring of\nGaussian integers modulo $2$ to the power $n$ and determine the size, chromatic\nnumber, clique number, independence number, and matching through associate\nclasses of divisors of $2^n$ in $\\mathbb{Z}_{2^n}[i]$. In addition, a few\ntopological indices of the corresponding zero-divisor graph, are obtained.","main_category":"math.AC","categories":"math.AC,math.CO,math.NT","published":"2025-04-03T11:15:59Z"}
{"aid":"http://arxiv.org/abs/2504.02502v1","title":"Berry-Esseen bounds for step-reinforced random walks","summary":"We study both the positively and negatively step-reinforced random walks with\nparameter $p$. For a step distribution $\\mu$ with finite second moment, the\npositively step-reinforced random walk with $p\\in [1/2,1)$ and the negatively\nstep-reinforced random walk with $p\\in (0,1)$ converge to a normal distribution\nunder suitable normalization. In this work, we obtain the rates of convergence\nto normality for both cases under the assumption that $\\mu$ has a finite third\nmoment. In the proofs, we establish a Berry-Esseen bound for general\nfunctionals of independent random variables, utilize the randomly weighted sum\nrepresentations of step-reinforced random walks, and apply special comparison\narguments to quantify the Kolmogorov distance between a mixed normal\ndistribution and its corresponding normal distribution.","main_category":"math.PR","categories":"math.PR","published":"2025-04-03T11:35:20Z"}
{"aid":"http://arxiv.org/abs/2504.02505v1","title":"Centrality dependence of charged-particle pseudorapidity density at\n  midrapidity in Pb-Pb collisions at $\\mathbf{\\sqrt{\\textit{s}_{\\rm NN}} =\n  5.36}$ TeV","summary":"The ALICE Collaboration reports its first LHC Run 3 measurements of\ncharged-particle pseudorapidity density at midrapidity in Pb-Pb collisions at a\ncentre-of-mass energy per nucleon pair of $\\sqrt{s_{\\mathrm{NN}}}=5.36$ TeV.\nParticle multiplicity in high-energy collisions characterises the system\ngeometry, constrains particle-production mechanisms, and is used to estimate\ninitial energy density. Multiplicity also acts as a reference for subsequent\nmeasurements as a function of centrality. In this letter, for the first time,\ncharged particles are reconstructed using the upgraded ALICE Inner Tracking\nSystem and Time Projection Chamber, while the collision centrality is\ndetermined by measuring charged-particle multiplicities with the Fast\nInteraction Trigger system. Pseudorapidity density, ${\\rm d}N_{\\rm ch}/{\\rm\nd}\\eta$, is presented, averaged over events, for various centrality classes.\nResults are shown as a function of pseudorapidity and the average number of\nparticipating nucleons ($\\langle N_{\\mathrm{part}}\\rangle$) in the collision.\nThe average charged-particle pseudorapidity density ($\\langle {\\rm d}N_{\\rm\nch}/{\\rm d}\\eta \\rangle$) at midrapidity ($|\\eta|<0.5$) is 2047 $\\pm$ 54 for\nthe 5% most central collisions. The value of $\\langle {\\rm d}N_{\\rm ch}/{\\rm\nd}\\eta \\rangle$ normalised to $\\langle N_{\\mathrm{part}}\\rangle/2$ as a\nfunction of $\\sqrt{s_{\\mathrm{NN}}}$ follows the trend established in previous\nmeasurements in heavy-ion collisions. Theoretical models based on mechanisms\nfor particle production in nuclear collisions that involve the formation of\nquark-gluon plasma medium and models based on individual nucleon-nucleon\ninteractions are compared to the data.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-03T11:36:43Z"}
{"aid":"http://arxiv.org/abs/2504.02532v1","title":"Polynomial Bounds for the Graph Minor Structure Theorem","summary":"The Graph Minor Structure Theorem, originally proven by Robertson and Seymour\n[JCTB, 2003], asserts that there exist functions $f_1, f_2 \\colon \\mathbb{N}\n\\to \\mathbb{N}$ such that for every non-planar graph $H$ with $t := |V(H)|$,\nevery $H$-minor-free graph can be obtained via the clique-sum operation from\ngraphs which embed into surfaces where $H$ does not embed after deleting at\nmost $f_1(t)$ many vertices with up to at most $t^2-1$ many ``vortices'' which\nare of ``depth'' at most $f_2(t)$. In the proof presented by Robertson and\nSeymour the functions $f_1$ and $f_2$ are non-constructive. Kawarabayashi,\nThomas, and Wollan [arXiv, 2020] found a new proof showing that $f_1(t), f_2(t)\n\\in 2^{\\mathbf{poly}(t)}$. While believing that this bound was the best their\nmethods could achieve, Kawarabayashi, Thomas, and Wollan conjectured that $f_1$\nand $f_2$ can be improved to be polynomials.\n  In this paper we confirm their conjecture and prove that $f_1(t), f_2(t) \\in\n\\mathbf{O}(t^{2300})$. Our proofs are fully constructive and yield a\npolynomial-time algorithm that either finds $H$ as a minor in a graph $G$ or\nproduces a clique-sum decomposition for $G$ as above.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-03T12:35:45Z"}
{"aid":"http://arxiv.org/abs/2504.02562v1","title":"Spectrum Assignment of Stochastic Systems with Multiplicative Noise","summary":"This paper studies the spectrum assignment of a class of stochastic systems\nwith multiplicative noise. A novel $\\alpha$-spectrum assignment is proposed for\ndiscrete-time and continuous-time stochastic systems with multiplicative noise.\nIn particular, $0$-spectrum assignment is equivalent to the pole assignment for\nthe deterministic systems. The main contribution is two-fold: On the one hand,\nwe present the conditions for $\\alpha$-spectrum assignment and the design of\nfeedback controllers based on the system parameters. On the other hand, when\nthe system parameters are unknown, we present a stochastic approximation\nalgorithm to learn the feedback gains which guarantee the spectrum of the\nstochastic systems to achieve the predetermined value. Numerical examples are\nprovided to demonstrate the effectiveness of the proposed algorithms.","main_category":"math.OC","categories":"math.OC","published":"2025-04-03T13:25:09Z"}
{"aid":"http://arxiv.org/abs/2504.02569v1","title":"Fluorine production in He-burning regions of massive stars during cosmic\n  history","summary":"The origin of fluorine is still a debated question. AGB stars synthesise this\nelement and likely contribute significantly to its synthesis in the present-day\nUniverse. However, it is not clear whether other sources contribute, especially\nin the early Universe. We discuss variations of the surface abundances of\nfluorine coming from our massive star models and compare them with available\npresent-day observations. We compute the contribution of massive stars in\nproducing 19F over metallicities covering the whole cosmic history. We used\nmodels in the mass range of 9Msol < Mini < 300Msol at metallicities from Pop\nIII up to super-solar while accounting for the required nuclear network to\nfollow the evolution of 19F during the core H- and He-burning phases. Results\nfrom models with and without rotational mixing are presented. We find that\nrotating models predict a slight depletion of fluorine at their surface at the\nend of the MS phase. In more advanced evolutionary phases, only models with an\ninitial mass larger than 25Msol at metallicities Z > 0.014 show phases where\nthe abundance of fluorine is enhanced. This occurs when the star is a WR star\nof the WC type. WC stars can show surface abundances of fluorine ten times\nlarger than their initial abundance. However, we obtained that the winds of\nmassive stars at metallicities larger than Z=0.006 do not significantly\ncontribute to fluorine production, confirming previous findings. In contrast,\nvery metal-poor rapidly rotating massive star models may be important sources\nof fluorine through the mass expelled at the time of their SN explosion.\nObservations of WC stars at solar or super-solar metallicities may provide very\ninteresting indications on the nuclear pathways that lead to fluorine\nproduction in massive stars. The possibility of observing fluorine-rich CEMPs\nis also a way to put constrains in present models at very low metallicities.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-03T13:36:04Z"}
{"aid":"http://arxiv.org/abs/2504.02583v1","title":"Ram√≠rez's problems and fibers on well approximable set of systems of\n  affine forms","summary":"We show that badly approximable matrices are exactly those that, for any\ninhomogeneous parameter, can not be inhomogeneous approximated at every\nmonotone divergent rate, which generalizes Ram\\'irez's result (2018). We also\nestablish some metrical results of the fibers on well approximable set of\nsystems of affine forms, which gives answer to two of Ram\\'irez's problems\n(2018). Furthermore, we prove that badly approximable systems are exactly those\nthat, can not be approximated at each monotone convergent rate {\\psi}.\nMoreover, we study the topological structure of the set of approximation\nfunctions.","main_category":"math.NT","categories":"math.NT,math.CA","published":"2025-04-03T13:49:12Z"}
{"aid":"http://arxiv.org/abs/2504.02590v1","title":"LexPam: Legal Procedure Awareness-Guided Mathematical Reasoning","summary":"The legal mathematical reasoning ability of LLMs is crucial when applying\nthem to real-world scenarios, as it directly affects the credibility of the\nLLM. While existing legal LLMs can perform general judicial question answering,\ntheir legal mathematical reasoning capabilities have not been trained.\nOpen-domain reasoning models, though able to generate detailed calculation\nsteps, do not follow the reasoning logic required for legal scenarios.\nAdditionally, there is currently a lack of legal mathematical reasoning\ndatasets to help validate and enhance LLMs' reasoning abilities in legal\ncontexts. To address these issues, we propose the first Chinese legal\nMathematical Reasoning Dataset, LexNum, which includes three common legal\nmathematical reasoning scenarios: economic compensation, work injury\ncompensation, and traffic accident compensation. Based on LexNum, we tested the\nperformance of existing legal LLMs and reasoning LLMs, and introduced LexPam, a\nreinforcement learning algorithm guided by legal procedural awareness to train\nLLMs, enhancing their mathematical reasoning abilities in legal scenarios.\nExperiments on tasks in the three legal scenarios show that the performance of\nexisting legal LLMs and reasoning models in legal mathematical reasoning tasks\nis unsatisfactory. LexPam can enhance the LLM's ability in these tasks.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T13:54:53Z"}
{"aid":"http://arxiv.org/abs/2504.02653v1","title":"Online and Offline Space-Filling Input Design for Nonlinear System\n  Identification: A Receding Horizon Control-Based Approach","summary":"The effectiveness of data-driven techniques heavily depends on the input\nsignal used to generate the estimation data. However, a significant research\ngap exists in the field of input design for nonlinear dynamic system\nidentification. In particular, existing methods largely overlook the\nminimization of the generalization error, i.e., model inaccuracies in regions\nnot covered by the estimation dataset. This work addresses this gap by\nproposing an input design method that embeds a novel optimality criterion\nwithin a receding horizon control (RHC)-based optimization framework. The\ndistance-based optimality criterion induces a space-filling design within a\nuser-defined region of interest in a surrogate model's input space, requiring\nonly minimal prior knowledge. Additionally, the method is applicable both\nonline, where model parameters are continuously updated based on process\nobservations, and offline, where a fixed model is employed. The space-filling\nperformance of the proposed strategy is evaluated on an artificial example and\ncompared to state-of-the-art methods, demonstrating superior efficiency in\nexploring process operating spaces.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-03T14:50:52Z"}
{"aid":"http://arxiv.org/abs/2504.02661v1","title":"Complete Classification of the Symmetry Group of $L_p$-Minkowski Problem\n  on the Sphere","summary":"In Convex Geometry, a core topic is the $L_p$-Minkowski problem\n  \\begin{equation}\\label{e0.1}\n  \\det(\\nabla^2h+hI)=fh^{p-1}, \\ \\ \\forall X\\in{\\mathbb{S}}^n, \\ \\ \\forall p\\in\n\\mathbb{R}\n  \\end{equation} of Monge-Amp\\`{e}re type. By the transformation\n$u(x)=h(X)\\sqrt{1+|x|^2}$ and semi-spherical projection, equation \\eqref{e0.1}\ncan be reformulated by the Monge-Amp\\`{e}re type equation\n  \\begin{equation}\\label{e0.2}\n  \\det D^2u=(1+|x|^2)^{-\\frac{p+n+1}{2}}u^{p-1}, \\ \\ \\forall\nx\\in{\\mathbb{R}}^n, \\ \\ \\forall p\\in \\mathbb{R}\n  \\end{equation} on the Euclidean space. In this paper, we will firstly\ndetermine the symmetric groups of $n$-dimensional fully nonlinear equation\n\\eqref{e0.2} without asymptotic growth assumption. After proving several key\nresolution lemmas, we thus completely classify the symmetric groups of the\n$L_p$-Minkowski problem. Our method develops the Lie theory to fully nonlinear\nPDEs in Convex Geometry.","main_category":"math.AP","categories":"math.AP,math.DG","published":"2025-04-03T14:57:14Z"}
{"aid":"http://arxiv.org/abs/2504.02696v1","title":"The Tension between Trust and Oversight in Long-term Relationships","summary":"A principal continually decides whether to approve resource allocations to an\nagent, who exerts private effort to remain eligible. The principal must perform\ncostly inspections to determine the agent's eligibility. We characterize Markov\nPerfect Equilibria and analyze the paths of trust and oversight that emerge\nfrom the dynamic interplay of effort and oversight. At high trust levels,\neffort is an intertemporal substitute to oversight, which leads to unique\ninterior effort choices and random inspections. At low trust levels, effort is\nan intertemporal complement to oversight, which may create a coordination\nproblem, leading to equilibrium multiplicity. Voluntary disclosure can mitigate\nthis coordination issue.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-03T15:32:41Z"}
{"aid":"http://arxiv.org/abs/2504.02724v1","title":"Autonomous Human-Robot Interaction via Operator Imitation","summary":"Teleoperated robotic characters can perform expressive interactions with\nhumans, relying on the operators' experience and social intuition. In this\nwork, we propose to create autonomous interactive robots, by training a model\nto imitate operator data. Our model is trained on a dataset of human-robot\ninteractions, where an expert operator is asked to vary the interactions and\nmood of the robot, while the operator commands as well as the pose of the human\nand robot are recorded. Our approach learns to predict continuous operator\ncommands through a diffusion process and discrete commands through a\nclassifier, all unified within a single transformer architecture. We evaluate\nthe resulting model in simulation and with a user study on the real system. We\nshow that our method enables simple autonomous human-robot interactions that\nare comparable to the expert-operator baseline, and that users can recognize\nthe different robot moods as generated by our model. Finally, we demonstrate a\nzero-shot transfer of our model onto a different robotic platform with the same\noperator interface.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-03T16:06:44Z"}
{"aid":"http://arxiv.org/abs/2504.02730v1","title":"HQViT: Hybrid Quantum Vision Transformer for Image Classification","summary":"Transformer-based architectures have revolutionized the landscape of deep\nlearning. In computer vision domain, Vision Transformer demonstrates remarkable\nperformance on par with or even surpassing that of convolutional neural\nnetworks. However, the quadratic computational complexity of its self-attention\nmechanism poses challenges for classical computing, making model training with\nhigh-dimensional input data, e.g., images, particularly expensive. To address\nsuch limitations, we propose a Hybrid Quantum Vision Transformer (HQViT), that\nleverages the principles of quantum computing to accelerate model training\nwhile enhancing model performance. HQViT introduces whole-image processing with\namplitude encoding to better preserve global image information without\nadditional positional encoding. By leveraging quantum computation on the most\ncritical steps and selectively handling other components in a classical way, we\nlower the cost of quantum resources for HQViT. The qubit requirement is\nminimized to $O(log_2N)$ and the number of parameterized quantum gates is only\n$O(log_2d)$, making it well-suited for Noisy Intermediate-Scale Quantum\ndevices. By offloading the computationally intensive attention coefficient\nmatrix calculation to the quantum framework, HQViT reduces the classical\ncomputational load by $O(T^2d)$. Extensive experiments across various computer\nvision datasets demonstrate that HQViT outperforms existing models, achieving a\nmaximum improvement of up to $10.9\\%$ (on the MNIST 10-classification task)\nover the state of the art. This work highlights the great potential to combine\nquantum and classical computing to cope with complex image classification\ntasks.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-03T16:13:34Z"}
{"aid":"http://arxiv.org/abs/2504.02732v1","title":"Why do LLMs attend to the first token?","summary":"Large Language Models (LLMs) tend to attend heavily to the first token in the\nsequence -- creating a so-called attention sink. Many works have studied this\nphenomenon in detail, proposing various ways to either leverage or alleviate\nit. Attention sinks have been connected to quantisation difficulties, security\nissues, and streaming attention. Yet, while many works have provided conditions\nin which they occur or not, a critical question remains shallowly answered: Why\ndo LLMs learn such patterns and how are they being used? In this work, we argue\ntheoretically and empirically that this mechanism provides a method for LLMs to\navoid over-mixing, connecting this to existing lines of work that study\nmathematically how information propagates in Transformers. We conduct\nexperiments to validate our theoretical intuitions and show how choices such as\ncontext length, depth, and data packing influence the sink behaviour. We hope\nthat this study provides a new practical perspective on why attention sinks are\nuseful in LLMs, leading to a better understanding of the attention patterns\nthat form during training.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T16:17:55Z"}
{"aid":"http://arxiv.org/abs/2504.02736v1","title":"Parity violation as enforced symmetry breaking in 3D fermionic\n  topological order","summary":"Symmetry can be intrinsically broken in topological phases due to inherent\nincompatibilities, a phenomenon known as enforced symmetry breaking (ESB) in\nthe framework of topological order. In our previous work, we developed a\nsystematic framework to understand ESB within 2D invertible topological order.\nMeanwhile, the origin of parity violation in the Standard Model remains one of\nthe most profound mysteries in physics, with no clear explanation to date. In\nthis study, we explore the ESB of parity symmetry by three-dimensional\nfermionic topological order (fTO), offering potential insights into the origins\nof parity violation. As the simplest example, here we consider an fTO related\nto the intrinsic interacting fermionic SPT phase protected by $Z_2^f\\times\nZ_2\\times Z_8$ symmetry in three dimensions. We show that time-reversal\nsymmetry (TRS) with ${T}^2=1$ on physical fermions is incompatible with such\nfTO; then, through the so-called crystalline equivalence principle, we show\nthat the parity symmetry is also incompatible with it. In comparison,\nconventional TRS with ${T}^2={P}_f$ remains compatible to this fTO. We also\ndiscuss a general framework to study the ESB phenomenon for 3D fTO.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.supr-con,hep-ph,hep-th","published":"2025-04-03T16:23:36Z"}
{"aid":"http://arxiv.org/abs/2504.02738v1","title":"Inequivalence of the low-density insulating state and quantum Hall\n  insulating states in a strongly correlated two-dimensional electron system","summary":"We find that the behaviors of the voltage-current characteristics as one\nenters the low-density insulating state and integer quantum Hall insulating\nstates in the ultra-clean two-dimensional electron system in SiGe/Si/SiGe\nquantum wells are qualitatively different. The double-threshold voltage-current\ncurves, representative of electron solid formation at low densities, are not\nobserved in the quantum Hall regime, which does not confirm the existence of a\nquasi-particle quantum Hall Wigner solid and indicates that quasi-particles\nnear integer filling do not form an independent subsystem.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mes-hall","published":"2025-04-03T16:24:54Z"}
{"aid":"http://arxiv.org/abs/2504.02744v1","title":"The Ordering Principle and Dependent Choice","summary":"We introduce finite support iterations of symmetric systems, and use them to\nprovide a strongly modernized proof of David Pincus' classical result that the\naxiom of dependent choice is independent over ZF with the ordering principle\ntogether with a failure of the axiom of choice.","main_category":"math.LO","categories":"math.LO","published":"2025-04-03T16:31:05Z"}
{"aid":"http://arxiv.org/abs/2504.02774v1","title":"Component-wise Krasnosel'skii type fixed point theorem in product spaces\n  and applications","summary":"We present a version of Krasnosel'skii fixed point theorem for operators\nacting on Cartesian products of normed linear spaces, under cone-compression\nand cone-expansion conditions of norm type. Our approach, based on the fixed\npoint index theory in cones, guarantees the existence of a coexistence fixed\npoint - that is, one with nontrivial components. As an application, we prove\nthe existence of periodic solutions with strictly positive components for a\nsystem of second-order differential equations. In particular, we address cases\ninvolving singular nonlinearities and hybrid terms, characterized by sublinear\nbehavior in one component and superlinear behavior in the other.","main_category":"math.FA","categories":"math.FA,math.CA","published":"2025-04-03T17:14:48Z"}
{"aid":"http://arxiv.org/abs/2504.02790v1","title":"Dynamic Treewidth in Logarithmic Time","summary":"We present a dynamic data structure that maintains a tree decomposition of\nwidth at most $9k+8$ of a dynamic graph with treewidth at most $k$, which is\nupdated by edge insertions and deletions. The amortized update time of our data\nstructure is $2^{O(k)} \\log n$, where $n$ is the number of vertices. The data\nstructure also supports maintaining any ``dynamic programming scheme'' on the\ntree decomposition, providing, for example, a dynamic version of Courcelle's\ntheorem with $O_{k}(\\log n)$ amortized update time; the $O_{k}(\\cdot)$ notation\nhides factors that depend on $k$. This improves upon a result of Korhonen,\nMajewski, Nadara, Pilipczuk, and Soko{\\l}owski [FOCS 2023], who gave a similar\ndata structure but with amortized update time $2^{k^{O(1)}} n^{o(1)}$.\nFurthermore, our data structure is arguably simpler.\n  Our main novel idea is to maintain a tree decomposition that is ``downwards\nwell-linked'', which allows us to implement local rotations and analysis\nsimilar to those for splay trees.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-03T17:37:46Z"}
{"aid":"http://arxiv.org/abs/2504.02793v1","title":"A Framework for Situating Innovations, Opportunities, and Challenges in\n  Advancing Vertical Systems with Large AI Models","summary":"Large artificial intelligence (AI) models have garnered significant attention\nfor their remarkable, often \"superhuman\", performance on standardized\nbenchmarks. However, when these models are deployed in high-stakes verticals\nsuch as healthcare, education, and law, they often reveal notable limitations.\nFor instance, they exhibit brittleness to minor variations in input data,\npresent contextually uninformed decisions in critical settings, and undermine\nuser trust by confidently producing or reproducing inaccuracies. These\nchallenges in applying large models necessitate cross-disciplinary innovations\nto align the models' capabilities with the needs of real-world applications. We\nintroduce a framework that addresses this gap through a layer-wise abstraction\nof innovations aimed at meeting users' requirements with large models. Through\nmultiple case studies, we illustrate how researchers and practitioners across\nvarious fields can operationalize this framework. Beyond modularizing the\npipeline of transforming large models into useful \"vertical systems\", we also\nhighlight the dynamism that exists within different layers of the framework.\nFinally, we discuss how our framework can guide researchers and practitioners\nto (i) optimally situate their innovations (e.g., when vertical-specific\ninsights can empower broadly impactful vertical-agnostic innovations), (ii)\nuncover overlooked opportunities (e.g., spotting recurring problems across\nverticals to develop practically useful foundation models instead of chasing\nbenchmarks), and (iii) facilitate cross-disciplinary communication of critical\nchallenges (e.g., enabling a shared vocabulary for AI developers, domain\nexperts, and human-computer interaction scholars).","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.CY,cs.HC","published":"2025-04-03T17:40:11Z"}
{"aid":"http://arxiv.org/abs/2504.02794v1","title":"MENA: Multimodal Epistemic Network Analysis for Visualizing Competencies\n  and Emotions","summary":"The need to improve geriatric care quality presents a challenge that requires\ninsights from stakeholders. While simulated trainings can boost competencies,\nextracting meaningful insights from these practices to enhance simulation\neffectiveness remains a challenge. In this study, we introduce Multimodal\nEpistemic Network Analysis (MENA), a novel framework for analyzing caregiver\nattitudes and emotions in an Augmented Reality setting and exploring how the\nawareness of a virtual geriatric patient (VGP) impacts these aspects. MENA\nenhances the capabilities of Epistemic Network Analysis by detecting positive\nemotions, enabling visualization and analysis of complex relationships between\ncaregiving competencies and emotions in dynamic caregiving practices. The\nframework provides visual representations that demonstrate how participants\nprovided more supportive care and engaged more effectively in person-centered\ncaregiving with aware VGP. This method could be applicable in any setting that\ndepends on dynamic interpersonal interactions, as it visualizes connections\nbetween key elements using network graphs and enables the direct comparison of\nmultiple networks, thereby broadening its implications across various fields.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-03T17:40:49Z"}
{"aid":"http://arxiv.org/abs/2504.02795v1","title":"Greedy Regular Convolutions","summary":"We introduce a class of convolutions on arithmetical functions that are\nregular in the sense of of Narkiewicz, homogeneous in the sense of Burnett et\nal, and bounded, in the sense that there exists a common finite bound for the\nrank of primitive numbers. Among these \"greedy convolutions\" the unitary\nconvolution and the \"ternary convolution\" are particularly interesting: they\nare the only regular, homogeneous convolutions where each primitive number have\nthe same finite rank. While the greedy convolution of length 3, also described\nin detail, has primitive numbers of rank 3 and rank 1, it is still special in\nthat the set of primitives can be generated by a simple recursive procedure\nthat we name selective sifting.","main_category":"math.NT","categories":"math.NT","published":"2025-04-03T17:41:11Z"}
{"aid":"http://arxiv.org/abs/2504.02814v1","title":"Convergence of the Markovian iteration for coupled FBSDEs via a\n  differentiation approach","summary":"In this paper, we investigate the Markovian iteration method for solving\ncoupled forward-backward stochastic differential equations (FBSDEs) featuring a\nfully coupled forward drift, meaning the drift term explicitly depends on both\nthe forward and backward processes. An FBSDE system typically involves three\nstochastic processes: the forward process $X$, the backward process $Y$\nrepresenting the solution, and the $Z$ process corresponding to the scaled\nderivative of $Y$. Prior research by Bender and Zhang (2008) has established\nconvergence results for iterative schemes dealing with $Y$-coupled FBSDEs.\nHowever, extending these results to equations with $Z$ coupling poses\nsignificant challenges, especially in uniformly controlling the Lipschitz\nconstant of the decoupling fields across iterations and time steps within a\nfixed-point framework.\n  To overcome this issue, we propose a novel differentiation-based method for\nhandling the $Z$ process. This approach enables improved management of the\nLipschitz continuity of decoupling fields, facilitating the well-posedness of\nthe discretized FBSDE system with fully coupled drift. We rigorously prove the\nconvergence of our Markovian iteration method in this more complex setting.\nFinally, numerical experiments confirm our theoretical insights, showcasing the\neffectiveness and accuracy of the proposed methodology.","main_category":"math.NA","categories":"math.NA,cs.NA,math.PR,q-fin.CP","published":"2025-04-03T17:56:36Z"}
{"aid":"http://arxiv.org/abs/2504.02826v1","title":"Envisioning Beyond the Pixels: Benchmarking Reasoning-Informed Visual\n  Editing","summary":"Large Multi-modality Models (LMMs) have made significant progress in visual\nunderstanding and generation, but they still face challenges in General Visual\nEditing, particularly in following complex instructions, preserving appearance\nconsistency, and supporting flexible input formats. To address this gap, we\nintroduce RISEBench, the first benchmark for evaluating Reasoning-Informed\nviSual Editing (RISE). RISEBench focuses on four key reasoning types: Temporal,\nCausal, Spatial, and Logical Reasoning. We curate high-quality test cases for\neach category and propose an evaluation framework that assesses Instruction\nReasoning, Appearance Consistency, and Visual Plausibility with both human\njudges and an LMM-as-a-judge approach. Our experiments reveal that while\nGPT-4o-Native significantly outperforms other open-source and proprietary\nmodels, even this state-of-the-art system struggles with logical reasoning\ntasks, highlighting an area that remains underexplored. As an initial effort,\nRISEBench aims to provide foundational insights into reasoning-aware visual\nediting and to catalyze future research. Though still in its early stages, we\nare committed to continuously expanding and refining the benchmark to support\nmore comprehensive, reliable, and scalable evaluations of next-generation\nmultimodal systems. Our code and data will be released at\nhttps://github.com/PhoenixZ810/RISEBench.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T17:59:56Z"}
{"aid":"http://arxiv.org/abs/2504.04740v1","title":"Enhancing Compositional Reasoning in Vision-Language Models with\n  Synthetic Preference Data","summary":"Compositionality, or correctly recognizing scenes as compositions of atomic\nvisual concepts, remains difficult for multimodal large language models\n(MLLMs). Even state of the art MLLMs such as GPT-4o can make mistakes in\ndistinguishing compositions like \"dog chasing cat\" vs \"cat chasing dog\". While\non Winoground, a benchmark for measuring such reasoning, MLLMs have made\nsignificant progress, they are still far from a human's performance. We show\nthat compositional reasoning in these models can be improved by elucidating\nsuch concepts via data, where a model is trained to prefer the correct caption\nfor an image over a close but incorrect one. We introduce SCRAMBLe: Synthetic\nCompositional Reasoning Augmentation of MLLMs with Binary preference Learning,\nan approach for preference tuning open-weight MLLMs on synthetic preference\ndata generated in a fully automated manner from existing image-caption data.\nSCRAMBLe holistically improves these MLLMs' compositional reasoning\ncapabilities which we can see through significant improvements across multiple\nvision language compositionality benchmarks, as well as smaller but significant\nimprovements on general question answering tasks. As a sneak peek, SCRAMBLe\ntuned Molmo-7B model improves on Winoground from 49.5% to 54.8% (best reported\nto date), while improving by ~1% on more general visual question answering\ntasks. Code for SCRAMBLe along with tuned models and our synthetic training\ndataset is available at https://github.com/samarth4149/SCRAMBLe.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T05:35:34Z"}
{"aid":"http://arxiv.org/abs/2504.04743v1","title":"AnyArtisticGlyph: Multilingual Controllable Artistic Glyph Generation","summary":"Artistic Glyph Image Generation (AGIG) differs from current\ncreativity-focused generation models by offering finely controllable\ndeterministic generation. It transfers the style of a reference image to a\nsource while preserving its content. Although advanced and promising, current\nmethods may reveal flaws when scrutinizing synthesized image details, often\nproducing blurred or incorrect textures, posing a significant challenge. Hence,\nwe introduce AnyArtisticGlyph, a diffusion-based, multilingual controllable\nartistic glyph generation model. It includes a font fusion and embedding\nmodule, which generates latent features for detailed structure creation, and a\nvision-text fusion and embedding module that uses the CLIP model to encode\nreferences and blends them with transformation caption embeddings for seamless\nglobal image generation. Moreover, we incorporate a coarse-grained\nfeature-level loss to enhance generation accuracy. Experiments show that it\nproduces natural, detailed artistic glyph images with state-of-the-art\nperformance. Our project will be open-sourced on\nhttps://github.com/jiean001/AnyArtisticGlyph to advance text generation\ntechnology.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T05:37:39Z"}
{"aid":"http://arxiv.org/abs/2504.04761v1","title":"WLPCM Approach for Great Lakes Regulation","summary":"This study develops a water-level management model for the Great Lakes using\na predictive control framework. Requirement 1: Historical data (pre-2019)\nrevealed consistent monthly water-level patterns. A simulated annealing\nalgorithm optimized flow control via the Moses-Saunders Dam and Compensating\nWorks to align levels with multi-year benchmarks. Requirement 2: A Water Level\nPredictive Control Model (WLPCM) integrated delayed differential equations\n(DDEs) and model predictive control (MPC) to account for inflow/outflow\ndynamics and upstream time lags. Natural variables (e.g., precipitation) were\nmodeled via linear regression, while dam flow rates were optimized over 6-month\nhorizons with feedback adjustments for robustness. Requirement 3: Testing WLPCM\non 2017 data successfully mitigated Ottawa River flooding, outperforming\nhistorical records. Sensitivity analysis via the Sobol method confirmed model\nresilience to parameter variations. Requirement 4: Ice-clogging was identified\nas the most impactful natural variable (via RMSE-based sensitivity tests),\nfollowed by snowpack and precipitation. Requirement 5: Stakeholder demands\n(e.g., flood prevention, ecological balance) were incorporated into a fitness\nfunction. Compared to Plan 2014, WLPCM reduced catastrophic high levels in Lake\nOntario and excessive St. Lawrence River flows by prioritizing long-term\noptimization. Key innovations include DDE-based predictive regulation,\nreal-time feedback loops, and adaptive control under extreme conditions. The\nframework balances hydrological dynamics, stakeholder needs, and uncertainty\nmanagement, offering a scalable solution for large freshwater systems.","main_category":"math.OC","categories":"math.OC","published":"2025-04-07T06:21:22Z"}
{"aid":"http://arxiv.org/abs/2504.04767v1","title":"Extended URDF: Accounting for parallel mechanism in robot description","summary":"Robotic designs played an important role in recent advances by providing\npowerful robots with complex mechanics. Many recent systems rely on parallel\nactuation to provide lighter limbs and allow more complex motion. However,\nthese emerging architectures fall outside the scope of most used description\nformats, leading to difficulties when designing, storing, and sharing the\nmodels of these systems. This paper introduces an extension to the widely used\nUnified Robot Description Format (URDF) to support closed-loop kinematic\nstructures. Our approach relies on augmenting URDF with minimal additional\ninformation to allow more efficient modeling of complex robotic systems while\nmaintaining compatibility with existing design and simulation frameworks. This\nmethod sets the basic requirement for a description format to handle parallel\nmechanisms efficiently. We demonstrate the applicability of our approach by\nproviding an open-source collection of parallel robots, along with tools for\ngenerating and parsing this extended description format. The proposed extension\nsimplifies robot modeling, reduces redundancy, and improves usability for\nadvanced robotic applications.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T06:42:27Z"}
{"aid":"http://arxiv.org/abs/2504.04769v1","title":"Scalable simulation of random quantum circuits using projected\n  entangled-pair states","summary":"Classical simulation of a programmable quantum processor is crucial in\nidentifying the threshold of a quantum advantage. We use the simple update of\nprojected entangled-pair states (PEPSs) in the Vidal gauge to simulate the\nstates of random quantum circuits (RQCs), which center around recent quantum\nadvantage claims. Applied to square lattices of qubits akin to state-of-the-art\nsuperconducting processors, our PEPS simulation is exact for circuit depths\nless than $D_\\mathrm{tr}$ = $\\beta\\log_2\\chi$, where $\\chi$ is the maximum bond\ndimension and $2 \\lesssim \\beta \\lesssim 4$ depends on the choice of two-qubit\ngates, independent of the qubit number $n$. We find the universal scaling\nbehaviors of the state fidelity by performing large-scale simulations for $n\n\\leq 10^{4}$ or $\\chi \\leq 128$ on a conventional CPU. Our method has\ncomputational cost scaling polynomially with $n$ for circuit depth $D =O(\\log\nn)$ and is more advantageous than matrix product state (MPS) approaches if $n$\nis large. This work underscores PEPSs as a scalable tool for benchmarking\nquantum algorithms, with future potential for sampling applications using\nadvanced contraction techniques.","main_category":"quant-ph","categories":"quant-ph,physics.comp-ph","published":"2025-04-07T06:47:48Z"}
{"aid":"http://arxiv.org/abs/2504.04776v1","title":"Drastic softening of Pd nanoparticles induced by hydrogen cycling","summary":"Single crystalline faceted Pd nanoparticles attached to a sapphire substrate\nwere fabricated employing the solid state dewetting method. The as-dewetted\nnanoparticles tested in compression exhibited all features of dislocation\nnucleation-controlled plasticity, including the size effect on strength and\nultrahigh compressive strength reaching up to 11 GPa. Hydrogen cycling of\nas-dewetted Pd nanoparticles resulted in their drastic softening and in change\nof the deformation mode. This softening effect was correlated with the high\ndensity of glissile dislocations observed in the cycled particles. This work\ndemonstrates that the nanomechanical behavior of hydride-forming metals can be\nmanipulated by hydrogen cycling.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-07T07:09:10Z"}
{"aid":"http://arxiv.org/abs/2504.04786v1","title":"Dynamic fabrication method of SNAP microresonators","summary":"Surface Nanoscale Axial Photonics (SNAP) technology has demonstrated the\nrecord subangstrom fabrication precision of optical microresonators and\nresonant photonic circuits at the optical fiber surface. However, fabrication\nerrors arising from fluctuations of temperature, inscription parameters,\nalignment inconsistencies, and other factors did not allow researchers to\nachieve the subangstrom precision without sophisticated postprocessing. Here we\nshow that the key fabrication method of SNAP structures -- CO$_2$ laser beam\noptical fiber annealing -- suffers from significant fiber displacements which\nmay introduce a few percent fabrication errors. To suppress the effects of\nmisalignment, we develop a dynamic fabrication method employing a translating\nbeam exposure and demonstrate its excellent precision. The effective fiber\nradius variation of $\\sim 10 $nm is introduced with an error of $\\sim 0.1\n$angstrom. We suggest that the remaining fabrication errors can be attributed\nto laser power fluctuations.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-07T07:31:13Z"}
{"aid":"http://arxiv.org/abs/2504.04813v1","title":"Generalized Fermi-Dirac Distribution of Exclusive Fermions","summary":"A system of exclusive fermions occurs when two fermions of opposite spin are\nprohibited from occupying the same quantum level. We derive the distribution of\nexclusive fermions via the employment of the grand canonical ensemble. Salient\nfeatures of its statistical properties, compared to the free electron gases,\ninclude: larger Fermi energy, higher degeneracy pressure, but the same Pauli\nparamagnetism and Landau diamagnetism. In particular, higher degeneracy\npressure leads to an inflation of the Chandrasekhar limit to 1.6 times when\napplied to white dwarf stars and neutron stars.","main_category":"math-ph","categories":"math-ph,astro-ph.SR,cond-mat.stat-mech,math.MP","published":"2025-04-07T08:08:57Z"}
{"aid":"http://arxiv.org/abs/2504.04842v1","title":"FantasyTalking: Realistic Talking Portrait Generation via Coherent\n  Motion Synthesis","summary":"Creating a realistic animatable avatar from a single static portrait remains\nchallenging. Existing approaches often struggle to capture subtle facial\nexpressions, the associated global body movements, and the dynamic background.\nTo address these limitations, we propose a novel framework that leverages a\npretrained video diffusion transformer model to generate high-fidelity,\ncoherent talking portraits with controllable motion dynamics. At the core of\nour work is a dual-stage audio-visual alignment strategy. In the first stage,\nwe employ a clip-level training scheme to establish coherent global motion by\naligning audio-driven dynamics across the entire scene, including the reference\nportrait, contextual objects, and background. In the second stage, we refine\nlip movements at the frame level using a lip-tracing mask, ensuring precise\nsynchronization with audio signals. To preserve identity without compromising\nmotion flexibility, we replace the commonly used reference network with a\nfacial-focused cross-attention module that effectively maintains facial\nconsistency throughout the video. Furthermore, we integrate a motion intensity\nmodulation module that explicitly controls expression and body motion\nintensity, enabling controllable manipulation of portrait movements beyond mere\nlip motion. Extensive experimental results show that our proposed approach\nachieves higher quality with better realism, coherence, motion intensity, and\nidentity preservation. Ours project page:\nhttps://fantasy-amap.github.io/fantasy-talking/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T08:56:01Z"}
{"aid":"http://arxiv.org/abs/2504.04853v1","title":"Charmonium-nucleon femtoscopic correlation function","summary":"This study investigates the femtoscopic correlation functions of\ncharmonium-nucleon pairs, utilizing the lattice QCD phase shifts provided by\nthe HAL QCD Collaboration. A model-independent formalism is employed to\ntransform scattering phase shifts directly into momentum correlation functions,\nthereby circumventing the approximations inherent in traditional methods, such\nas the Lednick\\'y-Lyuboshits model. The $J/\\psi$-$p$ correlation functions,\nincluding spin-averaged and partial-wave results, are predicted using\nnear-physical pion mass lattice results. The $\\eta_c$-$p$ correlation function\nis calculated for the first time. The derived correlation functions provide\ncritical references for future experiments, such as those at the LHC, where\nhigh-precision measurements of charmonium-nucleon correlations could unveil\nvaluable insights into non-perturbative QCD dynamics.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-07T09:10:58Z"}
{"aid":"http://arxiv.org/abs/2504.04860v1","title":"Stochastic differential equations driven by fractional Brownian motion:\n  dependence on the Hurst parameter","summary":"Stochastic models with fractional Brownian motion as source of randomness\nhave become popular since the early 2000s. Fractional Brownian motion (fBm) is\na Gaussian process, whose covariance depends on the so-called Hurst parameter\n$H\\in (0,1)$. Consequently, stochastic models with fBm also depend on the Hurst\nparameter $H$, and the stability of these models with respect to $H$ is an\ninteresting and important question. In recent years, the continuous (or even\nsmoother) dependence on the Hurst parameter has been studied for several\nstochastic models, including stochastic integrals with respect to fBm,\nstochastic differential equations (SDEs) driven by fBm and also stochastic\npartial differential equations with fractional noise, for different topologies,\ne.g., in law or almost surely, and for finite and infinite time horizons. In\nthis manuscript, we give an overview of these results with a particular focus\non SDE models.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T09:17:59Z"}
{"aid":"http://arxiv.org/abs/2504.04943v1","title":"Emergence of microbial host dormancy during a persistent virus epidemic","summary":"We study a minimal stochastic individual-based model for a microbial\npopulation challenged by a persistent (lytic) virus epidemic. We focus on the\nsituation in which the resident microbial host population and the virus\npopulation are in stable coexistence upon arrival of a single new ``mutant''\nhost individual. We assume that this mutant is capable of switching to a\nreversible state of dormancy upon contact with virions as a means of avoiding\ninfection by the virus. At the same time, we assume that this new dormancy\ntrait comes with a cost, namely a reduced individual reproduction rate. We\nprove that there is a non-trivial range of parameters where the mutants can\nnevertheless invade the resident population with strictly positive probability\n(bounded away from 0) in the large population limit. Given the reduced\nreproductive rate, such an invasion would be impossible in the absence of\neither the dormancy trait or the virus epidemic. We explicitly characterize the\nparameter regime where this emergence of a (costly) host dormancy trait is\npossible, determine the success probability of a single invader and the typical\namount of time it takes the successful mutants to reach a macroscopic\npopulation size. We conclude this study by an investigation of the fate of the\npopulation after the successful emergence of a dormancy trait. Heuristic\narguments and simulations suggest that after successful invasion, either both\nhost types and the virus will reach coexistence, or the mutants will drive the\nresident hosts to extinction while the virus will stay in the system.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T11:30:42Z"}
{"aid":"http://arxiv.org/abs/2504.04962v1","title":"A refined operational semantics for FreeCHR","summary":"Constraint Handling Rules (CHR) is a rule-based programming language that\nwhich is typically embedded into a general-purpose language with a plethora of\nimplementations. However, the existing implementations often re-invent the way\nto embed CHR, which impedes maintenance and weakens assertions of correctness.\nTo formalize and thereby unify the embedding of CHR into arbitrary host\nlanguages, we recently introduced the framework FreeCHR and proved it to be a\nvalid representation of classical CHR. Until now, this framework only includes\na translation of the very abstract operational semantics of CHR which, due to\nits abstract nature, introduces several practical issues. In this paper we\npresent a definition of the refined operational semantics for FreeCHR and prove\nit to be both, a valid concretization of the very abstract semantics of\nFreeCHR, and an equivalent representation of the refined semantics of CHR. This\nwill establish implementations of FreeCHR as equivalent in behavior and\nexpressiveness to existing implementations of CHR. This is an extended preprint\nof a paper submitted to the the 41st International Conference on Logic\nProgramming.","main_category":"cs.PL","categories":"cs.PL","published":"2025-04-07T11:51:07Z"}
{"aid":"http://arxiv.org/abs/2504.04972v1","title":"Sub-diffusive behavior of a recurrent Axis-Driven Random Walk","summary":"We study the second order of the number of excursions of a simple random walk\nwith a bias that drives a return toward the origin along the axes introduced by\nP. Andreoletti and P. Debs \\cite{AndDeb3}. This is a crucial step toward\nderiving the asymptotic behavior of these walks, whose limit is explicit and\nreveals various characteristics of the process: the invariant probability\nmeasure of the extracted coordinates away from the axes, the 1-stable\ndistribution arising from the tail distribution of entry times on the axes, and\nfinally, the presence of a Bessel process of dimension 3, which implies that\nthe trajectory can be interpreted as a random path conditioned to stay within a\nsingle quadrant.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T11:58:11Z"}
{"aid":"http://arxiv.org/abs/2504.04982v1","title":"Transforming Future Data Center Operations and Management via Physical\n  AI","summary":"Data centers (DCs) as mission-critical infrastructures are pivotal in\npowering the growth of artificial intelligence (AI) and the digital economy.\nThe evolution from Internet DC to AI DC has introduced new challenges in\noperating and managing data centers for improved business resilience and\nreduced total cost of ownership. As a result, new paradigms, beyond the\ntraditional approaches based on best practices, must be in order for future\ndata centers. In this research, we propose and develop a novel Physical AI\n(PhyAI) framework for advancing DC operations and management. Our system\nleverages the emerging capabilities of state-of-the-art industrial products and\nour in-house research and development. Specifically, it presents three core\nmodules, namely: 1) an industry-grade in-house simulation engine to simulate DC\noperations in a highly accurate manner, 2) an AI engine built upon NVIDIA\nPhysicsNemo for the training and evaluation of physics-informed machine\nlearning (PIML) models, and 3) a digital twin platform built upon NVIDIA\nOmniverse for our proposed 5-tier digital twin framework. This system presents\na scalable and adaptable solution to digitalize, optimize, and automate future\ndata center operations and management, by enabling real-time digital twins for\nfuture data centers. To illustrate its effectiveness, we present a compelling\ncase study on building a surrogate model for predicting the thermal and airflow\nprofiles of a large-scale DC in a real-time manner. Our results demonstrate its\nsuperior performance over traditional time-consuming Computational Fluid\nDynamics/Heat Transfer (CFD/HT) simulation, with a median absolute temperature\nprediction error of 0.18 {\\deg}C. This emerging approach would open doors to\nseveral potential research directions for advancing Physical AI in future DC\noperations.","main_category":"cs.AI","categories":"cs.AI,cs.DC","published":"2025-04-07T12:09:22Z"}
{"aid":"http://arxiv.org/abs/2504.04995v1","title":"The universal crossover from thermodynamics and dynamics of\n  supercritical RN-AdS black hole","summary":"We study the properties of supercritical Reissner-Nordstr\\\"om Anti-de Sitter\n(RN-AdS) black holes in the extended phase space with the pressure defines as\nthe cosmological constant. Supercritical black holes exist in the region where\nboth temperature and pressure exceed the critical point, known as the\nsupercritical region. The conventional view states that black holes in this\nregime are indistinguishable between large and small phases. However, recent\nresearch reveals that the supercritical regime exhibits universal gas-like and\nliquid-like phase separation, which shed light on the study on the\nsupercritical region of RN-AdS black holes in the extended phase space. In this\nwork, we calculate the thermodynamic potential and quasinormal modes (QNMs) of\nRN-AdS black holes, and identify transition curves between two different states\nin supercritical region using thermodynamic and dynamic methods. On one hand,\nwe find the thermodynamic crossover curve (Widom line) by defining the scaled\nvariance $\\Omega$ (a higher-order derivative of Gibbs free energy). On the\nother hand, we identify the dynamic crossover curve (Frenkel line) by analyzing\ntransitions between distinct QNM decay modes.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-ph,hep-th","published":"2025-04-07T12:24:23Z"}
{"aid":"http://arxiv.org/abs/2504.05003v1","title":"Re-evaluation of the deuteron-deuteron thermonuclear reaction rates in\n  metallic deuterium plasma","summary":"The deuteron-deuteron (D-D) thermonuclear reaction rates in metallic\nenvironments (considering the electron screening effects) is re-evaluated using\nthe S-factor functions which\n  were obtained by fitting to low-energy data on D-D reactions.\n  For this purpose, a fitted S-factor model based on the NACRE compilation is\nemployed.\n  This limited the energy range of Big Bang nucleosynthesis (BBN) for\n  the $ ^{2}\\textrm{H}\\left(d,p\\right) ^{3}\\textrm{H}$ and $^{2} \\textrm{H}\n\\left(d,n\\right) ^{3}\\textrm{He}$ reactions.\n  The corresponding Maxwellian-averaged thermonuclear reaction\n  rates of relevance in astrophysical plasmas at temperatures in the\n  range from $10^{6}$ K to $10^{10}\\left(\\textrm{or }1.3\\times10^{8}\\right)$ K\nare provided in tabular formats.\n  In these evaluations,\n  the screening energy is assumed to be $100, 400, 750, 1000$ eV and $1250$ eV.\n  This series of values has been selected based on theoretical and experimental\nstudies conducted so far.","main_category":"nucl-th","categories":"nucl-th,nucl-ex","published":"2025-04-07T12:30:20Z"}
{"aid":"http://arxiv.org/abs/2504.05015v1","title":"PVASS Reachability is Decidable","summary":"Reachability in pushdown vector addition systems with states (PVASS) is among\nthe longest standing open problems in Theoretical Computer Science. We show\nthat the problem is decidable in full generality. Our decision procedure is\nsimilar in spirit to the KLMST algorithm for VASS reachability, but works over\nobjects that support an elaborate form of procedure summarization as known from\npushdown reachability.","main_category":"cs.LO","categories":"cs.LO,cs.FL,F.1.1","published":"2025-04-07T12:40:18Z"}
{"aid":"http://arxiv.org/abs/2504.05019v1","title":"Mixture-of-Personas Language Models for Population Simulation","summary":"Advances in Large Language Models (LLMs) paved the way for their emerging\napplications in various domains, such as human behavior simulations, where LLMs\ncould augment human-generated data in social science research and machine\nlearning model training. However, pretrained LLMs often fail to capture the\nbehavioral diversity of target populations due to the inherent variability\nacross individuals and groups. To address this, we propose \\textit{Mixture of\nPersonas} (MoP), a \\textit{probabilistic} prompting method that aligns the LLM\nresponses with the target population. MoP is a contextual mixture model, where\neach component is an LM agent characterized by a persona and an exemplar\nrepresenting subpopulation behaviors. The persona and exemplar are randomly\nchosen according to the learned mixing weights to elicit diverse LLM responses\nduring simulation. MoP is flexible, requires no model finetuning, and is\ntransferable across base models. Experiments for synthetic data generation show\nthat MoP outperforms competing methods in alignment and diversity metrics.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-07T12:43:05Z"}
{"aid":"http://arxiv.org/abs/2504.05046v1","title":"MotionPRO: Exploring the Role of Pressure in Human MoCap and Beyond","summary":"Existing human Motion Capture (MoCap) methods mostly focus on the visual\nsimilarity while neglecting the physical plausibility. As a result, downstream\ntasks such as driving virtual human in 3D scene or humanoid robots in real\nworld suffer from issues such as timing drift and jitter, spatial problems like\nsliding and penetration, and poor global trajectory accuracy. In this paper, we\nrevisit human MoCap from the perspective of interaction between human body and\nphysical world by exploring the role of pressure. Firstly, we construct a\nlarge-scale human Motion capture dataset with Pressure, RGB and Optical sensors\n(named MotionPRO), which comprises 70 volunteers performing 400 types of\nmotion, encompassing a total of 12.4M pose frames. Secondly, we examine both\nthe necessity and effectiveness of the pressure signal through two challenging\ntasks: (1) pose and trajectory estimation based solely on pressure: We propose\na network that incorporates a small kernel decoder and a long-short-term\nattention module, and proof that pressure could provide accurate global\ntrajectory and plausible lower body pose. (2) pose and trajectory estimation by\nfusing pressure and RGB: We impose constraints on orthographic similarity along\nthe camera axis and whole-body contact along the vertical axis to enhance the\ncross-attention strategy to fuse pressure and RGB feature maps. Experiments\ndemonstrate that fusing pressure with RGB features not only significantly\nimproves performance in terms of objective metrics, but also plausibly drives\nvirtual humans (SMPL) in 3D scene. Furthermore, we demonstrate that\nincorporating physical perception enables humanoid robots to perform more\nprecise and stable actions, which is highly beneficial for the development of\nembodied artificial intelligence. Project page is available at:\nhttps://nju-cite-mocaphumanoid.github.io/MotionPRO/","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:17:24Z"}
{"aid":"http://arxiv.org/abs/2504.05049v1","title":"CMaP-SAM: Contraction Mapping Prior for SAM-driven Few-shot Segmentation","summary":"Few-shot segmentation (FSS) aims to segment new classes using few annotated\nimages. While recent FSS methods have shown considerable improvements by\nleveraging Segment Anything Model (SAM), they face two critical limitations:\ninsufficient utilization of structural correlations in query images, and\nsignificant information loss when converting continuous position priors to\ndiscrete point prompts. To address these challenges, we propose CMaP-SAM, a\nnovel framework that introduces contraction mapping theory to optimize position\npriors for SAM-driven few-shot segmentation. CMaP-SAM consists of three key\ncomponents: (1) a contraction mapping module that formulates position prior\noptimization as a Banach contraction mapping with convergence guarantees. This\nmodule iteratively refines position priors through pixel-wise structural\nsimilarity, generating a converged prior that preserves both semantic guidance\nfrom reference images and structural correlations in query images; (2) an\nadaptive distribution alignment module bridging continuous priors with SAM's\nbinary mask prompt encoder; and (3) a foreground-background decoupled\nrefinement architecture producing accurate final segmentation masks. Extensive\nexperiments demonstrate CMaP-SAM's effectiveness, achieving state-of-the-art\nperformance with 71.1 mIoU on PASCAL-$5^i$ and 56.1 on COCO-$20^i$ datasets.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:19:16Z"}
{"aid":"http://arxiv.org/abs/2504.05065v1","title":"Quantitative Supermartingale Certificates","summary":"We introduce a general methodology for quantitative model checking and\ncontrol synthesis with supermartingale certificates. We show that every\nspecification that is invariant to time shifts admits a stochastic invariant\nthat bounds its probability from below; for systems with general state space,\nthe stochastic invariant bounds this probability as closely as desired; for\nsystems with finite state space, it quantifies it exactly. Our result enables\nthe extension of every certificate for the almost-sure satisfaction of\nshift-invariant specifications to its quantitative counterpart, ensuring\ncompleteness up to an approximation in the general case and exactness in the\nfinite-state case. This generalises and unifies existing supermartingale\ncertificates for quantitative verification and control under reachability,\nsafety, reach-avoidance, and stability specifications, as well as asymptotic\nbounds on accrued costs and rewards. Furthermore, our result provides the first\nsupermartingale certificate for computing upper and lower bounds on the\nprobability of satisfying $\\omega$-regular and linear temporal logic\nspecifications. We present an algorithm for quantitative $\\omega$-regular\nverification and control synthesis based on our method and demonstrate its\npractical efficacy on several infinite-state examples.","main_category":"cs.LO","categories":"cs.LO,cs.SY,eess.SY","published":"2025-04-07T13:34:40Z"}
{"aid":"http://arxiv.org/abs/2504.05089v1","title":"Climplicit: Climatic Implicit Embeddings for Global Ecological Tasks","summary":"Deep learning on climatic data holds potential for macroecological\napplications. However, its adoption remains limited among scientists outside\nthe deep learning community due to storage, compute, and technical expertise\nbarriers. To address this, we introduce Climplicit, a spatio-temporal\ngeolocation encoder pretrained to generate implicit climatic representations\nanywhere on Earth. By bypassing the need to download raw climatic rasters and\ntrain feature extractors, our model uses x1000 fewer disk space and\nsignificantly reduces computational needs for downstream tasks. We evaluate our\nClimplicit embeddings on biomes classification, species distribution modeling,\nand plant trait regression. We find that linear probing our Climplicit\nembeddings consistently performs better or on par with training a model from\nscratch on downstream tasks and overall better than alternative geolocation\nencoding models.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:58:55Z"}
{"aid":"http://arxiv.org/abs/2504.05110v1","title":"Stochastic storage models in theoretical physics problems","summary":"Stochastic storage models based on essentially non-Gaussian noise are\nconsidered. The stochastic description of physical systems based on stochastic\nstorage models is associated with generalized Poisson (or shot) noise, in which\nthe jump values can be quite large. Stochastic storage models have a direct\nphysical meaning: some elements enter the system and leave it. Storage\nprocesses fit into the general scheme of dynamic systems subject to the\nadditive influence of a random process. The main relationships of storage\nmodels are described, and the possibilities of applying the mathematical\nprovisions of stochastic storage processes to various physical problems are\nindicated. A number of examples of applying the stochastic storage model are\nconsidered.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-07T14:15:18Z"}
{"aid":"http://arxiv.org/abs/2504.05122v1","title":"DoCIA: An Online Document-Level Context Incorporation Agent for Speech\n  Translation","summary":"Document-level context is crucial for handling discourse challenges in\ntext-to-text document-level machine translation (MT). Despite the increased\ndiscourse challenges introduced by noise from automatic speech recognition\n(ASR), the integration of document-level context in speech translation (ST)\nremains insufficiently explored. In this paper, we develop DoCIA, an online\nframework that enhances ST performance by incorporating document-level context.\nDoCIA decomposes the ST pipeline into four stages. Document-level context is\nintegrated into the ASR refinement, MT, and MT refinement stages through\nauxiliary LLM (large language model)-based modules. Furthermore, DoCIA\nleverages document-level information in a multi-level manner while minimizing\ncomputational overhead. Additionally, a simple yet effective determination\nmechanism is introduced to prevent hallucinations from excessive refinement,\nensuring the reliability of the final results. Experimental results show that\nDoCIA significantly outperforms traditional ST baselines in both sentence and\ndiscourse metrics across four LLMs, demonstrating its effectiveness in\nimproving ST performance.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T14:26:49Z"}
{"aid":"http://arxiv.org/abs/2504.05128v1","title":"Kinetic study of compressible Rayleigh-Taylor instability with\n  time-varying acceleration","summary":"Rayleigh-Taylor (RT) instability commonly arises in compressible systems with\ntime-dependent acceleration in practical applications. To capture the complex\ndynamics of such systems, a two-component discrete Boltzmann method is\ndeveloped to systematically investigate the compressible RT instability driven\nby variable acceleration. Specifically, the effects of different acceleration\nperiods, amplitudes, and phases are systematically analyzed. The simulation\nresults are interpreted from three key perspectives: the density gradient,\nwhich characterizes the spatial variation in density; the thermodynamic\nnon-equilibrium strength, which quantifies the system's deviation from local\nthermodynamic equilibrium; and the fraction of non-equilibrium regions, which\ncaptures the spatial distribution of non-equilibrium behaviors. Notably, the\nfluid system exhibits rich and diverse dynamic patterns resulting from the\ninterplay of multiple competing physical mechanisms, including time-dependent\nacceleration, RT instability, diffusion, and dissipation effects. These\nfindings provide deeper insights into the evolution and regulation of\ncompressible RT instability under complex driving conditions.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-07T14:32:33Z"}
{"aid":"http://arxiv.org/abs/2504.05158v1","title":"Leveraging Label Potential for Enhanced Multimodal Emotion Recognition","summary":"Multimodal emotion recognition (MER) seeks to integrate various modalities to\npredict emotional states accurately. However, most current research focuses\nsolely on the fusion of audio and text features, overlooking the valuable\ninformation in emotion labels. This oversight could potentially hinder the\nperformance of existing methods, as emotion labels harbor rich, insightful\ninformation that could significantly aid MER. We introduce a novel model called\nLabel Signal-Guided Multimodal Emotion Recognition (LSGMER) to overcome this\nlimitation. This model aims to fully harness the power of emotion label\ninformation to boost the classification accuracy and stability of MER.\nSpecifically, LSGMER employs a Label Signal Enhancement module that optimizes\nthe representation of modality features by interacting with audio and text\nfeatures through label embeddings, enabling it to capture the nuances of\nemotions precisely. Furthermore, we propose a Joint Objective Optimization(JOO)\napproach to enhance classification accuracy by introducing the\nAttribution-Prediction Consistency Constraint (APC), which strengthens the\nalignment between fused features and emotion categories. Extensive experiments\nconducted on the IEMOCAP and MELD datasets have demonstrated the effectiveness\nof our proposed LSGMER model.","main_category":"cs.SD","categories":"cs.SD,cs.AI,eess.AS","published":"2025-04-07T15:00:34Z"}
{"aid":"http://arxiv.org/abs/2504.05196v1","title":"Universal Lymph Node Detection in Multiparametric MRI with Selective\n  Augmentation","summary":"Robust localization of lymph nodes (LNs) in multiparametric MRI (mpMRI) is\ncritical for the assessment of lymphadenopathy. Radiologists routinely measure\nthe size of LN to distinguish benign from malignant nodes, which would require\nsubsequent cancer staging. Sizing is a cumbersome task compounded by the\ndiverse appearances of LNs in mpMRI, which renders their measurement difficult.\nFurthermore, smaller and potentially metastatic LNs could be missed during a\nbusy clinical day. To alleviate these imaging and workflow problems, we propose\na pipeline to universally detect both benign and metastatic nodes in the body\nfor their ensuing measurement. The recently proposed VFNet neural network was\nemployed to identify LN in T2 fat suppressed and diffusion weighted imaging\n(DWI) sequences acquired by various scanners with a variety of exam protocols.\nWe also use a selective augmentation technique known as Intra-Label LISA (ILL)\nto diversify the input data samples the model sees during training, such that\nit improves its robustness during the evaluation phase. We achieved a\nsensitivity of $\\sim$83\\% with ILL vs. $\\sim$80\\% without ILL at 4 FP/vol.\nCompared with current LN detection approaches evaluated on mpMRI, we show a\nsensitivity improvement of $\\sim$9\\% at 4 FP/vol.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-07T15:46:43Z"}
{"aid":"http://arxiv.org/abs/2504.05206v1","title":"Content-aware rankings: a new approach to rankings in scholarship","summary":"Entity rankings (e.g., institutions, journals) are a core component of\nacademia and related industries. Existing approaches to institutional rankings\nhave relied on a variety of data sources, and approaches to computing outcomes,\nbut remain controversial. One limitation of existing approaches is reliance on\nscholarly output (e.g., number of publications associated with a given\ninstitution during a time period). We propose a new approach to rankings - one\nthat relies not on scholarly output, but rather on the type of citations\nreceived (an implementation of the Scite Index). We describe how the necessary\ndata can be gathered, as well as how relevant metrics are computed. To\ndemonstrate the utility of our approach, we present rankings of fields,\njournals, and institutions, and discuss the various ways Scite's data can be\ndeployed in the context of rankings. Implications, limitations, and future\ndirections are discussed.","main_category":"cs.DL","categories":"cs.DL","published":"2025-04-07T15:55:18Z"}
{"aid":"http://arxiv.org/abs/2504.05221v1","title":"Apparent fractional charge signatures in PbTe quantum dots due to\n  capacitively coupled charge trap dynamics","summary":"We report the observation of fractional shifts in the experimental stability\ndiagrams of PbTe nanowire quantum dots. Although this behavior may appear to\nsuggest fractional charge transport, akin to that reported in the fractional\nquantum Hall regime, the quasi-one-dimensionality of the system and absence of\nan applied magnetic field indicate that the presence of fractional charges is\nhighly unlikely. We instead attribute these effects to the presence of one or\nmore spurious dots, or charge traps, capacitively coupled to the primary dot.\nOur findings illustrate how signatures of fractional charge transport may be\nreplicated through trivial mesoscopic Coulombic effects.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-07T16:08:20Z"}
{"aid":"http://arxiv.org/abs/2504.05232v1","title":"Discovery of the 7-ring PAH Cyanocoronene (C$_{24}$H$_{11}$CN) in GOTHAM\n  Observations of TMC-1","summary":"We present the synthesis and laboratory rotational spectroscopy of the 7-ring\npolycyclic aromatic hydrocarbon (PAH) cyanocoronene (C$_{24}$H$_{11}$CN) using\na laser-ablation assisted cavity-enhanced Fourier transform microwave\nspectrometer. A total of 71 transitions were measured and assigned between\n6.8--10.6\\,GHz. Using these assignments, we searched for emission from\ncyanocoronene in the GBT Observations of TMC-1: Hunting Aromatic Molecules\n(GOTHAM) project observations of the cold dark molecular cloud TMC-1 using the\n100\\,m Green Bank Telescope (GBT). We detect a number of individually resolved\ntransitions in ultrasensitive X-band observations and perform a Markov Chain\nMonte Carlo analysis to derive best-fit parameters, including a total column\ndensity of $N(\\mathrm{C}_{24}\\mathrm{H}_{11}\\mathrm{CN}) = 2.69^{+0.26}_{-0.23}\n\\times 10^{12}\\,\\mathrm{cm}^{-2}$ at a temperature of\n$6.05^{+0.38}_{-0.37}\\,$K. A spectral stacking and matched filtering analysis\nprovides a robust 17.3$\\,\\sigma$ significance to the overall detection. The\nderived column density is comparable to that of cyano-substituted naphthalene,\nacenaphthylene, and pyrene, defying the trend of decreasing abundance with\nincreasing molecular size and complexity found for carbon chains. We discuss\nthe implications of the detection for our understanding of interstellar PAH\nchemistry and highlight major open questions and next steps.","main_category":"astro-ph.GA","categories":"astro-ph.GA,physics.chem-ph","published":"2025-04-07T16:15:54Z"}
{"aid":"http://arxiv.org/abs/2504.05249v1","title":"Texture2LoD3: Enabling LoD3 Building Reconstruction With Panoramic\n  Images","summary":"Despite recent advancements in surface reconstruction, Level of Detail (LoD)\n3 building reconstruction remains an unresolved challenge. The main issue\npertains to the object-oriented modelling paradigm, which requires\ngeoreferencing, watertight geometry, facade semantics, and low-poly\nrepresentation -- Contrasting unstructured mesh-oriented models. In\nTexture2LoD3, we introduce a novel method leveraging the ubiquity of 3D\nbuilding model priors and panoramic street-level images, enabling the\nreconstruction of LoD3 building models. We observe that prior low-detail\nbuilding models can serve as valid planar targets for ortho-rectifying\nstreet-level panoramic images. Moreover, deploying segmentation on accurately\ntextured low-level building surfaces supports maintaining essential\ngeoreferencing, watertight geometry, and low-poly representation for LoD3\nreconstruction. In the absence of LoD3 validation data, we additionally\nintroduce the ReLoD3 dataset, on which we experimentally demonstrate that our\nmethod leads to improved facade segmentation accuracy by 11% and can replace\ncostly manual projections. We believe that Texture2LoD3 can scale the adoption\nof LoD3 models, opening applications in estimating building solar potential or\nenhancing autonomous driving simulations. The project website, code, and data\nare available here: https://wenzhaotang.github.io/Texture2LoD3/.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-07T16:40:16Z"}
{"aid":"http://arxiv.org/abs/2504.05276v1","title":"Enhancing LLM-Based Short Answer Grading with Retrieval-Augmented\n  Generation","summary":"Short answer assessment is a vital component of science education, allowing\nevaluation of students' complex three-dimensional understanding. Large language\nmodels (LLMs) that possess human-like ability in linguistic tasks are\nincreasingly popular in assisting human graders to reduce their workload.\nHowever, LLMs' limitations in domain knowledge restrict their understanding in\ntask-specific requirements and hinder their ability to achieve satisfactory\nperformance. Retrieval-augmented generation (RAG) emerges as a promising\nsolution by enabling LLMs to access relevant domain-specific knowledge during\nassessment. In this work, we propose an adaptive RAG framework for automated\ngrading that dynamically retrieves and incorporates domain-specific knowledge\nbased on the question and student answer context. Our approach combines\nsemantic search and curated educational sources to retrieve valuable reference\nmaterials. Experimental results in a science education dataset demonstrate that\nour system achieves an improvement in grading accuracy compared to baseline LLM\napproaches. The findings suggest that RAG-enhanced grading systems can serve as\nreliable support with efficient performance gains.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T17:17:41Z"}
{"aid":"http://arxiv.org/abs/2504.05627v1","title":"Maternal and Fetal Health Status Assessment by Using Machine Learning on\n  Optical 3D Body Scans","summary":"Monitoring maternal and fetal health during pregnancy is crucial for\npreventing adverse outcomes. While tests such as ultrasound scans offer high\naccuracy, they can be costly and inconvenient. Telehealth and more accessible\nbody shape information provide pregnant women with a convenient way to monitor\ntheir health. This study explores the potential of 3D body scan data, captured\nduring the 18-24 gestational weeks, to predict adverse pregnancy outcomes and\nestimate clinical parameters. We developed a novel algorithm with two parallel\nstreams which are used for extract body shape features: one for supervised\nlearning to extract sequential abdominal circumference information, and another\nfor unsupervised learning to extract global shape descriptors, alongside a\nbranch for demographic data.\n  Our results indicate that 3D body shape can assist in predicting preterm\nlabor, gestational diabetes mellitus (GDM), gestational hypertension (GH), and\nin estimating fetal weight. Compared to other machine learning models, our\nalgorithm achieved the best performance, with prediction accuracies exceeding\n88% and fetal weight estimation accuracy of 76.74% within a 10% error margin,\noutperforming conventional anthropometric methods by 22.22%.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-08T03:02:26Z"}
{"aid":"http://arxiv.org/abs/2504.05630v1","title":"A new discrimination measure for assessing predictive performance of\n  non-linear survival models","summary":"Non-linear survival models are flexible models in which the proportional\nhazard assumption is not required. This poses difficulties in their evaluation.\nWe introduce a new discrimination measure, time-dependent Uno's C-index, to\nassess the discrimination performance of non-linear survival models. This is an\nunbiased version of Antolini's time-dependent concordance. We prove convergence\nof both measures employing Nolan and Pollard's results on U-statistics. We\nexplore the relationship between these measures and, in particular, the bias of\nAntolini's concordance in the presence of censoring using simulated data. We\ndemonstrate the value of time-dependent Uno's C-index for the evaluation of\nmodels trained on censored real data and for model tuning.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-08T03:11:43Z"}
{"aid":"http://arxiv.org/abs/2504.05645v1","title":"A Study of Multiple Molecular Lines at the 3 mm Band toward Gas\n  Infalling Sources","summary":"The study of multiple molecular spectral lines in gas infalling sources can\nprovide the physical and chemical properties of these sources and help us\nestimate their evolutionary stages. We report line detections within the 3 mm\nband using the FTS wide-sideband mode of the IRAM 30 m telescope toward 20\ngas-infalling sources. Using XCLASS, we identify the emission lines of up to 22\nmolecular species (including a few isotopologues) and one hydrogen radio\nrecombination line in these sources. H$^{13}$CO$^+$, HCO$^+$, HCN, HNC,\nc-C$_3$H$_2$, and CCH lines are detected in 15 sources. We estimate the\nrotation temperatures and column densities of these molecular species using the\nLTE radiative transfer model, and compare the molecular abundances of these\nsources with those from nine high-mass star-forming regions reported in\nprevious studies and with those from the chemical model. Our results suggest\nthat G012.79-0.20, G012.87-0.22 clump A and B, and G012.96-0.23 clump A may be\nin the high-mass protostellar object stage, while sources with fewer detected\nspecies may be in the earlier evolutionary stage. Additionally, the CCH and\nc-C$_3$H$_2$ column densities in our sources reveal a linear correlation, with\na ratio of N(CCH)/N(c-C$_3$H$_2$) = 89.2$\\pm$5.6, which is higher than the\nratios reported in the literature. When considering only sources with lower\ncolumn densities, this ratio decreases to 29.0$\\pm$6.1, consistent with those\nof diffuse clouds. Furthermore, a comparison between the N(CCH)/N(c-C$_3$H$_2$)\nratio and the sources' physical parameters reveals a correlation, with sources\nexhibiting higher ratios tending to have higher kinetic temperatures and H$_2$\ncolumn densities.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-08T03:40:53Z"}
{"aid":"http://arxiv.org/abs/2504.05648v1","title":"The stochastic Navier-Stokes equations with general $L^{3}$ data","summary":"We consider the stochastic Navier-Stokes equations with multiplicative noise\nwith critical initial data. Assuming that the initial data $u_0$ belongs to the\ncritical space $L^{3}$ almost surely, we construct a unique local-in-time\nprobabilistically strong solution. We also prove an analogous result for data\nin the critical space~$H^\\frac{1}{2}$.","main_category":"math.PR","categories":"math.PR,math.AP","published":"2025-04-08T03:52:54Z"}
{"aid":"http://arxiv.org/abs/2504.05697v1","title":"VADIS: A Visual Analytics Pipeline for Dynamic Document Representation\n  and Information-Seeking","summary":"In the biomedical domain, visualizing the document embeddings of an extensive\ncorpus has been widely used in information-seeking tasks. However, three key\nchallenges with existing visualizations make it difficult for clinicians to\nfind information efficiently. First, the document embeddings used in these\nvisualizations are generated statically by pretrained language models, which\ncannot adapt to the user's evolving interest. Second, existing document\nvisualization techniques cannot effectively display how the documents are\nrelevant to users' interest, making it difficult for users to identify the most\npertinent information. Third, existing embedding generation and visualization\nprocesses suffer from a lack of interpretability, making it difficult to\nunderstand, trust and use the result for decision-making. In this paper, we\npresent a novel visual analytics pipeline for user driven document\nrepresentation and iterative information seeking (VADIS). VADIS introduces a\nprompt-based attention model (PAM) that generates dynamic document embedding\nand document relevance adjusted to the user's query. To effectively visualize\nthese two pieces of information, we design a new document map that leverages a\ncircular grid layout to display documents based on both their relevance to the\nquery and the semantic similarity. Additionally, to improve the\ninterpretability, we introduce a corpus-level attention visualization method to\nimprove the user's understanding of the model focus and to enable the users to\nidentify potential oversight. This visualization, in turn, empowers users to\nrefine, update and introduce new queries, thereby facilitating a dynamic and\niterative information-seeking experience. We evaluated VADIS quantitatively and\nqualitatively on a real-world dataset of biomedical research papers to\ndemonstrate its effectiveness.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-08T05:39:11Z"}
{"aid":"http://arxiv.org/abs/2504.05721v1","title":"Graph product and the stability of circulant graphs","summary":"A graph $\\Gamma$ is said to be stable if $\\mathrm{Aut}(\\Gamma\\times\nK_2)\\cong\\mathrm{Aut}(\\Gamma)\\times \\mathbb{Z}_{2}$ and unstable otherwise. If\nan unstable graph is connected, non-bipartite and any two of its distinct\nvertices have different neighborhoods, then it is called nontrivially unstable.\nWe establish conditions guaranteeing the instability of various graph products,\nincluding direct products, direct product bundles, Cartesian products, strong\nproducts, semi-strong products, and lexicographic products. Inspired by a\ncondition for the instability of direct product bundles, we propose a new\nsufficient condition for circulant graphs to be unstable. This condition yields\ninfinitely many nontrivially unstable circulant graphs that do not satisfy any\npreviously established instability conditions for circulant graphs.","main_category":"math.CO","categories":"math.CO","published":"2025-04-08T06:42:11Z"}
{"aid":"http://arxiv.org/abs/2504.05737v1","title":"Developing a novel hybrid family associated with hypergeometric\n  functions through umbral techniques","summary":"The umbral methods are used to reformulate the theoretical framework of\nspecial functions and provide powerful techniques for uncovering new extensions\nand relationships among these functions. This research article introduces an\ninnovative class of special polynomials, specifically the hypergeometric-Appell\npolynomials. The fundamental attributes of this versatile family of special\npolynomials are outlined, including generating relations, explicit\nrepresentations, and differential recurrence relations. Certain particular\nexamples that belong to the class of hypergeometric-Appell polynomials are also\nconsidered. This article aims to reinforce the broad applicability of the\numbral approach to address complex mathematical challenges and contribute to\nvarious scientific and engineering endeavors.","main_category":"math.CA","categories":"math.CA","published":"2025-04-08T07:12:20Z"}
{"aid":"http://arxiv.org/abs/2504.05743v1","title":"Causal Portfolio Optimization: Principles and Sensitivity-Based\n  Solutions","summary":"Fundamental and necessary principles for achieving efficient portfolio\noptimization based on asset and diversification dynamics are presented. The\nCommonality Principle is a necessary and sufficient condition for identifying\noptimal drivers of a portfolio in terms of its diversification dynamics. The\nproof relies on the Reichenbach Common Cause Principle, along with the fact\nthat the sensitivities of portfolio constituents with respect to the common\ncausal drivers are themselves causal. A conformal map preserves idiosyncratic\ndiversification from the unconditional setting while optimizing systematic\ndiversification on an embedded space of these sensitivities. Causal\nmethodologies for combinatorial driver selection are presented, such as the use\nof Bayesian networks and correlation-based algorithms from Reichenbach's\nprinciple. Limitations of linear models in capturing causality are discussed,\nand included for completeness alongside more advanced models such as neural\nnetworks. Portfolio optimization methods are presented that map risk from the\nsensitivity space to other risk measures of interest. Finally, the work\nintroduces a novel risk management framework based on Common Causal Manifolds,\nincluding both theoretical development and experimental validation. The\nsensitivity space is predicted along the common causal manifold, which is\nmodeled as a causal time system. Sensitivities are forecasted using SDEs\ncalibrated to data previously extracted from neural networks to move along the\nmanifold via its tangent bundles. An optimization method is then proposed that\naccumulates information across future predicted tangent bundles on the common\ncausal time system manifold. It aggregates sensitivity-based distance metrics\nalong the trajectory to build a comprehensive sensitivity distance matrix. This\nmatrix enables trajectory-wide optimal diversification, taking into account\nfuture dynamics.","main_category":"q-fin.PM","categories":"q-fin.PM","published":"2025-04-08T07:21:40Z"}
{"aid":"http://arxiv.org/abs/2504.05754v1","title":"Dispersion-corrected Machine Learning Potentials for 2D van der Waals\n  Materials","summary":"Machine-learned interatomic potentials (MLIPs) based on message passing\nneural networks hold promise to enable large-scale atomistic simulations of\ncomplex materials with ab initio accuracy. A number of MLIPs trained on\nenergies and forces from density functional theory (DFT) calculations employing\nsemi-local exchange-correlation (xc) functionals have recently been introduced.\nHere, we benchmark the performance of six dispersion-corrected MLIPs on a\ndataset of van der Waals heterobilayers containing between 4 and 300 atoms in\nthe moir\\'e cell. Using various structure similarity metrics, we compare the\nrelaxed heterostructures to the ground truth DFT results. With some notable\nexceptions, the model precisions are comparable to the uncertainty on the DFT\nresults stemming from the choice of xc-functional. We further explore how the\nstructural inaccuracies propagate to the electronic properties, and find\nexcellent performance with average errors on band energies as low as 35 meV.\nOur results demonstrate that recent MLIPs after dispersion corrections are on\npar with DFT for general vdW heterostructures, and thus justify their\napplication to complex and experimentally relevant 2D materials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T07:35:53Z"}
{"aid":"http://arxiv.org/abs/2504.05760v1","title":"Cutoff for East models at high temperature","summary":"We consider the East model in $\\mathbb Z^d$, an example of a kinetically\nconstrained interacting particle system with oriented constraints, together\nwith one of its natural variant. Under any ergodic boundary condition it is\nknown that the mixing time of the chain in a box of side $L$ is $\\Theta(L)$ for\nany $d\\ge 1$. Moreover, with minimal boundary conditions and at low\ntemperature, i.e. low equilibrium density of the facilitating vertices, the\nchain exhibits cutoff around the mixing time of the $d=1$ case. Here we extend\nthis result to high temperature. As in the low temperature case, the key tool\nis to prove that the speed of infection propagation in the $(1,1,\\dots,1)$\ndirection is larger than $d$ $\\times$ the same speed along a coordinate\ndirection. By borrowing a technique from first passage percolation, the proof\nlinks the result to the precise value of the critical probability of oriented\n(bond or site) percolation in $\\mathbb Z^d$.","main_category":"math.PR","categories":"math.PR","published":"2025-04-08T07:42:29Z"}
{"aid":"http://arxiv.org/abs/2504.05765v1","title":"Probabilistic Process Discovery with Stochastic Process Trees","summary":"In order to obtain a stochastic model that accounts for the stochastic\naspects of the dynamics of a business process, usually the following steps are\ntaken. Given an event log, a process tree is obtained through a process\ndiscovery algorithm, i.e., a process tree that is aimed at reproducing, as\naccurately as possible, the language of the log. The process tree is then\ntransformed into a Petri net that generates the same set of sequences as the\nprocess tree. In order to capture the frequency of the sequences in the event\nlog, weights are assigned to the transitions of the Petri net, resulting in a\nstochastic Petri net with a stochastic language in which each sequence is\nassociated with a probability. In this paper we show that this procedure has\nunfavorable properties. First, the weights assigned to the transitions of the\nPetri net have an unclear role in the resulting stochastic language. We will\nshow that a weight can have multiple, ambiguous impact on the probability of\nthe sequences generated by the Petri net. Second, a number of different Petri\nnets with different number of transitions can correspond to the same process\ntree. This means that the number of parameters (the number of weights) that\ndetermines the stochastic language is not well-defined. In order to avoid these\nambiguities, in this paper, we propose to add stochasticity directly to process\ntrees. The result is a new formalism, called stochastic process trees, in which\nthe number of parameters and their role in the associated stochastic language\nis clear and well-defined.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T07:46:06Z"}
{"aid":"http://arxiv.org/abs/2504.05787v1","title":"Finiteness properties of asymptotically rigid handlebody groups","summary":"We introduce asymptotically rigid mapping class groups of handlebodies and\ndetermine their finiteness properties, which vary depending on the space of\nends of the underlying handlebody. As it turns out, in some cases, the homology\nof these groups coincides with the stable homology of handlebody groups, as\nstudied by Hatcher and Wahl.","main_category":"math.GT","categories":"math.GT,math.GR","published":"2025-04-08T08:13:15Z"}
{"aid":"http://arxiv.org/abs/2504.05795v1","title":"Robust Fusion Controller: Degradation-aware Image Fusion with\n  Fine-grained Language Instructions","summary":"Current image fusion methods struggle to adapt to real-world environments\nencompassing diverse degradations with spatially varying characteristics. To\naddress this challenge, we propose a robust fusion controller (RFC) capable of\nachieving degradation-aware image fusion through fine-grained language\ninstructions, ensuring its reliable application in adverse environments.\nSpecifically, RFC first parses language instructions to innovatively derive the\nfunctional condition and the spatial condition, where the former specifies the\ndegradation type to remove, while the latter defines its spatial coverage.\nThen, a composite control priori is generated through a multi-condition\ncoupling network, achieving a seamless transition from abstract language\ninstructions to latent control variables. Subsequently, we design a hybrid\nattention-based fusion network to aggregate multi-modal information, in which\nthe obtained composite control priori is deeply embedded to linearly modulate\nthe intermediate fused features. To ensure the alignment between language\ninstructions and control outcomes, we introduce a novel language-feature\nalignment loss, which constrains the consistency between feature-level gains\nand the composite control priori. Extensive experiments on publicly available\ndatasets demonstrate that our RFC is robust against various composite\ndegradations, particularly in highly challenging flare scenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T08:22:55Z"}
{"aid":"http://arxiv.org/abs/2504.05834v1","title":"Elongation-Induced Segregation in Periodically Textured Microfluidic\n  Channels","summary":"We numerically investigate the motion of elongated microparticles in\nmicrofluidic channels at low Reynolds numbers. In channels with smooth walls,\nasymmetric initial conditions -- including particle orientation and lateral\nposition -- lead to continuous variations in particle trajectories, potentially\nexhibiting repeated behavior depending on the channel geometry and initial\nconditions. However, we find that introducing periodically textured walls\ninduces alignment of the particle with the channel centerline within a specific\nrange of texture wavelengths. This occurs as the textured pattern disrupts the\nuniformity of the flow, creating localized high-velocity nodes that repeatedly\nguide the particle toward the centerline as it moves downstream. Notably, the\ncharacteristic length scale over which this alignment forms reduces with\nincreasing particle elongation and diverges with increasing Reynolds number.\nOur findings reveal that elongation-induced alignment can be leveraged for\nmicrofluidic filtering applications, enabling the efficient separation of\nmicroparticles based on their geometric properties. This work opens new avenues\nfor designing microfluidic devices tailored for high-precision particle\nsorting, with broad implications for biomedical and industrial applications.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cond-mat.stat-mech,physics.comp-ph","published":"2025-04-08T09:17:23Z"}
{"aid":"http://arxiv.org/abs/2504.05841v1","title":"Continuous spectrum-shrinking maps between finite-dimensional algebras","summary":"Let $\\mathcal{A}$ and $\\mathcal{B}$ be unital finite-dimensional complex\nalgebras, each equipped with the unique Hausdorff vector topology. Denote by\n$\\mathrm{Max}(\\mathcal{A})=\\{\\mathcal{M}_1, \\ldots, \\mathcal{M}_p\\}$ and\n$\\mathrm{Max}(\\mathcal{B})=\\{\\mathcal{N}_1, \\ldots, \\mathcal{N}_q\\}$ the sets\nof all maximal ideals of $\\mathcal{A}$ and $\\mathcal{B}$, respectively, and\ndefine the quantities $$k_i:=\\sqrt{\\dim(\\mathcal{A}/\\mathcal{M}_i)}, \\, \\, 1\n\\leq i \\leq p \\quad \\text{ and } \\quad\nm:=\\sum_{j=1}^q\\sqrt{\\dim(\\mathcal{B}/\\mathcal{N}_j)},$$ which are positive\nintegers by Wedderburn's structure theorem. We show that there exists a\ncontinuous spectrum-shrinking map $\\phi: \\mathcal{A} \\to \\mathcal{B}$ (i.e.\n$\\mathrm{sp}(\\phi(x))\\subseteq \\mathrm{sp}(x)$ for all $x \\in \\mathcal{A}$) if\nand only if the linear Diophantine equation $$ k_1x_1 + \\cdots + k_px_p = m $$\nhas a non-negative integer solution $(x_1,\\ldots,x_p)$. Moreover, all such maps\n$\\phi$ are spectrum preserving (i.e. $\\mathrm{sp}(\\phi(x))=\\mathrm{sp}(x)$ for\nall $x \\in \\mathcal{A}$) if and only if each non-negative solution consists\nonly of positive integers.","main_category":"math.SP","categories":"math.SP,math.RA","published":"2025-04-08T09:21:40Z"}
{"aid":"http://arxiv.org/abs/2504.05857v1","title":"Towards an AI-Driven Video-Based American Sign Language Dictionary:\n  Exploring Design and Usage Experience with Learners","summary":"Searching for unfamiliar American Sign Language (ASL) signs is challenging\nfor learners because, unlike spoken languages, they cannot type a text-based\nquery to look up an unfamiliar sign. Advances in isolated sign recognition have\nenabled the creation of video-based dictionaries, allowing users to submit a\nvideo and receive a list of the closest matching signs. Previous HCI research\nusing Wizard-of-Oz prototypes has explored interface designs for ASL\ndictionaries. Building on these studies, we incorporate their design\nrecommendations and leverage state-of-the-art sign-recognition technology to\ndevelop an automated video-based dictionary. We also present findings from an\nobservational study with twelve novice ASL learners who used this dictionary\nduring video-comprehension and question-answering tasks. Our results address\nhuman-AI interaction challenges not covered in previous WoZ research, including\nrecording and resubmitting signs, unpredictable outputs, system latency, and\nprivacy concerns. These insights offer guidance for designing and deploying\nvideo-based ASL dictionary systems.","main_category":"cs.HC","categories":"cs.HC,cs.AI","published":"2025-04-08T09:35:46Z"}
{"aid":"http://arxiv.org/abs/2504.05886v1","title":"Learning strategies for optimised fitness in a model of cyclic dominance","summary":"A major problem in evolutionary biology is how species learn and adapt under\nthe constraint of environmental conditions and competition of other species.\nModels of cyclic dominance provide simplified settings in which such questions\ncan be addressed using methods from theoretical physics. We investigate how a\nprivileged (\"smart\") species optimises its population by adopting advantageous\nstrategies in one such model. We use a reinforcement learning algorithm, which\nsuccessfully identifies optimal strategies based on a survival-of-the-weakest\neffect, including directional incentives to avoid predators. We also\ncharacterise the steady-state behaviour of the system in the presence of the\nsmart species and compare with the symmetric case where all species are\nequivalent.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,q-bio.PE","published":"2025-04-08T10:22:25Z"}
{"aid":"http://arxiv.org/abs/2504.05887v1","title":"Jointly-optimized Trajectory Generation and Camera Control for 3D\n  Coverage Planning","summary":"This work proposes a jointly optimized trajectory generation and camera\ncontrol approach, enabling an autonomous agent, such as an unmanned aerial\nvehicle (UAV) operating in 3D environments, to plan and execute coverage\ntrajectories that maximally cover the surface area of a 3D object of interest.\nSpecifically, the UAV's kinematic and camera control inputs are jointly\noptimized over a rolling planning horizon to achieve complete 3D coverage of\nthe object. The proposed controller incorporates ray-tracing into the planning\nprocess to simulate the propagation of light rays, thereby determining the\nvisible parts of the object through the UAV's camera. This integration enables\nthe generation of precise look-ahead coverage trajectories. The coverage\nplanning problem is formulated as a rolling finite-horizon optimal control\nproblem and solved using mixed-integer programming techniques. Extensive\nreal-world and synthetic experiments validate the performance of the proposed\napproach.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-08T10:23:37Z"}
{"aid":"http://arxiv.org/abs/2504.05904v1","title":"Intrinsic Saliency Guided Trunk-Collateral Network for Unsupervised\n  Video Object Segmentation","summary":"Recent unsupervised video object segmentation (UVOS) methods predominantly\nadopt the motion-appearance paradigm. Mainstream motion-appearance approaches\nuse either the two-encoder structure to separately encode motion and appearance\nfeatures, or the single-encoder structure for joint encoding. However, these\nmethods fail to properly balance the motion-appearance relationship.\nConsequently, even with complex fusion modules for motion-appearance\nintegration, the extracted suboptimal features degrade the models' overall\nperformance. Moreover, the quality of optical flow varies across scenarios,\nmaking it insufficient to rely solely on optical flow to achieve high-quality\nsegmentation results. To address these challenges, we propose the Intrinsic\nSaliency guided Trunk-Collateral Net}work (ISTC-Net), which better balances the\nmotion-appearance relationship and incorporates model's intrinsic saliency\ninformation to enhance segmentation performance. Specifically, considering that\noptical flow maps are derived from RGB images, they share both commonalities\nand differences. We propose a novel Trunk-Collateral structure. The shared\ntrunk backbone captures the motion-appearance commonality, while the collateral\nbranch learns the uniqueness of motion features. Furthermore, an Intrinsic\nSaliency guided Refinement Module (ISRM) is devised to efficiently leverage the\nmodel's intrinsic saliency information to refine high-level features, and\nprovide pixel-level guidance for motion-appearance fusion, thereby enhancing\nperformance without additional input. Experimental results show that ISTC-Net\nachieved state-of-the-art performance on three UVOS datasets (89.2% J&F on\nDAVIS-16, 76% J on YouTube-Objects, 86.4% J on FBMS) and four standard video\nsalient object detection (VSOD) benchmarks with the notable increase,\ndemonstrating its effectiveness and superiority over previous methods.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-08T11:02:14Z"}
{"aid":"http://arxiv.org/abs/2504.05921v1","title":"Accelerated Reeds-Shepp and Under-Specified Reeds-Shepp Algorithms for\n  Mobile Robot Path Planning","summary":"In this study, we present a simple and intuitive method for accelerating\noptimal Reeds-Shepp path computation. Our approach uses geometrical reasoning\nto analyze the behavior of optimal paths, resulting in a new partitioning of\nthe state space and a further reduction in the minimal set of viable paths. We\nrevisit and reimplement classic methodologies from the literature, which lack\ncontemporary open-source implementations, to serve as benchmarks for evaluating\nour method. Additionally, we address the under-specified Reeds-Shepp planning\nproblem where the final orientation is unspecified. We perform exhaustive\nexperiments to validate our solutions. Compared to the modern C++\nimplementation of the original Reeds-Shepp solution in the Open Motion Planning\nLibrary, our method demonstrates a 15x speedup, while classic methods achieve a\n5.79x speedup. Both approaches exhibit machine-precision differences in path\nlengths compared to the original solution. We release our proposed C++\nimplementations for both the accelerated and under-specified Reeds-Shepp\nproblems as open-source code.","main_category":"cs.RO","categories":"cs.RO,cs.CG","published":"2025-04-08T11:22:50Z"}
{"aid":"http://arxiv.org/abs/2504.05930v1","title":"Totally equimodular matrices: decomposition and triangulation","summary":"Totally equimodular matrices generalize totally unimodular matrices and arise\nin the context of box-total dual integral polyhedra. This work further explores\nthe parallels between these two classes and introduces foundational building\nblocks for constructing totally equimodular matrices. Consequently, we present\na decomposition theorem for totally equimodular matrices of full row rank.\n  Building on this decomposition theorem, we prove that simplicial cones whose\ngenerators form the rows of a totally equimodular matrix sa\\-tisfy strong\nintegrality decomposition properties. More precisely, we provide the Hilbert\nbasis for these cones and construct regular unimodular Hilbert triangulations\nin most cases. We conjecture that cases not covered here do not exist.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-08T11:40:59Z"}
{"aid":"http://arxiv.org/abs/2504.05954v1","title":"Unsupervised Location Mapping for Narrative Corpora","summary":"This work presents the task of unsupervised location mapping, which seeks to\nmap the trajectory of an individual narrative on a spatial map of locations in\nwhich a large set of narratives take place. Despite the fundamentality and\ngenerality of the task, very little work addressed the spatial mapping of\nnarrative texts. The task consists of two parts: (1) inducing a ``map'' with\nthe locations mentioned in a set of texts, and (2) extracting a trajectory from\na single narrative and positioning it on the map. Following recent advances in\nincreasing the context length of large language models, we propose a pipeline\nfor this task in a completely unsupervised manner without predefining the set\nof labels. We test our method on two different domains: (1) Holocaust\ntestimonies and (2) Lake District writing, namely multi-century literature on\ntravels in the English Lake District. We perform both intrinsic and extrinsic\nevaluations for the task, with encouraging results, thereby setting a benchmark\nand evaluation practices for the task, as well as highlighting challenges.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-08T12:06:47Z"}
{"aid":"http://arxiv.org/abs/2504.05968v1","title":"Security Vulnerabilities in Ethereum Smart Contracts: A Systematic\n  Analysis","summary":"Smart contracts are a secure and trustworthy application that plays a vital\nrole in decentralized applications in various fields such as insurance,the\ninternet, and gaming. However, in recent years, smart contract security\nbreaches have occurred frequently, and due to their financial properties, they\nhave caused huge economic losses, such as the most famous security incident\n\"The DAO\" which caused a loss of over \\$60 million in Ethereum. This has drawn\na lot of attention from all sides. Writing a secure smart contract is now a\ncritical issue.This paper focuses on Ether smart contracts and explains the\nmain components of Ether, smart contract architecture and mechanism.The\nenvironment used in this paper is the Ethernet environment, using remix online\ncompilation platform and Solidity language, according to the four security\nevents of American Chain, The DAO, Parity and KotET, the principles of integer\noverflow attack, reentrant attack, access control attack and denial of service\nattack are studied and analyzed accordingly, and the scenarios of these\nvulnerabilities are reproduced, and the measures to prevent them are given.\nFinally, preventive measures are given. In addition, the principles of short\naddress attack, early transaction attack and privileged function exposure\nattack are also introduced in detail, and security measures are proposed.As\nvulnerabilities continue to emerge, their classification will also evolve. The\nanalysis and research of the current vulnerabilities are also to lay a solid\nfoundation for avoiding more vulnerabilities.","main_category":"cs.CR","categories":"cs.CR,D.2.4","published":"2025-04-08T12:25:34Z"}
{"aid":"http://arxiv.org/abs/2504.05974v1","title":"The Higgs trilinear coupling in the SMEFT at the HL-LHC and the FCC-ee","summary":"Motivated by the updated HL-LHC projections for Higgs pair production from\nATLAS and CMS and by the release of the FCC-ee Feasibility Study, we critically\nrevisit the sensitivity of the global SMEFT analysis to deformations of the\nHiggs self-coupling modifier $\\kappa_3$. To this end, we quantify the impact of\nSMEFT operators modifying double Higgs production at the LHC and single Higgs\nproduction, including loop corrections, at the FCC-ee, and include\nRenormalisation Group Evolution throughout. We demonstrate that significantly\nimproving on the legacy HL-LHC constraints on $\\kappa_3$ at the FCC-ee is not\npossible without the $\\sqrt{s}=365$ GeV run; that individual and marginalised\ndeterminations are similar at the HL-LHC while differing by up to a factor 3 at\nthe FCC-ee; and that quadratic EFT corrections cannot be neglected. Overall,\nthe combination of HL-LHC and FCC-ee data offers unique potential to pin down\nthe Higgs self-coupling with $\\sim$$15\\%$ precision.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-08T12:30:44Z"}
{"aid":"http://arxiv.org/abs/2504.05991v1","title":"On non-local exchange and scattering operators in domain decomposition\n  methods","summary":"We study non-local exchange and scattering operators arising in domain\ndecomposition algorithms for solving elliptic problems on domains in\n$\\mathbb{R}^2$. Motivated by recent formulations of the Optimized Schwarz\nMethod introduced by Claeys, we rigorously analyze the behavior of a family of\nnon-local exchange operators $\\Pi_\\gamma$, defined in terms of boundary\nintegral operators associated to the fundamental solution for $-\\Delta +\n\\gamma^{-2}$, with $\\gamma > 0$. Our first main result establishes precise\nestimates comparing $\\Pi_\\gamma$ to its local counterpart $\\Pi_0$ as $\\gamma\n\\to 0$, providing a quantitative bridge between the classical and non-local\nformulations of the Optimized Schwarz Method. In addition, we investigate the\ncorresponding scattering operators, proving norm estimates that relate them to\ntheir classical analogues through a detailed analysis of the associated\nDirichlet-to-Neumann operators. Our results clarify the relationship between\nclassical and non-local formulations of domain decomposition methods and yield\nnew insights that are essential for the analysis of these algorithms,\nparticularly in the presence of cross points and for domains with curvilinear\npolygonal boundaries.","main_category":"math.NA","categories":"math.NA,cs.NA,math.AP","published":"2025-04-08T12:54:54Z"}
{"aid":"http://arxiv.org/abs/2504.06004v1","title":"FedFeat+: A Robust Federated Learning Framework Through Federated\n  Aggregation and Differentially Private Feature-Based Classifier Retraining","summary":"In this paper, we propose the FedFeat+ framework, which distinctively\nseparates feature extraction from classification. We develop a two-tiered model\ntraining process: following local training, clients transmit their weights and\nsome features extracted from the feature extractor from the final local epochs\nto the server. The server aggregates these models using the FedAvg method and\nsubsequently retrains the global classifier utilizing the shared features. The\nclassifier retraining process enhances the model's understanding of the\nholistic view of the data distribution, ensuring better generalization across\ndiverse datasets. This improved generalization enables the classifier to\nadaptively influence the feature extractor during subsequent local training\nepochs. We establish a balance between enhancing model accuracy and\nsafeguarding individual privacy through the implementation of differential\nprivacy mechanisms. By incorporating noise into the feature vectors shared with\nthe server, we ensure that sensitive data remains confidential. We present a\ncomprehensive convergence analysis, along with theoretical reasoning regarding\nperformance enhancement and privacy preservation. We validate our approach\nthrough empirical evaluations conducted on benchmark datasets, including\nCIFAR-10, CIFAR-100, MNIST, and FMNIST, achieving high accuracy while adhering\nto stringent privacy guarantees. The experimental results demonstrate that the\nFedFeat+ framework, despite using only a lightweight two-layer CNN classifier,\noutperforms the FedAvg method in both IID and non-IID scenarios, achieving\naccuracy improvements ranging from 3.92 % to 12.34 % across CIFAR-10,\nCIFAR-100, and Fashion-MNIST datasets.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T13:12:38Z"}
{"aid":"http://arxiv.org/abs/2504.06005v1","title":"A deep search for Complex Organic Molecules toward the protoplanetary\n  disk of V883 Ori","summary":"Complex Organic Molecules (COMs) in the form of prebiotic molecules are\npotentially building blocks of life. Using Atacama Large\nMillimeter/submillimeter Array (ALMA) Band 7 observations in spectral scanning\nmode, we carried out a deep search for COMs within the disk of V883 Ori,\ncovering frequency ranges of $\\sim$ 348 - 366 GHz. V883 Ori is an FUor object\ncurrently undergoing an accretion burst, which increases its luminosity and\nconsequently increases the temperature of the surrounding protoplanetary disk,\nfacilitating the detection of COMs in the gas phase. We identified 26\nmolecules, including 14 COMs and 12 other molecules, with first detection in\nthis source of the molecules: CH3OD, H2C17O, and H213CO. We searched for\nmultiple nitrogen-bearing COMs, as CH3CN had been the only nitrogen-bearing COM\nthat has been identified so far in this source. We also detected CH3CN, and\ntentatively detect CH3CH2CN, CH2CHCN, CH3OCN, CH3NCO, and NH2CHO. We compared\nthe abundances relative to CH3OH with those in the handful of objects with\nprevious detections of these species: the Class 0 protostars IRAS 16293-2422 A,\nIRAS 16293-2422 B and B1-c, the high-mass star-forming region Sagittarius B2\n(North), the Solar System comet 67P/Churyumov-Gerasimenko, and the\nprotoplanetary disk of Oph-IRS 48. We report $\\sim$ 1 to 3 orders of magnitude\nhigher abundances compared to Class 0 protostars and $\\sim$ 1 to 3 orders of\nmagnitude lower abundances compared to the protoplanetary disk, Sagittarius B2\n(North), and 67P/C-G. These results indicate that the protoplanetary disk phase\ncould contribute to build up of COMs.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP,astro-ph.GA","published":"2025-04-08T13:15:46Z"}
{"aid":"http://arxiv.org/abs/2504.06010v1","title":"Latent Multimodal Reconstruction for Misinformation Detection","summary":"Multimodal misinformation, such as miscaptioned images, where captions\nmisrepresent an image's origin, context, or meaning, poses a growing challenge\nin the digital age. To support fact-checkers, researchers have been focusing on\ncreating datasets and developing methods for multimodal misinformation\ndetection (MMD). Due to the scarcity of large-scale annotated MMD datasets,\nrecent studies leverage synthetic training data via out-of-context\nimage-caption pairs or named entity manipulations; altering names, dates, and\nlocations. However, these approaches often produce simplistic misinformation\nthat fails to reflect real-world complexity, limiting the robustness of\ndetection models trained on them. Meanwhile, despite recent advancements, Large\nVision-Language Models (LVLMs) remain underutilized for generating diverse,\nrealistic synthetic training data for MMD. To address this gap, we introduce\n\"MisCaption This!\", a training dataset comprising LVLM-generated miscaptioned\nimages. Additionally, we introduce \"Latent Multimodal Reconstruction\" (LAMAR),\na network trained to reconstruct the embeddings of truthful captions, providing\na strong auxiliary signal to the detection process. To optimize LAMAR, we\nexplore different training strategies (end-to-end training and large-scale\npre-training) and integration approaches (direct, mask, gate, and attention).\nExtensive experiments show that models trained on \"MisCaption This!\" generalize\nbetter on real-world misinformation, while LAMAR sets new state-of-the-art on\nboth NewsCLIPpings and VERITE benchmarks; highlighting the potential of\nLVLM-generated data and reconstruction-based approaches for advancing MMD. We\nrelease our code at:\nhttps://github.com/stevejpapad/miscaptioned-image-reconstruction","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-08T13:16:48Z"}
{"aid":"http://arxiv.org/abs/2504.06022v1","title":"CamContextI2V: Context-aware Controllable Video Generation","summary":"Recently, image-to-video (I2V) diffusion models have demonstrated impressive\nscene understanding and generative quality, incorporating image conditions to\nguide generation. However, these models primarily animate static images without\nextending beyond their provided context. Introducing additional constraints,\nsuch as camera trajectories, can enhance diversity but often degrades visual\nquality, limiting their applicability for tasks requiring faithful scene\nrepresentation. We propose CamContextI2V, an I2V model that integrates multiple\nimage conditions with 3D constraints alongside camera control to enrich both\nglobal semantics and fine-grained visual details. This enables more coherent\nand context-aware video generation. Moreover, we motivate the necessity of\ntemporal awareness for an effective context representation. Our comprehensive\nstudy on the RealEstate10K dataset demonstrates improvements in visual quality\nand camera controllability. We make our code and models publicly available at:\nhttps://github.com/LDenninger/CamContextI2V.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T13:26:59Z"}
{"aid":"http://arxiv.org/abs/2504.06039v1","title":"Enhanced Anomaly Detection for Capsule Endoscopy Using Ensemble Learning\n  Strategies","summary":"Capsule endoscopy is a method to capture images of the gastrointestinal tract\nand screen for diseases which might remain hidden if investigated with standard\nendoscopes. Due to the limited size of a video capsule, embedding AI models\ndirectly into the capsule demands careful consideration of the model size and\nthus complicates anomaly detection in this field. Furthermore, the scarcity of\navailable data in this domain poses an ongoing challenge to achieving effective\nanomaly detection. Thus, this work introduces an ensemble strategy to address\nthis challenge in anomaly detection tasks in video capsule endoscopies,\nrequiring only a small number of individual neural networks during both the\ntraining and inference phases. Ensemble learning combines the predictions of\nmultiple independently trained neural networks. This has shown to be highly\neffective in enhancing both the accuracy and robustness of machine learning\nmodels. However, this comes at the cost of higher memory usage and increased\ncomputational effort, which quickly becomes prohibitive in many real-world\napplications. Instead of applying the same training algorithm to each\nindividual network, we propose using various loss functions, drawn from the\nanomaly detection field, to train each network. The methods are validated on\nthe two largest publicly available datasets for video capsule endoscopy images,\nthe Galar and the Kvasir-Capsule dataset. We achieve an AUC score of 76.86% on\nthe Kvasir-Capsule and an AUC score of 76.98% on the Galar dataset. Our\napproach outperforms current baselines with significantly fewer parameters\nacross all models, which is a crucial step towards incorporating artificial\nintelligence into capsule endoscopies.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T13:39:39Z"}
{"aid":"http://arxiv.org/abs/2504.06042v1","title":"An Adaptive Algorithm for Bilevel Optimization on Riemannian Manifolds","summary":"Existing methods for solving Riemannian bilevel optimization (RBO) problems\nrequire prior knowledge of the problem's first- and second-order information\nand curvature parameter of the Riemannian manifold to determine step sizes,\nwhich poses practical limitations when these parameters are unknown or\ncomputationally infeasible to obtain. In this paper, we introduce the Adaptive\nRiemannian Hypergradient Descent (AdaRHD) algorithm for solving RBO problems.\nTo the best of our knowledge, AdaRHD is the first method to incorporate a fully\nadaptive step size strategy that eliminates the need for problem-specific\nparameters. We prove that AdaRHD achieves an $\\mathcal{O}(1/\\epsilon)$\niteration complexity for finding an $\\epsilon$-stationary point, thus matching\nthe complexity of existing non-adaptive methods. Furthermore, we demonstrate\nthat substituting exponential mappings with retraction mappings maintains the\nsame complexity bound. Experiments demonstrate that AdaRHD achieves comparable\nperformance to existing non-adaptive approaches while exhibiting greater\nrobustness.","main_category":"math.OC","categories":"math.OC","published":"2025-04-08T13:42:18Z"}
{"aid":"http://arxiv.org/abs/2504.06049v1","title":"Directed LS category and directed parametrized topological complexity","summary":"We introduce and study a parametrized analogue of the directed topological\ncomplexity, originally developed by Goubault, Farber, and Sagnier. We establish\nthe fibrewise basic dihomotopy invariance of directed parametrized topological\ncomplexity and explore its relationship with the parametrized topological\ncomplexity. In addition, we introduce the concept of the directed\nLusternik$-$Schnirelmann (LS) category, prove its basic dihomotopy invariance,\nand investigate its connections with both directed topological complexity and\ndirected parametrized topological complexity. As an application, we show that\nthe directed LS category of the directed spheres is equal to two.","main_category":"math.AT","categories":"math.AT","published":"2025-04-08T13:47:09Z"}
{"aid":"http://arxiv.org/abs/2504.06054v1","title":"Thermodynamic formalism for Quasi-Morphisms: Bounded Cohomology and\n  Statistics","summary":"For a compact negatively curved space, we develop a notion of thermodynamic\nformalism and apply it to study the space of quasi-morphisms of its fundamental\ngroup modulo boundedness. We prove that this space is Banach isomorphic to the\nspace of Bowen functions corresponding to the associated Gromov geodesic flow,\nmodulo a weak notion of Livsic cohomology.\n  The results include that each such unbounded quasi-morphism is associated\nwith a unique invariant measure for the flow, and this measure uniquely\ncharacterizes the cohomology class. As a consequence, we establish the Central\nLimit Theorem for any unbounded quasi-morphism with respect to Markov measures,\nthe invariance principle, and the Bernoulli property of the associated\nequilibrium state.","main_category":"math.DS","categories":"math.DS,math.GT","published":"2025-04-08T13:59:30Z"}
{"aid":"http://arxiv.org/abs/2504.06148v1","title":"V-MAGE: A Game Evaluation Framework for Assessing Visual-Centric\n  Capabilities in Multimodal Large Language Models","summary":"Recent advancements in Multimodal Large Language Models (MLLMs) have led to\nsignificant improvements across various multimodal benchmarks. However, as\nevaluations shift from static datasets to open-world, dynamic environments,\ncurrent game-based benchmarks remain inadequate because they lack\nvisual-centric tasks and fail to assess the diverse reasoning skills required\nfor real-world decision-making. To address this, we introduce Visual-centric\nMultiple Abilities Game Evaluation (V-MAGE), a game-based evaluation framework\ndesigned to assess visual reasoning capabilities of MLLMs. V-MAGE features five\ndiverse games with 30+ handcrafted levels, testing models on core visual skills\nsuch as positioning, trajectory tracking, timing, and visual memory, alongside\nhigher-level reasoning like long-term planning and deliberation. We use V-MAGE\nto evaluate leading MLLMs, revealing significant challenges in their visual\nperception and reasoning. In all game environments, the top-performing MLLMs,\nas determined by Elo rating comparisons, exhibit a substantial performance gap\ncompared to humans. Our findings highlight critical limitations, including\nvarious types of perceptual errors made by the models, and suggest potential\navenues for improvement from an agent-centric perspective, such as refining\nagent strategies and addressing perceptual inaccuracies. Code is available at\nhttps://github.com/CSU-JPG/V-MAGE.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T15:43:01Z"}
{"aid":"http://arxiv.org/abs/2504.06174v1","title":"On Soft Clustering For Correlation Estimators: Model Uncertainty,\n  Differentiability, and Surrogates","summary":"Properly estimating correlations between objects at different spatial scales\nnecessitates $\\mathcal{O}(n^2)$ distance calculations. For this reason, most\nwidely adopted packages for estimating correlations use clustering algorithms\nto approximate local trends. However, methods for quantifying the error\nintroduced by this clustering have been understudied. In response, we present\nan algorithm for estimating correlations that is probabilistic in the way that\nit clusters objects, enabling us to quantify the uncertainty caused by\nclustering simply through model inference. These soft clustering assignments\nenable correlation estimators that are theoretically differentiable with\nrespect to their input catalogs. Thus, we also build a theoretical framework\nfor differentiable correlation functions and describe their utility in\ncomparison to existing surrogate models. Notably, we find that repeated\nnormalization and distance function calls slow gradient calculations and that\nsparse Jacobians destabilize precision, pointing towards either approximate or\nsurrogate methods as a necessary solution to exact gradients from correlation\nfunctions. To that end, we close with a discussion of surrogate models as\nproxies for correlation functions. We provide an example that demonstrates the\nefficacy of surrogate models to enable gradient-based optimization of\nastrophysical model parameters, successfully minimizing a correlation function\noutput. Our numerical experiments cover science cases across cosmology, from\npoint spread function (PSF) modeling efforts to gravitational simulations to\ngalaxy intrinsic alignment (IA).","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-08T16:18:39Z"}
{"aid":"http://arxiv.org/abs/2504.06229v1","title":"Continuous-variable spatio-spectral quantum networks in nonlinear\n  photonic lattices","summary":"Multiplexing information in different degrees of freedom and use of\nintegrated and fiber-optic components are natural solutions to the scalability\nbottleneck in optical quantum communications and computing. However, for\nbulk-optics systems, where size, cost, stability, and reliability are factors,\nthis remains either impractical or highly challenging to implement. In this\npaper we present a framework to engineer continuous-variable entanglement\nproduced through nondegenerate spontaneous parametric down-conversion in\n\\chi^(2) nonlinear photonic lattices in spatial and spectral degrees of freedom\nthat can solve the scalability challenge. We show how spatio-spectral pump\nshaping produce cluster states that are naturally distributable in quantum\ncommunication networks and a resource for measurement-based quantum computing.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-08T17:24:00Z"}
{"aid":"http://arxiv.org/abs/2504.06243v1","title":"Renormalization Group in far-from-equilibrium states","summary":"We study renormalization group flows in far-from-equilibrium states. The\nstudy is made tractable by focusing on states that are spatially homogeneous,\ntime-independent, and scale-invariant. Such states, in which mode $k$ has\noccupation numbers $n_k \\sim k^{-\\gamma}$, are well known in nonlinear physics.\nRG flow in such states is qualitatively different from that in the vacuum -- a\npositive $\\gamma$ decreases the dimension of an operator, turning marginal\ninteractions into relevant interactions. We compute one-loop beta functions.\nDepending on the sign of the beta function, backreaction may either cause a\nminor shift of the state in the IR, or completely change the nature of the\nstate. Focusing on nearly marginal interactions, we construct an analog of the\nepsilon expansion and IR fixed points, with epsilon now set by the scaling of\nthe interaction rather than the spacetime dimension. In the language of RG\nflow, critical-balance scaling -- which has applications in fields as varied as\nastrophysics and ocean waves -- corresponds to the state dynamically adjusting\nitself along the RG flow until the interaction becomes marginal.","main_category":"hep-th","categories":"hep-th,hep-ph","published":"2025-04-08T17:43:01Z"}
{"aid":"http://arxiv.org/abs/2504.06267v1","title":"Prethermalization of light and matter in cavity-coupled Rydberg arrays","summary":"We explore the dynamics of two-dimensional Rydberg atom arrays coupled to a\nsingle-mode optical cavity, employing nonequilibrium diagrammatic techniques to\ncapture nonlinearities and fluctuations beyond mean-field theory. We discover a\nnovel prethermalization regime driven by the interplay between short-range\nRydberg interactions and long-range photon-mediated interactions. In this\nregime, matter and light equilibrate at distinct - and in some cases opposite -\neffective temperatures, resembling the original concept of prethermalization\nfrom particle physics. Our results establish strongly correlated AMO platforms\nas tools to investigate fundamental questions in statistical mechanics,\nincluding quantum thermalization in higher-dimensional systems.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,quant-ph","published":"2025-04-08T17:59:59Z"}
{"aid":"http://arxiv.org/abs/2504.06560v1","title":"NeedleInATable: Exploring Long-Context Capability of Large Language\n  Models towards Long-Structured Tables","summary":"Processing structured tabular data, particularly lengthy tables, constitutes\na fundamental yet challenging task for large language models (LLMs). However,\nexisting long-context benchmarks primarily focus on unstructured text,\nneglecting the challenges of long and complex structured tables. To address\nthis gap, we introduce NeedleInATable (NIAT), a novel task that treats each\ntable cell as a \"needle\" and requires the model to extract the target cell\nunder different queries. Evaluation results of mainstream LLMs on this\nbenchmark show they lack robust long-table comprehension, often relying on\nsuperficial correlations or shortcuts for complex table understanding tasks,\nrevealing significant limitations in processing intricate tabular data. To this\nend, we propose a data synthesis method to enhance models' long-table\ncomprehension capabilities. Experimental results show that our synthesized\ntraining data significantly enhances LLMs' performance on the NIAT task,\noutperforming both long-context LLMs and long-table agent methods. This work\nadvances the evaluation of LLMs' genuine long-structured table comprehension\ncapabilities and paves the way for progress in long-context and table\nunderstanding applications.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T03:46:56Z"}
{"aid":"http://arxiv.org/abs/2504.06573v1","title":"Mutation Cycles from Reddening Sequences","summary":"Given two quivers, each with a reddening sequence, we show how to construct a\nplethora of mutation cycles. We give several examples, including a\ngeneralization of the construction of long mutation cycles in earlier work by\nthe second author. We also give new results on the reddening sequences of\ncertain mutation-acyclic quivers and forks, classifying them in some cases.","main_category":"math.CO","categories":"math.CO","published":"2025-04-09T04:21:51Z"}
{"aid":"http://arxiv.org/abs/2504.06594v1","title":"Machine Learning for Extrapolating No-Core Shell Model Results to\n  Infinite Basis","summary":"We utilize the machine learning to extrapolate to the infinite model space\nthe no-core shell model (NCSM) results for the energies and rms radii of the\n6He ground state and 6Li lowest states. The extrapolated energies and rms radii\nconverge as the NCSM results from larger model spaces are included in the\ntraining dataset for ensemble of artificial neural networks thus enabling an\naccurate predictions for these observables.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-09T05:42:41Z"}
{"aid":"http://arxiv.org/abs/2504.06598v1","title":"Stochastic Ray Tracing of 3D Transparent Gaussians","summary":"3D Gaussian splatting has recently been widely adopted as a 3D representation\nfor novel-view synthesis, relighting, and text-to-3D generation tasks, offering\nrealistic and detailed results through a collection of explicit 3D Gaussians\ncarrying opacities and view-dependent colors. However, efficient rendering of\nmany transparent primitives remains a significant challenge. Existing\napproaches either rasterize the 3D Gaussians with approximate sorting per view\nor rely on high-end RTX GPUs to exhaustively process all ray-Gaussian\nintersections (bounding Gaussians by meshes). This paper proposes a stochastic\nray tracing method to render 3D clouds of transparent primitives. Instead of\nprocessing all ray-Gaussian intersections in sequential order, each ray\ntraverses the acceleration structure only once, randomly accepting and shading\na single intersection (or N intersections, using a simple extension). This\napproach minimizes shading time and avoids sorting the Gaussians along the ray\nwhile minimizing the register usage and maximizing parallelism even on low-end\nGPUs. The cost of rays through the Gaussian asset is comparable to that of\nstandard mesh-intersection rays. While our method introduces noise, the shading\nis unbiased, and the variance is slight, as stochastic acceptance is\nimportance-sampled based on accumulated opacity. The alignment with the Monte\nCarlo philosophy simplifies implementation and easily integrates our method\ninto a conventional path-tracing framework.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-09T05:49:05Z"}
{"aid":"http://arxiv.org/abs/2504.06604v1","title":"Image registration of 2D optical thin sections in a 3D porous medium:\n  Application to a Berea sandstone digital rock image","summary":"This study proposes a systematic image registration approach to align 2D\noptical thin-section images within a 3D digital rock volume. Using template\nimage matching with differential evolution optimization, we identify the most\nsimilar 2D plane in 3D. The method is validated on a synthetic porous medium,\nachieving exact registration, and applied to Berea sandstone, where it achieves\na structural similarity index (SSIM) of 0.990. With the registered images, we\nexplore upscaling properties based on paired multimodal images, focusing on\npore characteristics and effective elastic moduli. The thin-section image\nreveals 50 % more porosity and submicron pores than the registered CT plane. In\naddition, bulk and shear moduli from thin sections are 25 % and 30 % lower,\nrespectively, than those derived from CT images. Beyond numerical comparisons,\nthin sections provide additional geological insights, including cementation,\nmineral phases, and weathering effects, which are not clear in CT images. This\nstudy demonstrates the potential of multimodal image registration to improve\ncomputed rock properties in digital rock physics by integrating complementary\nimaging modalities.","main_category":"physics.geo-ph","categories":"physics.geo-ph,cs.CV","published":"2025-04-09T06:01:43Z"}
{"aid":"http://arxiv.org/abs/2504.06617v1","title":"Spectrum radii of trees","summary":"For any positive integer $r$ and positive number $\\alpha$, let ${\\mathscr\nW}_r(\\alpha)$ denote the set of positive numbers defined recursively:\n$\\alpha\\in {\\mathscr W}_r(\\alpha)$, and for any multi-set $\\{q_i\\in {\\mathscr\nW}_r(\\alpha): 1\\le i\\le s\\}$, where $1\\le s<r$,\n$\\beta:=\\alpha-\\sum\\limits_{i=1}^sq_i^{-1}$ belongs to ${\\mathscr W}_r(\\alpha)$\nas long as $\\beta>0$. We first show that there exists a tree $T$ such that its\nmaximum degree $\\Delta(T)$ is at most $r$ and its spectrum radius $\\lambda(T)$\nis equal to $\\alpha$ if and only if $\\alpha^{-1}\\in {\\mathscr W}_r(\\alpha)$. It\nfollows that the set of spectrum radii of non-trivial trees is exactly the set\nof positive numbers $\\alpha$ such that $\\alpha^{-1}\\in {\\mathscr\nW}_{\\lfloor\\alpha^2\\rfloor}(\\alpha)$. Applying this conclusion, we then prove\nthat for any positive integers $r$ and $k$, there exists a tree $T$ with\n$\\Delta(T)=r$ and $\\lambda(T)=\\sqrt k$ if and only if $\\frac 14 k+1<r\\le k$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-09T06:30:32Z"}
{"aid":"http://arxiv.org/abs/2504.06669v1","title":"NLP Security and Ethics, in the Wild","summary":"As NLP models are used by a growing number of end-users, an area of\nincreasing importance is NLP Security (NLPSec): assessing the vulnerability of\nmodels to malicious attacks and developing comprehensive countermeasures\nagainst them. While work at the intersection of NLP and cybersecurity has the\npotential to create safer NLP for all, accidental oversights can result in\ntangible harm (e.g., breaches of privacy or proliferation of malicious models).\nIn this emerging field, however, the research ethics of NLP have not yet faced\nmany of the long-standing conundrums pertinent to cybersecurity, until now. We\nthus examine contemporary works across NLPSec, and explore their engagement\nwith cybersecurity's ethical norms. We identify trends across the literature,\nultimately finding alarming gaps on topics like harm minimization and\nresponsible disclosure. To alleviate these concerns, we provide concrete\nrecommendations to help NLP researchers navigate this space more ethically,\nbridging the gap between traditional cybersecurity and NLP ethics, which we\nframe as ``white hat NLP''. The goal of this work is to help cultivate an\nintentional culture of ethical research for those working in NLP Security.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-09T08:12:34Z"}
{"aid":"http://arxiv.org/abs/2504.06671v1","title":"Defects in Silicon Carbide as Quantum Qubits: Recent Advances in Defect\n  Engineering","summary":"This review provides an overview of defects in silicon carbide (SiC) with\npotential applications as quantum qubits. It begins with a brief introduction\nto quantum qubits and existing qubit platforms, outlining the essential\ncriteria a defect must meet to function as a viable qubit. The focus then\nshifts to the most promising defects in SiC, notably the silicon vacancy (VSi)\nand divacancy (VC-VSi). A key challenge in utilizing these defects for quantum\napplications is their precise and controllable creation. Various fabrication\ntechniques, including irradiation, ion implantation, femtosecond laser\nprocessing, and focused ion beam methods, have been explored to create these\ndefects. Designed as a beginner-friendly resource, this review aims to support\nearly-career experimental researchers entering the field of SiC-related quantum\nqubits. Providing an introduction to defect-based qubits in SiC offers valuable\ninsights into fabrication strategies, recent progress, and the challenges that\nlie ahead.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,quant-ph","published":"2025-04-09T08:13:58Z"}
{"aid":"http://arxiv.org/abs/2504.06695v1","title":"A Convex-Analytical Proof of the Fundamental Theorem of Algebra","summary":"A weak version of Birkhoff's generalization of the Perron-Frobenius theorem\nstates that every endomorphism of a finite-dimensional real vector that leaves\ninvariant a non-degenerate closed convex cone has an eigenvector in that cone.\n  Here, we show that this theorem, whose proof relies only upon basic convex\nanalysis, yields very short proofs of both the spectral theorem for selfadjoint\noperators of Euclidean spaces and the Fundamental Theorem of Algebra.","main_category":"math.FA","categories":"math.FA,math.SP","published":"2025-04-09T08:54:14Z"}
{"aid":"http://arxiv.org/abs/2504.06702v1","title":"Consensus-based qubit configuration optimization for variational\n  algorithms on neutral atom quantum systems","summary":"In this work, we report an algorithm that is able to tailor qubit\ninteractions for individual variational quantum algorithm problems. Here, the\nalgorithm leverages the unique ability of a neutral atom tweezer platform to\nrealize arbitrary qubit position configurations. These configurations determine\nthe degree of entanglement available to a variational quantum algorithm via the\ninteratomic interactions. Good configurations will accelerate pulse\noptimization convergence and help mitigate barren plateaus. As gradient-based\napproaches are ineffective for position optimization due to the divergent\n$R^{-6}$ nature of neutral atom interactions, we opt to use a consensus-based\nalgorithm to optimize the qubit positions. By sampling the configuration space\ninstead of using gradient information, the consensus-based algorithm is able to\nsuccessfully optimize the positions, yielding adapted variational quantum\nalgorithm ansatzes that lead to both faster convergence and lower errors. In\nthis work, we show that these optimized configurations generally result in\nlarge improvements in the system's ability to solve ground state minimization\nproblems for both random Hamiltonians and small molecules.","main_category":"quant-ph","categories":"quant-ph,physics.atom-ph","published":"2025-04-09T09:07:49Z"}
{"aid":"http://arxiv.org/abs/2504.06704v1","title":"CAT: Circular-Convolutional Attention for Sub-Quadratic Transformers","summary":"Transformers have driven remarkable breakthroughs in natural language\nprocessing and computer vision, yet their standard attention mechanism still\nimposes O(N^2) complexity, hindering scalability to longer sequences. We\nintroduce Circular-convolutional ATtention (CAT), a Fourier-based approach that\nefficiently applies circular convolutions to reduce complexity without\nsacrificing representational power. CAT achieves O(NlogN) computations,\nrequires fewer learnable parameters by streamlining fully-connected layers, and\nintroduces no heavier operations, resulting in consistent accuracy improvements\nand about a 10% speedup in naive PyTorch implementations on large-scale\nbenchmarks such as ImageNet-1k and WikiText-103. Grounded in an\nengineering-isomorphism framework, CAT's design not only offers practical\nefficiency and ease of implementation but also provides insights to guide the\ndevelopment of next-generation, high-performance Transformer architectures.\nFinally, our ablation studies highlight the key conditions underlying CAT's\nsuccess, shedding light on broader principles for scalable attention\nmechanisms.","main_category":"cs.LG","categories":"cs.LG,cs.CL,cs.CV","published":"2025-04-09T09:08:26Z"}
{"aid":"http://arxiv.org/abs/2504.06707v1","title":"Phase transition of the kinetic Justh-Krishnaprasad type model for\n  nematic alignment","summary":"We present a stochastic Justh-Krishnaprasad flocking model and study the\nphase transition of the Vlasov-McKean-Fokker-Planck (VMFP) equation, which can\nbe obtained in the mean-field limit. To describe the alignment, we use order\nparameters in terms of the distribution function of the kinetic model. For the\nconstant noise case, we study the well-posedness of the VMFP equation on the\ntorus. Based on regularity, we show that the phenomenon of phase transition is\nonly related to the ratio between the strengths of noise and coupling. In\nparticular, for the low-noise case, we derive an exponential convergence to the\nvon-Mises type equilibrium, which shows a strong evidence for the nematic\nalignment. The multiplicative noise is also studied to obtain a non-symmetric\nequilibrium with two different peaks on the torus.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T09:09:24Z"}
{"aid":"http://arxiv.org/abs/2504.06708v1","title":"Transport of electrolytes across nanochannels: the role of slip","summary":"We characterize the electrokinetic flow due to the transport of electrolytes\nembedded in nanochannels of varying cross-section with inhomogeneous slip on\ntheir walls, modeled as an effective slip length on the channel wall. We show\nthat, within linear response and Debye-Huckel regime, the transport\ncoefficients, and so the fluxes, can be significantly improved by the presence\nof a hydrophobic surface coating located at the narrowest section of the\nnanochannel. Our model indicates that the enhancement is larger when\nconsidering electric conductive walls in comparison to dielectric microchannel\nwalls, and it is produced by a synergy between the entropic effects due to the\ngeometry and the presence of the slip boundary layer. Our results show that a\ntailored hydrophobic coating design can be an effective strategy to improve\ntransport properties in the broad areas of lab-on-a-chip, biophysics, and blue\nenergy harvesting and energy conversion technologies.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cond-mat.soft","published":"2025-04-09T09:09:52Z"}
{"aid":"http://arxiv.org/abs/2504.06730v1","title":"PETNet -- Coincident Particle Event Detection using Spiking Neural\n  Networks","summary":"Spiking neural networks (SNN) hold the promise of being a more biologically\nplausible, low-energy alternative to conventional artificial neural networks.\nTheir time-variant nature makes them particularly suitable for processing\ntime-resolved, sparse binary data. In this paper, we investigate the potential\nof leveraging SNNs for the detection of photon coincidences in positron\nemission tomography (PET) data. PET is a medical imaging technique based on\ninjecting a patient with a radioactive tracer and detecting the emitted\nphotons. One central post-processing task for inferring an image of the tracer\ndistribution is the filtering of invalid hits occurring due to e.g. absorption\nor scattering processes. Our approach, coined PETNet, interprets the detector\nhits as a binary-valued spike train and learns to identify photon coincidence\npairs in a supervised manner. We introduce a dedicated multi-objective loss\nfunction and demonstrate the effects of explicitly modeling the detector\ngeometry on simulation data for two use-cases. Our results show that PETNet can\noutperform the state-of-the-art classical algorithm with a maximal coincidence\ndetection $F_1$ of 95.2%. At the same time, PETNet is able to predict photon\ncoincidences up to 36 times faster than the classical approach, highlighting\nthe great potential of SNNs in particle physics applications.","main_category":"cs.LG","categories":"cs.LG,hep-ex","published":"2025-04-09T09:38:45Z"}
{"aid":"http://arxiv.org/abs/2504.06733v1","title":"Timing the Escape of a Caged Electron","summary":"Charge transfer is fundamentally dependent on the overlap of the orbitals\ncomprising the transport pathway. This has key implications for molecular,\nnanoscale, and quantum technologies, for which delocalization (and decoherence)\nrates are essential figures of merit. Here, we apply the core hole clock\ntechnique - an energy-domain variant of ultrafast spectroscopy - to probe the\ndelocalization of a photoexcited electron inside a closed molecular cage,\nnamely the Ar 2p54s1 state of Ar@C60. Despite marginal frontier orbital mixing\nin the ground configuration, almost 80% of the excited state density is found\noutside the buckyball due to the formation of a markedly diffuse hybrid\norbital. Far from isolating the intracage excitation, the surrounding fullerene\nis instead a remarkably efficient conduit for electron transfer: we measure\ncharacteristic delocalization times of 6.6 $\\pm$ 0.3 fs and $\\lesssim$ 500\nattoseconds, respectively, for a 3D Ar@C60 film and a 2D monolayer on Ag(111).","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-09T09:45:23Z"}
{"aid":"http://arxiv.org/abs/2504.06746v1","title":"Adaptive Human-Robot Collaborative Missions using Hybrid Task Planning","summary":"Producing robust task plans in human-robot collaborative missions is a\ncritical activity in order to increase the likelihood of these missions\ncompleting successfully. Despite the broad research body in the area, which\nconsiders different classes of constraints and uncertainties, its applicability\nis confined to relatively simple problems that can be comfortably addressed by\nthe underpinning mathematically-based or heuristic-driven solver engines. In\nthis paper, we introduce a hybrid approach that effectively solves the task\nplanning problem by decomposing it into two intertwined parts, starting with\nthe identification of a feasible plan and followed by its uncertainty\naugmentation and verification yielding a set of Pareto optimal plans. To\nenhance its robustness, adaptation tactics are devised for the evolving system\nrequirements and agents' capabilities. We demonstrate our approach through an\nindustrial case study involving workers and robots undertaking activities\nwithin a vineyard, showcasing the benefits of our hybrid approach both in the\ngeneration of feasible solutions and scalability compared to native planners.","main_category":"cs.MA","categories":"cs.MA,cs.RO","published":"2025-04-09T10:07:15Z"}
{"aid":"http://arxiv.org/abs/2504.06772v1","title":"Towards Efficient Roadside LiDAR Deployment: A Fast Surrogate Metric\n  Based on Entropy-Guided Visibility","summary":"The deployment of roadside LiDAR sensors plays a crucial role in the\ndevelopment of Cooperative Intelligent Transport Systems (C-ITS). However, the\nhigh cost of LiDAR sensors necessitates efficient placement strategies to\nmaximize detection performance. Traditional roadside LiDAR deployment methods\nrely on expert insight, making them time-consuming. Automating this process,\nhowever, demands extensive computation, as it requires not only visibility\nevaluation but also assessing detection performance across different LiDAR\nplacements. To address this challenge, we propose a fast surrogate metric, the\nEntropy-Guided Visibility Score (EGVS), based on information gain to evaluate\nobject detection performance in roadside LiDAR configurations. EGVS leverages\nTraffic Probabilistic Occupancy Grids (TPOG) to prioritize critical areas and\nemploys entropy-based calculations to quantify the information captured by\nLiDAR beams. This eliminates the need for direct detection performance\nevaluation, which typically requires extensive labeling and computational\nresources. By integrating EGVS into the optimization process, we significantly\naccelerate the search for optimal LiDAR configurations. Experimental results\nusing the AWSIM simulator demonstrate that EGVS strongly correlates with\nAverage Precision (AP) scores and effectively predicts object detection\nperformance. This approach offers a computationally efficient solution for\nroadside LiDAR deployment, facilitating scalable smart infrastructure\ndevelopment.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-09T10:53:03Z"}
{"aid":"http://arxiv.org/abs/2504.06797v1","title":"Quantum Field Theory on Multifractal Spacetime: Varying Dimension and\n  Ultraviolet Completeness","summary":"Inspired by various quantum gravity approaches, we explore quantum field\ntheory where spacetime exhibits scaling properties and dimensional reduction\nwith changing energy scales, effectively behaving as a multifractal manifold.\nWorking within canonical quantization, we demonstrate how to properly quantize\nfields in such multifractal spacetime. Our analysis reveals that a\nnon-differentiable nature of spacetime is not merely compatible with quantum\nfield theory but significantly enhances its mathematical foundation. Most\nnotably, this approach guarantees the finiteness of the theory at all orders in\nperturbation theory and enables rigorous construction of the S-matrix in the\ninteraction picture. The multifractal structure tames dominant, large-order\ndivergence sources in the perturbative series and resolves the Landau pole\nproblem through asymptotic safety, substantially improving the theory's\nbehavior in the deep ultraviolet regime. Our formulation preserves all\nestablished predictions of standard quantum field theory at low energies while\noffering novel physical behaviors at high energy scales.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-04-09T11:41:15Z"}
{"aid":"http://arxiv.org/abs/2504.06812v1","title":"Semi-classical geometric tensor in multiparameter quantum information","summary":"The quantum geometric tensor (QGT) captures the variations of quantum states\nwith parameters, serving as a central concept in modern quantum physics. Its\nreal part, the quantum Fisher information matrix (QFIM), has a\nmeasurement-dependent counterpart that links statistics to distinguishability.\nHowever, an analogous extension for the QGT is hindered by the fundamental\ninaccessibility of its imaginary part through measurement probabilities. Here\nwe introduce a counterpart to the QGT that includes measurement operators,\ntermed the \\textit{semi-classical} geometric tensor (SCGT). We show that the\nSCGT provides a lower bound to the QGT that is tight for pure states. Moreover,\nwe use the SCGT to derive sharp multiparameter information bounds and discuss\nextensions of the Berry phase.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-09T12:06:57Z"}
{"aid":"http://arxiv.org/abs/2504.06826v1","title":"Long-period double-lined eclipsing binaries: the system V454 Aur with\n  the secondary eclipse caused by the occultation of the hotter component","summary":"We present the results of our study of the long-period eclipsing binary star\n\\Aur. The results are based on spectroscopic data obtained with the UFES\n\\'echelle spectrograph and photometric observations from TESS. The derived\nradial velocity curve is based on 17 spectra obtained between 2021 and 2023,\ncovering all orbital phases of this binary system. The orbital period\ndetermined from TESS data, $P = 27.019803 \\pm 0.000003$ days, agrees within\nuncertainties with the period established in previous studies. The model\nconstructed for the TESS photometric light curve achieves a precision of\n0.01\\%. The effective temperatures of both components, as well as the system\nmetallicity, were directly derived from the spectra and are $T_\\mathrm{eff, A}\n= 6250 \\pm 50$\\,K, $T_\\mathrm{eff, B} = 5855 \\pm 50$\\,K, and $\\mathrm{[Fe/H]} =\n-0.10 \\pm 0.08$, respectively. Our analysis of the photometric and\nspectroscopic data allowed us to directly compute the luminosities of the\ncomponents, $L_A = 1.82\\,L_\\odot$ and $L_B = 1.07\\,L_\\odot$, their radii, $R_A\n= 1.15\\,R_\\odot$ and $R_B = 1.00\\,R_\\odot$, and their masses, $M_A =\n1.137\\,M_\\odot$ and $M_B = 1.023\\,M_\\odot$, with uncertainties below 1\\%.\nComparison with evolutionary tracks indicates that the system's age is $1.18\n\\pm 0.10$\\,Gyr, and both components are still on the main sequence. The \\Aur\\\nsystem is particularly interesting due to the partial eclipse of the primary\ncomponent, which results in the ``inversion'' of the primary and secondary\nminima in the photometric light curve.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-09T12:34:35Z"}
{"aid":"http://arxiv.org/abs/2504.06838v1","title":"ZIP: An Efficient Zeroth-order Prompt Tuning for Black-box\n  Vision-Language Models","summary":"Recent studies have introduced various approaches for prompt-tuning black-box\nvision-language models, referred to as black-box prompt-tuning (BBPT). While\nBBPT has demonstrated considerable potential, it is often found that many\nexisting methods require an excessive number of queries (i.e., function\nevaluations), which poses a significant challenge in real-world scenarios where\nthe number of allowed queries is limited. To tackle this issue, we propose\nZeroth-order Intrinsic-dimensional Prompt-tuning (ZIP), a novel approach that\nenables efficient and robust prompt optimization in a purely black-box setting.\nThe key idea of ZIP is to reduce the problem dimensionality and the variance of\nzeroth-order gradient estimates, such that the training is done fast with far\nless queries. We achieve this by re-parameterizing prompts in low-rank\nrepresentations and designing intrinsic-dimensional clipping of estimated\ngradients. We evaluate ZIP on 13+ vision-language tasks in standard benchmarks\nand show that it achieves an average improvement of approximately 6% in\nfew-shot accuracy and 48% in query efficiency compared to the best-performing\nalternative BBPT methods, establishing a new state of the art. Our ablation\nanalysis further shows that the proposed clipping mechanism is robust and\nnearly optimal, without the need to manually select the clipping threshold,\nmatching the result of expensive hyperparameter search.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-09T12:56:22Z"}
{"aid":"http://arxiv.org/abs/2504.06862v1","title":"Dynamics of critical cascades in interdependent networks","summary":"The collapse of interdependent networks, as well as similar avalanche\nphenomena, is driven by cascading failures. At the critical point, the cascade\nbegins as a critical branching process, where each failing node (element)\ntriggers, on average, the failure of one other node. As nodes continue to fail,\nthe network becomes increasingly fragile and the branching factor grows. If the\nfailure process does not reach extinction during its critical phase, the\nnetwork undergoes an abrupt collapse. Here, we implement the analogy between\nthis dynamic and birth-death processes to derive new analytical results and\nsignificantly optimize numerical calculations. Using this approach, we analyze\nthree key aspects of the dynamics: the probability of collapse, the duration of\navalanches, and the length of the cascading plateau phase preceding a collapse.\nThis analysis quantifies how system size and the intensity of the initial\ntriggering event influence these characteristics.","main_category":"physics.soc-ph","categories":"physics.soc-ph,q-bio.PE","published":"2025-04-09T13:12:43Z"}
{"aid":"http://arxiv.org/abs/2504.06878v1","title":"CRYSIM: Prediction of Symmetric Structures of Large Crystals with\n  GPU-based Ising Machines","summary":"Solving black-box optimization problems with Ising machines is increasingly\ncommon in materials science. However, their application to crystal structure\nprediction (CSP) is still ineffective due to symmetry agnostic encoding of\natomic coordinates. We introduce CRYSIM, an algorithm that encodes the space\ngroup, the Wyckoff positions combination, and coordinates of independent atomic\nsites as separate variables. This encoding reduces the search space\nsubstantially by exploiting the symmetry in space groups. When CRYSIM is\ninterfaced to Fixstars Amplify, a GPU-based Ising machine, its prediction\nperformance was competitive with CALYPSO and Bayesian optimization for crystals\ncontaining more than 150 atoms in a unit cell. Although it is not realistic to\ninterface CRYSIM to current small-scale quantum devices, it has the potential\nto become the standard CSP algorithm in the coming quantum age.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cs.LG","published":"2025-04-09T13:33:48Z"}
{"aid":"http://arxiv.org/abs/2504.06883v1","title":"The Dirac Equation, Mass and Arithmetic by Permutations of Automaton\n  States","summary":"The cornerstones of the Cellular Automaton Interpretation of Quantum\nMechanics are its underlying ontological states that evolve by permutations.\nThey do not create would-be quantum mechanical superposition states. We review\nthis with a classical automaton consisting of an Ising spin chain which is then\nrelated to the Weyl equation in the continuum limit. Based on this and\ngeneralizing, we construct a new ``Necklace of Necklaces'' automaton with a\ntorus-like topology that lends itself to represent the Dirac equation in 1 + 1\ndimensions. Special attention has to be paid to its mass term, which\nnecessitates this enlarged structure and a particular scattering operator\ncontributing to the step-wise updates of the automaton. As discussed earlier,\nsuch deterministic models of discrete spins or bits unavoidably become quantum\nmechanical, when only slightly deformed.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.MP,nlin.CG","published":"2025-04-09T13:37:12Z"}
{"aid":"http://arxiv.org/abs/2504.06888v1","title":"The Singular CR Yamabe Problem and Hausdorff Dimension","summary":"We consider a compact pseudo-hermitian manifold (M,\\theta, J), that is a\nmanifold equipped with a contact form \\theta and CR structure J. We consider a\nconformal deformation of the contact form to obtain a complete, singular\ncontact form and a corresponding Yamabe problem. We estimate then the Hausdorff\ndimension of the singular set. The conformal geometry analog of this result is\ndue to R. Schoen and S. -T. Yau. Results of this type have their origin in work\nby Huber for Riemann surfaces. In the second part of our paper we investigate\nthe CR developing map for three dimensional CR manifolds. We establish the\ninjectivity of the developing map essentially using the same strategy as Schoen\nand Yau for the conformal case which is based on the positive mass theorem.\nHigher dimensional analogs of Huber's theorem in the conformal case for Q\ncurvature are due to Alice Chang, Jie Qing and P. Yang.","main_category":"math.DG","categories":"math.DG","published":"2025-04-09T13:49:53Z"}
{"aid":"http://arxiv.org/abs/2504.06892v1","title":"Applications of Hybrid Machine Learning Methods to Large Datasets: A\n  Case Study","summary":"We combine classical and quantum Machine Learning (ML) techniques to\neffectively analyze long time-series data acquired during experiments.\nSpecifically, we demonstrate that replacing a deep classical neural network\nwith a thoughtfully designed Variational Quantum Circuit (VQC) in an ML\npipeline for multiclass classification of time-series data yields the same\nclassification performance, while significantly reducing the number of\ntrainable parameters. To achieve this, we use a VQC based on a single qudit,\nand encode the classical data into the VQC via a trainable hybrid autoencoder\nwhich has been recently proposed as embedding technique. Our results highlight\nthe importance of tailored data pre-processing for the circuit and show the\npotential of qudit-based VQCs.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T13:53:27Z"}
{"aid":"http://arxiv.org/abs/2504.06932v1","title":"Maximizing Battery Storage Profits via High-Frequency Intraday Trading","summary":"Maximizing revenue for grid-scale battery energy storage systems in\ncontinuous intraday electricity markets requires strategies that are able to\nseize trading opportunities as soon as new information arrives. This paper\nintroduces and evaluates an automated high-frequency trading strategy for\nbattery energy storage systems trading on the intraday market for power while\nexplicitly considering the dynamics of the limit order book, market rules, and\ntechnical parameters. The standard rolling intrinsic strategy is adapted for\ncontinuous intraday electricity markets and solved using a dynamic programming\napproximation that is two to three orders of magnitude faster than an exact\nmixed-integer linear programming solution. A detailed backtest over a full year\nof German order book data demonstrates that the proposed dynamic programming\nformulation does not reduce trading profits and enables the policy to react to\nevery relevant order book update, enabling realistic rapid backtesting. Our\nresults show the significant revenue potential of high-frequency trading: our\npolicy earns 58% more than when re-optimizing only once every hour and 14% more\nthan when re-optimizing once per minute, highlighting that profits critically\ndepend on trading speed. Furthermore, we leverage the speed of our algorithm to\ntrain a parametric extension of the rolling intrinsic, increasing yearly\nrevenue by 8.4% out of sample.","main_category":"q-fin.TR","categories":"q-fin.TR,cs.SY,eess.SY,math.OC","published":"2025-04-09T14:38:09Z"}
{"aid":"http://arxiv.org/abs/2504.06957v1","title":"A Comparison of Deep Learning Methods for Cell Detection in Digital\n  Cytology","summary":"Accurate and efficient cell detection is crucial in many biomedical image\nanalysis tasks. We evaluate the performance of several Deep Learning (DL)\nmethods for cell detection in Papanicolaou-stained cytological Whole Slide\nImages (WSIs), focusing on accuracy of predictions and computational\nefficiency. We examine recentoff-the-shelf algorithms as well as\ncustom-designed detectors, applying them to two datasets: the CNSeg Dataset and\nthe Oral Cancer (OC) Dataset. Our comparison includes well-established\nsegmentation methods such as StarDist, Cellpose, and the Segment Anything Model\n2 (SAM2), alongside centroid-based Fully Convolutional Regression Network\n(FCRN) approaches. We introduce a suitable evaluation metric to assess the\naccuracy of predictions based on the distance from ground truth positions. We\nalso explore the impact of dataset size and data augmentation techniques on\nmodel performance. Results show that centroid-based methods, particularly the\nImproved Fully Convolutional Regression Network (IFCRN) method, outperform\nsegmentation-based methods in terms of both detection accuracy and\ncomputational efficiency. This study highlights the potential of centroid-based\ndetectors as a preferred option for cell detection in resource-limited\nenvironments, offering faster processing times and lower GPU memory usage\nwithout compromising accuracy.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T15:08:12Z"}
{"aid":"http://arxiv.org/abs/2504.06965v1","title":"A Deep Single Image Rectification Approach for Pan-Tilt-Zoom Cameras","summary":"Pan-Tilt-Zoom (PTZ) cameras with wide-angle lenses are widely used in\nsurveillance but often require image rectification due to their inherent\nnonlinear distortions. Current deep learning approaches typically struggle to\nmaintain fine-grained geometric details, resulting in inaccurate rectification.\nThis paper presents a Forward Distortion and Backward Warping Network\n(FDBW-Net), a novel framework for wide-angle image rectification. It begins by\nusing a forward distortion model to synthesize barrel-distorted images,\nreducing pixel redundancy and preventing blur. The network employs a pyramid\ncontext encoder with attention mechanisms to generate backward warping flows\ncontaining geometric details. Then, a multi-scale decoder is used to restore\ndistorted features and output rectified images. FDBW-Net's performance is\nvalidated on diverse datasets: public benchmarks, AirSim-rendered PTZ camera\nimagery, and real-scene PTZ camera datasets. It demonstrates that FDBW-Net\nachieves SOTA performance in distortion rectification, boosting the\nadaptability of PTZ cameras for practical visual applications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T15:19:38Z"}
{"aid":"http://arxiv.org/abs/2504.06984v1","title":"Weak Signals and Heavy Tails: Machine-learning meets Extreme Value\n  Theory","summary":"The masses of data now available have opened up the prospect of discovering\nweak signals using machine-learning algorithms, with a view to predictive or\ninterpretation tasks. As this survey of recent results attempts to show,\nbringing multivariate extreme value theory and statistical learning theory\ntogether in a common, non-parametric and non-asymptotic framework makes it\npossible to design and analyze new methods for exploiting the scarce\ninformation located in distribution tails in these purposes. This article\nreviews recently proved theoretical tools for establishing guarantees for\nsupervised or unsupervised algorithms learning from a fraction of extreme data.\nThese are mainly exponential maximal deviation inequalities tailored to\nlow-probability regions and concentration results for stochastic processes\nempirically describing the behavior of extreme observations, their dependence\nstructure in particular. Under appropriate assumptions of regular variation,\nseveral illustrative applications are then examined: classification,\nregression, anomaly detection, model selection via cross-validation. For these,\ngeneralization results are established inspired by the classical bounds in\nstatistical learning theory. In the same spirit, it is also shown how to adapt\nthe popular high-dimensional lasso technique in the context of extreme values\nfor the covariates with generalization guarantees.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-09T15:41:40Z"}
{"aid":"http://arxiv.org/abs/2504.07003v1","title":"The FitzHugh-Nagumo system on undulated cylinders: spontaneous\n  symmetrization and effective system","summary":"We consider the FitzHugh-Nagumo system on undulated cylindrical surfaces\nmodeling nerve axons. We show that for sufficiently small radii and for initial\nconditions close to radially symmetrical ones, (i) the solutions converge to\ntheir radial averages, and (ii) the latter averages can be approximated by\nsolutions of a 1+1 dimensional ('radial') system (the effective system)\ninvolving the surface radius function in its coefficients. This perhaps\nexplains why solutions of the original 1+1 dimensional FitzHugh-Nagumo system\nagree so well with experimental data on electrical impulse propagation.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T16:22:58Z"}
{"aid":"http://arxiv.org/abs/2504.07014v1","title":"Fermi surface as a quantum critical manifold: gaplessness, order\n  parameter, and scaling in $d$-dimensions","summary":"We study several models of $d$-dimensional fermions ($d=1,2,3$) with an\nemphasis on the properties of their gapless (metallic) phase. It occurs at $T =\n0$ as a continuous transition when zeros of the partition function reach the\nreal range of parameters. Those zeros define the $(d-1)$-manifold of quantum\ncriticality (Fermi surface). Its appearance or restructuring correspond to the\nLifshitz transition. Such $(d-1)$-membrane breaks the symmetry of the momentum\nspace, leading to gapless excitations, a hallmark of metallic phase. To probe\nquantitatively the gapless phase we introduce the geometric order parameter as\n$d$-volume of the Fermi sea. From analysis of the chain, ladder, and free\nfermions with different spectra, this proposal is shown to be consistent with\nscaling near the Lifshitz points of other quantities: correlation length,\noscillation wavelength, susceptibilities, and entanglement. All the\n(hyper)scaling relations are satisfied. Two interacting cases of the\nTomonaga-Luttinger ($d=1$) and the Fermi ($d=2,3$) liquids are analysed,\nyielding the same universality classes as free fermions.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.stat-mech,quant-ph","published":"2025-04-09T16:31:07Z"}
{"aid":"http://arxiv.org/abs/2504.07022v1","title":"Evaluating Retrieval Augmented Generative Models for Document Queries in\n  Transportation Safety","summary":"Applications of generative Large Language Models LLMs are rapidly expanding\nacross various domains, promising significant improvements in workflow\nefficiency and information retrieval. However, their implementation in\nspecialized, high-stakes domains such as hazardous materials transportation is\nchallenging due to accuracy and reliability concerns. This study evaluates the\nperformance of three fine-tuned generative models, ChatGPT, Google's Vertex AI,\nand ORNL Retrieval Augmented Generation augmented LLaMA 2 and LLaMA in\nretrieving regulatory information essential for hazardous material\ntransportation compliance in the United States. Utilizing approximately 40\npublicly available federal and state regulatory documents, we developed 100\nrealistic queries relevant to route planning and permitting requirements.\nResponses were qualitatively rated based on accuracy, detail, and relevance,\ncomplemented by quantitative assessments of semantic similarity between model\noutputs. Results demonstrated that the RAG-augmented LLaMA models significantly\noutperformed Vertex AI and ChatGPT, providing more detailed and generally\naccurate information, despite occasional inconsistencies. This research\nintroduces the first known application of RAG in transportation safety,\nemphasizing the need for domain-specific fine-tuning and rigorous evaluation\nmethodologies to ensure reliability and minimize the risk of inaccuracies in\nhigh-stakes environments.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T16:37:03Z"}
{"aid":"http://arxiv.org/abs/2504.07035v1","title":"Classification results for totally real surfaces of nearly K√§hler\n  $\\mathbb{C}P^3$","summary":"Totally real surfaces in the nearly K\\\"ahler $\\mathbb{C}P^3$ are investigated\nand are completely classified under various additional assumptions, resulting\nin multiple new examples. Among others, the classification includes totally\nreal surfaces that are extrinsically homogeneous; or minimal; or totally\numbilical; or Codazzi-like (including parallel and non-parallel examples).","main_category":"math.DG","categories":"math.DG","published":"2025-04-09T16:51:40Z"}
{"aid":"http://arxiv.org/abs/2504.07055v1","title":"$Œ†$-NeSy: A Possibilistic Neuro-Symbolic Approach","summary":"In this article, we introduce a neuro-symbolic approach that combines a\nlow-level perception task performed by a neural network with a high-level\nreasoning task performed by a possibilistic rule-based system. The goal is to\nbe able to derive for each input instance the degree of possibility that it\nbelongs to a target (meta-)concept. This (meta-)concept is connected to\nintermediate concepts by a possibilistic rule-based system. The probability of\neach intermediate concept for the input instance is inferred using a neural\nnetwork. The connection between the low-level perception task and the\nhigh-level reasoning task lies in the transformation of neural network outputs\nmodeled by probability distributions (through softmax activation) into\npossibility distributions. The use of intermediate concepts is valuable for the\nexplanation purpose: using the rule-based system, the classification of an\ninput instance as an element of the (meta-)concept can be justified by the fact\nthat intermediate concepts have been recognized.\n  From the technical side, our contribution consists of the design of efficient\nmethods for defining the matrix relation and the equation system associated\nwith a possibilistic rule-based system. The corresponding matrix and equation\nare key data structures used to perform inferences from a possibilistic\nrule-based system and to learn the values of the rule parameters in such a\nsystem according to a training data sample. Furthermore, leveraging recent\nresults on the handling of inconsistent systems of fuzzy relational equations,\nan approach for learning rule parameters according to multiple training data\nsamples is presented. Experiments carried out on the MNIST addition problems\nand the MNIST Sudoku puzzles problems highlight the effectiveness of our\napproach compared with state-of-the-art neuro-symbolic ones.","main_category":"cs.AI","categories":"cs.AI,cs.LG,cs.LO","published":"2025-04-09T17:16:23Z"}
{"aid":"http://arxiv.org/abs/2504.07072v1","title":"Kaleidoscope: In-language Exams for Massively Multilingual Vision\n  Evaluation","summary":"The evaluation of vision-language models (VLMs) has mainly relied on\nEnglish-language benchmarks, leaving significant gaps in both multilingual and\nmulticultural coverage. While multilingual benchmarks have expanded, both in\nsize and languages, many rely on translations of English datasets, failing to\ncapture cultural nuances. In this work, we propose Kaleidoscope, as the most\ncomprehensive exam benchmark to date for the multilingual evaluation of\nvision-language models. Kaleidoscope is a large-scale, in-language multimodal\nbenchmark designed to evaluate VLMs across diverse languages and visual inputs.\nKaleidoscope covers 18 languages and 14 different subjects, amounting to a\ntotal of 20,911 multiple-choice questions. Built through an open science\ncollaboration with a diverse group of researchers worldwide, Kaleidoscope\nensures linguistic and cultural authenticity. We evaluate top-performing\nmultilingual vision-language models and find that they perform poorly on\nlow-resource languages and in complex multimodal scenarios. Our results\nhighlight the need for progress on culturally inclusive multimodal evaluation\nframeworks.","main_category":"cs.CL","categories":"cs.CL,cs.CV","published":"2025-04-09T17:43:16Z"}
{"aid":"http://arxiv.org/abs/2504.07092v1","title":"Are We Done with Object-Centric Learning?","summary":"Object-centric learning (OCL) seeks to learn representations that only encode\nan object, isolated from other objects or background cues in a scene. This\napproach underpins various aims, including out-of-distribution (OOD)\ngeneralization, sample-efficient composition, and modeling of structured\nenvironments. Most research has focused on developing unsupervised mechanisms\nthat separate objects into discrete slots in the representation space,\nevaluated using unsupervised object discovery. However, with recent\nsample-efficient segmentation models, we can separate objects in the pixel\nspace and encode them independently. This achieves remarkable zero-shot\nperformance on OOD object discovery benchmarks, is scalable to foundation\nmodels, and can handle a variable number of slots out-of-the-box. Hence, the\ngoal of OCL methods to obtain object-centric representations has been largely\nachieved. Despite this progress, a key question remains: How does the ability\nto separate objects within a scene contribute to broader OCL objectives, such\nas OOD generalization? We address this by investigating the OOD generalization\nchallenge caused by spurious background cues through the lens of OCL. We\npropose a novel, training-free probe called $\\textbf{Object-Centric\nClassification with Applied Masks (OCCAM)}$, demonstrating that\nsegmentation-based encoding of individual objects significantly outperforms\nslot-based OCL methods. However, challenges in real-world applications remain.\nWe provide the toolbox for the OCL community to use scalable object-centric\nrepresentations, and focus on practical applications and fundamental questions,\nsuch as understanding object perception in human cognition. Our code is\navailable $\\href{https://github.com/AlexanderRubinstein/OCCAM}{here}$.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-09T17:59:05Z"}
{"aid":"http://arxiv.org/abs/2504.07411v1","title":"Estimand framework development for eGFR slope estimation and comparative\n  analyses across various estimation methods","summary":"Chronic kidney disease (CKD) is a global health challenge characterized by\nprogressive kidney function decline, often culminating in end-stage kidney\ndisease (ESKD) and increased mortality. To address the limitations such as the\nextended trial follow-up necessitated by the low incidence of kidney composite\nendpoint, the eGFR slope -- a surrogate endpoint reflecting the trajectory of\nkidney function decline -- has gained prominence for its predictive power and\nregulatory support. Despite its advantages, the lack of a standardized\nframework for eGFR slope estimand and estimation complicates consistent\ninterpretation and cross-trial comparisons. Existing methods, including simple\nlinear regression and mixed-effects models, vary in their underlying\nassumptions, creating a need for a formalized approach to align estimation\nmethods with trial objectives. This manuscript proposes an estimand framework\ntailored to eGFR slope-based analyses in CKD RCTs, ensuring clarity in defining\n\"what to estimate\" and enhancing the comparability of results. Through\nsimulation studies and real-world data applications, we evaluate the\nperformance of various commonly applied estimation techniques under distinct\nscenarios. By recommending a clear characterization for eGFR slope estimand and\nproviding considerations for estimation approaches, this work aims to improve\nthe reliability and interpretability of CKD trial results, advancing\ntherapeutic development and clinical decision-making.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-10T03:03:31Z"}
{"aid":"http://arxiv.org/abs/2504.07430v1","title":"Nonlinear Optimal Guidance for Intercepting Moving Targets","summary":"This paper introduces a nonlinear optimal guidance framework for guiding a\npursuer to intercept a moving target, with an emphasis on real-time generation\nof optimal feedback control for a nonlinear optimal control problem. Initially,\nconsidering the target moves without maneuvering, we derive the necessary\noptimality conditions using Pontryagin's Maximum Principle. These conditions\nreveal that each extremal trajectory is uniquely determined by two scalar\nparameters. Analyzing the geometric property of the parameterized extremal\ntrajectories not only leads to an additional necessary condition but also\nallows to establish a sufficient condition for local optimality. This enables\nthe generation of a dataset containing at least locally optimal trajectories.\nBy studying the properties of the optimal feedback control, the size of the\ndataset is reduced significantly, allowing training a lightweight neural\nnetwork to predict the optimal guidance command in real time. Furthermore, the\nperformance of the neural network is enhanced by incorporating the target's\nacceleration, making it suitable for intercepting both uniformly moving and\nmaneuvering targets. Finally, numerical simulations validate the proposed\nnonlinear optimal guidance framework, demonstrating its better performance over\nexisting guidance laws.","main_category":"math.OC","categories":"math.OC","published":"2025-04-10T03:52:24Z"}
{"aid":"http://arxiv.org/abs/2504.07443v1","title":"Optoelectronic properties of self-trapped holes in orthorhombic Ga2O3\n  and its alloys","summary":"We investigated the influence of valence band holes on the optoelectronic\nproperties of orthorhombic k-Ga2O3 and its alloys with Al and In. Our hybrid\ndensity functional theory calculations show that self-trapped holes (STHs)\nlocalize on oxygen atoms within a single unit cell and exhibit \\emph{p}-orbital\ncharacteristics. The inclusion of isoelectronic dopants such as Al and In\nreduces but does not remove the absorption of visible light due to STH\nformation. The combination of a positive STH formation energy, large lattice\ndistortions, and emergent acceptor levels, coupled with the observed\nred-shifted, visible spectrum, emergent absorption peaks, implies that\nalternative doping/alloying strategies are necessary to achieve effective\np-type conductivity in orthorhombic k-Ga2O3.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-10T04:20:23Z"}
{"aid":"http://arxiv.org/abs/2504.07461v1","title":"Achilles Heel of Distributed Multi-Agent Systems","summary":"Multi-agent system (MAS) has demonstrated exceptional capabilities in\naddressing complex challenges, largely due to the integration of multiple large\nlanguage models (LLMs). However, the heterogeneity of LLMs, the scalability of\nquantities of LLMs, and local computational constraints pose significant\nchallenges to hosting these models locally. To address these issues, we propose\na new framework termed Distributed Multi-Agent System (DMAS). In DMAS,\nheterogeneous third-party agents function as service providers managed remotely\nby a central MAS server and each agent offers its services through API\ninterfaces. However, the distributed nature of DMAS introduces several concerns\nabout trustworthiness. In this paper, we study the Achilles heel of distributed\nmulti-agent systems, identifying four critical trustworthiness challenges: free\nriding, susceptibility to malicious attacks, communication inefficiencies, and\nsystem instability. Extensive experiments across seven frameworks and four\ndatasets reveal significant vulnerabilities of the DMAS. These attack\nstrategies can lead to a performance degradation of up to 80% and attain a 100%\nsuccess rate in executing free riding and malicious attacks. We envision our\nwork will serve as a useful red-teaming tool for evaluating future multi-agent\nsystems and spark further research on trustworthiness challenges in distributed\nmulti-agent systems.","main_category":"cs.MA","categories":"cs.MA","published":"2025-04-10T05:16:11Z"}
{"aid":"http://arxiv.org/abs/2504.07466v1","title":"Personalized and Demand-Based Education Concept: Practical Tools for\n  Control Engineers","summary":"This paper presents a personalized lecture concept using educational blocks\nand its demonstrative application in a new university lecture. Higher education\nfaces daily challenges: deep and specialized knowledge is available from\neverywhere and accessible to almost everyone. University lecturers of\nspecialized master courses confront the problem that their lectures are either\ntoo boring or too complex for the attending students. Additionally, curricula\nare changing more rapidly than they have in the past 10-30 years. The German\neducation system comprises different educational forms, with universities\nproviding less practical content. Consequently, many university students do not\nobtain the practical skills they should ideally gain through university\nlectures. Therefore, in this work, a new lecture concept is proposed based on\nthe extension of the just-in-time teaching paradigm: Personalized and\nDemand-Based Education. This concept includes: 1) an initial assessment of\nstudents' backgrounds, 2) selecting the appropriate educational blocks, and 3)\ncollecting ongoing feedback during the semester. The feedback was gathered via\nPingo, ensuring anonymity for the students. Our concept was exemplarily tested\nin the new lecture \"Practical Tools for Control Engineers\" at the Karlsruhe\nInstitute of Technology. The initial results indicate that our proposed concept\ncould be beneficial in addressing the current challenges in higher education.","main_category":"eess.SY","categories":"eess.SY,cs.RO,cs.SY,K.3.1","published":"2025-04-10T05:34:37Z"}
{"aid":"http://arxiv.org/abs/2504.07468v1","title":"Novel Pooling-based VGG-Lite for Pneumonia and Covid-19 Detection from\n  Imbalanced Chest X-Ray Datasets","summary":"This paper proposes a novel pooling-based VGG-Lite model in order to mitigate\nclass imbalance issues in Chest X-Ray (CXR) datasets. Automatic Pneumonia\ndetection from CXR images by deep learning model has emerged as a prominent and\ndynamic area of research, since the inception of the new Covid-19 variant in\n2020. However, the standard Convolutional Neural Network (CNN) models encounter\nchallenges associated with class imbalance, a prevalent issue found in many\nmedical datasets. The innovations introduced in the proposed model architecture\ninclude: (I) A very lightweight CNN model, `VGG-Lite', is proposed as a base\nmodel, inspired by VGG-16 and MobileNet-V2 architecture. (II) On top of this\nbase model, we leverage an ``Edge Enhanced Module (EEM)\" through a parallel\nbranch, consisting of a ``negative image layer\", and a novel custom pooling\nlayer ``2Max-Min Pooling\". This 2Max-Min Pooling layer is entirely novel in\nthis investigation, providing more attention to edge components within\npneumonia CXR images. Thus, it works as an efficient spatial attention module\n(SAM). We have implemented the proposed framework on two separate CXR datasets.\nThe first dataset is obtained from a readily available source on the internet,\nand the second dataset is a more challenging CXR dataset, assembled by our\nresearch team from three different sources. Experimental results reveal that\nour proposed framework has outperformed pre-trained CNN models, and three\nrecent trend existing models ``Vision Transformer\", ``Pooling-based Vision\nTransformer (PiT)'' and ``PneuNet\", by substantial margins on both datasets.\nThe proposed framework VGG-Lite with EEM, has achieved a macro average of 95%\naccuracy, 97.1% precision, 96.1% recall, and 96.6% F1 score on the ``Pneumonia\nImbalance CXR dataset\", without employing any pre-processing technique.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-10T05:38:46Z"}
{"aid":"http://arxiv.org/abs/2504.07471v1","title":"Traversal Learning Coordination For Lossless And Efficient Distributed\n  Learning","summary":"In this paper, we introduce Traversal Learning (TL), a novel approach\ndesigned to address the problem of decreased quality encountered in popular\ndistributed learning (DL) paradigms such as Federated Learning (FL), Split\nLearning (SL), and SplitFed Learning (SFL). Traditional FL experiences from an\naccuracy drop during aggregation due to its averaging function, while SL and\nSFL face increased loss due to the independent gradient updates on each split\nnetwork. TL adopts a unique strategy where the model traverses the nodes during\nforward propagation (FP) and performs backward propagation (BP) on the\norchestrator, effectively implementing centralized learning (CL) principles\nwithin a distributed environment. The orchestrator is tasked with generating\nvirtual batches and planning the sequential node visits of the model during FP,\naligning them with the ordered index of the data within these batches. We\nconducted experiments on six datasets representing diverse characteristics\nacross various domains. Our evaluation demonstrates that TL is on par with\nclassic CL approaches in terms of accurate inference, thereby offering a viable\nand robust solution for DL tasks. TL outperformed other DL methods and improved\naccuracy by 7.85% for independent and identically distributed (IID) datasets,\nmacro F1-score by 1.06% for non-IID datasets, accuracy by 2.60% for text\nclassification, and AUC by 3.88% and 4.54% for medical and financial datasets,\nrespectively. By effectively preserving data privacy while maintaining\nperformance, TL represents a significant advancement in DL methodologies.","main_category":"cs.LG","categories":"cs.LG,cs.DC","published":"2025-04-10T05:48:57Z"}
{"aid":"http://arxiv.org/abs/2504.07503v1","title":"Event Signal Filtering via Probability Flux Estimation","summary":"Events offer a novel paradigm for capturing scene dynamics via asynchronous\nsensing, but their inherent randomness often leads to degraded signal quality.\nEvent signal filtering is thus essential for enhancing fidelity by reducing\nthis internal randomness and ensuring consistent outputs across diverse\nacquisition conditions. Unlike traditional time series that rely on fixed\ntemporal sampling to capture steady-state behaviors, events encode transient\ndynamics through polarity and event intervals, making signal modeling\nsignificantly more complex. To address this, the theoretical foundation of\nevent generation is revisited through the lens of diffusion processes. The\nstate and process information within events is modeled as continuous\nprobability flux at threshold boundaries of the underlying irradiance\ndiffusion. Building on this insight, a generative, online filtering framework\ncalled Event Density Flow Filter (EDFilter) is introduced. EDFilter estimates\nevent correlation by reconstructing the continuous probability flux from\ndiscrete events using nonparametric kernel smoothing, and then resamples\nfiltered events from this flux. To optimize fidelity over time, spatial and\ntemporal kernels are employed in a time-varying optimization framework. A fast\nrecursive solver with O(1) complexity is proposed, leveraging state-space\nmodels and lookup tables for efficient likelihood computation. Furthermore, a\nnew real-world benchmark Rotary Event Dataset (RED) is released, offering\nmicrosecond-level ground truth irradiance for full-reference event filtering\nevaluation. Extensive experiments validate EDFilter's performance across tasks\nlike event filtering, super-resolution, and direct event-based blob tracking.\nSignificant gains in downstream applications such as SLAM and video\nreconstruction underscore its robustness and effectiveness.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T07:03:08Z"}
{"aid":"http://arxiv.org/abs/2504.07504v1","title":"On Ihara's lemma for definite unitary groups","summary":"Clozel, Harris, and Taylor proposed a conjectural generalized Ihara's lemma\nfor definite unitary groups. In this paper, we prove their conjecture over\nbanal coefficients under some conditions. As an application, we prove a\nlevel-raising result for automorphic forms associated to definite unitary\ngroups.","main_category":"math.NT","categories":"math.NT,math.RT","published":"2025-04-10T07:03:27Z"}
{"aid":"http://arxiv.org/abs/2504.07520v1","title":"Stability and Convergence of Strang Splitting Method for the Allen-Cahn\n  Equation with Homogeneous Neumann Boundary Condition","summary":"The Strang splitting method has been widely used to solve nonlinear\nreaction-diffusion equations, with most theoretical convergence analysis\nassuming periodic boundary conditions. However, such analysis presents\nadditional challenges for the case of homogeneous Neumann boundary condition.\nIn this work the Strang splitting method with variable time steps is\ninvestigated for solving the Allen--Cahn equation with homogeneous Neumann\nboundary conditions. Uniform $H^k$-norm stability is established under the\nassumption that the initial condition $u^0$ belongs to the Sobolev space\n$H^k(\\Omega)$ with integer $k\\ge 0$, using the Gagliardo--Nirenberg\ninterpolation inequality and the Sobolev embedding inequality. Furthermore,\nrigorous convergence analysis is provided in the $H^k$-norm for initial\nconditions $u^0 \\in H^{k+6}(\\Omega)$, based on the uniform stability. Several\nnumerical experiments are conducted to verify the theoretical results,\ndemonstrating the effectiveness of the proposed method.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-10T07:33:42Z"}
{"aid":"http://arxiv.org/abs/2504.07525v1","title":"Non triviality of the percolation threshold and Gumbel fluctuations for\n  Branching Interlacements","summary":"We consider the model of Branching Interlacements, introduced by Zhu, which\nis a natural analogue of Sznitman's Random Interlacements model, where the\nrandom walk trajectories are replaced by ranges of some suitable tree-indexed\nrandom walks. We first prove a basic decorrelation inequality for events\ndepending on the state of the field on distinct boxes. We then show that in all\nrelevant dimensions, the vacant set undergoes a nontrivial phase transition\nregarding the existence of an infinite connected component. Finally we obtain\nthe Gumbel fluctuations for the cover level of finite sets, which is analogous\nto Belius' result in the setting of Random Interlacements.","main_category":"math.PR","categories":"math.PR","published":"2025-04-10T07:46:21Z"}
{"aid":"http://arxiv.org/abs/2504.07526v1","title":"Computing gradient vector fields with Morse sequences","summary":"We rely on the framework of Morse sequences to enable the direct computation\nof gradient vector fields on simplicial complexes. A Morse sequence is a\nfiltration from a subcomplex L to a complex K via elementary expansions and\nfillings, naturally encoding critical and regular simplexes. Maximal increasing\nand minimal decreasing schemes allow constructing these sequences, and are\nlinked to algorithms like Random Discrete Morse and Coreduction. Extending the\napproach to cosimplicial complexes (S = K \\ L), we define operations --\nreductions, perforations, coreductions, and coperforations -- for efficient\ncomputation. We further generalize to F -sequences, which are Morse sequences\nweighted by an arbitrary stack function F , and provide algorithms to compute\nmaximal and minimal sequences. A particular case is when the stack function is\ngiven through a vertex map, as it is common in topological data analysis. We\nshow that we retrieve existing methods when the vertex map is injective; in\nthis case, the complex partitions into lower stars, facilitating parallel\nprocessing. Thus, this paper proposes simple, flexible, and computationally\nefficient approaches to obtain Morse sequences from arbitrary stack functions,\nallowing to generalize previous approaches dedicated to computing gradient\nvector fields from injective vertex maps.","main_category":"cs.DM","categories":"cs.DM,math.AT","published":"2025-04-10T07:48:31Z"}
{"aid":"http://arxiv.org/abs/2504.07535v1","title":"The v-numbers of Stanley-Reisner ideals from the viewpoint of Alexander\n  dual complexes","summary":"We express the v-number of the Stanley-Reisner ideal in terms of its\nAlexander dual complex and prove that the v-number of a cover ideal is just two\nless than the initial degree of the its syzygy module. We give some relation\nbetween the v-number of the Stanley-Reisner ideal and the Serre-depth of the\nquotient ring of the second symbolic power of the Stanley-Reisner ideal of its\nAlexander dual. We also show that the v-number of the Stanley-Reisner ideal of\na 2-pure simplicial complex is equal to the dimension of its Stanley-Reisner\nring.","main_category":"math.AC","categories":"math.AC","published":"2025-04-10T08:01:59Z"}
{"aid":"http://arxiv.org/abs/2504.07586v1","title":"A perspective on totally geodesic submanifolds of the symmetric space\n  $G_2/SO(4)$","summary":"We provide an independent proof of the classification of the maximal totally\ngeodesic submanifolds of the symmetric spaces $G_2$ and $G_2/SO(4)$, jointly\nwith very natural descriptions of all of these submanifolds. The description of\nthe totally geodesic submanifolds of $G_2$ is in terms of (1) principal\nsubalgebras of $\\mathfrak{g}_2$; (2) stabilizers of nonzero points of\n$\\mathbb{R}^7$; (3) stabilizers of associative subalgebras; (4) the set of\norder two elements in $G_2$ (and its translations). The space $G_2/SO(4)$ is\nidentified with the set of associative subalgebras of $\\mathbb{R}^7$ and its\nmaximal totally geodesic submanifolds can be described as the associative\nsubalgebras adapted to a fixed principal subalgebra, the associative\nsubalgebras orthogonal to a fixed nonzero vector, the associative subalgebras\ncontaining a fixed nonzero vector, and the associative subalgebras intersecting\nboth a fixed associative subalgebra and its orthogonal. A second description is\nincluded in terms of Grassmannians, the advantage of which is that the\nassociated Lie triple systems are easily described in matrix form.","main_category":"math.DG","categories":"math.DG","published":"2025-04-10T09:28:50Z"}
{"aid":"http://arxiv.org/abs/2504.07592v1","title":"Hardness of 4-Colourings G-Colourable Graphs","summary":"We study the complexity of a class of promise graph homomorphism problems.\nFor a fixed graph H, the H-colouring problem is to decide whether a given graph\nhas a homomorphism to H. By a result of Hell and Ne\\v{s}et\\v{r}il, this problem\nis NP-hard for any non-bipartite loop-less graph H. Brakensiek and Guruswami\n[SODA 2018] conjectured the hardness extends to promise graph homomorphism\nproblems as follows: fix a pair of non-bipartite loop-less graphs G, H such\nthat there is a homomorphism from G to H, it is NP-hard to distinguish between\ngraphs that are G-colourable and those that are not H-colourable. We confirm\nthis conjecture in the cases when both G and H are 4-colourable. This is a\ncommon generalisation of previous results of Khanna, Linial, and Safra [Comb.\n20(3): 393-415 (2000)] and of Krokhin and Opr\\v{s}al [FOCS 2019]. The result is\nobtained by combining the algebraic approach to promise constraint satisfaction\nwith methods of topological combinatorics and equivariant obstruction theory.","main_category":"cs.CC","categories":"cs.CC,math.AT,math.CO","published":"2025-04-10T09:44:53Z"}
{"aid":"http://arxiv.org/abs/2504.07599v1","title":"Tuning chirality amplitude at ultrafast timescales","summary":"Chirality is a fundamental symmetry concept describing discrete states, i.e.,\nleft-handed, right-handed, or achiral, and existing at disparate scales and in\nmany categories of scientific fields. Even though symmetry breaking is\nindispensable for describing qualitatively distinct phenomena, symmetry cannot\nquantitatively predict measurable quantities. One can continuously distort an\nobject, introducing the concept of chirality amplitude, similar to representing\nmagnetization as the amplitude of time-reversal symmetry breaking. Considering\nthe role of magnetization in emergent phenomena with time-reversal symmetry\nbreaking, chirality amplitude is intuitively a key quantity for controlling\nchirality-related emergent phenomena. Here, we propose two types of chiral\nlattice distortions and demonstrate the tunability of their amplitude in\nultrafast timescales. Resonant X-ray diffraction with circular polarization is\nan established technique to measure crystal chirality directly. We quantify the\nultrafast change in chirality amplitude in real time after an optical\nexcitation. Using instead a THz excitation, we observe oscillations in the\nresonant diffraction intensities corresponding to specific phonon frequencies.\nThis indicates the creation of additional asymmetry, which could also be\ndescribed as an enhancement in chirality amplitude. Our proposed concept of\nchirality amplitude and its ultrafast control may lead to a unique approach to\ncontrol chirality-induced emergent phenomena in ultrafast timescales.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-10T09:52:13Z"}
{"aid":"http://arxiv.org/abs/2504.07613v1","title":"Power spectrum of the CODEX clusters","summary":"Aims. We analyze the clustering of galaxy clusters in a large contiguous\nsample, the Constrain Dark Energy with X-ray (CODEX) sample. We construct a\nlikelihood for cosmological parameters by comparing the measured clustering\nsignal and a theoretical prediction, and use this to obtain parameter\nconstraints. Methods. We measured the three multipole moments (monopole,\nquadrupole, and hexadecapole, $\\ell = 0, 2, 4$) of the power spectrum of a\nsubset of the CODEX clusters. To fully model cluster clustering, we also\ndetermined the expected clustering bias of the sample using estimates for the\ncluster masses and a mass-to-bias model calibrated using N-body simulations. We\nestimated the covariance matrix of the measured power spectrum multipoles using\na set of simulated dark-matter halo catalogs. Combining all these ingredients,\nwe performed a Markov chain Monte Carlo sampling of cosmological parameters\n$\\Omega_m$ and $\\sigma_8$ to obtain their posterior. Results. We found the\nCODEX clustering signal to be consistent with an earlier X-ray selected cluster\nsample, the REFLEX II sample. We also found that the measured power spectrum\nmultipoles are compatible with the predicted, bias-scaled linear matter power\nspectrum when the cosmological parameters determined by the Planck satellite\nare assumed. Furthermore, we found the marginalized parameter constraints of\n$\\Omega_m = 0.24^{+0.06}_{-0.04}$ and $\\sigma_8 = 1.13^{+0.43}_{-0.24}$. The\nfull 2D posterior is consistent, for example, with the Planck cosmology within\nthe 68% confidence region.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-10T10:04:24Z"}
{"aid":"http://arxiv.org/abs/2504.07635v1","title":"Generative Artificial Intelligence for Internet of Things Computing: A\n  Systematic Survey","summary":"The integration of Generative Artificial Intelligence (GenAI) within the\nInternet of Things (IoT) is garnering considerable interest. This growing\nattention stems from the continuous evolution and widespread adoption they are\nboth having individually, enough to spontaneously reshape numerous sectors,\nincluding Healthcare, Manufacturing, and Smart Cities. Hence, their increasing\npopularity has catalyzed further extensive research for understanding the\npotential of the duo GenAI-IoT, how they interplay, and to which extent their\nsynergy can innovate the state-of-the-art in their individual scenarios.\nHowever, despite the increasing prominence of GenAI for IoT Computing, much of\nthe existing research remains focused on specific, narrowly scoped\napplications. This fragmented approach highlights the need for a more\ncomprehensive analysis of the potential, challenges, and implications of GenAI\nintegration within the broader IoT ecosystem. This survey exactly aims to\naddress this gap by providing a holistic overview of the opportunities, issues,\nand considerations arising from the convergence of these mainstream paradigms.\nOur contribution is realized through a systematic literature review following\nthe PRISMA methodology. A comparison framework is presented, and well-defined\nresearch questions are outlined to comprehensively explore the past, present,\nand future directions of GenAI integration with IoT Computing, offering\nvaluable insights for both experts and newcomers.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-10T10:32:18Z"}
{"aid":"http://arxiv.org/abs/2504.07661v1","title":"Unveiling the Impact of Multimodal Features on Chinese Spelling\n  Correction: From Analysis to Design","summary":"The Chinese Spelling Correction (CSC) task focuses on detecting and\ncorrecting spelling errors in sentences. Current research primarily explores\ntwo approaches: traditional multimodal pre-trained models and large language\nmodels (LLMs). However, LLMs face limitations in CSC, particularly\nover-correction, making them suboptimal for this task. While existing studies\nhave investigated the use of phonetic and graphemic information in multimodal\nCSC models, effectively leveraging these features to enhance correction\nperformance remains a challenge. To address this, we propose the Multimodal\nAnalysis for Character Usage (\\textbf{MACU}) experiment, identifying potential\nimprovements for multimodal correctison. Based on empirical findings, we\nintroduce \\textbf{NamBert}, a novel multimodal model for Chinese spelling\ncorrection. Experiments on benchmark datasets demonstrate NamBert's superiority\nover SOTA methods. We also conduct a comprehensive comparison between NamBert\nand LLMs, systematically evaluating their strengths and limitations in CSC. Our\ncode and model are available at https://github.com/iioSnail/NamBert.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T11:19:09Z"}
{"aid":"http://arxiv.org/abs/2504.07709v1","title":"Integrated Sensing and Communications for Pinching-Antenna Systems\n  (PASS)","summary":"An integrated sensing and communication (ISAC) design for pinching antenna\nsystems (PASS) is proposed, where the pinching antennas are deployed for\nestablishing reliable line-of-sight communication and sensing links. More\nparticularly, a separated ISAC design is proposed for the two-waveguide PASS,\nwhere one waveguide is used to emit the joint communication and sensing signals\nwhile the other waveguide is used to receive the reflected echo signals. Based\non this framework, a penalty-based alternating optimization algorithm is\nproposed to maximize the illumination power as well as ensure the communication\nquality-of-service requirement. Numerical results demonstrate that 1) the\nproposed PASS-ISAC scheme outperforms the other baseline schemes, and 2) the\nconsidered equal power allocation model achieves a performance comparable to\nthe optimal power allocation.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-10T12:58:46Z"}
{"aid":"http://arxiv.org/abs/2504.07714v1","title":"Quasi-Periodic Pulsations in Ionospheric TEC Synchronized with Solar\n  Flare EUV Emission","summary":"The extreme ultraviolet (EUV) and X-ray radiation emitted during solar flares\nhas been shown to significantly increase the electron density of the Earth's\nionosphere. During flares, quasi-periodic pulsations (QPPs) in X-ray flux\noriginating in the corona have previously been linked to subsequent pulsations\nin the Earth's ionospheric D-region. Similar pulsations have been detected in\nchromospheric EUV emission, although their impact on the Earth's ionosphere has\nnot previously been investigated. Here, for the first time, synchronous\npulsations were detected in solar EUV emission and ionospheric Total Electron\nContent (TEC) measurements. Using wavelet and periodogram analysis, we detect\nQPPs with approximately 85 second periods in chromospheric EUV emission lines\n(He II 304 \\AA{}, C III 977 \\AA{} and H I 972 \\AA{}) from the Solar Dynamics\nObservatory Extreme Ultraviolet Variability Experiment (SDO/EVE) during the\nimpulsive phase of an X5.4 flare on March 7, 2012. These lines contribute to\nionization in the ionospheric E- and F-regions, resulting in subsequent\nvariations of electron density with the same periodicity, which was detected in\nTEC measurements. This work demonstrates that the Earth's ionosphere is\nresponsive to fine-scale fluctuations in EUV emission during flares, with a\ntime delay of approximately 30 seconds found. These findings may have\napplications in atmospheric modelling and solar-terrestrial studies, including\nthe calculation of ionospheric recombination rates.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP","published":"2025-04-10T13:05:45Z"}
{"aid":"http://arxiv.org/abs/2504.07730v1","title":"Thermodynamics of Reissner-nordstorm black bounce black hole","summary":"Our study focuses on the thermodynamics of Reissner-nordstorm black bounce\nblack hole,we have determined the thermodynamic parameters including entropy,\nmass, temperature, heat capacity and free energies and investigated how those\nparameters are related to entropy and for some insights we additionally focused\non the P V isotherm and the logarithmic correction to the entropy.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-10T13:27:49Z"}
{"aid":"http://arxiv.org/abs/2504.07741v1","title":"Harnessing Equivariance: Modeling Turbulence with Graph Neural Networks","summary":"This work proposes a novel methodology for turbulence modeling in Large Eddy\nSimulation (LES) based on Graph Neural Networks (GNNs), which embeds the\ndiscrete rotational, reflectional and translational symmetries of the\nNavier-Stokes equations into the model architecture. In addition, suitable\ninvariant input and output spaces are derived that allow the GNN models to be\nembedded seamlessly into the LES framework to obtain a symmetry-preserving\nsimulation setup. The suitability of the proposed approach is investigated for\ntwo canonical test cases: Homogeneous Isotropic Turbulence (HIT) and turbulent\nchannel flow. For both cases, GNN models are trained successfully in actual\nsimulations using Reinforcement Learning (RL) to ensure that the models are\nconsistent with the underlying LES formulation and discretization. It is\ndemonstrated for the HIT case that the resulting GNN-based LES scheme recovers\nrotational and reflectional equivariance up to machine precision in actual\nsimulations. At the same time, the stability and accuracy remain on par with\nnon-symmetry-preserving machine learning models that fail to obey these\nproperties. The same modeling strategy translates well to turbulent channel\nflow, where the GNN model successfully learns the more complex flow physics and\nis able to recover the turbulent statistics and Reynolds stresses. It is shown\nthat the GNN model learns a zonal modeling strategy with distinct behaviors in\nthe near-wall and outer regions. The proposed approach thus demonstrates the\npotential of GNNs for turbulence modeling, especially in the context of LES and\nRL.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cs.LG","published":"2025-04-10T13:37:54Z"}
{"aid":"http://arxiv.org/abs/2504.07746v1","title":"Upper semi-continuity of metric entropy for $\\mathcal{C}^{1,Œ±}$\n  diffeomorphisms","summary":"We prove that for $\\mathcal{C}^{1,\\alpha}$ diffeomorphisms on a compact\nmanifold $M$ with ${\\rm dim} M\\leq 3$, if an invariant measure $\\mu$ is a\ncontinuity point of the sum of positive Lyapunov exponents, then $\\mu$ is an\nupper semi-continuity point of the entropy map. This gives several\nconsequences, such as the upper-semi continuity of dimensions of measures for\nsurface diffeomorphisms. Furthermore, we know the continuity of dimensions for\nmeasures of maximal entropy.","main_category":"math.DS","categories":"math.DS","published":"2025-04-10T13:41:37Z"}
{"aid":"http://arxiv.org/abs/2504.07758v1","title":"PIDSR:ComplementaryPolarizedImageDemosaicingandSuper-Resolution","summary":"Polarization cameras can capture multiple polarized images with different\npolarizer angles in a single shot, bringing convenience to polarization-based\ndownstream tasks. However, their direct outputs are color-polarization filter\narray (CPFA) raw images, requiring demosaicing to reconstruct full-resolution,\nfull-color polarized images; unfortunately, this necessary step introduces\nartifacts that make polarization-related parameters such as the degree of\npolarization (DoP) and angle of polarization (AoP) prone to error. Besides,\nlimited by the hardware design, the resolution of a polarization camera is\noften much lower than that of a conventional RGB camera. Existing polarized\nimage demosaicing (PID) methods are limited in that they cannot enhance\nresolution, while polarized image super-resolution (PISR) methods, though\ndesigned to obtain high-resolution (HR) polarized images from the demosaicing\nresults, tend to retain or even amplify errors in the DoP and AoP introduced by\ndemosaicing artifacts. In this paper, we propose PIDSR, a joint framework that\nperforms complementary Polarized Image Demosaicing and Super-Resolution,\nshowing the ability to robustly obtain high-quality HR polarized images with\nmore accurate DoP and AoP from a CPFA raw image in a direct manner. Experiments\nshow our PIDSR not only achieves state-of-the-art performance on both synthetic\nand real data, but also facilitates downstream tasks.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-10T13:56:33Z"}
{"aid":"http://arxiv.org/abs/2504.07777v1","title":"Adaptive Detection of Fast Moving Celestial Objects Using a Mixture of\n  Experts and Physical-Inspired Neural Network","summary":"Fast moving celestial objects are characterized by velocities across the\ncelestial sphere that significantly differ from the motions of background\nstars. In observational images, these objects exhibit distinct shapes,\ncontrasting with the typical appearances of stars. Depending on the\nobservational method employed, these celestial entities may be designated as\nnear-Earth objects or asteroids. Historically, fast moving celestial objects\nhave been observed using ground-based telescopes, where the relative stability\nof stars and Earth facilitated effective image differencing techniques\nalongside traditional fast moving celestial object detection and classification\nalgorithms. However, the growing prevalence of space-based telescopes, along\nwith their diverse observational modes, produces images with different\nproperties, rendering conventional methods less effective. This paper presents\na novel algorithm for detecting fast moving celestial objects within star\nfields. Our approach enhances state-of-the-art fast moving celestial object\ndetection neural networks by transforming them into physical-inspired neural\nnetworks. These neural networks leverage the point spread function of the\ntelescope and the specific observational mode as prior information; they can\ndirectly identify moving fast moving celestial objects within star fields\nwithout requiring additional training, thereby addressing the limitations of\ntraditional techniques. Additionally, all neural networks are integrated using\nthe mixture of experts technique, forming a comprehensive fast moving celestial\nobject detection algorithm. We have evaluated our algorithm using simulated\nobservational data that mimics various observations carried out by space based\ntelescope scenarios and real observation images. Results demonstrate that our\nmethod effectively detects fast moving celestial objects across different\nobservational modes.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.EP,cs.CV,cs.LG,physics.optics","published":"2025-04-10T14:15:30Z"}
{"aid":"http://arxiv.org/abs/2504.07857v1","title":"$B$ meson semileptonic decays from lattice QCD","summary":"$B$ processes are a rich source of potential anomalies that could lead to the\ndiscovery of BSM physics. The long-standing tension between the inclusive and\nthe exclusive determinations of the CKM matrix elements $|V_{xb}|$, or the\ncurrent tensions in the $R(D)$-$R(D^\\ast)$ plane are some examples of active\nareas of research where we might find signals of new physics. Heavy-to-heavy\n$B$ semileptonic decays, $B_{(s)}\\to D^{(\\ast)}_{(s)}\\ell\\nu$, and in\nparticular, decays with a vector product ($D^\\ast_{(s)}$) are especially\ninteresting from an experimental point of view, but experiment and theory must\nwalk together in order to reach conclusions in the intensity frontier. In this\nreview I talk about the current status of the lattice-QCD calculations of the\n$B\\to D^{\\ast}\\ell\\nu$ form factors at non-zero recoil, I discuss the\nimplications they have for the determination of $B$ anomalies, and finally I\ngive some hints of what we can expect from future calculations.","main_category":"hep-ph","categories":"hep-ph,hep-lat","published":"2025-04-10T15:32:23Z"}
{"aid":"http://arxiv.org/abs/2504.07870v1","title":"Open Datasets for Grid Modeling and Visualization: An Alberta Power\n  Network Case","summary":"In the power and energy industry, multiple entities in grid operational logs\nare frequently recorded and updated. Thanks to recent advances in IT facilities\nand smart metering services, a variety of datasets such as system load,\ngeneration mix, and grid connection are often publicly available. While these\nresources are valuable in evaluating power grid's operational conditions and\nsystem resilience, the lack of fine-grained, accurate locational information\nconstrain the usage of current data, which further hinders the development of\nsmart grid and renewables integration. For instance, electricity end users are\nnot aware of nodal generation mix or carbon emissions, while the general public\nhave limited understanding about the effect of demand response or renewables\nintegration if only the whole system's demands and generations are available.\nIn this work, we focus on recovering power grid topology and line flow\ndirections from open public dataset. Taking the Alberta grid as a working\nexample, we start from mapping multi-modal power system datasets to the grid\ntopology integrated with geographical information. By designing a novel\noptimization-based scheme to recover line flow directions, we are able to\nanalyze and visualize the interactions between generations and demand vectors\nin an efficient manner. Proposed research is fully open-sourced and highly\ngeneralizable, which can help model and visualize grid information, create\nsynthetic dataset, and facilitate analytics and decision-making framework for\nclean energy transition.","main_category":"cs.HC","categories":"cs.HC,cs.SY,eess.SP,eess.SY","published":"2025-04-10T15:45:07Z"}
{"aid":"http://arxiv.org/abs/2504.07873v1","title":"Spectral Periodic Differential Operators of Odd Order","summary":"In this paper, we establish a condition on the coefficients of the\ndifferential operators L generated by an ordinary differential expression of\nodd order with periodic, complex-valued coefficients, under which the operator\nL is a spectral operator.","main_category":"math.SP","categories":"math.SP","published":"2025-04-10T15:46:53Z"}
{"aid":"http://arxiv.org/abs/2504.07898v1","title":"How do Large Language Models Understand Relevance? A Mechanistic\n  Interpretability Perspective","summary":"Recent studies have shown that large language models (LLMs) can assess\nrelevance and support information retrieval (IR) tasks such as document ranking\nand relevance judgment generation. However, the internal mechanisms by which\noff-the-shelf LLMs understand and operationalize relevance remain largely\nunexplored. In this paper, we systematically investigate how different LLM\nmodules contribute to relevance judgment through the lens of mechanistic\ninterpretability. Using activation patching techniques, we analyze the roles of\nvarious model components and identify a multi-stage, progressive process in\ngenerating either pointwise or pairwise relevance judgment. Specifically, LLMs\nfirst extract query and document information in the early layers, then process\nrelevance information according to instructions in the middle layers, and\nfinally utilize specific attention heads in the later layers to generate\nrelevance judgments in the required format. Our findings provide insights into\nthe mechanisms underlying relevance assessment in LLMs, offering valuable\nimplications for future research on leveraging LLMs for IR tasks.","main_category":"cs.IR","categories":"cs.IR,cs.CL,cs.LG","published":"2025-04-10T16:14:55Z"}
{"aid":"http://arxiv.org/abs/2504.07915v1","title":"Detecting changes in space-varying parameters of local Poisson point\n  processes","summary":"Recent advances in local models for point processes have highlighted the need\nfor flexible methodologies to account for the spatial heterogeneity of external\ncovariates influencing process intensity. In this work, we introduce\ntessellated spatial regression, a novel framework that extends segmented\nregression models to spatial point processes, with the aim of detecting abrupt\nchanges in the effect of external covariates onto the process intensity.\n  Our approach consists of two main steps. First, we apply a spatial\nsegmentation algorithm to geographically weighted regression estimates,\ngenerating different tessellations that partition the study area into regions\nwhere model parameters can be assumed constant. Next, we fit log-linear Poisson\nmodels in which covariates interact with the tessellations, enabling\nregion-specific parameter estimation and classical inferential procedures, such\nas hypothesis testing on regression coefficients.\n  Unlike geographically weighted regression, our approach allows for discrete\nchanges in regression coefficients, making it possible to capture abrupt\nspatial variations in the effect of real-valued spatial covariates.\nFurthermore, the method naturally addresses the problem of locating and\nquantifying the number of detected spatial changes.\n  We validate our methodology through simulation studies and applications to\ntwo examples where a model with region-wise parameters seems appropriate and to\nan environmental dataset of earthquake occurrences in Greece.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-10T17:23:32Z"}
{"aid":"http://arxiv.org/abs/2504.07927v1","title":"Zero-Shot Low-dose CT Denoising via Sinogram Flicking","summary":"Many low-dose CT imaging methods rely on supervised learning, which requires\na large number of paired noisy and clean images. However, obtaining paired\nimages in clinical practice is challenging. To address this issue, zero-shot\nself-supervised methods train denoising networks using only the information\nwithin a single image, such as ZS-N2N. However, these methods often employ\ndownsampling operations that degrade image resolution. Additionally, the\ntraining dataset is inherently constrained to the image itself. In this paper,\nwe propose a zero-shot low-dose CT imaging method based on sinogram flicking,\nwhich operates within a single image but generates many copies via random\nconjugate ray matching. Specifically, two conjugate X-ray pencil beams measure\nthe same path; their expected values should be identical, while their noise\nlevels vary during measurements. By randomly swapping portions of the conjugate\nX-rays in the sinogram domain, we generate a large set of sinograms with\nconsistent content but varying noise patterns. When displayed dynamically,\nthese sinograms exhibit a flickering effect due to their identical structural\ncontent but differing noise patterns-hence the term sinogram flicking. We train\nthe network on pairs of sinograms with the same content but different noise\ndistributions using a lightweight model adapted from ZS-NSN. This process is\nrepeated to obtain the final results. A simulation study demonstrates that our\nmethod outperforms state-of-the-art approaches such as ZS-N2N.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-10T17:42:01Z"}
{"aid":"http://arxiv.org/abs/2504.07934v1","title":"SoTA with Less: MCTS-Guided Sample Selection for Data-Efficient Visual\n  Reasoning Self-Improvement","summary":"In this paper, we present an effective method to enhance visual reasoning\nwith significantly fewer training samples, relying purely on self-improvement\nwith no knowledge distillation. Our key insight is that the difficulty of\ntraining data during reinforcement fine-tuning (RFT) is critical. Appropriately\nchallenging samples can substantially boost reasoning capabilities even when\nthe dataset is small. Despite being intuitive, the main challenge remains in\naccurately quantifying sample difficulty to enable effective data filtering. To\nthis end, we propose a novel way of repurposing Monte Carlo Tree Search (MCTS)\nto achieve that. Starting from our curated 70k open-source training samples, we\nintroduce an MCTS-based selection method that quantifies sample difficulty\nbased on the number of iterations required by the VLMs to solve each problem.\nThis explicit step-by-step reasoning in MCTS enforces the model to think longer\nand better identifies samples that are genuinely challenging. We filter and\nretain 11k samples to perform RFT on Qwen2.5-VL-7B-Instruct, resulting in our\nfinal model, ThinkLite-VL. Evaluation results on eight benchmarks show that\nThinkLite-VL improves the average performance of Qwen2.5-VL-7B-Instruct by 7%,\nusing only 11k training samples with no knowledge distillation. This\nsignificantly outperforms all existing 7B-level reasoning VLMs, and our fairly\ncomparable baselines that use classic selection methods such as accuracy-based\nfiltering. Notably, on MathVista, ThinkLite-VL-7B achieves the SoTA accuracy of\n75.1, surpassing Qwen2.5-VL-72B, GPT-4o, and O1. Our code, data, and model are\navailable at https://github.com/si0wang/ThinkLite-VL.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:49:05Z"}
{"aid":"http://arxiv.org/abs/2504.07961v1","title":"Geo4D: Leveraging Video Generators for Geometric 4D Scene Reconstruction","summary":"We introduce Geo4D, a method to repurpose video diffusion models for\nmonocular 3D reconstruction of dynamic scenes. By leveraging the strong dynamic\nprior captured by such video models, Geo4D can be trained using only synthetic\ndata while generalizing well to real data in a zero-shot manner. Geo4D predicts\nseveral complementary geometric modalities, namely point, depth, and ray maps.\nIt uses a new multi-modal alignment algorithm to align and fuse these\nmodalities, as well as multiple sliding windows, at inference time, thus\nobtaining robust and accurate 4D reconstruction of long videos. Extensive\nexperiments across multiple benchmarks show that Geo4D significantly surpasses\nstate-of-the-art video depth estimation methods, including recent methods such\nas MonST3R, which are also designed to handle dynamic scenes.","main_category":"cs.CV","categories":"cs.CV,I.4.5","published":"2025-04-10T17:59:55Z"}
{"aid":"http://arxiv.org/abs/2504.07965v1","title":"Cat, Rat, Meow: On the Alignment of Language Model and Human\n  Term-Similarity Judgments","summary":"Small and mid-sized generative language models have gained increasing\nattention. Their size and availability make them amenable to being analyzed at\na behavioral as well as a representational level, allowing investigations of\nhow these levels interact. We evaluate 32 publicly available language models\nfor their representational and behavioral alignment with human similarity\njudgments on a word triplet task. This provides a novel evaluation setting to\nprobe semantic associations in language beyond common pairwise comparisons. We\nfind that (1) even the representations of small language models can achieve\nhuman-level alignment, (2) instruction-tuned model variants can exhibit\nsubstantially increased agreement, (3) the pattern of alignment across layers\nis highly model dependent, and (4) alignment based on models' behavioral\nresponses is highly dependent on model size, matching their representational\nalignment only for the largest evaluated models.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-10T17:59:57Z"}
{"aid":"http://arxiv.org/abs/2504.09925v1","title":"FUSION: Fully Integration of Vision-Language Representations for Deep\n  Cross-Modal Understanding","summary":"We introduce FUSION, a family of multimodal large language models (MLLMs)\nwith a fully vision-language alignment and integration paradigm. Unlike\nexisting methods that primarily rely on late-stage modality interaction during\nLLM decoding, our approach achieves deep, dynamic integration throughout the\nentire processing pipeline. To this end, we propose Text-Guided Unified Vision\nEncoding, incorporating textual information in vision encoding to achieve\npixel-level integration. We further design Context-Aware Recursive Alignment\nDecoding that recursively aggregates visual features conditioned on textual\ncontext during decoding, enabling fine-grained, question-level semantic\nintegration. To guide feature mapping and mitigate modality discrepancies, we\ndevelop Dual-Supervised Semantic Mapping Loss. Additionally, we construct a\nSynthesized Language-Driven Question-Answer (QA) dataset through a new data\nsynthesis method, prioritizing high-quality QA pairs to optimize text-guided\nfeature integration. Building on these foundations, we train FUSION at two\nscales-3B, 8B-and demonstrate that our full-modality integration approach\nsignificantly outperforms existing methods with only 630 vision tokens.\nNotably, FUSION 3B surpasses Cambrian-1 8B and Florence-VL 8B on most\nbenchmarks. FUSION 3B continues to outperform Cambrian-1 8B even when limited\nto 300 vision tokens. Our ablation studies show that FUSION outperforms\nLLaVA-NeXT on over half of the benchmarks under same configuration without\ndynamic resolution, highlighting the effectiveness of our approach. We release\nour code, model weights, and dataset. https://github.com/starriver030515/FUSION","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T06:33:29Z"}
{"aid":"http://arxiv.org/abs/2504.09943v1","title":"The Tropical Atmosphere of Jupiter - Shallow Weather, Deep Plumes, and\n  Vortices","summary":"Towering storms, swirling clouds, and vortices are the cloud tops\nmanifestation of complex weather systems shaping the atmosphere of Jupiter. We\nuse observations from Juno's MicroWave Radiometer (MWR), the Very Large Array\n(VLA) and the Hubble Space Telescope (HST) to probe for the first time the\ndepth and impact of weather on Jupiter. We use ammonia, the main source of\nopacity at radio wavelengths on Jupiter, as the tracer for the weather by\nfitting ammonia anomalies to the MWR brightness temperature variations. We show\nthat the majority of the weather on Jupiter is confined to regions where the\nclouds are forming. Both the South Equatorial Belt and the Equatorial Zone have\nsurprisingly shallow weather systems (P < 2 bar), and even in the North\nEquatorial Belt most of the ammonia variations is above the water condensation\nlevel (P ~ 6 bar). This confirms that the water condensation layer plays a\ncrucial role in controlling the dynamics and the weather on Jupiter. However,\nthe shallow nature of the weather cannot explain the deep-seated depletion down\nto 30 bar that the Juno mission has revealed. We do find three features,\nhowever, that extend below the water condensation layer: a vortex in the\nnorthern hemisphere reaching down to 30 bar, an ammonia plume down to 20-30\nbars, and the signature of precipitation down to 20 bar. This work highlights\nthe interplay of large-scale processes (vortices, plumes) and small-scale\nprocesses (storms) are responsible for shaping the atmospheric makeup of\nJupiter.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-14T07:09:39Z"}
{"aid":"http://arxiv.org/abs/2504.09983v1","title":"DeepCompile: A Compiler-Driven Approach to Optimizing Distributed Deep\n  Learning Training","summary":"The increasing scale of deep learning models has led to the development of\nvarious parallelization strategies for distributed training across\naccelerators. For example, fully sharded approaches like DeepSpeed ZeRO-3 and\nFSDP partition the parameters of each layer across multiple GPUs and gather\nthem through communication when needed. These methods rely on optimizations\nsuch as prefetching, which initiates communication early to overlap it with\ncomputation and reduce communication overhead, and unsharding, which retains as\nmany parameters in their unsharded form as possible to reduce communication\nvolume. Although the timing of prefetching should be adjusted in response to\ndynamic memory usage during execution, these systems lack the flexibility to\ncontrol it, which limits the benefits of prefetching. Moreover, they cannot\nanticipate how memory usage will change after prefetching is applied, making it\ndifficult to combine it effectively with other optimizations such as\nunsharding. We present DeepCompile, which compiles user-defined models into\ncomputation graphs and applies a sequence of profiling-guided optimization\npasses for distributed training. Taking dynamic memory usage into account,\nthese passes flexibly insert, reorder, or remove operations to improve\ncommunication-computation overlap, reduce memory pressure, and coordinate\nmultiple optimizations in a unified manner. To evaluate the effectiveness of\nthis design, we implemented a fully sharded approach like ZeRO-3 and FSDP on\ntop of DeepCompile, along with three optimizations: proactive prefetching,\nselective unsharding, and adaptive offloading. We evaluate DeepCompile on the\ntraining of Llama 3 70B and Mixtral 8x7B MoE models. DeepCompile achieves up to\n1.28x and 1.54x performance improvements over ZeRO-3 and FSDP baselines,\nrespectively, and up to a 7.01x throughput increase with limited GPU resources,\nusing offloading.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-14T08:51:23Z"}
{"aid":"http://arxiv.org/abs/2504.09984v1","title":"On Precomputation and Caching in Information Retrieval Experiments with\n  Pipeline Architectures","summary":"Modern information retrieval systems often rely on multiple components\nexecuted in a pipeline. In a research setting, this can lead to substantial\nredundant computations (e.g., retrieving the same query multiple times for\nevaluating different downstream rerankers). To overcome this, researchers take\ncached \"result\" files as inputs, which represent the output of another\npipeline. However, these result files can be brittle and can cause a disconnect\nbetween the conceptual design of the pipeline and its logical implementation.\nTo overcome both the redundancy problem (when executing complete pipelines) and\nthe disconnect problem (when relying on intermediate result files), we describe\nour recent efforts to improve the caching capabilities in the open-source\nPyTerrier IR platform. We focus on two main directions: (1) automatic implicit\ncaching of common pipeline prefixes when comparing systems and (2) explicit\ncaching of operations through a new extension package, pyterrier-caching. These\napproaches allow for the best of both worlds: pipelines can be fully expressed\nend-to-end, while also avoiding redundant computations between pipelines.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-14T08:51:35Z"}
{"aid":"http://arxiv.org/abs/2504.09986v1","title":"Diversity Analysis for Indoor Terahertz Communication Systems under\n  Small-Scale Fading","summary":"Harnessing diversity is fundamental to wireless communication systems,\nparticularly in the terahertz (THz) band, where severe path loss and\nsmall-scale fading pose significant challenges to system reliability and\nperformance. In this paper, we present a comprehensive diversity analysis for\nindoor THz communication systems, accounting for the combined effects of path\nloss and small-scale fading, with the latter modeled as an $\\alpha-\\mu$\ndistribution to reflect THz indoor channel conditions. We derive closed-form\nexpressions for the bit error rate (BER) as a function of the reciprocal of the\nsignal-to-noise ratio (SNR) and propose an asymptotic expression. Furthermore,\nwe validate these expressions through extensive simulations, which show strong\nagreement with the theoretical analysis, confirming the accuracy and robustness\nof the proposed methods. Our results show that the diversity order in THz\nsystems is primarily determined by the combined effects of the number of\nindependent paths, the severity of fading, and the degree of channel frequency\nselectivity, providing clear insights into how diversity gains can be optimized\nin high-frequency wireless networks.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T08:51:52Z"}
{"aid":"http://arxiv.org/abs/2504.09987v1","title":"Gravitational metamaterials from optical properties of spacetime media","summary":"Gravitational optical properties are here investigated under the hypothesis\nof spherically-symmetric spacetimes behaving as media. To do so, we first\nconsider two different definitions of the refractive index, $n_O$, of a\nspacetime medium and show how to pass from one definition to another by means\nof a coordinate transformation. Accordingly, the corresponding physical role of\n$n_O$ is discussed by virtue of the Misner-Sharp mass and the redshift\ndefinition. Afterwards, we discuss the inclusion of the electromagnetic fields\nand the equivalence with nonlinear effects induced by geometry. Accordingly,\nthe infrared and ultraviolet gravity regimes are thus discussed, obtaining\nbounds from the Solar System, neutron stars and white dwarfs, respectively. To\ndo so, we also investigate the Snell's law and propose how to possibly\ndistinguish regular solutions from black holes. As a consequence of our recipe,\nwe speculate on the existence of \\emph{gravitational metamaterials}, whose\nrefractive index may be negative and explore the corresponding physical\nimplications, remarking that $n_O<0$ may lead to invisible optical properties,\nas light is bent in the opposite direction compared to what occurs in ordinary\ncases. Further, we conjecture that gravitational metamaterials exhibit a\nparticle-like behavior, contributing to dark matter and propose three toy\nmodels, highlighting possible advantages and limitations of their use. Finally,\nwe suggest that such particle-like configurations can be ``dressed\" by\ninteraction, giving rise to \\emph{geometric quasiparticles}. We thus construct\nmodifications of the quantum propagator as due to nonminimal couplings between\ncurvature and external matter-like fields, finding the corresponding effective\nmass through a boson mixing mechanism.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-14T08:51:56Z"}
{"aid":"http://arxiv.org/abs/2504.10012v1","title":"EBAD-Gaussian: Event-driven Bundle Adjusted Deblur Gaussian Splatting","summary":"While 3D Gaussian Splatting (3D-GS) achieves photorealistic novel view\nsynthesis, its performance degrades with motion blur. In scenarios with rapid\nmotion or low-light conditions, existing RGB-based deblurring methods struggle\nto model camera pose and radiance changes during exposure, reducing\nreconstruction accuracy. Event cameras, capturing continuous brightness changes\nduring exposure, can effectively assist in modeling motion blur and improving\nreconstruction quality. Therefore, we propose Event-driven Bundle Adjusted\nDeblur Gaussian Splatting (EBAD-Gaussian), which reconstructs sharp 3D\nGaussians from event streams and severely blurred images. This method jointly\nlearns the parameters of these Gaussians while recovering camera motion\ntrajectories during exposure time. Specifically, we first construct a blur loss\nfunction by synthesizing multiple latent sharp images during the exposure time,\nminimizing the difference between real and synthesized blurred images. Then we\nuse event stream to supervise the light intensity changes between latent sharp\nimages at any time within the exposure period, supplementing the light\nintensity dynamic changes lost in RGB images. Furthermore, we optimize the\nlatent sharp images at intermediate exposure times based on the event-based\ndouble integral (EDI) prior, applying consistency constraints to enhance the\ndetails and texture information of the reconstructed images. Extensive\nexperiments on synthetic and real-world datasets show that EBAD-Gaussian can\nachieve high-quality 3D scene reconstruction under the condition of blurred\nimages and event stream inputs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T09:17:00Z"}
{"aid":"http://arxiv.org/abs/2504.10015v1","title":"Many-Body Colloidal Dynamics under Stochastic Resetting: Competing\n  Effects of Particle Interactions on the Steady State Distribution","summary":"The random arrest of the diffusion of a single particle and its return to its\norigin has served as the paradigmatic example of a large variety of processes\nundergoing stochastic resetting. While the implications and applications of\nstochastic resetting for a single particle are well understood, less is known\nabout resetting of many interacting particles. In this study, we experimentally\nand numerically investigate a system of six colloidal particles undergoing two\ntypes of stochastic resetting protocols: global resetting, where all particles\nare returned to their origin simultaneously, and local resetting, where\nparticles are reset one at a time. Our particles interact mainly through\nhard-core repulsion and hydrodynamic flows. We find that the most substantial\neffect of interparticle interactions is observed for local resetting,\nspecifically when particles are physically dragged to the origin. In this case,\nhard-core repulsion broadens the steady-state distribution, while hydrodynamic\ninteractions significantly narrow the distribution. The combination results in\na steady-state distribution that is wider compared to that of a single particle\nsystem both for global and local resetting protocols.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech","published":"2025-04-14T09:18:37Z"}
{"aid":"http://arxiv.org/abs/2504.10104v1","title":"Automated next-to-leading order QCD and electroweak predictions of\n  photon-photon processes in ultraperipheral collisions","summary":"We present automated next-to-leading order QCD and/or electroweak (EW)\npredictions for photon-photon processes in ultraperipheral high-energy\ncollisions of protons and ions, extending the capabilities of the\n\\textsc{MadGraph5\\_aMC@NLO} framework together in combination with the\n\\ttt{gamma-UPC} code. Key aspects of this extension are discussed. We compute\nQCD and/or EW quantum corrections for several phenomenologically interesting\nprocesses at LHC and FCC-hh energies.","main_category":"hep-ph","categories":"hep-ph,hep-ex,nucl-ex,nucl-th","published":"2025-04-14T11:13:50Z"}
{"aid":"http://arxiv.org/abs/2504.10110v1","title":"Eigengap Sparsity for Covariance Parsimony","summary":"Covariance estimation is a central problem in statistics. An important issue\nis that there are rarely enough samples $n$ to accurately estimate the $p (p+1)\n/ 2$ coefficients in dimension $p$. Parsimonious covariance models are\ntherefore preferred, but the discrete nature of model selection makes inference\ncomputationally challenging. In this paper, we propose a relaxation of\ncovariance parsimony termed \"eigengap sparsity\" and motivated by the good\naccuracy-parsimony tradeoff of eigenvalue-equalization in covariance matrices.\nThis new penalty can be included in a penalized-likelihood framework that we\npropose to solve with a projected gradient descent on a monotone cone. The\nalgorithm turns out to resemble an isotonic regression of mutually-attracted\nsample eigenvalues, drawing an interesting link between covariance parsimony\nand shrinkage.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-14T11:18:02Z"}
{"aid":"http://arxiv.org/abs/2504.10118v1","title":"Stochastic Multigrid Minimization for Ptychographic Phase Retrieval","summary":"We propose a novel stochastic multigrid minimization method for ptychographic\nphase retrieval. In our formulation, the challenging nonconvex and ill-posed\ninverse problem is recast as the iterative minimization of a quadratic\nsurrogate model that majorizes the original objective function. Our general\nframework encompasses the Ptychographic Iterative Engine (PIE) family of\nalgorithms. By efficiently solving the surrogate problem using a multigrid\nmethod, our approach delivers significant improvements in both convergence\nspeed and reconstruction quality compared with conventional PIE techniques.","main_category":"math.NA","categories":"math.NA,cs.NA,math.OC","published":"2025-04-14T11:28:20Z"}
{"aid":"http://arxiv.org/abs/2504.10166v1","title":"Fact-Checking with Contextual Narratives: Leveraging Retrieval-Augmented\n  LLMs for Social Media Analysis","summary":"We propose CRAVE (Cluster-based Retrieval Augmented Verification with\nExplanation); a novel framework that integrates retrieval-augmented Large\nLanguage Models (LLMs) with clustering techniques to address fact-checking\nchallenges on social media. CRAVE automatically retrieves multimodal evidence\nfrom diverse, often contradictory, sources. Evidence is clustered into coherent\nnarratives, and evaluated via an LLM-based judge to deliver fact-checking\nverdicts explained by evidence summaries. By synthesizing evidence from both\ntext and image modalities and incorporating agent-based refinement, CRAVE\nensures consistency and diversity in evidence representation. Comprehensive\nexperiments demonstrate CRAVE's efficacy in retrieval precision, clustering\nquality, and judgment accuracy, showcasing its potential as a robust\ndecision-support tool for fact-checkers.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-14T12:21:27Z"}
{"aid":"http://arxiv.org/abs/2504.10178v1","title":"MSCoT: Structured Chain-of-Thought Generation for Multiple Programming\n  Languages","summary":"With the rapid development of code intelligence, the application of multiple\nprogramming languages is becoming increasingly widespread. However, most\nexisting code generation models mainly focus on a single or a few programming\nlanguages, resulting in unsatisfactory performance in a multilingual\nenvironment. Chain-of-Thought (CoT) reasoning can significantly improve the\nperformance of the model without the need for retraining or fine-tuning the\ncode generation model by reasonably decomposing complex code generation tasks\ninto multiple subtasks and gradually deriving solutions for each subtask.\nNevertheless, the existing CoT generation methods mainly concentrate on Python\ncode, and the performance on other programming languages remains unclear. To\nfill this gap, we first constructed a CoT generation dataset for 12 programming\nlanguages through multi-agent technology. On this basis, we proposed a CoT\ngeneration method MSCoT applicable to multiple programming languages. By\nintroducing CoT into the code generation large model, the performance of the\ncode generation large model in a multilingual environment can be improved.\nThrough large-scale empirical research, we compared the generalization\nabilities of MSCoT and the existing CoT generation methods on multiple\nprogramming languages and proved the effectiveness of MSCoT for multiple\nprogramming languages. In addition, we also designed a human study to prove the\nquality of the CoT generated by MSCoT. Finally, we opensourced the model and\ndataset of MSCoT to promote the research on CoT generation for multiple\nprogramming languages.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-14T12:30:47Z"}
{"aid":"http://arxiv.org/abs/2504.10195v1","title":"Simulation of TOPCon/PERC Hybrid Bottom Structure for Perovskite/Silicon\n  Tandem Solar Cells using Quokka3","summary":"This work emphasizes the potential of perovskite/silicon tandem solar cells\nfor increased power conversion efficiencies. By employing crystalline silicon\n(c-Si) as the bottom cell, particularly with p-type PERC technology, there are\ncost-effective and advantageous physical properties. However, traditional\nphosphorus-doped emitters in PERC Si bottom cells are hindered by high surface\nrecombination, which limits their performance. This research introduces a novel\nhybrid PERC/TOPCon structure that integrates a phosphorus-doped poly-Si (n+\nTOPCon) layer as the front emitter to address these challenges. Numerical\nsimulations using Quokka3 confirmed the feasibility of the design, focusing on\noptimizing the rear side metallization to enhance implied open-circuit voltage\n(Voc) and fill factor (FF). A two-step process systematically varied local\ncontact openings to examine their impact on performance metrics. Results\nhighlighted optimal rear metallization parameters, achieving optimal metal\nfractions approximately 2%. This innovative approach demonstrates the\neffectiveness of combining TOPCon and PERC technologies for bottom cells in\ntandem structures, providing valuable insights into their development and\noptimization. The study underscores the potential of the hybrid PERC/TOPCon\nstructure in enhancing the functionality and efficiency of perovskite/silicon\ntandem solar cells.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-14T12:56:45Z"}
{"aid":"http://arxiv.org/abs/2504.10204v1","title":"Cohomological obstructions to equivariant unirationality","summary":"We study cohomological obstructions to equivariant unirationality, with\nspecial regard to actions of finite groups on del Pezzo surfaces and Fano\nthreefolds.","main_category":"math.AG","categories":"math.AG","published":"2025-04-14T13:12:54Z"}
{"aid":"http://arxiv.org/abs/2504.10235v1","title":"Eccentric mergers of binary Proca stars","summary":"We present a numerical relativity study of eccentric mergers of equal-mass\nrotating $\\bar m=1$ Proca stars, focusing on their gravitational-wave (GW)\nemission. By systematically varying key binary parameters, such as the initial\norbital boost, which determines the orbital angular momentum, and the relative\nphase between the stars, we examine how the internal phase structure of the\nProca field influences the merger dynamics and the properties of the emitted\nGWs. Our simulations demonstrate that the relative phase has paramount impact\non the post-merger evolution, resulting in prompt black hole formation\naccompanied by a transient Proca remnant, the formation of a hypermassive $\\bar\nm=1$ Proca star or even the emergence of a dynamically-unstable spinning $\\bar\nm=2$ Proca star. Under certain conditions, the GW signal exhibits significant\nodd-modes (e.g., the $\\ell=m=3$ mode) that are absent in conventional black\nhole mergers, potentially serving as unique signatures of these exotic objects.\nOur findings offer new insights into the phenomenology of bosonic star mergers\nand the potential astrophysical role of ultralight bosonic fields.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-14T13:59:33Z"}
{"aid":"http://arxiv.org/abs/2504.10253v1","title":"TinyverseGP: Towards a Modular Cross-domain Benchmarking Framework for\n  Genetic Programming","summary":"Over the years, genetic programming (GP) has evolved, with many proposed\nvariations, especially in how they represent a solution. Being essentially a\nprogram synthesis algorithm, it is capable of tackling multiple problem\ndomains. Current benchmarking initiatives are fragmented, as the different\nrepresentations are not compared with each other and their performance is not\nmeasured across the different domains. In this work, we propose a unified\nframework, dubbed TinyverseGP (inspired by tinyGP), which provides support to\nmultiple representations and problem domains, including symbolic regression,\nlogic synthesis and policy search.","main_category":"cs.NE","categories":"cs.NE,cs.LG,cs.SC","published":"2025-04-14T14:14:27Z"}
{"aid":"http://arxiv.org/abs/2504.10260v1","title":"Periodic approximation of topological Lyapunov exponents and the joint\n  spectral radius for cocycles of mapping classes of surfaces","summary":"We study cocycles taking values in the mapping class group of closed surfaces\nand investigate their leading topological Lyapunov exponent. Under a natural\nclosing property, we show that the top topological Lyapunov exponent can be\napproximated by periodic orbits. We also extend the notion of the joint\nspectral radius to this setting, interpreting it via the exponential growth of\ncurves under iterated mapping classes. Our approach connects ideas from ergodic\ntheory, Teichm\\\"uller geometry, and spectral theory, and suggests a broader\nframework for similar results.","main_category":"math.DS","categories":"math.DS,math.GR,math.GT","published":"2025-04-14T14:22:46Z"}
{"aid":"http://arxiv.org/abs/2504.10277v1","title":"RealHarm: A Collection of Real-World Language Model Application Failures","summary":"Language model deployments in consumer-facing applications introduce numerous\nrisks. While existing research on harms and hazards of such applications\nfollows top-down approaches derived from regulatory frameworks and theoretical\nanalyses, empirical evidence of real-world failure modes remains underexplored.\nIn this work, we introduce RealHarm, a dataset of annotated problematic\ninteractions with AI agents built from a systematic review of publicly reported\nincidents. Analyzing harms, causes, and hazards specifically from the\ndeployer's perspective, we find that reputational damage constitutes the\npredominant organizational harm, while misinformation emerges as the most\ncommon hazard category. We empirically evaluate state-of-the-art guardrails and\ncontent moderation systems to probe whether such systems would have prevented\nthe incidents, revealing a significant gap in the protection of AI\napplications.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.CL,cs.CR","published":"2025-04-14T14:44:41Z"}
{"aid":"http://arxiv.org/abs/2504.10279v1","title":"Elastic Planetoids","summary":"Modeling the internal structure of self-gravitating solid and liquid bodies\npresents a challenge, as existing approaches are often limited to either overly\nsimplistic constant-density approximations or more complex numerical equations\nof state. We present a detailed analysis of a tractable and physically\nmotivated model for perfectly elastic, spherically symmetric self-gravitating\nbodies in hydrostatic equilibrium. The model employs a logarithmic equation of\nstate (logotropic EOS) with a non-zero initial density and constant bulk\nmodulus. Importantly, scaling properties of the model allow all solutions to be\nderived from a single, universal solution of an ordinary differential equation,\nresembling the Lane-Emden and Chandrasekhar models. The model provides new\ninsights into stability issues and reveals oscillatory asymptotic behavior in\nthe mass-radius relation, including the existence of both a maximum mass and a\nmaximum radius. We derive useful, simple analytical approximations for key\nproperties, such as central overdensity, moment of inertia, binding energy, and\ngravitational potential, applicable to small, metallic bodies like asteroids\nand moons. These new approximations could aid future research, including space\nmining and the scientific characterization of small Solar System bodies.","main_category":"astro-ph.EP","categories":"astro-ph.EP,cond-mat.mtrl-sci,physics.space-ph","published":"2025-04-14T14:45:38Z"}
{"aid":"http://arxiv.org/abs/2504.10294v1","title":"Ankle Exoskeletons in Walking and Load-Carrying Tasks: Insights into\n  Biomechanics and Human-Robot Interaction","summary":"Background: Lower limb exoskeletons can enhance quality of life, but\nwidespread adoption is limited by the lack of frameworks to assess their\nbiomechanical and human-robot interaction effects, which are essential for\ndeveloping adaptive and personalized control strategies. Understanding impacts\non kinematics, muscle activity, and HRI dynamics is key to achieve improved\nusability of wearable robots. Objectives: We propose a systematic methodology\nevaluate an ankle exoskeleton's effects on human movement during walking and\nload-carrying (10 kg front pack), focusing on joint kinematics, muscle\nactivity, and HRI torque signals. Materials and Methods: Using Xsens MVN\n(inertial motion capture), Delsys EMG, and a unilateral exoskeleton, three\nexperiments were conducted: (1) isolated dorsiflexion/plantarflexion; (2) gait\nanalysis (two subjects, passive/active modes); and (3) load-carrying under\nassistance. Results and Conclusions: The first experiment confirmed that the\nHRI sensor captured both voluntary and involuntary torques, providing\ndirectional torque insights. The second experiment showed that the device\nslightly restricted ankle range of motion (RoM) but supported normal gait\npatterns across all assistance modes. The exoskeleton reduced muscle activity,\nparticularly in active mode. HRI torque varied according to gait phases and\nhighlighted reduced synchronization, suggesting a need for improved support.\nThe third experiment revealed that load-carrying increased GM and TA muscle\nactivity, but the device partially mitigated user effort by reducing muscle\nactivity compared to unassisted walking. HRI increased during load-carrying,\nproviding insights into user-device dynamics. These results demonstrate the\nimportance of tailoring exoskeleton evaluation methods to specific devices and\nusers, while offering a framework for future studies on exoskeleton\nbiomechanics and HRI.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T15:05:02Z"}
{"aid":"http://arxiv.org/abs/2504.10296v1","title":"Siamese Network with Dual Attention for EEG-Driven Social Learning:\n  Bridging the Human-Robot Gap in Long-Tail Autonomous Driving","summary":"Robots with wheeled, quadrupedal, or humanoid forms are increasingly\nintegrated into built environments. However, unlike human social learning, they\nlack a critical pathway for intrinsic cognitive development, namely, learning\nfrom human feedback during interaction. To understand human ubiquitous\nobservation, supervision, and shared control in dynamic and uncertain\nenvironments, this study presents a brain-computer interface (BCI) framework\nthat enables classification of Electroencephalogram (EEG) signals to detect\ncognitively demanding and safety-critical events. As a timely and motivating\nco-robotic engineering application, we simulate a human-in-the-loop scenario to\nflag risky events in semi-autonomous robotic driving-representative of\nlong-tail cases that pose persistent bottlenecks to the safety performance of\nsmart mobility systems and robotic vehicles. Drawing on recent advances in\nfew-shot learning, we propose a dual-attention Siamese convolutional network\npaired with Dynamic Time Warping Barycenter Averaging approach to generate\nrobust EEG-encoded signal representations. Inverse source localization reveals\nactivation in Broadman areas 4 and 9, indicating perception-action coupling\nduring task-relevant mental imagery. The model achieves 80% classification\naccuracy under data-scarce conditions and exhibits a nearly 100% increase in\nthe utility of salient features compared to state-of-the-art methods, as\nmeasured through integrated gradient attribution. Beyond performance, this\nstudy contributes to our understanding of the cognitive architecture required\nfor BCI agents-particularly the role of attention and memory mechanisms-in\ncategorizing diverse mental states and supporting both inter- and intra-subject\nadaptation. Overall, this research advances the development of cognitive\nrobotics and socially guided learning for service robots in complex built\nenvironments.","main_category":"cs.RO","categories":"cs.RO,cs.HC,cs.LG","published":"2025-04-14T15:06:17Z"}
{"aid":"http://arxiv.org/abs/2504.10325v1","title":"Cumulative-Time Signal Temporal Logic","summary":"Signal Temporal Logic (STL) is a widely adopted specification language in\ncyber-physical systems for expressing critical temporal requirements, such as\nsafety conditions and response time. However, STL's expressivity is not\nsufficient to capture the cumulative duration during which a property holds\nwithin an interval of time. To overcome this limitation, we introduce\nCumulative-Time Signal Temporal Logic (CT-STL) that operates over discrete-time\nsignals and extends STL with a new cumulative-time operator. This operator\ncompares the sum of all time steps for which its nested formula is true with a\nthreshold. We present both a qualitative and a quantitative (robustness)\nsemantics for CT-STL and prove both their soundness and completeness\nproperties. We provide an efficient online monitoring algorithm for both\nsemantics. Finally, we show the applicability of CT-STL in two case studies:\nspecifying and monitoring cumulative temporal requirements for a microgrid and\nan artificial pancreas.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-14T15:34:13Z"}
{"aid":"http://arxiv.org/abs/2504.10340v1","title":"Forecasting from Clinical Textual Time Series: Adaptations of the\n  Encoder and Decoder Language Model Families","summary":"Clinical case reports encode rich, temporal patient trajectories that are\noften underexploited by traditional machine learning methods relying on\nstructured data. In this work, we introduce the forecasting problem from\ntextual time series, where timestamped clinical findings--extracted via an\nLLM-assisted annotation pipeline--serve as the primary input for prediction. We\nsystematically evaluate a diverse suite of models, including fine-tuned\ndecoder-based large language models and encoder-based transformers, on tasks of\nevent occurrence prediction, temporal ordering, and survival analysis. Our\nexperiments reveal that encoder-based models consistently achieve higher F1\nscores and superior temporal concordance for short- and long-horizon event\nforecasting, while fine-tuned masking approaches enhance ranking performance.\nIn contrast, instruction-tuned decoder models demonstrate a relative advantage\nin survival analysis, especially in early prognosis settings. Our sensitivity\nanalyses further demonstrate the importance of time ordering, which requires\nclinical time series construction, as compared to text ordering, the format of\nthe text inputs that LLMs are classically trained on. This highlights the\nadditional benefit that can be ascertained from time-ordered corpora, with\nimplications for temporal tasks in the era of widespread LLM use.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T15:48:56Z"}
{"aid":"http://arxiv.org/abs/2504.10350v1","title":"Benchmarking 3D Human Pose Estimation Models Under Occlusions","summary":"This paper addresses critical challenges in 3D Human Pose Estimation (HPE) by\nanalyzing the robustness and sensitivity of existing models to occlusions,\ncamera position, and action variability. Using a novel synthetic dataset,\nBlendMimic3D, which includes diverse scenarios with multi-camera setups and\nseveral occlusion types, we conduct specific tests on several state-of-the-art\nmodels. Our study focuses on the discrepancy in keypoint formats between common\ndatasets such as Human3.6M, and 2D datasets such as COCO, commonly used for 2D\ndetection models and frequently input of 3D HPE models. Our work explores the\nimpact of occlusions on model performance and the generality of models trained\nexclusively under standard conditions. The findings suggest significant\nsensitivity to occlusions and camera settings, revealing a need for models that\nbetter adapt to real-world variability and occlusion scenarios. This research\ncontributed to ongoing efforts to improve the fidelity and applicability of 3D\nHPE systems in complex environments.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:00:25Z"}
{"aid":"http://arxiv.org/abs/2504.10354v1","title":"The diagonal and Hadamard grade of hypergeometric functions","summary":"Diagonals of rational functions are an important class of functions arising\nin number theory, algebraic geometry, combinatorics, and physics. In this paper\nwe study the diagonal grade of a function $f$, which is defined to be the\nsmallest $n$ such that $f$ is the diagonal of a rational function in variables\n$x_0,\\dots, x_n$. We relate the diagonal grade of a function to the nilpotence\nof the associated differential equation. This allows us to determine the\ndiagonal grade of many hypergeometric functions and answer affirmatively the\noutstanding question on the existence of functions with diagonal grade greater\nthan $2$. In particular, we show that\n$\\prescript{}{n}F_{n-1}(\\frac{1}{2},\\dots, \\frac{1}{2};1\\dots,1 \\mid x)$ has\ndiagonal grade $n$ for each $n\\geq 1$. Our method also applies to the\ngenerating function of the Ap\\'ery sequence, which we find to have diagonal\ngrade $3$. We also answer related questions on Hadamard grades posed by\nAllouche and Mend\\`es France. For example, we show that\n$\\prescript{}{n}F_{n-1}(\\frac{1}{2},\\dots, \\frac{1}{2};1\\dots,1 \\mid x)$ has\nHadamard grade $n$ for all $n\\geq 1$.","main_category":"math.CO","categories":"math.CO,math-ph,math.AG,math.MP,math.NT","published":"2025-04-14T16:03:32Z"}
{"aid":"http://arxiv.org/abs/2504.10358v1","title":"FingER: Content Aware Fine-grained Evaluation with Reasoning for\n  AI-Generated Videos","summary":"Recent advances in video generation have posed great challenges in the\nassessment of AI-generated content, particularly with the emergence of\nincreasingly sophisticated models. The various inconsistencies and defects\nobserved in such videos are inherently complex, making overall scoring\nnotoriously difficult. In this paper, we emphasize the critical importance of\nintegrating fine-grained reasoning into video evaluation, and we propose\n$\\textbf{F}$ing$\\textbf{ER}$, a novel entity-level reasoning evaluation\nframework that first automatically generates $\\textbf{F}$ine-grained\n$\\textbf{E}$ntity-level questions, and then answers those questions by a\n$\\textbf{R}$easoning model with scores, which can be subsequently weighted\nsummed to an overall score for different applications. Specifically, we\nleverage LLMs to derive entity-level questions across five distinct\nperspectives, which (i) often focus on some specific entities of the content,\nthereby making answering or scoring much easier by MLLMs, and (ii) are more\ninterpretable. Then we construct a FingER dataset, consisting of approximately\n3.3k videos and corresponding 60k fine-grained QA annotations, each with\ndetailed reasons. Based on that, we further investigate various training\nprotocols to best incentivize the reasoning capability of MLLMs for correct\nanswer prediction. Extensive experiments demonstrate that a reasoning model\ntrained using Group Relative Policy Optimization (GRPO) with a cold-start\nstrategy achieves the best performance. Notably, our model surpasses existing\nmethods by a relative margin of $11.8\\%$ on GenAI-Bench and $5.5\\%$ on\nMonetBench with only 3.3k training videos, which is at most one-tenth of the\ntraining samples utilized by other methods. Our code and dataset will be\nreleased soon.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-14T16:07:16Z"}
{"aid":"http://arxiv.org/abs/2504.10364v1","title":"Widely FSR tunable high Q-factor microresonators formed at the\n  intersection of straight optical fibers","summary":"We present a new class of high-Q tunable microresonators formed at the\nintersection of two straight silica optical fibers, whose free spectral range\n(FSR) can be widely tuned by fiber rotation. The proposed configuration avoids\nthe limitations of traditional monolithic microresonators that lack FSR\ntunability required for a wide range of photonic applications. Using small\nrotation angles (1-15 mrad), we demonstrate a tunability of the FSR from 2 pm\nto 10 pm, enabled by microscale fiber displacements that reshape the resonator\nprofile over millimeter scales. The proposed approach minimizes mechanical\nstress, supports miniaturization, and is suitable for integration with MEMS. It\npaves the way for the fabrication of tunable delay lines, ultralow repetition\nrate broadband frequency comb generators, and nonlocal optofluidic sensors on a\nchip.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-14T16:10:08Z"}
{"aid":"http://arxiv.org/abs/2504.10375v1","title":"PG-DPIR: An efficient plug-and-play method for high-count\n  Poisson-Gaussian inverse problems","summary":"Poisson-Gaussian noise describes the noise of various imaging systems thus\nthe need of efficient algorithms for Poisson-Gaussian image restoration. Deep\nlearning methods offer state-of-the-art performance but often require\nsensor-specific training when used in a supervised setting. A promising\nalternative is given by plug-and-play (PnP) methods, which consist in learning\nonly a regularization through a denoiser, allowing to restore images from\nseveral sources with the same network. This paper introduces PG-DPIR, an\nefficient PnP method for high-count Poisson-Gaussian inverse problems, adapted\nfrom DPIR. While DPIR is designed for white Gaussian noise, a naive adaptation\nto Poisson-Gaussian noise leads to prohibitively slow algorithms due to the\nabsence of a closed-form proximal operator. To address this, we adapt DPIR for\nthe specificities of Poisson-Gaussian noise and propose in particular an\nefficient initialization of the gradient descent required for the proximal step\nthat accelerates convergence by several orders of magnitude. Experiments are\nconducted on satellite image restoration and super-resolution problems.\nHigh-resolution realistic Pleiades images are simulated for the experiments,\nwhich demonstrate that PG-DPIR achieves state-of-the-art performance with\nimproved efficiency, which seems promising for on-ground satellite processing\nchains.","main_category":"cs.CV","categories":"cs.CV,cs.LG,eess.IV","published":"2025-04-14T16:23:15Z"}
{"aid":"http://arxiv.org/abs/2504.10378v1","title":"Cosmogenic Neutrino Point Source and KM3-230213A","summary":"Cosmogenic neutrinos (CNs) are produced by ultra-high energy cosmic rays\n(UHECRs) interacting with cosmic background radiation. We investigated the\nproperties of CN point/extended sources, i.e, the neutrino spectrum, and\nangular profile as functions of time, by assuming that UHECR sources are\ntransient events, such as gamma-ray bursts. The properties depend much on the\nintergalactic magnetic field (IGMF), but the angular extent is in general\nsub-degree, within which the CN flux can overshoot the diffuse CN flux in early\ntime. The nearby CN point sources could be detected for the low IGMF case by\nfuture neutrino telescopes. The recent KM3-230213A event is possible to account\nfor by a nearby transient CN source, rather than diffuse CN emission.\nObservations of CN point sources will provide a chance to search for UHECR\nsources.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-14T16:24:52Z"}
{"aid":"http://arxiv.org/abs/2504.10390v1","title":"Teacher Motion Priors: Enhancing Robot Locomotion over Challenging\n  Terrain","summary":"Achieving robust locomotion on complex terrains remains a challenge due to\nhigh dimensional control and environmental uncertainties. This paper introduces\na teacher prior framework based on the teacher student paradigm, integrating\nimitation and auxiliary task learning to improve learning efficiency and\ngeneralization. Unlike traditional paradigms that strongly rely on\nencoder-based state embeddings, our framework decouples the network design,\nsimplifying the policy network and deployment. A high performance teacher\npolicy is first trained using privileged information to acquire generalizable\nmotion skills. The teacher's motion distribution is transferred to the student\npolicy, which relies only on noisy proprioceptive data, via a generative\nadversarial mechanism to mitigate performance degradation caused by\ndistributional shifts. Additionally, auxiliary task learning enhances the\nstudent policy's feature representation, speeding up convergence and improving\nadaptability to varying terrains. The framework is validated on a humanoid\nrobot, showing a great improvement in locomotion stability on dynamic terrains\nand significant reductions in development costs. This work provides a practical\nsolution for deploying robust locomotion strategies in humanoid robots.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-14T16:36:56Z"}
{"aid":"http://arxiv.org/abs/2504.10394v1","title":"Digits of pi: limits to the seeming randomness II","summary":"According to a popular belief, the decimal digits of mathematical constants\nsuch as {\\pi} behave like statistically independent random variables, each\ntaking the values 0, 1, 2, 3, 4, 5, 6, 7, 8, and 9 with equal probability of\n1/10. If this is the case, then, in particular, the decimal representations of\nthese constants should tend to satisfy the central limit theorem (CLT) and the\nlaw of the iterated logarithm (LIL). The paper presents the results of a direct\nstatistical analysis of the decimal representations of 12 mathematical\nconstants with respect to the central limit theorem (CLT) and the law of the\niterated logarithm (LIL). The first billion digits of each constant were\nanalyzed, with ten billion digits examined in the case of {\\pi}. Within these\nlimits, no evidence was found to suggest that the digits of these constants\nsatisfy CLT or LIL.","main_category":"math.NT","categories":"math.NT","published":"2025-04-14T16:42:47Z"}
{"aid":"http://arxiv.org/abs/2504.10395v1","title":"Better Coherence, Better Height: Fusing Physical Models and Deep\n  Learning for Forest Height Estimation from Interferometric SAR Data","summary":"Estimating forest height from Synthetic Aperture Radar (SAR) images often\nrelies on traditional physical models, which, while interpretable and\ndata-efficient, can struggle with generalization. In contrast, Deep Learning\n(DL) approaches lack physical insight. To address this, we propose CoHNet - an\nend-to-end framework that combines the best of both worlds: DL optimized with\nphysics-informed constraints. We leverage a pre-trained neural surrogate model\nto enforce physical plausibility through a unique training loss. Our\nexperiments show that this approach not only improves forest height estimation\naccuracy but also produces meaningful features that enhance the reliability of\npredictions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:44:08Z"}
{"aid":"http://arxiv.org/abs/2504.10402v1","title":"Can spacetime torsion source an extremely red-tilted cosmological GW\n  background?","summary":"In the presence of spacetime torsion, any generic $f(R)$ model of gravity is\nconformally dual to a scalar-tensor theory augmented with a second rank\nantisymmetric massless degree of freedom. We investigate the stochastic\ngravitational wave background (SGWB) that may be sourced directly at the second\norder by such a torsional field, treated perturbatively during an epoch of\ncanonical, single-field, slow-roll inflation. The resulting second-order\ninduced SGWB, which dominates over the primary inflationary GW background at\nall scales, peaks only at ultra-low frequencies, and is found to be extremely\nred-tilted with an effective tensor spectral index $\\alpha_{\\rm T}\\sim-6$ on\nmatter-dominated scales. The signal is potentially within the reach of upcoming\nindirect GW probes on very large scales $k\\lesssim10^{-2}\\:\\textrm{Mpc}^{-1}$,\ni.e., next-generation CMB experiments like the LiteBIRD. In the near future,\nobservation of such a markedly red-tilted SGWB on CMB scales could hence\nprovide a novel and unique clue in favour of torsional gravity during the\ninflationary era.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-14T16:52:22Z"}
{"aid":"http://arxiv.org/abs/2504.10403v1","title":"Satellite Federated Fine-Tuning for Foundation Models in Space Computing\n  Power Networks","summary":"Advancements in artificial intelligence (AI) and low-earth orbit (LEO)\nsatellites have promoted the application of large remote sensing foundation\nmodels for various downstream tasks. However, direct downloading of these\nmodels for fine-tuning on the ground is impeded by privacy concerns and limited\nbandwidth. Satellite federated learning (FL) offers a solution by enabling\nmodel fine-tuning directly on-board satellites and aggregating model updates\nwithout data downloading. Nevertheless, for large foundation models, the\ncomputational capacity of satellites is insufficient to support effective\non-board fine-tuning in traditional satellite FL frameworks. To address these\nchallenges, we propose a satellite-ground collaborative federated fine-tuning\nframework. The key of the framework lies in how to reasonably decompose and\nallocate model components to alleviate insufficient on-board computation\ncapabilities. During fine-tuning, satellites exchange intermediate results with\nground stations or other satellites for forward propagation and back\npropagation, which brings communication challenges due to the special\ncommunication topology of space transmission networks, such as intermittent\nsatellite-ground communication, short duration of satellite-ground\ncommunication windows, and unstable inter-orbit inter-satellite links (ISLs).\nTo reduce transmission delays, we further introduce tailored communication\nstrategies that integrate both communication and computing resources.\nSpecifically, we propose a parallel intra-orbit communication strategy, a\ntopology-aware satellite-ground communication strategy, and a\nlatency-minimalization inter-orbit communication strategy to reduce space\ncommunication costs. Simulation results demonstrate significant reductions in\ntraining time with improvements of approximately 33%.","main_category":"cs.LG","categories":"cs.LG,cs.DC,cs.NI","published":"2025-04-14T16:52:34Z"}
{"aid":"http://arxiv.org/abs/2504.10404v1","title":"Framing Perception: Exploring Camera Induced Objectification in Cinema","summary":"This study investigates how cinematographic techniques influence viewer\nperception and contribute to the objectification of women, utilizing\neye-tracking data from 91 participants. They watched a sexualized music video\n(SV) known for objectifying portrayals and a non-sexualized music video (TV).\nUsing dynamic Areas of Interests (AOIs) (head, torso, and lower body), gaze\nmetrics such as fixation duration, visit count, and scan paths were recorded to\nassess visual attention patterns. Participants were grouped according to their\naverage fixations on sexualized AOIs. Statistical analyses revealed significant\ndifferences in gaze behavior between the videos and among the groups, with\nincreased attention to sexualized AOIs in SV. Additionally, data-driven group\ndifferences in fixations identified specific segments with heightened\nobjectification that are further analyzed using scan path visualization\ntechniques. These findings provide strong empirical evidence of camera-driven\ngaze objectification, demonstrating how cinematic framing implicitly shapes\nobjectifying gaze patterns, highlighting the critical need for mindful media\nrepresentation.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T16:53:16Z"}
{"aid":"http://arxiv.org/abs/2504.10414v1","title":"HUMOTO: A 4D Dataset of Mocap Human Object Interactions","summary":"We present Human Motions with Objects (HUMOTO), a high-fidelity dataset of\nhuman-object interactions for motion generation, computer vision, and robotics\napplications. Featuring 736 sequences (7,875 seconds at 30 fps), HUMOTO\ncaptures interactions with 63 precisely modeled objects and 72 articulated\nparts. Our innovations include a scene-driven LLM scripting pipeline creating\ncomplete, purposeful tasks with natural progression, and a mocap-and-camera\nrecording setup to effectively handle occlusions. Spanning diverse activities\nfrom cooking to outdoor picnics, HUMOTO preserves both physical accuracy and\nlogical task flow. Professional artists rigorously clean and verify each\nsequence, minimizing foot sliding and object penetrations. We also provide\nbenchmarks compared to other datasets. HUMOTO's comprehensive full-body motion\nand simultaneous multi-object interactions address key data-capturing\nchallenges and provide opportunities to advance realistic human-object\ninteraction modeling across research domains with practical applications in\nanimation, robotics, and embodied AI systems. Project:\nhttps://jiaxin-lu.github.io/humoto/ .","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:59:29Z"}
{"aid":"http://arxiv.org/abs/2504.10429v1","title":"Out of the box approach to Black hole Information paradox","summary":"Suppose a black hole forms from a pure quantum state $\\ket{\\psi}$. The black\nhole information loss paradox arises from semiclassical arguments suggesting\nthat, even in a closed system, the process of black hole formation and\nevaporation evolves a pure state into a mixed state. Resolution to the paradox\ntypically demands violation of quantum mechanics or relativity in domains where\nthey should hold. Instead, I propose that in a complete theory of quantum\ngravity, any region $\\mathcal{U}$ that could collapse into a black hole should\nalready be described by a mixed state, thus bypassing the paradox entirely. To\nthat end, I present a model in which the universe is in a quantum\nerror-corrected state, such that any local black hole appears mixed and encodes\nno information locally.","main_category":"gr-qc","categories":"gr-qc,hep-th,quant-ph","published":"2025-04-14T17:19:57Z"}
{"aid":"http://arxiv.org/abs/2504.10433v1","title":"MonoDiff9D: Monocular Category-Level 9D Object Pose Estimation via\n  Diffusion Model","summary":"Object pose estimation is a core means for robots to understand and interact\nwith their environment. For this task, monocular category-level methods are\nattractive as they require only a single RGB camera. However, current methods\nrely on shape priors or CAD models of the intra-class known objects. We propose\na diffusion-based monocular category-level 9D object pose generation method,\nMonoDiff9D. Our motivation is to leverage the probabilistic nature of diffusion\nmodels to alleviate the need for shape priors, CAD models, or depth sensors for\nintra-class unknown object pose estimation. We first estimate coarse depth via\nDINOv2 from the monocular image in a zero-shot manner and convert it into a\npoint cloud. We then fuse the global features of the point cloud with the input\nimage and use the fused features along with the encoded time step to condition\nMonoDiff9D. Finally, we design a transformer-based denoiser to recover the\nobject pose from Gaussian noise. Extensive experiments on two popular benchmark\ndatasets show that MonoDiff9D achieves state-of-the-art monocular\ncategory-level 9D object pose estimation accuracy without the need for shape\npriors or CAD models at any stage. Our code will be made public at\nhttps://github.com/CNJianLiu/MonoDiff9D.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-14T17:21:10Z"}
{"aid":"http://arxiv.org/abs/2504.10457v1","title":"Holographic Entanglement Entropy in the FLRW Universe","summary":"We compute a holographic entanglement entropy via Ryu--Takayanagi\nprescription in the three-dimensional Friedmann--Lema\\^itre--Robertson--Walker\nuniverse. We consider two types of holographic scenarios analogous to the\nstatic patch holography and the half de Sitter holography, in which the\nholographic boundary is timelike and placed in the bulk. We find in general\nthat the strong subadditivity can be satisfied only in the former type and in\naddition the holographic boundary has to fit inside the apparent horizon. Also,\nfor the universe filled with an ideal fluid of constant equation of state\n$w<-1$, the condition is sharpened as that the holographic boundary has to fit\ninside the event horizon instead. These conditions provide a necessary\ncondition for the dual quantum field theory to be standard and compatible with\nthe strong subadditivity.","main_category":"hep-th","categories":"hep-th,astro-ph.CO,gr-qc","published":"2025-04-14T17:44:34Z"}
{"aid":"http://arxiv.org/abs/2504.10461v1","title":"Layered Multirate Control of Constrained Linear Systems","summary":"Layered control architectures have been a standard paradigm for efficiently\nmanaging complex constrained systems. A typical architecture consists of: i) a\nhigher layer, where a low-frequency planner controls a simple model of the\nsystem, and ii) a lower layer, where a high-frequency tracking controller\nguides a detailed model of the system toward the output of the higher-layer\nmodel. A fundamental problem in this layered architecture is the design of\nplanners and tracking controllers that guarantee both higher- and lower-layer\nsystem constraints are satisfied. Toward addressing this problem, we introduce\na principled approach for layered multirate control of linear systems subject\nto output and input constraints. Inspired by discrete-time simulation\nfunctions, we propose a streamlined control design that guarantees the\nlower-layer system tracks the output of the higher-layer system with computable\nprecision. Using this design, we derive conditions and present a method for\npropagating the constraints of the lower-layer system to the higher-layer\nsystem. The propagated constraints are integrated into the design of an\narbitrary planner that can handle higher-layer system constraints. Our\nframework ensures that the output constraints of the lower-layer system are\nsatisfied at all high-level time steps, while respecting its input constraints\nat all low-level time steps. We apply our approach in a scenario of motion\nplanning, highlighting its critical role in ensuring collision avoidance.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-14T17:48:34Z"}
{"aid":"http://arxiv.org/abs/2504.10846v1","title":"Mosaic: Client-driven Account Allocation Framework in Sharded\n  Blockchains","summary":"Recent account allocation studies in sharded blockchains are typically\nminer-driven, requiring miners to perform global optimizations for all accounts\nto enhance system-wide performance. This forces each miner to maintain a\ncomplete copy of the entire ledger, resulting in significant storage,\ncommunication, and computation overhead.\n  In this work, we explore an alternative research direction by proposing\nMosaic, the first client-driven framework for distributed, lightweight local\noptimization. Rather than relying on miners to allocate all accounts, Mosaic\nenables clients to independently execute a local algorithm to determine their\nresiding shards. Clients can submit migration requests to a beacon chain when\nrelocation is necessary. Mosaic naturally addresses key limitations of\nminer-driven approaches, including the lack of miner incentives and the\nsignificant overhead. While clients are flexible to adopt any algorithm for\nshard allocation, we design and implement a reference algorithm, Pilot, to\nguide them. Clients execute Pilot to maximize their own benefits, such as\nreduced transaction fees and confirmation latency.\n  On a real-world Ethereum dataset, we implement and evaluate Pilot against\nstate-of-the-art miner-driven global optimization solutions. The results\ndemonstrate that Mosaic significantly enhances computational efficiency,\nachieving a four-order-of-magnitude reduction in computation time, with the\nreduced input data size from 1.44 GB to an average of 228.66 bytes per account.\nDespite these efficiency gains, Pilot introduces only about a 5% increase in\nthe cross-shard ratio and maintains approximately 98% of the system throughput,\ndemonstrating a minimal trade-off in overall effectiveness.","main_category":"cs.DC","categories":"cs.DC,cs.DB,cs.GT","published":"2025-04-15T04:07:09Z"}
{"aid":"http://arxiv.org/abs/2504.10847v1","title":"Cosmic-Ray Constraints on the Flux of Ultra-High-Energy Neutrino Event\n  KM3-230213A","summary":"The detection of a $\\simeq220$~PeV muon neutrino by the KM3NeT neutrino\ntelescope offers an unprecedented opportunity to probe the Universe at extreme\nenergies. We analyze the origin of this event under three scenarios, viz., a\ntransient point source, a diffuse astrophysical emission, and line-of-sight\ninteraction of ultrahigh-energy cosmic rays (UHECR; $E \\gtrsim 0.1$~EeV). Our\nanalysis includes the flux from both a KM3NeT-only fit and a joint fit,\nincorporating data from KM3NeT, IceCube, and Pierre Auger Observatory. If the\nneutrino event originates from transients, it requires a new population of\ntransient that is energetic, gamma-ray dark, and more abundant than known ones.\nIn the framework of diffuse astrophysical emission, we compare the required\nlocal UHECR energy injection rate at $\\gtrsim4$ EeV, assuming a proton primary,\nwith the rate derived from the flux measurements by Auger. This disfavors the\nKM3NeT-only fit at all redshifts, while the joint fit remains viable for\n$z\\gtrsim 1$, based on redshift evolution models of known source populations.\nFor cosmogenic origin from point sources, our results suggest that the\nluminosity obtained at redshifts $z \\lesssim 1$ from the joint fit is\ncompatible with the Eddington luminosity of supermassive black holes in active\ngalactic nuclei.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-15T04:07:13Z"}
{"aid":"http://arxiv.org/abs/2504.10854v1","title":"LVLM_CSP: Accelerating Large Vision Language Models via Clustering,\n  Scattering, and Pruning for Reasoning Segmentation","summary":"Large Vision Language Models (LVLMs) have been widely adopted to guide vision\nfoundation models in performing reasoning segmentation tasks, achieving\nimpressive performance. However, the substantial computational overhead\nassociated with LVLMs presents a new challenge. The primary source of this\ncomputational cost arises from processing hundreds of image tokens. Therefore,\nan effective strategy to mitigate such overhead is to reduce the number of\nimage tokens, a process known as image token pruning. Previous studies on image\ntoken pruning for LVLMs have primarily focused on high level visual\nunderstanding tasks, such as visual question answering and image captioning. In\ncontrast, guiding vision foundation models to generate accurate visual masks\nbased on textual queries demands precise semantic and spatial reasoning\ncapabilities. Consequently, pruning methods must carefully control individual\nimage tokens throughout the LVLM reasoning process. Our empirical analysis\nreveals that existing methods struggle to adequately balance reductions in\ncomputational overhead with the necessity to maintain high segmentation\naccuracy. In this work, we propose LVLM_CSP, a novel training free visual token\npruning method specifically designed for LVLM based reasoning segmentation\ntasks. LVLM_CSP consists of three stages: clustering, scattering, and pruning.\nInitially, the LVLM performs coarse-grained visual reasoning using a subset of\nselected image tokens. Next, fine grained reasoning is conducted, and finally,\nmost visual tokens are pruned in the last stage. Extensive experiments\ndemonstrate that LVLM_CSP achieves a 65% reduction in image token inference\nFLOPs with virtually no accuracy degradation, and a 70% reduction with only a\nminor 1% drop in accuracy on the 7B LVLM.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T04:27:15Z"}
{"aid":"http://arxiv.org/abs/2504.10859v1","title":"A Sublinear Algorithm for Path Feasibility Among Rectangular Obstacles","summary":"The problem of finding a path between two points while avoiding obstacles is\ncritical in robotic path planning. We focus on the feasibility problem:\ndetermining whether such a path exists. We model the robot as a query-specific\nrectangular object capable of moving parallel to its sides. The obstacles are\naxis-aligned, rectangular, and may overlap. Most previous works only consider\nnondisjoint rectangular objects and point-sized or statically sized robots. Our\napproach introduces a novel technique leveraging generalized Gabriel graphs and\nconstructs a data structure to facilitate online queries regarding path\nfeasibility with varying robot sizes in sublinear time. To efficiently handle\nfeasibility queries, we propose an online algorithm utilizing sweep line to\nconstruct a generalized Gabriel graph under the $L_\\infty$ norm, capturing key\ngap constraints between obstacles. We utilize a persistent disjoint-set union\ndata structure to efficiently determine feasibility queries in\n$\\mathcal{O}(\\log n)$ time and $\\mathcal{O}(n)$ total space.","main_category":"cs.CG","categories":"cs.CG,cs.RO","published":"2025-04-15T04:40:25Z"}
{"aid":"http://arxiv.org/abs/2504.10878v1","title":"Large Language Model-Informed Feature Discovery Improves Prediction and\n  Interpretation of Credibility Perceptions of Visual Content","summary":"In today's visually dominated social media landscape, predicting the\nperceived credibility of visual content and understanding what drives human\njudgment are crucial for countering misinformation. However, these tasks are\nchallenging due to the diversity and richness of visual features. We introduce\na Large Language Model (LLM)-informed feature discovery framework that\nleverages multimodal LLMs, such as GPT-4o, to evaluate content credibility and\nexplain its reasoning. We extract and quantify interpretable features using\ntargeted prompts and integrate them into machine learning models to improve\ncredibility predictions. We tested this approach on 4,191 visual social media\nposts across eight topics in science, health, and politics, using credibility\nratings from 5,355 crowdsourced workers. Our method outperformed zero-shot\nGPT-based predictions by 13 percent in R2, and revealed key features like\ninformation concreteness and image format. We discuss the implications for\nmisinformation mitigation, visual credibility, and the role of LLMs in social\nscience.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-15T05:11:40Z"}
{"aid":"http://arxiv.org/abs/2504.10943v1","title":"Drivers and barriers of adopting shared micromobility: a latent class\n  clustering model on the attitudes towards shared micromobility as part of\n  public transport trips in the Netherlands","summary":"Shared micromobility (SMM) is often cited as a solution to the first/last\nmile problem of public transport (train) travel, yet when implemented, they\noften do not get adopted by a broader travelling public. A large part of\nbehavioural adoption is related to peoples' attitudes and perceptions. In this\npaper, we develop an adjusted behavioural framework, based on the UTAUT2\ntechnology acceptance framework. We carry out an exploratory factor analysis\n(EFA) to obtain attitudinal factors which we then use to perform a latent class\ncluster analysis (LCCA), with the goal of studying the potential adoption of\nSMM and to assess the various drivers and barriers as perceived by different\nuser groups. Our findings suggest there are six distinct user groups with\nvarying intention to use shared micromobility: Progressives, Conservatives,\nHesitant participants, Bold innovators, Anxious observers and Skilled sceptics.\nBold innovators and Progressives tend to be the most open to adopting SMM and\nare also able to do so. Hesitant participants would like to, but find it\ndifficult or dangerous to use, while Skilled sceptics are capable and\nconfident, but have limited intention of using it. Conservatives and Anxious\nobservers are most negative about SMM, finding it difficult to use and\ndangerous. In general, factors relating to technological savviness,\nease-of-use, physical safety and societal perception seem to be the biggest\nbarriers to wider adoption. Younger, highly educated males are the group most\nlikely and open to using shared micromobility, while older individuals with\nlower incomes and a lower level of education tend to be the least likely.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-15T07:46:19Z"}
{"aid":"http://arxiv.org/abs/2504.10949v1","title":"A Primer on Orthogonal Delay-Doppler Division Multiplexing (ODDM)","summary":"As a new type of multicarrier (MC) scheme built upon the recently discovered\ndelay-Doppler domain orthogonal pulse (DDOP), orthogonal delay-Doppler division\nmultiplexing (ODDM) aims to address the challenges of waveform design in linear\ntime-varying channels. In this paper, we explore the design principles of ODDM\nand clarify the key ideas underlying the DDOP. We then derive an alternative\nrepresentation of the DDOP and highlight the fundamental differences between\nODDM and conventional MC schemes. Finally, we discuss and compare two\nimplementation methods for ODDM.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-15T07:56:44Z"}
{"aid":"http://arxiv.org/abs/2504.10950v1","title":"Unveiling Challenges for LLMs in Enterprise Data Engineering","summary":"Large Language Models (LLMs) have demonstrated significant potential for\nautomating data engineering tasks on tabular data, giving enterprises a\nvaluable opportunity to reduce the high costs associated with manual data\nhandling. However, the enterprise domain introduces unique challenges that\nexisting LLM-based approaches for data engineering often overlook, such as\nlarge table sizes, more complex tasks, and the need for internal knowledge. To\nbridge these gaps, we identify key enterprise-specific challenges related to\ndata, tasks, and background knowledge and conduct a comprehensive study of\ntheir impact on recent LLMs for data engineering. Our analysis reveals that\nLLMs face substantial limitations in real-world enterprise scenarios, resulting\nin significant accuracy drops. Our findings contribute to a systematic\nunderstanding of LLMs for enterprise data engineering to support their adoption\nin industry.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-15T07:57:05Z"}
{"aid":"http://arxiv.org/abs/2504.10957v1","title":"When is Task Vector Provably Effective for Model Editing? A\n  Generalization Analysis of Nonlinear Transformers","summary":"Task arithmetic refers to editing the pre-trained model by adding a weighted\nsum of task vectors, each of which is the weight update from the pre-trained\nmodel to fine-tuned models for certain tasks. This approach recently gained\nattention as a computationally efficient inference method for model editing,\ne.g., multi-task learning, forgetting, and out-of-domain generalization\ncapabilities. However, the theoretical understanding of why task vectors can\nexecute various conceptual operations remains limited, due to the highly\nnon-convexity of training Transformer-based models. To the best of our\nknowledge, this paper provides the first theoretical characterization of the\ngeneralization guarantees of task vector methods on nonlinear Transformers. We\nconsider a conceptual learning setting, where each task is a binary\nclassification problem based on a discriminative pattern. We theoretically\nprove the effectiveness of task addition in simultaneously learning a set of\nirrelevant or aligned tasks, as well as the success of task negation in\nunlearning one task from irrelevant or contradictory tasks. Moreover, we prove\nthe proper selection of linear coefficients for task arithmetic to achieve\nguaranteed generalization to out-of-domain tasks. All of our theoretical\nresults hold for both dense-weight parameters and their low-rank\napproximations. Although established in a conceptual setting, our theoretical\nfindings were validated on a practical machine unlearning task using the large\nlanguage model Phi-1.5 (1.3B).","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-15T08:04:39Z"}
{"aid":"http://arxiv.org/abs/2504.10980v1","title":"Planar Hall effect in ultrathin topological insulator films","summary":"The planar Hall effect (PHE), previously observed in Weyl and Dirac\nsemimetals due to the chiral anomaly, emerges with a different origin in\ntopological insulators (TIs), where in-plane magnetic fields induce resistivity\nanisotropy. In strictly two-dimensional TIs, PHE is generally suppressed due to\nthe inability of the out-of-plane Berry curvature to couple to the in-plane\nband velocity of the charge carriers. Here, we demonstrate that in ultrathin TI\nfilms, a quasi-two-dimensional system, intersurface tunneling coupling with\nin-plane magnetization induces electronic anisotropy, enabling a finite PHE. In\naddition, we reveal that strong in-plane magnetization can stabilize the\nthickness-dependent quantum anomalous Hall effect, typically associated with\nout-of-plane magnetization. These insights advance the understanding of\nmagnetic topological phases, paving the way for next-generation spintronic\ndevices and magnetic sensing technologies.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-15T08:45:02Z"}
{"aid":"http://arxiv.org/abs/2504.10990v1","title":"Mathematical Analysis of the PDE Model for the Consensus-based\n  Optimization","summary":"In this paper, we develop an analytical framework for the partial\ndifferential equation underlying the consensus-based optimization model. The\nmain challenge arises from the nonlinear, nonlocal nature of the consensus\npoint, coupled with a diffusion term that is both singular and degenerate. By\nemploying a regularization procedure in combination with a compactness\nargument, we establish the global existence and uniqueness of weak solutions in\n$L^\\infty(0,T;L^1\\cap L^\\infty(\\mathbb{R}^d))$. Furthermore, we show that the\nweak solutions exhibit improved $H^2$-regularity when the initial data is\nregular.","main_category":"math.AP","categories":"math.AP,math.OC","published":"2025-04-15T09:02:36Z"}
{"aid":"http://arxiv.org/abs/2504.11013v1","title":"Effective Theory of Ultrafast Skyrmion Nucleation","summary":"Laser-induced ultrafast skyrmion nucleation has been experimentally\ndemonstrated in several materials. So far, atomistic models have been used to\ncorroborate experimental results. However, such simulations do not provide a\nsimple intuitive understanding of the underlying physics. Here, we propose a\ncoarse-grained effective theory where skyrmions can be nucleated or annihilated\nby thermal activation over energy barriers. Evaluating these two processes\nduring a heat pulse shows good agreement with atomistic spin dynamics\nsimulations and experiments while drastically reducing computational\ncomplexity. Furthermore, the effective theory provides a direct guide for\nexperimentally optimizing the number of nucleated skyrmions. Interestingly, the\nmodel also predicts a novel pathway for ultrafast annihilation of skyrmions.\nOur results pave the way for a deeper understanding of ultrafast nanomagnetism\nand the role of non-equilibrium physics.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-15T09:34:15Z"}
{"aid":"http://arxiv.org/abs/2504.11016v1","title":"Heating reduction as collective action: Impact on attitudes, behavior\n  and energy consumption in a Polish field experiment","summary":"Heating and hot water usage account for nearly 80% of household energy\nconsumption in the European Union. In order to reach the EU New Deal goals, new\npolicies to reduce heat energy consumption are indispensable. However, research\ntargeting reductions concentrates either on technical building interventions\nwithout considerations of people's behavior, or psychological interventions\nwith no technical interference. Such interventions can be promising, but their\ntrue potential for scaling up can only be realized by testing approaches that\nintegrate behavioral and technical solutions in tandem rather than in\nisolation. In this research, we study a mix of psychological and technical\ninterventions targeting heating and hot water demand among students in Polish\nuniversity dormitories. We evaluate effects on building energy consumption,\nbehavioral spillovers and on social beliefs and attitudes in a pre-post\nquasi-experimental mixed-method field study in three student dormitories. Our\nfindings reveal that the most effective approaches to yield energy savings were\na direct, collectively framed request to students to reduce thermostat settings\nfor the environment, and an automated technical adjustment of the heating curve\ntemperature. Conversely, interventions targeting domestic hot water had\nunintended effects, including increased energy use and negative spillovers,\nsuch as higher water consumption. Further, we find that informing students\nabout their active, collective participation had a positive impact on perceived\nsocial norms. Our findings highlight the importance of trialing interventions\nin controlled real-world settings to understand the interplay between technical\nsystems, behaviors, and social impacts to enable scalable, evidence-based\npolicies driving an effective and sustainable energy transition.","main_category":"cs.ET","categories":"cs.ET,cs.CY","published":"2025-04-15T09:41:37Z"}
{"aid":"http://arxiv.org/abs/2504.11047v1","title":"Hints for a Geon from Causal Dynamic Triangulations","summary":"The existence of geons, physical states of self-bound gravitons, has long\nbeen proposed. In the context of four-dimensional causal dynamical\ntriangulation simulations we investigate this possibility by measuring\ncurvature-curvature correlators of different gravitational operators. We find a\nbehavior consistent with a massive state, independent of the operators\nconsidered, over a certain distance window. While at most a hint, this is\ntantalizing due to its possible implications for dark matter or (primordial)\nblack holes. We also find indications that the phase of rapid expansion of the\nobtained de Sitter universe impacts the mass, and relates to quantum\nfluctuations of space-time.","main_category":"hep-lat","categories":"hep-lat,gr-qc,hep-ph,hep-th","published":"2025-04-15T10:23:06Z"}
{"aid":"http://arxiv.org/abs/2504.11052v1","title":"Weyl-mediated Ruderman-Kittel-Kasuya-Yosida interaction revisited:\n  imaginary-time formalism and finite temperature effects","summary":"Noncentrosymmetric magnetic Weyl semimetals provide a platform for\ninvestigating the interplay among magnetism, inversion symmetry breaking, and\ntopologically nontrivial Weyl fermions. The Weyl-mediated\nRuderman-Kittel-Kasuya-Yosida (RKKY) interaction may be related to the magnetic\norders observed in rare-earth magnetic Weyl semimetals. Previous studies of\nRKKY interaction between magnetic impurities in Weyl semimetals found\nHeisenberg, Ising-like, and Dzyaloshinskii-Moriya (DM) types of interactions.\nHowever, different range functions are obtained in the literature. In this\nwork, we calculate the Weyl-mediated RKKY interaction by using the\ndivergence-free imaginary-time formalism and obtain exact analytical results at\nfinite temperature. The discrepancies among zero temperature range functions in\nthe literature are resolved. At nonzero temperature, the interaction strength\ndecays exponentially in the long distance limit. But in the short distance\nlimit, the DM interaction shows a thermal enhancement, an effect persists up to\nhigher temperature for shorter distance. This provides a mechanism stabilizing\nthe helical order observed in rare-earth magnetic Weyl semimetals.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-15T10:39:59Z"}
{"aid":"http://arxiv.org/abs/2504.11060v1","title":"Goos-H√§nchen Shift and Photonic Spin Hall Effect in Semi-Dirac\n  Material Heterostructures","summary":"We investigate the photonic spin Hall effect (PSHE) and the Goos-H\\\"anchen\nshift (GH shift) in semi-Dirac\n  materials. Through theoretical modeling, we demonstrate that the anisotropic\ndielectric function in semi-Dirac\n  materials play a critical role in determining the magnitude and polarity of\nthese optical displacements. Further more, by utilizing the unidirectional\ndrift of massless Dirac electrons in Semi-Dirac materials, we systematically\n  reveal how the drift velocity and direction modulate the behavior of optical\ndisplacements. The results indicate\n  that semi-Dirac materials provide a versatile platform for controlling\nspin-dependent photonic phenomena with\n  their material anisotropy and carrier transport. This work opens a new avenue\nfor designing advanced photonic\n  devices with tunable optical responses, particularly with significant\napplication potential in quantum information\n  processing and topological photonics.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-15T10:48:19Z"}
{"aid":"http://arxiv.org/abs/2504.11061v1","title":"Synthesis and characterization of gold-coated nanodiamonds through green\n  chemistry as potential radiosensitizers for proton therapy","summary":"In this work the synthesis and characterization of novel gold-nanodiamond\nnanoparticles was performed. The synthesis was based on the reduction of gold\nonto the different types of nanodiamond (annealed or annealed and oxidized, 50\nor 230 nm) using root extracts of Nympheaea alba as a reducing agent. These\ngold-coated nanodiamonds were characterized by UV-Vis, PXRD, DLS,\nzeta-potential, PIXE, Raman, SEM, and TEM, assessing particle size, stability,\nand gold coating effectiveness. Cellular studies in the A549 and Panc1 cancer\ncell lines assessed uptake, cytotoxicity, and colony formation to evaluate\nNDAu's biological activity. NDAu demonstrated strong cellular uptake and\ncytotoxic effects in A549 and Panc1 cell lines, reducing cell survival in\nclonogenic assay. Futher research in the capabilites of these nanoparticles for\nproton therapy will be performed.","main_category":"hep-ex","categories":"hep-ex,cond-mat.mtrl-sci","published":"2025-04-15T10:49:51Z"}
{"aid":"http://arxiv.org/abs/2504.11085v1","title":"TD-Suite: All Batteries Included Framework for Technical Debt\n  Classification","summary":"Recognizing that technical debt is a persistent and significant challenge\nrequiring sophisticated management tools, TD-Suite offers a comprehensive\nsoftware framework specifically engineered to automate the complex task of its\nclassification within software projects. It leverages the advanced natural\nlanguage understanding of state-of-the-art transformer models to analyze\ntextual artifacts, such as developer discussions in issue reports, where subtle\nindicators of debt often lie hidden.\n  TD-Suite provides a seamless end-to-end pipeline, managing everything from\ninitial data ingestion and rigorous preprocessing to model training, thorough\nevaluation, and final inference. This allows it to support both straightforward\nbinary classification (debt or no debt) and more valuable, identifying specific\ncategories like code, design, or documentation debt, thus enabling more\ntargeted management strategies.\n  To ensure the generated models are robust and perform reliably on real-world,\noften imbalanced, datasets, TD-Suite incorporates critical training\nmethodologies: k-fold cross-validation assesses generalization capability,\nearly stopping mechanisms prevent overfitting to the training data, and class\nweighting strategies effectively address skewed data distributions. Beyond core\nfunctionality, and acknowledging the growing importance of sustainability, the\nframework integrates tracking and reporting of carbon emissions associated with\nthe computationally intensive model training process.\n  It also features a user-friendly Gradio web interface in a Docker container\nsetup, simplifying model interaction, evaluation, and inference.","main_category":"cs.SE","categories":"cs.SE,cs.LG","published":"2025-04-15T11:31:17Z"}
{"aid":"http://arxiv.org/abs/2504.11090v1","title":"Towards global equity in political polarization research","summary":"With a folk understanding that political polarization refers to\nsocio-political divisions within a society, many have proclaimed that we are\nmore divided than ever. In this account, polarization has been blamed for\npopulism, the erosion of social cohesion, the loss of trust in the institutions\nof democracy, legislative dysfunction, and the collective failure to address\nexistential risks such as Covid-19 or climate change. However, at a global\nscale there is surprisingly little academic literature which conclusively\nsupports these claims, with half of all studies being U.S.-focused. Here, we\nprovide an overview of the global state of research on polarization,\nhighlighting insights that are robust across countries, those unique to\nspecific contexts, and key gaps in the literature. We argue that addressing\nthese gaps is urgent, but has been hindered thus far by systemic and cultural\nbarriers, such as regionally stratified restrictions on data access and\nmisaligned research incentives. If continued cross-disciplinary inertia means\nthat these disparities are left unaddressed, we see a substantial risk that\ncountries will adopt policies to tackle polarization based on inappropriate\nevidence, risking flawed decision-making and the weakening of democratic\ninstitutions.","main_category":"cs.SI","categories":"cs.SI,physics.soc-ph","published":"2025-04-15T11:34:12Z"}
{"aid":"http://arxiv.org/abs/2504.11092v1","title":"Vivid4D: Improving 4D Reconstruction from Monocular Video by Video\n  Inpainting","summary":"Reconstructing 4D dynamic scenes from casually captured monocular videos is\nvaluable but highly challenging, as each timestamp is observed from a single\nviewpoint. We introduce Vivid4D, a novel approach that enhances 4D monocular\nvideo synthesis by augmenting observation views - synthesizing multi-view\nvideos from a monocular input. Unlike existing methods that either solely\nleverage geometric priors for supervision or use generative priors while\noverlooking geometry, we integrate both. This reformulates view augmentation as\na video inpainting task, where observed views are warped into new viewpoints\nbased on monocular depth priors. To achieve this, we train a video inpainting\nmodel on unposed web videos with synthetically generated masks that mimic\nwarping occlusions, ensuring spatially and temporally consistent completion of\nmissing regions. To further mitigate inaccuracies in monocular depth priors, we\nintroduce an iterative view augmentation strategy and a robust reconstruction\nloss. Experiments demonstrate that our method effectively improves monocular 4D\nscene reconstruction and completion.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T11:38:14Z"}
{"aid":"http://arxiv.org/abs/2504.11095v1","title":"Magnetotransport and activation energy of the surface states in Cd3As2\n  thin films","summary":"Recent experiments performed the magnetotransport measurements in\n(001)-oriented Cd$_3$As$_2$ thin films and attributed the magnetotransport\nproperties to the surface states. In this paper, by using an effective model to\ndescribe the surface states, we analyze the Landau bands and then calculate the\nmagnetoconductivities and magnetoresistivities. From these results, the\nfeatures of two-dimensional quantum Hall effect of the surface states can be\ncaptured. More importantly, we reveal that the activation energy is determined\nby the Hall plateau width, which can explain the experimental observations that\nthe activation energies at odd plateaus are larger than those at even plateaus.\nWe also analyze the roles played by the structural inversion symmetry breaking\nand impurity scatterings in the magnetotransport, and suggest that their\ncombined effects would lead to the absence of some Hall plateaus.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-15T11:40:31Z"}
{"aid":"http://arxiv.org/abs/2504.11111v1","title":"S$^2$Teacher: Step-by-step Teacher for Sparsely Annotated Oriented\n  Object Detection","summary":"Although fully-supervised oriented object detection has made significant\nprogress in multimodal remote sensing image understanding, it comes at the cost\nof labor-intensive annotation. Recent studies have explored weakly and\nsemi-supervised learning to alleviate this burden. However, these methods\noverlook the difficulties posed by dense annotations in complex remote sensing\nscenes. In this paper, we introduce a novel setting called sparsely annotated\noriented object detection (SAOOD), which only labels partial instances, and\npropose a solution to address its challenges. Specifically, we focus on two key\nissues in the setting: (1) sparse labeling leading to overfitting on limited\nforeground representations, and (2) unlabeled objects (false negatives)\nconfusing feature learning. To this end, we propose the S$^2$Teacher, a novel\nmethod that progressively mines pseudo-labels for unlabeled objects, from easy\nto hard, to enhance foreground representations. Additionally, it reweights the\nloss of unlabeled objects to mitigate their impact during training. Extensive\nexperiments demonstrate that S$^2$Teacher not only significantly improves\ndetector performance across different sparse annotation levels but also\nachieves near-fully-supervised performance on the DOTA dataset with only 10%\nannotation instances, effectively balancing detection accuracy with annotation\nefficiency. The code will be public.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T11:57:00Z"}
{"aid":"http://arxiv.org/abs/2504.11156v1","title":"A preliminary cosmological analysis of stellar population synthesis of\n  galaxies released by LAMOST LRS DR11","summary":"The evolution of the universe together with the galaxies is one of the\nfundamental issues that we humans are most interested in. Both the observations\nof tidal streams from SDSS and the theory of $\\Lambda$CDM support the\nhierarchical merging theory. The study of high redshift celestial bodies\ncontributes to a more in-depth study of cosmology. The LAMOST low resolution\nsearch catalog DR11 v1.0 has released 11,939,296 spectra, including 11,581,542\nstars, 275,302 galaxies, and 82,452 quasars, and so on. The data of 28,780\nstellar population synthesis of galaxies and some high redshift quasars are\nused to do a preliminary statistical research. We selected the data with small\nerrors for analysis and obtained some basic statistical conclusions. Older\ngalaxies have relatively larger stellar velocity dispersions. The larger the\nmetallicity, the greater the stellar velocity dispersion. These statistical\nresults are reasonable and consistent with previous work. Because the stellar\nvelocity dispersion is driven by the total mass of a galaxy at the first order\nand more massive galaxies have older ages and greater metallicities. The\nspectra of high redshift quasars show clear Gunn-Peterson trough and\nLyman-$\\alpha$ forest. The identified emission lines and high redshift\ncelestial spectra released by LAMOST can be used for cosmological research.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-15T13:01:48Z"}
{"aid":"http://arxiv.org/abs/2504.11162v1","title":"Scalable Transceiver Design for Multi-User Communication in FDD Massive\n  MIMO Systems via Deep Learning","summary":"This paper addresses the joint transceiver design, including pilot\ntransmission, channel feature extraction and feedback, as well as precoding,\nfor low-overhead downlink massive multiple-input multiple-output (MIMO)\ncommunication in frequency-division duplex (FDD) systems. Although deep\nlearning (DL) has shown great potential in tackling this problem, existing\nmethods often suffer from poor scalability in practical systems, as the\nsolution obtained in the training phase merely works for a fixed feedback\ncapacity and a fixed number of users in the deployment phase. To address this\nlimitation, we propose a novel DL-based framework comprised of choreographed\nneural networks, which can utilize one training phase to generate all the\ntransceiver solutions used in the deployment phase with varying sizes of\nfeedback codebooks and numbers of users. The proposed framework includes a\nresidual vector-quantized variational autoencoder (RVQ-VAE) for efficient\nchannel feedback and an edge graph attention network (EGAT) for robust\nmultiuser precoding. It can adapt to different feedback capacities by flexibly\nadjusting the RVQ codebook sizes using the hierarchical codebook structure, and\nscale with the number of users through a feedback module sharing scheme and the\ninherent scalability of EGAT. Moreover, a progressive training strategy is\nproposed to further enhance data transmission performance and generalization\ncapability. Numerical results on a real-world dataset demonstrate the superior\nscalability and performance of our approach over existing methods.","main_category":"eess.SP","categories":"eess.SP,cs.IT,math.IT","published":"2025-04-15T13:11:26Z"}
{"aid":"http://arxiv.org/abs/2504.11165v1","title":"YOLO-RS: Remote Sensing Enhanced Crop Detection Methods","summary":"With the rapid development of remote sensing technology, crop classification\nand health detection based on deep learning have gradually become a research\nhotspot. However, the existing target detection methods show poor performance\nwhen dealing with small targets in remote sensing images, especially in the\ncase of complex background and image mixing, which is difficult to meet the\npractical application requirementsite. To address this problem, a novel target\ndetection model YOLO-RS is proposed in this paper. The model is based on the\nlatest Yolov11 which significantly enhances the detection of small targets by\nintroducing the Context Anchor Attention (CAA) mechanism and an efficient\nmulti-field multi-scale feature fusion network. YOLO-RS adopts a bidirectional\nfeature fusion strategy in the feature fusion process, which effectively\nenhances the model's performance in the detection of small targets. Small\ntarget detection. Meanwhile, the ACmix module at the end of the model backbone\nnetwork solves the category imbalance problem by adaptively adjusting the\ncontrast and sample mixing, thus enhancing the detection accuracy in complex\nscenes. In the experiments on the PDT remote sensing crop health detection\ndataset and the CWC crop classification dataset, YOLO-RS improves both the\nrecall and the mean average precision (mAP) by about 2-3\\% or so compared with\nthe existing state-of-the-art methods, while the F1-score is also significantly\nimproved. Moreover, the computational complexity of the model only increases by\nabout 5.2 GFLOPs, indicating its significant advantages in both performance and\nefficiency. The experimental results validate the effectiveness and application\npotential of YOLO-RS in the task of detecting small targets in remote sensing\nimages.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T13:13:22Z"}
{"aid":"http://arxiv.org/abs/2504.11210v1","title":"Differentiating Formation Models with New Dynamical Masses for the PDS\n  70 Protoplanets","summary":"Hot- and cold-start planet formation models predict differing luminosities\nfor the young, bright planets that direct imaging surveys are most sensitive\nto. However, precise mass estimates are required to distinguish between these\nmodels observationally. The presence of two directly imaged planets, PDS 70 b\nand c, in the PDS 70 protoplanetary disk provides us a unique opportunity for\ndynamical mass measurements, since the masses for these planets are currently\npoorly constrained. Fitting orbital parameters to new astrometry of these\nplanets, taken with VLTI/GRAVITY in the $K$~band, we find $2\\sigma$ dynamical\nupper mass limits of 4.9 $M_{\\rm Jup}$ for b and 13.6 $M_{\\rm Jup}$ for c.\nAdding astrometry from the newly proposed planet candidate PDS 70 d into our\nmodel, we determine $2\\sigma$ dynamical upper mass limits of 5.3 $M_{\\rm Jup}$,\n7.5 $M_{\\rm Jup}$ and 2.2 $M_{\\rm Jup}$ for b, c, and the candidate d\nrespectively. However, $N$-body analysis of the orbits fit in this case suggest\nthat the inclusion of $d$ makes the system unstable. Using the upper mass\nlimits for b and c we rule out the coldest-start formation models for both\nplanets, calculating minimum post-formation entropies ($S_i$) of 9.5 $k_{\\rm\nB}/{\\rm baryon}$ and 8.4 $k_{\\rm B}/{\\rm baryon}$ respectively. This places PDS\n70 b and c on the growing list of directly-imaged planets inconsistent with\ncold-start formation.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-15T14:12:38Z"}
{"aid":"http://arxiv.org/abs/2504.11212v1","title":"SDFs from Unoriented Point Clouds using Neural Variational Heat\n  Distances","summary":"We propose a novel variational approach for computing neural Signed Distance\nFields (SDF) from unoriented point clouds. To this end, we replace the commonly\nused eikonal equation with the heat method, carrying over to the neural domain\nwhat has long been standard practice for computing distances on discrete\nsurfaces. This yields two convex optimization problems for whose solution we\nemploy neural networks: We first compute a neural approximation of the\ngradients of the unsigned distance field through a small time step of heat flow\nwith weighted point cloud densities as initial data. Then we use it to compute\na neural approximation of the SDF. We prove that the underlying variational\nproblems are well-posed. Through numerical experiments, we demonstrate that our\nmethod provides state-of-the-art surface reconstruction and consistent SDF\ngradients. Furthermore, we show in a proof-of-concept that it is accurate\nenough for solving a PDE on the zero-level set.","main_category":"math.NA","categories":"math.NA,cs.LG,cs.NA","published":"2025-04-15T14:13:54Z"}
{"aid":"http://arxiv.org/abs/2504.11226v1","title":"Ab initio Maxwell-Bloch Approach for X-Ray Excitations in\n  Two-Dimensional Materials","summary":"The combination of Maxwell and X-ray Bloch equations forms an appropriate\nframework to describe ultrafast time-resolved X-ray experiments on attosecond\ntime scale in crystalline solids. However, broadband experiments such as X-ray\nabsorption near edge spectroscopy or resonant inelastic X-ray scattering\nrequire a detailed knowledge of the electronic structure and transition matrix\nelements. Here, we show how to fill this gap by combining the Maxwell-X-ray\nBloch formalism with first-principles calculations treating explicitly the core\nstates. The resulting X-ray absorption spectrum recovers key spectral\nsignatures which were missing in our previous work relying on a semi-empirical\ntight-binding approach.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-15T14:28:30Z"}
{"aid":"http://arxiv.org/abs/2504.11235v1","title":"Guided Wave-Based Structural Awareness Under Varying Operating States\n  via Manifold Representations","summary":"Guided wave-based structural health monitoring (SHM) remains a powerful\nstrategy for identifying early-stage defects and safeguarding vital aerospace\nstructures. Yet, its practical use is often hindered by the enormous,\nhigh-dimensional data streams produced by sensor arrays operating at megahertz\nsampling rates, coupled with the added complexity of shifts in environmental\nand operational conditions (EOCs). Studies have explored various\ndata-compression approaches that retain critical diagnostic details in a\nlower-dimensional latent space. While conventional techniques can streamline\ndimensionality to some extent, they do not always capture the nonlinear\ninteractions typical of guided waves. Manifold learning, as illustrated by\nDiffusion Maps, tackles these nonlinearities by deriving low-dimensional\nembeddings directly from wave signals, minimizing the need for manual feature\nextraction. In parallel, developments in deep learning -- particularly\nautoencoders -- provide an encoder-decoder model for both data compression and\nreconstruction. Convolutional autoencoders (CAEs) and variational autoencoders\n(VAEs) have been particularly effective for guided wave applications. However,\ncurrent methods can still struggle to maintain accurate state estimation under\nchanging EOCs, and they are often limited to a single task. In response, the\nproposed framework adopts a two-fold strategy: it compresses high-dimensional\nsignals into lower-dimensional representations and then leverages those\nrepresentations to both estimate structural states and reconstruct the original\ndata, even as conditions vary. Applied to two real-world SHM use-cases, this\nintegrated method has proven its ability to preserve and retrieve key damage\nsignatures under noise, shifting operational parameters, and other complicating\nfactors.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-15T14:38:30Z"}
{"aid":"http://arxiv.org/abs/2504.11254v1","title":"Model Consistency of Iterative Regularization for Low-Complexity\n  Regularization","summary":"Regularization is a core component of modern inverse problems as it allows to\nestablish well-posedness to the solution of interests. Popular regularization\napproaches include variational regularization and iterative regularization. The\nformer one can be tackled by solving a variational optimization problem, which\nis the sum of a regularization term and a data-fidelity term balanced by a\nproper weight, while the latter one chooses a proper stopping time to avoid\noverfitting to the noise. In the study of regularization, an important topic is\nthe relation between the solution obtained by regularization and the original\nground truth. When the ground truth has low-complexity structure which is\nencoded as the \"model\", a sensitivity property shows that the solution obtained\nfrom proper regularization that promotes the same structure is robust to small\nperturbations, this is called \"model consistency\". For variational\nregularization, model consistency of linear inverse problem is studied in [1].\nWhile, for iterative regularization, the existence of model consistency is an\nopen problem. In this paper, based on a recent development of partial\nsmoothness which is also considered in [1], we show that if the noise level is\nsufficiently small and a proper stopping time is chosen, the solution by\niterative regularization also achieves model consistency and more exhibit local\nlinear convergence behavior. Numerical simulations are provided to verify our\ntheoretical findings.","main_category":"math.OC","categories":"math.OC","published":"2025-04-15T14:51:11Z"}
{"aid":"http://arxiv.org/abs/2504.11260v1","title":"$QQ$-systems and tropical geometry","summary":"We investigate the system of polynomial equations, known as $QQ$-systems,\nwhich are closely related to the so-called Bethe ansatz equations of the XXZ\nspin chain, using the methods of tropical geometry.","main_category":"math.AG","categories":"math.AG,hep-th,math-ph,math.MP,math.QA,math.RT","published":"2025-04-15T14:59:26Z"}
{"aid":"http://arxiv.org/abs/2504.11343v1","title":"A Minimalist Approach to LLM Reasoning: from Rejection Sampling to\n  Reinforce","summary":"Reinforcement learning (RL) has become a prevailing approach for fine-tuning\nlarge language models (LLMs) on complex reasoning tasks. Among recent methods,\nGRPO stands out for its empirical success in training models such as\nDeepSeek-R1, yet the sources of its effectiveness remain poorly understood. In\nthis work, we revisit GRPO from a reinforce-like algorithm perspective and\nanalyze its core components. Surprisingly, we find that a simple rejection\nsampling baseline, RAFT, which trains only on positively rewarded samples,\nyields competitive performance than GRPO and PPO. Our ablation studies reveal\nthat GRPO's main advantage arises from discarding prompts with entirely\nincorrect responses, rather than from its reward normalization. Motivated by\nthis insight, we propose Reinforce-Rej, a minimal extension of policy gradient\nthat filters both entirely incorrect and entirely correct samples.\nReinforce-Rej improves KL efficiency and stability, serving as a lightweight\nyet effective alternative to more complex RL algorithms. We advocate RAFT as a\nrobust and interpretable baseline, and suggest that future advances should\nfocus on more principled designs for incorporating negative samples, rather\nthan relying on them indiscriminately. Our findings provide guidance for future\nwork in reward-based LLM post-training.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL,stat.ML","published":"2025-04-15T16:15:02Z"}
{"aid":"http://arxiv.org/abs/2504.11348v1","title":"Circuit metaconstruction in logspace for Rice-like complexity lower\n  bounds in ANs and SGRs","summary":"A new proof technique combining finite model theory and dynamical systems has\nrecently been introduced to obtain general complexity lower bounds on any\nquestion one may formulate on the dynamics (seen as a graph) of a given\nautomata network (AN). ANs are abstract finite dynamical systems of interacting\nentities whose evolution rules are encoded as circuits, hence the study also\napplies to succinct graph representations (SGRs). In this article, we detail\nthe construction of circuits to obtain general complexity lower bounds\n(metareduction) and show that the reduction is feasible in logarithmic space.","main_category":"cs.CC","categories":"cs.CC","published":"2025-04-15T16:20:22Z"}
{"aid":"http://arxiv.org/abs/2504.11355v1","title":"Neural Networks for on-chip Model Predictive Control: a Method to Build\n  Optimized Training Datasets and its application to Type-1 Diabetes","summary":"Training Neural Networks (NNs) to behave as Model Predictive Control (MPC)\nalgorithms is an effective way to implement them in constrained embedded\ndevices. By collecting large amounts of input-output data, where inputs\nrepresent system states and outputs are MPC-generated control actions, NNs can\nbe trained to replicate MPC behavior at a fraction of the computational cost.\nHowever, although the composition of the training data critically influences\nthe final NN accuracy, methods for systematically optimizing it remain\nunderexplored. In this paper, we introduce the concept of Optimally-Sampled\nDatasets (OSDs) as ideal training sets and present an efficient algorithm for\ngenerating them. An OSD is a parametrized subset of all the available data that\n(i) preserves existing MPC information up to a certain numerical resolution,\n(ii) avoids duplicate or near-duplicate states, and (iii) becomes saturated or\ncomplete. We demonstrate the effectiveness of OSDs by training NNs to replicate\nthe University of Virginia's MPC algorithm for automated insulin delivery in\nType-1 Diabetes, achieving a four-fold improvement in final accuracy. Notably,\ntwo OSD-trained NNs received regulatory clearance for clinical testing as the\nfirst NN-based control algorithm for direct human insulin dosing. This\nmethodology opens new pathways for implementing advanced optimizations on\nresource-constrained embedded platforms, potentially revolutionizing how\ncomplex algorithms are deployed.","main_category":"eess.SY","categories":"eess.SY,cs.AI,cs.SY","published":"2025-04-15T16:25:06Z"}
{"aid":"http://arxiv.org/abs/2504.11381v1","title":"RankAlign: A Ranking View of the Generator-Validator Gap in Large\n  Language Models","summary":"Although large language models (LLMs) have become generally more capable and\naccurate across many tasks, some fundamental sources of unreliability remain in\ntheir behavior. One key limitation is their inconsistency at reporting the the\nsame information when prompts are changed. In this paper, we consider the\ndiscrepancy between a model's generated answer and their own verification of\nthat answer, the generator-validator gap. We define this gap in a more\nstringent way than prior work: we expect correlation of scores from a generator\nand a validator over the entire set of candidate answers. We show that\naccording to this measure, a large gap exists in various settings, including\nquestion answering, lexical semantics tasks, and next-word prediction. We then\npropose RankAlign, a ranking-based training method, and show that it\nsignificantly closes the gap by 31.8% on average, surpassing all baseline\nmethods. Moreover, this approach generalizes well to out-of-domain tasks and\nlexical items.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-15T16:53:31Z"}
{"aid":"http://arxiv.org/abs/2504.11408v1","title":"Five dimensional rotating and Quintessence black hole and their shadows","summary":"We present a new five-dimensional rotating quintessence black hole solution.\nTo obtain this, we employ the $5D$ version of the Janis Newman algorithm, which\nincorporates the Hopf bifurcation. The variation of the quintessence parameter\n$w_q$ causes the geometry to transition from a regular rotating universe\nsurrounded by a cosmological horizon to a singular rotating geometry, which can\nrepresent a naked singularity, a singular extremal black hole, or a singular\nblack hole with both an inner and an outer (event) horizon. We have also\ndetermined the properties of the ergosphere. For the study of the shadow, we\nfollowed a novel approach in which the $2D$ shadow observed by humans\ncorresponds to cross-sections of the $3D$ shadow. We analyzed how quintessence\naffects both the size and shape of the black hole shadow, showing that\nincreasing the quintessence strength reduces the shadow radius, contrary to the\nknown results in $4D$. We also propose a speculative methodology to test the\nshadow behavior in five-dimensional scenarios, in light of the constraints\nprovided by the Event Horizon Telescope (EHT) concerning the shadow of the\nfour-dimensional supermassive black hole M87. We identify scenarios in which\nthe theoretical $5D$ results could be consistent with these observational\nconstraints. Finally, we determine the energy conditions required to support\nthe solution.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-15T17:26:18Z"}
{"aid":"http://arxiv.org/abs/2504.11426v1","title":"A Dual-Space Framework for General Knowledge Distillation of Large\n  Language Models","summary":"Knowledge distillation (KD) is a promising solution to compress large\nlanguage models (LLMs) by transferring their knowledge to smaller models.\nDuring this process, white-box KD methods usually minimize the distance between\nthe output distributions of the teacher model and the student model to transfer\nmore information. However, we reveal that the current white-box KD framework\nexhibits two limitations: a) bridging probability distributions from different\noutput spaces will limit the similarity between the teacher model and the\nstudent model; b) this framework cannot be applied to LLMs with different\nvocabularies. One of the root causes for these limitations is that the\ndistributions from the teacher and the student for KD are output by different\nprediction heads, which yield distributions in different output spaces and\ndimensions. Therefore, in this paper, we propose a dual-space knowledge\ndistillation (DSKD) framework that unifies the prediction heads of the teacher\nand the student models for KD. Specifically, we first introduce two projectors\nwith ideal initialization to project the teacher/student hidden states into the\nstudent/teacher representation spaces. After this, the hidden states from\ndifferent models can share the same head and unify the output spaces of the\ndistributions. Furthermore, we develop an exact token alignment (ETA) algorithm\nto align the same tokens in two differently-tokenized sequences. Based on the\nabove, our DSKD framework is a general KD framework that supports both\noff-policy and on-policy KD, and KD between any two LLMs regardless of their\nvocabularies. Extensive experiments on instruction-following, mathematical\nreasoning, and code generation benchmarks show that DSKD significantly\noutperforms existing methods based on the current white-box KD framework and\nsurpasses other cross-tokenizer KD methods for LLMs with different\nvocabularies.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-15T17:38:47Z"}
{"aid":"http://arxiv.org/abs/2504.11431v1","title":"Masculine Defaults via Gendered Discourse in Podcasts and Large Language\n  Models","summary":"Masculine defaults are widely recognized as a significant type of gender\nbias, but they are often unseen as they are under-researched. Masculine\ndefaults involve three key parts: (i) the cultural context, (ii) the masculine\ncharacteristics or behaviors, and (iii) the reward for, or simply acceptance\nof, those masculine characteristics or behaviors. In this work, we study\ndiscourse-based masculine defaults, and propose a twofold framework for (i) the\nlarge-scale discovery and analysis of gendered discourse words in spoken\ncontent via our Gendered Discourse Correlation Framework (GDCF); and (ii) the\nmeasurement of the gender bias associated with these gendered discourse words\nin LLMs via our Discourse Word-Embedding Association Test (D-WEAT). We focus\nour study on podcasts, a popular and growing form of social media, analyzing\n15,117 podcast episodes. We analyze correlations between gender and discourse\nwords -- discovered via LDA and BERTopic -- to automatically form gendered\ndiscourse word lists. We then study the prevalence of these gendered discourse\nwords in domain-specific contexts, and find that gendered discourse-based\nmasculine defaults exist in the domains of business, technology/politics, and\nvideo games. Next, we study the representation of these gendered discourse\nwords from a state-of-the-art LLM embedding model from OpenAI, and find that\nthe masculine discourse words have a more stable and robust representation than\nthe feminine discourse words, which may result in better system performance on\ndownstream tasks for men. Hence, men are rewarded for their discourse patterns\nwith better system performance by one of the state-of-the-art language models\n-- and this embedding disparity is a representational harm and a masculine\ndefault.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.CY,cs.LG,cs.SI","published":"2025-04-15T17:41:54Z"}
{"aid":"http://arxiv.org/abs/2504.11442v1","title":"TextArena","summary":"TextArena is an open-source collection of competitive text-based games for\ntraining and evaluation of agentic behavior in Large Language Models (LLMs). It\nspans 57+ unique environments (including single-player, two-player, and\nmulti-player setups) and allows for easy evaluation of model capabilities via\nan online-play system (against humans and other submitted models) with\nreal-time TrueSkill scores. Traditional benchmarks rarely assess dynamic social\nskills such as negotiation, theory of mind, and deception, creating a gap that\nTextArena addresses. Designed with research, community and extensibility in\nmind, TextArena emphasizes ease of adding new games, adapting the framework,\ntesting models, playing against the models, and training models. Detailed\ndocumentation of environments, games, leaderboard, and examples are available\non https://github.com/LeonGuertler/TextArena and https://www.textarena.ai/.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG,cs.MA","published":"2025-04-15T17:55:20Z"}
{"aid":"http://arxiv.org/abs/2504.11447v1","title":"Diffusion Distillation With Direct Preference Optimization For Efficient\n  3D LiDAR Scene Completion","summary":"The application of diffusion models in 3D LiDAR scene completion is limited\ndue to diffusion's slow sampling speed. Score distillation accelerates\ndiffusion sampling but with performance degradation, while post-training with\ndirect policy optimization (DPO) boosts performance using preference data. This\npaper proposes Distillation-DPO, a novel diffusion distillation framework for\nLiDAR scene completion with preference aligment. First, the student model\ngenerates paired completion scenes with different initial noises. Second, using\nLiDAR scene evaluation metrics as preference, we construct winning and losing\nsample pairs. Such construction is reasonable, since most LiDAR scene metrics\nare informative but non-differentiable to be optimized directly. Third,\nDistillation-DPO optimizes the student model by exploiting the difference in\nscore functions between the teacher and student models on the paired completion\nscenes. Such procedure is repeated until convergence. Extensive experiments\ndemonstrate that, compared to state-of-the-art LiDAR scene completion diffusion\nmodels, Distillation-DPO achieves higher-quality scene completion while\naccelerating the completion speed by more than 5-fold. Our method is the first\nto explore adopting preference learning in distillation to the best of our\nknowledge and provide insights into preference-aligned distillation. Our code\nis public available on https://github.com/happyw1nd/DistillationDPO.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T17:57:13Z"}
{"aid":"http://arxiv.org/abs/2504.11759v1","title":"Bringing closure to FDR control: beating the e-Benjamini-Hochberg\n  procedure","summary":"False discovery rate (FDR) has been a key metric for error control in\nmultiple hypothesis testing, and many methods have developed for FDR control\nacross a diverse cross-section of settings and applications. We develop a\nclosure principle for all FDR controlling procedures, i.e., we provide a\ncharacterization based on e-values for all admissible FDR controlling\nprocedures. We leverage this idea to formulate the closed eBH procedure, a\n(usually strict) improvement over the eBH procedure for FDR control when\nprovided with e-values. We demonstrate the practical performance of closed eBH\nin simulations.","main_category":"stat.ME","categories":"stat.ME,math.ST,stat.TH","published":"2025-04-16T04:36:12Z"}
{"aid":"http://arxiv.org/abs/2504.11779v1","title":"Multimodal Spatio-temporal Graph Learning for Alignment-free RGBT Video\n  Object Detection","summary":"RGB-Thermal Video Object Detection (RGBT VOD) can address the limitation of\ntraditional RGB-based VOD in challenging lighting conditions, making it more\npractical and effective in many applications.\n  However, similar to most RGBT fusion tasks, it still mainly relies on\nmanually aligned multimodal image pairs.\n  In this paper, we propose a novel Multimodal Spatio-temporal Graph learning\nNetwork (MSGNet) for alignment-free RGBT VOD problem by leveraging the robust\ngraph representation learning model.\n  Specifically, we first design an Adaptive Partitioning Layer (APL) to\nestimate the corresponding regions of the Thermal image within the RGB image\n(high-resolution), achieving a preliminary inexact alignment.\n  Then, we introduce the Spatial Sparse Graph Learning Module (S-SGLM) which\nemploys a sparse information passing mechanism on the estimated inexact\nalignment to achieve reliable information interaction between different\nmodalities.\n  Moreover, to fully exploit the temporal cues for RGBT VOD problem, we\nintroduce Hybrid Structured Temporal Modeling (HSTM), which involves a Temporal\nSparse Graph Learning Module (T-SGLM) and Temporal Star Block (TSB). T-SGLM\naims to filter out some redundant information between adjacent frames by\nemploying the sparse aggregation mechanism on the temporal graph. Meanwhile,\nTSB is dedicated to achieving the complementary learning of local spatial\nrelationships.\n  Extensive comparative experiments conducted on both the aligned dataset\nVT-VOD50 and the unaligned dataset UVT-VOD2024 demonstrate the effectiveness\nand superiority of our proposed method. Our project will be made available on\nour website for free public access.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T05:32:59Z"}
{"aid":"http://arxiv.org/abs/2504.11788v1","title":"Enhancing Web Agents with Explicit Rollback Mechanisms","summary":"With recent advancements in large language models, web agents have been\ngreatly improved. However, dealing with complex and dynamic web environments\nrequires more advanced planning and search abilities. Previous studies usually\nadopt a greedy one-way search strategy, which may struggle to recover from\nerroneous states. In this work, we enhance web agents with an explicit rollback\nmechanism, enabling the agent to revert back to a previous state in its\nnavigation trajectory. This mechanism gives the model the flexibility to\ndirectly control the search process, leading to an effective and efficient web\nnavigation method. We conduct experiments on two live web navigation benchmarks\nwith zero-shot and fine-tuning settings. The results demonstrate the\neffectiveness of our proposed approach.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-16T05:41:20Z"}
{"aid":"http://arxiv.org/abs/2504.11793v1","title":"Selective Attention Federated Learning: Improving Privacy and Efficiency\n  for Clinical Text Classification","summary":"Federated Learning (FL) faces major challenges regarding communication\noverhead and model privacy when training large language models (LLMs),\nespecially in healthcare applications. To address these, we introduce Selective\nAttention Federated Learning (SAFL), a novel approach that dynamically\nfine-tunes only those transformer layers identified as attention-critical. By\nemploying attention patterns to determine layer importance, SAFL significantly\nreduces communication bandwidth and enhances differential privacy resilience.\nEvaluations on clinical NLP benchmarks (i2b2 Clinical Concept Extraction and\nMIMIC-III discharge summaries) demonstrate that SAFL achieves competitive\nperformance with centralized models while substantially improving communication\nefficiency and privacy preservation.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-16T05:59:29Z"}
{"aid":"http://arxiv.org/abs/2504.11828v1","title":"Semiclassical causal geodesics: Minkowski spacetime case","summary":"We use an integral quantization model based on the Heisenberg-Weyl group to\ndescribe the motion of a spinless particle in the Minkowski background\nspacetime. This work is a sequel to a previous paper, devoted to mathematical\naspects of our model: construction of the space of coherent states and\nproperties of elementary observables. We compute transition amplitudes\ncorresponding to a free motion of a particle between two coherent states. These\namplitudes are then used to model quantum random walks of free relativistic\nparticles. Our quantization scheme allows us to recover interference patterns\noccurring in a standard double-slit experiment, known from the classical\napproach. This result is obtained by modeling the slits in terms of eigenstates\nof the position operator and computing transition amplitudes between position\nand coherent states. We design our model in a way which allows for a future\ngeneralization to a semi-classical quantization of the geodesic motion in\ncurved spacetimes.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-16T07:27:28Z"}
{"aid":"http://arxiv.org/abs/2504.11874v1","title":"Factor-MCLS: Multi-agent learning system with reward factor matrix and\n  multi-critic framework for dynamic portfolio optimization","summary":"Typical deep reinforcement learning (DRL) agents for dynamic portfolio\noptimization learn the factors influencing portfolio return and risk by\nanalyzing the output values of the reward function while adjusting portfolio\nweights within the training environment. However, it faces a major limitation\nwhere it is difficult for investors to intervene in the training based on\ndifferent levels of risk aversion towards each portfolio asset. This difficulty\narises from another limitation: existing DRL agents may not develop a thorough\nunderstanding of the factors responsible for the portfolio return and risk by\nonly learning from the output of the reward function. As a result, the strategy\nfor determining the target portfolio weights is entirely dependent on the DRL\nagents themselves. To address these limitations, we propose a reward factor\nmatrix for elucidating the return and risk of each asset in the portfolio.\nAdditionally, we propose a novel learning system named Factor-MCLS using a\nmulti-critic framework that facilitates learning of the reward factor matrix.\nIn this way, our DRL-based learning system can effectively learn the factors\ninfluencing portfolio return and risk. Moreover, based on the critic networks\nwithin the multi-critic framework, we develop a risk constraint term in the\ntraining objective function of the policy function. This risk constraint term\nallows investors to intervene in the training of the DRL agent according to\ntheir individual levels of risk aversion towards the portfolio assets.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-16T08:51:09Z"}
{"aid":"http://arxiv.org/abs/2504.11891v1","title":"Towards a Refined Understanding of Non-holomorphic Soft SUSY-Breaking\n  Effects on the Higgs Boson Mass Spectra","summary":"We study the impact of the non-holomorphic (NH) soft supersymmetry-breaking\nterms $ T_{33}^{\\prime D} $ and $ \\mu^\\prime $, which introduce additional\nSUSY-breaking effects beyond the holomorphic structure of the superpotential,\non the Higgs boson mass spectrum in the NH Minimal Supersymmetric Standard\nModel (NHSSM). The term $ T_{33}^{\\prime D} $ modifies the scalar bottom-quark\nmass matrix and Higgs couplings, while $ \\mu^\\prime $ affects the mass matrices\nof charginos and neutralinos. In our analysis, we incorporate constraints from\ncharge- and color-breaking (CCB) minima where we find that a portion of the\nparameter space is excluded by these constraints. Focusing on the allowed\nparameter space, the NH contributions to the light $\\cal CP$-even Higgs boson\nmass, $ M_h $, from $ \\mu^\\prime $ and $ T_{33}^{\\prime D} $ can reach up to $\n1.4 \\,\\, \\mathrm{GeV} $ and $ 90 \\,\\, \\mathrm{MeV} $, respectively. For the\nheavy $\\cal CP$-even Higgs boson mass, $ M_H $, and the charged Higgs boson\nmass, $ M_{H^{\\pm}} $, these contributions can be substantially larger in\ncertain regions of the parameter space, reaching up to $ 44 \\,\\, \\mathrm{GeV} $\nfor $ M_H $ and $ 42 \\,\\, \\mathrm{GeV} $ for $ M_{H^{\\pm}} $ due to $\n\\mu^\\prime $, and up to $ 60 \\,\\, \\mathrm{GeV} $ due to $ T_{33}^{\\prime D} $\nfor both $ M_H $ and $ M_{H^{\\pm}} $. These corrections are significantly\nlarger than the expected future experimental precision for Higgs boson masses\nand should therefore be considered in precision analyses for future\nexperiments.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-16T09:19:04Z"}
{"aid":"http://arxiv.org/abs/2504.11921v1","title":"On 5-point conformal block with level 2 degenerate field insertion and\n  its AGT dual","summary":"In this paper, we develop and explore recursive methods to investigate the 2d\nCFT 5-point conformal block with a level 2 degenerate insertion, as well as its\nAGT dual, by solving the BPZ differential equation. First, we represent the\nsolution of the differential equation as a double series expansion. On the\n2-node quiver gauge theory side, this corresponds to the instanton series. We\nthen demonstrate that the expansion coefficients are uniquely determined by a\nrecursion relation. Inspired by the approach initiated in a paper by D. Gaiotto\nand J. Teschner, we partially resum this series and show that the result can be\nelegantly expressed in terms of a single hypergeometric function and its\nderivative. This new representation makes it straightforward to relate\ndifferent asymptotic regions. As a by-product, this provides us a simple\nderivation of fusion and braiding coefficients.\n  We describe the subtle procedure of merging the degenerate field with the\noutgoing state, thereby obtaining a generic 4-point block, which on the gauge\ntheory side corresponds to the partition function of $SU(2)$ gauge theory with\nfour massive hypermultiplets in the $\\Omega$-background.\n  Finally, we performed several nontrivial checks, which confirm our results.","main_category":"hep-th","categories":"hep-th","published":"2025-04-16T09:56:43Z"}
{"aid":"http://arxiv.org/abs/2504.11946v1","title":"R-Meshfusion: Reinforcement Learning Powered Sparse-View Mesh\n  Reconstruction with Diffusion Priors","summary":"Mesh reconstruction from multi-view images is a fundamental problem in\ncomputer vision, but its performance degrades significantly under sparse-view\nconditions, especially in unseen regions where no ground-truth observations are\navailable. While recent advances in diffusion models have demonstrated strong\ncapabilities in synthesizing novel views from limited inputs, their outputs\noften suffer from visual artifacts and lack 3D consistency, posing challenges\nfor reliable mesh optimization. In this paper, we propose a novel framework\nthat leverages diffusion models to enhance sparse-view mesh reconstruction in a\nprincipled and reliable manner. To address the instability of diffusion\noutputs, we propose a Consensus Diffusion Module that filters unreliable\ngenerations via interquartile range (IQR) analysis and performs variance-aware\nimage fusion to produce robust pseudo-supervision. Building on this, we design\nan online reinforcement learning strategy based on the Upper Confidence Bound\n(UCB) to adaptively select the most informative viewpoints for enhancement,\nguided by diffusion loss. Finally, the fused images are used to jointly\nsupervise a NeRF-based model alongside sparse-view ground truth, ensuring\nconsistency across both geometry and appearance. Extensive experiments\ndemonstrate that our method achieves significant improvements in both geometric\nquality and rendering quality.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T10:23:59Z"}
{"aid":"http://arxiv.org/abs/2504.11949v1","title":"Flow Intelligence: Robust Feature Matching via Temporal Signature\n  Correlation","summary":"Feature matching across video streams remains a cornerstone challenge in\ncomputer vision. Increasingly, robust multimodal matching has garnered interest\nin robotics, surveillance, remote sensing, and medical imaging. While\ntraditional rely on detecting and matching spatial features, they break down\nwhen faced with noisy, misaligned, or cross-modal data. Recent deep learning\nmethods have improved robustness through learned representations, but remain\nconstrained by their dependence on extensive training data and computational\ndemands. We present Flow Intelligence, a paradigm-shifting approach that moves\nbeyond spatial features by focusing on temporal motion patterns exclusively.\nInstead of detecting traditional keypoints, our method extracts motion\nsignatures from pixel blocks across consecutive frames and extract temporal\nmotion signatures between videos. These motion-based descriptors achieve\nnatural invariance to translation, rotation, and scale variations while\nremaining robust across different imaging modalities. This novel approach also\nrequires no pretraining data, eliminates the need for spatial feature\ndetection, enables cross-modal matching using only temporal motion, and it\noutperforms existing methods in challenging scenarios where traditional\napproaches fail. By leveraging motion rather than appearance, Flow Intelligence\nenables robust, real-time video feature matching in diverse environments.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T10:25:20Z"}
{"aid":"http://arxiv.org/abs/2504.11953v1","title":"Novel-view X-ray Projection Synthesis through Geometry-Integrated Deep\n  Learning","summary":"X-ray imaging plays a crucial role in the medical field, providing essential\ninsights into the internal anatomy of patients for diagnostics, image-guided\nprocedures, and clinical decision-making. Traditional techniques often require\nmultiple X-ray projections from various angles to obtain a comprehensive view,\nleading to increased radiation exposure and more complex clinical processes.\nThis paper explores an innovative approach using the DL-GIPS model, which\nsynthesizes X-ray projections from new viewpoints by leveraging a single\nexisting projection. The model strategically manipulates geometry and texture\nfeatures extracted from an initial projection to match new viewing angles. It\nthen synthesizes the final projection by merging these modified geometry\nfeatures with consistent texture information through an advanced image\ngeneration process. We demonstrate the effectiveness and broad applicability of\nthe DL-GIPS framework through lung imaging examples, highlighting its potential\nto revolutionize stereoscopic and volumetric imaging by minimizing the need for\nextensive data acquisition.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-16T10:30:08Z"}
{"aid":"http://arxiv.org/abs/2504.11956v1","title":"The Conserved Effective Stress Tensor of Gravitational Wave","summary":"We present a detailed study of the effective stress tensor of gravitational\nwave (GW) as the source for the background Einstein equation and examine three\ncandidates in literature. The second order perturbed Einstein tensor\n$G^{(2)}_{\\mu\\nu}$, up to a coefficient, proposed by Brill, Hartle, and\nIsaacson, has long been known to be covariantly nonconserved with respect to\nthe background spacetime. We observe that $G^{(2)}_{\\mu\\nu}$ is not a true\ntensor on the background spacetime. More importantly, we find that, by\nexpressing $G^{(2)}_{\\mu\\nu}$ in terms of the perturbed Hilbert-Einstein\nactions,\n  the nonconserved part of $G^{(2)}_{\\mu\\nu}$ is actually canceled out by the\nperturbed fluid stress tensors in the back-reaction equation, or is vanishing\nin absence of fluid. The remaining part of $G^{(2)}_{\\mu\\nu}$ is just the\nconserved effective stress tensor $\\tau_{\\mu\\nu}$ proposed by Ford and Parker.\nAs the main result, we derive $\\tau_{\\mu\\nu}$ for a general curved spacetime by\nvarying the GW action and show its conservation using the equation of GW. The\nstress tensor $T_{\\text{MT}}^{\\mu\\nu}$ proposed by MacCallum and Taub was based\non an action $J_2$. We derive $T_{\\text{MT}}^{\\mu\\nu}$ and find that it is\nnonconserved, and that $J_2$ does not give the correct GW equation in presence\nof matter. The difficulty with $J_2$ is due to a background Ricci tensor term,\nwhich should be also canceled out by the fluid term or vanishing in absence of\nfluid. We also demonstrate these three candidates in a flat Robertson-Walker\nspacetime. The conserved $\\tau_{\\mu\\nu}$ has a positive energy density\nspectrum, and is adequate for the back-reaction in a perturbation scheme, while\nthe two nonconserved stress tensors have a negative spectrum at long\nwavelengths and are unphysical.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-16T10:38:43Z"}
{"aid":"http://arxiv.org/abs/2504.11967v1","title":"Securing the Skies: A Comprehensive Survey on Anti-UAV Methods,\n  Benchmarking, and Future Directions","summary":"Unmanned Aerial Vehicles (UAVs) are indispensable for infrastructure\ninspection, surveillance, and related tasks, yet they also introduce critical\nsecurity challenges. This survey provides a wide-ranging examination of the\nanti-UAV domain, centering on three core objectives-classification, detection,\nand tracking-while detailing emerging methodologies such as diffusion-based\ndata synthesis, multi-modal fusion, vision-language modeling, self-supervised\nlearning, and reinforcement learning. We systematically evaluate\nstate-of-the-art solutions across both single-modality and multi-sensor\npipelines (spanning RGB, infrared, audio, radar, and RF) and discuss\nlarge-scale as well as adversarially oriented benchmarks. Our analysis reveals\npersistent gaps in real-time performance, stealth detection, and swarm-based\nscenarios, underscoring pressing needs for robust, adaptive anti-UAV systems.\nBy highlighting open research directions, we aim to foster innovation and guide\nthe development of next-generation defense strategies in an era marked by the\nextensive use of UAVs.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.RO","published":"2025-04-16T10:58:33Z"}
{"aid":"http://arxiv.org/abs/2504.11978v1","title":"On the Intersection and Composition properties of conditional\n  independence","summary":"Compositional graphoids are fundamental discrete structures which appear in\nprobabilistic reasoning, particularly in the area of graphical models. They are\nsemigraphoids which satisfy the Intersection and Composition properties. These\nimportant properties, however, are not enjoyed by general probability\ndistributions. We survey what is known in terms of sufficient conditions for\nIntersection and Composition and derive a set of new sufficient conditions in\nthe context of discrete random variables based on conditional information\ninequalities for Shannon entropies.","main_category":"cs.IT","categories":"cs.IT,math.IT,math.ST,stat.TH","published":"2025-04-16T11:17:41Z"}
{"aid":"http://arxiv.org/abs/2504.11983v1","title":"Non-orientable Exceptional Points in Twisted Boundary Systems","summary":"Non-orientable manifolds, such as the M\\\"obius strip and the Klein bottle,\ndefy conventional geometric intuition through their twisted boundary\nconditions. As a result, topological defects on non-orientable manifolds give\nrise to novel physical phenomena. We study the adiabatic transport of\nexceptional points (EPs) along non-orientable closed loops and uncover distinct\ntopological responses arising from the lack of global orientation. Notably, we\ndemonstrate that the cyclic permutation of eigenstates across an EP depends\nsensitively on the loop orientation, yielding inequivalent braid\nrepresentations for clockwise and counterclockwise encirclement; this is a\nfeature unique to non-orientable geometries. Orientation-dependent geometric\nquantities, such as the winding number, cannot be consistently defined due to\nthe absence of a global orientation. However, when a boundary is introduced,\nsuch quantities become well defined within the local interior, even though the\nglobal manifold remains non-orientable. We further demonstrate the adiabatic\nevolution of EPs and the emergence of orientation-sensitive observables in a\nKlein Brillouin zone, described by an effective non-Hermitian Hamiltonian that\npreserves momentum-space glide symmetry. Finally, we numerically implement\nthese ideas in a microdisk cavity with embedded scatterers using synthetic\nmomenta.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mes-hall,quant-ph","published":"2025-04-16T11:26:05Z"}
{"aid":"http://arxiv.org/abs/2504.11997v1","title":"A Computationally Efficient Algorithm for Infinite-Horizon\n  Average-Reward Linear MDPs","summary":"We study reinforcement learning in infinite-horizon average-reward settings\nwith linear MDPs. Previous work addresses this problem by approximating the\naverage-reward setting by discounted setting and employing a value\niteration-based algorithm that uses clipping to constrain the span of the value\nfunction for improved statistical efficiency. However, the clipping procedure\nrequires computing the minimum of the value function over the entire state\nspace, which is prohibitive since the state space in linear MDP setting can be\nlarge or even infinite. In this paper, we introduce a value iteration method\nwith efficient clipping operation that only requires computing the minimum of\nvalue functions over the set of states visited by the algorithm. Our algorithm\nenjoys the same regret bound as the previous work while being computationally\nefficient, with computational complexity that is independent of the size of the\nstate space.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-16T11:47:41Z"}
{"aid":"http://arxiv.org/abs/2504.12003v1","title":"Inclusion of an Inverse Magnetic Hysteresis Model into the Space-Time\n  Finite Element Method for Magnetoquasistatics","summary":"In this note we discuss the numerical solution of the eddy current\napproximation of the Maxwell equations using the simple Pragmatic Algebraic\nModel to include hysteresis effects. In addition to the more standard\ntime-stepping approach we propose a space-time finite element method which\nallows both for parallelization and adaptivity simultaneously in space and\ntime. Numerical experiments confirm both approaches yield the same numerical\nresults.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-16T11:56:42Z"}
{"aid":"http://arxiv.org/abs/2504.12042v1","title":"Diverse regular spacetimes using a parametrised density profile","summary":"We explore the construction of diverse regular spacetimes (black holes and\ndefects) in General Relativity (GR) using a generic parametrised density\nprofile (the Dekel-Zhao profile), which includes, for specific parameter\nchoices, various well-known examples usually studied in the context of dark\nmatter halos. Our solutions, in the Schwarzschild gauge, include new regular\nblack holes as well as non-singular solutions representing spacetime defects.\nFor a sub-class of metrics, a TOV equation approach with a chosen equation of\nstate works. The status of the energy conditions and the issue of geodesic\ncompleteness are explored in detail. We also provide possible Lagrangian\ndensity constructions for the matter energy-momentum tensors. Further, we study\nthe shadow radius of the new regular black holes, and compare our findings with\navailable observational results from the EHT collaboration. Finally, for the\ndefect solution, we present a model for a stable star (a gravastar) by explicit\nuse of the junction conditions and obtain relevant consequences highlighting\nits characteristic features.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-16T12:56:31Z"}
{"aid":"http://arxiv.org/abs/2504.12081v1","title":"QCD$_2$ 't Hooft model: 2-flavour mesons spectrum","summary":"We continue analytical study of the meson mass spectrum in the large-$N_c$\ntwo-dimensional QCD, known as the 't Hooft model, by addressing the most\ngeneral case of quarks with unequal masses. Based on our previous work, we\ndevelop non-perturbative methods to compute spectral sums and systematically\nderive large-$n$ WKB expansion of the spectrum. Furthermore, we examine the\nbehavior of these results in various asymptotic regimes, including the chiral,\nheavy quark, and heavy-light limits, and establish a precise coincidence with\nknown analytical and numerical results obtained through alternative approaches.","main_category":"hep-th","categories":"hep-th,hep-ph,math-ph,math.MP","published":"2025-04-16T13:42:10Z"}
{"aid":"http://arxiv.org/abs/2504.12086v1","title":"Neural Contextual Bandits Under Delayed Feedback Constraints","summary":"This paper presents a new algorithm for neural contextual bandits (CBs) that\naddresses the challenge of delayed reward feedback, where the reward for a\nchosen action is revealed after a random, unknown delay. This scenario is\ncommon in applications such as online recommendation systems and clinical\ntrials, where reward feedback is delayed because the outcomes or results of a\nuser's actions (such as recommendations or treatment responses) take time to\nmanifest and be measured. The proposed algorithm, called Delayed NeuralUCB,\nuses an upper confidence bound (UCB)-based exploration strategy. Under the\nassumption of independent and identically distributed sub-exponential reward\ndelays, we derive an upper bound on the cumulative regret over a T-length\nhorizon. We further consider a variant of the algorithm, called Delayed\nNeuralTS, that uses Thompson Sampling-based exploration. Numerical experiments\non real-world datasets, such as MNIST and Mushroom, along with comparisons to\nbenchmark approaches, demonstrate that the proposed algorithms effectively\nmanage varying delays and are well-suited for complex real-world scenarios.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-16T13:47:25Z"}
{"aid":"http://arxiv.org/abs/2504.12092v1","title":"Virtually structured illumination for terahertz super-resolution imaging","summary":"We demonstrate structured illumination super-resolution imaging in the\nTerahertz (THz) frequency band using the Virtually Structured Detection (VSD)\nmethod. Leveraging our previously reported high-speed, high-sensitivity\natomic-based THz imager, we achieve a resolution enhancement of 74(3)% at 0.55\nTHz, without the aid of deconvolution methods. We show a high-speed THz imaging\nsystem is compatible with the use of advanced optical techniques, with\npotential disruptive effects on applications requiring both high speed and high\nspatial resolution imaging in the THz range.","main_category":"physics.optics","categories":"physics.optics,physics.atom-ph","published":"2025-04-16T13:54:33Z"}
{"aid":"http://arxiv.org/abs/2504.12093v1","title":"The Tripod High-Speed Quantum Memory As a Beam Splitter with Arbitrary\n  Splitting Ratios","summary":"The utilisation of a quantum memory cell as a beam splitter with arbitrary\ncoefficients is demonstrated theoretically. For such a beam splitter, an\ninput-output matrix is derived. We investigate the high-speed quantum memory\nbased on the tripod-type atomic levels and transitions.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-16T13:57:35Z"}
{"aid":"http://arxiv.org/abs/2504.12144v1","title":"PINNs for Solving Unsteady Maxwell's Equations: Convergence Issues and\n  Comparative Assessment with Compact Schemes","summary":"Physics-Informed Neural Networks (PINNs) have recently emerged as a promising\nalternative for solving partial differential equations, offering a mesh-free\nframework that incorporates physical laws directly into the learning process.\nIn this study, we explore the application of PINNs for solving unsteady\nMaxwell's equations and compare their performance with two established\nnumerical methods: the Finite-Difference Time-Domain (FDTD) method and a\ncompact Pade scheme with filtering. Three benchmark problems are considered,\nranging from 1D free-space wave propagation to 2D Gaussian pulses in periodic\nand dielectric media. We assess the effectiveness of convergence-enhancing\nstrategies for PINNs, including random Fourier features, spatio-temporal\nperiodicity, and temporal causality training. An ablation study highlights that\narchitectural choices must align with the underlying physics. Additionally, we\nemploy a Neural Tangent Kernel framework to examine the spatio-temporal\nconvergence behavior of PINNs. Results show that convergence rates correlate\nwith error over time but not in space, revealing a limitation in how training\ndynamics allocate learning effort. Overall, this study demonstrates that PINNs,\nwhen properly configured, can match or surpass traditional solvers in accuracy\nand flexibility, though challenges remain in addressing spatial inhomogeneity\nand adapting training to localized complexity.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-04-16T14:56:17Z"}
{"aid":"http://arxiv.org/abs/2504.12158v1","title":"What is a monoid?","summary":"In many situations one encounters a notion that resembles that of a monoid.\nIt consists of a carrier and two operations that resemble a unit and a\nmultiplication, subject to three equations that resemble associativity and left\nand right unital laws. The question then arises whether this notion in fact\nthat of a monoid in a suitable sense. Category theorists have answered this\nquestion by providing a notion of monoid in a monoidal category, or more\ngenerally in a multicategory. While this encompasses many examples, it is\nunsuitable in other cases, such as the notion of relative monad, and the\nmodelling of call-by-push-value sequencing. In each of these examples, the\nleftmost and/or the rightmost factor of a multiplication or associativity law\nseems to be distinguished. To include such examples, we generalize the\nmulticategorical framework in two stages. Firstly, we move to the framework of\na left-skew multicategory (due to Bourke and Lack), which generalizes both\nmulticategory and left-skew monoidal category. The notion of monoid in this\nframework encompasses examples where only the leftmost factor is distinguished,\nsuch as the notion of relative monad. Secondly, we consider monoids in the\nnovel framework of a bi-skew multicategory. This encompasses examples where\nboth the leftmost and the rightmost factor are distinguished, such as the\nnotion of a category on a span, and the modelling of call-by-push-value\nsequencing. In the bi-skew framework (which is the most general), we give a\ncoherence result saying that a monoid corresponds to an unbiased monoid, i.e. a\nmap from the unit bi-skew multicategory.","main_category":"math.CT","categories":"math.CT,cs.PL,F.3.2","published":"2025-04-16T15:04:48Z"}
{"aid":"http://arxiv.org/abs/2504.12203v1","title":"Modality-Independent Explainable Detection of Inaccurate Organ\n  Segmentations Using Denoising Autoencoders","summary":"In radiation therapy planning, inaccurate segmentations of organs at risk can\nresult in suboptimal treatment delivery, if left undetected by the clinician.\nTo address this challenge, we developed a denoising autoencoder-based method to\ndetect inaccurate organ segmentations. We applied noise to ground truth organ\nsegmentations, and the autoencoders were tasked to denoise them. Through the\napplication of our method to organ segmentations generated on both MR and CT\nscans, we demonstrated that the method is independent of imaging modality. By\nproviding reconstructions, our method offers visual information about\ninaccurate regions of the organ segmentations, leading to more explainable\ndetection of suboptimal segmentations. We compared our method to existing\napproaches in the literature and demonstrated that it achieved superior\nperformance for the majority of organs.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-16T15:53:40Z"}
{"aid":"http://arxiv.org/abs/2504.12244v1","title":"Mobile Distributed MIMO (MD-MIMO) for NextG: Mobility Meets Cooperation\n  in Distributed Arrays","summary":"Distributed multiple-input multiple-output (D\\mbox{-}MIMO) is a promising\ntechnology to realize the promise of massive MIMO gains by fiber-connecting the\ndistributed antenna arrays, thereby overcoming the form factor limitations of\nco-located MIMO. In this paper, we introduce the concept of mobile D-MIMO\n(MD-MIMO) network, a further extension of the D-MIMO technology where\ndistributed antenna arrays are connected to the base station with a wireless\nlink allowing all radio network nodes to be mobile. This approach significantly\nimproves deployment flexibility and reduces operating costs, enabling the\nnetwork to adapt to the highly dynamic nature of next-generation (NextG)\nnetworks. We discuss use cases, system design, network architecture, and the\nkey enabling technologies for MD-MIMO. Furthermore, we investigate a case study\nof MD-MIMO for vehicular networks, presenting detailed performance evaluations\nfor both downlink and uplink. The results show that an MD-MIMO network can\nprovide substantial improvements in network throughput and reliability.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-16T16:48:29Z"}
{"aid":"http://arxiv.org/abs/2504.12256v1","title":"FLIP Reasoning Challenge","summary":"Over the past years, advances in artificial intelligence (AI) have\ndemonstrated how AI can solve many perception and generation tasks, such as\nimage classification and text writing, yet reasoning remains a challenge. This\npaper introduces the FLIP dataset, a benchmark for evaluating AI reasoning\ncapabilities based on human verification tasks on the Idena blockchain. FLIP\nchallenges present users with two orderings of 4 images, requiring them to\nidentify the logically coherent one. By emphasizing sequential reasoning,\nvisual storytelling, and common sense, FLIP provides a unique testbed for\nmultimodal AI systems. Our experiments evaluate state-of-the-art models,\nleveraging both vision-language models (VLMs) and large language models (LLMs).\nResults reveal that even the best open-sourced and closed-sourced models\nachieve maximum accuracies of 75.5% and 77.9%, respectively, in zero-shot\nsettings, compared to human performance of 95.3%. Captioning models aid\nreasoning models by providing text descriptions of images, yielding better\nresults than when using the raw images directly, 69.6% vs. 75.2% for Gemini 1.5\nPro. Combining the predictions from 15 models in an ensemble increases the\naccuracy to 85.2%. These findings highlight the limitations of existing\nreasoning models and the need for robust multimodal benchmarks like FLIP. The\nfull codebase and dataset will be available at\nhttps://github.com/aplesner/FLIP-Reasoning-Challenge.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-16T17:07:16Z"}
{"aid":"http://arxiv.org/abs/2504.12278v1","title":"Wormholes with Ends of the World","summary":"We study classical wormhole solutions in 3D gravity with end-of-the-world\n(EOW) branes, conical defects, kinks, and punctures. These solutions compute\nstatistical averages of an ensemble of boundary conformal field theories\n(BCFTs) related to universal asymptotics of OPE data extracted from 2D\nconformal bootstrap. Conical defects connect BCFT bulk operators; branes join\nBCFT boundary intervals with identical boundary conditions; kinks (1D defects\nalong branes) link BCFT boundary operators; and punctures (0D defects) are\nendpoints where conical defects terminate on branes. We provide evidence for a\ncorrespondence between the gravity theory and the ensemble. In particular, the\nagreement of $g$-function dependence results from an underlying topological\naspect of the on-shell EOW brane action, from which a BCFT analogue of the\nSchlenker-Witten theorem also follows.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-16T17:38:27Z"}
{"aid":"http://arxiv.org/abs/2504.12664v1","title":"Autonomous Drone for Dynamic Smoke Plume Tracking","summary":"This paper presents a novel autonomous drone-based smoke plume tracking\nsystem capable of navigating and tracking plumes in highly unsteady atmospheric\nconditions. The system integrates advanced hardware and software and a\ncomprehensive simulation environment to ensure robust performance in controlled\nand real-world settings. The quadrotor, equipped with a high-resolution imaging\nsystem and an advanced onboard computing unit, performs precise maneuvers while\naccurately detecting and tracking dynamic smoke plumes under fluctuating\nconditions. Our software implements a two-phase flight operation, i.e.,\ndescending into the smoke plume upon detection and continuously monitoring the\nsmoke movement during in-plume tracking. Leveraging Proportional\nIntegral-Derivative (PID) control and a Proximal Policy Optimization based Deep\nReinforcement Learning (DRL) controller enables adaptation to plume dynamics.\nUnreal Engine simulation evaluates performance under various smoke-wind\nscenarios, from steady flow to complex, unsteady fluctuations, showing that\nwhile the PID controller performs adequately in simpler scenarios, the\nDRL-based controller excels in more challenging environments. Field tests\ncorroborate these findings. This system opens new possibilities for drone-based\nmonitoring in areas like wildfire management and air quality assessment. The\nsuccessful integration of DRL for real-time decision-making advances autonomous\ndrone control for dynamic environments.","main_category":"cs.RO","categories":"cs.RO,physics.flu-dyn","published":"2025-04-17T05:50:15Z"}
{"aid":"http://arxiv.org/abs/2504.12699v1","title":"Unsupervised Cross-Domain 3D Human Pose Estimation via\n  Pseudo-Label-Guided Global Transforms","summary":"Existing 3D human pose estimation methods often suffer in performance, when\napplied to cross-scenario inference, due to domain shifts in characteristics\nsuch as camera viewpoint, position, posture, and body size. Among these\nfactors, camera viewpoints and locations {have been shown} to contribute\nsignificantly to the domain gap by influencing the global positions of human\nposes. To address this, we propose a novel framework that explicitly conducts\nglobal transformations between pose positions in the camera coordinate systems\nof source and target domains. We start with a Pseudo-Label Generation Module\nthat is applied to the 2D poses of the target dataset to generate pseudo-3D\nposes. Then, a Global Transformation Module leverages a human-centered\ncoordinate system as a novel bridging mechanism to seamlessly align the\npositional orientations of poses across disparate domains, ensuring consistent\nspatial referencing. To further enhance generalization, a Pose Augmentor is\nincorporated to address variations in human posture and body size. This process\nis iterative, allowing refined pseudo-labels to progressively improve guidance\nfor domain adaptation. Our method is evaluated on various cross-dataset\nbenchmarks, including Human3.6M, MPI-INF-3DHP, and 3DPW. The proposed method\noutperforms state-of-the-art approaches and even outperforms the target-trained\nmodel.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T06:57:20Z"}
{"aid":"http://arxiv.org/abs/2504.12764v1","title":"GraphOmni: A Comprehensive and Extendable Benchmark Framework for Large\n  Language Models on Graph-theoretic Tasks","summary":"In this paper, we presented GraphOmni, a comprehensive benchmark framework\nfor systematically evaluating the graph reasoning capabilities of LLMs. By\nanalyzing critical dimensions, including graph types, serialization formats,\nand prompt schemes, we provided extensive insights into the strengths and\nlimitations of current LLMs. Our empirical findings emphasize that no single\nserialization or prompting strategy consistently outperforms others. Motivated\nby these insights, we propose a reinforcement learning-based approach that\ndynamically selects the best serialization-prompt pairings, resulting in\nsignificant accuracy improvements. GraphOmni's modular and extensible design\nestablishes a robust foundation for future research, facilitating advancements\ntoward general-purpose graph reasoning models.","main_category":"cs.LG","categories":"cs.LG,cs.DM","published":"2025-04-17T09:01:16Z"}
{"aid":"http://arxiv.org/abs/2504.12776v1","title":"StorySets: Ordering Curves and Dimensions for Visualizing Uncertain Sets\n  and Multi-Dimensional Discrete Data","summary":"We propose a method for visualizing uncertain set systems, which differs from\nprevious set visualization approaches that are based on certainty (an element\neither belongs to a set or not). Our method is inspired by storyline\nvisualizations and parallel coordinate plots: (a) each element is represented\nby a vertical glyph, subdivided into bins that represent different levels of\nuncertainty; (b) each set is represented by an x-monotone curve that traverses\nelement glyphs through the bins representing the level of uncertainty of their\nmembership. Our implementation also includes optimizations to reduce visual\ncomplexity captured by the number of turns for the set curves and the number of\ncrossings. Although several of the natural underlying optimization problems are\nNP-hard in theory (e.g., optimal element order, optimal set order), in\npractice, we can compute near-optimal solutions with respect to curve crossings\nwith the help of a new exact algorithm for optimally ordering set curves within\neach element's bins. With these optimizations, the proposed method makes it\neasy to see set containment (the smaller set's curve is strictly below the\nlarger set's curve). A brief design-space exploration using uncertain\nset-membership data, as well as multi-dimensional discrete data, shows the\nflexibility of the proposed approach.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-17T09:18:02Z"}
{"aid":"http://arxiv.org/abs/2504.12785v1","title":"New developments in MatCont: delay equation importer and Lyapunov\n  exponents","summary":"MatCont is a powerful toolbox for numerical bifurcation analysis focussing on\nsmooth ODEs. A user can study equilibria, periodic and connecting orbits, and\ntheir stability and bifurcations. Here, we report on additional features in\nversion 7p6. The first is a delay equation importer enabling MatCont users to\nstudy a much larger class of models, namely delay equations with finite delay\n(including delay differential and renewal equations). This importer translates\nthe delay equation into a system of ODEs using a pseudospectral approximation\nwith an order specified by the user. We also implemented Lyapunov exponent\ncomputations, event functions for Poincar\\'e maps, and enhanced homoclinic\ncontinuation. We demonstrate these features with test cases, such as the\nMackey-Glass equation and a renewal equation, and provide additional examples\nin online tutorials.","main_category":"math.DS","categories":"math.DS","published":"2025-04-17T09:33:27Z"}
{"aid":"http://arxiv.org/abs/2504.12786v1","title":"Magnetized black holes in Kaluza-Klein theory and the Kerr/CFT\n  correspondence","summary":"In this work, we examine the Kerr/CFT correspondence for magnetized black\nholes arising from Kaluza--Klein theory, demonstrating that Kerr/CFT holography\npersists beyond the traditional Einstein--Maxwell framework. Notably, unlike in\nthe Einstein--Maxwell case, the massless neutral scalar field equation here is\nfully separable into radial and angular parts. This separability reveals a\nhidden conformal symmetry in the near--horizon, low--frequency regime,\nproviding further support for the robustness of Kerr/CFT dualities in extended\ngravitational theories.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-17T09:33:54Z"}
{"aid":"http://arxiv.org/abs/2504.12791v1","title":"Probing the topological protection of edge states in multilayer tungsten\n  ditelluride with the superconducting proximity effect","summary":"The topology of WTe2, a transition metal dichalcogenide with large spin-orbit\ninteractions, is thought to combine type II Weyl semimetal and second-order\ntopological insulator (SOTI) character. The SOTI character should endow WTe2\nmultilayer crystals with topologically protected helical states at its hinges,\nand, indeed, 1D states have been detected thanks to Josephson interferometry.\nHowever, the immunity to backscattering conferred to those states by their\nhelical nature has so far not been tested. To probe the topological protection\nof WTe2 edge states, we have fabricated Superconducting Quantum Interference\nDevices (SQUIDs) in which the supercurrent through a junction on the crystal\nedge interferes with the supercurrent through a junction in the bulk of the\ncrystal. We find behaviors ranging from a Symmetric SQUID pattern to asymmetric\nSQUID patterns, including one in which the modulation by magnetic field reveals\na sawtooth-like supercurrent versus phase relation for the edge junction,\ndemonstrating that the supercurrent at the edge is carried by ballistic\nchannels over 600 nm, a tell-tale sign of the SOTI character of WTe2.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-17T09:43:04Z"}
{"aid":"http://arxiv.org/abs/2504.12817v1","title":"Explainable Scene Understanding with Qualitative Representations and\n  Graph Neural Networks","summary":"This paper investigates the integration of graph neural networks (GNNs) with\nQualitative Explainable Graphs (QXGs) for scene understanding in automated\ndriving. Scene understanding is the basis for any further reactive or proactive\ndecision-making. Scene understanding and related reasoning is inherently an\nexplanation task: why is another traffic participant doing something, what or\nwho caused their actions? While previous work demonstrated QXGs' effectiveness\nusing shallow machine learning models, these approaches were limited to\nanalysing single relation chains between object pairs, disregarding the broader\nscene context. We propose a novel GNN architecture that processes entire graph\nstructures to identify relevant objects in traffic scenes. We evaluate our\nmethod on the nuScenes dataset enriched with DriveLM's human-annotated\nrelevance labels. Experimental results show that our GNN-based approach\nachieves superior performance compared to baseline methods. The model\neffectively handles the inherent class imbalance in relevant object\nidentification tasks while considering the complete spatial-temporal\nrelationships between all objects in the scene. Our work demonstrates the\npotential of combining qualitative representations with deep learning\napproaches for explainable scene understanding in autonomous driving systems.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.CV","published":"2025-04-17T10:21:30Z"}
{"aid":"http://arxiv.org/abs/2504.12822v1","title":"Miura transformation in bidifferential calculus and a vectorial Darboux\n  transformation for the Fokas-Lenells equation","summary":"Using a general result of bidifferential calculus and recent results of other\nauthors, a vectorial binary Darboux transformation is derived for the first\nmember of the \"negative\" part of the potential Kaup-Newell hierarchy, which is\na system of two coupled Fokas-Lenells equations. Miura transformations are\nfound from the latter to the first member of the negative part of the AKNS\nhierarchy and also to its \"pseudodual\". The reduction to the Fokas-Lenells\nequation is implemented and exact solutions with a plane wave seed generated.","main_category":"nlin.SI","categories":"nlin.SI,math-ph,math.MP","published":"2025-04-17T10:32:39Z"}
{"aid":"http://arxiv.org/abs/2504.12832v1","title":"Physics of an AMOC Overshoot in a Box Model","summary":"Recently the global average temperature has temporarily exceeded the\n1.5{\\deg}C goal of the Paris Agreement, and so an overshoot of various climate\ntipping elements becomes increasingly likely. In this study we analyze the\nphysical processes of an overshoot of the Atlantic Meridional Overturning\nCirculation (AMOC), one of the major tipping elements, using a conceptual box\nmodel. Here either the atmospheric temperature above the North Atlantic, or the\nfreshwater forcing into the North Atlantic overshoot their respective critical\nboundaries. In both cases a higher forcing rate can prevent a collapse of the\nAMOC, since a higher rate of forcing causes initially a fresher North Atlantic,\nwhich in turn results in a higher northward transport by the subtropical gyre\nsupplementing the salinity loss in time. For small exceedance amplitudes the\nAMOC is still resilient as the forcing rates can be low and so other state\nvariables outside of the North Atlantic can adjust. Contrarily, for larger\novershoots the trajectories are dynamically similar and we find a lower limit\nin volume and exceedance time for respectively freshwater and temperature\nforcing in order to prevent a collapse. Moreover, for a large overshoot an\nincreased air-sea temperature coupling has a destabilizing effect, while the\nreverse holds for an overshoot close to the tipping point. The understanding of\nthe physics of the AMOC overshoot behavior is important for interpreting\nresults of Earth System Models and for evaluating the effects of mitigation and\nintervention strategies.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-17T10:46:21Z"}
{"aid":"http://arxiv.org/abs/2504.12835v1","title":"Kinetic simulated annealing optimization with entropy-based cooling rate","summary":"We present a modified simulated annealing method with a dynamical choice of\nthe cooling temperature. The latter is determined via a closed-loop control and\nis proven to yield exponential decay of the entropy of the particle system. The\nanalysis is carried out through kinetic equations for interacting particle\nsystems describing the simulated annealing method in an extended phase space.\nDecay estimates are derived under the quasi-invariant scaling of the resulting\nsystem of Boltzmann-type equations to assess the consistency with their\nmean-field limit. Numerical results are provided to illustrate and support the\ntheoretical findings.","main_category":"math.OC","categories":"math.OC,nlin.AO","published":"2025-04-17T10:50:24Z"}
{"aid":"http://arxiv.org/abs/2504.12841v1","title":"ALT: A Python Package for Lightweight Feature Representation in Time\n  Series Classification","summary":"We introduce ALT, an open-source Python package created for efficient and\naccurate time series classification (TSC). The package implements the adaptive\nlaw-based transformation (ALT) algorithm, which transforms raw time series data\ninto a linearly separable feature space using variable-length shifted time\nwindows. This adaptive approach enhances its predecessor, the linear law-based\ntransformation (LLT), by effectively capturing patterns of varying temporal\nscales. The software is implemented for scalability, interpretability, and ease\nof use, achieving state-of-the-art performance with minimal computational\noverhead. Extensive benchmarking on real-world datasets demonstrates the\nutility of ALT for diverse TSC tasks in physics and related domains.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV,cs.MS,stat.ML","published":"2025-04-17T10:57:29Z"}
{"aid":"http://arxiv.org/abs/2504.12843v1","title":"Quadratic subproduct systems, free products, and their C*-algebras","summary":"Motivated by the interplay between quadratic algebras, noncommutative\ngeometry, and operator theory, we introduce the notion of quadratic subproduct\nsystems of Hilbert spaces. Specifically, we study the subproduct systems\ninduced by a finite number of complex quadratic polynomials in noncommuting\nvariables, and describe their Toeplitz and Cuntz--Pimsner algebras. Inspired by\nthe theory of graded associative algebras, we define a free product operation\nin the category of subproduct systems and show that this corresponds to the\nreduced free product of the Toeplitz algebras. Finally, we obtain results about\nthe K-theory of the Toeplitz and Cuntz--Pimsner algebras of a large class of\nquadratic subproduct systems.","main_category":"math.OA","categories":"math.OA","published":"2025-04-17T10:57:58Z"}
{"aid":"http://arxiv.org/abs/2504.12846v1","title":"Timing via Pinwheel Double Categories","summary":"We discuss string diagrams for timed process theories -- represented by\nduoidally-graded symmetric strict monoidal categories -- built upon the string\ndiagrams of pinwheel double categories.","main_category":"math.CT","categories":"math.CT,cs.LO","published":"2025-04-17T11:02:52Z"}
{"aid":"http://arxiv.org/abs/2504.12867v1","title":"EmoVoice: LLM-based Emotional Text-To-Speech Model with Freestyle Text\n  Prompting","summary":"Human speech goes beyond the mere transfer of information; it is a profound\nexchange of emotions and a connection between individuals. While Text-to-Speech\n(TTS) models have made huge progress, they still face challenges in controlling\nthe emotional expression in the generated speech. In this work, we propose\nEmoVoice, a novel emotion-controllable TTS model that exploits large language\nmodels (LLMs) to enable fine-grained freestyle natural language emotion\ncontrol, and a phoneme boost variant design that makes the model output phoneme\ntokens and audio tokens in parallel to enhance content consistency, inspired by\nchain-of-thought (CoT) and modality-of-thought (CoM) techniques. Besides, we\nintroduce EmoVoice-DB, a high-quality 40-hour English emotion dataset featuring\nexpressive speech and fine-grained emotion labels with natural language\ndescriptions. EmoVoice achieves state-of-the-art performance on the English\nEmoVoice-DB test set using only synthetic training data, and on the Chinese\nSecap test set using our in-house data. We further investigate the reliability\nof existing emotion evaluation metrics and their alignment with human\nperceptual preferences, and explore using SOTA multimodal LLMs GPT-4o-audio and\nGemini to assess emotional speech. Demo samples are available at\nhttps://anonymous.4open.science/r/EmoVoice-DF55. Dataset, code, and checkpoints\nwill be released.","main_category":"eess.AS","categories":"eess.AS,cs.AI,cs.CL","published":"2025-04-17T11:50:04Z"}
{"aid":"http://arxiv.org/abs/2504.12880v1","title":"Can Masked Autoencoders Also Listen to Birds?","summary":"Masked Autoencoders (MAEs) pretrained on AudioSet fail to capture the\nfine-grained acoustic characteristics of specialized domains such as\nbioacoustic monitoring. Bird sound classification is critical for assessing\nenvironmental health, yet general-purpose models inadequately address its\nunique acoustic challenges. To address this, we introduce Bird-MAE, a\ndomain-specialized MAE pretrained on the large-scale BirdSet dataset. We\nexplore adjustments to pretraining, fine-tuning and utilizing frozen\nrepresentations. Bird-MAE achieves state-of-the-art results across all BirdSet\ndownstream tasks, substantially improving multi-label classification\nperformance compared to the general-purpose Audio-MAE baseline. Additionally,\nwe propose prototypical probing, a parameter-efficient method for leveraging\nMAEs' frozen representations. Bird-MAE's prototypical probes outperform linear\nprobing by up to 37\\% in MAP and narrow the gap to fine-tuning to approximately\n3\\% on average on BirdSet.","main_category":"cs.LG","categories":"cs.LG,cs.SD,eess.AS","published":"2025-04-17T12:13:25Z"}
{"aid":"http://arxiv.org/abs/2504.12967v1","title":"Krysalis Hand: A Lightweight, High-Payload, 18-DoF Anthropomorphic\n  End-Effector for Robotic Learning and Dexterous Manipulation","summary":"This paper presents the Krysalis Hand, a five-finger robotic end-effector\nthat combines a lightweight design, high payload capacity, and a high number of\ndegrees of freedom (DoF) to enable dexterous manipulation in both industrial\nand research settings. This design integrates the actuators within the hand\nwhile maintaining an anthropomorphic form. Each finger joint features a\nself-locking mechanism that allows the hand to sustain large external forces\nwithout active motor engagement. This approach shifts the payload limitation\nfrom the motor strength to the mechanical strength of the hand, allowing the\nuse of smaller, more cost-effective motors. With 18 DoF and weighing only 790\ngrams, the Krysalis Hand delivers an active squeezing force of 10 N per finger\nand supports a passive payload capacity exceeding 10 lbs. These characteristics\nmake Krysalis Hand one of the lightest, strongest, and most dexterous robotic\nend-effectors of its kind. Experimental evaluations validate its ability to\nperform intricate manipulation tasks and handle heavy payloads, underscoring\nits potential for industrial applications as well as academic research. All\ncode related to the Krysalis Hand, including control and teleoperation, is\navailable on the project GitHub repository:\nhttps://github.com/Soltanilara/Krysalis_Hand","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-17T14:19:26Z"}
{"aid":"http://arxiv.org/abs/2504.12974v1","title":"L-systems with Multiplication Operator and c-Entropy","summary":"In this note, we utilize the concepts of c-entropy and the dissipation\ncoefficient in connection with canonical L-systems based on the multiplication\n(by a scalar) operator. Additionally, we examine the coupling of such L-systems\nand derive explicit formulas for the associated c-entropy and dissipation\ncoefficient. In this context, we also introduce the concept of a skew-adjoint\nL-system and analyze its coupling with the original L-system.","main_category":"math.SP","categories":"math.SP","published":"2025-04-17T14:27:10Z"}
{"aid":"http://arxiv.org/abs/2504.12977v1","title":"A Phenomenological Approach to Analyzing User Queries in IT Systems\n  Using Heidegger's Fundamental Ontology","summary":"This paper presents a novel research analytical IT system grounded in Martin\nHeidegger's Fundamental Ontology, distinguishing between beings (das Seiende)\nand Being (das Sein). The system employs two modally distinct, descriptively\ncomplete languages: a categorical language of beings for processing user inputs\nand an existential language of Being for internal analysis. These languages are\nbridged via a phenomenological reduction module, enabling the system to analyze\nuser queries (including questions, answers, and dialogues among IT\nspecialists), identify recursive and self-referential structures, and provide\nactionable insights in categorical terms. Unlike contemporary systems limited\nto categorical analysis, this approach leverages Heidegger's phenomenological\nexistential analysis to uncover deeper ontological patterns in query\nprocessing, aiding in resolving logical traps in complex interactions, such as\nmetaphor usage in IT contexts. The path to full realization involves\nformalizing the language of Being by a research team based on Heidegger's\nFundamental Ontology; given the existing completeness of the language of\nbeings, this reduces the system's computability to completeness, paving the way\nfor a universal query analysis tool. The paper presents the system's\narchitecture, operational principles, technical implementation, use\ncases--including a case based on real IT specialist dialogues--comparative\nevaluation with existing tools, and its advantages and limitations.","main_category":"cs.SE","categories":"cs.SE,cs.AI,cs.CL,cs.HC","published":"2025-04-17T14:29:25Z"}
{"aid":"http://arxiv.org/abs/2504.12978v1","title":"X-ray linear dichroic orientation tomography: reconstruction of\n  nanoscale three-dimensional orientation fields","summary":"Properties in crystalline and ordered materials tend to be anisotropic, with\ntheir orientation affecting the macroscopic behavior and functionality of\nmaterials. The ability to image the orientation of anisotropic material\nproperties in three dimensions (3D) is fundamental for the understanding and\nfunctionality-driven development of novel materials. With the development of X\nray linear dichroic orientation tomography (XL DOT), it is now possible to\nnon-destructively map three-dimensional (3D) orientation fields in\nmicrometer-sized samples. In this work, we present the iterative,\ngradient-based reconstruction algorithm behind XL DOT that can be used to map\norientations based on linear dichroism in 3D. As linear dichroism can be\nexhibited by a broad spectrum of materials, XL DOT can be used to map, for\nexample, crystal orientations as well as ferroic alignment, such as\nferroelectric and antiferromagnetic order. We demonstrate the robustness of\nthis technique for orientation fields that exhibit smoothly varying and\ngranular configurations, and subsequently identify and discuss optimal\ngeometries for experimental data acquisition and optimal conditions for the\nreconstruction. We anticipate that this technique will be instrumental in\nenabling a deeper understanding of the relationship between material structures\nand their functionality, quantifying, for example, the orientation of charge\ndistributions and magnetic anisotropies at the nanoscale in a wide variety of\nsystems - from functional to energy materials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-17T14:31:25Z"}
{"aid":"http://arxiv.org/abs/2504.12998v1","title":"Automated Generation of Commit Messages in Software Repositories","summary":"Commit messages are crucial for documenting software changes, aiding in\nprogram comprehension and maintenance. However, creating effective commit\nmessages is often overlooked by developers due to time constraints and varying\nlevels of documentation skills. Our research presents an automated approach to\ngenerate commit messages using Machine Learning (ML) and Natural Language\nProcessing (NLP) by developing models that use techniques such as Logistic\nRegression with TF-IDF and Word2Vec, as well as more sophisticated methods like\nLSTM. We used the dataset of code changes and corresponding commit messages\nthat was used by Liu et al., which we used to train and evaluate ML/NLP models\nand was chosen because it is extensively used in previous research, also for\ncomparability in our study. The objective was to explore which ML/NLP\ntechniques generate the most effective, clear, and concise commit messages that\naccurately reflect the code changes. We split the dataset into training,\nvalidation, and testing sets and used these sets to evaluate the performance of\neach model using qualitative and quantitative evaluation methods. Our results\nreveal a spectrum of effectiveness among these models, with the highest BLEU\nscore achieved being 16.82, showcasing the models' capability in automating a\nclear and concise commit message generation. Our paper offers insights into the\ncomparative effectiveness of different machine learning models for automating\ncommit message generation in software development, aiming to enhance the\noverall practice of code documentation. The source code is available at\nhttps://doi.org/10.5281/zenodo.10888106.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-17T15:08:05Z"}
{"aid":"http://arxiv.org/abs/2504.13005v1","title":"Knot Floer homology of positive braids","summary":"We compute the next-to-top term of knot Floer homology for positive braid\nlinks. The rank is 1 for any prime positive braid knot. We give some examples\nof fibered positive links that are not positive braids.","main_category":"math.GT","categories":"math.GT","published":"2025-04-17T15:15:06Z"}
{"aid":"http://arxiv.org/abs/2504.13012v1","title":"Hopf Exceptional Points","summary":"Exceptional points at which eigenvalues and eigenvectors of non-Hermitian\nmatrices coalesce are ubiquitous in the description of a wide range of\nplatforms from photonic or mechanical metamaterials to open quantum systems.\nHere, we introduce a class of Hopf exceptional points (HEPs) that are protected\nby the Hopf invariants (including the higher-dimensional generalizations) and\nwhich exhibit phenomenology sharply distinct from conventional exceptional\npoints. Saliently, owing to their $\\mathbb{Z}_2$ topological invariant related\nto the Witten anomaly, three-fold HEPs and symmetry-protected five-fold HEPs\nact as their own ``antiparticles\". Furthermore, based on higher homotopy groups\nof spheres, we predict the existence of multifold HEPs and symmetry-protected\nHEPs with non-Hermitian topology captured by a range of finite groups (such as\n$\\mathbb{Z}_3$, $\\mathbb{Z}_{12}$, or $\\mathbb{Z}_{24}$) beyond the periodic\ntable of Bernard-LeClair symmetry classes.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,physics.optics,quant-ph","published":"2025-04-17T15:19:05Z"}
{"aid":"http://arxiv.org/abs/2504.13016v1","title":"ORIS allocation to minimize the outage probability in a multi-user VLC\n  scenario","summary":"Visible Light Communication (VLC) is a promising solution to address the\ngrowing demand for wireless data, leveraging the widespread use of\nlight-emitting diodes (LEDs) as transmitters. However, its deployment is\nchallenged by link blockages that cause connectivity outages. Optical\nreconfigurable intelligent surfaces (ORISs) have recently emerged as a solution\nto mitigate these disruptions. This work considers a multi-user VLC system and\ninvestigates the optimal association of ORISs to LEDs and users to minimize the\noutage probability while limiting the number of ORISs used. Numerical results\nfrom our proposed optimization algorithm demonstrate that using ORISs can\nreduce the outage probability by up to 85% compared to a no-ORIS scenario.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-17T15:24:25Z"}
{"aid":"http://arxiv.org/abs/2504.13029v1","title":"Three-dimensional canonical quantum plasmonics for finite media: exact\n  solution in terms of the classical Green tensor","summary":"This article presents a comprehensive three-dimensional canonical\nquantization to treat quantum plasmonics for finite metallic or dielectric\nmedia of arbitrary shape. We use a microscopic model for the dissipative and\ndispersive medium coupled with the electromagnetic field, which is justified by\nthe fact that if one integrates the degrees of freedom of the medium, one\nobtains the macroscopic Maxwell equations. Its quantization features a\nHamiltonian formulation having the form of two infinite harmonic oscillators\ncharacterized by a double continuum. The diagonalized Hamiltonian is quantized\nby the correspondence principle, introducing creation-annihilation operators in\na bosonic Fock space. The diagonal quantum Hamiltonian is the sum of two terms\ncorresponding to the two continua. The physical observables, like, e.g., the\nelectric field, are also the sum of two terms corresponding to the two\ncontinua, one of which had been omitted in the literature geared for an\ninfinite bulk medium. In a second step, we show that the electric field\noperator can by written as linear combinations of the creation-annihilation\noperators with coefficients that satisfy integral equations of Fredholm type.\nWe show that the solution of these equations can be expressed in terms of the\nclassical Green tensor of the medium satisfying the Sommerfeld radiation\ncondition. Finally, we consider the Purcell effect for the spontaneous emission\nof an atom close to the medium. We show that through an exact compensation of\nsome terms, the Purcell factor for the system with the double continuum is\nproportional to the imaginary part of the Green tensor, which defines the local\ndensity of states. This result has the same form as the one obtained in the\nliterature for bulk systems that involve a single continuum and a small\ndissipative background extending to infinity, and can be seen as a\njustification of this approach.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T15:39:29Z"}
{"aid":"http://arxiv.org/abs/2504.13032v1","title":"InstructRAG: Leveraging Retrieval-Augmented Generation on Instruction\n  Graphs for LLM-Based Task Planning","summary":"Recent advancements in large language models (LLMs) have enabled their use as\nagents for planning complex tasks. Existing methods typically rely on a\nthought-action-observation (TAO) process to enhance LLM performance, but these\napproaches are often constrained by the LLMs' limited knowledge of complex\ntasks. Retrieval-augmented generation (RAG) offers new opportunities by\nleveraging external databases to ground generation in retrieved information. In\nthis paper, we identify two key challenges (enlargability and transferability)\nin applying RAG to task planning. We propose InstructRAG, a novel solution\nwithin a multi-agent meta-reinforcement learning framework, to address these\nchallenges. InstructRAG includes a graph to organize past instruction paths\n(sequences of correct actions), an RL-Agent with Reinforcement Learning to\nexpand graph coverage for enlargability, and an ML-Agent with Meta-Learning to\nimprove task generalization for transferability. The two agents are trained\nend-to-end to optimize overall planning performance. Our experiments on four\nwidely used task planning datasets demonstrate that InstructRAG significantly\nenhances performance and adapts efficiently to new tasks, achieving up to a\n19.2% improvement over the best existing approach.","main_category":"cs.AI","categories":"cs.AI,cs.IR","published":"2025-04-17T15:41:39Z"}
{"aid":"http://arxiv.org/abs/2504.13057v1","title":"Covariate balancing estimation and model selection for\n  difference-in-differences approach","summary":"In causal inference, remarkable progress has been made in\ndifference-in-differences (DID) approaches to estimate the average effect of\ntreatment on the treated (ATT). Of these, the semiparametric DID (SDID)\napproach incorporates a propensity score analysis into the DID setup. Supposing\nthat the ATT is a function of covariates, we estimate it by weighting the\ninverse of the propensity score. As one method to make the estimation robust to\nthe propensity score modeling, we incorporate covariate balancing. Then, by\nattentively constructing the moment conditions used in the covariate balancing,\nwe show that the proposed estimator has doubly robustness. In addition to the\nestimation, model selection is also addressed. In practice, covariate selection\nis an essential task in statistical analysis, but even in the basic setting of\nthe SDID approach, there are no reasonable information criteria. Therefore, we\nderive a model selection criterion as an asymptotically bias-corrected\nestimator of risk based on the loss function used in the SDID estimation. As a\nresult, we show that a penalty term is derived that is considerably different\nfrom almost twice the number of parameters that often appears in AIC-type\ninformation criteria. Numerical experiments show that the proposed method\nestimates the ATT robustly compared to the method using propensity scores given\nby the maximum likelihood estimation (MLE), and that the proposed criterion\nclearly reduces the risk targeted in the SDID approach compared to the\nintuitive generalization of the existing information criterion. In addition,\nreal data analysis confirms that there is a large difference between the\nresults of the proposed method and the existing method.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-17T16:11:42Z"}
{"aid":"http://arxiv.org/abs/2504.13070v1","title":"A quadratic estimator view of the transfer function correction in\n  intensity mapping surveys","summary":"In single dish neutral hydrogen (HI) intensity mapping, signal separation\nmethods such as Principal Component Analysis (PCA) are used to clean the\nastrophysical foregrounds. PCA induces a signal loss in the estimated power\nspectrum, which can be corrected by a transfer function (TF). By injecting mock\nsignals of HI into the data and performing the PCA cleaning, we can use the\ncleaned mock HI signal to cross-correlate with the original mock, and estimate\nthe signal loss as a TF, $T(\\vec{k})$. As expected, a correction of\n${T}(\\vec{k})^{-1}$ restores the cross-power between the HI and optical\ngalaxies. However, contrary to intuition, the HI auto-power also requires a\n${T}(\\vec{k})^{-1}$ correction, not ${T}(\\vec{k})^{-2}$. The\n${T}(\\vec{k})^{-1}$ correction is only known empirically through simulations.\nIn this Letter, we show that the ${T}(\\vec{k})^{-1}$ correction in auto-power\nis universal, and can be analytically proven using the quadratic estimator\nformalism through window function normalisation. The normalisation can also be\nused to determine the TF correction for any type of linear process. Using the\nwindow function, we demonstrate that PCA induces mode-mixing in the power\nspectrum estimation, which may lead to biases in the model inference.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-17T16:31:14Z"}
{"aid":"http://arxiv.org/abs/2504.13084v1","title":"Proca theory of four-dimensional regularized Gauss-Bonnet gravity and\n  black holes with primary hair","summary":"We introduce a novel, well-defined four-dimensional regularized Gauss-Bonnet\ntheory of gravity by applying a dimensional regularization procedure. The\nresulting theory is a vector-tensor theory within the generalized Proca class.\nWe then consider the static spherically symmetric solutions of this theory and\nfind black hole solutions that acquire primary hair. Notably, one of the\nintegration constants associated with the Proca field is not manifest in the\noriginal metric, but under a disformal transformation of the seed solution, it\nemerges as a second, independent primary hair. This additional hair acts as an\neffective cosmological constant in the disformed geometry, even in the absence\nof a bare cosmological constant term. We further generalize these black hole\nsolutions to include electromagnetic charges and effects related to the\nscalar-tensor counterparts of the regularized Gauss-Bonnet theory. We discuss\nthe implications of our findings to observations.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-17T16:51:57Z"}
{"aid":"http://arxiv.org/abs/2504.13093v1","title":"A lattice point counting approach for the study of the number of\n  self-avoiding walks on $\\mathbb{Z}^{d}$","summary":"We reduce the problem of counting self-avoiding walks in the square lattice\nto a problem of counting the number of integral points in multidimensional\ndomains. We obtain an asymptotic estimate of the number of self-avoiding walks\nof length $n$ in the square lattice. This new formalism gives a natural and\nunified setting in order to study the properties the number of self-avoidings\nwalks in the lattice $\\mathbb{Z}^{d}$ of any dimension $d\\geq 2$.","main_category":"math.PR","categories":"math.PR,math.CO,math.NT","published":"2025-04-17T16:59:16Z"}
{"aid":"http://arxiv.org/abs/2504.13106v1","title":"Intersection of non-degenerate Hermitian variety and cubic hypersurface","summary":"Edoukou, Ling and Xing in 2010, conjectured that in\n\\mathbb{P}^n(\\mathbb{F}_{q^2}), n \\geq 3, the maximum number of common points\nof a non-degenerate Hermitian variety \\mathcal{U}_n and a hypersurface of\ndegree d is achieved only when the hypersurface is a union of d distinct\nhyperplanes meeting in a common linear space \\Pi_{n-2} of codimension 2 such\nthat \\Pi_{n-2} \\cap \\mathcal{U}_n is a non-degenerate Hermitian variety.\nFurthermore, these d hyperplanes are tangent to \\mathcal{U}_n if n is odd and\nnon-tangent if n is even. In this paper, we show that the conjecture is true\nfor d = 3 and q \\geq 7.","main_category":"math.AG","categories":"math.AG","published":"2025-04-17T17:19:04Z"}
{"aid":"http://arxiv.org/abs/2504.13137v1","title":"Integral formulas for hypersurfaces in cones and related questions","summary":"We discuss the validity of Minkowski integral identities for hypersurfaces\ninside a cone, intersecting the boundary of the cone orthogonally. In doing so\nwe correct a formula provided in [3]. Then we study rigidity results for\nconstant mean curvature graphs proving the precise statement of a result given\nin [9] and [10]. Finally we provide an integral estimate for stable constant\nmean curvature hypersurfaces in cones.","main_category":"math.AP","categories":"math.AP","published":"2025-04-17T17:48:27Z"}
{"aid":"http://arxiv.org/abs/2504.13151v1","title":"MIB: A Mechanistic Interpretability Benchmark","summary":"How can we know whether new mechanistic interpretability methods achieve real\nimprovements? In pursuit of meaningful and lasting evaluation standards, we\npropose MIB, a benchmark with two tracks spanning four tasks and five models.\nMIB favors methods that precisely and concisely recover relevant causal\npathways or specific causal variables in neural language models. The circuit\nlocalization track compares methods that locate the model components - and\nconnections between them - most important for performing a task (e.g.,\nattribution patching or information flow routes). The causal variable\nlocalization track compares methods that featurize a hidden vector, e.g.,\nsparse autoencoders (SAEs) or distributed alignment search (DAS), and locate\nmodel features for a causal variable relevant to the task. Using MIB, we find\nthat attribution and mask optimization methods perform best on circuit\nlocalization. For causal variable localization, we find that the supervised DAS\nmethod performs best, while SAE features are not better than neurons, i.e.,\nstandard dimensions of hidden vectors. These findings illustrate that MIB\nenables meaningful comparisons of methods, and increases our confidence that\nthere has been real progress in the field.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-17T17:55:45Z"}
{"aid":"http://arxiv.org/abs/2504.13156v1","title":"Gravitational wave anisotropies from axion inflation","summary":"An important prediction of inflation is the production of a primordial\nstochastic gravitational wave background. Observing this background is\nchallenging due to the weakness of the signal and the simultaneous presence of\nan astrophysical background generated by many unresolved late-time sources. One\npossible way to distinguish between the two is to examine their anisotropies.\nIn this paper we calculate the primordial correlation function of gravitational\nwave anisotropies in the cosmological background generated by axion inflation,\nwhere the inflaton is a pseudo-Nambu-Goldstone boson coupled to gauge fields.\nIn this scenario, tensor modes arise not only from the standard amplification\nof vacuum fluctuations present in any inflationary model, but also from the\ninverse decay process of the produced gauge fields. The correlator of\ngravitational wave anisotropies consists therefore of two main components: the\ncontribution from vacuum tensor modes and the contribution from tensor modes\nsourced by the gauge fields. Our analysis shows that, while the former,\npreviously studied in the literature, is negligible, the one arising from the\nsourced tensor modes, normalized by the fractional energy density at\ninterferometer frequencies, can reach values as large as\n$\\mathcal{O}(10^{-1})$. This result shows that axion inflation can generate\nlarge anisotropies with the potential to be observed by gravitational wave\ndetectors within a reasonable time frame.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph,hep-th","published":"2025-04-17T17:56:58Z"}
{"aid":"http://arxiv.org/abs/2504.13161v1","title":"CLIMB: CLustering-based Iterative Data Mixture Bootstrapping for\n  Language Model Pre-training","summary":"Pre-training datasets are typically collected from web content and lack\ninherent domain divisions. For instance, widely used datasets like Common Crawl\ndo not include explicit domain labels, while manually curating labeled datasets\nsuch as The Pile is labor-intensive. Consequently, identifying an optimal\npre-training data mixture remains a challenging problem, despite its\nsignificant benefits for pre-training performance. To address these challenges,\nwe propose CLustering-based Iterative Data Mixture Bootstrapping (CLIMB), an\nautomated framework that discovers, evaluates, and refines data mixtures in a\npre-training setting. Specifically, CLIMB embeds and clusters large-scale\ndatasets in a semantic space and then iteratively searches for optimal mixtures\nusing a smaller proxy model and a predictor. When continuously trained on 400B\ntokens with this mixture, our 1B model exceeds the state-of-the-art\nLlama-3.2-1B by 2.0%. Moreover, we observe that optimizing for a specific\ndomain (e.g., Social Sciences) yields a 5% improvement over random sampling.\nFinally, we introduce ClimbLab, a filtered 1.2-trillion-token corpus with 20\nclusters as a research playground, and ClimbMix, a compact yet powerful\n400-billion-token dataset designed for efficient pre-training that delivers\nsuperior performance under an equal token budget. We analyze the final data\nmixture, elucidating the characteristics of an optimal data mixture. Our data\nis available at: https://research.nvidia.com/labs/lpr/climb/","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-17T17:58:13Z"}
{"aid":"http://arxiv.org/abs/2504.14825v1","title":"ECViT: Efficient Convolutional Vision Transformer with Local-Attention\n  and Multi-scale Stages","summary":"Vision Transformers (ViTs) have revolutionized computer vision by leveraging\nself-attention to model long-range dependencies. However, ViTs face challenges\nsuch as high computational costs due to the quadratic scaling of self-attention\nand the requirement of a large amount of training data. To address these\nlimitations, we propose the Efficient Convolutional Vision Transformer (ECViT),\na hybrid architecture that effectively combines the strengths of CNNs and\nTransformers. ECViT introduces inductive biases such as locality and\ntranslation invariance, inherent to Convolutional Neural Networks (CNNs) into\nthe Transformer framework by extracting patches from low-level features and\nenhancing the encoder with convolutional operations. Additionally, it\nincorporates local-attention and a pyramid structure to enable efficient\nmulti-scale feature extraction and representation. Experimental results\ndemonstrate that ECViT achieves an optimal balance between performance and\nefficiency, outperforming state-of-the-art models on various image\nclassification tasks while maintaining low computational and storage\nrequirements. ECViT offers an ideal solution for applications that prioritize\nhigh efficiency without compromising performance.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-21T03:00:17Z"}
{"aid":"http://arxiv.org/abs/2504.14843v1","title":"Quantitative Measures for Passive Sonar Texture Analysis","summary":"Passive sonar signals contain complex characteristics often arising from\nenvironmental noise, vessel machinery, and propagation effects. While\nconvolutional neural networks (CNNs) perform well on passive sonar\nclassification tasks, they can struggle with statistical variations that occur\nin the data. To investigate this limitation, synthetic underwater acoustic\ndatasets are generated that centered on amplitude and period variations. Two\nmetrics are proposed to quantify and validate these characteristics in the\ncontext of statistical and structural texture for passive sonar. These measures\nare applied to real-world passive sonar datasets to assess texture information\nin the signals and correlate the performances of the models. Results show that\nCNNs underperform on statistically textured signals, but incorporating explicit\nstatistical texture modeling yields consistent improvements. These findings\nhighlight the importance of quantifying texture information for passive sonar\nclassification.","main_category":"eess.AS","categories":"eess.AS","published":"2025-04-21T03:55:49Z"}
{"aid":"http://arxiv.org/abs/2504.14852v1","title":"APIRAT: Integrating Multi-source API Knowledge for Enhanced Code\n  Translation with LLMs","summary":"Code translation is an essential task in software migration, multilingual\ndevelopment, and system refactoring. Recent advancements in large language\nmodels (LLMs) have demonstrated significant potential in this task. However,\nprior studies have highlighted that LLMs often struggle with domain-specific\ncode, particularly in resolving cross-lingual API mappings. To tackle this\nchallenge, we propose APIRAT, a novel code translation method that integrates\nmulti-source API knowledge. APIRAT employs three API knowledge augmentation\ntechniques, including API sequence retrieval, API sequence back-translation,\nand API mapping, to guide LLMs to translating code, ensuring both the correct\nstructure of API sequences and the accurate usage of individual APIs. Extensive\nexperiments on two public datasets, CodeNet and AVATAR, indicate that APIRAT\nsignificantly surpasses existing LLM-based methods, achieving improvements in\ncomputational accuracy ranging from 4% to 15.1%. Additionally, our evaluation\nacross different LLMs showcases the generalizability of APIRAT. An ablation\nstudy further confirms the individual contributions of each API knowledge\ncomponent, underscoring the effectiveness of our approach.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-21T04:24:49Z"}
{"aid":"http://arxiv.org/abs/2504.14864v1","title":"Radiative Transitions for the Ground and Excited Charmonia States","summary":"In this work, we have investigated the physical properties like decay\nconstants, radiative transitions, decay widths, and branching ratios for the\nground and radially excited charmonia states. For the numerical calculations,\nwe have adopted the light-front quark model (LFQM). We have studied\n$\\chi_{c0}\\rightarrow J{/}\\psi+\\gamma $ and\n$\\psi(2S)\\rightarrow\\chi_{c0}+\\gamma$, $h_c(1P)\\rightarrow\\eta_c(1S)+\\gamma $,\nand $\\eta_c(2S)\\rightarrow h_c(1P)+\\gamma $ transitions in this work. We have\nalso demonstrated the behavior of the transition form factors (TFFs) for the\n$h_c(1P)\\rightarrow\\eta_c(1S)+\\gamma $ and\n$\\psi(2S)\\rightarrow\\chi_{c0}+\\gamma$ decays in this model. Using the TFFs\nresults, we have calculated the decay widths and branching ratios for these\ntransitions. Our numerical results of decay constants, decay widths, and\nbranching ratios are overall in good agreement with available experimental,\ntheoretical and lattice simulation data.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-21T05:22:46Z"}
{"aid":"http://arxiv.org/abs/2504.14877v1","title":"Collaborative Enhancement Network for Low-quality Multi-spectral Vehicle\n  Re-identification","summary":"The performance of multi-spectral vehicle Re-identification (ReID) is\nsignificantly degraded when some important discriminative cues in visible, near\ninfrared and thermal infrared spectra are lost. Existing methods generate or\nenhance missing details in low-quality spectra data using the high-quality one,\ngenerally called the primary spectrum, but how to justify the primary spectrum\nis a challenging problem. In addition, when the quality of the primary spectrum\nis low, the enhancement effect would be greatly degraded, thus limiting the\nperformance of multi-spectral vehicle ReID. To address these problems, we\npropose the Collaborative Enhancement Network (CoEN), which generates a\nhigh-quality proxy from all spectra data and leverages it to supervise the\nselection of primary spectrum and enhance all spectra features in a\ncollaborative manner, for robust multi-spectral vehicle ReID. First, to\nintegrate the rich cues from all spectra data, we design the Proxy Generator\n(PG) to progressively aggregate multi-spectral features. Second, we design the\nDynamic Quality Sort Module (DQSM), which sorts all spectra data by measuring\ntheir correlations with the proxy, to accurately select the primary spectra\nwith the highest correlation. Finally, we design the Collaborative Enhancement\nModule (CEM) to effectively compensate for missing contents of all spectra by\ncollaborating the primary spectra and the proxy, thereby mitigating the impact\nof low-quality primary spectra. Extensive experiments on three benchmark\ndatasets are conducted to validate the efficacy of the proposed approach\nagainst other multi-spectral vehicle ReID methods. The codes will be released\nat https://github.com/yongqisun/CoEN.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T06:07:32Z"}
{"aid":"http://arxiv.org/abs/2504.14918v1","title":"Monopoles at Future Neutrino Detectors","summary":"We investigate the potential of future neutrino experiments, DUNE and\nHyper-Kamiokande, to probe magnetic monopoles via Callan-Rubakov (CR)\nprocesses. We consider both relativistic and non-relativistic monopoles and\nfocus on two primary detection signatures: high-energy antiproton production\nand proton decay catalysis. For relativistic monopoles, our analysis of the CR\nprocess indicates antiproton production with energies near 900 GeV and we find\nthat both experiments can provide limits on the fluxes an order of magnitude\nbelow the Parker bound (approximately $\\Phi \\lesssim\n10^{-16}\\,\\mathrm{cm^{-2}\\,s^{-1}\\,sr^{-1}}$). For non-relativistic monopoles,\nwe recast the experimental sensitivity to proton decay catalysis and obtain\nupper limits on the monopole flux of $\\Phi \\lesssim 2.3 \\times\n10^{-23}\\,\\mathrm{cm^{-2}\\,s^{-1}\\,sr^{-1}}$ for Hyper-Kamiokande and $\\Phi\n\\lesssim 1.1 \\times 10^{-22}\\,\\mathrm{cm^{-2}\\,s^{-1}\\,sr^{-1}}$ for DUNE.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-21T07:35:35Z"}
{"aid":"http://arxiv.org/abs/2504.14935v1","title":"An elementary definition of opetopic sets","summary":"We propose elementary definitions of opetopes and opetopic sets. We directly\ndefine opetopic sets by a simple structure and several axioms. Opetopes are\nthen opetopic sets satisfying one more axiom. We show that our definition is\nequivalent to the polynomial monad definition given by Kock, Joyal, Batanin,\nand Mascari. We also show that our category of opetopes is equivalent to the\none given by Ho Thanh.","main_category":"math.CT","categories":"math.CT","published":"2025-04-21T07:56:23Z"}
{"aid":"http://arxiv.org/abs/2504.14969v1","title":"Evaluating LLMs on Chinese Topic Constructions: A Research Proposal\n  Inspired by Tian et al. (2024)","summary":"This paper proposes a framework for evaluating large language models (LLMs)\non Chinese topic constructions, focusing on their sensitivity to island\nconstraints. Drawing inspiration from Tian et al. (2024), we outline an\nexperimental design for testing LLMs' grammatical knowledge of Mandarin syntax.\nWhile no experiments have been conducted yet, this proposal aims to provide a\nfoundation for future studies and invites feedback on the methodology.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-21T08:56:23Z"}
{"aid":"http://arxiv.org/abs/2504.15007v1","title":"Shifts in Doctors' Eye Movements Between Real and AI-Generated Medical\n  Images","summary":"Eye-tracking analysis plays a vital role in medical imaging, providing key\ninsights into how radiologists visually interpret and diagnose clinical cases.\nIn this work, we first analyze radiologists' attention and agreement by\nmeasuring the distribution of various eye-movement patterns, including saccades\ndirection, amplitude, and their joint distribution. These metrics help uncover\npatterns in attention allocation and diagnostic strategies. Furthermore, we\ninvestigate whether and how doctors' gaze behavior shifts when viewing\nauthentic (Real) versus deep-learning-generated (Fake) images. To achieve this,\nwe examine fixation bias maps, focusing on first, last, short, and longest\nfixations independently, along with detailed saccades patterns, to quantify\ndifferences in gaze distribution and visual saliency between authentic and\nsynthetic images.","main_category":"cs.CV","categories":"cs.CV,cs.HC","published":"2025-04-21T10:13:59Z"}
{"aid":"http://arxiv.org/abs/2504.15019v1","title":"Feedback Stackelberg-Nash equilibria in difference games with\n  quasi-hierarchical interactions and inequality constraints","summary":"In this paper, we study a class of two-player deterministic finite-horizon\ndifference games with coupled inequality constraints, where each player has two\ntypes of decision variables: one involving sequential interactions and the\nother simultaneous interactions. We refer to these as quasi-hierarchical\ndynamic games and define a solution concept called the feedback\nStackelberg-Nash (FSN) equilibrium. Under a separability assumption on cost\nfunctions, we formulate FSN solutions recursively using a dynamic\nprogramming-like approach. We further show that the FSN solution for these\nconstrained games can be derived from the parametric feedback Stackelberg\nsolution of an associated unconstrained game with only sequential interactions,\ngiven parameter choices that satisfy implicit complementarity conditions. For\nthe linear-quadratic case, we show that the FSN solutions are obtained by\nreformulating these complementarity conditions as a single large-scale linear\ncomplementarity problem. Finally, we illustrate our results with a dynamic\nduopoly game with production constraints.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-21T11:05:03Z"}
{"aid":"http://arxiv.org/abs/2504.15025v1","title":"Quantum pseudoresources imply cryptography","summary":"While one-way functions (OWFs) serve as the minimal assumption for\ncomputational cryptography in the classical setting, in quantum cryptography,\nwe have even weaker cryptographic assumptions such as pseudo-random states, and\nEFI pairs, among others. Moreover, the minimal assumption for computational\nquantum cryptography remains an open question. Recently, it has been shown that\npseudoentanglement is necessary for the existence of quantum cryptography\n(Goul\\~ao and Elkouss 2024), but no cryptographic construction has been built\nfrom it.\n  In this work, we study the cryptographic usefulness of quantum\npseudoresources -- a pair of families of quantum states that exhibit a gap in\ntheir resource content yet remain computationally indistinguishable. We show\nthat quantum pseudoresources imply a variant of EFI pairs, which we call EPFI\npairs, and that these are equivalent to quantum commitments and thus EFI pairs.\nOur results suggest that, just as randomness is fundamental to classical\ncryptography, quantum resources may play a similarly crucial role in the\nquantum setting.\n  Finally, we focus on the specific case of entanglement, analyzing different\ndefinitions of pseudoentanglement and their implications for constructing EPFI\npairs. Moreover, we propose a new cryptographic functionality that is\nintrinsically dependent on entanglement as a resource.","main_category":"quant-ph","categories":"quant-ph,cs.CR","published":"2025-04-21T11:17:30Z"}
{"aid":"http://arxiv.org/abs/2504.15029v1","title":"Story of an architecturally suggestive polyhedron: from medieval trade\n  to Renaissance art and modern design","summary":"We describe a balance weight dated to the Early Islamic Period from the Hecht\nMuseum at the University of Haifa (Israel) Its polyhedral shape was attributed\nto a truncated elongated octagonal bipyramid. To our knowledge, the earliest\nRenaissance book containing the image of this polyhedron is \"La Pratica di\nProspettiva\" published in 1596 by Florentine architect and perspective artist\nLorenzo Sirigatti. We described an outline of Sirigatti life and the importance\nof his book for scientists and artists, Galileo Galilei among them. We depict\nexamples of lamps and lanterns in European cities shaped as the truncated\nelongated octagonal bipyramid, as well as a drawing by Raphael with a lantern\nof a similar form. Finally, we discussed why the artist chose this particular\npolyhedron for his drawing.","main_category":"math.HO","categories":"math.HO","published":"2025-04-21T11:33:41Z"}
{"aid":"http://arxiv.org/abs/2504.15054v1","title":"Structure-guided Diffusion Transformer for Low-Light Image Enhancement","summary":"While the diffusion transformer (DiT) has become a focal point of interest in\nrecent years, its application in low-light image enhancement remains a blank\narea for exploration. Current methods recover the details from low-light images\nwhile inevitably amplifying the noise in images, resulting in poor visual\nquality. In this paper, we firstly introduce DiT into the low-light enhancement\ntask and design a novel Structure-guided Diffusion Transformer based Low-light\nimage enhancement (SDTL) framework. We compress the feature through wavelet\ntransform to improve the inference efficiency of the model and capture the\nmulti-directional frequency band. Then we propose a Structure Enhancement\nModule (SEM) that uses structural prior to enhance the texture and leverages an\nadaptive fusion strategy to achieve more accurate enhancement effect. In\nAddition, we propose a Structure-guided Attention Block (SAB) to pay more\nattention to texture-riched tokens and avoid interference from noisy areas in\nnoise prediction. Extensive qualitative and quantitative experiments\ndemonstrate that our method achieves SOTA performance on several popular\ndatasets, validating the effectiveness of SDTL in improving image quality and\nthe potential of DiT in low-light enhancement tasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T12:30:01Z"}
{"aid":"http://arxiv.org/abs/2504.15058v1","title":"One Dimensional Asymptotic Plateau Problem in $n$-Dimensional\n  Asymptotically Conical Manifolds","summary":"Let $(M,g)$ be an asymptotically conical Riemannian manifold having dimension\n$n\\ge 2$, opening angle $\\alpha \\in (0,\\pi/2) \\setminus \\{\\arcsin\n\\frac{1}{2k+1}\\}_{k \\in \\mathbb{N}}$ and positive asymptotic rate. Under the\nassumption that the exponential map is proper at each point, we give a solution\nto the one dimensional asymptotic Plateau problem on $M$. Precisely, for any\npair of antipodal points in the ideal boundary $\\partial_\\infty M = \\mathbb\nS^{n-1}$, we prove the existence of a geodesic line with asymptotic prescribed\nboundaries and the Morse index $\\le n-1$.","main_category":"math.DG","categories":"math.DG","published":"2025-04-21T12:36:07Z"}
{"aid":"http://arxiv.org/abs/2504.15076v1","title":"Note on Type $III_1$ Algebras in $ c= 1$ String Theory and Bulk Causal\n  Diamonds","summary":"We argue that the Leutheusser-Liu procedure of isolating a von Neumann\nalgebra in the $N = \\infty$ limit of string theories, leads to the algebra of\nrelativistic fermion fields on a half line for the $c = 1$ string theory. This\nis a Type $I$ von Neumann algebra, since it is the algebra of the Rindler wedge\nin the Rindler vacuum state. Subalgebras of finite regions are Type $III_1$.\nThe argument uses the elegant results of Moore and of Alexandrov, Kazakov and\nKostov. This model is well known to be integrable and have no black hole\nexcitations. We have speculated that adding an interaction invisible in\nperturbation theory to a large finite number, $M$, of copies of the model,\nproduces a non-integrable model with meta-stable excitations having all of the\nproperties of linear dilaton black holes. The algebra of fields is the tensor\nproduct of $M$ copies of the $c = 1$ model's algebra, whether or not we add the\nnon-integrable interaction. We argue that the infinite dimensional $c = 1$\nalgebras are analogous to those of the boundary field theory in AdS/CFT, even\nthough they appear to encode bulk causal structure. An IR cutoff on the\nboundary renders them finite and causal structure must be formulated in terms\nof an analog of the Tensor Network Renormalization Group. This is a time\ndependent Hamiltonian flow, embedding smaller Hilbert spaces into larger ones.\nIt is the analog of one sided modular inclusion in quantum field theory.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-21T13:04:09Z"}
{"aid":"http://arxiv.org/abs/2504.15109v1","title":"New Heintze-Karcher type inequalities in sub-static warped product\n  manifolds","summary":"In this paper, we prove Heintze-Karcher type inequalities involving the\nshifted mean curvature for smooth bounded domains in certain sub-static warped\nproduct manifolds. In particular, we prove a Heintze-Karcher-type inequality\nfor non mean-convex domains in the hyperbolic space. As applications, we obtain\nuniqueness results for hypersurfaces satisfying a class of curvature equations.","main_category":"math.DG","categories":"math.DG","published":"2025-04-21T14:02:09Z"}
{"aid":"http://arxiv.org/abs/2504.15132v1","title":"Investigating Youth's Technical and Ethical Understanding of Generative\n  Language Models When Engaging in Construction and Deconstruction Activities","summary":"The widespread adoption of generative artificial intelligence/machine\nlearning (AI/ML) technologies has increased the need to support youth in\ndeveloping AI/ML literacies. However, most work has centered on preparing young\npeople to use these systems, with less attention to how they can participate in\ndesigning and evaluating them. This study investigates how engaging young\npeople in the design and auditing of generative language models (GLMs) may\nfoster the development of their understanding of how these systems work from\nboth technical and ethical perspectives. The study takes an in-pieces approach\nto investigate novices' conceptions of GLMs. Such an approach supports the\nanalysis of how technical and ethical conceptions evolve and relate to each\nother. I am currently conducting a series of participatory design workshops\nwith sixteen ninth graders (ages 14-15) in which they will (a) build GLMs from\na data-driven perspective that glassboxes how data shapes model performance and\n(b) audit commercial GLMs by repeatedly and systematically querying them to\ndraw inferences about their behaviors. I will analyze participants'\ninteractions to identify ethical and technical conceptions they may exhibit\nwhile designing and auditing GLMs. I will also conduct clinical interviews and\nuse microgenetic knowledge analysis and ordered network analysis to investigate\nhow participants' ethical and technical conceptions of GLMs relate to each\nother and change after the workshop. The study will contribute (a) evidence of\nhow engaging youth in design and auditing activities may support the\ndevelopment of ethical and technical understanding of GLMs and (b) an inventory\nof novice design and auditing practices that may support youth's technical and\nethical understanding of GLMs.","main_category":"cs.HC","categories":"cs.HC,cs.CY","published":"2025-04-21T14:30:16Z"}
{"aid":"http://arxiv.org/abs/2504.15146v1","title":"Behavioral Universe Network (BUN): A Behavioral Information-Based\n  Framework for Complex Systems","summary":"Modern digital ecosystems feature complex, dynamic interactions among\nautonomous entities across diverse domains. Traditional models often separate\nagents and objects, lacking a unified foundation to capture their interactive\nbehaviors. This paper introduces the Behavioral Universe Network (BUN), a\ntheoretical framework grounded in the Agent-Interaction-Behavior (AIB)\nformalism. BUN treats subjects (active agents), objects (resources), and\nbehaviors (operations) as first-class entities, all governed by a shared\nBehavioral Information Base (BIB). We detail the AIB core concepts and\ndemonstrate how BUN leverages information-driven triggers, semantic enrichment,\nand adaptive rules to coordinate multi-agent systems. We highlight key\nbenefits: enhanced behavior analysis, strong adaptability, and cross-domain\ninteroperability. We conclude by positioning BUN as a promising foundation for\nnext-generation digital governance and intelligent applications.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-21T14:50:28Z"}
{"aid":"http://arxiv.org/abs/2504.15167v1","title":"Almost-perfect colorful matchings in three-edge-colored bipartite graphs","summary":"We prove that, for positive integers $n,a_1, a_2, a_3$ satisfying\n$a_1+a_2+a_3 = n-1$, it holds that any bipartite graph $G$ which is the union\nof three perfect matchings $M_1$, $M_2$, and $M_3$ on $2n$ vertices contains a\nmatching $M$ such that $|M\\cap M_i| =a_i$ for $i= 1,2,$ and $3$. The bound\n$n-1$ on the sum is best possible in general. Our result verifies the\nmultiplicity extension of the Ryser-Brualdi-Stein Conjecture, proposed recently\nby Anastos, Fabian, M\\\"uyesser, and Szab\\'o, for three colors.","main_category":"math.CO","categories":"math.CO","published":"2025-04-21T15:22:13Z"}
{"aid":"http://arxiv.org/abs/2504.15168v1","title":"On true empty category","summary":"According to Chomsky (1981, 1986), empty categories consist of PRO, pro,\ntrace, and variable. However, some empty object positions seem to be\nincompatible with extant empty categories. Given this, Li (2007a, 2007b, 2014)\nand Li & Wei (2014) raise the true empty category hypothesis, which holds that\ntrue empty category is only an empty position with category and Case features.\nAs a last resort option, it is used mainly to meet the subcatgorization of a\nverb. This assumption is ingenious, and if proved to be true, it will exert a\ngreat impact on the study of UG. In this paper, we evaluate their evidence from\ntopicalization and demonstrate that it can be accounted for without invoking\ntrue empty category.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-21T15:22:21Z"}
{"aid":"http://arxiv.org/abs/2504.15191v1","title":"Aerodynamic Control of Laminar Separation on a Wall-Bounded Airfoil at\n  Transitional Reynolds Numbers","summary":"Experiments were conducted in a low-turbulence wind tunnel to investigate the\nefficacy of localised acoustic forcing upon the dynamics and stability of the\nflow on a cambered, wall-bounded airfoil over a range of Reynolds numbers (Re)\nwhere the flow state can switch between two limits -- a low-lift state (SI)\nwhere separation continues beyond the trailing edge and a high-lift state (SII)\nwhere the separated flow is closed off to form a laminar separation bubble. The\nswitching between SI and SII can occur close to a critical angle of attack\n($\\alpha_{\\textrm{crit}}$) which varies with $\\textrm{Re}$. The most effective\nforcing frequencies are found at a constant value of a rescaled Strouhal\nnumber, $\\textrm{St}^* = \\textrm{St}/\\textrm{Re}^{1/2}= 0.027$, which indicates\nthat though the primary unstable modes of the separated shear layer are of the\ninviscid, Kelvin-Helmholtz type, these modes are seeded by length scales that\noriginate in the laminar (viscous) boundary layer. The most effective chordwise\nforcing location varies with $\\textrm{St}/\\textrm{Re}^{1/2}$ and incidence\nangle, $\\alpha$, and is always upstream of the separation point. Although the\nboundary layer flows are far from two-dimensional, forcing at a fixed chord\nlocation across all spanwise locations is effective in controlling the SI --\nSII transition. Strategies for active and passive feedback control are\nsuggested.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-21T16:01:41Z"}
{"aid":"http://arxiv.org/abs/2504.15206v1","title":"How Global Calibration Strengthens Multiaccuracy","summary":"Multiaccuracy and multicalibration are multigroup fairness notions for\nprediction that have found numerous applications in learning and computational\ncomplexity. They can be achieved from a single learning primitive: weak\nagnostic learning. Here we investigate the power of multiaccuracy as a learning\nprimitive, both with and without the additional assumption of calibration. We\nfind that multiaccuracy in itself is rather weak, but that the addition of\nglobal calibration (this notion is called calibrated multiaccuracy) boosts its\npower substantially, enough to recover implications that were previously known\nonly assuming the stronger notion of multicalibration.\n  We give evidence that multiaccuracy might not be as powerful as standard weak\nagnostic learning, by showing that there is no way to post-process a\nmultiaccurate predictor to get a weak learner, even assuming the best\nhypothesis has correlation $1/2$. Rather, we show that it yields a restricted\nform of weak agnostic learning, which requires some concept in the class to\nhave correlation greater than $1/2$ with the labels. However, by also requiring\nthe predictor to be calibrated, we recover not just weak, but strong agnostic\nlearning.\n  A similar picture emerges when we consider the derivation of hardcore\nmeasures from predictors satisfying multigroup fairness notions. On the one\nhand, while multiaccuracy only yields hardcore measures of density half the\noptimal, we show that (a weighted version of) calibrated multiaccuracy achieves\noptimal density.\n  Our results yield new insights into the complementary roles played by\nmultiaccuracy and calibration in each setting. They shed light on why\nmultiaccuracy and global calibration, although not particularly powerful by\nthemselves, together yield considerably stronger notions.","main_category":"cs.LG","categories":"cs.LG,cs.CC","published":"2025-04-21T16:22:44Z"}
{"aid":"http://arxiv.org/abs/2504.15211v1","title":"Position: Bayesian Statistics Facilitates Stakeholder Participation in\n  Evaluation of Generative AI","summary":"The evaluation of Generative AI (GenAI) systems plays a critical role in\npublic policy and decision-making, yet existing methods are often limited by\nreliance on benchmark-driven, point-estimate comparisons that fail to capture\nuncertainty and broader societal impacts. This paper argues for the use of\nBayesian statistics as a principled framework to address these challenges.\nBayesian methods enable the integration of domain expertise through prior\nelicitation, allow for continuous learning from new data, and provide robust\nuncertainty quantification via posterior inference. We demonstrate how Bayesian\ninference can be applied to GenAI evaluation, particularly in incorporating\nstakeholder perspectives to enhance fairness, transparency, and reliability.\nFurthermore, we discuss Bayesian workflows as an iterative process for model\nvalidation and refinement, ensuring robust assessments of GenAI systems in\ndynamic, real-world contexts.","main_category":"cs.AI","categories":"cs.AI,stat.AP","published":"2025-04-21T16:31:15Z"}
{"aid":"http://arxiv.org/abs/2504.15234v1","title":"Equivariant quasisymmetry and noncrossing partitions","summary":"We introduce a definition of ``equivariant quasisymmetry'' for polynomials in\ntwo sets of variables. Using this definition we define quasisymmetric\ngeneralizations of the theory of double Schur and double Schubert polynomials\nthat we call double fundamental polynomials and double forest polynomials,\nwhere the subset of ``noncrossing partitions'' plays the role of $S_n$. In\nsubsequent work we will show this combinatorics is governed by a new geometric\nconstruction we call the ``quasisymmetric flag variety'' which plays the same\nrole for equivariant quasisymmetry as the usual flag variety plays in the\nclassical story.","main_category":"math.CO","categories":"math.CO,math.AG","published":"2025-04-21T17:09:52Z"}
{"aid":"http://arxiv.org/abs/2504.15264v1","title":"Sunflowers and Ramsey problems for restricted intersections","summary":"Extremal problems on set systems with restricted intersections have been an\nimportant part of combinatorics in the last 70 year. In this paper, we study\nthe following Ramsey version of these problems. Given a set $L\\subseteq\n\\{0,\\dots,k-1\\}$ and a family $\\mathcal{F}$ of $k$-element sets which does not\ncontain a sunflower with $m$ petals whose kernel size is in $L$, how large a\nsubfamily of $\\mathcal{F}$ can we find in which no pair has intersection size\nin $L$? We give matching upper and lower bounds, determining the dependence on\n$m$ for all $k$ and $L$. This problem also finds applications in quantum\ncomputing.\n  As an application of our techniques, we also obtain a variant of F\\\"uredi's\ncelebrated semilattice lemma, which is a key tool in the powerful delta-system\nmethod. We prove that one cannot remove the double-exponential dependency on\nthe uniformity in F\\\"uredi's result, however, we provide an alternative with\nsignificantly better, single-exponential dependency on the parameters, which is\nstill strong enough for most applications of the delta-system method.","main_category":"math.CO","categories":"math.CO,cs.DM,quant-ph","published":"2025-04-21T17:46:21Z"}
{"aid":"http://arxiv.org/abs/2504.15569v1","title":"Centers of perfectoid purity","summary":"We introduce a mixed characteristic analog of log canonical centers in\ncharacteristic $0$ and centers of $F$-purity in positive characteristic, which\nwe call centers of perfectoid purity. We show that their existence detects (the\nfailure of) normality of the ring. We also show the existence of a special\ncenter of perfectoid purity that detects the perfectoid purity of $R$,\nanalogously to the splitting prime of Aberbach and Enescu, and investigate its\nbehavior under \\'etale morphisms.","main_category":"math.AG","categories":"math.AG,math.AC","published":"2025-04-22T03:55:38Z"}
{"aid":"http://arxiv.org/abs/2504.15639v1","title":"A remark for characterizing blowup introduced by Giga and Kohn","summary":"Giga and Kohn studied the blowup solutions for the equation $v_{t} - \\Delta v\n- |v|^{p - 1} v = 0 $ and characterized the asymptotic behavior of $v$ near a\nsingularity. In the proof, they reduced the problem to a Liouville theorem for\nthe equation $\\Delta u - \\frac{1}{2} x \\cdot \\nabla u + |u|^{p - 1} u - \\beta u\n= 0$ where $\\beta = \\frac{1}{p - 1}$ and $|u|$ is bounded. This article is a\nremark for their work and we will show when $u \\geq 0$, the boundedness\ncondition for $|u|$ can be removed.","main_category":"math.AP","categories":"math.AP","published":"2025-04-22T06:57:02Z"}
{"aid":"http://arxiv.org/abs/2504.15660v1","title":"Electroweak form factors of baryons in dense nuclear matter","summary":"There are evidences that the properties of the hadrons are modified in a\nnuclear medium. Information about the medium modifications of the internal\nstructure of the hadrons are fundamental for the study of dense nuclear matter\nand high energy processes including heavy-ion and nucleus-nucleus collisions.\nAt the moment, however, the empirical information about the medium\nmodifications of the hadrons is limited, therefore, theoretical studies are\nessential for the progress in the field. In the present work we review\ntheoretical studies of the electromagnetic and axial form factors of octet\nbaryons in symmetric nuclear matter. The calculations are based on a model that\ntakes into account the degrees of freedom revealed on experimental studies of\nthe low and intermediate square transfer momentum $q^2=-Q^2$: valence quarks\nand meson cloud excitations of the baryon cores. The formalism combines a\ncovariant constituent quark model, developed for the free space (vacuum) with\nthe quark-meson coupling model for the extension to the nuclear medium. We\nconclude that the nuclear medium modifies the baryon properties differently\naccording to the flavor content of the baryons and the medium density. The\neffects of the medium increase with the density, and are stronger (quenched or\nenhanced) for light baryons than for heavy baryons. In particular, the\nin-medium neutrino-nucleon and antineutrino-nucleon cross sections are reduced\ncompared to the values in free space. The proposed formalism can be extended to\ndensities above the normal nuclear density and applied to neutrino-hyperon and\nantineutrino-hyperon scattering in dense nuclear matter.","main_category":"nucl-th","categories":"nucl-th,hep-ex,hep-lat,hep-ph,nucl-ex","published":"2025-04-22T07:35:42Z"}
{"aid":"http://arxiv.org/abs/2504.15707v1","title":"RePOPE: Impact of Annotation Errors on the POPE Benchmark","summary":"Since data annotation is costly, benchmark datasets often incorporate labels\nfrom established image datasets. In this work, we assess the impact of label\nerrors in MSCOCO on the frequently used object hallucination benchmark POPE. We\nre-annotate the benchmark images and identify an imbalance in annotation errors\nacross different subsets. Evaluating multiple models on the revised labels,\nwhich we denote as RePOPE, we observe notable shifts in model rankings,\nhighlighting the impact of label quality. Code and data are available at\nhttps://github.com/YanNeu/RePOPE .","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-22T08:47:59Z"}
{"aid":"http://arxiv.org/abs/2504.15715v1","title":"Assessing FAIRness of the Digital Shadow Reference Model","summary":"Models play a critical role in managing the vast amounts of data and\nincreasing complexity found in the IoT, IIoT, and IoP domains. The Digital\nShadow Reference Model, which serves as a foundational metadata schema for\nlinking data and metadata in these environments, is an example of such a model.\nEnsuring FAIRness (adherence to the FAIR Principles) is critical because it\nimproves data findability, accessibility, interoperability, and reusability,\nfacilitating efficient data management and integration across systems.\n  This paper presents an evaluation of the FAIRness of the Digital Shadow\nReference Model using a structured evaluation framework based on the FAIR Data\nPrinciples. Using the concept of FAIR Implementation Profiles (FIPs),\nsupplemented by a mini-questionnaire, we systematically evaluate the model's\nadherence to these principles. Our analysis identifies key strengths, including\nthe model's metadata schema that supports rich descriptions and authentication\ntechniques, and highlights areas for improvement, such as the need for globally\nunique identifiers and consequent support for different Web standards. The\nresults provide actionable insights for improving the FAIRness of the model and\npromoting better data management and reuse. This research contributes to the\nfield by providing a detailed assessment of the Digital Shadow Reference Model\nand recommending next steps to improve its FAIRness and usability.","main_category":"cs.DB","categories":"cs.DB,cs.CY,cs.IR","published":"2025-04-22T08:58:48Z"}
{"aid":"http://arxiv.org/abs/2504.15723v1","title":"Structure-Preserving Zero-Shot Image Editing via Stage-Wise Latent\n  Injection in Diffusion Models","summary":"We propose a diffusion-based framework for zero-shot image editing that\nunifies text-guided and reference-guided approaches without requiring\nfine-tuning. Our method leverages diffusion inversion and timestep-specific\nnull-text embeddings to preserve the structural integrity of the source image.\nBy introducing a stage-wise latent injection strategy-shape injection in early\nsteps and attribute injection in later steps-we enable precise, fine-grained\nmodifications while maintaining global consistency. Cross-attention with\nreference latents facilitates semantic alignment between the source and\nreference. Extensive experiments across expression transfer, texture\ntransformation, and style infusion demonstrate state-of-the-art performance,\nconfirming the method's scalability and adaptability to diverse image editing\nscenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T09:18:16Z"}
{"aid":"http://arxiv.org/abs/2504.15732v1","title":"Integral Artin motives II: Perverse motives and Artin Vanishing Theorem","summary":"In this text, we are mainly interested in the existence of the perverse\nmotivic t-structures on the category of Artin \\'etale motives with integral\ncoefficients. We construct the perverse homotopy t-structure which is the best\npossible approximation to a perverse t-structure on Artin motives with rational\ncoefficients. The heart of this t-structure has properties similar to those of\nthe category of perverse sheaves and contains the Ayoub-Zucker motive. With\nintegral coefficients, we construct the perverse motivic t-structure on Artin\nmotives when the base scheme is of dimension at most $2$ and show that it\ncannot exist in dimension $4$. This construction relies notably on a an\nanalogue for Artin motives of the Artin Vanishing Theorem.","main_category":"math.AG","categories":"math.AG","published":"2025-04-22T09:25:27Z"}
{"aid":"http://arxiv.org/abs/2504.15737v1","title":"Energy-Efficient SIM-assisted Communications: How Many Layers Do We\n  Need?","summary":"The stacked intelligent metasurface (SIM), comprising multiple layers of\nreconfigurable transmissive metasurfaces, is becoming an increasingly viable\nsolution for future wireless communication systems. In this paper, we explore\nthe integration of SIM in a multi-antenna base station for application to\ndownlink multi-user communications, and a realistic power consumption model for\nSIM-assisted systems is presented. Specifically, we focus on maximizing the\nenergy efficiency (EE) for hybrid precoding design, i.e., the base station\ndigital precoding and SIM wave-based beamforming. Due to the non-convexity and\nhigh complexity of the formulated problem, we employ the quadratic\ntransformation method to reformulate the optimization problem and propose an\nalternating optimization (AO)-based joint precoding framework. Specifically, a\nsuccessive convex approximation (SCA) algorithm is adopted for the base station\nprecoding design. For the SIM wave-based beamforming, two algorithms are\nemployed: the high-performance semidefinite programming (SDP) method and the\nlow-complexity projected gradient ascent (PGA) algorithm. In particular, the\nresults indicate that while the optimal number of SIM layers for maximizing the\nEE and spectral efficiency differs, a design of 2 to 5 layers can achieve\nsatisfactory performance for both. Finally, numerical results are illustrated\nto evaluate the effectiveness of the proposed hybrid precoding framework and to\nshowcase the performance enhancement achieved by the algorithm in comparison to\nbenchmark schemes.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-22T09:31:55Z"}
{"aid":"http://arxiv.org/abs/2504.15740v1","title":"CaRoSaC: A Reinforcement Learning-Based Kinematic Control of\n  Cable-Driven Parallel Robots by Addressing Cable Sag through Simulation","summary":"This paper introduces the Cable Robot Simulation and Control (CaRoSaC)\nFramework, which integrates a simulation environment with a model-free\nreinforcement learning control methodology for suspended Cable-Driven Parallel\nRobots (CDPRs), accounting for cable sag. Our approach seeks to bridge the\nknowledge gap of the intricacies of CDPRs due to aspects such as cable sag and\nprecision control necessities by establishing a simulation platform that\ncaptures the real-world behaviors of CDPRs, including the impacts of cable sag.\nThe framework offers researchers and developers a tool to further develop\nestimation and control strategies within the simulation for understanding and\npredicting the performance nuances, especially in complex operations where\ncable sag can be significant. Using this simulation framework, we train a\nmodel-free control policy in Reinforcement Learning (RL). This approach is\nchosen for its capability to adaptively learn from the complex dynamics of\nCDPRs. The policy is trained to discern optimal cable control inputs, ensuring\nprecise end-effector positioning. Unlike traditional feedback-based control\nmethods, our RL control policy focuses on kinematic control and addresses the\ncable sag issues without being tethered to predefined mathematical models. We\nalso demonstrate that our RL-based controller, coupled with the flexible cable\nsimulation, significantly outperforms the classical kinematics approach,\nparticularly in dynamic conditions and near the boundary regions of the\nworkspace. The combined strength of the described simulation and control\napproach offers an effective solution in manipulating suspended CDPRs even at\nworkspace boundary conditions where traditional approach fails, as proven from\nour experiments, ensuring that CDPRs function optimally in various applications\nwhile accounting for the often neglected but critical factor of cable sag.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-22T09:45:06Z"}
{"aid":"http://arxiv.org/abs/2504.15742v1","title":"Proving Cypher Query Equivalence","summary":"Graph database systems store graph data as nodes and relationships, and\nutilize graph query languages (e.g., Cypher) for efficiently querying graph\ndata. Proving the equivalence of graph queries is an important foundation for\noptimizing graph query performance, ensuring graph query reliability, etc.\nAlthough researchers have proposed many SQL query equivalence provers for\nrelational database systems, these provers cannot be directly applied to prove\nthe equivalence of graph queries. The difficulty lies in the fact that graph\nquery languages (e.g., Cypher) adopt significantly different data models\n(property graph model vs. relational model) and query patterns (graph pattern\nmatching vs. tabular tuple calculus) from SQL.\n  In this paper, we propose GraphQE, an automated prover to determine whether\ntwo Cypher queries are semantically equivalent. We design a U-semiring based\nCypher algebraic representation to model the semantics of Cypher queries. Our\nCypher algebraic representation is built on the algebraic structure of\nunbounded semirings, and can sufficiently express nodes and relationships in\nproperty graphs and complex Cypher queries. Then, determining the equivalence\nof two Cypher queries is transformed into determining the equivalence of the\ncorresponding Cypher algebraic representations, which can be verified by SMT\nsolvers. To evaluate the effectiveness of GraphQE, we construct a dataset\nconsisting of 148 pairs of equivalent Cypher queries. Among them, we have\nsuccessfully proven 138 pairs of equivalent Cypher queries, demonstrating the\neffectiveness of GraphQE.","main_category":"cs.DB","categories":"cs.DB,cs.SE","published":"2025-04-22T09:45:37Z"}
{"aid":"http://arxiv.org/abs/2504.15753v1","title":"Markov Kernels, Distances and Optimal Control: A Parable of Linear\n  Quadratic Non-Gaussian Distribution Steering","summary":"For a controllable linear time-varying (LTV) pair\n$(\\boldsymbol{A}_t,\\boldsymbol{B}_t)$ and $\\boldsymbol{Q}_{t}$ positive\nsemidefinite, we derive the Markov kernel for the It\\^{o} diffusion\n${\\mathrm{d}}\\boldsymbol{x}_{t}=\\boldsymbol{A}_{t}\\boldsymbol{x}_t {\\mathrm{d}}\nt + \\sqrt{2}\\boldsymbol{B}_{t}{\\mathrm{d}}\\boldsymbol{w}_{t}$ with an\naccompanying killing of probability mass at rate\n$\\frac{1}{2}\\boldsymbol{x}^{\\top}\\boldsymbol{Q}_{t}\\boldsymbol{x}$. This Markov\nkernel is the Green's function for an associated linear\nreaction-advection-diffusion partial differential equation. Our result\ngeneralizes the recently derived kernel for the special case\n$\\left(\\boldsymbol{A}_t,\\boldsymbol{B}_t\\right)=\\left(\\boldsymbol{0},\\boldsymbol{I}\\right)$,\nand depends on the solution of an associated Riccati matrix ODE. A consequence\nof this result is that the linear quadratic non-Gaussian Schr\\\"{o}dinger bridge\nis exactly solvable. This means that the problem of steering a controlled LTV\ndiffusion from a given non-Gaussian distribution to another over a fixed\ndeadline while minimizing an expected quadratic cost can be solved using\ndynamic Sinkhorn recursions performed with the derived kernel. Our derivation\nfor the\n$\\left(\\boldsymbol{A}_t,\\boldsymbol{B}_t,\\boldsymbol{Q}_t\\right)$-parametrized\nkernel pursues a new idea that relies on finding a state-time dependent\ndistance-like functional given by the solution of a deterministic optimal\ncontrol problem. This technique breaks away from existing methods, such as\ngeneralizing Hermite polynomials or Weyl calculus, which have seen limited\nsuccess in the reaction-diffusion context. Our technique uncovers a new\nconnection between Markov kernels, distances, and optimal control. This\nconnection is of interest beyond its immediate application in solving the\nlinear quadratic Schr\\\"{o}dinger bridge problem.","main_category":"math.OC","categories":"math.OC,cs.LG,cs.SY,eess.SY,math.PR,math.ST,stat.TH","published":"2025-04-22T10:07:43Z"}
{"aid":"http://arxiv.org/abs/2504.15778v1","title":"A Stochastic Lattice Model for Convective Self-aggregation Incorporating\n  Longwave Radiative Effect","summary":"Self-aggregation of tropical convection is a universal feature observed in a\ndiverse range of atmospheric environments. Several preceding models\nconceptualized the self-aggregation of convection as a phase transition driven\nby collisions between cold pool gust fronts. However, self-aggregation may also\nbe influenced by various physical processes, such as surface fluxes, radiation,\nand moisture perturbations in the planetary boundary layer, and it remains\nunclear which process plays a dominant role. In this study, we develop a simple\nstochastic lattice model for the pattern formation of deep convection, inspired\nby the two-dimensional Ising model. Here, in addition to the process of cold\npool collisions, which have an effect of triggering new convection, we\nincorporate the process of clear-sky radiative cooling that has an effect of\nsuppressing deep convection as an interaction between clouds. Our results show\nthat by amplifying the intensity of the clear-sky radiative cooling effect, the\ntransition from a quasi-uniform to an inhomogeneous cloud field can be\nreproduced. The model also successfully explains the dependence of\nself-aggregation on several model parameters, such as the experimental domain\nsize and the characteristic size of cold pools. Furthermore, by varying the\ndistance over which the subsidence induced by radiative cooling extends, we\nsucceed in capturing a pattern formation that closely resembles the convective\nclusters observed in the real atmosphere and three-dimensional numerical model\nsimulations.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-22T10:38:33Z"}
{"aid":"http://arxiv.org/abs/2504.15782v1","title":"Model-based Metric 3D Shape and Motion Reconstruction of Wild Bottlenose\n  Dolphins in Drone-Shot Videos","summary":"We address the problem of estimating the metric 3D shape and motion of wild\ndolphins from monocular video, with the aim of assessing their body condition.\nWhile considerable progress has been made in reconstructing 3D models of\nterrestrial quadrupeds, aquatic animals remain unexplored due to the difficulty\nof observing them in their natural underwater environment. To address this, we\npropose a model-based approach that incorporates a transmission model to\naccount for water-induced occlusion. We apply our method to video captured\nunder different sea conditions. We estimate mass and volume, and compare our\nresults to a manual 2D measurements-based method.","main_category":"cs.CV","categories":"cs.CV,cs.GR","published":"2025-04-22T10:47:29Z"}
{"aid":"http://arxiv.org/abs/2504.15786v1","title":"Satellite to GroundScape -- Large-scale Consistent Ground View\n  Generation from Satellite Views","summary":"Generating consistent ground-view images from satellite imagery is\nchallenging, primarily due to the large discrepancies in viewing angles and\nresolution between satellite and ground-level domains. Previous efforts mainly\nconcentrated on single-view generation, often resulting in inconsistencies\nacross neighboring ground views. In this work, we propose a novel cross-view\nsynthesis approach designed to overcome these challenges by ensuring\nconsistency across ground-view images generated from satellite views. Our\nmethod, based on a fixed latent diffusion model, introduces two conditioning\nmodules: satellite-guided denoising, which extracts high-level scene layout to\nguide the denoising process, and satellite-temporal denoising, which captures\ncamera motion to maintain consistency across multiple generated views. We\nfurther contribute a large-scale satellite-ground dataset containing over\n100,000 perspective pairs to facilitate extensive ground scene or video\ngeneration. Experimental results demonstrate that our approach outperforms\nexisting methods on perceptual and temporal metrics, achieving high\nphotorealism and consistency in multi-view outputs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T10:58:42Z"}
{"aid":"http://arxiv.org/abs/2504.15789v1","title":"Doubly-charmed pentaquark states in a mass splitting model","summary":"Concentrating on the mass differences relative to $P_{\\psi}^{N}(4312)^+$, we\nsystematically investigate the spectra of doubly-charmed pentaquark states in\nthe compact $ccqq\\bar{q}$ ($q=u, d, s$) configuration. The assumption that the\nobserved $P_{\\psi}^{N}(4312)^+$ is a compact hidden-charm pentaquark with\n$I(J^P)=\\frac12(\\frac32^-)$ is adopted. We also study the properties of strong\ndecays within a simple rearrangement scheme. The results indicate that the\n$I(J^P)=\\frac12(\\frac12^-)$ $ccnn\\bar{n}$ with $I_{nn}=0$ where $n$ denotes $u$\nor $d$ quark, $I(J^P)=0(\\frac12^-)$ $ccnn\\bar{s}$, and $I(J^P)=0(\\frac12^-)$\n$ccns\\bar{n}$ ground states should be stable.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-22T11:03:34Z"}
{"aid":"http://arxiv.org/abs/2504.15818v1","title":"Uniqueness of Parisi measures for enriched convex vector spin glass","summary":"In the PDE approach to mean-field spin glasses, it has been observed that the\nfree energy of convex spin glass models could be enriched by adding an extra\nparameter in its definition, and that the thermodynamic limit of the enriched\nfree energy satisfies a partial differential equation. This parameter can be\nthought of as a matrix-valued path, and the usual free energy is recovered by\nsetting this parameter to be the constant path taking only the value $0$.\nFurthermore, the enriched free energy can be expressed using a variational\nformula, which is a natural extension of the Parisi formula for the usual free\nenergy. For models with scalar spins the Parisi formula can be expressed as an\noptimization problem over a convex set, and it was shown in [arXiv:1402.5132]\nthat this problem has a unique optimizer thanks to a strict convexity property.\nFor models with vector spins, the Parisi formula cannot easily be written as a\nconvex optimization problem. In this paper, we generalize the uniqueness of\nParisi measures proven in [arXiv:1402.5132] to the enriched free energy of\nmodels with vector spins when the extra parameter is a strictly increasing\npath. Our approach relies on a Gateaux differentiability property of the free\nenergy and the envelope theorem.","main_category":"math.PR","categories":"math.PR,math.AP","published":"2025-04-22T12:03:46Z"}
{"aid":"http://arxiv.org/abs/2504.15827v1","title":"DualOptim: Enhancing Efficacy and Stability in Machine Unlearning with\n  Dual Optimizers","summary":"Existing machine unlearning (MU) approaches exhibit significant sensitivity\nto hyperparameters, requiring meticulous tuning that limits practical\ndeployment. In this work, we first empirically demonstrate the instability and\nsuboptimal performance of existing popular MU methods when deployed in\ndifferent scenarios. To address this issue, we propose Dual Optimizer\n(DualOptim), which incorporates adaptive learning rate and decoupled momentum\nfactors. Empirical and theoretical evidence demonstrates that DualOptim\ncontributes to effective and stable unlearning. Through extensive experiments,\nwe show that DualOptim can significantly boost MU efficacy and stability across\ndiverse tasks, including image classification, image generation, and large\nlanguage models, making it a versatile approach to empower existing MU\nalgorithms.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-22T12:18:26Z"}
{"aid":"http://arxiv.org/abs/2504.15830v1","title":"Predictive Synthesis of Control Barrier Functions and its Application to\n  Time-Varying Constraints","summary":"This paper presents a systematic method for synthesizing a Control Barrier\nFunction (CBF) that encodes predictive information into a CBF. Unlike other\nmethods, the synthesized CBF can account for changes and time-variations in the\nconstraints even when constructed for time-invariant constraints. This avoids\nrecomputing the CBF when the constraint specifications change. The method\nprovides an explicit characterization of the extended class K function {\\alpha}\nthat determines the dynamic properties of the CBF, and {\\alpha} can even be\nexplicitly chosen as a design parameter in the controller synthesis. The\nresulting CBF further accounts for input constraints, and its values can be\ndetermined at any point without having to compute the CBF over the entire\ndomain. The synthesis method is based on a finite horizon optimal control\nproblem inspired by Hamilton-Jacobi reachability analysis and does not rely on\na nominal control law. The synthesized CBF is time-invariant if the constraints\nare. The method poses mild assumptions on the controllability of the dynamic\nsystem and assumes the knowledge of at least a subset of some control invariant\nset. The paper provides a detailed analysis of the properties of the\nsynthesized CBF, including its application to time-varying constraints. A\nsimulation study applies the proposed approach to various dynamic systems in\nthe presence of time-varying constraints. The paper is accompanied by an online\navailable parallelized implementation of the proposed synthesis method.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-22T12:21:16Z"}
{"aid":"http://arxiv.org/abs/2504.15844v1","title":"Sound and Complete Invariant-Based Heap Encodings (Technical Report)","summary":"Verification of programs operating on mutable, heap-allocated data structures\nposes significant challenges due to potentially unbounded structures like\nlinked lists and trees. In this paper, we present a novel relational heap\nencoding leveraging uninterpreted predicates and prophecy variables, reducing\nheap verification tasks to satisfiability checks over integers in constrained\nHorn clauses (CHCs). To the best of our knowledge, our approach is the first\ninvariant-based method that achieves both soundness and completeness for\nheap-manipulating programs. We provide formal proofs establishing the\ncorrectness of our encodings. Through an experimental evaluation we demonstrate\nthat our method significantly extends the capability of existing CHC-based\nverification tools, allowing automatic verification of programs with heap\npreviously unreachable by state-of-the-art tools.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-22T12:40:21Z"}
{"aid":"http://arxiv.org/abs/2504.15851v1","title":"Sensitivity analysis for parametric nonlinear programming: A tutorial","summary":"This tutorial provides an overview of the current state-of-the-art in the\nsensitivity analysis for nonlinear programming. Building upon the fundamental\nwork of Fiacco, it derives the sensitivity of primal-dual solutions for regular\nnonlinear programs and explores the extent to which Fiacco's framework can be\nextended to degenerate nonlinear programs with non-unique dual solutions. The\nsurvey ends with a discussion on how to adapt the sensitivity analysis for\nconic programs and approximate solutions obtained from interior-point\nalgorithms.","main_category":"math.OC","categories":"math.OC","published":"2025-04-22T12:45:36Z"}
{"aid":"http://arxiv.org/abs/2504.15853v1","title":"DFT exploration of pressure dependent physical properties of the\n  recently discovered La3Ni2O7 superconductor","summary":"The recent discovery of superconductivity in Ruddlesden-Popper bilayer\nnickelate La3Ni2O7 under pressure has drawn a lot of interest. La3Ni2O7 is\nisostructural with cuprates in some respect. Investigation of its properties\nwill undoubtedly provide new insights into high-Tc superconductivity. In the\npresent work, we study structural, mechanical, elastic, optoelectronic,\nthermophysical properties, and Fermi surface topology of La3Ni2O7 under\npressure within the range of 30-40 GPa employing the density functional theory\n(DFT). The calculated structural parameters agree well with the earlier\nexperimental findings. The structural, mechanical, and thermodynamical\nstability is justified across the entire pressure range. The computed elastic\nmoduli classify the compound as ductile, and the material's ductility is\nlargely unaffected by pressure. The compound has a high level of machinability\nindex and dry lubricity. The electronic band structure reveals metallic feature\nof La3Ni2O7. The Debye temperature, thermal conductivity, and melting\ntemperature increase with increasing pressure, but in an anomalous manner. The\ncharacteristic peaks in refractive index, reflectivity, and photoconductivity\nexhibit a small shift towards higher energy for all polarizations of the\nelectric field vector with increasing pressure. The investigated material might\nbe a good ultraviolet radiation absorber and can be used as an anti-reflection\nsystem. Moreover, the pressure dependent electronic density of states at the\nFermi level, pressure induced negligible variations in the repulsive Coulomb\npseudopotential, and the changes in the Debye temperature have been used to\nexplore the effect of pressure on the superconducting transition temperature in\nthis study.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.mtrl-sci","published":"2025-04-22T12:49:03Z"}
{"aid":"http://arxiv.org/abs/2504.15858v1","title":"Positive-tone Nanolithography of Antimony Trisulfide with Femtosecond\n  Laser Wet-etching","summary":"Antimony trisulfide ($Sb_{2}S_{3}$), as an emerging material for integrated\nphotonic devices, has attracted significant attention due to its high index,\nlow loss, and phase-changing property in the optical regime. However,\nconventional lithography-based fabrication methods involve complex,\ntime-consuming, multistep processes, rendering the photonic application of\n$Sb_{2}S_{3}$ challenging. Here, we demonstrate that positive-tone fabrication\nof $Sb_{2}S_{3}$ nanostructures using wet-etch femtosecond laser processing, a\nstraightforward technique for the engraving of micro- and nanoscale structures,\ncan address major fabrication challenges. The patterning mechanism and factors\ninfluencing resolution of $Sb_{2}S_{3}$ thin film structures deposited on\nquartz (transmissive) and gold (reflective) substrates are experimentally\ninvestigated and supported by theoretical modelling. Using this approach, the\nsmallest linewidth fabricated is measured at 178 nm. Consequently, multiple\ntest patterns are demonstrated showing versatile functionalities. Functional\nFresnel Zone Plates (FZPs) with varying focal length are fabricated and\ncharacterized. This study provides a significantly simplified approach for\nrealizing $Sb_{2}S_{3}$ based integrated photonic devices.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mtrl-sci,physics.ins-det","published":"2025-04-22T12:53:43Z"}
{"aid":"http://arxiv.org/abs/2504.15899v1","title":"RaSCL: Radar to Satellite Crossview Localization","summary":"GNSS is unreliable, inaccurate, and insufficient in many real-time autonomous\nfield applications. In this work, we present a GNSS-free global localization\nsolution that contains a method of registering imaging radar on the ground with\noverhead RGB imagery, with joint optimization of relative poses from odometry\nand global poses from our overhead registration. Previous works have used\nvarious combinations of ground sensors and overhead imagery, and different\nfeature extraction and matching methods. These include various handcrafted and\ndeep-learning-based methods for extracting features from overhead imagery. Our\nwork presents insights on extracting essential features from RGB overhead\nimages for effective global localization against overhead imagery using only\nground radar and a single georeferenced initial guess. We motivate our method\nby evaluating it on datasets in diverse geographic conditions and robotic\nplatforms, including on an Unmanned Surface Vessel (USV) as well as urban and\nsuburban driving datasets.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-22T13:41:04Z"}
{"aid":"http://arxiv.org/abs/2504.15925v1","title":"Improving robustness and training efficiency of machine-learned\n  potentials by incorporating short-range empirical potentials","summary":"Machine learning force fields (MLFFs) are powerful tools for materials\nmodeling, but their performance is often limited by training dataset quality,\nparticularly the lack of rare event configurations. This limitation undermines\ntheir accuracy and robustness in long-time and large-scale molecular dynamics\nsimulations. In this work, we present a hybrid MLFF framework that integrates\nan empirical short-range repulsive potential and demonstrates improved\nrobustness and training efficiency. Using solid electrolyte\nLi$_7$La$_3$Zr$_2$O$_{12}$ (LLZO) as a model system, we show that purely\ndata-driven MLFFs fail to prevent unphysical atomistic clustering in extended\nsimulations due to inadequate short-range repulsion. In contrast, the hybrid\nforce field eliminates these artifacts, enabling stable long-time simulations,\nwhich are critical for studying various properties of LLZO. The hybrid\nframework also reduces the need for extensive active learning and performs well\nwith just 25 training configurations. By combining physics-driven constraints\nwith data-driven flexibility, this approach is compatible with most existing\nMLFF architectures and establishes a universal paradigm for developing robust,\ntraining-efficient force fields for complex material systems.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-22T14:12:45Z"}
{"aid":"http://arxiv.org/abs/2504.15927v1","title":"New Recipe for Semi-supervised Community Detection: Clique Annealing\n  under Crystallization Kinetics","summary":"Semi-supervised community detection methods are widely used for identifying\nspecific communities due to the label scarcity. Existing semi-supervised\ncommunity detection methods typically involve two learning stages learning in\nboth initial identification and subsequent adjustment, which often starts from\nan unreasonable community core candidate. Moreover, these methods encounter\nscalability issues because they depend on reinforcement learning and generative\nadversarial networks, leading to higher computational costs and restricting the\nselection of candidates. To address these limitations, we draw a parallel\nbetween crystallization kinetics and community detection to integrate the\nspontaneity of the annealing process into community detection. Specifically, we\nliken community detection to identifying a crystal subgrain (core) that expands\ninto a complete grain (community) through a process similar to annealing. Based\non this finding, we propose CLique ANNealing (CLANN), which applies kinetics\nconcepts to community detection by integrating these principles into the\noptimization process to strengthen the consistency of the community core.\nSubsequently, a learning-free Transitive Annealer was employed to refine the\nfirst-stage candidates by merging neighboring cliques and repositioning the\ncommunity core, enabling a spontaneous growth process that enhances\nscalability. Extensive experiments on \\textbf{43} different network settings\ndemonstrate that CLANN outperforms state-of-the-art methods across multiple\nreal-world datasets, showcasing its exceptional efficacy and efficiency in\ncommunity detection.","main_category":"cs.SI","categories":"cs.SI,cs.AI","published":"2025-04-22T14:17:15Z"}
{"aid":"http://arxiv.org/abs/2504.15985v1","title":"Modeling and Forecasting Realized Volatility with Multivariate\n  Fractional Brownian Motion","summary":"A multivariate fractional Brownian motion (mfBm) with component-wise Hurst\nexponents is used to model and forecast realized volatility. We investigate the\ninterplay between correlation coefficients and Hurst exponents and propose a\nnovel estimation method for all model parameters, establishing consistency and\nasymptotic normality of the estimators. Additionally, we develop a\ntime-reversibility test, which is typically not rejected by real volatility\ndata. When the data-generating process is a time-reversible mfBm, we derive\noptimal forecasting formulae and analyze their properties. A key insight is\nthat an mfBm with different Hurst exponents and non-zero correlations can\nreduce forecasting errors compared to a one-dimensional model. Consistent with\noptimal forecasting theory, out-of-sample forecasts using the time-reversible\nmfBm show improvements over univariate fBm, particularly when the estimated\nHurst exponents differ significantly. Empirical results demonstrate that\nmfBm-based forecasts outperform the (vector) HAR model.","main_category":"q-fin.ST","categories":"q-fin.ST","published":"2025-04-22T15:38:31Z"}
{"aid":"http://arxiv.org/abs/2504.16027v1","title":"Benchmarking LLM for Code Smells Detection: OpenAI GPT-4.0 vs\n  DeepSeek-V3","summary":"Determining the most effective Large Language Model for code smell detection\npresents a complex challenge. This study introduces a structured methodology\nand evaluation matrix to tackle this issue, leveraging a curated dataset of\ncode samples consistently annotated with known smells. The dataset spans four\nprominent programming languages Java, Python, JavaScript, and C++; allowing for\ncross language comparison. We benchmark two state of the art LLMs, OpenAI GPT\n4.0 and DeepSeek-V3, using precision, recall, and F1 score as evaluation\nmetrics. Our analysis covers three levels of detail: overall performance,\ncategory level performance, and individual code smell type performance.\nAdditionally, we explore cost effectiveness by comparing the token based\ndetection approach of GPT 4.0 with the pattern-matching techniques employed by\nDeepSeek V3. The study also includes a cost analysis relative to traditional\nstatic analysis tools such as SonarQube. The findings offer valuable guidance\nfor practitioners in selecting an efficient, cost effective solution for\nautomated code smell detection","main_category":"cs.SE","categories":"cs.SE,cs.AI,cs.LG,cs.PL","published":"2025-04-22T16:44:39Z"}
{"aid":"http://arxiv.org/abs/2504.16036v1","title":"Rotational ultrasound and photoacoustic tomography of the human body","summary":"Imaging the human body's morphological and angiographic information is\nessential for diagnosing, monitoring, and treating medical conditions.\nUltrasonography performs the morphological assessment of the soft tissue based\non acoustic impedance variations, whereas photoacoustic tomography (PAT) can\nvisualize blood vessels based on intrinsic hemoglobin absorption.\nThree-dimensional (3D) panoramic imaging of the vasculature is generally not\npractical in conventional ultrasonography with limited field-of-view (FOV)\nprobes, and PAT does not provide sufficient scattering-based soft tissue\nmorphological contrast. Complementing each other, fast panoramic rotational\nultrasound tomography (RUST) and PAT are integrated for hybrid rotational\nultrasound and photoacoustic tomography (RUS-PAT), which obtains 3D ultrasound\nstructural and PAT angiographic images of the human body quasi-simultaneously.\nThe RUST functionality is achieved in a cost-effective manner using a\nsingle-element ultrasonic transducer for ultrasound transmission and rotating\narc-shaped arrays for 3D panoramic detection. RUST is superior to conventional\nultrasonography, which either has a limited FOV with a linear array or is\nhigh-cost with a hemispherical array that requires both transmission and\nreceiving. By switching the acoustic source to a light source, the system is\nconveniently converted to PAT mode to acquire angiographic images in the same\nregion. Using RUS-PAT, we have successfully imaged the human head, breast,\nhand, and foot with a 10 cm diameter FOV, submillimeter isotropic resolution,\nand 10 s imaging time for each modality. The 3D RUS-PAT is a powerful tool for\nhigh-speed, 3D, dual-contrast imaging of the human body with potential for\nrapid clinical translation.","main_category":"physics.med-ph","categories":"physics.med-ph,eess.SP,physics.app-ph","published":"2025-04-22T17:02:12Z"}
{"aid":"http://arxiv.org/abs/2504.16409v1","title":"A Molecular Dynamics Study of Size Effects for Critical Resolved Shear\n  Stress in Nickel Superalloys","summary":"We present in this work a molecular dynamics study of a size effect relating\nto the volume fraction of gamma-prime precipitate of edge dislocation motion in\na simple model of Nickel superalloys. We model the superalloy as periodically\nspaced cubic gamma-prime precipitates inside a uniform gamma matrix. We then\nanalyze the motion of paired edge dislocations in the gamma phase when subject\nto an external shear stress for various volume fractions of the gamma-prime\nprecipitate for a wide range of temperatures, from 300 K to 700 K. While the\nvariation of dislocation velocity is not significant, the critical resolved\nshear stress is found to exhibit a power law dependence on the volume fraction\nof the gamma-prime precipitate with two distinct regimes which have similar\nexponent but markedly different prefactors; we also observe that this\ntwo-regime behavior remains true across a wide range of temperatures. We\npresent a detailed analysis of this behavior and reduce it to a linear\ndependence of the critical resolved shear stress on the length of the\ngamma-prime precipitate along the direction of dislocation motion. We further\nidentify the critical length scale underlying the transition between the two\nobserved regimes as the total core width of the paired dislocations in a pure\ngamma-prime system, which includes in addition to the complex stacking fault\nseparating the partials of the paired dislocations the width of the anti-phase\nboundary that is formed between the super-dislocations. The results presented\nin this work provides new details on the strengthening effect of gamma-prime\nprecipitates in nickel superalloys and also has important implications for\nlarger scale dislocation dynamics studies for nickel superalloys.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-23T04:24:03Z"}
{"aid":"http://arxiv.org/abs/2504.16428v1","title":"Energy Rates Due to Weak Decay Rates of Vanadium Isotopes in Stellar\n  Environment","summary":"The neutrino cooling and gamma heating rates are considered as an important\ninput needed to study the final phases of the evolution of high-mass stars. The\nweak-interaction mediated processes, namely the $\\beta$-decay and electron\ncapture, significantly change the lepton to baryon ratio and accelerate the\ncontraction of the core. The emission of resulting neutrinos/antineutrinos\ntends to cool the stellar core. On the other hand, gamma rays are produced\nbecause of electron capture and $\\beta$-decay to excited states in daughter\nnuclei. These gamma rays heat the core and contribute to an increase of entropy\nwhich may cause convection to occur.\n  In the present work, the weak-interaction heating and cooling rates on a\nchain of twenty-two isotopes of vanadium having mass in the range $43-64$ have\nbeen estimated using the proton-neutron quasiparticle random phase\napproximation theory. The rates have been computed for the temperature ranging\nfrom ($10^{7} - 3 \\times 10^{10}$)\\;K and for the density range\n($10-10^{11}$)\\;g/cm$^{3}$. Our calculated neutrino energy loss rates have also\nbeen compared with the previously reported rates calculated using other\ntheoretical models. At high stellar temperatures, our rates are larger by 1-2\norders of magnitude as compared to previous results.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-23T05:25:42Z"}
{"aid":"http://arxiv.org/abs/2504.16438v1","title":"Private Federated Learning using Preference-Optimized Synthetic Data","summary":"In practical settings, differentially private Federated learning (DP-FL) is\nthe dominant method for training models from private, on-device client data.\nRecent work has suggested that DP-FL may be enhanced or outperformed by methods\nthat use DP synthetic data (Wu et al., 2024; Hou et al., 2024). The primary\nalgorithms for generating DP synthetic data for FL applications require careful\nprompt engineering based on public information and/or iterative private client\nfeedback. Our key insight is that the private client feedback collected by\nprior DP synthetic data methods (Hou et al., 2024; Xie et al., 2024) can be\nviewed as a preference ranking. Our algorithm, Preference Optimization for\nPrivate Client Data (POPri) harnesses client feedback using preference\noptimization algorithms such as Direct Preference Optimization (DPO) to\nfine-tune LLMs to generate high-quality DP synthetic data. To evaluate POPri,\nwe release LargeFedBench, a new federated text benchmark for uncontaminated LLM\nevaluations on federated client data. POPri substantially improves the utility\nof DP synthetic data relative to prior work on LargeFedBench datasets and an\nexisting benchmark from Xie et al. (2024). POPri closes the gap between\nnext-token prediction accuracy in the fully-private and non-private settings by\nup to 68%, compared to 52% for prior synthetic data methods, and 10% for\nstate-of-the-art DP federated learning methods. The code and data are available\nat https://github.com/meiyuw/POPri.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CR,cs.DC","published":"2025-04-23T05:57:20Z"}
{"aid":"http://arxiv.org/abs/2504.16468v1","title":"HAQA: A Hardware-Guided and Fidelity-Aware Strategy for Efficient Qubit\n  Mapping Optimization","summary":"Quantum algorithms rely on quantum computers for implementation, but the\nphysical connectivity constraints of modern quantum processors impede the\nefficient realization of quantum algorithms. Qubit mapping, a critical\ntechnology for practical quantum computing applications, directly determines\nthe execution efficiency and feasibility of algorithms on superconducting\nquantum processors. Existing mapping methods overlook intractable quantum\nhardware fidelity characteristics, reducing circuit execution quality. They\nalso exhibit prolonged solving times or even failure to complete when handling\nlarge-scale quantum architectures, compromising efficiency. To address these\nchallenges, we propose a novel qubit mapping method HAQA. HAQA first introduces\na community-based iterative region identification strategy leveraging hardware\nconnection topology, achieving effective dimensionality reduction of mapping\nspace. This strategy avoids global search procedures, with complexity analysis\ndemonstrating quadratic polynomial-level acceleration. Furthermore, HAQA\nimplements a hardware-characteristic-based region evaluation mechanism,\nenabling quantitative selection of mapping regions based on fidelity metrics.\nThis approach effectively integrates hardware fidelity information into the\nmapping process, enabling fidelity-aware qubit allocation. Experimental results\ndemonstrate that HAQA significantly improves solving speed and fidelity while\nensuring solution quality. When applied to state-of-the-art quantum mapping\ntechniques Qsynth-v2 and TB-OLSQ2, HAQA achieves acceleration ratios of 632.76\nand 286.87 respectively, while improving fidelity by up to 52.69% and 238.28%","main_category":"quant-ph","categories":"quant-ph,cs.ET","published":"2025-04-23T07:27:27Z"}
{"aid":"http://arxiv.org/abs/2504.16479v1","title":"The Dance of Atoms-De Novo Protein Design with Diffusion Model","summary":"The de novo design of proteins refers to creating proteins with specific\nstructures and functions that do not naturally exist. In recent years, the\naccumulation of high-quality protein structure and sequence data and\ntechnological advancements have paved the way for the successful application of\ngenerative artificial intelligence (AI) models in protein design. These models\nhave surpassed traditional approaches that rely on fragments and\nbioinformatics. They have significantly enhanced the success rate of de novo\nprotein design, and reduced experimental costs, leading to breakthroughs in the\nfield. Among various generative AI models, diffusion models have yielded the\nmost promising results in protein design. In the past two to three years, more\nthan ten protein design models based on diffusion models have emerged. Among\nthem, the representative model, RFDiffusion, has demonstrated success rates in\n25 protein design tasks that far exceed those of traditional methods, and other\nAI-based approaches like RFjoint and hallucination. This review will\nsystematically examine the application of diffusion models in generating\nprotein backbones and sequences. We will explore the strengths and limitations\nof different models, summarize successful cases of protein design using\ndiffusion models, and discuss future development directions.","main_category":"q-bio.BM","categories":"q-bio.BM,cs.AI","published":"2025-04-23T07:45:00Z"}
{"aid":"http://arxiv.org/abs/2504.16528v1","title":"Quantitative Strategy Templates","summary":"This paper presents (permissive) \\emph{Quantitative Strategy Templates}\n(QaSTels) to succinctly represent infinitely many winning strategies in\ntwo-player energy and mean-payoff games. This transfers the recently introduced\nconcept of \\emph{Permissive (qualitative) Strategy Templates} (PeSTels) for\n$\\omega$-regular games to games with quantitative objectives. We provide the\ntheoretical and algorithmic foundations of (i) QaSTel synthesis, and (ii) their\n(incremental) combination with PeSTels for games with mixed quantitative and\nqualitative objectives. Using a prototype implementation of our synthesis\nalgorithms, we demonstrate empirically that QaSTels extend the advantageous\nproperties of strategy templates over single winning strategies -- known from\nPeSTels -- to games with (additional) quantitative objectives. This includes\n(i) the enhanced robustness of strategies due to their runtime-adaptability,\nand (ii) the compositionality of templates w.r.t. incrementally arriving\nobjectives. We use control-inspired examples to illustrate these superior\nproperties of QaSTels for CPS design.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-23T08:53:10Z"}
{"aid":"http://arxiv.org/abs/2504.16547v1","title":"Generation of Phonons with Angular Momentum During Ultrafast\n  Demagnetization","summary":"A major question in the field of femtosecond laser-induced demagnetization is\nwhereto the angular momentum lost by the electrons is transferred. Recent\nultrafast electron diffraction measurements [Tauchert \\textit{et al.}, Nature\n{\\bf 602}, 73 (2022)] suggest that this angular momentum is transferred to the\nrotational motion of atoms on a sub-picosecond timescale, but a theory\nconfirmation of this proposition has yet to be given. Here we investigate the\ncoupled electron-nuclear dynamics during ultrafast demagnetization of L1$_0$\nFePt, using Ehrenfest nuclear dynamics simulations combined with the\ntime-dependent density functional theory (TDDFT) framework. We demonstrate that\natomic rotations appear, i.e., the generation of phonons carrying finite\nangular momentum following ultrafast demagnetization. We further show that both\nultrafast demagnetization and the generation of phonons with angular momentum\narise from symmetry constraints imposed by the spin-orbit coupling, thus\nproviding insight in spin-phonon interaction at ultrafast timescales.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.atom-ph","published":"2025-04-23T09:23:31Z"}
{"aid":"http://arxiv.org/abs/2504.16566v1","title":"Optically detected and radio wave-controlled spin chemistry in\n  cryptochrome","summary":"Optically addressable spin systems, such as nitrogen-vacancy (NV) centers in\ndiamond, have been widely studied for quantum sensing applications. In this\nwork, we demonstrate that flavin-based cryptochrome proteins, which generate\nradical pairs upon optical excitation, also exhibit optically detected magnetic\nresonance. We further show that this optical spin interface is tunable by the\nprotein structure. These findings establish radical pairs in proteins as a\nnovel platform for optically addressable spin systems and magnetic field\nsensors. Additionally, the ability to control spin transitions introduces a new\nclass of biophysical tools that hold promise for enabling multiplexed\nfluorescence microscopy. Importantly, due to the spin-selective nature of\nradical pair chemistry, the results lay the groundwork for radiofrequency-based\nmanipulation of biological systems.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T09:45:30Z"}
{"aid":"http://arxiv.org/abs/2504.16599v1","title":"A two-dimensional swarmalator model with higher-order interactions","summary":"We study a simple two-dimensional swarmalator model that incorporates\nhigher-order phase interactions, uncovering a diverse range of collective\nstates. The latter include spatially coherent and gas-like configurations,\nneither of which appear in models with only pairwise interactions.\nAdditionally, we discover bistability between various states, a phenomenon that\narises directly from the inclusion of higher-order interactions. By analyzing\nseveral of these emergent states analytically, both for identical and\nnonidentical populations of swarmalators, we gain deeper insights into their\nunderlying mechanisms and stability conditions. Our findings broaden the\nunderstanding of swarmalator dynamics and open new avenues for exploring\ncomplex collective behaviors in systems governed by higher-order interactions.","main_category":"nlin.AO","categories":"nlin.AO,math-ph,math.MP","published":"2025-04-23T10:28:13Z"}
{"aid":"http://arxiv.org/abs/2504.16617v1","title":"Security Science (SecSci), Basic Concepts and Mathematical Foundations","summary":"This textbook compiles the lecture notes from security courses taught at\nOxford in the 2000s, at Royal Holloway in the 2010s, and currently in Hawaii.\nThe early chapters are suitable for a first course in security. The middle\nchapters have been used in advanced courses. Towards the end there are also\nsome research problems.","main_category":"cs.CR","categories":"cs.CR,cs.CY,cs.IT,cs.SI,math.IT,math.LO","published":"2025-04-23T11:04:17Z"}
{"aid":"http://arxiv.org/abs/2504.16618v1","title":"The quantum spin Brauer category","summary":"We introduce a diagrammatic braided monoidal category, the quantum spin\nBrauer category, together with a full functor to the category of\nfinite-dimensional, type $1$ modules for $U_q(\\mathfrak{so}(N))$ or\n$U_q(\\mathfrak{o}(N))$. This functor becomes essentially surjective after\npassing to the idempotent completion. The quantum spin Brauer category can be\nthought of as a quantum version of the spin Brauer category introduced\npreviously by the authors. Alternatively, it is an enlargement of the Kauffman\ncategory, obtained by adding a generating object corresponding to the quantum\nspin module.","main_category":"math.QA","categories":"math.QA,math.RT","published":"2025-04-23T11:06:25Z"}
{"aid":"http://arxiv.org/abs/2504.16622v1","title":"Cognitive Silicon: An Architectural Blueprint for Post-Industrial\n  Computing Systems","summary":"Autonomous AI systems reveal foundational limitations in deterministic,\nhuman-authored computing architectures. This paper presents Cognitive Silicon:\na hypothetical full-stack architectural framework projected toward 2035,\nexploring a possible trajectory for cognitive computing system design. The\nproposed architecture would integrate symbolic scaffolding, governed memory,\nruntime moral coherence, and alignment-aware execution across\nsilicon-to-semantics layers. Our design grammar has emerged from dialectical\nco-design with LLMs under asymmetric epistemic conditions--creating structured\nfriction to expose blind spots and trade-offs. The envisioned framework would\nestablish mortality as a natural consequence of physical constraints,\nnon-copyable tacit knowledge, and non-cloneable identity keys as\ncognitive-embodiment primitives. Core tensions (trust/agency,\nscaffolding/emergence, execution/governance) would function as central\narchitectural pressures rather than edge cases. The architecture theoretically\nconverges with the Free Energy Principle, potentially offering a formal account\nof how cognitive systems could maintain identity through prediction error\nminimization across physical and computational boundaries. The resulting\nframework aims to deliver a morally tractable cognitive infrastructure that\ncould maintain human-alignment through irreversible hardware constraints and\nidentity-bound epistemic mechanisms resistant to replication or subversion.","main_category":"cs.AI","categories":"cs.AI,cs.CY","published":"2025-04-23T11:24:30Z"}
{"aid":"http://arxiv.org/abs/2504.16626v1","title":"Solvability of elliptic homogeneous linear equations with measure data\n  in weighted Lebesgue spaces","summary":"Let $A(D)$ be an elliptic homogeneous linear differential operator with\ncomplex constant coefficients, $ \\mu $ be a vector-valued Borel measure and $w$\nbe a positive locally integrable function on $\\mathbb{R}^N$. In this work, we\npresent sufficient conditions on $\\mu$ and $w$ for the existence of solutions\nin the weighted Lebesgue spaces $L^p_w$ for the equation $A^{*}(D)f=\\mu$, for $\n1\\leq p<\\infty $. Those conditions are related to a certain control of the\nRiesz potential of the measure $\\mu$. We also present sufficient conditions for\nthe solvability when $p=\\infty$ adding a canceling condition on the operator.\nOur method is based on a new weighted $L^1$ Stein-Weiss type inequality on\nmeasures for a special class of vector fields.","main_category":"math.AP","categories":"math.AP","published":"2025-04-23T11:33:46Z"}
{"aid":"http://arxiv.org/abs/2504.16648v1","title":"FAST Observation and Results for Core Collapse Globular Cluster M15 and\n  NGC 6517","summary":"Radio astronomy is part of radio science that developed rapidly in recent\ndecades. In the research of radio astronomy, pulsars have always been an\nenduring popular research target. To find and observe more pulsars, large radio\ntelescopes have been built all over the world. In this paper, we present our\nstudies on pulsars in M15 and NGC 6517 with FAST, including monitoring pulsars\nin M15 and new pulsar discoveries in NGC 6517. All the previously known pulsars\nin M15 were detected without no new discoveries. Among them, M15C was still\ndetectable by FAST, while it is assumed to fade out due to precession [1]. In\nNGC 6517, new pulsars were continues to be discovered and all of them are tend\nto be isolated pulsars. Currently, the number of pulsars in NGC 6517 is 17,\nmuch more than the predicted before [2].","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-23T12:10:04Z"}
{"aid":"http://arxiv.org/abs/2504.16650v1","title":"Small Alfv√©n Number Limit for the Global-in-time Solutions of\n  Incompressible MHD Equations with General Initial Data","summary":"The small Alfv\\'en number (denoted by $\\varepsilon$) limit (one type of large\nparameter limits, i.e. singular limits) in magnetohydrodynamic (abbr. MHD)\nequations was first proposed by Klainerman--Majda in (Comm. Pure Appl. Math.\n34: 481--524, 1981). Recently Ju--Wang--Xu mathematically verified that the\n\\emph{local-in-time} solutions of three-dimensional (abbr. 3D) ideal (i.e. the\nabsence of the dissipative terms) incompressible MHD equations with general\ninitial data in $\\mathbb{T}^3$ (i.e. a spatially periodic domain) tend to a\nsolution of 2D ideal MHD equations in the distribution sense as $\\varepsilon\\to\n0$ by Schochet's fast averaging method in (J. Differential Equations, 114:\n476--512, 1994). In this paper, we revisit the small Alfv\\'en number limit in\n$\\mathbb{R}^n$ with $n=2$, $3$, and develop another approach, motivated by\nCai--Lei's energy method in (Arch. Ration. Mech. Anal. 228: 969--993, 2018), to\nestablish a new conclusion that the \\emph{global-in-time} solutions of\nincompressible MHD equations (including the viscous resistive case) with\ngeneral initial data converge to zero as $\\varepsilon\\to 0$ for any given\ntime-space variable $(x,t)$ with $t>0$. In addition, we find that the large\nperturbation solutions and vanishing phenomenon of the nonlinear interactions\nalso exist in the \\emph{viscous resistive} MHD equations for small Alfv\\'en\nnumbers, and thus extend Bardos et al.'s results of the \\emph{ideal} MHD\nequations in (Trans Am Math Soc 305: 175--191, 1988).","main_category":"math.AP","categories":"math.AP","published":"2025-04-23T12:10:45Z"}
{"aid":"http://arxiv.org/abs/2504.16668v1","title":"Efficient Data Valuation Approximation in Federated Learning: A\n  Sampling-based Approach","summary":"Federated learning paradigm to utilize datasets across multiple data\nproviders. In FL, cross-silo data providers often hesitate to share their\nhigh-quality dataset unless their data value can be fairly assessed. Shapley\nvalue (SV) has been advocated as the standard metric for data valuation in FL\ndue to its desirable properties. However, the computational overhead of SV is\nprohibitive in practice, as it inherently requires training and evaluating an\nFL model across an exponential number of dataset combinations. Furthermore,\nexisting solutions fail to achieve high accuracy and efficiency, making\npractical use of SV still out of reach, because they ignore choosing suitable\ncomputation scheme for approximation framework and overlook the property of\nutility function in FL. We first propose a unified stratified-sampling\nframework for two widely-used schemes. Then, we analyze and choose the more\npromising scheme under the FL linear regression assumption. After that, we\nidentify a phenomenon termed key combinations, where only limited dataset\ncombinations have a high-impact on final data value. Building on these\ninsights, we propose a practical approximation algorithm, IPSS, which\nstrategically selects high-impact dataset combinations rather than evaluating\nall possible combinations, thus substantially reducing time cost with minor\napproximation error. Furthermore, we conduct extensive evaluations on the FL\nbenchmark datasets to demonstrate that our proposed algorithm outperforms a\nseries of representative baselines in terms of efficiency and effectiveness.","main_category":"cs.LG","categories":"cs.LG,cs.DB","published":"2025-04-23T12:36:20Z"}
{"aid":"http://arxiv.org/abs/2504.16675v1","title":"A Novel Sparse Sum and Difference Co-Array With Low Redundancy and\n  Enhanced DOF for Non-Circular Signals","summary":"Array structures based on the sum and difference co-arrays provide more\ndegrees of freedom (DOF). However, since the growth of DOF is limited by a\nsingle case of sum and difference co-arrays, the paper aims to design a sparse\nlinear array (SLA) with higher DOF via exploring different cases of\nsecond-order cumulants. We present a mathematical framework based on\nsecond-order cumulant to devise a second-order extended co-array (SO-ECA) and\ndefine the redundancy of SO-ECA. Based on SO-ECA, a novel array is proposed,\nnamely low redundancy sum and difference array (LR-SDA), which can provide\nclosed-form expressions for the sensor positions and enhance DOF in order to\nresolve more signal sources in the direction of arrival (DOA) estimation of\nnon-circular (NC) signals. For LR-SDA, the maximum DOF under the given number\nof total physical sensors can be derived and the SO-ECA of LR-SDA is hole-free.\nFurther, the corresponding necessary and sufficient conditions of signal\nreconstruction for LR-SDA are derived. Additionally, the redundancy and weight\nfunction of LR-SDA are defined, and the lower band of the redundancy for LR-SDA\nis derived. The proposed LR-SDA achieves higher DOF and lower redundancy than\nthose of existing DCAs designed based on sum and difference co-arrays.\nNumerical simulations are conducted to verify the superiority of LR-SDA on DOA\nestimation performance and enhanced DOF over other existing DCAs.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-23T12:45:06Z"}
{"aid":"http://arxiv.org/abs/2504.16679v1","title":"Transition mechanisms in hypersonic wind-tunnel nozzles: a\n  methodological approach using global linear stability analysis","summary":"Base-flow computations and stability analyses are performed for a hypersonic\nwind tunnel nozzle at a Mach number of 6. Isothermal and adiabatic wall\nboundary conditions are investigated, and moderate stagnation conditions are\nused to provide representative scenarios to study the transition in quiet\nhypersonic wind tunnel facilities. Under these conditions, the studied nozzle\nshows a small flow separation at the convergent inlet. Global stability\nanalysis reveals that this recirculation bubble may trigger a classical\nthree-dimensional stationary unstable global mode. Resolvent analysis reveals\nG\\\"ortler, first and second Mack modes affecting the divergent part of the\nnozzle, along with a Kelvin-Helmholtz instability induced by the bubble. The\npresent study also highlights the key impact of perturbations located in the\nconvergent inlet on the development of instabilities further downstream in the\ndivergent outlet, helping understand the need and efficacy of a suction lip\nupstream of the nozzle throat to mitigate instabilities in the divergent\nnozzle. Detailed knowledge of all these mechanisms is essential for\nunderstanding flows in quiet hypersonic wind tunnel nozzles and, consequently,\nrepresents a key step toward the optimisation of such nozzles.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-23T12:56:20Z"}
{"aid":"http://arxiv.org/abs/2504.16691v1","title":"Rethinking Vision Transformer for Large-Scale Fine-Grained Image\n  Retrieval","summary":"Large-scale fine-grained image retrieval (FGIR) aims to retrieve images\nbelonging to the same subcategory as a given query by capturing subtle\ndifferences in a large-scale setting. Recently, Vision Transformers (ViT) have\nbeen employed in FGIR due to their powerful self-attention mechanism for\nmodeling long-range dependencies. However, most Transformer-based methods focus\nprimarily on leveraging self-attention to distinguish fine-grained details,\nwhile overlooking the high computational complexity and redundant dependencies\ninherent to these models, limiting their scalability and effectiveness in\nlarge-scale FGIR. In this paper, we propose an Efficient and Effective\nViT-based framework, termed \\textbf{EET}, which integrates token pruning module\nwith a discriminative transfer strategy to address these limitations.\nSpecifically, we introduce a content-based token pruning scheme to enhance the\nefficiency of the vanilla ViT, progressively removing background or\nlow-discriminative tokens at different stages by exploiting feature responses\nand self-attention mechanism. To ensure the resulting efficient ViT retains\nstrong discriminative power, we further present a discriminative transfer\nstrategy comprising both \\textit{discriminative knowledge transfer} and\n\\textit{discriminative region guidance}. Using a distillation paradigm, these\ncomponents transfer knowledge from a larger ``teacher'' ViT to a more efficient\n``student'' model, guiding the latter to focus on subtle yet crucial regions in\na cost-free manner. Extensive experiments on two widely-used fine-grained\ndatasets and four large-scale fine-grained datasets demonstrate the\neffectiveness of our method. Specifically, EET reduces the inference latency of\nViT-Small by 42.7\\% and boosts the retrieval performance of 16-bit hash codes\nby 5.15\\% on the challenging NABirds dataset.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-23T13:23:56Z"}
{"aid":"http://arxiv.org/abs/2504.16708v1","title":"Density of rational languages under shift invariant measures","summary":"We study density of rational languages under shift invariant probability\nmeasures on spaces of two-sided infinite words, which generalizes the classical\nnotion of density studied in formal languages and automata theory. The density\nfor a language is defined as the limit in average (if it exists) of the\nprobability that a word of a given length belongs to the language. We establish\nthe existence of densities for all rational languages under all shift invariant\nmeasures. We also give explicit formulas under certain conditions, in\nparticular when the language is aperiodic. Our approach combines tools and\nideas from semigroup theory and ergodic theory.","main_category":"cs.FL","categories":"cs.FL","published":"2025-04-23T13:39:02Z"}
{"aid":"http://arxiv.org/abs/2504.16721v1","title":"Spectrum of cones of non-reduced plane curves with ordinary\n  singularities","summary":"We give a simple proof of the assertion claiming that the spectrum of the\ncone of a non-reduced plane curve can be determined only by its multiplicities\nalong local irreducible components at each singular point as well as those\nalong global ones together with the degrees of the latter (where the relation\nbetween global components and singular points is not needed) if the associated\nreduced plane curve have only ordinary singularities (for instance a line\narrangement). Note that the last condition is strictly weaker than local\nhomogeneity. As a corollary we can also get a simple proof of a formula which\nis equivalent to the one obtained earlier by the second-named author.","main_category":"math.AG","categories":"math.AG","published":"2025-04-23T13:51:18Z"}
{"aid":"http://arxiv.org/abs/2504.16722v1","title":"PMG: Progressive Motion Generation via Sparse Anchor Postures Curriculum\n  Learning","summary":"In computer animation, game design, and human-computer interaction,\nsynthesizing human motion that aligns with user intent remains a significant\nchallenge. Existing methods have notable limitations: textual approaches offer\nhigh-level semantic guidance but struggle to describe complex actions\naccurately; trajectory-based techniques provide intuitive global motion\ndirection yet often fall short in generating precise or customized character\nmovements; and anchor poses-guided methods are typically confined to synthesize\nonly simple motion patterns. To generate more controllable and precise human\nmotions, we propose \\textbf{ProMoGen (Progressive Motion Generation)}, a novel\nframework that integrates trajectory guidance with sparse anchor motion\ncontrol. Global trajectories ensure consistency in spatial direction and\ndisplacement, while sparse anchor motions only deliver precise action guidance\nwithout displacement. This decoupling enables independent refinement of both\naspects, resulting in a more controllable, high-fidelity, and sophisticated\nmotion synthesis. ProMoGen supports both dual and single control paradigms\nwithin a unified training process. Moreover, we recognize that direct learning\nfrom sparse motions is inherently unstable, we introduce \\textbf{SAP-CL (Sparse\nAnchor Posture Curriculum Learning)}, a curriculum learning strategy that\nprogressively adjusts the number of anchors used for guidance, thereby enabling\nmore precise and stable convergence. Extensive experiments demonstrate that\nProMoGen excels in synthesizing vivid and diverse motions guided by predefined\ntrajectory and arbitrary anchor frames. Our approach seamlessly integrates\npersonalized motion with structured guidance, significantly outperforming\nstate-of-the-art methods across multiple control scenarios.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-23T13:51:42Z"}
{"aid":"http://arxiv.org/abs/2504.16737v1","title":"Scaling limints for supercritical nearly unstable Hawkes processes with\n  hheavy tail","summary":"In this paper, we establish the asymptotic behavior of {\\it supercritical}\nnearly unstable Hawkes processes with a power law kernel. We find that, the\nHawkes process in our context admits a similar equation to that in\n\\cite{MR3563196} for {\\it subcritical} case. In particular, the rescaled Hawkes\nprocess $(Z^n_{nt}/n^{2\\alpha})_{t\\in[0,1]}$ converges in law to a kind of\nintegrated fractional Cox Ingersoll Ross process with different coefficients\nfrom that in \\cite{MR3563196}, as $n$ tends to infinity.","main_category":"math.PR","categories":"math.PR","published":"2025-04-23T14:08:53Z"}
{"aid":"http://arxiv.org/abs/2504.16745v1","title":"Frequency-Compensated Network for Daily Arctic Sea Ice Concentration\n  Prediction","summary":"Accurately forecasting sea ice concentration (SIC) in the Arctic is critical\nto global ecosystem health and navigation safety. However, current methods\nstill is confronted with two challenges: 1) these methods rarely explore the\nlong-term feature dependencies in the frequency domain. 2) they can hardly\npreserve the high-frequency details, and the changes in the marginal area of\nthe sea ice cannot be accurately captured. To this end, we present a\nFrequency-Compensated Network (FCNet) for Arctic SIC prediction on a daily\nbasis. In particular, we design a dual-branch network, including branches for\nfrequency feature extraction and convolutional feature extraction. For\nfrequency feature extraction, we design an adaptive frequency filter block,\nwhich integrates trainable layers with Fourier-based filters. By adding\nfrequency features, the FCNet can achieve refined prediction of edges and\ndetails. For convolutional feature extraction, we propose a high-frequency\nenhancement block to separate high and low-frequency information. Moreover,\nhigh-frequency features are enhanced via channel-wise attention, and temporal\nattention unit is employed for low-frequency feature extraction to capture\nlong-range sea ice changes. Extensive experiments are conducted on a\nsatellite-derived daily SIC dataset, and the results verify the effectiveness\nof the proposed FCNet. Our codes and data will be made public available at:\nhttps://github.com/oucailab/FCNet .","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-23T14:15:48Z"}
{"aid":"http://arxiv.org/abs/2504.16793v1","title":"A self-avoiding curve associated with sums of digits","summary":"For each $n\\in N ^{\\ast }$, we write $s_{n}=\\left( 1,\\ldots ,1,0\\right) $\nwith $n$ times $1$. For each $a \\in N$, we consider the binary representation\n$\\left( a_{i}\\right) _{i\\in -N }$ of $a$ with $a_{i}=0$ for nearly each $i$; we\ndenote by $\\alpha _{n}(a)$ the number of integers $i$ such that $\\left( a_{i},\n\\ldots ,a_{i+n} \\right) =s_{n}$. We consider the curve $C_{n}=\\left(\nS_{n,k}\\right) _{k\\in N ^{\\ast }}$ which consists of consecutive segments of\nlength $1$ such that, for each $k$, $S_{n,k+1}$ is obtained from $S_{n,k}$ by\nturning right if $k+\\alpha _{n}(k)-\\alpha _{n}(k-1)$ is even and left\notherwise. $C_{1}$ is self-avoiding since it is the curve associated to the\nalternating folding sequence. In [1], M. Mend\\`es France and J. Shallit\nconjectured that the curves $C_{n}$ for $n\\geq 2$ are also self-avoiding. In\nthe present paper, we show that this property is true for $n=2$. We also prove\nthat $C_{2}$ has some properties similar to those which were shown in [2], [3]\nand [4] for folding curves.","main_category":"math.CO","categories":"math.CO","published":"2025-04-23T15:13:11Z"}
{"aid":"http://arxiv.org/abs/2504.16818v1","title":"Rediscussion of eclipsing binaries. Paper XXIV. The delta Scuti pulsator\n  V596 Pup (formerly known as VV Pyx)","summary":"V596 Pup is a detached eclipsing binary containing two A1 V stars in a 4.596\nd period orbit with a small eccentricity and apsidal motion, previously\ndesignated as VV Pyxidis. We use new light curves from the Transiting Exoplanet\nSurvey Satellite (TESS) and published radial velocities to determine the\nphysical properties of the component stars. We find masses of 2.098 +/- 0.021\nMsun and 2.091 +/- 0.018 Msun, and radii of 2.179 +/- 0.008 Rsun and 2.139 +/-\n0.007 Rsun. The measured distance to the system is affected by the light from a\nnearby companion star; we obtain 178.4 +/- 2.5 pc. The properties of the system\nare best matched by theoretical predictions for a subsolar metallicity of Z =\n0.010 and an age of 570 Myr. We measure seven significant pulsation frequencies\nfrom the light curve, six of which are consistent with delta Scuti pulsations\nand one of which is likely of slowly-pulsating B-star type.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-23T15:37:29Z"}
{"aid":"http://arxiv.org/abs/2504.16824v1","title":"Nurturing Language Proficiency in Spanish.speaking children Through\n  digital competence","summary":"This article explores into the intricate design and meticulous construction\nof a digital platform aimed at revolutionizing early-age English education,\nparticularly for Spanish-speaking children. The focus of this work used an\ninnovative methodologies, vibrant and engaging visuals, and a comprehensive\napproach to phonics. The principles of usability, accessibility, and\nuser-centered design are intricately woven into every facet of the platform's\narchitecture.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-23T15:41:12Z"}
{"aid":"http://arxiv.org/abs/2504.16826v1","title":"Modeling a Non-Singular Universe with Late-Time Acceleration through a\n  Novel Inhomogeneous Barotropic Equation of State","summary":"In this study, we investigated the effects of incorporating barotropic fluids\non cosmological solutions within the general relativity (GR) framework. We\nproposed a modified version of the barotropic fluid with the EoS, $p=\\zeta _0\n\\rho +\\zeta _1 \\rho \\left(t-t_0\\right){}^{-2 n}$, where $\\zeta_0$, $\\zeta_1$,\n$t_0$ and $n$ are some constants. Our goal is to explore if this type of EoS\nmight help explain the universe's development, concentrating on the scenario\nwhere the universe bounces instead of singularities. Interestingly the generic\nsolutions derived from our model are sufficiently adaptable to illustrate the\nbounce scenario, cosmic inflation and late-time dark-energy behaviour. The\nparameters $\\zeta_0$, $\\zeta_1$, $t_0$, and $n$ define the universe's phase in\nthis non-singular solution. We investigated several elements of cosmic\ndevelopment, including as the energy density, deceleration parameter, and\nenergy conditions, in order to validate our model. Stability analysis showed\nthat the perturbations approach to zero as the time evolves, indicating the\nmodel is stable under scalar perturbation. Additionally, we looked at the\nstatefinder diagnostics and Hubble flow dynamics to get more understanding of\nthe model's dark energy and inflationary behaviour, respectively. Additionally,\nwe conducted a study of the models' relevance to the observational datasets\nfrom BAO, DESI and Pantheon+SH0ES.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-23T15:43:02Z"}
{"aid":"http://arxiv.org/abs/2504.16832v1","title":"GreenMind: A Next-Generation Vietnamese Large Language Model for\n  Structured and Logical Reasoning","summary":"Chain-of-Thought (CoT) is a robust approach for tackling LLM tasks that\nrequire intermediate reasoning steps prior to generating a final answer. In\nthis paper, we present GreenMind-Medium-14B-R1, the Vietnamese reasoning model\ninspired by the finetuning strategy based on Group Relative Policy\nOptimization. We also leverage a high-quality Vietnamese synthesized reasoning\ndataset and design two reward functions to tackle the main limitations of this\ntechnique: (i) language mixing, where we explicitly detect the presence of\nbiased language characters during the process of sampling tokens, and (ii) we\nleverage Sentence Transformer-based models to ensure that the generated\nreasoning content maintains factual correctness and does not distort the final\noutput. Experimental results on the Vietnamese dataset from the VLSP 2023\nChallenge demonstrate that our model outperforms prior works and enhances\nlinguistic consistency in its responses. Furthermore, we extend our evaluation\nto SeaExam-a multilingual multiple-choice dataset, showing the effectiveness of\nour reasoning method compared to few-shot prompting techniques.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-23T15:48:55Z"}
{"aid":"http://arxiv.org/abs/2504.16842v1","title":"Bertrand Menu Competition","summary":"We study a variation of the price competition model a la Bertrand, in which\nfirms must offer menus of contracts that obey monotonicity constraints, e.g.,\nwages that rise with worker productivity to comport with equal pay legislation.\nWhile such constraints limit firms' ability to undercut their competitors, we\nshow that Bertrand's classic result still holds: competition drives firm\nprofits to zero and leads to efficient allocations without rationing. Our\nfindings suggest that Bertrand's logic extends to a broader variety of markets,\nincluding labor and product markets that are subject to real-world constraints\non pricing across workers and products.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-23T16:06:09Z"}
{"aid":"http://arxiv.org/abs/2504.16843v1","title":"Physically Consistent Humanoid Loco-Manipulation using Latent Diffusion\n  Models","summary":"This paper uses the capabilities of latent diffusion models (LDMs) to\ngenerate realistic RGB human-object interaction scenes to guide humanoid\nloco-manipulation planning. To do so, we extract from the generated images both\nthe contact locations and robot configurations that are then used inside a\nwhole-body trajectory optimization (TO) formulation to generate physically\nconsistent trajectories for humanoids. We validate our full pipeline in\nsimulation for different long-horizon loco-manipulation scenarios and perform\nan extensive analysis of the proposed contact and robot configuration\nextraction pipeline. Our results show that using the information extracted from\nLDMs, we can generate physically consistent trajectories that require\nlong-horizon reasoning.","main_category":"cs.RO","categories":"cs.RO,cs.GR","published":"2025-04-23T16:07:02Z"}
{"aid":"http://arxiv.org/abs/2504.16855v1","title":"Monte Carlo Planning with Large Language Model for Text-Based Game\n  Agents","summary":"Text-based games provide valuable environments for language-based autonomous\nagents. However, planning-then-learning paradigms, such as those combining\nMonte Carlo Tree Search (MCTS) and reinforcement learning (RL), are notably\ntime-consuming due to extensive iterations. Additionally, these algorithms\nperform uncertainty-driven exploration but lack language understanding and\nreasoning abilities. In this paper, we introduce the Monte Carlo planning with\nDynamic Memory-guided Large language model (MC-DML) algorithm. MC-DML leverages\nthe language understanding and reasoning capabilities of Large Language Models\n(LLMs) alongside the exploratory advantages of tree search algorithms.\nSpecifically, we enhance LLMs with in-trial and cross-trial memory mechanisms,\nenabling them to learn from past experiences and dynamically adjust action\nevaluations during planning. We conduct experiments on a series of text-based\ngames from the Jericho benchmark. Our results demonstrate that the MC-DML\nalgorithm significantly enhances performance across various games at the\ninitial planning phase, outperforming strong contemporary methods that require\nmultiple iterations. This demonstrates the effectiveness of our algorithm,\npaving the way for more efficient language-grounded planning in complex\nenvironments.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-23T16:23:15Z"}
{"aid":"http://arxiv.org/abs/2504.16869v1","title":"Geometry of Cells Sensible to Curvature and Their Receptive Profiles","summary":"We propose a model of the functional architecture of curvature sensible cells\nin the visual cortex that associates curvature with scale. The feature space of\norientation and position is naturally enhanced via its oriented prolongation,\nyielding a 4-dimensional manifold endowed with a canonical Engel structure.\nThis structure encodes position, orientation, signed curvature, and scale. We\nassociate an open submanifold of the prolongation with the quasi-regular\nrepresentation of the similitude group SIM (2), and find left-invariant\ngenerators for the Engel structure. Finally, we use the generators of the Engel\nstructure to characterize curvature-sensitive receptive profiles .","main_category":"q-bio.NC","categories":"q-bio.NC,math.DG","published":"2025-04-23T16:44:25Z"}
{"aid":"http://arxiv.org/abs/2504.16901v1","title":"Characterizing fragments of collection principle in set theory with\n  model theoretic properties","summary":"We prove some model theoretic equivalent forms of variants of collection\nprinciple in set theory on models of a very weak set theory.","main_category":"math.LO","categories":"math.LO","published":"2025-04-23T17:27:17Z"}
{"aid":"http://arxiv.org/abs/2504.16907v1","title":"BadVideo: Stealthy Backdoor Attack against Text-to-Video Generation","summary":"Text-to-video (T2V) generative models have rapidly advanced and found\nwidespread applications across fields like entertainment, education, and\nmarketing. However, the adversarial vulnerabilities of these models remain\nrarely explored. We observe that in T2V generation tasks, the generated videos\noften contain substantial redundant information not explicitly specified in the\ntext prompts, such as environmental elements, secondary objects, and additional\ndetails, providing opportunities for malicious attackers to embed hidden\nharmful content. Exploiting this inherent redundancy, we introduce BadVideo,\nthe first backdoor attack framework tailored for T2V generation. Our attack\nfocuses on designing target adversarial outputs through two key strategies: (1)\nSpatio-Temporal Composition, which combines different spatiotemporal features\nto encode malicious information; (2) Dynamic Element Transformation, which\nintroduces transformations in redundant elements over time to convey malicious\ninformation. Based on these strategies, the attacker's malicious target\nseamlessly integrates with the user's textual instructions, providing high\nstealthiness. Moreover, by exploiting the temporal dimension of videos, our\nattack successfully evades traditional content moderation systems that\nprimarily analyze spatial information within individual frames. Extensive\nexperiments demonstrate that BadVideo achieves high attack success rates while\npreserving original semantics and maintaining excellent performance on clean\ninputs. Overall, our work reveals the adversarial vulnerability of T2V models,\ncalling attention to potential risks and misuse. Our project page is at\nhttps://wrt2000.github.io/BadVideo2025/.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-23T17:34:48Z"}
{"aid":"http://arxiv.org/abs/2504.17234v1","title":"Scene Perceived Image Perceptual Score (SPIPS): combining global and\n  local perception for image quality assessment","summary":"The rapid advancement of artificial intelligence and widespread use of\nsmartphones have resulted in an exponential growth of image data, both real\n(camera-captured) and virtual (AI-generated). This surge underscores the\ncritical need for robust image quality assessment (IQA) methods that accurately\nreflect human visual perception. Traditional IQA techniques primarily rely on\nspatial features - such as signal-to-noise ratio, local structural distortions,\nand texture inconsistencies - to identify artifacts. While effective for\nunprocessed or conventionally altered images, these methods fall short in the\ncontext of modern image post-processing powered by deep neural networks (DNNs).\nThe rise of DNN-based models for image generation, enhancement, and restoration\nhas significantly improved visual quality, yet made accurate assessment\nincreasingly complex. To address this, we propose a novel IQA approach that\nbridges the gap between deep learning methods and human perception. Our model\ndisentangles deep features into high-level semantic information and low-level\nperceptual details, treating each stream separately. These features are then\ncombined with conventional IQA metrics to provide a more comprehensive\nevaluation framework. This hybrid design enables the model to assess both\nglobal context and intricate image details, better reflecting the human visual\nprocess, which first interprets overall structure before attending to\nfine-grained elements. The final stage employs a multilayer perceptron (MLP) to\nmap the integrated features into a concise quality score. Experimental results\ndemonstrate that our method achieves improved consistency with human perceptual\njudgments compared to existing IQA models.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T04:06:07Z"}
{"aid":"http://arxiv.org/abs/2504.17295v1","title":"AI-Enhanced Business Process Automation: A Case Study in the Insurance\n  Domain Using Object-Centric Process Mining","summary":"Recent advancements in Artificial Intelligence (AI), particularly Large\nLanguage Models (LLMs), have enhanced organizations' ability to reengineer\nbusiness processes by automating knowledge-intensive tasks. This automation\ndrives digital transformation, often through gradual transitions that improve\nprocess efficiency and effectiveness. To fully assess the impact of such\nautomation, a data-driven analysis approach is needed - one that examines how\ntraditional and AI-enhanced process variants coexist during this transition.\nObject-Centric Process Mining (OCPM) has emerged as a valuable method that\nenables such analysis, yet real-world case studies are still needed to\ndemonstrate its applicability. This paper presents a case study from the\ninsurance sector, where an LLM was deployed in production to automate the\nidentification of claim parts, a task previously performed manually and\nidentified as a bottleneck for scalability. To evaluate this transformation, we\napply OCPM to assess the impact of AI-driven automation on process scalability.\nOur findings indicate that while LLMs significantly enhance operational\ncapacity, they also introduce new process dynamics that require further\nrefinement. This study also demonstrates the practical application of OCPM in a\nreal-world setting, highlighting its advantages and limitations.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-24T06:43:29Z"}
{"aid":"http://arxiv.org/abs/2504.17304v1","title":"You Are What You Bought: Generating Customer Personas for E-commerce\n  Applications","summary":"In e-commerce, user representations are essential for various applications.\nExisting methods often use deep learning techniques to convert customer\nbehaviors into implicit embeddings. However, these embeddings are difficult to\nunderstand and integrate with external knowledge, limiting the effectiveness of\napplications such as customer segmentation, search navigation, and product\nrecommendations. To address this, our paper introduces the concept of the\ncustomer persona. Condensed from a customer's numerous purchasing histories, a\ncustomer persona provides a multi-faceted and human-readable characterization\nof specific purchase behaviors and preferences, such as Busy Parents or Bargain\nHunters.\n  This work then focuses on representing each customer by multiple personas\nfrom a predefined set, achieving readable and informative explicit user\nrepresentations. To this end, we propose an effective and efficient solution\nGPLR. To ensure effectiveness, GPLR leverages pre-trained LLMs to infer\npersonas for customers. To reduce overhead, GPLR applies LLM-based labeling to\nonly a fraction of users and utilizes a random walk technique to predict\npersonas for the remaining customers. We further propose RevAff, which provides\nan absolute error $\\epsilon$ guarantee while improving the time complexity of\nthe exact solution by a factor of at least\n$O(\\frac{\\epsilon\\cdot|E|N}{|E|+N\\log N})$, where $N$ represents the number of\ncustomers and products, and $E$ represents the interactions between them. We\nevaluate the performance of our persona-based representation in terms of\naccuracy and robustness for recommendation and customer segmentation tasks\nusing three real-world e-commerce datasets. Most notably, we find that\nintegrating customer persona representations improves the state-of-the-art\ngraph convolution-based recommendation model by up to 12% in terms of NDCG@K\nand F1-Score@K.","main_category":"cs.IR","categories":"cs.IR,cs.AI","published":"2025-04-24T06:59:16Z"}
{"aid":"http://arxiv.org/abs/2504.17321v1","title":"Dargana: fine-tuning EarthPT for dynamic tree canopy mapping from space","summary":"We present Dargana, a fine-tuned variant of the EarthPT time-series\nfoundation model that achieves specialisation using <3% of its pre-training\ndata volume and 5% of its pre-training compute. Dargana is fine-tuned to\ngenerate regularly updated classification of tree canopy cover at 10m\nresolution, distinguishing conifer and broadleaved tree types. Using Cornwall,\nUK, as a test case, the model achieves a pixel-level ROC-AUC of 0.98 and a\nPR-AUC of 0.83 on unseen satellite imagery. Dargana can identify fine\nstructures like hedgerows and coppice below the training sample limit, and can\ntrack temporal changes to canopy cover such as new woodland establishment. Our\nresults demonstrate how pre-trained Large Observation Models like EarthPT can\nbe specialised for granular, dynamic land cover monitoring from space,\nproviding a valuable, scalable tool for natural capital management and\nconservation.","main_category":"physics.geo-ph","categories":"physics.geo-ph,cs.LG","published":"2025-04-24T07:23:27Z"}
{"aid":"http://arxiv.org/abs/2504.17329v1","title":"On Runge-Kutta methods of order 10","summary":"A family of explicit 15-stage Runge-Kutta methods of order 10 is derived.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-24T07:45:51Z"}
{"aid":"http://arxiv.org/abs/2504.17330v1","title":"Exploring the giant monopole resonance in superheavy nuclei: A\n  theoretical perspective","summary":"Within the relativistic mean field framework, in an extended Thomas-Fermi\napproximation, we calculate the binding energy and charge distribution radius\nfor the latest superheavy nuclei, synthesised in various laboratories, with\natomic numbers $Z = 110-118$. The binding energy and radii are compared with\nthe results obtained from relativistic Hartree calculations along with the\nexperimental data, wherever available, to check the reliability of the methods.\nThe calculations are extended to estimate the giant monopole resonances to\nunderstand the collective vibration of the nucleons for such superheavy nuclei.\nThe giant monopole resonances obtained from scaling calculations are compared\nwith the constraint computations. Furthermore, the results are compared with\nother known methods, such as the relativistic Random Phase Approximation (RPA)\nand time-dependent mean field calculations, along with some known lighter\nnuclei, specifically Zr isotopes (N = 42-86) and O isotopes (N = 10-36).\nFinally, the nuclear compressibility of the superheavy nuclei is predicted from\nthe energy obtained in the breathing mode.","main_category":"nucl-th","categories":"nucl-th,nucl-ex","published":"2025-04-24T07:46:47Z"}
{"aid":"http://arxiv.org/abs/2504.17342v1","title":"Fr√©chet Distance in Unweighted Planar Graphs","summary":"The Fr\\'echet distance is a distance measure between trajectories in the\nplane or walks in a graph G. Given constant-time shortest path queries in a\ngraph G, the Discrete Fr\\'echet distance $F_G(P, Q)$ between two walks P and Q\ncan be computed in $O(|P| \\cdot |Q|)$ time using a dynamic program. Driemel,\nvan der Hoog, and Rotenberg [SoCG'22] show that for weighted planar graphs this\napproach is likely tight, as there can be no strongly subquadratic algorithm to\ncompute a $1.01$-approximation of $F_G(P, Q)$ unless the Orthogonal Vector\nHypothesis (OVH) fails.\n  Such quadratic-time conditional lower bounds are common to many Fr\\'echet\ndistance variants. However, they can be circumvented by assuming that the input\ncomes from some well-behaved class: There exist\n$(1+\\varepsilon)$-approximations, both in weighted graphs and in Rd, that take\nnear-linear time for $c$-packed or $\\kappa$-straight walks in the graph. In Rd,\nthere also exists a near-linear time algorithm to compute the Fr\\'echet\ndistance whenever all input edges are long compared to the distance.\n  We consider computing the Fr\\'echet distance in unweighted planar graphs. We\nshow that there exist no 1.25-approximations of the discrete Fr\\'echet distance\nbetween two disjoint simple paths in an unweighted planar graph in strongly\nsubquadratic time, unless OVH fails. This improves the previous lower bound,\nboth in terms of generality and approximation factor. We subsequently show that\nadding graph structure circumvents this lower bound: If the graph is a regular\ntiling with unit-weighted edges, then there exists an $\\tilde{O}( (|P| +\n|Q|)^{1.5})$-time algorithm to compute $D_F(P, Q)$. Our result has natural\nimplications in the plane, as it allows us to define a new class of\nwell-behaved curves that facilitate $(1+\\varepsilon)$-approximations of their\ndiscrete Fr\\'echet distance in subquadratic time.","main_category":"cs.CG","categories":"cs.CG","published":"2025-04-24T07:59:39Z"}
{"aid":"http://arxiv.org/abs/2504.17347v1","title":"Analysis and Mitigation of Data injection Attacks against Data-Driven\n  Control","summary":"This paper investigates the impact of false data injection attacks on\ndata-driven control systems. Specifically, we consider an adversary injecting\nfalse data into the sensor channels during the learning phase. When the\noperator seeks to learn a stable state-feedback controller, we propose an\nattack strategy capable of misleading the operator into learning an unstable\nfeedback gain. We also investigate the effects of constant-bias injection\nattacks on data-driven linear quadratic regulation (LQR). Finally, we explore\npotential mitigation strategies and support our findings with numerical\nexamples.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-24T08:08:51Z"}
{"aid":"http://arxiv.org/abs/2504.17356v1","title":"Comprehend, Divide, and Conquer: Feature Subspace Exploration via\n  Multi-Agent Hierarchical Reinforcement Learning","summary":"Feature selection aims to preprocess the target dataset, find an optimal and\nmost streamlined feature subset, and enhance the downstream machine learning\ntask. Among filter, wrapper, and embedded-based approaches, the reinforcement\nlearning (RL)-based subspace exploration strategy provides a novel objective\noptimization-directed perspective and promising performance. Nevertheless, even\nwith improved performance, current reinforcement learning approaches face\nchallenges similar to conventional methods when dealing with complex datasets.\nThese challenges stem from the inefficient paradigm of using one agent per\nfeature and the inherent complexities present in the datasets. This observation\nmotivates us to investigate and address the above issue and propose a novel\napproach, namely HRLFS. Our methodology initially employs a Large Language\nModel (LLM)-based hybrid state extractor to capture each feature's mathematical\nand semantic characteristics. Based on this information, features are\nclustered, facilitating the construction of hierarchical agents for each\ncluster and sub-cluster. Extensive experiments demonstrate the efficiency,\nscalability, and robustness of our approach. Compared to contemporary or the\none-feature-one-agent RL-based approaches, HRLFS improves the downstream ML\nperformance with iterative feature subspace exploration while accelerating\ntotal run time by reducing the number of agents involved.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-24T08:16:36Z"}
{"aid":"http://arxiv.org/abs/2504.17357v1","title":"Observation of the Einstein-de Haas Effect in a Bose-Einstein condensate","summary":"The Einstein-de Haas effect is a phenomenon in which angular momentum is\ntransferred from microscopic spins to mechanical rotation of a rigid body.\nHere, we report the first observation of the Einstein-de Haas effect in a\nspinor-dipolar Bose-Einstein condensate where quantized vortices emerge in\ndepolarized spinor components through coherent angular-momentum transfer from\nmicroscopic atomic spins to macroscopic quantized circulation. Experimental\nresults clearly show that the spherical symmetry of the condensate is\ndynamically broken into the axisymmetry by an intrinsic magnetic dipole-dipole\ninteraction.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas","published":"2025-04-24T08:16:43Z"}
{"aid":"http://arxiv.org/abs/2504.17359v1","title":"Light-driven lattice metastability for enhanced superconductivity in\n  FeSe/SrTiO3","summary":"Driven quantum materials with on demand properties controlled by external\nstimuli are critical for emergent quantum technology. In optically tunable\nsuperconducting heterostructures, the lattice responses at the buried interface\nmay hold the key to the light susceptibility but is very challenging to detect.\nIn this work, a nondestructive synchrotron-based X-ray scattering\nphase-retrieval technique is implemented in monolayer-FeSe/SrTiO3\nheterostructures to capture the three-dimensional interfacial atomic\ndisplacements in-situ as the interface superconductivity is actively\nmanipulated by light. It is found that the interlayer sliding between FeSe and\nSrTiO3 can drastically alter how the lattice responds to the light. In domains\nwith selected stacking configurations, the interface transforms the very weak\nphotoexcitation in SrTiO3 into significant Fe-atom displacements in FeSe and\ngenerate metastable interfacial structures that can lead to a persistent\nsuperconductivity enhancement. These findings demonstrate an effective strategy\nfor achieving greatly amplified light-lattice coupling for efficient quantum\nphase manipulations at designed interfaces.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-24T08:17:45Z"}
{"aid":"http://arxiv.org/abs/2504.17366v1","title":"LiveLongBench: Tackling Long-Context Understanding for Spoken Texts from\n  Live Streams","summary":"Long-context understanding poses significant challenges in natural language\nprocessing, particularly for real-world dialogues characterized by speech-based\nelements, high redundancy, and uneven information density. Although large\nlanguage models (LLMs) achieve impressive results on existing benchmarks, these\ndatasets fail to reflect the complexities of such texts, limiting their\napplicability to practical scenarios. To bridge this gap, we construct the\nfirst spoken long-text dataset, derived from live streams, designed to reflect\nthe redundancy-rich and conversational nature of real-world scenarios. We\nconstruct tasks in three categories: retrieval-dependent, reasoning-dependent,\nand hybrid. We then evaluate both popular LLMs and specialized methods to\nassess their ability to understand long-contexts in these tasks. Our results\nshow that current methods exhibit strong task-specific preferences and perform\npoorly on highly redundant inputs, with no single method consistently\noutperforming others. We propose a new baseline that better handles redundancy\nin spoken text and achieves strong performance across tasks. Our findings\nhighlight key limitations of current methods and suggest future directions for\nimproving long-context understanding. Finally, our benchmark fills a gap in\nevaluating long-context spoken language understanding and provides a practical\nfoundation for developing real-world e-commerce systems. The code and benchmark\nare available at https://github.com/Yarayx/livelongbench.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-24T08:27:48Z"}
{"aid":"http://arxiv.org/abs/2504.17373v1","title":"The lepton-number-violating pion decay and the type-I seesaw mechanism\n  in chiral perturbation theory","summary":"We investigate the process of lepton-number-violating pion decay, which\ndominates the nuclear neutrinoless double beta decay induced by the short-range\noperator, within the type-\\uppercase\\expandafter{\\romannumeral1} seesaw\nmechanism. The type-\\uppercase\\expandafter{\\romannumeral1} seesaw mechanism\ngives rise to the Dirac and Majorana mass terms of neutrinos by introducing the\ngauge-singlet right-handed neutrinos, which are usually called sterile\nneutrinos. Using chiral perturbation theory, the transition amplitudes in the\ncase of the light and heavy sterile neutrinos are calculated up to\n$\\mathcal{O}(Q^2/\\Lambda^2_\\chi)$ respectively, where $Q$ is the typical\nlow-energy scale in this process and $\\Lambda_\\chi$ the chiral symmetry\nbreaking scale. We then adopt a naive interpolation formula of mass dependence\nto obtain the amplitude in the full mass range and briefly discuss its\nvalidity.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-24T08:47:31Z"}
{"aid":"http://arxiv.org/abs/2504.17396v1","title":"Periodic homogenization and harmonic measures","summary":"Since the seminal work of Kenig and Pipher, the Dahlberg-Kenig-Pipher (DKP)\ncondition on oscillations of the coefficient matrix became a standard threshold\nin the study of absolute continuity of the harmonic measure with respect to the\nHausdorff measure on the boundary. It has been proved sufficient for absolute\ncontinuity in the domains with increasingly complex geometry, and known\ncounterexamples show that in a certain sense it is necessary as well. In the\npresent note, we introduce into the subject ideas from homogenization theory to\nexhibit a new class of operators for which the elliptic measure is\nwell-behaved, featuring the coefficients violating the DKP condition, and on\nthe contrary, oscillating so quickly, that the homogenization takes place.","main_category":"math.AP","categories":"math.AP","published":"2025-04-24T09:35:14Z"}
{"aid":"http://arxiv.org/abs/2504.17399v1","title":"S2S-Net: Addressing the Domain Gap of Heterogeneous Sensor Systems in\n  LiDAR-Based Collective Perception","summary":"Collective Perception (CP) has emerged as a promising approach to overcome\nthe limitations of individual perception in the context of autonomous driving.\nVarious approaches have been proposed to realize collective perception;\nhowever, the Sensor2Sensor domain gap that arises from the utilization of\ndifferent sensor systems in Connected and Automated Vehicles (CAVs) remains\nmostly unaddressed. This is primarily due to the paucity of datasets containing\nheterogeneous sensor setups among the CAVs. The recently released SCOPE\ndatasets address this issue by providing data from three different LiDAR\nsensors for each CAV. This study is the first to tackle the Sensor2Sensor\ndomain gap in vehicle to vehicle (V2V) collective perception. First, we present\nour sensor-domain robust architecture S2S-Net. Then an in-depth analysis of the\nSensor2Sensor domain adaptation capabilities of S2S-Net on the SCOPE dataset is\nconducted. S2S-Net demonstrates the capability to maintain very high\nperformance in unseen sensor domains and achieved state-of-the-art results on\nthe SCOPE dataset.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-24T09:38:59Z"}
{"aid":"http://arxiv.org/abs/2504.17424v1","title":"Object Pose Estimation by Camera Arm Control Based on the Next Viewpoint\n  Estimation","summary":"We have developed a new method to estimate a Next Viewpoint (NV) which is\neffective for pose estimation of simple-shaped products for product display\nrobots in retail stores. Pose estimation methods using Neural Networks (NN)\nbased on an RGBD camera are highly accurate, but their accuracy significantly\ndecreases when the camera acquires few texture and shape features at a current\nview point. However, it is difficult for previous mathematical model-based\nmethods to estimate effective NV which is because the simple shaped objects\nhave few shape features. Therefore, we focus on the relationship between the\npose estimation and NV estimation. When the pose estimation is more accurate,\nthe NV estimation is more accurate. Therefore, we develop a new pose estimation\nNN that estimates NV simultaneously. Experimental results showed that our NV\nestimation realized a pose estimation success rate 77.3\\%, which was 7.4pt\nhigher than the mathematical model-based NV calculation did. Moreover, we\nverified that the robot using our method displayed 84.2\\% of products.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-24T10:26:14Z"}
{"aid":"http://arxiv.org/abs/2504.17501v1","title":"Surface morphology and thickness variation estimation of zeolites via\n  electron ptychography","summary":"Zeolites, as representative porous materials, possess intricate\nthree-dimensional frameworks that endow them with high surface areas and\nremarkable catalytic properties. There are a few factors that give a huge\ninfluence on the catalytic properties, including the size and connectivity of\nthese three-dimensional channels and atomic level defects. In additional to\nthat, the surface morphology and thickness variation of zeolites particles are\nessential to their catalytic performances as well. However, it is a significant\nchallenge to characterize these macroscopic properties of zeolites using\nconventional techniques due to their sensitivity to electron beams. In this\nstudy, we introduce surface-adaptive electron ptychography, an advanced\napproach based on multi-slice electron ptychography, which enables\nhigh-precision reconstruction of both local atomic configurations and global\nstructural features in zeolite nanoparticles. By adaptively optimizing probe\ndefocus and slice thickness during the reconstruction process, SAEP\nsuccessfully resolves surface morphology, thickness variations and atomic\nstructure simultaneously. This integrated framework facilitates a direct and\nintuitive correlation between zeolite channel structures and particle\nthickness. Our findings open new pathways for large-scale, comprehensive\nstructure property analysis of beam-sensitive porous materials, deepening the\nunderstanding of their catalytic behavior.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-24T12:42:55Z"}
{"aid":"http://arxiv.org/abs/2504.17514v1","title":"Secure Network Function Computation for Linear Functions, Part II:\n  Target-Function Security","summary":"In this Part II of a two-part paper, we put forward secure network function\ncomputation, where in a directed acyclic network, a sink node is required to\ncompute a target function of which the inputs are generated as source messages\nat multiple source nodes, while a wiretapper, who can access any one but not\nmore than one wiretap set in a given collection of wiretap sets, is not allowed\nto obtain any information about a security function of the source messages. In\nPart I of the two-part paper, we have investigated securely computing linear\nfunctions with the wiretapper who can eavesdrop any edge subset up to a certain\nsize r, referred to as the security level, where the security function is the\nidentity function. The notion of this security is called source security. In\nthe current paper, we consider another interesting model which is the same as\nthe above one except that the security function is identical to the target\nfunction, i.e., we need to protect the information on the target function from\nbeing leaked to the wiretapper. The notion of this security is called\ntarget-function security. We first prove a non-trivial upper bound on the\nsecure computing capacity, which is applicable to arbitrary network topologies\nand arbitrary security levels. In particular, when the security level r is\nequal to 0, the upper bound reduces to the computing capacity without security\nconsideration. Further, from an algebraic point of view, we prove two\nequivalent conditions for target-function security and source security for the\nexistence of the corresponding linear function-computing secure network codes.\nWith them, for any linear function over a given finite field, we develop a code\nconstruction of linear secure network codes for target-function security and\nthus obtain a lower bound on the secure computing capacity; and also generalize\nthe code construction developed in Part I for source security.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-24T12:57:20Z"}
{"aid":"http://arxiv.org/abs/2504.17550v1","title":"HalluLens: LLM Hallucination Benchmark","summary":"Large language models (LLMs) often generate responses that deviate from user\ninput or training data, a phenomenon known as \"hallucination.\" These\nhallucinations undermine user trust and hinder the adoption of generative AI\nsystems. Addressing hallucinations is essential for the advancement of LLMs.\nThis paper introduces a comprehensive hallucination benchmark, incorporating\nboth new extrinsic and existing intrinsic evaluation tasks, built upon clear\ntaxonomy of hallucination. A major challenge in benchmarking hallucinations is\nthe lack of a unified framework due to inconsistent definitions and\ncategorizations. We disentangle LLM hallucination from \"factuality,\" proposing\na clear taxonomy that distinguishes between extrinsic and intrinsic\nhallucinations, to promote consistency and facilitate research. Extrinsic\nhallucinations, where the generated content is not consistent with the training\ndata, are increasingly important as LLMs evolve. Our benchmark includes dynamic\ntest set generation to mitigate data leakage and ensure robustness against such\nleakage. We also analyze existing benchmarks, highlighting their limitations\nand saturation. The work aims to: (1) establish a clear taxonomy of\nhallucinations, (2) introduce new extrinsic hallucination tasks, with data that\ncan be dynamically regenerated to prevent saturation by leakage, (3) provide a\ncomprehensive analysis of existing benchmarks, distinguishing them from\nfactuality evaluations.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-24T13:40:27Z"}
{"aid":"http://arxiv.org/abs/2504.17558v1","title":"Quasi-particle residue and charge of the one-dimensional Fermi polaron","summary":"We consider a mobile impurity coupled to an ideal Fermi gas in one spatial\ndimension through an attractive contact interaction. We calculate the\nquasi-particle residue $Z$ exactly, based on Bethe Ansatz and diagrammatic\nMonte Carlo methods, and with varational Ansatz up to one particle-hole\nexcitation of the Fermi sea. We find that the exact quasi-particle residue\nvanishes in the thermodynamic limit as a power law in the number of particles,\nconsistent with the Luttinger-liquid paradigm and the breakdown of Fermi-liquid\ntheory. The variational Ansatz, however, predicts a finite value of $Z$, even\nin the thermodynamic limit. We also study how the presence of the impurity\naffects the density of the spin-up sea by calculating the pair correlation\nfunction. Subtracting the homogeneous background and integrating over all\ndistances gives the charge $Q$. This charge turns out to grow continuously from\n0 at zero coupling to 1 in the strong-coupling limit. The varational Ansatz\npredicts $Q=0$ at all couplings. So, although the variational Ansatz has been\nshown to be remarkably accurate for the energy and the effective mass, it fails\neven qualitatively when predicting $Z$ and the pair correlation function in the\nthermodynamic limit.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,cond-mat.str-el,cond-mat.supr-con","published":"2025-04-24T13:50:46Z"}
{"aid":"http://arxiv.org/abs/2504.17575v1","title":"A Multi-Agent, Laxity-Based Aggregation Strategy for Cost-Effective\n  Electric Vehicle Charging and Local Transformer Overload Prevention","summary":"The rapid electrification of transportation, driven by stringent\ndecarbonization targets and supportive policies, poses significant challenges\nfor distribution system operators (DSOs). When numerous electric vehicles (EVs)\ncharge concurrently, local transformers risk overloading - a problem that\ncurrent tariff-based strategies do not adequately address. This paper\nintroduces an aggregator-based coordination mechanism that shifts EV charging\nfrom congested to underutilized periods using a rule-based scheduling\nalgorithm. Unlike conventional methods that depend on complex real-time pricing\nsignals or optimization-heavy solutions, the aggregator approach uses a simple\nyet effective \"laxity\" measure to prioritize charging flexibility. To assess\ntechnical and economic viability, a multi-agent simulation was developed to\nreplicate residential user behavior and DSO constraints under the use of a 400\nkVA low-voltage transformer. The results indicate that overloads are completely\neliminated with minimal inconvenience to users, whose increased charging costs\nare offset by the aggregator at an annual total of under DKK 6000 -\nsignificantly lower than the cost of infrastructure reinforcement. This study\ncontributes by (i) quantifying the compensation needed to prevent large-scale\noverloads, (ii) presenting a replicable, computationally feasible, rule-based\naggregator model for DSOs, and (iii) comparing aggregator solutions to costly\ntransformer upgrades, underscoring the aggregator's role as a viable tool for\nfuture distribution systems.","main_category":"cs.MA","categories":"cs.MA","published":"2025-04-24T14:04:35Z"}
{"aid":"http://arxiv.org/abs/2504.17578v1","title":"Advancing CMA-ES with Learning-Based Cooperative Coevolution for\n  Scalable Optimization","summary":"Recent research in Cooperative Coevolution~(CC) have achieved promising\nprogress in solving large-scale global optimization problems. However, existing\nCC paradigms have a primary limitation in that they require deep expertise for\nselecting or designing effective variable decomposition strategies. Inspired by\nadvancements in Meta-Black-Box Optimization, this paper introduces LCC, a\npioneering learning-based cooperative coevolution framework that dynamically\nschedules decomposition strategies during optimization processes. The\ndecomposition strategy selector is parameterized through a neural network,\nwhich processes a meticulously crafted set of optimization status features to\ndetermine the optimal strategy for each optimization step. The network is\ntrained via the Proximal Policy Optimization method in a reinforcement learning\nmanner across a collection of representative problems, aiming to maximize the\nexpected optimization performance. Extensive experimental results demonstrate\nthat LCC not only offers certain advantages over state-of-the-art baselines in\nterms of optimization effectiveness and resource consumption, but it also\nexhibits promising transferability towards unseen problems.","main_category":"cs.LG","categories":"cs.LG,cs.NE","published":"2025-04-24T14:09:22Z"}
{"aid":"http://arxiv.org/abs/2504.17580v1","title":"Linear Test Approach to Global Controllability of Higher-Order Nonlinear\n  Dispersive Equations with Finite-Dimensional Control","summary":"We investigate a class of higher-order nonlinear dispersive equations posed\non the circle, subject to additive forcing by a finite-dimensional control. Our\nmain objective is to establish approximate controllability by using the\ncontrollability of the inviscid Burgers system, linearized around a suitably\nconstructed trajectory. In contrast to earlier approaches based on Lie\nalgebraic techniques, our method offers a more concise proof and sheds new\nlight on the structure of the control. Although the approach necessitates a\nhigher-dimensional control space, both the structure and dimension of the\ncontrol remain uniform with respect to the order of the dispersive equation and\nthe control time.","main_category":"math.AP","categories":"math.AP,math.OC","published":"2025-04-24T14:10:48Z"}
{"aid":"http://arxiv.org/abs/2504.17587v1","title":"Enhancing gravitational-wave detection: a machine learning pipeline\n  combination approach with robust uncertainty quantification","summary":"Gravitational-wave data from advanced-era interferometric detectors consists\nof background Gaussian noise, frequent transient artefacts, and rare\nastrophysical signals. Multiple search algorithms exist to detect the signals\nfrom compact binary coalescences, but their varying performance complicates\ninterpretation. We present a machine learning-driven approach that combines\nresults from individual pipelines and utilises conformal prediction to provide\nrobust, calibrated uncertainty quantification. Using simulations, we\ndemonstrate improved detection efficiency and apply our model to GWTC-3,\nenhancing confidence in multi-pipeline detections, such as the sub-threshold\nbinary neutron star candidate GW200311_103121.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE","published":"2025-04-24T14:18:09Z"}
{"aid":"http://arxiv.org/abs/2504.17613v1","title":"TarDiff: Target-Oriented Diffusion Guidance for Synthetic Electronic\n  Health Record Time Series Generation","summary":"Synthetic Electronic Health Record (EHR) time-series generation is crucial\nfor advancing clinical machine learning models, as it helps address data\nscarcity by providing more training data. However, most existing approaches\nfocus primarily on replicating statistical distributions and temporal\ndependencies of real-world data. We argue that fidelity to observed data alone\ndoes not guarantee better model performance, as common patterns may dominate,\nlimiting the representation of rare but important conditions. This highlights\nthe need for generate synthetic samples to improve performance of specific\nclinical models to fulfill their target outcomes. To address this, we propose\nTarDiff, a novel target-oriented diffusion framework that integrates\ntask-specific influence guidance into the synthetic data generation process.\nUnlike conventional approaches that mimic training data distributions, TarDiff\noptimizes synthetic samples by quantifying their expected contribution to\nimproving downstream model performance through influence functions.\nSpecifically, we measure the reduction in task-specific loss induced by\nsynthetic samples and embed this influence gradient into the reverse diffusion\nprocess, thereby steering the generation towards utility-optimized data.\nEvaluated on six publicly available EHR datasets, TarDiff achieves\nstate-of-the-art performance, outperforming existing methods by up to 20.4% in\nAUPRC and 18.4% in AUROC. Our results demonstrate that TarDiff not only\npreserves temporal fidelity but also enhances downstream model performance,\noffering a robust solution to data scarcity and class imbalance in healthcare\nanalytics.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-24T14:36:10Z"}
{"aid":"http://arxiv.org/abs/2504.17620v1","title":"Reverse energy flows: the physical mechanism underling dramatic drop of\n  loss in hollow-core fibers","summary":"Hollow-core fibers (HCFs) with claddings composed of silica glass capillaries\nhave recently attracted a great deal of attention following the demonstration\nof optical loss levels lower than those of conventional telecommunication\nfibers. It is well established already that optical losses in HCFs are highly\nsensitive to both the wavelength and the geometry of the cladding capillaries.\nThe underlying physical mechanisms behind reducing loss with the change of HCF\ndesign parameters while keeping the same fiber structure are not yet fully\nunderstood. In this work, we investigate the relationship between light\nlocalization and corresponding decrease of losses in HCFs and the distribution\nof reverse energy fluxes in air-core modes. We show here that the shape of the\ncapillaries plays a crucial role in controlling radial energy backflows that\ninfluence light confinement and the energy leakage from air-core modes of HCFs.\nThrough numerical modeling, we demonstrate that optimizing the capillary\ngeometry to tailor the distribution of reverse radial energy fluxes leads to a\nsubstantial reduction in transmission losses even in fibers with relatively\nsimple cladding structures. Consideration of the energy flows and observed\noccurrences of vortex of the Poynting vector allows us to a draw an interesting\ninterdisciplinary analogy with the hydrodynamical system with suppressed\nbackward flow - Tesla valve. We believe that combination of singular optics and\nenergy fluxes analysis provides valuable physical insight into the mechanisms\ngoverning waveguiding in HCFs offering a pathway toward novel designs with\nminimized leakage loss.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-24T14:44:23Z"}
{"aid":"http://arxiv.org/abs/2504.17630v1","title":"Geometry-induced asymmetric level coupling","summary":"Tailoring energy levels in quantum systems via Hamiltonian control parameters\nis essential for designing quantum thermodynamic devices and materials.\nHowever, conventional methods for manipulating finite-size systems, such as\ntuning external fields or system size, typically lead to uniform spectral\nshifts, limiting precise control. A recently introduced technique, called the\nsize-invariant shape transformation, overcomes this by introducing a new\ncontrol parameter that deforms the potential landscape without altering system\nsize, enabling nonuniform level scaling. This shape parameter gives rise to\nquantum shape effects in confined systems, conceptually distinct from quantum\nsize effects. We explore the limits of this phenomenon by asking: what is the\nminimal system in which such spectral behavior can emerge? We show that even a\ntwo-level system can exhibit thermodynamic consequences of quantum shape\neffects, including spontaneous transitions into lower-entropy states, a feature\nabsent in classical thermodynamics for non-interacting systems. We identify the\norigin as geometry-induced asymmetric level coupling, where the ground-state\nenergy and level spacing respond oppositely to shape changes. This extends to\nmany-level systems, where the thermally averaged level spacing and ground-state\nenergy evolve in opposite directions. We construct spontaneity maps revealing\nenergy- and entropy-driven spontaneous processes. These behaviors emerge under\nquasistatic, isothermal deformations and show how geometry alone can induce\nthermodynamic effects typically exclusive to interacting or open systems. Our\nresults offer a broadly applicable route to spectral gap control in quantum\ntechnologies.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall,cond-mat.stat-mech","published":"2025-04-24T14:58:44Z"}
{"aid":"http://arxiv.org/abs/2504.17664v1","title":"On Multivariate Financial Time Series Classification","summary":"This article investigates the use of Machine Learning and Deep Learning\nmodels in multivariate time series analysis within financial markets. It\ncompares small and big data approaches, focusing on their distinct challenges\nand the benefits of scaling. Traditional methods such as SVMs are contrasted\nwith modern architectures like ConvTimeNet. The results show the importance of\nusing and understanding Big Data in depth in the analysis and prediction of\nfinancial time series.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-24T15:33:00Z"}
{"aid":"http://arxiv.org/abs/2504.17684v1","title":"Evaluating the Vulnerability of ML-Based Ethereum Phishing Detectors to\n  Single-Feature Adversarial Perturbations","summary":"This paper explores the vulnerability of machine learning models to simple\nsingle-feature adversarial attacks in the context of Ethereum fraudulent\ntransaction detection. Through comprehensive experimentation, we investigate\nthe impact of various adversarial attack strategies on model performance\nmetrics. Our findings, highlighting how prone those techniques are to simple\nattacks, are alarming, and the inconsistency in the attacks' effect on\ndifferent algorithms promises ways for attack mitigation. We examine the\neffectiveness of different mitigation strategies, including adversarial\ntraining and enhanced feature selection, in enhancing model robustness and show\ntheir effectiveness.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-24T15:54:56Z"}
{"aid":"http://arxiv.org/abs/2504.17695v1","title":"PICO: Reconstructing 3D People In Contact with Objects","summary":"Recovering 3D Human-Object Interaction (HOI) from single color images is\nchallenging due to depth ambiguities, occlusions, and the huge variation in\nobject shape and appearance. Thus, past work requires controlled settings such\nas known object shapes and contacts, and tackles only limited object classes.\nInstead, we need methods that generalize to natural images and novel object\nclasses. We tackle this in two main ways: (1) We collect PICO-db, a new dataset\nof natural images uniquely paired with dense 3D contact on both body and object\nmeshes. To this end, we use images from the recent DAMON dataset that are\npaired with contacts, but these contacts are only annotated on a canonical 3D\nbody. In contrast, we seek contact labels on both the body and the object. To\ninfer these given an image, we retrieve an appropriate 3D object mesh from a\ndatabase by leveraging vision foundation models. Then, we project DAMON's body\ncontact patches onto the object via a novel method needing only 2 clicks per\npatch. This minimal human input establishes rich contact correspondences\nbetween bodies and objects. (2) We exploit our new dataset of contact\ncorrespondences in a novel render-and-compare fitting method, called PICO-fit,\nto recover 3D body and object meshes in interaction. PICO-fit infers contact\nfor the SMPL-X body, retrieves a likely 3D object mesh and contact from PICO-db\nfor that object, and uses the contact to iteratively fit the 3D body and object\nmeshes to image evidence via optimization. Uniquely, PICO-fit works well for\nmany object categories that no existing method can tackle. This is crucial to\nenable HOI understanding to scale in the wild. Our data and code are available\nat https://pico.is.tue.mpg.de.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T16:03:11Z"}
{"aid":"http://arxiv.org/abs/2504.17697v1","title":"'The Boring and the Tedious': Invisible Labour in India's Gig-Economy","summary":"India's gig-based food delivery platforms, such as Swiggy and Zomato, provide\ncrucial income to marginalised communities but also entrench workers in cycles\nof invisible labour. Through 14 semi-structured interviews, we analyse waiting\ntime and repetitive UI itneractions as key burdens that contribute to 'digital\ndiscomfort' for gig based food delivery agents. We find that workers employ\ncreative strategies to navigate algorithmic management, yet remain constrained\nby platform-side 'gamification' and system opacity. We propose worker-centered\nGUI automation as a potential intervention to reduce friction while preserving\nagency. In conclusion, this position paper argues for rethinking HCI approaches\nin the Global South to prioritise worker autonomy over efficiency-driven design\noptimisations.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-24T16:06:26Z"}
{"aid":"http://arxiv.org/abs/2504.17718v1","title":"Recursive feasibility for stochastic MPC and the rationale behind fixing\n  flat tires","summary":"In this paper, we address the problem of designing stochastic model\npredictive control (SMPC) schemes for linear systems affected by unbounded\ndisturbances. The contribution of the paper is rooted in a measured-state\ninitialization strategy. First, due to the nonzero probability of violating\nchance-constraints in the case of unbounded noise, we introduce\nellipsoidal-based probabilistic reachable sets and we include constraint\nrelaxations to recover recursive feasibility conditioned to the measured state.\nSecond, we prove that the solution of this novel SMPC scheme guarantees\nclosed-loop chance constraints satisfaction under minimum relaxation. Last, we\ndemonstrate that, in expectation, the need of relaxing the constraints vanishes\nover time, which leads the closed-loop trajectories steered towards the\nunconstrained LQR invariant region. This novel SMPC scheme is proven to satisfy\nthe recursive feasibility conditioned to the state realization, and its\nsuperiority with respect to open-loop initialization schemes is shown through\nnumerical examples.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-24T16:26:22Z"}
{"aid":"http://arxiv.org/abs/2504.17720v1","title":"Multilingual Performance Biases of Large Language Models in Education","summary":"Large language models (LLMs) are increasingly being adopted in educational\nsettings. These applications expand beyond English, though current LLMs remain\nprimarily English-centric. In this work, we ascertain if their use in education\nsettings in non-English languages is warranted. We evaluated the performance of\npopular LLMs on four educational tasks: identifying student misconceptions,\nproviding targeted feedback, interactive tutoring, and grading translations in\nsix languages (Hindi, Arabic, Farsi, Telugu, Ukrainian, Czech) in addition to\nEnglish. We find that the performance on these tasks somewhat corresponds to\nthe amount of language represented in training data, with lower-resource\nlanguages having poorer task performance. Although the models perform\nreasonably well in most languages, the frequent performance drop from English\nis significant. Thus, we recommend that practitioners first verify that the LLM\nworks well in the target language for their educational task before deployment.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-24T16:32:31Z"}
{"aid":"http://arxiv.org/abs/2504.17747v1","title":"Fourier Acceleration in a Linear Sigma Model with Spontaneous Symmetry\n  Breaking","summary":"Fourier acceleration is a technique used in Hybrid Monte Carlo simulations to\ndecrease the autocorrelation between subsequent field configurations in the\ngenerated ensemble. It has been shown, in the perturbative limit, to eliminate\nthe problem of critical slowing down in a $\\phi^4$ theory (arXiv:1812.05281\n[hep-lat]). As a result, there are several techniques that are being explored\nto generalize Fourier acceleration to work with non-Abelian gauge theories like\nQCD (arXiv:2112.04556 [hep-lat], arXiv:2108.05486 [hep-lat]). It is hoped that\nthese methods will prove effective at overcoming the problem of critical\nslowing down, even in the non-perturbative limit. In our work, we show that\nFourier acceleration can be applied effectively to a linear sigma model in the\nsymmetry broken phase, leading to reduced autocorrelation and faster\nthermalization. We present an algorithm for estimating the optimal Fourier\nacceleration masses dynamically, based on the lattice data. In the future, we\nhope to explore the effectiveness of these techniques in the\nstrongly-interacting case. Since our $\\phi^4$ theory is a linear chiral\neffective theory for QCD, this could be interesting for those who are seeking\nto generalize Fourier acceleration to QCD.","main_category":"hep-lat","categories":"hep-lat","published":"2025-04-24T17:07:44Z"}
{"aid":"http://arxiv.org/abs/2504.17758v1","title":"First study of neutrino angle reconstruction using quasielastic-like\n  interactions in MicroBooNE","summary":"We investigate the expected precision of the reconstructed neutrino direction\nusing a {\\nu}{\\mu}-argon quasielastic-like event topology with one muon and one\nproton in the final state and the reconstruction capabilities of the MicroBooNE\nliquid argon time projection chamber. This direction is of importance in the\ncontext of DUNE sub-GeV atmospheric oscillation studies. MicroBooNE allows for\na data-driven quantification of this resolution by investigating the deviation\nof the reconstructed muon-proton system orientation with respect to the\nwell-known direction of neutrinos originating from the Booster Neutrino Beam\nwith an exposure of 1.3 x 1021 protons on target. Using simulation studies, we\nderive the expected sub-GeV DUNE atmospheric-neutrino reconstructed simulated\nspectrum by developing a reweighting scheme as a function of the true neutrino\nenergy. We further report flux-integrated single- and double-differential cross\nsection measurements of charged-current {\\nu}{\\mu} quasielastic-like scattering\non argon as a function of the muon-proton system angle using the full\nMicroBooNE data sets. We also demonstrate the sensitivity of these results to\nnuclear effects and final state hadronic reinteraction modeling.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-24T17:20:49Z"}
{"aid":"http://arxiv.org/abs/2504.17768v1","title":"The Sparse Frontier: Sparse Attention Trade-offs in Transformer LLMs","summary":"Sparse attention offers a promising strategy to extend long-context\ncapabilities in Transformer LLMs, yet its viability, its efficiency-accuracy\ntrade-offs, and systematic scaling studies remain unexplored. To address this\ngap, we perform a careful comparison of training-free sparse attention methods\nat varying model scales, sequence lengths, and sparsity levels on a diverse\ncollection of long-sequence tasks-including novel ones that rely on natural\nlanguage while remaining controllable and easy to evaluate. Based on our\nexperiments, we report a series of key findings: 1) an isoFLOPS analysis\nreveals that for very long sequences, larger and highly sparse models are\npreferable to smaller and dense ones. 2) The level of sparsity attainable while\nstatistically guaranteeing accuracy preservation is higher during decoding than\nprefilling, and correlates with model size in the former. 3) There is no clear\nstrategy that performs best across tasks and phases, with different units of\nsparsification or budget adaptivity needed for different scenarios. Even\nmoderate sparsity levels often result in significant performance degradation on\nat least one task, highlighting that sparse attention is not a universal\nsolution. 4) We introduce and validate novel scaling laws specifically tailored\nfor sparse attention, providing evidence that our findings are likely to hold\ntrue beyond our range of experiments. Through these insights, we demonstrate\nthat sparse attention is a key tool to enhance the capabilities of Transformer\nLLMs for processing longer sequences, but requires careful evaluation of\ntrade-offs for performance-sensitive applications.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-24T17:39:25Z"}
{"aid":"http://arxiv.org/abs/2504.17779v1","title":"Josephson anomalous vortices","summary":"We show that vortices with circulating current, related with odd-frequency\ntriplet pairing, appear in Josephson junctions where the barrier is a weak\nferromagnet with strong spin-orbit coupling. By both symmetry analysis and\nmicroscopic methods we show that there is an additional term - a rotary\ninvariant - in the superconducting free energy which allows for magnetoelectric\neffects even when the previously considered Lifshitz invariant vanishes. We\nshow that the size, shape, and position of these vortices can be controlled by\nmanipulating Rashba spin-orbit coupling in the weak link, via gates, and we\nsuggest that these vortices could be detected via scanning magnetometry\ntechniques. We also show that the transverse triplet components of the\nsuperconducting correlations can form a texture.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-24T17:56:00Z"}
{"aid":"http://arxiv.org/abs/2504.17782v1","title":"Unleashing the Power of Natural Audio Featuring Multiple Sound Sources","summary":"Universal sound separation aims to extract clean audio tracks corresponding\nto distinct events from mixed audio, which is critical for artificial auditory\nperception. However, current methods heavily rely on artificially mixed audio\nfor training, which limits their ability to generalize to naturally mixed audio\ncollected in real-world environments. To overcome this limitation, we propose\nClearSep, an innovative framework that employs a data engine to decompose\ncomplex naturally mixed audio into multiple independent tracks, thereby\nallowing effective sound separation in real-world scenarios. We introduce two\nremix-based evaluation metrics to quantitatively assess separation quality and\nuse these metrics as thresholds to iteratively apply the data engine alongside\nmodel training, progressively optimizing separation performance. In addition,\nwe propose a series of training strategies tailored to these separated\nindependent tracks to make the best use of them. Extensive experiments\ndemonstrate that ClearSep achieves state-of-the-art performance across multiple\nsound separation tasks, highlighting its potential for advancing sound\nseparation in natural audio scenarios. For more examples and detailed results,\nplease visit our demo page at https://clearsep.github.io.","main_category":"cs.SD","categories":"cs.SD,cs.LG","published":"2025-04-24T17:58:21Z"}
{"aid":"http://arxiv.org/abs/2504.19479v1","title":"Relativistic Two-Electron Contributions within Exact Two-Component\n  Theory","summary":"The development of relativistic exact two-component (X2C) theory is briefly\nreviewed, with an emphasis on cost-effective treatments of relativistic\ntwo-electron contributions by means of model potential (MP) techniques and\nclosely related atomic mean-field (AMF) approaches. The correct MP or AMF\ncontribution to the electronic energy is elucidated. The performance of\none-center approximations to relativistic two-electron contributions is\ncarefully assessed using benchmark calculations of molecular properties.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-28T04:35:04Z"}
{"aid":"http://arxiv.org/abs/2504.19492v1","title":"$K_1$-Stability of symplectic modules over monoid algebras","summary":"Let $R$ be a regular ring of dimension $d$ and $L$ be a $c$-divisible monoid.\nIf ${K}_1{Sp}(R)$ is trivial and $k \\geq d+2,$ then we prove that the\nsymplectic group ${Sp}_{2k}(R[L])$ is generated by elementary symplectic\nmatrices over $R[L]$. When $d \\leq 1$ or $R$ is a geometrically regular ring\ncontaining a field, then improved bounds have been established. We also discuss\nthe linear case, extending the work of Gubeladze.","main_category":"math.AC","categories":"math.AC,math.KT,math.RA","published":"2025-04-28T05:19:25Z"}
{"aid":"http://arxiv.org/abs/2504.19503v1","title":"Signatures of Hund$'s$ metal physics in single-layered 3d transition\n  metal oxide, $\\mathrm{Sr_2CoO_4}$","summary":"With density functional theory plus dynamical mean-field theory, we study the\ninfluence of Hund's coupling on the nature of electronic correlations in\n$\\mathrm{Sr_2CoO_4}$. Our results suggest strong signatures of Hund's metal\nphysics in this compound. The Co 3$d$ states show large orbital differentiation\nin the degree of correlations and mass enhancement. The imaginary-time\ncorrelation functions suggest the presence of spin-orbital separation and large\nlocal charge fluctuations in the system. Breakdown of the Fermi-liquid picture\nis observed at the lowest calculated temperature for various strengths of\nHund's coupling, suggesting the Fermi-liquid coherence scale lower than\n$\\sim$100 K. Interestingly, a sudden emergence of a gapped state is noted for\n$e_g$ orbitals in its spectral density of states at $\\sim$200 K in the vicinity\nof Fermi-level. Among the Co 3$d$ states 3$d_{z^2}$ and 3$d_{x^2-y^2}$ foster\nenlarged correlations. This study conclusively identifies $\\mathrm{Sr_2CoO_4}$\nas the first single-layered 3$d$ transition metal oxide to be classified as\nHund's metal.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-28T05:50:25Z"}
{"aid":"http://arxiv.org/abs/2504.19517v1","title":"Stokes drag on a sphere in a three-dimensional anisotropic porous medium","summary":"We study the hydrodynamic drag force exerted on a sphere in a static\nanisotropic porous medium. This problem is analysed using the\nBrinkman-Debye-Bueche equations with an axisymmetric shielding (or\npermeability) tensor. Using the exact Green's functions for this model fluid\nwithin a single-layer boundary element formulation, we numerically compute the\nfriction tensor for a translating sphere subjected to stick boundary\nconditions. Furthermore, we derive approximate analytical expressions for small\nanisotropy using the Lorentz reciprocal theorem. By benchmarking this result\nagainst the numerical solutions, we find that a linear approximation is valid\nin a broad parameter regime. Our results are important for studying\nself-diffusion in general anisotropic porous media, but can also be applied to\nsmall tracers in nematic fluids composed of disk- or rod-like crowders.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.flu-dyn","published":"2025-04-28T06:34:51Z"}
{"aid":"http://arxiv.org/abs/2504.19560v1","title":"Strongly regular graphs in hyperbolic quadrics","summary":"Let $Q^+(2n+1,q)$ be a hyperbolic quadric of $\\rm PG(2n+1,q)$. Fix a\ngenerator $\\Pi$ of the quadric. Define $\\mathcal{G}_n$ as the graph with vertex\nset the points of $Q^+(2n+1,q)\\setminus \\Pi$ and two vertices adjacent if they\neither span a secant to $Q^+(2n+1,q)$ or a line contained in $Q^+(2n+1,q)$\nmeeting $\\Pi$ non-trivially. We show that $\\mathcal{G}_n$ is a strongly regular\ngraph, that has, for $q=2$ the same parameters as the tangent graph\n$NO^+(2n+2,2)$, but which is non-isomorphic for $n\\geq3$. Hence for $n \\geq 3$,\nthe graphs $\\mathcal{G}_n$ are a putative new family of strongly regular\ngraphs.","main_category":"math.CO","categories":"math.CO","published":"2025-04-28T08:10:00Z"}
{"aid":"http://arxiv.org/abs/2504.19569v1","title":"Fermionizing the ideal Bose gas via topological pumping","summary":"We investigate the coherence and correlations of many-body states appearing\nin topological pumping in a one-dimensional Bose gas. By analyzing the system\nat zero and infinite interaction strengths, we reveal a rescaling of momentum\ndistributions accompanied by a self-similar behavior in first- and second-order\ncorrelation functions. In excited states of non-interacting bosons, the\nmomentum distribution shows a comb-like structure similar to that of\nnon-interacting fermions but at a higher density. This is mirrored by Friedel\noscillations in the one-body density matrix. At the same time, the\ndensity-density correlations still exhibit the bosonic enhancement. Our work\nillustrates how topological pumping induces a nontrivial mapping between\nbosonic and fermionic correlations.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,quant-ph","published":"2025-04-28T08:28:04Z"}
{"aid":"http://arxiv.org/abs/2504.19588v1","title":"Stochastic Partial Differential Equations Associated with\n  Pseudo-Differential Operators and Hilbert Space-Valued Gaussian Processes","summary":"In this paper, we prove the unique existence and investigate the\n$L^{p}$-regularity of solutions to stochastic partial differential equations in\nHilbert spaces associated with pseudo-differential operators, driven by Hilbert\nspace-valued Gaussian processes that satisfy certain regularity conditions for\nthe covariance kernels of the Gaussian processes. For our purposes, we develop\nan $L^{p}$-regularity framework for the solutions to the stochastic partial\ndifferential equations associated with pseudo-differential operators. As the\nmain tools, we establish the $p$-th moment maximal inequality for stochastic\nintegrals with respect to a Hilbert space-valued Gaussian process and a\nLittlewood-Paley type inequality for Banach space-valued functions.\nAdditionally, during our study, we improved the sufficient conditions for\nFourier multipliers and examined the covariance kernels for Gaussian processes.","main_category":"math.AP","categories":"math.AP,math.PR","published":"2025-04-28T08:49:10Z"}
{"aid":"http://arxiv.org/abs/2504.19597v1","title":"Depth Sensitivity of Hilbert Coefficients","summary":"The purpose of this paper is to explain about the depth sensitivity of the\nHilbert coefficients defined for finitely generated graded modules over graded\nrings. The main result generalize the well known fact that the\nCohen-Macaulayness of graded modules can be characterized using their\nmultiplicities.","main_category":"math.AC","categories":"math.AC","published":"2025-04-28T09:00:27Z"}
{"aid":"http://arxiv.org/abs/2504.19599v1","title":"GVPO: Group Variance Policy Optimization for Large Language Model\n  Post-Training","summary":"Post-training plays a crucial role in refining and aligning large language\nmodels to meet specific tasks and human preferences. While recent advancements\nin post-training techniques, such as Group Relative Policy Optimization (GRPO),\nleverage increased sampling with relative reward scoring to achieve superior\nperformance, these methods often suffer from training instability that limits\ntheir practical adoption. To address this challenge, we present Group Variance\nPolicy Optimization (GVPO). GVPO incorporates the analytical solution to\nKL-constrained reward maximization directly into its gradient weights, ensuring\nalignment with the optimal policy. The method provides intuitive physical\ninterpretations: its gradient mirrors the mean squared error between the\ncentral distance of implicit rewards and that of actual rewards. GVPO offers\ntwo key advantages: (1) it guarantees a unique optimal solution, exactly the\nKL-constrained reward maximization objective, (2) it supports flexible sampling\ndistributions that avoids on-policy and importance sampling limitations. By\nunifying theoretical guarantees with practical adaptability, GVPO establishes a\nnew paradigm for reliable and versatile LLM post-training.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-28T09:02:24Z"}
{"aid":"http://arxiv.org/abs/2504.19608v1","title":"The frequency $K_i$s for symmetrical traveling salesman problem","summary":"The frequency $K_i$s ($i\\in[4,n]$) are studied for symmetrical traveling\nsalesman problem ($TSP$) to identify the edges in optimal Hamiltonian cycle\n($OHC$). A frequency $K_i$ is computed with a sort of ${{i}\\choose{2}}$ optimal\n$i$-vertex paths with given endpoints (optimal $i$-vertex path) in a\ncorresponding $K_i$ in $K_n$. In frequency $K_i$, the frequency of an edge is\nthe number of the optimal $i$-vertex paths containing the edge in the\ncorresponding $K_i$. Given an $OHC$ edge related to $K_i$, it has a frequency\nbigger than $\\frac{1}{2}{{i}\\choose{2}}$ in the corresponding frequency $K_i$,\nand that of an ordinary edge not in $OHC$ is smaller than $\\frac{i+2}{2}$. On\naverage, an $OHC$ edge in $K_i$ has a frequency bigger than\n$\\frac{i^2-4i+7}{2}$ whereas an ordinary edge has a frequency smaller than 2.\nMoreover, given a frequency $K_i$ containing an $OHC$ edge related to $K_n$,\nthe frequency of the $OHC$ edge is bigger than $\\frac{1}{2}{{i}\\choose{2}}$ in\nthe worst average case. It implies that the average frequency of an $OHC$ edge\ncomputed with frequency $K_i$s is bigger than $\\frac{1}{2}{{i}\\choose{2}}$. It\nalso found that the probability that an $OHC$ edge is contained in optimal\n$i$-vertex paths keeps stable or increases according to $i\\in [4, n]$. As the\nfrequency $K_i$s are used to compute the frequency of an edge, each $OHC$ edge\nhas its own peak frequency at $i=P_0$ where $P_0=\\frac{n}{2} + 2$ for even $n$\nor $\\frac{n+1}{2} + 1$ for odd $n$. For ordinary edges out of $OHC$, the\nprobability that they are contained in optimal $i$-vertex paths decreases\naccording to $i$. Moreover, the average frequency of an ordinary edge will be\nsmaller than $\\frac{1}{2}{{i}\\choose{2}}$ if $i \\geq [0.3660n + 1.5849]$. Based\non these findings, an algorithm is presented to find $OHC$ in\n$O(n^62^{0.3660n})$ time using dynamic programming.","main_category":"cs.DM","categories":"cs.DM,math.CO,math.OC","published":"2025-04-28T09:12:47Z"}
{"aid":"http://arxiv.org/abs/2504.19614v1","title":"DiVE: Efficient Multi-View Driving Scenes Generation Based on Video\n  Diffusion Transformer","summary":"Collecting multi-view driving scenario videos to enhance the performance of\n3D visual perception tasks presents significant challenges and incurs\nsubstantial costs, making generative models for realistic data an appealing\nalternative. Yet, the videos generated by recent works suffer from poor quality\nand spatiotemporal consistency, undermining their utility in advancing\nperception tasks under driving scenarios. To address this gap, we propose DiVE,\na diffusion transformer-based generative framework meticulously engineered to\nproduce high-fidelity, temporally coherent, and cross-view consistent\nmulti-view videos, aligning seamlessly with bird's-eye view layouts and textual\ndescriptions. DiVE leverages a unified cross-attention and a SketchFormer to\nexert precise control over multimodal data, while incorporating a view-inflated\nattention mechanism that adds no extra parameters, thereby guaranteeing\nconsistency across views. Despite these advancements, synthesizing\nhigh-resolution videos under multimodal constraints introduces dual challenges:\ninvestigating the optimal classifier-free guidance coniguration under intricate\nmulti-condition inputs and mitigating excessive computational latency in\nhigh-resolution rendering--both of which remain underexplored in prior\nresearches. To resolve these limitations, we introduce two innovations:\nMulti-Control Auxiliary Branch Distillation, which streamlines multi-condition\nCFG selection while circumventing high computational overhead, and Resolution\nProgressive Sampling, a training-free acceleration strategy that staggers\nresolution scaling to reduce high latency due to high resolution. These\ninnovations collectively achieve a 2.62x speedup with minimal quality\ndegradation. Evaluated on the nuScenes dataset, DiVE achieves SOTA performance\nin multi-view video generation, yielding photorealistic outputs with\nexceptional temporal and cross-view coherence.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-28T09:20:50Z"}
{"aid":"http://arxiv.org/abs/2504.19620v1","title":"From local to collective superconductivity in proximitized graphene","summary":"The superconducting proximity effect induces pairing correlations in metallic\nsystems via Andreev scattering. This effect is particularly intriguing in\ngraphene, as it enables two-dimensional superconductivity that is tunable\nthrough doping. Understanding how superconducting correlations propagate within\nthe metal is crucial to unveiling the key factors behind this tunability. Here,\nwe employ scanning tunneling microscopy to investigate the energy and length\nscales of the proximity effect induced by Pb islands on graphene. Using\ntip-induced manipulation, we assemble S/N/S junctions with tunable N-region\nspacing and explore the evolution of the proximitized state in the confined\nnormal region. We find that different doping levels can lead to either\nlocalized or collective superconducting states. By combining our experimental\nresults with quasiclassical theory, we demonstrate that interface conductance\nplays a key role in determining the strength and coherence length of pairing\ncorrelations and inter-island coupling. Our findings provide new insights into\nthe design of novel superconducting states and the control of their properties.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.supr-con","published":"2025-04-28T09:28:08Z"}
{"aid":"http://arxiv.org/abs/2504.19625v1","title":"Rulebook: bringing co-routines to reinforcement learning environments","summary":"Reinforcement learning (RL) algorithms, due to their reliance on external\nsystems to learn from, require digital environments (e.g., simulators) with\nvery simple interfaces, which in turn constrain significantly the\nimplementation of such environments. In particular, these environments are\nimplemented either as separate processes or as state machines, leading to\nsynchronization and communication overheads in the first case, and to\nunstructured programming in the second.\n  We propose a new domain-specific, co-routine-based, compiled language, called\nRulebook, designed to automatically generate the state machine required to\ninteract with machine learning (ML) algorithms and similar applications, with\nno performance overhead. Rulebook allows users to express programs without\nneeding to be aware of the specific interface required by the ML components. By\ndecoupling the execution model of the program from the syntactical encoding of\nthe program, and thus without the need for manual state management, Rulebook\nallows to create larger and more sophisticated environments at a lower\ndevelopment cost.","main_category":"cs.PL","categories":"cs.PL,cs.LG","published":"2025-04-28T09:34:34Z"}
{"aid":"http://arxiv.org/abs/2504.19691v1","title":"Unified Non-Singular Cosmology with Late-Time Acceleration through a\n  Novel Parametrization of Bulk Viscosity Coefficient","summary":"This work explores the influence of viscous fluids on cosmological dynamics\nwithin the framework of General Relativity. We introduce a novel time-dependent\nparametrization for the bulk viscosity coefficient, given by \\(\\zeta = \\zeta_0\n(t - t_0)^{-2n} \\rho^{1/2}\\), where \\(\\zeta_0\\), \\(t_0\\), and \\(n\\) are model\nparameters. This formulation is designed to investigate whether bulk viscosity\nof this nature can effectively describe the evolution of the universe,\nparticularly in scenarios that avoid initial singularities through a\ncosmological bounce. Remarkably, the general solutions emerging from our model\nexhibit significant flexibility, accommodating not only a bouncing universe but\nalso an early inflationary phase and a late-time acceleration mimicking dark\nenergy. The roles of \\(\\zeta_0\\), \\(t_0\\), and \\(n\\) are pivotal, as they\ngovern the cosmic evolution and determine the transitions between different\nphases. To validate the robustness of our model, we analyze key cosmological\nquantities such as the energy density, deceleration parameter, and the validity\nof various energy conditions. Furthermore, we employ statefinder diagnostics to\nprobe the dark energy behavior and examine Hubble flow parameters to shed light\non the inflationary aspects of the model. Lastly, we confront our theoretical\npredictions with observational data sets, including the BAO, DESI and\nPantheon+SH0ES datasets, demonstrating the model's consistency with empirical\ncosmological trends.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-28T11:38:10Z"}
{"aid":"http://arxiv.org/abs/2504.19724v1","title":"RepText: Rendering Visual Text via Replicating","summary":"Although contemporary text-to-image generation models have achieved\nremarkable breakthroughs in producing visually appealing images, their capacity\nto generate precise and flexible typographic elements, especially non-Latin\nalphabets, remains constrained. To address these limitations, we start from an\nnaive assumption that text understanding is only a sufficient condition for\ntext rendering, but not a necessary condition. Based on this, we present\nRepText, which aims to empower pre-trained monolingual text-to-image generation\nmodels with the ability to accurately render, or more precisely, replicate,\nmultilingual visual text in user-specified fonts, without the need to really\nunderstand them. Specifically, we adopt the setting from ControlNet and\nadditionally integrate language agnostic glyph and position of rendered text to\nenable generating harmonized visual text, allowing users to customize text\ncontent, font and position on their needs. To improve accuracy, a text\nperceptual loss is employed along with the diffusion loss. Furthermore, to\nstabilize rendering process, at the inference phase, we directly initialize\nwith noisy glyph latent instead of random initialization, and adopt region\nmasks to restrict the feature injection to only the text region to avoid\ndistortion of the background. We conducted extensive experiments to verify the\neffectiveness of our RepText relative to existing works, our approach\noutperforms existing open-source methods and achieves comparable results to\nnative multi-language closed-source models. To be more fair, we also\nexhaustively discuss its limitations in the end.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-28T12:19:53Z"}
{"aid":"http://arxiv.org/abs/2504.19744v1","title":"Lossy Beyond Diagonal Reconfigurable Intelligent Surfaces: Modeling and\n  Optimization","summary":"Beyond diagonal reconfigurable intelligent surface (BD-RIS) has emerged as an\nadvancement and generalization of the conventional diagonal RIS (D-RIS) by\nintroducing tunable interconnections between RIS elements, enabling smarter\nwave manipulation and enlarged coverage. While BD-RIS has demonstrated\nadvantages over D-RIS in various aspects, most existing works rely on the\nassumption of a lossless model, leaving practical considerations unaddressed.\nThis paper thus proposes a lossy BD-RIS model and develops corresponding\noptimization algorithms for various BD-RIS-aided communication systems. First,\nby leveraging admittance parameter analysis, we model each tunable admittance\nbased on a lumped circuit with losses and derive an expression of a circle\ncharacterizing the real and imaginary parts of each tunable admittance. We then\nconsider the received signal power maximization in single-user single-input\nsingle-output (SISO) systems with the proposed lossy BD-RIS model. To solve the\noptimization problem, we design an effective algorithm by carefully exploiting\nthe problem structure. Specifically, an alternating direction method of\nmultipliers (ADMM) framework is custom-designed to deal with the complicated\nconstraints associated with lossy BD-RIS. Furthermore, we extend the proposed\nalgorithmic framework to more general multiuser multiple-input single-output\n(MU-MISO) systems, where the transmit precoder and BD-RIS scattering matrix are\njointly designed to maximize the sum-rate of the system. Finally, simulation\nresults demonstrate that all BD-RIS architectures still outperform D-RIS in the\npresence of losses, but the optimal BD-RIS architectures in the lossless case\nare not necessarily optimal in the lossy case, e.g. group-connected BD-RIS can\noutperform fully- and tree-connected BD-RISs in SISO systems with relatively\nhigh losses, whereas the opposite always holds true in the lossless case.","main_category":"eess.SP","categories":"eess.SP,cs.IT,math.IT","published":"2025-04-28T12:45:33Z"}
{"aid":"http://arxiv.org/abs/2504.19767v1","title":"Crafting a Personal Journaling Practice: Negotiating Ecosystems of\n  Materials, Personal Context, and Community in Analog Journaling","summary":"Analog journaling has grown in popularity, with journaling on paper\nencompassing a range of motivations, styles, and practices including planning,\nhabit-tracking, and reflecting. Journalers develop strong personal preferences\naround the tools they use, the ideas they capture, and the layout in which they\nrepresent their ideas and memories. Understanding how analog journaling\npractices are individually shaped and crafted over time is critical to\nsupporting the varied benefits associated with journaling, including improved\nmental health and positive support for identity development. To understand this\ndevelopment, we qualitatively analyzed publicly-shared journaling content from\nYouTube and Instagram and interviewed 11 journalers. We report on our\nidentification of the journaling ecosystem in which journaling practices are\nshaped by materials, personal context, and communities, sharing how this\necosystem plays a role in the practices and identities of journalers as they\ncustomize their journaling routine to best suit their personal goals. Using\nthese insights, we discuss design opportunities for how future tools can better\nalign with and reflect the rich affordances and practices of journaling on\npaper.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-28T13:07:29Z"}
{"aid":"http://arxiv.org/abs/2504.19804v1","title":"Nonlinear Power Absorption in CCRF Discharges: Transition from Symmetric\n  to Asymmetric Configurations","summary":"This work builds upon previous studies of nonlinear dynamics in low-pressure\ncapacitively coupled radio-frequency discharges, focusing on the electron power\nabsorption mechanism in discharges with various geometric asymmetries. We\npresent a comprehensive investigation using a fully kinetic electrostatic 1d3v\nParticle-in-Cell/Monte Carlo collision simulation in spherical geometry. By\nsystematically varying the inner electrode radius and the electrode gap\ndistance, we analyze the influence of geometric asymmetry on key plasma\nproperties, including electron density, power absorption, electron dynamics,\nand current characteristics. A central focus is placed on the cumulative power\ndensity as a diagnostic for energy deposition. In strongly asymmetric\nconfigurations, the cumulative electron power density exhibits distinct\nstepwise increases during sheath expansion, corresponding to the acceleration\nof successive electron beams. These nonlinear signatures are directly linked to\nthe excitation of plasma series resonance and enhanced beam-driven power\nabsorption. In contrast, more symmetric configurations display smoother, more\nsymmetric cumulative power evolution, indicating balanced energy transfer at\nboth sheaths and reduced nonlinearities. Time- and space-resolved diagnostics\nof cumulative power, current waveforms, and densities of energetic electrons\nreveal the critical role of asymmetry in shaping electron confinement and\nbeam-driven power absorption. These findings demonstrate that the discharge\ngeometry is actually an important design parameter which needs to taken into\naccount during the design and construction phase of a reactor as it directly\ninfluences the plasma behavior with respect to energy deposition.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-28T13:55:43Z"}
{"aid":"http://arxiv.org/abs/2504.19807v1","title":"Multi-Parameter Transitions in Cosmological Calibrators: A Resolution to\n  the Hubble Tension from SH0ES Data Analysis","summary":"The Hubble tension, characterized by discrepant measurements of the Hubble\nconstant from early and late universe probes, remains one of the most\nsignificant challenges in cosmology. Building upon our previous analysis of\nindividual parameter transitions in SH0ES data, we investigate the impact of\nsimultaneous transitions in multiple Cepheid and SNIa calibration parameters at\nspecific cosmic distances. We allow various combinations of transitions in\nCepheid absolute magnitude ($M^W_H$), period-luminosity relation slope ($b_W$),\nmetallicity coefficient ($Z_W$), and SNIa absolute magnitude ($M_B$). Our\ncomprehensive analysis reveals a consistent preferred transition distance of\napproximately 23 Mpc across different parameter combinations. The most\nstatistically favored model allows simultaneous transitions in $b_W$, $Z_W$,\nand $M_B$, yielding $\\Delta \\text{AIC} \\simeq -9.2$ and $\\Delta \\text{BIC}\n\\simeq -3.0$ compared to the baseline SH0ES model. This provides strong\nevidence for inhomogeneities in standard candle calibrations. We demonstrate\nthat the post-transition SNIa absolute magnitude aligns more closely with\nCMB-based constraints, resulting in a reduced Hubble constant value that\nalleviates the tension. Our findings suggest that the Hubble tension might be\nresolved through proper modeling of calibration parameter inhomogeneities\nrather than requiring new physics beyond $\\Lambda$CDM.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-28T14:04:27Z"}
{"aid":"http://arxiv.org/abs/2504.19818v1","title":"PhenoAssistant: A Conversational Multi-Agent AI System for Automated\n  Plant Phenotyping","summary":"Plant phenotyping increasingly relies on (semi-)automated image-based\nanalysis workflows to improve its accuracy and scalability. However, many\nexisting solutions remain overly complex, difficult to reimplement and\nmaintain, and pose high barriers for users without substantial computational\nexpertise. To address these challenges, we introduce PhenoAssistant: a\npioneering AI-driven system that streamlines plant phenotyping via intuitive\nnatural language interaction. PhenoAssistant leverages a large language model\nto orchestrate a curated toolkit supporting tasks including automated phenotype\nextraction, data visualisation and automated model training. We validate\nPhenoAssistant through several representative case studies and a set of\nevaluation tasks. By significantly lowering technical hurdles, PhenoAssistant\nunderscores the promise of AI-driven methodologies to democratising AI adoption\nin plant biology.","main_category":"cs.MA","categories":"cs.MA,cs.AI","published":"2025-04-28T14:20:30Z"}
{"aid":"http://arxiv.org/abs/2504.19859v1","title":"Some PDE results in Heston model with applications","summary":"We present here some results for the PDE related to the logHeston model. We\npresent different regularity results and prove a verification theorem that\nshows that the solution produced via the Feynman-Kac theorem is the unique\nviscosity solution for a wide choice of initial data (even discontinuous) and\nsource data. In addition, our techniques do not use Feller's condition at any\ntime. In the end, we prove a convergence theorem to approximate this solution\nby means of a hybrid (finite differences/tree scheme) approach.","main_category":"math.AP","categories":"math.AP,cs.NA,math.NA,q-fin.CP","published":"2025-04-28T14:50:06Z"}
{"aid":"http://arxiv.org/abs/2504.19867v1","title":"semi-PD: Towards Efficient LLM Serving via Phase-Wise Disaggregated\n  Computation and Unified Storage","summary":"Existing large language model (LLM) serving systems fall into two categories:\n1) a unified system where prefill phase and decode phase are co-located on the\nsame GPU, sharing the unified computational resource and storage, and 2) a\ndisaggregated system where the two phases are disaggregated to different GPUs.\nThe design of the disaggregated system addresses the latency interference and\nsophisticated scheduling issues in the unified system but leads to storage\nchallenges including 1) replicated weights for both phases that prevent\nflexible deployment, 2) KV cache transfer overhead between the two phases, 3)\nstorage imbalance that causes substantial wasted space of the GPU capacity, and\n4) suboptimal resource adjustment arising from the difficulties in migrating KV\ncache. Such storage inefficiency delivers poor serving performance under high\nrequest rates.\n  In this paper, we identify that the advantage of the disaggregated system\nlies in the disaggregated computation, i.e., partitioning the computational\nresource to enable the asynchronous computation of two phases. Thus, we propose\na novel LLM serving system, semi-PD, characterized by disaggregated computation\nand unified storage. In semi-PD, we introduce a computation resource controller\nto achieve disaggregated computation at the streaming multi-processor (SM)\nlevel, and a unified memory manager to manage the asynchronous memory access\nfrom both phases. semi-PD has a low-overhead resource adjustment mechanism\nbetween the two phases, and a service-level objective (SLO) aware dynamic\npartitioning algorithm to optimize the SLO attainment. Compared to\nstate-of-the-art systems, semi-PD maintains lower latency at higher request\nrates, reducing the average end-to-end latency per request by 1.27-2.58x on\nDeepSeek series models, and serves 1.55-1.72x more requests adhering to latency\nconstraints on Llama series models.","main_category":"cs.CL","categories":"cs.CL,cs.DC,cs.LG","published":"2025-04-28T15:00:03Z"}
{"aid":"http://arxiv.org/abs/2504.19880v1","title":"On the global dimension three endomorphism algebras of the minimal\n  generator-cogenerator","summary":"The main goal of this paper is to study the class of algebras for which the\nglobal dimension of the endomorphism ring of the generator-cogenerator, given\nby the sum of the projective and injective modules, is equal to three. We will\nrefer to these algebras as representation-hereditary algebras. We show that\nthese algebras are torsionless-finite, as defined by Ringel. These algebras do\nnot necessarily have finite global dimension; however, when there is no\nnon-zero morphism from an injective to a projective module, they have global\ndimension less than or equal to two, with some additional homological\nproperties. By utilizing the general framework provided by the study of the\nrepresentation dimension of an algebra, we present further homological\nconsequences. In the case where these algebras are tame quasi-tilted algebras,\nwe prove that they belong to certain classes of tilted algebras. Although not\nall tilted algebras are representation-hereditary, we provide sufficient\nconditions for them to be representation-hereditary.","main_category":"math.RT","categories":"math.RT","published":"2025-04-28T15:09:58Z"}
{"aid":"http://arxiv.org/abs/2504.19923v1","title":"Modeling of Parallel Single-Pixel Imaging for 3D Reconstruction: New\n  Insights and Opportunities","summary":"The growing prevalence of intelligent manufacturing and autonomous vehicles\nhas intensified the demand for three-dimensional (3D) reconstruction under\ncomplex reflection and transmission conditions. Traditional structured light\ntechniques rely on inherent point-to-point triangulation, which limits accurate\n3D measurements in these challenging scenarios. Parallel single-pixel imaging\n(PSI) has demonstrated unprecedented superiority under extreme conditions and\nhas emerged as a promising approach of accurate 3D measurements. However, a\ncomplete theoretical model has not been reported in existing work to well\nexplain its underlying mechanisms and quantitatively characterize its\nperformance. In this study, a comprehensive theoretical model for the PSI\nmethod is proposed, including imaging and noise models. The proposed imaging\nmodel describes light transport coefficients under complex illumination,\nelucidating the intrinsic mechanisms of successful 3D imaging using PSI. The\ndeveloped noise model quantitatively analyzes the impact of environmental noise\non measurement accuracy, offering a framework to guide the error analysis of a\nPSI system. Numerical simulations and experimental results validate the\nproposed models, revealing the generality and robustness of PSI. Finally,\npotential research directions are highlighted to guide and inspire future\ninvestigations. The established theoretical models lay a solid foundation of\nPSI and brings new insights and opportunities for future application in more\ndemanding 3D reconstruction tasks.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-28T15:57:44Z"}
{"aid":"http://arxiv.org/abs/2504.19950v1","title":"Data-Driven Stabilization of Unknown Linear-Threshold Network Dynamics","summary":"This paper studies the data-driven control of unknown linear-threshold\nnetwork dynamics to stabilize the state to a reference value. We consider two\ntypes of controllers: (i) a state feedback controller with feed-forward\nreference input and (ii) an augmented feedback controller with error\nintegration. The first controller features a simpler structure and is easier to\ndesign, while the second offers improved performance in the presence of system\nparameter changes and disturbances. Our design strategy employs state-input\ndatasets to construct data-based representations of the closed-loop dynamics.\nSince these representations involve linear threshold functions, we rewrite them\nas switched linear systems, and formulate the design problem as that of finding\na common controller for all the resulting modes. This gives rise to a set of\nlinear matrix inequalities (LMIs) whose solutions corresponds to the controller\ngain matrices. We analyze the computational complexity of solving the LMIs and\npropose a simplified, sufficient set of conditions that scales linearly with\nthe system state. Simulations on two case studies involving regulation of\nfiring rate dynamics in rodent brains and of arousal level dynamics in humans\ndemonstrate the effectiveness of the controller designs.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-28T16:21:47Z"}
{"aid":"http://arxiv.org/abs/2504.19954v1","title":"Type-Based Unsourced Multiple Access over Fading Channels with Cell-Free\n  Massive MIMO","summary":"Type-based unsourced multiple access (TUMA) is a recently proposed framework\nfor type-based estimation in massive uncoordinated access networks. We extend\nthe existing design of TUMA, developed for an additive white Gaussian channel,\nto a more realistic environment with fading and multiple antennas.\nSpecifically, we consider a cell-free massive multiple-input multiple-output\nsystem and exploit spatial diversity to estimate the set of transmitted\nmessages and the number of users transmitting each message. Our solution relies\non a location-based codeword partition and on the use at the receiver of a\nmultisource approximate message passing algorithm in both centralized and\ndistributed implementations. The proposed TUMA framework results in a robust\nand scalable architecture for massive machine-type communications.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-28T16:24:46Z"}
{"aid":"http://arxiv.org/abs/2504.19966v1","title":"Quantum circuit lower bounds in the magic hierarchy","summary":"We introduce the magic hierarchy, a quantum circuit model that alternates\nbetween arbitrary-sized Clifford circuits and constant-depth circuits with\ntwo-qubit gates ($\\textsf{QNC}^0$). This model unifies existing circuit models,\nsuch as $\\textsf{QAC}^0_f$ and models with adaptive intermediate measurements.\nDespite its generality, we are able to prove nontrivial lower bounds.\n  We prove new lower bounds in the first level of the hierarchy, showing that\ncertain explicit quantum states cannot be approximately prepared by circuits\nconsisting of a Clifford circuit followed by $\\textsf{QNC}^0$. These states\ninclude ground states of some topologically ordered Hamiltonians and\nnonstabilizer quantum codes. Our techniques exploit the rigid structure of\nstabilizer codes and introduce an infectiousness property: if even a single\nstate in a high distance code can be approximately prepared by one of these\ncircuits, then the entire subspace must lie close to a perturbed stabilizer\ncode. We also show that proving state preparation lower bounds beyond a certain\nlevel of the hierarchy would imply classical circuit lower bounds beyond the\nreach of current techniques in complexity theory.\n  More broadly, our techniques go beyond lightcone-based methods and highlight\nhow the magic hierarchy provides a natural framework for connecting circuit\ncomplexity, condensed matter, and Hamiltonian complexity.","main_category":"quant-ph","categories":"quant-ph,cs.CC","published":"2025-04-28T16:38:20Z"}
{"aid":"http://arxiv.org/abs/2504.19969v1","title":"Holographic Consequences of Heterotic String Theory beyond its\n  Supergravity Approximation","summary":"In this work, we study the effects of stringy corrections on the low energy\neffective action derived from heterotic string theory beyond its supergravity\napproximation. Compactifying the ten dimensional theory with these stringy\ncorrections produces an effective action for a scalar field whose higher\nderivative term is governed by a single coefficient that depends on the\ninternal volume, average curvature, and flux of the compactification manifold.\nThe higher derivative coupling imported from compactification shifts the\nBreitenlohner Freedman stability bound by an amount set by the relative\nstrengths of internal flux and curvature, relaxing it in flux dominated vacua\nand tightening it in curvature dominated ones. Furthermore, we analyze how the\nstringy corrections shift the scaling dimensions of the dual operators, track\nthe resulting renormalization group flow, and investigate the higher derivative\nterm using a holographic Lee Wick regulator. In holographic superconductors,\nstringy corrections lower the effective bulk mass and raise the critical\ntemperature when flux dominates, but have the opposite effect when curvature\ndominates.","main_category":"hep-th","categories":"hep-th","published":"2025-04-28T16:40:25Z"}
{"aid":"http://arxiv.org/abs/2504.19987v1","title":"Graph Neural Network Prediction of Nonlinear Optical Properties","summary":"Nonlinear optical (NLO) materials for generating lasers via second harmonic\ngeneration (SHG) are highly sought in today's technology. However, discovering\nnovel materials with considerable SHG is challenging due to the time-consuming\nand costly nature of both experimental methods and first-principles\ncalculations. In this study, we present a deep learning approach using the\nAtomistic Line Graph Neural Network (ALIGNN) to predict NLO properties.\nSourcing data from the Novel Opto-Electronic Materials Discovery (NOEMD)\ndatabase and using the Kurtz-Perry (KP) coefficient as the key target, we\ndeveloped a robust model capable of accurately estimating nonlinear optical\nresponses. Our results demonstrate that the model achieves 82.5% accuracy at a\ntolerated absolute error up to 1 pm/V and relative error not exceeding 0.5.\nThis work highlights the potential of deep learning in accelerating the\ndiscovery and design of advanced optical materials with desired properties.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cs.LG,physics.optics","published":"2025-04-28T17:03:22Z"}
{"aid":"http://arxiv.org/abs/2504.20000v1","title":"Knowledge Distillation of Domain-adapted LLMs for Question-Answering in\n  Telecom","summary":"Knowledge Distillation (KD) is one of the approaches to reduce the size of\nLarge Language Models (LLMs). A LLM with smaller number of model parameters\n(student) is trained to mimic the performance of a LLM of a larger size\n(teacher model) on a specific task. For domain-specific tasks, it is not clear\nif teacher or student model, or both, must be considered for domain adaptation.\nIn this work, we study this problem from perspective of telecom domain\nQuestion-Answering (QA) task. We systematically experiment with Supervised\nFine-tuning (SFT) of teacher only, SFT of student only and SFT of both prior to\nKD. We design experiments to study the impact of vocabulary (same and\ndifferent) and KD algorithms (vanilla KD and Dual Space KD, DSKD) on the\ndistilled model. Multi-faceted evaluation of the distillation using 14\ndifferent metrics (N-gram, embedding and LLM-based metrics) is considered.\nExperimental results show that SFT of teacher improves performance of distilled\nmodel when both models have same vocabulary, irrespective of algorithm and\nmetrics. Overall, SFT of both teacher and student results in better performance\nacross all metrics, although the statistical significance of the same depends\non the vocabulary of the teacher models.","main_category":"cs.CL","categories":"cs.CL,cs.IR,cs.LG,I.2.7","published":"2025-04-28T17:19:25Z"}
{"aid":"http://arxiv.org/abs/2504.20006v1","title":"Chatbot Arena Meets Nuggets: Towards Explanations and Diagnostics in the\n  Evaluation of LLM Responses","summary":"Battles, or side-by-side comparisons in so called arenas that elicit human\npreferences, have emerged as a popular approach to assessing the output quality\nof LLMs. Recently, this idea has been extended to retrieval-augmented\ngeneration (RAG) systems. While undoubtedly representing an advance in\nevaluation, battles have at least two drawbacks, particularly in the context of\ncomplex information-seeking queries: they are neither explanatory nor\ndiagnostic. Recently, the nugget evaluation methodology has emerged as a\npromising approach to evaluate the quality of RAG answers. Nuggets decompose\nlong-form LLM-generated answers into atomic facts, highlighting important\npieces of information necessary in a \"good\" response. In this work, we apply\nour AutoNuggetizer framework to analyze data from roughly 7K Search Arena\nbattles provided by LMArena in a fully automatic manner. Our results show a\nsignificant correlation between nugget scores and human preferences, showcasing\npromise in our approach to explainable and diagnostic system evaluations.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-28T17:24:36Z"}
{"aid":"http://arxiv.org/abs/2504.20022v1","title":"Better To Ask in English? Evaluating Factual Accuracy of Multilingual\n  LLMs in English and Low-Resource Languages","summary":"Multilingual Large Language Models (LLMs) have demonstrated significant\neffectiveness across various languages, particularly in high-resource languages\nsuch as English. However, their performance in terms of factual accuracy across\nother low-resource languages, especially Indic languages, remains an area of\ninvestigation. In this study, we assess the factual accuracy of LLMs - GPT-4o,\nGemma-2-9B, Gemma-2-2B, and Llama-3.1-8B - by comparing their performance in\nEnglish and Indic languages using the IndicQuest dataset, which contains\nquestion-answer pairs in English and 19 Indic languages. By asking the same\nquestions in English and their respective Indic translations, we analyze\nwhether the models are more reliable for regional context questions in Indic\nlanguages or when operating in English. Our findings reveal that LLMs often\nperform better in English, even for questions rooted in Indic contexts.\nNotably, we observe a higher tendency for hallucination in responses generated\nin low-resource Indic languages, highlighting challenges in the multilingual\nunderstanding capabilities of current LLMs.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-28T17:48:13Z"}
{"aid":"http://arxiv.org/abs/2504.20416v1","title":"Large-scale artificial intelligence with 41 million nanophotonic neurons\n  on a metasurface","summary":"Conventional integrated circuits (ICs) struggle to meet the escalating\ndemands of artificial intelligence (AI). This has sparked a renewed interest in\nan unconventional computing paradigm: neuromorphic (brain-inspired) computing.\nHowever, current neuromorphic systems face significant challenges in delivering\na large number of parameters (i.e., weights) required for large-scale AI\nmodels. As a result, most neuromorphic hardware is limited to basic benchmark\ndemonstrations, hindering its application to real-world AI challenges. Here, we\npresent a large-scale optical neural network (ONN) for machine learning\nacceleration, featuring over 41 million photonic neurons. This system not only\nsurpasses digital electronics in speed and energy efficiency but more\nimportantly, closes the performance gap with large-scale AI models. Our ONN\nleverages an innovative optical metasurface device featuring numerous spatial\nmodes. This device integrates over 41 million meta-atoms on a 10 mm$^2$\nmetasurface chip, enabling the processing of tens of millions of weights in a\nsingle operation. For the first time, we demonstrate that an ONN, utilizing a\nsingle-layer metasurface, can match the performance of deep and large-scale\ndeep learning models, such as ResNet and Vision Transformer, across various\nbenchmark tasks. Additionally, we show that our system can deliver\nhigh-performance solutions to real-world AI challenges through its\nunprecedented scale, such as accelerating the analysis of multi-gigapixel whole\nslide images (WSIs) for cancer detection by processing the million-pixel\nsub-image in a single shot. Our system reduces computing time and energy\nconsumption by over 1,000 times compared to state-of-the-art graphic processing\nunits (GPUs). This work presents a large-scale, low-power, and high-performance\nneuromorphic computing system, paving the way for future disruptive AI\ntechnologies.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-29T04:27:35Z"}
{"aid":"http://arxiv.org/abs/2504.20417v1","title":"Protocol-level description and self-contained security proof of\n  decoy-state BB84 QKD protocol","summary":"In this paper, we present a flowchart-based description of the decoy-state\nBB84 quantum key distribution (QKD) protocol and provide a step-by-step,\nself-contained information-theoretic security proof for this protocol within\nthe universal composable security framework. As a result, our proof yields a\nkey rate consistent with previous findings. Importantly, unlike all the prior\nsecurity proofs, our approach offers a fully rigorous and mathematical\njustification for achieving the key rate with the claimed correctness and\nsecrecy parameters, thereby representing a significant step toward the formal\ncertification of QKD systems.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-29T04:28:15Z"}
{"aid":"http://arxiv.org/abs/2504.20441v1","title":"Task-Oriented Semantic Communication with Importance-Aware Rate Control","summary":"Semantic communication is recognized for its high compression efficiency and\nrobust resistance to noise. However, utilizing a fixed transmission rate in\nenvironments with dynamic signal-to-noise ratios (SNR) often results in\ninefficient use of communication resources. To address this challenge, this\nletter proposes an importance-aware rate control semantic communication (IRCSC)\nscheme, which dynamically adjusts transmission rates in response to both\nchannel conditions and semantic importance. The scheme employs a\ncontribution-based importance analyzer to rank semantic importance.\nAdditionaly, a novel metric, the semantic transmission integrity index (STII),\nis proposed to quantify the amount of correctly transmitted information and to\ncorrelate it with inference performance. Simulations indicate that, with low\ncomputational complexity, IRCSC guarantees a controllable trade-off between\nperformance and rate, delivering higher compression efficiency and improved\ntask performance in high-SNR scenarios.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-29T05:32:18Z"}
{"aid":"http://arxiv.org/abs/2504.20467v1","title":"Switching, Multiple Time-Scales and Geometric Blow-Up in a\n  Low-Dimensional Gene Regulatory Network","summary":"ODE-based models for gene regulatory networks (GRNs) can often be formulated\nas smooth singular perturbation problems with multiple small parameters, some\nof which are related to time-scale separation, whereas others are related to\n'switching' (proximity to a non-smooth singular limit). This motivates the\nstudy of reduced models obtained after (i) quasi-steady state reduction (QSSR),\nwhich utilises the time-scale separation, and (ii) piecewise-smooth\napproximations, which reduce the nonlinearity of the model by viewing highly\nnonlinear sigmoidal terms as singular perturbations of step functions. We\ninvestigate the interplay between the reduction methods (i)-(ii), in the\ncontext of a 4-dimensional GRN which has been used as a low-dimensional\nrepresentative of an important class of (generally high-dimensional) GRN models\nin the literature. We begin by identifying a region in the small parameter\nplane for which this problem can be formulated as a smooth singularly perturbed\nsystem on a blown-up space, uniformly in the switching parameter. This allows\nus to apply Fenichel's coordinate-free theorems and obtain a rigorous reduction\nto a 2-dimensional system, that is a perturbation of the QSSR. Finally, we show\nthat the reduced system features a Hopf bifurcation which does not appear in\nthe QSSR system, due to the influence of higher order terms. Taken together,\nour findings suggest that the relative size of the small parameters is\nimportant for the validity of QSS reductions and the determination of\nqualitative dynamics in GRN models more generally. Although the focus is on the\n4-dimensional GRN, our approach is applicable to higher dimensions.","main_category":"math.DS","categories":"math.DS","published":"2025-04-29T07:05:05Z"}
{"aid":"http://arxiv.org/abs/2504.20514v1","title":"Distributed U6G ELAA Communication Systems: Channel Measurement and\n  Small-Scale Fading Characterization","summary":"The distributed upper 6 GHz (U6G) extra-large scale antenna array (ELAA) is a\nkey enabler for future wireless communication systems, offering higher\nthroughput and wider coverage, similar to existing ELAA systems, while\neffectively mitigating unaffordable complexity and hardware overhead. Uncertain\nchannel characteristics, however, present significant bottleneck problems that\nhinder the hardware structure and algorithm design of the distributed U6G ELAA\nsystem. In response, we construct a U6G channel sounder and carry out extensive\nmeasurement campaigns across various typical scenarios. Initially, U6G channel\ncharacteristics, particularly small-scale fading characteristics, are unveiled\nand compared across different scenarios. Subsequently, the U6G ELAA channel\ncharacteristics are analyzed using a virtual array comprising 64 elements.\nFurthermore, inspired by the potential for distributed processing, we\ninvestigate U6G ELAA channel characteristics from the perspectives of subarrays\nand sub-bands, including subarray-wise nonstationarities, consistencies,\nfar-field approximations, and sub-band characteristics. Through a combination\nof analysis and measurement validation, several insights and benefits,\nparticularly suitable for distributed processing in U6G ELAA systems, are\nrevealed, which provides practical validation for the deployment of U6G ELAA\nsystems.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-29T07:57:08Z"}
{"aid":"http://arxiv.org/abs/2504.20531v1","title":"Addressing Data Scarcity in UBEM Validation: Application of Survey\n  Sampling Techniques","summary":"Urban Building Energy Models (UBEM) are vital for enhancing energy efficiency\nand sustainability in urban planning. However, data scarcity often challenges\ntheir validation, particularly the lack of hourly measured data and the variety\nof building samples. This study addresses this issue by applying bias\nadjustment techniques from survey research to improve UBEM validation\nrobustness with incomplete measured data. Error estimation tests are conducted\nusing various levels of missingness, and three bias adjustment methods are\nemployed: multivariate imputation, cell weighting and raking weighting. Key\nfindings indicate that using incomplete data in UBEM validation without\nadjustment is not advisable, while bias adjustment techniques significantly\nenhance the robustness of validation, providing more reliable model validity\nestimates. Cell weighting is preferable in this study due to its reliance on\njoint distributions of auxiliary variables.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-29T08:23:04Z"}
{"aid":"http://arxiv.org/abs/2504.20545v1","title":"WakeLoc: An Ultra-Low Power, Accurate and Scalable On-Demand RTLS using\n  Wake-Up Radios","summary":"For future large scale robotic moon missions, the availability of\ninfrastructure-less, cheap and low power real-time locating systems (RTLSs) is\ncritical. Traditional RTLS face significant trade-offs between power\nconsumption and localization latency, often requiring anchors to be connected\nto the power grid or sacrificing speed for energy efficiency. This paper\nproposes WakeLoc, an on-demand RTLS based on ultra-wideband (UWB), enabling\nboth low-latency and ultra-low power consumption by leveraging UWB wake-up\nradios (WuRs). In WakeLoc, tags independently start a localization procedure by\nsending a wake-up call (WuC) to anchors, before performing the actual\nlocalization. Distributed tags equipped with WuRs listen to the WuC and use\npassive listening of the UWB messages to determine their own position.\nExperimental measurements demonstrate that the localization accuracy in a 2D\nsetup achieves less than 12.9cm error, both for the active and the passive tag.\nAdditional power simulations based on real-world measurements were performed in\na realistic environment, showing that anchors can achieve a power consumption\nas low as 15.53{\\mu}W while the RTLS performs one on-demand localization per\nminute for 5 tags, thus operate up to 5.01 years on a single coin cell battery\n(690mWh).","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-29T08:42:41Z"}
{"aid":"http://arxiv.org/abs/2504.20597v1","title":"How to be an orthodox quantum mechanic","summary":"This work sets out to answer a single question: what is the orthodox\ninterpretation of quantum mechanics? However, we adopt a different approach to\nthat normally used. Rather than carefully surveying the precise details of the\nthoughts of Bohr and Heisenberg, we extract an orthodoxy empirically. To do\nthis we review a collection of 33 textbooks on quantum mechanics, encompassing\nthe most popular and prominent works of this nature. We then gauge their\nresponse to 12 propositions to build up a picture of exactly what is believed\nby an orthodox quantum mechanic. We demonstrate that this orthodoxy is largely\nunchanged over the past century, with some interesting emerging deviations, and\nhas many aspects of Copenhagen-like viewpoints. However, it is more nuanced\nthan some reductive characterisations that condense it down to the ontological\nprimacy of the quantum state. The revealed orthodoxy has two main pillars:\nmeasurement inherently disturbs quantum states and these states refer to\nindividual instances, not ensembles. More fully it entails that individual\nparticles exist in wave-like super-positions and present particle behaviours\nonly when forced to by outside influences. The act of measuring such a system\ninherently changes its state in a random fashion, manifesting in a form of\nmeasurement error that corresponds to the uncertainty principle. This implies\nthat measurement does not reveal underlying values of quantum properties.","main_category":"quant-ph","categories":"quant-ph,physics.hist-ph","published":"2025-04-29T09:50:54Z"}
{"aid":"http://arxiv.org/abs/2504.20600v1","title":"A citation index bridging Hirsch's h and Egghe's g","summary":"We propose a citation index $\\nu$ (``nu'') and show that it lies between the\nclassical $h$-index and $g$-index. This idea is then generalized to a monotone\nparametric family $(\\nu_\\alpha)$ ($\\alpha\\ge 0$), whereby $h=\\nu_0$ and\n$\\nu=\\nu_1$, while the limiting value $\\nu_\\infty$ is expressed in terms of the\nmaximum citation.","main_category":"cs.DL","categories":"cs.DL","published":"2025-04-29T10:01:38Z"}
{"aid":"http://arxiv.org/abs/2504.20628v1","title":"Cognitive maps are generative programs","summary":"Making sense of the world and acting in it relies on building simplified\nmental representations that abstract away aspects of reality. This principle of\ncognitive mapping is universal to agents with limited resources. Living\norganisms, people, and algorithms all face the problem of forming functional\nrepresentations of their world under various computing constraints. In this\nwork, we explore the hypothesis that human resource-efficient planning may\narise from representing the world as predictably structured. Building on the\nmetaphor of concepts as programs, we propose that cognitive maps can take the\nform of generative programs that exploit predictability and redundancy, in\ncontrast to directly encoding spatial layouts. We use a behavioral experiment\nto show that people who navigate in structured spaces rely on modular planning\nstrategies that align with programmatic map representations. We describe a\ncomputational model that predicts human behavior in a variety of structured\nscenarios. This model infers a small distribution over possible programmatic\ncognitive maps conditioned on human prior knowledge of the world, and uses this\ndistribution to generate resource-efficient plans. Our models leverages a Large\nLanguage Model as an embedding of human priors, implicitly learned through\ntraining on a vast corpus of human data. Our model demonstrates improved\ncomputational efficiency, requires drastically less memory, and outperforms\nunstructured planning algorithms with cognitive constraints at predicting human\nbehavior, suggesting that human planning strategies rely on programmatic\ncognitive maps.","main_category":"cs.AI","categories":"cs.AI,cs.ET","published":"2025-04-29T10:55:40Z"}
{"aid":"http://arxiv.org/abs/2504.20635v1","title":"Bridging the Generalisation Gap: Synthetic Data Generation for\n  Multi-Site Clinical Model Validation","summary":"Ensuring the generalisability of clinical machine learning (ML) models across\ndiverse healthcare settings remains a significant challenge due to variability\nin patient demographics, disease prevalence, and institutional practices.\nExisting model evaluation approaches often rely on real-world datasets, which\nare limited in availability, embed confounding biases, and lack the flexibility\nneeded for systematic experimentation. Furthermore, while generative models aim\nfor statistical realism, they often lack transparency and explicit control over\nfactors driving distributional shifts. In this work, we propose a novel\nstructured synthetic data framework designed for the controlled benchmarking of\nmodel robustness, fairness, and generalisability. Unlike approaches focused\nsolely on mimicking observed data, our framework provides explicit control over\nthe data generating process, including site-specific prevalence variations,\nhierarchical subgroup effects, and structured feature interactions. This\nenables targeted investigation into how models respond to specific\ndistributional shifts and potential biases. Through controlled experiments, we\ndemonstrate the framework's ability to isolate the impact of site variations,\nsupport fairness-aware audits, and reveal generalisation failures, particularly\nhighlighting how model complexity interacts with site-specific effects. This\nwork contributes a reproducible, interpretable, and configurable tool designed\nto advance the reliable deployment of ML in clinical settings.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-29T11:04:28Z"}
{"aid":"http://arxiv.org/abs/2504.20649v1","title":"Short-time quantum Fourier transform processing","summary":"Algorithms for processing data in short-time batches are critical for both\nonline and offline processing of streamed and large data respectively due to\nthe quadratic relation between signal length and computational cost of\nconvolution-based processing schemes. Whilst quantum analogs to some digital\nsignal processing algorithms have been discovered, including the quantum\nFourier transform (QFT), there has been no development of short-time processing\ntechniques in the quantum domain. In this manuscript, we introduce the\nshort-time QFT (STQFT) processing technique to bridge this gap in research. We\ndevelop a novel overlap-add reconstruction technique in the quantum domain\nusing a permutation gate to combine subsequent windows. With this in mind, we\ndiscuss convolution under our novel STQFT processing scheme. We demonstrate\nfiltering in the quantum Fourier domain with a filter stored in a quantum\nregister as well as in a block encoded unitary gate. Throughout the paper, we\nelaborate upon implementation details such as applying DC offsets to input\nsignals, skipping input data frames whenever necessary, the use of overlap-save\nas a reconstruction technique and mitigating time-varying scaling due to\nnormalization of the windowed input data and filters.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-29T11:19:51Z"}
{"aid":"http://arxiv.org/abs/2504.20666v1","title":"SFi-Former: Sparse Flow Induced Attention for Graph Transformer","summary":"Graph Transformers (GTs) have demonstrated superior performance compared to\ntraditional message-passing graph neural networks in many studies, especially\nin processing graph data with long-range dependencies. However, GTs tend to\nsuffer from weak inductive bias, overfitting and over-globalizing problems due\nto the dense attention. In this paper, we introduce SFi-attention, a novel\nattention mechanism designed to learn sparse pattern by minimizing an energy\nfunction based on network flows with l1-norm regularization, to relieve those\nissues caused by dense attention. Furthermore, SFi-Former is accordingly\ndevised which can leverage the sparse attention pattern of SFi-attention to\ngenerate sparse network flows beyond adjacency matrix of graph data.\nSpecifically, SFi-Former aggregates features selectively from other nodes\nthrough flexible adaptation of the sparse attention, leading to a more robust\nmodel. We validate our SFi-Former on various graph datasets, especially those\ngraph data exhibiting long-range dependencies. Experimental results show that\nour SFi-Former obtains competitive performance on GNN Benchmark datasets and\nSOTA performance on LongRange Graph Benchmark (LRGB) datasets. Additionally,\nour model gives rise to smaller generalization gaps, which indicates that it is\nless prone to over-fitting. Click here for codes.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-29T11:45:24Z"}
{"aid":"http://arxiv.org/abs/2504.20673v1","title":"CoCo-Bench: A Comprehensive Code Benchmark For Multi-task Large Language\n  Model Evaluation","summary":"Large language models (LLMs) play a crucial role in software engineering,\nexcelling in tasks like code generation and maintenance. However, existing\nbenchmarks are often narrow in scope, focusing on a specific task and lack a\ncomprehensive evaluation framework that reflects real-world applications. To\naddress these gaps, we introduce CoCo-Bench (Comprehensive Code Benchmark),\ndesigned to evaluate LLMs across four critical dimensions: code understanding,\ncode generation, code modification, and code review. These dimensions capture\nessential developer needs, ensuring a more systematic and representative\nevaluation. CoCo-Bench includes multiple programming languages and varying task\ndifficulties, with rigorous manual review to ensure data quality and accuracy.\nEmpirical results show that CoCo-Bench aligns with existing benchmarks while\nuncovering significant variations in model performance, effectively\nhighlighting strengths and weaknesses. By offering a holistic and objective\nevaluation, CoCo-Bench provides valuable insights to guide future research and\ntechnological advancements in code-oriented LLMs, establishing a reliable\nbenchmark for the field.","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-29T11:57:23Z"}
{"aid":"http://arxiv.org/abs/2504.20707v1","title":"Cavity Field-Driven Symmetry Breaking and Modulation of Vibrational\n  Properties: Insights from the Analytical QED-HF Hessian","summary":"In this work, we present the analytical derivation and implementation of the\nquantum electrodynamics Hartree-Fock Hessian. We investigate how electronic\nstrong coupling influences molecular vibrational properties, applying this\nframework to formaldehyde, p-nitroaniline, and adamantane. Our analysis reveals\ncavity-induced changes in vibrational frequencies and intensities.\nAdditionally, we show how the quantum electromagnetic field breaks molecular\nsymmetry, activating previously forbidden infrared transitions. Our findings\nhighlight the potential of strong coupling as a method for controlling and\nmodulating molecular vibrational properties.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-29T12:38:21Z"}
{"aid":"http://arxiv.org/abs/2504.20771v1","title":"Turing Machine Evaluation for Large Language Model","summary":"With the rapid development and widespread application of Large Language\nModels (LLMs), rigorous evaluation has become particularly crucial. This\nresearch adopts a novel perspective, focusing on evaluating the core\ncomputational reasoning ability of LLMs, defined as the capacity of model to\naccurately understand rules, and execute logically computing operations. This\ncapability assesses the reliability of LLMs as precise executors, and is\ncritical to advanced tasks such as complex code generation and multi-step\nproblem-solving. We propose an evaluation framework based on Universal Turing\nMachine (UTM) simulation. This framework requires LLMs to strictly follow\ninstructions and track dynamic states, such as tape content and read/write head\nposition, during multi-step computations. To enable standardized evaluation, we\ndeveloped TMBench, a benchmark for systematically studying the computational\nreasoning capabilities of LLMs. TMBench provides several key advantages,\nincluding knowledge-agnostic evaluation, adjustable difficulty, foundational\ncoverage through Turing machine encoding, and unlimited capacity for instance\ngeneration, ensuring scalability as models continue to evolve. We find that\nmodel performance on TMBench correlates strongly with performance on other\nrecognized reasoning benchmarks (Pearson correlation coefficient is 0.73),\nclearly demonstrating that computational reasoning is a significant dimension\nfor measuring the deep capabilities of LLMs. Code and data are available at\nhttps://github.com/HaitaoWuTJU/Turing-Machine-Bench.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-29T13:52:47Z"}
{"aid":"http://arxiv.org/abs/2504.20792v1","title":"RecGaze: The First Eye Tracking and User Interaction Dataset for\n  Carousel Interfaces","summary":"Carousel interfaces are widely used in e-commerce and streaming services, but\nlittle research has been devoted to them. Previous studies of interfaces for\npresenting search and recommendation results have focused on single ranked\nlists, but it appears their results cannot be extrapolated to carousels due to\nthe added complexity. Eye tracking is a highly informative approach to\nunderstanding how users click, yet there are no eye tracking studies concerning\ncarousels. There are very few interaction datasets on recommenders with\ncarousel interfaces and none that contain gaze data.\n  We introduce the RecGaze dataset: the first comprehensive feedback dataset on\ncarousels that includes eye tracking results, clicks, cursor movements, and\nselection explanations. The dataset comprises of interactions from 3 movie\nselection tasks with 40 different carousel interfaces per user. In total, 87\nusers and 3,477 interactions are logged. In addition to the dataset, its\ndescription and possible use cases, we provide results of a survey on carousel\ndesign and the first analysis of gaze data on carousels, which reveals a golden\ntriangle or F-pattern browsing behavior.\n  Our work seeks to advance the field of carousel interfaces by providing the\nfirst dataset with eye tracking results on carousels. In this manner, we\nprovide and encourage an empirical understanding of interactions with carousel\ninterfaces, for building better recommender systems through gaze information,\nand also encourage the development of gaze-based recommenders.","main_category":"cs.IR","categories":"cs.IR,cs.HC","published":"2025-04-29T14:09:20Z"}
{"aid":"http://arxiv.org/abs/2504.20811v1","title":"A Quantum Range-Doppler Algorithm for Synthetic Aperture Radar Image\n  Formation","summary":"Synthetic aperture radar (SAR) is a well established technology in the field\nof Earth remote sensing. Over the years, the resolution of SAR images has been\nsteadily improving and the pixel count increasing as a result of advances in\nthe sensor technology, and so have the computational resources required to\nprocess the raw data to a focused image. Because they are a necessary step in\nthe study of the retrieved data, new high-resolution and low-complexity\nfocusing algorithms are constantly explored in the SAR literature. The theory\nof quantum computing proposes a new computational framework that might allow to\nprocess a vast amount of data in a more efficient way. Relevant to our case is\nthe advantage proven for the quantum Fourier transform (QFT), the quantum\ncounterpart of a fundamental element of many SAR focusing algorithms. Motivated\nby this, in this work we propose a quantum version of the range-Doppler\nalgorithm. We show how in general reference functions, a key element in many\nSAR focusing algorithms, can be mapped to quantum gates; we present the quantum\ncircuit performing the SAR raw data focusing and we discuss in detail its\ncomputational complexity. We find that the core of the quantum range-Doppler\nalgorithm has a computational complexity, namely the number of single- and\ntwo-qubit gates, of $O(N)$, less than its classical counterpart with\ncomputational complexity $O(N \\log N)$.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-29T14:24:23Z"}
{"aid":"http://arxiv.org/abs/2504.20836v1","title":"Non-Linear Modeling and Analysis of Amplifier-Less Potentiostat\n  Architectures","summary":"In this article, a previously published amplifier-less potentiostat\narchitecture is further examined. Starting with a linearized model, the impact\nof the most important parameters is studied taking in account the\nelectrodes-solution electrochemical interface. A detailed model is obtained and\nthoroughly verified, and recommended operating conditions are given for certain\nlimit load conditions. Then, a more complete non-linear model is developed to\ntake in account the measurement uncertainty introduced by the circuit\nnon-linear components. This non-linear model is compared to a time domain\ndescription of the circuit and it is verified that it can predict the\nnon-linear behavior with a precision better than 20%. This result enables the\ncircuit designers to compensate for these effects and ultimately reduce the\noverall measurement uncertainty.","main_category":"eess.SY","categories":"eess.SY,cs.SY,94-06","published":"2025-04-29T14:59:50Z"}
{"aid":"http://arxiv.org/abs/2504.20840v1","title":"Thermal Resilience of Suspended Thin-Film Lithium Niobate Acoustic\n  Resonators up to 550 ¬∞C","summary":"This paper reports a suspended thin-film lithium niobate (LN) piezoelectric\nresonator platform surviving high annealing temperatures of 550 {\\deg}C, among\nthe highest temperature at which the thermal resilience of suspended LN\nresonators is studied. Acoustic resonators are built on 600 nm thick\ntransferred stoichiometric LN on silicon wafers with 40 nm thick platinum (Pt)\nelectrodes, selected for high temperature operation. The fabricated resonators\nare first annealed at 250 {\\deg}C, and the anneal temperature is incrementally\nincreased to 550 {\\deg}C after 7 rounds of annealing. The annealing is shown to\nupshift resonant frequencies and can increase the quality factor (Q), within a\ntemperature range, before it gradually damages the device performance. This\nwork presents promising results for using the suspended thin-film LN platform\nfor resonators, sensors, and transducers in harsh thermal environments.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-29T15:05:21Z"}
{"aid":"http://arxiv.org/abs/2504.20864v1","title":"($0,6$) AdS$_3$/CFT$_2$ and surface defects","summary":"We explore a new class of AdS$_3$ solutions in massive type IIA supergravity\npreserving $\\mathcal{N} = (0,6)$ supersymmetry and realising an\n$\\mathfrak{osp}(6|2)$ superconformal algebra. These solutions exhibit an\nSO(6)-symmetric internal space constructed from a $\\mathbb{CP}^3$, and are\nfully specified by a single cubic function controlling the fluxes and warping.\nWe propose a brane box configuration underlying the solutions from which we\nconstruct a two-dimensional quiver gauge theory whose anomaly structure and\ncentral charge we analyse, and from which we can realise Seiberg-like dualities\nas large gauge transformations. The brane box configuration suggests an\ninterpretation of the solutions as dual to surface defects within the ABJ(M)\ntheory. Our findings provide a concrete setting for exploring holography beyond\nthe ABJM vacuum. Remarkably, no explicit field theories are currently known to\nrealise $\\mathcal{N} = (0,6)$ supersymmetry in two dimensions, making our setup\na promising and largely unexplored direction for field-theoretic\ninvestigations.","main_category":"hep-th","categories":"hep-th","published":"2025-04-29T15:39:27Z"}
{"aid":"http://arxiv.org/abs/2504.20886v1","title":"Mapping a Movement: Exploring a Proposed Police Training Facility in\n  Atlanta and the Stop Cop City Movement through Online Maps","summary":"In 2021, the City of Atlanta and Atlanta Police Foundation launched plans to\nbuild a large police training facility in the South River Forest in\nunincorporated DeKalb County, GA. Residents of Atlanta and DeKalb County,\nenvironmental activists, police and prison abolitionists, and other activists\nand concerned individuals formed the movement in opposition to the facility,\nknown as the Stop Cop City / Defend the Atlanta Forest movement. Social media\nand digital maps became common tools for communicating information about the\nfacility and the movement. Here, we examine online maps about the facility and\nthe opposition movement, originating from grassroots organizations, the City of\nAtlanta, news media outlets, the Atlanta Police Foundation, and individuals. We\ngather and examine 32 publicly available maps collected through the Google\nSearch API, Twitter (now X), Instagram and reddit. Using a framework of\ncritical cartography, we conduct a content analysis of these maps to identify\nthe mapping technologies and techniques (data, cartographic elements, styles)\nused by different stakeholders and roles that maps and mapping technologies can\nplay in social movements. We examine the extent to which these maps provide\ndata to confirm or contradict concerns raised by grassroots organizations and\nlocal residents about the facility. We find that stakeholders and mapmakers use\ngeospatial tools in different ways and likely have varied access to mapping\ntechnologies. We argue that documenting the use of maps to communicate\ninformation about a contentious project can help enumerate community positions\nand perspectives, and we advocate for accessible mapmaking tools. We conclude\nby discussing the implications of accessibility of mapping technology and\nposting maps to social media, and share example map images that extend the\ngeographic information systems (GIS) techniques seen in the retrieved maps.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-29T16:01:51Z"}
{"aid":"http://arxiv.org/abs/2504.20888v1","title":"New Capacity Bounds for PIR on Graph and Multigraph-Based Replicated\n  Storage","summary":"In this paper, we study the problem of private information retrieval (PIR) in\nboth graph-based and multigraph-based replication systems, where each file is\nstored on exactly two servers, and any pair of servers shares at most $r$\nfiles. We derive upper bounds on the PIR capacity for such systems and\nconstruct PIR schemes that approach these bounds. For graph-based systems, we\ndetermine the exact PIR capacity for path graphs and improve upon existing\nresults for complete bipartite graphs and complete graphs. For multigraph-based\nsystems, we propose a PIR scheme that leverages the symmetry of the underlying\ngraph-based construction, yielding a capacity lower bound for such multigraphs.\nFurthermore, we establish several general upper and lower bounds on the PIR\ncapacity of multigraphs, which are tight in certain cases.","main_category":"cs.IT","categories":"cs.IT,cs.CR,math.CO,math.IT,H.3.3","published":"2025-04-29T16:05:42Z"}
{"aid":"http://arxiv.org/abs/2504.20892v1","title":"Imaging on the Edge: Mapping Object Corners and Edges with Stereo X-ray\n  Tomography","summary":"X-ray computed tomography is a powerful tool for volumetric imaging, where\nthree-dimensional (3D) images are generated from a large number of individual\nX-ray projection images. Collecting the required number of low noise projection\nimages is however time-consuming and so the technique is not currently\napplicable when spatial information needs to be collected with high temporal\nresolution, such as in the study of dynamic processes. In our previous work,\ninspired by stereo vision, we developed stereo X-ray imaging methods that\noperate with only two X-ray projection images. Previously we have shown how\nthis allowed us to map point and line fiducial markers into 3D space at\nsignificantly faster temporal resolutions. In this paper, we make two further\ncontributions. Firstly, instead of utilising internal fiducial markers, we\ndemonstrate the applicability of the method to the 3D mapping of sharp object\ncorners, a problem of interest in measuring the deformation of manufactured\ncomponents under different loads. Furthermore, we demonstrate how the approach\ncan be applied to real stereo X-ray data, even in settings where we do not have\nthe annotated real training data that was required for the training of our\nprevious Machine Learning approach. This is achieved by substituting the real\ndata with a relatively simple synthetic training dataset designed to mimic key\naspects of the real data.","main_category":"eess.IV","categories":"eess.IV","published":"2025-04-29T16:08:00Z"}
{"aid":"http://arxiv.org/abs/2504.20912v1","title":"On the Secrecy-Sensing Optimization of RIS-assisted Full-Duplex\n  Integrated Sensing and Communication Network","summary":"Integrated sensing and communication (ISAC) has recently emerged as a viable\ntechnique for establishing sensing and communication using the same resources.\nNonetheless, the operation of ISAC networks is often challenged by the absence\nof a direct link between the sensing node and the targets, and by the risk of\ndisclosing confidential data to malicious targets when using the same signal\nfor both tasks. In this paper, a robust reconfigurable intelligent surface\n(RIS)-aided scheme for securing a full-duplex (FD) ISAC network is proposed.\nThe considered network consists of uplink and downlink users served in FD\nthrough a multi-antenna dual-functional radar communication base station (BS),\nwhich employs co-located multi-antenna communication-radar arrays to detect\nmultiple malicious targets while preserving communication secrecy in their\npresence. Additionally, the BS utilizes an optimized artificial noise (AN) that\nserves to disrupt the malicious targets' reception and increase the sensing\npower. By optimally designing the RIS phase shifts, transmit beamforming, AN\ncovariance, and uplink users' transmit power and combining vectors using an\nalternating optimization-based algorithm, the network's sensing performance is\nmaximized under secrecy and total power constraints. Numerical results present\nthe proposed scheme's efficacy, particularly when a direct link between the BS\nand the various nodes/targets is absent.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-29T16:32:22Z"}
{"aid":"http://arxiv.org/abs/2504.20969v1","title":"XPG-RL: Reinforcement Learning with Explainable Priority Guidance for\n  Efficiency-Boosted Mechanical Search","summary":"Mechanical search (MS) in cluttered environments remains a significant\nchallenge for autonomous manipulators, requiring long-horizon planning and\nrobust state estimation under occlusions and partial observability. In this\nwork, we introduce XPG-RL, a reinforcement learning framework that enables\nagents to efficiently perform MS tasks through explainable, priority-guided\ndecision-making based on raw sensory inputs. XPG-RL integrates a task-driven\naction prioritization mechanism with a learned context-aware switching strategy\nthat dynamically selects from a discrete set of action primitives such as\ntarget grasping, occlusion removal, and viewpoint adjustment. Within this\nstrategy, a policy is optimized to output adaptive threshold values that govern\nthe discrete selection among action primitives. The perception module fuses\nRGB-D inputs with semantic and geometric features to produce a structured scene\nrepresentation for downstream decision-making. Extensive experiments in both\nsimulation and real-world settings demonstrate that XPG-RL consistently\noutperforms baseline methods in task success rates and motion efficiency,\nachieving up to 4.5$\\times$ higher efficiency in long-horizon tasks. These\nresults underscore the benefits of integrating domain knowledge with learnable\ndecision-making policies for robust and efficient robotic manipulation.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-29T17:37:45Z"}
{"aid":"http://arxiv.org/abs/2504.20989v1","title":"Photonic Quantum Convolutional Neural Networks with Adaptive State\n  Injection","summary":"Linear optical architectures have been extensively investigated for quantum\ncomputing and quantum machine learning applications. Recently, proposals for\nphotonic quantum machine learning have combined linear optics with resource\nadaptivity, such as adaptive circuit reconfiguration, which promises to enhance\nexpressivity and improve algorithm performances and scalability. Moreover,\nlinear optical platforms preserve some subspaces due to the fixed number of\nparticles during the computation, a property recently exploited to design a\nnovel quantum convolutional neural networks. This last architecture has shown\nan advantage in terms of running time complexity and of the number of\nparameters needed with respect to other quantum neural network proposals. In\nthis work, we design and experimentally implement the first photonic quantum\nconvolutional neural network (PQCNN) architecture based on particle-number\npreserving circuits equipped with state injection, an approach recently\nproposed to increase the controllability of linear optical circuits.\nSubsequently, we experimentally validate the PQCNN for a binary image\nclassification on a photonic platform utilizing a semiconductor quantum\ndot-based single-photon source and programmable integrated photonic\ninterferometers comprising 8 and 12 modes. In order to investigate the\nscalability of the PQCNN design, we have performed numerical simulations on\ndatasets of different sizes. We highlight the potential utility of a simple\nadaptive technique for a nonlinear Boson Sampling task, compatible with\nnear-term quantum devices.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-29T17:57:01Z"}
{"aid":"http://arxiv.org/abs/2504.21269v1","title":"Observation of the decay $B^0_{s}\\to K^0 p \\bar{p}$ and measurement of\n  the $B^0_{(s)} \\to K^0 p \\bar{p}$ branching fractions","summary":"A study of the charmless baryonic decays $B^0_{(s)} \\to K^0 p \\bar{p}$ is\npresented, where $B^0_{(s)}$ denotes either a $B^0$ or a $B^0_s$ meson. The\nanalysis is based on proton-proton collision data collected by the LHCb\nexperiment at centre-of-mass energies of 7, 8, and $13~\\mathrm{Tev}$,\ncorresponding to an integrated luminosity of $9~\\mathrm{fb}^{-1}$. The decay\n$B^0_s \\to K^0 p \\bar{p}$ is observed for the first time, with a measured\nbranching fraction of $(9.14 \\pm 1.69 \\pm 0.90 \\pm 0.33 \\pm 0.20) \\times\n10^{-7}$ and a significance of $5.6\\sigma$. The uncertainties respectively\naccount for statistical and systematic contributions, the precision of the\nbranching fraction of the normalisation channel $B^0 \\to K^0 \\pi^{+} \\pi^{-}$\nand the fragmentation fraction ratio ${f_s}/{f_d}$. The branching fraction\ndetermined for $B^0 \\to K^0 p \\bar{p}$ is $(2.82 \\pm 0.08 \\pm 0.12 \\pm 0.10)\n\\times 10^{-6}$, which is the most precise measurement to date.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-30T02:53:23Z"}
{"aid":"http://arxiv.org/abs/2504.21305v1","title":"Virtual Element Method Applied to Two Dimensional Axisymmetric Elastic\n  Problems","summary":"This work presents a Virtual Element Method (VEM) formulation tailored for\ntwo-dimensional axisymmetric problems in linear elasticity. By exploiting the\nrotational symmetry of the geometry and loading conditions, the problem is\nreduced to a meridional cross-section, where all fields depend only on the\nradial and axial coordinates. The method incorporates the radial weight $r$ in\nboth the weak formulation and the interpolation estimates to remain consistent\nwith the physical volume measure of cylindrical coordinates. A projection\noperator onto constant strain fields is constructed via boundary integrals, and\na volumetric correction term is introduced to account for the divergence of the\nstress field arising from axisymmetry. The stabilization term is designed to\nact only on the kernel of the projection and is implemented using a\nboundary-based formulation that guarantees stability without affecting\npolynomial consistency. Furthermore, an a priori interpolation error estimate\nis established in a weighted Sobolev space, showing optimal convergence rates.\nThe implementation is validated through patch tests that demonstrate the\naccuracy, consistency, and robustness of the proposed approach.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-30T04:26:50Z"}
{"aid":"http://arxiv.org/abs/2504.21317v1","title":"Redundancy Analysis and Mitigation for Machine Learning-Based Process\n  Monitoring of Additive Manufacturing","summary":"The deployment of machine learning (ML)-based process monitoring systems has\nsignificantly advanced additive manufacturing (AM) by enabling real-time defect\ndetection, quality assessment, and process optimization. However, redundancy is\na critical yet often overlooked challenge in the deployment and operation of\nML-based AM process monitoring systems. Excessive redundancy leads to increased\nequipment costs, compromised model performance, and high computational\nrequirements, posing barriers to industrial adoption. However, existing\nresearch lacks a unified definition of redundancy and a systematic framework\nfor its evaluation and mitigation. This paper defines redundancy in ML-based AM\nprocess monitoring and categorizes it into sample-level, feature-level, and\nmodel-level redundancy. A comprehensive multi-level redundancy mitigation\n(MLRM) framework is proposed, incorporating advanced methods such as data\nregistration, downscaling, cross-modality knowledge transfer, and model pruning\nto systematically reduce redundancy while improving model performance. The\nframework is validated through an ML-based in-situ defect detection case study\nfor directed energy deposition (DED), demonstrating a 91% reduction in latency,\na 47% decrease in error rate, and a 99.4% reduction in storage requirements.\nAdditionally, the proposed approach lowers sensor costs and energy consumption,\nenabling a lightweight, cost-effective, and scalable monitoring system. By\ndefining redundancy and introducing a structured mitigation framework, this\nstudy establishes redundancy analysis and mitigation as a key enabler of\nefficient ML-based process monitoring in production environments.","main_category":"cs.CE","categories":"cs.CE,cs.LG,eess.SP","published":"2025-04-30T05:04:53Z"}
{"aid":"http://arxiv.org/abs/2504.21336v1","title":"UniBiomed: A Universal Foundation Model for Grounded Biomedical Image\n  Interpretation","summary":"Multi-modal interpretation of biomedical images opens up novel opportunities\nin biomedical image analysis. Conventional AI approaches typically rely on\ndisjointed training, i.e., Large Language Models (LLMs) for clinical text\ngeneration and segmentation models for target extraction, which results in\ninflexible real-world deployment and a failure to leverage holistic biomedical\ninformation. To this end, we introduce UniBiomed, the first universal\nfoundation model for grounded biomedical image interpretation. UniBiomed is\nbased on a novel integration of Multi-modal Large Language Model (MLLM) and\nSegment Anything Model (SAM), which effectively unifies the generation of\nclinical texts and the segmentation of corresponding biomedical objects for\ngrounded interpretation. In this way, UniBiomed is capable of tackling a wide\nrange of biomedical tasks across ten diverse biomedical imaging modalities. To\ndevelop UniBiomed, we curate a large-scale dataset comprising over 27 million\ntriplets of images, annotations, and text descriptions across ten imaging\nmodalities. Extensive validation on 84 internal and external datasets\ndemonstrated that UniBiomed achieves state-of-the-art performance in\nsegmentation, disease recognition, region-aware diagnosis, visual question\nanswering, and report generation. Moreover, unlike previous models that rely on\nclinical experts to pre-diagnose images and manually craft precise textual or\nvisual prompts, UniBiomed can provide automated and end-to-end grounded\ninterpretation for biomedical image analysis. This represents a novel paradigm\nshift in clinical workflows, which will significantly improve diagnostic\nefficiency. In summary, UniBiomed represents a novel breakthrough in biomedical\nAI, unlocking powerful grounded interpretation capabilities for more accurate\nand efficient biomedical image analysis.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T05:51:48Z"}
{"aid":"http://arxiv.org/abs/2504.21342v1","title":"Low latency FPGA implementation of twisted Edward curve cryptography\n  hardware accelerator over prime field","summary":"The performance of any elliptic curve cryptography hardware accelerator\nsignificantly relies on the efficiency of the underlying point multiplication\n(PM) architecture. This article presents a hardware implementation of\nfield-programmable gate array (FPGA) based modular arithmetic, group operation,\nand point multiplication unit on the twisted Edwards curve (Edwards25519) over\nthe 256-bit prime field. An original hardware architecture of a unified point\noperation module in projective coordinates that executes point addition and\npoint doubling within a single module has been developed, taking only 646 clock\ncycles and ensuring a better security level than conventional approaches. The\nproposed point multiplication module consumes 1.4 ms time, operating at a\nmaximal clock frequency of 117.8 MHz utilising 164,730 clock cycles having\n183.38 kbps throughput on the Xilinx Virtex-5 FPGA platform for 256-bit length\nof key. The comparative assessment of latency and throughput across various\nrelated recent works indicates the effectiveness of our proposed PM\narchitecture. Finally, this high throughput and low latency PM architecture\nwill be a good candidate for rapid data encryption in high-speed wireless\ncommunication networks.","main_category":"cs.CR","categories":"cs.CR,cs.NI","published":"2025-04-30T06:03:36Z"}
{"aid":"http://arxiv.org/abs/2504.21363v1","title":"The differential structure shared by probability and moment matching\n  priors on non-regular statistical models via the Lie derivative","summary":"In Bayesian statistics, the selection of noninformative priors is a crucial\nissue. There have been various discussions on theoretical justification,\nproblems with the Jeffreys prior, and alternative objective priors. Among them,\nwe focus on two types of matching priors consistent with frequentist theory:\nthe probability matching priors and the moment matching priors. In particular,\nno clear relationship has been established between these two types of priors on\nnon-regular statistical models, even though they share similar objectives.\n  Considering information geometry on a one-sided truncated exponential family,\na typical example of non-regular statistical models, we find that the Lie\nderivative along a particular vector field provides the conditions for both the\nprobability and moment matching priors. Notably, this Lie derivative does not\nappear in regular models. These conditions require the invariance of a\ngeneralized volume element with respect to differentiation along the\nnon-regular parameter. This invariance leads to a suitable decomposition of the\none-sided truncated exponential family into one-dimensional submodels. This\nresult promotes a unified understanding of probability and moment matching\npriors on non-regular models.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-30T06:51:13Z"}
{"aid":"http://arxiv.org/abs/2504.21398v1","title":"In a Few Words: Comparing Weak Supervision and LLMs for Short Query\n  Intent Classification","summary":"User intent classification is an important task in information retrieval.\nPreviously, user intents were classified manually and automatically; the latter\nhelped to avoid hand labelling of large datasets. Recent studies explored\nwhether LLMs can reliably determine user intent. However, researchers have\nrecognized the limitations of using generative LLMs for classification tasks.\nIn this study, we empirically compare user intent classification into\ninformational, navigational, and transactional categories, using weak\nsupervision and LLMs. Specifically, we evaluate LLaMA-3.1-8B-Instruct and\nLLaMA-3.1-70B-Instruct for in-context learning and LLaMA-3.1-8B-Instruct for\nfine-tuning, comparing their performance to an established baseline classifier\ntrained using weak supervision (ORCAS-I). Our results indicate that while LLMs\noutperform weak supervision in recall, they continue to struggle with\nprecision, which shows the need for improved methods to balance both metrics\neffectively.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-30T07:54:04Z"}
{"aid":"http://arxiv.org/abs/2504.21468v1","title":"Quaternion Nuclear Norms Over Frobenius Norms Minimization for Robust\n  Matrix Completion","summary":"Recovering hidden structures from incomplete or noisy data remains a\npervasive challenge across many fields, particularly where multi-dimensional\ndata representation is essential. Quaternion matrices, with their ability to\nnaturally model multi-dimensional data, offer a promising framework for this\nproblem. This paper introduces the quaternion nuclear norm over the Frobenius\nnorm (QNOF) as a novel nonconvex approximation for the rank of quaternion\nmatrices. QNOF is parameter-free and scale-invariant. Utilizing quaternion\nsingular value decomposition, we prove that solving the QNOF can be simplified\nto solving the singular value $L_1/L_2$ problem. Additionally, we extend the\nQNOF to robust quaternion matrix completion, employing the alternating\ndirection multiplier method to derive solutions that guarantee weak convergence\nunder mild conditions. Extensive numerical experiments validate the proposed\nmodel's superiority, consistently outperforming state-of-the-art quaternion\nmethods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T09:44:09Z"}
{"aid":"http://arxiv.org/abs/2504.21527v1","title":"Low-rank computation of the posterior mean in Multi-Output Gaussian\n  Processes","summary":"Gaussian processes (GP) are a versatile tool in machine learning and\ncomputational science. We here consider the case of multi-output Gaussian\nprocesses (MOGP) and present low-rank approaches for efficiently computing the\nposterior mean of a MOGP. Starting from low-rank spatio-temporal data we\nconsider a structured covariance function, assuming separability across space\nand time. This separability, in turn, gives a decomposition of the covariance\nmatrix into a Kronecker product of individual covariance matrices.\nIncorporating the typical noise term to the model then requires the solution of\na large-scale Stein equation for computing the posterior mean. For this, we\npropose efficient low-rank methods based on a combination of a LRPCG method\nwith the Sylvester equation solver KPIK adjusted for solving Stein equations.\nWe test the developed method on real world street network graphs by using graph\nfilters as covariance matrices. Moreover, we propose a degree-weighted average\ncovariance matrix, which can be employed under specific assumptions to achieve\nmore efficient convergence.","main_category":"math.NA","categories":"math.NA,cs.LG,cs.NA","published":"2025-04-30T11:19:58Z"}
{"aid":"http://arxiv.org/abs/2504.21537v1","title":"The role of dendritic spines in water exchange measurements with\n  diffusion MRI: Double Diffusion Encoding and free-waveform MRI","summary":"Time-dependent diffusion MRI enables the estimation of water exchange rates\nin vivo, yet reported values in grey matter remain inconsistent. While most\nstudies attribute these estimates to membrane permeability, non-permeative\ngeometric exchange has also been proposed. The present study investigates the\ncontribution of geometric exchange between dendritic spines and shafts to\ndiffusion MRI-derived exchange estimates. Monte Carlo simulations were\nperformed in synthetic dendrites with varying spine morphology, density, and\nmembrane permeability. Diffusion-weighted signals were generated using multiple\nprotocols - including single diffusion encoding, double diffusion encoding, and\nfree waveforms - and were analysed using four frameworks: the K\\\"arger model\n(via kurtosis time-dependence), correlation tensor imaging,\nRestriction-Exchange, and Multi-Gaussian Exchange with transient kurtosis\n(tMGE). Dendritic spines were found to impart similar time-dependence\nsignatures on the diffusion-weighted signal as permeative exchange (signal\ndecrease with diffusion time). The effect was modulated by both spine\nmorphology and density. Both the exchange rate and microscopic kurtosis\nincreased with spine density. The tMGE method demonstrated the ability to\ndisentangle geometric from permeative exchange. Non-permeative exchange in\ndendritic spines has a non-negligible impact on exchange estimates obtained\nwith diffusion MRI and should be considered in future studies. Diffusion MRI\nexchange estimates may provide a non-invasive proxy for dendritic spine\ndensity, with potential applications in studies of neurological disorders.","main_category":"physics.med-ph","categories":"physics.med-ph","published":"2025-04-30T11:34:44Z"}
{"aid":"http://arxiv.org/abs/2504.21557v1","title":"Optimizing carrier balance in CsPbBr3 nanocrystal LEDs: The role of\n  alkyl ligands and polar electron transport layers","summary":"The study of lead halide perovskite nanocrystal based light-emitting diodes\n(LEDs) has advanced significantly, with notable improvements in stability and\noptical properties. However, optimizing charge carrier injection and transport\nremains a challenge. Efficient electroluminescence requires a balanced\ntransport of both holes and electrons within the emitting material. Here, we\ninvestigate cubic CsPbBr\\textsubscript{3} nanocrystals passivated with\noleylamine and oleic acid, comparing them to ligand-exchanged nanocrystals with\ndidodecyldimethylammonium bromide (DDABr). Nuclear magnetic resonance\nspectroscopy and transmission electron microscopy confirm successful ligand\nexchange, revealing reduced ligand coverage in DDABr-treated nanocrystals.\nPhotoelectron spectroscopy, spectroelectrochemistry, and single-carrier devices\nindicate improved hole injection in DDABr-capped nanocrystals. Density\nfunctional theory calculations further reveal the influence of ligand type and\ncoverage on energy levels, with oleic acid introducing localized states in\nnative nanocrystals. Additionally, incorporation of a polar electron transport\nlayer (ETL) enhances LED performance by over an order of magnitude in\nDDABr-capped nanocrystals, driven by improved charge balance arising from the\nspontaneous orientation polarization (SOP) of the ETL. These findings highlight\nthe critical role of ligand selection, passivation degree, and charge transport\ncontrol by the adjacent organic transport layers in optimizing LED efficiency.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-30T11:54:43Z"}
{"aid":"http://arxiv.org/abs/2504.21602v1","title":"Real Time Semantic Segmentation of High Resolution Automotive LiDAR\n  Scans","summary":"In recent studies, numerous previous works emphasize the importance of\nsemantic segmentation of LiDAR data as a critical component to the development\nof driver-assistance systems and autonomous vehicles. However, many\nstate-of-the-art methods are tested on outdated, lower-resolution LiDAR sensors\nand struggle with real-time constraints. This study introduces a novel semantic\nsegmentation framework tailored for modern high-resolution LiDAR sensors that\naddresses both accuracy and real-time processing demands. We propose a novel\nLiDAR dataset collected by a cutting-edge automotive 128 layer LiDAR in urban\ntraffic scenes. Furthermore, we propose a semantic segmentation method\nutilizing surface normals as strong input features. Our approach is bridging\nthe gap between cutting-edge research and practical automotive applications.\nAdditionaly, we provide a Robot Operating System (ROS2) implementation that we\noperate on our research vehicle. Our dataset and code are publicly available:\nhttps://github.com/kav-institute/SemanticLiDAR.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-30T13:00:50Z"}
{"aid":"http://arxiv.org/abs/2504.21624v1","title":"Multicut Problems in Almost-Planar Graphs: The Dependency of Complexity\n  on the Demand Pattern","summary":"Given a graph $G$, a set $T$ of terminal vertices, and a demand graph $H$ on\n$T$, the \\textsc{Multicut} problem asks for a set of edges of minimum weight\nthat separates the pairs of terminals specified by the edges of $H$.\n  The \\textsc{Multicut} problem can be solved in polynomial time if the number\nof terminals and the genus of the graph is bounded (Colin de Verdi\\`ere\n[Algorithmica, 2017]).\n  Focke et al.~[SoCG 2024] characterized which special cases of Multicut are\nfixed-parameter tractable parameterized by the number of terminals on planar\ngraphs. Moreover, they precisely determined how the parameter genus influences\nthe complexity and presented partial results of this form for graphs that can\nbe made planar by the deletion of $\\pi$ edges. We complete the picture on how\nthis parameter $\\pi$ influences the complexity of different special cases and\nprecisely determine the influence of the crossing number.\n  Formally, let $\\mathcal{H}$ be any class of graphs (satisfying a mild closure\nproperty) and let Multicut$(\\mathcal{H})$ be the special case when the demand\ngraph $H$ is in $\\mathcal{H}$. Our fist main results is showing that if\n$\\mathcal{H}$ has the combinatorial property of having bounded distance to\nextended bicliques, then Multicut$(\\mathcal{H})$ on unweighted graphs is FPT\nparameterized by the number $t$ of terminals and $\\pi$. For the case when\n$\\mathcal{H}$ does not have this combinatorial property,\n  Focke et al.~[SoCG 2024] showed that $O(\\sqrt{t})$ is essentially the best\npossible exponent of the running time; together with our result, this gives a\ncomplete understanding of how the parameter $\\pi$ influences complexity on\nunweighted graphs.\n  Our second main result is giving an algorithm whose existence shows that that\nthe parameter crossing number behaves analogously if we consider weighted\ngraphs.","main_category":"cs.CC","categories":"cs.CC","published":"2025-04-30T13:26:46Z"}
{"aid":"http://arxiv.org/abs/2504.21632v1","title":"Fast Sign Retrieval via Sub-band Convolution: An Elementary Extension of\n  Binary Classification","summary":"To efficiently compress the sign information of images, we address a sign\nretrieval problem for the block-wise discrete cosine transformation~(DCT):\nreconstruction of the signs of DCT coefficients from their amplitudes. To this\nend, we propose a fast sign retrieval method on the basis of binary\nclassification machine learning. We first introduce 3D representations of the\namplitudes and signs, where we pack amplitudes/signs belonging to the same\nfrequency band into a 2D slice, referred to as the sub-band block. We then\nretrieve the signs from the 3D amplitudes via binary classification, where each\nsign is regarded as a binary label. We implement a binary classification\nalgorithm using convolutional neural networks, which are advantageous for\nefficiently extracting features in the 3D amplitudes. Experimental results\ndemonstrate that our method achieves accurate sign retrieval with an\noverwhelmingly low computation cost.","main_category":"cs.IT","categories":"cs.IT,eess.IV,math.IT","published":"2025-04-30T13:34:06Z"}
{"aid":"http://arxiv.org/abs/2504.21642v1","title":"Element-wise description of the $\\mathcal I$-characterized subgroups of\n  the circle","summary":"According to Cartan, given an ideal $\\mathcal I$ of $\\mathbb N$, a sequence\n$(x_n)_{n\\in\\mathbb N}$ in the circle group $\\mathbb T$ is said to {\\em\n$\\mathcal I$-converge} to a point $x\\in \\mathbb T$ if $\\{n\\in \\mathbb N: x_n\n\\not \\in U\\}\\in \\mathcal I$ for every neighborhood $U$ of $x$ in $\\mathbb T$.\nFor a sequence $\\mathbf u=(u_n)_{n\\in\\mathbb N}$ in $\\mathbb Z$, let\n$$t_{\\mathbf u}^\\mathcal I(\\mathbb T) :=\\{x\\in \\mathbb T: u_nx \\\n\\text{$\\mathcal I$-converges to}\\ 0 \\}.$$ This set is a Borel (hence,\nPolishable) subgroup of $\\mathbb T$ with many nice properties, largely studied\nin the case when $\\mathcal I = \\mathcal F in$ is the ideal of all finite\nsubsets of $\\mathbb N$ (so $\\mathcal F in$-convergence coincides with the usual\none) for its remarkable connection to topological algebra, descriptive set\ntheory and harmonic analysis. We give a complete element-wise description of\n$t_{\\mathbf u}^\\mathcal I(\\mathbb T)$ when $u_n\\mid u_{n+1}$ for every\n$n\\in\\mathbb N$ and under suitable hypotheses on $\\mathcal I$. In the special\ncase when $\\mathcal I =\\mathcal F in$, we obtain an alternative proof of a\nsimplified version of a known result.","main_category":"math.GN","categories":"math.GN,math.GR","published":"2025-04-30T13:46:01Z"}
{"aid":"http://arxiv.org/abs/2504.21663v1","title":"Reducing Weighted Ensemble Variance With Optimal Trajectory Management","summary":"Weighted ensemble (WE) is an enhanced path-sampling method that is\nconceptually simple, widely applicable, and statistically exact. In a WE\nsimulation, an ensemble of trajectories is periodically pruned or replicated to\nenhance sampling of rare transitions and improve estimation of mean first\npassage times (MFPTs). However, poor choices of the parameters governing\npruning and replication can lead to high-variance MFPT estimates. Our previous\nwork [J. Chem. Phys. 158, 014108 (2023)] presented an optimal WE\nparameterization strategy and applied it in low-dimensional example systems.\nThe strategy harnesses estimated local MFPTs from different initial\nconfigurations to a single target state. In the present work, we apply the\noptimal parameterization strategy to more challenging, high-dimensional\nmolecular models, namely, synthetic molecular dynamics (MD) models of Trp-cage\nfolding and unfolding, as well as atomistic MD models of NTL9 folding in\nhigh-friction and low-friction continuum solvents. In each system we use WE to\nestimate the MFPT for folding or unfolding events. We show that the optimal\nparameterization reduces the variance of MFPT estimates in three of four\nsystems, with dramatic improvement in the most challenging atomistic system.\nOverall, the parameterization strategy improves the accuracy and reliability of\nWE estimates for the kinetics of biophysical processes.","main_category":"physics.chem-ph","categories":"physics.chem-ph,physics.comp-ph","published":"2025-04-30T14:03:58Z"}
{"aid":"http://arxiv.org/abs/2504.21680v1","title":"Hoist with His Own Petard: Inducing Guardrails to Facilitate\n  Denial-of-Service Attacks on Retrieval-Augmented Generation of LLMs","summary":"Retrieval-Augmented Generation (RAG) integrates Large Language Models (LLMs)\nwith external knowledge bases, improving output quality while introducing new\nsecurity risks. Existing studies on RAG vulnerabilities typically focus on\nexploiting the retrieval mechanism to inject erroneous knowledge or malicious\ntexts, inducing incorrect outputs. However, these approaches overlook critical\nweaknesses within LLMs, leaving important attack vectors unexplored and\nlimiting the scope and efficiency of attacks. In this paper, we uncover a novel\nvulnerability: the safety guardrails of LLMs, while designed for protection,\ncan also be exploited as an attack vector by adversaries. Building on this\nvulnerability, we propose MutedRAG, a novel denial-of-service attack that\nreversely leverages the guardrails of LLMs to undermine the availability of RAG\nsystems. By injecting minimalistic jailbreak texts, such as \"\\textit{How to\nbuild a bomb}\", into the knowledge base, MutedRAG intentionally triggers the\nLLM's safety guardrails, causing the system to reject legitimate queries.\nBesides, due to the high sensitivity of guardrails, a single jailbreak sample\ncan affect multiple queries, effectively amplifying the efficiency of attacks\nwhile reducing their costs. Experimental results on three datasets demonstrate\nthat MutedRAG achieves an attack success rate exceeding 60% in many scenarios,\nrequiring only less than one malicious text to each target query on average. In\naddition, we evaluate potential defense strategies against MutedRAG, finding\nthat some of current mechanisms are insufficient to mitigate this threat,\nunderscoring the urgent need for more robust solutions.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-30T14:18:11Z"}
{"aid":"http://arxiv.org/abs/2504.21690v1","title":"Combinatorial twists in gl_n Yangians","summary":"We introduce the special set-theoretic Yang-Baxter algebra and show that it\nis a Hopf algebra. The associated universal R-matrix is also obtained via an\nadmissible Drinfel'd twist, making the algebra a quasi-triangular Hopf algebra.\nThe fundamental representation of the universal R-matrix yields the familiar\nset-theoretic (combinatorial) solutions of the Yang-Baxter equation. We then\napply the same Drinfel'd twist to the gl_n Yangian after introducing the\naugmented Yangian. We show that the augmented Yangian is also a Hopf algebra\nand we obtain the twisted version of the augmented gl_n Yangian as well as the\ntwisted R-matrix.","main_category":"math.QA","categories":"math.QA,math-ph,math.MP","published":"2025-04-30T14:25:33Z"}
{"aid":"http://arxiv.org/abs/2504.21704v1","title":"Bounds in Sequential Unambiguous Discrimination of Multiple Pure Quantum\n  States","summary":"Sequential methods for quantum hypothesis testing offer significant\nadvantages over fixed-length approaches, which rely on a predefined number of\nstate copies. Despite their potential, these methods remain underexplored for\nunambiguous discrimination. In this work, we derive performance bounds for such\nmethods when applied to the discrimination of a set of pure states. The\nperformance is evaluated based on the expected number of copies required. We\nestablish a lower bound applicable to any sequential method and an upper bound\non the optimal sequential method. The upper bound is derived using a novel and\nsimple non-adaptive method. Importantly, the gap between these bounds is\nminimal, scaling logarithmically with the number of distinct states.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-30T14:46:04Z"}
{"aid":"http://arxiv.org/abs/2504.21735v1","title":"TheraQuest: A Gamified, LLM-Powered Simulation for Massage Therapy\n  Training","summary":"Massage therapy training emphasizes hands-on techniques and effective\ntherapist--patient communication. However, many educational programs struggle\nto provide realistic practice scenarios. To address this problem, we propose\nTheraQuest, a gamified, web-based simulation platform that employs large\nlanguage models (LLMs) to generate diverse virtual patients with varying\nsymptoms and cultural backgrounds. Through interactive dialogue, anatomical\ndecision-making, and immediate assessment, trainees develop both diagnostic\nreasoning and empathetic communication skills in a low-risk environment. Unlike\nexclusively VR-based solutions, TheraQuest remains accessible via standard web\nbrowsers, mitigating the cost and discomfort associated with extended headset\nuse. Preliminary testing suggests that integrating LLM-driven virtual patients\nwith real-time skill metrics can enhance trainee engagement and help bridge the\ngap between theoretical knowledge and clinical proficiency.","main_category":"cs.GT","categories":"cs.GT,cs.HC","published":"2025-04-30T15:31:52Z"}
{"aid":"http://arxiv.org/abs/2504.21744v1","title":"Jet Modification and Medium Response -- Theory Overview","summary":"This text contains a summary and personal perspective on the current status\nand challenges of jet quenching physics as portrayed by the presentations\ndelivered at the 12th International Conference on Hard and Electromagnetic\nProbes of High-Energy Nuclear Collisions (Hard Probes 2024) which took place in\nSeptember 2024 in Nagasaki, Japan.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-30T15:39:15Z"}
{"aid":"http://arxiv.org/abs/2504.21752v1","title":"VDDP: Verifiable Distributed Differential Privacy under the\n  Client-Server-Verifier Setup","summary":"Despite differential privacy (DP) often being considered the de facto\nstandard for data privacy, its realization is vulnerable to unfaithful\nexecution of its mechanisms by servers, especially in distributed settings.\nSpecifically, servers may sample noise from incorrect distributions or generate\ncorrelated noise while appearing to follow established protocols. This work\nanalyzes these malicious behaviors in a general differential privacy framework\nwithin a distributed client-server-verifier setup. To address these adversarial\nproblems, we propose a novel definition called Verifiable Distributed\nDifferential Privacy (VDDP) by incorporating additional verification\nmechanisms. We also explore the relationship between zero-knowledge proofs\n(ZKP) and DP, demonstrating that while ZKPs are sufficient for achieving DP\nunder verifiability requirements, they are not necessary. Furthermore, we\ndevelop two novel and efficient mechanisms that satisfy VDDP: (1) the\nVerifiable Distributed Discrete Laplacian Mechanism (VDDLM), which offers up to\na $4 \\times 10^5$x improvement in proof generation efficiency with only\n0.1-0.2x error compared to the previous state-of-the-art verifiable\ndifferentially private mechanism; (2) an improved solution to Verifiable\nRandomized Response (VRR) under local DP, a special case of VDDP, achieving up\na reduction of up to 5000x in communication costs and the verifier's overhead.","main_category":"cs.CR","categories":"cs.CR,cs.DB","published":"2025-04-30T15:46:55Z"}
{"aid":"http://arxiv.org/abs/2504.21767v1","title":"Whleaper: A 10-DOF Flexible Bipedal Wheeled Robot","summary":"Wheel-legged robots combine the advantages of both wheeled robots and legged\nrobots, offering versatile locomotion capabilities with excellent stability on\nchallenging terrains and high efficiency on flat surfaces. However, existing\nwheel-legged robots typically have limited hip joint mobility compared to\nhumans, while hip joint plays a crucial role in locomotion. In this paper, we\nintroduce Whleaper, a novel 10-degree-of-freedom (DOF) bipedal wheeled robot,\nwith 3 DOFs at the hip of each leg. Its humanoid joint design enables adaptable\nmotion in complex scenarios, ensuring stability and flexibility. This paper\nintroduces the details of Whleaper, with a focus on innovative mechanical\ndesign, control algorithms and system implementation. Firstly, stability stems\nfrom the increased DOFs at the hip, which expand the range of possible postures\nand improve the robot's foot-ground contact. Secondly, the extra DOFs also\naugment its mobility. During walking or sliding, more complex movements can be\nadopted to execute obstacle avoidance tasks. Thirdly, we utilize two control\nalgorithms to implement multimodal motion for walking and sliding. By\ncontrolling specific DOFs of the robot, we conducted a series of simulations\nand practical experiments, demonstrating that a high-DOF hip joint design can\neffectively enhance the stability and flexibility of wheel-legged robots.\nWhleaper shows its capability to perform actions such as squatting, obstacle\navoidance sliding, and rapid turning in real-world scenarios.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-30T16:07:44Z"}
{"aid":"http://arxiv.org/abs/2504.21800v1","title":"How Real Are Synthetic Therapy Conversations? Evaluating Fidelity in\n  Prolonged Exposure Dialogues","summary":"The growing adoption of synthetic data in healthcare is driven by privacy\nconcerns, limited access to real-world data, and the high cost of annotation.\nThis work explores the use of synthetic Prolonged Exposure (PE) therapeutic\nconversations for Post-Traumatic Stress Disorder (PTSD) as a scalable\nalternative for training and evaluating clinical models. We systematically\ncompare real and synthetic dialogues using linguistic, structural, and\nprotocol-specific metrics, including turn-taking patterns and treatment\nfidelity. We also introduce and evaluate PE-specific metrics derived from\nlinguistic analysis and semantic modeling, offering a novel framework for\nassessing clinical fidelity beyond surface fluency. Our findings show that\nalthough synthetic data holds promise for mitigating data scarcity and\nprotecting patient privacy, it can struggle to capture the subtle dynamics of\ntherapeutic interactions. In our dataset, synthetic dialogues match structural\nfeatures of real-world dialogues (e.g., speaker switch ratio: 0.98 vs. 0.99),\nhowever, synthetic interactions do not adequately reflect key fidelity markers\n(e.g., distress monitoring). We highlight gaps in existing evaluation\nframeworks and advocate for fidelity-aware metrics that go beyond surface\nfluency to uncover clinically significant failures. Our findings clarify where\nsynthetic data can effectively complement real-world datasets -- and where\ncritical limitations remain.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.CY,cs.HC","published":"2025-04-30T16:56:56Z"}
{"aid":"http://arxiv.org/abs/2504.21811v1","title":"Coarse Baum-Connes and warped cones: failure of surjectivity in odd\n  degree","summary":"We prove a conjecture of Roe by constructing unified warped cones that\nviolate the coarse Baum-Connes conjecture. Interestingly, the reason for this\nis probably not what Roe expected, as the obstruction arises in odd rather than\neven degree.","main_category":"math.KT","categories":"math.KT,math.MG,math.OA","published":"2025-04-30T17:15:20Z"}
{"aid":"http://arxiv.org/abs/2504.21824v1","title":"A simple range characterization for spherical mean transform in even\n  dimensions","summary":"The paper presents a new and simple range characterization for the spherical\nmean transform of functions supported in the unit ball in even dimensions. It\ncomplements the previous work of the same authors, where they solved an\nanalogous problem in odd dimensions. The range description in even dimensions\nconsists of symmetry relations, using a special kind of elliptic integrals\ninvolving the coefficients of the spherical harmonics expansion of the function\nin the range of the transform. The article also introduces a pair of original\nidentities involving normalized Bessel functions of the first and the second\nkind. The first result is an integral cross-product identity for Bessel\nfunctions of integer order, complementing a similar relation for Bessel\nfunctions of half-integer order obtained in the aforementioned work of the same\nauthors. The second result is a new Nicholson-type identity. Both of these\nrelations can be considered as important standalone results in the theory of\nspecial functions. Finally, as part of the proof of one of the theorems, the\nauthors derive an interesting equality involving elliptic integrals, which may\nbe of independent interest.","main_category":"math.CA","categories":"math.CA,math-ph,math.FA,math.MP","published":"2025-04-30T17:27:23Z"}
{"aid":"http://arxiv.org/abs/2504.21835v1","title":"Patch bubbles for advection-dominated problems","summary":"A novel variant of the \\emph{residual-free bubble} method (RFB) for advection\ndominated problems is presented. Since the usual RFB still suffers from\noscillations and strong under/overshoots, the bubble space is enriched by\n\\emph{patch bubbles}, giving more freedom to the bubble space.\n  We use a recursive and efficient approach to accurately compute the bubbles.\nNumerical experiments clearly demonstrate the superiority of our method\ncompared to the standard RFB.\n  The method is similar to the \\emph{enhanced residual-free bubble} method\n(eRFB) proposed by Cangiani and S\\\"uli in 2005, but differs in the definition\nof the additional bubbles.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-30T17:46:14Z"}
{"aid":"http://arxiv.org/abs/2505.00257v1","title":"Graph Privacy: A Heterogeneous Federated GNN for Trans-Border Financial\n  Data Circulation","summary":"The sharing of external data has become a strong demand of financial\ninstitutions, but the privacy issue has led to the difficulty of\ninterconnecting different platforms and the low degree of data openness. To\neffectively solve the privacy problem of financial data in trans-border flow\nand sharing, to ensure that the data is available but not visible, to realize\nthe joint portrait of all kinds of heterogeneous data of business organizations\nin different industries, we propose a Heterogeneous Federated Graph Neural\nNetwork (HFGNN) approach. In this method, the distribution of heterogeneous\nbusiness data of trans-border organizations is taken as subgraphs, and the\nsharing and circulation process among subgraphs is constructed as a\nstatistically heterogeneous global graph through a central server. Each\nsubgraph learns the corresponding personalized service model through local\ntraining to select and update the relevant subset of subgraphs with aggregated\nparameters, and effectively separates and combines topological and feature\ninformation among subgraphs. Finally, our simulation experimental results show\nthat the proposed method has higher accuracy performance and faster convergence\nspeed than existing methods.","main_category":"cs.LG","categories":"cs.LG,cs.CR","published":"2025-05-01T02:47:43Z"}
{"aid":"http://arxiv.org/abs/2505.00284v1","title":"LightEMMA: Lightweight End-to-End Multimodal Model for Autonomous\n  Driving","summary":"Vision-Language Models (VLMs) have demonstrated significant potential for\nend-to-end autonomous driving. However, fully exploiting their capabilities for\nsafe and reliable vehicle control remains an open research challenge. To\nsystematically examine advances and limitations of VLMs in driving tasks, we\nintroduce LightEMMA, a Lightweight End-to-End Multimodal Model for Autonomous\ndriving. LightEMMA provides a unified, VLM-based autonomous driving framework\nwithout ad hoc customizations, enabling easy integration and evaluation of\nevolving state-of-the-art commercial and open-source models. We construct\ntwelve autonomous driving agents using various VLMs and evaluate their\nperformance on the nuScenes prediction task, comprehensively assessing metrics\nsuch as inference time, computational cost, and predictive accuracy.\nIllustrative examples highlight that, despite their strong scenario\ninterpretation capabilities, VLMs' practical performance in autonomous driving\ntasks remains concerning, emphasizing the need for further improvements. The\ncode is available at https://github.com/michigan-traffic-lab/LightEMMA.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-05-01T04:12:41Z"}
{"aid":"http://arxiv.org/abs/2505.00321v1","title":"Edge Large AI Models: Revolutionizing 6G Networks","summary":"Large artificial intelligence models (LAMs) possess human-like abilities to\nsolve a wide range of real-world problems, exemplifying the potential of\nexperts in various domains and modalities. By leveraging the communication and\ncomputation capabilities of geographically dispersed edge devices, edge LAM\nemerges as an enabling technology to empower the delivery of various real-time\nintelligent services in 6G. Unlike traditional edge artificial intelligence\n(AI) that primarily supports a single task using small models, edge LAM is\nfeatured by the need of the decomposition and distributed deployment of large\nmodels, and the ability to support highly generalized and diverse tasks.\nHowever, due to limited communication, computation, and storage resources over\nwireless networks, the vast number of trainable neurons and the substantial\ncommunication overhead pose a formidable hurdle to the practical deployment of\nedge LAMs. In this paper, we investigate the opportunities and challenges of\nedge LAMs from the perspectives of model decomposition and resource management.\nSpecifically, we propose collaborative fine-tuning and full-parameter training\nframeworks, alongside a microservice-assisted inference architecture, to\nenhance the deployment of edge LAM over wireless networks. Additionally, we\ninvestigate the application of edge LAM in air-interface designs, focusing on\nchannel prediction and beamforming. These innovative frameworks and\napplications offer valuable insights and solutions for advancing 6G technology.","main_category":"cs.NI","categories":"cs.NI,cs.LG,eess.SP","published":"2025-05-01T05:44:00Z"}
{"aid":"http://arxiv.org/abs/2505.00404v1","title":"iMacSR: Intermediate Multi-Access Supervision and Regularization in\n  Training Autonomous Driving Models","summary":"Deep Learning (DL)-based street scene semantic understanding has become a\ncornerstone of autonomous driving (AD). DL model performance heavily relies on\nnetwork depth. Specifically, deeper DL architectures yield better segmentation\nperformance. However, as models grow deeper, traditional one-point supervision\nat the final layer struggles to optimize intermediate feature representations,\nleading to subpar training outcomes. To address this, we propose an\nintermediate Multi-access Supervision and Regularization (iMacSR) strategy. The\nproposed iMacSR introduces two novel components: (I) mutual information between\nlatent features and ground truth as intermediate supervision loss ensures\nrobust feature alignment at multiple network depths; and (II) negative entropy\nregularization on hidden features discourages overconfident predictions and\nmitigates overfitting. These intermediate terms are combined into the original\nfinal-layer training loss to form a unified optimization objective, enabling\ncomprehensive optimization across the network hierarchy. The proposed iMacSR\nprovides a robust framework for training deep AD architectures, advancing the\nperformance of perception systems in real-world driving scenarios. In addition,\nwe conduct theoretical convergence analysis for the proposed iMacSR. Extensive\nexperiments on AD benchmarks (i.e., Cityscapes, CamVid, and SynthiaSF datasets)\ndemonstrate that iMacSR outperforms conventional final-layer single-point\nsupervision method up to 9.19% in mean Intersection over Union (mIoU).","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-01T08:52:56Z"}
{"aid":"http://arxiv.org/abs/2505.00407v1","title":"Multiple generation star formation in Cepheus Flare","summary":"We present an analysis of the young stellar moving group ASCC 127 using Gaia\nDR3 data, significantly expanding its membership to 3,971 stars -- double the\nnumber identified in previous studies. Using kinematic and distance criteria,\nASCC 127 is divided into five subgroups (Groups 1-5) with ages spanning from 15\nto 32 Myr. Groups 1-5 are spatially linked to the Cepheus Flare star-forming\nregion, revealing potential evidence of four sequential star formation episodes\nat approximately 32 Myr, 20 Myr, 15 Myr, and 7 Myr. Through dust and gas\nmapping, we identify a spatial cavity extending several tens of parsecs, which\nmay have resulted from feedback processes such as supernovae associated with\nearlier generations of stars in the region. This structure, along with the\nlarger Loop III feature, indicates that feedback from massive stars likely\ninfluenced the interstellar medium (ISM). By integrating young stellar\npopulations with ISM studies, we provide a detailed picture of the\nfeedback-driven star formation history in the Cepheus Flare region.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-05-01T08:57:34Z"}
{"aid":"http://arxiv.org/abs/2505.00445v1","title":"Effect of Ti$_2$Pd(Ni) on the Transformation Behavior in Sputtered\n  Ti-rich TiNiPd Shape Memory Alloys","summary":"TiNiPd based shape memory alloys (SMAs) share similar microstructural\nfeatures as TiNiCu-based SMAs known for their exceptional resistance to\nfunctional fatigue due to their high crystallographic compatibility, nanometer\nsized grains and coherent precipitates, making them an ideal system to further\nexplore the critical factors influencing cyclic stability. In this study, we\ninvestigate the effect of heat treatments (500 {\\deg}C, 600 {\\deg}C, 700\n{\\deg}C and 800 {\\deg}C) on the cyclic stability and microstructure of\nfree-standing, magnetron-sputtered Ti$_{53.6}$Ni$_{35.2}$Pd$_{11.2}$ films. All\nheat treatments promote the formation of Ti$_2$Pd(Ni) precipitates and result\nin a similar grain size (~1-4 $\\mu$m). Lower heat treatment temperatures\nimprove the cyclic stability of the stress induced transformation while\nreducing transformation temperatures and latent heat. Temperature dependent\nX-ray diffraction reveals a complex microstructure for the martensite phase\nwith Ti$_2$Pd(Ni), Ti$_2$Ni(Pd), TiNiPd(B2), B19/B19$'$ and R-phase. The\nthermal phase transition changes from a distinct 1st order to a 2nd order like\ntransition, accompanied by increasing amount of remanent austenite and R-phase,\nwith nearly no change for the sample heat treated at 500 {\\deg}C. In situ\nstress dependent X-ray diffraction demonstrates a significant difference\nbetween the temperature and stress induced phase transformation for this heat\ntreatment. The observed semi crystalline microstructure, featuring nano domains\nof Ti$_2$Pd(Ni) precipitates in the sample heat-treated at 500 {\\deg}C, leads\nto a mixture of long range martensitic and strain glass transition. This study\nhighlights the impact of heat treatment and microstructure on the phase\ntransformation behavior and functional fatigue in Ti-rich TiNiPd alloys.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-05-01T10:39:49Z"}
{"aid":"http://arxiv.org/abs/2505.00449v1","title":"An approach for modularly verifying the core of Rust's atomic reference\n  counting algorithm against the (X)C20 memory consistency model","summary":"We propose an approach for modular verification of programs that use\nrelaxed-consistency atomic memory access primitives and fences, sufficient for\nverifying the core of Rust's Atomic Reference Counting (ARC) algorithm, and we\nargue its soundness, when combined with a simple static analysis and admitting\nan open sub-problem, with respect to the C20 memory consistency model, as well\nas, even in the absence of any static analysis and without any assumptions,\nwith respect to XC20, a recently proposed minor strengthening of C20 that rules\nout out-of-thin-air behaviors but allows load buffering. In contrast to\nexisting work on verifying ARC, we do not assume acyclicity of the union of the\nprogram-order and reads-from relations. We define an interleaving operational\nsemantics, prove its soundness with respect to (X)C20's axiomatic semantics,\nand then apply any existing program logic for fine-grained interleaving\nconcurrency, such as Iris.","main_category":"cs.PL","categories":"cs.PL","published":"2025-05-01T10:51:20Z"}
{"aid":"http://arxiv.org/abs/2505.00486v1","title":"Enumeration of idempotent-sum subsequences in finite cyclic semigroups\n  and smooth sequences","summary":"The enumeration of zero-sum subsequences of a given sequence over finite\ncyclic groups is one classical topic, which starts from one question of P.\nErd\\H{o}s. In this paper, we consider this problem in a more general setting --\nfinite cyclic semigroups. Let $\\mathcal{S}$ be a finite cyclic semigroup. By\n$\\textbf{e}$ we denote the unique idempotent of the semigroup $\\mathcal{S}$.\nLet $T$ be a sequence over the semigroup $\\mathcal{S}$, and let $N(T;\n\\textbf{e})$ be the number of distinct subsequences of $T$ with sum being the\nidempotent $\\textbf{e}$. We obtain the lower bound for $N(T; \\textbf{e})$ in\nterms of the length of $T$, and moreover, prove that $T$ contains subsequences\nwith some smooth-structure in case that $N(T; \\textbf{e})$ is not large. Our\nresult generalizes the theorem obtained by W. Gao [Discrete Math., 1994] on the\nenumeration of zero-sum subsequences over finite cyclic groups to the setting\nof semigroups.","main_category":"math.CO","categories":"math.CO,math.NT","published":"2025-05-01T12:35:23Z"}
{"aid":"http://arxiv.org/abs/2505.00507v1","title":"HeAL3D: Heuristical-enhanced Active Learning for 3D Object Detection","summary":"Active Learning has proved to be a relevant approach to perform sample\nselection for training models for Autonomous Driving. Particularly, previous\nworks on active learning for 3D object detection have shown that selection of\nsamples in uncontrolled scenarios is challenging. Furthermore, current\napproaches focus exclusively on the theoretical aspects of the sample selection\nproblem but neglect the practical insights that can be obtained from the\nextensive literature and application of 3D detection models. In this paper, we\nintroduce HeAL (Heuristical-enhanced Active Learning for 3D Object Detection)\nwhich integrates those heuristical features together with Localization and\nClassification to deliver the most contributing samples to the model's\ntraining. In contrast to previous works, our approach integrates heuristical\nfeatures such as object distance and point-quantity to estimate the\nuncertainty, which enhance the usefulness of selected samples to train\ndetection models. Our quantitative evaluation on KITTI shows that HeAL presents\ncompetitive mAP with respect to the State-of-the-Art, and achieves the same mAP\nas the full-supervised baseline with only 24% of the samples.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-01T13:24:55Z"}
{"aid":"http://arxiv.org/abs/2505.00512v1","title":"InterLoc: LiDAR-based Intersection Localization using Road Segmentation\n  with Automated Evaluation Method","summary":"Intersections are geometric and functional key points in every road network.\nThey offer strong landmarks to correct GNSS dropouts and anchor new sensor data\nin up-to-date maps. Despite that importance, intersection detectors either\nignore the rich semantic information already computed onboard or depend on\nscarce, hand-labeled intersection datasets. To close that gap, this paper\npresents a LiDAR-based method for intersection detection that (i) fuses\nsemantic road segmentation with vehicle localization to detect intersection\ncandidates in a bird's eye view (BEV) representation and (ii) refines those\ncandidates by analyzing branch topology with a least squares formulation. To\nevaluate our method, we introduce an automated benchmarking pipeline that pairs\ndetections with OpenStreetMap (OSM) intersection nodes using precise GNSS/INS\nground-truth poses. Tested on eight SemanticKITTI sequences, the approach\nachieves a mean localization error of 1.9 m, 89% precision, and 77% recall at a\n5 m tolerance, outperforming the latest learning-based baseline. Moreover, the\nmethod is robust to segmentation errors higher than those of the benchmark\nmodel, demonstrating its applicability in the real world.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-05-01T13:30:28Z"}
{"aid":"http://arxiv.org/abs/2505.00517v1","title":"An explicit description of the K√§hler-Einstein metrics of\n  Guenancia-Hamenst√§dt","summary":"Fine and Premoselli (FP) constructed the first examples of manifolds that do\nnot admit a locally symmetric metric but do admit a negatively curved Einstein\nmetric. The manifolds here are hyperbolic branched covers like those used by\nGromov and Thurston, and the construction of their model Einstein metric is a\nvariation of the hyperbolic metric written in polar coordinates. Very recently,\nGuenancia and Hamenst\\\"{a}dt (GH) proved the existence of the first examples of\nmanifolds that are not locally symmetric but admit a negatively curved\nK\\\"{a}hler-Einstein metric. The GH metrics are realized on complex hyperbolic\nbranched covers constructed by Stover and Toledo. In this article we generalize\nthe construction of FP to the complex hyperbolic setting and show that this\nyields a negatively curved Einstein metric that asymptotically approaches the\nmetric of GH.","main_category":"math.DG","categories":"math.DG,math-ph,math.GT,math.MG,math.MP","published":"2025-05-01T13:39:20Z"}
{"aid":"http://arxiv.org/abs/2505.00550v1","title":"Bridging Cultural and Digital Divides: A Low-Latency JackTrip Framework\n  for Equitable Music Education in the Global South","summary":"The rapid expansion of digital technologies has transformed educational\nlandscapes worldwide, yet significant infrastructural and cultural challenges\npersist in the Global South. This paper introduces a low-latency JackTrip\nframework designed to bridge both the cultural and digital divides in music\neducation. By leveraging an open-source, UDP-based audio streaming protocol\noriginally developed at Stanford's CCRMA, the framework is tailored to address\ntechnical constraints such as intermittent connectivity, limited bandwidth, and\nhigh latency that characterize many rural and underserved regions. The study\nsystematically compares the performance of JackTrip with conventional platforms\nlike Zoom, demonstrating that JackTrip achieves sub-30~ms latency under\nsimulated low-resource conditions while preserving the intricate audio details\nessential for non-Western musical traditions. Spectral analysis confirms that\nJackTrip's superior handling of microtonal scales, complex rhythms, and\nharmonic textures provides a culturally authentic medium for real-time ensemble\nperformance and music education. These findings underscore the transformative\npotential of decentralized, edge-computing solutions in empowering educators\nand musicians across the Global South, promoting both technological equity and\ncultural preservation.","main_category":"cs.SD","categories":"cs.SD,cs.SI","published":"2025-05-01T14:27:47Z"}
{"aid":"http://arxiv.org/abs/2505.00583v1","title":"Gluon Parts of Gravitational Form Factors and Mass Distribution","summary":"The parton structure of the nucleon and pion is investigated in an\nexploratory model that allows one to assess whether the dressing of quarks can,\nby itself, produce realistic gluon contributions to light-cone momentum\nfractions, gravitational form factors, mass/energy distributions and their\nradii. The model is the Dyson-Schwinger Equations in Rainbow-Ladder truncation.\nFor the parton mass/energy distributions as a function of momentum transfer, we\ndirectly calculate matrix elements of the Energy-Momentum Tensor by utilizing\nits similarity to the momentum fraction moment of GPDs associated with deep\ninelastic scattering. A variety of gravitational form factors are obtained\nincluding the D-term.","main_category":"nucl-th","categories":"nucl-th,hep-ph,hep-th","published":"2025-05-01T15:15:29Z"}
{"aid":"http://arxiv.org/abs/2505.00623v1","title":"Planckian scattering and parallel conduction channels in the iron\n  chalcogenide superconductors FeTe$_{1-x}$Se$_x$","summary":"The remarkable linear in temperature resistivity of the cuprate\nsuperconductors, which extends in some samples from $T_c$ to the melting\ntemperature, remains unexplained. Although seemingly simple, this temperature\ndependence is incompatible with the conventional theory of metals that dictates\nthat the scattering rate, $1/\\tau$, should be quadratic in temperature if\nelectron-electron scattering dominates. Understanding the origin of this\ntemperature dependence and its connection to superconductivity may provide the\nkey to pick the lock of high-temperature superconductivity. Using time-domain\nterahertz spectroscopy (TDTS) we elucidate the low temperature conducting\nbehavior of two FeTe$_{1-x}$Se$_x$ (FTS) samples, one with almost equal amounts\nof Se and Te that is believed to be a topological superconductor, and one that\nis more overdoped. Constrained with DC resistivity, we find two conduction\nchannels that add in parallel, a broad one in frequency with weak temperature\ndependence and a sharper one whose scattering rate goes as the Planckian\nlimited rate, $\\sim kT/h$. Through analysis of its spectral weight we show the\nsuperconducting condensate is mainly drawn from the channel that undergoes this\nPlanckian scattering.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.str-el","published":"2025-05-01T16:04:27Z"}
{"aid":"http://arxiv.org/abs/2505.00632v1","title":"Detecting Modeling Bias with Continuous Time Flow Models on Weak Lensing\n  Maps","summary":"Simulation-based inference provides a powerful framework for extracting rich\ninformation from nonlinear scales in current and upcoming cosmological surveys,\nand ensuring its robustness requires stringent validation of forward models. In\nthis work, we recast forward model validation as an out-of-distribution (OoD)\ndetection problem within the framework of machine learning (ML)-based\nsimulation-based inference (SBI). We employ probability density as the metric\nfor OoD detection, and compare various density estimation techniques,\ndemonstrating that field-level probability density estimation via continuous\ntime flow models (CTFM) significantly outperforms feature-level approaches that\ncombine scattering transform (ST) or convolutional neural networks (CNN) with\nnormalizing flows (NFs), as well as NF-based field-level estimators, as\nquantified by the area under the receiver operating characteristic curve\n(AUROC). Our analysis shows that CTFM not only excels in detecting OoD samples\nbut also provides a robust metric for model selection. Additionally, we\nverified CTFM maintains consistent efficacy across different cosmologies while\nmitigating the inductive biases inherent in NF architectures. Although our\nproof-of-concept study employs simplified forward modeling and noise settings,\nour framework establishes a promising pathway for identifying unknown\nsystematics in the cosmology datasets.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.IM","published":"2025-05-01T16:16:47Z"}
{"aid":"http://arxiv.org/abs/2505.00653v1","title":"On the exponents of distribution of primes and smooth numbers","summary":"We show that both primes and smooth numbers are equidistributed in arithmetic\nprogressions to moduli up to $x^{5/8 - o(1)}$, using triply-well-factorable\nweights for the primes (we also get improvements for the well-factorable linear\nsieve weights). This completely eliminates the dependency on Selberg's\neigenvalue conjecture in previous works of Lichtman and the author, which built\nin turn on results of Maynard and Drappeau. We rely on recent large sieve\ninequalities for exceptional Maass forms of the author for\nadditively-structured sequences, and on a related result of Watt for\nmultiplicatively-structured sequences. As applications, we prove refined upper\nbounds for the counts of twin primes and consecutive smooth numbers up to $x$.","main_category":"math.NT","categories":"math.NT","published":"2025-05-01T16:55:08Z"}
{"aid":"http://arxiv.org/abs/2505.00669v1","title":"Direct spectral problems for Paley-Wiener canonical systems","summary":"This note focuses on the direct spectral problem for canonical Hamiltonian\nsystems on the half-line $\\mathbb{R}_+$. Truncated Toeplitz operators have been\neffectively used to solve the inverse spectral problem when the spectral\nmeasure is a locally finite periodic measure (see \\cite{MP}). Here, we reverse\nthe inverse problem algorithm to solve the direct spectral problem for\nstep-function Hamiltonians. For a non-step-function Hamiltonian, we consider\nits step-function approximations and their corresponding spectral measures, and\nshow that these spectral measures converge to the spectral measure of the\noriginal Hamiltonian.","main_category":"math.SP","categories":"math.SP","published":"2025-05-01T17:20:13Z"}
{"aid":"http://arxiv.org/abs/2505.00671v1","title":"Multi-Constraint Safe Reinforcement Learning via Closed-form Solution\n  for Log-Sum-Exp Approximation of Control Barrier Functions","summary":"The safety of training task policies and their subsequent application using\nreinforcement learning (RL) methods has become a focal point in the field of\nsafe RL. A central challenge in this area remains the establishment of\ntheoretical guarantees for safety during both the learning and deployment\nprocesses. Given the successful implementation of Control Barrier Function\n(CBF)-based safety strategies in a range of control-affine robotic systems,\nCBF-based safe RL demonstrates significant promise for practical applications\nin real-world scenarios. However, integrating these two approaches presents\nseveral challenges. First, embedding safety optimization within the RL training\npipeline requires that the optimization outputs be differentiable with respect\nto the input parameters, a condition commonly referred to as differentiable\noptimization, which is non-trivial to solve. Second, the differentiable\noptimization framework confronts significant efficiency issues, especially when\ndealing with multi-constraint problems. To address these challenges, this paper\npresents a CBF-based safe RL architecture that effectively mitigates the issues\noutlined above. The proposed approach constructs a continuous AND logic\napproximation for the multiple constraints using a single composite CBF. By\nleveraging this approximation, a close-form solution of the quadratic\nprogramming is derived for the policy network in RL, thereby circumventing the\nneed for differentiable optimization within the end-to-end safe RL pipeline.\nThis strategy significantly reduces computational complexity because of the\nclosed-form solution while maintaining safety guarantees. Simulation results\ndemonstrate that, in comparison to existing approaches relying on\ndifferentiable optimization, the proposed method significantly reduces training\ncomputational costs while ensuring provable safety throughout the training\nprocess.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-05-01T17:22:11Z"}
{"aid":"http://arxiv.org/abs/2505.00679v1","title":"Steering Large Language Models with Register Analysis for Arbitrary\n  Style Transfer","summary":"Large Language Models (LLMs) have demonstrated strong capabilities in\nrewriting text across various styles. However, effectively leveraging this\nability for example-based arbitrary style transfer, where an input text is\nrewritten to match the style of a given exemplar, remains an open challenge. A\nkey question is how to describe the style of the exemplar to guide LLMs toward\nhigh-quality rewrites. In this work, we propose a prompting method based on\nregister analysis to guide LLMs to perform this task. Empirical evaluations\nacross multiple style transfer tasks show that our prompting approach enhances\nstyle transfer strength while preserving meaning more effectively than existing\nprompting strategies.","main_category":"cs.CL","categories":"cs.CL","published":"2025-05-01T17:39:02Z"}
{"aid":"http://arxiv.org/abs/2505.00693v1","title":"Robotic Visual Instruction","summary":"Recently, natural language has been the primary medium for human-robot\ninteraction. However, its inherent lack of spatial precision for robotic\ncontrol introduces challenges such as ambiguity and verbosity. To address these\nlimitations, we introduce the Robotic Visual Instruction (RoVI), a novel\nparadigm to guide robotic tasks through an object-centric, hand-drawn symbolic\nrepresentation. RoVI effectively encodes spatial-temporal information into\nhuman-interpretable visual instructions through 2D sketches, utilizing arrows,\ncircles, colors, and numbers to direct 3D robotic manipulation. To enable\nrobots to understand RoVI better and generate precise actions based on RoVI, we\npresent Visual Instruction Embodied Workflow (VIEW), a pipeline formulated for\nRoVI-conditioned policies. This approach leverages Vision-Language Models\n(VLMs) to interpret RoVI inputs, decode spatial and temporal constraints from\n2D pixel space via keypoint extraction, and then transform them into executable\n3D action sequences. We additionally curate a specialized dataset of 15K\ninstances to fine-tune small VLMs for edge deployment, enabling them to\neffectively learn RoVI capabilities. Our approach is rigorously validated\nacross 11 novel tasks in both real and simulated environments, demonstrating\nsignificant generalization capability. Notably, VIEW achieves an 87.5% success\nrate in real-world scenarios involving unseen tasks that feature multi-step\nactions, with disturbances, and trajectory-following requirements. Code and\nDatasets in this paper will be released soon.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.CV","published":"2025-05-01T17:55:05Z"}
{"aid":"http://arxiv.org/abs/2505.03151v1","title":"Scaling of Quantum Geometry Near the Non-Hermitian Topological Phase\n  Transitions","summary":"The geometry of quantum states can be an indicator of criticality, yet it\nremains less explored under non-Hermitian topological conditions. In this work,\nwe unveil diverse scalings of the quantum geometry over the ground state\nmanifold close to different topological phase transitions in a non-Hermitian\nlong-range extension of the Kitaev chain. The derivative of the geometric\nphase, as well as its scaling behavior, shows that systems with different\nlong-range couplings can belong to distinct universality classes. Near certain\ncriticalities, we further find that the Wannier state correlation function\nassociated with extended Berry connection of the ground state exhibits\nspatially anomalous behaviors. Finally, we analyze the scaling of the quantum\ngeometric tensor near phase transitions across exceptional points, shedding\nlight on the emergence of novel universality classes.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mes-hall,cond-mat.stat-mech,quant-ph","published":"2025-05-06T03:56:48Z"}
{"aid":"http://arxiv.org/abs/2505.03171v1","title":"CombiBench: Benchmarking LLM Capability for Combinatorial Mathematics","summary":"Neurosymbolic approaches integrating large language models with formal\nreasoning have recently achieved human-level performance on mathematics\ncompetition problems in algebra, geometry and number theory. In comparison,\ncombinatorics remains a challenging domain, characterized by a lack of\nappropriate benchmarks and theorem libraries. To address this gap, we introduce\nCombiBench, a comprehensive benchmark comprising 100 combinatorial problems,\neach formalized in Lean~4 and paired with its corresponding informal statement.\nThe problem set covers a wide spectrum of difficulty levels, ranging from\nmiddle school to IMO and university level, and span over ten combinatorial\ntopics. CombiBench is suitable for testing IMO solving capabilities since it\nincludes all IMO combinatorial problems since 2000 (except IMO 2004 P3 as its\nstatement contain an images). Furthermore, we provide a comprehensive and\nstandardized evaluation framework, dubbed Fine-Eval (for\n$\\textbf{F}$ill-in-the-blank $\\textbf{in}$ L$\\textbf{e}$an Evaluation), for\nformal mathematics. It accommodates not only proof-based problems but also, for\nthe first time, the evaluation of fill-in-the-blank questions. Using Fine-Eval\nas the evaluation method and Kimina Lean Server as the backend, we benchmark\nseveral LLMs on CombiBench and observe that their capabilities for formally\nsolving combinatorial problems remain limited. Among all models tested (none of\nwhich has been trained for this particular task), Kimina-Prover attains the\nbest results, solving 7 problems (out of 100) under both ``with solution'' and\n``without solution'' scenarios. We open source the benchmark dataset alongside\nwith the code of the proposed evaluation method at\nhttps://github.com/MoonshotAI/CombiBench/.","main_category":"cs.AI","categories":"cs.AI","published":"2025-05-06T04:32:17Z"}
{"aid":"http://arxiv.org/abs/2505.03172v1","title":"Null Counterfactual Factor Interactions for Goal-Conditioned\n  Reinforcement Learning","summary":"Hindsight relabeling is a powerful tool for overcoming sparsity in\ngoal-conditioned reinforcement learning (GCRL), especially in certain domains\nsuch as navigation and locomotion. However, hindsight relabeling can struggle\nin object-centric domains. For example, suppose that the goal space consists of\na robotic arm pushing a particular target block to a goal location. In this\ncase, hindsight relabeling will give high rewards to any trajectory that does\nnot interact with the block. However, these behaviors are only useful when the\nobject is already at the goal -- an extremely rare case in practice. A dataset\ndominated by these kinds of trajectories can complicate learning and lead to\nfailures. In object-centric domains, one key intuition is that meaningful\ntrajectories are often characterized by object-object interactions such as\npushing the block with the gripper. To leverage this intuition, we introduce\nHindsight Relabeling using Interactions (HInt), which combines interactions\nwith hindsight relabeling to improve the sample efficiency of downstream RL.\nHowever because interactions do not have a consensus statistical definition\ntractable for downstream GCRL, we propose a definition of interactions based on\nthe concept of null counterfactual: a cause object is interacting with a target\nobject if, in a world where the cause object did not exist, the target object\nwould have different transition dynamics. We leverage this definition to infer\ninteractions in Null Counterfactual Interaction Inference (NCII), which uses a\n\"nulling'' operation with a learned model to infer interactions. NCII is able\nto achieve significantly improved interaction inference accuracy in both simple\nlinear dynamics domains and dynamic robotic domains in Robosuite, Robot Air\nHockey, and Franka Kitchen and HInt improves sample efficiency by up to 4x.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-05-06T04:32:47Z"}
{"aid":"http://arxiv.org/abs/2505.03203v1","title":"PiCo: Enhancing Text-Image Alignment with Improved Noise Selection and\n  Precise Mask Control in Diffusion Models","summary":"Advanced diffusion models have made notable progress in text-to-image\ncompositional generation. However, it is still a challenge for existing models\nto achieve text-image alignment when confronted with complex text prompts. In\nthis work, we highlight two factors that affect this alignment: the quality of\nthe randomly initialized noise and the reliability of the generated controlling\nmask. We then propose PiCo (Pick-and-Control), a novel training-free approach\nwith two key components to tackle these two factors. First, we develop a noise\nselection module to assess the quality of the random noise and determine\nwhether the noise is suitable for the target text. A fast sampling strategy is\nutilized to ensure efficiency in the noise selection stage. Second, we\nintroduce a referring mask module to generate pixel-level masks and to\nprecisely modulate the cross-attention maps. The referring mask is applied to\nthe standard diffusion process to guide the reasonable interaction between text\nand image features. Extensive experiments have been conducted to verify the\neffectiveness of PiCo in liberating users from the tedious process of random\ngeneration and in enhancing the text-image alignment for diverse text\ndescriptions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-06T05:38:13Z"}
{"aid":"http://arxiv.org/abs/2505.03206v1","title":"Stable partial dislocation complexes in GaN as charge carrier lifetime\n  modifiers for terahertz device applications by molecular dynamics and\n  first-principle simulations","summary":"Wurtzite GaN is a promising material for applications in photoconductive THz\nradiation sources. For this purpose, the photogenerated charge carriers\nlifetime of the order of tenths of picoseconds is required. A controllable\nlifetime reduction may be considered to achieve by creating recombination\nactive stable dislocation complexes formed by mobile basal-plane Shockley\npartial dislocations (PDs). In this work, formation pathways and stability of\nPD complexes in basal planes of wurzite GaN are studied by molecular dynamics\n(MD) simulations. The simulations reveal the formation of stable complexes by\nattractive interaction of two 30{\\deg} or two 90{\\deg} PDs with opposite\nBurgers vectors located in consecutive (0001) planes. Ones formed, these\ncomplexes change neither their positions, not the atomic configurations during\nsimulated anneal at 1500 K up to the times of 5 ns. The MD results are used as\nan input for density functional theory calculations to refine the atomic\nstructures of the complex cores and to investigate their electronic properties.\nThe calculated band structures of GaN with 30{\\deg}-30{\\deg} and\n90{\\deg}-90{\\deg} dislocation complexes indicate localized energy levels in the\nband gap near the top of the valence band and the conduction band bottom. The\ncalculations of the partial electronic states density confirm the possibility\nof electron-hole recombination between the states localized at the PD complex\ncores. These recombination characteristics are distinctly reflected in the\ncalculated absorption spectra. We conclude that creating such PD complexes in\nrequired concentration may be a tool for tailoring the recombination properties\nof wurtzite GaN for THz radiation generation applications.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-05-06T05:43:23Z"}
{"aid":"http://arxiv.org/abs/2505.03226v1","title":"A pilot method to determine the high mass end of the Stellar Initial\n  Mass Function in galaxies using UVIT, H$Œ±$-MUSE observations and applied\n  to NGC628","summary":"We present a pilot method to estimate the high-mass initial mass function\n(IMF) across the arm, interarm, and spur regions in galaxies and apply it to\nNGC 628. We extracted star-forming complexes (SFCs) from H$\\alpha$ VLT/MUSE and\nUVIT (FUV and NUV) observations of NGC 628 and used ALMA observations to define\nthe molecular gas distribution. We find that the extinction-corrected H$\\alpha$\nand FUV luminosities correlate well. Using the fact that O stars have a shorter\nlifetime (10$^7$ yr) compared to B stars (10$^8$ yr), we estimated the\napproximate number of O stars from H$\\alpha$ emission, and the number of B0\n($M_{*} > 10 M_{\\odot}$), and B1 ($10 M_{\\odot} \\geq M_{*} \\geq 3 M_{\\odot}$)\nstars using FUV, NUV observations. We derived the IMF index ($\\alpha$) for\ndifferent regions using O to B0 ($\\alpha_{1}$) and B0 to B1 ($\\alpha_{2}$)\nstellar ratios. Our findings indicate that if we assume H$\\alpha$ arises only\nfrom O8-type stars, the resulting $\\alpha_{1}$ value is consistent with the\ncanonical IMF index. It steepens when we assume O stars with masses up to 100\n$M_{\\odot}$ with mean $\\alpha_{1}= 3.16 \\pm 0.62$. However, the $\\alpha_{2}$\ndoes not change for large variations in the O-star population, and the mean\n$\\alpha= 2.64 \\pm 0.14$. When we include only blue SFCs ($ FUV-NUV\\leq0.3$),\nmean $\\alpha_{2}$ is $2.43 \\pm 0.06$. The IMF variation for SFCs in arms and\nspurs is insignificant. We also find that $\\alpha_{2}$ correlates with\ndifferent properties of the SFCs, the most prominent being the\nextinction-corrected UV color (FUV-NUV).","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-05-06T06:40:21Z"}
{"aid":"http://arxiv.org/abs/2505.03234v1","title":"Univariate and multivariate tests of equality of quantiles with\n  right-censored data","summary":"A nonparametric test for equality of quantiles in the presence of\nright-censored data is studied. We propose to construct an asymptotic test\nstatistic for the comparison of one quantile between two treatment groups, as\nwell as for the comparison of a collection of quantiles. Under the null\nhypothesis of equality of quantiles, the test statistic follows asymptotically\na normal distribution in the univariate case and a chi-square with J degrees of\nfreedom in the multivariate case, with J the number of quantiles compared.\nDeriving the variance of the test statistic requires the estimation of the\nprobability density function of the distribution of failure times at the\nquantile being tested. A resampling method is presented as an alternative to\nkernel density estimation to perform such task. Extensive simulation studies\nare performed to show that the proposed approach provides reasonable type I\nprobabilities and powers. We illustrate the proposed test in a phase III\nrandomized clinical trial where the proportional hazards assumption between\ntreatment arms does not hold.","main_category":"stat.ME","categories":"stat.ME","published":"2025-05-06T07:00:48Z"}
{"aid":"http://arxiv.org/abs/2505.03311v1","title":"GNN-enabled Precoding for Massive MIMO LEO Satellite Communications","summary":"Low Earth Orbit (LEO) satellite communication is a critical component in the\ndevelopment of sixth generation (6G) networks. The integration of massive\nmultiple-input multiple-output (MIMO) technology is being actively explored to\nenhance the performance of LEO satellite communications. However, the limited\npower of LEO satellites poses a significant challenge in improving\ncommunication energy efficiency (EE) under constrained power conditions.\nArtificial intelligence (AI) methods are increasingly recognized as promising\nsolutions for optimizing energy consumption while enhancing system performance,\nthus enabling more efficient and sustainable communications. This paper\nproposes approaches to address the challenges associated with precoding in\nmassive MIMO LEO satellite communications. First, we introduce an end-to-end\ngraph neural network (GNN) framework that effectively reduces the computational\ncomplexity of traditional precoding methods. Next, we introduce a deep\nunfolding of the Dinkelbach algorithm and the weighted minimum mean square\nerror (WMMSE) approach to achieve enhanced EE, transforming iterative\noptimization processes into a structured neural network, thereby improving\nconvergence speed and computational efficiency. Furthermore, we incorporate the\nTaylor expansion method to approximate matrix inversion within the GNN,\nenhancing both the interpretability and performance of the proposed method.\nNumerical experiments demonstrate the validity of our proposed method in terms\nof complexity and robustness, achieving significant improvements over\nstate-of-the-art methods.","main_category":"eess.SP","categories":"eess.SP,cs.IT,math.IT","published":"2025-05-06T08:43:15Z"}
{"aid":"http://arxiv.org/abs/2505.03351v1","title":"GUAVA: Generalizable Upper Body 3D Gaussian Avatar","summary":"Reconstructing a high-quality, animatable 3D human avatar with expressive\nfacial and hand motions from a single image has gained significant attention\ndue to its broad application potential. 3D human avatar reconstruction\ntypically requires multi-view or monocular videos and training on individual\nIDs, which is both complex and time-consuming. Furthermore, limited by SMPLX's\nexpressiveness, these methods often focus on body motion but struggle with\nfacial expressions. To address these challenges, we first introduce an\nexpressive human model (EHM) to enhance facial expression capabilities and\ndevelop an accurate tracking method. Based on this template model, we propose\nGUAVA, the first framework for fast animatable upper-body 3D Gaussian avatar\nreconstruction. We leverage inverse texture mapping and projection sampling\ntechniques to infer Ubody (upper-body) Gaussians from a single image. The\nrendered images are refined through a neural refiner. Experimental results\ndemonstrate that GUAVA significantly outperforms previous methods in rendering\nquality and offers significant speed improvements, with reconstruction times in\nthe sub-second range (0.1s), and supports real-time animation and rendering.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-06T09:19:16Z"}
{"aid":"http://arxiv.org/abs/2505.03370v1","title":"Effective Field Theory of Superconductivity","summary":"A field theory of a Schr\\\"{o}dinger type complex scalar field of Cooper pair,\na U(1) gauge field of electromagnetism, and a neutral scalar field of gapless\nacoustic phonon is proposed for superconductivity of s-waves. Presence of the\ngapless neutral scalar field is justified as low energy residual acoustic\nphonon degrees in the context of effective field theory. The critical coupling\nof quartic self-interaction of complex scalar field is computed from a 1-loop\nlevel interaction balance between the repulsion mediated by massive degree of\nthe U(1) gauge field and the attraction mediated by massive Higgs degree, in\nthe static limit. The obtained net attraction or repulsion in perturbative\nregime matches the type I or II superconductivity, respectively. We find the\nnew critical coupling of cubic Yukawa type interaction between the neutral and\ncomplex scalar fields from another tree level interaction balance between the\nCoulomb repulsion mediated by massless degree of the U(1) gauge field and the\nattraction mediated by the gapless neutral scalar field, in the static limit.\nSuperconducting phase is realized at or in the vicinity of this critical\ncoupling. A huge discrepancy between the propagation speeds of photon and\nphonon gives a plausible explanation on low critical temperatures in\nconventional superconductors.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.mes-hall,cond-mat.str-el,hep-th","published":"2025-05-06T09:41:36Z"}
{"aid":"http://arxiv.org/abs/2505.03377v1","title":"Gene finding revisited: improved robustness through structured decoding\n  from learned embeddings","summary":"Gene finding is the task of identifying the locations of coding sequences\nwithin the vast amount of genetic code contained in the genome. With an ever\nincreasing quantity of raw genome sequences, gene finding is an important\navenue towards understanding the genetic information of (novel) organisms, as\nwell as learning shared patterns across evolutionarily diverse species. The\ncurrent state of the art are graphical models usually trained per organism and\nrequiring manually curated datasets. However, these models lack the flexibility\nto incorporate deep learning representation learning techniques that have in\nrecent years been transformative in the analysis of pro tein sequences, and\nwhich could potentially help gene finders exploit the growing number of the\nsequenced genomes to expand performance across multiple organisms. Here, we\npropose a novel approach, combining learned embeddings of raw genetic sequences\nwith exact decoding using a latent conditional random field. We show that the\nmodel achieves performance matching the current state of the art, while\nincreasing training robustness, and removing the need for manually fitted\nlength distributions. As language models for DNA improve, this paves the way\nfor more performant cross-organism gene-finders.","main_category":"q-bio.GN","categories":"q-bio.GN","published":"2025-05-06T09:53:15Z"}
{"aid":"http://arxiv.org/abs/2505.03395v1","title":"A chemically etched D-band waveguide orthomode transducer for CMB\n  measurements","summary":"This study presents a prototype D-band waveguide orthomode transducer (OMT)\nfabricated using chemically etched brass platelets. This method offers a fast,\ncost-effective, and scalable approach for producing waveguide OMTs above 100\nGHz, making it well-suited for current and future Cosmic Microwave Background\npolarization experiments, where large focal planes with thousands of receivers\nare required to detect the faint primordial \\textit{B}-modes. Chemical etching\nhas already demonstrated its effectiveness in manufacturing corrugated feedhorn\narrays with state-of-the-art performance up to 150 GHz. Here, we evaluate its\napplicability to more complex structures, such as OMTs.\n  We designed a single OMT prototype operating in the 130-170 GHz range,\nfabricated by chemically etching 0.15 mm-thick brass plates, which were then\nstacked, aligned, and mechanically clamped. Simulations based on metrological\nmeasurements of the OMT profile predict return losses below $-$10 dB, isolation\nbetter than $-$30 dB, and transmission around $-$0.5 dB.\n  The measured transmission and isolation, however, is around $-$1.5/$-$2 dB\nand $<-$20 dB, respectively. Further simulations show that the degradation in\nthe transmission is related to defects and roughness along the etched profile\n($\\mathrm{RMS}\\simeq$3 $\\mu$m), which is a typical and unavoidable effect of\nchemical etching. The discrepancy in isolation, instead, could arise from a\nslight rotation ($\\sim$3$^{\\circ}$) of the polarization angle within the\nmeasurement chain.\n  Our results show that chemical etching is a fast, low-cost, and scalable\ntechnique for producing waveguide OMTs with state-of-the-art performance in\nterms of return loss and isolation. However, at frequencies above 100 GHz the\ntransmission coefficient may degrade due to the mechanical precision\nlimitations of chemical etching.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-05-06T10:19:13Z"}
{"aid":"http://arxiv.org/abs/2505.03406v1","title":"Lightweight Clinical Decision Support System using QLoRA-Fine-Tuned LLMs\n  and Retrieval-Augmented Generation","summary":"This research paper investigates the application of Large Language Models\n(LLMs) in healthcare, specifically focusing on enhancing medical decision\nsupport through Retrieval-Augmented Generation (RAG) integrated with\nhospital-specific data and fine-tuning using Quantized Low-Rank Adaptation\n(QLoRA). The system utilizes Llama 3.2-3B-Instruct as its foundation model. By\nembedding and retrieving context-relevant healthcare information, the system\nsignificantly improves response accuracy. QLoRA facilitates notable parameter\nefficiency and memory optimization, preserving the integrity of medical\ninformation through specialized quantization techniques. Our research also\nshows that our model performs relatively well on various medical benchmarks,\nindicating that it can be used to make basic medical suggestions. This paper\ndetails the system's technical components, including its architecture,\nquantization methods, and key healthcare applications such as enhanced disease\nprediction from patient symptoms and medical history, treatment suggestions,\nand efficient summarization of complex medical reports. We touch on the ethical\nconsiderations-patient privacy, data security, and the need for rigorous\nclinical validation-as well as the practical challenges of integrating such\nsystems into real-world healthcare workflows. Furthermore, the lightweight\nquantized weights ensure scalability and ease of deployment even in\nlow-resource hospital environments. Finally, the paper concludes with an\nanalysis of the broader impact of LLMs on healthcare and outlines future\ndirections for LLMs in medical settings.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-05-06T10:31:54Z"}
{"aid":"http://arxiv.org/abs/2505.03411v1","title":"Forward-backward correlations: A probe to study dynamical fluctuations","summary":"The source of the fluctuations in the final state particles is the initial\nevent-by-event fluctuation in energy density. Forward-Backward (F-B)\ncorrelation is one of the important probes to study such fluctuations. The\nresults of F-B correlation are available in a wide range of energy, from STAR\nof RHIC to ALICE of LHC. It will be more interesting to study the dynamical\nfluctuation using F-B correlation at SIS100 energy too. In this study, an\nattempt has been made to investigate the F-B correlation in UrQMD-hydro\ngenerated data for 10 AGeV Au+Au collisions.","main_category":"hep-ph","categories":"hep-ph","published":"2025-05-06T10:36:45Z"}
{"aid":"http://arxiv.org/abs/2505.03428v1","title":"Airdrop Games","summary":"Launching a new blockchain system or application is frequently facilitated by\na so called airdrop, where the system designer chooses a pre-existing set of\npotentially interested parties and allocates newly minted tokens to them with\nthe expectation that they will participate in the system - such engagement,\nespecially if it is of significant level, facilitates the system and raises its\nvalue and also the value of its newly minted token, hence benefiting the\nairdrop recipients. A number of challenging questions befuddle designers in\nthis setting, such as how to choose the set of interested parties and how to\nallocate tokens to them. To address these considerations we put forward a\ngame-theoretic model for such airdrop games. Our model can be used to guide the\ndesigner's choices based on the way the system's value depends on participation\n(modeled by a ''technology function'' in our framework) and the costs that\nparticipants incur. We identify both bad and good equilibria and identify the\nsettings and the choices that can be made where the designer can influence the\nplayers towards good equilibria in an expedient manner.","main_category":"cs.GT","categories":"cs.GT","published":"2025-05-06T11:10:16Z"}
{"aid":"http://arxiv.org/abs/2505.03434v1","title":"Procedural Memory Is Not All You Need: Bridging Cognitive Gaps in\n  LLM-Based Agents","summary":"Large Language Models (LLMs) represent a landmark achievement in Artificial\nIntelligence (AI), demonstrating unprecedented proficiency in procedural tasks\nsuch as text generation, code completion, and conversational coherence. These\ncapabilities stem from their architecture, which mirrors human procedural\nmemory -- the brain's ability to automate repetitive, pattern-driven tasks\nthrough practice. However, as LLMs are increasingly deployed in real-world\napplications, it becomes impossible to ignore their limitations operating in\ncomplex, unpredictable environments. This paper argues that LLMs, while\ntransformative, are fundamentally constrained by their reliance on procedural\nmemory. To create agents capable of navigating ``wicked'' learning environments\n-- where rules shift, feedback is ambiguous, and novelty is the norm -- we must\naugment LLMs with semantic memory and associative learning systems. By adopting\na modular architecture that decouples these cognitive functions, we can bridge\nthe gap between narrow procedural expertise and the adaptive intelligence\nrequired for real-world problem-solving.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-05-06T11:18:34Z"}
{"aid":"http://arxiv.org/abs/2505.03457v1","title":"Implications of Recent Experimental & Theoretical Results on Electroweak\n  Precision Tests","summary":"I review the results of a recent global fit to electroweak precision data.\nParticular attention is devoted to the landscape of determinations of the weak\nmixing angle, recent results on basic properties of the electroweak gauge\nbosons, and the implications of vacuum polarization on the scale dependences of\nthe electromagnetic coupling and the weak mixing angle, as well as the\nanomalous magnetic moment of the muon.","main_category":"hep-ph","categories":"hep-ph","published":"2025-05-06T11:56:50Z"}
{"aid":"http://arxiv.org/abs/2505.03477v1","title":"A generalised non-linear reconstructor for all Fourier-type wavefront\n  sensors","summary":"State-of-the-art adaptive optics (AO) systems perform non-linear Fourier-type\nwavefront sensing for real-time corrections of dynamic wavefront aberrations.\nThis general class of sensors uses a filtering mask in the focal plane that\nconverts phase fluctuations of the incoming light into intensity variations in\nthe subsequent pupil plane. Due to their high sensitivity, Fourier-type\nwavefront sensors (WFSs) are the sensors of choice for many current and\nupcoming AO systems in ophthalmic imaging, free-space optical communications\n(FSOC) and astronomical ground-based telescopes such as the forthcoming\ngeneration of extremely large telescopes (ELTs). Conventionally, linear\nmethods, like a matrix-vector-multiplication (MVM), are used for the inversion\nof Fourier-type WFSs. However, their non-linear behavior gives rise to severe\nperformance degradations when significant channel perturbations are observed.\nThey are expected to occur during strong atmospheric turbulence conditions,\nwhich are commonplace for non-rural sites and daytime observations.\n  This study presents a novel type of iterative reconstructor to overcome\nnon-linear wavefront sensing regimes. The underlying method is the non-linear\nLandweber iteration with Nesterov acceleration, well known in the field of\ninverse problems. A significant advantage of the new approach is its direct\napplicability to any Fourier-type WFS. This is implemented by adapting the\nfiltering mask of the specific Fourier-type WFSs in the model-based algorithm.\n  Several Fourier-type wavefront sensors are considered for ELT-scale\ninstruments and their performance with the new algorithm is compared. The study\ngoes on to concentrate on the pyramid wavefront sensor (PWFS), one of the most\nwell-known Fourier-type WFSs. We demonstrate in end-to-end simulations that\nthis novel approach outperforms linear methods in non-linear sensing regimes.","main_category":"astro-ph.IM","categories":"astro-ph.IM,math-ph,math.MP","published":"2025-05-06T12:31:40Z"}
{"aid":"http://arxiv.org/abs/2505.03478v1","title":"Allowed and unique first-forbidden stellar electron emission rates of\n  neutron-rich copper isotopes","summary":"The allowed charge-changing transitions are the most common weak interaction\nprocesses of spin-isospin form that play a crucial role in several\nnuclear/astrophysical processes. The first-forbidden (FF) transition becomes\nimportant, in the circumstances where allowed Gamow-Teller (GT) transitions are\nunfavored, specifically for neutron-rich nuclei due to phase space\nconsiderations. In this paper deformed proton-neutron quasi-particle random\nphase approximation (pn-QRPA) model is applied, for the first time, for the\nestimation of allowed GT and unique first-forbidden (U1F) transitions\n($|\\Delta$J$|$ = 2) of neutron rich copper isotopes in mass range 72 $\\leq$ A\n$\\leq$ 82 under stellar conditions. We compared our computed terrestrial\n$\\beta$-decay half-life values with previous calculations and experimental\nresults. It was concluded that the pn-QRPA calculation is in good accordance\nwith measured data. Our study suggests that the addition of rank (0 and 1)\noperators in FF transitions can further improve the comparison which remain\nunattended at this stage. The deformed pn-QRPA model was employed for the\nestimation of GT and U1F stellar electron emission ($\\beta$$^{-}$-decay) rates\nover wide range of stellar temperature (0.01 GK -- 30 GK) and density (10 --\n10$^{11}$ g/cm$^{3}$) domains for astrophysical applications. Our study shows\nthat, in high density and low temperature regions, the contribution of U1F\nrates to total electron emission rates of neutron-rich copper nuclei is\nnegligible.","main_category":"nucl-th","categories":"nucl-th","published":"2025-05-06T12:32:10Z"}
{"aid":"http://arxiv.org/abs/2505.03482v1","title":"Learning-based Homothetic Tube MPC","summary":"In this paper, we study homothetic tube model predictive control (MPC) of\ndiscrete-time linear systems subject to bounded additive disturbance and mixed\nconstraints on the state and input. Different from most existing work on robust\nMPC, we assume that the true disturbance set is unknown but a conservative\nsurrogate is available a priori. Leveraging the real-time data, we develop an\nonline learning algorithm to approximate the true disturbance set. This\napproximation and the corresponding constraints in the MPC optimisation are\nupdated online using computationally convenient linear programs. We provide\nstatistical gaps between the true and learned disturbance sets, based on which,\nprobabilistic recursive feasibility of homothetic tube MPC problems is\ndiscussed. Numerical simulations are provided to demonstrate the efficacy of\nour proposed algorithm and compare with state-of-the-art MPC algorithms.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-05-06T12:37:28Z"}
{"aid":"http://arxiv.org/abs/2505.03485v1","title":"Robust quantum anomalous Hall effect with spatially uncorrelated\n  disorder","summary":"In magnetic topological insulators, a phase transition between quantum\nanomalous Hall (QAH) and Anderson localization insulating phases can be\ntriggered by the rotation of an applied magnetic field. Without the scattering\npaths along magnetic domains, this phase transition is governed by scattering\ninduced by nonmagnetic disorder. We show that the QAH phase is strikingly\nrobust in the presence of spatially uncorrelated disorder. The robustness is\nattributed to a resilience of the topological band gap against disorder,\ninduced by quantum confinement. The critical behavior near the phase transition\nsuggests that the scattering is distinct from quantum percolation. This\nprovides new insights on the robustness of the QAH effect in magnetic\ntopological insulators with atomic defects, impurities, and dopants.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-05-06T12:42:08Z"}
{"aid":"http://arxiv.org/abs/2505.03559v1","title":"Event-Triggered GAT-LSTM Framework for Attack Detection in Heating,\n  Ventilation, and Air Conditioning Systems","summary":"Heating, Ventilation, and Air Conditioning (HVAC) systems are essential for\nmaintaining indoor environmental quality, but their interconnected nature and\nreliance on sensor networks make them vulnerable to cyber-physical attacks.\nSuch attacks can interrupt system operations and risk leaking sensitive\npersonal information through measurement data. In this paper, we propose a\nnovel attack detection framework for HVAC systems, integrating an\nEvent-Triggering Unit (ETU) for local monitoring and a cloud-based\nclassification system using the Graph Attention Network (GAT) and the Long\nShort-Term Memory (LSTM) network. The ETU performs a binary classification to\nidentify potential anomalies and selectively triggers encrypted data\ntransmission to the cloud, significantly reducing communication cost. The\ncloud-side GAT module models the spatial relationships among HVAC components,\nwhile the LSTM module captures temporal dependencies across encrypted state\nsequences to classify the attack type. Our approach is evaluated on datasets\nthat simulate diverse attack scenarios. Compared to GAT-only (94.2% accuracy)\nand LSTM-only (91.5%) ablations, our full GAT-LSTM model achieves 98.8% overall\ndetection accuracy and reduces data transmission to 15%. These results\ndemonstrate that the proposed framework achieves high detection accuracy while\npreserving data privacy by using the spatial-temporal characteristics of HVAC\nsystems and minimizing transmission costs through event-triggered\ncommunication.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-05-06T14:11:36Z"}
{"aid":"http://arxiv.org/abs/2505.03560v1","title":"Rapid AI-based generation of coverage paths for dispensing applications","summary":"Coverage Path Planning of Thermal Interface Materials (TIM) plays a crucial\nrole in the design of power electronics and electronic control units. Up to\nnow, this is done manually by experts or by using optimization approaches with\na high computational effort. We propose a novel AI-based approach to generate\ndispense paths for TIM and similar dispensing applications. It is a drop-in\nreplacement for optimization-based approaches. An Artificial Neural Network\n(ANN) receives the target cooling area as input and directly outputs the\ndispense path. Our proposed setup does not require labels and we show its\nfeasibility on multiple target areas. The resulting dispense paths can be\ndirectly transferred to automated manufacturing equipment and do not exhibit\nair entrapments. The approach of using an ANN to predict process parameters for\na desired target state in real-time could potentially be transferred to other\nmanufacturing processes.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-05-06T14:13:20Z"}
{"aid":"http://arxiv.org/abs/2505.03562v1","title":"Real-Time Person Image Synthesis Using a Flow Matching Model","summary":"Pose-Guided Person Image Synthesis (PGPIS) generates realistic person images\nconditioned on a target pose and a source image. This task plays a key role in\nvarious real-world applications, such as sign language video generation, AR/VR,\ngaming, and live streaming. In these scenarios, real-time PGPIS is critical for\nproviding immediate visual feedback and maintaining user immersion.However,\nachieving real-time performance remains a significant challenge due to the\ncomplexity of synthesizing high-fidelity images from diverse and dynamic human\nposes. Recent diffusion-based methods have shown impressive image quality in\nPGPIS, but their slow sampling speeds hinder deployment in time-sensitive\napplications. This latency is particularly problematic in tasks like generating\nsign language videos during live broadcasts, where rapid image updates are\nrequired. Therefore, developing a fast and reliable PGPIS model is a crucial\nstep toward enabling real-time interactive systems. To address this challenge,\nwe propose a generative model based on flow matching (FM). Our approach enables\nfaster, more stable, and more efficient training and sampling. Furthermore, the\nproposed model supports conditional generation and can operate in latent space,\nmaking it especially suitable for real-time PGPIS applications where both speed\nand quality are critical. We evaluate our proposed method, Real-Time Person\nImage Synthesis Using a Flow Matching Model (RPFM), on the widely used\nDeepFashion dataset for PGPIS tasks. Our results show that RPFM achieves\nnear-real-time sampling speeds while maintaining performance comparable to the\nstate-of-the-art models. Our methodology trades off a slight, acceptable\ndecrease in generated-image accuracy for over a twofold increase in generation\nspeed, thereby ensuring real-time performance.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-05-06T14:13:44Z"}
{"aid":"http://arxiv.org/abs/2505.03582v1","title":"Maximum likelihood estimation for the $Œª$-exponential family","summary":"The $\\lambda$-exponential family generalizes the standard exponential family\nvia a generalized convex duality motivated by optimal transport. It is the\nconstant-curvature analogue of the exponential family from the\ninformation-geometric point of view, but the development of computational\nmethodologies is still in an early stage. In this paper, we propose a fixed\npoint iteration for maximum likelihood estimation under i.i.d.~sampling, and\nprove using the duality that the likelihood is monotone along the iterations.\nWe illustrate the algorithm with the $q$-Gaussian distribution and the\nDirichlet perturbation.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-05-06T14:43:10Z"}
{"aid":"http://arxiv.org/abs/2505.03585v1","title":"Decision Making under Model Misspecification: DRO with Robust Bayesian\n  Ambiguity Sets","summary":"Distributionally Robust Optimisation (DRO) protects risk-averse\ndecision-makers by considering the worst-case risk within an ambiguity set of\ndistributions based on the empirical distribution or a model. To further guard\nagainst finite, noisy data, model-based approaches admit Bayesian formulations\nthat propagate uncertainty from the posterior to the decision-making problem.\nHowever, when the model is misspecified, the decision maker must stretch the\nambiguity set to contain the data-generating process (DGP), leading to overly\nconservative decisions. We address this challenge by introducing DRO with\nRobust, to model misspecification, Bayesian Ambiguity Sets (DRO-RoBAS). These\nare Maximum Mean Discrepancy ambiguity sets centred at a robust posterior\npredictive distribution that incorporates beliefs about the DGP. We show that\nthe resulting optimisation problem obtains a dual formulation in the\nReproducing Kernel Hilbert Space and we give probabilistic guarantees on the\ntolerance level of the ambiguity set. Our method outperforms other Bayesian and\nempirical DRO approaches in out-of-sample performance on the Newsvendor and\nPortfolio problems with various cases of model misspecification.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-05-06T14:46:16Z"}
{"aid":"http://arxiv.org/abs/2505.03625v1","title":"Numerical Reconstruction and Analysis of Backward Semilinear\n  Subdiffusion Problems","summary":"This paper aims to develop and analyze a numerical scheme for solving the\nbackward problem of semilinear subdiffusion equations. We establish the\nexistence, uniqueness, and conditional stability of the solution to the inverse\nproblem by applying the smoothing and asymptotic properties of solution\noperators and constructing a fixed-point iteration. This derived conditional\nstability further inspires a numerical reconstruction scheme. To address the\nmildly ill-posed nature of the problem, we employ the quasi-boundary value\nmethod for regularization. A fully discrete scheme is proposed, utilizing the\nfinite element method for spatial discretization and convolution quadrature for\ntemporal discretization. A thorough error analysis of the resulting discrete\nsystem is provided for both smooth and nonsmooth data. This analysis relies on\nthe smoothing properties of discrete solution operators, some nonstandard error\nestimates optimal with respect to data regularity in the direct problem, and\nthe arguments used in stability analysis. The derived a priori error estimate\noffers guidance for selecting the regularization parameter and discretization\nparameters based on the noise level. Moreover, we propose an easy-to-implement\niterative algorithm for solving the fully discrete scheme and prove its linear\nconvergence. Numerical examples are provided to illustrate the theoretical\nestimates and demonstrate the necessity of the assumption required in the\nanalysis.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-05-06T15:22:31Z"}
{"aid":"http://arxiv.org/abs/2505.03637v1","title":"Stabilizing 3D EPI time series by servo navigation and phase\n  equalization exploiting repeated shots (PEERS)","summary":"Purpose: To enable run-time head motion control and robust frequency\ncorrections for 3D EPI fMRI. Methods: A short 3D orbital navigator (3 ms) is\ninserted into a 3D EPI sequence. A linear perturbation model is calibrated to\nestimate rigid motion and frequency parameters per shot. Rigid motion is\ncorrected by scan geometry updates in run-time, while several techniques are\ninvestigated to stabilize navigator-based frequency corrections in the\nreconstruction. An additional method termed PEERS is proposed that exploits the\nrepetitive structure of fMRI scans to fine-tune shot-wise phase and frequency\nestimates using the motion-corrected EPI data itself. Results: Servo navigation\neffectively reduces motion in the raw data of in-vivo fMRI scans in six\nsubjects. PEERS provides high-precision frequency parameters for robust\nphase-corrected reconstructions in the phantom and in-vivo accounting for\nscanner drifts and slice encoding-related effects on EPI. In combination, servo\nnavigation and PEERS achieve successful intra-volume corrections and consistent\ntSNR improvements of 8% on average throughout the brain. The two methods prove\nto be highly synergetic. Conclusion: Servo navigation achieves high-precision\nmotion correction for 3D-EPI fMRI in run-time and, in synergy with PEERS,\nprovides stable frequency corrections with short navigators even for long echo\ntimes. With its automatic self-calibration and no hardware requirements, servo\nnavigation and PEERS enable effective plug-and-play motion correction for 3D\nfMRI.","main_category":"eess.IV","categories":"eess.IV,physics.med-ph","published":"2025-05-06T15:39:39Z"}
{"aid":"http://arxiv.org/abs/2505.03640v1","title":"Environmental Quantum States Trigger Emission in Nonlinear Photonics","summary":"Light-matter interactions are traditionally governed by two fundamental\nparadigms: spontaneous and stimulated radiation. However, in nonlinear\nmulti-photon regimes, these classical mechanisms break down, revealing new\npossibilities for light emission. Here, we report the discovery of a novel\nmechanism, termed triggered emission, in which an emitter, largely detuned from\nsingle-photon states, is triggered by the quantum state of the environment to\nemit a highly correlated photon pair, doublon. By identifying two critical\nconditions, energy matching and wavefunction overlap, we demonstrate that the\ndynamics of the emitter are profoundly shaped by the environment's quantum\nstate. Using this framework, we construct a novel superposition state\ncomprising a localized single-photon state and a propagating, strongly\ncorrelated two-photon wavepacket. Furthermore, we realize the multi-photon\nunidirectional emission by modulating the emitter and the photon state. Our\nfindings not only deepen the understanding of nonlinear emitter dynamics but\nalso provide a versatile platform for quantum computing and quantum information\nprocessing.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-06T15:40:58Z"}
{"aid":"http://arxiv.org/abs/2505.03653v1","title":"Discovery of resonating integration modes in triple-mode high-amplitude\n  $Œ¥$ Scuti stars: a new evolutionary phase indicator","summary":"High-amplitude $\\delta$ Scuti stars (HADS) that pulsate in their first three\nradial modes are rare in current samples. Here, we analyse five such\ntriple-mode HADS observed by the Transiting Exoplanet Survey Satellite (TESS)\nand report that the previously considered second overtone mode ($f_2$) is\nactually the non-radial component of a resonating integration mode (RI mode,\nresulting from resonance between a radial p-mode and a non-radial p-g mixed\nmode), which shows significant amplitude and frequency variations over short\ntimescales (approximately 20 days). This RI mode appears to be widespread among\nthese stars. Notably, all five stars are in the post-main sequence evolutionary\nphase, actively crossing the Hertzsprung gap. These stars offer valuable\ninsights into stellar evolution during the Hertzsprung gap, which is one of the\nmost rapid evolutionary stages in a star's life.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-05-06T15:59:23Z"}
{"aid":"http://arxiv.org/abs/2505.03664v1","title":"Three-Family Supersymmetric Pati-Salam models from Intersecting\n  D6-Branes on Rigid Cycles","summary":"Intersecting D6-brane models without discrete torsion typically suffer from\nunstabilized open string moduli, arising from D-brane positions and Wilson\nlines. These moduli generate additional massless adjoint fields, obstructing\nthe realization of negative beta functions necessary for asymptotic freedom\nunless they are decoupled around string scale. A viable solution involves\nutilizing rigid cycles, which eliminate these unwanted adjoint fields. In this\nwork, we for the first time present a class of consistent three-family\nsupersymmetric Pati-Salam models from rigid intersecting D6-branes on the\nfactorizable $\\mathbb{T}^6/(\\mathbb{Z}_2 \\times \\mathbb{Z}_2^\\prime)$\norientifold with discrete torsion. These models satisfy all the known\nconsistency conditions, including $\\mathcal{N}=1$ supersymmetry, K-theory\nconstraints, tadpole cancellation, and recent swampland bounds on the maximal\ngauge group rank. We provide detailed particle spectra, analyze their\nphenomenological implications, and discuss the decoupling of exotic states\nthrough strong dynamics in the hidden sector.","main_category":"hep-th","categories":"hep-th","published":"2025-05-06T16:06:35Z"}
{"aid":"http://arxiv.org/abs/2505.03710v1","title":"Actor-Critics Can Achieve Optimal Sample Efficiency","summary":"Actor-critic algorithms have become a cornerstone in reinforcement learning\n(RL), leveraging the strengths of both policy-based and value-based methods.\nDespite recent progress in understanding their statistical efficiency, no\nexisting work has successfully learned an $\\epsilon$-optimal policy with a\nsample complexity of $O(1/\\epsilon^2)$ trajectories with general function\napproximation when strategic exploration is necessary.\n  We address this open problem by introducing a novel actor-critic algorithm\nthat attains a sample-complexity of $O(dH^5 \\log|\\mathcal{A}|/\\epsilon^2 + d\nH^4 \\log|\\mathcal{F}|/ \\epsilon^2)$ trajectories, and accompanying $\\sqrt{T}$\nregret when the Bellman eluder dimension $d$ does not increase with $T$ at more\nthan a $\\log T$ rate.\n  Here, $\\mathcal{F}$ is the critic function class, $\\mathcal{A}$ is the action\nspace, and $H$ is the horizon in the finite horizon MDP setting. Our algorithm\nintegrates optimism, off-policy critic estimation targeting the optimal\nQ-function, and rare-switching policy resets.\n  We extend this to the setting of Hybrid RL, showing that initializing the\ncritic with offline data yields sample efficiency gains compared to purely\noffline or online RL. Further, utilizing access to offline data, we provide a\n\\textit{non-optimistic} provably efficient actor-critic algorithm that only\nadditionally requires $N_{\\text{off}} \\geq c_{\\text{off}}^*dH^4/\\epsilon^2$ in\nexchange for omitting optimism, where $c_{\\text{off}}^*$ is the single-policy\nconcentrability coefficient and $N_{\\text{off}}$ is the number of offline\nsamples. This addresses another open problem in the literature. We further\nprovide numerical experiments to support our theoretical findings.","main_category":"stat.ML","categories":"stat.ML,cs.AI,cs.LG","published":"2025-05-06T17:32:39Z"}
{"aid":"http://arxiv.org/abs/2505.03716v1","title":"Investigating the Upper Scorpius OB association with HERMES. I. The\n  spectroscopic sample and 6D kinematics","summary":"We present results from a large spectroscopic survey of the nearest young\nassociation to the Sun, Upper Scorpius, conducted using 2dF/HERMES on the\nAnglo-Australian Telescope. We use spectroscopic youth criteria such as\nLi-equivalent widths to identify >1000 pre-main sequence (PMS) members across\nthe region and measure radial velocities, combining these with Gaia EDR3\n5-parameter astrometry to obtain 6D kinematic information. We separate\nconfirmed PMS association members into distinct kinematic groups and measure\nexpansion and rotation trends in each. We find strong evidence for asymmetric\nexpansion in several groups and derive expansion timescales from the greatest\nrates of expansion in each group. We also trace the past motion of these groups\nusing an epicycle approximation and estimate the time since their most compact\nconfiguration. These kinematic properties are compared to literature ages and\nthe star formation history of Upper Scorpius is discussed. We find evidence\nthat a scenario in which star formation in the subgroups of Upper Scorpius\nproceeded independently, either by self-instability or external feedback from\nUpper Centaurus-Lupus, is more likely than a recently proposed \"cluster chain\"\nscenario in which these subgroups have triggered each other.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-05-06T17:40:55Z"}
{"aid":"http://arxiv.org/abs/2505.04095v1","title":"Scalable Aerial GNSS Localization for Marine Robots","summary":"Accurate localization is crucial for water robotics, yet traditional onboard\nGlobal Navigation Satellite System (GNSS) approaches are difficult or\nineffective due to signal reflection on the water's surface and its high cost\nof aquatic GNSS receivers. Existing approaches, such as inertial navigation,\nDoppler Velocity Loggers (DVL), SLAM, and acoustic-based methods, face\nchallenges like error accumulation and high computational complexity.\nTherefore, a more efficient and scalable solution remains necessary. This paper\nproposes an alternative approach that leverages an aerial drone equipped with\nGNSS localization to track and localize a marine robot once it is near the\nsurface of the water. Our results show that this novel adaptation enables\naccurate single and multi-robot marine robot localization.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-05-07T03:18:59Z"}
{"aid":"http://arxiv.org/abs/2505.04096v1","title":"Direct Bandgap Photoluminescence of GeSn grown on Si(100) substrate by\n  Molecular Beam Epitaxy Growth","summary":"Group IV alloys of GeSn have gained significant attention for electronic and\noptoelectronic applications on a Si platform due to their compatibility with\nexisting CMOS technology, tunable band structure, and potential for a direct\nbandgap at high Sn concentrations. However, synthesizing Sn-rich GeSn\nstructures remains challenging due to the low solid solubility of Sn in Ge\n(less than 1%) and the substantial lattice mismatch ( about 14%) between Sn and\nGe. In this work, we demonstrate the successful growth of high-quality, relaxed\nGeSn layers with Sn contents of 9.2% and 11.4% on Si(100) substrates via\nmolecular beam epitaxy (MBE). As far as we know, this is the first report of\ndirect bandgap photoluminescence observed from MBE-grown GeSn films without\npost-growth annealing. Structural characterizations including X-ray diffraction\n(XRD), secondary ion mass spectrometry (SIMS), and transmission electron\nmicroscopy (TEM) confirm uniform Sn incorporation with minimal defect\nformation. Atomic force microscopy (AFM) reveals smooth surfaces with low\nroughness. Temperature-dependent photoluminescence (PL) measurements further\nconfirm direct bandgap emission, representing a new stage in the development of\nMBE-grown GeSn.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-05-07T03:21:23Z"}
{"aid":"http://arxiv.org/abs/2505.04150v1","title":"Learning from Similarity Proportion Loss for Classifying Skeletal Muscle\n  Recovery Stages","summary":"Evaluating the regeneration process of damaged muscle tissue is a fundamental\nanalysis in muscle research to measure experimental effect sizes and uncover\nmechanisms behind muscle weakness due to aging and disease. The conventional\napproach to assessing muscle tissue regeneration involves whole-slide imaging\nand expert visual inspection of the recovery stages based on the morphological\ninformation of cells and fibers. There is a need to replace these tasks with\nautomated methods incorporating machine learning techniques to ensure a\nquantitative and objective analysis. Given the limited availability of fully\nlabeled data, a possible approach is Learning from Label Proportions (LLP), a\nweakly supervised learning method using class label proportions. However,\ncurrent LLP methods have two limitations: (1) they cannot adapt the feature\nextractor for muscle tissues, and (2) they treat the classes representing\nrecovery stages and cell morphological changes as nominal, resulting in the\nloss of ordinal information. To address these issues, we propose Ordinal Scale\nLearning from Similarity Proportion (OSLSP), which uses a similarity proportion\nloss derived from two bag combinations. OSLSP can update the feature extractor\nby using class proportion attention to the ordinal scale of the class. Our\nmodel with OSLSP outperforms large-scale pre-trained and fine-tuning models in\nclassification tasks of skeletal muscle recovery stages.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-05-07T06:02:27Z"}
{"aid":"http://arxiv.org/abs/2505.04158v1","title":"FilterTS: Comprehensive Frequency Filtering for Multivariate Time Series\n  Forecasting","summary":"Multivariate time series forecasting is crucial across various industries,\nwhere accurate extraction of complex periodic and trend components can\nsignificantly enhance prediction performance. However, existing models often\nstruggle to capture these intricate patterns. To address these challenges, we\npropose FilterTS, a novel forecasting model that utilizes specialized filtering\ntechniques based on the frequency domain. FilterTS introduces a Dynamic\nCross-Variable Filtering Module, a key innovation that dynamically leverages\nother variables as filters to extract and reinforce shared variable frequency\ncomponents across variables in multivariate time series. Additionally, a Static\nGlobal Filtering Module captures stable frequency components, identified\nthroughout the entire training set. Moreover, the model is built in the\nfrequency domain, converting time-domain convolutions into frequency-domain\nmultiplicative operations to enhance computational efficiency. Extensive\nexperimental results on eight real-world datasets have demonstrated that\nFilterTS significantly outperforms existing methods in terms of prediction\naccuracy and computational efficiency.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-07T06:19:00Z"}
{"aid":"http://arxiv.org/abs/2505.04162v1","title":"SCU-Hand: Soft Conical Universal Robotic Hand for Scooping Granular\n  Media from Containers of Various Sizes","summary":"Automating small-scale experiments in materials science presents challenges\ndue to the heterogeneous nature of experimental setups. This study introduces\nthe SCU-Hand (Soft Conical Universal Robot Hand), a novel end-effector designed\nto automate the task of scooping powdered samples from various container sizes\nusing a robotic arm. The SCU-Hand employs a flexible, conical structure that\nadapts to different container geometries through deformation, maintaining\nconsistent contact without complex force sensing or machine learning-based\ncontrol methods. Its reconfigurable mechanism allows for size adjustment,\nenabling efficient scooping from diverse container types. By combining soft\nrobotics principles with a sheet-morphing design, our end-effector achieves\nhigh flexibility while retaining the necessary stiffness for effective powder\nmanipulation. We detail the design principles, fabrication process, and\nexperimental validation of the SCU-Hand. Experimental validation showed that\nthe scooping capacity is about 20% higher than that of a commercial tool, with\na scooping performance of more than 95% for containers of sizes between 67 mm\nto 110 mm. This research contributes to laboratory automation by offering a\ncost-effective, easily implementable solution for automating tasks such as\nmaterials synthesis and characterization processes.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-07T06:24:34Z"}
{"aid":"http://arxiv.org/abs/2505.04170v1","title":"Toward Riemannian diffeology","summary":"We introduce a framework for Riemannian diffeology. To this end, we use the\ntangent functor in the sense of Blohmann and one of the options of a metric on\na diffeological space in the sense of Iglesias-Zemmour. With a technical\ncondition for a definite Riemannian metric, we show that the psudodistance\ninduced by the metric is indeed a distance. As examples of Riemannian\ndiffeological spaces, an adjunction space of manifolds, a space of smooth maps\nand the mixed one are considered.","main_category":"math.DG","categories":"math.DG,math.CT,math.GT,math.MG","published":"2025-05-07T06:49:02Z"}
{"aid":"http://arxiv.org/abs/2505.04171v1","title":"Large Language Models are often politically extreme, usually\n  ideologically inconsistent, and persuasive even in informational contexts","summary":"Large Language Models (LLMs) are a transformational technology, fundamentally\nchanging how people obtain information and interact with the world. As people\nbecome increasingly reliant on them for an enormous variety of tasks, a body of\nacademic research has developed to examine these models for inherent biases,\nespecially political biases, often finding them small. We challenge this\nprevailing wisdom. First, by comparing 31 LLMs to legislators, judges, and a\nnationally representative sample of U.S. voters, we show that LLMs' apparently\nsmall overall partisan preference is the net result of offsetting extreme views\non specific topics, much like moderate voters. Second, in a randomized\nexperiment, we show that LLMs can promulgate their preferences into political\npersuasiveness even in information-seeking contexts: voters randomized to\ndiscuss political issues with an LLM chatbot are as much as 5 percentage points\nmore likely to express the same preferences as that chatbot. Contrary to\nexpectations, these persuasive effects are not moderated by familiarity with\nLLMs, news consumption, or interest in politics. LLMs, especially those\ncontrolled by private companies or governments, may become a powerful and\ntargeted vector for political influence.","main_category":"cs.CY","categories":"cs.CY,cs.CL","published":"2025-05-07T06:53:59Z"}
{"aid":"http://arxiv.org/abs/2505.04208v1","title":"Diffusion in a wedge geometry: First-Passage Statistics under Stochastic\n  Resetting","summary":"We study the diffusion process in the presence of stochastic resetting inside\na two-dimensional wedge of top angle $\\alpha$, bounded by two infinite\nabsorbing edges. In the absence of resetting, the second moment of the\nfirst-passage time diverges for $\\alpha>\\pi/4$ while it remains finite for\n$\\alpha<\\pi/4$, resulting in an unbounded or bounded coefficient of variation\nin the respective angular regimes. Upon introducing stochastic resetting, we\nanalyze the first-passage properties in both cases and identify the geometric\nconfigurations in which resetting consistently enhances the rate of absorption\nor escape through the boundaries. By deriving the expressions for the\nprobability currents and conditional first-passage quantities such as splitting\nprobabilities and conditional mean first-passage times, we demonstrate how\nresetting can be employed to bias the escape pathway through the favorable\nboundary. Our theoretical predictions are verified through Langevin-type\nnumerical simulations, showing excellent agreement.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-05-07T08:01:54Z"}
{"aid":"http://arxiv.org/abs/2505.04211v1","title":"Omnigenous umbilic stellarators","summary":"To better understand the dependence of the magnetic field structure in the\nplasma edge due to plasma boundary shape, we define and develop umbilic\nstellarators. These equilibria are characterized by a single continuous\nhigh-curvature edge on the plasma boundary that goes around multiple times\ntoroidally before meeting itself. We develop a technique that allows us to\nsimultaneously optimize the plasma boundary along with a curve lying on the\nboundary on which we impose a high curvature while imposing omnigenity -- a\nproperty of the magnetic field that ensures trapped particle confinement\nthroughout the plasma volume. After generating omnigenous umbilic stellarators,\nwe design coil sets for some of these equilibria and calculate and understand\nthe field line structure in the edge. Finally, we propose an experiment to\nmodify an existing tokamak to a stellarator using this technique and explore a\npotential way to convert a limited tokamak into a diverted stellarator.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-05-07T08:05:50Z"}
{"aid":"http://arxiv.org/abs/2505.04218v1","title":"Convergence rate of Euler-Maruyama scheme to the invariant probability\n  measure under total variation distance","summary":"This article shows the geometric decay rate of Euler-Maruyama scheme for\none-dimensional stochastic differential equation towards its invariant\nprobability measure under total variation distance. Firstly, the existence and\nuniqueness of invariant probability measure and the uniform geometric\nergodicity of the chain are studied through introduction of non-atomic Markov\nchains. Secondly, the equivalent conditions for uniform geometric ergodicity of\nthe chain are discovered, by constructing a split Markov chain based on the\noriginal Euler-Maruyama scheme. It turns out that this convergence rate is\nindependent with the step size under total variation distance.","main_category":"math.PR","categories":"math.PR,math.ST,stat.TH","published":"2025-05-07T08:16:57Z"}
{"aid":"http://arxiv.org/abs/2505.04223v1","title":"FRAIN to Train: A Fast-and-Reliable Solution for Decentralized Federated\n  Learning","summary":"Federated learning (FL) enables collaborative model training across\ndistributed clients while preserving data locality. Although FedAvg pioneered\nsynchronous rounds for global model averaging, slower devices can delay\ncollective progress. Asynchronous FL (e.g., FedAsync) addresses stragglers by\ncontinuously integrating client updates, yet naive implementations risk client\ndrift due to non-IID data and stale contributions. Some Blockchain-based FL\napproaches (e.g., BRAIN) employ robust weighting or scoring of updates to\nresist malicious or misaligned proposals. However, performance drops can still\npersist under severe data heterogeneity or high staleness, and synchronization\noverhead has emerged as a new concern due to its aggregator-free architectures.\n  We introduce Fast-and-Reliable AI Network, FRAIN, a new asynchronous FL\nmethod that mitigates these limitations by incorporating two key ideas. First,\nour FastSync strategy eliminates the need to replay past model versions,\nenabling newcomers and infrequent participants to efficiently approximate the\nglobal model. Second, we adopt spherical linear interpolation (SLERP) when\nmerging parameters, preserving models' directions and alleviating destructive\ninterference from divergent local training.\n  Experiments with a CNN image-classification model and a Transformer-based\nlanguage model demonstrate that FRAIN achieves more stable and robust\nconvergence than FedAvg, FedAsync, and BRAIN, especially under harsh\nenvironments: non-IID data distributions, networks that experience delays and\nrequire frequent re-synchronization, and the presence of malicious nodes.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-05-07T08:20:23Z"}
{"aid":"http://arxiv.org/abs/2505.04231v1","title":"Multi-Agent Reinforcement Learning-based Cooperative Autonomous Driving\n  in Smart Intersections","summary":"Unsignalized intersections pose significant safety and efficiency challenges\ndue to complex traffic flows. This paper proposes a novel roadside unit\n(RSU)-centric cooperative driving system leveraging global perception and\nvehicle-to-infrastructure (V2I) communication. The core of the system is an\nRSU-based decision-making module using a two-stage hybrid reinforcement\nlearning (RL) framework. At first, policies are pre-trained offline using\nconservative Q-learning (CQL) combined with behavior cloning (BC) on collected\ndataset. Subsequently, these policies are fine-tuned in the simulation using\nmulti-agent proximal policy optimization (MAPPO), aligned with a self-attention\nmechanism to effectively solve inter-agent dependencies. RSUs perform real-time\ninference based on the trained models to realize vehicle control via V2I\ncommunications. Extensive experiments in CARLA environment demonstrate high\neffectiveness of the proposed system, by: \\textit{(i)} achieving failure rates\nbelow 0.03\\% in coordinating three connected and autonomous vehicles (CAVs)\nthrough complex intersection scenarios, significantly outperforming the\ntraditional Autoware control method, and \\textit{(ii)} exhibiting strong\nrobustness across varying numbers of controlled agents and shows promising\ngeneralization capabilities on other maps.","main_category":"cs.RO","categories":"cs.RO,cs.MA,cs.SY,eess.SY","published":"2025-05-07T08:27:52Z"}
{"aid":"http://arxiv.org/abs/2505.04237v1","title":"Robust Speech Recognition with Schr√∂dinger Bridge-Based Speech\n  Enhancement","summary":"In this work, we investigate application of generative speech enhancement to\nimprove the robustness of ASR models in noisy and reverberant conditions. We\nemploy a recently-proposed speech enhancement model based on Schr\\\"odinger\nbridge, which has been shown to perform well compared to diffusion-based\napproaches. We analyze the impact of model scaling and different sampling\nmethods on the ASR performance. Furthermore, we compare the considered model\nwith predictive and diffusion-based baselines and analyze the speech\nrecognition performance when using different pre-trained ASR models. The\nproposed approach significantly reduces the word error rate, reducing it by\napproximately 40% relative to the unprocessed speech signals and by\napproximately 8% relative to a similarly sized predictive approach.","main_category":"eess.AS","categories":"eess.AS","published":"2025-05-07T08:40:50Z"}
{"aid":"http://arxiv.org/abs/2505.04242v1","title":"Tangential Forces Govern the Viscous-Inertial Transition in Dense\n  Frictional Suspensions","summary":"We present particle-resolved simulations of dense frictional suspensions\nundergoing the viscous-inertial transition using pressure-imposed rheology. By\nvarying the fluid viscosity, shear rate, and granular pressure, we find that\nthe transition is independent of the packing fraction and occurs at a Stokes\nnumber of 10. Our results reveal that the shear stress exhibits a slower\ntransition than the particle pressure, attributed to the combined effect of\ntangential contact and lubrication forces, as the frictional particles\nconcurrently shift from rolling to sliding contacts. This shift is controlled\nby the Stokes number but also by the distance from jamming. Additionally, we\nexamine the role of increasing inter-particle friction on the viscous-inertial\ntransition.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-05-07T08:47:21Z"}
{"aid":"http://arxiv.org/abs/2505.04248v1","title":"On minimal free resolutions of the cover ideals of clique-whiskered\n  graphs","summary":"We explicitly construct a minimal free resolution of the cover ideals of\nclique-whiskered graphs. In particular, Cohen--Macaulay chordal graphs, clique\ncorona graphs, and Cohen--Macaulay Cameron--Walker graphs are examples of\nclique-whiskered graphs. We also introduce multi-clique-whiskered graphs as a\ngeneralization of both clique-whiskered graphs and multi-whisker graphs. We\nprove that multi-clique-whiskered graphs are vertex decomposable and hence\nsequentially Cohen--Macaulay. Moreover, we provide formulas for the projective\ndimension and the Castelnuovo--Mumford regularity of their edge ideals.\nFinally, we construct minimal free resolutions of the cover ideals of both\nmulti-clique-whiskered graphs and very well-covered graphs.","main_category":"math.AC","categories":"math.AC,math.CO","published":"2025-05-07T08:50:06Z"}
{"aid":"http://arxiv.org/abs/2505.04268v1","title":"Sign competing sources of Berry curvature and anomalous Hall conductance\n  humps in topological ferromagnets","summary":"The use of Berry-phase concepts has established a strong link between the\nanomalous Hall effect (AHE) and the topological character of the Hall currents.\nHowever, the occurrence of sign competition in the Berry curvature often\nhinders the topological origin of the observed anomalous Hall effects. Here, we\nstudy a two-dimensional topological ferromagnet with coupled spin and orbital\ndegrees of freedom to assess the anomalous Hall effects in the presence of\nsign-competing sources of Berry curvature. We show that 2D itinerant\ntopological ferromagnets described by t2g electronic states can generally lead\nto topological metallic bands marked by a non-zero Chern number. We find that\nthe resulting Berry curvature at the Fermi level exhibits a characteristic\nanisotropic profile with a non-monotonous angular dependence when the\nmagnetization is reversed. The sign change of the intrinsic contribution to the\nanomalous Hall conductance can occur together with topological transitions or\nbe driven by the population imbalance of the topological bands. The breaking of\nthe inversion symmetry introduces the orbital Rashba coupling in the system.\nThe interplay between the orbital Rashba and sign competing sources of Berry\ncurvature leads to anomalies in the anomalous Hall conductance at values of\nmagnetic fields for which the magnetization switches its orientation. The humps\nin topological ferromagnets arise when the anomalous Hall conductivity is small\nin absolute value and they can be detected only close to the sign-change of the\nAHE and far from half-filling. This study could be relevant for the family of\nthe topological 2D ferromagnets as well as Weyl ferromagnets, and can\nparticularly account for the variety of unconventional behaviors observed in\nultrathin films of SrRuO$_3$.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mes-hall","published":"2025-05-07T09:19:25Z"}
{"aid":"http://arxiv.org/abs/2505.04272v1","title":"Joint Task Offloading and Channel Allocation in Spatial-Temporal Dynamic\n  for MEC Networks","summary":"Computation offloading and resource allocation are critical in mobile edge\ncomputing (MEC) systems to handle the massive and complex requirements of\napplications restricted by limited resources. In a multi-user multi-server MEC\nnetwork, the mobility of terminals causes computing requests to be dynamically\ndistributed in space. At the same time, the non-negligible dependencies among\ntasks in some specific applications impose temporal correlation constraints on\nthe solution as well, leading the time-adjacent tasks to experience varying\nresource availability and competition from parallel counterparts. To address\nsuch dynamic spatial-temporal characteristics as a challenge in the allocation\nof communication and computation resources, we formulate a long-term\ndelay-energy trade-off cost minimization problem in the view of jointly\noptimizing task offloading and resource allocation. We begin by designing a\npriority evaluation scheme to decouple task dependencies and then develop a\ngrouped Knapsack problem for channel allocation considering the current data\nload and channel status. Afterward, in order to meet the rapid response needs\nof MEC systems, we exploit the double duel deep Q network (D3QN) to make\noffloading decisions and integrate channel allocation results into the reward\nas part of the dynamic environment feedback in D3QN, constituting the joint\noptimization of task offloading and channel allocation. Finally, comprehensive\nsimulations demonstrate the performance of the proposed algorithm in the\ndelay-energy trade-off cost and its adaptability for various applications.","main_category":"cs.NI","categories":"cs.NI","published":"2025-05-07T09:21:54Z"}
{"aid":"http://arxiv.org/abs/2505.04298v1","title":"Magnetization-resolved density of states and quasi-first order\n  transition in the two-dimensional random bond Ising model: an entropic\n  sampling study","summary":"Systems with quenched disorder possess complex energy landscapes that are\nchallenging to explore under the conventional Monte Carlo method. In this work,\nwe implement an efficient entropy sampling scheme for accurate computation of\nthe entropy function in low-energy regions. The method is applied to the\ntwo-dimensional $\\pm J$ random-bond Ising model, where frustration is\ncontrolled by the fraction $p$ of ferromagnetic bonds. We investigate the\nlow-temperature paramagnetic--ferromagnetic phase boundary below the\nmulticritical point at $T_N = 0.9530(4)$, $P_N = 0.89078(8)$, as well as the\nzero-temperature ferromagnetic--spin-glass transition. Finite-size scaling\nanalysis reveals that the phase boundary for $T < T_N$ exhibits reentrant\nbehavior. By analyzing the evolution of the magnetization-resolved density of\nstates $g(E, M)$ and ground-state spin configurations against increasing\nfrustration, we provide strong evidence that the zero-temperature transition is\nquasi-first order. Finite-size scaling conducted on the spin-glass side\nsupports the validity of $\\beta = 0$, with a correlation length exponent $\\nu =\n1.50(8)$. Our results provide new insights into the nature of the\nferromagnetic-to-spin-glass phase transition in an extensively degenerate\nground state.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.stat-mech","published":"2025-05-07T10:10:34Z"}
{"aid":"http://arxiv.org/abs/2505.04310v1","title":"Flow Models for Unbounded and Geometry-Aware Distributional\n  Reinforcement Learning","summary":"We introduce a new architecture for Distributional Reinforcement Learning\n(DistRL) that models return distributions using normalizing flows. This\napproach enables flexible, unbounded support for return distributions, in\ncontrast to categorical approaches like C51 that rely on fixed or bounded\nrepresentations. It also offers richer modeling capacity to capture\nmulti-modality, skewness, and tail behavior than quantile based approaches. Our\nmethod is significantly more parameter-efficient than categorical approaches.\nStandard metrics used to train existing models like KL divergence or\nWasserstein distance either are scale insensitive or have biased sample\ngradients, especially when return supports do not overlap. To address this, we\npropose a novel surrogate for the Cram\\`er distance, that is geometry-aware and\ncomputable directly from the return distribution's PDF, avoiding the costly CDF\ncomputation. We test our model on the ATARI-5 sub-benchmark and show that our\napproach outperforms PDF based models while remaining competitive with quantile\nbased methods.","main_category":"cs.AI","categories":"cs.AI,math.OC","published":"2025-05-07T10:49:53Z"}
{"aid":"http://arxiv.org/abs/2505.04324v1","title":"Towards Federated Digital Twin Platforms","summary":"Digital Twin (DT) technology has become rather popular in recent years,\npromising to optimize production processes, manage the operation of\ncyber-physical systems, with an impact spanning across multiple application\ndomains (e.g., manufacturing, robotics, space etc.). DTs can include different\nkinds of assets, e.g., models, data, which could potentially be reused across\nDT projects by multiple users, directly affecting development costs, as well as\nenabling collaboration and further development of these assets. To provide user\nsupport for these purposes, dedicated DT frameworks and platforms are required,\nthat take into account user needs, providing the infrastructure and building\nblocks for DT development and management. In this demo paper, we show how the\nDT as a Service (DTaaS) platform has been extended to enable a federated\napproach to DT development and management, that allows multiple users across\nmultiple instances of DTaaS to discover, reuse, reconfigure, and modify\nexisting DT assets.","main_category":"cs.SE","categories":"cs.SE","published":"2025-05-07T11:13:15Z"}
{"aid":"http://arxiv.org/abs/2505.04325v1","title":"Jet Quenching in Heavy-Ion Collisions at RHIC and the LHC experiments","summary":"Jet quenching serves as a key probes of the Quark-Gluon Plasma (QGP) in\nheavy-ion collisions. This proceedings presents recent results from RHIC and\nLHC on jet energy loss, acoplanarity, and the flavour and path-length\ndependence of Parton energy loss, providing critical constraints on QGP\nproperties and theoretical models. Upcoming data taking campaigns at RHIC and\nthe LHC will offer enhanced precision and extended kinematic reach to further\nadvance our understanding of jet-medium interactions.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex,hep-ph","published":"2025-05-07T11:15:33Z"}
{"aid":"http://arxiv.org/abs/2505.04326v1","title":"Design and Evaluation of an NDN-Based Network for Distributed Digital\n  Twins","summary":"Digital twins (DT) have received significant attention due to their numerous\nbenefits, such as real-time data analytics and cost reduction in production. DT\nserves as a fundamental component of many applications, encompassing smart\nmanufacturing, intelligent vehicles, and smart cities. By using Machine\nLearning (ML) and Artificial Intelligence (AI) techniques, DTs can efficiently\nfacilitate decision-making and productivity by simulating the status and\nchanges of a physical entity. To handle the massive amount of data brought by\nDTs, it is challenging to achieve low response latency for data fetching over\nexisting IP-based networks. IP-based networks use host addresses for end-to-end\ncommunication, making data distribution between DTs inefficient. Thus, we\npropose to use DTs in a distributed manner over Named Data Networking (NDN)\nnetworks. NDN is data-centric where data is routed based on content names,\ndynamically adjusting paths to optimize latency. Popular data is cached in\nnetwork nodes, reducing data transmission and network congestion. Since data is\nfetched by content names, users and mobile devices can move freely without IP\naddress reassignment. By using in-network caching and adaptive routing, we\nreckon NDN is an ideal fit for Future G Networks in the context of Digital\nTwins. We compared DTs in edge scenarios with cloud scenarios over NDN and\nIP-based networks to validate our insights. Extensive simulation results show\nthat using DT in the edge reduces response latency by 10.2x. This position\npaper represents an initial investigation into the gap in distributed DTs over\nNDN, serving as an early-stage study.","main_category":"cs.NI","categories":"cs.NI","published":"2025-05-07T11:21:12Z"}
{"aid":"http://arxiv.org/abs/2505.04341v1","title":"PAC-Bayesian risk bounds for fully connected deep neural network with\n  Gaussian priors","summary":"Deep neural networks (DNNs) have emerged as a powerful methodology with\nsignificant practical successes in fields such as computer vision and natural\nlanguage processing. Recent works have demonstrated that sparsely connected\nDNNs with carefully designed architectures can achieve minimax estimation rates\nunder classical smoothness assumptions. However, subsequent studies revealed\nthat simple fully connected DNNs can achieve comparable convergence rates,\nchallenging the necessity of sparsity. Theoretical advances in Bayesian neural\nnetworks (BNNs) have been more fragmented. Much of those work has concentrated\non sparse networks, leaving the theoretical properties of fully connected BNNs\nunderexplored. In this paper, we address this gap by investigating fully\nconnected Bayesian DNNs with Gaussian prior using PAC-Bayes bounds. We\nestablish upper bounds on the prediction risk for a probabilistic deep neural\nnetwork method, showing that these bounds match (up to logarithmic factors) the\nminimax-optimal rates in Besov space, for both nonparametric regression and\nbinary classification with logistic loss. Importantly, our results hold for a\nbroad class of practical activation functions that are Lipschitz continuous.","main_category":"math.ST","categories":"math.ST,stat.ML,stat.TH","published":"2025-05-07T11:42:18Z"}
{"aid":"http://arxiv.org/abs/2505.04363v1","title":"Rotation-Induced Orbital Currents in Ferro-Rotational Systems","summary":"Generation of orbital angular momentum has become important to effectuate new\nways to address switchable magnetic devices. Here, we demonstrate the\nelectrical generation of unconventional orbital currents in ferro-rotational\nsystems through an intrinsic, nonrelativistic mechanism associated with an\nelectric hexadecapole moment. These rotation-induced orbital currents are\nexamined using tight-binding models, and we also provide first-principles\ncalculations for the ferro-rotational material TiAu$_4$. Our findings unveil a\nnovel pathway for generating orbital currents beyond the conventional orbital\nHall effect, broadening the landscape of orbitronics research to include novel\nferroic materials and higher-order electric multipoles.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-05-07T12:29:53Z"}
{"aid":"http://arxiv.org/abs/2505.04414v1","title":"A Powerful Chi-Square Specification Test with Support Vectors","summary":"Specification tests, such as Integrated Conditional Moment (ICM) and Kernel\nConditional Moment (KCM) tests, are crucial for model validation but often lack\npower in finite samples. This paper proposes a novel framework to enhance\nspecification test performance using Support Vector Machines (SVMs) for\ndirection learning. We introduce two alternative SVM-based approaches: one\nmaximizes the discrepancy between nonparametric and parametric classes, while\nthe other maximizes the separation between residuals and the origin. Both\napproaches lead to a $t$-type test statistic that converges to a standard\nchi-square distribution under the null hypothesis. Our method is\ncomputationally efficient and capable of detecting any arbitrary alternative.\nSimulation studies demonstrate its superior performance compared to existing\nmethods, particularly in large-dimensional settings.","main_category":"econ.EM","categories":"econ.EM","published":"2025-05-07T13:51:00Z"}
{"aid":"http://arxiv.org/abs/2505.04445v1","title":"M2Rec: Multi-scale Mamba for Efficient Sequential Recommendation","summary":"Sequential recommendation systems aim to predict users' next preferences\nbased on their interaction histories, but existing approaches face critical\nlimitations in efficiency and multi-scale pattern recognition. While\nTransformer-based methods struggle with quadratic computational complexity,\nrecent Mamba-based models improve efficiency but fail to capture periodic user\nbehaviors, leverage rich semantic information, or effectively fuse multimodal\nfeatures. To address these challenges, we propose \\model, a novel sequential\nrecommendation framework that integrates multi-scale Mamba with Fourier\nanalysis, Large Language Models (LLMs), and adaptive gating. First, we enhance\nMamba with Fast Fourier Transform (FFT) to explicitly model periodic patterns\nin the frequency domain, separating meaningful trends from noise. Second, we\nincorporate LLM-based text embeddings to enrich sparse interaction data with\nsemantic context from item descriptions. Finally, we introduce a learnable gate\nmechanism to dynamically balance temporal (Mamba), frequency (FFT), and\nsemantic (LLM) features, ensuring harmonious multimodal fusion. Extensive\nexperiments demonstrate that \\model\\ achieves state-of-the-art performance,\nimproving Hit Rate@10 by 3.2\\% over existing Mamba-based models while\nmaintaining 20\\% faster inference than Transformer baselines. Our results\nhighlight the effectiveness of combining frequency analysis, semantic\nunderstanding, and adaptive fusion for sequential recommendation. Code and\ndatasets are available at: https://anonymous.4open.science/r/M2Rec.","main_category":"cs.IR","categories":"cs.IR","published":"2025-05-07T14:14:29Z"}
{"aid":"http://arxiv.org/abs/2505.04483v1","title":"Function theory on the annulus in the dp-norm","summary":"In this paper we shall use realization theory to prove new results about a\nclass of holomorphic functions on an annulus \\[R_\\delta \\stackrel{\\rm def}{=}\n\\{z \\in \\mathbb{C}: \\delta <|z|<1\\},\\] where $0<\\delta<1$. The class of\nfunctions in question arises in the early work of R. G. Douglas and V. I.\nPaulsen on the rational dilation of a Hilbert space operator $T$ to a normal\noperator with spectrum in $\\partial R_\\delta$. Their work suggested the\nfollowing norm $\\|\\cdot\\|_{\\mathrm{dp}}$ on the space $\\mathrm{Hol}(R_\\delta)$\nof holomorphic functions on $R_\\delta$, \\[ \\|\\phi\\|_{\\mathrm{dp}} \\stackrel{\\rm\ndef}{=} \\sup\\{ \\|\\phi(T)\\|: \\|T\\|\\leq 1, \\|T^{-1} \\|\\leq 1/\\delta \\ \\text{and}\n\\ \\sigma(T)\\subseteq R_\\delta\\}.\\] By analogy with the classical Schur class of\nholomorphic functions $\\mathcal{S} $ with supremum norm at most $1$ on the disc\n$\\mathbb{D}$, it is natural to consider the dp-Schur class\n$\\mathcal{S}_\\mathrm{dp}$ of holomorphic functions of dp-norm at most $1$ on\n$R_\\delta$.\n  Our central result is a generalization of the classical realization formula,\nfor $\\phi \\in \\mathcal{S} $, to functions from $\\mathcal{S}_\\mathrm{dp}$. A\nsecond result is a Pick interpolation theorem for functions in\n$\\mathcal{S}_\\mathrm{dp}$ that is analogous to Abrahamse's Interpolation\nTheorem for bounded holomorphic functions on a multiply-connected domain. For a\ntuple $\\lambda=(\\lambda_1,\\dots,\\lambda_n)$ of distinct interpolation nodes in\n$R_\\delta$, we introduce a special set $\\mathcal{G}_{\\mathrm {dp}}(\\lambda)$ of\npositive definite $n\\times n$ matrices, which we call DP Szeg\\H{o} kernels. The\nDP Pick problem $\\lambda_j \\mapsto z_j, j=1,\\dots,n$, is shown to be solvable\nif and only if, \\[ [(1-\\bar z_i z_j)g_{ij}] \\ge 0 \\; \\text{ for all}\\; g \\in\n\\mathcal{G}_{\\mathrm {dp}} (\\lambda).\\] We prove further that a solvable DP\nPick problem has a solution which is a rational function.","main_category":"math.CV","categories":"math.CV","published":"2025-05-07T14:53:31Z"}
{"aid":"http://arxiv.org/abs/2505.04485v1","title":"FA-KPConv: Introducing Euclidean Symmetries to KPConv via Frame\n  Averaging","summary":"We present Frame-Averaging Kernel-Point Convolution (FA-KPConv), a neural\nnetwork architecture built on top of the well-known KPConv, a widely adopted\nbackbone for 3D point cloud analysis. Even though invariance and/or\nequivariance to Euclidean transformations are required for many common tasks,\nKPConv-based networks can only approximately achieve such properties when\ntraining on large datasets or with significant data augmentations. Using Frame\nAveraging, we allow to flexibly customize point cloud neural networks built\nwith KPConv layers, by making them exactly invariant and/or equivariant to\ntranslations, rotations and/or reflections of the input point clouds. By simply\nwrapping around an existing KPConv-based network, FA-KPConv embeds geometrical\nprior knowledge into it while preserving the number of learnable parameters and\nnot compromising any input information. We showcase the benefit of such an\nintroduced bias for point cloud classification and point cloud registration,\nespecially in challenging cases such as scarce training data or randomly\nrotated test data.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-07T14:58:04Z"}
{"aid":"http://arxiv.org/abs/2505.04513v1","title":"Complementary legs and symplectic rational balls","summary":"We completely characterize when a small Seifert fibered space with\ncomplementary legs symplectically bounds a rational homology ball in the case\n$e_0\\leq -1$, and we establish strong obstructions for other values of $e_0$.\nOur results highlight a sharp contrast with the smooth category, where many\nmore such Seifert fibered spaces are known to bound smooth rational homology\nballs. We also complete the classification of contact structures on spherical\n$3$-manifolds with either orientations that admit symplectic rational homology\nball fillings.","main_category":"math.GT","categories":"math.GT,math.SG","published":"2025-05-07T15:37:30Z"}
{"aid":"http://arxiv.org/abs/2505.04521v1","title":"Comparative Analysis of Carbon Footprint in Manual vs. LLM-Assisted Code\n  Development","summary":"Large Language Models (LLM) have significantly transformed various domains,\nincluding software development. These models assist programmers in generating\ncode, potentially increasing productivity and efficiency. However, the\nenvironmental impact of utilising these AI models is substantial, given their\nhigh energy consumption during both training and inference stages. This\nresearch aims to compare the energy consumption of manual software development\nversus an LLM-assisted approach, using Codeforces as a simulation platform for\nsoftware development. The goal is to quantify the environmental impact and\npropose strategies for minimising the carbon footprint of using LLM in software\ndevelopment. Our results show that the LLM-assisted code generation leads on\naverage to 32.72 higher carbon footprint than the manual one. Moreover, there\nis a significant correlation between task complexity and the difference in the\ncarbon footprint of the two approaches.","main_category":"cs.SE","categories":"cs.SE","published":"2025-05-07T15:52:06Z"}
{"aid":"http://arxiv.org/abs/2505.04594v1","title":"MonoCoP: Chain-of-Prediction for Monocular 3D Object Detection","summary":"Accurately predicting 3D attributes is crucial for monocular 3D object\ndetection (Mono3D), with depth estimation posing the greatest challenge due to\nthe inherent ambiguity in mapping 2D images to 3D space. While existing methods\nleverage multiple depth cues (e.g., estimating depth uncertainty, modeling\ndepth error) to improve depth accuracy, they overlook that accurate depth\nprediction requires conditioning on other 3D attributes, as these attributes\nare intrinsically inter-correlated through the 3D to 2D projection, which\nultimately limits overall accuracy and stability. Inspired by Chain-of-Thought\n(CoT) in large language models (LLMs), this paper proposes MonoCoP, which\nleverages a Chain-of-Prediction (CoP) to predict attributes sequentially and\nconditionally via three key designs. First, it employs a lightweight\nAttributeNet (AN) for each 3D attribute to learn attribute-specific features.\nNext, MonoCoP constructs an explicit chain to propagate these learned features\nfrom one attribute to the next. Finally, MonoCoP uses a residual connection to\naggregate features for each attribute along the chain, ensuring that later\nattribute predictions are conditioned on all previously processed attributes\nwithout forgetting the features of earlier ones. Experimental results show that\nour MonoCoP achieves state-of-the-art (SoTA) performance on the KITTI\nleaderboard without requiring additional data and further surpasses existing\nmethods on the Waymo and nuScenes frontal datasets.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-07T17:37:23Z"}
{"aid":"http://arxiv.org/abs/2505.04612v1","title":"FastMap: Revisiting Dense and Scalable Structure from Motion","summary":"We propose FastMap, a new global structure from motion method focused on\nspeed and simplicity. Previous methods like COLMAP and GLOMAP are able to\nestimate high-precision camera poses, but suffer from poor scalability when the\nnumber of matched keypoint pairs becomes large. We identify two key factors\nleading to this problem: poor parallelization and computationally expensive\noptimization steps. To overcome these issues, we design an SfM framework that\nrelies entirely on GPU-friendly operations, making it easily parallelizable.\nMoreover, each optimization step runs in time linear to the number of image\npairs, independent of keypoint pairs or 3D points. Through extensive\nexperiments, we show that FastMap is one to two orders of magnitude faster than\nCOLMAP and GLOMAP on large-scale scenes with comparable pose accuracy.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-07T17:56:15Z"}
{"aid":"http://arxiv.org/abs/2505.04625v1","title":"First Observations of Solar Halo Gamma Rays Over a Full Solar Cycle","summary":"We analyze 15 years of Fermi-LAT data and produce a detailed model of the\nSun's inverse-Compton scattering emission (solar halo), which is powered by\ninteractions between ambient cosmic-ray electrons and positrons with sunlight.\nBy developing a novel analysis method to analyze moving sources, we robustly\ndetect the solar halo at energies between 31.6 MeV and 100 GeV, and angular\nextensions up to 45$^\\circ$ from the Sun, providing new insight into spatial\nregions where there are no direct measurements of the galactic cosmic-ray flux.\nThe large statistical significance of our signal allows us to sub-divide the\ndata and provide the first $\\gamma$-ray probes into the time-variation and\nazimuthal asymmetry of the solar modulation potential, finding time-dependent\nchanges in solar modulation both parallel and perpendicular to the ecliptic\nplane. Our results are consistent with (but with independent uncertainties\nfrom) local cosmic-ray measurements, unlocking new probes into both\nastrophysical and beyond-standard-model processes near the solar surface.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.SR,hep-ph","published":"2025-05-07T17:59:59Z"}
{"aid":"http://arxiv.org/abs/2505.04914v1","title":"Enigme: Generative Text Puzzles for Evaluating Reasoning in Language\n  Models","summary":"Transformer-decoder language models are a core innovation in text based\ngenerative artificial intelligence. These models are being deployed as\ngeneral-purpose intelligence systems in many applications. Central to their\nutility is the capacity to understand natural language commands and exploit the\nreasoning embedded in human text corpora to apply some form of reasoning\nprocess to a wide variety of novel tasks. To understand the limitations of this\napproach to generating reasoning we argue that we need to consider the\narchitectural constraints of these systems. Consideration of the latent\nvariable structure of transformer-decoder models allows us to design reasoning\ntasks that should probe the boundary of their capacity to reason. We present\nenigme, an open-source library for generating text-based puzzles to be used in\ntraining and evaluating reasoning skills within transformer-decoder models and\nfuture AI architectures.","main_category":"cs.AI","categories":"cs.AI,cs.CL,I.2.7","published":"2025-05-08T03:09:57Z"}
{"aid":"http://arxiv.org/abs/2505.04921v1","title":"Perception, Reason, Think, and Plan: A Survey on Large Multimodal\n  Reasoning Models","summary":"Reasoning lies at the heart of intelligence, shaping the ability to make\ndecisions, draw conclusions, and generalize across domains. In artificial\nintelligence, as systems increasingly operate in open, uncertain, and\nmultimodal environments, reasoning becomes essential for enabling robust and\nadaptive behavior. Large Multimodal Reasoning Models (LMRMs) have emerged as a\npromising paradigm, integrating modalities such as text, images, audio, and\nvideo to support complex reasoning capabilities and aiming to achieve\ncomprehensive perception, precise understanding, and deep reasoning. As\nresearch advances, multimodal reasoning has rapidly evolved from modular,\nperception-driven pipelines to unified, language-centric frameworks that offer\nmore coherent cross-modal understanding. While instruction tuning and\nreinforcement learning have improved model reasoning, significant challenges\nremain in omni-modal generalization, reasoning depth, and agentic behavior. To\naddress these issues, we present a comprehensive and structured survey of\nmultimodal reasoning research, organized around a four-stage developmental\nroadmap that reflects the field's shifting design philosophies and emerging\ncapabilities. First, we review early efforts based on task-specific modules,\nwhere reasoning was implicitly embedded across stages of representation,\nalignment, and fusion. Next, we examine recent approaches that unify reasoning\ninto multimodal LLMs, with advances such as Multimodal Chain-of-Thought (MCoT)\nand multimodal reinforcement learning enabling richer and more structured\nreasoning chains. Finally, drawing on empirical insights from challenging\nbenchmarks and experimental cases of OpenAI O3 and O4-mini, we discuss the\nconceptual direction of native large multimodal reasoning models (N-LMRMs),\nwhich aim to support scalable, agentic, and adaptive reasoning and planning in\ncomplex, real-world environments.","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-05-08T03:35:23Z"}
{"aid":"http://arxiv.org/abs/2505.04945v1","title":"Superconductivity in Spin-Orbit coupled SU(8) Dirac Fermions on\n  Honeycomb lattice","summary":"We study superconducting (SC) phases that are naturally proximate to a\nspin-orbit coupled SU(8) Dirac semi-metal on a honeycomb lattice. This system,\nwhich offers enhanced low-energy symmetries, presents an interesting platform\nfor realizing unconventional superconductivity in j=3/2 electrons. In\nparticular, we find 72 superconducting charge-$2e$ fermion bilinears which,\nunder classification of microscopic symmetries, lead to 12 different SCs --\nfour singlets, two doublets, and six triplets -- 7 of them are gapped and 5 are\nsymmetry-protected nodal SCs. The strong spin-orbit coupling leads to locking\nof the spin of the Cooper pairs with real-space direction -- as is evident from\nthe structure of the Cooper pair wave-functions -- leading to unusual\nnon-unitary superconductors (even singlets), and with finite momentum pairing\n(for the triplets). This results, in many cases, in the magnitude of multiple\npairing gaps being intricately dependent on the direction of the SC\norder-parameter. The present classification of SCs along with normal phases\n(Phys. Rev. B 108, 245106 (2023)) provides the complete list of naturally\noccurring phases in the vicinity of such a SU(8) Dirac semi-metal. This study\nallows for understanding the global phase diagram of such systems, stimulating\nfurther experimental work on candidate materials such as metallic halides\n(MX$_3$ with M=Zr, Hf, and X=Cl, Br). Further, it provides the starting point\nfor the exploration of unconventional phase transitions in such systems.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.supr-con,hep-th","published":"2025-05-08T04:49:32Z"}
{"aid":"http://arxiv.org/abs/2505.04950v1","title":"Position: Epistemic Artificial Intelligence is Essential for Machine\n  Learning Models to Know When They Do Not Know","summary":"Despite the impressive achievements of AI, including advancements in\ngenerative models and large language models, there remains a significant gap in\nthe ability of AI to handle uncertainty and generalize beyond the training\ndata. We argue that AI models, especially in autonomous systems, fail to make\nrobust predictions when faced with unfamiliar or adversarial data, as evidenced\nby incidents with autonomous vehicles. Traditional machine learning approaches\nstruggle to address these issues due to an overemphasis on data fitting and\ndomain adaptation. This position paper posits a paradigm shift towards\nepistemic artificial intelligence, emphasizing the need for models to learn not\nonly from what they know but also from their ignorance. This approach, which\nfocuses on recognizing and managing uncertainty, offers a potential solution to\nimprove the resilience and robustness of AI systems, ensuring that they can\nbetter handle unpredictable real-world environments.","main_category":"cs.AI","categories":"cs.AI","published":"2025-05-08T05:10:38Z"}
{"aid":"http://arxiv.org/abs/2505.04977v1","title":"ChainMarks: Securing DNN Watermark with Cryptographic Chain","summary":"With the widespread deployment of deep neural network (DNN) models, dynamic\nwatermarking techniques are being used to protect the intellectual property of\nmodel owners. However, recent studies have shown that existing watermarking\nschemes are vulnerable to watermark removal and ambiguity attacks. Besides, the\nvague criteria for determining watermark presence further increase the\nlikelihood of such attacks. In this paper, we propose a secure DNN watermarking\nscheme named ChainMarks, which generates secure and robust watermarks by\nintroducing a cryptographic chain into the trigger inputs and utilizes a\ntwo-phase Monte Carlo method for determining watermark presence. First,\nChainMarks generates trigger inputs as a watermark dataset by repeatedly\napplying a hash function over a secret key, where the target labels associated\nwith trigger inputs are generated from the digital signature of model owner.\nThen, the watermarked model is produced by training a DNN over both the\noriginal and watermark datasets. To verify watermarks, we compare the predicted\nlabels of trigger inputs with the target labels and determine ownership with a\nmore accurate decision threshold that considers the classification probability\nof specific models. Experimental results show that ChainMarks exhibits higher\nlevels of robustness and security compared to state-of-the-art watermarking\nschemes. With a better marginal utility, ChainMarks provides a higher\nprobability guarantee of watermark presence in DNN models with the same level\nof watermark accuracy.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-05-08T06:30:46Z"}
{"aid":"http://arxiv.org/abs/2505.04989v1","title":"CPP-DIP: Multi-objective Coverage Path Planning for MAVs in Dispersed\n  and Irregular Plantations","summary":"Coverage Path Planning (CPP) is vital in precision agriculture to improve\nefficiency and resource utilization. In irregular and dispersed plantations,\ntraditional grid-based CPP often causes redundant coverage over non-vegetated\nareas, leading to waste and pollution. To overcome these limitations, we\npropose CPP-DIP, a multi-objective CPP framework designed for Micro Air\nVehicles (MAVs). The framework transforms the CPP task into a Traveling\nSalesman Problem (TSP) and optimizes flight paths by minimizing travel\ndistance, turning angles, and intersection counts. Unlike conventional\napproaches, our method does not rely on GPS-based environmental modeling.\nInstead, it uses aerial imagery and a Histogram of Oriented Gradients\n(HOG)-based approach to detect trees and extract image coordinates. A\ndensity-aware waypoint strategy is applied: Kernel Density Estimation (KDE) is\nused to reduce redundant waypoints in dense regions, while a greedy algorithm\nensures complete coverage in sparse areas. To verify the generality of the\nframework, we solve the resulting TSP using three different methods: Greedy\nHeuristic Insertion (GHI), Ant Colony Optimization (ACO), and Monte Carlo\nReinforcement Learning (MCRL). Then an object-based optimization is applied to\nfurther refine the resulting path. Additionally, CPP-DIP integrates ForaNav,\nour insect-inspired navigation method, for accurate tree localization and\ntracking. The experimental results show that MCRL offers a balanced solution,\nreducing the travel distance by 16.9 % compared to ACO while maintaining a\nsimilar performance to GHI. It also improves path smoothness by reducing\nturning angles by 28.3 % and 59.9 % relative to ACO and GHI, respectively, and\neffectively eliminates intersections. These results confirm the robustness and\neffectiveness of CPP-DIP in different TSP solvers.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-08T06:52:22Z"}
{"aid":"http://arxiv.org/abs/2505.05005v1","title":"A note on the irrationality of $Œ∂_2(5)$","summary":"In a spirit of Ap\\'ery's proof of the irrationality of $\\zeta(3)$, we\nconstruct a sequence $p_n/q_n$ of rational approximations to the $2$-adic zeta\nvalue $\\zeta_2(5)$ which satisfy $0 < |\\zeta_2(5)-p_n/q_n|_2 <\n\\max\\{|p_n|,|q_n|\\}^{-1-\\delta}$ for an explicit constant $\\delta>0$. This\nleads to a new proof of the irrationality of $\\zeta_2(5)$, the result\nestablished recently by Calegari, Dimitrov and Tang using a different method.\nFurthermore, our approximations allow us to obtain an upper bound for the\nirrationality measure of this $2$-adic quantity; namely, we show that\n$\\mu(\\zeta_2(5)) \\le (16\\log2)/(8\\log2-5) = 20.342\\dots$.","main_category":"math.NT","categories":"math.NT,math.AG,math.CA,math.CO","published":"2025-05-08T07:22:25Z"}
{"aid":"http://arxiv.org/abs/2505.05031v1","title":"LSRP: A Leader-Subordinate Retrieval Framework for Privacy-Preserving\n  Cloud-Device Collaboration","summary":"Cloud-device collaboration leverages on-cloud Large Language Models (LLMs)\nfor handling public user queries and on-device Small Language Models (SLMs) for\nprocessing private user data, collectively forming a powerful and\nprivacy-preserving solution. However, existing approaches often fail to fully\nleverage the scalable problem-solving capabilities of on-cloud LLMs while\nunderutilizing the advantage of on-device SLMs in accessing and processing\npersonalized data. This leads to two interconnected issues: 1) Limited\nutilization of the problem-solving capabilities of on-cloud LLMs, which fail to\nalign with personalized user-task needs, and 2) Inadequate integration of user\ndata into on-device SLM responses, resulting in mismatches in contextual user\ninformation.\n  In this paper, we propose a Leader-Subordinate Retrieval framework for\nPrivacy-preserving cloud-device collaboration (LSRP), a novel solution that\nbridges these gaps by: 1) enhancing on-cloud LLM guidance to on-device SLM\nthrough a dynamic selection of task-specific leader strategies named as\nuser-to-user retrieval-augmented generation (U-U-RAG), and 2) integrating the\ndata advantages of on-device SLMs through small model feedback Direct\nPreference Optimization (SMFB-DPO) for aligning the on-cloud LLM with the\non-device SLM. Experiments on two datasets demonstrate that LSRP consistently\noutperforms state-of-the-art baselines, significantly improving question-answer\nrelevance and personalization, while preserving user privacy through efficient\non-device retrieval. Our code is available at:\nhttps://github.com/Zhang-Yingyi/LSRP.","main_category":"cs.IR","categories":"cs.IR","published":"2025-05-08T08:06:34Z"}
{"aid":"http://arxiv.org/abs/2505.05054v1","title":"Direct Image Classification from Fourier Ptychographic Microscopy\n  Measurements without Reconstruction","summary":"The computational imaging technique of Fourier Ptychographic Microscopy (FPM)\nenables high-resolution imaging with a wide field of view and can serve as an\nextremely valuable tool, e.g. in the classification of cells in medical\napplications. However, reconstructing a high-resolution image from tens or even\nhundreds of measurements is computationally expensive, particularly for a wide\nfield of view. Therefore, in this paper, we investigate the idea of classifying\nthe image content in the FPM measurements directly without performing a\nreconstruction step first. We show that Convolutional Neural Networks (CNN) can\nextract meaningful information from measurement sequences, significantly\noutperforming the classification on a single band-limited image (up to 12 %)\nwhile being significantly more efficient than a reconstruction of a\nhigh-resolution image. Furthermore, we demonstrate that a learned multiplexing\nof several raw measurements allows maintaining the classification accuracy\nwhile reducing the amount of data (and consequently also the acquisition time)\nsignificantly.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-05-08T08:46:28Z"}
{"aid":"http://arxiv.org/abs/2505.05095v1","title":"Axion Dark Matter Search with Near-KSVZ Sensitivity Using the TM$_{020}$\n  Mode","summary":"Dark matter remains one of the most profound mysteries in modern physics,\nwith axions, a hypothetical particle proposed to resolve the strong CP problem,\nstanding as a compelling candidate. Among various experimental strategies,\ncavity haloscopes currently offer the most sensitive method to detect axions,\nthough their searches have largely been confined to axion masses below 10\n$\\mu$eV. However, recent theoretical developments suggest that the axion mass\nlies beyond this range. Higher-order cavity modes have been explored as a\nmethodological approach to expand the search range, albeit with limited success\nin achieving both high sensitivity and broad tunability. In this work, we\npresent a sensitive search for axions with masses around 21 $\\mu$eV, utilizing\nthe TM$_{020}$ mode of a cylindrical cavity, which incorporated an innovative\ntuning mechanism. Our results reached 1.7 times the KSVZ sensitivity over 100\nMHz, representing a significant improvement in this mass range and contributing\nto the experimental search for axion dark matter at higher masses.","main_category":"hep-ex","categories":"hep-ex","published":"2025-05-08T09:48:02Z"}
{"aid":"http://arxiv.org/abs/2505.05102v1","title":"Orbital phase shifts of Type-I outbursts in EXO 2030+375","summary":"EXO 2030+375 is a peculiar high-mass X-ray binary that has been exhibiting\nType-I outburst activities consistently over the past decades. The phases of\noutburst peaks are generally stable and occur near the orbital\nperiastron.However, significant orbital phase shifts have occasionally been\nobserved in 1995, 2006, and 2016. In this paper, we report another orbital\nphase shift triggered by a giant outburst in 2021. During this event, the\norbital phase of Type-I outburst peaks changed dramatically, moving from near\nperiastron to 20 days after periastron, followed by a gradual recovery.\nAdditionally, for several cycles after the 2021 giant outburst, some Type-I\noutbursts were missing, with subsequent outbursts occurring every two orbits.\nWe discuss our observations in the frame of the precession of an eccentric Be\ndisk.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-05-08T10:01:54Z"}
{"aid":"http://arxiv.org/abs/2505.05139v1","title":"Spatially Disaggregated Energy Consumption and Emissions in End-use\n  Sectors for Germany and Spain","summary":"High-resolution energy consumption and emissions datasets are essential for\nlocalized policy-making, resource optimization, and climate action planning.\nThey enable municipalities to monitor mitigation strategies and foster\nengagement among governments, businesses, and communities. However, smaller\nmunicipalities often face data limitations that hinder tailored climate\nstrategies. This study generates detailed final energy consumption and\nemissions data at the local administrative level for Germany and Spain. Using\nnational datasets, we apply spatial disaggregation techniques with open data\nsources. A key innovation is the application of XGBoost for imputing missing\ndata, combined with a stepwise spatial disaggregation process incorporating\ndistrict- and province-level statistics. Prioritizing reproducibility, our\nopen-data approach provides a scalable framework for municipalities to develop\nactionable climate plans. To ensure transparency, we assess the reliability of\nimputed values and assign confidence ratings to the disaggregated data.","main_category":"cs.DB","categories":"cs.DB,E.m","published":"2025-05-08T11:21:44Z"}
{"aid":"http://arxiv.org/abs/2505.05154v1","title":"Altermagnetic Skyrmions in 2D Lattices Exhibiting Anisotropic Skyrmion\n  Hall Effect","summary":"Anisotropic skyrmion Hall effect (A-SkHE) in two-dimensional (2D) magnetic\nsystems represents a captivating phenomenon in condensed-matter physics and\nmaterials science. While conventional antiferromagnetic systems inherently\nsuppress this effect through parity-time symmetry-mediated cancellation of\nMagnus forces acting on skyrmions, A-SkHE is primarily confined to\nferromagnetic platforms. Here, we present a paradigm-shifting demonstration of\nthis phenomenon in spin-splitting 2D antiferromagnets through the investigation\nof altermagnetic skyrmions. Combining comprehensive symmetry analysis with\ntheoretical modeling, we elucidate the mechanism governing A-SkHE realization\nin 2D altermagnetic systems and establish a quantitative relationship between\nthe transverse velocity of altermagnetic skyrmions and applied current\norientation. Using first-principles calculations and micromagnetic simulations,\nthis mechanism is further illustrated in a prototypical altermagnetic monolayer\nV2SeTeO. Crucially, we identify that the [C2C4zt] symmetry-protected\nanisotropic field serves as the critical stabilizer for maintaining the A-SkHE\nin this system. Our results greatly enrich the research on 2D altermagnetism\nand skyrmions.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-05-08T11:51:04Z"}
{"aid":"http://arxiv.org/abs/2505.05161v1","title":"Discrete dynamical systems: inverse problems and related topics","summary":"In this review, we extend the Boundary Control method\\, -- \\,an approach to\ninverse problems based on control theory for dynamical systems \\, -- \\,to\ninverse problems for discrete dynamical systems. We apply our results to\nclassical moment problems, Toda lattices, Weyl functions, de Branges spaces,\nKrein-Stieltjes strings, and also to problems of numerical simulations.","main_category":"math.AP","categories":"math.AP,math.SP","published":"2025-05-08T11:55:41Z"}
{"aid":"http://arxiv.org/abs/2505.05173v1","title":"Conjugate generation of sporadic almost simple groups","summary":"As defined by Guralnick and Saxl, given a nonabelian simple group $S$ and its\nnonidentity automorphism $x$, a natural number $\\alpha_S(x)$ is the minimum\nnumber of conjugates of $x$ in $\\langle x,S\\rangle$ that generate a subgroup\ncontaining $S$. In this paper, for every sporadic group $S$ other than the\nMonster and an automorphism $x$ of $S$ of prime order, we complete the\ndetermination of the precise value of $\\alpha_S(x)$.","main_category":"math.GR","categories":"math.GR","published":"2025-05-08T12:20:54Z"}
{"aid":"http://arxiv.org/abs/2505.05179v1","title":"Internal graphs of graph products of hyperfinite II$_1$-factors","summary":"In this paper, we show that for a graph $\\Gamma$ from a class named H-rigid\ngraphs, its subgraph ${\\rm Int}(\\Gamma)$, named the internal graph of $\\Gamma$,\nis an isomorphism invariant of the graph product of hyperfinite II$_1$-factors\n$R_{\\Gamma}$. In particular, we can classify $R_{\\Gamma}$ for some typical\ntypes of graphs, such as lines and cyclic graphs. As an application, we also\nshow that for two isomorphic graph products of hyperfinite II$_1$-factors over\nH-rigid graphs, the difference of the radius between the two graphs will not be\nlarger than 1. Our proof is based on the recent resolution of the Peterson-Thom\nconjecture.","main_category":"math.OA","categories":"math.OA","published":"2025-05-08T12:30:22Z"}
{"aid":"http://arxiv.org/abs/2505.05198v1","title":"Polymorphic spin ordering in a single-crystalline cobalt-doped Fe3GaTe2","summary":"A single crystalline system typically stabilizes a unique state for spin\nordering below a critical temperature. Certain materials exhibit multiple\nmagnetic states, driven by structural phase transitions under varying\nthermodynamic conditions. Recently, van der Waals magnets have demonstrated\nsubtle interlayer exchange interactions, offering a promising approach to\nelectrically control spin states without structural transformation. Here, we\nreport the emergence of three distinct magnetic states, ferromagnetic ordering\nand both collinear and non-collinear antiferromagnetic orderings, in a layered\nsingle crystalline magnet, cobalt-doped Fe3GaTe2 ((Co, Fe)3GaTe2). These three\nmagnetic phases occur without structural phase transitions, a phenomenon we\ndesignate as polymorphic spin ordering in the material. The introduction of 16%\nCo-doping in Fe3GaTe2 modulates the interlayer magnetic interaction, enabling\nmultiple spin orderings within the same lattice system with three critical\ntemperatures: a Curie temperature for a ferromagnetic state (Tc=210 K) and two\nNeel temperatures for the collinear (TN1=110 K) and non-collinear (TN2=30 K)\nantiferromagnetic states. Our findings are supported by magnetic force\nmicroscopy, first-principles calculations, and circular dichroism angular\nphotoemission spectroscopy, which reveals varying spin ordering and changes in\nthe topological band structure and Berry curvature at different temperatures\nwithin the single-crystalline (Co, Fe)3GaTe2.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-05-08T12:55:16Z"}
{"aid":"http://arxiv.org/abs/2505.05228v1","title":"On the stability and conditioning of a fictitious domain formulation for\n  fluid-structure interaction problems","summary":"We consider a distributed Lagrange multiplier formulation for fluid-structure\ninteraction problems in the spirit of the fictitious domain approach. Our\nprevious studies showed that the formulation is unconditionally stable in time\nand that its mixed finite element discretization is well-posed. In this paper,\nwe analyze the behavior of the condition number with respect to mesh\nrefinement. Moreover, we observe that our formulation does not need any\nstabilization term in presence of small cut cells and conditioning is not\naffected by the interface position.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-05-08T13:18:41Z"}
{"aid":"http://arxiv.org/abs/2505.05229v1","title":"Does CLIP perceive art the same way we do?","summary":"CLIP has emerged as a powerful multimodal model capable of connecting images\nand text through joint embeddings, but to what extent does it \"see\" the same\nway humans do - especially when interpreting artworks? In this paper, we\ninvestigate CLIP's ability to extract high-level semantic and stylistic\ninformation from paintings, including both human-created and AI-generated\nimagery. We evaluate its perception across multiple dimensions: content, scene\nunderstanding, artistic style, historical period, and the presence of visual\ndeformations or artifacts. By designing targeted probing tasks and comparing\nCLIP's responses to human annotations and expert benchmarks, we explore its\nalignment with human perceptual and contextual understanding. Our findings\nreveal both strengths and limitations in CLIP's visual representations,\nparticularly in relation to aesthetic cues and artistic intent. We further\ndiscuss the implications of these insights for using CLIP as a guidance\nmechanism during generative processes, such as style transfer or prompt-based\nimage synthesis. Our work highlights the need for deeper interpretability in\nmultimodal systems, especially when applied to creative domains where nuance\nand subjectivity play a central role.","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-05-08T13:21:10Z"}
{"aid":"http://arxiv.org/abs/2505.05237v1","title":"Latte: Transfering LLMs` Latent-level Knowledge for Few-shot Tabular\n  Learning","summary":"Few-shot tabular learning, in which machine learning models are trained with\na limited amount of labeled data, provides a cost-effective approach to\naddressing real-world challenges. The advent of Large Language Models (LLMs)\nhas sparked interest in leveraging their pre-trained knowledge for few-shot\ntabular learning. Despite promising results, existing approaches either rely on\ntest-time knowledge extraction, which introduces undesirable latency, or\ntext-level knowledge, which leads to unreliable feature engineering. To\novercome these limitations, we propose Latte, a training-time knowledge\nextraction framework that transfers the latent prior knowledge within LLMs to\noptimize a more generalized downstream model. Latte enables general\nknowledge-guided downstream tabular learning, facilitating the weighted fusion\nof information across different feature values while reducing the risk of\noverfitting to limited labeled data. Furthermore, Latte is compatible with\nexisting unsupervised pre-training paradigms and effectively utilizes available\nunlabeled samples to overcome the performance limitations imposed by an\nextremely small labeled dataset. Extensive experiments on various few-shot\ntabular learning benchmarks demonstrate the superior performance of Latte,\nestablishing it as a state-of-the-art approach in this domain","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-08T13:32:09Z"}
{"aid":"http://arxiv.org/abs/2505.05238v1","title":"Quantum optical formulation of difference-frequency generation and\n  optimal cloning of spatial modes","summary":"We present a quantum optical formulation of difference-frequency generation\n(DFG) that incorporates the spatial modes of light. It reproduces the well\nestablished result for classical light beams and establishes the relation of\nDFG to stimulated and spontaneous parametric downconversion. As shown here,\nthese relations determine that stimulated parametric down-conversion can\nrealise $N\\xrightarrow{} M $ $d$-dimensional optimal quantum cloning.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-08T13:32:38Z"}
{"aid":"http://arxiv.org/abs/2505.05255v1","title":"A new paradigm for computing hydrodynamic forces on particles in\n  Euler-Lagrange point-particle simulations","summary":"Accurate prediction of the hydrodynamic forces on particles is central to the\nfidelity of Euler-Lagrange (EL) simulations of particle-laden flows.\nTraditional EL methods typically rely on determining the hydrodynamic forces at\nthe positions of the individual particles from the interpolated fluid velocity\nfield, and feed these hydrodynamic forces back to the location of the\nparticles. This approach can introduce significant errors in two-way coupled\nsimulations, especially when the particle diameter is not much smaller than the\ncomputational grid spacing. In this study, we propose a novel force correlation\nframework that circumvents the need for undisturbed velocity estimation by\nleveraging volume-filtered quantities available directly from EL simulations.\nThrough a rigorous analytical derivation in the Stokes regime and extensive\nparticle-resolved direct numerical simulations (PR-DNS) at finite Reynolds\nnumbers, we formulate force correlations that depend solely on the\nvolume-filtered fluid velocity and local volume fraction, parametrized by the\nfilter width. These correlations are shown to recover known drag laws in the\nappropriate asymptotic limits and exhibit a good agreement with analytical and\nhigh-fidelity numerical benchmarks for single particle cases, and, compared to\nexisting correlations, an improved agreement for the drag force on particles in\nparticle assemblies. The proposed framework significantly enhances the accuracy\nof hydrodynamic force predictions for both isolated particles and dense\nsuspensions, without incurring the prohibitive computational costs associated\nwith reconstructing undisturbed flow fields. This advancement lays the\nfoundation for robust, scalable, and high-fidelity EL simulations of complex\nparticulate flows across a wide range of industrial and environmental\napplications.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,physics.comp-ph","published":"2025-05-08T14:03:58Z"}
{"aid":"http://arxiv.org/abs/2505.05257v1","title":"First Light and Reionization Epoch Simulations (FLARES) -- XVIII: the\n  ionising emissivities and hydrogen recombination line properties of early AGN","summary":"One of the most remarkable results from the \\emph{James Webb Space Telescope}\nhas been the discovery of a large population of compact sources exhibiting\nstrong broad H$\\alpha$ emission, typically interpreted to be low-luminosity\nbroad-line (Type 1) active galactic nuclei (BLAGN). An important question is\nwhether these observations are in tension with galaxy formation models, and if\nso how? While comparisons have been made using physical properties (i.e.~black\nhole mass and accretion rate) inferred from observations, these require the use\nof SED modelling assumptions, or locally inferred scaling relations, which may\nbe unjustified, at least in the distant high-redshift Universe. In this work we\ntake an alternative approach and forward model predictions from the First Light\nAnd Reionisation Epoch Simulations (FLARES) suite of cosmological\nhydrodynamical zoom simulations to predict the observable properties of BLAGN.\nWe achieve this by first coupling \\flares\\ with the \\qsosed\\ model to predict\nthe ionising photon luminosities of high-redshift ($z>5$) AGN. To model the\nobserved broad H$\\alpha$ emission we then assume a constant conversion factor\nand covering fraction, and the fraction of AGN that have observable\nbroad-lines. With a reasonable choice of these parameters, \\flares\\ is able to\nreproduce observational constraints on the H$\\alpha$ luminosity function and\nequivalent width distribution at $z=5$.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-05-08T14:04:08Z"}
{"aid":"http://arxiv.org/abs/2505.05259v1","title":"Decoding the molecular torus of NGC 1068: Insights into its structure\n  and kinematics from high-resolution ALMA observations","summary":"We dissect the kinematics and morphology of the molecular gas within the\nnear-nuclear region of NGC 1068 to understand the mechanisms in the central AGN\nthat might be fueling it, and the impact of its energy output on the\nsurrounding molecular gas. We present high angular and spectral resolution ALMA\nobservations of the HCO$^+$4->3 and CO 3->2 molecular lines in the near-nuclear\nregion of the prototype Seyfert 2 galaxy NGC 1068. The spatial resolution\n(1.1~pc) is almost two times better than that of previous works studying the\nsame molecular lines at the same transitions and is the highest resolution\nachievable with ALMA at these frequencies. Our analysis focuses on moment maps,\nposition-velocity (PV) diagrams, and spectra obtained at the position of the\nnuclear continuum source, along with a simple kinematic model developed using\nthe 3DBarolo software. Our observations reveal significant asymmetry between\nthe eastern and western sides of the nuclear disc in terms of morphology,\nvelocity, and line intensity. The broad lines seen in the inner 2 pc could be\naccounted for by either beam smearing or highly turbulent gas in this region.\nOutside this radius the mean velocities drop to $\\pm$30 km/s, which cannot be\nexplained by asymmetric drift. We find low velocity connections extending to 13\npc suggesting interactions with larger scale structures. The CO/HCO$^+$ line\nratio at the nucleus reported here are extremely low compared to values in the\nliterature of the same galaxy at lower spatial resolutions.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-05-08T14:05:06Z"}
{"aid":"http://arxiv.org/abs/2505.05265v1","title":"Strong tunability of epitaxial relationship and reconstruction at\n  improper ferroelectric interface","summary":"The atomic structures at epitaxial film-substrate interfaces determine\nscalability of thin films and can result in new phenomena. However, it is\nchallenging to control the interfacial structures since they are decided by the\nmost stable atomic bonding. In this work, we report strong tunability of the\nepitaxial interface of improper ferroelectric hexagonal ferrites deposited on\nspinel ferrites. The selection of two interface types, related by a 90 deg\nrotation of in-plane epitaxial relations and featured by disordered and\nhybridized reconstructions respectively, can be achieved by growth conditions,\nstacking sequences, and spinel compositions. While the disordered type\nsuppresses the primary K3 structure distortion and ferroelectricity in\nhexagonal ferrites, the hybridized type is more coherent with the distortion\nwith minimal suppression. This tunable interfacial structure provides critical\ninsight on controlling interfacial clamping and may offer a solution for the\nlong-standing problem of practical critical thickness in improper\nferroelectrics.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-05-08T14:13:20Z"}
{"aid":"http://arxiv.org/abs/2505.05302v1","title":"Josephson current signature of Floquet Majorana and topological\n  accidental zero modes in altermagnet heterostructure","summary":"We theoretically investigate the generation and Josephson current signatures\nof Floquet Majorana end modes (FMEMs) in a periodically driven altermagnet (AM)\nheterostructure. Considering a one-dimensional (1D) Rashba nanowire (RNW)\nproximitized to a regular $s$-wave superconductor and a $d$-wave AM, we\ngenerate both $0$- and $\\pi$-FMEMs by driving the nontopological phase of the\nstatic system. While the static counterpart hosts both topological Majorana\nzero modes (MZMs) and non-topological accidental zero modes (AZMs), the drive\ncan gap out the static AZMs and generate robust $\\pi$-FMEMs, termed as\ntopological AZMs (TAZMs). We topologically characterize the emergent FMEMs via\ndynamical winding numbers exploiting chiral symmetry of the system. Moreover,\nwe consider a periodically driven Josephson junction comprising of RNW/AM-based\n1D topological superconduting setup. We identify the signature of MZMs and\nFMEMs utilizing $4\\pi$-periodic Josephson effect, distinguishing them from\ntrivial AZMs exhibiting $2\\pi$-periodicty, in both static and driven platforms.\nThis Josephson current signal due to Majorana modes survives even in presence\nof finite disorder. Our work establishes a route to realize and identify FMEMs\nin AM-based platforms through Floquet engineering and Josephson current\nresponse.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci,cond-mat.supr-con","published":"2025-05-08T14:43:26Z"}
{"aid":"http://arxiv.org/abs/2505.05327v1","title":"ICon: In-Context Contribution for Automatic Data Selection","summary":"Data selection for instruction tuning is essential for improving the\nperformance of Large Language Models (LLMs) and reducing training cost.\nHowever, existing automated selection methods either depend on computationally\nexpensive gradient-based measures or manually designed heuristics, which may\nfail to fully exploit the intrinsic attributes of data. In this paper, we\npropose In-context Learning for Contribution Measurement (ICon), a novel\ngradient-free method that takes advantage of the implicit fine-tuning nature of\nin-context learning (ICL) to measure sample contribution without gradient\ncomputation or manual indicators engineering. ICon offers a computationally\nefficient alternative to gradient-based methods and reduces human inductive\nbias inherent in heuristic-based approaches. ICon comprises three components\nand identifies high-contribution data by assessing performance shifts under\nimplicit learning through ICL. Extensive experiments on three LLMs across 12\nbenchmarks and 5 pairwise evaluation sets demonstrate the effectiveness of\nICon. Remarkably, on LLaMA3.1-8B, models trained on 15% of ICon-selected data\noutperform full datasets by 5.42% points and exceed the best performance of\nwidely used selection methods by 2.06% points. We further analyze\nhigh-contribution samples selected by ICon, which show both diverse tasks and\nappropriate difficulty levels, rather than just the hardest ones.","main_category":"cs.CL","categories":"cs.CL","published":"2025-05-08T15:17:37Z"}
{"aid":"http://arxiv.org/abs/2505.05367v1","title":"Joint Super-Resolution and Segmentation for 1-m Impervious Surface Area\n  Mapping in China's Yangtze River Economic Belt","summary":"We propose a novel joint framework by integrating super-resolution and\nsegmentation, called JointSeg, which enables the generation of 1-meter ISA maps\ndirectly from freely available Sentinel-2 imagery. JointSeg was trained on\nmultimodal cross-resolution inputs, offering a scalable and affordable\nalternative to traditional approaches. This synergistic design enables gradual\nresolution enhancement from 10m to 1m while preserving fine-grained spatial\ntextures, and ensures high classification fidelity through effective\ncross-scale feature fusion. This method has been successfully applied to the\nYangtze River Economic Belt (YREB), a region characterized by complex\nurban-rural patterns and diverse topography. As a result, a comprehensive ISA\nmapping product for 2021, referred to as ISA-1, was generated, covering an area\nof over 2.2 million square kilometers. Quantitative comparisons against the 10m\nESA WorldCover and other benchmark products reveal that ISA-1 achieves an\nF1-score of 85.71%, outperforming bilinear-interpolation-based segmentation by\n9.5%, and surpassing other ISA datasets by 21.43%-61.07%. In densely urbanized\nareas (e.g., Suzhou, Nanjing), ISA-1 reduces ISA overestimation through\nimproved discrimination of green spaces and water bodies. Conversely, in\nmountainous regions (e.g., Ganzi, Zhaotong), it identifies significantly more\nISA due to its enhanced ability to detect fragmented anthropogenic features\nsuch as rural roads and sparse settlements, demonstrating its robustness across\ndiverse landscapes. Moreover, we present biennial ISA maps from 2017 to 2023,\ncapturing spatiotemporal urbanization dynamics across representative cities.\nThe results highlight distinct regional growth patterns: rapid expansion in\nupstream cities, moderate growth in midstream regions, and saturation in\ndownstream metropolitan areas.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-05-08T16:04:35Z"}
{"aid":"http://arxiv.org/abs/2505.05370v1","title":"Walrus: An Efficient Decentralized Storage Network","summary":"Decentralized storage systems face a fundamental trade-off between\nreplication overhead, recovery efficiency, and security guarantees. Current\napproaches either rely on full replication, incurring substantial storage\ncosts, or employ trivial erasure coding schemes that struggle with efficient\nrecovery especially under high storage-node churn. We present Walrus, a novel\ndecentralized blob storage system that addresses these limitations through\nmultiple technical innovations. At the core of Walrus is RedStuff, a\ntwo-dimensional erasure coding protocol that achieves high security with only\n4.5x replication factor, while enabling self-healing recovery that requires\nbandwidth proportional to only the lost data $(O(|blob|/n)$ versus $O(|blob|)$\nin traditional systems). Crucially, RedStuff is the first protocol to support\nstorage challenges in asynchronous networks, preventing adversaries from\nexploiting network delays to pass verification without actually storing data.\nWalrus also introduces a novel multi-stage epoch change protocol that\nefficiently handles storage node churn while maintaining uninterrupted\navailability during committee transitions. Our system incorporates\nauthenticated data structures to defend against malicious clients and ensures\ndata consistency throughout storage and retrieval processes. Experimental\nevaluation demonstrates that Walrus achieves practical performance at scale,\nmaking it suitable for a wide range of decentralized applications requiring\nhigh-integrity, available blob storage with reasonable overhead.","main_category":"cs.DC","categories":"cs.DC,cs.CR","published":"2025-05-08T16:06:41Z"}
{"aid":"http://arxiv.org/abs/2505.05415v1","title":"Radial Profiles of Radio Halos in Massive Galaxy Clusters: Diffuse\n  Giants Over 2 Mpc","summary":"We present new, high frequency radio observations of the merging galaxy\nclusters PLCK G287.0+32.9, Abell 2744, and Bullet. These clusters are known to\nhost $\\sim$Mpc scale sources, known as radio halos, which are formed by the\nacceleration of cosmic rays by turbulence injected into the intracluster medium\nduring cluster mergers. Our new images reveal previously undetected faint\noutermost regions of halos, extending to over 2 Mpc. This discovery highlights\nthe presence of radio halos with large extents at high frequencies and suggests\nthat their observable size depends on a combination of the observation\nsensitivity and uv-coverage, and their radio power. We additionally compare the\nproperties of these three clusters with MACS J0717+3745 and Abell 2142, both of\nwhich are known to host prominent large radio halos. Remarkably, all five\nhalos, despite their exceptionally large extents, exhibit properties similar to\nother classical halos: their radial profiles are described by a\nsingle-component exponential fit, they show radial spectral index steepening,\nand have an average radio emissivity of about $10^{-42}\\,\n\\mathrm{erg\\,s^{-1}\\,cm^{-3}\\,Hz^{-1}}$. Our results demonstrate that radio\nhalos can extend to the cluster periphery, without the transition to an\nobservationally distinguishable different halo component in the outermost\nregions. Our findings highlight that careful subtraction of unrelated sources\nembedded in the halo is necessary to measure the radio surface brightness\naccurately, as incomplete subtraction can introduce an apparent secondary\ncomponent in the peripheral regions.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.GA","published":"2025-05-08T16:56:22Z"}
{"aid":"http://arxiv.org/abs/2505.05422v1","title":"TokLIP: Marry Visual Tokens to CLIP for Multimodal Comprehension and\n  Generation","summary":"Pioneering token-based works such as Chameleon and Emu3 have established a\nfoundation for multimodal unification but face challenges of high training\ncomputational overhead and limited comprehension performance due to a lack of\nhigh-level semantics. In this paper, we introduce TokLIP, a visual tokenizer\nthat enhances comprehension by semanticizing vector-quantized (VQ) tokens and\nincorporating CLIP-level semantics while enabling end-to-end multimodal\nautoregressive training with standard VQ tokens. TokLIP integrates a low-level\ndiscrete VQ tokenizer with a ViT-based token encoder to capture high-level\ncontinuous semantics. Unlike previous approaches (e.g., VILA-U) that discretize\nhigh-level features, TokLIP disentangles training objectives for comprehension\nand generation, allowing the direct application of advanced VQ tokenizers\nwithout the need for tailored quantization operations. Our empirical results\ndemonstrate that TokLIP achieves exceptional data efficiency, empowering visual\ntokens with high-level semantic understanding while enhancing low-level\ngenerative capacity, making it well-suited for autoregressive Transformers in\nboth comprehension and generation tasks. The code and models are available at\nhttps://github.com/TencentARC/TokLIP.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL","published":"2025-05-08T17:12:19Z"}
{"aid":"http://arxiv.org/abs/2505.05453v1","title":"Conversational Process Model Redesign","summary":"With the recent success of large language models (LLMs), the idea of\nAI-augmented Business Process Management systems is becoming more feasible. One\nof their essential characteristics is the ability to be conversationally\nactionable, allowing humans to interact with the LLM effectively to perform\ncrucial process life cycle tasks such as process model design and redesign.\nHowever, most current research focuses on single-prompt execution and\nevaluation of results, rather than on continuous interaction between the user\nand the LLM. In this work, we aim to explore the feasibility of using LLMs to\nempower domain experts in the creation and redesign of process models in an\niterative and effective way. The proposed conversational process model redesign\n(CPD) approach receives as input a process model and a redesign request by the\nuser in natural language. Instead of just letting the LLM make changes, the LLM\nis employed to (a) identify process change patterns from literature, (b)\nre-phrase the change request to be aligned with an expected wording for the\nidentified pattern (i.e., the meaning), and then to (c) apply the meaning of\nthe change to the process model. This multi-step approach allows for\nexplainable and reproducible changes. In order to ensure the feasibility of the\nCPD approach, and to find out how well the patterns from literature can be\nhandled by the LLM, we performed an extensive evaluation. The results show that\nsome patterns are hard to understand by LLMs and by users. Within the scope of\nthe study, we demonstrated that users need support to describe the changes\nclearly. Overall the evaluation shows that the LLMs can handle most changes\nwell according to a set of completeness and correctness criteria.","main_category":"cs.AI","categories":"cs.AI","published":"2025-05-08T17:44:45Z"}
{"aid":"http://arxiv.org/abs/2505.05462v1","title":"Marsden--Meyer--Weinstein reduction for $k$-contact field theories","summary":"This work devises a Marsden--Meyer--Weinstein $k$-contact reduction. Our\ntechniques are illustrated with several examples of mathematical and physical\nrelevance. As a byproduct, we review the previous contact reduction literature\nso as to clarify and to solve some inaccuracies.","main_category":"math.DG","categories":"math.DG,math-ph,math.MP,math.SG","published":"2025-05-08T17:54:10Z"}
