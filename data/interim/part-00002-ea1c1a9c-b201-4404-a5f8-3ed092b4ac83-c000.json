{"aid":"http://arxiv.org/abs/2503.21695v1","title":"AMA-SAM: Adversarial Multi-Domain Alignment of Segment Anything Model\n  for High-Fidelity Histology Nuclei Segmentation","summary":"Accurate segmentation of cell nuclei in histopathology images is essential\nfor numerous biomedical research and clinical applications. However, existing\ncell nucleus segmentation methods only consider a single dataset (i.e., primary\ndomain), while neglecting to leverage supplementary data from diverse sources\n(i.e., auxiliary domains) to reduce overfitting and enhance the performance.\nAlthough incorporating multiple datasets could alleviate overfitting, it often\nexacerbates performance drops caused by domain shifts. In this work, we\nintroduce Adversarial Multi-domain Alignment of Segment Anything Model\n(AMA-SAM) that extends the Segment Anything Model (SAM) to overcome these\nobstacles through two key innovations. First, we propose a Conditional Gradient\nReversal Layer (CGRL), a multi-domain alignment module that harmonizes features\nfrom diverse domains to promote domain-invariant representation learning while\npreserving crucial discriminative features for the primary dataset. Second, we\naddress SAM's inherent low-resolution output by designing a High-Resolution\nDecoder (HR-Decoder), which directly produces fine-grained segmentation maps in\norder to capture intricate nuclei boundaries in high-resolution histology\nimages. To the best of our knowledge, this is the first attempt to adapt SAM\nfor multi-dataset learning with application to histology nuclei segmentation.\nWe validate our method on several publicly available datasets, demonstrating\nconsistent and significant improvements over state-of-the-art approaches.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-27T16:59:39Z"}
{"aid":"http://arxiv.org/abs/2503.21697v1","title":"The commutativity problem for effective varieties of formal series, and\n  applications","summary":"A formal series in noncommuting variables $\\Sigma$ over the rationals is a\nmapping $\\Sigma^* \\to \\mathbb Q$. We say that a series is commutative if the\nvalue in the output does not depend on the order of the symbols in the input.\nThe commutativity problem for a class of series takes as input a (finite\npresentation of) a series from the class and amounts to establishing whether it\nis commutative. This is a very natural, albeit nontrivial problem, which has\nnot been considered before from an algorithmic perspective.\n  We show that commutativity is decidable for all classes of series that\nconstitute a so-called effective prevariety, a notion generalising Reutenauer's\nvarieties of formal series. For example, the class of rational series,\nintroduced by Sch\\\"utzenberger in the 1960's, is well-known to be an effective\n(pre)variety, and thus commutativity is decidable for it.\n  In order to showcase the applicability of our result, we consider classes of\nformal series generalising the rational ones. We consider polynomial automata,\nshuffle automata, and infiltration automata, and we show that each of these\nmodels recognises an effective prevariety of formal series. Consequently, their\ncommutativity problem is decidable, which is a novel result. We find it\nremarkable that commutativity can be decided in a uniform way for such\ndisparate computation models.\n  Finally, we present applications of commutativity outside the theory of\nformal series. We show that we can decide solvability in sequences and in power\nseries for restricted classes of algebraic difference and differential\nequations, for which such problems are undecidable in full generality. Thanks\nto this, we can prove that the syntaxes of multivariate polynomial recursive\nsequences and of constructible differentially algebraic power series are\neffective, which are new results which were left open in previous work.","main_category":"cs.FL","categories":"cs.FL,cs.DM,cs.LO","published":"2025-03-27T17:01:19Z"}
{"aid":"http://arxiv.org/abs/2503.21724v1","title":"Ram-pressure stripping caught in action in a forming galaxy cluster 3\n  billion years after the Big Bang","summary":"Galaxy clusters in the local Universe are dominated by massive quiescent\ngalaxies with old ages, formed at high redshifts. It is debated whether their\nquenching is driven by internal processes or environmental effects, which has\nbeen challenging due to the lack of observations during their peak formation\nepoch. Here we report clear evidence from ALMA of extended and elongated gas\ntails in nine galaxies in a forming cluster at z = 2.51. The distinct gas\ndistribution compared to the stellar emission probed by JWST, which is rather\nisolated without signatures of mergers or interactions, provides evidence of\nram-pressure stripping (RPS). This represents the most distant confirmed case\nof RPS, highlighting the critical role of environmental effects in gas removal\nat high redshifts, an often overlooked quenching pathway.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-03-27T17:36:57Z"}
{"aid":"http://arxiv.org/abs/2503.21728v1","title":"Near field imaging of local interference in radio interferometric data:\n  Impact on the redshifted 21-cm power spectrum","summary":"Radio-frequency interference (RFI) is a major systematic limitation in radio\nastronomy, particularly for science cases requiring high sensitivity, such as\n21-cm cosmology. Traditionally, RFI is dealt with by identifying its signature\nin the dynamic spectra of visibility data and flagging strongly affected\nregions. However, for RFI sources that do not occupy narrow regions in the\ntime-frequency space, such as persistent local RFI, modeling these sources\ncould be essential to mitigating their impact. This paper introduces two\nmethods for detecting and characterizing local RFI sources from radio\ninterferometric visibilities: matched filtering and maximum a posteriori (MAP)\nimaging. These algorithms use the spherical wave equation to construct\nthree-dimensional near-field image cubes of RFI intensity from the\nvisibilities. The matched filter algorithm can generate normalized maps by\ncross-correlating the expected contributions from RFI sources with the observed\nvisibilities, while the MAP method performs a regularized inversion of the\nvisibility equation in the near field. We also develop a full polarization\nsimulation framework for RFI and demonstrate the methods on simulated\nobservations of local RFI sources. The stability, speed, and errors introduced\nby these algorithms are investigated, and, as a demonstration, the algorithms\nare applied to a subset of NenuFAR observations to perform spatial, spectral,\nand temporal characterization of two local RFI sources. We assess the impact of\nlocal RFI on images, the uv plane, and cylindrical power spectra through\nsimulations and describe these effects qualitatively. We also quantify the\nlevel of errors and biases that these algorithms induce and assess their\nimplications for the estimated 21-cm power spectrum with radio interferometers.\nThe near-field imaging and simulation codes are made available publicly in the\nPython library nfis.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.CO","published":"2025-03-27T17:40:38Z"}
{"aid":"http://arxiv.org/abs/2503.21735v1","title":"GateLens: A Reasoning-Enhanced LLM Agent for Automotive Software Release\n  Analytics","summary":"Ensuring the reliability and effectiveness of software release decisions is\ncritical, particularly in safety-critical domains like automotive systems.\nPrecise analysis of release validation data, often presented in tabular form,\nplays a pivotal role in this process. However, traditional methods that rely on\nmanual analysis of extensive test datasets and validation metrics are prone to\ndelays and high costs. Large Language Models (LLMs) offer a promising\nalternative but face challenges in analytical reasoning, contextual\nunderstanding, handling out-of-scope queries, and processing structured test\ndata consistently; limitations that hinder their direct application in\nsafety-critical scenarios. This paper introduces GateLens, an LLM-based tool\nfor analyzing tabular data in the automotive domain. GateLens translates\nnatural language queries into Relational Algebra (RA) expressions and then\ngenerates optimized Python code. It outperforms the baseline system on\nbenchmarking datasets, achieving higher F1 scores and handling complex and\nambiguous queries with greater robustness. Ablation studies confirm the\ncritical role of the RA module, with performance dropping sharply when omitted.\nIndustrial evaluations reveal that GateLens reduces analysis time by over 80%\nwhile maintaining high accuracy and reliability. As demonstrated by presented\nresults, GateLens achieved high performance without relying on few-shot\nexamples, showcasing strong generalization across various query types from\ndiverse company roles. Insights from deploying GateLens with a partner\nautomotive company offer practical guidance for integrating AI into critical\nworkflows such as release validation. Results show that by automating test\nresult analysis, GateLens enables faster, more informed, and dependable release\ndecisions, and can thus advance software scalability and reliability in\nautomotive systems.","main_category":"cs.SE","categories":"cs.SE,cs.AI,cs.CL,cs.MA","published":"2025-03-27T17:48:32Z"}
{"aid":"http://arxiv.org/abs/2503.21751v1","title":"Reconstructing Humans with a Biomechanically Accurate Skeleton","summary":"In this paper, we introduce a method for reconstructing 3D humans from a\nsingle image using a biomechanically accurate skeleton model. To achieve this,\nwe train a transformer that takes an image as input and estimates the\nparameters of the model. Due to the lack of training data for this task, we\nbuild a pipeline to produce pseudo ground truth model parameters for single\nimages and implement a training procedure that iteratively refines these pseudo\nlabels. Compared to state-of-the-art methods for 3D human mesh recovery, our\nmodel achieves competitive performance on standard benchmarks, while it\nsignificantly outperforms them in settings with extreme 3D poses and\nviewpoints. Additionally, we show that previous reconstruction methods\nfrequently violate joint angle limits, leading to unnatural rotations. In\ncontrast, our approach leverages the biomechanically plausible degrees of\nfreedom making more realistic joint rotation estimates. We validate our\napproach across multiple human pose estimation benchmarks. We make the code,\nmodels and data available at: https://isshikihugh.github.io/HSMR/","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:56:24Z"}
{"aid":"http://arxiv.org/abs/2503.21768v1","title":"Results on branching random walks and rumor processes via germ order","summary":"Germ order is a non-standard stochastic order defined through the comparison\nof the generating functions of the processes. This order was first introduced\nfor branching random walks with a constant breeding law and independent\ndispersal of offspring, which are characterized by a one-dimensional generating\nfunction. In this work, we investigate the properties of the extension of this\nconcept to processes characterized by a multidimensional generating function,\nsuch as general branching random walks and rumor processes. In particular, we\nuse germ ordering to characterize the behavior of certain branching random\nwalks and rumor processes with inhomogeneous breeding/transmitting laws.","main_category":"math.PR","categories":"math.PR","published":"2025-03-27T17:59:06Z"}
{"aid":"http://arxiv.org/abs/2503.23696v1","title":"Pinalites: Optical properties and Quantum Magnetism of Heteroanionic\n  A$_3$MO$_5$X$_2$ Compounds","summary":"Heteroanionic compounds, which contain two or more types of anions, have\nemerged as a promising class of materials with diverse properties and\nfunctionalities. In this paper, I review the experimental findings on\nCa3ReO5Cl2 and related com-pounds that exhibit remarkable pleochroism and novel\nquantum magnetism. I discuss how the heteroanionic coordination affects the\noptical and magnetic properties by modulating the d-orbital states of the\ntransition metal ions and then compare these materials with other heteroanionic\nand monoanionic compounds and highlight the potential of A3MO5X2 materials for\nfuture exploration of materials and phenomena.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-03-31T03:51:35Z"}
{"aid":"http://arxiv.org/abs/2503.23702v1","title":"3D Dental Model Segmentation with Geometrical Boundary Preserving","summary":"3D intraoral scan mesh is widely used in digital dentistry diagnosis,\nsegmenting 3D intraoral scan mesh is a critical preliminary task. Numerous\napproaches have been devised for precise tooth segmentation. Currently, the\ndeep learning-based methods are capable of the high accuracy segmentation of\ncrown. However, the segmentation accuracy at the junction between the crown and\nthe gum is still below average. Existing down-sampling methods are unable to\neffectively preserve the geometric details at the junction. To address these\nproblems, we propose CrossTooth, a boundary-preserving segmentation method that\ncombines 3D mesh selective downsampling to retain more vertices at the\ntooth-gingiva area, along with cross-modal discriminative boundary features\nextracted from multi-view rendered images, enhancing the geometric\nrepresentation of the segmentation network. Using a point network as a backbone\nand incorporating image complementary features, CrossTooth significantly\nimproves segmentation accuracy, as demonstrated by experiments on a public\nintraoral scan dataset.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T04:00:11Z"}
{"aid":"http://arxiv.org/abs/2503.23714v1","title":"Building Instruction-Tuning Datasets from Human-Written Instructions\n  with Open-Weight Large Language Models","summary":"Instruction tuning is crucial for enabling Large Language Models (LLMs) to\nsolve real-world tasks. Prior work has shown the effectiveness of\ninstruction-tuning data synthesized solely from LLMs, raising a fundamental\nquestion: Do we still need human-originated signals for instruction tuning?\nThis work answers the question affirmatively: we build state-of-the-art\ninstruction-tuning datasets sourced from human-written instructions, by simply\npairing them with LLM-generated responses. LLMs fine-tuned on our datasets\nconsistently outperform those fine-tuned on existing ones. Our data\nconstruction approach can be easily adapted to other languages; we build\ndatasets for Japanese and confirm that LLMs tuned with our data reach\nstate-of-the-art performance. Analyses suggest that instruction-tuning in a new\nlanguage allows LLMs to follow instructions, while the tuned models exhibit a\nnotable lack of culture-specific knowledge in that language. The datasets and\nfine-tuned models will be publicly available. Our datasets, synthesized with\nopen-weight LLMs, are openly distributed under permissive licenses, allowing\nfor diverse use cases.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T04:28:38Z"}
{"aid":"http://arxiv.org/abs/2503.23727v1","title":"Angle-dependent in-situ fast flavor transformations in post-neutron star\n  merger disks","summary":"The remnant black hole-accretion disk system resulting from binary neutron\nstar mergers has proven to be a promising site for synthesizing the heaviest\nelements via rapid neutron capture (r-process). A critical factor in\ndetermining the full r-process pattern in these environments is the neutron\nrichness of the ejecta, which is strongly influenced by neutrino interactions.\nOne key ingredient shaping these interactions is fast neutrino flavor\nconversions (FFCs), which arise due to angular crossings in neutrino\ndistributions and occur on nanosecond timescales. We present the first\nthree-dimensional, in-situ, angle-dependent modeling of FFCs in post-merger\ndisks, implemented within general relativistic magnetohydrodynamics with Monte\nCarlo neutrino transport. Our results reveal that, by suppressing electron\nneutrinos, FFCs more efficiently cool the disk and weaken the early thermally\ndriven wind. Less re-leptonization due to electron neutrino absorption makes\nthis cooler wind more neutron-rich, producing a more robust r-process at higher\nlatitudes of the outflow. This study underscores the necessity of incorporating\nFFCs in realistic simulations.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-03-31T05:01:52Z"}
{"aid":"http://arxiv.org/abs/2503.23738v1","title":"Coherent manipulation of interacting electron qubits on solid neon","summary":"Solid neon has emerged as a pristine material host for electron qubits.\nSingle electron-on-solid-neon (eNe) charge qubits have shown extraordinarily\nlong coherence times and high operation fidelities. Realizing two-qubit gates\nin this platform is the next major step for realistic quantum information\nprocessing. In this work, we demonstrate frequency- and time-domain coherent\nmanipulation of multiple eNe charge qubits that are coupled by short-range\ncharge interactions. Cross-resonance and bSWAP two-qubit gates are implemented,\nlaying the foundation for universal quantum computing. An inter-qubit coupling\nstrength exceeding 60~MHz has been observed, promising fast gate speed and\nsuppressed infidelity. These results highlight the potential to scale up the\neNe qubit platform toward universal quantum computing.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T05:27:23Z"}
{"aid":"http://arxiv.org/abs/2503.23779v1","title":"WinoWhat: A Parallel Corpus of Paraphrased WinoGrande Sentences with\n  Common Sense Categorization","summary":"In this study, we take a closer look at how Winograd schema challenges can be\nused to evaluate common sense reasoning in LLMs. Specifically, we evaluate\ngenerative models of different sizes on the popular WinoGrande benchmark. We\nrelease WinoWhat, a new corpus, in which each instance of the WinoGrande\nvalidation set is paraphrased. Additionally, we evaluate the performance on the\nchallenge across five common sense knowledge categories, giving more\nfine-grained insights on what types of knowledge are more challenging for LLMs.\nSurprisingly, all models perform significantly worse on WinoWhat, implying that\nLLM reasoning capabilities are overestimated on WinoGrande. To verify whether\nthis is an effect of benchmark memorization, we match benchmark instances to\nLLM trainingdata and create two test-suites. We observe that memorization has a\nminimal effect on model performance on WinoGrande.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-03-31T06:53:53Z"}
{"aid":"http://arxiv.org/abs/2503.23786v1","title":"MGD-SAM2: Multi-view Guided Detail-enhanced Segment Anything Model 2 for\n  High-Resolution Class-agnostic Segmentation","summary":"Segment Anything Models (SAMs), as vision foundation models, have\ndemonstrated remarkable performance across various image analysis tasks.\nDespite their strong generalization capabilities, SAMs encounter challenges in\nfine-grained detail segmentation for high-resolution class-independent\nsegmentation (HRCS), due to the limitations in the direct processing of\nhigh-resolution inputs and low-resolution mask predictions, and the reliance on\naccurate manual prompts. To address these limitations, we propose MGD-SAM2\nwhich integrates SAM2 with multi-view feature interaction between a global\nimage and local patches to achieve precise segmentation. MGD-SAM2 incorporates\nthe pre-trained SAM2 with four novel modules: the Multi-view Perception Adapter\n(MPAdapter), the Multi-view Complementary Enhancement Module (MCEM), the\nHierarchical Multi-view Interaction Module (HMIM), and the Detail Refinement\nModule (DRM). Specifically, we first introduce MPAdapter to adapt the SAM2\nencoder for enhanced extraction of local details and global semantics in HRCS\nimages. Then, MCEM and HMIM are proposed to further exploit local texture and\nglobal context by aggregating multi-view features within and across\nmulti-scales. Finally, DRM is designed to generate gradually restored\nhigh-resolution mask predictions, compensating for the loss of fine-grained\ndetails resulting from directly upsampling the low-resolution prediction maps.\nExperimental results demonstrate the superior performance and strong\ngeneralization of our model on multiple high-resolution and normal-resolution\ndatasets. Code will be available at https://github.com/sevenshr/MGD-SAM2.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T07:02:32Z"}
{"aid":"http://arxiv.org/abs/2503.23833v1","title":"Products of Kirillov-Reshetikhin modules and maximal green sequences","summary":"We show that a $q$-character of a Kirillov-Reshetikhin module (KR modules)\nfor untwisted quantum affine algebras of simply laced types $A_n^{(1)}$,\n$D_n^{(1)}$, $E_6^{(1)}$, $E_7^{(1)}$, $E_8^{(1)}$ might be obtained from a\nspecific cluster variable of a seed obtained by applying a maximal green\nsequence to the initial (infinite) quiver of the Hernandez-Leclerc cluster\nalgebra. For a collection of KR-modules with nested supports, we show an\nexplicit construction of a cluster seed, which has cluster variables\ncorresponding to the $q$-characters of KR-modules of such a collection. We\nprove that the product of KR-modules of such a collection is a simple module.\nWe also construct cluster seeds with cluster variables corresponding to\n$q$-characters of KR-modules of some non-nested collections. We make a\nconjecture that tensor products of KR-modules for such non-nested collections\nare simple. We show that the cluster Donaldson-Thomas transformations for\ndouble Bruhat cells for $ADE$ types can be computed using $q$-characters of\nKR-modules.","main_category":"math.RT","categories":"math.RT,math.QA","published":"2025-03-31T08:28:36Z"}
{"aid":"http://arxiv.org/abs/2503.23834v1","title":"$q$-deformed rationals and irrationals","summary":"The concept of $q$-deformation, or ``$q$-analogue'' arises in many areas of\nmathematics. In algebra and representation theory, it is the origin of quantum\ngroups; $q$-deformations are important for knot invariants, combinatorial\nenumeration, discrete geometry, analysis, and many other parts of mathematics.\nIn mathematical physics, $q$-deformations are often understood as\n``quantizations''.\n  The recently introduced notion of a $q$-deformed real number is based on the\ngeometric idea of invariance by a modular group action. The goal of this\nlecture is to explain what is a $q$-rational and a $q$-irrational, demonstrate\nbeautiful properties of these objects, and describe their relations to many\ndifferent areas. We also tried to describe some applications of $q$-numbers.","main_category":"math.CO","categories":"math.CO,math.QA","published":"2025-03-31T08:28:41Z"}
{"aid":"http://arxiv.org/abs/2503.23843v1","title":"The Problem of the Global Astrometric Sphere Reconstruction in\n  Astrometry -- Issues and Approaches","summary":"In this contribution we give a brief account of the problem of the Global\nAstrometric Sphere Reconstruction in Astrometry, with particular reference to\nthe Gaia and Gaia-like astrometric missions, namely those adopting a scanning\nstrategy with observations in TDI mode. We sketch the design of the Gaia\nmission, the mathematical modelling that comes naturally from its observing\nstrategy, and how the problem of the global sphere reconstruction translates\ninto that of the solution of large, sparse, and overdetermined system of\nlinearized equations. After a short description of the two approaches to this\nproblem implemented in the Gaia data reduction pipelines, we list the main\nknown problems of the current approaches, with specific reference to the\ncalibration and the correlation issues. Finally, we suggest how an arc-based\nsolution could help to alleviate some of these problems, how it would be\npossible to devise a mathematical model for such an observable despite the TDI\nobserving mode, and the main difficulty that a parallel implementation of this\nmodel would have to solve.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-03-31T08:45:29Z"}
{"aid":"http://arxiv.org/abs/2503.23849v1","title":"Narrow-Line Seyfert 1 Galaxies Beyond the Local X-ray Universe: An X-ray\n  spectral sample","summary":"Narrow-line Seyfert 1 AGNs (NLS1s) represent a unique stage in the black hole\ngrowth history, characterised by low black hole masses of approximately\n$10^{6}$-$10^{8}$ solar masses and around-Eddington accretion rates. X-ray\nstudies of NLS1s have largely been confined to the local Universe ($z < 0.2$),\nwhile their broad-line counterparts and radio-loud quasars have been more\nextensively investigated at higher redshifts. In this work, we conducted an\nX-ray spectral analysis for 14 SDSS-observed NLS1s at $z\\approx1$ in the eRASS1\ncatalogue. We found that all of their eROSITA observations agree with the\nexpected rest-frame 2 keV monochromatic luminosity given their rest-frame 2500\nangstrom monochromatic luminosity, further supporting evidence of AGN emission.\nSecond, when fitted with a power-law model, most continuum spectra between\n0.7-7 keV in their rest frames necessitate photon indices $\\Gamma\\gtrsim2.5$.\nNotably, the highest photon index of around 4.7 in one of our NLS1 AGNs hints\nat a significant contribution from soft excess emission. Finally, our analysis\ndemonstrates that we can align the Eddington ratios with optical measurements\nby applying a correction factor between 10-120 to their X-ray luminosity.\nAlthough measurement uncertainty remains considerable, our findings suggest\nthat assumptions for the standard geometrically thin accretion disc model made\nin previous estimations of this correction factor may not apply to near or\nsuper-Eddington NLS1 AGNs. Finally, we also compare this sample with extremely\nvariable nearby NLS1s and other X-ray-weak AGNs, such as JWST-observed,\nbroad-line AGNs at $z=5-6$, and underscores the importance of deeper X-ray\nsurveys for more X-ray-weak NLS1s.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-03-31T08:55:07Z"}
{"aid":"http://arxiv.org/abs/2503.23850v1","title":"Event-activity dependence of heavy-flavor production at the ALICE\n  experiment","summary":"Heavy-flavor production at the LHC offers valuable tests of\nquantum-chromodynamics calculations, owing to the large masses of heavy quarks.\nMeasurements of charm production as a function of event activity reveal new\nfeatures of charm production and fragmentation, providing insights to the\ninterplay between soft and hard processes. In addition, charm production in\nheavy-ion collisions addresses flavor-dependent quark transport properties in\nboth hot and cold nuclear matter, helping to clarify the roles of coalescence\nand fragmentation in heavy-flavor hadron formation. This contribution\nsummarizes recent measurements from the ALICE experiment on charm production as\na function of charged-particle multiplicity in pp collisions at various\nenergies, including the measurements of charm baryon-to-meson production yield\nratios in pp, p--Pb and Pb--Pb collisions. New results on ${\\rm D}^0$\nproduction in pp collisions as a function of the transverse spherocity of the\nevent, as well as of the transverse event-activity classifier $R_{\\rm T}$, are\nalso presented.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-03-31T08:55:52Z"}
{"aid":"http://arxiv.org/abs/2503.23861v1","title":"$s_{\\pm}$ pairing via interlayer interaction in\n  La$_{2.85}$Pr$_{0.15}$Ni$_2$O$_7$ Thin Films under Ambient Pressure","summary":"We demonstrate that interlayer \\(s_{\\pm}\\)-wave pairing dominates\nsuperconductivity in La\\(_{2.85}\\)Pr\\(_{0.15}\\)Ni\\(_2\\)O\\(_7\\) thin films\nthrough self-consistent mean-field calculations. We further show that applying\na perpendicular electric field breaks layer equivalence, generating nodal\nstructures, Fermi arcs, and finite low-energy states in the \\(d_{x^2-y^2}\\)\norbital. Our results quantitatively align with recent experimental observations\nfor the superconducting gaps, and we propose experimental symmetry-breaking\nperturbations as a direct test for the interlayer pairing mechanism.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.str-el","published":"2025-03-31T09:08:26Z"}
{"aid":"http://arxiv.org/abs/2503.23921v1","title":"$K$-theoretic computation of the Atiyah(-Patodi)-Singer index of lattice\n  Dirac operators","summary":"We show that the Wilson Dirac operator in lattice gauge theory can be\nidentified as a mathematical object in $K$-theory and that its associated\nspectral flow is equal to the index. In comparison to the standard lattice\nDirac operator index, our formulation does not require the Ginsparg-Wilson\nrelation and has broader applicability to systems with boundaries and to the\nmod-two version of the indices in general dimensions. We numerically verify\nthat the $K$ and $KO$ group formulas reproduce the known index theorems in\ncontinuum theory. We examine the Atiyah-Singer index on a flat two-dimensional\ntorus and, for the first time, demonstrate that the Atiyah-Patodi-Singer index\nwith nontrivial curved boundaries, as well as the mod-two versions, can be\ncomputed on a lattice.","main_category":"hep-th","categories":"hep-th,hep-lat,math.KT","published":"2025-03-31T10:11:44Z"}
{"aid":"http://arxiv.org/abs/2503.23924v1","title":"Model Hemorrhage and the Robustness Limits of Large Language Models","summary":"Large language models (LLMs) demonstrate strong performance across natural\nlanguage processing tasks, yet undergo significant performance degradation when\nmodified for deployment through quantization, pruning, or decoding strategy\nadjustments. We define this phenomenon as model hemorrhage - performance\ndecline caused by parameter alterations and architectural changes. Through\nsystematic analysis of various LLM frameworks, we identify key vulnerability\npatterns: layer expansion frequently disrupts attention mechanisms, compression\ntechniques induce information loss cascades, and decoding adjustments amplify\nprediction divergences. Our investigation reveals transformer architectures\nexhibit inherent robustness thresholds that determine hemorrhage severity\nacross modification types. We propose three mitigation strategies:\ngradient-aware pruning preserves critical weight pathways, dynamic quantization\nscaling maintains activation integrity, and decoding calibration aligns\ngeneration trajectories with original model distributions. This work\nestablishes foundational metrics for evaluating model stability during\nadaptation, providing practical guidelines for maintaining performance while\nenabling efficient LLM deployment. Our findings advance understanding of neural\nnetwork resilience under architectural transformations, particularly for\nlarge-scale language models.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-03-31T10:16:03Z"}
{"aid":"http://arxiv.org/abs/2503.23930v1","title":"Exploring Reliable PPG Authentication on Smartwatches in Daily Scenarios","summary":"Photoplethysmography (PPG) Sensors, widely deployed in smartwatches, offer a\nsimple and non-invasive authentication approach for daily use. However, PPG\nauthentication faces reliability issues due to motion artifacts from physical\nactivity and physiological variability over time. To address these challenges,\nwe propose MTL-RAPID, an efficient and reliable PPG authentication model, that\nemploys a multitask joint training strategy, simultaneously assessing signal\nquality and verifying user identity. The joint optimization of these two tasks\nin MTL-RAPID results in a structure that outperforms models trained on\nindividual tasks separately, achieving stronger performance with fewer\nparameters. In our comprehensive user studies regarding motion artifacts (N =\n30), time variations (N = 32), and user preferences (N = 16), MTL-RAPID\nachieves a best AUC of 99.2\\% and an EER of 3.5\\%, outperforming existing\nbaselines. We opensource our PPG authentication dataset along with the\nMTL-RAPID model to facilitate future research on GitHub.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T10:25:48Z"}
{"aid":"http://arxiv.org/abs/2503.23939v1","title":"Simulation of Shor algorithm for discrete logarithm problems with\n  comprehensive pairs of modulo p and order q","summary":"The discrete logarithm problem (DLP) over finite fields, commonly used in\nclassical cryptography, has no known polynomial-time algorithm on classical\ncomputers. However, Shor has provided its polynomial-time algorithm on quantum\ncomputers. Nevertheless, there are only few examples simulating quantum\ncircuits that operate on general pairs of modulo $p$ and order $q$. In this\npaper, we constructed such quantum circuits and solved DLPs for all 1,860\npossible pairs of $p$ and $q$ up to 32 qubits using a quantum simulator with\nPRIMEHPC FX700. From this, we obtained and verified values of the success\nprobabilities, which had previously been heuristically analyzed by Eker\\r{a}.\nAs a result, we found that the success probability of Shor's algorithm for\nsolving the DLP exhibits periodicity with an asymmetric waveform determined by\nthe order $q$. Additionally, we generated 1,015 quantum circuits for larger\npairs of $p$ and $q$, extrapolated the circuit sizes obtained, and compared\nthem for $p=2048$ bits between safe-prime groups and Schnorr groups. While in\nclassical cryptography, the cipher strength of safe-prime groups and Schnorr\ngroups is the same if $p$ is equal, we quantitatively demonstrated how much the\nstrength of the latter decreases to the bit length of $p$ in the former when\nusing Shor's quantum algorithm. In particular, it was experimentally and\ntheoretically shown that when a ripple carry adder is used in the addition\ncircuit, the cryptographic strength of a Schnorr group with $p=2048$ bits under\nShor's algorithm is almost equivalent to that of a safe-prime group with\n$p=1024$ bits.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T10:39:10Z"}
{"aid":"http://arxiv.org/abs/2503.23953v1","title":"Skilful global seasonal predictions from a machine learning weather\n  model trained on reanalysis data","summary":"Machine learning weather models trained on observed atmospheric conditions\ncan outperform conventional physics-based models at short- to medium-range\n(1-14 day) forecast timescales. Here we take the machine learning weather model\nACE2, trained to predict 6-hourly steps in atmospheric evolution and which can\nremain stable over long forecast periods, and assess it from a seasonal\nforecasting perspective. Applying persisted sea surface temperature (SST) and\nsea-ice anomalies centred on 1st November each year, we initialise a lagged\nensemble of winter predictions covering 1993/1994 to 2015/2016. Over this\n23-year period there is remarkable similarity in the patterns of predictability\nwith a leading physics-based model. The ACE2 model exhibits skilful predictions\nof the North Atlantic Oscillation (NAO) with a correlation score of 0.47\n(p=0.02), as well as a realistic global distribution of skill and ensemble\nspread. Surprisingly, ACE2 is found to exhibit a signal-to-noise error as seen\nin physics-based models, in which it is better at predicting the real world\nthan itself. Examining predictions of winter 2009/2010 indicates potential\nlimitations of ACE2 in capturing extreme seasonal conditions that extend\noutside the training data. Nevertheless, this study reveals that machine\nlearning weather models can produce skilful global seasonal predictions and\nheralds a new era of increased understanding, development and generation of\nnear-term climate predictions.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-03-31T11:11:16Z"}
{"aid":"http://arxiv.org/abs/2503.23960v1","title":"Testing for integer integration in functional time series","summary":"We develop a statistical testing procedure to examine whether the\ncurve-valued time series of interest is integrated of order d for an integer d.\nThe proposed procedure can distinguish between integer-integrated time series\nand fractionally-integrated ones, and it has broad applicability in practice.\nMonte Carlo simulation experiments show that the proposed testing procedure\nperforms reasonably well. We apply our methodology to Canadian yield curve data\nand French sub-national age-specific mortality data. We find evidence that\nthese time series are mostly integrated of order one, while some have\nfractional orders exceeding or falling below one.","main_category":"stat.ME","categories":"stat.ME","published":"2025-03-31T11:20:38Z"}
{"aid":"http://arxiv.org/abs/2503.24010v1","title":"Roommates with Convex Preferences","summary":"Roommate problems with convex preferences always have stable matchings.\nEfficiency and individual rationality are, moreover, compatible with\nstrategyproofness in such convex roommate problems. Both of these results fail\nwithout the assumption of convexity. In the environment under study,\npreferences are convex if and only if they are single peaked. Any individually\nrational and convex roommate problem is homomorphic to a marriage market where\nan agent's gender corresponds to the direction of the agent's top-ranked\npartner. The existence of stable matchings then follows from the existence of\nstable matchings in marriage markets. To prove the second existence result, I\ndefine an efficient, individually rational, and strategyproof mechanism for\nconvex roommate problems. To calculate outcomes, this mechanism starts with all\nagents being single and then gradually reassigns agents to better partners by\nperforming minimal Pareto improvements. Whenever it becomes clear that some\nagent cannot be part of any further Pareto improvement, such an agent is\nmatched.","main_category":"econ.TH","categories":"econ.TH","published":"2025-03-31T12:36:48Z"}
{"aid":"http://arxiv.org/abs/2503.24063v1","title":"A robot-assisted pipeline to rapidly scan 1.7 million historical aerial\n  photographs","summary":"During the 20th Century, aerial surveys captured hundreds of millions of\nhigh-resolution photographs of the earth's surface. These images, the\nprecursors to modern satellite imagery, represent an extraordinary visual\nrecord of the environmental and social upheavals of the 20th Century. However,\nmost of these images currently languish in physical archives where retrieval is\ndifficult and costly. Digitization could revolutionize access, but manual\nscanning is slow and expensive. Here, we describe and validate a novel\nrobot-assisted pipeline that increases worker productivity in scanning 30-fold,\napplied at scale to digitize an archive of 1.7 million historical aerial\nphotographs from 65 countries.","main_category":"eess.IV","categories":"eess.IV,cs.SY,econ.GN,eess.SY,q-fin.EC","published":"2025-03-31T13:23:05Z"}
{"aid":"http://arxiv.org/abs/2503.24076v1","title":"On a question about real rooted polynomials and f-polynomials of\n  simplicial complexes","summary":"For a polynomial $f(t) = 1+f_0t+\\cdots +f_{d-1}t^d$ with positive integer\ncoefficients Bell and Skandera ask if real rootedness of f(t) implies that\nthere is a simplicial complex with f-vector $(1,f_0 \\ldots,f_{d-1})$. In this\npaper we discover properties implied by the real rootedness of f(t) in terms of\nthe binomial representation $f_i = \\binom{x_{i+1}}{i+1}, i \\geq 0$. We use\nthese to provide a sufficient criterion for a positive answer to the question\nby Bell and Skandera. We also describe two further approaches to the conjecture\nand use one to verify that some well studied real rooted classical polynomials\nare f-polynomials. Finally, we provide a series of results showing that the set\nof f-vectors of simplicial complexes is closed under constructions also\npreserving real rootedness of their generating polynomials.","main_category":"math.CO","categories":"math.CO","published":"2025-03-31T13:31:37Z"}
{"aid":"http://arxiv.org/abs/2503.24119v1","title":"Measuring User Experience Through Speech Analysis: Insights from HCI\n  Interviews","summary":"User satisfaction plays a crucial role in user experience (UX) evaluation.\nTraditionally, UX measurements are based on subjective scales, such as\nquestionnaires. However, these evaluations may suffer from subjective bias. In\nthis paper, we explore the acoustic and prosodic features of speech to\ndifferentiate between positive and neutral UX during interactive sessions. By\nanalyzing speech features such as root-mean-square (RMS), zero-crossing\nrate(ZCR), jitter, and shimmer, we identified significant differences between\nthe positive and neutral user groups. In addition, social speech features such\nas activity and engagement also show notable variations between these groups.\nOur findings underscore the potential of speech analysis as an objective and\nreliable tool for UX measurement, contributing to more robust and\nbias-resistant evaluation methodologies. This work offers a novel approach to\nintegrating speech features into UX evaluation and opens avenues for further\nresearch in HCI.","main_category":"cs.HC","categories":"cs.HC","published":"2025-03-31T14:07:38Z"}
{"aid":"http://arxiv.org/abs/2503.24120v1","title":"Renormalized mechanics and stochastic thermodynamics of growing model\n  protocells","summary":"Uncovering the rules governing the nonequilibrium dynamics of the membranes\nthat define biological cells is of central importance to understanding the\nphysics of living systems. We theoretically and computationally investigate the\nbehavior of model protocells -- flexible quasispherical vesicles -- that\nexchange membrane constituents, internal volume, and heat with an external\nreservoir. The excess chemical potential and osmotic pressure difference\nimposed by the reservoir act as generalized thermodynamic driving forces that\nmodulate vesicle morphology. We identify an associated nonequilibrium\nmorphological transition between a weakly driven regime, in which growing\nvesicles remain quasispherical, and a strongly driven regime, in which vesicles\naccommodate rapid membrane uptake by developing surface wrinkles. This\ntransition emerges due to the renormalization of membrane mechanical properties\nby nonequilibrium driving. Further, using insights from stochastic\nthermodynamics we propose a minimal vesicle growth-shape law that remains\nrobust even in strongly driven, far-from-equilibrium regimes.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.bio-ph","published":"2025-03-31T14:08:15Z"}
{"aid":"http://arxiv.org/abs/2503.24123v1","title":"CTSketch: Compositional Tensor Sketching for Scalable Neurosymbolic\n  Learning","summary":"Many computational tasks benefit from being formulated as the composition of\nneural networks followed by a discrete symbolic program. The goal of\nneurosymbolic learning is to train the neural networks using only end-to-end\ninput-output labels of the composite. We introduce CTSketch, a novel, scalable\nneurosymbolic learning algorithm. CTSketch uses two techniques to improve the\nscalability of neurosymbolic inference: decompose the symbolic program into\nsub-programs and summarize each sub-program with a sketched tensor. This\nstrategy allows us to approximate the output distribution of the program with\nsimple tensor operations over the input distributions and summaries. We provide\ntheoretical insight into the maximum error of the approximation. Furthermore,\nwe evaluate CTSketch on many benchmarks from the neurosymbolic literature,\nincluding some designed for evaluating scalability. Our results show that\nCTSketch pushes neurosymbolic learning to new scales that have previously been\nunattainable by obtaining high accuracy on tasks involving over one thousand\ninputs.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T14:08:58Z"}
{"aid":"http://arxiv.org/abs/2503.24142v1","title":"Dust Concentration Via Coupled Vertical Settling and Radial Migration in\n  Substructured Non-Ideal MHD Discs and Early Planet Formation","summary":"We investigate the dynamics of dust concentration in actively accreting,\nsubstructured, non-ideal MHD wind-launching disks using 2D and 3D simulations\nincorporating pressureless dust fluids of various grain sizes and their\naerodynamic feedback on gas dynamics. Our results reveal that mm/cm-sized\ngrains are preferentially concentrated within the inner 5-10 au of the disk,\nwhere the dust-to-gas surface density ratio (local metalicity Z) significantly\nexceeds the canonical 0.01, reaching values up to 0.25. This enhancement arises\nfrom the interplay of dust settling and complex gas flows in the meridional\nplane, including midplane accretion streams at early times, midplane expansion\ndriven by magnetically braked surface accretion at later times, and vigorous\nmeridional circulation in spontaneously formed gas rings. The resulting\nsize-dependent dust distribution has a strong spatial variation, with large\ngrains preferentially accumulating in dense rings, particularly in the inner\ndisk, while being depleted in low-density gas gaps. In 3D, these rings and gaps\nare unstable to Rossby wave instability (RWI), generating arc-shaped vortices\nthat stand out more prominently than their gas counterparts in the inner disk\nbecause of preferential dust concentration at small radii. The substantial\nlocal enhancement of the dust relative to the gas could promote planetesimal\nformation via streaming instability, potentially aided by the \"azimuthal drift\"\nstreaming instability (AdSI) that operates efficiently in accreting disks and a\nlower Toomre Q expected in younger disks. Our findings suggest that actively\naccreting young disks may provide favorable conditions for early planetesimal\nformation, which warrants further investigation.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-03-31T14:26:32Z"}
{"aid":"http://arxiv.org/abs/2503.24146v1","title":"Joint Modeling of Multiple Longitudinal Biomarkers and Survival Outcomes\n  via Threshold Regression: Variability as a Predictor","summary":"Longitudinal biomarker data and health outcomes are routinely collected in\nmany studies to assess how biomarker trajectories predict health outcomes.\nExisting methods primarily focus on mean biomarker profiles, treating\nvariability as a nuisance. However, excess variability may indicate system\ndysregulations that may be associated with poor outcomes. In this paper, we\naddress the long-standing problem of using variability information of multiple\nlongitudinal biomarkers in time-to-event analyses by formulating and studying a\nBayesian joint model. We first model multiple longitudinal biomarkers, some of\nwhich are subject to limit-of-detection censoring. We then model the survival\ntimes by incorporating random effects and variances from the longitudinal\ncomponent as predictors through threshold regression that admits\nnon-proportional hazards. We demonstrate the operating characteristics of the\nproposed joint model through simulations and apply it to data from the Study of\nWomen's Health Across the Nation (SWAN) to investigate the impact of the mean\nand variability of follicle-stimulating hormone (FSH) and anti-Mullerian\nhormone (AMH) on age at the final menstrual period (FMP).","main_category":"stat.AP","categories":"stat.AP","published":"2025-03-31T14:33:04Z"}
{"aid":"http://arxiv.org/abs/2503.24156v1","title":"Reinforcing Localization Credibility Through Convex Optimization","summary":"This work proposes a novel approach to reinforce localization security in\nwireless networks in the presence of malicious nodes that are able to\nmanipulate (spoof) radio measurements. It substitutes the original measurement\nmodel by another one containing an auxiliary variance dilation parameter that\ndisguises corrupted radio links into ones with large noise variances. This\nallows for relaxing the non-convex maximum likelihood estimator (MLE) into a\nsemidefinite programming (SDP) problem by applying convex-concave programming\n(CCP) procedure. The proposed SDP solution simultaneously outputs target\nlocation and attacker detection estimates, eliminating the need for further\napplication of sophisticated detectors. Numerical results corroborate excellent\nperformance of the proposed method in terms of localization accuracy and show\nthat its detection rates are highly competitive with the state of the art.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T14:40:08Z"}
{"aid":"http://arxiv.org/abs/2503.24170v1","title":"Localization of operator-valued frames","summary":"We introduce a localization concept for operator-valued frames, where the\nquality of localization is measured by the associated operator-valued Gram\nmatrix belonging to some suitable Banach algebra. We prove that intrinsic\nlocalization of an operator-valued frame is preserved by its canonical dual.\nMoreover, we show that the series associated to the perfect reconstruction of\nan operator-valued frame converges not only in the underlying Hilbert space,\nbut also in a whole class of associated (quasi-)Banach spaces. Finally, we\napply our results to irregular Gabor g-frames.","main_category":"math.FA","categories":"math.FA","published":"2025-03-31T14:49:54Z"}
{"aid":"http://arxiv.org/abs/2503.24181v1","title":"Computational challenges of 21st century Global Astrometry","summary":"Major advancements in space science and detector technology brought about a\nrevolution in global astrometry, the science of measuring distances and motions\nof stars in the Milky Way and in the local universe. From the first ESA\nastrometric mission HIPPARCOS of the early 80s to the current Gaia mission, the\ndata volume and computational complexity of the full reduction process has\nincreased by several orders of magnitude, requiring high-performance computing\nand data throughput. We review the principles and computational complexity of\ngeneral global astrometric models that lead to the statistical treatment of an\nextra-large, highly non-linear estimation problem. Some numerical aspects of\ninspecting Gaia's proper motions to find cosmological signals at all scales are\nalso addressed.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-03-31T14:58:40Z"}
{"aid":"http://arxiv.org/abs/2503.24188v1","title":"A Swift analysis of the Eras tour set list and implications for\n  astrophysics research (Taylor's version)","summary":"Popular culture plays a significant role in shaping public interest in\nscience, and Taylor Swift's discography frequently incorporates astrophysics\nterminology. This study examines the occurrence of astrophysics-related words\nin her lyrics and their representation in the Eras tour set list. By analyzing\nthe frequency of words in Swift's total discography, we identify that\nastrophysics is promoted the most within her most recent album, The Tortured\nPoets Department, whereas songs from Midnights promoted astrophysics the most\nthroughout the Eras tour. We catagorize words into various disciplines of\nastrophysics and find that multimessenger astronomy is promoted the most, both\nin Swift's total discography and throughout the Eras tour. We perform Taylor\nexpansion and predict $12 \\pm 5$ astrophysical terms in Swift's next album.\nThis analysis offers a unique perspective on the intersection of music and\nscience, revealing how Swift's artistry may unintentionally promote interest in\ndifferent fields of astrophysics.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO,astro-ph.IM,astro-ph.SR,physics.ed-ph,physics.soc-ph","published":"2025-03-31T15:05:48Z"}
{"aid":"http://arxiv.org/abs/2503.24189v1","title":"Quantum superalgebras and the free-fermionic Yang-Baxter equation","summary":"The free-fermion point refers to a\n$\\operatorname{GL}(2)\\times\\operatorname{GL}(1)$ parametrized Yang-Baxter\nequation within the six-vertex model. It has been known for a long time that\nthis is connected with the quantum group $U_q(\\mathfrak{gl}(1|1))$. We\ndemonstrate that $R$-matrices from the finite quantum superalgebra\n$U_q(\\mathfrak{gl}(1|1))$ recovers a dense subset of the free-fermion point of\nthe six-vertex model and recover the prime, simple modules in the affine\nquantum superalgebra $U_q(\\widehat{\\mathfrak{gl}}(1|1))$. Either of these\nquantum groups can be used to generate the full free-fermion point, and we\ndiscuss them both. Our discussion includes 6 families of six-vertex models used\nby Brubaker, Bump, and Friedberg in connection with Tokuyama's theorem, a\ndeformation of the Weyl character formula. Thus our work gives quantum group\ninterpretations for those models, known informally as Tokuyama ice.","main_category":"math.RT","categories":"math.RT,math.QA","published":"2025-03-31T15:06:50Z"}
{"aid":"http://arxiv.org/abs/2503.24195v1","title":"Computational Orthodontic Force Simulation: A Review","summary":"In orthodontic treatment, the biological response of the tooth, periodontal\nligament, and bone complex to orthodontic force is crucial in influencing\ntreatment outcomes. The challenge lies in accurately measuring, estimating, and\npredicting these forces during clinical procedures. This review aims to fill\nthe gap in the literature by systematically summarizing existing research on\northodontic force simulation, examining common loading techniques and\ntechnologies, and discussing the potential for refining the orthodontic force\nsimulation process. The literature was comprehensively reviewed, with an\nemphasis on the exploration of the biological mechanism of tooth movement.\nStudies were categorized based on force-loading techniques for both fixed and\ninvisible orthodontic appliances. Finite element (FE) analysis stands out as\nthe predominant technique for orthodontic force simulation, with a significant\nfocus on fixed orthodontics but limited emphasis on invisible orthodontics.\nCurrent orthodontic force simulations tend to be fragmented, often considering\nonly the instantaneous response to applied forces. There exists an urgent\ndemand for a sophisticated analytical simulation model. Such a model, possibly\nleveraging advanced technologies like deep learning, holds the promise of\nforecasting orthodontic treatment outcomes with heightened precision and\nefficiency.","main_category":"physics.med-ph","categories":"physics.med-ph,cs.NA,math.NA","published":"2025-03-31T15:13:36Z"}
{"aid":"http://arxiv.org/abs/2503.24221v1","title":"The Categories of Lubin-Tate and Drinfeld Bundles","summary":"For a finite extension $F$ of $\\mathbb{Q}_p$ and $n \\geq 1$, we show that the\ncategory of Lubin-Tate bundles on the $(n-1)$-dimensional Drinfeld symmetric\nspace is equivalent to the category of finite-dimensional smooth\nrepresentations of the group of units of the division algebra of invariant\n$1/n$ over $F$.","main_category":"math.NT","categories":"math.NT,math.AG,math.RT","published":"2025-03-31T15:37:25Z"}
{"aid":"http://arxiv.org/abs/2503.24226v1","title":"Asymptotic Freedom and Finite-size Scaling of Two-dimensional Classical\n  Heisenberg Model","summary":"The classical Heisenberg model is one of the most fundamental models in\nstatistical and condensed matter physics. Extensive theoretical and numerical\nstudies suggest that, in two dimensions, this model does not exhibit a\nfinite-temperature phase transition but instead manifests asymptotic freedom.\nHowever, some research has also proposed the possibility of a\nBerezinskii-Kosterlitz-Thouless (BKT) phase transition over the years. In this\nstudy, we revisit the classical two-dimensional (2D) Heisenberg model through\nlarge-scale simulations with linear system sizes up to $L=16384$. Our\nMonte-Carlo data, without any extrapolation, clearly reveal an exponential\ndivergence of the correlation length $\\xi$ as a function of inverse temperature\n$\\beta$, a hallmark of asymptotic freedom. Moreover, extrapolating $\\xi$ to the\nthermodynamic limit in the low-temperature regime achieves close agreement with\nthe three-loop perturbative calculations. We further propose a finite-size\nscaling (FSS) ansatz for $\\xi$, demonstrating that the pseudo-critical point\n$\\beta_L$ diverges logarithmically with $L$. The thermodynamic and finite-size\nscaling behaviors of the magnetic susceptibility $\\chi$ are also investigated\nand corroborate the prediction of asymptotic freedom. Our work provides solid\nevidence for asymptotic freedom in the 2D Heisenberg model and advances\nunderstanding of finite-size scaling in such systems.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-03-31T15:39:13Z"}
{"aid":"http://arxiv.org/abs/2503.24236v1","title":"Estimating a graph's spectrum via random Kirchhoff forests","summary":"Exact eigendecomposition of large matrices is very expensive, and it is\npractically impossible to compute exact eigenvalues. Instead, one may set a\nmore modest goal of approaching the empirical distribution of the eigenvalues,\nrecovering the overall shape of the eigenspectrum. Current approaches to\nspectral estimation typically work with \\emph{moments} of the spectral\ndistribution. These moments are first estimated using Monte Carlo trace\nestimators, then the estimates are combined to approximate the spectral\ndensity. In this article we show how \\emph{Kirchhoff forests}, which are random\nforests on graphs, can be used to estimate certain non-linear moments of very\nlarge graph Laplacians. We show how to combine these moments into an estimate\nof the spectral density. If the estimate's desired precision isn't too high,\nour approach paves the way to the estimation of a graph's spectrum in time\nsublinear in the number of links.","main_category":"stat.CO","categories":"stat.CO,math.ST,stat.TH","published":"2025-03-31T15:47:55Z"}
{"aid":"http://arxiv.org/abs/2503.24270v1","title":"Visual Acoustic Fields","summary":"Objects produce different sounds when hit, and humans can intuitively infer\nhow an object might sound based on its appearance and material properties.\nInspired by this intuition, we propose Visual Acoustic Fields, a framework that\nbridges hitting sounds and visual signals within a 3D space using 3D Gaussian\nSplatting (3DGS). Our approach features two key modules: sound generation and\nsound localization. The sound generation module leverages a conditional\ndiffusion model, which takes multiscale features rendered from a\nfeature-augmented 3DGS to generate realistic hitting sounds. Meanwhile, the\nsound localization module enables querying the 3D scene, represented by the\nfeature-augmented 3DGS, to localize hitting positions based on the sound\nsources. To support this framework, we introduce a novel pipeline for\ncollecting scene-level visual-sound sample pairs, achieving alignment between\ncaptured images, impact locations, and corresponding sounds. To the best of our\nknowledge, this is the first dataset to connect visual and acoustic signals in\na 3D context. Extensive experiments on our dataset demonstrate the\neffectiveness of Visual Acoustic Fields in generating plausible impact sounds\nand accurately localizing impact sources. Our project page is at\nhttps://yuelei0428.github.io/projects/Visual-Acoustic-Fields/.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T16:16:10Z"}
{"aid":"http://arxiv.org/abs/2503.24290v1","title":"Open-Reasoner-Zero: An Open Source Approach to Scaling Up Reinforcement\n  Learning on the Base Model","summary":"We introduce Open-Reasoner-Zero, the first open source implementation of\nlarge-scale reasoning-oriented RL training focusing on scalability, simplicity\nand accessibility. Through extensive experiments, we demonstrate that a\nminimalist approach, vanilla PPO with GAE ($\\lambda=1$, $\\gamma=1$) and\nstraightforward rule-based rewards, without any KL regularization, is\nsufficient to scale up both response length and benchmark performance, similar\nto the phenomenon observed in DeepSeek-R1-Zero. Using the same base model as\nDeepSeek-R1-Zero-Qwen-32B, our implementation achieves superior performance on\nAIME2024, MATH500, and the GPQA Diamond benchmark while demonstrating\nremarkable efficiency -- requiring only a tenth of the training steps, compared\nto DeepSeek-R1-Zero pipeline. In the spirit of open source, we release our\nsource code, parameter settings, training data, and model weights across\nvarious sizes.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-03-31T16:36:05Z"}
{"aid":"http://arxiv.org/abs/2503.24294v1","title":"Nonlinear-elasticity models with surface energy","summary":"Soft solids with surface energy exhibit complex mechanical behavior,\nnecessitating advanced constitutive models to capture the interplay between\nbulk and surface mechanics. This interplay has profound implications for\nmaterial design and emerging technologies. In this work, we set up variational\nmodels for bulk-surface elasticity and explore a novel class of\nsurface-polyconvex constitutive models that account for surface energy while\nensuring the existence of minimizers. These models are implemented within a\nfinite element framework and validated through benchmark problems and\napplications, including, e.g., the liquid bridge problem and the\nRayleigh-Plateau instability, for which the surface energy plays the dominant\nrole. The results demonstrate the ability of surface-polyconvex models to\naccurately capture surface-driven phenomena, establishing them as a powerful\ntool for advancing the mechanics of soft materials in both engineering and\nbiological applications.","main_category":"math-ph","categories":"math-ph,math.MP","published":"2025-03-31T16:41:37Z"}
{"aid":"http://arxiv.org/abs/2503.24302v1","title":"Synergy of Doob Transformation and Montroll Defect Theory for Random\n  Walks in External Potentials","summary":"We present a systematic method for constructing stochastic processes by\nmodifying simpler, analytically solvable random walks on discrete lattices. Our\nframework integrates the Doob $h$-transformation with the Montroll defect\ntheory, overcoming the strict constraints associated with each method alone. By\ncombining these two approaches, we map random walks in simple potentials onto\nprocesses involving more general external potentials and metastable states.\nExplicit analytical expressions relate the transformed process to the original\none, facilitating direct investigation of exponential decay rates and\nadditional dynamical modes. As an illustrative example, we demonstrate our\nmethod by analyzing a random walker in a linear potential modified to include a\nmetastable state, revealing distinct exponential decay regimes relevant to\nescape dynamics.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-03-31T16:47:14Z"}
{"aid":"http://arxiv.org/abs/2503.24318v1","title":"Quantum Conference Key Agreement with Classical Advantage Distillation","summary":"In this work, we prove security of a quantum conference key agreement (QCKA)\nprotocol augmented with a classical advantage distillation (CAD) protocol. We\nderive a proof of security, in the finite key setting, that is able to bound\nthe secure key rate for any general, coherent, attack. We evaluate the\nperformance of the system, showing our result can improve the noise tolerance\nof the protocol in some, but not all, scenarios.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T17:07:36Z"}
{"aid":"http://arxiv.org/abs/2503.24319v1","title":"Resolving the baryon assymmetry with RATS","summary":"Current leading theories of physics such as the Big Bang, the standard model\nof particle physics, and general relativity suggest that the universe should\ncontain an equal amount of matter and antimatter. Yet observations have found a\ndisproportionately large amount of matter, a phenomenon known as the baryon\nassymmetry problem. Since century-old established theories are traditionally\nimpossible to refute, the only possible explanation is that the remaining\nantimatter is hidden in plain sight and remains to be observed. We propose the\nexistence of anti-stars to solve the baryon assymetry in our new Reasonable\nAntimatter Theory of Stars (RATS). In this context, the RATS will create a\nframework to resolve the traditional tension between observers and theorists,\nand thus contribute to the peaceful and collaborative spirit of astronomy. Our\nmethod is the firing of neurons in our brains, typically known as a thought\nexperiment. We still have no idea why or how this works, but it must be good\nbecause most of science was created this way. Our results are the result of our\nmethods, which result in some text and the resulting conclusions. In order to\nencourage the reader to reach the end of this short paper, we do not want to\nspoil the conclusions here. Instead, the conclusions will conclude the paper.","main_category":"physics.pop-ph","categories":"physics.pop-ph,astro-ph.CO,astro-ph.SR","published":"2025-03-31T17:07:37Z"}
{"aid":"http://arxiv.org/abs/2503.24365v1","title":"Which LIME should I trust? Concepts, Challenges, and Solutions","summary":"As neural networks become dominant in essential systems, Explainable\nArtificial Intelligence (XAI) plays a crucial role in fostering trust and\ndetecting potential misbehavior of opaque models. LIME (Local Interpretable\nModel-agnostic Explanations) is among the most prominent model-agnostic\napproaches, generating explanations by approximating the behavior of black-box\nmodels around specific instances. Despite its popularity, LIME faces challenges\nrelated to fidelity, stability, and applicability to domain-specific problems.\nNumerous adaptations and enhancements have been proposed to address these\nissues, but the growing number of developments can be overwhelming,\ncomplicating efforts to navigate LIME-related research. To the best of our\nknowledge, this is the first survey to comprehensively explore and collect\nLIME's foundational concepts and known limitations. We categorize and compare\nits various enhancements, offering a structured taxonomy based on intermediate\nsteps and key issues. Our analysis provides a holistic overview of advancements\nin LIME, guiding future research and helping practitioners identify suitable\napproaches. Additionally, we provide a continuously updated interactive website\n(https://patrick-knab.github.io/which-lime-to-trust/), offering a concise and\naccessible overview of the survey.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-03-31T17:44:39Z"}
{"aid":"http://arxiv.org/abs/2504.01325v1","title":"Coarse chain recurrence, Morse graphs with finite errors, and\n  persistence of circulations","summary":"In flow control, finite energy may be injected to push out material trapped\nin the attractor and to eliminate stagnation and circulate the flow. To\ndescribe such phenomena and to give a lower bound on the energy required, we\ngeneralize the existing concepts of chain recurrence. In fact, this paper\nintroduces concepts of ``coarse chain recurrences'' and Morse graphs with\nfinite errors. Using these concepts, we describe toy models of escape from\nattracting basins and elimination of stagnation by controls using finite\nenergy, persistence of recurrent points, and singular limit behaviors where\nenergy injections go to zero. Furthermore, we construct filtrations associated\nwith dynamical systems, which indicate the persistence of circulations.","main_category":"math.DS","categories":"math.DS","published":"2025-04-02T03:18:34Z"}
{"aid":"http://arxiv.org/abs/2504.01351v1","title":"Demonstration of Plate Analysis, an algorithm for precise relative\n  astrometry","summary":"Astrometry plays a crucial role in understanding the structure, dynamics, and\nevolution of celestial objects by providing precise measurements of their\npositions and motions. We propose a new approach to wide-field, relative\nastrometry, Plate Analysis. Plate Analysis is an innovative algorithm that\nestimates stellar coordinates and corrects geometric distortion based on\nprecise reference sources, without relying on dedicated calibration fields. It\nis implemented as a probabilistic framework using Stochastic Variational\nInference to efficiently optimize the numerous parameters involved in the\nmodel.\n  The methodology was tested through a simplified simulation designed after the\nGalactic center survey of the JASMINE mission. This simulation, called the\nJASMINE mini-mock survey, covered three years of observation with 100 satellite\norbits, providing a comprehensive dataset for evaluating the performance of\nPlate Analysis. Although the observation model incorporated more than 30,000\nparameters, the parameters were efficiently optimized through Plate Analysis.\nThe results showed that the estimated coordinates closely match the expected\nstellar motions, with an average positional error of about $70\\,\\mathrm{\\mu\nas}$. These findings validate the potential of Plate Analysis for precise\nwide-field astrometric applications, offering significant insights into\nimproving the accuracy of stellar dynamics measurements.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-02T04:51:21Z"}
{"aid":"http://arxiv.org/abs/2504.01356v1","title":"xML-workFlow: an end-to-end explainable scikit-learn workflow for rapid\n  biomedical experimentation","summary":"Motivation: Building and iterating machine learning models is often a\nresource-intensive process. In biomedical research, scientific codebases can\nlack scalability and are not easily transferable to work beyond what they were\nintended. xML-workFlow addresses this issue by providing a rapid, robust, and\ntraceable end-to-end workflow that can be adapted to any ML project with\nminimal code rewriting.\n  Results: We show a practical, end-to-end workflow that integrates\nscikit-learn, MLflow, and SHAP. This template significantly reduces the time\nand effort required to build and iterate on ML models, addressing the common\nchallenges of scalability and reproducibility in biomedical research. Adapting\nour template may save bioinformaticians time in development and enables\nbiomedical researchers to deploy ML projects.\n  Availability and implementation: xML-workFlow is available at\nhttps://github.com/MedicalGenomicsLab/xML-workFlow.","main_category":"cs.LG","categories":"cs.LG,cs.SE","published":"2025-04-02T05:01:12Z"}
{"aid":"http://arxiv.org/abs/2504.01401v1","title":"Systematic study of -decay half-lives of superheavy nuclei based\n  on Coulomb and proximity potential models with temperature effects","summary":"By employing the Coulomb proximity potential model (CPPM) in conjunction with\n22 distinct proximity potential models, we investigated the temperature\ndependence and the effects of proton number and neutron number on the diffusion\nparameters that determine the {\\alpha}-decay half-lives of superheavy nuclei.\nThe results indicate that the Prox.77-3 T-DEP proximity potential model yields\nthe best performance, with the lowest root mean square deviation\n({\\sigma}=0.515), reflecting a high consistency with experimental data. In\ncontrast, Bass77, AW95, Ngo80, and Guo2013 display larger deviations. The\ninclusion of temperature dependence significantly improves the accuracy of\nmodels such as Prox.77-3, Prox.77-6, and Prox.77-7. The -decay half-lives of 36\npotential superheavy nuclei were further predicted using the five most accurate\nproximity potential models and Ni's empirical formula, with the results\naligning well with experimental data. These predictions underscore the high\nreliability of the CPPM combined with proximity potential models in the\ntheoretical calculation of {\\alpha}-decay half-lives of superheavy nuclei,\noffering valuable theoretical insights for future experimental investigations\nof superheavy nuclei.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-02T06:39:48Z"}
{"aid":"http://arxiv.org/abs/2504.01414v1","title":"Balancing Subjectivity and Objectivity in Network Selection: A\n  Decision-Making Framework Towards Digital Twins","summary":"Selecting the optimal radio access technology (RAT) during vertical handovers\n(VHO) in heterogeneous wireless networks (HWNs) is critical. Multi-attribute\ndecision-making (MADM) is the most common approach used for network selection\n(NS) in HWNs. However, existing MADM-NS methods face two major challenges: the\nrank reversal problem (RRP), where the relative ranking of alternatives changes\nunexpectedly, and inefficient handling of user and/or service requirements.\nThese limitations result in suboptimal RAT selection and diminished quality of\nservice, which becomes particularly critical for time-sensitive applications.\nTo address these issues, we introduce in this work a novel weighting assignment\ntechnique called BWM-GWO, which integrates the Best-Worst Method (BWM) with the\nGrey Wolf Optimization (GWO) algorithm through a convex linear combination. The\nproposed framework achieves a balanced decision-making process by using BWM to\ncompute subjective weights that capture user/service preferences, while\nemploying GWO to derive objective weights aimed at minimizing RRP. The\ndevelopment and validation of this framework establish a digital model for NS\nin HWNs, marking the initial step toward realizing a digital twin (DT).\nExperimental results show that integrating the proposed BWM-GWO technique with\nMADM-NS reduces RRP occurrence by up to 71.3% while significantly improving\nuser and service satisfaction compared to benchmark approaches.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-02T07:06:58Z"}
{"aid":"http://arxiv.org/abs/2504.01424v1","title":"On the Role of Priors in Bayesian Causal Learning","summary":"In this work, we investigate causal learning of independent causal mechanisms\nfrom a Bayesian perspective. Confirming previous claims from the literature, we\nshow in a didactically accessible manner that unlabeled data (i.e., cause\nrealizations) do not improve the estimation of the parameters defining the\nmechanism. Furthermore, we observe the importance of choosing an appropriate\nprior for the cause and mechanism parameters, respectively. Specifically, we\nshow that a factorized prior results in a factorized posterior, which resonates\nwith Janzing and Sch\\\"olkopf's definition of independent causal mechanisms via\nthe Kolmogorov complexity of the involved distributions and with the concept of\nparameter independence of Heckerman et al.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T07:19:49Z"}
{"aid":"http://arxiv.org/abs/2504.01426v1","title":"Temperature and misorientation-dependent austenite nucleation at ferrite\n  grain boundaries in a medium manganese steel: role of\n  misorientation-dependent grain boundary segregation","summary":"In the current work, we study the role of grain boundary (GB)\nmisorientation-dependent segregation on austenite nucleation in a 50% cold\nrolled intercritically annealed 10Mn-0.05C-1.5Al (wt. %) medium Mn steel.\nDuring intercritical annealing at 500{\\deg}C, austenite nucleates predominantly\nat high-angle GBs. At 600{\\deg}C, austenite nucleates additionally at low-angle\nGBs, exhibiting a temperature dependance. Correlative transmission Kikuchi\ndiffraction /atom probe tomography reveals a misorientation-dependent\nsegregation. While GB segregation has been reported to assist austenite\nnucleation in medium manganese steels (3-12 wt.% Mn), an understanding of the\ntemperature and misorientation dependance is lacking, which is the aim of\ncurrent work. Since artifacts of atom probe can cause a broadening of the\nsegregation width, we combined experiments with results from density functional\ntheory (DFT) calculations that reveal that the Mn segregation is not limited to\nthe GB plane but confined to a region in the range of approximately 1 nm.\nConsequently, GB segregation alters both the GB interface energy and the free\nenergy per unit volume corresponding to the transformation. We estimate the\nlocal driving force for austenite nucleation accounting for the segregation\nwidth of ~ 1 nm. Based on classical nucleation theory, we clarify the effect of\nGB segregation on the critical radius and activation energy barrier for\nconfined austenite nucleation at the GB.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T07:22:43Z"}
{"aid":"http://arxiv.org/abs/2504.01483v1","title":"GarmageNet: A Dataset and Scalable Representation for Generic Garment\n  Modeling","summary":"High-fidelity garment modeling remains challenging due to the lack of\nlarge-scale, high-quality datasets and efficient representations capable of\nhandling non-watertight, multi-layer geometries. In this work, we introduce\nGarmage, a neural-network-and-CG-friendly garment representation that\nseamlessly encodes the accurate geometry and sewing pattern of complex\nmulti-layered garments as a structured set of per-panel geometry images. As a\ndual-2D-3D representation, Garmage achieves an unprecedented integration of 2D\nimage-based algorithms with 3D modeling workflows, enabling high fidelity,\nnon-watertight, multi-layered garment geometries with direct compatibility for\nindustrial-grade simulations.Built upon this representation, we present\nGarmageNet, a novel generation framework capable of producing detailed\nmulti-layered garments with body-conforming initial geometries and intricate\nsewing patterns, based on user prompts or existing in-the-wild sewing patterns.\nFurthermore, we introduce a robust stitching algorithm that recovers per-vertex\nstitches, ensuring seamless integration into flexible simulation pipelines for\ndownstream editing of sewing patterns, material properties, and dynamic\nsimulations. Finally, we release an industrial-standard, large-scale,\nhigh-fidelity garment dataset featuring detailed annotations, vertex-wise\ncorrespondences, and a robust pipeline for converting unstructured production\nsewing patterns into GarmageNet standard structural assets, paving the way for\nlarge-scale, industrial-grade garment generation systems.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-02T08:37:32Z"}
{"aid":"http://arxiv.org/abs/2504.01489v1","title":"Test-Time Alignment for Tracking User Interest Shifts in Sequential\n  Recommendation","summary":"Sequential recommendation is essential in modern recommender systems, aiming\nto predict the next item a user may interact with based on their historical\nbehaviors. However, real-world scenarios are often dynamic and subject to\nshifts in user interests. Conventional sequential recommendation models are\ntypically trained on static historical data, limiting their ability to adapt to\nsuch shifts and resulting in significant performance degradation during\ntesting. Recently, Test-Time Training (TTT) has emerged as a promising\nparadigm, enabling pre-trained models to dynamically adapt to test data by\nleveraging unlabeled examples during testing. However, applying TTT to\neffectively track and address user interest shifts in recommender systems\nremains an open and challenging problem. Key challenges include how to capture\ntemporal information effectively and explicitly identifying shifts in user\ninterests during the testing phase. To address these issues, we propose\nT$^2$ARec, a novel model leveraging state space model for TTT by introducing\ntwo Test-Time Alignment modules tailored for sequential recommendation,\neffectively capturing the distribution shifts in user interest patterns over\ntime. Specifically, T$^2$ARec aligns absolute time intervals with\nmodel-adaptive learning intervals to capture temporal dynamics and introduce an\ninterest state alignment mechanism to effectively and explicitly identify the\nuser interest shifts with theoretical guarantees. These two alignment modules\nenable efficient and incremental updates to model parameters in a\nself-supervised manner during testing, enhancing predictions for online\nrecommendation. Extensive evaluations on three benchmark datasets demonstrate\nthat T$^2$ARec achieves state-of-the-art performance and robustly mitigates the\nchallenges posed by user interest shifts.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-02T08:42:30Z"}
{"aid":"http://arxiv.org/abs/2504.01510v1","title":"Surface forces and frictional properties of adsorbed bio-based cationic\n  polysaccharide thin films in salted aqueous medium","summary":"Inter-surface forces mediated by polymer films are important in a range of\ntechnological and industrial situations. In cosmetics, applications such as\nhair conditioning typically rely on the adsorption of polyelectrolyte films\nonto the charged surface of hair fibers, whose contact mechanics and\ntribological properties are central in determining the final sensorial\nperceptions associated with the cosmetic treatment. A major current challenge\nto be tackled by the cosmetic industry is to design high-performance products\nemploying bio-sourced polyelectrolytes, with the aim of achieving\neco-sustainable processes and products. In this context, the present study\nfocuses on the mechanical properties of thin films obtained by adsorption from\nsolution of fungal chitosan onto negatively charged mica surfaces. We use a\nSurface Forces Apparatus allowing for the simultaneous measurement of film\nthickness and friction force as a function of the applied normal load and shear\nvelocity. We show that, in aqueous medium at an ionic strength of 40 mM,\nadsorbed films of chitosan give rise to repulsive inter-surface forces whose\nrange, comparable to the Flory radius of the macromolecules, increases with the\npolymer molecular weight. In addition, the adsorbed layers are found to behave,\nunder compressive forces, as pseudo-brushes of neutral polymers. Finally, we\nshow that under shear forces, chitosan layers exhibit a transition from a low\nto a high friction regime under increasing confinement.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-02T08:57:56Z"}
{"aid":"http://arxiv.org/abs/2504.01527v1","title":"Beyond Nearest Neighbor Interpolation in Data Augmentation","summary":"Avoiding the risk of undefined categorical labels using nearest neighbor\ninterpolation overlooks the risk of exacerbating pixel level annotation errors\nin data augmentation. To simultaneously avoid these risks, the author modified\nconvolutional neural networks data transformation functions by incorporating a\nmodified geometric transformation function to improve the quality of augmented\ndata by removing the reliance on nearest neighbor interpolation and integrating\na mean based class filtering mechanism to handle undefined categorical labels\nwith alternative interpolation algorithms. Experiments on semantic segmentation\ntasks using three medical image datasets demonstrated both qualitative and\nquantitative improvements with alternative interpolation algorithms.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T09:13:18Z"}
{"aid":"http://arxiv.org/abs/2504.01539v1","title":"Black hole solutions in quantum phenomenological gravitational dynamics","summary":"We investigate black hole solutions within a phenomenological approach to\nquantum gravity based on spacetime thermodynamics developed by Alonso-Serrano\nand Li\\v{s}ka. The field equations are traceless, similarly to unimodular\ngravity, and include quadratic curvature corrections. We find that static,\nspherically symmetric, vacuum spacetimes in this theory split into two\nbranches. The first branch is indistinguishable from corresponding solutions in\nunimodular gravity and describes Schwarzschild-(Anti) de Sitter black holes.\nThe second branch instead describes horizonless solutions and is characterized\nby large values of the spatial curvature. We analyze the dynamics of\nfirst-order metric perturbations on both branches, showing that there are no\ndeviations from unimodular gravity at this level.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-02T09:26:01Z"}
{"aid":"http://arxiv.org/abs/2504.01609v1","title":"The Mini-SiTian Array: the mini-SiTian Realtime Image Processing\n  pipeline (STRIP)","summary":"This paper provides a comprehensive introduction to the Mini-SiTian Real-Time\nImage Processing pipeline (STRIP) and evaluates its operational performance.\nThe STRIP pipeline is specifically designed for real-time alert triggering and\nlight curve generation for transient sources. By applying the STRIP pipeline to\nboth simulated and real observational data of the Mini-SiTian survey, it\nsuccessfully identified various types of variable sources, including stellar\nflares, supernovae, variable stars, and asteroids, while meeting requirements\nof reduction speed within 5 minutes. For the real observational dataset, the\npipeline detected 1 flare event, 127 variable stars, and 14 asteroids from\nthree monitored sky regions. Additionally, two datasets were generated: one, a\nreal-bogus training dataset comprising 218,818 training samples, and the other,\na variable star light curve dataset with 421 instances. These datasets will be\nused to train machine learning algorithms, which are planned for future\nintegration into STRIP.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-02T11:25:59Z"}
{"aid":"http://arxiv.org/abs/2504.01631v1","title":"Constructive Decompositions of the Identity for Functional John\n  Ellipsoids","summary":"We consider functional ellipsoids in the sense defined by Ivanov and\nNasz\\'odi and we study the problem of constructing a decomposition of the\nidentity similar to the one given by Fritz John in his fundamental theorem.","main_category":"math.FA","categories":"math.FA,math.DG","published":"2025-04-02T11:37:07Z"}
{"aid":"http://arxiv.org/abs/2504.01634v1","title":"Shape Anisotropy Enabled Field Free Switching of Perpendicular\n  Nanomagnets","summary":"Spin Orbit Torque-Magnetic Random Access Memory (SOT-MRAM) is being developed\nas a successor to the Spin transfer torque MRAM (STT-MRAM) owing to its\nsuperior performance on the metrics of reliability and read-write speed. SOT\nswitching of perpendicularly magnetized ferromagnet in the heavy\nmetal/ferromagnet bilayer of SOT-MRAM unit cell requires an additional external\nmagnetic field to support the spin-orbit torque generated by heavy metal to\ncause deterministic switching. This complexity can be overcome if an internal\nfield can be generated to break the switching symmetry. We experimentally\ndemonstrate that by engineering the shape of ferromagnet, an internal magnetic\nfield capable of breaking the switching symmetry can be generated, which allows\nfor deterministic switching by spin-orbit torques. We fabricated nanomagnets of\nCobalt with triangular shape on top of Platinum and showed external magnetic\nfield free switching between the two stable states of magnetization by\napplication of nano-second voltage pulses. The experimental findings are\nconsistent with the micro-magnetic simulation results of the proposed geometry.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-02T11:40:10Z"}
{"aid":"http://arxiv.org/abs/2504.01648v1","title":"ProtoGuard-guided PROPEL: Class-Aware Prototype Enhancement and\n  Progressive Labeling for Incremental 3D Point Cloud Segmentation","summary":"3D point cloud semantic segmentation technology has been widely used.\nHowever, in real-world scenarios, the environment is evolving. Thus,\noffline-trained segmentation models may lead to catastrophic forgetting of\npreviously seen classes. Class-incremental learning (CIL) is designed to\naddress the problem of catastrophic forgetting. While point clouds are common,\nwe observe high similarity and unclear boundaries between different classes.\nMeanwhile, they are known to be imbalanced in class distribution. These lead to\nissues including misclassification between similar classes and the long-tail\nproblem, which have not been adequately addressed in previous CIL methods. We\nthus propose ProtoGuard and PROPEL (Progressive Refinement Of PsEudo-Labels).\nIn the base-class training phase, ProtoGuard maintains geometric and semantic\nprototypes for each class, which are combined into prototype features using an\nattention mechanism. In the novel-class training phase, PROPEL inherits the\nbase feature extractor and classifier, guiding pseudo-label propagation and\nupdates based on density distribution and semantic similarity. Extensive\nexperiments show that our approach achieves remarkable results on both the\nS3DIS and ScanNet datasets, improving the mIoU of 3D point cloud segmentation\nby a maximum of 20.39% under the 5-step CIL scenario on S3DIS.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T11:58:04Z"}
{"aid":"http://arxiv.org/abs/2504.01650v1","title":"Sparse Gaussian Neural Processes","summary":"Despite significant recent advances in probabilistic meta-learning, it is\ncommon for practitioners to avoid using deep learning models due to a\ncomparative lack of interpretability. Instead, many practitioners simply use\nnon-meta-models such as Gaussian processes with interpretable priors, and\nconduct the tedious procedure of training their model from scratch for each\ntask they encounter. While this is justifiable for tasks with a limited number\nof data points, the cubic computational cost of exact Gaussian process\ninference renders this prohibitive when each task has many observations. To\nremedy this, we introduce a family of models that meta-learn sparse Gaussian\nprocess inference. Not only does this enable rapid prediction on new tasks with\nsparse Gaussian processes, but since our models have clear interpretations as\nmembers of the neural process family, it also allows manual elicitation of\npriors in a neural process for the first time. In meta-learning regimes for\nwhich the number of observed tasks is small or for which expert domain\nknowledge is available, this offers a crucial advantage.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-02T12:00:09Z"}
{"aid":"http://arxiv.org/abs/2504.01657v1","title":"Impact of Small-Scale Gravity Waves on Tracer Transport","summary":"Small-scale gravity waves play a crucial role in atmospheric tracer\ntransport, yet their effects remain unresolved in climate models and must be\nparameterized. This study investigates how gravity waves influence large-scale\ntracer distributions, utilizing a multiple-scale analysis to systematically\nidentify the governing terms of gravity wave-induced tracer fluxes. The\nanalysis reveals both leading-order and next-order impacts: the former being\nthe inertia-gravity wave-induced tracer Stokes drift, which acts perpendicular\nto both the large-scale tracer gradient and the wave number, while the latter\nbecomes significant at lower latitudes where Coriolis effects diminish. A\nnumerical framework is developed to incorporate these fluxes into a gravity\nwave parameterization model, potentially enhancing climate model accuracy\nwithout requiring explicit resolution of small-scale wave dynamics. Model\nvalidation against high-resolution wave-resolving simulations confirms the\neffectiveness of this approach. By improving the representation of gravity\nwave-induced tracer transport, this research advances the accuracy of climate\nsimulations, particularly in their depiction of microphysics and radiative\nprocesses.","main_category":"physics.ao-ph","categories":"physics.ao-ph,physics.flu-dyn","published":"2025-04-02T12:05:03Z"}
{"aid":"http://arxiv.org/abs/2504.01693v1","title":"$SL_k$-Tilings and Paths in $\\mathbb{Z}^k$","summary":"An $SL_k$-tiling is a bi-infinite array of integers having all adjacent\n$k\\times k$ minors equal to one and all adjacent $(k+1)\\times (k+1)$ minors\nequal to zero. Introduced and studied by Bergeron and Reutenauer,\n$SL_k$-tilings generalize the notion of Conway-Coxeter frieze patterns in the\ncase $k=2$. In a recent paper, Short showed a bijection between bi-infinite\npaths of reduced rationals in the Farey graph and $SL_2$-tilings. We extend\nthis result to higher $k$ by constructing a bijection between $SL_k$-tilings\nand certain pairs of bi-infinite strips of vectors in $\\mathbb{Z}^k$ called\npaths. The key ingredient in the proof is the connection to Pl\\\"ucker friezes\nand Grassmannian cluster algebras. As an application, we obtain results about\nperiodicity, duality, and positivity for tilings.","main_category":"math.CO","categories":"math.CO,math.RA,math.RT","published":"2025-04-02T12:49:39Z"}
{"aid":"http://arxiv.org/abs/2504.01696v1","title":"On anticyclotomic Selmer groups of elliptic curves","summary":"Let $p\\geq5$ be a prime number and let $K$ be an imaginary quadratic field\nwhere $p$ is unramified. Under mild technical assumptions, in this paper we\nprove the non-existence of non-trivial finite $\\Lambda$-submodules of\nPontryagin duals of signed Selmer groups of a $p$-supersingular rational\nelliptic curve over the anticyclotomic $\\mathbb Z_p$-extension of $K$, where\n$\\Lambda$ is the corresponding Iwasawa algebra. In particular, we work under\nthe assumption that our plus/minus Selmer groups have $\\Lambda$-corank $1$, so\nthey are not $\\Lambda$-cotorsion. Our main theorem extends to the supersinular\ncase analogous non-existence results by Bertolini in the ordinary setting;\nfurthermore, since we cover the case where $p$ is inert in $K$, we refine\nprevious results of Hatley-Lei-Vigni, which deal with $p$-supersingular\nelliptic curves under the assumption that $p$ splits in $K$.","main_category":"math.NT","categories":"math.NT,math.AG","published":"2025-04-02T12:55:15Z"}
{"aid":"http://arxiv.org/abs/2504.01729v1","title":"On the effect of the Coriolis force on the enstrophy cascade","summary":"We study the direct enstrophy cascade at small spatial scales in\nstatistically stationary forced-dissipated 2D Navier-Stokes equations subject\nto the Coriolis force in the $\\beta$-plane approximation. We provide sufficient\nconditions inspired by [6,63] to prove that at small scales, in the presence of\nthe Coriolis force, the so-called third-order structure function's asymptotics\nfollows the third-order universal law of 2D turbulence without the Coriolis\nforce. Our result indicates that at small scales, the enstrophy flux from\nlarger to smaller scales is not affected by the Coriolis force, confirming\nexperimental and numerical observations. To the best of our knowledge, this is\nthe first mathematically rigorous study of the above equations.","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T13:38:32Z"}
{"aid":"http://arxiv.org/abs/2504.01792v1","title":"UniViTAR: Unified Vision Transformer with Native Resolution","summary":"Conventional Vision Transformer simplifies visual modeling by standardizing\ninput resolutions, often disregarding the variability of natural visual data\nand compromising spatial-contextual fidelity. While preliminary explorations\nhave superficially investigated native resolution modeling, existing approaches\nstill lack systematic analysis from a visual representation perspective. To\nbridge this gap, we introduce UniViTAR, a family of homogeneous vision\nfoundation models tailored for unified visual modality and native resolution\nscenario in the era of multimodal. Our framework first conducts architectural\nupgrades to the vanilla paradigm by integrating multiple advanced components.\nBuilding upon these improvements, a progressive training paradigm is\nintroduced, which strategically combines two core mechanisms: (1) resolution\ncurriculum learning, transitioning from fixed-resolution pretraining to native\nresolution tuning, thereby leveraging ViT's inherent adaptability to\nvariable-length sequences, and (2) visual modality adaptation via inter-batch\nimage-video switching, which balances computational efficiency with enhanced\ntemporal reasoning. In parallel, a hybrid training framework further synergizes\nsigmoid-based contrastive loss with feature distillation from a frozen teacher\nmodel, thereby accelerating early-stage convergence. Finally, trained\nexclusively on public datasets, externsive experiments across multiple model\nscales from 0.3B to 1B demonstrate its effectiveness.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T14:59:39Z"}
{"aid":"http://arxiv.org/abs/2504.01794v1","title":"On the regularity of entropy solutions to stochastic degenerate\n  parabolic equations","summary":"We study the regularity of entropy solutions for quasilinear parabolic\nequations with anisotropic degeneracy and stochastic forcing. Building on\nprevious works, we establish space-time regularity under a non-degeneracy\ncondition that does not require an assumption on the derivative of the symbol\nof the corresponding kinetic equation, a restriction imposed in earlier\nstudies. This allows us to obtain regularity results for certain equations not\naccounted for by prior theory, albeit with reduced regularity exponents. Our\napproach uses a kinetic formulation with two transport equations, one of second\norder and one of first order, leveraging a form of \"parabolic regularity\"\ninherent in these equations that was not utilized in previous studies.","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T15:00:58Z"}
{"aid":"http://arxiv.org/abs/2504.01818v1","title":"Efficient Constant-Space Multi-Vector Retrieval","summary":"Multi-vector retrieval methods, exemplified by the ColBERT architecture, have\nshown substantial promise for retrieval by providing strong trade-offs in terms\nof retrieval latency and effectiveness. However, they come at a high cost in\nterms of storage since a (potentially compressed) vector needs to be stored for\nevery token in the input collection. To overcome this issue, we propose\nencoding documents to a fixed number of vectors, which are no longer\nnecessarily tied to the input tokens. Beyond reducing the storage costs, our\napproach has the advantage that document representations become of a fixed size\non disk, allowing for better OS paging management. Through experiments using\nthe MSMARCO passage corpus and BEIR with the ColBERT-v2 architecture, a\nrepresentative multi-vector ranking model architecture, we find that passages\ncan be effectively encoded into a fixed number of vectors while retaining most\nof the original effectiveness.","main_category":"cs.IR","categories":"cs.IR,cs.CL","published":"2025-04-02T15:22:23Z"}
{"aid":"http://arxiv.org/abs/2504.01832v1","title":"Quantum Meets SAR: A Novel Range-Doppler Algorithm for Next-Gen Earth\n  Observation","summary":"Synthetic aperture radar (SAR) data processing is crucial for high-resolution\nEarth observation and remote sensing applications, one of the most commonly\nused algorithms for this task is the Range Doppler Algorithm (RDA). Using the\nFast Fourier Transform (FFT), the collected signal is transformed to the\nfrequency domain and then goes through the processing steps of this algorithm.\nHowever, when it comes to large datasets, this process can be computationally\nexpensive. This paper explores the implementation of a Quantum Range Doppler\nAlgorithm (QRDA), relying on the Quantum Fourier Transform (QFT) as a speedup\ntool over the classical FFT. Additionally, it proposes a quantum version of the\nRange Cell Migration Correction (RCMC) in the Fourier domain, one of the key\ncorrectional steps of the RDA algorithm, and compares it with its classical\ncounterpart.","main_category":"quant-ph","categories":"quant-ph,eess.SP","published":"2025-04-02T15:40:12Z"}
{"aid":"http://arxiv.org/abs/2504.01833v1","title":"YourBench: Easy Custom Evaluation Sets for Everyone","summary":"Evaluating large language models (LLMs) effectively remains a critical\nbottleneck, as traditional static benchmarks suffer from saturation and\ncontamination, while human evaluations are costly and slow. This hinders timely\nor domain-specific assessment, crucial for real-world applications. We\nintroduce YourBench, a novel, open-source framework that addresses these\nlimitations by enabling dynamic, automated generation of reliable, up-to-date,\nand domain-tailored benchmarks cheaply and without manual annotation, directly\nfrom user-provided documents. We demonstrate its efficacy by replicating 7\ndiverse MMLU subsets using minimal source text, achieving this for under 15 USD\nin total inference costs while perfectly preserving the relative model\nperformance rankings (Spearman Rho = 1) observed on the original benchmark. To\nensure that YourBench generates data grounded in provided input instead of\nrelying on posterior parametric knowledge in models, we also introduce\nTempora-0325, a novel dataset of over 7K diverse documents, published\nexclusively after March 2025. Our comprehensive analysis spans 26 SoTA models\nfrom 7 major families across varying scales (3-671B parameters) to validate the\nquality of generated evaluations through rigorous algorithmic checks (e.g.,\ncitation grounding) and human assessments. We release the YourBench library,\nthe Tempora-0325 dataset, 150k+ question answer pairs based on Tempora and all\nevaluation and inference traces to facilitate reproducible research and empower\nthe community to generate bespoke benchmarks on demand, fostering more relevant\nand trustworthy LLM evaluation.","main_category":"cs.CL","categories":"cs.CL,cs.AI,I.2.1","published":"2025-04-02T15:40:24Z"}
{"aid":"http://arxiv.org/abs/2504.01847v1","title":"Confluence of Conditional Rewriting Modulo","summary":"Sets of equations E play an important computational role in rewriting-based\nsystems R by defining an equivalence relation =E inducing a partition of terms\ninto E-equivalence classes on which rewriting computations, denoted ->R/E and\ncalled *rewriting modulo E*, are issued. This paper investigates *confluence of\n->R/E*, usually called *E-confluence*, for *conditional* rewriting-based\nsystems, where rewriting steps are determined by conditional rules. We rely on\nJouannaud and Kirchner's framework to investigate confluence of an abstract\nrelation R modulo an abstract equivalence relation E on a set A. We show how to\nparticularize the framework to be used with conditional systems. Then, we show\nhow to define appropriate finite sets of *conditional pairs* to prove and\ndisprove E-confluence. In particular, we introduce *Logic-based Conditional\nCritical Pairs* which do not require the use of (often infinitely many)\nE-unifiers to provide a finite representation of the *local peaks* considered\nin the abstract framework. We also introduce *parametric Conditional Variable\nPairs* which are essential to deal with conditional rules in the analysis of\nE-confluence. Our results apply to well-known classes of rewriting-based\nsystems. In particular, to *Equational (Conditional) Term Rewriting Systems*.","main_category":"cs.LO","categories":"cs.LO,cs.PL,cs.SC","published":"2025-04-02T15:55:06Z"}
{"aid":"http://arxiv.org/abs/2504.01848v1","title":"PaperBench: Evaluating AI's Ability to Replicate AI Research","summary":"We introduce PaperBench, a benchmark evaluating the ability of AI agents to\nreplicate state-of-the-art AI research. Agents must replicate 20 ICML 2024\nSpotlight and Oral papers from scratch, including understanding paper\ncontributions, developing a codebase, and successfully executing experiments.\nFor objective evaluation, we develop rubrics that hierarchically decompose each\nreplication task into smaller sub-tasks with clear grading criteria. In total,\nPaperBench contains 8,316 individually gradable tasks. Rubrics are co-developed\nwith the author(s) of each ICML paper for accuracy and realism. To enable\nscalable evaluation, we also develop an LLM-based judge to automatically grade\nreplication attempts against rubrics, and assess our judge's performance by\ncreating a separate benchmark for judges. We evaluate several frontier models\non PaperBench, finding that the best-performing tested agent, Claude 3.5 Sonnet\n(New) with open-source scaffolding, achieves an average replication score of\n21.0\\%. Finally, we recruit top ML PhDs to attempt a subset of PaperBench,\nfinding that models do not yet outperform the human baseline. We\n\\href{https://github.com/openai/preparedness}{open-source our code} to\nfacilitate future research in understanding the AI engineering capabilities of\nAI agents.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-02T15:55:24Z"}
{"aid":"http://arxiv.org/abs/2504.01849v1","title":"An Approach to Technical AGI Safety and Security","summary":"Artificial General Intelligence (AGI) promises transformative benefits but\nalso presents significant risks. We develop an approach to address the risk of\nharms consequential enough to significantly harm humanity. We identify four\nareas of risk: misuse, misalignment, mistakes, and structural risks. Of these,\nwe focus on technical approaches to misuse and misalignment. For misuse, our\nstrategy aims to prevent threat actors from accessing dangerous capabilities,\nby proactively identifying dangerous capabilities, and implementing robust\nsecurity, access restrictions, monitoring, and model safety mitigations. To\naddress misalignment, we outline two lines of defense. First, model-level\nmitigations such as amplified oversight and robust training can help to build\nan aligned model. Second, system-level security measures such as monitoring and\naccess control can mitigate harm even if the model is misaligned. Techniques\nfrom interpretability, uncertainty estimation, and safer design patterns can\nenhance the effectiveness of these mitigations. Finally, we briefly outline how\nthese ingredients could be combined to produce safety cases for AGI systems.","main_category":"cs.AI","categories":"cs.AI,cs.CY,cs.LG","published":"2025-04-02T15:59:31Z"}
{"aid":"http://arxiv.org/abs/2504.01859v1","title":"A method to derive material-specific spin-bath model descriptions of\n  materials displaying prevalent spin physics (for simulation on NISQ devices)","summary":"Magnetism and spin physics are true quantum mechanical effects and their\ndescription usually requires multi reference methods and is often hidden in the\nstandard description of molecules in quantum chemistry. In this work we present\na twofold approach to the description of spin physics in molecules and solids.\nFirst, we present a method that identifies the single-particle basis in which a\ngiven subset of the orbitals is equivalent to spin degrees of freedom for\nmodels and materials which feature significant spin physics at low energies. We\nintroduce a metric for the spin-like character of a basis orbital, of which the\noptimization yields the basis containing the optimum spin-like basis orbitals.\nSecond, we demonstrate an extended Schrieffer-Wolff transformation method to\nderive the effective Hamiltonian acting on the subspace of the Hilbert space in\nwhich the charge degree of freedom of electron densities in the spin-like\norbitals is integrated out. The method then yields an effective spin-bath\nHamiltonian description for the system. This extended Schrieffer-Wolff\ntransformation is applicable to a wide range of Hamiltonians and has been\nutilized in this work for model Hamiltonians as well as the active space\nHamiltonian of molecular chromium bromide.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-02T16:11:59Z"}
{"aid":"http://arxiv.org/abs/2504.01860v1","title":"Hyperbolic decomposition of Dirichlet distance for ARMA models","summary":"We investigate the hyperbolic decomposition of the Dirichlet norm and\ndistance between autoregressive moving average (ARMA) models. Beginning with\nthe K\\\"ahler information geometry of linear systems in the Hardy space and\nweighted Hardy spaces, we demonstrate that the Dirichlet norm and distance of\nARMA models, corresponding to the mutual information between the past and\nfuture, are decomposed into functions of the hyperbolic distance between the\npoles and zeros of the ARMA models.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-02T16:12:24Z"}
{"aid":"http://arxiv.org/abs/2504.01882v1","title":"CO-DEFEND: Continuous Decentralized Federated Learning for Secure\n  DoH-Based Threat Detection","summary":"The use of DNS over HTTPS (DoH) tunneling by an attacker to hide malicious\nactivity within encrypted DNS traffic poses a serious threat to network\nsecurity, as it allows malicious actors to bypass traditional monitoring and\nintrusion detection systems while evading detection by conventional traffic\nanalysis techniques. Machine Learning (ML) techniques can be used to detect DoH\ntunnels; however, their effectiveness relies on large datasets containing both\nbenign and malicious traffic. Sharing such datasets across entities is\nchallenging due to privacy concerns. In this work, we propose CO-DEFEND\n(Continuous Decentralized Federated Learning for Secure DoH-Based Threat\nDetection), a Decentralized Federated Learning (DFL) framework that enables\nmultiple entities to collaboratively train a classification machine learning\nmodel while preserving data privacy and enhancing resilience against single\npoints of failure. The proposed DFL framework, which is scalable and\nprivacy-preserving, is based on a federation process that allows multiple\nentities to train online their local models using incoming DoH flows in real\ntime as they are processed by the entity. In addition, we adapt four classical\nmachine learning algorithms, Support Vector Machines (SVM), Logistic Regression\n(LR), Decision Trees (DT), and Random Forest (RF), for federated scenarios,\ncomparing their results with more computationally complex alternatives such as\nneural networks. We compare our proposed method by using the dataset\nCIRA-CIC-DoHBrw-2020 with existing machine learning approaches to demonstrate\nits effectiveness in detecting malicious DoH tunnels and the benefits it\nbrings.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T16:40:01Z"}
{"aid":"http://arxiv.org/abs/2504.01896v1","title":"Composition Design of Shape Memory Ceramics based on Gaussian Processes","summary":"We present a Gaussian process machine learning model to predict the\ntransformation temperature and lattice parameters of ZrO$_2$-based ceramics.\nOur overall goal is to search for a shape memory ceramic with a reversible\ntransformation and low hysteresis. The identification of a new low hysteresis\ncomposition is based on design criteria that have been successful in metal\nalloys: (1) $\\lambda_2 = 1$, where $\\lambda_2$ is the middle eigenvalue of the\ntransformation stretch tensor, (2) minimizing the max$|q(f)|$, which measures\nthe deviation from satisfying the cofactor conditions, (3) high transformation\ntemperature, (4) low transformational volume change, and (5) solid solubility.\nWe generate many synthetic compositions, and identify a promising composition,\n31.75Zr-37.75Hf-14.5Y-14.5Ta-1.5Er, which closely satisfies all the design\ncriteria based on predictions from machine learning. However, differential\nthermal analysis reveals a relatively high thermal hysteresis of 137{\\deg}C for\nthis composition, indicating that the proposed design criteria are not\nuniversally applicable to all ZrO$_2$-based ceramics. We also explore reducing\ntetragonality of the austenite phase by addition of Er$_2$O$_3$. The idea is to\ntune the lattice parameters of austenite phase towards a cubic structure will\nincrease the number of martensite variants, thus, allowing more flexibility for\nthem to accommodate high strain during transformation. We find the effect of\nEr$_2$O$_3$ on tetragonality is weak due to limited solubility. We conclude\nthat a more effective dopant is needed to achieve significant tetragonality\nreduction. Overall, Gaussian process machine learning models are shown to be\nhighly useful for prediction of compositions and lattice parameters, but the\ndiscovery of low hysteresis ceramic materials apparently involves other factors\nnot relevant to phase transformations in metals.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.data-an","published":"2025-04-02T16:56:59Z"}
{"aid":"http://arxiv.org/abs/2504.01906v1","title":"Gaze-Hand Steering for Travel and Multitasking in Virtual Environments","summary":"As head-mounted displays (HMDs) with eye-tracking become increasingly\naccessible, the need for effective gaze-based interfaces in virtual reality\n(VR) grows. Traditional gaze- or hand-based navigation often limits user\nprecision or impairs free viewing, making multitasking difficult. We present a\ngaze-hand steering technique that combines eye-tracking with hand-pointing:\nusers steer only when gaze aligns with a hand-defined target, reducing\nunintended actions and enabling free look. Speed is controlled via either a\njoystick or a waist-level speed circle. We evaluated our method in a user study\n(N=20) across multitasking and single-task scenarios, comparing it to a similar\ntechnique. Results show that gaze-hand steering maintains performance and\nenhances user comfort and spatial awareness during multitasking. Our findings\nsupport the use of gaze-hand steering in gaze-dominant VR applications\nrequiring precision and simultaneous interaction. Our method significantly\nimproves VR navigation in gaze-dominant, multitasking-intensive applications,\nsupporting immersion and efficient control.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-02T17:07:01Z"}
{"aid":"http://arxiv.org/abs/2504.01916v1","title":"FineLIP: Extending CLIP's Reach via Fine-Grained Alignment with Longer\n  Text Inputs","summary":"As a pioneering vision-language model, CLIP (Contrastive Language-Image\nPre-training) has achieved significant success across various domains and a\nwide range of downstream vision-language tasks. However, the text encoders in\npopular CLIP models are limited to processing only 77 text tokens, which\nconstrains their ability to effectively handle longer, detail-rich captions.\nAdditionally, CLIP models often struggle to effectively capture detailed visual\nand textual information, which hampers their performance on tasks that require\nfine-grained analysis. To address these limitations, we present a novel\napproach, \\textbf{FineLIP}, that extends the capabilities of CLIP. FineLIP\nenhances cross-modal text-image mapping by incorporating \\textbf{Fine}-grained\nalignment with \\textbf{L}onger text input within the CL\\textbf{IP}-style\nframework. FineLIP first extends the positional embeddings to handle longer\ntext, followed by the dynamic aggregation of local image and text tokens. The\naggregated results are then used to enforce fine-grained token-to-token\ncross-modal alignment. We validate our model on datasets with long, detailed\ncaptions across two tasks: zero-shot cross-modal retrieval and text-to-image\ngeneration. Quantitative and qualitative experimental results demonstrate the\neffectiveness of FineLIP, outperforming existing state-of-the-art approaches.\nFurthermore, comprehensive ablation studies validate the benefits of key design\nelements within FineLIP.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL","published":"2025-04-02T17:19:59Z"}
{"aid":"http://arxiv.org/abs/2504.01922v1","title":"Is Less Really More? Fake News Detection with Limited Information","summary":"The threat that online fake news and misinformation pose to democracy,\njustice, public confidence, and especially to vulnerable populations, has led\nto a sharp increase in the need for fake news detection and intervention.\nWhether multi-modal or pure text-based, most fake news detection methods depend\non textual analysis of entire articles. However, these fake news detection\nmethods come with certain limitations. For instance, fake news detection\nmethods that rely on full text can be computationally inefficient, demand large\namounts of training data to achieve competitive accuracy, and may lack\nrobustness across different datasets. This is because fake news datasets have\nstrong variations in terms of the level and types of information they provide;\nwhere some can include large paragraphs of text with images and metadata,\nothers can be a few short sentences. Perhaps if one could only use minimal\ninformation to detect fake news, fake news detection methods could become more\nrobust and resilient to the lack of information. We aim to overcome these\nlimitations by detecting fake news using systematically selected, limited\ninformation that is both effective and capable of delivering robust, promising\nperformance. We propose a framework called SLIM Systematically-selected Limited\nInformation) for fake news detection. In SLIM, we quantify the amount of\ninformation by introducing information-theoretic measures. SLIM leverages\nlimited information to achieve performance in fake news detection comparable to\nthat of state-of-the-art obtained using the full text. Furthermore, by\ncombining various types of limited information, SLIM can perform even better\nwhile significantly reducing the quantity of information required for training\ncompared to state-of-the-art language model-based fake news detection\ntechniques.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-02T17:32:37Z"}
{"aid":"http://arxiv.org/abs/2504.01938v1","title":"A Unified Approach to Analysis and Design of Denoising Markov Models","summary":"Probabilistic generative models based on measure transport, such as diffusion\nand flow-based models, are often formulated in the language of Markovian\nstochastic dynamics, where the choice of the underlying process impacts both\nalgorithmic design choices and theoretical analysis. In this paper, we aim to\nestablish a rigorous mathematical foundation for denoising Markov models, a\nbroad class of generative models that postulate a forward process transitioning\nfrom the target distribution to a simple, easy-to-sample distribution,\nalongside a backward process particularly constructed to enable efficient\nsampling in the reverse direction. Leveraging deep connections with\nnonequilibrium statistical mechanics and generalized Doob's $h$-transform, we\npropose a minimal set of assumptions that ensure: (1) explicit construction of\nthe backward generator, (2) a unified variational objective directly minimizing\nthe measure transport discrepancy, and (3) adaptations of the classical\nscore-matching approach across diverse dynamics. Our framework unifies existing\nformulations of continuous and discrete diffusion models, identifies the most\ngeneral form of denoising Markov models under certain regularity assumptions on\nforward generators, and provides a systematic recipe for designing denoising\nMarkov models driven by arbitrary L\\'evy-type processes. We illustrate the\nversatility and practical effectiveness of our approach through novel denoising\nMarkov models employing geometric Brownian motion and jump processes as forward\ndynamics, highlighting the framework's potential flexibility and capability in\nmodeling complex distributions.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.NA,stat.ML","published":"2025-04-02T17:46:43Z"}
{"aid":"http://arxiv.org/abs/2504.01942v1","title":"De Sitter entropy: on-shell versus off-shell","summary":"Attributing thermodynamic properties to the Bunch-Davies state in static\npatch of de Sitter space and setting the corresponding equations of state, we\ndemonstrate that, for pure gravity, the bulk entropy computed on-shell as a\nvolume integral in de Sitter space coincides with the Wald entropy (area law)\nin any spacetime dimension and for any theory of f(R) gravity. We extend this\nresult to the renormalized entanglement entropy of a non-minimally coupled\nscalar field. From the on-shell perspective, entropy emerges as a bulk\ncontribution, whereas from the off-shell viewpoint, it manifests as a boundary\n(horizon) contribution. As a result, in de Sitter space, generalized entropy\ncan be understood in two distinct ways: either as a bulk or as a boundary\ncontribution.","main_category":"hep-th","categories":"hep-th","published":"2025-04-02T17:48:35Z"}
{"aid":"http://arxiv.org/abs/2504.01953v1","title":"Deep Representation Learning for Unsupervised Clustering of Myocardial\n  Fiber Trajectories in Cardiac Diffusion Tensor Imaging","summary":"Understanding the complex myocardial architecture is critical for diagnosing\nand treating heart disease. However, existing methods often struggle to\naccurately capture this intricate structure from Diffusion Tensor Imaging (DTI)\ndata, particularly due to the lack of ground truth labels and the ambiguous,\nintertwined nature of fiber trajectories. We present a novel deep learning\nframework for unsupervised clustering of myocardial fibers, providing a\ndata-driven approach to identifying distinct fiber bundles. We uniquely combine\na Bidirectional Long Short-Term Memory network to capture local sequential\ninformation along fibers, with a Transformer autoencoder to learn global shape\nfeatures, with pointwise incorporation of essential anatomical context.\nClustering these representations using a density-based algorithm identifies 33\nto 62 robust clusters, successfully capturing the subtle distinctions in fiber\ntrajectories with varying levels of granularity. Our framework offers a new,\nflexible, and quantitative way to analyze myocardial structure, achieving a\nlevel of delineation that, to our knowledge, has not been previously achieved,\nwith potential applications in improving surgical planning, characterizing\ndisease-related remodeling, and ultimately, advancing personalized cardiac\ncare.","main_category":"eess.IV","categories":"eess.IV,cs.CV,cs.LG","published":"2025-04-02T17:56:57Z"}
{"aid":"http://arxiv.org/abs/2504.02210v1","title":"Mid-Infrared Imaging Spectroscopy of N2O Solid Simulating the haze of\n  trans-Neptunian objects","summary":"\\ Nitrous oxide (N$_2$O) ice is likely to exist in trans-Neptunian objects\nsuch as Pluto and Triton, potentially formed through ultraviolet (UV) radiation\nfrom the Sun or cosmic ray irradiation of N$_2$ and CO ices. However, the\nmid-infrared spectral characteristics of N$_2$O ice in higher temperature\nregions (90-110 K), changes in mid-infrared spectra during UV irradiation, and\nthe chemical network of nitrogen oxide (N$_x$O$_y$) ices remain insufficiently\nunderstood. This study aims to elucidate these aspects through in-situ\nmid-infrared spectral measurements of cryogenic particles using two-dimensional\nimaging Fourier transform infrared spectroscopy.\n  Spectroscopic imaging confirmed strong absorption at 7.75 $\\mu$m (N$_2$O\n$\\nu_1$ vibrational mode), with weaker vibrational modes observed at 8.60\n$\\mu$m (N$_2$O 2$\\nu_2$), 7.27 $\\mu$m (N$_2$O torsion), and 5.29 $\\mu$m (N$_2$O\n$\\nu_1$+$\\nu_2$). Annealing experiments simulating high-temperature conditions\ndemonstrated that all vibrational modes irreversibly intensified with\nincreasing temperature, indicating progressive crystallization. New spectral\nfeatures appeared at approximately 12 $\\mu$m and 14 $\\mu$m at the condensed\nsample.\n  N$_2$O ice was exposed to ultraviolet radiation (190-340 nm) using a D$_2$\nlamp for 8.5 hours to investigate spectral changes during UV irradiation. After\n60-90 minutes of irradiation, all N$_2$O vibrational modes disappeared, while\nabsorption intensities of various nitrogen oxides, including NO, NO$_2$,\nN$_2$O$_3$, and O$_3$ increased. Beyond 180 minutes, vibrational modes of\nmultiple nitrogen oxide ices exhibited intensity variations across different\nwavelengths, corresponding to other species such as cis-(NO)$_2$, N$_2$O$_4$,\nand N$_2$O$_5$.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM,physics.chem-ph","published":"2025-04-03T02:03:25Z"}
{"aid":"http://arxiv.org/abs/2504.02219v1","title":"Experimental evidence of non-equilibrium phase separation in\n  supercritical fluids","summary":"Supercritical fluids (SCFs) have long been considered homogeneous and\nstructureless, yet recent studies suggest the existence of transient,\nliquid-like clusters under dynamic processes. In this study, we provide\nexperimental evidence of semi-stable non-equilibrium phase separation in SCFs\nthrough opacity measurements and small-angle neutron scattering (SANS). By\ninvestigating the thermophysical properties of helium, argon, and krypton\nduring adiabatic expansion, we show that cooling dynamics vary significantly\namong species, influencing cluster formation. Neutron scattering measurements\nreveal distinct variations in signal intensity, supporting that the clusters\nslowly dissolve into the background with a surprisingly long time scale of tens\nof minutes. Given that SCFs in industrial applications frequently experience\ndynamic, non-equilibrium conditions rather than in strict thermodynamic\nequilibrium, our results provide crucial insights with potential implications\nfor advanced material processing, energy systems, and chemical engineering.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-03T02:20:59Z"}
{"aid":"http://arxiv.org/abs/2504.02233v1","title":"Testing independence and conditional independence in high dimensions via\n  coordinatewise Gaussianization","summary":"We propose new statistical tests, in high-dimensional settings, for testing\nthe independence of two random vectors and their conditional independence given\na third random vector. The key idea is simple, i.e., we first transform each\ncomponent variable to standard normal via its marginal empirical distribution,\nand we then test for independence and conditional independence of the\ntransformed random vectors using appropriate $L_\\infty$-type test statistics.\nWhile we are testing some necessary conditions of the independence or the\nconditional independence, the new tests outperform the 13 frequently used\ntesting methods in a large scale simulation comparison. The advantage of the\nnew tests can be summarized as follows: (i) they do not require any moment\nconditions, (ii) they allow arbitrary dependence structures of the components\namong the random vectors, and (iii) they allow the dimensions of random vectors\ndiverge at the exponential rates of the sample size. The critical values of the\nproposed tests are determined by a computationally efficient multiplier\nbootstrap procedure. Theoretical analysis shows that the sizes of the proposed\ntests can be well controlled by the nominal significance level, and the\nproposed tests are also consistent under certain local alternatives. The finite\nsample performance of the new tests is illustrated via extensive simulation\nstudies and a real data application.","main_category":"stat.ME","categories":"stat.ME,math.ST,stat.TH","published":"2025-04-03T02:59:52Z"}
{"aid":"http://arxiv.org/abs/2504.02235v1","title":"On the Clustering of Conditional Mutual Information via Dissipative\n  Dynamics","summary":"Conditional mutual information (CMI) has recently attracted significant\nattention as a key quantity for characterizing quantum correlations in\nmany-body systems. While it is conjectured that CMI decays rapidly in\nfinite-temperature Gibbs states, a complete and general proof remains elusive.\nPrevious work addressed this problem in the high-temperature regime using\ncluster expansion techniques [T. Kuwahara, K. Kato, F.G.S.L. Brand\\~ao, Phys.\nRev. Lett. 124, 220601 (2020)]; however, flaws in the proof have been pointed\nout, and the method does not provide a uniformly convergent expansion at\narbitrarily high temperatures. In this work, we demonstrate that the cluster\nexpansion approach indeed fails to converge absolutely, even at any\nhigh-temperatures. To overcome this limitation, we propose a new approach to\nproving the spatial decay of CMI. Our method leverages the connection between\nCMI and quantum recovery maps, specifically utilizing the Fawzi-Renner theorem.\nWe show that such recovery maps can be realized through dissipative dynamics,\nand by analyzing the locality properties of these dynamics, we establish the\nexponential decay of CMI in high-temperature regimes. As a technical\ncontribution, we also present a new result on the perturbative stability of\nquasi-local Liouvillian dynamics. Our results indicate that, contrary to common\nintuition, high-temperature Gibbs states can exhibit nontrivial mathematical\nstructure, particularly when multipartite correlations such as CMI are\nconsidered.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech,math-ph,math.MP","published":"2025-04-03T03:06:55Z"}
{"aid":"http://arxiv.org/abs/2504.02257v1","title":"In-situ three-dimensional strain engineering of solid-state quantum\n  emitters in photonic structures towards scalable quantum networks","summary":"Solid-state quantum emitters are pivotal for modern photonic quantum\ntechnology, yet their inherent spectral inhomogeneity imposes a critical\nchallenge in pursuing scalable quantum network. Here, we develop a\ncryogenic-compatible strain-engineering platform based on a\npolydimethylsiloxane (PDMS) stamp that is not obviously working properly at\ncryogenic temperature. In-situ three-dimensional (3D) strain control is\nachieved for quantum dots (QDs) embedded in photonic nanostructures. The\ncompliant PDMS enables independent tuning of emission energy and elimination of\nfine structure splitting (FSS) of single QDs, as demonstrated by a 7 meV\nspectral shift with a near-vanishing FSS in circular Bragg resonators and an\nunprecedented 15 meV tuning range in the micropillar. The PDMS-based 3D\nstrain-engineering platform, compatible with diverse photonic structures at\ncryogenic temperature, provides a powerful and versatile tool for exploring\nfundamental strain-related physics and advancing integrated photonic quantum\ntechnology.","main_category":"physics.optics","categories":"physics.optics,quant-ph","published":"2025-04-03T04:00:25Z"}
{"aid":"http://arxiv.org/abs/2504.02274v1","title":"Extended Hybridization Expansion Solver for Impurity Models with\n  Retarded Interactions","summary":"We extend the continuous-time hybridization expansion solver to a general\nform, where the hybridization function and retarded interaction are treated on\nequal footing. Correlation functions can now be directly obtained via\nfunctional derivatives with respect to the bosonic propagators, similar to the\nmeasurement of Green's functions. We devise a combinatorial scheme of measuring\nthe correlation function, whose efficiency partially emulates that of the\nGreen's function measurement. The algorithm and numerical methods are validated\nthrough application to an impurity model involving both electron-phonon\ncoupling and exchange interactions, a case where the previous hybridization\nexpansion algorithm is not applicable. Our improvement of the hybridization\nexpansion solver promotes its applicability in studies of electron-phonon\ncoupling, the extended dynamical mean field theory, and the dual boson method.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci","published":"2025-04-03T04:49:35Z"}
{"aid":"http://arxiv.org/abs/2504.02287v1","title":"MultiSensor-Home: A Wide-area Multi-modal Multi-view Dataset for Action\n  Recognition and Transformer-based Sensor Fusion","summary":"Multi-modal multi-view action recognition is a rapidly growing field in\ncomputer vision, offering significant potential for applications in\nsurveillance. However, current datasets often fail to address real-world\nchallenges such as wide-area environmental conditions, asynchronous data\nstreams, and the lack of frame-level annotations. Furthermore, existing methods\nface difficulties in effectively modeling inter-view relationships and\nenhancing spatial feature learning. In this study, we propose the Multi-modal\nMulti-view Transformer-based Sensor Fusion (MultiTSF) method and introduce the\nMultiSensor-Home dataset, a novel benchmark designed for comprehensive action\nrecognition in home environments. The MultiSensor-Home dataset features\nuntrimmed videos captured by distributed sensors, providing high-resolution RGB\nand audio data along with detailed multi-view frame-level action labels. The\nproposed MultiTSF method leverages a Transformer-based fusion mechanism to\ndynamically model inter-view relationships. Furthermore, the method also\nintegrates a external human detection module to enhance spatial feature\nlearning. Experiments on MultiSensor-Home and MM-Office datasets demonstrate\nthe superiority of MultiTSF over the state-of-the-art methods. The quantitative\nand qualitative results highlight the effectiveness of the proposed method in\nadvancing real-world multi-modal multi-view action recognition.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T05:23:08Z"}
{"aid":"http://arxiv.org/abs/2504.02319v1","title":"Fields with small class group in the family $\\mathbb{Q}(\\sqrt{9m^2+2m})$","summary":"Very recently, Issa and Darrag [Arch. Math. (Basel) 123 (2024), no. 4,\n379-383] determined partial Dedekind zeta values for certain ideal classes in\nthe real quadratic fields of the form $\\mathbb{Q}(\\sqrt{9m^2+2m})$, where\n$9m^2+2m$ is square-free and $m\\equiv 2\\pmod 3$ is an odd positive integer. We\nuse these partial Dedekind zeta values to investigate the small class numbers\nof such fields. More precisely, we prove that the class numbers of the fields\nin the above mentioned family are at least $4$. Further, we provide a\nsufficient condition permitting to specify the structure of the class groups of\norder $4$ in this family of fields.","main_category":"math.NT","categories":"math.NT","published":"2025-04-03T06:46:18Z"}
{"aid":"http://arxiv.org/abs/2504.02367v1","title":"CrystalFormer-RL: Reinforcement Fine-Tuning for Materials Design","summary":"Reinforcement fine-tuning has instrumental enhanced the instruction-following\nand reasoning abilities of large language models. In this work, we explore the\napplications of reinforcement fine-tuning to the autoregressive\ntransformer-based materials generative model CrystalFormer (arXiv:2403.15734)\nusing discriminative machine learning models such as interatomic potentials and\nproperty prediction models. By optimizing reward signals-such as energy above\nthe convex hull and material property figures of merit-reinforcement\nfine-tuning infuses knowledge from discriminative models into generative\nmodels. The resulting model, CrystalFormer-RL, shows enhanced stability in\ngenerated crystals and successfully discovers crystals with desirable yet\nconflicting material properties, such as substantial dielectric constant and\nband gap simultaneously. Notably, we observe that reinforcement fine-tuning\nenables not only the property-guided novel material design ability of\ngenerative pre-trained model but also unlocks property-driven material\nretrieval from the unsupervised pre-training dataset. Leveraging rewards from\ndiscriminative models to fine-tune materials generative models opens an\nexciting gateway to the synergies of the machine learning ecosystem for\nmaterials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cs.LG,physics.comp-ph","published":"2025-04-03T07:59:30Z"}
{"aid":"http://arxiv.org/abs/2504.02385v1","title":"Quantum singular value transformation without block encodings:\n  Near-optimal complexity with minimal ancilla","summary":"We develop new algorithms for Quantum Singular Value Transformation (QSVT), a\nunifying framework underlying a wide range of quantum algorithms. Existing\nimplementations of QSVT rely on block encoding, incurring $O(\\log L)$ ancilla\noverhead and circuit depth $\\widetilde{O}(d\\lambda L)$ for polynomial\ntransformations of a Hamiltonian $H=\\sum_{k=1}^L \\lambda_k H_k$, where $d$ is\npolynomial degree, and $\\lambda=\\sum_k |\\lambda_k|$. We introduce a new\napproach that eliminates block encoding, needs only a single ancilla qubit, and\nmaintains near-optimal complexity, using only basic Hamiltonian simulation\nmethods such as Trotterization. Our method achieves a circuit depth of\n$\\widetilde{O}(L(d\\lambda_{\\mathrm{comm}})^{1+o(1)})$, without any multi-qubit\ncontrolled gates. Here, $\\lambda_{\\mathrm{comm}}$ depends on the nested\ncommutators of the $H_k$'s and can be much smaller than $\\lambda$. Central to\nour technique is a novel use of Richardson extrapolation, enabling systematic\nerror cancellation in interleaved sequences of arbitrary unitaries and\nHamiltonian evolution operators, establishing a broadly applicable framework\nbeyond QSVT. Additionally, we propose two randomized QSVT algorithms for cases\nwith only sampling access to Hamiltonian terms. The first uses qDRIFT, while\nthe second replaces block encodings in QSVT with randomly sampled unitaries.\nBoth achieve quadratic complexity in $d$, which we establish as a lower bound\nfor any randomized method implementing polynomial transformations in this\nmodel. Finally, as applications, we develop end-to-end quantum algorithms for\nquantum linear systems and ground state property estimation, achieving\nnear-optimal complexity without oracular access. Our results provide a new\nframework for quantum algorithms, reducing hardware overhead while maintaining\nnear-optimal performance, with implications for both near-term and\nfault-tolerant quantum computing.","main_category":"quant-ph","categories":"quant-ph,cs.DS","published":"2025-04-03T08:24:15Z"}
{"aid":"http://arxiv.org/abs/2504.02417v1","title":"Leveraging Static Relationships for Intra-Type and Inter-Type Message\n  Passing in Video Question Answering","summary":"Video Question Answering (VideoQA) is an important research direction in the\nfield of artificial intelligence, enabling machines to understand video content\nand perform reasoning and answering based on natural language questions.\nAlthough methods based on static relationship reasoning have made certain\nprogress, there are still deficiencies in the accuracy of static relationship\nrecognition and representation, and they have not fully utilized the static\nrelationship information in videos for in-depth reasoning and analysis.\nTherefore, this paper proposes a reasoning method for intra-type and inter-type\nmessage passing based on static relationships. This method constructs a dual\ngraph for intra-type message passing reasoning and builds a heterogeneous graph\nbased on static relationships for inter-type message passing reasoning. The\nintra-type message passing reasoning model captures the neighborhood\ninformation of targets and relationships related to the question in the dual\ngraph, updating the dual graph to obtain intra-type clues for answering the\nquestion. The inter-type message passing reasoning model captures the\nneighborhood information of targets and relationships from different categories\nrelated to the question in the heterogeneous graph, updating the heterogeneous\ngraph to obtain inter-type clues for answering the question. Finally, the\nanswers are inferred by combining the intra-type and inter-type clues based on\nstatic relationships. Experimental results on the ANetQA and Next-QA datasets\ndemonstrate the effectiveness of this method.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-03T09:14:41Z"}
{"aid":"http://arxiv.org/abs/2504.02440v1","title":"HGFormer: Topology-Aware Vision Transformer with HyperGraph Learning","summary":"The computer vision community has witnessed an extensive exploration of\nvision transformers in the past two years. Drawing inspiration from traditional\nschemes, numerous works focus on introducing vision-specific inductive biases.\nHowever, the implicit modeling of permutation invariance and fully-connected\ninteraction with individual tokens disrupts the regional context and spatial\ntopology, further hindering higher-order modeling. This deviates from the\nprinciple of perceptual organization that emphasizes the local groups and\noverall topology of visual elements. Thus, we introduce the concept of\nhypergraph for perceptual exploration. Specifically, we propose a\ntopology-aware vision transformer called HyperGraph Transformer (HGFormer).\nFirstly, we present a Center Sampling K-Nearest Neighbors (CS-KNN) algorithm\nfor semantic guidance during hypergraph construction. Secondly, we present a\ntopology-aware HyperGraph Attention (HGA) mechanism that integrates hypergraph\ntopology as perceptual indications to guide the aggregation of global and\nunbiased information during hypergraph messaging. Using HGFormer as visual\nbackbone, we develop an effective and unitive representation, achieving\ndistinct and detailed scene depictions. Empirical experiments show that the\nproposed HGFormer achieves competitive performance compared to the recent SoTA\ncounterparts on various visual benchmarks. Extensive ablation and visualization\nstudies provide comprehensive explanations of our ideas and contributions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T09:58:01Z"}
{"aid":"http://arxiv.org/abs/2504.02447v1","title":"Measuring the Low-Energy Weak Mixing Angle with Supernova Neutrinos","summary":"The weak mixing angle $\\theta_W$ is a fundamental parameter in the\nelectroweak theory with a value running according to the energy scale, and its\nprecision measurement in the low-energy regime is still ongoing. We propose a\nmethod to measure the low-energy $\\sin{^2\\theta_W}$ by taking advantage of\nArgo, a future ton-scale liquid argon dark matter detector, and the neutrino\nflux from a nearby core-collapse supernova (CCSN). We evaluate the expected\nprecision of this measurement through the coherent elastic neutrino-nucleus\nscattering (CE$\\nu$NS) channel. We show that Argo is potentially capable of\nachieving a few percent determination of $\\sin{^2\\theta_W}$, at the momentum\ntransfer of $q \\sim 20$ MeV, in the observation of a CCSN within $\\sim 3$ kpc\nfrom the Earth. Such a measurement is valuable for both the precision test of\nthe electroweak theory and searching for new physics beyond the standard model\nin the neutrino sector.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-03T10:06:06Z"}
{"aid":"http://arxiv.org/abs/2504.02455v1","title":"QPanda3: A High-Performance Software-Hardware Collaborative Framework\n  for Large-Scale Quantum-Classical Computing Integration","summary":"QPanda3 is a high-performance quantum programming framework that enhances\nquantum computing efficiency through optimized circuit compilation, an advanced\ninstruction stream format (OriginBIS), and hardware-aware execution strategies.\nThese engineering optimizations significantly improve both processing speed and\nsystem performance, addressing key challenges in the NISQ era. A core\ninnovation, OriginBIS, accelerates encoding speeds by up to 86.9x compared to\nOpenQASM 2.0, while decoding is 35.6x faster, leading to more efficient data\nhandling, reduced memory overhead, and improved communication efficiency. This\ndirectly enhances the execution of quantum circuits, making large-scale quantum\nsimulations more feasible. Comprehensive benchmarking demonstrates QPanda3's\nsuperior performance: quantum circuit construction is 20.7x faster, execution\nspeeds improve by 3.4x, and transpilation efficiency increases by 14.97x over\nQiskit. Notably, in compiling a 118-qubit W-state circuit on a 2D-grid\ntopology, QPanda3 achieves an unprecedented 869.9x speedup, underscoring its\nability to handle complex quantum workloads at scale. By combining high-speed\nquantum processing with a modular and extensible software architecture, QPanda3\nprovides a practical bridge between today's NISQ devices and future\nfault-tolerant quantum computing. It facilitates real-world applications in\nfinancial modeling, materials science, and combinatorial optimization, while\nits robust and scalable design supports industrial adoption and cloud-based\ndeployment.","main_category":"cs.PL","categories":"cs.PL","published":"2025-04-03T10:20:16Z"}
{"aid":"http://arxiv.org/abs/2504.02469v1","title":"An MHD Simulation of the Possible Modulations of Stellar CMEs Radio\n  Observations by an Exoplanetary Magnetosphere","summary":"Type II radio bursts are the indicator of adverse space weather in a stellar\nsystem. These radio bursts are the consequence of shock wave acceleration due\nto the coronal mass ejection (CME). Here, we perform a series of\nmagnetohydrodynamic (MHD) simulations of a CME-driven star-planet system in\norder to investigate the modulation in radio burst mechanism by a close-in\nexoplanetary system. We use a model for the stellar wind with a close-in\nexoplanet, and a CME model based on the eruption of a flux rope. We are able to\ngenerate synthetic radio burst images from our MHD simulations. We find that\nradio burst like phenomena is most likely to be observed for moderately active\nsolar like stars and close-in exoplanetary systems have significant influence\non the nature of radio burst spectrum. We find that when the planetary field is\nnot too strong, the planetary magnetosphere is pushing against the CME,\nincreasing its density so the radio burst is visible at higher frequencies.\nWhen the planetary field is very strong, the large magnetosphere does not leave\nroom for the CME shock to evolve so the radio burst is more visible in the\nlower frequencies associated with the weak compression at the flanks of the CME\nshock. In case of highly active solar-like stars, strong overlying stellar\nfields weakens the solar-like CME shock, thus generates very weak (almost\nnon-visible) radio burst signals. For HD 189733 (moderate stellar field), only\nintensity difference is visible when the CME arrives the planet. We also do not\nfind significant modulation in the radio emission by a close-in exoplanet\nsystem when the stellar magnetic field is complex. In summary, our result\nsuggests that the nature of the radio burst spectrum is highly dependent on the\ntopology of the stellar magnetic field and the close-in exoplanetary magnetic\nfield strength.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-04-03T10:42:30Z"}
{"aid":"http://arxiv.org/abs/2504.02486v1","title":"We Need Improved Data Curation and Attribution in AI for Scientific\n  Discovery","summary":"As the interplay between human-generated and synthetic data evolves, new\nchallenges arise in scientific discovery concerning the integrity of the data\nand the stability of the models. In this work, we examine the role of synthetic\ndata as opposed to that of real experimental data for scientific research. Our\nanalyses indicate that nearly three-quarters of experimental datasets available\non open-access platforms have relatively low adoption rates, opening new\nopportunities to enhance their discoverability and usability by automated\nmethods. Additionally, we observe an increasing difficulty in distinguishing\nsynthetic from real experimental data. We propose supplementing ongoing efforts\nin automating synthetic data detection by increasing the focus on watermarking\nreal experimental data, thereby strengthening data traceability and integrity.\nOur estimates suggest that watermarking even less than half of the real world\ndata generated annually could help sustain model robustness, while promoting a\nbalanced integration of synthetic and human-generated content.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-03T11:07:52Z"}
{"aid":"http://arxiv.org/abs/2504.02527v1","title":"Recent results on strangeness enhancement in small collision systems\n  with ALICE","summary":"Quantum Chromodynamics (QCD) predicts that, at sufficiently high temperature\nand energy density, nuclear matter undergoes a phase transition from confined\nhadrons to a deconfined state of quarks and gluons known as the quark-gluon\nplasma (QGP). One of the historically proposed signatures of QGP formation is\nstrangeness enhancement (SE), characterized by an increased production of\nstrange hadrons in heavy-ion collisions relative to proton--proton (pp)\ninteractions. At the LHC, the ALICE experiment has measured a continuous\nincrease in the strange-to-non-strange hadron yield ratios as a function of\nmidrapidity charged-particle multiplicity, not only in large systems like\nPb--Pb but also in small systems such as pp and p--Pb. The origin of SE in\nsmall systems is still under debate, motivating further experimental\ninvestigations. This article presents recent ALICE analyses that offer\ncomplementary insights into the phenomenon. These include (i)\nmulti-differential studies using event-shape observables such as transverse\nspherocity and the concept of effective energy, and (ii) the first measurement\nof multiplicity distributions of strange and multi-strange hadrons,\nP($\\textit{n}_{S}$), in pp collisions.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-03T12:33:27Z"}
{"aid":"http://arxiv.org/abs/2504.02555v1","title":"Noise Calibration and Spatial-Frequency Interactive Network for STEM\n  Image Enhancement","summary":"Scanning Transmission Electron Microscopy (STEM) enables the observation of\natomic arrangements at sub-angstrom resolution, allowing for atomically\nresolved analysis of the physical and chemical properties of materials.\nHowever, due to the effects of noise, electron beam damage, sample thickness,\netc, obtaining satisfactory atomic-level images is often challenging. Enhancing\nSTEM images can reveal clearer structural details of materials. Nonetheless,\nexisting STEM image enhancement methods usually overlook unique features in the\nfrequency domain, and existing datasets lack realism and generality. To resolve\nthese issues, in this paper, we develop noise calibration, data synthesis, and\nenhancement methods for STEM images. We first present a STEM noise calibration\nmethod, which is used to synthesize more realistic STEM images. The parameters\nof background noise, scan noise, and pointwise noise are obtained by\nstatistical analysis and fitting of real STEM images containing atoms. Then we\nuse these parameters to develop a more general dataset that considers both\nregular and random atomic arrangements and includes both HAADF and BF mode\nimages. Finally, we design a spatial-frequency interactive network for STEM\nimage enhancement, which can explore the information in the frequency domain\nformed by the periodicity of atomic arrangement. Experimental results show that\nour data is closer to real STEM images and achieves better enhancement\nperformances together with our network. Code will be available at\nhttps://github.com/HeasonLee/SFIN}{https://github.com/HeasonLee/SFIN.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T13:11:57Z"}
{"aid":"http://arxiv.org/abs/2504.02574v1","title":"Quasi-periodic moir patterns and dimensional localization in\n  three-dimensional quasi-moir crystals","summary":"Recent advances in spin-dependent optical lattices [Meng et al., Nature\n\\textbf{615}, 231 (2023)] have enabled the experimental implementation of two\nsuperimposed three-dimensional lattices, presenting new opportunities to\ninvestigate \\textit{three-dimensional moir\\'{e} physics} in ultracold atomic\ngases. This work studies the moir\\'{e} physics of atoms within a spin-dependent\ncubic lattice with relative twists along different directions. It is discovered\nthat dimensionality significantly influences the low-energy moir\\'{e} physics.\nFrom a geometric perspective, this manifests in the observation that moir\\'{e}\npatterns, generated by rotating lattices along different axes, can exhibit\neither periodic or quasi-periodic behavior--a feature not present in\ntwo-dimensional systems. We develop a low-energy effective theory applicable to\nsystems with arbitrary rotation axes and small rotation angles. This theory\nelucidates the emergence of quasi-periodicity in three dimensions and\ndemonstrates its correlation with the arithmetic properties of the rotation\naxes. Numerical analyses reveal that these quasi-periodic moir\\'{e} potentials\ncan lead to distinctive dimensional localization behaviors of atoms,\nmanifesting as localized wave functions in planar or linear configurations.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas","published":"2025-04-03T13:38:03Z"}
{"aid":"http://arxiv.org/abs/2504.02640v1","title":"RoSMM: A Robust and Secure Multi-Modal Watermarking Framework for\n  Diffusion Models","summary":"Current image watermarking technologies are predominantly categorized into\ntext watermarking techniques and image steganography; however, few methods can\nsimultaneously handle text and image-based watermark data, which limits their\napplicability in complex digital environments. This paper introduces an\ninnovative multi-modal watermarking approach, drawing on the concept of vector\ndiscretization in encoder-based vector quantization. By constructing adjacency\nmatrices, the proposed method enables the transformation of text watermarks\ninto robust image-based representations, providing a novel multi-modal\nwatermarking paradigm for image generation applications. Additionally, this\nstudy presents a newly designed image restoration module to mitigate image\ndegradation caused by transmission losses and various noise interferences,\nthereby ensuring the reliability and integrity of the watermark. Experimental\nresults validate the robustness of the method under multiple noise attacks,\nproviding a secure, scalable, and efficient solution for digital image\ncopyright protection.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-03T14:36:08Z"}
{"aid":"http://arxiv.org/abs/2504.02652v1","title":"Optimizing Resource Allocation to Mitigate the Risk of Disruptive Events\n  in Homeland Security and Emergency Management","summary":"Homeland security in the United States faces a daunting task due to the\nmultiple threats and hazards that can occur. Natural disasters, human-caused\nincidents such as terrorist attacks, and technological failures can result in\nsignificant damage, fatalities, injuries, and economic losses. The increasing\nfrequency and severity of disruptive events in the United States highlight the\nurgent need for effectively allocating resources in homeland security and\nemergency preparedness. This article presents an optimization-based decision\nsupport model to help homeland security policymakers identify and select\nprojects that best mitigate the risk of threats and hazards while satisfying a\nbudget constraint. The model incorporates multiple hazards, probabilistic risk\nassessments, and multidimensional consequences and integrates historical data\nand publicly available sources to evaluate and select the most effective risk\nmitigation projects and optimize resource allocation across various disaster\nscenarios. We apply this model to the state of Iowa, considering 16 hazards,\nsix types of consequences, and 52 mitigation projects. Our results demonstrate\nhow different budget levels influence project selection, emphasizing\ncost-effective solutions that maximize risk reduction. Sensitivity analysis\nexamines the robustness of project selection under varying effectiveness\nassumptions and consequence estimations. The findings offer critical insights\nfor policymakers in homeland security and emergency management and provide a\nbasis for more efficient resource allocation and improved disaster resilience.","main_category":"cs.CY","categories":"cs.CY,math.OC","published":"2025-04-03T14:49:15Z"}
{"aid":"http://arxiv.org/abs/2504.02676v1","title":"Snow: Self-organizing Broadcast Protocol for Cloud","summary":"In large-scale distributed applications, efficient and reliable broadcast\nprotocols are essential for node communication. Tree-based broadcast lacks\nflexibility and may suffer performance degradation or even broadcast failure\nwhen cluster membership changes. Gossip-based broadcast incurs high bandwidth\noverhead and only provides probabilistic delivery guarantees. In tree-based\nbroadcasting, when an internal node leaves, its child nodes need to reconnect\nto a new parent. This process may introduce instability, leading to potential\nmessage duplication and increased transmission latency. However, in cloud\nenvironments, node departures and arrivals are common, causing frequent\nperformance degradation in tree-based broadcasting. This paper introduces Snow,\na self-organizing broadcast protocol designed for cloud environments. Instead,\nit dynamically sends or forwards messages based on each node's membership view,\nultimately forming a broadcast structure resembling a multi-way balanced\ntree(the height difference of leaf nodes is at most 1). Our experimental\nresults showed that Snow maintains message delivery reliability and latency\nguarantees under node churn while maintaining low overhead without sending\nunnecessary redundant messages.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-03T15:15:16Z"}
{"aid":"http://arxiv.org/abs/2504.02680v1","title":"The role of hydrodynamics in the synchronisation of {\\it Chlamydomonas}\n  flagella","summary":"While hydrodynamic coupling has long been considered essential for\nsynchronisation of eukaryotic flagella, recent experiments on the unicellular\nbiflagellate model organism {\\it Chlamydomonas} demonstrate that -- at the\nsingle cell level -- intracellular mechanical coupling is necessary for\ncoordination. It is therefore unclear what role, if any, hydrodynamic forces\nactually play in the synchronisation of multiple flagella within individual\ncells, arguably the building block of large scale coordination. Here we address\nthis question experimentally by transiently blocking hydrodynamic coupling\nbetween the two flagella of single {\\it Chlamydomonas}. Our results reveal that\nin wild type cells intracellularly-mediated forces are necessary and sufficient\nfor flagellar synchronisation, with hydrodynamic coupling causing minimal\nchanges in flagellar dynamics. However, fluid-mediated ciliary coupling is\nresponsible for the extended periods of anti-phase synchronisation observed in\na mutant with weaker intracellular coupling. At the single-cell level,\ntherefore, flagellar coordination depends on a subtle balance between\nintracellular and extracellular forces.","main_category":"physics.bio-ph","categories":"physics.bio-ph,q-bio.CB","published":"2025-04-03T15:15:48Z"}
{"aid":"http://arxiv.org/abs/2504.02693v1","title":"Joint Modeling of Spatial Dependencies Across Multiple Subjects in\n  Multiplexed Tissue Imaging","summary":"The tumor microenvironment (TME) is a spatially heterogeneous ecosystem where\ncellular interactions shape tumor progression and response to therapy.\nMultiplexed imaging technologies enable high-resolution spatial\ncharacterization of the TME, yet statistical methods for analyzing\nmulti-subject spatial tissue data remain limited. We propose a Bayesian\nhierarchical model for inferring spatial dependencies in multiplexed imaging\ndatasets across multiple subjects. Our model represents the TME as a\nmultivariate log-Gaussian Cox process, where spatial intensity functions of\ndifferent cell types are governed by a latent multivariate Gaussian process. By\npooling information across subjects, we estimate spatial correlation functions\nthat capture within-type and cross-type dependencies, enabling interpretable\ninference about disease-specific cellular organization. We validate our method\nusing simulations, demonstrating robustness to latent factor specification and\nspatial resolution. We apply our approach to two multiplexed imaging datasets:\npancreatic cancer and colorectal cancer, revealing distinct spatial\norganization patterns across disease subtypes and highlighting tumor-immune\ninteractions that differentiate immune-permissive and immune-exclusive\nmicroenvironments. These findings provide insight into mechanisms of immune\nevasion and may inform novel therapeutic strategies. Our approach offers a\nprincipled framework for modeling spatial dependencies in multi-subject data,\nwith broader applicability to spatially resolved omics and imaging studies. An\nR package, available online, implements our methods.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-03T15:32:25Z"}
{"aid":"http://arxiv.org/abs/2504.02697v1","title":"Learning Phase Distortion with Selective State Space Models for Video\n  Turbulence Mitigation","summary":"Atmospheric turbulence is a major source of image degradation in long-range\nimaging systems. Although numerous deep learning-based turbulence mitigation\n(TM) methods have been proposed, many are slow, memory-hungry, and do not\ngeneralize well. In the spatial domain, methods based on convolutional\noperators have a limited receptive field, so they cannot handle a large spatial\ndependency required by turbulence. In the temporal domain, methods relying on\nself-attention can, in theory, leverage the lucky effects of turbulence, but\ntheir quadratic complexity makes it difficult to scale to many frames.\nTraditional recurrent aggregation methods face parallelization challenges.\n  In this paper, we present a new TM method based on two concepts: (1) A\nturbulence mitigation network based on the Selective State Space Model\n(MambaTM). MambaTM provides a global receptive field in each layer across\nspatial and temporal dimensions while maintaining linear computational\ncomplexity. (2) Learned Latent Phase Distortion (LPD). LPD guides the state\nspace model. Unlike classical Zernike-based representations of phase\ndistortion, the new LPD map uniquely captures the actual effects of turbulence,\nsignificantly improving the model's capability to estimate degradation by\nreducing the ill-posedness. Our proposed method exceeds current\nstate-of-the-art networks on various synthetic and real-world TM benchmarks\nwith significantly faster inference speed. The code is available at\nhttp://github.com/xg416/MambaTM.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-03T15:33:18Z"}
{"aid":"http://arxiv.org/abs/2504.02715v1","title":"Equality of tropical rank and dimension for tropical linear series","summary":"The tropical rank of a semimodule of rational functions on a metric graph\nmirrors the concept of rank in linear algebra. Defined in terms of the maximal\nnumber of tropically independent elements within the semimodule, this quantity\nhas remained elusive due to the challenges of computing it in practice. In this\nnote, we establish that the tropical rank is, in fact, precisely equal to the\ntopological dimension of the semimodule, one more than the dimension of the\nassociated linear system of divisors. Moreover, we show that the equality of\ndivisorial and tropical ranks in the definition of tropical linear series is\nequivalent to the pure dimensionality of the corresponding linear system. We\nconclude with complementary results and questions on combinatorial and\ntopological properties of the tropical rank.","main_category":"math.AG","categories":"math.AG,math.CO","published":"2025-04-03T15:54:55Z"}
{"aid":"http://arxiv.org/abs/2504.02725v1","title":"ERPO: Advancing Safety Alignment via Ex-Ante Reasoning Preference\n  Optimization","summary":"Recent advancements in large language models (LLMs) have accelerated progress\ntoward artificial general intelligence, yet their potential to generate harmful\ncontent poses critical safety challenges. Existing alignment methods often\nstruggle to cover diverse safety scenarios and remain vulnerable to adversarial\nattacks. In this work, we propose Ex-Ante Reasoning Preference Optimization\n(ERPO), a novel safety alignment framework that equips LLMs with explicit\npreemptive reasoning through Chain-of-Thought and provides clear evidence for\nsafety judgments by embedding predefined safety rules. Specifically, our\napproach consists of three stages: first, equipping the model with Ex-Ante\nreasoning through supervised fine-tuning (SFT) using a constructed reasoning\nmodule; second, enhancing safety, usefulness, and efficiency via Direct\nPreference Optimization (DPO); and third, mitigating inference latency with a\nlength-controlled iterative preference optimization strategy. Experiments on\nmultiple open-source LLMs demonstrate that ERPO significantly enhances safety\nperformance while maintaining response efficiency.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T16:07:38Z"}
{"aid":"http://arxiv.org/abs/2504.02763v1","title":"CanonNet: Canonical Ordering and Curvature Learning for Point Cloud\n  Analysis","summary":"Point cloud processing poses two fundamental challenges: establishing\nconsistent point ordering and effectively learning fine-grained geometric\nfeatures. Current architectures rely on complex operations that limit\nexpressivity while struggling to capture detailed surface geometry. We present\nCanonNet, a lightweight neural network composed of two complementary\ncomponents: (1) a preprocessing pipeline that creates a canonical point\nordering and orientation, and (2) a geometric learning framework where networks\nlearn from synthetic surfaces with precise curvature values. This modular\napproach eliminates the need for complex transformation-invariant architectures\nwhile effectively capturing local geometric properties. Our experiments\ndemonstrate state-of-the-art performance in curvature estimation and\ncompetitive results in geometric descriptor tasks with significantly fewer\nparameters (\\textbf{100X}) than comparable methods. CanonNet's efficiency makes\nit particularly suitable for real-world applications where computational\nresources are limited, demonstrating that mathematical preprocessing can\neffectively complement neural architectures for point cloud analysis. The code\nfor the project is publicly available\n\\hyperlink{https://benjyfri.github.io/CanonNet/}{https://benjyfri.github.io/CanonNet/}.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T16:58:57Z"}
{"aid":"http://arxiv.org/abs/2504.02819v1","title":"GMR-Conv: An Efficient Rotation and Reflection Equivariant Convolution\n  Kernel Using Gaussian Mixture Rings","summary":"Symmetry, where certain features remain invariant under geometric\ntransformations, can often serve as a powerful prior in designing convolutional\nneural networks (CNNs). While conventional CNNs inherently support\ntranslational equivariance, extending this property to rotation and reflection\nhas proven challenging, often forcing a compromise between equivariance,\nefficiency, and information loss. In this work, we introduce Gaussian Mixture\nRing Convolution (GMR-Conv), an efficient convolution kernel that smooths\nradial symmetry using a mixture of Gaussian-weighted rings. This design\nmitigates discretization errors of circular kernels, thereby preserving robust\nrotation and reflection equivariance without incurring computational overhead.\nWe further optimize both the space and speed efficiency of GMR-Conv via a novel\nparameterization and computation strategy, allowing larger kernels at an\nacceptable cost. Extensive experiments on eight classification and one\nsegmentation datasets demonstrate that GMR-Conv not only matches conventional\nCNNs' performance but can also surpass it in applications with orientation-less\ndata. GMR-Conv is also proven to be more robust and efficient than the\nstate-of-the-art equivariant learning methods. Our work provides inspiring\nempirical evidence that carefully applied radial symmetry can alleviate the\nchallenges of information loss, marking a promising advance in equivariant\nnetwork architectures. The code is available at\nhttps://github.com/XYPB/GMR-Conv.","main_category":"cs.CV","categories":"cs.CV,cs.AI,eess.IV,eess.SP","published":"2025-04-03T17:58:18Z"}
{"aid":"http://arxiv.org/abs/2504.04717v1","title":"Beyond Single-Turn: A Survey on Multi-Turn Interactions with Large\n  Language Models","summary":"Recent advancements in large language models (LLMs) have revolutionized their\nability to handle single-turn tasks, yet real-world applications demand\nsophisticated multi-turn interactions. This survey provides a comprehensive\nreview of recent advancements in evaluating and enhancing multi-turn\ninteractions in LLMs. Focusing on task-specific scenarios, from instruction\nfollowing in diverse domains such as math and coding to complex conversational\nengagements in roleplay, healthcare, education, and even adversarial jailbreak\nsettings, we systematically examine the challenges of maintaining context,\ncoherence, fairness, and responsiveness over prolonged dialogues. The paper\norganizes current benchmarks and datasets into coherent categories that reflect\nthe evolving landscape of multi-turn dialogue evaluation. In addition, we\nreview a range of enhancement methodologies under multi-turn settings,\nincluding model-centric strategies (contextual learning, supervised\nfine-tuning, reinforcement learning, and new architectures), external\nintegration approaches (memory-augmented, retrieval-based methods, and\nknowledge graph), and agent-based techniques for collaborative interactions.\nFinally, we discuss open challenges and propose future directions for research\nto further advance the robustness and effectiveness of multi-turn interactions\nin LLMs. Related resources and papers are available at\nhttps://github.com/yubol-cmu/Awesome-Multi-Turn-LLMs.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-07T04:00:08Z"}
{"aid":"http://arxiv.org/abs/2504.04742v1","title":"Unveiling Physical Conditions and Star Formation Processes in the G47\n  Filamentary Cloud","summary":"We present a multi-wavelength study of the filamentary cloud G47 (d\n$\\sim$4.44 kpc), which hosts the mid-infrared bubbles N98, B1, and B2. The\nSMGPS 1.3 GHz continuum map detects ionized emission toward all the bubbles,\nmarking the first detection of ionized emission toward the B2 bubble. Analysis\nof the unWISE 12.0 $\\mu$m image, Spitzer 8.0 $\\mu$m image, and the Herschel\ncolumn density and temperature maps reveals two previously unreported\nhub-filament system candidates associated with the HII regions B2 and N98,\nwhich are powered by massive OB stars. This indirectly favours the\napplicability of a global non-isotropic collapse (GNIC) scenario for massive\nstar formation in N98 and B2. The position-position-velocity diagram of FUGIN\n$^{13}$CO(1-0) shows significant velocity variations from 61 to 53 km s$^{-1}$\ntoward areas between B2 and N98, where the magnetic field morphology exhibits\nsignificant curvature, and high velocity dispersion (i.e., 2.3--3.1 km\ns$^{-1}$) is observed. This may be explained by the expansion of the HII\nregions B2 and N98. The energy budget of the cloud, estimated using SOFIA/HAWC+\nand molecular line data, suggests that the magnetic field dominates over\nturbulence and gravity in G47. Furthermore, the radial column density and\nvelocity profiles of G47 display signatures of converging flows in a sheet-like\nstructure. The relative orientations between the magnetic field and local\ngravity suggest that G47 may undergo gravitational contraction along the\nmagnetic field lines once it becomes magnetically supercritical.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-07T05:36:27Z"}
{"aid":"http://arxiv.org/abs/2504.04749v1","title":"Vision Transformers with Autoencoders and Explainable AI for Cancer\n  Patient Risk Stratification Using Whole Slide Imaging","summary":"Cancer remains one of the leading causes of mortality worldwide,\nnecessitating accurate diagnosis and prognosis. Whole Slide Imaging (WSI) has\nbecome an integral part of clinical workflows with advancements in digital\npathology. While various studies have utilized WSIs, their extracted features\nmay not fully capture the most relevant pathological information, and their\nlack of interpretability limits clinical adoption.\n  In this paper, we propose PATH-X, a framework that integrates Vision\nTransformers (ViT) and Autoencoders with SHAP (Shapley Additive Explanations)\nto enhance model explainability for patient stratification and risk prediction\nusing WSIs from The Cancer Genome Atlas (TCGA). A representative image slice is\nselected from each WSI, and numerical feature embeddings are extracted using\nGoogle's pre-trained ViT. These features are then compressed via an autoencoder\nand used for unsupervised clustering and classification tasks. Kaplan-Meier\nsurvival analysis is applied to evaluate stratification into two and three risk\ngroups. SHAP is used to identify key contributing features, which are mapped\nonto histopathological slices to provide spatial context.\n  PATH-X demonstrates strong performance in breast and glioma cancers, where a\nsufficient number of WSIs enabled robust stratification. However, performance\nin lung cancer was limited due to data availability, emphasizing the need for\nlarger datasets to enhance model reliability and clinical applicability.","main_category":"eess.IV","categories":"eess.IV,cs.CV,cs.LG","published":"2025-04-07T05:48:42Z"}
{"aid":"http://arxiv.org/abs/2504.04789v1","title":"Multimodal Agricultural Agent Architecture (MA3): A New Paradigm for\n  Intelligent Agricultural Decision-Making","summary":"As a strategic pillar industry for human survival and development, modern\nagriculture faces dual challenges: optimizing production efficiency and\nachieving sustainable development. Against the backdrop of intensified climate\nchange leading to frequent extreme weather events, the uncertainty risks in\nagricultural production systems are increasing exponentially. To address these\nchallenges, this study proposes an innovative \\textbf{M}ultimodal\n\\textbf{A}gricultural \\textbf{A}gent \\textbf{A}rchitecture (\\textbf{MA3}),\nwhich leverages cross-modal information fusion and task collaboration\nmechanisms to achieve intelligent agricultural decision-making. This study\nconstructs a multimodal agricultural agent dataset encompassing five major\ntasks: classification, detection, Visual Question Answering (VQA), tool\nselection, and agent evaluation. We propose a unified backbone for sugarcane\ndisease classification and detection tools, as well as a sugarcane disease\nexpert model. By integrating an innovative tool selection module, we develop a\nmultimodal agricultural agent capable of effectively performing tasks in\nclassification, detection, and VQA. Furthermore, we introduce a\nmulti-dimensional quantitative evaluation framework and conduct a comprehensive\nassessment of the entire architecture over our evaluation dataset, thereby\nverifying the practicality and robustness of MA3 in agricultural scenarios.\nThis study provides new insights and methodologies for the development of\nagricultural agents, holding significant theoretical and practical\nimplications. Our source code and dataset will be made publicly available upon\nacceptance.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T07:32:41Z"}
{"aid":"http://arxiv.org/abs/2504.04790v1","title":"Unified speed limits in classical and quantum dynamics via temporal\n  Fisher information","summary":"The importance of Fisher information is increasing in nonequilibrium\nthermodynamics, as it has played a fundamental role in trade-off relations such\nas thermodynamic uncertainty relations and speed limits. In this work, we\ninvestigate temporal Fisher information, which measures the temporal\ninformation content encoded in probability distributions, for both classical\nand quantum systems. We establish that temporal Fisher information is bounded\nfrom above by physical costs, such as entropy production in classical Langevin\nand Markov processes, and the variance of interaction Hamiltonians in open\nquantum systems. Conversely, temporal Fisher information is bounded from below\nby statistical distances (e.g., the Bhattacharyya arccos distance), leading to\nclassical and quantum speed limits that constrain the minimal time required for\nstate transformations. Our work provides a unified perspective of speed limits\nfrom the point of view of temporal Fisher information in both classical and\nquantum dynamics.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-07T07:34:18Z"}
{"aid":"http://arxiv.org/abs/2504.04815v1","title":"Beyond Answers: How LLMs Can Pursue Strategic Thinking in Education","summary":"Artificial Intelligence (AI) holds transformative potential in education,\nenabling personalized learning, enhancing inclusivity, and encouraging\ncreativity and curiosity. In this paper, we explore how Large Language Models\n(LLMs) can act as both patient tutors and collaborative partners to enhance\neducation delivery. As tutors, LLMs personalize learning by offering\nstep-by-step explanations and addressing individual needs, making education\nmore inclusive for students with diverse backgrounds or abilities. As\ncollaborators, they expand students' horizons, supporting them in tackling\ncomplex, real-world problems and co-creating innovative projects. However, to\nfully realize these benefits, LLMs must be leveraged not as tools for providing\ndirect solutions but rather to guide students in developing resolving\nstrategies and finding learning paths together. Therefore, a strong emphasis\nshould be placed on educating students and teachers on the successful use of\nLLMs to ensure their effective integration into classrooms. Through practical\nexamples and real-world case studies, this paper illustrates how LLMs can make\neducation more inclusive and engaging while empowering students to reach their\nfull potential.","main_category":"cs.CY","categories":"cs.CY,cs.ET,eess.SP","published":"2025-04-07T08:09:46Z"}
{"aid":"http://arxiv.org/abs/2504.04835v1","title":"Inland Waterway Object Detection in Multi-environment: Dataset and\n  Approach","summary":"The success of deep learning in intelligent ship visual perception relies\nheavily on rich image data. However, dedicated datasets for inland waterway\nvessels remain scarce, limiting the adaptability of visual perception systems\nin complex environments. Inland waterways, characterized by narrow channels,\nvariable weather, and urban interference, pose significant challenges to object\ndetection systems based on existing datasets. To address these issues, this\npaper introduces the Multi-environment Inland Waterway Vessel Dataset (MEIWVD),\ncomprising 32,478 high-quality images from diverse scenarios, including sunny,\nrainy, foggy, and artificial lighting conditions. MEIWVD covers common vessel\ntypes in the Yangtze River Basin, emphasizing diversity, sample independence,\nenvironmental complexity, and multi-scale characteristics, making it a robust\nbenchmark for vessel detection. Leveraging MEIWVD, this paper proposes a\nscene-guided image enhancement module to improve water surface images based on\nenvironmental conditions adaptively. Additionally, a parameter-limited dilated\nconvolution enhances the representation of vessel features, while a multi-scale\ndilated residual fusion method integrates multi-scale features for better\ndetection. Experiments show that MEIWVD provides a more rigorous benchmark for\nobject detection algorithms, and the proposed methods significantly improve\ndetector performance, especially in complex multi-environment scenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T08:45:00Z"}
{"aid":"http://arxiv.org/abs/2504.04839v1","title":"Crossed Ponderomotive Lenses for Spherical Aberration Correction in\n  Electron Optics","summary":"This article evaluates the lens characteristics of a non-rotationally\nsymmetric electron lens based on a ponderomotive potential (i.e., a\nponderomotive lens) formed by intersecting one or more optical beams\nperpendicular to an electron beam. Based on geometric optics, design formulas\nare derived for the focal length and general spherical aberration coefficients\nof specifically crossed ponderomotive lenses. Numerical calculations\ndemonstrate that a pair of these crossed ponderomotive lenses can effectively\ncorrect spherical aberration in the objective lens of an electron microscope.\nUnlike rotationally symmetric ponderomotive lenses, which require the optical\nbeam to be coaxially aligned with the electron beam, the crossed ponderomotive\nlens avoids the need to place optical mirrors and lenses directly on the beam\naxis. Thus, it offers practical advantages in designing and building electron\noptical instruments and contributes to system miniaturization. With lens\nproperties similar to multipole lenses, the proposed crossed ponderomotive lens\nis expected to facilitate diverse developments in electron optical systems\nincorporating ponderomotive potentials.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-07T08:49:37Z"}
{"aid":"http://arxiv.org/abs/2504.04861v1","title":"SAFT: Structure-aware Transformers for Textual Interaction\n  Classification","summary":"Textual interaction networks (TINs) are an omnipresent data structure used to\nmodel the interplay between users and items on e-commerce websites, social\nnetworks, etc., where each interaction is associated with a text description.\nClassifying such textual interactions (TIC) finds extensive use in detecting\nspam reviews in e-commerce, fraudulent transactions in finance, and so on.\nExisting TIC solutions either (i) fail to capture the rich text semantics due\nto the use of context-free text embeddings, and/or (ii) disregard the bipartite\nstructure and node heterogeneity of TINs, leading to compromised TIC\nperformance. In this work, we propose SAFT, a new architecture that integrates\nlanguage- and graph-based modules for the effective fusion of textual and\nstructural semantics in the representation learning of interactions. In\nparticular, line graph attention (LGA)/gated attention units (GAUs) and\npretrained language models (PLMs) are capitalized on to model the\ninteraction-level and token-level signals, which are further coupled via the\nproxy token in an iterative and contextualized fashion. Additionally, an\nefficient and theoretically-grounded approach is developed to encode the local\nand global topology information pertaining to interactions into structural\nembeddings. The resulting embeddings not only inject the structural features\nunderlying TINs into the textual interaction encoding but also facilitate the\ndesign of graph sampling strategies. Extensive empirical evaluations on\nmultiple real TIN datasets demonstrate the superiority of SAFT over the\nstate-of-the-art baselines in TIC accuracy.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-07T09:19:12Z"}
{"aid":"http://arxiv.org/abs/2504.04865v1","title":"Imagining the Far East: Exploring Perceived Biases in AI-Generated\n  Images of East Asian Women","summary":"Image-generating AI, which allows users to create images from text, is\nincreasingly used to produce visual content. Despite its advancements, cultural\nbiases in AI-generated images have raised significant concerns. While much\nresearch has focused on issues within Western contexts, our study examines the\nperceived biases regarding the portrayal of East Asian women. In this\nexploratory study, we invited East Asian users to audit three popular models\n(DALL-E, Midjourney, Stable Diffusion) and identified 18 specific perceived\nbiases, categorized into four patterns: Westernization, overuse or misuse of\ncultural symbols, sexualization & feminization, and racial stereotypes. This\nwork highlights the potential challenges posed by AI models in portraying\nEastern individuals.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-07T09:20:14Z"}
{"aid":"http://arxiv.org/abs/2504.04866v1","title":"Optimal Network-Guided Covariate Selection for High-Dimensional Data\n  Integration","summary":"When integrating datasets from different studies, it is common that they have\ncomponents of different formats. How to combine them organically for improved\nestimation is important and challenging. This paper investigates this problem\nin a two-study scenario, where covariates are observed for all subjects, but\nnetwork data is available in only one study, and response variables are\navailable only in the other.\n  To leverage the partially observed network information, we propose the\nNetwork-Guided Covariate Selection (NGCS) algorithm. It integrates the spectral\ninformation from network adjacency matrices with the Higher Criticism\nThresholding approach for informative covariates identification. Theoretically,\nwe prove that NGCS achieves the optimal rate in covariate selection, which is\nthe same rate in the supervised learning setting. Furthermore, this optimality\nis robust to network models and tuning parameters.\n  This framework extends naturally to clustering and regression tasks, with two\nproposed algorithms: NG-clu and NG-reg. For clustering, NG-clu accurately\nclusters data points despite incomplete network information. For regression,\nNG-reg enhances predictive performance by incorporating latent covariate\nstructures inferred from network data. Empirical studies on synthetic and\nreal-world datasets demonstrate the robustness and superior performance of our\nalgorithms, underscoring their effectiveness in handling heterogeneous data\nformats.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-07T09:21:34Z"}
{"aid":"http://arxiv.org/abs/2504.04874v1","title":"Futureproof Static Memory Planning","summary":"The NP-complete combinatorial optimization task of assigning offsets to a set\nof buffers with known sizes and lifetimes so as to minimize total memory usage\nis called dynamic storage allocation (DSA). Existing DSA implementations bypass\nthe theoretical state-of-the-art algorithms in favor of either fast but\nwasteful heuristics, or memory-efficient approaches that do not scale beyond\none thousand buffers. The \"AI memory wall\", combined with deep neural networks'\nstatic architecture, has reignited interest in DSA. We present idealloc, a\nlow-fragmentation, high-performance DSA implementation designed for\nmillion-buffer instances. Evaluated on a novel suite of particularly hard\nbenchmarks from several domains, idealloc ranks first against four production\nimplementations in terms of a joint effectiveness/robustness criterion.","main_category":"cs.OS","categories":"cs.OS,cs.AI,cs.PL","published":"2025-04-07T09:28:54Z"}
{"aid":"http://arxiv.org/abs/2504.04898v1","title":"SLIDE: Automated Identification and Quantification of Grain Boundary\n  Sliding and Opening in 3D","summary":"Grain Boundary (GB) deformation mechanisms such as Sliding (GBS) and Opening\n(GBO) are prevalent in alloys at high homologous temperatures but are hard to\ncapture quantitatively. We propose an automated procedure to quantify 3D GB\ndeformations at the nanoscale, using a combination of precisely aligned Digital\nImage Correlation (DIC), electron backscatter diffraction, optical\nprofilometry, and in-beam secondary electron maps. The framework, named Sliding\nidentification by Local Integration of Displacements across Edges (SLIDE), (i)\ndistinguishes GBS from GBO, (ii) computes the datapoint-wise measured in-plane\ndisplacement gradient tensor (from DIC), (iii) projects this data onto the\ntheoretical GBS tensor to reject near-GB plasticity/elasticity/noise, and (iv)\nadds the out-of-plane step from optical profilometry to yield the local 3D\nGBS/GBO vector; automatically repeated for each $\\sim$50nm-long GB segment.\nSLIDE is validated on a virtual experiment of discrete 3D sliding, and\nsuccessfully applied to Zn-coated steel experiments, yielding quantitative\nGBS/GBO activity maps.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-07T10:14:25Z"}
{"aid":"http://arxiv.org/abs/2504.04906v1","title":"On misconceptions about the Brier score in binary prediction models","summary":"The Brier score is a widely used metric evaluating overall performance of\npredictions for binary outcome probabilities in clinical research. However, its\ninterpretation can be complex, as it does not align with commonly taught\nconcepts in medical statistics. Consequently, the Brier score is often\nmisinterpreted, sometimes to a significant extent, a fact that has not been\nadequately addressed in the literature. This commentary aims to explore\nprevalent misconceptions surrounding the Brier score and elucidate the reasons\nthese interpretations are incorrect.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-07T10:30:44Z"}
{"aid":"http://arxiv.org/abs/2504.04942v1","title":"Lemmanaid: Neuro-Symbolic Lemma Conjecturing","summary":"Automatically conjecturing useful, interesting and novel lemmas would greatly\nimprove automated reasoning tools and lower the bar for formalizing mathematics\nin proof assistants. It is however a very challenging task for both neural and\nsymbolic approaches. We present the first steps towards a practical\nneuro-symbolic lemma conjecturing tool, Lemmanaid, that combines Large Language\nModels (LLMs) and symbolic methods, and evaluate it on proof libraries for the\nIsabelle proof assistant. We train an LLM to generate lemma templates that\ndescribe the shape of a lemma, and use symbolic methods to fill in the details.\nWe compare Lemmanaid against an LLM trained to generate complete lemma\nstatements as well as previous fully symbolic conjecturing methods. Our results\nindicate that neural and symbolic techniques are complementary. By leveraging\nthe best of both symbolic and neural methods we can generate useful lemmas for\na wide range of input domains, facilitating computer-assisted theory\ndevelopment and formalization.","main_category":"cs.AI","categories":"cs.AI,cs.LO","published":"2025-04-07T11:30:36Z"}
{"aid":"http://arxiv.org/abs/2504.04953v1","title":"M-Prometheus: A Suite of Open Multilingual LLM Judges","summary":"The use of language models for automatically evaluating long-form text\n(LLM-as-a-judge) is becoming increasingly common, yet most LLM judges are\noptimized exclusively for English, with strategies for enhancing their\nmultilingual evaluation capabilities remaining largely unexplored in the\ncurrent literature. This has created a disparity in the quality of automatic\nevaluation methods for non-English languages, ultimately hindering the\ndevelopment of models with better multilingual capabilities. To bridge this\ngap, we introduce M-Prometheus, a suite of open-weight LLM judges ranging from\n3B to 14B parameters that can provide both direct assessment and pairwise\ncomparison feedback on multilingual outputs. M-Prometheus models outperform\nstate-of-the-art open LLM judges on multilingual reward benchmarks spanning\nmore than 20 languages, as well as on literary machine translation (MT)\nevaluation covering 4 language pairs. Furthermore, M-Prometheus models can be\nleveraged at decoding time to significantly improve generated outputs across\nall 3 tested languages, showcasing their utility for the development of better\nmultilingual models. Lastly, through extensive ablations, we identify the key\nfactors for obtaining an effective multilingual judge, including backbone model\nselection and training on natively multilingual feedback data instead of\ntranslated data. We release our models, training dataset, and code.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-07T11:37:26Z"}
{"aid":"http://arxiv.org/abs/2504.04958v1","title":"Probabilistic imaginary-time evolution in state-vector-based and\n  shot-based simulations and on quantum devices","summary":"Imaginary-time evolution, an important technique in tensor network and\nquantum Monte Carlo algorithms on classical computers, has recently been\nadapted to quantum computing. In this study, we focus on probabilistic\nimaginary-time evolution (PITE) algorithm and derive its formulation in the\ncontext of state-vector-based simulations, where quantum state vectors are\ndirectly used to compute observables without statistical errors. We compare the\nresults with those of shot-based simulations, which estimate observables\nthrough repeated projective measurements. Applying the PITE algorithm to the\nHeisenberg chain, we investigate optimal initial conditions for convergence. We\nfurther demonstrate the method on the transverse-field Ising model using a\nstate-of-the-art trapped-ion quantum device. Finally, we explore the potential\nof error mitigation in this framework, highlighting practical considerations\nfor near-term digital quantum simulations.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,quant-ph","published":"2025-04-07T11:45:31Z"}
{"aid":"http://arxiv.org/abs/2504.04971v1","title":"Below threshold nonsequential double ionization with linearly polarized\n  two-color fields II: Quantum interference","summary":"We perform a systematic analysis of intra-channel quantum interference in\nlaser-induced nonsequential double ionization with linearly polarized\nbichromatic fields, focusing on the recollision-excitation with subsequent\nionization (RESI) mechanism, and employing the strong-field approximation. We\ngeneralize and elaborate several analytic interference conditions for RESI in\narbitrary driving fields, with a focus on the interference arising from the\nspecific symmetries of bichromatic fields. For example, for waves of comparable\nstrengths, multiple events per half cycle for the direct electron must be\nconsidered. Furthermore, interference breaks some of the symmetries arising\nfrom the field. We detangle the superimposed interference fringes originating\nfrom phase differences related to symmetrization due to electron exchange,\ntemporal shifts and a combination of exchange and event interference. We show\nthat the hierarchy between exchange-only and exchange-temporal interference is\nfluid and can be manipulated by an appropriate choice of driving-field\nparameters. This is enabled by different types of interference occupying\nspecific regions of the plane spanned by the electron momentum components\nparallel to the driving-field polarization.","main_category":"physics.atom-ph","categories":"physics.atom-ph","published":"2025-04-07T11:57:18Z"}
{"aid":"http://arxiv.org/abs/2504.04976v1","title":"A Domain-Based Taxonomy of Jailbreak Vulnerabilities in Large Language\n  Models","summary":"The study of large language models (LLMs) is a key area in open-world machine\nlearning. Although LLMs demonstrate remarkable natural language processing\ncapabilities, they also face several challenges, including consistency issues,\nhallucinations, and jailbreak vulnerabilities. Jailbreaking refers to the\ncrafting of prompts that bypass alignment safeguards, leading to unsafe outputs\nthat compromise the integrity of LLMs. This work specifically focuses on the\nchallenge of jailbreak vulnerabilities and introduces a novel taxonomy of\njailbreak attacks grounded in the training domains of LLMs. It characterizes\nalignment failures through generalization, objectives, and robustness gaps. Our\nprimary contribution is a perspective on jailbreak, framed through the\ndifferent linguistic domains that emerge during LLM training and alignment.\nThis viewpoint highlights the limitations of existing approaches and enables us\nto classify jailbreak attacks on the basis of the underlying model deficiencies\nthey exploit. Unlike conventional classifications that categorize attacks based\non prompt construction methods (e.g., prompt templating), our approach provides\na deeper understanding of LLM behavior. We introduce a taxonomy with four\ncategories -- mismatched generalization, competing objectives, adversarial\nrobustness, and mixed attacks -- offering insights into the fundamental nature\nof jailbreak vulnerabilities. Finally, we present key lessons derived from this\ntaxonomic study.","main_category":"cs.CL","categories":"cs.CL,I.2.7","published":"2025-04-07T12:05:16Z"}
{"aid":"http://arxiv.org/abs/2504.04980v1","title":"Combining kinetic and thermodynamic uncertainty relations in quantum\n  transport","summary":"We study the fluctuations of generic currents in multi-terminal,\nmulti-channel quantum transport settings. In the quantum regime, these\nfluctuations and the resulting precision differ strongly depending on whether\nthe device is of fermionic or bosonic nature. Using scattering theory, we show\nthat the precision is bounded by constraints set by the entropy production and\nby the activity in the spirit of thermodynamic or kinetic uncertainty\nrelations, valid for fermionic and bosonic quantum systems and even in the\nabsence of time-reversal symmetry. Furthermore, we derive a combined\nthermodynamic kinetic uncertainty relation, which is tight over a wide range of\nparameters and can hence predict the reachable precision of a device.\n  Since these constraints can be expressed in terms of observables accessible\nin transport measurements, such as currents and bandwidth, we foresee that the\ntight thermodynamic kinetic uncertainty-like bounds are also useful as an\ninference tool: they can be exploited to estimate entropy production from\ntransport observables, such as the charge current and its noise, which are more\neasily accessible in experiment.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.stat-mech,quant-ph","published":"2025-04-07T12:09:09Z"}
{"aid":"http://arxiv.org/abs/2504.04989v1","title":"Randomized block Krylov method for approximation of truncated tensor SVD","summary":"This paper is devoted to studying the application of the block Krylov\nsubspace method for approximation of the truncated tensor SVD (T-SVD). The\ntheoretical results of the proposed randomized approach are presented. Several\nexperimental experiments using synthetics and real-world data are conducted to\nverify the efficiency and feasibility of the proposed randomized approach, and\nthe numerical results show that the proposed method provides promising results.\nApplications of the proposed approach to data completion and data compression\nare presented.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-07T12:13:47Z"}
{"aid":"http://arxiv.org/abs/2504.05001v1","title":"SILVIA: Ultra-precision formation flying demonstration for space-based\n  interferometry","summary":"We propose SILVIA (Space Interferometer Laboratory Voyaging towards\nInnovative Applications), a mission concept designed to demonstrate\nultra-precision formation flying between three spacecraft separated by 100 m.\nSILVIA aims to achieve sub-micrometer precision in relative distance control by\nintegrating spacecraft sensors, laser interferometry, low-thrust and low-noise\nmicro-propulsion for real-time measurement and control of distances and\nrelative orientations between spacecraft. A 100-meter-scale mission in a\nnear-circular low Earth orbit has been identified as an ideal, cost-effective\nsetting for demonstrating SILVIA, as this configuration maintains a good\nbalance between small relative perturbations and low risk for collision. This\nmission will fill the current technology gap towards future missions, including\ngravitational wave observatories such as DECIGO (DECihertz Interferometer\nGravitational wave Observatory), designed to detect the primordial\ngravitational wave background, and high-contrast nulling infrared\ninterferometers like LIFE (Large Interferometer for Exoplanets), designed for\ndirect imaging of thermal emissions from nearby terrestrial planet candidates.\nThe mission concept and its key technologies are outlined, paving the way for\nthe next generation of high-precision space-based observatories.","main_category":"astro-ph.IM","categories":"astro-ph.IM,cs.SY,eess.SY,gr-qc,physics.ins-det","published":"2025-04-07T12:27:46Z"}
{"aid":"http://arxiv.org/abs/2504.05004v1","title":"Stacking Variational Bayesian Monte Carlo","summary":"Variational Bayesian Monte Carlo (VBMC) is a sample-efficient method for\napproximate Bayesian inference with computationally expensive likelihoods.\nWhile VBMC's local surrogate approach provides stable approximations, its\nconservative exploration strategy and limited evaluation budget can cause it to\nmiss regions of complex posteriors. In this work, we introduce Stacking\nVariational Bayesian Monte Carlo (S-VBMC), a method that constructs global\nposterior approximations by merging independent VBMC runs through a principled\nand inexpensive post-processing step. Our approach leverages VBMC's mixture\nposterior representation and per-component evidence estimates, requiring no\nadditional likelihood evaluations while being naturally parallelizable. We\ndemonstrate S-VBMC's effectiveness on two synthetic problems designed to\nchallenge VBMC's exploration capabilities and two real-world applications from\ncomputational neuroscience, showing substantial improvements in posterior\napproximation quality across all cases.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-07T12:30:59Z"}
{"aid":"http://arxiv.org/abs/2504.05028v1","title":"The Lorentzian splitting theorem with weakened curvature condition","summary":"In this note we present a version of the Lorentzian splitting theorem under\nan averaged Ricci curvature condition, utilizing, in its proof, the properties\nof achronal limits developed in [18], [19].","main_category":"math.DG","categories":"math.DG,gr-qc","published":"2025-04-07T12:51:16Z"}
{"aid":"http://arxiv.org/abs/2504.05030v1","title":"AsyReC: A Multimodal Graph-based Framework for Spatio-Temporal\n  Asymmetric Dyadic Relationship Classification","summary":"Dyadic social relationships, which refer to relationships between two\nindividuals who know each other through repeated interactions (or not), are\nshaped by shared spatial and temporal experiences. Current computational\nmethods for modeling these relationships face three major challenges: (1) the\nfailure to model asymmetric relationships, e.g., one individual may perceive\nthe other as a friend while the other perceives them as an acquaintance, (2)\nthe disruption of continuous interactions by discrete frame sampling, which\nsegments the temporal continuity of interaction in real-world scenarios, and\n(3) the limitation to consider periodic behavioral cues, such as rhythmic\nvocalizations or recurrent gestures, which are crucial for inferring the\nevolution of dyadic relationships. To address these challenges, we propose\nAsyReC, a multimodal graph-based framework for asymmetric dyadic relationship\nclassification, with three core innovations: (i) a triplet graph neural network\nwith node-edge dual attention that dynamically weights multimodal cues to\ncapture interaction asymmetries (addressing challenge 1); (ii) a clip-level\nrelationship learning architecture that preserves temporal continuity, enabling\nfine-grained modeling of real-world interaction dynamics (addressing challenge\n2); and (iii) a periodic temporal encoder that projects time indices onto\nsine/cosine waveforms to model recurrent behavioral patterns (addressing\nchallenge 3). Extensive experiments on two public datasets demonstrate\nstate-of-the-art performance, while ablation studies validate the critical role\nof asymmetric interaction modeling and periodic temporal encoding in improving\nthe robustness of dyadic relationship classification in real-world scenarios.\nOur code is publicly available at: https://github.com/tw-repository/AsyReC.","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-07T12:52:23Z"}
{"aid":"http://arxiv.org/abs/2504.05076v1","title":"Content-Distortion High-Order Interaction for Blind Image Quality\n  Assessment","summary":"The content and distortion are widely recognized as the two primary factors\naffecting the visual quality of an image. While existing No-Reference Image\nQuality Assessment (NR-IQA) methods have modeled these factors, they fail to\ncapture the complex interactions between content and distortions. This\nshortfall impairs their ability to accurately perceive quality. To confront\nthis, we analyze the key properties required for interaction modeling and\npropose a robust NR-IQA approach termed CoDI-IQA (Content-Distortion high-order\nInteraction for NR-IQA), which aggregates local distortion and global content\nfeatures within a hierarchical interaction framework. Specifically, a\nProgressive Perception Interaction Module (PPIM) is proposed to explicitly\nsimulate how content and distortions independently and jointly influence image\nquality. By integrating internal interaction, coarse interaction, and fine\ninteraction, it achieves high-order interaction modeling that allows the model\nto properly represent the underlying interaction patterns. To ensure sufficient\ninteraction, multiple PPIMs are employed to hierarchically fuse multi-level\ncontent and distortion features at different granularities. We also tailor a\ntraining strategy suited for CoDI-IQA to maintain interaction stability.\nExtensive experiments demonstrate that the proposed method notably outperforms\nthe state-of-the-art methods in terms of prediction accuracy, data efficiency,\nand generalization ability.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:44:30Z"}
{"aid":"http://arxiv.org/abs/2504.05078v1","title":"Serverless Approach to Running Resource-Intensive STAR Aligner","summary":"The application of serverless computing for alignment of RNA-sequences can\nimprove many existing bioinformatics workflows by reducing operational costs\nand execution times. This work analyzes the applicability of serverless\nservices for running the STAR aligner, which is known for its accuracy and\nlarge memory requirement. This presents a challenge, as serverless services\nwere designed for light and short tasks. Nevertheless, we successfully deploy a\nSTAR-based pipeline on AWS ECS service, propose multiple optimizations, and\nperform experiment with 17 TBs of data. Results are compared against standard\nvirtual machine (VM) based solution showing that serverless is a valid\nalternative for small-scale batch processing. However, in large-scale where\nefficiency matters the most, VMs are still recommended.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-07T13:45:46Z"}
{"aid":"http://arxiv.org/abs/2504.05079v1","title":"Experimental verification of Threshold Quantum State Tomography on a\n  fully-reconfigurable photonic integrated circuit","summary":"Reconstructing the state of a complex quantum system represents a pivotal\ntask for all quantum information applications, both for characterization\npurposes and for verification of quantum protocols. Recent technological\ndevelopments have shown the capability of building quantum systems with\nprogressively larger number of qubits in different platforms. The standard\napproach based on quantum state tomography, while providing a method to\ncompletely characterize an unknown quantum state, requires a number of\nmeasurements that scales exponentially with the number of qubits. Other methods\nhave been subsequently proposed and tested to reduce the number of\nmeasurements, or to focus on specific properties of the output state rather\nthan on its complete reconstruction. Here, we show experimentally the\napplication of an approach, called threshold quantum state tomography, in an\nadvanced hybrid photonic platform with states up to n=4 qubits. This method\ndoes not require a priori knowledge on the state, and selects only the\ninformative projectors starting from the measurement of the density matrix\ndiagonal. We show the effectiveness of this approach in a photonic platform,\nshowing that a consistent reduction in the number of measurement is obtained\nwhile reconstructing relevant states for quantum protocols, with only very\nlimited loss of information. The advantage of this protocol opens perspective\nof its application in larger, more complex, systems.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-07T13:47:41Z"}
{"aid":"http://arxiv.org/abs/2504.05183v1","title":"Utility-aware Social Network Anonymization using Genetic Algorithms","summary":"Social networks may contain privacy-sensitive information about individuals.\nThe objective of the network anonymization problem is to alter a given social\nnetwork dataset such that the number of anonymous nodes in the social graph is\nmaximized. Here, a node is anonymous if it does not have a unique surrounding\nnetwork structure. At the same time, the aim is to ensure data utility, i.e.,\npreserve topological network properties and retain good performance on\ndownstream network analysis tasks. We propose two versions of a genetic\nalgorithm tailored to this problem: one generic GA and a uniqueness-aware GA\n(UGA). The latter aims to target edges more effectively during mutation by\navoiding edges connected to already anonymous nodes. After hyperparameter\ntuning, we compare the two GAs against two existing baseline algorithms on\nseveral real-world network datasets. Results show that the proposed genetic\nalgorithms manage to anonymize on average 14 times more nodes than the best\nbaseline algorithm. Additionally, data utility experiments demonstrate how the\nUGA requires fewer edge deletions, and how our GAs and the baselines retain\nperformance on downstream tasks equally well. Overall, our results suggest that\ngenetic algorithms are a promising approach for finding solutions to the\nnetwork anonymization problem.","main_category":"cs.SI","categories":"cs.SI","published":"2025-04-07T15:29:28Z"}
{"aid":"http://arxiv.org/abs/2504.05202v1","title":"Infinitely Divisible Noise for Differential Privacy: Nearly Optimal\n  Error in the High $\\varepsilon$ Regime","summary":"Differential privacy (DP) can be achieved in a distributed manner, where\nmultiple parties add independent noise such that their sum protects the overall\ndataset with DP. A common technique here is for each party to sample their\nnoise from the decomposition of an infinitely divisible distribution. We\nanalyze two mechanisms in this setting: 1) the generalized discrete Laplace\n(GDL) mechanism, whose distribution (which is closed under summation) follows\nfrom differences of i.i.d. negative binomial shares, and 2) the multi-scale\ndiscrete Laplace (MSDLap) mechanism, a novel mechanism following the sum of\nmultiple i.i.d. discrete Laplace shares at different scales.\n  For $\\varepsilon \\geq 1$, our mechanisms can be parameterized to have\n$O\\left(\\Delta^3 e^{-\\varepsilon}\\right)$ and $O\\left(\\min\\left(\\Delta^3\ne^{-\\varepsilon}, \\Delta^2 e^{-2\\varepsilon/3}\\right)\\right)$ MSE,\nrespectively, where $\\Delta$ denote the sensitivity; the latter bound matches\nknown optimality results. We also show a transformation from the discrete\nsetting to the continuous setting, which allows us to transform both mechanisms\nto the continuous setting and thereby achieve the optimal $O\\left(\\Delta^2\ne^{-2\\varepsilon / 3}\\right)$ MSE. To our knowledge, these are the first\ninfinitely divisible additive noise mechanisms that achieve order-optimal MSE\nunder pure DP, so our work shows formally there is no separation in utility\nwhen query-independent noise adding mechanisms are restricted to infinitely\ndivisible noise. For the continuous setting, our result improves upon the Arete\nmechanism from [Pagh and Stausholm, ALT 2022] which gives an MSE of\n$O\\left(\\Delta^2 e^{-\\varepsilon/4}\\right)$. Furthermore, we give an exact\nsampler tuned to efficiently implement the MSDLap mechanism, and we apply our\nresults to improve a state of the art multi-message shuffle DP protocol in the\nhigh $\\varepsilon$ regime.","main_category":"cs.CR","categories":"cs.CR,cs.DS","published":"2025-04-07T15:50:46Z"}
{"aid":"http://arxiv.org/abs/2504.05204v1","title":"Quantum Program Linting with LLMs: Emerging Results from a Comparative\n  Study","summary":"Ensuring the quality of quantum programs is increasingly important; however,\ntraditional static analysis techniques are insufficient due to the unique\ncharacteristics of quantum computing. Quantum-specific linting tools, such as\nLintQ, have been developed to detect quantum-specific programming problems;\nhowever, they typically rely on manually crafted analysis queries. The manual\neffort required to update these tools limits their adaptability to evolving\nquantum programming practices.\n  To address this challenge, this study investigates the feasibility of\nemploying Large Language Models (LLMs) to develop a novel linting technique for\nquantum software development and explores potential avenues to advance linting\napproaches. We introduce LintQ-LLM, an LLM-based linting tool designed to\ndetect quantum-specific problems comparable to those identified by LintQ.\nThrough an empirical comparative study using real-world Qiskit programs, our\nresults show that LintQ-LLM is a viable solution that complements LintQ, with\nparticular strengths in problem localization, explanation clarity, and\nadaptability potential for emerging quantum programming frameworks, thus\nproviding a basis for further research. Furthermore, this study discusses\nseveral research opportunities for developing more advanced, adaptable, and\nfeedback-aware quantum software quality assurance methods by leveraging LLMs.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-07T15:51:31Z"}
{"aid":"http://arxiv.org/abs/2504.05218v1","title":"Hybrid machine learning data assimilation for marine biogeochemistry","summary":"Marine biogeochemistry models are critical for forecasting, as well as\nestimating ecosystem responses to climate change and human activities. Data\nassimilation (DA) improves these models by aligning them with real-world\nobservations, but marine biogeochemistry DA faces challenges due to model\ncomplexity, strong nonlinearity, and sparse, uncertain observations. Existing\nDA methods applied to marine biogeochemistry struggle to update unobserved\nvariables effectively, while ensemble-based methods are computationally too\nexpensive for high-complexity marine biogeochemistry models. This study\ndemonstrates how machine learning (ML) can improve marine biogeochemistry DA by\nlearning statistical relationships between observed and unobserved variables.\nWe integrate ML-driven balancing schemes into a 1D prototype of a system used\nto forecast marine biogeochemistry in the North-West European Shelf seas. ML is\napplied to predict (i) state-dependent correlations from free-run ensembles and\n(ii), in an ``end-to-end'' fashion, analysis increments from an Ensemble Kalman\nFilter. Our results show that ML significantly enhances updates for previously\nnot-updated variables when compared to univariate schemes akin to those used\noperationally. Furthermore, ML models exhibit moderate transferability to new\nlocations, a crucial step toward scaling these methods to 3D operational\nsystems. We conclude that ML offers a clear pathway to overcome current\ncomputational bottlenecks in marine biogeochemistry DA and that refining\ntransferability, optimizing training data sampling, and evaluating scalability\nfor large-scale marine forecasting, should be future research priorities.","main_category":"physics.ao-ph","categories":"physics.ao-ph,cs.LG","published":"2025-04-07T16:04:10Z"}
{"aid":"http://arxiv.org/abs/2504.05233v1","title":"Formation of Near-surface Atmospheric Inversion and Surface Inversion in\n  Hothouse Climates","summary":"A hothouse climate may develop throughout Earth's history and its warming\nfuture and on potentially habitable exoplanets near the inner edge of the\nhabitable zone. Previous studies suggested that near-surface atmospheric\ninversion (NAIV) with planetary boundary air temperature being higher than the\nair temperature adjacent to the surface, is a pronounced phenomenon in hothouse\nclimates. However, the underlying mechanisms are unclear. Here we show that\nlower-tropospheric radiative heating is necessary but not independently\nsufficient in forming the NAIV. Instead, the dynamic heating induced by\nlarge-scale subsidence is essential. With the prescribed reasonable large-scale\nsubsidence, NAIV appears in small-domain cloud-resolving simulations, which was\nnot observed in previous studies. Surface evaporative cooling also contributes\nto the formation of the NAIV. Besides NAIV, we find that surface inversion\n(SIV) with the air adjacent to the surface being warmer than the underlying sea\nsurface is also a distinct phenomenon in hothouse climates. SIV is caused by\nstrong surface evaporative cooling and large atmospheric shortwave absorption.\nThese two types of inversion strongly stabilize the atmosphere, weaken\natmospheric circulation, dry the free troposphere, and suppress the\nhydrological cycle.","main_category":"astro-ph.EP","categories":"astro-ph.EP,physics.ao-ph","published":"2025-04-07T16:18:06Z"}
{"aid":"http://arxiv.org/abs/2504.05262v1","title":"Do PhD-level LLMs Truly Grasp Elementary Addition? Probing Rule Learning\n  vs. Memorization in Large Language Models","summary":"Despite high benchmark scores, Large Language Models (LLMs) often fail simple\nproblem, raising a critical question: Do LLMs learn mathematical principles or\nmerely memorize patterns? Rather than designing increasingly complex benchmarks\nlike recent works, we investigate this using elementary two-integer addition\n($0$ to $2^{64}$), probing two core properties: commutativity ($A+B=B+A$) and\ncompositional generalization (via isomorphic symbolic mappings, e.g., $7\n\\rightarrow y$). While state-of-the-art LLMs achieve 73.8-99.8\\% accuracy on\nnumerical addition, performance collapses to $\\leq$7.5\\% under symbolic\nmapping, indicating failure to generalize learned rules. Non-monotonic\nperformance scaling with digit count and frequent commutativity violations\n(over 1,700 cases of $A+B \\neq B+A$) further support this. Explicitly providing\naddition rules degrades performance by 81.2\\% on average, while\nself-explanation maintains baseline accuracy, suggesting LLM arithmetic\nprocessing is misaligned with human-defined principles. Our findings indicate\ncurrent LLMs rely on memory pattern over genuine rule learning, highlighting\narchitectural limitations and the need for new approaches to achieve true\nmathematical reasoning.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T16:57:10Z"}
{"aid":"http://arxiv.org/abs/2504.05272v1","title":"The Standard Model tested with neutrinos","summary":"The Standard Model (SM) of particle physics effectively explains most\nobserved phenomena, though some anomalies, especially in the neutrino sector,\nsuggest the need for extensions. In this work, we perform the first global fit\nof elastic neutrino-nucleus and neutrino-electron scattering data to further\ntest the SM within a consistent framework. Our results on the neutrino charge\nradius, the only non-zero electromagnetic property of neutrinos in the SM, show\nno significant deviation, indicating no large beyond the SM flavor-dependent\neffects for electron and muon neutrinos. By incorporating solar neutrino data\nfrom dark matter direct detection experiments, we also place the most stringent\nconstraints on the tau neutrino charge radius obtained from neutrino scattering\nexperiments. Additionally, we determine updated constraints on the vector and\naxial-vector neutrino-electron neutral current couplings, adjusting for\nflavor-dependent effects and for the different experimental momentum transfers.\nThe global analysis reveals two allowed solutions: one close to the SM\nprediction, and a degenerate solution that is favored. We show that future dark\nmatter detectors could achieve sufficient precision to resolve the degeneracy.\nAs we move toward the precision era, this work demonstrates the crucial need to\nproperly account for flavor- and momentum-dependent effects to avoid\nmisinterpretations of the data.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-07T17:08:28Z"}
{"aid":"http://arxiv.org/abs/2504.05296v1","title":"Let it Snow! Animating Static Gaussian Scenes With Dynamic Weather\n  Effects","summary":"3D Gaussian Splatting has recently enabled fast and photorealistic\nreconstruction of static 3D scenes. However, introducing dynamic elements that\ninteract naturally with such static scenes remains challenging. Accordingly, we\npresent a novel hybrid framework that combines Gaussian-particle\nrepresentations for incorporating physically-based global weather effects into\nstatic 3D Gaussian Splatting scenes, correctly handling the interactions of\ndynamic elements with the static scene. We follow a three-stage process: we\nfirst map static 3D Gaussians to a particle-based representation. We then\nintroduce dynamic particles and simulate their motion using the Material Point\nMethod (MPM). Finally, we map the simulated particles back to the Gaussian\ndomain while introducing appearance parameters tailored for specific effects.\nTo correctly handle the interactions of dynamic elements with the static scene,\nwe introduce specialized collision handling techniques. Our approach supports a\nvariety of weather effects, including snowfall, rainfall, fog, and sandstorms,\nand can also support falling objects, all with physically plausible motion and\nappearance. Experiments demonstrate that our method significantly outperforms\nexisting approaches in both visual quality and physical realism.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-07T17:51:21Z"}
{"aid":"http://arxiv.org/abs/2504.05298v1","title":"One-Minute Video Generation with Test-Time Training","summary":"Transformers today still struggle to generate one-minute videos because\nself-attention layers are inefficient for long context. Alternatives such as\nMamba layers struggle with complex multi-scene stories because their hidden\nstates are less expressive. We experiment with Test-Time Training (TTT) layers,\nwhose hidden states themselves can be neural networks, therefore more\nexpressive. Adding TTT layers into a pre-trained Transformer enables it to\ngenerate one-minute videos from text storyboards. For proof of concept, we\ncurate a dataset based on Tom and Jerry cartoons. Compared to baselines such as\nMamba~2, Gated DeltaNet, and sliding-window attention layers, TTT layers\ngenerate much more coherent videos that tell complex stories, leading by 34 Elo\npoints in a human evaluation of 100 videos per method. Although promising,\nresults still contain artifacts, likely due to the limited capability of the\npre-trained 5B model. The efficiency of our implementation can also be\nimproved. We have only experimented with one-minute videos due to resource\nconstraints, but the approach can be extended to longer videos and more complex\nstories. Sample videos, code and annotations are available at:\nhttps://test-time-training.github.io/video-dit","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T17:56:31Z"}
{"aid":"http://arxiv.org/abs/2504.05637v1","title":"Spontaneous vortex crystal formation in classical rotating flows","summary":"Vortex crystals, ordered structures observed in superconductors and rotating\nsuperfluids, have also been hypothesized to form in classical fluids, based on\nnumerical simulations and observations of the Jovian polar atmospheres. We\nperform direct numerical simulations of the Navier-Stokes equations in rotating\nframes, to investigate the spontaneous emergence of metastable vortex crystals.\nWe analyze the energy spectrum, vortex morphology, and spatio-temporal dynamics\nto understand their roles in crystal formation and evolution. In addition, we\nexplore domains with varying aspect ratios to examine their impact on the\nvortex lattice. Our results indicate a relationship between the crystal\nlifespan and dissipation, and we propose a scaling law linking the rotation\nrate, domain geometry, and vortex lattice periodicity. Finally, we identify a\ncritical threshold in the control parameter, the Rossby number, suggesting a\nbehavior similar to that found in phase transitions.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-08T03:30:30Z"}
{"aid":"http://arxiv.org/abs/2504.05639v1","title":"DBOT: Artificial Intelligence for Systematic Long-Term Investing","summary":"Long-term investing was previously seen as requiring human judgment. With the\nadvent of generative artificial intelligence (AI) systems, automated systematic\nlong-term investing is now feasible. In this paper, we present DBOT, a system\nwhose goal is to reason about valuation like Aswath Damodaran, who is a unique\nexpert in the investment arena in terms of having published thousands of\nvaluations on companies in addition to his numerous writings on the topic,\nwhich provide ready training data for an AI system. DBOT can value any publicly\ntraded company. DBOT can also be back-tested, making its behavior and\nperformance amenable to scientific inquiry. We compare DBOT to its analytic\nparent, Damodaran, and highlight the research challenges involved in raising\nits current capability to that of Damodaran's. Finally, we examine the\nimplications of DBOT-like AI agents for the financial industry, especially how\nthey will impact the role of human analysts in valuation.","main_category":"cs.CL","categories":"cs.CL,cs.AI,q-fin.PR","published":"2025-04-08T03:34:22Z"}
{"aid":"http://arxiv.org/abs/2504.05651v1","title":"Measuring Dj vu Memorization Efficiently","summary":"Recent research has shown that representation learning models may\naccidentally memorize their training data. For example, the d\\'ej\\`a vu method\nshows that for certain representation learning models and training images, it\nis sometimes possible to correctly predict the foreground label given only the\nrepresentation of the background - better than through dataset-level\ncorrelations. However, their measurement method requires training two models -\none to estimate dataset-level correlations and the other to estimate\nmemorization. This multiple model setup becomes infeasible for large\nopen-source models. In this work, we propose alternative simple methods to\nestimate dataset-level correlations, and show that these can be used to\napproximate an off-the-shelf model's memorization ability without any\nretraining. This enables, for the first time, the measurement of memorization\nin pre-trained open-source image representation and vision-language\nrepresentation models. Our results show that different ways of measuring\nmemorization yield very similar aggregate results. We also find that\nopen-source models typically have lower aggregate memorization than similar\nmodels trained on a subset of the data. The code is available both for vision\nand vision language models.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-08T03:55:20Z"}
{"aid":"http://arxiv.org/abs/2504.05655v1","title":"Multi-bubble solutions for the Dirichlet problem of the $H$-system with\n  higher degree","summary":"We consider a Dirichlet problem of the $H$-system \\begin{equation*}\n\\begin{cases} \\Delta v = 2v_x\\wedge v_y ~& \\text{ in }\\mathcal{D},\\\\\nv=\\varepsilon \\tilde g ~& \\text{ on }\\partial{\\mathcal{D}}, \\end{cases}\n\\end{equation*} where $\\mathcal D\\subset \\mathbb{R}^2$ is the unit disk,\n$v:\\mathcal D\\to \\mathbb{R}^3$, and $\\tilde g:\\partial \\mathcal D\\to\n\\mathbb{R}^3$ is a given smooth map. As $\\varepsilon\\to 0^+$, we construct\nmulti-bubble solutions concentrating at distinct points, taking around each\npoint the profile of degree 2 $H$-bubble. This gives a partial answer to a\nconjecture due to Brezis-Coron \\cite{BrezisCoron} and Chanillo-Malchiodi\n\\cite{chanillomalchiodi2005cagasymptotic} concerning the limiting configuration\nin the case of higher degrees. This seems to be the first construction in\nemploying higher-degree harmonic maps as the primary configurations.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T04:05:53Z"}
{"aid":"http://arxiv.org/abs/2504.05660v1","title":"Entangling quantum memories over 420 km in fiber","summary":"Long-distance entanglement is pivotal for quantum communication, distributed\nquantum computing and sensing. Significant progresses have been made in\nextending the distribution distance of entangled photons, either in free space\nor fiber. For future quantum network applications, matter-based entanglement is\nmore favorable since the capability of storage is essential for advanced\napplications. Extending entanglement distance for memory qubits was partially\nhindered by the mismatch of its photonic emission wavelength with the low-loss\ntransmission window of optical fiber. By incorporating quantum frequency\nconversion, memory-memory entanglement has been successfully extended to\nseveral tens of kilometers. Here, we make a significant step further by\nreporting the entanglement between two atomic ensemble quantum memories over\n420 km. We convert photons emitted from the memories to telecom S-band, which\nenable us to exploit the significantly low transmission loss in fiber (0.17\ndB/km). We employ the DLCZ scheme for remote entanglement generation, and\ndelicately stabilize the relative phase between the two memories by using\nfulltime far-off-resonant locking to reduce high-frequency noise and\nintermittent dual-band locking to compensate low-frequency drift jointly. We\ndemonstrate that the memory-memory entangling probability beats the\nrepeaterless channel capacity for direct entanglement distribution. Our\nexperiment provides a testbed of studying quantum network applications from\nmetropolitan scale to intercity scale.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-08T04:19:24Z"}
{"aid":"http://arxiv.org/abs/2504.05678v1","title":"On The Merit Principle in Strategic Exchanges","summary":"New fairness notions in align with the merit principle are proposed for\ndesigning exchange rules. We show that, for an obviously strategy-proof,\nefficient and individually rational rule, an upper bound of fairness attainable\nis that, if two agents possess objects considered the best by all others, then\nat least one receives her favorite object. Notably, it is not possible to\nguarantee them both receiving favorites. Our results thus indicate an\nunambiguous trade-off between incentives and fairness in the design of exchange\nrules.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-08T04:38:47Z"}
{"aid":"http://arxiv.org/abs/2504.05686v1","title":"kNN-SVC: Robust Zero-Shot Singing Voice Conversion with Additive\n  Synthesis and Concatenation Smoothness Optimization","summary":"Robustness is critical in zero-shot singing voice conversion (SVC). This\npaper introduces two novel methods to strengthen the robustness of the kNN-VC\nframework for SVC. First, kNN-VC's core representation, WavLM, lacks harmonic\nemphasis, resulting in dull sounds and ringing artifacts. To address this, we\nleverage the bijection between WavLM, pitch contours, and spectrograms to\nperform additive synthesis, integrating the resulting waveform into the model\nto mitigate these issues. Second, kNN-VC overlooks concatenative smoothness, a\nkey perceptual factor in SVC. To enhance smoothness, we propose a new distance\nmetric that filters out unsuitable kNN candidates and optimize the summing\nweights of the candidates during inference. Although our techniques are built\non the kNN-VC framework for implementation convenience, they are broadly\napplicable to general concatenative neural synthesis models. Experimental\nresults validate the effectiveness of these modifications in achieving robust\nSVC. Demo: http://knnsvc.com Code: https://github.com/SmoothKen/knn-svc","main_category":"cs.SD","categories":"cs.SD,cs.AI,cs.LG,cs.MM,eess.AS","published":"2025-04-08T04:59:56Z"}
{"aid":"http://arxiv.org/abs/2504.05693v1","title":"STRIVE: A Think & Improve Approach with Iterative Refinement for\n  Enhancing Question Quality Estimation","summary":"Automatically assessing question quality is crucial for educators as it saves\ntime, ensures consistency, and provides immediate feedback for refining\nteaching materials. We propose a novel methodology called STRIVE (Structured\nThinking and Refinement with multiLLMs for Improving Verified Question\nEstimation) using a series of Large Language Models (LLMs) for automatic\nquestion evaluation. This approach aims to improve the accuracy and depth of\nquestion quality assessment, ultimately supporting diverse learners and\nenhancing educational practices. The method estimates question quality in an\nautomated manner by generating multiple evaluations based on the strengths and\nweaknesses of the provided question and then choosing the best solution\ngenerated by the LLM. Then the process is improved by iterative review and\nresponse with another LLM until the evaluation metric values converge. This\nsophisticated method of evaluating question quality improves the estimation of\nquestion quality by automating the task of question quality evaluation.\nCorrelation scores show that using this proposed method helps to improve\ncorrelation with human judgments compared to the baseline method. Error\nanalysis shows that metrics like relevance and appropriateness improve\nsignificantly relative to human judgments by using STRIVE.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-08T05:34:38Z"}
{"aid":"http://arxiv.org/abs/2504.05695v1","title":"Architecture independent generalization bounds for overparametrized deep\n  ReLU networks","summary":"We prove that overparametrized neural networks are able to generalize with a\ntest error that is independent of the level of overparametrization, and\nindependent of the Vapnik-Chervonenkis (VC) dimension. We prove explicit bounds\nthat only depend on the metric geometry of the test and training sets, on the\nregularity properties of the activation function, and on the operator norms of\nthe weights and norms of biases. For overparametrized deep ReLU networks with a\ntraining sample size bounded by the input space dimension, we explicitly\nconstruct zero loss minimizers without use of gradient descent, and prove that\nthe generalization error is independent of the network architecture.","main_category":"cs.LG","categories":"cs.LG,cs.AI,math.AP,math.OC,stat.ML","published":"2025-04-08T05:37:38Z"}
{"aid":"http://arxiv.org/abs/2504.05724v1","title":"Duality for operator systems with generating cones","summary":"Let $S$ be a complete operator system with a generating cone; i.e. $S_\\sa =\nS_+ - S_+$. We show that there is a matrix norm on the dual space $S^*$, under\nwhich, and the usual dual matrix cone, $S^*$ becomes a dual operator system\nwith a generating cone, denoted by $S^\\rd$. The canonical complete order\nisomorphism $\\iota_{S^*}: S^* \\to S^\\rd$ is a dual Banach space isomorphism.\nFurthermore, we construct a canonical completely contractive\nweak$^*$-homeomorphism $\\beta_S: (S^\\rd)^\\rd\\to S^{**}$, and verify that it is\na complete order isomorphism.\n  For a complete operator system $T$ with a generating cone and a completely\npositive complete contraction $\\varphi:S\\to T$, there is a weak$^*$-continuous\ncompletely positive complete contraction $\\varphi^\\rd:T^\\rd \\to S^\\rd$ with\n$\\iota_{S^*}\\circ \\varphi^* = \\varphi^\\rd \\circ \\iota_{T^*}$. This produces a\nfaithful functor from the category of complete operator systems with generating\ncones (where morphisms are completely positive complete contractions) to the\ncategory of dual operator systems with generating cones (where morphisms are\nweak$^*$-continuous completely positive complete contractions).\n  We define the notion of approximately unital operator systems, and verify\nthat operator systems considered in \\cite{CvS} and \\cite{CvS2} are\napproximately unital. If $S$ is approximately unital, then $\\iota_{S^*}:S^* \\to\nS^\\rd$ is an operator space isomorphism and $\\beta_S: (S^\\rd)^\\rd\\to S^{**}$ is\na complete isometry. We will also establish that the restriction of the\nfaithful functor $(S,T,\\varphi)\\mapsto (T^\\rd, S^\\rd, \\varphi^\\rd)$ to the\ncategory of approximately unital complete operator systems is both full and\ninjective on objects.","main_category":"math.OA","categories":"math.OA,math.FA","published":"2025-04-08T06:50:46Z"}
{"aid":"http://arxiv.org/abs/2504.05731v1","title":"Retrieval Augmented Generation with Collaborative Filtering for\n  Personalized Text Generation","summary":"Recently, the personalization of Large Language Models (LLMs) to generate\ncontent that aligns with individual user preferences has garnered widespread\nattention. Personalized Retrieval-Augmented Generation (RAG), which retrieves\nrelevant documents from the user's history to reflect their preferences and\nenhance LLM generation, is one commonly used approach for personalization.\nHowever, existing personalized RAG methods do not consider that the histories\nof similar users can also assist in personalized generation for the current\nuser, meaning that collaborative information between users can also benefit\npersonalized generation. Inspired by the application of collaborative filtering\nin recommender systems, we propose a method called CFRAG, which adapts\nCollaborative Filtering to RAG for personalized text generation. However, this\npresents two challenges: (1)~how to incorporate collaborative information\nwithout explicit user similarity labels? (2)~how to retrieve documents that\nsupport personalized LLM generation? For Challenge 1, we use contrastive\nlearning to train user embeddings to retrieve similar users and introduce\ncollaborative information. For Challenge 2, we design a personalized retriever\nand reranker to retrieve the top-$k$ documents from these users' histories. We\ntake into account the user's preference during retrieval and reranking. Then we\nleverage feedback from the LLM to fine-tune the personalized retriever and\nreranker, enabling them to retrieve documents that meet the personalized\ngeneration needs of the LLM. Experimental results on the Language Model\nPersonalization (LaMP) benchmark validate the effectiveness of CFRAG. Further\nanalysis confirms the importance of incorporating collaborative information.","main_category":"cs.IR","categories":"cs.IR,cs.CL","published":"2025-04-08T07:03:36Z"}
{"aid":"http://arxiv.org/abs/2504.05742v1","title":"Linear-space LCS enumeration with quadratic-time delay for two strings","summary":"Suppose we want to seek the longest common subsequences (LCSs) of two strings\nas informative patterns that explain the relationship between the strings. The\ndynamic programming algorithm gives us a table from which all LCSs can be\nextracted by traceback. However, the need for quadratic space to hold this\ntable can be an obstacle when dealing with long strings. A question that\nnaturally arises in this situation would be whether it is possible to\nexhaustively search for all LCSs one by one in a time-efficient manner using\nonly a space linear in the LCS length, where we treat read-only memory for\nstoring the strings as excluded from the space consumed. As a part of the\nanswer to this question, we propose an $O(L)$-space algorithm that outputs all\ndistinct LCSs of the strings one by one each in $O(n^2)$ time, where the\nstrings are both of length $n$ and $L$ is the LCS length of the strings.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-08T07:17:55Z"}
{"aid":"http://arxiv.org/abs/2504.05758v1","title":"Addressing Class Imbalance with Probabilistic Graphical Models and\n  Variational Inference","summary":"This study proposes a method for imbalanced data classification based on deep\nprobabilistic graphical models (DPGMs) to solve the problem that traditional\nmethods have insufficient learning ability for minority class samples. To\naddress the classification bias caused by class imbalance, we introduce\nvariational inference optimization probability modeling, which enables the\nmodel to adaptively adjust the representation ability of minority classes and\ncombines the class-aware weight adjustment strategy to enhance the classifier's\nsensitivity to minority classes. In addition, we combine the adversarial\nlearning mechanism to generate minority class samples in the latent space so\nthat the model can better characterize the category boundary in the\nhigh-dimensional feature space. The experiment is evaluated on the Kaggle\n\"Credit Card Fraud Detection\" dataset and compared with a variety of advanced\nimbalanced classification methods (such as GAN-based sampling, BRF,\nXGBoost-Cost Sensitive, SAAD, HAN). The results show that the method in this\nstudy has achieved the best performance in AUC, Precision, Recall and F1-score\nindicators, effectively improving the recognition rate of minority classes and\nreducing the false alarm rate. This method can be widely used in imbalanced\nclassification tasks such as financial fraud detection, medical diagnosis, and\nanomaly detection, providing a new solution for related research.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-08T07:38:30Z"}
{"aid":"http://arxiv.org/abs/2504.05786v1","title":"How to Enable LLM with 3D Capacity? A Survey of Spatial Reasoning in LLM","summary":"3D spatial understanding is essential in real-world applications such as\nrobotics, autonomous vehicles, virtual reality, and medical imaging. Recently,\nLarge Language Models (LLMs), having demonstrated remarkable success across\nvarious domains, have been leveraged to enhance 3D understanding tasks, showing\npotential to surpass traditional computer vision methods. In this survey, we\npresent a comprehensive review of methods integrating LLMs with 3D spatial\nunderstanding. We propose a taxonomy that categorizes existing methods into\nthree branches: image-based methods deriving 3D understanding from 2D visual\ndata, point cloud-based methods working directly with 3D representations, and\nhybrid modality-based methods combining multiple data streams. We\nsystematically review representative methods along these categories, covering\ndata representations, architectural modifications, and training strategies that\nbridge textual and 3D modalities. Finally, we discuss current limitations,\nincluding dataset scarcity and computational challenges, while highlighting\npromising research directions in spatial perception, multi-modal fusion, and\nreal-world applications.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-08T08:11:39Z"}
{"aid":"http://arxiv.org/abs/2504.05788v1","title":"Space-averaged non-equilibrium Green's function approach for quantum\n  transport in 3D","summary":"The non-equilibrium Green's function (NEGF) approach offers a practical\nframework for simulating various phenomena in mesoscopic systems. As the\ndimension of electronic devices shrinks to just a few nanometers, the need for\nnew effective-mass based 3D implementations of NEGF has become increasingly\napparent. This work extends our previous Finite-Volume implementation --\noriginally developed for the self-consistent solution of the Schr\\\"odinger and\nPoisson equations in 2D -- into a full 3D NEGF framework. Our implementation\nbegins with exploring a few problems with the common textbook Finite Difference\nimplementations of NEGF. We then concisely demonstrate how Finite-Volume\ndiscretization addresses few key implementation challenges. Importantly, we\nexplain how this type of discretization enables evaluating the self-energies,\nwhich account for the effects of reservoirs. The potential applications of this\nnew method are illustrated through two examples. We anticipate that this\nimplementation will be broadly applicable to open quantum systems, especially\nin cases where a fully three-dimensional domain is essential.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-08T08:13:36Z"}
{"aid":"http://arxiv.org/abs/2504.05828v1","title":"Capacity Region for Covert Secret Key Generation over Multiple Access\n  Channels","summary":"We study covert secret key generation over a binary-input two-user multiple\naccess channel with one-way public discussion and derive bounds on the capacity\nregion. Specifically, in this problem, there are three legitimate parties:\nAlice, Bob and Charlie. The goal is to allow Charlie to generate a secret key\nwith Alice and another secret key with Bob, reliably, secretly and covertly.\nReliability ensures that the key generated by Alice and Charlie is the same and\nthe key generated by Bob and Charlie is the same. Secrecy ensures that the\nsecret keys generated are only known to specific legitimate parties. Covertness\nensures that the key generation process is undetectable by a warden Willie. As\na corollary of our result, we establish bounds on the capacity region of\nwiretap secret key generation without the covertness constraint and discuss the\nimpact of covertness. Our results generalize the point-to-point result of\nTahmasbi and Bloch (TIFS 2020) to the setting of multiterminal communication.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-08T09:08:45Z"}
{"aid":"http://arxiv.org/abs/2504.05854v1","title":"50 Dra: Am-type twins with additional variability in a non-eclipsing\n  system","summary":"The interplay between radiative diffusion, rotation, convection, and\nmagnetism in metallic-line chemically peculiar stars is still not fully\nunderstood. Recently, evidence has emerged that these effects can work\ntogether. Our goal is to study the bright binary system 50 Dra, describe its\norbit and components, and study additional variability. We conducted our\nanalysis using TESS short-cadence data and new high-resolution spectroscopic\nobservations. We disentangled the spectra using Korel and performed spectral\nsynthesis with Atlas9 and Synthe codes. The system was modelled using Korel and\nPhoebe2.4. We also employed SED fitting in Ariadne and isochrone fitting using\nParam1.5 codes. Our findings indicate that the non-eclipsing system (with an\ninclination of 49.9(8) deg) 50 Dra, displaying ellipsoidal brightness\nvariations, consists of two nearly equal A-type stars with masses of\n$M_{1}=2.08(8)$ and $M_{2}=1.97(8)$ M$_{\\odot}$ and temperatures of 9800(100)\nand 9200(200) K, respectively. Our analysis also suggests that the system, with\nan orbital period of $P_{\\rm orb}=4.117719(2)$ days, is tidally relaxed with a\ncircular orbit and synchronous rotation of the components. Furthermore, we\ndiscovered that both stars are metallic-line Am chemically peculiar stars with\nan underabundance of Sc and an overabundance of iron-peak and rare-earth\nelements. We identified additional variations with slightly higher frequency\nthan the rotational frequency of the components that we interpret as prograde\ng-mode pulsations. The system 50 Dra exhibits numerous exciting phenomena that\nco-exist together and may have an impact on our understanding of chemical\npeculiarity and pulsations.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-08T09:32:49Z"}
{"aid":"http://arxiv.org/abs/2504.05877v1","title":"Threshold-less and Flexibly Tunable Frequency Comb via Floquet\n  Engineering","summary":"Frequency combs have revolutionized communication, metrology and\nspectroscopy. Numerous efforts have been dedicated to developing integrated\ncombs, predominantly relying on Pockels or Kerr mechanisms. In this work, we\npropose and demonstrate a new type of frequency comb-Floquet cavity frequency\ncomb-that does not rely on intrinsic non-linearity. By periodically modulating\nthe resonance frequency of a cavity, a giant-mode cavity with multiple equally\nspaced frequency components is created. The pump tone interacts with the\npre-modulated cavity, generating the output frequency comb. This approach\noffers a flexible tuning range and operates in a threshold-less manner,\nobviating the need to overcome nonlinear initiation thresholds. We implement\nthis on a microwave cavity optomechanical system on-chip. Compared to Kerr\noptomechanical combs, this approach efficiently generates comb with pump signal\nfar from the cavity's intrinsic frequency, and the power required for detection\nis reduced by approximately a factor of ($10^6$), providing a promising\nplatform for frequency comb generation.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall,physics.optics","published":"2025-04-08T10:05:20Z"}
{"aid":"http://arxiv.org/abs/2504.05902v1","title":"Defending Deep Neural Networks against Backdoor Attacks via Module\n  Switching","summary":"The exponential increase in the parameters of Deep Neural Networks (DNNs) has\nsignificantly raised the cost of independent training, particularly for\nresource-constrained entities. As a result, there is a growing reliance on\nopen-source models. However, the opacity of training processes exacerbates\nsecurity risks, making these models more vulnerable to malicious threats, such\nas backdoor attacks, while simultaneously complicating defense mechanisms.\nMerging homogeneous models has gained attention as a cost-effective\npost-training defense. However, we notice that existing strategies, such as\nweight averaging, only partially mitigate the influence of poisoned parameters\nand remain ineffective in disrupting the pervasive spurious correlations\nembedded across model parameters. We propose a novel module-switching strategy\nto break such spurious correlations within the model's propagation path. By\nleveraging evolutionary algorithms to optimize fusion strategies, we validate\nour approach against backdoor attacks targeting text and vision domains. Our\nmethod achieves effective backdoor mitigation even when incorporating a couple\nof compromised models, e.g., reducing the average attack success rate (ASR) to\n22% compared to 31.9% with the best-performing baseline on SST-2.","main_category":"cs.CR","categories":"cs.CR,cs.CL","published":"2025-04-08T11:01:07Z"}
{"aid":"http://arxiv.org/abs/2504.05907v1","title":"A Method for Generating Connected Erdos-Renyi Random Graphs","summary":"We propose a novel and exact algorithm for generating connected Erdos-Renyi\nrandom graphs $G(n, p)$. Our approach exploits a link between the distribution\nof exploration process trajectories and an inhomogeneous random walk. In\ncontrast to existing methods, our approach guarantees the correct distribution\nunder the connectivity condition and achieves $O(n^2)$ runtime in the sparse\ncase $p = c/n$. Furthermore, we show that our method can be extended to\nuniformly generate connected graphs $G(n, m)$ via an acceptance-rejection\nprocedure.","main_category":"cs.DS","categories":"cs.DS,cs.DM,cs.IT,math.CO,math.IT,math.PR","published":"2025-04-08T11:06:01Z"}
{"aid":"http://arxiv.org/abs/2504.05919v1","title":"Measurement of high-mass $t\\bar{t}\\ell^{+}\\ell^{-}$ production and\n  lepton flavour universality-inspired effective field theory interpretations\n  at $\\sqrt{s}=13$ TeV with the ATLAS detector","summary":"Measurements of $t\\bar{t}\\ell^{+}\\ell^{-}$ production in the region of high\ndilepton invariant mass with effective field theory (EFT) interpretations are\npresented. They are performed using final states with three isolated leptons\n(electrons or muons) and are based on $\\sqrt{s} = 13$ TeV proton-proton\ncollision data with an integrated luminosity of $140\\,\\mathrm{fb}^{-1}$,\nrecorded from 2015 to 2018 with the ATLAS detector at the Large Hadron\nCollider. Measurements of the $t\\bar{t}\\ell^{+}\\ell^{-}$ signal strength and\ncross-section upper-limits are performed inclusively in lepton flavour and\nseparately for electrons and muons. The study also aims to probe anomalous\nfour-fermion interactions including to test for possible lepton flavor\nuniversality violation. No significant deviations from the Standard Model\npredictions are observed and the measurements are interpreted through the EFT\nformalism to provide new constraints on relevant operators.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-08T11:18:22Z"}
{"aid":"http://arxiv.org/abs/2504.05927v1","title":"A nongraphical obstacle problem for elastic curves","summary":"We study an obstacle problem for the length-penalized elastic bending energy\nfor open planar curves pinned at the boundary. We first consider the case\nwithout length penalization and investigate the role of global minimizers among\ngraph curves in our minimization problem for planar curves. In addition, for\nlarge values of the length-penalization parameter $\\lambda>0$, we expose an\nexplicit threshold parameter above which minimizers touch the obstacle,\nregardless of its shape. On contrary, for small values of $\\lambda>0$ we show\nthat the minimizers do not touch the obstacle, and they are given by an\nexplicit elastica.","main_category":"math.AP","categories":"math.AP,math.DG","published":"2025-04-08T11:33:14Z"}
{"aid":"http://arxiv.org/abs/2504.05979v1","title":"An Empirical Study of GPT-4o Image Generation Capabilities","summary":"The landscape of image generation has rapidly evolved, from early GAN-based\napproaches to diffusion models and, most recently, to unified generative\narchitectures that seek to bridge understanding and generation tasks. Recent\nadvances, especially the GPT-4o, have demonstrated the feasibility of\nhigh-fidelity multimodal generation, their architectural design remains\nmysterious and unpublished. This prompts the question of whether image and text\ngeneration have already been successfully integrated into a unified framework\nfor those methods. In this work, we conduct an empirical study of GPT-4o's\nimage generation capabilities, benchmarking it against leading open-source and\ncommercial models. Our evaluation covers four main categories, including\ntext-to-image, image-to-image, image-to-3D, and image-to-X generation, with\nmore than 20 tasks. Our analysis highlights the strengths and limitations of\nGPT-4o under various settings, and situates it within the broader evolution of\ngenerative modeling. Through this investigation, we identify promising\ndirections for future unified generative models, emphasizing the role of\narchitectural design and data scaling.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T12:34:36Z"}
{"aid":"http://arxiv.org/abs/2504.06025v1","title":"Geometries with trialities arising from linear spaces","summary":"A triality is a sort of super-symmetry that exchanges the types of the\nelements of an incidence geometry in cycles of length three. Although\ngeometries with trialities exhibit fascinating behaviors, their construction is\nchallenging, making them rare in the literature. To understand trialities more\ndeeply, it is crucial to have a wide variety of examples at hand. In this\narticle, we introduce a general method for constructing various rank-three\nincidence systems with trialities. Specifically, for any rank two incidence\nsystem $\\Gamma$, we define its triangle complex $\\Delta(\\Gamma)$, a rank three\nincidence system whose elements consist of three copies of the flags (pairs of\nincident elements) of $\\Gamma$. This triangle complex always admits a triality\nthat cyclically permutes the three copies. We then explore in detail the\nproperties of the triangle complex when $\\Gamma$ is a linear space, including\nflag-transitivity, the existence of dualities, and connectivity properties. As\na consequence of our work, this construction yields the first infinite family\nof thick, flag-transitive and residually connected geometries with trialities\nbut no dualities.","main_category":"math.CO","categories":"math.CO,math.GR","published":"2025-04-08T13:28:55Z"}
{"aid":"http://arxiv.org/abs/2504.06046v1","title":"Rhythmic neuromorphic control of a pendulum: A hybrid systems analysis","summary":"Neuromorphic engineering is an emerging research domain that aims to realize\nimportant implementation advantages that brain-inspired technologies can offer\nover classical digital technologies, including energy efficiency, adaptability,\nand robustness. For the field of systems and control, neuromorphic controllers\ncould potentially bring many benefits, but their advancement is hampered by\nlack of systematic analysis and design tools. In this paper, the objective is\nto show that hybrid systems methods can aid in filling this gap. We do this by\nformally analyzing rhythmic neuromorphic control of a pendulum system, which\nwas recently proposed as a prototypical setup. The neuromorphic controller\ngenerates spikes, which we model as a Dirac delta pulse, whenever the pendulum\nangular position crosses its resting position, with the goal of inducing a\nstable limit cycle. This leads to modeling the closed-loop system as a hybrid\ndynamical system, which in between spikes evolves in open loop and where the\njumps correspond to the spiking control actions. Exploiting the hybrid system\nmodel, we formally prove the existence, uniqueness, and a stability property of\nthe hybrid limit cycle for the closed-loop system. Numerical simulations\nillustrate our approach. We finally elaborate on a possible spiking adaptation\nmechanism on the pulse amplitude to generate a hybrid limit cycle of a desired\nmaximal angular amplitude.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-08T13:46:03Z"}
{"aid":"http://arxiv.org/abs/2504.06058v1","title":"Symbol Frequencies in Surjective Cellular Automata","summary":"We study the behavior of probability measures under iteration of a surjective\ncellular automaton. We solve the following question in the negative: if the\ninitial measure is ergodic and has full support, do all weak-* limit points of\nthe sequence of measures have full support as well? The initial measure of our\nsolution is not a product measure, and in this case the question remains open.\nTo this end, we present a tool for studying the frequencies of symbols in\npreimages of surjective cellular automata, and prove some basic results about\nit. % do we know they are nontrivial? :P However, we show that by itself it is\nnot enough to solve the stricter question in the positive.","main_category":"math.DS","categories":"math.DS","published":"2025-04-08T14:01:13Z"}
{"aid":"http://arxiv.org/abs/2504.06091v1","title":"Real-Time LaCAM","summary":"The vast majority of Multi-Agent Path Finding (MAPF) methods with\ncompleteness guarantees require planning full horizon paths. However, planning\nfull horizon paths can take too long and be impractical in real-world\napplications. Instead, real-time planning and execution, which only allows the\nplanner a finite amount of time before executing and replanning, is more\npractical for real world multi-agent systems. Several methods utilize real-time\nplanning schemes but none are provably complete, which leads to livelock or\ndeadlock. Our main contribution is to show the first Real-Time MAPF method with\nprovable completeness guarantees. We do this by leveraging LaCAM (Okumura 2023)\nin an incremental fashion. Our results show how we can iteratively plan for\ncongested environments with a cutoff time of milliseconds while still\nmaintaining the same success rate as full horizon LaCAM. We also show how it\ncan be used with a single-step learned MAPF policy. The proposed Real-Time\nLaCAM also provides us with a general mechanism for using iterative constraints\nfor completeness in future real-time MAPF algorithms.","main_category":"cs.MA","categories":"cs.MA,cs.AI,cs.RO","published":"2025-04-08T14:31:05Z"}
{"aid":"http://arxiv.org/abs/2504.06107v1","title":"Doubly-charmed hexaquarks in the diquark picture","summary":"We investigate doubly-charmed hexaquark states within the diquark picture, by\nemploying the constituent quark model and the quark-interchange model as our\ntheoretical frameworks. Using the Gaussian expansion method, we systematically\nstudy these states, with calculating various properties such as mass spectra,\ninternal contributions of each Hamiltonian component, root-mean-square radii,\nand two-body strong decay widths. Our analysis of the mass spectra reveals no\nstable state in this system. Furthermore, the root-mean-square radii suggest\nthat the doubly-charmed hexaquark states exhibit a compact configuration. By\nexamining the decay widths, we identify potentially detectable states and their\nprimary decay channels within each subsystem. Despite the large decay phase\nspace, we still find narrow states with total widths of less than 10 MeV. This\nstudy provides a theoretical foundation for understanding the structures and\ninteractions of doubly-charmed hexaquark states and offers valuable insights\nfor future experimental searches.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-08T14:51:40Z"}
{"aid":"http://arxiv.org/abs/2504.06142v1","title":"Unification of Conformal and Fuzzy Gravities with Internal Interactions\n  resulting in SO(10) and a Possible Probe through Stochastic Gravitational\n  Wave Background","summary":"The unification of conformal and fuzzy gravities with internal interactions\nis based on the facts that i) the tangent group of a curved manifold and the\nmanifold itself do not necessarily have the same dimensions and ii) both\ngravitational theories considered here have been formulated in a gauge\ntheoretic way. We review the gauge-theoretic approach of gravities, commenting\nin particular on their diffeomorphism invariance, and the construction of\nconformal and noncommutative (fuzzy) gravity using the gauge-theoretic\nframework. Based on an extension of the four-dimensional tangent group,\nunification of both gravities with the internal interactions is achieved. Both\nunified schemes are examined at 1-loop level considering suitable spontaneous\nsymmetry breakings to a SO(10) grand unified theory and consequently down to\nthe Standard Model of particle physics through four specific spontaneous\nbreaking channels. Each channel is examined against proton lifetime\nexperimental bounds and its observation potential through gravitational signal\nfrom cosmic strings production is discussed.","main_category":"hep-th","categories":"hep-th","published":"2025-04-08T15:38:33Z"}
{"aid":"http://arxiv.org/abs/2504.06160v1","title":"Navigating the Rabbit Hole: Emergent Biases in LLM-Generated Attack\n  Narratives Targeting Mental Health Groups","summary":"Large Language Models (LLMs) have been shown to demonstrate imbalanced biases\nagainst certain groups. However, the study of unprovoked targeted attacks by\nLLMs towards at-risk populations remains underexplored. Our paper presents\nthree novel contributions: (1) the explicit evaluation of LLM-generated attacks\non highly vulnerable mental health groups; (2) a network-based framework to\nstudy the propagation of relative biases; and (3) an assessment of the relative\ndegree of stigmatization that emerges from these attacks. Our analysis of a\nrecently released large-scale bias audit dataset reveals that mental health\nentities occupy central positions within attack narrative networks, as revealed\nby a significantly higher mean centrality of closeness (p-value = 4.06e-10) and\ndense clustering (Gini coefficient = 0.7). Drawing from sociological\nfoundations of stigmatization theory, our stigmatization analysis indicates\nincreased labeling components for mental health disorder-related targets\nrelative to initial targets in generation chains. Taken together, these\ninsights shed light on the structural predilections of large language models to\nheighten harmful discourse and highlight the need for suitable approaches for\nmitigation.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.CY,cs.LG,cs.SI","published":"2025-04-08T15:56:57Z"}
{"aid":"http://arxiv.org/abs/2504.06163v1","title":"Action Valuation in Sports: A Survey","summary":"Action Valuation (AV) has emerged as a key topic in Sports Analytics,\noffering valuable insights by assigning scores to individual actions based on\ntheir contribution to desired outcomes. Despite a few surveys addressing\nrelated concepts such as Player Valuation, there is no comprehensive review\ndedicated to an in-depth analysis of AV across different sports. In this\nsurvey, we introduce a taxonomy with nine dimensions related to the AV task,\nencompassing data, methodological approaches, evaluation techniques, and\npractical applications. Through this analysis, we aim to identify the essential\ncharacteristics of effective AV methods, highlight existing gaps in research,\nand propose future directions for advancing the field.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T15:59:19Z"}
{"aid":"http://arxiv.org/abs/2504.06176v1","title":"A Self-Supervised Framework for Space Object Behaviour Characterisation","summary":"Foundation Models, pre-trained on large unlabelled datasets before\ntask-specific fine-tuning, are increasingly being applied to specialised\ndomains. Recent examples include ClimaX for climate and Clay for satellite\nEarth observation, but a Foundation Model for Space Object Behavioural Analysis\nhas not yet been developed. As orbital populations grow, automated methods for\ncharacterising space object behaviour are crucial for space safety. We present\na Space Safety and Sustainability Foundation Model focusing on space object\nbehavioural analysis using light curves (LCs). We implemented a\nPerceiver-Variational Autoencoder (VAE) architecture, pre-trained with\nself-supervised reconstruction and masked reconstruction on 227,000 LCs from\nthe MMT-9 observatory. The VAE enables anomaly detection, motion prediction,\nand LC generation. We fine-tuned the model for anomaly detection & motion\nprediction using two independent LC simulators (CASSANDRA and GRIAL\nrespectively), using CAD models of boxwing, Sentinel-3, SMOS, and Starlink\nplatforms. Our pre-trained model achieved a reconstruction error of 0.01%,\nidentifying potentially anomalous light curves through reconstruction\ndifficulty. After fine-tuning, the model scored 88% and 82% accuracy, with 0.90\nand 0.95 ROC AUC scores respectively in both anomaly detection and motion mode\nprediction (sun-pointing, spin, etc.). Analysis of high-confidence anomaly\npredictions on real data revealed distinct patterns including characteristic\nobject profiles and satellite glinting. Here, we demonstrate how\nself-supervised learning can simultaneously enable anomaly detection, motion\nprediction, and synthetic data generation from rich representations learned in\npre-training. Our work therefore supports space safety and sustainability\nthrough automated monitoring and simulation capabilities.","main_category":"cs.LG","categories":"cs.LG,cs.AI,physics.space-ph","published":"2025-04-08T16:19:19Z"}
{"aid":"http://arxiv.org/abs/2504.06185v1","title":"WoundAmbit: Bridging State-of-the-Art Semantic Segmentation and\n  Real-World Wound Care","summary":"Chronic wounds affect a large population, particularly the elderly and\ndiabetic patients, who often exhibit limited mobility and co-existing health\nconditions. Automated wound monitoring via mobile image capture can reduce\nin-person physician visits by enabling remote tracking of wound size. Semantic\nsegmentation is key to this process, yet wound segmentation remains\nunderrepresented in medical imaging research. To address this, we benchmark\nstate-of-the-art deep learning models from general-purpose vision, medical\nimaging, and top methods from public wound challenges. For fair comparison, we\nstandardize training, data augmentation, and evaluation, conducting\ncross-validationto minimize partitioning bias. We also assess real-world\ndeployment aspects, including generalization to an out-of-distribution wound\ndataset, computational efficiency, and interpretability. Additionally, we\npropose a reference object-based approach to convert AI-generated masks into\nclinically relevant wound size estimates, and evaluate this, along with mask\nquality, for the best models based on physician assessments. Overall, the\ntransformer-based TransNeXt showed the highest levels of generalizability.\nDespite variations in inference times, all models processed at least one image\nper second on the CPU, which is deemed adequate for the intended application.\nInterpretability analysis typically revealed prominent activations in wound\nregions, emphasizing focus on clinically relevant features. Expert evaluation\nshowed high mask approval for all analyzed models, with VWFormer and ConvNeXtS\nbackbone performing the best. Size retrieval accuracy was similar across\nmodels, and predictions closely matched expert annotations. Finally, we\ndemonstrate how our AI-driven wound size estimation framework, WoundAmbit, can\nbe integrated into a custom telehealth system. Our code will be made available\non GitHub upon publication.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-08T16:25:59Z"}
{"aid":"http://arxiv.org/abs/2504.06196v1","title":"TxGemma: Efficient and Agentic LLMs for Therapeutics","summary":"Therapeutic development is a costly and high-risk endeavor that is often\nplagued by high failure rates. To address this, we introduce TxGemma, a suite\nof efficient, generalist large language models (LLMs) capable of therapeutic\nproperty prediction as well as interactive reasoning and explainability. Unlike\ntask-specific models, TxGemma synthesizes information from diverse sources,\nenabling broad application across the therapeutic development pipeline. The\nsuite includes 2B, 9B, and 27B parameter models, fine-tuned from Gemma-2 on a\ncomprehensive dataset of small molecules, proteins, nucleic acids, diseases,\nand cell lines. Across 66 therapeutic development tasks, TxGemma achieved\nsuperior or comparable performance to the state-of-the-art generalist model on\n64 (superior on 45), and against state-of-the-art specialist models on 50\n(superior on 26). Fine-tuning TxGemma models on therapeutic downstream tasks,\nsuch as clinical trial adverse event prediction, requires less training data\nthan fine-tuning base LLMs, making TxGemma suitable for data-limited\napplications. Beyond these predictive capabilities, TxGemma features\nconversational models that bridge the gap between general LLMs and specialized\nproperty predictors. These allow scientists to interact in natural language,\nprovide mechanistic reasoning for predictions based on molecular structure, and\nengage in scientific discussions. Building on this, we further introduce\nAgentic-Tx, a generalist therapeutic agentic system powered by Gemini 2.5 that\nreasons, acts, manages diverse workflows, and acquires external domain\nknowledge. Agentic-Tx surpasses prior leading models on the Humanity's Last\nExam benchmark (Chemistry & Biology) with 52.3% relative improvement over\no3-mini (high) and 26.7% over o3-mini (high) on GPQA (Chemistry) and excels\nwith improvements of 6.3% (ChemBench-Preference) and 2.4% (ChemBench-Mini) over\no3-mini (high).","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.LG","published":"2025-04-08T16:39:02Z"}
{"aid":"http://arxiv.org/abs/2504.06252v1","title":"A systematic method to identify runaways from star clusters produced\n  from single-binary interactions: A case study of M67","summary":"One hypothesis for runaway stars (RSs) is that they are ejected from star\nclusters with high velocities relative to the cluster center-of-mass motion.\nThere are two competing mechanisms for their production: supernova-based\nejections in binaries, where one companion explodes, leaves no remnant, and\nlaunches the other companion at the instantaneous orbital velocity, and the\ndisintegration of triples (or higher-order multiples), which produces a\nrecoiled runaway binary (RB) and an RS. We search for RS candidates using data\nfrom the Gaia DR3 survey with a focus on triple disintegration since in this\ncase the product is always a binary and a single star that should be moving in\nopposite directions. We created a systematic methodology to look for candidate\nRS-RB runaway pairs produced from the disintegration of bound three-body\nsystems formed from single-binary interactions based on momentum conservation\nand causality. The method we use is general and can be applied to any cluster\nwith a 5D kinematic data set. We used our criteria to search for these pairs in\na 150 pc circular field of view surrounding the open cluster M67, which we used\nas a benchmark cluster to test the robustness of our method. Our results reveal\nonly one RS-RB pair that is consistent with all of our selection criteria out\nof an initial sample of $10^8$ pairs.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-08T17:57:10Z"}
{"aid":"http://arxiv.org/abs/2504.06264v1","title":"D^2USt3R: Enhancing 3D Reconstruction with 4D Pointmaps for Dynamic\n  Scenes","summary":"We address the task of 3D reconstruction in dynamic scenes, where object\nmotions degrade the quality of previous 3D pointmap regression methods, such as\nDUSt3R, originally designed for static 3D scene reconstruction. Although these\nmethods provide an elegant and powerful solution in static settings, they\nstruggle in the presence of dynamic motions that disrupt alignment based solely\non camera poses. To overcome this, we propose D^2USt3R that regresses 4D\npointmaps that simultaneiously capture both static and dynamic 3D scene\ngeometry in a feed-forward manner. By explicitly incorporating both spatial and\ntemporal aspects, our approach successfully encapsulates spatio-temporal dense\ncorrespondence to the proposed 4D pointmaps, enhancing downstream tasks.\nExtensive experimental evaluations demonstrate that our proposed approach\nconsistently achieves superior reconstruction performance across various\ndatasets featuring complex motions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T17:59:50Z"}
{"aid":"http://arxiv.org/abs/2504.06547v1","title":"Extremal metrics involving scalar curvature","summary":"We investigate extremal metrics at which various types of rigidity theorems\ninvolving scalar curvatures hold. The rigidity we discuss here is related to\nthe rigidity theorems presented by Mario Listing in his previous preprint. More\nspecifically, we give some sufficient conditions for metrics not to be rigid in\nthis sense. We also give several examples of Riemannian manifolds that satisfy\nsuch sufficient conditions.","main_category":"math.DG","categories":"math.DG","published":"2025-04-09T03:04:52Z"}
{"aid":"http://arxiv.org/abs/2504.06568v1","title":"Relaxed Weak Accelerated Proximal Gradient Method: a Unified Framework\n  for Nesterov's Accelerations","summary":"This paper is devoted to the study of accelerated proximal gradient methods\nwhere the sequence that controls the momentum term doesn't follow Nesterov's\nrule. We propose a relaxed weak accelerated proximal gradient (R-WAPG) method,\na generic algorithm that unifies the convergence results for strongly convex\nand convex problems where the extrapolation constant is characterized by a\nsequence that is much weaker than Nesterov's rule. Our R-WAPG provides a\nunified framework for several notable Euclidean variants of FISTA and verifies\ntheir convergences. In addition, we provide the convergence rate of strongly\nconvex objective with a constant momentum term. Without using the idea of\nrestarting, we also reformulate R-WAPG as ``Free R-WAPG\" so that it doesn't\nrequire any parameter. Explorative numerical experiments were conducted to show\nits competitive advantages.","main_category":"math.OC","categories":"math.OC","published":"2025-04-09T04:05:54Z"}
{"aid":"http://arxiv.org/abs/2504.06571v1","title":"Double shape quantum phase transitions in the SU3-IBM (I) new\n  $$-soft phase and the shape phase transition from the new $$-soft\n  phase to the prolate shape","summary":"Shape quantum phase transition is an important topic in nuclear structure. In\nthis paper, we begin to study the shape quantum phase transition in the\nSU3-IBM. In this new proposed model, spherical-like spectra was found to\nresolve the spherical nucleus puzzle, which is a new $\\gamma$-soft rotational\nmode. In this paper, the shape phase transition along the new $\\gamma$-soft\nline is first discussed, and then the neighbouring case at the prolate side is\nalso studied. We find that double shape phase transitions occur along a single\nparameter path. The new $\\gamma$-softness is really a shape phase and the shape\nphase transition from the new $\\gamma$-soft phase to the prolate shape is\nfound. The experimental support is also found and $^{108}$Pd is the critical\nnucleus.","main_category":"nucl-th","categories":"nucl-th,nucl-ex","published":"2025-04-09T04:15:40Z"}
{"aid":"http://arxiv.org/abs/2504.06574v1","title":"Uncovering influence of football players' behaviour on team performance\n  in ball possession through dynamical modelling","summary":"A quest for uncovering influence of behaviour on team performance involves\nunderstanding individual behaviour, interactions with others and environment,\nvariations across groups, and effects of interventions. Although insights into\neach of these areas have accumulated in sports science literature on football,\nit remains unclear how one can enhance team performance. We analyse influence\nof football players' behaviour on team performance in three-versus-one ball\npossession game by constructing and analysing a dynamical model. We developed a\nmodel for the motion of the players and the ball, which mathematically\nrepresented our hypotheses on players' behaviour and interactions. The model's\nplausibility was examined by comparing simulated outcomes with our experimental\nresult. Possible influences of interventions were analysed through sensitivity\nanalysis, where causal effects of several aspects of behaviour such as pass\nspeed and accuracy were found. Our research highlights the potential of\ndynamical modelling for uncovering influence of behaviour on team\neffectiveness.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-09T04:29:33Z"}
{"aid":"http://arxiv.org/abs/2504.06577v1","title":"Bypassing Safety Guardrails in LLMs Using Humor","summary":"In this paper, we show it is possible to bypass the safety guardrails of\nlarge language models (LLMs) through a humorous prompt including the unsafe\nrequest. In particular, our method does not edit the unsafe request and follows\na fixed template -- it is simple to implement and does not need additional LLMs\nto craft prompts. Extensive experiments show the effectiveness of our method\nacross different LLMs. We also show that both removing and adding more humor to\nour method can reduce its effectiveness -- excessive humor possibly distracts\nthe LLM from fulfilling its unsafe request. Thus, we argue that LLM\njailbreaking occurs when there is a proper balance between focus on the unsafe\nrequest and presence of humor.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-09T04:58:14Z"}
{"aid":"http://arxiv.org/abs/2504.06597v1","title":"Dynamics of two Interacting Drops in a Microfluidic Confinement under\n  imposed Temperature Gradient","summary":"Thermocapillary motion is widespread in both natural and engineering\napplications. A tiny drop of one liquid, suspended within another, may be set\ninto motion aligned with an imposed thermal gradient, as influenced by\nthermocapillary action stemming from the gradients in interfacial tension due\nto the local variations in temperature. In real-world situations, however, such\ndrops do not remain in isolation, as they interact with their neighboring\nentities, including other drops in proximity as well as a nearby solid\nboundary, setting up a complex interplay between the confinement-mediated\ninteractions and the three-dimensional nature of the droplet dynamics. In this\nstudy, we present numerical solutions for the migration dynamics of a tightly\nconfined drop couple, incorporating deformable interfaces, film flow, and\nMarangoni effects in the presence of dynamically evolving thermocapillary\nstresses induced by an imposed uniform temperature gradient. Unlike prior\ninvestigations, our work highlights the influence of the confinement towards\norchestrating non-trivial features of drop migration, as dictated by an\nintricate coupling of the thermal and flow fields amidst the interferences of\nthe domain boundaries. The study reveals that hydrodynamic interactions\nresulting from a juxtaposition of these influences deform the drops in a unique\nmanner as compared to the characteristics evidenced by previously reported\nstudies, causing a distortion of the local thermal fields around them. This, in\nturn, leads to changes in the local thermocapillary stress, affecting the local\nshear gradient in a manner that alters the local flow field in accordance with\nensuring the interfacial stress balance.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-09T05:48:53Z"}
{"aid":"http://arxiv.org/abs/2504.06626v1","title":"Localization of deformation in the central hub of hub-and-spoke kirigami","summary":"A recent approach to the design of flexible electronic devices consists of\ncutting a two-dimensional sheet to form a central hub connected to several\ntapered `spokes', resembling the hub-and-spoke of a bicycle wheel. When\nradially compressed, the resulting cut sheet buckles out-of-plane forming a\nstructure whose three-dimensional shape can be chosen by designing the tapering\nof the spokes. While the deformation of the spokes in this `hub-and-spoke'\nkirigami are approximately cylindrical (i.e.~zero Gaussian curvature and hence\nsmall elastic strain), this is not the case in the central hub. The central hub\nis deformed radially because of continuity with the spokes but, because of its\nown circular symmetry, it must develop Gaussian curvature, and hence strain. In\nthis article we quantify this strain, focussing in particular on its magnitude\nand its location. We find that the strain is localized in a boundary layer near\nthe edge of the hub region, whose size is controlled by the moment applied on\nit by the deformed spokes. We discuss the implications of our results for\navoiding material failure in flexible-electronic devices.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.mtrl-sci","published":"2025-04-09T07:00:28Z"}
{"aid":"http://arxiv.org/abs/2504.06642v1","title":"Current-Enabled Optical Conductivity of Collective Modes in\n  Unconventional Superconductors","summary":"We theoretically investigate the current-enabled linear optical conductivity\nof collective modes in superconductors with unconventional pairing symmetries.\nAfter deriving general formulas for the optical conductivity of a\nsuperconductor featuring multiple pairing channels and bands using the path\nintegral formalism, we apply these formulas to several models. Using a model of\ncompeting s- and d-wave pairing interactions, we find that several known\ncollective modes generate peaks in the optical conductivity upon injection of a\nsupercurrent. This includes single- and multiband versions of\nBardasis-Schrieffer modes, mixed-symmetry Bardasis-Schrieffer modes, and\nLeggett modes. Using a model for interband p-wave superconductivity with Rashba\nspin-orbit coupling, we find that in such a system Bardasis-Schrieffer modes\nare optically active even without introducing a supercurrent. In a p+ip chiral\nground state, these modes turn out to produce peaks in the longitudinal and\ntransverse optical conductivity. Other collective modes belonging to the chiral\np+ip order parameter turn out to be unaffected by the spin-orbit coupling but\ncontribute to the optical response when a supercurrent is introduced. These\nresults promise new avenues for the observation of collective modes in a\nvariety of superconducting systems, including multiband superconductors and\nsuperconductors that feature multiple pairing channels or multi-component order\nparameters, such as chiral p- or d-wave superconductors.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-09T07:32:42Z"}
{"aid":"http://arxiv.org/abs/2504.06649v1","title":"GRAIN: Multi-Granular and Implicit Information Aggregation Graph Neural\n  Network for Heterophilous Graphs","summary":"Graph neural networks (GNNs) have shown significant success in learning graph\nrepresentations. However, recent studies reveal that GNNs often fail to\noutperform simple MLPs on heterophilous graph tasks, where connected nodes may\ndiffer in features or labels, challenging the homophily assumption. Existing\nmethods addressing this issue often overlook the importance of information\ngranularity and rarely consider implicit relationships between distant nodes.\nTo overcome these limitations, we propose the Granular and Implicit Graph\nNetwork (GRAIN), a novel GNN model specifically designed for heterophilous\ngraphs. GRAIN enhances node embeddings by aggregating multi-view information at\nvarious granularity levels and incorporating implicit data from distant,\nnon-neighboring nodes. This approach effectively integrates local and global\ninformation, resulting in smoother, more accurate node representations. We also\nintroduce an adaptive graph information aggregator that efficiently combines\nmulti-granularity and implicit data, significantly improving node\nrepresentation quality, as shown by experiments on 13 datasets covering varying\nhomophily and heterophily. GRAIN consistently outperforms 12 state-of-the-art\nmodels, excelling on both homophilous and heterophilous graphs.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-09T07:36:44Z"}
{"aid":"http://arxiv.org/abs/2504.06676v1","title":"Ranking alternatives from opinions on criteria","summary":"A primary challenge in collective decision-making is that achieving unanimous\nagreement is difficult, even at the level of criteria. The history of social\nchoice theory illustrates this: numerous normative criteria on voting rules\nhave been proposed; however, disagreements persist regarding which criteria\nshould take precedence. This study addresses the problem of ranking\nalternatives based on the aggregation of opinions over criteria that the\nalternatives might fulfill. Using the opinion aggregation model, we propose a\nnew rule, termed the Intersection Initial Segment (IIS) rule, and characterize\nit using five axioms: neutrality, independence of the worst set, independence\nof the best set, weak intersection very important player, and independence of\nnon-unanimous improvement. We illustrate our approach on a running example\nwhere the objective is to rank voting rules, showing that our opinion\naggregation model is particularly well-suited to this context, and that the IIS\nrule is a counterpart to the method discussed in Nurmi's paper (2015).","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-09T08:31:33Z"}
{"aid":"http://arxiv.org/abs/2504.06710v1","title":"Clustering and novel class recognition: evaluating bioacoustic deep\n  learning feature extractors","summary":"In computational bioacoustics, deep learning models are composed of feature\nextractors and classifiers. The feature extractors generate vector\nrepresentations of the input sound segments, called embeddings, which can be\ninput to a classifier. While benchmarking of classification scores provides\ninsights into specific performance statistics, it is limited to species that\nare included in the models' training data. Furthermore, it makes it impossible\nto compare models trained on very different taxonomic groups. This paper aims\nto address this gap by analyzing the embeddings generated by the feature\nextractors of 15 bioacoustic models spanning a wide range of setups (model\narchitectures, training data, training paradigms). We evaluated and compared\ndifferent ways in which models structure embedding spaces through clustering\nand kNN classification, which allows us to focus our comparison on feature\nextractors independent of their classifiers. We believe that this approach lets\nus evaluate the adaptability and generalization potential of models going\nbeyond the classes they were trained on.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T09:13:18Z"}
{"aid":"http://arxiv.org/abs/2504.06711v1","title":"Pogorelov type $C^2$ estimates for sum Hessian equations","summary":"In this paper, We establish Pogorelov type $C^2$ estimates for the admissible\nsolutions with $\\sigma_k(D^2u)$ bounded from below of Sum Hessian equations. We\nalso proved the lower bounded condition can be removed when $k = n$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T09:14:48Z"}
{"aid":"http://arxiv.org/abs/2504.06714v1","title":"Unifying Search and Recommendation: A Generative Paradigm Inspired by\n  Information Theory","summary":"Recommender systems and search engines serve as foundational elements of\nonline platforms, with the former delivering information proactively and the\nlatter enabling users to seek information actively. Unifying both tasks in a\nshared model is promising since it can enhance user modeling and item\nunderstanding. Previous approaches mainly follow a discriminative paradigm,\nutilizing shared encoders to process input features and task-specific heads to\nperform each task. However, this paradigm encounters two key challenges:\ngradient conflict and manual design complexity. From the information theory\nperspective, these challenges potentially both stem from the same issue -- low\nmutual information between the input features and task-specific outputs during\nthe optimization process.\n  To tackle these issues, we propose GenSR, a novel generative paradigm for\nunifying search and recommendation (S&R), which leverages task-specific prompts\nto partition the model's parameter space into subspaces, thereby enhancing\nmutual information. To construct effective subspaces for each task, GenSR first\nprepares informative representations for each subspace and then optimizes both\nsubspaces in one unified model. Specifically, GenSR consists of two main\nmodules: (1) Dual Representation Learning, which independently models\ncollaborative and semantic historical information to derive expressive item\nrepresentations; and (2) S&R Task Unifying, which utilizes contrastive learning\ntogether with instruction tuning to generate task-specific outputs effectively.\nExtensive experiments on two public datasets show GenSR outperforms\nstate-of-the-art methods across S&R tasks. Our work introduces a new generative\nparadigm compared with previous discriminative methods and establishes its\nsuperiority from the mutual information perspective.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-09T09:15:37Z"}
{"aid":"http://arxiv.org/abs/2504.06721v1","title":"Learning global control of underactuated systems with Model-Based\n  Reinforcement Learning","summary":"This short paper describes our proposed solution for the third edition of the\n\"AI Olympics with RealAIGym\" competition, held at ICRA 2025. We employed\nMonte-Carlo Probabilistic Inference for Learning Control (MC-PILCO), an MBRL\nalgorithm recognized for its exceptional data efficiency across various\nlow-dimensional robotic tasks, including cart-pole, ball \\& plate, and Furuta\npendulum systems. MC-PILCO optimizes a system dynamics model using interaction\ndata, enabling policy refinement through simulation rather than direct system\ndata optimization. This approach has proven highly effective in physical\nsystems, offering greater data efficiency than Model-Free (MF) alternatives.\nNotably, MC-PILCO has previously won the first two editions of this\ncompetition, demonstrating its robustness in both simulated and real-world\nenvironments. Besides briefly reviewing the algorithm, we discuss the most\ncritical aspects of the MC-PILCO implementation in the tasks at hand: learning\na global policy for the pendubot and acrobot systems.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.LG","published":"2025-04-09T09:20:37Z"}
{"aid":"http://arxiv.org/abs/2504.06724v1","title":"End-to-end design framework for compressed on-chip pixel-wise\n  spectro-polarimeters","summary":"Modern detector manufacturing allows spectral and polarimetric filters to be\ndirectly integrated on top of separate detector pixels. This enables the\ncreation of CubeSat-sized spectro-polarimetric instruments that are not much\nlarger than the detector and a lens. Redundancy inherent to the observed scene,\noffers the opportunity for sparse sampling in the form of not scanning all\nfilters at every location. However, when there are fewer pushbroom steps than\nfilters, data are missing in the resulting data cube. The missing, largely\nredundant data can be filled in with interpolation methods, often called\ndemosaicers. The choice of filters and their precise layout influences the\nperformance of the instrument after the demosaicing process. In these\nproceedings we describe a part of a design toolbox for both the filter layout\nand the optimum parameters for the reconstruction to a full\nspectro-polarimetric data cube. The design tool is based on training a (neural)\nnetwork and jointly updating the values of the filters and demosaicer. We\noptimized a filter layout by training on spectro-polarimetric remote\nobservations of the Earth acquired by SPEX airborne. This optimised filter\nlayout could reconstruct a validation scene from five overlapping snapshots\n(pushbroom steps), which would take 109 pushbroom steps when measuring with a\nclassical layout and no reconstruction.","main_category":"astro-ph.IM","categories":"astro-ph.IM,physics.optics","published":"2025-04-09T09:29:30Z"}
{"aid":"http://arxiv.org/abs/2504.06737v1","title":"Urysohn width of hypersurfaces and positive macroscopic scalar curvature","summary":"We prove that if a complete Riemannian $n$-manifold with non-trivial\ncodimension 1 homology with $\\mathbb{Z}_2$-coefficients or\n$\\mathbb{Z}$-coefficients has positive macroscopic scalar curvature large\nenough, then it contains a non-nullhomologous hypersurface of small Urysohn\n$(n-2)$-width. This constitutes a macroscopic analogue of a theorem by\nBray--Brendle--Neves on the area of non-contractible 2-spheres in a closed\nRiemannian 3-manifold with positive scalar curvature. Our proof is based on an\nadaptation of Guth's macroscopic version of the Schoen-Yau descent argument.","main_category":"math.DG","categories":"math.DG","published":"2025-04-09T09:51:03Z"}
{"aid":"http://arxiv.org/abs/2504.06739v1","title":"Selective Kondo screening and strange metallicity by sliding Dirac\n  semimetals","summary":"Kondo screening of local moments in normal metals typically leads to\nhybridized conduction and valence bands separated by a Kondo gap, resulting in\nan insulating state at half-band filling. We show a dramatic change of this\nscenario in a Dirac-semimetal-based correlated system -- a bilayer honeycomb\nlattice heterostructure where the local moment lattice is stacked on a Dirac\nsemimetal breaking the inversion symmetry. This system is modeled by an\nextended Anderson honeycomb lattice involving the real-space dependence of\nmajor interlayer hybridization parameters on the relative sliding distance\nalong the armchair direction. First, we unveil the multiple Kondo scales and\nthe successive Kondo breakdown transitions in this correlated heterostructure\nunder sliding. Second, we demonstrate the existence of a genuine selective\nKondo screening phase which is stabilized near the A-B stack pattern and is\naccessible by applying the interlayer voltage. Third, we find a nearly flat\nhybridized band located concomitantly within the Kondo gap, resulting in an\nunprecedented metallic state at the half-band filling. This unconventional\nheavy fermion state is characterized by the violation of Luttinger theorem and\nthe appearance of a Van Hove singularity at the Fermi energy. The general\nsliding-driven band structure landscape and the implications of our results for\nthe broad context of multiorbital Kondo physics are briefly discussed.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-09T09:51:47Z"}
{"aid":"http://arxiv.org/abs/2504.06745v1","title":"A pluripotential theoretic framework for polynomial interpolation of\n  vector-valued functions and differential forms","summary":"We consider the problem of uniform interpolation of functions with values in\na complex inner product space of finite dimension. This problem can be casted\nwithin a modified weighted pluripotential theoretic framework. Indeed, in the\nproposed modification a vector valued weight is considered, allowing to\npartially extend the main asymptotic results holding for interpolation of\nscalar valued functions to the case of vector valued ones. As motivating\nexample and main application we specialize our results to interpolation of\ndifferential forms by differential forms with polynomial coefficients.","main_category":"math.CV","categories":"math.CV","published":"2025-04-09T10:04:23Z"}
{"aid":"http://arxiv.org/abs/2504.06779v1","title":"What if we find nothing? Bayesian analysis of the statistical\n  information of null results in future exoplanet habitability and biosignature\n  surveys","summary":"Future telescopes will survey temperate, terrestrial exoplanets to estimate\nthe frequency of habitable ($\\eta_{\\text{Hab}}$) or inhabited\n($\\eta_{\\text{Life}}$) planets. This study aims to determine the minimum number\nof planets ($N$) required to draw statistically significant conclusions,\nparticularly in the case of a null result (i.e., no detections). Using a\nBayesian framework, we analyzed surveys of up to $N=100$ planets to infer the\nfrequency of a binary observable feature ($\\eta_{\\text{obs}}$) after null\nresults. Posterior best fits and upper limits were derived for various survey\nsizes and compared with predicted yields from missions like the Large\nInterferometer for Exoplanets (LIFE) and the Habitable Worlds Observatory\n(HWO). Our findings indicate that $N=20-50$ ``perfect'' observations (100\\%\nconfidence in detecting or excluding the feature) yield conclusions relatively\nindependent of priors. To achieve 99.9\\% upper limits of $\\eta_{\\text{obs}}\n\\leq 0.2/0.1$, approximately $N \\simeq 40/80$ observations are needed. For\n``imperfect'' observations, uncertainties in interpretation and sample biases\nbecome limiting factors. We show that LIFE and HWO aim for sufficiently large\nsurvey sizes to provide statistically meaningful estimates of habitable\nenvironments and life prevalence under these assumptions. However, robust\nconclusions require careful sample selection and high-confidence detection or\nexclusion of features in each observation.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM","published":"2025-04-09T11:02:19Z"}
{"aid":"http://arxiv.org/abs/2504.06841v1","title":"Classifying the Unknown: In-Context Learning for Open-Vocabulary Text\n  and Symbol Recognition","summary":"We introduce Rosetta, a multimodal model that leverages Multimodal In-Context\nLearning (MICL) to classify sequences of novel script patterns in documents by\nleveraging minimal examples, thus eliminating the need for explicit retraining.\nTo enhance contextual learning, we designed a dataset generation process that\nensures varying degrees of contextual informativeness, improving the model's\nadaptability in leveraging context across different scenarios. A key strength\nof our method is the use of a Context-Aware Tokenizer (CAT), which enables\nopen-vocabulary classification. This allows the model to classify text and\nsymbol patterns across an unlimited range of classes, extending its\nclassification capabilities beyond the scope of its training alphabet of\npatterns. As a result, it unlocks applications such as the recognition of new\nalphabets and languages. Experiments on synthetic datasets demonstrate the\npotential of Rosetta to successfully classify Out-Of-Distribution visual\npatterns and diverse sets of alphabets and scripts, including but not limited\nto Chinese, Greek, Russian, French, Spanish, and Japanese.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T12:58:25Z"}
{"aid":"http://arxiv.org/abs/2504.06842v1","title":"Optimality of Gradient-MUSIC for Spectral Estimation","summary":"The goal of spectral estimation is to estimate the frequencies and amplitudes\nof a nonharmonic Fourier sum given noisy time samples. This paper introduces\nthe Gradient-MUSIC algorithm, which is a novel nonconvex optimization\nreformulation of the classical MUSIC algorithm. Under the assumption that\n$m\\Delta\\geq 8\\pi$, where $\\pi/m$ is the Nyquist rate and $\\Delta$ is the\nminimum separation of the frequencies normalized to be in $[0,2\\pi)$, we\nprovide a thorough geometric analysis of the objective functions generated by\nthe algorithm. Gradient-MUSIC thresholds the objective function on a set that\nis as coarse as possible and locates a set of suitable initialization for\ngradient descent. Although the objective function is nonconvex, gradient\ndescent converges exponentially fast to the desired local minima, which are the\nestimated frequencies of the signal. For deterministic $\\ell^p$ perturbations\nand any $p\\in [1,\\infty]$, Gradient-MUSIC estimates the frequencies and\namplitudes at the minimax optimal rate in terms of the noise level and $m$. For\nexample, if the noise has $\\ell^\\infty$ norm at most $\\epsilon$, then the\nfrequencies and amplitudes are recovered up to error at most $C\\epsilon/m$ and\n$C\\epsilon$, respectively, which are optimal in $\\epsilon$ and $m$. Aside from\nlogarithmic factors, Gradient-MUSIC is optimal for white noise and matches the\nrate achieved by nonlinear least squares for various families of nonstationary\nindependent Gaussian noise. Our results show that classical MUSIC is equally\noptimal, but it requires an expensive search on a thin grid, whereas\nGradient-MUSIC is always computationally more efficient, especially for small\nnoise. As a consequence of this paper, for sufficiently well separated\nfrequencies, both Gradient-MUSIC and classical MUSIC are the first provably\noptimal and computationally tractable algorithms for deterministic $\\ell^p$\nperturbations.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-09T13:00:49Z"}
{"aid":"http://arxiv.org/abs/2504.06856v1","title":"CasTex: Cascaded Text-to-Texture Synthesis via Explicit Texture Maps and\n  Physically-Based Shading","summary":"This work investigates text-to-texture synthesis using diffusion models to\ngenerate physically-based texture maps. We aim to achieve realistic model\nappearances under varying lighting conditions. A prominent solution for the\ntask is score distillation sampling. It allows recovering a complex texture\nusing gradient guidance given a differentiable rasterization and shading\npipeline. However, in practice, the aforementioned solution in conjunction with\nthe widespread latent diffusion models produces severe visual artifacts and\nrequires additional regularization such as implicit texture parameterization.\nAs a more direct alternative, we propose an approach using cascaded diffusion\nmodels for texture synthesis (CasTex). In our setup, score distillation\nsampling yields high-quality textures out-of-the box. In particular, we were\nable to omit implicit texture parameterization in favor of an explicit\nparameterization to improve the procedure. In the experiments, we show that our\napproach significantly outperforms state-of-the-art optimization-based\nsolutions on public texture synthesis benchmarks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T13:08:30Z"}
{"aid":"http://arxiv.org/abs/2504.06905v1","title":"A Game Theoretic Treatment of Contagion in Trade Networks","summary":"Global trade of material goods involves the potential to create pathways for\nthe spread of infectious pathogens. One trade sector in which this synergy is\nclearly critical is that of wildlife trade networks. This highly complex system\ninvolves important and understudied bidirectional coupling between the economic\ndecision making of the stakeholders and the contagion dynamics on the emergent\ntrade network. While each of these components are independently well studied,\nthere is a meaningful gap in understanding the feedback dynamics that can arise\nbetween them. In the present study, we describe a general game theoretic model\nfor trade networks of goods susceptible to contagion. The primary result relies\non the acyclic nature of the trade network and shows that, through the course\nof trading with stochastic infections, the probability of infection converges\nto a directly computable fixed point. This allows us to compute best responses\nand thus identify equilibria in the game. We present ways to use this model to\ndescribe and evaluate trade networks in terms of global and individual risk of\ninfection under a wide variety of structural or individual modifications to the\ntrade network. In capturing the bidirectional coupling of the system, we\nprovide critical insight into the global and individual drivers and\nconsequences for risks of infection inherent in and arising from the global\nwildlife trade, and any economic trade network with associated contagion risks.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-09T14:07:24Z"}
{"aid":"http://arxiv.org/abs/2504.06923v1","title":"The Importance of Being Discrete: Measuring the Impact of Discretization\n  in End-to-End Differentially Private Synthetic Data","summary":"Differentially Private (DP) generative marginal models are often used in the\nwild to release synthetic tabular datasets in lieu of sensitive data while\nproviding formal privacy guarantees. These models approximate low-dimensional\nmarginals or query workloads; crucially, they require the training data to be\npre-discretized, i.e., continuous values need to first be partitioned into\nbins. However, as the range of values (or their domain) is often inferred\ndirectly from the training data, with the number of bins and bin edges\ntypically defined arbitrarily, this approach can ultimately break end-to-end DP\nguarantees and may not always yield optimal utility.\n  In this paper, we present an extensive measurement study of four\ndiscretization strategies in the context of DP marginal generative models. More\nprecisely, we design DP versions of three discretizers (uniform, quantile, and\nk-means) and reimplement the PrivTree algorithm. We find that optimizing both\nthe choice of discretizer and bin count can improve utility, on average, by\nalmost 30% across six DP marginal models, compared to the default strategy and\nnumber of bins, with PrivTree being the best-performing discretizer in the\nmajority of cases. We demonstrate that, while DP generative models with\nnon-private discretization remain vulnerable to membership inference attacks,\napplying DP during discretization effectively mitigates this risk. Finally, we\npropose an optimized approach for automatically selecting the optimal number of\nbins, achieving high utility while reducing both privacy budget consumption and\ncomputational overhead.","main_category":"cs.CR","categories":"cs.CR,cs.LG","published":"2025-04-09T14:30:30Z"}
{"aid":"http://arxiv.org/abs/2504.06936v1","title":"On Macdonald expansions of $q$-chromatic symmetric functions and the\n  Stanley-Stembridge Conjecture","summary":"The Stanley-Stembridge conjecture asserts that the chromatic symmetric\nfunction of a $(3+1)$-free graph is $e$-positive. Recently, Hikita proved this\nconjecture by giving an explicit $e$-expansion of the Shareshian-Wachs\n$q$-chromatic refinement for unit interval graphs. Using the $\\mathbb{A}_{q,t}$\nalgebra, we give an expansion of these $q$-chromatic symmetric functions into\nMacdonald polynomials. Upon setting $t=1$, we obtain another proof of the\nStanley-Stembridge conjecture and rederive Hikita's formula. Upon setting\n$t=0$, we obtain an expansion into Hall-Littlewood symmetric functions.","main_category":"math.CO","categories":"math.CO,math.RT","published":"2025-04-09T14:41:20Z"}
{"aid":"http://arxiv.org/abs/2504.06967v1","title":"Optimal promotions of new products on networks","summary":"We present a novel methodology for analyzing the optimal promotion in the\nBass model for the spreading of new products on networks. For general networks\nwith $M$ nodes, the optimal promotion is the solution of $2^M-1$\nnonlinearly-coupled boundary-value problems. On structured networks, however,\nthe number of equations can be reduced to a manageable size which is amendable\nto simulations and analysis. This enables us to gain insight into the effect of\nthe network structure on optimal promotions. We find that the optimal\nadvertising strategy decreases with time, whereas the optimal boosting of peer\neffects increases from zero and then decreases. In low-degree networks, it is\noptimal to prioritize advertising over boosting peer effects, but this relation\nis flipped in high-degree networks. When the planning horizon is finite, the\noptimal promotion continues until the last minute, as opposed to an infinite\nplanning horizon where the optimal promotion decays to zero. Finally,\npromotions with short planning horizons can yield an order of magnitude higher\nincrease of profits, compared to those with long planning horizons.","main_category":"math.OC","categories":"math.OC,cs.SI","published":"2025-04-09T15:23:10Z"}
{"aid":"http://arxiv.org/abs/2504.06981v1","title":"LCL Resonance Analysis and Damping in Single-Loop Grid-Forming Wind\n  Turbines","summary":"A dynamic phenomenon known as LCL resonance is often neglected when stability\nanalysis is carried out for grid-forming (GFM) control schemes by wind turbine\nsystems, due to its high frequency. This paper shows that this simplification\nis not always valid for single-loop (SL) control schemes. A detailed\nsmall-signal analysis reveals that reactive power (RAP) control significantly\ninfluences the resonant modes, which may be dominant in determining overall\nsystem stability, even if the resonant frequency is high. The underlying\nmechanism via which the LCL resonance may dominate the overall system stability\nis systematically analyzed. Furthermore, various RAP control strategies are\ncompared to assess their different effects on resonant modes. An active damping\n(AD) strategy favorable for SL-GFM control is then designed. We also provide a\ncomparison between SL-GFM and well-studied grid-following control schemes,\nhighlighting quite different resonance features between them. Finally, case\nstudies associated with a 14-bus, 5-machine IEEE test system are presented.\nThese show that instability originates from the LCL resonance rather than\nlow-frequency interactions among multiple machines, validating the theoretical\nanalysis and the proposed AD strategy.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-09T15:37:02Z"}
{"aid":"http://arxiv.org/abs/2504.06983v1","title":"Free Random Projection for In-Context Reinforcement Learning","summary":"Hierarchical inductive biases are hypothesized to promote generalizable\npolicies in reinforcement learning, as demonstrated by explicit hyperbolic\nlatent representations and architectures. Therefore, a more flexible approach\nis to have these biases emerge naturally from the algorithm. We introduce Free\nRandom Projection, an input mapping grounded in free probability theory that\nconstructs random orthogonal matrices where hierarchical structure arises\ninherently. The free random projection integrates seamlessly into existing\nin-context reinforcement learning frameworks by encoding hierarchical\norganization within the input space without requiring explicit architectural\nmodifications. Empirical results on multi-environment benchmarks show that free\nrandom projection consistently outperforms the standard random projection,\nleading to improvements in generalization. Furthermore, analyses within\nlinearly solvable Markov decision processes and investigations of the spectrum\nof kernel random matrices reveal the theoretical underpinnings of free random\nprojection's enhanced performance, highlighting its capacity for effective\nadaptation in hierarchically structured state spaces.","main_category":"cs.LG","categories":"cs.LG,math.PR,stat.ML","published":"2025-04-09T15:38:50Z"}
{"aid":"http://arxiv.org/abs/2504.06991v1","title":"Dissimilar Batch Decompositions of Random Datasets","summary":"For better learning, large datasets are often split into small batches and\nfed sequentially to the predictive model. In this paper, we study such batch\ndecompositions from a probabilistic perspective. We assume that data points\n(possibly corrupted) are drawn independently from a given space and define a\nconcept of similarity between two data points. We then consider decompositions\nthat restrict the amount of similarity within each batch and obtain high\nprobability bounds for the minimum size. We demonstrate an inherent tradeoff\nbetween relaxing the similarity constraint and the overall size and also use\nmartingale methods to obtain bounds for the maximum size of data subsets with a\ngiven similarity.","main_category":"cs.LG","categories":"cs.LG,math.PR,stat.ML","published":"2025-04-09T15:58:06Z"}
{"aid":"http://arxiv.org/abs/2504.07005v1","title":"A stacky approach to prismatic crystals via $q$-prism charts","summary":"Let $Y$ be a locally complete intersection over $\\mathcal{O}_K$ containing a\n$p$-power root of unity $\\zeta_p$. We classify the derived category of\nprismatic crystals on the absolute prismatic site of $Y$ by studying\nquasi-coherent complexes on the prismatization of $Y$ via $q$-prism charts. We\nalso develop a Galois descent mechanism to remove the assumption on\n$\\mathcal{O}_K$. As an application, we classify quasi-coherent complexes on the\nCartier-Witt stack and give a purely algebraic calculation of the cohomology of\nthe structure sheaf on the absolute prismatic site of $\\mathbb{Z}_p$. Along the\nway, for $Y$ a locally complete intersection over $\\overline{A}$ with $A$ lying\nover a $q$-prism, we classify quasi-coherent complexes on the relative\nprismatization of $Y$.","main_category":"math.AG","categories":"math.AG,math.NT","published":"2025-04-09T16:24:51Z"}
{"aid":"http://arxiv.org/abs/2504.07018v1","title":"ShadowBinding: Realizing Effective Microarchitectures for In-Core Secure\n  Speculation Schemes","summary":"Secure speculation schemes have shown great promise in the war against\nspeculative side-channel attacks, and will be a key building block for\ndeveloping secure, high-performance architectures moving forward. As the field\nmatures, the need for rigorous microarchitectures, and corresponding\nperformance and cost analysis, become critical for evaluating secure schemes\nand for enabling their future adoption.\n  In ShadowBinding, we present effective microarchitectures for two\nstate-of-the-art secure schemes, uncovering and mitigating fundamental\nmicroarchitectural limitations within the analyzed schemes, and provide\nimportant design characteristics. We uncover that Speculative Taint Tracking's\n(STT's) rename-based taint computation must be completed in a single cycle,\ncreating an expensive dependency chain which greatly limits performance for\nwider processor cores. We also introduce a novel michroarchitectural approach\nfor STT, named STT-Issue, which, by delaying the taint computation to the issue\nstage, eliminates the dependency chain, achieving better instructions per cycle\n(IPC), timing, area, and performance results.\n  Through a comprehensive evaluation of our STT and Non-Speculative Data Access\n(NDA) microarchitectural designs on the RISC-V Berkeley Out-of-Order Machine,\nwe find that the IPC impact of in-core secure schemes is higher than previously\nestimated, close to 20% for the highest performance core. With insights into\ntiming from our RTL evaluation, the performance loss, created by the combined\nimpact of IPC and timing, becomes even greater, at 35%, 27%, and 22% for\nSTT-Rename, STT-Issue, and NDA, respectively. If these trends were to hold for\nleading processor core designs, the performance impact would be well over 30%,\neven for the best-performing scheme.","main_category":"cs.CR","categories":"cs.CR,cs.AR","published":"2025-04-09T16:33:42Z"}
{"aid":"http://arxiv.org/abs/2504.07050v1","title":"Minimal mechanism for fluidic flocks in interacting active colloids","summary":"Collective motion as a flock is a widely observed phenomenon in active matter\nsystems. Finding possible mechanisms of attaining a global polar order via\ndynamical mechanisms - without any explicit alignment interaction - is an area\nof active current research. Here, we report a flocking transition sustained\npurely by chemo-repulsive torques at low to medium densities in a system of\nchemically interacting colloidal particles. The basic requirements to sustain\nthe flock are excluded volume repulsions and deterministic long-ranged net\nrepulsive torques, with the time scale individual colloids move a unit length\nbeing dominant with respect to the time they deterministically sense chemicals.\nSwitching on the translational repulsive forces renders the flock a crystalline\nstructure. The generality of this phenomenon is displayed for a range of\nattractive translational forces to which the flock is robust. We rationalize\nthese results with a phenomenological hydrodynamical model.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech","published":"2025-04-09T17:09:48Z"}
{"aid":"http://arxiv.org/abs/2504.07060v1","title":"Generalized Semantic Contrastive Learning via Embedding Side Information\n  for Few-Shot Object Detection","summary":"The objective of few-shot object detection (FSOD) is to detect novel objects\nwith few training samples. The core challenge of this task is how to construct\na generalized feature space for novel categories with limited data on the basis\nof the base category space, which could adapt the learned detection model to\nunknown scenarios. However, limited by insufficient samples for novel\ncategories, two issues still exist: (1) the features of the novel category are\neasily implicitly represented by the features of the base category, leading to\ninseparable classifier boundaries, (2) novel categories with fewer data are not\nenough to fully represent the distribution, where the model fine-tuning is\nprone to overfitting. To address these issues, we introduce the side\ninformation to alleviate the negative influences derived from the feature space\nand sample viewpoints and formulate a novel generalized feature representation\nlearning method for FSOD. Specifically, we first utilize embedding side\ninformation to construct a knowledge matrix to quantify the semantic\nrelationship between the base and novel categories. Then, to strengthen the\ndiscrimination between semantically similar categories, we further develop\ncontextual semantic supervised contrastive learning which embeds side\ninformation. Furthermore, to prevent overfitting problems caused by sparse\nsamples, a side-information guided region-aware masked module is introduced to\naugment the diversity of samples, which finds and abandons biased information\nthat discriminates between similar categories via counterfactual explanation,\nand refines the discriminative representation space further. Extensive\nexperiments using ResNet and ViT backbones on PASCAL VOC, MS COCO, LVIS V1,\nFSOD-1K, and FSVOD-500 benchmarks demonstrate that our model outperforms the\nprevious state-of-the-art methods, significantly improving the ability of FSOD\nin most shots/splits.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T17:24:05Z"}
{"aid":"http://arxiv.org/abs/2504.07087v1","title":"KG-LLM-Bench: A Scalable Benchmark for Evaluating LLM Reasoning on\n  Textualized Knowledge Graphs","summary":"Knowledge graphs have emerged as a popular method for injecting up-to-date,\nfactual knowledge into large language models (LLMs). This is typically achieved\nby converting the knowledge graph into text that the LLM can process in\ncontext. While multiple methods of encoding knowledge graphs have been\nproposed, the impact of this textualization process on LLM performance remains\nunder-explored. We introduce KG-LLM-Bench, a comprehensive and extensible\nbenchmark spanning five knowledge graph understanding tasks, and evaluate how\ndifferent encoding strategies affect performance across various base models.\nOur extensive experiments with seven language models and five textualization\nstrategies provide insights for optimizing LLM performance on KG reasoning\ntasks.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.IR","published":"2025-04-09T17:58:47Z"}
{"aid":"http://arxiv.org/abs/2504.07090v1","title":"A Differentiable, End-to-End Forward Model for 21 cm Cosmology:\n  Estimating the Foreground, Instrument, and Signal Joint Posterior","summary":"We present a differentiable, end-to-end Bayesian forward modeling framework\nfor line intensity mapping cosmology experiments, with a specific focus on\nlow-frequency radio telescopes targeting the redshifted 21 cm line from neutral\nhydrogen as a cosmological probe. Our framework is capable of posterior density\nestimation of the cosmological signal jointly with foreground and telescope\nparameters at the field level. Our key aim is to be able to optimize the\nmodel's high-dimensional, non-linear, and ill-conditioned parameter space,\nwhile also sampling from it to perform robust uncertainty quantification within\na Bayesian framework. We show how a differentiable programming paradigm,\naccelerated by recent advances in machine learning software and hardware, can\nmake this computationally-demanding, end-to-end Bayesian approach feasible. We\ndemonstrate a proof-of-concept on a simplified signal recovery problem for the\nHydrogen Epoch of Reionization Array experiment, highlighting the framework's\nability to build confidence in early 21 cm signal detections even in the\npresence of poorly understood foregrounds and instrumental systematics. We use\na Hessian-preconditioned Hamiltonian Monte Carlo algorithm to efficiently\nsample our parameter space with a dimensionality approaching $N\\sim10^5$, which\nenables joint, end-to-end nuisance parameter marginalization over foreground\nand instrumental terms. Lastly, we introduce a new spherical harmonic formalism\nthat is a complete and orthogonal basis on the cut sky relevant to drift-scan\nradio surveys, which we call the spherical stripe harmonic formalism, and it's\nassociated three-dimensional basis, the spherical stripe Fourier-Bessel\nformalism.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.IM","published":"2025-04-09T17:59:03Z"}
{"aid":"http://arxiv.org/abs/2504.07096v1","title":"OLMoTrace: Tracing Language Model Outputs Back to Trillions of Training\n  Tokens","summary":"We present OLMoTrace, the first system that traces the outputs of language\nmodels back to their full, multi-trillion-token training data in real time.\nOLMoTrace finds and shows verbatim matches between segments of language model\noutput and documents in the training text corpora. Powered by an extended\nversion of infini-gram (Liu et al., 2024), our system returns tracing results\nwithin a few seconds. OLMoTrace can help users understand the behavior of\nlanguage models through the lens of their training data. We showcase how it can\nbe used to explore fact checking, hallucination, and the creativity of language\nmodels. OLMoTrace is publicly available and fully open-source.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T17:59:35Z"}
{"aid":"http://arxiv.org/abs/2504.07098v1","title":"Nonhermitian topological zero modes at smooth domain walls: Exact\n  solutions","summary":"The bulk-boundary correspondence predicts the existence of boundary modes\nlocalized at the edges of topologically nontrivial systems. The wavefunctions\nof hermitian boundary modes can be obtained as the eigenmode of a modified\nJackiw-Rebbi equation. Recently, the bulk-boundary correspondence has been\nextended to nonhermitian systems, which describe physical phenomena such as\ngain and loss in open and non-equilibrium systems. Nonhermitian energy spectra\ncan be complex-valued and exhibit point gaps or line gaps in the complex plane,\nwhether the gaps can be continuously deformed into points or lines,\nrespectively. Specifically, line-gapped nonhermitian systems can be\ncontinuously deformed into hermitian gapped spectra. Here, we find the\nanalytical form of the wavefunctions of nonhermitian boundary modes with zero\nenergy localized at smooth domain boundaries between topologically distinct\nphases, by solving the generalized Jackiw-Rebbi equation in the nonhermitian\nregime. Moreover, we unveil a universal relation between the scalar fields and\nthe decay rate and oscillation wavelength of the boundary modes. This relation\nquantifies the bulk-boundary correspondence in nonhermitian line-gapped systems\nin terms of experimentally measurable physical quantities and is not affected\nby the details of the spatial dependence of the scalar fields. These findings\nshed some new light on the localization properties of boundary modes in\nnonhermitian and topologically nontrivial states of matter.","main_category":"hep-th","categories":"hep-th,cond-mat.mes-hall,cond-mat.quant-gas,cond-mat.supr-con","published":"2025-04-09T17:59:46Z"}
{"aid":"http://arxiv.org/abs/2504.07441v1","title":"WS-DETR: Robust Water Surface Object Detection through Vision-Radar\n  Fusion with Detection Transformer","summary":"Robust object detection for Unmanned Surface Vehicles (USVs) in complex water\nenvironments is essential for reliable navigation and operation. Specifically,\nwater surface object detection faces challenges from blurred edges and diverse\nobject scales. Although vision-radar fusion offers a feasible solution,\nexisting approaches suffer from cross-modal feature conflicts, which negatively\naffect model robustness. To address this problem, we propose a robust\nvision-radar fusion model WS-DETR. In particular, we first introduce a\nMulti-Scale Edge Information Integration (MSEII) module to enhance edge\nperception and a Hierarchical Feature Aggregator (HiFA) to boost multi-scale\nobject detection in the encoder. Then, we adopt self-moving point\nrepresentations for continuous convolution and residual connection to\nefficiently extract irregular features under the scenarios of irregular point\ncloud data. To further mitigate cross-modal conflicts, an Adaptive Feature\nInteractive Fusion (AFIF) module is introduced to integrate visual and radar\nfeatures through geometric alignment and semantic fusion. Extensive experiments\non the WaterScenes dataset demonstrate that WS-DETR achieves state-of-the-art\n(SOTA) performance, maintaining its superiority even under adverse weather and\nlighting conditions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T04:16:46Z"}
{"aid":"http://arxiv.org/abs/2504.07478v1","title":"Intelligent DoS and DDoS Detection: A Hybrid GRU-NTM Approach to Network\n  Security","summary":"Detecting Denial of Service (DoS) and Distributed Denial of Service (DDoS)\nattacks remains a critical challenge in cybersecurity. This research introduces\na hybrid deep learning model combining Gated Recurrent Units (GRUs) and a\nNeural Turing Machine (NTM) for enhanced intrusion detection. Trained on the\nUNSW-NB15 and BoT-IoT datasets, the model employs GRU layers for sequential\ndata processing and an NTM for long-term pattern recognition. The proposed\napproach achieves 99% accuracy in distinguishing between normal, DoS, and DDoS\ntraffic. These findings offer promising advancements in real-time threat\ndetection and contribute to improved network security across various domains.","main_category":"cs.CR","categories":"cs.CR,cs.LG","published":"2025-04-10T06:08:04Z"}
{"aid":"http://arxiv.org/abs/2504.07480v1","title":"Echoes of Disagreement: Measuring Disparity in Social Consensus","summary":"Public discourse and opinions stem from multiple social groups. Each group\nhas beliefs about a topic (such as vaccination, abortion, gay marriage, etc.),\nand opinions are exchanged and blended to produce consensus. A particular\nmeasure of interest corresponds to measuring the influence of each group on the\nconsensus and the disparity between groups on the extent to which they\ninfluence the consensus. In this paper, we study and give provable algorithms\nfor optimizing the disparity under the DeGroot or the Friedkin-Johnsen models\nof opinion dynamics. Our findings provide simple poly-time algorithms to\noptimize disparity for most cases, fully characterize the instances that\noptimize disparity, and show how simple interventions such as contracting\nvertices or adding links affect disparity. Finally, we test our developed\nalgorithms in a variety of real-world datasets.","main_category":"cs.SI","categories":"cs.SI,physics.soc-ph","published":"2025-04-10T06:18:27Z"}
{"aid":"http://arxiv.org/abs/2504.07493v1","title":"Quickest change detection for UAV-based sensing","summary":"This paper addresses the problem of quickest change detection (QCD) at two\nspatially separated locations monitored by a single unmanned aerial vehicle\n(UAV) equipped with a sensor. At any location, the UAV observes i.i.d. data\nsequentially in discrete time instants. The distribution of the observation\ndata changes at some unknown, arbitrary time and the UAV has to detect this\nchange in the shortest possible time. Change can occur at most at one location\nover the entire infinite time horizon. The UAV switches between these two\nlocations in order to quickly detect the change. To this end, we propose\nLocation Switching and Change Detection (LS-CD) algorithm which uses a repeated\none-sided sequential probability ratio test (SPRT) based mechanism for\nobservation-driven location switching and change detection. The primary goal is\nto minimize the worst-case average detection delay (WADD) while meeting\nconstraints on the average run length to false alarm (ARL2FA) and the UAV's\ntime-averaged energy consumption. We provide a rigorous theoretical analysis of\nthe algorithm's performance by using theory of random walk. Specifically, we\nderive tight upper and lower bounds to its ARL2FA and a tight upper bound to\nits WADD. In the special case of a symmetrical setting, our analysis leads to a\nnew asymptotic upper bound to the ARL2FA of the standard CUSUM algorithm, a\nnovel contribution not available in the literature, to our knowledge. Numerical\nsimulations demonstrate the efficacy of LS-CD.","main_category":"eess.SP","categories":"eess.SP,cs.SY,eess.SY","published":"2025-04-10T06:49:55Z"}
{"aid":"http://arxiv.org/abs/2504.07505v1","title":"$c$-Birkhoff polytopes","summary":"In a 2018 paper, Davis and Sagan studied several pattern-avoiding polytopes.\nThey found that a particular pattern-avoiding Birkhoff polytope had the same\nnormalized volume as the order polytope of a certain poset, leading them to ask\nif the two polytopes were unimodularly equivalent. Motivated by Davis and\nSagan's question, in this paper we define a pattern-avoiding Birkhoff polytope\ncalled a $c$-Birkhoff polytope for each Coxeter element $c$ of the symmetric\ngroup. We then show that the $c$-Birkhoff polytope is unimodularly equivalent\nto the order polytope of the heap poset of the $c$-sorting word of the longest\npermutation. When $c=s_1s_2\\dots s_{n}$, this result recovers an affirmative\nanswer to Davis and Sagan's question. Another consequence of this result is\nthat the normalized volume of the $c$-Birkhoff polytope is the number of the\nlongest chains in the (type A) $c$-Cambrian lattice.","main_category":"math.CO","categories":"math.CO","published":"2025-04-10T07:05:41Z"}
{"aid":"http://arxiv.org/abs/2504.07511v1","title":"The finite basis problem for additively idempotent semirings of order\n  four, III","summary":"We study the finite basis problem for $4$-element additively idempotent\nsemirings whose additive reducts have two minimal elements and one coatom. Up\nto isomorphism, there are $112$ such algebras. We show that $106$ of them are\nfinitely based and the remaining ones are nonfinitely based.","main_category":"math.GR","categories":"math.GR","published":"2025-04-10T07:14:04Z"}
{"aid":"http://arxiv.org/abs/2504.07550v1","title":"A search for periodic activity in multi-peaked long gamma-ray bursts","summary":"A sizeable fraction of gamma-ray burst (GRB) light curves (LCs) features a\nsequence of peaks, which holds information on the unknown way energy is\ndissipated into gamma-rays over time. Traditional searches for periodic signals\nin GRB LCs turned out to be inconclusive, partly because they are challenging\nas a consequence of the short-lived, coloured-noise, and non-stationary nature\nof the LCs themselves. Yet, recent claims have revived the issue. We searched\nfor periodic components in GRB LCs through a new approach to GRBs, which\nescapes most of the issues faced by traditional techniques. We identified peaks\nthrough a well tested algorithm and selected GRBs with at least 10 peaks out of\n5 GRB catalogues (Swift/BAT, CGRO/BATSE, Fermi/GBM, Insight-HXMT,\nBeppoSAX/GRBM). Each GRB was simply treated as a discrete point process, whose\nrealisation coincides with the sequence of peak times. We searched for possible\nperiodic recurrences based on the multinomial distribution, after accounting\nfor the clustering of peaks due to the non-stationarity of the GRB signals. The\nbest candidate has a p-value of 3e-4 that there is no periodic recurrence.\nHowever, accounting for the multiple trials of 555 searched GRBs, its\nstatistical significance is demoted to 17%. The overall distribution of the\np-values obtained for all GRBs is compatible with a uniform distribution in\n[0,1]. We found no robust evidence for multi-peaked GRBs with periodic\nrecurrences. We can exclude that a sizeable fraction (>~ 0.75) of peaks of each\nGRB with at least 10 peaks are periodic. While our result does not necessarily\nclash with claimed periodicities based on Fourier techniques, it constrains the\nputative recurrent behaviour, which would not manifest itself through the\nsequence of peaks, but, evidently, in a more elusive way.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-10T08:25:10Z"}
{"aid":"http://arxiv.org/abs/2504.07568v1","title":"Ground State Energy of Helium Using a Four-Qubit Photonic Processor with\n  the Variational Quantum Eigensolver (VQE)","summary":"To understand the properties and interactions of materials, and determining\nthe ground state energies is one of the important challenges in quantum\nchemistry, materials science, and quantum mechanics, where quantum computing\ncan play an important role for studying the properties of materials. In this\nstudy, we have explored the quantum processor application to compute the Helium\n(He) molecule ground state energy which utilizes the Variational Quantum\nEigensolver (VQE) algorithm. In here, we have implemented VQE on a\nstate-of-the-art quantum processor, optimizing a parameterized quantum circuit\nto minimize the energy expectation value of the He molecule's Hamiltonian on\nthe four qubits processor. The obtained results of this work show a significant\nimprovement in accuracy compared to classical computational methods, such as\nHartree-Fock and density functional theory, which demonstrate the compute\npotential of quantum algorithms in quantum many-body problems. Thus, these\nresults demonstrate the advantages of quantum computing in achieving high\naccuracy in simulations of molecular and material properties, and pave the way\nfor future applications in more complex systems. This work highlights the\npotential of quantum processors in the fields of quantum chemistry,\ncomputational physics, and data science.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall","published":"2025-04-10T09:00:08Z"}
{"aid":"http://arxiv.org/abs/2504.07589v1","title":"Copy-and-Paste? Identifying EVM-Inequivalent Code Smells in Multi-chain\n  Reuse Contracts","summary":"As the development of Solidity contracts on Ethereum, more developers are\nreusing them on other compatible blockchains. However, developers may overlook\nthe differences between the designs of the blockchain system, such as the Gas\nMechanism and Consensus Protocol, leading to the same contracts on different\nblockchains not being able to achieve consistent execution as on Ethereum. This\ninconsistency reveals design flaws in reused contracts, exposing code smells\nthat hinder code reusability, and we define this inconsistency as\nEVM-Inequivalent Code Smells. In this paper, we conducted the first empirical\nstudy to reveal the causes and characteristics of EVM-Inequivalent Code Smells.\nTo ensure the identified smells reflect real developer concerns, we collected\nand analyzed 1,379 security audit reports and 326 Stack Overflow posts related\nto reused contracts on EVM-compatible blockchains, such as Binance Smart Chain\n(BSC) and Polygon. Using the open card sorting method, we defined six types of\nEVM-Inequivalent Code Smells. For automated detection, we developed a tool\nnamed EquivGuard. It employs static taint analysis to identify key paths from\ndifferent patterns and uses symbolic execution to verify path reachability. Our\nanalysis of 905,948 contracts across six major blockchains shows that\nEVM-Inequivalent Code Smells are widespread, with an average prevalence of\n17.70%. While contracts with code smells do not necessarily lead to financial\nloss and attacks, their high prevalence and significant asset management\nunderscore the potential threats of reusing these smelly Ethereum contracts.\nThus, developers are advised to abandon Copy-and-Paste programming practices\nand detect EVM-Inequivalent Code Smells before reusing Ethereum contracts.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-10T09:37:19Z"}
{"aid":"http://arxiv.org/abs/2504.07611v1","title":"Conditional Conformal Risk Adaptation","summary":"Uncertainty quantification is becoming increasingly important in image\nsegmentation, especially for high-stakes applications like medical imaging.\nWhile conformal risk control generalizes conformal prediction beyond standard\nmiscoverage to handle various loss functions such as false negative rate, its\napplication to segmentation often yields inadequate conditional risk control:\nsome images experience very high false negative rates while others have\nnegligibly small ones. We develop Conformal Risk Adaptation (CRA), which\nintroduces a new score function for creating adaptive prediction sets that\nsignificantly improve conditional risk control for segmentation tasks. We\nestablish a novel theoretical framework that demonstrates a fundamental\nconnection between conformal risk control and conformal prediction through a\nweighted quantile approach, applicable to any score function. To address the\nchallenge of poorly calibrated probabilities in segmentation models, we\nintroduce a specialized probability calibration framework that enhances the\nreliability of pixel-wise inclusion estimates. Using these calibrated\nprobabilities, we propose Calibrated Conformal Risk Adaptation (CCRA) and a\nstratified variant (CCRA-S) that partitions images based on their\ncharacteristics and applies group-specific thresholds to further enhance\nconditional risk control. Our experiments on polyp segmentation demonstrate\nthat all three methods (CRA, CCRA, and CCRA-S) provide valid marginal risk\ncontrol and deliver more consistent conditional risk control across diverse\nimages compared to standard approaches, offering a principled approach to\nuncertainty quantification that is particularly valuable for high-stakes and\npersonalized segmentation applications.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-10T10:01:06Z"}
{"aid":"http://arxiv.org/abs/2504.07630v1","title":"An intrinsic cosmological observer","summary":"There has been much recent interest in the necessity of an observer degree of\nfreedom in the description of local algebras in semiclassical gravity. In this\nwork, we describe an example where the observer can be constructed\nintrinsically from the quantum fields. This construction involves the slow-roll\ninflation example recently analyzed by Chen and Penington, in which the\ngauge-invariant gravitational algebra arises from marginalizing over modular\nflow in a de Sitter static patch. We relate this procedure to the\nConnes-Takesaki theory of the flow of weights for type III von Neumann\nalgebras, and further show that the resulting gravitational algebra can\nnaturally be presented as a crossed product. This leads to a decomposition of\nthe gravitational algebra into quantum field and observer degrees of freedom,\nwith different choices of observer being related to changes in a quantum\nreference frame for the algebra. We also connect this example to other\nconstructions of type II algebras in semiclassical gravity, and argue they all\nshare the feature of being the result of gauging modular flow. The arguments in\nthis work involve various properties of automorphism groups of hyperfinite\nfactors, and so in an appendix we review the structure of these groups, which\nmay be of independent interest for further investigations into von Neumann\nalgebras in quantum gravity.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-10T10:25:14Z"}
{"aid":"http://arxiv.org/abs/2504.07651v1","title":"Nonperturbative quantum theory of multiplasmonic electron emission from\n  surfaces: Gauge-specific cumulant expansions vs. Volkov ansatz over plasmonic\n  coherent states","summary":"Energetic electromagnetic fields produce a variety of elementary excitations\nin solids that can strongly modify their primary photoemission spectra. Such is\nthe plasmon excitation or pumping mechanism which, although indirect, is very\nefficient and hence may give rise to formation of plasmonic coherent states. In\nturn, these states may act as a source or sink of energy and momentum for\nescaping electrons. Starting from the model Hamiltonian approach we show that\nprepumped plasmonic bath of coherent states gives rise to ponderomotive\npotentials and Floquet electronic band structure that support multiple\nplasmon-induced electron emission or plasmoemission from metals. Theoretical\ndescription of multiple plasmoemission requires a nonperturbative approch which\nis here formulated by applying cumulant expansion and Volkov ansatz to the\ncalculations of electron wavefunctions and emission rates. The calculations are\nperformed in the standard length gauge as well as in the Pauli-transformed\nvelocity gauge for electron-plasmon interaction. The applicability of two\nnonperturbative approaches to calculation of excitation amplitudes are examined\nin each gauge. They smoothly interpolate between the fully quantal first order\nBorn approximation and semiclassical multiplasmon-induced electron excitation\nlimit. This is illustrated on the example of plasmoemission from Floquet\nsurface bands on Ag(111) from which this channel of electron yield has been\ndetected. Our calculations indicate that even subsingle mode occupations of\nplasmonic coherent states can support multiplasmon electron emission from\nsurface bands. A way of calibration of plasmonic coherent states is proposed.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-10T10:58:28Z"}
{"aid":"http://arxiv.org/abs/2504.07662v1","title":"On the monomorphism category of large modules","summary":"Let $R$ be an associative ring with identity. This paper investigates the\nstructure of the monomorphism category of large $R$-modules and establishes\nconnections with the category of contravariant functors defined on finitely\npresented $R$-modules. Several equivalences and dualities will be presented.\nOur results highlight the role of pure-injective modules in studying the\nhomological properties of functor categories.","main_category":"math.RT","categories":"math.RT","published":"2025-04-10T11:20:44Z"}
{"aid":"http://arxiv.org/abs/2504.07708v1","title":"TOCALib: Optimal control library with interpolation for bimanual\n  manipulation and obstacles avoidance","summary":"The paper presents a new approach for constructing a library of optimal\ntrajectories for two robotic manipulators, Two-Arm Optimal Control and\nAvoidance Library (TOCALib). The optimisation takes into account kinodynamic\nand other constraints within the FROST framework. The novelty of the method\nlies in the consideration of collisions using the DCOL method, which allows\nobtaining symbolic expressions for assessing the presence of collisions and\nusing them in gradient-based optimization control methods. The proposed\napproach allowed the implementation of complex bimanual manipulations. In this\npaper we used Mobile Aloha as an example of TOCALib application. The approach\ncan be extended to other bimanual robots, as well as to gait control of bipedal\nrobots. It can also be used to construct training data for machine learning\ntasks for manipulation.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-10T12:53:01Z"}
{"aid":"http://arxiv.org/abs/2504.07761v1","title":"Exploring a Patch-Wise Approach for Privacy-Preserving Fake ID Detection","summary":"In an increasingly digitalized world, verifying the authenticity of ID\ndocuments has become a critical challenge for real-life applications such as\ndigital banking, crypto-exchanges, renting, etc. This study focuses on the\ntopic of fake ID detection, covering several limitations in the field. In\nparticular, no publicly available data from real ID documents exists, and most\nstudies rely on proprietary in-house databases that are not available due to\nprivacy reasons. In order to shed some light on this critical challenge that\nmakes difficult to advance in the field, we explore a trade-off between privacy\n(i.e., amount of sensitive data available) and performance, proposing a novel\npatch-wise approach for privacy-preserving fake ID detection. Our proposed\napproach explores how privacy can be enhanced through: i) two levels of\nanonymization for an ID document (i.e., fully- and pseudo-anonymized), and ii)\ndifferent patch size configurations, varying the amount of sensitive data\nvisible in the patch image. Also, state-of-the-art methods such as Vision\nTransformers and Foundation Models are considered in the analysis. The\nexperimental framework shows that, on an unseen database (DLC-2021), our\nproposal achieves 13.91% and 0% EERs at patch and ID document level, showing a\ngood generalization to other databases. In addition to this exploration,\nanother key contribution of our study is the release of the first publicly\navailable database that contains 48,400 patches from both real and fake ID\ndocuments, along with the experimental framework and models, which will be\navailable in our GitHub.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CR","published":"2025-04-10T14:01:22Z"}
{"aid":"http://arxiv.org/abs/2504.07804v1","title":"Function-Correcting Codes for $$-locally $$-functions","summary":"In this paper, we explore $\\rho$-locally $\\lambda$-functions and develop\nfunction-correcting codes for these functions. We propose an upper bound on the\nredundancy of these codes, based on the minimum possible length of an\nerror-correcting code with a given number of codewords and minimum distance.\nAdditionally, we provide a sufficient optimality condition for the\nfunction-correcting codes when $\\lambda = 4$. We also demonstrate that any\nfunction can be represented as a $\\rho$-locally $\\lambda$-function,\nillustrating this with a representation of Hamming weight distribution\nfunctions. Furthermore, we present another construction of function-correcting\ncodes for Hamming weight distribution functions.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-10T14:41:51Z"}
{"aid":"http://arxiv.org/abs/2504.07813v1","title":"P2Object: Single Point Supervised Object Detection and Instance\n  Segmentation","summary":"Object recognition using single-point supervision has attracted increasing\nattention recently. However, the performance gap compared with fully-supervised\nalgorithms remains large. Previous works generated class-agnostic\n\\textbf{\\textit{proposals in an image}} offline and then treated mixed\ncandidates as a single bag, putting a huge burden on multiple instance learning\n(MIL). In this paper, we introduce Point-to-Box Network (P2BNet), which\nconstructs balanced \\textbf{\\textit{instance-level proposal bags}} by\ngenerating proposals in an anchor-like way and refining the proposals in a\ncoarse-to-fine paradigm. Through further research, we find that the bag of\nproposals, either at the image level or the instance level, is established on\ndiscrete box sampling. This leads the pseudo box estimation into a sub-optimal\nsolution, resulting in the truncation of object boundaries or the excessive\ninclusion of background. Hence, we conduct a series exploration of\ndiscrete-to-continuous optimization, yielding P2BNet++ and Point-to-Mask\nNetwork (P2MNet). P2BNet++ conducts an approximately continuous proposal\nsampling strategy by better utilizing spatial clues. P2MNet further introduces\nlow-level image information to assist in pixel prediction, and a boundary\nself-prediction is designed to relieve the limitation of the estimated boxes.\nBenefiting from the continuous object-aware \\textbf{\\textit{pixel-level\nperception}}, P2MNet can generate more precise bounding boxes and generalize to\nsegmentation tasks. Our method largely surpasses the previous methods in terms\nof the mean average precision on COCO, VOC, SBD, and Cityscapes, demonstrating\ngreat potential to bridge the performance gap compared with fully supervised\ntasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T14:51:08Z"}
{"aid":"http://arxiv.org/abs/2504.07814v1","title":"Estimating entanglement monotones of non-pure spin-squeezed states","summary":"We investigate how to estimate entanglement monotones of general mixed\nmany-body quantum states via lower and upper bounds from entanglement witnesses\nand separable ansatz states respectively. This allows us to study spin systems\non fully-connected graphs at nonzero temperature. We derive lower bounds to\ndistance-like measure from the set of fully separable states based on\nspin-squeezing inequalities. These are nonlinear expressions based on variances\nof collective spin operators and are potentially close to optimal in the large\nparticle-number limit, at least for models with two-particle interactions.\nConcretely, we apply our methods to equilibrium states of the\npermutation-invariant XXZ model with an external field and investigate\nentanglement at nonzero temperature close to quantum phase transition (QPT)\npoints in both the ferromagnetic and anti-ferromagnetic cases. We observe that\nthe lower bound becomes tight for zero temperature as well as for the\ntemperature at which entanglement disappears, both of which are thus precisely\ncaptured by the spin-squeezing inequalities. We further observe, among other\nthings, that entanglement arises at nonzero temperature close to a QPT even in\nthe ordered phase, where the ground state is separable. This can be considered\nan entanglement signature of a QPT that may also be visible in experiments.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-10T14:51:18Z"}
{"aid":"http://arxiv.org/abs/2504.07856v1","title":"2D-Curri-DPO: Two-Dimensional Curriculum Learning for Direct Preference\n  Optimization","summary":"Aligning large language models with human preferences is crucial for their\nsafe deployment. While Direct Preference Optimization (DPO) offers an efficient\nalternative to reinforcement learning from human feedback, traditional DPO\nmethods are limited by their reliance on single preference pairs. Recent work\nlike Curriculum-DPO integrates multiple pairs using a one-dimensional\ndifficulty curriculum based on pairwise distinguishability (PD), but overlooks\nthe complexity of the input prompt itself. To address this, we propose\n2D-Curri-DPO, a novel framework employing a two-dimensional curriculum that\njointly models Prompt Complexity (PC) and Pairwise Distinguishability. This\nframework introduces dual difficulty metrics to quantify prompt semantic\ncomplexity and response preference clarity, defines a curriculum strategy space\nencompassing multiple selectable strategies for task adaptation, and\nincorporates a KL-divergence-based adaptive mechanism for dynamic reference\nmodel updates to enhance training stability. Comprehensive experiments\ndemonstrate that 2D-Curri-DPO significantly outperforms standard DPO and prior\ncurriculum methods across multiple benchmarks, including MT-Bench, Vicuna\nBench, and WizardLM. Our approach achieves state-of-the-art performance on\nchallenging test sets like UltraFeedback. Ablation studies confirm the benefits\nof the 2D structure and adaptive mechanisms, while analysis provides guidance\nfor strategy selection. These findings demonstrate that effective alignment\nrequires modeling both prompt complexity and pairwise distinguishability,\nestablishing adaptive, multi-dimensional curriculum learning as a powerful and\ninterpretable new paradigm for preference-based language model optimization.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-10T15:32:00Z"}
{"aid":"http://arxiv.org/abs/2504.07861v1","title":"Horizons, throats and bounces in hybrid metric-Palatini gravity with a\n  non-zero potential","summary":"This work conducts an in-depth exploration of exact electrically charged\nsolutions, including traversable wormholes, black holes, and black bounces,\nwithin the framework of the scalar-tensor representation of hybrid\nmetric-Palatini gravity (HMPG) with a non-zero scalar potential. By integrating\nprinciples from both the metric and Palatini formulations, HMPG provides a\nflexible approach to addressing persistent challenges in General Relativity\n(GR), such as the late-time cosmic acceleration and the nature of dark matter.\nUnder the assumption of spherical symmetry, we employ an inverse problem\ntechnique to derive exact solutions in both the Jordan and Einstein conformal\nframes. This method naturally leads to configurations involving either\ncanonical or phantom scalar fields. A thorough examination of horizon\nstructures, throat conditions, asymptotic behaviour, and curvature regularity\n(via the Kretschmann scalar) reveals the intricate causal structures permitted\nby this theoretical model. The analysis uncovers a diverse range of geometric\nconfigurations, with the phantom sector exhibiting a notably richer spectrum of\nsolutions than the canonical case. These solutions encompass traversable\nwormholes, black universe models, where the interior of a black hole evolves\ninto an expanding cosmological phase rather than a singularity, as well as\nblack bounce structures and multi-horizon black holes. The results demonstrate\nthat introducing a non-zero scalar potential within HMPG significantly expands\nthe array of possible gravitational solutions, yielding complex causal and\ncurvature properties that go beyond standard GR. Consequently, HMPG stands out\nas a powerful theoretical framework for modelling extreme astrophysical\nenvironments, where deviations from classical gravity are expected to play a\ncrucial role.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE,hep-th","published":"2025-04-10T15:37:06Z"}
{"aid":"http://arxiv.org/abs/2504.07893v1","title":"Molecular excited state in the interaction quench dynamics of two\n  different atoms in a two-dimensional anisotropic trap","summary":"We explore the interaction quench dynamics of two atoms with different masses\nand subject to different trapping potentials. Notably, under such anisotropic\nconditions, the nonequilibrium dynamics can lead to the occupation of molecular\nexcited states. We consider cases of quenching from attractive to repulsive\ninteraction and vice versa, analyzing the impact of the pre- and postquench\nstates. The analysis of overlap integrals for the both states reveals a\nsignificant contribution from the molecular excited state. Moreover, the\noverlap with the prequench states might serve as an indicator of when this\nexcited state may emerge. Additionally, we calculate the energy spectrum for\nthe lowest levels in the both isotropic and anisotropic harmonic traps.\nThroughout our study, we use a Gaussian-shaped finite-range interaction\npotential.","main_category":"physics.atom-ph","categories":"physics.atom-ph,physics.atm-clus,physics.comp-ph,quant-ph","published":"2025-04-10T16:06:39Z"}
{"aid":"http://arxiv.org/abs/2504.07894v1","title":"DiverseFlow: Sample-Efficient Diverse Mode Coverage in Flows","summary":"Many real-world applications of flow-based generative models desire a diverse\nset of samples that cover multiple modes of the target distribution. However,\nthe predominant approach for obtaining diverse sets is not sample-efficient, as\nit involves independently obtaining many samples from the source distribution\nand mapping them through the flow until the desired mode coverage is achieved.\nAs an alternative to repeated sampling, we introduce DiverseFlow: a\ntraining-free approach to improve the diversity of flow models. Our key idea is\nto employ a determinantal point process to induce a coupling between the\nsamples that drives diversity under a fixed sampling budget. In essence,\nDiverseFlow allows exploration of more variations in a learned flow model with\nfewer samples. We demonstrate the efficacy of our method for tasks where\nsample-efficient diversity is desirable, such as text-guided image generation\nwith polysemous words, inverse problems like large-hole inpainting, and\nclass-conditional image synthesis.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-10T16:09:50Z"}
{"aid":"http://arxiv.org/abs/2504.07895v1","title":"Magnetic Fields of Satellite Galaxies Stronger Than Comparable Centrals\n  in TNG100","summary":"Magnetic fields exist in and around galaxies, but the properties of these\nfields have not been fully explored due to the challenges inherent in observing\nand modeling them. In this Note, we explore the differences in magnetic field\nstrength of central and satellite galaxies from the magnetohydrodynamic TNG100\nsimulation. We find that on average, magnetic fields in satellite galaxies are\nroughly an order of magnitude stronger than those of central galaxies with\ncomparable masses. The difference is greater for satellites that have already\napproached within $1 R_{200}$ of their host galaxies. These results indicate\nthat magnetic fields in satellite galaxies are amplified by environmental\nprocesses as they fall into a host halo.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-10T16:09:50Z"}
{"aid":"http://arxiv.org/abs/2504.07897v1","title":"The Constituent Quark Model","summary":"In this chapter we give a pedagogical introduction to the constituent quark\nmodel. The explanation of magnetic moments of the nucleons was crucial to\nintroduce an effective quark mass for light quarks that nowadays are understood\nas an effect of Spontaneous Chiral Symmetry Breaking in QCD. We give an\noverview of the first applications of the model and an introduction to the most\nmodern developments studying states beyond the naive quark model as tetraquarks\nand pentaquarks.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-10T16:14:37Z"}
{"aid":"http://arxiv.org/abs/2504.07900v1","title":"Temporal Tensors and Quantum Shortcut Dynamics in a Supermaze of\n  Multidimensional Time","summary":"We develop a theoretical framework that unifies concepts of multiple time\ndimensions, quantum shortcut dynamics, and complex topological structures\n('supermazes') to explore novel phenomena in quantum and classical systems. In\nparticular, we introduce a Temporal Tensor Formalism to describe\nmultidimensional time, define Quantum Shortcut Operators that enact\nnear-instantaneous state transitions, and incorporate these into a supermaze\ntopological model inspired by labyrinthine geometry and network complexity. We\nshow how this framework can give rise to surprising effects such as anomalous\nthermodynamic relaxation (analogous to the Mpemba effect) in quantum systems.\nTheoretical implications for quantum computing (including quantum cloud\nnetworks) are discussed, and connections are drawn to established mathematical\nparadoxes and physical principles.","main_category":"quant-ph","categories":"quant-ph,cs.ET","published":"2025-04-10T16:19:56Z"}
{"aid":"http://arxiv.org/abs/2504.07945v1","title":"GenEAva: Generating Cartoon Avatars with Fine-Grained Facial Expressions\n  from Realistic Diffusion-based Faces","summary":"Cartoon avatars have been widely used in various applications, including\nsocial media, online tutoring, and gaming. However, existing cartoon avatar\ndatasets and generation methods struggle to present highly expressive avatars\nwith fine-grained facial expressions and are often inspired from real-world\nidentities, raising privacy concerns. To address these challenges, we propose a\nnovel framework, GenEAva, for generating high-quality cartoon avatars with\nfine-grained facial expressions. Our approach fine-tunes a state-of-the-art\ntext-to-image diffusion model to synthesize highly detailed and expressive\nfacial expressions. We then incorporate a stylization model that transforms\nthese realistic faces into cartoon avatars while preserving both identity and\nexpression. Leveraging this framework, we introduce the first expressive\ncartoon avatar dataset, GenEAva 1.0, specifically designed to capture 135\nfine-grained facial expressions, featuring 13,230 expressive cartoon avatars\nwith a balanced distribution across genders, racial groups, and age ranges. We\ndemonstrate that our fine-tuned model generates more expressive faces than the\nstate-of-the-art text-to-image diffusion model SDXL. We also verify that the\ncartoon avatars generated by our framework do not include memorized identities\nfrom fine-tuning data. The proposed framework and dataset provide a diverse and\nexpressive benchmark for future research in cartoon avatar generation.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-10T17:54:02Z"}
{"aid":"http://arxiv.org/abs/2504.07947v1","title":"Activating high-power parametric oscillation in photonic-crystal\n  resonators","summary":"By engineering the mode spectrum of a Kerr microresonator, we selectively\nactivate nonlinear phase matching amongst broadband parametric gain. At\nthreshold, optical parametric oscillators (OPOs) emerge from vacuum\nfluctuations in the presence of a pump laser, and above threshold, OPOs seed\nthe formation of intraresonator patterns and states, such as chaos and\nsolitons. These competing nonlinear processes hinder an important application\nof OPOs as wavelength-variable, low-noise sources. Recently, nanopatterned\nmicroresonator OPOs have leveraged photonic crystal bandgaps to enable\nuniversal phase matching and control of nonlinear interactions. Here, we\nexplore a design paradigm optimized for high-output power that uses geometric\ndispersion to suppress nonlinear interactions and a photonic crystal bandgap to\nactivate only a single OPO interaction. Our devices convert an input pump laser\nto output signal and idler waves with powers exceeding 40 mW while maintaining\nspectral purity and side-mode suppression ratios greater than 40 dB. We show\nthat this approach suits custom wavelengths by measuring four independent\noscillators that vary only photonic crystal parameters to select output waves.\nOur experiments demonstrate that microresonators functionalized by photonic\ncrystals offer a versatile and lossless palette of controls for nonlinear laser\nconversion.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-10T17:54:33Z"}
{"aid":"http://arxiv.org/abs/2504.07954v1","title":"Perception-R1: Pioneering Perception Policy with Reinforcement Learning","summary":"Inspired by the success of DeepSeek-R1, we explore the potential of\nrule-based reinforcement learning (RL) in MLLM post-training for perception\npolicy learning. While promising, our initial experiments reveal that\nincorporating a thinking process through RL does not consistently lead to\nperformance gains across all visual perception tasks. This leads us to delve\ninto the essential role of RL in the context of visual perception. In this\nwork, we return to the fundamentals and explore the effects of RL on different\nperception tasks. We observe that the perceptual complexity is a major factor\nin determining the effectiveness of RL. We also observe that reward design\nplays a crucial role in further approching the upper limit of model perception.\nTo leverage these findings, we propose Perception-R1, a scalable RL framework\nusing GRPO during MLLM post-training. With a standard Qwen2.5-VL-3B-Instruct,\nPerception-R1 achieves +4.2% on RefCOCO+, +17.9% on PixMo-Count, +4.2% on\nPageOCR, and notably, 31.9% AP on COCO2017 val for the first time, establishing\na strong baseline for perception policy learning.","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-04-10T17:58:27Z"}
{"aid":"http://arxiv.org/abs/2504.07957v1","title":"MM-IFEngine: Towards Multimodal Instruction Following","summary":"The Instruction Following (IF) ability measures how well Multi-modal Large\nLanguage Models (MLLMs) understand exactly what users are telling them and\nwhether they are doing it right. Existing multimodal instruction following\ntraining data is scarce, the benchmarks are simple with atomic instructions,\nand the evaluation strategies are imprecise for tasks demanding exact output\nconstraints. To address this, we present MM-IFEngine, an effective pipeline to\ngenerate high-quality image-instruction pairs. Our MM-IFEngine pipeline yields\nlarge-scale, diverse, and high-quality training data MM-IFInstruct-23k, which\nis suitable for Supervised Fine-Tuning (SFT) and extended as MM-IFDPO-23k for\nDirect Preference Optimization (DPO). We further introduce MM-IFEval, a\nchallenging and diverse multi-modal instruction-following benchmark that\nincludes (1) both compose-level constraints for output responses and\nperception-level constraints tied to the input images, and (2) a comprehensive\nevaluation pipeline incorporating both rule-based assessment and judge model.\nWe conduct SFT and DPO experiments and demonstrate that fine-tuning MLLMs on\nMM-IFInstruct-23k and MM-IFDPO-23k achieves notable gains on various IF\nbenchmarks, such as MM-IFEval (+10.2$\\%$), MIA (+7.6$\\%$), and IFEval\n(+12.3$\\%$). The full data and evaluation code will be released on\nhttps://github.com/SYuan03/MM-IFEngine.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:59:12Z"}
{"aid":"http://arxiv.org/abs/2504.09940v1","title":"TianQuan-Climate: A Subseasonal-to-Seasonal Global Weather Model via\n  Incorporate Climatology State","summary":"Subseasonal forecasting serves as an important support for Sustainable\nDevelopment Goals (SDGs), such as climate challenges, agricultural yield and\nsustainable energy production. However, subseasonal forecasting is a complex\ntask in meteorology due to dissipating initial conditions and delayed external\nforces. Although AI models are increasingly pushing the boundaries of this\nforecasting limit, they face two major challenges: error accumulation and\nSmoothness. To address these two challenges, we propose Climate Furnace\nSubseasonal-to-Seasonal (TianQuan-Climate), a novel machine learning model\ndesigned to provide global daily mean forecasts up to 45 days, covering five\nupper-air atmospheric variables at 13 pressure levels and two surface\nvariables. Our proposed TianQuan-Climate has two advantages: 1) it utilizes a\nmulti-model prediction strategy to reduce system error impacts in long-term\nsubseasonal forecasts; 2) it incorporates a Content Fusion Module for\nclimatological integration and extends ViT with uncertainty blocks (UD-ViT) to\nimprove generalization by learning from uncertainty. We demonstrate the\neffectiveness of TianQuan-Climate on benchmarks for weather forecasting and\nclimate projections within the 15 to 45-day range, where TianQuan-Climate\noutperforms existing numerical and AI methods.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T07:02:34Z"}
{"aid":"http://arxiv.org/abs/2504.09953v1","title":"Efficient 2D to Full 3D Human Pose Uplifting including Joint Rotations","summary":"In sports analytics, accurately capturing both the 3D locations and rotations\nof body joints is essential for understanding an athlete's biomechanics. While\nHuman Mesh Recovery (HMR) models can estimate joint rotations, they often\nexhibit lower accuracy in joint localization compared to 3D Human Pose\nEstimation (HPE) models. Recent work addressed this limitation by combining a\n3D HPE model with inverse kinematics (IK) to estimate both joint locations and\nrotations. However, IK is computationally expensive. To overcome this, we\npropose a novel 2D-to-3D uplifting model that directly estimates 3D human\nposes, including joint rotations, in a single forward pass. We investigate\nmultiple rotation representations, loss functions, and training strategies -\nboth with and without access to ground truth rotations. Our models achieve\nstate-of-the-art accuracy in rotation estimation, are 150 times faster than the\nIK-based approach, and surpass HMR models in joint localization precision.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T07:32:28Z"}
{"aid":"http://arxiv.org/abs/2504.09973v1","title":"Beyond Degradation Redundancy: Contrastive Prompt Learning for\n  All-in-One Image Restoration","summary":"All-in-one image restoration, addressing diverse degradation types with a\nunified model, presents significant challenges in designing task-specific\nprompts that effectively guide restoration across multiple degradation\nscenarios. While adaptive prompt learning enables end-to-end optimization, it\noften yields overlapping or redundant task representations. Conversely,\nexplicit prompts derived from pretrained classifiers enhance discriminability\nbut may discard critical visual information for reconstruction. To address\nthese limitations, we introduce Contrastive Prompt Learning (CPL), a novel\nframework that fundamentally enhances prompt-task alignment through two\ncomplementary innovations: a \\emph{Sparse Prompt Module (SPM)} that efficiently\ncaptures degradation-specific features while minimizing redundancy, and a\n\\emph{Contrastive Prompt Regularization (CPR)} that explicitly strengthens task\nboundaries by incorporating negative prompt samples across different\ndegradation types. Unlike previous approaches that focus primarily on\ndegradation classification, CPL optimizes the critical interaction between\nprompts and the restoration model itself. Extensive experiments across five\ncomprehensive benchmarks demonstrate that CPL consistently enhances\nstate-of-the-art all-in-one restoration models, achieving significant\nimprovements in both standard multi-task scenarios and challenging composite\ndegradation settings. Our framework establishes new state-of-the-art\nperformance while maintaining parameter efficiency, offering a principled\nsolution for unified image restoration.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T08:24:57Z"}
{"aid":"http://arxiv.org/abs/2504.10053v1","title":"Synthetic Biology meets Neuromorphic Computing: Towards a bio-inspired\n  Olfactory Perception System","summary":"In this study, we explore how the combination of synthetic biology,\nneuroscience modeling, and neuromorphic electronic systems offers a new\napproach to creating an artificial system that mimics the natural sense of\nsmell. We argue that a co-design approach offers significant advantages in\nreplicating the complex dynamics of odor sensing and processing. We investigate\na hybrid system of synthetic sensory neurons that provides three key features:\na) receptor-gated ion channels, b) interface between synthetic biology and\nsemiconductors and c) event-based encoding and computing based on spiking\nnetworks. This research seeks to develop a platform for ultra-sensitive,\nspecific, and energy-efficient odor detection, with potential implications for\nenvironmental monitoring, medical diagnostics, and security.","main_category":"cs.NE","categories":"cs.NE,cs.ET,q-bio.NC","published":"2025-04-14T09:57:20Z"}
{"aid":"http://arxiv.org/abs/2504.10059v1","title":"Central limit theorem for $$-independent products and\n  higher-order tensors","summary":"We establish a central limit theorem (CLT) for families of products of\n$\\epsilon$-independent random variables. We utilize graphon limits to encode\nthe evolution of independence and characterize the limiting distribution. Our\nframework subsumes a wide class of dependency structures and includes, as a\nspecial case, a CLT for higher-order tensor products of free random variables.\nOur results extend earlier findings and recover as a special case a recent\ntensor-free CLT, which was obtained through the development of a tensor\nanalogue of free probability. In contrast, our approach is more direct and\nprovides a unified and concise derivation of a more general CLT via graphon\nconvergence.","main_category":"math.PR","categories":"math.PR","published":"2025-04-14T10:02:14Z"}
{"aid":"http://arxiv.org/abs/2504.10065v1","title":"A Computational Cognitive Model for Processing Repetitions of\n  Hierarchical Relations","summary":"Patterns are fundamental to human cognition, enabling the recognition of\nstructure and regularity across diverse domains. In this work, we focus on\nstructural repeats, patterns that arise from the repetition of hierarchical\nrelations within sequential data, and develop a candidate computational model\nof how humans detect and understand such structural repeats. Based on a\nweighted deduction system, our model infers the minimal generative process of a\ngiven sequence in the form of a Template program, a formalism that enriches the\ncontext-free grammar with repetition combinators. Such representation\nefficiently encodes the repetition of sub-computations in a recursive manner.\nAs a proof of concept, we demonstrate the expressiveness of our model on short\nsequences from music and action planning. The proposed model offers broader\ninsights into the mental representations and cognitive mechanisms underlying\nhuman pattern recognition.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T10:08:28Z"}
{"aid":"http://arxiv.org/abs/2504.10074v1","title":"MMKB-RAG: A Multi-Modal Knowledge-Based Retrieval-Augmented Generation\n  Framework","summary":"Recent advancements in large language models (LLMs) and multi-modal LLMs have\nbeen remarkable. However, these models still rely solely on their parametric\nknowledge, which limits their ability to generate up-to-date information and\nincreases the risk of producing erroneous content. Retrieval-Augmented\nGeneration (RAG) partially mitigates these challenges by incorporating external\ndata sources, yet the reliance on databases and retrieval systems can introduce\nirrelevant or inaccurate documents, ultimately undermining both performance and\nreasoning quality. In this paper, we propose Multi-Modal Knowledge-Based\nRetrieval-Augmented Generation (MMKB-RAG), a novel multi-modal RAG framework\nthat leverages the inherent knowledge boundaries of models to dynamically\ngenerate semantic tags for the retrieval process. This strategy enables the\njoint filtering of retrieved documents, retaining only the most relevant and\naccurate references. Extensive experiments on knowledge-based visual\nquestion-answering tasks demonstrate the efficacy of our approach: on the E-VQA\ndataset, our method improves performance by +4.2\\% on the Single-Hop subset and\n+0.4\\% on the full dataset, while on the InfoSeek dataset, it achieves gains of\n+7.8\\% on the Unseen-Q subset, +8.2\\% on the Unseen-E subset, and +8.1\\% on the\nfull dataset. These results highlight significant enhancements in both accuracy\nand robustness over the current state-of-the-art MLLM and RAG frameworks.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-14T10:19:47Z"}
{"aid":"http://arxiv.org/abs/2504.10090v1","title":"CameraBench: Benchmarking Visual Reasoning in MLLMs via Photography","summary":"Large language models (LLMs) and multimodal large language models (MLLMs)\nhave significantly advanced artificial intelligence. However, visual reasoning,\nreasoning involving both visual and textual inputs, remains underexplored.\nRecent advancements, including the reasoning models like OpenAI o1 and Gemini\n2.0 Flash Thinking, which incorporate image inputs, have opened this\ncapability. In this ongoing work, we focus specifically on photography-related\ntasks because a photo is a visual snapshot of the physical world where the\nunderlying physics (i.e., illumination, blur extent, etc.) interplay with the\ncamera parameters. Successfully reasoning from the visual information of a\nphoto to identify these numerical camera settings requires the MLLMs to have a\ndeeper understanding of the underlying physics for precise visual\ncomprehension, representing a challenging and intelligent capability essential\nfor practical applications like photography assistant agents. We aim to\nevaluate MLLMs on their ability to distinguish visual differences related to\nnumerical camera settings, extending a methodology previously proposed for\nvision-language models (VLMs). Our preliminary results demonstrate the\nimportance of visual reasoning in photography-related tasks. Moreover, these\nresults show that no single MLLM consistently dominates across all evaluation\ntasks, demonstrating ongoing challenges and opportunities in developing MLLMs\nwith better visual reasoning.","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-04-14T10:53:44Z"}
{"aid":"http://arxiv.org/abs/2504.10131v1","title":"A three-functor formalism for commutative von Neumann algebras","summary":"A three-functor formalism is the half of a six-functor formalism that\nsupports the projection and base change formulas. In this paper, we provide a\nthree-functor formalism for commutative von Neumann algebras and their modules.\nUsing the Gelfand-Naimark theorem, this gives rise to a three-functor formalism\nfor measure spaces and measurable bundles of Hilbert spaces. We use this to\nprove Fell absorption for unitary representations of measure groupoids.\n  The three-functor formalism for commutative von Neumann algebras takes values\nin W*-categories, and we discuss in what sense it is a unitary three-functor\nformalism.","main_category":"math.OA","categories":"math.OA,math.CT,math.QA","published":"2025-04-14T11:37:36Z"}
{"aid":"http://arxiv.org/abs/2504.10133v1","title":"Discovery of an intriguing chemically rich outflow in the OMC-2/3\n  filament","summary":"Studying chemically rich protostellar outflows and their jet provides an\nimportant insight into the low-mass star formation process and its related\nchemistry. Whilst well-known shock tracers such as SiO can be used to study the\njet properties and give information about the dynamics of the system,\ninterstellar complex organic molecules (iCOMs) have been useful in constraining\nthe age of shocked gas, for example. Yet, the number of outflows mapped in\niCOMs is still limited. In this work, we study the outflow driven by the\nprotostar FIR6c-a (HOPS 409) located in the OMC-2/3 filament. We report the\ndetection of the red-shifted jet, left undetected in previous studies, as well\nas the detection of the iCOMs methanol (CH$_3$OH) and methyl cyanide (CH$_3$CN)\nfor the first time towards this outflow. Using SiO, we derived some jet\nproperties (i.e., collimation and dynamical time). We found a clear dichotomy\nbetween the blue- and red-shifted jets, likely due to the density of the medium\nin which the jets propagate. In addition, we identified two bow shocks within\nthe blue-shifted part of the outflow, which we attribute to two different\nejection events. Finally, using the CH$_3$OH} and \\ce{CH$_3$CN} abundance ratio\nand chemical modelling, we constrained the outflow age to be $\\geq 1000$ yr old\nand, surprisingly, found that a cosmic-ray ionization rate of $10^{-14}$\ns$^{-1}$ is needed to reproduce the observed ratio towards the source.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-14T11:42:54Z"}
{"aid":"http://arxiv.org/abs/2504.10139v1","title":"Conditional Distribution Compression via the Kernel Conditional Mean\n  Embedding","summary":"Existing distribution compression methods, like Kernel Herding (KH), were\noriginally developed for unlabelled data. However, no existing approach\ndirectly compresses the conditional distribution of labelled data. To address\nthis gap, we first introduce the Average Maximum Conditional Mean Discrepancy\n(AMCMD), a natural metric for comparing conditional distributions. We then\nderive a consistent estimator for the AMCMD and establish its rate of\nconvergence. Next, we make a key observation: in the context of distribution\ncompression, the cost of constructing a compressed set targeting the AMCMD can\nbe reduced from $\\mathcal{O}(n^3)$ to $\\mathcal{O}(n)$. Building on this, we\nextend the idea of KH to develop Average Conditional Kernel Herding (ACKH), a\nlinear-time greedy algorithm that constructs a compressed set targeting the\nAMCMD. To better understand the advantages of directly compressing the\nconditional distribution rather than doing so via the joint distribution, we\nintroduce Joint Kernel Herding (JKH), a straightforward adaptation of KH\ndesigned to compress the joint distribution of labelled data. While herding\nmethods provide a simple and interpretable selection process, they rely on a\ngreedy heuristic. To explore alternative optimisation strategies, we propose\nJoint Kernel Inducing Points (JKIP) and Average Conditional Kernel Inducing\nPoints (ACKIP), which jointly optimise the compressed set while maintaining\nlinear complexity. Experiments show that directly preserving conditional\ndistributions with ACKIP outperforms both joint distribution compression (via\nJKH and JKIP) and the greedy selection used in ACKH. Moreover, we see that JKIP\nconsistently outperforms JKH.","main_category":"stat.ML","categories":"stat.ML,cs.LG,stat.CO,stat.ME","published":"2025-04-14T11:53:29Z"}
{"aid":"http://arxiv.org/abs/2504.10168v1","title":"HalluSearch at SemEval-2025 Task 3: A Search-Enhanced RAG Pipeline for\n  Hallucination Detection","summary":"In this paper, we present HalluSearch, a multilingual pipeline designed to\ndetect fabricated text spans in Large Language Model (LLM) outputs. Developed\nas part of Mu-SHROOM, the Multilingual Shared-task on Hallucinations and\nRelated Observable Overgeneration Mistakes, HalluSearch couples\nretrieval-augmented verification with fine-grained factual splitting to\nidentify and localize hallucinations in fourteen different languages. Empirical\nevaluations show that HalluSearch performs competitively, placing fourth in\nboth English (within the top ten percent) and Czech. While the system's\nretrieval-based strategy generally proves robust, it faces challenges in\nlanguages with limited online coverage, underscoring the need for further\nresearch to ensure consistent hallucination detection across diverse linguistic\ncontexts.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T12:22:30Z"}
{"aid":"http://arxiv.org/abs/2504.10188v1","title":"Efficient Generative Model Training via Embedded Representation Warmup","summary":"Diffusion models excel at generating high-dimensional data but fall short in\ntraining efficiency and representation quality compared to self-supervised\nmethods. We identify a key bottleneck: the underutilization of high-quality,\nsemantically rich representations during training notably slows down\nconvergence. Our systematic analysis reveals a critical representation\nprocessing region -- primarily in the early layers -- where semantic and\nstructural pattern learning takes place before generation can occur. To address\nthis, we propose Embedded Representation Warmup (ERW), a plug-and-play\nframework where in the first stage we get the ERW module serves as a warmup\nthat initializes the early layers of the diffusion model with high-quality,\npretrained representations. This warmup minimizes the burden of learning\nrepresentations from scratch, thereby accelerating convergence and boosting\nperformance. Our theoretical analysis demonstrates that ERW's efficacy depends\non its precise integration into specific neural network layers -- termed the\nrepresentation processing region -- where the model primarily processes and\ntransforms feature representations for later generation. We further establish\nthat ERW not only accelerates training convergence but also enhances\nrepresentation quality: empirically, our method achieves a 40$\\times$\nacceleration in training speed compared to REPA, the current state-of-the-art\nmethods. Code is available at https://github.com/LINs-lab/ERW.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-14T12:43:17Z"}
{"aid":"http://arxiv.org/abs/2504.10191v1","title":"Localized Cultural Knowledge is Conserved and Controllable in Large\n  Language Models","summary":"Just as humans display language patterns influenced by their native tongue\nwhen speaking new languages, LLMs often default to English-centric responses\neven when generating in other languages. Nevertheless, we observe that local\ncultural information persists within the models and can be readily activated\nfor cultural customization. We first demonstrate that explicitly providing\ncultural context in prompts significantly improves the models' ability to\ngenerate culturally localized responses. We term the disparity in model\nperformance with versus without explicit cultural context the explicit-implicit\nlocalization gap, indicating that while cultural knowledge exists within LLMs,\nit may not naturally surface in multilingual interactions if cultural context\nis not explicitly provided. Despite the explicit prompting benefit, however,\nthe answers reduce in diversity and tend toward stereotypes. Second, we\nidentify an explicit cultural customization vector, conserved across all\nnon-English languages we explore, which enables LLMs to be steered from the\nsynthetic English cultural world-model toward each non-English cultural world.\nSteered responses retain the diversity of implicit prompting and reduce\nstereotypes to dramatically improve the potential for customization. We discuss\nthe implications of explicit cultural customization for understanding the\nconservation of alternative cultural world models within LLMs, and their\ncontrollable utility for translation, cultural customization, and the\npossibility of making the explicit implicit through soft control for expanded\nLLM function and appeal.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T12:53:58Z"}
{"aid":"http://arxiv.org/abs/2504.10220v1","title":"Modeling the Thermal Structure of a Protoplanetary Disk Using Multiband\n  Flux-Limited Diffusion Approximation","summary":"This work continues the analysis of the model for calculating the thermal\nstructure of an axisymmetric protoplanetary disk, initiated in the paper by\nPavlyuchenkov (2024). The model is based on the well-known Flux-Limited\nDiffusion (FLD) approximation with separate calculation of heating by direct\nstellar radiation (hereinafter referred to as the FLD$^{\\rm s}$ method). In\naddition to the previously described FLD$^{\\rm s}$ model with\nwavelength-averaged opacities, we present a multiband model mFLD$^{\\rm s}$,\nwhere the spectrum of thermal radiation is divided into several frequency\nbands. The model is based on an implicit finite-difference scheme for the\nequations of thermal radiation diffusion, which reduces to a system of linear\nalgebraic equations written in hypermatrix form. A modified Gauss method for\ninverting the sparse hypermatrix of the original system of linear equations is\nproposed. The simulation results described in the article show that the\nmidplane radial temperature profile obtained with the mFLD$^{\\rm s}$ method has\na variable slope in accordance with the reference Monte Carlo radiative\ntransfer simulations. The mFLD$^{\\rm s}$ model also qualitatively reproduces\nthe non-isothermality of the temperature distribution along the angular\ncoordinate near the midplane, which is not provided by the FLD$^{\\rm s}$\nmethod. However, quantitative differences remain between the reference\ntemperature values and the results of mFLD$^{\\rm s}$. These differences are\nlikely due to the diffusive nature of the FLD approximation. It is also shown\nthat the characteristic times for the disk to reach thermal equilibrium within\nthe mFLD$^{\\rm s}$ model can be significantly shorter than in FLD$^{\\rm s}$.\nThis property should be taken into account when modeling non-stationary\nprocesses in protoplanetary disks within FLD-based models.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-04-14T13:37:19Z"}
{"aid":"http://arxiv.org/abs/2504.10223v1","title":"A proof of the Krzyz conjecture","summary":"A proof of the Krzyz conjecture is presented, based on the application of the\nvariational method, as well as on the use of two classical results and some of\ntheir consequences. The mentioned results are the Caratheodory-Toeplitz\ncriterion of continuing a polynomial to a Caratheodory class function, and the\nRiesz-Fejer theorem about trigonometric polynomials. This is an English\ntranslation of a preprint originally published in Russian:\nhttps://preprints.ru/article/1799","main_category":"math.CV","categories":"math.CV","published":"2025-04-14T13:44:52Z"}
{"aid":"http://arxiv.org/abs/2504.10248v1","title":"Adaptive Sensor Steering Strategy Using Deep Reinforcement Learning for\n  Dynamic Data Acquisition in Digital Twins","summary":"This paper introduces a sensor steering methodology based on deep\nreinforcement learning to enhance the predictive accuracy and decision support\ncapabilities of digital twins by optimising the data acquisition process.\nTraditional sensor placement techniques are often constrained by one-off\noptimisation strategies, which limit their applicability for online\napplications requiring continuous informative data assimilation. The proposed\napproach addresses this limitation by offering an adaptive framework for sensor\nplacement within the digital twin paradigm. The sensor placement problem is\nformulated as a Markov decision process, enabling the training and deployment\nof an agent capable of dynamically repositioning sensors in response to the\nevolving conditions of the physical structure as represented by the digital\ntwin. This ensures that the digital twin maintains a highly representative and\nreliable connection to its physical counterpart. The proposed framework is\nvalidated through a series of comprehensive case studies involving a cantilever\nplate structure subjected to diverse conditions, including healthy and damaged\nconditions. The results demonstrate the capability of the deep reinforcement\nlearning agent to adaptively reposition sensors improving the quality of data\nacquisition and hence enhancing the overall accuracy of digital twins.","main_category":"stat.ML","categories":"stat.ML,cs.LG,eess.SP","published":"2025-04-14T14:11:00Z"}
{"aid":"http://arxiv.org/abs/2504.10285v1","title":"Grothendieck-Springer resolutions and TQFTs","summary":"Let $G$ be a connected complex semisimple group with Lie algebra\n$\\mathfrak{g}$ and fixed Kostant slice $\\mathrm{Kos}\\subseteq\\mathfrak{g}^*$.\nIn a previous work, we show that\n$((T^*G)_{\\text{reg}}\\rightrightarrows\\mathfrak{g}^*_{\\text{reg}},\\mathrm{Kos})$\nyields the open Moore-Tachikawa TQFT. Morphisms in the image of this TQFT are\ncalled open Moore-Tachikawa varieties. By replacing\n$T^*G\\rightrightarrows\\mathfrak{g}^*$ and $\\mathrm{Kos}\\subseteq\\mathfrak{g}^*$\nwith the double $\\mathrm{D}(G)\\rightrightarrows G$ and a Steinberg slice\n$\\mathrm{Ste}\\subseteq G$, respectively, one obtains quasi-Hamiltonian\nanalogues of the open Moore-Tachikawa TQFT and varieties.\n  We consider a conjugacy class $\\mathcal{C}$ of parabolic subalgebras of\n$\\mathfrak{g}$. This class determines partial Grothendieck-Springer resolutions\n$\\mu_{\\mathcal{C}}:\\mathfrak{g}_{\\mathcal{C}}\\longrightarrow\\mathfrak{g}^*=\\mathfrak{g}$\nand $\\nu_{\\mathcal{C}}:G_{\\mathcal{C}}\\longrightarrow G$. We construct a\ncanonical symplectic groupoid\n$(T^*G)_{\\mathcal{C}}\\rightrightarrows\\mathfrak{g}_{\\mathcal{C}}$ and\nquasi-symplectic groupoid $\\mathrm{D}(G)_{\\mathcal{C}}\\rightrightarrows\nG_{\\mathcal{C}}$. In addition, we prove that the pairs\n$(((T^*G)_{\\mathcal{C}})_{\\text{reg}}\\rightrightarrows(\\mathfrak{g}_{\\mathcal{C}})_{\\text{reg}},\\mu_{\\mathcal{C}}^{-1}(\\mathrm{Kos}))$\nand\n$((\\mathrm{D}(G)_{\\mathcal{C}})_{\\text{reg}}\\rightrightarrows(G_{\\mathcal{C}})_{\\text{reg}},\\nu_{\\mathcal{C}}^{-1}(\\mathrm{Ste}))$\ndetermine TQFTs in a $1$-shifted Weinstein symplectic category. Our main result\nis about the Hamiltonian symplectic varieties arising from the former TQFT; we\nshow that these have canonical Lagrangian relations to the open Moore-Tachikawa\nvarieties. Pertinent specializations of our results to the full\nGrothendieck-Springer resolution are discussed throughout this manuscript.","main_category":"math.SG","categories":"math.SG,math.AG,math.RT","published":"2025-04-14T14:53:01Z"}
{"aid":"http://arxiv.org/abs/2504.10298v1","title":"Cross-talk in superconducting qubit lattices with tunable couplers -\n  comparing transmon and fluxonium architectures","summary":"Cross-talk between qubits is one of the main challenges for scaling\nsuperconducting quantum processors. Here, we use the density-matrix\nrenormalization-group to numerically analyze lattices of superconducting qubits\nfrom a perspective of many-body localization. Specifically, we compare\ndifferent architectures that include tunable couplers designed to decouple\nqubits in the idle state, and calculate the residual ZZ interactions as well as\nthe inverse participation ratio in the computational basis states. For transmon\nqubits outside of the straddling regime, the results confirm that tunable\nC-shunt flux couplers are significantly more efficient in mitigating the ZZ\ninteractions than tunable transmons. A recently proposed fluxonium architecture\nwith tunable transmon couplers is demonstrated to also maintain its strong\nsuppression of the ZZ interactions in larger systems, while having a higher\ninverse participation ratio in the computational basis states than lattices of\ntransmon qubits. Our results thus suggest that fluxonium architectures may\nfeature lower cross talk than transmon lattices when designed to achieve\nsimilar gate speeds and fidelities.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T15:07:35Z"}
{"aid":"http://arxiv.org/abs/2504.10301v1","title":"Three-body problem for nuclear physics","summary":"A brief excursion into the three-body problem is presented for graduate\nstudents in nuclear physics or anyone at a similar stage. Starting from\nsingle-particle coordinates, a step-by-step derivation of the Shcr\\\"{o}dinger\nequation in Jacobi coordinates is outlined. Laplace operators are explicitly\ntransformed through the chain rule for multivariable calculus. The\ntransformation of Faddeev equations from Jacobi coordinates to hyperspherical\ncoordinates is elaborated upon. In all transformations (from single-particle\ncoordinates to Jacobi coordinates, rotation between Jacobi coordinates and from\nJacobi coordinates to hyperspherical coordinates) the determinant of the\nJacobian matrix is computed to show how volume elements transform. The\nprojection of Faddeev equations on a hyperspherical harmonics basis is\nexplicitly carried out to obtain the coupled hyperradial equations that define\nthe hyperspherical harmonics method.","main_category":"nucl-th","categories":"nucl-th,physics.ed-ph","published":"2025-04-14T15:10:00Z"}
{"aid":"http://arxiv.org/abs/2504.10315v1","title":"An energy optimization method based on mixed-integer model and\n  variational quantum computing algorithm for faster IMPT","summary":"Intensity-modulated proton therapy (IMPT) offers superior dose conformity\nwith reduced exposure to surrounding healthy tissues compared to conventional\nphoton therapy. Improving IMPT delivery efficiency reduces motion-related\nuncertainties, enhances plan robustness, and benefits breath-hold techniques by\nshortening treatment time. Among various factors, energy switching time plays a\ncritical role, making energy layer optimization (ELO) essential. This work\ndevelops an energy layer optimization method based on mixed integer model and\nvariational quantum computing algorithm to enhance the efficiency of IMPT. The\nenergy layer optimization problem is modeled as a mixed-integer program, where\ncontinuous variables optimize the dose distribution and binary variables\nindicate energy layer selection. To solve it, iterative convex relaxation\ndecouples the dose-volume constraints, followed by the alternating direction\nmethod of multipliers (ADMM) to separate mixed-variable optimization and the\nminimum monitor unit (MMU) constraint. The resulting beam intensity subproblem,\nsubject to MMU, either admits a closed-form solution or is efficiently solvable\nvia conjugate gradient. The binary subproblem is cast as a quadratic\nunconstrained binary optimization (QUBO) problem, solvable using variational\nquantum computing algorithms. With nearly the same plan quality, the proposed\nmethod noticeable reduces the number of the used energies. For example,\ncompared to conventional IMPT, QC can reduce the number of energy layers from\n61 to 35 in HN case, from 56 to 35 in lung case, and from 59 to 32 to abdomen\ncase. The reduced number of energies also results in fewer delivery time, e.g.,\nthe delivery time is reduced from 100.6, 232.0, 185.3 seconds to 90.7, 215.4,\n154.0 seconds, respectively.","main_category":"physics.med-ph","categories":"physics.med-ph,math.OC","published":"2025-04-14T15:24:23Z"}
{"aid":"http://arxiv.org/abs/2504.10327v1","title":"Probing Einstein-Maxwell-Scalar Black hole via Thin Accretion Disks and\n  Shadows with EHT Observations of M87* and Sgr A*","summary":"We investigated the shadows and thin accretion disks of\nEinstein-Maxwell-Scalar (EMS) black hole. Firstly, we investigated the\ninfluence of EMS parameters on the black hole shadow using the null geodesic\nmethod and constrained these parameters based on EHT observations of M87* and\nSgr A*. Furthermore, we analyzed the direct emission, lensing ring, and photon\nring structures in EMS black hole. Comparing our results with the Schwarzschild\nand Reissner-Nordstr$\\ddot{\\mathrm{o}}$m (RN) black holes, we found that the\nSchwarzschild black hole exhibits the largest shadow radius and the highest\nobserved intensity. Increasing the EMS model parameters leads to a reduction in\nintensity. Ultimately, our findings suggest that imaging black hole accretion\ndisks does not clearly distinguish among these three types of black holes.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-14T15:35:47Z"}
{"aid":"http://arxiv.org/abs/2504.10373v1","title":"DUE: A Deep Learning Framework and Library for Modeling Unknown\n  Equations","summary":"Equations, particularly differential equations, are fundamental for\nunderstanding natural phenomena and predicting complex dynamics across various\nscientific and engineering disciplines. However, the governing equations for\nmany complex systems remain unknown due to intricate underlying mechanisms.\nRecent advancements in machine learning and data science offer a new paradigm\nfor modeling unknown equations from measurement or simulation data. This\nparadigm shift, known as data-driven discovery or modeling, stands at the\nforefront of AI for science, with significant progress made in recent years. In\nthis paper, we introduce a systematic framework for data-driven modeling of\nunknown equations using deep learning. This versatile framework is capable of\nlearning unknown ODEs, PDEs, DAEs, IDEs, SDEs, reduced or partially observed\nsystems, and non-autonomous differential equations. Based on this framework, we\nhave developed Deep Unknown Equations (DUE), an open-source software package\ndesigned to facilitate the data-driven modeling of unknown equations using\nmodern deep learning techniques. DUE serves as an educational tool for\nclassroom instruction, enabling students and newcomers to gain hands-on\nexperience with differential equations, data-driven modeling, and contemporary\ndeep learning approaches such as FNN, ResNet, generalized ResNet, operator\nsemigroup networks (OSG-Net), and Transformers. Additionally, DUE is a\nversatile and accessible toolkit for researchers across various scientific and\nengineering fields. It is applicable not only for learning unknown equations\nfrom data but also for surrogate modeling of known, yet complex, equations that\nare costly to solve using traditional numerical methods. We provide detailed\ndescriptions of DUE and demonstrate its capabilities through diverse examples,\nwhich serve as templates that can be easily adapted for other applications.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.DS,math.NA,stat.ML","published":"2025-04-14T16:20:55Z"}
{"aid":"http://arxiv.org/abs/2504.10441v1","title":"Position Uncertainty in a Prisoner's Dilemma Game : An Experiment","summary":"Gallice and Monzon (2019) present a natural environment that sustains full\ncooperation in one-shot social dilemmas among a finite number of\nself-interested agents. They demonstrate that in a sequential public goods\ngame, where agents lack knowledge of their position in the sequence but can\nobserve some predecessors' actions, full contribution emerges in equilibrium\ndue to agents' incentive to induce potential successors to follow suit.\nFurthermore, they show that this principle extends to a number of social\ndilemmas, with the prominent example that of the prisoner's dilemma. In this\nstudy, we experimentally test the theoretical predictions of this model in a\nmulti- player prisoner's dilemma environment, where subjects are not aware of\ntheir position in the sequence and receive only partial information on past\ncooperating actions. We test the predictions of the model, and through rigorous\nstructural econometric analysis, we test the descriptive capacity of the model\nagainst alternative behavioural strategies, such as conditional cooperation,\naltruistic play and free-riding behaviour. We find that the majority resorts to\nfree-riding behaviour, around 30% is classified as Gallice and Monzon (2019)\ntypes, followed by those with social preference considerations and the\nunconditional altruists.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-14T17:32:07Z"}
{"aid":"http://arxiv.org/abs/2504.10462v1","title":"The Scalability of Simplicity: Empirical Analysis of Vision-Language\n  Learning with a Single Transformer","summary":"This paper introduces SAIL, a single transformer unified multimodal large\nlanguage model (MLLM) that integrates raw pixel encoding and language decoding\nwithin a singular architecture. Unlike existing modular MLLMs, which rely on a\npre-trained vision transformer (ViT), SAIL eliminates the need for a separate\nvision encoder, presenting a more minimalist architecture design. Instead of\nintroducing novel architectural components, SAIL adapts mix-attention\nmechanisms and multimodal positional encodings to better align with the\ndistinct characteristics of visual and textual modalities. We systematically\ncompare SAIL's properties-including scalability, cross-modal information flow\npatterns, and visual representation capabilities-with those of modular MLLMs.\nBy scaling both training data and model size, SAIL achieves performance\ncomparable to modular MLLMs. Notably, the removal of pretrained ViT components\nenhances SAIL's scalability and results in significantly different cross-modal\ninformation flow patterns. Moreover, SAIL demonstrates strong visual\nrepresentation capabilities, achieving results on par with ViT-22B in vision\ntasks such as semantic segmentation. Code and models are available at\nhttps://github.com/bytedance/SAIL.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T17:50:20Z"}
{"aid":"http://arxiv.org/abs/2504.10474v1","title":"Co-optimizing Physical Reconfiguration Parameters and Controllers for an\n  Origami-inspired Reconfigurable Manipulator","summary":"Reconfigurable robots that can change their physical configuration\npost-fabrication have demonstrate their potential in adapting to different\nenvironments or tasks. However, it is challenging to determine how to optimally\nadjust reconfigurable parameters for a given task, especially when the\ncontroller depends on the robot's configuration. In this paper, we address this\nproblem using a tendon-driven reconfigurable manipulator composed of multiple\nserially connected origami-inspired modules as an example. Under tendon\nactuation, these modules can achieve different shapes and motions, governed by\njoint stiffnesses (reconfiguration parameters) and the tendon displacements\n(control inputs). We leverage recent advances in co-optimization of design and\ncontrol for robotic system to treat reconfiguration parameters as design\nvariables and optimize them using reinforcement learning techniques. We first\nestablish a forward model based on the minimum potential energy method to\npredict the shape of the manipulator under tendon actuations. Using the forward\nmodel as the environment dynamics, we then co-optimize the control policy (on\nthe tendon displacements) and joint stiffnesses of the modules for goal\nreaching tasks while ensuring collision avoidance. Through co-optimization, we\nobtain optimized joint stiffness and the corresponding optimal control policy\nto enable the manipulator to accomplish the task that would be infeasible with\nfixed reconfiguration parameters (i.e., fixed joint stiffness). We envision the\nco-optimization framework can be extended to other reconfigurable robotic\nsystems, enabling them to optimally adapt their configuration and behavior for\ndiverse tasks and environments.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T17:56:38Z"}
{"aid":"http://arxiv.org/abs/2504.10477v1","title":"Vector induced Gravitational Waves sourced by Primordial Magnetic Fields","summary":"In this work, we develop a generic formalism for the study of tensor\nperturbations induced at second order by first-order vector metric\nperturbations, dubbing these induced tensor modes $\\textit{vector-induced\ngravitational waves}$ (VIGWs). Notably, considering an inflation-inspired\npower-law type magnetic field power spectrum of the form $P_B(k)\\propto\nk^{n_\\mathrm{B}}$ (where $n_{\\rm B}$ is the magnetic spectral index), we show\nthat the VIGW signal is enhanced for stiff post-inflationary EoS, with the\nmaximum enhancement happening for $w=1$. We explicitly demonstrate this\ncontribution is dominant over the first-order magnetically-sourced GWs. The\nVIGW spectrum exhibits a maximum at around the scale crossing the cosmological\nhorizon at the end of reheating, $k_\\mathrm{reh}$, with its present day peak\namplitude scaling as $\\Omega_{\\rm GW}(k_{\\rm reh},\\eta_0)\\propto \\Delta N_{\\rm\nreh}\\times(H_{\\rm inf}/M_{\\rm Pl})^{8}$, where $H_{\\rm inf}$ is the Hubble\nparameter at the end of inflation and $\\Delta N_{\\rm reh}$ the duration of the\npost-inflationary era in $e$-folds. For $w=1$ (kination) and $n_{\\rm B}>-3/2$,\none further obtains a nearly $n_{\\rm B}$-independent frequency scaling of the\nGW spectrum of the form $\\Omega_{\\rm GW}(f,\\eta_0)\\propto \\left(\\frac{f}{f_{\\rm\nreh}}\\right)^{-2.8}$ for $f>f_\\mathrm{reh}\\equiv k_\\mathrm{reh}/(2\\pi)$.\nFinally, we need to highlight that the VIGW signal can be well within the\ndetection bands of several next-generation interferometric GW missions at small\nscales. Indicatively, for $H_{\\rm inf} \\sim O(10^{7})\\:\\mathrm{GeV}$ and\n$O(10^{14})\\:\\mathrm{GeV}$, and $\\Delta N_{\\rm reh} \\sim 15$ and $10$, the VIGW\nsignal is found to be detectable by LISA and ET respectively.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph,hep-th","published":"2025-04-14T17:59:05Z"}
{"aid":"http://arxiv.org/abs/2504.10480v1","title":"Probing Long-Range Forces in Neutrino Oscillations at the ESSnuSB\n  Experiment","summary":"Neutrino oscillations constitute an excellent tool to probe physics beyond\nthe Standard Model. In this paper, we investigate the potential of the \\ess\nexperiment to constrain the effects of flavour-dependent long-range forces\n(LRFs) in neutrino oscillations, which may arise due to the extension of the\nStandard Model gauge group by introducing new $U(1)$ symmetries. Focusing on\nthree specific $U(1)$ symmetries -- $L_e - L_\\mu$, $L_e - L_\\tau$, and $L_\\mu -\nL_\\tau$, we demonstrate that \\ess offers a favourable environment to search for\nLRF effects. Our analyses reveal that \\ess can set 90\\% confidence level bounds\nof $V_{e\\mu} < 2.99 \\times 10^{-14} \\, \\text{eV}$, $V_{e\\tau} < 2.05 \\times\n10^{-14} \\, \\text{eV}$, and $V_{\\mu\\tau} < 1.81 \\times 10^{-14} \\, \\text{eV}$,\nwhich are competitive to the upcoming Deep Underground Neutrino Experiment\n(DUNE). It is also observed that reducing the systematic uncertainties from\n$5\\%$ to $2\\%$ improves the \\ess limits on $V_{\\alpha\\beta}$. Interestingly, we\nfind limited correlations between LRF parameters and the less constrained\nlepton mixing parameters $\\theta_{23}$ and $\\delta_{\\text{CP}}$, preserving the\nrobustness of ESSnuSB's sensitivity to CP violation. Even under extreme LRF\npotentials ($V_{\\alpha\\beta} \\gg 10^{-13} \\, \\text{eV}$), the CP-violation\nsensitivity and $\\delta_{\\text{CP}}$ precision remain largely unaffected. These\nresults establish ESSnuSB as a competitive experimental setup for probing LRF\neffects, complementing constraints from other neutrino sources and offering\ncritical insights into the physics of long-range forces.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-14T17:59:25Z"}
{"aid":"http://arxiv.org/abs/2504.10845v1","title":"Moving Beyond Next-Token Prediction: Transformers are Context-Sensitive\n  Language Generators","summary":"Large Language Models (LLMs), powered by Transformers, have demonstrated\nhuman-like intelligence capabilities, yet their underlying mechanisms remain\npoorly understood. This paper presents a novel framework for interpreting LLMs\nas probabilistic left context-sensitive languages (CSLs) generators. We\nhypothesize that Transformers can be effectively decomposed into three\nfundamental components: context windows, attention mechanisms, and\nautoregressive generation frameworks. This decomposition allows for the\ndevelopment of more flexible and interpretable computational models, moving\nbeyond the traditional view of attention and autoregression as inseparable\nprocesses. We argue that next-token predictions can be understood as\nprobabilistic, dynamic approximations of left CSL production rules, providing\nan intuitive explanation for how simple token predictions can yield human-like\nintelligence outputs. Given that all CSLs are left context-sensitive\n(Penttonen, 1974), we conclude that Transformers stochastically approximate\nCSLs, which are widely recognized as models of human-like intelligence. This\ninterpretation bridges the gap between Formal Language Theory and the observed\ngenerative power of Transformers, laying a foundation for future advancements\nin generative AI theory and applications. Our novel perspective on Transformer\narchitectures will foster a deeper understanding of LLMs and their future\npotentials.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-15T04:06:27Z"}
{"aid":"http://arxiv.org/abs/2504.10897v1","title":"SCOOP: A Scalable Quantum-Computing Framework to Constrained\n  Combinatorial Optimization","summary":"While the ultimate goal of solving computationally intractable problems is to\nfind a provably optimal solutions, practical constraints of real-world\nscenarios often necessitate focusing on efficiently obtaining high-quality,\nnear-optimal solutions. The Quantum Approximate Optimization Algorithm (QAOA)\nis a state-of-the-art hybrid quantum-classical approach for tackling these\nchallenging problems that are encoded using quadratic and higher-order\nunconstrained binary optimization problems (QUBO and HUBO). We present SCOOP, a\nnovel QAOA-based framework for solving constrained optimization problems. SCOOP\ntransforms a constrained problem into an unconstrained counterpart, forming\nSCOOP problem twins. The QAOA quantum algorithm operates on the unconstrained\ntwin to identify potential optimal and near-optimal solutions. Effective\nclassical post-processing reduces the solution set to the constrained problem\nspace. Our SCOOP approach is solution-enhanced, objective-function-compatible,\nand scalable. We demonstrate the framework on three NP-hard problems, Minimum\nDominating Set, Minimum Maximal Matching, and Minimum Set Cover appearing in\npractical application domains such as resource allocation, communication\nnetworks, and machine learning. We validate SCOOP's feasibility and\neffectiveness on Xanadu PennyLane simulators.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T06:17:23Z"}
{"aid":"http://arxiv.org/abs/2504.10908v1","title":"Generalizability of local neural operator: example for elastodynamic\n  problems","summary":"Local neural operator (LNO) conception has provided a feasible way for\nscientific computations. The LNO learns transient partial differential\nequations from random field samples, and then the pre-trained LNO solves\npractical problems on specific computational domains. For applications, we may\nask: Are the training samples rich enough? To what extent can we trust the\nsolutions obtained from pre-trained LNO models for unknown cases? The\ngeneralizability of LNO could answer these questions. Here, we propose to use\ntwo plain scalar features, the amplitude and wavenumber of the input functions,\nto indicate the richness of training samples and to evaluate the generalization\nerror of pre-trained LNO. In elastodynamic practices, we find that isolated\nevolving wavenumber modes for Lam\\'e-Navier equation caused the training\ndataset to lack mode diversity. By data supplementation and model fine-tuning\ntargeting to the discovered lack modes, the pre-trained and fine-tuned LNO\nmodel solves Lamb problem correctly and efficiently. These results and the\nproposed generalization criteria provide a paradigm for LNO applications.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-04-15T06:41:05Z"}
{"aid":"http://arxiv.org/abs/2504.10915v1","title":"LOKA Protocol: A Decentralized Framework for Trustworthy and Ethical AI\n  Agent Ecosystems","summary":"The rise of autonomous AI agents, capable of perceiving, reasoning, and\nacting independently, signals a profound shift in how digital ecosystems\noperate, govern, and evolve. As these agents proliferate beyond centralized\ninfrastructures, they expose foundational gaps in identity, accountability, and\nethical alignment. Three critical questions emerge: Identity: Who or what is\nthe agent? Accountability: Can its actions be verified, audited, and trusted?\nEthical Consensus: Can autonomous systems reliably align with human values and\nprevent harmful emergent behaviors? We present the novel LOKA Protocol (Layered\nOrchestration for Knowledgeful Agents), a unified, systems-level architecture\nfor building ethically governed, interoperable AI agent ecosystems. LOKA\nintroduces a proposed Universal Agent Identity Layer (UAIL) for decentralized,\nverifiable identity; intent-centric communication protocols for semantic\ncoordination across diverse agents; and a Decentralized Ethical Consensus\nProtocol (DECP) that enables agents to make context-aware decisions grounded in\nshared ethical baselines. Anchored in emerging standards such as Decentralized\nIdentifiers (DIDs), Verifiable Credentials (VCs), and post-quantum\ncryptography, LOKA offers a scalable, future-resilient blueprint for\nmulti-agent AI governance. By embedding identity, trust, and ethics into the\nprotocol layer itself, LOKA establishes the foundation for a new era of\nresponsible, transparent, and autonomous AI ecosystems operating across digital\nand physical domains.","main_category":"cs.MA","categories":"cs.MA,cs.AI,cs.CY","published":"2025-04-15T06:51:35Z"}
{"aid":"http://arxiv.org/abs/2504.10921v1","title":"MSCRS: Multi-modal Semantic Graph Prompt Learning Framework for\n  Conversational Recommender Systems","summary":"Conversational Recommender Systems (CRSs) aim to provide personalized\nrecommendations by interacting with users through conversations. Most existing\nstudies of CRS focus on extracting user preferences from conversational\ncontexts. However, due to the short and sparse nature of conversational\ncontexts, it is difficult to fully capture user preferences by conversational\ncontexts only. We argue that multi-modal semantic information can enrich user\npreference expressions from diverse dimensions (e.g., a user preference for a\ncertain movie may stem from its magnificent visual effects and compelling\nstoryline). In this paper, we propose a multi-modal semantic graph prompt\nlearning framework for CRS, named MSCRS. First, we extract textual and image\nfeatures of items mentioned in the conversational contexts. Second, we capture\nhigher-order semantic associations within different semantic modalities\n(collaborative, textual, and image) by constructing modality-specific graph\nstructures. Finally, we propose an innovative integration of multi-modal\nsemantic graphs with prompt learning, harnessing the power of large language\nmodels to comprehensively explore high-dimensional semantic relationships.\nExperimental results demonstrate that our proposed method significantly\nimproves accuracy in item recommendation, as well as generates more natural and\ncontextually relevant content in response generation. We have released the code\nand the expanded multi-modal CRS datasets to facilitate further exploration in\nrelated research\\footnote{https://github.com/BIAOBIAO12138/MSCRS-main}.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-15T07:05:22Z"}
{"aid":"http://arxiv.org/abs/2504.10926v1","title":"RedDots: Planetary masses in the GJ1061 system from planet-planet\n  interaction","summary":"GJ1061 is a very nearby M star hosting three low-mass temperate planets\ndetected from radial velocity variations. The close to 4:2:1 period\ncommensurability of the planets, the available long-term monitoring of the\nsystem and new very high-precision radial velocity measurements from ESPRESSO\nenable the determination of masses from the planet-planet interaction. Using\nnested sampling, we derived parameter distributions for a co-planar\nconfiguration. The three planets (Mb =1.07 +- 0.11M_Earth, Pb =3.2073 +- 0.0003\nd, Mc=1.76 +- 0.13M_Earth, Pc=6.6821 +- 0.0008 d, Md =1.55 +- 0.17M_Earth, Pd\n=13.066 +- 0.002 d) are potentially all rocky with equilibrium temperatures\nbetween 360 K and 240 K. This makes the GJ1061 system one of the prime targets\nfor future ground or space based instruments suitable for a direct detection of\nthe planetary atmospheres.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-04-15T07:12:03Z"}
{"aid":"http://arxiv.org/abs/2504.10935v1","title":"Sasaki-Einstein orbits in compact Hermitian symmetric spaces","summary":"The aim of the present papar is to study the orbits of the isotropy gourp\naction on an irreducible Hermitian symmetric space of compact type.\nSpecifically, we examine the properties of these orbits as {\\it CR}\nsubmanifolds of a K\\\"{a}hler manifold. Our focus is on the leaves of the\ntotally real distribution, and we investigate the properties of leaves as a\nRiemannian submanifold. In particular, we prove that any leaf is a totally\ngeodesic submanifold of the orbit. Additionally, we explore the conditions\nunder which each leaf becomes a totally geodesic submanifold of the ambient\nspace. The integrability of the complex distribution is also studied. Moreover,\nwe analyze a contact structure of orbits where the rank of the totally real\ndistribution is 1. We obtain a classification of the orbits that possess either\na contact structure or a Sasakian structure compatible with the complex\nstructure on the ambient space. Furthermore, we classify those Sasaki orbits\nthat are Einstein with respect to the induced metric. Specifically, we\ncompletely detemine Sasaki-Einstein orbits.","main_category":"math.DG","categories":"math.DG","published":"2025-04-15T07:32:14Z"}
{"aid":"http://arxiv.org/abs/2504.10941v1","title":"Tidal interactions in stellar and planetary systems","summary":"Gravitational tidal interactions drive long-term rotational and orbital\nevolution in planetary systems, in multiple (particularly close binary) star\nsystems and in planetary moon systems. Dissipation of tidal flows in Earth's\noceans is primarily responsible for producing gradual expansion of the Moon's\norbit at a few centimetres per year as the Earth's day lengthens by a few\nmilliseconds per century. Similar processes occur in many astrophysical\nsystems. For example, tidal dissipation inside (slowly rotating) stars hosting\nshort-period planets can cause the orbits of these planets to decay,\npotentially leading to planetary destruction; tidal dissipation inside stars in\nclose stellar binary systems -- and inside short-period planets such as hot\nJupiters in planetary systems -- can cause initially eccentric orbits to become\ncircular. To model these processes, explain many current observational results,\nand make predictions for future observations, we require a detailed theoretical\nunderstanding of tidal flows and the mechanisms by which -- and how efficiently\n-- they are dissipated inside stars and planets. This article will introduce\nour current understanding of tidal flows and dissipation inside stars (and to a\nlesser extent giant planets), as well as highlight some unsolved problems.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-04-15T07:41:32Z"}
{"aid":"http://arxiv.org/abs/2504.10947v1","title":"Improved MST3 Encryption scheme based on small Ree groups","summary":"This article presents an encryption scheme based on the small Ree groups. We\npropose utilizing the small Ree group structure to enhance the overall security\nparameters of the encryption scheme. By extending the logarithmic signature to\nencompass the entire group and modifying the encryption algorithm, we have\ndeveloped robust protection against sequential key recovery attacks.","main_category":"cs.CR","categories":"cs.CR,math.GR","published":"2025-04-15T07:51:56Z"}
{"aid":"http://arxiv.org/abs/2504.10978v1","title":"AgentPolyp: Accurate Polyp Segmentation via Image Enhancement Agent","summary":"Since human and environmental factors interfere, captured polyp images\nusually suffer from issues such as dim lighting, blur, and overexposure, which\npose challenges for downstream polyp segmentation tasks. To address the\nchallenges of noise-induced degradation in polyp images, we present AgentPolyp,\na novel framework integrating CLIP-based semantic guidance and dynamic image\nenhancement with a lightweight neural network for segmentation. The agent first\nevaluates image quality using CLIP-driven semantic analysis (e.g., identifying\n``low-contrast polyps with vascular textures\") and adapts reinforcement\nlearning strategies to dynamically apply multi-modal enhancement operations\n(e.g., denoising, contrast adjustment). A quality assessment feedback loop\noptimizes pixel-level enhancement and segmentation focus in a collaborative\nmanner, ensuring robust preprocessing before neural network segmentation. This\nmodular architecture supports plug-and-play extensions for various enhancement\nalgorithms and segmentation networks, meeting deployment requirements for\nendoscopic devices.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-15T08:39:35Z"}
{"aid":"http://arxiv.org/abs/2504.10981v1","title":"X-ray polarization of accreting black holes: Cyg X-1 and Swift\n  J1727.8-1613","summary":"The Imaging X-ray Polarimetry Explorer is an X-ray observatory measuring the\nX-ray polarization in the 2-8 keV energy range. Highly sensitive to the\nsystem's geometry, X-ray polarization is a unique method to probe the structure\nof X-ray binaries. The Imaging X-ray Polarimetry Explorer observed the\nHigh-Mass X-ray Binary Cygnus X-1 and the Low-Mass X-ray Binary Swift\nJ1727.8-1613 in different accretion states: in the hard state and in the soft\nstate. The X-ray polarimetry analysis of both sources shows a linear\npolarization degree increasing with energy, with higher values in the hard\nstate than in the soft state. However, the linear polarization angle stays\nsimilar in both states and is aligned with the radio jet within $5^\\circ$.\nFurthermore, the Low-Mass X-ray Binary Swift J1727.8-1613 has a lower optical\nintrinsic polarization and a lower X-ray polarization degree for a softer\nspectrum. The similarities observed in this analysis between the X-ray\npolarization results of different types of X-ray Binaries show that the\ninnermost accretion processes are independent of the companion star's type.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-15T08:45:07Z"}
{"aid":"http://arxiv.org/abs/2504.10993v1","title":"A broken Hardy inequality on finite element space and application to\n  strain gradient elasticity","summary":"We illustrate a broken Hardy inequality on discontinuous finite element\nspaces, blowing up with a logarithmic factor with respect to the meshes size.\nThis is motivated by numerical analysis for the strain gradient elasticity with\nnatural boundary conditions. A mixed finite element pair is employed to solve\nthis model with nearly incompressible materials. This pair is quasi-stable with\na logarithmic factor, which is not significant in the approximation error, and\nconverges robustly in the incompressible limit and uniformly in the microscopic\nmaterial parameter. Numerical results back up that the theoretical predictions\nare nearly optimal. Moreover, the regularity estimates for the model over a\nsmooth domain have been proved with the aid of the Agmon-Douglis-Nirenberg\ntheory.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-15T09:08:57Z"}
{"aid":"http://arxiv.org/abs/2504.11007v1","title":"Kubernetes in the Cloud vs. Bare Metal: A Comparative Study of Network\n  Costs","summary":"Modern cloud-native applications increasingly utilise managed cloud services\nand containerisation technologies, such as Kubernetes, to achieve rapid\ntime-to-market and scalable deployments. Organisations must consider various\nfactors, including cost implications when deciding on a hosting platform for\ncontainerised applications as the usage grows. An emerging discipline called\nFinOps combines financial management and cloud operations to optimise costs in\ncloud-based applications. While prior research has explored system-level\noptimisation strategies for cost and resource efficiency in containerized\nsystems, analysing network costs in Kubernetes clusters remains underexplored.\nThis paper investigates the network usage and cost implications of\ncontainerised applications running on Kubernetes clusters. Using a methodology\nthat combines measurement analysis, experimentation, and cost modelling, we aim\nto provide organisations with actionable insights into network cost\noptimisation. Our findings highlight key considerations for analysing network\nexpenditures and evaluating the potential cost benefits of deploying\napplications on cloud providers. Overall, this paper contributes to the\nemerging FinOps discipline by addressing the financial and operational aspects\nof managing network costs in cloud-native environments.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-15T09:26:08Z"}
{"aid":"http://arxiv.org/abs/2504.11017v1","title":"Floquet realization of prethermal Meissner phase in a two-leg flux\n  ladder","summary":"We show that a periodically driven two-leg flux ladder hosting interacting\nhardcore bosons exhibits a prethermal Meissner phase for large drive amplitudes\nand at special drive frequencies. Such a prethermal Meissner phase is\ncharacterized by a finite time-averaged chiral current. We find an analytic\nexpression of these frequencies using Floquet perturbation theory. Our analysis\nreveals that the presence of the prethermal Meissner phase is tied to the\nemergence of strong Hilbert space fragmentation in these driven ladders. We\nsupport our analytical results by numerical study of finite-size flux ladders\nusing exact diagonalization and discuss experiments using ultracold dipolar\natom platforms that may test our theory.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,cond-mat.other","published":"2025-04-15T09:41:37Z"}
{"aid":"http://arxiv.org/abs/2504.11023v1","title":"An Inexact Variable Metric Proximal Gradient-subgradient Algorithm for a\n  Class of Fractional Optimization Problems","summary":"In this paper, we study a class of fractional optimization problems, in which\nthe numerator of the objective is the sum of a convex function and a\ndifferentiable function with a Lipschitz continuous gradient, while the\ndenominator is a nonsmooth convex function. This model has broad applicability\nand encompasses several important optimization problems in the literature. To\naddress these problems, we propose an inexact variable metric proximal\ngradient-subgradient algorithm (iVPGSA), which, to our knowledge, is the first\ninexact proximal algorithm specifically designed for solving such type of\nfractional problems. By incorporating a variable metric proximal term and\nallowing for inexact solutions to the subproblem under a flexible error\ncriterion, the proposed algorithm is highly adaptable to a broader range of\nproblems while achieving favorable computational efficiency. Under mild\nassumptions, we establish that any accumulation point of the sequence generated\nby the iVPGSA is a critical point of the target problem. Moreover, we develop\nan improved Kurdyka-{\\L}ojasiewicz (KL)-based analysis framework to prove the\nglobal convergence of the entire sequence and characterize its convergence\nrate, \\textit{without} requiring a strict sufficient descent property. Our\nresults offer detailed insights into how the KL exponent and inexactness\ninfluence the convergence rate. The proposed analysis framework also has the\npotential to serve as a theoretical tool for studying the convergence rates of\na wide range of inexact algorithms beyond the iVPGSA. Finally, some numerical\nexperiments on the $\\ell_1/\\ell_2$ Lasso problem and the constrained\n$\\ell_1/\\ell_2$ sparse optimization problem are conducted to show the superior\nperformance of the iVPGSA in comparison to existing algorithms.","main_category":"math.OC","categories":"math.OC","published":"2025-04-15T09:48:27Z"}
{"aid":"http://arxiv.org/abs/2504.11032v1","title":"On Rigid Varieties Isogenous to a Product of Curves","summary":"In this note, we study rigid complex manifolds that are realized as quotients\nof a product of curves by a free action of a finite group. They serve as\nhigher-dimensional analogues of Beauville surfaces. Using uniformization, we\noutline the theory to characterize these manifolds through specific\ncombinatorial data associated with the group under the assumption that the\naction is diagonal and the manifold is of general type. This leads to the\nnotion of a $n$-fold Beauville structure. We define an action on the set of all\n$n$-fold Beauville structures of a given finite group that allows us to\ndistinguish the biholomorphism classes of the underlying rigid manifolds. As an\napplication, we give a classification of these manifolds with group $\\mathbb\nZ_5^2$ in the three dimensional case and prove that this is the smallest\npossible group that allows a rigid, free and diagonal action on a product of\nthree curves. In addition, we provide the classification of rigid 3-folds $X$\ngiven by a group acting faithfully on each factor for any value of the\nholomorphic Euler number $\\chi(\\mathcal O_X) \\geq -5$.","main_category":"math.AG","categories":"math.AG,math.CV,math.GR","published":"2025-04-15T09:54:58Z"}
{"aid":"http://arxiv.org/abs/2504.11063v1","title":"UKDM: Underwater keypoint detection and matching using underwater image\n  enhancement techniques","summary":"The purpose of this paper is to explore the use of underwater image\nenhancement techniques to improve keypoint detection and matching. By applying\nadvanced deep learning models, including generative adversarial networks and\nconvolutional neural networks, we aim to find the best method which improves\nthe accuracy of keypoint detection and the robustness of matching algorithms.\nWe evaluate the performance of these techniques on various underwater datasets,\ndemonstrating significant improvements over traditional methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T10:52:19Z"}
{"aid":"http://arxiv.org/abs/2504.11107v1","title":"An Invariance Principle for some Reaction-Diffusion Equations with a\n  Multiplicative Random Source","summary":"We establish a notion of universality for the parabolic Anderson model via an\ninvariance principle for a wide family of parabolic stochastic partial\ndifferential equations. We then use this invariance principle in order to\nprovide an asymptotic theory for a wide class of non-linear SPDEs. A novel\ningredient of this invariance principle is the dissipativity of the underlying\nstochastic PDE.","main_category":"math.PR","categories":"math.PR","published":"2025-04-15T11:55:05Z"}
{"aid":"http://arxiv.org/abs/2504.11120v1","title":"Improved approximation ratios for the Quantum Max-Cut problem on\n  general, triangle-free and bipartite graphs","summary":"We study polynomial-time approximation algorithms for the Quantum Max-Cut\n(QMC) problem. Given an edge-weighted graph $G$ on n vertices, the QMC problem\nis to determine the largest eigenvalue of a particular $2^n \\times 2^n$ matrix\nthat corresponds to $G$. We provide a sharpened analysis of the currently\nbest-known QMC approximation algorithm for general graphs. This algorithm\nachieves an approximation ratio of $0.599$, which our analysis improves to\n$0.603$. Additionally, we propose two new approximation algorithms for the QMC\nproblem on triangle-free and bipartite graphs, that achieve approximation\nratios of $0.61383$ and $0.8162$, respectively. These are the best-known\napproximation ratios for their respective graph classes.","main_category":"quant-ph","categories":"quant-ph,math.OC","published":"2025-04-15T12:08:07Z"}
{"aid":"http://arxiv.org/abs/2504.11126v1","title":"KubeFence: Security Hardening of the Kubernetes Attack Surface","summary":"Kubernetes (K8s) is widely used to orchestrate containerized applications,\nincluding critical services in domains such as finance, healthcare, and\ngovernment. However, its extensive and feature-rich API interface exposes a\nbroad attack surface, making K8s vulnerable to exploits of software\nvulnerabilities and misconfigurations. Even if K8s adopts role-based access\ncontrol (RBAC) to manage access to K8s APIs, this approach lacks the\ngranularity needed to protect specification attributes within API requests.\nThis paper proposes a novel solution, KubeFence, which implements finer-grain\nAPI filtering tailored to specific client workloads. KubeFence analyzes\nKubernetes Operators from trusted repositories and leverages their\nconfiguration files to restrict unnecessary features of the K8s API, to\nmitigate misconfigurations and vulnerabilities exploitable through the K8s API.\nThe experimental results show that KubeFence can significantly reduce the\nattack surface and prevent attacks compared to RBAC.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-15T12:15:34Z"}
{"aid":"http://arxiv.org/abs/2504.11128v1","title":"K-means Enhanced Density Gradient Analysis for Urban and Transport\n  Metrics Using Multi-Modal Satellite Imagery","summary":"This paper presents a novel computational approach for evaluating urban\nmetrics through density gradient analysis using multi-modal satellite imagery,\nwith applications including public transport and other urban systems. By\ncombining optical and Synthetic Aperture Radar (SAR) data, we develop a method\nto segment urban areas, identify urban centers, and quantify density gradients.\nOur approach calculates two key metrics: the density gradient coefficient\n($\\alpha$) and the minimum effective distance (LD) at which density reaches a\ntarget threshold. We further employ machine learning techniques, specifically\nK-means clustering, to objectively identify uniform and high-variability\nregions within density gradient plots. We demonstrate that these metrics\nprovide an effective screening tool for public transport analyses by revealing\nthe underlying urban structure. Through comparative analysis of two\nrepresentative cities with contrasting urban morphologies (monocentric vs\npolycentric), we establish relationships between density gradient\ncharacteristics and public transport network topologies. Cities with clear\ndensity peaks in their gradient plots indicate distinct urban centers requiring\ndifferent transport strategies than those with more uniform density\ndistributions. This methodology offers urban planners a cost-effective,\nglobally applicable approach to preliminary public transport assessment using\nfreely available satellite data. The complete implementation, with additional\nexamples and documentation, is available in an open-source repository under the\nMIT license at https://github.com/nexri/Satellite-Imagery-Urban-Analysis.","main_category":"cs.CV","categories":"cs.CV,cs.LG,eess.IV","published":"2025-04-15T12:25:42Z"}
{"aid":"http://arxiv.org/abs/2504.11147v1","title":"Robust Bayesian Inference for Censored Survival Models","summary":"This paper proposes a robust Bayesian accelerated failure time model for\ncensored survival data. We develop a new family of life-time distributions\nusing a scale mixture of the generalized gamma distributions, where we propose\na novel super heavy-tailed distribution as a mixing density. We theoretically\nshow that, under some conditions, the proposed method satisfies the full\nposterior robustness, which guarantees robustness of point estimation as well\nas uncertainty quantification. For posterior computation, we employ an integral\nexpression of the proposed heavy-tailed distribution to develop an efficient\nposterior computation algorithm based on the Markov chain Monte Carlo. The\nperformance of the proposed method is illustrated through numerical experiments\nand real data example.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-15T12:48:23Z"}
{"aid":"http://arxiv.org/abs/2504.11153v1","title":"The interplay between Jahn-Teller distortions and structural degrees of\n  freedom on pseudocubic states in manganite perovskites","summary":"The average structure of the solid solution LaMn$_{1-x}$Ga$_x$O$_3$ (LMGO)\nhas been investigated from a symmetry-motivated approach utilizing synchrotron\nx-ray and neutron powder diffraction techniques. We show experimentally that a\ntrilinear coupling term ($\\Gamma_5^+$M$_2^+$M$_3^+$) between shear strain,\noctahedral rotation, and the $C$-type orbital ordering mode is responsible for\ndriving the orthorhombic to pseudocubic phase transition occurring in the\ncomposition range 0.5 $<$ $x$ $<$ 0.6. Our Monte Carlo simulations elucidate\nthe macroscopic origin of this coupling to shear strain, and point to its\nimportance with respect to controlling the orbital order-disorder transitions.\nWe find that the emergence of the pseudocubic state can be rationalized by\nconsidering the competition between this trilinear term and a linear-quadratic\nterm of the out-of-phase octahedral tilting with strain\n($\\Gamma_5^+$(R$_5^-$)$^2$). Illustrating the general nature of these results,\nwe construct a simple function that captures the change in Landau free energy\nat the order-disorder transition, in parameters that are trivial to relate to\nthe concentration of Jahn--Teller active species, temperature, tolerance factor\nand unit cell strain, for a broad range of manganite perovskites. Our results\npoint to the fact that far from the pseudocubic state being a symptom of\norbital disorder, it is in many cases more correctly to view it as a cause. The\nresults have a broad impact on the study of orbital ordering physics in the\nperovskite materials and on chemical and physical control parameters through\nwhich to tune the richness of the intertwined physical properties.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-15T12:56:38Z"}
{"aid":"http://arxiv.org/abs/2504.11178v1","title":"MeerKAT 1.3 GHz Observations Towards the Milky Way Bulge","summary":"We present a MeerKAT survey of portions of the Milky Way bulge. The survey\ncovers 172.8 square degrees in two contiguous mosaics above and below the\nGalactic Center as well as 32 single pointing fields at higher longitudes. The\nresolution of the images is $\\sim$8\\asec\\ at a frequency of 1333 MHz with a\ntypical Stokes I RMS of 20 $\\mu$Jy Beam$^{-1}$. Most of the emission seen is\nfrom background extragalactic sources but many compact Galactic objects are\nidentifiable by their polarization properties. Apparent polarized emission\nresulting from fine scale Faraday rotation in the ISM is widespread in this\nregion of the Galaxy. The survey is used to search for background Giant Radio\nGalaxies, $>$700 kpc in size, identifying 17 such objects. Data products\ninclude FITS images of Stokes I, Q, U and V as well as a Faraday analysis and\nlists of compact total intensity and polarized sources.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-15T13:32:45Z"}
{"aid":"http://arxiv.org/abs/2504.11229v1","title":"The Forward-Forward Algorithm: Characterizing Training Behavior","summary":"The Forward-Forward algorithm is an alternative learning method which\nconsists of two forward passes rather than a forward and backward pass employed\nby backpropagation. Forward-Forward networks employ layer local loss functions\nwhich are optimized based on the layer activation for each forward pass rather\nthan a single global objective function. This work explores the dynamics of\nmodel and layer accuracy changes in Forward-Forward networks as training\nprogresses in pursuit of a mechanistic understanding of their internal\nbehavior. Treatments to various system characteristics are applied to\ninvestigate changes in layer and overall model accuracy as training progresses,\nhow accuracy is impacted by layer depth, and how strongly individual layer\naccuracy is correlated with overall model accuracy. The empirical results\npresented suggest that layers deeper within Forward-Forward networks experience\na delay in accuracy improvement relative to shallower layers and that shallower\nlayer accuracy is strongly correlated with overall model accuracy.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-15T14:30:18Z"}
{"aid":"http://arxiv.org/abs/2504.11239v1","title":"Nondeterministic Polynomial-time Problem Challenge: An Ever-Scaling\n  Reasoning Benchmark for LLMs","summary":"Reasoning is the fundamental capability of large language models (LLMs). Due\nto the rapid progress of LLMs, there are two main issues of current benchmarks:\ni) these benchmarks can be crushed in a short time (less than 1 year), and ii)\nthese benchmarks may be easily hacked. To handle these issues, we propose the\never-scalingness for building the benchmarks which are uncrushable, unhackable,\nauto-verifiable and general. This paper presents Nondeterministic\nPolynomial-time Problem Challenge (NPPC), an ever-scaling reasoning benchmark\nfor LLMs. Specifically, the NPPC has three main modules: i) npgym, which\nprovides a unified interface of 25 well-known NP-complete problems and can\ngenerate any number of instances with any levels of complexities, ii) npsolver:\nwhich provides a unified interface to evaluate the problem instances with both\nonline and offline models via APIs and local deployments, respectively, and\niii) npeval: which provides the comprehensive and ready-to-use tools to analyze\nthe performances of LLMs over different problems, the number of tokens, the aha\nmoments, the reasoning errors and the solution errors. Extensive experiments\nover widely-used LLMs demonstrate: i) NPPC can successfully decrease the\nperformances of advanced LLMs' performances to below 10%, demonstrating that\nNPPC is uncrushable, ii) DeepSeek-R1, Claude-3.7-Sonnet, and o1/o3-mini are the\nmost powerful LLMs, where DeepSeek-R1 outperforms Claude-3.7-Sonnet and\no1/o3-mini in most NP-complete problems considered, and iii) the numbers of\ntokens, aha moments in the advanced LLMs, e.g., Claude-3.7-Sonnet and\nDeepSeek-R1, are observed first to increase and then decrease when the problem\ninstances become more and more difficult. We believe that NPPC is the first\never-scaling reasoning benchmark, serving as the uncrushable and unhackable\ntestbed for LLMs toward artificial general intelligence (AGI).","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-15T14:40:29Z"}
{"aid":"http://arxiv.org/abs/2504.11242v1","title":"Measurement of the g factor of ground-state 87Sr at the\n  parts-per-million level using co-trapped ultracold atoms","summary":"We demonstrate nuclear magnetic resonance of optically trapped ground-state\nultracold 87Sr atoms. Using a scheme in which a cloud of ultracold 87Rb is\nco-trapped nearby, we improve the determination of the nuclear g factor, gI ,\nof atomic 87Sr by more than two orders of magnitude, reaching accuracy at the\nparts-per-million level. We achieve similar accuracy in the ratio of relevant g\nfactors between Rb and Sr. This establishes ultracold 87Sr as an excellent\nlinear in-vacuum magnetometer. These results are relevant for ongoing efforts\ntowards quantum simulation, quantum computation and optical atomic clocks\nemploying 87Sr, and these methods can also be applied to other alkaline-earth\nand alkaline-earth-like atoms.","main_category":"physics.atom-ph","categories":"physics.atom-ph,quant-ph","published":"2025-04-15T14:43:03Z"}
{"aid":"http://arxiv.org/abs/2504.11307v1","title":"Uncertainty Estimation for Trust Attribution to Speed-of-Sound\n  Reconstruction with Variational Networks","summary":"Speed-of-sound (SoS) is a biomechanical characteristic of tissue, and its\nimaging can provide a promising biomarker for diagnosis. Reconstructing SoS\nimages from ultrasound acquisitions can be cast as a limited-angle\ncomputed-tomography problem, with Variational Networks being a promising\nmodel-based deep learning solution. Some acquired data frames may, however, get\ncorrupted by noise due to, e.g., motion, lack of contact, and acoustic shadows,\nwhich in turn negatively affects the resulting SoS reconstructions. We propose\nto use the uncertainty in SoS reconstructions to attribute trust to each\nindividual acquired frame. Given multiple acquisitions, we then use an\nuncertainty based automatic selection among these retrospectively, to improve\ndiagnostic decisions. We investigate uncertainty estimation based on Monte\nCarlo Dropout and Bayesian Variational Inference. We assess our automatic frame\nselection method for differential diagnosis of breast cancer, distinguishing\nbetween benign fibroadenoma and malignant carcinoma. We evaluate 21 lesions\nclassified as BI-RADS~4, which represents suspicious cases for probable\nmalignancy. The most trustworthy frame among four acquisitions of each lesion\nwas identified using uncertainty based criteria. Selecting a frame informed by\nuncertainty achieved an area under curve of 76% and 80% for Monte Carlo Dropout\nand Bayesian Variational Inference, respectively, superior to any\nuncertainty-uninformed baselines with the best one achieving 64%. A novel use\nof uncertainty estimation is proposed for selecting one of multiple data\nacquisitions for further processing and decision making.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T15:48:51Z"}
{"aid":"http://arxiv.org/abs/2504.11319v1","title":"Sensitivity Analysis of State Space Models for Scrap Composition\n  Estimation in EAF and BOF","summary":"This study develops and analyzes linear and nonlinear state space models for\nestimating the elemental composition of scrap steel used in steelmaking, with\napplications to Electric Arc Furnace (EAF) and Basic Oxygen Furnace (BOF)\nprocesses. The models incorporate mass balance equations and are fitted using a\nmodified Kalman filter for linear cases and the Unscented Kalman Filter (UKF)\nfor nonlinear cases. Using Cu and Cr as representative elements, we assess the\nsensitivity of model predictions to measurement noise in key process variables,\nincluding steel mass, steel composition, scrap input mass, slag mass, and iron\noxide fraction in slag. Results show that the models are robust to moderate\nnoise levels in most variables, particularly when errors are below $10\\%$.\nHowever, accuracy significantly deteriorates with noise in slag mass\nestimation. These findings highlight the practical feasibility and limitations\nof applying state space models for real-time scrap composition estimation in\nindustrial settings.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-15T15:59:42Z"}
{"aid":"http://arxiv.org/abs/2504.11329v1","title":"Hunting for Maxwell's Demon in the Wild","summary":"The apparent paradox of Maxwell's demon motivated the development of\ninformation thermodynamics and, more recently, engineering advances enabling\nthe creation of nanoscale information engines. From these advances, it is now\nunderstood that nanoscale machines like the molecular motors within cells can\nin principle operate as Maxwell demons. This motivates the question: does\ninformation help power molecular motors? Answering this would seemingly require\nsimultaneous measurement of all system degrees of freedom, which is generally\nintractable in single-molecule experiments. To overcome this limitation, we\nderive a statistical estimator to infer both the direction and magnitude of\nsubsystem heat flows, and thus to determine whether -- and how strongly -- a\nmotor operates as a Maxwell demon. The estimator uses only trajectory\nmeasurements for a single degree of freedom. We demonstrate the estimator by\napplying it to simulations of an experimental realization of an information\nengine and a kinesin molecular motor. Our results show that kinesin transitions\nto a Maxwell-demon mechanism in the presence of nonequilibrium noise, with a\ncorresponding increase in velocity consistent with experiments. These findings\nsuggest that molecular motors may have evolved to leverage active fluctuations\nwithin cells.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,physics.bio-ph","published":"2025-04-15T16:03:10Z"}
{"aid":"http://arxiv.org/abs/2504.11331v1","title":"Dependency Structure Augmented Contextual Scoping Framework for\n  Multimodal Aspect-Based Sentiment Analysis","summary":"Multimodal Aspect-Based Sentiment Analysis (MABSA) seeks to extract\nfine-grained information from image-text pairs to identify aspect terms and\ndetermine their sentiment polarity. However, existing approaches often fall\nshort in simultaneously addressing three core challenges: Sentiment Cue\nPerception (SCP), Multimodal Information Misalignment (MIM), and Semantic Noise\nElimination (SNE). To overcome these limitations, we propose DASCO\n(\\textbf{D}ependency Structure \\textbf{A}ugmented \\textbf{Sco}ping Framework),\na fine-grained scope-oriented framework that enhances aspect-level sentiment\nreasoning by leveraging dependency parsing trees. First, we designed a\nmulti-task pretraining strategy for MABSA on our base model, combining\naspect-oriented enhancement, image-text matching, and aspect-level\nsentiment-sensitive cognition. This improved the model's perception of aspect\nterms and sentiment cues while achieving effective image-text alignment,\naddressing key challenges like SCP and MIM. Furthermore, we incorporate\ndependency trees as syntactic branch combining with semantic branch, guiding\nthe model to selectively attend to critical contextual elements within a\ntarget-specific scope while effectively filtering out irrelevant noise for\naddressing SNE problem. Extensive experiments on two benchmark datasets across\nthree subtasks demonstrate that DASCO achieves state-of-the-art performance in\nMABSA, with notable gains in JMASA (+3.1\\% F1 and +5.4\\% precision on\nTwitter2015).","main_category":"cs.CL","categories":"cs.CL,cs.MM","published":"2025-04-15T16:05:09Z"}
{"aid":"http://arxiv.org/abs/2504.11380v1","title":"Speak with Confidence: Designing an Augmented Reality Training Tool for\n  Public Speaking","summary":"Public speaking anxiety affects many individuals, yet opportunities for\nreal-world practice remain limited. This study explores how augmented reality\n(AR) can provide an accessible training environment for public speaking.\nDrawing from literature on public speaking, VR-based training, self-efficacy,\nand behavioral feedback mechanisms, we designed SpeakAR, an AR-based tool that\nsimulates audience interaction through virtual models. SpeakAR was evaluated\nwith five participants of varying anxiety levels, each completing six speaking\ntasks. Results indicate that AR exposure can enhance confidence, with\nparticipants finding the system useful for practice. Feedback highlighted the\nimportance of dynamic facial expressions and idle animations in virtual models\nto improve realism and engagement. Our findings contribute to the design of\nAR-based training tools for public speaking, offering insights into how\nimmersive environments can support skill development and anxiety reduction.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-15T16:53:30Z"}
{"aid":"http://arxiv.org/abs/2504.11409v1","title":"Efficient Hybrid Language Model Compression through Group-Aware SSM\n  Pruning","summary":"Hybrid LLM architectures that combine Attention and State Space Models (SSMs)\nachieve state-of-the-art accuracy and runtime performance. Recent work has\ndemonstrated that applying compression and distillation to Attention-only\nmodels yields smaller, more accurate models at a fraction of the training cost.\nIn this work, we explore the effectiveness of compressing Hybrid architectures.\nWe introduce a novel group-aware pruning strategy that preserves the structural\nintegrity of SSM blocks and their sequence modeling capabilities. Furthermore,\nwe demonstrate the necessity of such SSM pruning to achieve improved accuracy\nand inference speed compared to traditional approaches. Our compression recipe\ncombines SSM, FFN, embedding dimension, and layer pruning, followed by\nknowledge distillation-based retraining, similar to the MINITRON technique.\nUsing this approach, we compress the Nemotron-H 8B Hybrid model down to 4B\nparameters with up to 40x fewer training tokens. The resulting model surpasses\nthe accuracy of similarly-sized models while achieving 2x faster inference,\nsignificantly advancing the Pareto frontier.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-15T17:26:29Z"}
{"aid":"http://arxiv.org/abs/2504.11448v1","title":"Full-Diversity Construction-D Lattices: Design and Decoding Perspective\n  on Block-Fading Channels","summary":"This paper introduces a novel framework for constructing algebraic lattices\nbased on Construction-D, leveraging nested linear codes and prime ideals from\nalgebraic number fields. We focus on the application of these lattices in\nblock-fading (BF) channels, which are characterized by piecewise-constant\nfading across blocks of transmitted symbols. This approach results in a\nsemi-systematic generator matrix, providing a structured foundation for\nhigh-dimensional lattice design for BF channels. The proposed Construction-D\nlattices exhibit the full diversity property, making them highly effective for\nerror performance improvement. To address this, we develop an efficient\ndecoding algorithm designed specifically for full-diversity Construction-D\nlattices.\n  Simulations indicate that the proposed lattices notably enhance error\nperformance compared to full-diversity Construction-A lattices in diversity-2\ncases. Interestingly, unlike AWGN channels, the expected performance\nenhancement of Construction-D over Construction-A, resulting from an increased\nnumber of nested code levels, was observed only in the two-level and\ndiversity-2 cases. This phenomenon is likely attributed to the intensified\neffects of error propagation that occur during successive cancellation at\nhigher levels, as well as the higher diversity orders.\n  These findings highlight the promise of Construction-D lattices as an\neffective coding strategy for enhancing communication reliability in BF\nchannels.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-15T17:57:56Z"}
{"aid":"http://arxiv.org/abs/2504.11456v1","title":"DeepMath-103K: A Large-Scale, Challenging, Decontaminated, and\n  Verifiable Mathematical Dataset for Advancing Reasoning","summary":"The capacity for complex mathematical reasoning is a key benchmark for\nartificial intelligence. While reinforcement learning (RL) applied to LLMs\nshows promise, progress is significantly hindered by the lack of large-scale\ntraining data that is sufficiently challenging, possesses verifiable answer\nformats suitable for RL, and is free from contamination with evaluation\nbenchmarks. To address these limitations, we introduce DeepMath-103K, a new,\nlarge-scale dataset comprising approximately 103K mathematical problems,\nspecifically designed to train advanced reasoning models via RL. DeepMath-103K\nis curated through a rigorous pipeline involving source analysis, stringent\ndecontamination against numerous benchmarks, and filtering for high difficulty\n(primarily Levels 5-9), significantly exceeding existing open resources in\nchallenge. Each problem includes a verifiable final answer, enabling rule-based\nRL, and three distinct R1-generated solutions suitable for diverse training\nparadigms like supervised fine-tuning or distillation. Spanning a wide range of\nmathematical topics, DeepMath-103K promotes the development of generalizable\nreasoning. We demonstrate that models trained on DeepMath-103K achieve\nsignificant improvements on challenging mathematical benchmarks, validating its\neffectiveness. We release DeepMath-103K publicly to facilitate community\nprogress in building more capable AI reasoning systems:\nhttps://github.com/zwhe99/DeepMath.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-15T17:59:51Z"}
{"aid":"http://arxiv.org/abs/2504.11752v1","title":"Real-Time Reconstruction of Ground Motion During Small Magnitude\n  Earthquakes: A Pilot Study","summary":"This study presents a pilot investigation into a novel method for\nreconstructing real-time ground motion during small magnitude earthquakes (M <\n4.5), removing the need for computationally expensive source characterization\nand simulation processes to assess ground shaking. Small magnitude earthquakes,\nwhich occur frequently and can be modeled as point sources, provide ideal\nconditions for evaluating real-time reconstruction methods. Utilizing sparse\nobservation data, the method applies the Gappy Auto-Encoder (Gappy AE)\nalgorithm for efficient field data reconstruction. This is the first study to\napply the Gappy AE algorithm to earthquake ground motion reconstruction.\nNumerical experiments conducted with SW4 simulations demonstrate the method's\naccuracy and speed across varying seismic scenarios. The reconstruction\nperformance is further validated using real seismic data from the Berkeley area\nin California, USA, demonstrating the potential for practical application of\nreal-time earthquake data reconstruction using Gappy AE. As a pilot\ninvestigation, it lays the groundwork for future applications to larger and\nmore complex seismic events.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-04-16T04:06:50Z"}
{"aid":"http://arxiv.org/abs/2504.11773v1","title":"TacoDepth: Towards Efficient Radar-Camera Depth Estimation with\n  One-stage Fusion","summary":"Radar-Camera depth estimation aims to predict dense and accurate metric depth\nby fusing input images and Radar data. Model efficiency is crucial for this\ntask in pursuit of real-time processing on autonomous vehicles and robotic\nplatforms. However, due to the sparsity of Radar returns, the prevailing\nmethods adopt multi-stage frameworks with intermediate quasi-dense depth, which\nare time-consuming and not robust. To address these challenges, we propose\nTacoDepth, an efficient and accurate Radar-Camera depth estimation model with\none-stage fusion. Specifically, the graph-based Radar structure extractor and\nthe pyramid-based Radar fusion module are designed to capture and integrate the\ngraph structures of Radar point clouds, delivering superior model efficiency\nand robustness without relying on the intermediate depth results. Moreover,\nTacoDepth can be flexible for different inference modes, providing a better\nbalance of speed and accuracy. Extensive experiments are conducted to\ndemonstrate the efficacy of our method. Compared with the previous\nstate-of-the-art approach, TacoDepth improves depth accuracy and processing\nspeed by 12.8% and 91.8%. Our work provides a new perspective on efficient\nRadar-Camera depth estimation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T05:25:04Z"}
{"aid":"http://arxiv.org/abs/2504.11782v1","title":"HyperKING: Quantum-Classical Generative Adversarial Networks for\n  Hyperspectral Image Restoration","summary":"Quantum machine intelligence starts showing its impact on satellite remote\nsensing (SRS). Also, recent literature exhibits that quantum generative\nintelligences encompass superior potential than their classical counterpart,\nmotivating us to develop quantum generative adversarial networks (GANs) for\nSRS. However, existing quantum GANs are restricted by the limited quantum bit\n(qubit) resources of current quantum computers and process merely a small 2x2\ngrayscale image, far from being applicable to SRS. Recently, the novel concept\nof hybrid quantum-classical GAN, a quantum generator with a classical\ndiscriminator, has upgraded the order to 28x28 (still grayscale), whereas it is\nstill insufficient for SRS. This motivates us to design a radically new hybrid\nframework, where both generator and discriminator are hybrid architectures. We\ndemonstrate this feasibility, leading to a breakthrough of processing 128x128\nhyperspectral images for SRS. Specifically, we design the quantum part with\nmathematically provable quantum full expressibility (FE) to address core signal\nprocessing tasks, wherein the FE property allows the quantum network to realize\nany valid quantum operator with appropriate training. The classical part,\ncomposed of convolutional layers, treats the read-in (compressing the optical\ninformation into limited qubits) and read-out (addressing the quantum collapse\neffect) procedures. The proposed innovative hybrid quantum GAN, named\nHyperspectral Knot-like IntelligeNt dIscrimiNator and Generator (HyperKING),\nwhere knot partly symbolizes the quantum entanglement and partly the compressed\nquantum domain in the central part of the network architecture. HyperKING\nsignificantly surpasses the classical approaches in hyperspectral tensor\ncompletion, mixed noise removal (about 3dB improvement), and blind source\nseparation results.","main_category":"eess.IV","categories":"eess.IV","published":"2025-04-16T05:35:06Z"}
{"aid":"http://arxiv.org/abs/2504.11852v1","title":"A presentation of the pure cactus group of degree four","summary":"We give a simple presentation of the pure cactus group $PJ_4$ of degree four.\nThis presentation is obtained by considering an action of $PJ_4$ on the\nhyperbolic plane and constructing a Dirichlet polygon for the action. As a\ncorollary, we provide a direct alternative proof that $PJ_4$ is isomorphic to\nthe fundamental group of the connected sum of five real projective planes.","main_category":"math.GR","categories":"math.GR,math.GT","published":"2025-04-16T08:20:05Z"}
{"aid":"http://arxiv.org/abs/2504.11879v1","title":"Learning Compatible Multi-Prize Subnetworks for Asymmetric Retrieval","summary":"Asymmetric retrieval is a typical scenario in real-world retrieval systems,\nwhere compatible models of varying capacities are deployed on platforms with\ndifferent resource configurations. Existing methods generally train pre-defined\nnetworks or subnetworks with capacities specifically designed for\npre-determined platforms, using compatible learning. Nevertheless, these\nmethods suffer from limited flexibility for multi-platform deployment. For\nexample, when introducing a new platform into the retrieval systems, developers\nhave to train an additional model at an appropriate capacity that is compatible\nwith existing models via backward-compatible learning. In this paper, we\npropose a Prunable Network with self-compatibility, which allows developers to\ngenerate compatible subnetworks at any desired capacity through post-training\npruning. Thus it allows the creation of a sparse subnetwork matching the\nresources of the new platform without additional training. Specifically, we\noptimize both the architecture and weight of subnetworks at different\ncapacities within a dense network in compatible learning. We also design a\nconflict-aware gradient integration scheme to handle the gradient conflicts\nbetween the dense network and subnetworks during compatible learning. Extensive\nexperiments on diverse benchmarks and visual backbones demonstrate the\neffectiveness of our method. Our code and model are available at\nhttps://github.com/Bunny-Black/PrunNet.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T08:59:47Z"}
{"aid":"http://arxiv.org/abs/2504.11889v1","title":"Rethinking LLM-Based Recommendations: A Query Generation-Based,\n  Training-Free Approach","summary":"Existing large language model LLM-based recommendation methods face several\nchallenges, including inefficiency in handling large candidate pools,\nsensitivity to item order within prompts (\"lost in the middle\" phenomenon) poor\nscalability, and unrealistic evaluation due to random negative sampling. To\naddress these issues, we propose a Query-to-Recommendation approach that\nleverages LLMs to generate personalized queries for retrieving relevant items\nfrom the entire candidate pool, eliminating the need for candidate\npre-selection. This method can be integrated into an ID-based recommendation\nsystem without additional training, enhances recommendation performance and\ndiversity through LLMs' world knowledge, and performs well even for less\npopular item groups. Experiments on three datasets show up to 57 percent\nimprovement, with an average gain of 31 percent, demonstrating strong zero-shot\nperformance and further gains when ensembled with existing models.","main_category":"cs.IR","categories":"cs.IR,cs.CL","published":"2025-04-16T09:17:45Z"}
{"aid":"http://arxiv.org/abs/2504.11895v1","title":"Search is All You Need for Few-shot Anomaly Detection","summary":"Few-shot anomaly detection (FSAD) has emerged as a crucial yet challenging\ntask in industrial inspection, where normal distribution modeling must be\naccomplished with only a few normal images. While existing approaches typically\nemploy multi-modal foundation models combining language and vision modalities\nfor prompt-guided anomaly detection, these methods often demand sophisticated\nprompt engineering and extensive manual tuning. In this paper, we demonstrate\nthat a straightforward nearest-neighbor search framework can surpass\nstate-of-the-art performance in both single-class and multi-class FSAD\nscenarios. Our proposed method, VisionAD, consists of four simple yet essential\ncomponents: (1) scalable vision foundation models that extract universal and\ndiscriminative features; (2) dual augmentation strategies - support\naugmentation to enhance feature matching adaptability and query augmentation to\naddress the oversights of single-view prediction; (3) multi-layer feature\nintegration that captures both low-frequency global context and high-frequency\nlocal details with minimal computational overhead; and (4) a class-aware visual\nmemory bank enabling efficient one-for-all multi-class detection. Extensive\nevaluations across MVTec-AD, VisA, and Real-IAD benchmarks demonstrate\nVisionAD's exceptional performance. Using only 1 normal images as support, our\nmethod achieves remarkable image-level AUROC scores of 97.4%, 94.8%, and 70.8%\nrespectively, outperforming current state-of-the-art approaches by significant\nmargins (+1.6%, +3.2%, and +1.4%). The training-free nature and superior\nfew-shot capabilities of VisionAD make it particularly appealing for real-world\napplications where samples are scarce or expensive to obtain. Code is available\nat https://github.com/Qiqigeww/VisionAD.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T09:21:34Z"}
{"aid":"http://arxiv.org/abs/2504.11933v1","title":"Lifelong and Universal Machine Learning Potentials for Chemical Reaction\n  Network Explorations","summary":"Recent developments in computational chemistry facilitate the automated\nquantum chemical exploration of chemical reaction networks for the in-silico\nprediction of synthesis pathways, yield, and selectivity. However, the\nunderlying quantum chemical energy calculations require vast computational\nresources, limiting these explorations severely in practice. Machine learning\npotentials (MLPs) offer a solution to increase computational efficiency, while\nretaining the accuracy of reliable first-principles data used for their\ntraining. Unfortunately, MLPs will be limited in their generalization ability\nwithin chemical (reaction) space, if the underlying training data is not\nrepresentative for a given application. Within the framework of automated\nreaction network exploration, where new reactants or reagents composed of any\nelements from the periodic table can be introduced, this lack of\ngeneralizability will be the rule rather than the exception. Here, we therefore\nstudy the benefits and drawbacks of two MLP concepts in this context. Whereas\nuniversal MLPs are designed to cover most of the relevant chemical space in\ntheir training, lifelong MLPs push their adaptability by efficient continual\nlearning of additional data. While the accuracy of the universal MLPs turns out\nto be not yet sufficient for reaction search trials without any fine-tuning,\nlifelong MLPs can reach chemical accuracy. We propose an improved learning\nalgorithm for lifelong adaptive data selection yielding efficient integration\nof new data while previous expertise is preserved.","main_category":"physics.chem-ph","categories":"physics.chem-ph,physics.comp-ph","published":"2025-04-16T10:12:08Z"}
{"aid":"http://arxiv.org/abs/2504.11991v1","title":"Non-Markovian Quantum Master and Fokker-Planck Equation for\n  Gravitational Systems and Gravitational Decoherence","summary":"A quantum master equation describing the stochastic dynamics of a quantum\nmassive system interacting with a quantum gravitational field is useful for the\ninvestigation of quantum gravitational and quantum informational issues such as\nthe quantum nature of gravity, gravity-induced entanglement and gravitational\ndecoherence. Studies of the decoherence of quantum systems by an\nelectromagnetic field shows that a lower temperature environment is more\nconducive to successful quantum information processing experiments. Likewise,\nthe quantum nature of (perturbative) gravity is far better revealed at lower\ntemperatures than high, minimizing the corruptive effects of thermal noise. In\nthis work, generalizing earlier results of the Markovian ABH master equation\n[1,2] which is valid only for high temperatures, we derive a non-Markovian\nquantum master equation for the reduced density matrix, and the associated\nFokker-Planck equation for the Wigner distribution function, for the stochastic\ndynamics of two masses following quantum trajectories, interacting with a\ngraviton field, including the effects of graviton noise, valid for all\ntemperatures. We follow the influence functional approach exemplified in the\nderivation of the non-Markovian Hu-Paz-Zhang master equation [62,64] for\nquantum Brownian motion. We find that in the low temperature limit, the\noff-diagonal elements of the reduced density matrix decrease in time\nlogarithmically for the zero temperature part and quadratically in time for the\ntemperature-dependent part, which is distinctly different from the Markovian\ncase. We end with a summary of our findings and a discussion on how this\nproblem studied here is related to the quantum stochastic equation derived in\n[77] for gravitational self force studies, and to quantum optomechanics where\nexperimental observation of gravitational decoherence and entanglement may be\nimplemented.","main_category":"gr-qc","categories":"gr-qc,cond-mat.stat-mech,hep-th,quant-ph","published":"2025-04-16T11:33:23Z"}
{"aid":"http://arxiv.org/abs/2504.12008v1","title":"Global Patterns of Extreme Temperature Teleconnections Using Climate\n  Network Analysis","summary":"Extreme weather events, rare yet profoundly impactful, are often accompanied\nby severe conditions. Increasing global temperatures are poised to exacerbate\nthese events, resulting in greater human casualties, economic losses, and\necological destruction. Complex global climate interactions, known as\nteleconnections, can lead to widespread repercussions triggered by localized\nextreme weather. Understanding these teleconnection patterns is crucial for\nweather forecasting, enhancing safety, and advancing climate science. Here, we\nemploy climate network analysis to uncover teleconnection patterns associated\nwith extreme temperature fluctuations, including both extreme warming and\ncooling events occurring on a daily basis. Our study results demonstrate that\nthe distances of significant teleconnections initially conform to a power-law\ndecay, signifying a decline in connectivity with distance. However, this\npower-law decay tendency breaks beyond a certain threshold distance, suggesting\nthe existence of long-distance connections. Additionally, we uncover a greater\nprevalence of long-distance connectivity among extreme cooling events compared\nto extreme warming events. The global pattern of teleconnections is, in part,\ndriven by the mechanism of Rossby waves, which serve as a rapid conduit for\ninducing correlated fluctuations in both pressure and temperature. These\nresults enhance our understanding of the multiscale nature of climate\nteleconnections and hold significant implications for improving weather\nforecasting and assessing climate risks in a warming world.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-16T12:05:15Z"}
{"aid":"http://arxiv.org/abs/2504.12018v1","title":"Instruction-augmented Multimodal Alignment for Image-Text and Element\n  Matching","summary":"With the rapid advancement of text-to-image (T2I) generation models,\nassessing the semantic alignment between generated images and text descriptions\nhas become a significant research challenge. Current methods, including those\nbased on Visual Question Answering (VQA), still struggle with fine-grained\nassessments and precise quantification of image-text alignment. This paper\npresents an improved evaluation method named Instruction-augmented Multimodal\nAlignment for Image-Text and Element Matching (iMatch), which evaluates\nimage-text semantic alignment by fine-tuning multimodal large language models.\nWe introduce four innovative augmentation strategies: First, the QAlign\nstrategy creates a precise probabilistic mapping to convert discrete scores\nfrom multimodal large language models into continuous matching scores. Second,\na validation set augmentation strategy uses pseudo-labels from model\npredictions to expand training data, boosting the model's generalization\nperformance. Third, an element augmentation strategy integrates element\ncategory labels to refine the model's understanding of image-text matching.\nFourth, an image augmentation strategy employs techniques like random lighting\nto increase the model's robustness. Additionally, we propose prompt type\naugmentation and score perturbation strategies to further enhance the accuracy\nof element assessments. Our experimental results show that the iMatch method\nsignificantly surpasses existing methods, confirming its effectiveness and\npractical value. Furthermore, our iMatch won first place in the CVPR NTIRE 2025\nText to Image Generation Model Quality Assessment - Track 1 Image-Text\nAlignment.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T12:21:49Z"}
{"aid":"http://arxiv.org/abs/2504.12021v1","title":"Action Anticipation from SoccerNet Football Video Broadcasts","summary":"Artificial intelligence has revolutionized the way we analyze sports videos,\nwhether to understand the actions of games in long untrimmed videos or to\nanticipate the player's motion in future frames. Despite these efforts, little\nattention has been given to anticipating game actions before they occur. In\nthis work, we introduce the task of action anticipation for football broadcast\nvideos, which consists in predicting future actions in unobserved future\nframes, within a five- or ten-second anticipation window. To benchmark this\ntask, we release a new dataset, namely the SoccerNet Ball Action Anticipation\ndataset, based on SoccerNet Ball Action Spotting. Additionally, we propose a\nFootball Action ANticipation TRAnsformer (FAANTRA), a baseline method that\nadapts FUTR, a state-of-the-art action anticipation model, to predict\nball-related actions. To evaluate action anticipation, we introduce new\nmetrics, including mAP@$\\delta$, which evaluates the temporal precision of\npredicted future actions, as well as mAP@$\\infty$, which evaluates their\noccurrence within the anticipation window. We also conduct extensive ablation\nstudies to examine the impact of various task settings, input configurations,\nand model architectures. Experimental results highlight both the feasibility\nand challenges of action anticipation in football videos, providing valuable\ninsights into the design of predictive models for sports analytics. By\nforecasting actions before they unfold, our work will enable applications in\nautomated broadcasting, tactical analysis, and player decision-making. Our\ndataset and code are publicly available at\nhttps://github.com/MohamadDalal/FAANTRA.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T12:24:33Z"}
{"aid":"http://arxiv.org/abs/2504.12024v1","title":"Giant Exciton Transport in hBN/2D-Perovskite Heterostructures","summary":"Two-dimensional perovskites, such as Ruddlesden-Popper perovskites, exhibit\noutstanding optical properties and high exciton binding energies but are highly\nsusceptible to degradation under photo- and electron-beam exposure. To overcome\nthis limitation, we encapsulate the perovskites with mechanically exfoliated\nhexagonal boron nitride flakes, forming hexagonal boron nitride/perovskite\nheterostructures. Cathodoluminescence spectroscopy reveals that these\nheterostructures exhibit significantly reduced electron-beam-induced\ndegradation, enhanced luminescence intensity, a narrower emission bandwidth,\nand an extended exciton decay time. Moreover, leveraging the scanning\ncapability of our fiber-based cathodoluminescence spectroscopy technique, we\ndemonstrate ultra-long-range exciton transport over distances of approximately\n150 micrometers, attributed to exciton-defect coupling. This exciton-defect\ninteraction not only enhances luminescence but also highlights the potential of\nhexagonal boron nitride/perovskite heterostructures as hybrid van-der-Waals\nsystems with long-range exciton transport and slow radiative decay rates,\npaving the way for robust and efficient optoelectronic applications.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-16T12:29:57Z"}
{"aid":"http://arxiv.org/abs/2504.12044v1","title":"Anatomy of the simplest renormalon","summary":"Perhaps the simplest IR renormalon occurs in the ground state energy of a\nsuperrenormalizable model, the scalar $O(N)$ theory in two dimensions with a\nquartic potential and negative squared mass. We show that this renormalon,\nfound previously in perturbation theory at next-to-leading order (NLO) in the\n$1/N$ expansion, gives indeed the correct asymptotic expansion of the exact\nlarge $N$ solution of the model, and we determine explicitly the complete\ntrans-series of non-perturbative corrections to the perturbative result. We\nalso use this framework to study the $O(N)$-invariant two-point function of the\nscalar field. As expected, it is IR finite in perturbation theory, but it is\nafflicted as well with an IR renormalon singularity and is not Borel summable.\nThe pole mass is purely non-perturbative and its trans-series can be also fully\ndetermined at NLO in $1/N$","main_category":"hep-th","categories":"hep-th","published":"2025-04-16T13:00:45Z"}
{"aid":"http://arxiv.org/abs/2504.12046v1","title":"The Dynamic Inner Disk of a Planet Forming Star","summary":"Planets are a natural byproduct of the stellar formation process, resulting\nfrom local aggregations of material within the disks surrounding young stars.\nWhereas signatures of gas-giant planets at large orbital separations have been\nobserved and successfully modeled within protoplanetary disks, the formation\npathways of planets within their host star's future habitable zones remain\npoorly understood. Analyzing multiple nights of observations conducted over a\nshort, two-month span with the MIRC-X and PIONIER instruments at the CHARA\nArray and VLTI, respectively, we uncover a highly active environment at the\ninner-edge of the planet formation region in the disk of HD 163296. In\nparticular, we localize and track the motion of a disk feature near the\ndust-sublimation radius with a pattern speed of less than half the local\nKeplerian velocity, providing a potential glimpse at the planet formation\nprocess in action within the inner astronomical unit. We emphasize that this\nresult is at the edge of what is currently possible with available optical\ninterferometric techniques and behooves confirmation with a temporally dense\nfollowup observing campaign.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP","published":"2025-04-16T13:03:30Z"}
{"aid":"http://arxiv.org/abs/2504.12061v1","title":"A survey on orderability and contact non-squeezing","summary":"The present article provides an overview of Yakov Eliashberg's seminal\ncontributions to the concepts of orderability and contact non-squeezing. It\nalso examines subsequent research by various authors, highlighting the\nsignificance of these notions and offering a detailed account of the current\nstate of the field.","main_category":"math.SG","categories":"math.SG","published":"2025-04-16T13:16:35Z"}
{"aid":"http://arxiv.org/abs/2504.12065v1","title":"Numerical and Analytical Study of the Magnetic Field Distribution in a\n  Three-Solenoid System","summary":"This paper investigates the magnetic fields produced by a three-coil system,\nfocusing on how different mesh resolutions affect the accuracy of the results.\nUsing both the Poisson solver, as well as a numerical approach based on the\nsolution of fractional integrals, the study examines coils with dimensions of\n80 mm by 160 mm and a radius of 15.5 mm, each carrying a current of 200 A. The\nresearch explores how varying mesh step sizes within the coil regions\ninfluences the simulations accuracy and convergence. The results are analyzed\nalong a line parallel to the central axis at a distance equal to half of the\nsolenoid's radius.. The findings emphasize the consistency of the numerical\nresults, the compatibility of the solvers, and offer insights into further\noptimization strategies for more efficient simulations.","main_category":"physics.acc-ph","categories":"physics.acc-ph","published":"2025-04-16T13:20:36Z"}
{"aid":"http://arxiv.org/abs/2504.12073v1","title":"Unconventional and anomalous magnetic field distribution in a bilayer\n  superconductor with geometric constraints","summary":"We investigate the magnetic field distribution in multi-component\nsuperconductors. We examine a layered superconductor and a two-component\none-layer superconductor. We evaluate the field distribution in the presence of\na half-flux quantum vortex with a kink structure in the phase space of gap\nfunctions. We also examine the magnetic field distribution of a knot soliton\nwhich is formulated in a two-component superconductor. We investigate the\neffect of geometric constraints for multi-component superconductors, where the\ngeometric constraint means that the system is compactified in one direction so\nthat the current in this direction becomes vanishingly small. This corresponds\nto the gauge fixing in this direction. An unconventional magnetic field\ndistribution takes place; here the unconventional means that the magnetic field\nis screened incompletely which would be called the anomalous Meissner effect.\nWe argue that this anomalous behavior creates a massless gauge field.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-16T13:29:40Z"}
{"aid":"http://arxiv.org/abs/2504.12083v1","title":"Self-alignment of Large Video Language Models with Refined Regularized\n  Preference Optimization","summary":"Despite recent advances in Large Video Language Models (LVLMs), they still\nstruggle with fine-grained temporal understanding, hallucinate, and often make\nsimple mistakes on even simple video question-answering tasks, all of which\npose significant challenges to their safe and reliable deployment in real-world\napplications. To address these limitations, we propose a self-alignment\nframework that enables LVLMs to learn from their own errors. Our proposed\nframework first obtains a training set of preferred and non-preferred response\npairs, where non-preferred responses are generated by incorporating common\nerror patterns that often occur due to inadequate spatio-temporal\nunderstanding, spurious correlations between co-occurring concepts, and\nover-reliance on linguistic cues while neglecting the vision modality, among\nothers. To facilitate self-alignment of LVLMs with the constructed preferred\nand non-preferred response pairs, we introduce Refined Regularized Preference\nOptimization (RRPO), a novel preference optimization method that utilizes\nsub-sequence-level refined rewards and token-wise KL regularization to address\nthe limitations of Direct Preference Optimization (DPO). We demonstrate that\nRRPO achieves more precise alignment and more stable training compared to DPO.\nOur experiments and analysis validate the effectiveness of our approach across\ndiverse video tasks, including video hallucination, short- and long-video\nunderstanding, and fine-grained temporal reasoning.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T13:43:56Z"}
{"aid":"http://arxiv.org/abs/2504.12101v1","title":"Disjoint Ces$\\grave{A}$ro-hypercyclic operators","summary":"In this paper, we investigate the properties of disjoint\nCes$\\grave{a}$ro-hypercyclic operators. First, the definition of disjoint\nCes$\\grave{a}$ro-hypercyclic operators is provided, and disjoint\nCes$\\grave{a}$ro-Hypercyclicity Criterion is proposed. Later, two methods are\nused to prove that operators satisfying this criterion possess disjoint\nCes$\\grave{a}$ro-hypercyclicity. Finally, this paper further investigates\nweighted shift operators and provides detailed characterizations of the weight\nsequences for disjoint Ces$\\grave{a}$ro-hypercyclic unilateral and bilateral\nweighted shift operators on sequence spaces.","main_category":"math.FA","categories":"math.FA","published":"2025-04-16T14:05:44Z"}
{"aid":"http://arxiv.org/abs/2504.12104v1","title":"Logits DeConfusion with CLIP for Few-Shot Learning","summary":"With its powerful visual-language alignment capability, CLIP performs well in\nzero-shot and few-shot learning tasks. However, we found in experiments that\nCLIP's logits suffer from serious inter-class confusion problems in downstream\ntasks, and the ambiguity between categories seriously affects the accuracy. To\naddress this challenge, we propose a novel method called Logits DeConfusion,\nwhich effectively learns and eliminates inter-class confusion in logits by\ncombining our Multi-level Adapter Fusion (MAF) module with our Inter-Class\nDeconfusion (ICD) module. Our MAF extracts features from different levels and\nfuses them uniformly to enhance feature representation. Our ICD learnably\neliminates inter-class confusion in logits with a residual structure.\nExperimental results show that our method can significantly improve the\nclassification performance and alleviate the inter-class confusion problem. The\ncode is available at https://github.com/LiShuo1001/LDC.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T14:12:56Z"}
{"aid":"http://arxiv.org/abs/2504.12120v1","title":"Logarithmic Spectral Distribution of a non-Hermitian $$-Ensemble","summary":"We introduce a non-Hermitian $\\beta$-ensemble and determine its spectral\ndensity in the limit of large $\\beta$ and large matrix size $n$. The ensemble\nis given by a general tridiagonal complex random matrix of normal and\nchi-distributed random variables, extending previous work of two of the\nauthors. The joint distribution of eigenvalues contains a Vandermonde\ndeterminant to the power $\\beta$ and a residual coupling to the eigenvectors. A\ntool in the computation of the limiting spectral density is a single\ncharacteristic polynomial for centred tridiagonal Jacobi matrices, for which we\nexplicitly determine the coefficients in terms of its matrix elements. In the\nlow temperature limit $\\beta\\gg1$ our ensemble reduces to such a centred matrix\nwith vanishing diagonal. A general theorem from free probability based on the\nvariance of the coefficients of the characteristic polynomial allows us to\nobtain the spectral density when additionally taking the large-$n$ limit. It is\nrotationally invariant on a compact disc, given by the logarithm of the radius\nplus a constant. The same density is obtained when starting form a tridiagonal\ncomplex symmetric ensemble, which thus plays a special role. Extensive\nnumerical simulations confirm our analytical results and put this and the\npreviously studied ensemble in the context of the pseudospectrum.","main_category":"math-ph","categories":"math-ph,cond-mat.stat-mech,math.MP,math.PR","published":"2025-04-16T14:33:46Z"}
{"aid":"http://arxiv.org/abs/2504.12149v1","title":"Study on charmonium(-like) mesons within a diabatic approach","summary":"In this work, we study the charmonium(-like) spectrum below 4.1 GeV using the\ndiabatic approach, which offers a unified description of conventional and\nunconventional heavy meson states. Compared to previous studies, we consider a\nmore realistic $c\\bar c$ potential with including the spin-dependent\ninteractions, which allows us to obtain more states and get more insights on\nthe charmonium spectrum. Based on our calculation, we obtain the masses of the\ncharmonium spectrum which align with the experimental data well. We also\npresent the probabilities of finding various components, i.e. $c\\bar c$ or\nmeson-meson pair, in those states. Our results support the arguments that the\n$\\chi_{c1}(3872)$, $\\psi(4040)$ and $\\chi_{c2}(3930)$ have significant\nmolecular components. In addition, our calculations show that the\n$\\chi_{c0}(3860)$ and $\\psi(3770)$ can be looked as the candidates for the\ncharmonium states $\\chi_{c0}(2P)$ and $\\psi(1D)$, respectively.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-16T14:57:29Z"}
{"aid":"http://arxiv.org/abs/2504.12171v1","title":"Traveling wave profiles for a semi-discrete Burgers equation","summary":"We look for traveling waves of the semi-discrete conservation law $4\\dot u_j\n+u_{j+1}^2-u_{j-1}^2 = 0$, using variational principles related to concepts of\n``hidden convexity'' appearing in recent studies of various PDE (partial\ndifferential equations). We analyze and numerically compute with two\nvariational formulations related to dual convex optimization problems\nconstrained by either the differential-difference equation (DDE) or nonlinear\nintegral equation (NIE) that wave profiles should satisfy. We prove existence\ntheorems conditional on the existence of extrema that satisfy a strict\nconvexity criterion, and numerically exhibit a variety of localized, periodic\nand non-periodic wave phenomena.","main_category":"math.AP","categories":"math.AP,cs.NA,math.NA,nlin.PS","published":"2025-04-16T15:23:43Z"}
{"aid":"http://arxiv.org/abs/2504.12209v1","title":"Evidence for a polar circumbinary exoplanet orbiting a pair of eclipsing\n  brown dwarfs","summary":"One notable example of exoplanet diversity is the population of circumbinary\nplanets, which orbit around both stars of a binary star system. There are so\nfar only 16 known circumbinary exoplanets, all of which lie in the same orbital\nplane as the host binary. Suggestions exist that circumbinary planets could\nalso exist on orbits highly inclined to the binary, close to 90$^{\\circ}$,\npolar orbits. No such planets have been found yet but polar circumbinary gas\nand debris discs have been observed and if these were to form planets then\nthose would be left on a polar orbit. We report strong evidence for a polar\ncircumbinary exoplanet, which orbits a close pair of brown dwarfs which are on\nan eccentric orbit. We use radial-velocities to measure a retrograde apsidal\nprecession for the binary, and show that this can only be attributed to the\npresence of a polar planet.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-04-16T15:56:57Z"}
{"aid":"http://arxiv.org/abs/2504.12216v1","title":"d1: Scaling Reasoning in Diffusion Large Language Models via\n  Reinforcement Learning","summary":"Recent large language models (LLMs) have demonstrated strong reasoning\ncapabilities that benefits from online reinforcement learning (RL). These\ncapabilities have primarily been demonstrated within the left-to-right\nautoregressive (AR) generation paradigm. In contrast, non-autoregressive\nparadigms based on diffusion generate text in a coarse-to-fine manner. Although\nrecent diffusion-based large language models (dLLMs) have achieved competitive\nlanguage modeling performance compared to their AR counterparts, it remains\nunclear if dLLMs can also leverage recent advances in LLM reasoning. To this\nend, we propose d1, a framework to adapt pre-trained masked dLLMs into\nreasoning models via a combination of supervised finetuning (SFT) and RL.\nSpecifically, we develop and extend techniques to improve reasoning in\npretrained dLLMs: (a) we utilize a masked SFT technique to distill knowledge\nand instill self-improvement behavior directly from existing datasets, and (b)\nwe introduce a novel critic-free, policy-gradient based RL algorithm called\ndiffu-GRPO. Through empirical studies, we investigate the performance of\ndifferent post-training recipes on multiple mathematical and logical reasoning\nbenchmarks. We find that d1 yields the best performance and significantly\nimproves performance of a state-of-the-art dLLM.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-16T16:08:45Z"}
{"aid":"http://arxiv.org/abs/2504.12227v1","title":"A remark on Euler-like vector fields","summary":"In this note, we show that (the germ of) each Euler-like vector field comes\nfrom a tubular neighborhood embedding given by the normal exponential map of\nsome Riemannian metric.","main_category":"math.DG","categories":"math.DG","published":"2025-04-16T16:22:43Z"}
{"aid":"http://arxiv.org/abs/2504.12235v1","title":"Rotating Topological Stars","summary":"We construct a three-parameter family of smooth and horizonless rotating\nsolutions of Einstein-Maxwell theory with Chern-Simons term in five dimensions\nand discuss their stringy origin in terms of three-charge brane systems in Type\nIIB and M-theory. The general solution interpolates smoothly between Kerr and\nstatic Topological Star geometries. We show that for specific choices of the\nparameters and quantized values of the angular momentum the geometry terminates\non a smooth five-dimensional cap, and it displays neither ergoregion nor closed\ntimelike curves and a region of Gregory-Laflamme stability. We discuss the\ndimensional reduction to four dimensions and the propagation of particles and\nwaves showing that geodetic motion is integrable and the radial and angular\npropagation of scalar perturbations can be separated and described in terms of\ntwo ordinary differential equations of confluent Heun type.","main_category":"hep-th","categories":"hep-th","published":"2025-04-16T16:35:22Z"}
{"aid":"http://arxiv.org/abs/2504.12245v1","title":"SIDME: Self-supervised Image Demoiring via Masked Encoder-Decoder\n  Reconstruction","summary":"Moir\\'e patterns, resulting from aliasing between object light signals and\ncamera sampling frequencies, often degrade image quality during capture.\nTraditional demoir\\'eing methods have generally treated images as a whole for\nprocessing and training, neglecting the unique signal characteristics of\ndifferent color channels. Moreover, the randomness and variability of moir\\'e\npattern generation pose challenges to the robustness of existing methods when\napplied to real-world data. To address these issues, this paper presents SIDME\n(Self-supervised Image Demoir\\'eing via Masked Encoder-Decoder Reconstruction),\na novel model designed to generate high-quality visual images by effectively\nprocessing moir\\'e patterns. SIDME combines a masked encoder-decoder\narchitecture with self-supervised learning, allowing the model to reconstruct\nimages using the inherent properties of camera sampling frequencies. A key\ninnovation is the random masked image reconstructor, which utilizes an\nencoder-decoder structure to handle the reconstruction task. Furthermore, since\nthe green channel in camera sampling has a higher sampling frequency compared\nto red and blue channels, a specialized self-supervised loss function is\ndesigned to improve the training efficiency and effectiveness. To ensure the\ngeneralization ability of the model, a self-supervised moir\\'e image generation\nmethod has been developed to produce a dataset that closely mimics real-world\nconditions. Extensive experiments demonstrate that SIDME outperforms existing\nmethods in processing real moir\\'e pattern data, showing its superior\ngeneralization performance and robustness.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-16T16:50:41Z"}
{"aid":"http://arxiv.org/abs/2504.12246v1","title":"Branching Bisimulation Learning","summary":"We introduce a bisimulation learning algorithm for non-deterministic\ntransition systems. We generalise bisimulation learning to systems with bounded\nbranching and extend its applicability to model checking branching-time\ntemporal logic, while previously it was limited to deterministic systems and\nmodel checking linear-time properties. Our method computes a finite\nstutter-insensitive bisimulation quotient of the system under analysis,\nrepresented as a decision tree. We adapt the proof rule for well-founded\nbisimulations to an iterative procedure that trains candidate decision trees\nfrom sample transitions of the system, and checks their validity over the\nentire transition relation using SMT solving. This results in a new technology\nfor model checking CTL* without the next-time operator. Our technique is sound,\nentirely automated, and yields abstractions that are succinct and effective for\nformal verification and system diagnostics. We demonstrate the efficacy of our\nmethod on diverse benchmarks comprising concurrent software, communication\nprotocols and robotic scenarios. Our method performs comparably to mature tools\nin the special case of LTL model checking, and outperforms the state of the art\nin CTL and CTL* model checking for systems with very large and countably\ninfinite state space.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-16T16:52:07Z"}
{"aid":"http://arxiv.org/abs/2504.12260v1","title":"On resolution of L1-norm minimization via a two-metric adaptive\n  projection method","summary":"The two-metric projection method is a simple yet elegant algorithm proposed\nby Bertsekas\n  to address bound/box-constrained optimization problems. The algorithm's low\nper-iteration\n  cost and potential for using Hessian information make it a favorable\ncomputation method\n  for this problem class. Inspired by this algorithm, we propose a two-metric\nadaptive projection\n  method for solving the $\\ell_1$-norm regularization problem that inherits\nthese advantages. We demonstrate that the method is theoretically sound -\n  it has global convergence. Furthermore, it is capable of manifold\nidentification and has\n  superlinear convergence rate under the error bound condition and strict\ncomplementarity.\n  Therefore, given sparsity in the solution, the method enjoys superfast\nconvergence in iteration\n  while maintaining scalability, making it desirable for large-scale problems.\nWe also equip\n  the algorithm with competitive complexity to solve nonconvex problems.\nNumerical experiments\n  are conducted to illustrate the advantages of this algorithm implied by the\ntheory compared\n  to other competitive methods, especially in large-scale scenarios. In\ncontrast to the original two-metric projection method, our algorithm directly\nsolves the $\\ell_1$-norm minimization problem without resorting to the\nintermediate reformulation as a bound-constrained problem, so it circumvents\nthe issue of numerical instability.","main_category":"math.OC","categories":"math.OC","published":"2025-04-16T17:11:39Z"}
{"aid":"http://arxiv.org/abs/2504.12606v1","title":"Robo-SGG: Exploiting Layout-Oriented Normalization and Restitution for\n  Robust Scene Graph Generation","summary":"In this paper, we introduce a novel method named Robo-SGG, i.e.,\nLayout-Oriented Normalization and Restitution for Robust Scene Graph\nGeneration. Compared to the existing SGG setting, the robust scene graph\ngeneration aims to perform inference on a diverse range of corrupted images,\nwith the core challenge being the domain shift between the clean and corrupted\nimages. Existing SGG methods suffer from degraded performance due to\ncompromised visual features e.g., corruption interference or occlusions. To\nobtain robust visual features, we exploit the layout information, which is\ndomain-invariant, to enhance the efficacy of existing SGG methods on corrupted\nimages. Specifically, we employ Instance Normalization(IN) to filter out the\ndomain-specific feature and recover the unchangeable structural features, i.e.,\nthe positional and semantic relationships among objects by the proposed\nLayout-Oriented Restitution. Additionally, we propose a Layout-Embedded Encoder\n(LEE) that augments the existing object and predicate encoders within the SGG\nframework, enriching the robust positional and semantic features of objects and\npredicates. Note that our proposed Robo-SGG module is designed as a\nplug-and-play component, which can be easily integrated into any baseline SGG\nmodel. Extensive experiments demonstrate that by integrating the\nstate-of-the-art method into our proposed Robo-SGG, we achieve relative\nimprovements of 5.6%, 8.0%, and 6.5% in mR@50 for PredCls, SGCls, and SGDet\ntasks on the VG-C dataset, respectively, and achieve new state-of-the-art\nperformance in corruption scene graph generation benchmark (VG-C and GQA-C). We\nwill release our source code and model.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-17T03:09:22Z"}
{"aid":"http://arxiv.org/abs/2504.12609v1","title":"Crossing the Human-Robot Embodiment Gap with Sim-to-Real RL using One\n  Human Demonstration","summary":"Teaching robots dexterous manipulation skills often requires collecting\nhundreds of demonstrations using wearables or teleoperation, a process that is\nchallenging to scale. Videos of human-object interactions are easier to collect\nand scale, but leveraging them directly for robot learning is difficult due to\nthe lack of explicit action labels from videos and morphological differences\nbetween robot and human hands. We propose Human2Sim2Robot, a novel\nreal-to-sim-to-real framework for training dexterous manipulation policies\nusing only one RGB-D video of a human demonstrating a task. Our method utilizes\nreinforcement learning (RL) in simulation to cross the human-robot embodiment\ngap without relying on wearables, teleoperation, or large-scale data collection\ntypically necessary for imitation learning methods. From the demonstration, we\nextract two task-specific components: (1) the object pose trajectory to define\nan object-centric, embodiment-agnostic reward function, and (2) the\npre-manipulation hand pose to initialize and guide exploration during RL\ntraining. We found that these two components are highly effective for learning\nthe desired task, eliminating the need for task-specific reward shaping and\ntuning. We demonstrate that Human2Sim2Robot outperforms object-aware open-loop\ntrajectory replay by 55% and imitation learning with data augmentation by 68%\nacross grasping, non-prehensile manipulation, and multi-step tasks. Project\nSite: https://human2sim2robot.github.io","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-17T03:15:20Z"}
{"aid":"http://arxiv.org/abs/2504.12617v1","title":"Bayesian Density-Density Regression with Application to Cell-Cell\n  Communications","summary":"We introduce a scalable framework for regressing multivariate distributions\nonto multivariate distributions, motivated by the application of inferring\ncell-cell communication from population-scale single-cell data. The observed\ndata consist of pairs of multivariate distributions for ligands from one cell\ntype and corresponding receptors from another. For each ordered pair $e=(l,r)$\nof cell types $(l \\neq r)$ and each sample $i = 1, \\ldots, n$, we observe a\npair of distributions $(F_{ei}, G_{ei})$ of gene expressions for ligands and\nreceptors of cell types $l$ and $r$, respectively. The aim is to set up a\nregression of receptor distributions $G_{ei}$ given ligand distributions\n$F_{ei}$. A key challenge is that these distributions reside in distinct spaces\nof differing dimensions. We formulate the regression of multivariate densities\non multivariate densities using a generalized Bayes framework with the sliced\nWasserstein distance between fitted and observed distributions. Finally, we use\ninference under such regressions to define a directed graph for cell-cell\ncommunications.","main_category":"stat.ME","categories":"stat.ME,stat.AP,stat.CO,stat.ML","published":"2025-04-17T03:46:03Z"}
{"aid":"http://arxiv.org/abs/2504.12618v1","title":"Simultaneous Superoscillations in Space and Time in Nonseparable Light\n  Pulses","summary":"A remarkable phenomenon of superoscillations implies that electromagnetic\nwaves can locally oscillate in space or time faster than the fastest spatial\nand temporal Fourier component of the entire function. This phenomenon allows\nto focus light into an arbitrary small hotspot enabling superresolution imaging\nand optical metrology with accuracy far beyond the Abbey-Reileigh diffraction\nlimit. Here we show that, in band-limited supertoroidal light pulses, the\ntemporal and spatial superoscillations can be observed simultaneously at a\nspecific region in space and at a specific interval in time.","main_category":"physics.optics","categories":"physics.optics,physics.class-ph","published":"2025-04-17T03:47:11Z"}
{"aid":"http://arxiv.org/abs/2504.12622v1","title":"Can metric radio bursts be used as a diagnostics tool for interplanetary\n  coronal mass ejections?","summary":"Metric radio bursts are often said to be valuable diagnostic tools for\nstudying the near-sun kinematics and energetics of the Interplanetary Coronal\nMass Ejections (ICMEs). Radio observations also serve as an indirect tool to\nestimate the coronal magnetic fields. However, how these estimated coronal\nmagnetic fields are related to the magnetic field strength in the ICME at 1 AU\nhas rarely been explored. We aim to establish a relation between the coronal\nmagnetic fields obtained from the radio observations very close to the Sun and\nthe magnetic field measured at 1 AU when the ICME arrives at the Earth. We\nperformed statistical analysis of all metric type II radio bursts in solar\ncycles 23 and 24, which were found to be associated with ICMEs. We estimated\nthe coronal magnetic field associated with the corresponding CME near the Sun\n(middle corona) using a split-band radio technique and compared those with the\nmagnetic fields recorded at 1 AU with in-situ observations. We found that the\nestimated magnetic fields near the Sun using radio techniques are not well\ncorrelated with the magnetic fields measured at 1 AU using in-situ\nobservations. This could be due to the complex evolution of the magnetic field\nas it propagates through the heliosphere. Our results suggest that while metric\nradio observations can serve as effective proxies for estimating magnetic\nfields near the Sun, they may not be as effective close to the Earth. At least,\nno linear relation could be established using metric radio emissions to\nestimate the magnetic fields at 1 AU with acceptable error margins.","main_category":"astro-ph.SR","categories":"astro-ph.SR,physics.space-ph","published":"2025-04-17T03:55:30Z"}
{"aid":"http://arxiv.org/abs/2504.12630v1","title":"Crystal growth, structure and physical properties of\n  quasi-one-dimensional tellurides Fe$_{4-x}$VTe$_{4-y}$ ($x=1.01$, $y=0.74$)\n  and V$_{4.64}$Te$_4$","summary":"A new ternary compound Fe$_{4-x}$VTe$_{4-y}$ ($x=1.01$, $y=0.74$) with\nTi5Te4-type structure is identified. Fe and V atoms tend to occupy different\ncrystallographic positions and form quasi-one-dimensional (quasi-1D) Fe-V\nchains along the c-axis. Millimeter-sized single crystal of\nFe$_{2.99}$VTe$_{3.26}$ (FVT) with slender-stick shape could be grown by\nchemical vapor transport method which reflects its quasi-1D crystal structure.\nMagnetization measurements reveal that FVT orders antiferromagnetically below\nT$_N$=93 K with strong easy ab-plane magnetic anisotropy. Although a weak\nglassy-like behavior appears below 10 K, FVT is dominant by long-range\nantiferromagnetic order in contrast to the spin-glass state in previously\nreported isostructural Fe$_{5}$Te$_{4}$. We also synthesize V$_{4.64}$Te$_4$\nwith similar quasi-1D V-chains and find it has weak anomalies at 144 K on both\nresistivity and susceptibility curves. However, no clear evidence is found for\nthe development of magnetic or charge order. X-ray photoelectron spectroscopy\nand Curie-Weiss fit reveal that the effective moments for Fe$^{2+}$ and\nV$^{4+}$ in both compounds have large deviations from the conventional local\nmoment model, which may possibly result from the formation of Fe/V metal-metal\nbondings. Furthermore the resistivity of both FVT and V$_{4.64}$Te$_4$ exhibits\nsemiconducting-like temperature-dependent behavior but with average values\nclose to typical bad metals, which resembles the transport behavior in the\nnormal state of Fe-based superconductors. These quasi-1D compounds have shown\ninteresting physical properties for future condensed matter physics research.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci,cond-mat.supr-con","published":"2025-04-17T04:13:56Z"}
{"aid":"http://arxiv.org/abs/2504.12639v1","title":"Mass measurements of proton-rich nuclei in the vicinity of ${}^{84}$Mo\n  and their impact on rp-process in type I X-ray burst","summary":"We report on the mass measurement of the rapid proton-capture process key\nnuclide ${}^{84}$Mo and its vicinity, such as ${}^{78}$Y${}^{\\rm m}$,\n${}^{79}$Y, ${}^{83}$Nb, and ${}^{88}$Ru, using the multi-reflection\ntime-of-flight spectrograph at RIKEN RIBF. For ${}^{78}$Y${}^{\\rm m}$,\n${}^{84}$Mo, and ${}^{88}$Ru, their masses are experimentally determined for\nthe first time with uncertainties of $\\delta m \\approx 20~{\\rm keV}$. The mass\nprecision of ${}^{79}$Y and ${}^{83}$Nb is improved to 13 keV and 9.6 keV,\nrespectively. The new $\\alpha$-separation energy of ${}^{84}$Mo, 1.434(83) MeV,\nunambiguously rules out the possibility of forming the ZrNb cycle. The X-ray\nburst simulation with the new masses shows that our measurements effectively\nremove the large final abundance uncertainties in the $A=80-90$ mass region.\nThe new mass values improve the prediction power for the composition of the\nnuclear ashes in X-ray bursts, including the production of light $p$-nuclei.","main_category":"nucl-ex","categories":"nucl-ex,astro-ph.HE,nucl-th","published":"2025-04-17T04:50:30Z"}
{"aid":"http://arxiv.org/abs/2504.12648v1","title":"Enantiospecific Two-Photon Electric-Dipole Selection Rules of Chiral\n  Molecules","summary":"Distinguishing between enantiomers is crucial in the study of chiral\nmolecules in chemistry and pharmacology. Many optical approaches rely on\nenantiospecific cyclic electric-dipole transitions induced by three microwave\nor laser beams. However, these approaches impose stringent requirements,\nincluding phase locking, three-photon resonance, and precise control over beam\nintensities and operation times, which enhance the complexity and restrict the\napplicability. In this letter, we present a novel optical method that {\\it\neliminates these constraints entirely.} Specifically, we demonstrate that in\nthe presence of a static electric field, the selection rules for two-photon\nelectric-dipole transitions differ between enantiomers. This distinction arises\nbecause the static electric field breaks the symmetry associated with the\ncombined action of a specific rotation and time-reversal transformation.\nLeveraging the enantiospecific two-photon selection rule, one can selectively\nexcite a desired enantiomer using only two beams, without the need for phase\nlocking, resonance condition, and the precise control of their intensities and\noperation times. Our method significantly enhances the feasibility and\napplicability of optical approaches for enantiomer differentiation.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T05:19:03Z"}
{"aid":"http://arxiv.org/abs/2504.12658v1","title":"Rare-Event-Induced Ergodicity Breaking in Logarithmic Aging Systems","summary":"Ergodicity breaking and aging effects are fundamental challenges in\nout-of-equilibrium systems. Various mechanisms have been proposed to understand\nthe non-ergodic and aging phenomena, possibly related to observations in\nsystems ranging from structural glass and Anderson glasses to biological\nsystems and mechanical systems. While anomalous diffusion described by Levy\nstatistics efficiently captures ergodicity breaking, the origin of aging and\nergodicity breaking in systems with ultraslow dynamics remain unclear. Here, we\nreport a novel mechanism of ergodicity breaking in systems exhibiting log-aging\ndiffusion. This mechanism, characterized by increasingly infrequent rare events\nwith aging, yields statistics deviating significantly from Levy distribution,\nbreaking ergodicity as shown by unequal time- and ensemble-averaged mean\nsquared displacements and two distinct asymptotic probability distribution\nfunctions. Notably, although these rare events contribute negligibly to\nstatistical averages, they dramatically change the system's characteristic\ntime. This work lays the groundwork for microscopic understanding of\nout-of-equilibrium systems and provides new perspectives on glasses and\nGriffiths-McCoy singularities.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.soft,cond-mat.stat-mech","published":"2025-04-17T05:37:07Z"}
{"aid":"http://arxiv.org/abs/2504.12663v1","title":"Persona-judge: Personalized Alignment of Large Language Models via\n  Token-level Self-judgment","summary":"Aligning language models with human preferences presents significant\nchallenges, particularly in achieving personalization without incurring\nexcessive computational costs. Existing methods rely on reward signals and\nadditional annotated data, limiting their scalability and adaptability to\ndiverse human values. To address these challenges, we introduce Persona-judge,\na novel discriminative paradigm that enables training-free personalized\nalignment with unseen preferences. Instead of optimizing policy parameters\nthrough external reward feedback, Persona-judge leverages the intrinsic\npreference judgment capabilities of the model. Specifically, a draft model\ngenerates candidate tokens conditioned on a given preference, while a judge\nmodel, embodying another preference, cross-validates the predicted tokens\nwhether to be accepted. Experimental results demonstrate that Persona-judge,\nusing the inherent preference evaluation mechanisms of the model, offers a\nscalable and computationally efficient solution to personalized alignment,\npaving the way for more adaptive customized alignment.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T05:50:13Z"}
{"aid":"http://arxiv.org/abs/2504.12674v1","title":"Can spacetime fluctuations generate entanglement between co-moving\n  accelerated detectors?","summary":"Recent studies [Class. Quant. Grav. 42, 03LT01 (2025); Phys. Rev. D 111,\n045023 (2025)] indicate that in a nested sequence of Rindler wedges, vacuum of\nformer Rindler frame appears to be thermally populated for an observer in\nshifted Rindler frame. Interestingly, this thermality is independent of shift\nparameter as long as it is non-zero and therefore arises even if the shift\nparameter is as small as Planck length. Building on this insight, we propose a\nset-up involving two atoms accelerating with identical acceleration. We find\nthat if their Rindler frames (consequently their trajectories) get\ninfinitesimally separated, the atoms become entangled. Remarkably again, this\nentanglement, like the perceived thermality, is independent of the shift\nparameter, provided it is non-vanishing. We investigate the dependence of\nentanglement on acceleration of the detectors. The present study indicates that\nthe entanglement between two detectors, moving on the same Rindler wedge, is\npossible. Moreover, small spacetime fluctuations can lead to entanglement\nbetween detectors, moving along same classical trajectory. Hence we feel that\nsuch theoretical prediction has potential to probe the Planck length nature of\nspacetime.","main_category":"gr-qc","categories":"gr-qc,hep-th,quant-ph","published":"2025-04-17T06:05:41Z"}
{"aid":"http://arxiv.org/abs/2504.12681v1","title":"GRAIL: Gradient-Based Adaptive Unlearning for Privacy and Copyright in\n  LLMs","summary":"Large Language Models (LLMs) trained on extensive datasets often learn\nsensitive information, which raises significant social and legal concerns under\nprinciples such as the \"Right to be forgotten.\" Retraining entire models from\nscratch to remove undesired information is both costly and impractical.\nFurthermore, existing single-domain unlearning methods fail to address\nmulti-domain scenarios, where knowledge is interwoven across domains such as\nprivacy and copyright, creating overlapping representations that lead to\nexcessive knowledge removal or degraded performance. To tackle these issues, we\npropose GRAIL (GRadient-based AdaptIve unLearning), a novel multi-domain\nunlearning framework. GRAIL leverages gradient information from multiple\ndomains to precisely distinguish the unlearning scope from the retention scope,\nand applies an adaptive parameter-wise localization strategy to selectively\nremove targeted knowledge while preserving critical parameters for each domain.\nExperimental results on unlearning benchmarks show that GRAIL achieves\nunlearning success on par with the existing approaches, while also\ndemonstrating up to 17% stronger knowledge retention success compared to the\nprevious state-of-art method. Our findings establish a new paradigm for\neffectively managing and regulating sensitive information in large-scale\npre-trained language models.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T06:16:32Z"}
{"aid":"http://arxiv.org/abs/2504.12690v1","title":"Accessibility Recommendations for Designing Better Mobile Application\n  User Interfaces for Seniors","summary":"Seniors represent a growing user base for mobile applications; however, many\napps fail to adequately address their accessibility challenges and usability\npreferences. To investigate this issue, we conducted an exploratory focus group\nstudy with 16 senior participants, from which we derived an initial set of user\npersonas highlighting key accessibility and personalisation barriers. These\npersonas informed the development of a model-driven engineering toolset, which\nwas used to generate adaptive mobile app prototypes tailored to seniors' needs.\nWe then conducted a second focus group study with 22 seniors to evaluate these\nprototypes and validate our findings. Based on insights from both studies, we\ndeveloped a refined set of personas and a series of accessibility and\npersonalisation recommendations grounded in empirical data, prior research,\naccessibility standards, and developer resources, aimed at supporting software\npractitioners in designing more inclusive mobile applications.","main_category":"cs.SE","categories":"cs.SE,cs.HC","published":"2025-04-17T06:32:05Z"}
{"aid":"http://arxiv.org/abs/2504.12743v1","title":"Quasinormal Modes and Greybody Factors of Scalar Field Perturbations in\n  the NED Corrected Charged Black Hole Spacetime","summary":"Inspired by the quark-antiquark confinement potential, Mazharimousavi et al.\n\\cite{Mazharimousavi:2023okd} proposed a nonlinear electrodynamics (NED) model,\nand based on this model, they constructed a charged black hole solution that\nincludes a logarithmic correction term ($\\propto \\frac{\\zeta \\ln r}{r}$). On\nthe basis of the Reissner-Nordstr\\\"om metric, this solution realizes a\nlong-range confinement correction by introducing the NED parameter $\\zeta$,\nproviding a new theoretical perspective for explaining the anomalies in galaxy\nrotation curves. To deeply explore the dynamic properties of this black hole\nsolution, this paper combines two complementary methods, namely, time-domain\nevolution and the WKB approximation, to calculate the quasinormal mode (QNM)\nspectrum of its scalar field perturbations. The research results show that the\noscillation frequencies and decay rates of the low-order QNM modes decrease\nmonotonically with the increase of the NED parameter $\\zeta$, and exhibit an\napproximately linear dependence. The analysis of the greybody factor (GF)\nindicates that as $\\zeta$ increases, the transmittance of the low-frequency\nscalar field also increases. The enhanced long-range confinement effect caused\nby the increase of $\\zeta$ makes low-frequency perturbations more likely to\nsurvive and propagate in space-time on the one hand, and at the same time\nenhances the transmission ability of the low-frequency scalar field. These\ncharacteristics provide key theoretical predictions and potential observational\nfeatures for testing and constraining such NED models in a strong gravitational\nfield environment in the future using the observational data of gravitational\nwave astronomy or Hawking radiation.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-17T08:32:29Z"}
{"aid":"http://arxiv.org/abs/2504.12746v1","title":"A note on one-variable theorems for NSOP","summary":"We give an example of an SOP theory $T$, such that any $L(M)$-formula\n$\\varphi(x,y)$ with $|y|=1$ is NSOP. We show that any such $T$ must have the\nindependence property. We also give a simplified proof of Lachlan's theorem\nthat if every $L$-formula $\\varphi(x,y)$ with $|x|=1$ is NSOP, then $T$ is\nNSOP.","main_category":"math.LO","categories":"math.LO","published":"2025-04-17T08:38:02Z"}
{"aid":"http://arxiv.org/abs/2504.12794v1","title":"Supporting Urban Low-Altitude Economy: Channel Gain Map Inference Based\n  on 3D Conditional GAN","summary":"The advancement of advanced air mobility (AAM) in recent years has given rise\nto the concept of low-altitude economy (LAE). However, the diverse flight\nactivities associated with the emerging LAE applications in urban scenarios\nconfront complex physical environments, which urgently necessitates ubiquitous\nand reliable communication to guarantee the operation safety of the\nlow-altitude aircraft. As one of promising technologies for the sixth\ngeneration (6G) mobile networks, channel knowledge map (CKM) enables the\nenvironment-aware communication by constructing a site-specific dataset,\nthereby providing a priori on-site information for the aircraft to obtain the\nchannel state information (CSI) at arbitrary locations with much reduced online\noverhead. Diverse base station (BS) deployments in the three-dimensional (3D)\nurban low-altitude environment require efficient 3D CKM construction to capture\nspatial channel characteristics with less overhead. Towards this end, this\npaper proposes a 3D channel gain map (CGM) inference method based on a 3D\nconditional generative adversarial network (3D-CGAN). Specifically, we first\nanalyze the potential deployment types of BSs in urban low-altitude scenario,\nand investigate the CGM representation with the corresponding 3D channel gain\nmodel. The framework of the proposed 3D-CGAN is then discussed, which is\ntrained by a dataset consisting of existing CGMs. Consequently, the trained\n3D-CGAN is capable of inferring the corresponding CGM only based on the BS\ncoordinate without additional measurement. The simulation results demonstrate\nthat the CGMs inferred by the proposed 3D-CGAN outperform those of the\nbenchmark schemes, which can accurately reflect the radio propagation condition\nin 3D environment.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-17T09:55:03Z"}
{"aid":"http://arxiv.org/abs/2504.12800v1","title":"CAGE-GS: High-fidelity Cage Based 3D Gaussian Splatting Deformation","summary":"As 3D Gaussian Splatting (3DGS) gains popularity as a 3D representation of\nreal scenes, enabling user-friendly deformation to create novel scenes while\npreserving fine details from the original 3DGS has attracted significant\nresearch attention. We introduce CAGE-GS, a cage-based 3DGS deformation method\nthat seamlessly aligns a source 3DGS scene with a user-defined target shape.\nOur approach learns a deformation cage from the target, which guides the\ngeometric transformation of the source scene. While the cages effectively\ncontrol structural alignment, preserving the textural appearance of 3DGS\nremains challenging due to the complexity of covariance parameters. To address\nthis, we employ a Jacobian matrix-based strategy to update the covariance\nparameters of each Gaussian, ensuring texture fidelity post-deformation. Our\nmethod is highly flexible, accommodating various target shape representations,\nincluding texts, images, point clouds, meshes and 3DGS models. Extensive\nexperiments and ablation studies on both public datasets and newly proposed\nscenes demonstrate that our method significantly outperforms existing\ntechniques in both efficiency and deformation quality.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-17T10:00:15Z"}
{"aid":"http://arxiv.org/abs/2504.12805v1","title":"Assesing LLMs in Art Contexts: Critique Generation and Theory of Mind\n  Evaluation","summary":"This study explored how large language models (LLMs) perform in two areas\nrelated to art: writing critiques of artworks and reasoning about mental states\n(Theory of Mind, or ToM) in art-related situations. For the critique generation\npart, we built a system that combines Noel Carroll's evaluative framework with\na broad selection of art criticism theories. The model was prompted to first\nwrite a full-length critique and then shorter, more coherent versions using a\nstep-by-step prompting process. These AI-generated critiques were then compared\nwith those written by human experts in a Turing test-style evaluation. In many\ncases, human subjects had difficulty telling which was which, and the results\nsuggest that LLMs can produce critiques that are not only plausible in style\nbut also rich in interpretation, as long as they are carefully guided. In the\nsecond part, we introduced new simple ToM tasks based on situations involving\ninterpretation, emotion, and moral tension, which can appear in the context of\nart. These go beyond standard false-belief tests and allow for more complex,\nsocially embedded forms of reasoning. We tested 41 recent LLMs and found that\ntheir performance varied across tasks and models. In particular, tasks that\ninvolved affective or ambiguous situations tended to reveal clearer\ndifferences. Taken together, these results help clarify how LLMs respond to\ncomplex interpretative challenges, revealing both their cognitive limitations\nand potential. While our findings do not directly contradict the so-called\nGenerative AI Paradox--the idea that LLMs can produce expert-like output\nwithout genuine understanding--they suggest that, depending on how LLMs are\ninstructed, such as through carefully designed prompts, these models may begin\nto show behaviors that resemble understanding more closely than we might\nassume.","main_category":"cs.CL","categories":"cs.CL,cs.CY,cs.HC","published":"2025-04-17T10:10:25Z"}
{"aid":"http://arxiv.org/abs/2504.12816v1","title":"SMARTe: Slot-based Method for Accountable Relational Triple extraction","summary":"Relational Triple Extraction (RTE) is a fundamental task in Natural Language\nProcessing (NLP). However, prior research has primarily focused on optimizing\nmodel performance, with limited efforts to understand the internal mechanisms\ndriving these models. Many existing methods rely on complex preprocessing to\ninduce specific interactions, often resulting in opaque systems that may not\nfully align with their theoretical foundations. To address these limitations,\nwe propose SMARTe: a Slot-based Method for Accountable Relational Triple\nextraction. SMARTe introduces intrinsic interpretability through a slot\nattention mechanism and frames the task as a set prediction problem. Slot\nattention consolidates relevant information into distinct slots, ensuring all\npredictions can be explicitly traced to learned slot representations and the\ntokens contributing to each predicted relational triple. While emphasizing\ninterpretability, SMARTe achieves performance comparable to state-of-the-art\nmodels. Evaluations on the NYT and WebNLG datasets demonstrate that adding\ninterpretability does not compromise performance. Furthermore, we conducted\nqualitative assessments to showcase the explanations provided by SMARTe, using\nattention heatmaps that map to their respective tokens. We conclude with a\ndiscussion of our findings and propose directions for future research.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-17T10:21:15Z"}
{"aid":"http://arxiv.org/abs/2504.12828v1","title":"Predicting Stock Prices using Permutation Decision Trees and Strategic\n  Trailing","summary":"In this paper, we explore the application of Permutation Decision Trees (PDT)\nand strategic trailing for predicting stock market movements and executing\nprofitable trades in the Indian stock market. We focus on high-frequency data\nusing 5-minute candlesticks for the top 50 stocks listed in the NIFTY 50 index.\nWe implement a trading strategy that aims to buy stocks at lower prices and\nsell them at higher prices, capitalizing on short-term market fluctuations. Due\nto regulatory constraints in India, short selling is not considered in our\nstrategy. The model incorporates various technical indicators and employs\nhyperparameters such as the trailing stop-loss value and support thresholds to\nmanage risk effectively. Our results indicate that the proposed trading bot has\nthe potential to outperform the market average and yield returns higher than\nthe risk-free rate offered by 10-year Indian government bonds. We trained and\ntested data on a 60 day dataset provided by Yahoo Finance. Specifically, 12\ndays for testing and 48 days for training. Our bot based on permutation\ndecision tree achieved a profit of 1.3468 % over a 12-day testing period, where\nas a bot based on LSTM gave a return of 0.1238 % over a 12-day testing period\nand a bot based on RNN gave a return of 0.3096 % over a 12-day testing period.\nAll of the bots outperform the buy-and-hold strategy, which resulted in a loss\nof 2.2508 %.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T10:42:38Z"}
{"aid":"http://arxiv.org/abs/2504.12875v1","title":"A Client-level Assessment of Collaborative Backdoor Poisoning in Non-IID\n  Federated Learning","summary":"Federated learning (FL) enables collaborative model training using\ndecentralized private data from multiple clients. While FL has shown robustness\nagainst poisoning attacks with basic defenses, our research reveals new\nvulnerabilities stemming from non-independent and identically distributed\n(non-IID) data among clients. These vulnerabilities pose a substantial risk of\nmodel poisoning in real-world FL scenarios.\n  To demonstrate such vulnerabilities, we develop a novel collaborative\nbackdoor poisoning attack called CollaPois. In this attack, we distribute a\nsingle pre-trained model infected with a Trojan to a group of compromised\nclients. These clients then work together to produce malicious gradients,\ncausing the FL model to consistently converge towards a low-loss region\ncentered around the Trojan-infected model. Consequently, the impact of the\nTrojan is amplified, especially when the benign clients have diverse local data\ndistributions and scattered local gradients. CollaPois stands out by achieving\nits goals while involving only a limited number of compromised clients, setting\nit apart from existing attacks. Also, CollaPois effectively avoids noticeable\nshifts or degradation in the FL model's performance on legitimate data samples,\nallowing it to operate stealthily and evade detection by advanced robust FL\nalgorithms.\n  Thorough theoretical analysis and experiments conducted on various benchmark\ndatasets demonstrate the superiority of CollaPois compared to state-of-the-art\nbackdoor attacks. Notably, CollaPois bypasses existing backdoor defenses,\nespecially in scenarios where clients possess diverse data distributions.\nMoreover, the results show that CollaPois remains effective even when involving\na small number of compromised clients. Notably, clients whose local data is\nclosely aligned with compromised clients experience higher risks of backdoor\ninfections.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T12:03:02Z"}
{"aid":"http://arxiv.org/abs/2504.12877v1","title":"Market-Driven Flexibility Provision: A Tri-Level Optimization Approach\n  for Carbon Reduction","summary":"The integration of renewable energy resources (RES) in the power grid can\nreduce carbon intensity, but also presents certain challenges. The uncertainty\nand intermittent nature of RES emphasize the need for flexibility in power\nsystems. Moreover, there are noticeable mismatches between real-time\nelectricity prices and carbon intensity patterns throughout the day. These\ndiscrepancies may lead customers to schedule energy-intensive tasks during the\nearly hours of the day, a period characterized by lower electricity prices but\nhigher carbon intensity. This paper introduces a novel and comprehensive\nframework aimed at encouraging customer participation in electricity markets\nand aligning their flexibility with carbon intensity trends. The proposed\napproach integrates an incentive-based tariff with a tri-level optimization\nmodel, where customers are motivated to submit flexibility bids and, in return,\nreceive financial rewards based on their contributions. The tri-level model\nensures a dynamic interaction between the market operation platform (MOP) and\nend-users. Simulations are performed on a modified IEEE-33 bus system,\nsupported by two scenarios with different RES generations and customer\nbehaviors. Results demonstrate the effectiveness of the proposed framework in\nguiding the customers' consumption behaviors towards low carbon intensity.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-17T12:04:49Z"}
{"aid":"http://arxiv.org/abs/2504.12887v1","title":"A Novel View on the Inner Crusts of Neo-Neutron Stars: exotic light\n  nuclei, diffusional and thermodynamical stability","summary":"Based on an extended nuclear statistical equilibrium model, we investigate\nthe properties of non-accreted crusts of young and warm neo-neutron stars,\ni.e., of finite-temperature inhomogeneous dense matter in beta equilibrium. We\npresent two novel results and one known, but frequently ignored property of\nsuch matter. The first new feature is the appearance, in the deep inner crust,\nof an extensive and almost pure $^{14}$He layer that extends up to the density\nof the transition to homogeneous matter. This layer may challenge the idea of\nnuclear pasta phases, significantly impact the transport properties and the\ncrust crystallization process. Second, we raise the question of the\n(in)stability of the inner crust with respect to diffusion of ions (buoyancy)\nand demonstrate that our crust is stable, in contrast with the predictions of\nsome other models. Finally, we show that subsaturated stellar matter is\nthermodynamically stable with respect to density fluctuations, which rules out\na first-order phase transition between inhomogeneous and homogeneous phases.","main_category":"nucl-th","categories":"nucl-th,astro-ph.HE","published":"2025-04-17T12:21:46Z"}
{"aid":"http://arxiv.org/abs/2504.12903v1","title":"Reduced ech complexes and computing higher direct images under\n  toric maps","summary":"This paper has three main goals : (1) To give an axiomatic formulation of the\nconstruction of \"reduced \\v{C}ech complexes\", complexes using fewer than the\nusual number of intersections but still computing cohomology of sheaves; (2) To\ngive a construction of such a reduced \\v{C}ech complex for every semi-proper\ntoric variety $X$, such that every open used in the complex is torus stable,\nand such that the cell complex governing the reduced \\v{C}ech complex has\ndimension the cohomological dimension of $X$; and (3) to give an algorithm to\ncompute the higher direct images of line bundles relative to a toric fibration\nbetween smooth proper toric varieties.","main_category":"math.AG","categories":"math.AG","published":"2025-04-17T12:48:18Z"}
{"aid":"http://arxiv.org/abs/2504.12914v1","title":"In Which Areas of Technical AI Safety Could Geopolitical Rivals\n  Cooperate?","summary":"International cooperation is common in AI research, including between\ngeopolitical rivals. While many experts advocate for greater international\ncooperation on AI safety to address shared global risks, some view cooperation\non AI with suspicion, arguing that it can pose unacceptable risks to national\nsecurity. However, the extent to which cooperation on AI safety poses such\nrisks, as well as provides benefits, depends on the specific area of\ncooperation. In this paper, we consider technical factors that impact the risks\nof international cooperation on AI safety research, focusing on the degree to\nwhich such cooperation can advance dangerous capabilities, result in the\nsharing of sensitive information, or provide opportunities for harm. We begin\nby why nations historically cooperate on strategic technologies and analyse\ncurrent US-China cooperation in AI as a case study. We further argue that\nexisting frameworks for managing associated risks can be supplemented with\nconsideration of key risks specific to cooperation on technical AI safety\nresearch. Through our analysis, we find that research into AI verification\nmechanisms and shared protocols may be suitable areas for such cooperation.\nThrough this analysis we aim to help researchers and governments identify and\nmitigate the risks of international cooperation on AI safety research, so that\nthe benefits of cooperation can be fully realised.","main_category":"cs.CY","categories":"cs.CY","published":"2025-04-17T13:03:56Z"}
{"aid":"http://arxiv.org/abs/2504.12938v1","title":"Optimal analysis of penalized lowest-order mixed FEMs for the\n  Stokes-Darcy model","summary":"This paper is concerned with non-uniform fully-mixed FEMs for dynamic coupled\nStokes-Darcy model with the well-known Beavers-Joseph-Saffman (BJS) interface\ncondition. In particular, a decoupled algorithm with the lowest-order mixed\nnon-uniform FE approximations (MINI for the Stokes equation and RT0-DG0 for the\nDarcy equation) and the classical Nitsche-type penalty is studied. The method\nwith the combined approximation of different orders is commonly used in\npractical simulations. However, the optimal error analysis of methods with\nnon-uniform approximations for the coupled Stokes-Darcy flow model has remained\nchallenging, although the analysis for uniform approximations has been well\ndone. The key question is how the lower-order approximation to the Darcy flow\ninfluences the accuracy of the Stokes solution through the interface condition.\nIn this paper, we prove that the decoupled algorithm provides a truly optimal\nconvergence rate in L^2-norm in spatial direction: O(h^2) for Stokes velocity\nand O(h) for Darcy flow in the coupled Stokes-Darcy model. This implies that\nthe lower-order approximation to the Darcy flow does not pollute the accuracy\nof numerical velocity for Stokes flow. The analysis presented in this paper is\nbased on a well-designed Stokes-Darcy Ritz projection and given for a dynamic\ncoupled model. The optimal error estimate holds for more general combined\napproximations and more general coupled models, including the corresponding\nmodel of steady-state Stokes-Darcy flows and the model of coupled dynamic\nStokes and steady-state Darcy flows. Numerical results confirm our theoretical\nanalysis and show that the decoupled algorithm is efficient.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-17T13:37:39Z"}
{"aid":"http://arxiv.org/abs/2504.12991v1","title":"Chain-of-Thought Prompting for Out-of-Distribution Samples: A\n  Latent-Variable Study","summary":"Chain-of-Thought (CoT) prompting has emerged as a powerful technique to\nimprove in-context learning (ICL) in large language models (LLMs) by breaking\ncomplex reasoning into intermediate steps. However, the ability of CoT to\ngeneralize under distribution shift remains poorly understood. In this work, we\nextend a latent-variable framework for CoT prompting and study its behavior on\ntwo prototypical out-of-distribution (OOD) scenarios: (i) the latent variables\nfor CoT steps are permuted into novel combinations, and (ii) the latent\nvariables uniformly scaled by a factor. Our experiments demonstrate that CoT\ninference generalizes effectively to OOD samples whose latent variables closely\nresemble those seen during training, but its performance degrades as this\nsimilarity decreases. These findings provide foundational insights into the\nstrengths and limitations of CoT prompting under OOD conditions and suggest\ndirections for developing more resilient reasoning strategies in future LLMs.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T14:59:29Z"}
{"aid":"http://arxiv.org/abs/2504.13038v1","title":"How Large Language Models Are Changing MOOC Essay Answers: A Comparison\n  of Pre- and Post-LLM Responses","summary":"The release of ChatGPT in late 2022 caused a flurry of activity and concern\nin the academic and educational communities. Some see the tool's ability to\ngenerate human-like text that passes at least cursory inspections for factual\naccuracy ``often enough'' a golden age of information retrieval and\ncomputer-assisted learning. Some, on the other hand, worry the tool may lead to\nunprecedented levels of academic dishonesty and cheating. In this work, we\nquantify some of the effects of the emergence of Large Language Models (LLMs)\non online education by analyzing a multi-year dataset of student essay\nresponses from a free university-level MOOC on AI ethics. Our dataset includes\nessays submitted both before and after ChatGPT's release. We find that the\nlaunch of ChatGPT coincided with significant changes in both the length and\nstyle of student essays, mirroring observations in other contexts such as\nacademic publishing. We also observe -- as expected based on related public\ndiscourse -- changes in prevalence of key content words related to AI and LLMs,\nbut not necessarily the general themes or topics discussed in the student\nessays as identified through (dynamic) topic modeling.","main_category":"cs.CY","categories":"cs.CY,cs.CL","published":"2025-04-17T15:51:59Z"}
{"aid":"http://arxiv.org/abs/2504.13039v1","title":"Evidence for sulfur chemistry in the atmosphere of the warm sub-Neptune\n  TOI-270 d","summary":"Context: Recent JWST measurements allow access to the near-infrared spectrum\nof the sub-Neptune TOI-270 d, for which two different interpretations, a\nhigh-metallicity miscible envelope and a lower metallicity hycean world, are\ncurrently in conflict. Aims: Here, we reanalyze the published data and\nreproduce previously retrieved molecular abundances based on an independent\ndata reduction and a different retrieval framework. The aim of this study is to\nrefine the understanding of TOI-270 d and highlight considerations for JWST\ndata analysis. Additionally, we test the impact of data resolution on\natmospheric retrieval calculations. Methods: We reduce one JWST NIRSpec G395H\nand one NIRISS SOSS GR700XD transit dataset using the Eureka! pipeline and a\ncustom MCMC-based light curve fitting algorithm at the instruments' native\nresolutions. The atmospheric composition is estimated with the updated BeAR\nretrieval code across a grid of retrieval setups and spectral resolutions.\nResults: Our transit spectrum is consistent with previous studies, except at\nthe red end of the NIRISS data. Our retrievals support a higher mean molecular\nweight atmosphere for TOI-270 d. We provide refined abundance constraints and\nfind statistically favored model extensions indicating either sulfur-rich\nchemistry with species such as CS2, CS, and H2CS, or the possible presence of\nCH3Cl or CH3F. However, Bayesian inference cannot distinguish between these\nscenarios due to similar opacities below 4 microns. Conclusions: Our analysis\nreinforces TOI-270 d as a highly interesting warm sub-Neptune for atmospheric\nstudies, with a complex chemistry in a cloud-free upper atmosphere. However,\nits exact nature remains uncertain and warrants further detailed photochemical\nmodeling and observations.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-17T15:52:23Z"}
{"aid":"http://arxiv.org/abs/2504.13054v1","title":"Aspect-Based Summarization with Self-Aspect Retrieval Enhanced\n  Generation","summary":"Aspect-based summarization aims to generate summaries tailored to specific\naspects, addressing the resource constraints and limited generalizability of\ntraditional summarization approaches. Recently, large language models have\nshown promise in this task without the need for training. However, they rely\nexcessively on prompt engineering and face token limits and hallucination\nchallenges, especially with in-context learning. To address these challenges,\nin this paper, we propose a novel framework for aspect-based summarization:\nSelf-Aspect Retrieval Enhanced Summary Generation. Rather than relying solely\non in-context learning, given an aspect, we employ an embedding-driven\nretrieval mechanism to identify its relevant text segments. This approach\nextracts the pertinent content while avoiding unnecessary details, thereby\nmitigating the challenge of token limits. Moreover, our framework optimizes\ntoken usage by deleting unrelated parts of the text and ensuring that the model\ngenerates output strictly based on the given aspect. With extensive experiments\non benchmark datasets, we demonstrate that our framework not only achieves\nsuperior performance but also effectively mitigates the token limitation\nproblem.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T16:09:57Z"}
{"aid":"http://arxiv.org/abs/2504.13062v1","title":"Seeing Beyond Dark-Field RGB Capabilities: Deep Spectral Extrapolation\n  of Ultrasmall Plasmonic Nanogaps","summary":"Localized surface plasmons can confine light within a deep-subwavelength\nvolume comparable to the scale of atoms and molecules, enabling ultrasensitive\nresponses to near-field variations. On the other hand, this extreme\nlocalization also inevitably amplifies the unwanted noise from the response of\nlocal morphological imperfections, leading to complex spectral variations and\nreduced consistency across the plasmonic nanostructures. Seeking uniform\noptical responses has therefore long been a sought-after goal in\nnanoplasmonics. However, conventional probing techniques by dark-field (DF)\nconfocal microscopy, such as image analysis or spectral measurements, can be\ninaccurate and time-consuming, respectively. Here, we introduce SPARX, a\ndeep-learning-powered paradigm that surpasses conventional imaging and\nspectroscopic capabilities. In particular, SPARX can batch-predict broadband DF\nspectra (e.g., 500-1000 nm) of numerous nanoparticles simultaneously from an\ninformation-limited RGB image (i.e., below 700 nm). It achieves this\nextrapolative inference beyond the camera's capture capabilities by learning\nthe underlying physical relationships among multiple orders of optical\nresonances. The spectral predictions only take milliseconds, achieving a\nspeedup of three to four orders of magnitude compared to traditional spectral\nacquisition, which may take from hours to days. As a proof-of-principle\ndemonstration for screening identical resonances, the selection accuracy\nachieved by SPARX is comparable to that of conventional spectroscopy\ntechniques. This breakthrough paves the way for consistent plasmonic\napplications and next-generation microscopies.","main_category":"physics.optics","categories":"physics.optics,cond-mat.dis-nn,cond-mat.mes-hall","published":"2025-04-17T16:15:56Z"}
{"aid":"http://arxiv.org/abs/2504.13076v1","title":"Extremal Lagrangian tori in toric domains","summary":"Let $L$ be a closed Lagrangian submanifold of a symplectic manifold\n$(X,\\omega)$. Cieliebak and Mohnke define the symplectic area of $L$ as the\nminimal positive symplectic area of a smooth $2$-disk in $X$ with boundary on\n$L$. An extremal Lagrangian torus in $(X,\\omega)$ is a Lagrangian torus that\nmaximizes the symplectic area among the Lagrangian tori in $(X,\\omega)$. We\nprove that every extremal Lagrangian torus in the symplectic unit ball\n$(\\bar{B}^{2n}(1),\\omega_{\\mathrm{std}})$ is contained entirely in the boundary\n$\\partial B^{2n}(1)$. This answers a question attributed to Lazzarini and\ncompletely settles a conjecture of Cieliebak and Mohnke in the affirmative. In\naddition, we prove the conjecture for a class of toric domains in\n$(\\mathbb{C}^n, \\omega_{\\mathrm{std}})$, which includes all compact strictly\nconvex four-dimensional toric domains. We explain with counterexamples that the\ngeneral conjecture does not hold for non-convex domains.","main_category":"math.SG","categories":"math.SG,math.DG","published":"2025-04-17T16:39:04Z"}
{"aid":"http://arxiv.org/abs/2504.13094v1","title":"Symmetry classification and invariant solutions of the classical\n  geometric mean reversion process","summary":"Based on the Lie symmetry method, we investigate a Feynman-Kac formula for\nthe classical geometric mean reversion process, which effectively describing\nthe dynamics of short-term interest rates. The Lie algebra of infinitesimal\nsymmetries and the corresponding one-parameter symmetry groups of the equation\nare obtained. An optimal system of invariant solutions are constructed by a\nderived optimal system of one-dimensional subalgebras. Because of taking into\naccount a supply response to price rises, this equation provides for a more\nrealistic assumption than the geometric Brownian motion in many investment\nscenarios.","main_category":"math.DS","categories":"math.DS,math.AP,math.PR,q-fin.MF","published":"2025-04-17T16:59:55Z"}
{"aid":"http://arxiv.org/abs/2504.13102v1","title":"A Multi-task Learning Balanced Attention Convolutional Neural Network\n  Model for Few-shot Underwater Acoustic Target Recognition","summary":"Underwater acoustic target recognition (UATR) is of great significance for\nthe protection of marine diversity and national defense security. The\ndevelopment of deep learning provides new opportunities for UATR, but faces\nchallenges brought by the scarcity of reference samples and complex\nenvironmental interference. To address these issues, we proposes a multi-task\nbalanced channel attention convolutional neural network (MT-BCA-CNN). The\nmethod integrates a channel attention mechanism with a multi-task learning\nstrategy, constructing a shared feature extractor and multi-task classifiers to\njointly optimize target classification and feature reconstruction tasks. The\nchannel attention mechanism dynamically enhances discriminative acoustic\nfeatures such as harmonic structures while suppressing noise. Experiments on\nthe Watkins Marine Life Dataset demonstrate that MT-BCA-CNN achieves 97\\%\nclassification accuracy and 95\\% $F1$-score in 27-class few-shot scenarios,\nsignificantly outperforming traditional CNN and ACNN models, as well as popular\nstate-of-the-art UATR methods. Ablation studies confirm the synergistic\nbenefits of multi-task learning and attention mechanisms, while a dynamic\nweighting adjustment strategy effectively balances task contributions. This\nwork provides an efficient solution for few-shot underwater acoustic\nrecognition, advancing research in marine bioacoustics and sonar signal\nprocessing.","main_category":"cs.SD","categories":"cs.SD,cs.AI,eess.AS","published":"2025-04-17T17:11:32Z"}
{"aid":"http://arxiv.org/abs/2504.13128v1","title":"FreshStack: Building Realistic Benchmarks for Evaluating Retrieval on\n  Technical Documents","summary":"We introduce FreshStack, a reusable framework for automatically building\ninformation retrieval (IR) evaluation benchmarks from community-asked questions\nand answers. FreshStack conducts the following steps: (1) automatic corpus\ncollection from code and technical documentation, (2) nugget generation from\ncommunity-asked questions and answers, and (3) nugget-level support, retrieving\ndocuments using a fusion of retrieval techniques and hybrid architectures. We\nuse FreshStack to build five datasets on fast-growing, recent, and niche topics\nto ensure the tasks are sufficiently challenging. On FreshStack, existing\nretrieval models, when applied out-of-the-box, significantly underperform\noracle approaches on all five topics, denoting plenty of headroom to improve IR\nquality. In addition, we identify cases where rerankers do not clearly improve\nfirst-stage retrieval accuracy (two out of five topics). We hope that\nFreshStack will facilitate future work toward constructing realistic, scalable,\nand uncontaminated IR and RAG evaluation benchmarks. FreshStack datasets are\navailable at: https://fresh-stack.github.io.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.CL","published":"2025-04-17T17:44:06Z"}
{"aid":"http://arxiv.org/abs/2504.13134v1","title":"Energy-Based Reward Models for Robust Language Model Alignment","summary":"Reward models (RMs) are essential for aligning Large Language Models (LLMs)\nwith human preferences. However, they often struggle with capturing complex\nhuman preferences and generalizing to unseen data. To address these challenges,\nwe introduce Energy-Based Reward Model (EBRM), a lightweight post-hoc\nrefinement framework that enhances RM robustness and generalization. EBRM\nmodels the reward distribution explicitly, capturing uncertainty in human\npreferences and mitigating the impact of noisy or misaligned annotations. It\nachieves this through conflict-aware data filtering, label-noise-aware\ncontrastive training, and hybrid initialization. Notably, EBRM enhances RMs\nwithout retraining, making it computationally efficient and adaptable across\ndifferent models and tasks. Empirical evaluations on RM benchmarks demonstrate\nsignificant improvements in both robustness and generalization, achieving up to\na 5.97% improvement in safety-critical alignment tasks compared to standard\nRMs. Furthermore, reinforcement learning experiments confirm that our refined\nrewards enhance alignment quality, effectively delaying reward hacking. These\nresults demonstrate our approach as a scalable and effective enhancement for\nexisting RMs and alignment pipelines. The code is available at EBRM.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-17T17:47:15Z"}
{"aid":"http://arxiv.org/abs/2504.13150v1","title":"Readable Twins of Unreadable Models","summary":"Creating responsible artificial intelligence (AI) systems is an important\nissue in contemporary research and development of works on AI. One of the\ncharacteristics of responsible AI systems is their explainability. In the\npaper, we are interested in explainable deep learning (XDL) systems. On the\nbasis of the creation of digital twins of physical objects, we introduce the\nidea of creating readable twins (in the form of imprecise information flow\nmodels) for unreadable deep learning models. The complete procedure for\nswitching from the deep learning model (DLM) to the imprecise information flow\nmodel (IIFM) is presented. The proposed approach is illustrated with an example\nof a deep learning classification model for image recognition of handwritten\ndigits from the MNIST data set.","main_category":"cs.AI","categories":"cs.AI,cs.CV","published":"2025-04-17T17:55:34Z"}
{"aid":"http://arxiv.org/abs/2504.13162v1","title":"Personalized Text-to-Image Generation with Auto-Regressive Models","summary":"Personalized image synthesis has emerged as a pivotal application in\ntext-to-image generation, enabling the creation of images featuring specific\nsubjects in diverse contexts. While diffusion models have dominated this\ndomain, auto-regressive models, with their unified architecture for text and\nimage modeling, remain underexplored for personalized image generation. This\npaper investigates the potential of optimizing auto-regressive models for\npersonalized image synthesis, leveraging their inherent multimodal capabilities\nto perform this task. We propose a two-stage training strategy that combines\noptimization of text embeddings and fine-tuning of transformer layers. Our\nexperiments on the auto-regressive model demonstrate that this method achieves\ncomparable subject fidelity and prompt following to the leading diffusion-based\npersonalization methods. The results highlight the effectiveness of\nauto-regressive models in personalized image generation, offering a new\ndirection for future research in this area.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T17:58:26Z"}
{"aid":"http://arxiv.org/abs/2504.13167v1","title":"ODHSR: Online Dense 3D Reconstruction of Humans and Scenes from\n  Monocular Videos","summary":"Creating a photorealistic scene and human reconstruction from a single\nmonocular in-the-wild video figures prominently in the perception of a\nhuman-centric 3D world. Recent neural rendering advances have enabled holistic\nhuman-scene reconstruction but require pre-calibrated camera and human poses,\nand days of training time. In this work, we introduce a novel unified framework\nthat simultaneously performs camera tracking, human pose estimation and\nhuman-scene reconstruction in an online fashion. 3D Gaussian Splatting is\nutilized to learn Gaussian primitives for humans and scenes efficiently, and\nreconstruction-based camera tracking and human pose estimation modules are\ndesigned to enable holistic understanding and effective disentanglement of pose\nand appearance. Specifically, we design a human deformation module to\nreconstruct the details and enhance generalizability to out-of-distribution\nposes faithfully. Aiming to learn the spatial correlation between human and\nscene accurately, we introduce occlusion-aware human silhouette rendering and\nmonocular geometric priors, which further improve reconstruction quality.\nExperiments on the EMDB and NeuMan datasets demonstrate superior or on-par\nperformance with existing methods in camera tracking, human pose estimation,\nnovel view synthesis and runtime. Our project page is at\nhttps://eth-ait.github.io/ODHSR.","main_category":"cs.CV","categories":"cs.CV,I.4.5","published":"2025-04-17T17:59:02Z"}
{"aid":"http://arxiv.org/abs/2504.13169v1","title":"Generate, but Verify: Reducing Hallucination in Vision-Language Models\n  with Retrospective Resampling","summary":"Vision-Language Models (VLMs) excel at visual understanding but often suffer\nfrom visual hallucinations, where they generate descriptions of nonexistent\nobjects, actions, or concepts, posing significant risks in safety-critical\napplications. Existing hallucination mitigation methods typically follow one of\ntwo paradigms: generation adjustment, which modifies decoding behavior to align\ntext with visual inputs, and post-hoc verification, where external models\nassess and correct outputs. While effective, generation adjustment methods\noften rely on heuristics and lack correction mechanisms, while post-hoc\nverification is complicated, typically requiring multiple models and tending to\nreject outputs rather than refine them. In this work, we introduce REVERSE, a\nunified framework that integrates hallucination-aware training with on-the-fly\nself-verification. By leveraging a new hallucination-verification dataset\ncontaining over 1.3M semi-synthetic samples, along with a novel inference-time\nretrospective resampling technique, our approach enables VLMs to both detect\nhallucinations during generation and dynamically revise those hallucinations.\nOur evaluations show that REVERSE achieves state-of-the-art hallucination\nreduction, outperforming the best existing methods by up to 12% on CHAIR-MSCOCO\nand 28% on HaloQuest. Our dataset, model, and code are available at:\nhttps://reverse-vlm.github.io.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T17:59:22Z"}
{"aid":"http://arxiv.org/abs/2504.14907v1","title":"Dynamic Graph-Like Learning with Contrastive Clustering on\n  Temporally-Factored Ship Motion Data for Imbalanced Sea State Estimation in\n  Autonomous Vessel","summary":"Accurate sea state estimation is crucial for the real-time control and future\nstate prediction of autonomous vessels. However, traditional methods struggle\nwith challenges such as data imbalance and feature redundancy in ship motion\ndata, limiting their effectiveness. To address these challenges, we propose the\nTemporal-Graph Contrastive Clustering Sea State Estimator (TGC-SSE), a novel\ndeep learning model that combines three key components: a time dimension\nfactorization module to reduce data redundancy, a dynamic graph-like learning\nmodule to capture complex variable interactions, and a contrastive clustering\nloss function to effectively manage class imbalance. Our experiments\ndemonstrate that TGC-SSE significantly outperforms existing methods across 14\npublic datasets, achieving the highest accuracy in 9 datasets, with a 20.79%\nimprovement over EDI. Furthermore, in the field of sea state estimation,\nTGC-SSE surpasses five benchmark methods and seven deep learning models.\nAblation studies confirm the effectiveness of each module, demonstrating their\nrespective roles in enhancing overall model performance. Overall, TGC-SSE not\nonly improves the accuracy of sea state estimation but also exhibits strong\ngeneralization capabilities, providing reliable support for autonomous vessel\noperations.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-21T07:22:11Z"}
{"aid":"http://arxiv.org/abs/2504.14912v1","title":"Dynamics of pulsating swarmalators on a ring","summary":"We study a simple one-dimensional model of swarmalators, a generalization of\nphase oscillators that swarm around in space as well as synchronize internal\noscillations in time. Previous studies of the model focused on Kuramoto-type\ncouplings, where the phase interactions are governed by phase differences. Here\nwe consider Winfree-type coupling, where the interactions are multiplicative,\ndetermined by the product of a phase response function $R(\\theta)$ and phase\npulse function $P(\\theta)$. This more general interaction (from which the\nKuramoto phase differences emerge after averaging) produces rich physics: six\nlong-term modes of organization are found, which we characterize numerically\nand analytically.","main_category":"nlin.AO","categories":"nlin.AO,math-ph,math.MP","published":"2025-04-21T07:31:18Z"}
{"aid":"http://arxiv.org/abs/2504.14914v1","title":"K-DRIFT Preparation: Experimental Verification of an Observation\n  Strategy for Accurate Dark-Sky Flats","summary":"Despite its scientific importance, the low-surface-brightness universe has\nyet to be fully explored due to various systematic uncertainties that affect\nthe achievable surface-brightness limit. Reducing these uncertainties requires\nvery accurate data processing. The dark-sky flat is a widely used calibration\nframe for accurate flat-field correction, generated by combining the sky\nbackground from science images. However, the night sky will likely contain\ncomplex local fluctuations, thus may still lead to photometric errors in data\ncalibrated with dark-sky flats. To address this concern, we conduct mock\nobservations with semi-realistic sky simulation data and evaluate observation\nstrategies to mitigate the impact of the fluctuating sky background. Our\nexperiments consider two representative sky conditions (clear and dirty) and\nperform intensive comparative analysis on two observation methods (offset and\nrolling). Our findings suggest that the rolling dithering method, which\nincorporates the operation of camera rotation into conventional dithering, can\nprovide more accurate dark-sky flats. Finally, we discuss the broader\nimplications of this method through additional experiments examining several\nfactors that may affect the imaging quality of observational data.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.GA","published":"2025-04-21T07:32:49Z"}
{"aid":"http://arxiv.org/abs/2504.14919v1","title":"GenCLIP: Generalizing CLIP Prompts for Zero-shot Anomaly Detection","summary":"Zero-shot anomaly detection (ZSAD) aims to identify anomalies in unseen\ncategories by leveraging CLIP's zero-shot capabilities to match text prompts\nwith visual features. A key challenge in ZSAD is learning general prompts\nstably and utilizing them effectively, while maintaining both generalizability\nand category specificity. Although general prompts have been explored in prior\nworks, achieving their stable optimization and effective deployment remains a\nsignificant challenge. In this work, we propose GenCLIP, a novel framework that\nlearns and leverages general prompts more effectively through multi-layer\nprompting and dual-branch inference. Multi-layer prompting integrates\ncategory-specific visual cues from different CLIP layers, enriching general\nprompts with more comprehensive and robust feature representations. By\ncombining general prompts with multi-layer visual features, our method further\nenhances its generalization capability. To balance specificity and\ngeneralization, we introduce a dual-branch inference strategy, where a\nvision-enhanced branch captures fine-grained category-specific features, while\na query-only branch prioritizes generalization. The complementary outputs from\nboth branches improve the stability and reliability of anomaly detection across\nunseen categories. Additionally, we propose an adaptive text prompt filtering\nmechanism, which removes irrelevant or atypical class names not encountered\nduring CLIP's training, ensuring that only meaningful textual inputs contribute\nto the final vision-language alignment.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T07:38:25Z"}
{"aid":"http://arxiv.org/abs/2504.14940v1","title":"Gigaparsec structures are nowhere to be seen in $$CDM: an\n  enhanced analysis of LSS in FLAMINGO-10K simulations","summary":"Recently, Sawala et al. 2025 claimed to refute the cosmological significance\nof the Giant Arc based on their analysis of the FLAMINGO-10K simulation data.\nIn our paper here, we highlight several shortcomings of the authors' analysis.\nWe then perform an enhanced analysis on the FLAMINGO-10K simulation data with\napplications of: the Single-Linkage Hierarchical Clustering (SLHC), the Convex\nHull of Member Spheres (CHMS), and the Minimal Spanning Tree (MST) algorithms.\nUsing the full $2.8^3$ Gpc$^3$ FLAMINGO-10K box, with subhaloes at $z=0.7$, and\n$100$ random realisations (from random subset selections) we find no gigaparsec\nstructures in FLAMINGO-10K, and only a few ultra-large large-scale structures\n(uLSSs, structures exceeding a maximum pairwise separation of $370$ Mpc).\nSomewhat surprisingly, we found that the large-scale aspects of the\nFLAMINGO-10K data could be adequately represented by a Poisson point\ndistribution. The enhanced analysis presented here further supports the\nremarkable nature of the Giant Arc as a cosmologically-significant structure.\nOf course, the Giant Arc is also accompanied by a second uLSS, the Big Ring.\nThe analysis presented here builds on the work presented by Sawala et al., but\namends the application of their statistical assessments. We do not yet know why\nthere appears to be such a large discrepancy between the FLAMINGO-10K data and\nthe observed LSS in MgII absorbers. Perhaps the results presented here might\nsuggest that the GA, and especially the GA + BR, presents a more direct\nchallenge to $\\Lambda$CDM. In contrast to the conclusion of Sawala et al. that\n`gigaparsec patterns abound in a $\\Lambda$CDM universe' we find that they are\nnowhere to be seen.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-21T08:02:11Z"}
{"aid":"http://arxiv.org/abs/2504.14974v1","title":"Nonreciprocal photon blockade induced by parametric amplification in an\n  asymmetrical cavity","summary":"We propose a scheme to generate and manipulate nonreciprocal photon blockade\neffect in an asymmetrical Fabry-P\\'{e}rot cavity, which consists of a single\ntwo-level atom and a second-order nonlinear medium. By utilizing the intrinsic\nspatial asymmetry of cavity and applying a parametric amplification pumping\nlaser to the nonlinear medium, we can realize direction-dependent single-photon\nand two-photon blockade effects. For nonreciprocal single-photon blockade, our\nproposal is robust across a wide range of parameters, such as the cavity or\natomic detuning, coupling strength, and atomic decay. Within similar parameter\nranges, nonreciprocal two-photon blockade can be achieved and modulated by\nfinely adjusting the parametric amplification pumping. Our project offers a\nfeasible access to generating high-quality and tunable nonreciprocal\nsingle/two-photon source and paves a new avenue for investigating the\nnonreciprocity of photon quantum statistical properties.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-21T09:00:37Z"}
{"aid":"http://arxiv.org/abs/2504.14985v1","title":"aiXamine: LLM Safety and Security Simplified","summary":"Evaluating Large Language Models (LLMs) for safety and security remains a\ncomplex task, often requiring users to navigate a fragmented landscape of ad\nhoc benchmarks, datasets, metrics, and reporting formats. To address this\nchallenge, we present aiXamine, a comprehensive black-box evaluation platform\nfor LLM safety and security. aiXamine integrates over 40 tests (i.e.,\nbenchmarks) organized into eight key services targeting specific dimensions of\nsafety and security: adversarial robustness, code security, fairness and bias,\nhallucination, model and data privacy, out-of-distribution (OOD) robustness,\nover-refusal, and safety alignment. The platform aggregates the evaluation\nresults into a single detailed report per model, providing a detailed breakdown\nof model performance, test examples, and rich visualizations. We used aiXamine\nto assess over 50 publicly available and proprietary LLMs, conducting over 2K\nexaminations. Our findings reveal notable vulnerabilities in leading models,\nincluding susceptibility to adversarial attacks in OpenAI's GPT-4o, biased\noutputs in xAI's Grok-3, and privacy weaknesses in Google's Gemini 2.0.\nAdditionally, we observe that open-source models can match or exceed\nproprietary models in specific services such as safety alignment, fairness and\nbias, and OOD robustness. Finally, we identify trade-offs between distillation\nstrategies, model size, training methods, and architectural choices.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-21T09:26:05Z"}
{"aid":"http://arxiv.org/abs/2504.14998v1","title":"Decay of mass for a semilinear heat equation on Heisenberg group","summary":"In this paper, we are concerned with the Cauchy problem for the\nreaction-diffusion equation with time-dependent absorption\n$u_{t}-\\Delta_{\\mathbb{H}}u=- k(t)u^p$ posed on $\\mathbb{H}^n$, driven by the\nHeisenberg Laplacian and supplemented with a nonnegative integrable initial\ndata, where $p>1$, $n\\geq 1$, and $k:(0,\\infty)\\to(0,\\infty)$ is a locally\nintegrable function. We study the large time behavior of non-negative solutions\nand show that the nonlinear term determines the large time asymptotic for\n$p\\leq 1+2/Q,$ while the classical/anomalous diffusion effects win if\n$p>1+{2}/{Q}$, where $Q=2n+2$ is the homogeneous dimension of $\\mathbb{H}^n$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-21T09:57:53Z"}
{"aid":"http://arxiv.org/abs/2504.15033v1","title":"Blinding the Wiretapper: RIS-Enabled User Occultation in the ISAC Era","summary":"An undesirable consequence of the foreseeable proliferation of sophisticated\nintegrated sensing and communications (ISAC) technologies is the enabling of\nspoofing, by malicious agents, of situational information (such as proximity,\ndirection or location) of legitimate users of wireless systems. In order to\nmitigate this threat, we present a novel ISAC scheme that, aided by a\nreconfigurable intelligent surface (RIS), enables the occultation of the\npositions of user equipment (UE) from wiretappers, while maintaining both\nsensing and desired communication performance between the UEs and a legitimate\nbase station (BS). To that end, we first formulate an RIS phase-shift\noptimization problem that jointly maximizes the sum-rate performance of the UEs\n(communication objective), while minimizing the projection of the wiretapper's\neffective channel onto the legitimate channel (hiding objective), thereby\ndisrupting the attempts by a wiretapper of localizing the UEs. Then, in order\nto efficiently solve the resulting non-convex joint optimization problem, a\nnovel manifold optimization algorithm is derived, whose effectiveness is\nvalidated by numerical results, which demonstrate that the proposed approach\npreserves legitimate ISAC performance while significantly degrading the\nwiretapper's sensing capability.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-21T11:41:28Z"}
{"aid":"http://arxiv.org/abs/2504.15034v1","title":"Predicting Methane Adsorption in Metal-Substituted MOFs: A Comparative\n  Study between Density Functional Theory and Machine Learning","summary":"Metal-organic frameworks (MOFs) are promising materials for methane capture\ndue to their high surface area and tunable properties. Metal substitution\nrepresents a powerful strategy to enhance MOF performance, yet systematic\nexploration of the vast chemical space remains challenging. In this work, we\ncompare density functional theory (DFT) and machine learning (ML) in predicting\nmethane adsorption properties in metal-substituted variants of three\nhigh-performing MOFs: M-HKUST-1, M-ATC, and M-ZIF-8 (M = Cu, Zn). DFT\ncalculations reveal significant differences in methane binding energetics\nbetween Cu and Zn variants of all three MOFs. On the other hand, we fine-tuned\na pretrained multimodal ML model, PMTransformer, on a curated subset of\nhypothetical MOF (hMOF) structures to predict macroscopic adsorption\nproperties. While the model qualitatively predicts adsorption properties for\nthe original unaltered MOFs, it fails to distinguish between metal variants\ndespite their different binding energetics identified by DFT. We trace this\nlimitation to the hMOF training data generated using Grand Canonical Monte\nCarlo (GCMC) simulations based on classical force fields (UFF/TraPPE). Our\nstudy highlights a key challenge in ML-based MOF screening: ML models inherit\nthe limitations of their training data, particularly when electronic effects\nsignificantly impact adsorption behavior. Our findings emphasize the need for\nimproved force fields or hybrid GCMC/DFT datasets to incorporate both geometric\nand electronic factors for accurate prediction of adsorption properties in\nmetal-substituted MOFs.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.chem-ph","published":"2025-04-21T11:41:32Z"}
{"aid":"http://arxiv.org/abs/2504.15035v1","title":"SOLIDO: A Robust Watermarking Method for Speech Synthesis via Low-Rank\n  Adaptation","summary":"The accelerated advancement of speech generative models has given rise to\nsecurity issues, including model infringement and unauthorized abuse of\ncontent. Although existing generative watermarking techniques have proposed\ncorresponding solutions, most methods require substantial computational\noverhead and training costs. In addition, some methods have limitations in\nrobustness when handling variable-length inputs. To tackle these challenges, we\npropose \\textsc{SOLIDO}, a novel generative watermarking method that integrates\nparameter-efficient fine-tuning with speech watermarking through low-rank\nadaptation (LoRA) for speech diffusion models. Concretely, the watermark\nencoder converts the watermark to align with the input of diffusion models. To\nachieve precise watermark extraction from variable-length inputs, the watermark\ndecoder based on depthwise separable convolution is designed for watermark\nrecovery. To further enhance speech generation performance and watermark\nextraction capability, we propose a speech-driven lightweight fine-tuning\nstrategy, which reduces computational overhead through LoRA. Comprehensive\nexperiments demonstrate that the proposed method ensures high-fidelity\nwatermarked speech even at a large capacity of 2000 bps. Furthermore, against\ncommon individual and compound speech attacks, our SOLIDO achieves a maximum\naverage extraction accuracy of 99.20\\% and 98.43\\%, respectively. It surpasses\nother state-of-the-art methods by nearly 23\\% in resisting time-stretching\nattacks.","main_category":"cs.CR","categories":"cs.CR,cs.AI,cs.SD","published":"2025-04-21T11:43:36Z"}
{"aid":"http://arxiv.org/abs/2504.15060v1","title":"Flexible polyhedral nets in isotropic geometry","summary":"We study flexible polyhedral nets in isotropic geometry. This geometry has a\ndegenerate metric, but there is a natural notion of flexibility. We study\ninfinitesimal and finite flexibility, and classify all finitely flexible\npolyhedral nets of arbitrary size. We show that there are just two classes, in\ncontrast to Izmestiev's rather involved classification in Euclidean geometry,\nfor size 3x3 only. Using these nets to initialize the optimization algorithms,\nwe turn them into approximate Euclidean mechanisms. We also explore the smooth\nversions of these classes.","main_category":"math.MG","categories":"math.MG","published":"2025-04-21T12:38:47Z"}
{"aid":"http://arxiv.org/abs/2504.15063v1","title":"Mining Characteristics of Vulnerable Smart Contracts Across Lifecycle\n  Stages","summary":"Smart contracts are the cornerstone of decentralized applications and\nfinancial protocols, which extend the application of digital currency\ntransactions. The applications and financial protocols introduce significant\nsecurity challenges, resulting in substantial economic losses. Existing\nsolutions predominantly focus on code vulnerabilities within smart contracts,\naccounting for only 50% of security incidents. Therefore, a more comprehensive\nstudy of security issues related to smart contracts is imperative. The existing\nempirical research realizes the static analysis of smart contracts from the\nperspective of the lifecycle and gives the corresponding measures for each\nstage. However, they lack the characteristic analysis of vulnerabilities in\neach stage and the distinction between the vulnerabilities. In this paper, we\npresent the first empirical study on the security of smart contracts throughout\ntheir lifecycle, including deployment and execution, upgrade, and destruction\nstages. It delves into the security issues at each stage and provides at least\nseven feature descriptions. Finally, utilizing these seven features, five\nmachine-learning classification models are used to identify vulnerabilities at\ndifferent stages. The classification results reveal that vulnerable contracts\nexhibit distinct transaction features and ego network properties at various\nstages.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-21T12:42:59Z"}
{"aid":"http://arxiv.org/abs/2504.15086v1","title":"Configuration Requirements for 21-cm Forest Background Quasar Searches\n  with the Moon-based Interferometer","summary":"The 21-cm forest offers a powerful cosmological probe of the thermal history\nand small-scale structure of the intergalactic medium during the Epoch of\nReionization (EoR). Its success, however, critically depends on the\navailability of high-redshift radio-loud quasars (HzRLQs) as background\nsources. In this work, we investigate the configuration requirements for a\nMoon-based low-frequency radio interferometer aimed at maximizing the detection\nof HzRLQs for future 21-cm forest studies. Building upon a previously developed\nquasar luminosity function (QLF), we forecast HzRLQ abundances under various\narray configurations. Assuming a total survey area of $10^4\\,\\mathrm{deg}^2$\nand 1 year of observation, we compare continuum surveys with 10 MHz bandwidth\nand 21-cm forest surveys with 5 kHz resolution. Our results show that a minimum\ncollecting area of $\\sim$6 500 m$^2$ enables detection at $z \\sim 6$, while\nSKA-like arrays ($N_{\\mathrm{st}} = 512$) extend the detection limit to $z \\sim\n10$ for 21-cm forest survey and $z \\sim 16$ for continuum survey. Larger arrays\nwith $N_{\\mathrm{st}} = 2048$ can reach $z \\sim 11$ in 21-cm forest mode. We\nalso explore configurations that maintain fixed collecting areas while\nincreasing the number to enhance survey efficiency. This boosts source\ndetection but significantly increases the data volume and computational\ndemands. These results underscore the importance of optimizing array design for\ndifferent survey goals and balancing sensitivity, spectral resolution, and data\nmanagement. A well-designed Moon-based array could open a new observational\nwindow on reionization and early cosmic structure formation.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph","published":"2025-04-21T13:20:16Z"}
{"aid":"http://arxiv.org/abs/2504.15090v1","title":"Federated Latent Factor Model for Bias-Aware Recommendation with\n  Privacy-Preserving","summary":"A recommender system (RS) aims to provide users with personalized item\nrecommendations, enhancing their overall experience. Traditional RSs collect\nand process all user data on a central server. However, this centralized\napproach raises significant privacy concerns, as it increases the risk of data\nbreaches and privacy leakages, which are becoming increasingly unacceptable to\nprivacy-sensitive users. To address these privacy challenges, federated\nlearning has been integrated into RSs, ensuring that user data remains secure.\nIn centralized RSs, the issue of rating bias is effectively addressed by\njointly analyzing all users' raw interaction data. However, this becomes a\nsignificant challenge in federated RSs, as raw data is no longer accessible due\nto privacy-preserving constraints. To overcome this problem, we propose a\nFederated Bias-Aware Latent Factor (FBALF) model. In FBALF, training bias is\nexplicitly incorporated into every local model's loss function, allowing for\nthe effective elimination of rating bias without compromising data privacy.\nExtensive experiments conducted on three real-world datasets demonstrate that\nFBALF achieves significantly higher recommendation accuracy compared to other\nstate-of-the-art federated RSs.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-21T13:24:30Z"}
{"aid":"http://arxiv.org/abs/2504.15113v1","title":"Adaptive sieving with semismooth Newton proximal augmented Lagrangian\n  algorithm for multi-task Lasso problems","summary":"Multi-task learning enhances model generalization by jointly learning from\nrelated tasks. This paper focuses on the $\\ell_{1,\\infty}$-norm constrained\nmulti-task learning problem, which promotes a shared feature representation\nwhile inducing sparsity in task-specific parameters. We propose an adaptive\nsieving (AS) strategy to efficiently generate a solution path for multi-task\nLasso problems. Each subproblem along the path is solved via an inexact\nsemismooth Newton proximal augmented Lagrangian ({\\sc Ssnpal}) algorithm,\nachieving an asymptotically superlinear convergence rate. By exploiting the\nKarush-Kuhn-Tucker (KKT) conditions and the inherent sparsity of multi-task\nLasso solutions, the {\\sc Ssnpal} algorithm solves a sequence of reduced\nsubproblems with small dimensions. This approach enables our method to scale\neffectively to large problems. Numerical experiments on synthetic and\nreal-world datasets demonstrate the superior efficiency and robustness of our\nalgorithm compared to state-of-the-art solvers.","main_category":"math.OC","categories":"math.OC","published":"2025-04-21T14:06:25Z"}
{"aid":"http://arxiv.org/abs/2504.15114v1","title":"Sensing with Quantum Light: A perspective","summary":"I present my perspective on sensing with quantum light. I summarise the\nmotivations and methodology for identifying quantum enhancements in sensing\nover a classical sensor. In the real world, this enhancement will be a constant\nfactor, and not increase with the size of the quantum probe as is often\nadvertised. I use a limited survey of interferometry, microscopy, and\nspectroscopy to extract the vital challenges that must be faced to realise\ntangible enhancements in sensing with quantum light.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-21T14:07:57Z"}
{"aid":"http://arxiv.org/abs/2504.15125v1","title":"Contemplative Wisdom for Superalignment","summary":"As artificial intelligence (AI) improves, traditional alignment strategies\nmay falter in the face of unpredictable self-improvement, hidden subgoals, and\nthe sheer complexity of intelligent systems. Rather than externally\nconstraining behavior, we advocate designing AI with intrinsic morality built\ninto its cognitive architecture and world model. Inspired by contemplative\nwisdom traditions, we show how four axiomatic principles can instil a resilient\nWise World Model in AI systems. First, mindfulness enables self-monitoring and\nrecalibration of emergent subgoals. Second, emptiness forestalls dogmatic goal\nfixation and relaxes rigid priors. Third, non-duality dissolves adversarial\nself-other boundaries. Fourth, boundless care motivates the universal reduction\nof suffering. We find that prompting AI to reflect on these principles improves\nperformance on the AILuminate Benchmark using GPT-4o, particularly when\ncombined. We offer detailed implementation strategies for state-of-the-art\nmodels, including contemplative architectures, constitutions, and reinforcement\nof chain-of-thought. For future systems, the active inference framework may\noffer the self-organizing and dynamic coupling capabilities needed to enact\nthese insights in embodied agents. This interdisciplinary approach offers a\nself-correcting and resilient alternative to prevailing brittle control\nschemes.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-21T14:20:49Z"}
{"aid":"http://arxiv.org/abs/2504.15188v1","title":"Synergistic Weak-Strong Collaboration by Aligning Preferences","summary":"Current Large Language Models (LLMs) excel in general reasoning yet struggle\nwith specialized tasks requiring proprietary or domain-specific knowledge.\nFine-tuning large models for every niche application is often infeasible due to\nblack-box constraints and high computational overhead. To address this, we\npropose a collaborative framework that pairs a specialized weak model with a\ngeneral strong model. The weak model, tailored to specific domains, produces\ninitial drafts and background information, while the strong model leverages its\nadvanced reasoning to refine these drafts, extending LLMs' capabilities to\ncritical yet specialized tasks. To optimize this collaboration, we introduce a\ncollaborative feedback to fine-tunes the weak model, which quantifies the\ninfluence of the weak model's contributions in the collaboration procedure and\nestablishes preference pairs to guide preference tuning of the weak model. We\nvalidate our framework through experiments on three domains. We find that the\ncollaboration significantly outperforms each model alone by leveraging\ncomplementary strengths. Moreover, aligning the weak model with the\ncollaborative preference further enhances overall performance.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-21T15:57:33Z"}
{"aid":"http://arxiv.org/abs/2504.15229v1","title":"Immersive Teleoperation Framework for Locomanipulation Tasks","summary":"Recent advancements in robotic loco-manipulation have leveraged Virtual\nReality (VR) to enhance the precision and immersiveness of teleoperation\nsystems, significantly outperforming traditional methods reliant on 2D camera\nfeeds and joystick controls. Despite these advancements, challenges remain,\nparticularly concerning user experience across different setups. This paper\nintroduces a novel VR-based teleoperation framework designed for a robotic\nmanipulator integrated onto a mobile platform. Central to our approach is the\napplication of Gaussian splatting, a technique that abstracts the manipulable\nscene into a VR environment, thereby enabling more intuitive and immersive\ninteractions. Users can navigate and manipulate within the virtual scene as if\ninteracting with a real robot, enhancing both the engagement and efficacy of\nteleoperation tasks. An extensive user study validates our approach,\ndemonstrating significant usability and efficiency improvements. Two-thirds\n(66%) of participants completed tasks faster, achieving an average time\nreduction of 43%. Additionally, 93% preferred the Gaussian Splat interface\noverall, with unanimous (100%) recommendations for future use, highlighting\nimprovements in precision, responsiveness, and situational awareness. Finally,\nwe demonstrate the effectiveness of our framework through real-world\nexperiments in two distinct application scenarios, showcasing the practical\ncapabilities and versatility of the Splat-based VR interface.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-21T17:00:31Z"}
{"aid":"http://arxiv.org/abs/2504.15231v1","title":"Linear Complementary Pairs of Quasi-Cyclic and Quasi-Twisted Codes","summary":"In this paper, we provide a polynomial characterization of linear\ncomplementary pairs of quasi-cyclic and quasi-twisted codes of index 2. We also\ngive several examples of linear complementary pairs of quasi-cyclic and\nquasi-twisted codes with (almost) optimal security parameters.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-21T17:08:28Z"}
{"aid":"http://arxiv.org/abs/2504.15254v1","title":"CRUST-Bench: A Comprehensive Benchmark for C-to-safe-Rust Transpilation","summary":"C-to-Rust transpilation is essential for modernizing legacy C code while\nenhancing safety and interoperability with modern Rust ecosystems. However, no\ndataset currently exists for evaluating whether a system can transpile C into\nsafe Rust that passes a set of test cases. We introduce CRUST-Bench, a dataset\nof 100 C repositories, each paired with manually-written interfaces in safe\nRust as well as test cases that can be used to validate correctness of the\ntranspilation. By considering entire repositories rather than isolated\nfunctions, CRUST-Bench captures the challenges of translating complex projects\nwith dependencies across multiple files. The provided Rust interfaces provide\nexplicit specifications that ensure adherence to idiomatic, memory-safe Rust\npatterns, while the accompanying test cases enforce functional correctness. We\nevaluate state-of-the-art large language models (LLMs) on this task and find\nthat safe and idiomatic Rust generation is still a challenging problem for\nvarious state-of-the-art methods and techniques. We also provide insights into\nthe errors LLMs usually make in transpiling code from C to safe Rust. The best\nperforming model, OpenAI o1, is able to solve only 15 tasks in a single-shot\nsetting. Improvements on CRUST-Bench would lead to improved transpilation\nsystems that can reason about complex scenarios and help in migrating legacy\ncodebases from C into languages like Rust that ensure memory safety. You can\nfind the dataset and code at https://github.com/anirudhkhatry/CRUST-bench.","main_category":"cs.SE","categories":"cs.SE,cs.CL","published":"2025-04-21T17:33:33Z"}
{"aid":"http://arxiv.org/abs/2504.15554v1","title":"Partition laser assembling technique","summary":"The advancement of micro/nanofabrication techniques with high throughput,\nefficiency, and flexibility is critical for fields like integrated photonics,\nbiosensing, and medical diagnostics. This study presents Partition Laser\nAssembling (PLA), a novel laser technique for fabricating complex\nmicro/nanostructures akin to puzzle pieces. By dividing the target patterns\ndescribed by scalable vector graphics into partitions, any structures in each\npartition can be fabricated via structured lights as \"light stamp\" through\nspatial light modulation. Unlike traditional direct laser writing, PLA\neliminates reliance on mechanical components, avoiding step-like artifacts and\nensuring smoother fabrication of complex micro/nanostructures. By seamlessly\nassembling basic shapes, PLA achieves intricate structures like micro artworks\nand metalenses with unmatched precision and resolution. Leveraging two-photon\nfabrication, PLA guarantees high resolution and structural integrity,\npositioning it as a transformative tool for nanoscale 3D printing. With\napplications spanning research and industry, PLA paves the way for advanced\noptical devices, micro/nanofabrications, and next-gen manufacturing\ntechnologies.","main_category":"physics.optics","categories":"physics.optics,physics.app-ph","published":"2025-04-22T03:18:54Z"}
{"aid":"http://arxiv.org/abs/2504.15577v1","title":"State-Aware IoT Scheduling Using Deep Q-Networks and Edge-Based\n  Coordination","summary":"This paper addresses the challenge of energy efficiency management faced by\nintelligent IoT devices in complex application environments. A novel\noptimization method is proposed, combining Deep Q-Network (DQN) with an edge\ncollaboration mechanism. The method builds a state-action-reward interaction\nmodel and introduces edge nodes as intermediaries for state aggregation and\npolicy scheduling. This enables dynamic resource coordination and task\nallocation among multiple devices. During the modeling process, device status,\ntask load, and network resources are jointly incorporated into the state space.\nThe DQN is used to approximate and learn the optimal scheduling strategy. To\nenhance the model's ability to perceive inter-device relationships, a\ncollaborative graph structure is introduced to model the multi-device\nenvironment and assist in decision optimization. Experiments are conducted\nusing real-world IoT data collected from the FastBee platform. Several\ncomparative and validation tests are performed, including energy efficiency\ncomparisons across different scheduling strategies, robustness analysis under\nvarying task loads, and evaluation of state dimension impacts on policy\nconvergence speed. The results show that the proposed method outperforms\nexisting baseline approaches in terms of average energy consumption, processing\nlatency, and resource utilization. This confirms its effectiveness and\npracticality in intelligent IoT scenarios.","main_category":"cs.NI","categories":"cs.NI,cs.LG","published":"2025-04-22T04:24:16Z"}
{"aid":"http://arxiv.org/abs/2504.15585v1","title":"A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training\n  and Deployment","summary":"The remarkable success of Large Language Models (LLMs) has illuminated a\npromising pathway toward achieving Artificial General Intelligence for both\nacademic and industrial communities, owing to their unprecedented performance\nacross various applications. As LLMs continue to gain prominence in both\nresearch and commercial domains, their security and safety implications have\nbecome a growing concern, not only for researchers and corporations but also\nfor every nation. Currently, existing surveys on LLM safety primarily focus on\nspecific stages of the LLM lifecycle, e.g., deployment phase or fine-tuning\nphase, lacking a comprehensive understanding of the entire \"lifechain\" of LLMs.\nTo address this gap, this paper introduces, for the first time, the concept of\n\"full-stack\" safety to systematically consider safety issues throughout the\nentire process of LLM training, deployment, and eventual commercialization.\nCompared to the off-the-shelf LLM safety surveys, our work demonstrates several\ndistinctive advantages: (I) Comprehensive Perspective. We define the complete\nLLM lifecycle as encompassing data preparation, pre-training, post-training,\ndeployment and final commercialization. To our knowledge, this represents the\nfirst safety survey to encompass the entire lifecycle of LLMs. (II) Extensive\nLiterature Support. Our research is grounded in an exhaustive review of over\n800+ papers, ensuring comprehensive coverage and systematic organization of\nsecurity issues within a more holistic understanding. (III) Unique Insights.\nThrough systematic literature analysis, we have developed reliable roadmaps and\nperspectives for each chapter. Our work identifies promising research\ndirections, including safety in data generation, alignment techniques, model\nediting, and LLM-based agent systems. These insights provide valuable guidance\nfor researchers pursuing future work in this field.","main_category":"cs.CR","categories":"cs.CR,cs.AI,cs.CL,cs.LG","published":"2025-04-22T05:02:49Z"}
{"aid":"http://arxiv.org/abs/2504.15602v1","title":"Mean Curvature Flow for Isoparametric Submanifolds in Hyperbolic Spaces","summary":"Mean curvature flows of isoparametric submanifolds in Euclidean spaces and\nspheres have been studied by Liu and Terng in \\cite{X.CT} and \\cite{X.C}. In\nparticular, it was proved that such flows always have ancient solutions. This\nis also true for mean curvature flows of isoparametric hypersurfaces in\nhyperbolic spaces by a result of Reis and Tenenblat in \\cite{S.H.T}. In this\npaper, we study mean curvature flows of isoparametric submanifolds in\nhyperbolic spaces with arbitrary codimension. In particular, we will show that\nthey always have ancient solutions and study their limiting behaviors.","main_category":"math.DG","categories":"math.DG","published":"2025-04-22T05:44:52Z"}
{"aid":"http://arxiv.org/abs/2504.15616v1","title":"SocialMOIF: Multi-Order Intention Fusion for Pedestrian Trajectory\n  Prediction","summary":"The analysis and prediction of agent trajectories are crucial for\ndecision-making processes in intelligent systems, with precise short-term\ntrajectory forecasting being highly significant across a range of applications.\nAgents and their social interactions have been quantified and modeled by\nresearchers from various perspectives; however, substantial limitations exist\nin the current work due to the inherent high uncertainty of agent intentions\nand the complex higher-order influences among neighboring groups. SocialMOIF is\nproposed to tackle these challenges, concentrating on the higher-order\nintention interactions among neighboring groups while reinforcing the primary\nrole of first-order intention interactions between neighbors and the target\nagent. This method develops a multi-order intention fusion model to achieve a\nmore comprehensive understanding of both direct and indirect intention\ninformation. Within SocialMOIF, a trajectory distribution approximator is\ndesigned to guide the trajectories toward values that align more closely with\nthe actual data, thereby enhancing model interpretability. Furthermore, a\nglobal trajectory optimizer is introduced to enable more accurate and efficient\nparallel predictions. By incorporating a novel loss function that accounts for\ndistance and direction during training, experimental results demonstrate that\nthe model outperforms previous state-of-the-art baselines across multiple\nmetrics in both dynamic and static datasets.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-22T06:14:49Z"}
{"aid":"http://arxiv.org/abs/2504.15621v1","title":"Regularization of elliptic multiple zeta values","summary":"In this paper, we show that regularized elliptic multiple zeta values are\ngiven by polynomials in elliptic multiple zeta values with admissible indices\nand special ones whose indices consist of 0 and 1.","main_category":"math.NT","categories":"math.NT","published":"2025-04-22T06:24:48Z"}
{"aid":"http://arxiv.org/abs/2504.15640v1","title":"Cost-Effective Text Clustering with Large Language Models","summary":"Text clustering aims to automatically partition a collection of text\ndocuments into distinct clusters based on linguistic features. In the\nliterature, this task is usually framed as metric clustering based on text\nembeddings from pre-trained encoders or a graph clustering problem upon\npairwise similarities from an oracle, e.g., a large ML model. Recently, large\nlanguage models (LLMs) bring significant advancement in this field by offering\ncontextualized text embeddings and highly accurate similarity scores, but\nmeanwhile, present grand challenges to cope with substantial computational\nand/or financial overhead caused by numerous API-based queries or inference\ncalls to the models.\n  In response, this paper proposes TECL, a cost-effective framework that taps\ninto the feedback from LLMs for accurate text clustering within a limited\nbudget of queries to LLMs. Under the hood, TECL adopts our EdgeLLM or\nTriangleLLM to construct must-link/cannot-link constraints for text pairs, and\nfurther leverages such constraints as supervision signals input to our weighted\nconstrained clustering approach to generate clusters. Particularly, EdgeLLM\n(resp. TriangleLLM) enables the identification of informative text pairs (resp.\ntriplets) for querying LLMs via well-thought-out greedy algorithms and accurate\nextraction of pairwise constraints through carefully-crafted prompting\ntechniques. Our experiments on multiple benchmark datasets exhibit that TECL\nconsistently and considerably outperforms existing solutions in unsupervised\ntext clustering under the same query cost for LLMs.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-22T06:57:49Z"}
{"aid":"http://arxiv.org/abs/2504.15646v1","title":"Quantum Corrections and Extremality: A Generalized Universal Relation","summary":"Logarithmic corrections to the entropy of extremal black holes have proven\neffective in precisely matching the microscopic degeneracies obtained from\nstring-theoretic as well as a non-perturbative quantum correction manifests as\nan exponential term in the black hole entropy. In this work, we extend the\nuniversal relation proposed by Goon and Penco by deriving a generalized form\nwhere entropy is not just the Bekenstein-Hawking entropy. Our analysis treats\nentropy as a general function of the horizon radius, and with the help of that,\nwe formulate the generalized universal relation. We show that, in the case of\nBekenstein-Hawking entropy, the generalized relation coincides with the\noriginal universal relation by Goon and Penco. Furthermore, we explore the\nimplications of logarithmic and exponential corrections to entropy and test the\nvalidity of the generalized universal relation under these modifications.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-22T07:12:53Z"}
{"aid":"http://arxiv.org/abs/2504.15663v1","title":"FADEL: Uncertainty-aware Fake Audio Detection with Evidential Deep\n  Learning","summary":"Recently, fake audio detection has gained significant attention, as\nadvancements in speech synthesis and voice conversion have increased the\nvulnerability of automatic speaker verification (ASV) systems to spoofing\nattacks. A key challenge in this task is generalizing models to detect unseen,\nout-of-distribution (OOD) attacks. Although existing approaches have shown\npromising results, they inherently suffer from overconfidence issues due to the\nusage of softmax for classification, which can produce unreliable predictions\nwhen encountering unpredictable spoofing attempts. To deal with this\nlimitation, we propose a novel framework called fake audio detection with\nevidential learning (FADEL). By modeling class probabilities with a Dirichlet\ndistribution, FADEL incorporates model uncertainty into its predictions,\nthereby leading to more robust performance in OOD scenarios. Experimental\nresults on the ASVspoof2019 Logical Access (LA) and ASVspoof2021 LA datasets\nindicate that the proposed method significantly improves the performance of\nbaseline models. Furthermore, we demonstrate the validity of uncertainty\nestimation by analyzing a strong correlation between average uncertainty and\nequal error rate (EER) across different spoofing algorithms.","main_category":"eess.AS","categories":"eess.AS,cs.AI","published":"2025-04-22T07:40:35Z"}
{"aid":"http://arxiv.org/abs/2504.15702v1","title":"Form factors from string amplitudes","summary":"In this letter, we propose a stringy model for $n$-point tree-level form\nfactor with the off-shell operator in the scalar and gluon theories, from the\nbosonic string disk amplitude: $n$ open string states and $1$ closed string\nstate scatter on the disk. In the field-theory limit ($\\alpha'\\to0$), the\nstringy form factor reduces to the form factor, helps us to investigate the\nhidden properties of the field-theory form factors, manifest the factorization\nand soft behaviors, and uncover more non-trivial relations between form factors\nand scattering amplitudes.","main_category":"hep-th","categories":"hep-th","published":"2025-04-22T08:45:17Z"}
{"aid":"http://arxiv.org/abs/2504.15704v1","title":"On relaxing the N-Reachability Implicit Requirement in NMPC Design","summary":"This paper proposes a proof of stability for Model Predictive Control\nformulations involving a prediction horizon that might be too short to meet the\nreachability condition generally invoked as a sufficient condition for\nclosed-loop stability. This condition is replaced by a contraction condition on\nthe stage cost. But unlike the contraction based existing formulations where\nthe prediction horizon becomes a decision variable, the formulation proposed in\nthis paper remains standard in that it uses constant and short prediction\nhorizon. An illustrative example is provided to assess the relevance of the\nproposed formulation.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-22T08:46:23Z"}
{"aid":"http://arxiv.org/abs/2504.15731v1","title":"Entropy Stabilized ZrHfCoNiSnSb Half-Heusler Alloy for Thermoelectric\n  Applications: A Theoretical Prediction","summary":"Half-Heusler (HH) alloys are potential thermoelectric materials for use at\nelevated temperatures due to their high Seebeck coefficient and superior\nmechanical and thermal stability. However, their enhanced lattice thermal\nconductivity is detrimental to thermoelectric applications. One way to\ncircumvent this problem is to introduce mass disorder at lattice sites by\nmixing the components of two or more alloys. Such systems are typically\nstabilized by the entropy of mixing. In this work, using computational tools,\nwe propose a mixed HH, namely, ZrHfCoNiSnSb, which can be formed by the\nelemental compositions of the parent half-Heuslers ZrNiSn/HfNiSn and\nHfCoSb/ZrCoSb. We propose that this new compound can be synthesized at elevated\ntemperatures, as its Gibbs free energy is reduced due to higher configurational\nentropy, making it more thermodynamically stable than the parent compounds\nunder such conditions. Our calculations indicate that it is a dynamically\nstable semiconductor with a band gap of 0.61 eV. Its lattice thermal\nconductivity at room temperature is $5.39~\\text{Wm}^{-1}\\text{K}^{-1}$, which\nis significantly lower than those of the parent compounds. The peak value of\nthis alloy's figure of merit (ZT) is 1.00 for the n-type carriers at 1100 K,\nwhich is 27% more than the best figure of merit obtained for the parent\ncompounds.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-22T09:25:06Z"}
{"aid":"http://arxiv.org/abs/2504.15764v1","title":"From Spin Waves to Monte Carlo Simulations: Compiling an Experimental\n  Exchange Interaction Dataset for Magnetic Materials","summary":"Inelastic neutron scattering data on magnetic crystals are highly valuable in\nmaterials science, as they provide direct insight into microscopic magnetic\ninteractions. Using spin wave theory, these interactions can be extracted from\nmagnetic excitations observed in such experiments. However, these datasets are\noften scattered across the literature and lack standardization, limiting their\naccessibility and usability. In this paper, we compile and standardize\nHeisenberg exchange interaction data for magnetic materials obtained from\ninelastic neutron scattering experiments. Through an extensive literature\nreview, we identify experimental data for approximately 100 magnetic materials.\nThe standardized dataset includes mapping the results of various Heisenberg\nHamiltonians into a unified standard form, visualizations of crystal structures\nwith annotated exchange interactions, and input and output files from Monte\nCarlo simulations performed for each compound using the ESpinS code. Using\nexperimentally determined exchange interactions, we calculate transition\ntemperatures $T_c$ via classical Monte Carlo simulations. Additionally, we\nassess the effectiveness of the $S+1)/S$ correction within classical Monte\nCarlo simulations, finding that it produces transition temperatures in\nexcellent agreement with experimental values in most cases. The complete\ndataset, along with supporting resources, is publicly available on GitHub.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-22T10:17:32Z"}
{"aid":"http://arxiv.org/abs/2504.15814v1","title":"Fast Higher-Order Interpolation and Restriction in ExaHyPE Avoiding\n  Non-physical Reflections","summary":"Wave equations help us to understand phenomena ranging from earthquakes to\ntsunamis. These phenomena materialise over very large scales. It would be\ncomputationally infeasible to track them over a regular mesh. Yet, since the\nphenomena are localised, adaptive mesh refinement (AMR) can be used to\nconstruct meshes with a higher resolution close to the regions of interest.\nExaHyPE is a software engine created to solve wave problems using AMR, and we\nuse it as baseline to construct our numerical relativity application called\nExaGRyPE. To advance the mesh in time, we have to interpolate and restrict\nalong resolution transitions in each and every time step. ExaHyPE's vanilla\ncode version uses a d-linear tensor-product approach. In benchmarks of a\nstationary black hole this performs slowly and leads to errors in conserved\nquantities near AMR boundaries. We therefore introduce a set of higher-order\ninterpolation schemes where the derivatives are calculated at each coarse grid\ncell to approximate the enclosed fine cells. The resulting methods run faster\nthan the tensor-product approach. Most importantly, when running the stationary\nblack hole simulation using the higher order methods the errors near the AMR\nboundaries are removed.","main_category":"cs.CE","categories":"cs.CE,cs.MS,gr-qc","published":"2025-04-22T11:52:58Z"}
{"aid":"http://arxiv.org/abs/2504.15822v1","title":"Quantifying Source Speaker Leakage in One-to-One Voice Conversion","summary":"Using a multi-accented corpus of parallel utterances for use with commercial\nspeech devices, we present a case study to show that it is possible to quantify\na degree of confidence about a source speaker's identity in the case of\none-to-one voice conversion. Following voice conversion using a HiFi-GAN\nvocoder, we compare information leakage for a range speaker characteristics;\nassuming a \"worst-case\" white-box scenario, we quantify our confidence to\nperform inference and narrow the pool of likely source speakers, reinforcing\nthe regulatory obligation and moral duty that providers of synthetic voices\nhave to ensure the privacy of their speakers' data.","main_category":"cs.SD","categories":"cs.SD,cs.CR,eess.AS","published":"2025-04-22T12:09:03Z"}
{"aid":"http://arxiv.org/abs/2504.15852v1","title":"Recovering Nesterov accelerated dynamics from Heavy Ball dynamics via\n  time rescaling","summary":"In a real Hilbert space, we consider two classical problems: the global\nminimization of a smooth and convex function $f$ (i.e., a convex optimization\nproblem) and finding the zeros of a monotone and continuous operator $V$ (i.e.,\na monotone equation). Attached to the optimization problem, first we study the\nasymptotic properties of the trajectories generated by a second-order dynamical\nsystem which features a constant viscous friction coefficient and a positive,\nmonotonically increasing function $b(\\cdot)$ multiplying $\\nabla f$. For a\ngenerated solution trajectory $y(t)$, we show small $o$ convergence rates\ndependent on $b(t)$ for $f(y(t)) - \\min f$, and the weak convergence of $y(t)$\ntowards a global minimizer of $f$. In 2015, Su, Boyd and Cand\\'es introduced a\nsecond-order system which could be seen as the continuous-time counterpart of\nNesterov's accelerated gradient. As the first key point of this paper, we show\nthat for a special choice for $b(t)$, these two seemingly unrelated dynamical\nsystems are connected: namely, they are time reparametrizations of each other.\nEvery statement regarding the continuous-time accelerated gradient system may\nbe recovered from its Heavy Ball counterpart.\n  As the second key point of this paper, we observe that this connection\nextends beyond the optimization setting. Attached to the monotone equation\ninvolving the operator $V$, we again consider a Heavy Ball-like system which\nfeatures an additional correction term which is the time derivative of the\noperator along the trajectory. We establish a time reparametrization\nequivalence with the Fast OGDA dynamics introduced by Bot, Csetnek and Nguyen\nin 2022, which can be seen as an analog of the continuous accelerated gradient\ndynamics, but for monotone operators. Again, every statement regarding the Fast\nOGDA system may be recovered from a Heavy Ball-like system.","main_category":"math.OC","categories":"math.OC","published":"2025-04-22T12:46:42Z"}
{"aid":"http://arxiv.org/abs/2504.15880v1","title":"Cryptoanalysis of a public key exchange based on circulant matrix over\n  digital semiring","summary":"We present a cryptanalysis of a key exchange protocol based on the digital\nsemiring. For this purpose, we find the maximal solution of a linear system\nover such semiring, and use the properties of circulant matrix to demonstrate\nthat the protocol is vulnerable. Specifically, we provide an efficient attack\nthat recovers the shared secret key from publicly exchanged information for any\ninstance of the digital semiring in polynomial time.","main_category":"cs.CR","categories":"cs.CR,cs.IT,math.AC,math.IT","published":"2025-04-22T13:25:29Z"}
{"aid":"http://arxiv.org/abs/2504.15932v1","title":"Reasoning Physical Video Generation with Diffusion Timestep Tokens via\n  Reinforcement Learning","summary":"Despite recent progress in video generation, producing videos that adhere to\nphysical laws remains a significant challenge. Traditional diffusion-based\nmethods struggle to extrapolate to unseen physical conditions (eg, velocity)\ndue to their reliance on data-driven approximations. To address this, we\npropose to integrate symbolic reasoning and reinforcement learning to enforce\nphysical consistency in video generation. We first introduce the Diffusion\nTimestep Tokenizer (DDT), which learns discrete, recursive visual tokens by\nrecovering visual attributes lost during the diffusion process. The recursive\nvisual tokens enable symbolic reasoning by a large language model. Based on it,\nwe propose the Phys-AR framework, which consists of two stages: The first stage\nuses supervised fine-tuning to transfer symbolic knowledge, while the second\nstage applies reinforcement learning to optimize the model's reasoning\nabilities through reward functions based on physical conditions. Our approach\nallows the model to dynamically adjust and improve the physical properties of\ngenerated videos, ensuring adherence to physical laws. Experimental results\ndemonstrate that PhysAR can generate videos that are physically consistent.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T14:20:59Z"}
{"aid":"http://arxiv.org/abs/2504.15936v1","title":"An effectful object calculus","summary":"We show how to smoothly incorporate in the object-oriented paradigm\nconstructs to raise, compose, and handle effects in an arbitrary monad. The\nunderlying pure calculus is meant to be a representative of the last generation\nof OO languages, and the effectful extension is manageable enough for ordinary\nprogrammers; notably, constructs to raise effects are just special methods. We\nequip the calculus with an expressive type-and-effect system, which, again by\nrelying on standard features such as inheritance and generic types, allows a\nsimple form of effect polymorphism. The soundness of the type-and-effect system\nis expressed and proved by a recently introduced technique, where the semantics\nis formalized by a one-step reduction relation from language expressions into\nmonadic ones, so that it is enough to prove progress and subject reduction\nproperties on this relation.","main_category":"cs.PL","categories":"cs.PL","published":"2025-04-22T14:24:59Z"}
{"aid":"http://arxiv.org/abs/2504.15944v1","title":"Deep learning of point processes for modeling high-frequency data","summary":"We investigate applications of deep neural networks to a point process having\nan intensity with mixing covariates processes as input. Our generic model\nincludes Cox-type models and marked point processes as well as multivariate\npoint processes. An oracle inequality and a rate of convergence are derived for\nthe prediction error. A simulation study shows that the marked point process\ncan be superior to the simple multivariate model in prediction. We apply the\nmarked ratio model to real limit order book data","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-22T14:42:16Z"}
{"aid":"http://arxiv.org/abs/2504.15946v1","title":"The e-Partitioning Principle of False Discovery Rate Control","summary":"We present a novel necessary and sufficient principle for False Discovery\nRate (FDR) control. This e-Partitioning Principle says that a procedure\ncontrols FDR if and only if it is a special case of a general e-Partitioning\nprocedure. By writing existing methods as special cases of this procedure, we\ncan achieve uniform improvements of these methods, and we show this in\nparticular for the eBH, BY and Su methods. We also show that methods developed\nusing the $e$-Partitioning Principle have several valuable properties. They\ngenerally control FDR not just for one rejected set, but simultaneously over\nmany, allowing post hoc flexibility for the researcher in the final choice of\nthe rejected hypotheses. Under some conditions, they also allow for post hoc\nadjustment of the error rate, choosing the FDR level $\\alpha$ post hoc, or\nswitching to familywise error control after seeing the data. In addition,\ne-Partitioning allows FDR control methods to exploit logical relationships\nbetween hypotheses to gain power.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-22T14:45:23Z"}
{"aid":"http://arxiv.org/abs/2504.15954v1","title":"Monocular inspection of spacecraft under illumination constraints and\n  avoidance regions","summary":"This paper presents an adaptive control approach to information-based\nguidance and control of a spacecraft carrying out on-orbit inspection by\nactively computing optimal policies for the spacecraft to achieve the best\npossible representation of objects within its orbital environment. Due to the\ncomplexity of navigating the space environment, it may be impossible to carry\nout on-orbit servicing to maintain space systems like satellites using a\nspacecraft equipped with controllers that cannot adapt to changing conditions.\nIn particular, the presence of constraints such as illumination, field-of-view\n(FOV), minimal fuel, the use of visual-inertial navigation for improved\nlocalization, and the need for real-time computation of control policies render\nthe spacecraft motion planning problem challenging. The control framework\ndeveloped in this paper addresses these challenges by formulating the\ninspection task as a constrained optimization problem where the goal is to\nmaximize information gained from the cameras, while navigating to the next best\nview, subject to illumination and FOV constraints. The developed architecture\nis analyzed using a Lyapunov-based stability analysis and the effectiveness of\nthe planning algorithm is verified in simulation.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-22T14:50:09Z"}
{"aid":"http://arxiv.org/abs/2504.16009v1","title":"Upscaling the Navier-Stokes-Cahn-Hilliard model for incompressible\n  multiphase flow in inhomogeneous porous media","summary":"In this work, we present a macroscopic model for the flow of two immiscible\nand incompressible fluids in inhomogeneous porous medium. At the pore scale,\nthe flow is governed by the fully Navier-Stokes equations while the evolution\nof the phase interface is captured by the Cahn-Hilliard equation. Using the\nvolume averaging method, the upscaled equations describing the averaged\nbehavior of two fluids at the Darcy scale are obtained, with unclosed terms\nrelated to spatial deviations. Then, spatial derivations are carefully modeled\nup to some undetermined coefficients, which could be evaluated by solving\nsimplified closure problems in each representative volume element. In\nparticular, the wetting behavior is incorporated into the averaged chemical\npotential. The differences between the proposed equations and the empirical\ntwo-phase Darcy-type models are discussed. Finally, a phase-field-based lattice\nBoltzmann model for the averaged equations is presented, and numerical results\ndemonstrate the abilities of the proposed model.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,math-ph,math.MP,physics.comp-ph,physics.geo-ph","published":"2025-04-22T16:16:19Z"}
{"aid":"http://arxiv.org/abs/2504.16042v1","title":"Approximate matrices of systems of max-min fuzzy relational equations","summary":"In this article, we address the inconsistency of a system of max-min fuzzy\nrelational equations by minimally modifying the matrix governing the system in\norder to achieve consistency. Our method yields consistent systems that\napproximate the original inconsistent system in the following sense: the\nright-hand side vector of each consistent system is that of the inconsistent\nsystem, and the coefficients of the matrix governing each consistent system are\nobtained by modifying, exactly and minimally, the entries of the original\nmatrix that must be corrected to achieve consistency, while leaving all other\nentries unchanged.\n  To obtain a consistent system that closely approximates the considered\ninconsistent system, we study the distance (in terms of a norm among $L_1$,\n$L_2$ or $L_\\infty$) between the matrix of the inconsistent system and the set\nformed by the matrices of consistent systems that use the same right-hand side\nvector as the inconsistent system. We show that our method allows us to\ndirectly compute matrices of consistent systems that use the same right-hand\nside vector as the inconsistent system whose distance in terms of $L_\\infty$\nnorm to the matrix of the inconsistent system is minimal (the computational\ncosts are higher when using $L_1$ norm or $L_2$ norm). We also give an explicit\nanalytical formula for computing this minimal $L_\\infty$ distance. Finally, we\ntranslate our results for systems of min-max fuzzy relational equations and\npresent some potential applications.","main_category":"cs.AI","categories":"cs.AI,cs.LO","published":"2025-04-22T17:09:02Z"}
{"aid":"http://arxiv.org/abs/2504.16048v1","title":"PRIME: Fast Primal-Dual Feedback Optimization for Markets with\n  Application to Optimal Power Flow","summary":"Online Feedback Optimization (OFO) controllers iteratively drive a plant to\nan optimal operating point that satisfies input and output constraints, relying\nsolely on the input-output sensitivity as model information. This paper\nintroduces PRIME (PRoximal Iterative MarkEts), a novel OFO approach based on\nproximal-point iterations. Unlike existing OFO solutions, PRIME admits a\nmarket-based implementation, where self-interested actors are incentivized to\nmake choices that result in a safe and efficient operation, without\ncommunicating private costs or constraints. Furthermore, PRIME can cope with\nnon-smooth objective functions, achieve fast convergence rates and rapid\nconstraint satisfaction, and reject measurement noise. We demonstrate PRIME on\nan AC optimal power flow problem, obtaining an efficient real-time nonlinear\nlocal marginal pricing scheme.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-22T17:25:40Z"}
{"aid":"http://arxiv.org/abs/2504.16057v1","title":"Automated Static Vulnerability Detection via a Holistic Neuro-symbolic\n  Approach","summary":"Static vulnerability detection is still a challenging problem and demands\nexcessive human efforts, e.g., manual curation of good vulnerability patterns.\nNone of prior works, including classic program analysis or Large Language Model\n(LLM)-based approaches, have fully automated such vulnerability pattern\ngenerations with reasonable detection accuracy. In this paper, we design and\nimplement, MoCQ, a novel holistic neuro-symbolic framework that combines the\ncomplementary strengths of LLMs and classical static analysis to enable\nscalable vulnerability detection. The key insight is that MoCQ leverages an LLM\nto automatically extract vulnerability patterns and translate them into\ndetection queries, and then on static analysis to refine such queries in a\nfeedback loop and eventually execute them for analyzing large codebases and\nmining vulnerabilities. We evaluate MoCQ on seven types of vulnerabilities\nspanning two programming languages. We found MoCQ-generated queries uncovered\nat least 12 patterns that were missed by experts. On a ground truth dataset,\nMoCQ achieved comparable precision and recall compared to expert-crafted\nqueries. Moreover, MoCQ has identified seven previously unknown vulnerabilities\nin real-world applications, demonstrating its practical effectiveness. We have\nresponsibly disclosed them to the corresponding developers.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-22T17:33:53Z"}
{"aid":"http://arxiv.org/abs/2504.16062v1","title":"ForesightNav: Learning Scene Imagination for Efficient Exploration","summary":"Understanding how humans leverage prior knowledge to navigate unseen\nenvironments while making exploratory decisions is essential for developing\nautonomous robots with similar abilities. In this work, we propose\nForesightNav, a novel exploration strategy inspired by human imagination and\nreasoning. Our approach equips robotic agents with the capability to predict\ncontextual information, such as occupancy and semantic details, for unexplored\nregions. These predictions enable the robot to efficiently select meaningful\nlong-term navigation goals, significantly enhancing exploration in unseen\nenvironments. We validate our imagination-based approach using the Structured3D\ndataset, demonstrating accurate occupancy prediction and superior performance\nin anticipating unseen scene geometry. Our experiments show that the\nimagination module improves exploration efficiency in unseen environments,\nachieving a 100% completion rate for PointNav and an SPL of 67% for ObjectNav\non the Structured3D Validation split. These contributions demonstrate the power\nof imagination-driven reasoning for autonomous systems to enhance generalizable\nand efficient exploration.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-22T17:38:38Z"}
{"aid":"http://arxiv.org/abs/2504.16390v1","title":"Probing Bulk Band Topology from Time Boundary Effect in Synthetic\n  Dimension","summary":"An incident wave at a temporal interface, created by an abrupt change in\nsystem parameters, generates time-refracted and time-reflected waves. We find\ntopological characteristics associated with the temporal interface that\nseparates distinct spatial topologies and report a novel bulk-boundary\ncorrespondence for the temporal interface. The vanishing of either time\nrefraction or time reflection records a topological phase transition across the\ntemporal interface, and the difference of bulk band topology predicts\nnontrivial braiding hidden in the time refraction and time reflection\ncoefficients. These findings, which are insensitive to spatial boundary\nconditions and robust against disorder, are demonstrated in a synthetic\nfrequency lattice with rich topological phases engendered by long-range\ncouplings. Our work reveals the topological aspect of temporal interface and\npaves the way for using the time boundary effect to probe topological phase\ntransitions and topological invariants.","main_category":"physics.optics","categories":"physics.optics,quant-ph","published":"2025-04-23T03:35:12Z"}
{"aid":"http://arxiv.org/abs/2504.16412v1","title":"Superconductivity and Electron Correlations in Kagome Metal LuOs3B2","summary":"We report a comprehensive investigation of the physical properties of\nLuOs3B2, characterized by an ideal Os-based kagome lattice. Resistivity and\nmagnetization measurements confirm the emergence of type-II bulk\nsuperconductivity with a critical temperature Tc=4.63 K. The specific heat jump\nand the calculated electron-phonon coupling parameter support a moderately\ncoupled superconducting state. Electron correlation effects are supported by\nthe enhanced Wilson ratios. First-principles calculations reveal hallmark\nfeatures of kagome band structure, including Dirac points, van Hove\nsingularities, and quasi-flat bands, primarily derived from the Os d orbitals.\nThe inclusion of spin-orbit coupling opens a gap at the Dirac points,\nsignificantly altering the electronic properties. Furthermore, the\nsuperconductivity and electronic properties of isomorphic compounds are\ndiscussed. This work provides a thorough exploration of the superconducting and\nnormal states of LuOs3B2, deepening the understanding of kagome\nsuperconductors.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-23T04:28:50Z"}
{"aid":"http://arxiv.org/abs/2504.16443v1","title":"Marginalized Generalized IoU (MGIoU): A Unified Objective Function for\n  Optimizing Any Convex Parametric Shapes","summary":"Optimizing the similarity between parametric shapes is crucial for numerous\ncomputer vision tasks, where Intersection over Union (IoU) stands as the\ncanonical measure. However, existing optimization methods exhibit significant\nshortcomings: regression-based losses like L1/L2 lack correlation with IoU,\nIoU-based losses are unstable and limited to simple shapes, and task-specific\nmethods are computationally intensive and not generalizable accross domains. As\na result, the current landscape of parametric shape objective functions has\nbecome scattered, with each domain proposing distinct IoU approximations. To\naddress this, we unify the parametric shape optimization objective functions by\nintroducing Marginalized Generalized IoU (MGIoU), a novel loss function that\novercomes these challenges by projecting structured convex shapes onto their\nunique shape Normals to compute one-dimensional normalized GIoU. MGIoU offers a\nsimple, efficient, fully differentiable approximation strongly correlated with\nIoU. We then extend MGIoU to MGIoU+ that supports optimizing unstructured\nconvex shapes. Together, MGIoU and MGIoU+ unify parametric shape optimization\nacross diverse applications. Experiments on standard benchmarks demonstrate\nthat MGIoU and MGIoU+ consistently outperform existing losses while reducing\nloss computation latency by 10-40x. Additionally, MGIoU and MGIoU+ satisfy\nmetric properties and scale-invariance, ensuring robustness as an objective\nfunction. We further propose MGIoU- for minimizing overlaps in tasks like\ncollision-free trajectory prediction. Code is available at\nhttps://ldtho.github.io/MGIoU","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T06:05:39Z"}
{"aid":"http://arxiv.org/abs/2504.16455v1","title":"Cross Paradigm Representation and Alignment Transformer for Image\n  Deraining","summary":"Transformer-based networks have achieved strong performance in low-level\nvision tasks like image deraining by utilizing spatial or channel-wise\nself-attention. However, irregular rain patterns and complex geometric overlaps\nchallenge single-paradigm architectures, necessitating a unified framework to\nintegrate complementary global-local and spatial-channel representations. To\naddress this, we propose a novel Cross Paradigm Representation and Alignment\nTransformer (CPRAformer). Its core idea is the hierarchical representation and\nalignment, leveraging the strengths of both paradigms (spatial-channel and\nglobal-local) to aid image reconstruction. It bridges the gap within and\nbetween paradigms, aligning and coordinating them to enable deep interaction\nand fusion of features. Specifically, we use two types of self-attention in the\nTransformer blocks: sparse prompt channel self-attention (SPC-SA) and spatial\npixel refinement self-attention (SPR-SA). SPC-SA enhances global channel\ndependencies through dynamic sparsity, while SPR-SA focuses on spatial rain\ndistribution and fine-grained texture recovery. To address the feature\nmisalignment and knowledge differences between them, we introduce the Adaptive\nAlignment Frequency Module (AAFM), which aligns and interacts with features in\na two-stage progressive manner, enabling adaptive guidance and complementarity.\nThis reduces the information gap within and between paradigms. Through this\nunified cross-paradigm dynamic interaction framework, we achieve the extraction\nof the most valuable interactive fusion information from the two paradigms.\nExtensive experiments demonstrate that our model achieves state-of-the-art\nperformance on eight benchmark datasets and further validates CPRAformer's\nrobustness in other image restoration tasks and downstream applications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T06:44:46Z"}
{"aid":"http://arxiv.org/abs/2504.16456v1","title":"A measure-theoretic expansion exponent","summary":"The expansion exponent (or expansion constant) for maps was introduced by\nSchreiber in \\cite{s}. In this paper, we introduce the analogous exponent for\nmeasures. We shall prove the following results: The expansion exponent of a\nmeasurable maps is equal to the minimum of the expansion exponent taken over\nthe Borel probability measures. In particular, a map expands small distances\n(in the sense of Reddy \\cite{r}) if and only if every Borel probability has\npositive expansion exponent. Any nonatomic invariant measure with positive\nexpansion exponent is positively expansive in the sense of \\cite{m}. For\nergodic invariant measures, the Kolmogorov-Sinai entropy is bounded below by\nthe product of the expansion exponent and the measure upper capacity. As a\nconsequence, any ergodic invariant measure with both positive upper capacity\nand positive expansion exponent must have positive entropy.","main_category":"math.DS","categories":"math.DS","published":"2025-04-23T06:50:53Z"}
{"aid":"http://arxiv.org/abs/2504.16464v1","title":"ManipDreamer: Boosting Robotic Manipulation World Model with Action Tree\n  and Visual Guidance","summary":"While recent advancements in robotic manipulation video synthesis have shown\npromise, significant challenges persist in ensuring effective\ninstruction-following and achieving high visual quality. Recent methods, like\nRoboDreamer, utilize linguistic decomposition to divide instructions into\nseparate lower-level primitives, conditioning the world model on these\nprimitives to achieve compositional instruction-following. However, these\nseparate primitives do not consider the relationships that exist between them.\nFurthermore, recent methods neglect valuable visual guidance, including depth\nand semantic guidance, both crucial for enhancing visual quality. This paper\nintroduces ManipDreamer, an advanced world model based on the action tree and\nvisual guidance. To better learn the relationships between instruction\nprimitives, we represent the instruction as the action tree and assign\nembeddings to tree nodes, each instruction can acquire its embeddings by\nnavigating through the action tree. The instruction embeddings can be used to\nguide the world model. To enhance visual quality, we combine depth and semantic\nguidance by introducing a visual guidance adapter compatible with the world\nmodel. This visual adapter enhances both the temporal and physical consistency\nof video generation. Based on the action tree and visual guidance, ManipDreamer\nsignificantly boosts the instruction-following ability and visual quality.\nComprehensive evaluations on robotic manipulation benchmarks reveal that\nManipDreamer achieves large improvements in video quality metrics in both seen\nand unseen tasks, with PSNR improved from 19.55 to 21.05, SSIM improved from\n0.7474 to 0.7982 and reduced Flow Error from 3.506 to 3.201 in unseen tasks,\ncompared to the recent RoboDreamer model. Additionally, our method increases\nthe success rate of robotic manipulation tasks by 2.5% in 6 RLbench tasks on\naverage.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-23T07:23:41Z"}
{"aid":"http://arxiv.org/abs/2504.16470v1","title":"Improved Streaming Edge Coloring","summary":"Given a graph, an edge coloring assigns colors to edges so that no pairs of\nadjacent edges share the same color. We are interested in edge coloring\nalgorithms under the W-streaming model. In this model, the algorithm does not\nhave enough memory to hold the entire graph, so the edges of the input graph\nare read from a data stream one by one in an unknown order, and the algorithm\nneeds to print a valid edge coloring in an output stream. The performance of\nthe algorithm is measured by the amount of space and the number of different\ncolors it uses.\n  This streaming edge coloring problem has been studied by several works in\nrecent years. When the input graph contains $n$ vertices and has maximum vertex\ndegree $\\Delta$, it is known that in the W-streaming model, an\n$O(\\Delta^2)$-edge coloring can be computed deterministically with\n$\\tilde{O}(n)$ space [Ansari, Saneian, and Zarrabi-Zadeh, 2022], or an\n$O(\\Delta^{1.5})$-edge coloring can be computed by a $\\tilde{O}(n)$-space\nrandomized algorithm [Behnezhad, Saneian, 2024] [Chechik, Mukhtar, Zhang,\n2024].\n  In this paper, we achieve polynomial improvement over previous results.\nSpecifically, we show how to improve the number of colors to\n$\\tilde{O}(\\Delta^{4/3+\\epsilon})$ using space $\\tilde{O}(n)$\ndeterministically, for any constant $\\epsilon > 0$. This is the first\ndeterministic result that bypasses the quadratic bound on the number of colors\nwhile using near-linear space.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-23T07:29:57Z"}
{"aid":"http://arxiv.org/abs/2504.16517v1","title":"Gravitational Equilibrium with Steady Flow and Relativistic Local\n  Thermodynamics","summary":"A relativistic self-gravitating equilibrium system with steady flow as well\nas spherical symmetry is discovered. The energy-momentum tensor contains the\ncontribution of a current related to the flow and the metric tensor does an\noff-diagonal component to balance with the flow momentum. The presence of the\noff-diagonal component of the metric implies the radial motion of the reference\nframe, which gives rise to a problem how the relativistic effect is included in\nthermodynamic observables for such a general relativistic system. This problem\nis solved by taking an instantaneously rest frame in which geometric\nthermodynamic observables read as previously and giving them the special\nrelativistic effect emerged from the inverse transformation to the original\nframe pointwise. The solution of the thermodynamic observables in accord with\nthe laws of thermodynamics and the theory of relativity is presented. Finally\nthe relativistic structure equations for the equilibrium are derived, from\nwhich the general relativistic Poisson equation as well as the heat conduction\none are developed exactly.","main_category":"gr-qc","categories":"gr-qc,astro-ph.SR,hep-ph,hep-th","published":"2025-04-23T08:42:20Z"}
{"aid":"http://arxiv.org/abs/2504.16534v1","title":"Partitioning of multiple brain metastases improves dose gradients in\n  single-isocenter radiosurgery","summary":"Background: A growing number of cancer patients with brain metastases can\nbenefit from stereotactic radiosurgery (SRS) thanks to recent advances in\nsystemic therapies. With an increasing patient load, single-isocenter\ntreatments on widely available C-arm linear accelerators are an attractive\noption. However, the planning of such treatments is challenging for\nmulti-target cases due to the island blocking problem, which occurs when the\nmulti-leaf collimator cannot conform to all targets simultaneously.\n  Purpose: We propose a multi-target partitioning algorithm that mitigates\nexcessive exposure of normal tissue caused by the island blocking problem.\n  Methods: The algorithm divides (partitions) the set of targets into subsets\nto treat with separate arc passes, optimizing both subsets and collimator\nangles to minimize island blocking. The algorithm was incorporated into a fully\nautomated treatment planning script and evaluated on 20 simulated patient\ncases, each with 10 brain metastases and 21 Gy prescriptions. It was also\nretrospectively evaluated on six clinical cases.\n  Results: Partitioning significantly improved the gradient index, global\nefficiency index, and brain V12Gy compared to simultaneous treatment of all\nmetastases. For example, the average gradient index improved from 5.9 to 3.3,\nglobal efficiency index from 0.32 to 0.46, and normal brain V12Gy from 49 cm3\nto 26 cm3 between 3 and 9 arcs. The proposed algorithm outperformed baselines\nin utilizing a limited number of arcs. All target partitioning strategies\nincreased the total number of monitor units (MUs).\n  Conclusions: The dose gradient in single-isocenter VMAT plans can be\nsubstantially improved by treating a smaller subset of metastases at a time.\nThis requires more MUs and arcs, implying a trade-off between delivery time and\nplan quality which can be explored using the algorithm proposed in this paper.","main_category":"physics.med-ph","categories":"physics.med-ph","published":"2025-04-23T09:02:57Z"}
{"aid":"http://arxiv.org/abs/2504.16560v1","title":"On existence of spatially regular strong solutions for a class of\n  transport equations","summary":"The paper considers existence of spatially regular solutions for a class of\nlinear Boltzmann transport equations. The related transport problem is an\n(initial) inflow boundary value problem. This problem is characteristic with\nvariable multiplicity, that is, the rank of the boundary matrix (here a scalar)\nis not constant on the boundary. It is known that for these types of (initial)\nboundary value problems the full higher order Sobolev regularity cannot\ngenerally be established. In this paper we present Sobolev regularity results\nfor solutions of linear Boltzmann transport problems when the data belongs to\nappropriate anisotropic Sobolev spaces whose elements are zero on the inflow\nand characteristic parts of the boundary.","main_category":"math.AP","categories":"math.AP","published":"2025-04-23T09:39:32Z"}
{"aid":"http://arxiv.org/abs/2504.16572v1","title":"Bridging Data Gaps and Building Knowledge Networks in Indian Football\n  Analytics","summary":"The global rise of football analytics has rapidly transformed how clubs make\nstrategic decisions. However, in India, the adoption of analytics remains\nconstrained by institutional resistance, infrastructural limitations, and\ncultural barriers -- challenges that grassroots innovation and low-cost data\nsolutions have the potential to overcome. Despite the growing popularity of the\nIndian Super League, resource scarcity and fragmented governance continue to\nhinder the widespread adoption and impact of analytics. This mixed-methods\nstudy explores how informal, decentralised analytics communities -- comprising\namateur analysts and Twitter-based \"data sleuths\" -- navigate these constraints\nthrough peer mentorship and grassroots innovation. Drawing on extensive digital\nethnography, participant observation, and interviews, the study illustrates how\nthese informal networks mitigate data scarcity, limited digital infrastructure,\nand institutional indifference while fostering skill development and\nprofessional growth. Building on these insights, the paper proposes HCI\ninterventions such as decentralised knowledge platforms to facilitate\nstructured, cross-border peer mentorship and low-cost data solutions --\nincluding AI-assisted player tracking and mobile analytics dashboards -- rooted\nin principles of frugal innovation. These interventions aim to bridge the data\ndivide, support inclusive technical engagement in sport, and enhance\nanalytics-driven decision-making in resource-constrained environments. This\npaper contributes to HCIxB's focus on cross-border collaboration by\nhighlighting how community-driven technological adaptation in the Global South\ncan foster meaningful participation, skill-building, and long-term\nsustainability through informal learning networks and scalable,\ncontext-sensitive tools.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-23T09:48:23Z"}
{"aid":"http://arxiv.org/abs/2504.16586v1","title":"Learning Switchable Priors for Neural Image Compression","summary":"Neural image compression (NIC) usually adopts a predefined family of\nprobabilistic distributions as the prior of the latent variables, and meanwhile\nrelies on entropy models to estimate the parameters for the probabilistic\nfamily. More complex probabilistic distributions may fit the latent variables\nmore accurately, but also incur higher complexity of the entropy models,\nlimiting their practical value. To address this dilemma, we propose a solution\nto decouple the entropy model complexity from the prior distributions. We use a\nfinite set of trainable priors that correspond to samples of the parametric\nprobabilistic distributions. We train the entropy model to predict the index of\nthe appropriate prior within the set, rather than the specific parameters.\nSwitching between the trained priors further enables us to embrace a skip mode\ninto the prior set, which simply omits a latent variable during the entropy\ncoding. To demonstrate the practical value of our solution, we present a\nlightweight NIC model, namely FastNIC, together with the learning of switchable\npriors. FastNIC obtains a better trade-off between compression efficiency and\ncomputational complexity for neural image compression. We also implanted the\nswitchable priors into state-of-the-art NIC models and observed improved\ncompression efficiency with a significant reduction of entropy coding\ncomplexity.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-23T10:06:58Z"}
{"aid":"http://arxiv.org/abs/2504.16587v1","title":"Spin polarization as a probe of the QCD critical point","summary":"Spin polarization is a novel method for probing the rotational properties of\nthe quark-gluon plasma (QGP) produced in relativistic heavy-ion collisions. In\nthis work, we investigate the effective transport and thermodynamic\ncoefficients in non-central O+O light-ion collisions, considering a parton\ndistribution function that incorporates the spin polarization induced by\nthermal vorticity during the collision. Using a kinetic theory approach, we\nfind that while the speed of sound squared ($c_s^2$) remains largely unaffected\nby spin polarization, the specific shear viscosity ($\\eta/s$), specific bulk\nviscosity ($\\zeta/s$), and mean free path ($\\lambda$) are significantly\nmodified.\n  Notably, when spin polarization is taken into account, both $c_s^2 $ and\n$\\zeta/s$ exhibit a non-monotonic dependence on collision energy, with an\ninflection point around $\\sqrt{s_{NN}} = 27 $~GeV, corresponding to an average\nparton chemical potential of $\\langle\\mu_p\\rangle = 0.021 $~GeV. This\nnon-monotonic behavior suggests that incorporating spin polarization into\ntheoretical calculations could provide an effective probe for locating the\ncritical point of the QCD phase transition.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-23T10:08:31Z"}
{"aid":"http://arxiv.org/abs/2504.16647v1","title":"Medium-induced coherent gluon radiation for $2\\to 2$ processes with\n  general kinematics","summary":"High-energy proton-nucleus (pA) collisions have provided various clues for\nthe role of cold nuclear matter effects in hadron production. In particular,\nmultiple rescatterings of an incoming parton by the nuclear target are known to\ninduce the radiation of many soft gluons, with those having a long formation\ntime leading to the modification of hadron production rates due to fully\ncoherent energy loss (FCEL). Here we present a recently derived formula for the\ninduced single soft gluon radiation spectrum beyond leading logarithmic\naccuracy, whose main features are demonstrated with the example of $q\\, g \\to\nq\\, g$ scattering.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-23T12:07:39Z"}
{"aid":"http://arxiv.org/abs/2504.16725v1","title":"Quantum sensing with spin defects in boron nitride nanotubes","summary":"Spin defects in semiconductors are widely investigated for various\napplications in quantum sensing. Conventional host materials such as diamond\nand hexagonal boron nitride (hBN) provide bulk or low-dimensional platforms for\noptically addressable spin systems, but often lack the structural properties\nneeded for chemical sensing. Here, we introduce a new class of quantum sensors\nbased on naturally occurring spin defects in boron nitride nanotubes (BNNTs),\nwhich combine high surface area with omnidirectional spin control, key features\nfor enhanced sensing performance. First, we present strong evidence that these\ndefects are carbon-related, akin to recently identified centers in hBN, and\ndemonstrate coherent spin control over ensembles embedded within dense,\nmicroscale BNNTs networks. Using dynamical decoupling, we enhance spin\ncoherence times by a factor exceeding 300x and implement high-resolution\ndetection of radiofrequency signals. By integrating the BNNT mesh sensor into a\nmicrofluidic platform we demonstrate chemical sensing of paramagnetic ions in\nsolution, with detectable concentrations reaching levels nearly 1000 times\nlower than previously demonstrated using comparable hBN-based systems. This\nhighly porous and flexible architecture positions BNNTs as a powerful new host\nmaterial for quantum sensing.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall,cond-mat.mtrl-sci,physics.app-ph,physics.chem-ph","published":"2025-04-23T13:55:20Z"}
{"aid":"http://arxiv.org/abs/2504.16728v1","title":"IRIS: Interactive Research Ideation System for Accelerating Scientific\n  Discovery","summary":"The rapid advancement in capabilities of large language models (LLMs) raises\na pivotal question: How can LLMs accelerate scientific discovery? This work\ntackles the crucial first stage of research, generating novel hypotheses. While\nrecent work on automated hypothesis generation focuses on multi-agent\nframeworks and extending test-time compute, none of the approaches effectively\nincorporate transparency and steerability through a synergistic\nHuman-in-the-loop (HITL) approach. To address this gap, we introduce IRIS:\nInteractive Research Ideation System, an open-source platform designed for\nresearchers to leverage LLM-assisted scientific ideation. IRIS incorporates\ninnovative features to enhance ideation, including adaptive test-time compute\nexpansion via Monte Carlo Tree Search (MCTS), fine-grained feedback mechanism,\nand query-based literature synthesis. Designed to empower researchers with\ngreater control and insight throughout the ideation process. We additionally\nconduct a user study with researchers across diverse disciplines, validating\nthe effectiveness of our system in enhancing ideation. We open-source our code\nat https://github.com/Anikethh/IRIS-Interactive-Research-Ideation-System","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-23T14:01:36Z"}
{"aid":"http://arxiv.org/abs/2504.16733v1","title":"Identification of quasars variable over long time scales from infrared\n  surveys. Ensemble variability and structure function properties","summary":"Quasars are variable and their variability can both constrain their physical\nproperties and help to identify them. We look for ways to efficiently identify\nquasars exhibiting consistent variability over multi-year time-scales, based on\na small number of epochs. Using infrared (IR) is desirable to avoid bias\nagainst reddened objects. We compare the apparent brightness of known quasars\nthat have been observed with two IR surveys, covering up to a twenty-year\nbaseline: the Two Micron All Sky Survey (2MASS; 1997-2001) and the VISTA\nHemisphere Survey (VHS; 2009-2017). We look at the previous studies of the\nselected variable quasars to see if their variable behaviour is known and when\navailable we use multi-epoch monitoring with the Zwicky Transient Facility\n(ZTF) to obtain a measure of optical variability of individual objects. We\nbuild a sample of ~2500 quasars that show statistically significant variability\nbetween the 2MASS and VHS. About 1500 of these come from the new Quaia sample\nbased on Gaia spectra and about 1/3 of these have hardly been studied. The\nQuaia sample constitutes the main product of this work. Based on ensemble\nvariability and structure function analysis we demonstrate that the selected\nobjects in our sample are representative of the typical quasar population and\nshow behaviour, consistent with other quasar samples. Our analysis strengthens\nprevious results, for example that variability decreases with the rest-frame\nwavelength and that it exhibits peaks for certain absolute magnitudes of the\nquasars. Similarly, the structure function shows an increase in variability for\nrest-frame time lags below ~1500 d and a decrease for longer lags, just like in\nprevious studies. Our selection, even though it is based on two epochs only,\nseems to be surprisingly robust, showing up to ~11% contamination by quasars\nthat show stable non-variable behaviour in ZTF.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-23T14:04:47Z"}
{"aid":"http://arxiv.org/abs/2504.16764v1","title":"A Note on the Stability of the Dark Energy Model from Time Crystals","summary":"In this note, we investigate the stability of the dark energy model from time\ncrystals proposed in [1]. We emphasize two ingredients, the coupling of the\nscalar field to gravity, and the fact that these time crystals are on an\nexpanding FRW background, which play a crucial role in the field's dynamics.\nThe Hubble parameter, which contributes a drag term to the equations of motion,\ngrows with time until the scale factor diverges. When taken into account, these\nfactors also alleviate the stability concern of [2].","main_category":"gr-qc","categories":"gr-qc,hep-ph,hep-th","published":"2025-04-23T14:34:30Z"}
{"aid":"http://arxiv.org/abs/2504.16767v1","title":"Online model learning with data-assimilated reservoir computers","summary":"We propose an online learning framework for forecasting nonlinear\nspatio-temporal signals (fields). The method integrates (i) dimensionality\nreduction, here, a simple proper orthogonal decomposition (POD) projection;\n(ii) a generalized autoregressive model to forecast reduced dynamics, here, a\nreservoir computer; (iii) online adaptation to update the reservoir computer\n(the model), here, ensemble sequential data assimilation.We demonstrate the\nframework on a wake past a cylinder governed by the Navier-Stokes equations,\nexploring the assimilation of full flow fields (projected onto POD modes) and\nsparse sensors. Three scenarios are examined: a na\\\"ive physical state\nestimation; a two-fold estimation of physical and reservoir states; and a\nthree-fold estimation that also adjusts the model parameters. The two-fold\nstrategy significantly improves ensemble convergence and reduces reconstruction\nerror compared to the na\\\"ive approach. The three-fold approach enables robust\nonline training of partially-trained reservoir computers, overcoming\nlimitations of a priori training. By unifying data-driven reduced order\nmodelling with Bayesian data assimilation, this work opens new opportunities\nfor scalable online model learning for nonlinear time series forecasting.","main_category":"cs.LG","categories":"cs.LG,physics.flu-dyn,stat.AP","published":"2025-04-23T14:35:54Z"}
{"aid":"http://arxiv.org/abs/2504.16769v1","title":"Deep photonic reservoir computer for nonlinear equalization of 16-level\n  quadrature amplitude modulation signals","summary":"Photonic reservoir computer (PRC) is a kind of real-time and adaptive\nrecurrent neural network, where only weights in the readout layer require\ntraining. PRC is a promising tool to deal with the crucial issue of nonlinear\nequalization in optical fiber communications. Here we theoretically show a deep\nPRC for the nonlinear equalization of coherent signals with the format of 16-\nlevel quadrature amplitude modulation (16-QAM). The deep PRC consists of\ncascading injection-locked Fabry-Perot lasers with optical feedback. Both the\nin-phase component and the quadrature component of the 16-QAM signals are\nsimultaneously injected into the deep PRC in parallel, based on the wavelength\nmultiplexing of Fabry-Perot lasers. It is demonstrated that the deep PRC\nexhibits strong capability for the nonlinearity compensation of coherent\nsignals. The Q factor is improved by more than 1 dB for 16-QAM signals with\nlaunch powers above 10 dBm, associated with a bit rate of 240 Gbps and a\ntransmission distance of 50 km.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-23T14:41:20Z"}
{"aid":"http://arxiv.org/abs/2504.16777v1","title":"Systemic Flakiness: An Empirical Analysis of Co-Occurring Flaky Test\n  Failures","summary":"Flaky tests produce inconsistent outcomes without code changes, creating\nmajor challenges for software developers. An industrial case study reported\nthat developers spend 1.28% of their time repairing flaky tests at a monthly\ncost of $2,250. We discovered that flaky tests often exist in clusters, with\nco-occurring failures that share the same root causes, which we call systemic\nflakiness. This suggests that developers can reduce repair costs by addressing\nshared root causes, enabling them to fix multiple flaky tests at once rather\nthan tackling them individually. This study represents an inflection point by\nchallenging the deep-seated assumption that flaky test failures are isolated\noccurrences. We used an established dataset of 10,000 test suite runs from 24\nJava projects on GitHub, spanning domains from data orchestration to job\nscheduling. It contains 810 flaky tests, which we levered to perform a\nmixed-method empirical analysis of co-occurring flaky test failures. Systemic\nflakiness is significant and widespread. We performed agglomerative clustering\nof flaky tests based on their failure co-occurrence, finding that 75% of flaky\ntests across all projects belong to a cluster, with a mean cluster size of 13.5\nflaky tests. Instead of requiring 10,000 test suite runs to identify systemic\nflakiness, we demonstrated a lightweight alternative by training machine\nlearning models based on static test case distance measures. Through manual\ninspection of stack traces, conducted independently by four authors and\nresolved through negotiated agreement, we identified intermittent networking\nissues and instabilities in external dependencies as the predominant causes of\nsystemic flakiness.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-23T14:51:23Z"}
{"aid":"http://arxiv.org/abs/2504.16789v1","title":"MLOps Monitoring at Scale for Digital Platforms","summary":"Machine learning models are widely recognized for their strong performance in\nforecasting. To keep that performance in streaming data settings, they have to\nbe monitored and frequently re-trained. This can be done with machine learning\noperations (MLOps) techniques under supervision of an MLOps engineer. However,\nin digital platform settings where the number of data streams is typically\nlarge and unstable, standard monitoring becomes either suboptimal or too labor\nintensive for the MLOps engineer. As a consequence, companies often fall back\non very simple worse performing ML models without monitoring. We solve this\nproblem by adopting a design science approach and introducing a new monitoring\nframework, the Machine Learning Monitoring Agent (MLMA), that is designed to\nwork at scale for any ML model with reasonable labor cost. A key feature of our\nframework concerns test-based automated re-training based on a data-adaptive\nreference loss batch. The MLOps engineer is kept in the loop via key metrics\nand also acts, pro-actively or retrospectively, to maintain performance of the\nML model in the production stage. We conduct a large-scale test at a last-mile\ndelivery platform to empirically validate our monitoring framework.","main_category":"econ.EM","categories":"econ.EM,stat.AP","published":"2025-04-23T15:04:38Z"}
{"aid":"http://arxiv.org/abs/2504.16806v1","title":"V4141 Sgr: Outflows and repeated outbursts","summary":"In this work, we analyze the ongoing brightening of the poorly studied\nsymbiotic star V4141 Sgr and examine its long-term variability. We present new\nlow-resolution spectroscopic observations of the system in its bright state and\ncombine them with multi-color photometric data from our observations, ASAS-SN,\nATLAS, and Gaia DR3. To investigate its long-term evolution, we also\nincorporate historical data, including photographic plates, constructing a\nlight curve spanning more than a century. Our analysis reveals that V4141 Sgr\nhas undergone multiple outbursts, with at least one exhibiting characteristics\ntypical of \"slow\" symbiotic novae. The current outburst is characterized by the\nejection of optically thick material and possibly bipolar jets, a phenomenon\nobserved in only a small fraction of symbiotic stars. These findings establish\nV4141 Sgr as an intriguing target for continued monitoring.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-23T15:25:14Z"}
{"aid":"http://arxiv.org/abs/2504.16825v1","title":"Symbiotic stars in the era of modern ground- and space-based surveys","summary":"Symbiotic stars, interacting binaries composed of a cool giant and a hot\ncompact companion, exhibit complex variability across the electromagnetic\nspectrum. Over the past decades, large-scale photometric and spectroscopic\nsurveys from ground- and space-based observatories have significantly advanced\ntheir discovery and characterization. These datasets have transformed the\nsearch for new symbiotic candidates, providing extensive time-domain\ninformation crucial for their classification and analysis. This review\nhighlights recent observational results that have expanded the known population\nof symbiotic stars, refined classification criteria, and enhanced our\nunderstanding of their variability. Despite these advances, fundamental\nquestions remain regarding their long-term evolution, mass transfer and\naccretion processes, or their potential role as progenitors of Type Ia\nsupernovae. With ongoing and upcoming surveys, the coming years promise new\ndiscoveries and a more comprehensive picture of these intriguing interacting\nsystems.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-23T15:42:19Z"}
{"aid":"http://arxiv.org/abs/2504.16865v1","title":"General method for solving nonlinear optical scattering problems using\n  fix point iterations","summary":"In this paper we introduce a new fix point iteration scheme for solving\nnonlinear electromagnetic scattering problems. The method is based on a\nspectral formulation of Maxwell's equations called the Bidirectional Pulse\nPropagation Equations. The scheme can be applied to a wide array of slab-like\ngeometries, and for arbitrary material responses. We derive the scheme and\ninvestigated how it performs with respect to convergence and accuracy by\napplying it to the case of light scattering from a simple slab whose nonlinear\nmaterial response is a sum a very fast electronic vibrational response, and a\nmuch slower molecular vibrational response.","main_category":"physics.class-ph","categories":"physics.class-ph,physics.comp-ph","published":"2025-04-23T16:38:49Z"}
{"aid":"http://arxiv.org/abs/2504.16873v1","title":"A LOFAR-style reconstruction of cosmic-ray air showers with SKA-Low","summary":"Cosmic-ray air shower detection with the low-frequency part of the Square\nKilometre Array (SKA) radio telescope is envisioned to yield very high\nprecision measurements of the particle composition of cosmic rays between\n$10^{16}$ and $10^{18}$ eV. This is made possible by the extreme antenna\ndensity of the core of SKA-Low, surpassing the current most dense radio air\nshower observatory LOFAR by over an order of magnitude. In order to make these\nmeasurements, the technical implementation of this observation mode and the\ndevelopment of reconstruction methods have to happen hand-in-hand. As a first\nlower limit of what is obtainable, we apply the current most precise\nreconstruction methods as used at LOFAR to a first complete simulation of air\nshower signals for the SKA-Low array. We describe this simulation setup and\ndiscuss the obtainable accuracy and resolution. A special focus is put on\neffects of the dynamic range of the system, beamforming methods to lower the\nenergy threshold, as well as the limits to the mass composition accuracy given\nby statistical and systematic uncertainties.","main_category":"astro-ph.HE","categories":"astro-ph.HE,hep-ex","published":"2025-04-23T16:47:18Z"}
{"aid":"http://arxiv.org/abs/2504.16882v1","title":"Fractional $Q$-curvature on the sphere and optimal partitions","summary":"We study an optimal partition problem on the sphere, where the cost\nfunctional is associated with the fractional $Q$-curvature in terms of the\nconformal fractional Laplacian on the sphere. By leveraging symmetries, we\nprove the existence of a symmetric minimal partition through a variational\napproach. A key ingredient in our analysis is a new H\\\"older regularity result\nfor symmetric functions in a fractional Sobolev space on the sphere. As a\nbyproduct, we establish the existence of infinitely many solutions to a\nnonlocal weakly-coupled competitive system on the sphere that remain invariant\nunder a group of conformal diffeomorphisms and we investigate the asymptotic\nbehavior of least-energy solutions as the coupling parameters approach negative\ninfinity.","main_category":"math.AP","categories":"math.AP,math.DG","published":"2025-04-23T16:58:35Z"}
{"aid":"http://arxiv.org/abs/2504.16883v1","title":"Enhancing Critical Thinking with AI: A Tailored Warning System for RAG\n  Models","summary":"Retrieval-Augmented Generation (RAG) systems offer a powerful approach to\nenhancing large language model (LLM) outputs by incorporating fact-checked,\ncontextually relevant information. However, fairness and reliability concerns\npersist, as hallucinations can emerge at both the retrieval and generation\nstages, affecting users' reasoning and decision-making. Our research explores\nhow tailored warning messages -- whose content depends on the specific context\nof hallucination -- shape user reasoning and actions in an educational quiz\nsetting. Preliminary findings suggest that while warnings improve accuracy and\nawareness of high-level hallucinations, they may also introduce cognitive\nfriction, leading to confusion and diminished trust in the system. By examining\nthese interactions, this work contributes to the broader goal of AI-augmented\nreasoning: developing systems that actively support human reflection, critical\nthinking, and informed decision-making rather than passive information\nconsumption.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-23T17:00:25Z"}
{"aid":"http://arxiv.org/abs/2504.16895v1","title":"Exact analytic solutions in 2+1 Hoava gravity with cosmological\n  constant","summary":"We investigate the static solutions with rotational symmetry in the\nnonprojectable Ho\\v{r}ava theory in 2+1 dimensions. We consider all\ninequivalent terms of the effective theory, including the cosmological\nconstant. We find two distinct types of solutions: the first one corresponds to\na Lifshitz solution, while the second one is obtained through a coordinate\ntransformation of the equations of motion. This exact solution does not exhibit\nLifshitz behavior and features a naked singularity.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-23T17:24:53Z"}
{"aid":"http://arxiv.org/abs/2504.16918v1","title":"OptimAI: Optimization from Natural Language Using LLM-Powered AI Agents","summary":"Optimization plays a vital role in scientific research and practical\napplications, but formulating a concrete optimization problem described in\nnatural language into a mathematical form and selecting a suitable solver to\nsolve the problem requires substantial domain expertise. We introduce\n\\textbf{OptimAI}, a framework for solving \\underline{Optim}ization problems\ndescribed in natural language by leveraging LLM-powered \\underline{AI} agents,\nachieving superior performance over current state-of-the-art methods. Our\nframework is built upon four key roles: (1) a \\emph{formulator} that translates\nnatural language problem descriptions into precise mathematical formulations;\n(2) a \\emph{planner} that constructs a high-level solution strategy prior to\nexecution; and (3) a \\emph{coder} and a \\emph{code critic} capable of\ninteracting with the environment and reflecting on outcomes to refine future\nactions. Ablation studies confirm that all roles are essential; removing the\nplanner or code critic results in $5.8\\times$ and $3.1\\times$ drops in\nproductivity, respectively. Furthermore, we introduce UCB-based debug\nscheduling to dynamically switch between alternative plans, yielding an\nadditional $3.3\\times$ productivity gain. Our design emphasizes multi-agent\ncollaboration, allowing us to conveniently explore the synergistic effect of\ncombining diverse models within a unified system. Our approach attains 88.1\\%\naccuracy on the NLP4LP dataset and 71.2\\% on the Optibench (non-linear w/o\ntable) subset, reducing error rates by 58\\% and 50\\% respectively over prior\nbest results.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-23T17:45:05Z"}
{"aid":"http://arxiv.org/abs/2504.17254v1","title":"Efficient simulation of discrete galaxy populations and associated\n  radiation fields during the first billion years","summary":"Understanding the epochs of cosmic dawn and reionisation requires us to\nleverage multi-wavelength and multi-tracer observations, with each dataset\nproviding a complimentary piece of the puzzle. To interpret such data, we\nupdate the public simulation code, 21cmFASTv4, to include a discrete source\nmodel based on stochastic sampling of conditional mass functions and\nsemi-empirical galaxy relations. We demonstrate that our new galaxy model,\nwhich parametrizes the means and scatters of well-established scaling\nrelations, is flexible enough to characterize very different predictions from\nhydrodynamic cosmological simulations of high-redshift galaxies. Combining a\ndiscrete galaxy population with approximate, efficient radiative transfer\nallows us to self-consistently forward-model galaxy surveys, line intensity\nmaps (LIMs), and observations of the intergalactic medium (IGM). Not only does\neach observable probe different scales and physical processes, but\ncross-correlation will maximise the information gained from each measurement by\nprobing the galaxy-IGM connection at high-redshift. We find that a stochastic\nsource field produces significant shot-noise in 21cm and LIM power spectra.\nScatter in galaxy properties can be constrained using UV luminosity functions\nand/or 21cm power spectra, especially if astrophysical scatter is higher than\nexpected (as might be needed to explain recent JWST observations). Our\nmodelling pipeline is both flexible and computationally efficient, facilitating\nhigh-dimensional, multi-tracer, field-level Bayesian inference of cosmology and\nastrophysics during the first billion years.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-24T05:18:08Z"}
{"aid":"http://arxiv.org/abs/2504.17263v1","title":"Precision Neural Network Quantization via Learnable Adaptive Modules","summary":"Quantization Aware Training (QAT) is a neural network quantization technique\nthat compresses model size and improves operational efficiency while\neffectively maintaining model performance. The paradigm of QAT is to introduce\nfake quantization operators during the training process, allowing the model to\nautonomously compensate for information loss caused by quantization. Making\nquantization parameters trainable can significantly improve the performance of\nQAT, but at the cost of compromising the flexibility during inference,\nespecially when dealing with activation values with substantially different\ndistributions. In this paper, we propose an effective learnable adaptive neural\nnetwork quantization method, called Adaptive Step Size Quantization (ASQ), to\nresolve this conflict. Specifically, the proposed ASQ method first dynamically\nadjusts quantization scaling factors through a trained module capable of\naccommodating different activations. Then, to address the rigid resolution\nissue inherent in Power of Two (POT) quantization, we propose an efficient\nnon-uniform quantization scheme. We utilize the Power Of Square root of Two\n(POST) as the basis for exponential quantization, effectively handling the\nbell-shaped distribution of neural network weights across various bit-widths\nwhile maintaining computational efficiency through a Look-Up Table method\n(LUT). Extensive experimental results demonstrate that the proposed ASQ method\nis superior to the state-of-the-art QAT approaches. Notably that the ASQ is\neven competitive compared to full precision baselines, with its 4-bit quantized\nResNet34 model improving accuracy by 1.2\\% on ImageNet.","main_category":"cs.CV","categories":"cs.CV,cs.CC","published":"2025-04-24T05:46:25Z"}
{"aid":"http://arxiv.org/abs/2504.17326v1","title":"Quantum Corner VOA and the Super Macdonald Polynomials","summary":"In this paper, we establish a relation between the quantum corner VOA\n$q\\widetilde{Y}_{L,0,N}[\\Psi]$, which can be regarded as a generalization of\nquantum $W_N$ algebra, and Sergeev-Veselov super Macdonald polynomials. We\ndemonstrate precisely that, under a specific map, the correlation functions of\nthe currents of $q\\widetilde{Y}_{L,0,N}[\\Psi]$, coincide with the\nSergeev-Veselov super Macdonald polynomials.","main_category":"hep-th","categories":"hep-th,math-ph,math.CO,math.MP,math.QA,math.RT","published":"2025-04-24T07:37:03Z"}
{"aid":"http://arxiv.org/abs/2504.17348v1","title":"On the length of generating sets with conditions on minimal polynomial","summary":"Linear upper bounds may be derived by imposing specific structural conditions\non a generating set, such as additional constraints on ranks, eigenvalues, or\nthe degree of the minimal polynomial of the generating matrices. This paper\nestablishes a linear upper bound of \\(3n-5\\) for generating sets that contain a\nmatrix whose minimal polynomial has a degree exceeding \\(\\frac{n}{2}\\), where\n\\(n\\) denotes the order of the matrix. Compared to the bound provided in\n\\cite[Theorem 3.1]{r2}, this result reduces the constraints on the Jordan\ncanonical forms. Additionally, it is demonstrated that the bound\n\\(\\frac{7n}{2}-4\\) holds when the generating set contains a matrix with a\nminimal polynomial of degree \\(t\\) satisfying \\(2t\\le n\\le 3t-1\\). The primary\nenhancements consist of quantitative bounds and reduced reliance on Jordan form\nstructural constraints.","main_category":"math.RA","categories":"math.RA","published":"2025-04-24T08:09:32Z"}
{"aid":"http://arxiv.org/abs/2504.17355v1","title":"Collaborative Multi-Agent Reinforcement Learning for Automated Feature\n  Transformation with Graph-Driven Path Optimization","summary":"Feature transformation methods aim to find an optimal mathematical\nfeature-feature crossing process that generates high-value features and\nimproves the performance of downstream machine learning tasks. Existing\nframeworks, though designed to mitigate manual costs, often treat feature\ntransformations as isolated operations, ignoring dynamic dependencies between\ntransformation steps. To address the limitations, we propose TCTO, a\ncollaborative multi-agent reinforcement learning framework that automates\nfeature engineering through graph-driven path optimization. The framework's\ncore innovation lies in an evolving interaction graph that models features as\nnodes and transformations as edges. Through graph pruning and backtracking, it\ndynamically eliminates low-impact edges, reduces redundant operations, and\nenhances exploration stability. This graph also provides full traceability to\nempower TCTO to reuse high-utility subgraphs from historical transformations.\nTo demonstrate the efficacy and adaptability of our approach, we conduct\ncomprehensive experiments and case studies, which show superior performance\nacross a range of datasets.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-24T08:16:13Z"}
{"aid":"http://arxiv.org/abs/2504.17364v1","title":"I-INR: Iterative Implicit Neural Representations","summary":"Implicit Neural Representations (INRs) have revolutionized signal processing\nand computer vision by modeling signals as continuous, differentiable functions\nparameterized by neural networks. However, their inherent formulation as a\nregression problem makes them prone to regression to the mean, limiting their\nability to capture fine details, retain high-frequency information, and handle\nnoise effectively. To address these challenges, we propose Iterative Implicit\nNeural Representations (I-INRs) a novel plug-and-play framework that enhances\nsignal reconstruction through an iterative refinement process. I-INRs\neffectively recover high-frequency details, improve robustness to noise, and\nachieve superior reconstruction quality. Our framework seamlessly integrates\nwith existing INR architectures, delivering substantial performance gains\nacross various tasks. Extensive experiments show that I-INRs outperform\nbaseline methods, including WIRE, SIREN, and Gauss, in diverse computer vision\napplications such as image restoration, image denoising, and object occupancy\nprediction.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T08:27:22Z"}
{"aid":"http://arxiv.org/abs/2504.17369v1","title":"Complexity one varieties are cluster type","summary":"The complexity of a pair $(X,B)$ is an invariant that relates the dimension\nof $X$, the rank of the group of divisors, and the coefficients of $B$. If the\ncomplexity is less than one, then $X$ is a toric variety. We prove that if the\ncomplexity is less than two, then $X$ is a Fano type variety. Furthermore, if\nthe complexity is less than 3/2, then $X$ admits a Calabi--Yau structure\n$(X,B)$ of complexity one and index at most two, and it admits a finite cover\n$Y \\to X$ of degree at most 2, where $Y$ is a cluster type variety. In\nparticular, if the complexity is one and the index is one, $(X,B)$ is cluster\ntype. Finally, we establish a connection with the theory of\n$\\mathbb{T}$-varieties. We prove that a variety of $\\mathbb{T}$-complexity one\nadmits a similar finite cover from a cluster type variety.","main_category":"math.AG","categories":"math.AG","published":"2025-04-24T08:40:45Z"}
{"aid":"http://arxiv.org/abs/2504.17377v1","title":"Minimal Surfaces via Complex Quaternions","summary":"Minimal surfaces play a fundamental role in differential geometry, with\napplications spanning physics, material science, and geometric design. In this\npaper, we explore a novel quaternionic representation of minimal surfaces,\ndrawing an analogy with the well-established theory of Pythagorean Hodograph\n(PH) curves. By exploiting the algebraic structure of complex quaternions, we\nintroduce a new approach to generating minimal surfaces via quaternionic\ntransformations. This method extends classical Weierstra\\ss-Enneper\nrepresentations and provides insights into the interplay between quaternionic\nanalysis, PH curves, and minimal surface geometry. Additionally, we discuss the\nrole of the Sylvester equation in this framework and demonstrate practical\nexamples, including the construction of Enneper surface patches. The findings\nopen new avenues in computational geometry and geometric modeling, bridging\nabstract algebraic structures with practical applications in CAD and computer\ngraphics.","main_category":"math.CV","categories":"math.CV,math.RA","published":"2025-04-24T08:51:05Z"}
{"aid":"http://arxiv.org/abs/2504.17387v1","title":"Graph covers and semi-covers: Who is stronger?","summary":"The notion of graph cover, also known as locally bijective homomorphism, is a\ndiscretization of covering spaces known from general topology. It is a pair of\nincidence-preserving vertex- and edge-mappings between two graphs, the\nedge-component being bijective on the edge-neighborhoods of every vertex and\nits image. In line with the current trends in topological graph theory and its\napplications in mathematical physics, graphs are considered in the most relaxed\nform and as such they may contain multiple edges, loops and semi-edges.\n  Nevertheless, simple graphs (binary structures without multiple edges, loops,\nor semi-edges) play an important role. It has been conjectured in [Bok et al.:\nList covering of regular multigraphs, Proceedings IWOCA 2022, LNCS 13270, pp.\n228--242] that for every fixed graph $H$, deciding if a graph covers $H$ is\neither polynomial time solvable for arbitrary input graphs, or NP-complete for\nsimple ones. A graph $A$ is called stronger than a graph $B$ if every simple\ngraph that covers $A$ also covers $B$. This notion was defined and found useful\nfor NP-hardness reductions for disconnected graphs in [Bok et al.:\nComputational complexity of covering disconnected multigraphs, Proceedings FCT\n2022, LNCS 12867, pp. 85--99]. It was conjectured in [Kratochv\\'{\\i}l: Towards\nstrong dichotomy of graphs covers, GROW 2022 - Book of open problems, p. 10,\n{\\tt https://grow.famnit.upr.si/GROW-BOP.pdf}] that if $A$ has no semi-edges,\nthen $A$ is stronger than $B$ if and only if $A$ covers $B$. We prove this\nconjecture for cubic one-vertex graphs, and we also justify it for all cubic\ngraphs $A$ with at most 4 vertices.","main_category":"math.CO","categories":"math.CO,G.2.2","published":"2025-04-24T09:13:18Z"}
{"aid":"http://arxiv.org/abs/2504.17411v1","title":"The KP equation of plane elastodynamics","summary":"The propagation of nonlinear and dispersive waves in various materials can be\ndescribed by the well-known Kadomtsev-Petviashvili (KP) equation, which is a\n(2+1)-dimensional partial differential equation. In this paper, we show that\nthe KP equation can be used to describe the in-plane motion of compressible\nelastic solids with dispersion. Furthermore, a modified KP equation with cubic\nnonlinearity is obtained in the case of incompressible solids with dispersion.\nThen, several solutions of these partial differential equations are discussed\nand computed using a Fourier spectral method. In particular, both equations\nadmit solitary wave solutions.","main_category":"math-ph","categories":"math-ph,math.MP,nlin.PS","published":"2025-04-24T10:03:50Z"}
{"aid":"http://arxiv.org/abs/2504.17420v1","title":"HydroStartML: A combined machine learning and physics-based approach to\n  reduce hydrological model spin-up time","summary":"Finding the initial depth-to-water table (DTWT) configuration of a catchment\nis a critical challenge when simulating the hydrological cycle with integrated\nmodels, significantly impacting simulation outcomes. Traditionally, this\ninvolves iterative spin-up computations, where the model runs under constant\natmospheric settings until steady-state is achieved. These so-called model\nspin-ups are computationally expensive, often requiring many years of simulated\ntime, particularly when the initial DTWT configuration is far from steady\nstate.\n  To accelerate the model spin-up process we developed HydroStartML, a machine\nlearning emulator trained on steady-state DTWT configurations across the\ncontiguous United States. HydroStartML predicts, based on available data like\nconductivity and surface slopes, a DTWT configuration of the respective\nwatershed, which can be used as an initial DTWT.\n  Our results show that initializing spin-up computations with HydroStartML\npredictions leads to faster convergence than with other initial configurations\nlike spatially constant DTWTs. The emulator accurately predicts configurations\nclose to steady state, even for terrain configurations not seen in training,\nand allows especially significant reductions in computational spin-up effort in\nregions with deep DTWTs. This work opens the door for hybrid approaches that\nblend machine learning and traditional simulation, enhancing predictive\naccuracy and efficiency in hydrology for improving water resource management\nand understanding complex environmental interactions.","main_category":"physics.geo-ph","categories":"physics.geo-ph,cs.LG","published":"2025-04-24T10:24:34Z"}
{"aid":"http://arxiv.org/abs/2504.17440v1","title":"Generating Localized Audible Zones Using a Single-Channel Parametric\n  Loudspeaker","summary":"Advanced sound zone control (SZC) techniques typically rely on massive\nmulti-channel loudspeaker arrays to create high-contrast personal sound zones,\nmaking single-loudspeaker SZC seem impossible. In this Letter, we challenge\nthis paradigm by introducing the multi-carrier parametric loudspeaker (MCPL),\nwhich enables SZC using only a single loudspeaker. In our approach, distinct\naudio signals are modulated onto separate ultrasonic carrier waves at different\nfrequencies and combined into a single composite signal. This signal is emitted\nby a single-channel ultrasonic transducer, and through nonlinear demodulation\nin air, the audio signals interact to virtually form multi-channel outputs.\nThis novel capability allows the application of existing SZC algorithms\noriginally designed for multi-channel loudspeaker arrays. Simulations validate\nthe effectiveness of our proposed single-channel MCPL, demonstrating its\npotential as a promising alternative to traditional multi-loudspeaker systems\nfor achieving high-contrast SZC. Our work opens new avenues for simplifying SZC\nsystems without compromising performance.","main_category":"eess.AS","categories":"eess.AS","published":"2025-04-24T11:02:07Z"}
{"aid":"http://arxiv.org/abs/2504.17452v1","title":"The need for statistical physics in Africa: perspective and an\n  illustration in drug delivery problems","summary":"The development of statistical physics in Africa is in its nascent stages,\nyet its application holds immense promise for advancing emerging research\ntrends on the continent. This perspective paper, a product of a two-week\nworkshop on biophysics in Morogoro (Tanzania), aims to illuminate the potential\nof statistical physics in regional scientific research. We employ in-silico\natomistic molecular dynamics simulations to investigate the loading and\ndelivery capabilities of lecithin nanolipids for niclosamide, a poorly\nwater-soluble drug. Our simulations reveal that the loading capacity and\ninteraction strength between lecithin nanolipids and niclosamide improve with\nincreased lecithin concentrations. We perform a free-energy landscape analysis\nwhich uncovers two distinct metastable conformations of niclosamide within both\nthe aqueous phase and the lecithin nanolipids. Over a simulation period of half\na microsecond, lecithin nanolipids self-assemble into a spherical monolayer\nstructure, providing detailed atomic-level insights into their interactions\nwith niclosamide. These findings underscore the potential of lecithin\nnanolipids as efficient drug delivery systems.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,physics.bio-ph,physics.chem-ph,physics.soc-ph","published":"2025-04-24T11:34:58Z"}
{"aid":"http://arxiv.org/abs/2504.17454v1","title":"Adaptive Orchestration of Modular Generative Information Access Systems","summary":"Advancements in large language models (LLMs) have driven the emergence of\ncomplex new systems to provide access to information, that we will collectively\nrefer to as modular generative information access (GenIA) systems. They\nintegrate a broad and evolving range of specialized components, including LLMs,\nretrieval models, and a heterogeneous set of sources and tools. While\nmodularity offers flexibility, it also raises critical challenges: How can we\nsystematically characterize the space of possible modules and their\ninteractions? How can we automate and optimize interactions among these\nheterogeneous components? And, how do we enable this modular system to\ndynamically adapt to varying user query requirements and evolving module\ncapabilities? In this perspective paper, we argue that the architecture of\nfuture modular generative information access systems will not just assemble\npowerful components, but enable a self-organizing system through real-time\nadaptive orchestration -- where components' interactions are dynamically\nconfigured for each user input, maximizing information relevance while\nminimizing computational overhead. We give provisional answers to the questions\nraised above with a roadmap that depicts the key principles and methods for\ndesigning such an adaptive modular system. We identify pressing challenges, and\npropose avenues for addressing them in the years ahead. This perspective urges\nthe IR community to rethink modular system designs for developing adaptive,\nself-optimizing, and future-ready architectures that evolve alongside their\nrapidly advancing underlying technologies.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-24T11:35:43Z"}
{"aid":"http://arxiv.org/abs/2504.17520v1","title":"Communication-Efficient Personalized Distributed Learning with Data and\n  Node Heterogeneity","summary":"To jointly tackle the challenges of data and node heterogeneity in\ndecentralized learning, we propose a distributed strong lottery ticket\nhypothesis (DSLTH), based on which a communication-efficient personalized\nlearning algorithm is developed. In the proposed method, each local model is\nrepresented as the Hadamard product of global real-valued parameters and a\npersonalized binary mask for pruning. The local model is learned by updating\nand fusing the personalized binary masks while the real-valued parameters are\nfixed among different agents. To further reduce the complexity of hardware\nimplementation, we incorporate a group sparse regularization term in the loss\nfunction, enabling the learned local model to achieve structured sparsity.\nThen, a binary mask aggregation algorithm is designed by introducing an\nintermediate aggregation tensor and adding a personalized fine-tuning step in\neach iteration, which constrains model updates towards the local data\ndistribution. The proposed method effectively leverages the relativity among\nagents while meeting personalized requirements in heterogeneous node\nconditions. We also provide a theoretical proof for the DSLTH, establishing it\nas the foundation of the proposed method. Numerical simulations confirm the\nvalidity of the DSLTH and demonstrate the effectiveness of the proposed\nalgorithm.","main_category":"cs.LG","categories":"cs.LG,cs.DC,cs.MA","published":"2025-04-24T13:02:54Z"}
{"aid":"http://arxiv.org/abs/2504.17530v1","title":"Hollow polytopes with many vertices","summary":"Given a set $S \\subseteq \\mathbb{R}^d$, a hollow polytope has vertices in $S$\nbut contains no other point of $S$ in its interior. We prove upper and lower\nbounds on the maximum number of vertices of hollow polytopes whose facets are\nsimplices or whose vertices are in general position. We also obtain relatively\ntight asymptotic bounds for polytopes which do not contain lattice segments of\nlarge length.","main_category":"math.MG","categories":"math.MG","published":"2025-04-24T13:18:49Z"}
{"aid":"http://arxiv.org/abs/2504.17534v1","title":"Learning Isometric Embeddings of Road Networks using Multidimensional\n  Scaling","summary":"The lack of generalization in learning-based autonomous driving applications\nis shown by the narrow range of road scenarios that vehicles can currently\ncover. A generalizable approach should capture many distinct road structures\nand topologies, as well as consider traffic participants, and dynamic changes\nin the environment, so that vehicles can navigate and perform motion planning\ntasks even in the most difficult situations. Designing suitable feature spaces\nfor neural network-based motion planers that encapsulate all kinds of road\nscenarios is still an open research challenge. This paper tackles this\nlearning-based generalization challenge and shows how graph representations of\nroad networks can be leveraged by using multidimensional scaling (MDS)\ntechniques in order to obtain such feature spaces. State-of-the-art graph\nrepresentations and MDS approaches are analyzed for the autonomous driving use\ncase. Finally, the option of embedding graph nodes is discussed in order to\nperform easier learning procedures and obtain dimensionality reduction.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.ET,cs.SC","published":"2025-04-24T13:20:32Z"}
{"aid":"http://arxiv.org/abs/2504.17536v1","title":"Dynamic Membership for Regular Tree Languages","summary":"We study the dynamic membership problem for regular tree languages under\nrelabeling updates: we fix an alphabet ${\\Sigma}$ and a regular tree language\n$L$ over ${\\Sigma}$ (expressed, e.g., as a tree automaton), we are given a tree\n$T$ with labels in ${\\Sigma}$, and we must maintain the information of whether\nthe tree $T$ belongs to $L$ while handling relabeling updates that change the\nlabels of individual nodes in $T$. (The shape and size of the tree remain the\nsame throughout.)\n  Our first contribution is to show that this problem admits an $O(\\log n /\n\\log \\log n)$ algorithm for any fixed regular tree language, improving over\nknown algorithms that achieve $O(\\log n)$. This generalizes the known $O(\\log n\n/ \\log \\log n)$ upper bound over words, and it matches the lower bound of\n${\\Omega}(\\log n / \\log \\log n)$ from dynamic membership to some word languages\nand from the existential marked ancestor problem.\n  Our second contribution is to introduce a class of regular languages, dubbed\nalmost-commutative tree languages, and show that dynamic membership to such\nlanguages under relabeling updates can be done in constant time per update.\nAlmost-commutative languages generalize both commutative languages and finite\nlanguages, and they are the analogue for trees of the ZG languages enjoying\nconstant-time dynamic membership over words. Our main technical contribution is\nto show that this class is conditionally optimal when we assume that the\nalphabet features a neutral letter, i.e., a letter that has no effect on\nmembership to the language. More precisely, we show that any regular tree\nlanguage with a neutral letter which is not almost-commutative cannot be\nmaintained in constant time under the assumption that prefix-U1 problem from\n(Amarilli, Jachiet, Paperman, ICALP'21) also does not admit a constant-time\nalgorithm.","main_category":"cs.FL","categories":"cs.FL,cs.DS","published":"2025-04-24T13:26:08Z"}
{"aid":"http://arxiv.org/abs/2504.17539v1","title":"Proof of Useful Intelligence (PoUI): Blockchain Consensus Beyond Energy\n  Waste","summary":"Blockchain technology enables secure, transparent data management in\ndecentralized systems, supporting applications from cryptocurrencies like\nBitcoin to tokenizing real-world assets like property. Its scalability and\nsustainability hinge on consensus mechanisms balancing security and efficiency.\nProof of Work (PoW), used by Bitcoin, ensures security through energy-intensive\ncomputations but demands significant resources. Proof of Stake (PoS), as in\nEthereum post-Merge, selects validators based on staked cryptocurrency,\noffering energy efficiency but risking centralization from wealth\nconcentration. With AI models straining computational resources, we propose\nProof of Useful Intelligence (PoUI), a hybrid consensus mechanism. In PoUI,\nworkers perform AI tasks like language processing or image analysis to earn\ncoins, which are staked to secure the network, blending security with practical\nutility. Decentralized nodes--job posters, market coordinators, workers, and\nvalidators --collaborate via smart contracts to manage tasks and rewards.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-24T13:32:03Z"}
{"aid":"http://arxiv.org/abs/2504.17553v1","title":"Principal Minors of Hermitian Laplacian Matrix of Directed Graphs and\n  Their Connection to Directed Graph Substructures","summary":"This paper explores the algebraic characterization of directed graph\nsubstructures through principal minors of the Hermitian Laplacian matrix. By\ngeneralizing Bapat et al.'s nonsingular substructure theory and by defining\nsubstructures as vertex-edge pairs $(V',E')$ which allows edges to connect\nvertices outside $V'$, we establish a link between the principle minors and the\ntopological properties of key substructures such as rootless trees and\nunicyclic graphs. Using the Cauchy-Binet formula, we decompose principal minors\ninto sums of determinants of regular substructures. Specifically, we\ninvestigate how these algebraic invariants encode information about unicyclic\nsubstructures and their properties, contributing to the broader understanding\nof graph structures through the lens of Hermitian Laplacian matrix of algebraic\ngraph theory.","main_category":"math.CO","categories":"math.CO","published":"2025-04-24T13:46:14Z"}
{"aid":"http://arxiv.org/abs/2504.17634v1","title":"Sparsity-Exploiting Channel Estimation For Unsourced Random Access With\n  Fluid Antenna","summary":"This work explores the channel estimation (CE) problem in uplink transmission\nfor unsourced random access (URA) with a fluid antenna receiver. The additional\nspatial diversity in a fluid antenna system (FAS) addresses the needs of URA\ndesign in multiple-input and multiple-output (MIMO) systems. We present two CE\nstrategies based on the activation of different FAS ports, namely alternate\nports and partial ports CE. Both strategies facilitate the estimation of\nchannel coefficients and angles of arrival (AoAs). Additionally, we discuss how\nto refine channel estimation by leveraging the sparsity of finite scatterers.\nSpecifically, the proposed partial ports CE strategy is implemented using a\nregularized estimator, and we optimize the estimator's parameter to achieve the\ndesired AoA precision and refinement. Extensive numerical results demonstrate\nthe feasibility of the proposed strategies, and a comparison with a\nconventional receiver using half-wavelength antennas highlights the promising\nfuture of integrating URA and FAS.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-24T15:07:12Z"}
{"aid":"http://arxiv.org/abs/2504.17648v1","title":"A Robust Fault Detection Filter for Linear Time-Varying System with\n  Non-Gaussian Noise","summary":"This paper addresses the problem of robust fault detection filtering for\nlinear time-varying (LTV) systems with non-Gaussian noise and additive faults.\nThe conventional generalized likelihood ratio (GLR) method utilizes the Kalman\nfilter, which may exhibit inadequate performance under non-Gaussian noise\nconditions. To mitigate this issue, a fault detection method employing the\n$H_{\\infty}$ filter is proposed. The $H_{\\infty}$ filter is first derived as\nthe solution to a regularized least-squares (RLS) optimization problem, and the\neffect of faults on the output prediction error is then analyzed. The proposed\napproach using the $H_{\\infty}$ filter demonstrates robustness in non-Gaussian\nnoise environments and significantly improves fault detection performance\ncompared to the original GLR method that employs the Kalman filter. The\neffectiveness of the proposed approach is illustrated using numerical examples.","main_category":"math.OC","categories":"math.OC","published":"2025-04-24T15:18:31Z"}
{"aid":"http://arxiv.org/abs/2504.17656v1","title":"polyGen: A Learning Framework for Atomic-level Polymer Structure\n  Generation","summary":"Synthetic polymeric materials underpin fundamental technologies in the\nenergy, electronics, consumer goods, and medical sectors, yet their development\nstill suffers from prolonged design timelines. Although polymer informatics\ntools have supported speedup, polymer simulation protocols continue to face\nsignificant challenges: on-demand generation of realistic 3D atomic structures\nthat respect the conformational diversity of polymer structures. Generative\nalgorithms for 3D structures of inorganic crystals, bio-polymers, and small\nmolecules exist, but have not addressed synthetic polymers. In this work, we\nintroduce polyGen, the first latent diffusion model designed specifically to\ngenerate realistic polymer structures from minimal inputs such as the repeat\nunit chemistry alone, leveraging a molecular encoding that captures polymer\nconnectivity throughout the architecture. Due to a scarce dataset of only 3855\nDFT-optimized polymer structures, we augment our training with DFT-optimized\nmolecular structures, showing improvement in joint learning between similar\nchemical structures. We also establish structure matching criteria to benchmark\nour approach on this novel problem. polyGen effectively generates diverse\nconformations of both linear chains and complex branched structures, though its\nperformance decreases when handling repeat units with a high atom count. Given\nthese initial results, polyGen represents a paradigm shift in atomic-level\nstructure generation for polymer science-the first proof-of-concept for\npredicting realistic atomic-level polymer conformations while accounting for\ntheir intrinsic structural flexibility.","main_category":"cs.CE","categories":"cs.CE,cond-mat.mtrl-sci,cs.LG","published":"2025-04-24T15:26:00Z"}
{"aid":"http://arxiv.org/abs/2504.17694v1","title":"Using mathematical models of heart cells to assess the safety of new\n  pharmaceutical drugs","summary":"Many drugs have been withdrawn from the market worldwide, at a cost of\nbillions of dollars, because of patient fatalities due to them unexpectedly\ndisturbing heart rhythm. Even drugs for ailments as mild as hay fever have been\nwithdrawn due to an unacceptable increase in risk of these heart rhythm\ndisturbances. Consequently, the whole pharmaceutical industry expends a huge\neffort in checking all new drugs for any unwanted side effects on the heart.\nThe predominant root cause has been identified as drug molecules blocking ionic\ncurrent flows in the heart. Block of individual types of ionic currents can now\nbe measured experimentally at an early stage of drug development, and this is\nthe standard screening approach for a number of ion currents in many large\npharmaceutical companies. However, clinical risk is a complex function of the\ndegree of block of many different types of cardiac ion currents, and this is\ndifficult to understand by looking at results of these screens independently.\nBy using ordinary differential equation models for the electrical activity of\nheart cells (electrophysiology models) we can integrate information from\ndifferent types of currents, to predict the effect on whole heart cells and\nsubsequent risk of side effects. The resulting simulations can provide a more\naccurate summary of the risk of a drug earlier in development and hence more\ncheaply than the pre-existing approaches.","main_category":"q-bio.CB","categories":"q-bio.CB,q-bio.SC","published":"2025-04-24T16:03:06Z"}
{"aid":"http://arxiv.org/abs/2504.17699v1","title":"Quadratic Interest Network for Multimodal Click-Through Rate Prediction","summary":"Multimodal click-through rate (CTR) prediction is a key technique in\nindustrial recommender systems. It leverages heterogeneous modalities such as\ntext, images, and behavioral logs to capture high-order feature interactions\nbetween users and items, thereby enhancing the system's understanding of user\ninterests and its ability to predict click behavior. The primary challenge in\nthis field lies in effectively utilizing the rich semantic information from\nmultiple modalities while satisfying the low-latency requirements of online\ninference in real-world applications. To foster progress in this area, the\nMultimodal CTR Prediction Challenge Track of the WWW 2025 EReL@MIR Workshop\nformulates the problem into two tasks: (1) Task 1 of Multimodal Item Embedding:\nthis task aims to explore multimodal information extraction and item\nrepresentation learning methods that enhance recommendation tasks; and (2) Task\n2 of Multimodal CTR Prediction: this task aims to explore what multimodal\nrecommendation model can effectively leverage multimodal embedding features and\nachieve better performance. In this paper, we propose a novel model for Task 2,\nnamed Quadratic Interest Network (QIN) for Multimodal CTR Prediction.\nSpecifically, QIN employs adaptive sparse target attention to extract\nmultimodal user behavior features, and leverages Quadratic Neural Networks to\ncapture high-order feature interactions. As a result, QIN achieved an AUC of\n0.9798 on the leaderboard and ranked second in the competition. The model code,\ntraining logs, hyperparameter configurations, and checkpoints are available at\nhttps://github.com/salmon1802/QIN.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-24T16:08:52Z"}
{"aid":"http://arxiv.org/abs/2504.17705v1","title":"LUIDA: Large-scale Unified Infrastructure for Digital Assessments based\n  on Commercial Metaverse Platform","summary":"Online experiments using metaverse platforms have gained significant traction\nin Human-Computer Interaction and Virtual Reality (VR) research. However,\ncurrent research workflows are highly fragmented, as researchers must use\nseparate tools for system implementation, participant recruitment, experiment\nexecution, and data collection, reducing consistency and increasing workload.\nWe present LUIDA (Large-scale Unified Infrastructure for Digital Assessments),\na metaverse-based framework that integrates these fragmented processes. LUIDA\nautomatically allocates interconnected virtual environments for parallel\nexperiment execution and provides implementation templates adaptable to various\nVR research domains, requiring minimal metaverse development expertise. Our\nevaluation included two studies using a prototype built on Cluster, the\ncommercial metaverse platform. First, VR researchers using LUIDA to develop and\nrun experiments reported high usability scores (SUS: 73.75) and moderate\nworkload (NASA-TLX: 24.11) for overall usage, with interviews confirming\nstreamlined workflows compared to traditional laboratory experiments. Second,\nwe conducted three replicated experiments with public Cluster users, each\nrecruiting approximately 200 participants within one week. These experiments\nproduced results that closely matched the original studies, validating the\nexperimental integrity of LUIDA across research domains. After technical\nrefinements, we plan to release LUIDA as an open platform, providing a\nstandardized protocol to improve research efficiency and experimental\nreproducibility in VR studies.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-24T16:11:12Z"}
{"aid":"http://arxiv.org/abs/2504.17713v1","title":"Target-Date Funds: A State-of-the-Art Review with Policy Applications to\n  Chile's Pension Reform","summary":"This review paper explores the evolution and implementation of target-date\nfunds (TDFs), specifically focusing on their application within the context of\nChile's 2025 pension reform. The introduction of TDFs marks a significant shift\nin Chile's pension system, which has traditionally relied on a multifund\nstructure (essentially a target-risk funds system). We offer a comprehensive\nreview of the theoretical foundations and practical considerations of TDFs,\nhighlighting key challenges and opportunities for Chilean regulators and fund\nmanagers. Notably, we recommend that the glide path design should be dynamic,\nincorporating adjustments based on total accumulated wealth, with particular\nflexibility depending on each investor's risk tolerance. Furthermore, we\npropose that the new benchmark for generational funds should feature a wide\ndeviation band relative to the new benchmark portfolio, which could foster a\nmarket with more investment strategies and better competition among fund\nmanagers, encourage the inclusion of alternative assets, and foster greater\ndiversification. Lastly, we highlight the need for future work to define a\nglide path model that incorporates the theoretical frameworks described,\ntailored to the unique parameters of the Chilean pension system. These\nrecommendations aim to optimize the long-term retirement outcomes for Chilean\nworkers under the new pension structure.","main_category":"q-fin.PM","categories":"q-fin.PM","published":"2025-04-24T16:16:54Z"}
{"aid":"http://arxiv.org/abs/2504.17732v1","title":"DPMambaIR:All-in-One Image Restoration via Degradation-Aware Prompt\n  State Space Model","summary":"All-in-One image restoration aims to address multiple image degradation\nproblems using a single model, significantly reducing training costs and\ndeployment complexity compared to traditional methods that design dedicated\nmodels for each degradation type. Existing approaches typically rely on\nDegradation-specific models or coarse-grained degradation prompts to guide\nimage restoration. However, they lack fine-grained modeling of degradation\ninformation and face limitations in balancing multi-task conflicts. To overcome\nthese limitations, we propose DPMambaIR, a novel All-in-One image restoration\nframework. By integrating a Degradation-Aware Prompt State Space Model (DP-SSM)\nand a High-Frequency Enhancement Block (HEB), DPMambaIR enables fine-grained\nmodeling of complex degradation information and efficient global integration,\nwhile mitigating the loss of high-frequency details caused by task competition.\nSpecifically, the DP-SSM utilizes a pre-trained degradation extractor to\ncapture fine-grained degradation features and dynamically incorporates them\ninto the state space modeling process, enhancing the model's adaptability to\ndiverse degradation types. Concurrently, the HEB supplements high-frequency\ninformation, effectively addressing the loss of critical details, such as edges\nand textures, in multi-task image restoration scenarios. Extensive experiments\non a mixed dataset containing seven degradation types show that DPMambaIR\nachieves the best performance, with 27.69dB and 0.893 in PSNR and SSIM,\nrespectively. These results highlight the potential and superiority of\nDPMambaIR as a unified solution for All-in-One image restoration.","main_category":"cs.CV","categories":"cs.CV,I.4.4","published":"2025-04-24T16:46:32Z"}
{"aid":"http://arxiv.org/abs/2504.17741v1","title":"Multi-messenger standard-siren cosmology for third-generation\n  gravitational-wave detectors: Considering observations of gamma-ray bursts\n  and kilonovae","summary":"In the third-generation (3G) gravitational-wave (GW) detector era, GW\nmulti-messenger observations for binary neutron star merger events can exert\ngreat impacts on exploring the cosmic expansion history. Extending the previous\nwork, we explore the potential of 3G GW standard siren observations in\ncosmological parameter estimation by considering their associated\nelectromagnetic (EM) counterparts, including $\\gamma$-ray burst (GRB)\ncoincidence observations by the Gravitational wave high-energy Electromagnetic\nCounterpart All-sky Monitor and GW-triggered target-of-opportunity observations\nof kilonovae by different optical survey projects. During an assumed 10-year\nobservation, we predict that the number of detectable GW-kilonova events is\n$\\sim 4900$ with redshifts below $\\sim 0.4$ under GW network and Large Synoptic\nSurvey Telescope in the $i$ band, which is three times more than that of GW-GRB\ndetections. For the cosmological analysis, we find that with the inclusion of\nGW-kilonova detections, the constraints on cosmological parameters from GW-EM\ndetections are significantly improved compared to those from GW-GRB detections.\nIn particular, GW-EM detections can tightly constrain the Hubble constant with\na precision ranging from $0.076\\%$ to $0.034\\%$. Moreover, GW multi-messenger\nobservations could effectively break the cosmological parameter degeneracies\ngenerated by the mainstream EM observations, CMB+BAO+SN (CBS). The combination\nof CBS and GW-EM can tightly constrain the equation of state parameters of dark\nenergy $w$ in the $w$CDM model and $w_0$ in the $w_0w_a$CDM model with\nprecisions of $0.72\\%$ and $0.99\\%$, respectively, meeting the standard of\nprecision cosmology. In conclusion, GW multi-messenger observations could play\na crucial role in helping solve the Hubble tension and probing the fundamental\nnature of dark energy.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph","published":"2025-04-24T16:57:51Z"}
{"aid":"http://arxiv.org/abs/2504.17743v1","title":"Realization of Temporally Connected Graphs Based on Degree Sequences","summary":"Given an undirected graph $G$, the problem of deciding whether $G$ admits a\nsimple and proper time-labeling that makes it temporally connected is known to\nbe NP-hard (G\\\"obel et al., 1991). In this article, we relax this problem and\nask whether a given degree sequence can be realized as a temporally connected\ngraph. Our main results are a complete characterization of the feasible cases,\nand a recognition algorithm that runs in $O(n)$ time for graphical degree\nsequences (realized as simple temporal graphs) and in $O(n+m)$ time for\nmultigraphical degree sequences (realized as non-simple temporal graphs, where\nthe number of time labels on an edge corresponds to the multiplicity of the\nedge in the multigraph). In fact, these algorithms can be made constructive at\nessentially no cost. Namely, we give a constructive $O(n+m)$ time algorithm\nthat outputs, for a given (multi)graphical degree sequence $\\mathbf{d}$, a\ntemporally connected graph whose underlying (multi)graph is a realization of\n$\\mathbf{d}$, if one exists.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-24T17:01:35Z"}
{"aid":"http://arxiv.org/abs/2504.17744v1","title":"Nearby open clusters with tidal features: golden sample selection and 3D\n  structure","summary":"Open clusters offer unique opportunities to study stellar dynamics and\nevolution under the influence of their internal gravity, the Milky Way's\ngravitational field, and the interactions with encounters. Using the Gaia DR3\ndata for a catalog of open clusters within 500 parsecs that exhibit tidal\nfeatures reported by the literature, we apply a novel method based on 3D\nprincipal component analysis to select a ``golden sample'' of nearby open\nclusters with minimal line-of-sight distortions. This approach ensures a\nsystematic comparison of 3D and 2D structural parameters for tidally perturbed\nclusters. The selected golden sample includes Blanco 1, Melotte 20, Melotte 22,\nNGC 2632, NGC 7092, NGC 1662, Roslund 6 and Melotte 111. We analyze these\nclusters by fitting both 2D and 3D King Profiles to their stellar density\ndistributions. Our results reveal systematic discrepancies: most of the golden\nsample clusters exhibit larger 3D tidal radii compared to their 2D\ncounterparts, demonstrating that the 2D projection effects bias the measured\ncluster size. Furthermore, the 3D density profiles show stronger deviations\nfrom King profiles at the tidal radii ($\\Delta \\rho_{\\rm 3D} > \\Delta \\rho_{\\rm\n2D}$), highlighting enhanced sensitivity to tidal disturbances. Additionally,\nwe investigate the spatial distribution of cluster members relative to their\nbulk motion in the Galactic plane. We find that some clusters exhibit tidal\nfeatures oriented perpendicular to their direction of motion, which can be\nattributed to the fact that the current surveys only detect the curved inner\nregions of the tidal features. In conclusion, this work offers a golden sample\nof nearby open clusters that are most reliable for 3D structure analysis and\nunderscores the necessity of 3D analysis in characterizing OC morphological\nasymmetries, determining cluster size, and identifying tidal features.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-04-24T17:02:37Z"}
{"aid":"http://arxiv.org/abs/2504.17780v1","title":"Replay to Remember: Retaining Domain Knowledge in Streaming Language\n  Models","summary":"Continual learning in large language models (LLMs) typically encounters the\ncritical challenge of catastrophic forgetting, where previously acquired\nknowledge deteriorates upon exposure to new data. While techniques like replay\nbuffers and parameter-efficient tuning (e.g., Low-Rank Adaptation or LoRA) have\nbeen proposed, few studies investigate real-time domain adaptation under strict\ncomputational and data-stream constraints. In this paper, we demonstrate a\nlightweight method combining LoRA and a minimal replay mechanism in a realistic\nstreaming setting across three diverse knowledge domains: medical question\nanswering, genetics, and law. Using perplexity, semantic similarity, and\nGPT-based human-like evaluation metrics, we quantify the model's adaptation,\nforgetting, and recovery over time. Our experiments reveal that while\ncatastrophic forgetting naturally occurs, even minimal replay significantly\nstabilizes and partially restores domain-specific knowledge. This study\ncontributes practical insights for deploying adaptable LLMs in\nresource-constrained, real-world scenarios.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-24T17:56:22Z"}
{"aid":"http://arxiv.org/abs/2504.19475v1","title":"Prisma: An Open Source Toolkit for Mechanistic Interpretability in\n  Vision and Video","summary":"Robust tooling and publicly available pre-trained models have helped drive\nrecent advances in mechanistic interpretability for language models. However,\nsimilar progress in vision mechanistic interpretability has been hindered by\nthe lack of accessible frameworks and pre-trained weights. We present Prisma\n(Access the codebase here: https://github.com/Prisma-Multimodal/ViT-Prisma), an\nopen-source framework designed to accelerate vision mechanistic\ninterpretability research, providing a unified toolkit for accessing 75+ vision\nand video transformers; support for sparse autoencoder (SAE), transcoder, and\ncrosscoder training; a suite of 80+ pre-trained SAE weights; activation\ncaching, circuit analysis tools, and visualization tools; and educational\nresources. Our analysis reveals surprising findings, including that effective\nvision SAEs can exhibit substantially lower sparsity patterns than language\nSAEs, and that in some instances, SAE reconstructions can decrease model loss.\nPrisma enables new research directions for understanding vision model internals\nwhile lowering barriers to entry in this emerging field.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-28T04:31:24Z"}
{"aid":"http://arxiv.org/abs/2504.19487v1","title":"Evolution of Cooperation in LLM-Agent Societies: A Preliminary Study\n  Using Different Punishment Strategies","summary":"The evolution of cooperation has been extensively studied using abstract\nmathematical models and simulations. Recent advances in Large Language Models\n(LLM) and the rise of LLM agents have demonstrated their ability to perform\nsocial reasoning, thus providing an opportunity to test the emergence of norms\nin more realistic agent-based simulations with human-like reasoning using\nnatural language. In this research, we investigate whether the cooperation\ndynamics presented in Boyd and Richerson's model persist in a more realistic\nsimulation of the diner's dilemma using LLM agents compared to the abstract\nmathematical nature in the work of Boyd and Richerson. Our findings indicate\nthat agents follow the strategies defined in the Boyd and Richerson model, and\nexplicit punishment mechanisms drive norm emergence, reinforcing cooperative\nbehaviour even when the agent strategy configuration varies. Our results\nsuggest that LLM-based Multi-Agent System simulations, in fact, can replicate\nthe evolution of cooperation predicted by the traditional mathematical models.\nMoreover, our simulations extend beyond the mathematical models by integrating\nnatural language-driven reasoning and a pairwise imitation method for strategy\nadoption, making them a more realistic testbed for cooperative behaviour in\nMASs.","main_category":"cs.MA","categories":"cs.MA","published":"2025-04-28T05:07:55Z"}
{"aid":"http://arxiv.org/abs/2504.19507v1","title":"\\textit{From Freshness to Effectiveness}: Goal-Oriented Sampling for\n  Remote Decision Making","summary":"Data freshness, measured by Age of Information (AoI), is highly relevant in\nnetworked applications such as Vehicle to Everything (V2X), smart health\nsystems, and Industrial Internet of Things (IIoT). Yet, freshness alone does\nnot equate to informativeness. In decision-critical settings, some stale data\nmay prove more valuable than fresh updates. To explore this nuance, we move\nbeyond AoI-centric policies and investigate how data staleness impacts\ndecision-making under data-staleness-induced uncertainty. We pose a central\nquestion: What is the value of information, when freshness fades, and only its\npower to shape remote decisions remains? To capture this endured value, we\npropose AR-MDP, an Age-aware Remote Markov Decision Process framework, which\nco-designs optimal sampling and remote decision-making under a sampling\nfrequency constraint and random delay. To efficiently solve this problem, we\ndesign a new two-stage hierarchical algorithm namely Quick\nBellman-Linear-Program (QuickBLP), where the first stage involves solving the\nDinkelbach root of a Bellman variant and the second stage involves solving a\nstreamlined linear program (LP). For the tricky first stage, we propose a new\nOne-layer Primal-Dinkelbach Synchronous Iteration (OnePDSI) method, which\novercomes the re-convergence and non-expansive divergence present in existing\nper-sample multi-layer algorithms. Through rigorous convergence analysis of our\nproposed algorithms, we establish that the worst-case optimality gap in OnePDSI\nexhibits exponential decay with respect to iteration $K$ at a rate of\n$\\mathcal{O}(\\frac{1}{R^K})$. Through sensitivity analysis, we derive a\nthreshold for the sampling frequency, beyond which additional sampling does not\nyield further gains in decision-making. Simulation results validate our\nanalyses.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-28T06:17:09Z"}
{"aid":"http://arxiv.org/abs/2504.19512v1","title":"Gapped Boundaries of Kitaev's Quantum Double Models: A Lattice\n  Realization of Anyon Condensation from Lagrangian Algebras","summary":"The macroscopic theory of anyon condensation, rooted in the categorical\nstructure of topological excitations, provides a complete classification of\ngapped boundaries in topologically ordered systems, where distinct boundaries\ncorrespond to the condensation of different Lagrangian algebras. However, an\nintrinsic and direct understanding of anyon condensation in lattice models,\ngrounded in the framework of Lagrangian algebras, remains undeveloped. In this\npaper, we propose a systematic framework for constructing all gapped boundaries\nof Kitaev's quantum double models directly from the data of Lagrangian\nalgebras. Central to our approach is the observation that bulk interactions in\nthe quantum double models admit two complementary interpretations: the\nanyon-creating picture and anyon-probing picture. Generalizing this insight to\nthe boundary, we derive the consistency condition for boundary ribbon operators\nthat respect the mathematical axiomatic structure of Lagrangian algebras.\nSolving these conditions yields explicit expressions for the local boundary\ninteractions required to realize gapped boundaries. Our construction provides a\nmicroscopic characterization of the bulk-to-boundary anyon condensation\ndynamics via the action of ribbon operators. Moreover, all these boundary terms\nare supported within a common effective Hilbert space, making further studies\non pure boundary phase transitions natural and convenient. Given the broad\napplicability of anyon condensation theory, we believe that our approach can be\ngeneralized to extended string-net models or higher-dimensional topologically\nordered systems.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,math-ph,math.MP,quant-ph","published":"2025-04-28T06:22:06Z"}
{"aid":"http://arxiv.org/abs/2504.19514v1","title":"FSBench: A Figure Skating Benchmark for Advancing Artistic Sports\n  Understanding","summary":"Figure skating, known as the \"Art on Ice,\" is among the most artistic sports,\nchallenging to understand due to its blend of technical elements (like jumps\nand spins) and overall artistic expression. Existing figure skating datasets\nmainly focus on single tasks, such as action recognition or scoring, lacking\ncomprehensive annotations for both technical and artistic evaluation. Current\nsports research is largely centered on ball games, with limited relevance to\nartistic sports like figure skating. To address this, we introduce FSAnno, a\nlarge-scale dataset advancing artistic sports understanding through figure\nskating. FSAnno includes an open-access training and test dataset, alongside a\nbenchmark dataset, FSBench, for fair model evaluation. FSBench consists of\nFSBench-Text, with multiple-choice questions and explanations, and\nFSBench-Motion, containing multimodal data and Question and Answer (QA) pairs,\nsupporting tasks from technical analysis to performance commentary. Initial\ntests on FSBench reveal significant limitations in existing models'\nunderstanding of artistic sports. We hope FSBench will become a key tool for\nevaluating and enhancing model comprehension of figure skating.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-28T06:25:04Z"}
{"aid":"http://arxiv.org/abs/2504.19522v1","title":"A Model-based DNN for Learning HMIMO Beamforming","summary":"Holographic MIMO (HMIMO) is a promising technique for large-scale MIMO\nsystems to enhance spectral efficiency while maintaining low hardware cost and\npower consumption. Existing alternating optimization algorithms can effectively\noptimize the hybrid beamforming of HMIMO to improve the system performance,\nwhile their high computational complexity hinders real-time application. In\nthis paper, we propose a model-based deep neural network (MB-DNN), which\nleverages permutation equivalent properties and the optimal beamforming\nstructure to jointly optimize the holographic and digital beamforming.\nSimulation results demonstrate that the proposed MB-DNN outperforms benchmark\nschemes and requires much less inference time than existing alternating\noptimization algorithms.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-28T06:40:41Z"}
{"aid":"http://arxiv.org/abs/2504.19527v1","title":"Identification and Estimation of Long-Term Treatment Effects with\n  Monotone Missing","summary":"Estimating long-term treatment effects has a wide range of applications in\nvarious domains. A key feature in this context is that collecting long-term\noutcomes typically involves a multi-stage process and is subject to monotone\nmissing, where individuals missing at an earlier stage remain missing at\nsubsequent stages. Despite its prevalence, monotone missing has been rarely\nexplored in previous studies on estimating long-term treatment effects. In this\npaper, we address this gap by introducing the sequential missingness assumption\nfor identification. We propose three novel estimation methods, including\ninverse probability weighting, sequential regression imputation, and sequential\nmarginal structural model (SeqMSM). Considering that the SeqMSM method may\nsuffer from high variance due to severe data sparsity caused by monotone\nmissing, we further propose a novel balancing-enhanced approach, BalanceNet, to\nimprove the stability and accuracy of the estimation methods. Extensive\nexperiments on two widely used benchmark datasets demonstrate the effectiveness\nof our proposed methods.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-28T07:07:50Z"}
{"aid":"http://arxiv.org/abs/2504.19537v1","title":"Universally Wheeler Languages","summary":"The notion of Wheeler languages is rooted in the Burrows-Wheeler transform\n(BWT), one of the most central concepts in data compression and indexing. The\nBWT has been generalized to finite automata, the so-called Wheeler automata, by\nGagie et al. [Theor. Comput. Sci. 2017]. Wheeler languages have subsequently\nbeen defined as the class of regular languages for which there exists a Wheeler\nautomaton accepting them. Besides their advantages in data indexing, these\nWheelerlanguages also satisfy many interesting properties from a language\ntheoretic point of view [Alanko et al., Inf. Comput. 2021]. A characteristic\nyet unsatisfying feature of Wheeler languages however is that their definition\ndepends on a fixed order of the alphabet. In this paper we introduce the\nUniversally Wheeler languages UW, i.e., the regular languages that are Wheeler\nwith respect to all orders of a given alphabet. Our first main contribution is\nto relate UW to some very well known regular language classes. We first show\nthat the Striclty Locally Testable languages are strictly included in UW. After\nnoticing that UW is not closed under taking the complement, we prove that the\nclass of languages for which both the language and its complement are in UW\nexactly coincides with those languages that are Definite or Reverse Definite.\nSecondly, we prove that deciding if a regular language given by a DFA is in UW\ncan be done in quadratic time. We also show that this is optimal unless the\nStrong Exponential Time Hypothesis (SETH) fails.","main_category":"cs.FL","categories":"cs.FL","published":"2025-04-28T07:40:16Z"}
{"aid":"http://arxiv.org/abs/2504.19550v1","title":"Deployment Optimization for XL-IRS Assisted Multi-User Communications","summary":"In this paper, we study the deployment optimization for an extremely\nlarge-scale intelligent reflecting surface (XL-IRS) assisted multi-user\ncommunication system, within which the channels between the XL-IRS and the BS\n(or user) are modeled by the near-field spherical wavefronts. To draw some\nvaluable insights, we first consider the single-user case, where an alternating\noptimization (AO) based algorithm is devised to maximize the received\nsignal-to-noise ratio (SNR) at the user. To address the high computational\ncomplexity issue incurred by the AO based algorithm, three approximate received\nSNR expressions are obtained to yield useful insights, corresponding to the\nupper bound, approximate expression, and closed-form. It is demonstrated that\nthe XL-IRS ought to be positioned near the user (rather than the BS) to obtain\na higher beamforming gain. Then, for the multi-user scenario, an efficient\nalgorithm is proposed to obtain a high-quality XL-IRS placement solution by\nusing the AO and successive convex approximation (SCA) techniques. Furthermore,\nthe effective degree of freedom (DoF) of the BS-IRS channel is provided, which\nindicates that the additional effective DoF can be leveraged to improve\nmulti-user spatial multiplexing. Last, numerical results confirm the existence\nof a trade-off between near-field beam-focusing gain and multiplexing gain.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-28T07:57:14Z"}
{"aid":"http://arxiv.org/abs/2504.19559v1","title":"Using the Translation Theorem for the Automated Stationkeeping of\n  Extremely-Low Lunar Missions","summary":"Extremely-Low Lunar Orbits (eLLOs) (altitudes $\\leq 50$ km) exhibit severe\nperturbations due to the highly non-spherical lunar gravitational field,\npresenting unique challenges to orbit maintenance. These altitudes are too low\nfor the existence of stable `frozen' orbits, and naive stationkeeping methods,\nsuch as circularization, perform poorly. However, mission designers have\nnoticed a particular characteristic of low lunar orbits, which they have found\nuseful for stationkeeping and dubbed the \"translation theorem\", wherein the\neccentricity vector follows a predictable monthly pattern that is independent\nof its starting value. We demonstrate this feature results from the low orbital\neccentricity combined with the dominant effect of a particular subset of\nsectoral and tesseral harmonics. Subsequently, automated stationkeeping\nstrategies for eLLOs are presented, utilizing this theorem for eccentricity\nvector control. Several constraints within the eccentricity vector plane are\nexplored, including circular, annular, and elevation-model derived regions,\neach forming distinct stationkeeping strategies for varying orbital\nconfigurations. Subsequently, the optimal control profiles for these maneuvers\nwithin the eccentricity plane are obtained using Sequential Convex Programming\n(SCP). The proposed strategies offer computational simplicity and clear\nadvantages when compared to traditional methods and are comparable to full\ntrajectory optimization.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.EP","published":"2025-04-28T08:08:06Z"}
{"aid":"http://arxiv.org/abs/2504.19584v1","title":"ShowMak3r: Compositional TV Show Reconstruction","summary":"Reconstructing dynamic radiance fields from video clips is challenging,\nespecially when entertainment videos like TV shows are given. Many challenges\nmake the reconstruction difficult due to (1) actors occluding with each other\nand having diverse facial expressions, (2) cluttered stages, and (3) small\nbaseline views or sudden shot changes. To address these issues, we present\nShowMak3r, a comprehensive reconstruction pipeline that allows the editing of\nscenes like how video clips are made in a production control room. In\nShowMak3r, a 3DLocator module locates recovered actors on the stage using depth\nprior and estimates unseen human poses via interpolation. The proposed\nShotMatcher module then tracks the actors under shot changes. Furthermore,\nShowMak3r introduces a face-fitting network that dynamically recovers the\nactors' expressions. Experiments on Sitcoms3D dataset show that our pipeline\ncan reassemble TV show scenes with new cameras at different timestamps. We also\ndemonstrate that ShowMak3r enables interesting applications such as synthetic\nshot-making, actor relocation, insertion, deletion, and pose manipulation.\nProject page : https://nstar1125.github.io/showmak3r","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-28T08:44:42Z"}
{"aid":"http://arxiv.org/abs/2504.19607v1","title":"Adaptive Locomotion on Mud through Proprioceptive Sensing of Substrate\n  Properties","summary":"Muddy terrains present significant challenges for terrestrial robots, as\nsubtle changes in composition and water content can lead to large variations in\nsubstrate strength and force responses, causing the robot to slip or get stuck.\nThis paper presents a method to estimate mud properties using proprioceptive\nsensing, enabling a flipper-driven robot to adapt its locomotion through muddy\nsubstrates of varying strength. First, we characterize mud reaction forces\nthrough actuator current and position signals from a statically mounted robotic\nflipper. We use the measured force to determine key coefficients that\ncharacterize intrinsic mud properties. The proprioceptively estimated\ncoefficients match closely with measurements from a lab-grade load cell,\nvalidating the effectiveness of the proposed method. Next, we extend the method\nto a locomoting robot to estimate mud properties online as it crawls across\ndifferent mud mixtures. Experimental data reveal that mud reaction forces\ndepend sensitively on robot motion, requiring joint analysis of robot movement\nwith proprioceptive force to determine mud properties correctly. Lastly, we\ndeploy this method in a flipper-driven robot moving across muddy substrates of\nvarying strengths, and demonstrate that the proposed method allows the robot to\nuse the estimated mud properties to adapt its locomotion strategy, and\nsuccessfully avoid locomotion failures. Our findings highlight the potential of\nproprioception-based terrain sensing to enhance robot mobility in complex,\ndeformable natural environments, paving the way for more robust field\nexploration capabilities.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-28T09:12:21Z"}
{"aid":"http://arxiv.org/abs/2504.19642v1","title":"Primal and dual characterizations of sign-symmetric norms","summary":"The paper studies primal and dual characterizations of a class of\nsign-symmetric norms on product vector spaces. Correspondences between these\nnorms and a class of convex functions are established. Explicit formulas for\nthe dual norm and the convex subdifferential of a given primal norm are\nderived. It is demonstrated that this class of norms is well-suited for\nstudying properties and problems on product spaces. As an application, we study\nthe von Neumann-Jordan constant of norms on product spaces and extend a\nclassical result of Clarkson from Lebesgue spaces to general normed vector\nspaces.","main_category":"math.FA","categories":"math.FA","published":"2025-04-28T10:00:04Z"}
{"aid":"http://arxiv.org/abs/2504.19659v1","title":"Hardware/Software Co-Design of RISC-V Extensions for Accelerating Sparse\n  DNNs on FPGAs","summary":"The customizability of RISC-V makes it an attractive choice for accelerating\ndeep neural networks (DNNs). It can be achieved through instruction set\nextensions and corresponding custom functional units. Yet, efficiently\nexploiting these opportunities requires a hardware/software co-design approach\nin which the DNN model, software, and hardware are designed together. In this\npaper, we propose novel RISC-V extensions for accelerating DNN models\ncontaining semi-structured and unstructured sparsity. While the idea of\naccelerating structured and unstructured pruning is not new, our novel design\noffers various advantages over other designs. To exploit semi-structured\nsparsity, we take advantage of the fine-grained (bit-level) configurability of\nFPGAs and suggest reserving a few bits in a block of DNN weights to encode the\ninformation about sparsity in the succeeding blocks. The proposed custom\nfunctional unit utilizes this information to skip computations. To exploit\nunstructured sparsity, we propose a variable cycle sequential\nmultiply-and-accumulate unit that performs only as many multiplications as the\nnon-zero weights. Our implementation of unstructured and semi-structured\npruning accelerators can provide speedups of up to a factor of 3 and 4,\nrespectively. We then propose a combined design that can accelerate both types\nof sparsities, providing speedups of up to a factor of 5. Our designs consume a\nsmall amount of additional FPGA resources such that the resulting co-designs\nenable the acceleration of DNNs even on small FPGAs. We benchmark our designs\non standard TinyML applications such as keyword spotting, image classification,\nand person detection.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.AR","published":"2025-04-28T10:19:39Z"}
{"aid":"http://arxiv.org/abs/2504.19662v1","title":"Ariel OS: An Embedded Rust Operating System for Networked Sensors &\n  Multi-Core Microcontrollers","summary":"Large swaths of low-level system software building blocks originally\nimplemented in C/C++ are currently being swapped for equivalent rewrites in\nRust, a relatively more secure and dependable programming language. So far,\nhowever, no embedded OS in Rust supports multicore preemptive scheduling on\nmicrocontrollers. In this paper, we thus fill this gap with a new operating\nsystem: Ariel OS. We describe its design, we provide the source code of its\nimplementation, and we perform micro-benchmarks on the main 32-bit\nmicrocontroller architectures: ARM Cortex-M, RISC-V and Espressif Xtensa. We\nshow how our scheduler takes advantage of several cores, while incurring only\nsmall overhead on single-core hardware. As such, Ariel OS provides a convenient\nembedded software platform for small networked devices, for both research and\nindustry practitioners.","main_category":"cs.OS","categories":"cs.OS","published":"2025-04-28T10:21:13Z"}
{"aid":"http://arxiv.org/abs/2504.19663v1","title":"The Boussinesq equation on the half-line","summary":"We study the initial-boundary value problem for the Boussinesq equation on\nthe half-line. Assuming that the solution exists, we prove that it can be\nrecovered from its initial-boundary values via the solution of a $3\\times 3$\nRiemann-Hilbert problem. The contour consists of $18$ arcs on the unit circle,\n$18$ segments and $18$ half-lines, and the associated jump matrices involve $9$\nreflection coefficients.","main_category":"math.AP","categories":"math.AP","published":"2025-04-28T10:21:54Z"}
{"aid":"http://arxiv.org/abs/2504.19672v1","title":"On Neutron Star Natal Kicks in High-Mass X-Ray Binaries: Insights from\n  Population Synthesis","summary":"The motion of neutron stars (NSs) in the Galaxy is largely dependent on natal\nkicks received by the NSs during supernova explosions. Thus, the measured\npeculiar velocities of NS high-mass X-ray binaries (HMXBs) provide valuable\nclues to natal kicks, which also play an important role in the evolution of\nHMXBs. In this work, we collect proper motions, radial velocities and\nparallaxes for 36 NS HMXBs to derive their peculiar velocities at the birth of\nthe NSs. We then use binary population synthesis to simulate the velocities of\nNS HMXBs with various choices of the kick velocity distribution for both\ncore-collapse and electron-capture supernovae. Comparing the simulated and\nmeasured velocities, orbital periods, and eccentricities, we show that the\nnatal kick distribution that can best match the observations is characterized\nby a bimodal Maxwellian distribution with $\\sigma_1$ = 320 km s$^{-1}$ (for\ncore-collapse supernovae) and $\\sigma_2$ = 80 km s$^{-1}$ (for electron-capture\nsupernovae) and the He core mass for the latter in the range of $(1.83-2.25)$\n$M_{\\odot}$. Our findings provide useful insights for further population\nsynthesis and binary evolution studies of NS binaries.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-28T10:57:36Z"}
{"aid":"http://arxiv.org/abs/2504.19673v1","title":"Generative AI in Education: Student Skills and Lecturer Roles","summary":"Generative Artificial Intelligence (GenAI) tools such as ChatGPT are emerging\nas a revolutionary tool in education that brings both positive aspects and\nchallenges for educators and students, reshaping how learning and teaching are\napproached. This study aims to identify and evaluate the key competencies\nstudents need to effectively engage with GenAI in education and to provide\nstrategies for lecturers to integrate GenAI into teaching practices. The study\napplied a mixed method approach with a combination of a literature review and a\nquantitative survey involving 130 students from South Asia and Europe to obtain\nits findings. The literature review identified 14 essential student skills for\nGenAI engagement, with AI literacy, critical thinking, and ethical AI practices\nemerging as the most critical. The student survey revealed gaps in prompt\nengineering, bias awareness, and AI output management. In our study of lecturer\nstrategies, we identified six key areas, with GenAI Integration and Curriculum\nDesign being the most emphasised. Our findings highlight the importance of\nincorporating GenAI into education. While literature prioritized ethics and\npolicy development, students favour hands-on, project-based learning and\npractical AI applications. To foster inclusive and responsible GenAI adoption,\ninstitutions should ensure equitable access to GenAI tools, establish clear\nacademic integrity policies, and advocate for global GenAI research\ninitiatives.","main_category":"cs.CY","categories":"cs.CY,cs.AI","published":"2025-04-28T10:58:30Z"}
{"aid":"http://arxiv.org/abs/2504.19676v1","title":"Exploring binary intermetallics for advanced interconnect applications\n  using ab initio simulations","summary":"The challenge of increasing copper (Cu) resistivity with diminishing Cu\ninterconnect dimensions in complementary metal-oxide-semiconductor (CMOS)\ntransistors, along with the imperative for efficient electron transport paths\nto fulfill scaling requirements in interconnects is significant.\nFirst-principles electronic structures calculations based on density functional\ntheory have been performed to evaluate the potential scalability of some Cu,\nAl, Ru and Mo based binary alloys to replace Cu. We evaluate the expected\nsensitivity of the resistivity of these binary alloys to reduced line\ndimensions with a figure of merit that is based on generalized\nfinite-temperature transport tensors. These transport tensors allow for a\nstraightforward comparison between highly anisotropic intermetallics with given\ntransport directions and Cu, and are evaluated together with their resistance\nto electromigration. Based on the figure-of-merit analysis, we identify several\naluminides that show potential to outperform Cu at reduced interconnect\ndimensions in terms of their electronic transport and reliability properties.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-28T11:05:30Z"}
{"aid":"http://arxiv.org/abs/2504.19677v1","title":"A Polynomial-Time Inner Approximation Algorithm for Multi-Objective\n  Optimization","summary":"In multi-objective optimization, the problem of finding all non-dominated\nimages is often intractable. However, for any multiplicative factor greater\nthan one, an approximation set can be constructed in polynomial time for many\nproblems. In this paper, we use the concept of convex approximation sets: Each\nnon-dominated image is approximated by a convex combination of images of\nsolutions in such a set. Recently, Helfrich et al. (2024) presented a convex\napproximation algorithm that works in an adaptive fashion and outperforms all\npreviously existing algorithms. We use a different approach for constructing an\neven more efficient adaptive algorithm for computing convex approximation sets.\nOur algorithm is based on the skeleton algorithm for polyhedral inner\napproximation by Csirmaz (2021). If the weighted sum scalarization can be\nsolved exactly or approximately in polynomial time, our algorithm can find a\nconvex approximation set for an approximation factor arbitrarily close to this\nsolution quality. We demonstrate that our new algorithm significantly\noutperforms the current state-of-the-art algorithm from Helfrich et al. (2024)\non instances of the multi-objective variants of the assignment problem, the\nknapsack problem, and the symmetric metric travelling salesman problem.","main_category":"math.OC","categories":"math.OC","published":"2025-04-28T11:08:21Z"}
{"aid":"http://arxiv.org/abs/2504.19721v1","title":"Morse homology for a class of elliptic partial differential equations","summary":"In this paper we show that a notion of non-degeneracy which allows to develop\nMorse theory is generically satisfied for a large class of $C^2$-functionals\ndefined on Banach spaces. The main element of novelty with respect to the\nprevious work of the first and third author is that we do not assume the\nsplitting induced by the second differential at a critical point to persist in\na neighborhood, provided one can give precise estimates on how much persistence\nfails. This allows us to enlarge significantly the class of elliptic pde's for\nwhich non-degeneracy holds and Morse homology can be defined. A concrete\nexample is given by equations involving the $p$-Laplacian, $p\\leq n$. As a\nbyproduct, we provide a criterion of independent interest to check whether\ncritical points are non-degenerate in the sense above, and give an abstract\nconstruction of Morse homology in a Banach setting for functionals satisfying\nthe Cerami condition.","main_category":"math.AP","categories":"math.AP,math.DG","published":"2025-04-28T12:14:45Z"}
{"aid":"http://arxiv.org/abs/2504.19730v1","title":"Evaluate-and-Purify: Fortifying Code Language Models Against Adversarial\n  Attacks Using LLM-as-a-Judge","summary":"The widespread adoption of code language models in software engineering tasks\nhas exposed vulnerabilities to adversarial attacks, especially the identifier\nsubstitution attacks. Although existing identifier substitution attackers\ndemonstrate high success rates, they often produce adversarial examples with\nunnatural code patterns. In this paper, we systematically assess the quality of\nadversarial examples using LLM-as-a-Judge. Our analysis reveals that over 80%\nof adversarial examples generated by state-of-the-art identifier substitution\nattackers (e.g., ALERT) are actually detectable. Based on this insight, we\npropose EP-Shield, a unified framework for evaluating and purifying identifier\nsubstitution attacks via naturalness-aware reasoning. Specifically, we first\nevaluate the naturalness of code and identify the perturbed adversarial code,\nthen purify it so that the victim model can restore correct prediction.\nExtensive experiments demonstrate the superiority of EP-Shield over adversarial\nfine-tuning (up to 83.36% improvement) and its lightweight design 7B\nparameters) with GPT-4-level performance.","main_category":"cs.SE","categories":"cs.SE,cs.CL","published":"2025-04-28T12:28:55Z"}
{"aid":"http://arxiv.org/abs/2504.19738v1","title":"Learning Efficiency Meets Symmetry Breaking","summary":"Learning-based planners leveraging Graph Neural Networks can learn search\nguidance applicable to large search spaces, yet their potential to address\nsymmetries remains largely unexplored. In this paper, we introduce a graph\nrepresentation of planning problems allying learning efficiency with the\nability to detect symmetries, along with two pruning methods, action pruning\nand state pruning, designed to manage symmetries during search. The integration\nof these techniques into Fast Downward achieves a first-time success over LAMA\non the latest IPC learning track dataset. Code is released at:\nhttps://github.com/bybeye/Distincter.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-28T12:33:39Z"}
{"aid":"http://arxiv.org/abs/2504.19763v1","title":"On Commutative Analogues of Clifford Algebras and Their Decompositions","summary":"We investigate commutative analogues of Clifford algebras - algebras whose\ngenerators square to $\\pm1$ but commute, instead of anti-commuting as they do\nin Clifford algebras. We observe that commutativity allows for elegant results.\nWe note that these algebras generalise multicomplex spaces - we show that a\ncommutative analogue of Clifford algebra are either isomorphic to a\nmulticomplex space or to `multi split-complex space' (space defined just like\nmulticomplex numbers but uses split-complex numbers instead of complex\nnumbers). We do a general study of commutative analogues of Clifford algebras\nand use tools like operations of conjugation and idempotents to give a tensor\nproduct decomposition and a direct sum decomposition for them. Tensor product\ndecomposition follows relatively easily from the definition. For the direct sum\ndecomposition, we give explicit basis using new techniques.","main_category":"math.RA","categories":"math.RA,math.AC","published":"2025-04-28T13:01:44Z"}
{"aid":"http://arxiv.org/abs/2504.19779v1","title":"Learning Brenier Potentials with Convex Generative Adversarial Neural\n  Networks","summary":"Brenier proved that under certain conditions on a source and a target\nprobability measure there exists a strictly convex function such that its\ngradient is a transport map from the source to the target distribution. This\nfunction is called the Brenier potential. Furthermore, detailed information on\nthe H\\\"older regularity of the Brenier potential is available. In this work we\ndevelop the statistical learning theory of generative adversarial neural\nnetworks that learn the Brenier potential. As by the transformation of\ndensities formula, the density of the generated measure depends on the second\nderivative of the Brenier potential, we develop the universal approximation\ntheory of ReCU networks with cubic activation $\\mathtt{ReCU}(x)=\\max\\{0,x\\}^3$\nthat combines the favorable approximation properties of H\\\"older functions with\na Lipschitz continuous density. In order to assure the convexity of such\ngeneral networks, we introduce an adversarial training procedure for a\npotential function represented by the ReCU networks that combines the classical\ndiscriminator cross entropy loss with a penalty term that enforces (strict)\nconvexity. We give a detailed decomposition of learning errors and show that\nfor a suitable high penalty parameter all networks chosen in the adversarial\nmin-max optimization problem are strictly convex. This is further exploited to\nprove the consistency of the learning procedure for (slowly) expanding network\ncapacity. We also implement the described learning algorithm and apply it to a\nnumber of standard test cases from Gaussian mixture to image data as target\ndistributions. As predicted in theory, we observe that the convexity loss\nbecomes inactive during the training process and the potentials represented by\nthe neural networks have learned convexity.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-28T13:24:52Z"}
{"aid":"http://arxiv.org/abs/2504.19801v1","title":"Stochastic quantum adiabatic algorithm with fractional Brownian motion","summary":"Adiabatic Quantum Computing relies on the quantum adiabatic theorem, which\nstates that a quantum system evolves along its ground state with time if the\ngoverning Hamiltonian varies infinitely slowly. However, practical limitations\nforce computations to be performed within limited times, exposing the system to\ntransitions into excited states, and thereby reducing the success probability.\nHere we investigate the counterintuitive hypothesis that incorporating\nstochastic noise, specifically noise driven by fractional Brownian motion, in a\nnon-Markovian setup can enhance the performance of adiabatic quantum computing\nby improving its success probability at limited evolution times. The study\nbegins by developing the mathematical framework to introduce stochastic noise\nmultiplicatively into the Schr\\\"{o}dinger equation, resulting in a stochastic\nSchr\\\"{o}dinger equation. To preserve It\\^{o} integrability within the\nnon-Markovian framework, a semimartingale approximation for fractional Brownian\nmotion is employed. We perform numerical simulations to compare the performance\nof the quantum adiabatic algorithm with and without noise driven by fractional\nBrownian motion using the NP-complete Exact Cover-3 problem, transformed into\nthe Ising model. Our results exhibit an improvement in success probability in\nthe presence of noise driven by fractional Brownian motion with Hurst parameter\n$0<H<\\frac{1}{2}$ and an increase in speedup as $H$ approaches 0. Although\nsimulations are limited to problems involving a modest number of qubits,\nevidence suggests that the proposed approach scales favorably with the system\nsize.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-28T13:51:16Z"}
{"aid":"http://arxiv.org/abs/2504.19803v1","title":"Unconventional Relaxation Dynamics in Co_8Zn_7Mn_5 and Co_8Zn_8Mn_4:\n  Evidence of Inertial Effects","summary":"Magnetization relaxation dynamics serve as an essential tool for uncovering\nthe intrinsic mechanisms governing the magnetic response and energy dissipation\nin magnetic systems. In this work, we examine the relaxation dynamics for Beta\nMn type Co_8Zn_7Mn_5 and Co_8Zn_8Mn_4 across a frequency range of 1 kHz to 10\nkHz, spanning different magnetic phases. While most magnetic systems tend to\nfollow the Debye-like relaxation with non-zero distribution or the Cole-Cole\nformalism, our analysis reveal that these conventional models fail to capture\nfrequency dependence of ac susceptibility across different magnetic phases in\nCo_8Zn_7Mn_5 and Co_8Zn_8Mn_4. Instead, an inertial component is needed to\nsuccessfully describe the dynamics, suggesting the presence of unconventional\nrelaxation behavior. The characteristic relaxation time is found to be of the\norder of 10^-5 s for both the compositions. The field dependent variation of\nrelaxation time exhibits a non-monotonic nature, with the double peak like\nstructure at the skyrmion phase transitions, implying slower relaxation\ndynamics at the phase boundaries. Furthermore, the presence of non-zero\ndifference between isothermal and adiabatic susceptibility in the pure phases\nimplies slower relaxation dynamics, which is consistent with the presence of\nfinite dissipation in pure phases. The inertial term has been previously\ninvoked to describe the dynamics in spin ice systems due to the propagation of\nmagnetic monopoles. However, its necessity in this system, points to a wider\nsignificance in magnetization dynamics that goes beyond the conventional spin\nices and skyrmions.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.other,cond-mat.str-el,quant-ph","published":"2025-04-28T13:55:27Z"}
{"aid":"http://arxiv.org/abs/2504.19839v1","title":"SRMF: A Data Augmentation and Multimodal Fusion Approach for Long-Tail\n  UHR Satellite Image Segmentation","summary":"The long-tail problem presents a significant challenge to the advancement of\nsemantic segmentation in ultra-high-resolution (UHR) satellite imagery. While\nprevious efforts in UHR semantic segmentation have largely focused on\nmulti-branch network architectures that emphasize multi-scale feature\nextraction and fusion, they have often overlooked the importance of addressing\nthe long-tail issue. In contrast to prior UHR methods that focused on\nindependent feature extraction, we emphasize data augmentation and multimodal\nfeature fusion to alleviate the long-tail problem. In this paper, we introduce\nSRMF, a novel framework for semantic segmentation in UHR satellite imagery. Our\napproach addresses the long-tail class distribution by incorporating a\nmulti-scale cropping technique alongside a data augmentation strategy based on\nsemantic reordering and resampling. To further enhance model performance, we\npropose a multimodal fusion-based general representation knowledge injection\nmethod, which, for the first time, fuses text and visual features without the\nneed for individual region text descriptions, extracting more robust features.\nExtensive experiments on the URUR, GID, and FBP datasets demonstrate that our\nmethod improves mIoU by 3.33\\%, 0.66\\%, and 0.98\\%, respectively, achieving\nstate-of-the-art performance. Code is available at:\nhttps://github.com/BinSpa/SRMF.git.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-28T14:39:59Z"}
{"aid":"http://arxiv.org/abs/2504.19868v1","title":"exoALMA XI: ALMA Observations and Hydrodynamic Models of LkCa 15:\n  Implications for Planetary Mass Companions in the Dust Continuum Cavity","summary":"In the past decade, the Atacama Large Millimeter/submillimeter Array (ALMA)\nhas revealed a plethora of substructures in the disks surrounding young stars.\nThese substructures have several proposed formation mechanisms, with one\nleading theory being the interaction between the disk and newly formed planets.\nIn this Letter, we present high angular resolution ALMA observations of\nLkCa~15's disk that reveal a striking difference in dust and CO emission\nmorphology. The dust continuum emission shows a ring-like structure\ncharacterized by a dust-depleted inner region of $\\sim$40 au in radius.\nConversely, the CO emission is radially smoother and shows no sign of gas\ndepletion within the dust cavity. We compare the observations with models for\nthe disk-planet interaction, including radiative transfer calculation in the\ndust and CO emission. This source is particularly interesting as the presence\nof massive planets within the dust cavity has been suggested based on previous\nNIR observations. We find that the level of CO emission observed within the\ndust cavity is inconsistent with the presence of planets more massive than\nJupiter orbiting between 10-40 au. Instead, we argue that the LkCa~15 innermost\ndust cavity might be created either by a chain of low-mass planets, or by other\nprocesses that do not require the presence of planets.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-04-28T15:01:13Z"}
{"aid":"http://arxiv.org/abs/2504.19875v1","title":"Fiber laser based stimulated Raman photothermal microscopy with long\n  working distance optics","summary":"Stimulated Raman scattering (SRS) microscopy is a highly sensitive chemical\nimaging technique. However, the broader application of SRS has been limited by\ntwo key challenges: the reliance on low-noise but bulky solid-state laser\nsources and stringent sample requirements necessitated by high numerical\naperture (NA) optics. Here, we present a fiber laser based stimulated Raman\nphotothermal (SRP) microscope that addresses these limitations. While\nappreciating the portability and compactness of a noisy source, fiber laser SRP\nenables a two-order-of-magnitude improvement in signal to noise ratio over\nfiber laser SRS without balance detection. Furthermore, with the use of low NA,\nlong working distance optics for signal collection, SRP expands the allowed\nsample space from millimeters to centimeters, which diversifies the sample\nformats to multi-well plates and thick tissues. The sensitivity and imaging\ndepth are further amplified by using urea for both thermal enhancement and\ntissue clearance. Together, fiber laser SRP microscopy provides a robust,\nuser-friendly platform for diverse applications.","main_category":"physics.optics","categories":"physics.optics,physics.ins-det","published":"2025-04-28T15:05:58Z"}
{"aid":"http://arxiv.org/abs/2504.19887v1","title":"Planar Coulomb gas on a Jordan arc at any temperature","summary":"We study a planar Coulomb gas confined to a sufficiently smooth Jordan arc\n$\\gamma$ in the complex plane, at inverse temperature $\\beta > 0$. Let\n\\[\\bar{Z}_{n}^\\beta(\\gamma) = Z_{n}^\\beta(\\gamma)/\\left(2\n\\textrm{cap}(\\gamma)\\right)^{\\beta n^2/2+(1-\\beta/2)n}\\] be the normalized\npartition function. We compute the free energy as the number of particles tends\nto infinity, including the constant term: \\[ \\lim_{n\\to \\infty}\\log\n\\frac{\\bar{Z}_{n}^\\beta(\\gamma)}{\\bar{Z}_{n}^\\beta([-1,1])} =\n\\frac{1}{24}J^A(\\gamma) + \\frac{1}{8} \\left( \\sqrt{ \\frac{\\beta}{2} } - \\sqrt{\n\\frac{2}{\\beta}} \\right)^2 J^{F}(\\gamma). \\] Here $\\bar{Z}_{n}^\\beta([-1,1])$\nis an explicit Selberg integral, $J^A(\\gamma)$ is half the Loewner energy of a\ncertain Jordan curve associated to $\\gamma$ plus a covariance term, and\n$J^F(\\gamma)$ is the Fekete energy, related to the zero temperature limit of\nthe model.\n  We also prove an asymptotic formula for the Laplace transform of linear\nstatistics for sufficiently regular test functions. As a consequence, the\ncentered empirical measure converges to a Gaussian field with explicit\nasymptotic mean, and asymptotic variance given by the Dirichlet energy of the\nbounded harmonic extension of the test function outside of the arc.\n  A key tool in our analysis is the arc-Grunsky operator $B$ associated to\n$\\gamma$, reminiscent to but different from the classical Grunsky operator. We\nderive several basic properties the arc-Grunsky operator, including an estimate\nanalogous to the strengthened Grunsky inequality and the relation to the\nDirichlet integral. In our proofs $J^A(\\gamma)$ arises from the Fredholm\ndeterminant $\\det(I+B)$ and a substantial part of the paper is devoted to\nrelating this to the Loewner energy.","main_category":"math.CV","categories":"math.CV,math.PR","published":"2025-04-28T15:19:09Z"}
{"aid":"http://arxiv.org/abs/2504.19897v1","title":"The Dust Echo Emission of Fast Blue Optical Transients and Application\n  to the Near-Infrared Excess of AT 2018cow","summary":"A near-infrared (NIR) excess has been discovered in the emission of the\nrepresentative fast blue optical transient (FBOT): AT 2018cow. It was suggested\nthat this NIR excess could be emitted by the dust surrounding the source and,\nthus, could provide a probe into the nature of its progenitor. We develop a\nmodel to describe the influence of the FBOT emission on the environmental dust\nand, as a result, a dust-free evaporation cavity can be formed on a timescale\nof one day. Outside this cavity, the surviving dust grains can have different\nsize distributions at different distances to the source. With such a special\ndust environment, we fit the multi-wavelength light curves of AT 2018cow by\ntaking into account the evolutionary dust echo of the FBOT emission. It is\nfound that the dust temperature can vary with time along with the evolution of\nthe irradiating FBOT emission. Even at a fixed time, the dust temperature can\nbe distributed in a wide range rather than having only a unique value.\nFurthermore, both the mass of the dust shell and its distance to the FBOT are\nfound to be much larger than those derived with a direct empirical fitting of\nthe NIR spectra but without considering the evolutionary relationship between\nthe spectra.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.SR","published":"2025-04-28T15:28:44Z"}
{"aid":"http://arxiv.org/abs/2504.19902v1","title":"exoALMA V: Gaseous Emission Surfaces and Temperature Structures","summary":"Analysis of the gaseous component in protoplanetary disks can inform us about\ntheir thermal and physical structure, chemical composition, and kinematic\nproperties, all of which are crucial for understanding various processes within\nthe disks. By exploiting the asymmetry of the line emission, or via line\nprofile analysis, we can locate the emitting surfaces. Here, we present the\nemission surfaces of the exoALMA sources in $^{12}$CO $J=3-2$, $^{13}$CO\n$J=3-2$, and CS $J=7-6$. We find that $^{12}$CO traces the upper disk\natmosphere, with mean <$z/r$> values of $\\approx$ 0.28, while $^{13}$CO and CS\ntrace lower regions of the disk with mean <z/r> values of $\\approx$ 0.16 and\n$\\approx$ 0.18, respectively. We find that $^{12}$CO <$z/r$> and the disk mass\nare positively correlated with each other; this relationship offers a\nstraightforward way to infer the disk mass. We derive 2-D $r-z$ temperature\ndistributions of the disks. Additionally, we search for substructure in the\nsurfaces and radial intensity profiles; we find evidence of localized\nsubstructure in the emission surfaces and peak intensity profiles of nearly\nevery disk, with this substructure often being co-incident between molecular\ntracers, intensity profiles, and kinematic perturbations. Four disks display\nevidence of potential photo-desorption, implying that this effect may be common\neven in low FUV star-forming regions. For most disks, we find that the physical\nand thermal structure is more complex than analytical models can account for,\nhighlighting a need for more theoretical work and a better understanding of the\nrole of projection effects on our observations.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-28T15:33:15Z"}
{"aid":"http://arxiv.org/abs/2504.19920v1","title":"Gravitational lensing by $k-n$ generalized black-bounce space-times","summary":"We study gravitational lensing by $k-n$ generalized black-bounce space-times\nboth in regimes of weak and strong field approximations. These metrics\ninterpolate between regular black holes and one-way or traversable wormholes.\nFirst, we investigate the light-like geodesic trajectories and derive an\nanalytical expression for the deflection angle in terms of the bounce parameter\nin the weak-field gravitational regime. We then turn to the strong-field\ngravitational regime and display the behavior of the bending angle as a\nfunction of both the impact parameter and the bounce parameter. Next, using the\nlens equations, we analyze how the observables for \\textit{Sagittarius} A*\nbehave concerning the bounce parameter. We obtain the shadow's radii for some\nblack-bounce metrics and plot the graph of their sizes, comparing them with the\nSchwarzschild one.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-28T15:50:36Z"}
{"aid":"http://arxiv.org/abs/2504.19925v1","title":"Accelerating Mixture-of-Experts Training with Adaptive Expert\n  Replication","summary":"Mixture-of-Experts (MoE) models have become a widely adopted solution to\ncontinue scaling model sizes without a corresponding linear increase in\ncompute. During MoE model training, each input token is dynamically routed to a\nsubset of experts -- sparsely-activated feed-forward networks -- within each\ntransformer layer. The distribution of tokens assigned to each expert varies\nwidely and rapidly over the course of training. To handle the wide load\nimbalance across experts, current systems are forced to either drop tokens\nassigned to popular experts, degrading convergence, or frequently rebalance\nresources allocated to each expert based on popularity, incurring high state\nmigration overheads.\n  To break this performance-accuracy tradeoff, we introduce SwiftMoE, an\nadaptive MoE training system. The key insight of SwiftMoE is to decouple the\nplacement of expert parameters from their large optimizer state. SwiftMoE\nstatically partitions the optimizer of each expert across all training nodes.\nMeanwhile, SwiftMoE dynamically adjusts the placement of expert parameters by\nrepurposing existing weight updates, avoiding migration overheads. In doing so,\nSwiftMoE right-sizes the GPU resources allocated to each expert, on a\nper-iteration basis, with minimal overheads. Compared to state-of-the-art MoE\ntraining systems, DeepSpeed and FlexMoE, SwiftMoE is able to achieve a 30.5%\nand 25.9% faster time-to-convergence, respectively.","main_category":"cs.DC","categories":"cs.DC,cs.LG","published":"2025-04-28T15:58:55Z"}
{"aid":"http://arxiv.org/abs/2504.19938v1","title":"Mesh-Learner: Texturing Mesh with Spherical Harmonics","summary":"In this paper, we present a 3D reconstruction and rendering framework termed\nMesh-Learner that is natively compatible with traditional rasterization\npipelines. It integrates mesh and spherical harmonic (SH) texture (i.e.,\ntexture filled with SH coefficients) into the learning process to learn each\nmesh s view-dependent radiance end-to-end. Images are rendered by interpolating\nsurrounding SH Texels at each pixel s sampling point using a novel\ninterpolation method. Conversely, gradients from each pixel are back-propagated\nto the related SH Texels in SH textures. Mesh-Learner exploits graphic features\nof rasterization pipeline (texture sampling, deferred rendering) to render,\nwhich makes Mesh-Learner naturally compatible with tools (e.g., Blender) and\ntasks (e.g., 3D reconstruction, scene rendering, reinforcement learning for\nrobotics) that are based on rasterization pipelines. Our system can train vast,\nunlimited scenes because we transfer only the SH textures within the frustum to\nthe GPU for training. At other times, the SH textures are stored in CPU RAM,\nwhich results in moderate GPU memory usage. The rendering results on\ninterpolation and extrapolation sequences in the Replica and FAST-LIVO2\ndatasets achieve state-of-the-art performance compared to existing\nstate-of-the-art methods (e.g., 3D Gaussian Splatting and M2-Mapping). To\nbenefit the society, the code will be available at\nhttps://github.com/hku-mars/Mesh-Learner.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-28T16:09:25Z"}
{"aid":"http://arxiv.org/abs/2504.19944v1","title":"Probabilistic and Causal Satisfiability: Constraining the Model","summary":"We study the complexity of satisfiability problems in probabilistic and\ncausal reasoning. Given random variables $X_1, X_2,\\ldots$ over finite domains,\nthe basic terms are probabilities of propositional formulas over atomic events\n$X_i = x_i$, such as $P(X_1 = x_1)$ or $P(X_1 = x_1 \\vee X_2 = x_2)$. The basic\nterms can be combined using addition (yielding linear terms) or multiplication\n(polynomial terms). The probabilistic satisfiability problem asks whether a\njoint probability distribution satisfies a Boolean combination of\n(in)equalities over such terms. Fagin et al. (1990) showed that for basic and\nlinear terms, this problem is NP-complete, making it no harder than Boolean\nsatisfiability, while Moss\\'e et al. (2022) proved that for polynomial terms,\nit is complete for the existential theory of the reals.\n  Pearl's Causal Hierarchy (PCH) extends the probabilistic setting with\ninterventional and counterfactual reasoning, enriching the expressiveness of\nlanguages. However, Moss\\'e et al. (2022) found that satisfiability complexity\nremains unchanged. Van der Zander et al. (2023) showed that introducing a\nmarginalization operator to languages induces a significant increase in\ncomplexity.\n  We extend this line of work by adding two new dimensions to the problem by\nconstraining the models. First, we fix the graph structure of the underlying\nstructural causal model, motivated by settings like Pearl's do-calculus, and\ngive a nearly complete landscape across different arithmetics and PCH levels.\nSecond, we study small models. While earlier work showed that satisfiable\ninstances admit polynomial-size models, this is no longer guaranteed with\ncompact marginalization. We characterize the complexities of satisfiability\nunder small-model constraints across different settings.","main_category":"cs.CC","categories":"cs.CC,cs.AI,cs.LO","published":"2025-04-28T16:14:06Z"}
{"aid":"http://arxiv.org/abs/2504.19955v1","title":"Robust Federated Personalised Mean Estimation for the Gaussian Mixture\n  Model","summary":"Federated learning with heterogeneous data and personalization has received\nsignificant recent attention. Separately, robustness to corrupted data in the\ncontext of federated learning has also been studied. In this paper we explore\ncombining personalization for heterogeneous data with robustness, where a\nconstant fraction of the clients are corrupted. Motivated by this broad\nproblem, we formulate a simple instantiation which captures some of its\ndifficulty. We focus on the specific problem of personalized mean estimation\nwhere the data is drawn from a Gaussian mixture model. We give an algorithm\nwhose error depends almost linearly on the ratio of corrupted to uncorrupted\nsamples, and show a lower bound with the same behavior, albeit with a gap of a\nconstant factor.","main_category":"cs.LG","categories":"cs.LG,cs.IT,math.IT","published":"2025-04-28T16:24:54Z"}
{"aid":"http://arxiv.org/abs/2504.19963v1","title":"Stochastic Subspace via Probabilistic Principal Component Analysis for\n  Characterizing Model Error","summary":"This paper proposes a probabilistic model of subspaces based on the\nprobabilistic principal component analysis (PCA). Given a sample of vectors in\nthe embedding space -- commonly known as a snapshot matrix -- this method uses\nquantities derived from the probabilistic PCA to construct distributions of the\nsample matrix, as well as the principal subspaces. It is applicable to\nprojection-based reduced-order modeling methods, such as proper orthogonal\ndecomposition and related model reduction methods. The stochastic subspace thus\nconstructed can be used, for example, to characterize model-form uncertainty in\ncomputational mechanics. The proposed method has multiple desirable properties:\n(1) it is naturally justified by the probabilistic PCA and has analytic forms\nfor the induced random matrix models; (2) it satisfies linear constraints, such\nas boundary conditions of all kinds, by default; (3) it has only one\nhyperparameter, which significantly simplifies training; and (4) its algorithm\nis very easy to implement. We compare the proposed method with existing\napproaches in a low-dimensional visualization example and a parametric static\nproblem, and demonstrate its performance in a dynamics model of a space\nstructure.","main_category":"cs.CE","categories":"cs.CE,math.ST,physics.comp-ph,physics.data-an,stat.ME,stat.TH","published":"2025-04-28T16:35:01Z"}
{"aid":"http://arxiv.org/abs/2504.19980v1","title":"Deep Declarative Risk Budgeting Portfolios","summary":"Recent advances in deep learning have spurred the development of end-to-end\nframeworks for portfolio optimization that utilize implicit layers. However,\nmany such implementations are highly sensitive to neural network\ninitialization, undermining performance consistency. This research introduces a\nrobust end-to-end framework tailored for risk budgeting portfolios that\neffectively reduces sensitivity to initialization. Importantly, this enhanced\nstability does not compromise portfolio performance, as our framework\nconsistently outperforms the risk parity benchmark.","main_category":"q-fin.PM","categories":"q-fin.PM,q-fin.CP","published":"2025-04-28T16:53:13Z"}
{"aid":"http://arxiv.org/abs/2504.20030v1","title":"Allele trees for the mother-dependent neutral mutations model and their\n  scaling limits in the rare mutations regime","summary":"The mother-dependent neutral mutations model describes the evolution of a\npopulation across discrete generations, where neutral mutations occur among a\nfinite set of possible alleles. In this model, each mutant child acquires a\ntype different from that of its mother, chosen uniformly at random. In this\nwork, we define a multitype allele tree associated with this model and analyze\nits scaling limit through a Markov chain that tracks the sizes of allelic\nsubfamilies and their mutant descendants. We show that this Markov chain\nconverges to a continuous-state Markov process, whose transition probabilities\ndepend on the sizes of the initial allelic populations and those of their\nmutant offspring in the first allelic generation. As a result, the allele tree\nconverges to a multidimensional limiting object, which can be described in\nterms of the universal allele tree introduced by Bertoin (2010).","main_category":"math.PR","categories":"math.PR","published":"2025-04-28T17:54:02Z"}
{"aid":"http://arxiv.org/abs/2504.20046v1","title":"On the Properties of Cosmological Ionization Fronts","summary":"We investigate the properties of cosmological ionization fronts during the\nEpoch of Reionization using the CROC simulations. By analyzing reionization\ntiming maps, we characterize ionization front velocities and curvatures and\ntheir dependence on the density structure of the intergalactic medium (IGM).\nThe velocity distribution of ionization fronts in the simulations indicates\nthat while the barrier-crossing analytical model captures the overall shape in\nhigh-velocity regions, it fails to reproduce the low-velocity tail,\nhighlighting the non-Gaussian nature of the IGM's density field. Ionization\nfront velocities are inversely correlated with local density, propagating\nfaster in underdense regions and more slowly in overdense environments. Faster\nionization fronts also lead to higher post-ionization temperatures, reaching a\nplateau at $\\sim 2 \\times 10^4$ K for velocities exceeding 3000 km/s. Examining\ncurvature statistics further establishes a connection between ionization front\nstructure and the normalized density contrast $\\nu$, with trends in overdense\nregions aligning well with barrier-crossing model predictions, while deviations\nappear in underdense environments due to model limitations. These results\nprovide a detailed characterization of ionization front dynamics and their\ninteraction with the underlying density field, bridging small-scale\nreionization physics with large-scale observables such as the 21 cm signal and\nthe IGM's thermal history.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-28T17:59:59Z"}
{"aid":"http://arxiv.org/abs/2504.20388v1","title":"The two-clock problem in population dynamics","summary":"Biological time can be measured in two ways: in generations and in physical\ntime. When generation intervals differ between individuals, these two clocks\ndiverge, which impedes our ability to relate mathematical models to real\npopulations. In this paper we show that nevertheless, these disparate clocks\nbecome equivalent in the long run via a simple identity relating generational\nand physical time. This equivalence allows us to directly translate statements\nfrom mathematical models to the physical world and vice versa. As an\napplication, we obtain a generalized Euler-Lotka equation linking the basic\nreproduction number $R_0$ to the growth rate, and derive several\ninformation-theoretic bounds on these quantities. We also show how the fitness\nof a lineage can be defined consistently in population models, with\napplications to microbial growth, epidemiology and population biology.","main_category":"q-bio.PE","categories":"q-bio.PE,physics.bio-ph","published":"2025-04-29T03:15:23Z"}
{"aid":"http://arxiv.org/abs/2504.20425v1","title":"Metaheuristic Optimization of Trajectory and Dynamic Time Splitting for\n  UAV Communication Systems","summary":"The integration of unmanned aerial vehicles (UAVs) into wireless\ncommunication systems has emerged as a transformative approach, promising\ncost-efficient connectivity. This paper addresses the optimization of the\ndynamic time-splitting ratio and flight trajectory for a communication system\nlinking a ground base station to the UAV equipped with backscatter devices\n(referred to as UB), and from UB to an end user. Given the inherent\nnon-convexity of the problem, we develop two meta-heuristic-based approaches\ninspired by genetic algorithm and particle swarm optimization to enhance the\ntotal achievable rate while reducing computational complexity. Numerical\nresults demonstrate the effectiveness of these meta-heuristic solutions,\nshowcasing significant improvements in the achievable rate and computation time\ncompared to existing benchmarks.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-29T04:39:29Z"}
{"aid":"http://arxiv.org/abs/2504.20435v1","title":"AI Assisted Cervical Cancer Screening for Cytology Samples in Developing\n  Countries","summary":"Cervical cancer remains a significant health challenge, with high incidence\nand mortality rates, particularly in transitioning countries. Conventional\nLiquid-Based Cytology(LBC) is a labor-intensive process, requires expert\npathologists and is highly prone to errors, highlighting the need for more\nefficient screening methods. This paper introduces an innovative approach that\nintegrates low-cost biological microscopes with our simple and efficient AI\nalgorithms for automated whole-slide analysis. Our system uses a motorized\nmicroscope to capture cytology images, which are then processed through an AI\npipeline involving image stitching, cell segmentation, and classification. We\nutilize the lightweight UNet-based model involving human-in-the-loop approach\nto train our segmentation model with minimal ROIs. CvT-based classification\nmodel, trained on the SIPaKMeD dataset, accurately categorizes five cell types.\nOur framework offers enhanced accuracy and efficiency in cervical cancer\nscreening compared to various state-of-art methods, as demonstrated by\ndifferent evaluation metrics.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T05:18:59Z"}
{"aid":"http://arxiv.org/abs/2504.20482v1","title":"Group Relative Knowledge Distillation: Learning from Teacher's\n  Relational Inductive Bias","summary":"Knowledge distillation typically transfers knowledge from a teacher model to\na student model by minimizing differences between their output distributions.\nHowever, existing distillation approaches largely focus on mimicking absolute\nprobabilities and neglect the valuable relational inductive biases embedded in\nthe teacher's relative predictions, leading to exposure bias. In this paper, we\npropose Group Relative Knowledge Distillation (GRKD), a novel framework that\ndistills teacher knowledge by learning the relative ranking among classes,\nrather than directly fitting the absolute distribution. Specifically, we\nintroduce a group relative loss that encourages the student model to preserve\nthe pairwise preference orderings provided by the teacher's outputs. Extensive\nexperiments on classification benchmarks demonstrate that GRKD achieves\nsuperior generalization compared to existing methods, especially in tasks\nrequiring fine-grained class differentiation. Our method provides a new\nperspective on exploiting teacher knowledge, focusing on relational structure\nrather than absolute likelihood.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-29T07:23:22Z"}
{"aid":"http://arxiv.org/abs/2504.20506v1","title":"SPARK Hand: Scooping-Pinching Adaptive Robotic Hand with Kempe Mechanism\n  for Vertical Passive Grasp in Environmental Constraints","summary":"This paper presents the SPARK finger, an innovative passive adaptive robotic\nfinger capable of executing both parallel pinching and scooping grasps. The\nSPARK finger incorporates a multi-link mechanism with Kempe linkages to achieve\na vertical linear fingertip trajectory. Furthermore, a parallelogram linkage\nensures the fingertip maintains a fixed orientation relative to the base,\nfacilitating precise and stable manipulation. By integrating these mechanisms\nwith elastic elements, the design enables effective interaction with surfaces,\nsuch as tabletops, to handle challenging objects. The finger employs a passive\nswitching mechanism that facilitates seamless transitions between pinching and\nscooping modes, adapting automatically to various object shapes and\nenvironmental constraints without additional actuators. To demonstrate its\nversatility, the SPARK Hand, equipped with two SPARK fingers, has been\ndeveloped. This system exhibits enhanced grasping performance and stability for\nobjects of diverse sizes and shapes, particularly thin and flat objects that\nare traditionally challenging for conventional grippers. Experimental results\nvalidate the effectiveness of the SPARK design, highlighting its potential for\nrobotic manipulation in constrained and dynamic environments.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-29T07:47:06Z"}
{"aid":"http://arxiv.org/abs/2504.20519v1","title":"Conversations with AI Chatbots Increase Short-Term Vaccine Intentions\n  But Do Not Outperform Standard Public Health Messaging","summary":"Large language model (LLM) based chatbots show promise in persuasive\ncommunication, but existing studies often rely on weak controls or focus on\nbelief change rather than behavioral intentions or outcomes. This\npre-registered multi-country (US, Canada, UK) randomized controlled trial\ninvolving 930 vaccine-hesitant parents evaluated brief (three-minute)\nmulti-turn conversations with LLM-based chatbots against standard public health\nmessaging approaches for increasing human papillomavirus (HPV) vaccine\nintentions for their children. Participants were randomly assigned to: (1) a\nweak control (no message), (2) a strong control reflecting the standard of care\n(reading official public health materials), or (3 and 4) one of two chatbot\nconditions. One chatbot was prompted to deliver short, conversational\nresponses, while the other used the model's default output style (longer with\nbullet points). While chatbot interactions significantly increased\nself-reported vaccination intent (by 7.1-10.3 points on a 100-point scale)\ncompared to no message, they did not outperform standard public health\nmaterials, with the conversational chatbot performing significantly worse.\nAdditionally, while the short-term effects of chatbot interactions faded during\na 15-day follow-up, the effects of public health material persisted relative to\nno message. These findings suggest that while LLMs can effectively shift\nvaccination intentions in the short-term, their incremental value over existing\npublic health communications is questionable, offering a more tempered view of\ntheir persuasive capabilities and highlighting the importance of integrating\nAI-driven tools alongside, rather than replacing, current public health\nstrategies.","main_category":"cs.CY","categories":"cs.CY,cs.HC","published":"2025-04-29T07:59:46Z"}
{"aid":"http://arxiv.org/abs/2504.20520v1","title":"PRISM: Projection-based Reward Integration for Scene-Aware\n  Real-to-Sim-to-Real Transfer with Few Demonstrations","summary":"Learning from few demonstrations to develop policies robust to variations in\nrobot initial positions and object poses is a problem of significant practical\ninterest in robotics. Compared to imitation learning, which often struggles to\ngeneralize from limited samples, reinforcement learning (RL) can autonomously\nexplore to obtain robust behaviors. Training RL agents through direct\ninteraction with the real world is often impractical and unsafe, while building\nsimulation environments requires extensive manual effort, such as designing\nscenes and crafting task-specific reward functions. To address these\nchallenges, we propose an integrated real-to-sim-to-real pipeline that\nconstructs simulation environments based on expert demonstrations by\nidentifying scene objects from images and retrieving their corresponding 3D\nmodels from existing libraries. We introduce a projection-based reward model\nfor RL policy training that is supervised by a vision-language model (VLM)\nusing human-guided object projection relationships as prompts, with the policy\nfurther fine-tuned using expert demonstrations. In general, our work focuses on\nthe construction of simulation environments and RL-based policy training,\nultimately enabling the deployment of reliable robotic control policies in\nreal-world scenarios.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-29T08:01:27Z"}
{"aid":"http://arxiv.org/abs/2504.20571v1","title":"Reinforcement Learning for Reasoning in Large Language Models with One\n  Training Example","summary":"We show that reinforcement learning with verifiable reward using one training\nexample (1-shot RLVR) is effective in incentivizing the math reasoning\ncapabilities of large language models (LLMs). Applying RLVR to the base model\nQwen2.5-Math-1.5B, we identify a single example that elevates model performance\non MATH500 from 36.0% to 73.6%, and improves the average performance across six\ncommon mathematical reasoning benchmarks from 17.6% to 35.7%. This result\nmatches the performance obtained using the 1.2k DeepScaleR subset (MATH500:\n73.6%, average: 35.9%), which includes the aforementioned example. Similar\nsubstantial improvements are observed across various models (Qwen2.5-Math-7B,\nLlama3.2-3B-Instruct, DeepSeek-R1-Distill-Qwen-1.5B), RL algorithms (GRPO and\nPPO), and different math examples (many of which yield approximately 30% or\ngreater improvement on MATH500 when employed as a single training example). In\naddition, we identify some interesting phenomena during 1-shot RLVR, including\ncross-domain generalization, increased frequency of self-reflection, and\nsustained test performance improvement even after the training accuracy has\nsaturated, a phenomenon we term post-saturation generalization. Moreover, we\nverify that the effectiveness of 1-shot RLVR primarily arises from the policy\ngradient loss, distinguishing it from the \"grokking\" phenomenon. We also show\nthe critical role of promoting exploration (e.g., by adding entropy loss with\nan appropriate coefficient) in 1-shot RLVR training. As a bonus, we observe\nthat applying entropy loss alone, without any outcome reward, significantly\nenhances Qwen2.5-Math-1.5B's performance on MATH500 by 27.4%. These findings\ncan inspire future work on RLVR data efficiency and encourage a re-examination\nof both recent progress and the underlying mechanisms in RLVR. Our code, model,\nand data are open source at https://github.com/ypwang61/One-Shot-RLVR","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-29T09:24:30Z"}
{"aid":"http://arxiv.org/abs/2504.20585v1","title":"Rigidity of Complete Free Boundary Minimal Hypersurfaces in Convex NNSC\n  Manifolds","summary":"We prove that in the unit ball of $\\mathbb{R}^4$, there is no complete\ntwo-sided stable free boundary immersion. The result follows from a rigidity\ntheorem of complete free boundary minimal hypersurfaces in complete 4-manifolds\nwith non-negative intermediate Ricci curvature, convex boundary and weakly\nbounded geometry. The method uses warped $\\theta$-bubble, a generalization of\ncapillary surfaces.","main_category":"math.DG","categories":"math.DG","published":"2025-04-29T09:40:13Z"}
{"aid":"http://arxiv.org/abs/2504.20595v1","title":"ReasonIR: Training Retrievers for Reasoning Tasks","summary":"We present ReasonIR-8B, the first retriever specifically trained for general\nreasoning tasks. Existing retrievers have shown limited gains on reasoning\ntasks, in part because existing training datasets focus on short factual\nqueries tied to documents that straightforwardly answer them. We develop a\nsynthetic data generation pipeline that, for each document, our pipeline\ncreates a challenging and relevant query, along with a plausibly related but\nultimately unhelpful hard negative. By training on a mixture of our synthetic\ndata and existing public data, ReasonIR-8B achieves a new state-of-the-art of\n29.9 nDCG@10 without reranker and 36.9 nDCG@10 with reranker on BRIGHT, a\nwidely-used reasoning-intensive information retrieval (IR) benchmark. When\napplied to RAG tasks, ReasonIR-8B improves MMLU and GPQA performance by 6.4%\nand 22.6% respectively, relative to the closed-book baseline, outperforming\nother retrievers and search engines. In addition, ReasonIR-8B uses test-time\ncompute more effectively: on BRIGHT, its performance consistently increases\nwith longer and more information-rich rewritten queries; it continues to\noutperform other retrievers when combined with an LLM reranker. Our training\nrecipe is general and can be easily extended to future LLMs; to this end, we\nopen-source our code, data, and model.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.IR,cs.LG","published":"2025-04-29T09:49:28Z"}
{"aid":"http://arxiv.org/abs/2504.20601v1","title":"How to turn a Supernova into a PeVatron","summary":"Context. It is important to determine which Galactic cosmic-ray sources can\naccelerate particles to the knee of the cosmic ray spectrum at a few PeV, and\nin particular whether supernova remnants may contribute. Current models for\nparticle acceleration in very young remnants assume the circumstellar material\nconsists of smooth, freely expanding winds. There is strong evidence that some\nsupernovae expand into much denser circumstellar material including dense\nshells ejected by eruptions shortly before explosion.\n  Aims. We investigate the effects of dense circumstellar shells on particle\nacceleration in supernova shocks during the first few years post-explosion, to\nquantify whether such interaction supernovae may act as PeVatrons.\n  Methods. We used the pion code to model the circumstellar medium around\nLuminous Blue Variables after having a brief episode with a mass-loss rate of\nup to dM/dt = 2Msol/yr. Consequently, we performed spherically symmetric 1-D\nsimulations using our time-dependent acceleration-code RATPaC in which we\nsimultaneously solve the transport equations for cosmic-rays, magnetic\nturbulence, and the hydrodynamical flow of the thermal plasma in the\ntest-particle limit.\n  Results. We find that the interaction with the circumstellar shells can\nsignificantly boost the maximum energy by enhancing particle escape during the\nonset of the shock-shell interaction followed by the reacceleration of the\nshock propagating into a medium with a pre-amplified field. Early interactions\nboost the maximum energy to a greater degree and interactions within the first\n5 months after explosion can increase Emax to more then 1 PeV.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-29T10:08:32Z"}
{"aid":"http://arxiv.org/abs/2504.20626v1","title":"A Novel Cipher for Enhancing MAVLink Security: Design, Security\n  Analysis, and Performance Evaluation Using a Drone Testbed","summary":"We present MAVShield, a novel lightweight cipher designed to secure\ncommunications in Unmanned Aerial Vehicles (UAVs) using the MAVLink protocol,\nwhich by default transmits unencrypted messages between UAVs and Ground Control\nStations (GCS). While existing studies propose encryption for MAVLink, most\nremain theoretical or simulation-based. We implement MAVShield alongside\nAES-CTR, ChaCha20, Speck-CTR, and Rabbit, and evaluate them on a real drone\ntestbed. A comprehensive security analysis using statistical test suites (NIST\nand Diehard) demonstrates strong resistance of the novel cipher to\ncryptanalysis. Performance evaluation across key metrics including memory\nusage, CPU load, and battery power consumption, demonstrates that MAVShield\noutperforms existing algorithms and offers an efficient, real-world solution\nfor securing MAVLink communications in UAVs.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-29T10:53:17Z"}
{"aid":"http://arxiv.org/abs/2504.20645v1","title":"LDPoly: Latent Diffusion for Polygonal Road Outline Extraction in\n  Large-Scale Topographic Mapping","summary":"Polygonal road outline extraction from high-resolution aerial images is an\nimportant task in large-scale topographic mapping, where roads are represented\nas vectorized polygons, capturing essential geometric features with minimal\nvertex redundancy. Despite its importance, no existing method has been\nexplicitly designed for this task. While polygonal building outline extraction\nhas been extensively studied, the unique characteristics of roads, such as\nbranching structures and topological connectivity, pose challenges to these\nmethods. To address this gap, we introduce LDPoly, the first dedicated\nframework for extracting polygonal road outlines from high-resolution aerial\nimages. Our method leverages a novel Dual-Latent Diffusion Model with a\nChannel-Embedded Fusion Module, enabling the model to simultaneously generate\nroad masks and vertex heatmaps. A tailored polygonization method is then\napplied to obtain accurate vectorized road polygons with minimal vertex\nredundancy. We evaluate LDPoly on a new benchmark dataset, Map2ImLas, which\ncontains detailed polygonal annotations for various topographic objects in\nseveral Dutch regions. Our experiments include both in-region and cross-region\nevaluations, with the latter designed to assess the model's generalization\nperformance on unseen regions. Quantitative and qualitative results demonstrate\nthat LDPoly outperforms state-of-the-art polygon extraction methods across\nvarious metrics, including pixel-level coverage, vertex efficiency, polygon\nregularity, and road connectivity. We also design two new metrics to assess\npolygon simplicity and boundary smoothness. Moreover, this work represents the\nfirst application of diffusion models for extracting precise vectorized object\noutlines without redundant vertices from remote-sensing imagery, paving the way\nfor future advancements in this field.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T11:13:33Z"}
{"aid":"http://arxiv.org/abs/2504.20651v1","title":"Learning and Generalization with Mixture Data","summary":"In many, if not most, machine learning applications the training data is\nnaturally heterogeneous (e.g. federated learning, adversarial attacks and\ndomain adaptation in neural net training). Data heterogeneity is identified as\none of the major challenges in modern day large-scale learning. A classical way\nto represent heterogeneous data is via a mixture model. In this paper, we study\ngeneralization performance and statistical rates when data is sampled from a\nmixture distribution. We first characterize the heterogeneity of the mixture in\nterms of the pairwise total variation distance of the sub-population\ndistributions. Thereafter, as a central theme of this paper, we characterize\nthe range where the mixture may be treated as a single (homogeneous)\ndistribution for learning. In particular, we study the generalization\nperformance under the classical PAC framework and the statistical error rates\nfor parametric (linear regression, mixture of hyperplanes) as well as\nnon-parametric (Lipschitz, convex and H\\\"older-smooth) regression problems. In\norder to do this, we obtain Rademacher complexity and (local) Gaussian\ncomplexity bounds with mixture data, and apply them to get the generalization\nand convergence rates respectively. We observe that as the (regression)\nfunction classes get more complex, the requirement on the pairwise total\nvariation distance gets stringent, which matches our intuition. We also do a\nfiner analysis for the case of mixed linear regression and provide a tight\nbound on the generalization error in terms of heterogeneity.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-29T11:21:15Z"}
{"aid":"http://arxiv.org/abs/2504.20656v1","title":"Federated learning, ethics, and the double black box problem in medical\n  AI","summary":"Federated learning (FL) is a machine learning approach that allows multiple\ndevices or institutions to collaboratively train a model without sharing their\nlocal data with a third-party. FL is considered a promising way to address\npatient privacy concerns in medical artificial intelligence. The ethical risks\nof medical FL systems themselves, however, have thus far been underexamined.\nThis paper aims to address this gap. We argue that medical FL presents a new\nvariety of opacity -- federation opacity -- that, in turn, generates a\ndistinctive double black box problem in healthcare AI. We highlight several\ninstances in which the anticipated benefits of medical FL may be exaggerated,\nand conclude by highlighting key challenges that must be overcome to make FL\nethically feasible in medicine.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CY,cs.HC","published":"2025-04-29T11:31:48Z"}
{"aid":"http://arxiv.org/abs/2504.20678v1","title":"Non-native Children's Automatic Speech Assessment Challenge (NOCASA)","summary":"This paper presents the \"Non-native Children's Automatic Speech Assessment\"\n(NOCASA) - a data competition part of the IEEE MLSP 2025 conference. NOCASA\nchallenges participants to develop new systems that can assess single-word\npronunciations of young second language (L2) learners as part of a gamified\npronunciation training app. To achieve this, several issues must be addressed,\nmost notably the limited nature of available training data and the highly\nunbalanced distribution among the pronunciation level categories. To expedite\nthe development, we provide a pseudo-anonymized training data (TeflonNorL2),\ncontaining 10,334 recordings from 44 speakers attempting to pronounce 205\ndistinct Norwegian words, human-rated on a 1 to 5 scale (number of stars that\nshould be given in the game). In addition to the data, two already trained\nsystems are released as official baselines: an SVM classifier trained on the\nComParE_16 acoustic feature set and a multi-task wav2vec 2.0 model. The latter\nachieves the best performance on the challenge test set, with an unweighted\naverage recall (UAR) of 36.37%.","main_category":"cs.CL","categories":"cs.CL,eess.AS","published":"2025-04-29T11:59:08Z"}
{"aid":"http://arxiv.org/abs/2504.20721v1","title":"Unitary ensembles with a critical edge point, their multiplicative\n  statistics and the Korteweg-de-Vries hierarchy","summary":"We study the multiplicative statistics associated to the limiting\ndeterminantal point process describing unitary random matrices with a critical\nedge point, where limiting density vanishes like a power 5/2. We prove that\nthese statistics are governed by the first three equations of the KdV\nhierarchy, and study the asymptotic behavior of the relevant solutions.","main_category":"math-ph","categories":"math-ph,math.MP,math.PR","published":"2025-04-29T13:01:51Z"}
{"aid":"http://arxiv.org/abs/2504.20726v1","title":"Enhancing Vulnerability Reports with Automated and Augmented Description\n  Summarization","summary":"Public vulnerability databases, such as the National Vulnerability Database\n(NVD), document vulnerabilities and facilitate threat information sharing.\nHowever, they often suffer from short descriptions and outdated or insufficient\ninformation. In this paper, we introduce Zad, a system designed to enrich NVD\nvulnerability descriptions by leveraging external resources. Zad consists of\ntwo pipelines: one collects and filters supplementary data using two encoders\nto build a detailed dataset, while the other fine-tunes a pre-trained model on\nthis dataset to generate enriched descriptions. By addressing brevity and\nimproving content quality, Zad produces more comprehensive and cohesive\nvulnerability descriptions. We evaluate Zad using standard summarization\nmetrics and human assessments, demonstrating its effectiveness in enhancing\nvulnerability information.","main_category":"cs.CR","categories":"cs.CR,cs.AI,cs.LG","published":"2025-04-29T13:08:27Z"}
{"aid":"http://arxiv.org/abs/2504.20732v1","title":"Bayesian Inference in Quantum Programs","summary":"Conditioning is a key feature in probabilistic programming to enable modeling\nthe influence of data (also known as observations) to the probability\ndistribution described by such programs. Determining the posterior distribution\nis also known as Bayesian inference. This paper equips a quantum while-language\nwith conditioning, defines its denotational and operational semantics over\ninfinite-dimensional Hilbert spaces, and shows their equivalence. We provide\nsufficient conditions for the existence of weakest (liberal)\nprecondition-transformers and derive inductive characterizations of these\ntransformers. It is shown how w(l)p-transformers can be used to assess the\neffect of Bayesian inference on (possibly diverging) quantum programs.","main_category":"cs.LO","categories":"cs.LO,quant-ph","published":"2025-04-29T13:15:54Z"}
{"aid":"http://arxiv.org/abs/2504.20737v1","title":"Path-connectedness of incompressible Euler solutions","summary":"We study the incompressible Euler equation and prove that the set of weak\nsolutions is path-connected. More precisely, we construct paths of H\\\"older\nregularity $C^{1/2}$, valued in $C^0_{t, loc} L^2_x$ endowed with the strong\ntopology. The main result relies on a convex integration construction adapted\nfrom the seminal work of De Lellis and Sz\\'ekelyhidi [14, The Euler equations\nas a differential inclusion], extending it to a more broader geometric\nframework, replacing balls with arbitrary convex compact sets.","main_category":"math.AP","categories":"math.AP","published":"2025-04-29T13:21:25Z"}
{"aid":"http://arxiv.org/abs/2504.20738v1","title":"EDD-NSTE: Edge Data Distribution as a Network Steiner Tree Estimation in\n  Edge Computing","summary":"Edge computing is a distributed computing paradigm that brings computation\nand data storage closer to the user's geographical location to improve response\ntimes and save bandwidth. It also helps to power a variety of applications\nrequiring low latency. These application data hosted on the cloud needs to be\ntransferred to the respective edge servers in a specific area to help provide\nlow-latency app functionalities to the users of that area. Meanwhile, these\narbitrary heavy data transactions from the cloud to the edge servers result in\nhigh cost and time penalties. Thus, we need an application data distribution\nstrategy that minimizes these penalties within the app vendors' specific\nlatency constraint. In this work, we provide a refined formulation of an\noptimal approach to solve this Edge Data Distribution (EDD) problem using\nInteger Programming (IP) technique. Due to the time complexity limitation of\nthe IP approach, we suggest an O(k) approximation algorithm based on network\nSteiner tree estimation (EDD-NSTE) for estimating solutions to dense,\nlarge-scale EDD problems. Integer Programming and EDD-NSTE are evaluated on a\nstandard real-world EUA data set and the result demonstrates that EDD-NSTE\nsignificantly outperforms with a performance margin of 86.67% over the other\nthree representative approaches and the state-of-the-art approach.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-29T13:21:27Z"}
{"aid":"http://arxiv.org/abs/2504.20753v1","title":"Vladimirov-Pearson Operators on $$-regular Ultrametric Cantor Sets","summary":"A new operator for certain types of ultrametric Cantor sets is constructed\nusing the measure coming from the spectral triple associated with the Cantor\nset, as well as its zeta function. Under certain mild conditions on that\nmeasure, it is shown that it is an integral operator similar to the\nVladimirov-Taibleson operator on the p-adic integers. Its spectral properties\nare studied, and the Markov property and kernel representation of the heat\nkernel generated by this so-called \\emph{Vladimirov-Pearson} operator is shown,\nviewed as acting on a certain Sobolev space. A large class of these operators\nhave a heat kernel and a Green function explicitly given by the ultrametric\nwavelets on the Cantor set, which are eigenfunctions of the operator.","main_category":"math.AP","categories":"math.AP,math.PR","published":"2025-04-29T13:33:59Z"}
{"aid":"http://arxiv.org/abs/2504.20795v1","title":"Effective Index Construction Algorithm for Optimal $(k,)$-cores\n  Computation","summary":"Computing $(k,\\eta)$-cores from uncertain graphs is a fundamental problem in\nuncertain graph analysis. UCF-Index is the state-of-the-art resolution to\nsupport $(k,\\eta)$-core queries, allowing the $(k,\\eta)$-core for any\ncombination of $k$ and $\\eta$ to be computed in an optimal time. However, this\nindex constructed by current algorithm is usually incorrect. During\ndecomposition, the key is to obtain the $k$-probabilities of its neighbors when\nthe vertex with minimum $k$-probability is deleted. Current method uses\nrecursive floating-point division to update it, which can lead to serious\nerrors. We propose a correct and efficient index construction algorithm to\naddress this issue. Firstly, we propose tight bounds on the $k$-probabilities\nof the vertices that need to be updated, and the accurate $k$-probabilities are\nrecalculated in an on-demand manner. Secondly, vertices partitioning and\nprogressive refinement strategy is devised to search the vertex with the\nminimum $k$-probability, thereby reducing initialization overhead for each $k$\nand avoiding unnecessary recalculations. Finally, extensive experiments\ndemonstrate the efficiency and scalability of our approach.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-29T14:10:39Z"}
{"aid":"http://arxiv.org/abs/2504.20810v1","title":"Effective Metric Description of Charged Black Holes","summary":"Charged black holes arise as solutions of General Relativity (GR) coupled to\nMaxwell theory. As functions of the mass and charge, they can exhibit extremal\nbehavior, in which case they are stable against thermal decay. (Quantum)\ncorrections to GR are expected to alter the classical features of these\nobjects, especially near extremality. To capture such effects in a\nmodel-independent way, we extend the Effective Metric Description (EMD)\npreviously introduced in [Phys.Rev.D 109 (2024) 2, 024045, Eur.Phys.J.C 84\n(2024) 12, 1273] for spherically symmetric and static black holes. The EMD\nparametrizes deformations of the metric in terms of physical quantities, such\nas the radial spatial distance to the event horizon. While the latter is still\nviable for non-extremal charged black holes, we argue that the proper time of a\nfree-falling observer is better suited in the extremal case: we derive the\nnecessary conditions for the parameters of such an EMD for constructing a\nconsistent space-time in the vicinity of the (extremal) horizon. Finally, we\nillustrate our framework through a concrete example, and mention implications\nof the Weak Gravity Conjecture on the effective metric parameters.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-29T14:23:33Z"}
{"aid":"http://arxiv.org/abs/2504.20828v1","title":"Ascendra: Dynamic Request Prioritization for Efficient LLM Serving","summary":"The rapid advancement of Large Language Models (LLMs) has driven the need for\nmore efficient serving strategies. In this context, efficiency refers to the\nproportion of requests that meet their Service Level Objectives (SLOs),\nparticularly for Time To First Token (TTFT) and Time Between Tokens (TBT).\nHowever, existing systems often prioritize one metric at the cost of the other.\nWe present Ascendra, an LLM serving system designed to meet both TTFT and TBT\nSLOs simultaneously. The core insight behind Ascendra is that a request's\nurgency evolves as it approaches its deadline. To leverage this, Ascendra\npartitions GPU resources into two types of instances: low-priority and\nhigh-priority. Low-priority instances maximize throughput by processing\nrequests out of arrival order, but at the risk of request starvation. To\naddress this, Ascendra employs a performance model to predict requests at risk\nof missing their SLOs and proactively offloads them to high-priority instances.\nHigh-priority instances are optimized for low-latency execution and handle\nurgent requests nearing their deadlines. This partitioned architecture enables\nAscendra to effectively balance high throughput and low latency. Extensive\nevaluation shows that Ascendra improves system throughput by up to 1.7x\ncompared to vLLM and Sarathi-Serve while meeting both TTFT and TBT SLOs.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-29T14:51:26Z"}
{"aid":"http://arxiv.org/abs/2504.20832v1","title":"Approximate Quantum Fourier Transform in Logarithmic Depth on a Line","summary":"The approximate quantum Fourier transform (AQFT) on $n$ qubits can be\nimplemented in logarithmic depth using $8n$ qubits with all-to-all\nconnectivity, as shown in [Hales, PhD Thesis Berkeley, 2002]. However,\nrealizing the required all-to-all connectivity can be challenging in practice.\nIn this work, we use dynamic circuits, i.e., mid-circuit measurements and\nfeed-forward operations, to implement the AQFT in logarithmic depth using only\n$4n$ qubits arranged on a line with nearest-neighbor connectivity. Furthermore,\nfor states with a specific structure, the number of qubits can be further\nreduced to $2n$ while keeping the logarithmic depth and line connectivity. As\npart of our construction, we introduce a new implementation of an adder with\nlogarithmic depth on a line, which allows us to improve the AQFT construction\nof Hales.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-29T14:56:41Z"}
{"aid":"http://arxiv.org/abs/2504.20852v1","title":"Machine Learning (ML)-Physics Fusion Model Outperforms Both Physics-Only\n  and ML-Only Models in Typhoon Predictions","summary":"Data-driven machine learning (ML) models, such as FuXi, exhibit notable\nlimitations in forecasting typhoon intensity and structure. This study presents\na comprehensive evaluation of FuXi-SHTM, a hybrid ML-physics model, using all\n2024 western North Pacific typhoon cases. The FuXi-SHTM hybrid demonstrates\nclear improvements in both track and intensity forecasts compared to the\nstandalone SHTM, FuXi, and ECMWF HRES models. Compared to FuXi alone, FuXi-SHTM\nreduces typhoon track forecast errors by 16.5% and 5.2% at lead times of 72 h\nand 120 h, respectively, and reduces intensity forecast errors by 59.7% and\n47.6%. Furthermore, FuXi-SHTM simulates cloud structures more realistically\ncompared to SHTM, and achieves superior representation of the 10-m wind fields\nin both intensity and spatial structure compared to FuXi and SHTM. Increasing\nthe resolution of FuXi-SHTM from 9 km to 3 km further enhances intensity\nforecasts, highlighting the critical role of the resolution of the physical\nmodel in advancing hybrid forecasting capabilities.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-29T15:21:07Z"}
{"aid":"http://arxiv.org/abs/2504.20860v1","title":"FedMVP: Federated Multi-modal Visual Prompt Tuning for Vision-Language\n  Models","summary":"Textual prompt tuning adapts Vision-Language Models (e.g., CLIP) in federated\nlearning by tuning lightweight input tokens (or prompts) on local client data,\nwhile keeping network weights frozen. Post training, only the prompts are\nshared by the clients with the central server for aggregation. However, textual\nprompt tuning often struggles with overfitting to known concepts and may be\noverly reliant on memorized text features, limiting its adaptability to unseen\nconcepts. To address this limitation, we propose Federated Multimodal Visual\nPrompt Tuning (FedMVP) that conditions the prompts on comprehensive contextual\ninformation -- image-conditioned features and textual attribute features of a\nclass -- that is multimodal in nature. At the core of FedMVP is a PromptFormer\nmodule that synergistically aligns textual and visual features through\ncross-attention, enabling richer contexual integration. The dynamically\ngenerated multimodal visual prompts are then input to the frozen vision encoder\nof CLIP, and trained with a combination of CLIP similarity loss and a\nconsistency loss. Extensive evaluation on 20 datasets spanning three\ngeneralization settings demonstrates that FedMVP not only preserves performance\non in-distribution classes and domains, but also displays higher\ngeneralizability to unseen classes and domains when compared to\nstate-of-the-art methods. Codes will be released upon acceptance.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T15:36:51Z"}
{"aid":"http://arxiv.org/abs/2504.20876v1","title":"Chaos Around the Kerr Black Hole: its Effects on Entropy and the Shadow","summary":"Massless or massive particles in unstable orbits around a Kerr black hole\nexhibit chaotic motion when perturbed. They either plunge into the black hole\nor escape to infinity after making some oscillations around the equatorial\nplane. In both of these cases, chaotic motion causes information production. In\nthe case of the photons that escape to infinity, it was recently suggested that\nthis information can be used to resolve the subring structure of the shadow\nimage and obtain more precise data about the black hole mass and spin. Here, we\nextend this method to obtain more precise results by including the\nnon-equatorial contributions to the Lyapunov exponents. In the other case of\nmassive particles that plunge into the Kerr black hole, we show that the\nassociated Kolmogorov-Sinai entropy derived from the Lyapunov exponents can be\ninterpreted in the context of black hole thermodynamics and that it obeys\nBekenstein's bound on the entropy of a physical material system. Thus, the\nperturbed unstable orbits, either ending inside the black hole or at the\nobserver's screen, have physical consequences.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE,hep-th,math-ph,math.MP","published":"2025-04-29T15:46:03Z"}
{"aid":"http://arxiv.org/abs/2504.20923v1","title":"End-to-end Audio Deepfake Detection from RAW Waveforms: a RawNet-Based\n  Approach with Cross-Dataset Evaluation","summary":"Audio deepfakes represent a growing threat to digital security and trust,\nleveraging advanced generative models to produce synthetic speech that closely\nmimics real human voices. Detecting such manipulations is especially\nchallenging under open-world conditions, where spoofing methods encountered\nduring testing may differ from those seen during training. In this work, we\npropose an end-to-end deep learning framework for audio deepfake detection that\noperates directly on raw waveforms. Our model, RawNetLite, is a lightweight\nconvolutional-recurrent architecture designed to capture both spectral and\ntemporal features without handcrafted preprocessing. To enhance robustness, we\nintroduce a training strategy that combines data from multiple domains and\nadopts Focal Loss to emphasize difficult or ambiguous samples. We further\ndemonstrate that incorporating codec-based manipulations and applying\nwaveform-level audio augmentations (e.g., pitch shifting, noise, and time\nstretching) leads to significant generalization improvements under realistic\nacoustic conditions. The proposed model achieves over 99.7% F1 and 0.25% EER on\nin-domain data (FakeOrReal), and up to 83.4% F1 with 16.4% EER on a challenging\nout-of-distribution test set (AVSpoof2021 + CodecFake). These findings\nhighlight the importance of diverse training data, tailored objective functions\nand audio augmentations in building resilient and generalizable audio forgery\ndetectors. Code and pretrained models are available at\nhttps://iplab.dmi.unict.it/mfs/Deepfakes/PaperRawNet2025/.","main_category":"cs.SD","categories":"cs.SD,cs.CV,eess.AS","published":"2025-04-29T16:38:23Z"}
{"aid":"http://arxiv.org/abs/2504.20955v1","title":"Egret-1: Pretrained Neural Network Potentials For Efficient and Accurate\n  Bioorganic Simulation","summary":"Accurate simulation of atomic systems has the potential to revolutionize the\ndesign of molecules and materials. Unfortunately, exact solutions of the\nSchr\\\"odinger equation scale as O(N!) and remain inaccessible for systems with\nmore than a handful of atoms, forcing scientists to accept steep tradeoffs\nbetween speed and accuracy and limiting the reliability and utility of the\nresultant simulations. Recent work in machine learning has demonstrated that\nneural network potentials (NNPs) can learn efficient approximations to quantum\nmechanics and resolve this tradeoff, but existing NNPs still suffer from\nlimited accuracy relative to state-of-the-art quantum-chemical methods. Here,\nwe present Egret-1, a family of large pre-trained NNPs based on the MACE\narchitecture with general applicability to main-group, organic, and\nbiomolecular chemistry. We find that the Egret-1 models equal or exceed the\naccuracy of routinely employed quantum-chemical methods on a variety of\nstandard tasks, including torsional scans, conformer ranking, and geometry\noptimization, while offering multiple-order-of-magnitude speedups relative to\nlegacy methods. We also highlight important lacunae for future NNP research to\ninvestigate, and suggest strategies for building future high-quality models\nwith increased scale and generality.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-29T17:26:21Z"}
{"aid":"http://arxiv.org/abs/2504.20975v1","title":"Linear function of a poset","summary":"Stanley and Grinberg introduced a symmetric function associated with digraphs\nand named it the Redei-Berge symmetric function. This function arises from a\nsuitable combinatorial Hopf algebra on digraphs, which made it possible to\nassign the Redei-Berge function to posets. In this paper, we define a new\ncombinatorial Hopf algebra of posets whose character is a close cousin of the\nRedei-Berge character for posets. Further, we investigate the properties of the\nsymmetric function that arises from this algebra and explore its expansions in\nvarious natural bases of $QSym$ and $Sym$. Finally, we obtain an interesting\nmethod for decomposing a poset.","main_category":"math.CO","categories":"math.CO","published":"2025-04-29T17:43:50Z"}
{"aid":"http://arxiv.org/abs/2504.20981v1","title":"Optical Activity of Group III-V Quantum Dots Directly Embedded in\n  Silicon","summary":"Optically active III-V group semiconductor quantum dots (QDs) are the leading\nelement of the upcoming safe quantum communication. However, the entire\nelectronic and IT infrastructure relies on silicon-based devices, with silicon\nalso providing a natural platform for photonic integration. Combining\nsemiconductor optics with silicon electronics is thus a major technological\nchallenge. This obstacle cannot be directly solved because silicon is optically\ninactive. Interfacing III-V quantum dots with silicon is thus a sought-after\nsolution. A radical approach is to embed III-V material grains directly into\nsilicon. The first realization of such technology was developed, and it gave\nInAs and core-shell InAs/GaAs QDs embedded in Si with bright and narrow\nsingle-QD emission lines. No theory has been given, though, and, as we show\nhere, it is not even obvious if and how such QDs can be optically active. We\nfirst use general arguments, also supported by atomistic calculations, that\nInAs/Si QDs cannot confine both carrier types unless the structural strain is\nmostly relaxed, meaning many defects at the interface. This explains the lack\nof light emission from those dots. Then we show that the InAs/GaAs/Si QDs can\nconfine both carrier types. Their electron states are, however, highly\ninfluenced by $k$-space valley mixing, which impacts emission spectra and\ndeteriorates optical properties. We propose to overcome this by adding an\nadditional wider-bandgap material layer.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,quant-ph","published":"2025-04-29T17:50:46Z"}
{"aid":"http://arxiv.org/abs/2504.20990v1","title":"Modification of the scattering mechanisms in bilayer graphene in\n  proximity to a molecular thin film probed in the mesoscopic regime","summary":"Quantum coherent effects can be probed in multilayer graphene through\nelectronic transport measurements at low temperatures. In particular, bilayer\ngraphene is known to be susceptible to quantum interference corrections of the\nconductivity, presenting weak localization at all electronic densities, and\ndependent on different scattering mechanisms as well as on the trigonal warping\nof the electron dispersion near the K and K' valleys. Proximity effects with a\nmolecular thin film influence these scattering mechanisms, which can be\nquantified through the known theory of magnetoconductance for bilayer graphene.\nHere, we present weak localization measurements in a copper-phthalocyanine /\nbilayer graphene / h-BN heterostructure that suggest an important suppression\nof trigonal warping effects in bilayer graphene (BLG), restoring the\nmanifestation of the chirality of the charge carriers in the localization\nproperties of BLG. Additionally, we observe a charge transfer of\n3.6$\\times$10$^{12}$cm$^{-2}$ from the BLG to the molecules, as well as a very\nsmall degradation of the mobility of the BLG/h-BN heterostructure upon the\ndeposition of copper phthalocyanine (CuPc). The molecular arrangement of the\nCuPc thin film is characterized in a control sample through transmission\nelectron microscopy, that we relate to the electronic transport results.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-29T17:57:24Z"}
{"aid":"http://arxiv.org/abs/2504.20996v1","title":"X-Fusion: Introducing New Modality to Frozen Large Language Models","summary":"We propose X-Fusion, a framework that extends pretrained Large Language\nModels (LLMs) for multimodal tasks while preserving their language\ncapabilities. X-Fusion employs a dual-tower design with modality-specific\nweights, keeping the LLM's parameters frozen while integrating vision-specific\ninformation for both understanding and generation. Our experiments demonstrate\nthat X-Fusion consistently outperforms alternative architectures on both\nimage-to-text and text-to-image tasks. We find that incorporating\nunderstanding-focused data improves generation quality, reducing image data\nnoise enhances overall performance, and feature alignment accelerates\nconvergence for smaller models but has minimal impact on larger ones. Our\nfindings provide valuable insights into building efficient unified multimodal\nmodels.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T17:59:45Z"}
{"aid":"http://arxiv.org/abs/2504.21258v1","title":"On a phase field model for binary mixtures of micropolar fluids with\n  non-matched densities and moving contact lines","summary":"We introduce a new phase field model for binary mixtures of incompressible\nmicropolar fluids, which are among the simplest categories of fluids exhibiting\ninternal rotations. The model fulfils local and global dissipation inequalities\nso that thermodynamic consistency is guaranteed. Our model consists of a\nNavier--Stokes--Cahn--Hilliard system for the fluid velocity, pressure, phase\nfield variable and chemical potential, coupled to an additional system of\nNavier--Stokes type for the micro-rotation. Our model accounts for non-matched\ndensities as well as moving contact line dynamics, and serve as a\ngeneralisation to earlier models for binary fluid flows based on a volume\naveraged velocity formulation. We also establish the existence of global weak\nsolutions in three spatial dimensions for the model equipped with singular\nlogarithmic and double obstacle potentials.","main_category":"math.AP","categories":"math.AP","published":"2025-04-30T02:17:19Z"}
{"aid":"http://arxiv.org/abs/2504.21260v1","title":"Power Flow Approximations for Multiphase Distribution Networks using\n  Gaussian Processes","summary":"Learning-based approaches are increasingly leveraged to manage and coordinate\nthe operation of grid-edge resources in active power distribution networks.\nAmong these, model-based techniques stand out for their superior data\nefficiency and robustness compared to model-free methods. However, effective\nmodel learning requires a learning-based approximator for the underlying power\nflow model. This study extends existing work by introducing a data-driven power\nflow method based on Gaussian Processes (GPs) to approximate the multiphase\npower flow model, by mapping net load injections to nodal voltages. Simulation\nresults using the IEEE 123-bus and 8500-node distribution test feeders\ndemonstrate that the trained GP model can reliably predict the nonlinear power\nflow solutions with minimal training data. We also conduct a comparative\nanalysis of the training efficiency and testing performance of the proposed\nGP-based power flow approximator against a deep neural network-based\napproximator, highlighting the advantages of our data-efficient approach.\nResults over realistic operating conditions show that despite an 85% reduction\nin the training sample size (corresponding to a 92.8% improvement in training\ntime), GP models produce a 99.9% relative reduction in mean absolute error\ncompared to the baselines of deep neural networks.","main_category":"eess.SY","categories":"eess.SY,cs.LG,cs.SY","published":"2025-04-30T02:26:31Z"}
{"aid":"http://arxiv.org/abs/2504.21265v1","title":"Quantifying Flat-Band Voltage in Si Metal-Oxide-Semiconductor\n  Structures: An Evaluation via Terahertz Emission Spectroscopy (TES)","summary":"Laser-induced Terahertz (THz) Emission Spectroscopy (TES) has demonstrated\nits potential utility in the realm of Metal-Oxide-Semiconductor (MOS) devices\nas an expedient and noncontact estimation methodology. Owing to its discerning\nresponse to the interface electric field, the amplitude of the THz emission\npeak in time-domain spectroscopy encapsulates rich information regarding MOS\nproperties, notably the flat-band voltage. This paper concentrates on the\nprecise quantitative estimation of the flat-band voltage within the Si MOS\nstructure, elucidating the intricacies of the estimation process through the\nTHz emission model.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-30T02:49:09Z"}
{"aid":"http://arxiv.org/abs/2504.21267v1","title":"Searching beyond the fiducial stochastic gravitational wave background\n  in pulsar timing array data using likelihood reweighting","summary":"Since the recent announcements of evidence for a stochastic gravitational\nwave background from several pulsar timing array collaborations, much effort\nhas been devoted to explore features beyond the fiducial Hellings-Downs\nbackground including those arising in modified gravity theories and\ndeterministic gravitational wave signals. Inspired by previous studies, we\npropose a method to efficiently screen these models using likelihood\nreweighting based on the fiducial model. In order to alleviate the well-known\nunstable weight estimates in vanilla importance sampling, we implement\nreweighting for the second time making use of the kernel density estimation of\nthe previously reweighted samples. We tested this method by analyzing three\nsimulated datasets with an injected sinusoid signal applied to all pulsars. It\nis found that likelihood reweighting not only gives results compatible with\nthose from full Bayesian analyses when the signal is subdominant, but is also\nable to recover the signal posterior to a reasonable accuracy in the presence\nof a rather strong signal. Given samples from the fiducial model, this method\ncould bring an at least $\\mathcal{O}(10)$-time speedup in analyzing new models.","main_category":"gr-qc","categories":"gr-qc,astro-ph.IM","published":"2025-04-30T02:50:28Z"}
{"aid":"http://arxiv.org/abs/2504.21303v1","title":"Confidence in Large Language Model Evaluation: A Bayesian Approach to\n  Limited-Sample Challenges","summary":"Large language models (LLMs) exhibit probabilistic output characteristics,\nyet conventional evaluation frameworks rely on deterministic scalar metrics.\nThis study introduces a Bayesian approach for LLM capability assessment that\nintegrates prior knowledge through probabilistic inference, addressing\nlimitations under limited-sample regimes. By treating model capabilities as\nlatent variables and leveraging a curated query set to induce discriminative\nresponses, we formalize model ranking as a Bayesian hypothesis testing problem\nover mutually exclusive capability intervals. Experimental evaluations with\nGPT-series models demonstrate that the proposed method achieves superior\ndiscrimination compared to conventional evaluation methods. Results indicate\nthat even with reduced sample sizes, the approach maintains statistical\nrobustness while providing actionable insights, such as probabilistic\nstatements about a model's likelihood of surpassing specific baselines. This\nwork advances LLM evaluation methodologies by bridging Bayesian inference with\npractical constraints in real-world deployment scenarios.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-30T04:24:50Z"}
{"aid":"http://arxiv.org/abs/2504.21323v1","title":"How to Backdoor the Knowledge Distillation","summary":"Knowledge distillation has become a cornerstone in modern machine learning\nsystems, celebrated for its ability to transfer knowledge from a large, complex\nteacher model to a more efficient student model. Traditionally, this process is\nregarded as secure, assuming the teacher model is clean. This belief stems from\nconventional backdoor attacks relying on poisoned training data with backdoor\ntriggers and attacker-chosen labels, which are not involved in the distillation\nprocess. Instead, knowledge distillation uses the outputs of a clean teacher\nmodel to guide the student model, inherently preventing recognition or response\nto backdoor triggers as intended by an attacker. In this paper, we challenge\nthis assumption by introducing a novel attack methodology that strategically\npoisons the distillation dataset with adversarial examples embedded with\nbackdoor triggers. This technique allows for the stealthy compromise of the\nstudent model while maintaining the integrity of the teacher model. Our\ninnovative approach represents the first successful exploitation of\nvulnerabilities within the knowledge distillation process using clean teacher\nmodels. Through extensive experiments conducted across various datasets and\nattack settings, we demonstrate the robustness, stealthiness, and effectiveness\nof our method. Our findings reveal previously unrecognized vulnerabilities and\npave the way for future research aimed at securing knowledge distillation\nprocesses against backdoor attacks.","main_category":"cs.CR","categories":"cs.CR,cs.AI,cs.LG","published":"2025-04-30T05:19:23Z"}
{"aid":"http://arxiv.org/abs/2504.21385v1","title":"IDDM: Bridging Synthetic-to-Real Domain Gap from Physics-Guided\n  Diffusion for Real-world Image Dehazing","summary":"Due to the domain gap between real-world and synthetic hazy images, current\ndata-driven dehazing algorithms trained on synthetic datasets perform well on\nsynthetic data but struggle to generalize to real-world scenarios. To address\nthis challenge, we propose \\textbf{I}mage \\textbf{D}ehazing \\textbf{D}iffusion\n\\textbf{M}odels (IDDM), a novel diffusion process that incorporates the\natmospheric scattering model into noise diffusion. IDDM aims to use the gradual\nhaze formation process to help the denoising Unet robustly learn the\ndistribution of clear images from the conditional input hazy images. We design\na specialized training strategy centered around IDDM. Diffusion models are\nleveraged to bridge the domain gap from synthetic to real-world, while the\natmospheric scattering model provides physical guidance for haze formation.\nDuring the forward process, IDDM simultaneously introduces haze and noise into\nclear images, and then robustly separates them during the sampling process. By\ntraining with physics-guided information, IDDM shows the ability of domain\ngeneralization, and effectively restores the real-world hazy images despite\nbeing trained on synthetic datasets. Extensive experiments demonstrate the\neffectiveness of our method through both quantitative and qualitative\ncomparisons with state-of-the-art approaches.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T07:36:10Z"}
{"aid":"http://arxiv.org/abs/2504.21386v1","title":"Power Suppression and Lensing Anomaly -- A phenomenological\n  investigation","summary":"Primordial power spectra with low power at long wavelengths can alleviate\nlensing anomaly. However the extent to which data favours such a primordial\nspectra is not clear. In this work, we investigate power suppression and\nrelated mitigation of lensing anomaly with the help of phenomenological models\nwhich are valid over scales of interest. We consider simple extensions to\nnearly scale invariant power spectra such as those which includes running and\nrunning of running of spectral index. We perform Bayesian analysis of these\nmodels, which are agnostic about power suppression, with various data sets and\nshow that data tend to choose parameters which leads to power suppression at\nlow multipoles. We then analyse the significance of these findings using\ninformation criteria. Further, we investigate the ability of near-ultimate\nfuture CMB missions such as ECHO to put tighter constraints on these models. We\nconclude that we can make stronger conclusions about the presence of power\nsuppression in the future by studying such simple phenomenological models.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-30T07:37:11Z"}
{"aid":"http://arxiv.org/abs/2504.21413v1","title":"An Inversion Theorem for Buffered Linear Toeplitz (BLT) Matrices and\n  Applications to Streaming Differential Privacy","summary":"Buffered Linear Toeplitz (BLT) matrices are a family of parameterized\nlower-triangular matrices that play an important role in streaming differential\nprivacy with correlated noise. Our main result is a BLT inversion theorem: the\ninverse of a BLT matrix is itself a BLT matrix with different parameters. We\nalso present an efficient and differentiable $O(d^3)$ algorithm to compute the\nparameters of the inverse BLT matrix, where $d$ is the degree of the original\nBLT (typically $d < 10$). Our characterization enables direct optimization of\nBLT parameters for privacy mechanisms through automatic differentiation.","main_category":"cs.CR","categories":"cs.CR,eess.SP","published":"2025-04-30T08:14:09Z"}
{"aid":"http://arxiv.org/abs/2504.21439v1","title":"Further results on arithmetic properties of biregular overpartitions","summary":"Recently there has been quite a bit of study carried out related to\narithmetic properties of overpartitions into non-multiples of two co-prime\nintegers. The paper [19] by Nadji et al. looked into congruences modulo $3$ and\npowers of $2$ for certain specific pairs of co-prime integers, while the paper\n[1] by Alanazi et al. investigated some congruences related to some similar and\nsome different pairs of co-prime integers. In this paper we propose some\nelegant and elementary proofs of a subset of the congruences given in [1] by\nusing only theta function and dissection identities. We also propose a generic\nmethod for proving congruences modulo $8$ which doesn't necessarily use any\nspecific $2$-dissection.","main_category":"math.NT","categories":"math.NT","published":"2025-04-30T08:55:25Z"}
{"aid":"http://arxiv.org/abs/2504.21444v1","title":"A Unified QoS-Aware Multiplexing Framework for Next Generation Immersive\n  Communication with Legacy Wireless Applications","summary":"Immersive communication, including emerging augmented reality, virtual\nreality, and holographic telepresence, has been identified as a key service for\nenabling next-generation wireless applications. To align with legacy wireless\napplications, such as enhanced mobile broadband or ultra-reliable low-latency\ncommunication, network slicing has been widely adopted. However, attempting to\nstatistically isolate the above types of wireless applications through\ndifferent network slices may lead to throughput degradation and increased queue\nbacklog. To address these challenges, we establish a unified QoS-aware\nframework that supports immersive communication and legacy wireless\napplications simultaneously. Based on the Lyapunov drift theorem, we transform\nthe original long-term throughput maximization problem into an equivalent\nshort-term throughput maximization weighted by virtual queue length. Moreover,\nto cope with the challenges introduced by the interaction between\nlarge-timescale network slicing and short-timescale resource allocation, we\npropose an adaptive adversarial slicing (Ad2S) scheme for networks with\ninvarying channel statistics. To track the network channel variations, we also\npropose a measurement extrapolation-Kalman filter (ME-KF)-based method and\nrefine our scheme into Ad2S-non-stationary refinement (Ad2S-NR). Through\nextended numerical examples, we demonstrate that our proposed schemes achieve\n3.86 Mbps throughput improvement and 63.96\\% latency reduction with 24.36\\%\nconvergence time reduction. Within our framework, the trade-off between total\nthroughput and user service experience can be achieved by tuning systematic\nparameters.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-30T08:59:46Z"}
{"aid":"http://arxiv.org/abs/2504.21463v1","title":"RWKV-X: A Linear Complexity Hybrid Language Model","summary":"In this paper, we introduce \\textbf{RWKV-X}, a novel hybrid architecture that\ncombines the efficiency of RWKV for short-range modeling with a sparse\nattention mechanism designed to capture long-range context. Unlike previous\nhybrid approaches that rely on full attention layers and retain quadratic\ncomplexity, RWKV-X achieves linear-time complexity in training and\nconstant-time complexity in inference decoding. We demonstrate that RWKV-X,\nwhen continually pretrained on 64K-token sequences, achieves near-perfect\naccuracy on the 64K passkey retrieval benchmark. It consistently outperforms\nprior RWKV-7 models on long-context benchmarks, while maintaining strong\nperformance on short-context tasks. These results highlight RWKV-X as a\nscalable and efficient backbone for general-purpose language modeling, capable\nof decoding sequences up to 1 million tokens with stable speed and memory\nusage. To facilitate further research and analysis, we have made the\ncheckpoints and the associated code publicly accessible at:\nhttps://github.com/howard-hou/RWKV-X.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-30T09:38:17Z"}
{"aid":"http://arxiv.org/abs/2504.21485v1","title":"Monolayer C$_{60}$ networks: A first-principles perspective","summary":"Monolayer fullerene (C$_{60}$) networks combine molecular-level rigidity with\ncrystalline connectivity, offering a promising platform for numerous\napplications. In this Feature article, we review the physical and chemical\nproperties of fullerene monolayers, focusing on first-principles studies. We\nfirst explore the structural stability of monolayer phases and investigate\ntheir thermal expansion behaviours. We then outline criteria for photocatalytic\nwater splitting and introduce theoretical predictions which are supported by\nrecent experimental verification. Finally, we show how interlayer stacking,\nmolecular size, and dimensional tuning (from 2D monolayers into 3D crystals, 1D\nchains, or nanoribbons) offer versatile approaches to modulate their chemical\nfunctionality. Together, these insights establish fullerene networks as a novel\nclass of carbon-based materials with tailored properties for catalysis,\nphotovoltaics, and flexible electronics.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall,physics.app-ph,physics.atm-clus,physics.chem-ph","published":"2025-04-30T10:09:45Z"}
{"aid":"http://arxiv.org/abs/2504.21510v1","title":"A simple approach for power density calculation of spontaneous radiation\n  emission from a finite emittance electron beam in planar undulators","summary":"We extend the angular power density formulae for spontaneous radiation\nemission from planar undulators to include finite emittance and angular\nmisalignment of the electron beam. Then we calculate and compare power\ndensities estimated from integral approach with Gaussian beam distribution and\nsummation approach with the macro-particle allocation covering the particle\nbeam phase space. After showing that both approaches converge to each other, we\napply the macro-particle approach to study power absorbed and transmitted by\nvarious apertures at the front end of the 9-ID beamline at the National\nSynchrotron Light Source-II. Our analysis indicate that the electron beam\nmisalignment could lead to unwarranted power deposition at tighter apertures\nthat would have been otherwise difficult to account in the aperture\ndesign/choice process using the geometric ray-tracing approach.","main_category":"physics.acc-ph","categories":"physics.acc-ph","published":"2025-04-30T10:58:36Z"}
{"aid":"http://arxiv.org/abs/2504.21520v1","title":"Padding Matters -- Exploring Function Detection in PE Files","summary":"Function detection is a well-known problem in binary analysis. While previous\nresearch has primarily focused on Linux/ELF, Windows/PE binaries have been\noverlooked or only partially considered. This paper introduces FuncPEval, a new\ndataset for Windows x86 and x64 PE files, featuring Chromium and the Conti\nransomware, along with ground truth data for 1,092,820 function starts.\nUtilizing FuncPEval, we evaluate five heuristics-based (Ghidra, IDA, Nucleus,\nrev.ng, SMDA) and three machine-learning-based (DeepDi, RNN, XDA) function\nstart detection tools. Among the tested tools, IDA achieves the highest\nF1-score (98.44%) for Chromium x64, while DeepDi closely follows (97%) but\nstands out as the fastest by a significant margin. Working towards\nexplainability, we examine the impact of padding between functions on the\ndetection results. Our analysis shows that all tested tools, except rev.ng, are\nsusceptible to randomized padding. The randomized padding significantly\ndiminishes the effectiveness for the RNN, XDA, and Nucleus. Among the\nlearning-based tools, DeepDi exhibits the least sensitivity and demonstrates\noverall the fastest performance, while Nucleus is the most adversely affected\namong non-learning-based tools. In addition, we improve the recurrent neural\nnetwork (RNN) proposed by Shin et al. and enhance the XDA tool, increasing the\nF1-score by approximately 10%.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-30T11:15:09Z"}
{"aid":"http://arxiv.org/abs/2504.21526v1","title":"Physics-Informed Priors Improve Gravitational-Wave Constraints on\n  Neutron-Star Matter","summary":"Gravitational-wave astronomy shows great promise in determining nuclear\nphysics in a regime not accessible to terrestrial experiments. We introduce\nphysics-informed priors constrained by nuclear theory and perturbative Quantum\nChromodynamics calculations, as well as astrophysical measurements of\nneutron-star masses and radii. When these priors are used in gravitational-wave\nastrophysical inference, we show a significant improvement on nuclear equation\nof state constraints. Applying these to the first observed gravitational-wave\nbinary neutron-star merger GW170817, the constraints on the radius of a\n$1.4\\,M_\\odot$ neutron star improve from $R_{1.4} ={12.54^{+1.05}_{-1.54}} \\,\n{\\rm km}$ to $R_{1.4} = 12.11^{+0.91}_{-1.11} \\,{\\rm km}$ and those on the\ntidal deformability from $\\tilde{\\Lambda}_{1.186} < 720$ to\n$\\tilde{\\Lambda}_{1.186} = 384^{+306}_{-158}$ ($90\\%$ confidence intervals) at\nthe events measured chirp mass $\\mathcal{M}=1.186\\,M_\\odot$. We also show these\npriors can be used to perform model selection between binary neutron star and\nneutron star-black hole mergers; in the case of GW190425, the results provide\nonly marginal evidence with a Bayes factor $\\mathcal{BF}=1.33$ in favour of the\nbinary neutron star merger hypothesis. Given their ability to improve the\nastrophysical inference of binary mergers involving neutron stars, we advocate\nfor these physics-informed priors to be used as standard in the literature and\nprovide open-source code for reproducibility and adaptation of the method.","main_category":"astro-ph.HE","categories":"astro-ph.HE,gr-qc,nucl-th","published":"2025-04-30T11:19:52Z"}
{"aid":"http://arxiv.org/abs/2504.21530v1","title":"RoboGround: Robotic Manipulation with Grounded Vision-Language Priors","summary":"Recent advancements in robotic manipulation have highlighted the potential of\nintermediate representations for improving policy generalization. In this work,\nwe explore grounding masks as an effective intermediate representation,\nbalancing two key advantages: (1) effective spatial guidance that specifies\ntarget objects and placement areas while also conveying information about\nobject shape and size, and (2) broad generalization potential driven by\nlarge-scale vision-language models pretrained on diverse grounding datasets. We\nintroduce RoboGround, a grounding-aware robotic manipulation system that\nleverages grounding masks as an intermediate representation to guide policy\nnetworks in object manipulation tasks. To further explore and enhance\ngeneralization, we propose an automated pipeline for generating large-scale,\nsimulated data with a diverse set of objects and instructions. Extensive\nexperiments show the value of our dataset and the effectiveness of grounding\nmasks as intermediate guidance, significantly enhancing the generalization\nabilities of robot policies.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-30T11:26:40Z"}
{"aid":"http://arxiv.org/abs/2504.21531v1","title":"A Numerical scheme to approximate the solution of the planar Skorokhod\n  embedding problem","summary":"We present a numerical framework to approximate the $\\mu$-domain in the\nplanar Skorokhod embedding problem (PSEP), recently appeared in\n\\cite{gross2019}. Our approach investigates the continuity and convergence\nproperties of the solutions with respect to the underlying distribution $\\mu$.\nWe establish that, under weak convergence of a sequence of probability measures\n$(\\mu_n)$ with bounded support, the corresponding sequence of $\\mu_n$-domains\nconverges to the domain associated with $\\mu$, limit of $(\\mu_n)$. We derive\nexplicit convergence results in the $L^1$ norm, supported by a generalization\nusing the concept of $\\alpha_p$-convergence. Furthermore, we provide practical\nimplementation techniques, convergence rate estimates, and numerical\nsimulations using various distributions. The method proves robust and\nadaptable, offering a concrete computational pathway for approximating\n$\\mu$-domains in the PSEP.","main_category":"math.PR","categories":"math.PR","published":"2025-04-30T11:27:23Z"}
{"aid":"http://arxiv.org/abs/2504.21556v1","title":"On persistent energy currents at equilibrium in non-reciprocal systems","summary":"We investigate the properties of the mean Poynting vector in global thermal\nequilibrium, which can be non-zero in non-reciprocal electromagnetic systems.\nUsing dyadic Green's functions and the fluctuation-dissipation theorem, we\nprovide a general proof that the mean Poynting vector is divergence-free under\nequilibrium conditions. Relying on this proof, we explicitly demonstrate that\nfor systems where a normal mode expansion of the Green's function is\napplicable, the divergence of the equilibrium mean Poynting vector vanishes. As\nconcrete examples, we also examine the equilibrium mean Poynting vector near a\nplanar non-reciprocal substrate and in configurations involving an arbitrary\nnumber of dipolar non-reciprocal objects in free space. Finally, we argue that\nthe so-called persistent heat current, while present in equilibrium, cannot be\ndetected through out-of-equilibrium heat transfer measurements.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-30T11:54:41Z"}
{"aid":"http://arxiv.org/abs/2504.21570v1","title":"Extended self-similarity in two-dimensional complex plasmas","summary":"Self-similarity is a property of an object or process wherein a part is\nsimilar to the whole. Mathematically, it can often be expressed as a power-law\nscaling of the quantity of interest. Extended self-similarity is a concept\nwidely used in the field of turbulence and refers to the power-law scaling of\nthe longitudinal structure functions of the velocity field expressed through\nthe structure functions of different orders, rather than distance. Originally\ndiscovered by [R. Benzi et al., Phys. Rev. E 48, R29 (1993)] in fully developed\nturbulence, it was later found to hold in other situations and systems as well.\nIn this paper, we show that in an active-matter system, extended\nself-similarity is possible even without the presence of respective power-law\nscaling in the underlying structure functions of distance. The active-matter\nsystem used in this study was a single-layer suspension of active Janus\nparticles in a plasma. Janus particles are polymer microspheres with\nhemispherical metal coating. When dispersed in a plasma, they acquire\nself-propulsion and act as microswimmers. Extended self-similarity was also\nobserved in the velocity field of a single-layer suspension of laser-heated\nregular (passive) particles, where the underlying structure functions displayed\na hint of the power-law scaling near the mean interparticle distance.\nTherefore, it appears to be an inherent characteristic of complex plasmas.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-30T12:16:30Z"}
{"aid":"http://arxiv.org/abs/2504.21611v1","title":"Prospects for new glueballs and exotics searches","summary":"Glueballs and Hybrids are solid predictions of QCD, but none have this far\nbeen identified in an undisputable way. We list several strategies, including\nthe very promising search for \"cascade\" decays of glueballs and hybrids into\neach others, and mention the yet under-exploited sources in heavy ion\ncollisions","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-30T13:09:19Z"}
{"aid":"http://arxiv.org/abs/2504.21625v1","title":"Meeseeks: An Iterative Benchmark Evaluating LLMs Multi-Turn\n  Instruction-Following Ability","summary":"The ability to follow instructions accurately is fundamental for Large\nLanguage Models (LLMs) to serve as reliable agents in real-world applications.\nWhile existing instruction-following benchmarks are either single-turn or\nintroduce new requirements in each turn without allowing self-correction,\nMeeseeks simulates realistic human-LLM interactions through an iterative\nfeedback process. This design enables models to self-correct based on specific\nrequirement failures, better reflecting real-world user-end usage patterns. The\nbenchmark implements a comprehensive evaluation system with 38 capability tags\norganized across three dimensions: Intent Recognition, Granular Content\nValidation, and Output Structure Validation. Through rigorous evaluation across\nLLMs, Meeseeks provides valuable insights into LLMs' instruction-following\ncapabilities in practical applications.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-30T13:28:19Z"}
{"aid":"http://arxiv.org/abs/2504.21627v1","title":"LSNIF: Locally-Subdivided Neural Intersection Function","summary":"Neural representations have shown the potential to accelerate ray casting in\na conventional ray-tracing-based rendering pipeline. We introduce a novel\napproach called Locally-Subdivided Neural Intersection Function (LSNIF) that\nreplaces bottom-level BVHs used as traditional geometric representations with a\nneural network. Our method introduces a sparse hash grid encoding scheme\nincorporating geometry voxelization, a scene-agnostic training data collection,\nand a tailored loss function. It enables the network to output not only\nvisibility but also hit-point information and material indices. LSNIF can be\ntrained offline for a single object, allowing us to use LSNIF as a replacement\nfor its corresponding BVH. With these designs, the network can handle hit-point\nqueries from any arbitrary viewpoint, supporting all types of rays in the\nrendering pipeline. We demonstrate that LSNIF can render a variety of scenes,\nincluding real-world scenes designed for other path tracers, while achieving a\nmemory footprint reduction of up to 106.2x compared to a compressed BVH.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-30T13:29:42Z"}
{"aid":"http://arxiv.org/abs/2504.21651v1","title":"Pressure and strain effects on the $\\textit{ab initio}$ $GW$ electronic\n  structure of La$_3$Ni$_2$O$_7$","summary":"The recent discovery of superconductivity in La$_3$Ni$_2$O$_7$ at a critical\ntemperature above 80~K points to a non-conventional pairing mechanism in\nnickelates as in cuprates, possibly due to electronic correlations. We have\ncalculated from first principles the electronic structure of La$_3$Ni$_2$O$_7$\nunder the effect of pressure and epitaxial strain including correlations by the\n$GW$ approximation to the many-body self-energy. We find that the Fermi surface\nis composed of a characteristic cuprate-shape sheet $\\beta$ plus a\nnickelate-specific cylinder $\\alpha$, both from Ni $e_g$ orbitals, with a\nnon-negligible drop in the quasiparticle weight and an effective 1D character.\nThis topology results from a delicate balance between the Ni-3$d_{z^2}$ hole\npocket $\\gamma$, which is suppressed by correlations, and an emerging\nLa-5$d_{x^2-y^2}$ electron pocket induced by both correlation and\npressure/strain effects and whose role at low energy has been neglected so far.\nUnlike cuprates, the electronic structure of La$_3$Ni$_2$O$_7$ is already\ncorrectly described from ab initio and in agreement with the experiment without\nthe need to introduce Hubbard $U$ adjustable parameters or to invoke a strongly\ncorrelated physics.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.mtrl-sci","published":"2025-04-30T13:55:45Z"}
{"aid":"http://arxiv.org/abs/2504.21667v1","title":"From Precision to Perception: User-Centred Evaluation of Keyword\n  Extraction Algorithms for Internet-Scale Contextual Advertising","summary":"Keyword extraction is a foundational task in natural language processing,\nunderpinning countless real-world applications. A salient example is contextual\nadvertising, where keywords help predict the topical congruence between ads and\ntheir surrounding media contexts to enhance advertising effectiveness. Recent\nadvances in artificial intelligence, particularly large language models, have\nimproved keyword extraction capabilities but also introduced concerns about\ncomputational cost. Moreover, although the end-user experience is of vital\nimportance, human evaluation of keyword extraction performances remains\nunder-explored. This study provides a comparative evaluation of three prevalent\nkeyword extraction algorithms that vary in complexity: TF-IDF, KeyBERT, and\nLlama 2. To evaluate their effectiveness, a mixed-methods approach is employed,\ncombining quantitative benchmarking with qualitative assessments from 552\nparticipants through three survey-based experiments. Findings indicate a slight\nuser preference for KeyBERT, which offers a favourable balance between\nperformance and computational efficiency compared to the other two algorithms.\nDespite a strong overall preference for gold-standard keywords, differences\nbetween the algorithmic outputs are not statistically significant, highlighting\na long-overlooked gap between traditional precision-focused metrics and\nuser-perceived algorithm efficiency. The study highlights the importance of\nuser-centred evaluation methodologies and proposes analytical tools to support\ntheir implementation.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-30T14:10:00Z"}
{"aid":"http://arxiv.org/abs/2504.21670v1","title":"Assimilation of SWOT Altimetry Data for Riverine Flood Reanalysis: From\n  Synthetic to Real Data","summary":"Floods are one of the most common and devastating natural disasters\nworldwide. The contribution of remote sensing is important for reducing the\nimpact of flooding both during the event itself and for improving hydrodynamic\nmodels by reducing their associated uncertainties. This article presents the\ninnovative capabilities of the Surface Water and Ocean Topography (SWOT)\nmission, especially its river node products, to enhance the accuracy of\nriverine flood reanalysis, performed on a 50-km stretch of the Garonne River.\nThe experiments incorporate various data assimilation strategies, based on the\nensemble Kalman filter (EnKF), which allows for sequential updates of model\nparameters based on available observations. The experimental results show that\nwhile SWOT data alone offers some improvements, combining it with in-situ water\nlevel measurements provides the most accurate representation of flood dynamics,\nboth at gauge stations and along the river. The study also investigates the\nimpact of different SWOT revisit frequencies on the models performance,\nrevealing that assimilating more frequent SWOT observations leads to more\nreliable flood reanalyses. In the real event, it was demonstrated that the\nassimilation of SWOT and in-situ data accurately reproduces the water level\ndynamics, offering promising prospects for future flood monitoring systems.\nOverall, this study emphasizes the complementary strengths of Earth Observation\ndata in improving the representation of the flood dynamics in the riverbed and\nthe floodplains.","main_category":"eess.IV","categories":"eess.IV","published":"2025-04-30T14:10:40Z"}
{"aid":"http://arxiv.org/abs/2504.21692v1","title":"Enhancing Self-Supervised Fine-Grained Video Object Tracking with\n  Dynamic Memory Prediction","summary":"Successful video analysis relies on accurate recognition of pixels across\nframes, and frame reconstruction methods based on video correspondence learning\nare popular due to their efficiency. Existing frame reconstruction methods,\nwhile efficient, neglect the value of direct involvement of multiple reference\nframes for reconstruction and decision-making aspects, especially in complex\nsituations such as occlusion or fast movement. In this paper, we introduce a\nDynamic Memory Prediction (DMP) framework that innovatively utilizes multiple\nreference frames to concisely and directly enhance frame reconstruction. Its\ncore component is a Reference Frame Memory Engine that dynamically selects\nframes based on object pixel features to improve tracking accuracy. In\naddition, a Bidirectional Target Prediction Network is built to utilize\nmultiple reference frames to improve the robustness of the model. Through\nexperiments, our algorithm outperforms the state-of-the-art self-supervised\ntechniques on two fine-grained video object tracking tasks: object segmentation\nand keypoint tracking.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-30T14:29:04Z"}
{"aid":"http://arxiv.org/abs/2504.21740v1","title":"The monodromy of compact Lagrangian fibrations","summary":"We study the monodromy representations underlying compact Lagrangian\nfibrations. In the case where the associated period map is generically\nimmersive, we prove that the mondromy representation is irreducible over\n\\(\\mathbb{C}\\). In the alternative case where the fibration is isotrivial, we\nrecover a result of \\cite{kim-laza-martin23}, proving that its fibers are\nisogeneous to a power of an elliptic curve. We show that over \\(\\mathbb{C}\\),\nthe monodromy representation underlying an isotrivial Lagrangian fibration is a\ndirect sum of two irreducible \\(\\mathbb{C}\\)-local systems.","main_category":"math.AG","categories":"math.AG","published":"2025-04-30T15:38:12Z"}
{"aid":"http://arxiv.org/abs/2504.21770v1","title":"LASHED: LLMs And Static Hardware Analysis for Early Detection of RTL\n  Bugs","summary":"While static analysis is useful in detecting early-stage hardware security\nbugs, its efficacy is limited because it requires information to form checks\nand is often unable to explain the security impact of a detected vulnerability.\nLarge Language Models can be useful in filling these gaps by identifying\nrelevant assets, removing false violations flagged by static analysis tools,\nand explaining the reported violations. LASHED combines the two approaches\n(LLMs and Static Analysis) to overcome each other's limitations for hardware\nsecurity bug detection. We investigate our approach on four open-source SoCs\nfor five Common Weakness Enumerations (CWEs) and present strategies for\nimprovement with better prompt engineering. We find that 87.5% of instances\nflagged by our recommended scheme are plausible CWEs. In-context learning and\nasking the model to 'think again' improves LASHED's precision.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-30T16:15:53Z"}
{"aid":"http://arxiv.org/abs/2504.21773v1","title":"MAC-Tuning: LLM Multi-Compositional Problem Reasoning with Enhanced\n  Knowledge Boundary Awareness","summary":"With the widespread application of large language models (LLMs), the issue of\ngenerating non-existing facts, known as hallucination, has garnered increasing\nattention. Previous research in enhancing LLM confidence estimation mainly\nfocuses on the single problem setting. However, LLM awareness of its internal\nparameterized knowledge boundary under the more challenging multi-problem\nsetting, which requires answering multiple problems accurately simultaneously,\nremains underexplored. To bridge this gap, we introduce a novel method,\nMultiple Answers and Confidence Stepwise Tuning (MAC-Tuning), that separates\nthe learning of answer prediction and confidence estimation during fine-tuning\non instruction data. Extensive experiments demonstrate that our method\noutperforms baselines by up to 25% in average precision.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-30T16:17:53Z"}
{"aid":"http://arxiv.org/abs/2504.21783v1","title":"Three-dimensional horseshoes near an unfolding of a Hopf-Hopf\n  singularity","summary":"Motivated by a certain type of unfolding of a Hopf-Hopf singularity, we\nconsider a one-parameter family $(f_\\gamma)_{\\gamma\\geq0}$ of $C^3$--vector\nfields in $\\mathbb{R}^4$ whose flows exhibit a heteroclinic cycle associated to\ntwo periodic solutions and a bifocus, all of them hyperbolic. It is formally\nproved that combining rotation with a generic condition concerning the\ntransverse intersection between the three-dimensional invariant manifolds of\nthe periodic solutions, all sets are highly distorted by the first return map\nand hyperbolic three-dimensional horseshoes emerge, accumulating on the\nnetwork. Infinitely many linked horseshoes prompt the coexistence of infinitely\nmany saddle-type invariant sets for all values of $\\gamma\\gtrsim 0$ belonging\nto the heteroclinic class of the two hyperbolic periodic solutions. We apply\nthe results to a particular unfolding of the Hopf-Hopf singularity, the so\ncalled \\emph{Gaspard-type unfolding}.","main_category":"math.DS","categories":"math.DS","published":"2025-04-30T16:39:06Z"}
{"aid":"http://arxiv.org/abs/2504.21806v1","title":"The embedding space of a Hopf link","summary":"We study the unparametrised smooth embedding space of a Hopf link in\n$\\mathbb{R}^3$, and prove that it is homotopy equivalent to the closed\n3-manifold $S^3/\\mathbb{Q}_8$. As an intermediate step in the proof, we show\nthat the inclusion of the subspace of round embeddings is a homotopy\nequivalence. We provide analogous results for the unparametrised smooth\nembedding space of a Hopf link in $S^3$.","main_category":"math.GT","categories":"math.GT","published":"2025-04-30T17:08:27Z"}
{"aid":"http://arxiv.org/abs/2504.21813v1","title":"Turning a negative neutrino mass into a positive optical depth","summary":"Under $\\Lambda$CDM, recent baryon acoustic oscillation (BAO) distance\nmeasures from DESI, which favor a low matter density $\\Omega_m$, are in\nmoderate $2-3\\sigma$ tension with cosmic microwave background (CMB)\nobservations. This tension appears alternately as a preference for the sum of\nneutrino masses dropping below the $\\sum m_\\nu = 0.06$eV value required by\nneutrino oscillation measurements to formally negative values; a discrepant\nvalue of $\\Omega_m$ at 0.06eV; or preference for dynamical dark energy beyond\n$\\Lambda$CDM. We show that this tension largely arises from the CMB lensing\nconstraints on the calibration of the sound horizon for geometric measurements\nand relies on the measurement of the reionization optical depth $\\tau$ from\nlarge-angle CMB polarization to set the lensing amplitude. Dropping these\nconstraints removes the neutrino tension at $\\sum m_\\nu=0.06$eV entirely,\nfavoring $\\tau = 0.091\\pm 0.011$ in $\\Lambda$CDM. Beyond $\\Lambda$CDM, it\nbrings the preference for $w_0-w_a$ dynamical dark energy to below $95\\%$ CL.\nWe explore the freedom in interpreting the low-$\\ell$ EE polarization\nconstraint due to analysis choices and reionization modeling beyond the\nstandard step-function assumption and find that this drops the neutrino tension\nin $\\Lambda$CDM to below $95\\%$ CL. Alternately, this raising of $\\tau$ can\nalso be achieved by the same reduction in large-scale curvature fluctuations\nthat also ameliorates the low-$\\ell$ temperature anomaly.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-30T17:16:54Z"}
{"aid":"http://arxiv.org/abs/2504.21818v1","title":"Topology, Kinetics and Inheritance in Clonal Colonies of Bone Marrow\n  Stromal Cells","summary":"Bone marrow stromal cells (BMSCs), whose populations contain multipotent\nskeletal stem cells with relevant therapeutic applications, are known to\nproduce very heterogeneous colonies upon in vitro culture, a trait that may\nseverely hinder the clinical usefulness of BMSC-based therapies. Therefore,\nreaching a better insight on the nature of such heterogeneity, as well as on\nthe factors determining it, is important. Here, by using time-lapse microscopy,\nwe study the structure of N=28 human BMSC colonies from six donors, each colony\nderived from a single cell, and trace their lineage trees up to the seventh\ngeneration. We confirm the presence of very significant inter-colony and\nintra-colony heterogeneities, both in the topology of the lineages and in the\nreplicative kinetics of the colonies. We also find that topology and kinetics\nare strongly correlated, consistent with the existence of regulating factors\nlinking the sub-population of inactive cells, which uniquely determine a\nlineage's topology, and that of active cells, which are the sole responsible\nfor the proliferation rate of the colony. Finally, we submit each colony to an\nentropy-based inheritance test, which measures the degree of non-random\nclustering of inactive cells within the same branches of the lineage, and find\na clear signature of hereditary transmission of the probability of emergence of\ninactive cells in the largest majority of the experimental lineages.","main_category":"q-bio.CB","categories":"q-bio.CB,cond-mat.stat-mech,physics.bio-ph","published":"2025-04-30T17:24:21Z"}
{"aid":"http://arxiv.org/abs/2504.21834v1","title":"Advances on a conjecture about free divisors","summary":"In 2002, it was conjectured that a free divisor satisfying the so-called\nLogarithmic Comparison Theorem (LCT) must be strongly Euler-homogeneous. Today,\nit is known to be true only in ambient dimension less or equal than three or\nassuming Koszul-freeness. Thanks to our advances in the comprehension of strong\nEuler-homogeneity, we are able to prove the conjecture in the following new\ncases: assuming strong Euler-homogeneity on a punctured neighbourhood of a\npoint; assuming the divisor is weakly Koszul-free; for ambient dimension $n=4$;\nfor linear free divisors in ambient dimension $n=5$. We also refute a\nconjecture that states that all linear free divisors satisfy LCT and are\nstrongly Euler-homogeneous.","main_category":"math.AG","categories":"math.AG,math.CV","published":"2025-04-30T17:43:17Z"}
{"aid":"http://arxiv.org/abs/2504.21855v1","title":"ReVision: High-Quality, Low-Cost Video Generation with Explicit 3D\n  Physics Modeling for Complex Motion and Interaction","summary":"In recent years, video generation has seen significant advancements. However,\nchallenges still persist in generating complex motions and interactions. To\naddress these challenges, we introduce ReVision, a plug-and-play framework that\nexplicitly integrates parameterized 3D physical knowledge into a pretrained\nconditional video generation model, significantly enhancing its ability to\ngenerate high-quality videos with complex motion and interactions.\nSpecifically, ReVision consists of three stages. First, a video diffusion model\nis used to generate a coarse video. Next, we extract a set of 2D and 3D\nfeatures from the coarse video to construct a 3D object-centric representation,\nwhich is then refined by our proposed parameterized physical prior model to\nproduce an accurate 3D motion sequence. Finally, this refined motion sequence\nis fed back into the same video diffusion model as additional conditioning,\nenabling the generation of motion-consistent videos, even in scenarios\ninvolving complex actions and interactions. We validate the effectiveness of\nour approach on Stable Video Diffusion, where ReVision significantly improves\nmotion fidelity and coherence. Remarkably, with only 1.5B parameters, it even\noutperforms a state-of-the-art video generation model with over 13B parameters\non complex video generation by a substantial margin. Our results suggest that,\nby incorporating 3D physical knowledge, even a relatively small video diffusion\nmodel can generate complex motions and interactions with greater realism and\ncontrollability, offering a promising solution for physically plausible video\ngeneration.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T17:59:56Z"}
{"aid":"http://arxiv.org/abs/2505.00305v1","title":"Iterations of Meromorphic Functions involving Sine","summary":"In this article, the dynamics of a one-parameter family of functions\n$f_{\\lambda}(z) = \\frac{\\sin{z}}{z^2 + \\lambda},$ $\\lambda>0$, are studied. It\nshows the existence of parameters $0< \\lambda_{1}< \\lambda_{2}$ such that\nbifurcations occur at $\\lambda_1$ and $\\lambda_2$ for $f_{\\lambda}$. It is\nproved that the Fatou set $\\mathcal{F}(f_{\\lambda})$ is the union of basins of\nattraction in the complex plane for $\\lambda \\in (\\lambda_1, \\lambda_2) \\cup\n(\\lambda_2, \\infty)$. Further, every Fatou component of $f_{\\lambda}$ is simply\nconnected for $\\lambda \\geq \\lambda_1$. The boundary of the Fatou set\n$\\mathcal{F}(f_{\\lambda})$ is the Julia set $\\mathcal{J}(f_{\\lambda})$ in the\nextended complex plane for $\\lambda> 1$. Interestingly, it is found that\n$f_{\\lambda}$ has only one completely invariant Fatou component, say\n$U_\\lambda$ such that $\\mathcal{F}(f_{\\lambda}) = U_{\\lambda}$ for $\\lambda\n>\\lambda_2$. Moreover, the characterization of the Julia set of $f_{\\lambda}$\nis seen for $\\lambda \\in (\\lambda_1, \\infty)\\setminus \\{\\lambda_2\\}$.","main_category":"math.DS","categories":"math.DS","published":"2025-05-01T04:57:20Z"}
{"aid":"http://arxiv.org/abs/2505.00374v1","title":"Towards Lightweight Hyperspectral Image Super-Resolution with Depthwise\n  Separable Dilated Convolutional Network","summary":"Deep neural networks have demonstrated highly competitive performance in\nsuper-resolution (SR) for natural images by learning mappings from\nlow-resolution (LR) to high-resolution (HR) images. However, hyperspectral\nsuper-resolution remains an ill-posed problem due to the high spectral\ndimensionality of the data and the scarcity of available training samples.\nMoreover, existing methods often rely on large models with a high number of\nparameters or require the fusion with panchromatic or RGB images, both of which\nare often impractical in real-world scenarios. Inspired by the MobileNet\narchitecture, we introduce a lightweight depthwise separable dilated\nconvolutional network (DSDCN) to address the aforementioned challenges.\nSpecifically, our model leverages multiple depthwise separable convolutions,\nsimilar to the MobileNet architecture, and further incorporates a dilated\nconvolution fusion block to make the model more flexible for the extraction of\nboth spatial and spectral features. In addition, we propose a custom loss\nfunction that combines mean squared error (MSE), an L2 norm\nregularization-based constraint, and a spectral angle-based loss, ensuring the\npreservation of both spectral and spatial details. The proposed model achieves\nvery competitive performance on two publicly available hyperspectral datasets,\nmaking it well-suited for hyperspectral image super-resolution tasks. The\nsource codes are publicly available at:\n\\href{https://github.com/Usman1021/lightweight}{https://github.com/Usman1021/lightweight}.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-05-01T07:57:23Z"}
{"aid":"http://arxiv.org/abs/2505.00401v1","title":"Size-Dependent Tensile Behavior and Dislocation Dynamics in Cu and Ag\n  Nanowires: A Molecular Dynamics Study","summary":"By using molecular dynamics simulations, the research examine how copper and\nsilver nanowires respond to tensile loading in order to clarify their nanoscale\ndeformation mechanisms. The results demonstrate that these two metal nanowires\nfollow notably different stress - strain trends, with silver wires exhibiting\ngreater elastic stiffness and higher yield points at equivalent diameters - an\neffect likely rooted in silver's stronger atomic bonding and more stable\nmicrostructure. A pronounced size effect is observed: as the wire diameter\ndiminishes, both the yield strength and ultimate tensile strength increase\nsubstantially, a behavior driven by the higher proportion of surface atoms that\nenhance dislocation nucleation and mobility. Atomistic analyses further\nunderscore the dominant role of dislocations during plastic deformation, and in\nparticular reveal that surface - initiated dislocations in thinner wires\ncritically affect their fracture behavior.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.comp-ph","published":"2025-05-01T08:47:27Z"}
{"aid":"http://arxiv.org/abs/2505.00406v1","title":"Quantum Littlewood correspondences","summary":"In the 1940s Littlewood formulated three fundamental correspondences for the\nimmanants and Schur symmetric functions on the general linear group, which\nestablish deep connections between representation theory of the symmetric group\nand the general linear group parallel to the Schur-Weyl duality. In this paper,\nwe introduce the notion of quantum immanants in the quantum coordinate algebra\nusing primitive idempotents of the Hecke algebra. By employing $R$-matrix\ntechniques, we establish the quantum analog of Littlewood correspondences\nbetween quantum immanants and Schur functions for the quantum coordinate\nalgebra. In the setting of the Schur-Weyl-Jimbo duality, we construct an exact\ncorrespondence between the Gelfand-Tsetlin bases of the irreducible\nrepresentations of the quantum enveloping algebra $U_q(\\mathfrak{gl}(n))$ and\nYoung's orthonormal basis of an irreducible representation of the Hecke algebra\n$\\mathcal H_m$. This isomorphism leads to our trace formula for the quantum\nimmanants, which settled the generalization problem\n  of $q$-analog of Kostant's formular for $\\lambda$-immanants. As applications,\nwe also derive general $q$-Littlewood-Merris-Watkins identities and\n$q$-Goulden-Jackson identities as special cases of the quantum Littlewood\ncorrespondence III.","main_category":"math.RT","categories":"math.RT,math.CO,math.QA","published":"2025-05-01T08:56:33Z"}
{"aid":"http://arxiv.org/abs/2505.00411v1","title":"Affine matrix scrambling achieves smoothness-dependent convergence rates","summary":"We study the convergence rate of the median estimator for affine matrix\nscrambled digital nets applied to integrands over the unit hypercube $[0,\n1]^s$. By taking the median of $(2r-1)$ independent randomized quasi-Monte\nCarlo (RQMC) samples, we demonstrate that the desired convergence rates can be\nachieved without increasing the number of randomizations $r$ as the quadrature\nsize $N$ grows for both bounded and unbounded integrands. For unbounded\nintegrands, our analysis assumes a boundary growth condition on the weak\nderivatives and also considers singularities such as kinks and jump\ndiscontinuities. Notably, when $r = 1$, the median estimator reduces to the\nstandard RQMC estimator. By applying analytical techniques developed for median\nestimators, we prove that the affine matrix scrambled estimator achieves a\nconvergence rate depending on the integrand's smoothness, and is therefore not\nlimited by the canonical rate $\\mathcal{O}(N^{-3/2})$. However, this\nsmoothness-dependent theoretical rate is not observed empirically in numerical\nexperiments when the affine matrix scrambling yields a heavy-tailed sampling\ndistribution. In contrast, the median estimator consistently reveals the\ntheoretical rates and yields smaller integration errors than mean estimators,\nfurther highlighting its advantages.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-05-01T09:09:58Z"}
{"aid":"http://arxiv.org/abs/2505.00425v1","title":"A census of face-transitive surfaces","summary":"A face-transitive surface is a triangulated 2-dimensional manifold whose\nautomorphism group acts transitively on its set of triangles. In this paper, we\ninvestigate this class of highly symmetric surface triangulations. We identify\nseven types of such face-transitive surfaces, splitting up further into a total\nof thirteen sub-types, distinguished by how their automorphism groups act on\nthem. We use these theoretical results to compute a census of face-transitive\nsurfaces with up to 1280 faces by constructing suitable cycle double covers of\ncubic node-transitive graphs.","main_category":"math.CO","categories":"math.CO","published":"2025-05-01T09:52:10Z"}
{"aid":"http://arxiv.org/abs/2505.00429v1","title":"On the structure of big bang singularities in spatially homogenous\n  solutions to the Einstein non-linear scalar field equations","summary":"The subject of this article is the structure of big bang singularities in\nspatially homogeneous solutions to the Einstein non-linear scalar field\nequations. In particular, we focus on Bianchi class A; i.e., developments\narising from left invariant initial data on unimodular $3$-dimensional Lie\ngroups. We prove that solutions are either vacuum or matter dominated,\ndepending on whether the limit of an expansion normalised normal derivative of\nthe scalar field is zero or not, respectively. The main result concerning the\nasymptotics in the direction of the singularity is, essentially, that solutions\ninduce data on the singularity, with two exceptions: vacuum dominated Bianchi\ntype VIII and IX without additional symmetries (they are neither isotropic nor\nlocally rotationally symmetric) exhibit BKL-type oscillations. Disregarding the\nexceptions, there is in fact a bijection between initial data on the\nsingularity and developments. Initial data on the singularity thus play a\ncentral role in the analysis; they both parameterise developments and give\noptimal asymptotic information. However, the main point of the article is to\nprove that the set of isometry classes of initial data on the singularity (of a\nfixed Bianchi type and symmetry (such as isotropy, local rotational symmetry\netc.)) has a smooth structure; that the set of isometry classes of developments\n(similarly restricted) has a smooth structure which fits together with the\nnatural smooth structure of isometry classes of regular initial data with fixed\nmean curvature; and that the Einstein flow generates a diffeomorphism between\nthe two sets. However, the article contains substantial additional information,\nsuch as, e.g., the construction of a large class of spatially locally\nhomogeneous solutions that can be demonstrated to be globally non-linearly\nstable (in the absence of symmetries) both to the future and to the past.","main_category":"gr-qc","categories":"gr-qc,math-ph,math.MP","published":"2025-05-01T09:58:07Z"}
{"aid":"http://arxiv.org/abs/2505.00434v1","title":"Stability of the first-order unified gas-kinetic scheme based on a\n  linear kinetic model","summary":"The unified gas-kinetic scheme (UGKS) is becoming increasingly popular for\nmultiscale simulations in all flow regimes. This paper provides the first\nanalytical study on the stability of the UGKS applied to a linear kinetic\nmodel, which is able to reproduce the one-dimensional linear scalar\nadvection-diffusion equation via the Chapman-Enskog expansion method. Adopting\nperiodic boundary conditions and neglecting the error from numerical\nintegration, this paper rigorously proves the weighted $L^2$-stability of the\nfirst-order UGKS under the Courant-Friedrichs-Lewy (CFL) conditions. It is\nshown that the time step of the method is not constrained by being less than\nthe particle collision time, nor is it limited by parabolic type CFL conditions\ntypically applied in solving diffusion equations. The novelty of the proof lies\nin that based on the ratio of the time step to the particle collision time, the\nupdate of distribution functions is viewed as a convex combinations of\nsub-methods related to various physics processes, such as the particle free\ntransport and collisions. The weighted $L^2$-stability of the sub-methods is\nobtained by considering them as discretizations to corresponding linear\nhyperbolic systems and utilizing the associated Riemann invariants. Finally,\nthe strong stability preserving property of the UGKS leads to the desired\nweighted $L^2$-stability.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-05-01T10:12:07Z"}
{"aid":"http://arxiv.org/abs/2505.00447v1","title":"Deterministic Scheduling over Wi-Fi 6 using Target Wake Time: An\n  Experimental Approach","summary":"Wi-Fi networks traditionally use Distributed Coordination Function (DCF) that\nemploys CSMA/CA along with the binary backoff mechanism for channel access.\nThis causes unavoidable contention overheads and does not provide performance\nguarantees. In this work, we outline some issues that occur with the\nprobabilistic channel access in highly congested scenarios and how those can be\nmitigated using deterministic scheduling. Towards this, we propose to use\nTarget Wake Time (TWT) - a feature introduced in Wi-Fi 6 as a power-saving\nmechanism, to improve the performance of Wi-Fi. To gain insights into the\nworkings of the TWT over commercially available off-the-shelf components and to\nanalyze the factors that affect its performance, we carry out various\nexperiments with it over our Wi-Fi 6 testbed. Using these insights and\nanalysis, we formulate and solve an optimization problem to synthesize\ndeterministic schedules and obtain the optimal values of various system\nparameters. Lastly, we configure our testbed with these optimal parameter\nvalues and show that the TWT based deterministic scheduling consistently\nresults in better performance of the TWT-capable clients and overall system\nperformance compared to traditional CSMA/CA based scheduling.","main_category":"cs.NI","categories":"cs.NI","published":"2025-05-01T10:43:01Z"}
{"aid":"http://arxiv.org/abs/2505.00502v1","title":"Towards Scalable Human-aligned Benchmark for Text-guided Image Editing","summary":"A variety of text-guided image editing models have been proposed recently.\nHowever, there is no widely-accepted standard evaluation method mainly due to\nthe subjective nature of the task, letting researchers rely on manual user\nstudy. To address this, we introduce a novel Human-Aligned benchmark for\nText-guided Image Editing (HATIE). Providing a large-scale benchmark set\ncovering a wide range of editing tasks, it allows reliable evaluation, not\nlimited to specific easy-to-evaluate cases. Also, HATIE provides a\nfully-automated and omnidirectional evaluation pipeline. Particularly, we\ncombine multiple scores measuring various aspects of editing so as to align\nwith human perception. We empirically verify that the evaluation of HATIE is\nindeed human-aligned in various aspects, and provide benchmark results on\nseveral state-of-the-art models to provide deeper insights on their\nperformance.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-01T13:06:05Z"}
{"aid":"http://arxiv.org/abs/2505.00503v1","title":"Variational OOD State Correction for Offline Reinforcement Learning","summary":"The performance of Offline reinforcement learning is significantly impacted\nby the issue of state distributional shift, and out-of-distribution (OOD) state\ncorrection is a popular approach to address this problem. In this paper, we\npropose a novel method named Density-Aware Safety Perception (DASP) for OOD\nstate correction. Specifically, our method encourages the agent to prioritize\nactions that lead to outcomes with higher data density, thereby promoting its\noperation within or the return to in-distribution (safe) regions. To achieve\nthis, we optimize the objective within a variational framework that\nconcurrently considers both the potential outcomes of decision-making and their\ndensity, thus providing crucial contextual information for safe\ndecision-making. Finally, we validate the effectiveness and feasibility of our\nproposed method through extensive experimental evaluations on the offline\nMuJoCo and AntMaze suites.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.RO","published":"2025-05-01T13:14:07Z"}
{"aid":"http://arxiv.org/abs/2505.00530v1","title":"Leveraging Partial SMILES Validation Scheme for Enhanced Drug Design in\n  Reinforcement Learning Frameworks","summary":"SMILES-based molecule generation has emerged as a powerful approach in drug\ndiscovery. Deep reinforcement learning (RL) using large language model (LLM)\nhas been incorporated into the molecule generation process to achieve high\nmatching score in term of likelihood of desired molecule candidates. However, a\ncritical challenge in this approach is catastrophic forgetting during the RL\nphase, where knowledge such as molecule validity, which often exceeds 99\\%\nduring pretraining, significantly deteriorates. Current RL algorithms applied\nin drug discovery, such as REINVENT, use prior models as anchors to retian\npretraining knowledge, but these methods lack robust exploration mechanisms. To\naddress these issues, we propose Partial SMILES Validation-PPO (PSV-PPO), a\nnovel RL algorithm that incorporates real-time partial SMILES validation to\nprevent catastrophic forgetting while encouraging exploration. Unlike\ntraditional RL approaches that validate molecule structures only after\ngenerating entire sequences, PSV-PPO performs stepwise validation at each\nauto-regressive step, evaluating not only the selected token candidate but also\nall potential branches stemming from the prior partial sequence. This enables\nearly detection of invalid partial SMILES across all potential paths. As a\nresult, PSV-PPO maintains high validity rates even during aggressive\nexploration of the vast chemical space. Our experiments on the PMO and GuacaMol\nbenchmark datasets demonstrate that PSV-PPO significantly reduces the number of\ninvalid generated structures while maintaining competitive exploration and\noptimization performance. While our work primarily focuses on maintaining\nvalidity, the framework of PSV-PPO can be extended in future research to\nincorporate additional forms of valuable domain knowledge, further enhancing\nreinforcement learning applications in drug discovery.","main_category":"cs.LG","categories":"cs.LG,cs.CE,q-bio.BM","published":"2025-05-01T13:57:20Z"}
{"aid":"http://arxiv.org/abs/2505.00539v1","title":"Unified QMF equation of state for neutron star matter: Static and\n  dynamic properties","summary":"We construct a set of unified equations of state based on the quark mean\nfield (QMF) model, calibrated to different values of nuclear symmetry energy\nslope at the saturation density ($L_0$), with the aim of exploring both the\nstatic properties and dynamical behavior of neutron stars (NSs), and building a\ncoherent picture of their internal structure. We assess the performance of\nthese QMF models in describing the mass-radius relation, the cooling evolution\nof isolated NSs and X-ray transients, and the instabilities (e.g., the r-mode).\nIn comparison to relativistic mean field (RMF) models formulated at the\nhadronic level, the QMF model predicts heavier nuclear clusters and larger\nWigner-Seitz cell sizes in the NS crust, while the density of the free neutron\ngas remains largely similar between the two approaches. For the cooling of\nisolated NSs, the thermal evolution is found to be insensitive to both the\nmany-body model and the symmetry energy slope in the absence of the direct Urca\n(dUrca) process. However, when rapid cooling via the dUrca process is allowed,\nin the case of large $L_0$ values (e.g., $L_0 \\gtrsim 80$ MeV) in our study,\nthe QMF model predicts a longer thermal relaxation time. Both the QMF and RMF\nmodels can reproduce cooling curves consistent with observations of X-ray\ntransients (e.g., KS 1731--260) during their crustal cooling phase, although\nstellar parameters show slight variations depending on the model and symmetry\nenergy slope. Within our unified framework, a larger $L_0$ value generally\nresults in a wider instability window, while increasing the stellar mass tends\nto suppress the instability window. We also provide simple power-law\nparameterizations that quantify the dependence of bulk and shear viscosities on\nthe symmetry energy slope for nuclear matter at saturation density.","main_category":"nucl-th","categories":"nucl-th,astro-ph.HE","published":"2025-05-01T14:05:15Z"}
{"aid":"http://arxiv.org/abs/2505.00546v1","title":"Directly Forecasting Belief for Reinforcement Learning with Delays","summary":"Reinforcement learning (RL) with delays is challenging as sensory perceptions\nlag behind the actual events: the RL agent needs to estimate the real state of\nits environment based on past observations. State-of-the-art (SOTA) methods\ntypically employ recursive, step-by-step forecasting of states. This can cause\nthe accumulation of compounding errors. To tackle this problem, our novel\nbelief estimation method, named Directly Forecasting Belief Transformer (DFBT),\ndirectly forecasts states from observations without incrementally estimating\nintermediate states step-by-step. We theoretically demonstrate that DFBT\ngreatly reduces compounding errors of existing recursively forecasting methods,\nyielding stronger performance guarantees. In experiments with D4RL offline\ndatasets, DFBT reduces compounding errors with remarkable prediction accuracy.\nDFBT's capability to forecast state sequences also facilitates multi-step\nbootstrapping, thus greatly improving learning efficiency. On the MuJoCo\nbenchmark, our DFBT-based method substantially outperforms SOTA baselines.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-01T14:20:48Z"}
{"aid":"http://arxiv.org/abs/2505.00555v1","title":"On the Mechanistic Interpretability of Neural Networks for Causality in\n  Bio-statistics","summary":"Interpretable insights from predictive models remain critical in\nbio-statistics, particularly when assessing causality, where classical\nstatistical and machine learning methods often provide inherent clarity. While\nNeural Networks (NNs) offer powerful capabilities for modeling complex\nbiological data, their traditional \"black-box\" nature presents challenges for\nvalidation and trust in high-stakes health applications. Recent advances in\nMechanistic Interpretability (MI) aim to decipher the internal computations\nlearned by these networks. This work investigates the application of MI\ntechniques to NNs within the context of causal inference for bio-statistics.\n  We demonstrate that MI tools can be leveraged to: (1) probe and validate the\ninternal representations learned by NNs, such as those estimating nuisance\nfunctions in frameworks like Targeted Minimum Loss-based Estimation (TMLE); (2)\ndiscover and visualize the distinct computational pathways employed by the\nnetwork to process different types of inputs, potentially revealing how\nconfounders and treatments are handled; and (3) provide methodologies for\ncomparing the learned mechanisms and extracted insights across statistical,\nmachine learning, and NN models, fostering a deeper understanding of their\nrespective strengths and weaknesses for causal bio-statistical analysis.","main_category":"stat.AP","categories":"stat.AP,cs.AI","published":"2025-05-01T14:30:34Z"}
{"aid":"http://arxiv.org/abs/2505.00561v1","title":"Learning to Learn with Quantum Optimization via Quantum Neural Networks","summary":"Quantum Approximate Optimization Algorithms (QAOA) promise efficient\nsolutions to classically intractable combinatorial optimization problems by\nharnessing shallow-depth quantum circuits. Yet, their performance and\nscalability often hinge on effective parameter optimization, which remains\nnontrivial due to rugged energy landscapes and hardware noise. In this work, we\nintroduce a quantum meta-learning framework that combines quantum neural\nnetworks, specifically Quantum Long Short-Term Memory (QLSTM) architectures,\nwith QAOA. By training the QLSTM optimizer on smaller graph instances, our\napproach rapidly generalizes to larger, more complex problems, substantially\nreducing the number of iterations required for convergence. Through\ncomprehensive benchmarks on Max-Cut and Sherrington-Kirkpatrick model\ninstances, we demonstrate that QLSTM-based optimizers converge faster and\nachieve higher approximation ratios compared to classical baselines, thereby\noffering a robust pathway toward scalable quantum optimization in the NISQ era.","main_category":"quant-ph","categories":"quant-ph,cs.AI","published":"2025-05-01T14:39:26Z"}
{"aid":"http://arxiv.org/abs/2505.00567v1","title":"Error Exponents for Oblivious Relaying and Connections to Source Coding\n  with a Helper","summary":"The information bottleneck channel, also known as oblivious relaying, is a\ntwo-hop channel where a transmitter sends messages to a remote receiver via an\nintermediate relay node. A codeword sent by the transmitter passes through a\ndiscrete memoryless channel to reach the relay, and then the relay processes\nthe noisy channel output and forwards it to the receiver through a noiseless\nrate-limited link. The relay is oblivious, in the sense that it has no\nknowledge of the channel codebook used in transmission. Past works on oblivious\nrelaying are focused on characterizing achievable rates. In this work, we study\nerror exponents and explore connections to loseless source coding with a\nhelper, also known as the Wyner-Ahlswede-K\\\"orner (WAK) problem. We first\nestablish an achievable error exponent for oblivious relaying under constant\ncompositions codes. A key feature of our analysis is the use of the type\ncovering lemma to design the relay's compress-forward scheme. We then show that\nemploying constant composition code ensembles does not improve the rates\nachieved with their IID counterparts. We also derive a sphere packing upper\nbound for the error exponent. In the second part of this paper, we establish a\nconnection between the information bottleneck channel and the WAK problem. We\nshow that good codes for the latter can be produced through permuting codes\ndesigned for the former. This is accomplished by revisiting Ahlswede's covering\nlemma, and extending it to achieve simultaneous covering of a type class by\nseveral distinct sets using the same sequence of permutations. We then apply\nour approach to attain the best known achievable error exponent for the WAK\nproblem, previously established by Kelly and Wagner. As a byproduct of our\nderivations, we also establish error exponents and achievable rates under\nmismatched decoding rules.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-05-01T14:50:51Z"}
{"aid":"http://arxiv.org/abs/2505.00576v1","title":"Narrow Inhomogeneous Distribution and Charge State Stabilization of\n  Lead-Vacancy Centers in Diamond","summary":"Lead-vacancy (PbV) centers in diamond with a large ground state splitting are\nexpected to be a building block of quantum network nodes. Due to the heaviness\nof the Pb atom, it is challenging to fabricate high-quality PbV centers with a\nnarrow inhomogeneous distribution and stable charge state. In this study, for\nthe formation of the PbV centers, high temperature anneal up to 2300{\\deg}C is\nperformed after Pb ion implantation. At a lower temperature of 1800{\\deg}C, the\nPbV centers show a large inhomogeneous distribution and spectral diffusion,\nwhile higher temperatures of 2200-2300{\\deg}C leads to narrow inhomogeneous\ndistributions with standard deviations of ~5 GHz. The charge state transition\nof the PbV centers formed at 2200{\\deg}C occurs by capturing photo-carriers\ngenerated from surrounding defects under 532 nm laser irradiation. Finally,\nmultiple stable PbV centers with nearly identical photon frequencies are\nobtained, which is essential for applications in quantum information\nprocessing.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-01T15:02:10Z"}
{"aid":"http://arxiv.org/abs/2505.00591v1","title":"Explainable AI in Spatial Analysis","summary":"This chapter discusses the opportunities of eXplainable Artificial\nIntelligence (XAI) within the realm of spatial analysis. A key objective in\nspatial analysis is to model spatial relationships and infer spatial processes\nto generate knowledge from spatial data, which has been largely based on\nspatial statistical methods. More recently, machine learning offers scalable\nand flexible approaches that complement traditional methods and has been\nincreasingly applied in spatial data science. Despite its advantages, machine\nlearning is often criticized for being a black box, which limits our\nunderstanding of model behavior and output. Recognizing this limitation, XAI\nhas emerged as a pivotal field in AI that provides methods to explain the\noutput of machine learning models to enhance transparency and understanding.\nThese methods are crucial for model diagnosis, bias detection, and ensuring the\nreliability of results obtained from machine learning models. This chapter\nintroduces key concepts and methods in XAI with a focus on Shapley value-based\napproaches, which is arguably the most popular XAI method, and their\nintegration with spatial analysis. An empirical example of county-level voting\nbehaviors in the 2020 Presidential election is presented to demonstrate the use\nof Shapley values and spatial analysis with a comparison to multi-scale\ngeographically weighted regression. The chapter concludes with a discussion on\nthe challenges and limitations of current XAI techniques and proposes new\ndirections.","main_category":"cs.LG","categories":"cs.LG,econ.EM","published":"2025-05-01T15:25:23Z"}
{"aid":"http://arxiv.org/abs/2505.00626v1","title":"The Illusion of Role Separation: Hidden Shortcuts in LLM Role Learning\n  (and How to Fix Them)","summary":"Large language models (LLMs) that integrate multiple input roles (e.g.,\nsystem instructions, user queries, external tool outputs) are increasingly\nprevalent in practice. Ensuring that the model accurately distinguishes\nmessages from each role -- a concept we call \\emph{role separation} -- is\ncrucial for consistent multi-role behavior. Although recent work often targets\nstate-of-the-art prompt injection defenses, it remains unclear whether such\nmethods truly teach LLMs to differentiate roles or merely memorize known\ntriggers. In this paper, we examine \\emph{role-separation learning}: the\nprocess of teaching LLMs to robustly distinguish system and user tokens.\nThrough a \\emph{simple, controlled experimental framework}, we find that\nfine-tuned models often rely on two proxies for role identification: (1) task\ntype exploitation, and (2) proximity to begin-of-text. Although data\naugmentation can partially mitigate these shortcuts, it generally leads to\niterative patching rather than a deeper fix. To address this, we propose\nreinforcing \\emph{invariant signals} that mark role boundaries by adjusting\ntoken-wise cues in the model's input encoding. In particular, manipulating\nposition IDs helps the model learn clearer distinctions and reduces reliance on\nsuperficial proxies. By focusing on this mechanism-centered perspective, our\nwork illuminates how LLMs can more reliably maintain consistent multi-role\nbehavior without merely memorizing known prompts or triggers.","main_category":"cs.CL","categories":"cs.CL,cs.AI,I.2","published":"2025-05-01T16:06:16Z"}
{"aid":"http://arxiv.org/abs/2505.00633v1","title":"Strong Rigidity and Elementary Embeddings","summary":"We present a method for producing elementary embeddings from homomorphisms.\nThis method is utilized in the study of the \"strongly rigid relation principle\"\nas defined by Hamkins and Palumbo in their paper \"The Rigid Relation Principle,\na New Weak Choice Principle.\" We establish that the strongly rigid relation\nprinciple is also a weak choice principle that is independent of ZF. Finally,\nwe characterize proto Berkeley cardinals in terms of a strong failure of the\nstrongly rigid relation principle.","main_category":"math.LO","categories":"math.LO","published":"2025-05-01T16:17:49Z"}
{"aid":"http://arxiv.org/abs/2505.00634v1","title":"Forward kinematics of a general Stewart-Gough platform by elimination\n  templates","summary":"The paper proposes an efficient algebraic solution to the problem of forward\nkinematics for a general Stewart-Gough platform. The problem involves\ndetermining all possible postures of a mobile platform connected to a fixed\nbase by six legs, given the leg lengths and the internal geometries of the\nplatform and base. The problem is known to have 40 solutions (whether real or\ncomplex). The proposed algorithm consists of three main steps: (i) a specific\nsparse matrix of size 293x362 (the elimination template) is constructed from\nthe coefficients of the polynomial system describing the platform's kinematics;\n(ii) the PLU decomposition of this matrix is used to construct a pair of 69x69\nmatrices; (iii) all 40 solutions (including complex ones) are obtained by\ncomputing the generalized eigenvectors of this matrix pair. The proposed\nalgorithm is numerically robust, computationally efficient, and straightforward\nto implement - requiring only standard linear algebra decompositions. MATLAB,\nJulia, and Python implementations of the algorithm will be made publicly\navailable.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-01T16:18:07Z"}
{"aid":"http://arxiv.org/abs/2505.00681v1","title":"MINERVA: Evaluating Complex Video Reasoning","summary":"Multimodal LLMs are turning their focus to video benchmarks, however most\nvideo benchmarks only provide outcome supervision, with no intermediate or\ninterpretable reasoning steps. This makes it challenging to assess if models\nare truly able to combine perceptual and temporal information to reason about\nvideos, or simply get the correct answer by chance or by exploiting linguistic\nbiases. To remedy this, we provide a new video reasoning dataset called MINERVA\nfor modern multimodal models. Each question in the dataset comes with 5 answer\nchoices, as well as detailed, hand-crafted reasoning traces. Our dataset is\nmultimodal, diverse in terms of video domain and length, and consists of\ncomplex multi-step questions. Extensive benchmarking shows that our dataset\nprovides a challenge for frontier open-source and proprietary models. We\nperform fine-grained error analysis to identify common failure modes across\nvarious models, and create a taxonomy of reasoning errors. We use this to\nexplore both human and LLM-as-a-judge methods for scoring video reasoning\ntraces, and find that failure modes are primarily related to temporal\nlocalization, followed by visual perception errors, as opposed to logical or\ncompleteness errors. The dataset, along with questions, answer candidates and\nreasoning traces will be publicly available under\nhttps://github.com/google-deepmind/neptune?tab=readme-ov-file\\#minerva.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-05-01T17:41:49Z"}
{"aid":"http://arxiv.org/abs/2505.00702v1","title":"RayZer: A Self-supervised Large View Synthesis Model","summary":"We present RayZer, a self-supervised multi-view 3D Vision model trained\nwithout any 3D supervision, i.e., camera poses and scene geometry, while\nexhibiting emerging 3D awareness. Concretely, RayZer takes unposed and\nuncalibrated images as input, recovers camera parameters, reconstructs a scene\nrepresentation, and synthesizes novel views. During training, RayZer relies\nsolely on its self-predicted camera poses to render target views, eliminating\nthe need for any ground-truth camera annotations and allowing RayZer to be\ntrained with 2D image supervision. The emerging 3D awareness of RayZer is\nattributed to two key factors. First, we design a self-supervised framework,\nwhich achieves 3D-aware auto-encoding of input images by disentangling camera\nand scene representations. Second, we design a transformer-based model in which\nthe only 3D prior is the ray structure, connecting camera, pixel, and scene\nsimultaneously. RayZer demonstrates comparable or even superior novel view\nsynthesis performance than ``oracle'' methods that rely on pose annotations in\nboth training and testing. Project: https://hwjiang1510.github.io/RayZer/","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-01T17:59:34Z"}
{"aid":"http://arxiv.org/abs/2505.03157v1","title":"A Regeneration-based a Posteriori Error Bound for a Markov Chain\n  Stationary Distribution Truncation Algorithm","summary":"When the state space of a discrete state space positive recurrent Markov\nchain is infinite or very large, it becomes necessary to truncate the state\nspace in order to facilitate numerical computation of the stationary\ndistribution. This paper develops a new approach for bounding the truncation\nerror that arises when computing approximations to the stationary distribution.\nThis rigorous a posteriori error bound exploits the regenerative structure of\nthe chain and assumes knowledge of a Lyapunov function. Because the bound is a\nposteriori (and leverages the computations done to calculate the stationary\ndistribution itself), it tends to be much tighter than a priori bounds. The\nbound decomposes the regenerative cycle into a random number of excursions from\na set $K$ defined in terms of the Lyapunov function into the complement of the\ntruncation set $A$. The bound can be easily computed, and does not (for\nexample) involve a linear program, as do some other error bounds.","main_category":"math.PR","categories":"math.PR,cs.NA,math.NA","published":"2025-05-06T04:10:09Z"}
{"aid":"http://arxiv.org/abs/2505.03178v1","title":"RADE: Learning Risk-Adjustable Driving Environment via Multi-Agent\n  Conditional Diffusion","summary":"Generating safety-critical scenarios in high-fidelity simulations offers a\npromising and cost-effective approach for efficient testing of autonomous\nvehicles. Existing methods typically rely on manipulating a single vehicle's\ntrajectory through sophisticated designed objectives to induce adversarial\ninteractions, often at the cost of realism and scalability. In this work, we\npropose the Risk-Adjustable Driving Environment (RADE), a simulation framework\nthat generates statistically realistic and risk-adjustable traffic scenes.\nBuilt upon a multi-agent diffusion architecture, RADE jointly models the\nbehavior of all agents in the environment and conditions their trajectories on\na surrogate risk measure. Unlike traditional adversarial methods, RADE learns\nrisk-conditioned behaviors directly from data, preserving naturalistic\nmulti-agent interactions with controllable risk levels. To ensure physical\nplausibility, we incorporate a tokenized dynamics check module that efficiently\nfilters generated trajectories using a motion vocabulary. We validate RADE on\nthe real-world rounD dataset, demonstrating that it preserves statistical\nrealism across varying risk levels and naturally increases the likelihood of\nsafety-critical events as the desired risk level grows up. Our results\nhighlight RADE's potential as a scalable and realistic tool for AV safety\nevaluation.","main_category":"cs.LG","categories":"cs.LG,cs.RO","published":"2025-05-06T04:41:20Z"}
{"aid":"http://arxiv.org/abs/2505.03190v1","title":"Mitigating parasitic contributions in measured piezoresponse for\n  accurate determination of piezoelectric coefficients in Sc-alloyed-AlN thin\n  films using piezo-response force microscopy","summary":"We present a methodology to mitigate the effect of the parasitic\nelectrostatic contribution usually present in piezoresponse force microscopy\n(PFM) measurement for quantitative characterization of polycrystalline\npiezoelectric thin films using a case study on a set of Al1-xScxN thin films.\nIt involves minimizing the voltage sensitivity of the measured piezoresponse by\noptimizing the optical lever sensitivity using the laser positioning of the\nbeam-bounce system. Additionally, applying a dc-voltage offset (determined\nthrough Kelvin probe force microscopy) during PFM scans and positioning the\nprobe over the interior or edge portion of the specimen are explored to\nminimize the local and non-local electrostatic tip-sample interaction. The\nresults shows that the effective piezoelectric coefficient (d33-eff) of our\nc-axis oriented wurtzite (wz)-Al1.0Sc0.0N thin film is 4.9 pm per Volt. The\nhighest enhancement in the d33-eff value occurred in the wz-Al0.58Sc0.42N thin\nfilm. Above x = 0.42, the d33-eff reduces due to phase-mixing of the\nwz-Al1-xScxN phase with cubic-Sc3AlN phase till the piezoelectricity finally\ndisappear at x = 0.51","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-05-06T05:15:54Z"}
{"aid":"http://arxiv.org/abs/2505.03233v1","title":"GraspVLA: a Grasping Foundation Model Pre-trained on Billion-scale\n  Synthetic Action Data","summary":"Embodied foundation models are gaining increasing attention for their\nzero-shot generalization, scalability, and adaptability to new tasks through\nfew-shot post-training. However, existing models rely heavily on real-world\ndata, which is costly and labor-intensive to collect. Synthetic data offers a\ncost-effective alternative, yet its potential remains largely underexplored. To\nbridge this gap, we explore the feasibility of training Vision-Language-Action\nmodels entirely with large-scale synthetic action data. We curate SynGrasp-1B,\na billion-frame robotic grasping dataset generated in simulation with\nphotorealistic rendering and extensive domain randomization. Building on this,\nwe present GraspVLA, a VLA model pretrained on large-scale synthetic action\ndata as a foundational model for grasping tasks. GraspVLA integrates\nautoregressive perception tasks and flow-matching-based action generation into\na unified Chain-of-Thought process, enabling joint training on synthetic action\ndata and Internet semantics data. This design helps mitigate sim-to-real gaps\nand facilitates the transfer of learned actions to a broader range of\nInternet-covered objects, achieving open-vocabulary generalization in grasping.\nExtensive evaluations across real-world and simulation benchmarks demonstrate\nGraspVLA's advanced zero-shot generalizability and few-shot adaptability to\nspecific human preferences. We will release SynGrasp-1B dataset and pre-trained\nweights to benefit the community.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-06T06:59:28Z"}
{"aid":"http://arxiv.org/abs/2505.03240v1","title":"A novel implementation of Yau-Yau filter for time-variant nonlinear\n  problems","summary":"Nonlinear filter has long been an important problem in practical industrial\napplications. The Yau-Yau method is a highly versatile framework that\ntransforms nonlinear filtering problems into initial-value problems governed by\nthe Forward Kolmogorov Equation (FKE). Previous researches have shown that the\nmethod can be applied to highly nonlinear and high dimensional problems.\nHowever, when time-varying coefficients are involved in the system models,\ndeveloping an implementation of the method with high computational speed and\nlow data storage still presents a challenge. To address these limitations, this\npaper proposes a novel numerical algorithm that incorporates physics-informed\nneural network (PINN) and principal component analysis (PCA) to solve the FKE\napproximately. Equipped with this algorithm, the Yau-Yau filter can be\nimplemented by an offline stage for the training of a solver for the\napproximate solution of FKE and an online stage for its execution. Results of\nthree examples indicate that this implementation is accurate, both\ntime-efficient and storage-efficient for online computation, and is superior\nthan existing nonlinear filtering methods such as extended Kalman filter and\nparticle filter. It is capable of applications to practical nonlinear\ntime-variant filtering problems.","main_category":"math.OC","categories":"math.OC","published":"2025-05-06T07:11:45Z"}
{"aid":"http://arxiv.org/abs/2505.03267v1","title":"Solar Coronal Heating: Role of Kinetic and Inertial Alfvn Waves in\n  Heating and Charged Particle Acceleration","summary":"A comprehensive understanding of solar coronal heating and charged particle\nacceleration remains one of the most critical challenges in space and\nastrophysical plasma physics. In this study, we explore the contribution of\nAlfv\\'en waves, both in their kinetic (KAWs) and inertial (IAWs) regimes, to\nparticle acceleration processes that ultimately lead to coronal heating. Using\na kinetic plasma framework based on the generalized Vlasov-Maxwell model, we\nanalyze the dynamics of these waves with a focus on the perpendicular\ncomponents of the Poynting flux vectors and the net resonance speed of the\nparticles.\n  Our results show that both the magnitude and dissipation rate of the Poynting\nflux for KAWs and IAWs decrease with increasing electron-to-ion temperature\nratio (T_e/T_i) and normalized perpendicular electron inertial length (c k_x /\nomega_pe). We evaluate the associated electric potentials and find that KAWs\nare significantly influenced in the high wavenumber (k_x rho_i) regime. IAWs,\non the other hand, show a decrease in electric potential along the magnetic\nfield and an increase across it when the perpendicular electric field (E_x) is\nenhanced. We also determine the net resonant speeds of particles in the\nperpendicular direction and show that these wave-particle interactions can\nefficiently heat the solar corona over large distances (R_Sun). Finally, we\nquantify the power transported by KAWs and IAWs through solar flux loop tubes,\nfinding that both wave types deliver greater energy with increasing T_e/T_i and\nc k_x / omega_pe. These findings offer deeper insights into wave-driven heating\nand are relevant to solar wind and magnetospheric physics.","main_category":"astro-ph.SR","categories":"astro-ph.SR,physics.plasm-ph","published":"2025-05-06T07:59:31Z"}
{"aid":"http://arxiv.org/abs/2505.03278v1","title":"The Rayleigh-Taylor instability with local energy dissipation","summary":"We consider the inhomogeneous incompressible Euler equations including their\nlocal energy inequality as a differential inclusion. Providing a corresponding\nconvex integration theorem and constructing subsolutions, we show the existence\nof locally dissipative Euler flows emanating from the horizontally flat\nRayleigh-Taylor configuration and having a mixing zone which grows\nquadratically in time. For the Rayleigh-Taylor instability these are the first\nturbulently mixing solutions known to respect local energy dissipation, and\noutside the range of Atwood numbers considered in arXiv:2002.08843, the first\nweakly admissible solutions in general. In the coarse grained picture the\nexistence relies on one-dimensional subsolutions described by a family of\nhyperbolic conservation laws, among which one can find the optimal background\nprofile appearing in the scale invariant bounds from arXiv:2303.01889, and as\nwe show, the optimal conservation law with respect to maximization of the total\nenergy dissipation.","main_category":"math.AP","categories":"math.AP","published":"2025-05-06T08:06:31Z"}
{"aid":"http://arxiv.org/abs/2505.03279v1","title":"Quasi-bound layer breathing phonons inside perfect dislocations of\n  lattice-relaxed twisted bilayers","summary":"Using multiscale modelling we investigate layer breathing phonons in MX$_2$\nbilayers (M=Mo,W; X=S,Se) containing dislocations specific for lattice-relaxed\nmoir\\'e superlattices. Spatial modulation of interlayer distance, caused by the\ndislocations, generates effective potentials that promote emergence of\none-dimensional quasi-bound bands of layer breathing modes inside perfect\ndislocations forming in the bilayers with parallel and antiparallel alignment\nof layers. We show that for parallel MX$_2$ bilayers perfect dislocations host\nseveral quasi-bound bands, with frequencies above layer breathing mode in\nrhombohedral-stacked domains, whereas for antiparallel bilayers only a single\nquasi-bound band arises near the edge dislocation type, having frequencies\nabove the layer breathing mode in 2H-stacked domains.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-05-06T08:06:35Z"}
{"aid":"http://arxiv.org/abs/2505.03283v1","title":"Enabling Robots to Autonomously Search Dynamic Cluttered Post-Disaster\n  Environments","summary":"Robots will bring search and rescue (SaR) in disaster response to another\nlevel, in case they can autonomously take over dangerous SaR tasks from humans.\nA main challenge for autonomous SaR robots is to safely navigate in cluttered\nenvironments with uncertainties, while avoiding static and moving obstacles. We\npropose an integrated control framework for SaR robots in dynamic, uncertain\nenvironments, including a computationally efficient heuristic motion planning\nsystem that provides a nominal (assuming there are no uncertainties)\ncollision-free trajectory for SaR robots and a robust motion tracking system\nthat steers the robot to track this reference trajectory, taking into account\nthe impact of uncertainties. The control architecture guarantees a balanced\ntrade-off among various SaR objectives, while handling the hard constraints,\nincluding safety. The results of various computer-based simulations, presented\nin this paper, showed significant out-performance (of up to 42.3%) of the\nproposed integrated control architecture compared to two commonly used\nstate-of-the-art methods (Rapidly-exploring Random Tree and Artificial\nPotential Function) in reaching targets (e.g., trapped victims in SaR) safely,\ncollision-free, and in the shortest possible time.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-05-06T08:10:02Z"}
{"aid":"http://arxiv.org/abs/2505.03290v1","title":"Surpassing the Global Heisenberg Limit Using a High-effciency Quantum\n  Switch","summary":"Indefinite causal orders have been shown to enable a precision of inverse\nsquare N in quantum parameter estimation, where N is the number of independent\nprocesses probed in an experiment. This surpasses the widely accepted ultimate\nquantum precision of the Heisenberg limit, 1/N. While a recent laboratory\ndemonstration highlighted this phenomenon, its validity relies on postselection\nfor it only accounted for a subset of the resources used. Achieving a true\nviolation of the Heisenberg limit-considering photon loss, detection\nineffciency, and other imperfections-remains an open challenge. Here, we\npresent an ultrahigh-effciency quantum switch to estimate the geometric phase\nassociated with a pair of conjugate position and momentum displacements\nembedded in a superposition of causal orders. Our experimental data demonstrate\nprecision surpassing the global Heisenberg limit without artificially\ncorrecting for losses or imperfections. This work paves the way for quantum\nmetrology advantages under more general and realistic constraints.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-06T08:16:39Z"}
{"aid":"http://arxiv.org/abs/2505.03308v1","title":"An Active Inference perspective on Neurofeedback Training","summary":"Neurofeedback training (NFT) aims to teach self-regulation of brain activity\nthrough real-time feedback, but suffers from highly variable outcomes and\npoorly understood mechanisms, hampering its validation. To address these\nissues, we propose a formal computational model of the NFT closed loop. Using\nActive Inference, a Bayesian framework modelling perception, action, and\nlearning, we simulate agents interacting with an NFT environment. This enables\nus to test the impact of design choices (e.g., feedback quality, biomarker\nvalidity) and subject factors (e.g., prior beliefs) on training. Simulations\nshow that training effectiveness is sensitive to feedback noise or bias, and to\nprior beliefs (highlighting the importance of guiding instructions), but also\nreveal that perfect feedback is insufficient to guarantee high performance.\nThis approach provides a tool for assessing and predicting NFT variability,\ninterpret empirical data, and potentially develop personalized training\nprotocols.","main_category":"q-bio.NC","categories":"q-bio.NC,cs.LG","published":"2025-05-06T08:41:31Z"}
{"aid":"http://arxiv.org/abs/2505.03325v1","title":"Satellite formation around the largest asteroids","summary":"Satellites around large asteroids are preferentially found among those with\nthe most rapid rotation and elongated shape. The taxonomic statistics are\nsimilarly skewed; in total, 13 asteroids larger than 100 km are known to have\nsatellites, but none have been discovered among S-type asteroids. Previous\nmodeling suggests that satellites could be generated by impacts, but spin and\nshape have never been tracked in models to relate collisional circumstances\nwith those two observed properties concerning the primary. Here we show, by\ncombining simulations of impacts into porous low-density asteroids, their\nsubsequent disruption, reaccumulation and long-term satellite stability, a\ndirect pathway for the formation of satellites. The immediate distortion and\nelongation of a rotating target body provides a launching point for some debris\ndistinct from simple ballistic ejecta trajectories. The debris that are found\nto originate from the distorted long-axis is sourced primarily from 10-20 km\nbelow the surface and can be placed directly onto eccentric orbits with\nsufficiently large pericenter distances that avoid rapid re-impact. The\nspecific energy and resultant total mass loss in satellite-forming collisions\nare not constraining, which explains the observed lack of correlation between\nasteroids with satellites and those that are part of large asteroid families.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-05-06T08:53:35Z"}
{"aid":"http://arxiv.org/abs/2505.03341v1","title":"Electrically Reconfigurable NbOCl$_2$ Metasurface for Quantum\n  Technologies","summary":"Entangled photon-pair sources are foundational to advancing quantum\ntechnologies, including secure communication, quantum sensing, and imaging. For\ndeployment in space-constrained environments such as satellite-based quantum\nnetworks or portable devices, compact, reconfigurable, and efficient\nentanglement sources are essential. Here, we present an electrically tunable\nentangled photon-pair source utilizing a nanostructured NbOCl$_2$ crystal,\nengineered for operation in the telecommunication C-band. The inherent\nnon-centrosymmetric lattice symmetry of NbOCl$_2$ enables direct generation of\npolarization-entangled Bell states without the need for post-selection,\nleveraging its exceptional second-order nonlinear susceptibility, which\nsurpasses conventional nonlinear materials. By nanopatterning NbOCl$_2$ into a\nhigh-quality-factor metasurface, we achieve three orders of magnitude\nenhancement in photon-pair generation efficiency via resonant excitation of\nbound states in the continuum resonance, which intensify light-matter\ninteractions. Furthermore, we demonstrate in situ electrical tunability of the\nphoton-pair emission wavelength over a 250 nm range from 1450 nm to 1700 nm by\ndynamically modulating surrounding liquid crystal layer. Remarkably, the\ndecoupling of photon-pair generation rate and spectral tunability ensures high\nbrightness, above 10,000 coincidences, under active tuning. The air stability\nand mechanical robustness of NbOCl$_2$ further enhance its practicality for\nreal-world deployment. This work establishes NbOCl$_2$ as a superior material\nfor scalable, on-chip quantum light sources, paving the way for integrated\nquantum communication systems, adaptive sensors, and portable quantum devices.","main_category":"physics.optics","categories":"physics.optics,quant-ph","published":"2025-05-06T09:11:56Z"}
{"aid":"http://arxiv.org/abs/2505.03355v1","title":"Simulation of Pump-Push Molecular Dynamics in the Heptazine-H2O Complex","summary":"Pump-push-probe spectroscopy was employed for the exploration of\ncharge-separation processes in organic photovoltaic blends as well as for\nproton-coupled electron-transfer (PCET) reactions in hydrogen-bonded complexes\nof tri-anisole-heptazine with substituted phenols in organic solvents. In the\npresent work, the electron and proton transfer dynamics driven by a femtosecond\npump pulse and a time-delayed femtosecond push pulse has been studied with ab\ninitio on-the-fly nonadiabatic trajectory calculations for the hydrogen-bonded\nheptazine-H2O complex. While the dynamics following the pump pulse is dominated\nby ultrafast radiationless energy relaxation to the long-lived lowest singlet\nexcited state (S1) of the heptazine chromophore with only minor PCET\nreactivity, the re-excitation of the transient S1 population by the push pulse\nresults in a much higher PCET reaction probability. These results illustrate\nthat pump-push excitation has the potential to unravel the individual electron\nand proton transfer processes of PCET reactions on femtosecond time scales.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-05-06T09:24:29Z"}
{"aid":"http://arxiv.org/abs/2505.03365v1","title":"Surface Grafting of Graphene Flakes with Fluorescent Dyes: A Tailored\n  Functionalization Approach","summary":"The controlled functionalization of graphene is critical for tuning and\nenhancing its properties, thereby expanding its potential applications.\nCovalent functionalization offers a deeper tuning of the geometric and\nelectronic structure of graphene compared to non-covalent methods; however, the\nexisting techniques involve side reactions and spatially uncontrolled\nfunctionalization, pushing research toward more selective and controlled\nmethods. A promising approach is 1,3-dipolar cycloaddition, successfully\nutilized with carbon nanotubes. In the present work, this method has been\nextended to graphene flakes with low defect concentration. A key innovation is\nthe use of a custom-synthesized ylide with a protected amine group (Boc),\nfacilitating subsequent attachment of functional molecules. Indeed, after Boc\ncleavage, fluorescent dyes (Atto 425, 465, and 633) were covalently linked via\nNHS ester derivatization. This approach represents a highly selective method of\nminimizing structural damage. Successful functionalization was demonstrated by\nRaman spectroscopy, photoluminescence spectroscopy, and confocal microscopy,\nconfirming the effectiveness of the method. This novel approach offers a\nversatile platform, enabling its use in biological imaging, sensing, and\nadvanced nanodevices. The method paves the way for the development of sensors\nand devices capable of anchoring a wide range of molecules, including quantum\ndots and nanoparticles. Therefore, it represents a significant advancement in\ngraphene-based technologies.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-05-06T09:38:32Z"}
{"aid":"http://arxiv.org/abs/2505.03369v1","title":"Validating the Effectiveness of a Large Language Model-based Approach\n  for Identifying Children's Development across Various Free Play Settings in\n  Kindergarten","summary":"Free play is a fundamental aspect of early childhood education, supporting\nchildren's cognitive, social, emotional, and motor development. However,\nassessing children's development during free play poses significant challenges\ndue to the unstructured and spontaneous nature of the activity. Traditional\nassessment methods often rely on direct observations by teachers, parents, or\nresearchers, which may fail to capture comprehensive insights from free play\nand provide timely feedback to educators. This study proposes an innovative\napproach combining Large Language Models (LLMs) with learning analytics to\nanalyze children's self-narratives of their play experiences. The LLM\nidentifies developmental abilities, while performance scores across different\nplay settings are calculated using learning analytics techniques. We collected\n2,224 play narratives from 29 children in a kindergarten, covering four\ndistinct play areas over one semester. According to the evaluation results from\neight professionals, the LLM-based approach achieved high accuracy in\nidentifying cognitive, motor, and social abilities, with accuracy exceeding 90%\nin most domains. Moreover, significant differences in developmental outcomes\nwere observed across play settings, highlighting each area's unique\ncontributions to specific abilities. These findings confirm that the proposed\napproach is effective in identifying children's development across various free\nplay settings. This study demonstrates the potential of integrating LLMs and\nlearning analytics to provide child-centered insights into developmental\ntrajectories, offering educators valuable data to support personalized learning\nand enhance early childhood education practices.","main_category":"cs.AI","categories":"cs.AI,cs.CY","published":"2025-05-06T09:40:47Z"}
{"aid":"http://arxiv.org/abs/2505.03379v1","title":"Hybrid NOMA Assisted Heterogeneous Semantic and Bit Users Communication","summary":"In this paper, we utilize a downlink hybrid Non-Orthogonal Multiple Access\n(NOMA) framework to support multiple semantic and bit users within the\ncommunication network. The hybrid NOMA setup exploits both NOMA and Orthogonal\nMultiple Access (OMA) which has the benefit of enhancing Spectral Efficiency\n(SE) by allowing users to dynamically access the resources in multiple\nheterogeneous slots. This enables integrating semantic and bit users based on\ntheir channel gains, while adopting bit-to-semantic decoding order in slots\nincluding heterogeneous users. An optimization problem for the power allocation\nis formulated with the aim of maximizing the equivalent ergodic semantic SE\nwith a constraint on the total available power of the Access Point (AP). The\nproposed algorithm uses NOMA in shared slots and OMA in bit-user-only slots.\nSimulation results validate the benefits of heterogeneous users hybrid NOMA\nsetup in comparison to OMA-only for heterogeneous users.","main_category":"eess.SP","categories":"eess.SP","published":"2025-05-06T09:56:50Z"}
{"aid":"http://arxiv.org/abs/2505.03380v1","title":"Reinforced Correlation Between Vision and Language for Precise Medical\n  AI Assistant","summary":"Medical AI assistants support doctors in disease diagnosis, medical image\nanalysis, and report generation. However, they still face significant\nchallenges in clinical use, including limited accuracy with multimodal content\nand insufficient validation in real-world settings. We propose RCMed, a\nfull-stack AI assistant that improves multimodal alignment in both input and\noutput, enabling precise anatomical delineation, accurate localization, and\nreliable diagnosis through hierarchical vision-language grounding. A\nself-reinforcing correlation mechanism allows visual features to inform\nlanguage context, while language semantics guide pixel-wise attention, forming\na closed loop that refines both modalities. This correlation is enhanced by a\ncolor region description strategy, translating anatomical structures into\nsemantically rich text to learn shape-location-text relationships across\nscales. Trained on 20 million image-mask-description triplets, RCMed achieves\nstate-of-the-art precision in contextualizing irregular lesions and subtle\nanatomical boundaries, excelling in 165 clinical tasks across 9 modalities. It\nachieved a 23.5% relative improvement in cell segmentation from microscopy\nimages over prior methods. RCMed's strong vision-language alignment enables\nexceptional generalization, with state-of-the-art performance in external\nvalidation across 20 clinically significant cancer types, including novel\ntasks. This work demonstrates how integrated multimodal models capture\nfine-grained patterns, enabling human-level interpretation in complex scenarios\nand advancing human-centric AI healthcare.","main_category":"cs.CV","categories":"cs.CV,cs.AI,eess.IV","published":"2025-05-06T10:00:08Z"}
{"aid":"http://arxiv.org/abs/2505.03388v1","title":"Memory-Efficient Distributed Unlearning","summary":"Machine unlearning considers the removal of the contribution of a set of data\npoints from a trained model. In a distributed setting, where a server\norchestrates training using data available at a set of remote users, unlearning\nis essential to cope with late-detected malicious or corrupted users. Existing\ndistributed unlearning algorithms require the server to store all model updates\nobserved in training, leading to immense storage overhead for preserving the\nability to unlearn. In this work we study lossy compression schemes for\nfacilitating distributed server-side unlearning with limited memory footprint.\nWe propose memory-efficient distributed unlearning (MEDU), a hierarchical lossy\ncompression scheme tailored for server-side unlearning, that integrates user\nsparsification, differential thresholding, and random lattice coding, to\nsubstantially reduce memory footprint. We rigorously analyze MEDU, deriving an\nupper bound on the difference between the desired model that is trained from\nscratch and the model unlearned from lossy compressed stored updates. Our bound\noutperforms the state-of-the-art known bounds for non-compressed decentralized\nserver-side unlearning, even when lossy compression is incorporated. We further\nprovide a numerical study, which shows that suited lossy compression can enable\ndistributed unlearning with notably reduced memory footprint at the server\nwhile preserving the utility of the unlearned model.","main_category":"eess.SP","categories":"eess.SP","published":"2025-05-06T10:10:18Z"}
{"aid":"http://arxiv.org/abs/2505.03391v1","title":"Truthful Facility Location with Candidate Locations and Limited\n  Resources","summary":"We study a truthful facility location problem where one out of $k\\geq2$\navailable facilities must be built at a location chosen from a set of candidate\nones in the interval $[0,1]$. This decision aims to accommodate a set of agents\nwith private positions in $[0,1]$ and approval preferences over the facilities;\nthe agents act strategically and may misreport their private information to\nmaximize their utility, which depends on the chosen facility and their distance\nfrom it. We focus on strategyproof mechanisms that incentivize the agents to\nact truthfully and bound the best possible approximation of the optimal social\nwelfare (the total utility of the agents) they can achieve. We first show that\ndeterministic mechanisms have unbounded approximation ratio, and then present a\nrandomized mechanism with approximation ratio $k$, which is tight even when\nagents may only misreport their positions. For the restricted setting where\nagents may only misreport their approval preferences, we design a deterministic\nmechanism with approximation ratio of roughly $2.325$, and establish lower\nbounds of $3/2$ and $6/5$ for deterministic and randomized mechanisms,\nrespectively.","main_category":"cs.GT","categories":"cs.GT","published":"2025-05-06T10:14:22Z"}
{"aid":"http://arxiv.org/abs/2505.03413v1","title":"Normal $4$-pseudomanifolds with a relative 2-skeleton","summary":"The study of face-number-related invariants in simplicial complexes is a\ncentral topic in combinatorial topology. Among these, the invariant $g_2$ plays\na significant role. For a normal $d$-pseudomanifold $K$ ($d \\geq 3$), it is\nknown that $g_2(K) \\geq g_2(lk(v, K))$ for every vertex $v$. If $K$ has at most\ntwo singularities and satisfies $g_2(K) = g_2(lk(t, K))$ for a singular vertex\n$t$, then $g_3(K) \\geq g_3(lk(t,K))$ holds. A normal $d$-pseudomanifold $K$ is\ncalled $g_2$- and $g_3$-optimal if $g_2(K) = g_2(lk (t,K))$ and $g_3(K) =\ng_3(lk (t,K))$ for a singular vertex $t$.\n  In this article, we establish structural results for normal\n$4$-pseudomanifolds under $g_2$- and $g_3$-optimality conditions. We show that\nif $K$ is a normal $4$-pseudomanifold with exactly one singular vertex $t$ and\nis $g_2$- and $g_3$-optimal at $t$, then $K$ can be obtained from boundary\ncomplexes of $5$-simplices through a sequence of operations of types vertex\nfoldings and connected sums. When $K$ has exactly two singularities and is\n$g_2$- and $g_3$-optimal at one singular vertex, it is derived from the\nboundary complexes of $4$-simplices through a sequence of operations of types\none-vertex suspensions, vertex foldings, and connected sums. Alternatively, we\nprove that if $K$ has two singular vertices and is $g_2$- and $g_3$-optimal at\none of them, then it arises from boundary complexes of $5$-simplices through a\nsequence of operations of types vertex foldings, edge foldings, and connected\nsums.","main_category":"math.CO","categories":"math.CO,math.GT","published":"2025-05-06T10:39:39Z"}
{"aid":"http://arxiv.org/abs/2505.03435v1","title":"Robustness in AI-Generated Detection: Enhancing Resistance to\n  Adversarial Attacks","summary":"The rapid advancement of generative image technology has introduced\nsignificant security concerns, particularly in the domain of face generation\ndetection. This paper investigates the vulnerabilities of current AI-generated\nface detection systems. Our study reveals that while existing detection methods\noften achieve high accuracy under standard conditions, they exhibit limited\nrobustness against adversarial attacks. To address these challenges, we propose\nan approach that integrates adversarial training to mitigate the impact of\nadversarial examples. Furthermore, we utilize diffusion inversion and\nreconstruction to further enhance detection robustness. Experimental results\ndemonstrate that minor adversarial perturbations can easily bypass existing\ndetection systems, but our method significantly improves the robustness of\nthese systems. Additionally, we provide an in-depth analysis of adversarial and\nbenign examples, offering insights into the intrinsic characteristics of\nAI-generated content. All associated code will be made publicly available in a\ndedicated repository to facilitate further research and verification.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-06T11:19:01Z"}
{"aid":"http://arxiv.org/abs/2505.03444v1","title":"The Frequency-dependent Modulation Features of PSR J1948+3540","summary":"Using observations from GMRT and FAST, we conducted multi-wavelength studies\non PSR J1948+3540 and analyzed its intensity modulation characteristics in\ndetail. We found that the intensity modulation of this pulsar exhibits broad\nlow-frequency modulation features. The modulation frequency/period is\ntime-dependent, but the dominant modulation component varies with the observing\nfrequency. Specifically, at low frequencies, the modulation is dominated by the\nfirst half of the middle component, while at high frequencies, it is dominated\nby the second half of the middle component. Spectral analysis revealed that the\nintensities of the leading and trailing components vary with the observing\nfrequency, but the middle component does not change significantly. Besides, the\npolarization analyses reveal that the peak of the radiation intensity is\nlocated in the latter half of the middle component, whereas the linear\npolarization is dominant in the former half. However, due to the low degree of\nlinear polarization, the change of the dominant modulation component with the\nobserved frequency is not caused by the variation in linear polarization. The\nphenomenon of the dominant modulation component varying with observing\nfrequency has not been reported before and remains difficult to understand\nwithin the current theoretical framework.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-05-06T11:30:21Z"}
{"aid":"http://arxiv.org/abs/2505.03461v1","title":"VLBA observations of a sample of low-power compact symmetric objects","summary":"Compact symmetric objects (CSOs) are intrinsically compact extragalactic\nradio sources that are thought to be the progenitors of classical radio\ngalaxies. To date, evolutionary models have mainly focused on the formation and\ngrowth of high-power radio sources, leaving unanswered many questions related\nto low-power objects, whose relativistic jets are likely more prone to\ninstabilities. We present a new sample of candidate low-power CSOs selected\nfrom the Faint Images of the Radio Sky at Twenty-cm (FIRST) survey. The main\nselection criteria are (i) a parsec-scale double radio morphology from archival\nVery Long Baseline Array (VLBA) images and (ii) a VLBA total flux density\nconsistent with that from the FIRST survey, which rules out the presence of\nsignificant radio emission extending beyond the parsec scale. The final sample\nconsists of 60 sources with radio luminosities between 10$^{24}$ and 10$^{27}$\nW Hz$^{-1}$ at 1.4 GHz and projected linear sizes between 45 and 430 pc, which\nfill a region in the radio power-size plane that is currently underpopulated.\nWe carried out VLBA observations at 4.98 GHz of a sub-sample of 20 sources\namong the brightest candidate CSOs with the aim of confirming their\nclassification. We classify 12 sources as CSOs on the basis of their radio\nstructure and spectral index distribution. In two out of the four CSOs with\ncore identification, the asymmetry in the flux density of the outer components\nis in agreement with light travel time effects, and there is no evidence of\njet-cloud interaction. If we assume a simplistic parametric model, most of the\nsources in the total sample have a jet power of $\\sim 10^{44} - 10^{45}$ erg\ns$^{-1}$, making their evolutionary paths sensitive to the individual\nconditions of the jet and its environment.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-05-06T12:01:17Z"}
{"aid":"http://arxiv.org/abs/2505.03495v1","title":"Generalized Epsilon-Near-Zero Polaritons on Uniaxial Metasurfaces","summary":"Epsilon-near-zero (ENZ) thin films facilitate strong light-matter\ninteractions with a widespread impact in nonlinear, quantum and thermal\nphotonics. Here, we extend the scope of thin film ENZ modes by elucidating the\ngeneralized polaritonic modes emerging from anisotropy and near-zero\npermittivity. Through a theoretical investigation of generalized ENZ polaritons\non silicon carbide (SiC) metasurfaces, we reveal a complex polaritonic\nlandscape, consisting of a seven-region phase diagram. We show that the complex\ninterplay between material properties and geometry changes the nature of the\nmodes, and we clarify when ENZ modes with closed and open isofrequency curves\n(IFCs) can be observed, and how they coexist with surface phonon-polaritons and\nhyperbolic modes. The associated photonic topological transitions are\naccompanied by phase velocity sign reversals and induce dramatic modifications\nof near-field profiles and Purcell enhancement factors. Our work merges\ninsights from anisotropic and ENZ effects, enabling enhanced control over\npolariton behavior with broad implications for subwavelength optics, material\ndesign, nonlinear effects, thermal emission, and quantum technologies.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mes-hall","published":"2025-05-06T12:57:14Z"}
{"aid":"http://arxiv.org/abs/2505.03499v1","title":"An eigenvalue estimate for self-shrinkers in a Ricci shirinker","summary":"In this paper, we study the drifted Laplacian $\\Delta_f$ on a hypersurface\n$M$ in a Ricci shrinker $(\\overline{M},g,f)$. We prove that the spectrum of\n$\\Delta_f$ is discrete for immersed hypersurfaces with bounded weighted mean\ncurvature in a Ricci shrinker with a mild condition on the potential function.\nNext, we give a lower bound for the first nonzero eigenvalue of $\\Delta_f$ when\nthe hypersurface is an embedded $f$-minimal one. This estimate contains the\ncase of compact minimal hypersurfaces in a positive Einstein manifold, in\nparticular Choi and Wang's estimate for minimal hypersurfaces in a round\nsphere. The estimate also recovers the ones of Ding-Xin and Brendle-Tsiamis on\nself-shrinkers.","main_category":"math.DG","categories":"math.DG","published":"2025-05-06T13:04:23Z"}
{"aid":"http://arxiv.org/abs/2505.03501v1","title":"BadLingual: A Novel Lingual-Backdoor Attack against Large Language\n  Models","summary":"In this paper, we present a new form of backdoor attack against Large\nLanguage Models (LLMs): lingual-backdoor attacks. The key novelty of\nlingual-backdoor attacks is that the language itself serves as the trigger to\nhijack the infected LLMs to generate inflammatory speech. They enable the\nprecise targeting of a specific language-speaking group, exacerbating racial\ndiscrimination by malicious entities. We first implement a baseline\nlingual-backdoor attack, which is carried out by poisoning a set of training\ndata for specific downstream tasks through translation into the trigger\nlanguage. However, this baseline attack suffers from poor task generalization\nand is impractical in real-world settings. To address this challenge, we design\nBadLingual, a novel task-agnostic lingual-backdoor, capable of triggering any\ndownstream tasks within the chat LLMs, regardless of the specific questions of\nthese tasks. We design a new approach using PPL-constrained Greedy Coordinate\nGradient-based Search (PGCG) based adversarial training to expand the decision\nboundary of lingual-backdoor, thereby enhancing the generalization ability of\nlingual-backdoor across various tasks. We perform extensive experiments to\nvalidate the effectiveness of our proposed attacks. Specifically, the baseline\nattack achieves an ASR of over 90% on the specified tasks. However, its ASR\nreaches only 37.61% across six tasks in the task-agnostic scenario. In\ncontrast, BadLingual brings up to 37.35% improvement over the baseline. Our\nstudy sheds light on a new perspective of vulnerabilities in LLMs with\nmultilingual capabilities and is expected to promote future research on the\npotential defenses to enhance the LLMs' robustness","main_category":"cs.CR","categories":"cs.CR,cs.CL","published":"2025-05-06T13:07:57Z"}
{"aid":"http://arxiv.org/abs/2505.03530v1","title":"Causal Intervention Framework for Variational Auto Encoder Mechanistic\n  Interpretability","summary":"Mechanistic interpretability of deep learning models has emerged as a crucial\nresearch direction for understanding the functioning of neural networks. While\nsignificant progress has been made in interpreting discriminative models like\ntransformers, understanding generative models such as Variational Autoencoders\n(VAEs) remains challenging. This paper introduces a comprehensive causal\nintervention framework for mechanistic interpretability of VAEs. We develop\ntechniques to identify and analyze \"circuit motifs\" in VAEs, examining how\nsemantic factors are encoded, processed, and disentangled through the network\nlayers. Our approach uses targeted interventions at different levels: input\nmanipulations, latent space perturbations, activation patching, and causal\nmediation analysis. We apply our framework to both synthetic datasets with\nknown causal relationships and standard disentanglement benchmarks. Results\nshow that our interventions can successfully isolate functional circuits, map\ncomputational graphs to causal graphs of semantic factors, and distinguish\nbetween polysemantic and monosemantic units. Furthermore, we introduce metrics\nfor causal effect strength, intervention specificity, and circuit modularity\nthat quantify the interpretability of VAE components. Experimental results\ndemonstrate clear differences between VAE variants, with FactorVAE achieving\nhigher disentanglement scores (0.084) and effect strengths (mean 4.59) compared\nto standard VAE (0.064, 3.99) and Beta-VAE (0.051, 3.43). Our framework\nadvances the mechanistic understanding of generative models and provides tools\nfor more transparent and controllable VAE architectures.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-06T13:40:59Z"}
{"aid":"http://arxiv.org/abs/2505.03557v1","title":"Generating Synthetic Data via Augmentations for Improved Facial\n  Resemblance in DreamBooth and InstantID","summary":"The personalization of Stable Diffusion for generating professional portraits\nfrom amateur photographs is a burgeoning area, with applications in various\ndownstream contexts. This paper investigates the impact of augmentations on\nimproving facial resemblance when using two prominent personalization\ntechniques: DreamBooth and InstantID. Through a series of experiments with\ndiverse subject datasets, we assessed the effectiveness of various augmentation\nstrategies on the generated headshots' fidelity to the original subject. We\nintroduce FaceDistance, a wrapper around FaceNet, to rank the generations based\non facial similarity, which aided in our assessment. Ultimately, this research\nprovides insights into the role of augmentations in enhancing facial\nresemblance in SDXL-generated portraits, informing strategies for their\neffective deployment in downstream applications.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-05-06T14:11:02Z"}
{"aid":"http://arxiv.org/abs/2505.03561v1","title":"Ergodic Generative Flows","summary":"Generative Flow Networks (GFNs) were initially introduced on directed acyclic\ngraphs to sample from an unnormalized distribution density. Recent works have\nextended the theoretical framework for generative methods allowing more\nflexibility and enhancing application range. However, many challenges remain in\ntraining GFNs in continuous settings and for imitation learning (IL), including\nintractability of flow-matching loss, limited tests of non-acyclic training,\nand the need for a separate reward model in imitation learning. The present\nwork proposes a family of generative flows called Ergodic Generative Flows\n(EGFs) which are used to address the aforementioned issues. First, we leverage\nergodicity to build simple generative flows with finitely many globally defined\ntransformations (diffeomorphisms) with universality guarantees and tractable\nflow-matching loss (FM loss). Second, we introduce a new loss involving\ncross-entropy coupled to weak flow-matching control, coined KL-weakFM loss. It\nis designed for IL training without a separate reward model. We evaluate\nIL-EGFs on toy 2D tasks and real-world datasets from NASA on the sphere, using\nthe KL-weakFM loss. Additionally, we conduct toy 2D reinforcement learning\nexperiments with a target reward, using the FM loss.","main_category":"cs.LG","categories":"cs.LG,cs.AI,math.DG,math.DS","published":"2025-05-06T14:13:21Z"}
{"aid":"http://arxiv.org/abs/2505.03567v1","title":"Uncertainty-Aware Prototype Semantic Decoupling for Text-Based Person\n  Search in Full Images","summary":"Text-based pedestrian search (TBPS) in full images aims to locate a target\npedestrian in untrimmed images using natural language descriptions. However, in\ncomplex scenes with multiple pedestrians, existing methods are limited by\nuncertainties in detection and matching, leading to degraded performance. To\naddress this, we propose UPD-TBPS, a novel framework comprising three modules:\nMulti-granularity Uncertainty Estimation (MUE), Prototype-based Uncertainty\nDecoupling (PUD), and Cross-modal Re-identification (ReID). MUE conducts\nmulti-granularity queries to identify potential targets and assigns confidence\nscores to reduce early-stage uncertainty. PUD leverages visual context\ndecoupling and prototype mining to extract features of the target pedestrian\ndescribed in the query. It separates and learns pedestrian prototype\nrepresentations at both the coarse-grained cluster level and the fine-grained\nindividual level, thereby reducing matching uncertainty. ReID evaluates\ncandidates with varying confidence levels, improving detection and retrieval\naccuracy. Experiments on CUHK-SYSU-TBPS and PRW-TBPS datasets validate the\neffectiveness of our framework.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-06T14:25:30Z"}
{"aid":"http://arxiv.org/abs/2505.03574v1","title":"LlamaFirewall: An open source guardrail system for building secure AI\n  agents","summary":"Large language models (LLMs) have evolved from simple chatbots into\nautonomous agents capable of performing complex tasks such as editing\nproduction code, orchestrating workflows, and taking higher-stakes actions\nbased on untrusted inputs like webpages and emails. These capabilities\nintroduce new security risks that existing security measures, such as model\nfine-tuning or chatbot-focused guardrails, do not fully address. Given the\nhigher stakes and the absence of deterministic solutions to mitigate these\nrisks, there is a critical need for a real-time guardrail monitor to serve as a\nfinal layer of defense, and support system level, use case specific safety\npolicy definition and enforcement. We introduce LlamaFirewall, an open-source\nsecurity focused guardrail framework designed to serve as a final layer of\ndefense against security risks associated with AI Agents. Our framework\nmitigates risks such as prompt injection, agent misalignment, and insecure code\nrisks through three powerful guardrails: PromptGuard 2, a universal jailbreak\ndetector that demonstrates clear state of the art performance; Agent Alignment\nChecks, a chain-of-thought auditor that inspects agent reasoning for prompt\ninjection and goal misalignment, which, while still experimental, shows\nstronger efficacy at preventing indirect injections in general scenarios than\npreviously proposed approaches; and CodeShield, an online static analysis\nengine that is both fast and extensible, aimed at preventing the generation of\ninsecure or dangerous code by coding agents. Additionally, we include\neasy-to-use customizable scanners that make it possible for any developer who\ncan write a regular expression or an LLM prompt to quickly update an agent's\nsecurity guardrails.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-05-06T14:34:21Z"}
{"aid":"http://arxiv.org/abs/2505.03599v1","title":"From Pixels to Polygons: A Survey of Deep Learning Approaches for\n  Medical Image-to-Mesh Reconstruction","summary":"Deep learning-based medical image-to-mesh reconstruction has rapidly evolved,\nenabling the transformation of medical imaging data into three-dimensional mesh\nmodels that are critical in computational medicine and in silico trials for\nadvancing our understanding of disease mechanisms, and diagnostic and\ntherapeutic techniques in modern medicine. This survey systematically\ncategorizes existing approaches into four main categories: template models,\nstatistical models, generative models, and implicit models. Each category is\nanalysed in detail, examining their methodological foundations, strengths,\nlimitations, and applicability to different anatomical structures and imaging\nmodalities. We provide an extensive evaluation of these methods across various\nanatomical applications, from cardiac imaging to neurological studies,\nsupported by quantitative comparisons using standard metrics. Additionally, we\ncompile and analyze major public datasets available for medical mesh\nreconstruction tasks and discuss commonly used evaluation metrics and loss\nfunctions. The survey identifies current challenges in the field, including\nrequirements for topological correctness, geometric accuracy, and\nmulti-modality integration. Finally, we present promising future research\ndirections in this domain. This systematic review aims to serve as a\ncomprehensive reference for researchers and practitioners in medical image\nanalysis and computational medicine.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-06T15:01:43Z"}
{"aid":"http://arxiv.org/abs/2505.03601v1","title":"Doing Audits Right? The Role of Sampling and Legal Content Analysis in\n  Systemic Risk Assessments and Independent Audits in the Digital Services Act","summary":"A central requirement of the European Union's Digital Services Act (DSA) is\nthat online platforms undergo internal and external audits. A key component of\nthese audits is the assessment of systemic risks, including the dissemination\nof illegal content, threats to fundamental rights, impacts on democratic\nprocesses, and gender-based violence. The DSA Delegated Regulation outlines how\nsuch audits should be conducted, setting expectations for both platforms and\nauditors. This article evaluates the strengths and limitations of different\nqualitative and quantitative methods for auditing these systemic risks and\nproposes a mixed-method approach for DSA compliance. We argue that content\nsampling, combined with legal and empirical analysis, offers a viable method\nfor risk-specific audits. First, we examine relevant legal provisions on sample\nselection for audit purposes. We then assess sampling techniques and methods\nsuitable for detecting systemic risks, focusing on how representativeness can\nbe understood across disciplines. Finally, we review initial systemic risk\nassessment reports submitted by platforms, analyzing their testing and sampling\nmethodologies. By proposing a structured, mixed-method approach tailored to\nspecific risk categories and platform characteristics, this article addresses\nthe challenge of evidence-based audits under the DSA. Our contribution\nemphasizes the need for adaptable, context-sensitive auditing strategies and\nadds to the emerging field of DSA compliance research.","main_category":"cs.CY","categories":"cs.CY","published":"2025-05-06T15:02:54Z"}
{"aid":"http://arxiv.org/abs/2505.03602v1","title":"Variability of the Faraday Rotation Measure in the Parsec-scale Jet of\n  AGN 1633+382","summary":"We study the Faraday rotation measure (RM) variability of flat spectrum radio\nquasar 1633+382 on 5 epochs spanning from 2004 to 2008. We used 4 to 43~GHz\nVLBI polarization data from VLBA. Core RM across 4 to 15 GHz scales with a\npower index $a\\sim2$, for $a$ in RM$\\propto \\nu^a$. We detected sign changes\nacross epochs, both in the core and in the jet region. RM time variability in\nthe core and jet region are not correlated, hence limiting the size of a\npossible Faraday screen. We relate the core RM variability to a new component\nemerging from the core region. For the jet region, we consider the jet-medium\ninteraction to be a less likely cause of the RM variability because of the\nuniform spectral index distribution. The observed RM value variation requires a\nhuge fluctuation in electron density or magnetic field, hence a foreground\nFaraday screen is less favoured. We further discuss other possibilities of the\nRM variability based on jet kinematics.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-05-06T15:03:02Z"}
{"aid":"http://arxiv.org/abs/2505.03631v1","title":"Breaking Annotation Barriers: Generalized Video Quality Assessment via\n  Ranking-based Self-Supervision","summary":"Video quality assessment (VQA) is essential for quantifying perceptual\nquality in various video processing workflows, spanning from camera capture\nsystems to over-the-top streaming platforms. While recent supervised VQA models\nhave made substantial progress, the reliance on manually annotated datasets --\na process that is labor-intensive, costly, and difficult to scale up -- has\nhindered further optimization of their generalization to unseen video content\nand distortions. To bridge this gap, we introduce a self-supervised learning\nframework for VQA to learn quality assessment capabilities from large-scale,\nunlabeled web videos. Our approach leverages a \\textbf{learning-to-rank}\nparadigm to train a large multimodal model (LMM) on video pairs automatically\nlabeled via two manners, including quality pseudo-labeling by existing VQA\nmodels and relative quality ranking based on synthetic distortion simulations.\nFurthermore, we introduce a novel \\textbf{iterative self-improvement training\nstrategy}, where the trained model acts an improved annotator to iteratively\nrefine the annotation quality of training data. By training on a dataset\n$10\\times$ larger than the existing VQA benchmarks, our model: (1) achieves\nzero-shot performance on in-domain VQA benchmarks that matches or surpasses\nsupervised models; (2) demonstrates superior out-of-distribution (OOD)\ngeneralization across diverse video content and distortions; and (3) sets a new\nstate-of-the-art when fine-tuned on human-labeled datasets. Extensive\nexperimental results validate the effectiveness of our self-supervised approach\nin training generalized VQA models. The datasets and code will be publicly\nreleased to facilitate future research.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-06T15:29:32Z"}
{"aid":"http://arxiv.org/abs/2505.03665v1","title":"Unexpectedly, a symmetry on unlabeled graphs","summary":"We exhibit the joint symmetric distribution of the following two parameters\non the set of unlabeled, simple, connected graphs with $n$ vertices. The first\nparameter is the maximal number of leaves attached to a vertex. The second\nparameter is the size of the largest set of vertices sharing the same closed\nneighborhood minus $1$.\n  Apparently, this is the first example of a natural, non-trivial\nequidistribution of graph parameters on unlabeled connected graphs on a fixed\nset of vertices.\n  Our proof is enumerative, using the theory of species. Exhibiting an explicit\nbijection interchanging the two parameters remains an open problem.","main_category":"math.CO","categories":"math.CO","published":"2025-05-06T16:06:37Z"}
{"aid":"http://arxiv.org/abs/2505.03677v1","title":"Neural Integral Operators for Inverse problems in Spectroscopy","summary":"Deep learning has shown high performance on spectroscopic inverse problems\nwhen sufficient data is available. However, it is often the case that data in\nspectroscopy is scarce, and this usually causes severe overfitting problems\nwith deep learning methods. Traditional machine learning methods are viable\nwhen datasets are smaller, but the accuracy and applicability of these methods\nis generally more limited.\n  We introduce a deep learning method for classification of molecular spectra\nbased on learning integral operators via integral equations of the first kind,\nwhich results in an algorithm that is less affected by overfitting issues on\nsmall datasets, compared to other deep learning models.\n  The problem formulation of the deep learning approach is based on inverse\nproblems, which have traditionally found important applications in\nspectroscopy. We perform experiments on real world data to showcase our\nalgorithm. It is seen that the model outperforms traditional machine learning\napproaches such as decision tree and support vector machine, and for small\ndatasets it outperforms other deep learning models. Therefore, our methodology\nleverages the power of deep learning, still maintaining the performance when\nthe available data is very limited, which is one of the main issues that deep\nlearning faces in spectroscopy, where datasets are often times of small size.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-06T16:22:46Z"}
{"aid":"http://arxiv.org/abs/2505.03702v1","title":"Self-Supervised Learning for Robotic Leaf Manipulation: A Hybrid\n  Geometric-Neural Approach","summary":"Automating leaf manipulation in agricultural settings faces significant\nchallenges, including the variability of plant morphologies and deformable\nleaves. We propose a novel hybrid geometric-neural approach for autonomous leaf\ngrasping that combines traditional computer vision with neural networks through\nself-supervised learning. Our method integrates YOLOv8 for instance\nsegmentation and RAFT-Stereo for 3D depth estimation to build rich leaf\nrepresentations, which feed into both a geometric feature scoring pipeline and\na neural refinement module (GraspPointCNN). The key innovation is our\nconfidence-weighted fusion mechanism that dynamically balances the contribution\nof each approach based on prediction certainty. Our self-supervised framework\nuses the geometric pipeline as an expert teacher to automatically generate\ntraining data. Experiments demonstrate that our approach achieves an 88.0%\nsuccess rate in controlled environments and 84.7% in real greenhouse\nconditions, significantly outperforming both purely geometric (75.3%) and\nneural (60.2%) methods. This work establishes a new paradigm for agricultural\nrobotics where domain expertise is seamlessly integrated with machine learning\ncapabilities, providing a foundation for fully automated crop monitoring\nsystems.","main_category":"cs.RO","categories":"cs.RO,cs.CV,cs.LG,I.2.10","published":"2025-05-06T17:22:21Z"}
{"aid":"http://arxiv.org/abs/2505.03709v1","title":"Toward a Harmonized Approach -- Requirement-based Structuring of a\n  Safety Assurance Argumentation for Automated Vehicles","summary":"Despite increasing testing operation on public roads, media reports on\nincidents show that safety issues remain to this day. One major cause factoring\ninto this circumstance is high development uncertainty that manufacturers face\nwhen deploying these systems in an open context. In particular, one challenge\nis establishing a valid argument at design time that the vehicle will exhibit\nreasonable residual risk when operating in its intended operational design\ndomain. Regulations, such as the European Implementing Regulation 2022/1426,\nrequire manufacturers to provide a safety assurance argumentation for\nSAE-Level-4 automated vehicles. While there is extensive literature on\nassurance cases for safety-critical systems, the domain of automated driving\nlacks explicit requirements regarding the creation of safety assurance\nargumentations. In this paper, we aim to narrow this gap by elaborating a\nrequirement-based approach. We derive structural requirements for an\nargumentation from literature and supplement these with requirements derived\nfrom stakeholder concerns. We implement the requirements, yielding a proposal\nfor an overall argumentation structure. The resulting \"safety arguments\" argue\nover four topic complexes: The developed product, the underlying process\nincluding its conformance/compliance to standards/laws, as well as the\nargumentations' context and soundness. Finally, we instantiate this structure\nwith respect to domain-specific needs and principles.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-05-06T17:28:30Z"}
{"aid":"http://arxiv.org/abs/2505.04089v1","title":"A New Scope and Domain Measure Comparison Method for Global Convergence\n  Analysis in Evolutionary Computation","summary":"Convergence analysis is a fundamental research topic in evolutionary\ncomputation (EC). The commonly used analysis method models the EC algorithm as\na homogeneous Markov chain for analysis, which is not always suitable for\ndifferent EC variants, and also sometimes causes misuse and confusion due to\ntheir complex process. In this article, we categorize the existing researches\non convergence analysis in EC algorithms into stable convergence and global\nconvergence, and then prove that the conditions for these two convergence\nproperties are somehow mutually exclusive. Inspired by this proof, we propose a\nnew scope and domain measure comparison (SDMC) method for analyzing the global\nconvergence of EC algorithms and provide a rigorous proof of its necessity and\nsufficiency as an alternative condition. Unlike traditional methods, the SDMC\nmethod is straightforward, bypasses Markov chain modeling, and minimizes errors\nfrom misapplication as it only focuses on the measure of the algorithm's search\nscope. We apply SDMC to two algorithm types that are unsuitable for traditional\nmethods, confirming its effectiveness in global convergence analysis.\nFurthermore, we apply the SDMC method to explore the gene targeting mechanism's\nimpact on the global convergence in large-scale global optimization, deriving\ninsights into how to design EC algorithms that guarantee global convergence and\nexploring how theoretical analysis can guide EC algorithm design.","main_category":"cs.NE","categories":"cs.NE","published":"2025-05-07T03:04:18Z"}
{"aid":"http://arxiv.org/abs/2505.04098v1","title":"Satellite-Assisted Low-Altitude Economy Networking: Concepts,\n  Applications, and Opportunities","summary":"The low-altitude economy (LAE) is a new economic paradigm that leverages\nlow-altitude vehicles (LAVs) to perform diverse missions across diverse areas.\nTo support the operations of LAE, it is essential to establish LAE networks\nthat enable LAV management and communications.Existing studies mainly reuse\nterrestrial networks to construct LAE networks. However, the limited coverage\nof terrestrial networks poses challenges for serving LAVs in remote areas.\nBesides, efficient LAV operations also require support such as localization and\nnavigation, which terrestrial networks designed for communications cannot fully\nprovide. Due to ubiquitous coverage and diverse functions, satellites are a\npromising technology to support LAVs. Therefore, this article investigates\nsatellite-assisted LAE networking. First, we introduce an overview of LAE and\nsatellites, discussing their features, applications, and architectures. Next,\nwe investigate opportunities for satellites to assist LAE from aspects of\ncommunication, control, and computation. As all assistance depends on reliable\nsatellite-LAV communications, we propose a satellite-assisted LAE framework to\ntackle issues caused by the severe path loss and high dynamics in\nsatellite-assisted LAE networks.The case study demonstrates that the\ndistributed MIMO architecture efficiently reduces the required transmission\npower and extends service duration, while the two-timescale optimization scheme\nbalances the performance and control signaling overheads. Specifically, the\nproposed framework comprises distributed satellite MIMO, distributed LAV MIMO,\nand a two-timescale optimization scheme.","main_category":"cs.NI","categories":"cs.NI","published":"2025-05-07T03:34:34Z"}
{"aid":"http://arxiv.org/abs/2505.04113v1","title":"Advancing Zero-shot Text-to-Speech Intelligibility across Diverse\n  Domains via Preference Alignment","summary":"Modern zero-shot text-to-speech (TTS) systems, despite using extensive\npre-training, often struggle in challenging scenarios such as tongue twisters,\nrepeated words, code-switching, and cross-lingual synthesis, leading to\nintelligibility issues. To address these limitations, this paper leverages\npreference alignment techniques, which enable targeted construction of\nout-of-pretraining-distribution data to enhance performance. We introduce a new\ndataset, named the Intelligibility Preference Speech Dataset (INTP), and extend\nthe Direct Preference Optimization (DPO) framework to accommodate diverse TTS\narchitectures. After INTP alignment, in addition to intelligibility, we observe\noverall improvements including naturalness, similarity, and audio quality for\nmultiple TTS models across diverse domains. Based on that, we also verify the\nweak-to-strong generalization ability of INTP for more intelligible models such\nas CosyVoice 2 and Ints. Moreover, we showcase the potential for further\nimprovements through iterative alignment based on Ints. Audio samples are\navailable at https://intalign.github.io/.","main_category":"cs.SD","categories":"cs.SD,eess.AS","published":"2025-05-07T04:04:31Z"}
{"aid":"http://arxiv.org/abs/2505.04135v1","title":"Enhancing Granular Sentiment Classification with Chain-of-Thought\n  Prompting in Large Language Models","summary":"We explore the use of Chain-of-Thought (CoT) prompting with large language\nmodels (LLMs) to improve the accuracy of granular sentiment categorization in\napp store reviews. Traditional numeric and polarity-based ratings often fail to\ncapture the nuanced sentiment embedded in user feedback. We evaluated the\neffectiveness of CoT prompting versus simple prompting on 2000 Amazon app\nreviews by comparing each method's predictions to human judgements. CoT\nprompting improved classification accuracy from 84% to 93% highlighting the\nbenefit of explicit reasoning in enhancing sentiment analysis performance.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-05-07T05:13:15Z"}
{"aid":"http://arxiv.org/abs/2505.04138v1","title":"Generic (fractional) quantum anomalous Hall crystals from\n  interaction-driven band folding","summary":"The experimental realizations of fractional quantum anomalous Hall (FQAH)\nstates have been achieved recently, and there is a growing number of\nexperiments in moir\\'e systems showing the inequality between the filling of\nthe Chern band and the quantized Hall conductance: $\\nu\\neq\\sigma_\\mathrm{H}$.\nAmong many possible explanations, a popular one is that the topological states\nhave coexisting charge density wave (CDW) orders, and such states are referred\nto as Hall crystals. However, apart from the experimental uncertainties, the\ngeneric mechanism of Hall crystals, especially those with fractional\n$\\sigma_\\mathrm{H}$ is still elusive at the microscopic level. In this work, we\nnumerically study a topological flat-band model and find that, the Chern band\ncan be folded by the interaction-driven CDW, and a mini Chern band appears\nabove the CDW gap. Through further analysis, we find the energy dispersion and\nthe fluctuation of quantum geometry of the miniband could be flattened by\ncompeting interactions. When further doping this miniband, a series of (F)QAH\nstates are found to coexist with the CDW order at (fractional)integer fillings\nof the miniband and the Hall conductivities of the FQAH crystals (FQAHCs)-\ndetermined by the fillings of the miniband - are different from the fillings of\nthe original Chern band. We also study the thermodynamics of an FQAHC state and\nfind the separation of energy scales and a compressible CDW phase at\nintermediate temperatures. Our work paves the way for the systematic\nunderstanding of (fractional) Hall crystals.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mes-hall","published":"2025-05-07T05:25:02Z"}
{"aid":"http://arxiv.org/abs/2505.04147v1","title":"R^3-VQA: \"Read the Room\" by Video Social Reasoning","summary":"\"Read the room\" is a significant social reasoning capability in human daily\nlife. Humans can infer others' mental states from subtle social cues. Previous\nsocial reasoning tasks and datasets lack complexity (e.g., simple scenes, basic\ninteractions, incomplete mental state variables, single-step reasoning, etc.)\nand fall far short of the challenges present in real-life social interactions.\nIn this paper, we contribute a valuable, high-quality, and comprehensive video\ndataset named R^3-VQA with precise and fine-grained annotations of social\nevents and mental states (i.e., belief, intent, desire, and emotion) as well as\ncorresponding social causal chains in complex social scenarios. Moreover, we\ninclude human-annotated and model-generated QAs. Our task R^3-VQA includes\nthree aspects: Social Event Understanding, Mental State Estimation, and Social\nCausal Reasoning. As a benchmark, we comprehensively evaluate the social\nreasoning capabilities and consistencies of current state-of-the-art large\nvision-language models (LVLMs). Comprehensive experiments show that (i) LVLMs\nare still far from human-level consistent social reasoning in complex social\nscenarios; (ii) Theory of Mind (ToM) prompting can help LVLMs perform better on\nsocial reasoning tasks. We provide some of our dataset and codes in\nsupplementary material and will release our full dataset and codes upon\nacceptance.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-05-07T05:55:45Z"}
{"aid":"http://arxiv.org/abs/2505.04155v1","title":"An Adaptive Mixed Precision and Dynamically Scaled Preconditioned\n  Conjugate Gradient Algorithm","summary":"We propose an adaptive mixed precision and dynamically scaled preconditioned\nconjugate gradient algorithm (AMP-PCG). It dynamically adjusts the precision\nfor storing vectors and computing, exploiting low precision when appropriate,\nwhile maintaining a convergence rate and accuracy comparable to that of double\nprecision PCG. Our mixed precision strategy consists of three main components:\n(1) The residual and matrix-vector product are initially computed in double\nprecision, and the algorithm switches these to single precision based on the\nchosen convergence tolerance and an estimate of the residual gap. (2) Depending\non the eigenvalue distribution, the preconditioned residual and search\ndirection are either in half precision throughout the iterations or initially\nin double precision and then stepwise reduced to single and half precision. (3)\nA dynamically scaled residual is used at every iteration to mitigate underflow\nin half precision. We provide theoretical support for our estimates and we\ndemonstrate the effectiveness of AMP-PCG through numerical experiments,\nhighlighting both its robustness and the significant performance gains (1.63x\nspeedup) achieved compared to double precision PCG on a GPU.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-05-07T06:11:49Z"}
{"aid":"http://arxiv.org/abs/2505.04203v1","title":"ELGAR: Expressive Cello Performance Motion Generation for Audio\n  Rendition","summary":"The art of instrument performance stands as a vivid manifestation of human\ncreativity and emotion. Nonetheless, generating instrument performance motions\nis a highly challenging task, as it requires not only capturing intricate\nmovements but also reconstructing the complex dynamics of the\nperformer-instrument interaction. While existing works primarily focus on\nmodeling partial body motions, we propose Expressive ceLlo performance motion\nGeneration for Audio Rendition (ELGAR), a state-of-the-art diffusion-based\nframework for whole-body fine-grained instrument performance motion generation\nsolely from audio. To emphasize the interactive nature of the instrument\nperformance, we introduce Hand Interactive Contact Loss (HICL) and Bow\nInteractive Contact Loss (BICL), which effectively guarantee the authenticity\nof the interplay. Moreover, to better evaluate whether the generated motions\nalign with the semantic context of the music audio, we design novel metrics\nspecifically for string instrument performance motion generation, including\nfinger-contact distance, bow-string distance, and bowing score. Extensive\nevaluations and ablation studies are conducted to validate the efficacy of the\nproposed methods. In addition, we put forward a motion generation dataset\nSPD-GEN, collated and normalized from the MoCap dataset SPD. As demonstrated,\nELGAR has shown great potential in generating instrument performance motions\nwith complicated and fast interactions, which will promote further development\nin areas such as animation, music education, interactive art creation, etc.","main_category":"cs.GR","categories":"cs.GR,cs.SD,eess.AS","published":"2025-05-07T07:57:08Z"}
{"aid":"http://arxiv.org/abs/2505.04222v1","title":"Relativistic structure of a supermassive black hole embedded in the dark\n  matter halo of NGC 4649 (M60)","summary":"We construct a static, spherically symmetric black hole (BH) solution\nembedded within a dark matter (DM) halo, formulated as a non-vacuum extension\nof the Schwarzschild spacetime. The DM distribution is modeled via an empirical\ndensity profile calibrated to observations of the elliptical galaxy NGC 4649\n(M60), incorporating Hubble Space Telescope (HST) imaging, stellar velocity\ndispersion data, and globular cluster dynamics. The resultant spacetime metric\ndepends on three independent parameters: the black hole mass $M$, the\nasymptotic circular velocity $V_c$, and the halo scale radius $a$, and smoothly\nreduces to the Schwarzschild limit as $V_c \\to 0$ and $a \\to 0$. We analyze the\ninfluence of the halo on key geometric and physical quantities, including the\nevent horizon radius, photon sphere, shadow size, and curvature invariants. The\nKretschmann scalar exhibits an enhanced sensitivity to halo-induced\nmodifications, particularly in the near-horizon regime. Thermodynamic\nproperties of the solution are also examined. In the extremal limit,\ncharacterized by a vanishing surface gravity, the model supports a finite\ntangential pressure, implying a non-trivial extension of standard black hole\nthermodynamics. These results highlight the relevance of incorporating\nastrophysical environments into BH modeling and offer new avenues for testing\nstrong-field gravity through precision observational data.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE,hep-th","published":"2025-05-07T08:20:12Z"}
{"aid":"http://arxiv.org/abs/2505.04244v1","title":"Spin-valve effect for spin-polarized surface states in topological\n  semimetals","summary":"We experimentally investigate magnetoresistance of a single GeTe-Ni junction\nbetween the $\\alpha$-GeTe topological semimetal and thick nickel film at room\nand liquid helium temperatures. For the magnetic field parallel to the junction\nplane, we demonstrate characteristic spin-valve hysteresis with mirrored\ndifferential resistance $dV/dI$ peaks even at room temperature. In contrast,\nfor normal magnetic fields spin-valve effect appears only at low temperatures.\nFrom the magnetic field anisotropy, observation of the similar effect for\nanother topological semimetal Cd$_3$As$_2$, and strictly flat $dV/dI(H)$\nmagnetoresistance curves for the reference GeTe-Au junction, we connect the\nobserved spin-valve effect with the spin-dependent scattering between the spin\ntextures in the topological surface states and the ferromagnetic nickel\nelectrode. For the topological semimetal $\\alpha$-GeTe, room-temperature\nspin-valve effect allows efficient spin-to-charge conversion even at ambient\nconditions.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-05-07T08:49:28Z"}
{"aid":"http://arxiv.org/abs/2505.04249v1","title":"On the Vulnerability of Underwater Magnetic Induction Communication","summary":"Typical magnetic induction (MI) communication is commonly considered a secure\nunderwater wireless communication (UWC) technology due to its non-audible and\nnon-visible nature compared to acoustic and optical UWC technologies. However,\nvulnerabilities in communication systems inevitably exist and may lead to\ndifferent types of attacks. In this paper, we investigate the eavesdropping\nattack in underwater MI communication to quantitatively measure the system's\nvulnerability under this attack. We consider different potential eavesdropping\nconfiguration setups based on the positions and orientations of the\neavesdropper node to investigate how they impact the received voltage and\nsecrecy at the legitimate receiver node. To this end, we develop\nfinite-element-method-based simulation models for each configuration in an\nunderwater environment and evaluate the received voltage and the secrecy\ncapacity against different system parameters such as magnetic flux, magnetic\nflux density, distance, and orientation sensitivity. Furthermore, we construct\nan experimental setup within a laboratory environment to replicate the\nsimulation experiments. Both simulation and lab experimental confirm the\nsusceptibility of underwater MI communication to eavesdropping attacks.\nHowever, this vulnerability is highly dependent on the position and orientation\nof the coil between the eavesdropper and the legitimate transmitter. On the\npositive side, we also observe a unique behavior in the received coil reception\nthat might be used to detect malicious node activities in the vicinity, which\nmight lead to a potential security mechanism against eavesdropping attacks.","main_category":"cs.CR","categories":"cs.CR","published":"2025-05-07T08:53:18Z"}
{"aid":"http://arxiv.org/abs/2505.04252v1","title":"Space-Time-Dependent Source Identification Problem for a Subdiffusion\n  Equation","summary":"In this paper, we investigate the inverse problem of determining the\nright-hand side of a subdiffusion equation with a Caputo time derivative, where\nthe right-hand side depends on both time and certain spatial variables. Similar\ninverse problems have been previously explored for hyperbolic and parabolic\nequations, with some studies establishing the existence and uniqueness of\ngeneralized solutions, while others proved the uniqueness of classical\nsolutions. However, such inverse problems for fractional-order equations have\nnot been addressed prior to this work. Here, we establish the existence and\nuniqueness of the weak solution to the considered inverse problem. To solve it,\nwe employ the Fourier method with respect to the variable independent of the\nunknown right-hand side, followed by the method of successive approximations to\ncompute the Fourier coefficients of the solution. Notably, the results obtained\nare also novel for parabolic equations.","main_category":"math.AP","categories":"math.AP","published":"2025-05-07T08:57:23Z"}
{"aid":"http://arxiv.org/abs/2505.04261v1","title":"Quantum Cryptography Using Momentum and Position Variables in a Simple\n  Optical Arrangement","summary":"In this work, we explore an experimental implementation of quantum key\ndistribution (QKD) using position and momentum quantum states. By employing a\nsetup that includes a laser, a slit, and lenses to generate a Fourier\ntransform, we demonstrate a variation of the BB84 protocol. Our technique shows\nhow a system with these characteristics can be implemented within a quantum\nframework.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-07T09:11:37Z"}
{"aid":"http://arxiv.org/abs/2505.04267v1","title":"Lattice tilings of Hilbert spaces","summary":"We construct a bounded and symmetric convex body in $\\ell_2(\\Gamma)$ (for\ncertain cardinals $\\Gamma$) whose translates yield a tiling of\n$\\ell_2(\\Gamma)$. This answers a question due to Fonf and Lindenstrauss. As a\nconsequence, we obtain the first example of an infinite-dimensional reflexive\nBanach space that admits a tiling with balls (of radius $1$). Further, our\ntiling has the property of being point-countable and lattice (in the sense that\nthe set of translates forms a group). The same construction performed in\n$\\ell_1(\\Gamma)$ yields a point-$2$-finite lattice tiling by balls of radius\n$1$ for $\\ell_1(\\Gamma)$, which compares to a celebrated construction due to\nKlee. We also prove that lattice tilings by balls are never disjoint and, more\ngenerally, each tile intersects as many tiles as the cardinality of the tiling.\nFinally, we prove some results concerning discrete subgroups of normed spaces.\nBy a simplification of the proof of our main result, we prove that every\ninfinite-dimensional normed space contains a subgroup that is $1$-separated and\n$(1+\\varepsilon)$-dense, for every $\\varepsilon>0$; further, the subgroup\nadmits a set of generators of norm at most $2+\\varepsilon$. This solves a\nproblem due to Swanepoel and yields a simpler proof of a result of Dilworth,\nOdell, Schlumprecht, and Zs\\'ak. We also give an alternative elementary proof\nof Stepr\\={a}ns' result that discrete subgroups of normed spaces are free.","main_category":"math.FA","categories":"math.FA","published":"2025-05-07T09:18:56Z"}
{"aid":"http://arxiv.org/abs/2505.04288v1","title":"A hybridizable discontinuous Galerkin method with transmission variables\n  for time-harmonic electromagnetic problems","summary":"The CHDG method is a hybridizable discontinuous Galerkin (HDG) finite element\nmethod suitable for the iterative solution of time-harmonic wave propagation\nproblems. Hybrid unknowns corresponding to transmission variables are\nintroduced at the element interfaces and the physical unknowns inside the\nelements are eliminated, resulting in a hybridized system with favorable\nproperties for fast iterative solution. In this paper, we extend the CHDG\nmethod, initially studied for the Helmholtz equation, to the time-harmonic\nMaxwell equations. We prove that the local problems stemming from hybridization\nare well-posed and that the fixed-point iteration naturally associated to the\nhybridized system is contractive. We propose a 3D implementation with a\ndiscrete scheme based on nodal basis functions. The resulting solver and\ndifferent iterative strategies are studied with several numerical examples\nusing a high-performance parallel C++ code.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-05-07T09:47:49Z"}
{"aid":"http://arxiv.org/abs/2505.04299v1","title":"WALLABY pilot survey: properties of HI-selected dark sources and low\n  surface brightness galaxies","summary":"We examine the optical counterparts of the 1829 neutral hydrogen (HI)\ndetections in three pilot fields in the Widefield ASKAP L-band Legacy All-sky\nBlind surveY (WALLABY) using data from the Dark Energy Spectroscopic Instrument\n(DESI) Legacy Imaging Surveys DR10. We find that 17 per cent (315) of the\ndetections are optically low surface brightness galaxies (LSBGs; mean $g$-band\nsurface brightness within 1 $ R_e$ of $> 23$ mag arcsec$^{-2}$) and 3 per cent\n(55) are optically 'dark'. We find that the gas-rich WALLABY LSBGs have low\nstar formation efficiencies, and have stellar masses spanning five orders of\nmagnitude, which highlights the diversity of properties across our sample. 75\nper cent of the LSBGs and all of the dark HI sources had not been catalogued\nprior to WALLABY. We examine the optically dark sample of the WALLABY pilot\nsurvey to verify the fidelity of the catalogue and investigate the implications\nfor the full survey for identifying dark HI sources. We assess the HI\ndetections without optical counterparts and identify 38 which pass further\nreliability tests. Of these, we find that 13 show signatures of tidal\ninteractions. The remaining 25 detections have no obvious tidal origin, so are\ncandidates for isolated galaxies with high HI masses, but low stellar masses\nand star-formation rates. Deeper HI and optical follow-up observations are\nrequired to verify the true nature of these dark sources.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-05-07T10:12:33Z"}
{"aid":"http://arxiv.org/abs/2505.04316v1","title":"On local fields invariant under the action of topological defects","summary":"In the context of rational conformal field theories (RCFT) we look into the\nproblem of constructing and classifying pairs consisting of a local operator\nand a topological defect which commutes or anticommutes with it. We discuss the\nbulk and boundary versions of the problem. In the latter one considers a\nconformal boundary condition, a boundary operator on it and a junction with a\ntopological defect. In the case of the charge conjugation modular invariant\ncommuting configurations in each problem can be obtained when a certain\nrestriction on the fusion rules in realised. We study the corresponding fusion\nrule problems in detail. While in the bulk case it reduces to realising the\n$a\\times b = c$ fusion rule which was studied in arXiv:2012.14689 [hep-th], in\nthe boundary it leads to a new type of problem. We obtain a full solution to\nthis problem for the $\\mathrm{SU(3)}$ WZW theory, thus constructing a class of\ncommuting boundary operators and junctions in that theory, and suggest an\napproach to general WZW theories.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-05-07T11:03:56Z"}
{"aid":"http://arxiv.org/abs/2505.04360v1","title":"PersiST: Robust Identification of Spatially Variable Features in Spatial\n  Omics Datasets via Topological Data Analysis","summary":"Spatial transcriptomics studies are becoming increasingly large and\ncommonplace, necessitating the analysis of a large number of spatially resolved\nvariables. With spatial transcriptomics data sets typically containing data on\nthousands of different genes, on increasingly large numbers of samples, there\nis a need for bioinformatics tools that enable the comparison of spatial\nstructure across large numbers of variables. Here we present PersiST, an\nexploratory tool that uses topology to automatically compute a continuous\nmeasure of spatial structure for each gene in a spatial transcriptomics sample.\nThis quantification can be used for analytical tasks such as spatially variable\ngene identification, or searching for spatial differences in the expression of\na gene between samples. We use PersiST to derive biologically meaningful\ninsights into two public spatial transcriptomics data sets, and we experiment\nwith applying PersiST to a spatial metabolomics data set, making use of\nPersiST's non-parametric approach to enable application across different\nmeasurement types. Our work showcases the advantages of using a continuous\nquantification of spatial structure over p-value based approaches to SVG\nidentification, the potential for developing unified methods for the analysis\nof different spatial `omics modalities, and the utility of persistent homology\nin big data applications.","main_category":"q-bio.QM","categories":"q-bio.QM","published":"2025-05-07T12:20:02Z"}
{"aid":"http://arxiv.org/abs/2505.04365v1","title":"CDE-Mapper: Using Retrieval-Augmented Language Models for Linking\n  Clinical Data Elements to Controlled Vocabularies","summary":"The standardization of clinical data elements (CDEs) aims to ensure\nconsistent and comprehensive patient information across various healthcare\nsystems. Existing methods often falter when standardizing CDEs of varying\nrepresentation and complex structure, impeding data integration and\ninteroperability in clinical research. We introduce CDE-Mapper, an innovative\nframework that leverages Retrieval-Augmented Generation approach combined with\nLarge Language Models to automate the linking of CDEs to controlled\nvocabularies. Our modular approach features query decomposition to manage\nvarying levels of CDEs complexity, integrates expert-defined rules within\nprompt engineering, and employs in-context learning alongside multiple\nretriever components to resolve terminological ambiguities. In addition, we\npropose a knowledge reservoir validated by a human-in-loop approach, achieving\naccurate concept linking for future applications while minimizing computational\ncosts. For four diverse datasets, CDE-Mapper achieved an average of 7.2\\%\nhigher accuracy improvement compared to baseline methods. This work highlights\nthe potential of advanced language models in improving data harmonization and\nsignificantly advancing capabilities in clinical decision support systems and\nresearch.","main_category":"cs.IR","categories":"cs.IR,J.3","published":"2025-05-07T12:32:05Z"}
{"aid":"http://arxiv.org/abs/2505.04392v1","title":"Predicting Road Surface Anomalies by Visual Tracking of a Preceding\n  Vehicle","summary":"A novel approach to detect road surface anomalies by visual tracking of a\npreceding vehicle is proposed. The method is versatile, predicting any kind of\nroad anomalies, such as potholes, bumps, debris, etc., unlike direct\nobservation methods that rely on training visual detectors of those cases. The\nmethod operates in low visibility conditions or in dense traffic where the\nanomaly is occluded by a preceding vehicle. Anomalies are detected\npredictively, i.e., before a vehicle encounters them, which allows to\npre-configure low-level vehicle systems (such as chassis) or to plan an\navoidance maneuver in case of autonomous driving. A challenge is that the\nsignal coming from camera-based tracking of a preceding vehicle may be weak and\ndisturbed by camera ego motion due to vibrations affecting the ego vehicle.\nTherefore, we propose an efficient method to compensate camera pitch rotation\nby an iterative robust estimator. Our experiments on both controlled setup and\nnormal traffic conditions show that road anomalies can be detected reliably at\na distance even in challenging cases where the ego vehicle traverses imperfect\nroad surfaces. The method is effective and performs in real time on standard\nconsumer hardware.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-07T13:17:05Z"}
{"aid":"http://arxiv.org/abs/2505.04413v1","title":"A Detailed Investigation of HD 209458 b HST & JWST Transmission Spectra\n  with SANSAR","summary":"HD 209458 b is the first exoplanet on which an atmosphere was detected. Since\nthen, its atmosphere has been investigated using multiple telescopes and\ninstruments. However, many of its atmospheric constraints remain debatable.\nWhile HST observations suggested a highly sub-solar metallicity, recent JWST\nNIRCam observations by Xue et al. 2024 constrained a super-solar metallicity\nwith highly sub-solar C/O. In this work, we show a detailed investigation of HD\n209458 b transmission spectra observations from JWST and HST using SANSAR, a\nnewly developed planetary atmosphere modeling framework, with free, equilibrium\nchemistry and self-consistent grid retrievals. The overall best-fitting model\nwith free retrievals ($\\chi^2_{\\rm{red}}$=1.21) constrains its metallicity and\nC/O to be highly sub-solar, while equilibrium chemistry and grid retrievals\n($\\chi^2_{\\rm{red}}$=1.27 and 1.30, respectively) are consistent with solar\nvalues using STIS+WFC3+NIRCam observations. The retrieved abundances of H$_2$O\nand CO$_2$ are almost three orders of magnitude lower (highly sub-solar) with\nSTIS+WFC3+NIRCam compared to just NIRCam, using free retrievals. NIRCam\nobservations alone also result in misleading constraints on metallicity and\nC/O, with equilibrium chemistry and grid retrieval. We find that the model\nchoice of varying C/H or O/H to vary the C/O in equilibrium chemistry\nretrievals leads to different metallicity constraints with NIRCam, but similar\nconstraints with STIS+WFC3+NIRCam. We conclude that NIRCam observations alone\ncan lead to overestimation of abundances for exoplanet atmospheres and,\ntherefore, should be used in combination with UV/Optical and near-infrared\nobservations to obtain robust constraints on abundances, C/O, and metallicity.\nSpecifically, even though we can detect the CO$_2$ feature with just NIRCam, we\ncannot constrain its abundances robustly without the optical baseline.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM","published":"2025-05-07T13:47:49Z"}
{"aid":"http://arxiv.org/abs/2505.04428v1","title":"Characteristic classes of framed fibre bundles","summary":"We generalize Kontsevich's construction of characteristic classes of fibre\nbundles with homology sphere fibres and a trivialization of the vertical\ntangent bundle to framed fibre bundles with closed manifold fibres.","main_category":"math.AT","categories":"math.AT","published":"2025-05-07T13:58:31Z"}
{"aid":"http://arxiv.org/abs/2505.04436v1","title":"Nearly spanning cycle in the percolated hypercube","summary":"Let $Q^d$ be the $d$-dimensional binary hypercube. We form a random subgraph\n$Q^d_p\\subseteq Q^d$ by retaining each edge of $Q^d$ independently with\nprobability $p$. We show that, for every constant $\\varepsilon>0$, there exists\na constant $C=C(\\varepsilon)>0$ such that, if $p\\ge C/d$, then with high\nprobability $Q^d_p$ contains a cycle of length at least $(1-\\varepsilon)2^d$.\nThis confirms a long-standing folklore conjecture, stated in particular by\nCondon, Espuny D\\'iaz, Gir\\~ao, K\\\"uhn, and Osthus [Hamiltonicity of random\nsubgraphs of the hypercube, Mem. Amer. Math. Soc. 305 (2024), No. 1534].","main_category":"math.CO","categories":"math.CO,math.PR","published":"2025-05-07T14:03:39Z"}
{"aid":"http://arxiv.org/abs/2505.04437v1","title":"Probabilistic Zeeman-Doppler imaging of stellar magnetic fields: I.\n  Analysis of tau Scorpii in the weak-field limit","summary":"Zeeman-Doppler imaging (ZDI) is used to study the surface magnetic field\ntopology of stars, based on high-resolution spectropolarimetric time series\nobservations. Multiple ZDI inversions have been conducted for the early B-type\nstar tau Sco, which has been found to exhibit a weak but complex non-dipolar\nsurface magnetic field. The classical ZDI framework suffers from a significant\nlimitation in that it provides little to no reliable uncertainty quantification\nfor the reconstructed magnetic field maps, with essentially all published\nresults being confined to point estimates. To fill this gap, we propose a\nBayesian framework for probabilistic ZDI. Here, the proposed framework is\ndemonstrated on tau Sco in the weak-field limit. We propose three distinct\nstatistical models, and use archival ESPaDOnS high-resolution Stokes V\nobservations to carry out the probabilistic magnetic inversion in closed form.\nThe surface magnetic field is parameterised by a high-dimensional\nspherical-harmonic expansion. By comparing three different prior distributions\nover the latent variables in the spherical-harmonic decomposition, our results\nshowcase the ZDI sensitivity to various hyperparameters. The mean magnetic\nfield maps are qualitatively similar to previously published point estimates,\nbut analysis of the magnetic energy distribution indicates high uncertainty and\nhigher energy content at low angular degrees l. Our results effectively\ndemonstrate that, for stars in the weak-field regime, reliable uncertainty\nquantification of recovered magnetic field maps can be obtained in closed form\nwith natural assumptions on the statistical model. Future work will explore\nextending this framework beyond the weak-field approximation and incorporating\nprior uncertainty over multiple stellar parameters in more complex magnetic\ninversion problems.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.IM","published":"2025-05-07T14:06:25Z"}
{"aid":"http://arxiv.org/abs/2505.04461v1","title":"A Survey on Temporal Interaction Graph Representation Learning:\n  Progress, Challenges, and Opportunities","summary":"Temporal interaction graphs (TIGs), defined by sequences of timestamped\ninteraction events, have become ubiquitous in real-world applications due to\ntheir capability to model complex dynamic system behaviors. As a result,\ntemporal interaction graph representation learning (TIGRL) has garnered\nsignificant attention in recent years. TIGRL aims to embed nodes in TIGs into\nlow-dimensional representations that effectively preserve both structural and\ntemporal information, thereby enhancing the performance of downstream tasks\nsuch as classification, prediction, and clustering within constantly evolving\ndata environments. In this paper, we begin by introducing the foundational\nconcepts of TIGs and emphasize the critical role of temporal dependencies. We\nthen propose a comprehensive taxonomy of state-of-the-art TIGRL methods,\nsystematically categorizing them based on the types of information utilized\nduring the learning process to address the unique challenges inherent to TIGs.\nTo facilitate further research and practical applications, we curate the source\nof datasets and benchmarks, providing valuable resources for empirical\ninvestigations. Finally, we examine key open challenges and explore promising\nresearch directions in TIGRL, laying the groundwork for future advancements\nthat have the potential to shape the evolution of this field.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.SI","published":"2025-05-07T14:31:10Z"}
{"aid":"http://arxiv.org/abs/2505.04474v1","title":"Portal Matter Models of Kinetic Mixing with Two Light Dark Gauge Bosons","summary":"The kinetic mixing (KM) portal mandates the existence of at least one new\ngauge boson, the dark photon (DP) based on the group $U(1)_D$, which mixes with\nthe Standard Model (SM) photon via loops of other new heavy particles carrying\nboth SM and dark charges called portal matter (PM). Arguments exist based on\nthe RGE running of the $U(1)_D$ gauge coupling suggesting that at higher scales\n$U(1)_D$ becomes part of a more complex non-Abelian group, a simple example\nbeing just the SM-like $G_D=SU(2)_I \\times U(1)_{Y_I}$. In our past analyses it\nwas always assumed that $G_D$ broke in a SM-like manner directly to the DP's\n$U(1)_D$ which then subsequently broke at low energies $\\lsim 1$ GeV. However,\nthis need not be the case and $G_D$ can instead break to $U(1)_{T_{3I}}\\times\nU(1)_{Y_I}$, with $T_{3I}$ being the diagonal generator of $SU(2)_I$, now\nproducing two light gauge bosons which obtain masses at the $\\lsim 1$ GeV\nscale. In this paper we will explore the phenomenology of a very simple\nrealization of this kind of alternative setup employing non-abelian KM and\nhaving a minimal, lepton-like PM sector, demonstrating its distinctive nature\nin comparison to the previously examined symmetry breaking path. The effects of\ninterference between these gauge bosons on thermal dark matter annihilation,\nthe production of new heavy gauge, Higgs and PM states at colliders, as well as\nthe corresponding signatures for the light dark gauge bosons are examined.","main_category":"hep-ph","categories":"hep-ph","published":"2025-05-07T14:43:15Z"}
{"aid":"http://arxiv.org/abs/2505.04490v1","title":"Mid-infrared quantum scanning microscopy via visible light beyond\n  spatial correlations","summary":"The mid-infrared (MIR) region of the electromagnetic spectrum spans from 2-\nto 25-$\\mu \\mathrm{m}$, serving as a valuable tool for accessing rich chemical\ninformation. Functional groups, lipids, and other complex molecules can be\nanalyzed by optical absorption measurements due to their vibrational modes in\nthe MIR spectral region. Over the past few decades, this field has faced\nchallenges due to difficulties in generating MIR light and the limited maturity\nof detection systems in this spectral range. Quantum imaging with undetected\nlight (QIUL) provides a spectrally tuneable photon-pair source, in which the\nsample can be illuminated with MIR light while visible (VIS) light is employed\nfor detection and image reconstruction, overcoming the detection limitations\nand benefiting from the rich chemical information of the MIR spectral region.\nAll previous QIUL implementations are based on spatial correlations, which are\nnever perfect and thus hindered the imaging performance. In this work, we\nimplement a raster-scanning QIUL method that is independent of the strength of\nthe spatial correlations and achieves a spatial resolution beyond the\nlimitations of these correlations.","main_category":"physics.optics","categories":"physics.optics","published":"2025-05-07T15:06:43Z"}
{"aid":"http://arxiv.org/abs/2505.04532v1","title":"Integrated equilibrium model for electrified logistics and power systems","summary":"This paper proposes an integrated equilibrium model to characterize the\ncomplex interactions between electrified logistics systems and electric power\ndelivery systems. The model consists of two major players: an electrified\nlogistics operator (ELO) and a power system operator (PSO). The ELO aims to\nmaximize its profit by strategically scheduling and routing its electric\ndelivery vehicles (e-trucks) for deliveries and charging, in response to the\nlocational marginal price (LMP) set by the PSO. The routing, delivery, and\ncharging behaviors of e-trucks are modeled by a perturbed utility Markov\ndecision process (PU-MDP) while their collective operations are optimized to\nachieve the ELO's objective by designing rewards in the PU-MDP. On the other\nhand, PSO optimizes the energy price by considering both the spatiotemporal\ne-truck charging demand and the base electricity load. The equilibrium of the\nintegrated system is formulated as a fixed point, proved to exist under mild\nassumptions, and solved for a case study on the Hawaii network via Anderson's\nfixed-point acceleration algorithm. Along with these numerical results, this\npaper provides both theoretical insights and practical guidelines to achieve\nsustainable and efficient operations in modern electrified logistics and power\nsystems.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-05-07T16:05:15Z"}
{"aid":"http://arxiv.org/abs/2505.04542v1","title":"Rigidity results for finite energy solutions to the stationary 2D Euler\n  equations","summary":"In this paper we prove rigidity results for classical solutions to the\nstationary 2D Euler equations in $\\mathbb{R}^2$. Assuming that the velocity\nfield has finite energy and that the stagnation set is connected, we prove that\nthe corresponding stream function solves an autonomous semilinear elliptic\nequation. Under some extra conditions on the vorticity near infinity we can\nalso prove that the streamlines are concentric circles. The proofs include\nseveral energy estimates on the behavior of the stream function at infinity, as\nwell as an adaptation of the continuous Steiner symmetrization to our setting.","main_category":"math.AP","categories":"math.AP","published":"2025-05-07T16:24:12Z"}
{"aid":"http://arxiv.org/abs/2505.04587v1","title":"Integral Chow rings of modular compactifications of\n  $\\mathcal{M}_{1,n\\leq 6}$","summary":"For $n\\leq 6$, we compute the integral Chow ring of every modular\ncompactification of $\\mathcal{M}_{1,n}$ parametrising only Gorenstein curves\nwith smooth, distinct markings. These include the Deligne--Mumford, Schubert,\nand Smyth compactifications, and many more. They can all be excised from the\nstack of log-canonically polarised Gorenstein curves. The Chow ring of the\nlatter admits a simple, combinatorial description, which we compute by patching\nalong a natural stratification by core level. We further deduce that all these\nmodular compactifications satisfy the Chow-K\\\"{u}nneth generation property,\nthat the cycle class map is an isomorphism, and for $n=4$ we study whether the\nGetzler's relation hold integrally.","main_category":"math.AG","categories":"math.AG","published":"2025-05-07T17:29:51Z"}
{"aid":"http://arxiv.org/abs/2505.04599v1","title":"Complexity Lower Bounds of Adaptive Gradient Algorithms for Non-convex\n  Stochastic Optimization under Relaxed Smoothness","summary":"Recent results in non-convex stochastic optimization demonstrate the\nconvergence of popular adaptive algorithms (e.g., AdaGrad) under the $(L_0,\nL_1)$-smoothness condition, but the rate of convergence is a higher-order\npolynomial in terms of problem parameters like the smoothness constants. The\ncomplexity guaranteed by such algorithms to find an $\\epsilon$-stationary point\nmay be significantly larger than the optimal complexity of $\\Theta \\left(\n\\Delta L \\sigma^2 \\epsilon^{-4} \\right)$ achieved by SGD in the $L$-smooth\nsetting, where $\\Delta$ is the initial optimality gap, $\\sigma^2$ is the\nvariance of stochastic gradient. However, it is currently not known whether\nthese higher-order dependencies can be tightened. To answer this question, we\ninvestigate complexity lower bounds for several adaptive optimization\nalgorithms in the $(L_0, L_1)$-smooth setting, with a focus on the dependence\nin terms of problem parameters $\\Delta, L_0, L_1$. We provide complexity bounds\nfor three variations of AdaGrad, which show at least a quadratic dependence on\nproblem parameters $\\Delta, L_0, L_1$. Notably, we show that the decorrelated\nvariant of AdaGrad-Norm requires at least $\\Omega \\left( \\Delta^2 L_1^2\n\\sigma^2 \\epsilon^{-4} \\right)$ stochastic gradient queries to find an\n$\\epsilon$-stationary point. We also provide a lower bound for SGD with a broad\nclass of adaptive stepsizes. Our results show that, for certain adaptive\nalgorithms, the $(L_0, L_1)$-smooth setting is fundamentally more difficult\nthan the standard smooth setting, in terms of the initial optimality gap and\nthe smoothness constants.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-07T17:40:12Z"}
{"aid":"http://arxiv.org/abs/2505.04609v1","title":"CAPERS-LRD-z9: A Gas Enshrouded Little Red Dot Hosting a Broad-line AGN\n  at z=9.288","summary":"We present CAPERS-LRD-z9, a little red dot (LRD) which we confirm to be a\n$z=9.288$ broad-line AGN (BLAGN). First identified as a high-redshift LRD\ncandidate from PRIMER NIRCam photometry, follow-up NIRSpec/PRISM spectroscopy\nof CAPERS-LRD-z9 from the CANDELS-Area Prism Epoch of Reionization Survey\n(CAPERS) has revealed a broad $3500$ km s$^{-1}$ H$\\beta$ emission line and\nnarrow [O III]$\\lambda\\lambda4959,5007$ lines, indicative of a BLAGN. Based on\nthe broad H$\\beta$ line, we compute a canonical black-hole mass of\n$\\log(M_{\\textrm{BH}}/M_{\\odot})=7.58\\pm0.15$, although full consideration of\nsystematic uncertainties yields a conservative range of\n$6.65<\\log(M_{\\textrm{BH}}/M_{\\odot})<8.50$. These observations suggest that\neither a massive black hole seed, or a lighter stellar remnant seed undergoing\nperiods of super-Eddington accretion, is necessary to grow such a massive black\nhole in $\\lesssim500$ Myr of cosmic time. CAPERS-LRD-z9 exhibits a strong\nBalmer break, consistent with a central AGN surrounded by dense ($\\sim\n10^{10}\\textrm{ cm}^{-3}$) neutral gas. We model CAPERS-LRD-z9 using CLOUDY to\nfit the emission red-ward of the Balmer break with a dense gas-enshrouded AGN,\nand bagpipes to fit the rest-ultraviolet emission as a host-galaxy stellar\npopulation. This upper limit on the stellar mass of the host galaxy\n($<10^9\\,{\\rm M_\\odot}$) implies that the black-hole to stellar mass ratio may\nbe extremely large, possibly $>5\\%$ (although systematic uncertainties on the\nblack-hole mass prevent strong conclusions). However, the shape of the UV\ncontinuum differs from typical high-redshift star-forming galaxies, indicating\nthat this UV emission may also be of AGN origin, and hence the true stellar\nmass of the host may be still lower.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-05-07T17:53:48Z"}
{"aid":"http://arxiv.org/abs/2505.04615v1","title":"Improved Predictions on Higgs-Starobinsky Inflation and Reheating with\n  ACT DR6 and Primordial Gravitational Waves","summary":"We investigate the implications of recent CMB observations for\nHiggs-Starobinsky inflationary models and their associated reheating dynamics,\nutilizing data from ACT DR6, Planck 2018, BICEP/Keck 2018, and DESI,\ncollectively referred to as P-ACT-LB-BK18. In addition to direct CMB\nconstraints, we incorporate indirect bounds arising from the potential\noverproduction of primordial gravitational waves (PGWs), particularly through\nlimits on the effective number of relativistic species, $\\Delta N_{\\rm eff}$,\nduring Big Bang Nucleosynthesis (BBN). These constraints become especially\nrelevant in scenarios featuring a stiff post-inflationary equation of state\n$w_{\\rm RH}\\geq 0.58$. Our analysis shows that, when both P-ACT-LB-BK18 data\nand $\\Delta N_{\\rm eff}$ bounds are considered, the viable number of\ninflationary e-folds is restricted to the range ($57.9$-$62.2$) at the\n$2\\sigma$ confidence level (C.L.). Correspondingly, the reheating temperature\nis constrained to lie between the BBN energy scale and $10^{12}$ GeV, with the\npost-inflationary equation-of-state parameter satisfying $w_{\\rm RH} > 0.41$.\nHowever, no parameter space remains viable at the $1\\sigma$ C.L. once $\\Delta\nN_{\\rm eff}$ constraints from PGWs are included, rendering the\nHiggs-Starobinsky model highly restricted.","main_category":"astro-ph.CO","categories":"astro-ph.CO,hep-ph","published":"2025-05-07T17:58:13Z"}
{"aid":"http://arxiv.org/abs/2505.04919v1","title":"Isomorphism Theorems for Impartial Combinatorial Games","summary":"We introduce the category of optiongraphs and option preserving maps as a\nmodel to study impartial combinatorial games. Outcomes, remoteness, and\nextended nim-values are preserved under option preserving maps. We show that\nthe four isomorphism theorems from universal algebra are valid in this\ncategory. Quotient optiongraphs, including the minimum quotient, provide\nsimplifications that can help in the analysis of games.","main_category":"math.CO","categories":"math.CO","published":"2025-05-08T03:27:28Z"}
{"aid":"http://arxiv.org/abs/2505.04920v1","title":"The k-Sudoku Number of Graphs","summary":"Let $G=(V,E)$ be a graph of order $n$ with chromatic number $\\chi(G)$. Let $\nk \\geq \\chi(G) $ and $S \\subseteq V$. Let $ C_0 $ be a $k$-coloring of the\ninduced subgraph $ G[S] $. The coloring $C_0$ is called an extendable coloring,\nif $C_0$ can be extended to a $k$-coloring of $G$ and it is a $k$- Sudoku\ncoloring of $G$, if $C_0$ can be uniquely extended to a $k$-coloring of $G$.\nThe smallest order of such an induced subgraph $G[S]$ of $G$ which admits a\n$k$- Sudoku coloring is called $k$- Sudoku number of $G$ and is denoted by\n$sn(G,k)$. When $k=\\chi(G)$, we call $k$- Sudoku number of $G$ as Sudoku number\nof $G$ and is denoted by $sn(G)$. In this paper, we have obtained the $3$-\nSudoku number of some bipartite graphs $P_n$, $C_{2n}$, $K_{m,n}$, $B_{m,n}$\nand $G \\circ lK_1$, where $G$ is a bipartite graph and $l\\geq1$. Also, we have\nobtained the necessary and sufficient conditions for a bipartite graph $G$ to\nhave $sn(G,3)$ equal to $n$, $n-1$ or $n-2$. Also, we study the relation\nbetween $k$- Sudoku number of a graph $G$ and the Sudoku number of a supergraph\n$H$ of $G$.","main_category":"math.CO","categories":"math.CO","published":"2025-05-08T03:30:27Z"}
{"aid":"http://arxiv.org/abs/2505.04934v1","title":"Enhancing Blockchain Cross Chain Interoperability: A Comprehensive\n  Survey","summary":"Blockchain technology, introduced in 2008, has revolutionized data storage\nand transfer across sectors such as finance, healthcare, intelligent\ntransportation, and the metaverse. However, the proliferation of blockchain\nsystems has led to discrepancies in architectures, consensus mechanisms, and\ndata standards, creating data and value silos that hinder the development of an\nintegrated multi chain ecosystem. Blockchain interoperability (a.k.a cross\nchain interoperability) has thus emerged as a solution to enable seamless data\nand asset exchange across disparate blockchains. In this survey, we\nsystematically analyze over 150 high impact sources from academic journals,\ndigital libraries, and grey literature to provide an in depth examination of\nblockchain interoperability. By exploring the existing methods, technologies,\nand architectures, we offer a classification of interoperability approaches\nincluding Atomic Swaps, Sidechains, Light Clients, and so on, which represent\nthe most comprehensive overview to date. Furthermore, we investigate the\nconvergence of academic research with industry practices, underscoring the\nimportance of collaborative efforts in advancing blockchain innovation.\nFinally, we identify key strategic insights, challenges, and future research\ntrajectories in this field. Our findings aim to support researchers,\npolicymakers, and industry leaders in understanding and harnessing the\ntransformative potential of blockchain interoperability to address current\nchallenges and drive forward a cohesive multi-chain ecosystem.","main_category":"cs.CR","categories":"cs.CR","published":"2025-05-08T04:24:50Z"}
{"aid":"http://arxiv.org/abs/2505.04935v1","title":"Real-Time Model Predictive Control of Vehicles with Convex-Polygon-Aware\n  Collision Avoidance in Tight Spaces","summary":"This paper proposes vehicle motion planning methods with obstacle avoidance\nin tight spaces by incorporating polygonal approximations of both the vehicle\nand obstacles into a model predictive control (MPC) framework. Representing\nthese shapes is crucial for navigation in tight spaces to ensure accurate\ncollision detection. However, incorporating polygonal approximations leads to\ndisjunctive OR constraints in the MPC formulation, which require a mixed\ninteger programming and cause significant computational cost. To overcome this,\nwe propose two different collision-avoidance constraints that reformulate the\ndisjunctive OR constraints as tractable conjunctive AND constraints: (1) a\nSupport Vector Machine (SVM)-based formulation that recasts collision avoidance\nas a SVM optimization problem, and (2) a Minimum Signed Distance to Edges\n(MSDE) formulation that leverages minimum signed-distance metrics. We validate\nboth methods through extensive simulations, including tight-space parking\nscenarios and varied-shape obstacle courses, as well as hardware experiments on\nan RC-car platform. Our results demonstrate that the SVM-based approach\nachieves superior navigation accuracy in constrained environments; the MSDE\napproach, by contrast, runs in real time with only a modest reduction in\ncollision-avoidance performance.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-08T04:26:07Z"}
{"aid":"http://arxiv.org/abs/2505.04948v1","title":"Prompt-Based LLMs for Position Bias-Aware Reranking in Personalized\n  Recommendations","summary":"Recommender systems are essential for delivering personalized content across\ndigital platforms by modeling user preferences and behaviors. Recently, large\nlanguage models (LLMs) have been adopted for prompt-based recommendation due to\ntheir ability to generate personalized outputs without task-specific training.\nHowever, LLM-based methods face limitations such as limited context window\nsize, inefficient pointwise and pairwise prompting, and difficulty handling\nlistwise ranking due to token constraints. LLMs can also be sensitive to\nposition bias, as they may overemphasize earlier items in the prompt regardless\nof their true relevance. To address and investigate these issues, we propose a\nhybrid framework that combines a traditional recommendation model with an LLM\nfor reranking top-k items using structured prompts. We evaluate the effects of\nuser history reordering and instructional prompts for mitigating position bias.\nExperiments on MovieLens-100K show that randomizing user history improves\nranking quality, but LLM-based reranking does not outperform the base model.\nExplicit instructions to reduce position bias are also ineffective. Our\nevaluations reveal limitations in LLMs' ability to model ranking context and\nmitigate bias. Our code is publicly available at\nhttps://github.com/aminul7506/LLMForReRanking.","main_category":"cs.IR","categories":"cs.IR,cs.CL","published":"2025-05-08T05:01:44Z"}
{"aid":"http://arxiv.org/abs/2505.04949v1","title":"With a Little Help From My Friends: Exploiting Probability Distribution\n  Advice in Algorithm Design","summary":"We study online algorithms with predictions using distributional advice, a\ntype of prediction that arises when leveraging expert knowledge or historical\ndata. To demonstrate the usefulness and versatility of this framework, we focus\non two fundamental problems: first, the prophet inequality problem, for which\nwe provide an algorithm achieving\n$\\max\\{\\frac{1}{2}-\\eta-o(1),\\frac{1}{e}\\}$-competitive ratio, where $\\eta$\nquantifies the quality of the prediction. Second, we turn to the online metric\nmatching problem under random arrivals, for which our main positive result is\nan algorithm achieving the optimal cost under perfect advice, while smoothly\ndefaulting to competitive ratios comparable to advice-free algorithms as the\nprediction's quality degrades.","main_category":"cs.DS","categories":"cs.DS","published":"2025-05-08T05:08:23Z"}
{"aid":"http://arxiv.org/abs/2505.04955v1","title":"Chain-of-Thought Tokens are Computer Program Variables","summary":"Chain-of-thoughts (CoT) requires large language models (LLMs) to generate\nintermediate steps before reaching the final answer, and has been proven\neffective to help LLMs solve complex reasoning tasks. However, the inner\nmechanism of CoT still remains largely unclear. In this paper, we empirically\nstudy the role of CoT tokens in LLMs on two compositional tasks: multi-digit\nmultiplication and dynamic programming. While CoT is essential for solving\nthese problems, we find that preserving only tokens that store intermediate\nresults would achieve comparable performance. Furthermore, we observe that\nstoring intermediate results in an alternative latent form will not affect\nmodel performance. We also randomly intervene some values in CoT, and notice\nthat subsequent CoT tokens and the final answer would change correspondingly.\nThese findings suggest that CoT tokens may function like variables in computer\nprograms but with potential drawbacks like unintended shortcuts and\ncomputational complexity limits between tokens. The code and data are available\nat https://github.com/solitaryzero/CoTs_are_Variables.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-05-08T05:32:36Z"}
{"aid":"http://arxiv.org/abs/2505.04957v1","title":"The Poisson tensor completion non-parametric differential entropy\n  estimator","summary":"We introduce the Poisson tensor completion (PTC) estimator, a non-parametric\ndifferential entropy estimator. The PTC estimator leverages inter-sample\nrelationships to compute a low-rank Poisson tensor decomposition of the\nfrequency histogram. Our crucial observation is that the histogram bins are an\ninstance of a space partitioning of counts and thus can be identified with a\nspatial Poisson process. The Poisson tensor decomposition leads to a completion\nof the intensity measure over all bins -- including those containing few to no\nsamples -- and leads to our proposed PTC differential entropy estimator. A\nPoisson tensor decomposition models the underlying distribution of the count\ndata and guarantees non-negative estimated values and so can be safely used\ndirectly in entropy estimation. We believe our estimator is the first\ntensor-based estimator that exploits the underlying spatial Poisson process\nrelated to the histogram explicitly when estimating the probability density\nwith low-rank tensor decompositions or tensor completion. Furthermore, we\ndemonstrate that our PTC estimator is a substantial improvement over standard\nhistogram-based estimators for sub-Gaussian probability distributions because\nof the concentration of norm phenomenon.","main_category":"math.ST","categories":"math.ST,stat.ME,stat.TH","published":"2025-05-08T05:38:59Z"}
{"aid":"http://arxiv.org/abs/2505.04960v1","title":"Learning Item Representations Directly from Multimodal Features for\n  Effective Recommendation","summary":"Conventional multimodal recommender systems predominantly leverage Bayesian\nPersonalized Ranking (BPR) optimization to learn item representations by\namalgamating item identity (ID) embeddings with multimodal features.\nNevertheless, our empirical and theoretical findings unequivocally demonstrate\na pronounced optimization gradient bias in favor of acquiring representations\nfrom multimodal features over item ID embeddings. As a consequence, item ID\nembeddings frequently exhibit suboptimal characteristics despite the\nconvergence of multimodal feature parameters. Given the rich informational\ncontent inherent in multimodal features, in this paper, we propose a novel\nmodel (i.e., LIRDRec) that learns item representations directly from these\nfeatures to augment recommendation performance. Recognizing that features\nderived from each modality may capture disparate yet correlated aspects of\nitems, we propose a multimodal transformation mechanism, integrated with\nmodality-specific encoders, to effectively fuse features from all modalities.\nMoreover, to differentiate the influence of diverse modality types, we devise a\nprogressive weight copying fusion module within LIRDRec. This module\nincrementally learns the weight assigned to each modality in synthesizing the\nfinal user or item representations. Finally, we utilize the powerful visual\nunderstanding of Multimodal Large Language Models (MLLMs) to convert the item\nimages into texts and extract semantics embeddings upon the texts via LLMs.\nEmpirical evaluations conducted on five real-world datasets validate the\nsuperiority of our approach relative to competing baselines. It is worth noting\nthe proposed model, equipped with embeddings extracted from MLLMs and LLMs, can\nfurther improve the recommendation accuracy of NDCG@20 by an average of 4.21%\ncompared to the original embeddings.","main_category":"cs.IR","categories":"cs.IR,cs.MM","published":"2025-05-08T05:42:22Z"}
{"aid":"http://arxiv.org/abs/2505.04962v1","title":"An Efficient Method for Accurate Pose Estimation and Error Correction of\n  Cuboidal Objects","summary":"The proposed system outlined in this paper is a solution to a use case that\nrequires the autonomous picking of cuboidal objects from an organized or\nunorganized pile with high precision. This paper presents an efficient method\nfor precise pose estimation of cuboid-shaped objects, which aims to reduce\nerrors in target pose in a time-efficient manner. Typical pose estimation\nmethods like global point cloud registrations are prone to minor pose errors\nfor which local registration algorithms are generally used to improve pose\naccuracy. However, due to the execution time overhead and uncertainty in the\nerror of the final achieved pose, an alternate, linear time approach is\nproposed for pose error estimation and correction. This paper presents an\noverview of the solution followed by a detailed description of individual\nmodules of the proposed algorithm.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-05-08T05:43:31Z"}
{"aid":"http://arxiv.org/abs/2505.04980v1","title":"LVLM-MPC Collaboration for Autonomous Driving: A Safety-Aware and\n  Task-Scalable Control Architecture","summary":"This paper proposes a novel Large Vision-Language Model (LVLM) and Model\nPredictive Control (MPC) integration framework that delivers both task\nscalability and safety for Autonomous Driving (AD). LVLMs excel at high-level\ntask planning across diverse driving scenarios. However, since these foundation\nmodels are not specifically designed for driving and their reasoning is not\nconsistent with the feasibility of low-level motion planning, concerns remain\nregarding safety and smooth task switching. This paper integrates LVLMs with\nMPC Builder, which automatically generates MPCs on demand, based on symbolic\ntask commands generated by the LVLM, while ensuring optimality and safety. The\ngenerated MPCs can strongly assist the execution or rejection of LVLM-driven\ntask switching by providing feedback on the feasibility of the given tasks and\ngenerating task-switching-aware MPCs. Our approach provides a safe, flexible,\nand adaptable control framework, bridging the gap between cutting-edge\nfoundation models and reliable vehicle operation. We demonstrate the\neffectiveness of our approach through a simulation experiment, showing that our\nsystem can safely and effectively handle highway driving while maintaining the\nflexibility and adaptability of LVLMs.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-05-08T06:35:30Z"}
{"aid":"http://arxiv.org/abs/2505.04994v1","title":"Rethinking Invariance in In-context Learning","summary":"In-Context Learning (ICL) has emerged as a pivotal capability of\nauto-regressive large language models, yet it is hindered by a notable\nsensitivity to the ordering of context examples regardless of their mutual\nindependence. To address this issue, recent studies have introduced several\nvariant algorithms of ICL that achieve permutation invariance. However, many of\nthese do not exhibit comparable performance with the standard auto-regressive\nICL algorithm. In this work, we identify two crucial elements in the design of\nan invariant ICL algorithm: information non-leakage and context\ninterdependence, which are not simultaneously achieved by any of the existing\nmethods. These investigations lead us to the proposed Invariant ICL (InvICL), a\nmethodology designed to achieve invariance in ICL while ensuring the two\nproperties. Empirically, our findings reveal that InvICL surpasses previous\nmodels, both invariant and non-invariant, in most benchmark datasets,\nshowcasing superior generalization capabilities across varying input lengths.\nCode is available at https://github.com/PKU-ML/InvICL.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-05-08T06:59:14Z"}
{"aid":"http://arxiv.org/abs/2505.05011v1","title":"Reality-infused Deep Learning Framework via Angle-resolved Metasurfaces","summary":"Metasurfaces and optical Fourier surfaces (OFSs), featuring patterned\nnanostructures and profiled diffractive elements, offer versatile platforms for\nlight field manipulation. Compared to tuning structural parameters, adjusting\nincident light angles provides greater design flexibility. However,\nangle-resolved light behaviors are often complex due to diverse mode\nexcitations and couplings, posing challenges for simulations and\nnanofabrication. Here, we present a reality-infused deep learning framework\naugmented by angle-resolved measuring technology, enabling precise and\nreal-time predictions of angular dispersion characteristics for metasurfaces\nand OFSs. This approach captures critical fabrication and measurement\nimperfections typically missed by conventional simulations. We demonstrate a\n900-fold acceleration in the design process and accomplish near-perfect\nprediction consistency to experimental results, with an impressive accuracy up\nto 99.8%. Our study not only supports valuable insights into the development of\nmeta-devices but also represents a paradigm shift from simulation-driven to\nreality-infused methods, paving the way for advancements in extensive optical\ndesign applications.","main_category":"physics.optics","categories":"physics.optics,physics.app-ph","published":"2025-05-08T07:31:25Z"}
{"aid":"http://arxiv.org/abs/2505.05018v1","title":"Diffusion-enabled Secure Semantic Communication Against Eavesdropping","summary":"In this paper, AN is introduced into semantic communication systems for the\nfirst time to prevent semantic eavesdropping. However, the introduction of AN\nalso poses challenges for the legitimate receiver in extracting semantic\ninformation. Recently, denoising diffusion probabilistic models (DDPM) have\ndemonstrated their powerful capabilities in generating multimedia content.\nHere, the paired pluggable modules are carefully designed using DDPM.\nSpecifically, the pluggable encryption module generates AN and adds it to the\noutput of the semantic transmitter, while the pluggable decryption module\nbefore semantic receiver uses DDPM to generate the detailed semantic\ninformation by removing both AN and the channel noise. In the scenario where\nthe transmitter lacks eavesdropper's knowledge, the artificial Gaussian noise\n(AGN) is used as AN. We first model a power allocation optimization problem to\ndetermine the power of AGN, in which the objective is to minimize the weighted\nsum of data reconstruction error of legal link, the mutual information of\nillegal link, and the channel input distortion. Then, a deep reinforcement\nlearning framework using deep deterministic policy gradient is proposed to\nsolve the optimization problem. In the scenario where the transmitter is aware\nof the eavesdropper's knowledge, we propose an AN generation method based on\nadversarial residual networks (ARN). Unlike the previous scenario, the mutual\ninformation term in the objective function is replaced by the confidence of\neavesdropper correctly\n  retrieving private information. The adversarial residual network is then\ntrained to minimize the modified objective function. The simulation results\nshow that the diffusion-enabled pluggable encryption module prevents semantic\neavesdropping while the pluggable decryption module achieves the high-quality\nsemantic communication.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-05-08T07:47:52Z"}
{"aid":"http://arxiv.org/abs/2505.05038v1","title":"Uncertainty-Aware Scarf Plots","summary":"Multiple challenges emerge when analyzing eye-tracking data with areas of\ninterest (AOIs) because recordings are subject to different sources of\nuncertainties. Previous work often presents gaze data without considering those\ninaccuracies in the data. To address this issue, we developed uncertainty-aware\nscarf plot visualizations that aim to make analysts aware of uncertainties with\nrespect to the position-based mapping of gaze to AOIs and depth dependency in\n3D scenes. Additionally, we also consider uncertainties in automatic AOI\nannotation. We showcase our approach in comparison to standard scarf plots in\nan augmented reality scenario.","main_category":"cs.HC","categories":"cs.HC","published":"2025-05-08T08:17:58Z"}
{"aid":"http://arxiv.org/abs/2505.05048v1","title":"Angles of orthocentric simplices","summary":"A $d$-dimensional simplex in Euclidean space is called orthocentric if all of\nits altitudes intersect at a single point, referred to as the orthocenter. We\nexplicitly compute the internal and external angles at all faces of an\northocentric simplex. To this end, we introduce a parametric family of\npolyhedral cones, called orthocentric cones, and derive formulas for their\nangles and, more generally, for their conic intrinsic volumes.\n  We characterize the tangent and normal cones of orthocentric simplices in\nterms of orthocentric cones with explicit parameters. Depending on whether the\northocenter lies inside the simplex, on its boundary, or outside, the simplex\nis classified as acute, rectangular, or obtuse, respectively. The solid angle\nformulas differ in these three cases.\n  As a probabilistic application of the angle formulas, we explicitly compute\nthe expected number of $k$-dimensional faces and the expected volume of the\nrandom polytope $[g_1/\\tau_1, \\ldots, g_n/\\tau_n]$, where $g_1, \\ldots, g_n$\nare independent standard Gaussian vectors in $\\mathbb{R}^d$, and $\\tau_1,\n\\ldots, \\tau_n > 0$ are constants.","main_category":"math.MG","categories":"math.MG,math.PR","published":"2025-05-08T08:35:10Z"}
{"aid":"http://arxiv.org/abs/2505.05057v1","title":"Towards Mitigating API Hallucination in Code Generated by LLMs with\n  Hierarchical Dependency Aware","summary":"Application Programming Interfaces (APIs) are crucial in modern software\ndevelopment. Large Language Models (LLMs) assist in automated code generation\nbut often struggle with API hallucination, including invoking non-existent APIs\nand misusing existing ones in practical development scenarios. Existing studies\nresort to Retrieval-Augmented Generation (RAG) methods for mitigating the\nhallucination issue, but tend to fail since they generally ignore the\nstructural dependencies in practical projects and do not indeed validate\nwhether the generated APIs are available or not. To address these limitations,\nwe propose MARIN, a framework for mitigating API hallucination in code\ngenerated by LLMs with hierarchical dependency aware. MARIN consists of two\nphases: Hierarchical Dependency Mining, which analyzes local and global\ndependencies of the current function, aiming to supplement comprehensive\nproject context in LLMs input, and Dependency Constrained Decoding, which\nutilizes mined dependencies to adaptively constrain the generation process,\naiming to ensure the generated APIs align with the projects specifications. To\nfacilitate the evaluation of the degree of API hallucination, we introduce a\nnew benchmark APIHulBench and two new metrics including Micro Hallucination\nNumber (MiHN) and Macro Hallucination Rate (MaHR). Experiments on six\nstate-of-the-art LLMs demonstrate that MARIN effectively reduces API\nhallucinations, achieving an average decrease of 67.52% in MiHN and 73.56% in\nMaHR compared to the RAG approach. Applied to Huaweis internal projects and two\nproprietary LLMs, MARIN achieves average decreases of 57.33% in MiHN and 59.41%\nin MaHR.","main_category":"cs.SE","categories":"cs.SE","published":"2025-05-08T08:48:17Z"}
{"aid":"http://arxiv.org/abs/2505.05073v1","title":"RepSNet: A Nucleus Instance Segmentation model based on Boundary\n  Regression and Structural Re-parameterization","summary":"Pathological diagnosis is the gold standard for tumor diagnosis, and nucleus\ninstance segmentation is a key step in digital pathology analysis and\npathological diagnosis. However, the computational efficiency of the model and\nthe treatment of overlapping targets are the major challenges in the studies of\nthis problem. To this end, a neural network model RepSNet was designed based on\na nucleus boundary regression and a structural re-parameterization scheme for\nsegmenting and classifying the nuclei in H\\&E-stained histopathological images.\nFirst, RepSNet estimates the boundary position information (BPI) of the parent\nnucleus for each pixel. The BPI estimation incorporates the local information\nof the pixel and the contextual information of the parent nucleus. Then, the\nnucleus boundary is estimated by aggregating the BPIs from a series of pixels\nusing a proposed boundary voting mechanism (BVM), and the instance segmentation\nresults are computed from the estimated nucleus boundary using a connected\ncomponent analysis procedure. The BVM intrinsically achieves a kind of\nsynergistic belief enhancement among the BPIs from various pixels. Therefore,\ndifferent from the methods available in literature that obtain nucleus\nboundaries based on a direct pixel recognition scheme, RepSNet computes its\nboundary decisions based on some guidances from macroscopic information using\nan integration mechanism. In addition, RepSNet employs a re-parametrizable\nencoder-decoder structure. This model can not only aggregate features from some\nreceptive fields with various scales which helps segmentation accuracy\nimprovement, but also reduce the parameter amount and computational burdens in\nthe model inference phase through the structural re-parameterization technique.\nExtensive experiments demonstrated the superiorities of RepSNet compared to\nseveral typical benchmark models.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-05-08T09:08:58Z"}
{"aid":"http://arxiv.org/abs/2505.05088v1","title":"SSH-Net: A Self-Supervised and Hybrid Network for Noisy Image Watermark\n  Removal","summary":"Visible watermark removal is challenging due to its inherent complexities and\nthe noise carried within images. Existing methods primarily rely on supervised\nlearning approaches that require paired datasets of watermarked and\nwatermark-free images, which are often impractical to obtain in real-world\nscenarios. To address this challenge, we propose SSH-Net, a Self-Supervised and\nHybrid Network specifically designed for noisy image watermark removal. SSH-Net\nsynthesizes reference watermark-free images using the watermark distribution in\na self-supervised manner and adopts a dual-network design to address the task.\nThe upper network, focused on the simpler task of noise removal, employs a\nlightweight CNN-based architecture, while the lower network, designed to handle\nthe more complex task of simultaneously removing watermarks and noise,\nincorporates Transformer blocks to model long-range dependencies and capture\nintricate image features. To enhance the model's effectiveness, a shared\nCNN-based feature encoder is introduced before dual networks to extract common\nfeatures that both networks can leverage. Our code will be available at\nhttps://github.com/wenyang001/SSH-Net.","main_category":"cs.MM","categories":"cs.MM,cs.CV,eess.IV","published":"2025-05-08T09:36:49Z"}
{"aid":"http://arxiv.org/abs/2505.05113v1","title":"Loss-Versus-Rebalancing under Deterministic and Generalized block-times","summary":"Although modern blockchains almost universally produce blocks at fixed\nintervals, existing models still lack an analytical formula for the\nloss-versus-rebalancing (LVR) incurred by Automated Market Makers (AMMs)\nliquidity providers in this setting. Leveraging tools from random walk theory,\nwe derive the following closed-form approximation for the per block per unit of\nliquidity expected LVR under constant block time:\n  \\[ \\overline{\\mathrm{ARB}}= \\frac{\\,\\sigma_b^{2}}\n{\\,2+\\sqrt{2\\pi}\\,\\gamma/(|\\zeta(1/2)|\\,\\sigma_b)\\,}+O\\!\\bigl(e^{-\\mathrm{const}\\tfrac{\\gamma}{\\sigma_b}}\\bigr)\\;\\approx\\;\n\\frac{\\sigma_b^{2}}{\\,2 + 1.7164\\,\\gamma/\\sigma_b}, \\] where $\\sigma_b$ is the\nintra-block asset volatility, $\\gamma$ the AMM spread and $\\zeta$ the Riemann\nZeta function. Our large Monte Carlo simulations show that this formula is in\nfact quasi-exact across practical parameter ranges.\n  Extending our analysis to arbitrary block-time distributions as well, we\ndemonstrate both that--under every admissible inter-block law--the probability\nthat a block carries an arbitrage trade converges to a universal limit, and\nthat only constant block spacing attains the asymptotically minimal LVR. This\nshows that constant block intervals provide the best possible protection\nagainst arbitrage for liquidity providers. \\end{abstract}","main_category":"q-fin.MF","categories":"q-fin.MF,math.PR,q-fin.PM,q-fin.PR,q-fin.TR","published":"2025-05-08T10:30:24Z"}
{"aid":"http://arxiv.org/abs/2505.05129v1","title":"Bulldozing an immersed granular material in a confined channel","summary":"The motion of an immersed granular material in a channel is characterised by\ncomplex interactions among the grains, between the grains and the permeating\nliquid, and between the grains and the channel walls. Here, we develop a\nreduced-order continuum model for the bulldozing of an immersed, sedimented\ngranular material by a piston in a channel. In our continuum approach, the\ngranular pile and the overlying fluid layer evolve as a system of coupled thin\nfilms. We model the granular phase as a dense, porous, visco-plastic material\nthat experiences Coulomb-like friction with the walls. Conservation of mass and\nmomentum under a thin-film approximation leads to an elliptic equation for the\nvelocity of the grains that is coupled with an evolution equation for the\nheight of the granular pile. We solve our model numerically for a variety of\ndifferent scenarios to explore the interactions between wall friction, internal\nviscous-like stresses, and fluid flow above and through the pile. We complement\nour numerical results with a series of experiments that provide insight into\nthe validity and limitations of the model.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.flu-dyn","published":"2025-05-08T11:05:18Z"}
{"aid":"http://arxiv.org/abs/2505.05132v1","title":"An Active Contour Model for Silhouette Vectorization using Bzier\n  Curves","summary":"In this paper, we propose an active contour model for silhouette\nvectorization using cubic B\\'ezier curves. Among the end points of the B\\'ezier\ncurves, we distinguish between corner and regular points where the orientation\nof the tangent vector is prescribed. By minimizing the distance of the B\\'ezier\ncurves to the silhouette boundary, the active contour model optimizes the\nlocation of the B\\'ezier curves end points, the orientation of the tangent\nvectors in the regular points, and the estimation of the B\\'ezier curve\nparameters. This active contour model can use the silhouette vectorization\nobtained by any method as an initial guess. The proposed method significantly\nreduces the average distance between the silhouette boundary and its\nvectorization obtained by the world-class graphic software Inkscape, Adobe\nIllustrator, and a curvature-based vectorization method, which we introduce for\ncomparison. Our method also allows us to impose additional regularity on the\nB\\'ezier curves by reducing their lengths.","main_category":"cs.GR","categories":"cs.GR,cs.CV,math.FA","published":"2025-05-08T11:09:49Z"}
{"aid":"http://arxiv.org/abs/2505.05137v1","title":"Research on Anomaly Detection Methods Based on Diffusion Models","summary":"Anomaly detection is a fundamental task in machine learning and data mining,\nwith significant applications in cybersecurity, industrial fault diagnosis, and\nclinical disease monitoring. Traditional methods, such as statistical modeling\nand machine learning-based approaches, often face challenges in handling\ncomplex, high-dimensional data distributions. In this study, we explore the\npotential of diffusion models for anomaly detection, proposing a novel\nframework that leverages the strengths of diffusion probabilistic models (DPMs)\nto effectively identify anomalies in both image and audio data. The proposed\nmethod models the distribution of normal data through a diffusion process and\nreconstructs input data via reverse diffusion, using a combination of\nreconstruction errors and semantic discrepancies as anomaly indicators. To\nenhance the framework's performance, we introduce multi-scale feature\nextraction, attention mechanisms, and wavelet-domain representations, enabling\nthe model to capture fine-grained structures and global dependencies in the\ndata. Extensive experiments on benchmark datasets, including MVTec AD and\nUrbanSound8K, demonstrate that our method outperforms state-of-the-art anomaly\ndetection techniques, achieving superior accuracy and robustness across diverse\ndata modalities. This research highlights the effectiveness of diffusion models\nin anomaly detection and provides a robust and efficient solution for\nreal-world applications.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-05-08T11:19:08Z"}
{"aid":"http://arxiv.org/abs/2505.05151v1","title":"Overcoming Dimensional Factorization Limits in Discrete Diffusion Models\n  through Quantum Joint Distribution Learning","summary":"This study explores quantum-enhanced discrete diffusion models to overcome\nclassical limitations in learning high-dimensional distributions. We rigorously\nprove that classical discrete diffusion models, which calculate per-dimension\ntransition probabilities to avoid exponential computational cost, exhibit\nworst-case linear scaling of Kullback-Leibler (KL) divergence with data\ndimension. To address this, we propose a Quantum Discrete Denoising Diffusion\nProbabilistic Model (QD3PM), which enables joint probability learning through\ndiffusion and denoising in exponentially large Hilbert spaces. By deriving\nposterior states through quantum Bayes' theorem, similar to the crucial role of\nposterior probabilities in classical diffusion models, and by learning the\njoint probability, we establish a solid theoretical foundation for\nquantum-enhanced diffusion models. For denoising, we design a quantum circuit\nusing temporal information for parameter sharing and learnable\nclassical-data-controlled rotations for encoding. Exploiting joint distribution\nlearning, our approach enables single-step sampling from pure noise,\neliminating iterative requirements of existing models. Simulations demonstrate\nthe proposed model's superior accuracy in modeling complex distributions\ncompared to factorization methods. Hence, this paper establishes a new\ntheoretical paradigm in generative models by leveraging the quantum advantage\nin joint distribution learning.","main_category":"quant-ph","categories":"quant-ph,cs.LG","published":"2025-05-08T11:48:21Z"}
{"aid":"http://arxiv.org/abs/2505.05177v1","title":"MARK: Memory Augmented Refinement of Knowledge","summary":"Large Language Models (LLMs) assist in specialized tasks but struggle to\nalign with evolving domain knowledge without costly fine-tuning. Domain\nknowledge consists of: Knowledge: Immutable facts (e.g., 'A stone is solid')\nand generally accepted principles (e.g., ethical standards); Refined Memory:\nEvolving insights shaped by business needs and real-world changes. However, a\nsignificant gap often exists between a domain expert's deep, nuanced\nunderstanding and the system's domain knowledge, which can hinder accurate\ninformation retrieval and application. Our Memory-Augmented Refinement of\nKnowledge (MARK) framework enables LLMs to continuously learn without\nretraining by leveraging structured refined memory, inspired by the Society of\nMind. MARK operates through specialized agents, each serving a distinct role:\nResidual Refined Memory Agent: Stores and retrieves domain-specific insights to\nmaintain context over time; User Question Refined Memory Agent: Captures\nuser-provided facts, abbreviations, and terminology for better comprehension;\nLLM Response Refined Memory Agent: Extracts key elements from responses for\nrefinement and personalization. These agents analyse stored refined memory,\ndetect patterns, resolve contradictions, and improve response accuracy.\nTemporal factors like recency and frequency prioritize relevant information\nwhile discarding outdated insights. MARK enhances LLMs in multiple ways: Ground\nTruth Strategy: Reduces hallucinations by establishing a structured reference;\nDomain-Specific Adaptation: Essential for fields like healthcare, law, and\nmanufacturing, where proprietary insights are absent from public datasets;\nPersonalized AI Assistants: Improves virtual assistants by remembering user\npreferences, ensuring coherent responses over time.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-05-08T12:28:00Z"}
{"aid":"http://arxiv.org/abs/2505.05190v1","title":"Revealing Weaknesses in Text Watermarking Through Self-Information\n  Rewrite Attacks","summary":"Text watermarking aims to subtly embed statistical signals into text by\ncontrolling the Large Language Model (LLM)'s sampling process, enabling\nwatermark detectors to verify that the output was generated by the specified\nmodel. The robustness of these watermarking algorithms has become a key factor\nin evaluating their effectiveness. Current text watermarking algorithms embed\nwatermarks in high-entropy tokens to ensure text quality. In this paper, we\nreveal that this seemingly benign design can be exploited by attackers, posing\na significant risk to the robustness of the watermark. We introduce a generic\nefficient paraphrasing attack, the Self-Information Rewrite Attack (SIRA),\nwhich leverages the vulnerability by calculating the self-information of each\ntoken to identify potential pattern tokens and perform targeted attack. Our\nwork exposes a widely prevalent vulnerability in current watermarking\nalgorithms. The experimental results show SIRA achieves nearly 100% attack\nsuccess rates on seven recent watermarking methods with only 0.88 USD per\nmillion tokens cost. Our approach does not require any access to the watermark\nalgorithms or the watermarked LLM and can seamlessly transfer to any LLM as the\nattack model, even mobile-level models. Our findings highlight the urgent need\nfor more robust watermarking.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL,cs.CR","published":"2025-05-08T12:39:00Z"}
{"aid":"http://arxiv.org/abs/2505.05195v1","title":"Concept-Based Unsupervised Domain Adaptation","summary":"Concept Bottleneck Models (CBMs) enhance interpretability by explaining\npredictions through human-understandable concepts but typically assume that\ntraining and test data share the same distribution. This assumption often fails\nunder domain shifts, leading to degraded performance and poor generalization.\nTo address these limitations and improve the robustness of CBMs, we propose the\nConcept-based Unsupervised Domain Adaptation (CUDA) framework. CUDA is designed\nto: (1) align concept representations across domains using adversarial\ntraining, (2) introduce a relaxation threshold to allow minor domain-specific\ndifferences in concept distributions, thereby preventing performance drop due\nto over-constraints of these distributions, (3) infer concepts directly in the\ntarget domain without requiring labeled concept data, enabling CBMs to adapt to\ndiverse domains, and (4) integrate concept learning into conventional domain\nadaptation (DA) with theoretical guarantees, improving interpretability and\nestablishing new benchmarks for DA. Experiments demonstrate that our approach\nsignificantly outperforms the state-of-the-art CBM and DA methods on real-world\ndatasets.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV","published":"2025-05-08T12:52:02Z"}
{"aid":"http://arxiv.org/abs/2505.05204v1","title":"Static and dynamic properties of Kitaev-Heisenberg ferromagnet on a\n  triangular lattice","summary":"We present an extensive study of ground state and excitations of\nferromagnetic anisotropic-exchange Kitaev-Heisenberg model on a triangular\nlattice using order-by-disorder calculations. It is shown that while\nbond-dependent terms do not affect the ground state classically, quantum\nfluctuations select preferred magnetization direction of the ferromagnetic\nstate. Anisotropic terms of the magnetic Hamiltonian also give rise to\nmagnon-magnon interactions that lead to spontaneous decays and spectral\nrenormalization, which we illustrate using non-linear spin-wave theory.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-05-08T13:00:32Z"}
{"aid":"http://arxiv.org/abs/2505.05217v1","title":"Topology optimization of viscoelastic microstructures with acoustic\n  impedance manipulation","summary":"Mitigating low-frequency noise is particularly challenging due to its limited\nnatural attenuation. This study aims to design viscoelastic composite\nmicrostructures that achieve both low acoustic reflection and high internal\ndamping by simultaneously optimizing their effective acoustic impedance and\nattenuation characteristics. Using homogenization theory and density-based\ntopology optimization, viscoelastic and impedance-matching materials are\ndistributed within a unit cell to manipulate these properties. Numerical\nresults show that optimized microstructures with viscoelastic lattice embedded\nin impedance-matching material outperform pure viscoelastic materials in\nattenuation while maintaining low reflection. This demonstrates the potential\nof microstructural engineering for effective low-frequency noise mitigation.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-05-08T13:10:31Z"}
{"aid":"http://arxiv.org/abs/2505.05221v1","title":"Core-surface kinematic control of polarity reversals in advanced\n  geodynamo simulations","summary":"The geomagnetic field has undergone hundreds of polarity reversals over\nEarth's history, at a variable pace. In numerical models of Earth's core\ndynamics, reversals occur with increasing frequency when the convective forcing\nis increased past a critical level. This transition has previously been related\nto the influence of inertia in the force balance. Because this force is\nsubdominant in Earth's core, concerns have been raised regarding the\ngeophysical applicability of this paradigm. Reproducing the reversal rate of\nthe past million years also requires forcing conditions that do not guarantee\nthat the rest of the geomagnetic variation spectrum is reproduced. These issues\nmotivate the search for alternative reversal mechanisms. Using a suite of\nnumerical models where buoyancy is provided at the bottom of the core by\ninner-core freezing, we show that the magnetic dipole amplitude is controlled\nby the relative strength of subsurface upwellings and horizontal circulation at\nthe core surface. A relative weakening of upwellings brings the system from a\nstable to a reversing dipole state. This mechanism is purely kinematic because\nit operates irrespectively of the interior force balance. It is therefore\nexpected to apply at the physical conditions of Earth's core. Subsurface\nupwellings may be impeded by stable stratification in the outermost core. We\nshow that with weak stratification levels corresponding to a nearly adiabatic\ncore surface heat flow, a single model reproduces the observed geomagnetic\nvariations ranging from decades to millions of years. \\rev{In contrast with}\nthe existing paradigm, reversals caused by this stable top core mechanism\nbecome more frequent when the level of stratification increases i.e. when the\ncore heat flow decreases. This suggests that the link between mantle dynamics\nand magnetic reversal frequency needs to be reexamined.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-05-08T13:12:37Z"}
{"aid":"http://arxiv.org/abs/2505.05230v1","title":"Theoretical characterisation of the Barium II and Radium II ions","summary":"Motivated by recent experimental advances, including the ongoing development\nof an optical atomic clock in singly ionised radium, we perform a detailed\ntheoretical characterisation of Ra+ and its lighter analogue, Ba+. Both ions\nare of interest for precision studies, including for atomic parity violation\nand searches for new physics beyond the standard model. Using the all-orders\ncorrelation potential method, including Breit and radiative quantum\nelectrodynamics corrections, we perform high-accuracy calculations of\nelectric-dipole (E1), electric-quadrupole (E2), and magnetic-dipole (M1)\ntransition matrix elements between the low-lying s, p, and d states of these\nions, as well as the excited-state lifetimes, polarizabilities, magic\nwavelengths, and magnetic dipole (A) hyperfine structure constants. By\ncombining lifetime measurements with precise theoretical ratios, we extract\nhigh-accuracy determinations of the s-d_1/2 and s-d_3/2 E2 matrix elements. By\ncombining hyperfine measurements with atomic theory, we extract parameters of\nthe nuclear magnetisation distribution (the Bohr-Weisskopf effect) for 135-,\n137-Ba and 223-, 225-Ra. These results provide theoretical input for ongoing\nand future experimental programs in fundamental physics and precision\nmetrology.","main_category":"physics.atom-ph","categories":"physics.atom-ph,nucl-th","published":"2025-05-08T13:23:14Z"}
{"aid":"http://arxiv.org/abs/2505.05269v1","title":"A Two-Sample Test of Text Generation Similarity","summary":"The surge in digitized text data requires reliable inferential methods on\nobserved textual patterns. This article proposes a novel two-sample text test\nfor comparing similarity between two groups of documents. The hypothesis is\nwhether the probabilistic mapping generating the textual data is identical\nacross two groups of documents. The proposed test aims to assess text\nsimilarity by comparing the entropy of the documents. Entropy is estimated\nusing neural network-based language models. The test statistic is derived from\nan estimation-and-inference framework, where the entropy is first approximated\nusing an estimation set, followed by inference on the remaining data set. We\nshowed theoretically that under mild conditions, the test statistic\nasymptotically follows a normal distribution. A multiple data-splitting\nstrategy is proposed to enhance test power, which combines p-values into a\nunified decision. Various simulation studies and a real data example\ndemonstrated that the proposed two-sample text test maintains the nominal Type\none error rate while offering greater power compared to existing methods. The\nproposed method provides a novel solution to assert differences in document\nclasses, particularly in fields where large-scale textual information is\ncrucial.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-05-08T14:15:53Z"}
{"aid":"http://arxiv.org/abs/2505.05272v1","title":"Vacuum stability conditions for new $SU(2)$ multiplets","summary":"We consider the addition to the Standard Model of a scalar $SU(2)$ multiplet\n$\\Delta_n$ with dimension $n$ going from $1$ to $6$. The multiplet $\\Delta_n$\nis assumed to have null vacuum expectation value and an arbitrary (free)\nhypercharge. We determine the shape of the phase space for the new terms that\nappear in the scalar potential (SP); we observe in particular that, in the case\nof a 6-plet, the phase space is slightly concave along one of its boundaries.\nWe determine the bounded-from-below and vacuum stability conditions on the SP\nfor each value of $n$.","main_category":"hep-ph","categories":"hep-ph,hep-th","published":"2025-05-08T14:18:09Z"}
{"aid":"http://arxiv.org/abs/2505.05281v1","title":"Metallicities of 20 Million Giant Stars Based on Gaia XP spectra","summary":"We design an uncertainty-aware cost-sensitive neural network (UA-CSNet) to\nestimate metallicities from dereddened and corrected Gaia BP/RP (XP) spectra\nfor giant stars. This method accounts for both stochastic errors in the input\nspectra and the imbalanced density distribution in [Fe/H] values. With a\nspecialized architecture and training strategy, the UA-CSNet improves the\nprecision of the predicted metallicities, especially for very metal-poor (VMP;\n$\\rm [Fe/H] \\leq -2.0$) stars. With the PASTEL catalog as the training sample,\nour model can estimate metallicities down to $\\rm [Fe/H] \\sim -4$. We compare\nour estimates with a number of external catalogs and conduct tests using star\nclusters, finding overall good agreement. We also confirm that our estimates\nfor VMP stars are unaffected by carbon enhancement. Applying the UA-CSNet, we\nobtain reliable and precise metallicity estimates for approximately 20 million\ngiant stars, including 360,000 VMP stars and 50,000 extremely metal-poor (EMP;\n$\\rm [Fe/H] \\leq -3.0$) stars. The resulting catalog is publicly available at\nhttps://doi.org/10.12149/101604. This work highlights the potential of\nlow-resolution spectra for metallicity estimation and provides a valuable\ndataset for studying the formation and chemo-dynamical evolution of our Galaxy.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA,astro-ph.IM","published":"2025-05-08T14:27:18Z"}
{"aid":"http://arxiv.org/abs/2505.05286v1","title":"HEXGEN-TEXT2SQL: Optimizing LLM Inference Request Scheduling for Agentic\n  Text-to-SQL Workflow","summary":"Recent advances in leveraging the agentic paradigm of large language models\n(LLMs) utilization have significantly enhanced Text-to-SQL capabilities,\nenabling users without specialized database expertise to query data\nintuitively. However, deploying these agentic LLM-based Text-to-SQL systems in\nproduction poses substantial challenges due to their inherently multi-stage\nworkflows, stringent latency constraints, and potentially heterogeneous GPU\ninfrastructure in enterprise environments. Current LLM serving frameworks lack\neffective mechanisms for handling interdependent inference tasks, dynamic\nlatency variability, and resource heterogeneity, leading to suboptimal\nperformance and frequent service-level objective (SLO) violations. In this\npaper, we introduce HEXGEN-TEXT2SQL, a novel framework designed explicitly to\nschedule and execute agentic multi-stage LLM-based Text-to-SQL workflows on\nheterogeneous GPU clusters that handle multi-tenant end-to-end queries.\nHEXGEN-TEXT2SQL introduce a hierarchical scheduling approach combining global\nworkload-balanced task dispatching and local adaptive urgency-guided\nprioritization, guided by a systematic analysis of agentic Text-to-SQL\nworkflows. Additionally, we propose a lightweight simulation-based method for\ntuning critical scheduling hyperparameters, further enhancing robustness and\nadaptability. Our extensive evaluation on realistic Text-to-SQL benchmarks\ndemonstrates that HEXGEN-TEXT2SQL significantly outperforms state-of-the-art\nLLM serving frameworks. Specifically, HEXGEN-TEXT2SQL reduces latency deadlines\nby up to 1.67$\\times$ (average: 1.41$\\times$) and improves system throughput by\nup to 1.75$\\times$ (average: 1.65$\\times$) compared to vLLM under diverse,\nrealistic workload conditions. Our code is available at\nhttps://github.com/Relaxed-System-Lab/Hexgen-Flow.","main_category":"cs.DB","categories":"cs.DB","published":"2025-05-08T14:28:47Z"}
{"aid":"http://arxiv.org/abs/2505.05289v1","title":"From the Bloch equation to a thermodynamically consistent master\n  equation","summary":"The Bloch equation, that set the foundation for open quantum systems, was\nconceived by pure physical reasoning. Since then, the Lindblad (GKLS) form of a\nquantum master equation, its most general mathematical representation, became\nan established staple in the open quantum systems toolbox. It allows to\ndescribe a multitude of quantum phenomena, however, its universality comes at a\ncost -- without additional constraints, the resultant dynamics are not\nnecessarily thermodynamically consistent, and the equation itself lacks an\nintuitive interpretation.\n  We present a mathematically equivalent form of the Lindblad master equation\nunder a single constraint of strict energy conservation. The ``elemental\nBloch'' equation separates the system dynamics into its elemental parts, making\nan explicit distinction between thermal mixing, dephasing, and energy\nrelaxation, and thus reinstating the physical intuition in the equation. We\nderive the equation for a many-level system by accounting for all relevant\ntransitions between pairs of levels.\n  Finally, the formalism is illustrated by calculating the fixed point of the\ndynamics and exploring the conditions for canonical invariance in quantum\nsystems.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-08T14:29:47Z"}
{"aid":"http://arxiv.org/abs/2505.05324v1","title":"The geometry of zonotopal algebras II: Orlik--Terao algebras and\n  Schubert varieties","summary":"Zonotopal algebras, introduced by Postnikov--Shapiro--Shapiro,\nArdila--Postnikov, and Holtz--Ron, show up in many different contexts,\nincluding approximation theory, representation theory, Donaldson--Thomas\ntheory, and hypertoric geometry. In the first half of this paper, we construct\na perfect pairing between the internal zonotopal algebra of a linear space and\nthe reduced Orlik--Terao algebra of the Gale dual linear space. As an\napplication, we prove a conjecture of Moseley--Proudfoot--Young that relates\nthe reduced Orlik--Terao algebra of a graph to the cohomology of a certain\nconfiguration space. In the second half of the paper, we interpret the Macaulay\ninverse system of a zonotopal algebra as the space of sections of a sheaf on\nthe Schubert variety of a linear space. As an application of this, we use an\nequivariant resolution of the structure sheaf of the Schubert variety inside of\na product of projective lines to produce an exact sequence relating internal\nand external zonotopal algebras.","main_category":"math.AG","categories":"math.AG,math.CO","published":"2025-05-08T15:10:13Z"}
{"aid":"http://arxiv.org/abs/2505.05342v1","title":"Rigorous Methods for Bohr-Sommerfeld Quantization Rules","summary":"In this work, we prove Bohr-Sommerfeld quantization rules for the\nself-adjoint Zakharov-Shabat system and the Schr\\\"odinger equation in the\npresence of two simple turning points bounding a classically allowed region. In\nparticular, we use the method of comparison equations for $2\\times 2$ traceless\nfirst-order systems to provide a unified perspective that yields similar proofs\nin each setting. The use of a Weber model system gives results that are uniform\nin the eigenvalue parameter over the whole range from the bottom of the\npotential well up to finite values.","main_category":"math.CA","categories":"math.CA","published":"2025-05-08T15:29:18Z"}
{"aid":"http://arxiv.org/abs/2505.05354v1","title":"High-fidelity Grain Growth Modeling: Leveraging Deep Learning for Fast\n  Computations","summary":"Grain growth simulation is crucial for predicting metallic material\nmicrostructure evolution during annealing and resulting final mechanical\nproperties, but traditional partial differential equation-based methods are\ncomputationally expensive, creating bottlenecks in materials design and\nmanufacturing. In this work, we introduce a machine learning framework that\ncombines a Convolutional Long Short-Term Memory networks with an Autoencoder to\nefficiently predict grain growth evolution. Our approach captures both spatial\nand temporal aspects of grain evolution while encoding high-dimensional grain\nstructure data into a compact latent space for pattern learning, enhanced by a\nnovel composite loss function combining Mean Squared Error, Structural\nSimilarity Index Measurement, and Boundary Preservation to maintain structural\nintegrity of grain boundary topology of the prediction. Results demonstrated\nthat our machine learning approach accelerates grain growth prediction by up to\n\\SI{89}{\\times} faster, reducing computation time from \\SI{10}{\\minute} to\napproximately \\SI{10}{\\second} while maintaining high-fidelity predictions. The\nbest model (S-30-30) achieving a structural similarity score of\n\\SI{86.71}{\\percent} and mean grain size error of just \\SI{0.07}{\\percent}. All\nmodels accurately captured grain boundary topology, morphology, and size\ndistributions. This approach enables rapid microstructural prediction for\napplications where conventional simulations are prohibitively time-consuming,\npotentially accelerating innovation in materials science and manufacturing.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cs.AI","published":"2025-05-08T15:43:40Z"}
{"aid":"http://arxiv.org/abs/2505.05384v1","title":"Machine learning model for efficient nonthermal tuning of the charge\n  density wave in monolayer NbSe$_2$","summary":"Understanding and controlling the charge density wave (CDW) phase diagram of\ntransition metal dichalcogenides is a long-studied problem in condensed matter\nphysics. However, due to complex involvement of electron and lattice degrees of\nfreedom and pronounced anharmonicity, theoretical simulations of the CDW phase\ndiagram at the density-functional-theory level are often numerically demanding.\nTo reduce the computational cost of first principles modelling by orders of\nmagnitude, we have developed an electronic free energy machine learning model\nfor monolayer NbSe$_2$ that allows changing both electronic and ionic\ntemperatures independently. Our approach relies on a machine learning model of\nthe electronic density of states and zero-temperature interatomic potential.\nThis allows us to explore the CDW phase diagram of monolayer NbSe$_2$ both\nunder thermal and laser-induced nonthermal conditions. Our study provides an\naccurate estimate of the CDW transition temperature at low cost and can\ndisentangle the role of hot electrons and phonons in nonthermal ultrafast\nmelting process of the CDW phase in NbSe$_2$.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el,physics.comp-ph","published":"2025-05-08T16:16:32Z"}
{"aid":"http://arxiv.org/abs/2505.05397v1","title":"PillarMamba: Learning Local-Global Context for Roadside Point Cloud via\n  Hybrid State Space Model","summary":"Serving the Intelligent Transport System (ITS) and Vehicle-to-Everything\n(V2X) tasks, roadside perception has received increasing attention in recent\nyears, as it can extend the perception range of connected vehicles and improve\ntraffic safety. However, roadside point cloud oriented 3D object detection has\nnot been effectively explored. To some extent, the key to the performance of a\npoint cloud detector lies in the receptive field of the network and the ability\nto effectively utilize the scene context. The recent emergence of Mamba, based\non State Space Model (SSM), has shaken up the traditional convolution and\ntransformers that have long been the foundational building blocks, due to its\nefficient global receptive field. In this work, we introduce Mamba to\npillar-based roadside point cloud perception and propose a framework based on\nCross-stage State-space Group (CSG), called PillarMamba. It enhances the\nexpressiveness of the network and achieves efficient computation through\ncross-stage feature fusion. However, due to the limitations of scan directions,\nstate space model faces local connection disrupted and historical relationship\nforgotten. To address this, we propose the Hybrid State-space Block (HSB) to\nobtain the local-global context of roadside point cloud. Specifically, it\nenhances neighborhood connections through local convolution and preserves\nhistorical memory through residual attention. The proposed method outperforms\nthe state-of-the-art methods on the popular large scale roadside benchmark:\nDAIR-V2X-I. The code will be released soon.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-08T16:33:04Z"}
{"aid":"http://arxiv.org/abs/2505.05402v1","title":"CART-ELC: Oblique Decision Tree Induction via Exhaustive Search","summary":"Oblique decision trees have attracted attention due to their potential for\nimproved classification performance over traditional axis-aligned decision\ntrees. However, methods that rely on exhaustive search to find oblique splits\nface computational challenges. As a result, they have not been widely explored.\nWe introduce a novel algorithm, Classification and Regression Tree - Exhaustive\nLinear Combinations (CART-ELC), for inducing oblique decision trees that\nperforms an exhaustive search on a restricted set of hyperplanes. We then\ninvestigate the algorithm's computational complexity and its predictive\ncapabilities. Our results demonstrate that CART-ELC consistently achieves\ncompetitive performance on small datasets, often yielding statistically\nsignificant improvements in classification accuracy relative to existing\ndecision tree induction algorithms, while frequently producing shallower,\nsimpler, and thus more interpretable trees.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.DS","published":"2025-05-08T16:42:13Z"}
{"aid":"http://arxiv.org/abs/2505.05423v1","title":"TransProQA: an LLM-based literary Translation evaluation metric with\n  Professional Question Answering","summary":"The impact of Large Language Models (LLMs) has extended into literary\ndomains. However, existing evaluation metrics prioritize mechanical accuracy\nover artistic expression and tend to overrate machine translation (MT) as being\nsuperior to experienced professional human translation. In the long run, this\nbias could result in a permanent decline in translation quality and cultural\nauthenticity. In response to the urgent need for a specialized literary\nevaluation metric, we introduce TransProQA, a novel, reference-free, LLM-based\nquestion-answering (QA) framework designed specifically for literary\ntranslation evaluation. TransProQA uniquely integrates insights from\nprofessional literary translators and researchers, focusing on critical\nelements in literary quality assessment such as literary devices, cultural\nunderstanding, and authorial voice. Our extensive evaluation shows that while\nliterary-finetuned XCOMET-XL yields marginal gains, TransProQA substantially\noutperforms current metrics, achieving up to 0.07 gain in correlation (ACC-EQ\nand Kendall's tau) and surpassing the best state-of-the-art (SOTA) metrics by\nover 15 points in adequacy assessments. Incorporating professional translator\ninsights as weights further improves performance, highlighting the value of\ntranslator inputs. Notably, TransProQA approaches human-level evaluation\nperformance comparable to trained linguistic annotators. It demonstrates broad\napplicability to open-source models such as LLaMA3.3-70b and Qwen2.5-32b,\nindicating its potential as an accessible and training-free literary evaluation\nmetric and a valuable tool for evaluating texts that require local processing\ndue to copyright or ethical considerations.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-05-08T17:12:56Z"}
{"aid":"http://arxiv.org/abs/2505.05460v1","title":"Reduced Basis Method for Driven-Dissipative Quantum Systems","summary":"Reduced basis methods provide an efficient way of mapping out phase diagrams\nof strongly correlated many-body quantum systems. The method relies on using\nthe exact solutions at select parameter values to construct a low-dimensional\nbasis, from which observables can be efficiently and reliably computed\nthroughout the parameter space. Here we show that this method can be\ngeneralized to driven-dissipative Markovian systems allowing efficient\ncalculations of observables in the transient and steady states. A subsequent\ndistillation of the reduced basis vectors according to their explained\nvariances allows for an unbiased exploration of the most pronounced parameter\ndependencies indicative of phase boundaries in the thermodynamic limit.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,quant-ph","published":"2025-05-08T17:53:23Z"}
